418|10000|Public
5000|$|Writing {{about real}} people usually {{means there is}} a wealth of {{material}} to draw on. Not in this case. Apart from mentions in a few ghosted autobiographies and tabloid newspaper interviews there was virtually nothing. This meant we had to look in some odd places <b>for</b> <b>our</b> <b>data.</b> We had our memories of course; we both remembered Big Daddy on 'Tiswas' and Kendo Nagasaki being unmasked. We remembered the spectacle of seemingly thousands of old ladies at a fever pitch of excitement by the ringside, waving their umbrellas {{in the air and}} chanting 'Easy easy!' It was this excitement we wished to transmit by translating wrestling into theatre. Which, of course, is what it always was.|$|E
30|$|<b>For</b> <b>our</b> <b>data,</b> we fitted {{these three}} models using Proc CATMOD in SAS {{software}} [23]. <b>For</b> <b>our</b> <b>data,</b> the best model was the non-homogeneous model. Table 4 shows the regression coefficients, standard errors, and p values.|$|E
40|$|The {{fluctuation}} conductivity measurement {{on the new}} Y-based Y 3 Ba 5 Cu 8 O 18 - x superconductor is presented. The dimensional crossovers {{between different}} temperature regimes were analyzed with Aslamazov-Larkin (AL) theory and a good quantitative agreement was achieved for the experimental data. <b>For</b> <b>our</b> <b>data,</b> the mean field regime is dominated by 2 D AL fluctuations. Our results reveal the occurrence of critical fluctuation regime in consistent with the prediction of the full dynamic 3 D XY model. We found the dynamical critical exponent to be z= 3. 4 <b>for</b> <b>our</b> <b>data.</b> We analyzed also the excess conductivity data by Hikami-Larkin theory and estimated the phase relaxation time. Copyright EDP Sciences, SIF, Springer-Verlag Berlin Heidelberg 2011...|$|E
30|$|In our design we have {{included}} NCCN as the risk classification system <b>for</b> classify <b>our</b> <b>data.</b>|$|R
5000|$|To {{illustrate}} {{the use of}} powers of two in the scale factor, let's use a factor of 1/16 with the above data set. The binary value <b>for</b> <b>our</b> original <b>data</b> set is given below: ...|$|R
30|$|Because of {{the need}} <b>for</b> amino acids, <b>our</b> <b>data</b> further implies that encephalization could only develop in an {{omnivorous}} species.|$|R
30|$|The final {{diagnostic}} {{check for}} the suitability of the data for factor analysis was the factorability of R. Low bivariate correlations (<[*]. 30) indicate that factor analysis could be inappropriate for the given data. This assumption was reasonably met <b>for</b> <b>our</b> <b>data.</b>|$|E
30|$|As before, we fit {{these models}} using Proc CATMOD in SAS {{software}} [23]. <b>For</b> <b>our</b> <b>data</b> the best models were the non-homogeneous pairwise agreement {{model and the}} non-homogeneous three-way agreement model. Table 4 shows the regression coefficients, standard errors, and p values.|$|E
30|$|<b>For</b> <b>our</b> <b>data,</b> {{a binary}} {{classification}} was performed using a non-linear SVC with a radial basis function (RBF) kernel. The SVM was trained on identified sources. The obtained separation conditions of different group of objects were {{then used to}} classify the unknown sources.|$|E
40|$|Main {{content of}} this task is summary and {{explanation}} of main methods,which {{can be used}} to evaluation the results from measuring of pollutants in combustion gases. The way which should be most acceptable <b>for</b> <b>our</b> <b>datas</b> will be consequently used in a simply example. There will be mentioned the importace of chosing the entering datas and their dependence on outer conditions. Another chapter will be devoted to emission standarts of main pollutants in Czech republic and in chosen world countries too. There will be mentioned the historical developement of these standarts and hypothesis to the future about this question too...|$|R
40|$|We {{demonstrate}} perfect imaging in Maxwell’s {{fish eye}} <b>for</b> microwaves. <b>Our</b> <b>data</b> {{show that the}} field of a line source is imaged with subwavelength resolution over superwavelength distances, provided the field is allowed to leave through passive outlets that {{play the role of}} a detector array in imaging. 1 a...|$|R
3000|$|The {{assignment}} for each OFDM subcarrier is {{calculated from the}} fact that the IFFT matrix <b>for</b> <b>our</b> OFDM transmitted <b>data</b> <b>for</b> symbol 1 is [...]...|$|R
3000|$|... max). This {{range was}} ρ∈ [0.2, 2] in our case, {{and the best}} fit for ρ can be easily found by visual {{inspection}} of the curves obtained by substituting several values for ρ from this range. The above described procedure <b>for</b> <b>our</b> <b>data</b> resulted in l [...]...|$|E
30|$|Our GEE {{models in}} both Experiments 1 and 2 {{revealed}} that shorter response times were linked with more correct responses on both tasks. As in Experiment 1, this association might {{be explained by}} several models of perceptual decision making; however, determining which of these models best accounts <b>for</b> <b>our</b> <b>data</b> {{is beyond the scope}} of the current paper.|$|E
30|$|Systematically, we {{interpolated}} the obtained routes so {{that each}} route has 100 waypoints to guarantee the fairness in comparison among different routes, regarding {{the distance to the}} mobile phone usage locations. The task here was to find the nearest route to the mobile usage locations. The number of data points (waypoints) of 100 <b>for</b> <b>our</b> <b>data</b> interpolation was arbitrarily chosen.|$|E
30|$|Alternatively, {{it could}} also be related to {{time-varying}} unobserved fixed effects related to changes in the characteristics of the employer, occupation or sector. Women may, for example, switch to smaller firms, which we cannot control <b>for</b> in <b>our</b> <b>data.</b> Göggel and Zwick (2012) and Fitzenberger and Kunze (2005) show the importance of occupational mobility.|$|R
30|$|As can be {{seen from}} Table  2, the four {{parameters}} of sample No. 1 from three repeated measurements were very similar and the relative standard deviation values were relatively small. It was safe to conclude that the results were stable and repeatable, which provided a reliable basis <b>for</b> <b>our</b> subsequent <b>data</b> analysis.|$|R
30|$|For this reason, {{we need to}} {{evaluate}} {{at the same time}} the level of sophistication of a product and of the needs of a customer using the data in the purchase matrix, and recursively correct the one with the other. We adapt the procedure of [17], adjusting it <b>for</b> <b>our</b> big <b>data.</b>|$|R
40|$|This {{application}} proves XML as {{the excellent}} backend technology for storing and sharing {{data in a}} highly structured manner. And also demonstrates XML provides the framework for creating customized markup languages, as we have customized <b>for</b> <b>our</b> <b>data</b> needs in the application discussed above. So the data would have the flexibility of spreadsheet along with the visual accessibility of a web page...|$|E
30|$|New columns were created: INTERVAL 1, INTERVAL 2, INTERVAL 3, and INTERVAL 4, {{which were}} filled with actual fire return {{intervals}} (in years). <b>For</b> <b>our</b> <b>data,</b> the highest fire frequency was five; hence, we needed to calculate a maximum of four intervals. Any number of fire return intervals could be calculated, such {{that the number of}} INTERVAL columns equals the highest fire frequency minus one.|$|E
40|$|A {{test for}} spatial {{correlation}} is considered when the binary observations are {{obtained from a}} regular grid. We use the auto-logistic model <b>for</b> <b>our</b> <b>data</b> and a conditional uniformly most powerful unbiased test for the spatial correlation is found. We use a Monte Carlo method based on a Markov chain for conducting the test. A numerical example is given. Auto-logistic distribution Hypothesis testing Markov chain Monte Carlo...|$|E
3000|$|... of {{the block}} size. Thus, <b>for</b> <b>our</b> 4 <b>data</b> packets per block, we set the {{redundancy}} check packet number to 1 or 2. Four concrete schemes, that is, BCH scheme, RS scheme with two redundancy packets, and RS_BCH scheme {{with one or two}} redundancy packets, are discussed here and referred as BCH, RS ([...] [...]...|$|R
30|$|Another {{analyzed}} {{factor was}} the available pasture in areas shared with livestock. <b>For</b> mixed-sex groups <b>our</b> <b>data</b> showed the major size on feeding groups was on winter in which was available ray grass pasture for cattle.|$|R
40|$|It {{has been}} {{suggested}} that maternal undernutrition results in facultative adjustment of the sex ratio at birth among humans, favouring females. We tested this hypothesis using data from the Demographics and Health Survey of Ethiopia <b>for</b> 2000. <b>Our</b> <b>data</b> provide at best limited support for the suggestion that maternal nutritional status is associated with the sex ratio at birth in humans...|$|R
40|$|ACKNOWLEDGMENTS We {{thank the}} Tsawout and Tseycum First Nations bands for {{allowing}} access to Mandarte, everyone {{who contributed to}} long-term data collection, and the European Research Council, U. K. Royal Society, National Sciences and Engineering Research Council of Canada, and Swiss National Science Foundation for their valuable ongoing support. DATA ARCHIVING The doi <b>for</b> <b>our</b> <b>data</b> is doi: 10. 5061 /dryad. 0015 b. Peer reviewedPublisher PD...|$|E
30|$|Third, our network {{snapshots}} {{have the}} small-world phenomenon {{characterized by a}} high average clustering coefficient (of around 0.2 <b>for</b> <b>our</b> <b>data)</b> and small average shortest path length (between around four and eight <b>for</b> <b>our</b> <b>data).</b> The small-world phenomenon has been observed in many other social networks (Bonato et al. 2010; Watts and Strogatz 1998; Watts 1999. It is interesting that both the average clustering coefficients and the average shortest path lengths of our network snapshots are statistically significantly higher than expected by chance in the networks of the same sizes (p-value < 0.01) (Fig.  3), while typically, the higher the average clustering coefficient, the lower the average shortest path length, and vice versa. Our result suggests that our network snapshots might {{have a number of}} smaller highly densely connected regions (resulting in high average clustering coefficients) that are separated from each other via few interactions, i.e., via sparse network regions (resulting in higher than random average shortest path length). This is confirmed by high modularity (between around 0.6 - 0.9 in our data, Fig.  3).|$|E
40|$|Abstract—Quality of Experience is a {{parameter}} used {{to express}} the relationship between Quality of Service and the satisfaction of network service subscribers. The modeling of Quality of Experience demands for solving a multidimensional problem. In this paper, we present a Quality of Experience analysis of streaming videos. Related to this, we show that we can reduce {{the dimensions of the}} Quality of Experience modeling with the help of Principle Component Analysis techniques. We demonstrate that <b>for</b> <b>our</b> <b>data</b> set the Zero Throughput Time and the Packet Delay Variation are enough to get a picture {{of the state of the}} network. We further calculate the Mahalanobis distance to analyze the outliers in the data set. We illustrate that <b>for</b> <b>our</b> <b>data</b> set the 97. 5 % quantile for the Mahalanobis distance is a good threshold that indicates low user perception. We also advocate the use of robust statistics in the analysis of Quality of Experience as we are dealing with contaminated data sets. Index Terms—Mahalanobis Distance; Quality of Experience; video streaming; robust statistics; 3 G network measurements...|$|E
30|$|H 0 workday (dash-dotted green line): The {{standardized}} [37] {{average load}} of a household during workdays with two small load peaks at noon and one larger {{peak in the}} evening. The type of households and the broader geographic region for the “H 0 ” profile in the standard {{are the same as}} <b>for</b> <b>our</b> test <b>data</b> described above.|$|R
40|$|This work {{presents}} the data model we adopted <b>for</b> annotating coreference. <b>Our</b> <b>data</b> model includes {{different levels of}} annotation, such as part-of-speech, syntax and discourse. We compare our encoding schemes to the abstract XML encoding being proposed as standard. We also present <b>our</b> tool <b>for</b> coreference resolution that handles <b>our</b> <b>data</b> model. ...|$|R
40|$|I {{discuss some}} {{directions}} <b>for</b> evolving <b>our</b> <b>data</b> management {{services in the}} next years, using the experience in operating heavy-duty data storage services at CERN, notably for the Worldwide LHC Computing Grid (WLCG). These new developments are potentially useful beyond our community, wherever {{the success of a}} project depends on large computing resources and requires the active participation of a large and distributed collaborations...|$|R
30|$|Factors were {{identified}} using orthogonal rotation (varimax method as in Kaiser [1970]; Gorsuch [1983]) {{so that a}} smaller number of highly-correlated variables might be put under each factor and interpretation becomes easier (Field [2005]). In accordance with Kaiser’s criterion, all factors exceeding an eigenvalue of one were retained (Kaiser [1970]). Kaiser’s criterion is accurate when the number of variables is less than 30 (Field [2005]), which was the case <b>for</b> <b>our</b> <b>data</b> set.|$|E
40|$|Abstract In {{this paper}} {{steganography}} {{is used in}} a different way. Image is not transmitted over the channel rather image {{is used as a}} key between the sender and receiver means it acts as a shared key between the sender and receiver. The index array that contains the indices <b>for</b> <b>our</b> <b>data</b> hidden in the image is transmitted. Before transmitting divide and mean method is applied for increasing the complexity of the data...|$|E
30|$|Tone {{duration}}: We {{define the}} factor tone duration by {{the duration of}} the song extracts {{in order to maintain the}} rhythmic structure. If this factor is modified, all tone lengths of the song extract are adjusted in the same way. We consider two factor levels: 12 and 25 s which, <b>for</b> <b>our</b> <b>data,</b> results in tone lengths between 0.1 and 0.5 s for the first level and between 0.2 and 1.0 s for the second level.|$|E
40|$|In February of 2008, SurveyUSA polled 600 {{people in}} each state and asked who {{they would vote for}} in either {{head-to-head}} match-up: Obama vs. McCain, and Clinton vs. McCain. Here we integrate these polls with prior information; how each state voted in comparison to the national outcome in the 2004 election. We use Bayesian methods to merge prior and poll data, weighting each by its respective information. The variance <b>for</b> <b>our</b> poll <b>data</b> incorporates both sampling variability and variability due to time before the election, estimated using pre-election poll data from the 2000 and 2004 elections. The variance <b>for</b> <b>our</b> prior <b>data</b> is estimated using the results of the past nine presidential elections. The union of prior and poll data results in a posterior distribution predicting how each state will vote, in turn giving us posterior intervals for both the popular and electoral vote outcomes of the 2008 presidential election. Lastly, these posterior distributions are updated with the most recent poll data as of August...|$|R
5000|$|... "Our {{findings}} indicate that alcohol drinking at the levels typically consumed by {{the general population of}} the United States is probably not a risk factor <b>for</b> pancreatic cancer. <b>Our</b> <b>data</b> suggest, however, that heavy alcohol drinking may be related to pancreatic cancer risk." ...|$|R
40|$|International audienceAllowing for sign-dependence in {{discounting}} substantially {{improves the}} description of people's time preferences. The deviations from constant discounting that we observed were more pronounced for losses than <b>for</b> gains. <b>Our</b> <b>data</b> also suggest that the discount function should be flexible enough to allow for increasing impatience. These findings challenge the current practice in modeling intertemporal choice where sign-dependence is largely ignored and only decreasing impatience is allowed. The sign-dependent model of Loewenstein and Prelec (1992) with the constant sensitivity discount function of Ebert and Prelec (2007) provided the best fit to <b>our</b> <b>data...</b>|$|R
