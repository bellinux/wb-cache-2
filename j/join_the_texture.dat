1|10000|Public
50|$|At the {{beginning}} of the illustrated page from the score, for instance, the woodwinds and brass (notated {{at the top of the}} page) are playing short repeated passages. The composer specifies completely the music for each player, leaving the interpretation to the individuals: only the co-ordination between the parts is unspecified. The strings (notated at the bottom of the page) <b>join</b> <b>the</b> <b>texture</b> by sections: first the violins, then the violas, the cellos and lastly the basses, all playing rapid repeating figures. The string players do not coordinate their playing (even within sections) except for their entries. These entries are indicated by the conductor, as instructed by the down-arrows above the string parts.|$|E
30|$|The tip {{takes the}} whole 5 th <b>texture</b> to <b>join</b> <b>the</b> 6 th <b>texture</b> during <b>the</b> 1 st sliding for surface IV, {{and these two}} textures form a big <b>texture.</b> As <b>the</b> sliding going on, <b>the</b> big <b>texture</b> {{includes}} 2 layers and comes to steady state, and the cover layer also gets a stable structure. Atoms taken by the tip accumulate {{on the top of}} <b>the</b> 4 th <b>texture</b> gradually, which induces that the tip contacts with <b>the</b> 4 th <b>texture</b> and <b>the</b> accumulated atoms. From the 11 th sliding, the sliding processes come to steady state, and average friction forces for even slidings are a little higher than the cases of odd slidings. This phenomenon is caused by the contacts between the tip and <b>the</b> 4 th <b>texture</b> including its accumulated atoms, as shown in Figure  10 (d). For the even slidings, the tip scratches <b>the</b> 4 th <b>texture</b> and its accumulated atoms, which induces high friction forces due to high ploughing components.|$|R
50|$|Kazuo Imai (born September 24, 1955) is a Tokyo-based guitarist {{who plays}} in a {{rigorous}} and original free improvisation idiom. His music <b>joins</b> <b>the</b> rigour and <b>texture</b> of contemporary classical with the passion of free jazz. He has played with many Western and Japanese improvisers, including Lee Konitz, Barre Phillips, Arthur Doyle, Han Bennink, Irene Schweizer, Shuichi Chino, Tetsu Saitoh and Kazue Sawai. In addition to playing solo and in collaborations, Imai {{is also a member}} of the important collective improvisation group Marginal Consort. As well as guitar, Imai also plays viola da gamba.|$|R
50|$|Khachatur Abovyan, 1972, in {{the city}} of Abovyan, done from small {{multicolor}} pieces of natural stones. In this mosaic the painter managed to realize his innovation, beautifully <b>joining</b> <b>the</b> color to <b>the</b> <b>texture</b> of stone and metal, attempting to reach necessary artistic integrity.|$|R
50|$|When a texel is {{requested}} that is outside of <b>the</b> <b>texture,</b> {{one of two}} techniques is used: clamping or wrapping. Clamping limits the texel to <b>the</b> <b>texture</b> size, moving it to the nearest edge if {{it is more than}} <b>the</b> <b>texture</b> size. Wrapping moves the texel in increments of <b>the</b> <b>texture's</b> size to bring it back into <b>the</b> <b>texture.</b> Wrapping causes a texture to be repeated; clamping causes it to be in one spot only.|$|R
40|$|We {{performed}} two {{experiments to}} examine how the hue affects <b>the</b> ocurrence of <b>texture</b> laciness, in which one of two textures is seen through the other {{in front of it}} for some arrangement. Nineteen undergraduates rated <b>the</b> <b>texture</b> laciness, and also estimated an apparent depth magnitude between <b>the</b> <b>textures.</b> We varied <b>the</b> hue of one of two textures keeping that of the other constant in Experiment 1. We varied the hue of background in orange, yellow, green, blue green, white and black, keeping the hues of <b>the</b> <b>textures</b> constant in Experiment 2. <b>The</b> <b>texture</b> laciness occurred more strongly with the decreasing similarity in hue between <b>the</b> <b>textures,</b> and also with the increasing difference in similarity of hue between the background and each of <b>the</b> <b>textures.</b> <b>The</b> results indicate that the occurrence of laciness is affected not by the local similarity of hue between <b>the</b> <b>textures</b> but <b>the</b> global similarity of hue among <b>the</b> <b>textures</b> and <b>the</b> background...|$|R
40|$|Abstract. Texture {{compression}} {{technology is}} {{an effective way to}} improve the capacity of <b>the</b> <b>texture</b> without increasing <b>the</b> <b>texture</b> memory. This paper studies a texture compression method based on mipmap technology, details several texture compression formats, and describes <b>the</b> <b>texture</b> file of several formats generating and corresponding parameters adjustment. Practical results show that <b>the</b> <b>texture</b> compression method based on mipmap technology can not only achieve high texture compression ratio, but also cause no effect on <b>the</b> <b>texture</b> quality...|$|R
40|$|This study {{examines}} {{the effects of}} congruency between <b>the</b> <b>texture</b> of <b>the</b> packaging and <b>the</b> <b>texture</b> of <b>the</b> product. Three experiments on chocolate tasting reveal that when <b>the</b> <b>texture</b> of <b>the</b> product is not congruent with <b>the</b> <b>texture</b> of <b>the</b> packaging, {{this leads to a}} disconfirmation of expectations and a lower evaluation of the taste of chocolate...|$|R
40|$|Copyright Holder: The Academy of Marketing ScienceThis study {{examines}} {{the effects of}} congruency between <b>the</b> <b>texture</b> of <b>the</b> packaging and <b>the</b> <b>texture</b> of <b>the</b> product. Three experiments on chocolate tasting reveal that when <b>the</b> <b>texture</b> of <b>the</b> product is not congruent with <b>the</b> <b>texture</b> of <b>the</b> packaging, {{this leads to a}} disconfirmation of expectations and a lower evaluation of the taste of chocolate...|$|R
40|$|Visualisation {{of terrain}} data {{has been an}} active area of {{research}} {{for more than an}} decade already and astonishing results have been achieved already. But there are still some issues to resolve, e. g. <b>the</b> <b>texturing</b> of current terrain rendering engines is based on orthographic projection, which leads to artifacts in very steep places like walls or cliffs, where small pieces of <b>the</b> <b>texture</b> is applied to large parts of the terrain model. To increase <b>the</b> <b>texture</b> information in these steep places it is necessary to increase the size of <b>the</b> <b>texture</b> area that is applied to these pieces of the terrain model. To solve the problem a new parameterization for the terrain model is computed and <b>the</b> <b>texture</b> is enhanced by additional information. Due to the new parameterization <b>the</b> orthographic <b>texture</b> has to be resampled to fit the new parameterization or in other words, <b>the</b> <b>texture</b> has to be “reparameterized”. Ground-images are merged into <b>the</b> reparameterized <b>texture</b> to increase <b>the</b> <b>texture</b> details in steep places...|$|R
3000|$|... <b>the</b> {{concatenated}} <b>texture</b> parameters {{consisting of}} <b>the</b> affine <b>texture</b> transform u and <b>the</b> <b>texture</b> parameters [...]...|$|R
40|$|A video content {{analysis}} tool for video coding is presented. The underlying assumption of our {{approach is that}} <b>the</b> <b>textures</b> in a video scene can be labeled subjectively relevant or irrelevant. Relevant textures are defined as containing subjectively meaningful details, while irrelevant textures contain less important subjective details. We apply this idea to video coding using a texture analyzer and a <b>texture</b> synthesizer. <b>The</b> <b>texture</b> analyzer (encoder side) identifies <b>the</b> <b>texture</b> regions with unimportant subjective details and generates side information for <b>the</b> <b>texture</b> synthesizer (decoder side), which inserts synthetic <b>textures</b> at <b>the</b> specified locations. The focus {{of this paper is}} <b>the</b> <b>texture</b> analyzer, which uses MPEG- 7 descriptors for similarity estimation. <b>The</b> <b>texture</b> analyzer is based on a split and merge segmentation approach and also provides solutions concerning temporal mapping of identified detail-irrelevant <b>textures.</b> <b>The</b> current implementation of <b>the</b> <b>texture</b> analyzer yields an identification rate of up to 93 %. 1...|$|R
40|$|A yukata {{is a type}} of {{traditional}} Japanese kimono. An alignment of its texture pattern is an important factor of the yukata design. There are rules in <b>the</b> <b>texture</b> alignment of <b>the</b> yukata. The rules are comparratively simple. However, <b>the</b> <b>texture</b> alignment is difficult for the designer because <b>the</b> <b>texture</b> alignment should be performed with consideration to the rules and the wearer's taste, Additioanlly, it is necessary for the designer to create the cutting pattern from a limited length of the kimono cloth. Consequently, a design support system for the yukata is required. We have developed the image processing algorithm to simulate the condition of <b>the</b> <b>texture</b> alignment. It becomes possible to perform <b>the</b> <b>texture</b> alignment based on the traditioonal rule automatically. However, some cutting pattern becomes over length of a standard kimono cloth. In this paper, we describe a multi-agent system for supporting <b>the</b> <b>texture</b> alignment of <b>the</b> yukata. We developed texture alignment agents, and a management agent. The management agent acts management of the wearer's body sizes, the condition of <b>the</b> <b>texture</b> alignment and <b>the</b> cutting pattern and orders to <b>the</b> <b>texture</b> alignment agents to carry out <b>the</b> <b>texture</b> alignment according to the wearer's taste. By repeating trial and error, <b>the</b> realistic <b>texture</b> alignment became possible. </p...|$|R
40|$|We {{assume that}} <b>the</b> <b>textures</b> {{in a video}} scene can be {{classified}} into two categories: textures with unimportant subjective details and the remainder. We utilize this assumption for improved video coding using a texture analyzer and a <b>texture</b> synthesizer. <b>The</b> <b>texture</b> analyzer identifies <b>the</b> <b>texture</b> regions with unimportant subjective details and generates coarse masks as well as side information for <b>the</b> <b>texture</b> synthesizer at <b>the</b> decoder side. <b>The</b> <b>texture</b> synthesizer replaces <b>the</b> identified <b>textures</b> by inserting synthetic <b>textures</b> for <b>the</b> identified regions. <b>The</b> <b>texture</b> analyzer is based on MPEG- 7 descriptors. Our approach has been integrated into an H. 264 /AVC codec. Bit-rate savings up to 19. 4 % are shown for a semi-automatic texture analyzer given similar subjective quality as the H. 264 /AVC codec without the presented approach. 1...|$|R
40|$|A texture {{is said to}} have a {{symmetry}} {{if there}} is a transformation such that <b>the</b> <b>texture</b> before transformation is matched with that after transformation on their overlapping region. Particularly, when such a transformation preserves distance, it is called an isometry. There are four kinds of isometries in the plane: translation, reflection, rotation and glide reflection. A texture is said to be regular if it has translation symmetries in at least two distinct directions. Given a regular texture, a collection of symmetries for <b>the</b> <b>texture</b> form a group. It is called the symmetry group for <b>the</b> <b>texture.</b> A mathematical analysis of these group shows that there are exactly seventeen different symmetry groups in the plane. A fundamental region is a smallest polygonal subregion of <b>the</b> <b>texture</b> that can reproduce <b>the</b> <b>texture</b> by applying <b>the</b> isometries for <b>the</b> <b>texture</b> to <b>the</b> region. Given a regular <b>texture,</b> <b>the</b> symmetry group for <b>the</b> <b>texture</b> and its fundamental region give a complete representation [...] ...|$|R
40|$|Conventional {{mappings}} from <b>the</b> <b>texture</b> {{plane to}} three-dimensional surfaces fail {{to maintain the}} arc length of <b>the</b> <b>texture</b> when it is mapped onto the surface. This leads to unnatural texture appearance. In addition, texture gradient information is distorted, leading to poor perception of depth. We have developed an efficient algorithm which warps <b>the</b> <b>texture</b> in <b>the</b> <b>texture</b> plane such that the arc length of <b>the</b> <b>texture</b> on <b>the</b> three-dimensional surface is approximately preserved everywhere on the surface. This leads to much more natural texture appearance and preserves texture gradient information. Texture images are preprocessed before the mapping from <b>the</b> <b>texture</b> plane to <b>the</b> three-dimensional surface so no additional run time overhead is incurred compared to conventional two-dimensional texture mapping methods...|$|R
40|$|Electron {{backscatter}} diffraction (EBSD) method, Oriented growth. Abstract. The {{paper presented}} <b>the</b> <b>texture</b> evolution during primary recrystallization and following grain {{growth in the}} heavily cold-rolled Ni 3 Al single crystals. It turned out that <b>the</b> <b>texture</b> evolution occurred in the two stages. First, primary recrystallization caused the drastic change of <b>the</b> as-rolled <b>texture.</b> Then, as grain growth proceeded, <b>the</b> <b>texture</b> returned to <b>the</b> same one as <b>the</b> as-rolled <b>textures.</b> This texture return can be designated as <b>Texture</b> memory effect. <b>The</b> mechanism of <b>the</b> <b>texture</b> memory effect was discussed based on {{the analysis of the}} orientation relationship between the as-rolled and <b>the</b> primary recrystallization <b>textures...</b>|$|R
50|$|The UV mapping {{process at}} its {{simplest}} requires three steps: unwrapping the mesh, creating <b>the</b> <b>texture,</b> and applying <b>the</b> <b>texture.</b>|$|R
30|$|The {{first and}} second factors {{indicate}} <b>the</b> <b>texture</b> and Gaussian distribution components, respectively. <b>The</b> <b>texture</b> in one superpixel was assumed homogenous based on the SLIC algorithm. Therefore, <b>the</b> <b>texture</b> component in (3) can be regard as constant, and then, the pixels in the superpixel could be considered iid.|$|R
50|$|In {{graphics}} hardware, typically when <b>the</b> <b>texture</b> is sampled anisotropically, several probes (texel samples) of <b>the</b> <b>texture</b> around <b>the</b> {{center point}} are taken, {{but on a}} sample pattern mapped according to the projected shape of <b>the</b> <b>texture</b> at that pixel, although earlier software methods have used summed area tables.|$|R
30|$|For surface II, the tip takes part of <b>the</b> 3 rd <b>texture,</b> <b>the</b> whole 4 th and 5 th textures {{to slide}} towards <b>the</b> 6 th <b>texture</b> and {{scratches}} <b>the</b> 6 th <b>texture</b> in <b>the</b> 1 st sliding. Attractive forces between the tip and <b>the</b> <b>textures</b> {{are so high}} that most atoms adhere to the tip, and scratches between the tip and <b>the</b> <b>textures</b> occur occasionally. Besides, <b>the</b> <b>textures</b> and cover layer do not form stable structures, so the average friction forces fluctuate all the time.|$|R
40|$|Three {{experiments}} {{were designed to}} examine how <b>the</b> luminances of <b>textures</b> and their background affect <b>the</b> ocurrence of <b>texture</b> laciness, in which one of two textures is seen through the other {{in front of it}} for some arrangement. Twenty-six subjects rated <b>the</b> <b>texture</b> laciness in <b>the</b> experiments, and 14 subjects also estimated the apparent depth magnitude between <b>the</b> <b>textures</b> in Experiment 3. Experiment 1 showed that <b>the</b> <b>texture</b> laciness occurred more strongly with the decreasing smilarity in luminance between <b>the</b> <b>textures.</b> Experiments 2 and 3 showed that texture laciness occurred more strongly with increasing difference in similarity of luminance between each <b>texture</b> and background. <b>The</b> results indicate that the occurrence of laciness is affected not by the local similarity of luminance between <b>the</b> <b>textures</b> but <b>the</b> global similarity of luminance among <b>the</b> <b>textures</b> and <b>the</b> background. A similarity in the results between the laciness and the apparent depth suggests some relationship between the laciness and the depth...|$|R
40|$|Abstract. Six {{samples of}} Nd-Fe-B-permanent magnets, {{distinguished}} in <b>the</b> <b>texture</b> degree, have been measured by neutron diffraction in the reflection and transmission regimes. <b>The</b> <b>texture</b> in <b>the</b> samples {{was formed by}} application of impulses of external magnetic field µ 0 H = 4 T. Analysis of the obtained neutron diagrams {{by means of the}} Fullprof program allowed quantitative determination of <b>the</b> <b>texture</b> degree and conclusion to be made that <b>the</b> <b>texture</b> degree grows with an increase in numbers of magnetic field impulses...|$|R
40|$|Abstract. Three {{different}} textures {{were produced}} by Laser Surface Texturing (LST) on Al 2 O 3 /TiC ceramic surfaces. MoS 2 solid lubricants were filled into <b>the</b> <b>textures.</b> <b>The</b> friction and wear properties of textured and untextured surfaces were investigated by carrying out sliding tests against AISI 440 C stainless steel balls. Results {{showed that the}} textured surfaces filled with MoS 2 solid lubricants exhibited lower friction coefficient and excellent anti-wear properties compared with untextured surfaces. At <b>the</b> <b>texture</b> spacing of 100 µm, 150 µm and 200 µm, wavy textured surface had the lowest friction coefficient, while it was the dimpled surface at <b>the</b> <b>texture</b> spacing of 250 µm. MoS 2 film in the spaces between <b>the</b> <b>textures</b> was formed by mechanical engagement of particles in the rough surfaces and solid lubricants in <b>textures.</b> <b>The</b> friction coefficient and wear rates were reduced by supply of solid lubricants from <b>the</b> <b>textures</b> to <b>the</b> surfaces, bulges around <b>the</b> <b>textures</b> and TiO 2 formed after laser texturing...|$|R
40|$|This article {{presents}} an analysis-synthesis scheme using 2 D deformable meshes for video coding. The analysis stage allows to decouple the motion from <b>the</b> <b>texture</b> and to code each information independently. The motion {{is represented by}} a 2 D deformable mesh which provides long term tracking of <b>the</b> <b>texture.</b> <b>The</b> <b>texture</b> frames are extracted by motion-compensating the frames on a reference grid and are represented as a t+ 2 D volume of datas free from motion. The complete decoupling of the motion and <b>the</b> <b>texture</b> allows to code the motion with loss with no impact on <b>the</b> <b>texture</b> coding and to pass the coding gain on <b>the</b> <b>texture</b> to improve <b>the</b> visual quality of the reconstructed sequence. Our scheme performs {{as well as the}} H 264 /AVC video coder on some sequences and offers several functionnalities such as scalability, video object coding, 3 D reconstruction, etc [...] . 1...|$|R
30|$|Texture is {{a spatial}} {{distribution}} of the pixels in the image, which can be expressed by the correlation between neighboring pixels [27, 28]. Texture analysis {{is a process of}} a qualitative or quantitative description of <b>the</b> <b>texture</b> that is extracted by image processing technology. Due to the complicated visual perception of human and <b>the</b> diversity of <b>texture,</b> it is difficult to find a mathematical model to accurately describe <b>the</b> <b>texture</b> features. All of the existing methods on the extraction of <b>the</b> <b>texture</b> feature do not describe <b>the</b> <b>texture</b> feature of all images by using one method.|$|R
40|$|For a {{patch of}} random visual texture {{embedded}} in a surrounding background of similar texture, we demonstrate that the perceived contrast of <b>the</b> <b>texture</b> patch depends substantially on the contrast of the background. When <b>the</b> <b>texture</b> patch is surrounded by high-contrast <b>texture,</b> <b>the</b> bright points of <b>the</b> <b>texture</b> patch appear dimmer, and simultaneously, its dark points appear less dark than when it {{is surrounded by a}} uniform background. The induced reduction of apparent contrast is greatly diminished when (i) <b>the</b> <b>texture</b> patch and background are filtered into nonoverlapping spatial frequency bands or (ii) <b>the</b> <b>texture</b> patch and background are presented to different eyes. Our results are unanticipated by all current theories of lightness perception and point to a perceptual mechanism for contrast gain control occurring at an early cortical or precortical neural locus...|$|R
30|$|<b>The</b> use of <b>texture</b> {{features}} is {{an effective}} method when searching for texture images that have large differences in thickness, density, and the like. However, when there is little difference between the easily distinguishable information such as the thickness and the density between <b>the</b> <b>textures,</b> <b>the</b> usual <b>texture</b> features are difficult to accurately reflect the difference between <b>the</b> <b>textures</b> of different human visual perceptions.|$|R
40|$|<b>The</b> TEXRET-System, a <b>texture</b> {{retrieval}} {{system based on}} soft-computing technologies is being developed. One of the main system features is synthesis of <b>the</b> requested <b>textures</b> when these are {{not found in the}} database, which allows a growing of <b>the</b> database. Missing <b>textures</b> are synthesized interactively using Markov Random Fields and interactive genetic algorithms. This article is centered on <b>the</b> <b>texture</b> synthesis of <b>the</b> <b>texture...</b>|$|R
40|$|A {{segmentation}} algorithm for image {{content analysis}} is presented. We assume that <b>the</b> <b>textures</b> {{in a video}} scene can be labeled subjectively relevant or irrelevant. Relevant textures are defined as containing subjectively meaningful details, while irrelevant textures {{can be seen as}} image content with less important subjective details. We apply this idea to video coding using a texture analyzer and a <b>texture</b> synthesizer. <b>The</b> <b>texture</b> analyzer (encoder side) identifies <b>the</b> <b>texture</b> regions with unimportant subjective details and generates side information for <b>the</b> <b>texture</b> synthesizer (decoder side), which in turn inserts synthetic <b>textures</b> at <b>the</b> specified locations. The focus of this paper is <b>the</b> <b>texture</b> analyzer, which uses multiple MPEG- 7 descriptors simultaneously for similarity estimation. <b>The</b> <b>texture</b> analyzer is based on a split and merge segmentation approach. Its current implementation yields an identification rate of up to 96 % and an average gain of up to 10 % compared to single descriptor usage...|$|R
30|$|According to the {{analysis}} and verification above, two merits of the improved RIU-LBP operator are observed. The first merit {{is the ability to}} eliminate the disturbance of the small gray value variation in <b>the</b> <b>texture</b> regions, which can improve the robustness for <b>the</b> description of <b>texture</b> regions with <b>the</b> same <b>texture</b> feature. <b>The</b> second one is the strong discrimination capability for different texture regions, such as <b>the</b> flat <b>texture</b> region and <b>the</b> rough <b>texture</b> region. These two advantages are in favor of the segmentation and the classification of <b>the</b> <b>texture</b> image.|$|R
40|$|A yukata {{is a type}} of {{traditional}} Japanese clothing. An alignment of its texture pattern is an important factor of the yukata design. In the traditional design of the yukata, the calculation of <b>the</b> size, <b>texture</b> alignment and <b>the</b> development of the cutting pattern are manually performed. There are traditional rules for <b>the</b> <b>texture</b> alignment. Especially, <b>the</b> <b>texture</b> alignment depends on the experience and intuition of the skilled person. We have developed a CAD system for Japanese kimono. In this paper, we describe methods for automatic texture alignment. At first, image processing algorithms to detect <b>the</b> <b>texture</b> pattern in <b>the</b> kimono cloth are developed. Secondarily, methods of <b>the</b> <b>texture</b> alignment based on the traditional rules are developed. Finally, image processing algorithms for <b>the</b> <b>texture</b> alignment based on the traditional rules are proposed. By using this CAD system, designers can easily tailor the yukata regardless of their skill. </p...|$|R
30|$|From {{the formula}} 11, {{we can get}} Qi that is related to <b>the</b> <b>texture</b> of <b>the</b> image. The much bigger Qi means <b>the</b> higher <b>texture</b> in <b>the</b> blocks of the image and the easier to embed watermarks. <b>The</b> <b>texture</b> image of Lena using {{different}} b is as shown in Fig.  5.|$|R
40|$|An image {{compression}} approach capable of exploiting redundancies {{in groups of}} images is introduced. The approach is based on image segmentation, texture analysis and <b>texture</b> synthesis. <b>The</b> proposed algorithm extracts textured regions from an image and merges them with similar texture data from other images, {{in order to take}} advantage of textural re-occurrences between <b>the</b> images. <b>The</b> <b>texture</b> extraction is done by taking overlapping rectangular texture parameter samples from the input image(s), and using a clustering algorithm to merge them into spatially connected regions, resulting in a polygonal <b>texture</b> map. <b>The</b> <b>textures</b> of that map are henceforth analysed by extracting various features from <b>the</b> <b>texture</b> regions. Using a metric defined on these features, <b>the</b> <b>textures</b> are then merged with entries from a central database, which consists of all <b>the</b> <b>textures</b> in all <b>the</b> images of the image collection, so that for each image, only a polygonal segmentation map and references into this texture database need to be stored. Decoding (decompression) works by extracting <b>the</b> polygonal <b>texture</b> map followed by filling the map regions with patterns generated using texture synthesis based on <b>the</b> <b>texture</b> feature vectors from the database...|$|R
50|$|The {{function}} of the Raster Memory board is to perform rasterization. It also contains <b>the</b> <b>texture</b> memory and raster memory, which is more {{commonly known as the}} framebuffer. Rasterization is performed in the Fragment Generator and the eighty Image Engines. The Fragment Generator comprises four ASIC designs: the Scan Converter (SC) ASIC, the Texel Address Calculator (TA) ASIC, <b>the</b> <b>Texture</b> Memory Controller (TM) ASIC and <b>the</b> <b>Texture</b> Fragment (TF) ASIC.|$|R
30|$|As {{shown in}} Fig.  4, {{there is a}} strong {{correlation}} between QPTAVT and <b>the</b> <b>texture</b> complexity. An increase in the complexity of <b>the</b> <b>texture</b> results in a corresponding increase in the threshold of the QPTAVT.|$|R
