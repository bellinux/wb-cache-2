56|61|Public
3000|$|... (multiparametric classification) {{using the}} method {{developed}} in Iqbal et al. [25]. Depending {{on the number of}} voxels in each category, several <b>different</b> <b>voxel</b> distribution patterns could be identified.|$|E
30|$|For PVE assessment, a Jaszczak Flangeless Esser PET phantom with rod inserts (4.8 – 12.7  mm) was imaged at 60  min post 48  MBq 18 F-FDG {{injection}} with 90  s/bed {{for body}} and 10  min for brain according to ACR accreditation guidelines [37]. Images were reconstructed in SD, HD, and UHD with <b>different</b> <b>voxel</b> sizes.|$|E
40|$|In {{this paper}} we present two {{efficient}} GPU-based visual hull computation algorithms. We compare {{them in terms}} of performance using image sets of varying size and <b>different</b> <b>voxel</b> resolutions. In addition, we present a real-time 3 D reconstruction system which uses the proposed GPU-based reconstruction method to achieve real-time performance (30 fps) using 16 cameras and 4 PCs...|$|E
30|$|On {{the other}} hand, complex {{structural}} information {{is embedded in}} the tensor data. For example, in the neuroimaging data, values of adjacent voxels are usually correlated with each other [2]. Such spatial relationships among <b>different</b> <b>voxels</b> in a tensor image can be very important in neuroimaging applications. Conventional tensor-based approaches focus on reshaping the tensor data into matrices/vectors, and thus, the original spatial relationships are lost. The integration of structural information is expected to improve the accuracy and interpretability of tensor models.|$|R
5000|$|Here ETL is {{the echo}} train length, and ESP is the spacing of echoes in the echo train. If the {{acquisition}} simulated has the echo {{in the middle}} of ETL used for central k-space then [...] The scanner parameters TE and TR are the same over the entire slice/volume that is being synthesized but the parameters T1, T2, PD and the resulting signal S are <b>different</b> for <b>different</b> <b>voxels.</b> The parameters T1, T2, and PD correspond to physical properties of the tissue within the voxel.|$|R
40|$|We are {{interested}} in investigating white matter connectivity using a novel computational framework that does not use diffusion tensor imaging (DTI) but only uses T 1 -weighted magnetic resonance imaging. The proposed method relies on correlating Jacobian determinants across <b>different</b> <b>voxels</b> based on the tensor-based morphometry (TBM) framework. In this paper, we show agreement between the TBM-based white matter connectivity and the DTI-based white matter atlas. As an application, altered white matter connectivity in a clinical population is determined. Index Terms — structural connectivity, brain network, tensor-based morphometry, white matter atlas 1...|$|R
40|$|Abstract—In {{this article}} we intend to present a method of obtaining high {{complexity}} sinthetic scenes by using simple volumes as the building blocks. The below described method {{can be used to}} obtain both homogenous and heterogenous volumes. This is done by combining volumes of <b>different</b> <b>voxel</b> densities. Index Terms—volumetric data, voxel, constructive solid geometry, volume modelling, constructive volume geometry. I...|$|E
40|$|Texto completo: acesso restrito. p. 150 – 155 Objective: To {{evaluate}} {{the accuracy of}} linear measurements on dry mandible specimens using cone beam computed tomography (CBCT) images acquired with <b>different</b> <b>voxel</b> sizes. Methodology: Eight human dry mandibles were submitted to CBCT examination, using the i-CAT (Imaging Sciences, Inc. Hatfield, PA) device and four protocols with <b>different</b> <b>voxel</b> sizes. Tomographic slices with a more central view of the markers, placed on six sites on each mandible, were selected to perform measurements. Values obtained from direct measurements on the dry mandible after sectioning them on the preestablished sites were compared with measurements from the tomographic images and the measurement error. Results: There was no statistical difference between the measurement error of the protocols (P = 0. 606). The mean value {{of the difference between}} the values obtained in the images and the dry mandible was smaller than 1 mm for all the protocols. Conclusion: The accuracy of vertical and horizontal measurements, using CBCT (i-CAT) for the four protocols, was shown to...|$|E
40|$|In this study, {{we carry}} out viewshed {{analysis}} to landscape voxel models derived from airborne laser scanner data. The objective is to make comparisons of viewshed analysis with <b>different</b> <b>voxel</b> models; the ground model representing the bare Earth, the surface model including also all above-ground features, and the combined model, which is formed from the ground model and the laser measurements in voxel domain. The combined model contains openings in vegetation below tree crowns. This paper explores the variation {{in the size of}} the visible area when the <b>different</b> <b>voxel</b> models are used. The generated voxel models and results from viewshed analysis are visualized using a number of cartographic means. The methods include generation of voxel model, implementation of the Line of Sight (LoS) algorithm and visualization techniques. The airborne laser data is classified to ground and other points before creation of a voxel model. Results of the study present the influence of using a real 3 D model instead of 2. 5 D surface in the calculation of viewshed analysis. The produced visualizations are compared, and positive and negative aspects of the representations are analysed...|$|E
50|$|For IR and DIR {{the signal}} may be {{negative}} in some voxels. In a real MRI scanner the signal {{is complex and}} due to off-resonance effects and other scanner imperfections the phase of the complex value may vary between <b>different</b> <b>voxels,</b> this leads to it being difficult to distinguish between a positive and negative signal. It is common to only reconstruct the magnitude image. For the synthetic images {{it is easy to}} keep the sign of the synthesized signal and thereby effectively creating a contrast weight that corresponds to a phase-sensitive inversion recovery (PSIR) which may also be called IR Real or Corrected Real.|$|R
40|$|It {{has been}} {{demonstrated}} that the hemodynamic signal from individual venules can be detected directly with fMRI. Here, the hemodynamic signal from BOLD and CBV fMRI was measured at high temporal(100 ms) and spatial resolution(150 x 150 µm) in layer 4 / 5 of the rat forepaw S 1 with fast gradient-echo MRI. Distinctly <b>different</b> <b>voxels</b> were activated in BOLD vs CBV fMRI. In contrast to the BOLD activated voxels primarily located at the penetrating venules, CBV activated voxels were primarily located at penetrating arterioles. This result {{makes it possible to}} directly image the CBV and BOLD response at the single-vessel level to understand neurovascular coupling...|$|R
40|$|We {{propose a}} fast, efficient, general, simple, valid and robust method of {{estimating}} and making inference about the delay of the fMRI response modeled as a temporal shift of the hemodynamic response function (HRF). We estimate the shift unbiasedly using two optimally chosen basis functions for a spectrum of time shifted HRFs. This is done at every voxel, to create an image of estimated delays and their standard deviations. This {{can be used to}} compare delays for the same stimulus at <b>different</b> <b>voxels,</b> or for <b>different</b> stimuli at the same voxel. Our method is compared to other alternatives, and validated on an fMRI data set from an experiment in pain perception. 1...|$|R
40|$|Parallel imaging is {{intrinsically}} limited by Maxwell’s equations. A {{complete set of}} vector solutions to the Helmholtz equation consists of both curl-free and divergence-free fields. In this study we investigated the contribution of electric-type current patterns to UISNR for <b>different</b> <b>voxel</b> positions and acceleration factors in a spherical model at 9. 4 T. For moderate acceleration the electric mode increased UISNR by maximally 55. For very high acceleration, however, UISNR was mostly caused by the magnetic mode. The reason for {{this might be the}} much faster growing power loss of the electric mode with respect to the expansion order...|$|E
40|$|Background: The {{teeth with}} undiagnosed {{vertical}} root fractures (VRFs) {{are likely to}} receive endodontic treatment or retreatment, leading to frustration and inappropriate endodontic therapies. Moreover, many cases of VRFs cannot be diagnosed definitively until the extraction of tooth. Objectives: This study aimed to assess the use of <b>different</b> <b>voxel</b> resolutions of two different cone beam computerized tomography (CBCT) units in the detection VRFs in vitro. Materials and Methods: The study material comprised 74 extracted human mandibular single rooted premolar teeth without root fractures that had not undergone any root-canal treatment. Images were obtained by two different CBCT units. Four image sets wer...|$|E
40|$|Background/purpose: The {{reliability}} {{and accuracy of}} linear distance and voxel density (VD) measurements are very important in dentistry. The {{purpose of this study}} was to assess the accuracy and reliability of linear distances and VD measurements of cone-beam computed tomography (CBCT) at <b>different</b> <b>voxel</b> sizes. Materials and methods: Eighteen-millimeter linears of size 40 gutta-percha were prepared in fresh sheep head. The head was scanned using CBCT with 0. 25, 0. 3, and 0. 40 voxel sizes. Standard linear distances of gutta-percha were measured in panoramic CBCT images at 0. 25, 0. 3, and 0. 4 voxel sizes. VD measurements were made separately on spongeous bone of palatal surfaces of the roots of teeth 4, 5, and 6 of maxilla and on cortical bone of teeth 4, 5, and 6 regions of the left and right hemimandibles through cross-sectional imaging. Results: We found that linear distance measurements on panoramic image of CBCT were slightly lower than physical measurements. A significant difference was not found for the gutta-percha linear distances and cortical VD measurements at <b>different</b> <b>voxel</b> sizes (P ≥  0. 05). The correlation between measurements of VD at different voxels in cortical bone was greater than 0. 85 (P =  0. 000). Conclusion: Linear distance measurements on the sheep head cadaver of 0. 25, 0. 3, and 0. 4 voxel sizes were similar and reliable when compared with physical measurements. In minimizing radiation exposure, VD measurement of cortical bone at 0. 4 voxel-based CBCT could be used to estimate cortical bone density. However, studies should be performed on the human head cadaver...|$|E
40|$|China Soc Image & Graph, Xian Univ Technol, NW Univ, Shaanxi Prov Key Lab Speech & Image Informat Proc, Natl Nat Sci Fdn China, TOYOU FEIJI Elect Co, CPS, IEEE Comp SocThe paper {{presents}} {{a novel approach}} for simulating realistic time-varied carpets. By the approach, a 3 D carpet is constructed first by image-based techniques from a single photo input, through a texel structure, established to generate realistic carpet with its pattern guided by the captured image. Secondly, a time-varying simulation model is proposed to capture {{various aspects of the}} time-dependent appearance of carpets such as dust accumulation, color fading and fiber change. Additionally, a time-varying map is provided to control the specific weathering degrees at <b>different</b> <b>voxels</b> in time through a hierarchal model. Experimental results show that the realistic time-varying simulation is successfully achieved with the proposed techniques...|$|R
5000|$|In {{the figure}} shown below, P1 {{refers to the}} first-step of the {{iterative}} reconstruction process, of the projection matrix P of the fan-beam geometry, which is constrained by the data fidelity term. This may contain noise and artifacts as no regularization is performed. The minimization of P1 is solved through the conjugate gradient least squares method. P2 refers to the second step of the iterative reconstruction process wherein it utilizes the edge-preserving total variation regularization term to remove noise and artifacts, and thus {{improve the quality of}} the reconstructed image/signal. The minimization of P2 is done through a simple gradient descent method. Convergence is determined by testing, after each iteration, for image positivity, by checking if [...] for the case when [...] (Note that [...] refers to the different x-ray linear attenuation coefficients at <b>different</b> <b>voxels</b> of the patient image).|$|R
30|$|Accordingly, {{the aim of}} {{this study}} was to develop a tissue {{characterization}} mapping (TCM) technique by combining the established LGE method with our novel percent edema mapping (PEM) method to enable the classification of tissue in the <b>different</b> MRI <b>voxels</b> as healthy, edematous, necrotic, hemorrhagic, or scarred using a canine model of reperfused MI.|$|R
40|$|The {{permeability}} and Forchheimer {{coefficients of}} a porous medium, volcanic rock, are determined using micro-tomography images. A cubic volume {{in the middle}} of the images is extracted as REV (representative volume). The voids in the REV are discretised into anisotropic voxels using the commercial program of GeoDict. Seven computational domains with <b>different</b> <b>voxel</b> size in flow direction are generated. The velocity and pressure fields in the voids are obtained for Reynolds numbers ranging from 0. 01 to 10. The obtained fields are used to determine the permeability and the Forchheimer coefficients. The performed calculations show that the nominal pore size changes with the voxel size in flow direction, however permeability and the Forchheimer coefficient approaches to the constant values...|$|E
40|$|We compare two transform-based {{indexing}} {{methods for}} retrieval of 3 D objects. We apply 3 D Discrete Fourier Transform (DFT) and 3 D Radial Cosine Transform (RCT) to the voxelized data of 3 D objects. Rotation invariant features {{are derived from}} the coefficients of these transforms. Furthermore we compare two <b>different</b> <b>voxel</b> representations, namely, binary denoting object and background space, and continuous after distance transformation. In the binary voxel representation the voxel values are simply set to 1 {{on the surface of}} the object and 0 elsewhere. In the continuous-valued representation the space is filled with a function of distance transform. The rotation invariance properties of the DFT and RCT schemes are analyzed. We have conducted retrieval experiments on the Princeton Shape Benchmark and investigated the retrieval performance of the methods using several quality measures. 1...|$|E
40|$|Meteorological {{simulation}} {{tools to}} model gas exchange phenomena within forests require well defined information of forest structure (e. g., 3 D forest models) {{as a basis}} for the computation of the turbulent flow shaped by the drag of the vegetation. The paper describes techniques to obtain 3 D data describing forest stands from dense terrestrial laser scanner point clouds. In a first step, stems are automatically detected from the laser scanner data, forming a basis for the determination of tree density, distance patterns and average stem distance. In a second step, the 3 D point cloud is translated into a voxel structure representing the forest. A method to segment voxel clusters with the goal of a tree wise interpretation, is presented. From this voxel structure, drag coefficients can be derived via the local density and distribution of stems, branches and leaves. Therefore <b>different</b> <b>voxel</b> attributes are calculated. 1...|$|E
3000|$|According to our experiments, we drew a new {{heuristic}} {{to calculate}} the minResolution parameter. It is not desired to have too small resolution that allows many vertices {{to fall into the}} same voxel. So, we aim to distribute the vertices to <b>different</b> <b>voxels</b> as much as possible. We start with the assumption that vertices are distributed homogeneously. We also know that a mesh is generally represented with the vertices located on the surface and inside of the mesh is empty. Hence, we can assume that vertices are located on the facets of the bounding box. More conservatively, we take the facet of the AABB with the minimum area and obtain a resolution that allows distributing all the N vertices of the mesh to this facet homogeneously. For this purpose, we first calculate the proportions of the facets of the AABB (w,h, and d in Eq. 9). Then, we can express each dimension as a function of some constant k (such that w [...]...|$|R
40|$|Abstract. We {{propose a}} novel method for {{deformable}} tensor–to–tensor registration of Diffusion Tensor Imaging (DTI) data. Our registration method considers estimated diffusion tensors as normally distributed random variables whose covariance matrices describe uncertainties {{in the mean}} estimated tensor due to factors such as noise in diffusion weighted images (DWIs), tissue diffusion properties, and experimental design. The dissimilarity between distributions of tensors in two <b>different</b> <b>voxels</b> is computed using the Kullback-Leibler divergence to drive a deformable registration process, which is not only affected by principal diffusivities and principal directions, but also the underlying DWI properties. We in general do not assume the positive definite nature of the tensor space given the pervasive influence of noise and other factors. Results indicate that the proposed metric weights voxels more heavily whose diffusion tensors are estimated with greater certainty and exhibit anisotropic diffusion behavior thus, intrinsically favoring coherent white matter regions whose tensors are estimated with high confidence. ...|$|R
40|$|Abstract. Compressed Sensing (CS) takes {{advantage}} of signal sparsity or com-pressibility and allows superb signal reconstruction from relatively few measure-ments. Based on CS theory, a suitable dictionary for sparse representation of the signal is required. In diffusion MRI (dMRI), CS methods were proposed to recon-struct diffusion-weighted signal and the Ensemble Average Propagator (EAP), {{and there are two}} kinds of Dictionary Learning (DL) methods: 1) Discrete Repre-sentation DL (DR-DL), and 2) Continuous Representation DL (CR-DL). DR-DL is susceptible to numerical inaccuracy owing to interpolation and regridding er-rors in a discretized q-space. In this paper, we propose a novel CR-DL approach, called Dictionary Learning- Spherical Polar Fourier Imaging (DL-SPFI) for ef-fective compressed-sensing reconstruction of the q-space diffusion-weighted sig-nal and the EAP. In DL-SPFI, an dictionary that sparsifies the signal is learned from the space of continuous Gaussian diffusion signals. The learned dictionary is then adaptively applied to <b>different</b> <b>voxels</b> using a weighted LASSO framework for robust signal reconstruction. The adaptive dictionary is proved to be opti...|$|R
40|$|X-Ray Computed Tomography (CT) {{scanning}} is {{an effective}} method for estimating the porosity of various engineering materials and biomedical specimens such as tissue scaffolds and bones. However, the scanning and analysis parameters {{play a significant role}} in the accuracy of the porosity value determined from CT scan. This paper presents details of an investigation carried out to understand the effect of system parameters, namely the voxel size, X-ray focal spot size and segmentation threshold, on the estimated porosity by taking an example of safety-critical foam used for impact protection applications. <b>Different</b> <b>voxel</b> resolutions and focal spot sizes are selected in a total of 12 scanning tests and the effect of segmentation threshold is analyzed on each of these tests. The study indicates that the obtained porosity value is greatly influenced by the choice of voxel size at larger spot sizes and less influenced at smaller spot sizes. The threshold also has significant effect on the porosity value, especially at larger voxel sizes...|$|E
40|$|This paper {{introduces}} a new acceleration technique for ray casting type volume rendering called IsoRegion Leaping. A factorization {{of the sample}} composition equation leads to our new algorithm {{which is based on}} homogeneity inside a volume. We create an IsoRegion data structure to help identifying homogeneous voxel cubes, which is independent of the viewing parameters and shading conditions, thus can be pre-processed. Accumulated colors and transparencies of homogeneous ray segments are pre-computed into a look-up table according to <b>different</b> <b>voxel</b> values and ray segment lengths. Attributes of ray segments piercing through IsoRegion blocks are looked-up from the table. Therefore, unnecessary sample compositions within IsoRegions are saved. This voxel leaping technique is experimentally proved to be efficient even for real-life medical volume data. A speedup of 2 to 3 times is measured while preserving the image quality. Images generated by our algorithm and the ones from the original algorithm without IsoRegion Leaping acceleration are identical, both theoretically and experimentally...|$|E
40|$|Vector Decomposition MachineEsta tese é dedicada aos meus pais Paula e José, avós Clementina e Sidónio e à minha irmã Mariana, por terem sempre confiado em mim de todas as formas possiveis, mesmo The thesis {{put forth}} in this {{dissertation}} is that machine learning classifiers {{can be used}} as instruments for decoding variables of interest from functional magnetic resonance imaging (fMRI) data. There are two main goals in decoding: • Showing that the variable of interest can be predicted from the data in a statistically reliable manner (i. e. there’s enough information present). • Shedding light on how the data encode the information needed to predict, taking into account what the classifier used can learn and any criteria by which the data are filtered (e. g. how voxels and time points used are chosen). Chapter 2 considers the issues that arise when using traditional linear classifiers and several <b>different</b> <b>voxel</b> selection techniques to strive towards thes...|$|E
40|$|International audienceOne {{important}} {{problem in}} diffusion MRI (dMRI) is {{to recover the}} diffusion weighted signal from {{only a limited number}} of samples in q-space. An ideal framework for solving this problem is Compressed Sensing (CS), which takes advantage of the signal's sparseness or compressibility, allowing the entire signal to be reconstructed from relatively few measurements. CS theory requires a suitable dictionary that sparsely represents the signal. To date in dMRI there are two kinds of Dictionary Learning (DL) methods: 1) discrete representation based DL (DR-DL), and 2) continuous representation based DL (CR-DL). Due to the discretization in q-space, DR-DL suffers from the numerical errors in interpolation and regridding. By considering a continuous representation using Spherical Polar Fourier (SPF) basis, this paper proposes a novel CR-DL based Spherical Polar Fourier Imaging, called DL-SPFI, to recover the diffusion signal as well as the Ensemble Average Propagator (EAP) in continuous 3 D space with closed form. DL-SPFI learns an optimal dictionary from the space of Gaussian diffusion signals. Then the learned dictionary is adaptively applied for <b>different</b> <b>voxels</b> in a weighted LASSO framework to robustly recover the di ffusion signal and the EAP. Compared with the start-of-the-art CR-DL method by Merlet et al. and DRDL by Bilgic et al., DL-SPFI has several advantages. First, the learned dictionary, which is proved to be optimal in the space of Gaussian diffusion signal, can be applied adaptively for <b>different</b> <b>voxels.</b> To our knowledge, this is the first work to learn a voxel-adaptive dictionary. The importance of this will be shown theoretically and empirically in the context of EAP estimation. Second, based on the theoretical analysis of SPF basis, we devise an efficient learning process in a small subspace of SPF coefficients, not directly in q-space as done by Merlet et al [...] Third, DL-SPFI also devises different regularization for different atoms in the learned dictionary for robust estimation, by considering the structural prior in the space of signal exemplars. We evaluate DL-SPFI in comparison to L 1 -norm regularized SPFI (L 1 -SPFI) with fixed SPF basis, and the DR-DL by Bilgic et al. The experiments on synthetic data and real data demonstrate that the learned dictionary is sparser than SPF basis and yields lower reconstruction error than Bilgic's method, even though only simple synthetic Gaussian signals were used for training in DL-SPFI in contrast to real data used by Bilgic et al...|$|R
30|$|In the {{regression}} part of encoding, regularized linear regression models such as lasso (Kay et al. 2008), ridge regression (Güçlü and van Gerven 2014) and graph-constrained elastic net (Kay et al. 2008; Schoenmakers et al. 2013) were most commonly used. Recently, {{a more advanced}} sparse nonparametric regression model was proposed (Vu et al. 2011). In spite of the successful prediction of brain activity using these models, one drawback of these voxel-wise models in previous studies is that the response of each voxel is modeled separately; thus, the estimated parameters of <b>different</b> <b>voxels</b> are independent. As a result, these regression models cannot fully employ the correlations between voxels and brain regions. Numerous studies have indicated the benefits of taking the spatial smoothness of fMRI data into account. For example, in the decoding models, when the spatial structure of the data is considered, higher decoding accuracies and more informative and interpretable results can be obtained (Michel et al. 2011; de Brecht and Yamagishi 2012). In functional brain mapping, combining local brain activity often results in more consistent patterns across subjects (Kriegeskorte et al. 2006). All {{these results suggest that}} spatial structure of fMRI data should also be considered in encoding models.|$|R
40|$|OBJECT: Diffusion tensor imaging (DTI) of {{the breast}} may provide a {{powerful}} new approach {{for the detection of}} intraductal processes. The aim of this investigation was to characterize the relation between diffusion tensor parameters [fractional anisotropy (FA), mean diffusivity (MD) ] in normal breast tissue to obtain information on the microenvironment of the diffusing water molecules and to provide a systematic approach for DTI analysis. MATERIALS AND METHODS: Seven female, healthy volunteers underwent prospective double-spin-echo prepared echo-planar diffusion-weighted sequence (TR/TE 8, 250  ms/ 74  ms, b values 0 and 500  s/mm (2), six encoding directions, 12 averages, 35 slices) in 4 consecutive weeks (3. 0 T). Quantitative maps of diffusion tensor parameters were computed offline with custom routines. The interdependence of MD and FA in <b>different</b> <b>voxels</b> was analysed by linear and exponential regression. RESULTS: All MD and FA maps were of excellent quality. A consistent pattern was observed in that lower fractional anisotropy values were more likely associated with higher mean diffusivity values. The dependence exhibited an exponential behavior with a correlation coefficient R =  0. 60 (R linear =  0. 57). CONCLUSION: The likelihood with which FA and MD values are observed in a voxel within normal breast tissue is characterized by a specific pattern, which can be described by an exponential model. Moreover, we could show that the proposed technique does not depend on the menstrual cycle...|$|R
40|$|Abstract — X-Ray Computed Tomography (CT) {{scanning}} is {{an effective}} method for estimating the porosity of various engineering materials and biomedical specimens such as tissue scaffolds and bones. However, the scanning and analysis parameters {{play a significant role}} in the accuracy of the porosity value determined from CT scan. This paper presents details of an investigation carried out to understand the effect of system parameters, namely the voxel size, X-ray focal spot size and segmentation threshold, on the estimated porosity by taking an example of safety-critical foam used for impact protection applications. <b>Different</b> <b>voxel</b> resolutions and focal spot sizes are selected in a total of 12 scanning tests and the effect of segmentation threshold is analyzed on each of these tests. The study indicates that the obtained porosity value is greatly influenced by the choice of voxel size at larger spot sizes and less influenced at smaller spot sizes. The threshold also has significant effect on the porosity value, especially at larger voxel sizes. Keywords-X-ray computed tomography, porosity, foam, CT scanning parameters I...|$|E
40|$|Creative Commons Attribution License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. We present a new discriminant analysis (DA) method called Multiple Subject Barycentric Discriminant Analysis (MUSUBADA) suited for analyzing fMRI data because it handles datasets with multiple participants that each provides different {{number of variables}} (i. e., voxels) that are themselves grouped into regions of interest (ROIs). Like DA, MUSUBADA (1) assigns observations to predefined categories, (2) gives factorial maps displaying observations and categories, and (3) optimally assigns observations to categories. MUSUBADA handles cases with more variables than observations and can project portions of the data table (e. g., subtables, which can represent participants or ROIs) on the factorial maps. Therefore MUSUBADA can analyze datasets with <b>different</b> <b>voxel</b> numbers per participant and, so does not require spatial normalization. MUSUBADA statistical inferences are implemented with cross-validation techniques (e. g., jackknife and bootstrap), its performance is evaluated with confusion matrices (for fixed and random models) and represented with prediction, tolerance, and confidence intervals. We present an example wher...|$|E
40|$|This study {{assessed}} in vitro the diagnostic ability of cone beam computed tomography (CBCT) scans with <b>different</b> <b>voxel</b> resolutions in {{the detection of}} simulated external root resorption (ERR). For that purpose, 59 teeth were viewed through iCAT tomography (Imaging Sciences International, Inc, Hatfield, PA) following three protocols in which the variation was the voxel resolu-tion (0. 4, 0. 3, and 0. 2 mm). A calibrated examiner blinded to the protocol assessed the images through the i-CAT View software (Imaging Sciences Interna-tional, Inc). The chi-square statistical analysis did not show associations between voxel resolution, section plane, size of cavity, and radicular third. Sensitivity and specificity values were similar. However, likelihood ra-tio values of 6. 4 for a 0. 4 -mm voxel, 16 for a 0. 3 -mm voxel, and 12 for a 0. 2 -mm voxel were found. It was concluded that CBCT is a reliable method for the in-vestigation of simulated ERR, and a 0. 3 -mm voxel {{appeared to be the}} best protocol, associating good diagnostic performance with lower X-ray exposure. (...|$|E
40|$|Abstract. In this paper, {{we present}} a group {{sparsity}} constrained patch based label propagation method for multi-atlas automatic brain labeling. The proposed method formulates the label propagation process as a graph-based theoretical framework, where each voxel in the input image is linked to each candidate voxel in each atlas image by an edge in the graph. The weight of the edge is estimated based on a sparse representation framework to identify {{a limited number of}} candidate voxles whose local image patches can best represent the local image patch of each voxel in the input image. The group sparsity constraint to capture the dependency among candidate voxels with the same anatomical label is also enforced. It is shown that based on the edge weight estimated by the proposed method, the anatomical label for each voxel in the input image can be estimated more accurately by the label propagation process. Moreover, we extend our group sparsity constrained patch based label propagation framework to the reproducing kernel Hilbert space (RKHS) to capture the nonlinear similarity of patches among <b>different</b> <b>voxels</b> and construct the sparse representation in high dimensional feature space. The proposed method was evaluated on the NA 0 -NIREP database for automatic human brain anatomical labeling. It was also compared with several state-of-the-art multi-atlas based brain labeling algorithms. Experimental results demonstrate that our method consistently achieves the highest segmentation accuracy among all methods used for comparison. ...|$|R
40|$|Abstract. Label fusion {{is a key}} step in multi-atlas based segmentation, which {{combines}} labels from multiple atlases to make the final decision. However, most of the current label fusion methods consider each voxel equally and independently during label fusion. In our point of view, however, <b>different</b> <b>voxels</b> act <b>different</b> roles {{in the way that}} some voxels might have much higher confidence in label determination than others, i. e., because of their better alignment across all registered atlases. In light of this, we propose a sequential label fusion framework for multi-atlas based image segmentation by hierarchically using the voxels with high confidence to guide the labeling procedure of other challenging voxels (whose registration results among deformed atlases are not good enough) to afford more accurate label fusion. Specifically, we first measure the corresponding labeling confidence for each voxel based on the k-nearest-neighbor rule, and then perform label fusion sequentially according to the estimated labeling confidence on each voxel. In particular, for each label fusion process, we use not only the propagated labels from atlases, but also the estimated labels from the neighboring voxels with higher labeling confidence. We demonstrate the advantage of our method by deploying it to the two popular label fusion algorithms, i. e., majority voting and local weighted voting. Experimental results show that our sequential label fusion method can consistently improve the performance of both algorithms in terms of segmentation/labeling accuracy. ...|$|R
40|$|Spatial whole-brain Bayesian {{modeling}} of task-related functional {{magnetic resonance imaging}} (fMRI) is a great computational challenge. Most of the currently proposed methods therefore do inference in subregions of the brain separately or do approximate inference without comparison to the true posterior distribution. A popular such method, which is now the standard method for Bayesian single subject analysis in the SPM software, is introduced in Penny et al. (2005 b). The method processes the data slice-by-slice and uses an approximate variational Bayes (VB) estimation algorithm that enforces posterior independence between activity coefficients in <b>different</b> <b>voxels.</b> We introduce a fast and practical Markov chain Monte Carlo (MCMC) scheme for exact inference in the same model, both slice-wise and for the whole brain using a 3 D prior on activity coefficients. The algorithm exploits sparsity and uses modern techniques for efficient sampling from high-dimensional Gaussian distributions, leading to speed-ups without which MCMC would not be a practical option. Using MCMC, we are for the first time able to evaluate the approximate VB posterior against the exact MCMC posterior, and show that VB can lead to spurious activation. In addition, we develop an improved VB method that drops the assumption of independent voxels a posteriori. This algorithm is shown to be much faster than both MCMC and the original VB for large datasets, with negligible error compared to the MCMC posterior. Funding agencies: Swedish Research Council (Vetenskapsradet) [20135229]; Knut and Alice Wallenberg Foundation [KAW 20012. 0067]</p...|$|R
