64|3787|Public
500|$|Each {{individual}} {{has a unique}} callosities pattern. In 2016, a competitive effort resulted {{in the use of}} <b>facial</b> <b>recognition</b> <b>software</b> to derive a process to uniquely identify right whales with about 87% accuracy based on their callosities. The primary role of callosities has been considered to be protection against predators. Right whale declines might have also reduced barnacles. Right whales are very large, robust whales that can grow up to and over [...] long and weigh up to , almost as big as bowhead whales and much larger than other species with high dependencies on shallow waters. An unusually large 40% of their body weight is blubber, which is of relatively low density. Consequently, unlike many other species of whale, dead right whales tend to float. Right whales swim slowly, reaching only [...] at top speed. However, they are highly acrobatic and frequently breach (jump clear of the sea surface), tail-slap and lobtail.|$|E
500|$|Set {{some time}} before {{the events of the}} first game, the main character, whose name is later {{revealed}} to be Jeremy Fitzgerald, has started working as a night watch security guard at the [...] "new and improved" [...] Freddy Fazbear's Pizza. The [...] "upgraded" [...] versions of the animatronic characters, which have special <b>facial</b> <b>recognition</b> <b>software</b> to protect the children from potential harm, were not programmed with a proper night mode; when things go silent, their programming tells them that they are in the wrong room and they seek out the nearest source of noise to find people to entertain, which happens to be in the player's office. The player must again listen to the instructions of a [...] "phone guy", and attempt to defend themselves from the animatronics using several mechanics. Like the previous game, the player must survive from midnight to 6 AM. Jeremy is apparently moved to day shift after Night 6 as the animatronics' hostility becomes too dangerous, with the restaurant closing down shortly after.|$|E
2500|$|... 18 January – Japanese {{researchers}} {{create a}} [...] "privacy visor" [...] which uses near-infrared light to render its wearer unrecognizable to <b>facial</b> <b>recognition</b> <b>software.</b>|$|E
40|$|Abstract — An {{endoscope}} is {{an invaluable}} tool to interpret conditions within a body. Flexible endoscopes {{are controlled by}} a set of rotational knobs requiring a doctor’s hands to guide and locate the view. This research uses a combination of a camera, <b>facial</b> <b>recognition</b> techniques and <b>software</b> to create a hands-free gesture recognition application for use by a physician to probe the internals of a human body. The physician will utilize the head movements to move the endoscopic camera freeing their hands to perform a procedure or other functions. I...|$|R
40|$|The {{prevalence}} of human error in safety-critical occupations remains {{a major challenge}} to mission success despite increasing automation in control processes. Although various methods have been proposed to prevent incidences of human error, none of these {{have been developed to}} employ the detection and regulation of Operator Functional State (OFS), or the optimal condition of the operator while performing a task, in work environments due to drawbacks such as obtrusiveness and impracticality. A video-based system with the ability to infer an individual's emotional state from facial feature patterning mitigates some of the problems associated with other methods of detecting OFS, like obtrusiveness and impracticality in integration with the mission environment. This paper explores the utility of <b>facial</b> expression <b>recognition</b> as a technology for inferring OFS by first expounding on the intricacies of OFS and the scientific background behind emotion and its relationship with an individual's state. Then, descriptions of the feedback loop and the emotion protocols proposed for the <b>facial</b> <b>recognition</b> program are explained. A basic version of the <b>facial</b> expression <b>recognition</b> program uses Haar classifiers and OpenCV libraries to automatically locate key facial landmarks during a live video stream. Various methods of creating <b>facial</b> expression <b>recognition</b> <b>software</b> are reviewed to guide future extensions of the program. The paper concludes with an examination of the steps necessary in the research of emotion and recommendations for the creation of an automatic <b>facial</b> expression <b>recognition</b> program for use in real-time, safety-critical mission...|$|R
40|$|Entrepreneurs face a {{daunting}} challenge in turning {{a solution to}} a compelling problem into a viable business. Recent research into multi-sided platforms and collective action has highlighted an approach that may enable entrepreneurs to {{lower the risk of}} a new venture and increase revenue by delivering value to all stakeholders in a collective, not just to the company itself. However, the shift in thinking required to apply this new approach is a challenge of its own. In this article, we provide an overview of both the new and traditional approaches to development and commercialization. Next, we describe a problem for which we are currently developing a business opportunity to solve: helping parents provide adequate and appropriate support to children with attention deficit hyperactivity disorder (ADHD) or autism. We then use this problem as a case study to illustrate how the implementation of a <b>facial</b> emotion <b>recognition</b> <b>software</b> application might be substantially different depending on the development and commercialization approach used. Finally, we describe the key lessons learned and next steps in developing this business opportunity...|$|R
2500|$|Facebook's market {{dominance}} {{has led to}} international media coverage and significant reporting of its shortcomings. Notable issues include Internet privacy, such as its widespread use of a [...] "like" [...] button on third-party websites tracking users, possible indefinite records of user information, automatic <b>facial</b> <b>recognition</b> <b>software,</b> {{and its role in}} the workplace, including employer-employee account disclosure.|$|E
2500|$|... (2017) On {{view at the}} Park Avenue Armory through August 6, 2017, Hansel and Gretel is an {{installation}} exploring the theme of surveillance. The project, a collaboration of Ai Weiwei and architects Jacques Herzog and Pierre de Meuron, features surveillance cameras equipped with <b>facial</b> <b>recognition</b> <b>software,</b> near-infrared floor projections, tethered, autonomous drones and sonar beacons. A [...] includes a curatorial statement, artist biographies, a livestream of the installation and a timeline of surveillance technology from ancient to modern times.|$|E
2500|$|In 2004, for {{an episode}} titled [...] "Hunting Nazis", the {{television}} series Unsolved History used <b>facial</b> <b>recognition</b> <b>software</b> to compare Alois Brunner's official SS photograph {{with a recent}} photo of [...] "Georg Fischer", {{and came up with}} a match of 8.1 points out of 10, which they claimed was, despite the elapse of over 50 years in aging, equivalent to a match with 95% certainty. Brazilian police were reportedly investigating whether a suspect living in the country under an assumed name is actually Alois Brunner. Deputy Commander Asher Ben-Artzi, the head of Israel's Interpol and Foreign Liaison Section, passed on a Brazilian request for Brunner's fingerprints to Nazi hunter Efraim Zuroff, head of the Simon Wiesenthal Center in Jerusalem, but Zuroff could not find any.|$|E
40|$|This paper {{presents}} an experimental study on modeling machine emotion elicitation in a socially intelligent service, the typing tutor. The {{aim of the}} study is to evaluate {{the extent to which the}} machine emotion elicitation can influence the affective state (valence and arousal) of the learner during a tutoring session. The tutor provides continuous real-time emotion elicitation via graphically rendered emoticons, as an emotional feedback to learner’s performance. Good performance is rewarded by the positive emoticon, based on the notion of positive reinforcement. <b>Facial</b> emotion <b>recognition</b> <b>software</b> is used to analyze the affective state of the learner for later evaluation. Experimental results show the correlation between the positive emoticon and the learner’s affective state is significant for all 13 (100 %) test participants on the arousal dimension and for 9 (69 %) test participants on both affective dimensions. The results also confirm our hypothesis and show that the machine emotion elicitation is significant for 11 (85 %) of 13 test participants. We conclude that the machine emotion elicitation with simple graphical emoticons has a promising potential for the future development of the tutor...|$|R
40|$|The {{commercial}} face <b>recognition</b> <b>software</b> FaceIt ® Identification and Surveillance {{was evaluated}} using the <b>Facial</b> <b>Recognition</b> Technology (FERET) database. The experimental results show {{the performance of}} FaceIt ® with variations in illumination, expression, age, head size, pose, {{and the size of}} the database which all remain difficult problems in face recognition technology...|$|R
40|$|Over {{the last}} ten years or so, <b>facial</b> <b>recognition</b> has become a popular area of {{research}} in computer vision {{and one of the most}} successful applications of image analysis and understanding. Because of the nature of the problem, not only computer science researchers are interested in it, but neuroscientists and psychologists also. It is the general opinion that advances in computer vision research will provide useful insights to neuroscientists and psychologists into how human brain works, and vice versa. Humans have always had the innate ability to recognize and distinguish between faces,yet computers only recently have shown the same ability. In the mid 1960 s, scientists began work on using the computer to recognize human faces. Since then,facial <b>recognition</b> <b>software</b> has come a long way. In this article, we will look at the reason behind using <b>facial</b> <b>recognition,</b> the various technology used in the <b>facial</b> <b>recognition,</b> the products been made to implement this biometrics technique and also the criticisms and advantages that are bounded with it...|$|R
50|$|Polar Rose was {{a company}} from Malmö, Sweden which made <b>facial</b> <b>recognition</b> <b>software.</b>|$|E
50|$|Tests of <b>facial</b> <b>recognition</b> <b>software</b> {{dating from}} 2006 showed error rates {{of up to}} 52 percent for the disabled.|$|E
50|$|In September 2015, Snapchat {{acquired}} Looksery {{to develop}} Lenses for its mobile app, a feature based on Looksery's <b>facial</b> <b>recognition</b> <b>software.</b>|$|E
50|$|In January 2013 Japanese {{researchers}} from the National Institute of Informatics created 'privacy visor' glasses that uses nearly infrared light to make the face underneath it unrecognizable to face <b>recognition</b> <b>software.</b> The latest version uses a titanium frame, light-reflective material and a mask which uses angles and patterns to disrupt <b>facial</b> <b>recognition</b> technology through both absorbing and bouncing back light sources. In December 2016 a form of anti-CCTV and <b>facial</b> <b>recognition</b> sunglasses called 'reflectacles' were invented by a custom-spectacle-craftsmen based in Chicago named Scott Urban. They reflect infrared and, optionally, visible light which makes the users face a white blur to cameras. The project easily surpassed its crowdfunding goal of $28,000 and reflectacles will be commercially available by June 2017.It is conceivable that such technology might be fused with future head-mounted displays such as potential successors of HoloLens.|$|R
40|$|Emotional numbing is {{a symptom}} of {{post-traumatic}} stress disorder (PTSD) characterized by a loss of interest in usually enjoyable activities, feeling detached from others, and an inability to express a full range of emotions. Emotional numbing is usually assessed through self-report, and is particularly difficult to ascertain among young children. We conducted a pilot study to explore the use of facial expression ratings in response to a comedy video clip, and to assess emotional reactivity among preschool children directly exposed to the Great East Japan Earthquake. This study included 23 child participants. Child PTSD symptoms were measured using {{a modified version of the}} Parent’s Report of the Child’s Reaction to Stress scale. Children were filmed while watching a 2 -minute video compilation of natural scenes (‘baseline video’) followed by a 2 -minute video clip from a television comedy (‘comedy video’). Children’s facial expressions were processed using Noldus FaceReader software, which implements the Facial Action Coding System (FACS). We investigated the association between PTSD symptom scores and facial emotion reactivity using linear regression analysis. Children with higher PTSD symptom scores showed a significantly greater proportion of neutral facial expressions, controlling for sex, age and baseline facial expression (p <. 05). This pilot study suggests that facial emotion reactivity could provide an index against which emotional numbing could be measured in young children, using <b>facial</b> expression <b>recognition</b> <b>software.</b> This pilot study adds to the emerging literature on using experimental psychopathology methods to characterize children’s reactions to disasters...|$|R
50|$|Examples {{of early}} {{surveillance}} states include the former Soviet Union {{and the former}} East Germany, which had a large network of informers and an advanced technology base in computing and spy-camera technology. But these states did not have today's technologies for mass surveillance, {{such as the use}} of databases and pattern <b>recognition</b> <b>software</b> to cross-correlate information obtained by wire tapping, including speech recognition and telecommunications traffic analysis, monitoring of financial transactions, automatic number plate recognition, the tracking of the position of mobile telephones, and <b>facial</b> <b>recognition</b> systems and the like which recognize people by their appearance, gait, DNA profiling, etc.|$|R
50|$|In April 2014, the {{advertising}} agency iStrategyLabs produced a two-way mirror capable of automatically posting selfies to Twitter, using <b>facial</b> <b>recognition</b> <b>software.</b>|$|E
50|$|Gl{{advertising}} (n) is {{outdoor advertising}} that uses cameras and <b>facial</b> <b>recognition</b> <b>software</b> {{to read a}} consumer's mood, then pushes products relevant to the target emotional state. It uses emotion recognition software to tailor outdoor adverts to consumers' mood.|$|E
5000|$|At Super Bowl XXXV in January 2001, {{police in}} Tampa, Florida, used Identix’s <b>facial</b> <b>recognition</b> <b>software,</b> FaceIt, {{to scan the}} crowd for {{potential}} criminals and terrorists in attendance at the event [...] (it found 19 people with pending arrest warrants).|$|E
40|$|ABSTRACT GENDER DIFFERENCES IN <b>FACIAL</b> <b>RECOGNITION</b> by ?? Karley M. Winters 2009 Master of Arts in Psychology Psychological Science Option California State University, Chico Spring 2009 Past {{research}} has found significant gender differences in <b>facial</b> <b>recognition,</b> with women recognizing more faces than men. It has also been found that women recognize more same-sex faces. This study attempted to replicate these findings and to explore {{the effect of a}} variety of social-personality variables (self-esteem, self-attribute appraisal, body satisfaction, and personality traits) on these differential recognition processes. Multivariate analyses indicated significant gender differences in same-sex and opposite-sex <b>facial</b> <b>recognition</b> abilities, yet not in total <b>facial</b> <b>recognition.</b> Regression analyses examined the ability of these social-personality variables to predict <b>facial</b> <b>recognition,</b> but the results were not significant. Alternative explanations for gender differences in <b>facial</b> <b>recognition</b> are discussed. CSU, Chic...|$|R
40|$|Over {{the past}} decade <b>Facial</b> <b>Recognition</b> has become more {{cohesive}} and reliable than ever before. We begin with an analysis explaining why certain <b>facial</b> <b>recognition</b> methodologies examined under FERET, FRVT 2000, FRVT 2002, and FRVT 2006 have become stronger and why other approaches to <b>facial</b> <b>recognition</b> are losing traction. Second, we cluster the stronge...|$|R
5|$|<b>Facial</b> <b>recognition</b> software: A {{photograph}} {{transmitted by}} the SEALs to CIA headquarters in Langley, Virginia, for <b>facial</b> <b>recognition</b> analysis yielded a 90 to 95 percent likely match.|$|R
5000|$|In 2006, Scheirer founded {{her first}} MIT Media Lab spinout Empathyx, Inc. where she {{attempted}} to commercialize the Galvactivator. In 2009, Affectiva licensed the Galvactivator from MIT. Rana el Kaliouby and Rosalind Picard would continue to utilize the patent over the next 3 years, developing their own skin conductance sensor called the Q Sensor which also used some of the technology from the MIT Media Lab's iCalm, another wearable physiological monitoring device. Affectiva used the Q Sensor {{in addition to their}} <b>facial</b> <b>recognition</b> <b>software</b> to measure physiological stress and excitement in focus groups. Affectiva discontinued their use of the [...] "Q Sensor" [...] in 2013 to focus their attention exclusively on their patented Affdex <b>facial</b> <b>recognition</b> <b>software.</b>|$|E
5000|$|The forward {{plan for}} FIND {{included}} {{the addition of}} <b>facial</b> <b>recognition</b> <b>software</b> (much like the United States' FERET database) to the system. Due to budget pressures, the project was cancelled in early 2008 but this decision was under review in October 2008.|$|E
50|$|One of the {{outcomes}} of the project includes a CT facial reconstruction of Padihershef. Using the scans, 3D <b>facial</b> <b>recognition</b> <b>software</b> and a thorough knowledge of mummy forensics, Elias' group undertook a thorough analysis based on all these factors and using a 3D skull model, developed a representation of what Padi may have looked like in life.|$|E
50|$|While it {{has been}} widely {{recognized}} that many cognitive abilities, such as general intelligence, have genetic bases, evidence for the genetic basis of <b>facial</b> <b>recognition</b> abilities specifically is fairly recent. Some of the earliest published research {{on the relationship between}} <b>facial</b> <b>recognition</b> and genetics focused on the genetic bases of <b>facial</b> <b>recognition</b> in the context of genetic disorders which impair <b>facial</b> <b>recognition</b> abilities, such as Turner syndrome. In a study by Lawrence, K. et al. in 2003 the authors found significantly poorer <b>facial</b> <b>recognition</b> abilities in individuals with Turner syndrome, a genetic disorder which results in impaired amygdala functioning, suggesting that amygdala functioning may impact face perception. Evidence for the genetic basis of <b>facial</b> <b>recognition</b> abilities in the general population, however, comes from studies on face perception in twin participants by Wilmer, J. B. et al. in 2009, in which the <b>facial</b> <b>recognition</b> scores on the Cambridge Face Memory test were twice as similar for monozygotic twins in comparison to dizygotic twins. This finding was supported by a twin study on the genetic bases of <b>facial</b> <b>recognition</b> by Zhu, Q. et al. in (2009) which found a similar difference in <b>facial</b> <b>recognition</b> scores when comparing monozygotic and dizygotic twins and Shakeshaft, N. G. & Plomin, R. (2015), which determined the heritability of <b>facial</b> <b>recognition</b> to be approximately 61%, using a similar set of twin studies. There was also no significant relationship identified between <b>facial</b> <b>recognition</b> scores and measures of any other cognitive abilities, most notably the lack of a correlation with general object recognition abilities. This suggests that <b>facial</b> <b>recognition</b> abilities are not only heritable, but that their genetic basis is independent from the bases of other cognitive abilities and are specialized for face perception. Research by Cattaneo, Z. et al. (2016) and suggest that the more extreme examples of <b>facial</b> <b>recognition</b> abilities, specifically hereditary prosopagnosics, are also highly genetically correlated. For hereditary prosopagnosics, an autosomal dominant model of inheritance has been proposed by Kennerknecht, I. et al. (2006). Research by Cattaneo, Z. et al. (2016) also correlated the probability of hereditary prosopagnosia with the presence of single nucleotide polymorphisms along the Oxytocin receptor gene (OXTR), specifically at nucleotides rs2254298 and rs53576 on OXTR intron three, suggesting that these alleles may serve a critical role in normal face perception. Mutation from the wild type allele at these loci has also been found to result in other disorders in which social and <b>facial</b> <b>recognition</b> deficits are common, such as autism spectrum disorder, which may imply that the genetic bases for general <b>facial</b> <b>recognition</b> are complex and polygenic. This relationship between the OXTR gene and <b>facial</b> <b>recognition</b> abilities is also supported by studies of individuals who do not suffer from hereditary prosopagnosia by Melchers, M. et al. (2013) and Westberg, L. et al. (2016) which correlated general <b>facial</b> <b>recognition</b> abilities with different polymorphisms of the OXTR gene, specifically rs7632287 and rs2268498. Further research is needed to confirm the specific mechanisms of these genetic components on face perception; however, current evidence does suggest that <b>facial</b> <b>recognition</b> abilities are highly linked to genetic, rather than environmental, bases.|$|R
5000|$|One theory {{explains}} that normal <b>facial</b> <b>recognition</b> requires automatic processes, whereas special <b>facial</b> <b>recognition</b> requires controlled processes. [...] Automatic processes are aided by correlative stimuli and responses, while controlled processes are aided by stimuli and responses {{that do not}} correlate. This indicates that <b>facial</b> <b>recognition</b> depends on type of attention, automatic or controlled, rather than focus on global or local features.|$|R
40|$|Abstract — This paper {{analyzes}} {{the feasibility of}} using <b>facial</b> <b>recognition</b> as an additional security measure in travel documents. Accuracy of current <b>facial</b> <b>recognition</b> systems falls short for applications in large, high-traffic security environments. Biometric data specifications in passports provided by the International Civil Aviation Organization (ICAO) have inherent security flaws. Social impact of incorporating <b>facial</b> <b>recognition</b> globally requires significant effort from all participating countries...|$|R
5000|$|Facebook's market {{dominance}} {{has led to}} international media coverage and significant reporting of its shortcomings. Notable issues include Internet privacy, such as its widespread use of a [...] "like" [...] button on third-party websites tracking users, possible indefinite records of user information, automatic <b>facial</b> <b>recognition</b> <b>software,</b> {{and its role in}} the workplace, including employer-employee account disclosure.|$|E
50|$|Activist {{groups have}} stated that the bill poses a severe threat to the freedom of assembly. In an era where social media brings people {{together}} the technologies the government is involved with like <b>facial</b> <b>recognition</b> <b>software</b> and video surveillance are {{at an all-time high}} and are actively being used to identify individuals at protests who may not wish to be identified.|$|E
5000|$|Criticism of Facebook {{relates to}} how Facebook's market {{dominance}} {{have led to}} international media coverage and significant reporting of its shortcomings. Notable issues include Internet privacy, such as its use of a widespread [...] "like" [...] button on third-party websites tracking users, possible indefinite records of user information, automatic <b>facial</b> <b>recognition</b> <b>software,</b> {{and its role in}} the workplace, including employer-employee account disclosure.|$|E
5000|$|One {{explanation}} {{is a possible}} biological dysfunction in the brain region where facial processing occurs. Research indicates that global processing, <b>facial</b> <b>recognition,</b> and emotional expression recognition are all linked to the right hemisphere. [...] A defect in that area would explain the characteristics of autism. For further information on <b>facial</b> <b>recognition</b> and processing in individuals with autism see the autism and <b>facial</b> <b>recognition</b> section of face perception.|$|R
40|$|There {{are many}} new and {{exciting}} technologies. This case study presents one that is not quite in the mainstream yet – <b>facial</b> <b>recognition.</b> <b>Facial</b> <b>recognition</b> {{has been used by}} the United States Department of Homeland Security for recognition of individuals who might have ties to terrorism activities. This case presents a hypothetical usage – using <b>facial</b> <b>recognition</b> with a customer relationship management system to give retail customers a better shopping experience. Thi...|$|R
5000|$|<b>Facial</b> <b>Recognition</b> and Spoof Detection <b>Software</b> (API)The <b>facial</b> <b>recognition</b> [...] {{technology}} entails spoof detection. This means that, {{if someone}} tries {{to hold up}} a picture of someone who as been granted access, on their phone or {{on a piece of}} paper, then this will not work as the technology will detect that there has been an attack. The <b>facial</b> <b>recognition</b> technology [...] itself has almost perfect accuracy. This form of spoof detection technology does not exist anywhere else.|$|R
