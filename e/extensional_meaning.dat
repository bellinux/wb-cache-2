5|4|Public
40|$|In {{the present}} paper, we {{describe}} a theoretical {{approach to the}} interpretation of utterances in spoken language dialogue systems. The paper presents a decidable version of Discourse Representation Theory based on Description Logics. It shows how terminological reasoning can be integrated into parsing, while reasoning about the <b>extensional</b> <b>meaning</b> of utterances serves for realizing mixedinitiative dialogues...|$|E
40|$|This task {{investigates the}} <b>extensional</b> <b>meaning</b> of body part terms, in {{particular}} the terms for {{the upper and lower}} limbs. Two questions are addressed, namely (i) are the boundaries of these body parts universal, guided by proposed universals of object recognition? (ii) How can we compare the extensional meanings of body part terms within and across different systems of nomenclature? Consultants receive booklets with line drawings of a body and are asked to colour in specific parts of the body...|$|E
40|$|Although name-bindings are {{ubiquitous}} in computer science, they are well-known to be cumbersome to encode and reason about in logic and type theory. There are many proposed solutions {{to this problem}} in the literature, {{but most of these}} proposals, however, have been <b>extensional,</b> <b>meaning</b> they are defined in terms of other concepts in the theory. This makes it difficult to apply these pro-posals in intensional theories like the Calculus of Inductive Con-structions, or CIC. In this paper, we introduce an approach to encoding name-bindings that is intensional, as it attempts to capture the meaning of a name-binding in itself. This approach combines in a straightfor-ward manner with CIC to form the Calculus of Nominal Inductive Constructions, or CNIC. CNIC supports induction over data con-taining bindings, comparing of names for equality, and associating meta-language types with names in a fashion similar to HOAS, fea-tures which have been shown difficult to support in practice. 1...|$|E
40|$|Biproduct dagger {{categories}} {{serve as}} models for natural language. In particular, the biproduct dagger category of finite dimensional vector spaces over the field of real numbers accommodates both the extensional models of predicate calculus and the intensional models of quantum logic. The morphisms representing the <b>extensional</b> <b>meanings</b> of a grammatical string are translated to morphisms representing the intensional meanings such that truth is preserved. Pregroup grammars serve as the tool that transforms a grammatical string into a morphism. The chosen linguistic examples concern negation, relative noun phrases, comprehension and quantifiers...|$|R
40|$|The {{domain of}} the human body is an ideal focus for {{semantic}} typology, since the body is a physical universal and all languages have terms referring to its parts. Previous research on body part terms has depended on secondary sources (e. g. dictionaries), and has lacked sufficient detail or clarity for a thorough understanding of these terms’ semantics. The present special issue is the outcome of a collaborative project aimed at improving approaches to investigating the semantics of body part terms, by developing materials to elicit information that provides for cross-linguistic comparison. The articles in this volume are original fieldwork-based descriptions of terminology for parts of the body in ten languages. Also included are an elicitation guide and experimental protocol used in gathering data. The contributions provide inventories of body part terms in each language, with analysis of both intensional and <b>extensional</b> aspects of <b>meaning,</b> differences in morphological complexity, semantic relations among terms, and discussion of partonomic structure within the domain...|$|R
40|$|In this dissertation, I {{explore the}} work of Donald Davidson, reveal an {{inconsistency}} in it, and resolve that inconsistency {{in a way that}} complements a debate in philosophy of science. In Part One, I explicate Davidson's extensional account of meaning; though not defending Davidson from all objections, I nonetheless present his seemingly disparate views as a coherent whole. In Part Two, I explicate Davidson's views on the dualism between conceptual schemes and empirical content, isolating four seemingly different arguments that Davidson makes against the dualism; I demonstrate that, though the arguments fail, each is ultimately meant to rely on his account of meaning.;In Part Three, I show that Davidson's <b>extensional</b> account of <b>meaning</b> gives rise to the analytic-synthetic distinction, while simultaneously needing to reject it. I then propose a resolution to Davidson's dilemma. Rather than treating interpretation of meaning as continuous with the holistic enterprise of science, as Quine treats translation, one should treat it as conceptually prior to science, as Kant treats epistemology. Nonetheless I recognize four reasons why Davidson himself would reject doing so. I therefore propose a view called 'transcendental semantics', based on Davidson's, that accepts my resolution. Further, transcendental semantics, like Kant's own transcendental idealism, posits a single conceptual scheme; nonetheless Kant's is concerned with Newtonian physics, transcendental semantics' with interpretation.;Finally, in Part Four, I show how positing such a scheme allows transcendental semantics to complement a promising neo-Carnapian account of theory confirmation in science proposed by Michael Friedman. Scientists are first and foremost interpreters, a fact that allows transcendental semantics to help Friedman establish the possibility of rational continuity through scientific revolutions. In fact, transcendental semantics, by complementing Friedman's project, reunites two of Carnap's own concerns, philosophy of language and philosophy of science. I conclude that philosophy of language without philosophy of science is empty, while philosophy of science without philosophy of language is blin...|$|R
40|$|A basic {{technique}} for designing curved shapes {{in the plane}} is interpolating splines. The designer inputs a sequence of control points, and the computer fits a smooth curve that goes through these points. The literature of interpolating splines is rich, much of it based on the mathematical idealization of a thin elastic strip constrained {{to pass through the}} points. Until now there is little consensus on which, if any, of these splines is ideal. This thesis explores the properties of an ideal interpolating spline. The most important property is fairness, a property often in tension with locality, meaning that perturbations to the input points do not affect sections of the curve at a distance. The idealized elastic strip has two serious problems. A sequence of co-circular input points results in a curve deviating from a circular arc. For some other inputs, no solution (with finite extent) exists at all. The idealized elastic strip has two properties worth preserving. First, any ideal spline must be <b>extensional,</b> <b>meaning</b> that the insertion of a new point on the curve shouldn't change its shape. Second, curve segments between any two adjacent control points are drawn from a two-parameter family (and this property is closely related to good locality properties). A central result of this thesis is that any spline sharing these properties also has the property that all segments between two control points are cut from a single, fixed generating curve. Thus, the problem of choosing an ideal spline isreduced to that of choosing the ideal generating curve. The Euler spiral has excellent all-around properties, and, for some applications, a log-aesthetic curve may be even better. Shapes in applications, such as font outlines, contain extra features such as corners and transitions between straight lines and smooth curves. Attaching additional constraints to control points expresses these features, and, carefully applied, give the designer a richer palette of curve types. The splines presented in this thesis are entirely practical as well, especially for designing fonts. Sophisticated new numerical techniques compute the splines at interactive speeds, as well as convert to optimized cubic Bézier representation...|$|E
40|$|In {{this book}} I {{have tried to}} develop an {{analysis}} of the concept of an empirical law, an analysis that differs in many ways from the alternative analyse's found in contemporary literature dealing with the subject. 1 am referring especially to two well-known views, viz. the regularity and necessity views, which have given rise to many interesting papers and books within the philosophy of science. In developing my own views, it very soon became clear to me that the mere restatement of these alternative views, followed by a discussion of their defects and an explanation of my own view, would not suffice to show what 1 regard as basically unsound in these views. If we seriously consider the well-known difficulties facing the regularity view, we have to consider the possibility that the time has arrived to stop our attempts to solve, by means of patch-work additions, the fundamental problem of empirical laws within the traditional context of logical positivist doctrines. I have tried to find a solution which is based on a different philosophical context, the main incentive being that the discouraging results of the customary attempts to solve the problem might have been the outcome of the fundamental philosophical setting within which the problem had been formulated and within which everyone looked for a solution. The problem of empirical laws is not a problem existing by its own rights - it is shaped by an underlying point of view or theoretical framework. For this reason I have started with a brief sketch of the logical positivist context. However, I want to stress the fact that my intention was not to offer an historical exposition, but an exposition which becomes meaningful when related to the subsequent arguments concerning empirical laws. The notion of direct or theory-free observation has been taken as the fundamental characteristic of the logical positivist point of view. This view has been further characterised by means of five theses, among which is the thesis that observational terms are isolated or theory-independent units of <b>extensional</b> <b>meaning.</b> These terms are then supposed to be the starting-points of meaning and the end-points of confirmation, and these very characteristics mark the privileged position such terms have in a logical positivist philosophy. The post-positivist view, on the other hand, is characterised by the opposing notion of theory-loaded observation. This notion leads to other conclusions which radically oppose some of the theses of logical positivism. The notion of theory- loaded observation itself, although often clearly stated, has not yet been systematically elucidated, and I have made an attempt to do this in ch. I after my sketch of the logical positivist context. This {{seemed to me to be}} necessary in order to make my post-positivist point of view as clear as possible, before tackling the problem of empirical law itself. I have paid special attention to the lawlikeness of concepts and their confirmation and falsification. These epistemological issues are followed by a separate examination of Goodman's riddle in ch. II, because it lies somewhere between the lawlikeness of concepts and the lawlikeness of laws. If Goodman's riddle is taken as a serious problem, as I think it should, it is primarily a problem of concept or theory formation and not a problem of induction. In ch. III the regularity view has been examined and the well-known difficulties related to such a view are considered, assuming the knowledge gained in ch. I. This has led to some interesting results, especially in connection with the analysis of counterfactuals and the confirmation of 'normal' singular conditionals, to which I return in the last chapter. Three different views of the necessity view are briefly stated and investigated in ch. IV. RESCHER'S view is, I think, close to mine, which has been developed in ch. V. However, there are fundamental epistemological differences between our views. In the last chapter I have given my own analysis of the concept of an empirical law, which should not be taken as a synthesis of a regularity and a necessity view, but as opposed to both. It is, as far as particulars may count, the result of {{an analysis of the}} concepts 'regularity' and 'necessity'. I have tried to argue that the greatest shortcoming of the regularity view lies in the fact that the proponents of such a view have not been really concerned with the concept of 'regularity' itself. They usually take this concept to be intuitively clear enough to serve as basis for their analysis. Their attacks upon the necessity view are based on the reproach that 'necessity' is a very obscure concept, and that it should, therefore, be avoided in the philosophy of science. We could, however, reproach them in a similar way, since the concept of 'regularity' is anything but clear. One may say that an empirical law formulates a 'regularity in nature', but we can only do justice to the function a law has in science, if we are ready to view this regularity as a necessary connection, which does not exist in an observer-independent reality, but in a theoretically co-constituted empirical world. This investigation does not pretend to answer all questions concerning empirical laws. It should, therefore, not be regarded as complete, but neither should the arguments and suggestions be regarded as completely free from ambiguity. Much remains to be done in order to offer a generally acceptable theory and better understanding...|$|E

