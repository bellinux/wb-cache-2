71|19|Public
50|$|Studies {{have shown}} that people with {{acrophobia}} and/or an extreme fear of falling have higher scores of SMD, or space and motion discomfort. These are physical symptoms elicited by visual or <b>kinesthetic</b> <b>information</b> that is inadequate for normal spatial orientation. Space and motion discomfort arises when conflicting information is detected among visual, kinesthetic, and vestibular sensory channels. Evidence has supported the claim that patients with anxiety and SMD rely more heavily on visual cues for postural changes.|$|E
40|$|SummaryNumerous {{studies have}} shown that extra-retinal signals can disambiguate motion {{information}} created by movements of the eye or head [1]. We report a new form of cross-modal sensory integration in which the <b>kinesthetic</b> <b>information</b> generated by active hand movements essentially captures ambiguous visual motion information. Several previous {{studies have shown}} that active movement can bias observers' percepts of bi-stable stimuli [2, 3]; however, these effects seem to be best explained by attentional mechanisms [4]. We show that <b>kinesthetic</b> <b>information</b> can change an otherwise stable perception of motion, providing evidence of genuine fusion between visual and <b>kinesthetic</b> <b>information.</b> The experiments take advantage of the aperture problem [5], in which the motion of a one-dimensional grating pattern behind an aperture, while geometrically ambiguous, appears to move stably in the grating normal direction. When actively moving the pattern, however, the observer sees the motion to be in the hand movement direction...|$|E
40|$|We {{reviewed}} {{the literature on}} the peripheral sources of <b>kinesthetic</b> <b>information</b> and some relevant sensorimotor functions in the central nervous system. Human movement is thought to be controlled by a hybrid control system consisting of closed-loop and openloop control mechanisms, in reference to <b>kinesthetic</b> <b>information</b> available from various sensory receptors. <b>Kinesthetic</b> <b>information</b> about limb position and movement is believed to be available primarily from muscle and tendon receptors, with cutaneous and joint receptors supplementarily subserving to sense limb position and movement. On receiving kinesthetic signals available from sensory receptors, spinal segmental mechanisms are responsible for either facilitating or inhibiting the activity of the motoneurones of agonist and antagonist muscles used in limb movements. These facilitatory and inhibitory actions in the spinal segmental systems can be examined by measuring the H-reflex (Hoffmann, 1918), with several careful considerations being needed when using the H-reflex technique. Sensory information is sent to the central nervous system via spinal ascending pathways, and is processed in cortical and subcortical sensorimotor systems. The cortical and subcortical systems make movement plans and prepare motor commands to be sent to the spinal segmental systems. The cortical motor system is believed to send a copy of the motor commands (efference copy), in advance of the planned movement to be actually executed, to cortical sensory areas as well. This efference copy sent to the sensory areas is thought to subserve to effectively evaluate the <b>kinesthetic</b> <b>information</b> available, via spinal pathways, from the execution of the movement. Various human movements, such as limb joint movements, are thus executed with various sensorimotor neural network systems being activated. To further understand the mechanisms underlying human movement we should fully take into account the various neural levels of sensorimotor functions in relation to the specific neural and behavioural conditions of the movement to be examined...|$|E
40|$|This paper {{deals with}} the {{development}} of a multisensory virtual environment with visual, haptic, and aural feedbacks for simulating the five-axis CNC milling process. The paper focuses on the haptic and au-ral rendering of the virtual milling process. Haptic rendering provides the user with <b>kinesthetic</b> and tactile <b>information.</b> <b>Kinesthetic</b> informa-tion is displayed by the cutting force of a milling machine. The tactile information is conveyed by the haptic texturing. Aural rendering sim-ulates the machine sound and provides the aural feedback to the user. Using ideas from the concepts of image-based rendering, haptic and aural rendering are accelerated by pre-sampling related environment’s parameters in a perception-dependent way. ...|$|R
40|$|The role of afferent {{information}} in bimanual directional interference was studied {{by means of}} a modulation of the response-produced {{information in}} one of both limbs. In Experiment 1, visual information was either present, withdrawn, or shown with a directional transformation on a LCD screen. In Experiment 2, the technique of muscle tendon vibration was used to bias the <b>kinesthetic</b> afferent <b>information</b> associated with movement. The findings revealed strong evidence for directional interference between both limbs. Nevertheless, no evidence could be advanced that the observed interference from the right onto the left limb movement was modulated by manipulation of the afferent sources of information. It is concluded that directional interference primarily emerges at the efferent level of movement planning and organization. status: publishe...|$|R
40|$|The choreutic {{conception}} of the spatial aspect of body movements (originated by Rudolf Laban) was reevaluated according to cognitive and motor control research. "Kinesthetic spatial cognition" (analogous to visual spatial cognition) was identified as the psychological realm of choreutic knowledge. Kinesthesia was identified as arising from sensory receptors throughout the body. Kinesthetic space was defined as spatial information derived from kinesthesia. Kinesthetic spatial cognition was defined as cognitive processes (eg. mental rehearsal) involving kinesthetic spatial knowledge. This concept of kinesthetic spatial cognition has not been heretofore explicitly developed in cognitive science. Elements of the choreutic conception were psychologically validated since they are also well identified in cognitive and motor research. These include how spatial information is defined relative to a reference system; kinesthetic spatial knowledge {{is based on a}} mental code of elemental locations; higher-order networks of locations are collected into map-like spatial images; and many symmetrical operations can be performed. Close similarities were identified between choreutic polyhedral-shaped cognitive maps of the "kinesphere" and the "trajectory formation" model. A choreutic prototype/deflection hypothesis posits that dimensions and diagonals serve as conceptual prototypes while actual body movement consists of deflections. Similar spatial prototypes were identified in visual spatial cognition, a kinesiological analysis supported the bodily tendency towards deflections, and this concurred with ergonomic measurements of the shape of the workspace. An experiment attempted to identify prototypes in kinesthetic spatial cognition. Categories of <b>kinesthetic</b> spatial <b>information</b> are distinguished within choreutics and dance. These were reevaluated according to perceptual processes and kinesiology. Choreutic topological forms deflecting across various kinespheric nets are analogous to N. Bernstein's {{conception of}} the "co-ordinational net of the motor field [...] . as oscillating like a cobweb in the wind". An experiment demonstrated that <b>kinesthetic</b> spatial <b>information</b> is organised into cognitive categories and that choreutic material and Labanotation symbols can be advantageously used in experimental research...|$|R
40|$|Combination {{of visual}} and <b>kinesthetic</b> <b>information</b> is {{essential}} to perceive bodily movements. We conducted behavioral and {{functional magnetic resonance imaging}} experiments to investigate the neuronal correlates of visuokinesthetic combination in percep-tion of hand movement. Participants experienced illusory flexion movement of their hand elicited by tendon vibration while they viewed video-recorded flexion (congruent: CONG) or extension (incongruent: INCONG) motions of their hand. The amount of illusory experience was graded by the visual velocities only when visual information regarding hand motion was concordant with <b>kinesthetic</b> <b>information</b> (CONG). The left posterolateral cerebellum was specifically recruited under the CONG, and this left cerebellar activation was consistent for both left and right hands. The left cerebellar activity reflected the participants ’ intensity of illusory hand movement under the CONG, and we further showed tha...|$|E
40|$|This paper {{focuses on}} the problem of force-feedback for the human-operator hand when {{manipulating}} virtual objects. We propose a method for the computation of feedback-forces that have to be applied on each individual phalanx and finger of the human hand in order to display pertinent, <b>kinesthetic</b> <b>information</b> about static or dynamic characteristics of objects present in the virtual scene. Externa...|$|E
40|$|In {{everyday}} life, {{spatial navigation}} involving locomotion provides congruent visual, vestibular and <b>kinesthetic</b> <b>information</b> {{that need to}} be integrated. Yet, previous studies on human brain activity during navigation focus on stationary setups, neglecting vestibular and kinesthetic feedback. The aim of our work is to uncover the influence of those sensory modalities on cortical processing. We developed a fully immersive virtual reality setup combined with high-density mobile electroencephalography (EEG). Participants traversed one leg of a triangle, turned on the spot, continued along the second leg and finally indicated the location of their starting position. Vestibular and <b>kinesthetic</b> <b>information</b> was provided either in combination, as isolated sources of information or not at all within a 2 x 2 full factorial intra-subjects design. EEG data were processed by clustering independent components, and time-frequency spectrograms were calculated. In parietal, occipital and temporal clusters, we detected alpha suppression during the turning movement, which is associated with a heightened demand of visuo-attentional processing, and closely resembles results reported in previous stationary studies. This decrease is present in all conditions and therefore seems to generalize to more natural settings. Yet, in incongruent conditions, when different sensory modalities did not match, the decrease is significantly stronger. Additionally, in more anterior areas, we found that providing only vestibular but no <b>kinesthetic</b> <b>information</b> results in alpha increase. These observations demonstrate that stationary experiments omit important aspects of sensory feedback. Therefore, it is important to develop more natural experimental settings in order to capture a more complete picture of neural correlates of spatial navigation...|$|E
40|$|In a {{triangle}} completion task {{designed to assess}} path integration skill, younger and older adults performed similarly after being led, while blindfolded, along the route segments on foot, which provided both <b>kinesthetic</b> and vestibular <b>information</b> about the outbound path. In contrast, older adults’ performance was impaired, relative to that of younger adults, after they were conveyed, while blindfolded, along the route segments in a wheelchair, which limited them principally to vestibular information. Correlational evidence suggested that cognitive resources were significant factors in accounting for age-related decline in path integration performance...|$|R
40|$|The primate dorsal pathway {{has been}} {{proposed}} to compute vision for action. Although recent findings suggest that dorsal pathway structures contribute to somatosensory action control as well, it is yet not clear {{whether or not the}} development of dorsal pathway functions depends on early visual experience. Using functional magnetic resonance imaging, we investigated the pattern of cortical activation in congenitally blind and matched blindfolded sighted adults while performing kinesthetically guided hand move-ments. Congenitally blind adults activated similar dorsal pathway structures as sighted controls. Group-specific activations were found in the extrastriate cortex and the auditory cortex for congenitally blind humans and in the precuneus and the presupplementary motor area for sighted humans. Dorsal pathway activity was in addition observed for working memory maintenance of <b>kinesthetic</b> movement <b>information</b> in both groups. Thus, the results suggest that dorsal pathway functions develop in the absence of vision. This favors the idea of a general mechanism of movement control that operates regardless of the sensory input modality. Group differences in cortical activation patterns imply different movement control strategies as a function of visual experience...|$|R
40|$|The {{effect of}} {{unilateral}} tendon vibration {{on the performance}} of cyclical bimanual forearm movements was investigated across different cycling frequencies (from 0. 67 to 2. 53 Hz). The spatiotemporal features of the individual limb motions as well as their coordination were studied. Tendon vibration was found to result in a substantial reduction in the amplitude of the vibrated arm, leaving the nonvibrated arm unaffected. The vibration-induced amplitude reduction decreased from 26 % to 11 % as cycling frequency increased even though significant reductions were still observed at the highest cycling frequencies. Tendon vibration was also found to result in an increase of the phase lead of the dominant arm with respect to the nondominant arm, but this effect was not modulated by cycling frequency. The data argue in favor of a closed-loop mode of movement control during cyclical high-speed movements. It is suggested that <b>kinesthetic</b> afferent <b>information</b> is processed and used to guide action up to near-maximal movement speeds, reinforcing recent claims with respect to visual information processing. status: publishe...|$|R
40|$|This chapter {{presents}} {{an overview of}} interesting scientific findings related to human haptic perception and discuss the usability of these scientific findings for the design and development of virtual environments including haptic rendering. The first section of the chapter deals with pure haptic perception whereas {{the second and third}} sections are devoted to the integration of <b>kinesthetic</b> <b>information</b> with other sensory inputs like vision and audition...|$|E
40|$|Reaching out for {{objects with}} an unseen arm {{involves}} using both visual and <b>kinesthetic</b> <b>information.</b> Neither visual nor <b>kinesthetic</b> <b>information</b> is perfect. Each {{is subject to}} both constant and variable errors. To evaluate how such errors influence performance in natural goal-directed movements, we asked subjects to align a real 5 -cm cube, which they held in their hand but could not see, with a three-dimensional visual simulation of such a cube. The simulated cube was presented at one of four target locations {{at the corners of}} an imaginary tetraeder. Subjects made successive, self-paced movements between these target locations. They could not see anything except the simulated cube throughout the experiment. Initial analysis of the spatial dispersion of movement endpoints demonstrated that the major source of errors under these conditions was visual. Further analysis of the relationship between variability of the starting positions and endpoints showed that the errors were primarily in judging the endpoint, rather than the direction or amplitude of the required movement vector. The findings support endpoint control of human goal-directed movements...|$|E
40|$|Visual {{judgments}} of distance are often inaccurate. Nevertheless, information on distance must be procured if retinal image size {{is to be}} used to judge an object's dimensions. In the present study, we examined whether <b>kinesthetic</b> <b>information</b> about an object's distance - based on the posture of the arm and hand when holding it - influences the object's perceived size. Subjects were presented with a computer simulation of a cube. This cube's position was coupled to that of a rod in the subject's hand. Its size was varied between presentations. Subjects had to judge whether the cube they saw was larger than, smaller than, or the same size as a reference. On some presentations, a small difference was introduced between the positions of the rod and of the simulated cube. When the simulated cube was slightly closer than the rod, subjects judged the cube to be larger. When it was farther away, they judged it to be smaller. We show that these changes in perceived size are due to alterations in the cube's distance from the subject rather than to <b>kinesthetic</b> <b>information...</b>|$|E
40|$|Reaching for {{a target}} {{involves}} integrative coordinate transformation processes between {{the representation of}} the target location, the sensorimotor information of limb of reach, and body space. Although right hemisphere dominance for visuospatial information processing is well established, corresponding right hemisphere dominance for <b>kinesthetic</b> spatial <b>information</b> processing remains to be demonstrated. We explored neural mechanisms of encoding target locations using 15 O-butanol positron emission tomography (PET) in normal volunteers in a factorial experiment, where modality (visual/kinesthetic) and hemispace of target presentation (left/right of midsagittal plane) were varied systematically. After target presentation, subjects reached to the encoded target location. PET data analysis using SPM 99 showed increased neural activity (P < 0. 05, corrected) associated with left hemispace target presentation in right hemisphere areas (sensorimotor, anterior cingulate, insular, and temporo-occipital cortex) only. By contrast, right hemispace target presentation activated bilateral temporo-occipital cortex, which extended into the right temporo-parietal cortex and left sensorimotor cortex. A significant interaction of hemispace and modality of target presentation observed in right temporo-parietal cortex resulted from an increase in neural activity with kinesthetic target presentation in right hemispace. The data support an important role for the right temporo-parietal area in visuospatial processing and suggest a specific role of the right hemisphere in kinesthetic spatial processing...|$|R
40|$|Figure 1 : Using visual <b>information,</b> <b>kinesthetics</b> and {{biofeedback}} from electromyograms (EMG), {{users can}} grasp, move and drop virtual objects. Virtual Reality environments {{have the ability}} to present users with rich visual representations of simulated environments. However, means to interact with these types of illusions are generally unnat-ural {{in the sense that they}} do not match the methods humans use to grasp and move objects in the physical world. We demonstrate a system that enables users to interact with virtual objects with nat-ural body movements by combining visual information, kinesthet-ics and biofeedback from electromyograms (EMG). Our method allows virtual objects to be grasped, moved and dropped through muscle exertion classification based on physical world masses. We show that users can consistently reproduce these calibrated exer-tions, allowing them to interface with objects in a novel way...|$|R
40|$|Current force feedback, haptic {{interface}} devices are generally {{limited to the}} display of low frequency, high amplitude spatial data. A typical device consists of a low impedance framework {{of one or more}} degrees-of-freedom (dof), allowing a user to explore a pre-defined workspace via an end effector such as a handle, thimble, probe or stylus. The movement of the device is then constrained using high gain positional feedback, thus reducing the apparent dof of the device and conveying the illusion of hard contact to the user. Such devices are, however, limited to a narrow bandwidth of frequencies, typically below 30 Hz, and are not well suited to the display of surface properties, such as object texture. This paper details a device to augment an existing force feedback haptic display with a vibrotactile display, thus providing a means of conveying low amplitude, high frequency spatial information of object surface properties. 1. Haptics and Haptic Interfaces Haptics is the study of human touch and interaction with the external environment via touch. Information from the human sense of touch can be classified in to two categories, cutaneous and <b>kinesthetic.</b> Cutaneous <b>information</b> is provided via the mechanoreceptive nerve endings in the glabrous skin of the human hand. It is primarily a means of relaying information regarding small-scale details in the form of skin stretch, compression and vibration. Kinesthetic sensin...|$|R
40|$|Saccades to {{somatosensory}} targets have longer latencies and {{are less}} accurate and precise than saccades to visual targets. Here we examined how different somatosensory information influences the planning and control of saccadic eye movements. Participants fixated a central cross and initiated a saccade {{as fast as possible}} in response to a tactile stimulus that was presented to either the index or the middle fingertip of their unseen left hand. In a static condition, the hand remained at a target location for the entire block of trials and the stimulus was presented at a fixed time after an auditory tone. Therefore, the target location was derived only from proprioceptive and tactile information. In a moving condition, the hand was first actively moved to the same target location and the stimulus was then presented immediately. Thus, in the moving condition additional <b>kinesthetic</b> <b>information</b> about the target location was available. We found shorter saccade latencies in the moving compared to the static condition, but no differences in accuracy or precision of saccadic endpoints. In a second experiment, we introduced variable delays after the auditory tone (static condition) or {{after the end of the}} hand movement (moving condition) in order to reduce the predictability of the moment of the stimulation and to allow more time to process the <b>kinesthetic</b> <b>information.</b> Again, we found shorter latencies in the moving compared to the static condition but no improvement in saccade accuracy or precision. In a third experiment, we showed that the shorter saccade latencies in the moving condition cannot be explained by the temporal proximity between the relevant event (auditory tone or end of hand movement) and the moment of the stimulation. Our findings suggest that <b>kinesthetic</b> <b>information</b> facilitates planning, but not control, of saccadic eye movements to proprioceptive-tactile targets...|$|E
40|$|Interference between {{location}} and distance information in motor short-term memory has been hypothesized {{on the basis}} of the systematic pattern of undershooting and overshooting in movement reproduction that occurs when the starting position for reproduction movements is shifted. To determine the possible contribution of limb-specific <b>kinesthetic</b> <b>information</b> to this systematic undershooting–overshooting pattern, we compared the reproduction of linear arm positioning movements performed under either same-limb or switched-limb conditions. Ten subjects were assigned to either a location or distance cue condition, and each subject completed a total of 40 trials, 20 under same-limb and 20 under switched-limb conditions. Each trial consisted of criterion and reproduction movements, separated by a 10 -s retention interval. The starting position for the reproduction movement was shifted by 0, 2, or 4 cm in either direction from that of the criterion movement. The systematic undershooting–overshooting pattern, which occurs when either the movement location or distance is reproduced, arose under both the same-limb and switched-limb conditions, suggesting that the primary cause of the location-distance interference is not limb-specific <b>kinesthetic</b> <b>information.</b> Rather, more abstract information in the form of a conceptual memory code appears to be the probable cause of the locationdistance interference phenomenon...|$|E
40|$|Two {{experiments}} {{were conducted to}} investigate the role of internal information. The path completion task revealed that internal (vestibular and <b>kinesthetic)</b> <b>information</b> facilitates {{the accuracy of the}} homing direction, especially when the number of turns increases. The spatial learning task revealed that the information enhances learning relative locations of points in the path when tracing back on the path is needed to estimate directions. It was concluded that internal information would contribute to forming survey knowledge by providing the homing directions through path integration...|$|E
40|$|This is {{a survey}} of {{research}} issues for haptic and locomotion interfaces. A key issue is the workspace and dexterity of haptic devices. In the simulation of real environments, interactive geometric computations on complex models are a fundamental problem. Haptic rendering of forces of contact are increasingly based on measurements on real environments. Scientific visualization is another promising area for haptic interfaces, but {{the issue of how}} to usefully display data haptically needs to be worked out. Locomotion rendering issues include the display of inertial forces, slope, unilateral constraints, and turning. Examples of approaches to these issues are presented. 1 Introduction Haptic interfaces are robots that provide information to people by manipulating them. The information is a reflection of sensed forces by a remotely controlled slave robot or by a computer simulation. This <b>kinesthetic</b> or tactual <b>information</b> is a compliment to visual or auditory perception, in order to buil [...] ...|$|R
40|$|While it {{is known}} that {{softness}} discrimination relies on both <b>kinesthetic</b> and cutaneous <b>information,</b> relatively little work has been done on the realization of haptic devices replicating the two cues in an integrated and effective way. In this paper, we first discuss the ambiguities that arise in unimodal touch, and provide a simple intuitive explanation in terms of basic contact mechanics. With this as a motivation, we discuss the implementation and control of an integrated device, where a conventional kinesthetic haptic display is combined with a cutaneous softness display. We investigate the effectiveness of the integrated display via a number of psychophysical tests and compare the subjective perception of softness with that obtained by direct touch on physical objects. Results show that the subjects interacting with the integrated haptic display are able to discriminate softness better than with either a purely kinesthetic or a purely cutaneous display...|$|R
40|$|Global society {{requires}} {{acceleration and}} diversification of ways data’s transmission, erasing {{the boundaries between}} people and nations. However, there always will be a certain sign that distinguishes one ethnic group among others. Ethno­cultural specificity is kept and transmitted by various means. Cuisine {{as one of the}} most important everyday realities is also transmitting ethnic and cultural meanings. Moreover, each dish is a kind of special semiotic text content. Are there reasons that motivate each of us to choose the dishes? Do our choices genetically depend on our ancestors? Or just have a set of personal culinary preferences? The national dish is one of the cultural and historical features. Every national cuisine established concepts that have appeared in the process of communication. Borsch is such a concept and the ethnic mark for Ukrainians at the same time. Cooking and eating is a synthetic type of communication that produces transmission and perception of <b>information</b> <b>kinesthetic,</b> auditory and visual methods. Except the usual everyday dishes there are festive that are becoming solemn, not average...|$|R
40|$|The aim of {{this study}} is to {{determine}} whether the eye position shift changes perceived distance, that is, whether <b>kinesthetic</b> <b>information</b> from eye muscles affects distance perception. Two experiments were done, in a dark room (reduced-cue situation), with 27 participants, psychology undergraduates. Participants had a task to match distances of three stimuli, on three viewing directions, 0, 30 and 60 deg rees relative to the body. Head and body of participants were fixed, and they changed viewing directions only by moving their eyes. Stimuli were 7 c...|$|E
40|$|The {{brain is}} able to {{determine}} angular self-motion from visual, vestibular, and <b>kinesthetic</b> <b>information.</b> There is compelling evidence that both humans and non-human primates integrate visual and inertial (i. e., vestibular and <b>kinesthetic)</b> <b>information</b> in a statistically optimal fashion when discriminating heading direction. In the present study, we investigated whether the brain also integrates information about angular self-motion in a similar manner. Eight participants performed a 2 IFC task in which they discriminated yaw-rotations (2 -s sinusoidal acceleration) on peak velocity. Just-noticeable differences (JNDs) were determined {{as a measure of}} precision in unimodal inertial-only and visual-only trials, as well as in bimodal visual-inertial trials. The visual stimulus was a moving stripe pattern, synchronized with the inertial motion. Peak velocity of comparison stimuli was varied relative to the standard stimulus. Individual analyses showed that data of three participants showed an increase in bimodal precision, consistent with the optimal integration model; while data from the other participants did not conform to maximum-likelihood integration schemes. We suggest that either the sensory cues were not perceived as congruent, that integration might be achieved with fixed weights, or that estimates of visual precision obtained from non-moving observers do not accurately reflect visual precision during self-motion. © 2013 Springer-Verlag Berlin Heidelberg...|$|E
40|$|This study {{deals with}} the {{following}} questions: (1) How precisely are movement properties matched for the two arms? (2) Is matching of movements of the two arms affected by visual information? (3) Are movements of one arm affected by <b>kinesthetic</b> <b>information</b> arising from the contralateral arm? (4) Does alteration in the motor performance of one arm affect movement performance in the other arm?;During experiments, subjects grasped a vertical rod attached to a horizontal manipulandum bar. The subject 2 ̆ 7 s shoulder was abducted to 90 deg. The manipulandum bar was pivoted above the subject 2 ̆ 7 s elbow. Subjects made step-tracking flexion/extension movements about the elbow. Both simultaneously and independently made movements of the two arms, performed at the subject 2 ̆ 7 s own speed, were studied.;During simultaneous arm movements, movements of the two arms were initiated at the same times. The degree of matching of movement parameters was dependent on visual information. In the absence of visual information, these parameters were exactly matched in simultaneous movements of the two arms. When visual information was provided by displaying the position of right or left arm to the subject, {{the movements of the}} 2 ̆ 2 non-displayed 2 ̆ 2 arm were consistently of greater amplitudes and velocities than those of the 2 ̆ 2 displayed 2 ̆ 2 arm. The relation between movement peak velocity and amplitude was linear for each arm and was the same (matched) for both arms under all visual conditions. This matching was also seen for the independently made movements.;In some experiments the left arm was loaded. Loading altered the slope of the peak velocity-amplitude relation in movements of the left arm. Similar changes occurred in the velocity-amplitude relation of the right (non-loaded) arm.;To test interlimb responses to <b>kinesthetic</b> <b>information,</b> high frequency (120 Hz) mechanical vibration of muscle tendons was used to stimulate muscle spindles of the elbow movers. Vibration of the triceps muscle of one arm produced overshooting of the intended flexion end-position by the opposite arm.;It is concluded that the motor actions of the two arms are functionally linked. Matching of movements made by the two arms may reflect the operation of a common motor program which can be modified by visual and <b>kinesthetic</b> <b>information...</b>|$|E
40|$|With {{reference}} to Regional research case study ─ I：Targeting Seniors and Regional research case study─Ⅱ：Targeting Children. The effects of physical exercise through sports were analyzed. In research case study I, seniors who incorporated physical exercise into their lifestyle routines {{were instructed to}} exercise for 90 minutes/day. As a result there was an improvement in the distance {{of change in the}} center of balance when standing（an index for physical stability）；that is, an increase in the static equilibrium function. These improvements are an indication of improved reaction and increased muscular strength. In other words, the subjects’ standing posture improved as a result of physical exercise, and the subjects were able to “stand more firmly. ” In this way, we have discovered the value of “health” which everyone desires. 　Meanwhile, in the case of children with outstanding flexibility, children with strong athletic performance in one-leg-standing, hopping, and repetitive side jumping were seen as having a shorter distance of change in the center of balance when standing. This suggests that in children with a strong ability to stand on one foot {{for a long time and}} children with strong dynamic balance capabilities, physical exercise developed neuromuscular functions, and promoted stretch reactions when standing, <b>kinesthetic</b> sense <b>information,</b> and calf triceps muscle functions. This is expected to tie into a strong awareness of posture education, in terms of “standing firmly. ” At the same time, we believe that the subjects came one step closer to the value of“ physical strength” in the context of growth and development. One method for increasing health and physical strength among seniors and children can be summarized as follows: １．A guide who is familiar with the subjects is present ２．A manager who works for everyone’s benefit is present ３．There is a place where everyone can come together in an environment that is like a clu...|$|R
40|$|Acquired alexia is {{a reading}} {{disorder}} caused by neurological damage {{and is usually}} the result of small, left-hemisphere, inferior parietal lobe lesions involving the angular gyrus. It {{is often associated with}} aphasia and there appears to be some relationship between the severity and nature of aphasic auditory comprehension problems and the severity and nature of alexia. The variables effecting comprehension include word frequency, part of speech, emotionality, personal relevancy, syntactic complexity and length and degree of inference required for interpretation. Individuals with acquired alexia can be classified into four groups: deep alexia, surface alexia, phonological alexia and pure alexia. Error patterns, as they relate to semantics, orthographic length and word frequency distinguish the types of acquired alexia. Some have suggested that phonological alexia is on the continuum of deep alexia (Friedman 1). Several approaches have been implemented to facilitate rehabilitation of reading skills. The Multiple Oral Reading (MOR) approach utilized repetition of oral reading to facilitate whole word recognition (Beeson 2) whereas the Cross Modality Cueing approach combined <b>kinesthetic</b> and visual <b>information</b> to access the lexicon (Seki 3). The Brief Exposure approach appealed to implicit learning suggesting that even brief exposure to words resulted in a degree of wor...|$|R
40|$|Can {{instructors}} impact {{their student}} performance by recommending an activity {{just prior to}} taking an exam? In this study, college ollege students {{were randomly assigned to}} one of three treatment groups (study, exercise, or meditation) or a control group. Each group was given two different types of tests; a traditional concept exam, and a non non-traditional hands-on on exam designed to test mastery of computer applications. A multiple analysis of covariance (MANCOVA) was conducted. Although the same pattern is seen in both the IT Concepts exam and the Hands-On Computer Application exam, significance was only ly reached in the latter. The study group performed about the same as the control group. The exercise group performed much worse. The meditation group did better than any other group in the study. The authors conclude that prior prior-to-exam activity may be a strong influence in exam performance, especially when the exam is testing a combination of <b>kinesthetic</b> and cognitive <b>information</b> such as that needed for hands-on on computer application exams. Further research is needed to determine the parameters for the scope pe of activities that influence performance...|$|R
40|$|International audienceThis study {{aimed at}} {{supporting}} {{the specificity of}} learning hypothesis, when aiming was based on internal cues, as directing the hand toward a "self-defined" target location. Participants practiced modest (20 trials) or intensive (720 trials) training with visual and proprioceptive information or proprioceptive information only. Pretests and posttests were performed in sensory conditions that {{did or did not}} match the training condition. Results showed that dynamic visual cues played a dominant role {{at the beginning of the}} task, and an intensive practice resulted in increased accuracy of <b>kinesthetic</b> <b>information</b> and efferent mechanisms of motor responses. These results have implications with regard to motor learning conceptions and training as a function of the task constraints...|$|E
40|$|Abstract This paper {{presents}} a new miniature haptic display to convey ample haptic {{information to a}} user of a handheld interface. There are buttons on interfaces or general electronic devices, but existing buttons provide haptic feedback of only one passive pattern to a user. Because humans perceive tactile and <b>kinesthetic</b> <b>information</b> simultaneously when they handle objects the proposed actuator provides both sensations at once. It is able to generate various levels of kinesthetic sensations when pressing a button under diverse situations. Also, vibrotactile feedback can be delivered for exciting haptic effects with numerous patterns. Its performance was evaluated {{in accordance with the}} resistive force by changing the intensity of the input current. Experiments show that the proposed actuator ha...|$|E
40|$|Human {{beings are}} superbly moving animals. Sensing limb {{movements}} or limb position is essential when we precisely control our limb movements. Indeed, it is diffi-cult for deafferented experimental animals or human patients lacking proprioceptive inputs to perform normal multijoint limb movements {{even though it}} is true that they can initiate limb movements (Bard and others 1995; Ghez and Sainburg 1995; Sainburg and others 1995). These evidences indicate that sensory afferent inputs conveying kinesthetic or proprioceptive information to the brain are important for the brain to archive precise and elaborate control of limb movements. Furthermore, it also might be true that the kinesthetic feedback information during limb movements plays cru-cial roles when we acquire a motor skill. For example, healthy subjects can rotate two balls simultaneously on their palms (Kawashima and others 1998). When they try to rotate the balls as many times as possible within a restricted period (for 30 seconds) in one trial, the num-ber of rotations significantly increases trial by trial. This skill improvement can be observed even in a situation in which subjects rotate the balls with their eyes closed. In this situation, because visual information of hand move-ments or ball movements is completely eliminated dur-ing the performance, <b>kinesthetic</b> <b>information</b> is the only available feedback information from the complex hand/finger movements. Thus, we may speculate that the kinesthetic feedback information updates motor pro-grams so as to improve the motor performance trial by trial. The idea that <b>kinesthetic</b> <b>information</b> during limb movements plays crucial roles when we acquire a motor skill was supported {{by the fact that the}} deafferented patients showed a difficulty in acquiring new motor skills (Gordon and others 1995) ...|$|E
40|$|Marshall McLuhan’s {{assertion}} that the “medium is the message,” coupled with his understanding of media as holding transformative power, yields {{an understanding of the}} increasing significance of multimodal communication and new technologies. Modes of representation and communication have shifted from the audio or visual experience to inherently multimodal. Gunther Kress and Theo van Leeuwen assert that “language and multimedia [are] moving towards multimodal communication. ” My dissertation addresses the question of how meaning is created within each medium and ways in which each mode contributes to the overall meaning-making potential. While the visual, verbal, and <b>kinesthetic</b> modes present <b>information</b> differently, they all work together to formulate a “multimodal ensemble”; I examine multimodal ensembles across the media of film, graphic narratives, and commercials. In my conclusions, I will apply multimodal communication to pedagogical practices in order to adapt to the changes in and evolution of literacies. My research draws from multiple disciplines including literary theory, film studies, pedagogy, multimodal discourse analysis, communications and semiotics, proving that the message/meaning is driven by the 2 ̆ 2 complexity of interaction, representation, and communication” (Jewitt 1). Finally, I conclude that multimodal literacy needs to be connected to the multimodal aesthetic experience across cultural, social, and historical landscapes...|$|R
40|$|We {{address the}} problem of whether and how {{adaptation}} to suppression of visual information occurs in catching behavior. To this end, subjects were provided with advance information about the height of fall and the mass of a ball and an auditory cue signaled the time of release. Adaptation did occur, as indicated by the unimpaired ability to catch the ball without vision; however, it involved a major reorganization of the muscle responses. The subjects were unable to produce anticipatory activity consistently, but preset the responses elicited by the impact. These responses were more complex and prolonged than those observed in the control experiments (with vision). In particular, medium- and long-latency responses were much larger, and the changes in elbow, wrist, and metacarpophalangeal angles following impact were more oscillatory than in the control. The general pattern of the EMG responses switched from that characteristic of catching with vision to that characteristic of catching without vision from the first trial of each experiment. However, the responses produced without vision were calibrated adaptively in the course of an experiment. In fact, the limb oscillations induced by the impact were significantly larger in the first trial than in the following trials. This seems to suggest that the parameters of the responses are adjusted based on an internal model of the dynamic interaction between the falling ball and the limb. This model is initially constructed from a priori knowledge on impact parameters and is subsequently updated {{on the basis of the}} <b>kinesthetic</b> and cutaneous <b>information</b> obtained during the first trial...|$|R
40|$|The {{primary goal}} {{of the present study}} was to {{investigate}} the efficacy of a multisensory reading approach (Lindamood Phoneme Sequencing Program) for the treatment of clients diagnosed with acquired alexia. All three participants improved their decoding skills as an effect of the LiPS program but with distinguishable characteristics believed to relate to their type of acquired alexia. The participant with surface alexia demonstrated the greatest learning curve as compared to the participants with deep or phonological alexia. All three participants showed a positive effect on cognitive-communicative abilities other than reading. Findings will be related to the connectionist approach to reading. Full Text Acquired alexia is a reading disorder caused by neurological damage and is usually the result of small, left-hemisphere, inferior parietal lobe lesions involving the angular gyrus. It is often associated with aphasia and there appears to be some relationship between the severity and nature of aphasic auditory comprehension problems and the severity and nature of alexia. The variables effecting comprehension include word frequency, part of speech, emotionality, personal relevancy, syntactic complexity and length and degree of inference required for interpretation. Individuals with acquired alexia can be classified into four groups: deep alexia, surface alexia, phonological alexia and pure alexia. Error patterns, as they relate to semantics, orthographic length and word frequency distinguish the types of acquired alexia. Some have suggested that phonological alexia is on the continuum of deep alexia (Friedman 1). Several approaches have been implemented to facilitate rehabilitation of reading skills. The Multiple Oral Reading (MOR) approach utilized repetition of oral reading to facilitate whole word recognition (Beeson 2) whereas the Cross Modality Cueing approach combined <b>kinesthetic</b> and visual <b>information</b> to access the lexicon (Seki 3). The Brief Exposure approach appealed to implicit learning suggesting that even brief exposure to words resulted in a degree of word recognition (Rothi and Moss 4). In contrast to the whole word approach, some approaches have sought to strengthen the grapheme to phoneme conversion. Such approaches included the keyword approach as reported by Hillis and Caramazza 5 and the Cued Oral Reading by Hillis an...|$|R
