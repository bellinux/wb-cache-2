25|10000|Public
5000|$|Visitor {{separates}} an algorithm from {{an object}} structure {{by moving the}} <b>hierarchy</b> <b>of</b> <b>methods</b> into one object.|$|E
50|$|The ECJ's {{judgment}} was essentially that no <b>hierarchy</b> <b>of</b> <b>methods</b> of service {{existed between the}} different methods of service allowed under the regulation, and that the time limit must logically run from the first date of service regardless of which method has been employed.|$|E
40|$|Recent {{progress}} in computational vortex flow aerodynamics at the Langley Research Center is reviewed. Emphasis {{is placed on}} Navier-Stokes methodology, both for compressible and incompressible flows, and results are presented from central and upwind-biased schemes for fully laminar, transitional, and fully turbulent flows. In addition, results are presented from selected potential-based methods to address the hierarchy of formulations presently available for the computational analysis of aerodynamic vortex flows. Some comparisons among this <b>hierarchy</b> <b>of</b> <b>methods</b> are shown...|$|E
50|$|During World War II, a {{considerable}} amount of training materials for the military were developed based on the principles of instruction, learning, and human behavior. Tests for assessing a learner’s abilities were used to screen candidates for the training programs. After the success of military training, psychologists began to view training as a system, and developed various analysis, design, and evaluation procedures. In 1946, Edgar Dale outlined a <b>hierarchy</b> <b>of</b> instructional <b>methods,</b> organized intuitively by their concreteness.|$|R
40|$|The {{strength}} of shock-loaded single crystal tantalum [100] has been experimentally determined using in situ broadband x-ray Laue diffraction {{to measure the}} strain state of the compressed crystal, and elastic constants calculated from first principles. The inferred strength reaches 35  GPa at a shock pressure of 181  GPa and is in excellent agreement with a multiscale strength model [N. [*]R. Barton et al., J. Appl. Phys. 109, 073501 (2011) ], which employs a <b>hierarchy</b> <b>of</b> simulation <b>methods</b> over a range of length scales to calculate strength from first principles...|$|R
40|$|The article {{considers}} {{the problem of}} determining the optimality criterion in the synthesis of transport routes in flexible manufacturing systems, using a genetic algorithm, reduced to the travelling salesman problem. The problem {{is regarded as a}} multi-criteria, since the solution may have multiple criteria, such as route length, travel time, cost, etc. Review <b>of</b> <b>methods</b> for solving multi-objective problems, like a <b>method</b> <b>of</b> evaluating and ranking, <b>method</b> <b>of</b> analysis <b>of</b> <b>hierarchies</b> and <b>method</b> <b>of</b> validation into super-criteria. Determine their strengths and weaknesses, as well as an analysis of the feasibility <b>of</b> using each <b>method</b> to determine the optimality criterion in a specific task. As a result, on the basis of studies concluded that in article, the most expedient method is to use validation into super-criteria because it lets you to define a numerical evaluation of alternatives, without creating additional criteria. ? ?????? ??????????????? ???????? ??????????? ???????? ????????????? ? ?????? ??????? ???????????? ????????? ???, ??? ?????? ????????????? ?????????, ????????? ? ?????? ????????????. ?????? ??????????????? ??? ??????????????????, ??? ??? ??????? ????? ????? ????????? ?????????, ????? ??? ?????? ????????, ????? ???????????, ????????? ? ??. ??????????????? ?????? ??????? ?????????????????? ?????, ? ?????? ????? ?????? ? ????????????, ????? ??????? ???????? ? ????? ?????? ? ?????????????. ???????????? ?? ???????????? ? ??????????, ? ????? ?????????? ?????? ???????????????? ????????????? ??????? ?????? ??? ??????????? ???????? ????????????? ? ?????????? ??????. ? ??????????, ?? ???? ??????????? ???????????? ???????? ?????, ??? ?? ?????? ?? ??????? ????????, ???????? ?????????????? ???????? ????????????? ?????? ??????? ? ?????????????, ??? ??? ?? ????????? ?????????? ???????? ?????? ????????????, ??? ???????? ?????????????? ?????????...|$|R
40|$|This article {{responds}} to Graham-Rowe et al. (2011), which categorised 77 evaluations of transport interventions into 5 levels of ‘quality’. This {{article focuses on}} Graham-Rowe et al. ’s treatment of randomised controlled trials (RCTs) and their recommendation, also made by others, that RCTs should be used ‘wherever possible’ in transport research. It analyses the RCTs reviewed by Graham-Rowe et al. and the hierarchy of research methods they use. It proposes 5 criteria for the valid application of RCTs, which it argues would imply that the circumstances in transport studies where RCTs are demonstrably superior to other methods are very limited. It finds no valid justification for a <b>hierarchy</b> <b>of</b> <b>methods</b> and argues that attempting to apply such a hierarchy would generate misleading advice for policy makers...|$|E
40|$|Accepted [...] . Received [...] .; in {{original}} form [...] . A number of space missions {{dedicated to the}} search for exo-planets via the transit method, such as COROT, Eddington and Kepler, are planned for launch over the next few years. They will need to address problems associated with the automated and efficient detection of planetary transits in light curves affected by a variety of noise sources, including stellar variability. To maximise the scientific return of these missions, it is important to develop and test appropriate algorithms in advance of their launch dates. Starting from a general purpose maximum likelihood approach we discuss the links between a variety of period and transit finding methods. The natural endpoint of this <b>hierarchy</b> <b>of</b> <b>methods</b> is shown to be a fast, robust and statistically efficient least-squares algorithm based on box-shaped transits. This approach is predicated on the assumption of periodic transits hidden in random noise, usually assumed to be superposed on a flat continuum with regula...|$|E
40|$|Efficiently {{updating}} an SVD-based {{data representation}} while keeping accurate {{track of the}} data mean when new observations are coming in is a common objective in many practical application scenarios. In this paper, two different SVD update algorithms capable of treating an arbitrary number of new observations are introduced following the symmetric EVD philosophy. These methods are compared to an SVD update method known from the literature. The comparison criterion of interest is the theoretical computational complexity, it being understood that the dimension of the observation vectors is {{much larger than the}} number of observations. From this point of view, a <b>hierarchy</b> <b>of</b> <b>methods</b> is derived, and the computational savings of the update strategies pursuing the symmetric EVD approach are demonstrated. It is exposed, how the compression level of the initial SVD model affects the performance of these algorithms and the break point where one method becomes more efficent than the other is determined. In addition, simple rules of thumb are derived for easing the choice of an algorithm valid in most practical scenarios...|$|E
40|$|Electron {{transport}} {{in model}} Si nanotransistors is examined by numerical simulation using a <b>hierarchy</b> <b>of</b> simulation <b>methods,</b> from full Boltzmann, to hydrodynamic, energy transport, and drift-diffusion. The on-current of a MOSFET {{is shown to}} be limited by transport across a low-field region about one mean-free-path long and located {{at the beginning of}} the channel. Commonly used transport models based on simplified solutions of the Boltzmann equation are shown to fail under such conditions. The cause for this failure is related to the neglect of the carriers' drift energy and to the collision-dominated assumptions typically used in the development of simplified transport models...|$|R
40|$|International audienceIn this paper, we {{construct}} a <b>hierarchy</b> <b>of</b> hybrid numerical <b>methods</b> for multi-scale kinetic equations based on moment realizability matrices, a concept introduced by Levermore, Mo- rokoff and Nadiga. Following such a criterion, one can consider hybrid scheme where the hydrodynamic part is given {{either by the}} compressible Euler or Navier-Stokes equations, or even with more general models, such as the Burnett or super-Burnett systems...|$|R
40|$|The {{limits of}} direct unitary {{transformation}} of many-fermion Hamiltonians are explored. Practical application of such transformations requires that effective many-body interactions be discarded {{over the course}} of a calculation. The truncation of the Hamiltonian leads to finite errors and in some cases divergences. A new formalism is proposed to manage errors and avoid divergences. Removing all interactions from a many-fermion Hamiltonian reduces it to fermion number operators allowing for direct calculation of eigenvalues. If the same transformations are applied to the bare fermions, eigenfermions are produced whose Slater determinants form eigenstates. This enables a <b>hierarchy</b> <b>of</b> diagonalization <b>methods</b> <b>of</b> increasing accuracy as fewer interactions are discarded from the Hamiltonian. Comment: Supplementary to APS March Meeting 2010 talk...|$|R
40|$|The article {{analyzed}} {{the establishment of}} the social history of science as an interdisciplinary field of study. The main attention is focused to the substantiation of theoretical and methodological, cultural and historical features of the process. Profound understanding of the social history science as an inter-disciplinary field that draws on the theoretical and methodological foundations of social history and sociology science. Methods of internanalism and eksternanalism were used in the analysis of the main factors in the formation and development of scientific knowledge, to identify the strategic factors affecting historical epoch on the development of science in general. Were considered the relationship of science as a social institution with other social institutions within them acroanalytical strategy of social history science, and especially the study of individual cases, the analysis of unique events of history science within the microanalytical strategy and situational studies. Were proved that a methodological interdisciplinary of social history science outlined its range of problems, ensured progress in the knowledge of the research object, set the main task ratio and the <b>hierarchy</b> <b>of</b> <b>methods</b> and findings...|$|E
40|$|AbstractObjectivesProbabilistic {{uncertainty}} {{analysis is}} a common means of evaluating pharmacoeconomic models and exploring decision uncertainty. Uncertain parameters are assigned probability distributions and analyses performed by Monte Carlo simulation. Correlations between input parameters are rarely accounted for despite recommendations from several guidelines. By outlining theoretical reasons for including correlations and showing numerous examples of existing correlations, we appeal to the analyst to consider input dependencies. Our objective is to review the available methods to do so, give technical details on implementation and show, by using examples of published studies, the effect input correlations have on model outputs. MethodsA <b>hierarchy</b> <b>of</b> <b>methods</b> for dealing with correlations in Monte Carlo simulation is presented and used. The choice of method depends {{on the amount of}} information available on dependency and consists of functional modeling, joint distributions/copulas, and coupling of marginal distributions. ResultsWe induced input correlation with various methods and showed that in most cases the choice of optimal decision remained the same as in the independent scenario. There was, however, a significant change in the value of further information because of inducing input correlations. The results were similar for various dependency structures and were mainly a function of the strength of correlation, as measured by the linear correlation coefficient. ConclusionProbabilistic uncertainty analysis reflects joint uncertainty across input parameters only when dependence among input parameters is accounted for...|$|E
40|$|The three {{commonly}} used propellant systems - H 2 /O 2, RP- 1 /O 2, and solid propellants - primarily radiate as molecular emitters, non-scattering small particles, and scattering larger particles, respectively. Present technology has accepted the uncoupling of the radiation analysis {{from that of}} the flowfield. This approximation becomes increasingly inaccurate as one considers plumes, interior rocket chambers, and nuclear rocket propulsion devices. This study will develop a <b>hierarchy</b> <b>of</b> <b>methods</b> which will address radiation/convection coupling in all of the aforementioned propulsion systems. The nature of the radiation/convection coupled problem is that the divergence of the radiative heat flux must be included in the energy equation and that the local, volume-averaged intensity of the radiation must be determined by a solution of the radiative transfer equation (RTE). The intensity is approximated by solving the RTE along several lines of sight (LOS) for each point in the flowfield. Such a procedure is extremely costly; therefore, further approximations are needed. Modified differential approximations are being developed for this purpose. It is not obvious which order of approximations are required for a given rocket motor analysis. Therefore, LOS calculations have been made for typical rocket motor operating conditions in order to select the type approximations required. The results of these radiation calculations, and the interpretation of these intensity predictions are presented herein...|$|E
40|$|A robot visual servoing system using a fixed {{camera is}} considered. Two {{adaptive}} controllers are proposed for visually tracking {{a moving target}} {{in the presence of}} camera uncertainties. The first adaptive strategy is based on an original method recently proposed. The key idea is to use a <b>hierarchy</b> <b>of</b> control <b>method</b> to solve the adaptive control problem. The adaptive algorithm is robust {{in the sense that it}} has reduced sensitivity to kinematic uncertainties. The second new adaptive law is based on the symmetrization of the control matrix. Experimental results with a robot manipulator in a planar motion illustrate the robustness and viability of the proposed scheme...|$|R
40|$|The {{vertical}} {{electronic excitation}} energies for the narrow-bandgap polymers LBPF, EP 37 and EP 62 have been calculated using Density Functional Theory (DFT). Also the vertical excitation energies for the acceptor unit of LBPF have been calculated using the Hartree-Fock (HF), DFT and Coupled Cluster (CC) methods. The calculations cover the visible and infrared wave length region and two strong transitions are obtained, one {{corresponding to the}} pi to pi* transition and one corresponding to the pi to Acceptor transition. The excitation energies obtained from DFT are below the corresponding experimental results and attempts have therefore been made to perform bench-marking calculations using a <b>hierarchy</b> <b>of</b> CC <b>methods...</b>|$|R
40|$|A new {{approach}} for the automatic equivalence checking of behavioral or structural descriptions of designs with complex control is presented. The verification tool combines symbolic simulation with a <b>hierarchy</b> <b>of</b> equivalence checking <b>methods,</b> including decision-diagram based techniques, with increasing accuracy {{in order to}} optimize overall verification time without giving false negatives. The equivalence checker is {{able to cope with}} different numbers of control steps and different implementational details in the two descriptions to be compared...|$|R
40|$|Abstract Background The {{reasoning}} behind evaluating medical interventions {{is that a}} <b>hierarchy</b> <b>of</b> <b>methods</b> exists which successively produce {{improved and}} therefore more rigorous evidence based medicine upon which to make clinical decisions. At the foundation of this hierarchy are case studies, retrospective and prospective case series, followed by cohort studies with historical and concomitant non-randomized controls. Open-label randomized controlled studies (RCTs), and finally blinded, placebo-controlled RCTs, which offer most internal validity are considered the most reliable evidence. Rigorous RCTs remove bias. Evidence from RCTs forms the basis of meta-analyses and systematic reviews. This hierarchy, founded on a pharmacological model of therapy, is generalized to other interventions which may be complex and non-pharmacological (healing, acupuncture and surgery). Discussion The hierarchical model is valid for limited questions of efficacy, for instance for regulatory purposes and newly devised products and pharmacological preparations. It is inadequate {{for the evaluation of}} complex interventions such as physiotherapy, surgery and complementary and alternative medicine (CAM). This {{has to do with the}} essential tension between internal validity (rigor and the removal of bias) and external validity (generalizability). Summary Instead of an Evidence Hierarchy, we propose a Circular Model. This would imply a multiplicity of methods, using different designs, counterbalancing their individual strengths and weaknesses to arrive at pragmatic but equally rigorous evidence which would provide significant assistance in clinical and health systems innovation. Such evidence would better inform national health care technology assessment agencies and promote evidence based health reform. </p...|$|E
40|$|The {{development}} of robust mathematical models {{could provide the}} necessary tools for a more rapid, efficient, and reliable spouted bed technology development. Computer simulations can be very useful to aid this design and scale-up process: firstly, they can contribute to obtain a fundamental insight into their complex dynamic behavior by understanding the elementary physical principles such as drag, friction, dissipation etc.; secondly, the simulations {{can be used as}} a design tool where the ultimate goal is to have a numerical model with predictive capabilities for gas-particle flows at engineering scale. Clearly, one single simulation method will not be able to achieve this goal, but a <b>hierarchy</b> <b>of</b> <b>methods</b> modelling phenomena on different length and time scales can achieve this. The most fruitful approach will be when they are simultaneously followed, so that they can mutually benefit from each other. In this sense, this paper presents a review of the current state of the art of modelling on spouted and spout-fluid beds through an analysis of recent literature following a multiscale approach (molecular and particle, lab, plant and industrial scale). The main features of the different scales together with their current limits are discussed and specific topics are highlighted as paths that still need to be explored. In summary, the paper aims to define the theoretical setline and the basis of improvement that would lead to a robust multiscale model with solid links between micro and macroscopic phenomena. If done with the correct balance between accuracy and computational costs it will gear SB towards their reliable and successful implementation...|$|E
40|$|Some linear and {{nonlinear}} optical (NLO) {{properties of}} Ni(SCH) 4 {{and several of}} its derivatives have been computed by employing a series of basis sets and a <b>hierarchy</b> <b>of</b> <b>methods</b> (e. g., HF, DFT, coupled cluster, and multiconfigurational techniques). The electronic structure of Ni(SCH) 4 has been also analyzed by using CASSCF/CASPT 2, ab initio valence bond, and DFT methods. In particular we discuss how the diradicaloid character (DC) of Ni(SCH) 4 significantly affects its NLO properties. The quasidegeneracy of the two lowest-energy singlet states 1 [*]mathg and 1 [*]math 1 u, the clear DC nature of the former, and the {{very large number of}} low-lying states enhance the NLO properties values. These particular features are used to interpret the NLO properties of Ni(SCH) 4. The DC of the considered derivatives has been estimated and correlated with the NLO properties. CASVB computations have shown that the structures with Ni(II) are the dominant ones, while those with Ni(0) and Ni(IV) have negligible weight. The weights of the four diradical structures were discussed in connection with the weight of the structures, where all the electrons are paired. Comparative discussion of the properties of Ni(SCH) 4 with those of tetrathia fulvalene demonstrates the very large effect of Ni on the properties of the Ni-dithiolene derivatives. A similar remarkable effect on the NLO properties is produced by one or two methyl or C 3 S groups. The considered Ni-dithiolene derivatives have exceptionally large NLO properties. This feature in connection with their other physical properties makes them ideal candidates for photonic applications. Luis. Serrano@uv. e...|$|E
40|$|In this paper, we {{construct}} a <b>hierarchy</b> <b>of</b> hybrid numerical <b>methods</b> for multi-scale kinetic equations based on moment realizability matrices, a concept introduced by Levermore, Morokoff and Nadiga. Following such a criterion, one can consider hybrid scheme where the hydrodynamic part is given {{either by the}} compressible Euler or Navier-Stokes equations, or even with more general models, such as the Burnett or super-Burnett systems. Comment: 27 pages, edit: typo and metadata chang...|$|R
40|$|Abstract. Computer {{simulations}} of amphiphilic systems are reviewed. Research areas cover {{a wide range}} of length and time scales, and a whole <b>hierarchy</b> <b>of</b> models and <b>methods</b> has been developed to address them all. They range from atomistically realistic models, idealized chain models, lattice spin models, to phenomenological models such as Ginzburg-Landau models and random interface models. Selected applications are discussed in order to illustrate the use of the models and the insights they can offer...|$|R
40|$|Many-body {{perturbation}} {{theory in the}} GW approximation is a useful method for describing electronic properties associated with charged excitations. A <b>hierarchy</b> <b>of</b> GW <b>methods</b> exists, starting from non-self-consistent G 0 W 0, through partial self-consistency in the eigenvalues (ev-scGW) and in the Green function (scGW 0), to fully self-consistent GW (scGW). Here, we assess the performance <b>of</b> these <b>methods</b> for benzene, pyridine, and the diazines. The quasiparticle spectra are compared to photoemission spectroscopy (PES) experiments with respect to all measured particle removal energies and the ordering of the frontier orbitals. We find that {{the accuracy of the}} calculated spectra does not match the expectations based on their level of self-consistency. In particular, for certain starting points G 0 W 0 and scGW 0 provide spectra in better agreement with the PES than scGW...|$|R
40|$|Abridged) Space {{missions}} {{to search for}} exo-planets via the transit method, such as COROT, Eddington and Kepler, will need to address {{problems associated with the}} automated and efficient detection of planetary transits in light curves affected by a variety of noise sources, including stellar variabilility. Starting from a general purpose maximum likelihood approach we discuss the links between a variety of period and transit finding methods. The natural endpoint of this <b>hierarchy</b> <b>of</b> <b>methods</b> is shown to be a fast, robust and statistically efficient least-squares algorithm based on box-shaped transits. This approach is predicated on the assumption of periodic transits hidden in random noise, usually assumed to be superposed on a flat continuum with regular continuous sampling. We next show how to generalise the transit finding method to the more realistic scenario where complex stellar (micro) variability, irregular sampling and long gaps in the data are all present. Tests of this methodology on simulated Eddington light curves including realistic stellar micro-variability, irregular sampling and data gaps, are used to quantify the performance. In the case where transit durations are short compared to the dominant timescales for stellar variability and data record segments, it is possible to decouple the transit signal from the remainder. We conclude that even with realistic contamination from stellar variability, irregular sampling, and gaps in the data record, it is still possible to detect transiting planets with an efficiency close to the idealised theoretical bound. In particular, space missions have the potential to approach the regime of detecting earth-like planets around G 2 V-type stars. Comment: 16 pages, 15 figures, submitted to MNRA...|$|E
40|$|By {{means of}} {{low-temperature}} {{scanning tunneling microscopy}} (STM) and spectroscopy (STS), we have investigated the adsorption of single Au atoms on a PTCDA monolayer physisorbed on the Au(111) surface. A chemical reaction between the Au atom and the PTCDA molecule leads {{to the formation of}} a radical that has an unpaired electron in its highest occupied orbital. This orbital is a π orbital that extends over the whole Au-PTCDA complex. Because of the large Coulomb repulsion in this orbital, the unpaired electron generates a local moment when the molecule is adsorbed on the Au(111) surface. We demonstrate the formation of the radical and the existence of the local moment after adsorption by observing a zero-bias differential conductance peak that originates from the Kondo effect. By temperature dependent measurements of the zero-bias differential conductance, we determine the Kondo temperature to be TK=(38 ± 8) K. For the theoretical description of the properties of the Au-PTCDA complex we use a <b>hierarchy</b> <b>of</b> <b>methods,</b> ranging from density functional theory (DFT) including a van der Waals correction to many-body perturbation theory (MBPT) and the numerical renormalization group (NRG) approach. Regarding the high-energy orbital spectrum, we obtain an excellent agreement with experiments by both spin-polarized DFT/MBPT and NRG. Moreover, the NRG provides an accurate description of the low-energy excitation spectrum of the spin degree of freedom, predicting a Kondo temperature very close to the experimental value. This is achieved by a detailed analysis of the universality of various definitions of TK and by taking into account the full energy dependence of the coupling function between the molecule-metal complex and the metallic substrate...|$|E
40|$|This thesis {{concerns}} {{the development of}} computational methods for efficient flexible-aircraft flight dynamics analyses. An argument is made for a <b>hierarchy</b> <b>of</b> <b>methods</b> that provide predictive capability for loads and stability analyses, {{and the ability to}} create low-order dynamic models for control system synthesis. The proposed aeroelastic models are formulated using three-dimensional unsteady aerodynamics {{in the form of an}} unsteady vortex-lattice method developed to model the relatively complex kinematics inherent in flexible-aircraft dynamics, and in particular the unsteady induced drag. No assumptions are made relating to the kine- matics of the fluid-structure interface (inputs) and use of the three-dimensional Joukowski relation naturally resolves all components of the unsteady aerodynamic forcing (outputs). A consistent linearization of this method about an arbitrary reference state yields nondimen- sional (independent of free-stream dynamic pressure) discrete-time state-space models that resolve frequencies up to a spatio-temporal Nyquist limit defined by the wake discretization, and have a convenient form for coupling with structural dynamics models. Aircraft structural components are modelled using a geometrically-exact composite beam formulation, and, additionally, in the case of linear dynamics, a generic modal description. The latter allows the linear aerodynamics to be expressed in a reduced set of inputs and outputs, thus obtaining a time-domain alternative to the classical frequency-domain-based doublet-lattice method. The models modified for these modal degrees-of-freedom are shown to be amenable to balanced realization and truncation, and are verified in flutter analyses where only 10 - 100 balanced states are required (compared to 1000 - 10, 000 physical states) for converged results. Finally, predictive controllers and linear-quadratic regulators are synthesized using reduced-order aeroelastic models, and are applied in nonlinear simulations for gust-load alleviation. Open Acces...|$|E
50|$|A Zope website {{is usually}} {{composed}} {{of objects in}} a Zope Object Database, not files on a file system, as is usual with most web servers. This allows users to harness the advantages of object technologies, such as encapsulation. Zope maps URLs to objects using the containment <b>hierarchy</b> <b>of</b> such objects; <b>methods</b> {{are considered to be}} contained in their objects as well. Data can be stored in other databases as well, or on the file system, but ZODB is the most common solution.|$|R
40|$|We {{present a}} bond-order {{potential}} (BOP) for the bcc transition metal tungsten. The bond-order potentials are a real-space semiempirical scheme for {{the description of}} interatomic interactions based on the tight-binding approximation. In the <b>hierarchy</b> <b>of</b> atomic-scale-modeling <b>methods</b> the BOPs thus provide a direct bridge between electronic-structure and atomistic techniques. Two variants of the BOP were constructed and extensively tested against accurate first-principles methods {{in order to assess}} the potentials 2 ̆ 7 reliability and applicability. A comparison of the BOP with a central-force potential is used to demonstrate that a correct description of directional mixed covalent and metallic bonds is crucial for a successful and fully transferable model. The potentials are applied in studies of low-index surfaces, symmetrical tilt grain boundaries, and dislocations...|$|R
40|$|Abstract. M {{parameter}} extends Java {{by allowing}} methods to have methods as parameters. [BO 08 b] furnishes a semantics of m parameters and applications in OO programming. In this paper, we present an {{implementation of the}} extended language based on program preprocessing. We also discuss {{the integration of the}} extended programs with ordinary Java programs, and hence Java API. Further- more, mc parameters are defined: they are a variant of m parameters for which the class <b>hierarchy</b> <b>of</b> the <b>method</b> passed as parameter must be provided in the formal and actual parameter. Semantics for mc parameters is given but, in this case, an implementation with callbacks [Hor 07] is proposed. Eventually, we dis- cuss how mc parameters deal with overloaded methods...|$|R
40|$|A {{number of}} space {{missions}} {{dedicated to the}} search for exoplanets via the transit method, such as COROT, Eddington and Kepler, are planned for launch over the next few years. They will need to address problems associated with the automated and efficient detection of planetary transits in light curves affected by a variety of noise sources, including stellar variability. To maximize the scientific return of these missions, it is important to develop and test appropriate algorithms in advance of their launch dates. Starting from a general-purpose maximum-likelihood approach we discuss the links between a variety of period- and transit-finding methods. The natural endpoint of this <b>hierarchy</b> <b>of</b> <b>methods</b> is shown to be a fast, robust and statistically efficient least-squares algorithm based on box-shaped transits. This approach is predicated on the assumption of periodic transits hidden in random noise, usually assumed to be superposed on a flat continuum with regular continuous sampling. We next show how to generalize the transit-finding method to the more realistic scenario where complex stellar (micro) variability, irregular sampling and long gaps in the data are all present. Tests of this methodology on simulated Eddington light curves, including realistic stellar microvariability, irregular sampling and gaps in the data record, are used to quantify the performance. Visually, these systematic effects can completely overwhelm the underlying signal of interest. However, in the case where transit durations are short compared to the dominant time-scales for stellar variability and data record segments, it is possible to decouple the transit signal from the remainder. We conclude that even with realistic contamination from stellar variability, irregular sampling, and gaps in the data record, it is still possible to detect transiting planets with an efficiency close to the idealized theoretical bound. In particular, space missions have the potential to approach the regime of detecting Earth-like planets around G 2 V-type stars...|$|E
40|$|Optical {{manipulation}} is {{of broad}} interest in physics, chemistry, and biology. In the literature, {{most of the}} studies are focused on the optical trapping on a single object. In this thesis, we investigated the light-induced interaction of a collection of particles. The light-induced interaction between small particles was studied by a <b>hierarchy</b> <b>of</b> <b>methods</b> including the dipole theory, the multiple scattering and Maxwell stress tensor formalism, and the finite-difference-time-domain method. We showed that the multiple scattering between small particles could induce a binding mechanism to stabilize optically organized structures, {{but at the same time}} induced an intrinsic unbinding mechanism. The stability of optically organized structure was studied and a concept of “optical density” was introduced to gauge the destabilizing effect. We found that light-induced forces could bind dielectric spheres into extended structures through two mechanisms, each with its own length scale which could be adjusted by the configuration of the external light source. By manipulating the commensurability of the two length scales, these two mechanisms cooperated to bind a large number of spheres. When the two length scales became incommensurate for some particular incident angle, the competition between the two mechanisms led to modulated structures and other complex phenomena such as re-entrant stability. We searched for the possibility for stabilizing larger clusters. For this purpose, we found that circularly polarized light bound dielectric spheres into large-scale two-dimensional hexagonal lattice and multiple scattering also induced a rotation of optically bound structures. We searched for configurations that could induce optical trapping by field enhancement. Enhanced transmission on perforated metallic film system was studied. Surface modes bound on multi perforated perfect metal plate system were analytical solved and related to different high transmittance modes. Near-field enhancement was discovered on perforated area at high transmission frequency and potential optical manipulation approaches were demonstrated...|$|E
40|$|During {{the past}} 15 years, {{a number of}} {{initiatives}} have been undertaken at national level to develop ocean forecasting systems operating at regional and/or global scales. The co-ordination between these efforts has been organized internationally through the Global Ocean Data Assimilation Experiment (GODAE). The French MERCATOR project {{is one of the}} leading participants in GODAE. The MERCATOR systems routinely assimilate a variety of observations such as multi-satellite altimeter data, sea-surface temperature and in situ temperature and salinity profiles, focusing on high-resolution scales of the ocean dynamics. The assimilation strategy in MERCATOR is based on a <b>hierarchy</b> <b>of</b> <b>methods</b> of increasing sophistication including optimal interpolation, Kalman filtering and variational methods, which are progressively deployed through the Syst`eme d’Assimilation MERCATOR (SAM) series. SAM- 1 is based on a reduced-order optimal interpolation which can be operated using ‘altimetry-only’ or ‘multi-data’ set-ups; it relies on the concept of separability, assuming that the correlations can be separated into a product of horizontal and vertical contributions. The second release, SAM- 2, is being developed to include new features from the singular evolutive extended Kalman (SEEK) filter, such as three-dimensional, multivariate error modes and adaptivity schemes. The third one, SAM- 3, considers variational methods such as the incremental four-dimensional variational algorithm. Most operational forecasting systems evaluated during GODAE are based on least-squares statistical estimation assuming Gaussian errors. In the framework of the EU MERSEA (Marine EnviRonment and Security for the European Area) project, research is being conducted to prepare the next-generation operational ocean monitoring and forecasting systems. The research effort will explore nonlinear assimilation formulations to overcome limitations of the current systems. This paper provides an overview of the developments conducted in MERSEA with the SEEK filter, the Ensemble Kalman filter and the sequential importance re-sampling filter. ...|$|E
40|$|Up to now, {{exceptional}} {{situations in}} workflow management {{have only been}} handled by using physical relations between work items (e. g. "rejecting and giving back results within a workflow"). The approach {{presented in this paper}} uses meta-information from a workflow to support problem-solving by workers within the workflow. Based on the WAM approach that builds up a situation-specific <b>hierarchy</b> <b>of</b> tasks, a <b>method</b> is presented that is also able to cope with the adaptation of already planned as well as already carried out parts of a workflow...|$|R
50|$|Engineering {{controls}} is {{the highest}} in the <b>hierarchy</b> <b>of</b> risk reduction <b>methods</b> when elimination <b>of</b> the hazard is not possible. These types of controls typically involve making changes in equipment or other changes to minimize the level of noise that reaches a worker's ear. They may also involve measures such as barriers between the worker and the source of the noise, mufflers, regular maintenance of the machinery, or substituting quieter equipment. Examples of noise control strategies adopted in the workplace can be seen among the winners of the Safe-in-Sound Excellence in Hearing Loss Prevention Awards.|$|R
40|$|We {{demonstrate}} that nonlocally coupled limit-cycle oscillators subject to spatiotemporally white Gaussian noise can exhibit a noise-induced transition to turbulent states. After illustrating noise-induced turbulent states with numerical simulations using two representative models of limit-cycle oscillators, we develop {{a theory that}} clarifies the effective dynamical instabilities leading to the turbulent behavior using a <b>hierarchy</b> <b>of</b> dynamical reduction <b>methods.</b> We determine the parameter region where the system can exhibit noise-induced turbulent states, which is successfully confirmed by extensive numerical simulations at each level of the reduction. Comment: 23 pages, 17 figures, to appear in Phys. Rev. ...|$|R
