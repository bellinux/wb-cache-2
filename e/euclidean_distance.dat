6663|1161|Public
5|$|The {{most basic}} {{property}} of the Reuleaux triangle {{is that it has}} constant width, meaning that for every pair of parallel supporting lines (two lines of the same slope that both touch the shape without crossing through it) the two lines have the same <b>Euclidean</b> <b>distance</b> from each other, regardless of the orientation of these lines. In any pair of parallel supporting lines, one of the two lines will necessarily touch the triangle at one of its vertices. The other supporting line may touch the triangle at any point on the opposite arc, and their distance (the width of the Reuleaux triangle) equals the radius of this arc.|$|E
25|$|In the Euclidean TSP (see below) the {{distance}} between two cities is the <b>Euclidean</b> <b>distance</b> between the corresponding points.|$|E
25|$|A Euclidean graph is a graph {{in which}} the {{vertices}} represent points in the plane, and the edges are assigned lengths equal to the <b>Euclidean</b> <b>distance</b> between those points; see Geometric graph theory.|$|E
40|$|Abstract—Combining {{different}} distance matrices or dissimi-larity representations usually {{can increase}} the performance of individual ones. In this work, we experimentally study {{on the performance of}} combining <b>Euclidean</b> <b>distances</b> and its rela-tionship with the non-Euclideaness produced from combining <b>Euclidean</b> <b>distances.</b> Also, the relationship between the degree of non-Euclideaness from combining <b>Euclidean</b> <b>distances</b> and the correlations between these <b>Euclidean</b> <b>distances</b> are also investigated in the experiments. From the experimental results, we observe that combining dis-similarities computed with <b>Euclidean</b> <b>distances</b> usually performs better than combining dissimilarities computed with squared <b>Euclidean</b> <b>distances.</b> Also, the improvements are highly related to the degree of non-Euclideaness. Moreover, the degree of non-Euclideaness is relatively high if two highly uncorrelated dissimilarity matrices are combined. And the degree of non-Euclideaness becomes lower if two dissimilarity matrices to be combined are more correlated. I...|$|R
50|$|Note: In {{software}} that implements Ward's method, {{it is important}} to check whether the function arguments should specify <b>Euclidean</b> <b>distances</b> or squared <b>Euclidean</b> <b>distances.</b>|$|R
40|$|The Johnson-Lindenstrauss lemma allows {{dimension}} reduction on real vectors {{with low}} distortion on their pairwise <b>Euclidean</b> <b>distances.</b> This result {{is often used}} in algorithms such as $k$-means or $k$ nearest neighbours since they only use <b>Euclidean</b> <b>distances,</b> and has sometimes been used in optimization algorithms involving the minimization of <b>Euclidean</b> <b>distances.</b> In this paper we introduce a first attempt at using this lemma {{in the context of}} feasibility problems in linear and integer programming, which cannot be expressed only in function of <b>Euclidean</b> <b>distances...</b>|$|R
25|$|In -dimensional Euclidean space (e.g. simply {{space in}} Galilean relativity), the {{isometry}} group (the maps preserving the regular <b>Euclidean</b> <b>distance)</b> is the Euclidean group. It {{is generated by}} rotations, reflections and translations. When time is amended as a fourth dimension, the further transformations of translations in time and Galilean boosts are added, and the group of all these transformations is called the Galilean group. All Galilean transformations preserve the -dimensional <b>Euclidean</b> <b>distance.</b> This distance is purely spatial. Time differences are separately preserved as well. This changes in the spacetime of special relativity, where space and time are interwoven.|$|E
25|$|The {{difference}} or {{distance between}} two colors is a metric {{of interest in}} color science. It allows quantified examination of a notion that formerly could only be described with adjectives. Quantification of these properties is of great importance to those whose work is color critical. Common definitions {{make use of the}} <b>Euclidean</b> <b>distance</b> in a device independent color space.|$|E
25|$|As most {{definitions}} of color distance are distances within a color space, the standard means of determining distances is the <b>Euclidean</b> <b>distance.</b> If one presently has an RGB (Red, Green, Blue) tuple and wishes {{to find the}} color difference, computationally {{one of the easiest}} is to call R, G, B linear dimensions defining the color space.|$|E
3000|$|... 0.1 was rejected, we {{observed}} {{the average of}} all <b>Euclidean</b> <b>distances</b> (80) due to each algorithm. The algorithm that presented the lowest average of <b>Euclidean</b> <b>distances</b> was the one chosen as the most adequate. If H [...]...|$|R
40|$|Random {{projections}} {{are typically}} {{used to study}} low distortion linear embeddings that approximately preserve <b>Euclidean</b> <b>distances</b> between pairs of points in a setS ⊂ R D. Of particular interest is when the set S is a low-dimensional submanifold ofR D. Recent results by Baraniuk and Wakin [2007] and Clarkson [2007] shed light on how to pick the projection dimension to achieve low distortion of <b>Euclidean</b> <b>distances</b> between points on a manifold. While preserving ambient <b>Euclidean</b> <b>distances</b> on a manifold does imply preserving intrinsic path-lengths between pairs of points on a manifold, here we investigate how one can reason directly about preserving path-lengths without having {{to appeal to the}} ambient <b>Euclidean</b> <b>distances</b> between points. In doing so, we can improve upon Baraniuk and Wakin’s result by removing the dependence on the ambient dimension D, and simplify Clarkson’s result by using a single covering quantity and giving explicit dependence on constants. ...|$|R
50|$|Classical MDS assumes <b>Euclidean</b> <b>distances.</b> So {{this is not}} {{applicable}} for direct dissimilarity ratings.|$|R
25|$|Spacetime is {{equipped}} with an indefinite non-degenerate bilinear form, variously called the Minkowski metric, the Minkowski norm squared or Minkowski inner product {{depending on the context}} The Minkowski inner product is defined as to yield the spacetime interval between two events when given their coordinate difference vector as argument. Equipped with this inner product, the mathematical model of spacetime is called Minkowski space. The analogue of the Galilean group for Minkowski space, preserving the spacetime interval (as opposed to the spatial <b>Euclidean</b> <b>distance)</b> is the Poincaré group.|$|E
25|$|Optimal {{spanning}} tree problems {{have also been}} studied for finite sets of points in a geometric space such as the Euclidean plane. For such an input, a {{spanning tree}} is again a tree that has as its vertices the given points. The quality of the tree is measured {{in the same way}} as in a graph, using the <b>Euclidean</b> <b>distance</b> between pairs of points as the weight for each edge. Thus, for instance, a Euclidean minimum spanning tree is the same as a graph minimum spanning tree in a complete graph with Euclidean edge weights. However, it is not necessary to construct this graph in order to solve the optimization problem; the Euclidean minimum spanning tree problem, for instance, can be solved more efficiently in O(nlogn) time by constructing the Delaunay triangulation and then applying a linear time planar graph minimum spanning tree algorithm to the resulting triangulation.|$|E
500|$|Starr's {{corollary}} to the Shapley–Folkman theorem {{states that}} the squared <b>Euclidean</b> <b>distance</b> from any pointx in the convexified sum to the original (unconvexified) sum [...] is bounded by {{the sum of the}} squares of theD largest inner-radii of the setsQ'n.|$|E
50|$|We can generalize the {{previous}} 2D extended Boolean model example to higher t-dimensional space using <b>Euclidean</b> <b>distances.</b>|$|R
50|$|This point {{minimizes}} {{the sum of}} squared <b>Euclidean</b> <b>distances</b> between itself and each point in the set.|$|R
40|$|International audienceMIMO systems exploit {{multi-path}} propagation {{to improve}} throughput {{and performance of}} digital communication systems. However, at the receiver side, the computation of <b>Euclidean</b> <b>distances</b> requires prohibitive computational complexity particularly when combined with a high-order constellation. Conventionally, {{it is necessary to}} calculate all the <b>Euclidean</b> <b>distances</b> to find the maximum likelihood solution. In this letter, we propose a novel approach based on the principle of conditioned detection combined with lattice-reduction techniques to estimate the closest point to the received symbol without the computation of all the <b>Euclidean</b> <b>distances.</b> Thanks to this approach, a reduction up to 95 % of the required number of multiplications is achieved without any degradation in terms of performance by comparison with a conventional BP technique...|$|R
500|$|The Shapley–Folkman theorem {{states that}} the squared <b>Euclidean</b> <b>distance</b> from any point in the convexified sum to the {{original}} (unconvexified) sum is bounded by {{the sum of the}} squares of theD largest circumradii of the setsQ'n (the radii of the smallest spheres enclosing these sets). This bound is independent of the number of summand-setsN (if ...|$|E
500|$|Starr's {{corollary}} [...] states an upperbound on the <b>Euclidean</b> <b>distance</b> [...] {{between the}} Minkowskisum ofN sets and the convexhull of the Minkowskisum; this {{distance between the}} sum and its convex hull is a measurement of the non-convexity of the set. For simplicity, this distance is called the [...] "non-convexity" [...] of the set (with respect to Starr's measurement). Thus, Starr's bound on the non-convexity of the sum depends on only theD largest innerradii of the summand-sets; however, Starr's bound {{does not depend on}} the number of summand-setsN, when.|$|E
500|$|... quantifies the {{avoidance}} principle {{for a single}} curve {{in terms of the}} ratio between the arc length (of the shorter of two arcs) and <b>Euclidean</b> <b>distance</b> between pairs of points, sometimes called the stretch factor. He shows that the stretch factor is strictly decreasing at each of its local maxima, except for the case of the two ends of a diameter of a circle in which case the stretch factor is constant at [...] This monotonicity property implies {{the avoidance}} principle, for if the curve would ever touch itself the stretch factor would become infinite at the two touching points.|$|E
30|$|<b>Euclidean</b> <b>distances</b> {{quantized}} on 19 bits each. Therefore {{the benefits}} in write access memory operations {{will be less}} for high constellation sizes.|$|R
30|$|As {{highlighted}} in Equation (6), the soft demapper at the receiver requires two major steps for the computation of the APP {{values of the}} GF(q) coded symbols: (i) <b>Euclidean</b> <b>distances</b> computation, and (ii) Marginalization across all possible combinations. The <b>Euclidean</b> <b>distances</b> computation is typically required for ML hard detector. In our case, since soft values are required, the MIMO ML detection and non-binary soft demapping are combined together into one single function, referred to as soft ML demapping.|$|R
3000|$|... are the <b>euclidean</b> <b>distances</b> {{between the}} {{communicator}} or the jammer and receiver i, respectively, considering {{that there are}} N receivers; and N [...]...|$|R
2500|$|Under {{the usual}} (<b>Euclidean)</b> <b>distance</b> {{function}} d(x,y) = |x'y|, the real numbers are a metric space and hence also a topological space. [...] Restricting the <b>Euclidean</b> <b>distance</b> function gives the irrationals {{the structure of}} a metric space. [...] Since the subspace of irrationals is not closed, ...|$|E
2500|$|... where d(p, q) is {{the usual}} <b>Euclidean</b> <b>distance</b> between p and q.|$|E
2500|$|For each sample, {{calculate}} the <b>Euclidean</b> <b>distance</b> [...] between {{the pair of}} co-ordinates.|$|E
3000|$|... {{requires}} calculating {{and comparing}} eight <b>Euclidean</b> <b>distances</b> for every received symbol. This complexity problem exists for any single transmitter user constellation with [...]...|$|R
3000|$|... n− 1 } {{is defined}} with the sorted <b>Euclidean</b> <b>distances</b> {{with respect to}} the other descriptors. The keypoint is matched only if d [...]...|$|R
3000|$|Evaluate {{the sum of}} the Gaussian {{distributions}} {{using the}} squared <b>Euclidean</b> <b>distances</b> between the test feature vector x and the training vectors x [...]...|$|R
2500|$|... {{and this}} {{quantity}} is {{the square of}} the <b>Euclidean</b> <b>distance</b> between [...] and the origin.|$|E
2500|$|The radius or radial {{distance}} is the <b>Euclidean</b> <b>distance</b> from the origin [...] to [...]|$|E
2500|$|The <b>Euclidean</b> <b>distance</b> {{between two}} {{points of the}} plane with Cartesian {{coordinates}} [...] and [...] is ...|$|E
50|$|It is {{more robust}} to noise and {{outliers}} {{as compared to}} -means because it minimizes a sum of pairwise dissimilarities instead of a sum of squared <b>Euclidean</b> <b>distances.</b>|$|R
30|$|In {{addition}} to the modulation order and the code rate, a third parameter should be considered regarding the iterative demapping implementation choice. In this regard, two configurations should be analyzed. In the first configuration, denoted CASE 1, the <b>Euclidean</b> <b>distances</b> are re-calculated at each demapping iteration. While in the second configuration, denoted CASE 2, the computation of the <b>Euclidean</b> <b>distances</b> are done only once, at the first iteration, then stored and reused in later demapping iterations. Thus, CASE 1 implies higher arithmetic computations, however less memory access, than CASE 2.|$|R
30|$|Furthermore, RGB, {{the device}} space, is poorly {{related to the}} human visual system. Colour {{differences}} calculated as <b>Euclidean</b> <b>distances</b> between RGB co-ordinates do not correspond well to how humans perceive colour differences. Much {{research has been done}} on deriving colour spaces such as CIELAB and CIELUV that are designed to be perceptually uniform, i.e. where <b>Euclidean</b> <b>distances</b> correspond to perceived distances in all regions of the colour space [29]. Uniform colour spaces have been used in colour quantisation algorithms and have been shown to perform better compared to algorithms based on the RGB space [30].|$|R
