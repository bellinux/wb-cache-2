5|122|Public
5000|$|A clone BCV is a {{traditional}} method, and uses one-to-one separate physical storage (splitable <b>disk</b> <b>mirror)</b> ...|$|E
40|$|The {{dominant}} hurdle to {{the operation}} of optomechanical systems in the quantum regime is the coupling of the vibrating element to a thermal reservoir via mechanical supports. Here we propose a scheme that uses an optical spring to replace the mechanical support. We show that the resolved-sideband regime of cooling can be reached in a configuration using a high-reflectivity <b>disk</b> <b>mirror</b> held by an optical tweezer {{as one of the}} end-mirrors of a Fabry-Perot cavity. We find a final phonon occupation number of the trapped mirror n̅= 0. 14 for reasonable parameters, well within the quantum regime. This demonstrates the promise of dielectric disks attached to optical springs for the observation of quantum effects in macroscopic objects. Comment: 4 pages, 2 figure...|$|E
40|$|The {{object of}} this study is the {{analysis}} of the <b>disk</b> <b>mirror</b> discovered in 2010 during the rescue archaeological excavations carried out in occasion of the construction of the Arad-Timişoara motorway, respectively the Arad-Seceani sector. The mirror was found at  ca. 1 m north grave 1 in site B 0 _ 6, where beside other two cremation graves, poorly preserved, other 129 archaeological features were also investigated. Though not exhaustively, we attempt herein to present the origin, distribution of this mirror type in the Sarmatian world and the chronological interval of their use within said environment. The author notes that these <b>disk</b> <b>mirror</b> types from the funerary Sarmatian features of the Great Hungarian Plain count amongst the most numerous, being found within funerary contexts on the entire duration of the Sarmatian inhabitancy of this geographical area. Further, the author notes that mirrors of the type are widely spread on broad geographical areas, hence the establishment of any production centres is highly difficult, but also that very likely, they were produced in various cultural environments over several centuries. Their high numbers in the Sarmatian world proves it is possible they made them, although there is no certain substantiating evidence. The author does not exclude either the possibility of the presence of travelling artisans in the Sarmatian environment making certain item categories upon order, mirrors of the type included. In terms of the dating of G 1 at Arad (site B_ 06), where the mirror most definitely originates, the author concludes that together with the other two graves (G 2 and G 3) are contemporary and date sometime {{to the end of the}} 2 nd century – early decades of the 3 rd century AD...|$|E
40|$|Unequaled {{improvements}} in processor and I/O speeds make many {{applications such as}} databases and operating systems to be increasingly I/O bound. Many schemes such as disk caching and <b>disk</b> <b>mirroring</b> have been proposed to address the problem. In this thesis we focus only on <b>disk</b> <b>mirroring.</b> In <b>disk</b> <b>mirroring,</b> a logical <b>disk</b> image is maintained on two physical disks allowing a single disk failure to be transparent to application programs. Although <b>disk</b> <b>mirroring</b> improves data availability and reliability, it has two major drawbacks. First, writes are expensive because both disks must be updated. Second, load balancing during failure mode operation is poor because all requests are serviced by the surviving <b>disk.</b> Distorted <b>mirrors</b> was proposed to address the write problem and interleaved declustering to address the load balancing problem. In this thesis we perform a comparative study of these two schemes under various operating modes. In addition we also study traditional mirroring to provide a common basis for comparison...|$|R
50|$|SME Server {{software}} supports both {{hardware and}} software <b>disk</b> <b>mirroring</b> (RAID 1), USB Disk backup & tape backup for additional data protection.|$|R
5000|$|<b>Disk</b> <b>mirroring</b> so {{that failure}} of {{internal}} disks does {{not result in}} system crashes. The Distributed Replicated Block Device is one example.|$|R
40|$|We {{investigate}} {{the distribution of}} bright main sequence stars near {{the northern edge of}} the M 33 disk. Clustering on sub-kpc scales is seen among stars with ages near 10 Myr, and two large star-forming complexes are identified. Similar large-scale grouping is not evident among stars with ages 100 Myr. These stars are also distributed over a much larger area than those with younger ages, and it is argued that random stellar motions alone, as opposed to orderly motions of the type spurred by large scale secular effects, can re-distribute stars out to distances of at least 2 kpc (i. e. one disk scale length) from their birth places on 100 Myr timescales. Such random motions may thus {{play a significant role in}} populating the outer regions of the M 33 disk. Finally, it is suggested that - to the extent that the ambient properties of the outer <b>disk</b> <b>mirror</b> those in the main body of the disk - stars in this part of M 33 may have formed in star clusters with masses 50 - 250 solar, which is substantially lower than the peak of the solar neighborhood initial cluster mass function. Comment: ApJ (Letters), accepted for publicatio...|$|E
40|$|Looking for {{a quantum}} field theory model of Archimedean {{algebraic}} geometry a class of infinite-dimensional integral representations of classical special functions was introduced. Precisely the special functions such as Whittaker functions and Gamma-function were identified with correlation functions in topological field theories on a two-dimensional <b>disk.</b> <b>Mirror</b> symmetry of the underlying topological field theory leads to a dual finite-dimensional integral representations reproducing classical integral representations for the corresponding special functions. The mirror symmetry interchanging infinite- and finite-dimensional integral representations provides an incarnation of the local Archimedean Langlands duality {{on the level of}} classical special functions. In this note we provide some directions to higher-dimensional generalizations of our previous results. In the first part we consider topological field theory representations of multiple local L-factors introduced by Kurokawa and expressed through multiple Barnes's Gamma-functions. In the second part we are dealing with generalizations based on consideration of topological Yang-Mills theories on non-compact four-dimensional manifolds. Presumably, in analogy with the mirror duality in two-dimensions, S-dual description should be instrumental for deriving integral representations for a particular class of {{quantum field theory}} correlation functions and thus providing a new interesting class of special functions supplied with canonical integral representations. Comment: 21 pages, typos are fixed and important reference is adde...|$|E
50|$|<b>Disk</b> <b>mirroring</b> {{differs from}} file {{shadowing}} that operates on the file level, and disk snapshots where data images are never re-synced with their origins.|$|R
50|$|Storage appliances: provide {{massive amounts}} of storage and {{additional}} higher level functionality (ex: <b>Disk</b> <b>mirroring</b> and Data striping) for multiple attached systems using the transparent local storage area networks computer paradigm.|$|R
50|$|Real-Time Compression can be {{combined}} with Easy Tiering, Thin Provisioning and Virtual <b>Disk</b> <b>Mirroring.</b> It was initially invented by the acquired startup Storwize Inc., which also served as new name for the SVC-derived IBM storage systems family.|$|R
5000|$|XRC is a z/Series {{asynchronous}} <b>disk</b> <b>mirroring</b> technique {{which is}} effective over any distance. It keeps the data time consistent across multiple ESS (Enterprise Storage Server) or HDS (Hitachi Data Systems) disk subsystems at the recovery site.|$|R
50|$|In data storage, <b>disk</b> <b>mirroring</b> is the {{replication}} of logical disk volumes onto separate physical hard disks {{in real time}} to ensure continuous availability. It is most commonly used in RAID 1. A mirrored volume is a complete logical representation of separate volume copies.|$|R
5000|$|SFT II {{provides}} a <b>disk</b> <b>mirroring</b> or duplexing {{system based on}} RAID 1; mirroring refers to two disk drives holding the same data, duplexing uses two data channels/controllers to connect the disks (fault tolerance on the disk level and optionally on the data-channel level).|$|R
5000|$|Mirrored volumes: {{the volume}} {{contains}} several disks, and when data is written to one {{it is also}} written to the other disks. This means that if one disk fails, the data can be totally recovered from the other <b>disk.</b> <b>Mirrored</b> volumes are also known as RAID-1.|$|R
5000|$|A {{geographically}} distributed, highly available clustered storage setup leveraging {{the virtual}} <b>disk</b> <b>mirroring</b> feature across datacenters within 300 km distance. Stretched Clusters can span 2, 3 or 4 datacenters (chain or ring topology, a 4-site cluster requiring 8 cluster nodes). Cluster consistency is ensured {{by a majority}} voting set.|$|R
5000|$|Mirrored volumes, {{also known}} as RAID-1, store {{identical}} copies of their data on 2 or more identical <b>disks</b> (<b>mirrored).</b> This allows for fault tolerance; in the event one disk fails, the other disk(s) can keep the server operational until the server can be shut down for replacement of the failed disk.|$|R
5000|$|<b>Disk</b> <b>mirroring.</b> This {{was done}} in the {{filesystem}} and not the device driver, so that slightly (or even completely) different devices could still be mirrored together. Mirroring a small hard disk to the floppy was a popular way to test mirroring as ejecting the floppy was an easy way to induce disk errors.|$|R
5000|$|Electromechanical {{television}} - Nipkow <b>disk</b> with <b>mirrors</b> {{instead of}} slots (ca. 1925) ...|$|R
5000|$|Continuous data {{protection}} : Instead of scheduling periodic backups, the system immediately logs every {{change on the}} host system. This is generally done by saving byte or block-level differences rather than file-level differences. It differs from simple <b>disk</b> <b>mirroring</b> in that it enables a roll-back of the log and thus restoration of old images of data.|$|R
40|$|Disk arrays, or RAIDs, {{have become}} the {{solution}} to increase the capacity, bandwidth and reliability of most storage systems. In spite of its high redundancy level, <b>disk</b> <b>mirroring</b> is a popular RAID paradigm, because replicating data also doubles the bandwidth available for processing read requests, improves the reliability and achieves fault tolerance. In this paper, we present a new RAID architecture called RAID-RMS in which a special hybrid mechanism is used to map the data blocks to the cluster. The main idea behind the proposed algorithm is to combine the data block striping and <b>disk</b> <b>mirroring</b> technique with a data block rotation. The resulting architecture improves the parallelism reliability and efficiency of the RAID array. We show that the proposed architecture is able to serve many more disk requests {{compared to the other}} mirroring-based architectures. We also argue that a more balanced disk load is attained by the given architecture, especially when there are some disk failures...|$|R
40|$|GeckoFS is a file / {{storage system}} that saves power by {{spinning}} down hard disks. It overlays a log abstraction over a fault-tolerant mirrored multi-disk array. A log-structured storage system writes {{only to the}} log head, hence it continuously and sequentially writes to {{the same set of}} striped, <b>mirrored</b> <b>disks</b> for long periods of time. Read requests are served from the primary <b>disks,</b> while the <b>mirror</b> <b>disks</b> can be powered down to trade off read throughput for power savings...|$|R
50|$|In some implementations, the <b>mirrored</b> <b>disk</b> can {{be split}} off {{and used for}} data backup, {{allowing}} the first disk to remain active. However merging the two disks then may require a synchronization period if any write I/O activity has occurred to the <b>mirrored</b> <b>disk.</b>|$|R
40|$|In this paper, {{we propose}} SiLo, a novel energy {{efficient}} shifted logging storage architecture, for write-oriented workloads. By organizing free storage space of redundant <b>mirrored</b> <b>disks</b> in a RAID 10 system into a logical logging space pool and shifting logger among different <b>mirrored</b> <b>disk</b> pairs, {{only one or}} few <b>mirrored</b> <b>disk</b> pairs are used as the on-duty logger {{at a time and}} all the other off-duty <b>mirrored</b> <b>disk</b> pairs are set to low-power state for power saving. SiLo is extremely effective for the write-oriented workloads. Extensive trace-driven evaluations demonstrate the power saving potentiality and performance scalability. Thorough analysis and comparison of reliability between SiLo and typical RAID 10 demonstrates that the MTTDL of SiLo is much larger than that of typical RAID 10. ...|$|R
40|$|Collaborating in the {{evaluation}} of GeckoFS, a file system based on KyotoFS, that saves power by spinning down hard disks. It overlays a log abstraction over a fault-tolerant mirrored multi-disk array. A log-structured storage system writes only to the log head, hence it continuously and sequentially writes to the same set of striped, <b>mirrored</b> <b>disks</b> for long periods of time. Read requests are served from the primary <b>disks,</b> while the <b>mirror</b> <b>disks</b> can be powered down to trade off read throughput for power savings. Power-Lean Cloud Storag...|$|R
5000|$|... #Caption: Fig.1. An optically-pumped <b>disk</b> laser (active <b>mirror).</b>|$|R
40|$|Abstract — Energy-efficiency is {{becoming}} increasingly important for storage systems to reduce {{the total cost of}} ownership (TCO). In this paper, we propose an energy saving policy named eRAID for conventional disk based RAID- 1 systems using redundancy. In particular, we develop a dynamic performance control scheme {{with the help of a}} performance predictor based on queueing network theory. Moreover, we discuss alternative data layout schemes that are more energy-efficient than traditional <b>disk</b> <b>mirroring.</b> Experimental results show that eRAID can save up to 30 % energy without violating predefined performance constraints. I...|$|R
50|$|NetWare 2.x {{implemented}} {{a number of}} features inspired by mainframe and minicomputer systems that were not available in other operating systems of the day. The System Fault Tolerance (SFT) features included standard read-after-write verification (SFT-I) with on-the-fly bad block re-mapping (at the time, disks did not have that feature built in) and software RAID1 (<b>disk</b> <b>mirroring,</b> SFT-II). The Transaction Tracking System (TTS) optionally protected files against incomplete updates. For single files, this required only a file attribute to be set. Transactions over multiple files and controlled roll-backs were possible by programming to the TTS API.|$|R
2500|$|... fsck cannot always {{validate}} {{and repair}} data when checksums are stored with data (often {{the case in}} many file systems), because the checksums may also be corrupted or unreadable. ZFS always stores checksums separately from the data they verify, improving reliability {{and the ability of}} scrub to repair the volume. ZFS also stores multiple copies of data – metadata in particular may have upwards of 4 or 6 copies (multiple copies per disk and multiple <b>disk</b> <b>mirrors</b> per volume), greatly improving the ability of scrub to detect and repair extensive damage to the volume, compared to fsck.|$|R
5000|$|There is no native {{operating}} system {{support for the}} Cloud Files API {{so it is not}} yet possible to [...] "map" [...] or [...] "mount" [...] it as a virtual drive without third-party software like JungleDisk that translates to a supported standard such as WebDAV. There are no concepts of [...] "appending" [...] or [...] "locking" [...] data within Cloud Files (which may affect some <b>disk</b> <b>mirroring</b> or backup solutions), nor support for permissions or transcoding. Data is organised into [...] "containers" [...] but {{it is not possible to}} create nested folders without a translation layer.|$|R
50|$|In {{addition}} to providing an additional copy of {{the data for the}} purpose of redundancy in case of hardware failure, <b>disk</b> <b>mirroring</b> can allow each disk to be accessed separately for reading purposes. Under certain circumstances, this can significantly improve performance as the system can choose for each read which disk can seek most quickly to the required data. This is especially significant where there are several tasks competing for data on the same disk, and thrashing (where the switching between tasks takes up more time than the task itself) can be reduced. This is an important consideration in hardware configurations that frequently access the data on the disk.|$|R
50|$|The {{most basic}} method is <b>disk</b> <b>mirroring,</b> typical for locally {{connected}} disks. The storage industry narrows the definitions, so mirroring {{is a local}} (short-distance) operation. A replication is extendable across a computer network, so the disks can be located in physically distant locations, and the master-slave database replication model is usually applied. The purpose of replication is to prevent damage from failures or disasters that may occur in one location, or in case such events do occur, improve the ability to recover. For replication, latency is the key factor because it determines either how far apart the sites can be or the type of replication that can be employed.|$|R
5000|$|Backup site or {{disaster}} recovery center (DR center): In {{the event of}} a disaster, the data on backup media will not be sufficient to recover. Computer systems onto which the data can be restored and properly configured networks are necessary too. Some organizations have their own data recovery centers that are equipped for this scenario. Other organizations contract this out to a third-party recovery center. Because a DR site is itself a huge investment, backing up is very rarely considered the preferred method of moving data to a DR site. A more typical way would be remote <b>disk</b> <b>mirroring,</b> which keeps the DR data as up to date as possible.|$|R
50|$|The {{original}} processor {{that went}} into service at Baynard house {{was known as the}} MK2 BL processor. It was replaced (though not perhaps in Baynard House?) by the POPUS1. One of these was in Lancaster House in Liverpool. Later, these too were replaced with a much smaller system known as R2PU or release 2 processor utility. This was the 4 CPU per cluster and 8 cluster system described above. In more recent times, some of the clusters were replaced with more modern hardware while the original processing clusters 0 to 3 were upgraded in many ways. There were many very advanced features in the system that explain why these are still in use today like self fault detection and recovery, battery backed ram <b>disks,</b> <b>mirrored</b> <b>disk</b> storage, auto replacement of a failed memory unit, the ability to trial new software and roll back to the previous version and a bespoke instruction set.|$|R
5000|$|... #Caption: Fig.2. A <b>disk</b> laser (active <b>mirror)</b> {{configuration}} {{presented in}} 1992 at the SPIE conference.|$|R
25|$|In addition, pools {{can have}} hot spares to {{compensate}} for failing <b>disks.</b> When <b>mirroring,</b> block devices can be grouped according to physical chassis, so that the filesystem can continue {{in the case of}} the failure of an entire chassis.|$|R
