10|313|Public
40|$|This {{main purpose}} of the {{research}} was to develop and manufacture a prototype for a new Wireless Surface Electrode for acquiring surface Electromyography (sEMG) signals from the vastus lateralis muscle from the quadriceps of the knee in real-time. Initially an extensive literature review {{was carried out which}} looked at literature either presented at recognised international conferences or published in journals. The literature review focused on papers from the year 2000 using two keywords, which were ‘Wireless’ and ‘Electromyography’. This showed that the majority of papers had been presented at conferences and published in their proceedings. The literature review showed that there were three main techniques used for wireless transmission with a large variation in the settings for the gain used, filtering and data acquisition of the sEMG signals. For this research the overall design of the new Wireless Surface Electromyography (WsEMG) Electrodes consisted of two newly designed and developed components: (a) an Electrode <b>Interface</b> <b>Node</b> and (b) a Computer <b>Interface</b> <b>Node.</b> The wireless link between the two nodes used a ZigBee protocol. The data acquisition was carried out using LabVIEW software to develop a new virtual instrument. The electrode <b>interface</b> <b>node</b> used an integrated circuit chip from a family programme system on the chip (PSoC®). The PSOC® chip enable module configuration of the instrumentation amplifier, the low-pass filter, the analogue to digital convertor and it also required a universal asynchronous receiver/transmitter to interface to an XBee® transceiver module. The computer <b>interface</b> <b>node</b> was developed to be a USB dongle to connect to a laptop computer. The USB dongle consisted of another XBee® transceiver module and a USB universal asynchronous receiver/transmitter...|$|E
40|$|International audienceIn {{the context}} of hybrid sparse linear solvers based on domain {{decomposition}} and Schur complement approaches, getting a domain decomposition tool leading to a good balancing of both the internal node set size and the <b>interface</b> <b>node</b> set size is a critical point for parallel computation. We propose several variations of the existing algorithms in the multilevel Scotch partitioner and we illustrate the improved results on a collection of graphs coming from numerical scientific applications...|$|E
40|$|Summary. Interface {{boundary}} conditions {{are the key}} ingredient to design efficient domain decomposition methods. However, convergence cannot be obtained for any method {{in a number of}} iterations less than the number of subdomains minus one {{in the case of a}} one-way splitting. This optimal convergence can be obtained with generalized Robin type {{boundary conditions}} associated with an operator equal to the Schur complement of the outer domain. Since the Schur complement is too expensive to compute exactly, a new approach based on the computation of the exact Schur complement for a small patch around each <b>interface</b> <b>node</b> is presented for the two-Lagrange multiplier FETI method. ...|$|E
30|$|Non-matching meshes: the {{interface}} Γ is {{aligned with the}} edges of the elements but the <b>interface</b> <b>nodes</b> of both models are shifted (see Fig.  3  (top-right)).|$|R
40|$|Media-On-Demand (MOD) servers {{cater to}} users' needs for data and {{information}} such as news, movies, interactive games, music, merchandise catalogs, etc. This requires the storage, management, and delivery of huge amounts of multimedia data. One of the models of a MOD server is general network of computers. Some of the nodes in the network are storage nodes which contain data repositories, {{and the others are}} <b>interface</b> <b>nodes</b> which obtain data from storage nodes and deliver them to the users (clients) in a timely fashion. Determining the locations of the storage nodes to minimize the data traffic between them and the <b>interface</b> <b>nodes</b> is a global optimization problem. This paper presents an offline heuristic for choosing the locations of storage <b>nodes</b> and clustering <b>interface</b> <b>nodes</b> with storage nodes so as to minimize the traffic from the storage nodes. The proposed algorithm has been validated by simulations. Keywords: MOD Servers, Network, Storage nodes, Clustering, K-means algorithm. [...] ...|$|R
40|$|Domain {{decomposition}} techniques {{combined with}} the finite element tearing and interconnecting (FETI) method has become popular for parallel computations in finite element analysis. In the original FETI method, {{the continuity of the}} displacement field across the sub-domain boundaries is enforced via the classical Lagrange multiplier technique. In this paper, domain decomposition is used as well, but continuity conditions are imposed via the "localized Lagrange multiplier" technique. In this approach, <b>interface</b> <b>nodes</b> are created and continuity conditions are enforced between the displacements of the boundary nodes and those of the <b>interface</b> <b>nodes.</b> The presence of the <b>interface</b> <b>nodes</b> maximizes the independence of the sub-domains and enables the use of augmented Lagrangian terms that improve the numerical conditioning of the problem. The localized Lagrange multiplier technique is formulated within the finite element framework and the solution procedure of domain-decomposed problem is described in detail. The proposed approach has been implemented in Dymore, a finite element based multibody dynamics code for comprehensive rotorcraft simulation. Copyright© 2014 by the American Helicopter Society International,Inc. All rights reserved...|$|R
40|$|As NASA {{works to}} develop an {{effective}} integrated portable life support system design for exploration Extravehicular activity (EVA), alternatives to the current system s electrical power and control architecture are needed to support new requirements for flexibility, maintainability, reliability, and reduced mass and volume. Experience with the current Extravehicular Mobility Unit (EMU) has demonstrated that the current architecture, based in a central power supply, monitoring and control unit, with dedicated analog wiring harness connections to active components in the system has {{a significant impact on}} system packaging and seriously constrains design flexibility in adapting to component obsolescence and changing system needs over time. An alternative architecture based in the use of a digital data bus offers possible wiring harness and system power savings, but risks significant penalties in component complexity and cost. A hybrid architecture that relies on a set of electronic and power interface nodes serving functional models within the Portable Life Support System (PLSS) is proposed to minimize both packaging and component level penalties. A common <b>interface</b> <b>node</b> hardware design can further reduce penalties by reducing the nonrecurring development costs, making miniaturization more practical, maximizing opportunities for maturation and reliability growth, providing enhanced fault tolerance, and providing stable design interfaces for system components and a central control. Adaptation to varying specific module requirements can be achieved with modest changes in firmware code within the module. A preliminary design effort has developed a common set of hardware interface requirements and functional capabilities for such a node based on anticipated modules comprising an exploration PLSS, and a prototype node has been designed assembled, programmed, and tested. One instance of such a node has been adapted to support testing the swingbed carbon dioxide and humidity control element in NASA s advanced PLSS 2. 0 test article. This paper will describe the common <b>interface</b> <b>node</b> design concept, results of the prototype development and test effort, and plans for use in NASA PLSS 2. 0 integrated tests...|$|E
40|$|A visual {{environment}} for object-oriented simulation of queuing networks is developed. A key design {{objective is to}} minimize the amount of programming required from the modeler while maintaining the full modeling power of a custom-made simulator for the queuing network application domain. The environment structure {{is based on a}} recently developed standard for the design of simulation environments The software is designed and implemented on top of the MODSIM II simulation system. Generic base classes are provided for the modeler which can been arranged in a certain network topology using a point-and-click visual <b>interface.</b> <b>Node</b> parameters can then be modified from their default values using dialog boxes to conform with the model component properties. If necessary, the modeler may also change the default behavior of the basic model components by overriding the definition of some of these components methods and/or deriving new object classes with completely different behavior...|$|E
40|$|Halliburton Energy Services and Oak Ridge National Laboratory {{established}} a CRADA to conduct applied research {{to develop a}} general purpose, High-Temperature, Smart Transducer <b>Interface</b> <b>Node</b> and Telemetry System (HSTINTS) capable of temporally-coherent multiple-channel, high speed, high-resolution data transuction and acquisition while operating in a hostile thermal, chemical, and pressure environment for {{extended periods of time}} over a single coaxial cable. This ambitious, high-risk effort required development of custom dielectric isolated integrated circuits, amplified hybrid couplers for telemetry and an audio-frequency based power supply and distribution system using an engineered application of standing waves to compensate voltage drop along a 2 mile long cable. Several goals were achieved but underestimated challenges and a couple of mistakes hampered progress. When it was determined that an additional year of concerted effort would be required to complete the system demonstration, the sponsor withdrew funding and terminated the effort...|$|E
5000|$|In {{some cases}} the <b>interface</b> <b>nodes</b> of the {{substructures}} are non-conforming, e.g. when two substructures are meshed separately. In such cases a non-Boolean matrix [...] has {{to be used in}} order to enforce a weak interface compatibility.|$|R
40|$|Abstract — The {{traditional}} {{message passing}} algorithm devel-oped by Pearl in 1980 s provides exact inference for discrete poly-tree Bayesian networks. When {{there are multiple}} paths (loops) in the network, we can still apply Pearl’s algorithm to provide approximate solutions and it is so-called “loopy propagation”. However, when mixed random variables (continuous and discrete variables) {{are present in the}} network, there is no theoretical sound method so far for efficient message passing. In this paper, we propose a novel approach to compute, propagate and integrate the messages for hybrid models. Specifically, we propose to first partition the network into separate parts by introducing the concept of <b>interface</b> <b>nodes.</b> We then apply different algorithms for each sub-network. Finally we integrate the information through the channel of <b>interface</b> <b>nodes</b> and then calculate the posterior distributions for all hidden variables. The numerical experiment results show that the algorithm works well for hybrid Bayesian networks...|$|R
40|$|In this work, {{a method}} is {{proposed}} for modifying the standard master-slave stiffness matrix so that linear consistency across the interface {{of the master}} and slave meshes is achieved. The existence of such a local stiffness modification is implied {{by the work of}} [Dohrmann, et al, to appear]. The present work aims at achieving the same linear consistency through a different method of stiffness modification that is based on simply ensuring zero residual force at the interior <b>interface</b> <b>nodes</b> for all non-zero-stress linear displacement fields and zero residual force at all <b>interface</b> <b>nodes</b> for all rigid-body linear displacement fields. These zero residuals ensure that the local stiffness modification results in an interface that passes the patch test. Numerical examples herein demonstrate that the maximum stress error at the interface goes to zero with the proposed method while it does not for the standard master-slave method...|$|R
40|$|The {{traditional}} {{message passing}} algorithm was originally developed by Pearl in the 1980 s for computing exact inference solutions for discrete polytree Bayesian networks. When a loop {{is present in}} the network, propagating messages are not exact, but the loopy algorithm usually converges and provides good approximate solutions. However, in general hybrid Bayesian networks, the message representation and manipulation for arbitrary continuous variable and message propagation between different types of variables are still open problems. The novelty of the work presented here is to propose a framework to compute, propagate, and integrate messages for hybrid models. First, we combine unscented transformation and Pearl’s message passing algorithm to deal with the arbitrary functional relationships between continuous variables in the network. For the general hybrid model, we partition the network into separate network segments by introducing the concept of <b>interface</b> <b>node.</b> We then apply different algorithms for each subnetwork. Finally we integrate the information through the channel of interface nodes and then estimate the posterior distributions for all hidden variables. The numerical experiments show that the algorithm works well for nonlinear hybrid BNs. Manuscript received October 6, 2007; revised May 19, 2008; released for publication June 16, 2008...|$|E
40|$|The {{cost and}} {{complexity}} of deploying measurement infrastructure in the Internet {{for the purpose of}} analyzing its structure and behavior is considerable. Basic questions about the utility of increasing the number of measurements and measurement sites have not yet been addressed which has led to a "more is better" approach to wide-area measurement studies. In this paper, we step toward a more quantifiable understanding of the marginal utility of performing wide-area measurements in the context of Internet topology discovery. We characterize the observable topology in terms of nodes, links, node degree distribution, and distribution of end-to-end flows using statistical and information-theoretic techniques. We classify nodes discovered on the routes between a set of 8 sources and 1277 destinations to differentiate nodes which make up the so called "backbone" from those which border the backbone and those on links between the border nodes and destination nodes. This process includes reducing nodes that advertise multiple interfaces to single IP addresses. We show that the utility of adding sources beyond the second source quickly diminishes from the perspective of <b>interface,</b> <b>node,</b> link and node degree discovery. We also show that the utility of adding destinations is constant for interfaces, nodes, links and node degree indicating that {{it is more important to}} add destinations than sources. Keywords [...] - Network measurement, traceroute, topology discovery, Internet tomography I...|$|E
40|$|Localised {{failure in}} quasibrittle {{materials}} is due {{mainly to the}} effects of combined shear and compression. Once the cohesion strength is reached, shear tractions generate slip and aggregate interlocking that cause dilatancy inducing crack opening. Further damage reduces the cohesion and dilatancy so that eventually only a residual friction state remains. The energy dissipated due to friction and interlocking needs to be considered in the constitutive law. Initially, a Mohr-Coulomb yield surface with a tension cut-off will be investigated. A compression cap will be included when the modelled interfaces are not appropriately aligned and compressive failure must be controlled. The evolution of the yield surface and the appropriate flow rules {{to be used in the}} interface/particle model, are questions which will be examined. The particle/interface model with plasticity concentrated at the interface nodes, which can produce the correct volumetric expansion, will also be studied. A composite model has been developed to represent the heterogeneity of concrete consisting of coarse aggregates, mortar matrix and the mortar-aggregate interface. The constituents of concrete are modelled using triangular elements with six interface nodes along their sides. Fracture is captured through a constitutive softening-fracture law at the interface nodes, which bound the elastic domain inside each element. The inelastic displacement at an <b>interface</b> <b>node</b> represents the crack opening, which is associated to the conjugate internodal force by a single branch softening law. The path-dependent softening behaviour is derived in irreversible rate formulation within a quasi-prescribed displacement control. At each event in the loading history, all equilibrium solutions for the prescribed mesh can be obtained and the critical equilibrium path with the minimum increment of external work adopted. The crack profile develops restrictively to the interface boundaries of the defined mesh. No re-meshing is carried out. Solutions to the irreversible rate formulation are obtained using a mathematical programming procedure in the form of a linear complementary problem. Other work is aimed at incorporating fibre reinforcement in the model. Fibre particles are modelled by introducing additional linear elements interconnecting distant interface nodes in the matrix media after the generation of matrix-aggregate structure...|$|E
5000|$|... 3GPP TS 25.469: UTRAN Iuh <b>interface</b> Home <b>Node</b> B (HNB) Application Part (HNBAP) {{signalling}} - {{interface between}} HNB and HNB-GW ...|$|R
40|$|Mobile {{semantic}} grids {{are characterized}} by high heterogeneity and volatility of their component nodes. Hence, discovery procedures more flexible than the ones borrowed from wired approaches are desirable. We present a hybrid ZigBee/Bluetooth grid infrastructure where Knowledge Representation techniques and technologies have been exploited to perform a capillary data dissemination, to interconnect the user with <b>interface</b> <b>nodes</b> and to perform an advanced resource discovery. A case study is reported along with experimental results on a prototype implementation. 1...|$|R
5000|$|... 3GPP TR 25.469: HNBAP Technical Report - A {{technical}} report {{that looks at}} the UTRAN Iuh <b>interface</b> Home <b>Node</b> B (HNB) Application Part (HNBAP) signalling ...|$|R
40|$|Abstract — Wireless technologies, such as IEEE 802. 11, {{that are}} used for ad hoc {{networks}} provides mobile <b>node</b> with multiple <b>interfaces</b> and multiple channels to make efficient use of network capacity. This paper studies multiple <b>interfaced</b> mobile <b>node</b> against single <b>interface</b> mobile <b>node</b> with different switching strategies and also focuses some important properties of AODV routing protocols. This paper has put an approach to AODV protocol that {{how it could be}} implemented on mobile <b>node</b> with multiple <b>interface</b> in wireless ad hoc network to use all channels efficientl...|$|R
40|$|An {{increasing}} number of applications require real-time reasoning under uncertainty with streaming input. The temporal (dynamic) Bayes net formalism provides a powerful representational framework for such applications. However, existing exact inference algorithms for dynamic Bayes nets do not scale {{to the size of}} models required for real world applications which often contain hundreds or even thousands of variables for each time slice. In addition, existing algorithms were not developed with real-time processing in mind. We have developed a new computational approach to support real-time exact inference in large temporal Bayes nets. Our approach tackles scalability by recognizing that the complexity of the inference depends on the number of <b>interface</b> <b>nodes</b> between time slices and by exploiting the distinction between static and dynamic nodes {{in order to reduce the}} number of <b>interface</b> <b>nodes</b> and to factorize their joint probability distribution. We approach the real-time issue by organizing temporal Bayes nets into static representations, and then using the symbolic probabilistic inference algorithm to derive analytic expressions for the static representations. The parts of these expressions that do not change at each time step are pre-computed. The remaining parts are compiled into efficient procedural code so that the memory and CPU resources required by the inference are small and fixed. Comment: Appears in Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (UAI 2002...|$|R
40|$|In turbomachinery, direct {{contacts}} between bladed disks and surrounding casings occur {{through a variety}} of mechanisms that may lead to severe damages. These mechanisms still remain unclear and understanding their origins is a new challenge. On that subject, the present work deals with a new full 3 D strategy in order to provide meaningful insights to designers. It involves reduced computational costs and a robust contact methodology able to account for high relative displacements at the contact interface. The first aspect of the problem is addressed through the reduction of the structures using the Craig-Bampton approach. The second one is treated with the use of spline concepts in order to smooth the contact surface and thus, avoid numerical issues. Accordingly, one set of <b>interface</b> <b>nodes</b> belonging to the area where contact is anticipated is defined for each structure. The contact constraints are enforced through a surface spline attached to the <b>interface</b> <b>nodes</b> of the casing. The respective contact forces are calculated using the Lagrange multiplier framework within an explicit time-marching procedure. Accuracy and computational costs are controlled {{by the size of the}} reduced-order models. The capabilities of this very versatile strategy encompass a wide range of finite element meshes and interaction problems that may occur in fan, turbine or compressor sections. First results show complex behaviors with coupling between the different modes of the structures and sensitivity to the friction coefficient...|$|R
40|$|Modern large, complex, {{engineering}} structures normally encompass {{a number of}} substructures which are assembled together by several types of joints. Despite, the highly sophisticated finite element method that is widely used to predict dynamic behaviour of assembled complete structures, the predicted results achieved, of assembled structures are often far from the experimental observation in comparison with those of substructures. The inaccuracy of prediction {{is believed to be}} largely due to invalid assumptions about the input data on the initial finite element models, particularly those on joints, boundary conditions and also loads. Therefore, model updating methods are usually used to improve the initial finite element models by using the experimentally observed results. This thesis is concerned with the application of model updating methods to a welded structure that consists of several substructures made from thin steel sheets that are assembled together by a number of spot welds. However, the welded structure with a large surface area is susceptible to initial curvature due to its low flexible stiffness or manufacturing or assembling errors and to initial stress due to fabrication, assembly and welding process of substructures. Nevertheless, such initial stress is very difficult to estimate by theoretical analysis or to measure. This thesis puts forward the idea of including initial curvature and/or initial stress (which have a large effect on natural frequencies) as an updating parameter for improving the performance of the finite element model of a structure made from thin steel sheets. The application of conventional iterative model updating methods which use a full finite element model has been widely practised. However when updating large, complex structures with {{a very large number of}} degrees of freedom, this application becomes impractical and computationally expensive due to the repeated solution of the eigensolution problem and repeated calculation of the sensitivity matrix. It is therefore preferable to use a substructuring scheme based model updating which is highly computationally efficient for the reconciliation of the finite element model with the test structure. However, in certain practical cases, where the confidential and proprietary issues of modelling work are of concern between the collaborating companies, in which the finite element models of the substructures could not be revealed and only the condensed matrices of the substructures are used instead, the areas of the substructures having fewer number of <b>interface</b> <b>nodes</b> would always be the first choice as the <b>interface</b> <b>nodes.</b> For welded structures, the nodes in the vicinity of spot weld element models are few and hence are usually taken as the <b>interface</b> <b>nodes</b> for connecting substructures. However, the present MSC. NASTRAN superelement model reduction procedures are known not to allow the nodes of CWELD elements to be the <b>interface</b> <b>nodes</b> of substructure. Prior to the present study, no work appears to have been done to use the nodes of CWELD elements as the <b>interface</b> <b>nodes</b> of substructures in the investigation of dynamic behaviour of welded structures. In this work, the application of branch elements as the interface elements of substructure are proposed and tested. Prior to the present study, it also appears that there has been no work done concerning the adjustment of the finite element model of the welded structure by including the effects of initial curvatures, initial stress and boundary conditions that are contributing to the modelling errors, via the combination between the Craig-Bampton CMS and model updating. This thesis presents two approaches for model updating of the welded structure: the conventional methods which use full finite element model and the substructuring scheme based model updating which uses the Craig-Bampton CMS technique. The accuracy and efficiency of both approaches are thoroughly discussed and presented and are validated with the experimentally observed results...|$|R
40|$|Commonly used mobile devices, like smart {{phones and}} tablets, are {{currently}} becoming {{an integral part}} of measurement systems. This paper describes the design principles for a measurement system using such devices and gives an example of a system for measuring the carbon content in the ashes from power industry boilers. The functions of the system are described with a division into the ones implemented on a mobile device and other user <b>interfaces</b> <b>nodes.</b> The methods of programming mobile devices are presented including their advantages and disadvantages. The presented multi-user solution can be used in other measurement systems, as well...|$|R
40|$|The paper proposes two {{scalable}} {{variants of}} the Neumann–Neumann algorithm {{for the lowest}} order Crouzeix–Raviart finite element or the nonconforming P 1 finite element on nonmatching meshes. The overall discretization is done using a mortar technique {{which is based on}} the application of an approximate matching condition for the discrete functions, requiring function values only at the mesh <b>interface</b> <b>nodes.</b> The algorithms are analyzed using the abstract Schwarz framework, proving a convergence which is independent of the jumps in the coefficients of the problem and only depends logarithmically on the ratio between the subdomain size and the mesh size...|$|R
40|$|In this paper, {{a finite}} element domain {{decomposition}} method using local and mixed Lagrange multipliers {{for a large}} scal structural analysis is presented. The proposed algorithms use local and mixed Lagrange multipliers to improve computational efficiency. In the original FETI method, classical Lagrange multiplier technique was used. In the dual-primal FETI method, the <b>interface</b> <b>nodes</b> are used at the corner nodes of each sub-domain. On the other hand, the proposed FETI-local analysis adopts localized Lagrange multipliers and the proposed FETI-mixed analysis uses both global and local Lagrange multipliers. The numerical analysis results by the proposed algorithms are compared with those obtained by dual-primal FETI method...|$|R
50|$|Support for {{redundant}} <b>interfaces</b> and redundant <b>nodes</b> - This is {{a common}} requirement for safety-concerned applications.|$|R
30|$|Monitorability {{covers the}} way how nodes in the consumer’s and provider’s conceptual-level {{business}} processes link to each other via constructs with the properties termed messaging and polling. The nodes of the externalized process part connect to nodes in the corresponding service-provider process. The degree of monitorability of service provisioning for a service consumer increases {{by the amount of}} node linkages. At a minimum, all <b>interface</b> <b>nodes</b> of both domain processes need to be linked with each other. Additional nodes may be linked that belong to the respective business processes of service consumers and service providers. We refer to [32] for detailed pattern specifications and to [25] for collaborating counterparty-interaction patterns during setup.|$|R
40|$|Abstract—In {{this paper}} we propose a {{numerical}} scheme based on finite differences for the numerical solution of nonlinear multi-point boundary value problems over adjacent domains. In each subdomain the solution is governed by different equation. The solutions are required to be smooth across the interfaces. The approach is based on using finite difference approximation of the derivatives at the <b>interface</b> <b>nodes.</b> A modified multidimentional Newton’s method is proposed for solving the nonlinear system of equations. The accuracy of the proposed scheme is validated by examples whose exact solutions are known. The method is then applied to solve for the velocity profile of fluid flow through multilayer porous media. Keywords: Multi-dimensional Newton’s method, Porous media, Multilayer flows, interface regio...|$|R
40|$|Abstract The scaled {{boundary}} {{method is}} {{an excellent way to}} model unbounded domains. However, it is limited to linear problems. Many soft-groundgeotechnical problems require both non-linear constitutive behaviour for the soil, to capture pre-failure deformations, and the presence of an unbounded domain. Adaptive meshfree methods are ideally suited to such problems. This paper couples a meshless lo-cal Petrov–Galerkin method for the near field with a meshless scaled boundary method of similar type for the far field. The method presented is novel as the de-grees of freedom of all nodes in the support of the <b>interface</b> <b>nodes</b> are coupled to the stiffness of the unbounded domain, rather than just the <b>nodes</b> on the <b>interface...</b>|$|R
40|$|An {{efficient}} parallel algorithm for {{the time}} dependent incompressible Navier-Stokes equations is developed in this paper. The time discretization {{is based on a}} direction splitting method which only requires solving a sequence of one-dimensional Poisson type equations at each time step. Then, a spectral-element method is used to approximate these one-dimensional problems. A Schur-complement approach is used to decouple the computation of <b>interface</b> <b>nodes</b> from that of interior nodes, allowing an efficient parallel implementation. The unconditional stability of the full discretized scheme is rigorously proved for the two-dimensional case. Numerical results are presented to show that this algorithm retains the same order of accuracy as a usual spectral-element projection type schemes but it is much more efficient, particularly on massively parallel computers. ? 2014 IMACS...|$|R
40|$|Finite element {{methodology}} for steady state thermal analysis of convectively cooled structures {{has been extended}} for transient analysis. The finite elements are based on representing the fluid passages by fluid bulk-temperature <b>nodes</b> and fluid-solid <b>interface</b> <b>nodes.</b> The formulation of the finite element equations for a typical flow passage {{is based on the}} weighted residual method with upwind weighting functions. Computer implementation of the convective finite element methodology using explicit and implicit time integration algorithms is described. Accuracy and efficiency of the methodology is evaluated by comparisons with analytical solutions and finite-difference lumped-parameter analyses. The comparative analyses demonstrate that finite element conduction/conduction methodology may be used to predict transient temperatures with an accuracy equal or superior to the lumped-parameter finite-difference method...|$|R
30|$|We {{define the}} process of {{selecting}} a channel for a radio <b>interface</b> at each <b>node</b> as a Markov chain.|$|R
5000|$|... 6.Interface {{boundary}} condition : {{when there is}} an interface (in composite walls) of different walls having different thermo-physical properties, the two different solid media A and B are assumed to be perfect contact and thus have same temperature at <b>interface</b> at <b>node</b> m (as shown in figure-5).|$|R
3000|$|... {{spectrum}} {{blocks of}} each segment to the <b>interfaces</b> of every <b>node.</b> For example, {{if we have}} 30 spectrum blocks, and [...]...|$|R
40|$|This paper {{develops}} a fundamental theory of realizations of linear and group codes on general graphs using elementary group theory, including basic group duality theory. Principal new and extended results include: normal realization duality; analysis of systems-theoretic properties of fragments of realizations and their connections; "minimal = trim and proper" theorem for cycle-free codes; results showing that all constraint codes except <b>interface</b> <b>nodes</b> may {{be assumed to}} be trim and proper, and that the interesting part of a cyclic realization is its " 2 -core;" notions of observability and controllability for fragments, and related tests; relations between state-trimness and controllability, and dual state-trimness and observability. Comment: 32 pages, 22 figures. To appear in IEEE Transactions on Information Theory. Part {{of this paper was}} presented at the 2012 Allerton Conferenc...|$|R
40|$|Sensor {{networks}} {{are on the}} verge of being widely-deployed in large-scale in the near-future. A sensor node consists of large inexpensive microprocessors with one or more sensor types attached to it besides a wireless communication <b>interface.</b> These <b>nodes</b> are typically thrown around over a physical region that needs to b...|$|R
