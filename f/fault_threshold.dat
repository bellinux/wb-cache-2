18|100|Public
40|$|Abstract: This paper studies {{consensus}} {{control for}} a multi-agent {{system with a}} faulty node. The node dynamics follow a continuous-time consensus protocol with negative feedback from the relative state of the neighbors, where the faulty node is instead using positive feedback from the state. Conditions for reaching consensus are established, and a <b>fault</b> <b>threshold</b> is introduced. Numerical examples investigate how the <b>fault</b> <b>threshold</b> determines the system behavior...|$|E
40|$|Abstract. Leakage {{is one of}} big {{security}} {{risks in}} the explosive gas atmosphere. In view of the weak current and detection difficulty of leakage signal, a novel method of leakage detection is proposed. According to leakage transient characteristics, this method takes zero-sequence voltage as the <b>fault</b> <b>threshold</b> value triggering measurement device. Auto-correlation function is used to analyze leakage signal energy and cross-correlation function is used to calculated leakage signal phase relationship {{in order to identify}} leakage line further. Theoretical analysis and simulation show that the proposed method can greatly improve the sensitivity of weak leakage signal detection...|$|E
40|$|Quorum-based {{protocols}} {{can be used}} {{to manage}} data when it is replicated at multiple server nodes to improve availability and performance. If some server nodes can be compromised by a malicious adversary, Byzantine quorums must be used to ensure correct access to replicated data. This paper introduces reconfigurable Byzantine quorums, which allow various quorum protocol parameters to be adapted based on the behavior of compromised nodes and the performance needs of the system. We present a protocol that generalizes dynamic Byzantine quorums by allowing the system size to change as faulty servers are removed from the system, in addition to adapting the <b>fault</b> <b>threshold.</b> A new architecture and algorithm that provide the capability to detect and remove faulty servers are also described. Finally, simulation results are presented that demonstrate the benefits offered by our approach. 1...|$|E
30|$|When {{disturbances}} or uncertainties {{exist in}} the system, a <b>fault</b> detection <b>threshold</b> method is usually used {{to determine whether the}} system has a fault [15 – 17]. This section provides <b>fault</b> detection <b>thresholds</b> calculated according to the definition of norm.|$|R
40|$|This paper {{considers}} incipient {{sensor fault}} development detection issue {{for a class}} of nonlinear systems with “observer unmatched” uncertainties. A particular FD (fault detection) sliding mode observer is designed for the augmented system formed by the original system and incipient sensor faults. The parameters are obtained using LMI and line filter techniques to guarantee that the generated residuals are robust to uncertainties and that sliding motion is not destroyed by faults. Then, three levels of novel adaptive <b>thresholds</b> (incipient sensor <b>fault</b> <b>thresholds,</b> sensor <b>fault</b> <b>thresholds</b> and sensor failure thresholds) are proposed based on the reduced order sliding mode dynamics, which effectively improve the incipient sensor fault development detectability. Case study of on the traction system in CRH (China Railway High-speed) is presented to demonstrate {{the effectiveness of the}} proposed incipient sensor fault development and senor faults detection schemes...|$|R
40|$|International audienceThis paper {{presents}} a Design-for-Test method for folded and interpolated analog-to-digital converters. The test approach samples relative voltage deviations among internal circuit nodes. A fault simulation {{is used to}} establish the <b>fault</b> detection <b>threshold</b> of the BIST by using a CAT platform...|$|R
40|$|A fault {{detection}} method for nonlinear systems, {{which is based}} on Probabilistic Neural Network Filtering (PNNF), is presented. PNNF limits the maximum estimation error of the asymptotic Bayes optimal result and describes the tracking process with an expression. On the basis of these properties of PNNF and the statistical characteristics of the noise of the system, a <b>fault</b> <b>threshold</b> can be better calculated, especially for the tracking process corresponding to a strong disturbance. According to the threshold, the fault can be detected by evaluating the residuals. Also, for some special cases when a fault is potential but the system is in steady state, which causes the information for {{fault detection}} may be insufficient and a group of disturbances are artificially input with definite amplitudes, so that the result of detection can be enhanced by comparing the real with the expected tracking processes of the filter. Examples are given to demonstrate the method of fault detection based on PNNF. ...|$|E
40|$|Abstract. In {{this paper}} we {{introduce}} GAFT (Generalized Anomaly and <b>Fault</b> <b>Threshold),</b> featuring a novel system architecture that {{is capable of}} setting, monitoring and detecting generalized thresholds and soft faults proactively and adaptively. GAFT monitors many network parameters simultaneously, analyzes statistically their performance, combines intelligently the individual decisions and derives an integrated result of compliance for each service class. We have carried out simulation experiments of network resource and service deterioration, when increasingly congested in the presence of class-alien traffic, where GAFT combines intelligently, using a neural network classifier, 12 monitored network performance parameter decisions into a unified result. To this end, we tested five different types of neural network classifiers: Perceptron, BP, PBH, Fuzzy ARTMAP, and RBF. Our results indicate that BP and PBH provide more effective classification than the other neural networks. We also stress tested the entire system, which showed that GAFT can reliably detect class-alien traffic with intensity as low as five to ten percent of typical service class traffic. ...|$|E
40|$|In this paper, an {{original}} method for bearing fault detection in high speed synchronous machines is presented. This method {{is based on}} the statistical process of Welch’s periodogram of the stator currents in order to obtain stable and normalized fault indicators. The principle of the method is to statistically compare the current spectrum to a healthy reference so as to quantify the changes over the time. A statistic-based indicator is then constructed by monitoring speciﬁc harmonic family. The proposed method was tested on two experimental test campaigns for four diﬀerent speeds and compared to a vibration indicator. The method was evaluated using a rigorous performance evaluation metric. A threshold evaluation was performed and shows that the proposed method is very tolerant to the machine speed. Thus, the use of an unique <b>fault</b> <b>threshold</b> whatever the speed can be considered. Results showed excellent agreement as compared with the vibration indicator, with an overall correlation of r = 0. 74 and only 4...|$|E
40|$|This is an Accepted Manuscript of {{an article}} {{published}} by Taylor & Francis in Vehicle System Dynamics on 2017 - 01 - 24, available online: [URL] paper proposes an approach for the estimation of the road angles independent from the road friction conditions. The method employs unknown input observers on the roll and pitch dynamics of the vehicle. The correlation between the road angle rates and the pitch/roll rates of the vehicle is also investigated to increase the accuracy. Dynamic <b>fault</b> <b>thresholds</b> are implemented in the algorithm to ensure reliable estimation of the vehicle body and road angles. Performance of the proposed approach in reliable estimation of the road angles is experimentally demonstrated through vehicle road tests. Road test experiments include various driving scenarios on different road conditions to thoroughly validate the proposed approach...|$|R
40|$|Abstract: Up-down {{counters}} {{are commonly}} used in the aerospace industry for <b>fault</b> detection <b>thresholding.</b> This paper applies the up-down counter technique to detect wind turbine <b>faults.</b> The <b>thresholding</b> problem involves a tradeoff between false alarms and missed detections. Counter based thresholding can detect smaller faults with higher probability and lower false alarms than is possible using simple constant thresholds. This improvement is achieved by effectively introducing dynamics into the thresholding logic as opposed to decisioning based on a single time step. Up down counters are applied {{to the development of}} a fault detection system for a commercial sized 4. 8 MW wind turbine. Realistic fault scenarios in the sensing, actuation and drivetrain subsystems are considered. It is seen that most faults can be detected with fast detection times and minimal false alarms without implementation of more complex filtering and detection techniques on residuals...|$|R
40|$|Amplitude noise which inflicts {{a random}} two qubit term {{is one of}} the main {{obstacles}} preventing the implementation of a high fidelity two-body gate below the <b>fault</b> tolerance <b>threshold.</b> This noise is difficult to refocus as any refocusing technique could only tackle noise with frequency below the operation rate. Since the two qubit gate speed is normally the slowest rate in the system, it constitutes the last bottleneck towards an implementation of a gate below the <b>fault</b> tolerant <b>threshold.</b> Here we propose to use composite pulses as a dynamical decoupling approach, in order to reduce two qubit gate noise for trapped ions systems. This is done by refocusing the building blocks of ultrafast entangling gates, where the amplitude noise is reduced to shot-to-shot (STS) noise. We present detailed simulations showing that the fault-tolerance threshold could be achieved with the proposed approach...|$|R
40|$|The Radiation Security System (RSS) at the Los Alamos Neutron Science Center (LANSCE) is an {{engineered}} {{safety system}} that provides personnel protection from prompt radiation due to accelerated proton beams. The Beam Current Limiter (XL), {{as an active}} component of the RSS, limits the maximum average current in a beamline, thus the current available for a beam spill accident. Exceeding the pre-set limit initiates action by the RSS to mitigate the hazard (insertion of beam stoppers in the low energy beam transport). The beam limiter is an electrically isolated, toroidal transformer and associated electronics. The device was designed to continuously monitor beamline currents independent of any external timing. Fail-safe operation was a prime consideration in its development. Fail-safe operation is defined as functioning as intended (due to redundant circuitry), functioning with a more sensitive <b>fault</b> <b>threshold,</b> or generating a fault condition. This report describes the design philosophy, hardware, implementation, operation, and limitations of the device...|$|E
30|$|One of {{the most}} {{important}} prognostics system has been developed for EMA which plays a dominant rule in controlling surfaces of new-generation fly-by-wire aircraft and spacecraft in severe conditions [53, 54]. EMA is a safety critical part. The ability to confidently monitor, diagnose, and prognose EMA can save lives as well as millions of dollars. NASA Ames Diagnostic & Prognostic Group in collaboration with Impact, Moog, Georgia Institute of Technology, California Polytechnic State University, Oregon State University, and US Army developed a very useful PHM system for EMA. The developed system can be used onboard in real time to provide current and predicted EMA health that allows safe reconfiguration. To achieve this goal, a flyable electromechanical actuator test stand is developed and used in laboratory experiments as well as in flight onboard UH- 60 Blackhawk aircraft. After the diagnostics system catches the fault, the prognostics system which uses GPR is initiated for RUL estimation based on the fault mode and intersection of fault progression with the <b>fault</b> <b>threshold.</b> Results show that prediction error of time to failure is less than 10  %.|$|E
40|$|On-line {{monitoring}} of electric power transformers {{can provide a}} clear indication of their status and ageing behavior. This paper proposes neural modeling and the local statistical approach to fault diagnosis for the detection of incipient faults in power transformers. The method can detect transformer failures at their early stages and consequently can deter critical conditions for the power grid. A neural-fuzzy network is used to model the thermal condition of the power transformer in fault-free operation (the thermal condition is associated to a temperature variable known as hot-spot temperature). The output of the neural-fuzzy network is compared to measurements from the power transformer and the obtained residuals undergo statistical processing according to a fault detection and isolation algorithm. If a <b>fault</b> <b>threshold</b> (that is optimally defined according to detection theory) is exceeded, then deviation from normal operation can be detected at its early stages and an alarm can be launched. In several cases fault isolation can be also performed, i. e. the sources of fault in the power transformer model can be also identified. The performance of the proposed methodology is tested through simulation experiments...|$|E
40|$|ISBN : 978 - 2 - 84813 - 124 - 5 International audienceThis paper {{presents}} a Design-for-Test method for folded and interpolated analog-to-digital converters. The test approach samples relative voltage deviations among internal circuit nodes. A fault simulation {{is used to}} establish the <b>fault</b> detection <b>threshold</b> of the BIST by using a CAT platform...|$|R
30|$|The {{sections}} {{of this paper}} are organized as follows. In Section  2, the preliminary and problem statement of fault detection filter are presented. The fault detection filter performance analysis and design conditions are proposed in Section  3. The <b>fault</b> detection <b>threshold</b> is given in Section  4, and in Section  5 numerical simulation examples are given.|$|R
40|$|Joint {{enterprise}} principles {{have extended}} accomplice liability {{to establish a}} form of guilt by association. Judicial sleight of hand has been adapted, in general, to common design rationale, {{and it has been}} used as a prosecutorial expedient towards establishing derivative inculpation. The pro-prosecution bias attached to joint enterprise doctrine is self-evident, and courts have zealously favoured its application as an inculpatory tool. This article focuses on extant law relating to fault elements for homicide within common design, and comparatively reviews alternative juridical precepts. New proposals are adduced on appropriate <b>fault</b> <b>thresholds</b> levels that ought to be supererogatory to satisfy the specific intention offence definitional element for a murder conviction. The debate then extends to review withdrawal principles as part of reverse conduct prophylaxis. A new restatement is chartered that identifies imputed normative proportionality for withdrawal, penitent motive, and reverse burden of persuasion as key factorisations...|$|R
40|$|Abstract. A fault {{detection}} and diagnosis method for the hydraulic servo {{system based on}} adaptive threshold and self-organizing map (SOM) neural network is proposed in this study. The nonlinear, time-varying, fluid-solid coupling properties of the hydraulic servo system are considered. Fault detection is realized based on a two-stage radial basis function (RBF) neural network model. The first-stage RBF neural network is adopted as a fault observer for the hydraulic servo system; the residual error signal is generated by comparing the estimated observer output with the actual measurements. To overcome the drawback of false alarms when the traditional fixed <b>fault</b> <b>threshold</b> is used, an adaptive threshold producer is established by the second-stage RBF neural network. Fault occurrence is detected by comparing the residual error signal with the adaptive threshold. When a system fault is detected, the SOM neural network is employed to implement fault classification and isolation by analyzing {{the features of the}} residual error signal. Three types of common faults are simulated to verify the performance and effectiveness of the proposed method. Experimental results demonstrate that the proposed method based on adaptive threshold and SOM neural network is effective in detecting and isolating the failure of the hydraulic servo system...|$|E
40|$|Fault-tolerant {{services}} typically make {{assumptions about}} the type and maximum number of faults that they can tolerate while providing their correctness guarantees; when such a <b>fault</b> <b>threshold</b> is violated, correctness is lost. We revisit the notion of fault thresholds {{in the context of}} long-term archival storage. We observe that fault thresholds are inevitably violated in longterm services, making traditional fault tolerance inapplicable to the long-term. In this work, we undertake a “reallocation of the fault-tolerance budget ” of a long-term service. We split the service into service pieces, each of which can tolerate a different number of faults without failing (and without causing the whole service to fail) : each piece can be either in a critical trusted fault tier, which must never fail, or an untrusted fault tier, which can fail massively and often, or other fault tiers in between. By carefully engineering the split of a long-term service into pieces that must obey distinct fault thresholds, we can prolong its inevitable demise. We demonstrate this approach with Bonafide, a long-term key-value store that, unlike all similar systems proposed in the literature, maintains integrity in the face of Byzantine faults without requiring self-certified data. We describe the notion of tiered fault tolerance, the design, implementation, and experimental evaluation of Bonafide, and argue that our approach is a practical yet significant improvement over {{the state of the art}} for long-term services. ...|$|E
40|$|The Derivative-free {{nonlinear}} Kalman Filter {{is proposed}} for state estimation and fault diagnosis in distributed parameter systems {{and particularly in}} dynamical systems described by partial differential equations of the nonlinear wave type. At a first stage, a nonlinear filtering approach for estimating the dynamics of a 1 D nonlinear wave equation, from measurements provided from {{a small number of}} sensors is developed. It is shown that the numerical solution of the associated partial differential equation results into a set of nonlinear ordinary differential equations. With the application of diffeomorphism that is based on differential flatness theory it is shown that an equivalent description of the system is obtained in the linear canonical (Brunovsky) form. This transformation enables to obtain local estimates about the state vector of the system through the application of the standard Kalman Filter recursion. At a second stage, the local statistical approach to fault diagnosis is used to perform fault diagnosis for the distributed parameters system by processing with elaborated statistical tools the differences (residuals) between the output of the Kalman Filter and the measurements obtained from the distributed parameter system. Optimal selection of the <b>fault</b> <b>threshold</b> is succeeded by using the local statistical approach to fault diagnosis. The efficiency of the proposed filtering approach for performing fault diagnosis in distributed parameters systems is confirmed through simulation experiments. Comment: 11 pages, 8 figure...|$|E
40|$|Based on the geodynamics, an {{earthquake}} {{does not take}} place until the momentum-energy excess a <b>faulting</b> <b>threshold</b> value of rock due to {{the movement of the}} fluid layer under the rock layer and the transport and accumulation of the momentum. From the nonlinear equations of fluid mechanics, a simplified nonlinear solution of momentum corresponding the accumulation of the energy could be derived. Otherwise, a chaos equation could be obtained, in which chaos corresponds to the earthquake, which shows complexity on seismology, and impossibility of exact prediction of earthquakes. But, combining the Carlson-Langer model and the Gutenberg-Richter relation, the magnitude-period formula of the earthquake may be derived approximately, and some results can be calculated quantitatively. For example, we forecast a series of earthquakes of 2004, 2009 and 2014, especially in 2019 in California. Combining the Lorenz model, we discuss the earthquake migration to and fro. Moreover, many external causes for earthquake are merely the initial conditions of this nonlinear system. Comment: 7 page...|$|R
40|$|In this paper, we {{will present}} an {{analysis}} on the fault erasure BP decoders based on the density evolution. In the fault BP decoder, messages exchanged in a BP process are stochastically corrupted due to unreliable logic gates and flip-flops; i. e., we assume circuit components with transient faults. We derived a set of the density evolution equations for the fault erasure BP processes. Our density evolution analysis reveals the asymptotic behaviors of the estimation error probability of the fault erasure BP decoders. In contrast to the fault free cases, {{it is observed that}} the error probabilities of the fault erasure BP decoder converge to positive values, and that there exists a discontinuity in an error curve corresponding to the <b>fault</b> BP <b>threshold.</b> It is also shown that an message encoding technique provides higher <b>fault</b> BP <b>thresholds</b> than those of the original decoders at the cost of increased circuit size. Comment: 12 pages, submitted to ISIT 201...|$|R
40|$|In {{principle}} a 1 D {{array of}} nearest-neighbour linked qubits {{is compatible with}} fault tolerant quantum computing. However such a restricted topology necessitates a large overhead for shuffling qubits and consequently the <b>fault</b> tolerance <b>threshold</b> is far lower than in 2 D architectures. Here we identify a middle ground: a 1 D segmented chain which is a linear array of segments, {{each of which is}} a well-connected zone with all-to-all connectivity. The architecture is relevant to both ion trap and solid-state systems. We establish that fault tolerance can be achieved either by a surface code alone, or via an additional concatenated four-qubit gauge code. We find that the <b>fault</b> tolerance <b>threshold</b> is 0. 12 % for 15 -qubit segments, while larger segments are superior. For 35 or more qubits per segment one can achieve computation on a meaningful scale with today's state-of-the-art fidelities without the use of the upper concatenation layer, thus minimising the overall device size. Comment: 15 pages, 12 figure...|$|R
40|$|Quorum {{protocols}} offer several benefits {{when used}} to maintain replicated data but techniques for reducing overheads {{associated with them}} have not been explored in detail. It is desirable that a system be able to adapt its operation so that fault tolerance related overheads are only incurred when the protocol execution actually encounters faults. There {{are a number of}} issues that need to be carefully examined to achieve such agility of quorum based systems. We make use of a file system prototype, developed in our Agile Store project, to experimentally evaluate several techniques that are important for efficient implementation of Byzantine fault-tolerant quorum protocols. We present an optimistic quorum collection scheme and a probabilistic hashing scheme for determining the response to a quorum request, and show that they lead to significant performance improvements. The Agile Store also makes use of reconfigurable quorum techniques to allow system size and <b>fault</b> <b>threshold</b> to be dynamically varied when, for example, faulty servers are removed, new servers are added, or the threat level is changed. We quantify the performance gains made possible by such reconfiguration of quorum parameters. We also show how performance scales with different system parameters and how it is affected by design choices such as whether to use proxies. We believe that the results in the paper provide important insights into how to implement quorum protocols to provide good performance while achieving Byzantine fault tolerance. 1...|$|E
40|$|This {{dissertation}} {{presents a}} model-based reasoning architecture with a two fold purpose: {{to detect and}} classify component faults from observable system behavior, and to generate fault propagation models {{so as to make}} a more accurate estimation of current operational risks. It incorporates a novel approach to system level diagnostics by addressing the need to reason about low-level inaccessible components from observable high-level system behavior. In the field of complex system maintenance it can be invaluable as an aid to human operators. The first step is the compilation of the database of functional descriptions and associated fault-specific features for each of the system components. The system is then analyzed to extract structural information, which, in addition to the functional database, is used to create the structural and functional models. A fault-symptom matrix is constructed from the functional model and the features database. The <b>fault</b> <b>threshold</b> levels for these symptoms are founded on the nominal baseline data. Based on the fault-symptom matrix and these thresholds, a diagnostic decision tree is formulated in order to intelligently query about the system health. For each faulty candidate, a fault propagation tree is generated from the structural model. Finally, the overall system health status report includes both the faulty components and the associated at risk components, as predicted by the fault propagation model. Ph. D. Committee Chair: Vachtsevanos, George; Committee Member: Liang, Steven; Committee Member: Michaels, Thomas; Committee Member: Vela, Patricio; Committee Member: Wardi, Yora...|$|E
40|$|International audienceIn this paper, an {{original}} method for bearing fault detection in high speed synchronous machines is presented. This method {{is based on}} the statistical process of Welch's periodogram of the stator currents in order to obtain stable and normalized fault indicators. The principle of the method is to statistically compare the current spectrum to a healthy reference so as to quantify the changes over the time. A statistic-based indicator is then constructed by monitoring speciﬁc harmonic family. The proposed method was tested on two experimental test campaigns for four diﬀerent speeds and compared to a vibration indicator. The method was evaluated using a rigorous performance evaluation metric. A threshold evaluation was performed and shows that the proposed method is very tolerant to the machine speed. Thus, the use of an unique <b>fault</b> <b>threshold</b> whatever the speed can be considered. Results showed excellent agreement as compared with the vibration indicator, with an overall correlation of r = 0. 74 and only 4 % of false alarms. Performance demonstrated by this novel method was superior to those of a classical energy-based indicator in terms of correlation with the vibration indicator and detection stability. Moreover, results showed also a better robustness of the proposed method since good performance can be obtained with the same detection threshold whatever the speed or the measure campaign whereas it needs to be redeﬁned for each case with the classical indicator. This work shows the advantages of a statistic-based approach in order to increase the robustness of bearing fault detection in permanent-magnet synchronous machines...|$|E
30|$|The {{waveforms}} {{during three}} {{phase to ground}} fault is shown in Fig.  6. The fault is again introduced at 0.5  s. The residual voltage and residual current waveforms calculated according to residual system state equation are shown in Fig.  7. According to Theorem 4, the <b>fault</b> detection <b>threshold</b> is Jth[*]=[*] 2.62 * 104. As seen from the simulation, when t[*]>[*] 0.52  s, the system fault is detected.|$|R
40|$|A model-based fault {{detection}} algorithm assuming uncertain process parameters {{is used for}} detecting poorly operating lambda-tuned control loops. The a priori information obtained from lambda-tuning is used to create an observer as residual generator. The observer has integral action which {{makes it possible to}} obtain a tight <b>fault</b> detection <b>threshold.</b> A linear optimization approach is used for finding the parameters in the threshold. Godkänd; 2006; 20061228 (ysko...|$|R
30|$|The {{waveforms}} during phase-AB {{to ground}} fault {{are shown in}} Fig.  4 where the fault is introduced at 0.5  s. Due {{to the existence of}} various disturbances and uncertainties in the system, measurement noise is inevitably introduced when measuring system output. The residual voltage and residual current waveforms are shown in Fig.  5. According to Theorem 4, the <b>fault</b> detection <b>threshold</b> is Jth[*]=[*] 0.136 * 104. As seen from the simulation, when t[*]>[*] 0.52  s, the fault is detected.|$|R
40|$|CARE 3 MENU generates {{an input}} file for the CARE III program. CARE III {{is used for}} {{reliability}} prediction of complex, redundant, fault-tolerant systems including digital computers, aircraft, nuclear and chemical control systems. The CARE III input file often becomes complicated and is not easily formatted with a text editor. CARE 3 MENU provides an easy, interactive method of creating an input file by automatically formatting a set of user-supplied inputs for the CARE III system. CARE 3 MENU provides detailed on-line help {{for most of its}} screen formats. The reliability model input process is divided into sections using menu-driven screen displays. Each stage, or set of identical modules comprising the model, must be identified and described in terms of number of modules, minimum number of modules for stage operation, and critical <b>fault</b> <b>threshold.</b> The fault handling and fault occurence models are detailed in several screens by parameters such as transition rates, propagation and detection densities, Weibull or exponential characteristics, and model accuracy. The system fault tree and critical pairs fault tree screens are used to define the governing logic and to identify modules affected by component failures. Additional CARE 3 MENU screens prompt the user for output options and run time control values such as mission time and truncation values. There are fourteen major screens, many with default values and HELP options. The documentation includes: 1) a users guide with several examples of CARE III models, the dialog required to input them to CARE 3 MENU, and the output files created; and 2) a maintenance manual for assistance in changing the HELP files and modifying any of the menu formats or contents. CARE 3 MENU is written in FORTRAN 77 for interactive execution and has been implemented on a DEC VAX series computer operating under VMS. This program was developed in 1985...|$|E
40|$|Safe and {{permanent}} storage {{of carbon dioxide}} in geologic reservoirs is critical to geologic sequestration. The objective {{of this study is}} to quantify the conditions under which a general (simulated) fault network and a specific (field case) fault network will fail and leak carbon dioxide out of a reservoir. Faults present a potential fast-path for CO{sub 2 } leakage from reservoirs to the surface. They also represent potential induced seismicity hazards. It is important to have improved quantitative understandings of the processes that trigger activity on faults and the risks they present. Fortunately, the conditions under which leakage along faults is induced can be predicted and quantified given the fault geometry, reservoir pressure, an in-situ stress tensor. We proposed to expand the current capabilities of <b>fault</b> <b>threshold</b> characterization and apply that capability to a site where is CO{sub 2 } injection is active or planned. Specifically, we proposed to use a combination of discrete/explicit and continuum/implicit codes to provide constrain the conditions of fault failure. After minor enhancements of LLNL's existing codes (e. g., LDEC), we would create a 3 D synthetic model of a common configuration (e. g., a faulted dome). During these steps, we will identify a field site where the necessary information is available and where the operators are willing to share the necessary information. We would then execute an analysis specific to the field case. The primary products by quarter are: 1 Q [...] Identification of likely field case; 2 Q [...] Functioning prototype fault model; 3 Q [...] Execution of fault-slip/migration calculation for synthetic case; and 4 Q [...] Begin simulation of fault-slip/migration calculation for field system. It is worth noting that due to the continuing resolution, we did not receive any funds until 3 Q, and did not receive > 65 % of the support until 4 Q. That said, we were still able to meet all of our milestones for FY 07 on time and on budget...|$|E
40|$|The latest {{technologies}} of integrated circuit manufacturing allow billions of transistors to be arranged {{on a single}} chip, enabling us to implement a complex parallel system, which requires a communications architecture with high scalability and high degree of parallelism, such as a Network-on-Chip (NoC). These technologies {{are very close to}} physical limitations, which increases the quantity of faults in circuit manufacturing and at runtime. Therefore, it is essential to provide a method for fault recovery that would enable the NoC to operate in the presence of faults and still ensure deadlock-free routing. The preprocessing of the most probable fault scenarios allows us to anticipate the calculation of deadlock-free routing, reducing the time that is necessary to interrupt the system during a fault occurrence. This work proposes a technique that employs the preprocessing of fault scenarios based on forecasting fault tendencies, which is performed with a <b>fault</b> <b>threshold</b> circuit operating in agreement with high-level software. The technique encompasses methods for dissimilarity analysis of scenarios based on cross-correlation measurements of fault link matrices, which allow us to define a reduced and efficient set of fault coverage scenarios. Experimental results employing RTL simulation with synthetic traffic prove the quality of the analytic metrics that are used to select the preprocessed scenarios. Furthermore, the experiments show the efficacy and efficiency of the proposed dissimilarity methods, quantifying the latency penalization when using the coverage scenarios approach. As Ãltimas tecnologias de fabricaÃÃo de circuitos integrados habilitam bilhÃes de transistores a serem postos em um Ãnico chip, permitindo implementar um sistema paralelo complexo, o qual requer uma arquitetura de comunicaÃÃo que tenha grande escalabilidade e alto grau de paralelismo, tal como uma rede intrachip, em inglÃs, Network-on-Chip (NoC). Estas tecnologias estÃo muito prÃximas de limitaÃÃes fÃsicas, aumentando a quantidade de falhas na fabricaÃÃo dos circuitos e em tempo de operaÃÃo. Portanto, Ã essencial fornecer um mÃtodo para recuperaÃÃo de falha que permita a NoC operar na presenÃa de falhas e ainda garantir roteamento livre de deadlock. O prÃ-processamento de cenÃrios de falha mais provÃveis permite antecipar o cÃlculo de rotas livres de deadlock, reduzindo o tempo necessÃrio para interromper o sistema durante a ocorrÃncia de uma falha. Esta tese propÃe uma tÃcnica que emprega o prÃ-processamento de cenÃrios de falha baseado na previsÃo de tendÃncia de falhas, a qual Ã realizada com um circuito de limiar de falha operando em conjunto com um software de alto nÃvel. A tÃcnica contempla anÃlises de mÃtodos de dissimilaridade de cenÃrios baseadas na correlaÃÃo cruzada de matrizes bidimensionais de conexÃes com falha, que permite definir um conjunto reduzido e eficiente de cenÃrios de cobertura de falhas. Resultados experimentais, empregando simulaÃÃo com precisÃo em nÃvel de ciclo e trÃfego sintÃtico, provam a qualidade das mÃtricas analÃticas usadas para selecionar os cenÃrios prÃ-processados. AlÃm do mais, os experimentos mostraram a eficÃcia e eficiÃncia dos mÃtodos de dissimilaridades propostos, quantificando a penalizaÃÃo de latÃncia no uso da abordagem de cenÃrios de cobertura...|$|E
40|$|Abstract — Proper {{detection}} of various faults occurring on {{the transmission line}} is very essential. In this paper, detection and classification of some these faults is done {{based on the information}} conveyed by the wavelet analysis of power systems transients. Maximum norm values, maximum detail coefficient, energy of the current signals are calculated from the Wavelet Toolbox in MATLAB/Simulink. Maximum norm value and energy of the signals detects the <b>fault</b> and <b>threshold</b> detail coefficient classifies the faul...|$|R
40|$|Statistical filter based sensor {{and data}} {{acquisition}} (DAQ) fault detection {{is presented in}} this study. The parameters of a large-scale data set of ship performance and navigation information are considered as statistical distributions and principal component analysis (PCA) is used to identify the hidden structure of the same data set. This data set relates to a specific operating region of the main engine, where ship performance and navigation conditions can be linearized. The structure derived under PCA is further investigated to identify the respective sensor and DAQ fault situations as the main contribution. That is done by projecting the same data set into the respective principal components, where {{a new set of}} ship performance and navigation parameters is derived. Then, the respective parameter variance values of the new data set are calculated and the thresholds that relate to the same variance values for detecting sensor and DAQ fault situations are derived. Finally, the data set of ship performance and navigation information is analyzed through these <b>fault</b> <b>thresholds</b> and the successful results on identifying complex fault situations are presented in this study. Hence, this approach can be used to develop advanced sensor and DAQ fault detection and isolation methodologies of ship performance and navigation monitoring systems...|$|R
40|$|We {{demonstrate}} new experimental {{procedures for}} measuring small errors in a superconducting quantum bit (qubit). By carefully separating out gate and measurement errors, we construct a complete error budget and demonstrate single qubit gate fidelities of 0. 98, limited by energy relaxation. We also {{introduce a new}} metrology tool [...] a Ramsey interference error filter [...] that can measure the occupation probability of the state | 2 〉 down to 10 ^- 4, a magnitude near the <b>fault</b> tolerant <b>threshold.</b> Comment: 5 pages. 5 figures. Submitted to Physical Review Letter...|$|R
