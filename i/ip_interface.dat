37|112|Public
5000|$|Transfer those clips {{to other}} video servers or playout {{directly}} (via <b>IP</b> <b>interface</b> or SDI) ...|$|E
50|$|NetFlow usually captures all packets {{received}} by an ingress <b>IP</b> <b>interface,</b> but some NetFlow implementations use IP filters {{to decide if}} a packet can be observed by NetFlow.|$|E
50|$|Some NetFlow {{implementations}} {{also allow}} {{the observation of}} packets on the egress <b>IP</b> <b>interface,</b> but this must be used with care: all flows from any ingress interface with NetFlow enabled to any interface with NetFlow enabled could be counted twice.|$|E
50|$|Ground station {{equipment}} may be monitored and controlled remotely, often via serial and/or <b>IP</b> <b>interfaces.</b>|$|R
5000|$|Security for block-based storage {{systems with}} Fibre Channel and <b>IP</b> <b>interfaces</b> (above {{and beyond the}} storage {{networking}} materials) ...|$|R
40|$|Usually, {{a set of}} Traceroute {{measurements}} {{collected for}} {{a large amount of}} target IPs contain one or several route hops at which the <b>IP</b> <b>interfaces</b> vary from one measurement to another. These variations occur even if several measurements share the same length and the same last hops. This is likely a consequence of load balancing, a traffic engineering policy which aims at sharing the load to ensure quality of service. In this paper, we consider the problem of conducting alias resolution on <b>IP</b> <b>interfaces</b> discovered via Traceroute and which are involved in load balancing. By conducting alias resolution in such a context, we want to verify if the <b>IP</b> <b>interfaces</b> involved in load balancing belong to unique routers, and more broadly, how relevant is alias resolution in this context. To do so, we use a slightly edited version of TreeNET, a topology discovery tool which relies on a tree-like structure based on Traceroute measurements to map a target domain. The upgraded TreeNET along the measurements described in this paper are both freely available online. Peer reviewe...|$|R
5000|$|Type 2 - Network LSA - the {{designated}} router (DR) on a broadcast segment (e.g. Ethernet) lists which routers are joined {{together by the}} segment. Type 2 LSAs are flooded across their own area only. The link-state ID of the type 2 LSA is the <b>IP</b> <b>interface</b> address of the DR.|$|E
50|$|RANAP {{signalling}} protocol {{resides in the}} control plane of Radio network layer of Iu interface in the UMTS (Universal Mobile Telecommunication System) protocol stack. Iu interface is the interface between RNC (Radio Network Controller) and CN (Core Network). nb. For Iu-ps transport RANAP is carried on SCTP if <b>IP</b> <b>interface</b> used on this.|$|E
50|$|The gateway address must be {{configured}} on each host. The network host <b>IP</b> <b>interface</b> binds {{the gateway}} {{address to the}} MAC address of the physical gateway by broadcasting IP datagrams and caching the MAC address of the reply from the gateway in an ARP table stored on the host. The gateway address may be added manually. On Windows computers, the gateway address is configured using the TCP/IP Properties.|$|E
50|$|A Virtual Layer-3 Switch is the software-emulated virtual IP router. Several Virtual Layer-3 Switches can {{be created}} on a single VPN Server instance. A Virtual Layer-3 Switch has virtual <b>IP</b> <b>interfaces</b> {{connected}} to Virtual Hubs. It also has several static routing table entries.|$|R
3000|$|..., and Motion Compensation (MC) for decoding. An <b>IP</b> memory <b>interface</b> is {{provided}} by the architecture to achieve the integration. All IP modules are connected to the <b>IP</b> memory <b>interface,</b> which provides accelerators a straight way to exchange data between the host and memory spaces. Interrupt signals can be generated by accelerators when demanded. Moreover, to control the concurrent performance of accelerators, an IP bus arbitrator is designed and integrated in the <b>IP</b> memory <b>interface,</b> for the interface controller to allocate appropriate memory operation time for each IP module, and avoid the memory access conflicts possibly caused by heterogeneous IP operations.|$|R
50|$|Gn: <b>IP</b> based <b>interface</b> between SGSN {{and other}} SGSNs and (internal) GGSNs. DNS also shares this interface. Uses the GTP Protocol.|$|R
50|$|Media gateway {{protocols}} {{were developed}} {{based on the}} Internet model of networking, the Internet Protocol Suite, and {{are referred to as}} device control protocols. A media gateway is a device that offers an <b>IP</b> <b>interface</b> and a legacy telephone interface and that converts media, such as audio and video streams, between them. The legacy telephone interface may be complex, such as an interface to a PSTN switch, or may be a simple interface to a traditional telephone. Depending on the size and purpose of the gateway, it may allow IP-originated calls to terminate to the PSTN or vice versa, or may simply provide a means to connect a telephone to a telecommunication system via an IP network.|$|E
50|$|The MicroBlaze has a {{versatile}} interconnect system {{to support a}} variety of embedded applications. MicroBlaze's primary I/O bus, the CoreConnect PLB bus, is a traditional system-memory mapped transaction bus with master/slave capability. A newer version of the MicroBlaze, supported in both Spartan-6 and Virtex-6 implementations, {{as well as the}} 7-Series, supports the AXI specification. The majority of vendor-supplied and third-party <b>IP</b> <b>interface</b> to PLB directly (or through a PLB to OPB bus bridge). For access to local-memory (FPGA RAM), MicroBlaze uses a dedicated LMB bus, which reduces loading on the other buses. User-defined coprocessors are supported through a dedicated FIFO-style connection called FSL (Fast Simplex Link). The coprocessor(s) interface can accelerate computationally intensive algorithms by offloading parts or the entirety of the computation to a user-designed hardware module.|$|E
5000|$|... 1983. First {{opportunity}} to fix addressing missed. The need for application names and distributed directories that mapped application names to internetwork addresses was well understood since mid-1970s. They {{were not there}} at the beginning {{since it was a}} major effort and there were very few applications, but they were expected to be introduced once the “host file” was automated (the host file was centrally maintained and mapped human-readable synonyms of addresses to its numeric value). However, application names were not introduced and DNS, the Domain Name System, was designed and deployed, continuing to use well-known ports to identify applications. The advent of the web and HTTP caused the need for application names, introducing URLs. However the URL format ties each application instance to a physical interface of a computer and a specific transport connection (since the URL contains the DNS name of an <b>IP</b> <b>interface</b> and TCP port number), making multi-homing and mobility very hard to achieve.|$|E
40|$|The growing {{requirements}} on the correct {{design of a}} highperformance system {{in a short time}} force us to use IP’s in many designs. In this paper, we propose a new approach to select the optimal set of <b>IP’s</b> and <b>interfaces</b> to make the application program meet the performance constraints in ASIP designs. The proposed approach selects <b>IP’s</b> with considering <b>interfaces</b> and supports concurrent execution of parts of task in kernel as software code with others in IP’s, while the previous state-of-the-art approaches do not consider <b>IP’s</b> and <b>interfaces</b> simultaneously and cannot support the concurrent execution. The experimental results on real applications show that the proposed approach is effective in making application programs meet the performance constraints using IP’s. ...|$|R
40|$|Platform-based {{design is}} a method to {{implement}} complex SoCs, avoiding chip design from scratch. A promising evolution of platform-based design are MPSoC. Such generic architectures might furnish enough performance for several classes of embedded systems. An associated advantage of these architectures is flexibility at the software level. In principle, hardware is not flexible. Thus, dedicated IP blocks must be inserted before chip design, or enough area can be reserved for them when using reconfigurable blocks. Dynamic self-reconfigurable systems (DSRSs) introduce flexibility to hardware. In DSRSs, IP blocks are loaded according to application demand, reducing area, power consumption and system cost. An MPSoC based platform, associated with dynamic reconfiguration, provides both hardware and software flexibility. This paper has two main goals. First, to present the necessary infrastructure for DSRSs, identifying which components are required in these systems, such as a configuration controller, configuration ports and reconfigurable <b>IP</b> <b>interfaces.</b> The second objective is to discuss practical implementations choices and area-performance tradeoffs. The paper employs case studies to access the advantages and problems related to different implementations for the communication infrastructure (bus and NoC), the configuration controller (hardware and software) and <b>IP</b> <b>interfaces</b> (LUT and tristate based) ...|$|R
50|$|Gi: <b>IP</b> based <b>interface</b> {{between the}} GGSN {{and a public}} data network (PDN) either {{directly}} to the Internet or through a WAP gateway.|$|R
50|$|Radio over Internet Protocol, or RoIP, {{is similar}} to Voice over IP (VoIP), but augments two-way radio {{communications}} rather than telephone calls. From the system point of view, it is essentially VoIP with PTT (Push To Talk). To the user it can be implemented like any other radio network. With RoIP, at least one node of a network is a radio (or a radio with an <b>IP</b> <b>interface</b> device) connected via IP to other nodes in the radio network. The other nodes can be two-way radios, but could also be dispatch consoles either traditional (hardware) or modern (software on a PC), POTS telephones, softphone applications running on a computer such as Skype phone, PDA, smartphone, or some other communications device accessible over IP. RoIP can be deployed over private networks {{as well as the}} public Internet. It is useful in land mobile radio systems used by public safety departments and fleets of utilities spread over a broad geographic area. Like other centralized radio systems such as trunked radio systems, issues of delay or latency and reliance on centralized infrastructure can be impediments to adoption by public safety agencies.|$|E
40|$|In this paper, {{we present}} a Design for Reuse {{technique}} suitable for Soft IP cores, implemented as algorithmic or RT synthesis model, that focuses on customizable <b>IP</b> <b>interface</b> implementations. By exploiting the features of VHDL+, an extension to VHDL, we separate the specifications of the IP functional behaviour and <b>IP</b> <b>interface</b> protocols into different design units. Interface customization is done through specification of system specific interface communication protocols, followed by an <b>IP</b> <b>interface</b> generation at signal level with our tool MODIS...|$|E
3000|$|A {{convergence}} protocol (PDCP) responsible for <b>IP</b> <b>interface</b> and related functions (header compression, ciphering, etc.) [...]...|$|E
50|$|Sockets Direct Protocol only {{deals with}} stream sockets, and if {{installed}} in a system, bypasses the OS resident TCP stack for stream connections between any endpoints on the RDMA fabric. All other socket types (such as datagram, raw, packet, etc.) are supported by the Linux IP stack and operate over standard <b>IP</b> <b>interfaces</b> (i.e., IPoIB on InfiniBand fabrics). The IP stack has no dependency on the SDP stack; however, the SDP stack depends on IP drivers for local IP assignments and for IP address resolution for endpoint identifications.|$|R
50|$|Gp: <b>IP</b> based <b>interface</b> between {{internal}} SGSN {{and external}} GGSNs. Between the SGSN and the external GGSN, {{there is the}} border gateway (which is essentially a firewall). Also uses the GTP Protocol.|$|R
50|$|The switch {{architecture}} for the ERS 8800 supports up to 720 gigabits {{per second}} of gross throughput. The Switch Fabric performs up to 512 Gigabits per second in an active/active configuration with a frame forwarding rate of up to 380 million packets per second. The frame length is from 64 to 1,518 bytes, with Jumbo frame support of up to 9,600 bytes. The 8800 supports up to 128 groups of multi-link trunks, with 8 links per group; additionally, it can also support up to 4,000 VLANs, 32 multiple spanning tree groups, 64 thousand MAC addresses, and 1,972 <b>IP</b> <b>interfaces.</b>|$|R
40|$|This memo {{defines a}} data {{structure}} {{that can be}} appended to selected ICMP messages. The ICMP extension defined herein {{can be used to}} identify any combination of the following: the <b>IP</b> <b>interface</b> upon which a datagram arrived, the sub-IP component of an <b>IP</b> <b>interface</b> upon which a datagram arrived, the <b>IP</b> <b>interface</b> through which the datagram would have been forwarded had it been forwardable, and the IP next hop to which the datagram would have been forwarded. Devices can use this ICMP extension to identify interfaces and their components by any combination of the following: ifIndex, IPv 4 address, IPv 6 address, name, and MTU. ICMP-aware devices can use these extensions to identify both numbered and unnumbered interfaces...|$|E
40|$|Extending ICMP for Interface and Next-Hop Identification This memo {{defines a}} data {{structure}} {{that can be}} appended to selected ICMP messages. The ICMP extension defined herein {{can be used to}} identify any combination of the following: the <b>IP</b> <b>interface</b> upon which a datagram arrived, the sub-IP component of an <b>IP</b> <b>interface</b> upon which a datagram arrived, the <b>IP</b> <b>interface</b> through which the datagram would have been forwarded had it been forwardable, and the IP next hop to which the datagram would have been forwarded. Devices can use this ICMP extension to identify interfaces and their components by any combination of the following: ifIndex, IPv 4 address, IPv 6 address, name, and MTU. ICMP-aware devices can use these extensions to identify both numbered and unnumbered interfaces...|$|E
30|$|The {{approach}} {{developed and}} tested with 3 G/UMTS can be migrated to 4 G/LTE-based systems, albeit {{with a few}} modifications, due to technological differences. The baseband processing in the network nodes is performed by similar resources, conceptually equivalent to CE. On the other hand, the radio carrier capacity is no longer defined by SC tree, standard in CDMA. In LTE, the radio channel will be divided into multiple radio carriers and transmitted using frequency multiplexing techniques such as OFDMA. Full <b>IP</b> <b>interface</b> S 1 replaces Iub, and links the E-NodeB directly to the gateway, bypassing the current RNC. Consequently, the model can be extended by redefining the module of radio interface resource occupation and modeling appropriately the new <b>IP</b> <b>interface,</b> S 1. In addition, CE per service consumption table needs to be updated. Future development roadmap includes developing the 4 G/LTE version of the model incorporating real system evaluations of real operative 4 G networks {{as soon as they}} become available. At the time of publication, small demonstrative clusters are deployed, but none is yet in production service.|$|E
5000|$|The VSP 9000 {{supports}} up to 240 10 Gigabit Ethernet {{ports and}} is future-ready to support 40 Gigabit Ethernet and 100 Gigabit Ethernet ports which speed over a 100 Terabit per second Switch Cluster. The chassis also supports Shortest Path Bridging, Provider link state bridging, and Split multi-link trunking {{at up to}} 480 trunks with 16 links per trunk group. This product can also maintain over 4000 VLANs and <b>IP</b> <b>interfaces</b> with support for up to ten thousand static IP routes over an IP forwarding table with 500 thousand entires. Some more technological performance measures are as follows: ...|$|R
5000|$|Router id {{is highest}} <b>interface</b> <b>IP</b> or highest {{loopback}} IP if one exists ...|$|R
40|$|With {{ubiquitous}} computing and network access now a reality, multiple network conduits are become widely available to mobile {{as well as}} static hosts: for instance wired connections, 802. 11 style LANs, Bluetooth, and cellular phone modems. Selection of the preferred mode of data transfer is a dynamic optimization problem which depends {{on the type of}} application, its bandwidth/latency/jitter requirements, current network conditions (such as congestion or traffic patterns), cost, power consumption, battery life, and so on. Furthermore, since wireless bandwidth is likely to remain a scarce resource, we foresee scenarios wherein mobile hosts will require simultaneous data transfer across multiple <b>IP</b> <b>interfaces</b> to obtain higher overall bandwidth...|$|R
40|$|In {{relativistic}} {{heavy ion}} reactions {{which can be}} studied at large particle accelerator facilities such as GSI Darmstadt [1], large amounts of event data are generated by the detectors, typically {{in the order of}} several Gbytes/s. Among all of these events, only a small proportion is of interest due to its particular physics content and should be selected in realtime for later analysis and storage. It is impractical and very expensive to store the entire data set and perform the selection offline. Thus, a specifically designed event selector before the final storage or analysis system could be used to discard a major fraction of background events with little loss of the interesting events. One main task of this thesis project is to design an event selector in VHDL. The event selector contains two parts: <b>IP</b> <b>Interface</b> and User IP. The <b>IP</b> <b>interface</b> realizes event data transferring between DDR SDRAM and FIFOs inside the event selector by using DMA and interrupt services. User IP is the algorithm part to select interesting events from a large number of background events...|$|E
40|$|A {{multi-port}} memory controller (MPMC) {{is used in}} applications where multiple devices share {{a common}} memory controller. An MPMC is a common requirement in many video, embedded, and communications applications where data from multiple sources moves through a common memory device, typically DDR 3 SDRAM. This application note demonstrates {{how to create a}} basic DDR 3 MPMC design using a 7 series FPGA and the Vivado ™ Design Suite [Ref 1]. The MPMC is created by combining the Memory Interface Generator (MIG) core and the AXI Interconnect IP, both of which are provided in the Vivado tools. AXI is a standardized <b>IP</b> <b>interface</b> protocol based on the Advanced Microcontroller Bus Architecture (AMBA ® 4) specification [Ref 2]. This reference design uses the AXI 4, AXI 4 -Lite, and AXI 4 -Stream interfaces as described in the AXI 4 specification. These interfaces provide a common <b>IP</b> <b>interface</b> protocol framework for building the system. Overview The example design in this application note is a full working hardware system on the KC 705 evaluation board in the Xilinx Kintex™- 7 FPGA KC 705 Evaluation Kit [Ref 3]...|$|E
40|$|This paper {{describes}} {{the implementation of}} an ATM protocol stack as a protocol family within a 4. 3 BSD derived Unix. A novel approach {{to the implementation of}} the management and control functions for the ATM protocol stack has been adopted. The data path is implemented within the kernel but all control and management functions are implemented by a user space daemon. An encapsulation of IP on the ATM protocol is provided by means of a logical <b>IP</b> <b>interface.</b> The mapping of IP addresses to ATM addresses is performed by the user space daemon...|$|E
40|$|Abstract The article {{analyzes}} {{the influence of}} the Internet Protocol (<b>IP)</b> access <b>interface</b> on the packet loss probability and delay times in the optical packet switched network. The network and node model have been proposed, and the structure of the <b>IP</b> access <b>interface,</b> including assembler and holder, have been included in the analysis. It has been shown that the increase of the maximum optical packet sizes, as well as use of the holding feature as contention resolution mechanism, decrease the packet loss probability, but introduce delays at the optical network access points. Modeling and analysis were based on the discrete event simulation assuming self-similar traffic sources. IP packet lengths were modeled using empirical data...|$|R
50|$|Prior to IP telephony, {{when you}} wanted to connect a {{telecommunications}} system to a telecom network {{it was necessary to}} have a telecom-specific physical interface. This could mean an analog interface (POTS/DS-0), for low-density non-network systems, or a digital interface, such as a T-1 or E-1 line (DS-1, delivering 24 or 32 DS-0s). A DS-4 connection delivers 274.176 Mbit/s or 4032 DS-Os. In each case, telecom-specific electronic interfaces, which were proprietary and, therefore, relatively expensive, were necessary. The situation changes dramatically with an all-IP telecom infrastructure. The network interfaces move from being a significant proprietary component to off-the-shelf high-performance <b>IP</b> <b>interfaces,</b> an inherent feature in every modern computing system. Today, 10-Gigabit Ethernet' telephony systems are being deployed.|$|R
40|$|DESCRIPTION Embedded System Design with VivadoTM Design Suite {{software}} for ZynqTM System-on Chip. Software implementation with the Software Development Kit (SDK). Hardware/software co-design: creation of custom-defined VHDL <b>IP</b> cores, <b>interfacing</b> with the AXI bus, and creating software applications {{to control the}} VHDL IP cores...|$|R
