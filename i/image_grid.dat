76|374|Public
50|$|Vidoop's core {{technology}} is the Vidoop Dynamic <b>Image</b> <b>Grid,</b> a login tool that powers Vidoop Secure and thus myVidoop.com. The company also sells advertising space, allowing a company to place its products as images in the grid. There are currently two multi-national advertisers: Smart USA (a division of Daimler) and ConocoPhillips (Phillips66, Conoco, and 76 brand gas stations). One regional advertiser: Mazzio's. And one local advertiser: Jackie Cooper Imports (A local Tulsa, OK auto dealer).|$|E
5000|$|... dBase {{features}} an IDE with a Command Window and Navigator, a just-in-time compiler, a preprocessor, a virtual-machine interpreter, a linker for creating dBase application [...]EXEs, a freely available runtime engine, and numerous two-way GUI design tools including a Form Designer, Report Designer, Menu Designer, Label Designer, Datamodule Designer, SQL Query Designer, and Table Designer. Two-way Tools {{refers to the}} ability to switch back and forth between using a GUI design tool and the source code editor. Other tools include a Source Code Editor, a Project Manager that simplifies building and deploying a dBase application, and an integrated Debugger. dBase features structured exception handling and has many built-in classes that can be subclassed via single inheritance. There are visual classes, data classes, and many other supporting classes. Visual classes include Form, SubForm, Notebook, Container, Entryfield, RadioButton, SpinBox, ComboBox, ListBox, PushButton, <b>Image,</b> <b>Grid,</b> ScrollBar, ActiveX, Report, ReportViewer, Text, TextLabel and many others. Database classes include Session, Database, Query, Rowset, Field, StoredProc and Datamodule classes. Other classes include File, String, Math, Array, Date, Exception, Object and others. dBase objects can be dynamically subclassed by adding new properties to them at runtime.|$|E
30|$|It {{should be}} noted that the size of the images {{obtained}} by the first and second database is 256 [*]×[*] 256 and the size of the images obtained by the third, fourth and fifth databases is 320 [*]×[*] 320. For an image of size 256 [*]×[*] 256, an <b>image</b> <b>grid</b> of size 32 [*]×[*] 32 is considered suitable and is fed into CT through an iterative procedure. The <b>image</b> <b>grid</b> is further decomposed to four subbands of size 16 [*]×[*] 16. For an image of size 320 [*]×[*] 320, an <b>image</b> <b>grid</b> of size 40 [*]×[*] 40 is considered suitable for CT decomposition. In this case, the obtained four subbands’ size is 20 [*]×[*] 20. The size of the <b>image</b> <b>grid</b> is experimentally determined as the minimum of the negative power of two of the original image size, which maintains an edge region.|$|E
40|$|Microarray <b>image</b> <b>gridding</b> is one {{important}} step of microarray image analysis to determine 2 D image coordinates of all array {{spots in the}} hybridized gene chip image. Accuracy of <b>image</b> <b>gridding</b> will affect the reliability of gene-chip data extraction and even the final analysis results of gene-chip assays. To promote microarray <b>image</b> <b>gridding</b> accuracy and computation efficiency, we presented a microarray <b>image</b> <b>gridding</b> method based on image projection transformation and power spectral analysis. Firstly we transformed 2 D microarray image into vertical and horizontal 1 D projection sequences, secondly utilized signal processing methods of low pass filtering, zero mean, FFT, and power spectral estimation by periodogram method to get spots array row and column span information, and finally realized the microarray <b>image</b> <b>gridding</b> according to the local maxima and span information of spots array. The gridding experiments showed that this method had met the requirements of computing accuracy and efficiency of microarray <b>image</b> <b>gridding...</b>|$|R
40|$|Microarray <b>image</b> <b>gridding</b> is one {{important}} step of microarray image analysis to determine 2 D image coordinates of all array {{spots in the}} hybridized gene chip image. Accuracy of microarray <b>image</b> <b>gridding</b> will affect the reliability of gene-chip data extraction and even the final analysis results of gene-chip assays. However, in recent years, many new microarray <b>image</b> <b>gridding</b> methods presented have higher accuracy but have more computation complexity than those precedented ones. To promote gridding accuracy and decrease computation complexity simultaneously, we presented a novel and simple microarray <b>image</b> <b>gridding</b> method based on image projection sequences analysis and local extrema searching. Firstly we transformed 2 D microarray image into vertical and horizontal 1 D projection sequences, secondly utilized signal processing methods of low pass filtering and zero mean to filtered projection sequences, thirdly computed the first-order difference and second-order difference for the smoothed signals, and finally realized microarray <b>image</b> <b>gridding</b> according to the local extrema of difference sequences and span information of spots array on the microarray <b>image.</b> The subsequent <b>gridding</b> experiments showed that this method had met the requirements of computing accuracy and efficiency of microarray <b>image</b> <b>gridding.</b> Academy of Mathematics and Systems Science; IEEE Robotics and Automation Society; IEEE Control Systems Society; National Natural Science Foundation of China; Chinese Association of Automatio...|$|R
3000|$|... n/N)). The gray {{values of}} neighbors {{that are not}} in the <b>image</b> <b>grids</b> can be {{calculated}} by interpolation. The step function s(x) is described with s(x)= 1 if x≥ 0 and s(x)= 0 otherwise. The minimum value in Eq. (1) denotes the label of the rotation invariant LBP at the central pixel.|$|R
40|$|This {{document}} describes equations {{and relations}} {{needed for the}} panorama stitching assignment in the course TSBB 09 Image Sensors. We define the camera calibration matrix and rotational homographies, and solve the Orthogonal Procrustes problem. We also describe the axis-angle parametrisation, points on the unit sphere, and spherical coordinates. 1 Image Plane and <b>Image</b> <b>Grid</b> The image plane is the 3 D plane where the image sensor is located, see figure 1. By the <b>image</b> <b>grid</b> we instead mean the grid of image pixels grabbed by the sensor. Whereas the image plane has physical dimensions, {{the dimensions of the}} <b>image</b> <b>grid</b> are measured in numbers of pixels. The camera coordinate system (CCS) is a 3 D coordinate system centred in a point known as the optical centre, see figure 1. In the ideal pin-hole camera, the optical centre is the pin hole, and for the ideal thin lens camera, the optical centre is the centre of the lens. Conversions between CCS coordinates and <b>image</b> <b>grid</b> coordinates (hereafter image coordinates) are performed using the camera calibration matrix. The camera calibration matrix K is a 3 × 3 matrix which maps a point X ∈ R 3 in the CCS to image coordinates according to: x ̃ ∼ KX. (1) Here x ̃ = (sx, sy, s) T ∈ P 2 is the homogeneous representation of an image point x = (x, y) T ∈ R 2. 1 Real <b>image</b> <b>grid</b> i pr(c,c) x y...|$|E
3000|$|... on the <b>image</b> <b>grid,</b> {{except when}} {{either one of}} the two targets or both are close to the image borders. Finally, for [...]...|$|E
3000|$|... {{and finding}} the maximum over the <b>image</b> <b>grid</b> of the sum of {{likelihood}} maps weighted by the a priori probability for each state [...]...|$|E
40|$|A novel {{approach}} {{that uses the}} concepts of parallel imaging to grid data sampled along a non-Cartesian trajectory using GRAPPA operator gridding (GROG) is described. GROG shifts any acquired data point to its nearest Cartesian location, thereby converting non-Cartesian to Cartesian data. Unlike other parallel imaging methods, GROG synthesizes the net weight for a shift in any direction from a single basis set of weights along the logical k-space directions. Given the vastly reduced size of the basis set, GROG calibration and reconstruc-tion requires fewer operations and less calibration data than other parallel imaging methods for gridding. Instead of calcu-lating and applying a density compensation function (DCF), GROG requires only local averaging, as the reconstructed points fall upon the Cartesian grid. Simulations are performed {{to demonstrate that the}} root mean square error (RMSE) values of <b>images</b> <b>gridded</b> with GROG are similar to those for <b>images</b> <b>gridded</b> using the gold-standard convolution gridding. Finally, GROG is compared to the convolution gridding technique using data sampled along radial, spiral, rosette, and BLADE (a. k. a. periodically rotated overlapping parallel lines with enhance...|$|R
25|$|The <b>image</b> is <b>gridded</b> with a {{template}} and {{the intensities of}} each feature (composed of several pixels) is quantified.|$|R
25|$|<b>Image</b> analysis: <b>gridding,</b> spot {{recognition}} of the scanned image (segmentation algorithm), removal or marking of poor-quality and low-intensity features (called flagging).|$|R
40|$|In {{this paper}} we {{describe}} {{a study on}} <b>image</b> <b>grid</b> display with automatic vertical scrolling. While scroll operations are normally carried out manually by the user, {{in the context of}} RSVP (Rapid Serial Visual Presentation) techniques this work considers a presentation mode in which the <b>image</b> <b>grid</b> is automatically scrolled. Through experiments carried out with 50 testers, we have investigated user performance while looking for specific target subjects within large collections of images. Different numbers of columns and scrolling speeds have been considered. The search task implied both clicking on the identified target pictures and simply vocally stating their visual recognition. To this purpose, and to identify possible specific gaze behaviours, eye tracking technology has been exploited. The obtained results show that number of columns and scroll speed do affect search performance. Moreover, the userâs gaze tends to focus on different screen areas depending on the values of these two parameters. Although {{it is not possible to}} definitely find an optimal columnsâspeed combination that is valid in all cases, the particular context of use can suggest feasible solutions according to oneâs needs. To the best of our knowledge, <b>image</b> <b>grid</b> display with automatic scrolling has never been studied to date. Keywords: <b>Image</b> <b>grid</b> display, Automatic scrolling, Image presentation modes, Image collections, Rapid serial visual presentatio...|$|E
40|$|In this paper, {{a concept}} of {{multipurpose}} object detection system, recently introduced in our previous work, is clarified. The business aspect of this method is transformation of a classifier into an object detector/locator via an <b>image</b> <b>grid.</b> This is a universal framework for locating objects of interest through classification. The framework standardizes and simplifies implementation of custom systems by doing only a custom analysis of the classification results on the <b>image</b> <b>grid.</b> Comment: 3 pages, 2 figures, 6 refs. arXiv admin note: substantial text overlap with arXiv: 1310. 717...|$|E
30|$|Remark. Equation (8) {{assumes that}} the target's {{template}} is entirely located within the sensor <b>image</b> <b>grid.</b> Otherwise, for targets that {{are close to the}} image borders, the summation limits in (8) must be changed accordingly to take into account portions of the target that are no longer visible.|$|E
40|$|International audienceSpatial {{aliasing}} {{may affect}} methods based on <b>grid</b> <b>image</b> processing to retrieve displacement and strain maps in experimental mechanics. Such methods aim at estimating these maps {{on the surface}} of a specimen subjected to a loading test. Aliasing, which is often not noticeable to the naked eye in the <b>grid</b> <b>images,</b> may give spurious fringes in the strain maps. This paper presents an analysis of aliasing in this context and provides the reader with simple guidelines to minimize the effect of aliasing on strain maps extracted from <b>grid</b> <b>images...</b>|$|R
40|$|Arrays are an {{appropriate}} data model for <b>images,</b> <b>gridded</b> output from computational models, {{and other types}} of data. This paper describes an approach to array query processing. Queries are expressed in AML, a logical algebra that is easily extended with user-defined functions to support a wide variety of array operations. For example, compression, filtering, and algebraic operations on images can be described. We show how AML expressions involving such operations can be treated declaratively and subjected to useful rewrite optimizations. We also describe a plan generator that produces efficient iterator-based plans from rewritten AML expressions. ...|$|R
40|$|The present paper {{focuses on}} {{a new class of}} mesh filter for {{grayscale}} <b>images,</b> called <b>grid</b> smoothing filter. The framework presented considers an image as a sampling grid associated to a set of gray levels. Furthermore, the sampling grid is seen as mesh composed by vertices and edges, the number of vertices being equal to the number of pixels in the image. Embedding the mesh in a 2 D Euclidian space, each vertex has two spatial coordinates and one attribute, the value of the gray level. Starting from the classical formulation of Laplacian mesh filtering, a novel objective function is introduced. The minimization of the objective function leads to new spatial coordinates for the vertices in the mesh. A reconstruction mechanism is then applied to the non-uniform mesh to reconstruct a grayscale image. Whereas the Laplacian mesh filter aims at smoothing an <b>image,</b> the <b>grid</b> smoothing tends at sharpening the edges of the <b>image.</b> The <b>grid</b> smoothing framework is applied to image enhancement in this paper...|$|R
40|$|A non-rigid body {{registration}} algorithm {{was proposed}} by Kovalev and Petrou [1] where the <b>image</b> <b>grid</b> was deformed by localised deformation operators in order to optimise a global cost function. In this paper, we propose to implement this non-rigid body registration over a multiresolution pyramid {{in order to obtain}} large-scale deformations at the coarse levels and fine-detail deformations at the finer levels, resulting in faster convergence...|$|E
30|$|Scale {{invariant}} feature transform (SIFT) presents some {{advantages in}} terms of invariance to image scaling, translation, and rotation; accordingly, the use of SIFT does not require preprocessing stage, like accurate face alignment. Demirkus et al. [39] exploited these characteristics using a Markovian classification model, and Wang et al. [40] extracted SIFT descriptors at regular <b>image</b> <b>grid</b> points and combined them with global shape contexts of the face, adopting AdaBoost for classification.|$|E
40|$|The aims of {{this study}} are to develop a new method of extracting the image {{construct}} about health and to comprehends its image construct. One of the methods of extracting environmental evaluation structure formed through individual experience is the Evalution Grid Method. However, some problems were found when it was applied on the concept of health, and development of a new method was needed. 2 ̆ 7 <b>Image</b> <b>Grid</b> Method 2 ̆ 7 was developed based on Evaluation Grid Method. This method is the combination of remembering behavior settings and laddering them without presented elements comparing procedures As a result of the investigation using the new method, 10 behavior settings about health were found. Especially, important are 2 ̆ 7 exercise 2 ̆ 7, 2 ̆ 7 eating 2 ̆ 7 and 2 ̆ 7 sleep 2 ̆ 7. This kind of knowledge is useful for space design meeting the demands of health. This study shows that adopting the <b>Image</b> <b>Grid</b> Method is able to extract which could not be comprehend by the Evaluation Grid Method...|$|E
50|$|Most {{digital imaging}} systems display an <b>image</b> as a <b>grid</b> of tiny, square pixels. However, some imaging systems, {{especially}} those that must be compatible with standard-definition television motion pictures, display an <b>image</b> as a <b>grid</b> of rectangular pixels, in which the pixel width and height are different. Pixel Aspect Ratio describes this difference.|$|R
5000|$|... a GeoRaster {{feature to}} store, index, query, analyze, and deliver GeoRaster data (raster <b>image</b> and <b>gridded</b> data and its {{associated}} metadata) with virtual mosaics, raster-algebra operations, image processing, Java API, and GDAL-Based ETL Wizard ...|$|R
40|$|An {{important}} {{stage in}} microarray <b>image</b> analysis is <b>gridding.</b> Microarray <b>image</b> <b>gridding</b> {{is done to}} locate sub arrays in a microarray image and find co-ordinates of spots within each sub array. For accurate identification of spots, most of the proposed gridding methods require human intervention. In this paper a fully automatic gridding method which enhances spot intensity in the preprocessing step as per a histogram based threshold method is used. The gridding step finds co-ordinates of spots from horizontal and vertical profile of the image. To correct errors due to the grid line placement, a grid line refinement technique is proposed. The algorithm is applied on different image databases and results are compared based on spot detection accuracy and time. An average spot detection accuracy of 95. 06 % depicts the proposed method’s flexibility and accuracy in finding the spot co-ordinates for different database images...|$|R
30|$|Thus far, {{atmosphere}} phase {{for selected}} radar image pixels {{has been estimated}} using the permanent scatterer selection. Once the APSs have been estimated and resampled on the uniform <b>image</b> <b>grid,</b> data can be compensated for this phase contribution (Strozzi et al. 2005; Pipia et al. 2008). After accurate atmosphere phase estimation and removal, we can compute the displacement phase including the linear and nonlinear components on a pixel-by-pixel basis (Lee et al. 2008).|$|E
40|$|AbstractTo {{estimate}} {{the strength of}} automotive bodies under impact loading and to predict the crack occurrence of high strength steel sheets, the local fracture strain and the ductile damage limit must be measured by experiments to provide data for metal forming simulation by using FEM. In the present study, the local strains at the cracking position and its nonlinear strain path during a simple uniaxial tensile test were measured using a digital <b>image</b> <b>grid</b> method developed by authors. Then, a new identification method for the ductile damage limit of steel sheets was proposed {{with the aid of}} the measured nonlinear local strain historical path and local fracture strain. By changing the grid pitch length of the digital <b>image</b> <b>grid</b> method, the effect of grid pitch length on the measured local fracture strain and ductile damage limit were investigated. This experimental investigation is very useful to predict the fracture occurrence conditions if various sizes of finite element mesh were employed in the simulation. The ductile damage limit identified by the newly proposed method using a simple uniaxial tensile test agreed very well compared with the conventional press test...|$|E
3000|$|In {{this section}} we shall {{introduce}} some notation, {{as well as}} briefly summarize the alignment process. A range image can be conceived as the projection of a 2 D <b>image</b> <b>grid</b> on a 3 D target object surface and the acquisition of depth-related information from that surface. The resulting dataset is a “structured” point cloud, that {{is a set of}} points lying in a 3 D space, and associated to a pixel of the acquisition grid. We define a range image as a map [...]...|$|E
5000|$|... #Caption: A {{satellite}} <b>image</b> {{showing the}} <b>grid</b> pattern of rural land in Saskatchewan ...|$|R
40|$|Modern {{management}} of biomedical systems {{involves the use}} of many distributed resources, such as high performance computational resources to analyze biomedical data, mass storage systems to store them, medical instruments (microscopes, tomographs, etc.), advanced visualization and rendering tools. Grids offer the computational power, security and availability needed by such novel applications. This paper presents BIG (Biomedical <b>Imaging</b> <b>Grid),</b> a Web-based Grid portal for {{management of}} biomedical information (data and images) in a distributed environment. BIG is an interactive environment that deals with complex user's requests, regarding the acquisition of biomedical data, the "processing" and "delivering" of biomedical images, using the power and security of Computational Grids...|$|R
5000|$|... #Caption: Image-based flow {{visualization}} where a <b>grid</b> <b>image</b> is advected by {{the flow}} field.|$|R
40|$|Automatic {{alignment}} (matching) of two-dimensional {{gel electrophoresis}} images is of primary interest {{in the field of}} proteomics. The method of 2 D gel image matching proposed in a previous paper [1] is based on fuzzy alignment of features extracted from gels ’ images and enables both global and local interpolation of the <b>image</b> <b>grid,</b> followed by brightness interpolation. There are two types of pixel coordinate mapping (forward and inverse) and the choice of mapping method might affect the quality of the results obtained. In this paper the two types of grid mapping method are compared...|$|E
40|$|Patrick Sutherland is Director of The Elephant Vanishes, a {{long-term}} photographic {{documentation of the}} regeneration of the Elephant and Castle, undertaken with students on the MA Photojournalism and Documentary Photography course (MAPJD). Each year of the project students were set themes, which interrogate {{different aspects of the}} regeneration and development project. The resulting exhibition and book embraces divergent creative strategies: a key aspect of the work produced is its visual variety, leading to a rich layering and overlapping of documentary forms. This work is edited and curated into exhibition and book format by Sutherland. The overall project. The Elephant Vanishes, was launched with a PARC study day at LCC in 2006. Numerous people including Prof Val Williams, Prof Tom Hunter, Adam Broomberg and Oliver Chanarin, Paul Lowe, John Easterby and Brigitte Lardinois contributed to the project. This work is edited and curated into exhibition and book format by Sutherland. The overall project. The Elephant Vanishes, was launched with a PARC study day at LCC in 2006. Numerous people including Prof Val Williams, Prof Tom Hunter, Adam Broomberg and Oliver Chanarin, Paul Lowe, John Easterby and Brigitte Lardinois contributed to the project. Community: the Elephant and Castle is the second part of this three-part work, exisiting in book and exhibition format. The exhibition consisted of 118 individual framed or mounted photographic prints by 11 photographers, of which one is a 350 <b>image</b> <b>grid</b> and one a 28 <b>image</b> <b>grid...</b>|$|E
30|$|Both video demos {{show the}} ability of the {{proposed}} algorithms to (1) detect and track a present target both inside the <b>image</b> <b>grid</b> and near its borders, (2) detect when a target leaves the image and indicate that there is no target present until a new target appears and (3), when a new target enters the scene, correctly detect that the target is present and track it accurately. In the sequel, for illustrative purposes only, we show in the paper the detection/tracking results for a few selected frames using the RS algorithm and a dataset that is different from the one shown in the video demos.|$|E
50|$|As of 19 July 2017, {{the project}} had over 5 million {{photographs}} contributed by over 12,500 contributors, covering over 97% of Great Britain and over 40% of Ireland. There were {{an average of}} 19.7 <b>images</b> per <b>grid</b> square.|$|R
50|$|Photo: Displays all the colours the screen/phone {{can handle}} it one <b>image,</b> on a <b>grid.</b>|$|R
5000|$|Layout constructor: page layout, cartographic {{elements}} (view, legend, north, scale, frames, <b>image,</b> text, graphic), <b>grid,</b> templates.|$|R
