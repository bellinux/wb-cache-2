1467|10000|Public
5|$|Fourier {{series are}} used to solve {{boundary}} value problems in partial differential equations. In 1822, Fourier first used this technique to solve the heat equation. A discrete version of the Fourier series {{can be used in}} sampling applications where the <b>function</b> <b>value</b> is known only at a finite number of equally spaced points. In this case the Fourier series is finite and its value is equal to the sampled values at all points. The set of coefficients is known as the discrete Fourier transform (DFT) of the given sample sequence. The DFT {{is one of the key}} tools of digital signal processing, a field whose applications include radar, speech encoding, image compression. The JPEG image format is an application of the closely related discrete cosine transform.|$|E
5|$|The {{same idea}} of using a DAG to {{represent}} a family of paths occurs in the binary decision diagram, a DAG-based data structure for representing binary functions. In a binary decision diagram, each non-sink vertex is labeled {{by the name of}} a binary variable, and each sink and each edge is labeled by a 0 or 1. The <b>function</b> <b>value</b> for any truth assignment to the variables is the value at the sink found by following a path, starting from the single source vertex, that at each non-sink vertex follows the outgoing edge labeled with the value of that vertex's variable. Just as directed acyclic word graphs {{can be viewed as a}} compressed form of tries, binary decision diagrams can be viewed as compressed forms of decision trees that save space by allowing paths to rejoin when they agree on the results of all remaining decisions.|$|E
25|$|This series {{expansion}} is extremely useful in solving partial differential equations. In this article, {{we will not}} be concerned with convergence issues; it is nice to note that all Lipschitz-continuous functions have a converging Fourier {{series expansion}}, and nice enough discontinuous functions have a Fourier series that converges to the <b>function</b> <b>value</b> at most points.|$|E
50|$|Many {{programming}} languages support {{passing and}} returning <b>function</b> <b>values,</b> {{which can be}} applied to arguments. Whether this suffices to call <b>function</b> <b>values</b> first-class is disputed.|$|R
5000|$|... {{where the}} {{sequence}} of potential <b>function</b> <b>values</b> forms a telescoping series in which all terms other than the initial and final potential <b>function</b> <b>values</b> cancel in pairs.|$|R
3000|$|The shape <b>functions</b> <b>values</b> are {{computed}} {{and displayed}} in Table  1 for this example [...]. As the quadrature points are located double symmetric they {{lead to the}} same <b>function</b> <b>values</b> just ordered differently.|$|R
25|$|Optimization {{problems}} are often multi-modal; that is, they possess multiple good solutions. They {{could all be}} globally good (same cost <b>function</b> <b>value)</b> or {{there could be a}} mix of globally good and locally good solutions. Obtaining all (or at least some of) the multiple solutions is the goal of a multi-modal optimizer.|$|E
25|$|Double-precision floating-point {{implementations}} of the gamma {{function and}} its logarithm {{are now available}} in most scientific computing software and special functions libraries, for example TK Solver, Matlab, GNU Octave, and the GNU Scientific Library. The gamma function was also added to the C standard library (math.h). Arbitrary-precision implementations are available in most computer algebra systems, such as Mathematica and Maple. PARI/GP, MPFR and MPFUN contain free arbitrary-precision implementations. A little-known feature of the calculator app included with the Android operating system {{is that it will}} accept fractional values as input to the factorial function and return the equivalent gamma <b>function</b> <b>value.</b> The same is true for Windows Calculator (in scientific mode).|$|E
25|$|Following the {{approach}} suggested by , Thomas Hales, {{then at the}} University of Michigan, determined that the maximum density of all arrangements could be found by minimizing a function with 150 variables. In 1992, assisted by his graduate student Samuel Ferguson, he embarked on a research program to systematically apply linear programming methods to find a lower bound {{on the value of}} this function for each one of a set of over 5,000 different configurations of spheres. If a lower bound (for the <b>function</b> <b>value)</b> could be found for every one of these configurations that was greater than the value of the function for the cubic close packing arrangement, then the Kepler conjecture would be proved. To find lower bounds for all cases involved solving about 100,000 linear programming problems.|$|E
30|$|In the BH algorithm, a {{large amount}} of {{computation}} is needed when calculating fitness <b>function</b> <b>values</b> of all stars. When a star is sucked in by the black hole, a new star generates randomly {{at the same time and}} the next iteration starts. Then their fitness <b>function</b> <b>values</b> are recalculated and the new black holes are repositioned. In this process, it can be found that except only a few sucked stars, the position of most stars do not change, so their fitness <b>function</b> <b>values</b> have not changed. If they are recalculated in a new iteration, the computation obviously increases. So, in order to solve this problem, we propose the FBH algorithm. The fitness <b>function</b> <b>values</b> of all stars are calculated in the initialization and then only the fitness <b>function</b> <b>values</b> of new stars are recalculated in Step 5.|$|R
5000|$|The input for {{the method}} is a {{continuous}} function f, an interval b, and the <b>function</b> <b>values</b> f(a) and f(b). The <b>function</b> <b>values</b> are of opposite sign (there {{is at least one}} zero crossing within the interval). Each iteration performs these steps: ...|$|R
50|$|The method {{constructs}} {{a grid of}} size {{determined by}} {{the distribution of the}} two dimensional data points. Using this grid, the <b>function</b> <b>values</b> are calculated at each grid point. To do this the method utilises a series of Gaussian functions, given a distance weighting {{in order to determine the}} relative importance of any given measurement on the determination of the <b>function</b> <b>values.</b> Correction passes are then made to optimise the <b>function</b> <b>values,</b> by accounting for the spectral response of the interpolated points.|$|R
500|$|The {{derivative}} of {{a function of}} a real variable measures the sensitivity to change of the <b>function</b> <b>value</b> (output value) {{with respect to a}} change in its argument (input value). Derivatives are a fundamental tool of calculus. [...] For example, the {{derivative of}} the position of a moving object with respect to time is the object's velocity: this measures how quickly the position of the object changes when time advances.|$|E
2500|$|Define a {{function}} ψ based on Euler's totient function φ; it will map positive integers to non-negative integers. For an odd prime, p, {{and a positive}} integer, k, set ψ(p'k) equal to the totient <b>function</b> <b>value,</b> ...|$|E
2500|$|There are two ideas {{fundamental}} to duality theory. One {{is the fact}} that (for the symmetric dual) the dual of a dual linear program is the original primal linear program. Additionally, every feasible solution for a linear program gives a bound on the optimal value of the objective function of its dual. [...] The weak duality theorem states that the objective <b>function</b> <b>value</b> of the dual at any feasible solution is always {{greater than or equal to}} the objective <b>function</b> <b>value</b> of the primal at any feasible solution. The strong duality theorem states that if the primal has an optimal solution, x*, then the dual also has an optimal solution, y*, and cTx*=bTy*.|$|E
5000|$|Fourth, {{this article}} only deals with {{trigonometric}} <b>function</b> <b>values</b> when the expression in radicals is in real radicals—roots of real numbers. Many other trigonometric <b>function</b> <b>values</b> are expressible in, for example, cube roots of complex numbers that cannot be rewritten {{in terms of}} roots of real numbers. For example, the trigonometric <b>function</b> <b>values</b> of any angle that is one-third of an angle θ considered in this article can be expressed in cube roots and square roots by using the cubic equation formula to solve ...|$|R
30|$|Prediction {{models with}} {{independent}} variables {{extracted from the}} ALS data were formulated to predict priority <b>function</b> <b>values</b> of the form of Eq. 2. Priority <b>function</b> <b>values</b> corresponding to Eq. 1 were obtained by ordering the aforementioned predictions, i.e., no separate models were constructed for the function form of Eq. 2.|$|R
40|$|This paper {{considers}} the cross-correlation <b>function</b> <b>values</b> {{of a family}} of binary sequences obtained born finite geometries. These values are shown to depend on the intersection of hyperplanes in a projective space and the cross-correlation <b>function</b> <b>values</b> of the nonlinear feedforward functions used {{in the construction of the}} geometric sequences. 1...|$|R
2500|$|Invariance under order-preserving {{transformations of}} the {{objective}} <b>function</b> <b>value</b> , in that for any [...] the behavior is identical on [...] for all strictly increasing [...] This invariance is easy to verify, because only the -ranking {{is used in the}} algorithm, which is invariant under the choice of [...]|$|E
2500|$|Little-o [...] {{notation}} {{is common}} in mathematics but rarer in computer science. In computer science, the variable (and <b>function</b> <b>value)</b> is most often a natural number. In mathematics, the variable and function values are often [...] real numbers. The following properties (expressed in the more recent, set-theoretical notation) can be useful: ...|$|E
2500|$|The <b>function</b> <b>value</b> of {{the pair}} (x, y) is f((x, y)). [...] However, it is {{customary}} to drop one set of parentheses and consider f(x, y) a function of two variables, x and y. Functions of two variables may be plotted on the three-dimensional Cartesian as ordered triples of the form (x, y, f(x, y)).|$|E
5000|$|For {{positive}} half-integers, the <b>function</b> <b>values</b> {{are given}} exactly by ...|$|R
40|$|A {{method is}} {{described}} for unconstrained function minimization using <b>function</b> <b>values</b> and no derivatives. A quadratic {{model of the}} function is formed by interpolation to points in a table of <b>function</b> <b>values.</b> The quadratic model (not necessarily positive definite) is minimized over a constraining region of validity to locate the next trial point. The points of interpolation are chosen from a data table containing <b>function</b> <b>values</b> at an initial grid and at subsequent trial points. The method is efficient in its use of function evaluations, but expensive in computation required to choose new trial points. 1...|$|R
3000|$|On {{the other}} hand, the {{dimension}} of the data range has long been limited to 1, since it is considerably difficult to track {{the change in the}} inverse image in terms of multiple <b>function</b> <b>values</b> simultaneously. Of course, we can construct a contour tree for each of the multiple <b>function</b> <b>values</b> individually while this scheme does not provide any information about relationships among the multiple <b>function</b> <b>values.</b> For example, it is preferable to extract some coherent relationships between temperature and pressure in some space when we try to extract features of differential topology from data samples of a multivariate function [...]...|$|R
2500|$|In this context, the {{elements}} of X are called arguments of f. For each argument x, the corresponding unique y in the codomain is called the <b>function</b> <b>value</b> at x or the image of x under f. It is written as f(x). One says that f associates y with x or maps x to y. This is abbreviated by ...|$|E
2500|$|Akimoto et al. and Glasmachers et al. {{discovered}} independently {{that the}} update {{of the distribution}} parameters resembles the descend in direction of a sampled natural gradient of the expected objective <b>function</b> <b>value</b> [...] (to be minimized), where the expectation is taken under the sample distribution. With the parameter setting of [...] and , i.e. without step-size control and rank-one update, CMA-ES can thus {{be viewed as an}} instantiation of Natural Evolution Strategies (NES).|$|E
2500|$|... thus each {{term of the}} sum is {{the area}} of a {{rectangle}} with height equal to the <b>function</b> <b>value</b> at the distinguished point of the given sub-interval, and width {{the same as the}} sub-interval width. Let [...] be the width of sub-interval i; then the mesh of such a tagged partition is the width of the largest sub-interval formed by the partition, [...] The Riemann integral of a function f over the interval [...] is equal to S if: ...|$|E
5000|$|The {{values at}} {{integers}} {{are related to}} multiple zeta <b>function</b> <b>values</b> by ...|$|R
40|$|We {{construct}} Monte Carlo {{methods for}} the $L^ 2 $-approximation in Hilbert spaces of multivariate functions sampling {{no more than}} $n$ <b>function</b> <b>values</b> of the target function. Their errors {{catch up with the}} rate of convergence and the preasymptotic behavior of the error of any algorithm sampling $n$ pieces of arbitrary linear information, including <b>function</b> <b>values...</b>|$|R
5000|$|Derivative-free {{optimization}} is {{a subject}} of mathematical optimization. This method is applied to a certain optimization problem when its derivatives are unavailable or unreliable. Derivate-free method establishes model based on sample <b>function</b> <b>values</b> or directly draw a sample set of <b>function</b> <b>values</b> without exploiting detailed model. Since it needs no derivatives, it cannot be compared to derivative-based methods.|$|R
2500|$|The {{rigorous}} {{definition of}} a real valued function of a real variable is usually given in a first course in calculus {{in terms of the}} idea of a limit. [...] First, a function is said to be continuous at a point on the real line if the limit as x approaches that point is equal to the <b>function</b> <b>value</b> at that point. [...] Then a function is said to be continuous if it is continuous at every point. [...] A point where a function is not continuous is called a discontinuity.|$|E
2500|$|One {{can view}} {{the same problem}} graph-theoretically, by {{constructing}} a functional graph (that is, a directed graph in which each vertex has a single outgoing edge) the vertices of which are the elements of [...] and the edges of which map an element to the corresponding <b>function</b> <b>value,</b> {{as shown in the}} figure. The set of vertices reachable from [...] starting vertex [...] form a subgraph with a shape resembling the Greek letter rho (...) : a path of length [...] from [...] to a cycle of [...] vertices.|$|E
2500|$|CMA-ES {{stands for}} Covariance Matrix Adaptation Evolution Strategy. Evolution {{strategies}} (ES) are stochastic, derivative-free methods for numerical optimization [...] of non-linear or non-convex continuous optimization problems. They {{belong to the}} class of evolutionary algorithms and evolutionary computation. [...] An evolutionary algorithm is broadly {{based on the principle}} of biological evolution, namely the repeated interplay of variation (via recombination and mutation) and selection: in each generation (iteration) new individuals (candidate solutions, denoted as [...] ) are generated by variation, usually in a stochastic way, of the current parental individuals. Then, some individuals are selected to become the parents in the next generation based on their fitness or objective <b>function</b> <b>value</b> [...] Like this, over the generation sequence, individuals with better and better -values are generated.|$|E
25|$|The <b>function</b> <b>values</b> for Σ(n) and S(n) {{are only}} known exactly for nnbsp&<nbsp&5.|$|R
5000|$|The <b>function</b> <b>values</b> [...] {{are small}} in magnitude, at least around the minimum.|$|R
40|$|This paper {{provides}} {{cumulative distribution}} <b>function</b> <b>values</b> {{for the standard}} multivariate normal distribution. The values are derived from a simulation model for the multivariate normal distribution, which can be run on any standard personal computer. Utilizing user-input distribution parameters, the model simulates the actual standard multivariate normal distribution. Since approximations of the standard multivariate normal distribution are not used, the results are very accurate. The cumulative distribution <b>function</b> <b>values</b> can be found using a newly created Microsoft Excel function that allows exceptional flexibility for the user. The cumulative distribution <b>function</b> <b>values</b> can also be located on tables that were developed utilizing the simulation methods...|$|R
