117|3408|Public
25|$|Measurements of {{the energy}} and arrival {{directions}} of the ultra-high energy primary cosmic rays by the techniques of <b>density</b> <b>sampling</b> and fast timing of extensive air showers were first carried out in 1954 {{by members of the}} Rossi Cosmic Ray Group at the Massachusetts Institute of Technology. The experiment employed eleven scintillation detectors arranged within a circle 460 meters in diameter {{on the grounds of the}} Agassiz Station of the Harvard College Observatory. From that work, and from many other experiments carried out all over the world, the energy spectrum of the primary cosmic rays is now known to extend beyond 1020eV. A huge air shower experiment called the Auger Project is currently operated at a site on the pampas of Argentina by an international consortium of physicists, led by James Cronin, winner of the 1980 Nobel Prize in Physics from the University of Chicago, and Alan Watson of the University of Leeds. Their aim is to explore the properties and arrival directions of the very highest-energy primary cosmic rays. The results are expected to have important implications for particle physics and cosmology, due to a theoretical Greisen–Zatsepin–Kuzmin limit to the energies of cosmic rays from long distances (about 160 million light years) which occurs above 1020eV because of interactions with the remnant photons from the Big Bang origin of the universe.|$|E
500|$|This result {{showed that}} {{scintillation}} counters {{can not only}} determine of the arrival times of shower disks at many detectors spread over a large area, but also to estimate the number of particles striking each detector. [...] These capabilities combine the [...] "fast-timing" [...] method of determining shower arrival directions with the <b>density</b> <b>sampling</b> method of determining their size {{and the location of}} their axes.|$|E
50|$|In the 1950s Clark {{worked with}} Professor Bruno Rossi and other {{collaborators}} on several large cosmic ray air shower experiments that used the novel methods of <b>density</b> <b>sampling</b> and fast timing {{to measure the}} energy spectrum of the primary cosmic rays to 1 billion billion (10^18) electron volts and to determine the distribution of their celestial arrival directions.|$|E
40|$|Iodine {{molecules}} were adsorbed {{into the}} one-dimensional channels of AlPO 4 - 11 (AEL) single crystals via physical diffusion method. Different iodine loading <b>density</b> AEL <b>samples</b> were obtained. In low iodine loading <b>density</b> <b>samples,</b> vibrational modes of vapor-like iodine molecules with two different orientations were revealed. In high iodine loading <b>density</b> <b>samples,</b> vibrational modes of linear iodine molecular chains (I 2) n and vapor-like iodine molecules with different orientations were observed. Crystalline iodine structures with orientation perpendicular to crystal channels axis were also discovered inside high iodine loading <b>density</b> AEL <b>samples.</b> Ags and B 3 gs modes of crystalline iodine {{were observed in}} Raman spectra and their geometric configuration was verified by polarized Raman spectra. Ionic iodine wires were found in high iodine loading <b>density</b> AEL <b>samples</b> saturated in KI solution. Their linear geometric configurations were verified by polarized Raman spectra...|$|R
40|$|We {{present results}} of {{temperature}} dependent measurements of dynamics of polymer grafted nanoparticles with high grafting density with star polymerlike morphology. We observed {{for the low}} grafting density and hence low functionality sample, a dynamically arrested state with lowering of temperature, similar to what was conjectured earlier. However the high grafting <b>density</b> <b>sample</b> shows liquidlike relaxation at all measured temperatures. Possible origin of dynamical arrest in the two grafting <b>density</b> <b>sample</b> is discussed...|$|R
40|$|Experimental {{data were}} taken to {{determine}} the acoustic absorbing properties of uniform low density and layered variable <b>density</b> <b>samples</b> using a bulk absober with a perforated plate facing to hold the material in place. In the layered variable density case, the bulk absorber was packed such that the lowest density layer began at {{the surface of the}} sample and progressed to higher density layers deeper inside. The samples were placed in a rectangular duct and measurements were taken using the two microphone method. The data were used to calculate specific acoustic impedances and normal incidence absorption coefficients. Results showed that for uniform <b>density</b> <b>samples</b> the absorption coefficient at low frequencies decreased with increasing density and resonances occurred in the absorption coefficient curve at lower densities. These results were confirmed by a model for uniform density bulk absorbers. Results from layered variable <b>density</b> <b>samples</b> showed that low frequency absorption was the highest when the lowest density possible was packed in the first layer near the exposed surface. The layers of increasing <b>density</b> within the <b>sample</b> had the effect of damping the resonances...|$|R
5000|$|This result {{showed that}} {{scintillation}} counters {{can not only}} determine of the arrival times of shower disks at many detectors spread over a large area, but also to estimate the number of particles striking each detector. These capabilities combine the [...] "fast-timing" [...] method of determining shower arrival directions with the <b>density</b> <b>sampling</b> method of determining their size {{and the location of}} their axes.|$|E
50|$|Measurements of {{the energy}} and arrival {{directions}} of the ultra-high energy primary cosmic rays by the techniques of <b>density</b> <b>sampling</b> and fast timing of extensive air showers were first carried out in 1954 {{by members of the}} Rossi Cosmic Ray Group at the Massachusetts Institute of Technology. The experiment employed eleven scintillation detectors arranged within a circle 460 meters in diameter {{on the grounds of the}} Agassiz Station of the Harvard College Observatory. From that work, and from many other experiments carried out all over the world, the energy spectrum of the primary cosmic rays is now known to extend beyond 1020 eV. A huge air shower experiment called the Auger Project is currently operated at a site on the pampas of Argentina by an international consortium of physicists, led by James Cronin, winner of the 1980 Nobel Prize in Physics from the University of Chicago, and Alan Watson of the University of Leeds. Their aim is to explore the properties and arrival directions of the very highest-energy primary cosmic rays. The results are expected to have important implications for particle physics and cosmology, due to a theoretical Greisen-Zatsepin-Kuzmin limit to the energies of cosmic rays from long distances (about 160 million light years) which occurs above 1020 eV because of interactions with the remnant photons from the Big Bang origin of the universe.|$|E
40|$|Abstract: Compressed sensing and {{magnetic}} resonance imaging are hot topics {{in the field of}} signal processing. In this study we introduced in Lustig’s variable <b>density</b> <b>sampling</b> method, integrated it to compressed sensing, and applied it to brain MRI acquisition. The realistic experiment shows the variable <b>density</b> <b>sampling</b> recovery better than traditional random sampling method on a 256 x 256 brain magnetic resonance image at acceleration factor as 3...|$|E
30|$|The {{calculation}} flow of {{the peak}} density algorithm is shown in Fig.  1. The basic principle is to measure <b>sample</b> <b>density</b> {{based on the number}} of similar samples. Select the maximum <b>density</b> <b>sample</b> of the local area as the clustering center, and ensure that the distance between the sample and other samples with a larger density is large enough.|$|R
40|$|The {{oxidation}} behaviour of hot-pressed β-SiAlON ceramics with different densities {{has been investigated}} up to 1853. K in air using thermogravimetry (TG). The microstructures of the oxidised samples were determined by scanning electron microscopy (SEM), and the phases after oxidation were confirmed by X-ray diffraction (XRD). The oxidation kinetics of the higher <b>density</b> <b>sample</b> was diffusion controlled. For the lower <b>density</b> <b>sample,</b> it was controlled by both an interface reaction and diffusion in the early stage but diffusion controlled after a certain time. The oxidation curves can be well described by Chou 2 ̆ 7 s model with the "characteristic oxidation time" index introduced...|$|R
40|$|International audienceCyanobacteria {{and their}} toxins {{are known as}} a health hazard in recreative and {{distributed}} waters. Monitoring data from 2004 to 2011 were collected at regional scale to characterize exposition parameters to microcystins in Brittany (Western France). The data show that cyanobacteria populations are experiencing a composition shift leading to a longer duration of cell densities higher than WHO alert levels 2 and 3. Microcystins however {{appear to be more}} frequently detected with subacute concentrations in low cell <b>density</b> <b>samples</b> than in high cell <b>density</b> <b>samples</b> or during bloom episodes. Positive relations are described between microcystin concentrations, detection frequencies and cyanobacteria biovolumes, allowing for a novel definition of alert levels and decision framework following WHO recommendation...|$|R
40|$|Methods: This paper {{presents}} a simple computer program for incidence <b>density</b> <b>sampling.</b> This program was evaluated using data {{derived from a}} cohort study of mortality among workers employed in the nuclear weapons industry. Controls were selected for cases via incidence density sampling; {{an estimate of the}} exposure-mortality association was obtained via conditional logistic regression. After 100 iterations of this procedure, the average effect estimate was compared to the risk estimate obtained via proportional hazards regression. The same methods were used to evaluate a program for incidence <b>density</b> <b>sampling</b> that was proposed previously by Pearce in 1989. ...|$|E
40|$|Abstract—Incoherence between {{sparsity}} {{basis and}} sensing basis {{is an essential}} concept for compressive sampling. In this context, we advocate a coherence-driven optimization procedure for variable <b>density</b> <b>sampling.</b> The associated minimization problem is solved by use of convex optimization algorithms. We also propose a refinement of our technique when prior information {{is available on the}} signal support in the sparsity basis. The effectiveness of the method is confirmed by numerical experiments. Our results also provide a theoretical underpinning to state-of-the-art variable density Fourier sampling procedures used in MRI. Index Terms—compressed sensing, variable <b>density</b> <b>sampling,</b> magnetic resonance imaging. I...|$|E
40|$|The angular {{resolution}} of radio maps made by earth-based VLBI observations can be exceeded by placing {{at least one}} element of a VLBI array into earth orbit. A VLBI observatory in space can offer the additional advantages of increased sky coverage, higher <b>density</b> <b>sampling</b> of Fourier components, and rapid mapping of objects whose structure changes {{in less than a}} day. This paper explores the future of this technique...|$|E
40|$|An {{adaptive}} importance {{sampling methodology}} is proposed {{to compute the}} multidimensional integrals encountered in reliability analysis. In the proposed methodology, samples are simulated as the states of a Markov chain and are distributed asymptotically according to the optimal importance <b>sampling</b> <b>density.</b> A kernel <b>sampling</b> <b>density</b> is then constructed from these samples which is used as the <b>sampling</b> <b>density</b> in an importance sampling simulation. The Markov chain samples populate the region of higher probability density in the failure domain and so the kernel <b>sampling</b> <b>density</b> approximates the optimal importance <b>sampling</b> <b>density</b> for a large variety of shapes of the failure domain. This adaptive feature is insensitive to the probability level to be estimated. A numerical example demonstrates the accuracy, efficiency and robustness of the method...|$|R
40|$|Shubnikov de Haas (SdH) {{oscillations}} and Angle Resolved PhotoEmission Spectroscopy (ARPES) {{are used}} to probe the Fermi surface of single crystals of Bi 2 Se 3. We find that SdH and ARPES probes quantitatively agree on measurements of the effective mass and bulk band dispersion. In high carrier <b>density</b> <b>samples,</b> the two probes also agree in the exact position of the Fermi level EF, but for lower carrier <b>density</b> <b>samples</b> discrepancies emerge {{in the position of}} EF. In particular, SdH reveals a bulk three-dimensional Fermi surface for <b>samples</b> with carrier <b>densities</b> as low as 10 ^ 17 cm- 3. We suggest a simple mechanism to explain these differences and discuss consequences for existing and future transport studies of topological insulators. Comment: 5 mages, 5 figure...|$|R
40|$|International audienceWe {{present some}} of the recent {{developments}} on heavy-ion channeling experiments, in the framework of X-ray emission and inner-shell processes. We discuss the possibility to characterize the very low electron <b>densities</b> <b>sampled</b> by hyperchanneled ions, and we report on an attempt to observe exotic trielectronic recombination...|$|R
40|$|Particle-based {{simulation}} {{plays an}} important role in many different fields of science and engineering. Two common visualization approaches for the resulting data are glyph-based rendering and <b>density</b> <b>sampling</b> employing volume rendering. Fine geometric features are inherently captured by glyph-based methods. However, they might suffer from aliasing and the global structure is often poorly conveyed. Volume rendering preserves the global structure but is limited due to the sampling resolution. To avoid aliasing artifacts and large memory footprints, we propose a direct volume rendering technique with on-demand <b>density</b> <b>sampling</b> of the particle data, as combination of splatting, texture slicing, and ray casting. We optimized our system with a novel ray cast termination employing early-z-test culling and hardware occlusion queries utilizing inter-frame coherency. Our system contains a fully-featured volume renderer and captures all geometric features of the data set representable at the available display resolution. Since no pre-computation is required, the proposed method can be used easily to visualize time-dependent data sets. The effectiveness of our approach is shown with examples from different application fields...|$|E
40|$|Compressed sensing (CS) {{provides}} an {{efficient way to}} acquire and reconstruct natural images from a reduced number of linear projection measurements at sub-Nyquist sampling rates. A key to the success of CS is the design of the measurement ensemble. This paper addresses the design of a novel variable <b>density</b> <b>sampling</b> strategy, where the “a priori ” information about the statistical distributions that natural images exhibit in the wavelet domain is exploited. Compared to the current sampling schemes for compressed image sampling, the proposed variable <b>density</b> <b>sampling</b> has the following advantages: 1) The number of necessary measurements for image reconstruction is reduced; 2) The proposed sampling approach can be applied to several transform domains leading to simple implementations. In particular, the proposed method is applied to the compressed sampling in the 2 D ordered discrete Hadamard transform (DHT) domain for spatial domain imaging. Furthermore, to evaluate the incoherence of different sampling schemes, a new metric that incorporates the “a priori ” information is also introduced. Extensive simulations show the effectiveness of the proposed sampling methods. 1...|$|E
40|$|Abstract — Compressive sensing is a {{relatively}} new measurement paradigm which seeks to capture the “essential” aspects of a high-dimensional object using as few measurements as possible. In this work we demonstrate successful application of compressive sensing framework to digital Fresnel holography. It is shown that when applying compressive sensing approach to Fresnel fields a special sampling scheme should be adopted for improved results. Index Terms—Compressive Imaging, Fresnel digital holography, Variable <b>density</b> <b>sampling...</b>|$|E
3000|$|... exc = 6 W/cm 2. This values well {{compare with}} η ≈ 1 × 10 − 2 {{relative}} to a standard DE quantum dot sample with similar (ρ = 1.2 × 109 cm− 2) nanostructure <b>density</b> (<b>sample</b> D 680 of Ref. [28]). No dependence of η on P [...]...|$|R
30|$|It {{is clear}} that ED method is the fastest (with low quality) and GPR is the most {{computationally}} expensive method (with good quality), {{and the result is}} consistent with the existing literatures. For example, at <b>sample</b> <b>density</b> of 3 % for image Lena, ED representation takes only 0.026 s, while GPR method takes 248 s. For image peppers at <b>sample</b> <b>density</b> of 3 %, ED method takes 0.027 s while GPR takes 318 s. The smaller <b>sample</b> <b>density,</b> the longer time GPR needs because more points need to be removed before reaching the desired <b>sample</b> <b>density.</b> For all other methods, the computational cost is lower for smaller <b>sample</b> <b>density.</b>|$|R
40|$|Methods were {{investigated}} and modeled {{to produce a}} graininess by <b>density</b> <b>sample</b> matrix. The graininess values {{were based on a}} model derived for certain imaging processes that has a high correlation to the subjective impression of graininess for nominally uniform image areas. After modeling several processes, a photographic technique was chosen and a matrix manufactured...|$|R
40|$|Six bulk <b>density</b> <b>sampling</b> {{methods were}} {{evaluated}} {{for use in}} neutron gauge calibration. All six methods provided estimates of bulk density which were generally within 5 % of bulk density profiles measured using a gamma probe. Standard errors of estimate ranged from 3 to 7 %. When used with care, downhole, coring, and drive samplers {{can be used to}} successfully measure soil moisture and bulk density profiles for use in neutron probe calibration...|$|E
40|$|A {{variable}} <b>density</b> <b>sampling</b> pattern {{based on}} Bayesian statistics is presented and {{compared to a}} uniform density statistical pattern and a judgmental approach in a real case study. The Bayesian statistics, supported by a software tool, supplied a soil sampling plan similar to the judgmental one, especially {{for the number of}} sampling points and their location. It allowed statistical goals to be set and expert judgment {{to be included in the}} sampling strategy in a transparent and systematic procedure. For these reasons, it appears quite suitable for inclusion into Quality Assurance Quality Control plans...|$|E
40|$|Soil carbon {{stocks are}} {{commonly}} quantified at fixed depths {{as the product}} of soil bulk density, depth and organic carbon (OC) concentration. However, this method systematically overestimates OC stocks in treatments with greater bulk densities such as minimum tillage, exaggerating their benefits. Its use has compromised estimates of OC change where bulk densities differed between treatments or over time periods. We argue that its use should be discontinued and a considerable body of past research re-evaluated. Accurate OC estimations must be based on quantification in equivalent soil masses (ESMs). The objective of this publication is to encourage accurate quantification of changes in OC stocks and other soil properties using ESM procedures by developing a simple procedure to quantify OC in multiple soil layers. We explain errors inherent in fixed depth procedures and show how these errors are eliminated using ESM methods. We describe a new ESM procedure for calculating OC stocks in multiple soil layers and show that it can be implemented without bulk <b>density</b> <b>sampling,</b> which reduces sampling time and facilitates evaluations at greater depths, where bulk <b>density</b> <b>sampling</b> is difficult. A spreadsheet has been developed to facilitate calculations. A sample adjustment procedure is described to facilitate OC quantification in a single equivalent soil mass layer from the surface, when multiple-layer quantification is not necessary. Peer Revie...|$|E
40|$|The {{asymptotic}} behaviour of the bootstrap {{distribution of the}} sample median and other sample quantiles is considered when the distribution function is not necessarily differentiable at the corresponding population quantile. It is shown that the appropriate bootstrap distribution function does not generally converge to the limiting distribution of the sample quantile. Bootstrap Convex functions Non-regular <b>density</b> <b>Sample</b> quantile...|$|R
40|$|Data mining {{in large}} data sets often {{requires}} a sampling or summarization step {{to form an}} in-core representation of the data that can be processed more e#ciently. Uniform random sampling is frequently used in practice and also frequently criticized because it will miss small clusters. Many natural phenomena are known to follow Zipf's distribution and the inability of uniform sampling to #nd small clusters is of practical concern. <b>Density</b> Biased <b>Sampling</b> is proposed to probabilistically under-sample dense regions and over-sample light regions. A weighted sample is used to preserve the densities of the original data. <b>Density</b> biased <b>sampling</b> naturally includes uniform sampling as a special case. A memory e#cient algorithm is proposed that approximates <b>density</b> biased <b>sampling</b> using only a single scan of the data. We empirically evaluate <b>density</b> biased <b>sampling</b> using synthetic data sets that exhibit varying cluster size distributions. Our proposed method scales linearly and out performs uni [...] ...|$|R
40|$|International audienceTopological {{analysis}} of electron <b>densities</b> <b>sampled</b> on 3 D grids {{have been performed}} on two different crystalline compounds-ammonium dihydrogen phosphate and urea-using the software package InteGriTy {{and the results are}} compared to that of analytical derivation from the software Newprop and TOPOND. Both critical points and integrated quantities are considered with emphasis put on bond critical points and atomic charges...|$|R
40|$|Reducing {{acquisition}} {{time is of}} fundamental importance in various imaging modalities. The concept of variable <b>density</b> <b>sampling</b> provides a nice framework to achieve this. It was justified recently from a theoretical {{point of view in}} the compressed sensing (CS) literature. Unfortunately, the sampling schemes suggested by current CS theories may not be relevant since they do not take the acquisition constraints into account (for example, continuity of the acquisition trajectory in Magnetic Resonance Imaging - MRI). In this paper, we propose a numerical method to perform variable <b>density</b> <b>sampling</b> with block constraints. Our main contribution is to propose a new way to draw the blocks in order to mimic CS strategies based on isolated measurements. The basic idea is to minimize a tailored dissimilarity measure between a probability distribution defined on the set of isolated measurements and a probability distribution defined on a set of blocks of measurements. This problem turns out to be convex and solvable in high dimension. Our second contribution is to define an efficient minimization algorithm based on Nesterov's accelerated gradient descent in metric spaces. We study carefully the choice of the metrics and of the prox function. We show that the optimal choice may depend on the type of blocks under consideration. Finally, we show that we can obtain better MRI reconstruction results using our sampling schemes than standard strategies such as equiangularly distributed radial lines...|$|E
40|$|Information theory {{allows one}} to define an optimal {{sampling}} <b>density.</b> <b>Sampling</b> above this critical frequency adds very little accuracy to the mapping results. We demonstrate {{the establishment of a}} critical sampling grid for the Stratonion mixed sulphide mining area in Chalkidiki peninsula, Greece, and the extraction of maximum information; the data used was derived from a previous sampling campaign carried out to estimate ore reserves and predict the net neutralization potential (NNP) of the rock formations. A structural analysis of NNP values generates a variogram model {{that can be used to}} define the optimum sampling grid. © 2007 Springer-Verlag...|$|E
40|$|International audienceWe {{consider}} {{the problem of}} embedding a low-dimensional set, M, from an infinite-dimensional Hilbert space, H, to a finite-dimensional space. Defining appropriate random linear projections, we propose two constructions of linear maps that have the restricted isometry property (RIP) on the secant set of M with high probability. The first one is optimal {{in the sense that}} it only needs a number of projections essentially proportional to the intrinsic dimension of M to satisfy the RIP. The second one, which is based on a variable <b>density</b> <b>sampling</b> technique, is computationally more efficient, while potentially requiring more measurements...|$|E
40|$|We {{analyze the}} density {{distribution}} of marine sediments using <b>density</b> <b>samples</b> taken from 716 drill {{sites of the}} Deep Sea Drilling Project (DSDP). The samples taken within the upper stratigraphic layer exhibit a prevailing trend of the decreasing density with the increasing ocean depth (at a rate of − 0. 05 [*]g/cm 3 per 1 [*]km). Our results confirm findings of published studies that the density nonlinearly increases with the increasing sediment depth due to compaction. We further establish a 3 D density model of marine sediments and propose theoretical models of the ocean-sediment and sediment-bedrock density contrasts. The sediment density-depth equation approximates <b>density</b> <b>samples</b> with an average uncertainty of about 10 % and better represents the density distribution especially at deeper sections of basin sediments than a uniform density model. The analysis of DSDP density data also reveals that the average density of marine sediments is 1. 70 [*]g/cm 3 and the average density of the ocean bedrock is 2. 9 [*]g/cm 3...|$|R
40|$|Sexual {{behavior}} in the field crickets, Gryllus veletis and G. pennsylvanicus, was studied in outdoor arenas (12 m 2) at high {{and low levels of}} population density in 1983 and 1984. Crickets were weighed, individually marked, and observed from 2200 until 0800 hrs for at least 9 continuous nights. Calling was measured at 5 min intervals, and movement and matings were recorded hourly. Continuous 24 hr observations were also conducted,·and occurrences of aggressive and courtship songs were noted. The timing of males searching, calling, courting, and fighting for females should coincide with female movement and mating patterns. For most samples female movement and matings occurred at night in the 24 hr observations and were randomly distributed with time for both species in the 10 hr observations. Male movement for G. veletis high density only was enhanced at night in the 24 hr observations, however, males called more at night in both species at high and low densities. Male movement was randomly distributed with time in the 10 hr observations, and calling increased at dawn for the G. pennsylvanicus 1984 high <b>density</b> <b>sample,</b> but was randomly distributed in other samples. Most courtship and aggression songs in the 24 hr observations were too infrequent for statistical testing and generally did not coincide with matings. Assuming residual reproductive value, and costs attached to a male trait in terms of future reproductive success decline with age, males should behave in more costly ways with age; by calling and moving more with age. Consequently, mating rates should increase with age. Female behavior may not change with age. G. veletis, females moved more with age at both low <b>density</b> <b>samples,</b> however, crickets moved less with age at high density. G. pennsylvanicus females moved more with age in the 1984 low <b>density</b> <b>sample,</b> whereas crickets moved less with age in the 1983 high <b>density</b> <b>sample.</b> For both species males in the 1984 high <b>density</b> <b>samples</b> called less with age. For G. pennsylvanicus in 1983 calling and mating rates increased with age. Mating rates decreased with age for G. veletis males in the high <b>density</b> <b>sample.</b> Aging may not affect cricket behavior. As population density increases fewer calling sites become available, costs of territoriality increase, and matings resulting from non-calling behavior should increase. For both species the amount of calling and in G. veletis the distance travelled per night was not different between densities. G. pennsylvanicus males and females moved more at low density. At the same deneity levels there were no differences in calling, mating, and, movement rates in G. veletis, however, G. pennsylvanicus males moved more at high density in 1983 than 1984. There was a positive relationship between calling and mating for the G. pennsylvanicus low <b>density</b> <b>sample</b> only, and selection was acting directly to increase calling. For both species no relationships between movement and mating success was found, however, the selection gradient on movement in the G. veletis high density population was significant. The intensity of selection was not significant and was probably due to the inverse relationship between displacement and weight. Larger males should call more, mate more, and move less than smaller males. There were no correlations between calling and individual weight, and an inverse correlation between movement and size in the G. veletis high density population only. In G. pennsylvanicus, there was a positive correlation between individual weight and mating, but, some correlate of weight was under counter selection pressure and-prevented significance of the intensity of selection. In contrast, there was an inverse correlation in the G. ·veletis low <b>density</b> B <b>sample.</b> Both measures of selection intensities were significant and showed that weight only was under selection pressures. An inverse correlation between calling and movement was found for G. veletis at low density only. Because males are territorial, females are predicted to move more than males, however, if movement is a mode of male-male reproductive competition then males may move more than females. G. pennsylvanicus males moved more than females in all samples, however, G. veletis males and females moved similar distances at all densities. The variation in relative mating success explained by calling scores, movement, and weight for both species and all samples were not significant In addition, for both species and all samples the intensity of selection never equalled the opportunity for selection...|$|R
40|$|Pork was {{cured by}} (a) the Wiltshire method and (b) a {{hygienic}} sweet cure process. Representative samples of both bacons were inoculated at `low' density (103 organisms/g.) and `high' density (106 organisms/g.) with a toxin-producing strain of Staphylococcus aureus, `High' and `low' <b>density</b> <b>samples</b> of both bacons were each stored at 5 ° C. for 42 days and 15 ° C. for 21 days...|$|R
