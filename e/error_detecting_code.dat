40|3733|Public
50|$|A parity bit, {{or check}} bit, {{is a bit}} added to a string of binary code {{to ensure that the}} total number of 1-bits in the string is even or odd. Parity bits are used as the {{simplest}} form of <b>error</b> <b>detecting</b> <b>code.</b>|$|E
5000|$|Finally, some {{transport}} layer protocols, for example TCP, but not UDP, provide end-to-end reliable communication, i.e. error recovery {{by means of}} <b>error</b> <b>detecting</b> <b>code</b> and automatic repeat request (ARQ) protocol. The ARQ protocol also provides flow control, which may be combined with congestion avoidance.|$|E
50|$|Data is encoded using 7 unit binary codes sent using a seven bit <b>error</b> <b>detecting</b> <b>code</b> called van Duuren code or CCITT Telegraph Alphabet No. 3. The data is sent in two {{channels}} labelled A and B, or four channels labeled A, B, C and D. Data {{from the}} different channels are interleaved using a time division multiplex system. The two channel system is called ARQ-M2, the four channel system is called ARQ-M4.|$|E
40|$|Abstract—The <b>error</b> <b>detecting</b> {{problem for}} limited {{magnitude}} errors over high radix channels is studied. In this error model, the error magnitude does not exceed a certain limit known beforehand. For asymmetric and unidirectional channels, both all and t <b>error</b> <b>detecting</b> <b>codes</b> are studied. Further, close-tooptimal codes are proposed. For symmetric channels, optimal all <b>error</b> <b>detecting</b> <b>codes</b> are given. I...|$|R
3000|$|... [...]. Relay nodes decode {{the data}} and some <b>error</b> <b>detecting</b> <b>codes</b> such as cyclic {{redundancy}} check (CRC) or other linear block codes are used to verify the decoding results.|$|R
40|$|Graduation date: 2005 In some {{practical}} systems, {{most of the}} errors are of 1 → 0 type and 0 → 1 errors occur very rarely. In this thesis, first, {{the capacity of the}} asymmetric channel is derived. The capacity of the binary symmetric channel (BSC) and the Z-channel can be derived from this expression as special cases. Second, the <b>error</b> <b>detecting</b> capability of Bose-Lin codes beyond the maximum designed error detection capability are described. Third, a new class of a systematic t-unidirectional <b>error</b> <b>detecting</b> <b>codes</b> over Z [subscript m], m≥ 2 is designed. These <b>codes</b> can <b>detect</b> 2 <b>errors</b> using r= 2 check bits and up to m[superscript (r- 2) ] + r- 2 errors using r> 2 check bits. Some upper bound on the maximum number of detectable errors when using r check bits are given. Finally, some analysis on the data throughput when using the following protocols over the m-ary Z-Channel, m≥ 2 are derived: (1) ARQ protocols using t-Asymmetric <b>Error</b> <b>Detecting</b> (t-AED) <b>codes.</b> (2) ARQ protocols using All Asymmetric <b>Error</b> <b>Detecting</b> (AAED) <b>codes.</b> (3) Type-I Hybrid ARQ protocols using t-Asymmetric Error Correcting and All Asymmetric <b>Error</b> <b>Detecting</b> (t-EC/AAED) <b>codes.</b> (4) ARQ Protocols with diversity combining using t-Asymmetric Error Correcting and All Asymmetric <b>Error</b> <b>Detecting</b> (t-EC/AAED) <b>codes.</b> Finally, some open research problems are described...|$|R
50|$|The DSC is a {{synchronous}} system using characters composed from a ten-bit <b>error</b> <b>detecting</b> <b>code.</b> The bits are encoded using frequency shift keying. For High Frequency and Medium Frequency two tones 170 Hz apart {{either side of}} the allocated frequency with 100 Baud symbol rate are used. For VHF the two tones used are 1300 and 2100 Hz with a symbol rate of 1200 Baud. Each character is transmitted twice with a time delay. The detailed specification is published in the International Telecommunications Union recommendation ITU-R M.493, revision 14 being the most recent.|$|E
5000|$|... EDC/ECC and ECC/ECC are the {{two most}} common cache error {{protection}} techniques used in commercial microprocessors. The EDC/ECC technique uses an <b>error</b> <b>detecting</b> <b>code</b> (EDC) in the level 1 cache. If an error is detected, data is recovered from ECC-protected level 2 cache. The ECC/ECC technique uses an ECC-protected level 1 cache and an ECC-protected level 2 cache. CPUs that use the EDC/ECC technique always write-through all STOREs to the level 2 cache, so that when an error is detected during a read from the level 1 data cache, a copy of that data can be recovered from the level 2 cache.|$|E
50|$|In {{information}} theory, a {{parity bit}} appended to a binary number provides the simplest form of <b>error</b> <b>detecting</b> <b>code.</b> If a single {{bit in the}} resulting value is changed, then it will {{no longer have the}} correct parity: changing a bit in the original number gives it a different parity than the recorded one, and changing the parity bit while not changing the number it was derived from again produces an incorrect result. In this way, all single-bit transmission errors may be reliably detected. Some more sophisticated error detecting codes are also based on the use of multiple parity bits for subsets of the bits of the original encoded value.|$|E
40|$|AbstractA {{new class}} of {{symmetric}} <b>error</b> correcting/unidirectional <b>error</b> <b>detecting</b> <b>codes</b> are developed. They provide protection against both transient and permanent faults. The codes are systematic in nature and, hence, the information bits are easy to retrieve. The encoding/decoding methods for these codes are discussed...|$|R
40|$|We {{analyze the}} {{electrical}} phenomena {{that can affect}} {{the integrity of the}} communication among different chips within a system in package (SiP). We address these issues for a real case, for which electrical parameters are extracted from layout and used to build a netlist employed for electrical characterization. We show that crosstalk, and in particular inductive crosstalk, is the electrical phenomenon mainly affecting signal transmission within the SiP. Then, we evaluate the kinds of errors that can be originated. We show that errors caused by inductive coupling among SiP interconnects can be unidirectional only, thus allowing designers to implement error control coding techniques based on all unidirectional <b>error</b> <b>detecting</b> <b>codes.</b> This allows significant cost reduction over the alternate use of non-unidirectional <b>error</b> <b>detecting</b> <b>codes...</b>|$|R
50|$|Like all {{unidirectional}} <b>error</b> <b>detecting</b> codes,Berger <b>codes</b> {{can also}} be used in delay-insensitive circuits.|$|R
5000|$|In telecommunication, a Berger code is a {{unidirectional}} <b>error</b> <b>detecting</b> <b>code,</b> {{named after}} its inventor, J. M. Berger. Berger codes can detect all unidirectional errors. Unidirectional errors are errors that only flip ones into zeroes or only zeroes into ones, {{such as in}} asymmetric channels. The check bits of Berger codes are computed by summing all the zeroes in the information word, and expressing that sum in natural binary. If the information word consists of [...] bits, then the Berger code needs [...] "check bits", giving a Berger code of length k+n. (In other words, the [...] check bits are enough to check up to [...] information bits).Berger codes can detect any number of one-to-zero bit-flip errors, as long as no zero-to-one errors occurred in the same code word.Similarly, Berger codes can detect any number of zero-to-one bit-flip errors, as long as no one-to-zero bit-flip errors occur in the same code word.Berger codes cannot correct any error.|$|E
40|$|Abstract—This paper {{presents}} the decoder {{design for the}} single error correcting and double <b>error</b> <b>detecting</b> <b>code</b> proposed by the authors in an earlier paper. The speed of error detection and correction of a code is largely dependent upon the associated encoder and decoder circuits. The complexity and the speed of such circuits {{are determined by the}} number of 1 ’s in the parity check matrix (PCM). The number of 1 ’s in the parity check matrix for the code proposed by the authors are fewer than in any currently known single error correcting/double <b>error</b> <b>detecting</b> <b>code.</b> This results in simplified encoding and decoding circuitry for error detection and correction...|$|E
40|$|We {{show that}} the Sylow 2 -subgroups of nearly all Chevalley groups in even {{characteristic}} allow {{the definition of a}} check-character-system which detects all single and the most important double errors. Keywords: check character system, check digit system, <b>error</b> <b>detecting</b> <b>code,</b> Suzuki- 2 -groups, fixed-point-free automorphisms, p-groups, Chevalley groups 1...|$|E
40|$|In {{this paper}} 1 we propose a {{combination}} of PLA decomposition and unidirectional <b>error</b> <b>detecting</b> techniques which permits concurrent testing for all single faults in a circuit (both in the decomposed modules and on the interconnection lines), for a lower area overhead cost than is normally associated with unidirectional <b>error</b> <b>detecting</b> <b>codes.</b> 1 Introduction In this paper we combine PLA decomposition techniques with modified forms of unidirectional <b>error</b> <b>detecting</b> <b>codes</b> [2]. This combination permits detection of all single faults within the circuit for a lower area cost than would be obtained by applying a standard UED code to a PLA. Preliminary efforts in combining the two techniques show significant improvements in these area overheads, although {{in many cases the}} results are still unacceptably high for practical applications. While {{it is well known that}} decomposition of large sparse PLAs can lead to reductions in circuit size [3] [4], the process becomes even more significant when [...] ...|$|R
50|$|As of 2009, {{the most}} common error-{{correction}} codes use Hamming or Hsiao codes that provide single bit error correction and double bit error detection (SEC-DED). Other error-correction codes have been proposed for protecting memory double-bit error correcting and triple-bit <b>error</b> <b>detecting</b> (DEC-TED) <b>codes,</b> single-nibble <b>error</b> correcting and double-nibble <b>error</b> <b>detecting</b> (SNC-DND) <b>codes,</b> Reed-Solomon <b>error</b> correction codes, etc. However, in practice multi-bit correction is usually implemented by interleaving multiple SEC-DED codes.|$|R
5000|$|A second {{solution}} requires unforgeable message signatures. For security-critical systems, digital signatures (in modern computer systems, {{this may}} be achieved in practice using public-key cryptography) can provide Byzantine fault tolerance {{in the presence of}} an arbitrary number of traitorous generals. However, for safety-critical systems, simple <b>error</b> <b>detecting</b> <b>codes,</b> such as CRCs, provide weaker but often sufficient coverage at a much lower cost. This is true for both Byzantine and non-Byzantine faults. Thus, cryptographic digital signature methods are not a good choice for safety-critical systems, unless there is also a specific security threat as well. While <b>error</b> <b>detecting</b> <b>codes,</b> such as CRCs, are better than cryptographic techniques, neither provide adequate coverage for active electronics in safety-critical systems. This is illustrated by the Schrödinger CRC scenario where a CRC-protected message with a single Byzantine faulty bit presents different data to different observers and each observer sees a valid CRC.|$|R
40|$|A fixed-length {{binary code}} is called t [...] {{unidirectional}} error detecting if no codeword {{can be transformed}} into another codeword by at most t unidirectional errors. In this paper we consider the problem of mapping information sequences of length k into codewords of a t-unidirectional <b>error</b> <b>detecting</b> <b>code</b> of length k + p. In case of systematic codes we show that the parameters p and t must satisfy the relation t 2 p Γ 2 p= 2 + 1 +p. Moreover, we give a simple systematic encoding to map information sequences into codewords of a t-unidirectional <b>error</b> <b>detecting</b> <b>code.</b> In case of non-systematic codes, we give a method to design t [...] unidirectional error detecting codes in which the number p of check bits must satisfy the inequality t 2 p Γ p Γ 1. The encoding and decoding algorithms require time linear in the number k of information bits...|$|E
30|$|One is {{that the}} {{encoding}} cells in quantizer’s encoders {{are designed to be}} affected by the transmission channel characteristics, for example [7], or the final positioning of the reconstruction in decoders depends on channel characteristics, for example [8], which is called as channel optimized quantizers. In [9 – 12], some necessary optimality conditions are given. Alternatively, an <b>error</b> <b>detecting</b> <b>code</b> can be cascaded with the quantizer at the expense of added transmission rate in [13].|$|E
40|$|The paper proposes an {{approach}} for designing TSC networks {{by means of}} <b>error</b> <b>detecting</b> <b>code</b> application, based on {{the analysis of the}} desired fault-error relation. The network structure is analyzed by taking into account each possible fault, belonging to the adopted fault set, and by verifying if the produced error is detectable with respect to the adopted encoding. If undetectable faults are located the network is locally modified, so that area overheads for TSC designs are limited...|$|E
2500|$|A second {{solution}} requires unforgeable message signatures. [...] For security-critical systems, digital signatures (in modern computer systems, {{this may}} be achieved in practice using public-key cryptography) can provide Byzantine fault tolerance {{in the presence of}} an arbitrary number of traitorous generals. [...] However, for safety-critical systems, simple <b>error</b> <b>detecting</b> <b>codes,</b> such as CRCs, provide weaker but often sufficient coverage at a much lower cost. [...] This is true for both Byzantine and non-Byzantine faults. [...] Thus, cryptographic digital signature methods are not a good choice for safety-critical systems, unless there is also a specific security threat as well. While <b>error</b> <b>detecting</b> <b>codes,</b> such as CRCs, are better than cryptographic techniques, neither provide adequate coverage for active electronics in safety-critical systems. [...] This is illustrated by the Schrödinger CRC scenario where a CRC-protected message with a single Byzantine faulty bit presents different data to different observers and each observer sees a valid CRC.|$|R
40|$|Recent {{research}} has shown that fault diagnosis and possibly fault tolerance are important features when implementing cryptographic algorithms by means of hardware devices. In fact, some security attack procedures are based on the injection of faults. At the same time, hardware implementations of cryptographic algorithms, i. e. crypto-processors, are becoming widespread. There is however, only very limited research on implementing fault diagnosis and tolerance in crypto-algorithms. Fault diagnosis is studied for the RC 5 crypto-algorithm, a recently proposed block-cipher algorithm that is suited for both software and hardware implementations. RC 5 is based on a mix of arithmetic and logic operations, and is therefore a challenge for fault diagnosis. We study fault propagation in RC 5, and propose and evaluate the cost/performance tradeoffs of several <b>error</b> <b>detecting</b> <b>codes</b> for RC 5. Costs are estimated in terms of hardware overhead, and performances in terms of fault coverage. Our most important conclusion is that, despite its nonuniform nature, RC 5 can be efficiently protected by using low-cost <b>error</b> <b>detecting</b> <b>codes...</b>|$|R
40|$|In the {{automatic}} repeat request (ARQ) protocol, the sender keeps retransmitting {{a code word}} until it receives a positive acknowledgment from the receiver sent through the feedback channel. This correspondence proposes plain and diversity combining hybrid ARQ protocol communication schemes suitable for the m(>= 2) -ary asymmetric channel using t-asymmetric error correcting/all asymmetric <b>error</b> <b>detecting</b> (t-AEC/AAED) <b>codes.</b> The analysis shows that error correction definitely improves the throughput of the system compared to the ARQ protocol which uses only <b>error</b> <b>detecting</b> <b>codes.</b> The correspondence provides simple analytic expressions for {{the average number of}} transmissions of a code word in both plain and diversity combining t-AEC/AAED ARQ (t >= 0) protocol systems over the m-ary asymmetric channel, m>= 2. An example is shown on how to get very close to the Z-channel capacity. [ [...] . ...|$|R
40|$|We {{consider}} {{check digit}} systems over a group G with check equation T (a 1) T 2 (a 2) ΔΔΔ T n (an) = e for fixed e 2 G and permutation T of G. Such a system detects all single errors (i. e. errors {{in only one}} component); and it detects adjacent transpositions (i. e. errors of the form : : : ab : : : Γ! : : : ba : : :) iff T is anti [...] symmetric that means that T fulfills the condition x T(y) 6 = y T(x) for all x; y 2 G with x 6 = y: In this survey we shall report {{on the existence of}} groups with anti [...] symmetric mappings, define equivalence relations between check digit systems and describe, in the special case of the dihedral group D 5, the equivalence classes. Keywords: check digit system, check character system, <b>error</b> <b>detecting</b> <b>code,</b> anti [...] symmetric mapping, complete mapping, orthomorphism, dihedral group, Chevalley group. 1 Introduction A check digit system with one check character is a systematic <b>error</b> <b>detecting</b> <b>code</b> over an alphabet A which arises by a [...] ...|$|E
40|$|A new burst <b>error</b> <b>detecting</b> <b>code</b> is {{described}} {{which has the}} form of the sum codes in that the check bits are determined from the algebraic sum of suitably weighted information bits. With the use of approximately k + log 2 (n/k) redundancy bits,where n is the number of information bits, the resultant code will detect all bursts of errors of length k or less in any channel and will also be a perfect error detection code in a completely asymmetric channel...|$|E
40|$|AbstractCodes {{which can}} correct t {{symmetric}} errors and detect all unidirectional errors {{have been shown}} to be useful in fault-tolerant applications. They provide protection against transient, intermittent and permanent faults. Efficient codes have already been developed for this purpose/ However, for most of these codes it is not possible to obtain a simple encoder and decoder. We have developed a systematic t-error correcting/all unidirectional <b>error</b> <b>detecting</b> <b>code,</b> which is comparable in redundancy to the most efficient known systematic codes with the same capability. In addition, our code is easy to encode and decode...|$|E
40|$|Abstract — This paper {{introduces}} a new coding scheme that faces simultaneously different issues of interconnection design (power, noise and crosstalk). Based on skewing signals on the link, its implementation {{is very simple}} and area-efficient. This scheme permits to double bandwidth and to improve noise tolerance {{through the use of}} two <b>error</b> <b>detecting</b> <b>codes.</b> The first one uses temporal redundancy and the second one is a parity-based <b>detecting</b> <b>code.</b> This noise tolerance property enables to decrease the power supply voltage to reduce power consumption. I...|$|R
50|$|Again, we {{are able}} to infer from the table of {{encodings}} that {{it must have been the}} letter A being transmitted. The number of errors this code can spot is one less than the number of time slots. It has also been proved that if the number of frequencies is a prime or a power of a prime, the orthogonal Latin squares produce <b>error</b> <b>detecting</b> <b>codes</b> that are as efficient as possible.|$|R
40|$|Abstract — Inspired by {{unidirectional}} <b>error</b> <b>detecting</b> <b>codes</b> {{that are}} used in situations where only one kind of bit error is possible (e. g., it is possible to change a bit “ 0 ” into a bit “ 1 ”, but not the contrary), we propose integrity codes (I-codes) for radio communication channels, which enable integrity protection of messages exchanged between entities that do not hold any mutual authentication material (i. e. public keys or shared secret keys). The construction of I-codes enables a sender to encode any message such that if its integrity is violated in transmission over a radio channel, the receiver is able to detect it. In order to achieve this, we rely on the physical properties of the radio channel and on unidirectional <b>error</b> <b>detecting</b> <b>codes.</b> We analyze in detail the use of I-codes and we present their implementation on a wireless platform as a “proof of concept”. We further introduce a novel concept called “authentication through presence”, whose broad applications include broadcast authentication, key establishment and navigation signal protection. We perform a detailed analysis of the security of our coding scheme and we show that it is secure within a realistic attacker model...|$|R
40|$|Graduation date: 2009 In {{diversity}} combining automatic repeat request (ARQ), erroneous packets {{are combined}} together forming a single, more reliable, packet. In this thesis, we give a diversity combining scheme for the m-ary unidirectional channel. A system using the given scheme with a t-unidirectional <b>error</b> <b>detecting</b> <b>code</b> is able to correct up to Emax = floor(t/ 2) unidirectional errors. To use the given scheme, the decoder {{should be able to}} decide the error type (increasing or decreasing). Hence, we give simple techniques to make this decision for various unidirectional error detecting codes...|$|E
40|$|We propose {{schemes that}} are {{efficient}} when {{each pair of}} qubits undergoes some imperfect collective decoherence with different baths. In the proposed scheme, each pair of qubits is first encoded in a decoherence-free subspace composed of two qubits. Leakage out of the encoding space generated by the imperfection is reduced by the quantum Zeno effect. Phase errors in the encoded bits generated by the imperfection are reduced by concatenation of the decoherence-free subspace with either a three-qubit quantum error correcting code that corrects only phase errors or a two-qubit quantum <b>error</b> <b>detecting</b> <b>code</b> that detects only phase errors, connected with the quantum Zeno effect again. Comment: no correction, 3 pages, RevTe...|$|E
40|$|We propose schemes {{which are}} {{efficient}} when each pairs of qubits undergo some imperfect collective decoherence with different baths. In the proposed scheme, each pairs of qubits are encoded in the decoherence free subspace composed of 2 qubits first. Leakage {{out of the}} encoding space generated by the imperfection is reduced by quantum Zeno effect. Phase errors in the encoded bits generated by the imperfection is reduced by either concatenation of the decoherence free subspace with 3 -qubit quantum error correcting code that corrects only phase errors or concatenation of the decoherence free subspace with 2 -qubit quantum <b>error</b> <b>detecting</b> <b>code</b> that detects only phase errors and quantum Zeno effect again...|$|E
40|$|The {{security}} of communication or computational systems protected by traditional <b>error</b> <b>detecting</b> <b>codes</b> rely {{on the assumption that}} the information bits of the message (output of the device-under-attack) are not known to attackers or the error patterns are not controllable by external forces. For applications where the assumption is not valid, e. g. secure cryptographic devices, secret sharing, etc, the {{security of}} systems protected by traditional <b>error</b> <b>detecting</b> <b>codes</b> can be easily compromised by an attacker. In this paper, we present constructions for strongly secure codes based on the nonlinear encoding functions. For (k, m, r) strongly secure codes, a message contains three parts: k-bit information data y, m-bit random data x and r-bit redundancy f(y, x). For any error e and information y, the fraction of x that masks the error e is less than 1. In this paper we describe lower and upper bounds on the proposed codes and show that the presented constructions can generate optimal or close to optimal codes. An efficient encoding and decoding method for the codes minimizing the number of multipliers using the multivariate Horner scheme is presented...|$|R
40|$|Abstract—Cryptographic devices {{suffer from}} fault {{injection}} attacks. The security of crypto-systems protected by traditional <b>error</b> <b>detecting</b> <b>codes</b> {{rely on the}} assumption that the information bits and the error patterns are not both controllable by the attacker. For applications where the assumption is not valid, the security of systems protected by traditional <b>error</b> <b>detecting</b> <b>codes</b> can be easily compromised. In this paper, we present constructions for algebraic manipulation detection (AMD) codes based on the nonlinear encoding functions. For a (k, m, r) AMD code, a message contains three parts: k-bit information data y, m-bit random data x and r-bit redundancy f(y, x). For any error e and information y, the fraction of x that masks the error e is less than 1. In this paper we describe lower and upper bounds on AMD codes and show that the presented constructions can generate optimal or close to optimal AMD codes in many cases. We presented efficient encoding and decoding methods for AMD codes minimizing the number of multipliers using the multivariate Horner scheme. The proposed codes can provide a guaranteed high <b>error</b> <b>detecting</b> probability even if both the information bits of the code and the non-zero error patterns are controllable by an attacker. These codes can be used for design of secure multipliers, secure memories or secure hardware implementing cryptography algorithms resistant to fault injection attacks...|$|R
40|$|We propose {{an on-line}} testing {{approach}} {{for the control}} logic of high performance microprocessors. Rather than adding information redundancy (in the form of <b>error</b> <b>detecting</b> <b>codes),</b> we propose {{to look for the}} information redundancy (referred to as Function-Inherent Codes) that the microprocessor control logic may inherently have, due to its required functionality. We will show that this allows to achieve on-line testing at significant savings in terms of area and power consumption, and with lower or comparable impact on system performance and design costs, compared to alternate, traditional on-line testing approaches...|$|R
