12|14|Public
50|$|Texas Instruments {{engineers}} afforded 16kB of Video Display Processor (VDP) RAM to the TI99/4A's <b>graphics</b> <b>coprocessor,</b> a TMS9918A. The VDP RAM was DRAM, {{with the}} VDP handling refresh. This is expandable to 192kB {{with the use}} of a Yamaha V9938 as a user-designed modification (not a standard upgrade option).|$|E
50|$|The term copperbar {{comes from}} a <b>graphics</b> <b>coprocessor</b> on the Amiga home {{computer}} {{referred to as the}} Copper (a shortened form of coprocessor). It can be programmed to change the display colors per scan line without requiring the CPU, except to update the position of the bars once per frame.|$|E
50|$|Although Intel {{had made}} earlier chips {{targeting}} graphics (e.g., 82786 <b>graphics</b> <b>coprocessor),</b> this {{was seen as}} Intel's first attempt {{to break into the}} video controller marketplace. The effort was a failure and led to Intel leaving the market for some time. The Indeo video compressor was originally built to work with the i750, but was later ported to other systems as well.|$|E
50|$|In 1991, S3 Graphics {{introduced}} the S3 86C911, which its designers {{named after the}} Porsche 911 as an implication of the performance increase it promised. The 86C911 spawned a host of imitators: by 1995, all major PC graphics chip makers had added 2D acceleration support to their chips. By this time, fixed-function Windows accelerators had surpassed expensive general-purpose <b>graphics</b> <b>coprocessors</b> in Windows performance, and these coprocessors faded away from the PC market.|$|R
40|$|Part I - Graphics Fundamentals PC GRAPHICS OVERVIEW History and Evolution Short History of PC Video PS/ 2 Video Systems SuperVGA <b>Graphics</b> <b>Coprocessors</b> and Accelerators <b>Graphics</b> Applications State-of-the-Art in PC Graphics 3 D Application Programming Interfaces POLYGONAL MODELING Vector and Raster Data Coordinate Systems Modeling with Polygons IMAGE TRANSFORMATIONS Matrix-based Representations Matrix Arithmetic 3 D Transformations PROGRAMMING MATRIX TRANSFORMATIONS Numeric Data in Matrix Form Array Processing PROJECTIONS AND RENDERING Perspective The Rendering Pipeline LIGHTING AND SHADING Lighti...|$|R
40|$|Abstract—Portable mobile {{computing}} and communication applications demand low-power and low-energy with high performance. These competing demands drive SoC development. Especially, 3 D graphics-intensive applications are predicted to become widely {{available on a}} variety of portable mobile devices ranging from laptops to PDAs to mobile phones. Such 3 D <b>graphics</b> <b>coprocessors</b> were originally developed for home computers and game consoles, which use steady power supplies. But a portable mobile device has a limited battery life, which needs to be prolonged as much as possible. Consequently, low power design is the most important segment in order to become competitively portable mobile consumer electronics. We are developing a high-performance, low-power, 3 D-graphics SoC to meet such requirements. This paper introduces our developing energy-awared mobile 3 D graphics SoC and its real-time performance/energy monitoring and control. Keywords- 3 D graphics accelerator; energy-awared; low-power design; OpenGL ES; performance monitoring; system-on-chip I...|$|R
5000|$|The {{main board}} also had four 80-pin {{expansion}} slots. The 1616 shared this backplane with a platform developed by Andrew Morton for Keno Computer Systems, allowing the 1616 to use expansion boards {{developed for the}} Keno Computer Systems platform (primarily the 34010 <b>graphics</b> <b>coprocessor),</b> although the form-factor was different, which left the KCS cards {{sticking out of the}} top of the 1616 case! ...|$|E
50|$|The Visual 1050 was an 8-bit desktop {{computer}} sold by Visual Technology {{in the early}} 1980s. The computer ran under the CP/M operating system and used 2 400KB, 5¼, SSDD, 96tpi floppy disk drives (TEAC FD-55E) for mass storage with an optional 10Mb external Winchester hard disk drive. In addition to the Zilog Z80 processor clocked at 4 MHz, the Visual 1050 also included a MOS Technology 6502 used as a <b>graphics</b> <b>coprocessor.</b>|$|E
5000|$|Although not {{the first}} PC video card to support {{hardware}} acceleration, IBM's 8514 is often credited as the first PC mass-market fixed-function accelerator. Up until the 8514's introduction, PC graphics acceleration was relegated to expensive workstation-class, <b>graphics</b> <b>coprocessor</b> boards. Coprocessor boards (such as the TARGA Truevision series) were designed around special CPU or digital signal processor chips which were programmable. Fixed-function accelerators, such as the 8514, sacrificed programmability for better cost/performance ratio.|$|E
50|$|The {{successor}} to the TMS34010, the TMS34020 (1988), provides several enhancements including an interface for a special <b>graphics</b> floating point <b>coprocessor,</b> the TMS34082 (1989). The primary function of the TMS34082 is to allow the TMS340 architecture to generate high quality three-dimensional (3D) graphics. The performance level of 60 million vertices per second was advanced at the time.|$|R
50|$|The Second Wave {{arrived in}} October 1979 {{when the first}} {{competitor}} in the new home computer market, Texas Instruments, fielded their TI-99/4 (whose CPU is a full 16-bit processor). Established game console maker Atari followed closely in November with their 400 and 800, which were the first home computers ever to have circuitry dedicated to processing of graphical video and audio data (inherited from Atari game console products). In 1980 Sinclair in the UK launched their super-cheap ZX80, heralded as the least expensive computer ever offered. Also in early 1980 the Radio Shack Color Computer made its debut. This was the first commercial computer to use the powerful Motorola 6809 CPU. In early 1981 Commodore introduced its VIC-20 which rivaled the Ataris for gameplay with a custom video chip that made hi-res color affordable but not so capable as the Atari's <b>graphics</b> <b>coprocessors.</b> The VIC-20 would become the first computer to sell one million units. Sinclair followed up the ZX80 with its ZX81 in March 1981. Sinclair would team up with Timex to market its home computers in the USA. In June Texas Instruments followed up its 99/4 with the improved 99/4A. In December Acorn Computer in the UK produced the BBC Micro. Finally in April 1982 Sinclair again topped itself with its new Spectrum. This last {{can be seen as}} a transition between the second wave and the third; successor models of the Spectrum would evolve in that direction.|$|R
50|$|It was {{the second}} {{three-dimensional}} Nintendo-developed game, behind 1992's X, also developed in cooperation with Argonaut Software. Star Fox was Nintendo's first game to use polygonal graphics. It accomplished this by being the first ever game to use the Super FX <b>graphics</b> acceleration <b>coprocessor</b> powered GSU-1. The complex display of three-dimensional models with polygons was still new and uncommon in console video games, and the game was much-hyped as a result. It has been re-imagined in three reboots/remakes: as Star Fox 64 on the Nintendo 64 in 1997, Star Fox 64 3D on the Nintendo 3DS in 2011, and Star Fox Zero on the Wii U in 2016.|$|R
50|$|In {{order to}} {{construct}} the VIC-II, Charpentier and Winterble made a market survey of current home computers and video games, listing up the current features, and what features they wanted {{to have in the}} VIC-II. The idea of adding sprites came from the Texas Instruments TI-99/4A computer and its TMS9918 <b>graphics</b> <b>coprocessor.</b> The idea to support collision detection came from the Mattel Intellivision. The Atari 800 was also mined for desired features. About 3/4 of the chip surface is used for the sprite functionality.|$|E
5000|$|Released in November 2012, its {{two models}} offer 8 or 16 GB and 1 GB of DDR3 system memory. Each {{features}} a 10.1 inch 1280×800 TFT display and Nvidia Tegra 3 SoC including a quad core 1.2 GHz CPU. And <b>Graphics</b> <b>Coprocessor</b> ULP High Performance 12-Core NVIDIA GeForce GPU. Also includes in a front-facing 2 MP camera. Ships with Android 4.0 {{but can be}} upgraded to Android 4.1 (Jelly Bean). Average Battery Life (in hours) 8 hours Number of USB 2.0 Ports 1- USB 2.0 Port 1- Micro USB 2.0 Port MicroSD memory card up to 32GB Item Dimensions L x W x H 10.20 x 6.90 x 0.48 inches Item Weight 1.5 pounds Wireless Type 802.11bgn Bluetooth® 2.1+EDR Sensors:G-Sensor, Gyroscope ...|$|E
50|$|Amiga computers, due {{to their}} special design {{attention}} to graphics performance, created in the 1980s a vast market of framebuffer based graphics cards. Noteworthy to mention was the graphics card in Amiga A2500 Unix, which was in 1991 the first computer to implement an X11 server program as a server for hosting graphical environments and the Open Look GUI graphical interface in high resolution (1024x1024 or 1024x768 at 256 colors). The graphics card for A2500 Unix was called the A2410 (Lowell TIGA Graphics Card) and was an 8-bit graphics board based on the Texas Instruments TMS34010 clocked at 50 MHz. It was a complete intelligent <b>graphics</b> <b>coprocessor.</b> The A2410 graphics card for Amiga was co-developed with Lowell University. Other noteworthy Amiga framebuffer based cards were: the Impact Vision IV24 graphics card from GVP, an interesting integrated video suite, capable of mixing 24-bit framebuffer, with Genlock, Chromakey, TV signal pass-thru and TV in a window capabilities; the DCTV an external graphics adapter and video capture system; the Firecracker 32-bit graphics card; the Harlequin card, the Colorburst; the HAM-E external framebuffer. The Graffiti external graphics card is still available on the market.|$|E
25|$|It was {{the second}} {{three-dimensional}} Nintendo-developed game, behind 1992's X, also developed in cooperation with Argonaut Software. Star Fox was Nintendo's first game to use polygonal graphics. It accomplished this by being the first ever game to use the Super FX <b>graphics</b> acceleration <b>coprocessor</b> powered GSU-1. The complex display of three-dimensional models with polygons was still new and uncommon in console video games, and the game was much-hyped as a result. It has been re-imagined in three reboots/remakes: as Star Fox 64 on the Nintendo 64 in 1997, Star Fox 64 3D on the Nintendo 3DS in 2011, and Star Fox Zero on the Wii U in 2016. Nintendo re-released Star Fox worldwide in September 2017 {{as part of the}} company's Super NES Classic Edition.|$|R
40|$|Trends in both {{consumer}} and high performance computing are bringing {{not only more}} cores, but also increased heterogeneity among the computational resources within a single machine. In many machines, {{one of the greatest}} computational resources is now their <b>graphics</b> <b>coprocessors</b> (GPUs), not just their primary CPUs. But GPU programming and memory models differ dramatically from conventional CPUs, and the relative performance characteristics of the different processors vary widely between machines. Different processors within a system often perform best with different algorithms and memory usage patterns, and achieving the best overall performance may require mapping portions of programs across all types of resources in the machine. To address the problem of efficiently programming machines with increasingly heterogeneous computational resources, we propose a programming model in which the best mapping of programs to processors and memories is determined empirically. Programs define choices in how their individual algorithms may work, and the compiler generates further choices in how they can map to CPU and GPU processors and memory systems. These choices are given to an empirical autotuning framework that allows the space of possible implementations to be searched at installation time. The rich choice space allows the autotuner to construct poly-algorithms that combine many different algorithmic techniques, using both the CPU and the GPU, to obtain better performance than any one technique alone. Experimental results show that algorithmic changes, and the varied use of both CPUs and GPUs, are necessary to obtain up to a 16. 5 x speedup over using a single program configuration for all architectures. United States. Dept. of Energy (Award DE-SC 0005288) United States. Defense Advanced Research Projects Agency (Award HR 0011 - 10 - 9 - 0009) National Science Foundation (U. S.) (Award CCF- 0632997...|$|R
30|$|The {{design of}} the Intel Phi as a {{standalone}} system was a critical aspect that motivated its use in this work. The use of PCIe to connect <b>coprocessors</b> (<b>Graphics</b> Processing Unit (GPU) or Intel Phi) to the CPU has {{shown to be a}} major bottleneck for attaining high performance in data intensive applications, limiting the application throughput to that of the PCIe channel used. Previous work that used GPU for IP lookup reported this limitation [1, 2]. Thus, even though the number of computing cores of current Intel Phi processors is smaller than the one found in GPUs, the Intel Phi is likely to emerge as a major platform for the practical deployment of parallel and efficient IP lookup algorithms.|$|R
5000|$|ISC also {{received}} {{the right to}} manufacture DIAB's DS90-10 and DS90-20 machines as its file servers. The multiprocessor DS90-20's, however, were too expensive for the target market and ISC designed its own servers and ported DNIX to them. ISC designed its own GUI-based diskless workstations for use with these file servers, and ported DNIX again. (Though ISC used Daisy workstations running Daisy DNIX to design the machines that would run DIAB's DNIX, there was negligible confusion internally as the drafting and layout staff rarely talked to the software staff. Moreover, the hardware design staff didn't use either system! The running joke went something like: [...] "At ISC we build computers, we don't use them.") The asynchronous I/O support of DNIX allowed for easy event-driven programming in the workstations, which performed well {{even though they had}} relatively limited resources. (The GUI diskless workstation had a 7 MHz 68010 processor and was usable with only 512K of memory, of which the kernel consumed approximately half. Most workstations had 1 MB of memory, though there were later 2 MB and 4 MB versions, along with 10 MHz processors.) A full-blown installation could consist of one server (16 MHz 68020, 8 MB of RAM, and a 200 MB hard disk) and up to 64 workstations. Though slow to boot up, such an array would perform acceptably in a bank teller application. Besides the innate efficiency of DNIX, the associated DIAB C compiler was key to high performance. It generated particularly good code for the 68010, especially after ISC got done with it. (ISC also retargeted it to the Texas Instruments TMS34010 <b>graphics</b> <b>coprocessor</b> used in its last workstation.) The DIAB C compiler was, of course, used to build DNIX itself {{which was one of the}} factors contributing to its efficiency, and is still available (in some form) through Wind River Systems.|$|E
40|$|The <b>Graphics</b> <b>Coprocessor</b> Engine (GRACE) {{is one of}} the Coprocessors {{within the}} ESPRIT II EuroWorkStation project (2569). It {{performs}} the graphics interface between the operators and their applications. Mainly there are two objectives to achieve: displaying the results of a computation and interacting with human users. The high speed generation of graphics data requires the design of specialized multiprocessor hardware for parallel processing of graphics objects and rendering purposes. The construction of a User Interface is based on object-oriented principles. The provision and support of graphics standards is used to integrate the design and facilitate the porting of existing applications...|$|E
40|$|As various applied sensors {{have been}} {{integrated}} into embedded devices, the Embedded Graphics Processing Unit (EGPU) has assumed more processing tasks, which requires an EGPU with higher performance. A tile-based EGPU is proposed {{that can be}} used in both general-purpose computing and 3 D graphics rendering. With fused, scalable, and hierarchical parallelism architecture, the EGPU has the ability to address nearly 100 million vertices or fragments and achieves 1 GFLOPS per second at a clock frequency of 200 [*]MHz. A fused and scalable architecture, constituted by Universal Processing Engine (UPE) and <b>Graphics</b> <b>Coprocessor</b> Cluster (GCC), ensures that the EGPU can adapt to various graphic processing scenes and situations, achieving more efficient rendering. Moreover, hierarchical parallelism is implemented via the UPE. Additionally, tiling brings a significant reduction in both system memory bandwidth and power consumption. A 0. 18 [*]µm technology library is used for timing and power analysis. The area of the proposed EGPU is 6. 5 [*]mm ∗ 6. 5 [*]mm, and its power consumption is approximately 349. 318 [*]mW. Experimental results demonstrate that the proposed EGPU can be used in a System on Chip (SoC) configuration connected to sensors to accelerate its processing and create a proper balance between performance and cost...|$|E
40|$|GPU {{acceleration}} is {{a promising}} approach {{to speed up}} query processing of database systems by using low cost <b>graphic</b> processors as <b>coprocessors.</b> Two major trends have emerged in this area: (1) The development of frameworks for scheduling tasks in heterogeneous CPU/GPU platforms, which is mainly {{in the context of}} coprocessing for applications and does not consider specifics of database-query processing and optimization. (2) The acceleration of database operations using efficient GPU algorithms, which typically cannot be applied easily on other database systems, because of their analytical–algorithm-specific cost models. One major challenge is how to combine traditional database query processing with GPU coprocessing techniques and efficient database operation scheduling in a GPU-aware query optimizer. In this thesis, we develop a hybrid query processing engine, which extends the traditional physical optimization process to generate hybrid query plans and to perform a cost-based optimization {{in a way that the}} advantages of CPUs and GPUs are combined. Furthermore, we aim at a portable solution between different GPU-accelerated database management systems to maximize applicability. Preliminary results indicate great potential. 1...|$|R
40|$|Novel"manycore" architectures, such as {{graphics}} processors, are high-parallel and high-performance shared-memory architectures [7] born {{to solve}} specific {{problems such as}} the graphical ones. Those architectures can be exploited to solve {{a wider range of}} problems by designing the related algorithm for such architectures. We present a fast sorting algorithm implementing an efficient bitonic sorting network. This algorithm is highly suitable for information retrieval applications. Sorting is a fundamental and universal problem in computer science. Even if sort has been extensively addressed by many research works, it still remains an interesting challenge to make it faster by exploiting novel technologies. In this light, this paper shows how to use <b>graphics</b> processors as <b>coprocessors</b> to speed up sorting while allowing CPU to perform other tasks. Our new algorithm exploits a memory-efficient data access pattern maintaining the minimum number of accesses to the memory out of the chip. We introduce an efficient instruction dispatch mechanism to improve the overall sorting performance. We also present a cache-based computational model for graphics processors. Experimental results highlight remarkable improvements over prior CPU-based sorting methods, and a significant improvement over previous GPU-based sorting algorithms...|$|R
50|$|The Fifth, last wave of {{computers}} specially meant {{for use as}} home computers arrived in June 1985 with the Atari ST. Soon after, but unavailable until 1986, came Commodore's Amiga. These new machines were an entirely new breed built around Motorola's 16/32-bit 68000 processor, the same as used in Apple's expensive Macintosh and premature Sinclair QL. This chip promised superior performance due to its advanced architecture and fast clock rate, made possible by fast yet inexpensive memory chips. Also, the 68000 could access megabytes of memory linearly, without any need for Intel's segmented memory model. This made huge, sophisticated programs easy to produce. Both machines used the new 3.5 inch floppy drives offering four times the storage of the 5.25 inch drives. The user interface used was graphical, like the Macintosh. The ST used a licensed version of Digital Research's GEM and the Amiga's original GUI featured true multitasking and windowing capability. The video hardware in these two computers could render graphics in {{hundreds or thousands of}} colors in high resolution. The Amiga had dedicated <b>graphics</b> and sound <b>coprocessors</b> for high performance video and audio. It found use as a workstation for motion video, a first for a standalone computer costing far less than dedicated motion-video processing equipment. Stereo sound became standard for the first time; the Atari ST gained popularity as an affordable alternative for MIDI equipment for the production of music. After a slow start the ST and Amiga gained traction in the market as software developers increased support for them. In following years both lines would be advanced using the faster, fully 32-bit successors of the Motorola 68000 CPU.|$|R
30|$|Miniaturization {{and power}} {{consumption}} {{are the first}} constraints for the design self-content mobile AR systems. Object positioning and drawing require computation resources, but control capacities are also necessary to handle data acquisition from sensors and communication protocols. The implementation of the first prototypes for such applications was based on backpacked laptops with 3 D graphics cards [9, 10]. Advanced mobile multiprocessor architectures are now available (e.g. OMAP 5, Snapdragon, Atom N 2800, ST-Ericsson Nova, Apple A 5,...), and they are typically based on cortex ARM cores or Intel Atoms with specialized <b>graphics</b> and video <b>coprocessors.</b> The main advantage of such architectures is the availability of software development frameworks. This kind of platforms is typically embedded in recent AR systems that also integrate IMU sensors: OMAP 3530 for Optinvent and OMAP 4430 for Vuzix and Google. However, they are mainly used to handle the video stream and the wired or wireless communication with a smartphone that remotely runs the AR application. As a matter of fact, high-resolution video games and video and image processing for object identification and complex online 3 D graphics computations would justify such processing resources. However, the type of AR applications we are targeting requires simple objects instead. Secondly, {{they do not need}} cameras and complex pose computation that requires image processing. So we believe and we demonstrate that such general-purpose processor (GPP)+GPU solutions are actually oversized regarding power autonomy constraints. We present in Section 2 an implementation of such a solution based on the Nova system-on-chip (SoC). Another possible solution is provided by reconfigurable architectures that enable specifically optimized and low-frequency designs. These rely on hardware/software design methodologies and recent high-performance FPGAs. These FPGAs are often power-hungry; however, the roadmap of FPGAs is clearly focused on this power issue with the aim to address the embedded system market. Recent hybrid ARM/FPGA architectures such a Xilinx/Zynq open new perspectives. On-chip memory capacity is also a key issue where significant progress has been made. For example, the Artix Xilinx low-power, low-cost family embeds up to 12 Mbits of block RAM. Regarding GPUs on FPGAs, Xylon has added a 3 D graphics module to the Logibrick library available under license in an early access version for evaluation. The architecture relies on a three-stage pipeline. This solution is a simplified version of the usual graphics pipeline and is designed for general purpose OpenGL embedded system (ES) applications. It shows that low-frequency dedicated architectures can be designed for this purpose. In [11], the authors present a GPU-inspired and multi-threaded softcore architecture, which is programmable with the NVIDIA Cg language. The aim is to simplify the use of FPGA-based acceleration boards for high-performance computing. Our approach is different, it is dedicated and designed for embedded systems and AR applications with a high focus on data locality optimization for minimizing data transfers.|$|R

