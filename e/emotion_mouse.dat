4|3|Public
40|$|This paper {{describes}} initial experiments collecting physiological {{data from}} subjects performing computer tasks. A prototype realtime <b>Emotion</b> <b>Mouse</b> collected skin temperature, {{galvanic skin response}} (GSR), and heartbeat data. Possible applications to distance education, and a second-generation system are discussed...|$|E
40|$|Automatic {{dialogue}} systems used, for instance, in call centers, {{should be}} able to determine in a critical phase of the dialogue––indicated by the customers vocal expression of anger/irritation––when it is better to pass over to a human operator. At a first glance, this {{does not seem to be}} a complicated task: It is reported in the literature that emotions can be told apart quite reliably on the basis of prosodic features. However, these results are achieved most of the time in a laboratory setting, with experienced speakers (actors), and with elicited, controlled speech. We compare classification results obtained with the same feature set for elicited speech and for a Wizard-of-Oz scenario, where users believe that they are really communicating with an automatic dialogue system. It turns out that the closer we get to a realistic scenario, the less reliable is prosody as an indicator of the speakersÕ emotional state. As a consequence, we propose to change the target such that we cease looking for traces of particular emotions in the usersÕ speech, but instead look for indicators of TROUBLE INCOMMUNICATION. INCOMMUNICATION For this reason, we propose the module Monitoring of User State [especially of] <b>Emotion</b> (<b>MOUSE</b> MOUSE) in which a prosodic classifier is combined with other knowledge sources, such as conversationally peculiar linguistic behavior, for example, the use of repetitions. For this module, preliminary exper-imental results are reported showing a more adequate modelling of TROUBLE INCOMMUNICATION...|$|E
40|$|Automatic {{dialogue}} systems used in call-centers, for instance, {{should be}} able to determine in a critical phase of the dialogue - indicated by the costumers vocal expression of anger/irritation - when it is better to pass over to a human operator. At a first glance, this seems not to be a complicated task: It is reported in the literature that emotions can be told apart quite reliably on the basis of prosodic features. However, these results are most of the time achieved in a laboratory setting, with experienced speakers (actors), and with elicited, controlled speech. We report classification results obtained within different experimental settings for the two-class-problem `neutral vs. anger' using a vector of prosodic features and discuss the impact of single features on the classification rate. Recognition rates for these settings are best for a speaker-specific classifier (one experienced speaker, acting), worse for a speaker-independent classifier (several less experienced speakers, reading), and even worse for a speaker-independent classifier with naive subjects performing the task of appointment scheduling in a Wizard-of-Oz-scenario where a malfunctioning system is simulated in order to evoke anger. The first situation mirrors most of the settings reported in the literature, the third is closest to the `real-life'-task. It thus turns out that prosody alone is not reliable as an indicator of the speakers emotional state the closer we get to a realistic scenario. As a consequence, the prosodic classifier was combined with other knowledge sources in the module Monitoring Of User State [especially of] <b>Emotion</b> (<b>MoUSE)</b> ...|$|E
40|$|Narcolepsy is a sleep {{disorder}} {{caused by}} the loss of orexin (hypocretin) -producing neurons and marked by excessive daytime sleepiness and a sudden weakening of muscle tone, or cataplexy, often triggered by strong <b>emotions.</b> In a <b>mouse</b> model for narcolepsy, we previously demonstrated that serotonin neurons of the dorsal raphe nucleus (DRN) mediate the suppression of cataplexy-like episodes (CLEs) by orexin neurons. Using an optogenetic tool, in this paperwe show that the acute activation of DRN serotonin neuron terminals in the amygdala, but not in nuclei involved in regulating rapid eye-movement sleep and atonia, suppressed CLEs. Not only did stimulating serotonin nerve terminals reduce amygdala activity, but the chemogenetic inhibition of the amygdala using designer receptors exclusively activated by designer drugs also drastically decreased CLEs, whereas chemogenetic activation increased them. Moreover, the optogenetic inhibition of serotonin nerve terminals in the amygdala blocked the anticataplectic effects of orexin signaling in DRN serotonin neurons. Taken together, the results suggest that DRN serotonin neurons, as a downstream target of orexin neurons, inhibit cataplexy by reducing the activity of amygdala as a center for emotional processing...|$|R
40|$|People with {{narcolepsy}} {{often have}} episodes of cataplexy, brief periods of muscle weakness triggered by strong emotions. Many researchers are now studying mouse models of narcolepsy, but definitions of cataplexy-like behavior in mice differ across labs. To establish a common language, the International Working Group on Rodent Models of Narcolepsy reviewed {{the literature on}} cataplexy in people with narcolepsy and in dog and mouse models of narcolepsy and then developed a consensus definition of murine cataplexy. The group concluded that murine cataplexy is an abrupt episode of nuchal atonia lasting at least 10 seconds. In addition, theta activity dominates the EEG during the episode, and video recordings document immobility. To distinguish a cataplexy episode from REM sleep after a brief awakening, at least 40 seconds of wakefulness must precede the episode. Bouts of cataplexy fitting this definition are common in mice with disrupted orexin/hypocretin signaling, but these events almost never occur in wild type mice. It remains unclear whether murine cataplexy is triggered by strong <b>emotions</b> or whether <b>mice</b> remain conscious during the episodes as in people with narcolepsy. This working definition provides helpful insights into murine cataplexy and should allow objective and accurate comparisons of cataplexy in future studies using mouse models of narcolepsy...|$|R
40|$|This thesis {{aimed at}} {{developing}} {{a better understanding}} on how mice perceive their own emotional state. Next to extending on previous research on the adaptive capacities laboratory mice, we aimed at approaching the emotional perceptions of mice by establishing a behavioural test {{for the assessment of}} judgement bias. Adaptive behaviour translates into the waning of a behavioural response over time (i. e. behavioural habituation). Evaluation of behavioural habituation therefore offers a valuable “behavioural tool” to investigate changes in emotional assessments of a given stimulus in animals. The results of this thesis show that mice differ significantly regarding their ability to adapt to challenging conditions. Further, to better understand whether such behaviour might reflect the animals’ perception of its own emotional state we aimed at developing a judgement bias test for mice. A judgement bias results from an either more positive or more negative interpretation of an ambiguous stimulus (a stimulus with uncertain value). Negative emotional states induce a more negative interpretation while positive emotional states induce a more positive interpretation of the same stimulus: the glass is either half full or half empty. This thesis supports the idea that odour conditioning tests can be useful in investigating judgement bias in mice, although some methodological issues remain to be solved in future experiments. In addition to behavioural observations, different physiological and central nervous parameters were investigated {{in order to get a}} first indication of the underlying mechanisms that may regulate emotional perception in mice. From both the findings on mouse behaviour and at the central nervous level in the present thesis and previous work it can be concluded that a lack of behavioural habituation might be the result of an impaired cognitive control of emotional processes. Such a characteristic seems to have a clear genetic component since environmental challenges alone did not result in a persistent impairment of habituation in mice. From that it can be concluded that impaired habituation might be indicative of exceeded adaptive capacities and might be a valuable “behavioural tool” to investigate emotional dysfunctions in animals. In addition, brain area’s related to emotion and cognition seem to be involved in the expression of judgement biases as well, supporting the notion that the measurement of judgement biases in mice might provide more information on the animals’ perception of its own emotional state and, thus, first steps have been taken in establishing methods for gaining a better understanding of the (dys) regulation of <b>emotions</b> in <b>mice</b> and, hence in the management of their welfare...|$|R
40|$|Automatic {{dialogue}} systems used in call-centers, for instance, {{should be}} able to determine in a critical phase of the dialogue- indicated by the costumers vocal expression of anger/irritation- when it is better to pass over to a human operator. At a rst glance, this seems not to be a complicated task: It is reported in the literature that emotions can be told apart quite reliably on the basis of prosodic features. However, these results are most of the time achieved in a laboratory setting, with experienced speakers (actors), and with elicited, controlled speech. We report classi cation results obtained within di erent experimental settings for the two-class-problem `neutral vs. anger ' using a vector of prosodic features and discuss the impact of single features on the classi cation rate. Recognition rates for these settings are best for a speaker-speci c classi er (one experienced speaker, acting), worse for a speaker-independent classi er (several less experienced speakers, reading), and even worse for a speaker-independent classi er with naive subjects performing the task of appointment scheduling in a Wizard-of-Oz-scenario where a malfunctioning system is simulated in order to evoke anger. The rst situation mirrors most of the settings reported in the literature, the third is closest to the `real-life'-task. It thus turns out that prosody alone is not reliable as an indicator of the speakers emotional state the closer we get to a realistic scenario. As a consequence, the prosodic classi er was combined with other knowledge sources in the module Monitoring Of User State [especially of] <b>Emotion</b> (<b>MoUSE).</b> 1...|$|E

