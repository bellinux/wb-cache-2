0|1126|Public
30|$|Many real-life {{networks}} behave not deterministic but stochastic. Examples can {{be found}} in areas like communication systems, production, maintenance, and logistics systems. Construction and analysis of stochastic network optimization models rely on techniques from <b>fundamental</b> <b>probability</b> theory and mathematical statistics.|$|R
5000|$|<b>Probability</b> <b>sets</b> {{which make}} the nonadditive Tsallis entropy to be {{extensive}} in the thermodynamical sense.|$|R
60|$|The {{plan was}} bound to be extensive, as its objects were extensive, and it took for granted in the case of Ireland the <b>fundamental</b> <b>probabilities</b> of civil society. He who looks with “indolent and kingly gaze” upon all {{projects}} of written constitutions need not turn to the Appendix unless he will. Two features of the plan were cardinal.|$|R
3000|$|... is a <b>probability</b> <b>set</b> {{determined}} as follows: to each interval {{is associated}} a weight {{which is the}} product of probabilities δ [...]...|$|R
40|$|A Bayesian {{game is a}} game of {{incomplete}} {{information in}} which {{the rules of the}} game are not fully known to all players. We consider the Bayesian game of Battle of Sexes that has several Bayesian Nash equilibria and investigate its outcome when the underlying <b>probability</b> <b>set</b> is obtained from generalized Einstein-Podolsky-Rosen experiments. We find that this <b>probability</b> <b>set,</b> which may become non-factorizable, results in a unique Bayesian Nash equilibrium of the game. Comment: 18 pages, 2 figures, accepted for publication in Quantum Information Processin...|$|R
40|$|Published online: 20 September 2014 A Bayesian {{game is a}} game of {{incomplete}} {{information in}} which {{the rules of the}} game are not fully known to all players. We consider the Bayesian game of Battle of Sexes that has several Bayesian Nash equilibria and investigate its outcome when the underlying <b>probability</b> <b>set</b> is obtained from generalized Einstein–Podolsky–Rosen experiments. We find that this <b>probability</b> <b>set,</b> which may become non-factorizable, results in a unique Bayesian Nash equilibrium of the game. Azhar Iqbal, James M. Chappell, Qiang Li, Charles E. M. Pearce, Derek Abbot...|$|R
40|$|The {{properties}} of one???step Markov, rotationally and m???step (m= 1 or 2) translationally invariant (MRT) probability measures on q???state???site (qSS) Bethe lattices are studied. A theorem is proven, which completely defines such measures {{in terms of}} m(q 2 +q) <b>fundamental</b> <b>probabilities.</b> These are explicitly calculated for any MRT???qSS Hamiltonian model. As a consequence of our approach, the dychotomy between alternative solutions of Hamiltonian models on Bethe lattices is solved...|$|R
2500|$|In this <b>probability</b> <b>setting,</b> {{the measure}} [...] is {{intended}} as a probability , the integral with respect to [...] as an expected value , and the function [...] as a random variable X.|$|R
40|$|International audienceWhen {{working with}} <b>sets</b> of <b>probabilities,</b> basic {{information}} fusion operators quickly reach their limits: intersection becomes empty, while union {{results in a}} poorly informative model. An attractive means to overcome these limitations is to use maximal coherent subsets (MCS). However, identifying the maximal coherent subsets is generally NP-hard. Previous proposals advocating the use of MCS to merge <b>probability</b> <b>sets</b> have not provided efficient ways to perform this task. In this paper, we propose an efficient approach to do such a merging between imprecise probability masses, a popular model of <b>probability</b> <b>sets,</b> and test it on an ensemble classification problem...|$|R
40|$|The {{class of}} Riemann zeta {{distribution}} {{is one of}} the classical classes of probability distributions on R. Multidimensional Shintani zeta function is introduced and its definable probability distributions on R^d are studied. This class contains some <b>fundamental</b> <b>probability</b> distributions such as binomial and Poisson distributions. The relation with multidimensional polynomial Euler product, which induces multidimensional infinitely divisible distributions on R^d, is also studied. Comment: 15 pages. arXiv admin note: text overlap with arXiv: 1204. 404...|$|R
5000|$|<b>Fundamentals</b> of <b>probability</b> {{theory and}} in {{particular}} the use of some measurement results to evaluate, Budapest, Textbook Publishers, 1965, 206 p [...]|$|R
30|$|When each MANET {{is named}} with, say, eight random {{characters}} then the <b>probability</b> <b>sets</b> close to 1 {{for the two}} merging MANET’s for {{not to have the}} same ID. The purpose of MANET ID is to differentiate the nodes belonging to different networks.|$|R
40|$|This paper {{addresses}} {{the estimation of}} a semiparametric sample selection index model where both the selection rule and the outcome variable are binary. Since the marginal effects are often of primary interest and are difficult to recover in a semiparametric setting, we develop estimators for both the marginal effects and the underlying model parameters. The marginal effect estimator only uses observations which {{are members of a}} high <b>probability</b> <b>set</b> in which the selection problem is not present. A key innovation is that this high <b>probability</b> <b>set</b> is data dependent. The model parameter estimator is a quasi-likelihood estimator based on regular kernels with bias corrections. We establish their large sample properties and provide simulation evidence confirming that these estimators perform well in finite samples. ...|$|R
40|$|We derive an {{extension}} of McDiarmid's inequality for functions f with bounded differences on a high <b>probability</b> <b>set</b> Y (instead of almost surely). The behavior of f outside Y may be arbitrary. The proof is short and elementary, and relies on {{an extension}} argument similar to Kirszbraun's theorem. Comment: Note (4 pages...|$|R
40|$|Inferences in {{directed}} acyclic graphs {{associated with}} <b>probability</b> <b>sets</b> and <b>probability</b> intervals are NP-hard, even for polytrees. In this paper {{we focus on}} such inferences, and propose: 1) a substantial improvement on Tessems A / R algorithm FOR polytrees WITH probability intervals; 2) a new algorithm FOR direction - based local search(IN <b>sets</b> OF <b>probability)</b> that improves ON existing methods; 3) a collection OF branch - AND - bound algorithms that combine the previous techniques. The first two techniques lead TO approximate solutions, WHILE branch - AND - bound procedures can produce either exact OR approximate solutions. We report ON dramatic improvements ON existing techniques FOR inference WITH <b>probability</b> <b>sets</b> AND intervals, IN SOME cases reducing the computational effort BY many orders OF magnitude. Comment: Appears in Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence (UAI 2003...|$|R
40|$|We extend vector {{formalism}} {{by including}} {{it in the}} algebra of split octonions, which we treat as the universal algebra to describe physical signals. The new geometrical interpretation of the products of octonionic basis units is presented. Eight real parameters of octonions are interpreted as the space-time coordinates, momentum and energy. In our approach the two fundamental constants, c and �, have the geometrical meaning and appear from the condition of positive definiteness of the octonion norm. We connect the property of non-associativity with the time irreversibility and <b>fundamental</b> <b>probabilities</b> in physics. PACS numbers: 01. 55. +b; 02. 10. De; 04. 50. +h...|$|R
40|$|We {{study the}} {{existence}} of SRB measures of C 2 diffeomorphisms for attractors whose bundles admit Holder continuous invariant (non-dominated) splittings. We prove the existence when one subbundle has the non-uniform expanding property on a set with positive Lebesgue measure and the other subbundle admits non-positive Lyapunov exponents on a total <b>probability</b> <b>set.</b> Comment: 31 page...|$|R
40|$|The Dutch book {{argument}} is a coherence {{condition for the}} existence of subjective probabilities. This note gives a general framework of analysis for this argument in a nonadditive <b>probability</b> <b>setting.</b> Particular cases are given by comonotonic and affinely related Dutch books that lead to Choquet expectations and Min expectations. Coherence; Dutch Book; Constant Linearity; Choquet Expectation; Multiple Priors...|$|R
60|$|We were {{no longer}} bound, but yet {{remained}} helpless. I could move neither hand nor foot, struggle as I might. It was as if my limbs were dead while my body yet remained alive; but Jacob, who had in his wild plan considered just such a <b>probability,</b> <b>set</b> about chafing {{my arms and legs}} until the feeling began to return.|$|R
40|$|Although the neutrosophic {{statistics}} {{has been}} defined since 1996, and published in the 1998 book Neutrosophy. / Neutrosophic <b>Probability,</b> <b>Set,</b> and Logic, {{it has not been}} developed since now. A similar fate had the neutrosophic probability that, except a few sporadic articles published in the meantime, it was barely developed in the 2013 book “Introduction to Neutrosophic Measure, Neutrosophic Integral, and Neutrosophic Probability”...|$|R
40|$|<b>Probability</b> answer <b>set</b> {{programming}} is a declarative programming {{that has been}} shown effective for representing and reasoning about a variety of probability reasoning tasks. However, the lack of probability aggregates, e. g. expected values, {{in the language of}} disjunctive hybrid probability logic programs (DHPP) disallows the natural and concise representation of many interesting problems. In this paper, we extend DHPP to allow arbitrary probability aggregates. We introduce two types of probability aggregates; a type that computes the expected value of a classical aggregate, e. g., the expected value of the minimum, and a type that computes the probability of a classical aggregate, e. g, the probability of sum of values. In addition, we define a <b>probability</b> answer <b>set</b> semantics for DHPP with arbitrary probability aggregates including monotone, antimonotone, and nonmonotone probability aggregates. We show that the proposed <b>probability</b> answer <b>set</b> semantics of DHPP subsumes both the original <b>probability</b> answer <b>set</b> semantics of DHPP and the classical answer set semantics of classical disjunctive logic programs with classical aggregates, and consequently subsumes the classical answer set semantics of the original disjunctive logic programs. We show that the proposed <b>probability</b> answer <b>sets</b> of DHPP with probability aggregates are minimal probability models and hence incomparable, which is an important property for nonmonotonic probability reasoning...|$|R
3000|$|Two {{experiments}} of simulation {{data and}} real data {{have been carried}} out to evaluate the performance of the proposed filter in comparison with the other four filters, including the PDA filter [3], IMM-PDA filter [12], fuzzy adaptive (FA) α-β filter [21], and FRLS filter [28] in terms of the position root mean squared errors (RMSE). In the experiments, the detection probability and gate <b>probability</b> <b>set</b> P [...]...|$|R
30|$|All {{experimental}} data {{were subjected to}} Student t-test to determine the significance level {{with respect to the}} control. The number of replicates varied from 3 to 7, depending on the experiment. Therefore, t-tests for two-samples assuming unequal variances were performed with a significance level of <b>probability</b> <b>set</b> at p[*]<[*] 0.05. All error bars were standard deviations of multiple measurements of each parameter, all derived from biological replicates.|$|R
40|$|We show that, for {{sequences}} of vectors of multiple Wigner integrals {{with respect to}} a free Brownian motion, componentwise convergence to semicircular is equivalent to joint convergence. This result extends to the free <b>probability</b> <b>setting</b> some findings by Peccati and Tudor (2005), and represents a multidimensional counterpart of a limit theorem inside the free Wigner chaos established by Kemp, Nourdin, Peccati and Speicher (2011). Comment: 11 page...|$|R
40|$|Inferences in {{directed}} acyclic graphs {{associated with}} <b>probability</b> intervals and <b>sets</b> of probabil-ities are NP-hard, even for polytrees. We pro-pose: 1) an improvement on Tessem’s A/R algo-rithm for inferences on polytrees associated with probability intervals; 2) a new algorithm for ap-proximate inferences based on local search; 3) branch-and-bound algorithms that combine the previous techniques. The first two algorithms produce complementary approximate solutions, while branch-and-bound procedures can gener-ate either exact or approximate solutions. We report improvements on existing techniques for inference with <b>probability</b> <b>sets</b> and intervals, {{in some cases}} reducing computational effort by sev-eral orders of magnitude. ...|$|R
40|$|We {{present a}} unified logical {{framework}} for representing and reasoning about both probability {{quantitative and qualitative}} preferences in <b>probability</b> answer <b>set</b> programming, called <b>probability</b> answer <b>set</b> optimization programs. The proposed framework is vital to allow defining probability quantitative preferences over the possible outcomes of qualitative preferences. We show the application of <b>probability</b> answer <b>set</b> optimization programs to {{a variant of the}} well-known nurse restoring problem, called the nurse restoring with probability preferences problem. To the best of our knowledge, this development is the first to consider a logical framework for reasoning about probability quantitative preferences, in general, and reasoning about both probability quantitative and qualitative preferences in particular. Comment: arXiv admin note: substantial text overlap with arXiv: 1304. 2384, arXiv: 1304. 279...|$|R
3000|$|... by 1. Then, {{the sensor}} node uses (10) to {{recalculate}} the table <b>probability</b> and <b>set</b> try {{for the previous}} [...]...|$|R
30|$|The VSM and {{probability}} {{model can}} simplify the text processing into vector space or <b>probability</b> <b>set.</b> It involves the term frequency property {{to describe the}} number of occurrences of query words in the paper. Considering the particularity of document segmentation, the word in different sections has a different weight of summarization for the paper, which simply calculates that word appearance is not sufficient. Meanwhile, there is no vocabulary set with standard semantic feature and document label.|$|R
3000|$|... of {{intervals}} {{issued from}} compelled links (for non-compelled links, probabilities are {{accounted for by}} means of the random selection process); these weights are then normalized to obtain probabilities. Finally, the histogram of the interference gain G can be constructed from these resulting amplitude and <b>probability</b> <b>sets.</b> It is important to note, however, that, as a random drawing process is involved, a number of iterations might be needed in order for this process to converge (elements of S [...]...|$|R
40|$|This {{introduction}} to probability theory transforms a highly abstract subject {{into a series}} of coherent concepts. Its extensive discussions and clear examples, written in plain language, expose students to the rules and methods of probability. Suitable for an introductory probability course, this volume requires abstract and conceptual thinking skills and a background in calculus. Topics include classical <b>probability,</b> <b>set</b> theory, axioms, <b>probability</b> functions, random and independent random variables, expected values, and covariance and correlations. Additional subjects include stochastic proces...|$|R
40|$|The {{emphasis}} of this textbook is on industrial applications of Statistical Measurement Theory. It {{deals with the}} principal issues of measurement theory, is concise and intelligibly written, and to a wide extent self-contained. Difficult theoretical issues are separated from the mainstream presentation. Each topic starts with an informal introduction followed by an example, the rigorous problem formulation, solution method, and a detailed numerical solution. Each chapter concludes {{with a set of}} exercises of increasing difficulty, mostly with solutions. The book is meant as a text for graduate students and a reference for researchers and industrial experts specializing in measurement and measurement data analysis for quality control, quality engineering and industrial process improvement using statistical methods. Knowledge of calculus and <b>fundamental</b> <b>probability</b> and statistics is required for the understanding of its contents...|$|R
40|$|Despite the {{tremendous}} empirical success of quantum theory {{there is still}} widespread disagreement about what it {{can tell us about}} the nature of the world. A central question is whether the theory is about our knowledge of reality, or a direct statement about reality itself. Regardless of their stance on this question, current interpretations of quantum theory regard the Born rule as fundamental and add an independent state-update (or "collapse") rule to describe how quantum states change upon measurement. In this paper we present an alternative perspective and derive a probability rule that subsumes both the Born rule and the collapse rule. We show that this more <b>fundamental</b> <b>probability</b> rule can provide a rigorous foundation for informational, or "knowledge-based", interpretations of quantum theory. Comment: 6 + 2 pages; 3 figure...|$|R
30|$|Each {{operator}} accesses all channels {{with the}} same transmit probability at the same time. Note that the initial transmit <b>probabilities</b> are <b>set</b> to 1.|$|R
40|$|International audienceWe study {{different}} possibilities {{to apply}} the principles of rough paths theory in a non-commutative <b>probability</b> <b>setting.</b> First, we extend previous results obtained by Capitaine, Donati-Martin and Victoir in Lyons' original formulation of rough paths theory. Then we settle the bases of an alternative non-commutative integration procedure, {{in the spirit of}} Gubinelli's controlled paths theory, and which allows us to revisit the constructions of Biane and Speicher in the free Brownian case. New approximation results are also derived from the strategy...|$|R
3000|$|... where μ is the {{approximation}} {{form of the}} offset measure, D is {{the fusion}} structure between different offset set models under different offset parameters, μ̃_G_ 1 |P^' is the high-level offset <b>set</b> <b>probability</b> measure, and μ̃_G_ 2 |P.^' is the middle offset <b>set</b> <b>probability</b> measure.|$|R
50|$|The first theory {{seems less}} likely, {{and its a}} priori <b>{{probability}}</b> is <b>set</b> at 1%, while the probability of the second is logically set to 99%.|$|R
