30|42|Public
25|$|IBM JCL uses {{a double}} slash to start each {{line in a}} batch <b>job</b> <b>stream</b> except for /* and /&.|$|E
2500|$|It is also {{possible}} to use solely the macro processing abilities of an assembler to generate code written in completely different languages, for example, to generate a version of a program in COBOL using a pure macro assembler program containing lines of COBOL code inside assembly time operators instructing the assembler to generate arbitrary code. IBM OS/360 uses macros to perform system generation. The user specifies options by coding a series of assembler macros. [...] Assembling these macros generates a <b>job</b> <b>stream</b> to build the system, including job control language and utility control statements.|$|E
5000|$|EXEC II is a batch {{processing}} operating system that supports a single <b>job</b> <b>stream</b> with concurrent spooling.|$|E
50|$|With V3R3 (1992), all TPNS {{programs}} and utilities (ITPxxxxx) could be operated entirely from ISPF in a panel-driven fashion, instead of through the TSO command line, or through discrete JCL <b>job</b> <b>streams.</b>|$|R
40|$|Abstract – Clusters, multi-cluster {{systems and}} the grid are {{becoming}} popular high performance computing infrastructures. How jobs are scheduled on them greatly influence the performance. Since jobs are online in most computer systems, they are scheduled when the entire information about them is unknown. We propose a greedy scheduling algorithm that uses both arrival order and how hard a job is to schedule while prioritizing. We compare its performance {{with that of the}} Fit processor First Served (FPFS) algorithm. We deduce performance dominance on different <b>job</b> <b>streams...</b>|$|R
5000|$|Conversational Programming System or CPS was {{an early}} Time-sharing system offered by IBM which ran on System/360 {{mainframes}} circa 1967 through 1972. CPS was implemented as an interpreter, and users could select either a rudimentary form of BASIC or a reasonably complete version of PL/I. A third option provided remote job entry (RJE) features allowing users to submit JCL <b>job</b> <b>streams</b> for batch processing. A fourth option was called control mode. Normally, only the system operator would be permitted to use control mode. The available features in control mode included: ...|$|R
50|$|IBM JCL uses {{a double}} slash to start each {{line in a}} batch <b>job</b> <b>stream</b> except for /* and /&.|$|E
5000|$|A simple {{example of}} a <b>job</b> <b>stream</b> is a system to print payroll checks which might consist of the {{following}} steps, performed on a batch of inputs: ...|$|E
50|$|SMP/E is {{a single}} large program which runs as a batch job. A series of ISPF panels {{can be used to}} interactively build the SMP/E <b>job</b> <b>stream</b> based on user input.|$|E
50|$|Ontario's Ministry of Citizenship, Immigration, and International Trade {{recruits}} international post-secondary {{students as}} permanent residents through three Provincial Nominee Programs: the International Student With <b>Job</b> Offer <b>Stream,</b> the International Masters Graduate Stream, and the International PhD Graduate Stream.|$|R
40|$|This thesis {{describes}} {{regression analysis}} and shows {{how it can}} be used in account auditing and in computer system performance analysis. The study first introduces regression analysis techniques and statistics. Then, the use of regression analysis in auditing to detect "out of line" accounts and to determine audit sample size is discussed. These applications led to the concept of using regression analysis to predict job completion times in a computer system. The feasibility of this application of regression analysis was tested by constructing a predictive model to estimate job completion times using a computer system simulator. The predictive model's performance for the various <b>job</b> <b>streams</b> simulated shows that job completion time prediction is a feasible application for regression analysis...|$|R
40|$|Two {{independent}} Poisson <b>streams</b> of <b>jobs</b> {{flow into}} a single-server service system having a limited common buffer that can hold at most one job. If a type-i job (i= 1, 2) finds the server busy, it is blocked and routed {{to a separate}} type-i retrial (orbit) queue that attempts to re-dispatch its jobs at its specific Poisson rate. This creates a system with three dependent queues. Such a queueing system serves {{as a model for}} two competing <b>job</b> <b>streams</b> in a carrier sensing multiple access system. We study the queueing system using multi-dimensional probability generating functions, and derive its necessary and sufficient stability conditions while solving a boundary value problem. Various performance measures are calculated and numerical results are presented. Comment: N° RR- 7999 (2012...|$|R
50|$|For MVT (either TYPE=MVT or TYPE=M65MP) with TSO, the TSOGEN macro {{plays the}} same role as GENERATE. Either macros {{analyzes}} the options specified on the previous macro calls and punches the Stage 2 <b>job</b> <b>stream.</b>|$|E
50|$|Stage 1 is the {{compilation}} of {{a sequence of}} assembler macro instructions describing the configuration to be installed or updated. The assembler does not actually compile any object code, but instead compiles a series of PUNCH pseudo-ops in order to generate a <b>job</b> <b>stream</b> for Stage 2. As IBM changed the nomenclature for OS/360 options, it also changed the Sysgen macro definitions to use newer names for the options.|$|E
5000|$|The Multiple Sequential Scheduler option, {{known as}} Multiprogramming with a Fixed Number of Tasks (MFT) {{provided}} execution of multiple concurrent jobs. Execution was {{governed by a}} priority which had a default for each stream or could be requested separately for each job. MFT version II added subtasks (threads), which executed at a priority based on that of the parent job. Each <b>job</b> <b>stream</b> defined {{the maximum amount of}} memory which could be used by any job in that stream.|$|E
30|$|In the {{remainder}} of this paper, the terms task and message <b>stream</b> (<b>job</b> and message) will be indistinctly used.|$|R
40|$|ProcSimity is a {{software}} tool that supports research in processor allocation and scheduling for highly parallel systems. ProcSimity's multicomputer simulator supports experimentation with selected allocation and scheduling algorithms on architectures {{with a range}} of network topologies and for several current routing and flow control mechanisms. Message-passing can be simulated in detail at the flit level or at a higher level of modeling. Our tool supports both stochastic <b>job</b> <b>streams</b> as well as communication patterns from actual parallel applications, including several of the NAS parallel benchmarks. ProcSimity's visualization and performance analysis tool allows the user to view a dynamic animation of the selected algorithms as well as a variety of system and job level performance metrics. ProcSimity has been successfully used in experiments investigating the feasibility of non-contiguous processor allocation in meshes and k-ary n-cubes. 1 Introduction We have developed {{a software}} too [...] ...|$|R
40|$|In {{spite of}} growing uses of {{information}} technologies, institutional policies for job classification and compensation {{in the information}} fields appear not to be keeping pace with changes in actua job content. The <b>job</b> <b>streams</b> {{that have been in}} existence for decades have not been adjusted {{to take into account the}} significant alterations occurring at working levels on campuses. Drawing on a study conducted from 1990 to 1992, this paper provides some empirical evidence that points toward the need to create one information job family and some models that point in the direction of the future. The exploratory study analyzed 63 jobs in computing centers and libraries at three selected institutions. The notion that a single job family for academic computing and library jobs is emerging was validated through this study. Also apparent wls the need for analytical factors to be selected carefully and adjusted to reflect the values of th...|$|R
50|$|It is also {{possible}} to use solely the macro processing abilities of an assembler to generate code written in completely different languages, for example, to generate a version of a program in COBOL using a pure macro assembler program containing lines of COBOL code inside assembly time operators instructing the assembler to generate arbitrary code. IBM OS/360 uses macros to perform system generation. The user specifies options by coding a series of assembler macros. Assembling these macros generates a <b>job</b> <b>stream</b> to build the system, including job control language and utility control statements.|$|E
50|$|In computing, {{a job is}} a unit of work or unit of {{execution}} (that performs said work). A component of a job (as a unit of work) is called a task or a step (if sequential, as in a <b>job</b> <b>stream).</b> As a unit {{of execution}}, a job may be concretely identified with a single process, which may in turn have subprocesses (child processes; the process corresponding to the job being the parent process) which perform the tasks or steps that comprise {{the work of the}} job; or with a process group; or with an abstract reference to a process or process group, as in Unix job control.|$|E
5000|$|In a non-interactive {{computer}} system, particularly IBM mainframes, a <b>job</b> <b>stream,</b> jobstream, {{or simply}} job is {{the sequence of}} job control language statements (JCL) and data (called instream data) that comprise a single [...] "unit of work for an operating system". The term job traditionally means a one-off piece of work, and is contrasted with a batch (executing the same steps over many inputs), but non-interactive computation {{has come to be}} called [...] "batch processing", and thus a unit of batch processing is often called a job, or by the oxymoronic term batch job; see job for details. Performing a job consists of executing one or more programs. Each program execution, called a job step, jobstep, or step, is usually related in some way to the others in the job. Steps in a job are executed sequentially, possibly depending on the results of previous steps, particularly in batch processing.|$|E
40|$|International audienceTwo {{independent}} Poisson <b>streams</b> of <b>jobs</b> {{flow into}} a single-server service system having a limited common buffer that can hold at most one job. If a type- i job (i= 1, 2) finds the server busy, it is blocked and routed {{to a separate}} type- i retrial (orbit) queue that attempts to re-dispatch its jobs at its specific Poisson rate. This creates a system with three dependent queues. Such a queueing system serves {{as a model for}} two competing <b>job</b> <b>streams</b> in a carrier sensing multiple access system. We study the queueing system using multi-dimensional probability generating functions, and derive its necessary and sufficient stability conditions while solving a Riemann–Hilbert boundary value problem. Various performance measures are calculated and numerical results are presented. In particular, numerical results demonstrate that the proposed multiple access system with two types of jobs and constant retrial rates provides incentives for the users to respect their contracts...|$|R
40|$|Modern {{embedded}} multimedia systems process multiple concurrent {{streams of}} data processing <b>jobs.</b> <b>Streams</b> often have throughput requirements. These jobs are implemented on a multiprocessor {{system as a}} task graph. Tasks communicate data over buffers, where tasks wait on sufficient space in output buffers before producing their data. For cost reasons, jobs share resources. Because jobs can share resources with other jobs that include tasks with data-dependent execution rates, we assume run-time scheduling on shared resources. Budget schedulers are applied, because they guarantee a minimum budget in a maximum replenishment interval. Both the buffer sizes {{as well as the}} budgets influence the temporal behaviour of a job. Interestingly, a trade-off exists: a larger buffer size can allow for a smaller budget while still meeting the throughput requirement. This work is the first to address the simultaneous computation of budget and buffer sizes. We solve this non-linear problem by formulating it as a second-order cone program. We present tight approximations to obtain a non-integral second-order cone program that has polynomial complexity. Our experiments confirm the non-linear trade-off between budget and buffer sizes...|$|R
40|$|It is a {{significant}} problem to provide a robust and portable software environment that can link together clusters of workstations and other heterogeneous computers. There are particular difficulties when the computer clusters to be managed transcend administrative boundaries across wide-area networks. We review some of the technologies that have emerged recently for managing arbitrary computer programs across clusters of computers, and use our experiences with such systems to illustrate the difficulties in managing systems across wide areas. A simplifying approach is to limit the services provided across wide-area clusters to well-defined processing and data access modules, that are specified a priori and are advertised between servers. Client programs can then invoke queries on databases, and set up processing tasks based on combinations of these well-defined services. Developers can build new modules or services conforming to a well specified application programming interface and new services can be tested within administrative boundaries before being made available across wide-area clusters. This is the approach we take with our DISCWorld metacomputing environment. We focus on {{a description of the}} scheduling aspects involved in managing multiple <b>job</b> <b>streams</b> acros...|$|R
5000|$|In 1968, {{work began}} on adding {{time-sharing}} capability to Exec 8. It was delivered with level 23 {{of the executive}} in 1969. Time sharing (called demand mode) had the same capabilities as batch and real time processes. Everything {{that could be done}} in batch could be done from an ASCII terminal. In demand mode, <b>job</b> <b>stream</b> I/O was attached to a terminal handler rather than card image (input) and spool (output) files. The same run control language was used for both. A few years later, more specific time sharing commands were added, and some control statements could be issued asynchronously for immediate processing, even when neither the executive or the running program were expecting data. Those commands, which could be entered only from a terminal, began with [...] "@@". Because they could be performed without stopping other work in progress from the same terminal, they were called transparent commands. At first these were just statements to kill the current program or redirect terminal output to a file, but eventually, almost all control statements were allowed to be [...] "immediate." ...|$|E
5000|$|On IBM's Job Control Language (JCL) used on {{its earlier}} MVS and current z/OS {{operating}} systems, data which is inline to a <b>job</b> <b>stream</b> {{can be identified}} by an * on a DD statement, such asorIn the first case, the lines of text follow and are combined into a pseudo file with the DD name SYSIN. All records following the command are combined until either another OS/JCL command occurs (any line beginning with [...] ), the default EOF sequence (...) is found, or the physical end of data occurs. In the second case, the conditions are the same, except the DLM= operand is used to specify the text string signalling end of data, {{which can be used}} if a data stream contains JCL (again, any line beginning with [...] ), or the [...] sequence (such as comments in C or C++ source code). The following compiles and executes an assembly language program, supplied as in-line data to the assembler.//AHAR JOB ('ALEX HARRIS')// EXEC ASMLG//SYSIN DD *APROG START XR 15,15 BR 14 END/*//* JOB ENDSThe [...] statement is the functional equivalent of Indicating s stream of data follows, terminated by [...]|$|E
40|$|Workload {{allocation}} and job dispatching are {{two fundamental}} components in static job scheduling for distributed systems. This paper addresses static workload allocation techniques for {{two types of}} <b>job</b> <b>stream</b> in multicluster systems, namely, non-real-time job streams and softreal-time job streams, which request different qualities of service. Two workload allocation strategies (called ORT and OMR) are developed by establishing and numerically solving two optimisation equation sets. The ORT strategy achieves the Optimised mean Response Time for the nonreal-time job stream; while the OMR strategy can gain the Optimised mean Miss Rate for the soft-real-time <b>job</b> <b>stream</b> over multiple clusters (these strategies can also be applied in a single cluster system). The effectiveness of both strategies is demonstrated through theoretical analysis. The proposed workload allocation schemes are combined with two job dispatching strategies (Weighted Random and Weighted Round-Robin) to generate new static job scheduling algorithms for multicluster environments. These algorithms are evaluated through extensive experimental studies and {{the results show that}} compared with static approaches without the optimisation techniques, the proposed workload allocation schemes can significantly improve the performance of static job scheduling in multiclusters, in terms of both the mean response time (for the non-real-time jobs) and the mean miss rate (for soft-real-time jobs) *. 1...|$|E
50|$|Thousands {{of people}} looking for high-paying mining <b>jobs</b> <b>streamed</b> into Jeffrey City, and Western Nuclear {{designed}} and financed a company town for the workers and their families. At {{the height of the}} boom town optimism, an extremely large high school was built that included an Olympic-sized swimming pool. In the late 1970s and early 1980s, the uranium market collapsed and the mine was forced to close. As was typical of many boom towns, Jeffrey City was singularly dependent on the local mine, and after it closed {{there was no reason for}} residents to remain. What was once a thriving local community with shops, schools, library, sheriff, youth hostel, churches, medical clinics and more, became a ghost town as 95% of the residents left the town by 1986. Today, few institutions remain: the First (Southern) Baptist Church (which is still doing well thanks to the area ranchers who attend), a restaurant and bar called the Split Rock Café that caters to the few local residents and those passing through on the highway, and Monkingbird Pottery, a pottery studio. The Green Mountain Motel provides perhaps the only lodging along the 122 mi route between Rawlins and Riverton.|$|R
60|$|They {{hailed the}} riverman, {{who made a}} living by doing all sorts of <b>jobs</b> on the <b>stream.</b> He {{did not have much}} to do just then and readily agreed, for a small amount, to take them up the river and bring them back.|$|R
40|$|A service {{provisioning}} system is examined, where {{a number of}} servers are used to offer different types of services to paying customers. A customer is charged for the execution of a stream of jobs; the number of <b>jobs</b> in the <b>stream</b> {{and the rate of}} their submission is specified. On the other hand, the provider promises a certain quality of service (QoS), measured by the average waiting time of the <b>jobs</b> in the <b>stream.</b> A penalty is paid if the agreed QoS requirement is not met. The objective is to maximize the total average revenue per unit time. Dynamic policies for making server allocation and stream admission decisions are introduced and evaluated. The results of several simulations are described. 1...|$|R
40|$|In systems {{consisting}} of multiple clusters of processors which employ space sharing for scheduling jobs, such as our Distributed ASCI 1 Supercomputer (DAS), coallocation, i. e., the simultaneous allocation of processors to single jobs in different clusters, may be required. We study {{the performance of}} co-allocation by means of simulations for the mean response time of jobs depending {{on a set of}} scheduling decisions such as the number of schedulers and queues in the system, the way jobs with different numbers of components are distributed among these queues and the priorities imposed on the schedulers, and on the composition of the <b>job</b> <b>stream.</b> ...|$|E
40|$|Computer job {{scheduling}} is often performed with little {{understanding of the}} formal properties of the jobs being scheduled. One {{reason for this is}} that optimal solutions for {{job scheduling}} on computers are difficult to obtain if the <b>job</b> <b>stream</b> has mixed objectives, i. e., it consists of some jobs whose turnaround time has to be minimized and others whose deadlines must be met. A practical algorithm for scheduling mixed job streams on monoprogrammed computers, with potential application to a multiprogramming environment is presented. The algorithm takes into account variable cost rates for each job. Experimental results illustrate the efficiency of the algorithm in terms of both its proximity to optimal solutions and its low computational complexity. 1...|$|E
40|$|DOCU-TEXT, a {{proprietary}} software package that {{aids in the}} production of documentation for a data processing organization and can be installed and operated only on IBM computers is discussed. In organizing information that ultimately will reside in a data dictionary, DOCU-TEXT proved to be a useful documentation tool in extracting information from existing production jobs, procedure libraries, system catalogs, control data sets and related files. DOCU-TEXT reads these files to derive data that is useful at the system level. The output of DOCU-TEXT is a series of user selectable reports. These reports can reflect the interactions within a single <b>job</b> <b>stream,</b> a complete system, or all the systems in an installation. Any single report, or group of reports, can be generated in an independent documentation pass...|$|E
40|$|We {{present the}} SweGrid Accounting System (SGAS) — a {{decentralized}} and standardsbased system for Grid resource allocation enforcement {{that has been}} developed {{with an emphasis on}} a uniform data model and easy integration into existing scheduling and workload management software. The system has been tested at the six high-performance computing centers comprising the SweGrid computational resource, and addresses the need for soft, real-time quota enforcement across the SweGrid clusters. The SGAS framework is based on state-of-the-art Web and Grid services technologies. The openness and ubiquity of Web services combined with the fine-grained resource control and cross-organizational security models of Grid services proved to be a perfect match for the SweGrid needs. Extensibility and customizability of policy implementations for the three different parties that the system serves (the user, the resource manager, and the allocation authority) are key design goals. Another goal is end-toend security and single sign-on, to allow resources to reserve allocations and charge for resource usage on behalf of the user. We conclude this paper by illustrating the policy customization capabilities of SGAS in a simulated setting, where <b>job</b> <b>streams</b> are shaped using different modes of allocation policy enforcement. Finally, we discuss some of the early experiences from the production system...|$|R
40|$|Assembly {{job shop}} {{scheduling}} problem (AJSP) {{is an extension}} of classical job shop scheduling problem (JSP). AJSP starts with JSP and appends an assembly stage to the completed <b>jobs.</b> Lot <b>streaming</b> (LS) technique is a process of splitting jobs into smaller sub-jobs such that successive operations can be overlapped. This paper combines, for the first time, LS and AJSP, extending LS applicability to both machining and assembly. To solve this complex problem, an efficient algorithm is proposed using genetic algorithms and simple dispatching rules. Experimental results suggest that equal size LS outperforms varied size LS with respect to the objective function...|$|R
40|$|Enhancement of the {{computing}} in {{an engineering}} environment by {{the installation of}} a virtual muchine time-sharing system is discussed. This installation has been particularly useful in allow-ing the engineer to make the computer {{an integral part of}} a de-sign cycle through the interactive use of graphic displays. Described is a CP- 67 system implementing the virtual machine concept. By using an operating system of his choice in his own virtual machine, the engineering user has great flexibility in the development of applications [...] Virtual machine computing in an engineering environment by M. McGrath In the past few years, the virtual concept in computing has been used with several time-sharing systems. ” ” There are several reasons for this recent trend, the most important of which is to provide a multiaccess computer system that can be shared at the same time by many users, including personnel not familiar with the details of data processing. The requirements of data processing in the engineering environ-ment have expanded into many different areas and disciplines during {{the last four or five}} years. This is in contrast to the first twenty-odd years of scientific computing that were characterized by single-CPU, single-thread, batch <b>job</b> <b>streams.</b> The’introduction of the System/ 360 family of computers and multiprogramming was to some extent just an extension of the batch concept. Multi-programming enabled the computers to perform better from a systems point of view but had no effect on the philosophy of the engineering user. Multiprogramming permitted the development of interactive programs that provided more flexibility for the en-gineering user but still did not offer a practical method for a large number of users to have access to different computer systems simultaneously. Through time-sharing, computing for engineering is evolving into a system meeting the diverse needs of a variety of engi-neering personnel in real time. The engineer has been brough...|$|R
