324|751|Public
5000|$|All Redis {{commands}} supported at any <b>dataset</b> <b>size</b> - {{unlike the}} open source Redis Cluster, in Alpha stage as of December 2013, which only supports single-key operations.|$|E
5000|$|Typical Suitability {{reports are}} shown on [...] {{on the right}} side. Advisor Suitability {{provides}} <b>dataset</b> <b>size</b> (iteration space) modeling capabilities and performance penalties break-downn (exposing negative impact caused by Load Imbalance, Parallel Runtimes Overhead and Lock Contention).|$|E
40|$|A {{statistical}} methodology for estimating <b>dataset</b> <b>size</b> requirements for classifying microarray data using learning curves is introduced. The {{goal is to}} use existing classi � cation results to estimate <b>dataset</b> <b>size</b> requirements for future classi � cation experiments and to evaluate the gain in accuracy and signi � cance of classi � ers built with additional data. The method is based on � tting inverse power-law models to construct empirical learning curves. It also includes a permutation test procedure to assess the statistical signi � cance of classi � cation performance for a given <b>dataset</b> <b>size.</b> This procedure is applied to several molecular classi-� cation problems representing {{a broad spectrum of}} levels of complexity. Key words: gene expression pro � ling, molecular pattern recognition, DNA microarrays, microarray analysis, sample size estimation...|$|E
30|$|Previous {{researchers}} employed different datasets {{with various}} characteristics, such as different incident duration time phases, available data types, and <b>dataset</b> <b>sizes,</b> {{in their studies}} on traffic incident duration time analysis and prediction.|$|R
3000|$|... {{comprising}} {{only the}} ‘extremely rare’ scientist profiles within the TRWOK dataset {{shows that the}} distributions are remarkably similar except in the extreme right tail, which is only a finite-size effect due to the difference in <b>dataset</b> <b>sizes</b> [60].|$|R
5000|$|One {{interesting}} fact is {{that the}} algorithm which we are going to develop generates a synthetic <b>dataset</b> whose <b>size</b> is independent of the original dataset; in fact, it only depends on the VC-dimension of the concept class and the parameter [...] The algorithm outputs a <b>dataset</b> of <b>size</b> ...|$|R
40|$|This paper {{presents}} {{a novel approach}} for concatenative speech synthesis. This approach enables reduction of the <b>dataset</b> <b>size</b> of a concatenative text-to-speech system, namely the IBM trainable speech synthesis system, by more than an order of magnitude. A spectral acoustic feature based speech representation is used for computing a cost function during segment selection {{as well as for}} speech generation. Initial results indicate that even with a <b>dataset</b> <b>size</b> of a few megabytes it is possible to achieve quality which is significantly higher than existing small footprint formant based synthesizers. 1...|$|E
30|$|We {{can observe}} that an {{increase}} of the <b>dataset</b> <b>size</b> improves the accuracy significantly. In all cases, our MCF approach outperforms the other ones by resulting in less prediction errors.|$|E
3000|$|... [...]. The fibers in this {{component}} {{are less}} tightly packed, shorter in size {{with respect to}} the <b>dataset</b> <b>size</b> and they exhibit a curved structure which indicates a more problematic segmentation task for the presented algorithm.|$|E
40|$|Abstract — This paper {{analyzes}} {{the effects of}} distance between classes and training <b>datasets</b> <b>size</b> to XCS classifier system on imbalanced datasets. Our purpose is {{to answer the question}} whether the loss of performance incurred by the classifier faced with class imbalance problems stems from the class imbalance per se or it can be explained in some other ways. The experiments from 250 artificial imbalanced datasets show that XCS can perform well in some imbalance domains if the training <b>datasets</b> <b>size</b> is large enough and the distance between classes is appropriate. Thus, it dose not seem fair to correlate imbalance datasets directly to the loss performance of XCS. Through this research, we also know what kinds of datasets are suitable for training XCS and dealing with class imbalances alone will not always help improve performance of classifiers...|$|R
40|$|When highly-accurate and/or assumptionfree density {{estimation}} is needed, {{nonparametric methods}} are {{often called upon}} - most notably the popular kernel density estimation (KDE) method. However, the practitioner is instantly faced with the formidable computational cost of KDE for appreciable <b>dataset</b> <b>sizes,</b> which becomes even more prohibitive when many models with different kernel scales (bandwidths) must be evaluated [...] this is necessary for finding the optimal model, among other reasons. In previous work we presented an algorithm for fast KDE which addresses large <b>dataset</b> <b>sizes</b> and large dimensionalities, but assumes only a single bandwidth. In this paper we present a generalization of that algorithm allowing multiple models with different bandwidths to be computed simultaneously, in substantially less time than either running the singlebandwidth algorithm for each model independently, or running the standard exhaustive method. We show examples of computing the likelihood curve for 100, 000 data and 100 models ranging across 3 orders of magnitude in scale, in minutes or seconds...|$|R
40|$|GRID {{computing}} uses heterogeneous {{resources to}} solve large-scale computational problems. With increasing <b>dataset</b> <b>sizes</b> in data-intensive GRID applications reaching terabytes and even petabytes, high-performance I/O {{is emerging as}} an important research area. We discuss much of {{the current status of}} research in GRID I/O. We also describe our research ideas for handling noncontiguous I/O access, consistency, caching, fault-tolerance and improved performance. Key words. GRID I/O, parallel I/O, caching, versioning, lockin...|$|R
40|$|We {{present a}} {{scalable}} sequential Monte Carlo algorithm and its greedy counterpart for models based on Kingman’s coalescent. We utilize fast nearest neighbor algorithms to limit expensive computations {{to only a}} subset of data point pairs. For a <b>dataset</b> <b>size</b> of n, the resulting algorithm has O(n log n) computational complexity. We empirically verify that we achieve a large speedup in computation. When the gain in speed is used for {{increasing the number of}} particles, we can often obtain significantly better samples than those of previous algorithms. We apply our algorithm for learning visual taxonomies of birds on 6033 examples, a <b>dataset</b> <b>size</b> for which previous algorithms fail to be feasible. ...|$|E
30|$|We also plan to {{continue}} increasing our <b>dataset</b> <b>size.</b> Our {{goal is to}} have a dataset which consists of 500 malicious app samples and 500 benign app samples. With a larger <b>dataset</b> <b>size,</b> {{we will be able to}} test the scalability and portability of the mAIS. A larger <b>dataset</b> <b>size</b> not only increases the number of mobile app samples, but it could also increase the dimensionality of our problem and each app feature vector. This could occur because the number of features in each feature vector is determined by the existence of a particular feature across the entire dataset, as explained in Section 4. Empirical evidence is needed to determine if an increase in dataset will significantly increase the computational complexity of the mAIS. To accomplish this goal, we will continue to run data collection and increase the computation processing power available to us, which should aid in our ability to gather larger mobile apps. With this increased runtime and potential to analyze larger apps, we also plan to reorganize the mobile apps into their appropriate families, to determine if there is a significant difference in detection.|$|E
40|$|Recently, {{driven by}} a huge {{increase}} in <b>dataset</b> <b>size,</b> we’ve witnessed the development of various scalable software infrastructures for massive data processing. Several data-parallel programming models have been proposed to solve domain-specific applications. For example, MapReduce is best at handling group-by-aggregation applications. 1 Hadoo...|$|E
40|$|Author {{identification}} is a subfield of Natural Language Processing (NLP) that uses machine learning tech-niques {{to identify the}} author of a text. Most previous research focused on long texts with the assumption that a minimum text length threshold exists under which au-thor identification would no longer be effective. This pa-per examines author identification in short texts far be-low this threshold, focusing on messages retrieved from Twitter (maximum length: 140 characters) to determine the most effective feature set for author identification. Both Bag-of-Words (BOW) and Style Marker feature sets were extracted and evaluated through a series of 15 experiments involving up to 12 authors with large and small <b>dataset</b> <b>sizes.</b> Support Vector Machines (SVM) were used for all experiments. Our results achieve clas-sification accuracies approaching that of longer texts, even for small <b>dataset</b> <b>sizes</b> of 60 training instances per author. Style Marker feature sets were found to be sig-nificantly more useful than BOW feature sets as well as orders of magnitude faster, and are therefore suggested for potential applications in future research...|$|R
40|$|This paper {{studies the}} effect of {{synthetic}} feature vectors on the classification performance of hyperspectral remote sensing images. As feature vectors, it has been chosen to employ morphological attribute profiles, that have proven themselves in this field. At this early stage of our work, the relatively simple Bootstrapping algorithm {{has been used for}} synthetic feature vector generation. Based on experiments conducted on multiple hyperspectral datasets, it has been observed that synthetic feature vectors contribute considerably to classification performance in the case of limited training <b>dataset</b> <b>sizes...</b>|$|R
30|$|From Sections 6.2 to 6.5, we {{evaluate}} {{the performance of}} the Bloomfwd as the hash configurations, input query data characteristics, and prefix <b>dataset</b> <b>sizes</b> are varied, and we compare our approach to the MIHT algorithm. These analyses are intended to stress the algorithm under different scenarios {{in order to understand the}} aspects that affect its performance. The experiments in this phase use the Intel Xeon CPU and Intel Phi 7120 P processors only, because these processors are deployed in a local machine to which we have unlimited access.|$|R
40|$|Abstract — This paper {{presents}} an Artificial Neural Network design and Neural Network parameter optimization for emotional recognition of classified facial expressions. The main goal {{in this paper}} is to teach computers to recognize three distinct human emotions from static images. Training and Testing dataset will be collected and a multilayer perceptron network will be built to implement an emotion classifier. Two excellent face databases are used to construct the training and testing datasets. Cross-validation techniques were used to compare the parameters of the Neural Network classifier and the types of activation functions. This paper shows that the performance of the designed Neural Network is very high at above 90 % with around 60 / 40 ratio of training <b>dataset</b> <b>size</b> to test <b>dataset</b> <b>size...</b>|$|E
40|$|Dense and low {{dimensional}} word embeddings {{opened up}} the possibility to analyze text polarity with highly successful deep learning techniques like Convolution Neural Networks. In this paper we utilize pretrained word vectors in combination with simple neural networks of stacked convolution and max-pooling layers, to explore the role of <b>dataset</b> <b>size</b> and document length in sentiment polarity prediction. We experiment with song lyrics and reviews of products or movies and see that convolution-pooling combination is very fast and yet quiet effective. We also find interesting relations between <b>dataset</b> <b>size,</b> text length and length of feature maps with classification accuracy. Our next goal is {{the design of a}} generic neural architecture for analyzing polarity of various text types, with high accuracy and few hyper-parameter changes...|$|E
40|$|A {{major problem}} of pattern {{recognition}} systems {{is due to}} the large volume of training datasets including duplicate and similar training samples. In order to overcome this problem, some <b>dataset</b> <b>size</b> reduction and also dimensionality reduction techniques have been introduced. The algorithms presently used for <b>dataset</b> <b>size</b> reduction usually remove samples near to the centers of classes or support vector samples between different classes. However, the samples near to a class center include valuable information about the class characteristics and the support vector is important for evaluating system efficiency. This paper reports on the use of Modified Frequency Diagram technique for <b>dataset</b> <b>size</b> reduction. In this new proposed technique, a training dataset is rearranged and then sieved. The sieved training dataset along with automatic feature extraction/selection operation using Principal Component Analysis is used in an OCR application. The experimental results obtained when using the proposed system on one of the biggest handwritten Farsi/Arabic numeral standard OCR datasets, Hoda, show about 97 % accuracy in the recognition rate. The recognition speed increased by 2. 28 times, while the accuracy decreased only by 0. 7 %, when a sieved version of the dataset, which is only as half as the size of the initial training dataset, was used...|$|E
40|$|When using {{a shared}} memory multiprocessor, the {{programmer}} faces {{the selection of}} the portable programming model which will deliver the best performance. Even if he restricts his choice to the standard programming environments (MPI and OpenMP), he has a choice of a broad range of programming approaches. To help the programmer in his selection, we compare MPI with three OpenMP programming styles (loop level, loop level with large parallel sections, SPMD) using a subset of the NAS benchmark (CG, MG, FT, LU), two <b>dataset</b> <b>sizes</b> (A and B) and two shared memory multiprocessors (IB...|$|R
40|$|We {{introduce}} a ScatterNet {{that uses a}} parametric log transformation with Dual-Tree complex wavelets to extract translation invariant representations from a multi-resolution image. The parametric transformation aids the OLS pruning algorithm by converting the skewed distributions into relatively mean-symmetric distributions while the Dual-Tree wavelets improve the computational efficiency of the network. The proposed network is shown to outperform Mallat's ScatterNet on two image datasets, both for classification accuracy and computational efficiency. The advantages of the proposed network over other supervised and some unsupervised methods are also presented using experiments performed on different training <b>dataset</b> <b>sizes...</b>|$|R
40|$|This paper {{describes}} {{the design and}} implementation on MIMD parallel machines of P-AutoClass, a parallel version of the AutoClass system based upon the Bayesian method for determining optimal classes in large datasets. The P-AutoClass implementation divides the clustering task among the processors of a multicomputer so that they work on their own partition and exchange their intermediate results. The system architecture, its implementation and experimental performance results on different processor numbers and <b>dataset</b> <b>sizes</b> are presented and discussed. In particular, efficiency and scalability of P-AutoClass versus the sequential AutoClass system are evaluated and compared. ...|$|R
40|$|It is {{well known}} that Markov chain Monte Carlo (MCMC) methods scale poorly with <b>dataset</b> <b>size.</b> A popular class of methods for solving this issue is {{stochastic}} gradient MCMC. These methods use a noisy estimate of the gradient of the log posterior, which reduces the per iteration computational cost of the algorithm. Despite this, {{there are a number of}} results suggesting that stochastic gradient Langevin dynamics (SGLD), probably the most popular of these methods, still has computational cost proportional to the <b>dataset</b> <b>size.</b> We suggest an alternative log posterior gradient estimate for stochastic gradient MCMC, which uses control variates to reduce the variance. We analyse SGLD using this gradient estimate, and show that, under log-concavity assumptions on the target distribution, the computational cost required for a given level of accuracy is independent of the <b>dataset</b> <b>size.</b> Next we show that a different control variate technique, known as zero variance control variates can be applied to SGMCMC algorithms for free. This post-processing step improves the inference of the algorithm by reducing the variance of the MCMC output. Zero variance control variates rely on the gradient of the log posterior; we explore how the variance reduction is affected by replacing this with the noisy gradient estimate calculated by SGMCMC...|$|E
30|$|The {{research}} in the learning theory provides a rich set of knowledge in learning the complex relationships and patterns in the datasets. Vapnik et al. show {{that the proportion of}} the training <b>dataset</b> <b>size</b> to the complexity of the regression model determines whether to use the empirical or the structural risk minimizations [25]. In the auto-scaling domain, the Predictor component corresponds to the learning machine of the leaning process. Therefore, to improve the accuracy of the Predictor component, the risk minimization principle should be determined based on the complexity of the prediction techniques (i.e., the VC-dimension) and the training <b>dataset</b> <b>size.</b> The workload pattern complexity is the main driving factor of the Predictor component’s VC-dimension. Four sub-hypotheses are introduced in order to experiment the risk minimization principles vis-à-vis the different workload patterns.|$|E
40|$|Abstract: in {{the paper}} new non-conventional growing neural network is proposed. It coincides with the Cascade-Correlation Learning Architecture structurally, but uses ortho-neurons as basic {{structure}} units, which can be adjusted using linear tuning procedures. As compared with conventional approximating neural networks proposed approach allows significantly to reduce time required for weight coefficients adjustment and the training <b>dataset</b> <b>size...</b>|$|E
30|$|There exist many {{large-scale}} RDF datasets, e.g., Freebase 1 has 2.5 billion triples [6] and DBpeida 2 {{has more}} than 170 million triples [17]. LOD now connects more than 3000 datasets and currently {{has more than}} 84 billion triples, 3 {{with the number of}} data sources doubling within three years (2011 – 2014). The growth of RDF <b>dataset</b> <b>sizes</b> and the expansion of their use, coupled by the definition of a declarative query language (SPARQL) by W 3 C, have made RDF data management an active area of research and development, and a number of RDF data management systems have been developed.|$|R
30|$|As stated previously, {{the choice}} of ML {{framework}} will be largely application and user-specific. MLlib and H 2 O are very good options for general needs; each is fast, scalable to different <b>dataset</b> <b>sizes,</b> and has a fairly diverse selection of algorithms. MLlib offers a better selection for most areas of machine learning, but H 2 O is the only tool that has solutions for deep learning. In terms of usability, both have APIs for programming in multiple languages, and H 2 O also offers a GUI, {{making it easier to}} use for those without a high level of programming expertise.|$|R
30|$|Hu et al. {{tried to}} {{optimize}} the lookup table of Aho-Corasik algorithm in Gnort [8, 33]. The goal was to solve two issues: {{the increase in the}} number of signatures and the decrease in performance. Gnort used a modified algorithm, called CSAC, on a GPU card. The authors conducted their experiments using different <b>dataset</b> <b>sizes.</b> In addition, they tested their GPU implementation on different GPU cards: GTS 8800 and Tesla C 2050. The authors concluded that as the number of pattern increases, CSAC can still achieve a good performance improvement and reduce the memory usage using compression techniques.|$|R
40|$|Current {{methods for}} {{inferring}} population structure from genetic {{data do not}} provide formal significance tests for population differentiation. We discuss an approach to studying population structure (principal components analysis) that was first applied to genetic data by Cavalli-Sforza and colleagues. We place the method on a solid statistical footing, using results from modern statistics to develop formal significance tests. We also uncover a general "phase change" phenomenon about the ability to detect structure in genetic data, which emerges from the statistical theory we use, and has an important implication for the ability to discover structure in genetic data: for a fixed but large <b>dataset</b> <b>size,</b> divergence between two populations (as measured, for example, by a statistic like FST) below a threshold is essentially undetectable, but a little above threshold, detection will be easy. This means that we can predict the <b>dataset</b> <b>size</b> needed to detect structure...|$|E
40|$|This work {{addresses}} {{the problem of}} instance reduction using a distributed implementation of genetic algorithms. Different existing parallel and distributed models for parallelizing genetic algorithms are investigated and applied here {{to solve the problem}} of instance reduction. a new parallel model is proposed and implemented we called Global Control Parallel Genetic Algorithm. The results showed enormous reduction in time of 90 % over the other models. The resulted dataset showed an acceptable accuracy results on average over all datasets. The model achieved a better reduction in <b>dataset</b> <b>size</b> of 90. 22 % compared to the other models that didn’t get better that 87. 91 %. Thus, the proposed distributed system model for instance reduction showed better performance over all model in reducing the time and even reducing the training <b>dataset</b> <b>size</b> while maintaining the same level of accuracy of the original sequential genetic algorithm...|$|E
40|$|A novel {{approach}} {{to the problem of}} keyword retrieval in cursive handwritten documents is introduced in this work. Two issues are addressed: small <b>dataset</b> <b>size</b> and uneven sample distribution across the character set. The proposed strategies utilise graphemes (fragments of a handwritten word) to implement a recognition model which is subsequently used to form the feature model for the query word...|$|E
40|$|International audienceMining {{movement}} data {{to reveal}} interesting behavioral patterns has gained attention in recent years. One such pattern is the convoy pattern {{which consists of}} at least m objects moving together for at least k consecutive time instants where m and k are user-defined parameters. Existing algorithms for detecting convoy patterns, however do not scale to real-life <b>dataset</b> <b>sizes.</b> Therefore a distributed algorithm for convoy mining is inevitable. In this paper, we discuss the problem of convoy mining and analyze different data partitioning strategies {{to pave the way}} for a generic distributed convoy pattern mining algorithm...|$|R
3000|$|The second {{family of}} {{clustering}} algorithms is composed by [...] distance-based approaches. Given a <b>dataset</b> of <b>size</b> n, grouped into K clusters, such methods have usually the goal {{to find the}} K [...]...|$|R
5000|$|Most {{statistical}} problems {{begin with}} a <b>dataset</b> of <b>size</b> n. The asymptotic theory proceeds by assuming {{that it is possible}} to keep collecting additional data, so that the sample size would grow infinitely: ...|$|R
