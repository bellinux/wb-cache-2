1359|0|Public
25|$|Research {{has shown}} that sirens mounted behind the engine grill or under the wheel arches {{produces}} less unwanted noise inside the passenger cabin and {{to the side and}} rear of the vehicle while maintaining noise levels to give adequate warnings. The inclusion of broadband sound to sirens has the ability to increase localisation of sirens, as in a directional siren, as a spread of frequencies makes use of the three ways the brain detects a direction of a sound: <b>Interaural</b> level difference, <b>interaural</b> time difference and head-related transfer function.|$|E
2500|$|Jeffress, L.A.; Blodgett, H.C.; Deatherage, B.H. (1962) [...] "Effect of <b>Interaural</b> Correlation on the Precision of Centering a Noise," [...] Journal of the Acoustical Society of America 34: 1122, ...|$|E
2500|$|McFadden, D.; Jeffress, L.A.; Russell, W.E. (1973), [...] "Individual {{differences}} in sensitivity to <b>interaural</b> {{differences in}} time and level," [...] Perceptual and Motor Skills 37: 755, WOS:A1973R662300017, PM 4764506 ...|$|E
2500|$|Wilbanks, W.A.; Blodgett, H.C.; Jeffress, L.A. (1954), [...] "The {{effect of}} large <b>interaural</b> time {{differences}} upon {{the judgment of}} sidedness," [...] Journal of the Acoustical Society of America 26: 945, , WOS:A1954UD61900129 ...|$|E
2500|$|In 1977, {{the first}} {{conference on the}} topic of APD was {{organized}} by Robert W. Keith, Ph.D. at the University of Cincinnati. [...] The proceedings of that conference was published by Grune and Stratton under the title [...] "Central Auditory Dysfunction" [...] (Keith RW Ed.) [...] That conference started a new series of studies focusing on APD in children. Virtually all tests currently used to diagnose APD originate from this work. These early researchers also invented many of the auditory training approaches, including interhemispheric transfer training and <b>interaural</b> intensity difference training. This period gave us a rough understanding of the causes and possible treatment options for APD.|$|E
5000|$|A {{well-known}} {{example of}} TDOA is the <b>interaural</b> time difference. The <b>interaural</b> time {{difference is the}} difference in arrival time of a sound between two ears. The <b>interaural</b> time difference is given bywhere ...|$|E
50|$|If {{the ears}} are {{located at the}} side of the head, similar lateral {{localization}} cues as for the human auditory system can be used. This means: evaluation of <b>interaural</b> time differences (<b>interaural</b> phase differences) for lower frequencies and evaluation of <b>interaural</b> level differences for higher frequencies. The evaluation of <b>interaural</b> phase differences is useful, as long as it gives unambiguous results. This is the case, as long as ear distance is smaller than half the length (maximal one wavelength) of the sound waves. For animals with a larger head than humans the evaluation range for <b>interaural</b> phase differences is shifted towards lower frequencies, for animals with a smaller head, this range is shifted towards higher frequencies.|$|E
50|$|Since most {{animals have}} two ears, {{many of the}} effects of the human {{auditory}} system can also be found in other animals. Therefore, <b>interaural</b> time differences (<b>interaural</b> phase differences) and <b>interaural</b> level differences play a role for the hearing of many animals. But the influences on localization of these effects are dependent on head sizes, ear distances, the ear positions and the orientation of the ears.|$|E
5000|$|Viete, S. and Peña, J. L. and Konishi, M. (1997) The {{effects of}} <b>interaural</b> {{intensity}} difference on theprocessing of <b>interaural</b> time {{difference in the}} owl’s nucleus laminaris. J. Neurosci. 17: 1815 - 1824.|$|E
50|$|<b>Interaural</b> Phase Difference (IPD) {{refers to}} the {{difference}} in the phase of a wave that reaches each ear, and is dependent on the frequency of the sound wave and the <b>interaural</b> time differences (ITD).|$|E
50|$|Binaural cues are {{generated}} by the difference in hearing between {{the left and right}} ears. These differences include the <b>interaural</b> time difference (ITD) and the <b>interaural</b> intensity difference (IID). Binaural cues are used mostly for horizontal localization.|$|E
5000|$|<b>Interaural</b> Time Difference (ITD) Sound {{from the}} right side reaches the right ear earlier than the left ear. The {{auditory}} system evaluates <b>interaural</b> time differences from: (a) Phase delays at low frequencies and (b) group delays at high frequencies.|$|E
5000|$|These interchannel {{differences}} {{are not the}} same as <b>interaural</b> differences, as produced by artificial head recordings. Even the spacing of 17 cm is not strictly based on <b>interaural</b> ear spacing. The recording angle for this microphone system is ±48° = 96°.|$|E
5000|$|The sound {{information}} {{arriving at the}} left and right ears causes inter-aural time differences and <b>interaural</b> level differences. These small variations allow the brain and auditory system to calculate the direction and distance of the sound sources from the listener. <b>Interaural</b> time difference ...|$|E
5000|$|... #Caption: Figure 1: <b>Interaural</b> {{attenuation}} {{with air}} conduction.|$|E
5000|$|... #Caption: Figure 2: <b>Interaural</b> {{attenuation}} with {{bone conduction}} ...|$|E
50|$|Most mammals are {{adept at}} resolving the {{location}} of a sound source using <b>interaural</b> time differences and <b>interaural</b> level differences. However, no such time or level differences exist for sounds originating along the circumference of circular conical slices, where the cone's axis lies along the line between the two ears.|$|E
50|$|Owls {{must be able}} to {{determine}} the necessary angle of descent, i.e. the elevation, in addition to azimuth (horizontal angle to the sound). This bi-coordinate sound localization is accomplished through two binaural cues: the <b>interaural</b> time difference (ITD) and the <b>interaural</b> level difference (ILD), also known as the <b>interaural</b> intensity difference (IID). The ability in owls is unusual; in ground-bound mammals such as mice, ITD and ILD are not utilized in the same manner. In these mammals, ITDs tend to be utilized for localization of lower frequency sounds, while ILDs tend to be used for higher frequency sounds.|$|E
5000|$|Tonotopic maps: <b>interaural</b> time difference, {{frequency}} tonotopic {{maps of the}} cochlea ...|$|E
5000|$|Based on {{previous}} binaural sound localization methods, a hierarchical fuzzy {{artificial neural network}} system combines <b>interaural</b> time difference(ITD-based) and <b>interaural</b> intensity difference(IID-based) sound localization methods for higher accuracy {{that is similar to}} that of humans. Hierarchical Fuzzy Artificial Neural Networks [...] were used with the goal of the same sound localization accuracy as human ears.|$|E
5000|$|The MSO's main {{function}} is detection of <b>interaural</b> time difference (ITD) cues to binaural lateralization.|$|E
5000|$|... #Caption: <b>Interaural</b> Level Difference (ILD) between {{left ear}} (left) and right ear (right). a sweep from right ...|$|E
5000|$|... #Caption: <b>Interaural</b> Time Difference (ITD) between {{left ear}} (top) and right ear (bottom). 100 ms white noise ...|$|E
50|$|The {{superior}} olivary {{complex is}} located in the pons, and receives projections predominantly from the ventral cochlear nucleus, although the dorsal cochlear nucleus projects there as well, via the ventral acoustic stria. Within the superior olivary complex lies the lateral superior olive (LSO) and the medial superior olive (MSO). The former is important in detecting <b>interaural</b> level differences while the latter is important in distinguishing <b>interaural</b> time difference.|$|E
50|$|Around {{the year}} 1900 Lord Rayleigh {{developed}} the duplex (combination of two) theory of human sound localisation using two binaural cues, <b>interaural</b> phase difference (IPD) and <b>interaural</b> level difference (ILD) (based on {{analysis of a}} spherical head with no external pinnae). The theory posits that we use two primary cues for sound lateralisation, using {{the difference in the}} phases of sinusoidal components of the sound and the difference in amplitude (level) between the two ears.|$|E
5000|$|<b>Interaural</b> Intensity Difference (IID) or <b>Interaural</b> Level Difference (ILD) Sound {{from the}} right side has a higher level at the right ear than at the left ear, because the head shadows the left ear. These level {{differences}} are highly frequency dependent and they increase with increasing frequency. Massive theoretical researches demonstrate that IID relates to the signal frequency f and the angular position of the acoustic source θ. The function of IID is given by: ...|$|E
50|$|If {{the ears}} are {{located at the}} side of the head, <b>interaural</b> level {{differences}} appear for higher frequencies and can be evaluated for localization tasks. For animals with ears at the top of the head, no shadowing by the head will appear and therefore there will be much less <b>interaural</b> level differences, which could be evaluated. Many of these animals can move their ears, and these ear movements can be used as a lateral localization cue.|$|E
50|$|Sound {{localization}} is {{the ability}} to correctly identify the directional location of sounds. A sound stimulus localized in the horizontal plane is called azimuth; in the vertical plane it is referred to as elevation. The time, intensity, and spectral differences in the sound arriving at the two ears are used in localization. Localization of low frequency sounds is accomplished by analyzing <b>interaural</b> time difference (ITD). Localization of high frequency sounds is accomplished by analyzing <b>interaural</b> level difference (ILD).|$|E
5000|$|... #Caption: [...] <b>Interaural</b> time {{difference}} (ITD) between left (top) and right (bottom) ears. (sound source: 100 ms white noise from 90&deg; azimuth, 0&deg; elevation) ...|$|E
50|$|MPEG Surround coding uses our {{capacity}} to perceive sound in the 3D and captures that perception in a compact set of parameters. Spatial perception is primarily attributed to three parameters, or cues, describing how humans localize sound in the horizontal plane: <b>Interaural</b> level difference (ILD), <b>Interaural</b> time difference (ITD) and <b>Interaural</b> coherence (IC). This three concepts are illustrated in next image. Direct, or first-arrival, waveforms from the source hit the left ear at time, while direct sound received by the right ear is diffracted around the head, with time delay and level attenuation, associated. These two effects result in ITD and ILD {{are associated with the}} main source. At last, in a reverberant environment, reflected sound from the source, or sound from diffuse source, or uncorrelated sound can hit both ears, all of them are related with IC.|$|E
5000|$|When one {{listens to}} sounds over {{headphones}} (in {{what is known}} as the [...] "closed field") the sound source appears to arise from center of the head. On the other hand, under normal, so-called free-field, listening conditions sounds are perceived as being externalized. The direction of a sound in space (see sound localization) is determined by the brain when it analyses the interaction of incoming sound with head and external ears. A sound arising to one side reaches the near ear before the far ear (creating an <b>interaural</b> time difference, ITD), and will also be louder at the near ear (creating an <b>interaural</b> level difference, ILD - also known as <b>interaural</b> intensity difference, IID). These binaural cues allow sounds to be lateralized. Although conventional stereo headphone signals make used of ILDs (not ITDs) the sound is not perceived as being externalized.|$|E
5000|$|Saberi, K., Takahashi, Y., Konishi, M., Albeck, Y., Arthur, B. J. and Farahbod, H.1998 Effects of <b>interaural</b> decorrelation on neural and {{behavioral}} detection of spatial cues. Neuron 21:789-798.|$|E
50|$|Research {{has shown}} that sirens mounted behind the engine grill or under the wheel arches {{produces}} less unwanted noise inside the passenger cabin and {{to the side and}} rear of the vehicle while maintaining noise levels to give adequate warnings. The inclusion of broadband sound to sirens has the ability to increase localisation of sirens, as in a directional siren, as a spread of frequencies makes use of the three ways the brain detects a direction of a sound: <b>Interaural</b> level difference, <b>interaural</b> time difference and head-related transfer function.|$|E
50|$|There is less {{reliable}} phase estimation {{in the very}} low part of the frequency band, and in the upper frequencies the phase response {{is affected by the}} features of the pinna. Earlier studies also show that the HRTF phase response is mostly linear and that listeners are insensitive to the details of the <b>interaural</b> phase spectrum as long as the <b>interaural</b> time delay (ITD) of the combined low-frequency part of the waveform is maintained. This is the modeled phase response of the subject HRTF as a time delay, dependent on the direction and elevation.|$|E
5000|$|Localization {{accuracy}} is 1 degree for sources {{in front of}} the listener and 15 degrees for sources to the sides. Humans can discern <b>interaural</b> time differences of 10 microseconds or less.|$|E
50|$|These ambiguities can {{be removed}} by tilting the head, which can {{introduce}} a shift in both the amplitude and phase of sound waves arriving at each ear. This translates the vertical orientation of the <b>interaural</b> axis horizontally, thereby leveraging the mechanism of localization on the horizontal plane. Moreover, even with no alternation in {{the angle of the}} <b>interaural</b> axis (i.e. without tilting one's head) the hearing system can capitalize on interference patterns generated by pinnae, the torso, and even the temporary re-purposing of a hand as extension of the pinna (e.g., cupping one's hand around the ear).|$|E
