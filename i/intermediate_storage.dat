326|166|Public
25|$|Magnesium {{chloride}} {{has shown}} promise as a storage material for hydrogen. Ammonia, which {{is rich in}} hydrogen atoms, is used as an <b>intermediate</b> <b>storage</b> material. Ammonia can be effectively absorbed onto solid magnesium chloride, forming Mg(NH3)6Cl2. Ammonia is released by mild heat, and is then passed through a catalyst to give hydrogen gas.|$|E
25|$|A $60 million (raised to $90 million) {{retrofit}} {{program called}} ZR (Z Refurbished) {{was announced in}} 2004 to increase its power by 50%. The Z machine was dismantled in July 2006 for this upgrade, including the installation of newly designed hardware and components and more powerful Marx generators. The de-ionized water section of the machine {{has been reduced to}} about half the previous size while the oil section has been expanded significantly in order to house larger <b>intermediate</b> <b>storage</b> lines (i-stores) and new laser towers, which used to sit in the water section. The refurbishment was completed in October 2007.|$|E
2500|$|Worldwide, {{industry}} uses bulk material, like coal, as {{a source}} of energy or as a raw material for production processes. <b>Intermediate</b> <b>storage</b> facilities (for example stockpiles) are required to decouple the (discontinuous) supply of raw materials from the (continuous) production process. Large quality fluctuations of the material properties can occur due to the geographical origin of the raw materials. This means that processes using these raw materials have to deal with these fluctuations in order to produce products with a constant quality. The fluctuations can be dealt with in two ways: ...|$|E
50|$|Distributed pixel cache: offload <b>intermediate</b> pixel <b>storage</b> {{to one or}} {{more remote}} servers.|$|R
40|$|Engineer-To-Order (ETO) {{process chain}} types with a {{successive}} installation on-site {{are common in}} plant building and the construction industry. Usually, the core processes Engineering, Fabrication and Installation are disconnected, which creates high levels of Work in Progress (WIP) and long lead-Times. Furthermore, up to date information about the construction progress, as prerequisite for an on-demand delivery of ETO-components is always difficult to obtain. Usually, to prevent a lack of material on-site, costly <b>intermediate</b> <b>storages</b> are used, which extend the delivery time. Well-known approaches in research, like the Last Planner System (LPS) or the Location Based Management System (LBMS), increase collaboration on-site and improve the reliability of construction schedules, but have a limited impact on synchronizing the supply chain to the construction progress. The approach presented in the paper describes how off-site and on-site production can be coupled, to reach short construction lead-Times without wastefully <b>intermediate</b> <b>storages.</b> A first IT-prototype, based on "Industry 4. 0 " principles, was implemented and tested in an Italian medium-sized ETO construction supplier...|$|R
40|$|This paper {{focuses on}} a Flexible Flow Shop (FFS) problem in a paint company {{in an attempt to}} {{minimize}} production makespan. The FFS problem is characterized by multiple products being produced in machines in stages with sequence dependent set up times and infinite <b>intermediate</b> <b>storages.</b> As the FFS problem is computationally complex, two heuristic methods are employed to solve the Mixed Integer Linear Programming (MILP) problem formulated. The first heuristic is based on the Theory of Constraints and the second heuristic is based on a Genetic Algorithm. The Genetic Algorithm approach has resulted in a better production makespan...|$|R
5000|$|... #Subtitle level 3: Battery {{management}} and <b>intermediate</b> <b>storage</b> ...|$|E
5000|$|The {{waste is}} first stored in <b>intermediate</b> <b>storage</b> for 30 years.|$|E
5000|$|... (A) any temporary, <b>intermediate</b> <b>storage</b> of a wire or {{electronic}} communication incident to the electronic transmission thereof ...|$|E
50|$|In {{order to}} achieve higher power density and reliability, {{it makes sense to}} {{consider}} Matrix Converters that achieve three-phase AC-AC conversion without any <b>intermediate</b> energy <b>storage</b> element. Conventional Direct Matrix Converters (Fig. 4) perform voltage and current conversion in one single stage.|$|R
40|$|The wavelet based ECW image {{compression}} is compared with older compression techniques and other wavelet compression methods. The ability to compress images without intermediate tiling or <b>intermediate</b> disk <b>storage</b> {{is a big}} advantage of the ECW compression especially for the compression of big remote sensing data sets...|$|R
5000|$|... libLAS is {{a library}} for {{reading and writing}} {{geospatial}} data encoded in the ASPRS laser (LAS) file format, versions 1.0, 1.1 and 1.2. LAS-formatted data is heavily used in lidar processing operations. The LAS format is a sequential binary format used to store data from sensors and as <b>intermediate</b> processing <b>storage</b> by some applications.|$|R
5000|$|With read caches, a {{data item}} {{must have been}} fetched from its {{residing}} location {{at least once in}} order for subsequent reads of the data item to realize a performance increase by virtue of being able to be fetched from the cache's (faster) <b>intermediate</b> <b>storage</b> rather than the data's residing location. With write caches, a performance increase of writing a data item may be realized upon the first write of the data item by virtue of the data item immediately being stored in the cache's <b>intermediate</b> <b>storage,</b> deferring the transfer of the data item to its residing storage at a later stage or else occurring as a background process. Contrary to strict buffering, a caching process must adhere to a (potentially distributed) cache coherency protocol in order to maintain consistency between the cache's <b>intermediate</b> <b>storage</b> and the location where the data resides. Buffering, on the other hand, ...|$|E
5000|$|... #Caption: The middle {{tower is}} a typical Richter {{designed}} digester for pulp. The right cylinder is for preparation of the chips and the left silo is for <b>intermediate</b> <b>storage.</b>|$|E
5000|$|A spigot {{algorithm}} is an algorithm for computing {{the value of}} a mathematical constant such as [...] or e which generates output digits left to right, with limited <b>intermediate</b> <b>storage.</b>|$|E
5000|$|There {{were two}} forms of input and output: primary user input and output and an {{intermediate}} results output and input. The <b>intermediate</b> results <b>storage</b> allowed operation on problems too large to be handled entirely within the electronic memory. (The largest problem that could be solved {{without the use of}} the intermediate output and input was two simultaneous equations, a trivial problem.) ...|$|R
40|$|The {{per service}} cost have been serious {{impediment}} to wide spread usage of on-line digital continuous media service, {{especially in the}} entertainment arena. Although handling the continuous media may be achievable due to the technology advances in past few years, its competitiveness in the market with the existing service type such as video rental is still in question. In this paper, we propose a model for continuous media service in a distributed infrastructure which has a video warehouse and <b>intermediate</b> <b>storages</b> connected via a high speed communication network {{in an effort to}} reduce the resource requirement to support a set of service requests. The storage resource and network resource to support a set of requests should be properly quantified to a uniform metric to measure the efficiency of the service schedule. We developed a cost model which maps the given service schedule to a quantity. The proposed cost model is used to elaborately capture the amortized resource requirem [...] ...|$|R
3000|$|Proposed MC {{topology}} is {{an equivalent}} combination of an input virtual rectifier and the output virtual inverter {{connected to a}} virtual dc link. Virtual rectifier is controlled as classical current source rectifier and virtual inverter as the classical voltage source inverter. Bidirectional CSR is cascaded to VSI without any <b>intermediate</b> energy <b>storage</b> element physically present. The intermediate voltage is ‘virtual dc link voltage.’ [...]...|$|R
5000|$|The 7th {{edition of}} IBM System/360 Basic Operating System Programmer's Guide, dated September 1967, lists first among major changes support for [...] "an <b>intermediate</b> <b>storage</b> size (24K) for System/360 Model 30." ...|$|E
50|$|<b>Intermediate</b> <b>storage</b> {{area between}} the sources of {{information}} and the data warehouse (DW) or Data mart (DM). It is usually of temporary nature, and its contents can be erased after the DW/DM has been loaded successfully.|$|E
5000|$|Specific {{support for}} using an <b>intermediate</b> <b>storage</b> device, {{such as a}} {{removable}} flash disc, to synchronize two machines. Most synchronizing programs {{can be used in}} this way, but providing specific support for this can reduce the amount of data stored on a device.|$|E
40|$|Information was {{collated}} on {{the seed}} storage behaviour of 67 tree species {{native to the}} Amazon rainforest of Brazil; 38 appeared to show orthodox, 23 recalcitrant and six <b>intermediate</b> seed <b>storage</b> behaviour. A double-criteria key based on thousand-seed weight and seed moisture content at shedding to estimate likely seed storage behaviour, developed previously, showed good agreement with the above classifications. The key can aid seed storage behaviour identification considerably...|$|R
40|$|In this work, a continuous-time Mixed-Integer Linear Programming (MILP) {{model for}} the {{short-term}} scheduling in multi-stage batch plants is used. The MILP model accounts for ready unit times, release order times, sequence-dependent changeovers, transfer times between adjacent processing stages and different <b>intermediates</b> <b>storage</b> policies. A Lagrangean decomposition technique (Conejo et al., 2002) {{is applied to the}} MILP model in order to facilitate the resolution of real-world industrial cases. The proposed decomposition technique is thoroughly examined. An industrial case study of a multi-product multi-stage pharmaceuticals batch plant is addressed in order to demonstrate the performance and the advantages of the proposed decomposition scheme. The pharmaceutical plant under study consists of 17 processing equipments. The numerous (30 to 50) final products require 5 to 6 processing stages. Sequence-dependent changeovers are permitted in most stages. It is noteworthy that changeovers are usually of the same order of magnitude or even larger than the processing times. The main optimization goal is the minimization of the makespan. Results obtained are discussed highlighting the advantages and the special characteristics of the proposed scheduling model. Peer ReviewedPostprint (published version...|$|R
40|$|There is a push towards {{sourcing}} {{chemicals and}} materials from renewable feedstock such as lignocellulosic biomass. Value chain assessment {{can be used}} to evaluate the feasibility of the use of a certain technology and feedstock to produce various chemical sources in a given location. In this work an optimisation model for the value chain assessment of a lignocellulosic biorefinery was developed using mixed integer linear programing. The model allows for a comparison of two product sources which undergo mechanical and/or chemical pretreatment prior to processing by the biorefinery into three product streams, delivered to the customer. Optimisation chooses the source or sources of feedstock and the locations of <b>intermediate</b> <b>storages,</b> pretreatments, biorefinery(ies) and customers with respect to maximising profit. The model was verified based on a case study detailed in Scotland. The case study evaluates the use of felled softwood and/or to the use of sawmill by-products with the production of hemicellulose, lignin and cellulose. The results and implications of the optimisation of the scenario are discussed with respect to costs of transport, processing and product values...|$|R
50|$|A staging area, or landing zone, is an <b>intermediate</b> <b>storage</b> area {{used for}} data {{processing}} during the extract, transform and load (ETL) process. The data staging area sits between the data source(s) {{and the data}} target(s), which are often data warehouses, data marts, or other data repositories.|$|E
50|$|The S-graph {{framework}} is {{an approach to}} solving batch process scheduling problems in chemical plants. S-graph is suited for the problems with a non-intermediate storage (NIS) policy, which often appears in chemical productions, {{but it is also}} capable of solving problems with an unlimited <b>intermediate</b> <b>storage</b> (UIS) policy.|$|E
5000|$|The {{production}} of coal-water slurry fuel involves the crushing of coal or coal sludge to particles between 10 and 65 micrometers diameter (standard crushers can be used); wet milling and homogenisation (with additives as required). The resulting product (coal slurry) is then prepared for <b>intermediate</b> <b>storage</b> or transport ...|$|E
40|$|The p r {{service cost}} have been?rious {{impediment}} to wide spread usage of on-line digital continuous media service, {{especially in the}} entertainment arena. Although handling the continuous media may be achievable due to the technology advances in past few years, its com-petitiveness in the market with the existing service type such as video rental is still in question. In this papel; we propose a service paradigm for continuous media delivery in a distributed infrastructure {{in an effort to}} reduce the resource requirement to support a set of service requests. The storage resource and network resource to support a set of requests should be properly quant@ed to a uniform metric to measure the ejiciency of the service schedule. We developed a cost model which #maps the given service schedule to a quantity. The proposed cost model is used to capture the amortized resource requirement of the schedule and thus to measure the efJiciency of the schedule. We develop a scheduling algorithm which strategically repli-cates the requested continuous media jiles at the various <b>intermediate</b> <b>storages...</b>|$|R
40|$|ISBN: 978 - 142447994 - 8 International audienceIn {{this paper}} {{we present a}} new {{pipeline}} HW architecture for fast 2 -D erosions/dilations. The implementation {{is based on a}} recently proposed algorithm allowing to process 2 -D data in a stream, minimizing the use of memory and drastically reducing the computing latency. These elementary operators can be chained in an efficient pipeline to realize compound morphological operators (opening, closing, ASF filters, etc.) with no <b>intermediate</b> image <b>storage</b> and minimal latency...|$|R
40|$|A new {{multi-device}} {{wireless power}} transfer scheme that reduces the overall charging time is presented. The proposed scheme employs the <b>intermediated</b> energy <b>storage</b> (IES) circuit which consists of a constant power driving circuit and a super-capacitor. By utilizing the characteristic of high power density of the super-capacitor, the receiver can receive and store the energy in short duration and supply to the battery for long time. This enables the overlap of charging duration between all receivers. As a result, the overall charging time can be reduced...|$|R
50|$|Gorleben {{is known}} as the site of a {{controversial}} radioactive waste disposal facility, currently used as an <b>intermediate</b> <b>storage</b> facility but planned to serve with the salt dome Gorleben as a future deep final repository for waste from nuclear reactors. It has attracted frequent protests from environmentalists since the 1970s.|$|E
50|$|Magnesium {{chloride}} {{has shown}} promise as a storage material for hydrogen. Ammonia, which {{is rich in}} hydrogen atoms, is used as an <b>intermediate</b> <b>storage</b> material. Ammonia can be effectively absorbed onto solid magnesium chloride, forming Mg(NH3)6Cl2. Ammonia is released by mild heat, and is then passed through a catalyst to give hydrogen gas.|$|E
50|$|The {{reservoir}} {{serves as}} both an <b>intermediate</b> <b>storage</b> reservoir for {{water from the}} Quabbin Reservoir {{as well as a}} water source itself as it is also fed by its own watershed. The reservoir is fed by the Quinapoxet, and Stillwater rivers, along with the Quabbin Aqueduct, which carries water from the Quabbin Reservoir. It is part of the Nashua River Watershed and is the headwaters of the Nashua River. Because it is an <b>intermediate</b> <b>storage</b> reservoir, its water levels are kept relatively constant while the Quabbin Reservoir fluctuates based on precipitation and demand. At times when the Wachusett Reservoir becomes high due to its own watershed producing a large amount of runoff such as during snow melting, the flow from the Quabbin is shut off and water from the Ware River flows backwards down the Quabbin Aqueduct into the Quabbin Reservoir for storage.|$|E
40|$|Abstract. Gipfeli is a {{high-speed}} compression algorithm that uses back-ward references with a 16 -bit sliding window, based on 1977 paper by Lempel and Ziv, enriched with an ad-hoc entropy coding for both literals and backward references. We have implemented it in C++ and fine-tuned for very high performance. The compression ratio {{is similar to}} Zlib in the fastest mode, but Gipfeli is {{more than three times}} faster. This positions it as an ideal solution for many bandwidth-bound systems, <b>intermediate</b> data <b>storage</b> and parallel computations. ...|$|R
5000|$|This {{reorganization}} saves space {{because no}} state {{except for the}} calling function's address needs to be saved, either on the stack or on the heap, and the call stack frame for [...] is reused for the <b>intermediate</b> results <b>storage.</b> This also means that the programmer need not worry about running out of stack or heap space for extremely deep recursions. It is also worth noting that, in typical implementations, the tail recursive variant will be substantially faster than the other variant, but only by a constant factor.|$|R
40|$|In this paper, a {{single-stage}} AC/DC power-factor-corrected {{voltage regulator}} (PFCVR), which permits a direct transfer of partial input {{power to the}} output after the first power process, is presented. This technique results in lower voltage stress on the <b>intermediate</b> bus <b>storage</b> capacitor and improved conversion efficiency while achieving high power factor. The duty ratio {{is a function of}} the load so that the bus voltage decreases when the load becomes light. Experimental results to verify the theoretical analysis and performance of the PFCVR are reported. Department of Electronic and Information EngineeringRefereed conference pape...|$|R
