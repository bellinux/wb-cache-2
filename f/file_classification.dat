65|74|Public
50|$|Windows Server 2008 R2 {{supports}} up to 64 physical processors {{or up to}} 256 logical processors per system. (Only the Datacenter and Itanium editions {{can take}} advantage of the capability of 64 physical processors. Enterprise, the next-highest edition after those two, can only use 8.) When deployed in a file server role, new <b>File</b> <b>Classification</b> Infrastructure services allow files to be stored on designated servers in the enterprise based on business naming conventions, relevance to business processes and overall corporate policies.|$|E
40|$|Organized {{alphanumeric}} <b>file</b> <b>classification</b> {{according to}} subjectTitle devised by catalogerPhysical collection {{is stored in}} closed stack; digital version is available only through the Bilkent University Intitutional RepositoryCollection is open for research use. Not available for commercial use, sale, or reproductio...|$|E
40|$|AbstractAmong {{numerous}} Chinese keyword extraction methods, Chinese {{characteristics were}} shortly considered. This phenomenon {{going against the}} precision enhancement of the Chinese keyword extraction. An extended term frequency based method(Extended TF) is proposed in this paper which combined Chinese linguistic characteristics with basic TF method. Unary, binary and ternary grammars for the candidate keyword extraction {{as well as other}} linguistic features were all taken into account. The method establishes classification model using support vector machine. Tests show that the proposed extraction method improved key words precision and recall rate significantly. We applied the key words extracted by the extended TF method into the text <b>file</b> <b>classification.</b> Results show that the key words extracted by the proposed method contributed greatly to raising the precision of text <b>file</b> <b>classification...</b>|$|E
5000|$|Classification Challenges: Deciding on appeals by {{authorized}} {{persons who}} have <b>filed</b> <b>classification</b> challenges under Section 1.8 of E.O. 13526; ...|$|R
5000|$|Knowledge Organization Systems (KOS) is {{a generic}} term used in {{knowledge}} organization about authority <b>files,</b> <b>classification</b> schemes, thesauri, topic maps, ontologies etc.|$|R
40|$|Abstract. In {{this work}} we propose an XML based toolkit for the {{construction}} of an oral history digital archive that allows the <b>filing,</b> <b>classification</b> and annotation of multimedia resources associated to a corpus of interviews. We describe the general organization of the archive and focus on content creation tools. In particular, we present a document editor for the classification and annotation of interview transcriptions that allow...|$|R
40|$|This article {{presents}} the new <b>file</b> <b>classification</b> schema national for Italian schools, {{produced by the}} Italian Directorate General of Archives of the Ministry for Cultural Heritage, within the project Titulus Scuola. This classification schema represents {{the starting point for}} a standard documental system, aimed at the digital administration...|$|E
40|$|Pendik, 1946 Decemberİhsan Doğramacı Bilkent University, Main Campus Library Building, Hasan Âli Yücel Collection Ankara Turkey 06800 0 - 312 - 266 - 4472 0 - 312 - 266 - 4391 library@bilkent. edu. trOrganized {{alphanumeric}} <b>file</b> <b>classification</b> {{according to}} subjectHolographPhysical collection {{is stored in}} closed stack; digital version is available only through the Bilkent University Intitutional RepositoryCollection is open for research use. Not available for commercial use, sale, or reproductio...|$|E
40|$|This paper {{describes}} a new desktop metaphor/system called TimeScape. A user of TimeScape can spatially arrange {{information on the}} desktop. Any desktop item can be removed at any time, and the system supports timetravel to the past or {{the future of the}} desktop. The combination of spatial information arrangement and chronological navigation allows the user to organize and archive electric information without being bothered by document folders or <b>file</b> <b>classification</b> problems...|$|E
5000|$|VEST Registry is {{a catalog}} of {{controlled}} vocabularies (such as authority <b>files,</b> <b>classification</b> systems, concept maps, controlled lists, dictionaries, ontologies or subject headings); metadata sets (metadata element sets, namespaces and application profiles); and tools (such as library management software, content management systems or document repository software). It is concerned primarily with collecting and maintaining a consistent set of metadata for each resource. The scope of the VEST Registry {{is to provide a}} clearing house for tools, metadata sets and vocabularies used in food, agriculture, development, fisheries, forestry and natural resources information management context.|$|R
5000|$|A {{person who}} is already enlisted can <b>file</b> for <b>classification</b> as a 1-A-O {{conscientious}} objector to be assigned to two years of noncombatant service or civilian work [...] "contributing {{to the maintenance of}} the national health, safety, or interest." ...|$|R
40|$|Designing a {{suitable}} mechanism to confine commonly used applications is challenging {{as such a}} mechanism needs to satisfy conflicting requirements. The trade-off is between configurability and ease of use. In this paper, we present the design, implementation and evaluation of MAPbox, a general-purpose confinement mechanism that retains the ease of use of specialized sandboxes such as Janus and SBOX while providing significantly more configurability. The key idea is to group application behaviors into classes based on the expected functionality and the resources required to achieve that functionality. Classification of behaviors provides a set of behavior labels (class names) {{that can be used}} to concisely communicate the expected functionality of programs between the provider and the users. This is similar to the MIME-types used to concisely describe the expected format of data <b>files.</b> <b>Classification</b> of application behaviors also allows class-specific sandboxes to be built and instantiat [...] ...|$|R
40|$|Yenişehir, 1946 February 1 İhsan Doğramacı Bilkent University, Main Campus Library Building, Hasan Âli Yücel Collection Ankara Turkey 06800 0 - 312 - 266 - 4472 0 - 312 - 266 - 4391 library@bilkent. edu. trOrganized {{alphanumeric}} <b>file</b> <b>classification</b> {{according to}} subjectHolographPhysical collection {{is stored in}} closed stack; digital version is available only through the Bilkent University Intitutional RepositoryCollection is open for research use. Not available for commercial use, sale, or reproductio...|$|E
40|$|Erenköy, 1946 August 8 İhsan Doğramacı Bilkent University, Main Campus Library Building, Hasan Âli Yücel Collection Ankara Turkey 06800 0 - 312 - 266 - 4472 0 - 312 - 266 - 4391 library@bilkent. edu. trOrganized {{alphanumeric}} <b>file</b> <b>classification</b> {{according to}} subjectTitle devised by catalogerPhysical collection {{is stored in}} closed stack; digital version is available only through the Bilkent University Intitutional RepositoryCollection is open for research use. Not available for commercial use, sale, or reproductio...|$|E
40|$|Yalova, 1939 July 20. İhsan Doğramacı Bilkent University, Main Campus Library Building, Hasan Âli Yücel Collection Ankara Turkey 06800 0 - 312 - 266 - 4472 0 - 312 - 266 - 4391 library@bilkent. edu. trOrganized {{alphanumeric}} <b>file</b> <b>classification</b> {{according to}} subject. Title devised by cataloger. Physical collection {{is stored in}} closed stackDigital version is available only through the Bilkent University Intitutional Repository. Collection is open for research use. Not available for commercial use, sale, or reproduction...|$|E
40|$|The {{author has}} {{identified}} the following significant results. The most significant ADP {{result was the}} modification of the DAM package to produce classified printouts, scaled and registered to U. S. G. S., 71 / 2 minute topographic maps from LARSYS-type <b>classification</b> <b>files.</b> With this modification, all the powerful scaling and registration capabilities of DAM become available for multiclass <b>classification</b> <b>files.</b> The most significant results with respect to image interpretation were the application of mapping techniques to a new, more complex area, and the refinement of an image interpretation procedure which should yield the best results...|$|R
40|$|Abstract In {{computer}} forensics, carving is {{an important}} trick in the digital in-vestigator’s sleeve. Since files are typically stored as sequences of data blocks, the retrieval process basically consists of locating and appro-priately collating together the original blocks of each file. Traditional file carving solutions, generally based on signatures of file headers and footers, could be improved by performing a classification of each data block in the storage media as belonging to a given file type. Unfortu-nately <b>file</b> block <b>classification</b> techniques tend to be far from perfect in terms of accuracy. For an improvement of the classification results the presence of compound files, i. e. files containing sub-portions that are encoded similarly to a different data type, {{must be taken into}} account during the classifier preparation. In this work, we demonstrate that this impacts heavily on the performance of file block classifiers. In ad-dition, to generally improve the accuracy of classification, we propose a context-based classification architecture to improve block-by-block clas-sification schemes, by exploiting the contiguity of file blocks belonging to the same file on storage media. The approach is completely general and can be easily applied to any content-based <b>file</b> block <b>classification</b> algorithm...|$|R
5000|$|WebSphere Application Server for z/OS V8 {{introduced}} {{the ability to}} configure application server behavior down to the request level, rather than server level. This function is built upon the existing WLM <b>classification</b> <b>file</b> used to assign WLM transaction classes to identified requests. V8 provided additional XML tags to assign server behavior to requests identified in the XML.|$|R
40|$|Ankara], [date of {{production}} {{can not be}} identified]İhsan Doğramacı Bilkent University, Main Campus Library Building, Hasan Âli Yücel Collection Ankara Turkey 06800 0 - 312 - 266 - 4472 0 - 312 - 266 - 4391 library@bilkent. edu. trOrganized alphanumeric <b>file</b> <b>classification</b> according to subjectTitle devised by catalogerPhysical collection is stored in closed stack; digital version is available only through the Bilkent University Intitutional RepositoryCollection is open for research use. Not available for commercial use, sale, or reproductio...|$|E
40|$|Üsküdar (Paşakapısı), 1937 December 27. İhsan Doğramacı Bilkent University, Main Campus Library Building, Hasan Âli Yücel Collection Ankara Turkey 06800 0 - 312 - 266 - 4472 0 - 312 - 266 - 4391 library@bilkent. edu. trOrganized {{alphanumeric}} <b>file</b> <b>classification</b> {{according to}} subject. Title devised by cataloger. Physical collection {{is stored in}} closed stack; digital version is available only through the Bilkent University Intitutional Repository. Collection is open for research use. Not available for commercial use, sale, or reproduction...|$|E
40|$|This article {{present the}} general file {{considerations}} {{to take into}} account for file organization. Those were motivated the formulation of the research project in order to know the level of organization of the <b>file</b> <b>classification</b> system in surveillance and control organizations in Colombia. Later on and starting from a panoramic view over the foundations and Colombian file regulations, the classification system used in public entities and private institutions with a public is described. It also mentions the postulates proposed by international writers of treatises about document classification alternative systems. Based on those assumptions some questions are posed which invite archival community to think about the proposed topic...|$|E
40|$|This report {{explores the}} {{classification}} and clustering of audio <b>files.</b> The <b>classification</b> {{is based on}} Feature extraction using the MARSYAS tool. The performance of both the Logistic Regression and Support Vector Machine models is evaluated. Within Logistic Regression, information is produced based on the probabilities of classification that {{may be useful to}} the end-user. The clustering is based {{on the use of the}} Normalised Compression Distance, and the use of an agglomerative hierarchical clustering technique. The results show that SVMs work the best out of all considered techniques. The report suggests why this might be so, and offers suggestions on improving both clustering and classification techniques. 1...|$|R
50|$|On one occasion, the {{municipal}} government {{had attempted to}} impede the re-classification process for the system. Concerning nationally sensitive heritage sites, Portuguese law states that the authorized patrimonial agency (IPPAR, IGESPAR or DRCNorte) has to give explicit approval for projects within 50 m of a designated structure, or group of structures. There have been no approvals under its <b>classification</b> <b>file.</b>|$|R
50|$|Acoustiblok is {{qualified}} {{for use in}} commercial and institutionalconstruction by its UL <b>Classification</b> <b>file.</b> under, Fire Tests of Building Construction and Materials. This Classification includes use in wall designs of the U300, U400, and V400 series, and floor-ceiling constructions of the L500 series, as specified in ANSI/UL 263 Fire Resistance Ratings. Ratings of 1 and 2 hours can be obtained, depending on specific partition design.|$|R
40|$|Nearly 20, 000 {{cubic feet}} of U. S. Senate records are {{currently}} entrusted {{to the care of}} thF; Nar. ional Archives and Records Administration (NARA). This guide to those records is divided into 22 chapters. Chapter 1 describes the published records of Congress and related published research tools. It provides general information about the National Archives Senate <b>file</b> <b>classification</b> system, the arrangement of the unpublished paper records, and how to access the Senate records. Chapters 2 through 1 describe the records of each Senate standing committee for which Ole National Archives has records {{from the beginning of the}} standing committee system in 1816 to 1968. There is one chapter for. ach of the standing committees and each is divided into chronological periods. Chapters 18 and 19 describe records of the Senate select and special committees and the joint committees of Congress. Chapters 20 and 21 concern the noncommitte...|$|E
40|$|This paper {{describes}} {{the design and}} development of a decentralized firewall system powered by a novel malware detection engine. The firewall is built using blockchain technology. The detection engine aims to classify Portable Executable (PE) files as malicious or benign. <b>File</b> <b>classification</b> is carried out using a deep belief neural network (DBN) as the detection engine. Our approach is to model the files as grayscale images and use the DBN to classify those images into the aforementioned two classes. An extensive data set of 10, 000 files is used to train the DBN. Validation is carried out using 4, 000 files previously unexposed to the network. The final result of whether to allow or block a file is obtained by arriving at a proof of work based consensus in the blockchain network. Comment: To be published in " 2017 International Conference on Advances in Computing, Communication and Control (ICAC 3) ...|$|E
40|$|Abstract. We {{propose a}} novel {{application}} of Genetic Programming (GP) : {{the identification of}} file types via the analysis of raw binary streams (i. e., {{without the use of}} meta data). GP evolves programs with multiple components. One component analyses statistical features extracted from the raw byte-series to divide the data into blocks. These blocks are then analysed via another component to obtain a signature for each file in a training set. These signatures are then projected onto a two-dimensional Euclidean space via two further (evolved) program components. K-means clustering is applied to group similar signatures. Each cluster is then labelled according to the dominant label for its members. Once a program that achieves good classification is evolved it can be used on unseen data without requiring any further evolution. Experimental results show that GP compares very well with established <b>file</b> <b>classification</b> algorithms (i. e., Neural Networks, Bayes Networks and J 48 Decision Trees). ...|$|E
40|$|Abstract. In the Fourth Open Hypermedia Systems workshop, {{the authors}} {{presented}} scenarios {{and a set}} of prototype tools to explore the application of open hypermedia principles, including content-based navigation, to temporal media. The purpose of the current paper is to provide an update on this work, focussing in particular on the ongoing work on content based navigation of music. We describe the development of a system which classifies the musical parts in MIDI <b>files.</b> This <b>classification</b> is then used to enhance content based retrieval and navigation of music. The effectiveness of the various approaches to classification is evaluated with respect to both stand-alone performance and when used in conjunction with a contour database. ...|$|R
50|$|Sanitization is {{a problem}} area for MLS systems. Systems that {{implement}} MLS restrictions, like those defined by Bell-LaPadula model, only allow sharing when it does not obviously violate security restrictions. Users with lower clearances can easily share their work with users holding higher clearances, but not vice versa. There is no efficient, reliable mechanism by which a Top Secret user can edit a Top Secret file, remove all Top Secret information, and then deliver it to users with Secret or lower clearances. In practice, MLS systems circumvent this problem via privileged functions that allow a trustworthy user to bypass the MLS mechanism and change a <b>file's</b> security <b>classification.</b> However, the technique is not reliable.|$|R
40|$|This essay {{provides}} an overview of both the accomplishments and difficulties faced by OCLC as it has expanded in the vast Asia Pacific region. It describes the organizational changes as they evolved as this previously North American collaborative organization expanded westward and details initiatives pursued in each of the Asia Pacific countries where it has operated. Finally, it examines the five major challenges yet facing OCLC in the region: the lack of bibliographic name authority <b>files,</b> competing <b>classification</b> systems, competing MARC cataloging formats, the perceived high costs associated with participating OCLC programs and services, and the need for local vernacular products in addition to those developed largely for the North American and European markets. © Taylor & Francis Group, LLC. link_to_subscribed_fulltex...|$|R
40|$|This paper {{describes}} {{the concept of}} Time-Machine Computing (TMC), a time-centric approach to organizing information on computers. A system based on Time-Machine Computing allows a user to visit {{the past and the}} future states of computers. When a user needs to refer to a document that he/she was working on at some other time, he/she can travel in the time dimension and the system restores the computer state at that time. Since the user's activities on the system are automatically archived, the user's daily workspace is seamlessly integrated into the information archive. The combination of spatial information management of the desktop metaphor and time traveling allows a user to organize and archive information without being bothered by folder hierarchies or the <b>file</b> <b>classification</b> problems that are common in today's desktop environments. TMC also provides a mechanism for linking multiple applications and external information sources by exchanging time information. This paper describes [...] ...|$|E
40|$|The Feature Identification and Location Experiment (FILE) that {{is being}} {{designed}} for the detection and classification of four primary earth features (water, vegetation, bare land, and the clouds-snow-ice class) is described. Consideration {{is given to the}} <b>FILE</b> <b>classification</b> technology concept and the FILE instrument, which will use two solid-state CCD cameras operating at 0. 65 and 0. 85 -micron center frequency wavelengths, with the camera outputs being functions of the earth surface material radiance. The classification is based on camera output radiance ratio values. The preliminary analysis of the data collected on the STS 41 -G mission is discussed. The results demonstrated the suitability of using the two-channel-ratio detection technology and a simple (y = mx) algorithm to autonomously classify the four earth surface features. The technology is especially attractive as a cloud sensor, where, in advance of or during a mission, a threshold value for cloud cover percentage can be programmed and/or adaptively modified for use in the control of other remote sensors...|$|E
40|$|Statistical NLP models usually ouly {{consider}} coarse {{information and}} very restricted context {{to make the}} estimation of parameters feasible. To reduce the modeling error introduced by tt sim- plified probabilistic model, the Classification and Regression Tree (CART) method was adopted in this paper to select more discriminative features for automatic model refinement. Because the features are adopted dependently during splitting <b>file</b> <b>classification</b> tree in CART, the ntnnber of training data in each terminal node is small, which makes the labeling process of terminal nodes not robust. This over-tuning phenomenon cannot be completely removed by crossvalidation process (i. e., pruniug process). A probabilistic classification model based on the selected discriminative features is tlltls proposed to use the training data more efficiently. In tag ging the Brown Corpus, our probabilistic classi- fication model reduces tile error rate of the top 10 error dominant words from 5. 71 % to 4. 35 %, which shows 23. 82 % improvement over the un refined model...|$|E
40|$|Manual {{calibration}} {{is generally}} adopted in middle size league soccer robot {{competition and the}} method is not only complex but also poor adaptability. A manually re-calibration is often needed when the environment changed. In this paper, based on threshold <b>file,</b> an automatic <b>classification</b> and color calibration method is proposed and realized in VC++ programming environment Experimental {{results show that the}} threshold file based color adaptive calibration has good effect and can meet the real-time requirements...|$|R
40|$|This paper {{describes}} the Classification Subtask of the NTCIR- 5 Patent Retrieval Task. The {{purpose of this}} subtask is to evaluate the methods of classifying patents into multi-dimensional classification structures called F-term (<b>File</b> Forming Term) <b>classification</b> systems. We report on how this subtask was designed, the test collection released, {{and the results of}} the evaluation. solutions problems to be solved crystalline reliability long life emission stability emission intensity structure of active laye...|$|R
40|$|A major {{challenge}} in digital forensics is the efficient and accurate <b>file</b> type <b>classification</b> of {{a fragment of}} evidence data, {{in the absence of}} header and file system information. A typical approach to this problem is to classify the fragment based on simple statistics, such as the entropy and the statistical distance of byte histograms. This approach is ineffective when dealing with high entropy data, such as multimedia and compressed files, all of which often appear to be random. We propose a method incorporating a support vector machine (SVM). In particular, we extract feature vectors from the byte frequencies of a given fragment, and use an SVM to predict the type of the fragment under supervised learning. Our method is efficient and achieves high accuracy for high entropy data fragments...|$|R
