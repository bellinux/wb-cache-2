8779|488|Public
5|$|TumbleSeed is an indie action video game, {{created by}} {{developer}} Benedict Fritz and designer Greg Wohlwend, {{in which the}} player balances a rolling seed on an ascending, horizontally slanted vine past procedurally generated obstacles {{to reach the top}} of a mountain. It is based on the mechanical arcade game Ice Cold Beer and built partially through the Cards Against Humanity game incubation program. TumbleSeed was released in May 2017 to generally favorable reviews on macOS, Nintendo Switch, PlayStation 4, and Windows platforms. Critics, in particular, appreciated their <b>haptic</b> sense of the rolling seed from the Nintendo Switch's sensitive HD Rumble. Many reviewers noted TumbleSeed intense and sometimes uneven difficulty, which the developers hoped to address in a post-release update. They credited this stigma and a tepid critical reception for the game's slow sales, but were proud of their work.|$|E
25|$|<b>Haptic</b> display: These {{displays}} provide {{sense of}} touch to the user (<b>haptic</b> technology). This type of output is {{sometimes referred to as}} force feedback.|$|E
25|$|The taptic {{engine in}} the iPhone 6S {{provides}} <b>haptic</b> feedback each time users press the screen harder.|$|E
40|$|This book {{examines}} {{the state of}} the art in diverse areas of <b>haptics</b> (touch) -related research, including the psychophysics and neurophysiology of <b>haptics,</b> development of <b>haptics</b> displays and sensors, and applications to a wide variety of fields such as industry, education, therapy, medicine, and welfare for the visually impaired. It also discusses the potential of future <b>haptics</b> interaction, such as <b>haptics</b> for emotional control and remote <b>haptics</b> communication. The book offers a valuable resource not only for <b>haptics</b> and human interface researchers, but also for developers and designers at manufacturing corporations and in the entertainment industries...|$|R
40|$|<b>Haptics</b> can {{significantly}} enhance the user's sense of immersion and interactivity. An industrial application {{of virtual reality}} and <b>haptics</b> for product assembly is described in this paper, which provides a new and low-cost approach for product assembly design, assembly task planning and assembly operation training. A demonstration of the system with <b>haptics</b> device interaction was available at the session of exp. at' 11...|$|R
40|$|We {{report on}} the results of a user study to {{investigate}} the utility of passive <b>haptics</b> for eyes-free numeric entry. This work targets cursorless user interfaces designed for use with a watch-sized wrist-worn computer. Our study compared three approaches for selecting one of a set of eight numeric parameters and entering its value, both with and without visual feedback. The three selection methods utilized physical buttons alone, buttons with a touch-sensor utilizing passive <b>haptics,</b> and the touch sensor with passive <b>haptics</b> alone. The results show that passive <b>haptics</b> allowed users to perform parameter selection and number entry tasks, with statistically insignificant differences in accuracy and speed when used with and without visual feedback. Furthermore, there was no statistically significant difference in accuracy and speed between the button-based methods and the purely touch-sensor–based approaches. 1...|$|R
25|$|New research, using ultrasound, has {{developed}} a 3D <b>haptic</b> shape {{that can be seen}} and felt in mid-air.|$|E
25|$|Direct {{interaction}} {{is used for}} <b>haptic</b> or teleoperated devices, and the human has nearly complete control over the robot's motion.|$|E
25|$|Literature on spatial crossmodal biases {{suggests}} that visual modality often influences information from other senses. Some {{research indicates that}} vision dominates what we hear, when varying the degree of spatial congruency. This {{is known as the}} ventriloquist effect. In cases of visual and <b>haptic</b> integration, children younger than 8 years of age show visual dominance when required to identify object orientation. However, <b>haptic</b> dominance occurs when the factor to identify is object size.|$|E
40|$|This paper {{describes}} a research effort designed {{to advance the}} state-of-the-art {{in our understanding of}} how best to incorporate <b>haptics</b> technologies into training systems. Most modem military platforms require that humans monitor and interact with systems through control panels. While these tasks are largely cognitive in nature, they also require a sensorimotor-based interface. There has been virtually no research performed on the role of <b>haptics</b> in learning to interact with such systems in virtual environments, either in learning the sensorimotor or cognitive skills. Because <b>haptics</b> is difficult to simulate well and adds expense to training systems, the first question we asked was whether, in a simple reaction time task, the addition of <b>haptics</b> feedback contributes to performance or learning of the task versus another type of feedback, simpler to implement, such as auditory stimulatio...|$|R
40|$|Restoring {{mobility}} and rehabilitation of gait are high priorities for rehabilitation of neurological conditions. Cueing using metronomic rhythmic sensory stimulation via entrainment {{has been shown}} to improve gait, but almost all previous versions of this approach have used auditory or visual cues. In contrast, we have developed and pilot-tested a prototype wearable system for rhythmic cueing based on <b>haptics.</b> Our initial pilot study indicated the same kinds of improvement to gait with <b>haptics</b> as for other cueing modalities, but <b>haptics</b> offer some advantages over audio and visual cues. In particular, <b>haptics</b> are generally more practical for use out of doors, in noisy environments, or when wishing to keep open the ability to converse freely. However, <b>haptics</b> also allow the precisely targeted spatial placement of cues on alternate limbs, offering the ability to manipulate attention and proprioception for therapeutic benefit. We outline the theory behind our approach and report on the iterative design of the system as part of a user-centred design evaluation process involving a wide range of stakeholders...|$|R
5000|$|Button devices used as teleporters or {{trackers}} (Global <b>Haptics</b> GeoOrb, ...).|$|R
25|$|Additionally, to {{rationalize}} sensory dominance, Gori et al. (2008) advocates {{that the brain}} utilises the most direct source of information during sensory immaturity. In this case, orientation is primarily a visual characteristic. It can be derived directly from the object image that forms on the retina, irrespective of other visual factors. In fact, data shows that a functional property of neurons within primate visual cortices' are their discernment to orientation. In contrast, <b>haptic</b> orientation judgements are recovered through collaborated patterned stimulations, evidently an indirect source susceptible to interference. Likewise, when size is concerned <b>haptic</b> information coming from positions of the fingers is more immediate. Visual-size perceptions, alternatively, have to be computed using parameters such as slant and distance. Considering this, sensory dominance is a useful instinct to assist with calibration. During sensory immaturity, the more simple and robust information source {{could be used to}} tweak the accuracy of the alternate source. Follow-up work by Gori et al. (2012) showed that, at all ages, vision-size perceptions are near perfect when viewing objects within the <b>haptic</b> workspace (i.e. at arm's reach). However, systematic errors in perception appeared when the object was positioned beyond this zone. Children younger than 14 years tend to underestimate object size, whereas adults overestimated. However, if the object was returned to the <b>haptic</b> workspace, those visual biases disappeared. These results support the hypothesis that <b>haptic</b> information may educate visual perceptions. If sources are used for cross-calibration they cannot, therefore, be combined (integrated). Maintaining access to individual estimates is a trade-off for extra plasticity over accuracy, which could be beneficial in retrospect to the developing body.|$|E
25|$|<b>Haptic</b> code: This {{behavioral}} category concerns how {{participants are}} touching one another, such as caressing, holding, feeling, prolonged holding, spot touching, pressing against, accidental brushing, or not touching at all.|$|E
25|$|The medical {{animation}} may {{be viewed}} as a standalone visualization, or in combination with other sensory input devices, such as head-mounted displays, stereoscopic lenses, <b>haptic</b> gloves, interactive workstations, or Cave Automatic Virtual Environments (CAVEs).|$|E
40|$|VisPad {{is a new}} <b>haptics</b> {{design for}} {{visualizing}} data, constructed from commodity massage chair pads with custom controllers and interfaces to a computer. It is an output device for information transmitted to a user {{who sits on the}} pad. The user interface is unique in that it has a large feedback area and is passive in nature, where unlike most current <b>haptics</b> devices, the user’s hands are free to work on other things. VisPad can be used as the sole <b>haptics</b> device or can be used in conjunction with other <b>haptics</b> devices. We have tested the usefulness of VisPad in visualizing data by adding the VisPad interface to our protein structurealignment program (ProtAlign) and performing usability studies. The data demonstrates that more information can be perceived at one time with our multi-modal presentation than with graphics-based visualization alone. 1...|$|R
40|$|<b>Haptics</b> {{technologies}} are frequently used in virtual environments to allow participants to touch virtual objects. Medical applications {{are no exception}} and {{a wide variety of}} commercial and bespoke <b>haptics</b> hardware solutions have been employed to aid in the simulation of medical procedures. Intuitively the use of <b>haptics</b> will improve the training of the task. However, little evidence has been published to prove that this is indeed the case. In the paper we summarise the available evidence and use a case study from interventional radiology to discuss the question of how important is it to touch medical virtual environments...|$|R
5000|$|<b>Haptics</b> and Virtual Reality (Laboratory for Advanced User Interfaces and Virtual Reality) ...|$|R
25|$|Intention to touch: A nonverbal {{communication}} <b>haptic</b> code or cue is {{the intention}} behind it. Reaching your {{hand across the}} table to a somewhat unknown person is used as a way to show readiness to touch.|$|E
25|$|The motion {{controller}} features vibration-based <b>haptic</b> technology. In {{addition to}} providing a tracking reference, the controller's orb light {{can be used to}} provide visual feedback, simulating aesthetic effects such as the muzzle flash of a gun, or the paint on a brush.|$|E
25|$|Physical {{models and}} {{computer}} models have partially complementary strengths and weaknesses. Physical models {{can be used}} by those without access to a computer and now can be made cheaply out of plastic materials. Their tactile and visual aspects cannot be easily reproduced by computers (although <b>haptic</b> devices have occasionally been built). On a computer screen, the flexibility of molecules is also difficult to appreciate; illustrating the pseudorotation of cyclohexane {{is a good example of}} the value of mechanical models.|$|E
5000|$|Taarlab's ongoing {{research}} {{areas in}} the field of <b>Haptics</b> are as follows: ...|$|R
40|$|Abstract — Medical {{simulators}} {{provide a}} risk-free environ-ment for trainee doctors {{to practice and}} improve their skills. UltraPulse is a new tactile system designed to utilise focussed airborne ultrasound to mimic a pulsation effect {{such as that of}} a human arterial pulse. In this paper, we focus on the construction of the <b>haptics</b> component, which can later be integrated into a variety of medical procedure training simulators. I. INTRODUCTION AND BACKGROUND Medical simulators often use <b>haptics</b> devices to offer the doctor a training session to practice and improve their skills without exposing the patient to undue risk [1]. <b>Haptics</b> refers to both force feedback and tactile feedback but there ar...|$|R
40|$|Volume <b>haptics</b> {{has shown}} itself an {{effective}} way of enhancing precision and speed in interaction with medical or scientific visualization. This paper presents a mixed solver approach for the primitive-based volume <b>haptics</b> problem, {{to provide the best}} performance for every volume <b>haptics</b> application. For situations where the constraints are orthogonal we present a fast and high precision analytical solver. For complex configurations requiring support for non-orthogonal constraints we allow for fall-back on a numerical solver. The results show significantly improved performance with the analytical solver, allowing for higher stiffness and thus feedback of higher quality, while still allowing for transparent support for non-orthogonal constraints. ...|$|R
25|$|Touch is the {{earliest}} sense {{to develop in}} the fetus. The development of an infant's <b>haptic</b> senses and how {{it relates to the}} development of the other senses such as vision has been the target of much research. Human babies have been observed to have enormous difficulty surviving if they do not possess a sense of touch, even if they retain sight and hearing. Infants who can perceive through touch, even without sight and hearing, tend to fare much better.|$|E
25|$|In other simulations, visual {{components}} of the procedure are reproduced by computer graphics techniques, while touch-based components are reproduced by <b>haptic</b> feedback devices combined with physical simulation routines computed {{in response to the}} user's actions. Medical simulations of this sort will often use 3D CT or MRI scans of patient data to enhance realism. Some medical simulations are developed to be widely distributed (such as web-enabled simulations and procedural simulations that can be viewed via standard web browsers) and can be interacted with using standard computer interfaces, such as the keyboard and mouse.|$|E
25|$|Wired gloves. These {{can provide}} input to the {{computer}} about the position and rotation of the hands using magnetic or inertial tracking devices. Furthermore, some gloves can detect finger bending {{with a high degree}} of accuracy (5-10 degrees), or even provide <b>haptic</b> feedback to the user, which is a simulation of the sense of touch. The first commercially available hand-tracking glove-type device was the DataGlove, a glove-type device which could detect hand position, movement and finger bending. This uses fiber optic cables running down the back of the hand. Light pulses are created and when the fingers are bent, light leaks through small cracks and the loss is registered, giving an approximation of the hand pose.|$|E
40|$|In this report, we {{describe}} {{the case of an}} aphakic patient who underwent peripheral iris fixation of a foldable posterior chamber intraocular lens (IOL) in the absence of capsular support. The patient suffered from traumatic cataract with partial zonular dehiscence. He received phacoemulsification, and capsular rupture occurred subsequently. After complete anterior vitrectomy, the lens capsule disappeared completely. Six months later, secondary IOL implantation was performed. A clear corneal incision was made, and a paracentesis was created to insert a folded acrylic soft IOL and a temporary supporting device. The optic of a three-piece acrylic IOL was folded along the axis of the <b>haptics,</b> and both the <b>haptics</b> were bent and quickly maneuvered into the folded furrow of the optic. A bimanual unfolding maneuver created pupillary capture of the optic for stabilization and centration of the IOL, with the <b>haptics</b> expanding on the back surface of the iris, and the <b>haptics</b> were fixated to the peripheral iris with modified McCannel suturing. Fair visual outcome without complications was noted...|$|R
40|$|Improving {{transparency}} in teleoperation {{by means of}} cutaneous tactile force feedback,” ACM Transactions on Applied Perception (TAP), vol. 11, 2014. “Enhancing the performance of passive teleoperation systems via cutaneous feedback,” IEEE Transactions on <b>Haptics</b> (ToH), 2015. “Tactile sensitivity, grasps and feedback modalities in teleoperation, ” Under Review: IEEE Transactions on <b>Haptics</b> (ToH). Conference papers “On the role of cutaneous force in teleoperation: subtracting kinesthesia from complet...|$|R
40|$|Virtual reality {{applications}} seek {{to fully}} immerse participants into their virtual world experience. The investiga-tion of how stimuli {{on the different}} senses influence the users is therefore crucial. As navigation {{is one of the}} most ubiquitous tasks in virtual environments, studying the influence of <b>haptics</b> on user presence is a necessity for future applications. This work presents an empirical study on the role of <b>haptics</b> during travel in a desktop virtual envi-ronment. Three techniques were compared in respect to task performance, perceived task performance, perceived presence and mental and physical workload. While our results indicate that <b>haptics</b> has a positive influence on participant’s perceived presence and performance, his total workload remains constant. Furthermore, we show that these findings apply to both experienced and unexperienced virtual environment users...|$|R
25|$|In 2007, Rubinstein joined Palm as {{executive}} chairman of {{its board of}} directors; {{at about the same}} time, he stepped down as chairman of Immersion Corp., a developer of <b>haptic</b> technology. Rubinstein took control of Palm’s product development and led its research, development, and engineering efforts. One of his first tasks included winnowing the company's product lines and restructuring R teams. He was instrumental in developing the webOS platform and the Palm Pre. Rubinstein debuted both on January 8, 2009, at the Consumer Electronics Show (CES) in Las Vegas. On June 10, 2009, just four days after the successful release of his brainchild, the Palm Pre, Rubinstein was named the CEO of Palm.|$|E
25|$|Android's default user {{interface}} is mainly based on direct manipulation, using touch inputs that loosely correspond to real-world actions, like swiping, tapping, pinching, and reverse pinching to manipulate on-screen objects, {{along with a}} virtual keyboard. Game controllers and full-size physical keyboards are supported via Bluetooth or USB. The response to user input {{is designed to be}} immediate and provides a fluid touch interface, often using the vibration capabilities of the device to provide <b>haptic</b> feedback to the user. Internal hardware, such as accelerometers, gyroscopes and proximity sensors are used by some applications to respond to additional user actions, for example adjusting the screen from portrait to landscape depending on how the device is oriented, or allowing the user to steer a vehicle in a racing game by rotating the device, simulating control of a steering wheel.|$|E
25|$|The {{input device}} used for games, the game controller, varies across platforms. Common {{controllers}} include gamepads, joysticks, mouse devices, keyboards, the touchscreens of mobile devices, and buttons, or even, with the Kinect sensor, a person's hands and body. Players typically view {{the game on}} a video screen or television or computer monitor, or sometimes on virtual reality head-mounted display goggles. There are often game sound effects, music and, in the 2010s, voice actor lines which come from loudspeakers or headphones. Some games in the 2000s include <b>haptic,</b> vibration-creating effects, force feedback peripherals and virtual reality headsets. In the 2010s, the video game industry is of increasing commercial importance, with growth driven particularly by the emerging Asian markets and mobile games, which are played on smartphones. As of 2015, video games generated sales of USD 74 billion annually worldwide, and were the third-largest segment in the U.S. entertainment market, behind broadcast and cable TV.|$|E
50|$|The Khatib group's {{present day}} {{interests}} include modeling human motor control, muscle actuated control, humanoid robotics, <b>haptics</b> in neuroimaging, and multi-contact control.|$|R
40|$|We {{describe}} a calibration technique for a hand-immersive virtual-reality environment [...] the Reachin Display [1]. The technique we present {{allows us to}} calibrate both the <b>haptics</b> device and the stereo display environment simultaneously where calibration of the stereo display utilises the <b>haptics</b> device and vice versa. The calibration procedure is described and we present a modular architecture for constructing calibration functions and show how fine control over the individual calibration parameters that are used can be obtained...|$|R
5000|$|Commercial (large gaming areas sell gaming environments {{mixed with}} <b>haptics).</b> The Cheapnet, a free {{entry-level}} service offered by commercial vendors of gaming solutions, can in principle {{also be used}} to coordinate networked augmented reality representations across the globe. However, jitter and latency are considerable problems with this basic network when long distances are involved. In the novel, Robert Gu develops an algorithm that partially compensates for these technical deficiencies, and might ultimately allow the inclusion of <b>haptics.</b>|$|R
