78|546|Public
50|$|Participation in {{the network}} is open to any spatial <b>data</b> <b>producer</b> that is willing to place their {{geospatial}} information at the public’s disposal and {{for the development of}} the region. Participation by institutions that generate useful information for decision making and development activities is emphasized.|$|E
50|$|There are {{two kinds}} of PDOs: {{transmit}} and receive PDOs (TPDO and RPDO). The former is for data coming from the device (the device is a <b>data</b> <b>producer)</b> and the latter is for data going to the device (the device is a data consumer); that is, with RPDO you can send data to the device and with TPDO you can read data from the device. In the pre-defined connection set there are identifiers for four (4) TPDOs and four (4) RPDOs available. With configuration 512 PDOs are possible.|$|E
50|$|If {{a router}} decides that the Interest cannot be satisﬁed, e.g., the {{upstream}} link is down, {{there is no}} forwarding entry in the FIB, or extreme congestion occurs, the router can send a NACK to its downstream neighbor(s) that transmitted the Interest. Such a Negative Acknowledgment (NACK) may trigger the receiving router to forward the Interest to other interfaces to explore alternate paths. The PIT state enables routers to identify and discard looping packets, allowing them to freely use multiple paths toward the same <b>data</b> <b>producer.</b> Packets cannot loop in NDN, which means {{there is no need}} for time-to-live and other measures implemented in IP and related protocols to address these issues.|$|E
2500|$|... {{understand}} and generate by <b>data</b> <b>producers</b> {{as it is}} in a format ...|$|R
40|$|Data {{interoperability}} between {{computer systems}} {{is a critical}} goal for businesses. This thesis attempts to address data interoperability by proposing a design in which <b>data</b> <b>producers</b> produce an Abstract Data Interface to expose data. The interface allows data consumers to determine semantic matches, after which <b>data</b> <b>producers</b> and consumers can provide input to an Interface Generator that resolves the schematic differences. The result of the Interface Generator is an Interface that enables unfettered, interoperable data exchange between a data producer-data consumer pair. Thesis Supervisor: Dr. Amar Gupt...|$|R
3000|$|Big data {{should be}} put high enough in {{organization}} to allow traction, and favor end-to end synchronization between users and big <b>data</b> <b>producers</b> within an organization; [...]...|$|R
5000|$|In August 2013, Big Data {{released}} an interactive video entitled [...] "Facehawk", which, if given permission, {{connects to the}} viewer's Facebook profile and turns their timeline into a video. The video starts by displaying the viewer's Facebook home page and making it appear to update its status, then launches into a more abstract visual experience where pictures and status updates assemble to form a hawk. The project was created in collaboration with interactive artist and director Rajeev [...] "Jeeves" [...] Basu. According to the band, the video serves as a visual reminder for the audience about how much information they have shared on their Facebook profile, and how far back that information reaches. Big <b>Data</b> <b>producer</b> Alan Wilkis was an early adopter of Facebook, having created the 4,132nd account on the site while studying at Harvard University.|$|E
5000|$|Argus is {{composed}} of an advanced comprehensive network flow data generator, the Argus monitor, which processes packets (either capture files or live packet data) and generates detailed network traffic flow status reports of all the flows in the packet stream. Argus monitors all network traffic, data plane, control plane and management plane, not just Internet Protocol (IP) traffic. Argus captures much of the packet dynamics and semantics of each flow, {{with a great deal}} of data reduction, so you can store, process, inspect and analyze large amounts of network data efficiently. Argus provides reachability, availability, connectivity, duration, rate, load, good-put, loss, jitter, retransmission (data networks), and delay metrics for all network flows, and captures most attributes that are available from the packet contents, such as Layer 2 addresses, tunnel identifiers (MPLS, GRE, IPsec, etc...), protocol ids, SAP's, hop-count, options, L4 transport identification (RTP detection), host flow control indications, etc... Argus has implemented a number of packet dynamics metrics specifically designed for cyber security. Argus detects human typing behavior in any flow, but of particular interest is key-stroke detection in encrypted SSH tunnels. [...] and Argus generates the Producer Consumer Ratio (PCR) which indicates whether a network entity is a <b>data</b> <b>producer</b> and/or consumer, an important property when evaluating the potential for a node to be involved in an Advanced persistent threat (APT) mediated exfiltration.|$|E
3000|$|... 1 In the {{terminology}} of the <b>data</b> <b>producer,</b> {{we have used}} the Integrated File that merges all countries with comparable data, edition 4.3.|$|E
50|$|WITSML(tm) Standards {{support the}} “right time” {{seamless}} flow of drilling and completions <b>data</b> between <b>data</b> <b>producers</b> and <b>data</b> consumers to speed and enhance decision-making in the drilling and completions domain.|$|R
5000|$|Interest: A {{consumer}} {{puts the}} name of a desired piece of data into an Interest packet and sends it to the network. Routers use this name to forward the Interest toward the <b>data</b> <b>producer(s).</b>|$|R
50|$|A new version, MAGE-TAB, {{has been}} {{developed}} to be easier tounderstand and generate by <b>data</b> <b>producers</b> {{as it is in}} a format(tab-delimited) that can be viewed and edited using widely availablespreadsheet software, such as Microsoft Excel.|$|R
40|$|Metadata about {{geographical}} data {{is one of}} {{the more}} important elements of Spatial Data Infrastructure (Gadzicki, 2003). Many various users other than the geographical <b>data</b> <b>producer</b> use geographical data. It is often produced on demand by one organization and used by another one. Proper documentation such as metadata should provide other organizations with a it...|$|E
40|$|We {{describe}} a novel way of usage management using a infrastructure that enables accountability on the Web at the protocol level. The protocol, HTTPA (Accountable Hyper Text Transfer Protocol), requires the <b>data</b> <b>producer</b> {{and the data}} consumer {{to come to an}} agreement before the data transfer, enabling both parities will be held accountable for the agreement they had entered into. The data consumer will express the intentions of data access and usage, whereas the <b>data</b> <b>producer</b> will express the usage restrictions on the data. This data transfer is facilitated by a trusted third party “Provenance Controller ” in an “intentions and usage restrictions handshake”. The sender/data producer will evaluate to what extent the usage restrictions match the data consumer’s intentions. If they match, the data consumer is granted access to the data; else she is notified of the mismatched components. This protocol cannot prevent the unauthorized reuse of data, but rather {{it can be used to}} develop accountability mechanisms that will identify violators allowing them to be held them accountable for data they inappropriately consumed and served. ...|$|E
40|$|Isoquants that {{illustrate}} {{combinations of}} various inputs {{to produce a}} given level of output were estimated for wet corn co-products using UNL cattle feeding trial data and applied to actual producer <b>data.</b> <b>Producer</b> economic benefits from feeding wet co-products compared to corn were calculated. Although the combined producer savings from all three wet co-products totaled nearly $ 39 million, this value was not net of all cost differences between co-products and corn, including transportation, storage, and handling costs...|$|E
40|$|Abstract. Associating {{a license}} to data is a {{fundamental}} task when publishing data on the Web. However, in many cases <b>data</b> <b>producers</b> and publishers are not legal experts, and they usually have only a basic knowledge about the possible constraints they want to ensure concerning the use and reuse of their data. In this paper, we propose a framework called Licentia that offers to the <b>data</b> <b>producers</b> and publishers a suite of services to deal with licensing information. In particular, Licentia sup-ports, through a user-friendly interface, the users in selecting the license that better suits their needs, starting from the set of constraints proposed to regulate the terms of use and reuse of the data. ...|$|R
40|$|In {{parallel}} with massive genomic data production, data sharing practices have rapidly expanded {{over the last}} decade. To ensure authorized access to data, access review by data access committees (DACs) has been utilized as one potential solution. Here we discuss core elements to {{be integrated into the}} fabric of access review by both established and emerging DACs in order to foster fair, efficient, and responsible access to datasets. We particularly highlight the fact that the access review process could be adversely influenced by the potential conflicts of interest of <b>data</b> <b>producers,</b> particularly when they are directly involved in DACs management. Therefore, in structuring DACs and access procedures, possible data withholding by <b>data</b> <b>producers</b> should receive thorough attention. status: publishe...|$|R
50|$|When an Interest packet arrives, an NDN router ﬁrst {{checks the}} Content Store for {{matching}} data; if it exists the router returns the Data packet {{on the interface}} from which the Interest came. Otherwise the router looks up the name in its PIT, and if a matching entry exists, it simply records the incoming interface of this Interest in the PIT entry. In {{the absence of a}} matching PIT entry, the router will forward the Interest toward the <b>data</b> <b>producer(s)</b> based on information in the FIB as well as the router’s adaptive Forwarding Strategy. When a router receives Interests for the same name from multiple downstream nodes, it forwards only the ﬁrst one upstream toward the <b>data</b> <b>producer(s).</b>|$|R
40|$|In Geographic Information System (GIS) typical {{applications}} data {{usually comes}} {{from a wide range}} of providers. Such data has variable quality and typically the end user has limited access to the original source (if any). Among other problems those datasets might have missing values and also be affected by outliers. Missing values are common in tabular datasets (like population census, meteorological records, etc.) and the end user is forced to apply any methodology in order to fill the gaps. The <b>data</b> <b>producer</b> cannot recover the missing value and typically does not assign or suggest alternative values. Outliers might arise from careless measurements, instrument malfunction, wrong data processing routines, etc. Current systems give little help to the end user, while the <b>data</b> <b>producer</b> might go back and make another reading, or check the original records if available. This thesis is concerned with the development and testing of tools intended for two purposes: a) given some dataset, point out dubious values and b) suggest a procedure to assign suitable values for those in doubt or missing. The algorithms were designed in order to be useful for end users as well as data producers...|$|E
30|$|The {{data on the}} Web Ecosystem may {{be defined}} as a set of actors and {{artifacts}} involved in producing, distributing, and consuming data by using the Web [75]. An actor can be a user, a system, or a device and can act either as a <b>data</b> <b>producer</b> or as a data consumer. The former delivers and produces data of some type according to specific conditions. The latter consumes (e.g., processes, analyzes, filters, aggregates) data. Both actors interact with each other by exchanging datasets.|$|E
30|$|DDS [6] is a message-oriented {{middleware}} standard proposed by OMG. It adopts a topic-based publish-subscribe communication model, {{in which the}} <b>data</b> <b>producer</b> (i.e., the publisher) does not send data directly to its consumers (i.e., the subscribers). Instead, the data are published into a channel with a specified “topic” name; all consumers who subscribe this topic receive the data without knowledge of who published them. The publisher and the subscriber are decoupled {{in terms of both}} time and space, which is suitable for highly dynamic environment such as robotic distributed computing systems.|$|E
40|$|The {{evolution}} of data publication options has provided alternatives {{for members of}} scientific communities, including Earth Scientists, to publish data and enable their discovery and use by others. Currently available options for publishing scientific data offer choices for <b>data</b> <b>producers</b> to deposit their data for dissemination. An assessment of the current options for publishing scientific data demonstrates five categories of data publishing alternatives that are available for <b>producers</b> of scientific <b>data</b> to choose from when considering opportunities for data publication. Current categories of scientific data publication alternatives include opportunities offered by traditional and online scientific journals; domain repositories, archives, and data centers; personal, departmental, and project websites; institutional repositories; and data journals. These alternatives for publishing scientific data are compared {{in terms of the}} opportunities that they provide for <b>data</b> <b>producers,</b> <b>data</b> users, and other stakeholders...|$|R
40|$|The need {{to store}} in HDF 5 files {{increasing}} amounts of metadata of various complexity is greatly overcoming {{the capabilities of the}} Earth science metadata conventions currently in use. <b>Data</b> <b>producers</b> until now did not have much choice but to come up with ad hoc solutions to this challenge. Such solutions, in turn, pose {{a wide range of issues}} for data managers, distributors, and, ultimately, data users. The HDF Group is experimenting on a novel approach of using ISO 19115 metadata objects as a catch-all container for all the metadata that cannot be fitted into the current Earth science data conventions. This presentation will showcase how the HDF Product Designer software can be utilized to help <b>data</b> <b>producers</b> include various ISO metadata objects in their products...|$|R
40|$|Although {{during the}} data {{production}} phase, the <b>data</b> <b>producers</b> will usually ensure the products {{to be easily}} used by the specific power users the products serve. However, most data products are also posted for general public to use. It is not straightforward for <b>data</b> <b>producers</b> to anticipate what tools that these general end-data users are likely to use. In this talk, {{we will try to}} help fill in the gap by going over various tools related to Earth Science and how they work with the existing NASA HDF (Hierarchical Data Format) data products and the reasons why some products cannot be visualized or analyzed by existing tools. One goal is for to give insights for <b>data</b> <b>producers</b> on how to make their data product more interoperable. On the other hand, we also provide some hints for end users on how to make tools work with existing HDF data products. (tool category list: check the comments) HDF-EOS tools: HDFView HDF-EOS Plugin, HEG, h 4 tonccf, hdf-eos 2 dumper, NCL, MATLAB, IDL, etc. net; CDF-Java tools: Panoply, IDV, toosUI, NcML, etc. net; CDF-C tools: ArcGIS Desktop, GrADS, NCL, NCO, etc.; GDAL tools: ArcGIS Desktop, QGIS, Google Earth, etc.; CSV tools: ArcGIS Online, MS Excel, Tableau, etc...|$|R
40|$|National audienceThe {{environment}} {{around us}} is progressively equipped with various sensors, producing data continuously. The applications using these data face many challenges, such as data stream integration over an attribute (such as time) and knowledge extraction from raw data. In this {{paper we propose}} one approach to face those two challenges. First, data streams integration is performed using statecharts which represents a resume of data produced by the corresponding <b>data</b> <b>producer.</b> Second, we detect anomalous events over temporal relations among statecharts. We describe our approach in a demonstration scenario, that is using a visual tool called Patternator...|$|E
40|$|Maintenance {{has grown}} from pure R&D, {{to one of the}} common tasks per formed by a Hydrographic Office. As the volume of ENCs {{produced}} is grow ing, the <b>data</b> <b>producer</b> is faced with the problem of consistency of information between ENCs and traditional nautical charts. This problem concerns both the production and updating. This paper outlines different approaches {{that can be used to}} combine production and maintenance of traditional paper charts and ENCs. It also offers a deep insight into the technology behind dKart Publisher developed by HydroService AS, with the purpose of ENC-based paper charts production and maintenance...|$|E
40|$|Abstract. The {{environment}} {{around us}} is progressively equipped with various sensors, producing data continuously. The applications using these data face many challenges, such as data stream integration over an attribute (such as time) and knowledge extraction from raw data. In this {{paper we propose}} one approach to face those two challenges. First, data streams integration is performed using statecharts which represents a resume of data produced by the corresponding <b>data</b> <b>producer.</b> Second, we detect anomalous events over temporal relations among statecharts. We describe our approach in a demonstration scenario, that is using a visual tool called Patternator. ...|$|E
30|$|After {{scientists}} {{locate the}} data of interest, personal conversation and discussion with the original <b>data</b> <b>producer(s)</b> or collector(s), if possible, are always helpful by revealing first-hand information and subtle details of the data collection, including the fundamental assumptions, processing history, and native context that are essential for rigorous research inquiries.|$|R
40|$|Research {{conducted}} at Purdue University and the University of Illinois resorted in the instrument, the Data Curation Profiles Toolkit. This tool {{is used to}} interview researchers and <b>data</b> <b>producers</b> about the <b>data</b> they create in research projects, {{what they are doing}} with it, and what they would like to do with it...|$|R
40|$|Nowadays {{geospatial}} data users search for geospatial information within an SDI using discovery clients of a Geoportal application (i. e. INSPIRE Geoportal). If <b>data</b> <b>producers</b> want to promote related resources {{and make them}} available in the SDI, then they need to create metadata according to the predefined rules (i. e. INSPIRE metadata regulation) and publish them using a CSW standard. This approach allows for either distributed searches or harvesting metadata from different SDI nodes. Nevertheless, {{there are still a}} lot of <b>data</b> <b>producers</b> making their resources available on the Web without documenting and publishing in a standardised way. The paper describes a workflow to provide a tool to make OGC-based geospatial services found on the Internet discoverable through CSW-compatible service catalogues and, hence, more visible to a wider SDI community. JRC. H. 6 -Digital Earth and Reference Dat...|$|R
40|$|Abstract: Teachers ’ work {{is often}} {{subjected}} to data analysis from outside {{sources in the}} forms of standardized examinations and media critique. This article uses the literature of risk analysis to play with two important analogies for teachers {{with regards to the}} emerging big data culture and the risk decisions therein. The complex context of the classroom facilitates the exploration of teacher as big <b>data</b> <b>producer,</b> while the multi-faceted nature of risk decisions provide the groundwork for the exploration of teacher as risk analyst. Illustrative classroom episodes portray examples of real and virtual risk faced by teachers, and a third category—curricular risk—is proposed...|$|E
40|$|In {{this paper}} we propose to use {{feedback}} control to automatically allocate disk bandwidth in order to match the rate of disk I/O to the real-rate [13] needs of applications. We describe a model for adaptive resource management based on measuring the relative progress of stages in a producer-consumer pipeline. We show how to use prefetching to transform a passive disk into an active <b>data</b> <b>producer</b> whose progress can be controlled via feedback. Our progress-based framework allows the integrated control of multiple resources. The resulting system automatically adapts to varying application rates {{as well as to}} varying device latencies. ...|$|E
40|$|The Bachelor thesis {{deals with}} {{commutator}} direct current motors and electronically commutated motors of company Maxon motor AG. The {{first part of}} its deals basic structural elements and focuses {{on the characteristics of}} these engines, such as lifetime, revolution properties, efficiency and control methods. The thesis deals with properties, principle of operation and construction of hysteresis brake. Another important theme is improved by the construction of the dynamometer. The last part contains the actual measurement of DC commutator motors assigned Maxon RE and Maxon S, which are loaded with hysteresis brake and final evaluation measurements comparing measured values with the <b>data</b> <b>producer...</b>|$|E
40|$|After the {{dissolution}} of initial partnership network, involved into the international SIGLE cooperation, {{at the beginning of}} 2005, new and broader partnership network was founded at the end of 2009. In November 2012, there are 91 <b>data</b> <b>producers</b> from the fields of research and science, education, culture and also enterprise, namely research institutes, universities, libraries etc. Partnership network has been built to support National Repository of Grey Literature (NRGL). Grey literature <b>data</b> <b>producers</b> can choose from three types of cooperation with NRGL. All data are available through the Central Search Interface at [URL] in both Czech and English versions. National Technical Library (NTK) as a promoter supports partnership network in many ways. NTK runs informative webpages, e-mail conference, publishes manuals and methodologies, performs presentations and trainings and organizes full day conference every year. Includes: Conference preprint, Powerpoint presentation, Abstract and Biographical notesXAInternationa...|$|R
50|$|Survey of India dedicates {{itself to}} the {{advancement}} of theory, practice, collection and applications of geospatial data, and promotes an active exchange of information, ideas, and technological innovations amongst the <b>data</b> <b>producers</b> and users who will get access to such data of highest possible resolution at an affordable cost in the near real-time environment.|$|R
30|$|The bottom line, then, is {{that data}} for German {{enterprises}} that combine {{information from the}} statistics of employees covered by social security and information from surveys performed by the Statistical Offices, and firm level data that stem from different <b>data</b> <b>producers</b> in general, should be widely accessible to foster research and to support evidence-based policy advice.|$|R
