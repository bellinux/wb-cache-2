11|5820|Public
2500|$|A {{loudspeaker}} (or loud-speaker or speaker) is an electroacoustic transducer; which converts an <b>electrical</b> <b>audio</b> <b>signal</b> into {{a corresponding}} sound.|$|E
2500|$|The {{most widely}} used type of speaker in the 2010s is the dynamic speaker, invented in 1925 by Edward W. Kellogg and Chester W. Rice. [...] The dynamic speaker {{operates}} on the same basic principle as a dynamic microphone, but in reverse, to produce sound from an electrical signal. When an alternating current <b>electrical</b> <b>audio</b> <b>signal</b> is applied to its voice coil, a coil of wire suspended in a circular gap between the poles of a permanent magnet, the coil is forced to move rapidly back and forth due to Faraday's law of induction, which causes a diaphragm (usually conically shaped) attached to the coil to move back and forth, pushing on the air to create sound waves. Besides this most common method, there are several alternative technologies {{that can be used}} to convert an electrical signal into sound. The sound source (e.g., a sound recording or a microphone) must be amplified or strengthened with an audio power amplifier before the signal is sent to the speaker.|$|E
50|$|An {{important}} field of invention {{during this period}} was the tape recorder. Magnetic tape recording uses an amplified <b>electrical</b> <b>audio</b> <b>signal</b> to generate analogous variations of the magnetic field produced by a tape head, which impresses corresponding variations of magnetization on the moving tape. In playback mode, the signal path is reversed, the tape head acting as a miniature electric generator as the varyingly magnetized tape passes over it.|$|E
25|$|Headphones {{originated}} from the telephone receiver earpiece, {{and were the}} only way to listen to <b>electrical</b> <b>audio</b> <b>signals</b> before amplifiers were developed. The first truly successful set was developed in 1910 by Nathaniel Baldwin, who made them by hand in his kitchen and sold them to the United States Navy.|$|R
50|$|Later {{electronic}} switching systems implemented the digital {{representation of the}} <b>electrical</b> <b>audio</b> <b>signals</b> on subscriber loops by digitizing the analog signals and processing the resulting data for transmission between central offices. Time-division multiplexing (TDM) technology permitted the simultaneous transmission of multiple telephone calls on a single wire connection between central offices or other electronic switches, resulting in dramatic capacity improvements of the telephone network.|$|R
40|$|A {{stereophonic}} enhancement {{system is}} described which expands the perceived {{width of the}} stereo sound image. The system accepts <b>electrical</b> <b>audio</b> <b>signals</b> comprising a two-channel (left and right) stereo pair and produces enhanced left and right stereo signals for use with conventional two-channel audio recording and playback systems. The system includes control circuitry which monitors the dissimilarity of {{the left and right}} input signals and optionally the dissimilarity of the left and right processed output signals. An all-pass decorrelation subsystem can also be included for mono-to-stereo conversion of monophonic input signals prior to the spatial enhancement system. 1. INTRODUCTION Spatial enhancement processes are intended to produce the aural impression that the stereo sound field has become larger, and optionally to simulate a stereo effect from a monophonic recording. These features are useful in order to simulate a more spacious and natural sonic impression than can ordinaril [...] ...|$|R
50|$|An {{audio signal}} is a {{representation}} of sound, typically as an electrical voltage. Audio signals have frequencies in the audio frequency range of roughly 20 to 20,000 Hz (the limits of human hearing). Audio signals may be synthesized directly, or may originate at a transducer such as a microphone, musical instrument pickup, phonograph cartridge, or tape head. Loudspeakers or headphones convert an <b>electrical</b> <b>audio</b> <b>signal</b> into sound. Digital representations of audio signals exist {{in a variety of}} formats.|$|E
5000|$|A {{loudspeaker}} (or loud-speaker or speaker) is an electroacoustic transducer; which converts an <b>electrical</b> <b>audio</b> <b>signal</b> into {{a corresponding}} sound. [...] The {{most widely used}} type of speaker in the 2010s is the dynamic speaker, invented in 1925 by Edward W. Kellogg and Chester W. Rice. The dynamic speaker operates on the same basic principle as a dynamic microphone, but in reverse, to produce sound from an electrical signal. When an alternating current <b>electrical</b> <b>audio</b> <b>signal</b> is applied to its voice coil, a coil of wire suspended in a circular gap between the poles of a permanent magnet, the coil is forced to move rapidly back and forth due to Faraday's law of induction, which causes a diaphragm (usually conically shaped) attached to the coil to move back and forth, pushing on the air to create sound waves. Besides this most common method, there are several alternative technologies {{that can be used}} to convert an electrical signal into sound. The sound source (e.g., a sound recording or a microphone) must be amplified or strengthened with an audio power amplifier before the signal is sent to the speaker.|$|E
50|$|The wire {{is pulled}} rapidly across a {{recording}} head which magnetizes each point along the wire {{in accordance with}} the intensity and polarity of the <b>electrical</b> <b>audio</b> <b>signal</b> being supplied to the recording head at that instant. By later drawing the wire across the same or a similar head while the head is not being supplied with an electrical signal, the varying magnetic field presented by the passing wire induces a similarly varying electric current in the head, recreating the original signal at a reduced level.|$|E
40|$|Abstract Background Pregnancy {{testing in}} cattle is {{commonly}} invasive requiring manual rectal palpation of the reproductive tract that presents {{risks to the}} operator and pregnancy. Alternative non-invasive tests have been developed but have not gained popularity due to poor specificity, sensitivity and the inconvenience of sample handling. Our aim is to present the pilot study and proof of concept of a new non invasive technique to sense the presence and age (limited to the closest trimester of pregnancy) of the foetus by recording the <b>electrical</b> and <b>audio</b> <b>signals</b> produced by the foetus heartbeat using an array of specialized sensors embedded in a stand alone handheld prototype device. The device {{was applied to the}} right flank (approximately at the intercept of a horizontal line drawn through the right mid femur region of the cow and a vertical line drawn anywhere between lumbar vertebrae 3 to 5) of more than 2000 cattle from 13 different farms, including pregnant and not pregnant, a diversity of breeds, and both dairy and beef herds. Pregnancy status response is given “on the spot” from an optimized machine learning algorithm running on the device within seconds after data collection. Results Using combined <b>electrical</b> and <b>audio</b> foetal <b>signals</b> we detected pregnancy with a sensitivity of 87. 6 % and a specificity of 74. 6 % for all recorded data. Those values increase to 91 % and 81 % respectively by removing files with excessive noise (19 %). Foetus ageing was achieved by comparing the detected foetus heart-rate with published tables. However, given the challenging farm environment of a restless cow, correct foetus ageing was achieved for only 21 % of the correctly diagnosed pregnant cows. Conclusions In conclusion we have found that combining ECG and PCG measurements on the right flank of cattle provides a reliable and rapid method of pregnancy testing. The device has potential to be applied by unskilled operators. This will generate more efficient and productive management of farms. There is potential for the device to be applied to large endangered quadrupeds in captive breeding programs where early, safe and reliable pregnancy diagnosis can be imperative but currently difficult to achieve. </p...|$|R
5000|$|Audio {{electronics}} is {{the implementation}} of electronic circuit designs to perform conversions of sound/pressure wave signals to electrical signals, or vice versa. Electronic circuits considered a part of audio electronics may also be designed to achieve certain signal processing operations, {{in order to make}} particular alterations to the signal while it is in the <b>electrical</b> form. Additionally, <b>audio</b> <b>signals</b> can be created synthetically through the generation of electric signals from electronic devices. Audio Electronics were traditionally designed with analog electric circuit techniques until advances in digital technologies were developed. Moreover, digital signals are able to be manipulated by computer software much the same way audio electronic devices would, due to its compatible digital nature. Both analog and digital design formats are still used today, and the use of one or the other largely depends on the application. The following is a partial list of audio-related circuits/techniques/devices: ...|$|R
40|$|Nowadays, {{monitoring}} and control methods are applicable only for specific natural technological systems (NTS). As a result, statistical information about existing systems is not well coordinated. This drawback becomes more evident in emergency situations, when effective decisions must be taken within short time while different information flows have to be analysed. Monitoring information regarding incidents and disasters is received typically from different facilities (e. g. biometric systems, aerospace systems, etc.), and, therefore, it is heterogeneous in nature (e. g. <b>electrical</b> <b>signals,</b> <b>audio</b> and video information, text, etc.). Thus, since modern NTS are very complex and multi-functional objects, their {{monitoring and}} control should be performed in conditions of large-scale heterogeneous data sets. The INFROM project ”Integrated Intelligent Platform for Monitoring the Cross-Border Natural-Technological Systems” addresses the problem of integrated {{monitoring and control}} of cross-border natural-technological systems in normal and emergency situations, based on analysis of heterogeneous data received from both space and ground-based facilities...|$|R
5000|$|An {{electric}} megaphone is {{a handheld}} public address system, an electronic device that amplifies the human voice like an acoustic megaphone, using electric power. It {{consists of a}} microphone to convert sound waves into an <b>electrical</b> <b>audio</b> <b>signal,</b> an amplifier powered by a battery to increase {{the power of the}} audio signal, and a loudspeaker to convert the audio signal to sound waves again. Although slightly heavier than acoustic megaphones, electric megaphones can amplify the voice to a higher level, to over 90 dB. They have replaced acoustic megaphones in most applications, and are generally used to address congregations of people wherever stationary public address systems are not available; at outdoor sporting events, movie sets, political rallies, and street demonstrations.|$|E
5000|$|A {{speaker driver}} is an {{individual}} loudspeaker transducer that converts an <b>electrical</b> <b>audio</b> <b>signal</b> to sound waves. While the term is sometimes used interchangeably with the term loudspeaker (speaker), it is usually applied to specialized transducers which reproduce {{only a portion of}} the audible frequency range. For high fidelity reproduction of sound, multiple loudspeakers are often mounted in the same enclosure, each reproducing {{a different part of the}} audible frequency range. In this case the individual speakers are referred to as drivers and the entire unit is called a loudspeaker. Drivers made for reproducing high audio frequencies are called tweeters, those for middle frequencies are called mid-range drivers, and those for low frequencies are called woofers, while those for very low bass range are subwoofers. Less common types of drivers are supertweeters and rotary woofers.|$|E
50|$|The carbon microphone, {{also known}} as carbon button microphone, button microphone, or carbon transmitter, {{is a type of}} microphone, a {{transducer}} that converts sound to an <b>electrical</b> <b>audio</b> <b>signal.</b> It consists of two metal plates separated by granules of carbon. One plate is very thin and faces toward the speaking person, acting as a diaphragm. Sound waves striking the diaphragm cause it to vibrate, exerting a varying pressure on the granules, which in turn changes the electrical resistance between the plates. Higher pressure lowers the resistance as the granules are pushed closer together. A steady direct current is passed between the plates through the granules. The varying resistance results in a modulation of the current, creating a varying electric current that reproduces the varying pressure of the sound wave. In telephony, this undulating current is directly passed through the telephone wires to the central office. In public address systems or recording devices it is amplified by an audio amplifier. The frequency response of the carbon microphone, however, is limited to a narrow range, and the device produces significant electrical noise.|$|E
40|$|I {{have been}} playing the drums for {{thirteen}} years. I started out on an electric drum set and then progressed to an acoustic set. I have always {{wondered what it would}} sound like to combine the two types of sounds and this senior project dissected that interest to its raw form. Delving into the problems and solutions of combining digital and analog <b>audio</b> <b>signals</b> intrigued me and thus, became my senior project. The design process included research into the analog and digital realms, computer simulations, and actual implementation successes and failures. The signal path begins at the bass drum where a piezoelectric drum triggering transducer converts vibration into a specific voltage level. This voltage level flows into a voltage comparator circuit. When the threshold voltage, pre-determined through various test methods, of the voltage comparator is exceeded, the rail voltage flows into a voltage-controlled, open-collector N-MOSFET circuit. This acts as a switch which closes when the threshold voltage has been exceeded, completing the circuit of the external trigger pins that directly trigger pre-selected MP 3 tracks on an MP 3 Trigger circuit. This signal flows into a voltage follower circuit which acts as buffer, eliminating distortion. Finally, the signal flows into a summing circuit with an adjustable gain. Meanwhile, a microphone picks up the bass drum’s acoustical energy (sound waves) and converts this energy into <b>electrical</b> energy (the <b>audio</b> <b>signal).</b> This signal flows into a preamplifier which boosts the low-voltage signal to a reasonable level. This signal flows into a voltage follower which acts as a buffer for the microphone signal. Finally, this signal also flows into a summing circuit with an adjustable gain. The summing circuit combines the MP 3 <b>audio</b> <b>signal</b> with the microphone signal. The output of this signal connects to an output jack and a quarter-inch cable connects this output jack to a PA system which has a power amplifier. This is necessary in order to drive the speakers...|$|R
40|$|An input <b>audio</b> <b>signal</b> {{having an}} input {{temporal}} envelope is converted into an output <b>audio</b> <b>signal</b> having an output temporal envelope. The input temporal envelope of the input <b>audio</b> <b>signal</b> is characterized. The input <b>audio</b> <b>signal</b> is processed {{to generate a}} processed <b>audio</b> <b>signal,</b> wherein the processing de-correlates the input <b>audio</b> <b>signal.</b> The processed <b>audio</b> <b>signal</b> is adjusted based on the characterized input temporal envelope to generate the output <b>audio</b> <b>signal,</b> wherein the output temporal envelope substantially matches the input temporal envelope...|$|R
40|$|An audio {{enhancement}} {{device in}} accordance with the present invention comprises an extraction circuit (210) for extracting a first <b>audio</b> <b>signal</b> from a first input signaland a second <b>audio</b> <b>signal</b> from a second input signal, and extracting inter-channel parameters from atleast a part of the first <b>audio</b> <b>signal</b> and at least a part of the second <b>audio</b> <b>signal,</b> a processing circuit for processing (230) the first <b>audio</b> <b>signal</b> and the second audio 5 signalinto processed <b>audio</b> <b>signals,</b> and a re-instating circuit for re-instating (240) the inter- channel parameters into the processed <b>audio</b> <b>signals</b> resulting in a first output <b>audio</b> <b>signal</b> and a second output <b>audio</b> <b>signal...</b>|$|R
50|$|An {{important}} field of invention {{during this period}} was the tape recorder. Magnetic tape recording uses an amplified <b>electrical</b> <b>audio</b> <b>signal</b> to generate analogous variations of the magnetic field produced by a tape head, which impresses corresponding variations of magnetization on the moving tape. In playback mode, the signal path is reversed, the tape head acting as a miniature electric generator as the varyingly magnetized tape passes over it. The original solid steel ribbon {{was replaced by a}} much more practical coated paper tape, but acetate soon replaced paper as the standard tape base. Acetate has fairly low tensile strength and if very thin it will snap easily, so it was in turn eventually superseded by polyester. This technology, the basis for almost all commercial recording from the 1950s to the 1980s, was developed in the 1930s by German audio engineers who also rediscovered the principle of AC biasing (first used in the 1920s for wire recorders), which dramatically improved the frequency response of tape recordings. The technology was further improved just after World War II by American audio engineer John T. Mullin with backing from Bing Crosby Enterprises. Mullin's pioneering recorders were modifications of captured German recorders. In the late 1940s, the Ampex company produced the first tape recorders commercially available in the US.|$|E
40|$|An audio {{processing}} arrangement (200) comprises {{a plurality}} of audio sources (101, 102) generating input <b>audio</b> <b>signals,</b> a processing circuit (110) for deriving processed <b>audio</b> <b>signals</b> from the input <b>audio</b> <b>signals,</b> a combining circuit (120) for deriving a combined audio signalfrom the processed <b>audio</b> <b>signals,</b> and a control circuit (130) for controlling the processing circuit {{in order to maximize}} a power measure of the combined <b>audio</b> <b>signal</b> and for limiting a function of gains of the processed <b>audio</b> <b>signals</b> to a predetermined value. In accordance with the present invention, the audio processing arrangement (200) comprises a pre-processing circuit (140) for deriving pre-processed <b>audio</b> <b>signals</b> from the input <b>audio</b> <b>signals</b> to minimize a cross-correlation of interferences comprised in the input <b>audio</b> <b>signals.</b> The pre-processed signals are provided to the processing circuit (110) instead of the input <b>audio</b> <b>signals...</b>|$|R
40|$|WO 200280415 A UPAB: 20021129 NOVELTY - The method {{involves}} estimating (13) an <b>audio</b> <b>signal</b> {{specific characteristic}} of the <b>audio</b> <b>signal</b> indicating {{a measure of the}} energy of the inserted information, pre-processing (12) the signal based on the estimated characteristic to influence the energy and obtain a pre-processed <b>audio</b> <b>signal</b> and extracting (16) the information from the pre-processed <b>audio</b> <b>signal.</b> DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: an arrangement for detecting information inserted into an <b>audio</b> <b>signal,</b> an arrangement for inserting information into an <b>audio</b> <b>signal</b> and a method of inserting information into an <b>audio</b> <b>signal.</b> USE - For determining information with energy inserted into <b>audio</b> <b>signal.</b> ADVANTAGE - Enables secure determination of information inserted into an <b>audio</b> <b>signal</b> without reducing the data rate of the inserted information significantly...|$|R
40|$|WO 2008049587 A 1 UPAB: 20080620 NOVELTY - A {{compression}} unit (110) performs {{lossy compression}} of original representation of <b>audio</b> <b>signal</b> for obtaining compressed representation of <b>audio</b> <b>signal.</b> A {{difference between the}} compressed representation of <b>audio</b> <b>signal</b> and original representation of <b>audio</b> <b>signal</b> is calculated to obtain a discrimination representation (122). The ambient signal (132) is generated based on discrimination representation. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following: (1) multi-channel <b>audio</b> <b>signal</b> deriving apparatus; (2) ambient signal generation method; (3) multi-channel <b>audio</b> <b>signal</b> derivation method; (4) ambient signal generation program; and (5) multi-channel <b>audio</b> <b>signal</b> deriving program. USE - Apparatus for generating ambient <b>signal</b> from <b>audio</b> <b>signal</b> for upmixing mono <b>audio</b> <b>signals</b> recorded on DVD for playback on multi-channel system. ADVANTAGE - Prevents the introduction of synthetic audio effects to the ambient signal hence the ambient signal is free from reverberation...|$|R
40|$|A {{device for}} {{processing}} an <b>audio</b> <b>signal,</b> wherein the device comprises a detection unit adapted for detecting a widening {{state of the}} <b>audio</b> <b>signal,</b> and a widening modification unit adapted for modifying a widening characteristic of the <b>audio</b> <b>signal</b> depending on the detected widening state of the <b>audio</b> <b>signal...</b>|$|R
40|$|An {{apparatus}} {{for enhancing}} an <b>audio</b> <b>signal</b> comprises a signal processor for processing the <b>audio</b> <b>signal</b> {{in order to}} reduce or eliminate transient and tonal portions of the processed signal and a decorrelator for generating a first decorrelated signal and a second decorrelated signal from the processed signal. The apparatus further comprises a combiner for weightedly combining the first and the second decorrelated <b>signal</b> and the <b>audio</b> <b>signal</b> or a signal derived from the <b>audio</b> <b>signal</b> by coherence enhancement using time variant weighting factors and to obtain a two-channel <b>audio</b> <b>signal.</b> The apparatus further comprises a controller for controlling the time variant weighting factors by analyzing the <b>audio</b> <b>signal</b> so that different portions of the <b>audio</b> <b>signal</b> are multiplied by different weighting factors and the two-channel <b>audio</b> <b>signal</b> has a time variant degree of decorrelation...|$|R
40|$|An {{audio encoder}} for {{encoding}} an <b>audio</b> <b>signal,</b> comprises: a first encoding processor (600) for encoding a first <b>audio</b> <b>signal</b> portion in a frequency domain, wherein the first encoding processor (600) comprises: a time frequency converter (602) for converting the first <b>audio</b> <b>signal</b> portion into a frequency domain representation having spectral lines up {{to a maximum}} frequency of the first <b>audio</b> <b>signal</b> portion; an analyzer (604) for analyzing the frequency domain representation up to the maximum frequency to determine first spectral portions to be encoded with a first spectral resolution and second spectral regions to be encoded with a second spectral resolution, the second spectral resolution being lower than the first spectral resolution; a spectral encoder (606) for encoding the first spectral portions with the first spectral resolution and for encoding the second spectral portions with the second spectral resolution; a second encoding processor (610) for encoding a second different <b>audio</b> <b>signal</b> portion in the time domain; a controller (620) configured for analyzing the <b>audio</b> <b>signal</b> and for determining, which portion of the <b>audio</b> <b>signal</b> is the first <b>audio</b> <b>signal</b> portion encoded in the frequency domain and which portion of the <b>audio</b> <b>signal</b> is the second <b>audio</b> <b>signal</b> portion encoded in the time domain; and an encoded signal former (630) for forming an encoded <b>audio</b> <b>signal</b> comprising a first encoded signal portion for the first <b>audio</b> <b>signal</b> portion and a second encoded signal portion for the second <b>audio</b> <b>signal</b> portion...|$|R
40|$|DE 10129239 C UPAB: 20021204 NOVELTY - The water-marking method embeds a water-mark in an <b>audio</b> <b>signal</b> by {{providing}} a spectral representation of the <b>audio</b> <b>signal</b> and a spectral representation of the water-mark signal, the latter processed in dependence on the psychoacoustic masking threshold of the <b>audio</b> <b>signal,</b> to allow the water-mark signal to be combined with the <b>audio</b> <b>signal</b> without being audibly perceived. DETAILED DESCRIPTION - An INDEPENDENT CLAIM for a device for embedding a water-mark <b>signal</b> in an <b>audio</b> <b>signal</b> is also included. USE - The method is used for embedding a water-mark <b>signal</b> in an <b>audio</b> <b>signal.</b> ADVANTAGE - The method allows the water-mark signal to be embedded in the <b>audio</b> <b>signal</b> without being audibly perceived...|$|R
30|$|We {{will only}} {{consider}} tonal <b>audio</b> <b>signals,</b> that is, signals having a continuous spectrum containing {{a finite number}} of dominant frequency components. In this way, the majority of <b>audio</b> <b>signals</b> is covered, except for the class of percussive sounds. The performance of the different LP models described below will be evaluated for three types of audio signals: synthetic <b>audio</b> <b>signals</b> consisting of a sum of harmonic sinusoids in white noise, true monophonic <b>audio</b> <b>signals,</b> and true polyphonic <b>audio</b> <b>signals.</b>|$|R
40|$|An {{efficient}} encoded {{representation of}} a first and a second input <b>audio</b> <b>signal</b> can be derived using correlation information indicating a correlation {{between the first and}} the second input <b>audio</b> <b>signals,</b> when a signal characterization information, indicating at least a first or a second, different characteristic of the input <b>audio</b> <b>signal</b> is additionally considered. Phase information indicating a phase relation between the first and the second input <b>audio</b> <b>signals</b> is derived, when the input <b>audio</b> <b>signals</b> have the first characteristic. The phase information and a correlation measure are included into the encoded representation when the input <b>audio</b> <b>signals</b> have the first characteristic, and only the correlation information is included into the encoded representation when the input <b>audio</b> <b>signals</b> have the second characteristic...|$|R
40|$|Algorithms exist {{which will}} perform {{independent}} transformations on frequency or duration of a digital <b>audio</b> <b>signal.</b> These processes have different results {{different types of}} <b>audio</b> <b>signals.</b> A comparative study of granular and phase vocoder algorithms, implementation, and their respective effects on <b>audio</b> <b>signals</b> was made to determine which algorithm is best suited to {{a particular type of}} <b>audio</b> <b>signal...</b>|$|R
40|$|An Audio decoder for {{decoding}} a multi-audio-object <b>signal</b> {{having an}} <b>audio</b> <b>signal</b> {{of a first}} type and an <b>audio</b> <b>signal</b> of a second type encoded therein is described, the multi-audio-object signal consisting of a downmix signal (56) and side information (58), the side information comprising level information (60) of the <b>audio</b> <b>signal</b> of the first type and the <b>audio</b> <b>signal</b> of the second type in a first predetermined time/frequency resolution (42), and a residual signal (62) specifying residual level values in a second predetermined time/frequency resolution, the audio decoder comprising means (52) for computing prediction coefficients (64) based on the level information (60);; and means (54) for up-mixing the downmix signal (56) based on the prediction coefficients (64) and the residual signal (62) to obtain a first up-mix <b>audio</b> <b>signal</b> approximating the <b>audio</b> <b>signal</b> of the first type and/or a second up-mix <b>audio</b> <b>signal</b> approximating the <b>audio</b> <b>signal</b> of the second type...|$|R
40|$|WO 2009100876 A 1 UPAB: 20090902 NOVELTY - The device has a {{fingerprint}} calculator (304) computing {{a fingerprint}} per block of an <b>audio</b> <b>signal</b> (114) according to block allocation information (302) {{to obtain a}} sequence of test-audio signal-fingerprints (306). A fingerprint extractor (308) extracts a sequence of reference-audio signal-fingerprints from reference <b>audio</b> <b>signal</b> fingerprint information of multi-channel expansion data (132). A fingerprint correlator (312) correlates the two sequences to obtain a correlation result. A compensator (316) controls a time offset between the expansion data and the <b>audio</b> <b>signal</b> based on the result. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a method for synchronizing multi-channel expansion data with an <b>audio</b> <b>signal</b> (2) a device for processing an <b>audio</b> <b>signal</b> (3) a method for processing an <b>audio</b> <b>signal</b> (4) a computer program with a program core for executing a method for processing an <b>audio</b> <b>signal.</b> USE - Device for synchronizing multi-channel expansion data with an <b>audio</b> <b>signal</b> e. g. mono-downmix, stereo-downmix and monophonic <b>audio</b> <b>signal,</b> according to MPEG- 4 standard. ADVANTAGE - The compensator controls the time offset between the multi-channel expansion data and the <b>audio</b> <b>signal</b> based on the correlation result, thus reducing or eliminating the time offset between the multi-channel expansion data and the <b>audio</b> <b>signal,</b> and hence achieving an accurate synchronization by the block-based printing technology in an efficient and reliable manner, while obtaining a multi-channel reconstruction with high quality. The fingerprints represent a better and efficient characteristic for the <b>audio</b> <b>signal...</b>|$|R
50|$|<b>Audio</b> <b>signal</b> {{processing}} is {{the electronic}} manipulation of <b>audio</b> <b>signals</b> using analog and digital signal processing.|$|R
40|$|The thesis {{deals with}} {{negative}} influences of <b>audio</b> <b>signals</b> {{in the environment}} and the impact of the signals on human in psychological and physiological point of view. The origins of such <b>audio</b> <b>signals</b> as well as protection from their negative effects are considered. The thesis includes an overview study of standards and basic literature. Selected <b>audio</b> <b>signals</b> are presented using a program for negative <b>audio</b> <b>signal</b> analysis...|$|R
40|$|Abstract. This paper {{presents}} {{a system of}} <b>audio</b> <b>signal</b> processing based on FPGA,the system uses audio codec chip LM 4550 to A/D transform and D/A transform the input analog <b>audio</b> <b>signal</b> and output digital <b>audio</b> <b>signal.</b> Using FPGA as the high speed signal processor to realize volume adjustment and audio effect control,so it can output different style music. Meantime, the system designs a FFT computing module and control system of VGA display interface,to compute the digital <b>audio</b> <b>signal</b> which is A/D transformed,and real-time display the frequency spectrum of <b>audio</b> <b>signal</b> on VGA...|$|R
40|$|For a {{bandwidth}} {{extension of}} an <b>audio</b> <b>signal,</b> in a <b>signal</b> spreader the <b>audio</b> <b>signal</b> is temporally spread by a spread factor greater than 1. The temporally spread <b>audio</b> <b>signal</b> is then supplied to a demicator to decimate the temporally spread version by a decimation factor matched {{to the spread}} factor. The band generated by this decimation operation is extracted and distorted, and finally combined with the <b>audio</b> <b>signal</b> to obtain a bandwidth extended <b>audio</b> <b>signal.</b> A phase vocoder in the filterbank implementation or transformation implementation {{may be used for}} signal spreading...|$|R
40|$|We {{present a}} method for {{automatically}} equalizing music and <b>audio</b> <b>signals</b> based on information extracted from the signal. The main goal is to enhance the perceived audio quality especially if the sound quality of the <b>audio</b> <b>signal</b> is unsatisfactory. This method is based only on information contained within the <b>audio</b> <b>signal,</b> thus no further informa-tion is needed about recording conditions and equipment. The method adapts the equalizing {{in such a way}} that it re-duces the self-masking within an <b>audio</b> <b>signal,</b> in this way increasing the audibility of the information contained in the <b>audio</b> <b>signal.</b> Assuming that <b>audio</b> quality increases with the audibility of information within the <b>audio</b> <b>signal,</b> this approach will lead to an improved audio quality. ...|$|R
