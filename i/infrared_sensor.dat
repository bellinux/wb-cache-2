787|1936|Public
5|$|In 2007 the LITENING {{targeting}} pod was fitted, {{which increased}} {{the effectiveness of}} the aircraft in the attack of ground targets with a variety of standoff weapons, using laser guidance, a high-resolution forward-looking <b>infrared</b> <b>sensor</b> (FLIR), and a CCD camera used to obtain target imagery. LITENING pods have been fitted {{to a wide variety of}} other US aircraft, such as the McDonnell Douglas F/A-18 Hornet, the General Dynamics F-16 Fighting Falcon and the McDonnell Douglas AV-8B Harrier II.|$|E
5|$|The {{periscopes}} {{also had}} problems with their optics: periscope users reported difficulty in refocusing after changing magnification, duplication of images, and bands across the field of vision. These problems were attributed to RAN demands that the optical view be the first exposed when a periscope was raised above the water, instead of placing the <b>infrared</b> <b>sensor</b> and single-pulse radar at the head as on other submarines, requiring the optical path to be routed around these components. The periscopes were gradually improved, and were no longer a problem {{by the time the}} fast track submarines entered service.|$|E
5|$|With export {{interest}} from Brazil, Japan, and Italy {{serving as a}} source of encouragement to continue development of the Harrier II, McDonnell Douglas commenced work on a night-attack variant in 1985. With the addition of an <b>infrared</b> <b>sensor</b> and cockpit interface enhancements, the 87th production single-seat AV-8B became the first Harrier II to be modified for night attacks, leaving the McDonnell Douglas production line in June 1987. Flight tests proved successful and the night attack capability was validated. The first of 66 AV-8B(NA)s was delivered to the USMC in September 1989. An equivalent version of the AV-8B(NA) also served with the RAF under the designation GR7; earlier GR5 aircraft were subsequently upgraded to GR7 standards.|$|E
5000|$|Seeker: Dual-mode active (laser) {{and passive}} (<b>infrared)</b> <b>sensors.</b>|$|R
3000|$|<b>Infrared</b> <b>sensors</b> {{are largely}} {{employed}} in lane marking detection without the environmental limitations of cameras and lighting. Since their coverage range {{is limited to}} close distances, they are viewed capable in detecting lane departures [110]. Furthermore, <b>infrared</b> <b>sensors</b> are used in detecting pedestrians and bicycles, particularly at night [111].|$|R
5000|$|<b>Infrared</b> <b>sensors</b> (mounted either {{behind the}} {{windshield}} {{or under the}} vehicle) ...|$|R
5|$|The Kinect, a motion-sensing {{input device}} made by Microsoft and {{designed}} as a video game controller, was first introduced in November 2010, and was upgraded for the 2013 release of the eighth-generation Xbox One video game console. Kinect's capabilities were revealed in May 2013. The new Kinect uses an ultra-wide 1080p camera, which can function in the dark due to an <b>infrared</b> <b>sensor.</b> It employs higher-end processing power and new software, can distinguish between fine movements (such as a thumb movements), and can determine a user's heart rate by looking at his/her face. Microsoft filed a patent application in 2011 that suggests that the corporation may use the Kinect camera system to monitor the behavior of television viewers {{as part of a}} plan to make the viewing experience more interactive. On July 19, 2013, Microsoft stocks suffered its biggest one-day percentage sell-off since the year 2000 after its fourth-quarter report raised concerns among the investors on the poor showings of both Windows 8 and the Surface tablet; with more than 11 percentage points declining Microsoft suffered a loss of more than US$32 billion. For the 2010 fiscal year, Microsoft had five product divisions: Windows Division, Server and Tools, Online Services Division, Microsoft Business Division and Entertainment and Devices Division.|$|E
25|$|Following World War II, Soviet {{designers}} also {{experimented with}} unguided multibarreled rocket launchers but this design concept was abandoned {{in favor of}} guided missiles equipped with an <b>infrared</b> <b>sensor.</b>|$|E
25|$|A {{hand dryer}} is an {{electric}} device {{found in a}} public restroom and are used to dry hands. It may either operate with a button, or more recently, automatically using an <b>infrared</b> <b>sensor.</b> The hand dryer was invented in 1948 by George Clemens.|$|E
5000|$|... ultrasonic, motion, and <b>infrared</b> <b>sensors</b> {{which help}} the MABMAT {{navigate}} crime scene.|$|R
40|$|Abstract. This paper {{presents}} a new human-machine interface for controlling a wheelchair by head movements. The {{position of the}} head is determined by use of <b>infrared</b> <b>sensors,</b> with no parts attached {{to the head of}} the user. The placement of the <b>infrared</b> <b>sensors</b> are behind the head of the user, so that the field of view is no...|$|R
50|$|Sound Transit {{measures}} ridership {{by using}} the <b>infrared</b> <b>sensors</b> built into the doorways.|$|R
25|$|Electronic {{automatic}} flushes {{solve the}} problems of previous approaches, and are common in new installations. A passive <b>infrared</b> <b>sensor</b> identifies when the urinal has been used, by detecting when someone has stood in front of it and moved away, and then activates the flush. There usually is also a small override button, to allow optional manual flushing.|$|E
25|$|Pit vipers, pythons {{and some}} boas have organs {{that allow them}} to detect {{infrared}} light, such that these snakes are able to sense the body heat of their prey. The common vampire bat may also have an <b>infrared</b> <b>sensor</b> on its nose. It has been found that birds and some other animals are tetrachromats and have the ability to see in the ultraviolet down to 300 nanometers. Bees and dragonflies are also able to see in the ultraviolet. Mantis shrimps can perceive both polarized light and multispectral images and have twelve distinct kinds of color receptors, unlike humans which have three kinds and most mammals which have two kinds.|$|E
25|$|Some {{flushometer}} models {{require the}} user to either depress a lever or press a button, which in turn opens a flush valve allowing mains-pressure water to flow directly into the toilet bowl or urinal. Other flushometer models are electronically triggered, using an <b>infrared</b> <b>sensor</b> to initiate the flushing process. Typically, on electronically triggered models, an override button is provided in case the user wishes to manually trigger flushing earlier. Some electronically triggered models also incorporate a true mechanical manual override {{which can be used}} in the event of the failure of the electronic system. In retrofit installations, a self-contained battery-powered or hard-wired unit can be added to an existing manual flushometer to flush automatically when a user departs.|$|E
40|$|Abstract. The {{intrinsic}} value of information {{coupled with the}} dramatically falling costs of networked sensors suggest that ambient intelligence and ubiquitous computing are inevitable. However, before society resigns itself to a world of constant observation and tracking, a process of moralization and ethical deliberation should occur. In this paper we examine the ethical implications of choosing camera networks or infrared motion detector networks. We employ the Dimensional Metaethics approach to help us structure examination of the complex issues involved. The analysis indicates that choice of sensor technology can powerfully affect the ethical landscape surrounding the final system. This paper also analyzes empirical results from questionnaires that asked participants to rate and choose between scenarios involving pan-tilt-zoom cameras and <b>infrared</b> <b>sensors.</b> In testing against a hypothetical even split in opinion, we find instead a significant preference for the scenario involving <b>infrared</b> <b>sensors</b> (p = 0. 007). The results show that significant proportion (73 %, p = 0. 05) preferred a scenario with <b>infrared</b> <b>sensors</b> when compared to pan-tiltzoom cameras. Participants also report that the scenario with <b>infrared</b> <b>sensors</b> was significantly less invasive and expressed a significantly weaker preference toward situations “Without Sensors that Collect Information About Location ” (when compared with the scenario involving pan-tiltzoom cameras). In short, we find that both dimensional metaethics and questionnaire results suggest that <b>infrared</b> <b>sensors</b> are better. ...|$|R
40|$|This paper {{describes}} a new method for range estimation using low-cost <b>infrared</b> <b>sensors.</b> The intensity data obtained with <b>infrared</b> <b>sensors</b> depends highly {{on the surface}} properties and {{the configuration of the}} sensors and the surface. Therefore, in many of the related studies, either the properties of the surface are determined first or certain assumptions about the surface are made in order to calculate the distance and the orientation of the surface relative to the sensors. In this paper, we propose a novel method for position estimation of surfaces with <b>infrared</b> <b>sensors</b> without the need to determine the surface properties first. The method is verified experimentally with planar surfaces covered with white paper, wooden block, bubbled packing material, white styrofoam, blue and brown cardboard. The overall absolute mean error in the range estimates has been calculated as 0. 21 cm in the range from 12. 5 to 45 cm. The results obtained demonstrate that <b>infrared</b> <b>sensors</b> can be easily used for localization to an unexpectedly high accuracy without prior knowledge of the surface parameters. © 2004 IEEE...|$|R
40|$|This study {{investigates the}} use of {{low-cost}} <b>infrared</b> <b>sensors</b> in the differentiation and localization of target primitives commonly encountered in indoor environments, such as planes, corners, edges, and cylinders. The intensity readings from such sensors are highly dependent on target location and properties {{in a way that}} cannot be represented in a simple manner, making the differentiation and localization difficult. We propose {{the use of}} angular intensity scans from two <b>infrared</b> <b>sensors</b> and present a rule-based algorithm to process them. The method can achieve position-invariant target differentiation without relying on the absolute return signal intensities of the <b>infrared</b> <b>sensors.</b> The method is verified experimentally. Planes, 90 -deg corners, 90 -deg edges, and cylinders are differentiated with correct rates of 90 %, 100 %, 82. 5 %, and 92. 5 %, respectively. Targets are localized with average absolute range and azimuth errors of 0. 55 cm and 1. 03 deg. The demonstration shows that simple <b>infrared</b> <b>sensors,</b> when coupled with appropriate processing, can be used to extract a significantly greater amount of information than they are commonly employed for...|$|R
25|$|The {{use of an}} <b>infrared</b> <b>sensor</b> {{to detect}} {{position}} can cause some detection problems when other infrared sources are around, such as incandescent light bulbs or candles. This can be easily alleviated by using fluorescent lights around the Wii, which emit little to no infrared light. Innovative users have used other sources of IR light as Sensor Bar substitutes such {{as a pair of}} flashlights and a pair of candles. The Wii Remote picks up traces of heat from the sensor, then transmits it to the Wii console to control the pointer on your screen. Such substitutes for the Sensor Bar illustrate the fact that a pair of non-moving lights provide continuous calibration of the direction that the Wii Remote is pointing and its physical location relative to the light sources. There is no way to calibrate the position of the cursor relative to where the user is pointing the controller without the two stable reference sources of light provided by the Sensor Bar or substitutes. Third-party wireless sensor bars have also been released, which have been popular with users of Wii emulators since the official Sensor Bar utilizes a proprietary connector to connect to the Wii console.|$|E
25|$|On May 24, Midas 2 was orbited successfully, but the {{attitude}} control system failed. Some data was returned by the <b>infrared</b> <b>sensor</b> before the telemetry system also failed. Several planned experiments such as detection of flares {{on the ground and}} a Titan I missile test were abandoned. The next launch in the series did not take place for over a year and the program now moved to the West Coast, with Point Arguello's SLC-3 1-2 being its base of operations. During this interval, two CORONA satellites also carried and tested Midas sensors. Midas 3, the first operational model, was launched on July 24, 1961 using the new, restartable Agena B stage. The Atlas's programmer reset itself due to a malfunction during booster jettison, but the satellite reached orbit successfully. However, one solar panel failed to deploy, starving Midas 3 of electrical power and it died after a few orbits. Midas 4 (October 21) brought about further frustration when the Atlas lost roll control at T+186 seconds. The satellite was placed into an incorrect trajectory, causing the Agena to exhaust its attitude control gas trying to compensate during its two burns. By the time Midas 4 reached its intended transfer orbit, there was no attitude control gas left and the satellite could not be stabilized. It did manage to detect a Titan I launch from Cape Canaveral before one solar panel failed. A week into the mission, Midas 4 died when its batteries ran down.|$|E
500|$|The Menacer {{is a light}} gun {{peripheral}} {{released by}} Sega in 1992 for its Sega Genesis and Sega CD video game consoles. It was created in response to Nintendo's Super Scope and as Sega's successor to the Master System Light Phaser. The gun is built from three detachable parts (pistol, shoulder stock, sights), and communicates with the television via an <b>infrared</b> <b>sensor.</b> The Menacer was announced at the May 1992 Consumer Electronics Show in Chicago and was released later that year. The gun was bundled with a pack-in six-game cartridge of mostly shooting gallery games. Sega also released a Menacer bundle with [...]|$|E
50|$|The Subaru team {{is able to}} {{turn off}} their car's {{headlights}} and use <b>infrared</b> <b>sensors</b> for racing at night.|$|R
40|$|Designs of electron-tunneling <b>infrared</b> <b>sensors</b> and {{micromachining}} processes used {{to fabricate}} them modified to increase sensitivity and to simplify operation, adjustment, and associated circuitry. Corrugations, pinholes, and standard packaging incorporated into design. Deflection voltages reduced, and thermal drifts eliminated. Performances exceed {{those of other}} commercially available, uncooled <b>infrared</b> <b>sensors.</b> Operation of sensors simplified to such extent, now feasible to ship them to nonexpert users for routine testing and evaluation in their laboratories...|$|R
5000|$|The kits {{also come}} with common {{robotics}} hardware that connects easily {{with the software}} (<b>infrared</b> <b>sensors,</b> motors, microphone and video camera).|$|R
2500|$|Image: MIDAS <b>infrared</b> <b>sensor</b> {{installation}}.PNG|MIDAS <b>infrared</b> <b>sensor</b> installation ...|$|E
2500|$|An <b>infrared</b> <b>sensor</b> {{enables the}} {{microcontroller}} {{to communicate with}} a handheld device ...|$|E
2500|$|As of 2017 {{there are}} still a series of {{technical}} problems that need to be tackled, including the reliability of its WS-15 engines, [...] control system, stealth coatings and hull materials, and <b>infrared</b> <b>sensor.</b>|$|E
30|$|On {{the other}} hand, {{a number of}} studies on {{pedestrian}} counting have used devices such as <b>infrared</b> imaging <b>sensors</b> (Leykin and Hammoud 2006; Goubet et al. 2006), passive <b>infrared</b> <b>sensors</b> (Hashimoto et al. 1998), laser sensors (Cui et al. 2007), ultrasonic sensors (Chen et al. 2008). In addition, there are commercial pedestrian counters using devices such as <b>infrared</b> imaging <b>sensors</b> (IRISYS people counter 2014), active <b>infrared</b> <b>sensors</b> (PCW- 2 BX 03 directional people counter 2014), passive <b>infrared</b> <b>sensors</b> (Eco counter 2014), piezo films (Acoustic slab sensor 2014) and laser scanners (LOTraffic 2014). In particular, binary <b>sensors,</b> such as <b>infrared</b> <b>sensors</b> and piezo sensors, are among the simplest sensors, capable of detecting only {{the presence or absence of}} objects within the sensing region. Although binary sensors can neither detect the number of pedestrians nor identify individual pedestrians within the sensing region, they possess advantages such as low cost, simplicity, small size, and energy efficiency in comparison with other types of sensors. Therefore, methods for estimation of the number of pedestrians by using binary sensors have attracted attention. Since the capabilities of a single binary sensor are limited, as mentioned above, some researchers have considered using combinations of binary sensors for estimating the number of pedestrians together with their movement direction (Chen et al. 2008; Son et al. 2007; Lee 2009; Taniguchi and Nakano 2014). However, in these methods, the estimation accuracy significantly decreases in crowded environments where a large number of pedestrians move simultaneously.|$|R
50|$|Gas Sensor technologies, {{design and}} {{manufacture}} of <b>Infrared</b> <b>Sensors,</b> Pellistor Sensors, Metal Oxide Sensors, Thermal Conductivity Sensors, Electrochemical Sensors and Evaluation Kits, with applications in Mining, Oil and gas, Confined space entry, Indoor air quality, Industrial area protection and Leak detection.|$|R
50|$|The FRF2 {{precision}} rifle sight {{is based}} on the use of uncooled <b>infrared</b> <b>sensors,</b> combined with adapted magnifying optics. It also includes radio communication resources.|$|R
2500|$|The Army's AN/GSQ-187 Improved Remote Battlefield Sensor System (I-REMBASS) {{contains}} a Passive <b>Infrared</b> <b>Sensor,</b> DT-565/GSQ, which [...] "detects tracked or wheeled vehicles and personnel. It also {{provides information on}} which to base a count of objects passing through its detection zone and reports their direction of travel relative to its location. The monitor uses two different [...] sensors and their identification codes to determine direction of travel.|$|E
2500|$|The CTA data {{indicate}} maximum g-load of 45 g's, a turning speed {{at or above}} 20 degrees per second and maximum angle of screening more than 30 degrees. Another source says that the CTA is also developing an <b>infrared</b> <b>sensor</b> capable of trapping front for future versions. This means that the missile is not [...] "all-aspect" [...] and can only engage targets when fired towards {{the rear of the}} aircraft. This data may refer to older models.|$|E
2500|$|A roof-mounted {{electro-optical}} sensor turret {{is located}} {{forward of the}} rotor head, containing a forward looking <b>infrared</b> <b>sensor,</b> a laser rangefinder and a colour TV camera. [...] A total of four hardpoints are fitted under the rotorcraft's stub wings to allow the carriage of external stores, these have a total capacity of 132kg (291lb). The outer pylons can carry four Type 91 guided surface-to-air missiles, while the inner pylons are capable of carrying external fuel tanks for additional range or endurance. No additional armament is typically fitted.|$|E
5000|$|The {{documentation}} {{states that}} Roboquad's <b>infrared</b> <b>sensors</b> are sensitive {{enough to allow}} it to navigate doorways.It is also a good friend for people above 5.|$|R
50|$|Ground combat {{includes}} {{the use of}} both active and passive <b>infrared</b> <b>sensors</b> and so the USMC ground combat uniform requirements document specifies infrared reflective quality standards.|$|R
40|$|Intelligent ambient {{assisted}} living systems for elderly and handicapped people become affordable {{with the recent}} advances in computer and sensor technologies. In this paper, fall detection algorithm using multiple passive <b>infrared</b> <b>sensors</b> is developed. As a novel method for detecting a falling person, two passive <b>infrared</b> <b>sensors</b> are used concurrently {{in a room and}} developed a determination algorithm depending on the height at which the falling event is happened. Motionles detection system is integrated with the falling person detection system to provide a complete solution. Detection algorithms are implemented using embedded microprocessors. © 2013 IEEE...|$|R
