19|62|Public
2500|$|The Banu Musa {{brothers}} {{described a}} number of early automatic controls. Two-step level controls for fluids, an early form of <b>discontinuous</b> <b>variable</b> structure controls, {{was developed by the}} Banu Musa brothers. They also described an early feedback controller. Donald Routledge Hill wrote the following on the automatic controls underlying the mechanical trick devices described in the book: ...|$|E
50|$|The Persian Banū Mūsā brothers, {{in their}} Book of Ingenious Devices (850 AD), {{described}} {{a number of}} automatic controls. Two-step level controls for fluids, a form of <b>discontinuous</b> <b>variable</b> structure controls, {{was developed by the}} Banu Musa brothers. They also described a feedback controller.|$|E
5000|$|The Banu Musa {{brothers}} {{described a}} number of early automatic controls. Two-step level controls for fluids, an early form of <b>discontinuous</b> <b>variable</b> structure controls, {{was developed by the}} Banu Musa brothers. They also described an early feedback controller. Donald Routledge Hill wrote the following on the automatic controls underlying the mechanical trick devices described in the book: ...|$|E
30|$|Data were {{recorded}} and analysed with SPSS 12 statistical software: the X 2 test for <b>discontinuous</b> <b>variables</b> and Student’s t-test for continuous variables were used.|$|R
30|$|The genetic {{algorithm}} was combined with linear programming (LP) {{and was used}} in solving the problem of optimization which is a mixed integer linear problem. In this way, the <b>discontinuous</b> <b>variables</b> of the problem are modeled in the {{genetic algorithm}}, and in the section of fitness of the genetic algorithm, a LP is recalled.|$|R
40|$|A {{technique}} {{is described by}} which the latent structure model of multi-variate analysis formulated by Lazarsfeld may be applied with only moderate computational effort. The technique, termed disposition analysis, is based upon defining a functional relationship between variables and patterns of variables. Both continuous and <b>discontinuous</b> <b>variables</b> may be treated separately or intermixed. "TID- 4500 (35 th Edition); Mathematics and Computers. ""November 1964. "Includes bibliographical references (p. 13). A {{technique is}} described by which the latent structure model of multi-variate analysis formulated by Lazarsfeld may be applied with only moderate computational effort. The technique, termed disposition analysis, is based upon defining a functional relationship between variables and patterns of variables. Both continuous and <b>discontinuous</b> <b>variables</b> may be treated separately or intermixed. Mode of access: Internet. This bibliographic record is available under the Creative Commons CC 0 public domain dedication. The University of Florida Libraries, as creator of this bibliographic record, has waived all rights to it worldwide under copyright law, including all related and neighboring rights, to the extent allowed by law...|$|R
5000|$|In the 9th century, Banū Mūsā brothers' Book of Ingenious Devices {{described}} {{a number of}} early automatic controls in fluid mechanics. Two-step level controls for fluids, an early form of <b>discontinuous</b> <b>variable</b> structure controls, {{was developed by the}} Banu Musa brothers. They also {{described a}}n early feedback controller for fluids. According to Donald Routledge Hill, the Banu Musa brothers were [...] "masters in the exploitation of small variations" [...] in hydrostatic pressures and in using conical valves as [...] "in-line" [...] components in flow systems, [...] "the first known use of conical valves as automatic controllers." [...] They also described the use of other valves, including a plug valve, float valve and tap. The Banu Musa also developed an early fail-safe system where [...] "one can withdraw small quantities of liquid repeatedly, but if one withdraws a large quantity, no further extractions are possible." [...] The double-concentric siphon and the funnel with bent end for pouring in different liquids, neither of which appear in any earlier Greek works, were also original inventions by the Banu Musa brothers. Some of the other mechanisms they described include a float chamber and an early differential pressure.|$|E
40|$|Maximization and {{matching}} predictions were examined for a time-based analogue of the concurrent variable-interval variable-ratio schedule. One alternative was a variable interval whose time base operated relatively {{independent of the}} schedule chosen, {{and the other was}} a <b>discontinuous</b> <b>variable</b> interval for which timing progressed only when selected. Pigeons switched between schedules by pecking a changeover key. The maximization hypothesis predicts that subjects will show a bias toward the <b>discontinuous</b> <b>variable</b> interval and undermatching; however the obtained results conformed closely to the predictions of the matching law. Finally, a quantitative comparison was made of the bias and sensitivity estimates obtained in published concurrent variable-interval variable-ratio analogue studies. Results indicated that only the ratio-based analogue of the concurrent variable interval variable ratio studied by Green, Rachlin, and Hanson (1983) produced significant bias toward the variable-ratio alternative and undermatching, as predicted by reinforcement maximization...|$|E
40|$|In this paper, a weak {{formulation}} of the <b>discontinuous</b> <b>variable</b> coefficient Poisson equation with interfacial jumps is introduced. The existence, uniqueness and regularity of solutions of the Poisson equation are obtained. Finite difference methods {{can be derived from}} the weak formulation. An abstract framework is given for proving convergence of the finite difference methods for such problems. The finite difference method developed in [9] is proven to be convergent...|$|E
40|$|By using spline functions, {{a unified}} {{expression}} to describe various continuous or <b>discontinuous</b> <b>variables</b> in sandwich shells and laminated shells is derived. Then a general nonlinear theory of anisotropic sandwich shells faced with laminated composites is developed using {{the assumption of}} a smooth layer-wise curvilinear coordinate 8 after deformation. The theory combines the global theory and the discrete-layer theory of laminated shells {{in view of the}} structural characteristics of anisotropic sandwich shells faced with laminated composites. A series of refined theories for sandwich and laminated shells can be obtained directly by simplifying the general theory. 1...|$|R
40|$|In {{recent years}} {{significant}} reconstructions {{have been done}} in the programs of genetic improvement of farm animals. Although long-term selection for the improvement of production traits has reached the assumed objectives, it has also contributed to the degradation of the so-called functional traits (Hansen, 2000). Most production traits are geneti-cally and phenotypically continuous. For this rea-son linear models could be successfully used for their analysis. However, even though determined by the number of loci, some functional traits are <b>discontinuous</b> <b>variables.</b> They are called threshold traits. Many of them, for instance fertility, hatch-ability or resistance to certain diseases are binary traits...|$|R
30|$|To {{evaluate}} the fitness of chromosomes, {{the value of}} the proposed objective function is calculated. In {{such a way that the}} value of one chromosome in the genetic algorithm is assumed, the values of <b>discontinuous</b> <b>variables</b> of the problem are known. Thus, by replacing these values in the objective function and considering the limitations of the problem, a linear programming problem is formed. By solving this linear problem, the total value of the objective function will be defined and attributed to that chromosome. In this section, if the LP has no feasible response (as this is a minimizing problem), the given chromosome would be penalized with a big value.|$|R
40|$|Abstract. In this paper, a weak {{formulation}} of the <b>discontinuous</b> <b>variable</b> coefficient Poisson equation with interfacial jumps is studied. The existence, uniqueness and regularity of solutions of this problem are obtained. It is shown that {{the application of the}} Ghost Fluid Method by Fedkiw, Kang, and Liu to this problem in [9] can be obtained in framework is given for proving the convergence of finite difference methods derived from a weak problem, and as a consequence, the Ghost Fluid Method is proven to be convergent. 1...|$|E
40|$|Education is {{effectively}} {{used as a}} <b>discontinuous</b> <b>variable</b> in studies estimating the rates of return by level of education. We find that the normal procedure used for estimating the rate of return to broad aggregates such as secondary and high understates the returns to these levels and subsequently suggest a procedure for rectifying this bias. We also find, as expected, that broad aggregations that ignore sub-levels of education result {{in a loss of}} important insights about the interaction of education and the labor market. ...|$|E
40|$|In this paper, a {{switching}} control approach is stud-ied with applications to active vibration isolation. The control design {{is based on}} the concept of input-to-state stability of the resulting discontinuous feedback sys-tem with respect to disturbances. The switching con-trol strategy demonstrates improved disturbance rejec-tion under feedback combined with a small sensitivity to noise in the absence of such feedback. Herein the control effort needed to achieve improved performance is substantially reduced. To access the performance of the closed-loop system, the control scheme is tested on a commercially available isolation system. Key words Absolute stability, <b>discontinuous</b> <b>variable</b> gains...|$|E
40|$|A unifying {{modeling}} method is presented the (1) extends the declarative, equation based, object oriented modeling approach by <b>discontinuous</b> and <b>variable</b> structure components which arise from abstractions in physical system models and (2) combines this with imperative, reactive, discrete event controllers {{based on the}} statechart and the sequential function chart formalisms...|$|R
40|$|When complex {{projects}} {{result in}} large-cost over-runs, managers {{want to understand}} why this happened. There may be the possibility of making a claim against another party, or managers may simply wish to learn from any mistakes made. When using system dynamics (SD) models to analyse the reasons for project over-runs {{as a part of}} a litigation or organizational learning process, there is a strong focus on explaining historical aspects precisely. This leads to a need for the inclusion of <b>discontinuous</b> <b>variables.</b> This paper discusses the nature of discontinuities in SD models of project over-runs. Examples are given to demonstrate that the modelling of such discontinuities needs to be an integral part of the continuous simulation modelling process. Their inclusion helps to improve model validity and also, by forcing validity, uncover the important drivers of project behaviour. The examples given in this paper are significant drivers and suggest important learning about the behaviour of disrupted complex projects...|$|R
40|$|Abstract We {{present a}} {{numerical}} {{analysis of the}} dy-namics of all-to-all coupled Hodgkin-Huxley (HH) neuronal networks with Poisson spike inputs. It is im-portant to point out that, since the dynamical vector of the system contains <b>discontinuous</b> <b>variables,</b> we pro-pose a so-called pseudo-Lyapunov exponent adapted from the classical definition using only continuous dy-namical variables, and apply it in our numerical inves-tigation. The numerical results of the largest Lyapunov exponent using this new definition {{are consistent with the}} dynamical regimes of the network. Three typical dynamical regimes—asynchronous, chaotic and syn-chronous, are found as the synaptic coupling strength increases from weak to strong. We use the pseudo-Lyapunov exponent and the power spectrum analysis of voltage traces to characterize the types of the network behavior. In the nonchaotic (asynchronous or synchro-nous) dynamical regimes, i. e., the weak or strong cou-pling limits, the pseudo-Lyapunov exponent is negative and there is a good numerical convergence of the solu-tion in the trajectory-wise sense by using our numerical methods. Consequently, in these regimes the evolutio...|$|R
40|$|In this paper, a weak {{formulation}} of the <b>discontinuous</b> <b>variable</b> coefficient Poisson equation with interfacial jumps is studied. The existence, uniqueness and regularity of solutions of this problem are obtained. It is shown that {{the application of the}} Ghost Fluid Method by Fedkiw, Kang, and Liu to this problem can be obtained in a natural way through discretization of the weak formulation. An abstract framework is given for proving the convergence of finite difference methods derived from a weak problem, and as a consequence, the Ghost Fluid Method is proven to be convergent. Comment: 17 pages, 3 figure...|$|E
40|$|The {{economic}} dispatch {{problem of}} a virtual power plant (VPP) is becoming non-convex for distributed generators’ characteristics of valve-point loading effects, prohibited operating zones, and multiple fuel options. In this paper, the economic dispatch model of VPP is established and then solved by a distributed randomized gradient-free algorithm. To deal with the non-smooth objective function, its Gauss approximation is used to construct distributed randomized gradient-free oracles in optimization iterations. A projection operator is also introduced to solve the <b>discontinuous</b> <b>variable</b> space problem. An example simulation is implemented on a modified IEEE- 34 bus test system, and the results demonstrate the effectiveness and applicability of the proposed algorithm...|$|E
40|$|This paper applies three {{different}} control techniques {{to the design}} of a quarter car semi-active suspension system. The three techniques, originally developed to solve a constrained optimal control problem, are optimal gain switching, <b>discontinuous</b> <b>variable</b> structure control and explicit model predictive control. All of them divide the state space into convex regions and assign a linear or affine state feedback controller to each region. The partition of the state space is computed off-line. During the on-line phase, the controller switches between the subcontrollers according to the current state. All the above techniques gave satisfactory results when applied {{to the design of}} semiactive suspension systems. A detailed comparison in terms of computational complexity, performance and simplicity of the design is proposed in the paper. Published as...|$|E
40|$|Background: Many {{studies showed}} a {{connection}} between exposition {{to high levels of}} urban pollution (especially to particulate and traffic noise) and the onset of even deadly cardiovascular diseases. DESIGN: Meta-analysis of case-control design. Objectives: The aim {{of this study is to}} estimate the association between cardiovascular effects and occupational exposition to atmospheric pollution in urban environment. Methods: DATA SOURCES: Biomedcentral, MEDLINE/ PubMed, MEDLINE/ National Library of Medicine (NLM), MEDLINE Plus, Nioshtic- 2, Scopus, TOXNET/Toxline, unpublished studies known by the authors and acts of national and internationl conferences between 1988 and May 2010 included. There has not been any kind of language or typological restriction. CRITERIA OF ELEGIBILITY: The research on cardiovascular effects includes control cases of workers exposed to urban pollution, compared with non-exposed subjects. PARTICIPANTS AND INTERVENTIONS: The selected studies present outdoor workers exposed to urban pollution (drivers and petrol pump attendants) and a control group of indoor workers (managers, university students and other selected subjects). STUDY APPRAISAL AND SYNTHESIS METHODS: The evidences (independently token from two different authors) have been grouped in two classes, the first one formed by continuous variables (systolic blood pressure, diastolic blood pressure, heart rate, total cholesterol, HDL cholesterol, LDL cholesterol, triglycerides) and the second one by <b>discontinuous</b> <b>variables</b> (electrocardiographic abnormalities prevalence, hypertension prevalence, hypercholesterolemia prevalence). The studies related to both classes and presenting more than one variable for each class have been included and used, in order to elaborate the results. We calculated heterogeneity in each variable (ES calculation for continuous variables and OR calculation for <b>discontinuous</b> <b>variables).</b> Results: On 378 publications, we have selected and included 16 articles. The variables show statistically irrelevant differences between exposed group and control group, except regarding the triglycerides. Limitations. The controlled studies are limited and characterized by a non-homogeneous evaluation of both expositional times of workers to urban pollution and of professional expositional values. Conclusions: Considering the heterogeneity and the lack of studies, it is impossible at the moment to document effects on the cardiovascular system in workers exposed to urban pollution. The results of this meta-analysis only suggest the association of urban pollution with alteration of triglycerides blood levels (referring to just three studies). As reported in scientific literature on this subject, it is necessary to conduct a future professional investigation on this subject with more qualified and homogeneous studies...|$|R
40|$|We {{investigate}} {{the application of}} two heuristic methods, genetic algorithms and tabu/scatter search, to the optimisation of realistic portfolios. The model {{is based on the}} classical mean-variance approach, but enhanced with floor and ceiling constraints, cardinality constraints and nonlinear transaction costs which include a substantial illiquidity premium. It is shown that genetic algorithms can optimise such portfolios effectively and within reasonable times. This approach also copes easily with extensive modifications such as the addition of more intricate constraints, <b>discontinuous</b> <b>variables</b> and more complex objective functions. The results indicate that that both floor and ceiling constraints have a substantial negative impact on portfolio performance and should be examined critically. Another insight is that nonlinear transaction costs which are comparable in magnitude to forecast returns will tend to diversify portfolios; the effect of these costs on portfolio risk is, however, ambiguous, depending on the degree of diversification required for cost reduction. The number of assets in a portfolio invariably increases as a result of constraints, costs and their combination. The implementation of cardinality constraints is essential for finding the best-performing portfolio. The ability of the heuristic method to deal with cardinality constraints is one of its most powerful features. ...|$|R
40|$|The Cesam code is a {{consistent}} set {{of programs and}} routines which perform calculations of 1 D quasi-hydrostatic stellar evolution including microscopic diffusion of chemical species and diffusion of angular momentum. The solution of the quasi-static equilibrium is performed by a collocation method based on piecewise polynomials approximations projected on a B-spline basis; that allows stable and robust calculations, and the exact restitution of the solution, not only at grid points, even for the <b>discontinuous</b> <b>variables.</b> Other advantages are the monitoring by only one parameter of the accuracy and its improvement by super-convergence. An automatic mesh refinement has been designed for adjusting the localisations of grid points according to the changes of unknowns. For standard models, {{the evolution of the}} chemical composition is solved by stiffly stable schemes of orders up to four; in the convection zones mixing and evolution of chemical are simultaneous. The solution of the diffusion equation employs the Galerkin finite elements scheme; the mixing of chemicals is then performed by a strong turbulent diffusion. A precise restoration of the atmosphere is allowed for. Comment: 13 pages, 1 figure, accepted for publication in Astrophysics & Space Science, ESTA/CoRoT Volum...|$|R
40|$|In many {{geotechnical}} stability problems it {{is important}} to account for interface conditions between soil and structure, e. g. retaining walls and footings with no-tension contact. These interfaces can be considered as discontinuities in stress and velocity fields developed in the system undergoing plastic collapse. <b>Discontinuous</b> <b>variable</b> fields are often employed in FE lower and upper bound limit analyses to improve the performance of lower order elements used to obtain rigorous bounds on the collapse factor. Recently it was shown that these discontinuities can be conveniently represented by a patch of regular elements of zero thickness. This development opens the way for discontinuous LA formulations to be used with general yield criteria in both two-and three-dimensions to solve stability problems involving a wide variety of materials and interface conditions...|$|E
40|$|We thank Hans Husum for his {{interest}} for our article 1. The correlation between Injury Severity Score (ISS) and Physiological Severity Score (PSS) was calculated as Spearman’s rho, because the ISS is a <b>discontinuous</b> <b>variable.</b> Spearman’s rho was ÷ 0. 401, p < 0. 0005. This indicates {{that when the}} anatomical injury severity increases the physiological derangement is increased, which should be of no surprise. We agree that the PSS 2 is an approximation for the Revised Trauma Score (RTS) 3. Indeed, the PSS has severe drawbacks because it employs cut-off values for blood pressure and respiratory frequency that {{are different from the}} original PTS. Despite this, the PSS was able to predict mortality to a certain degree. The area under the curve when constructing a receiver operating curve for PSS as test variable and death a...|$|E
40|$|AbstractResidual {{stress is}} one of the most {{critical}} parameters in surface integrity, which has a great impact on fatigue life of the machined components. While the flank milling of titanium alloy Ti- 6 Al- 4 V has been widely applied to the manufacture of jet engine for its high productivity in aerospace industry, prediction of residual stress induced by this process is seldom reported. In this paper, an analytical model of residual stress is proposed, based on comprehensive analysis of the mechanical loading during flank milling. For the first time, the sequential <b>discontinuous</b> <b>variable</b> loading feature of flank milling is taken into consideration. An incremental elasto-plastic method followed by a relaxation procedure is used to get the stress-strain history of an arbitrary point in the subsurface so as to predict the residual stress retained in the workpiece after several loading cycles. We find that during the last phase in which the machined surface is generated, the main load comes from the plough effect of cutting edge as the uncut depth approaches zero. The simulation results indicate that the flank milled surface shows more compressive residual stress in the axial direction than in the feed direction. To validate the prediction, a series of cutting tests are conducted on Ti- 6 Al- 4 V using finish parameters and X-ray diffraction is utilized to obtain the residual stress...|$|E
40|$|Tanguy, Sebastien Menard, Thibaut Berlemont, AlainDevelopment and {{applications}} of numerical methods devoted to reactive interface simulations are presented. Emphasis {{is put on}} vaporization, where numerical difficulties arise in imposing accurate jump conditions for heat and mass transfers. We use both the Level Set Method and the Ghost Fluid Method to capture the interface motion accurately and to handle suitable jump conditions. A local vaporization mass flow rate per unit of surface area is defined and Stefan flow {{is involved in the}} process. Specific care has been devoted to the extension of <b>discontinuous</b> <b>variables</b> across the interface to populate ghost cells, in order to avoid parasitic currents and numerical diffusion across the interface. A projection method is set up to impose both the velocity field continuity and a divergence-free condition for the extended velocity field across the interface. The d(2) law is verified in the numerical simulations of the vaporization of an isolated static drop. Results are then presented for a water droplet moving in air. Vapor mass fraction and temperature fields inside and outside the droplet are presented. (c) 2006 Elsevier Inc. All rights reserved...|$|R
40|$|The Faustmann-Samuelson {{solution}} for optimal asset rotation is extended to consider both asset rejuvenation and nonconstant prices. A dynamic theoretical model is developed {{in terms of}} an optimal control problem with <b>discontinuous</b> control <b>variables,</b> and numerical solution procedures are outlined. The model is applied to layer hen replacement where hen rejuvenation by forced molting is a common industrial practice. Results indicate a sensitivity between the decision to rejuvenate or replace a hen and the egg price cycle, suggesting a mixed rotation strategy. Key words: asset replacement, dynamic programming, eggs, forced molting...|$|R
40|$|AbstractIn this paper, the {{development}} of a simulation program that can automatically generate equations of motion for mutibody systems in the discrete event simulation framework is presented. The need to analyze the dynamic response of mechanical systems that are under event triggered conditions is increasing. General mechanical systems can be defined as multibody systems that are collections of interconnected rigid bodies, consistent with various types of joints that limit the relative motion of pairs of bodies. For complex multibody systems, a systematic approach is required to efficiently set up the mathematical models. Therefore, a dynamics kernel was developed to automatically generate the equations of motion for multibody systems based on multibody dynamics. The developed dynamics kernel also provides the numerical solver for the dynamic analysis of multibody systems. The general multibody dynamics kernel cannot deal with <b>discontinuous</b> state <b>variables,</b> event triggered conditions, and state triggered conditions, though. To enable it to deal with multibody systems in discontinuous environments, the multibody dynamics kernel was integrated into a discrete event simulation framework, which was developed based on the discrete event system specification (DEVS) formalism. DEVS formalism is a modular and hierarchical formalism for modeling and analyzing systems under event triggered conditions, which are described by <b>discontinuous</b> state <b>variables.</b> To verify the developed program, it was applied to an block-lifting and transport simulation, and dynamic analysis of the system is carried out...|$|R
40|$|The {{question}} how to quantize a classical system where an angle phi {{is one of}} the basic canonical variables has been controversial {{since the early days of}} quantum mechanics. The problem is that the angle is a multivalued or <b>discontinuous</b> <b>variable</b> on the corresponding phase space. The remedy is to replace phi by the smooth periodic functions cos phi and sin phi. In the case of the canonical pair (phi,l),l: orbital angular momentum (OAM), the phase space S_(phi,l) ={phi in R mod 2 pi, l in R} has the global structure S^ 1 x R of a cylinder on which the Poisson brackets of the 3 functions cos phi, sin phi and l obey the Lie algebra of the euclidean group E(2) in the plane. This property provides the basis for the quantization of the system in terms of irreducible unitary representations of the group E(2) or of its covering groups. A crucial point is that - due to the fact that the subgroup SO(2) = S^ 1 is multiply connected - these representations allow for fractional OAM l = n + c, c in [0, 1). Such c not 0 have already been observed in cases like the Aharonov-Bohm and the fractional quantum Hall effects and they correspond to the quasi-momenta of Bloch waves in ideal crystals. The proposal of the present paper is to look for fractional OAM in connection with the quantum optics of Laguerre-Gaussian laser modes in external magnetic fields. The quantum theory of the phase space S_(phi,l) in terms of unitary representations of E(2) allows for two types of "coherent" states the properties of which are discussed in detail: Non-holomorphic minimal uncertainty states and holomorphic ones associated with Bargmann-Segal Hilbert spaces. Comment: Latex, 50 pages; v 2 : typos corrected, Refs. and a few remarks added; v 3 : version (up to a very few minor details) accepted for publication in PR...|$|E
40|$|The tectono-sedimentary Neogene {{evolution}} of a key area of Southern Tuscany has been analyzed. The area is characterized by two extensional basins (the Volterra Basin {{to the west and}} Val d'Elsa Basin to the east) separated by a morphological and structural high (the "Dorsale Medio Toscana"). The analysis has been carried out along a cross section from the southwest edge of the Volterra Basin (Mazzolla-Castellina in Chianti) to {{the eastern edge of the}} Val d'Elsa Basin (Chianti Mountain). Six paleo-sections were reconstructed ranging in age from the Serravallian to the Recent. Biostratigraphic and paleoenvironmental information obtained from micropaleontological analyses has allowed the evaluaionn of fault activities in the two basins at the various stages of evolution. During Serravallian-early Tortonian the whole area was part of a single sedimentary basin: the Ponsano Basin. That is, there is no evidence to suggest that at that time the "Dorsale Medio Toscana" was a morphological high. During late Tortoian the "Dorsale Medio Toscana" developed and separated the basins of Volterra and Val d'Era. The separation was not complete, however, as indicated by identlcal ostracod assemblages in the two basins. The basins contain fluvial and lacustrine sediments. Rapid rise and partial emersion of the "Dorsale Medio Toscana" and possible presence of relatively steep slopes are suggested by conglomeratic debris flow deposits interbedded with lacustrine sediments. Furthermore, pebbles of conglomeratic layers of fluvio-lacustnne sequence were totally originated from the rocks of ligurian units and from the Ponsano Formation that formed the ridge bedrock. During early Messinian the "Dorsale Medio Toscana" was fully emerged, and separated completely the two basins. In fact, Messinian marine facies have been found in the Volterra Basin but not in the Val d'Elsa Basin. During late Messinian ("lago mare" phase) a connection was re-established between the two basins as indicated by identical microfaunistical assemblages. This connection must have developed elsewhere, because along the studied cross-section the "Dorsale Medio Toscana" remained a morphological high. During Pliocene the two basins behaved differently. The Volterra Basin experienced a continuous high rate of sedimentation, whereas the Val d'Era Basin experienced <b>discontinuous,</b> <b>variable</b> sedimentation. Furthermore during the early Mlddle Pliocene, subsidence affected the area studied and much of the "Dorsale Medio Toscana" was submerged except in the Spicchiaiola-Pignano region. Afterwards still in the Middle Pliocene, the whole area was affected by regional uplift, which led to a major marine regression everywhere in Southern Tuscany...|$|E
40|$|Like {{many areas}} of the law, the Fifth Amendment has defied {{theoretical}} explanation by scholars. We examine whether the fifth amendment cases can be explained with a relatively simple theory, and find that they can. The key to that theory is the recognition that, although never acknowledged by the Court, its cases make plain that 2 ̆ 2 testimony 2 ̆ 2 is the substantive content of cognition - the propositions with truth-value that people hold or generate (as distinct from the ability to hold or generate propositions with truth-value). This observation leads to a comprehensive positive theory of the Fifth Amendment right: the government may not compel disclosure of the incriminating substantive results of cognition that themselves (the substantive results) are the product of state action. As we demonstrate in this article, this theory explains all of the cases, a feat not accomplished under any other scholarly or judicial theory; it even explains the most obvious datum that might be advanced against it - the sixth birthday question in Muniz. There remain two sources of ambiguity in Fifth Amendment adjudications. First, compulsion and incrimination are both continuous variables - questions of degree. The Court has recognized this and set about defining the amount of compulsion and incrimination necessary to a Fifth Amendment violation. The result is a common law of both topics rather than a precise metric of either. These two variables are independent and do not interact, which reduces the complexity of decision making. Compulsion, in other words, is in no way determined by {{the extent to which the}} results are incriminating. Compulsion is determined on its own, as is the sufficiency of incrimination. The second source of ambiguity arises from the Court not explicitly equating 2 ̆ 2 testimony 2 ̆ 2 with cognition, though that is precisely what has controlled its decisions. Given that the Court 2 ̆ 7 s opinions have not focused on substantive cognition as the third element of a Fifth Amendment violation, it is not surprising that the Court has not clarified whether cognition, too, is a continuous or <b>discontinuous</b> <b>variable.</b> This is where the future lies. The Court will have to clarify two matters: first, whether the extent of cognition matters, and second, the derivative consequences of cognition. In addition, the Court will have to determine whether these two issues are, like compulsion and incrimination, independent. Does the extensiveness of the compelled cognition determine how far its causal effect will be traced? We then note that this 2 ̆ 2 theory 2 ̆ 2 does not look like a standard academic theory with its attendant emphasis on normative analysis. We examine whether the normal meaning of 2 ̆ 2 normative justification 2 ̆ 2 is a very useful one in any field of law with the range of the fifth amendment, point out that it is quite similar to the fourth amendment in this regard, and that scholarly efforts to discover its 2 ̆ 2 true 2 ̆ 2 justification may be doomed to failure. This does not mean that fields of law are unjustified, but perhaps that the justification must come in other terms. The terms plainly applicable to these two areas are the traditional ones of the rule of law. The Court has strived to make sense of ambiguous directives through creating and sustaining relatively clear legal categories and by responding to new situations through analogies to prior cases. We think it plausible that, however dull this may appear to the legal theorist, the legal system may be better off as a result. The article thus adds to the growing literature concerning the nature of legal theorizing by demonstrating yet another area where legal theorizing in its modern conventional sense (involving the search for the moral or philosophical theory that justifies an area of law) has been completely ineffectual, whereas explanations that are informed by the presently neglected values of legality (clarity, precision, consistency, fidelity to authority) have considerable promise...|$|E
40|$|Under the {{supervision}} of Professor John Mitchell; 189 pp. The objective {{of the work is}} to develop methods for minimizing the energy costs of chilled water systems through optimal control. The general approach includes the following tasks: 1) proposing a system of parametric models that represent the real chilled water system, 2) determining model parameters from measured data, and 3) subjecting the system of parametric models to an optimization algorithm. A comprehensive approach for determining the optimal control for any general chilled water system is developed. The general system presents a difficult problem for parameter estimation and optimization because of <b>discontinuous</b> <b>variables</b> and nonlinear relationships between input and output variables. Various methods for parametric estimation and control optimization are pre- sented and demonstrated on simulated and actual plant models. The actual plant model consists of interconnected component models, including an electric motor driven chiller, a steam turbine driven chiller and associated steam condenser, and a multi- cell cooling tower. Different parameter estimation methods using measured plant data are applied and compared. Optimal supervisory control is determined through application of the simulated annealing method to the model. The dependence of optimal control settings upon independent variables (e. g. chilled water return temperature and ambient wet bulb temperature) is investi- gated. Cost savings of optimal over conventional control strategies are calculated and compared...|$|R
40|$|This is a {{collection}} of contributed papers which focus on recent results in areas of differential equations, function spaces, operator theory and interpolation theory. In particular, it covers current work on measures of non-compactness and real interpolation, sharp Hardy-Littlewood-Sobolev inequalites, the HELP inequality, error estimates and spectral theory of elliptic operators, pseudo differential operators with <b>discontinuous</b> symbols, <b>variable</b> exponent spaces and entropy numbers. These papers contribute to areas of analysis which have been and continue to be heavily influenced by the leading British analysts David Edmunds and Des Evans. This book marks their respective 80 th and 70 th birthdays...|$|R
40|$|Variation and {{cytotype}} distribution {{have been}} studied in secondary birch woodland where intermediates between Betula pendula and B. pubescens appear to predominate. Trees at three sites in lowland eastern England, with contrasting soil conditions, were examined. Thirty-eight of the trees studied proved to be tetraploid (2 n= 56) and the remaining 12 were diploid (2 n= 28); no triploids or aneuploids were detected. Principal Components Analysis of up to 20 biometric characters of leaves, catkins, fruits and achenes revealed an essentially continuous pattern of variation. The diploid trees displayed rather limited variation and corresponded fairly well with B. pendula. In contrast, the tetraploids showed very great variation which included that normally associated with both species {{and most of the}} possible kinds of intermediate. The same pattern of variation was evident in several <b>discontinuous</b> <b>variables</b> and also in measurements of pollen diameter and guard-cell length made on 20 trees at one site (Holme Fen). Variation was in part site-dependent, suggesting that the different environments were influencing phenotype. Twenty trees at one site (Dersingham) were located on a topographic gradient from bog to heath; here there was a strong correlation between the loadings of individual trees on the principal axes of variation and the elevation of those trees on the gradient. This indicates a morphological cline which might be determined by site-wetness. The cline was not associated with polyploidy, as it was mostly attributable to variation within the tetraploids...|$|R
