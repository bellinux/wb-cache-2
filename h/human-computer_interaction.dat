6633|330|Public
5|$|Douglas Engelbart, {{the founder}} of SRI's Augmentation Research Center (ARC), was the primary force behind the design and {{development}} of the multi-user oN-Line System (or NLS), featuring original versions of modern computer-human interface elements including bit-mapped displays, collaboration software, hypertext, and precursors to the graphical user interface such as the computer mouse. As a pioneer of <b>human-computer</b> <b>interaction,</b> Engelbart is arguably SRI's most notable alumnus. He was awarded the National Medal of Technology and Innovation in 2000.|$|E
5|$|Douglas Carl Engelbart (January 30, 1925– July 2, 2013) was an American {{engineer}} and inventor, {{and an early}} computer and Internet pioneer. He {{is best known for}} his work on founding the field of <b>human–computer</b> <b>interaction,</b> particularly while at his Augmentation Research Center Lab in SRI International, which resulted in creation of the computer mouse, and the development of hypertext, networked computers, and precursors to graphical user interfaces. These were demonstrated at The Mother of All Demos in 1968. Engelbart's Law, the observation that the intrinsic rate of human performance is exponential, is named after him.|$|E
5|$|Pausch was an {{assistant}} and {{associate professor in the}} Department of Computer Science at the University of Virginia's School of Engineering and Applied Science from 1988 until 1997. While there, he completed sabbaticals at Walt Disney Imagineering and Electronic Arts (EA). In 1997, Pausch became Associate Professor of Computer Science, <b>Human-Computer</b> <b>Interaction,</b> and Design at Carnegie Mellon University. In 1998, he was a co-founder, along with Don Marinelli, of CMU's Entertainment Technology Center (ETC), and he started the Building Virtual Worlds course at CMU, which he taught for 10 years. He consulted with Google on user interface design and also consulted with PARC, Imagineering, and Media Metrix. Pausch is also the founder of the Alice software project. He received the National Science Foundation Presidential Young Investigator Award and was a Lilly Foundation Teaching Fellow. Pausch was the author or co-author of five books and over 70 articles.|$|E
5000|$|... #Subtitle level 3: Center for Empathic <b>Human-Computer</b> <b>Interactions</b> (CEHCI) ...|$|R
2500|$|Carroll, John M. [...] Making Use: Scenario-Based Design of <b>Human-Computer</b> <b>Interactions.</b> MIT Press, 2000.|$|R
50|$|Computer {{software}} performance, particularly {{software application}} response time, is {{an aspect of}} software quality that is important in <b>human-computer</b> <b>interactions.</b>|$|R
5|$|The Electronic Delay Storage Automatic Calculator (EDSAC) {{mainframe}} computer {{was built in}} the University of Cambridge's Mathematical Laboratory between 1946 and 6 May 1949, when it ran its first program, and remained in use until 11 July 1958. The EDSAC {{was one of the first}} stored-program computers, with memory that could be read from or written to, and filled an entire room; it included three 35×16 dot matrix cathode ray tubes (CRTs) to graphically display the state of the computer's memory. As a part of a thesis on <b>human-computer</b> <b>interaction,</b> Alexander S. Douglas, a doctoral candidate in mathematics at the university, used one of these screens to portray other information to the user; he chose to do so via displaying the current state of a game.|$|E
5|$|OXO or Noughts and Crosses is a {{video game}} {{developed}} by A S Douglas in 1952 for the Electronic Delay Storage Automatic Calculator (EDSAC) computer, which simulates a game of noughts and crosses. It {{was one of the}} first games developed in the early history of video games. Douglas programmed the game as part of a thesis on <b>human-computer</b> <b>interaction</b> for the University of Cambridge. The EDSAC {{was one of the first}} stored-program computers, with memory that could be read from or written to, and had three small cathode ray tube screens to display the state of the memory; Douglas re-purposed one screen to demonstrate portraying other information to the user, such as the state of a noughts and crosses game. After the game served its purpose, it was discarded on the original hardware but later successfully reconstructed. OXO, along with a draughts game by Christopher Strachey completed around the same time, is one of the earliest known games to display visuals on an electronic screen. Under some definitions, it thus may qualify as the first video game, though other definitions exclude it due to its lack of moving or real-time updating graphics.|$|E
5|$|Following the 1947 {{invention}} of the cathode-ray tube amusement device, the earliest known interactive electronic game {{as well as the}} first to use an electronic display, the first true video games were created in the early 1950s. Initially created as technology demonstrations, such as the Bertie the Brain and Nimrod computers in 1950 and 1951, video games also became the purview of academic research. A series of games, generally simulating real-world board games, were created at various research institutions to explore programming, <b>human–computer</b> <b>interaction,</b> and computer algorithms. These include OXO and Christopher Strachey's draughts program in 1952, the first software-based games to incorporate a CRT display, and several chess and checkers programs. Possibly the first video game created simply for entertainment was 1958's Tennis for Two, featuring moving graphics on an oscilloscope. As computing technology improved over time, computers became smaller and faster, and the ability to work on them was opened up to university employees and undergraduate students {{by the end of the}} 1950s. These new programmers began to create games for non-academic purposes, leading up to the 1962 release of Spacewar! as one of the earliest known digital computer games to be available outside a single research institute.|$|E
2500|$|Researchers at the University of Cambridge {{demonstrate}} a virtual [...] "talking head" [...] with realistic emotions, {{which could lead}} to more naturalistic <b>human-computer</b> <b>interactions.</b>|$|R
50|$|The {{various kinds}} of computer-to-computer <b>interactions</b> and <b>human-computer</b> <b>interactions</b> that include liquid {{computing}} are not exclusive to each other; the various type of interactions can be combined.|$|R
50|$|Long {{is seen as}} one of {{the founders}} of the field of <b>human-computer</b> <b>interactions</b> in the UK. In 2010 Journal Interacting with Computers {{published}} a Special Issue Festschrift for John Long.|$|R
5|$|In 1952, Alexander S. Douglas created OXO, a {{software}} program for the Electronic Delay Storage Automatic Calculator (EDSAC) computer, which simulates a game of tic-tac-toe. The EDSAC {{was one of the}} first stored-program computers, with memory that could be read from or written to, and filled an entire room; it included three 35×16 dot matrix cathode ray tubes to graphically display the state of the computer's memory. As a part of a thesis on <b>human–computer</b> <b>interaction,</b> Douglas used one of these screens to portray other information to the user; he chose to do so via displaying the current state of a game. The player entered input using a rotary telephone controller, selecting which of the nine squares on the board they wished to move next. Their move would appear on the screen, and then the computer's move would follow. The game was not available to the general public, and was only available to be played in the University of Cambridge's Mathematical Laboratory, by special permission, as the EDSAC could not be moved. Like other early video games, after serving Douglas's purpose, the game was discarded. Around the same time, Strachey expanded his draughts program for another mainframe computer, the Manchester Mark 1, culminating in a version for the Ferranti Mark 1 in 1952, which had a CRT display. Like OXO, the display was mostly static, updating only when a move was made. OXO and Strachey's draughts program are the earliest known games to display visuals on an electronic screen.|$|E
25|$|The <b>Human-Computer</b> <b>Interaction</b> Institute (HCII) is a {{division}} of the School of Computer Science and {{is considered one of the}} leading centers of <b>human-computer</b> <b>interaction</b> research, integrating computer science, design, social science, and learning science. Such interdisciplinary collaboration is the hallmark of research done throughout the university.|$|E
25|$|The School {{is one of}} {{a handful}} that offer degrees in <b>Human-Computer</b> <b>Interaction.</b> The School offers master's degrees in <b>Human-Computer</b> <b>Interaction</b> Design, Music Informatics, Bioinformatics, Chemical Informatics, Security Informatics, and Computer Science, and Ph.D. degrees in Computer Science and in Informatics. Specialization areas for the Ph.D. in Computer Science include {{artificial}} intelligence, databases, distributed systems, formal methods, high-performance computing, programming languages, and security. The Informatics Ph.D. program offers tracks in bioinformatics, cheminformatics, complex systems, <b>human-computer</b> <b>interaction</b> design, logic and mathematical foundations of informatics, music informatics, security informatics, and social informatics.|$|E
30|$|AKT is a PhD {{student at}} the chair of {{cognitive}} psychology and cognitive ergonomics at the Technische Universität of Berlin. Her research interests include applying cognitive psychology to <b>human–computer</b> <b>interactions</b> and understanding how users evaluate experiences with technical devices.|$|R
40|$|The {{learning}} environment {{based on the}} KINECT Motion Sensing technology is able to fully mobilize the learners' multi-sensory organs, closely combine study with sports and enhance <b>human-computer</b> <b>interactions,</b> which can be conducive to the learners' health, greatly increase the relishes of learning and promote effective learning in the game, and finally compensate for the shortage of <b>human-computer</b> <b>interactions</b> in the traditional mouse and keyboard mode. The article elaborates on the KINECT Motion Sensing Technology and its educational applications status by analyzing its effective supports for game-oriented studying environment, based on which the article establishes a game-oriented {{learning environment}}. Eventually the article reveals an applicable case of game-oriented teaching and learning as a reference for related researches...|$|R
5000|$|On his website, Callas {{describes}} himself as [...] "an entrepreneur and innovator in information and business security, including cryptography, operating system security, public key infrastructure, and intellectual property rights," [...] as well as [...] "an innovator in <b>human-computer</b> <b>interactions,</b> collaboration and social virtual reality." ...|$|R
25|$|Dourish, P. and Anderson, K. 2006. Collective Information Practice: Exploring Privacy and Security as Social and Cultural Phenomena. <b>Human-Computer</b> <b>Interaction,</b> 21(3), 319-342.|$|E
25|$|In 2004, Reddy {{received}} the Okawa Prize for pioneering researches of large-scale artificial intelligence system, <b>human-computer</b> <b>interaction</b> and Internet, and outstanding contributions to information and telecommunications policy and nurture of many human resources.|$|E
25|$|Mynatt {{has taught}} courses in <b>Human-Computer</b> <b>Interaction,</b> Everyday Computing, Mobile and Ubuquitous Computing, and Media Computation. For seven years (2000–07) {{she played a}} {{leadership}} role in the design and management of two new programs: the Ph.D. in Human-Centered Computing and the M.S. program in <b>Human-Computer</b> <b>Interaction.</b> For the HCC Ph.D. program, she co-chaired the first formative committee that charted the possibilities for a new human-centric Ph.D. program, and directed the HCC program from its inception until the fall of 2006. She has published over 100 book chapters, conference publications, and journal articles in top tier locations such as ACM SIGCHI, CSCW, Ubicomp, and Pervasive.|$|E
40|$|Researchers in <b>human-computer</b> <b>interactions</b> {{know that}} {{software}} {{can easily be}} instrumented to create a trace of user events 2 in the interface (which we call a log file) for later analysis. Using these data for studying usability or other HCI questions is certainly attractive. • The data are cheap – data gathering is totally automated...|$|R
50|$|A typical {{example for}} an {{organization}} behaving as CAS, is Wikipedia - collaborated and managed by a loosely organized management structure, composed of a complex mix of <b>human-computer</b> <b>interactions.</b> By managing behavior, and not only mere content, Wikipedia uses simple rules to produce a complex, evolving knowledge base which has largely replaced older sources in popular use.|$|R
40|$|Addressing {{problems}} through online <b>human-computer</b> <b>interactions,</b> {{referred to}} broadly as crowdsourcing, {{has led to}} emerging platforms for massive design creation such as the 3 D Warehouse and the Build with Chrome project. From a design research perspective, crowd-sourced design creations and evaluations {{provide an opportunity to}} learn and model quantitatively how humans deal with design problems. Thi...|$|R
25|$|On {{a broader}} level, {{cognitive}} science is an interdisciplinary enterprise of cognitive psychologists, cognitive neuroscientists, researchers in artificial intelligence, linguists, <b>human–computer</b> <b>interaction,</b> computational neuroscience, logicians and social scientists. Computer simulations are sometimes used to model phenomena of interest.|$|E
25|$|Scratch input, an acoustic-based {{method of}} <b>Human-Computer</b> <b>Interaction</b> (HCI) that takes {{advantage}} of the characteristic sound produced when a finger nail, stick, or other object strikes or is dragged over a surface, such as a table or wall.|$|E
25|$|The US News and World Report ranks Bren School as 29th in the United States for Computer Science , and 14th {{in public}} {{university}} programs. Among some ICS subareas, {{the school is}} ranked 4th in <b>human-computer</b> <b>interaction,</b> 9th in software engineering, and 8th in databases.|$|E
30|$|Visual target {{tracking}} (VTT) [1 – 15] {{is a key}} enabling technology for numerous emerging computer vision applications including video surveillance, navigation, <b>human-computer</b> <b>interactions,</b> augmented reality, higher level scene understanding, and action recognition among many others. It is a challenging task because the visual observations often suffer from interference due to occlusion, scale and shape variation, illumination variation, background clutter, and related factors.|$|R
40|$|We present {{current and}} envisaged {{work on the}} AVEIRO project of our {{research}} group concerning virtual environments inhabited by autonomous embodied agents. These environments are being built for researching issues in <b>human-computer</b> <b>interactions</b> and intelligent agent applications. We describe the various strands {{of research and development}} that we are focussing on. The undertaking involves the collaborative effort of researchers from different disciplines...|$|R
40|$|In {{cognitive}} neuroscience {{the sense of}} agency {{is defined as the}} as the experience of controlling ones own actions and, through this control, affecting the external world. At CHI 2012 I presented a paper entitled I did that! Measuring Users Experience of Agency in their own Actions [1]. This extended abstract draws heavily on that paper, which described an implicit measure called intentional binding. This measure, developed by researchers in {{cognitive neuroscience}}, has been shown to provide a robust implicit measure for the sense of agency. My interest in intentional binding stemmed from prior HCI literature, (e. g. the work of Shneiderman) which emphasises the importance of the sense of control in <b>human-computer</b> <b>interactions.</b> The key question behind the CHI 2012 paper was: can we apply intention binding to provide an implicit measure for the experience of control in <b>human-computer</b> <b>interactions?</b> In investigating this question, replication was a key element of the experimental process. Comment: 4 pages, presented at RepliCHI 2013 at ACM CHI 201...|$|R
25|$|GroupLens Research is a <b>human–computer</b> <b>interaction</b> {{research}} lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems and online communities. GroupLens also works with mobile and ubiquitous technologies, digital libraries, and local geographic information systems.|$|E
25|$|Brent Hecht {{joined the}} GroupLens faculty in 2013, {{focusing}} on geographic <b>human-computer</b> <b>interaction.</b> Lana Yarosh joined the GroupLens faculty in 2014; {{she works with}} social computing and child-computer interaction. A third professor, Haiyi Zhu, joined in 2015. Haiyi has published research on Facebook and other social networks.|$|E
25|$|It {{is a very}} {{important}} and challenging problem to track and understand the behavior of agents through videos taken by various cameras. The primary technique employed is computer vision. Vision-based activity recognition has found many applications such as <b>human-computer</b> <b>interaction,</b> user interface design, robot learning, and surveillance, among others.|$|E
40|$|Hands play a {{key role}} in <b>human-computer</b> <b>interactions.</b> Thus, this paper proposes a hand shape {{recognition}} method for implementing hand-based interfaces. The proposed method works robustly in real-time because it is based on simple but effective algorithms. It does not require additional equipments such as markers or sensors which may disturb user immersion. Also, since it recognizes both hands, it can provide us with natural two-handed interactions...|$|R
40|$|Relational {{agents are}} {{computational}} artifacts designed to build long-term, social-emotional {{relationships with their}} users. In this paper we argue that subtle expressivity is especially crucial in <b>human-computer</b> <b>interactions</b> with relational agents in which social tasks such as relationship building or negotiation are being performed. We discuss these issues {{in the context of}} a relational agent designed to interact repeatedly with users during a one-month exercise adoption program...|$|R
50|$|Autocomplete {{speeds up}} <b>human-computer</b> <b>interactions</b> when it {{correctly}} predicts the word a user intends to enter {{after only a}} few characters have been typed into a text input field. It works best in domains with a limited number of possible words (such as in command line interpreters), when some words are much more common (such as when addressing an e-mail), or writing structured and predictable text (as in source code editors).|$|R
