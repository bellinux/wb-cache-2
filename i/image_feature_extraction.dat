297|10000|Public
5000|$|Haralick's work {{in shape}} {{analysis}} and extraction uses {{the techniques of}} mathematical morphology. [...] He has developed the morphological sampling theorem which establishes a sound shape/size basis for {{the focus of attention}} mechanisms which can process image data in a multiresolution mode, thereby making some of the <b>image</b> <b>feature</b> <b>extraction</b> processes execute more efficiently. He has also developed recursive morphological algorithms for the computation of opening and closing transforms. The recursive algorithms permit all possible sized openings or closings for a given structuring element to be computed in constant time per pixel. He also developed statistical morphological methodologies for image analysis and noise removal. and noise removal ...|$|E
50|$|To {{illustrate}} the feasibility and capability of QIP algorithms and application, researchers always prefer {{to simulate the}} digital image processing tasks {{on the basis of}} the QIRs that we already have. By using the basic quantum gates and the aforementioned operations, so far, researchers have contributed to quantum <b>image</b> <b>feature</b> <b>extraction,</b> quantum image segmentation, quantum image morphology, quantum image comparison, quantum image filtering, quantum image classification, quantum image stabilization, among others. In particular, QIMP-based security technologies have attracted extensive interest of researchers as presented in the ensuing discussions. Similarly, these advancements have led to many applications in the areas of watermarking, encryption, and steganography etc., which form the core security technologies highlighted in this area.|$|E
50|$|Scale co-occurrence matrix (SCM) is {{a method}} for <b>image</b> <b>feature</b> <b>extraction</b> within scale space after wavelet transformation, {{proposed}} by Wu Jun and Zhao Zhongming (Institute of Remote Sensing Application, China). In practice, we first do discrete wavelet transformation for one gray image and get sub images with different scales. Then we construct a series of scale based concurrent matrixes, every matrix describing the gray level variation between two adjacent scales. Last we use selected functions (such as Harris statistical approach) to calculate measurements with SCM and do feature extraction and classification. One basis of the method is the fact: way texture information changes from one scale to another can represent that texture in some extent thus {{it can be used}} as a criterion for feature extraction. The matrix captures the relation of features between different scales rather than the features within a single scale space, which can represent the scale property of texture better. Also, there are several experiments showing that it can get more accurate results for texture classification than the traditional texture classification.|$|E
30|$|According to {{the types}} of {{features}} extracted from brain <b>images,</b> <b>feature</b> <b>extraction</b> methods can be roughly grouped into voxel-based, vertex-based, and ROI-based ones [38].|$|R
30|$|Comparative {{analysis}} of BRISK and ORB algorithm {{in the same}} scale rotating 90 ° <b>image</b> <b>feature</b> point <b>extraction</b> and different scale scaling 50 % and rotating 90 ° <b>image</b> <b>feature</b> point <b>extraction</b> time, <b>feature</b> point <b>extraction</b> number, accuracy, etc.|$|R
40|$|Precise fundus <b>image</b> <b>features</b> {{detection}} is {{an important}} factor for screening diabetic retinopathy. Some noises in fundus <b>image</b> <b>features</b> <b>extraction</b> need to be solved. This paper studies using phase information to attempt get better effect. We use and compare four phase-based approaches and get some instructive results...|$|R
40|$|There is {{provided}} a near duplicate video detection system. The system includes (a) a video clip acquisition module arranged {{to produce a}} video clip in machine readable data format defining a plurality of frames, (b) an image feature extractor in communication with the video clip acquisition module arranged to perform <b>image</b> <b>feature</b> <b>extraction</b> in respect of the frames and produce corresponding <b>image</b> <b>feature</b> <b>extraction</b> data in electronic format, (c) a feature vector generator in communication with the image feature extractor arranged to process the <b>image</b> <b>feature</b> <b>extraction</b> data to produce feature vector data in an electronic format corresponding {{to each of the}} frames, and (d) a summarization module responsive to the feature vector generator and arranged to convert the feature vector data into a summarization of the video clip in machine readable format...|$|E
30|$|Manyi Wu {{was born}} in 1983 and a Doctoral {{graduate}} student of Wuhan University, mainly concerned with UAV image processing and <b>image</b> <b>feature</b> <b>extraction.</b>|$|E
40|$|Abstract. <b>Image</b> <b>feature</b> <b>extraction</b> is an {{important}} technology in image matching and retrieval. For the problem of high computational complexity of spatial domain <b>image</b> <b>feature</b> <b>extraction</b> using the SIFT algorithm, and by studying the relationship between DCT coefficient matrix and image, the paper designed the DCT coefficients reduced matrix of image and proposed the algorithm of SIFT feature extraction in DCT domain reduced image. Experiments showed that with the low loss of accuracy in image matching and retrieval, the method proposed can significantly improve the computational efficiency of feature extraction...|$|E
40|$|In {{computer}} vision {{all of the}} existing researches are interested in synthetic <b>images</b> <b>features</b> <b>extraction.</b> Theses <b>images</b> contain many types of features. Indeed, the features are classified in 1 D feature (step, roof…) and 2 D features (corners). Nevertheless, some approaches interest {{in the study of}} real images. Moreover, the satellite images are one most complex real image. It presents a widespread real application (weather, military…). Accordingly, many researches are developed in this way. The satellite images present a great variety of features due to the trouble what returns their treatment is little delicate. In this paper, we introduce a new application of phase congruency model for <b>features</b> <b>extraction</b> in satellite <b>images.</b> The aim {{of this paper is to}} exploit the advantages and the limitations of this model applied in satellite <b>images</b> <b>features</b> <b>extraction.</b> On the other hand, two smoothing algorithms are used to improve the <b>features</b> <b>extraction</b> procedure. Key words: Satellite images, phase congruency model, smoothing algorith...|$|R
40|$|A {{pre-processing}} {{technique for}} <b>image</b> <b>features</b> <b>extraction</b> {{is presented in}} the paper. It is based on algebraic properties of image transform # that are invariant to a given geometrical transformation of an image. A vector of digital images is introduced. Image invariant is represented by a family of linear maps R...|$|R
30|$|S. Nithya {{received}} a B.E. degree in Information Technology from Avinashilingam Deemed University, Coimbatore, in 2004 and an M.E. degree in Computer Science and Engineering from Anna University, Chennai, in 2009 and is pursuing her Ph.D. in Anna University, Chennai. Her {{area of interest}} includes analysis of <b>images,</b> <b>feature</b> <b>extraction,</b> and texture classification.|$|R
40|$|Anisotropic {{diffusion}} is {{a powerful}} method for <b>image</b> <b>feature</b> <b>extraction</b> in which blurring is allowed to occur except at edges. Mean field annealing (MFA) is an image optimization technique {{which is used to}} find the best estimation of a blurred, noisy corrupted image. In this paper, we will show that MFA is versatile enough to be used for <b>image</b> <b>feature</b> <b>extraction</b> as well. Furthermore, the two major problems in anisotropic diffusion (white noise and geometric interpretation) can be solved by few modifications of the MFA equation. Finally, experiments and results will be presented. 1...|$|E
40|$|In this paper, a novel image {{projection}} {{analysis method}} (UIPDA) is first developed for <b>image</b> <b>feature</b> <b>extraction.</b> In contrast to Liu's projection discriminant method, UIPDA has the desirable property that the projected feature vectors are mutually uncorrelated. Also, a new LDA technique called EULDA is presented for further feature extraction. The proposed methods are tested on the ORL and the NUST 603 face databases. The experimental results demonstrate that: (i) UIPDA {{is superior to}} Liu's projection discriminant method and more efficient than Eigenfaces and Fisherfaces; (ii) EULDA outperforms the existing PCA plus LDA strategy; (iii) UIPDA plus EULDA is a very effective two-stage strategy for <b>image</b> <b>feature</b> <b>extraction.</b> Department of Computin...|$|E
30|$|Image {{classification}} {{is one of}} the hot research {{directions in}} computer vision field, and it is also the basic image classification system in other image application fields, which is usually divided into three important parts: image preprocessing, <b>image</b> <b>feature</b> <b>extraction</b> and classifier.|$|E
40|$|The aim of {{this work}} is to develop new method for <b>feature</b> <b>extraction</b> from MRI <b>images</b> based on Karhunen-Loeve {{transform}}. Application of Karhunen-Loeve transform for multidimensional MRI <b>images</b> <b>feature</b> <b>extraction</b> is presented. The main result of this work {{is that the first}} basis function has the major contribution into decomposition of MRI picture, the next basis functions contributions are decreasing with their number. Recommendations for <b>feature</b> <b>extraction</b> using proposed approach for diagnosis and classification of brain diseases are given. ?????? ????????? ?????????? ?????????????? ????????-????? ??? ??????? ???-???????????. ??????????? ????????? ??? ?????????? ??? ??????????? ???????????. ???????? ??????????? ?????????????? ????????-????? ??? ????????? ????????? ???-???????????. ???????????, ??? ?????????? ????? ????? ?????? ???????? ???????. ????????? ???????????? ?????????? ????????? ??????? ????????? ????????? ??? ????????????? ? ??????????? ???????????, ??????? ?????? ?? ???????? ????? ????????...|$|R
40|$|<b>Image</b> segmentation, <b>feature</b> <b>extraction</b> and <b>image</b> {{components}} classification form {{a fundamental}} problem in many applications of multi-dimensional signal processing. The paper {{is devoted to}} the use of Wavelet transform for <b>feature</b> <b>extraction</b> associated with <b>image</b> pixels and their classification in comparison with the watershed transform. A specific attention is paid to the use of Haar transform as a tool for image compression and <b>image</b> pixels <b>feature</b> <b>extraction.</b> Proposed algorithm is verified for simulated images and applied for a selected MR biomedical image processing in the MATLAB environment. ...|$|R
30|$|<b>Image</b> <b>feature</b> point <b>extraction</b> and {{matching}} {{is a very}} important technical link in image processing. Image matching, image stitching, 3 D (three dimension) modeling and other technical implementations rely on <b>image</b> <b>feature</b> point <b>extraction</b> {{and matching}}. After years of in-depth research and application practice, the algorithm for <b>feature</b> point <b>extraction</b> and description is constantly improving and perfecting. It has a wide range of applications in image matching [1, 2], image retrieval [3, 4], image recognition [5 – 7], video data tracking [8], image stitching [9], image classification [10], and many other aspects.|$|R
40|$|An <b>image</b> <b>feature</b> <b>extraction</b> method {{based on}} the twodimensional (2 -D) mel cepstrum is introduced. The concept of onedimensional mel cepstrum, which is widely used in speech recognition, is {{extended}} to 2 -D in this article. The feature matrix resulting from the 2 -D mel-cepstral analysis are applied to the support-vector-machine classifier with multi-class support to test {{the performance of the}} mel-cepstrum feature matrix. The AR, ORL, and Yale face databases are used in experimental studies, which indicate that recognition rates obtained by the 2 -D mel-cepstrum method are superior to the recognition rates obtained using 2 -D principal-component analysis and ordinary image-matrixbased face recognition. Experimental results show that 2 -D mel-cepstral analysis can also be used in other <b>image</b> <b>feature</b> <b>extraction</b> problems. © 2010 SPIE...|$|E
40|$|An {{interactive}} {{method of}} <b>image</b> <b>feature</b> <b>extraction</b> based on B-Spline curves is proposed. B-Splines are piecewise polynomial curves that are {{guided by a}} sequence of points called the control points. The proposed method differs from traditional one in that the features of an image are extracted automatically according to a limited sequence of control points inserted by user in an interactive way, and the extracted image features are described {{as a series of}} B-Spline curves. Consequentially, the analysis of image features becomes easy and effective because of the specific properties of the B-Spline curves, {{and at the same time}} a significant data compression is achieved. An <b>image</b> <b>feature</b> <b>extraction</b> software package based on the proposed method has been realized in C language...|$|E
40|$|Understanding and {{modeling}} {{the function of}} the neurons and neural systems are primary goal of systems neuroscience. Sparse coding theory demonstrates that the neurons in primary visual cortex form a sparse representation of natural scenes in the viewpoint of statistics. In this paper, we propose a novel sparse coding model based on structural similarity (SS_SC) for natural <b>image</b> <b>feature</b> <b>extraction.</b> The advantage for our model {{is to be able to}} preserve structural information from a scene, which human visual perception is highly adapted for. Using the proposed sparse coding model, the validity of <b>image</b> <b>feature</b> <b>extraction</b> is testified. Furthermore, compared with standard sparse coding (SC) model, the experimental results show that the quality of reconstructed images obtained by our method outperforms the SC method. Index Terms — Natural image, sparse coding, structura...|$|E
40|$|This study {{presents}} a novel algorithm {{to recognize a}} set of static hand gestures for the Human-Computer Interaction (HCI), based on hand segmentation using both wavelet network for <b>images</b> <b>feature</b> <b>extraction,</b> and supervised feed-forward neural network with back propagation training algorithm for recognition. One hundred and twenty hand gesture images were used for training and 60 for testing. The best classification rate of 97 % was obtained for the testing set...|$|R
40|$|In today’s world, {{biometrics}} {{system is}} used everywhere {{for the security}} and personal identification. Palmprint {{is a very important}} type of biometrics and it is used mostly in forensic applications. In this paper, high resolution palmprint <b>images</b> are used, <b>feature</b> <b>extraction</b> and matching steps are developed such as system is simple, more accurate and faster. Minutiae Cylindrical code is used for matching purpose. Palmprint recognition is difficult task because of size of large images. For high security applications high resolution palmprints are needed from which more extra information can be extracted. This Palmprint recognition system has many steps to common with fingerprint having optimized and specified steps to process large sized palmprint <b>images.</b> <b>Feature</b> <b>extraction</b> method is used to detect minutiae followed by local matching algorithm...|$|R
30|$|In {{addition}} to the texture <b>features,</b> the local <b>image</b> <b>features</b> <b>extraction</b> attracting increasing attention in recent years. A visual content descriptor can either be local or global. A local descriptor uses the visual features of regions or objects to describe the image, where as the global descriptor uses the visual features of the whole image. Several local descriptors have been described in the literature [17 – 29], where the local binary pattern (LBP) [17] {{is the most popular}} local feature descriptor.|$|R
40|$|AbstractWe {{propose a}} new photo {{summarization}} system {{that provides the}} user with a summarized view of clustered photos. The summarized view provides the following major functions to the user. It selects a representative photo from each clusters. It detects the noticeable region based on the <b>image</b> <b>feature</b> <b>extraction</b> method system...|$|E
40|$|Across {{all sectors}} of the modern {{information}} economy, large unstructured repositories of data are being aggregated at an ever-increasing rate. This move towards ‘big data ’ has created an enormous demand for techniques to efficiently extract structure from such data sets. Specific contexts for this demand include natural language models for organizing text corpuses, <b>image</b> <b>feature</b> <b>extraction</b> model...|$|E
40|$|This paper {{presents}} {{a new approach}} to <b>image</b> <b>feature</b> <b>extraction</b> which utilizes evolutionary autonomous agents. Image features are often mathematically defined in terms of the gray-level intensity at image pixels. The optimality of <b>image</b> <b>feature</b> <b>extraction</b> is to find all the feature pixels from the image. In the proposed approach, the autonomous agents, being distributed computational entities, operate directly in the two-dimensional lattice of a digital image, and exhibit a number of reactive behaviors. In order to effectively locate the feature pixels, individual agents sense the local stimuli from their image environment by means of evaluating the gray-level intensity of locally connected pixels, and accordingly activate their behaviors. The behavioral repository of the agents consists of: (1) featuremarking at local pixels and self-reproduction of offspring agents in the neighboring regions if the local stimuli are found to satisfy feature conditions, (2) diffusion to adjacent image [...] ...|$|E
25|$|<b>Image</b> pre-processing, and <b>feature</b> <b>extraction</b> and {{classification}} are {{two main}} stages of these CAD algorithms.|$|R
40|$|This thesis {{deals with}} {{automatic}} content-based image classification. The main {{goal of this}} work is implementation of application which is able to perform this task automatically. The solution consists of variable system using local <b>image</b> <b>features</b> <b>extraction</b> and visual vocabulary built by k-means method. Bag Of Words representation {{is used as a}} global <b>feature</b> describing each <b>image.</b> Support Vector Machines - the final component of this system - perform the classification based on this representation. In the last chapter, the results of this experimental system are presented...|$|R
30|$|A 3 D {{reconstruction}} component runs on {{the server}} on a multi-core CPU and GPU. This component generates a 3 D point cloud from the initial base <b>images</b> through <b>feature</b> <b>extraction,</b> matching, and the SfM procedure.|$|R
40|$|Cataloged from PDF {{version of}} article. In this article, an <b>image</b> <b>feature</b> <b>extraction</b> method based on {{two-dimensional}} (2 D) Mellin cepstrum is introduced. The concept of one-dimensional (1 D) mel-cepstrum that {{is widely used}} in speech recognition is extended to two-dimensions using both the ordinary 2 D Fourier transform and the Mellin transform. The resultant feature matrices are applied to two different classifiers such as common matrix approach and support vector machine to test {{the performance of the}} mel-cepstrum- and Mellin-cepstrum-based features. The AR face image database, ORL database, Yale database and FRGC database are used in experimental studies, which indicate that recognition rates obtained by the 2 D mel-cepstrum-based method are superior to that obtained using 2 D principal component analysis, 2 D Fourier-Mellin transform and ordinary image matrix-based face recognition in both classifiers. Experimental results indicate that 2 D cepstral analysis can also be used in other <b>image</b> <b>feature</b> <b>extraction</b> problems...|$|E
40|$|In this paper, {{we present}} a fast {{parallel}} implementation of an <b>image</b> <b>feature</b> <b>extraction</b> task on Connection Machine CM- 5. We show that, given a 2048 Θ 2048 grey level image as input, the extraction of image features, which includes edge detection, thinning, linking, and linear approximation, can be performed in less than 1. 2 seconds on a partition of CM- 5 having 512 processing nodes. A serial implementation written in C on a Sun Sparc 400 takes more than 8 minutes. Experimental results on various sizes of images using various partitions of CM- 5 are also reported. The software has been developed in a modular fashion to permit various techniques to be employed for the individual steps of the processing. Our technique starts by modeling the communication and computation features of the machine. Using this model, scalable algorithms are designed. 1 Introduction <b>Image</b> <b>feature</b> <b>extraction</b> is a fundamental process in vision. In general terms, the primary task of feature extraction is to ex [...] ...|$|E
40|$|In this article, an <b>image</b> <b>feature</b> <b>extraction</b> method {{based on}} {{two-dimensional}} (2 D) Mellin cepstrum is introduced. The concept of one-dimensional (1 D) mel-cepstrum that {{is widely used}} in speech recognition is extended to two-dimensions using both the ordinary 2 D Fourier transform and the Mellin transform. The resultant feature matrices are applied to two different classifiers such as common matrix approach and support vector machine to test {{the performance of the}} mel-cepstrum- and Mellin-cepstrum-based features. The AR face image database, ORL database, Yale database and FRGC database are used in experimental studies, which indicate that recognition rates obtained by the 2 D mel-cepstrum-based method are superior to that obtained using 2 D principal component analysis, 2 D Fourier-Mellin transform and ordinary image matrix-based face recognition in both classifiers. Experimental results indicate that 2 D cepstral analysis can also be used in other <b>image</b> <b>feature</b> <b>extraction</b> problems. © The Author 2010. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved...|$|E
50|$|A color layout {{descriptor}} (CLD) {{is designed}} to capture the spatial distribution of color in an <b>image.</b> The <b>feature</b> <b>extraction</b> process consists of two parts; grid based representative color selection and discrete cosine transform with quantization.|$|R
40|$|Abstract: Image {{analysis}} forms {{a general}} interdisciplinary area connecting general methods of sig-nal processing and applications in measurement, biomedicine and environmental engineering. The paper {{is devoted to}} selected mathematical methods of <b>image</b> <b>features</b> <b>extraction</b> enabling their reli-able classification invariant to image components rotation. The first methods under study assumes initial image segmentation using watershed transform as a basic method allowing definition of image segments with different features. The following step includes definition of <b>image</b> <b>features</b> necessary for <b>image</b> components classification. This problem is studied {{with the support of}} Radon transform that is able to change texture rotation to its translation followed by an appropriate method of <b>image</b> component <b>feature</b> <b>extraction.</b> The second method presents basic principle of <b>feature</b> based <b>image</b> segmentation using <b>feature</b> vector assigned to all image pixels estimated from their neighbourhood having a selected shape and size. Various statistical methods estimating features of these root pix-els are studied in the paper as well. Proposed methods are verified for simulated images formed by the mixture of different textures and then applied to selected biomedical images. All algorithms are presented in the Matlab environment...|$|R
40|$|Issues {{associated}} with the registration and rectification of remotely sensed data. Near and long range applications research tasks and some medium range technology augmentation research areas are recommended. <b>Image</b> sharpness, <b>feature</b> <b>extraction,</b> inter-image mapping, error analysis, and verification methods are addressed...|$|R
