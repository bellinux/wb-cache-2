55|8|Public
2500|$|The {{advertising}} and marketing campaign for Paranormal State broke new ground. In November 2007, a six-story billboard was erected {{at the corner of}} Prince and Mulberry Streets in New York City by [...] Behind the billboard were two <b>directional</b> <b>audio</b> (or audioSpotlights) which produce a highly focused beam of sound. Passers-by who walked directly {{in the path of the}} sound would hear spooky, disembodied voices whispering suggestive messages such as [...] "What's that?" [...] and [...] "Who's there? It's not your imagination." [...] But someone standing next to that person would hear nothing. The billboard had a dramatic effect on people coming within range of the [...] "cone of sound" [...] created by the <b>directional</b> <b>audio</b> speakers. The billboard was apparently the first commercial use of the technology on a billboard. A video of the installation can be seen here.|$|E
50|$|<b>Directional</b> <b>audio</b> train {{signaling}} may {{be accomplished}} {{through the use}} of an ultrasonic beam which will warn of the approach of a train while avoiding the nuisance of loud train signals on surrounding homes and businesses.|$|E
5000|$|The {{advertising}} and marketing campaign for Paranormal State broke new ground. In November 2007, a six-story billboard was erected {{at the corner of}} Prince and Mulberry Streets in New York City by BlueBlastMedia. Behind the billboard were two <b>directional</b> <b>audio</b> (or audioSpotlights) which produce a highly focused beam of sound. Passers-by who walked directly {{in the path of the}} sound would hear spooky, disembodied voices whispering suggestive messages such as [...] "What's that?" [...] and [...] "Who's there? It's not your imagination." [...] But someone standing next to that person would hear nothing. The billboard had a dramatic effect on people coming within range of the [...] "cone of sound" [...] created by the <b>directional</b> <b>audio</b> speakers. The billboard was apparently the first commercial use of the technology on a billboard. A video of the installation can be seen here.|$|E
5000|$|... and <b>directional</b> high-fidelity {{commercial}} <b>audio</b> systems (Sound from ultrasound) ...|$|R
40|$|The rapid {{expansion}} of the Internet and electronic commerce has encouraged many consumers to buy a variety of products online. However, due to the poor accessibility of online Web sites, visually impaired do not shop online or if they do, they often request help from sighted people. An online store prototype which has shopping features such as product catalogue, shopping cart and payment system was developed for this study. The system also includes a hapticaudio enabled browser to enable the visually impaired to receive force feedback via a haptic device for product evaluation and utilize voice command {{to interact with the}} system. This paper examined and reported results on the feasibility of a design suitable for the visually impaired to navigate, interact and access web content; a multimodal product presentation; and a haptic-audio interface for product evaluation. Some of our qualitative analysis suggests that a three-section product catalogue design with directed dialogue, <b>directional</b> cues, <b>audio</b> information and a haptic-audio enabled browser is feasible for the visually impaired to browse, interact, select and haptically evaluate online products...|$|R
40|$|Localization of {{multiple}} active speakers in natural environments {{with only two}} microphones is a challenging problem. Reverberation degrades performance of speaker localization based exclusively on <b>directional</b> cues. The <b>audio</b> modality alone has problems with localization accuracy while the video modality alone has problems with false speaker activity detections. This paper presents an approach based on audiovisual fusion in two stages. In the first stage, speaker activity is detected based on the audio-visual fusion which can handle false lip movements. In the second stage, a Gaussian fusion method is proposed to integrate the estimates of both modalities. As a consequence, the localization accuracy and robustness compared to the audio/video modality alone is significantly increased. Experimental results in various scenarios confirmed the improved performance of the proposed system...|$|R
50|$|Before 1954, all Tom and Jerry {{cartoons}} {{were produced}} in the standard Academy ratio and format; in 1954 and 1955, some of the output was dually produced in dual versions: one Academy-ratio negative composed for a flat widescreen (1.75:1) format and one shot in the CinemaScope process. From 1955 until {{the close of the}} MGM cartoon studio a year later, all Tom and Jerry cartoons were produced in CinemaScope, some even had their soundtracks recorded in Perspecta <b>directional</b> <b>audio.</b> All of the Hanna and Barbera cartoons were shot as successive color exposure negatives in Technicolor; the 1960s entries were done in Metrocolor. The 1960s entries also returned to the standard Academy ratio and format, too. The 2005 short The Karate Guard was also filmed in the standard Academy ratio and format.|$|E
40|$|The {{purpose of}} this project was to {{construct}} a parametric array of ultrasound sources {{and to use the}} nonlinear interactions of the waves as they propagate in air to generate highly <b>directional</b> <b>audio</b> frequencies. The parametric array consists of ultrasound transducers arranged so that their beams overlap spatially. The ultimate goal of the project was to produce a highly <b>directional</b> <b>audio</b> beam using the difference frequency beam that arises from the nonlinear interaction of the two ultrasonic primary beams. This project was successful in producing highly direction audio frequencies. The difference beam half-power angle was 5. 7 ° at 3 kHz. Complex audio signals were produced, but either at very low acoustic volumes or as a highly distorted signal at higher volumes...|$|E
40|$|<b>Directional</b> <b>audio</b> coding (DirAC) is a {{perceptually}} motivated {{method to}} reproduce spatial sound, which typically uses input from first-order coincident microphone arrays. This article presents {{a method to}} additionally use spaced microphone setups with DirAC. It is shown that since diffuse sound is incoherent between spatially separated microphones at certain frequencies, no decorrelation in DirAC processing is needed, which improves the perceived quality. Furthermore, the directions of sound sources {{are perceived to be}} more accurate and stable...|$|E
40|$|Most camera-based {{systems for}} finding and reading {{barcodes}} {{are designed to}} be used by sighted users (e. g. the Red Laser iPhone app), and assume the user carefully centers the barcode in the image before the barcode is read. Blind individuals could benefit greatly from such systems to identify packaged goods (such as canned goods in a supermarket), but unfortunately in their current form these systems are completely inaccessible because of their reliance on visual feedback from the user. To remedy this problem, we propose a computer vision algorithm that processes several frames of video per second to detect barcodes from a distance of several inches; the algorithm issues <b>directional</b> information with <b>audio</b> feedback (e. g. “left, ” “right”) and thereby guides a blind user holding a webcam or other portable camera to locate and home in on a barcode. Once the barcode is detected at sufficiently close range, a barcode reading algorithm previously developed by the authors scans and reads aloud the barcode and the corresponding product information. We demonstrate encouraging experimental results of our proposed system implemented on a desktop computer with a webcam held by a blindfolded user; ultimately the system will be ported to a camera phone for use by visually impaired users. 1...|$|R
40|$|As {{more and}} more {{retailers}} offer their products for sale online, their web-based content is becoming increasingly visual and complex for visually impaired persons to access, navigate, and interpret when using current accessibility technologies such as screen reader, voice browser and Braille display. This hindered their independence to go online to shop. In this paper, a study on whether visually impaired people can shop online independently is presented. An online store prototype which has shopping features such as shopping cart, product catalogue, online forms and payment system was developed for this purpose. The shopping features were designed to enrich the web-based data with haptic and audio properties. This paper examined and reported results on a website design which could enable the visually impaired to navigate, access, interpret and haptically interact with the web content; and on a product catalogue system which could enable the visually impaired to shop without assistance. Some of our qualitative analysis suggests that a consistent three-section webpage design with static content along {{with the aid of}} <b>directional</b> cues and <b>audio</b> information are feasible to design online shopping website for visually impaired. Also, for effective haptic evaluation of online products, the complete model and different parts of the model should be rendered separately in order to provide the user with a better perception about the product...|$|R
40|$|The 'Virtual Iraq' VR {{environment}} {{is designed to}} be an immersive tool foruse as an Exposure Therapy treatment tool for combat related PTSD. The application consists of a series of virtual scenarios designed to represent relevant contexts for VR exposure therapy, including city and desert road environments. In addition to the visual stimuli presented in the VR HMD, <b>directional</b> 3 D <b>audio,</b> vibrotactile and olfactory stimuli of relevance can be delivered. Stimulus presentation is controlled by the clinician via a separate 'wizard of oz'; interface, with the clinician in full audio contact with the patient. The presentation at the conference will detail the results of our research and clinical treatment protocols as they stand at that time. Presently, an open clinical trial to evaluate our system’s efficacy for PTSD treatment with military personnel is being conducted at the Naval Medical Center San Diego and at Ft. Lewis, Washington, and a randomized controlled trial comparing VR alone and VRcycloserine is in progress at Emory University. Ten other test sites are now on line between now and the conference addressing a variety of research questions involving assessment of PTSD, physiological markers of the disorder, impact of multiple trauma events, and an fMRI study. Thus far, eight male and female treatment completers (out of 11) at two of the treatment sites have shown clinically significant improvements at posttreatment, with these patients now no longer meeting PTSD criteria. Due to the challenges for treatment of this disorder, we are encouraged by these early results...|$|R
30|$|Despite being {{powerful}} and promising, the above approaches are substantially {{different from the}} application covered in this paper. The reason {{is that they are}} mainly based on a time-frequency analysis of different loudspeaker signals whereas our proposed method takes as input the signals from a small microphone array, which are successfully employed to describe the sound field in one point of the three-dimensional space. Therefore, the proposed method shares more similarities with another spatial sound processing technique known as <b>Directional</b> <b>Audio</b> Coding.|$|E
40|$|A time-frequency-domain {{non-linear}} parametric {{method for}} spatial audio processing is presented here, which can utilize microphone input having directional patterns of any order. The method {{is based on}} dividing the sound field into overlapping or non-overlapping sectors. Local pressure and velocity signals are measured within each sector, and an individual <b>Directional</b> <b>Audio</b> Coding (DirAC) processing is performed for each sector. It is shown, that in certain acoustically complex conditions the sector-based processing enhances the quality compared to traditional first-order DirAC processing...|$|E
30|$|<b>Directional</b> <b>Audio</b> Coding (DirAC) is a {{recently}} proposed method for spatial sound recording and reproduction [9] which shares many similarities with the binaural synthesis technique {{described in this}} paper. In a first analysis stage, DirAC uses typically a B-format microphone to capture the spatial properties of the sound recorded in a given environment (although other alternatives {{can also be used}} [10]). In a second stage, the analyzed spatial features are employed to reproduce the recorded sound again by means of an arbitrary loudspeaker setup. Note that although B-format signals are used, there are substantial differences with conventional Ambisonics reproduction [11].|$|E
40|$|This {{dissertation}} {{focuses on}} the development of novel parametric spatial audio techniques using compact microphone arrays. Compact arrays are of special interest since they can be adapted to fit in portable devices, opening the possibility of exploiting the potential of immersive spatial audio algorithms in our daily lives. The techniques developed in this thesis consider the use of signal processing algorithms adapted for human listeners, thus exploiting the capabilities and limitations of human spatial hearing. The findings of this research are in the following three areas of spatial <b>audio</b> processing: <b>directional</b> filtering, spatial <b>audio</b> reproduction, and direction of arrival estimation.   In directional filtering, two novel algorithms have been developed based on the cross-pattern coherence (CroPaC). The method essentially exploits the directional response of two different types of beamformers by using their cross-spectrum to estimate a soft masker. The soft masker provides a probability-like parameter that indicates whether there is sound present in specific directions. It is then used as a post-filter to provide further suppression of directionally distributed noise at the output of a beamformer. The performance of these algorithms represent a significant improvement over previous state-of-the-art methods.   In parametric spatial audio reproduction, an algorithm is developed for multi-channel loudspeaker and headphone rendering. Current limitations in spatial audio reproduction are related to high inter-channel coherence between the channels, which is common in signal-independent systems, or time-frequency artefacts in parametric systems. The developed algorithm focuses on solving these limitations by utilising two sets of beamformers. The first set of beamformers, namely analysis beamformers, is used to estimate a set of perceptually-relevant sound-field parameters, such as the separate channel energies, inter-channel time differences and inter-channel coherences of the target-output-setup signals. The directionality of the analysis beamformers is defined so that it follows that of typical loudspeaker panning functions and, for headphone reproduction, that of the head-related transfer functions (HRTFs). The directionality of the second set of high audio quality beamformers is then enhanced with the parametric information derived from the analysis beamformers. Listening tests confirm the perceptual benefit of such type of processing.  In direction of arrival (DOA) estimation, histogram analysis of beamforming and active intensity based DOA estimators has been proposed. Numerical simulations and experiments with prototype and commercial microphone arrays show that the accuracy of DOA estimation is improved...|$|R
40|$|The use of stereo {{microphone}} configuration as {{input to}} teleconference application of <b>Directional</b> <b>Audio</b> Coding (DirAC) is presented. DirAC {{is a method}} for spatial sound processing, in which {{the direction of the}} arrival of sound and diffuseness are analyzed, and used for different purposes in reproduction. So far, omnidirectional microphones arranged in an array have been used to generate input signals for one and two-dimensional sound field analysis in DirAC teleconferencing. In this study, the possibility to use domestic stereo microphones with DirAC analysis is investigated. Different methods to derive omnidirectional and dipole signals from stereo microphones for directional analysis are presented, and their applicability is discussed...|$|E
40|$|This article {{presents}} {{a new system}} for estimation the direction of multiple speakers and zooming the sound {{of one of them}} at a time. The proposed system is a combination of two levels; namely, sound source direction estimation, and acoustic zooming. The sound source direction estimation uses so-called the energetic analysis method for estimation the direction of multiple speakers, whereas the acoustic zooming is based on modifying the parameters of the <b>directional</b> <b>audio</b> coding (DirAC) in order to zoom the sound of a selected speaker among the others. Both listening tests and objective assessments are performed to evaluate this system using different time-frequency transforms...|$|E
40|$|This paper {{addresses}} {{the problem of}} <b>directional</b> <b>audio</b> beacon deployment. We describe how these beacons {{can be used on}} mobile robots to produce a system that can self-deploy and aid in disaster recovery efforts. A distributed algorithm that uses explicit communication to coordinate the deployment process is presented. The algorithm employs existing multi-robot task allocation methodologies and a procedure for clustering potential deployment locations in a problem domain-specific manner. Results from a sensor-based multi-robot simulation demonstrate that self-deploying beacons are indeed feasible and have the potential to decrease expected egress time. Furthermore, we show that the implementation is free of simulator-specific anomalies through trials with a group of physical robots...|$|E
40|$|<b>Directional</b> <b>audio</b> coding (DirAC) is a {{parametric}} {{approach for}} the analysis and reproduction of spatial sound. The DirAC parameters, namely direction-of-arrival and diffuseness of sound can be further exploited in modern teleconferencing systems. Based on the directional parameters, we can control a video camera to automatically steer on the active talker. In order to provide consistency between the visual and acoustical cues, the virtual recording position should match the visual movement. In this paper, we present an approach for an acoustical zoom, which provides audio rendering that follows {{the movement of the}} visual scene. The algorithm does not rely on a priori information regarding the sound reproduction system as it operates directly in the DirAC parameter domain...|$|E
40|$|<b>Directional</b> <b>Audio</b> Coding (DirAC) is an {{efficient}} technique {{to capture and}} reproduce spatial sound {{on the basis of}} a downmix audio signal, direction of arrival, and diffuseness of sound. In practice, these parameters are determined using arrays of omnidirectional microphones. The main drawback of such configurations is that the estimates are reliable only in a certain frequency range, which depends on the array size. To overcome this problem and cover large bandwidths, we propose concentric arrays of different sizes. We derive optimal joint estimators for the DirAC parameters with respect to the mean squared error. We address the problem of choosing the optimal array sizes for specific applications such as teleconferencing and we verify our findings with measurements...|$|E
40|$|<b>Directional</b> <b>Audio</b> Coding (DirAC) is an {{efficient}} technique {{to capture and}} reproduce spatial sound {{on the basis of}} a downmix signal and side information, i. e., direction of arrival and diffuseness of the sound field expressed in time-frequency domain. The main drawback of using arrays of omnidirectional microphones to obtain these parameters is that reliable estimates are available only in a certain frequency range, which depends on the aperture. To overcome this problem and cover large audio bandwidths nested microphone arrays can be used. In this paper, we derive optimal estimators which combine the microphone signals to achieve the best possible estimation of the DirAC parameters with respect to the mean squared error...|$|E
40|$|In <b>Directional</b> <b>Audio</b> Coding, {{a spatial}} audio {{technique}} for communications, {{the degree of}} diffuseness of the sound field represents an important parameter. Its estimation is traditionally carried out {{by means of an}} averaging in time domain, which inherently degrades the temporal resolution of the parameter. This is undesired since many relevant signal types, such as speech, are characterised by considerable temporal variability. This contribution proposes and investigates the use of spatial averaging by means of employing multiple sensors to improve the temporal resolution of the diffuseness parameter. The derivation of the spatial correlation function for ideal diffuse sound fields allows to design the sensor array optimally. Simulations and measurements confirm the theoretical results...|$|E
40|$|This thesis details {{real-time}} implementations of sound-field {{analysis and}} perceptually motivated reproduction methods for visualisation and auralisation purposes. For the former, various methods for visualising the relative distribution of sound energy from {{one point in}} space are investigated and contrasted; including a novel reformulation of the cross-pattern coherence (CroPaC) algorithm, which integrates a new side-lobe suppression technique. Whereas for auralisation applications, listening tests were conducted to compare ambisonics reproduction with a novel headphone formulation of the <b>directional</b> <b>audio</b> coding (DirAC) method. The {{results indicate that the}} side-lobe suppressed CroPaC method offers greater spatial selectivity in reverberant conditions compared with other popular approaches, and that the new DirAC formulation yields higher perceived spatial accuracy when compared to the ambisonics method...|$|E
40|$|Spatial audio coding {{techniques}} are fundamental for recording, coding and rendering spatial sound. Especially in teleconferencing, spatial sound reproduction helps {{in making a}} conversation feel more natural reducing the listening effort. However, if the acoustic sources are far from the microphone arrangement, the rendered sound may easily be corrupted by reverberation. This contribution proposes a dereverberation technique, which is integrated efficiently into the parameter domain of <b>Directional</b> <b>Audio</b> Coding (DirAC). Utilizing DirAC's signal model we derive a parametric method to reduce the diffuse portion of the recorded signal. Instrumental quality measures and informal listening tests confirm {{the efficiency of the}} proposed method to render a spatial sound scene less reverberant without introducing noticeable artifacts...|$|E
40|$|Methods for spatial audio {{processing}} {{are becoming}} more important as the variety of multichannel audio applications is permanently increasing. <b>Directional</b> <b>Audio</b> Coding (DirAC) represents a well proven technique to capture and reproduce spatial sound {{on the basis of}} a downmix audio signal and parametric side information, namely direction of arrival and diffuseness of the sound. In addition to spatial audio reproduction, the DirAC parameters can be exploited further. In this paper, we propose a computationally efficient approach to determine the position of sound sources based on DirAC parameters. It is shown that the proposed localization method provides reliable estimates even in reverberant environments. The approach also allows to trade off between localization accuracy and tracking performance of moving sound sources...|$|E
40|$|<b>Directional</b> <b>audio</b> coding (DirAC) {{provides}} an efficient representation of spatial sound using a downmix audio signal and parametric information, namely direction-of-arrival (DOA) and diffuseness of sound. Input to the DirAC analysis are B-format signals, usually obtained via microphone arrays. The DirAC parameter estimation is impaired when phase mismatch between the array sensors occurs. We present an approach for the in situ microphone array calibration solely {{based on the}} DirAC parameters. The algorithm aims at providing consistent parameter estimates rather than matching the sensors explicitly. It does neither require to remove the sensors from the array, nor depend on a priori knowledge such as the array size. We further propose a suitable excitation signal to assure robust calibration in reverberant environments...|$|E
40|$|<b>Directional</b> <b>Audio</b> Coding {{provides}} an efficient description of spatial sound {{in terms of}} few audio downmix signals and parametric side information, namely the direction-of-arrival (DOA) and diffuseness of the sound. This representation allows an accurate reproduction of the recorded spatial sound with almost arbitrary loudspeaker setups. The DOA information can be efficiently estimated with linear microphone arrays by considering the phase information between the sensors. Due to the microphone spacing, the DOA estimates are corrupted by spatial aliasing at higher frequencies affecting the sound reproduction quality. In this paper we propose to consider the signal envelope for estimating the DOA at higher frequencies to avoid the spatial aliasing problem. Experimental {{results show that the}} presented approach has great potential in improving the estimation accuracy and rendering quality...|$|E
40|$|In {{hands-free}} telephony, {{spatial filtering}} techniques are employed to enhance intelligibility of speech. More precisely, these techniques aim at reducing the reverberation {{of the desired}} speech signal and attenuating interferences. Additionally, it is well-known that the spatially separate reproduction of desired and interfering sources enhance intelligibility of speech. For the latter task, <b>Directional</b> <b>Audio</b> Coding (DirAC) {{has proven to be}} an efficient method to capture and reproduce spatial sound. In this contribution, we propose a spatial filtering processing block, which works in the parameter domain of DirAC. Simulation results show that compared to a standard beamformer the novel technique offers significantly higher interference attenuation, while introducing comparably low distortion of the desired signal. Additional subjective tests of speech intelligibility confirm the instrumentally obtained results...|$|E
40|$|The use {{of linear}} {{microphone}} array {{composed of two}} closely spaced omnidirectional microphones as input to teleconference application of <b>Directional</b> <b>Audio</b> Coding (DirAC) is presented. DirAC is a method for spatial sound processing, where {{the direction of the}} arrival of sound and diffuseness are analyzed, and used for different purposes in reproduction. Two-dimensional plane arrays have been used so far to generate input signals for DirAC, in which case it is possible to measure directly two-dimensional sound field. In this study, one-dimensional linear array is used to provide input signals for one-dimensional direction and diffuseness analysis in DirAC. Listening tests are conducted to evaluate the intelligibility of speech with two simultaneous talkers, when the linear array is used in teleconference application...|$|E
40|$|The {{importance}} of telecommunication {{continues to grow}} in our daily lives. An ambitious goal for developers is to provide the most natural means of audio communication by giving users the perception of being located next to each other. MPEG Spatial Audio Object Coding (SAOC) is a technology for coding, transmitting, and interactively reproducing spatial sound scenes on any conventional multi-loudspeaker setup (e. g., ITU 5. 1). This paper describes how <b>Directional</b> <b>Audio</b> Coding (DirAC) {{can be used as}} a recording front end for SAOC-based teleconferencing systems, capturing acoustic scenes and extracting the individual objects (talkers). By introducing a novel DirAC to SAOC parameter transcoder, a highly efficient way of combining both technologies is presented which enables interactive, object-based spatial teleconferencing...|$|E
40|$|The general {{focus of}} this paper {{concerns}} the development of telepresence within intelligent immersive environments. The overall aim {{is the development of}} a system that combines multiple audio and video feeds from geographically dispersed people into a single environment view, where sound appears to be linked to the appropriate visual source on a panoramic viewer based on the gaze of the user. More specifically this paper describes a novel <b>directional</b> <b>audio</b> system for telepresence which seeks to reproduce sound sources (conversations) in a panoramic viewer in their correct spatial positions to increase the realism associated with telepresence applications such as online meetings. The intention of this work is that external attendees to an online meeting would be able to move their head to focus on the video and audio stream from a particular person or group so as decrease the audio from all other streams (i. e. speakers) to a background level. The main contribution of this paper is a methodology that captures and reproduces these spatial audio and video relationships. In support of this we have created a multiple camera recording scheme to emulate the behavior of a panoramic camera, or array of cameras, at such meeting which uses the Chroma key photographic effect to integrate all streams into a common panoramic video image thereby creating a common shared virtual space. While this emulation is only implemented as an experiment, it opens the opportunity to create telepresence systems with selectable real time video and audio streaming using multiple camera arrays. Finally we report on the results of an evaluation of our spatial audio scheme that demonstrates that the techniques both work and improve the users' experience, by comparing a traditional omni <b>directional</b> <b>audio</b> scheme versus selectable directional binaural audio scenarios. © 2013 IEEE...|$|E
40|$|A spatial-sound {{processing}} technique, <b>Directional</b> <b>Audio</b> Coding (DirAC), {{provides a}} parametric {{representation of a}} sound field, containing data of the direction of arrival and the diffuseness in frequency channels depending on time. Such a representation {{can be obtained by}} a directional analysis from a square array of four omnidirectional microphones, which enables reliable direction estimation only within a limited frequency range. This paper proposes inserting a rigid cylinder into the array to cast an acoustic shadow and cause scattering. This produces prominent inter-microphone differences that are utilized in two alternative direction estimation methods, based either on energy gradients or vector quantization, having different computational complexities. Both methods estimate the direction reliably for almost over the entire audible frequency range, which is corroborated with objective measurements and subjective listening tests...|$|E
40|$|Applause-type {{signals are}} known to be {{challenging}} for parametric multichannel coding and spatial audio reproduction techniques. This phenomenon is investigated in the context of <b>directional</b> <b>audio</b> coding (DirAC), and it is found that the artifacts originate from the decorrelator processing of the transients of individual handclaps at the decoder. Commonly the decorrelation causes temporal smearing of the transients, producing prominent artifacts. It is shown that very good audio quality can be obtained with applause signals if the temporal resolution in encoding is high enough to analyze each distinct handclap in the signal separately. An implementation of DirAC for the reproduction of surround sound is shown, which is fine-tuned with special focus on applause signals. In addition the results from formal listening tests showing the subjective quality obtained with two well-known applause recordings are presented...|$|E
40|$|High-quality {{teleconferencing}} systems utilize {{surround sound}} to provide natural communication experience. <b>Directional</b> <b>Audio</b> Coding (DirAC) is an efficient parametric approach {{to capture and}} reproduce spatial sound. It uses a monophonic audio signal together with parametric spatial cue information. For reproduction, multiple loudspeaker signals are determined based on the DirAC stream. To allow for hands-free operation, multichannel acoustic echo control (AEC) has to be employed. Standard approaches apply multichannel adaptive filtering to address this problem. However, computational complexity constraints and convergence issues inhibit practical applications. This paper proposes an efficient combination of AEC and DirAC by explicitly exploiting its parametric sound field representation. The approach suppresses the echo components in the microphone signals solely based on the single channel audio signal used for the DirAC synthesis of the loudspeaker signals...|$|E
40|$|<b>Directional</b> <b>audio</b> coding (DirAC) is {{a recent}} method for spatial audio processing, based on a {{perceptually}} motivated representation of spatial sound. Due to its efficiency, DirAC has already been proposed for spatial audio teleconferencing scenarios. Modern hands-free communication systems usually include beamforming techniques to improve speech intelligibility by suppressing diffuse background noise and interfering sources. In this paper, we propose a novel spatial filtering method which can {{be integrated into the}} DirAC spatial codec. It uses a spectral weighting of the recorded audio signal, where the design of the corresponding spatial filter transfer function is based on the DirAC parameters, i. e., direction-of-arrival and diffuseness of the sound field. Simulation results show that compared to a standard beamformer the novel technique offers significantly higher interference attenuation, while introducing similar distortion of the desired signal...|$|E
