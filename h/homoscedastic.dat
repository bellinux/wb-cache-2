391|0|Public
25|$|The OLS {{estimator}} {{is consistent}} when the regressors are exogenous, and optimal {{in the class}} of linear unbiased estimators when the errors are <b>homoscedastic</b> and serially uncorrelated. Under these conditions, the method of OLS provides minimum-variance mean-unbiased estimation when the errors have finite variances. Under the additional assumption that the errors are normally distributed, OLS is the maximum likelihood estimator.|$|E
2500|$|The Gauss–Markov theorem {{states that}} under the spherical errors {{assumption}} (that is, the errors should be uncorrelated and <b>homoscedastic)</b> the estimator [...] is efficient {{in the class of}} linear unbiased estimators. This is called the best linear unbiased estimator (BLUE). Efficiency should be understood as if we were to find some other estimator [...] which would be linear in y and unbiased, then ...|$|E
5000|$|Two or {{more normal}} distributions, , are <b>homoscedastic</b> if {{they share a}} common {{covariance}} (or correlation) matrix, [...] <b>Homoscedastic</b> distributions are especially useful to derive statistical pattern recognition and machine learning algorithms. One popular example is Fisher's linear discriminant analysis.|$|E
5000|$|They are <b>homoscedastic,</b> that is {{all have}} the same finite variance: [...] and ...|$|E
5000|$|In other words, if {{the model}} errors [...] are <b>homoscedastic,</b> an observation's {{leverage}} score determines {{the degree of}} noise in the model's misprediction of that observation.|$|E
50|$|Alternative estimators {{have been}} {{proposed}} in MacKinnon & White (1985) that correct for unequal variances of regression residuals due to different leverage. Unlike the asymptotic White's estimator, their estimators are unbiased when the data are <b>homoscedastic.</b>|$|E
50|$|Student's t {{test for}} testing {{inclusion}} of a single explanatory variable, or the F test for testing {{inclusion of a}} group of variables, both under the assumption that model errors are <b>homoscedastic</b> and have a normal distribution.|$|E
50|$|This has {{the effect}} of {{standardizing}} the scale of the errors and “de-correlating” them. Since OLS is applied to data with <b>homoscedastic</b> errors, the Gauss-Markov theorem applies, and therefore the GLS estimate is the best linear unbiased estimator for β.|$|E
5000|$|The {{assumption}} of homoscedasticity simplifies mathematical and computational treatment. Serious violations in homoscedasticity (assuming a distribution of data is <b>homoscedastic</b> when {{in reality it}} is heteroscedastic [...] ) may result in overestimating the goodness of fit {{as measured by the}} Pearson coefficient.|$|E
50|$|F {{test for}} use {{when there are}} {{replicated}} observations, so that a comparison can be made between the lack-of-fit sum of squares and the pure error sum of squares, {{under the assumption that}} model errors are <b>homoscedastic</b> and have a normal distribution.|$|E
50|$|One {{instance}} in which robust estimation should be considered is {{when there is a}} strong suspicion of heteroscedasticity. In the <b>homoscedastic</b> model, it is assumed that the variance of the error term is constant for all values of x. Heteroscedasticity allows the variance to be dependent on x, which is more accurate for many real scenarios. For example, the variance of expenditure is often larger for individuals with higher income than for individuals with lower incomes. Software packages usually default to a <b>homoscedastic</b> model, even though such a model may be less accurate than a heteroscedastic model. One simple approach (Tofallis, 2008) is to apply least squares to percentage errors as this reduces the influence of the larger values of the dependent variable compared to ordinary least squares.|$|E
5000|$|In statistics, a {{sequence}} or a vector of random variables is <b>homoscedastic</b> [...] if all random {{variables in the}} sequence or vector have the same finite variance. This {{is also known as}} homogeneity of variance. The complementary notion is called heteroscedasticity. The spellings homoskedasticity and heteroskedasticity are also frequently used.|$|E
50|$|The OLS {{estimator}} {{is consistent}} when the regressors are exogenous, and optimal {{in the class}} of linear unbiased estimators when the errors are <b>homoscedastic</b> and serially uncorrelated. Under these conditions, the method of OLS provides minimum-variance mean-unbiased estimation when the errors have finite variances. Under the additional assumption that the errors are normally distributed, OLS is the maximum likelihood estimator.|$|E
5000|$|The Gauss-Markov theorem {{states that}} under the spherical errors {{assumption}} (that is, the errors should be uncorrelated and <b>homoscedastic)</b> the estimator [...] is efficient {{in the class of}} linear unbiased estimators. This is called the best linear unbiased estimator (BLUE). Efficiency should be understood as if we were to find some other estimator [...] which would be linear in y and unbiased, then ...|$|E
50|$|A {{mixture of}} two normal {{distributions}} has five parameters to estimate: the two means, the two variances and the mixing parameter. A mixture of two normal distributions with equal standard deviations is bimodal only if their means differ {{by at least}} twice the common standard deviation. Estimates of the parameters is simplified if the variances can be assumed to be equal (the <b>homoscedastic</b> case).|$|E
5000|$|If [...] is an {{ordinary}} least squares estimator in the classical linear regression model (that is, with normally distributed and <b>homoscedastic</b> error terms), and if the true value of parameter β is equal to β0, then the sampling distribution of the t-statistic is the Students t-distribution with (n − k) degrees of freedom, where n {{is the number of}} observations, and k is the number of regressors (including the intercept).|$|E
5000|$|Heteroscedasticity-consistent {{standard}} errors (HCSE), while still biased, improve upon OLS estimates. [...] HCSE is a consistent estimator of {{standard errors}} in regression models with heteroscedasticity. This method corrects for heteroscedasticity without altering {{the values of}} the coefficients. This method may be superior to regular OLS because if heteroscedasticity is present it corrects for it, however, if the data is <b>homoscedastic,</b> the standard errors are equivalent to conventional standard errors estimated by OLS. Several modifications of the White method of computing heteroscedasticity-consistent standard errors have been proposed as corrections with superior finite sample properties.|$|E
5000|$|Given {{an equal}} (50/50) mixture of two normal {{distributions}} {{with the same}} standard deviation and different means (<b>homoscedastic),</b> the overall distribution will exhibit low kurtosis relative to a single normal distribution - {{the means of the}} subpopulations fall on the shoulders of the overall distribution. If sufficiently separated, namely by twice the (common) standard deviation, so [...] these form a bimodal distribution, otherwise it simply has a wide peak. The variation of the overall population will also be greater than the variation of the two subpopulations (due to spread from different means), and thus exhibits overdispersion relative to a normal distribution with fixed variation [...] though it will not be overdispersed relative to a normal distribution with variation equal to variation of the overall population.|$|E
5000|$|In statistics, the Gauss-Markov theorem, {{named after}} Carl Friedrich Gauss and Andrey Markov, states {{that in a}} linear {{regression}} model in which the errors have expectation zero and are uncorrelated and have equal variances, the best linear unbiased estimator (BLUE) of the coefficients is given by the ordinary least squares (OLS) estimator, provided it exists. Here [...] "best" [...] means giving the lowest variance of the estimate, as compared to other unbiased, linear estimators. The errors {{do not need to}} be normal, nor do they need to be independent and identically distributed (only uncorrelated with mean zero and <b>homoscedastic</b> with finite variance). The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the James-Stein estimator (which also drops linearity) or ridge regression.|$|E
5000|$|Suppose {{there is}} a {{sequence}} of random variables [...] and a sequence of vectors of random variables, [...] In dealing with conditional expectations of Yt given Xt, the sequence {Yt}t=1n {{is said to be}} heteroscedastic if the conditional variance of Yt given Xt, changes with t. Some authors refer to this as conditional heteroscedasticity to emphasize {{the fact that it is}} the sequence of conditional variances that changes and not the unconditional variance. In fact, it is possible to observe conditional heteroscedasticity even when dealing with a sequence of unconditional <b>homoscedastic</b> random variables; however, the opposite does not hold. If the variance changes only because of changes in value of X and not because of a dependence on the index t, the changing variance might be described using a scedastic function.|$|E
5000|$|Bienaymé criticized Poisson's [...] "law {{of large}} numbers" [...] and was {{involved}} in a controversy with Cauchy. Both Bienaymé and Cauchy published regression methods at about the same time. Bienaymé had generalized the method of ordinary least squares. The dispute within the literature was over the superiority of one method over the other. It is now known that ordinary least squares is the best linear unbiased estimator provided errors are uncorrelated and <b>homoscedastic.</b> At the time, this was not known. Cauchy developed the Cauchy distribution to show a case where the method of ordinary least squares resulted in a perfectly inefficient estimator. This {{is due to the fact}} that the Cauchy distribution has no defined variance to minimize. This is the first direct appearance of the Cauchy distribution in the academic literature. The curve had been previously studied by others, though in the English language as the Witch of Agnesi.|$|E
5000|$|Using {{graphical}} tools, {{the potential}} multi-modality of n [...] {2, 3} mixtures is demonstrated; in particular it is {{shown that the}} number of modes may exceed n and that the modes may not be coincident with the component means. For two components they develop a graphical tool for analysis by instead solving the aforementioned differential with respect to w1 and expressing the solutions as a function Π(α), α ∈ 1 so that the number and location of modes for a given value of w1 corresponds to the number of intersections of the graph on the line Π(α) [...] w1. This in turn can be related to the number of oscillations of the graph and therefore to solutions of [...] leading to an explicit solution for a two component <b>homoscedastic</b> mixture given bywhere dM(μ1, μ2, Σ) [...] (μ2 − μ1)TΣ−1(μ2 − μ1) is the Mahalanobis distance.|$|E
30|$|M is {{not known}} exactly; and the error {{distribution}} may be neither Gaussian nor perfectly <b>homoscedastic.</b>|$|E
30|$|Note {{that the}} limits in (7) are valid {{regardless}} of whether y_t is <b>homoscedastic</b> or heteroscedastic.|$|E
40|$|The inferences for {{the order}} {{statistics}} for normal random variables {{with a general}} correlation structure, where correlations can be unequal or equal, positive or negative are discussed in this thesis. Specifically, based on a small correlations approach, we, first, develop the joint density function of the order statistics under the general correlation set-up. We. then, provide an approximation for the distribution of a single order statistic under the same correlation set-up. Special attention {{is given to the}} derivations for the distributions of the maxima and minima. The computational aspects of the distribution of the maxima, for example, are discussed in details for the <b>homoscedastic</b> equi-correlation, <b>homoscedastic</b> unequal correlations, and heteroscedastic unequal correlations cases. The applications of the proposed small correlations approach to compute the percentile points of the maxima are shown for the <b>homoscedastic</b> correlated normal variables following a stationary auto-regressive process of order one, and for the heteroscedastic correlated normal variables following a nonstationary antedependence model. Furthermore, the small correlations approach for the maxima is compared with the Bonferroni bounds approximation for unequally <b>homoscedastic</b> and heteroscedastic correlated normal variables...|$|E
3000|$|... 22 The Breusch-Pagan/Cook-Weisberg {{test for}} {{heteroscedasticity}} rejects {{the null hypothesis}} of a <b>homoscedastic</b> error term with Prob[*]>[*]Chi 2 [*]=[*] 0.000.|$|E
30|$|Statistical {{analyses}} were performed with JMP 10.0 (SAS Systems, USA). Data were tested for normality using the Shapiro–Wilk W test and for homogeneity of variance with the Levene test. If the data were normally distributed and the variance was homogeneous, the Tukey–Kramer HSD test was conducted. Otherwise, if the data were <b>homoscedastic</b> but not normally distributed, the Steel–Dwass test was used. If the data were normally distributed but not <b>homoscedastic,</b> the Welch’s ANOVA was performed.|$|E
3000|$|... where X denotes a vector {{of control}} {{variable}}s. Latent variable export intensity* has a normal <b>homoscedastic</b> distribution (Wooldridge, 2002, p. 540).|$|E
40|$|We {{describe}} {{the development of}} a multipoint nonparametric quantitative trait loci mapping method based on the Wilcoxon rank-sum test applicable to outbred half-sib pedigrees. The method has been evaluated on a simulated dataset and its efficiency compared with interval mapping by using regression. It was shown that the rank-based approach is slightly inferior to regression when the residual variance is <b>homoscedastic</b> normal; however, in three out of four other scenarios envisaged, i. e., residual variance heteroscedastic normal, <b>homoscedastic</b> skewed, and <b>homoscedastic</b> positively kurtosed, the latter outperforms the former one. Both methods were applied to a real data set analyzing the effect of bovine chromosome 6 on milk yield and composition by using a 125 -cM map comprising 15 microsatellites and a granddaughter design counting 1158 Holstein-Friesian sires. Peer reviewe...|$|E
40|$|Abstract: The {{performance}} of the Lasso is well understood under the assumptions of the standard linear model with <b>homoscedastic</b> noise. However, in several appli-cations, the standard model does not describe the important features of the data. This paper examines how the Lasso performs on a non-standard model that is mo-tivated by medical imaging applications. In these applications, the variance of the noise scales linearly with the expectation of the observation. Like all heteroscedas-tic models, the noise terms in this Poisson-like model are not independent of the design matrix. More specifically, this paper studies the sign consistency of the Lasso under a sparse Poisson-like model. In addition to studying sufficient conditions for the sign consistency of the Lasso estimate, this paper also gives necessary conditions for sign consistency. Both sets of conditions are comparable to results for the <b>homoscedastic</b> model, showing that when {{a measure of the}} signal to noise ratio is large, the Lasso performs well on both Poisson-like data and <b>homoscedastic</b> data. Simulations reveal that the Lasso performs equally well in terms of model selec-tion performance on both Poisson-like data and <b>homoscedastic</b> data (with properly scaled noise variance), across a range of parameterizations. Taken as a whole, these results suggest that the Lasso is robust to the Poisson-like heteroscedastic noise...|$|E
40|$|Constrained {{approaches}} to maximum likelihood estimation {{in the context}} of finite mixtures of normals have been presented in the literature. A fully data-dependent constrained method for maximum likelihood estimation of clusterwise linear regression is proposed, which extends previous work in equivariant data-driven estimation of finite mixtures of Gaussians for classification. The method imposes plausible bounds on the component variances, based on a target value estimated from the data, which we take to be the <b>homoscedastic</b> variance. Nevertheless, the present work does not only focus on classification recovery, but also on how well model parameters are estimated. In particular, the paper sheds light on the shrinkage-like interpretation of the procedure, where the target is the <b>homoscedastic</b> model: this is not only related to how close to the target the estimated scales are, but extends to the estimated clusterwise linear regressions and classification. We show, based on simulation and real-data based results, that our approach yields a final model being the most appropriate-to-the-data compromise between the heteroscedastic model and the <b>homoscedastic</b> model...|$|E
40|$|Abstract—In this letter, mixture {{subclass}} {{discriminant analysis}} (MSDA) that alleviates two shortcomings of subclass discriminant analysis (SDA) is proposed. In particular, it is shown that for data with Gaussian <b>homoscedastic</b> subclass structure a) SDA {{does not guarantee}} to provide the discriminant subspace that minimizes the Bayes error, and, b) the sample covariance matrix {{can not be used}} as the minimization metric of the discriminant analysis stability criterion (DSC). Based on this analysis MSDA modifies the objective function of SDA and utilizes a novel par-titioning procedure to aid discrimination of data with Gaussian <b>homoscedastic</b> subclass structure. Experimental results confirm the improved classification performance of MSDA. EDICS Category: IMD-PATT I...|$|E
40|$|This paper {{investigates the}} role of gender in {{remittance}} behavior among migrants using the 2004 Vietnam Migration Survey data. The gender dimension to remittance behavior has not featured strongly in the existing literature and our findings thus contain novel appeal. In addition, we use estimates from both <b>homoscedastic</b> and heteroscedastic tobit models to decompose the raw gender difference in remittances into treatment and endowment components. We find little evidence that gender differences in remittances are attributable to behavioral {{differences between men and}} women, and this finding is invariant to whether the <b>homoscedastic</b> or heteroscedastic tobit is used in estimation. Gender, internal migration, remittances, Vietnam, J 16, J 61...|$|E
3000|$|This {{specification}} assumes error term normally distributed with mean 0 and variance 1. A non <b>homoscedastic</b> assumption, specifically, variance {{as function}} of utilized agricultural area, was also tested. The likelihood-ratio test of heteroskedasticity {{was not significant}} with χ [...]...|$|E
3000|$|... 11 We rely on {{this rule}} of thumb since we cannot apply the tests {{proposed}} by Stock and Yogo (2005) because we use only one instrument and do not assume <b>homoscedastic</b> errors but allow for clustering at the agency level.|$|E
30|$|In this section, we derive {{analytically}} {{the effect}} of large additive outliers on the sample cross-correlations between past and squared observations generated by uncorrelated stationary processes that could be either <b>homoscedastic</b> or heteroscedastic. The main results are illustrated with some Monte Carlo experiments.|$|E
