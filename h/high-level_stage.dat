4|51|Public
30|$|The {{complementary}} <b>high-level</b> <b>stage</b> {{of problem}} solving is a goal-oriented process of affecting a desired outcome. For example, one may set forth parameters for a solution and seek out a solution that addresses these parameters. This stage may involve selecting and taking actions that could modify the observed behaviors or affect their underlying causes. Means-end analysis {{provides an example of}} this technique.[14]. We refer to this stage {{of problem solving}} as exploring the solution space.|$|E
40|$|Contingent capture {{occurs when}} {{distractors}} that share the target 2 ̆ 7 s defining attribute capture attention and slow down target identification. This slowdown has {{been attributed to}} an involuntary attentional shift to the location of a pertinent distractor. The present study examined an additional source of delay: the time spent in processing pertinent distractors. In 7 experiments, distractors were presented at fixation, and targets were presented either at fixation or peripherally. Contingent capture invariably occurred when a salient distractor was presented within about 600 ms before the target, even when spatial shifts in attentional focus were ruled out. A 2 -stage model is proposed in which stimuli must pass an input filter tuned to the target 2 ̆ 7 s defining attribute before gaining access to a <b>high-level</b> <b>stage</b> that is unavailable while a distractor is being processed. [ABSTRACT FROM AUTHOR...|$|E
40|$|We propose an {{approach}} for multi-pose face tracking by association of face detection responses in two stages using multiple cues. The low-level stage uses a two-threshold strategy to merge detection responses based on location, size and pose, resulting in short but reliable tracklets. The <b>high-level</b> <b>stage</b> uses different cues for computing a joint similarity measure between tracklets. The facial cue compares facial {{features of the}} most frontal face detections in pairs of tracklets. The classifier cue learns a discriminative appearance model for each tracklet, using detection pairs within reliable tracklets and between overlapping tracklets as training data. The constraint cue observes the compatibility of motion of two tracklets. The association of tracklets is globally optimized with the Hungarian algorithm. We validate our approach on two challenging episodes of two TV series and report a Multiple Object Tracking Accuracy (MOTA) of 82 % and 68. 2 %, respectively. ...|$|E
30|$|Let us compare our {{saliency}} model (BFSD) with {{a number}} of existing state-of-the-art methods, including graph-based manifold ranking (GMR)[7]; multi-context deep learning (MC)[27]; multiscale deep CNN (MDF)[28]; anisotropic centre-surround difference (ACSD)[10]; saliency detection at low-level, mid-level, and <b>high-level</b> <b>stages</b> (LMH)[19]; and exploiting global priors (GP)[20], among which GMR, MC and MDF are developed for RGB images, LMH and GP for RGB-D images, and ACSD for depth images. All of the results are produced using the public codes that are offered by the authors of the previously mentioned literature reports.|$|R
40|$|We {{describe}} a nonparametric pixel appearance probability model to represent local image information. It allows an optimal image analysis framework that integrates low- and <b>high-level</b> <b>stages</b> to substantially improve overall accuracy of object reconstruction. In this framework, feature detection {{would be an}} overall consequence rather than an intermediate result. The pixel appearance probability model is a probability density function obtained by grid quantization. The grid is found by a genetic algorithm and a local refinement algorithm. The density values are computed by smoothing neighboring cells. We apply the pixel appearance probability model to represent features of echocardiographic images. We illustrate the substantially improved performance on left ventricle surface reconstruction due to the proposed pixel appearance probability model. 1...|$|R
40|$|A novel UML-based {{analytical}} modeling methodology named MISQ is presented for optimizing Web service composition in Business Service Networks. MISQ enables functional and temporal analyses at a <b>high-level</b> design <b>stage</b> so that Web service composition can be optimized systematically. Furthermore, MISQ provides an automatic generation of Web service implementations for improving productivity and reliability...|$|R
30|$|In the 21 st century, {{there were}} some new {{features}} in the international crude oil market, including the increasing globalization of the oil market, {{the rapid growth of}} oil demand in non-OECD countries and the strengthening in the financial attributes of petroleum. The international crude oil prices showed large fluctuations and upward shocks. They fell from $ 25.22 per barrel in January 2000 to $ 19.06 per barrel in December 2001 due to the weakening of the US and global economies and the slowdown in oil demand caused by the “ 911 ” attacks and then continually went up to $ 32.18 per barrel in February 2003, the eve of the outbreak of the Iraq war. From 2000 to 2004, the economic resurgence brought a rapid increase in crude oil demand. Oil demand in OECD and Asia rose by 0.6 % and 4.8 % annually, respectively (IEA). Since 2005, the oil prices gradually entered into a <b>high-level</b> <b>stage</b> and increased to a record high in July 2008, i.e., $ 134.56 per barrel. Not only the Iraq war, Venezuela and Nigeria strikes and the hurricanes (Ivan, Katrina and Rita), but also the rapid growth in the global economy, the tight supply–demand balance, high spirits in speculations from other finance and commodity trading markets into oil market and the devaluation of US dollar caused by the reduction of interest rates of Fed pushed up oil prices. Afterward, because of the global financial crisis, world oil demand was slashed and oil price dramatically slumped toward about $ 43.05 per barrel in December 2008. Since February 2009, however, the oil price has experienced short-term low-level fluctuations and then rebounded continuously. In February 2011, oil price exceeded $ 100 per barrel again in just five months, i.e., $ 104.03 per barrel. From January 2011 to June 2014, the oil price remained volatile at a high level with a slight upward trend (Wu and Zhang 2014). However, high oil prices led to a significant increase in shale oil production in the USA. The transition from tight supply–demand to loose supply–demand dominated the international oil prices, which basically fluctuated within the range of $ 95 –$ 130 per barrel. From the second half of 2014, oil production in USA had been growing rapidly, driven by the breakthrough in shale oil technology and the repeal of the 40 -year-old US oil export embargo in December 8, 2015. In addition, the substantial growth in OPEC oil supply, weak oil demand, stronger US dollars and the increase in speculation caused oil prices to descend again to $ 31.93 per barrel in January 2016. Subsequently, oil prices have been slowly shored up above $ 50 per barrel because OPEC and non-OPEC producers reached an agreement on production reductions {{for the first time in}} November 30 and December 8, 2016, respectively.|$|E
40|$|In modern {{high-speed}} circuit design, {{the clock}} skew {{has been widely}} utilized as a manageable resource to improve the circuit performance. However, in <b>high-level</b> synthesis <b>stage,</b> the circuit is never optimized for the utilization of clock skew. This paper is the first attempt to the high-level synthesis of non-zero clock skew circuits. First, we show that the register binding in <b>high-level</b> synthesis <b>stage</b> has {{a significant impact on}} the clocking constraints between registers. As a result, different register binding solutions lead to different smallest feasible clock periods. Then, based on that observation, we formulate the problem of register binding for clock period minimization. Given a constraint on the number of registers, our objective is to find a minimum-period register binding solution. Experimental data show that, in most benchmark circuits, the lower bound of the clock period can be achieved without any extra overhead on the number of registers. 1...|$|R
40|$|This paper {{describes}} an implemented computer program called pret that automates {{the process of}} system identification: given hypotheses, observations, and specifications, it constructs an ordinary differential equation model of a target system with no other inputs or intervention from its user. The core {{of the program is}} a set of traditional system identification (SID) methods. A layer of artificial intelligence (AI) techniques built around this core automates the <b>high-level</b> <b>stages</b> of the identification process that are normally performed by a human expert. The AI layer accomplishes this by selecting and applying appropriate methods from the SID library and performing qualitative, symbolic, algebraic, and geometric reasoning on the user's inputs. For each supported domain (e. g., mechanics), the program uses a few powerful encoded rules (e. g., = 0) to combine hypotheses into models. A custom logic engine checks models against observations, using a set of encoded domain-independen [...] ...|$|R
40|$|In this paper, {{we propose}} a new Variable Testability Measure (VTM) for {{implementing}} testability at the <b>high-level</b> synthesis <b>stage</b> {{of the design}} process of integrated circuits. This new approach, based on binary decision diagrams, representing fully functional blocks of a circuit, and on their cyclomatic testability measures. It manipulates dataflow blocks to predict whether the circuit is testable and the vector set required to test it...|$|R
40|$|AbstractSpecificity {{has always}} been {{considered}} one of the hallmarks of perceptual learning, suggesting that performance improvement would reflect changes at early stages of visual analyses (e. g., V 1). More recently, however, this view has been challenged by studies documenting complete transfer of learning among different spatial locations or stimulus orientations when a double-training procedure is adopted. Here, we further investigate the conditions under which transfer of visual perceptual learning takes place, confirming that the passive stimulation at the transfer location seems to be insufficient to overcome learning specificity. By contrast, learning transfer is complete when performing a secondary task at the transfer location. Interestingly, (i) transfer emerges when the primary and secondary tasks are intermingled on a trial-by-trial basis, and (ii) the effects of learning generalization appear to be reciprocal, namely the primary task also serves to enable transfer of the secondary task. However, if the secondary task is not performed for a sufficient number of trials, then transfer is not enabled. Overall, the results lend support to the recent view that task-relevant perceptual learning may involve <b>high-level</b> <b>stages</b> of visual analyses...|$|R
40|$|Since the {{pioneering}} experimental work of Bisiach et al. (1984) on deficits in sound localisation associated with unilateral brain lesions and visual neglect, {{a number of}} systematic investigations have examined auditory processing in visuospatial neglect patients. Evidence {{from a variety of}} experimental paradigms has revealed some auditory deficits in detection and identification tasks, during bilateral stimulation; plus localisation deficits for single sounds. These deficits emerge predominantly for contra-lesional sounds, although some auditory disturbances applying to both contra- and ipsilesional sounds have also been documented. Here we review evidence suggesting that some of these auditory deficits arise in relatively <b>high-level</b> <b>stages</b> of spatial processing. In addition, we present new analyses showing that auditory deficits in identification and localisation tasks often correlate with clinical measures of visual neglect, across a variety of different studies and tasks. This empirical relation suggests that a disturbance of multisensory spatial processing may often account for the joint auditory and visual spatial deficits in neglect patients, although rarer dissociations between the modalities should also be considered...|$|R
40|$|This paper {{presents}} {{the design of}} a 60 W GaN HEMT based <b>high-level</b> modulating <b>stage</b> to be used in a IEEE 802. 16 e Mobile WiMAX polar transmitter. Following a transmission-line class E topology the load condition for maximizing the efficiency is selected close to the maximum value of the power generating function, as defined in, for an OFDMA modulating signal. The possible effect of such average-based design on the polar transmitter linearity is also studied...|$|R
40|$|Specificity {{has always}} been {{considered}} one of the hallmarks of perceptual learning, suggesting that per- formance improvement would reflect changes at early stages of visual analyses (e. g., V 1). More recently, however, this view has been challenged by studies documenting complete transfer of learning among dif- ferent spatial locations or stimulus orientations when a double-training procedure is adopted. Here, we further investigate the conditions under which transfer of visual perceptual learning takes place, confirm- ing that the passive stimulation at the transfer location seems to be insufficient to overcome learning specificity. By contrast, learning transfer is complete when performing a secondary task at the transfer location. Interestingly, (i) transfer emerges when the primary and secondary tasks are intermingled on a trial-by-trial basis, and (ii) the effects of learning generalization appear to be reciprocal, namely the pri- mary task also serves to enable transfer of the secondary task. However, if the secondary task is not per- formed for a sufficient number of trials, then transfer is not enabled. Overall, the results lend support to the recent view that task-relevant perceptual learning may involve <b>high-level</b> <b>stages</b> of visual analyses...|$|R
40|$|A robust, resilient, and {{enabling}} policy environment {{is critical to}} take agriculture innovations to scale at national or regional level. Policy formulation processes that consider climate variability, socioeconomic and environmental shocks require participatory, inclusive, and explorative scenarios to guide decision making. Learning alliances, or multi-stakeholder platforms, foster policy dialogue at community, district and <b>high-level</b> planning <b>stages</b> and lead to integrated, coordinated, and gender-responsive policy recommendations Decision makers at legislative and top-policy level can consider these recommendations in creating equitable, climate-resilient policy. International Fund for Agricultural Developmen...|$|R
40|$|AbstractWhen {{investigating}} perceptual learning (PL), {{most researchers}} use real figures as stimuli, but PL can occur when subjects are trained with virtual stimuli or even without any visual stimuli at all. Here, we first demonstrated that virtual lines {{have the same}} perceptual attributes as real lines by confirming that {{there is also an}} oblique effect in virtual lines (formed by a pair of circles) in an orientation discrimination task. Then, our ERP study showed that orientation discrimination learning and its transfer across real and virtual lines were associated with more negative parietal–occipital P 1 –N 1 (reduced P 1 and enhanced N 1), which indicated the involvement of <b>high-level</b> <b>stages</b> of visual information processing or the involvement of top-down influences. At the same time, the specific ERP changes in the frontal ERP components were differently associated with real versus virtual line orientation learning. That is, real line learning was characterized by an early and short-lasting frontal N 1 (120 – 140 ms) reduction, in contrast to a much later, widespread, and long-lasting P 150 – 300 decrease in virtual line learning. These results contribute {{to the understanding of the}} neural basis of perceptual learning and the distinction between real and virtual stimulus learning...|$|R
25|$|The Heil Talk Box {{was made}} famous after {{being used by}} Joe Walsh, Peter Frampton, and Richie Sambora. It was the first high-powered Talk Box on the market, which could {{reliably}} be used on <b>high-level</b> rock <b>stages.</b> The first Heil Talk Box was built for Joe Walsh's Barnstorm Tour. It was developed in 1973. Heil later sold the rights to Dunlop Manufacturing, Inc.. Frampton frequently used a Heil Talk Box after receiving one as a Christmas present from Heil in 1974, {{and it can be}} prominently heard on his 1975 album Frampton.|$|R
40|$|Convex {{optimization}} {{methods are}} employed to optimize a real-time (RT) system-on-chip (SoC) under {{a variety of}} physical resource-driven constraints, demonstrated on an industry MPEG 2 encoder SoC. The power optimization is compared to conventional performance-optimization framework, showing a factor of two and a half saving in power. Convex optimization is shown to be very efficient in a <b>high-level</b> early <b>stage</b> design exploration, guiding computer architects as to the choice of area, voltage, and frequency of the individual components of the Chip Multiprocessor (CMP). Comment: 6 pages, 3 figure...|$|R
50|$|The Heil Talk Box {{was made}} famous after {{being used by}} Joe Walsh, Peter Frampton, and Richie Sambora. It was the first high-powered Talk Box on the market, which could {{reliably}} be used on <b>high-level</b> rock <b>stages.</b> The first Heil Talk Box was built for Joe Walsh's Barnstorm Tour. It was developed in 1973. Heil later sold the rights to Dunlop Manufacturing, Inc.. Frampton frequently used a Heil Talk Box after receiving one as a Christmas present from Heil in 1974, {{and it can be}} prominently heard on his 1975 album Frampton.|$|R
30|$|The third <b>stage,</b> <b>high-level</b> visual processing, which spreads {{along the}} {{primary visual cortex}} to the lower {{temporal}} cortex, establishes categories and meanings. Here the brain integrates the visual information with relevant information coming {{from a variety of}} other sources, and enables us to recognise specific objects, faces and scenes” (Kandel, 2012).|$|R
40|$|AbstractPerceiving {{biological}} {{motion is}} important for understanding the intentions and future actions of others. Perceiving an approaching person’s behavior may be particularly important, because such behavior often precedes social interaction. To this end, the visual system may devote extra resources for perceiving an oncoming person’s heading. If this were true, humans should show increased sensitivity for perceiving approaching headings, and as a result, a repulsive perceptual effect around the categorical boundary of leftward/rightward motion. We tested these predictions and found evidence for both. First, observers were especially sensitive to the heading of an approaching person; variability in estimates of a person’s heading decreased near the category boundary of leftward/rightward motion. Second, we found a repulsion effect around the category boundary; a person walking approximately toward the observer was perceived as being repelled away from straight ahead. This repulsive effect was greatly exaggerated for perception of a very briefly presented person or perception of a chaotic crowd, suggesting that repulsion may protect against categorical errors when sensory noise is high. The repulsion effect with a crowd required integration of local motion and human form, suggesting an origin in <b>high-level</b> <b>stages</b> of visual processing. Similar repulsive effects may underlie categorical perception with other social features. Overall, our results show that a person’s direction of walking is categorically perceived, with improved sensitivity at the category boundary and a concomitant repulsion effect...|$|R
40|$|This paper {{describes}} an implemented computer program called pret that automates {{the process of}} system identi cation: given hypotheses, observations, and speci cations, it constructs an ordinary di erential equation model of a target system with no other inputs or intervention from its user. The core {{of the program is}} a set of traditional system identi cation (SID) methods. A layer of arti cial intelligence (AI) techniques built around this core automates the <b>high-level</b> <b>stages</b> of the identi cation process that are normally performed by ahuman expert. The AI layer accomplishes this by selecting and applying appropriate methods from the SID library and performing qualitative, symbolic, algebraic, and geometric reasoning on the user's inputs. For each supported domain (e. g., mechanics), the program uses a few powerful encoded rules (e. g., F = 0) to combine hypotheses into models. A custom logic engine checks models against observations, using a set of encoded domain-independent mathematical rules to infer facts about both, modulo the resolution inherent in the speci cations, and then searching for contradictions. The design of the next generation of this program is also described in this paper. In it, discrepancies between sets of facts will be used to guide the removal of unnecessary terms from a model. Power-series techniques will be exploited to synthesize new terms from scratch if the user's hypotheses are inadequate, and sensors and actuators will allow the tool to take aninput-output approach to modeling real physical systems. ...|$|R
40|$|We {{propose a}} hybrid body {{representation}} that represents each typical pose by both template-like view information and part-based structural information. Specifically, each body part {{as well as}} the whole body are represented by an off-line learned shape model where both region-based and edge-based priors are combined in a coupled shape representation. Part-based spatial priors are represented by a “star ” graphical model. This hybrid body representation can synergistically integrate pose recognition, localization and segmentation into one computational flow. Moreover, as an important step for feature extraction and model inference, segmentation is involved in the low-level, mid-level and <b>high-level</b> vision <b>stages,</b> where top-down prior knowledge and bottom-up data processing is well integrated via the proposed hybrid body representation. 1...|$|R
40|$|AbstractWith {{tremendous}} compaction in {{semiconductor devices}} {{over the past}} decades, power consumption in circuits has become an im- portant design concern. Peak power is the maximum instantaneous power at a particular time. For devices having multiple modes of operational unit, the highest power mode determines area, packaging and possibly heat sink cost of goods. In this paper, we present a technique for the minimization of peak power consumption in a design of circuit at the <b>high-level</b> synthesis <b>stage.</b> A PB-SAT based model has been proposed that minimizes the peak power and satisfies the resource constraints. Experimental results are obtained by applying the proposed method on high-level synthesis benchmark circuits for different resource constraints...|$|R
5000|$|The first high-powered Talk Box was {{developed}} by Bob Heil Heil {{came up with the}} first high-powered Talk Box that could be reliable when used on <b>high-level</b> rock <b>stages.</b> His first Heil Talk Box was built for Joe Walsh's Barnstorm tour. Heil and Walsh both avid ham radio experimenters (K9EID and WB6ACU), along with Walsh's guitar tech [...] "Krinkle" [...] combined a 250-watt JBL driver and suitable hi-pass filter which was used for Walsh's single [...] "Rocky Mountain Way". Walsh gives credit to Bill West, an electrical engineer, Nashville steel guitarist and first husband of country music legend Dottie West, for inventing the talk box for him in the May 2012 issue of Guitar World magazine.|$|R
40|$|The article {{touched upon}} {{the problem of}} {{providing}} health to human operator in carrying out the works-rest, characterized by a special responsibility and neuro-emotional high-voltage {{by means of the}} use of physical exercise. On the example of aviation event the importance of restoring the physical conditions transition from the monotonous <b>stage</b> to <b>high-level,</b> short-termism, crucial <b>stage</b> is shown (for example, the transition from cruise flight mode, taking place in the automatic mode to landing) ...|$|R
40|$|Recent work {{indicates}} that the specialization of face visual perception relies on the privileged processing of horizontal angles of facial information. This suggests that stimulus properties assumed to be fully resolved in primary visual cortex (V 1; e. g., orientation) in fact determine human vision until <b>high-level</b> <b>stages</b> of processing. To address this hypothesis, the present fMRI study explored the orientation sensitivity of V 1 and high-level face-specialized ventral regions such as the Occipital Face Area (OFA) and Fusiform Face Area (FFA) to different angles of face information. Participants viewed face images filtered to retain information at horizontal, vertical or oblique angles. Filtered images were viewed upright, inverted and (phase-) scrambled. FFA responded most strongly to the horizontal range of upright face information; its activation pattern reliably separated horizontal from oblique ranges, but only when faces were upright. Moreover, activation patterns induced in the right FFA and the OFA by upright and inverted faces could only be separated based on horizontal information. This {{indicates that}} the specialized processing of upright face information in the OFA and FFA essentially relies on the encoding of horizontal facial cues. This pattern was not passively inherited from V 1, which was found to respond less strongly to horizontal than other orientations likely due to adaptive whitening. Moreover, we found that orientation decoding accuracy in V 1 was impaired for stimuli containing no meaningful shape. By showing that primary coding in V 1 is influenced by high-order stimulus structure and that high-level processing is tuned to selective ranges of primary information, the present work suggests that primary and high-level levels of the visual system interact in order to modulate the processing of certain ranges of primary information depending on their relevance {{with respect to the}} stimulus and task at hand...|$|R
40|$|Clock gating is one {{of useful}} {{techniques}} to reduce the dynamic power consumption of synchronous sequential circuits. To reduce the power consumption of clock tree, previous work has shown that clock control logic should be synthesized in the <b>high-level</b> synthesis <b>stage.</b> However, previous work may suffer from a large circuit area overhead on the clock control logic. In this paper, we present an ILP (integer linear programming) formulation to consider both the clock tree and the clock control logic. Our optimization goal {{is not only to}} conform to the constraint on the overall power consumption, but also to minimize the area overhead of clock control logic. Compared with previous work, benchmark data show that our approach can greatly reduce the circuit area overhead under the same constraint on the overall power consumption...|$|R
40|$|The clock {{distribution}} and generation circuitry forms {{a critical component}} of current synchronous digital systems and is known to consume at least a quarter of the power budget of existing microprocessors. We propose and validate a high level model for evaluating the energy dissipation of the clock generation and distribution circuitry, including both the dynamic and leakage power components. The validation results show that the model is reasonably accurate, with the average deviation being within 10 % of SPICE simulations. Access to this model can enable further research at <b>high-level</b> design <b>stages</b> in optimizing the system clock power. To illustrate this, a few architectural modifications are considered and their effect on the clock subsystem and the total system power budget is assessed Index Terms [...] -Clock power-consumption-modeling, digitalCMOS, phase-locked-loop, VLSI low-power-design...|$|R
40|$|This paper {{argues that}} {{software}} measurement and the software development process are mutually dependent. Firstly, a high-level {{view of the}} relationship between measurement and the development process is taken. This view shows where the various activities within software measurement are positioned {{within the context of the}} <b>high-level</b> project <b>stages.</b> The topic of process modelling is introduced, and is used to develop a lower-level view of measurement integration with process. This shows that process models for measurement integration should be sufficiently fine-grained to show when measurements should be collected, how they should be collected, who should collect then, and how the results will be used (the usual lifecycle models are too coarse-grain to achieve this). It is also shown that measurement can be most easily integrated within an automated environment, as measurement collection should itself be automated. The initial work on the [...] ...|$|R
50|$|A central form of {{abstraction}} in computing is language abstraction: new artificial languages are developed to express {{specific aspects of}} a system. Modeling languages help in planning. Computer languages can be processed with a computer. An example of this abstraction process is the generational development of programming languages from the machine language to the assembly language and the <b>high-level</b> language. Each <b>stage</b> {{can be used as}} a stepping stone for the next stage. The language abstraction continues for example in scripting languages and domain-specific programming languages.|$|R
40|$|This paper {{addresses}} {{learning and}} recognition of human behaviour models from multi-modal observations in a smart home environment. The proposed approach successfully implements concurrent Hidden Markov Models that identify the occurring situation. This approach corresponds to the highlevel part from a framework to obtain high-level classification of human behaviour analysis. The results were obtained for a smart home environment, where cameras, microphones and a PMD sensor were deployed. The sensory information was first fed to the low-level classification stage, where it was analysed by four different classifiers which generate the observations to the <b>high-level</b> classification <b>stage.</b> For each situation an HMM is used, allowing the fusion of the data provided by the different sources present in the low-level classification stage. This approach proved to be highly scalable, since the recognition of new situations {{can be accomplished by}} means of adding the adequate HMM. 1...|$|R
40|$|An {{algorithm}} {{is presented to}} compute the shape of moving objects in image sequences. We assume that locally the motion fields of both the object and its environment can be represented by affine approximations. Based on hypotheses about these fields, an optimality principle is formulated to compute {{the shape of an}} object in terms of deformations of an arbitrary convex polygonal domain. As input data the algorithm merely requires first order derivatives of the image function. Numerical experiments using synthesized and real image data are presented. The results suggest that our approach is suited for tracking tasks within an bottom-up/top-down framework. 1 Introduction The ability to compute representations of independently moving objects is of vital importance for vision based systems. In this article, we focus on cases where ego-motion is known and expectations about object movements can be inferred from <b>high-level</b> processing <b>stages</b> (control of ego-motion, use of event models [9]). Fu [...] ...|$|R
40|$|Leakage current {{minimization}} is {{an important}} topic for event driven applications that {{spend most of their}} times in standby mode. Power gating technique {{is one of the most}} effective ways to reduce the standby leakage current. However, when power gating tech-nique is applied to a functional unit, there exists a delay-power tradeoff, which can be characterized with the widths of sleep transistors. In this paper, we point out that: under the same target clock period, there are many feasible clock skew schedules; since differ-ent clock skew schedules impose different timing constraints to functional units, different clock skew schedules may lead to different standby leakage currents. Based on that ob-servation, we present an MILP (mixed integer linear programming) approach to formally formulate the problem of simultaneous application of optimal clock skew scheduling and power-gated module selection (i. e., sleep transistor width selection) in <b>high-level</b> synthe-sis <b>stage.</b> Experimental data show that: compared with the existing design flow, our standby leakage current reduction achieves 29. 3 %...|$|R
40|$|Visual rivalry {{has been}} {{extensively}} characterized in the literature. It is thought to require spatial conflict between overlapping visual presentations, even in studies that have found nonspatial (i. e. nonretinal) influences on rivalry. Unexpectedly, we identified visual rivalry in the complete absence of spatial conflict. Participants experienced visual rivalry when we placed a nonambiguous motion stimulus in a nonspatial (in our case, object-based) reference frame. Moreover, a stimulus that was displaced within a nonspatial reference frame did not induce rivalry {{despite the presence of}} spatial conflict. This finding shows that nonspatial, object-based processing can overrule retinotopic processing and prevent rivalry from occurring when a perceived stimulus exists unambiguously in an object-based reference frame. our results identify a potent <b>high-level</b> conflict-resolution <b>stage</b> independent of low-level spatial visual conflict. This independence of spatial overlap provides an advantage to the visual system, allowing conflict resolution when an object is nonstationary on the retina (e. g., during frequently occurring eye movements) ...|$|R
40|$|One of the {{principal}} objectives of software engineering {{is to improve the}} quality of software products. Quality assurance must be guaranteed from the early stages of the software development life cycle, focusing on high-level design artifacts like class diagrams. Indeed, class diagrams constitute the backbone of objectoriented information systems (OOIS) so, their quality has a great impact on the quality of the product which is finally implemented. To assess class diagram quality, it is useful to have quantitative and objective measurement instruments. After having thoroughly reviewed existing OO measures applicable to class diagrams at a <b>high-level</b> design <b>stage,</b> we presented in a previous work [16, [19] a set of UML class diagram structural complexity metrics, a class diagram internal quality attribute, with the idea that it is related to the external quality of such diagrams. In order to gather empirical evidence that the proposed metrics could be early quality indicators of class diagrams, we carried out a controlled experiment. The aim of which was to investigate the relation between the structural complexity of class diagrams and their maintainability. Keywords...|$|R
