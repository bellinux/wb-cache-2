3|28|Public
5000|$|Display an <b>input</b> <b>prompt</b> dialog box, storing {{the result}} in the {{variable}} %A: ...|$|E
5000|$|An {{example of}} the {{conversational}} nature of NUTRAN is shown below. [...] is the command promptand [...] is the <b>input</b> <b>prompt.</b>|$|E
5000|$|While TECO is {{sometimes}} incorrectly considered a line editor, {{it is in}} fact modal and character-oriented. In non-technical terms, it's perhaps best described as a modern editor in the tradition of Vim running with the document out of view. Line commands are understood as searching for the two-character string [...] "CRLF", and the insertion point may in fact be positioned between these two characters. Because the PDP-6 used a modified IBM Selectric as a printer, and because the Selectric used physical movements of the platen and carriage to print text, boldface, strikethrough, and underscore were all possible by omitting either the CR or LF. Below is an example of TECO showcasing special text effects and its character-oriented nature; note that the asterisk is TECO's <b>input</b> <b>prompt,</b> and dollar signs stand for a press of the Escape key.|$|E
40|$|We {{formally}} {{specify the}} interpretation {{stage in a}} dual state space human-computer interaction cycle. This is done by extending / reorganising our previous cognitive architecture. In particular, we focus on shape related aspects of the interpretation process associated with device <b>input</b> <b>prompts.</b> A cash-point example illustrates our approach. Using the SAL model checking environment, we show how the extended cognitive architecture facilitates detection of prompt-shape induced human error...|$|R
25|$|Much of the {{gameplay}} involves solving puzzles {{by using}} items with other items or with objects and characters onscreen. Another significant {{aspect of the}} game involves talking with characters in the game, namely the bots that work in the ship and a parrot, by <b>inputting</b> <b>prompts</b> in the Chat-O-Mat mode. Additionally to conversation with characters through interpreting of user input, the parser often provides hints or explanations that {{come in the form}} of pre-recorded speech, which can help the player in progressing in the game.|$|R
5000|$|CBTraining {{does require}} an instructor, or [...] "guide", however the {{training}} is universal in its template {{because it is}} only individualized when the participant begins adding his/her own specific <b>input</b> when <b>prompted.</b> Therefore the internet is the most cost-effective and practical means to present CBTraining. Though the use of CBTraining in behavioral health began with live seminar programs, the ubiquity and convenience of the internet - coupled with easy program scalability - have created a transition to the virtual medium. There have been studies done comparing efficacy of internet programs focused on smoking cessation.|$|R
40|$|International audienceNeocortical layer VI is {{critically}} involved in thalamocortical activity changes during the sleep/wake cycle. It receives dense projections from thalamic nuclei {{sensitive to the}} wake-promoting neuropeptides orexins, and its deepest part, layer VIb, is the only cortical lamina reactive to orexins. This convergence of wake-promoting <b>inputs</b> <b>prompted</b> us to investigate how layer VIb can modulate cortical arousal, using patch-clamp recordings and optogenetics in rat brain slices. We found {{that the majority of}} layer VIb neurons were excited by nicotinic agonists and orexin through the activation of nicotinic receptors containing alpha 4 -alpha 5 -beta 2 subunits and OX 2 receptor, respectively. Specific effects of orexin on layer VIb neurons were potentiated by low nicotine concentrations and we used this paradigm to explore their intracortical projections. Co-application of nicotine and orexin increased the frequency of excitatory post-synaptic currents in the ipsilateral cortex, with maximal effect in infragranular layers and minimal effect in layer IV, {{as well as in the}} contralateral cortex. The ability of layer VIb to relay thalamocortical inputs was tested using photostimulation of channelrhodopsin-expressing fibers from the orexin-sensitive rhomboid nucleus in the parietal cortex. Photostimulation induced robust excitatory currents in layer VIa neurons that were not pre-synaptically modulated by orexin, but exhibited a delayed, orexin-dependent, component. Activation of layer VIb by orexin enhanced the reliability and spike-timing precision of layer VIa responses to rhomboid inputs. These results indicate that layer VIb acts as an orexin-gated excitatory feedforward loop that potentiates thalamocortical arousal...|$|R
50|$|Palm OS 5.2 {{is mainly}} a bugfix release, first {{implemented}} in the Samsung SGH-i500 in March 2003. It added support for 480x320 resolutions and introduced the new handwriting input system called Graffiti 2; the new <b>input</b> system was <b>prompted</b> by Xerox' lawsuit win against Palm. Graffiti 2 is based on Jot from CIC. The last bugfix release is version 5.2.8.|$|R
40|$|Human welfare {{depends on}} the amount and {{stability}} of agricultural production, as determined by crop yield and cultivated area. Yield increases asymptotically with the resources provided by farmers’ inputs and environmentally sensitive ecosystem services. Declining yield growth with increased <b>inputs</b> <b>prompts</b> conversion of more land to cultivation, but {{at the risk of}} eroding ecosystem services. To explore the interdependence of agricultural production and its stability on ecosystem services, we present and test a general graphical model, based on Jensen's inequality, of yield–resource relations and consider implications for land conversion. For the case of animal pollination as a resource influencing crop yield, this model predicts that incomplete and variable pollen delivery reduces yield mean and stability (inverse of variability) more for crops with greater dependence on pollinators. Data collected by the Food and Agriculture Organization of the United Nations during 1961 – 2008 support these predictions. Specifically, crops with greater pollinator dependence had lower mean and stability in relative yield and yield growth, despite global yield increases for most crops. Lower yield growth was compensated by increased land cultivation to enhance production of pollinator-dependent crops. Area stability also decreased with pollinator dependence, as it correlated positively with yield stability among crops. These results reveal that pollen limitation hinders yield growth of pollinator-dependent crops, decreasing temporal stability of global agricultural production, while promoting compensatory land conversion to agriculture. Although we examined crop pollination, our model applies to other ecosystem services for which the benefits to human welfare decelerate as the maximum is approached...|$|R
50|$|WUEV was in {{jeopardy}} early in 2006 when the University of Evansville administration were recipients of {{an offer to}} buy out the station by an undisclosed bidder. The receipt of the offer was announced on 31 January 2006 in AceNotes (the University's daily email to its students, staff, faculty {{and other members of}} the university community) along with a request for reader <b>input.</b> This <b>prompted</b> concerned alumni and students to a major grassroots campaign to protest the sale of the station and its operating bandwidth. According to local sources, including the University Crescent, over 400 letters were received on the subject, with an overwhelming majority against the proposed sale. In fact, according to every news report, the University of Evansville never offered one letter that supported the sale nor provided an example of anyone stating they were in favor of the sale.|$|R
40|$|Purpose - Increasing {{pressure}} to enhance research {{coupled with a}} desire for a broadening of academic <b>input,</b> are <b>prompting</b> greater levels of collaboration. Research collaboration can generate notable benefits but can also pose a variety of challenges. The {{purpose of this paper}} is to explore the reasons, facilitators, benefits and challenges of academic collaboration. It also provides suggestions to manage identifiable risks and enhance team dynamics. Design/methodology/approach - This is a conceptual paper exploring prior literature in relation to the contentious points of research collaboration, particularly in regard to authorship attribution. Findings - The authors present two checklists that researchers can utilise to ensure the successful completion of collaborative projects. The checklists incorporate the main factors required for effective collaborative work and research, and form a foundation for discussion among team members. Originality/value - The paper draws upon experiences, observations, academic literature and protocols, and provides strategies and recommendations to enhance collaboration and authorship attribution. The two checklists presented in the paper are value-adding for team members...|$|R
5000|$|The {{interactive}} cutscene {{element is}} {{integrated with the}} gameplay however. Correct <b>inputs</b> when <b>prompted</b> will advance the story while failure can cause the restart of a sequences and damage to health in a previous gameplay sequence. While a few sequences may continue regardless, certain quick-time events have degrees of success where the player may attempt to press at an even more specific time than when the prompt immediately and initially appears. For example, a press too early or later might register a merely [...] "good" [...] or [...] "great" [...] while the exact correct moment will register as [...] "excellent". The player's performance in this aspect, along with time taken to complete and overall damage inflicted is graded {{at the end of}} each episode, with the highest grade being an [...] "S Rank". At least 5 S Ranks or completing 50 episodes unlock the final hidden [...] "true ending" [...] of the game.|$|R
40|$|The issues {{discussed}} in this paper are based on topics raised during initial discussions between Infrastructure Australia representatives with stakeholders {{and as a result}} of internal research. The paper aims to <b>prompt</b> <b>input</b> regarding how to foster an environment in which infrastructure spending decisions can maximise their effectiveness in delivering on economic, social, and environmental objectives. Infrastructure Australia is a statutory advisory council with twelve members drawn from industry and government, including five from the private sector. Infrastructure Australia is supported by an Infrastructure Coordinator, within the Australian Government’s Infrastructure, Transport, Regional Development and Local Government portfolio...|$|R
40|$|Purpose – Increasing {{pressure}} to enhance research {{coupled with a}} desire for a broadening of academic <b>input,</b> are <b>prompting</b> greater levels of collaboration. Research collaboration can generate notable benefits but can also pose a variety of challenges. The {{purpose of this paper}} is to explore the reasons, facilitators, benefits and challenges of academic collaboration. It also provides suggestions to manage identifiable risks and enhance team dynamics. Design/methodology/approach – This is a conceptual paper exploring prior literature in relation to the contentious points of research collaboration, particularly in regard to authorship attribution. Findings – The authors present two checklists that researchers can utilise to ensure the successful completion of collaborative projects. The checklists incorporate the main factors required for effective collaborative work and research, and form a foundation for discussion among team members. Originality/value – The paper draws upon experiences, observations, academic literature and protocols, and provides strategies and recommendations to enhance collaboration and authorship attribution. The two checklists presented in the paper are value-adding for team members. <br /...|$|R
30|$|In {{this paper}} we have {{presented}} {{a method for}} predicting user mental states in spoken dialogue systems. These states are defined as {{the combination of the}} user emotional state and the predicted intention according to their objective in the dialogue. We have proposed an architecture in which our method is implemented as a module comprised of an emotion recognizer and an intention recognizer. The emotion recognizer obtains the user emotional state from the acoustics of their utterance as well as the dialogue history. The intention recognizer decides the next user action and their dialogue goal using a statistical approach that relies on the previous user <b>input</b> and system <b>prompt.</b>|$|R
40|$|A {{study of}} the use of and and or for specifying {{intersection}} and union relationships between conjoined qualifiers of varying characteristics was conducted using a simulated natural language query system. Subjects always used or correctly to indicate union but and was used to indicate both union and intersection. Interpretation rules were defined {{that could be used to}} clarify the intended meaning for and for some but not all of the cases. The results indicated subjects could implicitly learn to be more precise. These results suggest that natural language interfaces can be built to recognize ambiguous <b>input</b> and should <b>prompt</b> users for clarification. Simple syntactic elements that would distinguish the meaning of and can be defmed and taught to users...|$|R
40|$|The Hybrid Automated Reliability Predictor (HARP) {{integrated}} Reliability (HiRel) tool {{system for}} reliability/availability prediction offers a toolbox of integrated reliability/availability programs {{that can be}} used to customize the user's application in a workstation or nonworkstation environment. The Hybrid Automated Reliability Predictor (HARP) tutorial provides insight into HARP modeling techniques and the interactive textual <b>prompting</b> <b>input</b> language via a step-by-step explanation and demonstration of HARP's fault occurrence/repair model and the fault/error handling models. Example applications are worked in their entirety and the HARP tabular output data are presented for each. Simple models are presented at first with each succeeding example demonstrating greater modeling power and complexity. This document is not intended to present the theoretical and mathematical basis for HARP...|$|R
40|$|The United States Bureau of Mines (USBM) {{developed}} SPONCOM {{to aid in}} {{the assessment}} of the spontaneous combustion risk of an underground mining operation. A prior knowledge of the spontaneous combustion risk of the coal and factors that increase that risk can be useful in the planning and development of proactive monitoring, ventilation, and prevention plans for the mining operation. Interactive data <b>input</b> screens <b>prompt</b> the user for information about the coal's chemical and physical properties, the geologic and mining conditions encountered in the mining of the coal, and the mining practices employed. During the input process, 'expand' screens provide the user with specific information on each input parameter. This information includes a description of the parameter and its effect on the overall spontaneous combustion risk. The program logic determines the coal's relative spontaneous combustion potential, based on the coal's proximate and ultimate analyses, and heating value. The program then evaluates the impact of the coal properties, geologic and mining conditions, and mining practices on the spontaneous combustion risk of the mining operation. The program output provides details on each factor that increases the risk of spontaneous combustion...|$|R
40|$|One of {{the goals}} of Infrastructure Australia is to {{facilitate}} public discussion on how the nation could improve planning and investment in infrastructure to meet our future needs, as well as improving the way we use the infrastructure already in place. During the early phases of Infrastructure Australia’s activities, it became clear that members of the community, including people working in industry and government, have both ideas and information potentially of great value to the work being undertaken. This discussion paper aims to <b>prompt</b> <b>input</b> regarding how Public Private Partnerships (PPPs) could be used to optimise investment in public infrastructure and how the policies and processes for considering PPPs as an investment option and for implementing PPPs, could be improved...|$|R
40|$|This thesis {{addresses}} {{important issues}} in the conversion of nondeterministic finite automata into deterministic finite automata: {{the development of the}} conversion process, the behavior of the conversion process with respect to input automata, and the relationship of output automata to input automata. In developing a robust, efficient, and modular conversion program, it is necessary to analyze searching and sorting routines, abstract data types, and other issues in order to determine appropriate routines and structures for use with automata and their manipulation. Subset construction is a well-known procedure for converting a nondeterministic finite automaton into a deterministic finite automaton. A large part of this thesis explains the improvements made to an existing, inefficient, implementation of subset construction based on a pseudo-code specification. The testing phase of this project led to a study of the behavior of the conversion process with respect to different types of automata. Very few automata were available for testing, therefore, methods to generate test automata were examined. Some interesting behavior in the output automata, with respect to the <b>input</b> automata, <b>prompted</b> concurrent study in this area. A conjecture based on the density of automata enables us to estimate the cost of subset construction prior to actually performing the construction. In conclusion, recommended implementations of subset construction are suggested based upon information about the input automaton...|$|R
40|$|WudWWug (What you do With What you’ve got) is an {{innovative}} new online application developed at West College Scotland, for reflecting and tracking the personal development of essential, transferable skills. WudWWug provides 40 skills across the 4 capacities of Curriculum for Excellence, allowing learners to evaluate themselves against these skills. By using {{a series of}} <b>prompts</b> <b>inputting</b> these skills as they are developed, a personal profile page is created, which shows an academic record of their course. A key issue raised by employers is that young people are unable to articulate what skills they actually possess. This system allows students to identify all of the instances where they felt they had developed skills, written with the vocabulary of their own learning. It provides learners with a stronger, more detailed CV and improved articulation to express their development and education. ...|$|R
40|$|Phantom pain after arm {{amputation}} {{is widely}} believed to arise from maladaptive cortical reorganization, triggered by loss of sensory input. We instead propose that chronic phantom pain experience drives plasticity by maintaining local cortical representations and disrupting inter-regional connectivity. Here we show that, while loss of sensory input is generally characterized by structural and functional degeneration in the deprived sensorimotor cortex, the experience of persistent pain is associated with preserved structure and functional organization in the former hand area. Furthermore, consistent with the isolated nature of phantom experience, phantom pain is associated with reduced inter-regional functional connectivity in the primary sensorimotor cortex. We therefore propose that contrary to the maladaptive model, cortical plasticity associated with phantom pain is driven by powerful and long-lasting subjective sensory experience, such as triggered by nociceptive or top– down <b>inputs.</b> Our results <b>prompt</b> a revisiting {{of the link between}} phantom pain and brain organization...|$|R
5000|$|The {{third person}} action {{sequences}} resemble [...] "beat 'em up" [...] style gameplay where the player must defeat enemies in close combat, utilizing light and heavy attacks, counters, dashes and projectiles. While regular light attacks are fast, heavier attacks inflict more damage and can throw back multiple enemies yet can overheat requiring a cool down period between uses. Players can also perform counter moves if they <b>input</b> the current <b>prompt</b> during an enemy's attack. When an enemy is knocked down, special moves {{can be performed}} that further help fill the burst gauge. If however the player character is knocked back, {{they have a chance}} to quickly recover by landing on their feet and saving additional health. The rail shooter portion of the gameplay involves the player character moving yet on a fixed axis, being only able to move to dodge and maneuver against incoming attack and obstacles, all the while locking on and firing upon enemies.|$|R
40|$|Aircraft {{dynamics}} characteristics {{can only}} be identified from flight data when the aircraft dynamics are excited sufficiently. A preliminary study was conducted into what types and levels of manual piloted control excitation would be required for accurate Real-Time Parameter IDentification (RTPID) results by commercial airline pilots. This includes assessing the practicality for the pilot to provide this excitation when cued, and to further understand if pilot inputs during various phases of flight provide sufficient excitation naturally. An operationally representative task was evaluated by 5 commercial airline pilots using the NASA Ice Contamination Effects Flight Training Device (ICEFTD). Results showed that it is practical to use manual pilot inputs only {{as a means of}} achieving good RTPID in all phases of flight and in flight turbulence conditions. All pilots were effective in satisfying excitation requirements when cued. Much of the time, cueing was not even necessary, as just performing the required task provided enough excitation for accurate RTPID estimation. Pilot opinion surveys reported that the additional control <b>inputs</b> required when <b>prompted</b> by the excitation cueing were easy to make, quickly mastered, and required minimal training...|$|R
40|$|The {{taxonomy}} of optical emission detected during the critical first {{few minutes after}} the onset of a gamma-ray burst (GRB) defines two broad classes: prompt optical emission correlated with prompt gamma-ray emission, and early optical afterglow emission uncorrelated with the gamma-ray emission. The standard theoretical interpretation attributes prompt emission to internal shocks in the ultra-relativistic outflow generated by the internal engine; early afterglow emission is attributed to shocks generated by interaction with the surrounding medium. Here we report on observations of a bright GRB that, for the first time, clearly show the temporal relationship and relative strength of the two optical components. The observations indicate that early afterglow emission {{can be understood as}} reverberation of the energy <b>input</b> measured by <b>prompt</b> emission. Measurements of the early afterglow reverberations therefore probe the structure of the environment around the burst, whereas the subsequent response to late-time impulsive energy releases reveals how earlier flaring episodes have altered the jet and environment parameters. Many GRBs are generated by the death of massive stars that were born and died before the Universe was ten per cent of its current age, so GRB afterglow reverberations provide clues about the environments around some of the first stars. Comment: 13 pages, 4 figures, 1 table. Note: This paper has been accepted for publication in Nature, but is embargoed for discussion in the popular press until formal publication in Natur...|$|R
40|$|Despite {{significant}} progress {{in our understanding of}} the brain at both microscopic and macroscopic scales, the mechanisms by which low-level neuronal behavior gives rise to high-level mental processes such as memory still remain unknown. In this paper, we assess the plausibility and quantify the performance of polychronization, a newly proposed mechanism of neuronal encoding, which has been suggested to underlie a wide range of cognitive phenomena. We then investigate the effect of network topology on the reliability with which input stimuli can be distinguished based on their encoding in the form of so-called polychronous groups or spatiotemporal patterns of spikes. We find that small-world networks perform an order of magnitude better than random ones, enabling reliable discrimination between <b>inputs</b> even when <b>prompted</b> by increasingly incomplete recall cues. Furthermore, we show that small-world architectures operate at significantly reduced energetic costs and that their memory capacity scales favorably with network size. Finally, we find that small-world topologies introduce biologically realistic constraints on the optimal input stimuli, favoring especially the topographic inputs known to exist in many cortical areas. Our results suggest that mammalian cortical networks, by virtue of being both small-world and topographically organized, seem particularly well-suited to information processing through polychronization. This article addresses the fundamental question of encoding in neuroscience. In particular, evidence is presented in support of an emerging model of neuronal encoding in the neocortex based on spatiotemporal patterns of spikes...|$|R
40|$|The {{focus of}} {{investigation}} {{in this study}} was the online reading behavior of intermediate learners of French as they read a hypertext with L 1 and L 2 lexical glosses and their comprehension. By design, access to the L 2 translations was constrained by access to the L 1 gloss information first. This prescribed path of support was meant to maximize target language <b>input,</b> and to <b>prompt</b> cognitive and metacognitive processes toward the goal of increased comprehension. Comprehension was measured through multiple choice and recall tasks, and questionnaires were used to gather demographic data and learner perceptual variables. The study provides evidence that comprehension is increased with access to the hypertext glosses among readers who accessed both French and English language glosses, regardless of prior ability. Accessing only French glosses was not linked to greater comprehension, and no access to glosses reduced a comprehension factor score. Prior ability, as measured by a standardized FL placement exam, was not related to gloss access or time on task. L 2 readers' preference for L 1 language glosses in also reaffirmed to some extent, though French language glosses seem to have some appeal. Gender also {{played a role in the}} extent to which the text was enjoyed by L 2 readers, and there is suggestive evidence for the roles of background schema and formal schema based on a qualitative analysis of recall. Questionnaire data reveal insights on readers' perceptions of FLL, reading, their abilities, and reading online, findings which are related in a variety of ways to other factors in this study. Pedagogical implications are considered, as well as directions for future research...|$|R
40|$|The use of multi-touch {{interaction}} {{has become}} more widespread. With this increase of use, the change in <b>input</b> technique has <b>prompted</b> developers to reconsider other elements of typical computer design such as {{the shape of the}} display. There is an emerging need for software to be capable of functioning correctly with different display shapes. This research asked: ‘What must be considered when designing multi-touch software for use on different shaped displays?’ The results of two structured literature surveys highlighted the lack of support for multi-touch software to utilise more than one display shape. From a prototype system, observations on the issues of using different display shapes were made. An evaluation framework to judge potential solutions to these issues in multi-touch software was produced and employed. Solutions highlighted as being suitable were implemented into existing multi-touch software. A structured evaluation was then used to determine the success of the design and implementation of the solutions. The hypothesis of the evaluation stated that the implemented solutions would allow the applications to be used with a range of different display shapes {{in such a way that}} did not leave visual content items unfit for purpose. The majority of the results conformed to this hypothesis despite minor deviations from the designs of solutions being discovered in the implementation. This work highlights how developers, when producing multi-touch software intended for more than one display shape, must consider the issue of visual content items being occluded. Developers must produce, or identify, solutions to resolve this issue which conform to the criteria outlined in this research. This research shows that it is possible for multi-touch software to be made display shape independent...|$|R
40|$|In this thesis, an {{innovative}} algorithm {{for improving the}} accuracy of variational space-time stereoscopic reconstruction of ocean surfaces is presented. The space-time reconstruction method, developed based on stereo computer vision principles and variational optimization theory, takes videos captured by synchronized cameras as inputs and produces the shape and superficial pattern of an overlapped region of interest as outputs. These outputs {{are designed to be}} the minimizers of the variational optimization framework and are dependent on the estimation of the camera parameters. Therefore, from the perspective of computer vision, the proposed algorithm adjusts the estimation of camera parameters to lower the disagreement between the reconstruction and 2 -D camera recordings. From a mathematical perspective, since the minimizers of the variational framework are determined by a set of partial differential equations (PDEs), the algorithm modifies the coefficients of the PDEs based on the current numerical solutions to reduce the minimum of the optimization framework. Our algorithm increases the tolerance to the errors of camera parameters, so the joint operations of our algorithm and the variational reconstruction method can generate accurate space-time models even using videos captured by perturbed cameras as <b>input.</b> This breakthrough <b>prompts</b> the realization of ocean surface reconstruction using videos filmed by remotely-controlled helicopters in the future. A number of techniques, technical or theoretical, are explored to fulfill {{the development and implementation of}} the algorithm and relative computation issues. The effectiveness of the proposed algorithm is validated through the statistics applied to real ocean surface reconstructions of data collected from an offshore platform at the Crimean Peninsula, the Black Sea. Moreover, synthetic data generated using computer graphics are customized to simulate various situations that are not recorded in the Crimea dataset for the demonstration of the algorithm. Ph. D...|$|R
40|$|Human-computer {{interfaces}} {{which use}} speech as the medium for interaction present unique problems for human factors research, {{due to the}} fact that automatic speech recognition (ASR) technology is still error prone. The experiments described here address the design of ASR interfaces for data-entry tasks. Particular emphasis was placed on human factors, and users' data-entry performance was compared using not only quantitative measures of speed and accuracy but also more qualitative analyses of user-errors. Experiment 1 investigated the merits of using closed word-sets (syntax) to enhance recognition accuracy. Participants used a purely auditory interface (i. e. one with no visual component to it) programmed to exercise Full Syntacticconstraints (FS), Partial Syntacticconstraints (PS) or No Syntacticconstraints (NS) on the set of words available for recognition at any given time in the data-entry dialogue. Comparisons of data-entry performance showed an advantage of syntax in terms of ASR performance, and when errors and their consequences were taken into account PS was shown to accommodate users' attempts at error-correction more readily than FS. Experiment 2 compared design options for visual prompts and feedback: a limited area of the visual display was dedicated to the provision of prompts and feedback supporting the spoken data-entry dialogue. Two styles of visual prompt were contrasted: Options Prompts (OP) which displayed the full set of current options for <b>input,</b> and Fieldname <b>Prompts</b> (FP) which displayed only the current Fieldname but could be expanded on command to include the relevant options. The results showed that overall OP led to more efficient performance than FP. The errors made by users in the absence of visual feedback were compared with those occurring when the visual component was included in the interface. Recommendations for design of ASR systems for data-entry tasks are made based on the experimental results...|$|R
40|$|Structural {{flaws and}} cracks may grow under fatigue {{inducing}} loads and, upon reaching a critical size, cause structural failure to occur. The growth of these flaws and cracks may occur at load levels {{well below the}} ultimate load bearing capability of the structure. The Fatigue Crack Growth Computer Program, NASA/FLAGRO, was developed as an aid in predicting the growth of pre-existing flaws and cracks in structural components of space systems. The earlier version of the program, FLAGRO 4, was the primary analysis tool used by Rockwell International and the Shuttle subcontractors for fracture control analysis on the Space Shuttle. NASA/FLAGRO is an enhanced version {{of the program and}} incorporates state-of-the-art improvements in both fracture mechanics and computer technology. NASA/FLAGRO provides the fracture mechanics analyst with a computerized method of evaluating the "safe crack growth life" capabilities of structural components. NASA/FLAGRO could also be used to evaluate the damage tolerance aspects of a given structural design. The propagation of an existing crack is governed by the stress field {{in the vicinity of the}} crack tip. The stress intensity factor is defined in terms of the relationship between the stress field magnitude and the crack size. The propagation of the crack becomes catastrophic when the local stress intensity factor reaches the fracture toughness of the material. NASA/FLAGRO predicts crack growth using a two-dimensional model which predicts growth independently in two directions based on the calculation of stress intensity factors. The analyst can choose to use either a crack growth rate equation or a nonlinear interpolation routine based on tabular data. The growth rate equation is a modified Forman equation which can be converted to a Paris or Walker equation by substituting different values into the exponent. This equation provides accuracy and versatility and can be fit to data using standard least squares methods. Stress-intensity factor numerical values can be computed for making comparisons or checks of solutions. NASA/FLAGRO can check for failure of a part-through crack in the mode of a through crack when net ligament yielding occurs. NASA/FLAGRO has a number of special subroutines and files which provide enhanced capabilities and easy entry of data. These include crack case solutions, cyclic load spectrums, nondestructive examination initial flaw sizes, table interpolation, and material properties. The materials properties files are divided into two types, a user defined file and a fixed file. Data is entered and stored in the user defined file during program execution, while the fixed file contains already coded-in property value data for many different materials. <b>Prompted</b> <b>input</b> from CRT terminals consists of initial crack definition (which can be defined automatically), rate solution type, flaw type and geometry, material properties (if they are not in the built-in tables of material data), load spectrum data (if not included in the loads spectrum file), and design limit stress levels. NASA/FLAGRO output includes an echo of the input with any error or warning messages, the final crack size, whether or not critical crack size has been reached for the specified stress level, and a life history profile of the crack propagation. NASA/FLAGRO is modularly designed to facilitate revisions and operation on minicomputers. The program was implemented on a DEC VAX 11 / 780 with the VMS operating system. NASA/FLAGRO is written in FORTRAN 77 and has a memory requirement of 1. 4 MB. The program was developed in 1986...|$|R

