15|13|Public
5000|$|Examples of {{activities}} for which <b>Fagan</b> <b>Inspection</b> {{can be used}} are: ...|$|E
5000|$|In {{a typical}} <b>Fagan</b> <b>{{inspection}}</b> the inspection process {{consists of the}} following operations: ...|$|E
50|$|<b>Fagan</b> <b>Inspection</b> {{defines a}} {{process as a}} certain {{activity}} with a pre-specified entry and exit criteria. In every activity or operation for which entry and exit criteria are specified Fagan Inspections {{can be used to}} validate if the output of the process complies with the exit criteria specified for the process. <b>Fagan</b> <b>Inspection</b> uses a group review method to evaluate the output of a given process.|$|E
50|$|Entry {{criteria}} are the criteria or requirements {{which must be}} met to enter a specific process. For example, for <b>Fagan</b> <b>inspections</b> the high- and low-level documents must comply with specific entry-criteria {{before they can be}} used for a formal inspection process.|$|R
50|$|Exit {{criteria}} are the criteria or requirements {{which must be}} met to complete a specific process. For example, for <b>Fagan</b> <b>inspections</b> the low-level document must comply with specific exit-criteria (as specified in the high-level document) before the development process {{can be taken to}} the next phase.|$|R
40|$|The {{introduction}} of software formal <b>inspections</b> (<b>Fagan</b> <b>Inspections)</b> at JPL for finding and fixing defects {{early in the}} software development life cycle are reviewed. It is estimated that, by the year 2000, some software efforts will rise {{to as much as}} 80 percent of the total. Software problems are especially important at NASA as critical flight software must be error-free. It is shown that formal inspections are particularly effective at finding and removing defects having to do with clarity, correctness, consistency, and completeness. A very significant discovery was that code audits were not as effective at finding defects as code inspections...|$|R
50|$|For example, for <b>Fagan</b> <b>inspection,</b> the {{low-level}} document {{must comply}} with specific exit criteria (as specified in the high-level document) before the development process {{can be taken to}} the next phase.|$|E
5000|$|Although the <b>Fagan</b> <b>Inspection</b> {{method has}} been proved to be very effective, {{improvements}} have been suggested by multiple researchers. Genuchten for example has been researching the usage of an Electronic Meeting System (EMS) to improve the productivity of the meetings with positive results [...] 1997.|$|E
50|$|Inspection in {{software}} engineering, refers to peer review of any work product by trained individuals who look for defects using a well defined process. An inspection {{might also be}} referred to as a <b>Fagan</b> <b>inspection</b> after Michael Fagan, the creator of a very popular software inspection process.|$|E
30|$|According to (<b>Fagan</b> 1976), an <b>inspection</b> is a {{particular}} type of review that follows a well-defined and rigorous process to evaluate artifacts produced in software projects (<b>Fagan</b> 1976). Thus, <b>Inspection</b> and Review can both refer to the Review process. On analyzing the measures related to these processes in (Brito and Barcellos 2016), we noticed that all the measures could be related to the Review process. Therefore, we decided to eliminate the Inspection process and link the measures related to Inspection in (Brito and Barcellos 2016) to Review.|$|R
40|$|Abstract: Telecommunication {{software}} {{is expected to}} have a long lifespan during which many developers will add new features, modify existing features, or correct bugs. The software must be understandable, reliable, and maintainable otherwise the additions and modifications will take longer to develop and introduce further errors. Siemens has a software development process, which includes <b>Fagan</b> <b>inspections,</b> module testing, integration testing, internal, and customer field trials. The Quality Plan for a large software development stated that the developed software will be subject to either “ 100 % code reviews and normal levels of testing ” or “No code reviews and 100 % testing”. This paper tries to determine whether “ 100 % testing with no code reviews ” is a viable alternative to “ 100 % code reviews with testing ” for commercial software products. It provides a case study of a recently developed application that was subject to “ 100 % testing and no code reviews”. It uses a commercial tool to demonstrate the test coverage...|$|R
40|$|<b>Fagan</b> <b>inspections</b> are a {{structured}} review of development documents {{that consists of}} individual preparation, a meeting and rework {{by the author of}} the document. The meeting is used to log the defects found in preparation and to search for more defects. The effectiveness and eficiency of the meeting is typical & low as compared to that of the preparation. This paper describes the use of an EMS to support the logging meeting of a total of 14 electronic inspections in Philips Medical Systems and Baan Company. The results indicate that the electronic logging meeting contributed much more to the overall result of the inspection than was the case in a traditional inspection. The results have implications, both for the sojhvare inspections and EMS'. The implications for EMS as they are discussed in this paper are the increased use of meeting metrics, the use of inspections as a guinea pig and the benefits of fixed format input in an EMS. 1...|$|R
5000|$|A <b>Fagan</b> <b>inspection</b> is a {{structured}} {{process of trying}} to find [...] in development documents such as programming code, specifications, designs and others during various phases of the software development process. It is named after Michael Fagan, who is credited with being the inventor of formal software inspections.|$|E
50|$|In the {{follow-up}} {{phase of a}} <b>Fagan</b> <b>Inspection,</b> defects fixed in the rework phase should be verified. The moderator is usually responsible for verifying rework. Sometimes fixed work can be accepted without being verified, such as when the defect was trivial. In non-trivial cases, a full re-inspection is performed by the inspection team (not only the moderator).|$|E
50|$|Formal code review, {{such as a}} <b>Fagan</b> <b>inspection,</b> {{involves}} a careful and detailed process with multiple participants and multiple phases. Formal code reviews are the traditional method of review, in which software developers attend {{a series of meetings}} and review code line by line, usually using printed copies of the material. Formal inspections are extremely thorough and have been proven effective at finding defects in the code under review.|$|E
40|$|<b>Fagan</b> <b>inspections</b> are a {{structured}} review of software development documents {{that consists of}} individual preparation, a meeting and rework {{by the author of}} the document. The meeting is used to log the defects found in preparation and to search for more defects. The effectiveness and efficiency of the meeting is often low as compared to that of the preparation. This paper describes the results of the routine use of a Group Support System (GSS) to support inspections in the Baan Company. The results of 87 GSS inspections are compared to those of 102 traditional inspections. The results indicate that mature inspections show a higher effectiveness and efficiency if they are supported by a GSS. The difference is up to 40 percent, both in terms of Major defects per thousand lines of source code and in Major defects per person hour invested in preparation and logging. The benefit of using a GSS disappears, however, if the inspection process is not followed properly and the preparation rate is too high. The paper discusses the implications of these findings for both software engineering and GSS usage...|$|R
40|$|A Formal Inspection Technology Transfer Program, {{based on}} the {{inspection}} process developed by Michael Fagan at IBM, has been developed at JPL. The goal of this program is to support organizations wishing to use Formal Inspections {{to improve the quality}} of software and system level engineering products. The Technology Transfer Program provides start-up materials and assistance to help organizations establish their own Formal Inspection program. The course materials and certified instructors associated with the Technology Transfer Program have proven to be effective in classes taught at other NASA centers as well as at JPL. Formal <b>Inspections</b> (NASA tailored <b>Fagan</b> <b>Inspections)</b> are a set of technical reviews whose objective is to increase quality and reduce the cost of software development by detecting and correcting errors early. A primary feature of inspections is the removal of engineering errors before they amplify into larger and more costly problems downstream in the development process. Note that the word 'inspection' is used differently in software than in a manufacturing context. A Formal Inspection is a front-end quality enhancement technique, rather than a task conducted just prior to product shipment for the purpose of sorting defective systems (manufacturing usage). Formal Inspections are supporting and in agreement with the 'total quality' approach being adopted by many NASA centers...|$|R
40|$|This 288 -page {{study is}} one of the most {{comprehensive}} comparisons of the costs and benefits of software process improvement (SPI) methods to-date. It begins by exhibiting a comprehensive survey of software process improvement (SPI) literature, methods, approaches, metrics, costs and benefits, and existing comparisons. And, it concludes with the design of an in-depth return-on-investment (ROI) model, stunning breakeven analyses, and an extensible methodology for comparing software process improvement (SPI) cost and benefit data. It contains some very surprising results concerning the Personal Software Process (PSP), the Michael <b>Fagan</b> software <b>inspection</b> process, software reuse, defect prevention, software testing, cleanroom, Software Capability Maturity Model (SW-CMM or CMM), and ISO 9001...|$|R
40|$|This paper {{presents}} the results of an experiment that compared error detection capability of voting, instrumentation, and <b>Fagan</b> <b>inspection</b> methods. Several experiments have measured effectiveness of various error detection methods. However, most experiments have used different programs: consequently, the results are generally incompatible and do not allow one to make objective comparison on the cost-effectiveness of various approaches. No software can be developed using unlimited amount of resources, practitioners need empirical and objective data on the cost-effectiveness of various error detection methods to decide which methods to use during sojtware development. Results of this experiment is significant because these methods have been applied to the same program. Futhermore, the participant’s educational and industrial experience are comparable to that of the previous experiments [...] We conj 2 rmed the previous @ding that detecting errors in reliable programs is d. if$cult; none of the three methods detected {{more than half of all}} the known errors in the programs. Of the three methods employed, participants detected more errors by using <b>Fagan</b> <b>inspection</b> method than they did by voting or instrumentation. When the average number of hours needed to detect an error was compared, <b>Fagan</b> <b>inspection</b> method was shown to be more cost-effective than instrumentation method. 1...|$|E
40|$|In this paper, {{we explore}} why Fagan Inspections have become {{obsolete}} {{in the software}} industry, given the body of evidence which supports their use {{to improve the quality}} of software artefacts and the software development process. Since the late 1970 ’s, much has been written about how Fagan Inspections improve the quality of both processes and outputs of the software development process. The literature indicates that the <b>Fagan</b> <b>Inspection</b> technique can improve quality of software (or other software development artefacts) by a reduction in defects of 60 – 90...|$|E
40|$|This {{document}} {{contains the}} results of the final assessment of the PCIS Architecture documents PCIS Framework Definition and Rationale (DA 3) and PCIS Abstract Specification (DA 4). Keywords: Assessment, Completeness, Environments, <b>Fagan</b> <b>Inspection,</b> Framework, PCIS, PCTE, Project Support Environments(PSE), Risk Analysis, Scenario Analysis, Software Engineering, Structured Questionnaires, Traceability. NATO UNCLASSIFIED NATO UNCLASSIFIED This page intentionally blank NATO UNCLASSIFIED 3 of 180 PCIS Programme NATO UNCLASSIFIED FINAL Executive Summary (1) The architecture documents are globally compliant to the IRAC and to the ECMA/NIST Reference Model. While PCTE itself fulfills 55 % of the IRAC requirements completely or partially, the combination of PCIS and PCTE facilities covers 97 % of the requirements. (2) The architecture documents achieved a high level of quality. They provide sufficient rationale and enough examples for significant understandability and credibility. (3) Th [...] ...|$|E
40|$|Scenarios help {{practitioners}} {{to better understand}} the requirements of a software system as well as its interface with the environment. However, despite their widespread use both by object-oriented development teams and human [...] computer interface designers, scenarios are being built in a very ad-hoc way. Departing from the requirements engineering viewpoint, this article shows how inspections help software developers to better manage the production of scenarios. We used <b>Fagan</b> s <b>inspections</b> as the main paradigm in the design of our proposed process. The process was applied to case studies and data were collected regarding the types of problems as well as the effort to find them...|$|R
40|$|OVERVIEW: When {{learning}} defect detectors from static code measures, NaiveBayes learners {{are better}} than entrophy-based decision-tree learners. Also, accuracy is not a useful way to assess those detectors. Further, those learners need no more than 200 - 300 examples to learn adequate detectors, especially when the data has been heavily stratified; i. e. divided up into sub-sub-sub systems (and by “adequate”, we mean that those detectors perform nearly as well slower, more expensive manual inspections). The rest of this paper describes how we reached those conclusions after (i) an analysis of known baselines in the literature and (ii) a review of a assessment methods for detectors learned from the NASA defect logs of Figure 1. BASELINES: If defect detectors are interesting, they must somehow be better than known baselines in the literature. For example, consider manual code reviews. These reviews are labor intensive; depending on the methods, 8 to 20 LOC/minute can be inspected and this effort repeats for {{all members of the}} review team, which can be as large as four or six [5]. These reviews can also be effective. A recent panel at IEEE Metrics 2002 [6] concluded that such reviews can find ≈ 60 % of defects 1. That defect detection rate has a wide variance. Raffo found that the defect detection capability of industrial inspection methods can vary from T R(35, 50, 65) % 2 for full <b>Fagan</b> <b>inspections,</b> to T R(13, 21, 30) for some widely-used industrial practices. PUBLIC DOMAIN PROBLEMS: The data used in this study comes from the CM 1, JM 1, PC 1, KC 1 and KC...|$|R
40|$|Since their {{invention}} by <b>Fagan</b> in 1976, <b>inspections</b> {{proved to}} be an essential quality assurance technique in software engineering. Traditionally, inspections were used to detect defects in code documents, and later in requirements documents. However, not much is known how to apply inspections to design document. Statecharts are an important technique to describe the dynamic behavior of a software system. Thus, it is essential to define techniques for detecting defects in statechart models. In this report, checklists and reading scenarios are presented to support an inspector during defect detection for statecharts...|$|R
40|$|This {{document}} {{describes the}} assessment methodologies and assessment criteria {{to be used}} to assess the PCIS architecture documents. Keywords: Software Engineering Framework, PCIS, Assessment, Structured Questionnaires, <b>Fagan</b> <b>Inspection,</b> Risk Analysis, Completeness, Traceability, Scenario Analysis, PCTE. NATO UNCLASSIFIED NATO UNCLASSIFIED This page intentionally empty NATO UNCLASSIFIED 3 of 89 PCIS Programme NATO UNCLASSIFIED FINAL Acknowledgments (1) The work done by the PCIS assessment team was sponsored by NATO under the Special Working Group on Ada Project Support Environments. Work started in September 1992, and was completed in December 1993. (2) Funding from the US DoD (Ada Joint Program Office), UK MoD, NATO Communication and Information Systems Agency (NACISA), French MoD (Direction de l'Electronique et l'Informatique) and Italian MoD is gratefully acknowledged. (3) The following people have contributed to the assessment of the PCIS Framework: Mike BOYER, Audrey CANNING, [...] ...|$|E
40|$|Inspections, Reviews and walkthroughs {{are highly}} {{effective}} and efficient means for static software quality assurance. During {{the last three decades}} different variations and facets evolved on how to perform and apply such techniques, ranging from <b>Fagan</b> <b>inspection</b> over structured walkthroughs to Peer Reviews and simple Desk Checks. What is missing today is a systematic approach on how to select and apply the most appropriate technique under the consideration of the given development constraints and quality goals a company wants to achieve. This paper presents the first step towards a comprehensive planning framework for static quality assurance activities, i. e., the definition of a generic process that explicitly models the commonalities and variabilities of different techniques. The paper describes how such a process is defined by using concepts of product line engineering and how the generic process and a related decision model supports the selection of a technique...|$|E
40|$|Abstract: Software {{qualification}} {{includes such}} activities as a software Verification and Validation (V&V), a software safety analysis, a software configuration management and a {{software quality assurance}} for the safety-critical applications in Nuclear Power Plant (NPP). This paper presents the software qualification of a safety grade Programmable Logic Controller (PLC) which is applied to a Reactor Protection System prototype. The software V&V is characterized by defining the inputs, tasks, and outputs for all the software life cycle phases defined in the software V&V plan, and the V&V techniques such as a checklist-based review and the <b>Fagan</b> <b>Inspection,</b> a traceability analysis, a formal verification, and a software test are applied to improve the software quality. The software safety analysis process, which employs the HAZard OPerability (HAZOP) methodology, has been developed and applied to improve the software safety. All the software documents and source codes are managed as software configuration items throughout the software life cycle {{under the control of}} a software quality assurance plan and procedure. Automated software tools and a 3 rd part review also support the activities for the software qualification. Our experience shows that the software qualification is very efficient for systematically qualifying the safety-critical software of a PLC to be embedded in the safety-critical systems of a NPP, and they can be easily extended to other safety-critical applications such as in the railways, military, medicine, etc. Key-Words: Nuclear software qualification, software verification and validation, Software safety analysis...|$|E
40|$|In the {{embedded}} systems domain, statecharts {{have become an}} important technique to describe the dynamic behavior of a software system. In addition, statecharts are {{an important element of}} object-oriented design documents and are thus widely used in practice. However, not much is known about how to inspect them. Since their invention by <b>Fagan</b> in 1976, <b>inspections</b> proved to be an essential quality assurance technique in software engineering. Traditionally, inspections were used to detect defects in code documents, and later in requirements documents. In this report, we define a defect taxonomy for statecharts. Using this taxonomy, we present an inspection approach for inspecting statecharts, which combines existing inspection techniques with several new perspective-based scenarios. Moreover, we address the problems of inspecting large documents by using prioritized use cases in combination with perspective-based reading...|$|R

