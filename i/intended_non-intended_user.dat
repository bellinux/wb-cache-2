0|18|Public
40|$|Transmit {{beamforming}} is {{a versatile}} technique for signal transmission from {{an array of}} N antennas to one or multiple users [1]. In wireless communications, {{the goal is to}} increase the signal power at the intended user and reduce interference to <b>non-intended</b> <b>users.</b> A high signal power is achieved by transmitting the same data signal from all antennas, but with different amplitudes and phases, such that the signal components add coherently at the user. Low interference is accomplished by making the signal components add destructively at <b>non-intended</b> <b>users.</b> This corresponds mathematically to designing beamforming vectors (that describe the amplitudes and phases) to have large inner products with the vectors describing the intended channels and small inner products with <b>non-intended</b> <b>user</b> channels. If there is line-of-sight (LoS) between the transmitter and receiver, beamforming can be seen as forming a signal beam toward the receiver; see Figure 1. Beamforming can also be applied in non-LoS scenarios, if the multipath channel is known, by making the multipath components add coherently or destructively. Since transmit beamforming focuses the signal energy at certain places, less energy arrives to other places. This allows for so-called space-division multiple access (SDMA), where K spatially separated users are served simultaneously. One beamforming vector is assigned to each user and can be matched to its channel. Unfortunately, the finite number of transmit antennas only provides a limited amount o...|$|R
40|$|Transmit {{beamforming}} is {{a versatile}} technique for signal transmission from {{an array of}} $N$ antennas to one or multiple users [1]. In wireless communications, {{the goal is to}} increase the signal power at the intended user and reduce interference to <b>non-intended</b> <b>users.</b> A high signal power is achieved by transmitting the same data signal from all antennas, but with different amplitudes and phases, such that the signal components add coherently at the user. Low interference is accomplished by making the signal components add destructively at <b>non-intended</b> <b>users.</b> This corresponds mathematically to designing beamforming vectors (that describe the amplitudes and phases) to have large inner products with the vectors describing the intended channels and small inner products with <b>non-intended</b> <b>user</b> channels. While it is fairly easy to design a beamforming vector that maximizes the signal power at the intended user, it is difficult to strike a perfect balance between maximizing the signal power and minimizing the interference leakage. In fact, the optimization of multiuser transmit beamforming is generally a nondeterministic polynomial-time (NP) hard problem [2]. Nevertheless, this lecture shows that the optimal transmit beamforming has a simple structure with very intuitive properties and interpretations. This structure provides a theoretical foundation for practical low-complexity beamforming schemes. (See this lecture note for the complete abstract/introduction) Comment: Accepted for publication as lecture note in IEEE Signal Processing Magazine, 11 pages, 3 figures. The results can be reproduced using the following Matlab code: [URL]...|$|R
40|$|International audienceTransmit {{beamforming}} is {{a versatile}} technique for signal transmission from {{an array of}} N antennasto one or multiple users [1]. In wireless communications, {{the goal is to}} increase the signal power atthe intended user and reduce interference to <b>non-intended</b> <b>users.</b> A high signal power is achieved bytransmitting the same data signal from all antennas, but with different amplitudes and phases, suchthat the signal components add coherently at the user. Low interference is accomplished by making thesignal components add destructively at <b>non-intended</b> <b>users.</b> This corresponds mathematically to designingbeamforming vectors (that describe the amplitudes and phases) to have large inner products with thevectors describing the intended channels and small inner products with <b>non-intended</b> <b>user</b> channels. If there is line-of-sight (LoS) between the transmitter and receiver, beamforming can be seen as forminga signal beam toward the receiver; see Figure 1. Beamforming can also be applied in non-LoS scenarios,if the multipath channel is known, by making the multipath components add coherently or destructively. Since transmit beamforming focuses the signal energy at certain places, less energy arrives to otherplaces. This allows for so-called space-division multiple access (SDMA), where K spatially separatedusers are served simultaneously. One beamforming vector is assigned to each user and can be matchedto its channel. Unfortunately, the finite number of transmit antennas only provides a limited amount ofspatial directivity, which means that there are energy leakages between the users which act as interference. While it is fairly easy to design a beamforming vector that maximizes the signal power at the intendeduser, it is difficult to strike a perfect balance between maximizing the signal power and minimizingthe interference leakage. In fact, the optimization of multiuser transmit beamforming is generally anondeterministic polynomial-time (NP) hard problem [2]. Nevertheless, this lecture shows that the optimaltransmit beamforming has a simple structure with very intuitive properties and interpretations. Thisstructure provides a theoretical foundation for practical low-complexity beamforming schemes...|$|R
40|$|This study {{examines}} {{men and women}} intending entrepreneurs, who have graduated with an MBA from a top tier Business School. Entrepreneurs are compared to non-entrepreneurs {{for both men and}} women. A comparison between entrepreneurs and non-entrepreneurs with similar backgrounds allows for a more meaningful examination. The study focuses on career motivators of intending entrepreneurs and the findings both support and refute previous literature. Among the findings: intending women were not more dissatisfied with their careers, and they did possess different career motivators and intentions than women who were not likely to become entrepreneurs. The difference between <b>intending</b> and <b>non-intending</b> women matched a similar pattern between <b>intending</b> and <b>non-intending</b> men...|$|R
30|$|Technical-scientific dimension: ITA {{is always}} {{based on a}} {{technology}} to be assessed. Thus, analyses depend on this technical-scientific development, its benefits and problem-solving potential, just like the state of art, scientific evidence and the <b>intended</b> and <b>non-intended</b> consequences.|$|R
30|$|Furthermore, the inter-cell {{coordination}} in multi-cell massive MIMO {{systems is}} addressed in various works, either suppressing the inter-cell interference and inter-user interference completely [101] by coordinated beamforming. Another technique introduced in [102, 103] allows interference suppression with smaller excess of base station antennas. In [104], a multi-cell MIMO downlink channel is studied and a distributed interference alignment (IA) {{algorithm is proposed}} to suppress or minimize the interference to <b>non-intended</b> <b>users.</b> Also, [105] develops an IA technique for a downlink cellular system with CSI exchange and feedback within each cell. In [106, 107], conditions for the feasibility of IA and degree of freedom (DoF) for MIMO cellular networks are investigated.|$|R
30|$|The {{following}} medication {{information was}} collected: name of medicine, dose form, medication group [30], dose and frequency; prescribed in the PDMS within 24  h after admission; prescribed in the CPOE/CDS within 24  h after the ICU discharge. All discrepancies had an <b>intended</b> or <b>non-intended</b> score, a pADE score and a discrepancy type (omission, medication added, different dose or substitution).|$|R
40|$|As {{is known}} to all, the inter-cell {{interference}} of the cell-edge users in cellular network is serious which deteriorate the quality of communication to a great extent, so this study formulated a distributed, low system overhead linear precoding to solve this problem. It considered the downlink channel of a cellular broadband wireless system where base stations and users are assumed {{to have at least}} two antennas each and are scheduled based on fractional frequency reuse. Then, the study introduced a balancing algorithm which helps the adjacent base stations to simultaneously beamform to its own user while still minimizing the interference on the <b>non-intended</b> <b>user.</b> Finally, in this study, it also analyzed the degree of freedom can be achieved in the cellular network. The simulation results showed that this new scheme can improve the performance of the cell-edge user significantly while causing only a mild degradation in the performance of the in-cell users...|$|R
40|$|In this {{manuscript}} we tackle {{the problem of}} semi-distributed user selection with distributed linear precoding for sum rate maximization in multiuser multicell systems. A set of adjacent base stations (BS) form a cluster in order to perform coordinated transmission to cell-edge users, and coordination is carried out through a central processing unit (CU). However, the message exchange between BSs and the CU is limited to scheduling control signaling and no user data or channel state information (CSI) exchange is allowed. In the considered multicell coordinated approach, each BS has {{its own set of}} cell-edge users and transmits only to one intended user while interference to <b>non-intended</b> <b>users</b> at other BSs is suppressed by signal steering (precoding). We use two distributed linear precoding schemes, Distributed Zero Forcing (DZF) and Distributed Virtual Signal-to-Interference-plus-Noise Ratio (DVSINR). Considering multiple users per cell and the backhaul limitations, the BSs rely on local CSI to solve the user selection problem. First we investigate how the signal-to-noise-ratio (SNR) regime and the number of antennas at the BSs affect the effective channel gain (the magnitude of the channels after precoding) and its relationship with multiuser diversity. Considering that user selection must be based on the type of implemented precoding, we develop metrics of compatibility (estimations of the effective channel gains) that can be computed from local CSI at each BS and reported to the CU for scheduling decisions. Based on such metrics, we design user selection algorithms that can find a set of users that potentially maximizes the sum rate. Numerical results show the effectiveness of the proposed metrics and algorithms for different configurations of users and antennas at the base stations. Comment: 12 pages, 6 figure...|$|R
40|$|Abstract—Model Checking is an {{automated}} formal method for verifying whether a finite-state system satisfies a user-supplied specification. The {{usefulness of the}} verification result depends on how well the specification distinguishes <b>intended</b> from <b>non-intended</b> system behavior. Vacuity is a notion that helps formalize this distinction {{in order to improve}} the user’s understanding of why a property is satisfied. The goal {{of this paper is to}} expose vacuity in a property in a way that increases our knowledge of the design. Our approach, based on abstraction refinement, computes a maximal set of atomic subformula occurrences that can be strengthened without compromising satisfaction. The result is a shorter and stronger and thus, generally, more valuable property. We quantify the benefits of our technique on a substantial set of circuit benchmarks. I...|$|R
40|$|The {{available}} spectrum {{in cognitive}} radio networks is usually discontinuous but wide, which provides abundant frequency domain diversity. In this paper, we identify {{the opportunity of}} leveraging the newly-emerged technique interference alignment to exploit such diversity to support concurrent transmission and improve the network throughput in secondary networks. To enable interference alignment, independent-fading subcarriers should be grouped together to provide sufficient dimensions for <b>intended</b> signals and <b>non-intended</b> interferences at the receiver side. We formulate the subcarrier grouping problem for interference alignment to maximize the number of concurrent transmissions, and propose a greedy-based algorithm to solve it, which is proved to be optimal. Simulation results show that using the proposed scheme, the total throughput in cognitive radio networks can be greatly improved...|$|R
40|$|Using an {{in vitro}} selection, we have {{obtained}} oligonucleotide probes with high discriminatory power against multiple, similar nucleic acid sequences, {{which is often}} required in diagnostic applications for simultaneous testing of such sequences. We have tested this approach, referred to as iterative hybridizations, by selecting probes against six 22 -nt-long sequence variants representing human papillomavirus, (HPV). We have obtained probes that efficiently discriminate between HPV types that differ by 3 – 7 [*]nt. The probes were found effective to recognize HPV sequences of the type 6, 11, 16, 18 {{and a pair of}} type 31 and 33, either when immobilized on a solid support or in a reverse configuration, as well to discriminate HPV types from the clinical samples. This methodology can be extended to generate diagnostic kits that rely on nucleic acid hybridization between closely related sequences. In this approach, instead of adjusting hybridization conditions to the intended set of probe–target pairs, we ‘adjust’, through in vitro selection, the probes to the conditions we have chosen. Importantly, these conditions have to be ‘relaxed’, allowing the formation of a variety of not fully complementary complexes from which those that efficiently recognize and discriminate <b>intended</b> from <b>non-intended</b> targets can be readily selected...|$|R
40|$|Key message: Non-targeted {{metabolomics}} {{analysis revealed}} only intended metabolic changes in transgenic maize over-expressing the Aspergillus niger phyA 2. Abstract: Genetically modified (GM) crops {{account for a}} large proportion of modern agriculture worldwide, raising increasingly the public concerns of safety. Generally, according to substantial equivalence principle, if aGMcrop is demonstrated to be equivalently safe to its conventional species, {{it is supposed to be}} safe. In this study, taking the advantage of an established non-target metabolomic profiling platform based on the combination of UPLC-MS/MS with GC–MS, we compared the mature seed metabolic changes in transgenicmaize over-expressing the Aspergillus niger phyA 2 with its non-transgenic counterpart and other 14 conventional maize lines. In total, levels of nine out of identified 210 metabolites were significantly changed in transgenic maize as compared with its non-transgenic counterpart, and the number of significantly altered metabolites was reduced to only four when the natural variations were taken into consideration. Notably, those four metabolites were all associated with targeted engineering pathway. Our results indicated that although both <b>intended</b> and <b>non-intended</b> metabolic changes occurred in the mature seeds of this GM maize event, only intended metabolic pathway was found to be out of the range of the natural metabolic variation in the metabolome of the transgenic maize. Therefore, only when natural metabolic variation was taken into account, could non-targeted metabolomics provide reliable objective compositional substantial equivalence analysis on GM crops. Jun Rao, Litao Yang, Jinchao Guo, Sheng Quan, Guihua Chen, Xiangxiang Zhao, Dabing Zhang, Jianxin Sh...|$|R
40|$|New {{knowledge}} {{generated by}} an economic agent {{in a region}} will tend over time to flow to other economic agents in the same region but also to economic agents in other regions. It is quite common in the literature to use the concept of knowledge spillovers for such knowledge flows, irrespective of whether they are <b>intended</b> or <b>non-intended.</b> The potential for intra-re-gional knowledge spillover effects depends on the volume and character of the generation on new knowledge in each region {{as well as of}} the general characteristics of the individual re-gional economic milieu, i. e., those location attributes, which are regionally trapped and which include how well integrated it is with other regions. The larger this potential, the higher the probability that firms dependent upon knowledge spillovers will locate there and the higher probability that entrepreneurs will take advantage of this potential to launch innovations and to create new knowledge-based firms. To the extent that firms and entrepreneurs can enjoy these knowledge spillovers, they represent an externality or more specifically a knowledge externality in the regional economy. Great importance is in the literature attributed to knowledge spillovers and knowledge exter-nalities as drivers of regional economic development. Some authors, for example, claim that regional variations in localised knowledge spillovers are one of the main reasons behind re-gional variations in innovation performance. Against this background, the purpose of this chapter is, based upon a general characterization of knowledge flows, to analyse the character of knowledge externalities and, in particular, their sources, their economic nature, their recipients, their mechanisms and channels, their geographic reach, and their economic conse-quences generally and for regional economic development in particular. Knowledge flows; Knowledge externalities; Knowledge spillovers; Regional growt...|$|R
40|$|The {{demand for}} {{wireless}} {{services and the}} need for high data-rates are growing rapidly. Future generation networks are expected to provide high data-rates in the order of 1 Gbps in local area and 100 Mbps in wide area. It is a challenge for operators to meet this rising demand for high data-rates as the radio-spectrum is an expensive and scarce resource. In the last World Radio Communication conference (WRC' 07), less than 600 MHz bandwidth has been allocated to mobile communication systems. When considering the total predicted bandwidth demand of 1200 MHz - 1700 MHz in 2020, it is clear that there is a spectrum scarcity for mobile communication systems. This scarcity arises due to the exclusive allocation of the spectrum among different Radio Transmission Systems (RTS). A further exclusive splitting of spectrum among different operators leads to an apparent scarcity of the resources. While doing so, it should be clear that no operator will suffice in its own to meet the rising demand for high data-rates, when the current traditional way of spectrum utilization continues. Based on the arguments mentioned, the idea of spectrum sharing was born. When the operators share their licensed spectrum bands, they simply will reach higher bandwidths, the spectrum will always be utilized when an operator does not utilize it. Spectrum sharing among cellular operators introduces a new concept of Inter-Operator Interference (Inter-OI). Interference which is a natural result of operating in the same common spectrum band limits the capacity obtained from the spectrum. Therefore, it should be mitigated in an intelligent way. As opposed to other interference generation mechanisms known in wireless-networking, Inter-OI is a problem of two independent networks with conflicting objectives on the common resource. When this conflict is not solved, the advantages may turn into disadvantages. To solve the Inter-OI in the uplink and downlink of the involved cellular networks, there are some considerations that one has to take into account. First of all, information exchange: How much information can we gather about the interfering signals? There are two extreme cases possible: When we do not know anything about the interfering signals, we can make a Gaussian Random Signal Approximation which is not a realistic model of Inter-OI as it can be more severe due to the overlapping-cells of two different cellular networks. When we could get the whole interfering signal structure, we could jointly construct the signal or pre-cancel it in a multi-cell processing-fashion. However, due to the limited information exchange capability of the operators, full information exchange is not desirable. Once the exchangeable amount of information is fixed, the solution should provide enough efficiency to satisfy the operators above their non-sharing case. Furthermore, the solution should provide fairness among the operators. Of course, all should occur within an acceptable complexity. In this thesis, to cover the considerations mentioned above, a possible solution for the uplink-problem has been proposed by the means of a receive-beamforming approach for which the basestations need the Channel State Information (CSI) of the direct channels to their intended users and crosstalk channels to their <b>non-intended</b> <b>users.</b> To capture the needed CSI in this heterogeneous environment, the mobile terminals have been given user-specific pilots which are recognized by the basestations. For this approach, registration to both operators is required in order to capture the CSI while the users get the service from their own operator. For the downlink case, a transmit-beamforming approach has been proposed. The downlink-part of the problem is different. In this case, there are two base-stations, two decision-makers with conflicting objectives. Resource sharing problems with multiple decision-makers are subjected to Game Theory of the Applied Mathematics. Game Theory provides tools to predict the results of selfish and cooperative actions in a resource sharing problem. Instead of applying their best-response strategies selfishly, this thesis has proposed to apply SLNR-based beamforming for the beamforming-dimension of the problem and to apply the power levels in a leader-follower relationship as described in the literature. The needed objective functions have been constructed for the leader operator and follower operator by the means of capacity functions and have been solved as a non-convex optimization problem. The proposed approach has been simulated in a realistic scenario with i. i. d. Rayleigh Fading. The results {{have been shown to be}} satisfactory in comparison to the non-sharing case qua efficiency and fairness. Wireless and Mobile CommunicationsTelecommunicationsElectrical Engineering, Mathematics and Computer Scienc...|$|R
40|$|This thesis {{offers an}} {{analysis}} of Phnom Penh`s urban space in the longue durée, examining the concurrence of planning ‘from above’ and spontaneous order ‘from below’. By privileging the spatial point of view, the investigation attempts to overcome the false dichotomy of ‘planned’ versus ’unplanned’ order in urban development. Using Phnom Penh as a case-study for city development in a pre-colonial, colonial and post-colonial context, the production of space as a social process is identified in two ways: first ‘literally’ by a historical-critical analysis of the chronological course of urban construction based on archival records and, second, ‘visually’ by scrutinizing master and city plans as well as photographical veduta (i. e. aerial and satellite photography, photos of cityscapes or other relevant urban situations) of past and present. Structure: The thesis consists of five chapters (A-E), organised in three parts (Erster, Zweiter, Dritter Teil). After an introductory chapter (A), dealing with the research topic in general, the first part (chapters B-C) of the investigation follows a morphological approach. It presents the local building and historical town planning traditions of the lower Mekong region in pre-historical times onwards, analysing the pre-colonial times, followed by the French colonial era. The second part (chapter D) deals with the local development during the Cold War, subdivided in two distinct phases: the independence of decolonization (1954 - 1970 s) and {{the civil war and}} Khmer Rouge-time (1970 s- 1989). The third part (chapter E) specifically examines the situation {{after the fall of the}} Pol Pot-regime: the ‘new’ independence after the Vietnamese and UN-intervention. The appendix is ex-tensive, but ‘tailor-made’ providing datasheets and detailed background information, e. g. on climate, to allow the interested reader to further deepen some topics. Research questions: Three questions run like a thread through the thesis as recurrent themes: (1) To what extent is the city development a ‘planned’ or ‘unplanned’ process, and which interactions between the two dynamics can be discerned? (2) What power politics from ‘above’ and ‘below’ make up the political economy of space? (3) What kind of continuities and discontinuities can be identified as persistency and change in the cityscape? Social engineering projects ‘from above’ (by diverse governments and power groups) have continuously been challenged, partly evaded and actively counteracted in their own interest ‘from below’ (by the ‘common man’, informal settlers), thus characterizing the social space of Phnom Penh as a ‘common field of action’ (gemeinsamer Aktionsraum). Since colonial times, the physical engineering of space (aligning the urban morphology into a grid-pattern; dividing the city space in [marketable] plots) has been both a transfer from abroad and a quasi-continuity of local proceedings in urban construction. From thispoint of view the transformation of the royal residence-town into a colonial city and the subsequent change from a colonial administration centre of lesser importance within the French Indochinese Union to a dominant capital city of an independent state are revealing a complex pattern of competing interests of all ‘spatial’ actors: rich and poor, mighty and weak, officials and individuals, military and civilian, singles and families. Attempts of social engineering by the use of the built environment and the imple-mentation of physical change to it, however, have also been producing ‘frictions’ (Friktionen) ever since. As result, a third degree of order, besides the <b>intended</b> and <b>non-intended,</b> has emerged: epiphenomena (Epiphänomene; Phänomene der dritten Art). The self-organisation through the ‘auto-agglomeration’ of businesses during the resettlement process after the fall of the Khmer Rouge is examined as an example for this kind of spatial (re) ordering. Concluding the longue durée-analysis of Phnom Penh, the spatial distribution is analysed and presented in full detail as economy of espionage and imitation in chapter (E). Methodology: In order to achieve the primary object of this undertaking to write a historical geography of the production of Phnom Penh’s space, a multidisciplinary approach was necessary, combining historical-critical analysis (Historisch-kritische Methode); geography (spatial analysis, urban morphology) and sociology (questionnaires and interviews, ‘observing participation’). The very heterogeneous mixture of archival sources and newly generated data that informs this study required a reflexive grounded theory...|$|R
40|$|Transgenic animals play an {{important}} role in biomedical research. Their use as animal model is still increasing. Although the process of transgenesis may contribute to refinement of animal use, the application of the biotechnological procedures that are involved in the production of transgenic animals may also cause unexpected, uncontrolled, and even undetected animal suffering. Therefore, the aim of the present thesis was to study the effects of the biotechnological procedures involved in genetic modification on the welfare of the resulting offspring. The two most frequently used techniques for inserting new genetic material into the mammalian germ line, pronuclear microinjection and embryonic stem (ES) cell-mediated gene transfer, have been studied. Different groups of mice were generated, each of which had undergone different aspects of the microinjection technique (Chapters 2 and 3) or of the gene targeting technique (Chapters 4 and 5), in order to determine whether the specific manipulations have any effect on the development or behaviour of the progeny. In this way, the effects of microinjection, electroporation, embryo-culture or embryo transplantation on the development of (chimeric) mice could be studied separately. All mice of the different groups were tested in their pre-weaning (0 - 3 weeks of age) and post-weaning period (4 - 30 weeks of age) for behavioural and morphological/physiological development and for clinical appearance. Thereafter, post-mortem examinations were performed. In addition, the feasibility of the use of score sheets for monitoring the welfare of transgenic mice, as part of the daily care of animals, has been explored (Chapter 6). With both techniques, the biotechnological procedures increased (perinatal) pup mortality and body weight. In addition, with the gene targeting technique, 8 % of the chimeric animals was hermaphrodite. The results so far indicate that, under the present conditions, the biotechnological procedures (microinjection; in vitro culture; embryo transfer) mainly affect the viability of the embryos and seem to have no major effects on the development and behaviour of mice that survive the first 2 - 3 days after birth. However, before drawing general conclusions, more and different transgenic lines should be studied in a comparable way. A scoring system has been developed, containing a limited number of sensitive, easy to determine and non-invasive parameters, selected from our previous studies on implications of transgenesis for the well-being of mice. The feasibility of this scoring system has been tested, to assess the use of score sheets for monitoring the welfare of transgenic mice on a practical basis, as part of the animal technicians daily routine in a transgenic unit. It has been found to be both practical and useful. Therefore, in the production of transgenic animals, the use of score sheets is recommended, in order to detect both the <b>intended</b> and the <b>non-intended</b> (side) effects of the introduced or mutated gene at an early stage of development...|$|R
40|$|The thesis scrutinizes an {{emerging}} phenomenon in international relations: {{the increase in}} functional overlaps among international regimes. I approach this young field of study in three consecutive parts. The first part conceptualizes regime overlaps as ‘regime conflicts’. Following a broad sociological understanding of ‘conflict’, I define a regime conflict as an overlap among two or more international regimes, consisting of a significant contradiction of rules and / or rule-related behavior. This contradiction {{is based on a}} positional difference among actors over contested issues which fall into the jurisdictions of the involved regimes. I then develop an encompassing typology of regime conflicts. Two primary criteria target the behavioral nature of a conflict (latent or manifest) and the permissive or prohibitive character of the colliding rules (direct or indirect). Two sets of secondary criteria are: a) properties of the affected regimes: functions of the colliding rules (constitutive or operational); problem structures (single-domain or cross-domain); geographical scopes (global or regional); b) properties of the conflicts i. e. the positional difference: conflict arena (regime-internal or regime-external); conflict parties (governments, bureaucracies and / or non-state actors); intentionality (<b>intended</b> or <b>non-intended).</b> I illustrate the resulting types and sub-types with a series of brief case descriptions of conflicts among environmental and trade regimes. The first part concludes with definitions of two further terms, conflict transformation and conflict management. The second part establishes a theoretical framework to study the consequences of regime conflicts for the involved regimes. I adopt two independent variables from major theories of international regimes: the power structure and the knowledge structure in which the competing regimes are embedded. The dependent variable, regime prevalence, is framed as the stronger development of output (i. e. norms and rules) on the matters that are contested among the regimes. This prevalence is not only signaled by the output that the colliding regimes themselves produce, but also by rules and norms developed in third international institutions (inasmuch as they concern the contested issues). Indicators for the quality of output are its degrees of stringency, delegation and inclusiveness, the latter carrying the most weight. I introduce four context variables. The ‘conflict structure’ comprises the problem and situation structures of the contested issues. A benign conflict structure can support the causal effects of both independent variables, while a malign one may obstruct these effects. Another context variable, the decision structures of the colliding regimes, may only modify the consequences of the power structure. In turn, two other factors can alter the effects of the knowledge structure: the demand from regime parties for scientific input on the contested issue(s) as well as the openness of the involved regimes to scientific advice. Based on these various context factors, the independent and dependent variables, and the assumed causalities among them, I introduce two configurational hypothesis: 1. on the effect of the power structure, holding that, if context factors are favorable, the regime supported by the most powerful coalition of countries will prevail; 2. on the effect of the knowledge structure, holding that, if context factors are favorable, the regime supported by the stronger and more wide-spread basis of knowledge will prevail. I then establish conflict management as an intervening variable and discuss the causal mechanisms underlying the two hypotheses. Finally, two rival explanations are introduced: bureaucratic authority and leadership; and the influence of transnational civil society and business actors. Altogether, these elements constitute a three-layered research design to test the two hypotheses through 1. covariation analysis (of independent, dependent and context variables); 2. process analysis (of intervening variable and causal mechanisms); and 3. analysis of rival explanations. For the application of this framework, I choose the conflict between the UN climate regime and the world trade regime. I identify two major sets of contested issues among both regimes: trade-related policies and measures; and trade in emission allowances. The key finding of the in-depth analysis in the third part of the thesis is: the most powerful coalition of countries, led by the US, predominantly shaped the consequences of the regime conflict under scrutiny – leading to the prevalence of the World Trade Organization. The power-based hypothesis is confirmed in every analytical step, whereas the knowledge-based hypothesis does not pass the first hurdle of the covariation test. In the conclusions, I review these results and translate them into policy propositions: two options for issue-linking which could revive currently stalled management efforts for the climate-trade conflict...|$|R

