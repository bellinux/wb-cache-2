819|144|Public
5|$|The {{origins of}} {{philosophy}} of science trace back to Plato and Aristotle who distinguished {{the forms of}} approximate and exact reasoning, set out the threefold scheme of abductive, deductive, and <b>inductive</b> <b>inference,</b> and also analyzed reasoning by analogy. The eleventh century Arab polymath Ibn al-Haytham (known in Latin as Alhazen) conducted his research in optics by way of controlled experimental testing and applied geometry, especially in his investigations into the images resulting from the reflection and refraction of light. Roger Bacon (1214–1294), an English thinker and experimenter heavily influenced by al-Haytham, is recognized {{by many to be}} the father of modern scientific method. His view that mathematics was essential to a correct understanding of natural philosophy was considered to be 400 years ahead of its time.|$|E
25|$|Algorithmic IQ, or AIQ for short, is {{an attempt}} to convert the {{theoretical}} Universal Intelligence Measure from Legg and Hutter (based on Solomonoff's <b>inductive</b> <b>inference)</b> into a working practical test of machine intelligence.|$|E
25|$|Jürgen Schmidhuber (2000–2002) {{points out}} that Ray Solomonoff's theory of {{universal}} <b>inductive</b> <b>inference</b> and its extensions already {{provide a framework for}} maximizing our confidence in any theory, given a limited sequence of physical observations, and some prior distribution on the set of possible explanations of the universe.|$|E
40|$|In {{a formal}} theory of induction, <b>inductive</b> <b>inferences</b> are {{licensed}} by universal schemas. In a material theory of induction, <b>inductive</b> <b>inferences</b> are licensed by facts. With {{this change in}} the conception {{of the nature of}} induction, I argue that Hume’s celebrated “problem of induction” can no longer be set up and is thereby dissolved...|$|R
40|$|On {{the basis}} of the {{distinction}} between logical and factual probability, epistemic justification is distinguished from logical justification of induction. It is argued that, contrary to the accepted interpretation of Hume, Hume believes that <b>inductive</b> <b>inferences</b> are epistemically legitimate and justifiable. Hence the beliefs arrived at via (correct) <b>inductive</b> <b>inferences</b> are rational beliefs. According to this interpretation, Hume is not a radical skeptic about induction...|$|R
40|$|Past {{research}} suggests inductive judgments are made via simply assessing feature similarity (Osherson et al, 1990) while other research (Gelman & Markman, 1986) proposed that category labels convey information beyond other features. To further investigate these claims, we developed an online measure of decision-making. The present study examines how category labels affect <b>inductive</b> <b>inferences</b> {{by using a}} method akin to eye-tracking. The judgment results and the tracking data jointly {{support the view that}} category labels do affect <b>inductive</b> <b>inferences</b> in a way uniquely distinct from other feature information. Conceptual categories such as animal, vegetable, and furniture are the basis of <b>inductive</b> <b>inferences.</b> For example, given a concept vegetable, we are able to infer its taste an...|$|R
25|$|Around 1960, Ray Solomonoff {{founded the}} theory of {{universal}} <b>inductive</b> <b>inference,</b> {{the theory of}} prediction based on observations; for example, predicting the next symbol based upon a given series of symbols. The only assumption is that the environment follows some unknown but computable probability distribution. This theory is a mathematical formalization of Occam's razor.|$|E
25|$|The p-value was devised as an informal, but objective, index {{meant to}} help a {{researcher}} determine (based on other knowledge) whether to modify future experiments or strengthen one's faith in the null hypothesis. Hypothesis testing (and Type I/II errors) was devised by Neyman and Pearson as a more objective alternative to Fisher's p-value, also meant to determine researcher behaviour, but without requiring any <b>inductive</b> <b>inference</b> by the researcher.|$|E
25|$|The {{minimum message length}} {{principle}} of statistical and <b>inductive</b> <b>inference</b> and machine learning was developed by C.S. Wallace and D.M. Boulton in 1968. MML is Bayesian (i.e. it incorporates prior beliefs) and information-theoretic. It has the desirable properties of statistical invariance (i.e. the inference transforms with a re-parametrisation, such as from polar coordinates to Cartesian coordinates), statistical consistency (i.e. even for very hard problems, MML will converge to any underlying model) and efficiency (i.e. the MML model will converge to any true underlying model about as quickly as is possible). C.S. Wallace and D.L. Dowe (1999) showed a formal connection between MML and algorithmic information theory (or Kolmogorov complexity).|$|E
40|$|It is {{notoriously}} difficult {{to spell out}} the norms of inductive reasoning in a neat set of rules. I explore the idea that explanatory considerations {{are the key to}} sorting out the good <b>inductive</b> <b>inferences</b> from the bad. After defending the crucial explanatory virtue of stability, I apply this approach to a range of <b>inductive</b> <b>inferences,</b> puzzles, and principles such as the Raven and Grue problems, and the significance of varied data and random sampling...|$|R
40|$|Abstract In {{a formal}} theory of induction, <b>inductive</b> <b>inferences</b> are {{licensed}} by universal schemas. In a material theory of induction, <b>inductive</b> <b>inferences</b> are licensed by facts. With {{this change in}} the conception {{of the nature of}} induction, I argue that the celebrated “problem of induction ” can no longer be set up and is thereby dissolved. Attempts to recreate the problem in the material theory of induction fail. They require relations of inductive support to conform to an unsustainable, hierarchical empiricism...|$|R
40|$|Children’s {{understanding}} of race constancy and their subsequent use of {{race as a}} means of drawing <b>inductive</b> <b>inferences</b> were investigated. Race constancy was determined by children’s tendency to say that people could change category membership by changing their outside appearance. A second phase of the study measured how many race-based inferences children made relative to other social categories such as age or sex. The results indicated that children who had a better {{understanding of}} race constancy {{were also more likely to}} use race {{as a means of}} drawing <b>inductive</b> <b>inferences.</b> These findings support a developmental progression of race constancy and give insight to the development of potential bias and stereotypes...|$|R
2500|$|Significance {{testing is}} largely {{the product of}} Karl Pearson (p-value, Pearson's chi-squared test), William Sealy Gosset (Student's t-distribution), and Ronald Fisher ("null hypothesis", {{analysis}} of variance, [...] "significance test"), while hypothesis testing was developed by Jerzy Neyman and Egon Pearson (son of Karl). Ronald Fisher began his life in statistics as a Bayesian (Zabell 1992), but Fisher soon grew disenchanted with the subjectivity involved (namely use {{of the principle of}} indifference when determining prior probabilities), and sought to provide a more [...] "objective" [...] approach to <b>inductive</b> <b>inference..</b>|$|E
2500|$|The theorem says that, among {{algorithms}} that decode strings {{from their}} descriptions (codes), there exists an optimal one. This algorithm, for all strings, allows codes {{as short as}} allowed by any other algorithm up to an additive constant {{that depends on the}} algorithms, but not on the strings themselves. Solomonoff used this algorithm, and the code lengths it allows, to define a [...] "universal probability" [...] of a string on which <b>inductive</b> <b>inference</b> of the subsequent digits of the string can be based. Kolmogorov used this theorem to define several functions of strings, including complexity, randomness, and information.|$|E
2500|$|Mill's {{empiricism}} thus {{held that}} knowledge {{of any kind}} is not from direct experience but an <b>inductive</b> <b>inference</b> from direct experience. [...] The problems other philosophers have had with Mill's position center around the following issues: Firstly, Mill's formulation encounters difficulty when it describes what direct experience is by differentiating only between actual and possible sensations. [...] This misses some key discussion concerning conditions under which such [...] "groups of permanent possibilities of sensation" [...] might exist in the first place. [...] Berkeley put God in that gap; the phenomenalists, including Mill, essentially left the question unanswered. In the end, lacking an acknowledgement of an aspect of [...] "reality" [...] that goes beyond mere [...] "possibilities of sensation", such a position leads to a version of subjective idealism. Questions of how floor beams continue to support a floor while unobserved, how trees continue to grow while unobserved and untouched by human hands, etc., remain unanswered, and perhaps unanswerable in these terms. Secondly, Mill's formulation leaves open the unsettling possibility that the [...] "gap-filling entities are purely possibilities and not actualities at all". [...] Thirdly, Mill's position, by calling mathematics merely another species of <b>inductive</b> <b>inference,</b> misapprehends mathematics. [...] It [...] fails to fully consider the structure and method of mathematical science, the products of which are arrived at through an internally consistent deductive set of procedures which do not, either today or at the time Mill wrote, fall under the agreed meaning of induction.|$|E
40|$|Peirce notes (CP 2. 753) {{that there}} are certain forms of {{evolutionary}} constraints that delimit the vast class of human <b>inductive</b> <b>inferences.</b> The paper focuses on the problem of projectible properties which is analyzed in relation to modern cognitive science. In particular, the notion of a conceptual space is introduced and it is shown how this can be used to identify projectible properties. Furthermore, I outline how the so called prototype theory of concept formation can be interpreted in terms of conceptual spaces. The evolutionary origin of conceptual spaces is discussed. It is argued that the emerging picture of which predicates can be used in <b>inductive</b> <b>inferences</b> can be seen as an elaboration of Peirce's views...|$|R
40|$|Although {{our work}} does not {{directly}} {{address the question of}} learning through imitation, we believe it is relevant to this workshop as it addresses the question of how agents should exchange <b>inductive</b> <b>inferences.</b> Our approach can be extended to include Explanation Based Learning, which is conceptually close to learning through imitation. Our work was motivated by a lack of support for machine learning capabilities in agent communication languages such as KQML, Agent- 0 and FIPA. The requirements were that such any extension to these communication languages should allow heterogeneous inductive algorithms to interact on a principled, consistent basis and that the <b>inductive</b> <b>inferences</b> being communicated should not be able to introduce unsoundness into the agent community. Our approach is founded on using the version space model of inductive learning...|$|R
40|$|Recent {{research}} suggests that adults utilize thematic relations as well as taxonomic relations for guiding <b>inductive</b> <b>inferences,</b> and that thematic relations grow in salience with experience in a given domain. The present study examines the impact of experience on the salience of thematic versus taxonomic inferences. 151 kindergarten through sixth-grade children from urban, suburban, and rural communities in New England were given a forced choice triad induction task requiring them to project a novel internal substance or disease from a base species to a taxonomically or ecologically related target. Results indicate clear evidence of inductive selectivity; children projected insides taxonomically and disease ecologically, both at above-chance levels. Moreover, ecological projections of disease were more likely for older children and for children from more rural communities. Overall, results suggest that for children, like adults, experience renders non-taxonomic relations salient for selectively guiding <b>inductive</b> <b>inferences...</b>|$|R
2500|$|According to Jürgen Schmidhuber, the {{appropriate}} mathematical theory of Occam's razor already exists, namely, Solomonoff's theory of optimal <b>inductive</b> <b>inference</b> and its extensions. See discussions in David L. Dowe's [...] "Foreword re C. S. Wallace" [...] for the subtle {{distinctions between the}} algorithmic probability work of Solomonoff and the MML work of Chris Wallace, and see Dowe's [...] "MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness" [...] both for such discussions and for (in section 4) discussions of MML and Occam's razor. For a specific example of MML as Occam's razor in the problem of decision tree induction, see Dowe and Needham's [...] "Message Length as an Effective Ockham's Razor in Decision Tree Induction".|$|E
2500|$|Advocates of a Bayesian {{approach}} sometimes {{claim that}} the goal of a researcher is most often to objectively assess the probability that a hypothesis is true based on the data they have collected. [...] Neither Fisher's significance testing, nor Neyman–Pearson hypothesis testing can provide this information, and do not claim to. The probability a hypothesis is true can only be derived from use of Bayes' Theorem, which was unsatisfactory to both the Fisher and Neyman–Pearson camps due to the explicit use of subjectivity {{in the form of the}} prior probability. Fisher's strategy is to sidestep this with the p-value (an objective index based on the data alone) followed by <b>inductive</b> <b>inference,</b> while Neyman–Pearson devised their approach of inductive behaviour.|$|E
2500|$|Many of {{the proponents}} of this {{resolution}} and variants of it have been advocates of Bayesian probability, {{and it is now}} commonly called the Bayesian Solution, although, as Chihara observes, [...] "there {{is no such thing as}} the Bayesian solution. There are many different 'solutions' that Bayesians have put forward using Bayesian techniques." [...] Noteworthy approaches using Bayesian techniques include Earman, Eells, Gibson, Hosiasson-Lindenbaum, Howson and Urbach, Mackie, and Hintikka, who claims that his approach is [...] "more Bayesian than the so-called 'Bayesian solution' of the same paradox". Bayesian approaches that make use of Carnap's theory of <b>inductive</b> <b>inference</b> include Humburg, Maher, and Fitelson et al. Vranas introduced the term [...] "Standard Bayesian Solution" [...] to avoid confusion.|$|E
5000|$|The term {{deductive}} {{distinguishes the}} DN model's intended determinism from the probabilism of <b>inductive</b> <b>inferences.</b> [...] The term nomological {{is derived from}} the Greek word νόμος or nomos, meaning [...] "law". The DN model holds to a view of scientific explanation whose conditions of adequacy (CA)—semiformal but stated classically—are derivability (CA1), lawlikeness (CA2), empirical content (CA3), and truth (CA4).|$|R
5000|$|Fourthly, {{the process}} of {{learning}} involves the generation of expectations, which are the basis of the projectability of the class terms, {{in such a way that}} in their turn they form the basis of, among other things, <b>inductive</b> <b>inferences.</b> And lastly, as the criteria for relating the class and its reference vary, this forms the way of learning the subject matter.|$|R
30|$|Ward (2009) {{recently}} critically {{reviewed the}} role of Hill’s “criteria” and argued {{that they are not}} appropriate for either deductive or <b>inductive</b> <b>inferences</b> but that they have an important role to play in abductive inferences to the best explanation. This conclusion clearly places the commonly used Bradford Hill “criteria” within a realist epistemology and therefore appropriate for assessment of the theories constructed in this study.|$|R
2500|$|Medieval {{writers such}} as al-Ghazali and William of Ockham {{connected}} the problem with God's absolute power, asking how we can be certain that the world will continue behaving as expected when God could at any moment miraculously cause the opposite. Duns Scotus however argued that <b>inductive</b> <b>inference</b> from {{a finite number of}} particulars to a universal generalization was justified by [...] "a proposition reposing in the soul, 'Whatever occurs in a great many instances by a cause that is not free, is the natural effect of that cause. Some 17th-century Jesuits argued that although God could create {{the end of the world}} at any moment, it was necessarily a rare event and hence our confidence that it would not happen very soon was largely justified.|$|E
2500|$|Hume's {{solution}} to this problem is to argue that, rather than reason, natural instinct explains the human practice of making inductive inferences. He asserts that [...] "Nature, by an absolute and uncontroulable [...] necessity has determin'd us to judge as well as to breathe and feel." [...] Agreeing, philosopher John D. Kenyon writes: [...] "Reason might manage to raise a doubt about the truth of a conclusion of natural <b>inductive</b> <b>inference</b> just for a moment... but the sheer agreeableness of animal faith will protect us from excessive caution and sterile suspension of belief." [...] Commentators such as Charles Sanders Peirce have demurred from Hume's solution, while, some, such as Kant and Karl Popper, saw that Hume's analysis [...] "had posed a most fundamental challenge to all human knowledge claims." ...|$|E
2500|$|Critics {{have argued}} that Hume's {{position}} assumes the character of miracles and natural laws prior to any specific examination of miracle claims, thus it amounts to a subtle form of begging the question. To assume that testimony is a homogeneous reference group seems unwise- to compare private miracles with public miracles, unintellectual observers with intellectual observers {{and those who have}} little to gain and much to lose with those with much to gain and little to lose is not convincing to many. Indeed, many {{have argued that}} miracles not only do not contradict the laws of nature, but require the laws of nature to be intelligible as miraculous, and thus subverting the law of nature. For example, William Adams remarks that [...] "there must be an ordinary course of nature before anything can be extraordinary. There must be a stream before anything can be interrupted". They have also noted that it requires an appeal to <b>inductive</b> <b>inference,</b> as none have observed every part of nature nor examined every possible miracle claim, for instance those in the future. This, in Hume's philosophy, was especially problematic.|$|E
40|$|Recent {{studies have}} shown that {{children}} as young as age 31 / 2 use category membership as the basis of their <b>inductive</b> <b>inferences.</b> The present studies examine how children determine which category-based <b>inductive</b> <b>inferences</b> are warranted and which are unwarranted. Preschool and elementary school children learned various facts (e. g., "This apple has pectin inside") and reported whether they thought the facts generalized to other items varying in similarity to the target (e. g., other apples, a banana, and a stereo). Categories included both natural kinds and artifacts and varied as to how similar category members were to one another (category homogeneity, as rated by adults). Results indicate that even the youngest children placed certain constraints on their inferences. However, the preschoolers made few principled distinctions among categories, basing their inferences primarily on category homogeneity. In contrast, older children made several distinctions that seemed based on domain-specific knowledge. Most importantly, they drew more inferences within natural kinds than within artifact categories, at times even overextending the distinction. Comparison with other research suggests that increasing scientific knowledge exerts powerful effects on patterns of induction within basic-level categories...|$|R
40|$|Trust and Belief are {{two very}} closely {{connected}} notions. Hence {{one would expect that}} any mechanism that guides the management of one can efficaciously guide the other. In fact, devices such as Dempster-Shafer's theory of evidence have been successfully used in the management of both. This paper looks at a different mechanism devised for <b>inductive</b> <b>inferencing,</b> namely Spohn's Ordinal Conditional Functions, and shows that, when appropriately adapted and interpreted, it can fruitfully model the dynamics of trust via trust deficit. 6 page(s...|$|R
5000|$|... "The general laws of Nature are not, for {{the most}} part, {{immediate}} objects of perception. They are either <b>inductive</b> <b>inferences</b> from {{a large body of}} facts, the common truth in which they express, or, in their origin at least, physical hypotheses of a causal nature[...] [...] [...] They are in all cases, and in the strictest sense of the term, probable conclusions, approaching, indeed, ever and ever nearer to certainty, as they receive {{more and more of the}} confirmation of experience. ...” ...|$|R
2500|$|However, {{there are}} other controversies, Arthur Newell Strahler embeds {{peculiar}} anthropic distinctions {{in the name of}} naturalism: [...] "The naturalistic view is that the particular universe we observe came into existence and has operated through all time and in all its parts without the impetus or guidance of any supernatural agency. The naturalistic view is espoused by science as its fundamental assumption." [...] Variously known as background independence, the cosmological principle, the principle of universality, the principle of uniformity, or uniformitarianism, there are important philosophical assumptions that cannot be derived from nature. As noted by Stephen Jay Gould: [...] "You cannot go to a rocky outcrop and observe either the constancy of nature's laws or the working of unknown processes. [...] It works the other way around." [...] You first assume these propositions and [...] "then you go to the out crop of rock." [...] "The assumption of spatial and temporal invariance of natural laws is by no means unique to geology since it amounts to a warrant for <b>inductive</b> <b>inference</b> which, as Bacon showed nearly four hundred years ago, is the basic mode of reasoning in empirical science. Without assuming this spatial and temporal invariance, we have no basis for extrapolating from the known to the unknown and, therefore, no way of reaching general conclusions from a finite number of observations. (Since the assumption is itself vindicated by induction, it can in no way [...] "prove" [...] the validity of induction - an endeavor virtually abandoned after Hume demonstrated its futility two centuries ago)." [...] Gould also notes that natural processes such as Lyell's [...] "uniformity of process" [...] are an assumption: [...] "As such, it is another a priori assumption shared by all scientists and not a statement about the empirical world." [...] Such assumptions across time and space are needed for scientists to extrapolate into the unobservable past, according to G.G. Simpson: [...] "Uniformity is an unprovable postulate justified, or indeed required, on two grounds. First, nothing in our incomplete but extensive knowledge of history disagrees with it. Second, only with this postulate is a rational interpretation of history possible, and we are justified in seeking—as scientists we must seek—such a rational interpretation." [...] and according to R. Hooykaas: [...] "The principle of uniformity is not a law, not a rule established after comparison of facts, but a principle, preceding the observation of facts [...] [...] [...] It is the logical principle of parsimony of causes and of economy of scientific notions. By explaining past changes by analogy with present phenomena, a limit is set to conjecture, for {{there is only one way}} in which two things are equal, but there are an infinity of ways in which they could be supposed different." ...|$|E
60|$|Thus, in the {{preceding}} example, the ultimate <b>inductive</b> <b>inference</b> was, that a certain government was {{not likely to be}} overthrown; this inference was drawn according to a formula in which desire of the public good was set down as a mark of not being likely to be overthrown; a mark of this mark was, acting in a particular manner; and a mark of acting in that manner was, being asserted to do so by intelligent and disinterested witnesses: this mark, the government under discussion was recognized by the senses as possessing. Hence that government fell within the last induction, and by it was brought within all the others. The perceived resemblance of the case to one set of observed particular cases, brought it into known resemblance with another set, and that with a third.|$|E
60|$|If, then, {{a survey}} of the uniformities which have been ascertained to exist in nature, should point out some which, as far as any human purpose {{requires}} certainty, may be considered quite certain and quite universal; then by means of these uniformities {{we may be able to}} raise multitudes of other inductions to the same point in the scale. For if we can show, with respect to any <b>inductive</b> <b>inference,</b> that either it must be true, or one of these certain and universal inductions must admit of an exception; the former generalization will attain the same certainty, and indefeasibleness within the bounds assigned to it, which are the attributes of the latter. It will be proved to be a law; and if not a result of other and simpler laws, it will be a law of nature.|$|E
40|$|People can {{apparently}} make surprisingly sophisticated <b>inductive</b> <b>inferences,</b> {{despite the}} fact that there are constraints on cognitive resources that would make performing exact Bayesian inference computationally intractable. What algorithms could they be using to make this possible? We show that a simple sequential algorithm, Win-Stay, Lose-Shift (WSLS), can be used to approximate Bayesian inference, and is consistent with human behavior on a causal learning task. This algorithm provides a new way to understand people’s judgments and a new efficient method for performing Bayesian inference...|$|R
40|$|In {{the last}} sixty years Finnish {{analytical}} philosophers have been extensively investigating induction and probability, {{and their role}} in empirical sciences. In this paper the main lines and outcomes of such studies are examined. In particular, the following issues are considered: von Wright’s theory of inductive elimination and his analysis of inductive probabilities; the theory of inductive probabilities developed by Hintikka and his school; the contributions made by Finnish students {{to the development of}} Bayesian epistemology, i. e., the Bayesian analysis of <b>inductive</b> <b>inferences</b> and scientific method...|$|R
40|$|Multiagent Inductive Learning is {{the problem}} that groups of agents face {{when they want to}} perform {{inductive}} learning, but the data of interest is distributed among them. This paper focuses on concept learning, and presents A-MAIL, a framework for multiagent induction integrating ideas from inductive learning, case-based reasoning and argumentation. Argumentation is used as a communication framework with which the agents can communicate their <b>inductive</b> <b>inferences</b> to reach shared and agreed-upon concept definitions. We also identify the requirements for learning algorithms to be used in our framework, and propose an algorithm which satisfies them. 1...|$|R
