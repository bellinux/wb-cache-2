0|10000|Public
5000|$|UCITS V {{directive}} {{requires a}} <b>Key</b> Investor <b>Information</b> <b>Document</b> or KIID is produced for investors - see example (autokiid.com) ...|$|R
40|$|Unveiled by the European Commission on July 3 rd, the {{proposed}} Regulation on <b>key</b> <b>information</b> <b>documents</b> (KID) for packaged retail investment products (PRIPs) represents {{a step forward}} in enhancing the protection of retail investors and advancing the single market for financial services. While acknowledging in this Commentary that the KID is a commendable effort, ECMI/CEPS researcher Mirzha de Manuel Aramendía observes that pre-contractual disclosure {{is just one of}} the pieces in the jigsaw puzzle of investor protection and regrets that other pieces, such as MiFID and the IMD, are not so ambitiously constructed...|$|R
40|$|Introduction: This Quick Guide {{provides}} direct {{links to}} <b>key</b> websites, <b>information</b> and <b>documents</b> relating to: • Women in the Parliament of the Commonwealth of Australia • Women in the State and Territory Parliaments • Women in politics • Overseas parliaments • Other resources {{on women in}} parliament and politic...|$|R
40|$|Suppose {{there is}} a large corpus of XML documents, each of which {{describes}} a movie released in the last 30 years (for example, extracted from IMDB). A movie enthusiast wants to make a list of interesting movies based on various criteria, such as, the genre, lead actors, directors, etc. She first decides to narrow the focus to just thrillers. However, she then has to look into each document individually, since only then is it possible for her to tell whether the combination of actors, directors, etc. interests her. This would be timeconsuming if the documents in question contain hundreds of tags each. Instead, she could use our tool Xoom (XML-Zoom) which can extract and present the <b>key</b> <b>information</b> in every <b>document.</b> This would drastically cut down the time to go through the documents. She could then use Xoom to zoom into specific portions of each of the remaining documents, instead of opening and scanning them from top to bottom. In this proposal, we describe the construction of Xoom and outline a demonstration. 1...|$|R
40|$|During various {{activities}} undertaken for design, implementation {{and testing of}} various aircraft development projects like SARAS, HANSA, NM 5, etc at C-CADD, NAL, numerous project documents and internal reports were released. There was a need {{to keep track of}} bibliographic details of these documents, so that their <b>key</b> <b>information</b> can be easily retrieved and accessed. 	To fulfill the above necessity, the software <b>Document</b> <b>Information</b> System” is developed to maintain the offline <b>information</b> of various <b>documents</b> for various flight projects. This report discusses briefly about the <b>Document</b> <b>Information</b> System Software. ...|$|R
40|$|With the <b>Key</b> Investor <b>Information</b> <b>Document</b> (KID), the new UCITS IV {{framework}} {{brings a}} useful standardized and simplified scheme {{to explain the}} risk of mutual funds to non-professional investors. The Synthetic Risk and Reward Indicator (SRRI) methodology defines how to assess a volatility equivalent {{for each type of}} funds, and recognizes the specificities of various types of investment vehicles in the process. The SRRI rests upon two key principles: (i) risk-volatility mapping: the level of risk can be adequately translated by the volatility of returns; and (ii) reward to volatility: there must be a positive connection between the level of risk borne by the individual investor and the associated reward in terms of returns. We show that the SRRI methodology does not guarantee that these two principles are respected in practice. By forcing any type of risk to be translated into a volatility estimate, the approach overlooks investor’s heterogeneity in the definition of risk. The SRRI synthetic approach is powerless to adequately reflect the trade-off between normal and extreme risks the way it is perceived by individual investors. It also ignores that fund returns are not necessarily only related to volatility. We show that the KID does not replace a proper investment profiling system. The analysis of investor profiles is a necessary complement to the KID in order to provide adequate advice to investors. We provide an approach, based on the linear-exponential utility function, that enables the financial advisor to address the heterogeneity of investors when defining the risk of an investment portfolio. Peer reviewe...|$|R
40|$|Personal {{names are}} {{important}} and common information in many data sources, ranging from social networks and news articles to patient records and scientific documents. They are often used as queries for retrieving records and also as <b>key</b> <b>information</b> for linking <b>documents</b> from multiple sources. Matching personal names can be challenging due to variations in spelling and various formatting of names. While many approximated name matching techniques have been proposed, most are generic string-matching algorithms. Unlike other types of proper names, personal names are highly cultural. Many ethnicities have their own unique naming systems and identifiable characteristics. In this paper we explore such relationships between ethnicities and personal names to improve the name matching performance. First, we propose a name-ethnicity classifier based on the multinomial logistic regression. Our model can effectively identify nameethnicity from personal names in Wikipedia, which we use to define name-ethnicity, to within 85 % accuracy. Next, we propose a novel alignment-based name matching algorithm, based on Smith–Waterman algorithm and logistic regression. Different name matching models are then trained for different name-ethnicity groups. Our preliminary experimental result on DBLP’s disambiguated author dataset yields a performance of 99 % precision and 89 % recall. Surprisingly, textual features carry more weight than phonetic ones in nameethnicity classification...|$|R
40|$|This {{document}} was prepared by ALFI's implementation working {{group for the}} <b>Key</b> Investor <b>Information</b> <b>document</b> (KID). The working group comprises representatives of asset managers, management companies, securities service firms, audit firms, law firms, and <b>document</b> and <b>information</b> management firms. This document contains the working group's answers to questions about KID implementation. The answers are not necessarily definitive and {{they might not be}} suitable for every circumstance. This document is not meant to be an industry standard or a guide to best practice but it represents the view from a group of market participants. The Q&A has not been validated by any regulator. It does not diminish the management company's or the investment company's responsibility to comply with the EU Regulation 583 / 2010 on the KID, CESR's related guidelines and technical advice papers and any other European or national law or regulation. This document must not be relied upon as advice and is provided without any warranty of any kind and neither ALFI nor its members who contributed to this document accept any liability whatsoever for any action taken in reliance upon it. This document may be amended without prior notice to incorporate new material and to amend previously published material where the working group considers it appropriate. ALFI will publish amended copies of this document to its members, showing marked-up changes from the immediately preceding copy. The titles used in this document are references to the relevant recitals, chapters, sections and articles of the EU Regulation 583 / 2010 and associated CESR guidelines and consultation papers. ALFI's members are welcome to submit a question to the working group, which will review it and consider whether to include it in a future copy of this document. Please send your questions to info@alfi. lu. We will acknowledge receipt of each question but we regret that we may be unable to reply individually to each one...|$|R
40|$|Robotic {{intelligence}} has recently received significant {{attention in the}} research community. Application of such artificial intelligence {{can be used to}} perform automatic document retrieval and interpretation by a robot through query. So, it is necessary to extract the <b>key</b> <b>information</b> from the <b>document</b> based on the query to produce the desired feedback. For this purpose, in this paper we propose a system for automatic date field extraction from multi-lingual (English, Devnagari and Bangla scripts) handwritten documents. The date is a <b>key</b> piece of <b>information,</b> which can be used in various robotic applications such as date-wise document indexing/retrieval. In order to design the system, first the script of the document is identified, and based on the identified script, word components of each text line are classified into month and non-month classes using word-level feature extraction and classification. Next, non-month words are segmented into individual components and labelled into one of text, digit, punctuation or contraction categories. Subsequently, the date patterns are searched using the labelled components. Both numeric and semi-numeric regular expressions have been used for date part extraction. Dynamic Time Warping (DTW) and profile feature-based approaches are used for classification of month/non-month words. Other date components such as numerals and punctuation marks are recognised using a gradient-based feature and Support Vector Machine (SVM) classifier. The experiments are performed on English, Devnagari and Bangla document datasets and the encouraging results obtained from the system indicate the effectiveness of the proposed system. Griffith Sciences, School of Information and Communication TechnologyFull Tex...|$|R
40|$|When a {{group of}} authors collaboratively edits interre-lated documents, {{consistency}} problems occur almost im-mediately. Current document management systems (DMS) often lack adequate facilities for consistency management. We extend traditional DMS by explicit formal consistency rules. In contrast to many other approaches, we permit inconsistencies and present the consequences to the user, which is vital for flexible document management and in-formation management. Based on a novel semantics our tools pinpoint inconsistent document parts and tell pre-cisely when, where, and why a repository is inconsistent. In this paper we focus on a key issue: efficient tech-niques for consistency rule evaluation. Our strategy is known from databases: (1) static analysis characterizes and simplifies consistency rules and (2) at run-time rules are evaluated incrementally. The major differences to databases are that we consider informal documents and explicitly allow inconsistencies. Consequently, we lack for-mal update descriptions and cannot rely on consistency prior to updates. The contribution {{of this paper is}} to incrementally evalu-ate consistency rules in the presence of previous inconsis-tencies. We have implemented our techniques in a revision control system. Our experiments show that efficient incre-mental evaluation is the key to make our approach viable. <b>Key</b> words <b>information</b> management, <b>document</b> man-agement, consistency, incremental evaluation 1...|$|R
50|$|Section 3(1)(a) {{creates an}} offence of {{disclosing}} <b>information,</b> <b>documents</b> or other articles relating to international relations. This includes confidential <b>information,</b> <b>documents</b> or other article from a State {{other than the}} United Kingdom or an international organisation. This section applies only to crown servants and government contractors.|$|R
3000|$|... as its <b>keying</b> <b>information.</b> Therefore two sensors knowing each other's id can compute {{a shared}} key from their <b>keying</b> <b>information</b> as [...]...|$|R
2500|$|Official <b>Information</b> <b>Documents</b> {{from the}} Commonwealth of Massachusetts: ...|$|R
40|$|The {{following}} {{paper is}} {{an outgrowth of}} research performed with a data base of merged individual income tax returns and <b>information</b> <b>documents.</b> Tax Year 1989 was the first year for which such a data base was created and perfected. Traditionally, the Statistics of Income (SOI) Division of the Internal Revenue Service has interpreted its mandate to produce "statistics reasonably available {{with respect to the}} operations of the internal revenue laws " [1] as meaning tabulating data shown on tax returns. In recent years, with the computerization of the millions of <b>information</b> <b>documents</b> prepared by employers, banks, stock brokers, payers of pensions, etc., data from these documents have increasingly become "reasonably available. " Data from <b>information</b> <b>documents,</b> when matched to tax returns, can be used to serve as a check on the data shown on individual income tax returns, as well as to provide an indication of how much of the income on a joint return belongs to the husband and how much to the wife. In addition, it is possible to pull a sample of <b>information</b> <b>documents</b> that do not match to tax returns, and use them to tally data about non-filers. The data base used for this paper was created as a tool to compare tax return data to data gathered from <b>information</b> <b>documents.</b> It includes a sample of tax returns matched to <b>information</b> <b>documents,</b> as well as unmatched tax returns and unmatched <b>information</b> <b>documents.</b> The age of each individual in the sample was determined by matching his or her social security number (SSN) to the Year of Birth file, whic...|$|R
40|$|Library records {{consist of}} <b>information</b> <b>documented</b> in {{performance}} of the library’s official business. Any <b>information</b> <b>documenting</b> official business, whether recorded on paper or in portable document format (PDF), reproduced on microfilm, entered in electronic databases, documented photographically, recorded in video or audio media, or documented using any other medium, may constitute a record...|$|R
5000|$|Metadata with {{semantic}} meta-information, Charset <b>information,</b> <b>Document</b> Type Definition (DTD), etc.|$|R
5000|$|Workflow {{platforms}} - {{to route}} <b>information,</b> <b>documents</b> and direct process flow ...|$|R
5000|$|Cryptome CN: <b>Information,</b> <b>documents</b> and {{opinions}} {{banned by the}} People's Republic of China.|$|R
30|$|The {{objective}} is to minimize the total search cost t_search = t_submission× n+ t_switch× d when finding all <b>key</b> <b>information,</b> that is payoff = 10. Moreover, <b>key</b> <b>information</b> could be repeated in different sources.|$|R
5000|$|The {{transfer}} of <b>information,</b> <b>documents,</b> tasks, or objects from one {{step to the}} next ...|$|R
30|$|The reading {{items from}} both tests were {{examined}} {{to determine the}} aspects of the construct of reading that they seemed most likely to assess. Passages were also classified based on their topics. Additionally, the scope of each item was rated, using a five-point scale of very narrow for any item for which the <b>key</b> <b>information</b> necessary to answer it correctly was found within a single sentence, narrow if the <b>key</b> <b>information</b> was within the space of several sentences, moderate for any item for which the <b>key</b> <b>information</b> could be found within all or almost all of a single paragraph, broad if the <b>key</b> <b>information</b> was spread across {{more than a single}} paragraph, and very broad for any item for which the <b>key</b> <b>information</b> was distributed across more than half the text. The final step in the task analysis was to identify the response format for items.|$|R
50|$|Section 1(1) {{creates an}} offence of {{disclosing}} <b>information,</b> <b>documents</b> or other articles relating to security or intelligence.|$|R
500|$|Bristow, Mark. (2005) A History of Royal Air Force Northolt. RAF Northolt: No. 1 AIDU (Aeronautical <b>Information</b> <b>Documents</b> Unit) ...|$|R
5000|$|Managing www.protectionline.org, {{a project}} website {{providing}} <b>informations,</b> <b>documents,</b> publications, press releases and promoting urgent actions {{for the protection}} of HRD.|$|R
30|$|After {{disseminating}} the <b>keying</b> <b>information</b> to all worker sensors in {{the coverage}} area, the service sensor should erase all stored <b>key</b> space <b>information</b> for security enhancement.|$|R
3000|$|... • it {{can provide}} {{politicians}} with <b>information,</b> <b>documents</b> and a basis for decision support to assess climate change impacts and [...]...|$|R
5000|$|... provide <b>key</b> <b>information</b> {{about quality}} {{management}} to key stakeholders ...|$|R
40|$|Automatically extracting {{chemical}} <b>information</b> from <b>documents</b> is {{a challenging}} task, but an essential one {{for dealing with}} the vast quantity of data that is available. The task is least difficult for structured documents, such as chemistry department web pages or the output of computational chemistry programs, but requires increasingly sophisticated approaches for less structured documents, such as chemical papers. The identification of <b>key</b> units of <b>information,</b> such as chemical names, makes the extraction of useful <b>information</b> from unstructured <b>documents</b> possible...|$|R
5000|$|Using the Freedom of Information Act (United States) {{to force}} {{government}} agencies to release {{hundreds of thousands}} of pages of <b>information</b> <b>documenting</b> government misconduct; ...|$|R
40|$|In this paper, {{a method}} for {{automatic}} transcription of polyphonic music is proposed that exploits <b>key</b> <b>information.</b> The proposed system performs key detection using a matching technique with distributions of pitch class pairs, called Zweiklang profiles. The automatic transcription system is based on probabilistic latent component analysis, supporting templates from multiple instruments, as well as tuning deviations and frequency modulations. <b>Key</b> <b>information</b> is incorporated to the transcription system using Dirichlet priors during the parameter update stage. Experiments are performed on a polyphonic, multiple-instrument dataset of Bach chorales, where it is shown that incorporating <b>key</b> <b>information</b> improves multi-pitch detection and instrument assignment performance...|$|R
5000|$|<b>Key</b> <b>information</b> {{regarding}} each of {{the race}} events is as follows: ...|$|R
5000|$|... {{increasing}} {{the security of}} the supply chain for <b>key</b> <b>information</b> technologies; ...|$|R
50|$|Section 2(1) {{creates an}} offence of {{disclosing}} <b>information,</b> <b>documents</b> or other articles relating to defence. This section {{applies only to}} crown servants and government contractors.|$|R
5000|$|... {{require a}} person {{present on the}} {{premises}} to provide him with any facilities, <b>information,</b> <b>documents</b> or records, or other assistance, that he may reasonably request.|$|R
5000|$|... "There {{is exactly}} one <b>document</b> <b>{{information}}</b> {{item in the}} information set, and all other information items are accessible from {{the properties of the}} <b>document</b> <b>information</b> item, either directly or indirectly through the properties of other <b>information</b> items. The <b>document</b> <b>information</b> item has the following properties: ...|$|R
40|$|SyncML Device <b>Information</b> DTD This <b>document</b> {{defines the}} Document Type Definition (DTD) for the XML {{representation}} of the Device <b>Information</b> <b>document.</b> This XML document describes {{the capabilities of the}} device and is used in SyncML data synchronization protocol operations. Data synchronization provides the means for two different networked object stores to remain in identical states. Different forms of data synchronization can be categorized into {{one of a number of}} topologies, based on the architecture used by a data synchronization server, or sync engine. Sync engines need to understand the features of a device they synchronize with. This information is often stored in a Device <b>Information</b> <b>document</b> on the target device...|$|R
