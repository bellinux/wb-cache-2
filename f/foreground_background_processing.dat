0|2874|Public
5000|$|Advanced shaders (color, reflectance, transparency, displacement, <b>background,</b> <b>foreground,</b> post <b>processing)</b> ...|$|R
40|$|Values are {{critical}} for intelligent behavior, since values determine interests, and interests determine relevance. Therefore we address relevance {{and its role in}} intelligent behavior in animals and machines. Animals avoid exhaustive enumeration of possibilities by focusing on relevant aspects of the environment, which emerge into the (cognitive) foreground, while suppressing irrelevant aspects, which submerge into the background. Nevertheless, the background is not invisible, and aspects of it can pop into the <b>foreground</b> if <b>background</b> <b>processing</b> deems them potentially relevant. This illuminates the differences between representation in natural intelligence and (traditional) artificial intelligence. Traditionally artificial intelligence has started with simple, primitive features, and attempted to construct from them a representation of the environment. If too few features are used, then the processing is imprecise and crude. However, if sufficient features are used to permit precise pr [...] ...|$|R
40|$|Values are {{critical}} for intelligent behavior, since values determine interests, and interests determine relevance. Therefore we address relevance {{and its role in}} intelligent behavior in animals and machines. Animals avoid exhaustive enumeration of possibilities by focusing on relevant aspects of the environment, which emerge into the (cognitive) foreground, while suppressing irrelevant aspects, which submerge into the background. Nevertheless, the background is not invisible, and aspects of it can pop into the <b>foreground</b> if <b>background</b> <b>processing</b> deems them potentially relevant. This illuminates the differences between representation in natural intelligence and (traditional) artificial intelligence. Traditionally artificial intelligence has started with simple, primitive features, and attempted to construct from them a representation of the environment. If too few features are used, then the processing is imprecise and crude. However, if sufficient features are used to permit precise processing in all contexts, then the system is defeated by the combinatorial explosion of features. In natural intelligence, in contrast, we begin with a nervous system that can process in real-time the “concrete space ” represented by the interface between the animal’s nervous system and its environment. The separation of <b>foreground</b> from <b>background</b> then serves to increase the efficiency of this process. Instead of trying to construct the concrete world from abstract predicates, the brain projects the very highdimensional concrete world into lower dimensional subspaces; this projection is context-sensitive and rapidly adaptable. Therefore it is not vulnerable to the combinatorial explosion. We consider the connection between these ideas and the concepts of intentionality, as discussed by Brentano and Husserl, and information, as quantified by Shannon and Weaver. In particular, the Shannon-Weaver measure ignores relevance, which is essential to biologica...|$|R
40|$|Values are {{critical}} for intelligent behavior, since values determine interests, and interests determine relevance. Therefore we address relevance {{and its role in}} intelligent behavior in animals and machines. Animals avoid exhaustive enumeration of possibilities by focusing on relevant aspects of the environment, which emerge into the (cognitive) foreground, while suppressing irrelevant aspects, which submerge into the background. Nevertheless, the background is not invisible, and aspects of it can pop into the <b>foreground</b> if <b>background</b> <b>processing</b> deems them potentially relevant. Essential to these ideas are questions of how contexts are switched, which defines cognitive/behavioral episodes, and how new contexts are created, which allows the efficiency of foreground/background processing to be extended to new behaviors and cognitive domains. Next we consider mathematical characterizations of the foreground/background distinction, which we treat as a dynamic separation of the concrete space into (approximately) orthogonal subspaces, which are processed differently. <b>Background</b> <b>processing</b> is characterized by large receptive fields which project into a space of relatively low dimension to accomplish rough categorization of a novel stimulus and its approximate location. Such <b>background</b> <b>processing</b> is partly innate and partly learned, and we discuss possible correlational (Hebbian) learning mechanisms. Foreground processing is characterized by small receptive fields which project into a space of comparatively high dimension to accomplish precise categorization and localization of the stimuli relevant to the context. We also consider mathematical models of valences and affordances, which are an aspect of the foreground. Cells processing foregound information have no fixed meaning (i. e., their meaning is contextual), so it is necessary to explain how the processing accomplished by foreground neurons can be made relative to the context. Thus we consider the properties of several simple mathematical models of how the contextual representation controls foreground processing. We show how simple correlational processes accomplish the contextual separation of <b>foreground</b> from <b>background</b> on the basis of differential reinforcement. That is, these processes account for the contextual separation of the concrete space into disjoint subspaces corresponding to the <b>foreground</b> and <b>background.</b> Since an episode may comprise the activation of several contexts (at varying levels of activity) we consider models, suggested by quantum mechanics, of foreground processing in superposition. That is, the contextual state may be a weighted superposition of several pure contexts, with a corresponding superposition of the foreground representations and the processes operating on them. This leads us to a consideration of the nature and origin of contexts. Although some contexts are innate, many are learned. We discuss a mathematical model of contexts which allows a context to split into several contexts, agglutinate from several contexts, or to constellate out of relatively acontextual processing. Finally, we consider the acontextual processing which occurs when the current context is no longer relevant, and may trigger the switch to another context or the formation of a new context. We relate this to the situation known as "breakdown" in phenomenology...|$|R
5000|$|... 40- and 80-column text, with 24 lines (16 {{selectable}} <b>foreground,</b> <b>background,</b> border colors) ...|$|R
5000|$|... #Caption: The ThunderCats. From left to right: Tygra, WilyKit, Lion-O, WilyKat (<b>foreground),</b> Panthro (<b>background),</b> Snarf (<b>foreground),</b> Cheetara (<b>background).</b>|$|R
40|$|Abstract: We {{consider}} the effective stress-energy tensors for the <b>foreground</b> and <b>background</b> sectors in ghost-free bimetric gravity. By considering the symmetries of the theory, {{we show that}} the <b>foreground</b> and <b>background</b> null energy conditions (NECs) are strongly anti-correlated. In particular, the NECs can only be simultaneously ful-filled when they saturate, corresponding to <b>foreground</b> and <b>background</b> cosmological constants. In all other situations, either the <b>foreground</b> or the <b>background</b> is subject to a NEC-violating contribution to the total stress-energy...|$|R
40|$|<b>Foreground</b> <b>background</b> {{segmentation}} algorithms {{attempt to}} separate interesting or changing regions from the background in video sequences. Foreground detection is obviously more difficult {{when the camera}} viewpoint changes dynamically, such as when the camera undergoes a panning or tilting motion. In this paper, we propose an edge based <b>foreground</b> <b>background</b> estimation method, which can automatically detect and compensate for camera viewpoint changes. We will show that this method significantly outperforms state-of-the-art algorithms for the panning sequences in the ChangeDetection. NET 2014 dataset, while still performing well in the other categories...|$|R
2500|$|If {{a subject}} is at {{distance}} [...] and the <b>foreground</b> or <b>background</b> is at distance , let {{the distance between}} the subject and the <b>foreground</b> or <b>background</b> be indicated by ...|$|R
40|$|Image matting is {{the process}} of extracting a soft {{segmentation}} of an object in an image as defined by the matting equation. Most current techniques focus largely on computing the alpha values of unknown pixels and treat computation of the <b>foreground</b> and <b>background</b> colors as an afterthought, if at all. However, for many applications, such as compositing an object into a new scene or deleting an object from the scene, the <b>foreground</b> and <b>background</b> colors are vital for an acceptable answer. We propose a method of solving for the <b>foreground,</b> <b>background,</b> and alpha of an unknown region in an image simultaneously. This allows for novel constraints to be placed directly on the <b>foreground</b> and <b>background</b> as well as on alpha. We show through both visual results and quantitative measurements on standard datasets that this approach produces more accurate <b>foreground</b> and <b>background</b> values at each pixel while maintaining competitive results on the alpha matte. 1...|$|R
5000|$|The series {{uses the}} graphic process Morris used that employs colors to {{differentiate}} a character {{according to its}} value in the (<b>foreground,</b> <b>background),</b> according to his mood state (green rage, ...) or to describe a mood (red fire, night blue, ...).|$|R
50|$|Because each {{character}} {{can be assigned}} different <b>foreground</b> and <b>background</b> colors, it can be colored (for example) blue on the left (foreground color) and bright red on the right (background color). This can be reversed by swapping the <b>foreground</b> and <b>background</b> colors.|$|R
40|$|We {{extend the}} blind {{deblurring}} method [1] for separating images with two layers that have suffered different blurs: E. g. objects with different velocities, or at different focus depths. • The method only requires weak assumptions on the blurring filter. • It reasonably estimates, {{from a single}} degraded image:- A complete deblurred image (<b>foreground</b> + <b>background)</b> - Blurring filters (<b>foreground</b> + <b>background)</b> - Segmentation mask between <b>foreground</b> and <b>background.</b> • Enhancements are achieved both in real blurred photos and in synthetic degradations...|$|R
50|$|Weber & Welling here {{introduce}} {{the concept of}} <b>foreground</b> and <b>background.</b> <b>Foreground</b> parts correspond to an instance of a target object class, whereas background parts correspond to background clutter or false detections.|$|R
40|$|Generating novel, yet realistic, {{images of}} persons is a {{challenging}} task {{due to the}} complex interplay between the different image factors, such as the <b>foreground,</b> <b>background</b> and pose information. In this work, we aim at generating such images based on a novel, two-stage reconstruction pipeline that learns a disentangled representation of the aforementioned image factors and generates novel person images at the same time. First, a multi-branched reconstruction network is proposed to disentangle and encode the three factors into embedding features, which are then combined to re-compose the input image itself. Second, three corresponding mapping functions are learned in an adversarial manner in order to map Gaussian noise to the learned embedding feature space, for each factor respectively. Using the proposed framework, we can manipulate the <b>foreground,</b> <b>background</b> and pose of the input image, and also sample new embedding features to generate such targeted manipulations, that provide {{more control over the}} generation process. Experiments on Market- 1501 and Deepfashion datasets show that our model does not only generate realistic person images with new <b>foregrounds,</b> <b>backgrounds</b> and poses, but also manipulates the generated factors and interpolates the in-between states. Another set of experiments on Market- 1501 shows that our model can also be beneficial for the person re-identification task...|$|R
25|$|Gleizes' {{method was}} {{fundamentally}} synthetic. Although the landscape seems persuasively realistic (with its <b>foreground,</b> <b>background</b> and village in between), {{it is not}} an existing place somewhere between Paris and his studio at Courbevoie, consistent with Gleizes' method of bringing together various elements from different locations anteriorly observed in nature.|$|R
40|$|We {{consider}} {{the framework of}} attentional processing in light of Gestalt theory. The dichotomy of top-down and bottom-up attention is criticized as an anachronism {{in light of the}} interactive character of processing. The Gestalt concept of <b>foreground</b> <b>background</b> organization offers an appropriate contextualization for the notion of attention...|$|R
2500|$|For a given subject magnification, f-number, and {{distance}} from {{the subject of the}} <b>foreground</b> or <b>background</b> detail, the degree of detail blur varies with the lens focal length. For a background detail, the blur increases with focal length; for a foreground detail, the blur decreases with focal length. For a given scene, the positions of the subject, <b>foreground,</b> and <b>background</b> usually are fixed, and the distance between subject and the <b>foreground</b> or <b>background</b> remains constant regardless of the camera position; however, to maintain constant magnification, the subject distance must vary if the focal length is changed. For small distance between the <b>foreground</b> or <b>background</b> detail, the effect of focal length is small; for large distance, the effect can be significant. For a reasonably distant background detail, the blur disk diameter is ...|$|R
30|$|Differentiate the <b>foreground</b> and <b>background</b> {{region of}} human boundary.|$|R
5000|$|... #Caption: Both Holyrood trees, May 2014 (<b>foreground</b> and <b>background</b> right) ...|$|R
60|$|In the <b>foreground</b> and <b>background</b> {{there was}} a {{disappointed}} face.|$|R
30|$|Question 3 : Contrast ratio between <b>foreground</b> and <b>background</b> is suitable.|$|R
40|$|VISAPP {{is part of}} VISIGRAPP - International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and ApplicationsArea 3 - Motion, Tracking and Stereo Vision: Paper no. 13 This paper revisits the graph-cuts based {{approach}} for solving the multi-view stereo problem, and proposes a novel <b>foreground</b> / <b>background</b> energy which is shown to be unbiased and robust against noisy depth maps. Unlike most existing works which focus on deriving a robust photo-consistency energy, this paper targets at deriving a robust and unbiased <b>foreground</b> / <b>background</b> energy. By introducing a novel data-dependent <b>foreground</b> / <b>background</b> energy, we show {{that it is possible}} to recover the object surface from noisy depth maps even in the absence of the photo-consistency energy. This demonstrates that the <b>foreground</b> / <b>background</b> energy is equally important as the photo-consistency energy in graph-cuts based methods. Experiments on real data sequences further show that high quality reconstructions can be achieved using our proposed <b>foreground</b> / <b>background</b> energy with a very simple photo-consistency energy. link_to_subscribed_fulltextThe International Joint Conference on Computer Vision Theory and Applications (VISAPP 2011), Vilamoura, Algarve, Portugal, 5 - 7 March 2011. In Proceedings of VISAPP, 2011, p. 451 - 45...|$|R
40|$|In this paper, {{we present}} a new image matting {{algorithm}} that achieves state-of-the-art performance on a benchmark dataset of images. This is achieved by solving two ma-jor problems encountered by current sampling based al-gorithms. The first is that the range in which the fore-ground and background are sampled is often limited {{to such an extent}} that the true <b>foreground</b> and <b>background</b> colors are not present. Here, we describe a method by which a more comprehensive and representative set of samples is collected so as not to miss out on the true samples. This is accomplished by expanding the sampling range for pixels farther from the <b>foreground</b> or <b>background</b> boundary and ensuring that samples from each color distribution are in-cluded. The second problem is the overlap in color distri-butions of <b>foreground</b> and <b>background</b> regions. This causes sampling based methods to fail to pick the correct samples for <b>foreground</b> and <b>background.</b> Our design of an objective function forces those <b>foreground</b> and <b>background</b> samples to be picked that are generated from well-separated dis-tributions. Comparison on the dataset at and evaluation by www. alphamatting. com shows that the proposed method ranks first in terms of error measures used in the website. 1...|$|R
40|$|Image matting is {{the problem}} of {{determining}} for each pixel in an image whether it is <b>foreground,</b> <b>background,</b> or the mixing parameter, ”alpha”, for those pixels that are a mixture of <b>foreground</b> and <b>background.</b> Matting is inherently an ill-posed problem. Previous matting approaches either use naive color sampling methods to estimate <b>foreground</b> and <b>background</b> colors for unknown pixels, or use propagation-based methods to avoid color sampling under weak assumptions about image statistics. We argue that neither method itself is enough to generate good results for complex natural images. We analyze the weaknesses of previous matting approaches, and propose a new robust matting algorithm. In our approach we also sample <b>foreground</b> and <b>background</b> colors for unknown pixels, but more importantly, analyze the confidence of these samples. Only high confidence samples are chosen to contribute to the matting energy function which is minimized by a Random Walk. The energy function we define also contains a neighborhood term to enforce the smoothness of the matte. To validate the approach, we present an extensive and quantitative comparison between our algorithm and a number of previous approaches in hopes of providing a benchmark for future matting research. 1...|$|R
5000|$|... #Caption: Bridges over rivers Seine (<b>foreground),</b> Yonne (<b>background)</b> and {{statue of}} Napoléon ...|$|R
5000|$|... #Caption: C-130s from the: U.S., Canada, Australia and Israel (<b>foreground</b> to <b>background)</b> ...|$|R
5000|$|... #Caption: Eorsa {{from the}} north/northwest with Mull in the <b>foreground</b> and <b>background</b> ...|$|R
5000|$|... #Caption: Robert Tarn, Mackenzie Tarn and Johnston Tarn (<b>foreground</b> to <b>background),</b> Tarn Shelf ...|$|R
40|$|Post-printHow do we feel {{our body}} in emotion experience? In this paper I {{initially}} distinguish between <b>foreground</b> and <b>background</b> bodily feelings, and characterize {{them in some}} detail. Then I compare this distinction with the one between reflective and pre-reflective bodily self-awareness one finds in some recent philosophical phenomenological works, and conclude that both <b>foreground</b> and <b>background</b> bodily feelings {{can be understood as}} pre-reflective modes of bodily self-awareness that nevertheless differ in degree of self-presentation or self-intimation. Finally, I use the distinction between <b>foreground</b> and <b>background</b> bodily feelings to characterize the experience of being absorbed in an activity, as opposed to accounts that imply that absorption involves bodily inconspicuousness. European Research Counci...|$|R
5000|$|Elimination of <b>foreground</b> and <b>background</b> by way {{of using}} 100 percent of the canvas ...|$|R
5000|$|... #Caption: Main hall, with Gloster Meteor (<b>foreground),</b> Huanquero (<b>background)</b> and Urubu (hanging from roof) ...|$|R
5000|$|... #Caption: Nor Kyurin (<b>foreground),</b> Marmarashen (<b>background</b> with {{unfinished}} church), and Mt. Ararat, May 2009.|$|R
30|$|First, all {{annotation}} nodes in test subset {{were classified}} into two categories: <b>foreground</b> and <b>background.</b>|$|R
500|$|The most {{innovative}} technical aspect of Citizen Kane is the extended use of deep focus. In nearly every {{scene in the}} film, the <b>foreground,</b> <b>background</b> {{and everything in between}} are all in sharp focus. Cinematographer Toland did this through his experimentation with lenses and lighting. Toland described the achievement, made possible by the sensitivity of modern speed film, in an article for Theatre Arts magazine: ...|$|R
40|$|This paper {{proposes a}} new Bayesian {{framework}} for solving the matting problem, i. e. extracting a foreground element from a background image by estimating an opacity for each pixel of the foreground element. Our approach models both the <b>foreground</b> and <b>background</b> color distributions with spatiallyvarying sets of Gaussians, and assumes a fractional blending of the <b>foreground</b> and <b>background</b> colors {{to produce the}} final output. It then uses a maximum-likelihood criterion to estimate the optimal opacity, <b>foreground</b> and <b>background</b> simultaneously. In addition to providing a principled approach to the matting problem, our algorithm effectively handles objects with intricate boundaries, such as hair strands and fur, and provides an improvement over existing techniques for these difficult cases. 1...|$|R
