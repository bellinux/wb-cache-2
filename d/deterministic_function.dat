466|590|Public
2500|$|An {{increasing}} {{similarity of}} outcomes {{to what a}} purely <b>deterministic</b> <b>function</b> would produce ...|$|E
2500|$|Suppose {{we have a}} PP {{machine with}} time {{complexity}} T:=T(n) on input x of length n := |x|. Thus the machine flips a coin at most T times during the computation. We can thus view the machine as a <b>deterministic</b> <b>function</b> f (implemented, e.g. by a classical circuit) which takes two inputs (x, r) where r, a binary string of length T, represents {{the results of the}} random coin flips that are performed by the computation, and the output of f is 1 (accept) or 0 (reject). The definition of PP tells us that ...|$|E
50|$|Note: g(i) is any <b>deterministic</b> <b>function,</b> {{often the}} {{identity}} function.|$|E
40|$|This paper {{presents}} {{the integration of}} the optimization known as dynamic cut within the functional-logic system T OY. The implementation automatically detects <b>deterministic</b> <b>functions</b> at compile time, and includes in the generated code the test for detecting at run-time the computations that can actually be pruned. The outcome is a much better performance when executing <b>deterministic</b> <b>functions</b> including either or-branches in their definitional trees or extra variables in their conditions, with no serious overhead {{in the rest of the}} computations. The paper also proves the correctness of the criterion used for detecting <b>deterministic</b> <b>functions</b> w. r. t. the semantic calculus CRWL...|$|R
40|$|To enable {{inference}} {{in continuous}} Bayesian networks containing nonlinear deterministic conditional distributions, Cobb and Shenoy (2005) have proposed approximating nonlinear <b>deterministic</b> <b>functions</b> by piecewise linear ones. In this paper, we describe two princi-ples and a heuristic for finding piecewise linear approximations of nonlinear functions. We illustrate our approach for some commonly used one- and two-dimensional nonlinear <b>deterministic</b> <b>functions.</b> ...|$|R
30|$|Here, F,G,μ,σ,Q,R are {{continuous}} <b>deterministic</b> <b>functions</b> on [0,T], Q(t)> 0, R(t)> 0 and L> 0 is a constant.|$|R
5000|$|Inhomogeneous Poisson process, where λ(t) is {{restricted}} to a <b>deterministic</b> <b>function</b> ...|$|E
5000|$|An {{increasing}} {{similarity of}} outcomes {{to what a}} purely <b>deterministic</b> <b>function</b> would produce ...|$|E
50|$|Shekel {{function}} is a multidimensional, multimodal, continuous, <b>deterministic</b> <b>function</b> commonly {{used as a}} test function for testing optimization techniques.|$|E
30|$|An easy {{application}} of this result {{is the case of}} Lévy processes, for which the compensators are <b>deterministic</b> <b>functions.</b>|$|R
5000|$|... where [...] and [...] are <b>deterministic</b> <b>functions,</b> {{then the}} short rate model {{is said to}} have an affine term structure.|$|R
3000|$|... where G, G̅ are {{symmetric}} matrices and Q(·), Q̅(·), S(·), S̅(·), R(·), R̅(·) are <b>deterministic</b> matrix-valued <b>functions</b> with Q(·), Q̅(·), R(·), and R̅(·) being symmetric; g is an F_t-measurable random vector and G̅ is a deterministic vector; q(·), ρ(·) are vector-valued F-progressively measurable {{processes and}} Q̅(·), ρ̅(·) are vector-valued <b>deterministic</b> <b>functions.</b> Our mean-field stochastic linear quadratic (LQ, for short) optimal control {{problem can be}} stated as follows: [...]...|$|R
50|$|A PRF is an {{efficient}} (i.e. computable in polynomial time), <b>deterministic</b> <b>function</b> that maps two distinct sets (domain and range) {{and looks like}} a truly random function.|$|E
50|$|Two useful {{applications}} are {{in finding the}} characteristic function of a probability density function, and in finding the derivative function of a <b>deterministic</b> <b>function</b> {{with a small amount}} of noise. Subrandom numbers allow higher-order moments to be calculated to high accuracy very quickly.|$|E
50|$|Since {{in local}} {{volatility}} models the volatility is a <b>deterministic</b> <b>function</b> of the random stock price, local volatility models {{are not very}} well used to price cliquet options or forward start options, whose values depend specifically on the random nature of volatility itself.|$|E
50|$|Most {{database}} management systems restrict check constraints {{to a single}} row, with access to constants and <b>deterministic</b> <b>functions,</b> but not to data in other tables, or to data invisible to the current transaction because of transaction isolation.|$|R
40|$|Weierstrass–Mandelbrot {{functions}} {{are given a}} time–frequency interpretation which puts emphasis on their possible decomposition on chirps {{as an alternative to}} their standard, Fourier-based, representation. Examples of <b>deterministic</b> <b>functions</b> are considered, as well as randomized versions for which the analysis is applied to empirical estimates of statistical quantities...|$|R
5000|$|... where a and b are <b>deterministic</b> <b>functions,</b> t is a {{continuous}} index for time, x {{is a set}} of exogenous variables that may change with time, dt is a differential in time, and η is a random draw from a standard normal distribution at each instant.|$|R
5000|$|Norbert Wiener proved this theorem for {{the case}} of a <b>deterministic</b> <b>function</b> in 1930; Aleksandr Khinchin later {{formulated}} an analogous result for stationary stochastic processes and published that probabilistic analogue in 1934. [...] Albert Einstein explained, without proofs, the idea in a brief two-page memo in 1914.|$|E
50|$|An N×N Euclidean random matrix Â {{is defined}} {{with the help}} of an {{arbitrary}} <b>deterministic</b> <b>function</b> f(r, r′) and of N points {ri} randomly distributed in a region V of d-dimensional Euclidean space. The element Aij of the matrix is equal to f(ri, rj): Aij = f(ri, rj).|$|E
5000|$|Intuitively, mutual {{information}} measures {{the information that}} X and Y share: It measures how much knowing one of these variables reduces uncertainty about the other. For example, if X and Y are independent, then knowing X does not give any information about Y and vice versa, so their {{mutual information}} is zero. At the other extreme, if X is a <b>deterministic</b> <b>function</b> of Y and Y is a <b>deterministic</b> <b>function</b> of X then all information conveyed by X is shared with Y: knowing X determines the value of Y and vice versa. As a result, {{in this case the}} mutual information {{is the same as the}} uncertainty contained in Y (or X) alone, namely the entropy of Y (or X). Moreover, this mutual information is the same as the entropy of X and as the entropy of Y. (A very special case of this is when X and Y are the same random variable.) ...|$|E
30|$|Track {{irregularity}} is {{the main}} excitation source causing the vibration of vehicle–track structures. Previous studies [1, 2] have shown that track irregularity is a random process that cannot be described with <b>deterministic</b> <b>functions.</b> Vibrations of vehicle–track coupled systems excited by track irregularities should therefore be addressed using random vibration theory.|$|R
40|$|We study LIL's {{for moving}} averages of Banach space valued (<b>deterministic)</b> <b>functions</b> wrt. {{homogeneous}} infinitely divisible independently scattered random measures on metrizable LCA topological groups. {{upper and lower}} class upper and lower function LIL zero-one law moving average infinitely divisible process Lévy process stationary process stable process random integral regular variation...|$|R
40|$|Abstract—Weierstrass-Mandelbrot {{functions}} {{are given a}} time-frequency in-terpretation which puts emphasis on their possible decomposition on chirps {{as an alternative to}} their standard, Fourier-based, representation. Examples of <b>deterministic</b> <b>functions</b> are considered, as well as randomized versions for which the analysis is applied to empirical estimates of statistical quantities. Keywords—Weierstrass function, time-frequency, Mellin, chirps. ...|$|R
5000|$|Let [...] be {{the jump}} intensity. The Poisson process model for jumps {{is that the}} {{probability}} of one jump in the interval [...] is [...] plus higher order terms. [...] could be a constant, a <b>deterministic</b> <b>function</b> of time, or a stochastic process. The survival probability [...] is the probability that no jump {{has occurred in the}} interval [...] The change in the survival probability is ...|$|E
5000|$|Then {{for every}} , [...] and [...] are {{independent}} if {{and only if}} [...] It {{is important to note that}} this characterization does not hold for exponent in this case for bivariate , [...] is a <b>deterministic</b> <b>function</b> of the Pearson correlation. If [...] and [...] are [...] powers of the corresponding distances, , then [...] sample distance covariance can be defined as the nonnegative number for which ...|$|E
5000|$|To put it more formally, {{we assume}} {{that there is a}} joint {{probability}} distribution [...] over [...] and , and that the training set consists of [...] instances [...] drawn i.i.d. from [...] Note that the assumption of a joint probability distribution allows us to model uncertainty in predictions (e.g. from noise in data) because [...] is not a <b>deterministic</b> <b>function</b> of , but rather a random variable with conditional distribution [...] for a fixed [...]|$|E
5000|$|In {{probability}} theory and related fields, Malliavin calculus {{is a set}} of mathematical techniques and ideas that extend the mathematical field of calculus of variations from <b>deterministic</b> <b>functions</b> to stochastic processes. In particular, it allows the computation of derivatives of random variables. Malliavin calculus is also called the stochastic calculus of variations.|$|R
50|$|Applications that don't involve sorting {{would be}} in finding the mean, {{standard}} deviation, skewness and kurtosis of a statistical distribution, and in finding the integral and global maxima and minima of difficult <b>deterministic</b> <b>functions.</b> Subrandom numbers {{can also be used}} for providing starting points for deterministic algorithms that only work locally, such as Newton-Raphson iteration.|$|R
40|$|In {{this paper}} we {{construct}} general vector-valued infinite-divisible independently scattered random measures with values in R^m and their corresponding stochastic integrals. Moreover, given such a random measure, {{the class of}} all integrable matrix-valued <b>deterministic</b> <b>functions</b> is characterized in terms of certain characteristics of the random measure. In addition a general construction principle is presented...|$|R
5000|$|In {{an attempt}} to make GBM more {{realistic}} as a model for stock prices, one can drop the assumption that the volatility (...) is constant. If we assume that the volatility is a <b>deterministic</b> <b>function</b> of the stock price and time, this is called a local volatility model. If instead we assume that the volatility has a randomness of its own—often described by a different equation driven by a different Brownian Motion—the model is called a stochastic volatility model.|$|E
5000|$|It can {{be proved}} that realizations of any {{probability}} distribution {{other than the}} uniform one are mathematically equal to applying a (<b>deterministic)</b> <b>function</b> (namely, an inverse distribution function) on a random variable following the latter (i.e. an [...] "absolutely random" [...] one); the probabilities are contained in the deterministic element. A simple form of demonstrating it would be shooting randomly within a square and then (deterministically) interpreting a relatively large subsquare as the more probable outcome.|$|E
5000|$|... #Caption: The {{simplest}} way to quantize a signal {{is to choose}} the digital amplitude value closest to the original analog amplitude. This example shows the original analog signal (green), the quantized signal (black dots), the signal reconstructed from the quantized signal (yellow) {{and the difference between}} the original signal and the reconstructed signal (red). The difference between the original signal and the reconstructed signal is the quantization error and, in this simple quantization scheme, is a <b>deterministic</b> <b>function</b> of the input signal.|$|E
40|$|The {{problem of}} {{determining}} the mathematical model {{of the dynamics of}} multi-dimensional control systems in the presence of noise under the condition that the correlation functions cannot be found. Known statistical dynamics of linear systems is a more effective alternative. Background information is presented in the form of individual implementations nonergodic stochastic processes. Such a realization is <b>deterministic</b> <b>functions.</b> We introduce the concept of systems of sets of signals for the components on the semiring. For the system of sets of linearly dependent and linearly independent of the measured signals of a certain frequency properties. Frequency method is designed to deal with the noise on the set of <b>deterministic</b> <b>functions.</b> Example is the determination of the dynamic characteristics of the aircraft in accordance with the data obtained in one automatic landing. Comment: 9 pages. arXiv admin note: substantial text overlap with arXiv: 1103. 011...|$|R
30|$|Demand for perfect quality items is <b>deterministic</b> and <b>function</b> {{of current}} stock level.|$|R
30|$|Propagation models like Free Space and Two-Ray Ground {{predict the}} signal power {{received}} as <b>deterministic</b> <b>functions</b> of distance. It represents the communication {{area as a}} perfect sphere, however {{the behavior of a}} received signal propagation is random and distributed log-normally around the mean. The randomness of the signal behavior is caused by changes in the environment that directly impact the signal power [33].|$|R
