8753|91|Public
5|$|Not all {{software}} {{states are}} vulnerable to rowhammer attacks. An attacker thus needs to find right target states in order to utilize rowhammer errors. In practice, {{one of the main}} challenges is in identifying target states. Such typically have been done by domain experts. The mainstream <b>fault</b> <b>tolerance</b> community responded to rowhammer attacks with a systematic methodology which can be used to identify, validate, and evaluate rowhammer attack target states and their exploitability. That work is based on the well-established fault injection-based experimental methodology, and generalized attack target states and found a few practical target states that were previously unknown.|$|E
5|$|On October 29, 1969, {{the first}} {{connection}} {{on a wide}} area network to use packet switching, ARPANET, was established between nodes at Leonard Kleinrock's laboratory at University of California, Los Angeles (UCLA) and Douglas Engelbart's laboratory at SRI using Interface Message Processors at both sites. The following year, Engelbart's laboratory installed the first TENEX system outside of BBN where it was developed. In addition to SRI and UCLA, University of California, Santa Barbara and the University of Utah {{were part of the}} original four network nodes. By December 5, 1969, the entire four-node network was connected. In the 1970s, SRI developed packet-switched radio (a precursor to wireless networking), over-the-horizon radar, Deafnet, vacuum microelectronics, and software-implemented <b>fault</b> <b>tolerance.</b>|$|E
25|$|Some {{spacecraft}} {{such as the}} SpaceX Dragon flight system consider Byzantine <b>fault</b> <b>tolerance</b> {{in their}} design.|$|E
40|$|The Ad hoc {{networks}} are distributed networks, self-organized {{and does not}} require infrastructure. In such network, mobile infrastructures are subject of disconnections. This situation may concern a voluntary or involuntary disconnection of nodes caused by the high mobility in the Ad hoc network. In these problems we are trying through this work to contribute to solving these problems {{in order to ensure}} continuous service by proposing our service for <b>faults</b> <b>tolerance</b> based on Multi Agent Systems (MAS), which predict a problem and decision making in relation to critical nodes. Our work contributes to study the prediction of voluntary and involuntary disconnections in the Ad hoc network; therefore we propose our service for <b>faults</b> <b>tolerance</b> that allows for effective distribution of information in the Network by selecting some objects of the network to be duplicates of information...|$|R
40|$|An {{approach}} to reconfiguration in tree architectures {{has been developed}} in which redundant processors are allocated at the leaves. The scheme is called sub-tree oriented <b>fault</b> <b>tolerances</b> (SOFT) and is capable of tolerating both link failures as well as multiple processor failures. In this paper, the SOFT scheme is examined {{from the perspective of}} reconfigurability. Specific algorithms are presented for reconfiguration...|$|R
40|$|Abstract—NASA {{missions}} require autonomous {{systems that}} perform correctly {{for an extended}} period of time. These systems must make real-time decisions in logical sequence that meet timing requirements. These systems must anticipate faults induced by environmental change, but it is difficult to anticipate the infinite variety of situations one must encounter for the design of robotic explorers, spacecraft, and systems necessary for the management of a mission. An Automated Reasoning program seeks to establish tolerances for change or alteration and seeks computational formulas for verifying scalable <b>fault</b> <b>tolerances...</b>|$|R
25|$|A DHT {{system that}} is {{carefully}} designed to have Byzantine <b>fault</b> <b>tolerance</b> can defend against a Sybil attack.|$|E
25|$|Because of the decentralization, <b>fault</b> <b>tolerance,</b> and {{scalability}} of DHTs, {{they are}} inherently more resilient against a hostile attacker than a typical centralized system.|$|E
25|$|There {{are also}} {{fundamental}} challenges that {{are unique to}} distributed computing. The first example is challenges {{that are related to}} fault-tolerance. Examples of related problems include consensus problems, Byzantine <b>fault</b> <b>tolerance,</b> and self-stabilisation.|$|E
40|$|Abstract—Because {{fingerprint}} {{patterns are}} fuzzy {{in nature and}} ridge endings are changed easily by scares, we try to only use ridge bifurcation as fingerprints minutiae and also design a “ fuzzy feature image ＂ encoder by using cone membership function to represent the structure of ridge bifurcation features extracted from fingerprint. Then, we integrate the fuzzy encoder with back-propagation neural network (BPNN) as a recognizer which has variable <b>fault</b> <b>tolerances</b> for fingerprint recognition. Experimental {{results show that the}} proposed fingerprint recognition system is robust, reliable and rapid...|$|R
40|$|In {{distributed}} computing environments, <b>fault</b> [...] <b>tolerance</b> {{is an important}} objective, especially for parallel applications. Many {{distributed computing}} environments achieve <b>fault</b> [...] <b>tolerance</b> by periodic checkpointing. This {{has the advantage of}} relative ease of implementation and can be considered equivalent to task migration. However, there are two main disadvantages of such environments. One is that any work in progress after checkpoint- ing is lost when a fault occurs. The other is that these systems are heavily reliant on task migra- tion as the only mechanism for load balancing. This paper presents a system that overcomes these shortcomings by task duplication and by the integration of data migration into task migration as a load balancing mechanism. It also presents results of a preliminary implementation. Key Words: Distributed computing, Task Migration, Load Balancing, <b>Fault</b> [...] <b>Tolerance</b> Point of Contact: Samuel H. Russ Phone: + 1 (601) 325 [...] 7775 Fax: + 1 (601) 325 [...] 7692 Mail: Engi [...] ...|$|R
40|$|ISBN: 0818681683 We present {{here the}} first version of an {{automatic}} tool for the synthesis of dataparts with <b>fault</b> detection or <b>tolerance</b> characteristics. This work is to be combined with solutions already proposed for controllers, in order to provide a complete control-dominated synthesis flow allowing the synthesis of control/data architectures with <b>fault</b> detection or <b>tolerance</b> capabilities...|$|R
25|$|In {{computer}} science, hierarchical protection domains, {{often called}} protection rings, are mechanisms to protect data and functionality from faults (by improving <b>fault</b> <b>tolerance)</b> and malicious behaviour (by providing computer security). This approach is diametrically opposite {{to that of}} capability-based security.|$|E
25|$|All {{three models}} {{supported}} a triple-mode redundancy configuration with three CPUs {{used in a}} byzantine <b>fault</b> <b>tolerance</b> scheme with bus freeze, instruction retry, and chip replacement signals. The V80 also added parity signals to its data and address buses.|$|E
25|$|DNS serves other {{purposes}} {{in addition to}} translating names to IP addresses. For instance, mail transfer agents use DNS {{to find the best}} mail server to deliver e-mail: An MX record provides a mapping between a domain and a mail exchanger; this can provide an additional layer of <b>fault</b> <b>tolerance</b> and load distribution.|$|E
40|$|We {{analyze the}} {{achievable}} <b>fault</b> <b>tolerances</b> of shared memory consistency {{conditions in the}} form of t-resilience, the ability to withstand up to t node failures. We derive tight bounds for linearizability, sequential consistency, processor consistency, and some weaker memories in totally asynchronous systems, in which failed and slow nodes cannot be distinguished. For linearizability, we show that neither the read nor the write operation can tolerate more failures than a minority of the nodes. For sequential consistency, processor consistency, and related conditions, we show that one operation can be wait-free and the other cannot tolerate more failures than a minority of the nodes. Several weaker conditions can have both operations wait-free...|$|R
40|$|Studies of {{the path}} {{characteristics}} and path velocities of industrial robots reveal that the automation of complex movements involves enormous restrictions. These restrictions often result in longer machining periods and a modest economic efficiency of automation. Compliant systems increase the product-specific investment costs but lead to considerable reductions in production costs due to minimization of the remaining cost and due to shorter machining periods. Efficiency analyses were made to assess the nonmonetary parameters of compliant-system uses. Complex production processes can be controlled safely given adequate <b>fault</b> <b>tolerances</b> and a reduced system complexity. (orig.) SIGLEAvailable from TIB Hannover: F 94 B 1198 / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDeutsche Forschungsgemeinschaft (DFG), Bonn (Germany) DEGerman...|$|R
40|$|Abstract- Automotive constructors want to replace, {{critical}} {{mechanical functions}} by electronical components communicating by a real time embedded network (X-by-Wire technologies). To implement such critical functions, these networks have hard real-time and <b>faults</b> <b>tolerance</b> constraints. There exist two automotive protocol families: Event-Triggered e. g. CAN and Time-Triggered e. g. TTP/C. The {{aim of this}} paper is to compare these two protocols efficiency using Quality of Service (QoS) criteria. A methodology based on timed automata modeling (UPPAAL) is used to obtain efficiency measurements. An example of X-by-Wire application (engine control) is used to show impact of network properties on application QoS. The X-by-Wire application QoS gives from application point of view the protocol efficiency. K ey Words: Real Time embedded network...|$|R
25|$|An {{important}} {{consideration in the}} design of a kernel is the support it provides for protection from faults (<b>fault</b> <b>tolerance)</b> and from malicious behaviours (security). These two aspects are usually not clearly distinguished, and the adoption of this distinction in the kernel design leads to the rejection of a hierarchical structure for protection.|$|E
25|$|One {{approach}} is to use firmware and kernel support for <b>fault</b> <b>tolerance</b> (see above), and build the security policy for malicious behavior {{on top of that}} (adding features such as cryptography mechanisms where necessary), delegating some responsibility to the compiler. Approaches that delegate enforcement of security policy to the compiler and/or the application level are often called language-based security.|$|E
25|$|Hostnames and IP {{addresses}} are {{not required}} to match in a one-to-one relationship. Multiple hostnames may correspond to a single IP address, which is useful in virtual hosting, in which many web sites are served from a single host. Alternatively, a single hostname may resolve to many IP addresses to facilitate <b>fault</b> <b>tolerance</b> and load distribution to multiple server instances across an enterprise or the global Internet.|$|E
40|$|This {{work will}} try to join two axis of {{research}} which concepts are in vogue. The first concerns the federated identity. The studies in this topic will allow the interconnection of information system, access to different resources and, above all, a secure and controlled sharing data. The implementation of such architectures required several exchanges of requests and responses which can be costly in terms of traffic data. So the second axis, namely mobile agents, intervenes to solve these problems. They offer the advantage of reducing the network load, to move the code to the data, to provide more <b>faults</b> <b>tolerance</b> [...] . So this work seeks {{to take advantage of}} the benefits that can offer mobiles agents to improve the architecture of federated identity...|$|R
50|$|This work is {{centered}} on the assessment of a component’s safety and its fitness for purpose in terms of safety-relevant demands under operational loads. The applications range from proving the safety of power station components to confirming the <b>fault</b> <b>tolerances</b> of aerospace components, the life expectancy analysis of components in power stations and vehicles subjected to thermomechanical loads to crash analyses of vehicle components. The {{focus is on the}} operational behavior of modern materials as well as joins and hybrid constructions. Development work is also carried out on mechanism-based material models {{for a wide range of}} applications with which to describe the deformation and failure behavior of components under thermal and mechanical loads. Crash analysis increasingly involves determining the influence of the manufacturing process on the failure behavior of vehicle structures.|$|R
40|$|The Atomic {{broadcast}} problem {{constitutes an}} essential component in fault-tolerant distributed systems. An Atomic broadcast algorithm ensures that all processes deliver the same messages sequence. Many algorithms have been published. Recently, a new Paxos-based algorithm has been proposed for clustered systems, named Ring Paxos. It inherits many of its characteristics: safe under asynchronous assumptions, live under weak synchronous assumptions, and requires a majority of non faulty processes to ensure progress. However, the proposed algorithm relies on strong assumptions, and uses the group membership for <b>faults</b> <b>tolerance.</b> In this paper, we propose a new Ring Paxos-based atomic broadcast algorithm for distributed systems. It inherits some of Ring Paxos characteristics and uses failure detectors to tolerate failures. A slight comparison between Ring Paxos and the proposed algorithm shows that our algorithm surpasses {{the performance of the}} other algorithm...|$|R
25|$|Byzantine {{failures}} {{are considered}} the most general and most difficult class of failures among the failure modes. The so-called fail-stop failure mode occupies the simplest end of the spectrum. Whereas fail-stop failure model simply means {{that the only way}} to fail is a node crash, detected by other nodes, Byzantine failures imply no restrictions, which means that the failed node can generate arbitrary data, pretending to be a correct one, which makes <b>fault</b> <b>tolerance</b> difficult.|$|E
25|$|The {{objective}} of Byzantine <b>fault</b> <b>tolerance</b> {{is to be}} able to defend against Byzantine failures, in which components of a system fail with symptoms that prevent some components of the system from reaching agreement among themselves, where such agreement is needed for the correct operation of the system. Correctly functioning components of a Byzantine fault tolerant system will be able to provide the system's service, assuming there are not too many faulty components.|$|E
25|$|Modern {{communications}} {{theory has}} introduced methods to increase <b>fault</b> <b>tolerance</b> in cell organizations. In the past, if cell members only knew the cell leader, {{and the leader}} was neutralized, the cell was {{cut off from the}} rest of the organization. Game theory and graph theory have been applied to the study of optimal covert network design (see Lindelauf, R.H.A. et al. 2009. The influence of secrecy on the communication structure of covert networks. Social Networks 31: 126-137).|$|E
40|$|Presentation of the "Workshop on <b>fault</b> {{diagnosis}} and <b>tolerance</b> in cryptography" - FDTC 2004. Cryptographic devices {{are becoming increasingly}} ubiquitous and complex, making reliability an important design objective. Moreover, the diffusion of mobile, low-price consumer electronic equipment containing cryptographic components makes them more vulnerable to attack procedures, in particular to those based on injection of faults. This workshop aims at providing researchers in both the dependability and cryptography communities an opportunity to start bridging the gap between <b>fault</b> {{diagnosis and}} <b>tolerance</b> techniques, and cryptography...|$|R
40|$|When {{the shared}} memory {{paradigm}} is implemented in software on a distributed system, {{the result is}} distributed shared memory (DSM). Various consistency conditions for DSM have been explored in the literature. Each represents a tradeoff between efficiency and ease of use. Various {{quantitative and qualitative analyses}} of shared memory consistency conditions have been published. In this paper, we analyze the achievable <b>fault</b> <b>tolerances</b> of consistency conditions in the form of t-resilience, the ability to withstand up to t node failures. We derive tight bounds for several consistency conditions. The message-passing model is completely asynchronous; that is, failed processors cannot be distinguished from slow processors. 1 Introduction The programming of distributed systems is complex, due to the nondeterministic nature of such systems. In the message passing paradigm, the programmer has low-level control, but must explicitly manage shared data. The shared memory paradigm is attr [...] ...|$|R
40|$|Part 12 : Fault-Tolerant SystemsInternational audienceWhen {{a patient}} have severe heart diseases, Ventricular Assist Device (VAD) {{implantation}} may be necessary. However, {{the improvement of}} the interaction between the device and the patient’s behavior is crucial. Currently, the control of these pumps does not follow changes in patient behavior and the devices are no safe. Therefore, if VAD has no <b>faults</b> <b>tolerance</b> and no dynamic behavior according to the cardiovascular system performance, there is a serious limitation on expected results. This research investigates a mechatronic approach for this class of devices based on advanced techniques for control, instrumentation and automation to define a method for developing a hierarchical supervisory control system to control a VAD dynamically and securely. To apply this method, concepts based on Petri nets and Safety Instrumented Systems are used. This innovation reduces the interventions and unnecessary drugs, enabling a reduction of deposable material and patient hospitalization, and contributes to sustainability concept...|$|R
25|$|AOA (Angle Of Attack) is a {{critically}} important flight parameter, and full-authority flight control {{systems such as}} those equipping A330/A340 aircraft require accurate AOA data to function properly. The aircraft was fitted with three ADIRUs to provide redundancy and enable <b>fault</b> <b>tolerance,</b> and the FCPCs used the three independent AOA values to check their consistency. In the usual case, when all three AOA values were valid and consistent, the average value of AOA 1 and AOA 2 {{was used by the}} FCPCs for their computations. If either AOA 1 or AOA 2 significantly deviated from the other two values, the FCPCs used a memorised value for 1.2 seconds. The FCPC algorithm was very effective, but it could not correctly manage a scenario where there were multiple spikes in either AOA 1 or AOA 2 that were 1.2 seconds apart.|$|E
2500|$|... and the Boeing 787 {{flight control}} systems, use Byzantine <b>fault</b> <b>tolerance.</b> [...] Because these are {{real-time}} systems, their Byzantine <b>fault</b> <b>tolerance</b> solutions must have very low latency. [...] For example, SAFEbus can achieve Byzantine <b>fault</b> <b>tolerance</b> {{with on the}} order of a microsecond of added latency.|$|E
2500|$|Several system {{architectures}} were designed c. 1980 that implemented Byzantine <b>fault</b> <b>tolerance.</b> [...] These include: Draper's FTMP, ...|$|E
40|$|It is {{necessary}} to verify the <b>faults</b> <b>tolerance</b> of the European Train Control System (ETCS) on-board unit even if these faults are uncommon. Traditional test methods defined and used in ETCS do not allow to check this, so it {{is necessary}} to develop a new mechanism of tests. This paper presents the design and implementation of a saboteur applied to the railway sector. The main purpose of the saboteur is the fault injection in the communication interfaces. By means of a virtual laboratory it is possible to simulate actual train journeys to test the ETCS on-board unit. Making use of the saboteurs and the virtual laboratory it is possible to analyse the behaviour of the train in the presence of unexpected faults, and to verify that the decisions taken are correct to ensure the required safety level. Therefore, this work shows a testing strategy based on different kinds of train journeys when faults are injected, and the analysis of the results. </p...|$|R
40|$|Research is {{proposed}} into {{the theory and}} practice of distributed shared object systems. Specific points of inquiry are the application of compositional techniques to such systems, and techniques for constructing fault tolerant objects. In particular, we give an object-oriented model of concurrent systems, and show how to support proof reuse by applying existing compositional proof techniques to the model. We demonstrate the technique with an example, that of synchronizing nodes in a distributed system with gossip. We analyze the achievable <b>fault</b> <b>tolerances</b> of distributed shared memories in a totally asynchronous system. The analysis is in terms of t-resilience, the ability to operate correctly without blocking in spite of t node failures. We remark on current work on extending this analysis to general objects, and relationships to work on deriving lower bounds (in terms of network latencies) for various operations, as well as work on wait-free hierarchies. Finally, we present a design f [...] ...|$|R
40|$|Due to the {{inherent}} {{characteristics of the}} flight mission of a space launch vehicle (SLV), which is required to fly over very large distances and have very high <b>fault</b> <b>tolerances,</b> in general, SLV tracking systems (TSs) comprise multiple heterogeneous sensors such as radars, GPS, INS, and electrooptical targeting systems installed over widespread areas. To track an SLV without interruption and {{to hand over the}} measurement coverage between TSs properly, the mission control system (MCS) transfers slaving data to each TS through mission networks. When serious network delays occur, however, the slaving data from the MCS can lead to the failure of the TS. To address this problem, in this paper, we propose multiple model-based synchronization (MMS) approaches, which take advantage of the multiple motion models of an SLV. Cubic spline extrapolation, prediction through an α-β-γ filter, and a single model Kalman filter are presented as benchmark approaches. We demonstrate the synchronization accuracy and effectiveness of the proposed MMS approaches using the Monte Carlo simulation with the nominal trajectory data of Korea Space Launch Vehicle-I...|$|R
