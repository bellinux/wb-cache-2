5|19|Public
5000|$|Users {{will be able}} to {{set their}} default <b>download</b> <b>folder,</b> wallpaper, theme and reset the icon layout of a theme to its default layout from “Homescreen Preferences” ...|$|E
5000|$|Small {{practical}} {{programs are}} also included: screenshot, calendar, file search, automatic sorting <b>download</b> <b>folder,</b> Bleachbit for cleaning, archive manager [...] "Archive Manager", Disk Utility for formatting, Hardinfo for system information, Xl-wallpaper wallpaper changer.|$|E
50|$|Internet Config's {{purpose was}} to {{consolidate}} what was, at the time, an unwieldy number of options and settings related to Internet use {{that had not yet}} been integrated into the operating system's own control panel. Some settings were for a systemwide default web browser, home page, default FTP client, systemwide default <b>download</b> <b>folder,</b> and email settings. Internet Config represented an important ease of use advantage for the Macintosh platform on the early Internet.|$|E
25|$|Features of Dillo include bookmarks, tabbed browsing, {{and support}} for JPEG, PNG (including alpha transparency), and GIF images. Partial support for CSS was {{introduced}} in release 2.1. Settings such as the default fonts, background color, <b>downloads</b> <b>folder,</b> and home page are customizable through configuration files. Cookies are supported but disabled by default due to privacy concerns. While most web browsers retain the web cache and history after the program is closed, Dillo automatically clears them to improve both privacy and performance.|$|R
50|$|Lists {{are fully}} browsable, {{configurable}} and allow users to share {{exactly what they}} want with whom they want. Users can queue many downloads and can also <b>download</b> complete <b>folders.</b>|$|R
50|$|Firefox 43.0.1 was {{released}} on December 18, 2015 for desktop only, {{to prepare for the}} use of SHA-256 signing certificate for Windows builds, to meet a new signing requirement. Three days later, Firefox 43.0.2 {{was released}} for desktop only, citing not only the use of SHA-256 signing certificate for Windows builds, but also various security fixes. Firefox 43.0.3 was released for desktop only on December 28, 2015, fixing a network issue when using Nvidia's Network Access Manager, and improving the decoding of some videos on YouTube on some Windows configurations. Firefox 43.0.4 was released for desktop only on January 6, 2016, fixing a startup crash for users of a third party antivirus tool, allowing the creation of multi-user GNU/Linux <b>download</b> <b>folders,</b> and re-enabling SHA-1 certificates.|$|R
5000|$|For {{its first}} two years, the {{enclosure}} element had relatively few users and many developers simply avoided using it. Winer's company incorporated both RSS-enclosure and feed-aggregator features in its weblogging product, Radio Userland, the program favored by Curry, audioblogger Harold Gilchrist and others. Since Radio Userland had a built-in aggregator, it provided both the [...] "send" [...] and [...] "receive" [...] components of what was then called [...] "audioblogging". All that was needed for [...] "podcasting" [...] {{was a way to}} automatically move audio files from Radio Userland's <b>download</b> <b>folder</b> to an audio player (either software or hardware) -- along with enough compelling audio to make such automation worth the trouble.|$|E
40|$|The aim of {{this thesis}} was to {{implement}} prototype which, provides relevant information to the user at right time. The personal information that is targeted here was health-related information. This may include various type of information, such as drug information, education information, health monitor data for instance glucoses meter, step counter, personal notes, health related images,PDF files. To implement prototype, we use metadata of the information. Some of the metadata of the information describes {{the context of the}} information. We used time, date and location context of information to implement our goal successfully. By using these contexts of the information, the relevant information to user is provided. The four components were implemented to implement prototype: Metadata extractor, Information manger, controller and user interface. The metadata extractor allows user to download files and automatically store file in to the <b>download</b> <b>folder</b> and context of these files was extracted and stored in to the database. The second component was information manger; the main function of this component was to reads the context of downloaded files and make association of similar files by using context. The third component was controller, it was use to represent related files to the end users and the user interface allows user to interact with our system. The implemented prototype was tested for providing related information to the users. The information access was based on the context of the information, which eases to get results and to recognize useful information for the users. It was also tested whether the prototype stores updated files or not. The prototype makes association of new downloaded files to the database and it also avoids redundancy of files. Thus, it helps users to access the updated information and to reduce redundancy of data. The prototype provides user with the right set of information to the right time, by identifying the need of the users by matching with available information...|$|E
40|$|I used {{a machine}} with Ubuntu 16. 04 and DADA 2 (vsn 1. 5. 2) to coax the Ribosomal Database Project's Training set 11 {{and the current}} release of the RDP {{database}} (for the unaligned fasta) into a DADA 2 compatible format. If you use this, please cite the original sources too! # 1 Wrangle the RDP trainingsets and unaligned data into the <b>downloads</b> <b>folder</b> either by manually downloading them or by executing this from a terminal and move the file somewhere with /media/lauren/ 96 BA- 19 E 6 /fungallsu/RDPClassifier_fungiLSU_trainsetNo 11 _rawtrainingdata/fungiLSU_train_ 012014 _lsu_fixed. fa # 3 In R. Studio, summon the dada 2 pkg library(dada 2);packageVersion("dada 2 ") # 4 Transform the RDP formatted training fastas path<-"~"#change this to where your files sit on your computer dada 2 :::makeTaxonomyFasta_RDP(file. path(path, "fungiLSU_train_ 012014 _lsu_fixed. fa"), file. path(path, "fungiLSU_taxid_ 012014. txt"),"fungiLSU_trainset_ 012014. fa. gz") dada 2 :::makeSpeciesFasta_RDP("current_Fungi_unaligned. fa", "rdp_species_assignment_LSU. fa"...|$|R
50|$|As of August 2011, the Zune Marketplace has 62 apps for Zune HD, {{of which}} 42 are games. All of the apps and games are free. Apps {{available}} excluding games are Calendar, Fingerpaint, Stopwatch, Alarm Clock, Chord Finder, Facebook, Twitter, MSN Money, MSN Weather, Calculator, Piano, Metronome, Level, Drum Machine, Fan Prediction, Shuffle by Album, Windows Live Messenger, Notes, Email and Zune Reader. An extension to the Microsoft XNA framework providing development {{support for the}} Zune HD was released on September 16, 2009. The Zune PC Software {{can be used for}} adding apps to the Zune HD. The Windows Live Messenger app for the Zune HD was released on October 1, 2010, making Messenger available for all major mobile platforms.The email app was released for the Zune HD in April 2011 allowing users to sync with their email accounts and <b>download</b> <b>folders</b> and emails. The app is similar to the email interface on the Windows Phone.|$|R
40|$|Instructions for use In {{order to}} re-run this experiment, please follow these steps: 1) {{download}} this repository 2) unzip the <b>downloaded</b> <b>folder</b> 3) replace path/to/package in line 9 {{of the shell}} script inst/annual-forecasts-workflow. sh with the absolute path to the unzipped folder and save the file 4) run the shell script (on a Mac in the Terminal write: sh path/to/package/inst/annual-forecasts-workflow. sh; the author does not know the PC equivalent of this command) This shell script: 1) creates an R packrat project, which installs all of the packages used to originally run the analysis (note: this step may take 10 minutes or longer, sometimes due to a long installation of the stringi package) 2) runs make-forecasting-data. R, which puts together the forecasting data from the raw data 3) runs make-forecasts. R which conducts cross validation, model selection, and makes out-of-sample forecasts 4) runs Lauer-annual-DHF-figures. Rnw which makes the figures for the manuscript 5) runs Lauer-annual-DHF-supplement. Rnw which makes the supplement 6) runs Lauer-annual-DHF-manuscript. Rnw which makes the manuscrip...|$|R
40|$|The zip folder {{holds the}} files of the proof of concept for my PhD dissertation: “Comprehensive Odyssey”, a digital {{critical}} repository of the Odyssey and its sources: Perspectives and Consequences. To view it <b>download</b> the <b>folder,</b> unzip it and open "Comprehensive Odyssey home page. html". To view the source files open "Odyssey book 1. xml", "Bibliography secondary sources. xml" and "Scholia Book α. xml"...|$|R
40|$|Archived {{version of}} digital project and website, "Chronicling Hoosier" as of December 12, 2016. To use this {{archived}} {{version of a}} live website, <b>download</b> the zipped <b>folder,</b> unzip the folder, and then open the file named "index. html" This digital project was designed to work optimally in Google Chrome...|$|R
50|$|While Soulseek, {{like other}} P2P clients, allows a user to {{download}} individual files from another by selecting each {{one from a}} list of search results, a <b>Download</b> Containing <b>Folder</b> option simplifies the downloading of entire albums. For example, a user who wishes to facilitate the distribution of an entire album may place all tracks relating to the album together in a folder on the host PC, and the entire contents of that folder (i.e. all the album's track files) can then be downloaded automatically one after the other using this one command.|$|R
30|$|Download TOUGH 2 (optional) If {{the user}} {{would like to}} use the {{coupling}} with TOUGH 2 (reservoir option 6), then a TOUGH 2 executable should be provided in the GEOPHIRES <b>folder.</b> <b>Downloading</b> and running a TOUGH reservoir simulator requires the purchase of a license from Lawrence Berkeley National Laboratory (LBNL).|$|R
40|$|Presentation of, and {{measures}} used to analyse, business data. Comprehensive 63 page workbook including MS Excel exercises. This is an online version {{that can be}} displayed in a browser allowing the student to select exercises - <b>download</b> the zip <b>folder,</b> extract the files, upload to your desired location (the index, or home page, is called page_ 01. htm) ...|$|R
40|$|Respond to {{this article}} Alert me when this article is cited Alert me when {{responses}} are posted Alert me when a correction is posted View citation map Services Email this article to a friend Find similar articles in BMJ Find similar articles in PubMed Add article to my <b>folders</b> <b>Download</b> to citation manager Read articles citing this articl...|$|R
40|$|A video markscheme {{was created}} using a {{combination}} of Camtasia screen capture (on a Tablet PC) and 'live action' video taken with a camcorder. The resulting video supported students in the self-assessment of an organic chemistry exercise which had been set over the Easter vacation break. Feedback was collected from the students after the exercise and was overwhelmingly positive. The video won the 2010 award for 'Most Effective Use of Video in an Educational Context' from the Assocation for Learning Technology. <b>DOWNLOAD</b> THE ZIP <b>FOLDER</b> AND EXTRACT THE FILES TO ACCESS THEM...|$|R
50|$|For example, {{the weather}} map display {{system at the}} Department of Geography/Geology at the University of Nebraska at Omaha has been in {{continuous}} operation since 1999. Consisting of six Apple Macintosh computers, some dating to 1992 and with as little as 32 MB of memory, the system uses Cron and Applescript to perform certain operations every hour. Files that are downloaded include GIF or JPEG images that display current weather conditions, including NEXRAD radar, lightning strikes, weather warnings and watches. Once the files are <b>downloaded</b> to a <b>folder,</b> JPEGView displays the files in a continuous loop. After an hour, JPEGView stops, the weather maps are deleted {{a new set of}} maps are downloaded. JPEGView starts again and the new maps are displayed.|$|R
40|$|Uniform covers with a finite-dimensional nerve {{are rare}} (i. e., do not form a cofinal family) in many {{separable}} metric spaces of interest. To get hold on uniform homotopy properties of these spaces, a reasonably behaved {{notion of an}} infinite-dimensional metric polyhedron is needed; a specific list of desired properties was sketched by J. R. Isbell {{in a series of}} publications in 1959 - 64. In this paper we construct {{what appears to be the}} desired theory of uniform polyhedra; incidentally, considerable information about their metric and Lipschitz properties is obtained. Comment: 39 pages. v 2 : The combinatorial chapter of the first version has moved to arXiv:math. GT/ 1208. ????. (Hyperlinks to that paper and to the other prequel should work if the three pdf files are <b>downloaded</b> into one <b>folder.)</b> A lemma on mapping cylinders is corrected. Introduction is revised. Some minor results are added in the last sectio...|$|R
40|$|Abstract — 1 We {{present a}} first {{practical}} packet-level windowbased congestion controller (4 CP) that implements farsighted strategy, which was introduced and {{shown to be}} optimal for sources that value large long-run average throughput and are indifferent to sporadic throughput degradations (Key-Massoulié-Vojnović, 2005). Following farsighted strategy, the controller distinguishes good and bad congestion phases; in the former, it aims at balancing loss probability to a target value, while in the latter it virtually sends no data. The target loss probability is adapted very slowly so that the 4 CP source verifies a given (TCP) loss-throughput formula over large timescale. The send rate is reduced to (virtually) zero {{in a controlled manner}} only during bad congestion phases, and not under full control of other (TCP) transfers, as it is the case with prior low-priority service emulators. We believe that its underlying features make 4 CP a good candidate for file transfer applications such as file <b>downloading</b> and sharing, <b>folder</b> and database synchronization. We demonstrate that the short-timescale throughput flexibility of 4 CP can be at the benefit of competing short-run TCP transfers. In the design, we address a number of requirements, such as bad phase detection with low false positives and quick detection. Besides a new protocol design, we present new analysis results that include a sufficient condition for local stability that accounts for feedback delay, maximum achievable throughput gain of 4 CP user over a competing TCP user, and obtain an estimate for the false positive probability of the bad phase detector that provides parameter setting guidelines. Our results are validated by extensive simulations and some experiments over the Internet...|$|R
40|$|Music at the Fair!” {{gives the}} daily musical {{programs}} for The Trans-Mississippi and International Exposition, held in Omaha, Nebraska, June 1 through October 31, 1898. The Trans-Mississippi and International Exposition brought an unprecedented array of local, national, and international musical acts to Omaha, NE in 1898. This served to designate Omaha, 2 ̆ 2 {{the gateway to}} the west 2 ̆ 2 as a musical hub, {{as well as to}} incite musical excitement in the region. Some of the more popular acts featured were the Theodore Thomas Orchestra, the U. S. Marine Band, and the Apollo Club of Chicago. Many more groups and their musical programs can be found within the pages of this site. The “Music at the Fair!” website was created by Grace Carey, and last revised on May 19, 2006. It {{is the result of a}} two- year research grant funded by an Undergraduate Creative Activities and Research Experiences (UCARE) grant through the University of Nebraska at Lincoln. It is an extension of an ongoing project on music at the TME by Music Professor Peter Lefferts. The primary sources of information for the site are the following newspapers from June – November 1898 : The Omaha Daily Bee, the Omaha Evening Bee, and the Omaha World Herald, and the the official programs of the fair located in the archives at the Omaha Public Library. I would like to thank the helpful staff at the Nebraska State Historical Society and the downtown branch of the Omaha Public Library. Site Creator: Grace Carey Project Advisor: Peter Lefferts, Professor of Music History at the University of Nebraska, Lincoln The linked “Document” is a flat PDF version of the interactive website. To download the fully interactive html version, click on the “Related file” to <b>download</b> the zipped <b>folder.</b> When unzipped, click on the file named “index” to enter the website...|$|R
40|$| {{maximum number}} of events {{that you want to}} test. For {{instance}} if you choose a minimum of 1 and a maximum of 3 events, the interface will create 3 different inversions, one with a single exhumation event (called 1 ev), a second with 2 events (called 2 ev), and a third with 3 events [...] . In that case, 3 folders are created in the inversion directory : 1 ev, 2 ev, and 3 ev, each containing the executables for the inversion. See the example below: ``` ** Content of the Inversion folder ** └─── Inversions -> folder containing all inversion projects │ └─── TEST -> Folder of the multi-inversion project 'TEST' │ └─── 1 ev -> folder containing the executables └─── bin for the inversion using 1 event └─── data └─── modelscarp_param └─── results └─── src │ └─── 2 ev -> folder containing the executables └─── bin for the inversion using 2 events └─── data └─── modelscarp_param └─── results └─── src │ └─── 3 ev -> folder containing the executables └─── bin for the inversion using 3 events └─── data └─── modelscarp_param └─── results └─── src ``` Generate parameter files for the inversions create those inversion folders and start the assistant to run the inversion and plot the live results. Because the inversion can take a long time on a single computer, it is recommended to run the multiple inversions out of Matlab. The Matlab graphical interface will enable you to follow the results. To run an inversion: open a terminal (out of Matlab) Go to the inversion directory. For instance for the 1 event inversion: cd Modelscarp_V 2 /Inversions/TEST/ 1 ev/bin Start the inversion with the following command:. /modelscarp Because the inversion can take a long time on a single computer, it is recommended to run the multiple inversions out of Matlab. The Matlab graphical interface will enable you to follow the results by clicking on Live results, or on Plot results (on-going or finished inversion) on the initial menu. This interface enables you to follow the progress of each inversion that you have previously started, by selecting which inversion is followed on the left panel. -> When an inversion has finished, the results can be plotted on the right panel (cumulative slip over the time of each tested model, the color of the curve varies as function of the misfit of the model) -> Detailed results can be plotted showing for each tested models, the age and the slip of the events and the associated misfit (RMSw). Once an inversion has finished, you need to run the program envelop in the terminal (not in Matlab) to find all the models included within the analytical uncertainty and determine the uncertainties on the exhumation scenario. -> The cumulative slip of all those models are figured by the light green curves, and the best model in dark green. -> It is possible to plot the 36 Cl profile of the best model (red dots), compared with the data (black dots), as shown by the following figure: When all inversions have finished, it is possible to plot the RMSw of the best models has function of the number of events (as shown in the following figure) : It is also possible to plot the cumulative slip of the final scenario inferred from each inversion with a varying number of events: How to run modelscarp on a cluster ? It is better to run inversion on a cluster because usually a large number of iterations are required to converge and well explore the parameter space. Design the inversion project Similarly to the previous example, you need to create a multiple inversion project. In that case, you had to specify that the inversion will be operated on a cluster by clicking on cluster. Then generate the parameter files for the inversions. Copy the folder of the inversions on the cluster. The executables of each inversion have to be compiled on the cluster by running those commands in the terminal of your cluster, located in the directory of the inversion project. For instance: Connection from my computer to the cluster with the terminal: ssh yourcluster. com -l login Go to the directory of the inversion project called "TEST": cd your_path_to_modelscarp/Inversions/TEST Give the right to execute the script: chmod u+rwx compile_all. sh Execute the script of compilation:. /compile_all. sh wait for one or two minutes [...] . Start each inversion using the appropriated command of your cluster. For instance for the 1 event inversion, the script may contain those commands: % go to the binaries folder of the 1 event inversion cd your_path_to_modelscarp/Inversions/TEST/ 1 ev/bin % run the inversion program. /modelscarp_na % run the program to determine the uncertainties. /envelop At any time you can follow the evolution of an inversion by <b>downloading</b> the inversion <b>folder</b> on your computer, and using the Matlab interface Plot results (on-going or finished inversion) (in the first menu). In that case, the file tmp_misfitin the bin directory will be used to follow the evolution of the misfit over the iteration. <img src="Tutorial/images/Modelscarp_inversion_mult_ 5. png" width=" 400 "...|$|R

