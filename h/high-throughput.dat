10000|8|Public
5|$|Currently, {{solid-phase}} oligonucleotide synthesis {{is carried}} out automatically using computer-controlled instruments (oligonucleotide synthesizers) and is technically implemented in column, multi-well plate, and array formats. The column format is best suited for research and large scale applications where a <b>high-throughput</b> is not required. Multi-well plate format is designed specifically for <b>high-throughput</b> synthesis on small scale to satisfy the growing demand of industry and academia for synthetic oligonucleotides. A number of oligonucleotide synthesizers for small scale synthesis and medium to large scale synthesis are available commercially.|$|E
5|$|Following the uptake of Sanger sequencing, the Wellcome Trust Sanger Institute (then {{known as}} The Sanger Centre) had begun {{cataloguing}} sequence reads along with quality {{information in a}} database called The Trace Archive. The Trace Archive grew substantially with the commercialisation of <b>high-throughput</b> parallel sequencing technologies by companies such as Roche and Illumina.|$|E
5|$|Genome-scale RNAi {{research}} {{relies on}} <b>high-throughput</b> screening (HTS) technology. RNAi HTS technology allows genome-wide loss-of-function screening and is broadly {{used in the}} identification of genes associated with specific phenotypes. This technology has been hailed as the second genomics wave, following the first genomics wave of gene expression microarray and single nucleotide polymorphism discovery platforms.|$|E
5|$|In 2005 Stephan C. Schuster at Penn State University {{and colleagues}} {{published}} the first sequences {{of an environmental}} sample generated with <b>high-throughput</b> sequencing, in this case massively parallel pyrosequencing developed by 454 Life Sciences. Another early paper in this area appeared in 2006 by Robert Edwards, Forest Rohwer, and colleagues at San Diego State University.|$|E
5|$|In chemistry, {{peptides}} are synthesized by {{a variety}} of reactions. One of the most-used in solid-phase peptide synthesis uses the aromatic oxime derivatives of amino acids as activated units. These are added in sequence onto the growing peptide chain, which is attached to a solid resin support. The ability to easily synthesize vast numbers of different peptides by varying the types and order of amino acids (using combinatorial chemistry) has made peptide synthesis particularly important in creating libraries of peptides for use in drug discovery through <b>high-throughput</b> screening.|$|E
5|$|Nickel is an {{excellent}} alloying agent for certain precious metals and {{is used in the}} fire assay as a collector of platinum group elements (PGE). As such, nickel is capable of fully collecting all 6 PGE elements from ores, and of partially collecting gold. <b>High-throughput</b> nickel mines may also engage in PGE recovery (primarily platinum and palladium); examples are Norilsk in Russia and the Sudbury Basin in Canada.|$|E
5|$|Approaches to {{the design}} of {{genome-wide}} RNAi libraries can require more sophistication than the design of a single siRNA for a defined set of experimental conditions. Artificial neural networks are frequently used to design siRNA libraries and to predict their likely efficiency at gene knockdown. Mass genomic screening is widely seen as a promising method for genome annotation and has triggered the development of <b>high-throughput</b> screening methods based on microarrays. However, the utility of these screens and the ability of techniques developed on model organisms to generalize to even closely related species has been questioned, for example from C. elegans to related parasitic nematodes.|$|E
5|$|Because {{molecular}} diagnostics {{methods can}} detect sensitive markers, these tests are less intrusive than a traditional biopsy. For example, because cell-free nucleic acids exist in human plasma, a simple blood sample can {{be enough to}} sample genetic information from tumours, transplants or an unborn fetus. Many, but not all, molecular diagnostics methods based on nucleic acids detection use polymerase chain reaction (PCR) to vastly {{increase the number of}} nucleic acid molecules, thereby amplifying the target sequence(s) in the patient sample. The detection of the marker might use real time PCR, direct sequencing, or microarray chipsprefabricated chips that test many markers at once. The same principle applies to the proteome and the genome. <b>High-throughput</b> protein arrays can use complementary DNA or antibodies to bind and hence can detect many different proteins in parallel.|$|E
5|$|In {{addition}} to these preventable issues, GWA studies have attracted more fundamental criticism, mainly because of their assumption that common genetic variation plays {{a large role in}} explaining the heritable variation of common disease. This aspect of GWA studies has attracted the criticism that, although it could not have been known prospectively, GWA studies were ultimately not worth the expenditure. Alternative strategies suggested involve linkage analysis. More recently, the rapidly decreasing price of complete genome sequencing have also provided a realistic alternative to genotyping array-based GWA studies. It can be discussed if the use of this new technique is still referred to as a GWA study, but <b>high-throughput</b> sequencing does have potential to side-step some of the shortcomings of non-sequencing GWA.|$|E
5|$|In {{solid-phase}} synthesis, an oligonucleotide being assembled is covalently bound, via its 3'-terminal hydroxy group, to a {{solid support}} material and remains {{attached to it}} over the entire course of the chain assembly. The solid support is contained in columns whose dimensions depend {{on the scale of}} synthesis and may vary between 0.05mL and several liters. The overwhelming majority of oligonucleotides are synthesized on small scale ranging from 10nmol to 1μmol. More recently, <b>high-throughput</b> oligonucleotide synthesis where the solid support is contained in the wells of multi-well plates (most often, 96 or 384 wells per plate) became a method of choice for parallel synthesis of oligonucleotides on small scale. At the end of the chain assembly, the oligonucleotide is released from the solid support and is eluted from the column or the well.|$|E
5|$|New {{drugs are}} the {{products}} of a long drug development process, {{the first step of}} which is often the discovery of a new enzyme inhibitor. In the past the only way to discover these new inhibitors was by trial and error: screening huge libraries of compounds against a target enzyme and hoping that some useful leads would emerge. This brute force approach is still successful and has even been extended by combinatorial chemistry approaches that quickly produce large numbers of novel compounds and <b>high-throughput</b> screening technology to rapidly screen these huge chemical libraries for useful inhibitors.|$|E
5|$|The total {{complement}} of proteins present {{at a time}} in a cell or cell type is known as its proteome, and the study of such large-scale data sets defines the field of proteomics, named by analogy to the related field of genomics. Key experimental techniques in proteomics include 2D electrophoresis, which allows the separation {{of a large number of}} proteins, mass spectrometry, which allows rapid <b>high-throughput</b> identification of proteins and sequencing of peptides (most often after in-gel digestion), protein microarrays, which allow the detection of the relative levels of a large number of proteins present in a cell, and two-hybrid screening, which allows the systematic exploration of protein–protein interactions. The {{total complement}} of biologically possible such interactions is known as the interactome. A systematic attempt to determine the structures of proteins representing every possible fold is known as structural genomics.|$|E
25|$|They also {{proposed}} that new methods {{will be needed}} to model and summarize results of <b>high-throughput</b> analysis in ways that can be interpreted by biologists, as well as ways of integrating large-scale flow cytometry data with other <b>high-throughput</b> biological information, such as gene expression, genetic variation, metabolite levels and disease states.|$|E
25|$|The {{high demand}} for {{low-cost}} sequencing has driven {{the development of}} <b>high-throughput</b> sequencing technologies that parallelize the sequencing process, producing thousands or millions of sequences at once. <b>High-throughput</b> sequencing is intended to {{lower the cost of}} DNA sequencing beyond what is possible with standard dye-terminator methods. In ultra-high-throughput sequencing, as many as 500,000 sequencing-by-synthesis operations may be run in parallel.|$|E
25|$|Particularly in newer, <b>high-throughput</b> experiments, {{there is}} a need for {{visualization}} methods to help detect technical errors in individual samples.|$|E
25|$|Aerial {{photography}} and satellite imagery have provided high-accuracy, <b>high-throughput</b> methods for mapping physical features over large areas, such as coastlines, roads, buildings, and topography.|$|E
25|$|Because of {{its ability}} to {{dissolve}} many kinds of compounds, DMSO plays a role in sample management and <b>high-throughput</b> screening operations in drug design.|$|E
25|$|The {{negative}} {{binomial distribution}} is also commonly used to model gene expression {{in the form of}} discrete read count data from <b>high-throughput</b> RNA sequencing experiments.|$|E
25|$|Because {{there are}} no known {{naturally}} occurring deoxyribozymes, most known deoxyribozyme sequences have been discovered through a <b>high-throughput</b> in vitro selection technique, similar to SELEX.|$|E
25|$|This {{was echoed}} by {{another group of}} Pacific Biosciences and Stanford University researchers, who {{suggested}} that cloud computing could enable centralized, standardized, <b>high-throughput</b> analysis of flow cytometry experiments.|$|E
25|$|<b>High-throughput</b> {{screening}} (HTS) is {{a method}} for scientific experimentation especially used in drug discovery and relevant to the fields of biology and chemistry. Using robotics, data processing/control software, liquid handling devices, and sensitive detectors, <b>high-throughput</b> screening allows a researcher to quickly conduct millions of chemical, genetic, or pharmacological tests. Through this process one can rapidly identify active compounds, antibodies, or genes that modulate a particular biomolecular pathway. The results of these experiments provide starting points for drug design and for understanding the interaction or role of a particular biochemical process in biology.|$|E
25|$|The rapid {{increase}} in the dimensionality of flow cytometry data, coupled {{with the development of}} <b>high-throughput</b> robotic platforms capable of assaying hundreds to thousands of samples automatically have created a need for improved computational analysis methods.|$|E
25|$|Finally, {{diagnosis}} using {{flow cytometry}} {{data can be}} aided by supervised learning techniques, and discovery of new cell types of biological importance by <b>high-throughput</b> statistical methods, as part of pipelines incorporating all of the aforementioned methods.|$|E
25|$|It was {{originally}} {{developed at the}} Wellcome Trust Sanger Institute to bundle a FASTA sequence and its quality data, but has recently become the de facto standard for storing the output of <b>high-throughput</b> sequencing instruments such as the Illumina Genome Analyzer.|$|E
25|$|Protein–protein {{signalling}} interactions pose suitable therapeutic targets due {{to their}} specificity and pervasiveness. The random drug discovery approach uses compound banks that comprise random chemical structures, and requires a <b>high-throughput</b> method to test these structures in their intended target.|$|E
25|$|A {{major goal}} during the PSI:Biology phase is {{to utilize the}} <b>high-throughput</b> methods {{developed}} during the initiative's first decade to generate protein structures for functional studies, broadening the PSI's biomedical impact. It {{is also expected to}} advance knowledge and understanding of membrane proteins.|$|E
25|$|In academia, {{computational}} immunology is a {{field of}} science that encompasses <b>high-throughput</b> genomic and bioinformatics approaches to immunology. The field's main aim is to convert immunological data into computational problems, solve these problems using mathematical and computational approaches and then convert these results into immunologically meaningful interpretations.|$|E
25|$|Huang et al., (2008) {{have also}} {{developed}} at Purdue University (US) a simpler instrumentation and a faster method {{by using a}} low-temperature plasma probe to ionize the samples. The major obstacles being solved, the ESI-MS technique allows now <b>high-throughput</b> analysis of melamine traces in complex mixtures.|$|E
25|$|Since mRNAs {{are longer}} than the read-lengths of typical <b>high-throughput</b> {{sequencing}} methods, transcripts are usually fragmented prior to sequencing. The fragmentation method is a key aspect of sequencing library construction. It may incorporate chemical hydrolysis, nebulisation, or sonication of RNA, or utilise simultaneous fragmentation and tagging of cDNA by transposase enzymes.|$|E
25|$|RNA-Seq was {{established}} {{in concert with the}} rapid development of a range of <b>high-throughput</b> DNA sequencing technologies. However, before the extracted RNA transcripts are sequenced, several key processing steps are performed. Methods differ in the use of transcript enrichment, fragmentation, amplification, single or paired-end sequencing, and whether to preserve strand information.|$|E
25|$|Anduril is {{designed}} to enable systematic, flexible and efficient data analysis, particularly {{in the field of}} <b>high-throughput</b> experiments in biomedical research. The workflow system currently provides components for several types of analysis such as sequencing, gene expression, SNP, ChIP-on-chip, comparative genomic hybridization and exon microarray analysis as well as cytometry and cell imaging analysis.|$|E
25|$|Model organisms {{have been}} used in the study of S100B function. A {{conditional}} knockout mouse line, called S100btm1a(EUCOMM)Wtsi was generated as part of the International Knockout Mouse Consortium program — a <b>high-throughput</b> mutagenesis project to generate and distribute animal models of disease to interested scientists — at the Wellcome Trust Sanger Institute.|$|E
25|$|Sabatini’s {{research}} interests have expanded {{in recent years}} to include cancer metabolism as well as technology development surrounding the use of <b>high-throughput</b> genetic screens in human cells, most notably through the use of RNA interference and the CRISPR-Cas9 system. As of 2016, Sabatini has authored over 250 publications and has an h-index of 100.|$|E
25|$|At the University of Washington in the 1990s, Hood, Alan Blanchard, {{and others}} {{developed}} ink-jet DNA synthesis technology for creating DNA microarrays. By 2004, their ink-jet DNA synthesizer supported <b>high-throughput</b> identification and quantification of nucleic acids {{through the creation}} of one of the first DNA array chips, with expression levels numbering tens of thousands of genes.|$|E
25|$|Automated <b>high-throughput</b> sequencers have {{increased}} the speed and reduced the cost of sequencing, {{making it possible to}} offer genetic testing to consumers today for as little as $1,000. The emerging market of direct-to-consumer genome sequencing services has brought new questions about both the medical efficacy and the ethical dilemmas associated with widespread knowledge of individual genetic information.|$|E
25|$|A {{restriction}} of directed evolution {{is that a}} <b>high-throughput</b> assay is {{required in order to}} measure the effects {{of a large number of}} different random mutations. This can require extensive research and development before it can be used for directed evolution. Additionally, such assays are often highly specific to monitoring a particular activity and so are not transferable to new DE experiments.|$|E
