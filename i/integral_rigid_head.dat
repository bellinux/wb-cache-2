0|139|Public
50|$|Aircraft {{typically}} use {{three types}} of fuel tanks: <b>integral,</b> <b>rigid</b> removable, and bladder.|$|R
50|$|The cloth {{convertible}} top, initially {{available in}} four colors, was fully automatic, {{operated by a}} single, dashboard-mounted button. The top stored automatically under an <b>integral</b> <b>rigid</b> tonneau cover in a system pioneered in modern convertibles with the fourth generation Mercedes SL.|$|R
3000|$|... {{corresponded to}} the {{position}} of the Wave and Optotrak sensors after subtraction of the <b>rigid</b> <b>head</b> motion, m [...]...|$|R
3000|$|The unknown T and Φ can be {{optimised}} iteratively until convergence. For brain images, T {{describes the}} <b>rigid</b> <b>head</b> motion using three translations and three rotations. Y [...]...|$|R
40|$|We present 3 D Constrained Local Model (CLM-Z) for robust {{facial feature}} {{tracking}} under varying pose. Our approach integrates both depth and intensity {{information in a}} common framework. We show the benefit of our CLM-Z method in both accuracy and convergence rates over regular CLM formulation through experiments on publicly available datasets. Additionally, we demonstrate a way to combine a <b>rigid</b> <b>head</b> pose tracker with CLM-Z that benefits <b>rigid</b> <b>head</b> tracking. We show better performance than the current state-of-the-art approaches in head pose tracking with our extension of the generalised adaptive view-based appearance model (GAVAM). 1...|$|R
50|$|A windblocker or wind {{deflector}} minimizes noise and rushing air reaching the occupants. Mazda pioneered a version on the RX7 convertible which featured an <b>integral</b> <b>rigid</b> opaque panel that folded {{up from behind}} the front seats. Current convertibles feature windblockers of various designs including detachable fold-up designs (e.g., Toyota Solara), vertically retractable glass (e.g., Audi TT), minimal flaps (e.g., Mazda Miata) - or other integrated wind controlling systems.|$|R
5000|$|... #Caption: Jaguar XK circa 2008, with {{heatable}} glass {{rear window}} and fully automatic cloth top with <b>integral</b> top-concealing <b>rigid</b> tonneau ...|$|R
40|$|When {{inputting}} image {{sequence that}} {{is from the}} frontal-view neutral face to the side-view facial expression, our research wants to separate the <b>rigid</b> <b>head</b> motion and non-rigid facial expression and removes the head motion by incremental perspective motion model with three sub-regions. As to three sub-regions of the warping result, our research could overcome the edge problem of the sub-regions combination. From the separation results, it found that the missing problem would arise from the partial occlusion of side view image. So our research synthesizes the virtual expression image and warps the local linear regression result to the <b>rigid</b> <b>head</b> motion and non-rigid facial expression separation result by incremental perspective transformation. And it could replace the missing region of separation result and combine these two sub-regions to reconstruct the final result without the missing problem...|$|R
6000|$|Ricardo stared {{hard for}} a moment, spun on his heel, walked {{to the end of}} the room, came back smartly, and muttered a {{profound}} [...] "Ay! Ay!" [...] above Schomberg's <b>rigid</b> <b>head.</b> That the hotel-keeper was capable of a great moral effort was proved by a gradual return of his severe, Lieutenant-of-the-Reserve manner.|$|R
60|$|And {{he began}} to walk. Mr. Van Wyk, jumping up, saw the full meaning of the <b>rigid</b> <b>head,</b> the hesitating feet, the vaguely {{extended}} hand. His heart was beating fast; he moved a chair aside, and instinctively advanced as if to offer his arm. But Captain Whalley passed him by, making for the stairs quite straight.|$|R
50|$|The Optare Tempo is a {{full-size}} rigid single-deck bus manufactured by Optare and {{was launched in}} late 2004. It is marketed and sold as the replacement for the Optare Excel. It is designed as a lightweight bus, to use less fuel than traditional heavy duty <b>integral</b> <b>rigids.</b> As of July 2017, 233 had been built, including 27 Tempo SRs. The Tempo SR has now been replaced in the UK market by longer variants of the Optare MetroCity, although production of the Tempo SR continues for the Australian market.|$|R
30|$|Twenty-nine human {{subjects}} had a 30 -min [11 C]-PiB PET scan with simultaneous MR including 3 D navigators sampled at six time points, which {{were used to}} correct the PET image for <b>rigid</b> <b>head</b> motion. Five subjects with motion greater than 4  mm were reconstructed into six frames (one for each navigator) which were averaged to one image after MC.|$|R
40|$|There is {{evidence}} that visual concomitants of articulation facilitate speech perception. Specifically, {{the results of a}} study examining Cantonese phone and tone discrimination showed that Australian non-tonal language speakers were able to discriminate phones (consonants and vowels) on the basis of <b>rigid</b> <b>head</b> motion alone. Conversely, neither <b>rigid</b> <b>head</b> motion nor non-rigid face motion alone was sufficient for the visual perception of tones. However, participants in this experiment were non-tone language speakers with normal hearing. If visual information for tone is a general language phenomenon, augmentation may be graded in terms of familiarity of attending to visual cues. Thus, {{in order to determine the}} nature of the visual concomitants of tone, research needs to be conducted with people experienced in attending to visual cues. The aim of the present study was to explore the relationship between <b>rigid</b> and non-rigid <b>head</b> motion and the perception of phones and tones by using a hearing impaired population. An experiment was designed using Cantonese words to explore the visual concomitants of phones and tones across three different modalities (Audio Only, Visual Only and Auditory Visual) and three movement types (rigid, non-rigid, and combined). Preliminary results indicate the existence of visual information for phones and tones...|$|R
40|$|Natural {{face and}} head {{movements}} were mapped onto a computer rendered threedimensional average of 100 laser-scanned heads {{in order to}} isolate movement information from spatial cues and nonrigid movements from <b>rigid</b> <b>head</b> movements (Hill & Johnston, 2001). Experiment 1 investigated whether subjects could recognize, from a rotated view, facial motion {{that had previously been}} presented at a full-face view usinga delayed match to sample experimental paradigm. Experiment 2 compared recognition for views that were either between or outside initially presented views. Experiment 3 compared discrimination at full face, threequarters, and profile after learningat each of these views. A significant face inversion effect in Experiments 1 and 2 indicated subjects were usingface-based information rather than more general motion or temporal cues for optimal performance. In each experiment recognition performance only ever declined with a change in viewpoint between sample and test views when rigid motion was present. Nonrigid, face-based motion appears to be encoded in a viewpoint invariant, object-centred manner, whereas <b>rigid</b> <b>head</b> movement is encoded in a more view specific manner...|$|R
40|$|Natural {{movement}} plays {{a significant}} role in realistic speech animation. Numerous studies have demonstrated the contribution visual cues make to the degree we, as human observers, find an animation acceptable. <b>Rigid</b> <b>head</b> motion is one visual mode that universally co-occurs with speech, and so it is a reasonable strategy to seek a transformation from the speech mode to predict the head pose. Several previous authors have shown that prediction is possible, but experiments are typically confined to rigidly produced dialogue. Natural, expressive, emotive and prosodic speech exhibit motion patterns that are far more difficult to predict with considerable variation in expected head pose. Recently, Long Short Term Memory (LSTM) networks have become an important tool for modelling speech and natural language tasks. We employ Deep Bi-Directional LSTMs (BLSTM) capable of learning long-term structure in language, to model the relationship that speech has with <b>rigid</b> <b>head</b> motion. We then extend our model by conditioning with prior motion. Finally, we introduce a generative head motion model, conditioned on audio features using a Conditional Variational Autoencoder (CVAE). Each approach mitigates the problems of the one to many mapping that a speech to head pose model must accommodat...|$|R
40|$|Probing {{emotional}} {{facial expression}} recognition with the adaptation paradigm {{is one way}} to investigate the processes underlying emotional face recognition. Previous research suggests that these processes are tuned to dynamic facial information (facial movement). Here we examined the tuning of processes involved in the recognition of emotional facial expressions to different sources of facial movement information. Specifically we investigated the effect of the availability of <b>rigid</b> <b>head</b> movement and intrinsic facial movements (e. g., movement of facial features) {{on the size of the}} emotional facial expression adaptation effect. Using a three-dimensional (3 D) morphable model that allowed the manipulation of the availability of each of the two factors (intrinsic facial movement, head movement) individually, we examined emotional facial expression adaptation with happy and disgusted faces. Our results show that intrinsic facial movement is necessary for the emergence of an emotional facial expression adaptation effect with dynamic adaptors. The presence of <b>rigid</b> <b>head</b> motion modulates the emotional facial expression adaptation effect only in the presence of intrinsic facial motion. In a second experiment we show these adaptation effects are difficult to explain by merely the perceived intensity and clarity (uniqueness) of the adaptor expressions. Together these results suggest that processes encoding facial expressions are differently tuned to different sources of facial movements...|$|R
60|$|Hollis looked fixedly at Karain, {{who was the}} {{incarnation}} of {{the very essence of}} still excitement. He stood <b>rigid,</b> with <b>head</b> thrown back; his eyes rolled wildly, flashing; the dilated nostrils quivered.|$|R
40|$|Background: Tracking eye {{position}} {{is vital for}} behavioral and neurophysiological investigations in systems and cognitive neuroscience. Infrared camera systems which are now available {{can be used for}} eye tracking without the need to surgically implant magnetic search coils. These systems are generally employed using <b>rigid</b> <b>head</b> fixation in monkeys, which maintains the eye in a constant position and facilitates eye tracking. New method: We investigate the use of non-rigid head fixation using a helmet that constrains only general head orientation and allows some freedom of movement. We present a MATLAB software solution to gather and process eye position data, present visual stimuli, interact with various devices, provide experimenter feedback and store data for offline analysis. Comparison with existing method: Our software solution achieves excellent timing performance due to the use of data streaming, instead of the traditionally employed data storage mode for processing analog eye position data. Results: We present behavioral data from two monkeys, demonstrating that adequate performance levels can be achieved on a simple fixation paradigm and show how performance depends on parameters such as fixation window size. Our findings suggest that non-rigid head restraint can be employed for behavioral training and testing on a variety of gaze-dependent visual paradigms, reducing the need for <b>rigid</b> <b>head</b> restraint systems for some applications. Conclusion: While developed for macaque monkey, our system of course can work equally well for applications in human eye tracking where head constraint is undesirable...|$|R
40|$|Trains {{including}} reciprocating {{machines are}} subject to the most varied and often most severe torsional disturbances in comparison to other machinery classes. If crankshaft or rotating component failures occur as a result of shaft torsional oscillations, the consequences can be catastrophic. In this paper a new comprehensive model and solution method using analytical formulations are developed to study both steady state and transient response of complex reciprocating trains. Analytical results are presented and recommendations for torsional reliable trains are addressed. Couplings being the more accessible components within the train are often modified to tune the overall system. Recommendations for coupling: High torsional stiffness coupling (best option if allowed by torsional analysis), or flexible coupling (more elasticity and damping and more maintenance) or <b>integral</b> <b>rigid</b> forged flange connection (rugged train, less elasticity and damping) with single bearing electric machine...|$|R
40|$|Thc thrcedimcnsional head-neck modelof Dcng and Gold-smith (J. Biomcch., 1987) was adaptcd and {{implemented}} in thc integratcd multibody/finitc clemcnt codc MADYMo. Thc model compriscs <b>rigid</b> <b>head</b> and vertcbrae, connectcd by l inear viscoelastic intcrvertcbral joints and nonlinear clas-tic muscle elcments. lt was elaboratcly validatcd by com-paring modcl rcsponsr 3 with thc Ícsponscs of human volun-tcers subjcctcd to írontal and lateral sled accelcration im-pacts. Frir rgrecmcnt {{was found for}} both impacts. Furthcr, a scnsitivity rnalysis was performed to assess thc cffcct of parametcr variationr on model rcsponse. The model proved satisfactory and {{may be used as}} a tool to improve restraint systems or dummy necks...|$|R
5000|$|Propulsive: {{the posture}} is hunched over and <b>rigid</b> with the <b>head</b> and neck bent forward.|$|R
40|$|We {{present an}} {{annotated}} corpus of conversational facial displays {{designed to be}} used for generation. The corpus is based on a recording of a single speaker reading scripted output in the domain of the target generation system. The data in the corpus consists of the syntactic derivation tree of each sentence annotated with the full syntactic and pragmatic context, as well as the eye and eyebrow displays and <b>rigid</b> <b>head</b> motion used by the the speaker. The behaviours of the speaker show several contextual patterns, many of which agree with previous findings on conversational facial displays. The corpus data has been used in several studies exploring different strategies for selecting facial displays for a synthetic talking head. ...|$|R
40|$|We {{present a}} {{coarse-grained}} model {{in order to}} describe the unusual sequence of mesophases observed in aqueous solutions of nonionic lipids, such as monoolein. The lipid molecules are modeled as a <b>rigid</b> <b>head</b> and a flexible Gaussian tail, and water is treated explicitly. A key component of the model is thermally reversible hydrogen bonding between the lipid head and water resulting in changes in both head volume and the interactions of the hydrated head with its surroundings. Phase diagrams obtained from unit-cell self-consistent field simulations capture the qualitative thermotropic and lyotropic phase behavior of the monoolein-water system. The unusual phase sequences result from a competition between hydrogen bond formation, changes in head volume and interactions, lipid tail entropy, and the hydrophobic effect...|$|R
40|$|This is a {{study of}} the {{theoretical}} optimal (limiting) performance of helmets for the prevention of <b>head</b> injury. A <b>rigid</b> <b>head</b> injury model and a two-mass translational head injury model are employed. Several head injury criteria are utilized, including head acceleration, the head injury criterion (HIC), the energy imparted to the brain which is related to brain injury, and the power developed in the skull that is associated with skull fracture. A helmeted <b>head</b> hitting a <b>rigid</b> surface and a helmeted head hit by a moving object such as a ball are considered. The optimal characteristics of helmets and the impact responses of the helmeted head are investigated computationally. An experiment is conducted on an ensemble of bicycle helmets. Computational results are compared with the experimental results...|$|R
60|$|The smile which flickered {{upon the}} old Patrician's keen {{features}} died away suddenly, {{and his fingers}} closed upon his companion's wrist. The other had set <b>rigid,</b> his <b>head</b> advanced, his hawk eyes upon the northern skyline. Its straight, blue horizon was broken by two low black dots.|$|R
40|$|The {{technological}} {{control of}} concrete {{can only be}} considered a quality control procedure when all its steps are followed properly. Compressive strength testing plays {{a critical role in}} the technological control of concrete structures and in the technological development of concrete. The aim {{of this study is to}} select the most suitable preparation technique for conventional and high-strength concrete by analyzing mean strength, standard deviation and coefficients of variation. Test specimens with compressive strength ranging from 20 to 120 MPa were prepared in a laboratory and were then subjected to seven different types of surface treatment, using bonded, unbonded and mechanical wear (grinding) systems. Results show that the most effective technique is grinding using a <b>rigid</b> <b>head.</b> The performance of unbonded system was also suitable for use with conventional and high strength concrete...|$|R
40|$|The average {{orientation}} and {{flexibility of the}} phosphorylcholine group are deduced from deuterium and phosphorus- 31 nuclear magnetic resonance measurements of unsonicated phosphatidylcholine bilayers in the liquid crystalline state. The experimental data are consistent with a model in which the polar head group exhibits a restricted flexibility characterized by rapid transitions between two enantiomeric conformations. A completely flexible or a completely <b>rigid</b> <b>head</b> group structure can be excluded. The phosphorylcholine residue {{is found to be}} bent at the position of the phosphate group, due to a gauche-gauche conformation of the phosphodiester linkage. The choline dipole is aligned parallel to the plane of the membrane, which is in agreement with X-ray and neutron diffraction studies. The average orientation of the phosphorylcholine group is therfore {{the same as that of}} the phosphorylethanolamine head group...|$|R
50|$|Key adaptations are adaptations {{that allow}} {{a group of}} organisms to diversify. Daphnia lumholtzi is a water flea that is able to form <b>rigid</b> <b>head</b> spines in {{response}} to chemicals released when fish are present. These phenotypically plastic traits serve as an induced defense against these predators. A study showed that Daphnia pulicaria is competitively superior to D. lumholtzi {{in the absence of}} predators. However, in the presence of fish predation the invasive species formed its defenses and became the dominant water flea in the region. This switch in dominance suggests that the induced defense against fish predation could represent a key adaptation for the invasion success of D. lumholtzi. A defensive trait that qualifies as a key adaptation is most likely an example of escape and radiate coevolution.|$|R
6000|$|... [ROUS seizes her by {{both her}} arms. She stands <b>rigid,</b> with her <b>head</b> bent back. He {{releases}} her, and he too stands motionless.] ...|$|R
40|$|BACKGROUND: All trauma {{patients}} with a cervical spinal column injury or with a mechanism of injury {{with the potential to}} cause cervical spinal injury should be immobilised until a spinal injury is excluded. Immobilisation of the entire patient with a rigid cervical collar, backboard, head blocks with tape or straps is recommended by the Advanced Trauma Life Support guidelines. However there is insufficient evidence to support these guidelines. OBJECTIVE: To analyse the effects on the range of motion of the addition of a <b>rigid</b> collar to <b>head</b> blocks strapped on a backboard. METHOD: The active range of motion of the cervical spine was determined by computerised digital dual inclinometry, in 10 healthy volunteers with a <b>rigid</b> collar, <b>head</b> blocks strapped on a padded spine board and a combination of both. Maximal opening of the mouth with all types of immobiliser in place was also measured. RESULTS: The addition of a <b>rigid</b> collar to <b>head</b> blocks strapped on a spine board did not result in extra immobilisation of the cervical spine. Opening of the mouth was significantly reduced in {{patients with}} a rigid collar. CONCLUSION: Based on this proof of principle study and other previous evidence of adverse effects of rigid collars, the addition of a <b>rigid</b> collar to <b>head</b> blocks is considered unnecessary and potentially dangerous. Therefore the use of this combination of cervical spine immobilisers must be reconsidered...|$|R
40|$|AbstractThe insect head is {{composed}} of several segments. During embryonic development, the segments fuse to form a <b>rigid</b> <b>head</b> capsule where obvious segmental boundaries are lacking. Hence, the assignment of regions of the insect head to specific segments is hampered, especially with respect to dorsal (vertex) and lateral (gena) parts. We show that upon Tribolium labial (Tc-lab) knock down, the intercalary segment is deleted but not transformed. Furthermore, {{we find that the}} intercalary segment contributes to lateral parts of the head cuticle in Tribolium. Based on several additional mutant and RNAi phenotypes that interfere with gnathal segment development, we show that these segments do not contribute to the dorsal head capsule apart from the dorsal ridge. Opposing the classical view but in line with findings in the vinegar fly Drosophila melanogaster and the milkweed bug Oncopeltus fasciatus, we propose a “bend and zipper” model for insect head capsule formation...|$|R
40|$|Adapting to an {{emotional}} facial expression biases emotional judgments of an ambiguous facial expression {{away from the}} adapted facial expression. Previous studies examining emotional facial adaptation effects used static emotional facial expressions as adaptors. Since natural facial expressions are inherently dynamic, dynamic information might enhance {{the magnitude of the}} emotional facial expression adaptation effect. We tested this hypothesis by comparing emotional facial expression adaptation effects for static and dynamic facial expression adaptors. Stimuli were generated using a dynamic 3 D morphable face model. We found adaptation effects of similar magnitude for dynamic and static adaptors. When <b>rigid</b> <b>head</b> motion was removed (leaving only non-rigid intrinsic facial motion cues), the adaptation effects with dynamic adaptors disappeared. These results obtained with a novel method for the synthesis of facial expression stimuli suggest that {{at least part of the}} cognitive representation of facial expressions is dynamic and depends on head motion...|$|R
40|$|The role of {{physiological}} signals {{has a large}} impact on driver monitoring systems, since it tells something about the human state. This work addresses the recursive probabilistic inference problem in time-varying linear dynamic systems to incorporate invariance into the task of heart rate estimation from face videos under realistic conditions. The invariance encapsulates motion as well as varying illumination conditions in order to accurately estimate vitality parameters from human faces using conventional camera technology. The solution {{is based on the}} canonical state space representation of an Itô process and a Wiener velocity model. Empirical results yield to excellent real-time and estimation performance of heart rates in presence of disturbing factors, like <b>rigid</b> <b>head</b> motion, talking, facial expressions and natural illumination conditions making the process of human state estimation from face videos applicable in a much broader sense, pushing the technology towards advanced driver monitoring systems...|$|R
40|$|<b>Rigid</b> <b>head</b> {{motion is}} {{a gesture that}} conveys {{important}} non-verbal information in human commu-nication, and hence {{it needs to be}} appropriately modeled and included in realistic facial animations to effectively mimic human behaviors. In this paper, head motion sequences in expressive facial animations are analyzed in terms of their naturalness and emotional salience in perception. Statistical measures are derived from an audiovisual database, comprising synchronized facial gestures and speech, which revealed characteristic patterns in emotional head motion sequences. Head motion patterns with neutral speech significantly differ from head motion patterns with emotional speech in motion activation, range and velocity. The results show that head motion provides discriminating information about emotional categories. An approach to synthesize emotional head motion sequences driven by prosodic features is presented, expanding upon our previous framework on head motion synthesis. This method naturally models the specific temporal dynamics of emotional head motion sequences by building Hidden Marko...|$|R
40|$|Abstract — Previous {{research}} in automated expression analysis {{has focused on}} discrete actions with little attention to their timing either within or between persons. We investigated the interpersonal coordination of <b>rigid</b> <b>head</b> motion in 11 intimate couples {{with a history of}} interpersonal violence. The couples participated in both a low-conflict task in which they were asked to discuss a neutral topic as well as a high-conflict task in which they were asked to discuss an issue that was cause for conflict. Actor-partner analysis, which explicitly models that each partner is both a cause and an effect of the other’s behavior, was used to investigate differences between conditions in angular head velocities. Windowed cross-correlation was used to model interpersonal dynamics. Angular head velocities were slower for men than for their partners. Head velocities were strongly correlated between partners, with frequent shifts in lead-lag relationships between them. Keywords-component; Interpersonal coordination; head motion velocity; windowed cross-correlation; actor-partner analysis I...|$|R
40|$|Natural {{movement}} plays {{a significant}} role in realistic speech animation. Numerous studies have demonstrated the contribution visual cues make to the degree we, as human observers, find an animation acceptable. <b>Rigid</b> <b>head</b> motion is one visual mode that universally co-occurs with speech, and so it is a reasonable strategy to seek features from the speech mode to predict the head pose. Several previous authors have shown that prediction is possible, but experiments are typically confined to rigidly produced dialogue. Expressive, emotive and prosodic speech exhibit motion patterns that are far more difficult to predict with considerable variation in expected head pose. People involved in dyadic conversation adapt speech and head motion in response to the others’ speech and head motion. Using Deep Bi-Directional Long Short Term Memory (BLSTM) neural networks, we demonstrate {{that it is possible to}} predict not just the head motion of the speaker, but also the head motion of the listener from the speech signal...|$|R
