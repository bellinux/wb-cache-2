0|136|Public
40|$|AbstractBiometric {{authentication}} using <b>ear</b> <b>images</b> becoming popular nowadays in {{the field}} of security surveillance to identify a person. In this paper image processing techniques are used to study about the characteristics of several databases <b>Ear</b> <b>images</b> and to extract the features and data's from that <b>Ear</b> <b>images.</b> <b>Ear</b> is a stable biometric its appearance will not change even for long years. This paper explained about Contourlet transform and Appearance shape model (ASM) for feature extraction and, Fisher linear discriminant analysis (FLDA) is done for classification, ear matching. Here the feature extraction was done by both the Transform and Appearance shape model methods, So that the feature extraction result must be good. The proposed method has been evaluated on IIT Delhi Ear database of 50 <b>Ear</b> <b>images</b> from 10 persons and also tested on our own ear databases that are collected using webcam. The experimental results indicate that contourlet transform improves the overall performance when compared to Principal component analysis. The comparisons between the two feature extraction methods were done and its results were shown...|$|R
40|$|Abstract [...] This paper {{presents}} {{a new approach}} for automatic ear recognition system using energy-edge density feature and Back Propagation Neural Network (BPNN). Input <b>ear</b> <b>image</b> is decomposed into four sub-bands using Haar wavelet transform. Thereafter fused feature is extracted from image blocks {{of each of the}} detailed sub-bands. The fused feature is used as input to neural network for effective <b>ear</b> <b>image</b> classification. The proposed system has been tested using <b>ear</b> <b>images</b> collected from 350 people. Experimental results have demonstrated the effectiveness of the proposed system in term of recognition accuracy in comparison with previous methods. Index Term [...] <b>Ear</b> <b>image,</b> Haar wavelet transform, Back propagation Neural Network...|$|R
40|$|Abstract: The {{presented}} paper {{presents the}} statistical analysis of the diagonal dct coefficients of <b>ear’s</b> <b>images</b> in order to ascertaining the bio-metrics identity of a person. The dct coefficients matrix contains the frequency variations of <b>ear’s</b> <b>images</b> in three parts; {{the lower half of}} the matrix that contains the low frequency elements that make up the flashy part of the ear, the upper half that contain the high frequency elements in form of noise and diagonal elements that contain the maximum information about the features of the <b>ear’s</b> <b>image.</b> The diagonal elements or dct coefficients are then analyzed statistically in terms of mean deviation, standard deviation and covariance to identify the given <b>ear’s</b> <b>image...</b>|$|R
40|$|Active Contours Model is {{an image}} {{processing}} technique which is efficient for automatic ear detection on a side face <b>ear</b> <b>image.</b> The technique first separates ear regions {{from the rest of}} the image and then envelops the <b>ear</b> within the <b>image.</b> <b>Ear</b> detection process involves three major steps. Initialization process is done to determine the optimal location of the <b>ear</b> from the <b>image.</b> Then, the image is resized to allow faster iterations of the Active Contours. Next, iteration process of Active Contours Model to detect the boundary of the ear and segment the ear {{from the rest of the}} <b>image.</b> Then, <b>ear</b> multiplication to validate and compare the segmented ear whether it fits with the original image. To handle the detection of ears of various shapes and sizes, an ear template is created considering the ears of various shapes and resized automatically to a size suitable for the detection and iterations of the technique. The evaluation method for the accuracy is Area Overlap. The results shows an average of 74. 55...|$|R
40|$|Abstract: This paper {{presents}} {{a new approach}} for automatic ear recognition system using energy-edge density feature and Back Propagation Neural Network (BPNN). Input <b>ear</b> <b>image</b> is decomposed into four subbands using Haar wavelet transform. Thereafter fused feature is extracted from image blocks {{of each of the}} detailed sub-bands. The fused feature is used as input to neural network for effective <b>ear</b> <b>image</b> classification. The proposed system has been tested using <b>ear</b> <b>images</b> collected from 350 people. Experimental results have demonstrated the effectiveness of the proposed system in term of recognition accuracy in comparison with previous methods...|$|R
40|$|This paper {{presents}} {{a framework that}} uses <b>ear</b> <b>images</b> for human identification. The framework makes use of Principal Component Analysis (PCA) for <b>ear</b> <b>image</b> feature extraction and Multilayer Feed Forward Neural Network for classification. Framework are proposed to improve recognition accuracy of human identification. The framework was tested on an <b>ear</b> <b>image</b> database to evaluate its reliability and recognition accuracy. The experimental results showed that our framework achieved higher stable recognition accuracy and over-performed other existing methods. The recognition accuracy stability and computation time with respect to different image sizes and factors were investigated thoroughly {{as well in the}} experiments. <br /...|$|R
40|$|This paper {{proposes a}} novel method based on Haar wavelet {{transform}} and uniform local binary patterns(ULBPs) to recognize <b>ear</b> <b>images.</b> Firstly, <b>ear</b> <b>images</b> are decomposed by Haar wavelet transform. Then ULBPs are combined simultaneously with blockbased and multi-resolution methods to describe together the texture features of ear sub-images transformed by Haar wavelet. Finally, the texture features are classified by the nearest neighbor method. Experimental {{results show that}} Haar wavelet transform can boost effectively up intensity information of texture unit. It is not only fast but also robust to use ULBPs to extract texture features. The recognition rates of the method proposed by this paper outperform remarkably those of the classic PCA or KPCA especially when combining block-based and multiresolution methods. 1...|$|R
40|$|Personal {{identification}} using 2 D <b>ear</b> <b>images</b> {{still has}} many {{problems such as}} occlusion mostly caused byhair, earrings, and clothes. To avoid this problem, we propose to divide the <b>ear</b> <b>image</b> into non-overlappingequal divisions and identify persons through these non-occluded parts separately and then combine outputsof the classification of these parts in abstract, rank, and measurement level fusion. Experimental resultsshow that the increasing of recognition rate through combining small parts of non-occluded divisions ofear image...|$|R
40|$|Abstract: This paper {{presents}} {{a method for}} extracting distinctive invariant features from <b>ear</b> <b>images</b> {{that can be used}} to perform reliable matching between different views of an ear. It shows the extraction of features from an <b>ear</b> <b>image</b> and also the results of it are matching with other samples of both same and different subjects. Each of these feature vectors is supposed to be distinctive and invariant to any scaling, rotation or translation of the image...|$|R
40|$|Human {{identification}} {{has always}} been a topic that interested researchers around the world. Biometric methods are found to be more effective and much easier for the users than the traditional identification methods like keys, smart cards and passwords. Unlike with the traditional methods, with biometric methods the data acquisition is most of the times passive, which means the users do not take active part in data acquisition. Data acquisition can be performed using cameras, scanners or sensors. Human physiological biometrics such as face, eye and ear are good candidates for uniquely identifying an individual. However, human ear scores over face and eye because of certain advantages it has over face. The most challenging phase in human identification based on ear biometric is the segmentation of the <b>ear</b> <b>image</b> from the captured image which may contain many unwanted details. In this work, PDE based image processing techniques are used to segment out the <b>ear</b> <b>image.</b> Level Set Theory based image processing is employed to obtain the contour of the <b>ear</b> <b>image.</b> A few Level set algorithms are compared for their efficiency in segmenting test <b>ear</b> <b>images.</b> Comment: 15 page...|$|R
40|$|As a new {{biometric}} identification technology, {{the theory and}} application research of ear recognition has attracted more and more attention of scholars in recent years. Image-preprocessing and normalization of <b>ear</b> <b>image</b> {{is very important for}} the feature extraction. In this paper we apply the improved morphological filtering method to preprocessing the <b>ear</b> <b>image.</b> And we propose the angle normalization method by geometrical parameters. This method has the advantages of scaling invariance, translation invariance and rotation invariance. The normalization results are reasonable and good for later feature extraction...|$|R
30|$|The 3 dMDface {{scanning}} system scanned a subject’s {{head and neck}} area (a 180 ° facial <b>image</b> from <b>ear</b> to ear) in 1.5  ms at the highest resolution available (1236 [*]×[*] 1624  pixels). The two acquired stereo camera viewpoints (captured by the cameras located on two sides) were combined using a stereophotogrammetry technique which produced a single 3 D image.|$|R
40|$|Identity {{recognition}} from <b>ear</b> <b>images</b> {{is an active}} field of research within the biometric community. The ability to capture <b>ear</b> <b>images</b> from a distance and in a covert manner makes ear recognition technology an appealing choice for surveillance and security applications as well as related application domains. In contrast to other biometric modalities, where large datasets captured in uncontrolled settings are readily available, datasets of <b>ear</b> <b>images</b> are still limited in size and mostly of laboratory-like quality. As a consequence, ear recognition technology has not benefited yet from advances in deep learning and convolutional neural networks (CNNs) and is still lacking behind other modalities that experienced significant performance gains owing to deep recognition technology. In this paper we address this problem and aim at building a CNNbased ear recognition model. We explore different strategies towards model training with limited amounts of training data and show that by selecting an appropriate model architecture, using aggressive data augmentation and selective learning on existing (pre-trained) models, {{we are able to}} learn an effective CNN-based model using a little more than 1300 training images. The result of our work is the first CNN-based approach to ear recognition that is also made publicly available to the research community. With our model we are able to improve on the rank one recognition rate of the previous state-of-the-art by more than 25 % on a challenging dataset of <b>ear</b> <b>images</b> captured from the web (a. k. a. in the wild) ...|$|R
40|$|Ear {{biometric}} {{is considered}} {{as one of the}} most reliable and invariant biometrics characteristics in line with iris and fingerprint characteristics. In many cases, ear biometrics can be compared with face biometrics regarding many physiological and texture characteristics. In this paper, a robust and efficient ear recognition system is presented, which uses Scale Invariant Feature Transform (SIFT) as feature descriptor for structural representation of <b>ear</b> <b>images.</b> In order to make it more robust to user authentication, only the regions having color probabilities in a certain ranges are considered for invariant SIFT feature extraction, where the K-L divergence is used for keeping color consistency. Ear skin color model is formed by Gaussian mixture model and clustering the ear color pattern using vector quantization. Finally, K-L divergence is applied to the GMM framework for recording the color similarity in the specified ranges by comparing color similarity between a pair of reference model and probe <b>ear</b> <b>images.</b> After segmentation of <b>ear</b> <b>images</b> in some color slice regions, SIFT keypoints are extracted and an augmented vector of extracted SIFT features are created for matching, which is accomplished between a pair of reference model and probe <b>ear</b> <b>images.</b> The proposed technique has been tested on the IITK Ear database and the experimental results show improvements in recognition accuracy while invariant features are extracted from color slice regions to maintain the robustness of the system. Comment: 6 pages, 4 figures, ACTEA 200...|$|R
50|$|An orthopantomogram (OPG) is a {{panoramic}} dental X-ray {{of the upper}} and lower jaw. It shows a two-dimensional <b>image</b> from <b>ear</b> to ear. Particularly, OPG facilitates an accurate postoperative follow-up and monitoring of bone growth under a mono- or double-distractor treatment. Thereby, some TCS features could be seen on OPG, but better techniques are used to include the whole spectrum of TCS abnormalities instead of showing only the jaw abnormalities.|$|R
40|$|Biometrics {{includes}} {{the study of}} automatic methods for distinguishing human beings based on physical or behavioral traits. The problem of finding good biometric features and recognition methods {{has been researched extensively}} in recent years. Our research considers the use of ears as a biometric for human recognition. Researchers have not considered this biometric as much as others, which include fingerprints, irises, and faces. This thesis presents a novel approach to recognize individuals based on their outer <b>ear</b> <b>images</b> through spatial segmentation. This approach to recognizing is also good for dealing with occlusions. The study will present several feature extraction techniques based on spatial segmentation of the <b>ear</b> <b>image.</b> The study will also present a method for classifier fusion. Principal components analysis (PCA) is used in this research for feature extraction and dimensionality reduction. For classification, nearest neighbor classifiers are used. The research also investigates the use of <b>ear</b> <b>images</b> as a supplement to face images in a multimodal biometric system. Our base eigen-ear experiment results in an 84 % rank one recognition rate, and the segmentation method yielded improvements up t...|$|R
40|$|The use of {{biometrics}} {{for personal}} identification or authentication {{is very common}} now days. The technology of human ear recognition system is a latest technology in this field. In case of ear biometrics, the shape and appearance remains same throughout the life time of an individual contrary to facial recognition in which change of appearance with expression and age is a major problem. That {{is why it is}} advantageous to use it for personal identification. In this paper, we have proposed a new approach for an automated system for human ear identification. Our proposed method consists of three stages. In the first stage, preprocessing of <b>ear</b> <b>image</b> is done for its contrast enhancement and size normalization. In the second stage, features are extracted through Haar wavelets followed by ear identification using fast normalized cross correlation in the third stage. The proposed method is applied on USTB <b>ear</b> <b>image</b> database and IIT Delhi <b>ear</b> <b>image</b> database. Experimental results show that our proposed system achieves an average accuracy of 97. 2 % and 95. 2 % on these databases respectively. </p...|$|R
30|$|The {{face and}} thermal face data {{were taken from}} USTC NVIE Spontaneous Database [24 – 26], whereas the ear data were {{collected}} from IIT Delhi <b>Ear</b> <b>Image</b> Database [27, 28]. The dataset was created artificially by combining these two datasets because {{it is not possible to}} find a proper dataset for our work. In our dataset, there are 120 individuals. Each person was represented by ten face and ten thermal face images with spatial resolutions of 640 [*]×[*] 480 and 304 [*]×[*] 230 respectively. We added three <b>ear</b> <b>images</b> to each person artificially. Hence, our dataset consists of 2760 biometric measurements assigned to 120 individuals.|$|R
30|$|Using {{computer}} forensics, {{different methods}} of ear identification {{have been developed}} which may be helpful in extracting and identifying the <b>ear</b> <b>images</b> from CCTV cameras and other surveillance systems (Emersic et al. 2017; Yuan and Chun Mu 2012; Kumar and Wu 2012; Kumar and Chan 2013). However, the modern system of identification using new computerized techniques such as automatic identity recognition and local information fusion by <b>ear</b> <b>images</b> is based upon some computerized algorithms; however, they must be compensated with the anthropological knowledge-based morphological variations. We need to isolate endogamous communities and ethnicities based upon the special characteristics of the ears so that these characters can be combined with computerized algorithms for identification purposes.|$|R
40|$|This paper {{proposes a}} multimodal, {{biometric}} person authentication method using speech and <b>ear</b> <b>images</b> {{to attempt to}} improve the performance in mobile environments. It {{is well known that}} the performance of person authentication using only speech is deteriorated by acoustic noises and feature changes with time. Since the ear shape of each person does not change over time, integrating its image with speech information increases robustness of person authentication. Experiments are conducted using audio-visual database collected from 38 male speakers at five sessions over a half year period. Speech data are contaminated with white noise at various SNR conditions. Experimental results show that the authentication performance is improved by combining the <b>ear</b> <b>image</b> with speech in every SNR condition...|$|R
40|$|While {{identical}} twins identification {{is a well}} known challenge in face recognition, it seems that no work has explored automatic ear recognition for identical twin identification. <b>Ear</b> <b>image</b> recognition has been stud-ied for years, but Iannarelli (1989) {{appears to be the}} only work mentioning the twin identification (performed manually). We here explore the possibility of automatic twin identification from their <b>ear</b> <b>images</b> based on a recently proposed psychological model for face recog-nition in humans, known as Exception Report Model (ERM). We test our new approach on 39 pairs of identi-cal twins (78 subjects), with several levels of resolution, occlusion and noise, left ear vs. right ear, and feature optimization which verifies the robustness of the intro-duced features. ...|$|R
40|$|Automatic {{identity}} {{recognition from}} <b>ear</b> <b>images</b> represents an active {{field of research}} within the biometric community. The ability to capture <b>ear</b> <b>images</b> from a distance and in a covert manner makes the technology an appealing choice for surveillance and security applications {{as well as other}} application domains. Significant contributions {{have been made in the}} field over recent years, but open research problems still remain and hinder a wider (commercial) deployment of the technology. This paper presents an overview of the field of automatic ear recognition (from 2 D images) and focuses specifically on the most recent, descriptor-based methods proposed in this area. Open challenges are discussed and potential research directions are outlined with the goal of providing the reader with a point of reference for issues worth examining in the future. In addition to a comprehensive review on ear recognition technology, the paper also introduces a new, fully unconstrained dataset of <b>ear</b> <b>images</b> gathered from the web and a toolbox implementing several state-of-the-art techniques for ear recognition. The dataset and toolbox are meant to address some of the open issues in the field and are made publicly available to the research community. Comment: 17 pages, paper accepted to Neurocomputin...|$|R
40|$|Partial face images, e. g. 1 eyes, nose, and <b>ear</b> <b>images</b> are {{significant}} for face recognition. In this paper, {{we present a}} method for partial face extraction and recognition based on Radial Basis Function (RBF) networks. Focus has been centered on using <b>ear</b> <b>images</b> {{because they are not}} influenced by facial expression, and the influences of aging are negligible. Original human side face image with 320 x 240 pixels is input, and then the RBF network locates the ear and extracts it with a 200 x 120 pixels image. Next, another RBF network is constructed for the purpose of recognition. An algorithm that determines the radius of an RBF function is introduced. Dynamic radius, so called as compared to static one, i...|$|R
40|$|This paper investigates a new {{approach}} for human ear identification using holistic grey-level information. We employ Log-Gabor wavelets to extract the phase information, i. e. ear-codes, from the 1 D gray-level signals. Thus each ear is represented by a unique ear code or (phase template). The query <b>ear</b> <b>images</b> are compared {{with those in the}} database using Hamming distance. The minimum Hamming distance obtained from the rotation of ear template is used to authenticate the user. Our experiments on two different public ear databases achieve promising results and suggest its utility in ear-based authentication. This paper also illustrates that the phase information extracted from <b>ear</b> <b>images</b> can achieve significant performance improvement as compared to appearance-based approach employed in the literature. 1...|$|R
50|$|Trained as an {{abstract}} painter in the 1970s, when minimalism was a dominant way of working, Feintuch made {{a slow and}} gradual transition towards painting figuratively. His first solo exhibition in New York in 1988 included abstract paintings with broad expanses of color, alongside paintings of ears isolated on black fields. In his subsequent solo exhibition at Daniel Newburg Gallery in 1992, Feintuch exhibited large-scale black paintings, all containing life-sized <b>images</b> of <b>ears,</b> and he continued to work exclusively {{in black and white}} until 1996.|$|R
40|$|From secret {{knowledge}} like password up {{to physical}} traits as biometrics, current smartphone authentication systems are deemed inconvenience and difficult for users. Burdens on remembering password {{as well as}} privacy issues on stolen or forged biometrics have raised a futuristic idea of authentication systems. New system is hoped being transparent and with very minimum user involvement denoted as implicit authentication system. One {{of the ways to}} implicitly authenticate users is by authenticating them via image or video captured using smartphone camera during a call. During call interaction, we implicitly take <b>ear</b> <b>image</b> using front smartphone camera to recognize and authenticate users without them realizing. In this paper, we present a novel approach to ear recognition which considers both shape and texture information to represent <b>ear</b> <b>image.</b> Firstly, all Local Binary Pattern (LBP) are combined after extracted and concatenated into a single histogram. Second, in order to get geometric features, we use the idea of ear location center that is easily adjusted by smartphone user. Then, we combine previous steps to represent <b>ear</b> <b>image</b> as a descriptor. The recognition is performed using a nearest neighbor classifier computed feature space with Euclidean distance as a similarity/dissimilarity measure. Our proposed approach is very easy and simple thereby its simplicity allows very fast featu...|$|R
40|$|A color {{computer}} vision system was developed at Iowa State University, Ames, Iowa for morphological characterization of corn germplasm. The system consists of a color camera, a PC-AT host computer, a color frame digitizer, a video display monitor, a color video decoder and encoder, and a specially designed lighting chamber. The lighting chamber was specially designed and fabricated to provide uniform lighting for acquiring <b>images</b> of <b>ear</b> corn. The components of the system were matched and interfaced to configure the entire system. A {{study was conducted to}} calibrate each component and the entire system to ensure proper functioning of the system components and the acquisition of quality images. Images can be acquired in RGB (Red, Green and Blue) or HSI (Hue, Saturation, and Intensity) color coordinates. The system can provide a maximum resolution of 480 rows x 512 columns x 8 bits per pixels;Ostu 2 ̆ 7 s method of automatic thresholding technique was modified to segment the background of the color <b>image</b> of the <b>ear</b> corn. Algorithms and software were developed to extract the boundary of the <b>ear</b> corn <b>image,</b> and to determine the maximum length, maximum width, area and the perimeter of the image;Fractal geometry, moment invariant and knowledge based heuristic approaches were used to classify the shape of the <b>images</b> of <b>ears</b> of corn into one of the four possible shape classes as defined by the International Board of Plant Genetic Resources. These four shape classes are (1) round, (2) cylindrical, (3) conical, and (4) cylindrical-conical. Empirical relations were developed for two fractal based features, i. e. fractal-shape-factor and fractal perimeter to extract shape feature information. Seven higher order moment invariants were computed to represent shape features of the <b>ear</b> corn <b>image</b> in the moment invariant approach. The knowledge based heuristic approach provided the most accuracy of 96...|$|R
40|$|Abstract—Researchers have {{suggested}} that the ear may have advantages over the face for biometric recognition. Our previous experiments with ear and face recognition, using the standard principal component analysis approach, showed lower recognition performance using <b>ear</b> <b>images.</b> We report results of similar experiments on larger data sets that are more rigorously controlled for relative quality of face and <b>ear</b> <b>images.</b> We find that recognition performance is not significantly different between the face and the ear, for example, 70. 5 percent versus 71. 6 percent, respectively, in one experiment. We also find that multimodal recognition using both the ear and face results in statistically significant improvement over either individual biometric, for example, 90. 9 percent in the analogous experiment. Index Terms—Biometrics, multimodal biometrics, face recognition, ear recognition, appearance-based recognition, principal component analysis. ...|$|R
40|$|Biometric Technology for Human Identification IV, Orlando, FL, 9 - 10 April 2007 This paper investigates a new {{approach}} for human ear identification using holistic grey-level information. We employ Log-Gabor wavelets to extract the phase information, i. e. ear-codes, from the ID gray-level signals. Thus each ear is represented by a unique ear code or (phase template). The query <b>ear</b> <b>images</b> are compared {{with those in the}} database using Hamming distance. The minimum Hamming distance obtained from the rotation of ear template is used to authenticate the user. Our experiments on two different public ear databases achieve promising results and suggest its utility in ear-based authentication. This paper also illustrates that the phase information extracted from <b>ear</b> <b>images</b> can achieve significant performance improvement as compared to appearance-based approach employed in the literature. Department of Computin...|$|R
40|$|Ear {{recognition}} is a promising biometric measure, {{especially with the}} growing interest in multi-modal biometrics. Histogram of Oriented Gradients (HOG) has been effectively and efficiently used solving the problems of object detection and recognition, especially when illumination variations are present. This work presents a robust approach for ear recognition using multi-scale dense HOG features as a descriptor of 2 D <b>ear</b> <b>images.</b> The multi-scale features assure to capture the different and complicated structures of <b>ear</b> <b>images.</b> Dimensionality reduction was performed to avoid feature redundancy and provide a more efficient recognition process while being prone to over-fitting. Finally, a test was performed on a large and realistic database {{and the results were}} compared to {{the state of the art}} ear recognition approaches tested on the same dataset and under the same test procedure...|$|R
40|$|Researchers have {{suggested}} that the ear may have advantages over the face for biometric recogni-tion. Our previous experiments with ear and face recognition using the standard principal compo-nent analysis approach showed lower recognition performance using <b>ear</b> <b>images.</b> We report results of similar experiments on larger data sets that are more rigorously controlled for relative quality of face and <b>ear</b> <b>images.</b> We find that recognition performance is not significantly different between the face and the ear; for example, 69. 3 % versus 72. 7 %, respectively, in one experiment. We also find that multi-modal recognition using both the ear and face results in statistically significant improvement over either individual biometric; for example, 90. 9 % in the analogous experiment. Index terms- biometrics, face recognition, ear recognition, multi-modal biometrics, principal component analysis, appearance-based recognition. 1 1...|$|R
40|$|We {{present an}} {{experimental}} study {{to demonstrate the}} effect of the time difference in image acquisition for gallery and probe on the performance of ear recognition. This experimental research is the first study on the time effect on ear biometrics. For the purpose of recognition, we convolve banana wavelets with an <b>ear</b> <b>image</b> and then apply local binary pattern on the convolved image. The histograms of the produced image are then used as features to describe an ear. A histogram intersection technique is then applied on the histograms of two ears to measure the ear similarity for the recognition purposes. We also use analysis of variance (ANOVA) to select features to identify the best banana wavelets for the recognition process. The experimental results show that the recognition rate is only slightly reduced by time. The average recognition rate of 98. 5 % is achieved for an eleven month-difference between gallery and probe on an un-occluded ear data set of 1491 <b>images</b> of <b>ears</b> selected from Southamopton University ear database...|$|R
40|$|Abstract—From secret {{knowledge}} like password up {{to physical}} traits as biometrics, current smartphone authentication systems are deemed inconvenience and difficult for users. Burdens on remembering password {{as well as}} privacy issues on stolen or forged biometrics have raised a futuristic idea of authentication systems. New system is hoped being transparent and with very minimum user involvement denoted as implicit authentication system. One {{of the ways to}} implicitly authenticate users is by authenticating them via image or video captured using smartphone camera during a call. During call interaction, we implicitly take <b>ear</b> <b>image</b> using front smartphone camera to recognize and authenticate users without them realizing. In this paper, we present a novel approach to ear recognition which considers both shape and texture information to represent <b>ear</b> <b>image.</b> Firstly, all Local Binary Pattern (LBP) are combined after extracted and concatenated into a single histogram. Second, in order to get geometric features, we use the idea of ear location center that is easily adjusted by smartphone user. Then, we combine previous steps to represent <b>ear</b> <b>image</b> as a descriptor. The recognition is performed using a nearest neighbor classifier computed feature space with Euclidean distance as a similarity/dissimilarity measure. Our proposed approach is very easy and simple thereby its simplicity allows very fast feature extraction. We foresee that this experiment is applicable directly on smartphone. Keywords-ear;biometrics; implicit; user authentication; smartphone; I...|$|R
40|$|Ears are an {{emergent}} biometric accruing application advantages including no {{requirement for}} subject contact and acquisition without demand. To recognize a subject's ear, {{we aim to}} extract a characteristic vector from a human <b>ear</b> <b>image</b> that may subsequently {{be used to identify}} or confirm the identity of the owner. Towards this en...|$|R
40|$|Extraction and {{expression}} of features {{are critical to}} improving the recognition rate of <b>ear</b> <b>image</b> recognition. This paper proposes a new ear recognition method based on SIFT (Scale-invariant feature transform) and Forstner corner detection technology. Firstly, Forstner corner points and SIFT keypoints are detected respectively. Then taking Forstner corner into the SIFT algorithm to calculate their descriptor as the image feature vectors. Finally ear recognition based on these feature is carried out with Euclidean distance as similarity measurement. Abi-directional matching algorithmis utilized for improving recognition rate. Experiments on USTB database show that the recognition rate reaches more 94 %. The Experimental results prove {{the effectiveness of the}} proposed method in term of recognition accuracy in comparison with previous methods. It is robust to rigid changes of <b>ear</b> <b>image</b> and provides a new approach to the research for ear recognition...|$|R
40|$|One of {{the most}} recent trends in {{biometrics}} is recognition by ear appearance in head profile <b>images.</b> <b>Ear</b> localization to determine the region of interest containing ears is an important step in an ear biometric system. To this end, we propose a robust, simple and effective method for ear detection from profile images by employing a bank of curved and stretched Gabor wavelets, known as banana wavelets. Our analysis shows that the banana wavelets demonstrate better performance than Gabor wavelets technique for ear localization. This indicates that the curved wavelets are advantageous for the detection of curved structures such as ears. This ear detection technique is fully automated, has encouraging performance and appears to be robust to degradation by noise. Addition of a preprocessing stage, based on skin detection using colour and texture, can improve the detection results even further. For recognition, we convolve the banana wavelets with an <b>ear</b> <b>image</b> and then apply local binary pattern (LBP) for texture analysis to the convolved image. The LBP histograms of the produced image are then used as features to describe an ear. A histogram intersection technique is then applied on the LBP histograms of two ears to measure their similarity for recognition. Analysis of variance is also exploited here to select features to identify the best banana filters for the recognition process. We show that the new banana wavelets, in combination with other analysis, can be used to achieve recognition by the ear, with practical advantages. The analyses focus particularly in simulating addition of noise and occlusion to a standard database, and their evaluation on a newer and much more demanding ear database. We also present an experimental study to investigate the effect of time difference between image acquisition for gallery and probe on the performance of ear recognition. This experimental research is the first study on the effect of time on ear biometrics and show that the recognition rate remains unchanged over time, confirming another advantage of deploying the human ear as a biometric. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
