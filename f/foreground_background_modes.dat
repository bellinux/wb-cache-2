0|2834|Public
40|$|Abstract—This paper {{proposes a}} blind {{calibration}} algorithm for suppressing harmonic distortion in analog to digital con-verters (ADCs). The proposed algorithm {{does not need}} any external calibration signal and is first of its kind. The proposed algorithm relies on the properties of downsampling and orthog-onality of sinusoidal signals to estimate the harmonic distortion coefficients. The algorithm can be operated in both <b>foreground</b> and <b>background</b> <b>modes</b> to remove even and odd harmonics simultaneously. The algorithm is demonstrated on a first-order ring oscillator based ∆Σ ADC, whose performance is harmonic distortion limited. Built in 0. 13 µm, the algorithm improves the SNDR of the ADC by 39 dB while improving SFDR by 45 dB. I...|$|R
5000|$|... 40- and 80-column text, with 24 lines (16 {{selectable}} <b>foreground,</b> <b>background,</b> border colors) ...|$|R
5000|$|... #Caption: The ThunderCats. From left to right: Tygra, WilyKit, Lion-O, WilyKat (<b>foreground),</b> Panthro (<b>background),</b> Snarf (<b>foreground),</b> Cheetara (<b>background).</b>|$|R
40|$|Abstract: We {{consider}} the effective stress-energy tensors for the <b>foreground</b> and <b>background</b> sectors in ghost-free bimetric gravity. By considering the symmetries of the theory, {{we show that}} the <b>foreground</b> and <b>background</b> null energy conditions (NECs) are strongly anti-correlated. In particular, the NECs can only be simultaneously ful-filled when they saturate, corresponding to <b>foreground</b> and <b>background</b> cosmological constants. In all other situations, either the <b>foreground</b> or the <b>background</b> is subject to a NEC-violating contribution to the total stress-energy...|$|R
40|$|<b>Foreground</b> <b>background</b> {{segmentation}} algorithms {{attempt to}} separate interesting or changing regions from the background in video sequences. Foreground detection is obviously more difficult {{when the camera}} viewpoint changes dynamically, such as when the camera undergoes a panning or tilting motion. In this paper, we propose an edge based <b>foreground</b> <b>background</b> estimation method, which can automatically detect and compensate for camera viewpoint changes. We will show that this method significantly outperforms state-of-the-art algorithms for the panning sequences in the ChangeDetection. NET 2014 dataset, while still performing well in the other categories...|$|R
2500|$|If {{a subject}} is at {{distance}} [...] and the <b>foreground</b> or <b>background</b> is at distance , let {{the distance between}} the subject and the <b>foreground</b> or <b>background</b> be indicated by ...|$|R
40|$|Image matting is {{the process}} of extracting a soft {{segmentation}} of an object in an image as defined by the matting equation. Most current techniques focus largely on computing the alpha values of unknown pixels and treat computation of the <b>foreground</b> and <b>background</b> colors as an afterthought, if at all. However, for many applications, such as compositing an object into a new scene or deleting an object from the scene, the <b>foreground</b> and <b>background</b> colors are vital for an acceptable answer. We propose a method of solving for the <b>foreground,</b> <b>background,</b> and alpha of an unknown region in an image simultaneously. This allows for novel constraints to be placed directly on the <b>foreground</b> and <b>background</b> as well as on alpha. We show through both visual results and quantitative measurements on standard datasets that this approach produces more accurate <b>foreground</b> and <b>background</b> values at each pixel while maintaining competitive results on the alpha matte. 1...|$|R
5000|$|The series {{uses the}} graphic process Morris used that employs colors to {{differentiate}} a character {{according to its}} value in the (<b>foreground,</b> <b>background),</b> according to his mood state (green rage, ...) or to describe a mood (red fire, night blue, ...).|$|R
50|$|Because each {{character}} {{can be assigned}} different <b>foreground</b> and <b>background</b> colors, it can be colored (for example) blue on the left (foreground color) and bright red on the right (background color). This can be reversed by swapping the <b>foreground</b> and <b>background</b> colors.|$|R
40|$|We {{extend the}} blind {{deblurring}} method [1] for separating images with two layers that have suffered different blurs: E. g. objects with different velocities, or at different focus depths. • The method only requires weak assumptions on the blurring filter. • It reasonably estimates, {{from a single}} degraded image:- A complete deblurred image (<b>foreground</b> + <b>background)</b> - Blurring filters (<b>foreground</b> + <b>background)</b> - Segmentation mask between <b>foreground</b> and <b>background.</b> • Enhancements are achieved both in real blurred photos and in synthetic degradations...|$|R
50|$|Weber & Welling here {{introduce}} {{the concept of}} <b>foreground</b> and <b>background.</b> <b>Foreground</b> parts correspond to an instance of a target object class, whereas background parts correspond to background clutter or false detections.|$|R
40|$|Generating novel, yet realistic, {{images of}} persons is a {{challenging}} task {{due to the}} complex interplay between the different image factors, such as the <b>foreground,</b> <b>background</b> and pose information. In this work, we aim at generating such images based on a novel, two-stage reconstruction pipeline that learns a disentangled representation of the aforementioned image factors and generates novel person images at the same time. First, a multi-branched reconstruction network is proposed to disentangle and encode the three factors into embedding features, which are then combined to re-compose the input image itself. Second, three corresponding mapping functions are learned in an adversarial manner in order to map Gaussian noise to the learned embedding feature space, for each factor respectively. Using the proposed framework, we can manipulate the <b>foreground,</b> <b>background</b> and pose of the input image, and also sample new embedding features to generate such targeted manipulations, that provide {{more control over the}} generation process. Experiments on Market- 1501 and Deepfashion datasets show that our model does not only generate realistic person images with new <b>foregrounds,</b> <b>backgrounds</b> and poses, but also manipulates the generated factors and interpolates the in-between states. Another set of experiments on Market- 1501 shows that our model can also be beneficial for the person re-identification task...|$|R
25|$|Gleizes' {{method was}} {{fundamentally}} synthetic. Although the landscape seems persuasively realistic (with its <b>foreground,</b> <b>background</b> and village in between), {{it is not}} an existing place somewhere between Paris and his studio at Courbevoie, consistent with Gleizes' method of bringing together various elements from different locations anteriorly observed in nature.|$|R
40|$|We {{consider}} {{the framework of}} attentional processing in light of Gestalt theory. The dichotomy of top-down and bottom-up attention is criticized as an anachronism {{in light of the}} interactive character of processing. The Gestalt concept of <b>foreground</b> <b>background</b> organization offers an appropriate contextualization for the notion of attention...|$|R
2500|$|For a given subject magnification, f-number, and {{distance}} from {{the subject of the}} <b>foreground</b> or <b>background</b> detail, the degree of detail blur varies with the lens focal length. For a background detail, the blur increases with focal length; for a foreground detail, the blur decreases with focal length. For a given scene, the positions of the subject, <b>foreground,</b> and <b>background</b> usually are fixed, and the distance between subject and the <b>foreground</b> or <b>background</b> remains constant regardless of the camera position; however, to maintain constant magnification, the subject distance must vary if the focal length is changed. For small distance between the <b>foreground</b> or <b>background</b> detail, the effect of focal length is small; for large distance, the effect can be significant. For a reasonably distant background detail, the blur disk diameter is ...|$|R
30|$|Differentiate the <b>foreground</b> and <b>background</b> {{region of}} human boundary.|$|R
5000|$|... #Caption: Both Holyrood trees, May 2014 (<b>foreground</b> and <b>background</b> right) ...|$|R
60|$|In the <b>foreground</b> and <b>background</b> {{there was}} a {{disappointed}} face.|$|R
30|$|Question 3 : Contrast ratio between <b>foreground</b> and <b>background</b> is suitable.|$|R
40|$|VISAPP {{is part of}} VISIGRAPP - International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and ApplicationsArea 3 - Motion, Tracking and Stereo Vision: Paper no. 13 This paper revisits the graph-cuts based {{approach}} for solving the multi-view stereo problem, and proposes a novel <b>foreground</b> / <b>background</b> energy which is shown to be unbiased and robust against noisy depth maps. Unlike most existing works which focus on deriving a robust photo-consistency energy, this paper targets at deriving a robust and unbiased <b>foreground</b> / <b>background</b> energy. By introducing a novel data-dependent <b>foreground</b> / <b>background</b> energy, we show {{that it is possible}} to recover the object surface from noisy depth maps even in the absence of the photo-consistency energy. This demonstrates that the <b>foreground</b> / <b>background</b> energy is equally important as the photo-consistency energy in graph-cuts based methods. Experiments on real data sequences further show that high quality reconstructions can be achieved using our proposed <b>foreground</b> / <b>background</b> energy with a very simple photo-consistency energy. link_to_subscribed_fulltextThe International Joint Conference on Computer Vision Theory and Applications (VISAPP 2011), Vilamoura, Algarve, Portugal, 5 - 7 March 2011. In Proceedings of VISAPP, 2011, p. 451 - 45...|$|R
40|$|In this paper, {{we present}} a new image matting {{algorithm}} that achieves state-of-the-art performance on a benchmark dataset of images. This is achieved by solving two ma-jor problems encountered by current sampling based al-gorithms. The first is that the range in which the fore-ground and background are sampled is often limited {{to such an extent}} that the true <b>foreground</b> and <b>background</b> colors are not present. Here, we describe a method by which a more comprehensive and representative set of samples is collected so as not to miss out on the true samples. This is accomplished by expanding the sampling range for pixels farther from the <b>foreground</b> or <b>background</b> boundary and ensuring that samples from each color distribution are in-cluded. The second problem is the overlap in color distri-butions of <b>foreground</b> and <b>background</b> regions. This causes sampling based methods to fail to pick the correct samples for <b>foreground</b> and <b>background.</b> Our design of an objective function forces those <b>foreground</b> and <b>background</b> samples to be picked that are generated from well-separated dis-tributions. Comparison on the dataset at and evaluation by www. alphamatting. com shows that the proposed method ranks first in terms of error measures used in the website. 1...|$|R
40|$|Image matting is {{the problem}} of {{determining}} for each pixel in an image whether it is <b>foreground,</b> <b>background,</b> or the mixing parameter, ”alpha”, for those pixels that are a mixture of <b>foreground</b> and <b>background.</b> Matting is inherently an ill-posed problem. Previous matting approaches either use naive color sampling methods to estimate <b>foreground</b> and <b>background</b> colors for unknown pixels, or use propagation-based methods to avoid color sampling under weak assumptions about image statistics. We argue that neither method itself is enough to generate good results for complex natural images. We analyze the weaknesses of previous matting approaches, and propose a new robust matting algorithm. In our approach we also sample <b>foreground</b> and <b>background</b> colors for unknown pixels, but more importantly, analyze the confidence of these samples. Only high confidence samples are chosen to contribute to the matting energy function which is minimized by a Random Walk. The energy function we define also contains a neighborhood term to enforce the smoothness of the matte. To validate the approach, we present an extensive and quantitative comparison between our algorithm and a number of previous approaches in hopes of providing a benchmark for future matting research. 1...|$|R
5000|$|... #Caption: Bridges over rivers Seine (<b>foreground),</b> Yonne (<b>background)</b> and {{statue of}} Napoléon ...|$|R
5000|$|... #Caption: C-130s from the: U.S., Canada, Australia and Israel (<b>foreground</b> to <b>background)</b> ...|$|R
5000|$|... #Caption: Eorsa {{from the}} north/northwest with Mull in the <b>foreground</b> and <b>background</b> ...|$|R
5000|$|... #Caption: Robert Tarn, Mackenzie Tarn and Johnston Tarn (<b>foreground</b> to <b>background),</b> Tarn Shelf ...|$|R
5000|$|Optional trip {{recording}} also in <b>background</b> <b>mode</b> (while {{device is}} in sleep mode) ...|$|R
40|$|Post-printHow do we feel {{our body}} in emotion experience? In this paper I {{initially}} distinguish between <b>foreground</b> and <b>background</b> bodily feelings, and characterize {{them in some}} detail. Then I compare this distinction with the one between reflective and pre-reflective bodily self-awareness one finds in some recent philosophical phenomenological works, and conclude that both <b>foreground</b> and <b>background</b> bodily feelings {{can be understood as}} pre-reflective modes of bodily self-awareness that nevertheless differ in degree of self-presentation or self-intimation. Finally, I use the distinction between <b>foreground</b> and <b>background</b> bodily feelings to characterize the experience of being absorbed in an activity, as opposed to accounts that imply that absorption involves bodily inconspicuousness. European Research Counci...|$|R
5000|$|Elimination of <b>foreground</b> and <b>background</b> by way {{of using}} 100 percent of the canvas ...|$|R
5000|$|... #Caption: Main hall, with Gloster Meteor (<b>foreground),</b> Huanquero (<b>background)</b> and Urubu (hanging from roof) ...|$|R
5000|$|... #Caption: Nor Kyurin (<b>foreground),</b> Marmarashen (<b>background</b> with {{unfinished}} church), and Mt. Ararat, May 2009.|$|R
30|$|First, all {{annotation}} nodes in test subset {{were classified}} into two categories: <b>foreground</b> and <b>background.</b>|$|R
500|$|The most {{innovative}} technical aspect of Citizen Kane is the extended use of deep focus. In nearly every {{scene in the}} film, the <b>foreground,</b> <b>background</b> {{and everything in between}} are all in sharp focus. Cinematographer Toland did this through his experimentation with lenses and lighting. Toland described the achievement, made possible by the sensitivity of modern speed film, in an article for Theatre Arts magazine: ...|$|R
40|$|This paper {{proposes a}} new Bayesian {{framework}} for solving the matting problem, i. e. extracting a foreground element from a background image by estimating an opacity for each pixel of the foreground element. Our approach models both the <b>foreground</b> and <b>background</b> color distributions with spatiallyvarying sets of Gaussians, and assumes a fractional blending of the <b>foreground</b> and <b>background</b> colors {{to produce the}} final output. It then uses a maximum-likelihood criterion to estimate the optimal opacity, <b>foreground</b> and <b>background</b> simultaneously. In addition to providing a principled approach to the matting problem, our algorithm effectively handles objects with intricate boundaries, such as hair strands and fur, and provides an improvement over existing techniques for these difficult cases. 1...|$|R
40|$|In {{this report}} my work {{done during the}} CERN Summer Student Programme within the LHCb {{collaboration}} is summarized. Results obtained on B [...] > μ^+ ν_μ and K_s^ 0 [...] > μ^+ μ^- analyses are presented. For the first, the dominant <b>background</b> <b>modes</b> were studied and fitted to data. For the second, the efficiencies of the stripping cuts were calculated, and the dominant <b>background</b> <b>mode</b> studied and fitted...|$|R
2500|$|For a given scene, the {{distance}} between the subject and a <b>foreground</b> or <b>background</b> object is usually ...|$|R
