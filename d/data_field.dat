768|10000|Public
25|$|Message {{length is}} Max 260Bytes. <b>Data</b> <b>field</b> MAX 255.|$|E
25|$|Singly linked lists contain nodes {{which have}} a <b>data</b> <b>field</b> as well as 'next' field, which points to the next node in line of nodes. Operations that can be {{performed}} on singly linked lists include insertion, deletion and traversal.|$|E
25|$|Sentinel node may simplify certain list operations, by {{ensuring}} that the next or previous nodes exist for every element, and that even empty lists {{have at least one}} node. One may also use a sentinel node {{at the end of the}} list, with an appropriate <b>data</b> <b>field,</b> to eliminate some end-of-list tests. For example, when scanning the list looking for a node with a given value x, setting the sentinel's <b>data</b> <b>field</b> to x makes it unnecessary to test for end-of-list inside the loop. Another example is the merging two sorted lists: if their sentinels have data fields set to +∞, the choice of the next output node does not need special handling for empty lists.|$|E
40|$|Nowadays, {{there are}} {{increasing}} amount of <b>data</b> <b>fields</b> of tide and tidal current gained from ocean dynamical environment real-time stereo monitoring platform, model calculation and numerical simulation. Collaborative visualization of these <b>data</b> <b>fields</b> {{on the internet}} is becoming increasingly important for the utility of data. In this paper, we summarize the characters of tide and tidal current <b>data</b> <b>fields</b> and introduce a data process and visualization system. We organize the original data follow a certain criterion, preprocess the data to improve the visualization effective, use snap-shot spatio-temporal data model to organize the <b>data</b> <b>fields</b> and display the changing process of tide and tidal current. Through a well-organized metadata database, <b>data</b> <b>fields</b> are well managed. By using web services we provide proper services {{to meet the needs of}} both the public and professionals on the internet...|$|R
40|$|A {{statistical}} database {{is defined}} as a collection of N records used to produce summary information only. Each record contains confidential category and <b>data</b> <b>fields</b> of the same fixed length. Category fields are used to identify and select records, while <b>data</b> <b>fields</b> hold other information, mostly numerical...|$|R
50|$|T-trees do {{not keep}} {{copies of the}} indexed <b>data</b> <b>fields</b> within the index tree nodes themselves. Instead, they take {{advantage}} {{of the fact that the}} actual data is always in main memory together with the index so that they just contain pointers to the actual <b>data</b> <b>fields.</b>|$|R
25|$|The {{authority}} field {{represents the}} entity {{that created the}} CRID and its format {{is that of a}} DNS name. The <b>data</b> <b>field</b> represents a string of characters that will unambiguously identify the content within the authority scope (it is a string of characters assigned by the authority itself).|$|E
25|$|The {{ancillary}} <b>data</b> <b>field</b> {{can be used}} {{to store}} user defined data. The ancillary data is optional and the number of bits available is not explicitly given. The ancillary data is located after the Huffman code bits and ranges to where the next frame's main_data_begin points to. mp3PRO uses ancillary data to encode their bits to improve audio quality.|$|E
25|$|McKenna {{suspected}} that notable events in history {{could be identified}} that would help him locate the time wave's end date and attempted to find the best-fit placement when matching the graph to the <b>data</b> <b>field</b> of human history. The last harmonic of the wave has a duration of 67.29 years. Population growth, peak oil, and pollution statistics {{were some of the}} factors that pointed him to an early twenty-first century end date and when looking for an extremely novel event in human history as a signal that the final phase had begun McKenna picked the dropping of the atomic bomb on Hiroshima. This worked out to the graph reaching zero in mid-November 2012. When he later discovered {{that the end of the}} 13th baktun in the Maya calendar had been correlated by Western Maya scholars as December 21, 2012, he adopted their end date instead.|$|E
5000|$|A TFM file {{is broken}} down {{into a series of}} four-byte words, which can contain <b>data</b> <b>fields</b> of various lengths. Any <b>data</b> <b>fields</b> that are more than one byte long are held in big endian order. (The exact same file will be generated, {{regardless}} of architecture of the computer generating it.) ...|$|R
50|$|<b>Field</b> delimiters {{separate}} <b>data</b> <b>fields.</b> Record delimiters separate {{groups of}} fields.|$|R
50|$|PubChemSR {{supports}} a bulk download of selected <b>data</b> <b>fields</b> for multiple chemicals.|$|R
25|$|Thirty {{years ago}} there was neither real {{predictability}} nor qualitative understanding of the dominant mechanisms in emulsion polymerisation. Mechanisms had been ‘proved’ by comparing model predictions with experimental data. The <b>data</b> <b>field</b> was limited and the models had many adjustable parameters, or else fitting parameters had values that were subject to wide uncertainty: {{it was possible to}} choose values that could suit any model. It was not uncommon to find two papers claiming that quite different mechanisms were dominant in the same system, a result {{of not being able to}} isolate the individual steps. As a result of Gilbert’s work, all individual processes in emulsion polymerisation, one of the commonest ways of making everyday products, are now qualitatively and quantitatively understood. It is now possible to polymerise simple systems and to predict the molecular architecture that will be formed under chosen conditions, while for more complex conditions, trends can be semiquantitatively predicted and understood. The international scientific and technical community in this field now uses the mechanistic knowledge that he obtained as the key to understanding current processes and creating new processes and products. His work has put this industrially important field on a rigorous scientific footing.|$|E
5000|$|... "Rows" [...] {{in tables}} are {{represented}} as records that contain a key value and a <b>data</b> <b>field.</b> This <b>data</b> <b>field</b> may in turn be a tuple containing an Erlang data structure of any complexity.|$|E
5000|$|The {{next six}} bits contain {{information}} for specifying the Control Field. The initial two bits are fixed, while {{the last four}} are used to specify length field of the <b>Data</b> <b>Field.</b> The <b>Data</b> <b>Field</b> contains from zero to eight bytes of usable data. (Physical Layer.) ...|$|E
5000|$|Search for images {{based on}} <b>data</b> <b>fields</b> (keywords, country, subject, copyright, etc.).|$|R
5000|$|... the <b>data</b> (<b>Fields,</b> Objects, Managers, etc.) {{encapsulated}} by {{instances of}} the class.|$|R
50|$|Data type {{validation}} is customarily {{carried out}} on one or more simple <b>data</b> <b>fields.</b>|$|R
50|$|Message {{length is}} Max 260Bytes. <b>Data</b> <b>field</b> MAX 255.|$|E
5000|$|BatchSearch {{supports}} extract specific <b>data</b> <b>field</b> (like SMILES) {{for multiple}} queries.|$|E
5000|$|ISO 15022: 1999 Securities—Scheme for {{messages}} (<b>Data</b> <b>Field</b> Dictionary) (replaces ISO 7775) ...|$|E
5000|$|Flexibility {{in meeting}} client {{requirements}} (custom screen views, client-defined <b>data</b> <b>fields,</b> special reports, etc.); ...|$|R
50|$|Descriptive data (geometrical value) vary {{depending}} on the type of tool. The <b>data</b> <b>fields</b> are specified in the class list of characteristics. The meaning of the geometrical <b>data</b> <b>fields</b> is illustrated in diagrams and pictures. DIN 4000 recommends diagrams and pictures for their explanation. Varying graphics for different functions are stored either in the database, or with the components through data links.|$|R
30|$|The <b>data</b> <b>fields</b> of a {{back-end}} database are initialized to HaID, ID, TD and DATA.|$|R
5000|$|Chunk data : General purpose <b>data</b> <b>field</b> whose {{definition}} {{varies with the}} chunk type.|$|E
5000|$|Means of {{researches}} {{and collections}} of <b>data</b> (<b>field</b> works, experiments in production lines, etc.) ...|$|E
50|$|The team {{plays at}} First <b>Data</b> <b>Field.</b> Opened in 1988, the park seats 7,347 fans.|$|E
30|$|In this way, the {{customer}} account details will be obscured for protecting individual’s sensitive <b>data</b> <b>fields.</b>|$|R
50|$|Many {{applications}} need {{to access}} data via non-primary key <b>data</b> <b>fields.</b> Sherpa supports asynchronous secondary indexes.|$|R
5000|$|A built in, SQL-like {{expression}} language for writing queries to prefuse data structures and creating derived <b>data</b> <b>fields.</b>|$|R
5000|$|... invoke an {{extensive}} range of <b>data</b> <b>field</b> options, to create test data dynamically into messages; ...|$|E
5000|$|Data {{templates}} for pre-filled {{collections of}} <b>data</b> <b>field</b> values {{to be saved}} and later applied to images.|$|E
50|$|The {{contents}} {{and the length}} {{of the rest of the}} <b>Data</b> <b>field</b> depends on the NCP Function.|$|E
5000|$|It should {{enable the}} {{creation}} of new <b>data</b> <b>fields</b> by manipulating and calculating values based on other fields ...|$|R
40|$|The paper {{focuses on}} the {{possibilities}} of better organization and retrieval of Internet resources {{with the advent of}} eXtensible Markup Language (XML). The paper advocates the need of identifying necessary and sufficient bibliographic <b>data</b> <b>fields</b> for Internet resources, and generating numerical XML elements for the <b>data</b> <b>fields</b> using a standard syntax which brings together existing tag codes. The paper also brings into the issue of standard out put of search results...|$|R
50|$|Database systems often {{store data}} in {{structures}} called tables; in which columns are <b>data</b> <b>fields</b> and rows represent data records.|$|R
