1|142|Public
30|$|List {{screening}} {{is realized}} by modified and nested tables. The segment head of custom table {{is used as}} first-level screening title. Second-level screening catalog is achieved by nested table and custom table cells. By nesting second-level screening catalog, we obtain third-level screening catalog. The subtitle of first-level catalog is refreshed by recording the selected <b>filter</b> <b>item</b> in real time. Simultaneously, the server is synchronized to get the remaining product information.|$|E
3000|$|There were 319 {{participants}} who finished the experimental tasks. The survey used <b>filtering</b> <b>items</b> {{to determine if}} participants were actually reading the items (e.g., there are 8  days in a week). Three respondents were eliminated based on the <b>filtering</b> <b>items,</b> two identified their location as outside the US and were deleted, and 19 were also eliminated due to large blocks of missing data. After cleaning the data, there were 295 participants with usable data. The sample consisted of {{more men than women}} (F =  133, M =  162), who were primarily Caucasian American (84.8 [...]...|$|R
50|$|Fritted {{glass is}} finely porous glass through which gas or liquid may pass. Applications in {{laboratory}} glassware include use in fritted glass <b>filter</b> <b>items,</b> scrubbers, or spargers. Other laboratory applications of fritted glass include packing in chromatography columns and resin beds for special chemical synthesis.|$|R
5000|$|Job scheduler, visual flow designer, {{manage and}} move files across protocols. Pass {{a list of}} found files from one step to the next, <b>filtering</b> <b>items</b> out, {{multithreading}} multiple steps simultaneously, and monitoring in realtime {{the progress of the}} job visually and with realtime logging.|$|R
40|$|Google Translate's API {{creates the}} {{possibility}} to leverage machine translation to both filter global newsfeeds for content regarding a specific topic, and to aggregate <b>filtered</b> feed <b>items</b> as a newsfeed. <b>Filtered</b> <b>items</b> can be translated so that the resulting newsfeed can provide basic information about topic-specific news articles {{from around the globe}} in the desired language of the consumer. This article explores a possible solution for inputting alternate words and phrases in the user’s native language, aggregating and filtering newsfeeds progammatically, managing filter terms, and using Google Translate’s API...|$|R
50|$|Fritted {{glass is}} finely porous glass through which gas or liquid may pass. It {{is made by}} {{sintering}} together glass particles into a solid but porous body. This porous glass body can be called a frit. Applications in laboratory glassware include use in fritted glass <b>filter</b> <b>items,</b> scrubbers, or spargers. Other laboratory applications of fritted glass include packing in chromatography columns and resin beds for special chemical synthesis.|$|R
50|$|One of the {{problems}} with news aggregators is that the volume of articles can sometimes be overwhelming, especially when the user has many web feed subscriptions. As a solution, many feed readers allow users to tag each feed with one or more keywords which can be used to sort and filter the available articles into easily navigable categories. Another option is to import the user's Attention Profile to <b>filter</b> <b>items</b> based on their relevance to the user's interests.|$|R
5000|$|Exclusion and {{inclusion}} <b>filters</b> for specific <b>items</b> and file extensions ...|$|R
40|$|In {{the past}} decade there has been massive growth of data on the internet. Many people rely on XML based RSS feeds to receive updates from websites. In this paper, we propose a method for {{managing}} the RSS feeds from various news websites. A web service is developed to deliver <b>filtered</b> news <b>items</b> from RSS feeds to a mobile client. Each news item is indexed, subsequently, the indexes are used for <b>filtering</b> news <b>items.</b> Indexing is done in two steps. First, classical text categorization algorithms are used to assign a category to each news item, second, geoparsing is used to assign geolocation data to each news item. An android application is developed to access <b>filtered</b> news <b>items</b> by consuming the proposed web service. A prototype is implemented using Rapid miner 5. 0 as the data mining tool and SVM as the classification algorithm. Geoparsing and geocoding web services, and Android API are used to implement location-based access to news items. Experimental results prove that the proposed approach is effective and saves {{a significant amount of}} information overload processing time...|$|R
40|$|In {{this paper}} we address a {{particular}} recommendation task: retrieving musicians suited for a place of interest (POI). We present a knowledge-based framework built upon the DBpedia ontology linking items from different domains. Graphbased algorithms are used for ranking and <b>filtering</b> <b>items</b> in a target domain (music) with respect to their relatedness to an input item in a source domain (POIs). By conducting user studies we found that users appreciate and judge more valuable the suggestions generated by the proposed approach when a novel weight spreading activation algorithm is used to compute the matching between musicians and POIs. Moreover, users perceive compositions of the suggested musicians as suited for the POIs...|$|R
40|$|We {{consider}} information filtering, {{in which}} we face a stream of items too voluminous to process by hand (e. g., scientific articles, blog posts, emails), and must rely on a computer system to automatically <b>filter</b> out irrelevant <b>items.</b> Such systems face the exploration vs. exploitation tradeoff, in which it may be beneficial to present an item despite a low probability of relevance, just to learn about future items with similar content. We present a Bayesian sequential decision-making model of this problem, show how it may be solved to optimality using a decomposition to a collection of two-armed bandit problems, and show structural results for the optimal policy. We show that the resulting method is especially useful when facing the cold start problem, i. e., when <b>filtering</b> <b>items</b> for new users without {{a long history of}} past interactions. We then present an application of this information filtering method to a historical dataset from the arXiv. org repository of scientific articles. Comment: 36 pages, 5 figure...|$|R
5000|$|Output <b>filters</b> (to output <b>items</b> as HTML {{and as an}} {{alternative}} as PDF or others) ...|$|R
40|$|Abstract: The huge {{catalogues}} {{of video}} items currently available through live, on-demand and catchup TV based services {{coupled with the}} ever expanding range of online video services (Vimeo, YouTube, Netflix) provides users with unprecedented levels of choice. Not only is the choice of content expanding but so too are the range of formats, delivery mechanisms and the viewing devices (PC, TV/STB, mobile device). In order to navigate these repositories sensibly recommender systems provide {{a key role in}} helping a user <b>filter</b> <b>items</b> of interest. In this paper, we describe our initial work on integrating an IPTV service with social networks in order to support the personalisation process by exploiting the social graph...|$|R
25|$|Stream {{filtering}} {{is essentially}} a non-uniform reduction. <b>Filtering</b> involves removing <b>items</b> from the stream based on some criteria.|$|R
40|$|As {{the largest}} online {{marketplace}} in the world, eBay {{has a huge}} inventory where {{there are plenty of}} great rare items with potentially large, even rapturous buyers. These items are obscured in long tail of eBay item listing and hard to find through existing searching or browsing methods. It is observed that there are great rarity demands from users according to eBay query log. To keep up with the demands, the paper proposes a method to automatically detect rare items in eBay online listing. A large set of features relevant to the task are investigated to <b>filter</b> <b>items</b> and further measure item rareness. The experiments on the most rarity-demandintensitive domains show that the method may effectively detect rare items (> 90 % precision). Categories and Subject Descriptor...|$|R
40|$|Identifying tyre models {{directly}} from vehicle test data using an extended Kalman <b>filter</b> This <b>item</b> was submitted to Loughborough University’s Institutional Repository by the/an author. Citation: BEST, M. C., 2010. Identifying tyre models {{directly from}} vehicle test data using an extended Kalman filter. Vehicle System Dynamics: Internationa...|$|R
40|$|AbstractPersonalized {{information}} retrieval systems can help customers to gain orientation in information overload by determining which items are relevant for their interests. One type of {{information retrieval}} is content-based filtering. In content-based <b>filtering,</b> <b>items</b> contain words in natural language. Meanings of words in natural language are often ambiguous. The problem of word meaning disambiguation is often decomposed to determining semantic similarity of words. In this paper, the architecture of personalized information retrieval based on user interest is presented. The architecture includes user interface model, user interest model, detecting interest model and update model. It established a user model for personalized information retrieval based on user interest keyword list on client server, which can supply personalized information retrieval service for user with the communications and collaboration of all modules of the architecture...|$|R
40|$|This note shows a few {{examples}} of GAP computations concerning multiplicity-free permutation characters, with an emphasis on the classification of the faithful multiplicity-free permutation characters of the sporadic simple groups and their automorphism groups given in [BL 96]. For examples on GAP computations with permutation characters in general, see the note [Bre]. For further questions about GAP, consult its Reference Manual; in particular, for the description of the commands for character tables, see the chapter “Character Tables”. Section 1 of this note shows how to interpret the individual data available in the database. In Section 2, the main idea is to gather information from the database as a whole, by <b>filtering</b> <b>items</b> with suitable properties. Finally, Section 3 gives an impression how GAP can be used to obtain result...|$|R
40|$|The {{effect of}} face velocity, pleat density and pleat {{orientation}} {{on the most}} penetrating particle size, pressure drop and fractional efficiency of HEPA <b>filters</b> This <b>item</b> was submitted to Loughborough University's Institutional Repository by the/an author. Citation: AL-ATTAR, I. S [...] et al, 2011. The effect of face velocity, pleat den-sity and pleat orientation on the most penetrating particle size, pressure dro...|$|R
50|$|In {{recommender}} systems, {{the cold}} start problem is often reduced by adopting a hybrid approach between content-based matching and collaborative <b>filtering.</b> New <b>items</b> (which {{have not yet}} received any ratings from the community) would be assigned a rating automatically, based on the ratings assigned by the community to other similar items. Item similarity would be determined according to the items' content-based characteristics.|$|R
50|$|In winnowTag, each tag <b>filters</b> all <b>items</b> in all feeds {{added by}} all users to {{automatically}} find information on its topic. Thus {{it is possible}} to discover on-topic items from a larger set of feeds than could be manually reviewed, but not all the on-topic items are found, and there is no facility for seeing every item published in a set of feeds.|$|R
50|$|The site {{maintains}} localized websites {{for users}} in the United Kingdom, United States, and Denmark. It also uses algorithms and machine learning technology to tailor to individual users content such as the type of fashion products or styles displayed by the site. Users can <b>filter</b> displayed <b>items</b> by designer, brand, color, size, and price. The Fashion curates fashion trends and updates {{on a weekly basis}} for its userbase.|$|R
40|$|In {{decision}} theory, {{an agent}} chooses from {{a set of}} alternatives. When buying online, alternatives are "represented" in one form of another. For instance, online search results are lists of items, wine menus are often lists of lists (grouped by type or country), and online shopping often involves browsing or <b>filtering</b> <b>items</b> which {{can be viewed as}} navigating a tree. An agent can make use {{of the structure of the}} representation when choosing. For instance, in the case of a list he can use the order in which alternatives are represented. In this paper we model general representations and procedures operating on them. We then ask which properties procedures have to fulfill such that their choices can equivalently be understood as a maximization of a rational preference relation when representations are ignored. We fully characterize such procedures and establish that they are intimately linked to well known properties such as Sen's α. What is more, we show that there exist purely procedural properties that are sufficient for a rationalization...|$|R
40|$|Recommender Systems are {{learning}} systems that {{make use of}} data representing multi-user preferences over items (e. g. Vote [user, item] matrix), to try to predict the preference towards new items or products regarding a particular user. User preferences are in fact the learning target functions. The main objective {{of the system is}} to <b>filter</b> <b>items</b> according to the predicted preferences and present to the user the options that are most attractive to him; i. e. he would probably like the most. We study Recommender Systems viewed as a pool of independent prediction algorithms, one per every user, in situations in which each learner faces a sequence of trials, with a prediction to make in each step. The goal is to make as few mistakes as possible. We are interested in the case that each learner has reasons to believe that there exists some other target functions in the pool that consistently behaves similar, neutral or opposite to the target function it is trying to learn. The learner doesn't [...] ...|$|R
40|$|We {{report on}} the {{development}} of a novel technique to select relevant nodes for presentation in hierarchical visualizations. It adapts the Tree Cut Model to the problem of determining the uneven deepest relevant level in a hierarchy, using it as a criterion for <b>filtering</b> data <b>items.</b> In a case study using Docuburst, we demonstrate how this technique can help creating better overviews of data by reducing visual clutter while highlighting relevant data. ...|$|R
40|$|We {{consider}} information filtering, {{in which}} we face a stream of items too voluminous to process by hand (e. g., scientific articles, blog posts, emails), and must rely on a computer system to automatically <b>filter</b> out irrelevant <b>items.</b> Such systems face the exploration vs. exploitation tradeoff, in which it may be beneficial to present an item despite a low probability of relevance, just to learn about future items with similar content. We first present a simple Bayesian sequential decision-making model of this problem, {{where there is a}} unit forwarding cost and an user provides immediate feedback on every item forwarded. In the simple model, we can maximize expected total relevance minus forwarding cost using dynamic programming and a decomposition that exploits special problem structure, and show structural results for the optimal policy. We then extend the model in two realistic ways, allowing the user to provide periodic reviews on a bunch of accumulated items, and considering a constrained information filtering system where the user's cost of time is unknown. With that, we develop a policy that ranks items among categories with inspired costs. The proposing methods are especially useful when facing the cold start problem, i. e., when <b>filtering</b> <b>items</b> for new users without a long history of past interactions. We then present an application of the information filtering method to the arxiv. org repository of scientific articles, and show its implementation status in my. arxiv. org, a beta testing version of the website with recommender systems. 2020 - 08 - 1...|$|R
40|$|The {{potential}} benefit of integrating contextual information for recommendation has received much research attention recently, {{especially with the}} ever-increasing interest in mobile-based recommendation services. However, context based recommendation research is limited {{due to the lack}} of standard evaluation data with contextual information and reliable technology for extracting such information. As a result, there are no widely accepted conclusions on how, when and whether context helps. Additionally, a system often suffers from the so called cold start problem {{due to the lack of}} data for training the initial context based recommendation model. This paper proposes a novel solution to address these problems with automated information extraction techniques. We also compare several approaches for utilizing context based on a new data set collected using the proposed solution. The experimental results demonstrate that 1) IE-based techniques can help create a large scale context data with decent quality from online reviews, at least for restaurant recommendations; 2) context helps recommender systems rank items, however, does not help predict user ratings; 3) simply using context to <b>filter</b> <b>items</b> hurts recommendation per-Bingqing Wang’s work is done during his stay in the Researc...|$|R
50|$|This {{barnacle}} {{reaches a}} length of approximately 25 mm. Unlike most barnacles, it has no shell; the outermost integument is its tough, purplish-black mantle, without any calcareous plates. The body protrudes from the skin of its host and is usually encountered in pairs. The cirri, normally used by barnacles for <b>filtering</b> food <b>items</b> out of the water, are small and unbranched, and have lost their feeding function. Nutrition is instead extracted from the host through hidden tendrils that extend downwards from the base.|$|R
40|$|Retinal visual {{fields were}} {{determined}} using an ophthalmoscopic reflex technique in two seabird {{species of the}} family Procellariidae: white-chinned petrel Procellaria aequinoctialis and antarctic prion Pachyptila desolata. The binocular fields of both species show a similar shape but they differ in size and {{in the position of}} the bill within the field. In white-chinned petrels the binocular field extends vertically through approximately 140 degrees and has a maximum width of approximately 40 degrees. The bill is placed approximately central within the field. The binocular field of the prions is approximately half this width and vertical extent, and the bill is placed close to the ventral edge. These differences in binocular field topography can be correlated with the different foraging techniques that these birds employ when seeking a similar diet within the same environment. White-chinned petrels pursue individual items both at the surface and while diving to moderate depths. Antarctic prions feed primarily by <b>filtering</b> <b>items</b> from surface waters. These differences in visual field topography mirror those found in different terrestrial bird species that primarily employ visual or tactile cues in the pursuit of food items. White-chinned petrel eyes and visual fields show features of an amphibious optical design similar to those found in penguins and albatrosses. Copyright (C) 2001 S. Karger AG. Basel...|$|R
50|$|Flamingos filter-feed on brine shrimp. Their oddly shaped beaks are {{specially}} {{adapted to}} separate mud and silt {{from the food}} they eat, and are uniquely used upside-down. The <b>filtering</b> of food <b>items</b> is assisted by hairy structures called lamellae which line the mandibles, and the large rough-surfaced tongue.|$|R
50|$|One typical problem {{caused by}} the data {{sparsity}} is the cold start problem. As collaborative <b>filtering</b> methods recommend <b>items</b> based on users' past preferences, new users will need to rate sufficient number of items to enable the system to capture their preferences accurately and thus provides reliable recommendations.|$|R
40|$|Abstract. This paper {{describes}} a commercial {{web site that}} offers tourist information about Turin and the valleys hosting the 2006 Olympic Winter Games. Since this site offers {{a large amount of}} information for foreign and nonresident users, we decided to offer adaptive suggestions in order to <b>filter</b> the <b>items</b> presented to the users and to give orientation about the localization of the presented attractions. In this initial adaptation phase we decided to generate the adaptations by applying commonsense rules related to the features of the presented items without asking any registration from the users. 1...|$|R
40|$|A {{challenge}} for preference based recommender systems is to elicit user preferences in an accurate and efficient manner. Eliciting preferences from the user {{in the form}} of a query that is then used to <b>filter</b> <b>items</b> from a database can result in a coarse recommendation with numerous results returned. The problem lies in the user’s knowledge concerning the items among which they are searching. Unless the user is a domain expert, their preferences are likely to be expressed in a vague manner and so vague results ({{in the form of}} irrelevant alternatives) are returned. On the other hand, the advent of the world wide web has delivered an abundance of data at our fingertips. Information gathered from the web, reduced to structured ontologies, can prove useful in focussing preference elicitation mechanisms. In this paper we present a preference elicitation process which allows users to communicate their preferences in a simple manner, through examples presented to them. The system then makes use of an ontology model, based on expert information and social web resources. It elicits the user’s preferences guided by this ontology in an interactive and dynamic manner. We show that this leads to more effective recommendations. We evaluate our work through empirical experiments and discuss the results in terms of preference elicitation coverage as well as the prediction accuracy of the preference model. 1...|$|R
40|$|Objective: The WHODAS-II was {{substantially}} modified {{for use in}} the World Mental Health Surveys. This article considers {{psychometric properties}} and implications of <b>filter</b> <b>items</b> used to reduce respondent burden of the modified WHODAS-II. Study Design and Setting: Seventeen surveys in 16 countries administered a modified WHODAS-II to population samples (N = 38, 934 adults). Modifications included introducing filter questions for four subscales and substituting questions on the number of days activity was limited for the Life Activities domain. We evaluated distributional properties, reliability, and validity of the modified WHODAS-II. Results: Most respondents (77 %- 99 %) had zero scores on filtered subscales. Lower bound estimates of internal consistency (alpha) for the filtered subscales were typically in the 0. 70 s, but were higher for the Global scale. Loadings of subscale scores on a Global Disability factor were moderate to high. Correlations with the Sheehan Disability Scale were modest but consistently positive, while correlations with SF- 12 Physical Component Summary were considerably higher. Cross-national variability in disability scores was observed, but was not readily explainable. Conclusions: Internal consistency and validity of the modified WHODAS-II was generally supported, but use of filter questions impaired measurement properties. Group differences in modified WHODAS-II disability scores may be compared within, but not necessarily across, countries. (C) 2008 Elsevier Inc. All rights reserved...|$|R
40|$|Bidding for {{products}} on the Internet has become a common activity in our daily life. However, it’s a tedious problem {{that there are too}} many items for the bidder to select the cheapest one. In the results providing by eBay, {{only a small number of}} results are target items. This is a common situation while the user is searching for a main product in 3 C. We aim at helping the bidder compare items easily on auction websites. In this thesis we propose CADBid, which is a web-based system built between auction websites and the bidder. CADBid is able to automatically <b>filter</b> out non-target <b>items</b> and clean the descriptions about these items. Afterward, a list is generated which helps the bidder compare these items. The list only shows the target items along with their important properties. Our work focuses on two tasks. The first task is <b>item</b> <b>filtering.</b> The second is cleaning of descriptions. After cleaning of descriptions, the clean descriptions are used to assist the first task. We view the two tasks as classification problems and propose two feature sets. We build two classification models based on Support Vector Model. Our experiment shows that cleaning of description is helpful because clean descriptions indeed improve the accuracy of <b>item</b> <b>filtering.</b> With CADBid, the bidder will be convenient while making a good decision on which item to bid...|$|R
40|$|In many surveys, {{responses}} to earlier questions determine whether later questions are asked. The probability of an affirmative re-sponse {{to a given}} item is therefore nonzero only if the participant responded affirmatively to some set of logically prior items, known as “filter items. ” In such surveys, the usual conditional indepen-dence assumption of standard item response models fails. A weaker “partial independence ” assumption may hold, however, if an indi-vidual’s {{responses to}} different items are independent conditional on the item parameters, the individual’s latent trait, and the par-ticipant’s affirmative responses to each {{of a set of}} <b>filter</b> <b>items.</b> In this paper, we propose an item response model for such “partially independent ” item response data. We model such item response patterns as a function of a person-specific latent trait and a set of item parameters. Our model {{can be seen as a}} generalized hybrid of a discrete-time hazard model and a Rasch model. The proposed procedure yields estimates of (1) person-specific, interval-scale measures of a latent trait (or traits), along with person-specific standard errors of measurement; (2) conditional and marginal The research reported here was funded by grants from the National Insti-tute of Alcohol and Alcohol Use (grant R 01 -AA 13814) and the William T. Grant Foundation. We thank Stephen Buka and Scott Novak for helpful comments and Richard Congdon for applications programming to implement the statistical meth-ods reported herein...|$|R
