271|94|Public
5|$|HipHop Virtual Machine (HHVM) {{developed}} at Facebook and available as open source, it converts PHP code into a high-level bytecode (commonly {{known as an}} intermediate language), which is then translated into x86-64 machine code dynamically at runtime by a just-in-time (<b>JIT)</b> <b>compiler,</b> resulting in up to 6× performance improvements.|$|E
25|$|Where code {{is written}} and {{executed}} at runtime—a <b>JIT</b> <b>compiler</b> is a prominent example—the compiler can potentially {{be used to}} produce exploit code (e.g. using JIT Spray) that has been flagged for execution and therefore would not be trapped.|$|E
500|$|The {{foundation}} of PHP 7 is a PHP branch that was originally dubbed PHP next generation (phpng). It was authored by Dmitry Stogov, Xinchen Hui and Nikita Popov, and aimed to optimize PHP performance by refactoring the Zend Engine {{to use more}} compact data structures with improved cache locality while retaining near-complete language compatibility. [...] , WordPress-based benchmarks, which served as the main benchmark suite for the phpng project, showed an almost 100% increase in performance. [...] Changes from phpng are also expected {{to make it easier}} to improve performance in the future, as more compact data structures and other changes are seen as better suited for a successful migration to a just-in-time (<b>JIT)</b> <b>compiler.</b> [...] Because of the significant changes, the reworked Zend Engine is called Zend Engine 3, succeeding Zend Engine 2 used in PHP 5.|$|E
50|$|Some binary optimizers utilize {{run-time}} metrics (profiling) to introspectively {{improve performance}} using techniques similar to <b>JIT</b> <b>compilers.</b>|$|R
5000|$|Allow the JVM to {{use both}} {{the client and}} server <b>JIT</b> <b>compilers</b> in the same session with a method called tiered compiling: ...|$|R
5000|$|Just-in-time (<b>JIT)</b> <b>compilers</b> can [...] "splice together" [...] pre-compiled {{sections}} of code as longer object code/machine code segments. This reduces interpret time significantly and simultaneously speeds execution.|$|R
2500|$|Sun's JVM was {{equipped}} with a <b>JIT</b> <b>compiler</b> {{for the first time}} ...|$|E
2500|$|An {{optimizing}} just-in-time (<b>JIT)</b> <b>compiler</b> named FTL {{was announced}} on May 13, 2014. It uses LLVM to generate optimized machine code. [...] "FTL" [...] stands for [...] "Fourth-Tier-LLVM", and unofficially for faster-than-light, alluding to its speed. As of February 15 2016, the backend of FTL JIT {{is replaced by}} [...] "Bare Bones Backend" [...] (or B3 for short).|$|E
2500|$|The use of {{bytecode}} as {{an intermediate}} language permits Java programs to run on any platform that has a virtual machine available. [...] The use of a <b>JIT</b> <b>compiler</b> means that Java applications, after a short delay during loading and once they have [...] "warmed up" [...] by being all or mostly JIT-compiled, tend to run about as fast as native programs.|$|E
25|$|Java's {{performance}} has improved substantially {{since the early}} versions. Performance of <b>JIT</b> <b>compilers</b> relative to native compilers has in some optimized tests {{been shown to be}} quite similar.|$|R
40|$|Abstract. For {{performance}} reasons, it {{is desirable}} for Java just-in-time (<b>JIT)</b> <b>compilers</b> to statically identify array element accesses that can never cause an out of bounds exception, but the most precise analyses are too expensive to run in <b>JIT</b> <b>compilers.</b> We present verifiable annotations that {{can be added to}} Java programs to capture the results of range analyses as claimed linear inequalities and proofs of these claims. These proofs can be efficiently verified so that array bounds checks can be safely eliminated during JIT compilation without performing expensive range analyses at runtime. ...|$|R
40|$|We {{attempt to}} apply the {{technique}} of Tracing <b>JIT</b> <b>Compilers</b> [3, 2] {{in the context of}} the PyPy project 1 [4, 1], i. e. to programs that are interpreters for some dynamic languages, including Python. Tracing <b>JIT</b> <b>compilers</b> can greatly speed up programs that spend most of their time in loops in which they take similar code paths. However, applying an unmodified tracing JIT to a program that is itself a bytecode interpreter results in very limited or no speedup. In this talk we show how to guide tracing <b>JIT</b> <b>compilers</b> to greatly improve the speed of bytecode interpreters. One crucial point is to unroll the bytecode dispatch loop, based on two hints provided by the implementer of the bytecode interpreter. The technique is already mature enough to be applied to a number of example interpreters, but also to PyPy’s full Python interpreter, giving interesting speedups. References [1] C. F. Bolz and A. Rigo. How to not write a virtual machine. In Proceedings of the 3 rd Workshop on Dynamic Languages and Applications (DYLA 2007) ...|$|R
2500|$|The {{heart of}} the Java {{platform}} {{is the concept of}} a [...] "virtual machine" [...] that executes Java bytecode programs. This bytecode is the same no matter what hardware or operating system the program is running under. There is a JIT (Just In Time) compiler within the Java Virtual Machine, or JVM. The <b>JIT</b> <b>compiler</b> translates the Java bytecode into native processor instructions at run-time and caches the native code in memory during execution.|$|E
2500|$|The Java {{platform}} {{consists of}} several programs, {{each of which}} provides a portion of its overall capabilities. [...] For example, the Java compiler, which converts Java source code into Java bytecode (an intermediate language for the JVM), is provided {{as part of the}} Java Development Kit (JDK). [...] The Java Runtime Environment (JRE), complementing the JVM with a just-in-time (<b>JIT)</b> <b>compiler,</b> converts intermediate bytecode into native machine code on the fly. The Java platform also includes an extensive set of libraries.|$|E
2500|$|J2SE 1.2 (December 8, 1998) – Codename Playground. This and {{subsequent}} releases through J2SE 5.0 were rebranded Java 2 and the version name [...] "J2SE" [...] (Java 2 Platform, Standard Edition) replaced JDK {{to distinguish the}} base platform from J2EE (Java 2 Platform, Enterprise Edition) and J2ME (Java 2 Platform, Micro Edition). Major additions included reflection, a collections framework, Java IDL (an interface description language implementation for CORBA interoperability), and {{the integration of the}} Swing graphical API into the core classes. A Java Plug-in was released, and Sun's JVM was equipped with a <b>JIT</b> <b>compiler</b> for the first time.|$|E
50|$|Just-in-time {{compilation}} is {{a technique}} to increase execution speed of programs by compiling parts of a program to machine code at runtime. One way to categorize different <b>JIT</b> <b>compilers</b> is by their compilation scope. Whereas method-based <b>JIT</b> <b>compilers</b> translate one method {{at a time to}} machine code, tracing JITs use frequently executed loops as their unit of compilation.Tracing JITs are based on the assumptions that programsspend most of their time in some loops of the program ("hot loops") and subsequent loop iterations often take similar paths. Virtual machines that have a tracing JIT are often mixed-mode execution environments, meaning that they have either an interpreter or a method compiler in addition to the tracing JIT.|$|R
40|$|We {{attempt to}} apply the {{technique}} of Tracing JIT Com-pilers {{in the context of}} the PyPy project, i. e., to programs that are interpreters for some dynamic languages, including Python. Tracing <b>JIT</b> <b>compilers</b> can greatly speed up pro-grams that spend most of their time in loops in which they take similar code paths. However, applying an unmodified tracing JIT to a program that is itself a bytecode interpreter results in very limited or no speedup. In this paper we show how to guide tracing <b>JIT</b> <b>compilers</b> to greatly improve the speed of bytecode interpreters. One crucial point is to un-roll the bytecode dispatch loop, based on two hints provided by the implementer of the bytecode interpreter. We evalu-ate our technique by applying it to two PyPy interpreters: one is a small example, and the other one is the full Python interpreter. 1...|$|R
40|$|Run-time {{specialization}} (RTS) is {{a technique}} that e#ciently generates specialized programs with respect to runtime values. For e#ciently generating specialized programs, RTS constructs compiled native code fragments called templates at compile-time, and generates a specialized program by merely copying the templates. The generated programs are, on the other hand, less e#cient, since the technique prevents many optimizations. This study proposes bytecode specialization (BCS), which generates programs in a bytecode language, and then translates the generated bytecode into native code by using Just-In-Time (<b>JIT)</b> <b>compilers.</b> The advantages of BCS are: (1) e#cient specialization processes {{that are similar to}} RTS, (2) e#cient specialized programs thanks to the optimizations of <b>JIT</b> <b>compilers,</b> and (3) independence of source-to-bytecode compilers and of bytecode-to-native compilers thanks to our proposed binding-time analysis, which directly handles bytecode programs. Thus far, we have implement [...] ...|$|R
50|$|Some platforms, {{including}} FreeBSD, NetBSD, and WinPcap, use a just-in-time (<b>JIT)</b> <b>compiler</b> {{to convert}} BPF instructions into native code {{in order to}} improve performance. Linux includes a BPF <b>JIT</b> <b>compiler</b> which is disabled by default.|$|E
50|$|OdinMonkey is {{the name}} of Mozilla's new {{optimization}} module for asm.js, an easily compilable subset of JavaScript. OdinMonkey itself is not a <b>JIT</b> <b>compiler,</b> it uses the current <b>JIT</b> <b>compiler.</b> It's included with Firefox from release 22.|$|E
5000|$|Android 7.0 Nougat {{introduced}} <b>JIT</b> <b>compiler</b> with code profiling to ART, {{which lets}} it constantly improve {{the performance of}} Android apps as they run. The <b>JIT</b> <b>compiler</b> complements ART's current Ahead of Time compiler and helps improve runtime performance.|$|E
40|$|Code-reuse {{attacks are}} {{notoriously}} hard to defeat, and many current {{solutions to the}} problem focus on automated software diversity. This is a promising area of research, as diversity attacks one cause of code reuse attacks—the software monoculture. Software diversity raises the costs of an attack by providing users with different variations of the same program. However, modern software diversity implementations are still vulnerable to certain threats: code disclosure attacks and attacks targeted at <b>JIT</b> (just-in-time) <b>compilers</b> for dynamically compiled languages. In this dissertation, we address the pressing problem of building secure systems out of programs written in unsafe languages. Specifically, we use software diversity to present attackers with an unpredictable attack surface. This dissertation contributes new techniques that improve the security, efficiency, and coverage of software diversity. We discuss three practical aspects of software diversity deployment: (i) performance optimization using profile guided code randomization, (ii) transparent code randomization for <b>JIT</b> <b>compilers,</b> and (iii) code hiding support for <b>JIT</b> <b>compilers.</b> We make the following contributions: we show a generic technique to reduce the runtime cost of software diversity, describe the first technique that diversifies the output of <b>JIT</b> <b>compilers</b> and requires no source code changes to the JIT engine, and contribute new techniques to prevent disclosure of diversified code. Specifically, we demonstrate how to switch between execute-only and read-write page permissions to efficiently and comprehensively prevent JIT-oriented exploits. Our in-depth performance and security evaluation shows that software diversity can be efficiently implemented with low overhead (as low as 1 % for profile-guided NOP insertion and 7. 8 % for JIT code hiding) and is an effective defense against a large class of code reuse and code disclosure attacks...|$|R
5000|$|All {{objects are}} {{allocated}} on the heap. For functions using small objects, this {{can result in}} performance degradation and heap fragmentation, while stack allocation, in contrast, costs essentially zero. However, modern <b>JIT</b> <b>compilers</b> mitigate this problem to some extent with escape analysis or escape detection to allocate objects on the stack, since Oracle JDK 6.|$|R
50|$|Tracing {{just-in-time}} compilation is {{a technique}} used by virtual machines to optimize the execution of a program at runtime. This is done by recording a linear sequence of frequently executed operations, compiling them to native machine code and executing them. This is opposed to traditional just-in-time (<b>JIT)</b> <b>compilers</b> that work on a per-method basis.|$|R
50|$|Portable.NET uses SSA in its <b>JIT</b> <b>compiler.</b>|$|E
50|$|Mono uses SSA in its <b>JIT</b> <b>compiler</b> called Mini.|$|E
50|$|Android's Dalvik {{virtual machine}} uses SSA in its <b>JIT</b> <b>compiler.</b>|$|E
40|$|Just-In-Time (<b>JIT)</b> <b>compilers</b> {{interact}} with the Java Virtual Machine (JVM) at run time and compile appropriate bytecode sequences into native machine code. Loading and compilation time penalties are incurred at run time. However, the lack of need for lengthy translations yields benefits if methods are reused. In this paper, we provide a quantitative characterization of the execution behavior of the SPEC JVM 98 programs, in interpreter mode and using <b>JIT</b> <b>compilers.</b> There {{has not been an}} effort to study the interaction of the JIT compilation mode of java execution with architectural features. Such a study is important for the development and improvement of better compilers and virtual machines for executing Java. In our study we observe that the interpreter exhibits better instruction and data cache locality. We also observe differences in branch characteristics for the different modes of execution. Keywords: Just-in-Time Compilers, Java Language, SPEC JVM 98, Program Analysis, Cache Perfor [...] ...|$|R
40|$|Array-based {{languages}} such as MATLAB and Python (with NumPy) {{have become}} very popular for scientific computing. However, {{the performance of the}} implementations of these languages is often lacking. For example, some of the implementations are interpreted. Further, these languages were not designed with multi-core CPUs and GPUs in mind and thus don’t take full advantage of modern hardware. Thus, developing just-in-time (<b>JIT)</b> <b>compilers</b> for these languages that allow scientific programmers to efficiently target both CPUs and GPUs is of increasing interest. However building such compilers requires considerable effort. Prior to this thesis, there were no reusable compiler toolkits for array-based languages even though many of the compilation challenges are similar across languages. This thesis is about a set of two novel and reusable tools, Velociraptor and RaijinCL, that simplify the work of building <b>JIT</b> <b>compilers</b> for array-based languages targeting both CPUs and GPUs. Velociraptor is a reusable, embeddable dynamic compiler toolkit while RaijinCL is an auto-tuning high-performance matrix operations library...|$|R
5000|$|Safety {{guarantees}} {{come at a}} run-time cost. For example, the compiler {{is required}} to put appropriate range checks in the code. Guarding each array access with a range check is not efficient, so most <b>JIT</b> <b>compilers</b> will try to eliminate them statically or by moving them out of inner loops (although most native compilers for C++ {{will do the same}} when range-checks are optionally used).|$|R
50|$|The {{verifier}} permits {{only some}} bytecode sequences in valid programs, e.g. a jump (branch) instruction can only target an instruction {{within the same}} method. Furthermore, the verifier ensures that any given instruction operates on a fixed stack location, allowing the <b>JIT</b> <b>compiler</b> to transform stack accesses into fixed register accesses. Because of this, that the JVM is a stack architecture does not imply a speed penalty for emulation on register-based architectures when using a <b>JIT</b> <b>compiler.</b> In {{the face of the}} code-verified JVM architecture, it makes no difference to a <b>JIT</b> <b>compiler</b> whether it gets named imaginary registers or imaginary stack positions that must be allocated to the target architecture's registers. In fact, code verification makes the JVM different from a classic stack architecture, of which efficient emulation with a <b>JIT</b> <b>compiler</b> is more complicated and typically carried out by a slower interpreter.|$|E
50|$|PyPy uses {{a linear}} SSA {{representation}} for traces in its <b>JIT</b> <b>compiler.</b>|$|E
5000|$|Sun's JVM was {{equipped}} with a <b>JIT</b> <b>compiler</b> {{for the first time}} ...|$|E
5000|$|These {{arbitrary}} values {{can thus}} be designed with efficiency in mind - by selecting values {{that can be used}} as direct indexes to data or function pointers. For particular platforms/language, they can be specifically designed to minimize instruction path lengths using branch table values or even, in some cases such as in <b>JIT</b> <b>compilers,</b> consist of directly executable machine code [...] "snippets" [...] (or pointers to them).|$|R
40|$|This article {{starts with}} a short {{introduction}} of modern control networks and surveys severe problems, one faces when porting a Java Virtual Machine (JVM) to embedded components. Some possible solutions for those problems are presented, special purpose VMs, just-in-time (<b>JIT)</b> <b>compilers</b> {{or the use of}} compiled byte-code are evaluated. Finally, we assess a potential solution regarding a new approach for a Java embedded network that is currently under research and implemented in a future project...|$|R
40|$|For network {{computing}} on desktop machines, fast execution of Java bytecode programs is essential because these machines {{are expected to}} run substantial application programs written in Java. Higher Java performance {{can be achieved by}} Just-in-Time (<b>JIT)</b> <b>compilers</b> which translate the stack-based bytecode into registerbased machine code on demand. One crucial problem in Java JIT compilation is how to map and allocate stack entries and local variables into registers efficiently and quickly, so as to improve the Java performance...|$|R
