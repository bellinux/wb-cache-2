7|10000|Public
50|$|Because {{a funnel}} is {{automatically}} dropped when a thread blocks, {{care must be}} taken to ensure that synchronized resources are acquired again after any blocking operation. Specifically, acquiring a funnel can be a blocking operation, so if multiple funnels are needed, they must be acquired at once. This limits the utility of funnels because it increases the <b>granularity</b> <b>of</b> <b>locking</b> when multiple funnels need to be held at once.|$|E
40|$|Speculation is a {{well-known}} means of increasing parallelism among concurrent methods that are usually but not always independent. Traditional nonblocking data structures employ a particularly restrictive form of speculation. Software transactional memory (STM) systems employ a much more general—though typically blocking—form, {{and there is a}} wealth of options in between. We explore data-structure-specific speculation as a design pattern for concurrent data structures. Using several different structures as examples, we consider issues of safety (sandboxing), validation mechanism, and <b>granularity</b> <b>of</b> <b>locking.</b> We note that it can sometimes be useful to perform validation and locking at different granularities. Through experiments on UltraSPARC and x 86 platforms, we demonstrate that MSpec can lead to highly efficient algorithms, particularly in methods with a significant search component. ...|$|E
40|$|The size of {{main memory}} is {{becoming}} larger. With {{the number of}} Central Processing Unit (CPU) cores ever increasing in modern systems, with each of them being able to access memory, the organization of memory becomes more important. In multicore systems, {{there are two main}} architectures for memory organization with respect to the cores - Symmetric Multi-Processor (SMP) and Non-Uniform Memory Architecture (NUMA). Prior work has focused on the improvement of the performance of B-Trees in highly concurrent and distributed environments, as well as in memory, for shared-memory mul- tiprocessors. However, little focus has been given to the performance of main memory B-Trees for NUMA systems. This work focuses on improving the performance of B-Trees contained in main memory of NUMA systems by introducing modifications that consider its storage in the physically distributed main memory of the NUMA system. The work in this thesis makes the following contributions {{to the development of a}} distributed B-Tree, specifically in a NUMA environment, modified from a B-Tree originally designed for high concurrency: • It introduces replication of internal nodes of the tree and shows how this can improve its overall performance in a NUMA environment. • It introduces NUMA-aware locking procedures with the aim of managing contention and exploiting locality of lock requests with reference to previous client operation request locations. • It introduces changes in the <b>granularity</b> <b>of</b> <b>locking,</b> starting from the original locking of every node to the locking of certain levels of nodes, showing the tradeoff between the <b>granularity</b> <b>of</b> <b>locking</b> and the performance of the tree based on the workload. • It considers the combination of the different techniques, with the aim of finding the combination which performs well overall for varying read-heavy workloads and number of client threads...|$|E
40|$|This paper {{presents}} two queueing network models Which {{correspond to}} different implementations <b>of</b> the <b>lock</b> management algorithm for concurrent trans-action processing in a database system. These mo-dels are developed {{to investigate the}} effects <b>of</b> varying the <b>granularity</b> <b>of</b> <b>locks</b> {{and the degree of}} multiprogramming on the performance of a database system. A numerical example is presented for a set of apparently realistic parameters and its re-sults are discussed. In addition to other conclu-sions, these results also confirm the result of Ries and Stonebraker, using a simulation model [91, that a relatively coarse granularity is suf-ficient to allow enough parallelism for efficient resource utilization. In contrast with simulation models, the queueing network models presented in this paper allow us to examine more closely the cause-effect relationships of concurrent transac-tion processing in a database system at less cost. 1...|$|R
50|$|To prevent this, {{threading}} application programming interfaces (APIs) offer synchronization primitives such as mutexes to lock data structures against concurrent access. On uniprocessor systems, {{a thread}} running into a locked mutex must sleep and hence trigger a context switch. On multi-processor systems, the thread may instead poll the mutex in a spinlock. Both of these may sap performance and force processors in symmetric multiprocessing (SMP) systems to contend for the memory bus, {{especially if the}} <b>granularity</b> <b>of</b> the <b>locking</b> is fine.|$|R
40|$|In this paper, we {{describe}} recent work {{in developing a}} peer-to-peer collaborative environment. The study examines various locking mechanisms/policies by adjusting the <b>granularity</b> <b>of</b> the <b>locked</b> space within the shared document. Additionally, as the interface is highly dependent upon user input/interaction rather than CPU computation, the communication overheads dominate the scalability analysis. Consequently, this paper examines the communication overheads associated with five different events within the system. The paper concludes {{with a discussion of}} future work in further examining various locking granularities and related work in distributed memory systems and cache coherency models...|$|R
40|$|Lock {{preemption}} is {{a common}} problem with twophase locking. While a transaction is still active, its locks may be preempted to avoid a deadlock or to satisfy the lock request of a higher-priority transaction. In general, the victim of preemption is aborted. This paper suggests that the victim could be continued and its work up to preemption could be saved if the preempted lock is restored on its availability. Object-oriented database management systems based on clientserver architecture, multidatabase systems, and relational database management systems using page-locks are a few cases where lock restoration can be beneficial. Lock restoration works well when the <b>granularity</b> <b>of</b> <b>locking</b> {{is larger than the}} granularity of database operations, namely, reads and writes. This paper proposes a correctness criteria called value-serializability for isolation in histories generated by a lock restoring concurrency control scheme. A value-serializable history is shown to have the same behavior (in t [...] ...|$|E
40|$|In {{this report}} {{we present a}} new file {{facility}} architecture where a separate interface is provided to speedup processing of transaction oriented file operations. This interface is event driven and ensures that maximum number of transaction oriented file operations are processed and supervised at a client's workstation. Furthermore, it efficiently coordinates the processing of distributed transactions and relieves a server to take the responsibility of a coordinator or worker. In order to improve the performance we provide caching of file's data in the main memory of a client's workstation and the file server. We demonstrate that our design allows the <b>granularity</b> <b>of</b> <b>locking</b> as fine as a single byte and as coarse as an entire file. Therefore we claim our design addresses the requirements {{of a wide range}} of applications. The use of intentions list in our design ensures that transaction oriented file operations are resilient against system and media failures. We further demonstrate that it [...] ...|$|E
40|$|Three {{designs of}} {{hierarchical}} locking suitable for B-tree indexes are explored in detail and their {{advantages and disadvantages}} compared. Traditional hierarchies include index, leaf page, and key range or key value. Alternatively, locks on separator keys in interior B-tree pages can protect key ranges of different sizes. Finally, for keys consisting of multiple columns, key prefixes of different sizes permit a third form of hierarchical locking. Each of these approaches requires appropriate implementation techniques. The techniques explored here include node splitting and merging, lock escalation and lock de-escalation, and online changes in the <b>granularity</b> <b>of</b> <b>locking.</b> Those techniques are the first designs permitting introduction and removal of levels in a lock hierarchy on demand and without disrupting transaction or query processing. In addition, a simplification of traditional key range locking is introduced that applies principled hierarchical locking to keys in B-tree leaves. This new method of key range locking avoids counter-intuitive lock modes used in today’s highperformance database systems. Nonetheless, it increases concurrency among operations on individual keys and records beyond that enabled by traditional lock modes. ...|$|E
40|$|XML has {{a variety}} of {{properties}} such as tree structures, doc-ument order of nodes, a tag name accompanied each node, etc. These various aspects of XML make query processing difficult, and index structures for this purpose have attracted research at-tention. On the other hand, updates and concurrency control in XML have usually been left untouched. However, the design of the index structures and its concurrency control must not be dis-cussed separately, since the index structures affect the <b>granularity</b> <b>of</b> <b>locks.</b> Naive indexing methods often cannot localize locks and lead to the loss of concurrency. In this paper, we propose a dynamic index structure that is efficient in both of updates and query processing, and to mini-mize lock regions, we also present a new locking method, called adaptive granular locking, which utilizes hyper-rectangular locks in multidimensional space. In addition, organization <b>of</b> hyper-rectangular <b>locks</b> and page-level locks into proper layers achieves dramatic reduction of deadlock states in comparison with non-layered transaction model. Xerial, an XML database system, was implemented {{on the basis of these}} techniques. Our extensive ex-perimental results confirm its great advantages in transaction pro-cessing. To our knowledge, this is the first time that the issue of concur-rency control in XML is seriously discussed with careful consid-eration of the design of the index structure. ...|$|R
40|$|Abstract This paper {{provides}} a comprehensive treatment of index management in transaction systems. We present a method, called ARIESIIM (A/gorlthm for Recovery and /so-/atIon Exploiting Semantics forlndex Management), for concurrency control and recovery of B +-trees. ARI ES/lM guarantees serializability and uses write-ahead logging for recovery. K supports very high concurrency and good performance by (1) treating as the <b>lock</b> <b>of</b> a key the same lock {{as the one}} on the corresponding record data in a data page (e. g., at the record level), (2) not acquiring, in the interest of permitting very high concurrency, commit duration locks on index pages even during index structure modification operations (SMOS) like page splits and page deletions, and (3) allowing retrievals, inserts, and deletes to go on concurrently with SMOS. During restart recovery, any necessary redos of index changes are always performed in a pageoriented fashion (i. e., without traversing the index tree) and, during normal processing and restart recovery, whenever possible undos are performed in a page-oriented fashion. ARIES/lM permits different <b>granularities</b> <b>of</b> <b>locking</b> to be supported in a flexible manner. A subset of ARIES/lM has been implemented in the 0 S/ 2 Extended Edition Database Manager. 1 Since the <b>locking</b> ideas <b>of</b> ARIES/lM have general applicability, some of them have also been implemented in SQUDS and the VM Shared File System, even though those systems use the shadow-page technique for recovery. 1...|$|R
40|$|This paper {{presents}} an active, cooperative transaction model for shared databases which supports the collaboration of users and user groups in product design. The described cooperative transaction {{model is a}} component of an active database system that potentially represents all information needed during the product development process. The rules of this active database system are used for automatic notifications of its users e. g. in conflict situations. After an interactive conflict resolution, the database system allows cooperative work among users on shared data. Collaborative work on common data is realized through an extended compatibility matrix for <b>granularity</b> <b>locking</b> <b>of</b> shared objects. First, in this paper a brief survey of shared databases and cooperative transactions for multiuser environments is given. Next, a new approach of a shared database system and its transaction model is introduced. The architecture of the database system is shown {{as well as the}} way the transaction model realizes the <b>locking</b> <b>of</b> shared objects. Additionally, the benefits of such a transaction model and the kind of cooperation supported in this way are shown. ...|$|R
40|$|Abstract This paper {{describes}} a technique for use when multiple instances of a data base management system (DBMS), {{each with its}} own cache (buffer pool), can directly read and modify any data stored on a set of shared disks. Global locking and coherency control protocols are necessary in this context for assuring transaction consistency and for maintaining coherency of the data cached in the multiple caches. The coordination amongst the systems is performed by a set of local lock managers (LLMs) and a global lock manager (GLM). This typically involves sending messages. We describe a technique, called LP locking, which saves locking calls when the <b>granularity</b> <b>of</b> <b>locking</b> by transactions is the sase as the granularity of caching by the cache manager. The savings are gained by making the LLMs hide from the GLM the distinction between a transaction lock, called the L lock, and a cache-ownership lock, called the P lock, for the same object. The L and P locks for an object, though distinct at an LLM, are known as a single lock at the GLM. An LLM can grant an L or P lock request on an object locally if the combined lock mode of the L and P locks already held on that object by that LLM is equal to or higher than the requested mode. Such optimitations save messages between the LLMs and the GLM. Our ideas apply also to the client-server environ-ment which has become very popular in the OODBMS area and to the distributed shared memory environment. 1...|$|E
50|$|Optical {{switches}} build {{by companies}} such as Sycamore and Ciena (with STS-1 <b>granularity</b> <b>of</b> switching) and Tellium (with STS-48 <b>granularity</b> <b>of</b> switching) have been deployed in operational mesh networks. Calient has built all-optical switches based on 3D MEMS technology.|$|R
30|$|Estimated at the <b>granularity</b> <b>of</b> a heartbeat.|$|R
50|$|Different XML Pipeline {{implementations}} support different <b>granularity</b> <b>of</b> flow.|$|R
40|$|Impact {{analysis}} is a specialized process of program comprehension that investigates {{the nature and}} extent of a planned software change. Traditionally, impact analysis inspects dependencies among the software components of a fixed granularity; these components constitute a dependency graph. In this paper, we argue that the single granularity is insufficient and leads to imprecise analysis. We explain how the precision can be improved by variable granularity, where the programmers choose among the <b>granularity</b> <b>of</b> classes, the <b>granularity</b> <b>of</b> class members, and the <b>granularity</b> <b>of</b> code fragments. We assess the resulting precision by a case study on open-source software. 1...|$|R
40|$|The committed-choice {{language}} Fleng can extract much parallelism easily {{even from}} irregular programs using dataflow synchronization. However, {{there is a}} large overhead because the <b>granularity</b> <b>of</b> execution is very fine. If <b>granularity</b> <b>of</b> a program is coarsened, such an overhead can be reduced. This can be attained by fusing several goals into one goal, but this may cause deadlock. In this paper, we propose a safe goal fusion algorithm that statically optimizes <b>granularity</b> <b>of</b> a Fleng program. We implemented the algorithm and evaluated it on a parallel computer PIE 64. The evaluation shows that enough speedup can be attained by this method. 1 Introduction Committed-choice languages can extract much parallelism easily even from programs with irregular parallelism such as symbolic computation. This is achieved by single assignment variable and dataflow synchronization. However, the <b>granularity</b> <b>of</b> execution is so fine that overheads of parallel execution, such as context switching, synchro [...] ...|$|R
40|$|in {{terms of}} proliferation, {{increase}} {{in size and}} <b>granularity</b> <b>of</b> keratinocytes, from primary|$|R
5000|$|Determine {{the lowest}} level (<b>granularity)</b> <b>of</b> summary in a fact table (e.g. sales dollars).|$|R
50|$|A {{higher degree}} <b>of</b> <b>granularity</b> is {{achieved}} if each individual account {{may be taken}} by a clerk. This would allow any customer to be serviced without waiting for another customer who is accessing a different account. This is analogous to a record level lock and is normally the highest degree <b>of</b> <b>locking</b> <b>granularity</b> in a database management system.|$|R
50|$|Szabo influentially {{argued that}} a minimum <b>granularity</b> <b>of</b> micropayments is set by mental {{transaction}} costs.|$|R
5000|$|Timestamp <b>granularity</b> <b>of</b> 10 ms for Create and Modified times (but not {{as fine as}} NTFS's 0.1 ms).|$|R
40|$|This paper proposes and evaluates new {{synchronization}} {{schemes for}} a simultaneous multithreaded processor. We present a scalable mechanism that permits threads to cheaply synchronize within the processor, with blocked threads consuming no processor resources. We also introduce the concept <b>of</b> <b>lock</b> release prediction, which gains an additional improvement of 40 %. Overall, {{we show that}} these improvements in synchronization cost enable parallelization of code {{that could not be}} effectively parallelized using traditional techniques. 1. Introduction The performance of a multiprocessor's synchronization mechanisms determine the <b>granularity</b> <b>of</b> parallelism that can be exploited on that machine. Synchronization on a conventional multiprocessor carries a high cost due to the hardware levels at which synchronization and communication must occur (e. g., main memory). As a result, compilers and programmers must decompose parallel applications in a coarse-grained way in order to reduce synchronization [...] ...|$|R
40|$|Self-adjusting {{computation}} (SAC) {{provides an}} evaluation model where computations can respond automatically to modifications to their data {{by using a}} mechanism for propagating modifications through the computation. Current approaches to self-adjusting computation guarantee correctness by recording dependencies in a trace at the <b>granularity</b> <b>of</b> individual memory operations. Tracing at the <b>granularity</b> <b>of</b> memory operations, however, has some limitations: it can be asymptotically inefficient (e. g., compared to optimal solutions) because it cannot take advantage of problem-specific structure, it requires keeping a large computation trace (often proportional to the runtime of the program on the current input), and it introduces moderately large constant factors in practice. In this paper, we extend dependence-tracing {{to work at the}} <b>granularity</b> <b>of</b> the query and update operations of arbitrary (abstract...|$|R
50|$|Provia 400X RXP used what Fujifilm {{described}} as Epitaxial Sigma Crystal (ESC) technology {{to achieve a}} <b>granularity</b> <b>of</b> RMS11.|$|R
5000|$|For {{procedural}} programming, the <b>granularity</b> <b>of</b> {{the code}} is largely {{determined by the}} number of discrete procedures or modules.|$|R
5000|$|If G-bit is zero limit has a <b>granularity</b> <b>of</b> 1 byte, i.e. segment size may be 1, 2, ..., 220 bytes.|$|R
40|$|Generally speaking, digital {{libraries}} have multiple <b>granularities</b> <b>of</b> semantic units: book, chapter, page, paragraph and word. However, {{there are two}} limitations of current eBook retrieval systems: (1) the <b>granularity</b> <b>of</b> retrievable units is either too big or too small, scales such as chapters, paragraphs are ignored; (2) the retrieval results should be grouped by facets to facilitate user’s browsing and exploration. To overcome these limitations, we propose a multi-granularity multi-facet eBook retrieval approach...|$|R
3000|$|..., to {{calculate}} the available bandwidth accurately without depending on the coarse clock <b>granularity</b> <b>of</b> TCP. So, TCP TIBET has an [...]...|$|R
40|$|Abstract — To {{support service}} {{guarantees}} in packetswitched networks, three approaches {{have been proposed}} and studied in the literature. They are the Stateless Core (SCORE) approach, the Integrated Services (IntServ) approach, and the Differentiated Services (DiffServ) approach. The <b>granularities</b> <b>of</b> service guarantees provided by these approaches at each router are respectively packet level, flow level, and class level. I n this paper, we propose a novel approach, called Link-Based Fair Aggregation (LBFA) approach to scalable support of service guarantees. While the <b>granularity</b> <b>of</b> service guarantees supported by LBFA is link level at each router, we show through analysis that the proposed LBFA approach can achieve as good as or even better per-flow service guarantees than the current three approaches. Keywords — Per-flow service guarantees, Link based fair aggregation (LBFA), <b>Granularity</b> <b>of</b> service guarantees I...|$|R
3000|$|... r The {{worst case}} (i.e. No Traffic) {{is not present}} so that a finer <b>granularity</b> <b>of</b> the {{presented}} simulations can be shown.|$|R
30|$|Hierarchy aspects: {{the aspect}} {{extraction}} technique {{described in the}} “Extracting aspects through hierarchy clustering” section, using the topic <b>granularity</b> <b>of</b> [2, 7].|$|R
50|$|Theoretically, {{coherence}} can {{be performed}} at the load/store granularity. However, in practice it is generally performed at the <b>granularity</b> <b>of</b> cache blocks.|$|R
40|$|Granularity is an {{integral}} feature of temporal data. For instance, a person's age is commonly given to the <b>granularity</b> <b>of</b> years {{and the time of}} their next airline flight to the <b>granularity</b> <b>of</b> minutes. A <b>granularity</b> creates a discrete image, in terms of granules, of a (possibly continuous) time-line. Pairs <b>of</b> <b>granularities</b> are related in that some granularities are finer or coarser with respect to other granularities. A granularity graph records all the relationships between granularities, even among granularities in different calendars. Indeterminacy, or "don't know when" information, is a companion to granularity. A birthday, given to the <b>granularity</b> <b>of</b> days, does not reveal precisely when a person was born, only that they were born sometime during the indicated day. Temporal granularity and indeterminacy are {{two sides of the same}} coin, in that a time at a given granularity is indeterminate at all finer granularities. We present a formal model for granularity in temporal operations. [...] ...|$|R
40|$|In {{this paper}} we propose a {{framework}} of verb semantic description in order to organize different <b>granularity</b> <b>of</b> similar-ity between verbs. Since verb mean-ings highly depend on their arguments we propose a verb thesaurus on the ba-sis of possible shared meanings with predicate-argument structure. Motiva-tions of this work are to (1) construct a practical lexicon for dealing with alter-nations, paraphrases and entailment re-lations between predicates, and (2) pro-vide a basic database for statistical learn-ing system as well as a theoretical lex-icon study such as Generative Lexicon and Lexical Conceptual Structure. One of the characteristics of our description is that we assume several <b>granularities</b> <b>of</b> semantic classes to characterize verb meanings. The thesaurus form allows us to provide several <b>granularities</b> <b>of</b> shared meanings; thus, this gives us a further re-vision for applying more detailed analy-ses of verb meanings. ...|$|R
