1215|127|Public
25|$|On April 2, 1994, the {{factorization}} of RSA-129 {{was completed}} using QS. It was a 129-digit number, {{the product of}} two large primes, one of 64 digits and the other of 65. The factor base for this factorization contained 524339 primes. The data collection phase took 5000 MIPS-years, done in <b>distributed</b> <b>fashion</b> over the Internet. The data collected totaled 2GB. The data processing phase took 45 hours on Bellcore's (now Telcordia Technologies) MasPar (massively parallel) supercomputer. This was the largest published factorization by a general-purpose algorithm, until NFS was used to factor RSA-130, completed April 10, 1996. All RSA numbers factored since then have been factored using NFS.|$|E
25|$|An {{accounting}} of the energy utilized during a thermodynamic process, known as an energy balance, {{can be applied to}} automotive fuels. With today's technology, the manufacture of hydrogen via steam reforming can be accomplished with a thermal efficiency of 75 to 80percent. Additional energy will be required to liquefy or compress the hydrogen, and to transport it to the filling station via truck or pipeline. The energy that must be utilized per kilogram to produce, transport and deliver hydrogen (i.e., its well-to-tank energy use) is approximately 50MJ using technology available in 2004. Subtracting this energy from the enthalpy of one kilogram of hydrogen, which is 141MJ, and dividing by the enthalpy, yields a thermal energy efficiency of roughly 60%. Gasoline, by comparison, requires less energy input, per gallon, at the refinery, and comparatively little energy is required to transport it and store it owing to its high energy density per gallon at ambient temperatures. Well-to-tank, the supply chain for gasoline is roughly 80% efficient (Wang, 2002). Another grid-based method of supplying hydrogen would be to use electrical to run electrolysers. Roughly 6% of electricity is lost during transmission along power lines, and the process of converting the fossil fuel to electricity in the first place is roughly 33 percent efficient. Thus if efficiency is the key determinant it would be unlikely hydrogen vehicles would be fueled by such a method, and indeed viewed this way, electric vehicles would appear to be a better choice. However, as noted above, hydrogen can be produced from a number of feedstocks, in centralized or <b>distributed</b> <b>fashion,</b> and these afford more efficient pathways to produce and distribute the fuel.|$|E
2500|$|The {{existence}} of pure strategy Nash equilibrium is guaranteed in potential games, and multiple Nash equilibria may exist. Learning algorithms such as [...] "best response" [...] and [...] "better response" [...] can only {{guarantee that the}} iterative learning process can converge {{to one of the}} Nash equilibria (if multiple). Equilibrium selective learning algorithms aim to design a strategy where convergence to the best Nash equilibrium, with respect to the potential function, is guaranteed. In, the authors propose an equilibrium selective algorithm named MaxLogit, which provably converges to the best Nash equilibrium at the fastest speed in its class, using mixing rate analysis of induced Markovian chains. In a special case where every player shares the same objective function (hence the potential function), and possibly the same action set, the problem is equivalent to distributed combinatorial optimization which arises in many engineering applications. Equilibrium selective learning algorithms such as MaxLogit can be used in such combinatorial optimizations, even in a <b>distributed</b> <b>fashion.</b>|$|E
50|$|In 2013, Shai co-founded EAST 39th, a Men'swear {{clothing}} branch {{based in}} Sweden. The brand designs, markets, and <b>distributes</b> men <b>fashion</b> apparel across Scandinavia.|$|R
50|$|The company's main fashion house {{focuses on}} and <b>distributes</b> {{ready-to-wear}} outerwear, <b>fashion</b> accessories, fragrances, sunglasses, and cosmetics.|$|R
50|$|The Vlisco Group designs, {{produces}} and <b>distributes</b> <b>fashion</b> fabrics for the West and Central African {{market and}} African consumers in global metropolitan cities. Founded in Helmond, The Netherlands, in 1846, the Vlisco Group and their fabrics have grown into {{an essential part}} of African culture, receiving widespread attention from the art, design and fashion worlds. Vlisco Group's brand portfolio consists of four brands: Vlisco, Woodin, Uniwax and GTP. The company's head office, as well as the design and production facilities for the Vlisco brand, are located in Helmond. For the other brands these facilities are based in Ghana and Ivory Coast. The Vlisco Group has eight sales offices in numerous African countries and around 2,700 employees, (900 in The Netherlands and 1800 in Africa).|$|R
50|$|Another {{implementation}} of Reo is {{developed in the}} Scala programming language and executes circuits in a <b>distributed</b> <b>fashion.</b>|$|E
50|$|Decision support activities---including the {{development}} of assessments and other tools and information to support adaptation and mitigation decision making---are coordinated in a <b>distributed</b> <b>fashion</b> across the program and {{are part of the}} mandate of all IWGs and the Subcommittee on Global Change Research.|$|E
50|$|Clusterpoint {{database}} is a document-oriented {{database server}} platform for {{storage and processing}} of XML and JSON data in a <b>distributed</b> <b>fashion</b> on large clusters of commodity hardware. Database architecture blends ACID-compliant OLTP transactions, full-text search and analytics in the same code, delivering high availability, fault-tolerance, data replication and security.|$|E
50|$|The Journey is the Destination: the Ryan McGinley Purple Book. Paris: Purple Institute, 2013. Originally <b>distributed</b> with Purple <b>Fashion</b> issue 19.|$|R
5000|$|EVER Manifesto {{is a free}} print {{publication}} that [...] "aims to inspire positive transformations in how we live by generating sustainable solutions for both work and play that are aimed at protecting our planet for future generations". It is <b>distributed</b> at <b>fashion</b> shows and selected stores as well as published in PDF on its website.|$|R
40|$|Abstract—In this paper, {{we study}} data {{gathering}} with compressive sensing {{from the perspective}} of in-network computation in random networks, in which n nodes are uniformly and independently deployed in a unit square area. We formulate the problem of data gathering to compute multiround random linear function. We study the performance of in-network computation with compressive sensing in terms of energy consumption and latency in centralized and <b>distributed</b> <b>fashions.</b> For the centralized approach, we propose a tree-based protocol for computing multiround random linear function. The complexity of computation shows that the proposed protocol can save energy and reduce latency by a factor of Θ (√ n / log n) for data gathering comparing with the traditional approach, respectively. For the distributed approach, we propose a gossip-based approach and study the performance of energy and latency through theoretical analysis. We show that our approach needs fewer transmissions than the scheme using randomized gossip. I...|$|R
50|$|Cognitive radio technology, {{also known}} as smart radio. This allows {{different}} radio technologies to share the same spectrum efficiently by adaptively finding unused spectrum and adapting the transmission scheme {{to the requirements of}} the technologies currently sharing the spectrum. This dynamic radio resource management is achieved in a <b>distributed</b> <b>fashion</b> and relies on software-defined radio. See also the IEEE 802.22 standard for Wireless Regional Area Networks.|$|E
50|$|A {{change of}} {{value of the}} input point results in {{a change in the}} set of {{activated}} hyper-rectangles, and therefore a change in the set of memory cells participating in the CMAC output. The CMAC output is therefore stored in a <b>distributed</b> <b>fashion,</b> such that the output corresponding to any point in input space is derived from the value stored in a number of memory cells (hence the name associative memory). This provides generalisation.|$|E
50|$|In SPB as {{with other}} link state based protocols, the {{computations}} are done in a <b>distributed</b> <b>fashion.</b> Each node computes the Ethernet compliant forwarding behavior independently based on a normally synchronized common view of the network (at scales of about 1000 nodes or less) and the service attachment points (user network interface (UNI) ports). Ethernet filtering Database (or forwarding) tables are populated locally to independently and deterministically implement its portion of the network forwarding behavior.|$|E
40|$|Humans {{represent}} perceptual {{events in}} a <b>distributed,</b> feature-specific <b>fashion,</b> which called {{for some sort of}} feature integration. It has been suggested that processing an event leads {{to the creation of a}} temporary binding of the corresponding feature codes—an object file. Here we show that object files do not only comprise of perceptual feature codes but also include codes that reflect evaluations of the perceptual event...|$|R
50|$|Viewed as an {{information}} processing system, the natural immune system of organisms performs many complex tasks in parallel and <b>distributed</b> computing <b>fashion.</b> These include distinguishing {{between self and}} nonself, neutralization of nonself pathogens (viruses, bacteria, fungi, and parasites), learning, memory, associative retrieval, self-regulation, and fault-tolerance. Artificial immune systems are abstractions of the natural immune system, emphasizing these computational aspects. Their applications include computer virus detection, anomaly detection in a time series of data, fault diagnosis, pattern recognition, machine learning, bioinformatics, optimization, robotics and control.|$|R
40|$|The {{amount of}} {{completely}} sequenced chloroplast genomes increases rapidly every day, {{leading to the}} possibility to build large-scale phylogenetic trees of plant species. Considering a subset of close plant species defined according to their chloroplasts, the phylogenetic tree that can be inferred by their core genes is not necessarily well supported, due to the possible occurrence of problematic genes (i. e., homoplasy, incomplete lineage sorting, horizontal gene transfers, etc.) which may blur the phylogenetic signal. However, a trustworthy phylogenetic tree can still be obtained provided such a number of blurring genes is reduced. The problem is thus to determine the largest subset of core genes that produces the best-supported tree. To discard problematic genes and due to the overwhelming number of possible combinations, {{this article focuses on}} how to extract the largest subset of sequences in order to obtain the most supported species tree. Due to computational complexity, a distributed Binary Particle Swarm Optimization (BPSO) is proposed in sequential and <b>distributed</b> <b>fashions.</b> Obtained results from both versions of the BPSO are compared with those computed using an hybrid approach embedding both genetic algorithms and statistical tests. The proposal has been applied to different cases of plant families, leading to encouraging results for these families...|$|R
5000|$|Because this {{distributed}} knowledge, while incomplete, {{is essential}} to economic planning, its necessity is cited as {{evidence in support of}} the argument that economic planning must be performed in a similarly <b>distributed</b> <b>fashion</b> by individual actors. In other words, economic planning by a central actor (e.g. a government bureaucracy or a central bank) necessarily lacks this information because, as Hayek observed, statistical aggregates cannot accurately account for the universe of local knowledge: ...|$|E
50|$|Spreader {{plates are}} thin steel plates with holes {{through which the}} arbor {{connecting}} rods pass. Spreader plates are lowered onto the counterweights in a <b>distributed</b> <b>fashion</b> as the counterweight stack is being built. Typically one spreader plate is placed on top of every two feet of counterweight in the stack. Finally, a locking plate is lowered onto the completed, interleaved stack of counterweights and spreader plates and secured in place with a thumbscrew.|$|E
5000|$|Therefore, {{the panel}} {{majority}} said, [...] "this claim entails an unconventional technological solution (enhancing {{data in a}} <b>distributed</b> <b>fashion)</b> to a technological problem (massive record flows which previously required massive databases)." [...] Even though the claims use generic components, [...] "the claim's enhancing limitation necessarily requires that these generic components operate in an unconventional manner to achieve an improvement in computer functionality." [...] Accordingly, the panel majority reversed the district court judgment of patent ineligibility under § 101 for the '065 patent.|$|E
40|$|This paper {{presents}} an Internet-Based Logistics Management System to coordinate and disseminate tasks and related information for solving the heterogeneous {{vehicle routing problem}} using appropriate metaheuristic techniques, for use in enterprise chain networks. Its architecture involves a JAVA Web applet equipped with interactive communication capabilities between peripheral software tools. The system was developed in <b>distributed</b> software <b>fashion</b> technology for all computer platforms utilizing a Web browser, focusing on the detailed road network of Athens {{and the needs of}} the Athens Central Food Market enterprises. (c) 2004 Elsevier Ltd. All rights reserved...|$|R
40|$|In this paper, we {{introduce}} linear and nonlinear consensus protocols for {{networks of}} dynamic agents {{that allow the}} agents to agree in a <b>distributed</b> and cooperative <b>fashion.</b> We consider the cases of networks with communication time-delays and channels that have ltering eects. We nd a tight upper bound on the maximum xed time-delay that can be tolerated in the network...|$|R
40|$|This work studies optimal {{flow control}} of a micro grid {{consisting}} of households equipped with μ-CHP devices and gas and heat buffers. Agricultural wastes from households are used to produce biogas by a biogas generator. The produced biogas is, then, utilized to fulfill local demand of heat {{and power of the}} households. Excess biogas can be upgraded and sold to the low pressure gas grid. Excess electricity produced by the μ- CHPs of households can be also sold to the electricity grid. The aim of the control process is to maximize the estimated profit of the households while avoiding overloading gas and electricity grids and avoiding the biogas shortage. The decisions on the supply and consumption levels are done in both centralized and <b>distributed</b> <b>fashions</b> using model predictive control (MPC). The distributed MPC (dMPC) is developed from the centralized MPC (cMPC) by employing dual decomposition method combined with the projected sub-gradient method. In dMPC, each household makes decisions based on its local information, yet still needs to coordinate its supply and consumption bids to the grid operators and the biogas generator. The coordinations are formulated for synchronous and asynchronous implementations. With the distributed scheme, the grid operators and the biogas producer can manage households’ supply and consumption levels via dynamic pricing to obey the grid capacity constraints. We perform extensive simulations to investigate the behavior of dynamic pricing modified by the grid operators and the biogas generator. Furthermore, we provide numerical results to compare the performance of cMPC, synchronous dMPC, and asynchronous dMPC using realistic estimates of the selling prices and demand patterns...|$|R
50|$|Rendezvous hashing {{was invented}} in 1996 by David Thaler and Chinya Ravishankar at the University of Michigan. Consistent hashing {{appears to have been}} devised around the same time at MIT. One of the first {{applications}} of rendezvous hashing was to enable multicast clients on the Internet (in contexts such as the MBONE) to identify multicast rendezvous points in a <b>distributed</b> <b>fashion.</b> It was used in 1998 by Microsoft's Cache Array Routing Protocol (CARP) for distributed cache coordination and routing. Some Protocol Independent Multicast routing protocols use rendezvous hashing to pick a rendezvous point.|$|E
50|$|On April 2, 1994, the {{factorization}} of RSA-129 {{was completed}} using QS. It was a 129-digit number, {{the product of}} two large primes, one of 64 digits and the other of 65. The factor base for this factorization contained 524339 primes. The data collection phase took 5000 MIPS-years, done in <b>distributed</b> <b>fashion</b> over the Internet. The data collected totaled 2GB. The data processing phase took 45 hours on Bellcore's (now Telcordia Technologies) MasPar (massively parallel) supercomputer. This was the largest published factorization by a general-purpose algorithm, until NFS was used to factor RSA-130, completed April 10, 1996. All RSA numbers factored since then have been factored using NFS.|$|E
5000|$|Sun {{decided to}} keep their team {{together}} and instead explore a system on the leading edge. In addition to combining Unix flavours, the new system would {{also be able to}} run just about any other system as well, and do so in a <b>distributed</b> <b>fashion.</b> The system was first running in a [...] "complete" [...] fashion in 1993, and produced a series of research papers. In 1994 a [...] "research quality" [...] release was made under a non-commercial license, but it is unclear how widely this was used. The team broke up and moved to other projects within Sun, using some of the Spring concepts on a variety of other projects.|$|E
40|$|This paper motivates and {{illustrates}} {{a new approach}} to providing computer support for participative modelling of processes, and for modelling participative processes. This approach relies upon constructing computer-based artefacts that serve an explanatory role. The construction of such artefacts proceeds in a <b>distributed</b> and incremental <b>fashion</b> in association with the development of a working understanding amongst the participants engaged in process comprehension and design...|$|R
40|$|International audienceIn this work, we {{introduce}} {{a framework for}} designing autonomic information diffusion mechanisms in intermittently connected wireless networks. Our approach {{is based on the}} use of techniques and tools drawn from evolutionary computing research, which enable to embed evolutionary features in epidemic-style forwarding mechanisms. In this way, it is possible to build a system in which information dissemination strategies change at runtime to adapt to the current network conditions in a <b>distributed</b> autonomic <b>fashion.</b> A case study is then introduced, for which design and implementation choices are presented and discussed. Simulation results are reported to validate the ability of the proposed protocol to converge to the optimal operating point (or close to it) in unknown and changing environments...|$|R
40|$|Distributed {{multimedia}} applications have quality-of-service (QoS) requirements {{specified in}} terms of constraints on various metrics such as bandwidth and delay. The task of QoS routing {{is to find a}} path from the source node to the destination node with sucient resources to support the required end-to-end QoS. We propose several distributed algorithms for the bandwidth-constrained routing and the delay constrained routing. The algorithms are presented in the form of distributed recursive computation (DRC). DRC computes the global routing state in a <b>distributed,</b> recursive <b>fashion</b> and often leaves useful information at intermediate nodes during the process. An information-reuse scheme is studied to utilize such information {{in order to reduce the}} overall overhead. Our simulation shows that the overhead of the proposed algorithms is modest and stable...|$|R
5000|$|A {{parallel}} database system {{seeks to}} improve performance through parallelization of various operations, such as loading data, building indexes and evaluating queries. Although data may be stored in a <b>distributed</b> <b>fashion,</b> the distribution is governed solely by performance considerations. Parallel databases improve processing and input/output speeds by using multiple CPUs and disks in parallel. Centralized and client-server database systems are not powerful enough to handle such applications. In parallel processing, many operations are performed simultaneously, as opposed to serial processing, in which the computational steps are performed sequentially. Parallel databases can be roughly divided into two groups, {{the first group of}} architecture is the multiprocessor architecture, the alternatives of which are the following: ...|$|E
50|$|To create {{factorial}} codes, Horace Barlow {{and co-workers}} suggested {{to minimize the}} sum of the bit entropies of the code components of binary codes (1989). Jürgen Schmidhuber (1992) re-formulated the problem in terms of predictors and binary feature detectors, each receiving the raw data as an input. For each detector there is a predictor that sees the other detectors and learns to predict the output of its own detector in response to the various input vectors or images. But each detector uses a machine learning algorithm to become as unpredictable as possible. The global optimum of this objective function corresponds to a factorial code represented in a <b>distributed</b> <b>fashion</b> across the outputs of the feature detectors.|$|E
5000|$|Robots are {{mechanical}} systems that drive automation and perform chores {{that would seem}} difficult for man. Efforts {{have been made to}} co-ordinate and control a group of robots to undertake collaborative work to complete a task. Centralized control is often based on a [...] "star" [...] approach, where robots take turns to talk to the controller station. However, with wireless ad hoc networks, robots can form a communication network on-the-fly, i.e., robots can now [...] "talk" [...] to each other and collaborate in a <b>distributed</b> <b>fashion.</b> With a network of robots, the robots can communicate among themselves, share local information, and distributively decide how to resolve a task in the most effectiveand efficient way.|$|E
40|$|We {{introduce}} new efficient techniques for sharing cryptographic functions in a <b>distributed</b> dynamic <b>fashion.</b> These techniques dynamically and securely transform a distributed function (or secret sharing) representation between t-out-of-l (polynomial sharing) and t-out-of-t (additive sharing). We call the techniques poly-to-sum and sum-to-poly, respectively. Employing these techniques, we solve {{a number of}} open problems {{in the area of}} cryptographic function sharing. We design a threshold function sharing scheme with proactive security for general functions with a "homomorphic property" (a class which includes all RSA variants and Discrete Logarithm variants). The sharing has "optimal resilience" (server redundancy) and enables computation of the function by the servers assuring high availability, security and efficiency. Proactive security enables function sharing among servers while tolerating an adversary which is mobile and which dynamically corrupts and abandons servers (and perha [...] ...|$|R
40|$|Abstract In this work, we {{introduce}} {{a framework for}} designing autonomic information diffusion mechanisms in intermittently connected wireless networks. Our approach {{is based on the}} use of techniques and tools drawn from evolutionary computing research, which enable to embed evolutionary features in epidemic-style forwarding mechanisms. In this way, it is possible to build a system in which information dissemination strategies change at run-time to adapt to the current network conditions in a <b>distributed</b> autonomic <b>fashion.</b> A case study is then introduced, for which design and implementation choices are presented and discussed. Simulation results are reported to validate the ability of the proposed protocol to converge to the optimal operating point (or close to it) in unknown and changing environments. Key words: evolving protocols, evolutionary computation, genetic algorithms, wireless networks...|$|R
40|$|We {{devise a}} cross-layer design (CLD) of carrier sensing {{multiple}} access with collision avoidance (CSMA/CA) at the {{medium access control}} (MAC) layer with spectrum sensing (SpSe) at the physical layer for cognitive radio networks (CRNs). The proposed CLD relies on a Markov chain model with a state pair containing both the SpSe and the CSMA/CA with exponential backoff from which we derive the transmission and collision probabilities. Due to the 2 -dimensions of CSMA/CA model with exponential backoff, the resulted Markov chain is obtained with 3 -dimensions. Simulation and numerical results are derived and illustrated highlighting the impact of SpSe in CSMA/CA with exponential backoff. The obtained results {{could be used as}} performance criteria to evaluate the performance of specific CRNs when they are deployed in a <b>distributed</b> coordination <b>fashion</b> that is prone to collisions...|$|R
