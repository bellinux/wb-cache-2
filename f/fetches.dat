1197|10000|Public
5|$|Because this {{blend of}} crude oil is heavy and highly acidic, it <b>fetches</b> lower prices than {{benchmark}} crudes such as Brent or Minas.|$|E
5|$|He {{eventually}} accepts that {{he loves}} Uma and would marry her, breaking his vow. Knowing the truth, Uma forgives Hari and agrees to the proposal. Hari <b>fetches</b> Mangala sutra but finds out that Uma is dead. He realises that Uma has sacrificed her life for his love where {{she did not want}} Hari to break his vow.|$|E
5|$|Locke {{finds the}} polar bear's cave and rescues Eko from the polar bear. While Charlie <b>fetches</b> {{water from a}} stream, Locke apologizes to an {{unconscious}} Eko for his lack of faith. Eko appears to briefly awaken and tells Locke that he must rescue Jack, Kate and Sawyer. Upon arriving at camp, Hurley informs the camp that Jack and the others have been captured. As an explanation, Locke announces to the survivors {{that he plans to}} rescue Jack, Kate, and Sawyer, as Desmond indicated to Hurley earlier. Hurley mentions to Charlie a sense of déjà vu.|$|E
40|$|Simultaneous Multithreading (SMT) is an {{architectural}} technique {{that allows for}} the parallel execution of several threads simultaneously. <b>Fetch</b> performance {{has been identified as}} the most important bottleneck for SMT processors. The commonly adopted solution has been <b>fetching</b> from more than one thread each cycle. Recent studies have proposed a plethora of <b>fetch</b> policies to deal with <b>fetch</b> priority among threads, trying to increase <b>fetch</b> performance. In this paper we demonstrate that the simultaneous sharing of the <b>fetch</b> unit, apart from increasing the complexity of the <b>fetch</b> unit, can be counterproductive in terms of performance. We evaluate the use of high-performance <b>fetch</b> units in the context of SMT. Our new <b>fetch</b> architecture proposal allows us to feed an 8 -way processor <b>fetching</b> from a single thread each cycle, reducing complexity, and increasing the usefulness of proposed <b>fetch</b> policies. Our results show that using new high-performance <b>fetch</b> units, like the FTB or the stream <b>fetch,</b> provides higher performance than <b>fetching</b> from two threads using common SMT <b>fetch</b> architectures. Furthermore, our results show that our design obtains better average performance for any kind of workloads (both ILP and memory bounded benchmarks), in contrast to previously proposed solutions. 1...|$|R
40|$|Simultaneous Multithreading (SMT) is a {{technique}} that permits multiple threads to execute in parallel within a single processor. Usually, an SMT processor uses shared instruction queues to collect instructions from the different threads. Hence, an SMT processor's performance depends on how the instruction <b>fetch</b> unit fills these instruction queues. On each cycle the <b>fetch</b> unit must judiciously decide which threads to <b>fetch</b> instructions from. This paper proposes a new instruction <b>fetch</b> scheme that uses both <b>fetch</b> prioritizing and <b>fetch</b> gating for SMT processors. <b>Fetch</b> prioritizing sets up <b>fetch</b> priority for each thread {{based on the number}} of unresolved low-confidence branches from the thread, while <b>fetch</b> gating prevents <b>fetching</b> from a thread once it has a stipulated number of outstanding low-confidence branches. Based on the <b>fetch</b> priority of each thread, our <b>fetch</b> scheme finds threads that are most likely to be in their correct paths. This improves the overall throughput of an SMT processor by reducing the number of wrong-path instructions in the pipeline. Our experimental evaluation shows that, on the average, our <b>fetch</b> scheme provides 14. 9 % speedup over ICOUNT, which is the best <b>fetch</b> policy reported so far for SMT...|$|R
5000|$|... read {{instruction}} and decode it <b>fetch</b> these 10 numbers <b>fetch</b> those 10 numbers <b>fetch</b> another 10 numbers add and multiply them put the results here ...|$|R
5|$|Malcolm {{leaves the}} table {{only to return}} furious; Archie was lying. A heated debate ensues, and the four men wrestle over the bill until Anya tells them that the meal can be free. Malcolm insists {{it is not about}} the bill, and <b>fetches</b> a knife and {{chopping}} board. Archie and Malcolm are to play stabscotch, with the winner paying. Malcolm is quick but Archie is slower, repeatedly stabbing himself. Craig pulls the knife from Archie, inadvertently slashing Anya. She collapses as blood splatters. Anya is dead, and Malcolm formulates a story blaming Archie, but Archie has called a prison contact who will remove the body.|$|E
5|$|One {{month before}} the final task, Harry and Krum are talking when they {{encounter}} Crouch, who appears to have gone insane, but manages to tell Harry to get Dumbledore. Leaving Krum with Crouch, Harry <b>fetches</b> Dumbledore but returns to find Krum stunned and Crouch gone. Harry returns to preparing for the final task, a hedge maze. Inside the maze, Harry is forced to incapacitate Krum, who has been bewitched, to save Cedric. Working together, the two reach the cup. They agree to touch {{it at the same}} time, and doing so, discover that it is a Portkey that transports them to a graveyard. There, Peter Pettigrew kills Cedric and uses Harry's blood (along with his own hand and Tom Riddle Sr.'s bone) to resurrect Lord Voldemort.|$|E
5|$|From the {{apartment}} {{he shares with}} his hypochondriac mother Winifred, Seymour <b>fetches</b> his odd-looking, potted plant, but Mushnick is unimpressed by its sickly, drooping look. However, when Fouch suggests that Audrey Jr.'s uniqueness might attract {{people from all over the}} world to see it, Mushnick gives Seymour one week to revive it. Seymour has already discovered that the usual kinds of plant food do not nourish his strange hybrid and that every night at sunset the plant's leaves open up. When Seymour accidentally pricks his finger on another thorny plant, Audrey Jr. opens wider, eventually causing Seymour to discover that the plant craves blood. After that, each night Seymour nurses his creation with blood from his fingers. Although he feels increasingly listless, Audrey Jr. begins to grow and the shop's revenues increase due to the curious customers who are lured in to see the plant.|$|E
5000|$|Least Recently <b>Fetched</b> (LRF) - In this policy, warp {{for which}} {{instruction}} {{has not been}} <b>fetched</b> {{for the longest time}} gets priority in the <b>fetching</b> of an instruction.|$|R
40|$|Abstract: Instruction <b>fetch</b> {{mechanism}} is a performance bottleneck of a Superscalar Processor. <b>Fetch</b> performance {{can be improved}} {{with the aid of}} an instruction memory known as a Trace Cache. This paper presents analytical expressions, which describe instruction <b>fetch</b> performance of a Trace Cache microarchitecture. The instruction <b>fetch</b> rates predicted by the expressions differ by seven percent from the simulated <b>fetch</b> rates on the average. Keywords: Processor, Microarchitecture, Cache. 1...|$|R
40|$|This paper {{presents}} a coarse-grained reconfigurable instruction set processor for low power multimedia applications. The processor main feature is a scalable <b>fetch</b> architecture specially adapted for multimedia and DSP applications, {{and based on}} a VLIW processor. The <b>fetch</b> architecture is divided in two <b>fetch</b> engines: a main engine used for <b>fetching</b> the control code and a reconfigurable engine used for <b>fetching</b> the code for highly parallel loops. 1...|$|R
5|$|The main {{factor in}} the {{continued}} decline of the Javan rhinoceros population has been poaching for horns, a problem that affects all rhino species. The horns have been a traded commodity for more than 2,000 years in China, where they {{are believed to have}} healing properties. Historically, the rhinoceros' hide was used to make armor for Chinese soldiers, and some local tribes in Vietnam believed the hide could be used to make an antidote for snake venom. Because the rhinoceros' range encompasses many areas of poverty, it has been difficult to convince local people not to kill a seemingly (otherwise) useless animal which could be sold for a large sum of money. When the Convention on International Trade in Endangered Species of Wild Fauna and Flora first went into effect in 1975, the Javan rhinoceros was placed under complete Appendix 1 protection; all international trade in the Javan rhinoceros and products derived from it is illegal. Surveys of the rhinoceros horn black market have determined that Asian rhinoceros horn <b>fetches</b> a price as high as $30,000 per kg, three times the value of African rhinoceros horn.|$|E
5|$|Anya closes a {{restaurant}} where four men—northerners Archie, Malcolm and Kevin are entertaining southerner Craig—have finished a post-badminton meal. After a misunderstanding between Craig and the thickly accented Anya, Malcolm takes the bill, {{but he and}} Archie both wish to pay. Craig insists that he will pay, as he is leaving, and wealthier than the others. The three argue, with Archie unable to pay as the card machine lacks paper. Malcolm suggests that the bill should be split three ways, with the northerners treating Craig, but Kevin {{claims to be the}} poorest. Archie, Malcolm and Craig thrust cards at Anya until Kevin offers to pay. He counts cash as Anya <b>fetches</b> drinks. Craig thanks the others for making his trip bearable, and offers to pay, restarting the argument. This becomes about Malcolm's position as badminton-club secretary, with Malcolm revealing that Archie has spent time in prison. Anya arrives with drinks, and Craig, paying the bill, speaks of craving excitement, only to have his card declined. He phones his au pair for a card, keen she not look in the wrong drawer, but Malcolm snatches the phone. He is about to pay, but Archie stops him. He reveals that he wanted to pay as he has an inoperable brain tumour.|$|E
25|$|Some {{architectures}} (including ARM versions 3 and above, PowerPC, Alpha, SPARC V9, MIPS, PA-RISC, SuperH SH-4 and IA-64) {{feature a}} setting {{which allows for}} switchable endianness in data <b>fetches</b> and stores, instruction <b>fetches,</b> or both. This feature can improve performance or simplify the logic of networking devices and software. The word bi-endian, when said of hardware, denotes the capability of the machine to compute or pass data in either endian format.|$|E
40|$|This work {{proposes a}} new <b>fetch</b> unit model, {{inspired}} in the trace processor [8]. Instead of <b>fetching</b> instruction traces, our <b>fetch</b> unit will <b>fetch</b> instruction streams. An instruction stream is a sequential run of instructions, dened by the starting address and the stream length. All branches {{included in the}} stream {{are assumed to be}} not taken, except for the terminating one, which should be always taken (else, we are terminating the stream prematurely). We will show how stream <b>fetching</b> approaches the four factors determining instruction <b>fetch</b> performance: the width of instructions <b>fetched</b> per cycle, instruction cache misses, branch prediction throughput and branch prediction accuracy. 1 <b>Fetch</b> performance 1. 1 Width of instruction <b>fetch</b> All instructions in a stream are consecutive in memory, and a stream contains no taken branches. This makes it very simple to obtain several consecutive instruction cache lines from a multi-banked cache, and simply select the desired instruction [...] ...|$|R
50|$|Wider superscalar {{processors}} demand multiple {{instructions to}} be <b>fetched</b> {{in a single}} cycle for higher performance. Instructions to be <b>fetched</b> are not always in contiguous memory locations (basic blocks) because of branch and jump instructions. So processors need additional logic and hardware support to <b>fetch</b> and align such instructions from non-contiguous basic blocks. If multiple branches are predicted as not-taken, then processors can <b>fetch</b> instructions from multiple contiguous basic blocks in a single cycle. However, {{if any of the}} branches is predicted as taken, then processor should <b>fetch</b> instructions from the taken path in that same cycle. This limits the <b>fetch</b> capability of a processor.Consider these four basic blocks (A, B, C, D) as shown in the figure that correspond to a simple if-else loop. These blocks will be stored contiguously as ABCD in the memory. If the branch D is predicted not-taken, the <b>fetch</b> unit can <b>fetch</b> the basic blocks A,B,C which are placed contiguously. However, if D is predicted taken, the <b>fetch</b> unit has to <b>fetch</b> A,B,D which are non-contiguously placed. Hence, <b>fetching</b> these blocks which are non contiguously places, in a single cycle will be very difficult. So, in situations like these trace cache comes in aid to the processor.|$|R
50|$|<b>Fetching</b> {{complete}} pre-decoded instructions {{eliminates the}} need to repeatedly decode variable length complex instructions into simpler fixed-length micro-operations, and simplifies the process of predicting, <b>fetching,</b> rotating and aligning <b>fetched</b> instructions. A uop cache effectively offloads the <b>fetch</b> and decode hardware, thus decreasing power consumption and improving the frontend supply of decoded micro-operations. The uop cache also increases performance by more consistently delivering decoded micro-operations to the backend and eliminating various bottlenecks in the CPU's <b>fetch</b> and decode logic.|$|R
25|$|I like {{my girls}} from ten to sixteen—allowing of 17 or 18 {{as long as}} they’re {{not in love with}} anybody but me.—I’ve got some darlings of 8—12—14—just now, and my Pigwiggina here—12—who <b>fetches</b> my wood and is {{learning}} to play my bells.|$|E
25|$|The bluestripe snapper is {{commonly}} taken throughout its range by handlines, traps, and gill nets. It is usually marketed fresh, and {{is common in}} the markets of many countries. It {{is one of the}} principal species in the Hawaiian handline fishery, but as noted above, it <b>fetches</b> low prices at market.|$|E
25|$|Mabinogi has {{a variety}} of in-game books. Mabinogi <b>fetches</b> the {{contents}} of books you read over the Web using HTTP from mabibook.nexon.net. Using a program like WireShark (with a filter like 'http contains GET') or tcpdump can capture the HTTP requests sent when you read a book in the game.|$|E
5000|$|Little way, <b>fetch</b> pigsack. 'went {{not too far}} to <b>fetch</b> the pigs.' ...|$|R
60|$|It might <b>fetch</b> {{a hundred}} pounds--it might <b>fetch</b> {{a hundred and}} fifty.|$|R
5000|$|<b>Fetch</b> Standard, which [...] "defines requests, responses, and {{the process}} that binds them: fetching.". The <b>fetch</b> {{standard}} defines the 'fetch' JavaScript API, and supersedes the HTML5 <b>fetch</b> functionality, CORS and the HTTP Origin header semantics.|$|R
25|$|The {{species is}} of minor {{importance}} to local fisheries throughout its range, and is also considered a good game fish, especially in larger sizes. The species is rarely targeted by anglers though, due to its comparative rarity. The fish also <b>fetches</b> high prices at market, unlike many {{other members of the}} Carangidae.|$|E
25|$|The fairy {{magic was}} {{represented}} by circus tricks. For example, the fairies entered on trapeze bars, and the love potion that Puck <b>fetches</b> was a spinning plate on a rod, which Puck handed to Theseus from a trapeze fifteen feet above the stage. When Bottom turned into an ass, he acquired not the traditional ass's head, but a clown's red nose.|$|E
25|$|The {{functionality}} of the Mini mode {{is somewhat}} {{different from a}} conventional Web browser, {{with the amount of}} data which has to be transferred much reduced, but with some loss to functionality. Unlike straightforward web browsers, Opera Mini <b>fetches</b> all content through a proxy server, renders it using the Presto layout engine, and reformats web pages into a format more suitable for small screens.|$|E
5000|$|<b>Fetch</b> (standard) - defines requests, responses, and {{the process}} that binds them: <b>fetching.</b>|$|R
40|$|Wind <b>fetch</b> is the {{unobstructed}} {{length of}} water over which wind can blow {{from a certain}} direction. Averaging the wind <b>fetch</b> for numerous directions at the same location is therefore a reasonable measure of the overall wind exposure for a specific marine location. However, this process of calculating wind <b>fetch</b> can be extremely time-consuming and tedious, particularly if {{a large number of}} <b>fetch</b> vectors are required at many locations. The fetchR package calculates wind <b>fetch</b> with ease and summarises the information efficiently. There are also plot methods to help visualise the wind exposure at the various locations, and methods to output the <b>fetch</b> vectors to a KML file for further investigation...|$|R
40|$|Scalability is {{important}} in superscalar processors design. A superscalar processor {{is said to be}} linearly scalable if with linear increase in load or demand, performance remains constant relative to linear increase in resources. In this paper, for evaluating the instruction <b>fetching</b> scalability, an analytical model of a superscalar processor is proposed by defining the <b>fetch</b> unit as the “producer ” of instructions and the execution unit as the “consumer. ” The scalability of the <b>fetch</b> unit relative to its branch predictor – the Bi-Mode Predictor – is then evaluated using SPEC 2000 suite of benchmarks. Our simulation results strongly suggest that reducing branch misprediction penalty is a better alternative solution – compared with increasing prediction accuracy – for improving instruction <b>fetch</b> scalability. 1. Summary and future work In this paper, we composed an analytical model for evaluating instruction <b>fetching</b> scalability relative to branch prediction accuracy. For this purpose, we decoupled the <b>fetch</b> and execution engines using the model proposed in [1] and assumed the instruction cache to be totally perfect and based the <b>fetch</b> engine performance only on branch prediction accuracy. We defined the performance of the <b>fetch</b> unit as the number of instructions it produces in each cycle based on the prediction it makes for control instructions. However, this performance is dependent on the execution unit which informs the <b>fetch</b> unit of the resolved outcomes of branch instructions and keeps it on the correct execution path. To assess the scalability of the <b>fetch</b> unit, we proposed an analytical <b>fetching</b> model and developed formulas for measuring the <b>fetch</b> performance. Our formulas dictated two factors are necessary for evaluating the <b>fetch</b> engine performance...|$|R
25|$|All apartments on {{the west}} side of the {{building}} above the seventh floor overlook Central Park and the Reservoir, over the top of the adjacent William Starr Miller House. This is a highly desirable feature for a condominium in the city and one which <b>fetches</b> a substantial premium. This side of the structure was extensively reworked, with large windows and balconies on some apartments.|$|E
25|$|Recent Intel x86 and x86-64 {{architecture}} CPUs have a MOVBE instruction (Intel Core since generation 4, after Atom), which <b>fetches</b> a big-endian format {{word from}} memory or writes a word into memory in big-endian format. These processors are otherwise thoroughly little-endian. They also {{already had a}} range of swap instructions to reverse the byte order {{of the contents of}} registers, such as when words have already been fetched from memory locations where they were in the 'wrong' endianness.|$|E
25|$|When Mother Courage is {{trading in}} the Protestant city of Halle, Kattrin {{is left with}} a peasant family in the {{countryside}} overnight. As Catholic soldiers force the peasants to guide the army to the city for a sneak attack, Kattrin <b>fetches</b> a drum from the cart and beats it, waking the townspeople, but is herself shot. Early in the morning, Mother Courage sings a lullaby to her daughter's corpse, has the peasants bury it, and hitches herself to the cart.|$|E
40|$|Abstract—Instruction <b>fetching</b> is {{critical}} to the performance of a superscalar microprocessor. We develop a mathematical model for three different cache techniques and evaluate its performance both in theory and in simulation using the SPEC 95 suite of benchmarks. In all the techniques, the <b>fetching</b> performance is dramatically lower than ideal expectations. To help remedy the situation, we also evaluate its performance using prefetching. Nevertheless, <b>fetching</b> performance is fundamentally limited by control transfers. To solve this problem, we introduce a new <b>fetching</b> mechanism called a dual branch target buffer. The dual branch target buffer enables <b>fetching</b> performance to leap beyond the limitation imposed by conventional methods and achieve a high instruction <b>fetching</b> rate. Index Terms—Computer architecture, instruction <b>fetching,</b> superscalar microprocessor, performance analysis, branch target buffer. ————————— — F —————————...|$|R
30|$|To {{access the}} {{contents}} stored at local caches, the content <b>fetching</b> delay, i.e., the time duration required for searching the contents in the cache should be considered. In general, content <b>fetching</b> delay may {{vary depending on}} the types of storage devices, the underlying file searching mechanisms, and the amount of caching contents. Referring to [20], we model the content <b>fetching</b> delay as an exponentially distributed random variable and denote D_ijk^ca as the average content <b>fetching</b> delay required when UE j <b>fetching</b> file k from GAP i.|$|R
5000|$|Fair (FAIR) - In this policy, the {{scheduler}} {{makes sure}} all warps are given ‘fair’ {{opportunity in the}} number of instruction <b>fetched</b> for them. It <b>fetched</b> instruction to a warp for which minimum number of instructions have been <b>fetched.</b>|$|R
