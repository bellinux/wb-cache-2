73|392|Public
2500|$|State register: A special <b>Instruction</b> <b>Register</b> [...] "IR", finite and {{separate}} from the registers above, stores the current instruction to be executed and its address in the TABLE of instructions; this register and its TABLE {{is located in the}} finite state machine.|$|E
2500|$|But {{this does}} {{not solve the problem}} (unless one resorts to Gödel numbers). What is {{necessary}} is a method to fetch the address of a program instruction that lies (far) [...] "beyond/above" [...] the upper bound of the finite state machine's <b>instruction</b> <b>register</b> and TABLE.|$|E
2500|$|The IR {{is not the}} [...] "program counter" [...] (PC) of the RASP (or {{conventional}} computer). The PC is {{just another}} register similar to an accumulator, but dedicated to holding {{the number of the}} RASP's current register-based instruction. Thus a RASP has two [...] "instruction/program" [...] registers—(i) the IR (finite state machine's <b>Instruction</b> <b>Register),</b> and (ii) a PC (Program Counter) for the program located in the registers. (As well as a register dedicated to [...] "the PC", a RASP may dedicate another register to [...] "the Program-Instruction Register" [...] (going by any number of names such as [...] "PIR, [...] "IR", [...] "PR", etc.) ...|$|E
50|$|The machine {{instructions}} can {{be grouped}} into six categories: accumulator instructions, branch instructions, memory reference <b>instructions,</b> address <b>register</b> <b>instructions,</b> scratchpad <b>register</b> <b>instruction,</b> miscellaneous instructions (interrupt, input, output, indirect scratchpad register, load, and store).|$|R
40|$|Base {{register}} with immediate offset [Rn, #+/-] memory_address = Rn +/- offset 12 Rn is unchanged after <b>instruction</b> Base <b>register</b> with register offset [Rn, +/-] memory_address = Rn +/- Rm Rn is unchanged after <b>instruction</b> Base <b>register</b> with shifted register offset [Rn, +/-, #] memory_address = Rn +/- shifted_Rm Rn is unchanged after <b>instruction</b> Base <b>register</b> with immediate offset, pre-indexed [Rn, #+/-]! memory_address = Rn +/- offset 12 Rn = memory_address after <b>instruction</b> Base <b>register</b> with register offset, pre-indexed [Rn, +/-]! memory_address = Rn +/- Rm Rn = memory_address after <b>instruction</b> Base <b>register</b> with shifted register offset, pre-indexed [Rn, +/-, #]! memory_address = Rn +/- shifted_Rm Rn = memory_address after <b>instruction</b> Base <b>register</b> with immediate offset, post-indexed [Rn], #+/- memory_address = Rn Rn = Rn +/- offset 12 after <b>instruction</b> Base <b>register</b> with register offset, post-indexed [Rn], +/- memory_address = Rn Rn = Rn +/- Rm after <b>instruction</b> Base <b>register</b> with shifted register offset, post-indexe...|$|R
40|$|Abstract — We {{present an}} {{efficient}} programmable architecture for compute-intensive embedded applications. The processor architecture uses <b>instruction</b> <b>registers</b> {{to reduce the}} cost of delivering instructions, and a hierarchical and distributed data register organization to deliver data. <b>Instruction</b> <b>registers</b> capture <b>instruction</b> reuse and locality in inexpensive storage structures that are located near to the functional units. The data register organization captures reuse and locality in different levels of the hierarchy {{to reduce the cost}} of delivering data. Exposed communication resources eliminate pipeline registers and control logic, and allow the compiler to schedule efficient instruction and data movement. The architecture keeps a significant fraction of instruction and data bandwidth local to the functional units, which reduces the cost of supplying instructions and data to large numbers of functional units. This architecture achieves an energy efficiency that is 23 × greater than an embedded RISC processor. Index Terms — energy-efficient embedded processor architecture, <b>instruction</b> <b>registers,</b> hierarchical and distributed register organization I...|$|R
2500|$|In the {{following}} we are {{assuming that the}} <b>Instruction</b> <b>Register</b> (IR) encounters the μy [...] "routine" [...] at instruction number [...] "n". Its first action will be to establish a number in a dedicated [...] "w" [...] register—an [...] "example of" [...] the number that function φ( [...] x, y [...] ) must produce before the algorithm can terminate (classically this is the number zero, but see the footnote {{about the use of}} numbers other than zero). The algorithm's next action at instructiton [...] "n+1" [...] will be to clear the [...] "y" [...] register -- [...] "y" [...] will act as an [...] "up-counter" [...] that starts from 0. Then at instruction [...] "n+2" [...] the algorithm evaluates its function φ( [...] x, y [...] ) -- we assume this takes j instructions to accomplish—and {{at the end of its}} evaluation φ( [...] x, y [...] ) deposits its output in register [...] "φ". At the n+j+3rd instruction the algorithm compares the number in the [...] "w" [...] register (e.g. 0) to the number in the [...] "φ" [...] register—if they are the same the algorithm has succeeded and it escapes through exit; otherwise it increments the contents of the [...] "y" [...] register and loops back with this new y-value to test function φ( [...] x, y [...] ) again.|$|E
5000|$|SIR: (Scan <b>Instruction</b> <b>Register)</b> Performs an IEEE 1149.1 <b>Instruction</b> <b>Register</b> scan.|$|E
50|$|Clocking {{changes on}} TMS steps through a {{standardized}} JTAG state machine. The JTAG state machine can reset, access an <b>instruction</b> <b>register,</b> or access data {{selected by the}} <b>instruction</b> <b>register.</b>|$|E
40|$|This paper {{describes}} a novel processor architecture, called hyperscalar processor architecture, which encompasses {{the advantages of}} superscalar, VLIW, and vector processor architectures and excludes their disadvantages. In brief hyperscalar is a processor, i) whose instruction size and instruction-fetch bandwidth {{are the same as}} those of superscalar, ii) whose datapath is as large as that of VLIW, iii) which provides every independent functional unit with one or more compiler-visible <b>registers,</b> called <b>instruction</b> <b>registers,</b> and iv) which allows the program itself to load the <b>instruction</b> <b>registers</b> with <b>instructions</b> fetched from the memory and to execute them as a subroutine. As compiler techniques for creating an object code placed in the <b>instruction</b> <b>registers,</b> this paper proposes pseudo vector processing and software pipelining, and further discusses several issues on applying software pipeling to hyperscalar processors. This paper evaluates the performance attainable in hyperscalar processors, and then concludes that hyperscalar processors can outperform conventional superscalar, VLIW, and vector processors in terms of cost/performance...|$|R
50|$|DLX {{instructions}} can {{be broken}} down into three types, R-type, I-type and J-type. R-type <b>instructions</b> are pure <b>register</b> <b>instructions,</b> with three <b>register</b> references contained in the 32-bit word. I-type <b>instructions</b> specify two <b>registers,</b> and use 16 bits to hold an immediate value. Finally J-type instructions are jumps, containing a 26-bit address.|$|R
50|$|Control UnitControl unit {{contains}} a program counter and <b>instruction</b> <b>registers.</b> It fetches <b>instructions</b> and facilitates program flow. It supports single-operand instruction set {{and works with}} all 16 index registers of the arithmetic unit.|$|R
5000|$|<b>Instruction</b> <b>register,</b> {{holding the}} {{instruction}} currently being executed.|$|E
50|$|<b>Instruction</b> <b>Register</b> - The <b>{{instruction}}</b> <b>register</b> {{holds the}} instruction {{to be executed}} by the computer. This instruction defines {{the type of operation}} to be performed such as add, subtract, etc.; specifies the location address of the operand when necessary and indicates the sector address of the next instruction.|$|E
5000|$|In computing, an <b>{{instruction}}</b> <b>register</b> (IR) is {{the part}} of a CPU's control unit that holds the instruction currently being executed or decoded. In simple processors each instruction to be executed is loaded into the <b>instruction</b> <b>register</b> which holds it while it is decoded, prepared and ultimately executed, which can take several steps.|$|E
50|$|A common idiom {{involves}} shifting BYPASS {{into the}} <b>instruction</b> <b>registers</b> of all TAPs except one, which receives some other instruction. That way all TAPs except one expose a single bit data register, and values can be selectively shifted into {{or out of}} that one TAP's data register without affecting any other TAP.|$|R
50|$|Some of the {{complicated}} processors use a pipeline of <b>instruction</b> <b>registers</b> where {{each stage of}} the pipeline does part of the decoding, preparation or execution and then passes {{it to the next}} stage for its step. Modern processors can even do some of the steps out of order as decoding on several instructions is done in parallel.|$|R
5000|$|RISC — {{arithmetic}} <b>instructions</b> use <b>registers</b> only, so explicit 2-operand load/store {{instructions are}} needed: ...|$|R
5000|$|A {{fraction}} of a second later, the CPU copies the data from the MDR to the <b>instruction</b> <b>register</b> (IR) ...|$|E
5000|$|HIR: (Header <b>Instruction</b> <b>Register)</b> Specifies a header {{pattern that}} is {{prepended}} {{to the beginning}} of subsequent IR scan operations.|$|E
5000|$|TIR: (Trailer <b>Instruction</b> <b>Register)</b> Specifies {{a trailer}} pattern that is {{appended}} {{to the end}} of subsequent IR scan operations.|$|E
40|$|The rotary {{pipeline}} processor {{is a new}} architecture for superscalar computing. It {{is based on a}} simple and regular pipeline structure which can support several ALUs for efficient dispatching of multiple <b>instructions.</b> <b>Register</b> values flow around a rotary pipeline, constrained by local data dependencies. During normal operation the control circuits are not on the critical path and performance is only limited by data rates. The architecture is particularly well suited to implementation using self-timed logic. ...|$|R
30|$|In the {{analyzing}} stage, analysts try {{to determine}} the location and root cause of captured violations. The analysis is often processed {{with the help of}} debuggers, like GDB, windbg, or other binary analysis tools, like IDA Pro, OllyDbg, etc. Binary instrumentation tools, like Pin (Luk et al. 2005), could also be used to monitor the exact execution state of collected testcases, such as the thread information, <b>instructions,</b> <b>register</b> information and so on. Automatically crash analysis is another important field of research.|$|R
50|$|Execution begins during stage {{five for}} all <b>instructions.</b> The <b>register</b> files are read during stage four. The {{pipelines}} beginning at stage five cannot be stalled.|$|R
5000|$|Decode the {{instruction}}: During {{this cycle}} the encoded instruction {{present in the}} IR (<b>instruction</b> <b>register)</b> is interpreted by the decoder.|$|E
50|$|The {{control unit}} interprets and {{processes}} all machine functions {{and consists of}} a location counter, the <b>instruction</b> <b>register,</b> and the phase register.|$|E
50|$|In the {{instruction}} cycle, {{the instruction}} is {{loaded into the}} <b>Instruction</b> <b>register</b> after the processor fetches it from the memory location pointed by the program counter.|$|E
5000|$|X# {{can work}} with three {{low-level}} data structures: the registers, the stack and the memory, on different ports. The registers are the base of all normal operations for X#. A register can be copied to another by writing [...] as opposed to [...] or load/store <b>instructions.</b> <b>Registers</b> can be incremented or decremented just as easily. Arithmetic operations (add, subtract, multiply, divide) are written as [...] where [...] is a constant, variable, or register, and [...] is both an operand and the location where the result is stored.|$|R
5000|$|... <b>Instruction</b> Transfer <b>Register</b> (ITR), 33 bits (32 {{instruction}} {{plus one}} status bit) used to execute processor instructions {{while in a}} special [...] "Debug Mode" [...] (see below) ...|$|R
25|$|X# {{can work}} with three {{low-level}} data structures: the registers, the stack and the memory, on different ports. The registers are the base of all normal operations for X#. A register can be copied to another by writing DST = SRC as opposed to mov or load/store <b>instructions.</b> <b>Registers</b> can be incremented or decremented just as easily. Arithmetic operations (add, subtract, multiply, divide) are written as dest op src where src is a constant, variable, or register, and dest is both an operand and the location where the result is stored.|$|R
50|$|Decoding the op-code in the <b>instruction</b> <b>register</b> {{includes}} {{determining the}} instruction, determining where its operands are in memory, retrieving the operands from memory, allocating processor resources {{to execute the}} command (in superscalar processors), etc.|$|E
50|$|Each {{digital signal}} (pin or ball) {{on the package}} is defined, as are the {{registers}} and opcodes used in an IEEE 1149.1, IEEE 1149.6, IEEE 1149.8.1, IEEE 1532 and IEEE 1149.4 compliant IC. There is one <b>instruction</b> <b>register,</b> a minimum of a 1-bit bypass register, one boundary scan register and optionally a 32 bit device_id register. The registers other than the <b>instruction</b> <b>register</b> are called TDRs or Test Data Registers. The boundary scan register (BSR) is unique {{as it is the}} register which is also mapped to the I/O of the device. Many of the BSDL definitions are sets of single long string constants.|$|E
50|$|The {{front panel}} had three rows of red LEDs, {{displaying}} {{the contents of}} the accumulator, <b>instruction</b> <b>register,</b> and program counter (PC). A group of twenty switches and buttons were used to read or modify any selected register.|$|E
40|$|Architectural {{features}} such as pipelines, <b>instructions</b> that use <b>registers</b> implicitly, and <b>instructions</b> that can be executed on any of several types of functional units require a tightly integrated <b>instruction</b> scheduler and <b>register</b> allocator. Such an integrated system can detect the interactions between the various problems that must be solved and therefore improve the use of available resources. In this paper we show that the resource requirements framework developed in URSA for unifying <b>instruction</b> scheduling and <b>register</b> allocation is powerful enough to represent the problems presented by these architectural features. Thus, {{all of the problems}} can be addressed in a uniform manner and in conjunction with <b>instruction</b> scheduling and <b>register</b> allocation. URSA's representation can also incorporate a new algorithm for assigning instructions to functional units to reduce interlock delays in pipelined multiple issue architectures...|$|R
5000|$|Some {{additional}} two-operand <b>instructions</b> {{require a}} <b>register</b> source operand: ...|$|R
50|$|Generally, stack-based {{machines}} {{must use}} instructions to load {{data on the}} stack and manipulate that data, and, thus, require more <b>instructions</b> than <b>register</b> machines to implement the same high-level code, but the <b>instructions</b> in a <b>register</b> machine must encode the source and destination registers and, therefore, tend to be larger. This difference is of importance to VM interpreters, for which opcode dispatch tends to be expensive, along with other factors similarly relevant to just-in-time compilation.|$|R
