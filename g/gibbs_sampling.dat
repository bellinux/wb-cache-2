2393|1486|Public
25|$|Just another Gibbs sampler - (JAGS) Another {{open source}} {{alternative}} to WinBUGS. Uses <b>Gibbs</b> <b>sampling.</b>|$|E
25|$|Another {{class of}} methods for {{sampling}} {{points in a}} volume is to simulate random walks over it (Markov chain Monte Carlo). Such methods include the Metropolis-Hastings algorithm, <b>Gibbs</b> <b>sampling,</b> Wang and Landau algorithm, and interacting type MCMC methodologies such as the sequential Monte Carlo samplers.|$|E
25|$|The {{principle}} of detailed balance {{has been used}} in Markov chain Monte Carlo methods since their invention in 1953. In particular, in the Metropolis–Hastings algorithm and in its important particular case, <b>Gibbs</b> <b>sampling,</b> it is used as a simple and reliable condition to provide the desirable equilibrium state.|$|E
40|$|The <b>Gibbs</b> <b>sampler</b> is a {{very simple}} yet {{efficient}} method for the performance evaluation of product form loss networks. This paper introduces the setwise <b>Gibbs</b> <b>sampler</b> as a flexible tech-nique for analysing closed BCMP networks, which model telecommunication networks using window flow control. The efficiency of another variant, the filtered <b>Gibbs</b> <b>sampler</b> (FGS), is also investigated. It is shown that the FGS is considerably more efficient than the standard <b>Gibbs</b> <b>sampler.</b> It is also shown that traditional estimates of the accuracy of FGS can be excessively optimistic, and a more conservative estimator is presented...|$|R
40|$|This article aims {{to provide}} a method for {{approximately}} pre-determining convergence properties of the <b>Gibbs</b> <b>sampler.</b> This {{is to be done}} by first finding an approximate rate of convergence for a normal approximation of the target distribution. The rates of convergence for different implementation strategies of the <b>Gibbs</b> <b>sampler</b> are compared to find the best one. In general, the limiting convergence properties of the <b>Gibbs</b> <b>sampler</b> on a sequence of target distributions (approaching a limit) {{are not the same as}} the convergence properties of the <b>Gibbs</b> <b>sampler</b> on the limiting target distribution. Theoretical results are given in this article to justify that under conditions, the convergence properties of the <b>Gibbs</b> <b>sampler</b> can be approximated as well. A number of practical examples are given for illustratio...|$|R
40|$|The <b>Gibbs</b> <b>sampler</b> is a {{particularly}} popular Markov chain used for learning and inference problems in Graphical Models (GMs). These tasks are computationally intractable in general, and the <b>Gibbs</b> <b>sampler</b> often suffers from slow mixing. In this paper, we study the Swendsen-Wang dynamics which is a more sophisticated Markov chain designed to overcome bottlenecks that impede the <b>Gibbs</b> <b>sampler.</b> We prove O(n) mixing time for attractive binary pairwise GMs (i. e., ferromagnetic Ising models) on stochastic partitioned graphs having n vertices, under some mild conditions, including low temperature regions where the <b>Gibbs</b> <b>sampler</b> provably mixes exponentially slow. Our experiments also confirm that the Swendsen-Wang sampler significantly outperforms the <b>Gibbs</b> <b>sampler</b> when they are used for learning parameters of attractive GMs...|$|R
25|$|Markov chains {{have many}} {{applications}} as statistical models of real-world processes, such as studying cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, exchange rates of currencies, storage {{systems such as}} dams, and population growths of certain animal species. The algorithm known as PageRank, which was originally proposed for the internet search engine Google, {{is based on a}} Markov process. Furthermore, Markov processes are the basis for general stochastic simulation methods known as <b>Gibbs</b> <b>sampling</b> and Markov Chain Monte Carlo, are used for simulating random objects with specific probability distributions, and have found extensive application in Bayesian statistics.|$|E
500|$|Gibbs's early {{papers on}} the use of {{graphical}} methods in thermodynamics reflect a powerfully original understanding of what mathematicians would later call [...] "convex analysis", including ideas that, according to Barry Simon, [...] "lay dormant for about seventy-five years". [...] Important mathematical concepts based on Gibbs's work on thermodynamics and statistical mechanics include the Gibbs lemma in game theory, the Gibbs inequality in information theory, as well as <b>Gibbs</b> <b>sampling</b> in computational statistics.|$|E
2500|$|... {{which include}} the Metropolis-Hastings {{algorithm}} and <b>Gibbs</b> <b>sampling.</b>|$|E
40|$|We {{present a}} {{consistent}} self-contained and pedagogical {{review of the}} CMB <b>Gibbs</b> <b>sampler,</b> focusing on computational methods and code design. We provide an easy-to-use CMB <b>Gibbs</b> <b>sampler</b> named SLAVE developed in C++ using object-oriented design. While discussing why {{the need for a}} <b>Gibbs</b> <b>sampler</b> is evident and what the <b>Gibbs</b> <b>sampler</b> can be used for in a cosmological context, we review in detail the analytical expressions for the conditional probability densities and discuss the problems of galactic foreground removal and anisotropic noise. Having demonstrated that SLAVE is a working, usable CMB <b>Gibbs</b> <b>sampler,</b> we present the algorithm for white noise level estimation. We then give a short guide on operating SLAVE before introducing the post-processing utilities for obtaining the best-fit power spectrum using the Blackwell-Rao estimator. Comment: 11 pages...|$|R
3000|$|..., however this {{is usually}} inaccurate, so the {{posterior}} parameters are obtained by calculating the mean and covariance of the <b>Gibbs</b> <b>samples.</b> The bases D̃_t are also taken as {{the mean of the}} <b>Gibbs</b> <b>samples.</b>|$|R
40|$|International audiencehis paper proposes {{and compares}} two new {{sampling}} schemes for sparse deconvolution using a Bernoulli-Gaussian model. To tackle such a deconvolution {{problem in a}} blind and unsupervised context, the Markov Chain Monte Carlo (MCMC) framework is usually adopted, and the chosen sampling scheme is most often the <b>Gibbs</b> <b>sampler.</b> However, such a sampling scheme fails to explore the state space efficiently. Our first alternative, the K-tuple <b>Gibbs</b> <b>sampler,</b> is simply a grouped <b>Gibbs</b> <b>sampler.</b> The second one, called partially marginalized sampler, is obtained by integrating the Gaussian amplitudes out of the target distribution. While the mathematical validity of the first scheme is obvious as a particular instance of the <b>Gibbs</b> <b>sampler,</b> a more detailed analysis is provided to prove {{the validity of the}} second scheme. For both methods, optimized implementations are proposed in terms of computation and storage cost. Finally, simulation results validate both schemes as more efficient in terms of convergence time compared with the plain <b>Gibbs</b> <b>sampler.</b> Benchmark sequence simulations show that the partially marginalized sampler takes fewer iterations to converge than the K-tuple <b>Gibbs</b> <b>sampler.</b> However, its computation load per iteration grows almost quadratically with respect to the data length, while it only grows linearly for the K-tuple <b>Gibbs</b> <b>sampler...</b>|$|R
2500|$|Increased {{computing}} power has {{also led to}} {{the growing popularity of}} computationally intensive methods based on resampling, such as permutation tests and the bootstrap, while techniques such as <b>Gibbs</b> <b>sampling</b> have made use of Bayesian models more feasible. The computer revolution has implications for the future of statistics with new emphasis on [...] "experimental" [...] and [...] "empirical" [...] statistics. A large number of both general and special purpose statistical software are now available.|$|E
50|$|Bayesian {{inference}} using <b>Gibbs</b> <b>sampling</b> (BUGs) is {{a software}} package for performing Bayesian inference using Markov chain Monte Carlo (based on <b>Gibbs</b> <b>sampling).</b>|$|E
5000|$|The goal of <b>Gibbs</b> <b>Sampling</b> {{here is to}} {{approximate}} the distribution of [...] Since [...] is invariable for any of Z, <b>Gibbs</b> <b>Sampling</b> equations {{can be derived from}} [...] directly. The key point is to derive the following conditional probability: ...|$|E
40|$|We {{consider}} Bayesian {{estimation of}} a sample selection model and propose a highly efficient <b>Gibbs</b> <b>sampler</b> using the additional scale transformation step {{to speed up the}} convergence to the posterior distribution. Numerical examples are given to show the efficiency of our proposed <b>sampler.</b> Bayesian analysis <b>Gibbs</b> <b>sampler</b> Sample selection model Tobit model...|$|R
40|$|The {{geometrical}} {{convergence of}} the <b>Gibbs</b> <b>sampler</b> for simulating a probability distribution inRdis proved. The distribution has a density {{which is a}} bounded perturbation of a log-concave function and satisfies some growth conditions. The analysis {{is based on a}} representation of the <b>Gibbs</b> <b>sampler</b> and some powerful results from the theory of Harris recurrent Markov chains. Stochastic relaxation, <b>Gibbs</b> <b>sampler,</b> Markov chain, geometrical convergence, Harris recurrence, Monte Carlo Markov chain, Metropolis algorithm, nonlinear autoregression...|$|R
40|$|We {{introduce}} {{a set of}} new <b>Gibbs</b> <b>sampler</b> for Bayesian analysis of quantile re-gression model. The new algorithm, which partially collapsing an ordinary <b>Gibbs</b> <b>sampler,</b> is called Partially Collapsed <b>Gibbs</b> (PCG) <b>sampler.</b> Although the Metropolis-Hastings algorithm has been employed in Bayesian quantile regression, including median regression, PCG has superior convergence properties to an ordinary <b>Gibbs</b> <b>sampler.</b> Moreover, Our PCG sampler algorithm, {{which is based on}} a theoretic derivation of an asymmetric Laplace as scale mixtures of normal distributions, requires less computation than the ordinary <b>Gibbs</b> <b>sampler</b> and can significantly reduce the computation involved in approximating the Bayes Factor and marginal likelihood. Like the ordinary <b>Gibbs</b> <b>sampler,</b> the PCG sample {{can also be used to}} calculate any associated marginal and predictive distributions. The quantile regression PCG sampler is illustrated by analysing simulated data and the data of length of stay in hospital. The latter provides new insight into hospital perfor-mance. C-code along with an R interface for our algorithms is publicly available on request from the first author. JEL classification: C 11, C 14, C 21, C 31, C 52, C 53...|$|R
50|$|Generalized {{linear models}} (i.e. {{variations}} of linear regression) {{can sometimes be}} handled by <b>Gibbs</b> <b>sampling</b> as well. For example, probit regression for determining {{the probability of a}} given binary (yes/no) choice, with normally distributed priors placed over the regression coefficients, can be implemented with <b>Gibbs</b> <b>sampling</b> because it is possible to add additional variables and take advantage of conjugacy. However, logistic regression cannot be handled this way. One possibility is to approximate the logistic function with a mixture (typically 7-9) of normal distributions. More commonly, however, Metropolis-Hastings is used instead of <b>Gibbs</b> <b>sampling.</b>|$|E
5000|$|Random number generation, matrix for bootstrapping, <b>Gibbs</b> <b>sampling</b> and Monte Carlo {{simulation}} ...|$|E
50|$|Lawrence has {{particular}} {{contributions in}} the development of sequence alignment algorithms, which is approaching the modif finding problem by integrating the Bayesian statistics and <b>Gibbs</b> <b>sampling</b> strategy. In his seminal paper published in Science in 1993, the first application of the statistical technique <b>Gibbs</b> <b>sampling</b> to the problem of multiple sequence alignment was described and clearly illustrated.|$|E
40|$|Monte Carlo Markov {{process methods}} {{based on the}} <b>Gibbs</b> <b>sampler</b> and the Metropolis {{algorithm}} are employed to estimate the posterior distributions of parameters in the nonlinear mixed model. A hierarchical Bayes approach is used to specify the nonlinear mixed model, enabling estimation of the posterior distributions of the variance components {{as well as the}} fixed and random effects. The <b>Gibbs</b> <b>sampler</b> requires iterative sampling from conditional distributions, which frequently cannot be directly computed in the nonlinear mixed model. To sample from such unavailable conditional distributions, approximate <b>Gibbs</b> <b>sampler</b> schemes based on the Metropolis algorithm are employed. These techniques, first suggested by Hastings (1970), retain much of the simplicity of the <b>Gibbs</b> <b>sampler</b> (moving one coordinate at a time, based on one-step conditional distributions) while requiring considerably less computing time than other methods (e. g., rejection sampling and ratio of uniforms) proposed for applying the <b>Gibbs</b> <b>sampler</b> when conditional distributions are not directly computable Two applications to repeated measures data are presented...|$|R
40|$|Recently the <b>Gibbs</b> <b>sampler</b> {{has become}} a very popular {{estimation}} technique especially in Bayesian Statistics. In order to implement the <b>Gibbs</b> <b>sampler,</b> matrix factorizations must be computed which normally is not problematic. When the dimension of the matrices to be factored is large, computation time increases to an amount to merit special attention. I have found that when the matrices to be factored are separable or patterned, results from matrix theory can assist in computation time reduction. 1. INTRODUCTION Recently the <b>Gibbs</b> <b>sampler</b> {{has become one of}} the favored techniques for parameter estimation especially in Bayesian Statistics. The <b>Gibbs</b> <b>sampler</b> is a sampling based approach to calculating marginal posterior distributions especially useful when the densities are not integrable in closed form or are too high a dimension for other methods. The <b>Gibbs</b> <b>sampler</b> is a stochastic integration technique that draws samples from conditional densities and uses them to approximate the margina [...] ...|$|R
40|$|A new {{framework}} for color image segmentation is in-troduced generalizing {{the concepts of}} point-based and spatially-based methods. This framework is based on Markov Random Fields using a Continuous <b>Gibbs</b> <b>Sampler.</b> The Markov Random Fields approach allows for a rigor-ous computational framework where local and global spatial constraints can be globally optimized. Using a Continuous <b>Gibbs</b> <b>Sampler</b> enables the algorithm to adapt continuous-valued regional prototypes in a manner analogous to vector quantization while the discrete <b>Gibbs</b> <b>Sampler</b> is used to ad-just region boundaries. 1...|$|R
50|$|There are {{two ways}} that <b>Gibbs</b> <b>sampling</b> can fail. The first is when there are islands of high-probability states, with no paths between them. For example, {{consider}} a probability distribution over 2-bit vectors, where the vectors (0,0) and (1,1) each have probability ½, but the other two vectors (0,1) and (1,0) have probability zero. <b>Gibbs</b> <b>sampling</b> will become trapped {{in one of the}} two high-probability vectors, and will never reach the other one. More generally, for any distribution over high-dimensional, real-valued vectors, if two particular elements of the vector are perfectly correlated (or perfectly anti-correlated), those two elements will become stuck, and <b>Gibbs</b> <b>sampling</b> {{will never be able to}} change them.|$|E
5000|$|Just another Gibbs sampler - (JAGS) Another {{open source}} {{alternative}} to WinBUGS. Uses <b>Gibbs</b> <b>sampling.</b>|$|E
5000|$|Boltzmann machine - like a Hopfield net but uses {{annealed}} <b>Gibbs</b> <b>sampling</b> {{instead of}} gradient descent ...|$|E
50|$|A blocked <b>Gibbs</b> <b>sampler</b> groups {{two or more}} {{variables}} {{together and}} samples from their joint distribution conditioned on all other variables, rather than sampling from each one individually. For example, in a hidden Markov model, a blocked <b>Gibbs</b> <b>sampler</b> might sample from all the latent variables making up the Markov chain in one go, using the forward-backward algorithm.|$|R
40|$|For Bayesian {{inference}} on {{the mixture}} of factor analyzers (MFA), natural conjugate priors on the parameters are introduced and then a <b>Gibbs</b> <b>sampler</b> that generates parameter samples following the posterior is constructed. In addition, a deterministic estimation algorithm is derived by taking modes instead of samples from the conditional posteriors used in the <b>Gibbs</b> <b>sampler.</b> This {{is regarded as a}} maximum a posteriori (MAP) estimation algorithm with hyperparameter search. The behaviors of the <b>Gibbs</b> <b>sampler</b> and the deterministic algorithm are compared on a simulation experiment. ...|$|R
40|$|A setwise <b>Gibbs</b> <b>sampler</b> (SGS) {{method is}} {{developed}} to simulate stationary distributions and performance measures of network occupancy of Baskett-Chandy-Muntz-Palacios (BCMP) telecommunication models. It overcomes the simulation difficulty encountered in applying the standard <b>Gibbs</b> <b>sampler</b> to closed BCMP networks with constant occupancy constraints. We show Markov chains induced by SGS converge {{to the target}} stationary distributions. This article also investigates the filtered <b>Gibbs</b> <b>sampler</b> (FGS) as an efficient method for estimating various network performance measures. It shows that FGS's efficiency is considerable, but may be improperly overestimated. A more conservative performance estimator is then presented...|$|R
5000|$|<b>Gibbs</b> <b>sampling,</b> in {{its basic}} incarnation, {{is a special}} case of the Metropolis-Hastings algorithm. The point of <b>Gibbs</b> <b>sampling</b> is that given a multivariate {{distribution}} it is simpler to sample from a conditional distribution than to marginalize by integrating over a joint distribution. Suppose we want to obtain [...] samples of [...] from a joint distribution [...] Denote the th sample by [...] We proceed as follows: ...|$|E
5000|$|The {{process of}} {{simulated}} annealing {{is often used}} to reduce the [...] "random walk" [...] behavior {{in the early part of}} the sampling process (i.e. the tendency to move slowly around the sample space, with a high amount of autocorrelation between samples, rather than moving around quickly, as is desired). Other techniques that may reduce autocorrelation are collapsed <b>Gibbs</b> <b>sampling,</b> blocked <b>Gibbs</b> <b>sampling,</b> and ordered overrelaxation; see below.|$|E
5000|$|The idea of {{applying}} the Ising model with annealed <b>Gibbs</b> <b>sampling</b> is {{also present in}} Douglas Hofstadter's Copycat project: ...|$|E
40|$|We often seek to {{identify}} co-occurring hidden features {{in a set}} of observations. The Indian Buffet Process (IBP) provides a nonparametric prior on the features present in each observation, but current inference techniques for the IBP often scale poorly. The collapsed <b>Gibbs</b> <b>sampler</b> for the IBP has a running time cubic in the number of observations, and the uncollapsed <b>Gibbs</b> <b>sampler,</b> while linear, is often slow to mix. We present a new linear-time collapsed <b>Gibbs</b> <b>sampler</b> for conjugate likelihood models and demonstrate its efficacy on large real-world datasets. 1...|$|R
40|$|Typical {{implementations}} of genomic prediction utilize Markov chain Monte Carlo (MCMC) sampling {{to estimate}} effects. Metropolis-Hastings (MH) is a commonly-used algorithm. We considered three different Gibbs samplers {{to speed up}} BayesB, a commonly-used model for genomic prediction. These differ in the manner they sample the marker effect, the locus-specific variance and the indicator variable. They are a single-site <b>Gibbs</b> <b>Sampler,</b> a blocking <b>Gibbs</b> <b>Sampler</b> and a <b>Gibbs</b> <b>Sampler</b> with pseudo prior. These three versions of BayesB are about {{twice as fast as}} the one using a MH algorithm...|$|R
40|$|Abstract We {{discuss the}} {{convergence}} time of <b>Gibbs</b> <b>sampler</b> in Ising models. We obtain an improved explicit O(N logN) {{upper bound on}} the convergence time of the <b>Gibbs</b> <b>sampler</b> in Ising models with N sites. Our results are tighter and hold for the wider range of parameter values compared to the previous results. It is generally very difficult to decide when to stop the <b>Gibbs</b> <b>sampler</b> and our upper bounds are good practical guides for it. Moreover, they also give important information about the running time of coupling from the past algorithms...|$|R
