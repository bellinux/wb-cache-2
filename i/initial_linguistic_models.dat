0|1150|Public
40|$|Abstract –A new {{presentation}} for <b>linguistic</b> <b>model</b> of {{the object}} to be controlled in a control system is presented. Just as the importance of mathematic mode to conventional control theory, the <b>linguistic</b> <b>model</b> is important in a fuzzy control system. With the <b>linguistic</b> <b>model</b> of controlled object or process to be controlled, we can construct a close loop system representation. Consequently, we can discuss the system appearance {{with the assistance of}} the <b>linguistic</b> <b>model</b> as we do using a mathematic model in a conventional control system. In this paper, we discuss the representation of <b>linguistic</b> <b>model</b> and the combine methods for the controller <b>model</b> and the <b>linguistic</b> <b>model</b> of controlled object. Still we introduce a model construction method using human’s intuitional knowledge...|$|R
30|$|For the two {{scenarios}} outlined above, {{three types}} of experiments are carried out to evaluate the impact of affect on both the acoustic and the <b>linguistic</b> <b>models.</b> In the first experiment, the acoustic models are adapted whereas the <b>linguistic</b> <b>models</b> are kept fixed. In the second experiment, it is the other way round: only the <b>linguistic</b> <b>models</b> are adapted and the acoustic models are kept constant. Finally, both the acoustic and <b>linguistic</b> <b>models</b> are adapted.|$|R
40|$|This paper {{presents}} {{the problems of}} the development of recognizing <b>linguistic</b> <b>models</b> for natural language text analysis. These models are the important component of any linguistic knowledge base. Using the suggested approach we can develop recognizing <b>linguistic</b> <b>models</b> for any natural language. Examples of the recognizing <b>linguistic</b> <b>models</b> used for the analysis of inflectional languages (Belarusian and Russian) are given in the paper...|$|R
40|$|Nowadays, <b>Linguistic</b> <b>Modeling</b> is {{considered}} one of the most important applications of Fuzzy Set Theory, along with Fuzzy Control. <b>Linguistic</b> <b>models</b> have the advantage of providing a human-readable description of the system modeled in the form of a set of linguistic rules. In this chapter, we will analyze several approaches to improve the accuracy of <b>linguistic</b> <b>models</b> while maintaining their descriptive power. All these approaches will share the common idea of improving the way in which the Fuzzy Rule-Based System performs interpolative reasoning by improving the cooperation between the rules in the <b>linguistic</b> <b>model</b> Knowledge Base...|$|R
40|$|International audienceThe {{linguistic}} perspective {{emphasizes the}} use of linguistic taxonomy to classify (partition) graphical user interface concepts and elements on several linguistic levels with clearly-defined interfaces between levels. This perspective is based on Nielsen's Virtual Protocol for Interaction that consists of several linguistic levels: goal, pragmatic (task), semantic, syntactical, lexical, alphabetical and physical. A <b>linguistic</b> <b>modeling</b> is modeling the graphical interface by abstracting each linguistic level. The aim of the <b>linguistic</b> <b>modeling</b> is to enhance the maintainability quality of the graphical user interface model as defined in ISO- 25010 : 2011, by enhancing sub-qualities of modularity, analyzability and modifiability. Recent research reported on the linguistic perspective and the <b>linguistic</b> <b>modeling</b> requirements. In this paper, we elaborate more towards a <b>linguistic</b> <b>modeling</b> by modeling the task level; the high abstract level in the linguistic stack. Our contribution is an executable hierarchical task model that fulfils the specific needs towards <b>linguistic</b> <b>modeling...</b>|$|R
40|$|Abstract—In this paper, {{we propose}} {{accurate}} <b>linguistic</b> <b>modeling,</b> a methodology to design <b>linguistic</b> <b>models</b> that are accurate {{to a high}} degree and may be suitably interpreted. This approach {{will be based on}} two main assumptions related to the interpolative reasoning developed by fuzzy rule-based systems: a small change {{in the structure of the}} <b>linguistic</b> <b>model</b> based on allowing the linguistic rule to have two consequents associated and a different way to obtain the knowledge base based on generating a preliminary fuzzy rule set composed of a large number of rules and then selecting the subset of them best cooperating. Moreover, we will introduce two variants of an automatic design method for these kinds of <b>linguistic</b> <b>models</b> based on two well-known inductive fuzzy rule generation processes and a genetic process for selecting rules. The accuracy of the proposed methods will be compared with other <b>linguistic</b> <b>modeling</b> techniques with different characteristics when solving of three different applications. Index Terms—Descriptive Mamdani-type fuzzy rule-based systems, double-consequent linguistic rules, genetic algorithms, inductive fuzzy rule generation, <b>linguistic</b> <b>modeling,</b> rule selection. I...|$|R
40|$|We {{consider}} the principle "a new {{model is a}} model of an existing one" as the main scheme for deriving new <b>linguistic</b> <b>models</b> by metacomputation. We derive the basic requirements for metacomputation by a structural analysis of different model definitions, and show that in order to automate the creation of <b>linguistic</b> <b>models</b> the following operations on <b>linguistic</b> <b>models</b> have to be performed by metacomputation effectively and efficiently: composition, inversion, and specialization of algorithms. This may also serve as a unifying paradigm for different program transformation approaches. 1. INTRODUCTION During the last decades we have witnessed tremendous technological breakthroughs in the development and application of computers. The introduction of the computer was an evolutionary step in the control of formal <b>linguistic</b> <b>models,</b> a metasystem transition (MST). As a result the number of <b>linguistic</b> <b>models</b> created and used has significantly increased. The method of modern science is, in its e [...] ...|$|R
40|$|Using {{conditional}} fuzzy clustering, a <b>linguistic</b> <b>model</b> for {{static pressure}} signal of compressor outlet in aeroengine was established. The modeling {{process and the}} validation result demonstrated unique advances of <b>linguistic</b> <b>modeling</b> {{in the analysis of}} complex systems. The <b>linguistic</b> <b>model</b> was used to predict the pressure signal before the engine entered instability. The prediction result showed that the <b>linguistic</b> <b>model</b> could effectively recognize the sudden changes of pressure signal features. The detected change of signal might not necessarily be the commonly considered initial disturbance of compressor instability; however, the pattern recognition ability of <b>linguistic</b> <b>model</b> was still very attractive. At last, it pointed out that setting up a database containing experiment data and historical experience about engine aerodynamic instability and utilizing advanced intelligent computing technology in the database to develop knowledge discovery provide a new idea for the {{solution to the problem of}} aerodynamic instability in aeroengine...|$|R
40|$|When using {{linguistic}} {{approaches to}} solve decision problems, we need <b>linguistic</b> representation <b>models.</b> The symbolic model, the 2 -tuple fuzzy <b>linguistic</b> representation <b>model</b> and the continuous <b>linguistic</b> <b>model</b> are three existing <b>linguistic</b> representation <b>models</b> based on position indexes. Together with these three <b>linguistic</b> <b>models,</b> the corresponding ordered weighted averaging operators, {{such as the}} linguistic ordered weighted averaging operator, the 2 -tuple ordered weighted averaging operator and the extended ordered weighted averaging operator, have been developed, respectively. In this paper, we analyze the internal relationship among these operators, and propose a consensus operator under the continuous <b>linguistic</b> <b>model</b> (or the 2 -tuple fuzzy <b>linguistic</b> representation <b>model).</b> The proposed consensus operator {{is based on the}} use of the ordered weighted averaging operator and the deviation measures. Some desired properties of the consensus operator are also presented. In particular, the consensus operator provides an alternative consensus model for group decision making. This consensus model preserves the original preference information given by the decision makers as much as possible, and supports consensus process automatically, without moderator. Decision analysis <b>Linguistic</b> representation <b>model</b> OWA operator Deviation measure Consensus...|$|R
40|$|We look at recent {{accounts}} of the indefinite extensibility of the concept set and compare them with a certain <b>linguistic</b> <b>model</b> of indefinite extensibility. We suggest that the <b>linguistic</b> <b>model</b> has much to recommend over alternative {{accounts of}} indefinite extensibility, and we defend it against three prima facie objection...|$|R
40|$|We {{consider}} the principle “a new {{model is a}} model of an existing one ” as the main scheme for deriving new <b>linguistic</b> <b>models</b> by metacomputation. We derive the basic requirements for metacomputation by a structural analysis of different model definitions, and show that in order to automate the creation of <b>linguistic</b> <b>models</b> the following operations on <b>linguistic</b> <b>models</b> have to be performed by metacomputation effectively and efficiently: composition, inversion, and specialization of algorithms. This may also serve as a unifying paradigm for different program transformation approaches. 1...|$|R
40|$|<b>Linguistic</b> <b>Modeling</b> is the {{approach}} that allows human-computer interaction to be established by using natural-like language. We use Fourier-holography technique to implement <b>Linguistic</b> <b>Modeling</b> {{in the framework of}} Neuro-Fuzzy approach. We pay attention to implementation of non-monotonic semantics by this technique. We develop theoretical model and verify it by experimental illustration. 1...|$|R
5000|$|... {{integration}} period (8th-9th centuries): several language features (both West and non-West Slavic) {{spread across the}} borders of the <b>initial</b> <b>linguistic</b> regions; these changes are best explained by the integration process of the Slavs before and during the existence of Great Moravia ...|$|R
40|$|We {{study the}} {{structure}} of language hierarchies and their reduction by two forms of metacomputation in order to overcome the time and space complexity of language hierarchies. We show that program specialization and program composition are sufficient to reduce all forms of language hierarchies constructed from interpreters and translators. We argue that the reduction of language hierarchies {{is a prerequisite for}} effective formal <b>linguistic</b> <b>modeling</b> on a large scale. 1 Introduction One of the defining features of modern science is the use of languages, both informal and formal, to construct <b>linguistic</b> <b>models</b> of reality [8]. The introduction of the computer was a revolutionary step in the execution of formal <b>linguistic</b> <b>models</b> and, as a result, the number of <b>linguistic</b> <b>models</b> created and used has significantly increased in all branches of science during the last decades. Computer science, as we see it, is laying the foundations and developing the research paradigm and scientific me [...] ...|$|R
40|$|In {{this paper}} we {{introduce}} Accurate <b>Linguistic</b> <b>Modelling,</b> {{an approach to}} design <b>linguistic</b> <b>models</b> from data, which are accurate to a high degree and may be suitably interpreted. <b>Linguistic</b> <b>models</b> constitute an Intelligent Data Analysis structure that {{has the advantage of}} providing a human-readable description of the system modelled in the form of linguistic rules. Unfortunately, their accuracy is sometimes not as high as desired, thus causing the designer to discard them and replace them by other kinds of more accurate but less interpretable models. ALM has the aim of solving this problem by improving the accuracy of <b>linguistic</b> <b>models</b> while maintaining their descriptive power, taking as a base some modications on the interpolative reasoning developed by the Fuzzy Rule-Based System composing the model. In this contribution we shall introduce the main aspects of ALM, along with a specic design process based on it. The behaviour of this learning process in the solving of two dierent [...] ...|$|R
40|$|Juyeon Kang and Jungyeul Park (in preparation). <b>Linguistic</b> <b>Models</b> for Requirement Quality Analysis. Will be {{submitted}} to Requirements Engineering (Springer). November 2017. It requires NeuroNER, available at [URL] See also Kang J, Park J. Generating a <b>Linguistic</b> <b>Model</b> for Requirement Quality Analysis. In: Proceedings of the 30 th Pacific Asia Conference on Language, Information and Computation: Posters (PACLIC 30). Seoul, Korea; 2016 : 439 - 447. [URL]...|$|R
40|$|AbstractThe {{theory of}} prototypes {{provides}} a new semantic interpretation of vague concepts. In particular, the calculus derived from this interpretation {{results in the}} same calculus as label semantics proposed by Lawry. In the theory of prototypes, each basic linguistic label L has the form ‘about P’, where P {{is a set of}} prototypes of L and the neighborhood size of the underlying concept is described by the word ‘about’ which represents a probability density function δ on [0,+∞). In this paper we propose an approach to vague information coarsening based on the theory of prototypes. Moreover, we propose a framework for <b>linguistic</b> <b>modelling</b> within the theory of prototypes, in which the rules are concise and transparent. We then present a linguistic rule induction method from training data based on information coarsening and data clustering. Finally, we apply this <b>linguistic</b> <b>modelling</b> method to some benchmark time series prediction problems, which show that our <b>linguistic</b> <b>modelling</b> and information coarsening methods are potentially powerful tools for <b>linguistic</b> <b>modelling</b> and uncertain reasoning...|$|R
5000|$|The most {{critical}} review was Philip Kohl's Perils of Carts before Horses: <b>Linguistic</b> <b>Models</b> and the Underdetermined Archaeological Record in American Anthropologist. Kohl argues that Anthony's <b>linguistic</b> <b>model</b> is overly simple when regarding {{the development of}} the Indo-European languages as products of divergence, originating from one single source; though Kohl admits that Anthony pays attention to loanwords and the influence of neighboring cultures. Kohl is critical that Anthony's <b>linguistic</b> <b>model</b> guides [...] "the archaeological interpretation rather than the reverse"; according to Kohl, [...] "such a procedure almost necessarily means that the archaeological record is consistently manipulated to fit the <b>linguistic</b> <b>model</b> that it is meant to confirm; the reasoning is circular." [...] Kohl further notes that Anthony's reconstruction is bold and imaginative, but also [...] "necessarily selective" [...] and sometimes misleading when relying on a rather limited number of items. According to Kohl, ...the central problem with this book is its assumption that Indo-Europeans exclusively or nearly exclusively practiced certain cultural features, including technologies and even religious rituals. Was such exclusivity characteristic of the late prehistoric world or, rather, were peoples who spoke different languages continuously interacting with each other, adopting and transforming other peoples’ practices and beliefs? ...|$|R
30|$|GX {{designed}} and implemented the study, while C-RH provided <b>linguistic</b> <b>modeling</b> {{and interpretation of}} the result. All authors read and approved the final manuscript.|$|R
50|$|The {{linguistic}} {{processes of}} romantic nationalism demanded <b>linguistic</b> culture <b>models.</b> Romantic historiography was centered on biographies and produced culture heroes. The modern Italian of Risorgimento patriots like Alessandro Manzoni {{was based on}} the Tuscan dialects sanctified by Dante and Petrarch. In English, Shakespeare became an iconic figure (though not a modern <b>linguistic</b> <b>model).</b>|$|R
40|$|Abstract. Nowadays, {{information}} {{gathering in}} Internet {{is a complex}} activity and Internet users need systems to assist them to obtain the information required. In an earlier studies [5, 6, 16] we presented different fuzzy <b>linguistic</b> multi-agent <b>models</b> for helping users in their information gathering processes on the Web. In this paper, we present a new fuzzy <b>linguistic</b> multi-agent <b>model</b> to access information on the Web that incorporates the use of fuzzy multi-granular <b>linguistic</b> <b>modeling</b> to improve its user-system interaction and be more user-friendly...|$|R
40|$|This paper {{presents}} {{a survey of}} some fuzzy linguistic information access systems. The review shows information retrieval systems, filtering systems, recommender systems, and web quality evaluation tools, {{which are based on}} tools of fuzzy <b>linguistic</b> <b>modelling.</b> The fuzzy <b>linguistic</b> <b>modelling</b> allows us to represent and manage the subjectivity, vagueness and imprecision that is intrinsic and characteristic of the processes of information searching, and, in such a way, the developed systems allow users the access to quality information in a flexible and user-adapted way...|$|R
40|$|Summary. Nowadays, an {{abundant}} {{amount of information}} is created and delivered over electronic media. The information gathering in Internet is a complex activity and Internet users need tools to assist them to find the information required. Web multi-agent systems assist the users by gathering from Internet the information that best satisfies their specific needs. In this paper, we analyze some techniques that applied together could provide major advances {{in the design of}} these Web multi-agent systems in order to improve their performance: i) information filtering tools and ii) the fuzzy <b>linguistic</b> <b>modelling.</b> Then, we present a model of a fuzzy linguistic multi-agent system for searching and mining the Web that is designed using some filtering tools and a particular fuzzy <b>linguistic</b> <b>modelling,</b> called multi-granular fuzzy <b>linguistic</b> <b>modelling,</b> which is useful when we have different label sets to assess the information...|$|R
40|$|Abstract—In this paper, we {{are going}} to propose an {{approach}} to design <b>linguistic</b> <b>models</b> which are accurate to a high degree and may be suitably interpreted. This approach will be based on the development of a Hierarchical System of Linguistic Rules learning methodology. This methodology has been thought as a refinement of simple <b>linguistic</b> <b>models</b> which, preserving their descriptive power, introduces small changes to increase their accuracy. To do so, we extend the structure of the Knowledge Base of Fuzzy Rule Base Systems in a hierarchical way, {{in order to make it}} more flexible. This flexibilization will allow us to have linguistic rules defined over linguistic partitions with different granularity levels, and thus to improve the modeling of those problem subspaces where the former models have bad performance. Index Terms—Genetic algorithms, hierarchical knowledge base, hierarchical <b>linguistic</b> partitions, <b>linguistic</b> <b>modeling,</b> Mamdanitype fuzzy rule-based systems, rule selection. I...|$|R
40|$|Abstract—This paper {{describes}} how the different CAD tools of the environment Xfuzzy 3, developed in Microelectronics Institute of Seville and University of Seville, allow to translate expressive <b>linguistic</b> <b>models</b> into mathematical ones, in particular, into a combination of piecewise polynomial systems that can be implemented efficiently in hardware. The new synthesis tool of Xfuzzy 3 automates communication with Xilinx System Generator in Matlab, thus facilitating implementation of the <b>linguistic</b> <b>model</b> into an FPGA from Xilinx. This is illustrated with {{the design of a}} navigation controller for an autonomous robot. I...|$|R
40|$|This paper {{presents}} an evolutionary learning process for <b>linguistic</b> <b>modeling</b> with weighted double-consequent fuzzy rules. These kinds of fuzzy rules {{are used to}} improve the <b>linguistic</b> <b>modeling,</b> {{with the aim of}} introducing a trade-off between interpretability and precision. The use of weighted double-consequent fuzzy rules makes more complex the modeling and learning process, increasing the solution search space. Therefore, the cooperative coevolution, an advanced evolutionary technique proposed to solve decomposable complex problems, is considered to learn these kinds of rules. The proposal has been tested with different problems achieving good results...|$|R
40|$|This paper {{investigates the}} use of {{cognitive}} constraints in a computational <b>linguistic</b> <b>model</b> for speech recognition. The approach incorporates a cognitive-based phonology into a dynamic temporal framework {{with the aim of}} improving the robustness of speech recognition performance by analysing speech as an embodied artefact of human social cognition. This paper sketches the necessary extensions to an existing computational <b>linguistic</b> <b>model</b> and discusses how a distributional analysis based on cognitively motivated features can provide the basis for the establishment of the cognitive constraints for the purposes of constraint ranking in such a model...|$|R
50|$|The {{complexity}} of the Luganda tonal system has {{attracted the attention of}} numerous scholars, who have sought ways of describing Luganda tones most economically according to different <b>linguistic</b> <b>models.</b>|$|R
40|$|In {{this paper}} we extend the {{structure}} of the Knowledge Base of Fuzzy Rule Base Systems in a hierarchical way, {{in order to make it}} more exible. This exibility will allow us to have linguistic rules dened over linguistic partitions with dierent granularity levels, and thus to improve the modeling of those problem subspaces where the former models have bad performance. To do so, we propose a local approach to design <b>linguistic</b> <b>models</b> which are accurate to a high degree and may be suitably interpreted. This approach will be based on the development of a Hierarchical System of Linguistic Rules learning methodology, which has been thought as a renement of simple <b>linguistic</b> <b>models</b> which, preserves their descriptive power and introduces small changes to increase their accuracy. We also introduce an iterative extension to this method, and compare both with a previous global hierarchical method. Keywords: <b>Linguistic</b> <b>Modeling,</b> Mamdani-type Fuzzy Rule-Based Systems, hi [...] ...|$|R
2500|$|Tomasz P. Krzeszowski {{examines}} the conduit metaphor in Language History and <b>Linguistic</b> <b>Modelling</b> : A Festschrift for Jacek Fisiak on His 60th Birthday (Trends in Linguistics. Studies and Monographs, 101) (Vol.1) ...|$|R
5000|$|Prescriptive Limeño Spanish has {{adjusted}} considerably to {{more closely}} resemble the standard Spanish <b>linguistic</b> <b>model,</b> {{because of the}} city's disdain of the contact with the Andean world and autochthonous languages for centuries.|$|R
40|$|MorphoDiTa: Morphological Dictionary and Tagger is an {{open-source}} {{tool for}} morphological analysis of natural language texts. It performs morphological analysis, morphological generation, tagging and tokenization and is distributed as a standalone tool or a library, along with trained <b>linguistic</b> <b>models.</b> In the Czech language, MorphoDiTa achieves state-of-the-art results with a throughput around 10 - 200 K words per second. MorphoDiTa {{is a free}} software under LGPL license and the <b>linguistic</b> <b>models</b> are free for non-commercial use and distributed under CC BY-NC-SA license, although for some models the original data used to create the model may impose additional licensing conditions...|$|R
40|$|NameTag is an {{open-source}} {{tool for}} named entity recognition (NER). NameTag identifies proper names in text and classifies them into predefined categories, such as names of persons, locations, organizations, etc. NameTag is distributed as a standalone tool or a library, along with trained <b>linguistic</b> <b>models.</b> In the Czech language, NameTag achieves state-of-the-art performance (Straková et al. 2013). NameTag {{is a free}} software under LGPL license and the <b>linguistic</b> <b>models</b> are free for non-commercial use and distributed under CC BY-NC-SA license, although for some models the original data used to create the model may impose additional licensing conditions...|$|R
40|$|International audienceIn this paper, {{we propose}} an {{approach}} to explore large texts by highlighting coherent sub-parts. The exploration method relies on a graph representation of the text according to Hoey's <b>linguistic</b> <b>model</b> which allows the selection and the binding of adjacent and non-adjacent sentences. The main contribution of our work consists in proposing a method based on both Hoey's <b>linguistic</b> <b>model</b> and a special graph mining technique, called CoHoP mining, to extract coherent sub-parts of the graph representation of the text. We have conducted some experiments on several English texts showing {{the interest of the}} proposed approach...|$|R
40|$|International audienceThis paper {{presents}} {{a system for}} large vocabulary continuous speech recognition in condition of constrained hardware resources. We investigate efficient pruning and caching strategy aiming to handle extensive acoustic and <b>linguistic</b> <b>modeling.</b> Software components are analyzed in terms of resource consuming. Then, we evaluate the system performance in extreme configuration where acoustic and <b>linguistic</b> <b>models</b> are dramatically pruned. Results show that the system design we proposed allows to use large HMM-based acoustic models and tri-gram language models while performing very fast decoding, under 0. 6 real-time on a standard desktop computer while remaining the transcript relevance...|$|R
40|$|Abstract—In this paper, {{we propose}} an {{approach}} to explore large texts by highlighting coherent sub-parts. The exploration method relies on a graph representation of the text according to Hoey’s <b>linguistic</b> <b>model</b> which allows the selection and the binding of adjacent and non-adjacent sentences. The main contribution of our work consists in proposing a method based on both Hoey’s <b>linguistic</b> <b>model</b> and a special graph mining technique, called CoHoP mining, to extract coherent sub-parts of the graph representation of the text. We have conducted some experiments on several English texts showing {{the interest of the}} proposed approach. I...|$|R
