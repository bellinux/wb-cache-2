8|72|Public
5000|$|They {{allow for}} {{comparisons}} to occur across jobs, roles and levels, {{not only in}} terms of the competencies required, but also the proficiency levels needed using a common <b>incremental</b> <b>scale</b> for defining the competencies.|$|E
5000|$|Optical linear {{encoders}} {{dominate the}} high resolution market and may employ shuttering/Moiré, diffraction or holographic principles. Optical encoders {{are the most}} accurate of the standard styles of encoders, and {{the most commonly used}} in industrial automation applications. When specifying an optical encoder, it’s important that the encoder has extra protection built in to prevent contamination from dust, vibration and other conditions common to industrial environments. [...] Typical <b>incremental</b> <b>scale</b> periods vary from hundreds of micrometers down to sub-micrometer. Interpolation can provide resolutions as fine as a nanometre.|$|E
40|$|A {{difficulty}} with proposals for satellite {{solar power systems}} {{is the absence of}} a plausible evolutionary pathway to development of systems on the scale required. One possible pathway is discussed, where the required technologies are developed and refined on an <b>incremental</b> <b>scale.</b> The initial stages of the process are development of ground-based photovoltaic power and of beamed power systems for space use...|$|E
40|$|In this paper, we derive subgrid-scale models {{based on}} the {{numerical}} approximation of <b>incremental</b> <b>scales.</b> The velocity field is decomposed into large (resolved), incremental and small (subgrid) scales. A quasi-static approximation, introduced in previous works, {{is applied to the}} <b>incremental</b> <b>scales.</b> This treatment provides an accurate approximation of the subgrid-scale energy. However, it induces a decorrelation between <b>incremental</b> and large <b>scales</b> damaging the approximation of their nonlinear interactions. Two phase modification procedures, insuring the dissipativity of the nonlinear interaction terms, are proposed. The models are investigated in both a priori tests and large-eddy simulations of forced and decaying homogeneous turbulent flows. Comparisons with results obtained with the dynamic model and direct simulations are presented. One of the proposed models is shown to be more accurate than the dynamic model...|$|R
40|$|This paper {{uses the}} British Household Panel Survey to {{investigate}} when seniority is rewarded by automatic <b>incremental</b> <b>scales.</b> Scales {{are seen as}} an alternative to individual merit pay. They are likely to be used when individual productivity is hard to measure, when firms provide all workers with similar levels of training and when workers have sufficient bargaining power to gain insurance against mis-measurement in the allocation of merit pay. The data provide support for these hypotheses. Earnings; Merit Pay; Seniority; Unions...|$|R
2500|$|Solar {{and wind}} power are {{extremely}} scalable, {{as there are}} systems available from less than 1 watt to several megawatts. This {{makes it possible to}} initialize the electrification of a home or village with minimal initial capital. It also allows for dynamic and <b>incremental</b> <b>scaling</b> as load demands increases. [...] The component configuration of a wind or solar installation also provides a level of functional redundancy, improving the reliability of the system. If a single panel in a multi panel solar array is damaged, the rest of the system continues functioning unimpeded. In a similar way, the failure of a single wind tower in a multi tower configuration does not cause a system level failure.|$|R
40|$|From {{the outcome}} of 175 cases, a group of 4 types of {{custom-designed}} HA-coated hip stems, based upon an <b>incremental</b> <b>scale</b> of bone condition, was demonstrated to be sufficient for use with the variety of cavitary defects encountered in revision hip surgery. Harris Hip Score evaluation showed a significant improvement in hip pain and function. Radiographic measurements of axial migration over a 4 -year period were less than 2 mm. The migration data were similar across the 4 types of revision stem. A follow-up using DEXA scans showed preservation of bone in all regions up to 4 years, which justifies the design rationale for the close fit of the stems in the proximal region in achieving initial stability and strain transfer...|$|E
40|$|Narrativity, a {{term that}} {{describes}} the degree of “storyness” of a text, can also be applied to exhibition design, architectural practice, urban and landscape design to provide a useful analytical framework and creative methodologies for collaboration among theorists,content developers, architects and designers. Narrativity {{can be used to}} set out an <b>incremental</b> <b>scale</b> of “storyness” inviting discussion of the definition of narrative environments. All spaces can be made to tell a story. For example, sand dunes can tell a story of natural forces, in the forms shaped by wind and sea power, high-rise tower blocks can tell a story of socio-political forces, in the forms shaped by urban concentration, favelas tell a different story of urban development, shaped by dispossession, exhibitions tell stories of peoples’ material cultures, natural and social histories, scientific discoveries, and so on. From these examples, {{it can be seen that}} some environments are more deliberately narrative than others. When does an environment become a narrative environment? A narrativity scale progresses by identifying the narrative features from which powerful story experiences in space can be developed. Thinking of spaces as stories highlights the quality of audience or user experience, the message or content, and the degree of authorship and intentionality in the environment. The telling of the story develops from dramatic tension and its unfolding over space and time is interpreted through visual, audio, olfactory, haptic and tactile senses. Perfomativity, sequencing of events, framing, revealing and concealing, suspense, mimesis, diegesis, closure, focalisation, human and non-human agency all become explicit strategies or devices available to the creative practitioner. The narrativity scale is shown as a diagram and examples, shown through images and video, are mapped onto the diagram...|$|E
40|$|Proceeding of: the Nokia Workshop on Machine Consciousness, (in 13 th Finnish Artificial Intelligence Conference, STeP 2008), Helsinki, Finland, August 21 - 22, 2008. Is {{consciousness}} {{a binary}} on/off property? Or is {{it on the}} contrary a complex phenomenon that can be present in different states, qualities, and degrees? We support the latter and propose a linear <b>incremental</b> <b>scale</b> for consciousness applicable to artificial agents. ConsScale is a novel agent taxonomy intended to classify agents according to their level of consciousness. Even though testing for consciousness {{remains an open question}} in the domain of biological organisms, a review of current biological approaches is discussed as well as their possible adapted application into the realm of artificial agents. Regarding to the always controversial problem of phenomenology, in this work we have adopted a purely functional approach, in which we have defined a set of architectural and behavioral criteria for each level of consciousness. Thanks to this functional definition of the levels, we aim to specify a set of tests {{that can be used to}} unambiguously determine the higher level of consciousness present in the artificial agent under study. Additionally, since a number of objections can be presumably posed against our proposal, we have considered the most obvious critiques and tried to offer reasonable rebuttals to them. Having neglected the phenomenological dimension of consciousness, our proposal might be considered reductionist and incomplete. However, we believe our account provides a valuable tool for assessing the level of consciousness of an agent at least from a cognitive point of view. This research has been also supported by the Spanish Ministry of Education and Science under CICYT grant TRA 2007 - 67374 -C 02 - 02. Publicad...|$|E
40|$|Working with soil, sand, powders, ores, {{cement and}} {{sintered}} bricks, excavating, grading construction sites, driving off-road, transporting granules in chutes and pipes, sifting gravel, separating solids from gases, and using hoppers are so routine {{that it seems}} straightforward {{to do it on}} the Moon and Mars as we do it on Earth. This paper brings to the fore how little these processes are understood and the millennia-long trial-and-error practices that lead to today's massive over-design, high failure rate, and extensive <b>incremental</b> <b>scaling</b> up of industrial processes because of the inadequate predictive tools for design. We present a number of pragmatic scenarios where granular materials play a role, the risks involved, and what understanding is needed to greatly reduce the risks...|$|R
40|$|We {{describe}} {{the design and}} integration of adaptive techniques into a virtual university environment. It comprises a series of techniques that customizes the educational process to the learning curve of the user and pro-vides personalization features to the exchanging information flow. Its distinctive functionality is that it encompasses combined adaptation between educational material and well-known communication facilities. In fact the environment is personalized towards two directions. Firstly adaptation is performed separately per user activity and subsequently knowledge of the different levels is shared to provide further personalization globally to the environment. Time obsolescence of personalization {{is also used to}} prohibit outdated adaptation to keep loading the user profile. Finally the object-oriented methodology followed is discussed as it was considered fundamental for <b>incremental</b> <b>scaling,</b> reusability and maintenance of the environment. 1...|$|R
40|$|This paper {{presents}} a new persistent data management layer designed to simplify cluster-based Internet service construction. This self-managing layer, called a distributed data structure (DDS), {{presents a}} conventional single-site data structure interface to service authors, but partitions and replicates the data across a cluster. We have designed and implemented a distributed hash table DDS that has properties necessary for Internet services (<b>incremental</b> <b>scaling</b> of throughput and data capacity, fault tolerance and high availability, high concurrency, consistency, and durability). The hash table uses two-phase commits {{to present a}} coherent view of its data across all cluster nodes, allowing any node to service any task. We show that the distributed hash table simplies Internet service construction by decoupling service-specic logic from the complexities of persistent, consistent state management, and by allowing services to inherit the necessary service properties from the DDS rather [...] ...|$|R
40|$|Sorry, {{the full}} text of this article is not {{available}} in Huskie Commons. Please click on the alternative location to access it. 247 p. Extensive research has accumulated regarding the existence of individual differences in the way people use behavioral information when making evaluative judgments of others. This study specifically investigated how first-grade, fifth-grade, and college-aged students may be oriented to evaluate the actions of peers in terms of dispositions (entity theorists) or in terms of situational/contextual and motivational factors (incremental theorists). To better understand how children's entity or incremental orientations affect their evaluations of peers, several widely used measures of trait inferences (e. g., temporal stability, situational consistency, intent, and emotional prediction) and evaluative/predictive judgments (e. g., causal attribution and likability) were examined. Study 1 attempted to investigate the assessment of entity and incremental theorists across children and adults. Study 2 attempted to isolate important differences between entity and incremental theorists across social-evaluative dimensions, in the face of inconsistent information, and accuracy of behavioral recall. Study 1 consisted of 209 fifth- and sixth-grade participants and examined {{the reliability and validity of}} three measures via correlational, internal reliability, and factor analyses. The correlational analyses revealed modest relationships between entity-oriented scales; however, no correlation was found between one entity scale and an <b>incremental</b> <b>scale.</b> Internal consistency and factor analyses identified items in the entity/incremental scales that were not significantly contributing to the overall scales and were subsequently removed from the scales. A total of 180 first-grade, fifth-grade, and college-aged students participated in Study 2 examining differences in person perception as a function of age, theory orientation (entity vs. incremental), and behavior style of the target peer (aggressive vs. prosocial). No hypothesized main effects occurred between the entity and incremental theory groups in the study. However, several interactions were found suggesting that entity/incremental first graders made evaluative distinctions on the basis of their a priori orientations. Additionally, several grade main effects were observed, lending support to the development of social perception skills across grades. Fifth graders were more trait-consistent raters on measures of situational consistency, intent, and emotional prediction. The results suggest that attributional dimensions such as situational consistency, intent, and emotional prediction best separated first and fifth graders. These findings suggest that the development of entity/incremental orientation may occur as early as first grade and may have an effect on how young children interpret the actions of others...|$|E
40|$|Thesis (M. Ed.) [...] University of Melbourne,Faculty of Education, 1998 The Schools of the Future program {{introduced}} {{a series of}} educational reforms into Victoria, Australia leading {{to the development of}} self-managing schools within a state wide framework. One of the key initiatives of Schools of the Future was the introduction of a new career structure for principals, teachers and school support officers and the implementation of local. selection for all positions. This program is known as the Professional Recognition Program for Teachers and was introduced initially in 1995, at which time participation was voluntary. In July 1996 the Professional Recognition Program (PRP) became part of the industrial award with the official title of 'Teachers (Victorian Government Schools) Conditions of Employment Award' and participation was no longer voluntary. It has, however, continued {{to be known as the}} Professional Recognition Program or PRP. The Professional Recognition Program provides the framework for a local selection process, probation, annual performance review for Level 1 teachers, performance management for leading teachers, higher duties, special payments and sabbatical leave. The purpose of this thesis has been to examine the implementation of the Professional Recognition Program, from the perspective of the school Principal, at the end of 1997, its first full year in operation. In particular it has aimed to establish the impact that the introduction of the Professional Recognition Program has had at the school level on existing appraisal and professional development planning processes and on teachers' 'progress through the incremental pay scale. It has reviewed the ways in which schools have used their special payments to date. It also reviewed the time and workload issues for Principals involved in implementing the program. The method of research chosen was a questionnaire which was sent to all state schools in the Western Metropolitan Region of Melbourne. The questionnaire was directed to Principals and was designed to seek information on the implementation of the PRP using a mix of pre-coded questions and open comments. The major findings of this research have been that a majority of Principals value the introduction of performance management. In particular they value the opportunity provided by the annual review process to develop shared understandings and goals and to provide feedback and reward achievement. Principals also expressed a high degree of confidence in the professional development planning processes that they have developed in their schools. Principals are concerned however, at the significant cost to them of the increased time and workload that has arisen from the introduction of the PRP. Principals raised specific concerns related to the teachers at the top of the <b>incremental</b> <b>scale</b> whose needs do not seem to have been addressed effectively by the introduction of the PRP. Issues related to the use of accelerated progression and special payments were raised and need to be addressed. Concerns were raised with the lack of consistency of implementation across schools and a need for the provision of further professional development for Principals was raised. Restricted Access: Staff and Students of the University Onl...|$|E
40|$|Ultra-high precis {{measurements}} are domain of lasers interferometers. An optical resonator measuring method using {{broad spectrum of}} radiation of an optical frequency comb was designed and experimentally verified at our workplace. The measuring of a quantity – a distance of resonator mirrors – is provided by its conversion {{to the value of}} repetition frequency of the pulse laser with mode-locked optical frequency comb. In this paper the comparison of the absolute scale of the optical resonator with an <b>incremental</b> interferometer <b>scale</b> is introduced. The incremental interferometer is implemented for verification of the optical resonator scale. The double beam incremental interferometer is operating at the wavelength of 633 nm and the measuring mirror with piezo actuator is used as one of its reflectors. It turns out that the major error signal is the reflection of the periodic nonlinearity of the <b>incremental</b> resonator <b>scale.</b> The relative resolution of our method reaches values up to 10 - 9 while maintaining measuring scale...|$|R
40|$|Cluster {{hash tables}} (CHTs) are key {{components}} of many large-scale Internet services due to their highly-scalable performance and the prevalence {{of the type of}} data they store. Another advantage of CHTs is that they can be designed to be as self-managing as a cluster of stateless servers. One key to achieving this extreme manageability is reboot-based recovery that is predictably fast and has modest impact on system performance and availability. This “cheap ” recovery mechanism simplifies management in two ways. First, it simplifies failure detection by lowering the cost of acting on false positives. This enables one to use statistical techniques to turn hard-to-catch failures, such as node degradation, into failure, followed by recovery. Second, cheap recovery simplifies capacity planning by recasting repartitioning as failure plus recovery to achieve zero-downtime <b>incremental</b> <b>scaling.</b> These low-cost recovery and scaling mechanisms make it possible for the system to be continuously self-adjusting, a key property of self-managing systems...|$|R
40|$|Determination of the {{intentions}} of the test developer is fundamental to the choice of the analytical model for a rating scale. For confirmatory analysis, the developer's intentions inl-m the choice of the general form of the model, representing {{the manner in which the}} respondent interacts with the scale; these intentions also inform the choice of the precise statement of that form, representing the intention of the analyst to construct, for example, an "equal-interval " scale. The nature of the Likert rating scale is discussed. Examples of general forms and precise statements are given. Forms of the measurement model discussed include the dichotomous case, the Andrich model for holistic scales, the Glas model for <b>incremental</b> <b>scales,</b> and the McCullagh model for incidental scales. Mc-ns of modeling and communicating the intentional form of the scale are outlined. Other issues addressed include incorporating the developer's intentions, anchoring the scale calibrations, and general structural concepts. A sample design problem is presented. Two tables and 16 figures are included. (TJH) ***********************tA**A******M*A******A********ARA**************** * Reproductions supplied by EDRS are the best that can be made * * from the original document. * U. E. atemrasawr OF EDUCATIO...|$|R
40|$|E‐Collaboration {{and what}} it means for the modern {{business}} world is attracting more and more the attention of today’s leaders and professionals. Especially organizations whose products and services are interactively created and used by global teams consisting of customers and suppliers have every reason to understand E‐Collaboration for its many benefits and opportunities. This bachelor thesis investigates how E‐Collaboration can scale the information processing capacity of international sales organizations using the example of va‐Q‐tec Ltd ECollaboration tool requirements are defined taking the circumstances of va‐Q‐tec Ltd into consideration. The findings of the study show that an E‐Collaboration tool with resource management, workflow and dashboard tool features are most needed to scale va‐Q‐tec’s information processing capacity. Furthermore, this paper explores different aspects of ECollaboration including the basic components of collaboration, the <b>incremental</b> <b>scaling</b> of information processing capacity and the circumstances of today’s international sales organizations. Empirical findings reveal that scaling information processing capacity requires central storage and processor systems supported by information technology. Scaling information processing capacity by increasing the workforces is found to be inefficient. Selfservice interfaces allowing 24 / 7 information access and exchange are the new benchmark for sales organizations...|$|R
40|$|This paper uses a {{new data}} source to {{investigate}} whether wages rise more with seniority in unionized or nonunionized workplaces. The data distinguish establishments that have <b>incremental</b> wage <b>scales</b> with automatic progression by seniority. For unions with seniority scales, the union wage differential is increasing with seniority. This {{is not the case}} for unions without seniority scales. Taking account of this heterogeneity, the authors are able to reconcile previous paradoxical empirical findings. The results provide support for discriminating monopoly models of the trade union and have important efficiency and distributional implications. Copyright 1996 by The London School of Economics and Political Science. ...|$|R
30|$|Up to now, the {{implicit}} regularization of the correlation procedure {{is related to}} the definition of ZOIs (in a local approach) or elements (in a global approach) and the displacement interpolations therein since the inversion problem cannot be solved at the voxel <b>scale.</b> <b>Incremental</b> FE-based DVC {{can be seen as a}} strong regularization of local incremental DVC.|$|R
40|$|Working with soil, sand, powders, ores, {{cement and}} {{sintered}} bricks, excavating, grading construction sites, driving off-road, transporting granules in chutes and pipes, sifting gravel, separating solids from gases, and using hoppers are so routine {{that it seems}} straightforward to execute these operations on the Moon and Mars as we do on Earth. We discuss how little these processes are understood and point out the nature of trial-and-error practices {{that are used in}} today s massive over-design. Nevertheless, such designs have a high failure rate. Implementation and extensive <b>incremental</b> <b>scaling</b> up of industrial processes are routine because of the inadequate predictive tools for design. We present a number of pragmatic scenarios where granular materials play a role, the risks involved, what some of the basic issues are, and what understanding is needed to greatly reduce the risks. This talk will focus on a particular class of granular flow issues, those that pertain to dense materials, their physics, and the failure problems associated with them. In particular, key issues where basic predictability is lacking include stability of soils for the support of vehicles and facilities, ability to control the flow of dense materials (jamming and flooding/unjamming at the wrong time), the ability to predict stress profiles (hence create reliable designs) for containers such as bunkers or silos. In particular, stress fluctuations, which are not accounted for in standard granular design models, can be very large as granular materials flows, and one result is frequent catastrophic failure of granular devices...|$|R
40|$|International audienceThe metal {{foundations}} of offshore wind turbines are highly {{sensitive to the}} fatigue phenomenon. To date, current methods of fatigue design proposed in the regulations are an obstacle to the structural optimization and to the consideration of hazards. In this context, we propose an <b>incremental</b> two <b>scales</b> model of damage in order to follow the time evolution of the damage parameter. This time notion {{is important to the}} update of the model parameters using records from the Structural Health Monitoring. In this article, we focus on updating the parameters of the damage model using experimental data and the method of Bayesian updating based on an MCMC algorithm...|$|R
40|$|D ow nloaded from account, and the widths {{of growth}} {{increments}} in different directions. The model {{is used to}} formalize procedures necessary for the quantification of fish scale growth rate. The capability of the model for analysing objects with similar structural attributes as found in fish <b>scale</b> <b>incremental</b> patterns, such as those found in coral, otoliths, shells, and bones, is demonstrated...|$|R
40|$|With {{the advent}} of video sharing websites, the amount of videos on the {{internet}} grows rapidly. Web video categorization is an efficient methodology for organizing the huge amount of videos. In this paper we investigate the characteristics of web videos, and make two contributions for the large <b>scale</b> <b>incremental</b> web video categorization. First, we develop an effective semantic feature space Concept Collection for Web Video with Categorization Distinguishability (CCWV-CD), which is consisted of concepts with small semantic gap, and the concept correlations are diffused by a novel Wikipedia Propagation (WP) method. Second, we propose an incremental support vector machine with fixed number of support vectors (n-ISVM) for large <b>scale</b> <b>incremental</b> learning. To evaluate the performance of CCWV-CD, WP and n-ISVM, we conduct extensive experiments on the dataset of 80, 021 most representative videos on a video sharing website. The experiment {{results show that the}} CCWV-CD and WP is more representative for web videos, and the n-ISVM algorithm greatly improves the efficiency in the situation of incremental learning...|$|R
50|$|General Work {{competencies}} {{are most}} often expressed as <b>incremental</b> competency proficiency <b>scales</b> - in other words, proficiency at one level assumes proficiency at all levels below that level on the scale. Work Specific competencies, on the other hand, may be expressed as common group requirements and, where required, differences in proficiency requirements (by level of responsibility in a specified field of work) may be noted.|$|R
50|$|Organizations {{typically}} include <b>incremental</b> competency proficiency <b>scales</b> {{as part of}} {{the overall}} competency structure. These scales reflect the amount of proficiency typically required by the organization within a competency area. For example, communication skills may be a requirement for most entry-level jobs {{as well as at the}} Executive levels; however, the amount of communication proficiency needed at these two levels may be quite different.|$|R
40|$|Due to both {{wave and}} wind fluctuation, the metal {{foundations}} of offshore wind turbines are highly submitted to fatigue. To date, current methods of fatigue design {{proposed in the}} regulations are an obstacle to the structural optimization and to the consideration of some time-variant hazards. In this context, we propose an <b>incremental</b> two <b>scales</b> model of damage in order to follow the time evolution of the damage. This temporal notion is important for updating of the model parameters using records from the Structural Health Monitoring. In this paper, we focus on sensitivity analysis and updating {{the parameters of the}} damage model using experimental data and the method of Bayesian updating based on a Monte Carlo Markov Chain algorithm...|$|R
40|$|Simultaneous somatic patch-pipette {{recording}} {{of a single}} astrocyte to evoke voltage-gated calcium currents, and Ca^ 2 + imaging, were used to study the spatial and temporal profiles of depolarization-induced changes in intracellular Ca^ 2 +([Ca^ 2 +]_i) in the processes of cultured rat cortical astrocytes existing as pairs. Transient Ca^ 2 + changes locked to depolarization were observed as microdomains in the processes of the astrocyte pairs, and the responses were more pronounced in the adjoining astrocyte. Considering the functional significance of higher concentrations of glutamate observed in certain pathological conditions, Ca^ 2 + transients were recorded following pretreatment of cells with glutamate (500 lM for 20 min). This showed distance-dependent <b>incremental</b> <b>scaling</b> and attenuation {{in the presence of}} the metabotropic glutamate receptor (mGluR) antagonist, α-methyl(4 -carboxy-phenyl) glycine (MCPG). Estimation f local Ca^ 2 + diffusion coefficients in the astrocytic processes indicated higher values in the adjoining astrocyte of the glutamate pretreated group. Intracellular heparin introduced into the depolarized astrocyte did not affect the Ca^ 2 + transients in the heparin-loaded astrocyte but attenuated the Ca^ 2 +([Ca^ 2 +]_i) responses in the adjoining astrocyte, suggesting that inositol 1, 4, 5 triphosphate (IP_ 3) may be the transfer signal. The uncoupling agent, 1 -octanol, attenuated the Ca^ 2 +([Ca^ 2 +]_i) responses in both the control and lutamate pretreated astrocytes, indicating the role of gap junctional communication. Our studies indicate that individual astrocytes have distinct functional domains, and that the glutamateinduced alterations in Ca^ 2 + signaling involve a sequence of intra- and intercellular steps in which phospholipase C (PLC), IP_ 3, internal Ca^ 2 + stores, VGCC and gap junction channels appear to play an important role...|$|R
40|$|In this work, the phenomenological viscoplastic DSGZ model (Duan et al., 2001 [13]), {{developed}} for glassy or semi-crystalline polymers, is numerically implemented in a three-dimensional framework, following an implicit formulation. The computational methodology {{is based on}} the radial return mapping algorithm. This implicit formulation leads to the definition of the consistent tangent modulus which permits the implementation in <b>incremental</b> micromechanical <b>scale</b> transition analysis. The extended model is validated by simulating the polypropylene thermoplastic behavior at various strain rates (from 0. 92 s− 1 to 258 s− 1) and temperatures (from 20 °C to 60 °C). The model parameters for the studied material are identified using a heuristic optimization strategy based on genetic algorithm. The capabilities of the new implementation framework are illustrated by performing finite element simulations for multiaxial loading...|$|R
40|$|Introduction Well-organised {{practices}} deliver higher-quality care. Yet {{there has}} been very little effort so far to help primary care organisations achieve higher levels of team performance {{and to help them}} identify and prioritise areas where quality improvement efforts should be concentrated. No attempt at all has been made to achieve a method which would be capable of providing comparisons—and the stimulus for further improvement—at an international level. Methods The development of the International Family Practice Maturity Matrix took place in three phases: (1) selection and refinement of organisational dimensions; (2) development of <b>incremental</b> <b>scales</b> based on a recognised theoretical framework; and (3) testing the feasibility of the approach on an international basis, including generation of an automated web-based benchmarking system. Results This work has demonstrated the feasibility of developing an organisational assessment tool for primary care organisations that is sufficiently generic to cross international borders and is applicable across a diverse range of health settings, from state-organised systems to insurer-based health economies. It proved possible to introduce this assessment method in 11 countries in Europe and one in Africa, and to generate comparison benchmarks based on the data collected. The evaluation of the assessment process was uniformly positive with the view that the approach efficiently enables the identification of priorities for organisational development and quality improvement {{at the same time as}} motivating change by virtue of the group dynamics. Conclusions We are not aware of any other organisational assessment method for primary care which has been ‘born international,’ and that has involved attention to theory, dimension selection and item refinement. The principal aims were to achieve an organisational assessment which gains added value by using interaction, engagement comparative benchmarks: aims which have been achieved. The next step is to achieve wider implementation and to ensure that those who undertake the assessment method ensure linkages are made to planned investment in organisational development and quality improvement. Knowing the problems is only half the story...|$|R
40|$|For more {{publications}} {{and information on}} the International Family Practice Maturity Matrix, see [URL] Well-organised practices deliver higher-quality care. Yet there has been very little effort so far to help primary care organisations achieve higher levels of team performance {{and to help them}} identify and prioritise areas where quality improvement efforts should be concentrated. No attempt at all has been made to achieve a method which would be capable of providing comparisons [...] and the stimulus for further improvement [...] at an international level. METHODS: The development of the International Family Practice Maturity Matrix took place in three phases: (1) selection and refinement of organisational dimensions; (2) development of <b>incremental</b> <b>scales</b> based on a recognised theoretical framework; and (3) testing the feasibility of the approach on an international basis, including generation of an automated web-based benchmarking system. RESULTS: This work has demonstrated the feasibility of developing an organisational assessment tool for primary care organisations that is sufficiently generic to cross international borders and is applicable across a diverse range of health settings, from state-organised systems to insurer-based health economies. It proved possible to introduce this assessment method in 11 countries in Europe and one in Africa, and to generate comparison benchmarks based on the data collected. The evaluation of the assessment process was uniformly positive with the view that the approach efficiently enables the identification of priorities for organisational development and quality improvement {{at the same time as}} motivating change by virtue of the group dynamics. CONCLUSIONS: We are not aware of any other organisational assessment method for primary care which has been 'born international,' and that has involved attention to theory, dimension selection and item refinement. The principal aims were to achieve an organisational assessment which gains added value by using interaction, engagement comparative benchmarks: aims which have been achieved. The next step is to achieve wider implementation and to ensure that those who undertake the assessment method ensure linkages are made to planned investment in organisational development and quality improvement. Knowing the problems is only half the story. status: publishe...|$|R
40|$|Abstract—In this paper, {{we present}} a novel {{parallel}} coordinates design integrated with points (Scattering Points in Parallel Coor-dinates, SPPC), {{by taking advantage of}} both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated Dimensional <b>Incremental</b> Multidimensional <b>Scaling</b> (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks...|$|R
40|$|High coral {{cover and}} {{topographic}} complexity are favorable qualities {{of a healthy}} coral reef. Because coral reef restoration is expensive and coral growth is naturally slow, {{there is a need}} to strategically arrange coral transplants to maximize coral cover and topographic complexity. Similarly, it is important to understand how differences in the life history characteristics of coral transplants can influence changes in the structural attributes of coral reefs. This study utilizes agent-based computer modeling to explore the different spatial scenarios of coral transplantation using corals with contrasting r- and K-selected life histories. Spatial indexes are used to compare coral cover and topographic complexity at <b>incremental</b> time <b>scales,</b> within which disturbance events are of minor importance in spatial structuring. The outcomes of the model suggest that even-spaced grided transplanting arrangements provide the fastest increase in coral cover and three-dimensional habitat space (topographic complexity) across large temporal scales (< 30 years) for corals with r-selected life history strategies...|$|R
40|$|In this paper, {{we present}} a novel {{parallel}} coordinates design integrated with points (Scattering Points in Parallel Coordinates, SPPC), {{by taking advantage of}} both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated Dimensional <b>Incremental</b> Multidimensional <b>Scaling</b> (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks...|$|R
40|$|Abstract—Recent work in {{structure}} from motion (SfM) has built 3 D models from large collections of images downloaded from the Internet. Many approaches {{to this problem}} use incremental algorithms that solve progressively larger bundle adjustment problems. These <b>incremental</b> techniques <b>scale</b> poorly as the image collection grows, and can suffer from drift or local minima. We present an alternative framework for SfM based on finding a coarse initial solution using hybrid discrete-continuous optimization, and then improving that solution using bundle adjustment. The initial optimization step uses a discrete Markov random field (MRF) formulation, coupled with a continuous Levenberg-Marquardt refinement. The formulation naturally incorporates various sources of information about both the cameras and points, including noisy geotags and vanishing point estimates. We test our method on several large-scale photo collections, including one with measured camera positions, and show that it produces models {{that are similar to}} or better than those produced by incremental bundle adjustment, but more robustly and in a fraction of the time. Index Terms—Structure from motion, 3 D reconstruction, Markov random fields, belief propagation F...|$|R
40|$|Recent work in {{structure}} from motion (SfM) has successfully built 3 D models from large unstructured collections of images downloaded from the Internet. Most approaches use incremental algorithms that solve progressively larger bundle adjustment problems. These <b>incremental</b> techniques <b>scale</b> poorly {{as the number}} of images grows, and can drift or fall into bad local minima. We present an alternative formulation for SfM based on finding a coarse initial solution using a hybrid discrete-continuous optimization, and then improving that solution using bundle adjustment. The initial optimization step uses a discrete Markov random field (MRF) formulation, coupled with a continuous Levenberg-Marquardt refinement. The formulation naturally incorporates various sources of information about both the cameras and the points, including noisy geotags and vanishing point estimates. We test our method on several large-scale photo collections, including one with measured camera positions, and show that it can produce models that are similar to or better than those produced with incremental bundle adjustment, but more robustly and in a fraction of the time. 1...|$|R
