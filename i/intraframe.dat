187|5|Public
5000|$|Because {{interframe}} compression copies {{data from}} one frame to another, if the original frame is simply cut out (or lost in transmission), the following frames cannot be reconstructed properly. Some video formats, such as DV, compress each frame independently using <b>intraframe</b> compression. Making 'cuts' in intraframe-compressed video {{is almost as}} easy as editing uncompressed video: one finds the beginning and ending of each frame, and simply copies bit-for-bit each frame that one wants to keep, and discards the frames one doesn't want. Another difference between <b>intraframe</b> and interframe compression is that, with <b>intraframe</b> systems, each frame uses a similar amount of data. In most interframe systems, certain frames (such as [...] "I frames" [...] in MPEG-2) aren't allowed to copy data from other frames, so they require much more data than other frames nearby.|$|E
5000|$|It {{is simple}} to {{implement}} because {{it uses a}} mature compression standard (JPEG) with well-developed libraries, {{and it is an}} <b>intraframe</b> method of compression.|$|E
5000|$|In {{order to}} {{facilitate}} instant random access to any frame during editing, all SheerVideo codecs use only <b>intraframe</b> compression, meaning that every frame is a keyframe.|$|E
30|$|Visual degradation: since <b>intraframes</b> {{are very}} {{important}} in MPEG compression (all B- and P-frames are computed accordingly to I-frames), by encrypting them, high-visual degradation is achieved.|$|R
40|$|We use a {{new method}} based on {{discrete}} fuzzy transforms for coding/decoding frames of color videos {{in which we}} determine dynamically the GOP sequences. Frames can be differentiated into <b>intraframes,</b> predictive frames, and bidirectional frames, and we consider particular frames, called Δ-frames (resp., R-frames), for coding P-frames (resp., B-frames) by using two similarity measures based on Lukasiewicz -norm; moreover, a preprocessing phase is proposed to determine similarity thresholds for classifying the above types of frame. The proposed method provides acceptable results in terms of quality of the reconstructed videos {{to a certain extent}} if compared with classical-based F-transforms method and the standard MPEG- 4...|$|R
30|$|In video {{compression}} technologies, such as MEPG and H. 264 [4], encoded pictures (or frames) {{are arranged in}} groups of pictures (GOPs). An encoded video stream consists of successive GOPs. A GOP can contain the following frame types: I-frame, P-frame, and B-frame. The order of <b>intraframes</b> and interframes is specified in a GOP. An I-frame is a reference picture which is intracoded corresponding to a fixed image and it is independent of other pictures. A P-frame is predictive-coded frame which contains motion-compensated difference information from the preceding I- or P-frame. A B-frame is bidirectionally predictive-coded frame which contains different information from the preceding and following I- or P-frame within a GOP. I-frame and P-frame are {{often referred to as}} anchor frames. A GOP always begins with an I-frame. Afterwards, several P-frames follow. The B-frames are inserted between two consecutive anchor frames.|$|R
5000|$|MPEG IMX - a {{standard}} definition professional video recording format. Uses <b>intraframe</b> compression, 4:2:2 color subsampling and user-selectable constant video data rate of 30, 40 or 50 Mbit/s.|$|E
5000|$|DV uses lossy {{compression}} of video while audio is stored uncompressed. [...] An <b>intraframe</b> video compression scheme {{is used to}} compress video on a frame-by-frame basis with the discrete cosine transform (DCT).|$|E
50|$|One of {{the most}} {{powerful}} techniques for compressing video is interframe compression. Interframe compression uses one or more earlier or later frames in a sequence to compress the current frame, while <b>intraframe</b> compression uses only the current frame, effectively being image compression.|$|E
40|$|Rate control plays a {{key role}} in video coding standards. Its goal is to achieve a good quality at a given target bit-rate. In H. 264 /AVC, rate control {{algorithm}} for both Intra and Inter-frames suffers from some defects. In the Intra-frame rate control, the initial quantization parameter (QP) is mainly adjusted according to a global target bit-rate and length of GOP. This determination is inappropriate and generates errors in the whole of video sequence. For Inter coding unit (Frame or Macroblock), the use of MAD (Mean Average Differences) as a complexity measure, remains inefficient, resulting in improper QP values because the MAD handles locally images characteristics. QP miscalculations may also result from the linear prediction model which assumes similar complexity from coding unit to another. To overcome these defects, we propose in this paper, a new Rate-Quantization (R-Q) model resulting from extensive experiments. This latter is divided into two models. The first one is an Intra R-Q model used to determine an optimal initial quantization parameter for <b>Intraframes.</b> The second one is an Inter R-Q model that aims at determining the QP of Inter coding unit according to the statistics of the previous coded ones. It does not use any complexity measure and substitutes both linear and quadratic models used in H. 264 /AVC rate controller. Objective and subjective simulations have been carried out using JM 15. 0 reference software. Compared to this latter, the global R-Q model (Intra and Inte...|$|R
40|$|Abstract This paper {{presents}} and analyzes {{a new approach}} to data hiding that embeds in both the intra- and interframes from the H. 264 /AVC video codec. Most of the current video data hiding algorithms take into account only the <b>intraframes</b> for message embedding. This may be attributed to the perception that inter-frames are highly compressed due to the motion compensation, and any embedding message inside these may adversely affect the compression efficiency significantly. Payload of the inter-frames is also thought to be less, compared with the intra-frames, because of the lesser residual data. We analyze data hiding in both intra- and inter-frames over a wide range of QP values and observe that the payload of the inter is comparable with that of the intra-frames. Message embedding, in only those non-zero quantized transform coefficients (QTCs) which are above a specific threshold, enables us to detect and extract the message on the decoding side. There is no significant effect on the overall bitrate and PSNR of the video bitstream because instead of embedding message in the compressed bitstream, we have embedded it during the encoding process by taking into account the reconstruction loop. For the non-zero QTCs, in the case of intra-frames, we benefit from the spatial masking, while in the case of inter-frames, we exploit the motion and texture masking. We can notice that the data hiding is done during the compression process and the proposed scheme takes into account the reconstruction loop. The proposed scheme does not target robustness and the obtaine...|$|R
5000|$|Because {{interframe}} compression copies {{data from}} one frame to another, if the original frame is simply cut out (or lost in transmission), the following frames cannot be reconstructed properly. Making 'cuts' in intraframe-compressed video while video editing {{is almost as}} easy as editing uncompressed video: one finds the beginning and ending of each frame, and simply copies bit-for-bit each frame that one wants to keep, and discards the frames one doesn't want. Another difference between <b>intraframe</b> and interframe compression is that, with <b>intraframe</b> systems, each frame uses a similar amount of data. In most interframe systems, certain frames (such as [...] "I frames" [...] in MPEG-2) aren't allowed to copy data from other frames, so they require much more data than other frames nearby.|$|E
5000|$|... iFrame {{video and}} audio is encoded using lossy {{compression}}. Only <b>intraframe</b> compression is enabled; every frame is a stand-alone i-frame. Video is encoded with the AVC/H.264 compression scheme. Audio is encoded with the AAC codec. The compressed audio and video are multiplexed into a QuickTime file.|$|E
50|$|It is {{possible}} to build a computer-based video editor that spots problems caused when I frames are edited out while other frames need them. This has allowed newer formats like HDV {{to be used for}} editing. However, this process demands a lot more computing power than editing <b>intraframe</b> compressed video with the same picture quality.|$|E
50|$|MPEG IMX allows {{recording}} {{in standard}} definition, using MPEG-2 encoding at data rate of 30, 40 or 50 megabits per second. Unlike most other MPEG-2 implementations, IMX uses <b>intraframe</b> compression with each frame {{having the same}} exact size in bytes to simplify recording onto video tape. Sony claims that at 50 Mbit/s it offers visual quality that is comparable to Digital Betacam MPEG IMX is not supported in the XDCAM EX product line.|$|E
5000|$|While Xpress Pro was {{originally}} aimed at DV and uncompressed standard definition editors, the upgrade to Xpress Pro HD with version 5.0 {{of the software}} added support for high-definition editing with the 8-bit version of Avid's DNxHD codec or Panasonic's DVCPRO HD codec, and version 5.2 added support for HDV editing. Unlike some other editing packages, Xpress Pro HD edits HDV natively by decompressing the MPEG-2 stream on the fly, rather than transcoding into an <b>intraframe</b> codec.|$|E
50|$|Uncompressed video {{delivers}} maximum quality, {{but with}} a very high data rate.A variety of methods are used to compress video streams, with the most effective ones using a Group Of Pictures (GOP) to reduce spatial and temporal redundancy. Broadly speaking, spatial redundancy is reduced by registering differences between parts of a single frame; this task is known as <b>intraframe</b> compression and {{is closely related to}} image compression. Likewise, temporal redundancy can be reduced by registering differences between frames; this task is known as interframe compression, including motion compensation and other techniques. The most common modern standards are MPEG-2, used for DVD, Blu-ray and satellite television, and MPEG-4, used for AVCHD, Mobile phones (3GP) and Internet.|$|E
50|$|The most {{powerful}} used method works by comparing each frame {{in the video}} with the previous one. If the frame contains areas where nothing has moved, the system simply issues a short command that copies {{that part of the}} previous frame, bit-for-bit, into the next one. If sections of the frame move in a simple manner, the compressor emits a (slightly longer) command that tells the decompressor to shift, rotate, lighten, or darken the copy. This longer command still remains much shorter than <b>intraframe</b> compression. Interframe compression works well for programs that will simply be played back by the viewer, but can cause problems if the video sequence needs to be edited.|$|E
50|$|As {{a purely}} <b>intraframe</b> {{compression}} scheme, the image quality of M-JPEG is directly {{a function of}} each video frame's static (spatial) complexity. Frames with large smooth transitions or monotone surfaces compress well {{and are more likely}} to hold their original details with few visible compression artifacts. Frames exhibiting complex textures, fine curves and lines (such as writing on a newspaper) are prone to exhibit DCT artifacts such as ringing, smudging, and macroblocking. M-JPEG-compressed video is also insensitive to motion complexity, i.e. variation over time. It is neither hindered by highly random motion (such as the water-surface turbulence in a large waterfall), nor helped by the absence of motion (such as static landscape shot by tripod), which are two opposite extremes commonly used to test interframe video formats.|$|E
5000|$|MPEG IMX is a 2001 {{development}} of the Digital Betacam format. Digital video compression uses H.262/MPEG-2 Part 2 encoding at a higher bitrate than Betacam SX: 30 Mbit/s (6:1 compression), 40 Mbit/s (4:1 compression) or 50 Mbit/s (3.3:1 compression). Unlike most other MPEG-2 implementations, IMX uses <b>intraframe</b> compression. Additionally, IMX ensures that each frame has the same exact size in bytes to simplify recording onto video tape. Video recorded in the IMX format is compliant with CCIR 601 specification, with eight channels of audio and timecode track. It lacks an analog audio (cue) track as the Digital Betacam, but will read it as channel 7 if used for playback. This format has been standardized in SMPTE 365M and SMPTE 356M as [...] "MPEG D10 Streaming".|$|E
40|$|Abstract. In motion-compensated lifted wavelet video coding, the {{calculation}} of the highpass frame involves interframe prediction. Due to occlusions, or change of intensity, or new objects in the video frame, interframe prediction is not always effective. <b>Intraframe</b> prediction provides an alternative and increases coding efficiency. However, previous analysis shows that these <b>intraframe</b> predicted pixels suffer higher distortion propagation {{than the rest of}} the pixels in the open-loop scheme. The main contribution of this paper is to mitigate this increased distortion through an <b>intraframe</b> update step. We propose a perfectly invertible sequence of operations. In addition, we present theoretical analysis of the reduction in distortion due to the inclusion of the proposed <b>intraframe</b> update step for various <b>intraframe</b> prediction modes. This is compared with practical measurements. Index Terms lifted wavelet, intra prediction, update step...|$|E
40|$|A hybrid image {{predictive}} coding method is presented. The <b>intraframe</b> predictor is an adaptive FIR filter using the wellknown LMS algorithm to track continuously spatial local {{characteristics of the}} intensity. The interframe predictor is motion-adaptive using a pel-recursive method estimating the displacement vector. A weight coefficient is adapted continuously in order to favour the prediction mode which performs better between <b>intraframe</b> and motion compensation mode. For the sequence examined a significant improvement is obtained in comparison with only adaptive <b>intraframe</b> or only motion compensation mode. A crucial problem in {{predictive coding}}, particularly with adaptive techniques, is that of sensitivity to transmission errors. A method ensuring the autoadjustment of the decoder {{in the presence of}} isolated transmission errors is proposed for the <b>intraframe</b> mode. Neither overhead information nor error-correcting code are needed. I...|$|E
30|$|In WPS, <b>intraframe</b> {{swapping}} {{is first}} attempted {{to compensate the}} flow with dirty channel. If <b>intraframe</b> swapping fails, WPS tries to adjust the system of credit/debit. This presents the effective weight of flow {{at the beginning of}} the frame. WPS alleviates the problem that the large lagging flow captures the channel in IWFQ.|$|E
40|$|Speech {{enhancement}} using iterative Wiener filtering {{has been}} shown to require interframe and <b>intraframe</b> constraints in all-pole parameter estimation. In this correspondence, we show that a clean speech VQ codebook is more effective in providing <b>intraframe</b> constraints and, hence, better convergence of the iterative filtering scheme. Satisfactory speech enhancement results are obtained with a small codehook of 128, and the algorithm is effective for both white noise and pink noise up to 0 dB SNR...|$|E
40|$|Spatial {{transform}} coding {{has been widely}} applied for image compression because of its high coding efficiency. However, in many <b>intraframe</b> systems, in which every TV frame is independently processed, coding of moving objects {{in the case of}} interlaced input signals is not addressed. In this paper, we extend <b>intraframe</b> {{transform coding}} techniques for interlaced video signals with limited additional complexity. After discussing key aspects of an interlaced video signal, we present a simple motion-detection scheme which is suitable for an a priori block-coding decision, thereby saving hardware complexity. The transformer is modified to obtain either <b>intraframe</b> or intrafield transformed blocks by performing partially different fast cosine computation algorithms. As a result, the subjective image quality of the motion-adaptive coding technique is considerably improved as compared with the nonadaptive system...|$|E
40|$|H. 264 is an Advanced Video Coding {{standard}} that gives better coding efficiency {{than the previous}} standards. In H. 264, video compression is carried out in many ways such as Interframe prediction and <b>Intraframe</b> prediction. <b>Intraframe</b> prediction is {{carried out by the}} process of motion estimation by calculating motion vectors. <b>Intraframe</b> prediction reduces spatial redundancy (i. e.) similarity between pixels and Interframe prediction reduces the temporal redundancy (i. e.) change in video content from one frame to the next frame. In this paper we compare these two compression schemes of H. 264 in terms of compression ratio, PSNR and memory bandwidth. Finally we conclude that intra prediction method provides better video quality with average compression ratio 1. 034 and the percentage of memory saving is 96. 26 % but the average PSNR value is less compared to motion estimation...|$|E
30|$|There are no <b>intraframe</b> {{permutation}} errors, meaning that, {{assuming the}} amplitude estimates within a frame are correct, {{they will always}} be assigned to the correct source.|$|E
40|$|In a {{television}} system a digital picture signal {{is subjected to}} a transform coding {{for the purpose of}} bit rate reduction. In order to detect motion effects between the two fields of a picture, these fields are also examined in a motion detector 8310. If no motion is detected, <b>intraframe</b> transform is employed and if motion is detected intrafield transform is employed. Small motion effects can be eliminated by subjecting the picture signal to a median filtering before subjecting it to an <b>intraframe</b> transform...|$|E
30|$|Each message can be encoded to bit streams using current {{standard}} codec. Here, H. 264 encoder {{is chosen}} and obviously the proposed scheme {{is compatible with}} the standard codec. It is noted that in each message flexible group of picture (GOP) is employed which is helpful to refresh <b>intraframe</b> adaptively. Compared with the uniform period of <b>intraframe,</b> adaptive refreshment can keep up with the motion change between frames, so better temporal correlation can be maintained to achieve better error concealment if frame loss occurs in one message at the decoder.|$|E
40|$|In this paper, {{we present}} a fast mode {{decision}} method for H. 263 to H. 264 /AVC <b>intraframe</b> transcoding. The proposed algorithm {{is based on the}} observation that features of DCT coefficients extracted from H. 263 coded <b>intraframe</b> strongly relates to the optimal mode in H. 264 /AVC intra mode decision. Specifically, the total number of non-zero AC coefficients of four 8 x 8 DCT blocks in H. 263 is taken as a measurement in the intra block size decision. The objective is to reject improbable block types in earlier stages in order to achieve computation saving. In addition, a transform domain edge direction estimation is also adopted into our scheme to further speed up the intra mode prediction. Simulation results show that the proposed approach can reduce the computational complexity of <b>intraframe</b> transcoding by up to 65 % while maintaining the rate-distortion (R-D) performance. Department of Electronic and Information EngineeringRefereed conference pape...|$|E
40|$|Includes bibliographical {{references}} (leaf [61]) The {{objective of}} this study is to evaluate the compression performance of several variations of the JPEG-LS compression algorithm for video sequence compression, when interframe predictions are employed in addition to the standard <b>intraframe</b> predictions. <b>Intraframe</b> predictor of the JPEG-LS standard uses neighboring pixels of current pixel x to predict its value. Interframe predictions are implemented via the block matching technique. Optimal and sub-optimal search algorithms are investigated for block matching to evaluate the level of compression degradation caused by sub-optimal algorithms. Sub-optimal algorithms used in this study are two-dimensional logarithmic, three-step, orthogonal, and one-at-a-time search algorithms. Fixed and variable-size block matching techniques are employed to reveal their effects on the compression performance of JPEG-LS. High and low-motion video sequences are utilized to evaluate the performance of the algorithms. Performance results for three different cases are presented in this thesis. In the first case, only the <b>intraframe</b> predictions are used in the JPEG-LS. It is important to note that the compression rates obtained from the first case reflect the performance of the standard JPEG-LS algorithm and help us to form a benchmark for comparison purposes. The second case involves using only interframe predictions in the JPEG-LS scheme. In the third and final case, both interframe and <b>intraframe</b> predictions are calculated and the predictions yielding less prediction error are used. M. S. (Master of Science...|$|E
40|$|A wavelet-based video coder {{built on}} the {{principles}} of distributed source coding is described. The encoder employs a syndrome-based encoding strategy for intercoded coefcients while other co-efcients are intracoded using an embedded wavelet-based coder designed for the coding of arbitrarily shaped image objects. The de-coder uses a reference frame in the domain of a redundant wavelet transform to search for blocks matching the syndrome received from the encoder in order to decode intercoded coefcients. Ex-perimental results indicate that, due to improved <b>intraframe</b> coding, the proposed wavelet-based algorithm signicantly outperforms a similar technique constructed with JPEG-like <b>intraframe</b> coding. 1...|$|E
40|$|In this letter, {{we present}} an {{adaptive}} <b>intraframe</b> rate-quantization (R-Q) model for H. 264 /AVC video coding. The proposed method aims at selecting accurate quantization parameters (QP) for intra-coded frames {{according to the}} target bit rate. By taking gradient-based frame complexity measure into consideration, the model parameters can be adaptively updated. Experimental results show that when employing our proposed R-Q model, the <b>intraframe</b> target bits mismatch ratio can be reduced by up to 75 % {{as compared to the}} traditional Cauchy-density-based model. Hence, this is extremely useful for H. 264 /AVC rate control applications. Department of Electronic and Information Engineerin...|$|E
40|$|An {{efficient}} Block-based Trellis Quantization (BTQ) {{scheme is}} {{proposed for the}} quantization of the Line Spectral Frequencies (LSF) in speech coding applications. The scheme {{is based on the}} modelling of the LSF <b>intraframe</b> dependencies with a trellis structure. The ordering property and the fact that LSF parameters are bounded within a range is explicitly incorporated in the trellis model. BTQ search and design algorithms are discussed and an efficient algorithm for the index generation (finding the index of a path in the trellis) is presented. Also the Sequential Vector Decorrelation Technique is presented to effectively exploit the <b>intraframe</b> correlation of LSF parameters within the trellis. Based on the proposed Block-based Trellis Quantizer, two <b>intraframe</b> schemes and one interframe scheme are proposed. Comparisons to the Split-VQ [13], the Trellis Coded Quantization of LSF parameters [15], and the Multi-Stage VQ [12], as well as the interframe scheme used in IS- 641 EFRC [28] and the GSM AMR codec [29] are provided. These results demonstrate that the proposed BTQ schemes outperform the above systems...|$|E
40|$|Abstract—In this letter, {{we present}} an {{adaptive}} <b>intraframe</b> rate-quantization (R-Q) model for H. 264 /AVC video coding. The pro-posed method aims at selecting accurate quantization parameters (QP) for intra-coded frames {{according to the}} target bit rate. By taking gradient-based frame complexity measure into consider-ation, the model parameters can be adaptively updated. Experi-mental results show that when employing our proposed R-Q model, the <b>intraframe</b> target bits mismatch ratio can be reduced by up to 75 % {{as compared to the}} traditional Cauchy-density-based model. Hence, this is extremely useful for H. 264 /AVC rate control appli-cations. Index Terms—Frame complexity, H. 264 /AVC, rate control, rate-quantization. I...|$|E
40|$|Television {{system in}} which digitalized picture signals {{subjected}} to a transform coding are transmitted from an encoding station to a decoding station. In a television system a digital picture signal is subjected to a transform coding {{for the purpose of}} bit rate reduction. In order to detect motion effects between the two fields of a picture, these fields are also examined in a motion detector 8310. If no motion is detected, <b>intraframe</b> transform is employed and if motion is detected intrafield transform is employed. Small motion effects can be eliminated by subjecting the picture signal to a median filtering before subjecting it to an <b>intraframe</b> transform...|$|E
