11|250|Public
5000|$|His {{achievements}} {{include the}} development of chart parsing and <b>functional</b> <b>unification</b> <b>grammar</b> and major contributions to the application of finite state automata in computational phonology and morphology. He is also regarded as a leading authority on machine translation.|$|E
40|$|UI on the Fly is {{a system}} that {{dynamically}} presents coordinated multimodal content through natural language and a small-screen graphical user interface. It adapts to the user's preferences and situation. Multimodal <b>Functional</b> <b>Unification</b> <b>Grammar</b> (MUG) is a unification-based formalism that uses rules to generate content that is coordinated across several communication modes. Faithful variants are scored with a heuristic function...|$|E
40|$|A {{grammatical}} description often {{applies to}} a linguistic object only when that object has certain features. Such conditlonal descriptions can be indirectly modeled in Kay's <b>Functional</b> <b>Unification</b> <b>Grammar</b> (FUG) using functional descrlptions that are embedded within disjunctive alternatlves. An extension to FUG is proposed {{that allows for}} a direct representation of condltional descriptions. This extension {{has been used to}} model the input condltlons on the systems of systemlc grammar. Conditional descriptions are formally defined in terms of logical implicatlon and negatlon. This formal deftnltlon enables the use of conditional descrlptions as a general notatlonal extension to any of the unification-based gram mar representation systems currently used in computational linguistics...|$|E
40|$|Standard <b>Functional</b> <b>Unification</b> <b>Grammars</b> (FUGs) {{provide a}} {{structurally}} guided top-down control regime for text generation {{that is not}} appropriate for handling non-structural and dynamic constraints. We introduce two control tools that we have implemented for FUGs to address these limitations: bk-class, a tool to limit search by using a form of dependency-directed backtracking and external, a co-routine mechanism allowing a FUG to cooperate with dynamic constraint sources. We show how these tools complement the top-down regime of FUGs to enhance lexical choice...|$|R
40|$|<b>Functional</b> <b>Unification</b> <b>Grammars</b> (FUGs) {{are popular}} for natural {{language}} applications because the formalism uses very few primitives and is uniform and expressive. In our work on text generation, {{we have found}} that it also has annoying limitations: it is not suited for the expression of simple, yet very common, taxonomic relations and it does not allow the specification of completeness conditions. We have implemented an extension of traditional <b>functional</b> <b>unification.</b> This extension addresses these limitations whiIe preserving the desirable properties of FUGs. It is based on the notions of typed features and typed constituents. We show the advantages of this extension {{in the context of a}} grammar used for text generation...|$|R
40|$|We {{address the}} problem of {{generating}} adjectives in a text generation system. We distinguish between usages of adjectives informing the hearer of a property of an object and usages expressing an intention of the speaker, or an argumentative orientation. For such argumentative usages, we claim that a generator cannot simply map from information in the knowledge base to adjectives. Instead, we identify various knowledge sources necessary to decide whether to use an adjective, what adjective should be selected and what syntactic function it should have. We show how these decisions interact with lexical properties of adjectives and the syntax of the clause. We propose a mechanism for adjective selection and illustrate {{it in the context of}} the explanation component of the ADVISOR expert system. We describe an implementation of adjective selection using a version of <b>Functional</b> <b>Unification</b> <b>Grammars...</b>|$|R
40|$|We {{present an}} {{implemented}} procedure to select an appropriate connective to link two propositions, {{which is part}} of a large text generation system. Each connec- tive is defined as a set of constraints between features of fire propositions it connects. Our focus has been to identify pragmatic features that can be produced by a deep generator to provide a simple representation of connectives. Using these features, we can account for a variety of connective usages, and we can distinguish between similar connectives. We describe how a surface generator can produce complex sentences when given these features in input. The selection procedure is implemented as part of a large <b>functional</b> <b>unification</b> <b>grammar...</b>|$|E
40|$|With the {{development}} of internet, the audit work of IDS is becoming harder. The way of examining log file in text format cannot adapt to the serious situation. Natural Language Process (NLP) technology is a novel approach to solve this problem. In this paper, <b>Functional</b> <b>Unification</b> <b>Grammar</b> (FUG) in NLP was applied to intelligent query in IDS audit system, and XML schema was also employed in expression of accidence, syntax, vocabulary library and grammar. We utilized feature structure to describe the structure of vocabulary, phrase and sentence. SQL query object tree could be translated into SQL sentence easily with translation algorithm. We also took some steps to make the query fuzzy so as to give the query system more intelligence...|$|E
40|$|Consisting of two {{separate}} papers, "Representational Issues in Systemic Functional Grammar, " by Christian Matthiessen and "Systemic Grammar and <b>Functional</b> <b>Unification</b> <b>Grammar,</b> " by Robert Kasper, this document deals with systemic aspects of {{natural language processing}} and linguistic theory and with computational applications of M. A. K. Halliday's systemic functional grammar. The first paper is concerned with representation as it is defined by linguistics [...] how to represent language metalinguistically, or how to talk about talk. Topics covered in the paper include: (1) the lag between theory and representation; (2) dimensions of structure (including a sample grammar and discussion of the structuring, insert, expand, conflate, and preselect operators); (3) mode- of meaning and modes of structure, a characterization of representational problems of constituency, prosody, pulse, and interdependency; (4) modes o...|$|E
40|$|Standard <b>Functional</b> <b>Unification</b> <b>Grammars</b> (FUGs) {{provide a}} {{structurally}} guided top-down control regime for sentence generation. When using FUGs to perform content realization as a whole, including lexical choice, this regime {{is no longer}} appropriate for two reasons: (1) the unification of non-lexicalized semantic input with an integrated lexico-grammar requires mapping "floating" semantic elements which can trigger extensive backtracking and (2) lexical choice requires accessing external constraint sources on demand to preserve the modularity between conceptual and linguistic knowledge. We introduce two control tools that we have implemented for FUGs to address these limitations: bk-class, a form of dependency-directed backtracking to efficiently process "floating" constraints and external, a co-routine mechanism allowing a FUG to cooperate with external constraint sources during unification. We show how these tools complement the top-down regime of FUGs to control the whole content realization process...|$|R
40|$|Standard <b>Functional</b> <b>Unification</b> <b>Grammars</b> (FUGs) {{provide a}} {{structurally}} guided top-down control regime for text generation {{that is not}} appropriate for handling non-structural and dynamic constraints. We introduce two control tools that we have implemented for FUGs to address these limitations: bk-class, a tool to limit search by using a form of dependency-directed backtracking and external, a co-routine mechanism allowing a FUG to cooperate with dynamic constraint sources. We show how these tools complement the top-down regime of FUGs to enhance lexical choice. presses disjunction in FUG. The value of the alt 1 INTRODUCTION keyword {{is a list of}} FDs, each one called a branch. Text generation is the process of choosing linguisWhen unifying an input FD with such a disjunction, tic devices to satisfy various constraints. One of these the unifier non-deterministically selects one branch constraints is the semantic structure representing the that is compatible with the input. Disjunctions [...] ...|$|R
40|$|In this paper, {{we present}} several {{extensions}} to the FU formalism that address these limitations. These extensions {{are based on}} the formal semantics <b>Functional</b> <b>Unification</b> <b>Grammars</b> (FUGs) are presented in (Elhadad, 1990). They have been im- popular for natural language applications because the plemented and tested on several applications. formalism uses very few primitives and is uniform and expressive. In our work on text generation, we have found that it also has annoying limitations: it is not We first introduce the notion of typed features. It suited for the expression of simple, yet very common, allows the definition of a structure over the primitive taxonomic relations and it does not allow the symbols used in the grammar. The unifier can take specification of completeness conditions. We have advantage of this structure {{in a manner similar to}} (Aitimplemented an extension of traditional functional Kaci, 1984). We then introduce the notion of typed unification. This extension addres [...] ...|$|R
40|$|Language {{generation}} {{systems have}} {{used a variety of}} grammatical formalisms for producing syntactic structure and yet, there has been little research evaluating the formalisms for the specifics of the generation task. In our work at Columbia we have primarily used a unification based formalism, a <b>Functional</b> <b>Unification</b> <b>Grammar</b> (FUG) [Kay 79] and have found it well suited for many of the generation tasks we have addressed. Over {{the course of the past}} 5 years we have also explored the use of various off-the-shelf parsing formalisms, including an Augmented Transition Network (ATN) [Woods 70]. a Bottom-Up Chan Parser (BUP) [Finin 84], and a Declarative Clause Grammar (DCG) [Pereira & Warren 80]. In this paper, we identify the characteristics of FDG that we find useful for generation and contrast these with characteristics of the parsing formalisms and with other formalisms that are typically used for generation...|$|E
40|$|Sentence {{generation}} {{will be an}} integral part of future augmentative communication devices. By employing natural language processing techniques, we hope to enhance the speed, flexibility, and ease of use of current word-based systems. In this paper, we discuss the generation component of our "compansion" system, which expands compressed messages entered by the user into full English sentences. The two phases of this component are (1) the translator, which converts a semantic representation of the message into a syntactic "deep structure" representation and (2) the generator, which takes this "deep structure" and uses a <b>functional</b> <b>unification</b> <b>grammar</b> to produce a complete English sentence. Because of this modular design, the generator is independent of whatever semantic representation is used; thus, it could be easily adapted to other systems (e. g., sign language translation) through the use of a different translator. Introduction Sentence {{generation will}} be an important component of m [...] ...|$|E
40|$|This paper {{compares the}} use of Lisp and Prolog for the {{implementation}} of a functional grammar unification system. To achieve this comparison, we have taken as a starting point Michael Elhadad's FUF system, which is written in Lisp and produced a much smaller and more efficient Prolog version (PFUF) retaining many of FUF's essential features. Our approach is based on a precompilation scheme that reduces most of the runtime overhead. 1 Introduction Since its introduction in the early 80 's [Kay 79, Kay 85], the <b>functional</b> <b>unification</b> <b>grammar</b> formalism has rapidly gained acceptance in the field of text generation [M + 90]. Functional unification grammars display the following characteristics, which separate them from the standard context-free models such as the Prolog DCG formalism (see [GM 89] for details) : ffl The use of features (gender, number, etc: : :) to constrain rule selection. ffl The use of flexible constraints (patterns) to specify the order of the terminals in the linearized [...] ...|$|E
40|$|<b>Functional</b> <b>Unification</b> <b>Grammars</b> (PUGs) {{are popular}} for natural {{language}} applications because the formalism uses very few primitives and is uniform and expressive. In our work on text generation, {{we have found}} that it also has annoying limitations: it is not adapted to the expression of simple yet very common taxonomic relations and it does not allow easy manipulation of complex data-structures like lists or sets. We present in this paper a set of extensions that keep the desirable properties of the formalism but make it more flexible and easier to use. We first introduce the notion of typed features and typed constituents. Types define a structure over the set of primitive symbols used by the formalism. We then introduce extended unification: specialized unification methods can be defined for user-defined data-types. This extends the power of the system to handle complex data-structures efficiently. Taking advantage of a structured set of primitives and of specialized unification methods, the resulting formalism is more flexible, easier to use and produces better documented <b>grammars</b> than traditional <b>functional</b> <b>unification.</b> It can therefore be used to address deeper levels of text generation than was possible before...|$|R
40|$|This paper {{compares the}} use of Lisp and Prolog for the {{implementation}} of a <b>functional</b> <b>grammar</b> <b>unification</b> system. To achieve this comparison, we have taken as a starting point Michael Elhadad's FUF system, which is written in Lisp and produced a much smaller and more e cient Prolog version (PFUF) retaining many of FUF's essential features. Our approach is based on a precompilation scheme that reduces most of the runtime overhead...|$|R
40|$|Abstract being modified. In addition, these {{decisions}} interact with We {{address the problem}} of generating adjectives in a text generation system. We distinguish between usages of ad-jectives informing the hearer of a property of an object and usages expressing an intention of the speaker, or an ar-gumentative orientation. For such argumentative usages, we claim that a generator cannot simply map from infor-mation in the knowledge base to adjectives. Instead, we identify various knowledge sources necessary to decide whether to use an adjective, what adjective should be selected and what syntactic function it should have. We show how {{these decisions}} interact with lexical properties of adjectives and the syntax of the clause. We propose a mechanism for adjective selection and illustrate {{it in the context of}} the explanation component of the ADVISOR expert system. We describe an implementation of adjective selec-tion using a version of <b>Functional</b> <b>Unification</b> <b>Grammars.</b> the lexical properties of adjectives, the syntax of the clause and other factors like collocations. In this paper we therefore address the following two questions: What should be the input to a generator capable of producing argumentative usages of adjectives? And how should the generator combine the many interacting factors constraining the selection of an adjective? After reviewing previous work related to these ques-tions, we present the linguistic data upon which we base our approach and the conclusions we draw from its analysis. We then present and justify the input we require to properly select adjectives and discuss how adjective selection is constrained by the lexical properties of adjec-tives and interacts with other surface decisions. The paper illustrates the key features of our implementation of adjective selection in the context of the ADVISOR explanation component...|$|R
40|$|This paper {{describes}} {{a tool for}} supporting grammar development in those linguistic frameworks which employ some constraint-based formalism, such as LFG (Lexical Functional Grammar), HPSG (Head-Driven Phrase Structure Grammar) FUG (<b>Functional</b> <b>Unification</b> <b>Grammar)</b> and CUG (Categorial Unification Grammar). These approaches have in common that all {{or at least a}} substantial part of the grammar (such as rules, lexical entries, node labels etc.) is represented as sets of attribute-value pairs. In LISP or Prolog the structures can be internally represented as lists, but it is much more convenient and sometimes even indispensable to use graphical representations when developing grammars. During grammar processing, feature structures can become quite large (up to several thousand nodes), such that a customized view of the feature structure, which allows to selectively focus on relevant parts, becomes essential. Fegramed provides a fully interactive editor for developing, maintaining and viewing feature structures. It is a tool that is built to cope with the complexity of feature structures in grammar development and use...|$|E
40|$|This work {{describes}} {{a method for}} text planning that is suitable to small domains like train table information. Our aim is to introduce maximal variation in the packaging of information and in the linear order of its presentation. To this end, we regard text planning as a goal-driven process that dynamically constructs a text plan. The goal is a state where all information in the input is shared with the user; the means {{to achieve this goal}} are utterances. The application of utterances is limited by constraints that refer to the user's current state of knowledge. This approach to text planning can be conveniently implemented as a <b>functional</b> <b>unification</b> <b>grammar.</b> In addition, we show how optional or inferable information can be accounted for, how focus can be distributed, and how the generation of anaphoric expressions can be constrained by looking at the form and content of a previous utterance. 1 Introduction This work on text planning is part of a project that is concerned with invest [...] ...|$|E
40|$|Automatically {{summarizing}} {{vast amounts}} of on-line quantitative data with a short natural language paragraph has {{a wide range of}} real-world applications. However, this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation: conciseness, complex sentences, floating concepts, historical background, paraphrasing power and implicit content. In this thesis, I address these specific issues by proposing a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit. This model requires a new type of linguistic knowledge: revision operations, which specify the various ways a draft can be transformed in order to concisely accommodate a new piece of information. I present an in-depth corpus analysis of human-written sports summaries that resulted in an extensive set of such revision operations. I also present the implementation, based on <b>functional</b> <b>unification</b> <b>grammars,</b> of the system STREAK, which relies on these operations to incrementally generate complex sentences summarizing basketball games. This thesis also contains two quantitative evaluations. The first shows that the new revision-based generation model is far more robust than the one-shot model of previous generators. The second evaluation demonstrates that the revision operations acquired during the corpus analysis and implemented in STREAK are, for the most part, portable to at least one other quantitative domain (the stock market). STREAK is the first report generator that systematically places the facts which it summarizes in their historical perspective. It is more concise than previous systems thanks to its ability to generate more complex sentences and to opportunistically convey facts by adding a few words to carefully chosen draft constituents. The revision operations on which STREAK is based constitute the first set of corpus-based linguistic knowledge geared towards incremental generation. The evaluation presented in this thesis is also the first attempt to quantitatively assess the robustness of a new generation model and the portability of a new type of linguistic knowledge...|$|R
40|$|<b>Unification</b> <b>grammars</b> {{are widely}} {{accepted}} as an expressive means for describing {{the structure of}} natural languages. In general, the recognition problem is undecidable for <b>unification</b> <b>grammars.</b> Even with restricted variants of the formalism, off-line parsable grammars, the problem is computationally hard. We present two natural constraints on <b>unification</b> <b>grammars</b> which limit their expressivity and allow for efficient processing. We first show that non-reentrant <b>unification</b> <b>grammars</b> generate exactly the class of context-free languages. We then relax the constraint and show that one-reentrant <b>unification</b> <b>grammars</b> generate exactly the class of mildly context-sensitive languages. We thus relate the commonly used and linguistically motivated formalism of <b>unification</b> <b>grammars</b> to more restricted, computationally tractable classes of languages...|$|R
40|$|In {{this paper}} {{a method to}} compile <b>unification</b> <b>grammars</b> into speech {{recognition}} packages is presented, and in particular, rules are specified to transfer the compositional semantics stated in <b>unification</b> <b>grammars</b> into speech recognition grammars. The resulting compiler creates a context-free backbone of the <b>unification</b> <b>grammar,</b> eliminates left-recursive productions and removes redundant grammar rules. The method was tested on a medium-sized <b>unification</b> <b>grammar</b> for English using Nuance speech recognition software on a corpus of 131 utterances of 12 different speakers. Results showed no significant computational overhead with respect to speech recognition performances for speech recognition grammar with compositional semantics compared to grammars without...|$|R
40|$|In this paper, we {{assess the}} {{complexity}} results of formalisms that describe the feature theories used in computational linguistics. We show that from these complexity results no immediate {{conclusions can be}} drawn about {{the complexity of the}} recognition problem of <b>unification</b> <b>grammars</b> using these feature theories. On the one hand, the complexity of feature theories does not provide an upper bound for the complexity of such <b>unification</b> <b>grammars.</b> On the other hand, the complexity of feature theories need not provide a lower bound. Therefore, we argue for formalisms that describe actual <b>unification</b> <b>grammars</b> instead of feature theories. Thus the complexity results of these formalisms judge upon the hardness of <b>unification</b> <b>grammars</b> in computational linguistics. ...|$|R
40|$|First {{we define}} a <b>unification</b> <b>grammar</b> formalism. It {{is based on}} Lexical Functional Grammar (LFG), but has a strong {{restriction}} on the syntax of the equations. We then show that this grammar formalism defines a full abstract family of languages, {{and that it is}} capable of describing cross-serial dependencies of the type found in Swiss German. 1 Introduction Due to their combination of simplicity and flexibility <b>unification</b> <b>grammars</b> have become widely used in computational linguistics the last fifteen yeas. But this flexibility gives us also a very powerful formalism. As a result of this power, the membership problem for <b>unification</b> <b>grammars</b> in their most general form is undecidable. Therefore most of those grammars have restrictions to make them decidable, e. g. the off-line parsability constraint in LFG [12]. Nevertheless, the membership problem is NP-complete [1] or harder for most <b>unification</b> <b>grammar</b> formalisms. It is therefore interesting to study restrictions on <b>unification</b> <b>grammars</b> [...] ...|$|R
50|$|The Regulus Grammar Compiler is a {{software}} system for compiling <b>unification</b> <b>grammars</b> into grammars for speech recognition systems.|$|R
40|$|MoscouInternational audienceThis article {{presents}} the Meaning-Text <b>Unification</b> <b>Grammar's</b> current state, now that its formal foundations have been clarified {{with the development}} of Polarized <b>Unification</b> <b>Grammar.</b> Emphasis is put on the model's architecture and the role of polarization in linking its modules — semantics syntax interface and the well-formedness grammars of each representation leve...|$|R
40|$|This {{report is}} the user manual for FUF version 2. 0, a natural {{language}} generator program {{that uses the}} technique of <b>unification</b> <b>grammars.</b> The program is composed of two main modules: a unifier and a linearizer. The unifier takes as input a semantic description of the Lext to be generated and a <b>unification</b> <b>grammar,</b> and produces as output a rich syntactic description of the text. The linearizer interprets this syntactic description and produces an English sentence. This manual includes a detailed presentation of the technique of <b>unification</b> <b>grammars</b> and a reference manual for the current implementation (FUF 2. 0) ...|$|R
40|$|This paper {{presents}} a connectionist syntactic parser which uses Structure <b>Unification</b> <b>Grammar</b> as its grammatical framework. The parser is implemented in a connectionist architecture which stores and dynamically manipulates symbolic representations, but which can't represent arbitrary disjunction and has bounded memory. These {{problems can be}} overcome with Structure <b>Unification</b> <b>Grammar's</b> extensive use of partial description...|$|R
40|$|In {{this paper}} {{it will be}} shown how <b>unification</b> <b>grammars</b> {{can be used to}} build a {{reversible}} machine translation system. <b>Unification</b> <b>grammars</b> are often used to define the relation between strings and meaning representations in a declarative way. Such grammars are sometimes used in a bidirectional way, thus the same grammar is used for both parsing and generation. In this paper I will show how to use bidirectional <b>unification</b> <b>grammars</b> to define reversible relations between language dependent meaning representations. Furthermore it is shown how to obtain a completely reversible MT system using a series of (bidirectional) <b>unification</b> <b>grammars.</b> 1 Introduction The notion of a reversible MT system was first expressed by Landsbergen [11]. Such a system will in principle produce a set of possible translations, by employing linguistic knowledge only. Choosing the best translation from the set of linguistically possible translations will usually require other sources of knowledge, either incorpor [...] ...|$|R
40|$|This paper {{presents}} Trace & <b>Unification</b> <b>Grammar</b> (TUG), a declarative and reversible grammar formalism {{that brings}} together <b>Unification</b> <b>Grammar</b> (uG) and ideas of Government & Binding Theory (GB) in an undogrnatic way. A grammar compiler is presented that transforms a grammar {{written in the}} TUG formalism into two different forms, one being useful for parsing, the other being useful for generation...|$|R
40|$|In this paper, we {{assess the}} {{complexity}} results of formalisms that describe the feature theories used in computational linguistics. We show that from these complexity results no immediate {{conclusions can be}} drawn about {{the complexity of the}} recognition problem of <b>unification</b> <b>grammars</b> using these feature theories. On the one hand, the complexity of feature theories does not provide an upper bound for the complexity of such <b>unification</b> <b>grammars.</b> On the other hand, the complexity of feature theories need not provide a lower bound. Therefore, we argue for formalisms that describe actual <b>unification</b> <b>grammars</b> instead of feature theories. Thus the complexity results of these formalisms judge upon the hardness of <b>unification</b> <b>grammars</b> in computational linguistics. Comment: 16 pages, includes 3 Postscript figures, uses epsf. sty, also available by (1) anonymous ftp at ftp://ftp. fwi. uva. nl/pub/theory/illc/researchReports/LP- 95 - 01. ps. gz (2) WWW from [URL] This version differs slightly from the original technical Report. Some non-standard style-files are removed from this version...|$|R
40|$|The {{design of}} an LR parser based on {{interleaving}} the atomic symbol processing of a context-free backbone grammar {{with the full}} constraints of the underlying <b>unification</b> <b>grammar</b> is described. The parser employs a set of reduced constraints derived from the <b>unification</b> <b>grammar</b> in the LR parsing step. Gap threading is simulated to reduce the applicability of empty productions. Comment: 5 pages, uuncoded, gzipped PostScrip...|$|R
40|$|This paper {{presents}} a minimal enumerative {{approach to the}} problem of compiling typed <b>unification</b> <b>grammars</b> into CFG language models, a prototype implementation and results of experiments in which it was used to compile some non-trivial <b>unification</b> <b>grammars.</b> We argue that enumerative methods are considerably more useful than has been previously believed. Also, the simplicity of enumerative methods makes them a natural baseline against which to compare alternative approaches. 1...|$|R
40|$|This paper {{describes}} the analysis {{component of the}} language processing system PLAIN from tile viewpoint of <b>unification</b> <b>grammars.</b> The principles of Dependency <b>Unification</b> <b>Grammar</b> (DUG) are discussed. The computer language DRL (Dependency Representation Language) is introduced J. n which DUGs can be formulated. A unifi- cation-based parsing procedure {{is part of the}} formalisnl. PLAIN is implemented at the universities of Heidelberg, Bonn, Flensburg, Kiel, Zurich and Cambridge U. K...|$|R
40|$|This paper {{describes}} {{an attempt at}} creating a robust parsing system for the SCHISMA task domain. We describe how a probabilistic <b>unification</b> <b>grammar</b> is generated from a corpus of utterances collected in Wizard of Oz experiments. We tagged the corpus with syntactic categories and superficial syntactic structure using Standard Generalised Markup Language (SGML). From the annotated data thus obtained a probabilistic <b>unification</b> <b>grammar</b> was generated. The grammar was then tested on `seen' and `unseen' data from the same domain using a probabilistic leftcorner parser for PATRII <b>unification</b> <b>grammars.</b> We will evaluate the quality {{and size of the}} corpus from a syntactic point of view, describe the grammar we obtained, and report on the performance of the parsing system when applied to unseen data from the same domain...|$|R
