16|16|Public
50|$|The API is in {{the user}} space when the {{filesystem}} does not directly use <b>kernel</b> <b>facilities</b> but accesses disks using high-level operating system functions and provides functions in a library that a series of utilities use to access the filesystem.|$|E
5000|$|... prelink will (when {{run with}} the [...] "-R" [...] option) {{randomly}} select the address base that libraries are loaded at. This {{makes it more difficult}} to perform a return-to-libc attack on the system, because the addresses used are unique to that system. The reason prelink does this is because <b>kernel</b> <b>facilities</b> supplying address space layout randomization (ASLR) for libraries cannot be used in conjunction with prelink without defeating the purpose of prelink and forcing the dynamic linker to perform relocations at program load time.|$|E
5000|$|There is a {{variation}} of this scheme used in MS-DOS (DOS 4.0 onward) and compatibles to support CD-ROM and network file systems. Instead of adding code to the kernel, as in the old scheme, or using <b>kernel</b> <b>facilities</b> as in the kernel-based scheme, it traps all calls to a file and identifies if it should be redirected to the kernel's equivalent function or if {{it has to be}} handled by the specific filesystem driver, and the filesystem driver [...] "directly" [...] access the disk contents using low-level BIOS functions.|$|E
5000|$|The API is [...] "driver-based" [...] {{when the}} <b>kernel</b> {{provides}} <b>facilities</b> but the file system code resides totally {{external to the}} kernel (not even as a module of a modular kernel).|$|R
40|$|A {{proposal}} to achieve dynamic reconfiguration {{within the framework}} of the Ada programming language is presented. A dynamic linking <b>kernel</b> <b>facility</b> is illustrated and its implementation using the Verdix VADS 5. 5 Ada compiling system on a SUN 3 - 120 running the BSD Unix version 4. 3 operating system is discussed. This kernel allows an Ada program to dynamically change its own configuration, linking at run-time new pieces of code. It is shown how this dynamic facility can be consistently integrated at the Ada language level, without introducing severe inconsistencies with respect to the standard semantics...|$|R
40|$|FS-Cache is a <b>kernel</b> <b>facility</b> {{by which}} a net-work {{filesystem}} or other service can cache data locally, trading disk space to gain performance improvements for access to slow networks and media. It {{can be used by}} any filesystem that wishes to use it, for example AFS, NFS, CIFS, and ISOFS. It can support a variety of back-ends: different types of cache that have differ-ent trade-offs. FS-Cache is designed to impose as little over-head and as few restrictions as possible on the client network filesystem using it, whilst still providing the essential services. The presence of a cache indirectly improves performance of the network and the server by reducing the {{need to go to the}} network. ...|$|R
50|$|Though an {{expedient}} {{design for}} accessing standard <b>kernel</b> <b>facilities,</b> system calls are sometimes inappropriate for accessing non-standard hardware peripherals. By necessity, most hardware peripherals (aka devices) are directly addressable {{only within the}} kernel. But user code may need to communicate directly with devices; for instance, an administrator might configure the media type on an Ethernet interface. Modern operating systems support diverse devices, many of which offer a large collection of facilities. Some of these facilities may not be foreseen by the kernel designer, {{and as a consequence}} it is difficult for a kernel to provide system calls for using the devices.|$|E
50|$|The OS was {{designed}} with users in mind, rather than OS designers. It is organised {{as a relatively}} small kernel which defines a standard software interface to which extension modules are required to conform. Much of the system's functionality is implemented in modules coded in the ROM, though these can be supplanted by more evolved versions loaded into RAM. Among the <b>kernel</b> <b>facilities</b> are a general mechanism, named the callback handler, which allows a supervisor module to perform process multiplexing. This facility is used by a module forming part of the standard editor program to provide a terminal emulator window for console applications. The same approach {{made it possible for}} advanced users to implement modules giving RISC OS the ability to do pre-emptive multitasking.|$|E
50|$|JX is {{implemented}} as an extended Java virtual machine (the JX Core), adding {{support to the}} Java system for necessary features such as protection domains and hardware access, along {{with a number of}} components written in Java that provide <b>kernel</b> <b>facilities</b> to applications running on the computer. Because Java is a type-safe language, JX is able to provide isolation between running applications without needing to use hardware memory protection. This technique, known as language-based protection means that system calls and inter-process communication in JX does not cause an address space switch, an operation which is slow on most computers. JX runs on standard PCs, with support for a limited range of common hardware elements. It is open source software, developed by the University of Erlangen.|$|E
40|$|In {{a typical}} {{commercial}} multi-core processor, the last level cache (LLC) {{is shared by}} two or more cores. Existing {{studies have shown that}} the shared LLC is beneficial to concurrent query processes with commonly shared data sets. However, the shared LLC can also be a performance bottleneck to concurrent queries, each of which has private data structures, such as a hash table for the widely used hash join operator, causing serious cache conflicts. We show that cache conflicts on multi-core processors can significantly degrade overall database performance. In this paper, we propose a hybrid system method called MCC-DB for accelerating executions of warehouse-style queries, which relies on the DBMS knowledge of data access patterns to minimize LLC conflicts in multicore systems through an enhanced OS facility of cache partitioning. MCC-DB consists of three components: (1) a cacheaware query optimizer carefully selects query plans in order to balance the numbers of cache-sensitive and cache-insensitive plans; (2) a query execution scheduler makes decisions to corun queries with an objective of minimizing LLC conflicts; and (3) an enhanced OS <b>kernel</b> <b>facility</b> partitions the shared LLC according to each query’s cache capacity need and locality strength. We have implemented MCC-DB by patching the three components in PostgreSQL and Linux kernel. Our intensive measurements on an Intel multi-core system with warehouse-style queries show that MCC-DB can reduce query execution times by up to 33 %. 1...|$|R
50|$|Linux {{provides}} the pcimem utility to allow reading from and writing to MMIO addresses. The Linux kernel also allows tracing MMIO access from kernel modules (drivers) using the <b>kernel's</b> mmiotrace debug <b>facility.</b> To enable this, the Linux kernel should be compiled with the corresponding option enabled. mmiotrace {{is used for}} debugging closed-source device drivers.|$|R
40|$|We {{developed}} a system called Network Simulation Environment (NoSE) to simulate arbitrary network environments {{on a single}} Linux machine. NoSE provides a GUI and a management daemon {{that is capable of}} generating a complex network containing virtual hosts and switches with just a few clicks. Different virtual machines and network configurations can be archived in a library for later reuse. NoSE integrates different virtual machine emulators such as Xen, User-Mode-Linux and QEMU, the Linux <b>kernel’s</b> bridging <b>facilities,</b> and various network management and monitoring tools. Possible applications for our system include network simulation, testing, training, distributed application development, and analysis of security issues. In this paper we focus on building high-interaction honeynets with NoSE...|$|R
40|$|In 2. 5, strong {{cryptography}} {{has been}} incorporated into the kernel. This inclusion {{was a result of}} several motivating factors: remove duplicated code, harmonize IPv 6 /IPSec, and the usual crypto-paranoia. The authors will present the history of the Cryptographic API, its current state, what <b>kernel</b> <b>facilities</b> are currently using it, which ones should be using it, plus the new future applications including: 1. Hardware and assembly crypto drivers 2. Kernel module code-signing 3. Hardware random number generation 4. Filesystem encryption, including swap space...|$|E
40|$|This paper {{presents}} {{an overview of}} EXODUS, an extensible database system project that is addressing data management problems posed {{by a variety of}} challenging new applications. The goal of the project is to facilitate the fast development of high-performance, application-specific database systems. EXODUS provides certain <b>kernel</b> <b>facilities,</b> including a versatile storage manager. In addition, it provides an architectural framework for building application-specific database systems; powerful tools to help automate the generation of such systems, including a rule-based query optimizer generator and a persistent programming language; and libraries of generic software components (e. g., access methods) that are likely to be useful for many application domains. We briefly describe each of the components of EXODUS in this paper, and we also describe a next-generation DBMS that we are now building using the EXODUS tools. 1...|$|E
40|$|Abstract We {{have built}} a {{portable}} platform for running Standard ML of New Jersey programs on multiprocessors. It {{can be used to}} implement user-level thread packages for multiprocessors within the ML language with first-class continuations. The platform supports experimentation with different thread scheduling policies and synchronization constructs. It has been used to construct a Modula- 3 style thread package and a version of Concurrent ML, and has been ported to three different multiprocessors running variants of Unix. This paper describes the platform's design, implementation, and performance. 1 Introduction Many concurrent and parallel computations can be expressed elegantly and efficiently using collections of lightweight threads. Both kernel-level and user-level thread packages have become a common part of computing environments. User-level packages can offer substantially better performance than <b>kernel</b> <b>facilities,</b> because thread operations do not require expensive system calls [2, 15, 23]...|$|E
40|$|To support {{concurrent}} programming the MONADS-PC instruction set and operating system <b>kernel</b> provide <b>facilities</b> for process creation, synchronization and scheduling. These facilities are assimilated with the LEIBNIZ programming environment, appearing as module class definitions. They form {{a small and}} efficient set of primitives which, when utilized by the modular features of the LEIBNIZ programming language, allow software modules to be constructed to support {{concurrent programming}} {{in a variety of}} styles. Modules supporting some of the more common styles are described. In addition, the MONADS-PC System's persistent, capability-based programming environment provides some new and very useful possibilities for concurrent programming. Keywords: MONADS, Concurrent Programming, Synchronization, Semaphores, Operating Systems CR categories: D. 3. 3, D. 4. 1...|$|R
50|$|Available in BSD and POSIX Unix. I/O {{is issued}} asynchronously, {{and when it}} is {{completed}} a signal (interrupt) is generated. As in low-level <b>kernel</b> programming, the <b>facilities</b> available for safe use within the signal handler are limited, and the main flow of the process could have been interrupted at nearly any point, resulting in inconsistent data structures as seen by the signal handler. The signal handler is usually not able to issue further asynchronous I/O by itself.|$|R
40|$|FKT is a Fast <b>Kernel</b> Tracing <b>facility</b> {{that allows}} <b>kernel</b> {{developers}} {{to obtain a}} precise, time-stamped trace of the dynamic activities of kernel-level code on multiprocessor platforms. This is done by inserting special software " macros into the kernel code, typically one probe at the entrance and exit from each function of interest. Sets of these probes can be enabled and disabled under program control to selectively trace the dynamic execution ow through {{any part of the}} kernel. These macros invoke a highly optimized kernel function to record information into a large kernel buer. This buer can later be written to a le and analyzed o-line. Although probes do add execution overhead to the kernel, every attempt has been made to minimize it. The rst version of FKT has been implemented on Linux. Keywords: dynamic tracing, software monitoring, performance analysis, operating system, kernel. ...|$|R
40|$|Current {{operating}} systems {{are designed to}} provide leastcommon -denominator service {{to a variety of}} applications. They export few internal <b>kernel</b> <b>facilities,</b> and those which are exported have irregular interfaces. As a result, resource intensive applications such as database management systems and multimedia applications, are often poorly served by the operating system. These applications often {{go to great lengths to}} bypass normal kernel mechanisms to achieve acceptable performance. We describe a new kernel architecture, the VINO kernel, which addresses the limitations of conventional {{operating systems}}. The VINO design is driven by three principles: ffl Application Directed Policy: the operating system provides a collection of mechanisms, but applications dictate the policies applied to those mechanisms. ffl Kernel as Toolbox: applications can reuse the kernel's primitives. ffl Universal Resource Access: all resources are accessed through a single, common interface. VINO's power and [...] ...|$|E
40|$|We {{have built}} a {{portable}} platform for running Standard ML of New Jersey programs on multiprocessors. It {{can be used to}} implement user-level thread packages for multiprocessors within the ML language with rst-class continuations. The platform supports experimentation with dierent thread scheduling policies and synchronization constructs. It has been used to construct a Modula- 3 style thread package and a version of Concurrent ML, and has been ported to three dierent multiprocessors running variants of Unix. This paper describes the platform's design, implementation, and performance. 1 Introduction Many concurrent and parallel computations can be expressed elegantly and eciently using collections of lightweight threads. Both kernel-level and user-level thread packages have become a common part of computing environments. User-level packages can oer substantially better performance than <b>kernel</b> <b>facilities,</b> because thread operations do not require expensive system calls [2, 15, 23]. [...] ...|$|E
40|$|With {{non-traditional}} application {{areas such}} as engineering design, image/voice data management, scientific/statistical applications, and artificial intelligence systems all clamoring for ways to store and efficiently process larger and larger volumes of data, {{it is clear that}} traditional database technology has been pushed to its limits. It also seems clear that no single database system will be capable of simultaneously meeting the functionality and performance requirements of such a diverse set of applications. In this paper we describe the initial design of EXODUS, an extensible database system that will facilitate the fast development of high-performance, applicationspecific database systems. EXODUS provides certain <b>kernel</b> <b>facilities,</b> including a versatile storage manager and a type manager. In addition, it provides an architectural framework for building application-specific database systems, tools to partially automate the generation of such systems, and libraries of software components (e. g., access methods) that are likely to be useful for many application domains...|$|E
40|$|Recent work on {{software}} processes {{has produced a}} considerable amount of detailed information which renders the software life cycle more explicit by describing it as an enactable software process model. This article presents TEMPO: a software process modeling strategy based on Adele: a software con guration management <b>kernel.</b> The <b>facilities</b> for describing and enacting software process models are highlighted. TEMPO is an object oriented process model. Each software process is modeled as an object which encapsulates (role concept) the operations around a set of resources required to carry out a speci c software development activity. Each software activity provides workspace in which the developers work by calling operations on processes. On this way a software development environment may consist of a set of workspace working together by coordinating their activities. This paper concludes with an overview of the TEMPO implementation on top of Adele...|$|R
40|$|This paper {{presents}} a methodology for debugging {{the performance of}} message-passing programs on both tightly coupled and loosely coupled distributed-memory machines. The AIMS (Automated Instrumentation and Monitoring System) toolkit, a suite of software tools for measurement and analysis of performance, is introduced and its application illustrated using several benchmark programs drawn {{from the field of}} computational fluid dynamics. AIMS includes (i) Xinstrument, a powerful source-code instrumentor, which supports both Fortran 77 and C {{as well as a number}} of different message-passing libraries including Intel's NX Thinking Machines' CMMD, and PVM; (ii) Monitor, a library of timestamping and trace -collection routines that run on supercomputers (such as Intel's iPSC/ 860, Delta, and Paragon and Thinking Machines' CM 5) as well as on networks of workstations (including Convex Cluster and SparcStations connected by a LAN); (iii) Visualization <b>Kernel,</b> a trace-animation <b>facility</b> that supports source-code clickback, simultaneous visualization of computation and communication patterns, as well as analysis of data movements; (iv) Statistics Kernel, an advanced profiling facility, that associates a variety of performance data with various syntactic components of a parallel program; (v) Index Kernel, a diagnostic tool that helps pinpoint performance bottlenecks through the use of abstract indices; (vi) Modeling <b>Kernel,</b> a <b>facility</b> for automated modeling of message-passing programs that supports both simulation -based and analytical approaches to performance prediction and scalability analysis; (vii) Intrusion Compensator, a utility for recovering true performance from observed performance by removing the overheads of monitoring and their effects on the communication pattern of the program; and (viii) Compatibility Tools, that convert AIMS-generated traces into formats used by other performance-visualization tools, such as ParaGraph, Pablo, and certain AVS/Explorer modules...|$|R
40|$|This paper {{examines}} {{how and why}} web server performance changes as the workload at the server varies. We measure {{the performance of a}} PC acting as a standalone web server, running Apache on top of Linux. We use two important tools to understand what aspects of software architecture and implementation determine performance at the server. The first is a tool that we developed, called WebMonitor, which measures activity and resource consumption, both in the operating system and in the web server. The second is the <b>kernel</b> profiling <b>facility</b> distributed as part of Linux. We vary the workload at the server along two important dimensions: the number of clients concurrently accessing the server, {{and the size of the}} documents stored on the server. Our results quantify and show how more clients and larger files stress the web server and operating system in different and surprising ways. Our results also show the importance of fixed costs (i. e., opening and closing TCP connections, and up [...] ...|$|R
40|$|Distributed {{database}} systems {{need special}} operating system support. Support routines {{can be implemented}} inside the kernel or at the user level. Kernel-level functions, while efficient, are hard to implement. User-level implementations are easier, but suffer from poor performance and lack of security. This paper proposes {{a new approach to}} supplement or modify <b>kernel</b> <b>facilities</b> for database transaction processing. Our experimental facility, called Push, is based on an extension language interpreted within the kernel. Our implementation provides the efficiency of kernel-resident code as well as the simplicity and safety of user-level programming. This facility enables experimentation that would be difficult and time-consuming in current environments. The overhead of the Push implementation can be factored out to give a good estimate of the performance of a native kernel implementation. We have used Push to implement several kernel-resident services. In the case of multi-RPC and commit pro [...] ...|$|E
40|$|This work explores several {{system issues}} {{regarding}} {{the design and}} implementation of routing protocols for ad-hoc wireless networks. We examine the routing architecture in current operating systems and find it insufficient on several counts, especially for supporting on-demand or reactive routing protocols. Examples include lack of mechanisms for queuing outstanding packets awaiting route discovery and mechanisms for communicating route usage information from kernel to userspace. We propose an architecture and a generic API for any operating system to augment the current routing architecture. Implementing the API may normally require kernel modifications, but we provide an implementation for Linux using only the standard Linux 2. 4 <b>kernel</b> <b>facilities.</b> The API is provided as a shared user-space library called the Ad-hoc Support Library (ASL), which uses a small loadable kernel module. To prove the viability of our framework, we provide a full-fledged implementation of the AODV protocol using ASL, and a design for the DSR protocol. Through this study, we also reinforce our belief that it is profoundly important to consider system issues in ad-hoc routing protocol design. ...|$|E
40|$|Lucid, Inc. Programming {{language}} design {{combines the}} art of invention with judicious adaptation and rejection of ideas previously tried. This chapter presents aspects of {{the design of the}} Common Lisp Object System (CLOS) in the context of related ideas from many languages, providing a view of the CLOS within a broader space of designs. CLOS {{is the latest in a}} long history of additions of object-oriented extensions to Lisp. But CLOS is the first such extension that integrates the type and class systems, and provides a uniform client interface for calling ordinary functions and functions implemented in an object-oriented style. CLOS is also designed with three constraints not found in other object-oriented extensions. The first is to provide essential compatibility with other previously used objectoriented LISP facilities, such as the Symbolics Flavors system. Essential compatibility implies an easy path for transforming programs, supporting the most frequently used capabilities in such systems. The second constraint is that CLOS is to facilitate experimentation with new language features in a way that allows them to integrate but not interfere with the kernel of the system. The third is that CLOS <b>kernel</b> <b>facilities</b> are to be efficiently implementable o...|$|E
40|$|Current Linux <b>kernels</b> {{include a}} <b>facility</b> called TCP SYN cookies, {{conceived}} to face SYN flooding attacks. However, the current implementation of SYN cookies {{does not support}} the negotiation of TCP options, although some of them are relevant for throughput performance, such as large windows or selective acknowledgment. In this paper we present an improvement of the SYN cookie protocol, using all the current mechanisms for generating and validating cookies while allowing connections negotiated with SYN cookies to set up and use any TCP options. The key idea is to exploit a kind of TCP connection called "simultaneous connection initiation" in order to lead client hosts to send together TCP options and SYN cookies to a server being attacked...|$|R
40|$|Intertask/interprocess {{synchronization}} overheads may {{be significant}} in a multiprocessor-shared memory System-on-a-Chip implementation. These overheads are observed {{in terms of}} lock latency, lock delay and memory bandwidth consumption in the system. It {{has been shown that}} a hardware solution brings a much better performance improvement than the synchronization algorithms developed in software [3]. Our previous work presented a SoC Lock Cache (SoCLC) hardware mechanism which resolves the Critical Section (CS) interactions among multiple processors and improves the performance criteria in terms of lock latency, lock delay and bandwidth consumption in a shared memory multiprocessor SoC for short CSes [1]. This paper extends our previous work to support long CSes as well. This combined support involves modifications both in the RTOS <b>kernel</b> level <b>facilities</b> (such as support for preemptive versus non-preemptive synchronization, interrupt handling and RTOS initialization) and in the hardware mechanism. The worst-case simulation results of a database application model with client-server pair of tasks on a fourprocessor system showed that our mechanism achieved a 57 % improvement in lock latency, 14 % speed up in lock delay and a 35 % overall speedup in total execution time...|$|R
40|$|We have {{developed}} a facility for run-time optimization of a commodity operating system <b>kernel.</b> This <b>facility</b> {{is a first step}} towards an evolving operating system, one that adapts and changes over time without need for rebooting. Our infrastructure, currently implemented on UltraSPARC Solaris 7, includes the ability to do a detailed analysis of the running kernel's binary code, dynamically insert and remove code patches, and dynamically install new versions of kernel functions. As a first use of this technology, we have implemented a run-time kernel version of the code positioning I-cache optimizations, and obtained noticeable speedups in kernel performance. As a first case study, we performed run-time code positioning on the kernel's TCP read-side processing routine while running a Web client benchmark. We found that the code positioning optimizations reduced this function's execution time by 17. 6 %, resulting in an end-to-end benchmark speedup of 7 %. The primary contributions of this paper are the first run-time kernel implementation of code positioning, and an infrastructure for turning an unmodified commodity kernel into an evolving one. Two further contributions are made in kernel performance measurement. First, we provide a simple and effective algorithm for deriving control flow edge execution counts from basic block execution counts, which contradicts the widely held belief that edge counts cannot be derived from block counts. Second, we describe a means for converting wall time instrumentation-based kernel measurements into virtual (i. e., CPU) time measurements via instrumentation of the kernel's context switch handlers. ...|$|R
40|$|Transactions offer a {{powerful}} data-access method {{used in many}} databases today trough a specialized query API. User applications, however, use a different fileaccess API (POSIX) which does not offer transactional guarantees. Applications using transactions can become simpler, smaller, easier to develop and maintain, more reliable, and more secure. We explored several techniques how to provide transactional file access with minimal impact on existing programs. Our first prototype was a standalone kernel component within the Linux kernel, but it complicated the kernel considerably and duplicated some of Linux’s existing facilities. Our second prototype was all in user level, and while {{it was easier to}} develop, it suffered from high overheads. In this paper we describe our latest prototype and the evolution that led to it. We implemented a transactional file API inside the Linux kernel which integrates easily and seamlessly with existing <b>kernel</b> <b>facilities.</b> This design is easier to maintain, simpler to integrate into existing OSs, and efficient. We evaluated our prototype and other systems under a variety of workloads. We demonstrate that our prototype’s performance is better than comparable systems and comes close to the theoretical lower bound for a log-based transaction manager. ...|$|E
40|$|This thesis {{comprises}} of {{an in-depth}} investigation on {{issues related to}} high performance I/O architectures, including I/O caching, disk architectures as well as web servers. ^ The {{first part of this}} thesis presents a novel high-performance, low-cost disk architecture called DCD, Disk Caching Disk. DCD consists of a three-level storage hierarchy: a RAM buffer and a log disk and a data disk. Trace-driven simulation of DCD under the office/engineering workload demonstrates up to two orders of magnitude performance improvement for small writes when compared to existing disk systems. Furthermore, DCD is very reliable, and works in device or device driver level. As a result, it can be applied directly to current file systems without the need of changing underlying operation systems. ^ The second part of this thesis presents a new cache architecture called RAPID-Cache for Redundant, Asymmetrically Parallel, and Inexpensive Disk Cache. RAPID-Cache is a highly-reliable and inexpensive write cache for high-performance storage systems. A typical RAPID-Cache consists of two redundant write buffers on top of a disk system. One of the buffers is a primary cache made of RAM or NVRAM and the other is a backup cache containing a two level hierarchy: a small NVRAM buffer on top of a log disk. Our analysis and trace-driven simulation results show that the RAPID-Cache has significant reliability/cost advantages over conventional single NVRAM write caches and has great cost advantages over dual-copy NVRAM caches. ^ The third part of this thesis presents an in-depth study on I/O issues related to the Apache web server. Very few results have been published that quantitatively study the server behavior. Using standard benchmarks and several OS <b>kernel</b> tracing <b>facilities,</b> we quantitatively identified the server performance bottlenecks. We then proposed and implemented 7 techniques that improve the performance of Apache by 61 %. Finally, our results suggest that operating system support for directly sending data from the file system cache to the TCP/IP network can further improve the Web server performance dramatically. ...|$|R

