14|10000|Public
5000|$|... ptx is a Unix utility, {{named for}} the permuted index which can perform the {{function}} of the <b>Keyword</b> <b>in</b> <b>Context</b> (KWIC) search mode. There is a corresponding IBM mainframe utility which performs the same function. permuted indexes are often used in such places as bibliographic or medical databases, thesauruses, or web sites to aid in locating entries of interest.|$|E
50|$|The {{simplest}} {{and most}} objective form of content analysis considers unambiguous {{characteristics of the}} text such as word frequencies, the page area taken by a newspaper column, or the duration of a radio or television program. Analysis of simple word frequencies is limited because {{the meaning of a}} word depends on surrounding text. <b>Keyword</b> <b>In</b> <b>Context</b> routines address this by placing words in their textual context. This helps resolve ambiguities such as those introduced by synonyms and homonyms.|$|E
5000|$|According to Rev. Gerard O'Connor's Concordantia et Indices Missalium Romanorum, [...] "Most of the concordances {{produced}} {{in recent times}} and {{with the aid of}} computer software use both the KWIC (<b>keyword</b> <b>in</b> <b>context)</b> and KWICn (keyword in center) formats, which lists the keyword, usually highlighted in bold text in a consistent position, within a limited amount of context text, i.e. three or four words of the text prior to the keyword and the same amount of text following. This format is extremely useful in that the keyword is easily identified together with its context. ... The Concordance of the Roman Missal is {{produced in}} both the KWIC and KWICn formats and is noteworthy in that each word form is listed as it appears in the text, that is, it is un-lemmatized." ...|$|E
40|$|Presentation at Society of Southwest Archivists Meeting, Houston, Texas, May 22, 2008 Discusses how TEI (Text Encoding Initiative) {{can be used}} by {{archives}} and special collections libraries. Defines TEI and provides background on XML. Provides examples of how TEI can facilitate text analysis, placing <b>keywords</b> <b>in</b> <b>context,</b> preservation, nuanced searching, and more. Briefly explores how to implement TEI...|$|R
40|$|This {{thesis is}} a bottom‐up corpus stylistic {{exploration}} of the text world of H. P. Lovecraft’s stories {{that focuses on the}} emergence of semantic prosodies via <b>keywords</b> <b>in</b> <b>context,</b> collocation and n‐grams. The study addresses existing views on semantic prosody and tests the nine‐word window of collocational force (Louw 2000). It uncovers linguistic aspects of Lovecraft’s stories that could not be detected intuitively and provides a firm basis for some subjective literary assumptions. It also demonstrates how Lovecraft primes (Hoey 2007) his readers throughout his collection of stories to recognise and replicate the mental representations which surround invented proper nouns through triggering background knowledge intertextually...|$|R
40|$|Manually {{assigned}} keywords {{provide a}} valuable means for accessing large document collections. They {{can serve as}} a shallow document summary and enable more efficient retrieval and aggregation of information. In this paper we investigate <b>keywords</b> <b>in</b> the <b>context</b> of the Dutch Folktale Database, a large collection of stories including fairy tales, jokes and urban legends. We carry out a quantitative and qualitativ...|$|R
40|$|This is a {{computer}} assisted content analysis of a rightwing Austrian journal published from the 1950 s. On {{the basis of a}} <b>keyword</b> <b>in</b> <b>context</b> analysis and a plotting of the keyword occurrances according to the proximity of their apperance in the text conclusions are offered as to the ideological bias of the journal...|$|E
40|$|Maryland {{performed}} {{two sets}} of experiments for the 2003 Cross-Language Evaluation Forum's interactive track, one focused on interactive selection of appropriate translations for query terms, the second focused on interactive selection of relevant documents. Translation selection was supported using possible synonyms discovered through back translation and two techniques for generating <b>KeyWord</b> <b>In</b> <b>Context</b> (KWIC) examples of usage. The results indicate that searchers typically achieved a similar search eectiveness using fewer query iterations when interactive translation selection was available. For document selection, a complete extract of the rst 40 words of each news story was compared to a compressed extract generated using an automated parse-and-trim approach that approximates {{one way in which}} people can produce headlines...|$|E
40|$|This paper {{outlines}} {{tools and}} techniques {{to exploit the}} Web as a vast linguistic and cultural corpus. After {{a snapshot of the}} dimensions and diversity of the Web in late 2001, this paper surveys the capabilities and shortcomings of major web search engines and characterizes typical user search behavior. Next it describes KWiCFinder, a free search tool optimized for language professionals programmed by the author to make online research more efficient and effective. KWiCFinder automatically conducts a search, retrieves online documents matching the user's query, and produces a <b>keyword</b> <b>in</b> <b>context</b> concordance of those documents for rapid evaluation. Then the author details many of the considerations which went into designing KWiCFinder and the challenges of maintaining it. Next the usefulness of the Web as a source of linguistic data is discussed and illustrated with a number of examples. The article closes with a discussion of future directions for web concordancing...|$|E
40|$|This {{style file}} {{contains}} {{a set of}} definitions that allow keywords to be defined and printed in several convenient ways. For each keyword two definitions may be provided. This is to allow the use of <b>keywords</b> <b>in</b> two <b>contexts</b> (for instance English/French translation of the keywords). At the same time, keyword can be printed in roman, teletype, boldfaced or underlined. The user can define othe...|$|R
40|$|The authors {{report a}} series of {{controlled}} comparisons of fifty-eight one-to-one quali-tative interviews and thirty-seven mixed-sex joint interviews on the same health-related topics. Their analysis identifies comparative keyword frequencies and is supported by qualitative investigations of <b>keywords</b> <b>in</b> <b>context,</b> drawing on existing relevant knowledge of common gender differences in language choice. Gender differences are reduced and women’s perspectives are more prominent in joint interviews, so researchers wanting {{to find out about}} men’s experiences concerning health-related topics such as those associated with fatherhood may find out more in one-to-one interviews with men. The greater readiness of men to engage in gender-stereotyped behavior in sole interviews, most of which involved a female interviewer, suggests that an interviewer’s gender identity is perceived as somewhat neutral by comparison with the considerable salience of the gender of a joint respondent. This finding potentially contributes to knowledge of the qualitative interview as a special form of institutional talk...|$|R
40|$|Like in Output Data as HTML File, {{this lesson}} takes the {{frequency}} pairs collected in Counting Frequencies and outputs them in HTML. This time {{the focus is}} on <b>keywords</b> <b>in</b> <b>context</b> (KWIC) which creates n-grams from the original document content – in this case a trial transcript from the Old Bailey Online. You can use your program to select a keyword and the computer will output all instances of that keyword, along with the words to the left and right of it, making it easy to see at a glance how the keyword is used. Once the KWICs have been created, they are then wrapped in HTML and sent to the browser where they can be viewed. This reinforces what was learned in Output Data as HTML File, opting for a slightly different output. At the end of this lesson, {{you will be able to}} extract all possible n-grams from the text. In the next lesson, you will be learn how to output all of the n-grams of a given <b>keyword</b> <b>in</b> a document downloaded from the Internet, and display them clearly in your browser window...|$|R
40|$|The Web is an inexhaustible {{reservoir}} of machine-readable texts {{in most of}} the world’s written languages, available for compiling corpora or consulting directly as a “corpus”. This paper first surveys some characteristics of the Web and discusses the potential rewards and practical limitations of exploiting the Web either directly as a linguistic corpus or to compile corpora. Particular attention is paid to search engines, our gateways to the Web. Next the author reviews several innovative applications of Web data to corpus-related issues. KWiCFinder (KF), his application to help realize the Web’s promise for language scholars and learners, is described and motivated in detail. Readily accessible to novices yet powerful enough for advanced researchers, KF conducts Web searches, retrieves matching online documents and produces interactive <b>keyword</b> <b>in</b> <b>context</b> concordances of search terms. He details KF’s enhancements to AltaVista search and the limitations imposed by working with market-driven search engines. This paper then discusses the pitfalls of “webidence ” in serious research and proposes an initial solution. Finally the author reviews the future of the Web for corpus research and application...|$|E
40|$|This {{document}} {{is one of}} a series describing the background, functions, and utilization of the Regional Information System (RIS), developed by the Michigan-Ohio Regional Educational Laboratory (MOREL). RIS, which was developed to improve the accessibility of information for the educational practitioner, is described in this handbook. The handbook is also designed to help others plan, develop, and operate information systems. Included in the handbook are: (1) an introduction to RIS; (2) {{a detailed description of the}} System's two components: the Resource Bank and the Referral Library; (3) information on installation activities; (4) discussions of staffing, facilities, costs, the timetable, and evaluation; and (5) a summary of the evolution of the System. Appendixes include: the Resource Bank coding scheme, the Association Referral Information Service (ARIS) coding scheme, a list of suggested materials for a basic referral library collection, a sample numeric subclassification system, <b>keyword</b> <b>in</b> <b>Context</b> (KWIC) listings, the MOREL search procedure form, a sample data sheet, and an annotated list of selected collections of materials in the MODEL Information Center's information file. (Author/JB...|$|E
40|$|All {{engineering}} disciplines rely {{on standard}} components {{to design and}} build artifacts. The key technical challenge in software engineering is to enable the adoption of such a model {{to the development of}} software. The transformationfrom line-by-line development to component-based development will address many of the industry’s productivity and quality problems. Indeed, component-based software development has been a long- standing dream of the software industry, prompting a search for both technical and nontechnical solutions. A successful approach to component- based development requires a comprehensive solution that draws on advances in programming languages, programming paradigms, algorithm analysis, and software design. The technical problem can only be addressed by such an integrated solution. This paper presents an approach based on the C++ Standard Template Library. More than a traditional library, STL embodies a concrete approach to software design based on a well-defined taxonomy and theory of software components. I present the fundamental contributions of STL to a paradigm of component programming-a component-based software development paradigm {{in which there is a}} clear separation between component development and application development. I motivate component programming, give the requirements for components and catalogs, and give an example of component programming applied to the standard <b>Keyword</b> <b>in</b> <b>Context</b> (KWIC) problem. I then summarize the implications of component programming for the software industry and for software engineering education...|$|E
40|$|To support Search Requests and Quick Responses at the Aviation Safety Reporting System (ASRS), {{four new}} QUORUM {{methods have been}} developed: keyword search, phrase search, phrase generation, and phrase discovery. These methods build upon the core QUORUM methods of text analysis, modeling, and relevance-ranking. QUORUM keyword search {{retrieves}} ASRS incident narratives that contain one or more user-specified <b>keywords</b> <b>in</b> typical or selected contexts, and ranks the narratives on their relevance to the <b>keywords</b> <b>in</b> <b>context.</b> QUORUM phrase search retrieves narratives that contain one or more user-specified phrases, and ranks the narratives on their relevance to the phrases. QUORUM phrase generation produces a list of phrases from the ASRS database that contain a user-specified word or phrase. QUORUM phrase discovery finds phrases {{that are related to}} topics of interest. Phrase generation and phrase discovery are particularly useful for finding query phrases for input to QUORUM phrase search. The presentation of the new QUORUM methods includes: a brief review of the underlying core QUORUM methods; an overview of the new methods; numerous, concrete examples of ASRS database searches using the new methods; discussion of related methods; and, in the appendices, detailed descriptions of the new methods...|$|R
40|$|Manually {{assigned}} keywords {{provide a}} valuable means for accessing large document collections. They {{can serve as}} a shallow document summary and enable more efficient retrieval and aggregation of information. In this paper we investigate <b>keywords</b> <b>in</b> the <b>context</b> of the Dutch Folktale Database, a large collection of stories including fairy tales, jokes and urban legends. We carry out a quantitative and qualitative analysis of the <b>keywords</b> <b>in</b> the collection. Up to 80 % of the assigned keywords (or a minor variation) appear in the text itself. Human annotators show moderate to substantial agreement in their judgment of keywords. Finally, we evaluate a learning to rank approach to extract and rank keyword candidates. We conclude that this is a promising approach to automate this time intensive task...|$|R
40|$|City of pigs’ is a blog posting {{that once}} was a {{trending}} topic in Indonesia as it addressed the dirtiness of Bandung. This topic was not new since many newspaper has published news and articles about the some places in Bandung that is consistently dirty. However, what made this posting a trending topic was the author’s background (she was a foreigner), the text itself, and readers responses. Pros and cons did take place. As for the cons, many believe she addressed to specific communities, and established herself as separate group. In this paper I seek to describe how such assumption was derived. By using corpus approach, the text was processed and pronouns (with the contexts) were retrieved and analyzed. Pronoun reference analysis shows {{that some of the}} references are made exophorically, causing the readers have to use their metalinguistic knowledge, in this case the superiority of Caucasian race. At this point, multi interpretation is more likely to occur. The references for some pronouns are also generalized such as Muslims, People of Bandung, Asians and Indonesians, though some are implied. Quantitatively, the generalization is not much, but for some readers, this tends to be a crucial importance that cause them to respond the posting negatively. Keywords: blog, discourse, group identity, pronoun, text processing, <b>keyword</b> <b>in</b> <b>contexts...</b>|$|R
40|$|This study {{examines}} the usage and meanings of emotion-related body part {{terms that are}} found in metaphoric expressions. By using the data from electronic corpora of written and spoken languages, English head, heart, gut and leg parts and Japanese atama 'head', mune ‘chest’, hara ‘belly’ and ashi 'leg' are cross-culturally compared. The goal {{of this research is}} two-fold. One is to redefine the communicative function of metaphoric expressions that is conventionally considered peripheral. Another is to highlight potential ‘culture specific concepts’ by Lakoff and Johnson (1980) behind the metaphoric usages of the English and Japanese body part terms through a microscopic analysis of KWIC (<b>keyword</b> <b>in</b> <b>context)</b> search results. Research results show that English and Japanese associate different types of emotions/feelings with different parts of the body. For example, English places a center of self in the heart and Japanese places it at the gut. However, it appears that both English and Japanese commonly use Lakoff and Johnson’s (1980) ‘spatial orientation’ (e. g. up and down) to code one’s feelings/emotions in the body. My hypothesis is that the locations of the body parts play a role in representing different types of feelings. Specifically, I suggest that upper body represents controllable emotions and the lower body represents more primordial emotions and feelings such as anger and instinct...|$|E
40|$|The goal of {{this paper}} is to test three {{different}} NLP technologies to analyze French journalistic discourse about candidates during French presidential campaigns in order to evaluate discourses differences depending on the candidate gender and / or the candidate political party. Indeed it is suggested that working on a journalistic corpus with specific software can help studying linguistic patterns and choices which are made on the basis of political affiliation or gender stereotypes. These conclusions are drawn from quantitative and qualitative analysis carried out with 1. the software SEMY which gives semantic profiles semi-automatically; 2. the software ANTCONC which provides useful <b>Keyword</b> <b>in</b> <b>Context</b> (KWIC) or abstracts of the text in which is used the studied item, as well as collocations; 3. the software TERMOSTAT which works on discourse specificities, frequencies and most used morpho-syntactic patterns. Convergent asymmetries between female and male candidates in journalistic discourse (however conditionally) were found as far as our data dedicated to the 2007 and the 2012 presidential campaigns are concerned. We conclude that social gender (i. e. stereotypical expectations about who will be a typical member of a given category) and / or political favoritism may affect the representation of leadership in discourse and may affect in turn the readership, hence the electorate. Thus the paper recommends the use of corpus linguistic tools to support semi-automatic investigation of characteristics of political texts...|$|E
40|$|One of {{the most}} {{critical}} factors in changing teachers’ attitudes toward inclusive education practices {{is the way in which}} the school leader, that is a principal or vice-principal, actively and consistently demonstrates a positive attitude towards an inclusive school culture (Leithwood, Begley, 2 ̆ 6 Cousins, 1992). Specific types of behaviors by leaders may be more important than others in assisting teachers to develop their own attitudes concerning inclusive education. This convergent parallel mixed-methods study was designed to permit a comparison of rural Ontario elementary school leaders and teachers in a) their attitudes toward teaching students with mild to moderate disabilities and b) their perceptions of the value of school leader behaviors that support inclusive practices. Attitudes were assessed using the Attitudes Toward Teaching All Students with Mild to Moderate Disabilities instrument (Gregory 2 ̆ 6 Noto, 2012). School leaders’ behaviors were rated using items from the Louisiana Validated Practices Initiative (Louisiana Department of Education, 2005). A positive association was observed between participants’ attitudes and their ratings of the importance of specific behaviors of school leaders. Responses to an open-ended question soliciting reasons why leader behaviors are important were assessed using <b>keyword</b> <b>in</b> <b>context</b> analysis to observe patterns and themes. School leaders’ comments were related to the social justice foundations of inclusive education, while teachers’ comments related more to behaviors that support the practical implementation of inclusive education practices. The results of this study may assist school leaders to become aware of those behaviors that are most valued by teachers and other school leaders...|$|E
40|$|Google Print {{does not}} "change {{everything}} " regarding {{the need for}} professional cataloging and classification of books; its limitations make cataloging and classification even more important to researchers. Google’s keyword search mechanism, backed by the display of results in "relevance ranked " order, is expressly designed and optimized for quick information seeking rather than scholarship. Internet keyword searching does not provide scholars with the structured menus of research options, {{such as those in}} OPAC browse displays, that they need for overview perspectives on the book literature of their topics. Keyword searching fails to map the taxonomies that alert researchers to unanticipated aspects of their subjects. It fails to retrieve literature that uses keywords other than those the researcher can specify; it misses not only synonyms and variant phrases but also all relevant works in foreign languages. Searching by keywords {{is not the same as}} searching by conceptual categories. Google software fails especially to retrieve desired <b>keywords</b> <b>in</b> <b>contexts</b> segregated from the appearance of the same words <b>in</b> irrelevant <b>contexts.</b> As a consequence of the design limitations of the Google search interface, researchers cannot use Google to systematically recognize relevant books whose exact terminology they cannot specify in advance. Cataloging and classification, in contrast, do provide the recognition mechanisms that scholarship requires for systematic literature retrieval in boo...|$|R
40|$|Human {{resource}} {{development is a}} challenge in logistics, especially for small and medium-sized enterprises. The development towards Web 2. 0 and in touch the development to e-learning 2. 0 offers a chance to educate employees on-the-job. The <b>keywords</b> <b>in</b> this <b>context</b> are 'personal learning environment' and 'learning communities' <b>in</b> this <b>context.</b> This paper presents a possibility {{to make use of}} Web 2. 0 software for developing employees' knowledge in logistics. After illustrating the basic principles of e-learning {{as the result of a}} desk research, the authors draft a concept for an elearning 2. 0 environment in logistics. This concept will be used in the national excellence cluster 'LogistikRuhr' in Germany in order to provide high-quality online qualification options for logistics companies, especially small and medium-sized enterprises...|$|R
40|$|Older {{people are}} more prone to {{experience}} loneliness when living in residential care facilities. The {{purpose of this study was}} to explore older people&#x 0027;s experiences of loneliness <b>in</b> the <b>context</b> of institutionalized care. A voluntary and convenience-based sample of 10 white South African older people (age range 62 to 82 years; three men and seven women) was drawn. Data on the subjective experience of loneliness were then gathered through the Mmogo-method&#x 00 AE;, whereby drawings were employed to explore matters and issues of importance in the lives of older people that could be used to deal with loneliness. Data were analyzed thematically and visually as well as through the use of <b>keywords</b> <b>in</b> <b>context.</b> The results showed that older people experienced loneliness in terms of having unavailable interactions due to loss, and an absence of meaningful interpersonal interactions. Meaningful interpersonal interactions were described as when the older people had regular contact and a variety of interactions. Ineffective interpersonal styles (e. g. taking a controlling position in relationships and being rigid) elicited rejection and isolation, and were associated with a lack of confirmatory interpersonal relationships. It is recommended that greater emphasis should be placed on creating awareness of unhealthy group dynamics as well as on psychosocial interventions to develop group support. Interpersonal styles, either effective or ineffective, take place <b>in</b> a social <b>context,</b> which, <b>in</b> this research, was observed to be unsafe, lacking in care, and a non-stimulating environment...|$|R
40|$|We {{describe}} PAX, ”Portable Audio Concordance System”, a proof-of-concept {{prototype of}} a multipurpose, multilingual audio concordance toolkit. The {{primary goal is}} to support efficient grammar and lexicon construction in the documentation of unwritten languages; languages currently included are Ega, Anyi, and Koulango (Ivory Coast), additional samples in German and English. The approach combines methods from corpus linguistics, annotation theory and practice, phonetics and lexicography. 1. Objectives Finding occurences of selected utterances in multimodal corpora for multimodal lexica is {{the objective of the}} Portable Audio Concordance System (PAX) 1. Modern dictionaries these days claim to be corpus based, for example lexica from the COBUILD project (see (Sinclair, 1987)). This is in the sense that 1. the order of different meanings corresponds to the frequency in a defined corpus 2. the examples for the use of different words are taken from real world data, i. e. corpora. This presupposes a sufficiently preprocessed (markedup) textual source. For written texts {{there are a number of}} corpora used for this purpose such as the British National Corpus (British National Corpus, 2001) for English or the copora available via (COSMAS, 2002) for German. However, these corpora contain written texts, and there are concordances for lexical analysis of written texts, which are well known (see for example (van Eynde and Gibbon, 2000)), but no adequate concordancing tools for spoken language exist. The concordancing task for spoken language is difficult: units are less well identified, access to both transcription text and speech signal is required, and standard aids like word statistics need to be supplemented by visualised transformations of the speech signal. We demonstrate an enhanced <b>KeyWord</b> <b>in</b> <b>Context</b> (KWIC) concordance, based on a search space as defined by the annotation graph (Bird and Liberman, 2001), representing the transcription, and a search, which includes a variety of complex criteria. The XML formalism is based on the TASX format as described by (Milde and Gut, 2001). The position of a concordance in a concordance base...|$|E
40|$|BACKGROUND: Open-ended {{questions}} eliciting free-text comments {{have been}} widely adopted in surveys of patient experience. Analysis of free text comments can provide deeper or new insight, identify areas for action, and initiate further investigation. Also, they may be a promising way to progress from documentation of patient experience to achieving quality improvement. The usual methods of analyzing free-text comments {{are known to be}} time and resource intensive. To efficiently deal with a large amount of free-text, new methods of rapidly summarizing and characterizing the text are being explored. OBJECTIVE: The aim {{of this study was to}} investigate the feasibility of using freely available Web-based text processing tools (text clouds, distinctive word extraction, key words in context) for extracting useful information from large amounts of free-text commentary about patient experience, as an alternative to more resource intensive analytic methods. METHODS: We collected free-text responses to a broad, open-ended question on patients' experience of primary care in a cross-sectional postal survey of patients recently consulting doctors in 25 English general practices. We encoded the responses to text files which were then uploaded to three Web-based textual processing tools. The tools we used were two text cloud creators: TagCrowd for unigrams, and Many Eyes for bigrams; and Voyant Tools, a Web-based reading tool that can extract distinctive words and perform <b>Keyword</b> <b>in</b> <b>Context</b> (KWIC) analysis. The association of patients' experience scores with the occurrence of certain words was tested with logistic regression analysis. KWIC analysis was also performed to gain insight into the use of a significant word. RESULTS: In total, 3426 free-text responses were received from 7721 patients (comment rate: 44. 4 %). The five most frequent words in the patients' comments were "doctor", "appointment", "surgery", "practice", and "time". The three most frequent two-word combinations were "reception staff", "excellent service", and "two weeks". The regression analysis showed that the occurrence of the word "excellent" in the comments was significantly associated with a better patient experience (OR= 1. 96, 95 %CI= 1. 63 - 2. 34), while "rude" was significantly associated with a worse experience (OR= 0. 53, 95 %CI= 0. 46 - 0. 60). The KWIC results revealed that 49 of the 78 (63 %) occurrences of the word "rude" in the comments were related to receptionists and 17 (22 %) were related to doctors. CONCLUSIONS: Web-based text processing tools can extract useful information from free-text comments and the output may serve as a springboard for further investigation. Text clouds, distinctive words extraction and KWIC analysis show promise in quick evaluation of unstructured patient feedback. The results are easily understandable, but may require further probing such as KWIC analysis to establish the context. Future research should explore whether more sophisticated methods of textual analysis (eg, sentiment analysis, natural language processing) could add additional levels of understanding...|$|E
40|$|We {{report a}} series of {{controlled}} comparisons of 57 one-to-one qualitative interviews and 37 mixed-sex joint interviews on the same health related topics. Our analysis identifies comparative keyword frequencies and is supported by qualitative investigations of <b>keywords</b> <b>in</b> <b>context,</b> drawing on existing relevant knowledge of common gender differences in language choice. Men {{are less likely to}} swear in joint interviews and women no more likely to do so. Other gender differences, for example, concerning women’s propensity to talk about feelings and a wide range of other people, and men’s propensity to talk about information technology, are reduced in the joint interview setting. Health issues, including pregnancy and children’s health, appear to be seen by both men and women as topics where women’s perspectives should be prominent. The findings suggest that this tendency is more marked in the joint interview setting, so researchers wanting to find out about men’s experiences of fatherhood may find out more in one-to-one interviews with men. The greater readiness of men to engage in gender-stereotyped behaviour in sole interviews, most of which involved a female interviewer, suggests that an interviewer’s gender identity is perceived as somewhat neutral by comparison with the considerable salience of the gender of a joint respondent. This finding potentially contributes to knowledge of the qualitative interview as a special form of institutional talk...|$|R
40|$|Chapitre de 20 pages consacrés aux emplois de logiciels pour aider aux {{analyses}} semi-automatiques de discoursInternational audienceThis {{research study}} tested three different NLP technologies to analyze representative journalistic discourse {{used in the}} 2007 and 2012 presidential campaigns in France. The analysis focused on the discourse {{in relation to the}} candidate's gender and/ or political party. Our findings suggest that using specific software to examine a journalistic corpus can reveal linguistic patterns and choices {{made on the basis of}} political affiliation and/or gender stereotypes. These conclusions are drawn from quantitative and qualitative analysis carried out with three different software programs: SEMY, which semi-automatically provides semantic profiles; ANTCONC, which provides useful <b>Keywords</b> <b>in</b> <b>Context</b> (KWIC) or abstracts of texts, as well as collocations; TERMOSTAT, which reveals discourse specificities, frequencies and the most common morpho-syntactic patterns. Analysis of our data point to convergent asymmetries between female and male candidates in journalistic discourse (however conditionally) for the 2007 and the 2012 French presidential campaigns. We conclude that social gender (i. e., stereotypical expectations of who will be a typical member of a given category) and / or political favoritism may affect the representation of leadership in discourse, which, in turn, may influence the readership, hence the electorate. Thus the study recommends the use of corpus linguistic tools for the semi-automatic investigation of political texts...|$|R
40|$|Modern {{retrieval}} {{systems are}} in fact two-tier systems in which a user first views summaries of the results in a hit-list, and only when she decides to "click," the full result document is consulted. Standard information retrieval evaluation ignores the crucial summary step, and directly evaluates {{in terms of the}} relevance of the resulting document. In this paper, we investigate the impact of the result summaries on the user’s decision to click or not to click. Specifically, we want to find out both what information in the summary triggers a positive selection decision to view a result, and what information triggers a negative selection decision. We use a special document genre, archival finding aids, where results have a complex document structure and currently available systems experiment with structured summaries having both by an archivist) and query-biased snippets (showing the matching <b>keywords</b> <b>in</b> <b>context).</b> We conducted an experiment in which we asked test persons to explicitly mark the parts of summaries that trigger a selection decision, and asked them to explain further (i. e. why and how). The results from this user study indicate the importance of sufficient <b>context</b> <b>in</b> the summary. Selection decisions were primarily of the document. This may be a result of the completeness and coherence of the information in these elements, although also the length played a clear role. A whole paragraph (as in the abstract) triggered a decision more frequently than a short sentence (as in the title) or an incomplete sentence (as in the query-biased snippets) ...|$|R
40|$|The {{relationship}} between Greek love novels (especially Leucipe and Clitofont) and tragedy is analyzed in this study, {{by emphasizing the}} strong {{relationship between}} tragedy and rhetoric shown by most of these novels. In particular, I go deeper into some scenes where keywords related to the dramatics genres, especially tragedy, appear. This study is structured in two parts: in the first one, I pay attention to citations and {{to the use of}} &# 964;&# 961;&# 945;&# 947;&# 8179;&# 948;&# 943;&# 945; and its derivates; in the second one, The performance in the courtroom, the staging of the speeches on the VIII book of Achilles Tatius novel is analyzed. Through the revision of these <b>keywords</b> <b>in</b> their <b>context,</b> the importance of the rhetoric to systematize the reflection about the dramatic genres, particularly about tragedy, and their performance is suggested...|$|R
40|$|The {{power sector}} {{is in many}} ways {{different}} from other sectorsin the economy. Most of these peculiarities are linked to the difficulty to store electricity, the resulting necessity for supply to match demand in every instant of time, or the required distri-bution networks. The economic characteristics are partly linked to these properties, but are extended by the essential role of elec-tricity for production and services. <b>Keywords</b> <b>in</b> this <b>context</b> are security of supply, market power, resource use, long investment cycles, and adverse external effects. In effect, the electricity sec-tor is a classical example of a natural monopoly, where pareto-optimal self-regulation by market forces alone is hard to achieve, making the electricity sector prone to governmental re-gulation efforts. From an environmentalist perspective, electricity generation is a major source of greenhouse gases. In 2007, power plants emitted 38 percent of the annual CO 2 emissions in German...|$|R
40|$|Named entity {{disambiguation}} concerns linking {{a potentially}} ambiguous mention of named entity in text to an unambiguous identifier {{in a standard}} database. One approach to this task is supervised classification. However, the availability of training data is often limited, and the available data sets tend to be imbalanced and, in some cases, heterogeneous. We propose a new method that distinguishes a named entity by finding the informative <b>keywords</b> <b>in</b> its surrounding <b>context,</b> and then trains a model to predict whether each keyword indicates the semantic class of the entity. While maintaining a comparable performance to supervised classification, this method avoids using expensive manually annotated data for each new domain, and thus achieves better portability. ...|$|R
40|$|This paper {{reflects}} {{a research project}} {{on the influence of}} online news media (from print, radio, and televised outlets) on disaster response. Coverage on the October 2010 Indonesian tsunami and earthquake was gathered from 17 sources from October 26 through November 30. This data was analyzed quantitatively with respect to coverage intensity over time and among outlets. Qualitative analyses were also conducted using keywords and value scale that assessed the degree of positivity or negativity associated with that <b>keyword</b> <b>in</b> the <b>context</b> of accountability. Results yielded insights into the influence of online media on actors 2 ̆ 7 assumption of accountability and quality of response. It also provided information as to the optimal time window in which advocates and disaster management specialists can best present recommendations to improve policy and raise awareness. Coverage of outlets was analyzed individually, in groups, and as a whole, in order to discern behavior patterns for a better understanding of media interdependency. This project produced analytical insights but is primarily intended as a prototype for more refined and extensive research...|$|R
40|$|Many {{information}} management systems maintain multiple time stamped versions of documents. The archives of web pages, version control systems, wikis and backup mechanisms {{are examples of}} such systems. For such temporally versioned document collections, a search using keywords along the temporal dimension is valuable. This paper studies the temporal dimension of <b>keyword</b> search <b>in</b> the <b>context</b> of text document collections. The inverted index, which {{is an integral part}} of keyword based IR technique, requires several extensions for it to support keyword search over temporal document collections. We propose a number of techniques that explore such extensions. Several experimental results are also presented to compare the proposed solutions...|$|R
50|$|Java {{language}} {{designers have}} avoided new keywords {{as much as}} possible, preferring instead to introduce new syntactic constructs that were not legal before or to reuse existing <b>keywords</b> <b>in</b> new <b>contexts.</b> This way they didn't jeopardize backward compatibility. An example of the former {{can be found in}} how the for loop was extended to accept iterable types. An example of the latter can be found in how the extends and (especially) the super keywords were reused for specifying type bounds when generics were introduced in Java 1.5. At one time (Java 1.4) a new keyword assert was introduced that was not reserved as a keyword before. This had the potential to render previously valid code invalid, if for instance the code used assert as an identifier. The designers chose to address this problem with a four-step solution: 1) Introducing a compiler switch that indicates if Java 1.4 or later should be used, 2) Only marking assert as a keyword when compiling as Java 1.4 and later, 3) Defaulting to 1.3 to avoid rendering previous (non 1.4 aware code) invalid and 4) Issue warnings, if the <b>keyword</b> is used <b>in</b> Java 1.3 mode, in order to allow the developers to change the code.|$|R
40|$|Abstract. The {{developing}} {{of innovative}} solutions {{in the emerging}} eHealth market requires strong economic efforts which may be justified only in presence of particularly suitable boundary conditions. Among the factors retained of primary importance {{for the development of}} eHealth, a correct approach to id-management is unanimously considered fundamental. Three <b>keywords</b> <b>in</b> the id-management <b>context</b> appear particularly important: standardization, security and safety. Standardization may contribute to increase the size and duration of the eHealth market, while security and safety may encourage all the stakeholders to trust in a appropriate and safe management of all the very sensitive personal data involved in the eHealth applications. The aim of the present paper is analyzing some security and safety issues in eHealth from the particular prospective of the identity management and standardization. The paper highlights the mission of the EU funded “BioHealth ” project whose mission is to increase the stakeholders’ knowledge about existing and emerging standards in eHealth with particular reference to identity management [1]...|$|R
