6201|2066|Public
25|$|Connect-It - <b>Data</b> <b>integration</b> tool. It is {{now sold}} as HP Connect-It software.|$|E
25|$|The {{application}} of continuous delivery and DevOps to data analytics has been termed DataOps. DataOps seeks to integrate data engineering, <b>data</b> <b>integration,</b> data quality, data security, and data privacy with operations. It applies principles from DevOps, Agile Development and the statistical process control, used in lean manufacturing, {{to improve the}} cycle time of extracting value from data analytics.|$|E
25|$|SQL Server Integration Services (SSIS) {{provides}} ETL capabilities for SQL Server {{for data}} import, <b>data</b> <b>integration</b> and data warehousing needs. Integration Services includes GUI tools to build workflows such as extracting data from various sources, querying data, transforming data—including aggregation, de-duplication, de-/normalization and merging of data—and then exporting the transformed data into destination databases or files.|$|E
5000|$|On January 15, 2016, Untappd {{announced}} that it would become a subsidiary of Next Glass, a beer and wine rating and suggesting application. [...] Both companies indicated their applications will remain independent, but will benefit from increased <b>data</b> <b>integrations.</b>|$|R
40|$|In {{order to}} realize the {{integration}} and sharing for multi-source marine data, the paper took the visualization application of the multi-source marine environment data as an example to discuss the realization way of the <b>data's</b> <b>integration</b> and sharing. By encapsulating the marine environment data and its application model to web services, we constructed a multi-source marine environment data applying platform system framework through interne. The system can shield the data isomerism and the application environment isomerism, and realize the integration and sharing for the multi-source marine environment data. At {{the same time the}} distributed structure of the system can raise its flexibility and expansibility. So the establishment of the system proves the feasibility of web service in multi-source ocean environment <b>data's</b> <b>integration</b> and sharing...|$|R
50|$|While ETL Tools have {{traditionally}} been for developers and I.T. staff, the new trend is to provide these capabilities to business users so they can themselves create connections and <b>data</b> <b>integrations</b> when needed, rather than going to the I.T. staff. Gartner refers to these non-technical users as Citizen Integrators.|$|R
25|$|Moksiskaan is a <b>data</b> <b>integration</b> {{framework}} for the cancer research and molecular biology. The framework provides a relational database that represents a graph of biological entities such as genes, protein, drugs, pathways, diseases, biological processes, cellular components, and molecular functions. In addition, {{there is a wide}} set of analysis and accession tools built on top of this data. The great majority of these tools are implemented as Anduril components and functions.|$|E
25|$|Wanting {{to go back}} to his {{interesting}} life, Kyon activates {{the program}} and goes back in time to the Tanabata of three years ago. After meeting up with the future Mikuru, he obtains an uninstall program from the past's Yuki, which needs to be shot at the culprit right after the change in the early hours of December 18. Returning to the present, they find the culprit, Yuki, who had borrowed Haruhi's power to change everyone's memories except Kyon's, giving him the choice of which world he would rather live in. Kyon questions himself about his choice and thinks to himself that a normal world without the SOS Brigade and Haruhi Suzumiya would be calm and peaceful and thinks Yuki was tired of everything she had to do like monitoring Haruhi's behavior and protecting Kyon, but finally decides that his original world was more interesting and fun. Kyon tries to install the program into Yuki but is stabbed by Ryoko, who had retained her psychotic behavior. Before Ryoko can finish him off, he is rescued by future counterparts of Yuki, Mikuru and himself. He wakes up a few days later in a hospital, where the world is back to normal, but almost everyone believes Kyon had been in a coma since December 18 after falling down the stairs. When Yuki mentions to Kyon how the <b>Data</b> <b>Integration</b> Thought Entity would punish her for her actions, Kyon tells her to let them know that if they ever try such a thing, he can tell Haruhi about him being John Smith and have her alter reality so the organization would cease to exist. As December 24 comes and his everyday life returns, Kyon decides there is still time before he has to go back in time to save himself and decides to join in on the Christmas party.|$|E
500|$|In its 2014 report [...] "Cool Vendors in <b>Data</b> <b>Integration</b> and Data Quality", Gartner praised Paxata for {{developing}} a [...] "business-user-friendly" [...] data quality product that does not use code. Ventana Research said its spreadsheet-based user interface [...] "should resonate well with business analysts," [...] who are resistant {{to move away from}} familiar Excel-like programs. Gartner also said Paxata was recognized in the report due to its automated, algorithm-based features and how it tracks any changes made to the data.|$|E
30|$|<b>Data</b> integration: <b>Integration</b> of {{multiple}} databases, data cubes, or files.|$|R
40|$|Geographic <b>data</b> set <b>integration</b> is {{particularly}} important for update propagation, i. e. the reuse of updates from one data set in another data set. In this thesis geographic <b>data</b> set <b>integration</b> (also known as map integration) between two topographic data sets, GBKN and TOP 10 vector, is described. GBKN is a large-scale topographic data set and TOP 10 vector is a medium-scale topographic data set. Geographic <b>data</b> set <b>integration</b> (or map integration) is defined as ‘the process of establishing links between corresponding object instances in different, autonomously produced, geographic data sets of the same geographic space’. Corresponding object instances are semantically similar. Semantically similar means that corresponding object instances refer to the same terrain situation. In {{the first part of}} this thesis a general introduction to geographic <b>data</b> set <b>integration</b> is given. Relevant literature is reviewed. In the second part a conceptual framework for geographic <b>data</b> set <b>integration</b> is developed. Two important components of this framework are a domain ontology and a set of surveying rules. A domain ontology is important because it contains a set of shared concepts. It is this set of shared concepts of terrain situations that makes it possible to detect corresponding object instances...|$|R
40|$|Descriptive {{global scale}} diagnoses of the First Global Atmospheric Research Experiment SOP- 1 {{analyses}} {{were made and}} compared against controlled, real <b>data</b> <b>integrations</b> of the Goddard Laboratory of Atmospheric Science (GLAS) general circulation model (GCM) {{as well as other}} data sets. The effects of critical latitudes were studied; the influence of tropical wind data and latent heating upon the GLAS GCM was diagnosed; planetary wave structure on various time scales from the diurnal to the monthly was studied; and the GLAS analyses were compared with other analyses. Short term controlled GLAS GCM integrations show that: (1) the inclusion of tropical wind data in real <b>data</b> <b>integrations</b> has an important influence in the mid-latitude prediction in both hemispheres; and (2) the tropical divergent wind reacts almost immediately to alteration of the tropical latent heating. The presence or absence of zonally averaged easterlies depends strongly upon the presence of tropical latent heating...|$|R
500|$|According to IDC, SAS is {{the largest}} market-share holder in [...] "advanced analytics" [...] with 35.4 {{percent of the market}} as of 2013. It is the fifth largest market-share holder for {{business}} intelligence (BI) software with a 6.9% share and the largest independent vendor. It competes in the BI market against conglomerates, such as SAP BusinessObjects, IBM Cognos, SPSS Modeler, Oracle Hyperion, and Microsoft BI. SAS has been named in the Gartner Leader's Quadrant for <b>Data</b> <b>Integration</b> Tool and for Business Intelligence and Analytical Platforms.|$|E
500|$|In 2002, the Text Miner {{software}} was introduced. Text Miner analyzes text data like emails for patterns in Business Intelligence applications. In 2004, SAS Version 9.0 was released, which was dubbed [...] "Project Mercury" [...] and {{was designed to}} make SAS accessible to {{a broader range of}} business users. Version 9.0 added custom user interfaces based on the user's role and established the point-and-click user interface of SAS Enterprise Guide as the software's primary graphical user interface (GUI). The Customer Relationship Management (CRM) features were improved in 2004 with SAS Interaction Management. In 2008 SAS announced Project Unity, designed to integrate data quality, <b>data</b> <b>integration</b> and master data management.|$|E
2500|$|In 1992, CoSort added related data {{manipulation}} functions through a control language interface based on DEC VAX/VMS sort utility syntax, which evolved {{through the years}} to handle file-based <b>data</b> <b>integration</b> and staging functions in data warehouse ETL operations: ...|$|E
5000|$|Winner of Managing Automotion's Progressive Manufacturing 100 Award for <b>Data</b> & <b>Integration</b> Mastery ...|$|R
3000|$|... [...]). When {{dealing with}} {{discrete}} <b>data,</b> the <b>integration</b> {{process can be}} approximated using complex summation.|$|R
5000|$|Reduxio Storage Manager for Microsoft - <b>Data</b> {{protection}} <b>integration</b> {{software for}} Microsoft VSS based applications.|$|R
2500|$|In mathematics, an {{integral}} assigns numbers to functions {{in a way}} that can describe displacement, area, volume, and other concepts that arise by combining infinitesimal <b>data.</b> <b>Integration</b> is one of the two main operations of calculus, with its inverse, differentiation, being the other. Given a function [...] of a real variable [...] and an interval [...] of the real line, the definite integral ...|$|E
2500|$|The MGED Ontology was {{originally}} {{identified in the}} transcriptomics domain by the FGED Society and was developed {{to address the needs}} of <b>data</b> <b>integration.</b> [...] Following a mutual decision to collaborate, this effort later became a wider collaboration between groups such as FGED, PSI and MSI in response to the needs of areas such as transcriptomics, proteomics and metabolomics and the FuGO (Functional Genomics Investigation Ontology) was created. [...] This later became the OBI covering the wider scope of all biomedical investigations.|$|E
2500|$|As acting {{managing}} {{director for the}} Institute for Data Drive Design (ID3), a nonprofit research group founded out of MIT Media Lab, Harple led efforts to organize and frame work in digital currencies, identity solutions, trust frameworks, and big <b>data</b> <b>integration,</b> resulting in an industry announcement in the bitcoin segment: the ID3 Windhover Principles, a set of principles for identity, trust, and data to be implemented on an open source platform. Harple described the new digital framework, written collaboratively by digital currency industry stakeholders, as [...] "an inclusive platform to transform how we, as collective Internet users, can take back our personal data, and share it in a trusted and secure way — not only for Bitcoin and digital currency transactions, but for other data and media types as well". The Windhover principles were subsequently endorsed by 21 of the leading Bitcoin and digital currency companies.|$|E
50|$|In February 2012, Talend Open Studio for Big <b>Data,</b> an <b>integration</b> {{application}} for big data, was released.|$|R
50|$|Qwest Interprise America, Inc. (stylized !NTERPRISE) {{was created}} in 1995 to address the {{advanced}} <b>data,</b> network <b>integration</b> and interworking needs of large customers.|$|R
40|$|Automatings hema matchingis challenging. Previous {{approaches}} (e. g. [MBR 01, DDH 01]) to automatings hema matching {{focus on}} computing direct element matches between twos chemas Schemas however, rarely match directly. Thus {{to complete the}} tas k ofs hema matching, we musals compute indirect element matches In this paper, we presq t a framework for generating directas wellas many indirect element matches between as ources chema and a targets hema. Recognizing expected data values ass ciated withs hema elements and applying s hema-s tructure heurisrfq are the key ideas to computing indirect matches Experiments we have conducted overs everal real-world application domains s w encouraging resJXCV yielding over 90 %precisUq and recall for both direct and indirect element matches Keyword: Schema matching, <b>data</b> <b>integration,s</b> chema <b>integration,</b> <b>data</b> exchange. ...|$|R
2500|$|While {{much less}} {{expensive}} to compile and produce, the revised digital U.S. topo maps {{have been criticized for}} a lack of accuracy and detail in comparison to older generation maps based on aerial photo survey and field checks. As the digital databases were not designed for producing general purpose maps, <b>data</b> <b>integration</b> can be a problem when retrieved from sources with different resolutions and collection dates. [...] Man-made features once recorded by direct field observation are not in any public domain national database, and are frequently omitted from the newest generation digital topo maps, including windmills, mines and mineshafts, water tanks, fence lines, survey marks, parks, recreational trails, buildings, boundaries, pipelines, telephone lines, power transmission lines, and even railroads. [...] Additionally, the digital map's use of existing software may not properly integrate different feature classes or prioritize and organize text in areas of crowded features, obscuring important geographic details. [...] As a result, some have noted that the U.S. Topo maps currently fall short of traditional topographic map presentation standards achieved in maps drawn from 1945 [...] to 1992.|$|E
5000|$|Core <b>data</b> <b>integration</b> {{is the use}} of <b>data</b> <b>integration</b> {{technology}} for a significant, centrally planned and managed IT initiative within a company. Examples of core <b>data</b> <b>integration</b> initiatives could include: ...|$|E
5000|$|Because it is {{difficult}} to promptly roll out a centrally managed <b>data</b> <b>integration</b> solution that anticipates and meets all <b>data</b> <b>integration</b> requirements across an organization, IT engineers and even business users create edge <b>data</b> <b>integration,</b> using technology that may be incompatible with that used at the core. In contrast to a core <b>data</b> <b>integration,</b> an edge <b>data</b> <b>integration</b> is not centrally planned and is generally completed with a smaller budget and a tighter deadline.|$|E
40|$|Abstract:- Bitmap {{indexing}} is a diffuse {{approach for}} processing efficiently complex queries in decision support activities. Besides this common use of bitmap structures, {{the use of}} bitmap indices to represent analytical views of user’s data is presented here. In this approach, bitmaps can be created and utilized not only to index different domain attribute values, but also to pre-compute legal relational algebra query expressions useful for the analytic purposes. According to this approach, problems of <b>data</b> <b>integrations</b> and conceptual correlations of analytical data can be efficiently solved...|$|R
5000|$|Biometrics System (Sensors, <b>Integration,</b> <b>Data</b> Analysis, Verification Techniques) ...|$|R
30|$|<b>Data</b> {{sharing and}} <b>integration</b> The system uses the only {{database}} {{and the same}} sets of data for inference management. The interface between the database and the high-level language is utilized to achieve selective transmission and data call; as a result, the <b>data</b> sharing and <b>integration</b> efficiency is significantly improved.|$|R
50|$|Traditionally, <b>data</b> <b>integration</b> {{and data}} {{exchange}} systems {{have aimed to}} offer many of the purported services of dataspace systems.Dataspaces {{can be viewed as}} a next step in the evolution of <b>data</b> <b>integration</b> architectures, but are distinct from current <b>data</b> <b>integration</b> systems in the following way. <b>Data</b> <b>integration</b> systems require semantic integration before any services can be provided. Hence, although there is not a single schema to which all the data conforms and the data resides in a multitude of host systems, the <b>data</b> <b>integration</b> system knows the precise relationships between the terms used in each schema. As a result, significant up-front effort is required in order to set up a <b>data</b> <b>integration</b> system.|$|E
50|$|Ontology-based <b>data</b> <b>integration</b> {{involves}} the use of ontology(s) to effectively combine data or information from multiple heterogeneous sources. It is one of the multiple <b>data</b> <b>integration</b> approaches and may be classified as Global-As-View (GAV). The effectiveness of ontology based <b>data</b> <b>integration</b> is closely tied to the consistency and expressivity of the ontology used in the integration process.|$|E
50|$|It {{has been}} claimed that edge <b>data</b> <b>integration</b> do not {{typically}} require large budgets and centrally managed technologies, {{which is in}} contrast to a core <b>data</b> <b>integration.</b>|$|E
40|$|Abstract: - Bitmap {{indexing}} is a diffuse {{approach for}} processing efficiently complex queries in decision support activities. Besides this common use of bitmap structures, {{the use of}} bitmap indices to represent analytical views of user’s data is presented here. In this approach, bitmaps can be created and utilized not only to index different domain attribute values, but also to pre-compute legal relational algebra query expressions useful for the analytic purposes. According to this approach, problems of <b>data</b> <b>integrations</b> and conceptual correlations of analytical data can be efficiently solved...|$|R
40|$|We {{describe}} a software framework, GAIA, that supports semiautomated annotation of uncharacterized sequence data. The annotation framework incorporates annotation by <b>data</b> source <b>integration,</b> <b>data</b> analysis, and manual data entry. Components {{of the system}} include a con gurable, open data analysis pipeline, a relational information storage manager, and Java-based graphical user interfaces. We discuss design decisions and tradeo s in building such a system, and policies and strategies for producing consistent, uniform, high quality annotation. ...|$|R
2500|$|TACTIC: reporting, management, dashboard, <b>data</b> {{mining and}} <b>integration,</b> {{workflow}} capabilities ...|$|R
