2|10|Public
40|$|The idea of {{directional}} types is {{to describe}} the computational behaviour of Prolog programs by associating an input and an output assertion to every predicate. The <b>input</b> <b>assertion</b> puts a restriction on {{the form of the}} arguments of the predicate in the initial atomic goals. The output assertion describes the form of the arguments at success, given that the predicate is called as specified by its <b>input</b> <b>assertion.</b> This paper discusses two aspects of directional types: the declarative notion of input-output correctness and the operational notion of call correctness. By separating these two concepts, we readily obtain better correctness criteria than those existing in the literature. We further show how directional types can be used for controlling execution of logic programs through a delay mechanism. 1 Introduction Recently there has been a growing interest in the notion of directional types for Prolog programs [6, 12, 2, 3, 1, 11]. This kind of prescriptive typing describes the intende [...] ...|$|E
40|$|A {{description}} of methods and an implementation of a system for automalic generation of programs is given. The problems of writing programs for numerical computation, symbol manipulation, robot control and everyday planning have been studied and some programs generated. A particular formalism, i. e. a FRAME, has been developed to define the programming environment and permit the statement of a problem. A frame, F _ is formulated within the Logic of Prot_rams [Hoare 1969, Hoare and Wirth 1972] and includes primitive functions and procedures, axioms, definitions and rules of program composition. Given a frame, F, a problem for program constuction may be stated as a pair , where] is an <b>input</b> <b>assertion</b> and G is an output assertion. The program generation task is to construct a program A such that I{A}r, where I ': _ G. This process {{may be viewed as}} a search in the Logic of Programs for a proof that the generated program satisfies the given input-output assertions. Correctness of programs generated using the formal algorithm is discussed. A frame is translated into a backtrack problem solver augmented by special search procedures. The system is interactive, responds to simple advice and allows incremental and structured program development. The output or solution program is a subset of ALGOL containing procedure calls, assignments, while loops and conditional statements. This research was largely done at Stanford University as the author's Ph. D. Thesis...|$|E
50|$|In Between. Many tools {{require more}} user {{intervention}} than program analyses, {{in that they}} expect the user to <b>input</b> <b>assertions</b> such as pre/post specs for functions or loop invariants, but after this input is given they attempt to be fully or almost fully automatic; this mode of verification goes back to classic works in the 1970s such as J King's verifier, and the Stanford Pascal Verifier. This style of verifier has recently been called auto active verification, a term which intends to evoke the way of interacting with a verifier via an assert-check loop, analogous to the interaction between a programmer and a type-checker.|$|R
40|$|Data {{validation}} rules constitute the constraints that data input and processing must adhere to {{in addition to}} the structural constraints imposed by a data model. Web modeling tools do not make all types of data validation explicit in their models, hampering full code generation and model expressivity. Web application frameworks do not offer a consistent interface for data validation. In this paper, we present a solution for the integration of declarative data {{validation rules}} with user interface models in the domain of web applications, unifying syntax, mechanisms for error handling, and semantics of validation checks, and covering value well-formedness, data invariants, <b>input</b> <b>assertions,</b> and action assertions. We have implemented the approach in WebDSL, a domain-specific language for the definition of web applications. Software TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
40|$|AbstPorr-IIn this paper, {{we present}} an {{approach}} to verify emciently assertions added {{on top of the}} SystemC library and based on the Property Specification Language (EL). In order to improve the assertion coverage, we also propose an approach based on both static code analysis and genetic algorithms. Static code analysis will help generate a dependency relation between <b>inputs</b> and <b>assertion</b> parameters as well as define the ranges of <b>inputs</b> affecting the <b>assertion,</b> The genetic algorithm will optimize the test generation to get more efficient coverage of the assertion. Experimental results illustrate the efficiency or our approach compared to random simulation. I. IKTRODUCTION SystemC [7] is among a group of system level design languages proposed to raise the abstraction level for System-on-a-Chip (SoC) design and verification. It is expected t...|$|R
40|$|International audienceEvolution of Systems-On-Chip (SoC) {{increases}} {{the challenge of}} verification and post-silicon debug. Nowadays, Assertion Based Verification (ABV) is a widely used methodology. Languages like PSL (Property Specification Language) or SVA (System Verilog Assertions) allows engineers to define properties at Register Transfer Level (RTL). Properties can then be used to generate simulation/hardware assertion checkers for dynamic verification. In this paper, we propose to consider ANSI-C assertions during High-Level Synthesis (HLS) of hardware accelerators (HWacc) to automatically generate on-chip monitors (OCM). The proposed method is portable to any HLS tool and supports both static and dynamic application behaviors. OCM is implemented separately from the HWacc and an original technique is introduced for their synchronization. Two synthesis options are proposed for the OCM design i. e. speed and area. Experimental results show {{the interest of the}} proposed approach: while the cost of the OCMs mainly depends on the complexity of <b>input</b> <b>assertions,</b> setting synthesis option is area allows reducing the complexity of the OCM by 2. 37 x on average compared to the option for speed optimization...|$|R
40|$|This {{paper is}} a pre-print of: Danny M. Groenewegen, Eelco Visser. Integration of Data Validation and User Interface Concerns in a DSL for Web Applications. In Mark G. J. van den Brand, Jeff Gray, editors, Software Language Engineering, Second International Conference, SLE 2009, Denver, USA, October, 2009. Lecture Notes in Computer Science, Springer, 2009. Data {{validation}} rules constitute the constraints that data input and processing must adhere to {{in addition to}} the structural constraints imposed by a data model. Web modeling tools do not address data validation concerns explicitly, hampering full code generation and model expressivity. Web application frameworks do not offer a consistent interface for data validation. In this paper, we present a solution for the integration of declarative data validation rules with user interface models in the domain of web applications, unifying syntax, mechanisms for error handling, and semantics of validation checks, and covering value well-formedness, data invariants, <b>input</b> <b>assertions,</b> and action assertions. We have implemented the approach in WebDSL, a domain-specific language for the definition of web applications. Software Computer TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
40|$|AbstractKnowledge-based {{systems are}} often brittle when given unanticipated <b>input,</b> i. e. <b>assertions</b> or queries that misalign with the {{ontology}} {{of the knowledge}} base. We call such misalignments “loose speak”. We found that loose speak occurs frequently in interactions with knowledge-based systems, but with such regularity that it often can be interpreted and corrected algorithmically. We {{also found that the}} common types of loose speak, such as metonymy and noun-noun compounds, have a common root cause. We created a Loose-Speak Interpreter and evaluated it with a variety of empirical studies in different domains and tasks. We found that a single, parsimonious algorithm successfully interpreted numerous manifestations of loose speak with an average precision of 98 % and an average recall of 90 %...|$|R
40|$|Formally verifying {{properties}} of signals in a circuit has several applications in an equivalence checking based formal veri#cation #ow. In a hierarchical design, functionality is divided across blocks. This necessitates {{the use of}} constraints on input signals of a block to avoid false negatives. Validating such <b>input</b> constraints requires <b>assertion</b> checking at the outputs of modules generating the constrained signals. In this paper, we present an e#cient assertion checker for combinational properties which avoids the BDD explosion problem by #nding an optimal intermediate correlation free frontier. It has been successfully used in an industrial setting to uncover a number of bugs. 1 Introduction As the functional complexity of chips has grown, it has become impractical to reason about their correctness manually. Traditional techniques for veri#cation of a design against its speci#cation such as simulation or emulation-based methods can leave corner cases untested, and can be prohibiti [...] ...|$|R
40|$|In {{this report}} a {{computational}} study of ConceptNet 4 {{is performed using}} tools {{from the field of}} network analysis. Part I describes the process of extracting the data from the SQL database that is available online, as well as how the closure of the <b>input</b> among the <b>assertions</b> in the English language is computed. This part also performs a validation of the input as well as checks for the consistency of the entire database. Part II investigates the structural properties of ConceptNet 4. Different graphs are induced from the knowledge base by fixing different parameters. The degrees and the degree distributions are examined, the number and sizes of connected components, the transitivity and clustering coefficient, the cores, information related to shortest paths in the graphs, and cliques. Part III investigates non-overlapping, as well as overlapping communities that are found in ConceptNet 4. Finally, Part IV describes an investigation on rules. Comment: 152 pages, 99 tables, 23 figures (76 sub-figures...|$|R
40|$|The Property Specification Language (PSL) is an IEEE {{standard}} {{which allows}} developers to specify precise behavioral properties of hardware designs. PSL assertions can be embedded within code written in hardware description languages (HDL) such as Verilog to monitor signals of interest. Debugging simulations {{at the register}} transfer level (RTL) is often required to verify the functionality of a design before synthesis. Traditional methods of RTL debugging can help locate failures, but do not necessarily immediately help in discovering {{the reasons for the}} failures. The P 2 VSim tool presents the ability to combine multiple Verilog signals not only instantaneously, but also across multiple clock cycles, producing a graphical display of the state of active PSL assertions in a given RTL simulation. When using the P 2 VSim tool, users will write PSL assertions directly into their Verilog source files. After the tool searches for and loads the embedded assertions, execution trace monitors for the relevant Verilog signals are dynamically generated and written back into the Verilog source code. P 2 VSim then invokes an RTL simulator, Modelsim, to generate a simulation execution trace, requiring that the designer has some hardware or software testbench already in place. Next, the <b>input</b> PSL <b>assertions</b> are parsed into time intervals that have logical and temporal properties. These intervals are to be displayed graphically when PSL property checking is performed. Finally, the user is allowed to step through simulation one cycle at a time, while the tool applies the simulation execution trace to the instantiated time intervals, performing PSL property checking at each clock cycle. From this, the user can witness the exact clock cycles when PSL assertions are satisfied or violated, along with the causes of such results...|$|R
40|$|This paper {{describes}} Sledgehammer's {{design and}} operation {{as applied to}} the problem of scheduling Random Hall's desk. We briefly review the internal representation for <b>input</b> constraints and <b>assertions,</b> what constraints the system makes use of, the search techniques used, implementation goals, and the methods used to measure success. Later, we examine how well Sledgehammer performs on sample data runs and some justifications for the particular design choices underlying Sledgehammer. 2 Knowledge Engineering 2. 1 Data Representation Sledgehammer relies on four input files, as described below. Note that the Rank Data input file is equivalent to {{the first part of the}} supplied sample data file while the Worker Schedule file is equivalent to the second half of the sample data file. In addition to the data conveniently supplied in the sample data file, Sledgehammer tracks whether each worker is conditional or not, whether they are unreliable (and if so, for what days are they unreliable), and if they work Nightwatch, for which days are they willing to work desk before or after their Nightwatch shift. Sledgehammer retains all of the original information supplied in the input files; there is no loss of information. Rank Data The number of summers and terms each worker has worked des...|$|R

