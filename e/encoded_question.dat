1|43|Public
40|$|Previous machine {{comprehension}} (MC) datasets {{are either}} {{too small to}} train end-to-end deep learning models, or not difficult enough to evaluate the ability of current MC techniques. The newly released SQuAD dataset alleviates these limitations, and gives {{us a chance to}} develop more realistic MC models. Based on this dataset, we propose a Multi-Perspective Context Matching (MPCM) model, which is an end-to-end system that directly predicts the answer beginning and ending points in a passage. Our model first adjusts each word-embedding vector in the passage by multiplying a relevancy weight computed against the question. Then, we encode the question and weighted passage by using bi-directional LSTMs. For each point in the passage, our model matches the context of this point against the <b>encoded</b> <b>question</b> from multiple perspectives and produces a matching vector. Given those matched vectors, we employ another bi-directional LSTM to aggregate all the information and predict the beginning and ending points. Experimental result on the test set of SQuAD shows that our model achieves a competitive result on the leaderboard. Comment:...|$|E
50|$|In {{addition}} to the archive of texts, Menota also offers a handbook in XML text encoding, The Menota handbook. This {{is based on the}} Guidelines of the Text Encoding Initiative, and discusses a number of <b>encoding</b> <b>questions</b> relating to vernacular manuscripts. The handbook is published digitally on the Menota site, and it offers a full TEI-style Document Type Definition and a Relax NG schema for anyone who wants to encode Medieval Nordic manuscripts.|$|R
40|$|The {{last several}} years have seen {{intensive}} interest in exploring neural-network-based models for machine comprehension (MC) and question answering (QA). In this paper, we approach the problems by closely modelling questions in a neural network framework. We first introduce syntactic information to help <b>encode</b> <b>questions.</b> We then view and model different types of questions and the information shared among them as an adaptation task and proposed adaptation models for them. On the Stanford Question Answering Dataset (SQuAD), we show that these approaches can help attain better results over a competitive baseline...|$|R
40|$|In this paper, we {{developed}} a deep neural network (DNN) that learns to solve simultaneously the three tasks of the cQA challenge proposed by the SemEval- 2016 Task 3, i. e., question-comment similarity, question-question similarity and new question-comment similarity. The latter is the main task, which can exploit the previous two for achieving better results. Our DNN is trained jointly on all the three cQA tasks and learns to <b>encode</b> <b>questions</b> and comments into a single vector representation shared across the multiple tasks. The results on the official challenge test set show that our approach produces higher accuracy and faster convergence rates than the individual neural networks. Additionally, our method, which does not use any manual feature engineering, approaches {{the state of the}} art established with methods that make heavy use of it...|$|R
40|$|Proper {{definitions}} {{are given}} and an architecture is {{proposed for the}} model of cloud computing. Approaches that can ensure the safety on each level of the architecture are considered. Special attention is given to risks related to the confidence of providers, authentic user identification, and data <b>encoding,</b> juridical <b>questions</b> that that are encountered {{in the use of}} this technology, prospects of its implementation, and further development of cloud computing...|$|R
25|$|Unicode in {{principle}} resolves {{the issue of}} incompatible <b>encoding,</b> but other <b>questions</b> such as the handling of diacritics in extended Latin scripts are still being raised. These in turn relate to fundamental decisions regarding orthographies of African languages.|$|R
40|$|International audienceAlternation of {{forward and}} {{backward}} analyses is a standard technique in abstract interpretation of programs, which is in particular useful when we wish to prove unreachability of some undesired program states. The current state-of-the-art technique for combining forward (bottom-up, in logic programming terms) and backward (top-down) abstract interpretation of Horn clauses is query-answer transformation. It transforms a system of Horn clauses, such that standard forward analysis can propagate constraints both forward, and backward from a goal. Query-answer transformation is effective, but has issues that we wish to address. For that, we introduce a new backward collecting semantics, which is suitable for alternating {{forward and backward}} abstract interpretation of Horn clauses. We show how the alternation {{can be used to}} prove unreachability of the goal and how every subsequent run of an analysis yields a refined model of the system. Experimentally, we observe that combining forward and backward analyses is important for analysing systems that <b>encode</b> <b>questions</b> about reachability in C programs. In particular, the combination that follows our new semantics improves the precision of our own abstract interpreter, including when compared to a forward analysis of a query-answer-transformed system...|$|R
40|$|Alternation of {{forward and}} {{backward}} analyses is a standard technique in abstract interpretation of programs, which is in particular useful when we wish to prove unreachability of some undesired program states. The current state-of-the-art technique for combining forward (bottom-up, in logic programming terms) and backward (top-down) abstract interpretation of Horn clauses is query-answer transformation. It transforms a system of Horn clauses, such that standard forward analysis can propagate constraints both forward, and backward from a goal. Query-answer transformation is effective, but has issues that we wish to address. For that, we introduce a new backward collecting semantics, which is suitable for alternating {{forward and backward}} abstract interpretation of Horn clauses. We show how the alternation {{can be used to}} prove unreachability of the goal and how every subsequent run of an analysis yields a refined model of the system. Experimentally, we observe that combining forward and backward analyses is important for analysing systems that <b>encode</b> <b>questions</b> about reachability in C programs. In particular, the combination that follows our new semantics improves the precision of our own abstract interpreter, including when compared to a forward analysis of a query-answer-transformed system. Comment: Francesco Ranzato. 24 th International Static Analysis Symposium (SAS), Aug 2017, New York City, United States. Springer, Static Analysi...|$|R
40|$|The promise held by ideas like item {{banking and}} {{question}} repositories {{do not seem}} to have borne spectacular fruit in UK Higher Education. Projects have come and gone but a real culture of sharing of question content {{does not seem to have}} been established. This is in spite of the very real benefits such an approach ought to bring. This paper argues that the major hindrances to this are the complexity of existing xml standards, the difficulty of browsing of questions and the inability to embrace web 2. 0 ideas. It offers some results from the JISC funded MCQFM project as pointing in the direction this activity needs to go in order to facilitate greater collaboration among the community. It also believes that the actions of question and test sharing are so different from that of test deployment that potentially we need two standards not one: one for the exchange of questions, and one for their deployment. The Practice and Potential of Computer Aided Assessment Probably the three most diffuse and well known standards for <b>encoding</b> <b>question</b> content are Questionmark’s QML then IMS’s QTI 1. 2 and 2. 1 Each of them establish a defined group of questions that can be asked. They are: QTI 2. 1 QTI 1. 2 QM...|$|R
40|$|Abstract. One {{interpretation}} of levels of processing effects (LOP) on priming in implicit tests of memory is {{in terms of}} deficits in lexical processing during shallow study tasks. In two experiments the extent of lexical processing engaged in during standard shallow encoding tasks was manipulated by placing the <b>encoding</b> <b>question</b> either before or after the target stimulus. Clear evidence was found in explicit memory tasks that placing the question after the target stimulus increased the depth of processing of words presented in shallow encoding tasks. In contrast, {{there was no evidence of}} such an effect on the priming observed in implicit memory tasks. The results suggest that the role of lexical processing in LOP effects on priming requires further specification. Key words: implicit and explicit memory, levels of processing, lexical processing hypothesis Dissociations have played an important role in the vast body of recent research on implicit and explicit memory tasks (see Foster & Jelicic, 1999, for re-views) because they are argued to provide one of the primary sources of evidence for the independence of the mechanisms underlying these two forms of memory (e. g. Squire, 1994; but see Buchner & Wip-pich, 2000, and Dunn & Kirsner, 1988). One of the variables most frequently investigated in the search for dissociations between implicit and explicit memory is the level of processing required during stimulus encoding (Roediger & McDermott, 1993). The basic levels of processing (LOP) effect is that “deep ” semantic study processing leads to bette...|$|R
40|$|KIR 3 DS 1 receptors in the population. The two GWAS studies (2, 7, 8) demon-strate extreme {{dominance}} of the HLA class I region in the genetic association with control of HIV- 1 infection. This accounts for nearly 20 % of the observed variability in HIV- 1 con-trol. Given that both protective and highly sus-ceptible alleles are quite rare, the importance of T cell and/or natural killer cell control is extraordinary and rewards massive efforts to determine the structure and function of these genes and the molecules they <b>encode.</b> The <b>question</b> now is whether those not blessed with these protective genes can be immuno-logically pushed to make similar responses...|$|R
40|$|MAG (Mathematics Assessment Grid) System to {{integrate}} the mathematical question resources on Internet into a very large, open and virtual questions library. As part of the project, Mathematics Assessment Markup Language (MAML), {{which is used to}} <b>encode</b> <b>questions,</b> test papers and their description information, has been designed. The MAML, defined by XML, provides well-defined elements that can be used together with SVG and MathML for representing questions and test papers. It is easy to search and transfer questions in MAML on Internet. MAML can also be used in E-Learning and E-Testing system. Presentation information and description information of a <b>question</b> are <b>encoded</b> as well as the content of a question. The users can embed a well-formed question in MAML into XHTML page. The client side is only a browser with plugins for MAML, MathML and SVG. To implement MAML, we are developing an online editor (MaEdit) which is based on MAML, MathML and SVG. The users can edit a question in GUI mode or coding mode. The editor can transform a question between these two modes automatically. In this editor, the users can edit the text, mathematical formula and SVG graph of a question. Graph in other types such as bitmap, gif, jpeg can also be inserted into the question. After editing, the users can save the question which is represented by MAML, MathML and SVG into a database or as a file. 1. Background The Internet advent gave a powerful communication structure to easily access to any kind o...|$|R
40|$|A friend {{thinks of}} an integer between 0 and 15. You {{are allowed to}} ask seven yes/no-questions in order to {{determine}} which number your friend has in mind. However, he is allowed to tell at most one lie. Can you do this task? The theory of error correcting codes says that you can do it. In fact, this problem is solved by the Hamming code of length 7, with 4 information bits [2]. However, the practical question remains, can you find the number while standing on your feet together with your friend. This note presents seven question cards and one base card allowing you to do this feat. Each card <b>encodes</b> one <b>question.</b> Depending on the answer, the card is either placed right-side up or turned upside-down. Below is one of the cards and how it looks when turned over the northwest-southeast axis...|$|R
40|$|State {{assignment}} {{is a formidable}} task. As designs written in a hardware description language such as Esterel inherently carry more high level information that a register transfer level model, such information {{can be used to}} guide the <b>encoding</b> process. A <b>question</b> arises if the high level information alone is strong enough to suggest an efficient state assignment, allowing low-level details to be ignored. This report suggests that with Esterel’s flexibility, most optimization potential is not within the highlevel structure. It appears effective state assignmen...|$|R
40|$|Attention {{models have}} been intensively studied to improve NLP tasks such as machine {{comprehension}} via both question-aware passage attention model and self-matching attention model. Our research proposes phase conductor (PhaseCond) for attention models in two meaningful ways. First, PhaseCond, an architecture of multi-layered attention models, consists of multiple phases each implementing a stack of attention layers producing passage representations {{and a stack of}} inner or outer fusion layers regulating the information flow. Second, we extend and improve the dot-product attention function for PhaseCond by simultaneously <b>encoding</b> multiple <b>question</b> and passage embedding layers from different perspectives. We demonstrate the effectiveness of our proposed model PhaseCond on the SQuAD dataset, showing that our model significantly outperforms both state-of-the-art single-layered and multiple-layered attention models. We deepen our results with new findings via both detailed qualitative analysis and visualized examples showing the dynamic changes through multi-layered attention models...|$|R
40|$|I propose an {{implementation}} of the quantum private query protocol as described in an article using a photon to <b>encode</b> a <b>question</b> and reflectionor transmission of the photon as answer options. Each question is represented by a photon in a transmission line with both ends returning to the user, {{and the answer is}} represented by reflection or transmission of this photon caused by the single photon transistor as described in another article. By solving the quantum Langevin equations for the 32 × 32 -dimensional operators describing the single photon transistor the system is analysed. This analysis shows that the user privacy is maintained when the returning transmission lines are under the user's control. The probabilities for reflection and transmission are calculated to verify the behaviour of the answering mechanism. By using pulse trains instead of numbered lines to represent questions, the scalability of the system could be improved. Applied Physics and Applied MathematicsKavli Institute of Nanoscience DelftApplied Science...|$|R
40|$|This paper {{deals with}} editing tools and editing platforms, i. e. {{programs}} used by editors {{in order to}} fulfil one or more tasks {{in the creation of}} a scholarly digital edition (SDE). Recurring themes in the field of SDEs are the standardization of XML-TEI markup and the success of documentary digital editions (DDEs) – as compared with critical and genetic editions. The existing editing tools reflect these practices: a considerable number of transcribing and encoding tools, mostly TEI compliant, are developed and used in order to produce DDEs. A small selection of applications are analysed in detail here: T-Pen, CWRC-Writer, TextGrid, eLaborate and Ecdosis; the tools are compared in an initial summary table. A second table and recap reflect the common features of transcribing and <b>encoding</b> applications. <b>Questions</b> concerning the entire workflow necessary for the creation of a scholarly digital edition are addressed in brief. In applying Manovich's concept of 'software culture' to the field of digital editions, editing tools emerge as crucial, insofar as they may shape investigation and, eventually, scholarly products...|$|R
40|$|Tone {{languages}} are often reported {{to make use}} of utterancelevel intonation as well as of lexical tone. We test the alternative hypotheses that a) the coexistence of lexical tone and utterance-level intonation in tone languages results in a diminished functional load for intonation, and b) that lexical tone and intonation can coexist in tone languages without undermining each other’s functional load in a substantial way. In order to do this, we collected data from two large typological databases, and performed mixed-effects and phylogenetic regression analyses controlling for genealogical and areal factors to estimate the probability of a language exhibiting grammatical devices for <b>encoding</b> polar <b>questions</b> given its status as a tonal or an intonation-only language. Our analyses indicate that, while both tone and intonational languages tend to develop grammatical devices for marking polar questions above chance level, tone languages do this at a significantly higher frequency, with estimated probabilities ranging between 0. 88 and. 98. This statistical bias provides cross-linguistic empirical support to the view that the use of tonal features to mark lexical contrasts leads to a diminished functional load for utterance-level intonation...|$|R
40|$|Abstract. In this paper, {{we present}} TLQ, {{a tool that}} finds the state {{solutions}} to any CTL query. It extends existing approaches specialized in finding state solutions to special kinds of queries, being {{at the same time}} more efficient than general query checkers that can find all solution to any query. Its generality allows its application to new problems, such as finding stable states, as required in some applications from genetics. We describe the implementation of TLQ on top of the model-checker NuSMV, and show its effectiveness in finding the stable states of a gene network. We describe our tool TLQ that applies to the analysis of state-transition models, and can answer questions of the type: “What are the states that satisfy a property ϕ?”. We address those cases where ϕ cannot be formulated in a temporal logic appropriate for model checking. Instead, ϕ can be formulated as a temporal query suitable for query checking. An example of such a property ϕ is “reachability”. We cannot formulate a CTL property whose model-checking results in those states reachable from a given state, but we can formulate the CTL query EF? that literally <b>encodes</b> the <b>question...</b>|$|R
40|$|One {{important}} aspect of human spatial memory {{is the ability to}} remember the location of objects. Such locations are represented in multiple frames of reference, including eyecentered, body-centered, and object-based (world-centered) frames. The viewer-centered representations appear to require attention to encode; however, encoding object-toobject relations presents a computational problem. It seems unlikely that all object-to-object relations in the field of attention could be <b>encoded,</b> raising the <b>question</b> of which relations, if any, are available automatically, through early computation, and which may need to be generated later. To address this issue, we adopted an experimental paradigm developed by Milner and colleagues in the 1990 s, (e. g., Owen, Milner, Petrides, & Evans, 1996). There are two phases in the Milner paradigm. In the encoding phase...|$|R
40|$|We propose {{adaptive}} testing as {{a general}} mechanism for extracting information about stimuli from spike trains. Each test or question corresponds to choosing a neuron and a time interval and checking for a given number of spikes. No assumptions are made about the distribution of spikes or any other aspect of neural <b>encoding.</b> The chosen <b>questions</b> are those which most reduce the uncertainty about the stimulus, as measured by entropy and estimated from stimulus-response data. Our experiments are based on accurate simulations of responses to pure tones in the auditory nerve and are meant to illustrate the ideas rather than investigate the auditory system. The results cohere nicely with well-understood encoding of amplitude and frequency in the auditory nerve, suggesting that adaptive testing might provide {{a powerful tool for}} investigating complex and poorly understood neural structures. ...|$|R
40|$|In many cell types, Ca 2 + {{signals are}} {{organized}} {{in the form of}} repetitive spikes. The frequency of these intracellular Ca 2 + oscillations increases with the level of stimulation, suggesting the existence of a frequency <b>encoding</b> phenomenon. The <b>question</b> arises as to how the frequency of Ca 2 + oscillations can be decoded inside the cell. Ca 2 +/calmodulin kinase II has long been proposed as an attractive candidate, as it is a key target of Ca 2 + signals. By immobilizing the Ca 2 +/calmodulin kinase II and subjecting it to pulses of Ca 2 + of variable amplitude, duration, and frequency, De Koninck and Schulman have shown {{for the first time that}} the autonomous activity of Ca 2 +/calmodulin kinase II is highly sensitive to the temporal pattern of Ca 2 + oscillations. FLWINinfo:eu-repo/semantics/publishe...|$|R
40|$|An {{important}} issue in analog circuit design {{is the problem}} of digital to analog conversion, namely, the encoding of Boolean variables into a single analog value which contains enough information to reconstruct the values of the Boolean variables. A natural question is: What is the complexity of implementing the digital to analog <b>encoding</b> function? That <b>question</b> was recently answered in [5], where matching lower and upper bounds {{on the size of the}} circuit for the encoding function were proven. In particular, it was proven that Σ 3 nΓ 1 2 Υ 2 -input arithmetic gates are necessary and sufficient for implementing the encoding function of n Boolean variables. However, the proof of the upper bound is not constructive. In this paper, we present an explicit construction of a digital to analog encoder that is optimal in the number of 2 -input arithmetic gates. In addition, we present an efficient analog to digital decoding algorithm. Namely, given the encoded analog value, our d [...] ...|$|R
40|$|The {{principal}} {{aim of this}} thesis is to assess {{the view that the}} formal properties of sentences of natural languages <b>encode</b> truth-conditions. The <b>question</b> I pursue is whether truth-conditional semantic theories are capable of accounting for the various ways in which contextual factors contribute to the determination of the truth-conditional content of sentences. The thesis will assess and evaluate three different approaches standard contemporary truth-conditional semanticists have set forth in response to what I shall refer to as the challenge from pervasive context sensitivity, which is essentially the claim that context plays a more extensive role in the determination of content than that of fixing the semantic values of standard indexical expressions. I shall aim to show that each of the approaches mentioned fails to provide an adequate account of how the phenomenon of context sensitivity can be explained on the basis of our linguistic competence alone, and shall then explore some of the consequences of this...|$|R
40|$|The {{covalent}} {{modification of}} protein substrates by ubiquitin regulates a {{diverse range of}} critical biological functions. Although it has been established that ubiquitin-like modifiers evolved from prokaryotic sulphur transfer proteins it is less clear how complex eukaryotic ubiquitylation system arose and diversified from these prokaryotic antecedents. The discovery of ubiquitin, E 1 -like, E 2 -like and small-RING finger (srfp) protein components in the Aigarchaeota and the Asgard archaea superphyla has provided a substantive step toward addressing this evolutionary <b>question.</b> <b>Encoded</b> in operons, these components are likely representative of the progenitor apparatus that founded the modern eukaryotic ubiquitin modification systems. Here we report that these proteins from the archaeon Candidatus ‘Caldiarchaeum subterraneum’ operate together as a bona fide ubiquitin modification system, mediating a sequential ubiquitylation cascade reminiscent of the eukaryotic process. Our observations {{support the hypothesis that}} complex eukaryotic ubiquitylation signalling pathways have developed from compact systems originally inherited from an archaeal ancestor...|$|R
40|$|Attention {{has a role}} in much of perception, thought, and action. On the erotetic theory, the {{functional}} role of attention {{is a matter of}} the relationship between questions and what counts as answers to those <b>questions.</b> <b>Questions</b> <b>encode</b> the completion conditions of tasks for cognitive control purposes, and degrees of attention are degrees of sensitivity to the occurrence of answers. Questions and answers are representational contents given precise characterizations using tools from formal semantics, though attention does not depend on language. The erotetic theory proposes an integrated account of attention in cognitive control and of attentional focus in perception. The functional role of attentional focus on objects, properties, and locations has to do with picking out something that corresponds to what a task is 'about'. The erotetic theory of attention opens new avenues in theorizing about the relationship between attention, representational content, phenomenal character, and practical reason. A novel representationalist account of salience is proposed. The theory also provides an account of distraction that suggests when distraction is a defect in practical reasoning. © 2014 John Wiley and Sons Ltd...|$|R
40|$|ABSTRACT. This study {{described}} the feelings {{and experiences of}} a mother that has a child carrier of Down syndrome. This was a descriptive study with a qualitative approach {{of the type of}} case study. The subject of the study was a mother who has a daughter with Down syndrome. Data collection occurred by a semi-structured interview and non-systematic observation, from July to December 2008, during five meetings, scheduled in advance. For analysis, all the material was categorized by extensive readings and highlighting significant terms for the information <b>encoding.</b> Then, the <b>questions</b> used in the data collection were classified in sequence topics: Mother’s perception facing the diagnosis of Down Syndrome; The meaning of the concept risk baby; Explaining the Down Syndrome through religion; Mother’s perception regarding the care of the risk baby. The mother has not only difficulties to accept the child’s situation, but also in relation to to the care, justifying the need of health professionals to seek to assist these families to understand this diagnosis, minimizing their anguish, guilties and anxiety...|$|R
40|$|NOTE: Text or symbols not renderable {{in plain}} ASCII are {{indicated}} by [ [...] . ]. Abstract included in. pdf document. An important issue in analog circuit design {{is the problem}} of digital to analog conversion, namely, the encoding of Boolean variables into a single analog value which contains enough information to reconstruct the values of the Boolean variables. A natural question is: What is the complexity of implementing the digital to analog <b>encoding</b> function? That <b>question</b> was recently answered in (5), where matching lower and upper bounds {{on the size of the}} circuit for the encoding function were proven. In particular, it was proven that [ [...] . ] 2 -input arithmetic gates are necessary and sufficient for implementing the encoding function of n Boolean variables. However, the proof of the upper bound is not constructive. In this paper, we present an explicit construction of a digital to analog encoder that is optimal in the number of 2 -input arithmetic gates. In addition, we present an efficient analog to digital decoding algorithm. Namely, given the encoded analog value, our decoding algorithm reconstructs the original Boolean values. Our construction is suboptimal in that it uses constants [ [...] . ] bits...|$|R
40|$|Abstract—An {{important}} issue in analog circuit design {{is the problem}} of digital-to-analog conversion, i. e., the encoding of Boolean variables into a single analog value which contains enough information to reconstruct the values of the Boolean variables. A natural question is: What is the complexity of im-plementing the digital-to-analog <b>encoding</b> function? That <b>question</b> was recently answered by Wegener, who proved matching lower and upper bounds {{on the size of the}} circuit for the encoding function. In particular, it was proven that d(3 n 1) = 2 e 2 -input arithmetic gates are necessary and sufficient for implementing the encoding function of n Boolean variables. However, the proof of the upper bound is not constructive. In this paper, we present an explicit construction of a digital-to-analog encoder that is optimal in the number of 2 -input arithmetic gates. In addition, we present an efficient analog-to-digital decoding algorithm. Namely, given the encoded analog value, our decoding algorithm reconstructs the original Boolean values. Our construction is suboptimal in that it uses constants of maximum size n logn bits; the nonconstructive proof uses constants of maximum size 2 n + dlog ne bits. Index Terms—Complexity, construction, decoding, digital-to-analog, encoding...|$|R
40|$|Comunicació presentada a: Speech Prosody 2014, celebrada del 20 al 23 de maig de 2014 a Dublin, Irlanda. The {{overarching}} goal of {{this paper}} is to advance on the understanding of how evidential meanings are expressed in natural languages. Specifically, we aimed to investigate what type of meaning was <b>encoded</b> in yes-no <b>questions</b> through the combination of the question particle (QP) que ‘that’ and the nuclear intonational pattern L+H* L% in Majorcan Catalan yes-no questions (i. e., Que és un llibre?L+H* L% ‘QP-It’s a book?’), and to understand any temporal information that might be encoded through this construction. Several complementary research methods were used to address our question: the Discourse Completion Task, an acceptability task and a multiple-choice questionnaire. The results show that three types of information are encoded in QP que_L+H* L% questions: sentence modality, inference based on direct evidence and immediacy of the evidence. This research was funded by projects FFI 2011 - 23829 /FILO, BFU 2012 - 31995 (awarded by the Spanish Ministry of Science and Innovation and the Spanish Ministry of Economy and Competitiveness) and 2009 SGR 701 (awarded by the Generalitat de Catalunya) ...|$|R
40|$|The {{existence}} of a polynomial kernel for Odd Cycle Transversal was a notorious open problem in parameterized complexity. Recently, this was settled by the present authors (Kratsch and Wahlström, SODA 2012), with a randomized polynomial kernel for the problem, using matroid theory to <b>encode</b> flow <b>questions</b> over a set of terminals in size polynomial {{in the number of}} terminals. In the current work we further establish the usefulness of matroid theory to kernelization by showing applications of a result on representative sets due to Lovász (Combinatorial Surveys 1977) and Marx (TCS 2009). We show how representative sets can be used to give a polynomial kernel for the elusive Almost 2 -SAT problem. We further apply the representative sets tool to the problem of finding irrelevant vertices in graph cut problems, i. e., vertices which can be made undeletable without affecting the status of the problem. This gives the first significant progress towards a polynomial kernel for the Multiway Cut problem; in particular, we get a kernel of O(k^s+ 1) vertices for Multiway Cut instances with at most s terminals. Both these kernelization results have significant spin-off effects, producing the first polynomial kernels for a range of related problems. More generally, the irrelevant vertex results have implications for covering min-cuts in graphs. For a directed graph G=(V,E) and sets S, T ⊆ V, let r be the size of a minimum (S,T) -vertex cut (which may intersect S and T). We can find a set Z ⊆ V of size O(|S|*|T|*r) which contains a minimum (A,B) -vertex cut for every A ⊆ S, B ⊆ T. Similarly, for an undirected graph G=(V,E), a set of terminals X ⊆ V, and a constant s, we can find a set Z⊆ V of size O(|X|^s+ 1) which contains a minimum multiway cut for any partition of X into at most s pairwise disjoint subsets. Comment: 30 pages. To appear in FOCS 201...|$|R
40|$|BACKGROUND The ICD- 10 {{categories}} of the diagnosis "perinatal asphyxia" are defined by clinical signs and a 1 -minute Apgar score value. However, the modern conception is more complex and considers metabolic values related to the clinical state. A lack of consistency between the former clinical and the latter <b>encoded</b> diagnosis poses <b>questions</b> over {{the validity of the}} data. Our aim was to establish a refined classification which is able to distinctly separate cases according to clinical criteria and financial resource consumption. The hypothesis of the study is that outdated ICD- 10 definitions result in differences between the encoded diagnosis asphyxia and the medical diagnosis referring to the clinical context. METHODS Routinely collected health data (encoding and financial data) of the University Hospital of Bern were used. The study population was chosen by selected ICD codes, the encoded and the clinical diagnosis were analyzed and each case was reevaluated. The new method categorizes the diagnoses of perinatal asphyxia into the following groups: mild, moderate and severe asphyxia, metabolic acidosis and normal clinical findings. The differences of total costs per case were determined by using one-way analysis of variance. RESULTS The study population included 622 cases (P 20 "intrauterine hypoxia" 399, P 21 "birth asphyxia" 233). By applying the new method, the diagnosis asphyxia could be ruled out with a high probability in 47...|$|R
40|$|Theta band power (4 - 8 Hz) in {{the scalp}} {{electroencephalogram}} (EEG) {{is thought to}} be stronger during memory encoding for subsequently remembered items than for forgotten items. According to simultaneous EEG-functional magnetic resonance imaging (fMRI) measurements, the memory-dependent EEG theta is associated with multiple regions of the brain. This suggests that the multiple regions cooperate with EEG theta synchronization during successful memory <b>encoding.</b> However, a <b>question</b> still remains: What kind of neural dynamic organizes such a memory-dependent global network? In this study, the modulation of the EEG theta entrainment property during successful encoding was hypothesized to lead to EEG theta synchronization among a distributed network. Then, a transient response of EEG theta to a theta-band photic flicker with a short duration was evaluated during memory encoding. In the results, flicker-induced EEG power increased and decreased with a time constant of several hundred milliseconds following the onset and the offset of the flicker, respectively. Importantly, the offset response of EEG power was found to be significantly decreased during successful encoding. Moreover, the offset response of the phase locking index was also found to associate with memory performance. According to computational simulations, the results are interpreted as a smaller time constant (i. e., faster response) of a driven harmonic oscillator rather than a change in the spontaneous oscillatory input. This suggests that the fast response of EEG theta forms a global EEG theta network among memory-related regions during successful encoding, and it contributes to a flexible formation of the network along the time course...|$|R
40|$|The myeloid {{translocation}} gene 16 product MTG 16 {{is found}} in multiple transcription factor-containing complexes as a regulator of gene expression implicated in development and tumorigenesis. A stable Tet-On system for doxycycline-dependent expression of MTG 16 was established in B-lymphoblastoid Raji cells to unravel its molecular functions in transformed cells. A noticeable finding was that expression of certain genes involved in tumor cell metabolism including 6 -phosphofructo- 2 -kinase/fructose- 2, 6 -biphosphatase 3 and 4 (PFKFB 3 and PFKFB 4), and pyruvate dehydrogenase kinase isoenzyme 1 (PDK 1) was rapidly diminished when MTG 16 was expressed. Furthermore, hypoxia-stimulated production of PFKFB 3, PFKFB 4 and PDK 1 was inhibited by MTG 16 expression. The genes in <b>question</b> <b>encode</b> key regulators of glycolysis and its coupling to mitochondrial metabolism and are commonly found to be overexpressed in transformed cells. The MTG 16 Nervy Homology Region 2 (NHR 2) oligomerization domain and the NHR 3 protein-protein interaction domain were required intact for inhibition of PFKFB 3, PFKFB 4 and PDK 1 expression to occur. Expression of MTG 16 reduced glycolytic metabolism while mitochondrial respiration and formation of reactive oxygen species increased. The metabolic changes were paralleled by increased phosphorylation of mitogen-activated protein kinases, reduced levels of amino acids and inhibition of proliferation with a decreased fraction of cells in S-phase. Overall, our findings show that MTG 16 {{can serve as a}} brake on glycolysis, a stimulator of mitochondrial respiration and an inhibitor of cell proliferation. Hence, elevation of MTG 16 might have anti-tumor effect...|$|R
40|$|Stimulus {{repetition}} {{produces a}} decrease of the response in many cortical areas and different modalities. This adaptation is highly prominent in macaque inferior temporal (IT) neurons. Here we ask how these repetition-induced changes in IT responses affect the accuracy by which IT neurons <b>encode</b> objects. This <b>question</b> bears on the functional consequences of adaptation, which are still unclear. We recorded the responses of single IT neurons to sequences of familiar shapes, each shown for 300 ms with an inter-stimulus interval of the same duration. The difference in shape between the two successively presented stimuli, i. e. adapter and test, varied parametrically. The discriminability of the test stimuli was reduced for repeated compared to non-repeated stimuli. In some conditions for which adapter and test shapes differed, the cross-adaptation resulted in an enhanced discriminability. These single cell results were confirmed in a second experiment in which we recorded multi-unit spiking activity using a laminar microelectrode in macaque IT. Two familiar stimuli were presented successively for 500 ms each and separated with an inter-stimulus interval of the same duration. Trials consisted either of a repetition of the same stimulus or of their alternation. Small neuronal populations showed decreased classification accuracy for repeated compared to non-repeated test stimuli, but classification was enhanced for the test compared to adapter stimuli when the test stimulus differed from recently seen stimuli. These findings suggest that short-term, stimulus-specific adaptation in IT supports efficient coding of stimuli that differ from recently seen ones while impairing the coding of repeated stimuli...|$|R
40|$|ABSTRACT: During {{test and}} {{integration}} (step 5 in FEDEP), federate developers {{get together to}} ensure the technical interoperability of the participating systems. This includes testing if their systems exchange data according to the federation agreements. In HLA 1516, the technical format (encoding) of the data that is exchanged over the RTI is fully specified in the Federation Object Model. Each federate {{is responsible for the}} encoding and decoding of data based on this format. Still, this {{does not necessarily mean that}} all developers have successfully interpreted and implemented encoding/decoding. A surprisingly large portion of today’s federation efforts experience problems with this. Incorrect encoding/decoding can make federates or federations crash, hang or even worse; misinterpreting the received data. All of this introduce risk, delay and cost to integration. What is even worse, it may cause the final federation to run with incorrect outputs or provide inadequate training. While it is possible to use tools such as data loggers to check the correctness of the <b>encoding,</b> the fundamental <b>question</b> remains: Why does it have to be so hard to get the data that is exchanged over the RTI correctly encoded and decoded? This problem has already been solved in other interoperability solutions for distributed systems, such as CORBA, DCOM and Web Services. A solution for HLA, the Encoding Helpers, has been suggested for HLA Evolved based on an idea originating from the DMSO RTI Java API. A Tiger Team has been formed to provide the details. The encoding helpers are available both to C++ and Java developers and can also be used together with the Web Service HLA API...|$|R
