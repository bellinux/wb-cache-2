1305|291|Public
25|$|The <b>decoding</b> <b>process</b> reverses these steps, {{except the}} {{quantization}} {{because it is}} irreversible. In {{the remainder of this}} section, the encoding and decoding processes are described in more detail.|$|E
25|$|The DCT {{temporarily}} {{increases the}} bit-depth of the data, since the DCT coefficients of an 8-bit/component image {{take up to}} 11 or more bits (depending on fidelity of the DCT calculation) to store. This may force the codec to temporarily use 16-bit numbers to hold these coefficients, doubling {{the size of the}} image representation at this point; these values are typically reduced back to 8-bit values by the quantization step. The temporary increase in size at this stage is not a performance concern for most JPEG implementations, since typically only a very small part of the image is stored in full DCT form at any given time during the image encoding or <b>decoding</b> <b>process.</b>|$|E
25|$|Windows Media Audio (WMA) is {{the most}} common codec of the four WMA codecs. Colloquial usage of the term WMA, {{especially}} in marketing materials and device specifications, usually refers to this codec only. The first version of the codec released in 1999 is regarded as WMA 1. In the same year, the bit stream syntax, or compression algorithm, was altered in minor ways and became WMA 2. Since then, newer versions of the codec have been released, but the <b>decoding</b> <b>process</b> remained the same, ensuring compatibility between codec versions. WMA is a lossy audio codec based on the study of psychoacoustics. Audio signals that are deemed to be imperceptible to the human ear are encoded with reduced resolution during the compression process.|$|E
5000|$|... #Caption: Baseline {{sequential}} JPEG encoding and <b>decoding</b> <b>processes</b> ...|$|R
5000|$|... #Subtitle level 4: Video <b>decoding</b> <b>processes</b> {{that can}} be {{accelerated}} ...|$|R
5000|$|The video <b>decoding</b> <b>processes</b> {{that can}} be {{accelerated}} by today's modern GPU hardware are: ...|$|R
2500|$|Colossus {{was able}} to process 5,000 {{characters}} per second with the paper tape moving at [...] Sometimes, two or more Colossus computers tried different possibilities simultaneously in what now is called parallel computing, speeding the <b>decoding</b> <b>process</b> by {{perhaps as much as}} double the rate of comparison.|$|E
2500|$|The {{encoding}} {{description in}} the JPEG standard does not fix the precision {{needed for the}} output compressed image. However, the JPEG standard (and the similar MPEG standards) includes some precision requirements for the decoding, including {{all parts of the}} <b>decoding</b> <b>process</b> (variable length decoding, inverse DCT, dequantization, renormalization of outputs); the output from the reference algorithm must not exceed: ...|$|E
2500|$|At {{the end of}} this stage, {{before the}} reader becomes an expert reader, many {{processes}} are starting to become automatic. This increasing automaticity frees up cognitive resources so that the reader can reflect on meaning. [...] With the <b>decoding</b> <b>process</b> almost automatic by this point, the brain learns to integrate more metaphorical, inferential, analogical, background and experiential knowledge with every newly won millisecond. [...] This stage in learning to read often will last until early adulthood.|$|E
40|$|Developments of {{technology}} are increasing very fast. One {{of them is}} about digital image. Digital image is easy {{to find in the}} internet. There is a way to protect the images from copyright theft, watermark is a technique for protecting the copyright of the image in a digital world. There are few things needed to learn in watermarking an image. Converting value from binary to decimal and decimal to binary is needed to convert value and change the least significant bit in one pixel. The pattern that will be used in encode and <b>decode</b> <b>processes</b> are zig-zag pattern and sequence pattern. The program will do encode and <b>decode</b> <b>process</b> using two different patterns. Booth zig-zag or sequence pattern successfully do encode and <b>decode</b> <b>process.</b> The process using zig-zag pattern needs more time than sequence pattern...|$|R
30|$|This section {{describes}} the main {{step of the}} encoding and <b>decoding</b> <b>processes.</b> The proposed idea is explained more explicitly step by step with {{the description of the}} full process.|$|R
40|$|This article {{studies the}} {{emergence}} of ambiguity in communication through the concept of logical irreversibility and {{within the framework of}} Shannon's information theory. This leads us to a precise and general expression of the intuition behind Zipf's vocabulary balance in terms of a symmetry equation between the complexities of the coding and the <b>decoding</b> <b>processes</b> that imposes an unavoidable amount of logical uncertainty in natural communication. Accordingly, {{the emergence of}} irreversible computations is required if the complexities of the coding and the <b>decoding</b> <b>processes</b> are balanced in a symmetric scenario, which means that the emergence of ambiguous codes is a necessary condition for natural communication to succeed. Comment: 28 pages, 2 figure...|$|R
2500|$|Colossus was the world's first {{electronic}} digital programmable computer. It used a {{large number}} of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1500 thermionic valves (tubes), but Mark II with 2400 valves, was both 5 times faster and simpler to operate than Mark 1, greatly speeding the <b>decoding</b> <b>process.</b> [...] Mark 2 was designed while Mark 1 was being constructed. Allen Coombs took over leadership of the Colossus Mark 2 project when Tommy Flowers moved on to other projects.|$|E
2500|$|Decoding, on {{the other}} hand, is {{carefully}} defined in the standard. Most decoders are [...] "bitstream compliant", {{which means that the}} decompressed output that they produce from a given MP3 file will be the same, within a specified degree of rounding tolerance, as the output specified mathematically in the ISO/IEC high standard document (ISO/IEC 11172-3). Therefore, comparison of decoders is usually based on how computationally efficient they are (i.e., how much memory or CPU time they use in the <b>decoding</b> <b>process).</b> Over time this concern has become less of an issue as CPU speeds transitioned from MHz to GHz. Encoder/decoder overall delay is not defined, which means there is no official provision for gapless playback. However, some encoders such as LAME can attach additional metadata that will allow players that can handle it to deliver seamless playback.|$|E
5000|$|The <b>decoding</b> <b>process</b> {{uses the}} [...] "exclusive or" [...] {{operation}} {{to retrieve the}} encoded message.|$|E
30|$|Expanding window RLNC (EW-RLNC) {{algorithm}} [17, 18] {{that uses}} RLNC strategies to encode the packets in different windows while {{taking into account}} the decoding order of video layers and the hard deadline. The encoding and <b>decoding</b> <b>processes</b> of EW-RLNC algorithm are described in Appendix.|$|R
3000|$|The {{presented}} {{results are}} obtained through the simulations {{of the actual}} encoding, network packet error and <b>decoding</b> <b>processes.</b> The PER recovery simulation results are plotted using continuous unmarked lines. For comparison purposes, we also plot the theoretical curves using continuous marked lines based on (17) but taking the summation from [...]...|$|R
40|$|Abstract—Codes and {{associated}} lattices are {{studied in the}} lp metric, particularly in the l 1 (Lee) and the l ∞ (maximum) distances. Discussions and results on <b>decoding</b> <b>processes,</b> classi-fication and analysis of perfect or dense codes in these metrics are presented. Keywords—Codes and lattices, lp metric, Lee metric, perfect codes. I...|$|R
50|$|A {{simplified}} encoding and <b>decoding</b> <b>process</b> {{is defined}} for data symbols with a near uniform probability distribution.|$|E
5000|$|In essence, the TNC <b>decoding</b> <b>process,</b> {{like the}} LNC <b>decoding</b> <b>process</b> {{involves}} Gaussian elimination. However, since the packets in TNC have been coded {{in such a}} manner that the resulting coded packets are in triangular pattern, the computational process of triangularization, with complexity of , where [...] is the number of packets, can be bypassed. The receiver now only needs to perform back-substitution, with complexity given as [...] for each bit location.|$|E
5000|$|A {{normative}} Structured Audio scheduler description - {{it is the}} supervisory run-time {{element of}} the Structured Audio <b>decoding</b> <b>process.</b>|$|E
3000|$|The {{presented}} {{results are}} obtained through the simulations {{of the actual}} encoding, network packet loss and <b>decoding</b> <b>processes.</b> The PLR recovery simulation results are plotted using continuous unmarked lines in all figures in this section. For comparison purposes, we also plot the theoretical curves using continuous marked lines based on the following formula [6]: [...]...|$|R
40|$|In this work, three {{encryption}} {{techniques are}} proposed by manipulating the bin (binary symbol) of significant values, transform skip signals and suffixes in selected CTU (coding tree unit) of video slices under the HEVC standard. These techniques are applied with minimal parsing overhead during encoding and <b>decoding</b> <b>processes.</b> Experiment {{results show that}} the selected region can be sufficiently encrypted...|$|R
40|$|This CCITT Recommendation | ISO/IEC International Standard was {{prepared}} by CCITT Study Group VIII and the Joint Photographic Experts Group (JPEG) of ISO/IEC JTC 1 /SC 29 /WG 10. This Experts Group {{was formed in}} 1986 to establish a standard for the sequential progressive encoding of continuous tone grayscale and colour images. Digital Compression and Coding of Continuous-tone Still images, is published in two parts: Requirements and guidelines; Compliance testing. This part, Part 1, sets out requirements and implementation guidelines for continuous-tone still image encoding and <b>decoding</b> <b>processes,</b> and for the coded representation of compressed image data for interchange between applications. These processes and representations are intended to be generic, that is, to be applicable to {{a broad range of}} applications for colour and grayscale still images within communications and computer systems. Part 2, sets out tests for determining whether implementations comply with the requirments for the various encoding and <b>decoding</b> <b>processes</b> specified in Part 1...|$|R
50|$|Inflate is the <b>decoding</b> <b>process</b> {{that takes}} a Deflate bit stream for {{decompression}} and correctly produces the original full-size data or file.|$|E
50|$|In Cooperative-MIMO, the <b>decoding</b> <b>process</b> {{involves}} collecting NR linear {{combinations of}} NT original data symbols, where NR {{is usually the}} number of receiving nodes, and NT {{is the number of}} transmitting nodes. The <b>decoding</b> <b>process</b> can be interpreted as solving a system of NR linear equations, where the number of unknowns equals the number of data symbols (NT) and interference signals. Thus, in order for data streams to be successfully decoded, the number of independent linear equations (NR) must at least equal the number of data (NT) and interference streams.|$|E
50|$|The <b>decoding</b> <b>process</b> reverses these steps, {{except the}} {{quantization}} {{because it is}} irreversible. In {{the remainder of this}} section, the encoding and decoding processes are described in more detail.|$|E
30|$|Being not {{designed}} for WBCs with their specific characteristics in mind, the SE and TSE <b>decoding</b> <b>processes</b> are not efficient for direct use in WBCs. As one DVB-H burst (MPE-FEC frame) usually contains several WBC segments, even a single byte error in the MPE-FEC frame may cause a decoding failure. To improve the error protection in WBCs, the CSIT used by ADP for cross-layer decoding was developed.|$|R
40|$|The {{last decade}} {{has seen the}} {{development}} of powerful channel codes such as turbo codes and low-density parity-check (LDPC) codes. The impressive bit error rate (BER) performance of the associated <b>decoding</b> <b>processes</b> implicitly assumes coherent detection, meaning that the carrier phase must be recovered accurately before the data is decoded. However, since the receiver usually operates at extremely low signal-to-noise ratio (SNR) values, conventional carrie...|$|R
40|$|In this work, we {{developed}} a high speed LSI for encoding and decoding the RSA cryptogram and describe the processing method in this paper. This cryptogram is used not only for encrypting data, but also for such purposes as authentication. However, the RSA encoding and <b>decoding</b> <b>processes</b> {{take a long time}} because they require a great deal of calculations. As a result, this cryptogram is not suited for practical use...|$|R
50|$|VDPAU allows video {{programs}} {{to access the}} specialized video decoding ASIC on the GPU to offload portions of the video <b>decoding</b> <b>process</b> and video post-processing from the CPU to the GPU.|$|E
50|$|The {{definition}} of the <b>decoding</b> <b>process</b> is designed to facilitate low-complexity implementations of arithmetic encoding and decoding. Overall, CABAC provides improved coding efficiency compared with CAVLC-based coding, {{at the expense of}} greater computational complexity.|$|E
5000|$|UUTool {{was written}} in C and hand-optimized 68K {{assembler}} for speed in the encoding and <b>decoding</b> <b>process,</b> taking advantage of fewer cycles to process a 32 bit data word (4 bytes) as opposed to character by character.|$|E
5000|$|Even though XvMC {{currently}} only supports {{hardware acceleration}} of motion compensation (mo comp) and inverse discrete cosine transform (iDCT), (and Variable-Length Decoding for VIA Unichrome GPU), additional video <b>decoding</b> <b>processes</b> could {{be passed on}} to modern GPUs which could be accelerated via GPU fragment programs. XvMC could be extended in the future to support the same processes as the newer competing hardware video acceleration APIs like VDPAU, XvBA, and VAAPI: ...|$|R
40|$|Abstract. In {{order to}} promote the {{application}} of two dimensional barcode on mobile phone, this paper uses the popular Android technology, and researches QR code format and the <b>decode</b> <b>process</b> of the QR code; and then designs 2 D bar code recognition system based on the decode library Zxing. After testing, it is proved that the system has good generality and low resource consuming, and the software of itself is only 140 K...|$|R
40|$|The {{purpose of}} this paper is to study the Bose, Chaudhuri, and Hocquenghem (BCH) code, with an aim to {{simulate}} the encoding and <b>decoding</b> <b>processes.</b> The gain of the proposed code in investigated through applying it to binary phase sift keying (BPSK) modulation scheme in symmetric additive white Gaussian noise (AWGN) channel. The bit error probability (BEP) of coded (63, 36) BCH system was evaluated and compared with the performance of un-coded system...|$|R
