96|16|Public
25|$|For example: the floppy {{controller}} circuitry on the Wang PC {{was similar}} to that of the IBM PC but involved enough design differences that PC compatible software attempting to manipulate it directly would fail. Wang's PC emulation hardware would detect I/O and memory operations involving the addresses associated with the floppy controller in the IBM PC and generate an NMI. The NMI handler would immediately be activated (the exception vector having been appropriated during system init to point to ROM routines on the emulation board instead of the NMI routine in the PC BIOS) and would then update an internal representation of the IBM PC floppy controller and manipulate the real controller to reflect its state. Reads were satisfied in a similar way, by forcing an NMI, decoding the machine code indicated by the <b>Instruction</b> <b>Pointer</b> at the time of the fault, and then obtaining the desired info and updating the CPU registers accordingly before resuming the executing program.|$|E
50|$|In 64-bit mode, {{instructions}} can {{reference data}} {{relative to the}} <b>instruction</b> <b>pointer,</b> so there is less need to copy {{the value of the}} <b>instruction</b> <b>pointer</b> to another register.|$|E
5000|$|Writing to the <b>{{instruction}}</b> <b>pointer</b> {{is simple}} — a [...] instruction sets the <b>instruction</b> <b>pointer</b> {{to the target}} address, so, for example, a sequence like the following will put the contents of [...] into : ...|$|E
50|$|Improved noise {{immunity}} {{can be achieved}} by execution flow control known as token passing. The figure to the right shows the functional principle schematically. This method deals with program flow errors caused by the <b>instruction</b> <b>pointers.</b>|$|R
5000|$|The {{language}} was originally created by Chris Pressey in 1993 for the Amiga, {{as an attempt}} to devise a language which is as hard to compile as possible. Note that the [...] command allows for self-modifying code. Nevertheless, a number of compilers have subsequently been written. A number of extensions to the original [...] "Befunge-93" [...] specification also exist, most notably Funge-98, which extends the concept to an arbitrary number of dimensions and can be multithreaded, with multiple <b>instruction</b> <b>pointers</b> operating simultaneously on the same space. Befunge-extensions and variants are called Fungeoids or just Funges.|$|R
30|$|Pointer {{integrity}} defense: The Pointer Authentication (PA) {{mechanism is}} added to ARMv 8.3 -A to prevent memory corruption attacks (Qualcomm Technologies 2017). PA guarantees the integrity of pointers by binding each pointer with a Pointer Authentication Code (PAC). As the actual address space in 64 -bit architectures is less than 64 bits, PA places the PAC to the unused bits in the pointer value to minimize the size and performance impact. PACs are computed by a lightweight cryptography algorithm (Avanzi 2017) and added to the pointer values by extended PAC instructions. The integrity of pointers is verified and restored by the AUT instructions. To restrict the accesses to pointers in special context, PA allocates keys for <b>instruction</b> <b>pointers,</b> data <b>pointers</b> and general-purpose <b>instructions.</b> The keys are still managed by software.|$|R
5000|$|In 64-bit mode, near {{branches}} with the 66H (operand size override) prefix behave differently. Intel 64 ignores this prefix: the instruction has 32-bit sign extended offset, and <b>instruction</b> <b>pointer</b> is not truncated. AMD64 uses 16-bit offset {{field in the}} instruction, and clears the top 48 bits of <b>instruction</b> <b>pointer.</b>|$|E
5000|$|The {{language}} utilises a 64K {{block of}} memory, and 2 pointers - a memory pointer and an <b>instruction</b> <b>pointer.</b> The l33t interpreter tokenizes {{all the words}} in the source to create a sequence of numerical opCodes, and places them in order into the memory block, starting at byte 0. The <b>instruction</b> <b>pointer</b> will keep incrementing until it encounters an END. The memory pointer starts at the first byte after the instructions. Memory [...] "wraps": incrementing the memory and the <b>instruction</b> <b>pointer</b> past 64K will cause it to run around to byte 0, and vice versa.|$|E
5000|$|IP/EIP/RIP: <b>Instruction</b> <b>pointer.</b> Holds {{the program}} counter, the current {{instruction}} address.|$|E
40|$|Understanding {{where the}} system is {{spending}} its time is necessary for debugging and optimizing applications. As such, we present an analysis tool {{with the intent to}} continuously take measurements on every timer interrupt during a sampling period. The end result is a collection of data samples that have been aggregated to display what <b>instruction</b> <b>pointers</b> are seen most often. These aggregates can be viewed on an instruction level, an instance of an application, a subset of the running applications, or on the system as a whole. Based on the benchmarks, the majority of the results are verifiable and the sampling itself is extremely efficient with minimal overhead (0. 01 - 0. 9 percent). The overhead of the system utilizing the worst case backup scheme is three to six percent. ...|$|R
40|$|Recent {{studies have}} shown that most SPEC CPU 2 K {{benchmarks}} exhibit strong phase behavior, and the Cycles per Instruction (CPI) performance metric can be accurately predicted based on program’s control-flow behavior, by simply observing the sequencing of the program counters, or extended <b>instruction</b> <b>pointers</b> (EIPs). One motivation {{of this paper is to}} see if server workloads also exhibit such phase behavior. In particular, can EIPs effectively predict CPI in server workloads? We propose using regression trees to measure the theoretical upper bound on the accuracy of predicting the CPI using EIPs, where accuracy is measure by the explained variance of CPI with EIPs. Our results show that for most server workloads and, surprisingly, even for CPU 2 K benchmarks, the accuracy of predicting CPI from EIPs varies widely. We classify the benchmarks into four quadrants based on their CPI variance and predictability of CPI using EIPs. Our results indicate that no single sampling technique can be broadly applied to a large class of applications. We propose a new methodology that selects the best-suited sampling technique to accurately capture the program behavior. 1...|$|R
50|$|Some superscalar {{processors}} (MIPS R8000, Alpha 21264 and Alpha 21464 (EV8)) fetch {{each line}} of <b>instructions</b> with a <b>pointer</b> {{to the next}} line. This next line predictor handles branch target prediction as well as branch direction prediction.|$|R
5000|$|Brainfuck, which {{consists}} of only eight simple commands and an <b>instruction</b> <b>pointer</b> ...|$|E
50|$|The {{instruction}} {{set of the}} PDP-11 computer includes an instruction for moving data, which when constructed in a particular form causes itself to be moved from higher addresses to lower addresses; the form includes an automatic decrement of the <b>instruction</b> <b>pointer</b> register. Hence, when this instruction includes autodecrement of the <b>instruction</b> <b>pointer,</b> it behaves as a dynamic self-relocator.|$|E
50|$|Statistical {{sampling}} is {{the periodic}} recording of a processor's program counter or <b>instruction</b> <b>pointer.</b>|$|E
40|$|The Vienna Abstract Machine (VAM) is a Prolog machine {{developed}} at the TU Wien. In contrast to the standard implementation technique (Warren Abstract Machine – WAM), an inference in VAM is performed by unifying the goal and head immediately, instead of bypassing arguments through a register interface. We present two implementations for VAM: VAM 2 P and VAM 1 P. VAM 2 P is well suited for an intermediate code emulator (e. g. direct threaded code) which uses two <b>instruction</b> <b>pointers</b> for both goal code and head code. During an inference VAM 2 P fetches one instruction from the goal code, and one instruction from the head code and executes the combined instruction. More optimization is therefore possible, since information about the calling goal {{and the head of}} the clause is available at the same time. VAM performs cheap shallow backtracking, needs less dereferencing and trailing and implements a faster cut. In a Prolog with the occur-check, VAM omits many unnecessary operations. VAM 1 P is designed for native code compilation. It combines instructions at compile time and supports several optimizations, such as fast last-call optimization. In this paper we present the VAM in detail and compare it with existing machines. ...|$|R
50|$|Bellmac 32 has {{a program}} counter and 15 {{general-purpose}} 32-bit registers. Three {{of these are}} used to support the operating system {{and can be used}} when the microprocessor is in kernel mode. It has three other registers that are used by some <b>instructions</b> as stack <b>pointers.</b>|$|R
40|$|Two formal {{models for}} {{parallel}} computation are presented: an abstract conceptual model and a parallel-program model. The former model does {{not distinguish between}} control and data states. The latter model includes the capability for the representation of an infinite set of control states by allowing there to be arbitrarily many <b>instruction</b> <b>pointers</b> (or processes) executing the program. An induction principle is presented which treats the control and data state sets on the same ground. Through the use of “place variables,” {{it is observed that}} certain correctness conditions can be expressed without enumeration of the set of all possible control states. Examples are presented in which the induction principle is used to demonstrate proofs of mutual exclusion. It is shown that assertions-oriented proof methods are special cases of the induction principle. A special case of the assertions method, which is called parallel place assertions, is shown to be incomplete. A formalization of “deadlock” is then presented. The concept of a “norm” is introduced, which yields an extension, to the deadlock problem, of Floyd 2 ̆ 7 s technique for proving termination. Also discussed is an extension of the program model which allows each process to have its own local variables and permits shared global variables. Correctness of certain forms of implementation is also discussed. An Appendix is included which relates this work to previous work on the satisfiability of certain logical formulas...|$|R
5000|$|The <b>instruction</b> <b>pointer</b> {{is called}} [...] in 16-bit mode, [...] in 32-bit mode, and [...] in 64-bit mode. The <b>instruction</b> <b>pointer</b> {{register}} {{points to the}} memory address which the processor will next attempt to execute; it cannot be directly accessed in 16-bit or 32-bit mode, but a sequence like the following can be written to put the address of [...] into : ...|$|E
50|$|Arbitrary code {{execution}} {{is commonly}} achieved through {{control over the}} <b>instruction</b> <b>pointer</b> (such as a jump or a branch) of a running process. The <b>instruction</b> <b>pointer</b> points to the next instruction in the process that will be executed. Control over {{the value of the}} <b>instruction</b> <b>pointer</b> therefore gives control over which instruction is executed next. In order to execute arbitrary code, many exploits inject code into the process (for example by sending input to it which gets stored in an input buffer in RAM) and use a vulnerability to change the <b>instruction</b> <b>pointer</b> to have it point to the injected code. The injected code will then automatically get executed. This type of attack exploits the fact that most computers do not make a general distinction between code and data, so that malicious code can be camouflaged as harmless input data. Many newer CPUs have mechanisms to make this harder, such as a no-execute bit.|$|E
50|$|A funge is an esoteric {{programming}} language which models its programs as metric spaces with coordinate systems (often, but not necessarily, Cartesian) and which execute instructions located at points {{in their program}} space by moving an <b>instruction</b> <b>pointer</b> (a position vector which indicates the currently executing instruction) through that space. Different instructions determine {{the direction in which}} the <b>instruction</b> <b>pointer</b> moves, and consequently, the sequence of instructions that is executed.|$|E
40|$|We {{present a}} simple {{architectural}} mechanism called dynamic information flow tracking that can significantly improve {{the security of}} computing systems with negligible performance overhead. Dynamic information flow tracking protects programs against malicious software attacks by identifying spurious information flows from untrusted I/O and restricting the usage of the spurious information. Every security attack {{to take control of}} a program needs to transfer the program’s control to malevolent code. In our approach, the operating system identifies a set of input channels as spurious, and the processor tracks all information flows from those inputs. A broad range of attacks are effectively defeated by checking the use of the spurious values as <b>instructions</b> and <b>pointers.</b> Our protection is transparent to users or application programmers; the executables can be used without any modification. Also, our scheme only incurs, on average, a memory overhead of 1. 4 % and a performance overhead of 1. 1 %...|$|R
40|$|Cache {{memories}} {{have been}} extensively used {{to bridge the}} speed gap between high speed processors and relatively slow main memory. However, they are not widely used in real-time systems due to their unpredictable performance. This paper proposes an instruction prefetching scheme called threaded prefetching {{as an alternative to}} instruction caching in real-time systems. In the proposed threaded prefetching, an <b>instruction</b> block <b>pointer</b> called a thread is assigned to each instruction memory block and is made to point to the next block on the worst case execution path that is determined by a compile-time analysis. Also, the thread is not updated throughout the entire program execution to guarantee predictability. This paper also compares the worst case performances of various previous instruction prefetching schemes with that of the proposed threaded prefetching. By analyzing several benchmark programs, we show that the worst case performance of the proposed scheme is significantly better [...] ...|$|R
40|$|A common {{theoretical}} assumption in {{the study}} of information flow security in Java-like languages is that pointers are opaque - i. e., that the only properties that can be observed of pointers are the objects to which they point, and (at most) their equality. These assumptions often fail in practice. For example, various important operations in Java's standard API, such as hashcodes or serialization, might break pointer opacity. As a result, information-flow static analyses which assume pointer opacity risk being unsound in practice, since the pointer representation provides an unchecked implicit leak. We investigate information flow in the presence of non-opaque pointers for an imperative language with records, <b>pointer</b> <b>instructions</b> and exceptions, and develop an information flow aware type system which guarantees noninterference...|$|R
50|$|The {{language}} {{consists of}} eight commands, listed below. A brainfuck {{program is a}} sequence of these commands, possibly interspersed with other characters (which are ignored). The commands are executed sequentially, with some exceptions: an <b>instruction</b> <b>pointer</b> begins at the first command, and each command it points to is executed, after which it normally moves {{forward to the next}} command. The program terminates when the <b>instruction</b> <b>pointer</b> moves past the last command.|$|E
50|$|Detect that a stack buffer {{overflow}} has occurred and thus prevent redirection of the <b>instruction</b> <b>pointer</b> to malicious code.|$|E
50|$|CS:IP (CS is Code Segment, IP is <b>Instruction</b> <b>Pointer)</b> {{points to}} the address where the {{processor}} will fetch the next byte of code.|$|E
40|$|Noninterference in the {{presence}} of non-opaque pointers A common theoretical assumption in the study of information flow security in Java-like languages is that pointers are opaque – i. e., that the only properties that can be observed of pointers are the objects to which they point, and (at most) their equality. These assumptions often fail in practice. For example, various important operations in Java’s standard API, such as hashcodes or serialization, might break pointer opacity. As a result, information-flow static analyses which assume pointer opacity risk being unsound in practice, since the pointer representation provides an unchecked implicit leak. We investigate information flow in {{the presence}} of non-opaque pointers for an imperative language with records, <b>pointer</b> <b>instructions</b> and exceptions, and develop an information flow aware type system which guarantees noninterference. ...|$|R
40|$|This {{white paper}} {{describes}} a significant new feature of libsafe version 2. 0 : {{the ability to}} detect and handle format string vulnerability exploits. Such exploits have recently garnered attention in security advisories, discussion lists, web sites devoted to security, and even conventional media such as television and newspapers. Examples of vulnerable software include wu-ftpd (a common FTP daemon) and bind (A DNS [Domain Name System] server). This paper describes the vulnerability and the technique libsafe uses to detect and handle exploits. NOTE: This paper only describes one particular feature of libsafe version 2. 0 : the ability to detect and handle format string vulnerability exploits. Other features include support for code compiled without frame <b>pointer</b> <b>instructions,</b> extra debugging facilities, and bug fixes. See [1] for details of the original version of libsafe. ...|$|R
40|$|Patients {{with pain}} emanating from their spines {{represent}} {{some of the}} most frequent and challenging cases for physical therapists. Here is a comprehensive and practical introduction to the management of back pain and restricted spinal function caused by intervertebral disk damage. The authors provide evidence-based, clinically oriented strategies for the diagnosis and therapeutic treatment of disk injury in the lumbar, thoracic, and cervical spinal regions. The text gives an overview of research studies on the effects of physical therapy on back pain, step-by-step guidance on examination and conservative and postoperative physical therapy procedures, and detailed discussion of rehabilitation and prevention of further disk damage. Key Features: •Extensive coverage of examination, from patient history to tests for assessing spinal movement to nerve conduction •Precise <b>instructions</b> and useful <b>pointers</b> on treatment methods aid in daily practice •Chapter on basic principles of anatomy, physiology, and epidemiology offer foundational knowledge •Crucial information on approaches for rehabilitation and injury prevention, including strengthening, coordination exercises, and conditioning •Case studies present clinical examples that guide the reader through the full course of therapy • 70 clear line drawings illustrate how to maintain correct posture; avoid poor posture; and protect and train muscles, nerves, and joints Physical Therapy for Intervertebral Disk Disease is a complete guide to the diagnosis and physiotherapeutic treatment of problems resulting from intervertebral disk damage. Practitioners and students of physical therapy, rehabilitation medicine, and occupational therapy will read this book cover to cover and refer to it regularly when working to relieve back pain and restore full capacity in their patients...|$|R
50|$|These can {{be divided}} to the {{explicit}} part (such as values stored in variables) and the implicit part (return addresses and the <b>instruction</b> <b>pointer).</b>|$|E
5000|$|... ip or i (<b>instruction</b> <b>pointer)</b> of {{the virtual}} machine (not to be {{confused}} with the program counter of the underlying hardware implementing the VM) ...|$|E
50|$|In QEMU, {{a triple}} fault {{produces}} a dump {{of the virtual}} machine in the console, with the <b>instruction</b> <b>pointer</b> set to the instruction that triggered the first exception.|$|E
40|$|Common {{protection}} mechanisms fail to provide end-to-end security; programs with legitimate access to secret information are not prevented from leaking {{this to the}} world by accident or malice. Protecting the access to information {{is not enough to}} solve this problem. We have to ensure that the program uses the information in a secure way. Work on information flow security often ignores information flows through covert channels even though they pose a serious threat. In the first paper we present a framework for timing-aware information-flow type systems for a low-level language similar to a non-trivial subset of a sequential Java bytecode. The framework is parametrised over a time model of the instructions of the language and over the algorithm enforcing low-observational equivalence, used in the prevention of implicit and timing flows. This gives us the possibility to easily experiment with different time models. We argue that this is important for two reasons: 1) different applications may have different thresholds for what is an acceptable covert channel, and 2) different implementations of the same language may contain different possibilities of covert channels. In the second paper we investigate a threat to practical information flow security: the failure to include the runtime environment of a language into consideration. It is important that the assumptions that are made {{in the study of the}} core language are honoured by the runtime system, in which inevitably every program will be run. In particular, the second paper studies one commonly made assumption in analyses of Java that may be broken by the runtime environment: that pointers are opaque [...] i. e., that the only properties that can be observed of pointers are the objects to which they point, and (at most) their equality. These assumptions often fail in practise. For example, various important operations in Java's standard API, such as hashcodes or serialisation, might break pointer opacity. As a result, static information-flow analyses, which assume pointer opacity risk being unsound in practise, since the pointer representation provides an unchecked implicit leak [...] - a covert channel via the state of the memory allocator. We investigate information flow in the presence of non-opaque pointers for an imperative language with records, <b>pointer</b> <b>instructions</b> and exceptions, and develop an information flow aware type system which guarantees noninterference. </p...|$|R
50|$|If an <b>instruction</b> <b>pointer</b> error {{occurs during}} the {{execution}} {{and a program}} points to a memory segment filled with NOP instructions, inevitably an error occurred and is recognized.|$|E
5000|$|The MOVE {{instruction}} {{writes a}} 16-bit value {{into one of}} the chipset's hardware registers and is also used to strobe a new address into the Copper's <b>instruction</b> <b>pointer.</b>|$|E
