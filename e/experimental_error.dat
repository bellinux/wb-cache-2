2203|1866|Public
5|$|The Chicxulub Crater lends {{support to}} the theory {{postulated}} by the late physicist Luis Alvarez and his son, geologist Walter Alvarez, that the extinction of numerous animal and plant groups, including non-avian dinosaurs, may have resulted from a bolide impact (the Cretaceous–Paleogene extinction event). Luis and Walter Alvarez, at the time both faculty members at the University of California, Berkeley, postulated that this enormous extinction event, which was roughly contemporaneous with the postulated date of formation for the Chicxulub crater, could {{have been caused by}} just such a large impact. The age of the rocks marked by the impact shows that this impact structure dates from roughly 66 million years ago, the end of the Cretaceous period, and the start of the Paleogene period. It coincides with the K–Pg boundary, the geological boundary between the Cretaceous and Paleogene. The impact associated with the crater is thus implicated in the Cretaceous–Paleogene extinction event, including the worldwide extinction of non-avian dinosaurs. This conclusion has been the source of controversy. In March 2010, 41 experts from many countries reviewed the available evidence: 20 years' worth of data spanning a variety of fields. They concluded that the impact at Chicxulub triggered the mass extinctions at the K–Pg boundary. In 2013 a study compared isotopes in impact glass from the Chicxulub impact with the same isotopes in ash from the boundary where the extinction event occurred in the fossil record; the study concluded that the impact glasses were dated at 66.038 ± 0.049 Ma, and the deposits immediately above the discontinuity in the geological and fossil record was dated to 66.019 ± 0.021 Ma, the two dates being within 19,000 years of each other, or almost exactly the same within <b>experimental</b> <b>error.</b> The theory is now widely accepted by the scientific community. Some critics, including paleontologist Robert Bakker, argue that such an impact would have killed frogs as well as dinosaurs, yet the frogs survived the extinction event. Gerta Keller of Princeton University argues that recent core samples from Chicxulub prove the impact occurred about 300,000 years before the mass extinction, and thus could not have been the causal factor. However, this conclusion is unsupported by radioactive dating and sedimentology.|$|E
25|$|The {{experiment}} of Wilhelm Klinkerfues (1870) investigated {{whether an}} influence of Earth's motion on the absorption line of sodium exists. He obtained a positive result, {{but this was}} shown to be an <b>experimental</b> <b>error,</b> because a repetition of the experiment by Haga (1901) gave a negative result.|$|E
25|$|The COPE {{guidelines}} {{state that}} journal editors should consider retracting a publication {{if they have}} clear evidence that the findings are unreliable, either {{as a result of}} misconduct (e.g. data fabrication) or honest error (e.g. miscalculation or <b>experimental</b> <b>error).</b> Retraction is also appropriate in cases of redundant publication, plagiarism and unethical research.|$|E
5000|$|Latin squares {{are used}} in the design of agronomic {{research}} experiments to minimise <b>experimental</b> <b>errors</b> ...|$|R
40|$|Evaluation of the {{strength}} of association between predisposing or causal factors and disease can be express as odds ratio in case-control studies. In order to interpret correctly a point estimation of odds ratio we need to look also to its confidence intervals quality. The aim {{of this paper is to}} introduce three new methods of computing the confidence intervals, R 2 AC, R 2 Binomial, and R 2 BinomialC, and compare the performances with the asymptotic method called R 2 Wald. In order to assess the methods a PHP program was develop. First, the upper and lower confidence boundaries for all implemented methods were computes and graphically represented. Second, the <b>experimental</b> <b>errors,</b> standard deviations of the <b>experimental</b> <b>errors</b> and deviation relative to the imposed significance level α = 5 % were assessed. Estimating the <b>experimental</b> <b>errors</b> and standard deviations at central point for given sample sizes was the third criterion. The R 2 Wald and R 2 AC methods were assessed using random binomial variables (X, Y) and sample sizes (m, n) from 4 to 1000. The methods based on the original method Binomial adjusted for odds ratio (R 2 Binomial, R 2 BinomialC functions) obtain systematically the lowest deviation of the <b>experimental</b> <b>errors</b> percent relative to the expected error percent and the R 2 AC method, the closest average of the <b>experimental</b> <b>errors</b> percent to the expected error percent...|$|R
40|$|The {{determination}} of equilibrium constants {{is a widespread}} tool both to understand and to characterize protein-protein interactions. A variety of different methods, among them Scatchard analysis, {{is used to calculate}} these constants. Although more than 1000 articles dealing with equilibrium constants are published every year, the effects of <b>experimental</b> <b>errors</b> on the results are often disregarded when interpreting the data. In the present study we theoretically analysed the effect of various types of <b>experimental</b> <b>errors</b> on equilibrium constants derived by three different methods. A computer simulation clearly showed that certain <b>experimental</b> <b>errors,</b> namely inaccurate background correction, inexact calibration, saturation effects, slow kinetics and simple scattering, can adversely affect the result. The analysis further revealed that, for a given type of error, the same data set can produce different results depending on the method used...|$|R
25|$|Early {{experimental}} tests {{from the}} 1950s onwards gave positive results showing the force was real, but other external factors {{could not be}} ruled out as the primary cause, with the range of <b>experimental</b> <b>error</b> sometimes being nearly 100%. That changed in 1997 with Lamoreaux conculsively showing such the Casimir force was real. Results have been repeatedly replicated since then.|$|E
25|$|Naturally {{abundant}} chlorine {{consists of}} two isotopes, 35Cl and 37Cl, in a ratio of approximately 3:1. While the spring constants are identical within <b>experimental</b> <b>error,</b> the reduced masses are different causing measurable differences in the rotational energy, thus doublets are observed on close inspection of each absorption line, weighted in the same ratio of 3:1.|$|E
25|$|If <b>experimental</b> <b>error</b> {{follows a}} normal distribution, then, {{because of the}} linear {{relationship}} between residuals and observations, so should residuals, but since the observations are only {{a sample of the}} population of all possible observations, the residuals should belong to a Student's t-distribution. Studentized residuals are useful in making a statistical test for an outlier when a particular residual appears to be excessively large.|$|E
3000|$|RB within <b>experimental</b> <b>errors,</b> {{indicating}} that the Rashba SOC in sample B nearly equals to that in sample A, i.e., α [...]...|$|R
50|$|However, in {{the case}} that the <b>experimental</b> <b>errors</b> do belong to a normal distribution, the least-squares {{estimator}} is also a maximum likelihood estimator.|$|R
3000|$|The {{function}} Φ {{is called}} response surface or response function. The residual e [...] r [...] measures the <b>experimental</b> <b>errors</b> (Cochran and Cox 1962).|$|R
25|$|Experimental errors can be high in {{measuring}} equilibrium stability {{as well the}} folding/unfolding rates in water for the wild-type protein and mutants. The necessity of extrapolating phi values in pure water from measurements made in solutions containing denaturants adds uncertainty to the reported values. When the stability difference between the native and mutant protein are low (< 7 kJ/mol), <b>experimental</b> <b>error</b> can be very large; unusual phi-values outside the 0-1 range may arise from these errors rather than illustrating deviations from the conditions assumed by the method. In addition, calculated phi values {{have been shown to}} depend strongly on the number of data points collected and the laboratory in which the experiment was performed.|$|E
25|$|Many {{scientists}} {{tried to}} replicate the experiment with the few details available. Hopes faded due to {{the large number of}} negative replications, the withdrawal of many reported positive replications, the discovery of flaws and sources of <b>experimental</b> <b>error</b> in the original experiment, and finally the discovery that Fleischmann and Pons had not actually detected nuclear reaction byproducts. By late 1989, most scientists considered cold fusion claims dead, and cold fusion subsequently gained a reputation as pathological science. In 1989 the United States Department of Energy (DOE) concluded that the reported results of excess heat did not present convincing evidence of a useful source of energy and decided against allocating funding specifically for cold fusion. A second DOE review in 2004, which looked at new research, reached similar conclusions and did not result in DOE funding of cold fusion.|$|E
25|$|An {{excess heat}} {{observation}} {{is based on}} an energy balance. Various sources of energy input and output are continuously measured. Under normal conditions, the energy input can be matched to the energy output to within <b>experimental</b> <b>error.</b> In experiments such as those run by Fleischmann and Pons, an electrolysis cell operating steadily at one temperature transitions to operating at a higher temperature with no increase in applied current. If the higher temperatures were real, and not an experimental artifact, the energy balance would show an unaccounted term. In the Fleischmann and Pons experiments, the rate of inferred excess heat generation was in the range of 10–20% of total input, though this could not be reliably replicated by most researchers. Researcher Nathan Lewis discovered that the excess heat in Fleischmann and Pons's original paper was not measured, but estimated from measurements that didn't have any excess heat.|$|E
40|$|Torque {{magnetometer}} {{measurements of}} the magnetic moment of thin films are subject to systematic error {{as a result of}} the assumed reversal process, in addition to the <b>experimental</b> <b>errors.</b> By the use of unconventional methods of measuring the magnetic moment, which minimize the <b>experimental</b> <b>errors,</b> the effect of the systematic error is demonstrated. The suggestion is made that experiments of this type could also be used to investigate ripple and skew subject to a satisfactory reversal theory relating torque measurements to these effects...|$|R
2500|$|Consider an overdetermined {{system of}} linear equations, as might occur with {{repeated}} measurements {{of a physical}} phenomenon to compensate for <b>experimental</b> <b>errors.</b> Write , where [...] is , [...]|$|R
5000|$|... with [...] when [...] Unit weights, , {{are often}} used but, in that case, the {{expectation}} value of [...] is the root mean square of the <b>experimental</b> <b>errors.</b>|$|R
25|$|A more {{stringent}} test would involve following the chemical shifts {{of each and}} every atom in the molecule by nuclear magnetic resonance (NMR) as a function of temperature/denaturant. Though time-consuming, this method does not require any specific model for the interpretation of data. The Tms for all the atoms should be identical within <b>experimental</b> <b>error</b> if the protein folds in a two-state manner. But for a protein that folds globally downhill the unfolding curves should have widely different Tms. The atomic unfolding behavior of BBL was found to follow the latter, showing a large spread in the Tms consistent with global downhill behavior. The Tms of some atoms were found to be {{similar to that of the}} global Tm (obtained from a low-resolution technique like CD or fluorescence), indicating that the unfolding of multiple atoms has to be followed, instead of a few as is frequently done in such experiments. The average atomic unfolding behavior was strikingly similar to that of CD, underlining the fact that unfolding curves of low resolution experiments are highly simplified representations of a more complex behavior.|$|E
25|$|In 1989, Pons and Fleischmann {{submitted}} {{papers to}} the Journal of Electroanalytical Chemistry {{claiming that they}} had observed fusion in a room temperature device and disclosing their work in a press release. Some scientists reported excess heat, neutrons, tritium, helium and other nuclear effects in so-called cold fusion systems, which for a time gained interest as showing promise. Hopes fell when replication failures were weighed in view of several reasons cold fusion {{is not likely to}} occur, the discovery of possible sources of <b>experimental</b> <b>error,</b> and finally the discovery that Fleischmann and Pons had not actually detected nuclear reaction byproducts. By late 1989, most scientists considered cold fusion claims dead, and cold fusion subsequently gained a reputation as pathological science. However, a small community of researchers continues to investigate cold fusion claiming to replicate Fleishmann and Pons' results including nuclear reaction byproducts. Claims related to cold fusion are largely disbelieved in the mainstream scientific community. In 1989, the majority of a review panel organized by the US Department of Energy (DOE) found that the evidence for the discovery of a new nuclear process was not persuasive. A second DOE review, convened in 2004 to look at new research, reached conclusions similar to the first.|$|E
500|$|One {{consequence}} of the proposed changes {{to the definition of}} the ampere is that the definition will no longer be dependent on the definitions of the kilogram and the metre, but will still be dependent on the definition of the second. [...] In addition the vacuum permeability, vacuum permittivity and impedance of free space, which, in the current definition have exact values will, in the future, be subject to <b>experimental</b> <b>error.</b>|$|E
2500|$|... {{and thus}} {{accepted}} by the physics community. Experimental results which appear to contradict it are not reproducible and are thus widely believed {{to be due to}} <b>experimental</b> <b>errors.</b>|$|R
40|$|Dynamical {{decoupling}} (DD) is {{a popular}} technique for protecting qubits from the environment. However, unless special care is taken, <b>experimental</b> <b>errors</b> in the control pulses used in this technique can destroy the quantum information instead of preserving it. Here, we investigate techniques for making DD sequences robust against different types of <b>experimental</b> <b>errors</b> while retaining good decoupling efficiency in a fluctuating environment. We present experimental data from solid-state nuclear spin qubits and introduce a new DD sequence that is suitable for quantum computing and quantum memory. Comment: 4 pages, 5 figure...|$|R
40|$|The {{influence}} of <b>experimental</b> <b>errors</b> on {{the determination of}} flux control coefficients from transient metabolite concentrations with the method proposed by Delgado and Liao [(1992) Biochem. J. 282, 919 - 927] has been investigated by using Monte Carlo simulations. The method requires least-squares fitting of the transient metabolite concentrations. Three different fitting methods have been evaluated. Simulated metabolite concentrations of a fictive metabolic pathway were scattered randomly, emulating <b>experimental</b> <b>errors,</b> before performing the fits. This was repeated {{a large number of}} times; the mean values and standard deviations of the resulting control coefficients are reported. The results show that the proposed method for determining control coefficients is too sensitive to <b>experimental</b> <b>errors</b> to be practicable, with theoretically justified fitting methods. This is in particular due to the high degree of correlation between the concentrations. An alternative ad hoc fitting method produced biased mean values of the estimates of the control coefficients, but with remarkably low standard deviations...|$|R
2500|$|Hon, Giora. [...] "Is there {{a concept}} of <b>experimental</b> <b>error</b> in Greek astronomy?." [...] The British Journal for the History of Science 22.02 (1989): 129-150. (Available online at https://www.researchgate.net/profile/Giora_Hon/publication/231844424_Is_There_a_Concept_of_Experimental_Error_in_Greek_Astronomy/links/564fa57b08ae4988a7a858bd.pdf) ...|$|E
2500|$|It {{was found}} that the [...] color {{matching}} function could be set to zero above [...] while remaining within the bounds of <b>experimental</b> <b>error.</b> For computational simplicity, it was specified that this would be so.|$|E
2500|$|Design of experiments, using {{blocking}} {{to reduce}} the influence of confounding variables, and [...] randomized assignment of treatments to subjects to allow unbiased estimates of treatment effects and <b>experimental</b> <b>error.</b> At this stage, the experimenters and statisticians write the experimental protocol that will guide {{the performance of the}} experiment and which specifies the primary analysis of the experimental data.|$|E
5000|$|... #Caption: Figure 3: Wigner {{function}} of the coherent state depicted in Figure 2. The distribution is centered on state's amplitude α and is symmetric around this point. The ripples are due to <b>experimental</b> <b>errors.</b>|$|R
40|$|Treballs Finals de Grau de Química, Facultat de Química, Universitat de Barcelona, Any: 2016, Tutor: Joaquín F. Pérez de BenitoMany kinetic studies {{concerning}} homologous reaction series {{report the}} existence of an activation enthalpy-entropy linear correlation (compensation plot), its slope being the temperature at which {{all the members of the}} series have the same rate constant (isokinetic temperature). Unfortunately, it has been demonstrated by statistical methods that the <b>experimental</b> <b>errors</b> associated with the activation enthalpy and entropy are mutually interdependent. Therefore, the possibility that some of those correlations might be caused by accidental errors has been explored by numerical simulations. As a result of this study, a computer program has been developed to evaluate the probability that <b>experimental</b> <b>errors</b> might lead to a linear compensation plot parting from an initial randomly scattered set of activation parameters (p-test). Application of this program to kinetic data for 100 homologous reaction series extracted from bibliographic sources has allowed concluding that most of the reported compensation plots can hardly be explained by the accumulation of <b>experimental</b> <b>errors,</b> thus requiring {{the existence of}} a previously existing, physically meaningful correlatio...|$|R
40|$|The cost of {{large-scale}} association studies {{may be reduced}} substantially by analysis of pooled DNA from multiple individuals. Here we examine the optimal symmetric and asymmetric designs for pooling experiments for quantitative traits under a range of assumptions about the underlying genetic model and the sources of <b>experimental</b> <b>errors</b> in allele frequency estimation. The results indicate that, {{in the absence of}} <b>experimental</b> <b>errors</b> and for common alleles with additive effects, a symmetric pooling scheme comparing the top 27 % with the bottom 27 % of the trait distribution is optimal, extracting 80 % the total information available. A symmetric design is not optimal for rare or recessive alleles, which require asymmetric (or other) pooling strategies. Allele frequency measurement errors reduce the optimal pooling fraction as well as the overall efficiency of the pooling design. In contrast, random variation in the amount of DNA contributed by individuals to a pool reduces only the overall efficiency of the pooling design. Our results emphasize the importance of minimising <b>experimental</b> <b>errors</b> and suggest a pooling fraction of around 20 %. link_to_subscribed_fulltex...|$|R
2500|$|Measuring {{the angles}} [...] and [...] and the {{distance}} between the charges [...] and [...] is sufficient to verify that the equality is true taking into account the <b>experimental</b> <b>error.</b> In practice, angles can be difficult to measure, so if the length of the ropes is sufficiently great, the angles will be small enough to make the following approximation: ...|$|E
2500|$|Finally, Geiger and Marsden tested how the {{scattering}} varied with {{the velocity of}} the alpha particles (i.e. if s ∝ 1/v4). [...] Using the same apparatus again, they slowed the alpha particles by placing extra sheets of mica {{in front of the}} alpha particle source. [...] They found that, within the range of <b>experimental</b> <b>error,</b> that the number of scinitillations was indeed proportional to 1/v4.|$|E
2500|$|A New York Times article {{says that}} {{although}} peer reviewers were harshly critical of Pons' and Fleischmann's research, they did not apply such criticism to Jones' significantly more modest, theoretically supported findings. Although critics insisted that Jones' results were probably caused by <b>experimental</b> <b>error,</b> {{the majority of the}} reviewing physicists claimed that he was a careful scientist. Later research and experiments have supported Jones' metallic [...] "cold fusion" [...] (geo-fusion) reports.|$|E
25|$|When unit weights {{are used}} (W = I, the {{identity}} matrix), it is {{implied that the}} <b>experimental</b> <b>errors</b> are uncorrelated and all equal: M = σ2I, where σ2 is the a priori variance of an observation.|$|R
40|$|A {{method of}} {{inverting}} Abel's integral equation, which is fairly insensitive to <b>experimental</b> <b>errors,</b> is described. The method approximates the radial distribution {{by a series}} of Gaussian distributions; hence the accuracy is best in problems such as gas columns, where Gaussian distributions might be expected. Sandia Corporation Research Report SC- 4938 (RR) December 1963. Includes bibliographical references. A method of inverting Abel's integral equation, which is fairly insensitive to <b>experimental</b> <b>errors,</b> is described. The method approximates the radial distribution {{by a series of}} Gaussian distributions; hence the accuracy is best in problems such as gas columns, where Gaussian distributions might be expected. Mode of access: Internet...|$|R
40|$|The work {{described}} in this paper comprises the first direct experimental determination ever made of the surface energy of a true solid. The meagre amount of work done previously in this field, of which a brief account follows, {{has been based on}} theory, usually highly involved, which alone, aside from the <b>experimental</b> <b>errors,</b> introduces great uncertaintyin the results. The large <b>experimental</b> <b>errors,</b> added to this, makes such work merely qua 1 itative in nature. In contrast to this, the experimental results obtained in the present work give the surface energy directly, while the experimental method presents no unsurmountable difficulties and has a wide field of applicability. [ [...] . ...|$|R
