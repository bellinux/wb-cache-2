14|19|Public
6000|$|Still {{farther to}} soften the {{asperities}} of the scene, the dialogue is cast into a rude Hudibrastic metre, full of forced rhymes, and strange double-endings, with a rhythm ever changing, ever rough and lively, which might almost {{be compared to the}} hard, irregular, <b>fluctuating</b> <b>sound</b> of the regimental drum. In this ludicrous doggrel, with phrases and figures of a correspondent cast, homely, ridiculous, graphic, these men of service paint their hopes and doings. There are ranks and kinds among them; representatives of all the constituent parts of the motley multitude, which followed this prince of Condottieri. The solemn pedantry of the ancient Wachtmeister is faithfully given; no less so are the jocund ferocity and heedless daring of Holky's Jägers, or the iron courage and stern camp-philosophy of Pappenheim's Cuirassiers. Of the Jäger the sole principle is military obedience; he does not reflect or calculate; his business is to do whatever he is ordered, and to enjoy whatever he can reach. 'Free wished I to live,' he says, ...|$|E
40|$|Mixed Media {{installation}} at Yorkshire Sculpture Park (YSP), {{developed during}} Art for the Environment Residency awarded by University of the Arts London and YSP. Tree Radio {{is a sound}} installation which transformed an oak tree at the Sculpture Park into a micro radio station. A transmitter embedded into the tree relays as <b>fluctuating</b> <b>sound</b> the trees reactions to light, via sensors on the tree and probes in the tree, which also relay its water levels as electronic tones. Visitors at YSP {{can pick up the}} trees transmissions on their personal FM devices (such as phones with FM) if they are standing next to or near the tree...|$|E
40|$|An exact {{relation}} {{has been}} derived for homogeneous polytropic turbulence {{in terms of}} the two-point fluctuations. Unlike isothermal turbulence, the <b>fluctuating</b> <b>sound</b> speed appears to be a key factor in determining the scaling properties of polytropic turbulence. Three Mach numbers (current, gradient and turbulent Mach number) are defined to characterize the isotropic scaling. At subsonic scale, the Kolmogorov-like - 5 / 3 energy spectrum for ⇢ 1 / 3 v (obtained for isothermal turbulence) is modified by polytropic contribution. For supersonic turbulence, the source terms {{must be taken into account}} which further complicates the scaling and spectral properties. For highly supersonic case, the source terms, however, can be shown to be nearly equal to the source terms in isothermal turbulence thereby leading to a partial simplification. These theoretical results are extremely important for understanding the role of turbulence in the star-formation mechanism in polytropic clouds...|$|E
40|$|Audio {{visualization}} gives a {{graphical representation}} to beats, intensity, and the <b>fluctuating</b> <b>sounds</b> heard in music. Music dynamic animation, deriving from {{this concept of}} audio visualizers, implements a hard coded range styled beat detection. This algorithm prioritizes graphical representations of classical and instrumental music. These graphical representations are intended to {{provide a sense of}} imagery...|$|R
50|$|Psychedelic Desert is a noise ambient {{group from}} Osaka, Japan. Psychedelic Desert's music ranges from ambient drone soundscapes to layers of <b>fluctuating</b> <b>sounds</b> which stimulate the brainwaves of the listener. The band toured in Australia in 2008 and {{performed}} on two European tours and on various festivals in 2008 - 2010 (France, Switzerland, Germany, Italy, Slovenia, Netherlands) and released several albums, EPs and appeared on Pharmafabrik compilation albums Fabriksampler with artists Lull, Final, Nordvargr, KK Null and remixed a track for PureH {{on the album}} Signia. The band also host special music installation events called Liquid Beat Hotel in Otoya, Kobe and Osaka.|$|R
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. ECG (electrocardiography) {{consists}} of a few components and features that indicate the details of electrical conduction in {{each part of the}} heart. The simple pitch-mapping sonification of ECG cannot indicate these components to listeners, limiting its potential for diagnostic usages. We present an improved method to emphasize such key features in ECG sonification, using the principle that “we are attentive to loud, high-pitched, and rapidly <b>fluctuating</b> <b>sounds.</b> ” With this principle, we can guide the listener’s attention to subtle yet critical elements of the ECG waveform by controlling the degree of auditory saliency for each component. In this report, we describe ECG sonification step by step and discuss the cognitive and attentive issues as well as the emotional responses of the listeners...|$|R
40|$|Efficient {{prediction}} of passive noise reduction means for jet noise {{was the main}} objective in the joint research project OPTITHECK. Numerical nozzle design tools for industry require short computational time and must provide enough prediction sensitivity in noise level differences even for small geometry variations. Concerning these demands, a broadband jet noise prediction concept was recently successfully validated. The hybrid approach includes the following parts: Firstly a RANS computation which provides mean flow and statistical turbulence quantities. Secondly, fluctuating modal sound sources derived from the Tam & Auriault cross-correlation model, efficiently obtained from 2 -D stochastic realizations using the Random Particle Method (RPM). Thirdly, a Computational Aeroacoustics (CAA) prediction step utilizing the <b>fluctuating</b> <b>sound</b> sources. In this step the near-field solution of jet noise is aquired, which is extrapolated into far-field by the Ffowcs-Williams and Hawkings method to obtain a spectrum that can be compared with far-field measurements...|$|E
40|$|Accumulating {{evidence}} suggests that storing speech sounds requires transposing rapidly <b>fluctuating</b> <b>sound</b> waves into more easily encoded oromotor sequences. If so, then the classical speech areas in the caudalmost portion of the temporal gyrus (pSTG) and in the inferior frontal gyrus (IFG) may be critical for performing this acoustic-oromotor transposition. We tested this proposal by applying repetitive transcranial magnetic stimulation (rTMS) {{to each of these}} left-hemisphere loci, as well as to a nonspeech locus, while participants listened to pseudowords. After 5 minutes these stimuli were re-presented together with new ones in a recognition test. Compared to control-site stimulation, pSTG stimulation produced a highly significant increase in recognition error rate, without affecting reaction time. By contrast, IFG stimulation led only to a weak, non-significant, trend toward recognition memory impairment. Importantly, the impairment after pSTG stimulation was not due to interference with perception, since the same stimulation failed to affect pseudoword discrimination examined with short interstimulus intervals. Our findings suggest that pSTG is essential for transforming speech sounds into stored motor plans for reproducing the sound. Whether or not the IFG also plays a role in speech-sound recognition could not be determined from the present results...|$|E
40|$|The goal is {{to better}} {{understand}} <b>fluctuating</b> <b>sound</b> propagation in two distinct ocean acoustic regimes: Stratified shallow water, where sound is highly bottom interacting, and the temperate deep-ocean sound channel. Acoustic field fluctuations have time scales varying from {{less than a minute}} to hours, and horizontal spatial scales from tens of meters to kilometers, comparable to processing time scales and system spatial scales, and thus impact exploitation of underwater sound. With proper understanding, reliable predictions of temporal and spatial variability of received underwater sound may be possible, thus improving processing and handling of signals of interest. Processing could include remediation of signal degradation and/or exploitation of available sonic information. OBJECTIVES An objective is to quantify and explain underwater sound fluctuation behavior that has been observed in both shallow and deep regimes, for the purpose of meeting the stated goals. For shallow water, transmission loss and phase data are available at frequencies from 50 to 3000 Hz. For the deep-ocean sound channel, data are in hand for propagation at 50 to 100 Hz over 100 ’s to 1000 ’s of kilometers. Propagation and forward scattering models, both theoretical and computational, will be used to tes...|$|E
5000|$|In an {{interview}} with Danai Mavunga of ARISE magazine, Efya described her sound as [...] "Afro soul" [...] {{with a hint of}} pop. She said that her <b>sound</b> <b>fluctuates</b> depending on how she feels and who she's working with. In another interview posted on Modern Ghana's website, Efya cited Kojo Antwi, Aretha Franklin and The Temptations as her key musical influences. Moreover, she stated that she was into old school jazz and highlife growing up.|$|R
40|$|This is {{the final}} version of the article. Available from Wiley via the DOI in this record. Sound waves in water have both a {{pressure}} and a particle-motion component, yet few studies of underwater acoustic ecology have measured the particle-motion component of sound. While mammal hearing is based on detection of sound pressure, fish and invertebrates (i. e. most aquatic animals) primarily sense sound using particle motion. Particle motion can be calculated indirectly from sound pressure measurements under certain conditions, but these conditions are rarely met in the shelf-sea and shallow-water habitats that most aquatic organisms inhabit. Direct measurements of particle motion have been hampered by the availability of instrumentation and a lack of guidance on data analysis methods. Here, we provide an introduction to the topic of underwater particle motion, including the physics and physiology of particle-motion reception. We include a simple computer program for users to determine whether they are working in conditions where measurement of particle motion may be relevant. We discuss instruments that can be used to measure particle motion and the types of analysis appropriate for data collected. A supplemental tutorial and template computer code in matlab will allow users to analyse impulsive, continuous and <b>fluctuating</b> <b>sounds</b> from both pressure and particle-motion recordings. A growing body of research is investigating the role of sound in the functioning of aquatic ecosystems, and the ways in which sound influences animal behaviour, physiology and development. This work has particular urgency for policymakers and environmental managers, who have a responsibility to assess and mitigate the risks posed by rising levels of anthropogenic noise in aquatic ecosystems. As this paper makes clear, because many aquatic animals senses sound using particle motion, this component of the sound field must be addressed if acoustic habitats are to be managed effectively...|$|R
40|$|Complex {{broadband}} {{sounds are}} decomposed by the auditory filters {{into a series}} of relatively narrowband signals, each of which can be considered as a slowly varying envelope (E) superimposed on a more rapid temporal fine structure (TFS). Both E and TFS information are represented in the timing of neural discharges, although TFS information as defined here depends on phase locking to individual cycles of the stimulus waveform. This paper reviews the role played by TFS in masking, pitch perception, and speech perception and concludes that cues derived from TFS play an important role for all three. TFS may be especially important for the ability to “listen in the dips” of <b>fluctuating</b> background <b>sounds</b> when detecting nonspeech and speech signals. Evidence is reviewed suggesting that cochlear hearing loss reduces the ability to use TFS cues. The perceptual consequences of this, and reasons why it may happen, are discussed...|$|R
40|$|The {{long term}} {{goal is to}} better {{understand}} <b>fluctuating</b> <b>sound</b> propagation conditions in two distinct ocean acoustic environment types. The first type is stratified shallow water where sound is highly bottom interacting. The second type is the mostly non bottom-interacting temperate deep-ocean sound channel. Reliable predictions of temporal and spatial variability of received underwater sound can improve processing and handling of signals of interest, including remediation of signal degradation and exploitation of available sonic information. Acoustic field fluctuations have time scales from {{less than a minute}} to hours, and horizontal spatial scales from tens of meters (as short as a few wavelengths at our lowest frequencies) to kilometers, and thus impact exploitation of underwater sound. OBJECTIVES An overarching objective is to explain observed sound fluctuation behavior in environments with three-dimensional structure at all significant scales. For the shallow-water ocean environment, the objective is to develop knowledge of factors controlling acoustic field mean and variability (both transmission loss and phase) at frequencies from 50 to 3000 Hz. For the deep-ocean sound channel, the objective is to better characterize coupled-mode propagation at 50 to 100 Hz, which may have som...|$|E
40|$|We study various {{temporal}} correlation {{functions of}} a tagged particle in one-dimensional systems of interacting point particles evolving with Hamiltonian dynamics. Initial {{conditions of the}} particles are chosen from the canonical thermal distribution. The correlation functions are studied in finite systems, and their forms examined at short and long times. Various one-dimensional systems are studied. Results of numerical simulations for the Fermi-Pasta-Ulam chain are qualitatively similar to results for the harmonic chain, and agree unexpectedly well with a simple description in terms of linearized equations for damped <b>fluctuating</b> <b>sound</b> waves. Simulation results for the alternate mass hard particle gas reveal that - in contradiction to our earlier results [1] with smaller system sizes - the diffusion constant slowly converges to a constant value, {{in a manner consistent}} with mode coupling theories. Our simulations also show that the behaviour of the Lennard-Jones gas depends on its density. At low densities, it behaves like a hard-particle gas, and at high densities like an anharmonic chain. In all the systems studied, the tagged particle was found to show normal diffusion asymptotically, with convergence times depending on the system under study. Finite size effects show up at time scales larger than sound traversal times, their nature being system-specific. Comment: 15 pages, 12 figure...|$|E
40|$|Propagation {{of traffic}} noise {{in a city}} is a complex phenomenon, due to {{multiple}} reflection, diffraction, and scattering at irregular facades of buildings. These effects may be calculated with computer models based on numerical integration of the basic acoustic equations, but in practice these models can be applied only to small urban regions due to limited computer power. Here we propose a new approach for simulating urban traffic noise: a cellular automaton (CA) based on simple update rules for the configuration of cars in a city, and simple rules for propagation of sound to receivers. An example is presented for a square model city of 25 km 2, consisting of 10 6 square cells. The CA employs a time integration step of 0. 3 s, and includes noise contributions from all cars in the city. The <b>fluctuating</b> <b>sound</b> level is computed {{for a period of}} 24 h, both for a receiver along a street and for a receiver that is screened by buildings. While the sound level at the first receiver shows sharp peaks corresponding to passages of cars, the sound level fluctuations at the screened receiver are much smaller as most of the sound energy comes from distant cars in this case...|$|E
5000|$|Top 50 ARIA hit [...] "Psychoactive Summer" [...] is {{exemplary}} of Def FX's music, combining {{elements of}} electronica and heavy-metal instrumentations and grunge vocals. Their music throughout their career {{can be described}} as a fusion of elements of psychedelia, industrial, grunge, electronica, and heavy metal, and in their early days, even reggae and disco. In <b>fluctuating</b> degrees their <b>sound</b> has similarities to that of, Cliff Burton-era Metallica, Soundgarden, Jesus Jones, The Prodigy, INXS, Garbage, Rammstein, 1990s Wollongong grunge band Tumbleweed, Marilyn Manson, and especially Evanescence. Basha and Horne reformed Def FX for touring in 2012 and 2013.|$|R
5000|$|This cricket {{is mainly}} nocturnal. The males rub their wings {{together}} (stridulation) {{to produce a}} subtle but constant, <b>fluctuating</b> in volume <b>sound.</b> They sing from about five o'clock until {{three o'clock in the}} morning. After mating, the female lays her eggs in plant stems, especially in grape (Vitis vinifera). In June the nymphs live in the tissue and leaves of the plant. A few days after the last molt the male begins to sing. These crickets are omnivorous and usually feed on leaves or delicate flower parts such as pollen and petals, but also on animal foods such as aphids, spiders and insect larvae.|$|R
40|$|Flow and {{acoustic}} {{properties of}} a jet at Reynolds number of 70, 000 were studied at Mach 2. 1. Measurements {{in a free}} jet test facility were made with pitot tubes and hot-wire anemometry. Center-line Mach number distributions for natural and excited jets were obtained. A slow initial growth rate was in the potential core region of the jet, indicating a transition from laminar to turbulent flow in moderate Reynolds number jets. The transition occurred within the first 2 - 3 diameters. Spectral components were calculated for the <b>fluctuating</b> flowfield, and <b>sound</b> pressure levels were measured for the overall near-field noise. The centroid of noise was located about 8 nozzle diameters downstream. The growth rates of instabilities were determined to be in agreement with linear stability theory predictions over a broad frequency range...|$|R
40|$|In {{previous}} work a RANS based simulation technique for the simulation of broadband slat noise was established. Good agreement {{was found between}} predicted and measured slat noise spectra. These predictions were based on 2 D CAA computations and a connection to 3 D measured data is only possible assuming a certain functional behavior of the spanwise coherence of the essential slat noise source. For this purpose, results from trailing edge noise measurements were used. In this work the simulation strategy is extended to 3 D CAA computations, resolving the spanwise slat noise coherence {{as part of the}} CAA computations. The considered wing span is one main-chord, which is large enough to establish a realistic 3 D problem for the turbulence {{as well as for the}} sound radiation. The Fast Random Particle Mesh (FRPM) method is applied for this study to generate <b>fluctuating</b> <b>sound</b> sources from steady RANS turbulence statistics. The study is conducted for the 30 P 30 N airfoil with 0. 457 m main chord. The Mach number is 0. 17 and the angle of attack is 4 ∘. Good agreement is found between the previous 2 D and the 3 D results as well as with unsteady simulations published in the literature. The influence of sweep on slat noise generation is studied...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedDuring {{the summer of}} 1995, a multi-institutional field study called Shallow-Water Acoustic Random Medium (SWARM) was conducted in the Mid-Atlantic Bight continental shelf region {{off the coast of}} New Jersey. Environmental and acoustic sensors were deployed as part of SWARM to measure and characterize the internal waves and their impact on the spatial and temporal coherence of the acoustic transmissions. As part of the environmental monitoring network, two bottom-moored, upward-looking acoustic Doppler current profilers (ADCPs) were deployed. Large-amplitude, non-linear, internal soliton wave packets were observed to propagate shoreward from the shelfbreak. Based on the ADCP observations, a kinematic model of the soliton wave packets was developed to synthesize the corresponding temporal and spatial fluctuations in the sound-speed field. Using a coupled normal-mode sound propagation model and the synthesized sound speed variations, the variability of sound pressure and of the modal amplitudes for a 224 Hz CW transmission were simulated. The auto and cross-correlations of sound pressure at different depths, and of the modal amplitudes at a fixed range, were computed in an effort to estimate the vertical and temporal scales of the <b>fluctuating</b> <b>sound</b> field. The simulation method, the simulated acoustic variability as well as the results of the correlation analysis are presented and discussed in this report[URL] Republic of Singapore Nav...|$|E
40|$|Traditionally, {{long term}} {{measurements}} of atmospherically propagated sound signals have consisted of time series of multiminute averages. Only recently have continuous measurements with temporal resolution corresponding to turbulent time scales been available. With modern digital data acquisition systems {{we now have}} the capability to simultaneously record both acoustical and meteorological parameters with sufficient temporal resolution to allow us to examine in detail relationships between <b>fluctuating</b> <b>sound</b> and the meteorological variables, particularly wind and temperature, which locally determine the acoustic refractive index. The atmospheric acoustic propagation medium can be treated as a nonlinear dynamical system, a kind of signal processor whose innards depend on thermodynamic and turbulent processes in the atmosphere. The atmosphere is an inherently nonlinear dynamical system. In fact one simple model of atmospheric convection, the Lorenz system, may well be the most widely studied of all dynamical systems. In this paper we report some results of our having applied methods used to characterize nonlinear dynamical systems to study the characteristics of acoustical signals propagated through the atmosphere. For example, we investigate {{whether or not it is}} possible to parameterize signal fluctuations in terms of fractal dimensions. For time series one such parameter is the limit capacity dimension. Nicolis and Nicolis were among the first to use the kind of methods we have to study the properties of low dimension global attractors...|$|E
5000|$|The {{automatic}} algorithms {{are capable}} of detecting and tracking many contacts simultaneously. Were the Diver Detection sonar systems to rely strictly on the echograph generated by the sonar units overlaid on a navigation chart, then a diver or SDV would appear as a relatively small moving shape that is refreshed with each transmission or ping of the sonar against a <b>fluctuating</b> background of <b>sound</b> clutter and reverberation. The operator would have to recognize the shape and judge if it represents a threat calling for further action or not. This is problematic in {{that they would have}} to be highly trained sonar operators. For this reason, commercial DDS systems use automation to simplify the sonar display by suppressing the echograph and displaying only the chart and detection and tracking information.|$|R
40|$|Audio {{technology}} and contemporary sonic environments have affected perceptual habits at {{both individual and}} communal levels. As the perception of <b>sound</b> <b>fluctuates</b> between modes of attention and inattention, the narrative expectations generated by sonic materials may follow patterns of individual physical response that would in turn modify some communal perceptions of environmental soundscapes, silences in particular. In current sound design practice and the mainstream movie industry, the use of absolute silence as an absence of sound seems almost irrelevant. Film silence has become the complex technical product of mixing sounds, a view that departs from silence as a broad sound element added to vocal enunciation, music and special sound effects. As a subtle component of a narrative, cinematic silence {{may be at the}} junction of representation and reproduction of the acoustic biomass that we create and communicate to others. This paper examines how the subjective enaction of audio-filmic silence could develop from evolving acoustic ecologies, corporeal integration and cultural convention. In such a context, film silence could be a reciprocal tool that may generate modes of expression used to assess our personal and communal notions of environmental silences...|$|R
40|$|Many natural <b>sounds</b> <b>fluctuate</b> over time. The {{detectability}} {{of sounds}} {{in a sequence}} can be reduced by prior stimulation in {{a process known as}} forward masking. Forward masking is thought to reflect neural adaptation or neural persistence in the auditory nervous system, but it has been unclear where in the auditory pathway this processing occurs. To address this issue, the present study used a "Huggins pitch" stimulus, the perceptual effects of which depend on central auditory processing. Huggins pitch is an illusory tonal sensation produced when the same noise is presented to the two ears except for a narrow frequency band that is different (decorrelated) between the ears. The pitch sensation depends on the combination of the inputs to the two ears, a process that first occurs {{at the level of the}} superior olivary complex in the brainstem. Here it is shown that a Huggins pitch stimulus produces more forward masking in the frequency region of the decorrelation than a noise stimulus identical to the Huggins-pitch stimulus except with perfect correlation between the ears. This stimulus has a peripheral neural representation that is identical to that of the Huggins-pitch stimulus. The results show that processing in, or central to, the superior olivary complex can contribute to forward masking in human listeners...|$|R
40|$|Restricted Access. An open-access {{version is}} {{available}} at arXiv. org (one of the alternative locations) We study various temporal correlation functions of a tagged particle in one-dimensional systems of interacting point particles evolving with Hamiltonian dynamics. Initial conditions of the particles are chosen from the canonical thermal distribution. The correlation functions are studied in finite systems, and their forms examined at short and long times. Various one-dimensional systems are studied. Results of numerical simulations for the Fermi–Pasta–Ulam chain are qualitatively similar to results for the harmonic chain, and agree unexpectedly well with a simple description in terms of linearized equations for damped <b>fluctuating</b> <b>sound</b> waves. Simulation results for the alternate mass hard particle gas reveal that—in contradiction to our earlier results (Roy et al. in J Stat Phys 150 (5) : 851 – 866, 2013) with smaller system sizes—the diffusion constant slowly converges to a constant value, {{in a manner consistent}} with mode coupling theories. Our simulations also show that the behaviour of the Lennard–Jones gas depends on its density. At low densities, it behaves like a hard-particle gas, and at high densities like an anharmonic chain. In all the systems studied, the tagged particle was found to show normal diffusion asymptotically, with convergence times depending on the system under study. Finite size effects show up at time scales larger than sound traversal times, their nature being system-specific...|$|E
40|$|The {{long-term}} {{goal is to}} better understand <b>fluctuating</b> <b>sound</b> propagation in two distinct ocean acoustic regimes: Stratified shallow water, where sound is highly bottom interacting, and the temperate deep-ocean sound channel. Acoustic field fluctuations have time scales varying from {{less than a minute}} to hours, and horizontal spatial scales from tens of meters to kilometers, comparable to processing time scales and system spatial scales, and thus impact exploitation of underwater sound. With proper understanding, reliable predictions of temporal and spatial variability of received underwater sound may be possible, thus improving processing and handling of signals of interest. Processing could include remediation of signal degradation and exploitation of available sonic information. OBJECTIVES An objective is to explain underwater sound fluctuation behavior that has been observed in both shallow and deep regimes. For shallow water, we seek to understand the mean and variability of transmission loss and phase at frequencies from 50 to 3000 Hz. For the deep-ocean sound channel, the objective is to better characterize coupled-mode propagation at 50 to 100 Hz over 100 ’s to 1000 ’s of kilometers. Propagation and forward scattering models, theoretical and computational, will be used to generate and to test hypotheses. Therefore, making better models is a second (enabling) objective. APPROACH The planned approach for the three-year project includes analysis of acoustic propagation variability signatures in preexisting datasets and comparison of these signatures with expectations derived from theory and models. Part of the final year will be dedicated to the planning of a potential future experiment to address questions that remain unanswered by this effort. Data from multiple recent field exercises have been analyzed. For shallow water studies, data ar...|$|E
40|$|It is {{estimated}} that 26 {{million people in the}} United States alone aged 20 to 70 suffer from hearing loss of a sensorineural nature due to exposure to loud sounds at work or leisurely activities. People suffering from sensorineural hearing loss (SNHL) face difficulty in perceiving speech when competing sounds are present (e. g. in a restaurant or a bar). SNHL is often treated with prosthetic devices such as hearing aids and/or cochlear implants. Despite recent advances in these prosthetic devices, listeners continue to face difficulty perceiving speech in noise. ^ Speech and other complex sounds can be mathematically separated into rapidly varying temporal fine structure (TFS) and slowly varying envelope components. Recent perceptual studies have shown that poor speech intelligibility experienced by hearing-impaired listeners in degraded listening conditions is associated with their reduced ability to use TFS cues. These results have fueled an active debate about the role of TFS and envelope coding in normal and impaired hearing and have important implications for improving the ability of hearing aids and cochlear implants to restore speech perception in noise. However, these implications depend critically on the underlying physiological (neural) bases for these perceptual deficits. ^ The present study thoroughly characterized neural coding of envelope and TFS in normal and impaired auditory systems. Spike trains were recorded from auditory-nerve (AN) fibers in chinchillas with either normal-hearing or a noise-induced SNHL. Within- and across-fiber temporal coding (i. e., phase locking) to a broad range of stimuli was quantified. In contrast to common assumptions, our data suggest that SNHL does not degrade the fundamental ability of AN fibers to phase lock to either TFS or envelope. ^ Rather, several other effects of SNHL were observed that may contribute to perceptual deficits in the temporal processing of complex stimuli like speech. For example, (1) envelope coding was enhanced following SNHL, which may over-emphasize <b>fluctuating</b> background <b>sounds,</b> e. g., competing talkers, (2) across-fiber estimates of traveling-wave delays were reduced significantly, and (3) larger than expected shifts in the best frequency of excitation were observed, resulting in a disruption of the normal tonotopic map. Overall, this work demonstrates that perceptual TFS deficits do not result from a simple reduction in the temporal-coding ability of AN fibers, but rather are more likely due to neural response properties that are relevant for complex stimuli and that are not currently accounted for in hearing-aid and cochlear-implant signal processing strategies. ...|$|R
40|$|Water structures, for example, fountains, {{are common}} design {{elements}} in urban open public spaces. Their popularity is probably explained by their visual attractiveness. Less {{is known about}} how the sounds of water struc-tures influence the urban soundscape. This thesis explores the potential ef-fects of water sounds on urban soundscapes based {{on the character of}} water sounds. Three psychoacoustic studies were conducted in which listeners rated the perceptual properties of various water sounds. Study I found that water sounds had a limited ability to mask traffic noise, as the frequency composition of the sounds resulted in road-traffic noise masking fountain sounds more than the reverse. A partial loudness model of peripheral audito-ry processes overestimated the observed masking effect of water sound on road-traffic noise, and it was suggested that this was related to central pro-cesses, in particular, target/masker confusion. In Study II, water sounds of different degrees of perceived pleasantness were mixed with road-traffic noise to explore the overall effect on soundscape quality. The overall pleas-antness was increased substantially by adding a highly pleasant water sound; however, less pleasant water sounds had no effect or even reduced overall pleasantness. This result suggests that the perceptual properties of water-generated sounds should be taken into consideration in soundscape design. In Study III, this was explored by analyzing a large set of recordings of sounds of water fountains in urban open spaces. A multidimensional scaling analysis of similarity sortings of sounds revealed distinct groups of percep-tually different fountain sounds. The group of pleasant fountain sounds was characterized by relatively low loudness and high fluctuation strength and tonality, generating purling and rippling sounds. The group of unpleasant fountain sounds was characterized by high loudness and low fluctuation strength and tonality, generating a steady-state like noisy sound [...] A joint result of all three studies is that sounds from water structures with a high flow rate (i. e., a large jet and basin in Study I, a waterfall in Study II, and large fountains in Study III) generating a steady-state noisy sound should be avoided in soundscape design. Instead, soundscape design might better focus on more <b>fluctuating</b> water <b>sounds,</b> which were considered more pleasant in both studies II and III. A general conclusion from this thesis is that water-generated sounds may be used to improve the soundscape, but that great care must be taken in selecting the type of water sound to use. At the time of the doctoral defense, the following paper was unpublished and had a status as follows: Paper 3 : Manuscript. </p...|$|R
40|$|AbstractThe {{increased}} use of renewable energy sources in Continental Europe, in particular Germany, {{has led to a}} great variability in power production and prices. One proposed way to remedy the Continent's power balance – which is also economically viable in a free power market – is by the means of Norwegian pumped storage. However, the profitability in such an environment is highly dependent upon the extent of price variation in the market. In this paper, it has therefore been sought to find a stochastic price model in which the spot price is allowed to <b>fluctuate</b> around a <b>sound</b> forecast. With historical data from the German power market as the point of departure, a deterministic price curve with seasonal and daily patterns has been obtained through linear regression. This curve has been adjusted to the market expectations contained in power futures contracts. By contrasting the updated deterministic price curve with the actual spot price, it has been possible to obtain a time series model on the basis of deviations that are mainly stochastic. The time series model has been used to generate multiple spot price scenarios that serve as an input for a representative Norwegian pumped storage power station. Simulations show that both the power station's production planning and revenues are dependent on which scenario that is under consideration. Nonetheless, the production patterns under both the different scenarios and the real spot price are comparable, in particular with regards to the daily and weekly patterns. Similarly, the total profits depend on the variance of the price scenarios, but all scenarios, including the actual spot price, has been shown to yield significant revenues...|$|R
40|$|The {{influence}} of individual temporal portions of a level-fluctuating noise on global annoyance judgments {{was measured using}} perceptual weight analysis (cf. Berg, 1989). For loudness judgments {{it has been found}} that listeners attach greater weight to the beginning and the ending than to the middle of a stimulus (e. g. Oberfeld & Plank, 2005). Similar weights were expected for annoyance. Annoyance and loudness judgments were obtained from 12 listeners for the same stimuli in a two-interval forced-choice task. The results demonstrated a primacy effect for the temporal weighting of both annoyance and loudness. A recency effect was observed only for annoyance, although the temporal weights for loudness and annoyance were only marginally significantly different. A control experiment showed that the listeners were capable of independently judging the stimuli according to either their loudness or their annoyance: Noises with the same energy-equivalent level but different modulation depths were judged to differ in annoyance but not in loudness. Several different measures for assessing the annoyance of longer <b>sounds</b> <b>fluctuating</b> in level have been proposed (e. g. N 5, Leq or LA; cf. Zwicker & Fastl, 1999). These measures take into account parameters such as sound pressure level and frequency spectrum. However, the temporal aspect has not received much consideration in these calculations until now. Conventional measures assume that listeners weight the information provided by each temporal segment of a noise uniformly. The present study examined whether this approach is compatible with the perception of annoyance or whether temporal aspects should be considered in the estimation of annoyance. For loudness it has already been found that if listeners evaluate the overall loudness of a level fluctuating noise, the initial and final portions of the stimulus receive greater weigh...|$|R
5000|$|Billie Joe Armstrong {{had said}} the {{following}} about the trilogy: Each of the three albums has a totally different vibe. [...] "The first one is power pop. The second is more garage-y, Nuggets-type rock. And the third {{is supposed to be}} epic. With the first album you're getting in the mood to party. On the second one, you're at the party. And the third album you're cleaning up the mess." [...] ¡Tré! will be geared more towards stadium rock and will have more of a grandiose sound complete with string arrangements and brass sections. He also {{went on to say that}} the mood of ¡Tré! will be [...] "reflective" [...] and explained the album would be a [...] "mixed bag" [...] with the <b>sound</b> <b>fluctuating</b> from the punk rock feel of Dookie and Insomniac, the experimental elements of Nimrod and Warning and finishing with the stadium rock/rock opera sound taken from American Idiot and 21st Century Breakdown. While musically, Rob Cavallo said that [...] "They wanted to return to the simplicity of Dookie." [...] "We also wanted to go pre-Dookie, back to our love of Fifties and Sixties music, close-to-the-bone rock and roll. You don't hear a gazillion parts. The majority of this is drums, bass, two guitars and vocals." [...] Frontman Billie Joe also stated that ¡Tre! would be the most ambitious album of the trilogy. He has also stated the following of the album's opening track: [...] "Brutal Love", which marries glam rock, doo-wop and soul music, includes swelling strings at its conclusion." [...] "Dirty Rotten Bastards" [...] is Green Day “going all over the place”, according to Billie Joe. “It’s an arena song then a sing-along and it takes off. We wanted to make something similar to [...] "Jesus of Suburbia" [...] (off American Idiot) or a b-side off The Beatles’ Abbey Road.|$|R
40|$|Communication often {{occurs in}} environments where {{background}} <b>sounds</b> <b>fluctuate</b> and mask {{portions of the}} intended message. Listeners use envelope and periodicity cues to group together audible glimpses of speech and fill in missing information. When the background contains other talkers, listeners also use focused attention to select the appropriate target talker and ignore competing talkers. Whereas older adults are known to experience significantly more difficulty with these challenging tasks than younger adults, the sources of these difficulties remain unclear. In this project, three related experiments explored the effects of aging on several aspects of speech understanding in realistic listening environments. Experiments 1 and 2 determined {{the extent to which}} aging affects the benefit of envelope and periodicity cues for recognition of short glimpses of speech, phonemic restoration of missing speech segments, and/or segregation of glimpses with a competing talker. Experiment 3 investigated effects of age on the ability to focus attention on an expected voice in a two-talker environment. Twenty younger adults and 20 older adults with normal hearing participated in all three experiments and also completed a battery of cognitive measures to examine contributions from specific cognitive abilities to speech recognition. Keyword recognition and cognitive data were analyzed with an item-level logistic regression based on a generalized linear mixed model. Results indicated that older adults were poorer than younger adults at glimpsing short segments of speech but were able use envelope and periodicity cues to facilitate phonemic restoration and speech segregation. Whereas older adults performed poorer than younger adults overall, these groups did not differ in their ability to focus attention on an expected voice. Across all three experiments, older adults were poorer than younger adults at recognizing speech from a female talker both in quiet and with a competing talker. Results of cognitive tasks indicated that faster processing speed and better visual-linguistic closure were predictive of better speech understanding. Taken together these results suggest that age-related declines in speech recognition may be partially explained by difficulty grouping short glimpses of speech into a coherent message, which may be particularly difficult for older adults when the talker is female...|$|R

