107|471|Public
50|$|Dolby SVA matrix is the {{original}} name of the Dolby Stereo 4:2:4 <b>encoding</b> <b>matrix.</b>|$|E
5000|$|RCA Photophone, a variable-area format now universally {{used for}} optical analog soundtracks—since the late 1970s, usually with a Dolby <b>encoding</b> <b>matrix.</b>|$|E
5000|$|The term [...] "Dolby Surround" [...] {{refers to}} both the {{encoding}} and decoding in the home environment, while in the theater it is known [...] "Dolby Stereo", [...] "Dolby Motion Picture matrix" [...] or [...] "Dolby MP"."Pro Logic" [...] refers to the decoder used, there is no special Pro Logic <b>encoding</b> <b>matrix.</b>|$|E
50|$|The various <b>encoding</b> <b>matrixes</b> are {{described}} below.|$|R
30|$|Next, we {{introduce}} {{a method to}} construct the minimal trellis for systematic recursive convolutional <b>encoding</b> <b>matrices.</b>|$|R
3000|$|... }. A basic {{generator}} matrix G(D) {{is called}} minimal-basic if the overall constraint length ν is minimal over all equivalent basic <b>encoding</b> <b>matrices.</b>|$|R
5000|$|... where [...] We {{consider}} the source as having [...] input edges carrying the [...] vectors [...] By induction, one has that the vector [...] on any edge is a linear combination [...] {{and is a}} vector in [...] The k-dimensional vector [...] is simply the first k coordinates of the vector [...] We call the matrix whose rows are the vectors , where [...] are the incoming edges for a vertex , the global <b>encoding</b> <b>matrix</b> for [...] and denote it as [...] In practice the encoding vectors are chosen at random so the matrix [...] is invertible with high probability. Thus any receiver, on receiving [...] can find [...] by solving ...|$|E
40|$|The authors {{review the}} work of G. D. Forney, Jr., on the {{algebraic}} structure of convolutional encoders upon which some new results regarding minimal convolutional encoders rest. An example is given of a basic convolutional <b>encoding</b> <b>matrix</b> whose number of abstract states is minimal over all equivalent encoding matrices. However, this <b>encoding</b> <b>matrix</b> can be realized with a minimal number of memory elements neither in controller canonical form nor in observer canonical form. Thus, this <b>encoding</b> <b>matrix</b> is not minimal according to Forney's definition of a minimal encoder. To resolve this difficulty, the following three minimality criteria are introduced: minimal-basic <b>encoding</b> <b>matrix,</b> minimal <b>encoding</b> <b>matrix,</b> and minimal encoder. It is shown that all minimal-basic encoding matrices are minimal and that there exist minimal encoding matrices that are not minimal-basic. Several equivalent conditions are given for an <b>encoding</b> <b>matrix</b> to be minimal. It is proven that the constraint lengths of two equivalent minimal-basic encoding matrices are equal one by one up to a rearrangement. All results are proven using only elementary linear algebr...|$|E
40|$|Abstract-This semitutorial paper {{starts with}} a review of some of Fomey’s {{contributions}} on the algebraic structure of convolutional encoders on which some new results on minimal convolutional encoders rest. An example is given of a basic convolutional <b>encoding</b> <b>matrix</b> whose number of abstract states is minimal over all equivalent encoding matrices. However, this <b>encoding</b> <b>matrix</b> can be realized with a minimal number of mem-ory elements neither in controller canonical form nor in observer canonical form. Thus, this <b>encoding</b> <b>matrix</b> is not minimal accord-ing to Fomey’s definition of a minimal encoder. To resolve this difficulty, the following three minimality criteria are introduced: minimal-basic e n d k g mutrix (minimal overall constraint length over equivalent basic e n c d i matrices), minimal encoding mu-trix (minimal number of abstract states over equivalent encoding matrices), and minimal encoder (realization of a minimal <b>encoding</b> <b>matrix</b> with a minimal number of memory elements over all realizations). Among other results, it is shown that all minimal-basic encoding matrices are minimal, but that there exist (basic) minimal encoding matrices that are not minimal-basic! Several equivalent conditions are given for an <b>encoding</b> <b>matrix</b> to be minimal. It is also proven that the constraint lengths of two equivalent minimal-basic encoding matrices are equal one by one up to a rearrangement. All results are proven using only elementary h e a r algebra. Most important among the new results are a simple minimality test, the surprising fact that there exist basic encoding matrices that are minimal but not minimal-basic, the existence of basic encoding matrices that are nonminimal, and a recent result, due to Fomey, that states exactly when a basic <b>encoding</b> <b>matrix</b> is minimal. Index Terms- Convolufional code, basic <b>encoding</b> <b>matrix,</b> minimal-bask <b>encoding</b> <b>matrix,</b> minimal <b>encoding</b> <b>matrix,</b> minimal encoder, I...|$|E
3000|$|Graell i Amat et al.[1] {{tabulated}} good k × (k + 1) <b>encoding</b> <b>matrices</b> Gsys(D) {{to be used}} as component encoders {{of parallel}} concatenated turbo codes. We search for good (with respect to the pair (d [...]...|$|R
40|$|Distributed storage {{systems are}} {{becoming}} more and more popular with the rapidly increasing demand for large-scale data storage. To increase the capacity and I/O performance of a distributed storage system, scaling it up is a common method. Regenerating Codes are a class of distributed storage codes that offer good reliability through encoding and provide good bandwidth cost on failed nodes repairing. This paper studies the scaling problem of E-MSR codes based distributed storage systems with fixed number of redundancy codes. We generate the <b>encoding</b> <b>matrices</b> of an storage system carefully from the <b>encoding</b> <b>matrices</b> of an storage system to minimize the changes of encoded blocks when scaling. Therefore the system can be scaled up with relatively low bandwidth cost and computation cost...|$|R
3000|$|... {{are their}} multiplicities, and thus suited {{to be used}} as {{constituent}} encoders of turbo codes[5]. Good systematic recursive <b>encoding</b> <b>matrices</b> with increasing values of encoder memory sizes for a fixed code rate are listed. Turbo codes constructed with the family of constituent encoders given in[1] are shown to outperform some high-rate turbo codes obtained by puncturing a rate- 1 / 2 constituent encoder.|$|R
3000|$|Let Gsys(D) be a {{systematic}} recursive <b>encoding</b> <b>matrix</b> for a rate R = k/n convolutional code and let q(D) {{be the least}} common multiple of all denominators of the entries in Gsys(D). We construct a nonsystematic nonrecursive basic <b>encoding</b> <b>matrix,</b> denoted by G [...]...|$|E
3000|$|From G sys(D), use the Smith form {{decomposition}} {{procedure to}} obtain the basic nonsystematic nonrecursive <b>encoding</b> <b>matrix</b> G [...]...|$|E
30|$|We {{present a}} method to {{construct}} the minimal trellis for a recursive systematic convolutional <b>encoding</b> <b>matrix.</b> Such a trellis minimizes the trellis complexity measure introduced by McEliece and Lin[6], which applies to trellis-based decoding algorithms. As a contribution of this work, several new convolutional encoding matrices having an equivalent systematic recursive <b>encoding</b> <b>matrix,</b> optimized for turbo codes, are tabulated. They provide {{a wide range of}} performance-complexity trade-offs, to serve several practical applications.|$|E
3000|$|... of the D-STBC matrix. All of A_n_ℓ and B_n_ℓ (n_ℓ= 1... N_ 0) are {{characterized}} by the D-STBC matrix and are used to construct the code in a distributive manner (see Appendix Appendix 1 : Example STBC <b>encoding</b> <b>matrices)</b> [11, 29]. It {{is worth noting that}} many existing D-STBC matrix can be used, given the number of relays and the extent of the diversity gain required (N [...]...|$|R
40|$|Computational ghost imaging is {{a robust}} and compact {{system that has}} drawn wide attentions {{over the last two}} decades. Multispectral imaging {{possesses}} spatial and spectral resolving abilities, is very useful for surveying scenes and extracting detailed information. Existing multispectral imagers mostly utilize narrow band filters or dispersive optical devices to separate lights of different wavelengths, and then use multiple bucket detectors or an array detector to record them separately. Here, we propose a novel multispectral ghost imaging method that uses one single bucket detector with multiplexed illumination to produce colored image. The multiplexed illumination patterns are produced by three binary <b>encoded</b> <b>matrices</b> (corresponding to red, green, blue colored information, respectively) and random patterns. The results of simulation and experiment have verified that our method can be effective to recover the colored object. Our method has two major advantages: one is that the binary <b>encoded</b> <b>matrices</b> as cipher keys can protect the security of private contents; the other is that multispectral images are produced simultaneously by one single-pixel detector, which significantly reduces the amount of the data acquisition...|$|R
40|$|Abstract—We {{consider}} a {{time division duplex}} (TDD) nt × nr multiple-input multiple-output (MIMO) system with known channel state information (CSI) at both transmitter and receiver. Using singular value decomposition (SVD) precoding at the transmitter, the MIMO channels are transformed into parallel subchannels. To improve the low diversity order, we propose X- and Y-Codes, prior to SVD precoding, to pair subchannels having different diversity orders. Specifically, a pair of channels is jointly encoded using a 2 × 2 real matrix, which is fixed a priori and does not change with each channel realization. Moreover, we propose X-, Y-Precoders with the same <b>encoding</b> <b>matrices</b> as X-, Y-Codes, which adapt to each channel realization. The optimal <b>encoding</b> <b>matrices</b> for X- and Y-Codes/Precoders are derived analytically to minimize the average error probability. Finally, we see that X-, Y-Codes/Precoders indeed achieve higher diversity gains at very low encoding/decoding complexity for both well- and ill-conditioned channels, respectively, {{when compared to other}} precoding schemes in the literature. We also observe that for the Rayleigh fading channel model X- and Y-Codes/Precoders exhibit the best average error performance. Index Terms—TDD MIMO, precoding, SVD, diversity I...|$|R
40|$|Abstract—This paper {{deals with}} Fountain codes, and {{especially}} with their encoding matrices, which are required {{here to be}} invertible. A result is stated that an <b>encoding</b> <b>matrix</b> induces a permutation. Also, a result is that encoding matrices form a group with multiplication operation. An encoding is a transformation, which reduces the entropy of an initially high-entropy input vector. A special <b>encoding</b> <b>matrix,</b> with which the entropy reduction {{is more effective than}} with matrices created by the Ideal Soliton distribution is formed. Experimental results with entropy reduction are shown. Index Terms—Entropy-reducing transformation, Fountain codes, group, Ideal Soliton distribution, permutation...|$|E
40|$|This paper {{presents}} a speech enhancement method using non-negative matrix factorization. In training phase, we can obtain each basis matrix from speech and specific noise database. After training phase, the noisy signal {{is separated from}} the speech and noise estimate using basis matrix in enhancement phase. In order to improve the performance, we model the change of <b>encoding</b> <b>matrix</b> from training phase to enhancement phase using independent Gaussian distribution models, and then use the constraint of the objective function almost {{same as that of}} the above Gaussian models. Also, we perform a smoothing operation to the <b>encoding</b> <b>matrix</b> by taking into account previous value. Last, we apply the Log-Spectral Amplitude type algorithm as gain function...|$|E
40|$|Despite the {{linearity}} of its encoding, compressed sensing (CS) {{may be used}} {{to provide}} a limited form of data protection when random encoding matrices are used to produce sets of low-dimensional measurements (ciphertexts). In this paper, we quantify by theoretical means the resistance of the least complex form of this kind of encoding against known-plaintext attacks. For both standard CS with antipodal random matrices and recent multiclass encryption schemes based on it, we show how the number of candidate encoding matrices that match a typical plaintext-ciphertext pair is so large that the search for the true <b>encoding</b> <b>matrix</b> inconclusive. Such results on the practical ineffectiveness of known-plaintext attacks underlie the fact that even closely related signal recovery under <b>encoding</b> <b>matrix</b> uncertainty is doomed to fail. Practical attacks are then exemplified by applying CS with antipodal random matrices as a multiclass encryption scheme to signals such as images and electrocardiographic tracks, showing that the extracted information on the true <b>encoding</b> <b>matrix</b> from a plaintext-ciphertext pair leads to no significant signal recovery quality increase. This theoretical and empirical evidence clarifies that, although not perfectly secure, both standard CS and multiclass encryption schemes feature a noteworthy level of security against known-plaintext attacks, therefore increasing its appeal as a negligible-cost encryption method for resource-limited sensing applications...|$|E
40|$|In {{this paper}} unequal error-correcting {{capabilities}} of convolutional codes are studied. State-transition graphs {{are used for}} investigating the error-correcting capabilities for specific inputs or outputs of given convolutional <b>encoding</b> <b>matrices.</b> Active burst input- and output-distances are defined and shown to be generalizations of the active burst distance. These new distances provide better estimates of the error-correction capability, especially when we communicate close to or above the channel capacity and they {{are connected to the}} corresponding free input- and output-distances via lower bound...|$|R
40|$|International audienceWe {{describe}} a type {{system for the}} linear-algebraic lambda-calculus. The type system accounts for the linear-algebraic aspects of this extension of lambda-calculus: {{it is able to}} statically describe the linear combinations of terms that will be obtained when reducing the programs. This gives rise to an original type theory where types, {{in the same way as}} terms, can be superposed into linear combinations. We prove that the resulting typed lambda-calculus is strongly normalising and features a weak subject reduction. Finally, we show how to naturally <b>encode</b> <b>matrices</b> and vectors in this typed calculus...|$|R
40|$|AbstractSome models schemes of Fourier and Fresnel {{quantized}} protective holograms {{with visual}} effects are suggested. The condition {{to arrive at}} optimum relationship between the quality of reconstructed images, and the coefficient of data reduction about a hologram, and quantity of iterations in the reconstructing hologram process has been estimated through computer model. Higher protection level is achieved by means of greater number both bi-dimensional secret keys (more than 2128) in form of pseudorandom amplitude and phase <b>encoding</b> <b>matrixes,</b> and one-dimensional <b>encoding</b> key parameters for every image of single-layer or superimposed holograms...|$|R
30|$|The rest of {{this article}} is {{organized}} as follows. In Section 2, we introduce some basic definitions and notations. Section 3 introduces the minimal trellis construction for a systematic recursive convolutional <b>encoding</b> <b>matrix.</b> In Section 4, we present search code results. Section 5 concludes the article.|$|E
40|$|In this work, the {{conventional}} back-projection technique is extended for reconstructing sensitivity-encoded radial MRI. The generalized <b>encoding</b> <b>matrix</b> (GEM) is inverted by conjugate-gradient (CG) iteration, with matrix-vector multiplication performed by projection and back-projection. The feasibility of this novel method {{is demonstrated by}} simulation and MRI experiments...|$|E
30|$|It {{remains to}} show that the minimal trellis in Figure 1 with the {{systematic}} convention is the minimal trellis for the systematic recursive convolutional <b>encoding</b> <b>matrix</b> Gsys(D) in (6). We note that the generator matrices G(D) given in (8) and Gsys(D) in (6) are equivalent in the sense that both generate the same code. Therefore, except for the edge convention, the two trellises are exactly the same. Assuming that the information bits at the input of the encoder associated with Gsys(D) and the information bits associated with the minimal trellis in Figure 1 occupy the same positions, the systematic convention is unique. Consequently, the trellis in Figure 1 with the systematic convention in the first three sections is the minimal trellis for the systematic recursive convolutional <b>encoding</b> <b>matrix</b> Gsys(D) in (6).|$|E
40|$|Under reviewWe {{describe}} a type {{system for the}} linear-algebraic lambda-calculus. The type system accounts for the linear-algebraic aspects of this extension of lambda-calculus: {{it is able to}} statically describe the linear combinations of terms that will be obtained when reducing the programs. This gives rise to an original type theory where types, {{in the same way as}} terms, can be superposed into linear combinations. We prove that the resulting typed lambda-calculus is strongly normalising and features a weak subject reduction. Finally, we show how to naturally <b>encode</b> <b>matrices</b> and vectors in this typed calculus...|$|R
2500|$|Segment 7 <b>encodes</b> two <b>matrix</b> {{proteins}} (M1 and M2) {{by using}} different reading frames {{from the same}} RNA segment. About 3000 matrix protein molecules are needed to make one virion.|$|R
40|$|Erasure {{codes are}} {{employed}} by disk systems to tolerate failures. They are typi-cally characterized by bit-matrices {{that are used}} for encoding and decoding. The efficiency of an erasure code using a bit-matrix {{is directly related to}} the number of exclusive-or (XOR) operations required during the encoding pro-cess. Thus, a problem within the field of erasure coding is how to schedule the XOR operations for any given bit-matrix so that the fewest number of XOR operations are required. This paper develops an algorithm for finding the op-timum solution and analyzes the performance of two known heuristics on a set of <b>encoding</b> <b>matrices...</b>|$|R
40|$|Abstract — We {{optimize}} linear space-time {{codes for}} the case when the receiver uses successive cancellation decoding. Specifically, the proposed codes minimize the perfect cancellation bound on word error probability, which assumes error-free cancellation of previously detected symbols. Assuming perfect cancellation, we prove that to minimize the error probability in each stage of decoding, the <b>encoding</b> <b>matrix</b> must have orthogonal columns, regardless of the channel matrix. Given the <b>encoding</b> <b>matrix,</b> {{the average of the}} perfect cancellation bound over the random channel matrix serves as an upper bound on word error probability. The bound is minimized by numerically optimizing the distribution of data rate and energy among the various inputs to the space-time code. Simulation results for a 4 -input, 4 -output Rayleigh fading channel show that, at 12 b ⁄ s ⁄ Hz, optimizing the data rate and energy allocations for a linear complex field code leads to a performance improvement of nearly 9 dB. I...|$|E
40|$|The {{sensitivity}} of recovery algorithms {{with respect to}} a perfect knowledge of the <b>encoding</b> <b>matrix</b> is a general issue in many application scenarios in which compressed sensing is an option to acquire or encode natural signals. Quantifying this sensitivity in order to predict the result of signal recovery is therefore valuable when no a priori information can be exploited, e. g., when the <b>encoding</b> <b>matrix</b> is randomly perturbed without any exploitable structure. We tackle this aspect by means of a simplified model for the signal recovery problem, which enables the derivation of an average performance estimate that depends only on the interaction between the sensing and perturbation matrices. The effectiveness of the resulting heuristic is demonstrated by numerical exploration of signal recovery under three simple perturbation matrix models. Finally, we show how this estimate matches very well the degradation experienced by non-perfectly informed decoders in applications of compressed sensing to protecting the acquired information content in ECG tracks and sensitive images...|$|E
30|$|The {{construction}} of the “minimal” trellis for the systematic recursive convolutional <b>encoding</b> <b>matrix</b> Gsys(D) involves two main steps. First, we find the minimal trellis of an equivalent nonsystematic nonrecursive minimal-basic generator matrix in LR form. Then, the mapping between the information bits and coded bits in this trellis is changed in order to construct a systematic minimal trellis. The complete algorithm is summarized {{in the end of}} this section.|$|E
2500|$|Pythagorean triples can {{likewise}} be <b>encoded</b> into a <b>matrix</b> of {{the form}} ...|$|R
3000|$|... −  1) bit per pixel (bpp). Based on the <b>matrix</b> <b>encoding,</b> Zhang et al. (2007) {{proposed}} the “Hamming+ 1 ” scheme in 2007. Compared with the <b>matrix</b> <b>encoding</b> scheme, it used one more cover pixel to embed one more bit while the cost remain unchanged. Thus, the embedding capacity got increased to be (k +  1)/ 2 [...]...|$|R
40|$|We {{consider}} a {{time division duplex}} (TDD) n_t × n_r multiple-input multiple-output (MIMO) system with channel state information (CSI) at both the transmitter and receiver. We propose X- and Y-Codes to achieve high multiplexing and diversity gains at low complexity. The proposed precoding schemes are based upon the singular value decomposition (SVD) of the channel matrix which transforms the MIMO channel into parallel subchannels. Then X- and Y-Codes are used to improve the diversity gain by pairing the subchannels, prior to SVD precoding. In particular, the subchannels with good diversity are paired with those having low diversity gains. Hence, a pair of channels is jointly encoded using a 2 × 2 real matrix, which is fixed a priori and does not change with each channel realization. For X-Codes these matrices are 2 -dimensional rotation matrices parameterized by a single angle, while for Y-Codes, these matrices are 2 -dimensional upper left triangular matrices. The complexity of the maximum likelihood decoding (MLD) for both X- and Y-Codes is low. Specifically, the decoding complexity of Y-Codes {{is the same as}} that of a scalar channel. Moreover, we propose X-, Y-Precoders with the same structure as X-, Y-Codes, but the <b>encoding</b> <b>matrices</b> adapt to each channel realization. The optimal <b>encoding</b> <b>matrices</b> for X-, Y-Codes/Precoders are derived analytically. Finally, it is observed that X-Codes/Precoders perform better for well-conditioned channels, while Y-Codes/Precoders perform better for ill-conditioned channels, when compared to other precoding schemes in the literature...|$|R
