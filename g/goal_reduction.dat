18|1224|Public
50|$|The TANF {{program does}} not offer {{benefits}} sufficient to lift recipients out of poverty, and despite a strong economy, the majority of families who have moved off the TANF rolls have remained in poverty. Considerations of another traditional economic <b>goal,</b> <b>reduction</b> of inequality, only makes matters worse. Welfare reform has coincided with massive growth in income and wealth disparities; it {{has done little to}} slow the expansion of inequality and may have actually accelerated the trend. Has welfare reform created job opportunities for the poor? Has it promoted wages that allow low-wage workers to escape poverty? In both of these areas, the economic story remains the same: we have little evidence that reform has produced achievements that warrant the label of success.|$|E
40|$|We {{describe}} {{a model to}} exploit data parallelism present in associative computers for efficient execution of logic programs on associative supercomputers. We present an alternate scheme for logical structure representation which naturally interfaces lists and vectors on associative computers for efficient integration of symbolic and numerical computation on existing associative supercomputers. We also propose a scheme for efficient data parallel <b>goal</b> <b>reduction</b> which is almost independent of number of clauses. The data parallel <b>goal</b> <b>reduction</b> scheme efficiently pruns non unifiable clauses and performs binding of variables with single occurrence in goal and the clauses. The data parallel model reduces the cost of shallow backtracking, deep backtracking and detrailing significantly. The independence of parallel <b>goal</b> <b>reduction</b> scheme from number of clauses has been demonstrated by experimental results...|$|E
40|$|A {{model is}} {{presented}} {{which is designed}} to exploit data parallelism present in associative computers for the efficient execution of logic programs. Data parallel model allows efficient handling of very large knowledge bases. A scheme for logical data structure representation incorporating direct interface between lists and vectors is described which allows the efficient integration of symbolic and numerical computation on existing associative supercomputers. An algorithm for data parallel <b>goal</b> <b>reduction</b> which is almost independent of number of clauses is discussed. The associative <b>goal</b> <b>reduction</b> scheme efficiently prunes non-uni able clauses and performs data parallel binding of variables with single occurrence. The association property in the model effectively reduces the cost of shallow backtracking, deep backtracking, and garbage collection...|$|E
5000|$|Complete {{eradication}} of drunk driving {{is not the}} expected outcome. The <b>goal</b> is <b>reduction.</b>|$|R
50|$|The 197th Infantry Brigade was {{deactivated}} on December 13, 2013 {{in order}} that the U.S. Army would reach manning <b>goals</b> through <b>reductions</b> in the force.|$|R
5000|$|Provides {{authority}} for adopting mitigation actions {{to achieve the}} <b>reduction</b> <b>goal</b> ...|$|R
40|$|AbstractA {{well-known}} {{problem with}} PROLOG-style interpreters that perform <b>goal</b> <b>reduction</b> {{is the possibility}} of entering an infinite recursion, due to a subgoal being “essentially the same” as one of its ancestors. This is informally called a “loop”. We describe the tortoise-and-hare technique for detecting such loops. This technique has low overhead: a constant amount of time and space per <b>goal</b> <b>reduction</b> step. Therefore it should be practical to incorporate into high-performance interpreters. We discuss the special considerations needed for correct implementation in an interpreter that uses tail-recursion optimization. The issue of what to do when a loop or potential loop has been detected has been investigated elsewhere. We review these results, and conclude that loop detection is probably more useful as a debugging tool than as an extension {{to the power of the}} language...|$|E
40|$|Associative Computation is {{characterized}} by intertwining of search by content and data parallel computation. An algebra for associative computation is described. A compilation based model and a novel abstract machine for associative logic programming are presented. The model uses loose coupling of left hand side of the program, treated as data, and right hand side of the program, treated as low level code. This representation achieves e ciency by associative computation and data alignment during <b>goal</b> <b>reduction</b> and during execution of low level abstract instructions. Data alignment reduces the overhead of data movement. Novel schemes for associative manipulation of aliased uninstantiated variables, data parallel <b>goal</b> <b>reduction</b> in presence of multiple occurrences of the same variables in a goal, and data parallel computations on abstract data structures such as bags, sequences, and sets are described. The architecture, behavior, and performance evaluation of the model are presented...|$|E
40|$|Artificial Intelligence is a {{field that}} has {{attracted}} much attention in the last century. Humans are fascinated {{by the possibility of}} creat-ing beings that can act and think on their own. This paper developes the concept of production systems, a very popular way of representing an agent’s model of thinking. Production systems are based on sim-ple condition-action rules and they can be used to implement foward reasoning and <b>goal</b> <b>reduction</b> with relative simplicity. The article will explain all these concepts in detail. ...|$|E
5000|$|... #Subtitle level 4: Beam with fixed dimensions; <b>goal</b> is weight <b>reduction</b> ...|$|R
5000|$|Achieving Oakland’s 2020 GHG <b>Reduction</b> <b>Goal</b> {{will require}} {{unprecedented}} action to address {{all three of}} the major sources of GHG emissions: Transportation & Land Use, Building Energy Use, Material Consumption & Waste. For the purpose of developing the draft ECAP, Oakland's 36% GHG <b>reduction</b> <b>goal</b> is applied to each of these three categories of GHG emission sources: ...|$|R
5000|$|A {{shared vision}} for {{long-term}} cooperative action, including a long-term global <b>goal</b> for emission <b>reductions.</b>|$|R
40|$|A {{model is}} {{presented}} which exploits data level massive parallelism present in associative computers for the e cient execution of logic programs with large knowledge bases. The exploitation of data parallelism in <b>goal</b> <b>reduction</b> e ciently prunes non-uni able clauses resulting into e ective reduction of shallow backtracking, and marks the potential bindings for the variables with single occurrence {{in a manner}} which is independent {{of the number of}} clauses. During deep backtracking, bindings are released simultaneously using associative search resulting in a signi cant reduction in execution time overhead of backtracking and garbage collection. Ascheme for a logical data structure representation incorporating direct interface between lists and vectors is described. This allows the e cient integration of symbolic computation and a large class of vectorizable numerical computation on associative supercomputers...|$|E
30|$|Schuller et al. (2012) {{presented}} an integrated approach based on Integer Linear Programming (ILP) and simulation {{to address the}} SSP for complex workflows in conjunction with stochastic QoS parameters. The idea is to account for penalty cost, due to SLA violations, during the service selection process {{in order to reduce}} the impact of stochastic QoS behavior on total cost. The first two approaches of our work share the same <b>goal,</b> <b>reduction</b> of total costs of providing a composite cloud service, and a similar iterative service selection process with the work in (Schuller et al. 2012). However, our approaches consider both service usage costs and SLA violation penalties in the service adaptation step, and thus are more effective than the method in (Schuller et al. 2012) regarding total cost reduction.|$|E
40|$|This paper {{shows the}} use of partial-order program clauses and lattice domains for {{declarative}} programming. This paradigm is particularly useful for expressing concise solutions to problems from graph theory, program analysis, and database querying. These applications are characterized by a need to solve circular constraints and perform aggregate operations, a capability that is very clearly and efficiently provided by partial-order clauses. We present a novel approach to their declarative and operational semantics, {{as well as the}} correctness of the operational semantics. The declarative semantics is model-theoretic in nature, but the least model for any function is not the classical intersection of all models, but the greatest lower bound/least upper bound of the respective terms defined for this function in the different models. The operational semantics combines top-down <b>goal</b> <b>reduction</b> with memo-tables. In the partial-order programming framework, however, memoization is primarily nee [...] ...|$|E
5000|$|China {{is going}} global to satisfy energy {{security}} needs {{and to meet}} emission <b>reduction</b> <b>goals</b> ...|$|R
5000|$|Substantial weight {{reduction}} {{to within}} 5 to 10 {{percent of the}} vehicle weight <b>reduction</b> <b>goal</b> ...|$|R
50|$|Definition - climate {{legislation}} which mandates emissions <b>reduction</b> <b>goals</b> by particular dates, {{long term}} and mid-term.|$|R
40|$|Many real-life {{problems}} {{belong to}} the class of constraint satisfaction problems (CSP's), which are NP-complete, and some NP-hard, in general. When the problem size grows, it becomes difficult to program solutions and to execute the solution in a timely manner. In this paper, we present a general framework for integrating artificial neural networks and logic programming so as to provide an efficient and yet expressive programming environment for solving CSP's. To realize this framework, we propose PROCLANN, a novel constraint logic programming language. The PROCLANN language retains the simple and elegant declarative semantics of constraint logic programming. Operationally, PROCLANN uses the standard <b>goal</b> <b>reduction</b> strategy in the frontend to generate constraints, and an efficient backend constraint-solver based on artificial neural networks. Its operational semantics is probabilistic in nature. We show that PROCLANN is sound and weakly complete. A novelty of PROCLANN is that while it i [...] ...|$|E
40|$|Many real-life {{problems}} {{belong to}} the class of constraint satisfaction problems (CSP), which are NP-complete, and some NP-hard, in general. When the problem size grows, it becomes difficult to program solutions and to execute the solution in a timely manner. In this paper, we present a novel constraint logic programming language PROCLANN {{that is expected to}} handle CSP in the order {{of hundreds of thousands of}} variables and constraints. The syntax of PROCLANN is similar to that of Flat GHC. PROCLANN uses the standard <b>goal</b> <b>reduction</b> strategy as frontend to generate constraint and an efficient backend constraint-solver based on artificial neural network. PROCLANN retains the simple and elegant declarative semantics of constraint logic programming. Its operational semantics is probabilistic in nature but it possesses the soundness and probabilistic completeness results. A novelty of PROCLANN is that while it is a committed-choice language, PROCLANN supports non-determinism, [...] ...|$|E
40|$|This paper {{presents}} the TPCALP framework, a theorem-proving approach {{which aims to}} unify Abductive Logic Programming (ALP), Constraint Logic Programming (CLP) and Semantic Query Optimization (SQO). The framework combines the use of definitions, as in ordinary logic programming, {{with the use of}} integrity constraints, as in ALP and SQO. The programmer can choose to represent knowledge in either form subject to the condition that the integrity constraints be "properties" of the definitions. The paper defines a proof procedure for the framework and presents some formal results for the proof procedure with respect to the framework semantics. The proof procedure executes definitions in conventional logic programming <b>goal</b> <b>reduction</b> manner, and integrity constraints in forward reasoning style to check potential answers for consistency. The integrity constraints are used to process goals when the definitions cannot be used, either because they are not accessible (as in ALP and SQO) or because t [...] ...|$|E
5000|$|Corporation {{and other}} {{entities}} can prepare greenhouse gas inventories to track progress towards meeting an emission <b>reduction</b> <b>goal.</b>|$|R
40|$|Paper {{focusing}} on {{open educational resources}} (OERs) at UCT. OER initiatives have moved from a fringe activity to a key component in both teaching and learning in higher education and in the fulfilling the universities' mission and <b>goals.</b> <b>Reduction</b> {{in the cost of}} materials is yet to be realised in practice make it necessary to consider various strategies for new OER initiatives e. g. the OpenContent directory at UCT. This paper reviews the range of sustainability strategies mentioned in the literature, plots the results of a small-scale OER sustainability survey against these strategies and explains how these findings and other papers on OER initiatives were used to inform an in-house workshop at UCT to deliberate the future strategy for the sustainability of OER at UCT...|$|R
40|$|This article {{deals with}} the {{problems}} of oil and gas activities of the enterprise in the field of environmental management and implementation of the program of industrial environmental monitoring control of «Tomskgazprom». Principles of activity aimed to economic growth with the rational use of natural resources and preservation of the environment were analyzed (by JSC «Tomskgazprom»). Identified and justified task senior representative for EMS management, confirming that each employee understands the environmental policy and act in accordance with the EMS documents. On the basis of the research that the author has evaluated the environmental management system of JSC "Tomskgazprom" and showed its efficiency. JSC «Tomskgazprom» company has demonstrated the ability of EMS to achieve the commitments of environmental policy and <b>goals,</b> <b>reduction</b> of pollutant emissions...|$|R
40|$|This paper {{describes}} work on applying AI {{planning methods}} to generate human body motion {{for the purpose}} of animation. It is {{based on the fact that}} although we do not know how the body actually controls massively redundant degrees of freedom of its joints and moves in given situations, the appropriateness of specific behavior for particular conditions can be axiomatized at a gross level using commonsensical observations. Given the motion axioms (rules), the task of the planner is to find a discrete sequence of intermediate postures of the body via <b>goal</b> <b>reduction</b> reasoning based on the rules along with a procedure to discover specific collision-avoidance constraints, such that any two consecutive postures are related via primitive motions of the feet, the pelvis, the torso, the head, the hands, or other body parts. Our planner also takes account of the fact that body motions are continuous by taking advantage of execution-time feedback. Planning decisions are made in the task space where our elementary spatial intuition is preserved as far as possible, only dropping down to a joint space formulation typical in robot motion planning when absolutely necessary. We claim that our work is the first serious attempt to use an AI planning paradigm for animation of human body motion...|$|E
40|$|Many agent-oriented {{programming}} {{languages are}} based on the Prolog-like logical <b>goal</b> <b>reduction</b> approach where rules are used to reduce, in a depth-first way, a selected goal. The ability of agents to change between goals means that such languages often overlay the basic computational engine with a mechanism for dynamically changing which goal is selected. Our approach is different. The basic computational approach we use is that of model building for logical formulae, but the underlying formulae are temporal. This allows us to capture the dynamic nature of the agent explicitly. In addition, the temporal basis provides us with ways of having multiple active ‘goals ’ and being able to achieve several at once. As in most agent-oriented languages deliberation is used to choose between goals when not all can be satisfied at once. This basic execution of temporal formulae provides us with the foundation for agent programming. In order to deal with multi-agent systems in an equally straightforward way we also incorporate a very simple, but flexible, model of organisational structuring. These two aspects provide the core of the language implemented. There are, however, many extensions that have been proposed, some of which have been implemented, and all of which are mentioned in this article. These include varieties of agent belief, resourcebounded reasoning, the language’s use as a coordination language, and the use of contextual constraints...|$|E
40|$|AbstractThis paper {{shows the}} use of partial-order program clauses and lattice domains for {{declarative}} programming. This paradigm is particularly useful for expressing concise solutions to problems from graph theory, program analysis, and database querying. These applications are characterized by a need to solve circular constraints and perform aggregate operations, a capability that is very clearly and efficiently provided by partial-order clauses. We present a novel approach to their declarative and operational semantics, {{as well as the}} correctness of the operational semantics. The declarative semantics is model-theoretic in nature, but the least model for any function is not the classical intersection of all models, but the greatest lower bound/least upper bound of the respective terms defined for this function in the different models. The operational semantics combines top-down <b>goal</b> <b>reduction</b> with memo-tables. In the partial-order programming framework, however, memoization is primarily needed in order to detect circular circular function calls. In general we need more than simple memoization when functions are defined circularly in terms of one another through monotonic functions. In such cases, we accumulate a set of functional-constraints and solve them by general fixed-point-finding procedure. In order to prove the correctness of memoization, a straightforward induction on the length of the derivation will not suffice {{because of the presence of}} the memo-table. However, since the entries in the table grow monotonically, we identify a suitable table invariant that captures the correctness of the derivation. The partial-order programming paradigm has been implemented and all examples shown in this paper have been tested using this implementation...|$|E
50|$|An {{electric}} powered tug {{is being}} {{considered as a}} way for the Navy to reach its 2020 fossil fuel <b>reduction</b> <b>goals.</b>|$|R
40|$|Macromastia is {{a health}} problem that {{requires}} the coordination of surgical and medical specialists. <b>Goals</b> of <b>reduction</b> mammaplasty are to alleviate physical, emotional and psychosocial discomforts and to restore a conical-shaped breast, maintaining scars as short as possible. We report our approach for reduction mammaplasty with superior pedicle...|$|R
5000|$|... 2007 - Passed Climate Change Integration Act, setting {{greenhouse}} gas <b>reduction</b> <b>goals</b> for Oregon into statute and established statewide Global Warming Commission ...|$|R
40|$|AbstractDimiter Skordev quite {{correctly}} {{points out}} a bug in the algorithm 1 described. The additional condition he proposes (the repeated goal must be a descendant) {{does not provide a}} real solution, as his last example proves. However, I cannot agree with his conclusion (last paragraph) that the main problem is “that only first subgoals are compared,” and offer the following two paragraphs in response. I believe that the basic idea in my paper is correct, but that my description of how to implement it went wrong. The important idea is that when the “hare” is at a node of depth d in the proof tree, the “tortoise” should be at depth ⌊d 2 ⌋ on the path from the root to the “hare. ” Equating depth in the proof tree to height in the stack is my mistake, as Skordev's counterexamples nicely show. The fix is conceptually straightforward. Popular Prolog interpreters already keep track of depth in the proof tree, as can be seen from trace output. The remaining problem is efficiently {{to keep track of the}} location in the stack of the ancestor at one-half this depth. Note that the “open” goals are the ancestors, and there is exactly one at each “proof-tree depth. ” The tortoise needs to follow along on “open” goals, skipping the “closed” ones. I believe that interpreters normally maintain a chain through ancestors in one direction only: from the current goal back to the top level. It would be necessary to make this a doubly linked chain (or some equivalent) to facilitate the tortoise's movement. The overhead per <b>goal</b> <b>reduction</b> is still constant but somewhat greater than my erroneous published scheme...|$|E
40|$|After a brief {{historical}} {{introduction to}} both Parallel Logic Programming and Intelligent Backtracking history, this thesis concerns itself with forms of applying search-space narrowing techniques to the Extended Andorra Model and genetically related computational models. The main motivation {{is to achieve}} a higher overall performance for Logic Programming {{through the use of}} these two general approaches. The most relevant original contributions of this thesis are: A simple scheme for performing search-space pruning subsequent to <b>goal</b> <b>reduction,</b> in computational models based on and-or tree rewriting systems. This makes use of the failure information and can be seen as an application of the "first-fail" principle, achieving an improvement over the system it's based on of the order of up to 60 % in number of inferences. This scheme displays pathological behaviors on a sizable class of programs, due to its inherent lack of accuracy. An improved scheme, Seam, which is an abstract system for maintaining a dependency graph over a constraint domain, used for search-space pruning through goal re-ordering and the preservation of independent computations. This overcomes the limitations of the first one. It is shown to be exhaustive and non-redundant in its traversal of the search space. A model for Logic Programming system consisting of three components: the Inference Engine, the Constraint Solver and the Hypothesis Engine. Because of its generality, it can be coupled with several execution models, but is especially adequate to the Extended Andorra Model, as well as Kernel Andorra Prolog and its offspring. An application of the Seam scheme to the Andorra Kernel Language, thereby exhibiting its suitability for this execution model. Two prototypes based on the Sics K L / Ps sequential implementation, centering on a modified abstract machine. These implementations are used to test and validate the design and its feasibility, as well as the various compromises madeAvailable from Fundacao para a Ciencia e a Tecnologia, Servico de Informacao e Documentacao, Av. D. Carlos I, 126, 1249 - 074 Lisboa, Portugal / FCT - Fundação para o Ciência e a TecnologiaSIGLEPTPortuga...|$|E
40|$|The United Nation`s fifth Millennium <b>Goal,</b> <b>reduction</b> of {{maternal}} mortality, is significantly lagging behind schedule. Worldwide, approximately 600, 000 mothers {{die each year}} in complications due to pregnancy and childbirth. In emergency obstetrics, the caesarean section is a key measure used to reduce {{a large number of}} complications due to pregnancy and delivery. The concern has been the availability of surgical care in developing countries. Average caesarean section rates vary between 0. 4 %­­­— 40 %, unlike WHO`s recommended 5 — 15 %. There is socio-demographical distribution in caesarean section rates within countries. Also the overuse of caesarean sections can be seen in some areas. This Master`s thesis studies the distribution of caesarean sections according to socio-demographic factors in Mozambique. The data used was population—based data from years 1994 — 1997 and 1998 — 2003 from Demographic Health Survey (DHS). Mother`s age, parity, and educational level, partner´s educational level, wealth index and residential area were examined as socio-demographical factors. According to this study, the socio-demographic factors are related to the incidence of caesarean sections in Mozambique. The connection was found by carrying out cross tabulations, Pearson`s χ 2 - tests and logistic regression analyses. In 1994 — 1997 age group and parity were associated with incidence of caesarean sections when adjusted with all confounders. The older the mother was, the higher was the risk of a caesarean section. Women having their first child had caesarean section more often than women having at least their second or third child. People living in urban areas more likely receive a caesarean section than those in rural areas. In 1998 — 2003, in addition to age, parity and area of residence, the study found the wealth index to be the strongly associated socio-demographic factor for caesarean section. Caesarean sections were more common among women who—or whose partners—were highly educated. Socio-demographical factors, especially parity, have stronger association in incidence of caesarean sections in subsequent time period. Even in Maputo, the capital of Mozambique, where the caesarean section rates were the highest in 1998 — 2003 (12. 9 %), the rate was slightly under the recommended upper limit of WHO. On the basis of this study {{it is not possible to}} draw final conclusions on overuse of caesarean sections. Key words: socio-demographic factors, caesarean section, Demographic Health Survey, Mozambiqu...|$|E
40|$|In {{preparation}} for a Climate Action Plan, this policy and practice audit {{provides an overview of}} current city policies and practices with the potential to impact greenhouse gas (GHG) emissions <b>reduction</b> <b>goals.</b> The audit builds upon information previously collected in a GHG emissions inventory report to identify policies that are consistent or inconsistent with emissions <b>reductions</b> <b>goals.</b> Preliminary GHG emissions reductions recommendations address policy gaps and opportunity areas in suggesting strategies to achieve GHG emissions reductions...|$|R
40|$|In {{this paper}} we use {{splitting}} technique {{to estimate the}} probability of hitting a rare but critical set by the continuous component of a switching diffusion. Instead of following classical approach we use Wonham filter to achieve multiple <b>goals</b> including <b>reduction</b> of asymptotic variance and exemption from sampling the discrete components...|$|R
3000|$|... [...]. In {{order to}} achieve the <b>goal</b> of {{complexity}} <b>reduction,</b> our approach is to devise a static quantization scheme of the feature space [...]...|$|R
