3|107|Public
50|$|As Communications Service Providers {{continue}} to deploy new network assets and technology at an increasingly rapid pace, achieving <b>feature</b> <b>transparency</b> becomes very challenging. The benefit {{of creating a}} solution to ensure <b>feature</b> <b>transparency</b> will provide subscribers application feature parity across multiple networks, enable the service providers to consolidate their application platforms and fully enable them to leverage their network assets to offer converged applications across ever evolving networks.|$|E
5000|$|Windows Vista Basic: This {{style has}} aspects {{that are similar}} to Windows XP's [...] "Luna" [...] visual style with the {{addition}} of subtle animations such as those found on progress bars. It does not employ the Desktop Window Manager, as such, it does not <b>feature</b> <b>transparency</b> or translucency, window animation, Windows Flip 3D or any of the functions provided by the DWM. The Basic mode does not require the new Windows Display Driver Model (WDDM) for display drivers, and has similar video card requirements to Windows XP. For computers with video cards that are not powerful enough to support Windows Aero, this is the default graphics mode. Prior to Service Pack 1, a machine that failed Windows Genuine Advantage validation would also default to this visual style.|$|E
40|$|Abstract. Quantitative histomorphometry is {{the process}} of {{modeling}} appearance of disease morphology on digitized histopathology images via image–based features (e. g., texture, graphs). Due to the curse of di-mensionality, building classifiers with large numbers of features requires feature selection (which may require a large training set) or dimension-ality reduction (DR). DR methods map the original high–dimensional features in terms of eigenvectors and eigenvalues, which limits the poten-tial for <b>feature</b> <b>transparency</b> or interpretability. Although methods exist for variable selection and ranking on embeddings obtained via linear DR schemes (e. g., principal components analysis (PCA)), similar methods do not yet exist for nonlinear DR (NLDR) methods. In this work we present a simple yet elegant method for approximating the mapping between the data in the original feature space and the transformed data in the ker-nel PCA (KPCA) embedding space; this mapping provides the basis for quantification of variable importance in nonlinear kernels (VINK). We show how VINK can be implemented in conjunction with the popular Isomap and Laplacian eigenmap algorithms. VINK is evaluated in the contexts of three different problems in digital pathology: (1) predict-ing five year PSA failure following radical prostatectomy, (2) predicting Oncotype DX recurrence risk scores for ER+ breast cancers, and (3) distinguishing good and poor outcome p 16 + oropharyngeal tumors. We demonstrate that subsets of features identified by VINK provide sim-ilar or better classification or regression performance compared to the original high dimensional feature sets. ...|$|E
50|$|MoSes: {{originally}} developed by Australia-based Classic Solutions which merged with Tillinghast in 2002, MoSes provides a single common platform for many financial models. MoSes <b>features</b> <b>transparency</b> in its calculations {{for ease of}} auditing.|$|R
50|$|One of the {{features}} of Audion that set it apart from its rivals, particularly SoundJam, was its user interface, which <b>featured</b> <b>transparency</b> through a process that mimicked the functionality of alpha channels on Mac OS 9's QuickDraw, a graphics system that did not support them.|$|R
5000|$|Steamed rice. In general, an {{appropriate}} requirement of steamed rice <b>features</b> softness, <b>transparency,</b> and no agglomeration.|$|R
40|$|This paper {{presents}} a robust watermarking method for 3 D data represented as NURBS. The mark is generated starting {{from a public}} message on 64 bits and from a secret information on 22 bits. The mark is embedded into the Discrete Cosine Transform (DCT) coefficients corresponding to the control points, {{by means of a}} spread spectrum technique. The detection procedure does not require the original (unmarked) data. The proposed method <b>features</b> <b>transparency</b> and robustness with respect to knot insertion/removal, degree elevation/reduction, geometric attacks, compression, linear and non-linear filtering, noise addition and multiplication. The probability of false alarm is lower than 16 - 14...|$|R
50|$|A {{technical}} glass material {{launched by}} Arc International in 2006, Kwarx is used solely for making glasses under the Chef&Sommelier brand. It <b>features</b> perfect <b>transparency</b> and a resistance to mechanical shocks and professional dishwashers. Kwarx {{is made in}} the Arc International headquarters factory in Arques, France.|$|R
5000|$|CoINs <b>feature</b> {{internal}} <b>transparency</b> {{and direct}} communication. Members of a COIN collaborate and share knowledge directly with each other, {{rather than through}} hierarchies. They come together with a shared vision because they are intrinsically motivated {{to do so and}} seek to collaborate in some way to advance an idea.|$|R
50|$|A {{technical}} glass material {{launched by}} Arc International in 2010, Diamax is used solely {{for all products}} under the Cristal d'Arques brand. Contrarily to crystal, Diamax doesn't include any lead, thus doesn't reproduce the sound of crystal. It <b>features</b> high <b>transparency,</b> Diamax {{is made in the}} Arc International headquarters factory in Arques, France.|$|R
50|$|WindShield {{is another}} audio <b>transparency</b> <b>feature</b> of Bragi OS that was {{introduced}} with version OS 2.2. When enabled, {{it reduces the}} sound of breeze under windy conditions, while still letting the user hear the surroundings.|$|R
5000|$|Windows Aero: The new {{graphical}} {{user interface}} is named Windows Aero, which Jim Allchin stated is an acronym for Authentic, Energetic, Reflective, and Open. Microsoft intended the new interface to be cleaner and more aesthetically pleasing than those of previous Windows versions, <b>featuring</b> new <b>transparencies,</b> live thumbnails, live icons, and animations, thus providing {{a new level of}} eye candy. Laptop users report, however, that enabling Aero shortens battery life and reduces performance.|$|R
50|$|InDesign exports {{documents}} in Adobe's Portable Document Format (PDF) and has multilingual support. It {{was the first}} DTP application to support Unicode for text processing, advanced typography with OpenType fonts, advanced <b>transparency</b> <b>features,</b> layout styles, optical margin alignment, and cross-platform scripting using JavaScript.|$|R
50|$|Level 2 PostScript adds no {{specific}} <b>transparency</b> <b>features.</b> However, {{by the use}} of patterns, arbitrary graphics can be painted through masks defined by any vector or text operations. This is, however, complex to implement. In addition, this too often reached implementation limits, and few if any application programs ever offered this technique.|$|R
50|$|In {{addition}} to being earphones, The Dash doubles as a Bluetooth Headset. Even though The Dash provides noise isolation, the wearer can choose to channel ambient sound into the headphone thanks to its audio <b>transparency</b> <b>feature.</b> With a swipe on the touch surface of The Dash, the user can enable or disable ambient sound to pass through.|$|R
40|$|To attract customers, firms offer {{personalized}} services. This {{is perceived}} beneficial by many customers as it enhances the purchase experience and addresses customers’ needs. However, to offer personalized services, customer data {{has to be}} collected and analyzed. This practice gives rise to privacy concerns and can inhibit the usage of such services. Our research aims to address the tension between personalization and privacy by applying information boundary theory to investigate how respondents’ disposition to value privacy {{and the availability of}} information <b>transparency</b> <b>features</b> influences individuals’ intention to disclose information to personalized services. Based on an experimental study, we find a significant interaction between disposition to value privacy and personalization, while the implementation of <b>transparency</b> <b>features</b> does not yield substantial changes in information disclosure. Thus, in order to successfully offer personalized services, we recommend that practitioners take individuals’ privacy preferences into account for their service design...|$|R
40|$|Pragmatic {{clinical}} trials (PCTs) {{are considered a}} valuable means to directly improve day-to-day patient care through the comparison of health interventions in real world conditions. Increasing pragmatism in clinical research, however, calls for departures from the well-controlled conditions that are typically required for randomized trials by ethical and regulatory bodies. Such requirements are believed to impact scientific validity, generalizability and operational feasibility. Advocates of more lenient ethical and regulatory requirements for PCTs reject the moral distinction between clinical research and care, and propose a transition to a learning health care system that continuously generates knowledge through routine practice. Such claims {{have led to the}} following question: what are the arguments supporting departures from current trial ethics regulations and how well do they hold once applied to different varieties of PCTs? In the literature, three arguments are commonly offered as necessary, justificatory conditions: (1) the PCT poses minimal risks, (2) the PCT does not violate patient expectations, and (3) the PCT is socially valuable and impracticable otherwise. Interpretation of these conditions is ambiguous and contested, though {{there seems to be some}} common ground for less stringent oversight practices for specific, selected examples of standard of care PCTs. Application of the conditions to other varieties of PCTs, however, demonstrates that making broad ethical assertions about PCTs in general is flawed due to the variability in morally salient <b>features.</b> <b>Transparency</b> to the public and stakeholder engagement are crucial for enabling those PCTs that hold promise to change real world health care the most...|$|R
5000|$|Since the album's {{original}} release, {{an official}} reissue of Ain't That Good News came nearly forty years following its initial 1964 release on LP format. The reissued compact disc {{copies of the}} album featured Super-Audio and Hybrid format, also known as Super High Material, which enhanced audio quality {{through the use of}} polycarbonate plastic. Using a process developed by JVC and Universal Music Japan and discovered through the joint companies' research of LCD display manufacturing, these CDs <b>featured</b> improved <b>transparency</b> on the data side of the disc, allowing for more accurate reading of the data by the CD player laser head. The reissues were fully compatible with standard CD players, and are listed below: ...|$|R
40|$|Botnets {{are one of}} {{the most}} serious threats to Internet {{security}} today. Modern botnets have complex infrastructures consisting of multiple components, which can be dynamically installed, updated, and removed at any time during the botnet operation. Tracking botnets is essential for understanding the current threat landscape. However, state- of-the-art analysis approaches have several limitations. Many malware analysis systems like sandboxes have a very limited analysis time-out, and thus only allow limited insights into the long-time behavior of a botnet. In contrast, customized tracking systems are botnet-specific and need to be adopted to each malware family, which requires tedious manual reverse engineering. In this paper, we present BotWatcher, a novel approach for transparent and generic botnet tracking. To this end, we leverage dynamic analysis and memory forensics techniques to execute the initial malware sample and later installed modules in a controlled environment and regularly obtain insights into the state of the analysis system. The key idea behind BotWatcher is that by reasoning about the evolution of system state over time, we can reconstruct a high-level overview of the botnet lifecycle, i. e., the sequence of botnet actions that caused this evolution. Our approach is generic since it relies neither on previous knowledge of the botnet nor on OS-specific <b>features.</b> <b>Transparency</b> is achieved by performing outside-OS monitoring and not installing any analysis tools in the analysis environment. We implemented BotWatcher for Microsoft Windows and Mac OS X (both 32 - and 64 -bit architectures), and applied it to monitor four botnets targeting Microsoft Windows. To the best of our knowledge, we are the first to present a generic, transparent, and fully automated botnet tracking system...|$|R
50|$|The second {{version of}} the VTP {{included}} some minor bug fixes, {{as well as new}} features. Some new <b>features</b> included window <b>transparencies</b> with Glass2k, fixes to the sidebar, more Vista-style icons and several other third-party applications to enhance the Vista feel of the pack. The update also included a new visual style with improved Vista effects. This version generally had the look of Windows Vista during its development around Build 5112.|$|R
30|$|Carbonaceous chondrites display large chondrules of Mg-rich olivine, which {{provides}} the most prominent bands of the Allende sample spectra (Fig.  1). The lack of well-shaped O–H stretching vibration bands between 2 and 3  µm suggests a low-grade alteration of the sample (Salisbury and Hunt 1974; Miyamoto 1988). Lack of H–O–H bending vibration at 6.1 micron in the spectra under vacuum precludes the presence of surface adsorbed water in the sample. Most of the vibrational bands observable between 8 and 16  µm appear strongly reduced in the vacuum emissivity spectrum {{with respect to the}} purged emissivity, due to thermal gradients in the sample (Logan and Hunt 1970) and to the weakening (disappearance in high vacuum) of the <b>transparency</b> <b>feature</b> in vacuum (Salisbury et al. 1991). On the other hand some overtones below 7  µm are more prominent with respect to the other spectra shown in Fig.  1. The deep emissivity minimum (comparable to the <b>transparency</b> <b>feature</b> of olivine) at 12.5  µm suggests a dominant surface scattering and confirms the fine grain size of the sample (Salisbury and Walter 1989; Mustard and Hays 1997).|$|R
40|$|International audienceExploiting spatial locality, a key {{technique}} for improving disk I/O utilization and performance, faces additional {{challenges in the}} virtualized cloud because of the <b>transparency</b> <b>feature</b> of virtualization. This paper contributes a novel disk I/O scheduling framework, named Pregather, to improve disk I/O efficiency through exposure and exploitation of the special spatial locality in the virtualized environment, thereby improving the performance of disk-intensive applications without harming the <b>transparency</b> <b>feature</b> of virtualization. The key idea behind Pregather is to implement an intelligent model to predict the access regularity of spatial locality for each VM. Moreover, Pregather embraces an adaptive time slice allocation scheme to further reduce the resource contention and ensure fairness among VMs. We implement the Pregather disk scheduling framework and perform extensive experiments that involve multiple simultaneous applications of both synthetic benchmarks and MapReduce applications on Xen-based platforms. Our experiments demonstrate the accuracy of our prediction model and indicate that Pregather results in the high disk spatial locality and a significant improvement in disk throughput and application performance...|$|R
40|$|Abstract—Exploiting spatial locality, a key {{technique}} for improving disk I/O utilization and performance, faces additional {{challenges in the}} virtualized cloud because of the <b>transparency</b> <b>feature</b> of virtualization. This paper contributes a novel disk I/O scheduling framework, named Pregather, to improve disk I/O efficiency through exposure and exploitation of the special spatial locality in the virtualized environment, thereby improving the performance of disk-intensive applications without harming the <b>transparency</b> <b>feature</b> of virtualization. The key idea behind Pregather is to implement an intelligent model to predict the access regularity of spatial locality for each VM. Moreover, Pregather embraces an adaptive time slice allocation scheme to further reduce the resource contention and ensure fairness among VMs. We implement the Pregather disk scheduling framework and perform extensive experiments that involve multiple simultaneous applications of both synthetic benchmarks and MapReduce applications on Xen-based platforms. Our experiments demonstrate the accuracy of our prediction model and indicate that Pregather results in the high disk spatial locality and a significant improvement in disk throughput and application performance. Index Terms—Virtualization, disk-intensive, I/O scheduling, spatial locality, efficiency...|$|R
40|$|Click on {{the link}} to access the article (may not be free). That {{recommendation}} agents (RAs) can substantially improve consumers' decision making is well understood. Far less understood is the influence of specific design attributes of the RA interface on decision making and other outcome measures. We investigate a novel design for an RA interface that enables it to interactively demonstrate trade-offs among product attribute values (i. e., trade-off <b>transparency</b> <b>feature)</b> to improve consumers' perceived product diagnosticity and perceived enjoyment. We also examine {{the extent to which}} the trade-offs among product attribute values should be revealed to the user. Further, based on the stimulus organism-response model, we develop a theoretical model that extends the effort-accuracy framework by proposing perceived enjoyment and perceived product diagnosticity as two antecedents for perceived decision quality and perceived decision effort, respectively. In an experimental study, we find that (1) the trade-off <b>transparency</b> <b>feature</b> significantly affects perceived enjoyment and perceived product diagnosticity, (2) perceived enjoyment and perceived product diagnosticity follow an inverted U-shaped curve as the level of trade-off transparency increases, (3) although users spend more time understanding attribute trade-offs with the trade-off <b>transparency</b> <b>feature,</b> they are more efficient in selecting a product, (4) perceived enjoyment simultaneously leads to better perceived decision quality and lower perceived decision effort, and (5) perceived product diagnosticity leads to better perceived decision quality without compromising perceptions of decision effort. Theoretically, this study increases our understanding of how the design of an RA interface can improve consumers' product diagnosticity and enjoyment, and proposes two antecedents to improve perceived decision quality and reduce perceived decision effort. For design practitioners, our results indicate the importance of providing the trade-off <b>transparency</b> design <b>feature</b> to potential consumers. The authors thank the Social Sciences and Humanities Research Council of Canada (SSHRC) for its support...|$|R
40|$|This paper {{examines}} {{the role of}} Automatic Fiscal Stabilizers (AFS) for stabilizing the cyclical fluctuations of macroeconomic output {{as an alternative to}} discretionary fiscal policy, admitting its huge potential of being an anti crisis solution. The objectives of the study are the identification of the general features of the concept of automatic fiscal stabilizers and the logical assessment of them from economic perspectives. Based on the literature in the field, this paper points out the disadvantages of fiscal discretionary policy and argue the need of using Automatic Fiscal Stabilizers in order to provide a faster decision making process, shielded from political interference, and reduced uncertainty for households and business environment. The paper conclude about the need of using fiscal policy for smoothing the economic cycle, but in a way which includes among its <b>features</b> <b>transparency,</b> responsibility and clear operating mechanisms. Based on the research results the present paper assumes that pro-cyclicality reduces de effectiveness of the Automatic Fiscal Stabilizer and as a result concludes that {{it is very important to}} avoid the pro-cyclicality in fiscal rule design. Moreover, by committing in advance to specific fiscal policy action contingent on economic developments, uncertainty about the fiscal policy framework during a recession should be reduced. Being based on logical analysis and not focused on empirical, contextualized one, the paper presents some features of AFS operating mechanism and also identifies and systematizes the factors which provide its importance and national individuality. Reaching common understanding on the Automatic Fiscal Stabilizer concept as a institutional device for smoothing the gap of the economic cycles across different countries, particularly for the European Union Member States, will facilitate efforts to coordinate fiscal policy responses during a crisis, especially in the context of the fiscal harmonization. The main result of this study is the developing of the definition of Automatic Fiscal Stabilizer...|$|R
25|$|Unlike most earlier display protocols, X was {{specifically}} designed to be used over network connections rather than on an integral or attached display device. X <b>features</b> network <b>transparency,</b> which means an X program running on a computer somewhere on a network (such as the Internet) can display its user interface on an X server running on some other computer on the network. The X server is typically the provider of graphics resources and keyboard/mouse events to X clients, meaning that the X server is usually running on the computer {{in front of a}} human user, while the X client applications run anywhere on the network and communicate with the user's computer to request the rendering of graphics content and receive events from input devices including keyboards and mice.|$|R
40|$|Journalism {{scholars}} and practitioners have repeatedly argued that transparency {{is crucial to}} generate trust in the news media, which, over the years, has faced continues decline in public trust. As news organizations have been encouraged to implement transparency in their daily work, transparency has increasingly gained {{the status of a}} professional norm in journalism. However, very little is actually known about how journalists think and apply transparency in their everyday practices or how news organizations in the United States implement transparency. Similarly, normative assumptions about the trust-generating effects of transparency have not been consistently shown to exist. This dissertation examined to what extent journalists at 12 national news outlets embraced transparency on a day-to-day basis and how these news organizations implement transparency online at the news item level. Moreover, this dissertation tested whether existing <b>features</b> of <b>transparency</b> (hyperlinks, editorial explanations, corrections, staff biographies etc.) impact audiences’ trust perception of a news story. The results of the mixed method approach showed that transparency in journalism is far from being a professional norm, which guides journalists’ news production processes. An analysis of 27 in-depth interviews found that journalists rarely consider transparency in their work. Journalists agreed that the notion of transparency has value. They repeatedly suggested that the news outlets they work for utilize transparency as a promotional tool to engage audiences and to appear transparent, rather than significantly disclosing information about the inner workings of their news organization. The results of the content analysis supported this claim as the findings show that the <b>transparency</b> <b>features</b> news organizations currently use provide little information for audiences to learn about how journalism is done. Meanwhile, the results of two experiments indicate that participants may not recognize the intended meanings of the varied <b>transparency</b> <b>features,</b> as participants’ trust perception did not vary across different transparency conditions. The findings of this dissertation suggest that transparency in journalism is still a goal rather than reality. News organizations have not opened up {{to the extent that they}} may be understood as transparent organizations; instead their efforts to pull back the curtain so that audiences may see the inner workings of newsrooms can be considered translucent at best...|$|R
40|$|Map transparency, {{probably}} {{extracted from}} a larger publication, of Australian sites established along the coastline of the Australian Antarctic Territory by ANARE expeditions {{in the period of}} 1959 - 1960. This map is also taped to another <b>transparency</b> <b>featuring</b> shaded areas only and, when superimposed on top of the first map transparency, shows those areas documented by K 17 Trimetrogon photography.; "NMP/ 60 / 197 " [...] Bottom left of first transparency.; Also available online [URL]...|$|R
50|$|On August 17, 2011, Kojima {{released}} {{a series of}} images on Twitter. The images were of facial tests created in the Fox Engine. In addition, during a lecture at the University of Southern California held by Hideo Kojima, an image was shown to various students in {{a demonstration of the}} Fox Engine's capabilities with a scene depicting a forest environment. Later, on December 16, Kojima released more images over Twitter, including one image showcasing cloth <b>transparency</b> <b>features.</b>|$|R
40|$|Millimeterwaves and {{terahertz}} sensors {{can cover}} a broad field of applications ranging from production control to security scanners. The outstanding <b>features</b> are the <b>transparency</b> of many materials like textiles, paper and plastics in this frequency region, the good contrast of any humid or dense dielectric {{material and the}} capability to employ miniaturized RF systems and small antenna apertures or dielectric probes. A stand-alone-millimetre-wave-imager, SAMMY, was developed and built, to demonstrate the outstanding features {{of this part of}} the electromagnetic spectrum for material inspection...|$|R
40|$|Abstract. The {{purpose of}} virtual {{computing}} environment {{is to improve}} resource utilization by providing a unified integrated operating platform for users and applications based on aggregation of heterogeneous and autonomous resources. With the rapid development in recent years, hypervisor technologies have become mature and comprehensive with four <b>features,</b> including <b>transparency,</b> isolation, encapsulation and manageability. In this paper, a hypervisor based virtual computing infrastructure, named CIVIC, is proposed. Compared with existing approaches, CIVIC may benefit in several ways. It offers separated and isolated computing environment for end users, and realizes hardware and software consolidation and centralized management. Beside this, CIVIC provides a transparent view to upper layer applications, by hiding the dynamicity, distribution and heterogeneity of underlying resources. Performance of the infrastructure is evaluated by an initial deployment and experiment. The result shows that CIVIC can facilitate installation, configuration and deployment of network-oriented applications. ...|$|R
40|$|Luminescent ionogels were {{prepared}} by doping an europium(III) tetrakis beta-diketonate complex into an imidazolium ionic liquid, followed by immobilization of the ionic liquid by confinement in a silica network. The ionogels {{were obtained by}} a non-hydrolytic method as perfect monoliths <b>featuring</b> both the <b>transparency</b> of silica and the ionic conductivity performances of ionic liquids. The ionogels contain 80 vol % of ionic liquid. The organic-inorganic hybrid materials showed a very intense red photoluminescence under ultraviolet irradiation. The red emission has a very high coloric purity. status: publishe...|$|R
40|$|Cluster systems built {{mainly from}} {{commodity}} hardware components {{have become more}} and more usable for high performance computing tasks in the past few years. To increase the parallelism for applications, it is often desirable to combine those clusters to a higher lever, commonly called metacomputer. This class of high performance computing platforms can be understood as a cluster of clusters, where each cluster provides different processors, memory performance, cluster interconnect and external networking facilities. Our project called MetaMPICH provides a transparent MPI- 1 implementation for those inhomogeneous cluster systems. While this <b>feature</b> of <b>transparency</b> makes porting existing MPI applications to metacomputers quite simple, the slowest network connection and the slowest processor will dominate the performance and scalability {{due to the lack of}} opacity. This paper describes our approaches to adapt iterative, grid based simulation algorithms to the structures of such heterogeneous coupled clusters. 1...|$|R
40|$|This study, {{supported}} by the ministry of Local Government and Regional development, maps {{the way in which}} Norwegian municipalities use ICT in local democracy. New information and communication technologies have been proclaimed as a solution to democratic problems in modern society. The Internet, it is argued, offers opportunities to reconnect people to the political process, by reinventing the old electoral chain of command, or by developing a more participatory democracy. This study looks into how local governments are using the Internet through a systematic examination of their Internet products, i. e. their web sites. The findings are sorted in two broad categories: citizen information, and interaction between citizens and local government. This includes <b>features</b> like <b>transparency,</b> email availability, and online debate possibilities. The study shows that digital practices diverge significantly among Norwegian municipalities. Some municipalities are pioneers while others are followers and stand Byers...|$|R
40|$|We {{present an}} {{architecture}} for a core dWDM network which utilizes {{the concept of}} Optical Burst Switching (OBS) coupled with a Just-In-Time (JIT) signaling scheme. It is a reservation based architecture whose distinguishing characteristics are its relative simplicity, its amenability to hardware implementation, support for quality of service and multicast natively. Another important <b>feature</b> is data <b>transparency</b> - the network infrastructure is independent of {{the format of the}} data being transmitted on individual wavelengths. In this article we present a brief overview of the architecture and outline the most salient features...|$|R
40|$|This {{collection}} of <b>transparencies</b> <b>features</b> materials for life science, earth science, and physical sciences. The transparencies are downloadable and printable, {{or can be}} viewed on-screen. Earth Science topics include plate tectonics and the Earth's structure; landforms and weathering; water, hydrology, and weather; and ecosystems and food webs. Life science topics include, among others, evolution and the Earth's history, and structure and function in living things. Physical science topics include motion, forces, and energy; sound and light; and electricity and magnetism. Educational levels: Primary elementary, Intermediate elementary, Middle school, High school...|$|R
