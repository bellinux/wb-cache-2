149|1272|Public
5000|$|... #Caption: On the left, an {{intensity}} {{image of a}} cat. In the center, a <b>gradient</b> <b>image</b> in the x direction measuring horizontal change in intensity. On the right, a <b>gradient</b> <b>image</b> in the y direction measuring vertical change in intensity. Gray pixels have a small gradient; black or white pixels have a large gradient.|$|E
5000|$|... video wipe transitions: bar, barn door, box, clock (radial), diagonal, iris, matrix, {{and custom}} <b>gradient</b> <b>image</b> ...|$|E
5000|$|... #Caption: Figure 3 : Binary Image {{gradient}} is done {{to reduce}} sensitivity to lighting conditions and page coloration, a Sobel operator {{is applied to the}} original images (a). The binary <b>gradient</b> <b>image</b> is produced by thresholding the absolute value of the output (b).|$|E
40|$|In {{this paper}} we propose a multi-scale edge {{detection}} algorithm based on proportional scale summing. Our analysis shows that proportional scale summing successfully improves edge detection rate by applying independent thresholds on multi-scale <b>gradient</b> <b>images.</b> The proposed method improves edge detection and localization by summing <b>gradient</b> <b>images</b> with a proportional parameter cn (c < 1); which ensures that the detected edges are {{as close as possible to}} the fine scale. We employ non-maxima suppression and thinning step similar to Canny edge detection framework on the summed <b>gradient</b> <b>images.</b> The proposed method can detect edges successfully and experimental results show that it leads to better edge detection performance than Canny edge detector and scale multiplication edge detector...|$|R
40|$|This paper {{presents}} how using a correspondence-based inter-polation {{scheme for}} 3 D image registration improves the reg-istration accuracy. The interpolator {{takes into account}} corre-spondences across slices, which is an advantage, particularly when the volume has thick slices, and where anatomies lie non-parallel to the slice direction. We use our previously pre-sented approach for correspondence-based interpolation and demonstrate results on two different datasets, brain and car-diac MRI. The results are evaluated (i) qualitatively by ex-amination of <b>gradient</b> <b>images</b> and cardiac pig atlases and (ii) quantitatively by registering downsampled brain data using two different interpolators and subsequently applying the de-formation fields to the original data. The {{results show that the}} interpolator provides better <b>gradient</b> <b>images</b> and a more sharp cardiac atlas. Moreover, it provides better deformation fields on downsampled data, increasing the registration accuracy of original data to 5. 8 % on average with respect to a standard interpolator. Index Terms â€” Image interpolation, <b>image</b> registration, <b>image</b> <b>gradient,</b> atlas, magnetic resonance imagin...|$|R
40|$|Summary Differential {{interference}} contrast (DIC) {{is frequently}} used in conventional 2 D biological microscopy. Our recent investi-gations into producing a 3 D DIC microscope (in both conventional and confocal modes) have uncovered a fundamental difficulty: namely that the phase <b>gradient</b> <b>images</b> of DIC microscopy cannot be visualized using standard {{digital image processing}} and reconstruction techniques, as commonly used elsewhere in microscopy. We discuss two approaches {{to the problem of}} preparing <b>gradient</b> <b>images</b> for 3 D visualization: integration and the Hilbert transform. After applying the Hilbert transform, the dataset can then be visualized in 3 D using standard techniques. We find that the Hilbert transform provides a rapid qualitative pre-processing technique for 3 D visualiza-tion {{for a wide range of}} biological specimens in DIC microscopy, including chromosomes, which we use in this study...|$|R
50|$|Image {{gradients}} {{can be used}} {{to extract}} information from images. Gradient images are created from the original image (generally by convolving with a filter, one of the simplest being the Sobel filter) for this purpose. Each pixel of a <b>gradient</b> <b>image</b> measures the change in intensity of that same point in the original image, in a given direction. To get the full range of direction, gradient images in the x and y directions are computed.|$|E
5000|$|Non-Maximum {{suppression}} {{is applied}} to [...] "thin" [...] the edge. After applying gradient calculation, the edge extracted from the gradient value is still quite blurred. With respect to criterion 3, there should only be one accurate response to the edge. Thus non-maximum suppression can help to suppress all the gradient values to 0 except the local maximal, which indicates location with the sharpest change of intensity value. The algorithm for each pixel in the <b>gradient</b> <b>image</b> is: ...|$|E
50|$|The {{algorithm}} {{works on}} a gray scale image. During the successive flooding of the grey value relief, watersheds with adjacent catchment basins are constructed. This flooding process is performed on the <b>gradient</b> <b>image,</b> i.e. the basins should emerge along the edges. Normally this will lead to an over-segmentation of the image, especially for noisy image material, e.g. medical CT data. Either the image must be pre-processed or the regions must be merged {{on the basis of}} a similarity criterion afterwards.|$|E
40|$|Two {{approaches}} of multistage <b>gradient</b> robustification for <b>image</b> contour detection {{are presented in}} this paper: two stages of Di erence of Estimates and Difference of Estimate followed by an optimal filtering. Watershed transformation is then applied to these robustified <b>gradient</b> <b>images</b> to effectively detect image contours which are guaranteed tobe in closed form. Multistage gradient robustification provides the flexibility of using different image processing techniques and produces good detection results for the images highly corrupted with noise. ...|$|R
50|$|<b>Image</b> <b>gradients</b> {{can also}} be used for robust feature and texture matching. Different {{lighting}} or camera properties can cause two images of the same scene to have drastically different pixel values. This can cause matching algorithms to fail to match very similar or identical features. One way to solve this is to compute texture or feature signatures based on <b>gradient</b> <b>images</b> computed from the original <b>images.</b> These <b>gradients</b> are less susceptible to lighting and camera changes, so matching errors are reduced.|$|R
40|$|We {{present a}} novel method for {{patching}} holes in polygonal meshes and synthesizing surface with details based on existing geometry. The most novel feature of our proposed {{method is to}} transform the 3 D geometry synthesis problem into a 2 D domain by parameterizing surfaces and solve this problem in that domain. We then derive local geometry <b>gradient</b> <b>images</b> that encode intrinsic local geometry properties, which are invariant to object translation and rotation. The 3 D geometry of holes is then reconstructed from synthesized local <b>gradient</b> <b>images.</b> This method can be extended to execute other mesh editing operations such as geometry detail transfer or synthesis. The resulting major benefits of performing geometry synthesis in 2 D are more flexible and robust control, better leverage of the wealth of current 2 D image completion methods and greater e#ciency...|$|R
30|$|The general {{processes}} {{involved in}} calculating the watershed transform is shown in Figure 1. Generally, a <b>gradient</b> <b>image</b> is used as input to the watershed algorithm. By using a <b>gradient</b> <b>image</b> the catchment basins should correspond to the homogeneous grey level regions of the image. A common problem to the watershed transform is that it tends to oversegment the image due to noise or local irregularities in the <b>gradient</b> <b>image.</b> This can be corrected using a region merging algorithm or by preprocessing the image prior to {{the application of the}} watershed transform.|$|E
40|$|AbstractCanny's edge {{detection}} algorithm is a classical and robust method for {{edge detection}} in gray-scale images. The two significant {{features of this}} method are introduction of NMS (Non-Maximum Suppression) and double thresholding of the <b>gradient</b> <b>image.</b> Due to poor illumination, the region boundaries in an image may become vague, creating uncertainties in the <b>gradient</b> <b>image.</b> In this paper, we have proposed an algorithm based {{on the concept of}} type- 2 fuzzy sets to handle uncertainties that automatically selects the threshold values needed to segment the <b>gradient</b> <b>image</b> using classical Canny's edge detection algorithm. The results show that our algorithm works significantly well on different benchmark images as well as medical images (hand radiography images) ...|$|E
30|$|Note {{that more}} modern {{approaches}} to region merging in image segmentation use the original image for merging while the watershed is computed on the <b>gradient</b> <b>image</b> (e.g., Peng and Zhang 2011). Using the watershed on the <b>gradient</b> <b>image</b> results in regions of similar gray values, where the densities inside our peak patches are very inhomogeneous. Approaches to region merging are thus fundamentally different in image processing {{than they are}} in our case.|$|E
40|$|Power {{consumption}} {{is a critical}} factor for the deployment of embedded computer vision systems. We explore the use of computational cameras that directly output binary <b>gradient</b> <b>images</b> to reduce {{the portion of the}} power consumption allocated to image sensing. We survey the accuracy of binary gradient cameras on a number of computer vision tasks using deep learning. These include object recognition, head pose regression, face detection, and gesture recognition. We show that, for certain applications, accuracy can be on par or even better than what can be achieved on traditional images. We are also the first to recover intensity information from binary spatial <b>gradient</b> <b>images</b> [...] useful for applications with a human observer in the loop, such as surveillance. Our results, which we validate with a prototype binary gradient camera, point to the potential of gradient-based computer vision systems...|$|R
40|$|The large {{corrugation}} amplitudes in scanning tunnelling microscope (STM) {{images of}} metal surfaces have been commonly {{attributed to the}} action of forces between the tip and the sample. We have investigated the Cu(100) surface using a high-resolution non-contact atomic force microscope/scanning tunnelling microscope (nc-AFM/STM) in UHV. Force gradient and STM topography images were acquired simultaneously using constant tunnelling current feedback. Force <b>gradient</b> <b>images</b> showed atomic resolution whereas STM scans exhibited almost no contrast, corresponding to a flat tip trajectory during scans. The corrugation height in force <b>gradient</b> <b>images</b> was found to increase as the set tunnelling current was increased. Force gradient and tunnel current were directly measured {{as a function of}} separation, to determine the operating conditions during imaging. The STM operation regime is found to lie between the minimum of the stiffness curve and the start of repulsive force...|$|R
30|$|PET(/CT) and <b>gradient</b> PET <b>images</b> were {{displayed}} side-to-side, and volume of interests (VOIs) were delineated on the <b>gradient</b> PET <b>images</b> using a gradient-based manual contouring method (in-house developed software program). <b>Gradient</b> PET <b>images</b> are derived directly from reconstructed PET images and depict the relative change in counts between neighbouring voxels (Î” standardized uptake value [SUV]), which is typically the highest around tumour borders. <b>Gradient</b> PET <b>images</b> consequently provide an image where {{the borders of}} the lesion are most intense. Use of gradient PET data enables a (manual) VOI delineation method where lesion border location is independent of colour scale, in contrast to manual contouring on regular PET images. Additional motives for choosing gradient-based delineation were a lack of systematic delineation studies in metastatic melanoma and inaccuracy of EARL-recommended semi-automatic delineation methods for delineation of large heterogeneous tumour lesions or small yet highly 18 F-FDG-avid lesions [15].|$|R
40|$|For {{improving}} the processing speed {{and accuracy of}} edge detection, an adaptive edge detection method based on improved NMS (nonmaximum suppression) was proposed in this paper. In the method, the <b>gradient</b> <b>image</b> was computed by four directional Sobel operators. Then, the <b>gradient</b> <b>image</b> was processed by using NMS method. By defining a power map function, the elements values of <b>gradient</b> <b>image</b> histogram were mapped into a wider value range. By calculating the maximal between-class variance according to the mapped histogram, the corresponding threshold was obtained as adaptive threshold value in edge detection. Finally, to be convenient for engineering application, the proposed method was realized in FPGA (Field Programmable Gate Array). The experiment results demonstrated that the proposed method was effective in edge detection and suitable for real-time application...|$|E
40|$|An {{algorithm}} {{to derive}} simple presentation of medical image is introduced in this paper. It sounds important since the complex scene {{of this type}} of image resists any application for holding further image analysis. The algorithm consists of four processing stage i. e. <b>gradient</b> <b>image,</b> opening operation, watershed transform, and region merging. Due to the undesired characteristic of the existing operation for supporting segmentation process, an extension of the existing <b>gradient</b> <b>image,</b> opening operation and region merging procedure is proposed. Experiment has successfully been taken to some MRI skull images in which the proposed algorithm produced a simplified shape of the image object...|$|E
3000|$|... is {{determined}} by mean of the <b>gradient</b> <b>image</b> minus one fourth of its standard deviation. Thus, around fifty percent [24] of the gradient values are replaced with zeros, which reduces the oversegmentation problem significantly.|$|E
30|$|The local <b>gradients</b> of <b>image</b> are {{calculated}} and {{represented by a}} kind of symbol.|$|R
30|$|In this paper, a new biologically {{motivated}} {{method is}} proposed to effectively detect perceptually homogenous region boundaries. This method integrates {{the measure of}} spatial variations in texture with the intensity gradients. In the first stage, texture representation is calculated using the nondecimated complex wavelet transform. In the second stage, <b>gradient</b> <b>images</b> are computed {{for each of the}} texture features, as well as for grey scale intensity. These gradients are efficiently estimated using a new proposed algorithm based on a hypothesis model of the human visual system. After that, combining these <b>gradient</b> <b>images,</b> a region <b>gradient</b> which highlights the region boundaries is obtained. Nonmaximum suppression and then thresholding with hysteresis is used to detect contour map from the region gradients. Natural and textured images with associated ground truth contour maps are used to evaluate the operation of the proposed method. Experimental results demonstrate that the proposed contour detection method presents more effective performance than conventional approaches.|$|R
40|$|We {{report the}} {{implementation}} of an image sensor chip, termed wavefront image sensor chip (WIS), that can measure both intensity/amplitude and phase front variations of a light wave separately and quantitatively. By monitoring the tightly confined transmitted light spots through a circular aperture grid in a high Fresnel number regime, we can measure both intensity and phase front variations with a high sampling density (11 Âµm) and high sensitivity (the sensitivity of normalized phase gradient measurement is 0. 1 mrad under the typical working condition). By using WIS in a standard microscope, we can collect both bright-field (transmitted light intensity) and normalized phase <b>gradient</b> <b>images.</b> Our experiments further demonstrate that the normalized phase <b>gradient</b> <b>images</b> of polystyrene microspheres, unstained and stained starfish embryos, and strongly birefringent potato starch granules are improved versions of their corresponding differential interference contrast (DIC) microscope images {{in that they are}} artifact-free and quantitative. Besides phase microscopy, WIS can benefit machine recognition, object ranging, and texture assessment for a variety of applications...|$|R
3000|$|Gradient infimum {{value is}} {{computed}} from the gradient values of difference images of consecutive frames. It is utilized for making decision on watershed segments for classification as foreground or background. Left <b>gradient</b> <b>image</b> ([...] [...]...|$|E
40|$|This paper {{proposes a}} new {{technique}} for automatic face recognition using integrated peaks of the Hough transformed significant blocks of the binary <b>gradient</b> <b>image.</b> In this approach firstly the gradient of an image is calculated and a threshold is set to obtain a binary <b>gradient</b> <b>image,</b> which is less sensitive to noise and illumination changes. Secondly, significant blocks are extracted from the absolute <b>gradient</b> <b>image,</b> to extract pertinent information {{with the idea of}} dimension reduction. Finally the best fitted Hough peaks are extracted from the Hough transformed significant blocks for efficient face recognition. Then these Hough peaks are concatenated together, which are used as feature in classification process. The efficiency of the proposed method is demonstrated by the experiment on 1100 images from the FRAV 2 D face database, 2200 images from the FERET database, where the images vary in pose, expression, illumination and scale and 400 images from the ORL face database, where the images slightly vary in pose. Our method has shown 93. 3 %, 88. 5 % and 99 % recognition accuracy for the FRAV 2 D, FERET and the ORL database respectively. Comment: 6 pages. arXiv admin note: substantial text overlap with arXiv: 1312. 151...|$|E
40|$|This paper {{presents}} {{a novel approach}} for detecting vehicles for driver assistance. Assuming flat roads, vanishing point is first estimated using Hough transform space to reduce the computational complexity. Localization of vehicles is carried using horizontal projection on the horizontal <b>gradient</b> <b>image</b> below vanishing point. An uppermost and lowermost peak in the horizontal profile corresponds to search space of vehicles. Binarization of search space on the horizontal <b>gradient</b> <b>image</b> is done using Otsu algorithm. Verification of vehicles is carried {{through a series of}} rule based classifiers constructed using statistical moments, observing peaks in vertical profiling, vehicle texture, symmetry and shadow property. Experimentation was carried out on flat highway roads and detection rate of vehicles is nearly found to be 88. 23 %...|$|E
40|$|In this paper, {{we propose}} a {{technique}} for segmenting visual textures using features {{extracted from the}} reponses of Ga,bor filters, appropria. tely selec tecl to be tuned to texture components of the input image. In the proposed method segmentation is achieved by detecting boundaries between adjacent textured regions, and this segmentation algorithm works as follows. The input image is first filtered using a small set of Gabor filters, each tuned {{to one of the}} textures composing the original image. Abrupt changes in the obtained Gabor filter output images are found by detecting the underlying local extremas. For this purpose, a gradient operator is applied to output ima. ge of each Gabor filter, yielding a. set of <b>gradient</b> <b>images.</b> The textcrre <b>gradient</b> is sul>sequently obtained by grouping <b>gradient</b> <b>images</b> from all channels. Thresholding the texture gradient and thinning the result yields the expected texture boundaries. Experimental results on synthetic and natural textures, demonstrate the efficacy of the proposed technique. ...|$|R
40|$|In this paper, a new biologically {{motivated}} {{method is}} proposed to effectively detect perceptually homogenous region boundaries. This method integrates {{the measure of}} spatial variations in texture with the intensity gradients. In the first stage, texture representation is calculated using the nondecimated complex wavelet transform. In the second stage, <b>gradient</b> <b>images</b> are computed {{for each of the}} texture features, as well as for grey scale intensity. These gradients are efficiently estimated using a new proposed algorithm based on a hypothesis model of the human visual system. After that, combining these <b>gradient</b> <b>images,</b> a region <b>gradient</b> which highlights the region boundaries is obtained. Nonmaximum suppression and then thresholding with hysteresis is used to detect contour map from the region gradients. Natural and textured images with associated ground truth contour maps are used to evaluate the operation of the proposed method. Experimental results demonstrate that the proposed contour detection method presents more effective performance than conventional approaches. </p...|$|R
5000|$|The {{matrix of}} partial sums is {{calculated}} in one {{pass through the}} binary <b>gradient,</b> de-skewed <b>image.</b>|$|R
40|$|The paper makes {{a survey}} of the {{morphological}} tools which are useful for image simplification and segmentation. It starts presenting the connected filters, which have the unique feature to simplify the images without blurring the contours of the remaining objects. Such filters may be constructed on several criteria : size, contrast, complexity or type of motion. In the case where geometric criteria are used, it is possible to base a scale-space description of the images on a series of increasing filters. This is most useful when applied to a <b>gradient</b> <b>image</b> : successive filters will progressively fill the valleys of the <b>gradient</b> <b>image</b> and a watershed transform applied on these images will produce segmentations which are coarser and coarser. These segmentations have a tree structure : from a finer level to a coarser level, only fusions take place. Peer ReviewedPostprint (published version...|$|E
40|$|Abstractâ€”Morphological {{gradient}} {{is often}} used to find the gradient of an image which is further used for the transformation. However, noise in the <b>gradient</b> <b>image</b> results in to over-segmentation which have an undesirable bad effect on resulting segmented image. For the fine segmentation results the quality of the gradient estimate has a major influence on the segmentation performance. In this paper it is shown that different types of gradient are computed with the help of different operators and further these various gradients are used to segment the image with the help of watershed transformation. The resulting image constitute of watershed divide lines and the catchment basins. The purpose of this work is to show that the gradient obtained through different operators like Sobel, Prewitt, kirsch etc. have varying effect on watershed in terms of peak signal to noise ratio. Keyword- Watershed, <b>gradient,</b> <b>image</b> segmentation. I...|$|E
40|$|Abstract-A spatial {{clustering}} procedure {{applicable to}} multi-spectral image data is discussed. The procedure {{takes into account}} the spatial distribution of the measurements as well as their distribution in measure-ment space. The procedure calls for the generation and then thresholding of the <b>gradient</b> <b>image,</b> cleaning the thresholded image, labeling the connected regions in the cleaned image, and clustering the labeled regions. An experiment was carried out on ERTS data in order to study the effect of the selection of the <b>gradient</b> <b>image,</b> the threshold, and the cleaning process. Three gradients, three gradient thresholds, and two cleaning parameters yielded 18 gradient-thresholds combinations. The combination that yielded connected homogeneous regions with the smallest variance was Robertâ€™s gradient with distance 2, thresholded by its running mean, and a cleaning process that considered a resolution cell to be homogene&s if and only if at least 7 of its nearest neighbors were homogeneous. I...|$|E
50|$|One of {{the most}} common uses is in edge detection. After <b>{{gradient}}</b> <b>images</b> have been computed, pixels with large gradient values become possible edge pixels. The pixels with the largest gradient values {{in the direction of the}} gradient become edge pixels, and edges may be traced in the direction perpendicular to the gradient direction. One example of an edge detection algorithm that uses gradients is the Canny edge detector.|$|R
5000|$|Columns {{are easily}} {{segmented}} from the binary <b>gradient,</b> de-skewed <b>images</b> by summing pixels vertically {{as shown in}} Figure 4.|$|R
50|$|A paint {{generates the}} colors {{to be used}} for each pixel of the fill operation. The {{simplest}} paint is , which generates the same color for all pixels. More complicated paints may produce <b>gradients,</b> <b>images,</b> or indeed any combination of colors. Filling a circular shape using the color yellow results in a solid yellow circle, while filling the same circular shape using a paint that generates an image produces a circular cutout of the image.|$|R
