1|37|Public
40|$|Abstract. Much of the {{existing}} literature on default contagion assumes a direct causal relationships between two obligors ’ defaults. In this paper we present a model in which default contagion arises without causal links solely from information effects if investors are imperfectly informed about some common factors affecting the true riskiness of the obligors. We model this effect in a simple extension of the intensity-based modelling framework using unobserved frailty variables. If one obligor defaults in this model, the default intensities of other obligors exhibit jumps which are proportional to the covariances of the corresponding frailties. This allows the modelling of much higher (and more realistic) levels of default dependence between the obligors than what purely diffusion-based intensity models were able to capture previously, without adding too much additional complexity. The parameters of the dependence can be implied directly from spread jumps observed in the market, thus enabling a full specification of the model under pricing probabilities without recourse to historical default correlations. We furthermore present {{an extension of the}} model in which the size of the contagion effect can depend on the reason for the default and not just the identity of the <b>defaulted</b> <b>obligor,</b> thus introducing stochastic dependency. 1...|$|E
5000|$|The {{beneficiary}} of the guarantee must first prove the <b>obligor's</b> <b>default</b> before the guarantor becomes liable to pay.|$|R
50|$|Exposure at default or (EAD) is a {{parameter}} used in {{the calculation}} of economic capital or regulatory capital under Basel II for a banking institution. It {{can be defined as}} the gross exposure under a facility upon <b>default</b> of an <b>obligor.</b>|$|R
40|$|In {{this paper}} {{we present a}} new {{approach}} to incorporate dynamic default dependency in intensity-based default risk models. The model uses an arbitrary default dependency structure which is specified by the Copula of the times of default, this is combined with individual intensity-based models for the <b>defaults</b> of the <b>obligors</b> without loss of the calibration of the individual default-intensity models. The dynamics of the survival probabilities and credit spreads of individual obligors are derived and it is shown that in situations with positive dependence, the <b>default</b> of one <b>obligor</b> causes the credit spreads of the other obligors to jump upwards, as it is experienced empirically in situations with credit contagion. For th...|$|R
40|$|Mixture models play an {{important}} role in the modeling of portfolio losses. In these models the risk of <b>default</b> of individual <b>obligors</b> (indexed by i ∈{ 1, [...] .,m}) depends on an underlying set of common economic factors, denoted Ψ. Given these factors, the losses due to default li of individual obligors are assumed to be stochastically independent. Dependence betwee...|$|R
40|$|CreditRisk+ {{is one of}} {{the most}} widely {{implemented}} credit portfolio models. The independent factor assumption in the original model proposed by Credit Suisse First Boston (1997) underestimates the <b>default</b> correlations among <b>obligors.</b> This thesis introduces three enhanced models that capture the factor covariance structure: Compound Gamma Model, Hidden Gamma Model and Common Factor Model. I compute the portfolio loss distributions generated from these three models via the Fast Fourier Transform (FFT) algorithm. The economic interpretation for the model parameters are also provided. Moreover, the Saddlepoint approximation technique is applied to produce fast and accurate credit Value-at-Risk (VaR) at different levels. The numerical results reveal the ability of the enhanced models to capture the <b>default</b> correlations among <b>obligors.</b> Subsequently, I derive the formulas for VaR contributions in the three enhanced CreditRisk+ and perform numerical tests to show their stability. As one of the applications of the CreditRisk+, I estimate the expected tranche losses of CDO with the Compound Gamma Model and Hidden Gamma Model. Based on the modeling analysis and numerical studies, the enhanced CreditRisk+ models are appropriate choices to model default correlation with respect to different financial situations...|$|R
40|$|Simulation {{is widely}} used to {{estimate}} losses due to default and other credit events in financial portfolios. The challenge in doing this efficiently results from (i) rareevent aspects of large losses and (ii) complex dependence between <b>defaults</b> of multiple <b>obligors.</b> We discuss importance sampling techniques {{to address this problem}} in two portfolio credit risk models developed in the financial industry, with particular emphasis on a mixed Poisson model. We give conditions for asymptotic optimality of the estimators as the portfolio size grows...|$|R
40|$|In this paper, we {{consider}} the following inverse problem for the first hitting time distribution: given a Wiener process with a random initial state, probability distribution, F(t), and a linear boundary, b(t) =[mu]t, find a distribution of the initial state such that {{the distribution of the}} first hitting time is F(t). This problem has important applications in credit risk modeling where the process represents the so-called distance to <b>default</b> of an <b>obligor,</b> the first hitting time represents a default event and the boundary separates the healthy states of the <b>obligor</b> from the <b>default</b> state. We show that randomization of the initial state of the process makes the problem analytically tractable. ...|$|R
50|$|The {{main purpose}} of {{hypothecation}} is to mitigate the creditor's credit risk. If the debtor cannot pay, the creditor possesses the collateral and therefore can claim its ownership, sell it and thus compensate the lacking cash inflows. In a <b>default</b> of the <b>obligor</b> without previous hypothecation, the creditor cannot be sure that it can seize sufficient assets of the debtor. Because hypothecation {{makes it easier to}} get the debt and potentially decreases its price; the debtor wants to hypothecate as much debt as possible - but the isolation of 'good assets' for the collateral worsens the quality {{of the rest of the}} debtor's balance sheet and thus its credit quality.|$|R
40|$|Risk {{management}} that {{is connected with}} the customers of the insurance companies is a great challenge for the insurance companies, for they can prevent negative consequences by managing the latter. Globally, the insurance companies are confronted by insurance frauds which {{are one of the}} biggest risks of the insurance industry. Different sources state that approximately 10 percent of all the paid out claims is a consequence of the fraud. ACFE organization estimates in its study that the amount paid to the swindlers amounts to the 5 percent of all the income of the insurance companies. Most of the discovered frauds is connected with a long-term legal procedures; therefore, it is essential that an insurance company establishes an efficient system in order to prevent the frauds and upgrades it with the system of managing the risky persons, which includes all the risks of the clients that are stored in patterns and rules and are used for the needs of preventing. In the master’s thesis, an information system for managing risky persons, which includes the lists of persons different in contents, is developed. The criteria for placing on the lists are determined on the basis of past experiences of the insurance company and expert system for the detection and researching the frauds. In order to establish the information system, a data model, processing for the automatic placing of the persons on the lists, application for editing, erasure and entry of the lists and persons, had to be developed. In order to establish the information system the display of indicators in all the key applications of the insurance company with the manual of user’s managing of the application in different processes of handling the clients had to be established. The system includes the lists of persons who performed an insurance fraud in the past, were a part of judicial proceeding, were insolvent, were <b>defaulted</b> <b>obligors</b> of the insurance premium, persons liable to recourse, have bad damage results, have bad insurance-technical result and are risky from the perspective of large damage frequency. Financial effects of the development of the information system will appear in a long-term period, for the insurance business is an industry where an insurance company and a client have little contacts; measuring the effects of the developed information system is possible only at concluding insurance contracts and in settlements of the claims. An established system for managing the risky persons is an infrastructure or the framework for further development and the opportunity for further work connected with the inclusion of life, pension and medical insurances as well as possible completion of the lists also with the persons that bring above the average yield, or important clients of the company, for the infrastructure enables all that...|$|R
40|$|In {{this paper}} {{we present a}} model to price and hedge basket credit {{derivatives}} and collateralised loan obligation. Based upon the copula-approach by Schonbucher and Schubert (2001) the model allows a specification of the joint dynamics of credit spreads and default intensities, including a specification of the infection dynamics which cause credit spreads to widen at <b>defaults</b> of other <b>obligors.</b> Because of {{a high degree of}} analytical tractability, joint default and survival probabilities and also sensitivities can be given in closed-form which facilitates the development of hedging strategies based upon the model. The model uses a generalisation of the class of Archimedean copula functions which gives rise to more realistic credit spread dynamics than the Gaussian copula or the Student-t-copula which are usually chosen in practice. An example specification using Gamma-distributed factors is provided...|$|R
40|$|We {{study the}} implied default {{distributions}} for the iTraxx-CJ tranches {{by means of}} the Principle of Maximum Entropy. The profiles are quite different from those of some popular probabilistic models. We analyze their correlation structures, the conditional default probabilities p_ij and conditional default correlations ρ_ij. Here the subscript _ij means that the default probability and correlation are estimated under i <b>obligors</b> are <b>defaulted</b> and j <b>obligors</b> are non-defaulted among N <b>obligors.</b> The implied <b>default</b> distribution, ρ_n 0 shows singular behavior, jumps high and then decreases rapidly to zero with n. Correspondingly p_n 0 increases with n and saturates to some maximum value below 1. Such a behavior implies that the credit market expects a middle scale avalanche. We also discuss the "True" default correlation implied by the market quotes...|$|R
50|$|The {{holder of}} any debt {{is subject to}} {{interest}} rate risk and credit risk, inflationary risk, currency risk, duration risk, convexity risk, repayment of principal risk, streaming income risk, liquidity risk, default risk, maturity risk, reinvestment risk, market risk, political risk, and taxation adjustment risk. Interest rate risk refers {{to the risk of}} the market value of a bond changing due to changes in the structure or level of interest rates or credit spreads or risk premiums. The credit risk of a high-yield bond refers to the probability and probable loss upon a credit event (i.e., the <b>obligor</b> <b>defaults</b> on scheduled payments or files for bankruptcy, or the bond is restructured), or a credit quality change is issued by a rating agency including Fitch, Moody's, or Standard & Poors.|$|R
40|$|Abstract. In {{this paper}} {{we present a}} model to price and hedge basket credit {{derivatives}} and collateralised loan obligation. Based upon the copula-approach by Schönbucher and Schubert (2001) the model allows a specification of the joint dynamics of credit spreads and default intensities, including a specification of the infection dynamics which cause credit spreads to widen at <b>defaults</b> of other <b>obligors.</b> Because of {{a high degree of}} analytical tractability, joint default and survival probabilities and also sensitivities can be given in closed-form which facilitates the development of hedging strategies based upon the model. The model uses a generalisation of the class of Archimedean copula functions which gives rise to more realistic credit spread dynamics than the Gaussian copula or the Student-t-copula which are usually chosen in practice. An example specification using Gamma-distributed factors is provided. 1...|$|R
40|$|In {{this paper}} we propose a new nonparametric {{approach}} to interacting failing systems (FS), that is systems whose probability of failure is not negligible in a fixed time horizon, a typical example being firms and financial bonds. The main purpose when studying a FS is to calculate the probability of default and the distribution of the number of failures that may occur during the observation period. A model used to study a failing system is defined default model. In particular, we present a general recursive model constructed by the means of inter- acting urns. After introducing the theoretical model and its properties we show a first application to credit risk modeling, showing how to assess the idiosyncratic probability of <b>default</b> of an <b>obligor</b> and the joint probability of failure of a set of obligors in a portfolio of risks, that are divided into reliability classes...|$|R
40|$|This thesis studies {{an asset}} {{value-based}} approach for the valuation of credit portfolio risk including the estimation and the backtesting of the model’s forecasting ability. On {{the basis of}} the credit valuation model proposed by Black and Cox (1976) an asset value-based factor model for the forecasting of credit portfolio risk is suggested. The model includes credit losses from the <b>default</b> of <b>obligors</b> as well as negative changes of credits’ mark-to-model values. Using market prices of defaultable corporate bonds a quasi-maximum likelihood estimation of the state-space models of systematic factors and asset values of risk classes is performed. The backtesting procedure assesses the forecasting ability of the credit portfolio model using three zones of credit portfolio loss that are defined analogously to the regulatory backtesting of internal market risk models. Probability distributions of credit portfolio loss are simulated and the backtesting zones of portfolio loss are compared for different credit portfolios and different variations of the backtesting procedure, the model structure and the parameters. The results show that for typical levels of confidence and typical time horizons the Credit-VaR exceeds banks’ capital considerably. Furthermore, backtesting zones of credit portfolio loss that fit to banks’ capital levels result in a level of test significance that is distinctly lower than in the backtesting of market risk models. It is concluded that the revised capital requirements set by the Basel Committee do not prevent credit portfolio losses exceeding banks’ capital with the statistical confidence presumed by supervisory authorities...|$|R
40|$|Abstract. We {{study the}} implied default {{distributions}} for the iTraxx-CJ tranches {{by means of}} the Principle of Maximum Entropy. The profiles are quite different from those of some popular probabilistic models. We show how to analyze the correlation structures, the conditional default probabilities pi,j and conditional default correlations ρi,j. Here the subscript i,j means that the default probability and correlation are estimated under i <b>obligors</b> are <b>defaulted</b> and j <b>obligors</b> are non-defaulted among N <b>obligors.</b> The implied <b>default</b> distribution, ρi, 0 shows singular behavior, jumps high and then decreases rapidly to zero with i. Correspondingly pi, 0 increases with i and saturates to some maximum value below 1. Such a behavior implies that the credit market expects a medium-size avalanche. We also discuss the “True ” default correlation implied by the market quotes. PACS numbers: 89. 65. -s, 02. 50. -r † to whom correspondence should be addressed (mori@sci. kitasato-u. ac. jp) Implied Default Distribution...|$|R
40|$|Credit {{rating is}} the {{evaluation}} of the likelihood of an <b>obligor</b> to <b>default</b> on a loan. Each obligor in the bank’s credit portfolio isassigned to a certain rating class, or PD (probability of <b>default)</b> bucket; all <b>obligors</b> in a PD bucket then receive the same “pooled”PD, based on which a capital charge against credit risk must be computed. The only analytical approach to this problem is basedon k-means and has some limitations in practice. An error minimization approach to credit rating using differential evolution (DE) is introduced. The performances of DE and other common search heuristics are compared using credit rating data of a major Italianbank. Empirical results show that DE is clearly superior compared to a genetic algorithm (GA), particle swarm optimization (PSO),random search (RS) and two naïve partitioning approaches. Moreover, the proposed approach obtained better results than k-meansin much less runtime for a simplified instance of the problem where within-groups variances can be used for clustering...|$|R
40|$|This paper {{presents}} a robust and practical CDO valuation framework {{based on the}} application of multi-factor credit models in conjunction with weighted Monte Carlo techniques used in options pricing. The framework produces arbitrage-free prices and {{can be seen as}} an extension to the implied copula methodology of Hull and White (2006). We demonstrate the practical advantages of working through multi-factor models, rather than directly on a common hazard rate (or a set of them), to value consistently CDOs of bespoke portfolios, CDO-squared and cash CDOs. The multi-factor credit models which determine the codependence of <b>obligor</b> <b>defaults</b> are defined generally within the mathematical construction of Generalized Linear Mixed Models (GLMMs). The implied copula approach {{can be seen as a}} special case of a GLMM, as are other common credit portfolio models. For a given model, the quoted prices of various credit portfolio instruments, such as CDO tranches, are used to imply the “risk-neutral ” distributions (or processes) for the underlying systematic risk factors...|$|R
40|$|This paper {{proposes a}} {{modified}} copula approach to defining correlation dependence used for pricing credit derivatives. In pricing single-name credit instruments, {{it is necessary}} to consider the default dependence between the reference entity and the counterparty. In pricing multiname credit instruments, the effects of the <b>default</b> of an <b>obligor</b> on the remaining obligors must be addressed. For both single-name and multiname products, how default correlations react to common shocks should be appropriately measured. The copula approach for estimating default correlations is increasingly popular in practice due to its simplicity in specifying the joint distribution. It is in practice often combined with the structural and reduced-form approaches. However, it is found that in the currently available copula models, default correlation structure of many obligors in which there are opposite responses to a common macro factor cannot be appropriately handled. In this paper, we use one of the models to illustrate how the deficiency can be remedied. Other copula models with the same deficiency can be similarly modified...|$|R
40|$|This paper {{contributes}} to a growing literature on the pitfalls of diversification by shedding light on a new mechanism under which, full risk diversification can be sub-optimal. In particular, banks must choose the optimal level of diversification in a market where returns display a bimodal distribution. This feature results from the combination of two opposite economic trends that are weighted by the probability of being either in a bad or in a good state of the world. Banks have also interlocked balance sheets, with interbank claims marked-to-market according to the individual default probability of the <b>obligor.</b> <b>Default</b> is determined by extending the Black and Cox (1976) first-passage-time approach to a network context. We find that, {{even in the absence}} of transaction costs, the optimal level of risk diversification is interior. Moreover, in the presence of market externalities, individual incentives favor a banking system that is over-diversified with respect to the level of socially desirable diversification...|$|R
40|$|Master of ScienceDepartment of Industrial & Manufacturing Systems EngineeringChih-Hang WuThe recent {{economic}} crisis has been partially {{blamed on the}} decline in the housing market. This decline in the housing market resulted in an estimated 87 % decline in value of collateralized debt obligations (CDOs) between 2007 and 2008. This drastic decline in home values was sudden and unanticipated, thus it was incomprehensible for many investors how this would affect CDOs. This shows that while analytical techniques can be used to price CDOs, these techniques cannot be used to demonstrate the behavior of CDOs under radically different economic circumstances. To better understand the behavior of CDOs under different economic circumstances, numerical techniques such as Monte Carlo simulation can be used instead of analytical techniques to price CDOs. Andersen et al (2005) proposed a method for calculating the probability of defaults that could then be used in the Monte Carlo simulation to price the collateralized debt obligation. The research proposed by Andersen et al (2005) demonstrates the process of calculating correlated probability of defaults for a group of obligors. This calculation is based on the correlations between the obligors using copulas. Using this probability of default, the price of a collateralized debt obligation can be evaluated using Monte Carlo simulation. Monte Carlo simulation provides a more simple yet effective approach compared to analytical pricing techniques. Simulation also allows investors to {{have a better understanding of}} the behaviors of CDOs compared to analytical pricing techniques. By analyzing the various behaviors under uncertainty, it can be observed how a downturn in the economy could affect CDOs. This thesis extends on the use of copulas to simulate the correlation between obligors. Copulas allow for the creation of one joint distribution using a set of independent distributions thus allowing for an efficient way of modeling the correlation between obligors. The research contained within this thesis demonstrates how Monte Carlo simulation can be used to effectively price collateralized debt obligations. It also shows how the use of copulas can be used to accurately characterize the correlation between <b>obligor</b> <b>defaults</b> for pricing collateralized debt obligations. Numerical examples for both the <b>obligor</b> <b>defaults</b> and the price of collateralized debt obligations are presented to demonstrate the results using Monte Carlo simulation...|$|R
40|$|I develop {{methods that}} produce {{consistent}} {{estimates of the}} Vasicek-Basel IRB (VAIRB) credit risk model parameters. I apply these methods to Moody’s data on corporate defaults over the period 1920 – 2008 and assess the model fit and construct hypothesis tests using bootstrap methods. The {{results show that the}} VAIRB does not capture the variability in Moody’s default data: there are numerous episodes in which <b>obligors</b> <b>default</b> with much greater frequency than predicted. This pattern is consistent with a missing common factor that affects default correlation only intermittently—a missing factor similar to the frailty covariate in Duffie et al. (2009). Unlike Lopez (2004), I find the VAIRB correlation parameter to be larger for lower-rated credits. I use estimates of the VAIRB error distribution to construct capital allocations for model risk and find that the capital buffers for model risk are substantial, especially for lower-graded credits. VAIRB common factor estimates exhibit positive autocorrelation and thus long time series are usually necessary to produce reliable model estimates. Alternatively, I use common factor and correlation parameter estimates from the 1920 - 2008 data to contro...|$|R
40|$|Experiences {{manifest}} {{the importance}} of comovement and communicable characters among the risks of financial assets. Therefore, the portfolio view considering dependence relationship among credit entities {{is at the heart}} of risk measurement. This paper introduces a mixed Poisson model assuming <b>default</b> probabilities of <b>obligors</b> depending on a set of common economic factors to construct the dependence structure of obligors. Further, we apply mixed Poisson model into an empirical study with data of four industry portfolios in the financial market of China. In the process of model construction, the classical structural approach and option pricing formula contribute to estimate dynamic default probabilities of single obligor, which helps to obtain the dynamic Poisson intensities under the model assumption. Finally, given the values of coefficients in this model calculated by a nonlinear estimation, Monte Carlo technique simulates the progress of loss occurrence. Relationship between default probability and loss level reflected through the MC simulation has practical features. This study illustrates the practical value and effectiveness of mixed Poisson model in risk measurement for credit portfolio...|$|R
40|$|Evidence {{from many}} {{countries}} in recent years suggests that collateral values and recovery rates on corporate defaults can be volatile and, moreover, {{that they tend to}} go down just when the number of defaults goes up in economic downturns. This link between recovery rates and default rates has traditionally been neglected by credit risk models, as most of them focused on default risk and adopted static loss assumptions, treating the recovery rate either as a constant parameter or as a stochastic variable independent from the probability of default. This traditional focus on default analysis has been partly reversed by the recent significant {{increase in the number of}} studies dedicated to the subject of recovery rate estimation and the relationship between default and recovery rates. This paper presents a detailed review of the way credit risk models, developed during the last thirty years, treat the recovery rate and, more specifically, its relationship with the probability of <b>default</b> of an <b>obligor.</b> Recent empirical evidence concerning this issue is also presented and discussed. ...|$|R
40|$|Rating {{collateralised}} debt obligations (CDOs), {{which are}} based on tranched pools of credit risk exposures, does not only require attributing a probability of <b>default</b> to each <b>obligor</b> within the portfolio. It also involves assumptions concerning recovery rates and correlated defaults of pool assets, thus combining credit risk assessments of individual collateral assets with estimates about default correlations and other modelling assumptions. In this paper, we explain one of the most well-known models for rating CDOs, the so-called binomial expansion technique (BET). Comparing this approach with an alternative methodology based on Monte Carlo simulation, we then highlight the potential importance of correlation assumptions for the ratings of senior CDO tranches and explore what differences in methodologies across rating agencies may mean for senior tranche rating outcomes. The remainder of the paper talks about potential implications of certain model assumptions for ratings accuracy, that is the "model risk" taken by investors when acquiring CDO tranches, and whether and under what conditions methodological differences may generate incentives for issuers to strategically select rating agencies to get particular CDO structures rated. Collateralised debt obligations, credit risk modelling, rating agencies...|$|R
40|$|Defaults in {{a credit}} {{portfolio}} of many obligors {{or in an}} economy populated with firms tend to occur in waves. This may simply reflect their sharing of common risk factors and/or manifest their systemic linkages via credit chains. One popular approach to characterizing defaults in a large pool of obligors is the Poisson intensity model coupled with stochastic covariates. A constraining feature of such models is that <b>defaults</b> of different <b>obligors</b> are independent events after conditioning on the covariates, which makes them ill-suited for modeling clustered defaults. Although individual default intensities under such models can be high and correlated via the stochastic covariates, joint default rates will always be zero, because the joint default probabilities are {{in the order of}} the length of time squared or higher. In this paper, we develop a hierarchical intensity model with three layers of shocks – common, group-specific and individual. When a common (or group-specific) shock occurs, all obligors (or group members) face individual default probabilities, determining whether they actually default. The joint default rates under this hierarchical structure can be high, and thus the model better captures clustered defaults. This hierarchical intensity model can be estimated using the maximum likelihood principle. Its predicted default frequency plot is used to complement the typical cumulative accuracy plot (CAP) in default prediction. We implement the new model on the US corporate default/bankruptcy data and find it superior to the standard intensity model...|$|R
40|$|Portfolio credit {{derivatives}} The payoff {{is related to}} the credit events in a whole portfolio of risky assets–correlation products. Reference assets 1. n th to default credit default swaps 2. Collateralized debt obligations 3. Index tranches 4. CDO 2 structure Pricing considerations • <b>default</b> intensities of <b>obligors</b> in the portfolio • recovery rates upon default • default correlation among the obligorsBasket default swaps The credit event to insure against is the event of the k th default. A premium or spread s is paid as an insurance fee until maturity or the event of the k th default. If the k th default occurs before swap’s maturity, the Protection Buyer can present the defaulting bond to the Protection Seller in exchange for the face value of the bond. Sum of the kth-to-default swap spreads is greater than the sum of the individual spreads n∑ k= 1 s k> n∑ i= 1 si. Why? Both sides insure exactly the same risk, but {{at the time of the}} first default, one stops paying the huge spread s 1 on one side but on the plain-vanilla side one stops just paying the spread si of the first default i. In the figure, we show the k th-to-default spreads for 3 underlyings with s 1 = 0. 009, s 2 = 0. 010 and s 3 = 0. 001 and we assume pair-wise equal correlation. • If the credit events are independent, the fair spread s 1 is close to the sum of the fair default swap spreads. • If they are dependent, then s 1 = max i si. Loan...|$|R
40|$|This thesis {{deals with}} credit risk {{modeling}} and related mathematical issues. In particular we study first-passage models for credit risk, where <b>obligors</b> <b>default</b> upon first {{passage of a}} ``credit quality" process to zero. The first passage problem for correlated Brownian motion is a mathematical structure which arises quite naturally in such models, in particular the seminal multivariate Black-Cox model. In general this problem is analytically intractable, however in two dimensions analytic results are available. In addition to correcting mistakes in several published formulae, we derive an exact simulation scheme for sampling the passage times. Our algorithm exploits several interesting properties of planar Brownian motion and conformal local martingales. The main contribution of this thesis {{is the development of}} a novel multivariate framework for credit risk. We allow for both stochastic trend and volatility in credit qualities, with dependence introduced by letting these quantities be driven by systematic factors common to all obligors. Exploiting a conditional independence structure we are able to express the proportion of defaults in an asymptotically large portfolio as a path functional of the systematic factors. The functional in question returns crossing probabilities of time-changed Brownian motion to continuous barriers, and is typically not available in closed form. As such the distribution of portfolio losses is in general analytically intractable. As such we devise a scheme for simulating approximate losses and demonstrate almost sure convergence of this approximation. We show that the model calibrates well, across both tranches and maturities, to market quotes for CDX index tranches. In particular we are able to calibrate to data from 2006, as well as more recent ``distressed" data from 2008...|$|R
40|$|This paper {{develops}} rare event simulation {{methods for}} {{the estimation of}} portfolio credit risk — the risk of losses to a portfolio resulting from defaults of assets in the portfolio. Portfolio credit risk is measured through probabilities of large losses, which are typically due to <b>defaults</b> of many <b>obligors</b> (sources of credit risk) to which a portfolio is exposed. An essential element of a portfolio view of credit risk {{is a model of}} dependence between these sources of credit risk: large losses occur rarely and are most likely to result from systematic risk factors that affect multiple obligors. As a consequence, estimating portfolio credit risk poses a challenge both because of the rare-event property of large losses and the dependence between defaults. To address this problem, we develop an importance sampling technique within the widely used Gaussian copula model of dependence. We focus on difficulties arising in multifactor models — that is, models in which multiple factors may be common to multiple obligors, resulting in complex dependence between defaults. Our importance sampling procedure shifts the mean of the common factor to increase the frequency of large losses. In multifactor models, different combinations of factor outcomes and defaults can produce large losses, so our method combines multiple importance sampling distributions, each associated with a shift in the mean of common factors. We characterize “optimal ” mean shifts. Finding these points is both a combinatorial problem and a convex optimization problem, so we address computational aspects of this step as well. We establish asymptotic optimality results for our method, showing that — unlike standard simulation — it remains efficient as the event of interest becomes rarer. ...|$|R
40|$|In this work, {{we present}} a {{methodology}} for measuring and optimizing the credit risk of a loan portfolio {{taking into account the}} non-normality of the credit loss distribution. In particular, we aim at modelling accurately joint default events for credit assets. In order to achieve this goal, we build the loss distribution of the loan portfolio by Monte Carlo simulation. The times until <b>default</b> of each <b>obligor</b> in portfolio are simulated following a copula-based approach. In particular, we study four different types of dependence structure for the credit assets in portfolio: the Gaussian copula, the Student's t-copula, the grouped t-copula and the Clayton n-copula (or Cook-Johnson copula). Our aim is {{to assess the impact of}} each type of copula on the value of different portfolio risk measures, such as expected loss, maximum loss, credit value at risk and expected shortfall. In addition, we want to verify whether and how the optimal portfolio composition may change utilizing various types of copula for describing the default dependence structure. In order to optimize portfolio credit risk, we minimize the conditional value at risk, a risk measure both relevant and tractable, by solving a simple linear programming problem subject to the traditional constraints of balance, portfolio expected return and trading. The outcomes, in terms of optimal portfolio compositions, obtained assuming different default dependence structures are compared with each other. The solution of the risk minimization problem may suggest us how to restructure the inefficient loan portfolios in order to obtain their best risk/return profile. In the absence of a developed secondary market for loans, we may follow the investment strategies indicated by the solution vector by utilizing credit default swaps. © Banca Monte dei Paschi di Siena SpA, 2004...|$|R
40|$|Portfolio credit {{derivatives}} – correlation product The payoff {{is related to}} the credit events in a whole portfolio of risky assets – correlation products. 1. Collateralized debt obligations 2. CDO 2 structure Pricing considerations • <b>default</b> intensities of <b>obligors</b> in the portfolio • recovery rates upon default • default correlation among the <b>obligors</b> 1 Modeling <b>default</b> of single name Market’s assessment of the default risk of the obligor (assuming some form of market efficiency – information is aggregated in the market prices). The sources are • market prices of bonds and other defaultable securities issued by the obligor • prices of CDS’s referencing this obligor’s credit risk ⋆ Based on no-arbitrage pricing principle, a model that is based upon and calibrated to the prices of traded assets is immune to simple arbitrage strategies using these traded assets. 2 Credit spread: compensate investor for the risk of default on the underlying securities spread = yield on the loan − riskfree yield Construction of a credit risk adjusted yield curve is hindered by 1. The absence in money markets of liquid traded instruments on credit spread. 2. The absence of a complete term structure of credit spreads. At best we only have infrequent data points. 3 Term structure of credit spreads The price of a corporate bond must reflect not only the spot rates for default-free bonds but also a risk premium to reflect default risk and any options embedded in the issue. Simple approach 1. Take the spot rates that are used to discount the cash flows of corporate bonds to be the Treasury sport rates plus a constant credit spread. 2. Since the credit spread is expected to increase with maturity, we need a term structure for credit spreads. Unlike Treasury securities, there are no issuers that offer a sufficiently wide range of corporate zero-coupon securities to construct a zero-coupon spread curve...|$|R
40|$|In this {{dissertation}} {{we study}} {{models for the}} valuation of portfolios of credit risky securities and collateralised debt obligations. We start with models for single security of the reduced form type and investigate means of extending these to the portfolio level concentrating on <b>default</b> dependence between <b>obligors.</b> The Gaussian copula model has become a market standard and we study how the model deals with dependence between portfolio constituents. We implement the model and confirm analytical formulae for certain risk measures. Simplifying assumptions made eases implementation of this model but causes inconsistencies with observed market prices. Evidence {{of this is the}} observed correlation smile, highlighted by the recent global credit crises. This has caused researchers to look to extensions of the model to better fit current market pricing. We study a number of these extensions and compare the credit losses for various tranches to those under the standard model. A number of these extensions are able to replicate observed prices by accounting for some observed feature overlooked by the standard model. Of these the most promising appear to be those having default and recovery rates negatively correlated. Various empirical studies have found this to hold true. Another promising advancement is in the area of stochastic correlation. The main problems with such extensions is that no single one has been adopted as standard while all require more sophisticated numerical implementation than the convenient recursive algorithm available for the standard model. Even if such problems are overcome questions still remain. No current usable model is able to provide simultaneously both a term structure of credit spreads for the portfolio and individual constituents. This prevents the valuation of the next generation of credit products. An answer may well be beyond capabilities of the now familiar copula framework which has served the market for the last decade. Dissertation (MSc) [...] University of Pretoria, 2010. Mathematics and Applied Mathematicsunrestricte...|$|R
40|$|If a {{borrower}} defaults on a loan, a bank’s recovery {{may depend}} {{on the value of}} the loan collateral. The value of collateral, like the value of other assets, fluctuates with economic conditions. If the economy experiences a downturn, a bank can experience a double misfortune: many <b>obligors</b> <b>default,</b> and the value of collateral is damaged. Conventional credit models overlook the effect of economic conditions on collateral. They allow default to vary from year to year, but they hold fixed the average value of collateral and the average level of recovery. The distinctive feature of the credit model presented here is that an economic downturn causes damage to the value of collateral. When systematic collateral damage enters the credit model, the capital allocated to a highly collateralised loan can double or triple. 1 Taking collateral damage into account complicates a credit capital model. However, the results of the model can be well approximated by a function of expected loss alone. Expected loss can therefore be used as the basis of a credit capital estimate. This estimate is simpler, and can be more accurate than using the results of a conventional credit model that ignores the role of collateral damage. Credit capital model The credit capital model uses the conditional approach suggested by Finger (1999) and Gordy (2000). The variables in the model depend on a systematic risk factor, a random variable representing the good years and bad years of the economy. The co-variation between two variables stems from their mutual dependence on the systematic factor. Two variables that relate strongly to the systematic factor relate strongly to each other and therefore have a strong correlation. Exposure of $ 1 is assumed to each obligor j. At the end of a one-year analysis horizon, the value of collateral is a random number characterised by three positive parameters: its amount, mj; its volatility, sj; and its sensitivity to X, the systematic risk factor, also known as its “loading”, qj: Collateral = µ 1 + σ...|$|R
40|$|In this {{dissertation}} we {{have investigated}} the credit risk measurement of a credit portfolio {{by means of the}} wavelets theory. Banks became subject to regulatory capital requirements under Basel Accords and also to the supervisory review process of capital adequacy, this is the economic capital. Concentration risks in credit portfolios arise from an unequal distribution of loans to single borrowers (name concentration) or different industry or regional sectors (sector concentration) and may lead banks to face bankruptcy. The Merton model is the basis of the Basel II approach, it is a Gaussian one-factor model such that default events are driven by a latent common factor that is assumed to follow the Gaussian distribution. Under this model, loss only occurs when an <b>obligor</b> <b>defaults</b> in a fixed time horizon. If we assume certain homogeneity conditions, this one-factor model leads to a simple analytical asymptotic approximation of the loss distribution function and VaR. The VaR value at a high confidence level is the measure chosen in Basel II to calculate regulatory capital. This approximation, usually called Asymptotic Single Risk Factor model (ASRF), works well for a large number of small exposures but can underestimates risks in the presence of exposure concentrations. Then, the ASRF model does not provide an appropriate quantitative framework for the computation of economic capital. Monte Carlo simulation is a standard method for measuring credit portfolio risk {{in order to deal with}} concentration risks. However, this method is very time consuming when the size of the portfolio increases, making the computation unworkable in many situations. In summary, credit risk managers are interested in how can concentration risk be quantified in short times and how can the contributions of individual transactions to the total risk be computed. Since the loss variable can take only a finite number of discrete values, the cumulative distribution function (CDF) is discontinuous and then the Haar wavelets are particularly well-suited for this stepped-shape functions. For this reason, we have developed a new method for numerically inverting the Laplace transform of the density function, once we have approximated the CDF by a finite sum of Haar wavelet basis functions. Wavelets are used in mathematical analysis to denote a kind of orthonormal basis with remarkable approximation properties. The difference between the usual sine wave and a wavelet may be described by the localization property, while the sine wave is localized in frequency domain but not in time domain, a wavelet is localized in both, frequency and time domain. Once the CDF has been computed, we are able to calculate the VaR at a high loss level. Furthermore, we have computed also the Expected Shortfall (ES), since VaR is not a coherent risk measure in the sense that it is not sub-additive. We have shown that, in a wide variety of portfolios, these measures are fast and accurately computed with a relative error lower than 1 % when compared with Monte Carlo. We have also extended this methodology to the estimation of the risk contributions to the VaR and the ES, by taking partial derivatives with respect to the exposures, obtaining again high accuracy. Some technical improvements have also been implemented in the computation of the Gauss-Hermite integration formula in order to get the coefficients of the approximation, making the method faster while the accuracy remains. Finally, we have extended the wavelet approximation method to the multi-factor setting by means of Monte Carlo and quasi-Monte Carlo methods...|$|R
40|$|The {{thesis is}} an {{investigation}} into the pricing of credit risk under the intensity framework with a copula generating <b>default</b> dependence between <b>obligors.</b> The challenge of quantifying credit risk and the derivatives that are associated with the asset class has seen an explosion of mathematical research into the topic. As credit markets developed the modelling of credit risk on a portfolio level, under the intensity framework, was unsatisfactory in that either: 1. The state variables of the intensities were driven by diffusion processes and so could not generate the observed level of default correlation (see Schönbucher (2003 a)) or, 2. When a jump component was added to the state variables, it solved the problem of low default correlation, but the model became intractable with a high number of parameters to calibrate to (see Chapovsky and Tevaras (2006)) or, 3. Use was made of the conditional independence framework (see Duffie and Garleanu (2001)). Here, conditional on a common factor, obligors’ intensities are independent. However the framework does not produce the observed level of default correlation, especially for portfolios with obligors that are dispersed in terms of credit quality. Practitioners seeking to have interpretable parameters, tractability and to reproduce observed default correlations shifted away from generating default dependence with intensities and applied copula technology to credit portfolio pricing. The one factor Gaussian copula and some natural extensions, all falling under the factor framework, became standard approaches. The factor framework is an efficient means of generating dependence between obligors. The problem with the factor framework {{is that it does not}} give a representation to the dynamics of credit risk, which arise because credit spreads evolve with time. A comprehensive framework which seeks to address these issues is developed in the thesis. The framework has four stages: 1. Choose an intensity model and calibrate the initial term structure. 2. Calibrate the variance parameter of the chosen state variable of the intensity model. 3. When extended to a portfolio of obligors choose a copula and calibrate to standard market portfolio products. 4. Combine the two modelling frameworks, copula and intensity, to produce a dynamic model that generates dependence amongst obligors. The thesis contributes to the literature in the following way: • It finds explicit analytical formula for the pricing of credit default swaptions with an intensity process that is driven by the extended Vasicek model. From this an efficient calibration routine is developed. Many works (Jamshidian (2002), Morini and Brigo (2007) and Schönbucher (2003 b)) have focused on modelling credit swap spreads directly with modified versions of the Black and Scholes option formula. The drawback of using a modified Black and Scholes approach is that pricing of more exotic structures whose value depend on the term structure of credit spreads is not feasible. In addition, directly modelling credit spreads, which is required under these approaches, offers no explicit way of simulating default times. In contrast, with intensity models, there is a direct mechanism to simulate default times and a representation of the term structure of credit spreads is given. Brigo and Alfonsi (2005) and Bielecki et al. (2008) also consider intensity modelling for the purposes of pricing credit default swaptions. In their works the dynamics of the intensity process is driven by the Cox Ingersoll and Ross (CIR) model. Both works are constrained because the parameters of the CIR model they consider are constant. This means that when there is more than one tradeable credit default swaption exact calibration of the model is usually not possible. This restriction is not in place in our methodology. • The thesis develops a new method, called the loss algorithm, in order to construct the loss distribution of a portfolio of obligors. The current standard approach developed by Turc et al. (2004) requires differentiation of an interpolated curve (see Hagan and West (2006) for the difficulties of such an approach) and assumes the existence of a base correlation curve. The loss algorithm does not require the existence of a base correlation curve or differentiation of an interpolated curve to imply the portfolio loss distribution. • Schubert and Schönbucher (2001) show theoretically how to combine copula models and stochastic intensity models. In the thesis the Schubert and Schönbucher (2001) framework is implemented by combining the extended Vasicek model and the Gaussian copula model. An analysis of the impact of the parameters of the combined models and how they interact is given. This is as follows: – The analysis is performed by considering two products, securitised loans with embedded triggers and leverage credit linked notes with recourse. The two products both have dependence on two obligors, a counterparty and a reference <b>obligor.</b> – <b>Default</b> correlation is shown to impact significantly on pricing. – We establish that having large volatilities in the spread dynamics of the reference obligor or counterparty creates a de-correlating impact: the higher the volatility the lower the impact of default correlation. – The analysis is new because, classically, spread dynamics are not considered when modelling dependence between obligors. • The thesis introduces a notion called the stochastic liquidity threshold which illustrates a new way to induce intensity dynamics into the factor framework. • Finally the thesis shows that the valuation results for single <b>obligor</b> credit <b>default</b> swaptions can be extended to portfolio index swaptions after assuming losses on the portfolio occur on a discretised set and independently to the index spread level. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
