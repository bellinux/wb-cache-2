25|14|Public
50|$|<b>Equijoin</b> in {{relational}} algebra.|$|E
50|$|In {{case the}} {{operator}} θ is the equality operator (=) then this join is also called an <b>equijoin.</b>|$|E
50|$|Hash joins {{require an}} <b>equijoin</b> {{predicate}} (a predicate comparing values from one table with values {{from the other}} table using the equals operator '=').|$|E
40|$|We {{consider}} {{the complexity of}} join problems, focusing on <b>equijoins,</b> spatial-overlap joins, and set-containment joins. We use a graph pebbling model to characterize these joins combinatorially, by the length of their optimal pebbling strategies and computationally, by the complexity of discovering these strategies. Our results show that <b>equijoins</b> are the easiest of all joins, with optimal pebbling strategies that meet the lower bound over all join problems {{and that can be}} found in linear time. By contrast, spatial-overlap and set-containment joins are the hardest joins, with instances where optimal pebbling strategies reach the upper bound over all join problems and with the problem of discovering optimal pebbling strategies being NP-complete. For set-containment joins, we show that discovering the optimal pebbling is also MAX-SNP-Complete. As a consequence, we show that unless NP = P, there is a constant ɛ 0, such that this problem cannot be approximated within a factor of 1 + ɛ 0 in polynomial time. Our results shed some light on the difficulty the applied community has had in finding “good ” algorithms for spatial-overlap and set-containment joins. 1...|$|R
40|$|When {{it comes}} to {{performing}} PROC SQL joins, users supply {{the names of the}} tables for joining along with the join conditions, and the PROC SQL optimizer determines which of the available join algorithms to use for performing the join operation. Attendees explore nested loop joins, merge joins, index joins, and hash join algorithms along with selective options to control processing. This presentation illustrates the various join algorithms; join processes including Cartesian Product joins, <b>equijoins,</b> many table joins, and outer joins...|$|R
40|$|Real systems rarely store {{all their}} data in one large table. To {{do so would}} require {{maintaining}} several duplicate copies of the same values and could threaten {{the integrity of the}} data. Instead, IT departments everywhere almost always split their data among several different tables. Because of this, a method is needed to simultaneously access two or more tables to help answer the interesting questions about our data. This presentation illustrates a variety of join processes including Cartesian Product joins, <b>equijoins,</b> many table joins, and outer joins...|$|R
50|$|The {{natural join}} is arguably {{one of the}} most {{important}} operators since it is the relational counterpart of logical AND. Note carefully that if the same variable appears in each of two predicates that are connected by AND, then that variable stands for the same thing and both appearances must always be substituted by the same value. In particular, natural join allows the combination of relations that are associated by a foreign key. For example, in the above example a foreign key probably holds from Employee.DeptName to Dept.DeptName and then the natural join of Employee and Dept combines all employees with their departments. Note that this works because the foreign key holds between attributes with the same name. If this is not the case such as in the foreign key from Dept.manager to Employee.Name then we have to rename these columns before we take the natural join. Such a join is sometimes also referred to as an <b>equijoin</b> (see θ-join).|$|E
40|$|Literature on {{information}} integration across databases tacitly {{assumes that the}} data in each database can be revealed to the other databases. However, there is an increasing need for sharing information across autonomous entities {{in such a way}} that no information apart from the answer to the query is revealed. We formalize the notion of minimal information sharing across private databases, and develop protocols for intersection, <b>equijoin,</b> intersection size, and <b>equijoin</b> size. We also show how new applications can be built using the proposed protocols. 1...|$|E
40|$|Malaysian Hydrological Information System (MHIS) {{is one of}} the GIS {{applications}} that storing a large amount of data (such as rainfall, water level, evaporation and water quality). In such situation, it is important to ensure that the storage, retrieval and manipulation of these data are efficiently handled. However, the problem in MHIS is inefficient on retrieval data where {{it takes a long time}} to retrieve data. MHIS was developed based on cube system concept. The main objective introduced the cube system is to describe how the hydrology data will be store and retrieve in relational database. However, it is still lacking to handle a large amount of data. Thus, this paper proposed an <b>Equijoin</b> Optimization Technique to solve that problem. This technique was introduced based on modification of an <b>equijoin</b> method where an entity will be joined based on <b>equijoin</b> algorithm. In other words, the result relation is a new entity, T, contains tuples t made up of two tuples r and s, where r must be tuple in entity R and s must be tuple in entity S. Then, there are entity will be classified to other entity based on the appropriate attribute. Based on this technique, a SQL statement was created for data retrieval processing which is referring to the optimized entity. There are four main function in that process i) Select ii) Initialize iii) Operation and iv) Output. Also, in this research, testing and comparison analysis has been done between proposed technique, an <b>Equijoin</b> optimization and the previous technique MHIS Cube System. The result of the testing shows that the proposed technique can improve an execution time for query processing, then solve the issue has been discussed on this research...|$|E
40|$|On the {{complexity}} of division and set joins in the relational algebra We show that any expression of the relational division operator in the relational algebra with union, difference, projection, selection, and <b>equijoins,</b> must produce intermediate results of quadratic size. To prove this result, we show a dichotomy theorem about intermediate sizes of relational algebra expressions (they are either all linear, {{or at least one}} is quadratic); we link linear relational algebra expressions to expressions using only semijoins instead of joins; and we link these semijoin algebra expressions to the guarded fragment of first-order logic. 1...|$|R
40|$|Abstract — When a {{database}} system is extended with the skyline operator, {{it is important}} to determine {{the most efficient way to}} execute a skyline query across tables with join operations. This paper describes a framework for evaluating skylines in the presence of <b>equijoins,</b> including: (1) the development of algorithms to answer such queries over large input tables in a non-blocking, pipeline fashion, which significantly speeds up the entire query evaluation time. These algorithms are built on top of the traditional relational Nested-Loop and the Sort-Merge join algorithms, which allows easy implementation of these methods in existing relational systems; (2) a novel method for estimating the skyline selectivity of the joined table; (3) evaluation of skyline computation based on the estimation method and the proposed evaluation techniques; and (4) a systematic experimental evalu-ation to validate our skyline evaluation framework. I...|$|R
40|$|A non-equijoin of {{relations}} R and S is a band join if the join predicate requires {{values in the}} join attribute of R to fall within a specified band about the values in the join attribute of S. This paper describes a new algorithm, termed a truncating-hash band join, for evaluating band joins. This algorithm {{is based on the}} idea of truncating join attribute values in order to execute band joins in a way similar to hash join algorithms for <b>equijoins.</b> Unlike previously proposed algorithms for band joins, it does not sort either of the input relations during its execution. We present a comparison between the truncating-hash band join algorithm and previous algorithms for band joins using an analytical model. The model also compares an evaluation of band join algorithms for a parallel implementation on a "shared-nothing" multiprocessor system. The results show that the truncating-hash band join algorithm outperforms the other band join algorithms because of a significantly lower CPU cost. [...] ...|$|R
40|$|It {{is shown}} {{that the use of}} an {{adjusted}} algorithm can improve the performance of a nested query execution containing join operations. Apart from the <b>equijoin,</b> the union, Cartesian product, Θ-join, and intersection operations can be implemented in a pipelining way. The difference, however, cannot be implemented in this way. The proposed algorithms are implemented in PRISMA/D...|$|E
40|$|In a {{relational}} database {{submitted to a}} sequence of queries and updates, we show that we can describe a couple of relations by a bidimensional stochastic process. We then prove {{that the size of}} their <b>equijoin</b> or semijoin can be described asymptotically by a gaussian, non-markovian process. Keywords: {{relational database}}, derived relation, gaussian process, join size. 1 Introduction This paper is a sequel to the first paper [3], which deals with projections. Here we consider joins: <b>equijoin</b> and semijoin. The first paper will be denoted by GL. The present paper is organized as follows. Section 2 presents the joins and urns models, Section 3 describes the new two-dimensional processes related to the total number of balls. Section 4 deals with a preliminary lemma (generalizing Lemma 1 of GL). Section 5 analyzes the non-random static structure related to the the join model. Section 6 presents the main result of this paper, corresponding to the complete random structure. Section 7 conclude [...] ...|$|E
40|$|While the {{explosion}} of availability of information has become invaluable in modern society, it has also raised valid concerns about erosion of privacy. More and more, different entities are encouraged to share information in order to discover potential security risks, health pattern, or social behavior trends. However, some of this information is sensitive. Owners of information may be unwilling to share their whole databases with other entities, either to protect {{the privacy of the}} records, or because of the proprietary nature of the information. ^ We consider the following problem. How can we compute the intersection and the <b>equijoin</b> of databases owned by different parties, while revealing as little additional information as possible? One can address this challenge in different ways. Some protocols use trusted third parties, whereas some rely on the use of cryptographic techniques to achieve their goal without the use of a third party. An example of such an approach is a protocol proposed by Agrawal, Evfimievski and Srikant. In this thesis, we extend their protocol to apply to the intersection and the <b>equijoin</b> of three databases owned by three different entities. We also demonstrate the protocol with an implementation. ...|$|E
40|$|Query {{answers from}} servers {{operated}} by third parties {{need to be}} verified, as the third parties may not be trusted or their servers may be compromised. Most of the existing authentication methods construct validity proofs based on the Merkle hash tree (MHT). The MHT, however, imposes severe concurrency constraints that slow down data updates. We introduce a protocol, built upon signature aggregation, for checking the authenticity, completeness and freshness of query answers. The protocol offers the important property of allowing new data to be disseminated immediately, while ensuring that outdated values beyond a pre-set age can be detected. We also propose an efficient verification technique for ad-hoc <b>equijoins,</b> for which no practical solution existed. In addition, for servers that need to process heavy query workloads, we introduce a mechanism that significantly reduces the proof construction time by caching just {{a small number of}} strategically chosen aggregate signatures. The efficiency and efficacy of our proposed mechanisms are confirmed through extensive experiments. 1...|$|R
40|$|Abstract This paper {{presents}} GMP, {{a library}} for generic, SQL-style programming with multisets. It generalizes the querying core of SQL {{in a number}} of ways: Multisets may contain elements of arbitrary first-order data types, including references (pointers), recursive data types and nested multisets; it contains an expressive embedded domain-specific language for specifying user-definable equivalence and ordering relations, extending the built-in equality and inequality predicates; it admits mapping arbitrary functions over multisets, not just projections; it supports user-defined predicates in selections; and it allows user-defined aggregation functions. Most significantly, it avoids many cases of asymptotically inefficient nested iteration through Cartesian products that occur in a straightforward stream-based implementation of multisets. It accomplishes this by employing two novel techniques: symbolic (term) representations of multisets, specifically for Cartesian products, for facilitating dynamic symbolic computation, which intersperses algebraic simplification steps with conventional data processing; and discrimination-based joins, a generic technique for computing <b>equijoins</b> based on equivalence discriminators, as an alternative to hash-based and sort-merge joins...|$|R
40|$|Differential privacy {{promises}} to enable general data analytics while protecting individual privacy, but existing differential privacy mechanisms {{do not support}} the wide variety of features and databases used in real-world SQL-based analytics systems. This paper presents the first practical approach for differential privacy of SQL queries. Using 8. 1 million real-world queries, we conduct an empirical study to determine the requirements for practical differential privacy, and discuss limitations of previous approaches in light of these requirements. To meet these requirements we propose elastic sensitivity, a novel method for approximating the local sensitivity of queries with general <b>equijoins.</b> We prove that elastic sensitivity is an upper bound on local sensitivity and can therefore be used to enforce differential privacy using any local sensitivity-based mechanism. We build FLEX, a practical end-to-end system to enforce differential privacy for SQL queries using elastic sensitivity. We demonstrate that FLEX is compatible with any existing database, can enforce differential privacy for real-world SQL queries, and incurs negligible (0. 03 %) performance overhead...|$|R
40|$|This paper proposes {{the system}} {{enabling}} users to use heterogeneous databases {{in an integrated}} manner without any conversion and servers. In order to treat {{a variety of sources}} in a unified manner, this system is realized by using Java Database Connectivity (JDBC) in accessing databases on the user’s computer. It also joins and/or projects them as required. The syntax identifying a kind of database or file is introduced. The system maintains data by using ArrayLists in Java. It is experimentally shown that there is no practical problem in the <b>equijoin</b> of three tables having 100, 000 rows in heterogeneous databases...|$|E
40|$|As {{computer}} clusters {{are found}} to be highly effective for handling massive datasets, the design of efficient parallel algorithms for such a computing model is of great interest. We consider (α, k) -minimal algorithms for such a purpose, where α is the number of rounds in the algorithm, and k is a bound on the deviation from perfect workload balance. We focus on new (α, k) -minimal algorithms for sorting and skew <b>equijoin</b> operations for computer clusters. To {{the best of our knowledge}} the proposed sorting and skew join algorithms achieve the best workload balancing guarantee when compared to previous works. Our empirical study shows that they are close to optimal in workload balancing. In particular, our proposed sorting algorithm is around 25...|$|E
40|$|Interest in {{incremental}} {{and adaptive}} query processing {{has led to}} the investigation of <b>equijoin</b> evaluation algorithms that are non-blocking. This investigation has yielded a number of algorithms, including the symmetric hash join, the XJoin, the Ripple Join, and their variants. However, to our knowledge no one has proposed a nonblocking spatial join algorithm. In this paper, we propose a parallel non-blocking spatial join algorithm that uses duplicate avoidance rather than duplicate elimination. Results from a prototype implementation in a commercial parallel object-relational DBMS show that it generates answer tuples steadily even in the presence of memory overflow, and that its rate of producing answer tuples scales with the number of processors. Also, when allowed to run to completion, its performance is comparable with the state-of-the-art blocking parallel spatial join algorithm. 1...|$|E
40|$|AbstractWe {{consider}} a bottom-up query-evaluation scheme in which facts of relations {{are allowed to}} have nonground terms. The magic-sets query- rewriting technique is generalized to allow arguments of predicates {{to be treated as}} bound even though the rules do not provide ground bindings for those arguments. In particular, we regard as “bound” any argument containing a function symbol or a variable that appears more than once in the argument list. Generalized “magic” predicates are thus defined to compute the set of all goals reached in a top-down exploration of the rules, starting from a given query goal; these goals are not facts of constants as in previous versions of the magic-sets algorithm. The magic predicates are then used to restrict a bottom-up evaluation of the rules so that there are no redundant actions; that is, every step of the bottom-up computation must be performed by any algorithm that uses the same sideways information-passing strategy (sips). The price paid, compared to previous versions of Magic Sets, is that we must store relations with nonground facts, and we must perform unifications, rather than <b>equijoins,</b> when evaluating the rules bottom-up. The method is applicable to general Horn-clause logic programs...|$|R
40|$|We present four {{efficient}} parallel algorithms for computing a nonequijoin, called range-join, of two relations on N-dimensional mesh-connected computers. Range-joins {{of relations}} R and S {{are an important}} generalization of conventional <b>equijoins</b> and band-joins and are solved by permutation-based approaches in all proposed algorithms. In general, after sorting all subsets of both relations, the proposed algorithms permute every sorted subset of relation S to each processor in turn, where it is joined with the local subset of relation R. To permute the subsets of S efficiently, we propose two data permutation approaches, namely, the shifting approach which permutes the data recursively from lower dimensions to higher dimensions and the Hamiltonian-cycle approach which first constructs a Hamiltonian cycle on the mesh and then permutes the data along this cycle by repeatedly transferring data from each processor to its successor. We apply the shifting approach to meshes with different storage capacities which results in two different join algorithms. The basic shifting join (BASHJ) algorithm can minimize the number of subsets stored temporarily at a processor, but requires {{a large number of}} data transmissions, while the buffering shifting join (BUSHJ) algorithm can achieve a high parallelism and minimize the number of data transmissions, but requires a large number of subsets stored at each processorFull Tex...|$|R
40|$|Copyright © 2002 IEEEWe present four {{efficient}} parallel algorithms for computing a nonequijoin, called range-join, of two relations on N-dimensional mesh-connected computers. Range-joins {{of relations}} R and S {{are an important}} generalization of conventional <b>equijoins</b> and band-joins and are solved by permutation-based approaches in all proposed algorithms. In general, after sorting all subsets of both relations, the proposed algorithms permute every sorted subset of relation S to each processor in turn, where it is joined with the local subset of relation R. To permute the subsets of S efficiently, we propose two data permutation approaches, namely, the shifting approach which permutes the data recursively from lower dimensions to higher dimensions and the Hamiltonian-cycle approach which first constructs a Hamiltonian cycle on the mesh and then permutes the data along this cycle by repeatedly transferring data from each processor to its successor. We apply the shifting approach to meshes with different storage capacities which results in two different join algorithms. The basic shifting join (BASHJ) algorithm can minimize the number of subsets stored temporarily at a processor, but requires {{a large number of}} data transmissions, while the buffering shifting join (BUSHJ) algorithm can achieve a high parallelism and minimize the number of data transmissions, but requires a large number of subsets stored at each processor. Shao Dong Chen, Hong Shen, and Rodney Topo...|$|R
40|$|We study {{algorithms}} for computing the <b>equijoin</b> of two {{relations in}} B {{system with a}} standard architecture hut with large amounts of main memory. Our algorithms are especially efficient when the main memory available is B significant fraction {{of the size of}} one of the relations to he joined; hut they can be applied whenever there is memory equal to approximately the 8 qume root of the size of one relation. We present a new algorithm which is B hybrid of two hash-based algorithms and which dominates the other algorithma we present, including sort-merge. Even in B virtual memory environment, the hybrid algorithm dominates all the others we study. Finally, we describe how three popular tools to increase the efficiency ofjoins, namely filters, Babb arrays, and semijoins, can he grafted onto any of our algorithms...|$|E
40|$|This paper {{examines}} the parallel processing of exclusion {{join in a}} shared-nothing multiprocessor environment. First, a parallel hash-based exclusion join algorithm is presented. Unlike the case of <b>equijoin,</b> this algorithm does not work correctly {{in the presence of}} nulls in the join attributes. One solution is to restrict the hash-on attributes to non-nullable fields. However, this can lead to the well known data skew problem. If the number of tuples containing null values in their join attributes is small, an alternative is to replicate those tuples to all processors. Otherwise, we can consider a range partitioning algorithm where those tuples are only sent to a small subset of the processors. The hash-based algorithm usually outperforms the range partitioning algorithm except when the number of tuples containing null values in their join attributes is large or when the data is highly skewed...|$|E
40|$|<b>Equijoin</b> {{between two}} {{relations}} {{is one of}} the basic operations in relational database and a large volume of research have been devoted to it. However, in recent years, there hasn't been a survey which objectively compares a wide spectrum of various join techniques in their relative performances. This survey compares performance and practicality between various join techniques. Main criteria for performance comparisons are disk I/Os. For comparing of practicality, criteria used are easiness and flexibility of implementation. When comparing join techniques, each join technique is evaluated in its full potential, which means that if other techniques are available to enhance this join technique while retaining the main philosophy of it, the later techniques are applied. The main contribution of the paper is that it confirms the believe that no dramatical performance improvement of three major join techniques (nested loops, sort-based, and hash based) of relational database can b [...] ...|$|E
40|$|We {{optimize}} multiway <b>equijoins</b> on relational tables using degree information. We give a new bound {{that uses}} degree information to more tightly bound the maximum output {{size of a}} query. On real data, our bound {{on the number of}} triangles in a social network can be up to 95 times tighter than existing worst case bounds. We show that using only a constant amount of degree information, we are able to obtain join algorithms with a running time that has a smaller exponent than existing algorithms - for any database instance. We also show that this degree information can be obtained in nearly linear time, which yields asymptotically faster algorithms in the serial setting and lower communication algorithms in the MapReduce setting. In the serial setting, the data complexity of join processing can be expressed as a function O(IN^x + OUT) in terms of input size IN and output size OUT in which x depends on the query. An upper bound for x is given by fractional hypertreewidth. We are interested in situations in which we can get algorithms for which x is strictly smaller than the fractional hypertreewidth. We say that a join can be processed in subquadratic time if x < 2. Building on the AYZ algorithm for processing cycle joins in quadratic time, for a restricted class of joins which we call 1 -series-parallel graphs, we obtain a complete decision procedure for identifying subquadratic solvability (subject to the 3 -SUM problem requiring quadratic time). Our 3 -SUM based quadratic lower bound is tight, making it the only known tight bound for joins that does not require any assumption about the matrix multiplication exponent omega. We also give a MapReduce algorithm that meets our improved communication bound and handles essentially optimal parallelism...|$|R
40|$|AbstractÐIn this paper, {{we present}} four {{efficient}} parallel algorithms for computing a nonequijoin, called range-join, of two relations on N-dimensional mesh-connected computers. Range-joins of relations R and S {{are an important}} generalization of conventional <b>equijoins</b> and band-joins and are solved by permutation-based approaches in all proposed algorithms. In general, after sorting all subsets of both relations, the proposed algorithms permute every sorted subset of relation S to each processor in turn, where it is joined with the local subset of relation R. To permute the subsets of S efficiently, we propose two data permutation approaches, namely, the shifting approach which permutes the data recursively from lower dimensions to higher dimensions and the Hamiltonian-cycle approach which first constructs a Hamiltonian cycle on the mesh and then permutes the data along this cycle by repeatedly transferring data from each processor to its successor. We apply the shifting approach to meshes with different storage capacities which results in two different join algorithms. The Basic Shifting Join �BASHJ) algorithm can minimize the number of subsets stored temporarily at a processor, but requires {{a large number of}} data transmissions, while the Buffering Shifting Join �BUSHJ) algorithm can achieve a high parallelism and minimize the number of data transmissions, but requires a large number of subsets stored at each processor. For constructing a Hamiltonian cycle on a mesh, we propose two different methods which also result in two different join algorithms. The Recursive Hamiltonian-Cycle Join �REHCJ) algorithm uses a single processor to construct a Hamiltonian cycle recursively, while the Parallel Hamiltonian-Cycle Join �PAHCJ) algorithm uses all processors to construct a Hamiltonian cycle in parallel. We analyze and compare these algorithms. The results shows that both Hamiltonian cycle algorithms require less storage and local join operations than the shifting algorithms, but more data movement steps. Index TermsÐAnalysis of algorithms, data permutation, N-dimensional meshes, relational databases, parallel processing, performance, range-join operations. ...|$|R
40|$|Much {{recent work}} has {{focussed}} on the bottomup evaluation of Datalog programs. One approach, called magic-sets, {{is based on}} rewriting a logic program so that bottom-up fixpoint evaluation of the program avoids generation of irrelevant facts ([BMSU 86, BR 87, Ram 88]). It is widely believed that the principal application of the magicsets technique is to restrict computation in recursive queries using <b>equijoin</b> predicates. We extend the magic-sets transformation to use predicates other than equality (X ? 10, for example). This Extended Magic-Set technique has practical utility in "real" relational databases, not only for recursive queries, but for non-recursive queries as well; in ([MFPR 90]) we use the results in this paper and those in [MPR 90] to define a magic-set transformation for relational databases supporting SQL and its extensions, going on to describe an implementation of magic in Starburst ([HFLP 89]). We also give preliminary performance measurements. In extending magic-sets, we des [...] ...|$|E
40|$|This paper {{presents}} a new data structure for multiway and general join query acceleration, the hit-list, and an algorithm for its use. The hit-list is a surrogate index providing the mapping between {{the values of}} two attributes in a relation participating in an <b>equijoin</b> or a selection. The results of an analytical model, simulation study, and an implementation are presented. The performance advantages of this approach are made clear, {{as well as the}} basis for these results in the attainment of full selectivity. Extensions of hit-lists are also examined. 1. Introduction This paper {{presents a}} new data structure, the hit-list, which can be used to accelerate complex queries. The hit-list acceleration method is developed and applied to multi-way joins in which not all of the joining attributes are the same. An analytical model was developed which compared the response time of a multi-way join algorithm using hit-lists with the performance of an algorithm not using hit-lists. The comparison [...] ...|$|E
40|$|The {{efficiency}} of database join operations depends crucially on how page fetches are scheduled. In general, finding an optimum schedule is NP-hard. We show {{that for a}} class of popular spatial clustering techniques used for spatial data structures, an optimum page fetch schedule that holds two pages in main memory can be computed in time linear in {{the length of the}} schedule. In full generality, we prove spatial join scheduling to be NP-hard. 1 Introduction and Overview In databases in general and spatial databases in particular, join processing {{is one of the most}} expensive operations. One of the reasons is that for large databases, main memory capacity is a bottleneck: Pages may need to be fetched from disk more than once in order to compute a join. Since disk access time usually is the dominant part of the join computation time, it pays to schedule disk accesses carefully. This is not always easy: For two relations on disk, where each page contains a set of tuples, and an <b>equijoin</b> o [...] ...|$|E
40|$|Part 4 : Protection and Privacy of Data and Big DataInternational audienceData {{outsourcing}} allows data {{owners to}} keep their data in public clouds, which do not ensure the privacy of data and computations. One fundamental and useful framework for processing data in a distributed fashion is MapReduce. In this paper, we investigate and present techniques for executing MapReduce computations in the public cloud while preserving privacy. Specifically, we propose a technique to outsource a database using Shamir secret-sharing scheme to public clouds, and then, provide privacy-preserving algorithms for performing search and fetch, <b>equijoin,</b> and range queries using MapReduce. Consequently, in our proposed algorithms, the public cloud cannot learn the database or computations. All the proposed algorithms eliminate {{the role of the}} database owner, which only creates and distributes secret-shares once, and minimize the role of the user, which only needs to perform a simple operation for result reconstructing. We evaluate the efficiency by (i)  the number of communication rounds (between a user and a cloud), (ii)  the total amount of bit flow (between a user and a cloud), and (iii)  the computational load at the user-side and the cloud-side...|$|E
40|$|Abstract. Joins are {{arguably the}} most {{important}} relational operators. Poor implementations are tantamount to computing the Cartesian product of the input relations. In a temporal database, the problem is more acute for two reasons. First, conventional techniques are designed {{for the evaluation of}} joins with equality predicates rather than the inequality predicates prevalent in valid-time queries. Second, the presence of temporally varying data dramatically increases the size of a database. These factors indicate that specialized techniques are needed to efficiently evaluate temporal joins. We address this need for efficient join evaluation in temporal databases. Our purpose is twofold. We first survey all previously proposed temporal join operators. While many temporal join operators have been defined in previous work, this work has been done largely in isolation from competing proposals, with little, if any, comparison of the various operators. We then address evaluation algorithms, comparing the applicability of various algorithms to the temporal join operators and describing a performance study involving algorithms for one important operator, the temporal <b>equijoin.</b> Our focus, with respect to implementation, is on non-index-based join algorithms. Such algorithms do not rely on auxiliary access paths but may exploit sort orderings to achieve efficiency...|$|E
40|$|The query {{models of}} the recent {{generation}} of very large scale distributed (VLSD) shared-nothing data storage systems, including our own PNUTS and others (e. g. BigTable, Dynamo, Cassandra, etc.) are intentionally simple, focusing on simple lookups and scans and trading query expressiveness for massive scale. Indexes and views can expand the query expressiveness of such systems by materializing more complex access paths and query results. In this paper, we examine mechanisms to implement indexes and views in a massive scale distributed database. For web applications, minimizing update latencies is critical, so we advocate deferring the work of maintaining views and indexes as much as possible. We examine the design space, and conclude that two types of view implementations, called remote view tables (RVTs) and local view tables (LVTs), provide a good tradeoff between system throughput and minimizing view staleness. We describe how to construct and maintain such view tables, {{and how they can}} be used to implement indexes, group-by-aggregate views, <b>equijoin</b> views and selection views. We also introduce and analyze a consistency model that makes it easier for application developers to cope with the impact of deferred view maintenance. An empirical evaluation quantifies the maintenance costs of our views, and shows that they can significantly improve the cost of evaluating complex queries...|$|E
40|$|Under {{either the}} or-semantics or the weak semantics, {{the answer to}} a query over semistructured data {{consists}} of maximal rather than complete matchings, i. e., some query variables may be assigned null values. In the relational model, a similar effect is achieved by computing the full disjunction (rather than the natural join or <b>equijoin)</b> of the given relations. It is shown that under either the or-semantics or the weak semantics, query evaluation has a polynomial-time complexity {{in the size of the}} query, the database and the result. It is also shown that the evaluation of full disjunctions is reducible to query evaluation under the weak semantics and hence can be done in polynomial time in the size of the input and the output. Complexity results are also given for two related problems. One is evaluating a projection of the full disjunction and the other is evaluating the set of all tuples in the full disjunction that are non-null on some given attributes. In the special case of γ-acyclic relation schemes, both problems have polynomial-time algorithms in the size of the input and the output. In the general case, such algorithms do not exist, assuming that P = NP. Finally, it is shown that the weak semantics can generalize full disjunctions by allowing tuples to be joined according to general types of conditions, rather than just equalities among attributes. 1...|$|E
