876|1112|Public
5|$|Most {{variants}} of the AW101 {{are equipped with}} self-defence systems, such as chaff and flare dispensers, directed infrared countermeasures (infrared jammers), ESM (electronic support measures {{in the form of}} RF heads), and a laser detection and warning system. British Merlins have been outfitted with protective armour against small-arms fire. A chin-mounted forward looking infrared (FLIR) <b>imaging</b> <b>sensor</b> has been fitted to some variants.|$|E
25|$|Since {{then the}} number of megapixels in imaging sensors have {{increased}} steadily, with most companies focusing on high ISO performance, speed of focus, higher frame rates, the elimination of digital 'noise' produced by the <b>imaging</b> <b>sensor,</b> and price reductions to lure new customers.|$|E
25|$|In {{addition}} to ground-based lightning detection, several instruments aboard satellites {{have been constructed}} to observe lightning distribution. These include the Optical Transient Detector (OTD), aboard the OrbView-1 satellite launched on April 3, 1995, and the subsequent Lightning <b>Imaging</b> <b>Sensor</b> (LIS) aboard TRMM launched on November 28, 1997.|$|E
30|$|Traditional <b>imaging</b> <b>sensors,</b> such as {{visible and}} {{infrared}} cameras or laser radar systems, {{may have a}} reduced performance in adverse weather conditions, like fog [1 – 3]. Furthermore, in defense and security scenarios, smoke screens [4] may literally blind these <b>imaging</b> <b>sensors</b> based on very short wavelengths.|$|R
5000|$|... 3D {{modeling}} and tracking of clouds from satellite and terrestrial <b>imaging</b> <b>sensors</b> ...|$|R
40|$|Modern {{service robots}} {{need to be}} able to "see" the world. In order to design a {{perception}} system for robots modern range <b>imaging</b> <b>sensors</b> are used in conjunction with traditional colour <b>imaging</b> <b>sensors.</b> Two recognition systems build on this: a trainable object detector and a human kinematics reconstruction algorithm that can be used e. g. for gesture recognition...|$|R
25|$|Shallow-water {{operations}} require generalizing IR imaging {{to include}} a non-developmental Thermal <b>Imaging</b> <b>Sensor</b> System (TISS) to surface ships with a day/night, high-resolution, infrared (IR) and visual imaging, and laser range-finder capability to augment existing optical and radar sensors, especially against small boats and floating mines. Similar systems are now available in Army helicopters and armored fighting vehicles.|$|E
25|$|Sony has {{modified}} the DSLR formula {{in favor of}} single-lens translucent (SLT) cameras, which are still technically DSLRs, but feature a fixed mirror that allows most light through to the sensor while reflecting some light to the autofocus sensor. Sony's SLTs feature full-time phase detection autofocus during video recording as well as continuous shooting of up to 12 frame/s. The α series, whether traditional SLRs or SLTs, offers in-body sensor-shift image stabilization and retains the Minolta AF lens mount. , the lineup included the Alpha 68, the semipro Alpha 77 II, and the professional full-frame Alpha 99 II. The translucent (transmissive) fixed mirror allows 70 percent of the light to pass through onto the <b>imaging</b> <b>sensor,</b> meaning a 1/3rd stop loss light, {{but the rest of}} this light is continuously reflected onto the camera's phase detection AF sensor for fast autofocus for both the viewfinder and live view on the rear screen, even during video and continuous shooting. The reduced number of moving parts also makes for faster shooting speeds for its class. This arrangement means that the SLT cameras use an electronic viewfinder as opposed to an optical viewfinder, which some consider a disadvantage, but does have the advantage of a live preview of the shot with current settings, anything displayed on the rear screen is displayed on the viewfinder, and handles bright situations well.|$|E
2500|$|A digital single-lens {{reflex camera}} (also called a digital SLR or DSLR) is {{a digital camera}} that {{combines}} the optics and the mechanisms of a single-lens reflex camera with a digital <b>imaging</b> <b>sensor,</b> as opposed to photographic film. The reflex design scheme is the primary difference between a DSLR and other digital cameras. In the reflex design, light travels through the lens, then to a mirror that alternates to send the image to either the viewfinder or the image sensor. The traditional alternative {{would be to have}} a viewfinder with its own lens, hence the term [...] "single lens" [...] for this design. By using only one lens, the viewfinder of a DSLR presents an image that will not differ substantially from what is captured by the camera's sensor. A DSLR differs from non-reflex single-lens digital cameras in that the viewfinder presents a direct optical view through the lens, rather than being captured by the camera's image sensor and displayed by a digital screen.|$|E
40|$|Electro-optical <b>imaging</b> <b>sensors</b> {{form the}} {{principal}} devices that are typically {{used to obtain}} images of earth from satellite platforms, and substantial improvements in optics, electro-optical detection devices, cooling subsystems and composite structures have enabled the high quality performance exhibited by the current instrumentation. This paper reviews the fundamentals of system design for <b>imaging</b> <b>sensors</b> such as the Thematic Mapper on board Landsat, points out the key areas of current R&D, and briefly alludes to some important applications...|$|R
5000|$|With {{the advance}} of the digital <b>imaging</b> <b>sensors,</b> the same ETTR {{technique}} may be applicable to scenes with relatively high dynamic range (DR) (high-contrast, containing both very bright highlights and deep shadows, harshly-lit scenes), previously {{in the domain of}} HDR (High Dynamic Range) techniques involving multiple exposures. The better of the recent photographic <b>imaging</b> <b>sensors</b> of the 35 mm [...] "full-frame" [...] format, as of 2015, can accommodate up to about 14 stops of engineering dynamic range or 11.5 stops of useful photographic dynamic range in the raw shooting mode.|$|R
30|$|Multi-sensor—Image {{collection}} {{from multiple}} <b>imaging</b> <b>sensors</b> could {{be appropriate for}} mitigating degrading factors from uncontrollable and personalized attributes. Fusion could {{be done on the}} image features for age estimation.|$|R
5000|$|... #Subtitle level 3: Interferometric {{reflectance}} <b>imaging</b> <b>sensor</b> ...|$|E
50|$|NICMOS is {{also the}} name of the devices's 256×256-pixel <b>imaging</b> <b>sensor</b> built by Rockwell International Electro-Optical Center (now DRS Technologies).|$|E
5000|$|In 2007 this {{camcorder}} had {{the largest}} <b>imaging</b> <b>sensor</b> for a consumer camcorder, 1/2.5". Other distinguishing features of this camcorder include: ...|$|E
50|$|The SkySat {{satellites}} {{are based}} on the CubeSat concept with optimized design using inexpensive automotive grade electronics, as well as fast commercially available processors. The cameras use two-dimensional <b>imaging</b> <b>sensors.</b>|$|R
5000|$|... 2009: Willard S. Boyle, George E. Smith {{shared the}} Nobel Prize in Physics with Charles K. Kao. Boyle and Smith were cited for inventing {{charge-coupled}} device (CCD) semiconductor <b>imaging</b> <b>sensors.</b>|$|R
50|$|His {{research}} interests include molecular <b>imaging</b> <b>sensors</b> {{for the study of}} redox biology and metals, especially as applied to neuroscience and immunology, metal catalysts for renewable energy cycles, and green chemistry.|$|R
50|$|Some common {{applications}} of foveated imaging include <b>imaging</b> <b>sensor</b> hardwareand image compression.For descriptions {{of these and}} other applications, see the list below.|$|E
50|$|Georgian army {{upgraded}} T-72SIM-1 {{tanks are}} using Drawa-T fire control system, a {{development of the}} fire control system on PT-91. The FCS is equipped with laser range finder and thermal <b>imaging</b> <b>sensor.</b> The system is slightly {{different from the one}} used on Polish PT-91s, commander is using an LCD screen instead of the eyepiece. The Thermal Elbow Sight thermal <b>imaging</b> <b>sensor</b> used in Georgian tanks is of the same (Israeli) origin as the one used on PT-91 but the external housing is different.|$|E
5000|$|TTL {{metering}} {{systems have}} been incorporated into other types of cameras as well. Most digital [...] "point-and-shoot cameras" [...] use TTL metering, performed by the <b>imaging</b> <b>sensor</b> itself.|$|E
30|$|In smart {{lighting}} systems, {{the sensors}} being used can be generally {{divided into two}} categories: <b>imaging</b> <b>sensors</b> and non-imaging sensors. The computer vision community usually employs <b>imaging</b> <b>sensors</b> such as cameras and depth sensors to capture images, videos, and depth maps of the scene. An image, whether gray-level, RGB, or depth, has a 2 D structure, which describes the spatial distribution of objects or people in the space. A great deal of high-level information can be inferred from such data with computer vision and pattern recognition methods, which enable various applications such as object detection and tracking, event detection, and traffic surveillance.|$|R
50|$|Infrared image sensors include {{active and}} passive systems. For active sensing, IR <b>imaging</b> <b>sensors</b> {{typically}} scan a laser {{across the field}} of view of a scene and look for backscattered light at the absorption line wavelength of a specific target gas. Passive IR <b>imaging</b> <b>sensors</b> measure spectral changes at each pixel in an image and look for specific spectral signatures that indicate the presence of target gases. The types of compounds that can be imaged are the same as those that can be detected with infrared point detectors, but the images may be helpful in identifying the source of a gas.|$|R
40|$|Abstract — Target {{detection}} and localization {{is one of}} the key research challenges in sensor networks. In this paper we propose a heterogeneous wireless <b>sensor</b> network integrating <b>imaging</b> and non-imaging <b>sensors</b> to accomplish the {{detection and}} localization task in complex urban environments. The lowcost non-imaging sensors provide early detection and partial localization of potential targets and direct <b>imaging</b> <b>sensors</b> to focus on them. Accurate target location estimated by the <b>imaging</b> <b>sensors</b> is subsequently used for in-situ calibration of the non-imaging sensors so that localization error is minimized over time. We evaluate our approach through simulation and our preliminary results reveal that coordination across different sensing modalities increases localization accuracy and can reduce the amount of imaging data that must be carried by the network. I...|$|R
50|$|The AN/AAQ-26 is {{a second}} {{generation}} infrared detection set manufactured by Raytheon. The infrared detecting set is a high-performance multipurpose thermal <b>imaging</b> <b>sensor,</b> providing long-range navigation, surveillance, and fire control capabilities.|$|E
50|$|The camera's {{features}} were fairly impressive at launch including a 10x optical zoom, a 5.1-megapixel CCD <b>imaging</b> <b>sensor</b> {{as well as}} a host of manual settings which did not exist on Compact cameras.|$|E
5000|$|... #Caption: World map showing {{frequency}} of lightning strikes, in flashes per km² per year (equal-area projection), from combined 1995-2003 {{data from the}} Optical Transient Detector and 1998-2003 data from the Lightning <b>Imaging</b> <b>Sensor.</b>|$|E
50|$|The LCH's modern sensor suite, {{developed}} {{in cooperation with}} Israel, consists of a CCD Camera, forward-looking infrared <b>imaging</b> <b>sensors</b> and a laser range finder to facilitate target acquisition in all weather conditions, including at night.|$|R
50|$|Like {{structurally}} similar {{lead zirconate titanate}} and barium strontium titanate, PST can be {{used for}} manufacture of uncooled focal plane array infrared <b>imaging</b> <b>sensors</b> for thermal cameras. Both bulk and thin film structures are used.|$|R
50|$|Fixed-pattern noise (FPN) is {{the term}} given to a {{particular}} noise pattern on digital <b>imaging</b> <b>sensors</b> often noticeable during longer exposure shots where particular pixels are susceptible to giving brighter intensities above the general background noise.|$|R
50|$|The camera {{includes}} a manual focus wheel, mic and headphone jacks, {{and a slightly}} larger <b>imaging</b> <b>sensor,</b> producing 3200K gross pixels versus the HC5' 2100K. The HC7 also sports Sony's Super SteadyShot Optical Image Stabilization System.|$|E
5000|$|Both CMOS and LBCAST {{technologies}} branched from researchers {{discussions of}} [...] "amplifying sensors" [...] {{as a way}} to develop an <b>imaging</b> <b>sensor</b> with lower power requirements than the already-existing CCD sensor technology, for use in portable devices such as DSLR cameras.|$|E
5000|$|... #Caption: World map showing {{frequency}} of lightning strikes, in flashes per km² per year (equal-area projection). Lightning strikes most {{frequently in the}} Democratic Republic of the Congo. Combined 1995-2003 data from the Optical Transient Detector and 1998-2003 data from the Lightning <b>Imaging</b> <b>Sensor.</b>|$|E
40|$|Target {{detection}} and localization {{is one of}} the key research challenges in sensor networks. In this paper we propose a heterogeneous wireless <b>sensor</b> network integrating <b>imaging</b> and non-imaging <b>sensors</b> to accomplish the {{detection and}} localization task in complex urban environments. The lowcost non-imaging sensors provide early detection and partial localization of potential targets and direct <b>imaging</b> <b>sensors</b> to focus on them. Accurate target location estimated by the <b>imaging</b> <b>sensors</b> is then used to calibrate the non-imaging sensors. We evaluate our approach through simulation and implementation on a sensor network testbed that uses MicaZ motes equipped with magnetometers and a camera to track ferrous targets. Our preliminary results reveal that coordination across different sensing modalities increases localization accuracy and reduces the amount of imaging data that has to be processed by the network. ...|$|R
50|$|Dr. George Joseph {{has made}} {{significant}} contribution to the development of remote sensing technology in India, especially in the field of earth observation sensors. He is rightfully considered the pioneer of satellite based <b>imaging</b> <b>sensors</b> in India.|$|R
5000|$|... 'Ultraspectral' {{could be}} {{reserved}} for interferometer type <b>imaging</b> <b>sensors</b> with a very fine spectral resolution. These sensors often have (but not necessarily) a low spatial resolution of several pixels only, a restriction imposed by the high data rate.|$|R
