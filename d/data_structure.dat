10000|10000|Public
5|$|Since {{the only}} <b>data</b> <b>structure</b> is {{the set of}} active {{clusters}} and the stack containing {{a subset of the}} active clusters, the space required is linear in the number of input points.|$|E
5|$|Linear probing is a {{component}} of open addressing schemes for using a hash table to solve the dictionary problem. In the dictionary problem, a <b>data</b> <b>structure</b> should maintain a collection of key–value pairs subject to operations that insert or delete pairs from the collection or that search for the value associated with a given key.|$|E
5|$|A {{binary search}} tree is a binary tree <b>data</b> <b>structure</b> that works based on the {{principle}} of binary search. The records of the tree are arranged in sorted order, and each record in the tree can be searched using an algorithm similar to binary search, taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in {{binary search tree}}s. This can faster than the linear time insertion and deletion of sorted arrays, and binary trees retain the ability to perform all the operations possible on a sorted array, including range and approximate queries.|$|E
40|$|The {{topic of}} <b>data</b> <b>structures</b> has {{historically}} been taught with two major focuses: first, the basic definition and implementation of a small set of basic <b>data</b> <b>structures</b> (e. g. list, stack, queue, tree, graph), and second, the usage of these basic <b>data</b> <b>structures</b> as provided by a <b>data</b> <b>structures</b> framework in solving larger application problems. We see a further evolution of <b>data</b> <b>structures</b> to include new generations of hybrid and custom <b>data</b> <b>structures,</b> implying that our students must not only understand {{how to use these}} new <b>data</b> <b>structures</b> but that they continue to understand low-level implementation issues so that they can develop the next generation of <b>data</b> <b>structures</b> needed in the future. We suggest that the <b>data</b> <b>structures</b> course evolve to reflect these new generations of <b>data</b> <b>structures...</b>|$|R
50|$|<b>Data</b> <b>structures</b> {{consisted}} of numbers, strings, and arrays {{whereas in the}} Actor model <b>data</b> <b>structures</b> were Actors. Restricting <b>data</b> <b>structures</b> to numbers, strings, and arrays is problematical because it prohibits programmable <b>data</b> <b>structures.</b>|$|R
40|$|Summary. In {{this paper}} we survey {{some of the}} major <b>data</b> <b>structures</b> for {{encoding}} Level Of Detail (LOD) models. We classify LOD <b>data</b> <b>structures</b> according to the dimensionality of the basic structural element they represent into point-, triangle-, and tetrahedron-based <b>data</b> <b>structures.</b> Within each class we will review single-level <b>data</b> <b>structures,</b> general <b>data</b> <b>structures</b> for LOD models based on irregular meshes as well as more specialized <b>data</b> <b>structures</b> that assume a certain (semi-) regularity of the data. ...|$|R
5|$|For {{implementing}} associative arrays, hash tables, a <b>data</b> <b>structure</b> that maps keys {{to records}} using a hash function, are generally faster than binary search on a sorted array of records; most implementations require only amortized constant time on average. However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, {{as the only}} information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. In addition, all operations possible on a sorted array can be performed—such as finding the smallest and largest key and performing range searches.|$|E
5|$|Known {{methods for}} {{repeatedly}} finding the closest pair of clusters in a dynamic set of clusters either require superlinear space {{to maintain a}} <b>data</b> <b>structure</b> that can find closest pairs quickly, or they take greater than linear time to find each closest pair. The nearest-neighbor chain algorithm uses a smaller {{amount of time and}} space than the greedy algorithm by merging pairs of clusters in a different order. In this way, it avoids the problem of repeatedly finding closest pairs. Nevertheless, for many types of clustering problem, it can be guaranteed {{to come up with the}} same hierarchical clustering as the greedy algorithm despite the different merge order.|$|E
5|$|The {{increase}} in maximum bandwidth {{is achieved by}} raising the lane speed from 6 Gbit/s to 12 Gbit/s and {{increasing the number of}} AV data lanes from 3 to 4 (i.e. using all 4 lanes to carry data). The data lanes runs in inverted clock mode and embeds the clock signal in itself. This allows the clock lane to be used for data (in addition to the existing three data lanes). The lane <b>data</b> <b>structure</b> has been changed to a packet-based format. The lane encoding is changed from 8b/10b to 16b/18b (reducing the overhead from 20% to 11%).|$|E
40|$|We present two {{tools to}} support the {{teaching}} of <b>data</b> <b>structures</b> and algorithms: Visualizers, which provide interactive visualizations of user-written <b>data</b> <b>structures,</b> and Testers, which check the functionality of user-written <b>data</b> <b>structures.</b> We outline a prototype implementation of visualizers and testers for <b>data</b> <b>structures</b> written in Java, and report on classroom use of testers and visualizers in an introductory <b>Data</b> <b>Structures</b> and Algorithms (CS 2) course...|$|R
30|$|On a lower level, {{closer to}} the {{implementation}} of <b>data</b> <b>structures</b> themselves, it should be investigated how the actual exchange of <b>data</b> <b>structures</b> can be improved. Instead of treating the swap between any two <b>data</b> <b>structures</b> over the same interfaces, more efficient ways to swap between specific <b>data</b> <b>structures</b> should be investigated.|$|R
40|$|<b>Data</b> <b>structures</b> play {{a central}} role in modern {{computer}} science. You interact with <b>data</b> <b>structures</b> much more often than with algorithms (think of Google, your mail server, and even your network routers). In addition, <b>data</b> <b>structures</b> are essential building blocks in obtaining efficient algorithms. This course will cover major results and current directions of research in <b>data</b> <b>structures...</b>|$|R
5|$|The {{main idea}} of the {{algorithm}} is to find pairs of clusters to merge by following paths in the nearest neighbor graph of the clusters. Every such path will eventually terminate at a pair of clusters that are nearest neighbors of each other, and the algorithm chooses that pair of clusters as the pair to merge. In order to save work by re-using {{as much as possible}} of each path, the algorithm uses a stack <b>data</b> <b>structure</b> to keep track of each path that it follows. By following paths in this way, the nearest-neighbor chain algorithm merges its clusters in a different order than methods that always find and merge the closest pair of clusters. However, despite that difference, it always generates the same hierarchy of clusters.|$|E
5|$|The nearest-neighbor chain {{algorithm}} constructs a clustering in time {{proportional to}} {{the square of the}} number of points to be clustered. This is also {{proportional to the}} size of its input, when the input is provided {{in the form of an}} explicit distance matrix. The algorithm uses an amount of memory proportional to the number of points, when it is used for clustering methods such as Ward's method that allow constant-time calculation of the distance between clusters. However, for some other clustering methods it uses a larger amount of memory in an auxiliary <b>data</b> <b>structure</b> with which it keeps track of the distances between pairs of clusters.|$|E
5|$|The {{same idea}} of using a DAG to {{represent}} a family of paths occurs in the binary decision diagram, a DAG-based <b>data</b> <b>structure</b> for representing binary functions. In a binary decision diagram, each non-sink vertex is labeled {{by the name of}} a binary variable, and each sink and each edge is labeled by a 0 or 1. The function value for any truth assignment to the variables is the value at the sink found by following a path, starting from the single source vertex, that at each non-sink vertex follows the outgoing edge labeled with the value of that vertex's variable. Just as directed acyclic word graphs {{can be viewed as a}} compressed form of tries, binary decision diagrams can be viewed as compressed forms of decision trees that save space by allowing paths to rejoin when they agree on the results of all remaining decisions.|$|E
50|$|Data can be {{organized}} {{in many different}} types of <b>data</b> <b>structures,</b> including arrays, graphs, and objects. <b>Data</b> <b>structures</b> can store <b>data</b> of many different types, including numbers, strings and even other <b>data</b> <b>structures.</b> <b>Data</b> pass in and out of computers via peripheral devices.|$|R
50|$|Arrays {{are used}} to {{implement}} other <b>data</b> <b>structures,</b> such as lists, heaps, hash tables, deques, queues, stacks, strings, and VLists. Array-based implementations of other <b>data</b> <b>structures</b> are frequently simple and space-efficient (implicit <b>data</b> <b>structures),</b> requiring little space overhead, but may have poor space complexity, particularly when modified, compared to tree-based <b>data</b> <b>structures</b> (compare a sorted array to a search tree).|$|R
50|$|These {{types of}} <b>data</b> <b>structures</b> are {{particularly}} common in logical and functional programming, {{and in a}} purely functional program all data is immutable, so all <b>data</b> <b>structures</b> are automatically fully persistent. Persistent <b>data</b> <b>structures</b> can also be created using in-place updating of data and these may, in general, use less time or storage space than their purely functional counterparts. Purely functional <b>data</b> <b>structures</b> are persistent <b>data</b> <b>structures</b> that completely avoid the use of mutable state, but can often still achieve attractive amortized time complexity bounds.|$|R
25|$|A binary heap is a heap <b>data</b> <b>structure</b> {{that takes}} the form of a binary tree. Binary heaps are a common way of {{implementing}} priority queues. The binary heap was introduced by J. W. J. Williams in 1964, as a <b>data</b> <b>structure</b> for heapsort.|$|E
25|$|A {{discrimination}} tree term index stores {{its information}} in a trie <b>data</b> <b>structure.</b>|$|E
25|$|Fibonacci numbers {{arise in}} the {{analysis}} of the Fibonacci heap <b>data</b> <b>structure.</b>|$|E
5000|$|Many <b>data</b> <b>structures</b> in {{use today}} have 32-bit time {{representations}} embedded into their structure. A full list of these <b>data</b> <b>structures</b> {{is virtually impossible to}} derive but there are well-known <b>data</b> <b>structures</b> that have the Unix time problem: ...|$|R
50|$|File formats {{and other}} {{internal}} <b>data</b> <b>structures</b> {{are described in}} the <b>Data</b> <b>Structures</b> Programming Reference Manual.|$|R
30|$|At the {{beginning}} of each defense cycle, DSSR binary randomizes the <b>data</b> <b>structures</b> in the dynamic whitelist, and de-randomizes the <b>data</b> <b>structures</b> that are not in the dynamic whitelist. There are two challenges when we design SALADSPlus: (1) changing the dynamic whitelist of <b>data</b> <b>structures</b> at runtime without recompiling the program (SALADS compiles the source code with a static whitelist); (2) when DSSR binary randomizes <b>data</b> <b>structures,</b> multiple DSSR statements are executed based on the previous layout of the <b>data</b> <b>structures.</b> Without concurrency methods, the DSSR statements may access totally irrelevant fields.|$|R
25|$|Dynamic typing allows {{constructs}} {{that some}} static type checking would reject as illegal. For example, eval functions, which execute arbitrary data as code, become possible. An eval function is possible with static typing, but requires advanced uses of algebraic data types. Further, dynamic typing better accommodates transitional code and prototyping, such as allowing a placeholder <b>data</b> <b>structure</b> (mock object) to be transparently used {{in place of}} a full <b>data</b> <b>structure</b> (usually for the purposes of experimentation and testing).|$|E
25|$|A <b>data</b> <b>structure</b> is a {{particular}} way of organizing data in a computer {{so that it can}} be used efficiently.|$|E
25|$|Linked {{lists are}} a dynamic <b>data</b> <b>structure,</b> which can grow and be pruned, allocating and deallocating memory while {{the program is}} running.|$|E
40|$|This is {{the second}} course in a two-semester {{sequence}} introducing fundamental concepts and techniques for computer science and engineering. The course focuses on problem analysis, advanced programming concepts using JAVA and fundamental <b>data</b> <b>structures.</b> Students learn to analyze problems and evaluate potential solutions with respect to choice of <b>data</b> <b>structures</b> and computational efficiency. Student {{are exposed to the}} underlying implementation of basic <b>data</b> <b>structures</b> available in JAVA libraries and develop the skilled needs to extend existing <b>data</b> <b>structures</b> and design new <b>data</b> <b>structures</b> to solve increasingly complex problems. This is an integrated writing course...|$|R
50|$|Purely {{functional}} <b>data</b> <b>structures</b> are persistent. Persistency {{is required}} for functional programming; without it, the same computation could return different results. Functional programming may use persistent non-purely functional <b>data</b> <b>structures,</b> while those <b>data</b> <b>structures</b> {{may not be used}} in purely functional programs.|$|R
40|$|Ir{{radiance}} and radiance caching {{are important}} algorithms for solving the light transport problem in realistic image synthesis. They both require geometric search <b>data</b> <b>structures</b> for efficient rendering. Our {{goal was to}} improve the caching algorithms by improving these <b>data</b> <b>structures.</b> We have implemented 6 different <b>data</b> <b>structures</b> for irradiance caching, 2 previously used and 4 newly adapted to the problem. Our testing showed that multiple-reference <b>data</b> <b>structures</b> offer the best traversa...|$|R
25|$|A trie {{forms the}} {{fundamental}} <b>data</b> <b>structure</b> of Burstsort, which (in 2007) was the fastest known string sorting algorithm. However, {{now there are}} faster string sorting algorithms.|$|E
25|$|Given {{an overall}} design, {{a good choice}} of {{efficient}} algorithms and data structures, and efficient implementation of these algorithms and data structures comes next. After design, the choice of algorithms and data structures affects efficiency {{more than any other}} aspect of the program. Generally data structures are more difficult to change than algorithms, as a <b>data</b> <b>structure</b> assumption and its performance assumptions are used throughout the program, though this can be minimized by the use of abstract data types in function definitions, and keeping the concrete <b>data</b> <b>structure</b> definitions restricted to a few places.|$|E
25|$|Many {{data bits}} may not convey information. For example, data {{structures}} often store information redundantly, or have identical sections {{regardless of the}} information in the <b>data</b> <b>structure.</b>|$|E
40|$|The Boom Hierarchy is {{the family}} of <b>data</b> <b>structures</b> tree, list, bag, set. By {{combining}} their properties in other ways, more <b>data</b> <b>structures</b> can be made, like mobiles. The paper defines the <b>data</b> <b>structures</b> of this extended Boom Hierarchy and shows how the functions reduce, map, and filter are applied to them. 1 Introduction The Boom Hierarchy {{is the family}} of <b>data</b> <b>structures</b> tree, list, bag, set, {{to be used with}} the higher-order Squiggol functions reduce, map, filter. Example The term that filters the odd numbers from the list [1 [...] 10], and adds up their squares is += ffi sqr ffi odd / : [1 :: 10]: (Reduce =, map, and filter / are defined further down.) end of example In this paper the <b>data</b> <b>structures</b> are presented as free algebras. New <b>data</b> <b>structures</b> in the family (e. g. mobiles) spring from algebras with new combinations of laws. The relations between the <b>data</b> <b>structures</b> are explained and some sample <b>data</b> <b>structures.</b> No category theory required! 2 The Boom hierarchy The hie [...] ...|$|R
40|$|In {{this paper}} we {{describe}} a method, based on lazy evaluation, for creating infinite <b>data</b> <b>structures</b> in Ada. We illustrate some potential applications of infinite <b>data</b> <b>structures</b> and describe three different implementation approaches. 1. 1 Keywords Ada, functional programming, lazy evaluation, infinite <b>data</b> <b>structures.</b> 2...|$|R
40|$|This thesis {{deals with}} analysis, design and {{implementation}} of database in telecommunication company. The thesis consists of existing <b>data</b> <b>structures</b> analysis, functional requirements analysis, new <b>data</b> <b>structures</b> design, <b>data</b> consolidation and migration into new <b>data</b> <b>structures</b> and application implementation. Primary goal is monitoring of budget...|$|R
