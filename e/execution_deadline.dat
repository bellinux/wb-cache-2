9|99|Public
30|$|Consider the {{parameters}} such as delay in servicing an event, {{the number of}} waiting tasks, clock frequency, power manager delay, state transition time, detection probability and task <b>execution</b> <b>deadline</b> etc. as performance measure parameters.|$|E
30|$|Inspecting the {{original}} Slope One prediction equation 2, {{one can see}} that both the numerator and the denominator on the right hand {{side of the equation}} are just sums on their own. Since the actual division is not done on the server, an encrypted numerator and the plaintext denominator is sent to the client as shown in equation 6. This means that the client is free to submit more than one queries with disjoint vectors of items in each query and combine the results to form the final prediction. That is a Map-Reduce style parallelism, which we plan to implement in future prototypes. From a performance standpoint, this will ensure that the servlet’s response time will not be dependent {{on the size of the}} encrypted rating vector provided by the user, and therefore will not be subject to the GAE/J <b>execution</b> <b>deadline</b> of 30 s although Amazon Elastic Beanstalk presents no such <b>execution</b> <b>deadline.</b>|$|E
30|$|Resource {{allocation}} for the batch applications (i.e., on-and-off workload pattern) {{is usually}} {{referred to as}} scheduling which involves meeting a certain job <b>execution</b> <b>deadline</b> [4]. Scheduling is extensively studied in the grid environments [4] and also explored in the cloud environments, but it is outside {{of the scope of}} this paper. Similarly, the cloud services with a stable (or static) workload pattern do not require an auto-scaling system for resource allocation per se. Therefore, this paper considers cloud services with the periodic, growing, and unpredictable workload patterns.|$|E
40|$|CAD-systems {{supporting}} hardware/software codesign map different {{tasks of}} an algorithm onto processors. Some of the processors are programmable {{and others are}} application specific. We propose a new MILP (mixed integer linear program) model that allows to determine a mapping optimizing a trade off function between execution time, processor and communication cost. The mapping also guarantees that all specified <b>execution</b> <b>deadlines</b> are met. We demonstrate the efficiency with practical examples...|$|R
40|$|Abstract. The paper {{discusses}} {{the problem of}} robust buffer allocation for Resource-Constrained Project Scheduling Problem (RCPSP) with predefined milestones 1, for which <b>execution</b> <b>deadlines</b> have been established. To solve the problem, an algorithm is proposed supporting insertion of unit time buffers, with the simultaneous maximisation of new metrics of arrangement robustness. The presented results of experimental research speak for usabil-ity of the solutions proposed. The effectiveness is studied with use of test tasks 2 included in the Project Scheduling Problem Library (PSPLIB) with additionally specified project milestones...|$|R
40|$|Executing time {{critical}} applications within cloud environments while satisfying <b>execution</b> <b>deadlines</b> and response time requirements is challenging {{due to the}} difficulty of securing guaranteed performance from the underlying virtual infrastructure. Cost-effective solutions for hosting such applications in the Cloud require careful selection of cloud resources and efficient scheduling of individual tasks. Existing solutions for provisioning infrastructures for time constrained applications are typically based on a single global deadline. Many {{time critical}} applications however have multiple internal time constraints when responding to new input. In this paper we propose a cloud infrastructure planning algorithm that accounts for multiple overlapping internal deadlines on sets of tasks within an application workflow. In order to better compare with existing work, we adapted the IC-PCP algorithm and then compared it with our own algorithm using a large set of workflows generated at different scales with different <b>execution</b> profiles and <b>deadlines.</b> Our results show that the proposed algorithm can satisfy all overlapping deadline constraints where possible given the resources available, and do so with consistently lower host cost in comparison with IC-PCP...|$|R
40|$|Abstract—Time-triggered {{periodic}} control implementations {{are over}} provisioned for many execution scenarios {{in which the}} states of the controlled plants are close to equilibrium. To address this inefficient use of computation resources, researchers have proposed self-triggered control approaches in which the control task computes its <b>execution</b> <b>deadline</b> at runtime based on the state and dynamical properties of the controlled plant. The potential advantages of this control approach cannot, however, be achieved without adequate online resource-management policies. This paper addresses scheduling of multiple self-triggered control tasks that execute on a uniprocessor platform, where the optimization objective is to find tradeoffs between the control performance and CPU usag...|$|E
40|$|In {{this paper}} we {{concentrate}} on non-preemptive hard real-time scheduling algorithms. We compare FIFO, EDLF, SRTF and genetic algorithms for solving this problem. The {{objective of the}} scheduling algorithm is to dynamically schedule as many tasks as possible such that each task meets its <b>execution</b> <b>deadline,</b> while minimizing the total delay time {{of all of the}} tasks. We present a MicroGA that uses a small population size of 10 chromosomes, running for 10 trials using a rather high mutation rate with a sliding window of 10 tasks. The steady-state GA was determined to be better than the generational GA for our MicroGA. We also present a parallel MicroGA model designed for parallel processors. The parallel MicroGA works bests when migration is used to move tasks from one processor to another to even out the load as much a possible. Test cases show that the sequential MicroGA model and the parallel MicroGA model produced superior task schedules compared to other algorithms tested...|$|E
40|$|This {{research}} was supported by an Amazon Web Services Education Research grant. It is challenging to execute an application in a heterogeneous cloud cluster, which consists of multiple types of virtual machines with different performance capabilities and prices. This paper aims to mitigate this challenge by proposing a scheduling mechanism to optimise the execution of Bag-of-Task jobs on a heterogeneous cloud cluster. The proposed scheduler considers two approaches to select suitable cloud resources for executing a user application while satisfying pre-defined Service Level Objectives (SLOs) both in terms of <b>execution</b> <b>deadline</b> and minimising monetary cost. Additionally, a mechanism for dynamic re-assignment of jobs during execution is presented to resolve potential violation of SLOs. Experimental studies are performed both in simulation and on a public cloud using real-world applications. The results highlight that our scheduling approaches result in cost saving of up to 31 % in comparison to naive approaches that only employ a single type of virtual machine in a homogeneous cluster. Dynamic reassignment completely prevents deadline violation in the best-case and reduces deadline violations by 95 % in the worst-case scenario. Postprin...|$|E
5000|$|Over {{the course}} of nearly twelve years on death row Chessman filed dozens of appeals, acting as his own attorney, and {{successfully}} avoided eight <b>execution</b> <b>deadlines,</b> often by a few hours. Most appeals were based on assertions that {{he was forced to}} go to trial unprepared; that the trial itself was unfair; that confessions obtained by force and intimidation and promises of partial immunity were used in evidence against him; that California's [...] "Little Lindbergh Law" [...] was unconstitutional; and that the transcript of record forwarded upon appeal to the state supreme court was incomplete, and important parts of the proceedings were missing or incorrectly recorded. [...] In 1957 the U.S. Supreme Court ordered the State of California to conduct a full review of the transcripts. The review concluded that the transcripts were substantially accurate.|$|R
40|$|A {{computational}} grid is a wide-area {{computing environment}} for cross-domain resource sharing and service integration. Resource management and load balancing are key concerns when implementing grid middleware and improving resource utilization. Grid resource management {{can be implemented}} as a multiagent system with resource advertisement and discovery capabilities if job requests from users are associated with explicit QoS requirements. In this work agent-based self-organization is proposed to perform complementary load balancing for batch jobs with no explicit <b>execution</b> <b>deadlines.</b> In particular, an ant-like self-organizing mechanism is introduced and proved to be powerful to achieve overall grid load balancing through a collection of very simple local interactions. A modeling and simulation environment is developed to enable performance of the ant algorithm to be investigated quantitatively. Simulation results included in this work illustrate the impact of different performance optimization strategies on the overall system load balancing level, speed and efficiency. 1...|$|R
40|$|We {{describe}} {{the interface between}} a real-time resource allocation system with an AI planner {{in order to create}} fault-tolerant plans that are guaranteed to execute in hard real-time. The planner specifies the task set and all <b>execution</b> <b>deadlines</b> required to ensure system safety, then the resource allocator schedules these plans off-line to analyze execution platform resource utilization. A new interface module combines information from planning and resource allocation to enforce development of plans feasible for execution during a variety of internal system faults. Plans that over-utilize any system resource trigger feedback to the planner, which then searches for an alternate plan. A valid plan for each specified fault, including the nominal no-fault situation, is stored in a plan cache for subsequent real-time execution. We situate this work in the context of CIRCA, the Cooperative Intelligent Real-time Control Architecture, which focuses on developing and scheduli [...] ...|$|R
40|$|International audience—In the {{framework}} of network function virtualization, we consider in this paper the execution of Virtualized Network Functions (VNFs) in data centers whose computing capacities are limited. We assume that each VNF is composed of sub-functions to be executed on general purpose hardware, each sub-function requiring a random amount of processing time. Because of limited processing capacity, we investigate the relevance of resource pooling where available cores in a data center are shared by active VNFs. We study by simulation various algorithms for scheduling sub-functions composing active VNFs (namely Greedy, Round Robin and Dedicated Core algorithms). We additionally introduce an <b>execution</b> <b>deadline</b> criterion, which means that VNFs can renege if their sojourn time in the system exceeds by a certain factor their service time. This feature is especially relevant when considering the processing of real-time VNF. Simulations show that sub-functions chaining is critical with regard to performance. When sub-functions have to be executed in series, the simple Dedicated Core algorithm is the most efficient. When sub-functions can be executed in parallel, Greedy or Round Robin algorithms offer similar performance and outperform the Dedicated Core algorithm. Enabling {{as much as possible}} parallelism and avoiding chaining when designing a VNF are fundamental principles to gain from the available computing resources...|$|E
40|$|The skyrocketing {{amount of}} {{electricity}} consumed by many data {{centers around the}} globe has become a serious issue for the cloud computing and entire IT industry. The demand for data centers is rapidly increasing due to widespread usage of cloud services. It also leads to huge carbon emissions contributing to the global greenhouse effect. The US Environmental Protection Agency has declared that data centers represent {{a substantial portion of}} the energy consumption in the US and the whole world. Some of this energy consumption is caused by idle servers or servers running at higher-than-necessary frequencies. Due to the Dynamic Voltage and Frequency Scaling (DVFS) technology enabled in many CPUs, strategically reducing CPU frequency without affecting the Quality of Service (QoS) is desired. Our goal in this paper is to calculate and tune to the best CPU frequency for each running task combined with two commonly-used scheduling approaches, namely round robin and first fit algorithms, given the CPU configuration and the <b>execution</b> <b>deadline.</b> The effectiveness of our algorithms is evaluated under a CloudSim/CloudReport simulation environment as well as real hypervisor computer system with power gauge. The open source CloudReport, based on the CloudSim simulator, has been used to integrate our DVFS algorithm with the two scheduling algorithms to illustrate the efficiency of power saving in different scenarios. Furthermore, electricity consumption is measured and compared using power gauge of Watts Up meter...|$|E
40|$|The {{objective}} {{with this}} project was to create an autonomous drone with the capability to pick up, and deliver an object, without any human interference. This is an continuation of the work done during the pre-project. The obectives during this project were: 1. Improve the orientation controller 2. Implement a position controller with necessary sensors 3. Implement a method for the drone to recognize objects to be picked up, and lock on to the object 4. Implement a method for picking up an object 5. Do an overall test of all the objectives mentioned above 6. If there is enough time a collision detector system should be implemented. Before the orientation controller could be improved {{it was necessary to}} revise the orientation data processing algorithms. After implementing a calibration routine, motor throttle compensation, rollover compensation and acceptance test for the compass, and a tilt compensation function for the gyroscope, the results were satisfying. An LQR controller and cascade controller was tested in order to find the best alternative for controlling the drone's orientation. Both controllers were tested and tuned against the drone model in Simulink before implemented on the drone's MCU for further testing and tuning. The cascade configuration was precise and responsive, and proved to be the superior controller design for this use. With this, the first objective was met. In order for the drone to be implemented with a position controller the following new hardware was installed. 1. GNSS receiver, for measuring position and velocity 2. Pressure sensor, for accurately measuring altitude 3. Vision sensor, for detecting objects 4. IR sensor, for detecting the ground In order to get a visual feedback of the current status of the drone, LED's were installed. Appropriate drivers were developed for the new peripheral devices. Because of the new hardware a new PCB design was necessary, the new design made the electronics more concealed, and the drone more compact. A hook connected to a servo was suggested as a method for picking up objects, but was not implemented due to controller issues. In order for the visual representation of the drone's position and -velocity to be easy to comprehend the GNSS data was converted to ENU coordinates, and pressure sensor data was recalculated to altitude. Sensor fusion with kalman filtering was implemented to filter the velocity data, and a second order low-pass filter was used to filter the altitude data, this gave noise reduced measurements. The controller design used for positioning was a cascade controller, and was tuned and tested {{in the same manner as}} the orientation controller. The tuning of the position controller had to be done outside, but due to harsh weather conditions, not enough time was spent on tuning the controller, the parameters were therefore not optimal. The overall controller design and implementation worked as planned, with this, the second objective was met. The raw data from the vision sensor, object $x$- and $y$ position and object width, was recalculated to a three dimensional position vector, so the object position data could be used in the position controller. To make testing easier, the vision sensor was also modeled in Simulink. The flight controller combines all the controller and data processing modules plus necessary logic for the modules to cooperate. This was designed in Simulink because of the possibility to simulate against the drone model. Four flight modes were implemented in the flight controller, 1. Manual mode, 2. Manual GNSS mode, 3. Autonomous mode, and 4. Autonomous object mode. A battery monitoring system was also implemented for warning the user of low battery via the LED's. A real-time operating system was implemented due the need for doing several operations at the same time, and some modules having a strict <b>execution</b> <b>deadline.</b> There was implemented a total of seven tasks and one interrupt routine. The operating system worked flawlessly. All modes except "autonomous object mode" were tested on the physical drone, though the functionality of all three modes worked as expected there was definitively room for improvements. When testing "manual mode" an issue arose, when given a roll- or pitch input the drone was not able to hold its attitude over time, and would flatten out as it picked up speed. This affected the drone's top speed, which was noticeable on the performance in "autonomous mode" and "manual GNSS mode", this issue affected the drone's ability to hold its geographic position, and move to another position. The root cause of this issue was tough to be poor controller parameters. Because of this issue there was no point in implementing the "autonomous object mode" on the drone, this was rather simulated in Simulink, and the result was satisfying enough to suggest the mode to be implemented on a later moment. Due to the issues mentioned above, the "autonomous object mode" was never implemented on the drone, there was no point in implementing this mode as the position controller was not precise enough. With this, the third and fourth objective was not met, although much of the work has been done. A test of all the implemented objectives was done, the fifth objective was therefore met. There was no time to complete objective six...|$|E
3000|$|... {{and after}} their parent tasks have {{completed}} executing. In addition, each task of job j should complete its <b>execution</b> before the <b>deadline</b> {{of the job}} (d [...]...|$|R
40|$|Previous {{researches}} on real-time scheduling {{assume that}} the number of processors required to execute a task is fixed and its computation time is given based on this fixed number of processors. However, in multiprocessor systems, the computation time of scalable task varies depending on the number of processors allocated to it. By determining a proper number of processors to be allocated to each real-time task, more real-time tasks complete their <b>execution</b> before <b>deadlines.</b> In this paper, we propose a new on-line scheduling algorithm for scalable, aperiodic, nonpreemptive, and independent tasks. The proposed algorithm uses workload to represent the computational requirement of tasks and tries to reduce the total workload of all scheduled tasks so that a newly arrived task should have more feasibility to complete its <b>execution</b> before <b>deadline.</b> The algorithm works based on three rules. First, the number of processors allocated to tasks is kept as small as possible without violating deadl [...] ...|$|R
40|$|The {{ability to}} model periodic, {{sporadic}} and aperiodic tasks {{in a way}} that ensures their timing constraints such as worst-case <b>execution</b> time, <b>deadline</b> and periodicity is a major concern in embedded real-time programming. We propose the use of a concurrent event library to achieve the predictability of embedded real-time programs while retaining the advantages of modular development and reasoning of object-oriented languages and the benefit of event-driven programming. 1...|$|R
40|$|Adaptive Body Biasing (ABB) is a popularly used {{technique}} {{to mitigate the}} increasing impact of manufacturing process variations on leakage power dissipation. The efficacy of the ABB technique can be improved by partitioning a design {{into a number of}} “body-bias islands, ” each with its individual body-bias voltage. In this paper, we propose a system-level leakage variability mitigation framework to partition a multiprocessor system into body-bias islands at the processing element (PE) granularity at design time, and to optimally assign body-bias voltages to each island post-fabrication. As opposed to prior gate- and circuit-level partitioning techniques that constrain the global clock frequency of the system, we allow each island to run at a different speed and constrain only the relevant system performance metrics- in our case the <b>execution</b> <b>deadlines.</b> Experimental results show the efficacy of the proposed framework in reducing the mean and standard deviation of leakage power dissipation compared to a baseline system without ABB. At the same time, the proposed techniques provide significant runtime improvements over a previously proposed Monte-Carlo based technique while providing similar reductions in leakage power dissipation...|$|R
40|$|Abstract. Cloud {{computing}} {{provides an}} elastic, as-a-Service resource abstraction with a usage-based payment model, and {{is emerging as}} an attracting computing paradigm. This {{is especially true for}} computing in-tensive application workflows with high-throughput requirements, such as those involving large-scale image datasets. In this paper, we investigate the usage of cloud computing to support a medical image registration workflow using the CometCloud autonomic cloud computing framework. CometCloud supports the execution on workflows on heterogeneous, dy-namically federated (private and public) clouds, where the federation is driven by application requirements and user objectives. Specifically, in this investigation, we use objectives such as workflow <b>execution</b> <b>deadlines</b> and budget constraints to provision the appropriate type and number of resources, which are the federated with local private resources to provide additional resources to satisfy the objectives. We experimentally tested this cloud-based workflow on a large dataset containing two sets of con-secutive digitized breast tissue specimens. This cloud computing based image registration workflow shows promising results in its ability to meet high-throughput, deadline driven requirements. ...|$|R
40|$|This {{research}} has been conducted at the Computational Sciences Division of the Information Sciences Directorate at Ames Research Center (Automated Software Engineering Grp). The principle work this summer has been to review and refine the agenda that were carried forward from last summer. Formal specifications provide good support for designing a functionally correct system, however they are weak at incorporating non-functional performance requirements (like reliability). Techniques which utilize stochastic Petri nets (SPNs) are good for evaluating the performance and reliability for a system, but they may be too abstract and cumbersome from the stand point of specifying and evaluating functional behavior. Therefore, one major objective of this research is to provide an integrated approach to assist the user in specifying both functionality (qualitative: mutual exclusion and synchronization) and performance requirements (quantitative: reliability and <b>execution</b> <b>deadlines).</b> In this way, the merits of a powerful modeling technique for performability analysis (using SPNs) can be combined with a well-defined formal specification language. In doing so, we can come closer to providing a formal approach to designing a functionally correct system that meets reliability and performance goals...|$|R
40|$|Abstract—Purpose-built {{clusters}} permeate many of today’s or-ganizations, providing both large-scale {{data storage}} and comput-ing. Within local clusters, competition for resources complicates applications with deadlines. However, given {{the emergence of}} the cloud’s pay-as-you-go model, users are increasingly storing portions of their data remotely and allocating compute nodes on-demand to meet deadlines. This scenario gives rise to a hybrid cloud, where data stored across local and cloud resources may be processed over both environments. While a hybrid execution environment may be used to meet time constraints, users must now attend to the costs associated with data storage, data transfer, and node allocation time on the cloud. In this paper, we describe a modeling-driven resource allocation framework to support both time and cost sensitive execution for data-intensive applications executed in a hybrid cloud setting. We evaluate our framework using two data-intensive applications and a number of time and cost constraints. Our experimental results show that our system is capable of meeting <b>execution</b> <b>deadlines</b> within a 3. 6 % margin of error. Similarly, cost constraints are met within a 1. 2 % margin of error, while minimizing the application’s execution time. I...|$|R
40|$|In {{the past}} decade, the {{limitations}} of models considering fixed (worst case) task execution times have been acknowledged for large application classes within soft real-time systems. A more realistic model considers the tasks having varying execution times with given probability distributions. Considering such a model with specified task execution time probability distribution functions, an important performance indicator {{of the system is}} the expected deadline miss ratio of the tasks and of the task graphs. This article presents an approach for obtaining this indicator in an analytic way. Our goal is to keep the analysis cost low, in terms of required analysis time and memory, while considering as general classes of target application models as possible. The following main assumptions have been made on the applications which are modelled as sets of task graphs: the tasks are periodic, the task execution times have given generalised probability distribution functions, the task <b>execution</b> <b>deadlines</b> are given and arbitrary, the scheduling policy can belong to practically any class of non-preemptive scheduling policies, and a designer supplied maximum number of concurrent instantiations of the same task graph is tolerated in the system. Experiments show the efficiency of the proposed technique for monoprocessor systems...|$|R
40|$|AbstractIn this paper, we {{consider}} the problem of scheduling independent parallel tasks with individual deadlines so as to maximize the total work performed by the tasks which complete their <b>executions</b> before <b>deadlines.</b> We propose two polynomial-time approximation algorithms for nonmalleable parallel tasks and malleable tasks with linear speedup. For non-malleable tasks, the first algorithm guarantees an approximation factor of 5 + ε for any positive constant ε, while, for malleable tasks with linear speedup, the second algorithm guarantees an approximation factor of 4. 5...|$|R
40|$|Grid environments {{enable users}} to share {{non-dedicated}} resources that lack performance guarantees. This paper describes {{the design of}} application-centric middleware components to automatically recover from failures and dynamically adapt to grid environments with changing resource availabilities, improving fault-tolerance and performance. The key components of the application-centric approach are a global per-application execution history and an autonomic component that tracks {{the performance of a}} job on a grid resource against predictions based on the application execution history, to guide rescheduling decisions. Performance models of unmodified applications built using their execution history are used to predict failure as well as poor performance. A prototype of the proposed approach, an Autonomic Virtual Application Manager (AVAM), has been implemented {{in the context of the}} In-VIGO grid environment and its effectiveness has been evaluated for applications that generate CPU-intensive jobs with relatively short execution times (ranging from tens of seconds to less than an hour) on resources with highly variable loads [...] a workload generated by typical educational usage scenarios of In-VIGO-like grid environments. A memory-based learning algorithm is used to build the performance models for CPU-intensive applications that are used to predict the need for rescheduling. Results show that In-VIGO jobs managed by the AVAM consistently meet their <b>execution</b> <b>deadlines</b> under varying load conditions and gracefully recover from unexpected failures. 1...|$|R
40|$|Abstract – The {{increasing}} {{complexity of}} the wireless sensor and actor network (WSAN) applications together with the technological evolution {{of this kind of}} system has allowed higher level programming paradigms to be proposed for these networks. In this paper, a service based programming model for real time WSANs is proposed. It allows us to specify the services and their interaction in order to build applications. The model syntax is platform independent which will facilitate its use by automatic tools in the implementation phase. The real time issue is important in WSANs so the model allows us to specify real time requirements as service priorities, periods of service <b>execution</b> or <b>deadlines.</b> I...|$|R
40|$|Distributed {{real-time}} threads are schedulable entities with an end-to-end deadline that traverse nodes, {{carrying their}} scheduling context. In each node, the thread will be locally scheduled and predictions about deadline missing allow that actions {{are carried out}} to improve system performance. This paper presents a task model and deadline partitioning algorithms that consider {{the possibility of a}} distributed thread to follow different paths. The future execution flow of the distributed thread is only probabilistic known before its <b>execution.</b> End-to-end <b>deadline</b> missing prediction mechanisms can be carried out through definition of estimated local deadlines. Simulations show that the proposed prediction mechanism presents good results in overloaded systems. 1...|$|R
40|$|In my dissertation, I present ATLAS — the Auto-Training Look-Ahead Scheduler. ATLAS {{improves}} {{service to}} applications {{with regard to}} two non-functional properties: timeliness and overload detection. Timeliness is an important requirement to ensure user interface responsiveness and the smoothness of multimedia operations. Overload can occur when applications ask for more computation time than the machine can offer. Interactive systems have to handle overload situations dynamically at runtime. ATLAS provides timely service to applications, accessible through an easy-to-use interface. Deadlines specify timing requirements, workload metrics describe jobs. ATLAS employs machine learning to predict job <b>execution</b> times. <b>Deadline</b> misses are detected before they occur, so applications can react early...|$|R
40|$|We study {{stochastic}} {{models to}} mitigate the risk of poor Quality-of-Service (QoS) in computational markets. Consumers who purchase service expect both price and performance guarantees. They need to predict future demand to budget for sustained performance despite price fluctuations. Conversely, providers need to estimate demand to price future usage accurately. The bursty and skewed nature of demand in large-scale computer networks markets, exemplified by the Web and the stock market, challenges the statistical assumptions of independence and stationarity typically made in autoregression and Gaussian, Brownian Motion-based prediction models. This discrepancy leads to underestimation of investment risk, both for procurement and provisioning of capacity. We confirm this non-normal distribution behavior in our study of demand in computational markets. The high agility of a dynamic resource market requires flexible, efficient and adaptable predictions. Computational needs are typically expressed using performance levels, hence we estimate worst-case bounds of price distributions {{to mitigate the}} risk of missing <b>execution</b> <b>deadlines.</b> These requirements lead us to keep moving time windows of statistics, from which we approximate price percentile functions. We use snapshots of summary statistics to calculate prediction intervals and estimate model uncertainty. Our approach is model-agnostic, distribution-free both in prices and prediction errors, and does not require extensive sampling nor manual parameter tuning. Our simulations and experiments show that a Chebyshev inequality model generates accurate predictions with minimal data requirements. We also show that this approach mitigates the risk of dropped service level performance when selecting hosts to run a bag-of-task Grid application simulation in a live computational market cluster...|$|R
40|$|International audienceThe {{generalized}} multiframe (GMF) task {{has been}} proposed to model a task whose <b>execution</b> times, <b>deadlines</b> and minimum separation times are changed according to a specified pattern. In this paper we relax the assumption of having a specified activation pattern, this yields to non-cyclic GMF task. In this context, current schedulability analysis techniques for GMF task sets under dynamic priority assignment cannot be used. This paper presents response time analysis of non-cyclic GMF tasks executing on a uniprocessor according to earliest deadline first (EDF) scheduling policy. Also, a density-based sufficient schedulability test for non-cyclic GMF task sets is given. Finally an efficient approach is presented, for exact feasibility determination using computer simulation...|$|R
40|$|This paper {{presents}} Salt. Salt is {{a general}} purpose specification and assertion language developed for creating concise temporal specifications {{to be used in}} industrial verification environments. It incorporates ideas of existing approaches, such as specification patterns, but also provides nested scopes, exceptions, support for regular expressions and real-time. The latter is needed in particular for verification tasks to do with reactive systems imposing strict <b>execution</b> times and <b>deadlines...</b>|$|R
40|$|Abstract — The {{generalized}} multiframe (GMF) task {{has been}} proposed to model a task whose <b>execution</b> times, <b>deadlines</b> and minimum separation times are changed according to a specified pattern. In this paper we relax the assumption of having a specified activation pattern, this yields to non-cyclic GMF task. In this context, current schedulability analysis techniques for GMF task sets under dynamic priority assignment cannot be used. This paper presents response time analysis of non-cyclic GMF tasks executing on a uniprocessor according to earliest deadline first (EDF) scheduling policy. Also, a density-based sufficient schedulability test for non-cyclic GMF task sets is given. Finally an efficient approach is presented, for exact feasibility determination using computer simulation. Keywords-component: schedulability analysis, non-cyclic GMF task, EDF. I...|$|R
40|$|Workflow {{management}} systems should efficiently manage workflow constraints such as time, resource, and cost during workflow executions. Especially, workflow time management {{is important in}} timely scheduling of workflow process <b>execution,</b> avoiding <b>deadline</b> violations, and improving the workflow throughput. Though {{there have been some}} studies on the dynamic deadline management in a workflow, the importance of the static deadline management has not been much addressed in the past. We first describe our workflow model considered in this paper. Then, we propose a static deadline allocation method that can facilitate an efficient workflow processing. The proposed method can achieve high workflow throughput by analyzing the interrelated workflow components. We also present various experimental results that show the usefulness and efficiency of the method...|$|R
40|$|Scheduling {{problems}} that involve distance constraint tasks with repetitive requests {{is becoming increasingly}} popular in real time systems. Timing constraints defined by periods of fixed lengths for each task enforce some frequency of task <b>execution.</b> Alternatively <b>deadlines</b> could be specified relatively to the finish time of the previous execution of the same task. Hence the scheduling algorithms deal with tasks that virtually consist of infinite chains of jobs with specified temporal distance constraints between each pair of adjacent jobs. In this paper, unlike approaches that consider a preemptive distance constrained tasks scheduling subject to minimize time distance between task execution, we consider a problem of non preemptive tasks system with objective to reduce processor utilization while keeping the response times within their limits. As a consequence, free processor capacity remains to process sporadic tasks...|$|R
40|$|Abstract. Time {{management}} {{is a critical}} component of workflow-based process management. Important aspects of time management include planning of workflow process execution in time, estimating workflow <b>execution</b> duration, avoiding <b>deadline</b> violations, and satisfying all external time constraints such as fixed-date constraints and upper and lower bounds for time intervals between activities. In this paper, we present a framework for computing activity deadlines so that the overall process deadline is met and all external time constraints are satisfied. ...|$|R
40|$|In {{this paper}} we {{introduce}} a real-time {{extension of the}} concurrent object modeling language Creol {{which is based on}} duration statements indicating best and worst case <b>execution</b> times and <b>deadlines.</b> We show how to analyze schedulability of an abstraction of real-time concurrent objects in terms of timed automata. Further, we introduce techniques for testing the conformance between these behavioral abstractions and the executable semantics of Real-Time Creol in Real-Time Maude. As a case study we model and analyze the schedulability of thread pools in an industrial communication platform...|$|R
