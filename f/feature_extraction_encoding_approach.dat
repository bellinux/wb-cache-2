0|10000|Public
30|$|<b>Feature</b> <b>extraction</b> using fractal <b>encoding</b> of the {{normalized}} {{image and}} genetic algorithm.|$|R
30|$|The {{main problem}} with the BoVW {{approach}} is that the <b>feature</b> <b>extraction,</b> <b>feature</b> <b>encoding,</b> and classification are three separate problems. In order to counteract this problem, {{the size of the}} dictionary is increased to better divide the feature space, in some cases reaching hundreds of thousands of visual words. We created a neural network that is able to perform the same function as the BoVW but is able to learn jointly the <b>feature</b> <b>extraction,</b> coding, and classification functions.|$|R
30|$|This paper {{describes}} a methodology for diabetic retinopathy detection from eye fundus images using a generalization of the bag-of-visual-words (BoVW) method. We formulate the BoVW as two neural networks {{that can be}} trained jointly. Unlike the BoVW, our model is able {{to learn how to}} perform <b>feature</b> <b>extraction,</b> <b>feature</b> <b>encoding,</b> and classification guided by the classification error. The model achieves 0.97 area under the curve (AUC) on the DR 2 dataset while the standard BoVW approach achieves 0.94 AUC. Also, it performs at the same level of the state-of-the-art on the Messidor dataset with 0.90 AUC.|$|R
40|$|International audienceLocal video {{features}} provide state-of-the-art {{performance for}} action recognition. While {{the accuracy of}} action recognition has been continuously improved over the recent years, the low speed of <b>feature</b> <b>extraction</b> and subsequent recognition prevents current methods from scaling up to real-size problems. We address this issue and first develop highly efficient video features using motion information in video compression. We next explore feature encoding by Fisher vectors and demonstrate accurate action recognition using fast linear classifiers. Our method improves the speed of video <b>feature</b> <b>extraction,</b> <b>feature</b> <b>encoding</b> and action classification by two orders of magnitude {{at the cost of}} minor reduction in recognition accuracy. We validate our approach and compare it to {{the state of the art}} on four recent action recognition datasets...|$|R
40|$|The {{aim of this}} PhD {{thesis is}} to make a step forward towards {{teaching}} computers to understand videos in a similar way as humans do. In this work we tackle the video classification and/or action recognition tasks. This thesis was completed in a period of transition, the research community moving from traditional approaches (such as hand-crafted descriptor extraction) to deep learning. Therefore, this thesis captures this transition period, however, unlike image classification, where the state-of-the-art results are dominated by deep learning approaches, for video classification the deep learning approaches are not so dominant. As a matter of fact, most of the current state-of-the-art results in video classification are based on a hybrid approach where the hand-crafted descriptors are combined with deep features to obtain the best performance. This is due to several factors, such as the fact that video is a more complex data as compared to an image, therefore, more difficult to model and also that the video datasets are not large enough to train deep models with effective results. The pipeline for video classification can be broken down into three main steps: <b>feature</b> <b>extraction,</b> <b>encoding</b> and classification. While for the classification part, the existing techniques are more mature, for <b>feature</b> <b>extraction</b> and <b>encoding</b> there is still a significant room for improvement. In addition to these main steps, the framework contains some pre/post processing techniques, such as feature dimensionality reduction, feature decorrelation (for instance using Principal Component Analysis - PCA) and normalization, which can influence considerably the performance of the pipeline. One of the bottlenecks of the video classification pipeline is represented by the <b>feature</b> <b>extraction</b> step, where most of the approaches are extremely computationally demanding, what makes them not suitable for real-time applications. In this thesis, we tackle this issue, propose different speed-ups to improve the computational cost and introduce a new descriptor that can capture motion information from a video without the need of computing optical flow (which is very expensive to compute). Another important component for video classification is represented by the feature encoding step, which builds the final video representation that serves as input to a classifier. During the PhD, we proposed several improvements over the standard <b>approaches</b> for feature <b>encoding.</b> We also propose a new feature <b>encoding</b> <b>approach</b> for deep feature encoding. To summarize, the main contributions of this thesis are as follows 3 : (1) We propose several speed-ups for descriptor extraction, providing a version for the standard video descriptors that can run in real-time. We also investigate the trade-off between accuracy and computational efficiency; â€¨(2) We provide a new descriptor for extracting information from a video, which is very efficient to compute, being able to extract motion information without the need of extracting the optical flow; (3) We investigate different improvements over the standard <b>encoding</b> <b>approaches</b> for boosting the performance of the video classification pipeline.;(4) We propose a new feature <b>encoding</b> <b>approach</b> specifically designed for encoding local deep features, providing a more robust video representation. ...|$|R
40|$|The authors {{present a}} novel method for video {{retrieval}} on mobile devices. The target scenario is the following: features are extracted from a captured query video at the user side and transmitted {{to a remote}} server; then, video retrieval is applied within a stored database at the server side and relevant information about the query is returned to the user. In particular, {{we focus on the}} user side and propose a scalable method for video <b>feature</b> <b>extraction</b> and <b>encoding</b> taking into consideration the processing capabilities of the device and available bandwidth. Despite these constraints, the first results show a promising accuracy of retrieval...|$|R
40|$|This work {{presents}} an automatic technique for detection of abnormal events in crowds. Crowd behaviour {{is difficult to}} predict and might not be easily semantically translated. Moreover it is difficulty to track individuals in the crowd using {{state of the art}} tracking algorithms. Therefore we characterise crowd behaviour by observing the crowd optical flow and use unsupervised <b>feature</b> <b>extraction</b> to <b>encode</b> normal crowd behaviour. The unsupervised <b>feature</b> <b>extraction</b> applies spectral clustering to find the optimal number of models to represent normal motion patterns. The motion models are HMMs to cope with the variable number of motion samples that might be present in each observation window. The results on simulated crowds demonstrate the effectiveness of the approach for detecting crowd emergency scenarios. ...|$|R
40|$|Indirect Immunofluorescence Imaging of Human Epithelial Type 2 (HEp- 2) {{cells is}} an {{effective}} way to identify the presence of Anti-Nuclear Antibody (ANA). Most existing works on HEp- 2 cell classification mainly focus on <b>feature</b> <b>extraction,</b> <b>feature</b> <b>encoding</b> and classifier design. Very few efforts have been devoted to study the importance of the pre-processing techniques. In this paper, we analyze the importance of the pre-processing, and investigate the role of Gaussian Scale Space (GSS) theory as a pre-processing approach for the HEp- 2 cell classification task. We validate the GSS pre-processing under the Local Binary Pattern (LBP) and the Bag-of-Words (BoW) frameworks. Under the BoW framework, the introduced pre-processing approach, using only one Local Orientation Adaptive Descriptor (LOAD), achieved superior performance on the Executable Thematic on Pattern Recognition Techniques for Indirect Immunofluorescence (ET-PRT-IIF) image analysis. Our system, using only one feature, outperformed the winner of the ICPR 2014 contest that combined four types of features. Meanwhile, the proposed pre-processing method is not restricted to this work; it can be generalized to many existing works. Comment: 9 pages, 6 figure...|$|R
40|$|Object {{recognition}} {{is an important}} problem in computer vision, having diverse applications. In this work, we construct an end-to-end scene recognition pipeline consisting of <b>feature</b> <b>extraction,</b> <b>encoding,</b> pooling and classification. Our approach simultaneously utilize global feature descriptors {{as well as local}} feature descriptors from images, to form a hybrid feature descriptor corresponding to each image. We utilize DAISY features associated with key points within images as our local feature descriptor and histogram of oriented gradients (HOG) corresponding to an entire image as a global descriptor. We make use of a bag-of-visual-words encoding and apply Mini- Batch K-Means algorithm to reduce the complexity of our feature encoding scheme. A 2 -level pooling procedure is used to combine DAISY and HOG features corresponding to each image. Finally, we experiment with a multi-class SVM classifier with several kernels, in a cross-validation setting, and tabulate our results on the fifteen scene categories dataset. The average accuracy of our model was 76. 4 % {{in the case of a}} 40 %- 60 % random split of images into training and testing datasets respectively. The primary objective of this work is to clearly outline the practical implementation of a basic screne-recognition pipeline having a reasonable accuracy, in python, using open-source libraries. A full implementation of the proposed model is available in our github repository. Comment: A full implementation of our model is available at [URL]...|$|R
30|$|This paper {{investigates the}} problem of speaker {{recognition}} in noisy conditions. A new approach called nonnegative tensor principal component analysis (NTPCA) with sparse constraint is proposed for speech <b>feature</b> <b>extraction.</b> We <b>encode</b> speech as a general higher-order tensor in order to extract discriminative features in spectrotemporal domain. Firstly, speech signals are represented by cochlear feature based on frequency selectivity characteristics at basilar membrane and inner hair cells; then, low-dimension sparse features are extracted by NTPCA for robust speaker modeling. The useful information of each subspace in the higher-order tensor can be preserved. Alternating projection algorithm is used to obtain a stable solution. Experimental results demonstrate that our method can increase the recognition accuracy specifically in noisy environments.|$|R
40|$|The paper {{presents}} a fingerprint classification {{system and its}} performance in an identification system. The classification scheme is based on fingerprint <b>feature</b> <b>extraction,</b> which involves <b>encoding</b> the singular points (Core and Delta) together with their relative positions and directions obtained from a binaries fingerprint image. Image analysis is carried in four stages, namely, segmentation, directional image estimation, singular-point <b>extraction</b> and <b>feature</b> <b>encoding.</b> A fuzzyneural network classifier is used to implement the classification of input feature codes according to the well-known Henry system. Fingerprint images from NIST- 4 database were tested and, 98. 5 % classification accuracy was obtained for the five classes- problem...|$|R
50|$|Iris melanin, {{also known}} as chromophore, mainly {{consists}} of two distinct heterogeneous macromolecules, called eumelanin (brown-black) and pheomelanin (yellow-reddish), whose absorbance at longer wavelengths in the NIR spectrum is negligible. At shorter wavelengths within the VW spectrum, however, these chromophores are excited and can yield rich patterns. Hosseini, et al. provide a comparison between these two imaging modalities. An alternative <b>feature</b> <b>extraction</b> method to <b>encode</b> VW iris images was also introduced, which may offer an alternative approach for multi-modal biometric systems.|$|R
40|$|This paper evaluates an {{automatic}} technique for detection of abnormal events in crowds. Crowd behaviour {{is difficult to}} predict and might not be easily semantically translated. Moreover {{it is difficult to}} track individuals in the crowd using state of the art tracking algorithms. Therefore we characterise crowd behaviour by observing the crowd optical flow and use unsupervised <b>feature</b> <b>extraction</b> to <b>encode</b> normal crowd behaviour. The unsupervised <b>feature</b> <b>extraction</b> applies spectral clustering to find the optimal number of models to represent normal motion patterns. The motion models are HMMs to cope with the variable number of motion samples that might be present in each observation window. The results on simulated crowds analyse the robustness of the approach for detecting crowd emergency scenarios observing the crowd at local and global levels. The results on normal real data show the effectiveness in modelling the more diverse behaviour present in normal crowds. These results improve our previous work [1] in the detection of anomalies in pedestrian data. ...|$|R
40|$|This {{paper is}} a postprint {{of a paper}} {{submitted}} to and accepted for publication in ICPR 2006 and is subject to IEEE copyright. This work presents an automatic technique for detection of abnormal events in crowds. Crowd behaviour is difficult to predict and might not be easily semantically translated. Moreover it is difficulty to track individuals in the crowd using {{state of the art}} tracking algorithms. Therefore we characterise crowd behaviour by observing the crowd opti-cal flow and use unsupervised <b>feature</b> <b>extraction</b> to <b>encode</b> normal crowd behaviour. The unsupervised feature extrac-tion applies spectral clustering to find the optimal number of models to represent normal motion patterns. The mo-tion models are HMMs to cope with the variable number of motion samples that might be present in each observation window. The results on simulated crowds demonstrate the effectiveness of the approach for detecting crowd emergency scenarios. ...|$|R
40|$|Abstract. B-scan {{ultrasound}} {{provides a}} non-invasive low-cost imaging solution to primary care diagnostics. The inherent speckle {{noise in the}} images produced by this technique introduces uncertainty in the representation of their textural characteristics. To cope with the uncertainty, we propose a novel fuzzy <b>feature</b> <b>extraction</b> method to <b>encode</b> local texture. The proposed method extends the Local Binary Pattern (LBP) approach by incorporating fuzzy logic in the representation of local patterns of texture in ultrasound images. Fuzzification allows a Fuzzy Local Binary Pattern (FLBP) to contribute {{to more than a}} single bin in the distribution of the LBP values used as a feature vector. The proposed FLBP approach was experimentally evaluated for supervised classification of nodular and normal samples from thyroid ultrasound images. The results validate its effectiveness over LBP and other common <b>feature</b> <b>extraction</b> methods...|$|R
40|$|This paper {{presents}} the image information mining {{based on a}} communication channel concept. The <b>feature</b> <b>extraction</b> algorithms <b>encode</b> the image, while an analysis of topic discovery will decode and send its content to the user {{in the shape of}} a semantic map. We consider this approach for a real meaning based semantic annotation of very high resolution remote sensing images. The scene content is described using a multi-level hierarchical information representation. Feature hierarchies are discovered considering that higher levels are formed by combining features from lower level. Such a level to level mapping defines our methodology as a deep learning process. The whole analysis can be divided in two major learning steps. The first one regards the Bayesian inference to extract objects and assign basic semantic to the image. The second step models the spatial interactions between the scene objects based on Latent Dirichlet Allocation, performing a high level semantic annotation. We used a WorldView 2 image to exemplify the processing results. ...|$|R
30|$|Face {{recognition}} {{has attracted}} lots of attention, but current systems are yet far from human perception capabilities. A critical issue in face recognition is finding apt descriptors for modeling faces. Based on the descriptors, face recognition techniques can be broadly {{divided into three}} categories; holistic, feature-based, and hybrid face matching [17]. In holistic methods, the face is modeled by extracting a set of global features [18]. In this context, principal component analysis (PCA) [18], Mahalanobis cosine PCA (MahCos PCA) [19], linear discriminant analysis (LDA) [20], and 2 D PCA [21] have been explored. On the other hand, local feature-based descriptors have shown robustness to variance in pose and illumination [22]. Biswas et al. [23] described local facial landmarks with the Scale-Invariant Feature Transform (SIFT) features. At each landmark, Gabor magnitude factors are extracted as the pose-robust feature. Fischer et al. [24] suggested that extracting landmarks for non-frontal faces had a degrading effect on the recognition results and proposed robust landmark extraction around nose tip and mouth corners. Guo et al. [25] proposed local binary patterns (LBP)-based <b>features</b> <b>extraction</b> for <b>encoding</b> facial landmarks.|$|R
40|$|AbstractTexture {{analysis}} {{is a major}} task {{in many areas of}} computer vision and pattern recognition, including biological imaging. Indeed, visual textures can be exploited to distinguish specific tissues or cells in a biological sample, to highlight chemical reactions between molecules, as well as to detect subcellular patterns that can be evidence of certain pathologies. This makes automated texture analysis fundamental in many applications of biomedicine, such as the accurate detection and grading of multiple types of cancer, the differential diagnosis of autoimmune diseases, or the study of physiological processes. Due to their specific characteristics and challenges, the design of texture analysis systems for biological images has attracted ever-growing attention in the last few years. In this paper, we perform a critical review of this important topic. First, we provide a general definition of texture analysis and discuss its role in the context of bioimaging, with examples of applications from the recent literature. Then, we review the main approaches to automated texture analysis, with special attention to the methods of <b>feature</b> <b>extraction</b> and <b>encoding</b> that can be successfully applied to microscopy images of cells or tissues. Our aim is to provide an overview {{of the state of the}} art, as well as a glimpse into the latest and future trends of research in this area...|$|R
40|$|Biometrics {{is the use}} of {{physical}} characteristics like face, fingerprints, iris etc. of an individual for personal identification. Some of the challenging problems of face biometrics are face detection, face recognition, and face identification. These problems are being researched by the computer vision community for the last few decades. Considering the large population, the authentication process of an individual usually consumes a significant amount of time. One of the possible solutions is to divide the population into two halves based on gender. This will help to reduce the search space of authentication to almost half of the existing data and save substantial amount of time. Gender identification through face demands use of strong discriminative features and robust classifiers to separate the female and male faces without any ambiguity. In this thesis, an investigation has been made on gender classification through facial images using principal component analysis (PCA), and support vector machine (SVM). PCA is a dimensionality reduction technique, which is used to represent each image as a feature vector in a low dimensional subspace. SVM is a binary classifier for which PCA is the input in the form of features and predicts which of the two possible classes forms the output. Initially face region is extracted using a proposed skin colour segmentation approach. The face region is then subjected to PCA for <b>feature</b> <b>extraction,</b> which <b>encodes</b> second order statistics of data. These principal components are fed as input to SVM for classification...|$|R
40|$|This paper {{proposes a}} new face {{recognition}} algorithm called local derivative tetra pattern (LDTrP). The new technique LDTrP is used to alleviate the face recognition rate under real-time challenges. Local derivative pattern (LDP) is a directional <b>feature</b> <b>extraction</b> method to <b>encode</b> directional pattern features based on local derivative variations. The nth -order LDP is proposed to encode the first (n- 1) th order local derivative direction variations. The LDP templates extract high-order local information by encoding various distinctive spatial relationships contained in a given local region. The local tetra pattern (LTrP) encodes {{the relationship between the}} reference pixel and its neighbours by using the first-order derivatives in vertical and horizontal directions. LTrP extracts values which are based on the distribution of edges which are coded using four directions. The LDTrP combines the higher order directional feature from both LDP and LTrP. Experimental results on ORL and JAFFE database show that the performance of LDTrP is consistently better than LBP, LTP and LDP for face identification under various conditions. The performance of the proposed method is measured in terms of recognition rate...|$|R
40|$|Classification {{means to}} assign a given {{fingerprint}} {{to one of}} the existing classes already recognized in the literature. A search over all the fingerprints in the database takes a long time, so the goal is to reduce the search time and computational complexity by choosing an appropriate subset of database for search. Classifying a fingerprint images is and will remain a challenging problem in pattern recognition, due to the minimal interclass variability and maximal intraclass variability. This paper presents some intermediate results on fingerprint classification adopting a fuzzy neural network as decision stage. The classification is based on fingerprint <b>feature</b> <b>extraction,</b> which involves <b>encoding</b> the singular points (Core and Delta) together with their relative positions obtained from a fingerprint image. The output vector is defined in terms of membership values to the five classes, arch tented arch, whorl, left Loop and right Loop. Three models of fuzzy neural networks were implemented and fingerprint images from CASIA-FingerprintV 5 database were used for training and testing these networks. The experimental results have shown that the performance of Fuzzy neural networks is better as compared to the general neural network for fingerprint classification...|$|R
30|$|The {{more complex}} the {{structure}} of equipment is, the more the types of faults there are. The fault status and features are getting more and more. <b>Feature</b> <b>extraction</b> is {{necessary in order to}} make use of the information economically and efficiently. The ordinary methods of <b>feature</b> <b>extraction</b> are principle component <b>feature</b> <b>extraction,</b> <b>feature</b> <b>extraction</b> based on neural network, <b>feature</b> <b>extraction</b> based on wavelet transform, <b>feature</b> <b>extraction</b> based on mutual information entropy, <b>feature</b> <b>extraction</b> based on rough set, <b>feature</b> <b>extraction</b> based on the characteristics of fuzzy information optimization processing, <b>feature</b> <b>extraction</b> based on Euclidean distance, <b>feature</b> <b>extraction</b> based on probability distance measuring, <b>feature</b> <b>extraction</b> based on divergence criterion function, <b>feature</b> <b>extraction</b> based on support vector machine (SVM) etc.|$|R
40|$|Heart {{auscultation}} signal {{has served}} as an important primary symptom to identify pathological condition of cardiovascular system for a long time. However, clinical capabilities to properly analyze Heart Sound (HS) have regressed recently. Thus, a new approach for automated Cardiovascular Disease (CVD) diagnosis based on complexity and similarity analysis of HS is presented. The relevant technologies namely, Musical Instrument Digital Interface (MIDI) coding and N-gram encoding are utilized for <b>feature</b> <b>extraction</b> and pattern <b>encoding</b> of HS. Lempel and Ziv (LZ) complexity and Super-symmetric Comparison Distance (SCD) similarity measure are {{used to measure the}} complexity and similarity between two HSs individually. To identify specific problems and important attributes required for HS analysis using the proposed approach, various simulated HS signals are generated and critically tested. The effect of change in amplitude, heart rate and length of HS record are identified on the diagnosis results and their thresholds or tolerances are predefined. Through such explored results, HS records of patients with different physiological characteristics which are practically incomparable are made comparable. The final testing results of such a novel approach with an average diagnostic accuracy above 70 % in identifying some CVDs through comparing similarities of pathological conditions of HS with ones in benchmark database (DB) proves its feasibility and availability...|$|R
40|$|With {{microarray}} gene-expression data, {{we compare}} supervised <b>feature</b> <b>extraction</b> methods with the unsupervised <b>feature</b> <b>extraction</b> methods. From experimental results, it is {{shown that the}} supervised <b>feature</b> <b>extraction</b> methods are {{more powerful than the}} unsupervised <b>feature</b> <b>extraction</b> methods in terms of class separability...|$|R
40|$|Pupylation, one of {{the most}} {{important}} posttranslational modifications of proteins, typically takes place when prokaryotic ubiquitin-like protein (Pup) is attached to specific lysine residues on a target protein. Identification of pupylation substrates and their corresponding sites will facilitate the understanding of the molecular mechanism of pupylation. Comparing with the labor-intensive and time-consuming experiment approaches, computational prediction of pupylation sites is much desirable for their convenience and fast speed. In this study, a new bioinformatics tool named EnsemblePup was developed that used an ensemble of support vector machine classifiers to predict pupylation sites. The highlight of EnsemblePup was to utilize the Bi-profile Bayes <b>feature</b> <b>extraction</b> as the <b>encoding</b> scheme. The performance of EnsemblePup was measured with a sensitivity of 79. 49 %, a specificity of 82. 35 %, an accuracy of 85. 43 %, and a Matthews correlation coefficient of 0. 617 using the 5 -fold cross validation on the training dataset. When compared with other existing methods on a benchmark dataset, the EnsemblePup provided better predictive performance, with a sensitivity of 80. 00 %, a specificity of 83. 33 %, an accuracy of 82. 00 %, and a Matthews correlation coefficient of 0. 629. The experimental results suggested that EnsemblePup presented here might be useful to identify and annotate potential pupylation sites in proteins of interest. A web server for predicting pupylation sites was developed...|$|R
40|$|Abstract: Face Recognition is non-intrusive {{method of}} {{identifying}} individual faces by the <b>feature</b> <b>extraction</b> and classification of faces. Facial <b>feature</b> <b>extraction</b> {{is one of}} the most important and attempted problems in computer vision. This paper compares the different facial <b>feature</b> <b>extraction</b> techniques like geometry-based <b>feature</b> <b>extraction</b> (Gabor wavelet transform), appearance based techniques, color segmentation based techniques and template based <b>feature</b> <b>extraction.</b> These techniques provide diverse performance with various factors such as illumination variation, face expression variation noise and orientation...|$|R
40|$|Abstract. KPCA is a {{commonly}} used method for <b>feature</b> <b>extraction,</b> {{for the problems}} of kernel function and its parameters have a great influence on performance of KPCA <b>feature</b> <b>extraction</b> but the optimal parameters are difficult to select. This paper applied the bacterial foraging algorithm on KPCA <b>feature</b> <b>extraction</b> and the method of KPCA <b>feature</b> <b>extraction</b> based on bacterial foraging algorithm was proposed. The experiment of bearing <b>feature</b> <b>extraction</b> shows that the method which proposed in this paper is effective...|$|R
30|$|Additionally, {{there are}} many {{different}} <b>feature</b> <b>extraction</b> methods for each type feature. For example, the color <b>feature</b> <b>extraction</b> methods include color histogram, color invariant, color moments, etc. The texture <b>feature</b> <b>extraction</b> methods include Gray Level Co-occurrence Matrix (GLCM), Tamura, Gabor translation, etc. The shape <b>feature</b> <b>extraction</b> methods have contour-based extraction and region-based <b>extraction.</b> <b>Features</b> extracted from different <b>feature</b> <b>extraction</b> methods in the same type describe image information from various angles. For this reason, {{it is very difficult to}} find suitable <b>feature</b> <b>extraction</b> methods in various of ways. In this paper, we use a variety of <b>feature</b> <b>extraction</b> methods for each type and combine them to a multi-type feature. At last, the multi-type feature is sent into the classifier to recognize, and the recognition rate is higher than that of the existing literature.|$|R
50|$|Summarization {{of media}} content (<b>feature</b> <b>extraction).</b> The result of <b>feature</b> <b>extraction</b> is a description.|$|R
3000|$|Under the {{analysis}} grouping, the first paper is [...] "Phasor representation for narrowband {{active noise control}} systems" [...] by Fu-Kun Chen et al. This paper uses signal phasors to analyze behavior of two-tap adaptive filters for canceling norrowband noise, and proposes a best signal basis to improve both the convergence speed and steady-state performance. The second paper is [...] "On a method for improving impulsive sounds localization in hearing defenders" [...] by Benny SÃ¤llberg et al. This study presents a new algorithm to enhance perceived directionality of active hearing defenders used in police and military applications. The algorithm uses interaural level difference to enhance spatial information without increasing the impulse sound levels. [...] "Auditory sparse representation for robust speaker recognition based on tensor structure," [...] by Qiang Wu et al., looks into using a non-negative tensor principal component analysis for speech <b>feature</b> <b>extraction.</b> By <b>encoding</b> the speech in higher-order tensors, discriminative features can be extracted in the spectral-temporal domain to increase accuracy in speaker recognition in noisy environments. The next paper entitled [...] "Towards an intelligent acoustic front-end for automatic speech recognition: built-in speaker normalization (BISN)," [...] by Umit Yapanel and John Hansen, proposes a novel online vocal track length normalization algorithm entitled built-in speaker normalization. This algorithm unifies the nonlinear frequency warping function and speaker variability due to vocal tract length differences in the front-end of the automatic speech recognition and significantly reduces computational complexity. Significant word error-rate performance has also been achieved by this new algorithm for in-car and military noisy environments. The final paper in this grouping is on [...] "Using SVM as back-end classifier for language identification" [...] by Hongbin Suo et al. This paper describes an approach using support vector machines (SVMs) with radial basis function kernel for back-end classifier in language identification. Furthermore, a pair-wise posterior probability estimation is used to calibrate the output of each classifier.|$|R
40|$|International audienceThe {{complexity}} of Balinese script {{and the poor}} quality of palm leaf manuscripts provide a new challenge for testing and evaluation of robustness of <b>feature</b> <b>extraction</b> methods for character recognition. With the aim of finding the combination of <b>feature</b> <b>extraction</b> methods for character recognition of Balinese script, we present, in this paper, our experimental study on <b>feature</b> <b>extraction</b> methods for character recognition on palm leaf manuscripts. We investigated and evaluated the performance of 10 <b>feature</b> <b>extraction</b> methods and we proposed the proper and robust combination of <b>feature</b> <b>extraction</b> methods to increase the recognition rate...|$|R
5000|$|Methods for the {{summarization}} {{of media}} content (<b>feature</b> <b>extraction).</b> The result of <b>feature</b> <b>extraction</b> is a description.|$|R
40|$|In this {{technical}} report {{we want to}} connect two invariant <b>feature</b> <b>extraction</b> techniques, namely Shape Distribution and <b>feature</b> <b>extraction</b> based on Group Integration. Both techniques have a proven good performance, where Group Integration is mainly used for <b>feature</b> <b>extraction</b> on gray-value images [5, 6, 7, 1] and Shap...|$|R
40|$|This paper {{presents}} {{an overview of}} <b>feature</b> <b>extraction</b> methods for off-line recognition of segmented (isolated) characters. Selection of a <b>feature</b> <b>extraction</b> method is probably {{the single most important}} factor in achieving high recognition performance in character recognition systems. Different <b>feature</b> <b>extraction</b> methods are designed for different representations of the characters, such as solid binary characters, character contours, skeletons (thinned characters) or gray-level subimages of each individual character. The <b>feature</b> <b>extraction</b> methods are discussed in terms of invariance properties, reconstructability and expected distortions and variability of the characters. The problem of choosing the appropriate <b>feature</b> <b>extraction</b> method for a given application is also discussed. When a few promising <b>feature</b> <b>extraction</b> methods have been identified, they need to be evaluated experimentally to find the best method for the given application...|$|R
40|$|In Handwritten {{signatures}} {{analyzed for}} forgery have to undergo <b>feature</b> <b>extraction</b> process, due to varied samples in size rotation and intra-domain changes, invariance {{has to be}} achieved during <b>feature</b> <b>extraction</b> process; circular Hidden Markov Model with discrete radon transform approach of <b>feature</b> <b>extraction</b> provides invariance. On other hand Scale Invariant Feature Transform (SIFT) has inherent invariant <b>feature</b> <b>extraction</b> approach. This paper compares both approaches on common signature databases for False acceptance rate (FAR), False Rejection Rate (FRR) an...|$|R
40|$|<b>Feature</b> <b>extraction,</b> or {{dimensionality}} reduction, is {{an essential}} part of many machine learning applications. The necessity for <b>feature</b> <b>extraction</b> stems from the curse of dimensionality and the high computational cost of manipulating high-dimensional data. In this thesis we focus on <b>feature</b> <b>extraction</b> for classification. There are several approaches, and we will focus on two such: the increasingly popular information-theoretic approach, and the classical distance-based, or variance-based approach. Current algorithms for information-theoretic <b>feature</b> <b>extraction</b> are usually iterative. In contrast, PCA and LDA are popular examples of <b>feature</b> <b>extraction</b> techniques that can be solved by eigendecomposition, and do not require an iterative procedure. We study the behaviour of an example of iterative algorithm that maximises Kapur's quadratic mutual information by gradient ascent, and propose a new estimate of mutual information that can be maximised by closed-form eigendecomposition. This new technique is more computationally efficient than iterative algorithms, and its behaviour is more reliable and predictable than gradient ascent. Using a general framework of eigendecomposition-based <b>feature</b> <b>extraction,</b> we show a connection between information-theoretic and distance-based <b>feature</b> <b>extraction.</b> Using the distance-based approach, we study the effects of high input dimensionality and over-fitting on <b>feature</b> <b>extraction,</b> and propose a family of eigendecomposition-based algorithms that can solve this problem. We investigate the relationship between class-discrimination and over-fitting, and show why the advantages of information-theoretic <b>feature</b> <b>extraction</b> become less relevant in high-dimensional spaces. Open Acces...|$|R
