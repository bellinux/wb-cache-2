11|1|Public
30|$|The linear {{least squares}} (LLS) method finds a best fitting linear model that {{minimizes}} the {{mean square error}} between the system output and the desired output. Mathematically, it can be stated as finding an approximate solution to an overdetermined system of linear equations. Because the model output is only the weighted sum of the input features, it is suitable for implementation using processors without high computing power or for use in online processing. Linear discriminant analysis (LDA) uses a hyperplane to find the linear combination of features that best separates two or more classes of objects or events. Usually, the within-class, between-class, and mixture scatter matrices are used to formulate the criteria for searching the hyperplane so that {{the distance between the}} classes' means is minimized and the <b>interclass</b> <b>variance</b> is maximized [45, 46].|$|E
40|$|Abstract. Multi-variate side-channel attacks {{allow to}} break higher-order masking protections by {{combining}} several leakage samples. But how to optimally extract {{all the information}} contained in all possible d-tuples of points? In this article, we intro-duce preprocessing tools that answer this question. We first show that maximizing the higher-order CPA coefficient is equivalent to finding the maximum of the covariance. We apply this equivalence to the problem of trace dimensionality reduction by linear combination of its samples. Then we establish the link between this problem and the Principal Component Analysis. In a second step we present the optimal solution for the problem of maximizing the covariance. We also theoretically and empirically compare these methods. We finally apply them on real measurements, publicly avail-able under the DPA Contest v 4, to evaluate how the proposed techniques improve the second-order CPA (2 O-CPA). Keywords:Bi-variate attacks, second-order correlation power analysis (2 O-CPA), principal component analysis, <b>interclass</b> <b>variance,</b> covariance vector...|$|E
40|$|This paper {{presents}} a novel method {{for improving the}} training step of the single-scale Gabor filters by using the Boltzmann univariate marginal distribution algorithm (BUMDA) in X-ray angiograms. Since the single-scale Gabor filters (SSG) are governed by three parameters, the optimal selection of the SSG parameters is highly desirable {{in order to maximize}} the detection performance of coronary arteries while reducing the computational time. To obtain the best set of parameters for the SSG, the area (Az) under the receiver operating characteristic curve is used as fitness function. Moreover, to classify vessel and nonvessel pixels from the Gabor filter response, the <b>interclass</b> <b>variance</b> thresholding method has been adopted. The experimental results using the proposed method obtained the highest detection rate with Az= 0. 9502 over a training set of 40 images and Az= 0. 9583 with a test set of 40 images. In addition, the experimental results of vessel segmentation provided an accuracy of 0. 944 with the test set of angiograms...|$|E
40|$|Recent {{studies have}} {{demonstrated}} the disassociation between the mu and beta rhythms of electroencephalogram (EEG) during motor imagery tasks. The proposed algorithm in this paper uses a fully data-driven multivariate empirical mode decomposition (MEMD) {{in order to obtain}} the mu and beta rhythms from the nonlinear EEG signals. Then, the strong uncorrelating transform complex common spatial patterns (SUTCCSP) algorithm is applied to the rhythms so that the complex data, constructed with the mu and beta rhythms, becomes uncorrelated and its pseudocovariance provides supplementary power difference information between the two rhythms. The extracted features using SUTCCSP that maximize the <b>interclass</b> <b>variances</b> are classified using various classification algorithms for the separation of the left- and right-hand motor imagery EEG acquired from the Physionet database. This paper shows that the supplementary information of the power difference between mu and beta rhythms obtained using SUTCCSP provides an important feature for the classification of the left- and right-hand motor imagery tasks. In addition, MEMD is proved to be a preferred preprocessing method for the nonlinear and nonstationary EEG signals compared to the conventional IIR filtering. Finally, the random forest classifier yielded a high performance for the classification of the motor imagery tasks...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedA computer processing technique is advanced {{which seeks to}} retain or improve data information context while reducing the dimensionality of data representation. Defining information context as the relative proximity of data points, a nonlinear transformation is analytically derived which utilizes Euclidean distance {{to one or more}} reference points to provide a measure of similarity "between data points. The nonarbitrary reference points are selectively manipulated to provide, given certain constraints, a unique mapping from high dimensional space to one or more dimensions for each point in space. The transformation process enhances class clustering and interclass separation in the lower dimensional representation. Computer processed experimental results are presented of reduction from 32, 10, and 3 space into 2 space for both synthetic and real world data. Utilizing a ratio of intraclass variance to <b>interclass</b> <b>variance</b> as a figure of merit and as one possible optimization criterion, this technique yielded a significant ratio improvement in mapping from higher dimensional space into 2 dimensional space for all cases examined. [URL] United States Nav...|$|E
40|$|Separating {{an object}} in an image from its {{background}} is a central problem (called segmentation) in pattern recognition and computer vision. In this paper, we study {{the complexity of the}} segmentation problem, assuming that the object forms a connected region in an intensity image. We show that the optimization problem of separating a connected region in an n-pixel grid is NP-hard under the <b>interclass</b> <b>variance,</b> a criterion that is used in discriminant analysis. More importantly, we consider the basic case in which the object is separated by two x-monotone curves (i. e., the object itself is x-monotone), and present polynomial-time algorithms for computing exact and approximate optimal segmentation. Our main algorithm for exact optimal segmentation by two x-monotone curves runs in O(n^ 2) time; this algorithm is based on several techniques such as a parametric optimization formulation, a hand-probing algorithm for the convex hull of an unknown point set, and dynamic programming using fast matrix searching. Our efficient approximation scheme obtains an ε-approximate solution in O(ε^ n log L) time, whereεis any fixed constant with 1 >ε> 0, and L is the total sum of the absolute values of brightness levels of the image...|$|E
40|$|Motivation: Gene {{expression}} profiles should {{be useful in}} distinguishing variations in disease, since they reflect accurately the status of cells. The primary clustering of gene expression reveals the genotypes {{that are responsible for}} the proximity of members within each cluster, while further clustering elucidates the pathological features of the individual members of each cluster. However, since the first clustering process and the second classification step, in which the features are associated with clusters, are performed independently, the initial set of clusters may omit genes that are associated with pathologically meaningful features. Therefore, it is important to devise a way of identifying gene expression clusters that are associated with pathological features. Results: We present the novel technique of ‘itemset constrained clustering ’ (IC-Clustering), which computes the optimal cluster that maximizes the <b>interclass</b> <b>variance</b> of gene expression between groups, which are divided according to the restriction that only divisions that can be expressed using common features are allowed. This constraint automatically labels each cluster with a set of pathological features which characterize that cluster. When applied to liver cancer datasets, IC-Clustering revealed informative gene expression clusters, which could be annotated with various pathological features, such as ‘tumor ’ and ‘man’, or ‘except tumor ’ and ‘normal liver function’. In contrast, the k-means method overlooked these clusters. Contact...|$|E
40|$|This paper proposes the {{application}} of 3 different kinds of feature extractors to recognize & classify 5 models of vehicles. These feature extractors are Fast Fourier transform, discrete wavelet transform & discrete curvelet transform. To justify the correct amount of each feature extractor, we perform each of the mentioned transforms to input images, precisely. The classifier used in this paper is called k nearest-neighbor. The results of this test show, that the right recognition rate of vehicle’s model in this recognition system, {{at the time of}} using curvelet transform (Notice, all curvelet coefficients) is 100 %. For decreasing the dimension of feature vectors more & choosing the best features we’ve used <b>interclass</b> <b>variance</b> criteria to infraclass variance criteria. As a result of this performance, the size of feature vectors will be extremely decreased. Then, we perform our final impact feature vectors (The best Curvelet coefficients or the best wavelet coefficients or the best Fourier coefficients) to the KNN Classifier. Also, the results of this test show, the right recognition rate of vehicle’s model in this recognition system, at the time of using 0. 1 of all curvelet coefficients is 100 %. The comparison of the 3 proposed approaches for identifying the kind of vehicles showed that curvelet transform can extract better features among the proposed dataset. 1...|$|E
40|$|Abstract—Image {{segmentation}} by thresholding is a {{usual way}} in im- age processing and analysis. With some measures of differ- ence between images, some new methods for image thresh- old selection are put forward {{based on the}} principle that the difference between two parts from an good threshold-ing segmentation should be big and the differences between original image and two parts are both big. The OTSU al-gorithm(Maximization of <b>interclass</b> <b>variance)</b> is one of the superior threshold selection methods. Otsu’s method of im- age segmentation selects an optimum threshold by maxi- mizing the between-class variance in a gray image. Un- der studying the principle of Otsu method, we found it still deals directly with the gray-level histogram by parametric techniques, and the histogram is approximated in the least square sense by a sum of Gaussian distributions. However, the low-bandwidth Gaussian randomized procedure will be a more excellent model because of the low-bandwidth fre- quency response of the image transmission and acquisition system. In this case, the object and the background in im- age obey Rayleigh distributions, an improved threshold im- age segmentation algorithm based on the Otsu method is developed. The new improved algorithm takes into account that the object and the background in image obey Rayleigh distributions, and the maximum between-cluster variance is modified based on the model. From the experiment, the results show that the new improved algorithm has these ad- vantages such as high segmentation precision and fast com- putation speed. I...|$|E
30|$|This paper {{shows the}} use of a {{specific}} type of time series analyses, the so named recurrence plot (RP), for investigations of the outer hull of an imaged and pre-segmented object to derive image features suitable for usage in classificators. Additionally to the features derived by the well documented recurrence quantification analysis (RQA) a new set of features was developed based on closed structures (“eyes”) in a RP. The new features were named eye structure quantification (ESQ). Two sets of images are analysed: a) 1023 in-situ plankton images comprising nine different organism classes, and b) each 50 algorithmically created geometric shapes of five different classes. These images were characterised by standard image features, RQA quantification and the newly proposed features. A Linear Discriminant Analysis (LDA) was used to determine discriminative success between the classes of plankton organisms or geometric shapes respectively. The discriminative success was compared between a model using standard features and additional RQA and ESQ. For the high intra- and low <b>interclass</b> <b>variance</b> of the plankton contour line data set the included features enhanced discriminative success by 3  % to a maximum of 65.8  %. For the data set of geometric shapes an increase of 6.8  % to 95.2  % was observed. Although the overall increase of discriminative success was not extraordinary high by using a linear model, {{it can be seen that}} both RQA and ESQ are valuable auxiliary features to split specific classes from the entire population. Thus, they may also be valuable for methods mapping the finite dimensional feature space into higher dimensional spaces (e.g. Kernel trick, Support Vector Machines).|$|E
40|$|Abstract Background In {{order to}} detect {{potential}} disease clusters where a putative source cannot be specified, classical procedures scan the geographical area with circular windows through a specified grid imposed to the map. However, {{the choice of}} the windows' shapes, sizes and centers is critical and different choices may not provide exactly the same results. The aim of our work was to use an Oblique Decision Tree model (ODT) which provides potential clusters without pre-specifying shapes, sizes or centers. For this purpose, we have developed an ODT-algorithm to find an oblique partition of the space defined by the geographic coordinates. Methods ODT is based on the classification and regression tree (CART). As CART finds out rectangular partitions of the covariate space, ODT provides oblique partitions maximizing the <b>interclass</b> <b>variance</b> of the independent variable. Since it is a NP-Hard problem in R N, classical ODT-algorithms use evolutionary procedures or heuristics. We have developed an optimal ODT-algorithm in R 2, based on the directions defined by each couple of point locations. This partition provided potential clusters which can be tested with Monte-Carlo inference. We applied the ODT-model to a dataset in order to identify potential high risk clusters of malaria in a village in Western Africa during the dry season. The ODT results were compared with those of the Kulldorff' s SaTScan™. Results The ODT procedure provided four classes of risk of infection. In the first high risk class 60 %, 95 % confidence interval (CI 95 %) [52. 22 – 67. 55], of the children was infected. Monte-Carlo inference showed that the spatial pattern issued from the ODT-model was significant (p Satscan results yielded one significant cluster where the risk of disease was high with an infectious rate of 54. 21 %, CI 95 % [47. 51 – 60. 75]. Obviously, his center was located within the first high risk ODT class. Both procedures provided similar results identifying a high risk cluster {{in the western part of}} the village where a mosquito breeding point was located. Conclusion ODT-models improve the classical scanning procedures by detecting potential disease clusters independently of any specification of the shapes, sizes or centers of the clusters. </p...|$|E

