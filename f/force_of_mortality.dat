113|10000|Public
5000|$|In many instances, {{it is also}} {{desirable}} to determine the survival probability function when the <b>force</b> <b>of</b> <b>mortality</b> is known. To do this, integrate the <b>force</b> <b>of</b> <b>mortality</b> over the interval x to x + t ...|$|E
50|$|To {{understand}} conceptually how the <b>force</b> <b>of</b> <b>mortality</b> operates {{within a}} population, {{consider that the}} ages, x, where the probability density function fX(x) is zero, {{there is no chance}} of dying. Thus the <b>force</b> <b>of</b> <b>mortality</b> at these ages is zero.|$|E
5000|$|The <b>force</b> <b>of</b> <b>mortality</b> (hazard rate {{or failure}} rate) is [...] where f(x) is the {{probability}} density function. Under de Moivre's law, the <b>force</b> <b>of</b> <b>mortality</b> {{for a life}} aged x iswhich has the property of an increasing failure rate with respect to age.|$|E
40|$|In {{this paper}} we {{consider}} simultaneous estimation of a monotone sequence of parameters {{in the context}} of compound decision theory and obtain a class of monotone estimators with the strong asymptotic property that their compound risk converges uniformly to zero, for a large class of loss functions including the square error loss function and the absolute deviation loss function, as the number of parameters increases. We also show that when the number of parameters is fixed our estimators converge uniformly in probability to the parameters they are estimating, as the number of observations increases. As examples we consider estimation <b>of</b> <b>forces</b> <b>of</b> <b>mortality</b> with censored data in single and double decrement environments. Compound decision theory Monotone estimates Minimum distance <b>Forces</b> <b>of</b> <b>mortality</b> Censored data Asymptotically optimal Maximum likelihood...|$|R
40|$|Observing {{that there}} is a linear {{relationship}} between two sequences of the logarithm <b>of</b> the <b>forces</b> <b>of</b> <b>mortality</b> (hazard rates <b>of</b> the future lifetime) for two years, two variations of the linear logarithm hazard transform (LLHT) model are proposed in this project. We first regress the sequence of the logarithm <b>of</b> the <b>forces</b> <b>of</b> <b>mortality</b> for a cohort in year y on that for a base year. Next, we repeat the same procedure a number of times with y increased by one and the base year unchanged each time, and produce two sequences of slope and intercept parameters which both look linear. Then the simple linear regression and random walk with drift model are applied to each of these two parameter sequences. The fitted parameters can be used to forecast cohort mortality rates. Deterministically and stochastically forecasted cohort mortality rates with the two LLHT-based approaches, and the Lee-Carter and CBD models are presented, and their corresponding forecasted errors and associated confidence intervals are calculated for comparing the forecasting performances. Applications in pricing term life insurance and annuities are also given for illustration...|$|R
40|$|Fishery {{management}} plans ignore {{the potential for}} evolutionary change in har-vestable biomass. We subjected populations of an exploited fish (Menidia menidia) to large, small, or random size-selective harvest of adults over four generations. Harvested biomass evolved rapidly in directions counter to the size-dependent <b>force</b> <b>of</b> fishing <b>mortality.</b> Large-harvested populations initially produced the high-est catch but quickly evolved a lower yield than controls. Small-harvested popu-lations did the reverse. These shifts were caused by selection of genotypes with slower or faster rates of growth. Management tools that preserve natural genetic variation are necessary for long-term sustainable yield. It is well established that wild pest and pathogen populations may evolve in response to anthro-pogenic <b>forces</b> <b>of</b> <b>mortality</b> (1), but is the same true <b>of</b> fisheries? Fishing <b>mortality</b> is highly selective. Exploited stocks typically display greatly truncated size and age distributions tha...|$|R
5000|$|The <b>force</b> <b>of</b> <b>mortality</b> of the {{survival}} function {{is defined as}} ...|$|E
50|$|In actuarial science, {{the hazard}} rate is {{the rate of}} death for lives aged x. For a life aged x, the <b>force</b> <b>of</b> <b>mortality</b> t years later is the <b>force</b> <b>of</b> <b>mortality</b> for a (x + t)-year old. The hazard rate is also called the failure rate. Hazard rate and failure rate are names used in {{reliability}} theory.|$|E
5000|$|... where FX(x) is the {{cumulative}} distribution function of the continuous age-at-death random variable, X. As Δx tends to zero, so does this probability in the continuous case. The approximate <b>force</b> <b>of</b> <b>mortality</b> is this probability divided by Δx. If we let Δx tend to zero, we get the function for <b>force</b> <b>of</b> <b>mortality,</b> denoted as μ(x): ...|$|E
40|$|In this project, two {{approaches}} {{based on the}} linear logarithm hazard transform (LLHT) to modeling mortality rates are proposed. Empirical observations {{show that there is}} a linear relationship between two sequences of logarithm <b>of</b> the <b>forces</b> <b>of</b> <b>mortality</b> (hazard rates <b>of</b> the future lifetime) for two years. The estimated two parameters of the linear relationship can be used for forecasting mortality rates. Deterministic and stochastic mortality rates with the LLHT, Lee-Carter and CBD models are predicted, and their corresponding forecasted errors are calculated for comparing the forecasting performances. Finally, applications to pricing some mortality-linked securities based on the forecasted mortality rates are presented for illustration...|$|R
40|$|In this paper, {{we propose}} new {{relational}} models linking some specific mortality experience to a reference life table. Compared to existing relational models which distort the <b>forces</b> <b>of</b> <b>mortality,</b> we work {{here on the}} age scale. Precisely, age is distorted making individuals younger or older before performing the computations with the reference life table. This {{is in line with}} standard actuarial practice, specifically with the so-called Rueff’s adjustments. It is shown that the statistical inference can be conducted {{with the help of a}} suitably modified version of the standard IRWLS algorithm in a Poisson GLM/GAM setting. A dynamic version of this model is proposed to produce mortality projections. Numerical illustrations are performed on Belgian mortality statistics...|$|R
40|$|In large portfolios, {{the risk}} borne by annuity {{providers}} (insurance companies or pension funds) is basically {{driven by the}} randomness in the future mortality rates. To fix the ideas, we adopt here the standard Lee-Carter framework, where the future <b>forces</b> <b>of</b> <b>mortality</b> are decomposed in a log-bilinear way. This paper aims to provide accurate approximations for the quantiles of the conditional expected present value of the payments to the annuity provider, given the future path of the Lee-Carter time index. Mortality is stochastic while the discount factors are derived from a zero-coupon yield curve and {{are assumed to be}} deterministic. Numerical illustrations based on Belgian mortality (general population and insurance market statistics) show that the accuracy of the approximations proposed in this paper is remarkable, with relative difference less than 1 % for most probability levels. (C) 2007 Elsevier B. V. All rights reserved...|$|R
5000|$|This {{example is}} taken from. A {{survival}} model follows Makeham's law if the <b>force</b> <b>of</b> <b>mortality</b> is ...|$|E
50|$|The <b>force</b> <b>of</b> <b>mortality</b> is {{also called}} the force of failure. It is the {{probability}} density function of the distribution.|$|E
5000|$|Therefore, the {{survival}} probability {{of an individual}} of age x is written {{in terms of the}} <b>force</b> <b>of</b> <b>mortality</b> as ...|$|E
40|$|Abstract: Using {{data from}} the medical {{literature}} on age-specific and family-history specific incidence rates, we develop double-decrement models to evaluate the actuarial impact of {{a family history of}} breast cancer or ovarian cancer, and the impact of a positive test for the BRCA gene mutation. Increased <b>forces</b> <b>of</b> <b>mortality</b> are derived. It is found that females with some family histories of cancer and/or the presence of the BRCA mutation cannot be accepted at standard rates; depending on underwriting practice, most cases could be accepted at substandard rates. Then a Markov model is built to evaluate the likely effect of adverse selection resulting from women taking a genetic test without informing their insurer and consequently modifying their insurance purchase behavior. It is concluded that, at current testing rates, adverse selection should not be a major source of concern if companies apply strict underwriting rules, requesting cancer history and age at onset for all first degree relatives...|$|R
40|$|Genetic {{testing is}} a concern for {{insurers}} if they cannot use test results in underwriting. We model adverse selection in an insurance market with genetic testing for breast and ovarian cancer. Increased <b>forces</b> <b>of</b> <b>mortality</b> resulting from {{a family history of}} cancer or a positive test for a BRCA mutation are calculated. Using a Markov model, we estimate costs of adverse selection, assuming various testing and insurance purchase behaviors. Adverse selection should be controllable if companies apply strict underwriting rules, requesting cancer history and onset age for all first-degree relatives. If insurers fail to correctly identify the family history of the application and use it in pricing, adverse selection costs could become unbearable. GENETIC TESTING AND THE FEAR OF ADVERSE SELECTION Adverse selection can be defined as the process by which prospective policyholders may gain financial advantage through insurance purchase decisions based on risk characteristics known to them, but unknown and not revealed to the insurer. It is a source of concern for insurance companies because it could result in underpricing. Recent developments in the Human Genome Project, while offering medical prom...|$|R
40|$|Summary Parametric {{models have}} been {{suggested}} {{as an alternative to}} conventional life table techniques for interpretation of observed survival patterns in cancer. This paper extends earlier work on breast cancer by studying the fit of Boag's lognormal model to the survival of 8, 170 breast cancer cases reported to the Swedish Cancer Registry during 1961 - 1963. The model was also used to analyse the upward survival trend for breast cancer cases in Sweden during 1961 - 1973. The model fitted the 1961 - 1963 data well for the entire case material and for patients aged 70 years. It is possibly too simplistic, and perhaps does not accurately describe the <b>forces</b> <b>of</b> <b>mortality</b> or their interactions in old patients. Another disadvantage is that large case materials are necessary in order to obtain estimates with reasonably small standard errors. As an alternative to the conventional 5 - or 10 -year life table survival rates, several authors have suggested the use of parametric statistical models to interpret observed survival patterns in cance...|$|R
50|$|This symbol {{refers to}} central rate of mortality. It is {{approximately}} {{equal to the}} average <b>force</b> <b>of</b> <b>mortality,</b> averaged over the year of age.|$|E
5000|$|Since fX(x)=F 'X(x) is the {{probability}} density function of X, and S(x) = 1 - FX(x) is the survival function, the <b>force</b> <b>of</b> <b>mortality</b> {{can also be}} expressed variously as: ...|$|E
5000|$|<b>Force</b> <b>of</b> <b>mortality</b> is {{a synonym}} of hazard {{function}} {{which is used}} particularly in demography and actuarial science, where it is denoted by [...] The term hazard rate is another synonym.|$|E
40|$|International audienceIdentifying {{individual}} {{factors affecting}} life-span {{has long been}} of interest for biologists and demographers: how do some individuals manage to dodge the <b>forces</b> <b>of</b> <b>mortality</b> when the vast majority does not? Answering this question is not straightforward, {{partly because of the}} arduous task of accurately estimating longevity in wild animals, and of the statistical difficulties in correlating time-varying ecological covariables with a single number (time-to-event). Here we investigated the relationship between foraging strategy and life-span in an elusive and large marine predator: the Southern Elephant Seal (Mirounga leonina). Using teeth recovered from dead males on îles Kerguelen, Southern Ocean, we first aged specimens. Then we used stable isotopic measurements of carbon ([Formula: see text]) in dentin to study the effect of foraging location on individual life-span. Using a joint change-point/survival modelling approach which enabled us to describe the ontogenetic trajectory of foraging, we unveiled how a stable foraging strategy developed early in life positively covaried with longevity in male Southern Elephant Seals. Coupled with an appropriate statistical analysis, stable isotopes have the potential to tackle ecological questions of long standing interest but whose answer has been hampered by logistic constraints...|$|R
40|$|A {{method was}} {{developed}} for assessing coastwide effects of power plant impingement and entrainment on managed fish stocks. The method imbeds an assessment of anthropogenic effects that occur {{during the first year}} of life of fish (the period when most entrainment and impingement occur) into a standard age-structured stock assessment that addresses age-l and older fish. The method thereby provides a straightforward means for comparing the effects of entrainment and impingement mortality to other forms <b>of</b> anthropogenic <b>mortality</b> affecting coastwide fish stocks. The method uses standard equations from fishery science that represent the relationships among independent competing <b>forces</b> <b>of</b> <b>mortality,</b> stock abundance, and landings. Power plant mortality is treated like fishing mortality, and power plant losses are treated like fishery landings. The total age- 0 natural mortality rate is allocated to the individual age- 0 life stages based on a power function relating daily natural mortality rates to age-specific dry weights of fish. An illustrative example of the use of the method is presented for the Atlantic coast stock of Atlantic menhaden Brevoortia tyrannus, which was chosen because it is a coastwide stock, has a coastwide fishery, and is described by high-quality fisheries-dependent data. However, because available entrainment and impingement data were not adequate to support defensible coastwide estimates of the annual numbers killed by entrainment and impingement, actual estimates of the effects of entrainment and impingement on the coastwide Atlantic menhaden stock could not be computed. The method could be used to address the effects of any form <b>of</b> anthropogenic <b>mortality</b> affecting age- 0 fish, including loss of habitat, effects of toxic substances, fishing mortality, and fishery bycatch, provided that valid coastwide estimates of the annual numbers of fish killed by the source <b>of</b> <b>mortality</b> are available...|$|R
50|$|He is {{the author}} {{of more than a dozen}} books. First, he wrote Education of the American Population with John Folger (1967). Perhaps most notable was his book with Mary Powers {{entitled}} The Socioeconomic Approach to Status Measurement (1983). He co-wrote two handbooks on immigration (International Handbook of Internal Migration with David F. Sly and William Serow in 1990 and Handbook of International Migration with William Serow, David Sly and Robert Weller in 1990). Living and Dying in the USA: Health, Behavioral and Social <b>Forces</b> <b>of</b> Adult <b>Mortality</b> (2002) was his last academic book written in English. Most recently, he published The Golden Door, an historical novel (2006).|$|R
50|$|Among actuaries, <b>force</b> <b>of</b> <b>mortality</b> {{refers to}} what economists {{and other social}} {{scientists}} call the hazard rate and is construed as an instantaneous rate of mortality at a certain age measured on an annualized basis.|$|E
50|$|In actuarial science, <b>force</b> <b>of</b> <b>mortality</b> {{represents}} the instantaneous rate of mortality {{at a certain}} age measured on an annualized basis. It is identical in concept to failure rate, also called hazard function, in reliability theory.|$|E
5000|$|... where [...] is the {{probability}} density function of T, [...] is {{the probability}} of a life age [...] surviving to age [...] and [...] denotes <b>force</b> <b>of</b> <b>mortality</b> at time [...] for a life aged [...]|$|E
40|$|In general {{financial}} and actuarial modeling terminology a status {{is a set}} of well defined conditions. A future financial action takes place when the conditions change and the status is said to fail. If the conditions of the status are stochastic in time then the future lifetime of the status is the future lifetime random variable. This structure is central in the actuarial modeling of life insurance and life annuities. A population of like statuses is partitioned into distinct risk strata based on their mortality characteristics. In this paper a Markov Chain approach is used compute mortality rates in the multi-risk strata scenario for both individuals and collective populations. In the group survivorship context individuals at each future age can change risk strata or leave the group. Formulas for yearly conditional mortality rates for the risk defined strata that comprise the basis for actuarial multiple decrement mortality tables are presented. Further, the modeling of aggregate populations that are a mixture of risk strata is explored. Measurements based on the mean future lifetime and actuarial present values are proposed that assess <b>mortality</b> structure <b>of</b> individual risk strata relative to the aggregate population. The proposed Markov Chain approach and relevant actuarial computations are demonstrated on a hypothetical population comprised of risk strata associated with infant, wear-out and constant <b>forces</b> <b>of</b> <b>mortality...</b>|$|R
40|$|Persistent {{diarrhea}} (i. e. acute episodes lasting {{more than}} 14 days) {{has been recognized}} by the WHO as a major public health problem in developing countries and a research topic of high priority. Persistent diarrhea {{is often associated with}} malnutrition, growth faltering, and a substantial risk <b>of</b> <b>mortality</b> in children below 5 years of age. Reported incidence and case-fatality rates from persistent diarrhea vary substantially. Substantial disagreement exists regarding definition, incidence and various putative risk factors. Resolution of such measurement related problems will allow for an accurate estimate <b>of</b> the <b>force</b> <b>of</b> morbidity and <b>mortality</b> from presistent diarrhea, while the elucidation of its risk factors will simplify policy making and the tailoring of intervention programs...|$|R
40|$|Parametric {{models have}} been {{suggested}} {{as an alternative to}} conventional life table techniques for interpretation of observed survival patterns in cancer. This paper extends earlier work on breast cancer by studying the fit of Boag's lognormal model to the survival of 8, 170 breast cancer cases reported to the Swedish Cancer Registry during 1961 - 1963. The model was also used to analyse the upward survival trend for breast cancer cases in Sweden during 1961 - 1973. The model fitted the 1961 - 1963 data well for the entire case material and for patients aged less than 70 years. It was therefore used to help explain whether the upward survival trend was due to long term cures or merely to protracted survival with cancer. The estimated cured proportion among patients aged less than 70 years rose from 33 % +/- 2 % (s. e.) during 1961 - 1963 to 40 % +/- 3 % for cases 1971 - 1973 (P less than 0. 05). The median survival of uncured cases, was found to be similar during both periods, 4. 5 and 4. 6 years respectively. The model did not fit data for patients aged greater than 70 years. It is possibly too simplistic, and perhaps does not accurately describe the <b>forces</b> <b>of</b> <b>mortality</b> or their interactions in old patients. Another disadvantage is that large case materials are necessary in order to obtain estimates with reasonably small standard errors...|$|R
5000|$|... μx : the <b>force</b> <b>of</b> <b>mortality,</b> i.e. the {{instantaneous}} {{mortality rate}} at age x, i.e. {{the number of}} people dying in a short interval starting at age x, divided by ℓx and also divided by the length of the interval.|$|E
5000|$|The <b>force</b> <b>of</b> <b>mortality</b> [...] can be {{interpreted}} as the conditional density of failure at age x, while f(x) is the unconditional density of failure at age x. The unconditional density of failure at age x is the product of the probability of survival to age x, and the conditional density of failure at age x, given survival to age x.|$|E
5000|$|In {{addition}} to his roles within government Thatcher contributed {{to the field of}} statistics through writings collaborated upon with other academics. His 1983 article [...] "How Many People Have Ever Lived On Earth?", a publication of the International Statistical Institute, disproved the notion that the number of people living in the 20th century was in actuality much less than the total number of individuals previously in existence. His work on the Kannisto-Thatcher Database on Old Age Mortality is held by the Max Planck Institute for Demographic Research and regarded as one of its most vital collections. The database contains information from over 30 sovereign states on mortality and population size for males and females older than the age of 80. Their research was entered into computer format by the medical school at Odense University {{in the early part of}} the 1990s. Academic scholars James Vaupel and Väinö Kannisto helped him co-author the book The <b>Force</b> <b>of</b> <b>Mortality</b> at Ages 80 to 120, which was first published in 1998. Writing in the Journal of the Royal Statistical Society in 2000, Douglas Liddell placed Thatcher amongst [...] "stalwarts" [...] within the field of statistics, and compared him to others influential within the field including fellow statistician Michael Healy.|$|E
40|$|Longevity swaps {{have been}} one of the major success stories of pension scheme derisking in recent years. However, with some few exceptions, all of the {{transactions}} to date have been bespoke longevity swaps based upon the <b>mortality</b> experience <b>of</b> a portfolio of named lives. In order for this market to start to meet its true potential, solutions will ultimately be needed that provide protection for all types of members, are cost effective for large and smaller schemes, are tradable, and enable access to the wider capital markets. Index-based solutions have the potential to meet this need; however concerns remain with these solutions. In particular, the basis risk emerging from the potential mismatch between the underlying <b>forces</b> <b>of</b> <b>mortality</b> for the index reference portfolio and the pension fund/annuity book being hedged is the principal issue that has, to date, prevented many schemes progressing their consideration of index-based solutions. Two-population stochastic mortality models offer an alternative to overcome this obstacle as they allow market participants to compare and project the mortality experience for the reference and target populations and thus assess the amount of demographic basis risk involved in an index-based longevity hedge. In this paper, we systematically assess the suitability of several multi-population stochastic mortality models for assessing basis risks and provide guidelines on how to use these models in practical situations paying particular attention to the data requirements for the appropriate calibration and forecasting of such models...|$|R
40|$|Over {{the past}} several decades, life {{expectancy}} has gradually increased throughout the world, and in some countries, such as Japan, the average life expectancy is now more than 80 years. Nevertheless, only about one to two persons per 10, 000 will live to be one hundred years. Persons now aged 100 or more, were born on or before 1912, {{at a time when}} normal life expectancy was about 50 years. Thus centenarians are an example of a group that has successfully evaded the usual <b>forces</b> <b>of</b> <b>mortality</b> that affect all other humans. What can we learn from these remarkable, highly selected individuals, and what are the implications for global health?Exceptional individuals have had long lives in earlier times[1]. Hippocrates, considered to be the father of medicine, may have been a centenarian. Indeed, even in the late middle ages and early Renaissance, if one survived childbirth and the numerous, often fatal diseases of young adulthood, there was a reasonable chance of living into the seventies or eighties [2, 3]. These reports imply that even in periods when the overall mortality was high, some individuals lived to what would at the time have been considered exceptional ages. From a global viewpoint, the burden of disease is determined by two factors: life expectancy and the proportion of healthy years of life expectancy—the healthy span. By studying centenarians we can learn a great deal about disease (or absence of disease) at the extreme end of life, and we can use this information to assess what health services we will be required to provide as the world’s population gradually ages. The aim of this review is to summarize the factors that might be related to extreme longevity, and to discuss the global implications of increasing life span...|$|R
40|$|Tree {{mortality}} due {{to competition}} {{is one of}} the key drivers of forest succession in Canadian boreal mixedwood forests. We analyzed survival probability of trembling aspen (Populus tremuloides Michx.) and white spruce (Picea glauca (Moench) Voss.) trees and saplings, growing in pure and mixed stands experiencing self-thinning, in the Boreal Forest Natural Region of Alberta, Canada. Generalized logistic regression models were utilized to evaluate the effects of tree and stand characteristics on the survival probability of both species. Absolute size of the individuals, characterized by diameter at breast height, had a positive effect on the survival of both aspen and spruce. Aspen experienced decreasing survival with size, which is most likely linked to age rather than competition. Significant effects of basal area of trees larger than the subject tree indicated that one-sided inter- and intra-specific competition, rather than two-sided, is the primary driving <b>force</b> <b>of</b> competition-related <b>mortality</b> for both aspen and spruce. Periodic annual increment in diameter was a better predictor of survival than basal area of larger trees, indicating that growth rate is the most important individual characteristic that defines survival of both aspen and spruce in these self-thinning stands...|$|R
