0|3080|Public
5000|$|The {{validity}} of the CDI has been well-established. [...] Construct <b>validity</b> and <b>discriminant</b> <b>validity</b> has also been established. [...] Kovacs used experimental design to obtain <b>discriminant</b> <b>validity</b> between cases that were considered [...] "normal" [...] and those that were considered clinical. [...] Some studies have reflected <b>discriminant</b> <b>validity,</b> while others have not. Kovacs reported in 1992 that further research on <b>discriminant</b> <b>validity</b> was needed.|$|R
5000|$|Although {{there is}} no {{standard}} value for <b>discriminant</b> <b>validity,</b> a result less than [...]85 tells us that <b>discriminant</b> <b>validity</b> likely exists between the two scales. A result greater than [...]85, however, {{tells us that the}} two constructs overlap greatly and they are likely measuring the same thing. Therefore, we cannot claim <b>discriminant</b> <b>validity</b> between them.|$|R
30|$|<b>Discriminant</b> <b>validity</b> {{refers to}} the extent to which a {{construct}} is truly distinct from other constructs [58]. A widely used statistical measure for <b>discriminant</b> <b>validity</b> is a comparison of the Average Variance Extracted (AVE) with correlation squared [62]. In order to ensure <b>discriminant</b> <b>validity,</b> the AVE of two constructs must be more than the square of the correlation between the same two constructs. Our results show that AVE mean square root of each value variable is significantly greater than its correlation coefficient with other variables (see Table  5), thus <b>discriminant</b> <b>validity</b> is supported. Overall, the results show acceptable reliability, convergent <b>validity</b> and <b>discriminant</b> <b>validity,</b> which were appropriate for testing the research model.|$|R
40|$|This paper {{presents}} a simple procedure for estab-lishing convergent and <b>discriminant</b> <b>validity.</b> The method uses ordinary least-squares regression (OLS) with {{the correlations between}} measures as the depen-dent variable. Illustrations indicate that the method provides reasonable answers. Index terms: conver-gent <b>validity,</b> <b>discriminant</b> <b>validity,</b> multiple regres-sion. Establishing the validity of measures is {{a major focus of}} research. Essential to establishing validity with multi-item measures are notions of convergent and <b>discriminant</b> <b>validity</b> (Anastasi, 1968; Bohmstedt, 1970; I~u~nally 9 1978). Many approaches to convergent and <b>discriminant</b> <b>validity</b> assessment are derived from the multitrait-multimethod approach (Campbell & Fiske, 1959). This paper {{presents a}}n alternative to the LISREL-based nested model procedure used by Bagozzi (1978) and Widaman (1985). Background The most common approach to establishing convergent and <b>discriminant</b> <b>validity</b> is to demonstrat...|$|R
40|$|Bove, Pervan, Beatty, and Shiu [Bove, LL, Pervan, SJ, Beatty, SE, Shiu, E. Service worker role in {{encouraging}} customer organizational citizenship behaviors. J Bus Res 2009; 62 (7) : 698 – 705. ] develop and test a latent variable {{model of the}} role of service workers {{in encouraging}} customers' organizational citizenship behaviors. However, Bove et al. [Bove, LL, Pervan, SJ, Beatty, SE, Shiu, E. Service worker role in encouraging customer organizational citizenship behaviors. J Bus Res 2009; 62 (7) : 698 – 705. ] claim support for hypothesized relationships between constructs that, due to insufficient <b>discriminant</b> <b>validity</b> regarding certain constructs, may be inaccurate. This research comment discusses what <b>discriminant</b> <b>validity</b> represents, procedures for establishing <b>discriminant</b> <b>validity,</b> and presents an example of inaccurate <b>discriminant</b> <b>validity</b> assessment based upon the work of Bove et al. [Bove, LL, Pervan, SJ, Beatty, SE, Shiu, E. Service worker role in encouraging customer organizational citizenship behaviors. J Bus Res 2009; 62 (7) : 698 – 705. ]. Solutions to <b>discriminant</b> <b>validity</b> problems and a five-step procedure for assessing <b>discriminant</b> <b>validity</b> then conclude the paper. This comment hopes to motivate a review of <b>discriminant</b> <b>validity</b> issues and offers assistance to future researchers conducting latent variable analysi...|$|R
30|$|<b>Discriminant</b> <b>validity</b> {{has been}} tested and {{demonstrated}} in Table  6  in Appedix  1 that which shows the value of AVE of each construct {{is greater than the}} variance shared between the constructs; thus, it indicates the sufficient <b>discriminant</b> <b>validity.</b>|$|R
40|$|In questionnaires, items can be {{presented}} in a grouped format (same-scale items are presented in the same block) or in a randomized format (items from one scale are mixed with items from other scales). Some researchers have advocated the grouped format because it enhances <b>discriminant</b> <b>validity.</b> The current study demonstrates that positioning items in separate blocks of a questionnaire may indeed lead to increased <b>discriminant</b> <b>validity,</b> but this can happen even in instances where <b>discriminant</b> <b>validity</b> should not be present. In particular, the authors show that splitting an established unidimensional scale into two arbitrary blocks of items separated by unrelated buffer items results {{in the emergence of}} two clearly identifiable but artificial factors that show <b>discriminant</b> <b>validity...</b>|$|R
40|$|Graduation date: 2009 The {{purpose of}} this study was to examine the {{evidence}} of construct validity for self-report with assistance from a secondary source as a measure of physical activity (PA) in adults with intellectual disabilities (ID) in free-living environments. Thirty-seven participants (21 females, 16 males) with mild to moderate ID aged 19 - 74 years participated in the study. The Multitrait-Multimethod (MTMM) analysis was used to evaluate the evidence of construct validity for this procedure. Examination of the pattern of reliability and validity coefficients of the MTMM analysis revealed that the reliability coefficients for the self-report variables (PA and fat intake), activity counts, and step counts were higher than all convergent validity coefficients, except for the convergent validity between the two objective measures of PA, and <b>discriminant</b> <b>validity</b> coefficients. The convergent validity coefficients were greater than all of the <b>discriminant</b> <b>validity</b> coefficients except for the heterotrait-monomethod <b>discriminant</b> <b>validity</b> coefficient. The heterotrait-monomethod <b>discriminant</b> <b>validity</b> coefficient was higher than the heterotrait-heteromethod <b>discriminant</b> <b>validity</b> coefficients. The study demonstrated that self-report with assistance from a secondary source as a measure of PA in adults with ID has strong and generalized evidence of convergent validity and strong evidence of <b>discriminant</b> <b>validity...</b>|$|R
40|$|This paper {{presents}} a simple procedure for establishing convergent and <b>discriminant</b> <b>validity.</b> The method uses ordinary least-squares regression (OLS) with {{the correlations between}} measures as the dependent variable. Illustrations indicate that the method provides reasonable answers. Index terms: convergent <b>validity,</b> <b>discriminant</b> <b>validity,</b> multiple regression...|$|R
5000|$|... <b>discriminant</b> <b>validity</b> {{may involve}} {{delimitation}} from other disorders.|$|R
30|$|<b>Discriminant</b> <b>validity</b> is {{the extent}} to which a {{construct}} is absolutely distinct from other constructs (Hair et al., 2009), and it can be assessed at both the item and construct levels. At the item level, Barclay, Higgins, & Thompson (1995) proposed that <b>discriminant</b> <b>validity</b> is evident when an item correlates more highly with items in the construct it purports to measure than items belonging to other constructs. As shown in Appendix, an acceptable level of <b>discriminant</b> <b>validity</b> at the item level was found using the inter-correlations of items.|$|R
40|$|Examined the {{convergent}} and <b>discriminant</b> <b>validity</b> {{of a set}} of self-discrepancy measures developed {{within the}} theoretical framework of self-discrepancy theory (SDT). SDT maintains that perceived discrepancies between actual self and 2 self-guides representing (1) ideals and aspirations and (2) duties and responsibilities {{play a crucial role in}} affect regulation. Even though the theory has received wide support, some issues concerning convergent and <b>discriminant</b> <b>validity</b> of self-discrepancy measures have been raised. 215 individuals (aged 15 - 59 yrs) participated in the study. Results show acceptable levels of convergent and <b>discriminant</b> <b>validity</b> of the measures...|$|R
40|$|<b>Discriminant</b> <b>validity</b> {{assessment}} {{has become}} a generally accepted prerequisite for analyzing relationships between latent variables. For variance-based structural equation modeling, such as partial least squares, the Fornell-Larcker criterion and the examination of cross-loadings are the dominant approaches for evaluating <b>discriminant</b> <b>validity.</b> By means of a simulation study, we show that these approaches do not reliably detect the lack of <b>discriminant</b> <b>validity</b> in common research situations. We therefore propose an alternative approach, based on the multitrait-multimethod matrix, to assess discriminant validity: the heterotrait-monotrait ratio of correlations. We demonstrate its superior performance {{by means of a}} Monte Carlo simulation study, in which we compare the new approach to the Fornell-Larcker criterion and the assessment of (partial) cross-loadings. Finally, we provide guidelines on how to handle <b>discriminant</b> <b>validity</b> issues in variance-based structural equation modeling...|$|R
30|$|According to Fornell and Larcker (1981), for <b>discriminant</b> <b>validity</b> of two constructs, each AVE {{estimate}} {{should be}} greater than the shared variance estimate. The AVE for Benevolent Role Perspective (0.56) and AVE for Benevolent Authoritative Role Perspective (0.69) were larger than the shared variance between two constructs (0.32), confirms the <b>discriminant</b> <b>validity.</b>|$|R
3000|$|We also {{analyzed}} the constructs’ <b>discriminant</b> <b>validity</b> by examining whether the square {{root of the}} indicators’ AVE within any construct was higher than the correlations between it and any other construct (Son and Benbasat 2007). All included constructs met this criterion, thus evidencing <b>discriminant</b> <b>validity</b> (see Online Resource 1.2). Moreover, none of the correlations between any pair of constructs were higher than the threshold value of [...]. 9 (Son and Benbasat 2007), {{and there was no}} evidence of critically high cross-loadings between the main constructs (see Online Resource 1.3). Therefore, we can conclude that the reflective constructs possessed <b>discriminant</b> <b>validity.</b>|$|R
30|$|In {{order to}} assess for <b>discriminant</b> <b>validity</b> we {{compared}} the square root of the AVE with construct correlation coefficients and other measures [67 - 75]. As seen in Table  3 the square root of the AVE is larger with each constructs’ correlation coefficient. Based on these results each of the constructs has acceptable reliability, convergent and <b>discriminant</b> <b>validity.</b>|$|R
50|$|Campbell and Fiske (1959) {{introduced}} {{the concept of}} <b>discriminant</b> <b>validity</b> within their discussion on evaluating test validity. They {{stressed the importance of}} using both discriminant and convergent validation techniques when assessing new tests. A successful evaluation of <b>discriminant</b> <b>validity</b> shows that a test of a concept is not highly correlated with other tests designed to measure theoretically different concepts.|$|R
40|$|Objective. To {{validate}} the European League Against Rheumatism (EULAR), the American College of Rheumatology (ACR), acid the World Health Organization (WHO) /International League Against Rheumatism (ILAR) response criteria for rheumatoid arthritis (RA). Methods. EULAR response criteria were developed combining change from baseline {{and level of}} disease activity attained during followup, In a trial comparing hydroxychloroquine and sulfasalazine, we studied construct (radiographic progression), criterion (functional capacity), and <b>discriminant</b> <b>validity.</b> Results. EULAR response criteria had good construct, criterion, and <b>discriminant</b> <b>validity,</b> ACR and WHO/ILAR criteria showed only good criterion validity. Conclusion. EULAR response criteria showed better construct and <b>discriminant</b> <b>validity</b> than did the ACR and the WHO/ILAR response criteria for RA...|$|R
40|$|LISREL maximum {{likelihood}} confirmatory factor analyses (Jöreskog & Sörbom, 1984) {{were conducted to}} explore the effects of two questionnaire formats (grouping versus randomizing items) on the convergent and <b>discriminant</b> <b>validity</b> of two sets of questionnaire measures. The first set of measures consisted of satisfaction scales that had demonstrated acceptable psychometric properties in earlier studies; {{the second set of}} scales were job characteristics measures that had shown <b>discriminant</b> <b>validity</b> problems in previous research. Correlational data were collected from two groups of employed business administration students (N = 80 in each group) concurrently (Study 1) and at two points in time (Study 2). The results of the analyses showed that the grouped format was superior to the random format, particularly with respect to the weaker measures (the job characteristics scales). The results also illustrated and supported the usefulness of LISREL confirmatory factor analysis in studies of convergent and <b>discriminant</b> <b>validity.</b> Index terms: confirmatory factor analysis, convergent <b>validity,</b> <b>discriminant</b> <b>validity,</b> LISREL analysis, questionnaire formats, scale validity...|$|R
30|$|<b>Discriminant</b> <b>validity</b> (Hulland, 1999). Other {{tests in}} this study include {{composite}} reliability, and Freidman test.|$|R
30|$|Taken together, the {{constructs}} and measuring items {{in this study}} have good convergent and <b>discriminant</b> <b>validities.</b>|$|R
30|$|In {{the present}} context, the {{construct}} validity is of major relevance (see Cronbach and Meehl 1955). 4 In verifying {{the construct validity}}, we differentiate between convergent and <b>discriminant</b> <b>validity</b> in the following. Convergent validity indicates {{the degree to which}} different measures of the same construct correlate with each other. Conversely, <b>discriminant</b> <b>validity</b> means the degree to which measures of different constructs differ from each other (Campbell and Fiske 1959).|$|R
30|$|In {{order to}} examine the <b>discriminant</b> <b>validity</b> of the constructs, this study used the Fornell and Lacker [86] {{criterion}} whereby the average variance shared between each construct and its measures should be greater than the variance shared between the construct and other constructs. As shown in Table  2, the correlations for each construct are less than the square root of AVE for the indicators measuring that construct indicating adequate <b>discriminant</b> <b>validity.</b>|$|R
50|$|Convergent validity, a {{parameter}} {{often used}} in sociology, psychology, and other behavioral sciences, refers to {{the degree to which}} two measures of constructs that theoretically should be related, are in fact related. Convergent <b>validity,</b> along with <b>discriminant</b> <b>validity,</b> is a subtype of construct validity. Convergent validity can be established if two similar constructs correspond with one another, while <b>discriminant</b> <b>validity</b> applies to two dissimilar constructs that are easily differentiated.|$|R
40|$|Responses {{from high}} school sophomores to the Eliot-Price and the Guilford-Zimmerman tests of spatial {{orientation}} and visualization were evaluated {{in terms of the}} multitrait-multimethod matrix tech-nique. The Eliot-Price tests were found to meet all criteria for con-vergent and <b>discriminant</b> <b>validity.</b> However, the Guilford-Zimmer-man tests did not meet one of the criteria for <b>discriminant</b> <b>validity.</b> The Eliot-Price tests appeared to be more nearly precise measures of spatial orientation and visualization...|$|R
40|$|A major {{weakness}} of the Mood and Anxiety Symptom Questionnaire (MASQ) is that its <b>discriminant</b> <b>validity</b> has not been demonstrated in a clinical population of anxiety and mood disorder patients. This paper, using 470 anxiety and mood disorder patients, assessed the <b>discriminant</b> <b>validity</b> of the MASQ. The MASQ subscales showed statistically significant <b>discriminant</b> <b>validity,</b> but their maximum ability to discriminate is low at 70 %. Overall {{it was concluded that}} the MASQ had very weak clinical utility in differentiating anxiety and mood disorder patients, and gave rise to doubts as to the tripartite structure of the MASQ. When using the MASQ, future researchers should be mindful of its limitations when applied in a clinical population. (c) 2006 Elsevier Ireland Ltd. All rights reserved...|$|R
5000|$|The average {{variance}} extracted {{has often}} been used to assess <b>discriminant</b> <b>validity</b> based on the following [...] "rule of thumb": Based on the corrected correlations from the CFA model, the AVE {{of each of the}} latent constructs should be higher than the highest squared correlation with any other latent variable. If that is the case, <b>discriminant</b> <b>validity</b> is established on the construct level. This rule is known as Fornell-Larcker criterion. However, in simulation models this criterion did not proof reliable for variance-based structural equation models (e.g. PLS)., but for covariance-based structural equation models (e.g. Amos) only. An alternative to the Fornell-Larcker criterion {{that can be used for}} both types of structural equation models to assess <b>discriminant</b> <b>validity</b> is the heterotrait-monotrait ratio (HTMT).|$|R
3000|$|Data in Table  2 {{indicates}} <b>discriminant</b> <b>validity</b> between most factors, as {{the values}} of the square correlation (r [...]...|$|R
30|$|The {{results are}} {{presented}} in Tables  2 and 3. The <b>discriminant</b> <b>validity,</b> which assesses whether individual indicators can adequately distinguish among different constructs, was determined by examining the square root of AVEs {{in relation to the}} inter-construct correlations (Garver and Mentzer 1999). Based on Table 3, none of the inter-construct correlations were larger than the square root of the AVEs. Hence, we conclude that an acceptable level of <b>discriminant</b> <b>validity</b> was achieved.|$|R
40|$|There is a {{widespread}} use of statistical tests to evaluate measurement scales of latent constructs in the business arena. However, {{the results of these}} tests can yield misleading conclusions regarding the validity of measurement scales. Therefore, content validity has to be considered in order to avoid misleading outcomes. Through an empirical example, this paper shows how different statistical tests used to analyse <b>discriminant</b> <b>validity</b> yield ambiguous findings. Consequently, <b>discriminant</b> <b>validity</b> should be theoretically established...|$|R
30|$|Table  5 {{provides}} the correlation matrix for <b>discriminant</b> <b>validity,</b> {{which indicates the}} degree to which the constructs diverge from each other.|$|R
30|$|Turning to <b>discriminant</b> <b>validity,</b> {{the results}} suggest that most of the factors in the SWBQb share more {{variance}} with its specific indicators than with the other constructs (Hair et al., 2014). However, caution is needed when considering the <b>discriminant</b> <b>validity</b> of the Communal factor, as the √AVE values for this factor were poor, particularly with regard to its relationship with the personal factor. In addition, the personal and communal factors were extremely highly correlated (r[*]=[*] 0.92), suggesting similarity and redundancy. The overlap between these two factors has also been noted in a study carried out in Hong Kong (Yuen, 2015). As our study is the first to assess the <b>discriminant</b> <b>validity</b> of the SWBQ factors using AVE, further research is required to confirm the overlap between the personal and communal factors.|$|R
30|$|Finally, we {{assessed}} <b>discriminant</b> <b>validity</b> by testing the square root of each construct’s AVE values (Hair et al. 2014). <b>Discriminant</b> <b>validity</b> {{ensures that the}} correlation of indicator to its latent construct should be greater than its highest correlation with any other construct as it was suggested by Fornell-Larcker criterion (Fornell & Larcker 1981). It {{is based on the}} idea that a construct shares more variance with its associated indicators than any other construct. This is confirmed in our findings, as shown in Table 5, where the numbers along the diagonal in bold font (square root of AVE) are greater than the correlation between latent constructs (off-diagonal elements). Overall, the reliability and convergent and <b>discriminant</b> <b>validity</b> (construct validity) were supported in the research model; therefore, all reflective items were retained.|$|R
30|$|The {{construct}} {{reliability was}} checked with the construct Composite Reliability (CR). The validity was checked by using convergent <b>validity</b> and <b>discriminant</b> <b>validity.</b>|$|R
3000|$|... (27)[*]=[*] 3966.56, p[*]<[*] 0.01, CFI = 0.57, TLI[*]=[*] 0.43, and RMSEA[*]=[*] 0.20. Thus, the <b>discriminant</b> <b>validity</b> of {{the study}} {{variables}} was supported.|$|R
50|$|In psychology, <b>discriminant</b> <b>validity</b> or {{divergent}} {{validity tests}} whether concepts or measurements {{that are not}} supposed to be related are actually unrelated.|$|R
