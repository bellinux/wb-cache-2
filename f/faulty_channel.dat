14|38|Public
5000|$|Martin is {{credited}} with accidentally stumbling onto the electric guitar [...] "fuzz" [...] effect during a recording session with Robbins; his guitar was run through a <b>faulty</b> <b>channel</b> in a mixing console, generating the fuzz sound on [...] "Don't Worry".|$|E
5000|$|... "Don't Worry" [...] is {{an early}} example of guitar distortion. Session guitarist Grady Martin, using a <b>faulty</b> <b>channel</b> in the mixing-desk for his six-string bass, created a {{distorted}} sound. Although Martin {{did not like the}} sound, Robbins' producer left the guitar track as it was.|$|E
5000|$|When Robbins was {{recording}} his 1961 hit [...] "Don't Worry", session guitarist Grady Martin accidentally {{created the}} electric guitar [...] "fuzz" [...] effect - his six-string bass was {{run through a}} <b>faulty</b> <b>channel</b> in a mixing console. Robbins decided {{to keep it in}} the final version. The song reached No. 1 on the country chart, and No. 3 on the pop chart.Robbins was inducted into the Nashville Songwriters Hall of Fame in 1975. For his contribution to the recording industry, Robbins has a star on the Hollywood Walk of Fame at 6666 Hollywood Blvd.|$|E
40|$|We give a {{correctness}} {{proof of}} the sliding window protocol. Both safety and liveness properties are addressed. We show how <b>faulty</b> <b>channels</b> can be represented as nondeterministic programs. The correctness proof is given as a sequence of correctness-preserving transformations of a sequential program that satisfies the original specification, with the exception {{that it does not}} have any <b>faulty</b> <b>channels.</b> We work as long as possible with a sequential program, although the transformation steps are guided by the aim of going to a distributed program. The final transformation steps consist in distributing the actions of the sequential program over a number of processes...|$|R
40|$|Abstract. We {{consider}} {{the problem of}} computing minimum congestion, fault-tolerant, redundant assignments of messages to <b>faulty,</b> parallel delivery <b>channels.</b> In particular, we are given a set K of <b>faulty</b> <b>channels,</b> each having an integer capacity c i and failing independently with probability f i. We are also given a set M of messages to be delivered over...|$|R
40|$|We {{consider}} {{the problem of}} constructing minimum congestion, fault-tolerant, redundantassignments of objects to <b>faulty</b> parallel delivery <b>channels.</b> In particular, we are givena set M of <b>faulty</b> <b>channels,</b> each having an integer capacity c i and failing independently withprobability f i. All the channels have the same source s and destination t, and, in case of failure,a channel deliver...|$|R
5000|$|The above {{example of}} a 2oo3 fault {{tolerant}} system increases both mission reliability as well as safety. However, the [...] "basic" [...] reliability of the system will in this case still be lower than a non redundant (1oo1) or 2oo2 system. Basic reliability engineering covers all failures, including those that might not result in system failure, but do result in additional cost due to: maintenance repair actions; logistics; spare parts etc. For example, replacement or repair of 1 <b>faulty</b> <b>channel</b> in a 2oo3 voting system, (the system is still operating, although with one failed channel it has actually become a 2oo2 system) is contributing to basic unreliability but not mission unreliability. As an example, {{the failure of the}} tail-light of an aircraft will not prevent the plane from flying (and so is not considered a mission failure), but it does need to be remedied (with a related cost, and so does contribute to the basic unreliability levels).|$|E
50|$|Su-30MKI {{aerodynamic}} configuration is {{a longitudinal}} triplane with relaxed stability. The canard increases the aircraft lift ability and deflects automatically to allow high {{angle of attack}} (AoA) flights allowing it to perform Pugachev's Cobra. The integral aerodynamic configuration combined with thrust vectoring results in extremely capable manoeuvrability, taking off and landing characteristics. This high agility allows rapid deployment of weapons in any direction as desired by the crew. The canard notably assists in controlling the aircraft at large angles-of-attack and bringing it to a level flight condition. The aircraft has a fly-by-wire (FBW) with quadruple redundancy. Dependent on flight conditions, signals from the control stick position transmitter or the FCS may be coupled to remote control amplifiers and combined with feedback signals from acceleration sensors and rate gyros. The resultant control signals are coupled to the high-speed electro-hydraulic actuators of the elevators, rudders and the canard. The output signals are compared and, if the difference is significant, the <b>faulty</b> <b>channel</b> is disconnected. FBW {{is based on a}} stall warning and barrier mechanism which prevents stalls through dramatic increases of control stick pressure, allowing a pilot to effectively control the aircraft without exceeding the angle of attack and acceleration limitations. Although the maximum angle of attack is limited by the canards, the FBW acts as an additional safety mechanism.|$|E
40|$|Abstract: This paper {{suggests}} {{a new approach}} to checking understood as a validation and diagnostic procedure of the analogue measurement channels in 4 - 20 mA standard. The discussed method is very useful in field conditions especially for widespread long distance systems like those on ships. In each case it supports traditional methods but in the same specific situations of temperature measurement it can indicate a <b>faulty</b> <b>channel...</b>|$|E
40|$|A 9 U VME like double {{threshold}} discriminator {{has been}} designed and constructed at Frascati INFN laboratories. Its aim is to process the signals arising from gas drift chambers, introducing a very small time walk (650 ps). Each discriminator board houses 32 channels. Each channel is located on an independent printed circuit mounted on socket. This solution is very convenient for replacing <b>faulty</b> <b>channels</b> without loosing operation of the full board...|$|R
40|$|Central to {{fault-tolerant}} computing is redundancy management, {{and common}} to proofs of fault-tolerance is a maximum fault assumption. Typically a maximum fault assumption is rather restrictive. Usually, this {{is necessary to}} avoid assumptions about the behavior of <b>faulty</b> <b>channels.</b> A maximum fault assumption is useful because it allows reasoning about fault tolerance {{in the presence of}} arbitrarily malicious fault behavior. However, analysis of the architecture may establish certain scenarios in which the assumption may be weakened. Proofs comparing majority and plurality and proofs of simple reconfiguration strategies are presented in viewgraph form...|$|R
40|$|Projet EURECAThis paper describes, {{by means}} of an example, how one may {{mechanically}} verify concurrent programs on the automated theorem prover Lp. It presents a fully computer checked proof of a protocol for communications over <b>faulty</b> <b>channels.</b> The chosen specification environment is Unity, since the proposed model can be fruitfully applied {{to a wide variety of}} problems and modified or extended for special purposes. It provides a higher level of abstraction to express solutions to parallel programming problems. We investigate how the Unity methodology can be mechanized in Lp, and how we can use the theorem proving methodology to prove safety and liveness...|$|R
40|$|Introduction In this note, we give a {{correctness}} {{proof of}} the sliding window protocol. We discuss both safety and liveness properties. We specialize our program to window size 1 and obtain the alternating bit protocol. The alternating bit protocol {{can be traced back}} to [2]. We have been unable to trace back the origins of the sliding window protocols; [7] discusses one of the versions and lists networks using related protocols. 2 A <b>faulty</b> <b>channel</b> A communication protocol is used to provide reliable transmission of data over a faulty communication channel that garbles, duplicates, or loses data. We consider the case in which data is transmitted in one direction over the <b>faulty</b> <b>channel,</b> and we assume the presence of a channel in the opposite direction in JAN 173 - 1 order to be able to communicate the need for retransmission of a message. The latter channel is also faulty. No assumptions on the slack of the faulty or of the fault-free channel are to be made. It i...|$|E
40|$|We {{examine the}} problem of {{reliable}} networked control when the communication channel between the controller and the actuator periodically drops packets and is faulty i. e., corrupts/alters data. We first examine {{the use of a}} standard triple modular redundancy scheme (where the control input is sent via three independent channels) with majority voting to achieve mean square stability. While such a scheme is able to tolerate a single <b>faulty</b> <b>channel</b> when there are no packet drops, we show that the presence of lossy channel...|$|E
40|$|The famous {{alternating}} bit protocol is an algorithm for transmitting {{a sequence}} of data through a so-called <b>faulty</b> <b>channel,</b> i. e. a channel that can lose or duplicate injected data. The established literature provides a wealth of treatments and plenty of a-posteriori correctness proofs of the protocol; derivations of the algorithm, however, are very rare. The prime purpose of this note is to provide such a derivation from first principles, using the theory of Owicki and Gries as the only tool for reasoning about parallel programs...|$|E
40|$|We {{consider}} {{the problem of}} computing minimum congestion, fault-tolerant, redundant assignments of messages to <b>faulty</b> parallel delivery <b>channels.</b> In particular, we are given a set M of <b>faulty</b> <b>channels,</b> each having an integer capacity c i and failing independently with probability f i. We are also given a set of messages to be delivered over M, and a fault-tolerance constraint (1 Γ ffl), and we seek a redundant assignment OE that minimizes congestion Cong(OE), i. e. the maximum channel load, subject to the constraint that, with probability no less than (1 Γ ffl), all the messages have a copy {{on at least one}} active channel. We present a 4 -approximation algorithm for identical capacity channels and arbitrary message sizes, and a 2 l ln(jM j=ffl) ln(1 =fmax) m -approximation algorithm for related capacity channels and unit size messages. Both algorithms are based on computing a collection of disjoint channel subsets such that, with probability no less than (1 [...] ...|$|R
40|$|We {{study the}} problem of {{termination}} in distributed systems with <b>faulty</b> communication <b>channels.</b> We show that for asynchronous systems, protocols that guarantee knowledge gain via message transfers cannot be guaranteed to terminate even {{if we assume that}} only transient communication failures can occur, and want to achieve only a weak kind of termination. The same result holds for synchronous systems as well...|$|R
40|$|Suppose {{a binary}} string x = x 1 [...] . xn is being {{repeatedly}} broadcast over a <b>faulty</b> communication <b>channel.</b> Each time, the channel delivers a fixed number m of the digits (m < n) with the lost digits chosen uniformly at random, {{and the order}} of the remaining digits preserved. How large does m have to be to reconstruct the message?...|$|R
40|$|We {{consider}} {{agreement and}} leader election on asynchronous complete networks when the processors are reliable, {{but some of}} the channels are subject to failure. Fischer, Lynch, and Paterson have already shown that no deterministic algorithm can solve the agreement problem on asynchronous networks if any processor fails during the execution of the algorithm. Therefore, we consider only channel failures. The type of channel failure we consider in this paper is Byzantine failure, that is, channels fail by altering messages, sending false information, forging messages, losing messages at will, and so on. There are no restrictions on the behavior of a <b>faulty</b> <b>channel.</b> Therefore, a <b>faulty</b> <b>channel</b> may act as an adversary who forges messages on purpose to prevent the successful completion of the algorithm. Because we assume an asynchronous network, the channel delays are arbitrary. Thus, the faulty channels may not be detectable unless, for example, the faulty channels cause garbage to be sent. We present the first known agreement and leader election algorithm for asynchronous complete networks in which the processors are reliable but some channels may be Byzantine faulty. The algorithm can tolerate up to [n− 22] faulty channels, where n is the number of processors in the network. We show that the bound on the number of faulty channels is optimal. When the processors terminate their corresponding algorithms, all the processors in the network will have the same correct vector, where the vector contains the private values of all the processors...|$|E
40|$|Employing {{thousands}} of cores {{in a single}} chip is the natural trend to handle the ever increasing performance requirements of complex applications such as those used in graphics and multimedia processing. System-on-chips (SoCs) platforms based on network-on-chips (NoCs) could be a viable option for the deployment of large multicore designs with {{thousands of}} cores. This paper proposes the generalized binary de Bruijn (GBDB) graph as a reliable and efficient network topology for a large NoC. We propose a reliable routing algorithm to detour a <b>faulty</b> <b>channel</b> between two adjacent switches. In addition, using integer linear programming, we propose an optimal tile-based implementation for a GBDB-based NoC in which the number of channels is {{less than that of}} Torus which has the same number of links. Our experimental results show that the latency and energy consumption of the generalized de Bruijn graph are much less than those of Mesh and Torus. The low energy consumption of a de Bruijn graph-based NoC makes it suitable for portable devices which have to operate on limited batteries. Also, the gate level implementation of the proposed reliable routing shows small area, power, and timing overheads due to the proposed reliable routing algorithm...|$|E
40|$|The memory {{requirements}} for ultra-reliable computers {{are expected to}} increase due to future increases in mission functionality and operating-system requirements. This increase will {{have a negative effect}} on the reliability and cost of the system. Increased memory size will also reduce the ability to reintegrate a channel after a transient fault, since the time required to reintegrate a channel in a conventional fault-tolerant processor is dominated by memory realignment time. A Byzantine Resilient Fault-Tolerant Processor with Fault-Tolerant Shared Memory (FTP/FTSM) is presented as a solution to these problems. The FTSM uses an encoded memory system, which reduces the memory requirement by one-half compared to a conventional quad-FTP design. This increases the reliability and decreases the cost of the system. The realignment problem is also addressed by the FTSM. Because any single error is corrected upon a read from the FTSM, a faulty channel's corrupted memory does not need realignment before reintegration of the <b>faulty</b> <b>channel.</b> A combination of correct-on-access and background scrubbing is proposed to prevent the accumulation of transient errors in the memory. With a hardware-implemented scrubber, the scrubbing cycle time, and therefore the memory fault latency, can be upper-bounded at a small value. This technique increases the reliability of the memory system and facilitates validation of its reliability model...|$|E
40|$|A {{fault-tolerant}} adaptive wormhole routing {{function for}} Networks-on-Chips (NoCs) is presented. The novelty of this routing logic {{is that it}} is capable of using runtime information on availability of links to dynamically bypass <b>faulty</b> <b>channels.</b> When faults occur, no offline reconfiguration or dropping of packets is necessary. Instead, dynamic routes are suggested on-the-fly. Routing decisions are based only on local knowledge, which allows for fast switching. Our approach does not use any costly virtual channels. As we do not prohibit cyclic dependencies, the routing function provides minimal routing from source to destination even in the presence of faults. We have implemented the architecture design using synthesizable HDL. Using simulations, we have assessed the overhead of our approach in terms of latency, power and area. On average, even with 40 % of the links faulty our routing logic is capable performing correctly. Using formal verification, we have proven 100 % reliability up to three faults, i. e., for any combination of three faults our routing logic remains connected, deadlock-free and livelock-free. Keywords: Network communications, Fault Tolerance, Deadlocks, Routing protocols, Mechanical Verificatio...|$|R
40|$|Pressure {{sensors and}} {{isolation}} valves act {{to shut down}} defective servochannel. Redundant hydraulic system indirectly senses failure in any of its electrical control channels and mechanically isolates hydraulic <b>channel</b> controlled by <b>faulty</b> electrical <b>channel</b> so flat it cannot participate in operating system. With failure-detection and isolation technique, system can sustains two failed channels and still functions at full performance levels. Scheme useful on aircraft or other systems with hydraulic servovalves where failure cannot be tolerated...|$|R
40|$|Abstmct- The use of {{adaptive}} routing in a multicomputer inter-connection network improves network performance by {{making use of}} all available paths and provides fault tolerance by allowing messages to be routed around failed channels and nodes. This paper describes two deadlock-free adaptive routing algorithms. Both algorithms allocate virtual channels using a count {{of the number of}} dimension reversals a packet has performed to eliminate cycles in resource dependency graphs. The stdc algorithm eliminates cycles in the network channel dependency graph. The dynamic algorithm improves virtual channel utilization by permitting dependency cycles and instead eliminating cycles in the packet wail-for graph. We prove that these algorithms are deadlock-free and give experimental measurements of their performance. For nonuniform traffic patterns, these algorithms improve network throughput by a factor of three compared to deterministic routing. The dynamic algorithm gives better performance at moderate traffic rates but requires source throttling to remain stable at high traffic rates. Both algorithms allow the network to gracefully degrade in the presence of <b>faulty</b> <b>channels.</b> Index Terms-Communication networks, concurrent computing, flow control, interconnection networks, multicomputers, packet muting, par-allel processing. A. Interconnection Networks I...|$|R
40|$|Abstract—Technological {{evolution}} {{enables the}} integration of billions of transistors on a chip. As VLSI technology scales, and processing power continues to improve, inter-processor communication becomes a performance bottleneck. On-chip networks have been widely proposed as the interconnect fabric for high performance SoCs. Recently, NoC architectures are emerging as the candidate for highly scalable, reliable, and modular on-chip communication infrastructure platform. This paper proposes the generalized binary de Bruijn (GBDB) graph based on combinatorial application as a reliable and efficient network topology for a large NoC. We propose a deadlock free & reliable routing algorithm to detour a <b>faulty</b> <b>channel</b> between two adjacent switches. In this implementation, using just two-layer VLSI layout, we can implement a NoC with any desired number of nodes. Note that current VLSI technology allows more than two wiring layers and the number {{is expected to rise}} in the future. Our experimental results show that the latency and energy consumption of the generalized de Bruijn graph are much less than those of Mesh and Torus. The low energy consumption of a de Bruijn graph-based NoC makes it suitable for portable devices which have to operate on limited batteries. Also, the gate level implementation of the proposed reliable routing shows small area, power, and timing overheads due to the proposed reliable routing algorithm. Index Terms — Network on chip (NoC), combinatoria...|$|E
40|$|The thesis {{focuses on}} the control of {{asymmetric}} permanent magnet synchronous generator (PMSG) system, with particular reference to the suppression of its second harmonic (2 h) power, DC bus voltage and torque ripples. The asymmetries include the unbalanced resistances, unbalanced inductances, and unbalanced 3 -phase back-electromotive forces (EMFs). The mathematical model of the general asymmetries in the PMSG system is firstly presented. The power ripple and torque ripple due to the asymmetries without/with negative-(N-) sequence currents are then analysed in detail. It shows that there are 2 h impedances in the synchronous dq-axis frame. Consequently, the N-sequence currents emerge under the conventional current proportional and integral (PI) control, which will result in undesired 2 h power, DC bus voltage and torque ripples. To suppress the 2 h torque resulted from the N-sequence currents, three typical methods aiming for balanced currents without N-sequence currents are reviewed, evaluated and their relationship is revealed. It shows that all these three methods are capable of suppressing the N-sequence currents as verified by experiments. However, the 2 h power and DC bus voltage cannot be suppressed. To suppress the undesired 2 h power and DC bus voltage, an improved power control without any sequential component decomposers under general unbalanced conditions is proposed. Its effectiveness is validated by elaborated experiments on a prototype PMSG with inherent asymmetry and deliberately introduced asymmetries. However, the 2 h torque is compromised. To solve the 2 h torque, power and DC bus voltage simultaneously, the compensation in parallel with the DC bus is investigated in the PMSG system with asymmetric impedances. The undesired 2 h power from the PMSG is compensated by the 2 h power from the compensation unit. Two topologies of the compensation unit and corresponding control methods are investigated, while the compensation effectiveness is validated by experiments. Furthermore, the compensation unit with external circuits in series with the asymmetric PMSG is investigated. By the compensation in series, the original unbalanced system is modified to a balanced system in theory. Therefore, the N-sequence currents, 2 h power, DC bus voltage, and torque ripple can be naturally suppressed. The feasibility of this compensation method is verified by experiments at different speeds and load conditions, although the effectiveness may be slightly affected by the non-linearity of the compensation inductors in practice. Finally, the research of suppressing the 2 h DC bus voltage and torque ripple is extended to the dual 3 -phase PMSG system with one channel failed. By utilizing the windings, rectifier or inverter in the <b>faulty</b> <b>channel</b> which are still functional, three methods designated as two sets in parallel, two DC buses in parallel and N-sequence currents compensation are investigated, which require minimum extra hardware investment compared with the compensation in parallel and in series. ...|$|E
40|$|Fault {{tolerance}} and adaptive capabilities are challenges for modern Networks-on-Chip (NoC) {{due to the}} increase in physical defects in advanced manufacturing processes. Two novel adaptive routing algorithms, namely coarse and fine-grained look-ahead algorithms, are proposed in this paper to enhance 2 D mesh/torus NoC system fault-tolerant capabilities. These strategies use fault-flag codes from neighbouring nodes to obtain the status or conditions of real-time traffic in a NoC region; then calculate the path weights and choose the route to forward packets. This approach enables the router to minimise congestion for the adjacent connected channels and also to bypass a path with <b>faulty</b> <b>channels</b> by looking ahead at distant neighbouring router paths. The novelty of the proposed routing algorithms is the weighted path selection strategies, which make near-optimal routing decisions to maintain the NoC system performance under high fault rates. Results show that the proposed routing algorithms can achieve performance improvement compared to other state of the art works under various traffic loads and high fault rates. The routing algorithm with fine-grained look-ahead capability achieves a higher throughput compared with the coarse-grained approach under complex fault patterns. The hardware area/power overheads of both routing approaches are relatively low which does not prohibit scalability for large scale NoC implementations...|$|R
40|$|The Compact Muon Solenoid (CMS) {{is one of}} four {{large-scale}} {{experiments that}} is going to be installed at the Large Hadron Collider (LHC) at the European Laboratory for Particle Physics (CERN). For CMS an inner tracking system entirely equipped with silicon microstrip detectors was chosen. With an active area of about 198 m 2 it will be the largest tracking device of the world that was ever constructed using silicon sensors. The basic components in the construction of the tracking system are approximately 16, 000 so-called modules, which are pre-assembled units consisting of the sensors, the readout electronics and a support structure. The module production is carried out by a cooperation of number of institutes and industrial companies. To ensure the operation of the modules within the harsh radiation environment extensive tests have to be performed on all components. An important contribution to the quality assurance of the modules is made by a test system of which all components were developed in Aachen. In addition to thorough tests of the readout electronics and it enables the detection of many faults of the silicon sensor it is connected to. It is used in more than 20 different institutes in Europe and the USA which participate in the module production. The application of the test system for automated tests of modules requires a dedicated readout and analysis software. The software and all components of the test system will be explained in detail in this thesis. Different types of faults on a module show a significant behaviour in particular tests. A dedicated fault finding algorithm searches for these signatures. A safe identification of <b>faulty</b> <b>channels</b> and a reliable information on the respective type of fault is important. It facilitates the reparation and enables the assessment of the appropriateness of a module for the insertion into the tracker. It will be explained which approach was used to find the most appropriate tests for that purpose and how the fault finding algorithm was optimized to give reliable results independent of the specific test setup. Finally, the algorithm is used for the qualification of more than 500 repeatedly measured modules with known failures to verify its suitability. All <b>faulty</b> <b>channels</b> are found and more than 90 % of the faults are correctly identified. At the same time less than 0. 02 % of good channels are wrongly flagged as faulty. The assessment of the module quality is nearly independent of the particular setup and can be reproduced in about 96 % of the cases of repeatedly measured modules. In total, less than 0. 3 % of the <b>channels</b> are <b>faulty</b> and about 98 % of all modules are suited for the construction of the tracker...|$|R
40|$|Image {{restoration}} is {{an essential}} and unavoidable preprocessing operation for many security applications like biometric security, video surveillance, object tracking, image data communication etc. Images are generally degraded due to <b>faulty</b> sensor, <b>channel</b> transmission error, camera mis-focus, atmospheric turbulence, relative motion between camera and object etc. Such conditions are inevitable while capturing a scene through camera. Restoration of such images is highly essential for further image processing and other tasks. The work in this thesis has been submitted to a journal and is under review. The complete thesis shall be published once the review process ends...|$|R
40|$|The {{start of}} {{collisions}} at the LHC {{brings with it}} much excitement and many unknowns. It’s essential {{at this point in}} the experiment to be prepared with user-friendly tools to quickly and efficiently determine the quality of the data. Easy visualization of data for the shift crew and experts is one of the key factors in the data quality assessment process. The Data Quality Monitoring Display (DQMD) is a visualization tool for the automatic data quality assessment of the ATLAS experiment. It is the interface through which the shift crew and experts can validate the quality of the data being recorded or processed, be warned of problems related to data quality, and identify the origin of such problems. This tool allows great flexibility for visualization of results from automatic histogram checking through custom algorithms, the configuration used to run the algorithms, and histograms used for the check, with an overlay of reference histograms when applicable. The display also supports visualization of the results in graphical form ie hardware view of the detector to easily detect <b>faulty</b> <b>channels</b> or modules. It provides the shift crew with a checklist before the final assessment of the data is saved to the database, a list of experts to contact in case of problems, and actions to perform in case of failure. This paper describes the design and implementation of the DQMD and discusses experience from its usage and performance durin g ATLAS commissioning with cosmic ray and single beam data...|$|R
40|$|This paper {{introduces}} an algorithm that performs {{garbage collection}} in distributed systems of active objects (i. e., objects having their own threads of control). The proposed garbage collector {{is made of}} a set of local garbage collectors, one per node, loosely coupled to a global garbage collector. The novelties of the proposed garbage collector come from the fact that local garbage collectors need not be synchronized with each other for detecting garbage objects and that <b>faulty</b> communication <b>channels</b> are tolerated. The paper describes the proposed garbage collector, together with its implementation and performance for a concurrent object-oriented language running on a local area network of workstations...|$|R
40|$|Visual input {{improves}} {{speech comprehension}} when auditory signals are degraded due to background noise (Sumby & Pollack, 1954) or hearing impairments (Walden, Prosek, & Worthington, 1975). Listeners strategically put greater focus on visual information to augment impoverished auditory information. This advantage of visual reliance is routinely utilized at clinical settings for adults with neurogenic communication disorders. Individuals experiencing auditory comprehension deficits are frequently encouraged by clinicians {{to look at}} speakers’ faces during daily conversations. Despite the presumed advantage of visual information and the routine recommendation {{on the use of}} visual cues, {{there is a lack of}} research regarding the way individuals with brain lesions utilize visual information. To take advantage of visual cues, listeners should be able to interpret facial movements into linguistically meaningful codes. Individuals who cannot efficiently process acoustic signals of speech may lack the ability of translating visual information into linguistic symbols (Schmid & Ziegler, 2006). In such cases, combining information from the two <b>faulty</b> <b>channels</b> may not enhance speech understanding. Even if an individual can recognize and interpret visual information, he/she may have a lesion in the cross-modal integration area (Miller & D’Esposito, 2005; Molholm et al., 2006), which will not allow the person to benefit from visual input. This paper presents preliminary data from a study that examines: (1) whether individuals with stroke rely on visual input when auditory information is ambiguous, (2) whether an enforced reliance on visual cues can improve speech understanding, and (3) whether a participant’s ability to decipher visual information can be accounted for by his/her cognitivelinguistic characteristics...|$|R
40|$|The {{main goal}} {{of this paper is}} to develop an {{integrated}} general-purpose simulator for the Profibus MAC layer protocol in order to evaluate the steady-state behavior of this protocol, under a variety of possible operational conditions in a <b>faulty</b> communication <b>channel.</b> This protocol is part of the Profibus-DP system used widely as a standard and popular industrial communication system. This work examines deeply the performance of the protocol taking into account all critical system parameters and focusing on the main control (token/polling) and data communication (request/response) transactions. Using this simulator it can be shown how the data packet transfers, as well as the control packet transactions are strongly affected by the channel faults, especially for complex and expanded network topologies. However, under certain operational conditions the network performance can be acceptable...|$|R
40|$|We {{investigate}} {{the reliability of}} redundant assignments of colored ball classes to bins failing randomly and independently, where, if a bin fails, all the balls assigned to it are no longer available. In particular, for integers; 1, we consider at least bins of capacity C and failure probability f, and C balls colored with C colors. For any assignment not violating the bin capacities, we show an upper bound of (1 Γ f) on the probability {{that at least one}} ball from each color is available. 1 Introduction In many practical applications involving design with faulty components (e. g. fault-tolerant network design, fault-tolerant scheduling), a combinatorial structure, such as a graph, should be optimized to best tolerate random and independent faults with respect to a given property, such as connectivity [Lom 74]. For instance, consider a set of n objects all to be delivered to a specific destination using a set of m <b>faulty</b> delivery <b>channels</b> of a fixed capacity C. Each [...] ...|$|R
40|$|Abstract—This paper {{reports on}} an {{underwater}} cooperative localization algorithm for <b>faulty</b> low-bandwidth communica-tion <b>channels</b> {{based on a}} factor graph estimation frame-work. Vehicles measure the one-way-travel-time (OWTT) of acoustic broadcasts to obtain a relative range observation to the transmitting vehicle. We present a method to robustly share locally observed sensor data across the network by exploiting odometry factor composition. Our algorithm calls on approximate marginalization techniques to compute a compact set of informative factors that enable local navigation data to be shared efficiently. We provide results from a real-time implementation of our algorithm using two autonomous underwater vehicles and a surface vehicle. I...|$|R
40|$|LANDSAT- 4 Thematic Mapper (TM) {{digital image}} {{products}} recorded onto computer compatible tapes (CCTs), which {{were available for}} internal research purposes prior to August, 1983, are reviewed. The SCROUNGE image processing system at Goddard Space Flight Centr generated in tape formats: (1) raw band-sequential data (CCT-BT), generally used for internal transportation of digital data from one ground processing system to another; (2) calibrated data (CCT-AT), useful for reseachers doing radiometric characterization; and (3) geometrically resampled data (CCT-PT), the final product. The formats represent different steps {{in the process of}} producing fully-corrected TM data. The CCT-BT images are re-sequenced from telemetry format to image format, but are uncorrected radiometrically and geometrically. The CCT-AT images had data from two <b>faulty</b> data <b>channels</b> replaced and all data radiometrically calibrated. The CCT-PT images were resampled by cubic convolution procedures to provide a geometrically corrected image using satellite ephemeris and altitude data and scan-mirror correction data. The final product, the CCT-PT, is the one to which all of the radiometric and geometric corrections were applied...|$|R
