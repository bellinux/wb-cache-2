2|13|Public
40|$|AbstractThis paper {{describes}} Narrowing Grammar, a {{new kind}} of grammar that combines concepts from logic programming, rewriting, lazy evaluation, and logic grammar formalisms such as Definite Clause Grammar (DCG). A Narrowing Grammar is a finite set of rewrite rules. The semantics of Narrowing Grammar is defined by a specialized kind of outermost rewriting strategy called NU-narrowing. Narrowing Grammar is directly executable, like many logic grammars. In fact, Narrowing Grammar rules can be compiled to Prolog and executed by existing Prolog interpreters as generators or acceptors. Unlike many logic grammars, Narrowing Grammar also permits higher-order specification and modular composition, and it provides lazy evaluation by virtue of its rewriting strategy. Lazy evaluation is important in certain languageacceptance situations, such as in coroutined matching of multiple patterns against a stream. We compare Narrowing Grammar with several established logic grammars: Definite Clause Grammar, Metamorphosis Grammar, Extraposition Grammar and <b>Gapping</b> <b>Grammar,</b> showing how these logic grammars can be transformed to Narrowing Grammar. We also investigate the versatility of Narrowing Grammar in language analysis by applying it to several natural-language examples...|$|E
40|$|Since the {{introduction}} of metamorphosis grammars (MGs) 'Colmerauer. 1978). with their associated type 0 -like grammar rules, {{there has been a}} desire to allow more general rule formats in logic <b>grammars</b> <b>Gaps,</b> which refer to strings of unspecified symbols, were added to the MG rule, resulting in extraposition grammars (XGs) (Pereira, 1981) and <b>gapping</b> <b>grammars</b> (GGs) (Dahl and Abramson, 1984). Unrestricted <b>gapping</b> <b>grammars,</b> which provide an even more general rule format, possess rules of the form &quot;a-> B &quot; where a and / 3 many contain any number of terminal nonterminal or gap symbols in any order. FIGG. a Flexible Implementation of <b>Gapping</b> <b>Grammars,</b> is an implementation of a large subset of unrestricted GGs which allows either bottom-up or top-down parsing of sentences. This system provides more built in control facilities than previous logic grammar implementations, which allows the user to restrict the applicability of the rules, and to create grammar rules that will be executed more efficiently 1...|$|R
40|$|Dillard City Hall, GA. Dillard lies {{near the}} state 2 ̆ 7 s {{northern}} border, {{quite close to}} North Carolina. It remembers John Dillard, a prominent resident of the area. The town 2 ̆ 7 s main feature is the Dillard House, an inn, restaurant and conference center for the community. Originally this was the Rabun <b>Gap</b> <b>Grammar</b> School, Also inside the building is the community theater. The Foxfire fall Festival is held on its grounds during {{the fall of the}} year. [URL]...|$|R
40|$|International audienceMicropatterns and nanopatterns {{have been}} {{previously}} demonstrated {{to be useful}} techniques for object-oriented program comprehension. In this paper, we use a similar approach for identifying structurally similar fragments in grammars in a broad sense (contracts for commitment to structure), in particular parser specifications, metamodels and data models. Grammatical micropatterns bridge the <b>gap</b> between <b>grammar</b> metrics, which are easy to implement but hard to assign meaning to, and language design guidelines, which are inherently meaningful as stemming from current software language engineering practice but considerably harder to formalise...|$|R
5000|$|The Natick Dictionary, {{published}} in 1903 {{and based on}} the work of Dr. James H. Trumbull, includes descriptions of vocabulary, mainly from Eliot's Bible but also that of the other missionaries and Roger William's A Key .... The documents of the Indians were extensively analyzed by Ives Goddard and Kathleen Bragdon, with the 1988 release of Native Writings in Massachusett. Reconstructions of <b>gaps</b> in <b>grammar,</b> syntax, vocabulary and pronunciation could be filled by comparison with other related Algonquian languages or by reconstructions based on likely sound changes, such as George F. Aubin's Proto-Algonquian Dictionary of 1975.|$|R
40|$|We {{describe}} {{a new technology}} for using small collections of example sentences to automatically restrict a speech recognition grammar to allow only the more plausi- ble subset of the sentences it would other- wise admit. This technology is unusual because it bridges the <b>gap</b> between hand-built <b>grammars</b> (used with no training data) and statistical approaches (which require significant data) ...|$|R
40|$|Several differing {{approaches}} to parsing using Prolog are discussed and their characteristics outlined, in particular Definite Clause Grammar (DCG), the Bottom-Up Parser (BUP) and the Active Chart Parser. Attention {{is paid to}} the conflict that arises between the simplicity and efficiency of the parsing algorithm when using a grammar specified as a linguistic, rather than computationally efficient, description of a sublanguage. A simple and efficient parsing algorithm called ‘Word Incorporation’ is described. Its efficient implementation in Prolog and extensions for handing literals, the Kleene star operator and <b>gaps</b> in <b>grammar</b> rules are described using experience gained with the unification-based formalism, Lexical Functional Grammar (LFG). ...|$|R
40|$|Hierarchical phrase-based machine {{translation}} systems {{rely on the}} synchronous context free grammar formalism to learn and use translation rules containing <b>gaps.</b> The <b>grammars</b> learned by such systems become unmanageably large even for medium sized parallel corpora. The traditional approach of preprocessing the training data and loading all possible translation rules into memory does not scale well for hierarchical phrase-based systems. Online grammar extractors address this problem by constructing memory efficient data structures {{on top of the}} source side of the parallel data (often based on suffix arrays), which are used to efficientlymatch phrases in the corpus and to extract translation rules on the fly during decoding. This paper describes an open source implementation of an online synchronous context free grammar ex-tractor. Our approach builds on the work of Lopez (2008 a) and introduces a new technique for extending the lists of phrase matches for phrases containing gaps that reduces the extraction time by a factor of 4. Our extractor is available as part of the cdec toolkit 1 (Dyer et al., 2010). 1...|$|R
40|$|We {{describe}} {{a new technology}} for using small collections of example sentences to automatically restrict a speech recognition grammar to allow only the more plausible subset of the sentences it would otherwise admit. This technology is unusual because it bridges the <b>gap</b> between hand-built <b>grammars</b> (used with no training data) and statistical approaches (which require significant data). 1 Motivation Statistical modeling for speech recognition requires {{a large body of}} training text; we are addressing the cases where only very modest quantities of "training " data exist. Our method is relevant when the speech to be recognized contains patterns that can be straightforwardly abstracted from the semantics of the words appearing in them, but where the sentence set to be recognized is too large to cover with manually created rules. Using this technology, a small representative set of utterances (on the order of hundreds of sentences or phrases) is combined with an overlypermissive general gra [...] ...|$|R
40|$|Departing from a {{proposal}} by Keizer (2007) {{on how to}} bridge the <b>gap</b> between the <b>grammar</b> and the lexicon in Functional Discourse Grammar (FDG), this paper deals with three aspectual verbal periphrases in Spanish, which are, {{in the order of}} their degrees of grammaticalization, (i) weakly grammaticalized resultative tener + participle, (ii) egressive parar de + infinitive and (iii) strongly grammaticalized habitual soler + infinitive. In spite of their different syntactic behaviours, none of them is a truly lexical or truly grammatical item. After {{a detailed description of the}} syntax and semantics of these auxiliary constructions in comparison with truly auxiliary constructions, the proposal by García Velasco for the lexicon in FDG (this issue) is discussed and serves as a starting point for the development of the concept of lexical auxiliaries, which is then applied to the three periphrastic constructions. The representation of these constructions in FDG makes use of ‘combinations of partially instantiated frames’, introduced by Keizer (this issue), and adequately reflects the meanings and the morphosyntactic structure of lexical auxiliaries...|$|R
40|$|With our experiment, we {{show how}} we can detect and {{annotate}} clausal coordinate ellipsis with Constraint Grammar rules. We focus on such an elliptical structure {{in which there are}} two coordinated clauses, and the latter one lacks a verb. For example, the sentence This belongs to me and that to you demonstrates the ellipsis in question, namely <b>gapping.</b> The Constraint <b>Grammar</b> rules are made for a Finnish parsebank, FinnTreeBank. The FinnTreeBank project is building a parsebank in the dependency syntactic framework in which verbs are central since other sentence elements depend on them. Without correct detection of omitted verbs, the syntactic analysis of the whole sentence fails. In the experiment, we detect gapping based on morphology and linear order of the words without using syntactic or semantic information. The test corpus, Finnish Wikipedia, is morphologically analyzed but not disambiguated. Even with an ambiguous morphological analysis, the results show that 89, 9 % of the detected sentences are elliptical, making the rules accurate enough {{to be used in the}} creation of FinnTreeBank. Once we have a morphologically disambiguated corpus, we can write more accurate rules and expect better results...|$|R
40|$|The {{purpose of}} the present paper is the study of the {{interaction}} between learning English for Specific Purposes (ESP), in particular, English for the Financial Sector, and general English proficiency. The research examines the effects of an ESP course being taught for a year on the students' general English proficiency. Two sets of tests were prepared for that purpose and administered to 30 first-year students of finance and law. The students took the placement test twice, at the beginning {{and at the end of}} the school year. To monitor test performance over a research period, a parallel form measuring the same competences was administered at the beginning of the second semester. In the test development process a special consideration has been paid to the level of difficulty and its relation to the students' prior educational context. Drawing on the National State Matura exams the test is set at Common European Framework of Reference for Languages (CEFR) Level B 2. As regards its content the test is comprised of reading comprehension tasks (multiple matching, multiple-choice cloze, <b>gapped</b> text) and <b>grammar</b> tasks aiming to examine lexical and grammatical competence. There were two major assumptions in this study: 1) Learning ESP can improve students' general English proficiency, and 2) There is a more substantial improvement in lexical competence as compared to the improvement in grammatical competence. There is strong evidence in support of the first hypothesis, whereas for the second one the results were ambiguous. After major findings are presented and discussed, implications for ESP teaching are given in closing...|$|R
2500|$|In non-verb-final {{languages}}, {{apart from}} languages like Thai and Vietnamese with very strong politeness distinctions in their <b>grammars,</b> <b>gapped</b> relative clauses tend, however, to {{be restricted to}} positions {{high up in the}} accessibility hierarchy. With obliques and genitives, non-verb-final languages that do not have politeness restrictions on pronoun use tend to use pronoun retention. English is unusual in that all roles in the embedded clause can be indicated by gapping: e.g. [...] "I saw the man who is my friend", but also (in progressively less accessible positions cross-linguistically, according to the accessibility hierarchy described below) [...] "...who I know", [...] "...who I gave a book to", [...] "...who I spoke with", [...] "...who I run slower than". Usually, languages with gapping disallow it beyond a certain level in the accessibility hierarchy, and switch to a different strategy at this point. [...] Classical Arabic, for example, only allows gapping in the subject and sometimes the direct object; beyond that, a resumptive pronoun must be used. Some languages have no allowed strategies at all past a certain point—e.g. in many Austronesian languages, such as Tagalog, all relative clauses must have the shared noun serving the subject role in the embedded clause. In these languages, relative clauses with shared nouns serving [...] "disallowed" [...] roles can be expressed by passivizing the embedded sentence, thereby moving the noun in the embedded sentence into the subject position. This, for example, would transform [...] "The man who I gave a book to" [...] into [...] "The man who was given a book by me". Generally, languages such as this [...] "conspire" [...] to implement general relativization by allowing passivization from all positions — hence a sentence equivalent to [...] "The man who is run slower than by me" [...] is grammatical. Note also that gapping is often used in conjunction with case-marked relative pronouns (since the relative pronoun indicates the case role in the embedded clause), but this is not necessary (e.g. Chinese and Japanese both using gapping in conjunction with an indeclinable complementizer).|$|R

