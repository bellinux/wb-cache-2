878|1872|Public
5|$|The {{short-range}} {{committee was}} made up of members representing six computer manufacturers and three government agencies. The six computer manufacturers were Burroughs Corporation, IBM, Minneapolis-Honeywell (Honeywell Labs), RCA, Sperry Rand, and Sylvania Electric Products. The three government agencies were the US Air Force, the Navy's David Taylor Model Basin, and the National Bureau of Standards (now the National Institute of Standards and Technology). The committee was chaired by Joseph Wegstein of the US National Bureau of Standards. Work began by investigating <b>data</b> <b>description,</b> statements, existing applications and user experiences.|$|E
25|$|Because markup languages, {{and more}} {{generally}} <b>data</b> <b>description</b> languages (not necessarily textual markup), are not programming languages (they are data without instructions), {{they are more}} easily manipulated than programming languages—for example, web pages are presented as HTML documents, not C code, and thus can be embedded within other web pages, displayed when only partially received, and so forth. This leads to the web design principle {{of the rule of}} least power, which advocates using the least (computationally) powerful language that satisfies a task to facilitate such manipulation and reuse.|$|E
5000|$|... both Interface Description Language and <b>data</b> <b>description</b> {{language}} ...|$|E
40|$|What is goal of Data Orchestration: • to {{hold the}} analytical, {{processing}} and documentary consistency of <b>data</b> object <b>descriptions.</b> • to control the state of IS through the <b>data</b> objects <b>description</b> • the machine is processing the xdefinitions. • to share the understanding of <b>data</b> <b>descriptions</b> • between client and supplier • between analyst and programmer • between programmer and machine The objective {{of this paper is}} to present this approach o...|$|R
50|$|MCHP also {{maintains}} a public documentation library (<b>data</b> <b>descriptions</b> and concept dictionary) that provides consistent {{information about the}} data files in the repository and methods for using the data in population-based research. <b>Data</b> <b>descriptions</b> provide information about the data file, relationships between data sets, data quality reports, and data dictionary with descriptive and statistical details about all data elements. The concept dictionary documents methods developed at MCHP for analyzing data in the repository, including project-specific approaches, suggested readings and references.|$|R
5|$|FLOW-MATIC's inventor, Grace Hopper, {{also served}} as a {{technical}} adviser to the committee. FLOW-MATIC's major contributions to COBOL were long variable names, English words for commands and the separation of <b>data</b> <b>descriptions</b> and instructions.|$|R
5000|$|The DigSig <b>Data</b> <b>Description</b> for {{the above}} DigSig is as follows: ...|$|E
50|$|In 1971, {{largely in}} {{response}} to the need for programming language independence, the work was reorganized: development of the <b>Data</b> <b>Description</b> Language was continued by the <b>Data</b> <b>Description</b> Language Committee, while the COBOL DML was taken over by the COBOL language committee. With hindsight, this split had unfortunate consequences. The two groups never quite managed to synchronize their specifications, leaving vendors to patch up the differences. The inevitable consequence was a lack of interoperability among implementations.|$|E
50|$|A data {{definition}} language or <b>data</b> <b>description</b> language (DDL) is a syntax {{similar to a}} computer programming language for defining data structures, especially database schemas.|$|E
40|$|International audienceIt {{often happens}} that {{different}} references (i. e. <b>data</b> <b>descriptions),</b> possibly coming from different heterogeneous data sources, concern the same real world entity. In such cases, it is necessary: (i) to detect, through reconciliation methods, whether different <b>data</b> <b>descriptions</b> {{refer to the}} same real world entity and (ii) to fuse them into a unique representation. Here we assume the reference reconciliation is solved, and we propose a fusion method based on possibility theory, {{able to cope with}} uncertainty and with ontological knowledge. An imple- mentation using W 3 C standards is provided. Rising from the fusion process, an ontology enrichment procedure is proposed to complete the global ontology...|$|R
40|$|The {{problem of}} forward {{abstract}} interpretation of normal logic programs {{has not been}} formally addressed in the literature although negation as failure is dealt with through the built-in predicate ! {{in the way it}} is implemented in Prolog. This paper proposes a solution to this problem by deriving two generic fixed-point abstract semantics F^b and F^ for forward abstract interpretation of normal logic programs. F^b is intended for inferring <b>data</b> <b>descriptions</b> for edges in the program graph where an edge denotes the possibility that the control of execution transfers from its source program point to its destination program point. F^ is derived from F^b and is intended for inferring <b>data</b> <b>descriptions</b> for textual program points. Comment: 39 page...|$|R
50|$|According to HtDP, {{the design}} process starts with a careful {{analysis}} of the problem statement {{with the goal of}} extracting a rigorous description of the kinds of data that the desired program consumes and produces. The structure of these <b>data</b> <b>descriptions</b> determines the organization of the program.|$|R
50|$|In abductive reasoning, the {{premises}} do not guarantee a conclusion. Abduction moves from <b>data</b> <b>description</b> to a hypothesis without a necessary relationship between cause and effect.|$|E
50|$|In {{addition}} to the Tombstone Engine, Eric is {{the creator of the}} Open <b>Data</b> <b>Description</b> Language (OpenDDL) and the Open Game Engine Exchange (OpenGEX) file format.|$|E
5000|$|... 1972. [...] "Architecture Definition Technique: Its Objectives, Theory, Process, Facilities, and Practice." [...] co-authored with J. Bouvard. in: <b>Data</b> <b>Description,</b> Access and Control: Proceedings of the 1972 ACM-SIGFIDET Workshop, November 29-December 1, 1972.|$|E
40|$|The {{availability}} of space science <b>data,</b> a <b>description</b> of the <b>data,</b> and a <b>description</b> {{of the services}} supplied by the National Space Science Data Center (NSSDC) is presented. A series of cumulative indexes that reference the <b>data</b> <b>descriptions</b> contain: (1) a chronological listing of all spacecraft, experiments, and data descriptions; (2) an index of all spacecraft described, identified by common names and alternate names; (3) a listing of the original experiment institutions for experiments described; (4) a listing of the investigators associated with the experiments and their current affiliations; and (5) two displays of information about experiment data coverage for fields and particle data and a listing of all experiments sorted by phenomenon measured...|$|R
40|$|The {{journals}} of the Geographical Society of Finland are launching a new article type: <b>Data</b> <b>descriptions</b> (Datankuvauksia in Finnish, Beskrivningar av data in Swedish). The autumn issue of Terra (3 / 2014) pioneers the new article type. With this announcement we welcome manuscripts {{of this kind}} also to Fennia...|$|R
5000|$|Resource {{description}} {{framework for}} object and <b>data</b> space <b>descriptions</b> ...|$|R
5000|$|... #Caption: Non-free media <b>data</b> <b>Description</b> Ahmad Shah Massoud (leader of the anti-Taliban {{resistance}} and National Hero of Afghanistan) and Haji Abdul Qadir (Vice President of Afghanistan from Oct. 2001 until his assassination) shake hands in mid-2001.|$|E
50|$|Data Desk's developer, <b>Data</b> <b>Description,</b> pioneered linked graphic {{displays}} {{including a}} 3-D rotating plot and graphical slider control of parameters. It has also developed proprietary technology for computer-based multimedia instruction and currently provides contract data analysis services.|$|E
50|$|A {{significant}} part of RESTful API description is the specification of returned data structures. The IDL might either specify its own format or use an existing <b>data</b> <b>description</b> format. A notable example which many RESTful API DLs use is JSON Schema.|$|E
40|$|In {{many cases}} {{it is better}} to extract a set of {{decision}} trees and a set of possible logical <b>data</b> <b>descriptions</b> instead of a single model. Methods for creating forests of decision trees based on Separability of Split Value (SSV) criterion are presented. Preliminary results confirm their usefulness in understanding data structures...|$|R
50|$|DE/RPG or Data Entry RPG was {{exclusively}} {{available on}} the IBM 5280 series of data-entry workstations in the early '80s. It was similar to RPG III but lacking external <b>Data</b> <b>Descriptions</b> (DDS) to describe data(files) like on the System/38 and its successors. Instead, the DDS part had to be included into the RPG source itself.|$|R
5000|$|SPL - <b>Data</b> Flow <b>description</b> {{language}} of IBM InfoSphere Streams streaming engine ...|$|R
5000|$|Archival <b>Data</b> <b>Description</b> Mark-up Language (ADDML) [...] is a {{standard}} describing a collection of data files. The standard was originally developed by the National Archives of Norway (NAN), and existed in several different versions until a constant form was reached with 8.2, the present de facto standard.|$|E
5000|$|Data Sharing: Supports {{the access}} and {{exchange}} of data where access consists of ad hoc requests (such as a query of a data asset), and exchange consists of fixed, re-occurring transactions between parties. Enabled by capabilities provided by both the Data Context and <b>Data</b> <b>Description</b> standardization areas.|$|E
5000|$|BeerXML is a free, fully defined XML <b>data</b> <b>description</b> [...] {{standard}} {{designed for}} the exchange of beer brewing recipes [...] and other brewing data. Tables of recipes {{as well as other}} records such as hop schedules and malt bills can be represented using BeerXML for use by brewing software.|$|E
50|$|Any {{statistical}} inference requires some assumptions. A statistical {{model is a}} set of assumptions concerning the generation of the observed data and similar <b>data.</b> <b>Descriptions</b> of statistical models usually emphasize the role of population quantities of interest, about which we wish to draw inference. Descriptive statistics are typically used as a preliminary step before more formal inferences are drawn.|$|R
40|$|Availability, comparability, {{and quality}} of cross-national {{hospital}} discharge <b>data.</b> <b>Descriptions</b> of discharge reporting systems in six developed countries, with emphasis on coverage, types of data collected, procedures and definitions used in {{data collection and analysis}} and statistics routinely available. Discussion of health services system characteristics possibly affecting rates of hospital utilization. DHEW Publication No, (PHS) 80 - 135...|$|R
5000|$|<b>Data</b> Format <b>Description</b> Language (DFDL), for {{modeling}} of general text and binary data.|$|R
50|$|The Open <b>Data</b> <b>Description</b> Language (OpenDDL) is {{a generic}} text-based {{language}} {{that is designed to}} store arbitrary data in a concise human-readable format. It {{can be used as a}} means for easily exchanging information among many programs or simply as a method for storing a program's data in an editable format.|$|E
5000|$|FOCUS {{features}} {{the ability for}} the user to construct a <b>data</b> <b>description</b> file (called a [...] "master file description") referring to the actual data file, or even several different <b>data</b> <b>description</b> files addressing the same data file in different ways, rather than the usual practice of having the file structure hard-coded into the program. In this way, files of any structure from any source can be accessed or produced in many different ways, eliminating much of the data manipulation (for example concatenation, or parsing) usually required with other earlier programming languages to change variable formats or data structures. For instance, the same actual data file can be accessed (read or write) as each record being an 80 byte text string, or as 40 2 character numerical fields, other as 10 8-byte floating point numbers, etc., by the user simply re-writing the appropriate master file description as needed.|$|E
50|$|Developers use a <b>data</b> <b>description</b> {{specification}} (DDS) {{to describe}} data attributes in file descriptions that are {{external to the}} application program that processes the data, {{in the context of}} an IBM System i. The $ts table in Oracle stores information about every table in the database. It is part of the data dictionary that is created when the Oracle Database is created.|$|E
40|$|Study of {{comparability}} of cross-national hospital discharge <b>data.</b> <b>Descriptions</b> {{of discharge}} reporting systems {{with emphasis on}} coverage, types of data collected, procedures and definitions used in data collection and analysis, and statistics routinely available. Discussion of health services system characteristics likely to affect rates of hospital use. [Lola Jean Kozak, Ronald Andersen, and Odin W. Anderson]. Includes bibliographical references. 1580117...|$|R
40|$|In 1992 and 1993 the University of Berne cooperates {{with the}} Siemens-Albis AG Zurich {{in order to}} develop a method which allows to {{generate}} complete TTCN test cases from MSC descriptions. The goal is reached by extending the MSC language with a few new language constructs, relating MSCs and <b>data</b> <b>descriptions,</b> and developing the algorithms for the TTCN generation. The method is implemented by a set of prototype tools. The paper starts with a short introduction (Section 1). Then the current procedure of conformance testing is examined (Section 2). The extensions of the standardized MSC language are described and the specification of test cases with MSCs is shown (Section 3). The algorithm for the generation of TTCN behavior descriptions is sketched (Section 4) and MSCs are related to <b>data</b> <b>descriptions</b> (Section 5). The whole method is summarized and a set of prototype tools which implements the method is presented (Section 6). Finally, a short outlook is given (Section 7). CR Categories [...] ...|$|R
40|$|We {{present a}} dynamic {{multilingual}} repository for multi-source, multilevel linguistic <b>data</b> <b>descriptions.</b> The repository {{is able to}} integrate and merge multiple/concurrent descriptions of linguistic entities and allows existing relationships to be extended and new ones created. In addition, the repository is capable of also storing metadata, allowing for richer descriptions. We present results from work on large data collections and preview developments resulting from ongoing work. 1...|$|R
