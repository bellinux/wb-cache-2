0|10000|Public
40|$|The plant of BASF under {{consideration}} consists of multiple parallel production lines, which produce multiple products in a make-to-stock fashion for process industry. Complicating fac- tors for planning are the stochastic demand, setup <b>times,</b> <b>batch</b> <b>processing</b> and finite buffer capacities. The main contribution {{is the development}} of a three-stage methodology integrating production and inventory decisions, which can be used for the evaluation and optimization {{of a wide range of}} batch-production/inventory systems. Implementation of this methodology in a decision support tool enabled us to identify major opportunities for improvement of current practice...|$|R
50|$|It was {{the opinion}} of Linux Pratique {{magazine}} that Phatch 0.1.3 filled the gap between GIMP and Imagemagick, with a user-friendly interface saving a lot of <b>time</b> for <b>batch</b> <b>processing.</b> Overall {{it was felt that}} it offered fewer features than these two programs.|$|R
50|$|The Exec is {{at heart}} a real <b>time,</b> multi-threaded <b>batch</b> <b>processing</b> system. Everything {{has been built}} around that model. The Exec itself is largely {{structured}} as a real time program. Functions that are performed as Services in Windows or Daemons in Linux and UNIX are implemented as either activities within the Exec or as batch programs that are always running in the background.|$|R
40|$|Digital {{simulation}} models of enhanced TCAS 2 /CDTI traffic sensors are developed, based on actual or projected operational and performance characteristics. Two enhanced Traffic (or Threat) Alert and Collision Avoidance Systems are considered. A digital simulation program is developed in FORTRAN. The program contains {{an executive with}} a semireal <b>time</b> <b>batch</b> <b>processing</b> capability. The simulation program can be interfaced with other modules with a minimum requirement. Both the traffic sensor and CAS logic modules are validated by means of extensive simulation runs. Selected validation cases are discussed in detail, and capabilities and limitations of the actual and simulated systems are noted. The TCAS systems are not specifically intended for Cockpit Display of Traffic Information (CDTI) applications. These systems are sufficiently general to allow implementation of CDTI functions within the real systems' constraints...|$|R
50|$|As his {{personal}} motivating force, Streeter considers Licklider to be positing {{an escape from}} the limitations of the mode of computer use during his <b>time,</b> which was <b>batch</b> <b>processing.</b> Russell thinks Licklider was stimulated by an encounter with the newly developed PDP-1.|$|R
40|$|Overall {{equipment}} effectiveness (OEE) is {{a critical}} key performance indicator for all levels of management involved in manufacturing operations. OEE is an important cultural background for an engineering that will work in a manufacturing plant. This paper discusses a simulation model as a learning tool that helps the students to analyze how the efficiency losses overlapping and affecting production rate of a single machine. Indeed the software allows professor to characterize the production system assigning specific technical data relating to cycle <b>times,</b> <b>batch</b> <b>processing,</b> setup, major stops, quality defects. This opens the possibility to simulate specific system behavior that the student has to point out by the analysis of OEE. The student can also suggest improvements and have a new feedback by the educator in a continuous learning approach. As a result this paper concludes {{by a set of}} examples for OEE teaching...|$|R
40|$|In {{this paper}} we {{consider}} the problem of scheduling jobs with equal processing times on a single <b>batch</b> <b>processing</b> machine so as to minimize a primary and a secondary criteria. We provide optimal polynomial algorithms for various combinations of the primary and secondary criteria. This is the Pre-Published Version. 1 Bicriterion scheduling with equal <b>processing</b> <b>times</b> on a <b>batch</b> <b>processing</b> machin...|$|R
40|$|Real-time {{scheduling}} of {{semiconductor manufacturing}} operations, semiconductor test operations in particular, is complicated {{due to the}} following factors; multi-head resources, multi-level hardware dependency, temperature and hardware criteria, dynamic determination of processing time and indexing <b>time,</b> <b>batch</b> <b>processing</b> and re-entrant flow. A first-ofits -kind, object oriented (OO), discrete event simulation (DES) toolkit, RTMSim++ for real-time simulation-based scheduling applications has been conceptualized, designed, developed to resolve real-time scheduling problems in manufacturing. This paper reviews the work done {{in the development of}} RTMSim++ toolkit, and a case study in a realtime scheduling application. The salient features of the toolkit includes flexibility to customize and extend its functionality, real time shop floor status data initialization, and capability for modeling complex resource and process relationships. In the case study, RTMSim++ has been customized to incorporate very company specific heuristic rules, with the objectives of improving delivery performance, equipment utilization and cycle time...|$|R
50|$|In the {{ultrasonic}} reactor method, the ultrasonic waves {{cause the}} reaction mixture {{to produce and}} collapse bubbles constantly. This cavitation simultaneously provides the mixing and heating required {{to carry out the}} transesterification process. Thus, using an ultrasonic reactor for biodiesel production drastically reduces the reaction time, reaction temperatures, and energy input. Hence the process of transesterification can run inline rather than using the <b>time</b> consuming <b>batch</b> <b>processing.</b> Industrial scale ultrasonic devices allow for the industrial scale processing of several thousand barrels per day.|$|R
40|$|Open Access Article. This {{article is}} {{licensed}} under a Creative Commons Attribution 3. 0 Unported Licence. A microfluidic vortex fluidic device (VFD) operating in either confined or continuous mode {{is effective in}} high yielding photoredox reactions involving Rose Bengal, with short reaction times. This processing can be translated to multi-components reactions, also with significantly reduced <b>processing</b> <b>times</b> relative to <b>batch</b> <b>processing</b> and channel microfluidic processing, with comparable or improved yields...|$|R
40|$|The SEAPAK is a user {{interactive}} {{satellite data}} analysis package {{that was developed}} for the processing and interpretation of Nimbus- 7 /Coastal Zone Color Scanner (CZCS) and the NOAA Advanced Very High Resolution Radiometer (AVHRR) data. Significant revisions were made to version 1. 0 of the guide, and the ancillary environmental data analysis module was expanded. The package continues to emphasize user friendliness and user interactive data analyses. Additionally, because the scientific goals of the ocean color research being conducted have shifted to large space and <b>time</b> scales, <b>batch</b> <b>processing</b> capabilities for both satellite and ancillary environmental data analyses were enhanced, thus allowing large quantities of data to be ingested and analyzed in background...|$|R
40|$|Many process {{industries}} have hybrid production structures, where both batch and continuous processes are involved. Although much {{research has been}} conducted on either continuous or batch {{process industries}}, there is a distinct absence of research in hybrid process industries. This study addresses the modeling and simulation of such process industries by proposing a Timed Hybrid Petri net as a suitable method. The applicability and potential benefit of the proposed technique is shown through a typical hybrid sugar mill case study. A number of receivers are considered between batch and continuous operations in this sugar mill plant which results in a schedule with no idle <b>time</b> for <b>batch</b> <b>processing</b> units. Using the proposed method, the minimum size for each of these receivers is estimated...|$|R
5000|$|For many, lean is {{the set of}} [...] "tools" [...] that {{assist in}} the {{identification}} and steady elimination of waste. As waste is eliminated quality improves while production time and cost are reduced.A non exhaustive list of such tools would include: SMED, value stream mapping, Five S, Kanban (pull systems), poka-yoke (error-proofing), total productive maintenance, elimination of <b>time</b> <b>batching,</b> mixed model <b>processing,</b> rank order clustering, single point scheduling, redesigning working cells, multi-process handling and control charts (for checking mura).|$|R
50|$|Exec 8 {{began as}} a real time {{operating}} system with early use mostly in general scientific and engineering work, {{but it was also}} used in message switching, process control, simulation, and missile firing control. It was designed to run on systems that often had only 128K words (576 K bytes—less than the maximum memory size for the IBM PC XT), and was focused on real <b>time</b> and <b>batch</b> <b>processing.</b> While the earliest release levels did work in 128KW, increasing functionality in later releases made that untenable, since it didn't leave enough space for programs of useful size. The maximum memory capacity of an 1108 was 256KW (1,148 KB) so efficient use of memory was the most important constraint since core memory was the most expensive part of the system.|$|R
40|$|AbstractWe {{consider}} a single batch machine on-line scheduling problem with jobs arriving over <b>time.</b> A <b>batch</b> <b>processing</b> machine can handle up to B jobs simultaneously as a <b>batch,</b> and the <b>processing</b> <b>time</b> for a <b>batch</b> {{is equal to}} the longest processing time among the jobs in it. Each job becomes available at its arrival time, which is not known in advance, and its characteristics, such as processing time and delivery time, become known at its arrival. Once the processing of a job is completed we deliver it to the destination. The objective is to minimize the time by which all jobs have been delivered. In this paper, we deal with two variants: the unbound model where B is sufficiently large and the bounded model where B is finite. We provide on-line algorithms with competitive ratio 2 for the unbounded model and with competitive ratio 3 for the bounded model. For when each job has the same processing time, we provide on-line algorithms with competitive ratios (5 + 1) / 2, and these results are the best possible...|$|R
40|$|AbstractWe {{consider}} an online scheduling {{problem in a}} parallel <b>batch</b> <b>processing</b> system with jobs in a batch being allowed to restart. Online means that jobs arrive over time, and all jobs’ characteristics are unknown before their arrival <b>times.</b> A parallel <b>batch</b> <b>processing</b> machine can handle up to several jobs simultaneously. All jobs in a batch start and complete at the same time. The <b>processing</b> <b>time</b> of a <b>batch</b> {{is equal to the}} longest processing time of jobs in the batch. We are allowed to restart a batch, that is, a running batch may be interrupted, losing all the work done on it. Jobs in the interrupted batch are released and become independently unscheduled jobs. We deal with an unbounded model where each batch’s capacity is sufficiently large. We provide a linear online algorithm with competitive ratio 3 / 2 for the problem. We also show that the considered problem has no online algorithm using restarts with competitive ratio less than (5 − 5) / 2...|$|R
40|$|This {{automated}} processing pipeline {{has been in}} operation since 2002 and has greatly simplified data transfer and routine MRI data processing steps. Advantages of this approach include: • Automatic detection and processing occurs within minutes after files appear on the scanner. • Automatic display of head motion and image intensity plots at the scanner identifies image acquisition and subject stability problems in close to real <b>time.</b> • The <b>batch</b> <b>processing</b> service allows users to submit complex processing instructions involving diverse processing packages such as AIR 1, SPM 2, and AFNI 3. • Centralized processing logs and automated notifications of potential problems throughout the network. • The <b>Batch</b> <b>Processing</b> service takes care of scheduling, running, and monitoring all processing jobs, allowing full and efficient use of server resources. • Automated archiving of raw data files and DICOM images allows an additional safeguard for protecting data...|$|R
40|$|PC-SEAPAK is {{designed}} to provide a complete and affordable capability for processing and analysis of NOAA Advanced Very High Resolution Radiometer (AVHRR) and Nimbus- 7 Coastal Zone Color Scanner (CZCS) data. Since the release of version 3. 0 over a year ago, significant revisions were made to the AVHRR and CZCS programs and to the statistical data analysis module, and a number of new programs were added. This new version has 114 procedures listed in its menus. The package continues to emphasize user-friendliness and interactive data analysis. Additionally, because the scientific goals of the ocean color research being conducted have shifted to larger space and <b>time</b> scales, <b>batch</b> <b>processing</b> capabilities were enhanced, allowing large quantities of data to be easily ingested and analyzed. The development of PC-SEAPAK was paralled by two other activities that were influential and assistive: the global CZCS processing effort at GSFC and the continued development of VAX-SEAPAK. SEAPAK incorporates the instrument calibration and support all levels of data available from the CZCS archive...|$|R
40|$|In {{this paper}} we {{consider}} a practical scheduling problem commonly arising from batch production in a flexible manufacturing environment. Different part-types {{are to be}} produced in a flexible manufacturing cell organized into a two-stage production line. The jobs are processed in batches on the first machine, and the completion time of a job {{is defined as the}} completion <b>time</b> of the <b>batch</b> containing it. When processing of all jobs in a batch is completed on the first machine, the whole batch of jobs is transferred intact to the second machine. A constant setup time is incurred whenever a batch is formed on any machine. The tradeoff between the setup <b>times</b> and <b>batch</b> <b>processing</b> <b>times</b> gives rise to the batch composition decision. The problem is to find the optimal batch composition and the optimal schedule of the batches so that the makespan is minimized. The problem is shown to be strongly NP-hard. We identify some special cases by introducing their corresponding solution methods. Heuristic algorithms are also proposed to derive approximate solutions. We conduct computational experiments to study the effectiveness of the proposed heuristics. Department of Logistics and Maritime Studie...|$|R
40|$|Abstract — We present several discrete-time Markov queuing {{models to}} compare the {{performance}} of <b>batch</b> versus streaming <b>processing</b> of sensor data in a weather detection and monitoring system architecture. The first model assumes independent arrivals and illustrates the average case behavior of the system. The remaining models assume correlated arrivals and demonstrate how different scan strategies across multiple elevations impact system performance. We also show how the models are useful in dimensioning the computational resources of the system given workload arrival characteristics. We apply the models to several hypothetical scenarios with varying weather feature arrival and processing rates. We also evaluate our models using processing runtime data obtained by running two NEXRAD algorithms on weather data from six airports. Our results show that for this particular application and reasonable system utilizations, <b>delaying</b> processing start <b>time</b> to perform <b>batch</b> <b>processing</b> does not adversely affect system performance or require significant, additional computational resources. More generally, our models show how system performance {{is dependent on the}} scan strategy and the burstiness of the sensor data. I...|$|R
40|$|Abstract We {{consider}} {{the problem of}} minimizing the makespan(Cmax) on m identical parallel <b>batch</b> <b>processing</b> machines. The <b>batch</b> <b>processing</b> machine can process up to B jobs simultaneously. The jobs that are processed together form a batch, and all jobs in a batch start and complete at the same <b>time.</b> For a <b>batch</b> of jobs, the <b>processing</b> <b>time</b> of the <b>batch</b> {{is equal to the}} largest processing time among the jobs in the batch. In this paper, we design a fully polynomial time approximation scheme (FPTAS) to solve the bounded identical parallel batch scheduling problem Pm|B < n|Cmax when the number of identical parallel <b>batch</b> <b>processing</b> machines m is constant...|$|R
40|$|Abstract—Scalable stream {{processing}} and continuous dataflow systems are gaining traction {{with the rise}} of big data due to the need for processing high velocity data in near real <b>time.</b> Unlike <b>batch</b> <b>processing</b> systems such as MapReduce and workflows, static scheduling strategies fall short for continuous dataflows due to the variations in the input data rates and the need for sustained throughput. The elastic resource provisioning of cloud infrastructure is valuable to meet the changing resource needs of such continuous appli-cations. However, multi-tenant cloud resources introduce yet another dimension of performance variability that impacts the application’s throughput. In this paper we propose PLAStiCC, an adaptive scheduling algorithm that balances resource cost and application throughput using a prediction-based look-ahead approach. It not only addresses variations in the input data rates but also the underlying cloud infrastructure. In addition, we also propose several simpler static scheduling heuristics that operate in the absence of accurate performance prediction model. These static and adaptive heuristics are evaluated through extensive simulations using performance traces obtained from public and private IaaS clouds. Our results show an improvement of upto 20 % in the overall profit as compared to the reactive adaptation algorithm...|$|R
40|$|This report {{includes}} major {{findings and}} outlook from the transformational electrode drying project performance period from January 6, 2012 to August 1, 2012. Electrode drying before cell assembly is an operational bottleneck in battery manufacturing due to long drying <b>times</b> and <b>batch</b> <b>processing.</b> Water taken up during shipment and other manufacturing steps {{needs to be}} removed before final battery assembly. Conventional vacuum ovens are limited in drying speed due to a temperature threshold needed to avoid damaging polymer components in the composite electrode. Roll to roll operation and alternative treatments can increase the water desorption and removal rate without overheating and damaging other components in the composite electrode, thus considerably reducing drying time and energy use. The objective of this project was {{the development of an}} electrode drying procedure, and the demonstration of processes with no decrease in battery performance. The benchmark for all drying data was an 80 °C vacuum furnace treatment with a residence time of 18 – 22 hours. This report demonstrates an alternative roll to roll drying process with a 500 -fold improvement in drying time down to 2 minutes and consumption of only 30 % of the energy compared to vacuum furnace treatment...|$|R
40|$|Scalable stream {{processing}} and continuous dataflow systems are gaining traction {{with the rise}} of big data due to the need for processing high velocity data in near real <b>time.</b> Unlike <b>batch</b> <b>processing</b> systems such as MapReduce and workflows, static scheduling strategies fall short for continuous dataflows due to the variations in the input data rates and the need for sustained throughput. The elastic resource provisioning of cloud infrastructure is valuable to meet the changing resource needs of such continuous applications. However, multi-tenant cloud resources introduce yet another dimension of performance variability that impacts the application's throughput. In this paper we propose PLAStiCC, an adaptive scheduling algorithm that balances resource cost and application throughput using a prediction-based lookahead approach. It not only addresses variations in the input data rates but also the underlying cloud infrastructure. In addition, we also propose several simpler static scheduling heuristics that operate in the absence of accurate performance prediction model. These static and adaptive heuristics are evaluated through extensive simulations using performance traces obtained from Amazon AWS IaaS public cloud. Our results show an improvement of up to 20 % in the overall profit as compared to the reactive adaptation algorithm...|$|R
40|$|<b>Batch</b> <b>processing</b> {{technologies}} (Such as MapReduce, Hive, Pig) have matured {{and been}} {{widely used in}} the industry. These systems solved the issue processing big volumes of data successfully. However, first big amount of data need to be collected and stored in a database or file system. That is very time-consuming. Then it takes <b>time</b> to finish <b>batch</b> <b>processing</b> analysis jobs before get any results. While there are many cases that need analysed results from unbounded sequence of data in seconds or sub-seconds. To satisfy the increasing demand of processing such streaming data, several streaming processing systems are implemented and widely adopted, such as Apache Storm, Apache Spark, IBM InfoSphere Streams, and Apache Flink. They all support online stream processing, high scalability, and tasks monitoring. While how to evaluate stream processing systems before choosing one in production development is an open question. In this thesis, we introduce StreamBench, a benchmark framework to facilitate performance comparisons of stream processing systems. A common API component and a core set of workloads are defined. We implement the common API and run benchmarks for three widely used open source stream processing systems: Apache Storm, Flink, and Spark Streaming. A key feature of the StreamBench framework {{is that it is}} extensible [...] it supports easy definition of new workloads, in addition to making it easy to benchmark new stream processing systems...|$|R
40|$|AbstractScreening {{patients}} for methicillin-resistant Staphylococcus aureus (MRSA) carriage at hospital admission is widely accepted {{as an essential}} part of MRSA control programmes. It is assumed, although not proven, that rapid reporting of screening results will improve MRSA control, provided that a clear action plan for positive cases is in place and is being followed. An effective culture screening method is direct inoculation of pooled nose, throat and perineal swabs on a well-performing MRSA-selective chromogenic agar; presumptive MRSA colonies can be confirmed rapidly by latex agglutination with antibodies directed against penicillin-binding protein 2 a. This method will usually produce a positive result after 24 h of incubation in > 95 % of true-positive cases, and will be sufficient for most initial treatment and infection control decisions; full antimicrobial susceptibilities will be available on the next day. Inoculation of selective enrichment broth containing a colorimetric growth indicator is an alternative overnight culture method, but there may be problems with overgrowth of other organisms, such as enterococci. PCR methods are now available that can produce same-day results, provided that samples reach the laboratory in <b>time</b> for <b>batch</b> <b>processing,</b> but cultures are required for susceptibility testing. In comparison with culture-based methods, PCR tests are costly, and some have relatively high false-positivity rates; definitive evidence of their clinical cost-effectiveness is lacking. New point-of-care PCR tests are being introduced that are potentially even more rapid but are even more expensive; studies on the clinical cost-effectiveness of these very rapid tests are awaited...|$|R
40|$|We {{present a}} MIP model for <b>batch</b> <b>processing</b> {{problems}} {{occurring in the}} chemical industry. The formulation of the model {{is based on a}} nonuniform discretization of time. The scheduling horizon is divided into intervals such that each point of the time grid corresponds to the starting <b>time</b> of some <b>batch...</b>|$|R
50|$|Early {{mainframe}} computers (in the 1950s) were non-interactive, instead using <b>batch</b> <b>processing.</b> IBM's Job Control Language (JCL) is the {{archetype of}} languages {{used to control}} <b>batch</b> <b>processing.</b>|$|R
30|$|There {{are a few}} {{differences}} between utterance-based <b>batch</b> <b>processing</b> and full <b>batch</b> <b>processing.</b> In utterance-based <b>batch</b> <b>processing,</b> we normalize the features of each utterance to zero mean and compute a 100 -dimensional i-vector from this utterance. In full <b>batch</b> <b>processing,</b> we normalize the features of each speaker in a room to zero mean and compute a 100 -dimensional i-vector from this speaker in the room. In order to assign utterances in a room to speakers, we carry out speaker diarization using {{a modified version of}} the multi-stage segmentation and clustering system [42] as described before.|$|R
30|$|Another {{difference}} between utterance-based versus full <b>batch</b> <b>processing</b> {{is that we}} are able to decode with MLIFD features in full <b>batch</b> <b>processing.</b> The MLIFD features for an utterance are transformed using LDA + STC + FMLLR before input to the neural net. FMLLR transform per utterance resulted in significant increase in WER, and therefore, the MLIFD feature was not used in utterance-based <b>batch</b> <b>processing.</b> In full <b>batch</b> <b>processing,</b> the FMLLR is computed from all the utterances of a speaker in the room. In this scenario, MLIFD features gave very good results.|$|R
5000|$|John Backus {{said in the}} 1954 summer {{session at}} MIT that [...] "By time-sharing, a big {{computer}} {{could be used as}} several small ones; there would need to be a reading station for each user". But computers at that time, like IBM 704, were not powerful enough to implement such system. In June 1959, Christopher Strachey published a paper [...] "Time Sharing in Large Fast Computers" [...] at the UNESCO Information Processing Conference in Paris, where he envisaged a programmer debugging a program at a console (like a teletype) connected to the computer, while another program was running in the computer at the same time. Debugging programs was an important problem at that <b>time,</b> because with <b>batch</b> <b>processing,</b> it then often took a day from submitting a changed code, to getting the results. John McCarthy wrote a memo about that at MIT, after which a preliminary study committee and a working committee were established at MIT, to develop time sharing. The committees envisaged many users using the computer at the same time, decided the details of implementing such system at MIT, and started the development of the system.|$|R
50|$|Memo-posting is a {{term used}} in {{traditional}} computerized banking environments where <b>batch</b> <b>processing</b> is employed. It represents temporary credit or debit transactions/entries made to an account for which the complete posting to update the balance will be done {{as part of the}} EOD(end-of-day) <b>batch</b> <b>processing.</b> The temporary transaction created as part of the memo-posting will be reversed/removed after the actual transaction is posted in <b>batch</b> <b>processing.</b>|$|R
50|$|<b>Batch</b> <b>processing</b> is {{execution}} {{of a series of}} programs (jobs) on a computer without manual intervention. Several transactions, called a batch are collected and processed at the same time. The results of each transaction are not immediately available when the transaction is being entered; there is a <b>time</b> <b>delay.</b>|$|R
40|$|We {{consider}} {{the problem of}} minimizing the total late work (∑_j= 1 ^n V_j) on an unbounded <b>batch</b> <b>processing</b> machine, where Vj = min Tj, pj and Tj = max Cj - dj, 0. The <b>batch</b> <b>processing</b> machine can process up to B (B ≥ n) jobs simultaneously. The jobs that are processed together form a batch, and all jobs in a batch start and complete at the same time, respectively. For a batch of jobs, the <b>processing</b> <b>time</b> of the <b>batch</b> {{is equal to the}} largest processing time among the jobs in this batch. In this paper, we prove that the problem 1 |B ≥ n|∑_j= 1 ^nV_j is NP-hard. Scheduling, batching machine, late work, NP-hardness...|$|R
5000|$|<b>Batch</b> <b>processing</b> - the {{traditional}} {{date and time}} based execution of background tasks based on a defined period during which resources were available for <b>batch</b> <b>processing</b> (the <b>batch</b> window). In effect the original mainframe approach transposed onto the open systems environment.|$|R
30|$|The {{decoding}} {{algorithm is}} slightly different {{depending on whether}} we are doing utterance-based <b>batch</b> <b>processing</b> or full <b>batch</b> <b>processing.</b> For the maximum likelihood inverse filtering-based dereverberation (MLIFD) features that use FMLLR transform, we only use full <b>batch</b> <b>processing,</b> since we need to compute the FMLLR transform for the speaker from all the utterances of the speaker in the room. Computing the FMLLR transform from a single short utterance gives poor results (we need over 20 s of audio to estimate reasonable FMLLR transforms).|$|R
