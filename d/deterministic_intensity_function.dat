2|2178|Public
40|$|AbstractWe {{consider}} a single-server service station {{at which a}} stream of customers arrive in accordance with a point process with a locally integrable <b>deterministic</b> <b>intensity</b> <b>function</b> and customer service times are independently and identically distributed. Customers arriving at the station may be dispatched to somewhere else or may be admitted to the queue of the station and waiting to be served. In this paper, martingale theory for point processes is applied to obtain the optimal admission policy that minimizes the expected fixed duration cost due {{to the difference between}} the queue size and the throughput of the station, where the throughput of the station is being defined as the total number of customers admitted to the queue for the period...|$|E
40|$|Copula {{functions}} {{have become}} standard practice for pricing multi-name credit derivatives. Marginal default distributions are often chosen {{by using a}} simple <b>deterministic</b> <b>intensity</b> <b>function.</b> It is wellknown that this approach only generates default time correlation and, apart from jumps due to default events, does not generate correlation between the conditional default intensities, or the conditional spreads. In this paper we consider pricing multi-name credit derivatives taking both default time correlation as well as default intensity correlation into account. This is achieved by defining two common factors, one {{for each type of}} correlation. Further, we derive a fast way to price conditional on default events or survival for the factor model. Default and survival information is translated to information on the common factor. This approach allows us to graph conditional default intensities, or conditional CDS spreads, for simulated scenarios. These simulations show that our model results in a more realistic behavior of the conditional CDS spreads as one can distinguish both credit spread correlation as well as jumps in case of correlated default events...|$|E
40|$|The pricing {{framework}} {{used in this}} dissertation {{allows for}} the specification of catastrophe risk under the real-world measure. This gives the user {{a great deal of}} freedom in the assumptions made about the underlying catastrophe risk process (referred to in this dissertation as the aggregate loss process). Therefore, this dissertation aims to shed light on the effect of various assumptions and considerations on index-linked CAT bond prices based on the Property Claims Services (PCS) index. Also, given the lack of a closed-form solution to the pricing formulae used and the lack of a liquidly-traded secondary market, this dissertation compares two approximation methods to evaluate expressions involving the aggregate loss process: Monte Carlo simulation and a mixed-approximation method. The two price-approximation methods are largely consistent and seem to agree particularly in the upper quantiles of the distribution of the aggregate loss process. Another key consideration is that the third-party estimating the catastrophe losses in North America, PCS, only records catastrophe losses above $ 25 million. This dissertation therefore also explores the issue of left-truncated data and its effect when estimating the parameters of the aggregate loss process. For this purpose, it introduces a non-parametric approach to compare, in sample, the results of ignoring the threshold and taking it into account. In both these exercises, it becomes apparent that very heavy-tailed distributions need to be used with caution. In the former case, the use of very heavy-tailed distributions places restrictions on the distributions {{that can be used for}} the mixed-approximation method. Finally, as a more realistic avenue this dissertation proposes a simple stochastic intensity model to compare with the <b>deterministic</b> <b>intensity</b> model and found that, by parsimony, the <b>deterministic</b> <b>intensity</b> seems to provide a reasonable model for the upper quantiles of the aggregate loss process. The key results of this dissertation are that the pricing of CAT bonds depends on the quantiles of the aggregate loss process, as in evident both when comparing the approximation methods and the <b>deterministic</b> and stochastic <b>intensity</b> <b>functions,</b> and that left-truncation should be taken into account when valuing index-linked CAT bonds using data from PCS...|$|R
40|$|A {{technique}} {{to compute the}} Cumulative Distribution Function (CDF) of the Signal-to-Interference-plus-Noise-Ratio (SINR) for a wireless link with a multi-antenna, Linear, Minimum-Mean-Square-Error (MMSE) receiver {{in the presence of}} interferers distributed according to a non-homogenous Poisson point process on the plane, and independent Rayleigh fading between antennas is presented. This technique is used to compute the CDF of the SINR for several different models of <b>intensity</b> <b>functions,</b> in particular, power-law <b>intensity</b> <b>functions,</b> circular-symmetric Gaussian <b>intensity</b> <b>functions</b> and <b>intensity</b> <b>functions</b> described by a polynomial in a bounded domain. Additionally it is shown that if the number of receiver antennas is scaled linearly with the <b>intensity</b> <b>function,</b> the SINR converges in probability to a limit determined by the "shape" of the underlying <b>intensity</b> <b>function.</b> This work generalizes known results for homogenous Poisson networks to non-homogenous Poisson networks...|$|R
2500|$|An inhomogeneous Poisson process {{defined in}} the plane [...] is called a spatial Poisson process [...] It is defined with <b>intensity</b> <b>function</b> and its <b>intensity</b> measure is {{obtained}} performing an surface integral of its <b>intensity</b> <b>function</b> over some region. For example, its <b>intensity</b> <b>function</b> (as a function of Cartesian coordinates [...] and [...] ) can be ...|$|R
2500|$|For the inhomogeneous, {{a couple}} of {{different}} methods can be used depending {{on the nature of the}} <b>intensity</b> <b>function</b> [...] If the <b>intensity</b> <b>function</b> is sufficiently simple, then independent and random non-uniform (Cartesian or other) coordinates of the points can be generated. For example, simulating a Poisson point process on a circular window can be done for an isotropic <b>intensity</b> <b>function</b> (in polar coordinates [...] and [...] ), implying it is rotationally variant or independent of [...] but dependent on , by a change of variable in [...] if the <b>intensity</b> <b>function</b> is sufficiently simple.|$|R
5000|$|In {{digital camera}} the image <b>intensity</b> <b>function</b> is only {{measured}} in discrete sensor elements. Inexact interpolation of the discrete <b>intensity</b> <b>function</b> {{have to be}} used to recover the true one.|$|R
40|$|In this paper, a new optimization-based {{approach}} to constructing a poverty index is considered. From a general perspective, {{first and second}} order conditions based on a general poverty <b>intensity</b> <b>function</b> are derived. Then using specific <b>intensity</b> <b>functions</b> defined by [1, 3] respectively, we specify related necessary and sufficient conditions and the underlying poverty indices. An extension based on a large class of <b>intensity</b> <b>function</b> is also investigated...|$|R
40|$|In {{this paper}} one {{considers}} a general approach {{to construct a}} poverty index. In particular from a general perspective, first and second order conditions based on a general poverty <b>intensity</b> <b>function</b> are derived. Then using specific <b>intensity</b> <b>functions</b> defined by Sen, FGT and Shorrock respectively, one specifies related first and second conditions. An extension based on a large class of <b>intensity</b> <b>function</b> is also investigated...|$|R
50|$|Since the <b>intensity</b> <b>function</b> of {{a digital}} image is only known at {{discrete}} points, derivatives of this function cannot be defined unless {{we assume that}} there is an underlying continuous <b>intensity</b> <b>function</b> which has been sampled at the image points. With some additional assumptions, the derivative of the continuous <b>intensity</b> <b>function</b> can be computed as a function on the sampled <b>intensity</b> <b>function,</b> i.e. the digital image. It turns out that the derivatives at any particular point are <b>functions</b> of the <b>intensity</b> values at virtually all image points. However, approximations of these derivative functions can be defined at lesser or larger degrees of accuracy.|$|R
50|$|Since the <b>intensity</b> <b>function</b> of {{a digital}} image is only known at {{discrete}} points, derivatives of this function cannot be defined unless {{we assume that}} there is an underlying continuous <b>intensity</b> <b>function</b> which has been sampled at the image points. With some additional assumptions, the derivative of the continuous <b>intensity</b> <b>function</b> can be computed as a function on the sampled <b>intensity</b> <b>function,</b> i.e., the digital image. Approximations of these derivative functions can be defined at varying degrees of accuracy. The most common way to approximate the image gradient is to convolve an image with a kernel, such as the Sobel operator or Prewitt operator.|$|R
40|$|We {{consider}} {{the problem of}} estimating the <b>intensity</b> <b>function</b> of a cyclic Poisson point process. We suppose that only a single realization of the cyclic Poisson point process is observed within a bounded 'window', and our aim is to estimate consistently the <b>intensity</b> <b>function</b> at a given point. A nearest neighbor estimator of the <b>intensity</b> <b>function</b> is proposed, and we show that our estimator is weakly and strongly consistent, as the window expands...|$|R
40|$|We {{construct}} and investigate a consistent kernel-type nonparametric estimator of the <b>intensity</b> <b>function</b> of a cyclic Poisson process when the period is unknown. We do not assume any particular parametric {{form for the}} <b>intensity</b> <b>function,</b> nor do we even assume that it is continuous. Moreover, we consider the situation when only a single realization of the Poisson process is available, and only in a bounded window. We prove, in particular, that the proposed estimator is consistent when {{the size of the}} window indefinitely expands. We also obtain complete convergence of the estimator. Poisson process Cyclic Poisson process Periodic Poisson process Point process Cyclic <b>intensity</b> <b>function</b> Periodic <b>intensity</b> <b>function</b> Nonparametric estimation Consistency Rate of consistency...|$|R
30|$|Λ(RL): <b>Intensity</b> <b>function</b> for system failure.|$|R
40|$|This article {{contains}} the derivations of expressions for the mean squared errors for two estimators of the <b>intensity</b> <b>function</b> {{of the power}} law process, a nonhomogeneous Poisson process with <b>intensity</b> <b>function</b> ([beta]/[theta]) (t/[theta]) [beta]- 1. mean squared error efficiency Weibull process power law process nonhomogeneous Poisson process...|$|R
40|$|The non-homogeneous Poisson process (NHPP) {{model is}} a very {{important}} class of software reliability models and is widely used in software reliability engineering. NHPPs are characterized by their <b>intensity</b> <b>functions.</b> In the literature it is usually assumed that the functional forms of the <b>intensity</b> <b>functions</b> are known and only some parameters in <b>intensity</b> <b>functions</b> are unknown. The parametric statistical methods can then be applied to estimate or to test the unknown reliability models. However, in realistic situations it is often the case that the functional form of the failure intensity is not very well known or is completely unknown. In this case we have to use functional (non-parametric) estimation methods. The non-parametric techniques do not require any preliminary assumption on the software models and then can reduce the parameter modeling bias. The existing non-parametric methods in the statistical methods are usually not applicable to software reliability data. In this paper we construct some non-parametric methods to estimate the failure <b>intensity</b> <b>function</b> of the NHPP model, taking the particularities of the software failure data into consideration. Software reliability, NHPP model, <b>intensity</b> <b>function,</b> non-parametric estimation,...|$|R
40|$|Algorithms are {{developed}} for generating {{a sequence of}} event times from a nonhomogeneous Poisson process that {{is influenced by the}} values of covariates that vary with time. Closed form expressions for random variate generation are shown for several baseline <b>intensity</b> and link <b>functions.</b> Tw o specific models linking the baseline process to the general model are considered: the accelerated time model and the proportional intensity model. In the accelerated time model, the cumulative <b>intensity</b> <b>function</b> of a nonhomogeneous Poisson process under covariate effects is Λ(t; z(t)) =Λ 0 (t 0 ψ (z(u)) du), where z is a covariate vector, Λ 0 (t) isthe baseline cumulative <b>intensity</b> <b>function</b> and ψ (z) is the link function. In the proportional intensity model, the cumulative <b>intensity</b> <b>function</b> of a nonhomogeneous Poisson process under covariate effects is t Λ(t; z(t)) = ∫ ψ (z(u)) λ 0 (u) du, where λ 0 (t) isthe baseline <b>intensity</b> <b>function.</b> ...|$|R
40|$|Marko. Salmen kivi @ cs. helsinki. fi Sequences {{of events}} are an {{important}} type of data arising in various applications, including telecommunications, biostatistics, web access analysis, etc. A basic approach to modeling such sequences {{is to find the}} underlying <b>intensity</b> <b>functions</b> describing the expected number of events per time unit. Typically, the <b>intensity</b> <b>functions</b> are assumed to be piecewise constant. We therefore consider different ways of fitting intensity models to event sequence data. We start by considering a Bayesian approach using Markov chain Monte Carlo (MCMC) methods with varying number of pieces. These methods can be used to produce posterior distributions on the <b>intensity</b> <b>functions</b> and they can also accomodate covariates. The drawback is that they are computationally intensive and thus are not very suitable for data mining applications in which large numbers of <b>intensity</b> <b>functions</b> have to be estimated. We consider dynamic programming approaches to finding the change points in the <b>intensity</b> <b>functions.</b> These methods can find the maximum likelihood <b>intensity</b> <b>function</b> in O(n 2 k) time for a sequence of n events and k different pieces of intensity. We show that simple heuristics can be used to prune the number of potential change points, yielding speedups of several orders of magnitude. The results of the improved dynamic programming method correspond very closely with the posterior averages produced by the MCMC methods...|$|R
5000|$|... #Caption: Graph of the Airy <b>intensity</b> <b>function</b> vs. {{normalized}} radius ...|$|R
5000|$|One {{algorithm}} {{proposed for}} computing the temporal <b>intensity</b> <b>function</b> is: ...|$|R
40|$|The {{analysis}} of spatial point patterns {{that occur in}} the network domain have recently gained much attraction and various <b>intensity</b> <b>functions</b> and measures have been proposed. However, the linkage of spatial network statistics to regression models has not been approached so far. This paper presents a new regression approach which treats a generic <b>intensity</b> <b>function</b> of a planar point pattern that occurred on a network as the outcome of a set of different covariates and various graph statistics. Different to all alternative approaches, our model is the first which permits the statistical {{analysis of}} complex regression data in the context of network <b>intensity</b> <b>functions</b> for spatial point patterns. The potential of our new technique to model the structural dependencies of network <b>intensity</b> <b>functions</b> on various covariates and graph statistics is illustrated using call-in data on neighbour and community disturbances in an urban context...|$|R
40|$|Anonparametric {{technique}} for estimating the cumulative <b>intensity</b> <b>function</b> of a nonhomogeneous Poisson process {{from one or}} more realizations is developed. This technique does not require any arbitrary parameters from the modeler, and the estimated cumulative <b>intensity</b> <b>function</b> {{can be used to}} generate a point process for Monte Carlo simulation by inversion. Three examples are given...|$|R
40|$|In this paper, kernel {{function}} methods are considered for estimating the <b>intensity</b> <b>function</b> of a non-homogeneous Poisson process. A least-squares cross-validation bandwidth for the kernel intensity estimator is introduced, {{and it is}} proven that this bandwidth is asymptotically optimal for kernel intensity estimation. bandwidth selection <b>intensity</b> <b>function</b> cross-validation bandwidth kernel estimation nonstationary Poisson processes...|$|R
5000|$|The <b>intensity</b> <b>function</b> {{corresponding}} to the complex structure factor is equal to ...|$|R
40|$|A nonparametric {{technique}} for {{the estimation of}} the cumulative <b>intensity</b> <b>function</b> for a nonhomogeneous service process from one or more realizations that may contain idle periods is developed. This technique does not require any arbitrary parameters from the modeler. The estimated cumulative <b>intensity</b> <b>function</b> {{can be used for}} the generation of variates for simulation via inversion" [...] Author abstract...|$|R
2500|$|... {{where the}} density [...] is known, among other terms, as the <b>intensity</b> <b>function.</b>|$|R
40|$|A novel {{class of}} {{generating}} kernels for image pyramids is introduced. When these kernels are convolved with <b>intensity</b> <b>functions</b> of images, continuous piecewise surfaces composed of polynomial tensor products are fitted to the <b>intensity</b> <b>functions.</b> The fittings are optimal {{in the sense}} that the mean square error between them and the original <b>intensity</b> <b>functions</b> is minimized. Two members of the class are introduced, and symmetry, normalization, unimodality, and equal contribution properties are proved. These kernels possess attractive properties such as small window size, fast inverse transformation, and minimum error. Experiments show that they compare favorably with existing ones in terms of mean square error. link_to_subscribed_fulltex...|$|R
40|$|We study zero {{distribution}} of random linear combinations {{of the form}} P_n(z) =∑_j= 0 ^nη_jf_j(z), in any Jordan region Ω⊂ C. The basis functions f_j are entire functions that are real-valued on the real line, and η_ 0, [...] .,η_n are complex-valued iid Gaussian random variables. We derive an explicit <b>intensity</b> <b>function</b> {{for the number of}} zeros of P_n in Ω for each fixed n. Our main application is to polynomials orthogonal on the real line. Using the Christoffel-Darboux formula the <b>intensity</b> <b>function</b> takes a very simple shape. Moreover, we give the limiting value of the <b>intensity</b> <b>function</b> when the orthogonal polynomials are associated to Szegő weights...|$|R
40|$|Abstract A new {{approach}} for point process diagnostics is presented. The method {{is based on}} extending second-order statistics for point processes by weighting each point by the inverse of the conditional <b>intensity</b> <b>function</b> at the point’s location. The result is generalized versions of the spectral density, R/S statistic, correlation integral and K-function, {{which can be used}} to test the fit of a complex point process model with an arbitrary conditional <b>intensity</b> <b>function,</b> rather than a stationary Poisson model. Asymptotic properties of these generalized second-order statistics are derived, using an approach based on martingale theory. Keywords Residual analysis · Point process · Second-order analysis · Conditional <b>intensity</b> <b>function...</b>|$|R
5000|$|... {{which is}} the {{two-dimensional}} Fourier transform of the <b>intensity</b> <b>function.</b> This completes the proof.|$|R
40|$|This paper {{develops}} a new wavelet-domain Bayesian framework for modeling and estimating {{the intensity of}} a Poisson process directly from count observations. A new multiscale, multiplicative innovations model is developed as a prior for the underlying <b>intensity</b> <b>function.</b> The new prior model leads to a simple and efficient closed-form estimator that requires O(N) computations, where N is the dimension of the <b>intensity</b> <b>function.</b> We compare the new method with previously proposed wavelet-based approaches to this problem. 1. INTRODUCTION This paper considers the problem of estimating the intensity of a Poisson process from a single observation of the process. We observe counts c ¸ Poisson() (1) where is a 1 -d or 2 -d <b>intensity</b> <b>function.</b> The <b>intensity</b> <b>function</b> is discretized and to simplify the presentation we assume {{that it is a}} 1 -d signal vector, although all results are easily extended to images. Furthermore, we assume that both c and are N Θ 1 vectors. The contribution of this p [...] ...|$|R
40|$|A nonparametric {{technique}} for estimating the cumulative <b>intensity</b> <b>function</b> of a nonhomogeneous Poisson process {{from one or}} more realizations is developed. This technique does not require any arbitrary parameters from the modeler, and the estimated cumulative <b>intensity</b> <b>function</b> {{can be used to}} generate a point process for Monte Carlo simulation by inversion. Three examples are given. nonstationary Poisson process, repairable systems, time-dependent arrivals, simulation, variate generation...|$|R
40|$|We {{discuss and}} compare various {{approaches}} {{to the problem of}} bandwidth selection for kernel estimators of <b>intensity</b> <b>functions</b> of spatial point processes. We also propose a new method based on the Campbell formula applied to the reciprocal <b>intensity</b> <b>function.</b> The new method is fully non-parametric, does not require knowledge of the product densities, and is not restricted to a specific class of point process models...|$|R
40|$|Recent {{results on}} {{unfolding}} Poisson process <b>intensity</b> <b>function</b> are improved. Singular matrix approximation of the folding operator is allowed. For Euclidean spaces, the assumptions {{are expressed in}} terms of the decay rate of the singular values of the original folding operator rather than those of the approximating matrix. L 2 -convergence rates and approximation effects are discussed. Quasi-maximum likelihood Poisson process <b>Intensity</b> <b>function</b> Unfolding Discretization...|$|R
30|$|As {{discussed}} in the previous section, once any <b>intensity</b> transfer <b>function</b> T[Iin(x, y)] defined in (4) is determined, the proposed SDRCLCE equation (10) {{can be applied to}} the <b>intensity</b> transfer <b>function</b> and realize the function of SDRCLCE. This implies that the enhanced output of the proposed SDRCLCE algorithm is characterized by the selected <b>intensity</b> transfer <b>function.</b> Therefore, the selection of a suitable <b>intensity</b> transfer <b>function</b> is an important task before applying SDRCLCE algorithm. In this section, a novel <b>intensity</b> transfer <b>function</b> is first presented. The proposed algorithm is then derived based on SDRCLCE equation (10).|$|R
30|$|Linear or {{nonlinear}} dynamic processes {{have been}} simulated either deterministically or stochastically by Monte Carlo procedures. It {{is worth noting}} that a well-developed class of Monte Carlo simulation procedures essentially shares identical computational bases with the master equation algorithm presented in the preceding sections. Specifically, the assumptions of Markov property and temporal homogeneity of the random variables lead to the definitions of transition <b>intensity</b> <b>functions</b> [33, 40, 41]. As discussed in the “Model Formulation” section, probability balances of various events {{on the basis of these}} <b>intensity</b> <b>functions</b> give rise to the master equations. In the Monte Carlo simulation, the system’s state is simulated by a step-wise, random-walk scheme based on the same <b>intensity</b> <b>functions.</b>|$|R
