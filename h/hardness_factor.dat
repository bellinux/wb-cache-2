46|134|Public
5000|$|... a split 7" [...] with Refrigerator, {{included}} with {{an issue of}} Nipple <b>Hardness</b> <b>Factor</b> zine.|$|E
5000|$|... "Anti-Nomination", from a split 7" [...] with Refrigerator {{included}} with issue No. 8 of Nipple <b>Hardness</b> <b>Factor</b> zine (1995) ...|$|E
40|$|We study {{variants}} {{of the classic}} s-t cut problem and prove the following improved hardness results assuming the Unique Games Conjecture (UGC). - For any constant k ≥ 2 and ϵ > 0, we show that Directed Multicut with k source-sink pairs is hard to approximate within a factor k - ϵ. This matches the trivial k-approximation algorithm. By a simple reduction, our result for k = 2 implies that Directed Multiway Cut with two terminals (also known as s-t Bicut) is hard to approximate within a factor 2 - ϵ, matching the trivial 2 -approximation algorithm. Previously, the best <b>hardness</b> <b>factor</b> for these problems (for constant k) was 1. 5 - ϵ under the UGC. - For Length-Bounded Cut and Shortest Path Interdiction, we show that both problems are hard to approximate within any constant factor, even if we allow bicriteria approximation. If we want to cut vertices or the graph is directed, our <b>hardness</b> <b>factor</b> for Length-Bounded Cut matches the best approximation ratio up to a constant. Previously, the best <b>hardness</b> <b>factor</b> was 1. 1377 for Length-Bounded Cut and 2 for Shortest Path Interdiction. - Assuming {{a variant of the}} UGC (implied by another variant of Bansal and Khot), we prove {{that it is hard to}} approximate Resource Minimization Fire Containment within any constant factor. Previously, the best <b>hardness</b> <b>factor</b> was 2. Our results are based on a general method of converting an integrality gap instance to a length-control dictatorship test for {{variants of}} the s-t cut problem, which may be useful for other problems. Comment: 24 page...|$|E
40|$|We {{estimate}} the <b>hardness</b> <b>factors</b> and the equivalent 1 MeV neutron fluences for hadrons fluences expected at the GaAs positions wheels in the ATLAS Inner Detector. On this basis {{the degradation of}} the GaAs particle detectors made from different substrates {{as a function of}} years LHC operation is predicted. ...|$|R
40|$|AbstractThe Steiner tree {{problem on}} {{weighted}} graphs seeks a minimum weight subtree containing a given {{subset of the}} vertices (terminals). We show that it is NP-hard to approximate the Steiner tree problem within a factor 96 / 95. Our inapproximability results are stated in a parametric way, and explicit <b>hardness</b> <b>factors</b> would be improved automatically by providing gadgets and/or expanders with better parameters...|$|R
40|$|International audienceThe {{hardness}} of {{a material}} is generally {{affected by the}} indentation size effect. The strain gradient plasticity (SGP) theory is largely used to study this load dependence because it links the hardness to the intrinsic properties of the material. However, the characteristic scale-length {{is linked to the}} macrohardness, impeding any sound discussion. To find a relevant parameter, we suggest introducing a <b>hardness</b> length-scale <b>factor</b> that only depends on the shear modulus and the Burgers vector of the material and is easily calculable from the relation of the SGP theory. The variation of the <b>hardness</b> length-scale <b>factor</b> is thereafter used to discuss the hardness behavior of a magnetite crystal, the objective being to study the effect of the cumulative plasticity resulting from cyclic indentation. As a main result, the <b>hardness</b> length-scale <b>factor</b> is found to be constant by applying repeated cycles at a constant peak load whereas the macrohardness and the characteristic scale-length are both cycle dependent. When using incremental loads, the <b>hardness</b> length-scale <b>factor</b> monotonically decreases between two limits corresponding to those obtained at high and low loading rates, while the dwell-load duration increases. The physical meaning of such behavior is based on the modification of the dislocation network during the indentation process depending on the deformation rate...|$|R
40|$|We {{prove that}} various {{geometric}} covering problems, {{related to the}} Travelling Salesman Problem cannot be e#ciently approximated to within any constant factor unless P = NP. This includes the Group-Travelling Salesman Problem (TSP with Neighborhoods) in the Euclidean plane, the GroupSteiner -Tree in the Euclidean plane and the Minimum Watchman Tour and the Minimum Watchman Path in 3 -D. It resolves three open problems presented in the comprehensive survey of Mitchell [Mit 00], improves a previously known approximation <b>hardness</b> <b>factor</b> of [GL 00, dBGK 02] for the first problem, {{and it is the}} first approximation <b>hardness</b> <b>factor</b> for the other problems. Some inapproximability factors are also shown for special cases of the above problems, where the size of the sets is bounded. Group-TSP and Group-Steiner-Tree where each neighbourhood is connected are also considered...|$|E
40|$|Abstract. We prove an {{improved}} hardness of approximation result for two problems, namely, {{the problem of}} finding {{the size of the}} largest clique in a graph and the problem of finding the chromatic number of a graph. We show that for any constant γ> 0, there is no polynomial time algo-(log n) 3 / 4 +γ rithm that approximates these problems within factor n/ 2 in (log n) O(1) an n vertex graph, assuming NP � BPTIME(2). This improves (log n) 1 −γ′ the <b>hardness</b> <b>factor</b> of n/ 2 for some small (unspecified) con-stant γ ′> 0 shown by Khot [20]. Our main idea is to show {{an improved}} hardness result for the Min- 3 Lin-Deletion problem. An instance of Min- 3 Lin-Deletion is a system of linear equations modulo 2, where each equation is over three variables. The objective is to find the minimum number of equations that need to be deleted so that the remaining system of equations has a satisfying assignment. We show a <b>hardness</b> <b>factor</b> of 2 Ω(√ log n) for this problem, improving upon the <b>hardness</b> <b>factor</b> of (log n) β shown by H˚astad [18], for some small (unspecified) constant β> 0. The hardness results for clique and chromatic number are then obtained using the reduction from Min- 3 Lin-Deletion as given in [20]. ...|$|E
40|$|International audienceWe {{show that}} unless NP⊆RTIME(2 poly(logn)), {{there is no}} polynomial-time {{algorithm}} approximating the Shortest Vector Problem (SVP) on n-dimensional lattices in the ℓp norm (1 ≤p 0. This improves the previous best factor of 2 (logn) 1 / 2 −ε under the same complexity assumption due to Khot (J. ACM, 2005). Under the stronger assumption NP⊈RSUBEXP, we obtain a <b>hardness</b> <b>factor</b> of nc/loglogn for some c> 0. Our proof starts with Khot's SVP instances {{that are hard to}} approximate to within some constant. To boost the <b>hardness</b> <b>factor</b> we simply apply the standard tensor product of lattices. The main novel part is in the analysis, where we show that the lattices of Khot behave nicely under tensorization. At the heart of the analysis is a certain matrix inequality which was first used in the context of lattices by de Shalit and Parzanchevski...|$|E
50|$|Lattice-based {{cryptographic}} constructions are {{the leading}} candidates for public-key post-quantum cryptography. Indeed, the main alternatives to lattice-based cryptography are schemes based on the <b>hardness</b> <b>factoring</b> and related problems and schemes based on the hardness of the discrete logarithm and related problems. However, both factoring and the discrete logarithm {{are known to be}} solvable in polynomial time on a quantum computer. Furthermore, algorithms for factorization tend to yield algorithms for discrete logarithm, and vice versa. This further motivates the study of constructions based on alternative assumptions, such as the hardness of lattice problems.|$|R
30|$|In the pre-monsoon session, the <b>{{hardness}}</b> <b>factors</b> like calcium, magnesium, {{total hardness}} are clubbed with TDS and conductivity. Fluoride is clustered with the alkaline parameters such as pH, carbonate, bicarbonate and total alkalinity. Sulfate and phosphate form another distinct cluster in the pre-monsoon session demonstrating the factor of anthropogenic contamination of groundwater. In form of larger clusters three major ones {{can be observed}} from top—comprising of four (SO 4 2 −, K+, Na+, PO 4 3 −), seven (Ca 2 +, TH, Cl−, Fe 2 +, TDS, EC, Mg 2 +) and five parameters (F−, CO 3 2 −, pH, HCO 3 −, TA).|$|R
40|$|Abstract. Model atmospheres of {{isolated}} neutron stars with low magnetic field are calculated with Compton scattering taking into account. Models with effective temperatures 1, 3 and 5 MK, with two values of surface gravity (log g = 13. 9 and 14. 3), and different chemical compositions are calculated. Radiation spectra computed with Compton scattering are softer than the computed with Thomson scattering at high energies (E> 5 keV) for hot (Teff> 1 MK) atmospheres with hydrogen-helium composition. Compton scattering is more significant to hydrogen models with low surface gravity. The emergent spectra {{of the hottest}} (Teff> 3 MK) model atmospheres can be described by diluted blackbody spectra with <b>hardness</b> <b>factors</b> ∼ 1. 6 - 1. 9. Compton scattering is less important for models with solar abundance of heavy elements. 1...|$|R
40|$|We {{show that}} the MULTICUT, SPARSEST-CUT and MIN- 2 CNF £ DELETION {{problems}} are hard to approximate, assuming the Unique Games Conjecture of Khot [Kho 02]. In particular, we obtain an arbitrarily large constant factor hardness for these problems, and show that a quantitatively stronger version of the conjecture implies a <b>hardness</b> <b>factor</b> of ¤¦¥¨§�©���§�©����� �. ...|$|E
40|$|Abstract: We {{show that}} unless NP ⊆ RTIME(2 poly(logn)), {{there is no}} polynomial-time {{algorithm}} approximating the Shortest Vector Problem (SVP) on n-dimensional lattices in the ℓp norm (1 ≤ p 0. This improves the previous best factor of 2 (logn) 1 / 2 −ε under the same complexity assumption due to Khot (J. ACM, 2005). Under the stronger assumption NP � RSUBEXP, we obtain a <b>hardness</b> <b>factor</b> of nc/loglogn for some c> 0. Our proof starts with Khot’s SVP instances {{that are hard to}} approximate to within some constant. To boost the <b>hardness</b> <b>factor</b> we simply apply the standard tensor product of lattices. The main novelty is in the analysis, where we show that the lattices of Khot behave nicely under tensorization. At the heart of the analysis is a certain matrix inequality which was first used in the context of lattices by de Shalit and Parzanchevski (2006) ...|$|E
40|$|We {{prove that}} for an {{arbitrarily}} small constant > 0, assuming NP⊆DTIME(2 ^^O(1 /) n), the preprocessing {{versions of the}} closest vector problem and the nearest codeword problem are hard to approximate within a factor better than 2 ^ ^ 1 -n. This improves upon the previous <b>hardness</b> <b>factor</b> of (n) ^δ for some δ > 0 due to AKKV 05...|$|E
40|$|A {{question}} "what {{causes the}} taste {{difference between the}} water I drink?" came to my mind during the planning stage of this test? I had four different water to figure out this. I thought about reasons for the difference between this water, what kind of metal-based softening was made when softening water <b>hardness,</b> <b>factors</b> they were dependent on and how they changed or did not change. I wanted to investigate what was the water hardness of the samples used and to which hardness standard these samples conform by using the EDTA (Ethylene Diamine Tetra Acetic Acid) method and by determining the calcium and magnesium amounts and total hardness ratios. In addition, I decided to investigate reflection of these metal ions on pH. Water {{is the most important}} compound which is necessary for the existence and survival of mankind. About 4 / 3, in other words, 80...|$|R
30|$|The major {{variation}} {{observed in}} clustering patterns of both sessions is mainly related to fluoride. In post-monsoon session, fluoride contamination {{seems to be}} regulated by iron concentration and pH of groundwater whereas in pre-monsoon fluoride contamination in groundwater seems to be regulated primarily by the alkaline factors. Iron in the pre-monsoon session groups with <b>hardness</b> <b>factors.</b> Lateritic soil and clay soils dominate parts {{of the present study}} area as depicted in the geological map. Hence localized presence of iron in excess amounts in groundwater has been observed both during post and pre-monsoon sessions. Being a divalent ion, Fe 2 + also has potential to contribute to total hardness of water. Such a pattern is observed in the study area during pre-monsoon session, when iron shares a strong correlation with total hardness and calcium which is reflected in the pre-monsoon dendrogram as well, where iron is clustered with parameters defining the hardness character of groundwater.|$|R
40|$|In {{this paper}} we {{address the problem of}} {{constructing}} commitment schemes where the sender is bounded to polynomial time and the receiver may be all powerful. Many known constructions for such commitment schemes are based on the <b>hardness</b> of <b>factoring</b> large integers. However, these schemes typically use integers of a special form and thus require a rather expensive initialization procedure for establishing these special-form integers. In this paper we present a scheme which is based on the <b>hardness</b> of <b>factoring</b> large integers but avoids the need of a complex initialization procedure. Key words: Blum-Integers, Commitment Schemes, Factoring, Permutation Pairs. 1 Introduction In this {{paper we address}} the problem of constructing commitment schemes for (possibly long) messages. A commitment scheme is a protocol by which one party (called the Sender) can deliver a message to another party (called the Receiver) without revealing the contents of this message, and while being committed to this m [...] ...|$|R
40|$|Abstract. The {{hardening}} {{behavior of}} the welding heat affected zone (HAZ) with different heat input for 500 MPa grade screw thread steel is investigated in this paper. The single welding thermal cycle {{was applied to the}} test steel by a Gleeble- 3500 thermal simulator. With the definition of hardness ratio, relative <b>hardness</b> <b>factor</b> and partial hardness zone, the HAZ Max hardness, hardness distribution and hardness mechanism of steel were analyzed. The results show that the HAZ hardness is always higher than the base steel hardness. The hardness ratio is increasing with the heat input decreased. The distribution of relative <b>hardness</b> <b>factor</b> of HAZ can be expressed by the Avrami equation which can describe the distribution of HAZ hardness. The width of partial hardness zone increases rapidly with the heat input increased. But at a certain degree of heat input, the width of partial hardness decreases slightly. The microstructure generated by heat input is the intrinsic factor of the HAZ hardness variation. The HAZ hardness enhances as the martensite content increases. On the contrary the HAZ hardness reduces as the ferrite content enhance on condition the heat input increase or the observed area is far away from the HAZ...|$|E
40|$|We {{consider}} the Minimum Linear Arrangement {{problem and the}} (Uniform) Sparsest Cut problem. So far, these two notorious NP-hard graph problems have resisted all attempts to prove inapproximability results. We show {{that they have no}} polynomial time approximation scheme, unless NP-complete problems can be solved in randomized subexponential time. Furthermore, we show that the same techniques can be used for the Maximum Edge Biclique problem, for which we obtain a <b>hardness</b> <b>factor</b> similar to previous results but under a more standard assumption...|$|E
40|$|Abstract. We prove an {{improved}} hardness of approximation result for two problems, namely, {{the problem of}} finding {{the size of the}} largest clique in a graph and the problem of finding the chromatic number of a graph. We show that for any constant fl> 0, there is no polynomial time algorithm that approximates these problems within factor n/ 2 (log n) 3 / 4 +fl in an n vertex graph, assuming NP * BPTIME(2 (log n) O(1)). This improves the <b>hardness</b> <b>factor</b> of n/ 2 (log n...|$|E
40|$|Model atmospheres of {{isolated}} neutron stars with low magnetic field are calculated with Compton scattering taking into account. Models with effective temperatures 1, 3 and 5 MK, with two values of surface gravity log(g) g = 13. 9 and 14. 3), and different chemical compositions are calculated. Radiation spectra computed with Compton scattering are softer than the computed with Thomson scattering at high energies (E > 5 keV) for hot (T_eff > 1 MK) atmospheres with hydrogen-helium composition. Compton scattering is more significant to hydrogen models with low surface gravity. The emergent spectra {{of the hottest}} (T_eff > 3 MK) model atmospheres can be described by diluted blackbody spectra with <b>hardness</b> <b>factors</b> ~ 1. 6 - 1. 9. Compton scattering is less important for models with solar abundance of heavy elements. Comment: Proceedings of the 363. WE-Heraeus Seminar on: Neutron Stars and Pulsars (Posters and contributed talks) Physikzentrum Bad Honnef, Germany, May. 14 - 19, 2006, eds. W. Becker, H. H. Huang, MPE Report 291, pp. 173 - 17...|$|R
40|$|International audienceA {{methodology}} {{for determining the}} thin film hardness from a microindentation loading curve is proposed. The loading curve is modelled to compute the dynamic Martens hardness using the indentation depth reached during the test. Moreover, the indentation size effect is taken into account by applying the strain gradient plasticity theory. Then, the dynamic Martens hardness and the <b>hardness</b> length-scale <b>factor</b> are used to express the applied load {{as a function of}} the indentation depth. The proposed model involves three parameters: (i) the dynamic Martens macro-hardness, equivalent to the hardness obtained for an infinite applied load, (ii) the <b>hardness</b> length-scale <b>factor,</b> which represents the material resistance to plastic deformation under indentation and (iii) a corrective load, considering the rounded tip effect of the indenter and the zero shift. The model is validated on a 316 L stainless steel which subsequently is used as a substrate material for two different Diamond Like-Carbon thin films. The coated systems involved both a hydrogen-free mostly amorphous carbon–chromium (a-C) film of not, vert, similar 2. 6 μm in thickness and a hydrogenated, amorphous carbon (a-C:H) solid lubricant of not, vert, similar 2 μm...|$|R
40|$|AbstractThe general {{asymmetric}} TSP with {{triangle inequality}} {{is known to}} be approximable only within logarithmic factors. In this paper we study the asymmetric and symmetric TSP problems with bounded metrics, i. e., metrics where the distances are integers between one and some constant upper bound. In this case, the problem {{is known to be}} approximable within a constant factor. We prove that it is NP-hard to approximate the asymmetric TSP with distances one and two within 321 / 320 −ε and that it is NP-hard to approximate the symmetric TSP with distances one and two within 741 / 740 −ε for every constant ε> 0. Recently, Papadimitriou and Vempala announced improved approximation hardness results for both symmetric and asymmetric TSP with graph metric. We show that a similar construction can be used to obtain only slightly weaker approximation hardness results for TSP with triangle inequality and distances that are integers between one and eight. This shows that the Papadimitriou–Vempala construction is “local” in nature and, intuitively, indicates that it cannot be used to obtain <b>hardness</b> <b>factors</b> that grow with the size of the instance...|$|R
40|$|An {{instance}} of the 2 -Lin(2) problem is a system of equations of the form "x_i + x_j = b (mod 2) ". Given such {{a system in which}} it 2 ̆ 7 s possible to satisfy all but an epsilon fraction of the equations, we show it is NP-hard to satisfy all but a C*epsilon fraction of the equations, for any C < 11 / 8 = 1. 375 (and any 0 < epsilon <= 1 / 8). The previous best result, standing for over 15 years, had 5 / 4 in place of 11 / 8. Our result provides the best known NP-hardness even for the Unique Games problem, and it also holds for the special case of Max-Cut. The precise factor 11 / 8 is unlikely to be best possible; we also give a conjecture concerning analysis of Boolean functions which, if true, would yield a larger <b>hardness</b> <b>factor</b> of 3 / 2. Our proof is by a modified gadget reduction from a pairwise-independent predicate. We also show an inherent limitation to this type of gadget reduction. In particular, any such reduction can never establish a <b>hardness</b> <b>factor</b> C greater than 2. 54. Previously, no such limitation on gadget reductions was known...|$|E
40|$|Energy-constrained &nbsp;computing environments are&nbsp;emerging those years, {{especially}} in embedding computing. A&nbsp;game theoretic &nbsp;energy-aware scheduling algorithm for multi-core systems is proposed in this paper, namely, GTFTES&nbsp;(Generalized Tit-For-Tat Energy-aware Scheduling). GTFTES&nbsp;is {{designed to work}} in a resource-rich environment where&nbsp;resources always compete for tasks. A generalized Tit-for-Tat&nbsp;based method, where whether a core will &nbsp;cooperate &nbsp;or not is&nbsp;decided by a <b>hardness</b> <b>factor,</b> is considered in this paper. The&nbsp;algorithm is implemented in our EASS simulator. Simulations&nbsp;results show that the proposed game can reduce the&nbsp;temperature difference between different &nbsp;groups &nbsp;of cores&nbsp;which effectively avoids the local hotspot of a processor. &nbsp...|$|E
40|$|Silicon diodes {{processed}} by CNM on standard and oxygenated silicon substrates have been irradiated by 58 MeV lithium ions. The radiation-induced effects {{are very similar}} to the one observed after proton irradiation: substrate space charge sign inversion (SCSI), lower increase of the effective substrate doping concentration after SCSI for the oxygenated devices. The experimental radiation <b>hardness</b> <b>factor</b> has been determined to be 45. 01, within 8. 2 % with the expected value. These results suggest that 58 MeV Li ions are a suitable radiation source for radiation hardness studies by ions heavier than protons for the future very high luminosity hadron colliders...|$|E
40|$|Abstract: Consider a {{game where}} Alice generates an integer and Bob wins {{if he can}} factor that integer. Traditional game theory tells us that Bob will always win this game even though in {{practice}} Alice will win given our usual assumptions about the <b>hardness</b> of <b>factoring.</b> We define a new notion of bounded rationality, where the payoffs of players are discounted by the computation time they take to produce their actions. We use this notion to give a direct correspondence between the existence of equilibria where Alice has a winning strategy and the <b>hardness</b> of <b>factoring.</b> Namely, under a natural assumption on the discount rates, there is an equilibrium where Alice has a winning strategy iff there is a linear-time samplable distribution with respect to which Factoring is hard on average. We also give general results for discounted games over countable action spaces, including showing that any game with bounded and computable payoffs has an equilibrium in our model, even if each player is allowed a countable number of actions. It follows, for example, that the Largest Integer game has an equilibrium in our model though it has no Nash equilibria or ǫ-Nash equilibria...|$|R
40|$|Silicon {{particle}} detectors will be {{used extensively}} in experiments at the CERN Large Hadron Collider, where unprecedented particle fluences will cause significant atomic displacement damage. We present {{a model of the}} evolution of defect concentrations and consequent electrical behaviour in "novel" detector materials with various oxygen and carbon impurity concentrations. The divacancy-oxygen (V/sub 2 /O) defect is identified as the cause of changes in device characteristics during /sup 60 /Co gamma irradiation. In the case of hadron irradiation changes in detector doping concentration (N/sub eff/) are dominated by cluster defects, in particular the divacancy (V/sub 2 /), which exchange charge directly via a non-Shockley-Read- Hall mechanism. The V/sub 2 /O defect also contributes to Ne/sub eff/. This defect is more copiously produced during 24 GeV/c proton irradiation than during 1 MeV neutron irradiation on account of the higher vacancy introduction rate, hence the radiation hardness of materials is more sensitive to impurity concentrations in the case of protons than neutrons. We conclude that naive normalisation of N/sub eff/ data using <b>hardness</b> <b>factors</b> of radiation sources can be misleading, because point defect introduction rates do not necessarily scale with non-ionising energy loss. (22 refs) ...|$|R
40|$|The {{security}} {{of the most popular}} asymmetric cryptographic scheme RSA depends on the <b>hardness</b> of <b>factoring</b> large numbers. The best known method for factorization large integers is the General Number Field Sieve (GNFS). One important step within the GNFS is the factorization of midsize numbers for smoothness testing, an efficient algorithm for which is the Elliptic Curve Method (ECM). We present an efficient hardware implementation of ECM to factor numbers up to 200 bits, which is also scalable to other bit lengths. 1...|$|R
40|$|We {{show that}} unless NP ⊆ RTIME(2 poly(log n)), for any ε> 0 {{there is no}} polynomial-time {{algorithm}} approximating the Shortest Vector Problem (SVP) on n-dimensional lattices in the ℓp norm (1 ≤ p 0. Our proof starts with SVP instances from [18] {{that are hard to}} approximate to within some constant. To boost the <b>hardness</b> <b>factor</b> we simply apply the standard tensor product of lattices. The main novel part is in the analysis, where we show that the lattices of [18] behave nicely under tensorization. At the heart of the analysis is a certain matrix inequality which was first used in the context of lattices by de Shalit and Parzanchevski [12]. ...|$|E
40|$|Abstract: Text-To-Visual speech (TTVS) {{synthesis}} {{by computer}} {{can increase the}} speech intelligibility and make the human-computer interaction interfaces more friendly. This paper describes a Chinese text-to-visual speech synthesis system based on data-driven (sample based) approach, which is realized by short video segments concatenation. An effective method to construct two visual confusion trees for Chinese initials and finals is developed. A co-articulation model based on visual distance and <b>hardness</b> <b>factor</b> is proposed, {{which can be used}} in the recording corpus sentence selection in analysis phase and the unit selection in synthesis phase. The obvious difference between boundary images of the concatenation video segments is smoothed by image morphing technique. By combining with the acoustic Text-To-Speech (TTS) synthesis, a Chinese text-to-visual speech synthesis system is realized...|$|E
40|$|We {{study the}} {{relationship}} between the approximation factor for the Set-Cover problem and the parameters Δ : the maximum cardinality of any subset, and k : the maximum number of subsets containing any element of the ground set. We show an LP rounding based approximation of (k− 1) (1 −e−lnΔk− 1) + 1, which is substantially better than the classical algorithms in the range k[*]≈[*]ln Δ, and also improves on related previous works [19, 22]. For the interesting case when k[*]=[*]θ(logΔ) we also exhibit an integrality gap which essentially matches our approximation algorithm. We also prove a hardness of approximation factor of Ω(logΔ(loglogΔ) 2) when k[*]=[*]θ(logΔ). This is the first study of the <b>hardness</b> <b>factor</b> specifically for this range of k and Δ, and improves on the only other such result implicitly proved in [18]...|$|E
40|$|Emergent model {{spectra of}} neutron star atmospheres {{are widely used}} to fit the {{observed}} soft X-ray spectra {{of different types of}} isolated neutron stars. We investigate the effect of Compton scattering on the emergent spectra of hot (T_eff > 10 ^ 6 K) isolated neutron stars with weak magnetic fields. In order to compute model atmospheres in hydrostatic and radiative equilibrium we solve the radiation transfer equation with the Kompaneets operator. We calculate a set of models with effective temperatures in the range 1 - 5 * 10 ^ 6 K, with two values of surface gravity (log g = 13. 9 and 14. 3) and different chemical compositions. Radiation spectra computed with Compton scattering are softer than those computed without Compton scattering at high energies (E > 5 keV) for light elements (H or He) model atmospheres. The Compton effect is more significant in H model atmospheres and models with low surface gravity. The emergent spectra of the hottest (T_eff > 3 * 10 ^ 6 K) model atmospheres can be described by diluted blackbody spectra with <b>hardness</b> <b>factors</b> ~ 1. 6 - 1. 9. Compton scattering is less important in models with solar abundance of heavy elements. Comment: 7 pages, 1 table, 6 figures, Accepted for publication in A&...|$|R
40|$|A carbide {{factor was}} derived {{based upon a}} {{statistical}} analysis which related rolling-element fatigue life to {{the total number of}} residual carbide particles per unit area, median residual carbide size, and percent residual carbide area. An equation was empirically determined which predicts material hardness as a function of temperature. The limiting temperatures of all of the materials studied were dependent on initial room temperature hardness and tempering temperature. An equation was derived combining the effects of material <b>hardness,</b> carbide <b>factor,</b> and bearing temperature to predict rolling-element bearing life...|$|R
40|$|Abstract. We provide constructions for key {{assignment}} {{schemes that}} are provably secure under the factoring assumption {{in the standard}} model. Our first construction is for simple “chain ” hierarchies, and achieves security against key recovery attacks with a tight reduction from the problem of factoring integers of a special form. Our second construction applies for general hierarchies, achieves the stronger notion of key indistinguishability, and has security based on the <b>hardness</b> of <b>factoring</b> Blum integers. We compare our constructions to previous schemes, in terms of security and efficiency...|$|R
