164|1|Public
25|$|Since the minimax {{algorithm}} and its variants are inherently depth-first, a strategy such as <b>iterative</b> <b>deepening</b> is usually {{used in conjunction}} with alpha–beta so that a reasonably good move can be returned even if the algorithm is interrupted before it has finished execution. Another advantage of using <b>iterative</b> <b>deepening</b> is that searches at shallower depths give move-ordering hints, as well as shallow alpha and beta estimates, that both can help produce cutoffs for higher depth searches much earlier than would otherwise be possible.|$|E
2500|$|Normally during alpha–beta, the subtrees are {{temporarily}} {{dominated by}} either a first player advantage (when many first player moves are good, and at each search depth {{the first move}} checked by the first player is adequate, but all second player responses are required {{to try to find}} a refutation), or vice versa. This advantage can switch sides many times during the search if the move ordering is incorrect, each time leading to inefficiency. As the number of positions searched decreases exponentially each move nearer the current position, it is worth spending considerable effort on sorting early moves. An improved sort at any depth will exponentially reduce the total number of positions searched, but sorting all positions at depths near the root node is relatively cheap as there are so few of them. [...] In practice, the move ordering is often determined by the results of earlier, smaller searches, such as through <b>iterative</b> <b>deepening.</b>|$|E
5000|$|<b>Iterative</b> <b>deepening</b> A* is a {{best-first search}} that {{performs}} <b>iterative</b> <b>deepening</b> based on [...] ""-values {{similar to the}} ones computed in the A* algorithm.|$|E
5000|$|In an <b>iterative</b> <b>deepening</b> search, the nodes {{at depth}} [...] are {{expanded}} once, those at depth [...] are expanded twice, {{and so on}} up to the root of the search tree, which isexpanded [...] times. So the total number of expansions in an <b>iterative</b> <b>deepening</b> search is ...|$|E
5000|$|The {{higher the}} {{branching}} factor, {{the lower the}} overhead of repeatedly expanded states, but even when the branching factor is 2, <b>iterative</b> <b>deepening</b> search only takes about {{twice as long as}} a complete breadth-first search. This means that the time complexity of <b>iterative</b> <b>deepening</b> is still [...]|$|E
50|$|Similar to <b>iterative</b> <b>deepening</b> is {{a search}} {{strategy}} called iterative lengthening search {{that works with}} increasing path-cost limits instead of depth-limits. It expands nodes {{in the order of}} increasing path cost; therefore the first goal it encounters is the one with the cheapest path cost. But iterative lengthening incurs substantial overhead that makes it less useful than <b>iterative</b> <b>deepening.</b>|$|E
50|$|<b>Iterative</b> <b>deepening</b> is one {{technique}} {{to avoid this}} infinite loop and would reach all nodes.|$|E
5000|$|... (Note that <b>iterative</b> <b>deepening</b> has {{now seen}} C, when a {{conventional}} depth-first search did not.) ...|$|E
5000|$|Searching: Alpha-Beta Nega-Max Principal Variation search, <b>Iterative</b> <b>Deepening,</b> Null-move Forward Pruning, Static Exchange Evaluation (SEE).|$|E
5000|$|In essence, fringe {{search is}} {{a middle ground}} between A* and the <b>iterative</b> <b>deepening</b> A* variant (IDA*).|$|E
5000|$|<b>Iterative</b> <b>deepening</b> {{prevents}} this {{loop and}} {{will reach the}} following nodes on the following depths, assuming it proceeds left-to-right as above: ...|$|E
50|$|<b>Iterative</b> <b>deepening</b> A* (IDA*) is a graph {{traversal}} and path search algorithm {{that can}} find the shortest path between a designated start node and any {{member of a set}} of goal nodes in a weighted graph. It is a variant of <b>iterative</b> <b>deepening</b> depth-first search that borrows the idea to use a heuristic function to evaluate the remaining cost to get to the goal from the A* search algorithm. Since it is a depth-first search algorithm, its memory usage is lower than in A*, but unlike ordinary <b>iterative</b> <b>deepening</b> search, it concentrates on exploring the most promising nodes and thus does not go to the same depth everywhere in the search tree. Unlike A*, IDA* does not utilize dynamic programming and therefore often ends up exploring the same nodes many times.|$|E
50|$|Since the minimax {{algorithm}} and its variants are inherently depth-first, a strategy such as <b>iterative</b> <b>deepening</b> is usually {{used in conjunction}} with alpha-beta so that a reasonably good move can be returned even if the algorithm is interrupted before it has finished execution. Another advantage of using <b>iterative</b> <b>deepening</b> is that searches at shallower depths give move-ordering hints, as well as shallow alpha and beta estimates, that both can help produce cutoffs for higher depth searches much earlier than would otherwise be possible.|$|E
50|$|In general, <b>iterative</b> <b>deepening</b> is the {{preferred}} search method {{when there is a}} large search space and the depth of the solution is not known.|$|E
50|$|In {{computer}} science, <b>iterative</b> <b>deepening</b> search or {{more specifically}} <b>iterative</b> <b>deepening</b> depth-first search (IDS or IDDFS) {{is a state}} space/graph search strategy in which a depth-limited version of depth-first search is run repeatedly with increasing depth limits until the goal is found. IDDFS is equivalent to breadth-first search, but uses much less memory; on each iteration, it visits the nodes in the search tree {{in the same order}} as depth-first search, but the cumulative order in which nodes are first visited is effectively breadth-first.|$|E
5000|$|All together, an <b>iterative</b> <b>deepening</b> search from depth [...] all the {{way down}} to depth [...] expands only about [...] more nodes than a single breadth-first or depth-limited search to depth , when [...]|$|E
5000|$|Since [...] or [...] is a {{constant}} independent of [...] (the depth), if [...] (i.e., if the branching factor is greater than 1), the running time of the depth-first <b>iterative</b> <b>deepening</b> search is [...]|$|E
50|$|Since <b>iterative</b> <b>deepening</b> visits states {{multiple}} times, it {{may seem}} wasteful, {{but it turns out}} to be not so costly, since in a tree most of the nodes are in the bottom level, so it does not matter much if the upper levels are visited multiple times.|$|E
50|$|Fruit {{uses the}} {{classical}} Negascout (principal variation search) algorithm with <b>iterative</b> <b>deepening</b> to traverse the game tree. It also uses the null-move heuristic. The original version used a simplistic evaluation function with a robust search. Later versions have improved evaluation functions.The board representation is distinct — Fruit uses a 16x16 board.|$|E
50|$|If {{you have}} only one (or a few) queries to make, {{it may be more}} {{efficient}} to forgo the use of more complex data structures and compute the reachability of the desired pair directly. This can be accomplished in linear time using algorithms such as breadth first search or <b>iterative</b> <b>deepening</b> depth-first search.|$|E
5000|$|While the {{standard}} <b>iterative</b> <b>deepening</b> depth-first search uses search depth as the cutoff for each iteration, the IDA* uses the more informative , where [...] {{is the cost}} to travel from the root to node [...] and [...] is a problem-specific heuristic estimate of the cost to travel from [...] to the solution.|$|E
50|$|Also, {{listed below}} is {{pseudocode}} {{for a simple}} queue based level order traversal, and will require space proportional to {{the maximum number of}} nodes at a given depth. This can be as much as the total number of nodes / 2. A more space-efficient approach for this type of traversal can be implemented using an <b>iterative</b> <b>deepening</b> depth-first search.|$|E
5000|$|Bounded model {{checking}} algorithms unroll the FSM for a fixed {{number of}} steps [...] and check whether a property violation can occur in [...] or fewer steps. This typically involves encoding the restricted model as an instance of SAT. The process can be repeated with larger and larger values of [...] until all possible violations have been ruled out (cf. <b>Iterative</b> <b>deepening</b> depth-first search).|$|E
50|$|Unlike linked lists, {{one-dimensional}} arrays {{and other}} linear data structures, which are canonically traversed in linear order, trees may be traversed in multiple ways. They may be traversed in depth-first or breadth-first order. There are three common ways to traverse them in depth-first order: in-order, pre-order and post-order. Beyond these basic traversals, various more complex or hybrid schemes are possible, such as depth-limited searches like <b>iterative</b> <b>deepening</b> depth-first search.|$|E
5000|$|The AST is {{represented}} using Prolog terms {{and can be}} used to apply optimizations, to compile such expressions to machine-code, or to directly interpret such statements. As is typical for the relational nature of predicates, these definitions can be used both to parse and generate sentences, and also to check whether a given tree corresponds to a given list of tokens. Using <b>iterative</b> <b>deepening</b> for fair enumeration, each arbitrary but fixed sentence and its corresponding AST will be generated eventually: ...|$|E
50|$|Due to {{the absence}} of side effects, a {{functional}} logic program can be executed with different strategies. To evaluate expressions, Curry uses a variant of the needed narrowing strategy which combines lazy evaluation with non-deterministic search strategies. In contrast to Prolog, which uses backtracking to search for solutions, Curry does not fix a particular search strategy. Hence, there are implementations of Curry, like KiCS2, where the user can easily select a search strategy, like depth-first search (backtracking), breadth-first search, <b>iterative</b> <b>deepening,</b> or parallel search.|$|E
50|$|Given {{a random}} cube C, it is solved as <b>iterative</b> <b>deepening.</b> First all cubes are {{generated}} {{that are the}} result of applying 1 move to them. That is C * F, C * U, … Next, from this list, all cubes are generated that {{are the result of}} applying two moves. Then three moves and so on. If at any point a cube is found that needs too many moves based on the upper bounds to still be optimal it can be eliminated from the list.|$|E
50|$|The {{hash table}} {{implementing}} the transposition table can have other uses than finding transpositions. In alpha-beta pruning, {{the search is}} fastest (in fact, optimal) when {{the child of a}} node corresponding to the best move is always considered first. Of course {{there is no way of}} knowing the best move, but when <b>iterative</b> <b>deepening</b> is used, the move which was found to be the best in a shallower search is a good approximation. Therefore this move is tried first. For storing the best child of a node, the entry corresponding to that node in the transposition table is used.|$|E
5000|$|... {{function}} MTDF(root, f, d) g := f upperBound := +∞ lowerBound := -∞ while lowerBound < upperBound β := max(g, lowerBound+1) g := AlphaBetaWithMemory(root, β-1, β, d) if g < β then upperBound := g [...] else lowerBound := g return g" [...] f [...] " [...] : {{first guess}} for best value. The best the quicker algorithm converges. Could be 0 for first call." [...] d [...] " [...] : depth to loop for. An <b>iterative</b> <b>deepening</b> depth-first search {{could be done}} by calling MTDF (...) multiple times with incrementing [...] "d" [...] and providing the best previous result in [...] " [...] f [...] ".|$|E
50|$|For {{applications}} of DFS {{in relation to}} specific domains, such as searching for solutions in artificial intelligence or web-crawling, the graph to be traversed is often either too large to visit in its entirety or infinite (DFS may suffer from non-termination). In such cases, search is only performed to a limited depth; due to limited resources, such as memory or disk space, one typically does not use data structures {{to keep track of}} the set of all previously visited vertices. When search is performed to a limited depth, the time is still linear in terms of the number of expanded vertices and edges (although this number is not the same as the size of the entire graph because some vertices may be searched more than once and others not at all) but the space complexity of this variant of DFS is only proportional to the depth limit, and as a result, is much smaller than the space needed for searching to the same depth using breadth-first search. For such applications, DFS also lends itself much better to heuristic methods for choosing a likely-looking branch. When an appropriate depth limit is not known a priori, <b>iterative</b> <b>deepening</b> depth-first search applies DFS repeatedly with a sequence of increasing limits. In the artificial intelligence mode of analysis, with a branching factor greater than one, <b>iterative</b> <b>deepening</b> increases the running time by only a constant factor over the case in which the correct depth limit is known due to the geometric growth of the number of nodes per level.|$|E
5000|$|Ciao {{provides}} a full Prolog system (supporting ISO-Prolog),declarative subsets and extensions of Prolog, functional programming (including lazy evaluation), higher-order (with predicate abstractions), constraint programming, and objects, {{as well as}} feature terms(records), persistence, several control rules (breadth-first search, <b>iterative</b> <b>deepening,</b> ...), concurrency (threads/engines), distributed execution (agents), and parallel execution. Libraries also support WWW programming, sockets, external interfaces (C, Java, TclTk, relational databases, etc.), etc. Ciao is built on a kernel with an extensible modular design whichallows both restricting and extending the language — {{it can be seen}} as a language building language. These restrictions and extensions can be activated separately on each program module so that several extensions can coexist in the same application for different modules.|$|E
50|$|Normally during alpha-beta, the subtrees are {{temporarily}} {{dominated by}} either a first player advantage (when many first player moves are good, and at each search depth {{the first move}} checked by the first player is adequate, but all second player responses are required {{to try to find}} a refutation), or vice versa. This advantage can switch sides many times during the search if the move ordering is incorrect, each time leading to inefficiency. As the number of positions searched decreases exponentially each move nearer the current position, it is worth spending considerable effort on sorting early moves. An improved sort at any depth will exponentially reduce the total number of positions searched, but sorting all positions at depths near the root node is relatively cheap as there are so few of them. In practice, the move ordering is often determined by the results of earlier, smaller searches, such as through <b>iterative</b> <b>deepening.</b>|$|E
50|$|There {{are several}} techniques, which can greatly improve the {{performance}} of search trees {{in terms of both}} speed and memory. Pruning techniques such as alpha-beta pruning, Principal Variation Search, and MTD-f can reduce the effective branching factor without loss of strength. In tactical areas such as life and death, Go is particularly amenable to caching techniques such as transposition tables. These can reduce the amount of repeated effort, especially when combined with an <b>iterative</b> <b>deepening</b> approach. In order to quickly store a full-sized Go board in a transposition table, a hashing technique for mathematically summarizing is generally necessary. Zobrist hashing is very popular in Go programs because it has low collision rates, and can be iteratively updated at each move with just two XORs, rather than being calculated from scratch. Even using these performance-enhancing techniques, full tree searches on a full-sized board are still prohibitively slow. Searches can be sped up by using large amounts of domain specific pruning techniques, such as not considering moves where your opponent is already strong, and selective extensions like always considering moves next to groups of stones which are about to be captured. However, both of these options introduce a significant risk of not considering a vital move which would have changed the course of the game.|$|E
40|$|Plan Quality {{is defined}} as the sum of the costs {{associated}} with all the actions in a plan. This definition is incorporated into the Partial Order planner, UCPOP. For finding the optimal plans efficiently, he standard Best First Search strategy was compared against two versions of <b>Iterative</b> <b>Deepening</b> that were added to the UCPOP planner. Experiments over several problems in an extended version of blocks world domain and logistics domain show that while the first <b>iterative</b> <b>deepening</b> algorithm, based on the Depth First Search (ID-DEPTH-FS) yielded optimal plans with respect to number of actions in them, the second <b>iterative</b> <b>deepening</b> algorithm, based on the best first search (ID-BEST-FS) was both effective and efficient in finding optimal plans with respect to the total cost of all actions in it. Experiments on various ranking functions have shown that for standard Best First Search and its variants and for the the two <b>iterative</b> <b>deepening</b> algorithms added to UCPOP, ranking function based [...] ...|$|E
40|$|AbstractThe {{relationship}} between resolution theorem proving and graph search {{is complicated by}} control statements that affect the program's meaning. An interesting case arises when combining Prolog interpreters implementing the cut and <b>iterative</b> <b>deepening</b> search. Because these features are dependent, an interpreter that naively combines both features gives unintended answers to queries. In particular, negation as failure breaks down. One solution is to use sound negation, but many certain AI problems use both sound negation and negation as failure. As well, when debugging large Prolog programs, {{it is useful to}} be able to execute the same program with and without <b>iterative</b> <b>deepening,</b> even though the program contains cuts. Besides generating unintended answers, the Prolog interpreter naively combining cuts and <b>iterative</b> <b>deepening</b> also generates redundant answers. Here, we show how to avoid both...|$|E
40|$|We {{study the}} {{relationship}} between optimal planning algorithms, {{in the form of}} (<b>iterative</b> <b>deepening)</b> A ∗ with (forward) state-space search, and the reduction of the problem to SAT. Our results establish a strict dominance relation between the two approaches: any <b>iterative</b> <b>deepening</b> A ∗ search can be efficiently simulated in the SAT framework, assuming that the heuristic has been encoded in the SAT problem, but the opposite is not possible as A ∗ and IDA ∗ searches sometimes take exponentially longer. ...|$|E
