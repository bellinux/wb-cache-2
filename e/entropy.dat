10000|2208|Public
5|$|Another {{approach}} ignores {{energy and}} deals {{only with the}} molecular complexity estimated by the information <b>entropy</b> index. It speculates that the points of several natural compounds (urea, pyrimidine, dihydroxyacetone, uracil, cytosine, glycine, and alanine) fall into {{the range of the}} values typical for the known interstellar molecules that indicates high probability of their detection in interstellar environment. Additionally the molecules with maximal information <b>entropy,</b> i.e. the most complex compounds, make up approximately a half of the interstellar set and their percentage is decreased with the size. This trend may be associated with the different stabilities of the molecules with uniform (usually more stable) and diversified (usually less stable) chemical structures, so the detectable molecules with a large size must possess symmetric structure more probably than non-symmetric. The remarkable detection of low-entropy (highly symmetric) fullerene molecules supports this assumption. It is also noted that information <b>entropy</b> reflects the depth of hydrogenation of interstellar entities: the molecules with maximal information <b>entropy</b> are hydrogen-poor whereas the others are mainly hydrogen-rich.|$|E
25|$|Unlike {{many other}} {{functions}} of state, <b>entropy</b> cannot be directly observed {{but must be}} calculated. <b>Entropy</b> can be calculated for a substance as the standard molar <b>entropy</b> from absolute zero (also known as absolute <b>entropy)</b> or as a difference in <b>entropy</b> from some other reference state which is defined as zero <b>entropy.</b> <b>Entropy</b> has the dimension of energy divided by temperature, which has a unit of joules per kelvin (J/K) in the International System of Units. While {{these are the same}} units as heat capacity, the two concepts are distinct. <b>Entropy</b> is not a conserved quantity: for example, in an isolated system with non-uniform temperature, heat might irreversibly flow and the temperature become more uniform such that <b>entropy</b> increases. The second law of thermodynamics states that a closed system has <b>entropy</b> which may increase or otherwise remain constant. Chemical reactions cause changes in <b>entropy</b> and <b>entropy</b> {{plays an important role in}} determining in which direction a chemical reaction spontaneously proceeds.|$|E
25|$|Other {{important}} information theoretic quantities include Rényi <b>entropy</b> (a generalization of <b>entropy),</b> differential <b>entropy</b> (a generalization of quantities {{of information to}} continuous distributions), and the conditional mutual information.|$|E
40|$|Inspired by the {{generalized}} <b>entropies</b> for graphs, {{a class of}} generalized degree-based graph <b>entropies</b> is proposed using the known information-theoretic measures to characterize the structure of complex networks. The new <b>entropies</b> depend on assigning a probability distribution about the degrees to a network. In this paper, some extremal properties of {{the generalized}} degree-based graph <b>entropies</b> by using the degree powers are proved. Moreover, the relationships among the <b>entropies</b> are studied. Finally, numerical results are presented to illustrate {{the features of the}} new <b>entropies...</b>|$|R
40|$|Generalized <b>entropies</b> are {{studied as}} Lyapunov {{functions}} for the Master equation (Markov chains). Three basic properties of these Lyapunov functions {{are taken into}} consideration: universality (independence of the kinetic coefficients), trace-form (the form of sum over the states), and additivity (for composition of independent subsystems). All the <b>entropies,</b> which have all three properties simultaneously and are defined for positive probabilities, are found. They form a one-parametric family. We consider also pairs of <b>entropies</b> $S_{ 1 }$, $S_{ 2 }$, which are connected by the monotonous transformation $S_{ 2 }=F(S_{ 1 }) $ (equivalent <b>entropies).</b> All classes of pairs of universal equivalent <b>entropies,</b> one of which has a trace-form, and another is additive (these <b>entropies</b> can be different one from another), were found. These classes consist of two one-parametric families: the family of <b>entropies,</b> which are equivalent to the additive trace-form <b>entropies,</b> and the family of Renyi-Tsallis <b>entropies.</b> Comment: elsart-LaTeX 2 e, 11 page...|$|R
3000|$|... [...]. The {{position}} and momentum information <b>entropies</b> of D-dimensional quantum systems with central potentials, {{such as the}} isotropic harmonic oscillator and the hydrogen atom, depend on the <b>entropies</b> of the (hyper)spherical harmonics (see [2]). In turn, these <b>entropies</b> are {{expressed in terms of}} the <b>entropies</b> of the Gegenbauer (ultraspherical) polynomials [...]...|$|R
25|$|Tsallis <b>entropy</b> – a {{generalization}} {{of the standard}} Boltzmann–Gibbs <b>entropy.</b>|$|E
25|$|Claude Shannon's {{development}} of Information theory in 1948 {{gave rise to}} the <b>entropy</b> view of randomness. In this view, randomness is the opposite of determinism in a stochastic process. Hence if a stochastic system has <b>entropy</b> zero it has no randomness and any increase in <b>entropy</b> increases randomness. Shannon's formulation defaults to Boltzmann's 19th century formulation of <b>entropy</b> in case all probabilities are equal. <b>Entropy</b> is now widely used in diverse fields of science from thermodynamics to quantum chemistry.|$|E
25|$|So <b>entropy</b> is an {{adiabatic}} invariant. The Nlog(N) term {{makes the}} <b>entropy</b> additive, so the <b>entropy</b> of two volumes of gas {{is the sum}} of the entropies of each one.|$|E
40|$|We {{study the}} Euler {{numbers and the}} <b>entropies</b> of the non-extremal {{intersecting}} D-branes in ten-dimensions. We use the surface gravity to constrain the compactification radii. We correctly obtain the integer valued Euler numbers for these radii. Moreover, the <b>entropies</b> {{are found to be}} invariant under the T-duality transformation. In the extremal limit, we obtain the finite <b>entropies</b> only for two intersecting D-branes. We observe that these <b>entropies</b> are proportional the product of the charges of each D-brane. We further study the <b>entropies</b> of the boosted metrics. We find that their <b>entropies</b> can be interpreted in term of the microscopic states of D-branes...|$|R
40|$|We discuss two {{families}} of two-parameter <b>entropies</b> and divergences, {{derived from the}} standard Rényi and Tsallis <b>entropies</b> and divergences. These divergences and <b>entropies</b> are found as divergences or <b>entropies</b> of escort distributions. Exploiting the nonnegativity of the divergences, we derive {{the expression of the}} canonical distribution associated to the new <b>entropies</b> and a observable given as an escort-mean value. We show that this canonical distribution extends, and smoothly connects, the results obtained in nonextensive thermodynamics for the standard and generalized mean value constraints...|$|R
40|$|The Sharma-Mittal <b>entropies</b> generalize {{the celebrated}} Shannon, Rényi and Tsallis <b>entropies.</b> We report a closed-form formula for the Sharma-Mittal <b>entropies</b> and {{relative}} <b>entropies</b> for arbitrary exponential family distributions. We instantiate explicitly {{the formula for}} {{the case of the}} multivariate Gaussian distributions and discuss on its estimation. Comment: 9 pages, 3 figures; Journal of Physics A: Mathematical and Theoretical, December 2011. IO...|$|R
25|$|Despite similar notation, joint <b>entropy</b> {{should not}} be {{confused}} with cross <b>entropy.</b>|$|E
25|$|The {{statistical}} definition {{was developed}} by Ludwig Boltzmann in the 1870s by analyzing the statistical behavior of the microscopic components of the system. Boltzmann showed that this definition of <b>entropy</b> was equivalent to the thermodynamic <b>entropy</b> to within a constant number which has since been known as Boltzmann's constant. In summary, the thermodynamic definition of <b>entropy</b> provides the experimental definition of <b>entropy,</b> while the statistical definition of <b>entropy</b> extends the concept, providing an explanation and {{a deeper understanding of}} its nature.|$|E
25|$|Although {{the analogy}} between both {{functions}} is suggestive, {{the following question}} must be set: is the differential <b>entropy</b> a valid extension of the Shannon discrete <b>entropy?</b> Differential <b>entropy</b> lacks a number of properties that the Shannon discrete <b>entropy</b> hasnbsp&– it can even be negativenbsp&– and thus corrections have been suggested, notably limiting density of discrete points.|$|E
40|$|We {{present a}} method for {{improving}} measurements of the entanglement Rényi <b>entropies</b> in quantum Monte Carlo simulations by relating them with measurements of participation Rényi <b>entropies.</b> Exploiting the capability of building improved estimators for the latter allows to obtain very good estimates for entanglement Rényi <b>entropies.</b> When considering a full system instead of a bipartition, the method can be further ameliorated providing access to the thermodynamic Rényi <b>entropies</b> with high accuracy. We also explore a recently-proposed method for {{the reconstruction of the}} entanglement spectrum from entanglement Rényi <b>entropies</b> and finally show how potential entanglement Hamiltonians may be tested for their validity using a comparison with thermal Rényi <b>entropies.</b> Comment: 15 pages, 11 figure...|$|R
40|$|We {{study the}} {{generalized}} Rényi <b>entropies</b> which {{were introduced in}} the physics literature. The proper defintion of these <b>entropies</b> needs, in our opinion, further clarification. We show that the Rényi <b>entropies</b> do not contain any new information. On the other hand, we introduce {{the notion of the}} correlation <b>entropies,</b> which are not invariants of the dynamical systems in the measure-theoretic sense, but they are invariant under transformations of the state space with bounded distortion. With these correlation <b>entropies</b> we provide a formal definition which can serve as a basis for the results reported in the physics literature. ...|$|R
40|$|We show an {{interesting}} connexion between the coarse-grained distribution function arising {{in the theory}} of violent relaxation for collisionless stellar systems (Lynden-Bell 1967) and the notion of superstatistics introduced recently by Beck & Cohen (2003). We also discuss the analogies and differences between the statistical equilibrium state of a multi-components self-gravitating system and the metaequilibrium state of a collisionless stellar system. Finally, we stress the important distinction between mixing <b>entropies,</b> generalized <b>entropies,</b> H-functions, generalized mixing <b>entropies</b> and relative <b>entropies...</b>|$|R
25|$|Gibbs <b>entropy</b> – {{the usual}} {{statistical}} mechanical <b>entropy</b> of a thermodynamic system.|$|E
25|$|It {{follows from}} the second law of {{thermodynamics}} that the <b>entropy</b> {{of a system that}} is not isolated may decrease. An air conditioner, for example, may cool the air in a room, thus reducing the <b>entropy</b> of the air of that system. The heat expelled from the room (the system), which the air conditioner transports and discharges to the outside air, always makes a bigger contribution to the <b>entropy</b> of the environment than the decrease of the <b>entropy</b> of the air of that system. Thus, the total of <b>entropy</b> of the room plus the <b>entropy</b> of the environment increases, in agreement with the second law of thermodynamics.|$|E
25|$|Sackur–Tetrode <b>entropy</b> – the <b>entropy</b> of a {{monatomic}} classical {{ideal gas}} determined via quantum considerations.|$|E
40|$|Abstract. In this paper, {{information}} theoretic cryptography {{is discussed}} based on conditional Rényi <b>entropies.</b> Our discussion focuses {{not only on}} cryptography {{but also on the}} definitions of conditional Rényi <b>entropies</b> and the related information theoretic inequalities. First, we revisit conditional Rényi <b>entropies,</b> and clarify what kind of properties are required and actually satisfied. Then, we propose security criteria based on Rényi <b>entropies,</b> which suggests us deep relations between (conditional) Rényi <b>entropies</b> and error probabilities by using several guessing strategies. Based on these results, unified proof of impossibility, namely, the lower bounds of key sizes is derived based on conditional Rényi <b>entropies.</b> Our model and lower bounds include the Shannon’s perfect secrecy, and the minentropy based encryption presented by Dodis, and Alimomeni and Safavi-Naini. Finally, new optimal symmetric key cryptography and almost optimal secret sharing schemes are proposed which achieve our lower bounds...|$|R
40|$|Single-ion {{standard}} <b>entropies,</b> S-ion degrees, are additive {{values for}} {{estimation of the}} room-temperature (298 K) <b>entropies</b> of ionic solids. They {{may be used for}} inferring the <b>entropies</b> of ionic solids for which values are unavailable and for checking reported values, thus complementing the independent method of estimation from molar volumes (termed volume-based thermodynamics). Current single-anion <b>entropies</b> depend on the charge of the countercation, and so are difficult to apply to complex materials, such as minerals. The analysis of reported data here presented provides a self-consistent set of <b>entropies</b> for cations and charge-independent values for anions. Although the S-ion degrees values presented encompass only a limited set of ions, the retrieval of values for ions not listed is straightforward and is described. An unexpected and significant observation is that cation <b>entropies</b> are related to the molar volumes of the corresponding (neutral) condensed-phase metals...|$|R
40|$|Properties which generalize the {{standard}} recursivity of <b>entropies</b> are introduced. In the first section, a certain {{combination of these}} properties is characterized. Next, those sequences with satisfy a symmetry property {{in addition to the}} generalized recursivities are determined. Finally, various regularity conditions are imposed to characterize classes of <b>entropies</b> including the <b>entropies</b> of degree α...|$|R
25|$|To {{find the}} <b>entropy</b> {{difference}} between any two states of a system, the integral must be evaluated for some reversible path between the initial and final states. Since <b>entropy</b> {{is a state}} function, the <b>entropy</b> change of the system for an irreversible path {{is the same as}} for a reversible path between the same two states. However, the <b>entropy</b> change of the surroundings will be different.|$|E
25|$|This is a {{more natural}} form and this {{rescaled}} <b>entropy</b> exactly corresponds to Shannon's subsequent information <b>entropy.</b>|$|E
25|$|Boltzmann <b>entropy</b> – {{a type of}} Gibbs <b>entropy,</b> which neglects {{internal}} statistical correlations in {{the overall}} particle distribution.|$|E
30|$|We give several inequalities on {{generalized}} <b>entropies</b> involving Tsallis <b>entropies,</b> {{using some}} inequalities {{obtained by the}} improvements of Young’s inequality. We also give a generalized Han’s inequality.|$|R
40|$|This paper investigates Rényi's {{generalized}} <b>entropies</b> under linear and nonlinear scale-space evolutions of images. Scale-spaces {{are useful}} computer vision concepts for both scale analysis and image restoration. We regard images as densities and prove monotony and smoothness properties for the generalized <b>entropies.</b> The scale-space extended generalized <b>entropies</b> {{are applied to}} global scale selection and size estimations. Finally, we introduce an entropy-based fingerprint description for textures...|$|R
40|$|Abstract. Information theoretic {{cryptography}} {{is discussed}} based on conditional Renyi en-tropies. Our discussion focuses {{not only on}} cryptography {{but also on the}} denitions of con-ditional Renyi <b>entropies</b> and the related information theoretic inequalities. First, we revisit conditional Renyi <b>entropies,</b> and clarify what kind of properties are required and actually satis ed. Then, we propose security criteria based on Renyi <b>entropies,</b> which suggests us deep relations between (conditional) Renyi <b>entropies</b> and error probabilities by using sev-eral guessing strategies. Based on these results, unied proof of impossibility, namely, the lower bounds of key sizes is derived based on conditional Renyi <b>entropies.</b> Our model and lower bounds include the Shannon's perfect secrecy, and the min-entropy based encryption presented by Dodis, and Alimomeni and Safavi-Naini. Finally, a new optimal symmetric key encryption is proposed which achieve our lower bounds...|$|R
25|$|Joint <b>entropy</b> – is {{the measure}} how much <b>entropy</b> is {{contained}} in a joint system of two random variables.|$|E
25|$|Loop <b>entropy</b> – is the <b>entropy</b> lost upon {{bringing}} together two residues of a polymer within a prescribed distance.|$|E
25|$|Residual <b>entropy</b> – the <b>entropy</b> present after a {{substance}} is cooled arbitrarily close to absolute zero.|$|E
40|$|Scrambling is {{a process}} by which the state of a quantum system is {{effectively}} randomized. Scrambling exhibits different complexities depending on the degree of randomness it produces. For example, the complete randomization of a pure quantum state (Haar scrambling) implies the inability to retrieve information of the initial state by measuring only parts of the system (Page/information scrambling), but the converse is not necessarily the case. Here, we formally relate scrambling complexities to the degree of randomness, by studying the behaviors of generalized entanglement <b>entropies</b> [...] in particular Rényi <b>entropies</b> [...] and their relationship to designs, ensembles of states or unitaries that match the completely random states or unitaries (drawn from the Haar measure) up to certain moments. The main result is that the Rényi-α entanglement <b>entropies,</b> averaged over α-designs, are almost maximal. The result generalizes Page's theorem for the von Neumann <b>entropies</b> of small subsystems of random states. For designs of low orders, the average Rényi entanglement <b>entropies</b> can be non-maximal: we exhibit a projective 2 -design such that all higher order Rényi entanglement <b>entropies</b> are bounded away from the maximum. However, we show that the Rényi entanglement <b>entropies</b> of all orders are almost maximal for state or unitary designs of order logarithmic in the dimension of the system. That is, such designs are indistinguishable from Haar-random by the entanglement spectrum. Our results establish a formal correspondence between generalized <b>entropies</b> and designs of the same order. Comment: 60 page...|$|R
40|$|International audienceWe {{introduce}} quantum correlation measures {{based on}} the minimal change in unified <b>entropies</b> induced by local rank-one projective measurements, divided by a factor {{that depends on the}} generalized purity of the system in the case of nonadditive <b>entropies.</b> In this way, we overcome the issue of the artificial increasing of the value of quantum correlation measures based on nonadditive <b>entropies</b> when an uncorrelated ancilla is appended to the system, without changing the computability of our entropic correlation measures with respect to the previous ones. Moreover, we recover as limiting cases the quantum correlation measures based on von Neumann and Rényi <b>entropies</b> (i. e., additive <b>entropies),</b> for which the adjustment factor becomes trivial. In addition, we distinguish between total and semiquantum correlations and obtain some inequalities between them. Finally, we obtain analytical expressions of the entropic correlation measures for typical quantum bipartite systems...|$|R
40|$|Abstract: Charged Rényi <b>entropies</b> were {{recently}} introduced {{as a measure}} of en-tanglement between different charge sectors of a theory. We investigate the phase structure of charged Rényi <b>entropies</b> for CFTs with a light, charged scalar operator. The charged Rényi <b>entropies</b> are calculated holographically via areas of charged hyper-bolic black holes. These black holes can become unstable to the formation of scalar hair at sufficiently low temperature; this is the holographic superconducting instability in hyperbolic space. This implies that the Rényi <b>entropies</b> can be non-analytic in the Rényi parameter n. We find the onset of this instability {{as a function of the}} charge and dimension of the scalar operator. We also comment on the relation between the phase structure of these <b>entropies</b> and the phase structure of a holographic superconductor in flat space. ArXiv ePrint: 1407. nnnn [hep-th] a...|$|R
