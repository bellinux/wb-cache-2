7|325|Public
5000|$|A device {{included}} in or {{attached to a}} nuclear weapon system to preclude arming and/or launching until the insertion of a prescribed <b>discrete</b> <b>code</b> or combination. It may include equipment and cabling external to the weapon or weapon system to activate components within the weapon or weapon system.|$|E
40|$|This paper {{discusses}} cyberinformation {{studies of}} the chemical elements composition in nature, in particular the identification of scientific terminology that could describe this phenomenon, ie, the study of biochemical information, {{as well as the}} relationship between the digital language of chemical elements and theoretical aspects of this elements and cybernetics. In digital pictures of biochemistry, physical and chemical parameters are in a strict submission to programmed, cyber and information rules. In some examples, chemical elements are connected through the <b>discrete</b> <b>code</b> 931, which is transformed into 3 2...|$|E
40|$|International audienceThe {{synchronous}} language Lustre and its descendants {{have long}} been used to program and model discrete controllers. Recent work shows how to mix discrete and continuous elements in a Lustre-like language called Zélus. The resulting hybrid programs are deterministic and can be simulated with a numerical solver. In this article, we focus on a subset of hybrid programs where continuous behaviors are expressed using timers, nondeterministic guards, and invariants, as in Timed Safety Automata. We propose a source-to-source compilation pass to generate <b>discrete</b> <b>code</b> that, coupled with standard operations on Difference-Bound Matrices, produces symbolic traces that each represent a set of concrete traces...|$|E
40|$|Hashing {{has been}} widely used for {{large-scale}} search due to its low storage cost and fast query speed. By using supervised information, supervised hashing can significantly outperform unsupervised hashing. Recently, discrete supervised hashing and deep hashing are two representative progresses in supervised hashing. On one hand, hashing is essentially a discrete optimization problem. Hence, utilizing supervised information to directly guide <b>discrete</b> (binary) <b>coding</b> procedure can avoid sub-optimal solution and improve the accuracy. On the other hand, deep hashing, which integrates deep feature learning and hash-code learning into an end-to-end architecture, can enhance the feedback between feature learning and hash-code learning. The key in discrete supervised hashing is to adopt supervised information to directly guide the <b>discrete</b> <b>coding</b> procedure in hashing. The key in deep hashing is to adopt the supervised information to directly guide the deep feature learning procedure. However, there have not existed works which can use the supervised information to directly guide both <b>discrete</b> <b>coding</b> procedure and deep feature learning procedure in the same framework. In this paper, we propose a novel deep hashing method, called deep discrete supervised hashing (DDSH), to address this problem. DDSH is the first deep hashing method which can utilize supervised information to directly guide both <b>discrete</b> <b>coding</b> procedure and deep feature learning procedure, and thus enhance the feedback between these two important procedures. Experiments on three real datasets show that DDSH can outperform other state-of-the-art baselines, including both discrete hashing and deep hashing baselines, for image retrieval...|$|R
40|$|Output coding is {{a general}} method for solving multiclass {{problems}} by reducing them to multiple binary classification problems. Previous research on output coding has employed, almost solely, predefined <b>discrete</b> <b>codes.</b> We describe an algorithm that improves the performance of output codes by relaxing them to continuous codes. The relaxation procedure is cast as an optimization problem and {{is reminiscent of the}} quadratic program for support vector machines. We describe experiments with the proposed algorithm, comparing it to standard <b>discrete</b> output <b>codes.</b> The experimental results indicate that continuous relaxations of output codes often improve the generalization performance, especially for short codes. ...|$|R
50|$|Both {{the now-defunct}} HD DVD standard, and Blu-ray Disc include Dolby Digital Plus. It is a {{mandatory}} component of HD DVD and an optional component of Blu-ray. The {{maximum number of}} <b>discrete</b> <b>coded</b> channels {{is the same for}} both formats: 7.1. However, HD DVD and Blu-ray impose different technical constraints on the supported audio-codecs. Hence, the usage of DD+ differs substantially between HD DVD and Blu-ray Disc.|$|R
40|$|Hashing {{has emerged}} as a popular {{technique}} for fast nearest neighbor search in gi-gantic databases. In particular, learning based hashing has received considerable attention due to its appealing storage and search efficiency. However, the perfor-mance of most unsupervised learning based hashing methods deteriorates rapidly as the hash code length increases. We argue that the degraded performance is due to inferior optimization procedures used to achieve discrete binary codes. This paper presents a graph-based unsupervised hashing model to preserve the neigh-borhood structure of massive data in a <b>discrete</b> <b>code</b> space. We cast the graph hashing problem into a discrete optimization framework which directly learns the binary codes. A tractable alternating maximization algorithm is then proposed to explicitly deal with the discrete constraints, yielding high-quality codes to well capture the local neighborhoods. Extensive experiments performed on four large datasets with up to one million samples show that our discrete optimization based graph hashing method obtains superior search accuracy over state-of-the-art un-supervised hashing methods, especially for longer codes. ...|$|E
40|$|Recent {{years have}} {{witnessed}} the promising efficacy and efficiency of hashing (also known as binary code learning) for retrieving nearest neighbor in large-scale data collections. Particularly, with supervision knowledge (e. g., semantic labels), we may further gain considerable performance boost. Nevertheless, most existing supervised hashing schemes suffer from the following limitations: (1) severe quantization error caused by continuous relaxation of binary codes; (2) disturbance of unreliable codes in subsequent hash function learning; and (3) erroneous guidance derived from imprecise and incomplete semantic labels. In this work, we propose a novel supervised hashing approach, termed as Robust <b>Discrete</b> <b>Code</b> Modeling (RDCM), which directly learns high-quality discrete binary codes and hash functions by effectively suppressing the influence of unreliable binary codes and potentially noisily-labeled samples. RDCM employs ℓ norm, which is capable of inducing sample-wise sparsity, to jointly perform code selection and noisy sample identification. Moreover, we preserve the discrete constraint in RDCM to eliminate the quantization error. An efficient algorithm is developed to solve the discrete optimization problem. Extensive experiments conducted on various real-life datasets show {{the superiority of the}} proposed RDCM approach as compared to several state-of-the-art hashing methods...|$|E
40|$|Service Oriented Architectures (SOAs) are {{constantly}} gaining {{ground for the}} provision of business to business as well as user-centric services, mainly in the form of Web Services technology. SOAs enable service providers to design and deploy new,composite service offerings out of existing component services. In order to match end-user expectations with respect to personalization and ease of use, these services should be designed in a manner that allows them to exhibit a certain level of context-awareness which is a basic element towards a richer end-user experience. However, in the majority of such services, context-handling is still tightly coupled with the core functionality of the service, resulting in a design which is difficult to implement and maintain. The paper proposes the decoupling of core service logic from context-related functionality by adopting a Model-driven approach based on {{a modified version of the}} ContextUML metamodel. Core service logic and context handling are treated as separate concerns at the modeling level as well as in the resulting source code where Aspect Oriented Programming (AOP) encapsulates context-dependent behavior in <b>discrete</b> <b>code</b> modules. The design of a restaurant finder service is used to portray the modified ContextUML metamodel and the service modeling process which is covered in full. Respective code snippets belonging to the executable version of the service (part of work in progress) are also provided, illustrating the transition from model to code and the resulting separation of concerns. © 2007 IEEE...|$|E
40|$|The paper {{presents}} a method t o tackle {{the problem of}} designing <b>discrete</b> phase <b>codes</b> for the rejection of delay-Doppler clutter. Signal-to-Interference Ratio (SIR) {{has been used as}} t h e performance criterion and the maximization of SIR, for t h e case of coded rectangular pulse bursts, has been reduced to the minimization of a clutter integral. To solve the associated nonlinear optimization problem an integer programming algorithm has been adopted, using which it has been possible to obtain optimum signals for a variety of clutter distributions. The capability of the algorithm to provide optimum solutions inspite of the large number of local minima, makes it possible to design optimum <b>discrete</b> <b>coded</b> signals to reject arbitrary delay- Doppler clutter with moderate computational efforrs...|$|R
40|$|Parameter Estimation for ODEs and DDEs is an {{important}} topic in numerical analysis. In this paper, we present a novel approach to address this inverse problem. Cross-entropy algorithms are general algorithm which {{can be applied to}} solve global optimization problems. The main steps of cross-entropy methods are first to generate a set of trial samples from a certain distribution, then to update the distribution based on these generated sample trials. To overcome the prohibitive computation of standard cross-entropy algorithms, we develop a modification combining local search techniques. The modified cross-entropy algorithm can speed the convergence rate and improve the accuracy simultaneously. Two different coding schemes (continuous <b>coding</b> and <b>discrete</b> <b>coding)</b> are also introduced. Continuous coding uses a truncated multivariate Gaussian to generate trial samples, while <b>discrete</b> <b>coding</b> reduces the search space to a finite (but dense) subset of the feasible parameter values and uses a Bernoulli distribution to generate the trial samples (which are fixed point approximation of the actual parameters). Extensive numerical and real experiments are conducted to illustrate the power and advantages of the proposed methods. Compared to other existing state-of-the-art approaches o...|$|R
25|$|These two {{approaches}} can each be further {{divided into three}} families of protocols: discrete variable, continuous variable and distributed phase reference <b>coding.</b> <b>Discrete</b> variable protocols {{were the first to}} be invented, and they remain the most widely implemented. The other two families are mainly concerned with overcoming practical limitations of experiments. The two protocols described below both use <b>discrete</b> variable <b>coding.</b>|$|R
40|$|ABRIDGED) We {{present a}} new Schwarzschild orbit-superposition code {{designed}} to model discrete datasets composed of velocities of individual kinematic tracers in a dynamical system. This constitutes {{an extension of}} previous implementations that can only address continuous data {{in the form of}} (the moments of) velocity distributions, thus avoiding potentially important losses of information due to data binning. Furthermore, the code can handle any combination of available velocity components, i. e., only line-of-sight velocities, only proper motions, or a combination of both. It can also handle a combination of discrete and continuous data. The code finds the distribution function (DF, a function of the three integrals of motion E, Lz, and I 3) that best reproduces the available kinematic and photometric observations in a given axisymmetric gravitational potential. The fully numerical approach ensures considerable freedom on the form of the DF f(E,Lz,I 3). This allows a very general modeling of the orbital structure, thus avoiding restrictive assumptions about the degree of (an) isotropy of the orbits. We describe the implementation of the <b>discrete</b> <b>code</b> and present a series of tests of its performance based on the modeling of simulated datasets generated from a known DF. We find that the discrete Schwarzschild code recovers the original orbital structure, M/L ratios, and inclination of the input datasets to satisfactory accuracy, as quantified by various statistics. The code will be valuable, e. g., for modeling stellar motions in Galactic globular clusters, and those of individual stars, planetary nebulae, or globular clusters in nearby galaxies. This can shed new light on the total mass distributions of these systems, with central black holes and dark matter halos being of particular interest. Comment: ApJ, in press; 51 pages, 11 figures; manuscript revised following comments by refere...|$|E
40|$|Calculations {{have been}} {{performed}} on the Maine Yankee Power Plant to obtain three-dimensional neutron fluxes using the spatial synthesis with the two-dimensional <b>discrete</b> ordinates <b>code</b> DORT, the three-dimensional <b>discrete</b> ordinates <b>code</b> THREEDANT and the three-dimensional Monte Carlo code MCNP. Neutron fluxes are compared for energies above 0. 1 MeV and 1. 0 MeV as well as dpa. Results were obtained at the Yankee dosimetry locations and special test regions within the pressure vessel, in the reactor cavity, and in a shield tank detector well...|$|R
40|$|The Computerized Severity Index (CSI) is {{a commercially}} {{available}} scoring system for hospital inpatients. Trained abstractors review the patient's paper medical record {{and enter the}} diagnoses and relevant physiological facts. The HELP (Health Evaluation Through Logical Processing) System at LDS Hospital stores patient data in <b>discrete</b> <b>codes.</b> We believe that HELP's coded patient database may drive an automatic version of CSI {{without the need for}} manual input. This descriptive study examines the nature and depth of the HELP System patient findings needed to implement an automatic CSI...|$|R
30|$|In {{order to}} analyze the various kinds of IMOPs conveniently, we {{categorize}} them based on three kinds of basic IMOP components including the continuous frequency modulation (CFM), the <b>discrete</b> frequency <b>coded</b> (DFC) modulation and the <b>discrete</b> phase <b>coded</b> (DPC) modulation. Possible IMOPs in CFM class include constant frequency (CF), LFM and various nonlinear frequency modulations (NLFM). The DFC class contains binary frequency codes (BFC), the Costas codes and so on. The DPC class includes IMOPs such as binary phase codes (BPC), quadriphase codes (QPC) and polyphase codes (PPC).|$|R
40|$|AbstractThe {{immunity}} model, {{as used in}} the GNU cfengine project, is a distributed {{framework for}} performing policy conformant system administration, used on {{hundreds of thousands of}} Unix-like and Windows systems. This paper describes the idealized approach to policy-guided maintenance, that is approximated by cfengine, building on the notion of ‘convergent’ operations, i. e. those that reach stable equilibrium. Agents gravitate towards a policy-determined configurations, through the repeated application of unintelligent ‘anti-body’ operations or <b>discrete,</b> <b>coded</b> counter-measures. The distributed agents turn passive discovery of state into active strategy for ‘curing’ systems of policy transgressions...|$|R
40|$|This paper {{considers}} a novel image compression technique called hybrid predictive wavelet coding. The new proposed technique combines {{the properties of}} predictive <b>coding</b> and <b>discrete</b> wavelet <b>coding.</b> In contrast to JPEG 2000, the image data values are pre-processed using predictive coding to remove interpixel redundancy. The error values, which are {{the difference between the}} original and the predicted values, are <b>discrete</b> wavelet <b>coding</b> transformed. In this case, a nonlinear neural network predictor is utilised in the predictive coding system. The simulation results indicated that the proposed technique can achieve good compressed images at high decomposition levels in comparison to JPEG 2000...|$|R
50|$|This article {{contains}} list of <b>discrete</b> dipole approximation <b>codes</b> and their applications.|$|R
50|$|The first {{release of}} Clinical Terms Version 3 {{occurred}} in the late 1990s. The October 2010 release contained 298,102 <b>discrete</b> concept <b>codes</b> of which 55,829 were marked as inactive, and 58,130 were pharmaceutical products or devices.|$|R
40|$|The Computerized Severity Index (CSI) is {{a commercially}} {{available}} scoring system for hospital inpatients. Trained abstractors review the patient's paper medical record {{and enter the}} diagnoses and relevant physiological attributes. The HELP (Health Evaluation through Logical Processing) System at LDS Hospital stores patient data in <b>discrete</b> <b>codes.</b> This paper describes {{the development of an}} automatic interface between the standalone, personal-computer-based severity system and the mainframe-based hospital information system. The interface scores patient severity without the need for manual chart review. Severity scores from the automated and manual methods were identical for 70 % of 222 general medical patients scored retrospectively. An evaluation of the causes for differing scores between the two methods is presented...|$|R
30|$|An {{autonomous}} {{method for}} recognizing radar pulse modulations based on modulation components analysis is introduced in this paper. Unlike the conventional automatic modulation classification methods which extract modulation features {{based on a}} list of known patterns, this proposed method classifies modulations by the existence of basic modulation components including continuous frequency modulations, <b>discrete</b> frequency <b>codes</b> and <b>discrete</b> phase <b>codes</b> in an autonomous way. A feasible way to realize this method is using the features of abrupt changes in the instantaneous frequency rate curve which derived by the short-term general representation of phase derivative. This method is suitable not only for the basic radar modulations but also for complicated and hybrid modulations. The theoretical result and two experiments demonstrate the effectiveness of the proposed method.|$|R
40|$|According to the {{asynchronous}} <b>discrete</b> <b>coding</b> {{model of}} Miller, two manipulations should display underadditive effects on reaction time if they slow down noncontingent stages {{associated with the}} processing of two separable dimensions of a stimulus. Underadditive effects are also predicted by a dual route model when a task variable is factorially varied with design type (mixed vs blocked). Interpretations of both underadditive effects and their combination were evaluated. Intact and degraded stimuli were presented to 18 young adults either in a single block (mixed) or in separate blocks (blocked). Spatial stimulus-response (S-R) compatibility was manipulated in all conditions. Stimulus degradation and S-R compatibility interacted underadditively, but only in blocked presentations. Both interpretations of underadditive effects were supported. Eye-movement registrations provided additional support for the alternative routes model...|$|R
3000|$|In all {{measured}} cases, we manually {{selected the}} tuple maximizing the throughput. Our starting point was the theoretical analysis, but this analysis {{does not take}} into account the imperfect channel <b>code</b> and available <b>discrete</b> channel <b>code</b> rates (0.4, 0.5, …, 0.9). We also considered N [...]...|$|R
5000|$|After the malware is {{downloaded}} to {{a mobile}} device via Google Play Store, hackers {{can not only}} charge fees from a user's account through <b>discrete</b> computer <b>code</b> on an application, but can also collect the fees as well, thus collecting as much as $12,000 per month.|$|R
40|$|As {{integrated}} optical devices {{become more}} sophisticated, {{so does the}} experimentation and analysis required to design them. By augmenting conventional experiments with rigorous computer modeling we can lower costs, shorten schedules, and provide faster, more accurate predictions. <b>Discrete</b> modeling <b>codes</b> using finite differences or finite elements are th...|$|R
30|$|The {{performance}} of the transmitted waveforms is judged by their correlation properties (Deng et al. 2004; Liu et al. 2007, 2008). The waveforms with good autocorrelation properties provide high range resolution and good crosscorrelation helps in multiple target return separability. So, {{there is a need}} to design MIMO radar waveforms as orthogonal pulses with low correlation properties. In literature, the orthogonal sequences are generated with low autocorrelation and crosscorrelation peak sidelobe levels using various algorithms. Deng et al. (2004) has proposed simulated annealing (SA) algorithm to optimize the frequency sequences for the development of the orthogonal <b>discrete</b> frequency <b>coding</b> waveforms frequency hopping (DFCW_FF) for netted radar systems. Liu has proposed orthogonal DFCW_FF (Liu et al. 2007) and orthogonal <b>discrete</b> frequency <b>coding</b> waveforms linear frequency modulation (DFCW_LFM) (Liu et al. 2008) using a modified genetic algorithm (MGA).|$|R
40|$|Abstract: One of {{the basic}} issues in {{navigation}} of autonomous mobile robots is the obstacle avoidance task that is commonly achieved using reactive control paradigm where a local mapping from perceived states to actions is acquired. A control strategy with learning capabilities in an unknown environment can be obtained using reinforcement learning where the learning agent is given only sparse reward information. This credit assignment problem includes both temporal and structural aspects. While the temporal credit assignment problem is solved using core elements of reinforcement learning agent, solution of the structural credit assignment problem requires an appropriate internal state space representation of the environment. In this paper a <b>discrete</b> <b>coding</b> of the input space using a neural network structure is presented {{as opposed to the}} commonly used continuous internal representation. This enables a faster and more efficient convergence of the reinforcement learning process...|$|R
40|$|In {{this work}} we devise a {{strategy}} for <b>discrete</b> <b>coding</b> of anatomical form as described by a Bayesian prior model, quantifying the entropy of this representation {{as a function of}} code rate (number of bits), and its relationship geometric accuracy at clinically relevant scales. We study the shape of subcortical gray matter structures in the human brain through diffeomorphic transformations that relate them to a template, using data from the Alzheimer's Disease Neuroimaging Initiative to train a multivariate Gaussian prior model. We find that the at 1 mm accuracy all subcortical structures can be described with less than 35 bits, and at 1. 5 mm error all structures can be described with less than 12 bits. This work represents a first step towards quantifying the amount of information ordering a neuroimaging study can provide about disease status...|$|R
50|$|Transponder {{codes are}} four digit numbers {{transmitted}} by the transponder in an aircraft {{in response to}} a secondary surveillance radar interrogation signal to assist air traffic controllers in traffic separation. A <b>discrete</b> transponder <b>code</b> (often called a squawk code) is assigned by air traffic controllers to uniquely identify an aircraft. This allows easy identification of aircraft on radar.|$|R
5000|$|In {{order to}} fly within the DC SFRA, pilots of general {{aviation}} aircraft {{are required to}} file a special fight rules flight plan, obtain a <b>discrete</b> transponder <b>code,</b> and remain in contact with air traffic control at all times. [...] Special training is {{required in order to}} fly within 30 nm of the Washington DC (KDCA) VOR.|$|R
40|$|A {{method is}} {{described}} for generating electron cross sections that are comparable with standard <b>discrete</b> ordinates <b>codes</b> without modification. There are many advantages of using an established discrete ordinates solver, e. g. immediately available adjoint capability. Coupled electron-photon transport capability {{is needed for}} many applications, including the modeling of the response of electronics components to space and man-made radiation environments. The cross sections have been successfully used in the DORT, TWODANT and TORT <b>discrete</b> ordinates <b>codes.</b> The cross sections are shown to provide accurate and efficient solutions to certain multidimensional electron-photon transport problems. The key to the method is a simultaneous solution of the continuous-slowing-down (CSD) portion and elastic-scattering portion of the scattering source by the Goudsmit-Saunderson theory. The resulting multigroup-Legendre cross sections are {{much smaller than the}} true scattering cross sections that they represent. Under certain conditions, the cross sections are guaranteed positive and converge with a low-order Legendre expansion...|$|R
40|$|Experiments on accent type {{recognition}} and syntactic boundary detection of Japanese speech were conducted {{based on the}} statistical modeling of voice fundamental frequency contours formerly proposed by the authors. In the proposed modeling, fundamental frequency contours are segmented into moraic units to generate moraic contours, which are further represented by <b>discrete</b> <b>codes.</b> After modeling the accent types and syntactic boundaries, their recognition /detection was done for ATR speech corpus. As for the accent type recognition, 4 -mora words {{were used for the}} training and testing, and recognition rates around 74 % were obtained for speaker open experiments. As for the syntactic boundary detection, detectability of accent phrase boundaries was tested for sentence speech. Although the experiments were conducted only for the closed condition due to availability of speech corpus, the result indicated the usefulness of separating the boundary model into two depending on whether the bounda [...] ...|$|R
5000|$|Set-Membership constraints: The {{values for}} a column {{come from a}} set of <b>discrete</b> values or <b>codes.</b> For example, a person's gender may be Female, Male or Unknown (not recorded).|$|R
40|$|AbstractRadar {{equipment}} of stealth platforms such as aircraft {{have adopted}} the newest modern technology to design the signal waveforms. One of the important and effective methods is the hybrid waveform called spread spectrum stretch (S-cubed) which combines linear frequency modulation (LFM) and <b>discrete</b> phase <b>code.</b> In order to investigate the function of enemy's stealth radar equipment, the interception algorithm of S-cubed is needed. In this paper, a novel detection and parameter estimation approach for the reconnaissance S-cubed radar signal is presented. First, the generalized time-frequency representation of Zhao, Atlas, and Marks (ZAM-GTFR) and Hough transforms (HT) are applied to detecting the signal, and then the initial frequency and modulation slope of LFM are estimated from the ZAM-GTFR. On the basis of LFM information, the reconstructing signal is generated. Finally, the <b>code</b> rate of <b>discrete</b> phase <b>code</b> is extracted from the negative peaks of the ZAM-GTFR. Simulation {{results show that the}} proposed algorithm has higher estimation accuracy when the signal to noise ratio (SNR) is above 3 dB...|$|R
40|$|This paper {{presents}} a structured ordinal measure method for video-based face recognition that simultaneously learns ordinal filters and structured ordinal features. The problem is posed as a non-convex integer program problem that includes two parts. The first part learns stable ordinal filters to project video data into a large-margin ordinal space. The second seeks self-correcting and <b>discrete</b> <b>codes</b> by balancing the projected data and a rank-one ordinal matrix in a structured low-rank way. Unsupervised and supervised structures are {{considered for the}} ordinal matrix. In addition, as a complement to hierarchical structures, deep feature representations are integrated into our method to enhance coding stability. An alternating minimization method is employed to handle the discrete and low-rank constraints, yielding high-quality codes that capture prior structures well. Experimental results on three commonly used face video databases show that our method with a simple voting classifier can achieve state-of-the-art recognition rates using fewer features and samples...|$|R
