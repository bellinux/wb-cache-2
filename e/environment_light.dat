95|2561|Public
25|$|Also {{during the}} 1960s and 1970s artists {{as diverse as}} Eduardo Paolozzi, Chryssa, Claes Oldenburg, George Segal, Edward Kienholz, Nam June Paik, Wolf Vostell, Duane Hanson, and John DeAndrea {{explored}} abstraction, imagery and figuration through video art, <b>environment,</b> <b>light</b> sculpture, and installation art in new ways.|$|E
25|$|A diving mask (also half mask, {{dive mask}} or scuba mask) is {{an item of}} diving {{equipment}} that allows underwater divers, including, scuba divers, free-divers, and snorkelers to see clearly underwater. Surface supplied divers usually use a full face mask or diving helmet, but in some systems the half mask may be used. When the human eye is {{in direct contact with}} water as opposed to air, its normal <b>environment,</b> <b>light</b> entering the eye is refracted by a different angle and the eye is unable to focus the light. By providing an air space in front of the eyes, light enters normally and the eye is able to focus correctly.|$|E
25|$|Beach {{nourishment}} {{has significant}} impacts on local ecosystems. Nourishment may cause direct mortality to sessile organisms {{in the target}} area by burying them under the new sand. Seafloor habitat in both source and target areas are disrupted, e.g., when sand is deposited on coral reefs or when deposited sand hardens. Imported sand may differ in character (chemical makeup, grain size, non-native species) {{from that of the}} target <b>environment.</b> <b>Light</b> availability may be reduced, affecting nearby reefs and submerged aquatic vegetation. Imported sand may contain material toxic to local species. Removing material from near-shore environments may destabilize the shoreline, in part by steepening its submerged slope. Related attempts to reduce future erosion may provide {{a false sense of security}} that increases development pressure.|$|E
40|$|Figure 1 : Examples of {{applying}} our adaptive radiance transfer computations for probeless light estimation in Augmented Reality. (Left) Aug-mented Reality based interior shopping application. (Middle, Right) Physical gaming using depth cameras. Photorealistic Augmented Reality (AR) requires {{knowledge of the}} scene geometry and <b>environment</b> <b>lighting</b> to compute photomet-ric registration. Recent work has introduced probeless photometric registration, where <b>environment</b> <b>lighting</b> is estimated directly from observations of reflections in the scene rather than through an inva-sive probe such as a reflective ball. However, computing the dense radiance transfer of a dynamically changing scene is computation-ally challenging. In this work, we present an improved radiance transfer sampling approach, which combines adaptive sampling in image and visibility space with robust caching of radiance trans-fer to yield real time framerates for photorealistic AR scenes with dynamically changing scene geometry and <b>environment</b> <b>lighting...</b>|$|R
40|$|Image-based {{rendering}} {{methods that}} capture the surrounding environment, store {{it as an}} environment map, {{and use it as}} the incident <b>lighting</b> (i. e. <b>environment</b> <b>lighting)</b> have been used to render realistic images. Real-time rendering of scenes illuminated by environmental lighting, is beneficial in many applications such as lighting/material design, animation, and games. For photorealistic rendering under environmental lighting, the triple product of the environmental lighting, the BRDF, and the visibility function is integrated. Integrating the triple product is computationally expensive and this prevents from real-time rendering under all-frequency <b>environment</b> <b>lighting.</b> To address this, we propose an efficient rendering method for scenes illuminated by all-frequency environmental lighting. Our method uses spherical Gaussian (SG) functions to efficiently integrate the triple product...|$|R
50|$|Poloniny Dark-Sky Park {{was created}} {{to inform the public}} about the {{exceptionally}} preserved night environment in this area, to educate on the issue of protection of the <b>environment</b> against <b>light</b> pollution, to promote and protect the dark night sky, which is the basis of protecting the natural <b>environment</b> from <b>light</b> pollution.|$|R
500|$|Light gun {{shooters}} typically feature [...] "on-rails" [...] movement, {{which gives}} the player no control over the direction the protagonist moves in; the player only has control over aiming and shooting. Some games, however, may allow the protagonist to take cover at {{the push of a}} button. Other games may eschew on-rails movement altogether and allow the player to move the protagonist freely around the game's environment; still others may feature a static <b>environment.</b> <b>Light</b> gun shooters utilise a first person perspective for aiming, though some games may allow the player to switch to a third person perspective in order to maneuver the protagonist.|$|E
50|$|In {{order to}} improve the realism of the {{resulting}} simulations, the hippus effect can be approximated by adding small random variations to the <b>environment</b> <b>light</b> (in the range 0.05-0.3 Hz).|$|E
50|$|According to the Carbon Nutrient Balance Model, phlorotannins, {{which are}} {{predominantly}} carbon molecules free of nitrogen, are produced in higher yields in light <b>environment.</b> <b>Light</b> has greater importance than nitrogen availability.|$|E
40|$|Figure 1 : Our method can render various cloth fabrics with microcylinder {{appearance}} model under <b>environment</b> <b>lighting</b> at interactive frame rates. The insets {{show the}} environment maps. From left to right, cloth fabrics are linen plain, polyester satin charmuse, silk crepe de chine, velvet. This paper proposes an interactive rendering method of cloth fabrics under <b>environment</b> <b>lighting.</b> The outgoing radiance from cloth fabrics in the microcylinder model is calculated by integrating {{the product of}} the distant <b>environment</b> <b>lighting,</b> the visibility function, the weighting function that includes shadowing/masking effects of threads, and the light scattering function of threads. The radiance calculation at each shading point of the cloth fabrics is simplified to a linear combination of triple product integrals of two circular Gaussians and the visibility function, multiplied by precomputed spherical Gaussian convolutions of the weighting function. We propose an efficient calculation method of the triple product of two circular Gaussians and the visibility function by using the gradient of signed distance function to the visibility boundary where the binary visibility changes in the angular domain of the hemisphere. Our GPU implementation enables interactive rendering of static cloth fabrics with dynamic viewpoints and lighting. In addition, interactive editing of parameters for the scattering function (e. g. thread’s albedo) that controls the visual appearances of cloth fabrics can be achieved...|$|R
40|$|Figure 1 : The BRDF-Shop {{interface}} {{consists of}} a spherical canvas, where the artist can directly paint highlights and design a unique BRDF, (middle), and simultaneously and in real-time inspect the designed BRDF on a complex model rendered under <b>environment</b> <b>lighting</b> (left). Additionally, the interface was adapted for Maya (right), allowing fast integration in a production environment. We present an interface for quick and intuitive development of arbitrary, but physically correct, Bi-directional Reflectance Distribution Functions, or BRDFs. Our interface, referred to as BRDF-Shop, provides artists {{the ability to create}} a BRDF through positioning and manipulating highlights on a spherical canvas. We develop a novel mapping between painted highlights and specular lobes of an extended Ward BRDF model. The implementation of BRDF-Shop utilizes programmable graphics hardware to provide a realtime visualization of the material on a complex object in <b>environment</b> <b>lighting...</b>|$|R
50|$|The main {{concerns}} of exhibition <b>environments</b> include <b>light,</b> relative humidity, and temperature.|$|R
50|$|Also {{during the}} 1960s and 1970s artists {{as diverse as}} Eduardo Paolozzi, Chryssa, Claes Oldenburg, George Segal, Edward Kienholz, Nam June Paik, Wolf Vostell, Duane Hanson, and John DeAndrea {{explored}} abstraction, imagery and figuration through video art, <b>environment,</b> <b>light</b> sculpture, and installation art in new ways.|$|E
50|$|A diving mask (also half mask, {{dive mask}} or scuba mask) is {{an item of}} diving {{equipment}} that allows underwater divers, including, scuba divers, free-divers, and snorkelers to see clearly underwater. Surface supplied divers usually use a full face mask or diving helmet, but in some systems the half mask may be used. When the human eye is {{in direct contact with}} water as opposed to air, its normal <b>environment,</b> <b>light</b> entering the eye is refracted by a different angle and the eye is unable to focus the light. By providing an air space in front of the eyes, light enters normally and the eye is able to focus correctly.|$|E
5000|$|Light gun {{shooters}} typically feature [...] "on-rails" [...] movement, {{which gives}} the player no control over the direction the protagonist moves in; the player only has control over aiming and shooting. Some games, however, may allow the protagonist to take cover at {{the push of a}} button. Other games may eschew on-rails movement altogether and allow the player to move the protagonist freely around the game's environment; still others may feature a static <b>environment.</b> <b>Light</b> gun shooters utilise a first person perspective for aiming, though some games may allow the player to switch to a third person perspective in order to maneuver the protagonist.|$|E
5000|$|Eaton's Cooper Lighting Business {{manufactures}} {{lighting fixtures}} and related products to worldwide commercial, industrial, residential and utility markets. This includes track and recessed lighting (LED, fluorescent, H.I.D.), exit and emergency, vandal-resistant, landscape and complex <b>environment</b> <b>lighting.</b> Eaton's Cooper Lighting Business manufactures lighting fixtures under several brands, {{many of which}} were the result of acquisitions. These brands include: ...|$|R
40|$|Global {{illumination}} algorithms are at {{the center}} of realistic image synthesis and account for non-trivial light transport and occlusion within scenes, such as indirect illumination, ambient occlusion, and <b>environment</b> <b>lighting.</b> Their computationally most difficult part is determining light source visibility at each visible scene point. Height fields, on the other hand, constitute an important special case of geometry and are mainly used to describe certain types of objects such as terrains and to map detailed geometry onto object surfaces. The geometry of an entire scene can also be approximated by treating the distance values of its camera projection as a screen-space height field. In order to shadow height fields from <b>environment</b> <b>lights</b> a horizon map is usually used to occlude incident light. We reduce the per-receiver time complexity of generating the horizon map on N × N height fields from O(N) of the previous work to O(1) by using an algorithm that incrementall...|$|R
40|$|We {{examined}} {{the dependence of}} photosynthetic capacity on leaf nitrogen content and <b>light</b> <b>environment</b> in leaf microsites of six rainforest species growing naturally in understory and clearing habitats. All nine descriptors of the <b>light</b> <b>environment</b> in leaf microsites, encompassing canopy openness, potential exposure to sunflecks, and photosynthetically active photon flux density (PFD) integrated over one day, three months, and an entire year, were highly correlated with each other. Among species, Amax was strongly dependent on leaf nitrogen and on all descriptors of the <b>light</b> <b>environment</b> in the leaf microsite. Leaf nitrogen was also dependent on all descriptors of the <b>light</b> <b>environment.</b> Simple regressions of Amax on all measures of the <b>light</b> <b>environment</b> were significant for plants in the clearing, but not for plants growing in the understory. Regressions of leaf nitrogen {{on at least one}} descriptor of the <b>light</b> <b>environment</b> were significant for both clearing and understory plants. Over all species, and for the clearing plants alone, leaf nitrogen and a single descriptor of the <b>light</b> <b>environment</b> together explained significantly more variance in Amax than either variable alone. Multiple regressions using leaf nitrogen and all nine descriptors of the <b>light</b> <b>environment</b> did not explain a significantly greater amount of variance in photosynthetic capacity than multiple regressions using leaf nitrogen and a single light descriptor. In most cases, Amax was predicted better by the most general descriptors of the <b>light</b> <b>environment,</b> such as canopy openness and long-term photon flux density, and less accurately by shorter-term sensor measurements or descriptors based on the duration of potential sunfleck exposure. The gest predictors of Amax were frequently different than the best predictors of leaf nitrogen. In every case examined, Amax was less sensitive to variation in the <b>light</b> <b>environment</b> in understory than in clearing plants. © 1987 Springer-Verlag...|$|R
50|$|Beach {{nourishment}} {{has significant}} impacts on local ecosystems. Nourishment may cause direct mortality to sessile organisms {{in the target}} area by burying them under the new sand. Seafloor habitat in both source and target areas are disrupted, e.g., when sand is deposited on coral reefs or when deposited sand hardens. Imported sand may differ in character (chemical makeup, grain size, non-native species) {{from that of the}} target <b>environment.</b> <b>Light</b> availability may be reduced, affecting nearby reefs and submerged aquatic vegetation. Imported sand may contain material toxic to local species. Removing material from near-shore environments may destabilize the shoreline, in part by steepening its submerged slope. Related attempts to reduce future erosion may provide {{a false sense of security}} that increases development pressure.|$|E
5000|$|Before the mid-1980s, it was {{believed}} that only eukaryotes had circadian systems. The conclusion that only eukaryotes have circadian oscillators seemed reasonable, because it was assumed that an endogenous timekeeper with a period close to 24 hours would not be useful to prokaryotic organisms that often divide more rapidly than once every 24 hours. The assumption might be stated as, [...] "why have a timer for a cycle that is longer than your lifetime?" [...] While intuitive, the conclusion was flawed. It was {{based on the assumption that}} a bacterial cell is equivalent to a sexually reproducing multicellular organism. However, a bacterial culture is more like a mass of protoplasm that grows larger and larger and incidentally subdivides. From this perspective, it is reasonable that a 24-hour temporal program could be adaptive to a rapidly dividing protoplasm if the fitness of that protoplasm changes as a function of daily alterations in the <b>environment</b> (<b>light</b> intensity, temperature, etc.).|$|E
40|$|This paper {{presents}} a framework to perform outdoor photometric stereo by utilizing <b>environment</b> <b>light.</b> We present the main considerations {{in designing the}} framework and steps of the processing pipeline. Our framework extends existing algorithms to meet the robustness and variability necessary to operate out of a laboratory environment. We verify our <b>environment</b> <b>light</b> photometric stereo framework using both synthetic and real world examples. Our experimental results are promising even for objects captured in outdoor environments with very complicated natural lighting. 1...|$|E
40|$|Problem: {{automatic}} detection of observable events in surveillance video • Challenges: – requires application of several Computer Vision techniques • segmentation, person detection/tracking, object recognition, feature extraction, etc. – involves subtleties that are readily understood by humans, difficult to encode for {{machine learning approaches}} – can be complicated due to clutter in the <b>environment,</b> <b>lighting,</b> camera placement, traffic, etc. NIST Evaluation Process Choosing the right task and metric is ke...|$|R
50|$|The {{advantage}} of EVS is that safety {{in nearly all}} phases of flight are enhanced, especially during approach and landing in limited visibility. A pilot on a stabilized approach is able to recognize the runway <b>environment</b> (<b>lights,</b> runway markings, etc.) earlier in preparation for touchdown. Obstacles such as terrain, structures, and vehicles or other aircraft on the runway that might not otherwise be seen are clearly visible on the IR image.|$|R
40|$|Figure 1 : Our {{algorithm}} achieves interactive hair rendering {{and appearance}} editing under <b>environment</b> <b>lighting,</b> including both single and multiple scattering effects. In this example, the user directly paints onto the hair to edit the spatially-varying scattering parameters. This {{results in a}} dynamic simulation of hair coloring. From left to right, the hair is dyed with a progressively more vivid color. The environment map is represented by 40 SRBF lights, and our algorithm runs at 8. 3 fps on an NVIDIA GTX 580. We present an interactive algorithm for hair rendering and appearance editing under complex <b>environment</b> <b>lighting</b> represented as spherical radial basis functions (SRBFs). Our main contribution is to derive a compact 1 D circular Gaussian representation that can accurately model the hair scattering function introduced by [Marschner et al. 2003]. The primary benefit of this representation is that it enables us to evaluate, at run-time, closed-form integrals of the scattering function with each SRBF light, resulting in efficient computation of both single and multiple scatterings. In contrast to previous work, our algorithm computes the renderin...|$|R
40|$|As photoautotrophs, {{plants are}} exquisitely {{sensitive}} to their light <b>environment.</b> <b>Light</b> affects many developmental and physiological responses throughout plants ’ life histo-ries, including germination (Seed Dormancy and Germination doi/ 10. 1199 /tab. 0050), flowering (Flowering doi/ 10. 1199 /tab. 0055), {{and direction of}} growt...|$|E
30|$|Of {{course a}} tiny LED can {{highlight}} a sticky note. However, a blight flickering light may disturb person in distance because decay by distance of light intensity {{is very low}} [10],[11]. Meanwhile, though an soft light can make visual stimulation, {{it is difficult to}} be noticed certainly because it is affected by <b>environment</b> <b>light</b> easily.|$|E
30|$|Object {{tracking}} {{based on}} image has the difficulties and complexities. Movement of object from camera makes the image size of object larger, smaller or rotation in the object image. <b>Environment</b> <b>light</b> variations such as weather clouding or shadow creation during the day, causes {{changes in the}} object image. Despite many problems in object tracking, it has many applications.|$|E
40|$|In article the {{problems}} of a common and medical bionomics are presented. the modern problems {{of a state of}} an environment and health of the population stipulated by a sharp amplification of relative (mutual) negative influence of the man and the <b>environment</b> <b>lighted.</b> the place of diseases of an eye in a plane of ecological medicine surveyed. the number of the unfavorable ecological factors influential in health of the medical workers is parsed. </div...|$|R
40|$|We {{present a}} new {{real-time}} shadow rendering approach whose kernel is a hierarchical disk-based approximation {{to the scene}} geometry. We show that this approximated representation greatly accelerates the visibility inquiry, facilitating the real-time computation of anisotropic occlusion in GPU. By taking account of anisotropic occlusion, our approach can simulate the shadow cast from not only ambient light, but also point, directional and <b>environment</b> <b>lights.</b> Because no pre-computation is required, it is suitable for dynamically deforming objects. 1...|$|R
40|$|International audienceThis work {{presents}} {{an approach to}} render appropriate shadows with Image Based Lighting in Augmented Reality applications. To approximate the result of <b>environment</b> <b>lighting</b> and shadowing, the system uses a dome of shadow casting light sources. The color of each shadow {{is determined by the}} area of the environment behind the casting light source. As a result it is possible that changes in the lighting conditions immidiately affect the shadow casting of virtual objects on real object...|$|R
40|$|Inspired by the {{mechanism}} of imaging and adaptation to luminosity in insect compound eyes (ICE), we propose an ICE-based adaptive reconstruction method (ARM-ICE), which can adjust the sampling vision field of image according to the <b>environment</b> <b>light</b> intensity. The target scene can be compressive, sampled independently with multichannel through ARM-ICE. Meanwhile, ARM-ICE can regulate the visual field of sampling to control imaging according to the <b>environment</b> <b>light</b> intensity. Based on the compressed sensing joint sparse model (JSM- 1), we establish an information processing system of ARM-ICE. The simulation of a four-channel ARM-ICE system shows that the new method improves the peak signal-to-noise ratio (PSNR) and resolution of the reconstructed target scene under two different cases of light intensity. Furthermore, there is no distinct block effect in the result, and {{the edge of the}} reconstructed image is smoother than that obtained by the other two reconstruction methods in this work...|$|E
40|$|One {{augmented}} reality {{approach is to}} use digital projectors to alter {{the appearance of a}} physical scene, avoiding the need for head-mounted displays or special goggles. Instead, spatial {{augmented reality}} (SAR) systems depend on having sufficient light radiance to compensate the surface’s colors to those of a target visualization. However, standard SAR systems in dark room settings may suffer from insufficient light radiance causing bright colors to exhibit unexpected color shifts, resulting in a misleading visualization. We introduce a SAR framework which focuses on minimally altering the appearance of arbitrarily shaped and colored objects to exploit the presence of environment/room light as an additional light source to achieve compliancy for bright colors. While previous approaches have compensated for <b>environment</b> <b>light,</b> none have explicitly exploited the <b>environment</b> <b>light</b> to achieve bright, previously incompliant colors. We implement a full working system and compared our results to solutions achievable with standard SAR systems...|$|E
40|$|SummaryThe {{visual system}} relies on {{patterns}} {{of light to}} provide information about the layout of objects that populate our <b>environment.</b> <b>Light</b> is structured by the way it interacts with the three-dimensional shape, reflectance, and transmittance properties of objects. The input for vision is therefore a complex, conflated mixture of different sources of physical variation that the brain must somehow disentangle to recover the intrinsic properties of the objects and materials that fill the world...|$|E
40|$|Jonathan Dupuy and Eric Heitz are joint first authors Figure 1 : A {{high-quality}} animated {{production model}} (Ptex T-rex model c ○ Walt Disney Animation Studios.) rendered {{in real time}} under directional and <b>environment</b> <b>lighting</b> using LEADR mapping on an NVidia GTX 480 GPU. The surface appearance is preserved at all scales, using a single shading sample per pixel. Combined with adaptive GPU tessellation, our method provides the fastest, seamless, and antialiased progressive representation for displaced surfaces...|$|R
25|$|Visual {{perception}} {{is the ability}} to interpret the surrounding <b>environment</b> using <b>light</b> in the visible spectrum reflected by the objects in the environment.|$|R
40|$|We {{demonstrate}} how to exploit reflections for accurate registration of shiny objects: The <b>lighting</b> <b>environment</b> can be retrieved from the reflections under a distant illumination assumption. Since it remains unchanged {{when the camera}} or the object of interest moves, this provides powerful additional constraints that {{can be incorporated into}} standard pose estimation algorithms. The key idea and main contribution of the paper is therefore to show that the registration should also be performed in the <b>lighting</b> <b>environment</b> space, instead of in the image space only. This lets us recover very accurate pose estimates because the specularities are very sensitive to pose changes. An interesting side result is an accurate estimate of the <b>lighting</b> <b>environment.</b> Furthermore, since the mapping from <b>lighting</b> <b>environment</b> to specularities has no analytical expression for objects represented as 3 D meshes, and is not 1 -to- 1, registering <b>lighting</b> <b>environments</b> is far from trivial. However we propose a general and effective solution. Our approach is demonstrated on both synthetic and real images. 1...|$|R
