2|1|Public
40|$|Inertial sensors {{attached}} to a camera can provide valuable data about camera pose and movement. In biological vision systems, inertial cues provided by the vestibular system, are fused with vision at an early processing stage. Vision systems in autonomous vehicles can also benefit by taking inertial cues into account. In order to use off-the-shelf inertial sensors {{attached to}} a camera, appropriate modelling and calibration techniques are required. Camera calibration has been extensively studied, and standard techniques established. Inertial navigation systems, relying on highend sensors, also have established techniques. This paper presents a technique for modelling and calibrating the camera integrated with low-cost inertial sensors, three gyros and three accelerometers for full 3 D sensing. Using a pendulum with an <b>encoded</b> <b>shaft,</b> inertial sensor alignment, bias and scale factor can be estimated. Having both the camera and the inertial sensors observing the vertical direction at different poses, the rigid rotation between the two frames of reference can be estimated. Preliminary simulation and real data results are presented. ...|$|E
40|$|Abstract: This article {{presents}} a technique for modeling and calibrating a camera with integrated low-cost inertial sensors, three gyros and three accelerometers for full 3 D sensing. Inertial sensors {{attached to a}} camera can provide valuable data about camera pose and movement. In biological vision systems, inertial cues provided by the vestibular system, are fused with vision at an early processing stage. Vision systems in autonomous vehicles can also benefit by taking inertial cues into account. Camera calibration has been extensively studied, and standard techniques established. Inertial navigation systems, relying on high-end sensors, also have established techniques. Nevertheless, {{in order to use}} off-the-shelf inertial sensors attached to a camera, appropriate modeling and calibration techniques are required. For inertial sensor alignment, a pendulum instrumented with an <b>encoded</b> <b>shaft</b> is used to estimate the bias and scale factor of inertial measurements. For camera calibration, a standard and reliable camera calibration technique is used, based on images of a planar grid. Having both the camera and the inertial sensors calibrated and observing the vertical direction at different poses, the rigid rotation between the two frames of reference is estimated, using a mathematical model based on unit quaternions. The technique for this alignment and consequent results with simulated and real data are presented {{at the end of this}} article...|$|E
40|$|These studies {{examined}} {{the role of}} spatial encoding in inducing perception-action dissociations in visual illusions. Participants were shown a large-scale Müller-Lyer configuration with hoops as its tails. In Experiment 1, participants either made verbal estimates {{of the extent of}} the Müller-Lyer shaft (verbal task) or walked the extent without vision, in an offset path (blind-walking task). For both tasks, participants stood a small distance away from the configuration, to elicit object-relative <b>encoding</b> of the <b>shaft</b> with respect to its hoops. A similar illusion bias was found in the verbal and motoric tasks. In Experiment 2, participants stood at one endpoint of the shaft in order to elicit egocentric encoding of extent. Verbal judgments continued to exhibit the illusion bias, whereas blind-walking judgments did not. These findings underscore the importance of egocentric encoding in motor tasks for producing perception-action dissociations. A growing body of empirical evidence suggests that the human visual system comprises two separate but interacting processin...|$|R

