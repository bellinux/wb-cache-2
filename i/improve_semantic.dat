67|276|Public
5000|$|TRAK {{requires}} {{the type of}} every architecture description element in a TRAK architecture view to be explicitly shown so that each TRAK view {{can be read as}} a set of declarative statements. TRAK also allows a view to be constructed from textual statements. Since a TRAK view is a set of tuples / triples it is possible to use a graph or a set of RDF triples to present a TRAK view. TRAK also requires every block to have a name. The intent of this is to ensure that a TRAK architecture view is read as the author of the view meant it and <b>improve</b> <b>semantic</b> consistency. Presentation rules that apply to all TRAK architecture views are specified in the overall TRAK specification [...] (as 'Bye Laws').|$|E
50|$|Ontologies {{and other}} {{semantic}} technologies can be key enabling technologies for sensor networks {{because they will}} <b>improve</b> <b>semantic</b> interoperability and integration, as well as facilitate reasoning, classification {{and other types of}} assurance and automation not included in the Open Geospatial Consortium (OGC) standards. A semantic sensor network will allow the network, its sensors and the resulting data to be organised, installed and managed, queried, understood and controlled through high-level specifications. Ontologies for sensors provide a framework for describing sensors. These ontologies allow classification and reasoning on the capabilities and measurements of sensors, provenance of measurements and may allow reasoning about individual sensors as well as reasoning about the connection of a number of sensors as a macroinstrument. The sensor ontologies, to some degree, reflect the OGC standards and, given ontologies that can encode sensor descriptions, understanding how to map between the ontologies and OGC models is an important consideration. Semantic annotation of sensor descriptions and services that support sensor data exchange and sensor network management will serve a similar purpose as that espoused by semantic annotation of Web services. This research is conducted through the W3C Semantic Sensor Network Incubator Group (SSN-XG) activity.|$|E
40|$|This chapter {{gives an}} {{educational}} overview of: • The difference between informal and formal ontologies • The primary objectives of ontology design, re-use, extensibility, and interoperability • How formal ontologies {{can be used}} to map terminologies and classification systems • How formal ontologies <b>improve</b> <b>semantic</b> interoperability • The relationship between a well-formed ontology and the development of intelligent decision suppor...|$|E
5000|$|ROMULUS is a {{foundational}} ontology repository {{aimed at}} <b>improving</b> <b>semantic</b> interoperability. Currently {{there are three}} foundational ontologies in the repository: DOLCE, BFO and GFO.|$|R
5000|$|ROMULUS is a {{foundational}} ontology repository {{aimed at}} <b>improving</b> <b>semantic</b> interoperability. Currently {{there are three}} foundational ontologies in the repository: DOLCE, BFO and GFO. Features of ROMULUS include: ...|$|R
40|$|Abstract. Clustering text data streams is an {{important}} issue in data mining community and has a number of applications such as news group filtering, text crawling, document organization and topic detection and tracing etc. However, most methods are similarity-based approaches and use the TF*IDF scheme to represent the semantics of text data and often lead to poor clustering quality. In this paper, we firstly give an <b>improved</b> <b>semantic</b> smoothing model for text data stream environment. Then we use the <b>improved</b> <b>semantic</b> model to <b>improve</b> the clustering quality and present an online clustering algorithm for clustering massive text data streams. In our algorithm, a new cluster statistics structure, cluster profile, is presented in which the semantics of text data streams are captured. We also present the experimental results illustrating the effectiveness of our technique...|$|R
40|$|The overall problem {{addressed}} in {{this paper is to}} <b>improve</b> <b>semantic</b> interoperability in heterogeneous systems. Normally, the semantics of data is carried by ontology (concept model). Reconciling data semantics therefore boils down to reconciling relevant ontologies. A candidate solution is to use extensional information, i. e. the instance information of the ontology to enrich the ontology and further, based on the enrichment structure to calculate similarities between concepts in two ontologies...|$|E
40|$|Syntax-based vector {{spaces are}} used widely in lexical {{semantics}} {{and are more}} versatile than word-based spaces (Baroni and Lenci, 2010). However, they are also sparse, with resulting reliability and coverage problems. We address this problem by derivational smoothing, which uses knowledge about derivationally related words (oldish → old) to <b>improve</b> <b>semantic</b> similarity estimates. We develop a set of derivational smoothing methods and evaluate them on two lexical semantics tasks in German. Even for models built from very large corpora, simple derivational smoothing can improve coverage considerably. ...|$|E
40|$|Abstract. This paper {{presents}} {{an overview of}} ongoing work to develop a generic ontology design pattern for observation-based data on the Semantic Web. The core classes and relationships forming the pattern are discussed in detail and are aligned to the DOLCE foundational ontology to <b>improve</b> <b>semantic</b> interoperability and clarify the underlying ontological commitments. The pattern also forms the top-level of the the Semantic Sensor Network ontology developed by the W 3 C Semantic Sensor Network Incubator Group. The integration of both ontologies is discussed and directions of further work are pointed out. ...|$|E
40|$|In this paper, {{we provide}} an {{improved}} {{basis for the}} “distillation” program transformation. It is known that superlinear speedups can be obtained using distillation, but cannot be obtained by other ear-lier automatic program transformation techniques such as defor-estation, positive supercompilation and partial evaluation. We give distillation an <b>improved</b> <b>semantic</b> basis, and explain how superlin-ear speedups can occur...|$|R
50|$|ORM is attribute-free: unlike {{models in}} the {{entity-relationship}} (ER) and Unified Modeling Language (UML) methods, ORM treats all elementary facts as relationships and so treats decisions for grouping facts into structures (e.g. attribute-based entity types, classes, relation schemes, XML schemas) as implementation concerns irrelevant to semantics. By avoiding attributes in the base model, ORM <b>improves</b> <b>semantic</b> stability and enables verbalization into natural language.|$|R
40|$|Abstract. This paper {{presents}} a new method that aims at <b>improving</b> <b>semantic</b> indexing while {{reducing the number}} of indexing terms. Indexing terms are determined using a minimum redundancy cut in a hierarchy of conceptual hypernyms provided by an ontology (e. g. WordNet, EDR). The results of some information retrieval experiments carried out on several standard document collections using the EDR ontology are presented, illustrating the benefit of the method. ...|$|R
40|$|Abstract. This paper {{shows how}} a Fuzzy Ontology based {{approach}} can <b>improve</b> <b>semantic</b> documents retrieval. After formally defining a Fuzzy Knowledge Base, it is discussed a special type of new non-taxonomic fuzzy relationships, called (semantic) correlations. These correlations, first assigned by experts, are updated after querying, {{or when a}} document has been inserted into a database. It is then introduced an Information Retrieval algorithm that allows to derive a unique path among the entities involved in the query {{in order to obtain}} maxima semantic associations in the knowledge domain. ...|$|E
40|$|The starting-point of {{the paper}} is the debate {{recently}} developed in LIS literature about OPAC enhancement and the necessity to design OPACs based on search engines features. Supposed improving tools as relevance ranking and relevance feedback devices are examinated. Possible OPAC development lines, based on theoretical examination of relevance and pertinence concepts, according to Sarácevic view, and following semantics perspectives, are presented. Finally, enhancement of OPACs starting from their inner characteristics is proposed, and a plan to <b>improve</b> <b>semantic</b> search functions while maintaining existing indexing methodologies, that is document conceptual analysis, is outlined...|$|E
40|$|AbstractEven {{though the}} {{calculation}} of the semantic similarity between textual entities has {{received a lot of}} attention by the research community, the more general notion of semantic relatedness (which considers both taxonomic and non-taxonomic knowledge) has been significantly less studied and, in general, stays one step behind in terms of accuracy. In this paper, we <b>improve</b> <b>semantic</b> relatedness assessments by aggregating the highly-accurate ontology-based estimation of semantic similarity with the distributional resemblance of textual terms computed from large textual corpora. As a result, our approach is able to improve the accuracy of related works on a standard benchmark...|$|E
40|$|Semantic object {{detection}} {{is one of}} {{the most}} important and challenging problems in image analysis. Segmentation is an optimal approach to detect salient objects, but often fails to generate meaningful regions due to over-segmentation. This paper presents an <b>improved</b> <b>semantic</b> segmentation approach which is based on JSEG algorithm and utilizes multiple region merging criteria. The experimental results demonstrate that the proposed algorithm is encouraging and effective in salient object detection...|$|R
40|$|Schema {{matching}} is {{a critical}} step in many applications, such as data warehouse loading, Online Analytical Process (OLAP), Data mining, semantic web and schema integration. This task is defined for finding the semantic correspondences between elements of two schemas. Recently, schema matching has found considerable interest in both research and practice. In this paper, some approaches for supporting semantic schema matching compared and then we suggest three solutions for <b>improving</b> <b>semantic</b> schema matching problem...|$|R
40|$|In {{this paper}} we {{describe}} a hybrid approach to <b>improving</b> <b>semantic</b> extraction from news video. Experiments show {{the value of}} careful parameter tuning, exploiting multiple feature sets and multilingual linguistic resources, applying text retrieval approaches for image features, and establishing synergy between multiple concepts through undirected graphical models. No single approach provides a consistently better result for every concept detection, which suggests that extracting video semantics should exploit multiple resources and techniques rather than a single approach. 1...|$|R
40|$|A present {{challenge}} in today’s Internet of Things (IoT) ecosystem is to enable interoperability across hetero- geneous systems and service providers. Restricted {{access to data}} sources and services limits the capabilities of a smart city to improve social, environmental and economic aspects. Interoperability in the IoT is concerned with both, messaging interfaces and semantic understanding of heterogeneous data. In this paper, the first building blocks of an emerging open IoT ecosystem developed at the EU level are presented. Se- mantic web technologies are applied to the existing messaging components to support and <b>improve</b> <b>semantic</b> interoperability. The approach is demonstrated with a proof-of-concept for connected vehicle services in a smart city setting...|$|E
40|$|The {{experiment}} {{reported in}} this paper is a feature engeneering op-eration that explores the syntactic structures of three different semantic relation types with tree kernels. This is done {{in order to find}} whether syntax can be a good feature to <b>improve</b> <b>semantic</b> relation separability in classification tasks. The average accuracy obtained is 63. 09 %. 1 Introduction And related work In a previous experiment [1] it was found that three semantic relation classes (”role”, ”location”, ”social”) yielded better results in a classification task with respect to the seven semantic relation classes in ACE 2004 (see [3]), since those three classes are easily separable. The three semantic relations are: Role (entit...|$|E
40|$|Abstract. This paper {{presents}} {{the evaluation of}} a proposal for the creation and implementation of an intervention method on students ’ conceptualization of written language. It rests on the integration of concept maps and texts created by fourth grade Elementary School students in an online news production network. The analysis of the textual development is carried out based on the triangulation of data concerning levels of development of linear writing, as well as topological and semantic taxonomies for concept maps. The results indicate a reciprocal development {{with regard to the}} conceptualization of linear writing and the construction of concept maps, favoring consciousness-raising in the process of revising texts, in order to <b>improve</b> <b>semantic</b> and structural aspects of written language. ...|$|E
5000|$|Martínez-Costa C, Kalra D, Schulz S., <b>Improving</b> EHR <b>Semantic</b> Interoperability: Future Vision and Challenges, Stud Health Technol Inform, 2014, 205, p. 589-593. http://www.ncbi.nlm.nih.gov/pubmed/25160254 ...|$|R
40|$|In this paper, {{we present}} a {{heuristic}} mapping method and a prototype mapping system that support the process of semi-automatic ontology mapping {{for the purpose of}} <b>improving</b> <b>semantic</b> interoperability in heterogeneous systems. The approach is based on the idea of semantic enrichment, i. e. using instance information of the ontology to enrich the original ontologies and calculate similarities between elements in two ontologies. The functional settings for the mapping system are discussed and the evaluation of the prototype implementation of the approach is reported...|$|R
40|$|Abstract — This paper {{describes}} an approach for <b>improving</b> <b>semantic</b> queries by utilizing Universal Words (UWs) and a graph database. Concept Description Language (CDL) {{is used for}} representing the semantic data, and Neo 4 j graph database is used as the storage back-end. Cypher graph query language is {{used as the basis}} for implementing the <b>semantic</b> queries. For <b>improving</b> the queries, query expansion is performed by utilizing semantic relationships between UWs provided by UNL Ontology. Keywords- semantic computing; semantic web; semantic search; graph database; inexact graph matching; CDL; CWL; UNL; Neo 4 j; Cypher I...|$|R
40|$|Abstract. Recent {{progress}} in computational photography {{has shown that}} we can acquire physical information beyond visible (RGB) image representations. In particular, we can acquire near-infrared (NIR) cues with only slight modification to any standard digital camera. In this paper, we study whether this extra channel can <b>improve</b> <b>semantic</b> image segmentation. Based on a state-of-the-art segmentation framework and a novel manually segmented image database that contains 4 -channel images (RGB+NIR), we study how to best incorporate the specific characteristics of the NIR response. We show that it leads to improved performances for 7 classes out of 10 in the proposed dataset and discuss the results {{with respect to the}} physical properties of the NIR response. ...|$|E
40|$|Current Chinese {{social media}} text {{summarization}} models {{are based on}} an encoder-decoder framework. Although its generated summaries are similar to source texts literally, they have low semantic relevance. In this work, {{our goal is to}} <b>improve</b> <b>semantic</b> relevance between source texts and summaries for Chinese social media summarization. We introduce a Semantic Relevance Based neural model to encourage high semantic similarity between texts and summaries. In our model, the source text is represented by a gated attention encoder, while the summary representation is produced by a decoder. Besides, the similarity score between the representations is maximized during training. Our experiments show that the proposed model outperforms baseline systems on a social media corpus. Comment: Accepted by AC...|$|E
40|$|The overall issue {{addressed}} in {{this paper is to}} <b>improve</b> <b>semantic</b> interoperability among and across agent systems. We propose to use explanation as a way to approach that aim. The explanation process is expressed in terms of an explanation ontology shared by the agents who participate to the explanation session. The explanation ontology is defined in a way general enough to support a variety of explanation mechanisms. The paper describes the explanation ontology and provides a working through example illustrating how the proposed generic ontology can be used to develop specific explanation mechanism. Finally, the ontology is being integrated into a running agent platform – Agora to demonstrate the practical usefulness of the approach. 1...|$|E
40|$|Abstract. The {{measuring}} of semantic similarity {{is the key}} {{technique in}} information retrieval. Based on the common semantic similarity algorithm between concepts, this paper makes use of semantic weighted distance and introduces such factors as node density, concept attribute and concept information content, and presents an <b>improved</b> <b>semantic</b> similarity algorithm to make the measuring semantic similarity more accurate. Through experimental calculation and analysis, the semantic similarity obtained from the improved algorithm can describe more accurately the similar relation between ontology concepts, and correspond to a higher degree with human subjective judgment...|$|R
40|$|Abstract: The {{tendency}} of current cataloguing systems is to interchange metadata in XML {{according to the}} specific standard required by each user on demand. Furthermore, metadata schemas from different domains are not usually semantically distinct but overlap and {{relate to each other}} in complex ways. As a consequence, the semantic interoperability has to deal with the equivalences between those descriptions. There exist two main approaches in order to tackle this problem: solutions on the use of ontologies and solutions based on the creation of specific crosswalks for one-to-one mapping. This paper proposes a hierarchical one-to-one mapping solution for <b>improving</b> <b>semantic</b> interoperability...|$|R
40|$|Abstract. Subjective {{question}} {{marking system}} at present {{is affected by}} the attention of people, the subjective topic grading principles are common contrast degree of exam questions {{similar to those of the}} reference answer, and based on the <b>improved</b> <b>semantic</b> similarity algorithm, calculation of sentence similarity, the similarity degree of exam questions and reference answer is obtained, thus give scores. And design based on semantic similarity experiment, the experiment results show that the proposed multi-level fusion similarity calculation method to improve the original method, on the basis of integration advantages of various methods, make the calculation results meet the requirements of the scoring system...|$|R
40|$|Since 1990 CEN TC 251 and ISO TC 215 have {{developed}} an approach named Categorial Structure. It is a logic-based language that aims at standardising the upper level structure of a terminological model rather than agreeing on a reference clinical terminology or on a language-independent biomedical ontology. Since 2000 methods, tools and techniques based on upper level ontology and description logic formalism have been developed in the Semantic Web and the bio-ontology communities. The objective {{of this paper is}} to analyse the relation between the two approaches in order to promote the complementary use of ontology and structured information model tools in the harmonisation between biomedical terminologies and to <b>improve</b> <b>semantic</b> interoperability. ...|$|E
40|$|Robust {{semantic}} {{labeling of}} image regions {{is a basic}} problem in representing and retrieving image/video content. We propose an SVM-MRF framework to model features and their spatial distributions, leading towards a “semantic ” representation. Eigenfeatures of Gabor wavelet features and Gaussian mixture model are used for feature clustering. Since similar feature vectors in one cluster can come from several different semantic classes, SVM is applied to represent conditioned feature vector distributions within each cluster, and a Markov random field is used to model the spatial distributions of the semantic labels. A semantic layout representation is proposed to describe the semantics of the images. Experiments show that this method can <b>improve</b> <b>semantic</b> labeling and is useful in similarity search. 1...|$|E
40|$|Non-verbal {{modalities}} such as gesture {{can improve}} processing of spontaneous spoken language. For example, similar hand gestures tend to predict semantic similarity, so features that quantify gestural similarity can <b>improve</b> <b>semantic</b> {{tasks such as}} coreference resolution. However, not all hand movements are informative gestures; psychological {{research has shown that}} speakers are more likely to gesture meaningfully when their speech is ambiguous. Ideally, one would attend to gesture only in such circumstances, and ignore other hand movements. We present conditional modality fusion, which formalizes this intuition by treating the informativeness of gesture as a hidden variable to be learned jointly with the class label. Applied to coreference resolution, conditional modality fusion significantly outperforms both early and late modality fusion, which are current techniques for modality combination. ...|$|E
40|$|The {{importance}} of interoperability among computer systems has been progressively increasing {{over the last}} years. The tendency of current cataloguing systems is to interchange metadata in XML according to the specific standard required by each user on demand. According to the research literature, {{it seems that there}} exist two main approaches in order to tackle this problem: solutions that are based on the use of ontologies and solutions that are based on the creation of specific crosswalks for one-to-one mapping. This paper proposes a hierarchical one-to-one mapping solution for <b>improving</b> <b>semantic</b> interoperability. Keywords: Metadata standards, metadata servers, catalogu...|$|R
40|$|Background: Hyperlexia is a super ability {{demonstrated}} {{by a very}} specific group of individuals with developmental disorders. This term is {{used to describe the}} children with high ability in word recognition, but low reading comprehension skills, despite the problems in language, cognitive and social skills. The {{purpose of this study was}} to assess the effectiveness of <b>improving</b> the <b>semantic</b> aspect of language (increase in understanding and expression vocabulary) on reading comprehension in an autistic child with hyperlexia. Case: The child studied in this research was an autistic child with hyperlexia. At the beginning of this study he was 3 years and 11 months old. He could read, but his reading comprehension was low. In a period of 12 therapy session, understanding and expression of 160 words was taught to child. During this period, the written form of words was eliminated. After these sessions, the reading comprehension was re-assessed for the words that child could understand and express. Conclusion: <b>Improving</b> <b>semantic</b> aspect of language (understanding and expression of vocabulary) increase reading comprehension of written words...|$|R
40|$|Contextual {{information}} {{is crucial for}} semantic segmentation. However, finding the optimal trade-off between keeping desired fine details {{and at the same}} time providing sufficiently large receptive fields is non trivial. This is even more so, when objects or classes present in an image significantly vary in size. Dilated convolutions have proven valuable for semantic segmentation, because they allow to increase the size of the receptive field without sacrificing image resolution. However, in current state-of-the-art methods, dilation parameters are hand-tuned and fixed. In this paper, we present an approach for learning dilation parameters adaptively per channel, consistently <b>improving</b> <b>semantic</b> segmentation results on street-scene datasets like Cityscapes and Camvid. Comment: GCPR 201...|$|R
