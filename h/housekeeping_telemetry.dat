16|13|Public
50|$|The {{satellite}} provided {{ocean and}} land surface data. It orbited at 541 x 557 km with inclination of 50.7°.One of two onboard cameras malfunctioned, however it sent {{back more than}} two thousand images. <b>Housekeeping</b> <b>telemetry</b> was received until re-entry in 1991.|$|E
5000|$|Provide a low-rate {{data link}} (LRDL) {{interface}} to ISS to accept commands for the ELC and the resident experiments. The ExPCA is implemented as a remote terminal (RT) on the MIL-STD-1553 [...] "ISS local bus." [...] This interface also returns <b>housekeeping</b> <b>telemetry</b> from the ExPCA and resident experiments to the ISS.|$|E
50|$|Landsat 4 is {{the fourth}} {{satellite}} of the Landsat program. It was launched on July 16, 1982, with {{the primary goal of}} providing a global archive of satellite imagery. Although the Landsat Program is managed by NASA, data from Landsat 4 was collected and distributed by the U.S. Geological Survey. Landsat 4 science operations ended on December 14, 1993 when the satellite lost its ability to transmit science data, far beyond its designed life expectancy of five years. The satellite <b>housekeeping</b> <b>telemetry</b> and tracking continued to be maintained by NASA until it was decommissioned on June 15, 2001.|$|E
40|$|To meet {{challenging}} {{constraints on}} telemetry system weight and volume, a custom Light-Weight Instrumentation System {{was developed to}} collect vehicle environment and dynamics on a short-duration exo-atmospheric flight test vehicle. The total telemetry system, including electronics, sensors, batteries, and a 1 watt transmitter weighs about 1 kg. Over 80 channels of measurement, <b>housekeeping,</b> and <b>telemetry</b> system diagnostic data are transmitted at 128 kbps. The microcontroller-based design uses the automotive industry standard Controller Area Network to interface with and support in-flight control fimctions. Operational parameters are downloaded via a standard asynchronous serial communications intefiace. The basic design philosophy and functionality is described here...|$|R
40|$|For any {{scientific}} space mission, <b>Housekeeping</b> and Science <b>Telemetry</b> are {{two different}} kinds of data with different scope and structure; therefore a different approach is needed in their analysis. Here we will describe the rationale {{in the case of}} the Planck/LFI project and what was designed and developed to create the analysis and testing environment. Key words. Space vehicles – Methods: data analysis – Telemetry – 1...|$|R
40|$|International Telemetering Conference Proceedings / October 25 - 28, 1999 / Riviera Hotel and Convention Center, Las Vegas, NevadaTo meet {{challenging}} {{constraints on}} telemetry system weight and volume, a custom Light-Weight Instrumentation System {{was developed to}} collect vehicle environment and dynamics on a short-duration exo-atmospheric flight test vehicle. The total telemetry system, including electronics, sensors, batteries, and a 1 watt transmitter weighs about 1 kg. Over 80 channels of measurement, <b>housekeeping,</b> and <b>telemetry</b> system diagnostic data are transmitted at 128 kbps. The microcontroller-based design uses the automotive industry standard Controller Area Network to interface with and support in-flight control functions. Operational parameters are downloaded via a standard asynchronous serial communications interface. The basic design philosophy and functionality is described here...|$|R
40|$|Abstract — This paper {{describes}} how a ferroelectric RAM from Ramtron {{has been used}} to increase the reliability of PiCPoT, a small satellite developed at Politecnico di Torino for educational purposes. It compares the FeRAM solution with respect to a FLASH one. The memories are used for saving <b>housekeeping</b> <b>telemetry</b> data while the satellite is far from the ground station. Due to the intrinsic radiation tolerance and the lower power consumption, FeRAM are very suitable for the application. I...|$|E
30|$|In {{previous}} scientific satellites, {{to acquire}} the data at the specified time from the data recorder, {{it was necessary to}} check the physical address corresponding to the time recorded in the <b>housekeeping</b> <b>telemetry</b> and set it as the command parameter of data acquisition. Meanwhile, the Earth observation satellite manages the data acquisition time by adding the time tag information (e.g., GPS time) to the data (Nakagawa 2010). By having similar functions, the MDR is specified to manage data with the time tag information.|$|E
40|$|Abstract. This paper {{describes}} the Space Control Centres use {{case of the}} CUBIST FP 7 project 3. It introduces the concept of telemetry and {{describes the}} format and {{the contents of the}} <b>housekeeping</b> <b>telemetry</b> of SOLAR, one of the payloads flying on board of the International Space Station (ISS). Further on, it discusses several approaches to conceptual analysis of space telemetry. It also gives an overview of conversion options into a form suitable for FCA and concludes with an outlook of the expected outcomes of the conceptual analysis of telemetry...|$|E
40|$|The Monitor Proportional Counter Instrument for the HEAO-B X-ray Telescope {{satellite}} {{is designed}} to observe celestial X-ray sources {{in the range of}} 1 to 20 keV with intensities exceeding. 0002 Crab. It provides both spectral and temporal data, to complement the data from the other HEAO-B instruments, to compare with observations from previous flights, as well as to allow detailed study of time variant X-ray phenomena. The basic detector is a large area proportional counter system, consisting of two counters, high voltage power supplies and preamplifiers, mounted behind a collimator with a 2 / 3 degree square field of view. The signal processing, power distribution and control electronics are contained in a separate unit, which includes circuitry to perform pulse height analysis, background rejection, time interval measurement, redundancy switching and control, <b>housekeeping</b> and <b>telemetry</b> interfacing...|$|R
50|$|Spacecraft {{commands}} are formatted {{according to}} the spacecraft database, and are validated against the database before being transmitted. Commands may be issued manually in real time, {{or they may be}} part of automated or semi-automated procedures. Typically, received commands are acknowledged in telemetry. In certain cases, closed-loop control may be performed. Commanded activities may pertain directly to mission objectives, or they may be part of <b>housekeeping.</b> Commands (and <b>telemetry)</b> may be encrypted to prevent unauthorized access to the spacecraft or its data.|$|R
40|$|A {{family of}} science {{enabling}} radiation hard Application Specific Integrated Circuits (ASICs), Front End Electronics (FEEs) and Event Processing Systems, with flight heritage on many NASA missions, is presented. These technologies {{play an important}} role in the miniaturization of instruments -and spacecraft systems- at the same time increasing performance and reducing power. The technologies target time of flight, position sensing, and energy measurements as well as standard <b>housekeeping</b> and <b>telemetry</b> functions for particle and fields instruments, but find applications in other instrument categories too. More specifically the technologies include: the TOF chip, 1 D and 2 D Delay Lines with MCP detectors, for high precision fast and low power time of flight and position sensing; the Energy chip for multichannel SSD readout with time over threshold and standard voltage read out for TDC and ADC digitization; Fast multi channel read out chip with commandable thresholds; the TRIO chip for multiplexed ADC and housekeeping etc. It should be mentioned that the ASICs include basic trigger capabilities to enable random event processing in a heavy background of penetrators and UV foreground. Typical instruments include time of flight versus energy and look angle particle analyzers such as: plasma composition, energetic particle, neutral atom imaging as well as fast plasma and deltaE/E ion/electron telescopes. Flight missions include: Cassini/LEMMS, IMAGE/HENA, MESSENGER/EPPS/MLA/X-ray/MLA, STEREO, PLUTO-NH/PEPSSI/LORI, IBEX-Lo, JUNO/JEDI, RBSP/RBSPICE, MMS/HPCA/EPD, SO/SIS. Given the proven capability on heavy radiation missions such as JUNO, MMS and RBSB, as well diverse long duration missions such as MESSENGER, PLUTO and Cassini, it is expected that these technologies will {{play an important role}} in the particle and fields (at least) instruments on the upcoming JUICE and JEO missions...|$|R
40|$|Centre (DPC) {{is devoted}} to the {{handling}} of scientific and <b>housekeeping</b> <b>telemetry.</b> It receives raw telemetry packets from the LFI through a tailored version of the ESA telemetry handling software SCOS 2000, and generates time ordered information of scientific and housekeeping data to be processed by the subsequent DPC levels. In addition, the Level 1 performs live diagnostics on the LFI telemetry. An end-to-end test has been performed recently at the LFI integration site (Alcatel Alenia Space, Milan) using the qualification model equipment of the on-board Data Acquisition Electronics and Data Processing unit, and its core software. For scientific data, the test is based on the injection of deterministic signals with known properties in the acquisition electronics and their comparison with the signal reconstructed from the telemetry data. A regression test has been performed on the housekeeping data by inserting known parameters values into a set of real housekeeping packets...|$|E
40|$|Access to <b>housekeeping</b> <b>telemetry</b> is {{recurrent}} {{throughout the}} whole life of a satellite. Flight control teams, spacecraft manufacturer engineers and subsystem experts are all interested in accessing telemetry parameters {{to make sure that}} the satellite is running nominally. This is usually fulfilled by a traditional web server embedded within the control centre which performs extraction and calibration of the raw telemetry. However, this centralized solution is usually available only at the beginning of the operations preparation. The raw telemetry which is produced outside the control centres, e. g. at the satellite supplier premises or on launch pads, is rarely exploited by experts who may miss useful information because of the lack of widespread extraction means. Hence the idea of developing a universal portable application called PrestoDecom offering the same facilities as those inside a control centre, allowing work on raw telemetry archives anywhere, especially when the control centre is inaccessible. This innovative software was successfully used in 2003 to validate the satellite simulator on the PROTEUS multiplatform project. PrestoDecom has been rapidly adopted inside CNES by a growing user community conquered by its simplicity and efficiency. Today 2 / 3 of CNES satellite projects have already invested into PrestoDecom an...|$|E
40|$|Usually, {{telemetry}} data is sampled {{at regular}} intervals. If better observability {{is required for}} certain parameters, they are sampled more often. This is not always possible due to bandwidth limitations between space and ground. A common practice to respect this limitation consists of reducing the sampling rate of other parameters so that certain parameters of interest can be monitored more closely. In this way it seems {{that it is not}} possible to increase the observability of some parameters without decreasing the observability of others. In order to provide more observability for the same or reduced bandwidth, the Fractal Resampling technique has been researched and developed at ESOC. The fractal resampling takes the original time series data samples and produces a set of fewer samples, not necessarily at regular intervals, that resembles the original time series while offering a configurable maximum error guarantee. With the proposed fractal resampling technique, it is possible to sample data at higher rates on-board and downlink only the data samples necessary to reconstruct the original signal with the desired level of accuracy with important data reductions. The fractal resampling not only enables more observability, but it also reduces bandwidth requirements. It has been applied to all <b>housekeeping</b> <b>telemetry</b> parameters of the ESA mission Rosetta; the results show that only 5. 52 % of the original data is needed if the 1 % of the original amplitude is used as allowed maximum error. I...|$|E
40|$|In August, 1998 a Clouds and the Earth's Radiant Energy System (CERES) {{instrument}} <b>telemetry</b> <b>housekeeping</b> parameter {{generated a}} yellow warning message that indicated an on-board + 15 V Data Acquisition Assembly (DAA) power converter deregulation anomaly. An exhaustive investigation was undertaken {{to understand this}} anomaly and the long-term consequences which have severely reduced CERES operations on the Tropical Rainfall Measuring Mission (TRMM) spacecraft. Among investigations performed were ground tests that approximated the on-board electronic circuitry using a small quantity of flight identical components exposed to maximum spacecraft bus over-voltage conditions. These components include monolithic integrated microcircuits that perform analog signal conditioning on instrument sensor signals and an analog- to-digital converter (ADC) for the entire DAA. All microcircuit packages have either a bipolar silicon design with internal current limiting protections or have a {{complementary metal oxide semiconductor}} (CMOS) design with bias protections. Ground tests that have been running for approximately 8 months have indicated that these components are capable of withstanding as much as twice their input supply voltage ratings without noticeable performance degradation. These data provide CERES operators with confidence of being able to continue science operations over the remaining life of the TRMM mission. This paper will discuss this anomaly and some possible causes, a simulator of affected electronics, test results, prognosis for future CERES operations, and conclusions...|$|R
40|$|We have {{developed}} a new compact balloon payload called LITOS (Leibniz-Institute Turbulence Observations in the Stratosphere) for high resolution wind turbulence soundings in the stratosphere up to 35 km altitude. The wind measurements are performed using a constant temperature anemometer (CTA) with a vertical resolution of ~ 2. 5 mm, i. e. 2 kHz sampling rate at 5 m/s ascent speed. Thereby, for the first time, {{it is possible to}} study the entire turbulence spectrum down to the viscous subrange in the stratosphere. Including <b>telemetry,</b> <b>housekeeping,</b> batteries and recovery unit, the payload weighs less than 5 kg and can be launched from any radiosonde station. Since autumn 2007, LITOS has been successfully launched several times from the Leibniz-Institute of Atmospheric Physics (IAP) in Kühlungsborn, Germany (54 ° N, 12 ° E). Two additional soundings were carried out in 2008 and 2009 in Kiruna, Sweden (67 ° N, 21 ° E) as part of the BEXUS program (Balloon-borne EXperiments for University Students). We describe here the basic principle of CTA measurements and prove the validity of this method in the stratosphere. A first case study allows a clear distinction between non-turbulent regions and a turbulent layer with a thickness of some tens of meters. Since our measurements cover the transition between the inertial and viscous subrange, energy dissipation rates can be calculated with high reliability...|$|R
40|$|The {{design of}} a {{communications}} relay to provide constant access between the Earth and {{the far side of}} the Moon is presented. Placement of the relay in a halo orbit about the L 2 Earth-Moon Lagrange point allows the satellite to maintain constant simultaneous communication between Earth and scientific payloads on {{the far side of the}} Moon. The requirements of NASA's Discovery-class missions adopted and modified for this design are: total project cost should not exceed $ 150 million excluding launch costs, launch must be provided by Delta-class vehicle, and the satellite should maintain an operational lifetime of 10 to 15 years. The spacecraft will follow a transfer trajectory to the L 2 point, after launch by a Delta II 7925 vehicle in 1999. Low-level thrust is used for injection into a stationkeeping-free halo orbit once the spacecraft reaches the L 2 point. The shape of this halo orbit is highly elliptical with the maximum excursion from the L 2 point being 35000 km. A spun section and despun section connected through a bearing and power transfer assembly (BAPTA) compose the structure of the spacecraft. Communications equipment is placed on the despun section to provide for a stationary dual parabolic offset-feed array antenna system. The dual system is necessary to provide communications coverage during portions of maximum excursion on the halo orbit. Transmissions to the NASA Deep Space Network 34 m antenna include six channels (color video, two voice, scientific data from lunar payloads, satellite <b>housekeeping</b> and <b>telemetry</b> and uplinked commands) using the S- and X-bands. Four radioisotope thermoelectric generators (RTG's) provide a total of 1360 W to power onboard systems and any two of the four Hughes 13 cm ion thrusters at once. Output of the ion thrusters is approximately 17. 8 mN each with xenon as the propellant. Presence of torques generated by solar pressure on the antenna dish require the addition of a 'skirt' extending from the spun section of the satellite for balance. Total mass of the satellite is approximately 900 kg at a cost of $ 130 million FY 99...|$|R
40|$|One way of {{estimating}} the information {{content of a}} message is to compress it. Previous papers {{have shown that the}} information content of <b>housekeeping</b> <b>telemetry</b> packets is quite low as when they are stored in files they compress extremely well. Compressing packets and sending more of them in the same bandwidth would improve the information content of the data stream. This would bring benefits in terms of better reaction times and better spacecraft observability as well as reducing the upfront engineering effort. So far all methods proposed work on housekeeping data that has been stored on-board for transmission to the ground at some later point. This paper presents a method for compressing packets in real-time i. e. each individual packet is compressed into an equivalent smaller packet as soon as it is generated. This opens up the possibility of increasing the information content of both the playback and real-time telemetry streams with a unique process at generation time. Note that compression algorithms like ZIP cannot do this. They require a critical number of packets to be stored before the compression algorithm can be effective. This paper describes the tests run at ESA/ESOC using real spacecraft data to prove the concept. Compression ratios of ten are sometimes achieved i. e. an increase in information content of over 1000 %. Only a few microseconds are needed to compress a typical packet making it suitable for real-time. The method has been tested with data from spacecraft in different environments (including safe mode) and they have shown that the compression performance is very stable. ESA has recently filed an international patent covering the method. I...|$|E
30|$|Each AUTUMNX GBO gathers nearly 2.7 MB of {{raw data}} per day, or {{approximately}} 84 MB/month. The data gathering software logs the raw magnetic data in THEMIS GMAG binary format {{to the local}} disk while also transmitting it and housekeeping data via the lightweight UDP protocol. Taking into account network overhead and the data collection program’s UDP-based real-time telemetry transmission, a 500 MB/month data plan is more than adequate to service a typical AUTUMNX GBO site. The AUTUMNX data repository at Athabasca University ([URL] downloads accumulated data from each AUTUMNX station every hour or less using the rsync file transfer program, which has redundancy and ability to ensure that requested data is eventually obtained. Each AUTUMNX station continuously uploads current data and <b>housekeeping</b> <b>telemetry</b> every 10 seconds back to the AUTUMNX repository {{in the form of}} UDP datagrams, thus providing real time data reporting capabilities. The northern network infrastructure and the UDP protocol as a whole are not reliable, meaning that data packets may not arrive due to the network temporarily going down or other conditions. In the event that the network goes down, ground magnetic data continues to log to local disk provided there is electricity to power the control computer and magnetometer. The uninterruptable power supply (UPS) can maintain electric supply for several hours, ensuring continuity of data gathering function. Real time data and telemetry are lost during an outage, but rsync transfers resume once Internet is restored. Rsync resumes downloading the data that accumulated during the power or network outage, thus no data will be lost. Data loss was a problem with older magnetometer data collection systems like CANOPUS, which did not use local data storage (Mann et al. 2008).|$|E
40|$|The Level 1 of the Planck LFI Data Processing Centre (DPC) {{is devoted}} to the {{handling}} of the scientific and <b>housekeeping</b> <b>telemetry.</b> It is a critical component of the Planck ground segment which has to strictly commit to the project schedule to be ready for the launch and flight operations. In order to guarantee the quality necessary to achieve the objectives of the Planck mission, the design and development of the Level 1 software has followed the ESA Software Engineering Standards. A fundamental step in the software life cycle is the Verification and Validation of the software. The purpose of this work is to show an example of procedures, test development and analysis successfully applied to a key software project of an ESA mission. We present the end-to-end validation tests performed on the Level 1 of the LFI-DPC, by detailing the methods used and the results obtained. Different approaches have been used to test the scientific and housekeeping data processing. Scientific data processing has been tested by injecting signals with known properties directly into the acquisition electronics, in order to generate a test dataset of real telemetry data and reproduce as much as possible nominal conditions. For the HK telemetry processing, validation software have been developed to inject known parameter values into a set of real housekeeping packets and perform a comparison with the corresponding timelines generated by the Level 1. With the proposed validation and verification procedure, where the on-board and ground processing are viewed as a single pipeline, we demonstrated that the scientific and housekeeping processing of the Planck-LFI raw data is correct and meets the project requirements. Comment: 20 pages, 7 figures; this paper is part of the Prelaunch status LFI papers published on JINST: [URL]...|$|E
40|$|The Advanced Land Imager Assessment System (ALIAS) {{supports}} radiometric and {{geometric image}} processing for the Advanced Land Imager (ALI) instrument onboard NASA s Earth Observing- 1 (EO- 1) satellite. ALIAS {{consists of two}} processing subsystems for radiometric and geometric processing of the ALI s multispectral imagery. The radiometric processing subsystem characterizes and corrects, where possible, radiometric qualities including: coherent, impulse; and random noise; signal-to-noise ratios (SNRs); detector operability; gain; bias; saturation levels; striping and banding; and the stability of detector performance. The geometric processing subsystem and analysis capabilities support sensor alignment calibrations, sensor chip assembly (SCA) -to-SCA alignments and band-to-band alignment; and perform geodetic accuracy assessments, modulation transfer function (MTF) characterizations, and image-to-image characterizations. ALIAS also characterizes and corrects band-toband registration, and performs systematic precision and terrain correction of ALI images. This system can geometrically correct, and automatically mosaic, the SCA image strips into a seamless, map-projected image. This system provides a large database, which enables bulk trending for all ALI image data and significant instrument telemetry. Bulk trending consists of two functions: Housekeeping Processing and Bulk Radiometric Processing. The <b>Housekeeping</b> function pulls <b>telemetry</b> and temperature information from the instrument housekeeping files and writes this information to a database for trending. The Bulk Radiometric Processing function writes statistical information from the dark data acquired {{before and after the}} Earth imagery and the lamp data to the database for trending. This allows for multi-scene statistical analyses...|$|R
40|$|The Planck Low Frequency Instrument (LFI) will {{observe the}} Cosmic Microwave Background (CMB) by {{covering}} the frequency range 30 - 70 GHz in three bands. The primary instrument data source are the temperature samples {{acquired by the}} 22 radiometers mounted on the Planck focal plane. Such samples represent the scientific data of LFI. In addition, the LFI instrument generates the so called housekeeping data by sampling regularly the on-board sensors and registers. The housekeeping data provides information on the overall health status of the instrument and on the scientific data quality. The scientific and housekeeping data are collected on-board into telemetry packets compliant with the ESA Packet Telemetry standards. They represent the primary input to the first processing level of the LFI Data Processing Centre. In this work we show the software systems which build the LFI Level 1. A real-time assessment system, based on the ESA SCOS 2000 generic mission control system, has {{the main purpose of}} monitoring the housekeeping parameters of LFI and detect possible anomalies. A telemetry handler system processes the <b>housekeeping</b> and scientific <b>telemetry</b> of LFI, generating timelines for each acquisition chain and each housekeeping parameter. Such timelines represent the main input to the subsequent processing levels of the LFI DPC. A telemetry quick-look system allows the real-time visualization of the LFI scientific and housekeeping data, by also calculating quick statistical functions and fast Fourier transforms. The LFI Level 1 has been designed to support all the mission phases, from the instrument ground tests and calibration to the flight operations, and developed according to the ESA engineering standards. Comment: This paper is part of the Prelaunch status LFI papers published on JINST: [URL]...|$|R
40|$|Until the TEXUS- 42 (EML- 1) project, {{successfully}} {{launched in}} Dec. 2005, the payload of the TEXUS and the MAXUS were {{equipped with the}} former Kayser-Threde 12 bit based PCM data acquisition system. To fulfill experimental requirements for higher data resolution and the intention to reduce weight and also to improve {{the performance of the}} service module, ESA has taken initiative to contract industry for the development and built up of a new data acquisition system and the new TEXUS Service Module (TSM) in 2004. For the design, manufacturing and qualification task sharing, a cooperation of DLR Moraba and the Kayser-Threde GmbH has been initialized. With respect to the compatibility of already existing experiment modules, Kayser-Threde has developed, manufactured and qualified the decentralized 16 bit CTS 3000 (Compact Telemetry System) data acquisition system and together with DLR Moraba the TSM. In order to improve existing systems and to comply with new requirements the DLR/Moraba has designed a new power distribution and a GPS system. The TSM is incorporating all known standard features, modern technologies and is capable of serving actual and future experiment requirements. The TSM provides flexibility for future implementation of up to two digital TV respectively TM down links besides the three standard analog TV down links. The design implies economic technical concepts consuming a minimum of service module mass and length. The service module acquires and transmits all experimental and service system <b>housekeeping</b> data via <b>telemetry</b> transmitter to ground. Commands to the service system and for experiment control are received with a dedicated diversity system from the ground station and distributed onboard. Furthermore three TV down links, 3 -axis micro-g and acceleration measurement as well as a rate control (RCS) and a GPS system are incorporated. The TSM is integrated within a standard TEXUS cylindrical structure with Radax flanges on both ends. Most of the components are assembled on the instrumentation deck, which is fixated via shock mounts to the outer structure. All electronic boards for TM/TC, RCS, power switching, sequencing, μ-g measurement and housekeeping are integrated and wired within one...|$|R
40|$|International Telemetering Conference Proceedings / November 04 - 07, 1991 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe Telemetry Test Station {{has been}} {{developed}} at the Digital Systems Division, ISRO Satellite Centre, to test the <b>housekeeping</b> <b>telemetry</b> packages which will be flown onboard satellites. The heart of the test procedure is the decommutation, display and processing of the telemetry output format. The decommutation has been achieved by designing a simple plug in card to an IBM PC/XT compatible computer and writing the related assembly language software. The card and the software have been extensively tested and found to work satisfactorily upto 60 Kbps PCM data rate. To make the hardware and software flexible and truly general purpose, the acquisition should be independent of the modes of operation and data formats. All the parameters which define acquisition display and processing are therefore programmable and can be changed at any time. The parameters which influence acquisition are bit rate, word rate, frame rate, length of word, length of frame and frame synchronous code. The bit rate is transparent, i. e., need not be set by the user. The word length {{is assumed to be}} 8 bits or multiples of 8 bits. The other parameters are programmable {{at any time during the}} test session. Similarly, the parameters which affect display are the display rate, and positioning of the format including highlighting, alarm signals, related information etc. This gives a user the facility to tailor the display to his liking. The storage is also flexible and independent of display. All these modes are in real time and have therefore been coded in assembly. It has been found that a large part of the software is needed for user interface alone and user requirement is far more changeable than expected. The software is therefore designed for change. The problems and solutions in achieving these features are discussed in this paper...|$|E
40|$|The European Space Agency (ESA) and its European {{industry}} partners generate {{every year}} many new and innovative ideas for advancing European space technology regarding mission operations. On this basis, arises {{the idea of}} designing the ESA POCKET compression algorithm for satellites <b>housekeeping</b> <b>telemetry,</b> intended {{to be one of}} the experiments that will be validated in the OPS-SAT Mission. OPS-SAT is the first CubeSat designed by ESA, providing a low cost in-orbit laboratory available for authorised experimenters to test, demonstrate and validate their development software experiments. It will be available for experimenters wishing to test and demonstrate new software and mission operation concepts such as the ESA POCKET compression algorithm. ESA POCKET is a new method for compressing packets in real-time i. e. each individual packet is compressed into an equivalent smaller packet as soon as it is generated. This cannot be done by compression algorithms such as ZIP, since they require a critical number of packets to be stored before the compression algorithm can be effective. ESA POCKET is designed to be a software plug-in that is added just after each packet is generated. Another software plug-in is added just before the mission control system to intercept the compressed packets and expand them before arriving to the operators, to whom the disturbance is minimal since they do not notice it at all and thus all normal operations concepts can be applied. ESA POCKET aims at using compression to reduce the bandwidth consumed by housekeeping data, which can then be used instead for additional science data or for saving memory space, downlink time and downlink power. Thus, this opens up the possibility of increasing the information content. Moreover, as it works on single packets it can be applied only when needed, introducing much more flexibility into this chain and therefore, reducing preparation and operations costs. Besides OPS-SAT, for all its advantages and the successful performance results, ESA POCKET has been selected to fly also on the ESA Mission Proba- 3 and it considered as well for the TIA Mission Electra and for future UAV control systems...|$|E
40|$|In {{order to}} {{understand}} and mitigate the effects of space weather {{on the performance of}} geostationary (GEO) communications satellites, we analyze 16 years of archived telemetry data from Inmarsat, the UK-based telecommunications company. We compare 665, 112 operational hours of <b>housekeeping</b> <b>telemetry</b> from two generations of satellites, designated as Fleet A and Fleet B. Each generation experienced 13 solid-state power amplifier (SSPA) anomalies for a total of 26 anomalies from 1996 to 2012. We compare telemetry from the Inmarsat anomalies with space weather observations, including data from the OMNI 2 database, Geostationary Operational Environmental Satellites, the Advanced Composition Explorer Satellite, and Los Alamos National Laboratory (LANL) GEO observations; the evolution of the sunspot number; and the Kp index. Most SSPA anomalies for Fleet A occur as solar activity declines; Fleet B has not yet experienced a full solar cycle. For both fleets, the average value of Kp remained < 2 over time periods of 2 days, 3 days, and 2 weeks around the time of anomaly, which suggests that the anomalies occurred at times of relatively quiet geomagnetic activity and that they were probably not solely caused by surface charging. From 1996 to 2009, the average of the 1. 8 - 3. 5 MeV electron flux was 1. 98 #/(cm(2) s st keV). Five of the 26 anomalies, unfortunately, do not have corresponding science observations (specifically, electron flux data in the LANL data set), so part of this study focuses on the 21 anomalies when science observations were available. Six out of 21 anomalies experienced a high-energy electron flux greater than 1. 5 standard deviations above the mean of the log(10) of the flux between 7 and 14 days prior to the anomaly. By contrast, a Monte Carlo simulation finds that on average, only 2. 8 out of 21 (13 %) of randomly assigned anomalies occur between 7 and 14 days after an electron flux greater than 1. 5 standard deviations above the mean. Our observations suggest that internal charging from either past elevated radiation belt fluxes or some conditions related to relativistic electron enhancements (either causally or accidentally) is most likely responsible for the SSPA anomalies. We next consider the timing of these anomalies with respect to the local time (LT) and season. Anomalies occur at all LT sectors with 46 % (Fleet A) and 38. 5 % (Fleet B) in the midnight to dawn sector and 54 % (Fleet A) and 46 % (Fleet B) in the local noon to dusk sector. From the local time distribution, surface charging {{does not appear to be}} the sole causative agent of the anomalies. Understanding the connection between the space weather conditions and anomalies on subsystems and specific components on identical and similar geostationary communications satellites for periods of time longer than a solar cycle will help guide design improvements and provide insight on their operation during space weather events...|$|E
40|$|International Telemetering Conference Proceedings / October 28 - 31, 1996 / Town and Country Hotel and Convention Center, San Diego, CaliforniaThe Mission Operations Center (MOC) at APL is {{the first}} {{processing}} link in the MSX data system. Two key components of the MOC that {{play a role in}} the telemetry acquisition and processing functions are the Mission Control Center (MCC) and the Mission Processing Center (MPC). This paper will present a summary of the telemetry acquisition and data processing structure built to handle the high volume of MSX data and the unique hardware and software systems to perform these functions. The primary responsibility of the MCC is to maintain the health and safety of the MSX spacecraft. This is accomplished by communicating with the spacecraft through the APL stations and the AFSCN. The MCC receives the spacecraft <b>housekeeping</b> 16 Kb <b>telemetry</b> stream and commands the spacecraft via the 2 K command link. Due to the complexity of the spacecraft various analysis tools exist to evaluate the spacecraft health and to generate commands for controlling the spacecraft. The primary responsibility of the MPC is the initial processing of the 1 Mb and 25 Mb spacecraft science telemetry streams. The science data is recorded in a raw format, both analog and digital, and a digital 8 mm tape format, Level 1 A tape, which serves the MSX program as the transport media and format for science data dissemination. The MPC also collects downlink data from the MCC and planning products from the Operations Planning Center for inclusion on the Level 1 A tape to enable the MSX data community to analysis the data. This data is sent electronically to the MPC via a LAN. One of the key products provided on the Level 1 A tape from the MCC is a measure of the spacecraft clock against time standards. The MPC consists of a hardware front end for the capture and formatting of the science data and a computer system for the processing of the formatted science data to produce Level 1 A tapes. The hardware front end includes wideband analog recorders, decryption devices, data selectors, bit sync, and frame syncs. One of the unique features of the 25 Mb telemetry stream is that is transmitted to the ground in the reverse direction. The MPC must then reverse the data again which is accomplished via analog recorders in order to perform further processing. The computer system consists of three model VAX 4000 computers with 107 Gb of disk space and 12 8 mm tape drives. One VAX is task with reading the 25 Mb telemetry onto the disk. The second VAX reads to the 1 Mb telemetry onto the disk and produces a digital 8 mm tape of the raw data. The third VAX is tasks with processing the data and writing the Level 1 A tapes. The systems architecture is such that while today's data is being downlinked yesterday's data is being processed and written to Level 1 A tapes. Custom software was developed to perform the processing and data management within the MPC...|$|R

