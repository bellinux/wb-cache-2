1860|368|Public
5|$|A nonzero scalar {{multiple}} of an <b>identity</b> <b>matrix</b> {{is called a}} scalar matrix. If the matrix entries come from a field, the scalar matrices form a group, under matrix multiplication, that is isomorphic to the multiplicative group of nonzero elements of the field.|$|E
5|$|Constant elasticities {{can predict}} optimal pricing only by {{computing}} point elasticities at several points, {{to determine the}} price at which point elasticity equals -1 (or, for multiple products, the set of prices at which the point elasticity matrix is the negative <b>identity</b> <b>matrix).</b>|$|E
5|$|Although {{there exist}} {{polynomial}} time algorithms {{to find a}} matrix having given row and column sums, the solution may be far from unique: any submatrix {{in the form of}} a 22 <b>identity</b> <b>matrix</b> can be complemented without affecting the correctness of the solution. Therefore, researchers have searched for constraints on the shape to be reconstructed that can be used to restrict the space of solutions. For instance, one might assume that the shape is connected; however, testing whether there exists a connected solution is NP-complete. An even more constrained version that is easier to solve is that the shape is orthogonally convex: having a single contiguous block of squares in each row and column.|$|E
3000|$|... are <b>identity</b> <b>matrices.</b> Also {{assume that}} the source {{covariance}} <b>matrices</b> are also <b>identity</b> <b>matrices</b> (i.e., [...]...|$|R
2500|$|... where I'm and I'n are the [...] and [...] <b>identity</b> <b>matrices,</b> respectively.|$|R
5000|$|Compute {{the matrix}} [...] (here the 's are {{appropriately}} sized <b>identity</b> <b>matrices).</b>|$|R
25|$|A is column-equivalent to the n-by-n <b>identity</b> <b>matrix</b> In.|$|E
25|$|Because h is the {{imaginary}} unit, {{each of these}} three arrays has a square equal to the negative of the <b>identity</b> <b>matrix.</b>|$|E
25|$|An N×N unitary matrix (that is, {{a matrix}} V such that VV†=I, where V† is the {{conjugate}} transpose of V and I is the <b>identity</b> <b>matrix)</b> requires N2 real parameters to be specified.|$|E
5000|$|... where Im and In are the m × m and n × n <b>identity</b> <b>matrices,</b> respectively.|$|R
3000|$|... the GA-based {{procedure}} is initialized by a constant-value population. In particular, the <b>identity</b> <b>matrices</b> {{have been chosen}} for initialization.|$|R
2500|$|... {{where the}} {{subscripts}} on the <b>identity</b> <b>matrices</b> {{are there to}} keep in mind that they are of different dimensions. Define ...|$|R
25|$|When unit weights {{are used}} (W = I, the <b>identity</b> <b>matrix),</b> it is {{implied that the}} {{experimental}} errors are uncorrelated and all equal: M = σ2I, where σ2 is the a priori variance of an observation.|$|E
25|$|By definition, 1 is the magnitude, {{absolute}} value, or norm {{of a unit}} complex number, unit vector, and a {{unit matrix}} (more usually called an <b>identity</b> <b>matrix).</b> Note that the term unit matrix is sometimes used to mean something quite different.|$|E
25|$|To see this, {{look at the}} set of {{invertible}} square matrices of a given dimension, over a given field. Now it {{is straightforward}} to verify closure, associativity, and inclusion of identity (the <b>identity</b> <b>matrix)</b> and inverses. However, matrix multiplication is not commutative, therefore this group is nonabelian.|$|E
30|$|We {{compare the}} error rate {{performance}} of the SMARC-JNCC with the outage probability limit and the tighter lower bound, which are presented in Section ‘Lower bound for the WER’, and with standard network coding techniques (using <b>identity</b> <b>matrices</b> in HGLNC) and a layered network construction (also using <b>identity</b> <b>matrices</b> in HGLNC, and where, at the destination, the network code is only decoded after decoding all point-to-point codewords separately and taking a hard decision).|$|R
5000|$|Matrix: 3 {{editable}} tables, preset 2x2 and 3x3 <b>identity</b> <b>matrices,</b> matrix arithmetic (addition, subtraction, scalar/vector multiplication, matrix-vector multiplication (vector {{interpreted as}} column)) ...|$|R
2500|$|... {{in which}} the [...] "matrix" [...] {{expression}} is simply not a valid one. [...] Note, however, that if scalar multiples of <b>identity</b> <b>matrices</b> ...|$|R
25|$|The {{absolute}} {{value of the}} determinant together with the sign becomes the oriented area of the parallelogram. The oriented area {{is the same as}} the usual area, except that it is negative when the angle from the first to the second vector defining the parallelogram turns in a clockwise direction (which is opposite to the direction one would get for the <b>identity</b> <b>matrix).</b>|$|E
25|$|The {{geometrical}} {{operation of}} {{moving from a}} basic feasible solution to an adjacent basic feasible solution is implemented as a pivot operation. First, a nonzero pivot element is selected in a nonbasic column. The row containing this element is multiplied by its reciprocal to change this element to 1, and then multiples of the row {{are added to the}} other rows to change the other entries in the column to 0. The result is that, if the pivot element is in row r, then the column becomes the r-th column of the <b>identity</b> <b>matrix.</b> The variable for this column is now a basic variable, replacing the variable which corresponded to the r-th column of the <b>identity</b> <b>matrix</b> before the operation. In effect, the variable corresponding to the pivot column enters the set of basic variables and is called the entering variable, and the variable being replaced leaves the set of basic variables and is called the leaving variable. The tableau is still in canonical form but with the set of basic variables changed by one element.|$|E
25|$|An Hadamard {{matrix of}} size m is an m × m matrix H whose entries are ±1 such that HH⊤ =mIm, where H⊤ is the {{transpose}} of H and Im is the m×m <b>identity</b> <b>matrix.</b> An Hadamard matrix {{can be put}} into standardized form (that is, converted to an equivalent Hadamard matrix) where the first row and first column entries are all +1. If the size m>2 then m must be a multiple of 4.|$|E
3000|$|... {{denotes the}} <b>identity</b> <b>matrices,</b> 0 i,j is an i×j matrix {{containing}} zeros, and w is a generic diagonal matrix {{that contains the}} N+L coefficients of a time window function.|$|R
3000|$|... and I are the Fisher {{information}} and <b>identity</b> <b>matrices,</b> respectively [30]. It {{ensures that the}} estimator not only converges to the unknown parameter, but it converges fast enough at a rate [...]...|$|R
30|$|To {{impose the}} root-LDPC structure, it is {{necessary}} simply to initialize the graph with root-check connections, which appear as the <b>identity</b> <b>matrices</b> in the parity-check matrix of the code, and to ensure no additional edge placement is made either in the <b>identity</b> <b>matrices</b> or the null matrices specified by the root-LDPC structure. This is achieved in the PEG algorithm by modification of the indicator vector presented in [10]. Zeros in the indicator vectors, as presented in the following section, exclude check nodes from the expanded tree of the PEG algorithms and this exclude edge placement connecting to those check nodes.|$|R
25|$|The Jones matrix due to {{passage through}} a {{transparent}} material {{is dependent on}} the propagation distance as well as the birefringence. The birefringence (as well as the average refractive index) will generally be dispersive, that is, it will vary as a function of optical frequency (wavelength). In the case of non-birefringent materials, however, the 2×2 Jones matrix is the <b>identity</b> <b>matrix</b> (multiplied by a scalar phase factor and attenuation factor), implying no change in polarization during propagation.|$|E
25|$|If G is a group, the Whitehead group Wh(G) {{is defined}} {{to be the}} cokernel of the map G × {±1} → K1(Z) which sends (g,±1) to the {{invertible}} (1,1)-matrix (±g). Here Z is the group ring of G. Recall that the K-group K1(A) of a ring A {{is defined as the}} quotient of GL(A) by the subgroup generated by elementary matrices. The group GL(A) is the direct limit of the finite-dimensional groups GL(n, A) → GL(n+1, A); concretely, the group of invertible infinite matrices which differ from the <b>identity</b> <b>matrix</b> in only a finite number of coefficients. An elementary matrix here is a transvection: one such that all main diagonal elements are 1 and there is at most one non-zero element not on the diagonal. The subgroup generated by elementary matrices is exactly the derived subgroup, in other words the smallest normal subgroup such that the quotient by it is abelian.|$|E
25|$|In {{this step}} all {{or a group}} of the identities between two {{sequences}} are found using a look up table. The kmer value determines how many consecutive identities are required for a match to be declared. Thus the lesser the kmer value: the more sensitive the search. kmer=2 is frequently taken by users for protein sequences and kmer=4 or 6 for nucleotide sequences. Short oligonucleotides are usually run with kmer= 1. The program then finds all similar local regions, represented as diagonals of a certain length in a dot plot, between the two sequences by counting kmer matches and penalizing for intervening mismatches. This way, local regions of highest density matches in a diagonal are isolated from background hits. For protein sequences BLOSUM50 values are used for scoring kmer matches. This ensures that groups of identities with high similarity scores contribute more to the local diagonal score than to identities with low similarity scores. Nucleotide sequences use the <b>identity</b> <b>matrix</b> for the same purpose. The best 10 local regions selected from all the diagonals put together are then saved.|$|E
40|$|We {{present an}} {{approach}} for constructing LDPC codes without cycles of length 4 and 6. Firstly, we design 3 submatrices with different shifting functions {{given by the}} proposed schemes, then combine them into the matrix specified by the proposed approach, and, finally, expand the matrix into a desired parity-check <b>matrix</b> using <b>identity</b> <b>matrices</b> and cyclic shift <b>matrices</b> of the <b>identity</b> <b>matrices.</b> The simulation result in AWGN channel verifies that the BER of the proposed code is close to those of Mackay's random codes and Tanner's QC codes, and the good BER performance of the proposed can remain at high code rates...|$|R
50|$|It {{is closely}} related to the Matrix {{determinant}} lemma and its generalization. It is the determinant analogue of the Woodbury <b>matrix</b> <b>identity</b> for <b>matrix</b> inverses.|$|R
2500|$|... and {{describe}} multiplication by [...] {{in the complex}} plane. The superdiagonal blocks are 22 <b>identity</b> <b>matrices</b> and hence in this representation the matrix dimensions are larger than the complex Jordan form. The full real Jordan block is given by ...|$|R
500|$|It is {{a square}} matrix of order n, {{and also a}} special kind of {{diagonal}} matrix. It is called an <b>identity</b> <b>matrix</b> because multiplication with it leaves a matrix unchanged: ...|$|E
500|$|... where In is the n×n <b>identity</b> <b>matrix</b> with 1s on {{the main}} {{diagonal}} and 0s elsewhere. If B exists, it is unique and is called the inverse matrix of A, denoted A−1.|$|E
500|$|The <b>identity</b> <b>matrix</b> In of size n is the n-by-n matrix {{in which}} all the {{elements}} on the main diagonal are equal to 1 and all other elements are equal to 0, for example, ...|$|E
3000|$|... are the <b>identity</b> <b>matrices</b> with size h[*]×[*]h and w[*]×[*]w, respectively; h and w are {{the number}} of rows and columns extracted. Since all unitary {{orthogonal}} transforms such as the DCT are distributive to matrix multiplication [19], we have [...]...|$|R
5000|$|... and {{describe}} multiplication by [...] {{in the complex}} plane. The superdiagonal blocks are 2&times;2 <b>identity</b> <b>matrices</b> and hence in this representation the matrix dimensions are larger than the complex Jordan form. The full real Jordan block is given by ...|$|R
3000|$|... (considering {{more than}} one relay in general) are <b>identity</b> <b>matrices</b> or all-zero matrices, so that the network code {{simplifies}} to the relay packet being a linear combination of source packets, also expressed as XORing of packets or symbol-wise addition of packets.|$|R
