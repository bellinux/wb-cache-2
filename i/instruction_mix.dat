53|83|Public
5000|$|Analysis of Instruction parallelism, Instruction frequencies, <b>Instruction</b> <b>mix</b> ...|$|E
5000|$|A 400-MHz {{processor}} {{was used}} to execute a benchmark program with the following <b>instruction</b> <b>mix</b> and clock cycle count: ...|$|E
50|$|Previous GPU {{architectures}} implemented fixed-pipelines, i.e. {{there were}} distinct shader processors {{for each type}} of shader. TeraScale leverages many flexible shader processors which can be scheduled to process a variety of shader types, thereby significantly increasing GPU throughput (dependent on application <b>instruction</b> <b>mix</b> as noted below). The R600 core processes vertex, geometry, and pixel shaders as outlined by the Direct3D 10.0 specification for Shader Model 4.0 in addition to full OpenGL 3.0 support.|$|E
2500|$|... —A Video {{demonstration}} {{along with}} written <b>instructions,</b> for <b>mixing</b> a Champagne-based Bellini (Hosted at VideoJug.com) ...|$|R
40|$|Lowering {{active power}} {{dissipation}} is increasingly important for battery powered embedded microprocessors. Here, power reduction techniques applicable to fully associative translation lookaside buffers, {{as well as}} other associative structures and dynamic register files, are described. Powermill simulations of implementation in a microprocessor on 0. 18 µm process technology demonstrate 42 % power savings. Circuit implementations, as well as architectural simulations demonstrating applicability to typical <b>instruction</b> <b>mixes</b> are shown...|$|R
40|$|This paper {{addresses}} the potential speedup achieved by using decimal floating-point hardware, instead of software routines, on a high-performance superscalar architecture. Software routines were written to per-form decimal addition, subtraction, multiplication, and diuision. Cycle counts were then measured for each instruction using the Simplescalar simulator. Af-ter this, new hardware algorithms were deueloped, ex-isting hardware algorithms were analyzed, and cycle counts were estimated {{for the same}} set of instructions using specialized decimal floating-point hardware. This data was then used to show the potential speedup ob-tained for programs with different <b>instruction</b> <b>mixes</b> and a recently developed benchmark. ...|$|R
5000|$|The two {{classical}} metrics of CPU {{performance are}} IPC (instructions per cycle) and clock speed. While IPC {{is difficult to}} quantify due to dependence on the benchmark application's <b>instruction</b> <b>mix,</b> clock speed is a simple measurement yielding a single absolute number. Unsophisticated buyers would simply consider the processor with the highest clock speed {{to be the best}} product, and the Pentium 4 had the fastest clock speed. Because AMD's processors had slower clock speeds, it countered Intel's marketing advantage with the [...] "megahertz myth" [...] campaign. AMD product marketing used a [...] "PR-rating" [...] system, which assigned a merit value based on relative performance to a baseline machine.|$|E
50|$|The AN/AYK-14(V) is an {{airborne}} {{computer that}} was designed in 1976 by the Control Data Aerospace Division in Bloomington, Minnesota. It has a microprogrammed 16-bit CPU based on AMD 2900 series ICs that can use 4, 8, 16, or 32-bit data. The processor runs between 0.3 and 2.3 MIPS depending on the <b>instruction</b> <b>mix.</b> The instructions are a superset of the AN/UYK-20 computer and it can run AN/UYK-20 software. Due to its use in avionics, the AN/AYK-14 is designed for use at altitudes up to 70,000 feet and temperatures from -54C to 71C. The Navy directed the development and procurement of the AYK-14 in 1976. It is still in use on Navy fleet aircraft including the F/A-18, AV-8B, and the EA-6B.|$|E
50|$|Both the 6400 and 6600 CPUs had a {{cycle time}} of 100 ns (10MHz). Due to the serial {{nature of the}} 6400 CPU, its exact speed was heavily {{dependent}} on <b>instruction</b> <b>mix,</b> but generally around 1 MIPS. Floating-point additions were fairly fast at 11 clock cycles, however floating-point multiplication was very slow at 57 clock cycles. Thus its floating point speed would depend heavily on the mix of operations and could be under 200 kFLOPS. The 6600 was, of course, much faster. With good compiler instruction scheduling, the machine could approach its theoretical peak of 10 MIPS. Floating-point additions took four clock cycles, and floating-point multiplies took 10 clocks (but there were two multiply functional units, so two operations could be processing at the same time.) The 6600 could therefore have a peak floating point speed of 2-3 MFLOPS.|$|E
40|$|A more {{structured}} and streamlined design of implants is nowadays possible. In this paper {{we focus on}} implant processors located {{in the heart of}} implantable systems. We present a real and representative biomedical-application scenario where such a new processor can be employed. Based on a suitably selected processor simulator, various operational aspects of the application are being monitored. Findings on performance, cache behavior, branch prediction, power consumption, energy expenditure and <b>instruction</b> <b>mixes</b> are presented and analyzed. The suitability of such an implant processor and directions for future work are given. Microelectronics and Computer EngineeringMechanical, Maritime and Materials Engineerin...|$|R
40|$|Abstract — A more {{structured}} and streamlined design of implants is nowadays possible. In this paper {{we focus on}} implant processors located {{in the heart of}} implantable systems. We present a real and representative biomedical-application scenario where such a new processor can be employed. Based on a suitably selected processor simulator, various opera-tional aspects of the application are being monitored. Findings on performance, cache behavior, branch prediction, power consumption, energy expenditure and <b>instruction</b> <b>mixes</b> are presented and analyzed. The suitability of such an implant processor and directions for future work are given. Index Terms — implant, low power, low energy, compression, encryption, checksum, microarchitecture, personalized health-care I...|$|R
40|$|Abstract- Subwords are {{data items}} {{smaller than a}} word. Subword parallelism, a {{technique}} that packs multiple subwords in a register and processes them in parallel, {{has been used to}} accelerate multimedia applications significantly. However, subword computations also raise new challenges, one of which is the subword permutation problem, i. e., efficient rearrangement of subwords within a register or among several registers. <b>MIX</b> <b>instruction</b> is one of several instructions that have been implemented in general-purpose processors to address the subword permutation problem. The <b>MIX</b> <b>instruction</b> is very effective to perform certain subword permutations, namely, subword matrix transposes. However, it is still not clear whether <b>MIX</b> <b>instructions</b> can perform other types of permutations efficiently and, if they can, what subword permutations can be performed with what <b>MIX</b> <b>instructions.</b> This paper tries to answer these questions. It first gives a more general definition of MIX operations and then describes a class of subword permutations that the MIX operations can achieve. It also examines the instruction set architecture (ISA) support for the generalized MIX operations. I...|$|R
50|$|The {{speed of}} the {{execution}} unit (EU) and the bus of the 8086 CPU was well balanced; with a typical <b>instruction</b> <b>mix,</b> an 8086 could execute instructions out of the prefetch queue {{a good bit of}} the time. Cutting down the bus to 8 bits made it a serious bottleneck in the 8088. With the speed of instruction fetch reduced by 50% in the 8088 as compared to the 8086, a sequence of fast instructions can quickly drain the 4-byte prefetch queue. When the queue is empty, instructions take as long to complete as they take to fetch. Both the 8086 and 8088 take 4 clock cycles to complete a bus cycle; whereas for the 8086 this means 4 clocks to transfer 2 bytes, on the 8088 it is 4 clocks per byte. Therefore, for example, a 2-byte shift or rotate instruction, which takes the EU only 2 clock cycles to execute, actually takes 8 clocks to complete if it is not in the prefetch queue. A sequence of such fast instructions prevents the queue from being filled as fast as it is drained, and in general, because so many basic instructions execute in fewer than 4 clocks per instruction byte - including almost all the ALU and data-movement instructions on register operands and some of these on memory operands - it is practically impossible to avoid idling the EU in the 8088 at least 1/4 of the time while executing useful real-world programs, and {{it is not hard to}} idle it half the time. In short, an 8088 typically runs about half as fast as 8086 clocked at the same rate, because of the bus bottleneck (the only major difference).|$|E
40|$|In this paper, {{we present}} a {{detailed}} analysis of the MediaBench benchmark suite. MediaBench consists of a number of popular embedded applications for communications and multimedia. MediaBench performance characteristics were examined by running MediaBench under the SimpleScalar simulation environment. Characteristics such as <b>instruction</b> <b>mix,</b> branch prediction accuracy, cache hit rates, memory usage, and integer bit utilization were considered. This information can be of use in designing embedded systems targeted at multimedia applications. ...|$|E
40|$|Application {{performance}} {{dominated by}} a few computational kernels Performance tuning today Vendor-tuned libraries (e. g., BLAS) or user hand-tunes Automatic tuning (e. g., PHiPAC/ATLAS, FFTW/SPIRAL/UHFFT) Tuning sparse linear algebra kernels is hard Sparse code has [...] . high bandwidth requirements (extra storage) poor locality (indirect, irregular memory access) poor <b>instruction</b> <b>mix</b> (data structure manipulation) Sparse matrix-vector multiply (SpM ¡ V) performance: less than 10 % of machine peak Performance depends on kernel, architecture, and matrix Performance Optimizations and Boundsfor Sparse Matrix-Vector Multiply – p. 2 / 36...|$|E
40|$|A {{high-performance}} processor circuit {{called the}} SC- 3 {{has been developed}} {{to meet the requirements}} of advanced experiment and attitude control applications. It is based on the 16 MHz Intel 80386 / 80387 chip set and implements a dual bus system configuration which allows high-speed, 32 -bit wide memory and low-speed. 16 -bit wide Input Output(I/O) circuits to be separated. This separation maintains compatibility {{with a wide range of}} current I/O circuit designs while exploiting the high-bandwidth memory access capabilities of the 80386. Performance is further enhanced by means of a cache on the 32 -bit bus. Gibson, Whetstone, and Dhrystone <b>instruction</b> <b>mixes</b> have been used to evaluate performance under various operating modes. When the SC- 3 is constrained to execute from 16 -bit memory. the Gibson mix indicates a 32...|$|R
40|$|Gathering {{detailed}} {{measurements of}} the execution behavior of an instruction set architecture is difficult. There are two major problems that must be solved. First, for meaningful measurements to be obtained, programs that represent typical work load and <b>instruction</b> <b>mixes</b> must be used. This means that high-level language compilers for the target architecture are required. This problem is further compounded as most architectures require an optimizing compiler to exploit their capabilities. Building such a compiler can be a formidable task. The second problem is that gathering detailed dynamic measurements of an architecture using typical user programs reading typical data sets can consume significant computation resources. For example, a popular way to gather execution measurements is to simulate the architecture. This technique is often used when the architecture in question does not yet exist...|$|R
5000|$|Both {{positive}} and negative reinforcement increase behavior. Most people, especially children, will learn to follow <b>instruction</b> by a <b>mix</b> of {{positive and}} negative reinforcement.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThere {{is a need}} for a decision making/early selection tool for use in the government computer selection process. Such early selection tools are critical to the decision maker due to the environment in which the government procurer is forced to operate. The <b>instruction</b> <b>mix</b> sensitivity technique as demonstrated here has the potential to aid the government decision maker in evaluating the performance of a computer prior to the actual existence or availability of that hardware without resorting to costly and time consuming techniques such as simulation or modeling. [URL] United States Nav...|$|E
40|$|Quantitative {{performance}} analysis {{is the foundation}} for computer system design and innovation. In their classic paper, Emer and Clark noted that ‘‘a lack of detailed timing information impairs efforts to improve performance. ’ ’ 1 They pioneered the quantitative approach by characterizing <b>instruction</b> <b>mix</b> and cycles per instruction on timesharing workloads. Emer and Clark surprised expert readers by demonstrating {{a gap between the}} theoretical 1 million instructions per second (MIPS) peak of the VAX- 11 / 780 and the 0. 5 MIPS it delivered on real workloads. Hardware and software researchers in industry and academia no...|$|E
40|$|The paper {{introduces}} fine-grain clockgating {{schemes for}} fused multiply-add-type floating-point units (FPU). The clockgating {{is based on}} instruction type, precision and operand values. The presented schemes focus on reducing the power at peak performance, where each FPU stage is used in nearly every cycle and conventional schemes have little impact on the power comsumption. Depending on the <b>instruction</b> <b>mix,</b> the schemes allow to turn off 18 % to 74 % of the register bits. Even for the worst case instruction 18 % to 37 % of the FPU are shut down depending on the data patterns...|$|E
5000|$|Not {{making more}} formula than is needed. Formula can become {{contaminated}} during preparation, and bacteria can multiply quickly if formula is improperly stored. The safest practice {{is to make}} formula in smaller quantities on an as-needed basis to greatly reduce the possibility of contamination and always follow the label <b>instructions</b> for <b>mixing</b> formula.|$|R
40|$|Energy {{consumption}} optimization of HPC applications inherently requires {{measurements for}} reference and comparison. However, most of today’s systems lack the necessary hardware support for power or energy measurements. Furthermore, in-band data availability is preferred for specific optimization {{techniques such as}} auto-tuning. For this reason, we present in-band energy consumption models for the IBM POWER 7 processor based on hardware counters. We demonstrate that linear regression is a suitable means for modeling energy consumption, and we rely on already available, highlevelbenchmarks for training instead of self-written or handtuned micro-kernels. We compare modeling efforts for different <b>instruction</b> <b>mixes</b> caused by two compilers (GCC and IBM XL) as well as various multi-threading usage scenarios, and validate across our training benchmarks and two real-world applications. Results show mean errors of approximately 1 % and overall max errors of 5. 3 % for GCC...|$|R
5000|$|In October 2008, Aguilar {{opened an}} MMA school, the B.A.M.F. Mixed Martial Arts Center. His MMA gym, located in Paranaque, Philippines, offers <b>instruction</b> in <b>Mixed</b> Martial Arts, Brazilian Jiu Jitsu, Muay Thai, Wrestling and Boxing. Professional fighters like Royce Gracie, Saulo Ribeiro, and Mauricio [...] "Tinguinha" [...] Mariano have {{conducted}} seminars at the center.|$|R
40|$|Moore's Law {{states that}} the number of {{transistors}} on a device doubles every two years; however, it is often (mis) quoted based on its impact on CPU performance. This important corollary of Moore's Law states that improved clock frequency plus improved architecture yields a doubling of CPU performance every 18 months. This paper examines the impact of Moore's Law on the peak floating-point performance of FPGAs. Performance trends for individual operations are analyzed as well as the performance trend of a common <b>instruction</b> <b>mix</b> (multiply accumulate). The important result is that peak FPGA floating-point performance is growing significantly faster than peak floating-point performance for a CPU...|$|E
40|$|Sparse kernel {{performance}} {{depends on}} both the matrix and hardware platform. � Challenges in tuning sparse code • Typical uniprocessor performance < 10 % peak Indirect, irregular memory accesses High bandwidth requirements, poor <b>instruction</b> <b>mix</b> • Hardware complexity is increasing Microprocessor performance difficult to model Widening processor-memory gap; deep memory hierarchies • Performance depends on architecture, kernel, and matrix � Goal: Automatic tuning of sparse kernels • Choose best data structure and implementation for given kernel, sparse matrix, and machine o Matrix known only at run-time (in general) • Evaluate code against architecture-specific upper bounds Observations Performance depends strongly {{on both the}} matrix and hardware platform. ...|$|E
40|$|Results are {{presented}} {{of a study}} conducted with a digital simulation model {{being used in the}} design of the Automatically Reconfigurable Modular Multiprocessor System (ARMMS), a candidate computer system for future manned and unmanned space missions. The model simulates the activity involved as instructions are fetched from random access memory for execution in one of the system central processing units. A series of model runs measured instruction execution time under various assumptions pertaining to the CPU's and the interface between the CPU's and RAM. Design tradeoffs {{are presented}} in the following areas: Bus widths, CPU microprogram read only memory cycle time, multiple instruction fetch, and <b>instruction</b> <b>mix...</b>|$|E
40|$|We discuss {{classical}} and quantum computations {{in terms of}} corresponding Hamiltonian dynamics. This allows us to introduce quantum computations which involve parallel processing of both: the data and programme <b>instructions.</b> Using <b>mixed</b> quantum-classical dynamics we look for a full cost of computations on quantum computers with classical terminals. Comment: 5 pages, 2 EPS figures, LaTeX 2 e, AMSLaTe...|$|R
30|$|All {{statistical}} {{analyses were conducted}} using JMP (v 8.0, SAS Institute, North Carolina). A two-factor (height [low/high] X <b>instruction</b> [soft/natural/stiff]) <b>mixed</b> effects (participant–random effect, height and instruction–fixed effect) repeated measures analysis of variance (rmANOVA) {{was used to test}} for differences in the dependent measures between drop-landing conditions. Contrast analyses with Tukey HSD correction were performed to compare means and test interactions.|$|R
40|$|In Spanish, voiced stops weaken to approximants {{and display}} {{variables}} degrees of lenition {{according to the}} context in which the stop occurs, making them a complex pronunciation feature. Accumulated findings from cross-sectional research on second language (L 2) speakers suggests that many L 2 learners struggle to produce the approximants even at the most advanced levels of study. The present study offers a new perspective on the approximants by studying individual learners’ production of Spanish [β] over time and across phonetic contexts. Twenty-six English speaking learners of L 2 Spanish recorded two speaking tasks five times over a yearlong period corresponding to their second and third semesters of college-level language <b>instruction.</b> <b>Mixed</b> effects models were fit to learners’ C:V intensity ratio data to examine development, and stress and task type were included as substantive predictors. Although the group trajectory was flat, many learners displayed substantial change over time, including positive and negative trajectories...|$|R
40|$|The {{performance}} of scientific computing applications often achieves {{a small fraction}} of peak performance [7, 17]. In this paper, we discuss two causes of performance problems [...] insufficient memory bandwidth and a suboptimal <b>instruction</b> <b>mix</b> [...] {{in the context of a}} complete, parallel, unstructured mesh implicit CFD code. These results show that the {{performance of}} our code and of similar implicit codes is limited by the memory bandwidth of RISC-based processor nodes to as little as 10 % of peak performance for some critical computational kernels. Limits on the number of basic operations that can be performed in a single clock cycle also limit the performance of "cache-friendly" parts of the code...|$|E
40|$|We {{intend to}} {{investigate}} the behavior of MMX optimized applications on an X 86 general purpose processor. The applications will be written as C programs. The speci c applications are yet to be determined, but will be chosen carefully to represent the behavior of DSP applications as a whole. We will analyze the <b>instruction</b> <b>mix</b> and memory access behavior of both applications with MMX instrucions and without using dynamic performance modeling tools. We hope to isolate the speci c features of MMX technology {{that are responsible for}} speedup then locate and eliminate any potential performance bottlenecks. As part of the literature survey, welooked at various journal papers and other resources desribing the applications, performance evaluation and e ective cache utilization. 1 2...|$|E
40|$|As XML {{has become}} a {{standard}} for data representation and exchange, XML data processing {{becomes more and more}} important for server workloads like web servers and database servers. One of the most time consuming part is data parsing. In this paper, we present a performance study of XML data parsing through measurement and simulation. We evaluate the data parsing behavior and study architectural characteristics such as <b>instruction</b> <b>mix</b> and cache behavior. It is observed that XML data parsing benefits from a larger instruction cache compared to data cache. Based on our analysis, we incorporate new instructions with special hardware support to speedup certain frequently-used operations. Our simulation results have shown that these new instructions can improve the performance by up to 12. 7 %. ...|$|E
5000|$|The [...] "PowerPC 615" [...] is a PowerPC {{processor}} {{announced by}} IBM in 1994, but which never reached mass production. Its main feature was to incorporate an x86 core on die, thus making the processor able to natively process both PowerPC and x86 instructions. An operating system running on PowerPC 615 could either chose to execute 32-bit or 64-bit PowerPC instructions, 32-bit x86 <b>instructions</b> or a <b>mix</b> of three. <b>Mixing</b> <b>instructions</b> would involve a context switch in the CPU {{with a small}} overhead. The only operating systems that supported the 615 were Minix and a special development version of OS/2.|$|R
50|$|Some of {{his works}} were {{controversial}} at the time, like the argument he held with the Catholic Church over the teaching of Darwin's Theory of Evolution in the Liceo de Heredia and <b>mixed</b> <b>instruction.</b>|$|R
50|$|Metol is {{difficult}} to dissolve in solutions of high salt content and <b>instructions</b> for <b>mixing</b> developer formulae therefore almost always list metol first. It is important to dissolve chemicals in {{the order in which}} they are listed. Some photographers add a pinch of sodium sulfite before dissolving the metol to prevent oxidation, but large amounts of sulfite in solution will make it very slow for metol to dissolve.|$|R
