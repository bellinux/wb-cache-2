26|440|Public
5000|$|For some time, film theorists mistakenly {{believed}} that the camera was actually stopped for the effect, and then restarted (hence the occasionally used term [...] "stop trick"). However, later film historians such as Richard Abel and Elizabeth Ezra established that the effect {{was the result of}} Méliès's careful <b>frame</b> <b>matching</b> during the editing process, creating a seamless match cut out of two separately staged shots. Indeed, Méliès often used substitution splicing not as an obvious special effect, but as an inconspicuous editing technique, matching and combining short takes into one apparently seamless longer shot. Substitution splicing could become even more seamless when the film was colored by hand, as many of Méliès's films were; the addition of painted color acts as a sleight of hand technique allowing the cuts to pass by unnoticed.|$|E
40|$|Abstract. In {{this paper}} we propose ontology-based video content {{annotation}} and recommendation tools. Our system is able to perform automatic shot detection and supports users during the annotation phase in a collaborative framework by providing suggestions {{on the basis of}} actual user needs as well as modifiable user behaviour and interests. Annotations are based on domain ontologies expressing hierarchical links between entities and guarantying interoperability of resources. Examples to verify the effectiveness of both the shot detection and the <b>frame</b> <b>matching</b> modules are analyzed. 1...|$|E
40|$|In {{this project}} we present {{detection}} the motion in video frames using background <b>frame</b> <b>Matching.</b> These document video surveillance systems have become widely available {{to ensure safety}} and security in {{both the public and}} private sectors due to incidents of terrorist activity and other social problems. This paper proposes a novel motion detection method with a background model module and an object mask generation module with moving camera. We propose a self adaptive background matching method to select the background pixel at each frame with regard to background model generation. The quality of the proposed method is analyzed. The experimental results show that our proposed method has high accuracy and performance compared to previous methods using static camera...|$|E
50|$|Shaun Murphy {{came back}} from 7-12 down to win his quarter-final match against Matthew Stevens, a feat never before {{accomplished}} in a best of 25 <b>frame</b> <b>match.</b>|$|R
30|$|In {{the whole}} process, several {{criteria}} {{are used to}} determine whether a given block in current <b>frame</b> <b>matches</b> the search block in reference frame, such as mean absolute error (MAE), mean square error (MSE), and sum absolute difference (SAD).|$|R
50|$|MLS <b>frames</b> <b>matches</b> between Toronto FC and Columbus as a rivalry, {{creating}} a trophy called the Trillium Cup, {{awarded to the}} team that wins the season series.The Crew contests F.C. Dallas for the Lamar Hunt Pioneer Cup. Lamar Hunt {{was the owner of}} both of these teams until his death.|$|R
40|$|This thesis {{presents}} {{a new class}} of surface patches for the creation of sculptured surfaces in mechanical engineering applications of computer aided design. Ideas from differential geometry are used to create principal patches whose edges are lines of curvature. This is done by ensuring that the sides obey two equations called the <b>frame</b> <b>matching</b> and position matching conditions. It is shown that these conditions are both sufficie~t and necessary to create a patch based on lines of curvature. A solution to the <b>frame</b> <b>matching</b> equation is given for all cases where the patch boundaries are plane curves. Continuity between principal patches is examined. The method is illustrated by means of two well understood surface types which are of engineering importance: generalised cylinders and surfaces of revolution. The method is then used to create patches whose lines of curvature are circular arcs. Such patches come from surfaces known as Dupin's cyclides. These patches are demoostra ted to have one degree of freedom, assuming two sides of the patch are known, and a discussion of how to use this choice is given. Means of finding points in the patch interior are given. It is shown that cycl ide patches are a subset of rational biquadratic patches, and that the sphere, torus, cone, cylinder and plane are special cases. Another useful property is that the offset surface to a cyclide is another cyclide. The need for non four sided regions of surface is examined. These occur at umbilics when using principal patches. The behaviour of surfaces near umbilics is reviewed, and suggestions are made for dealing with such regions using principal patches. Some ideas for future work are recorded. KEYWORDS Computer aided design, computational geometry, sculpture...|$|E
40|$|This paper {{describes}} a simultaneous conversion technique of duration and spectrum {{based on a}} statistical model including time-sequence matching. Conventional GMM-based approaches cannot perform spectral conversion taking account of speaking rate because it assumes one to one <b>frame</b> <b>matching</b> between source and target features. However, speaker characteristics may appear in speaking rates. In order to perform duration conversion, we attach duration models to statistical models including time-sequence matching (DPGMM). Since DPGMM can represent two different length sequences directly, the conversion of spectrum and duration can be performed within an integrated framework. In the proposed technique, each mixture component of DPGMM has different duration transformation functions, therefore durations are converted nonlinearly and dependently on spectral information. In the subjective DMOS test, the proposed method is superior to the conventional method. Index Terms: voice conversion, GMM, duration conversion 1...|$|E
40|$|RGB-D {{cameras are}} novel sensing systems that capture RGB images along with per-pixel depth information. RGB-D cameras rely on either {{structured}} light patterns combined with stereo sensing [6, 10] or time-of-flight laser sensing [1] to generate depth estimates {{that can be}} associated with RGB pixels. Very soon, small, high-quality RGB-D cameras developed for computer gaming and home entertainment applications will become available at cost below $ 100. In this paper we investigate how such cameras can be used in the context of robotics, specifically for building dense 3 D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. The robotics and computer vision communities have developed a variety of techniques for 3 D mapping based on laser range scans [8, 11], stereo cameras [7], monocular cameras [3], and unsorted collections of photos [4]. While RGB-D cameras provide the opportunity to build 3 D maps of unprecedented richness, they have drawbacks that make their application to 3 D mapping difficult: They provide depth only up to a limited distance (typically less than 5 m), depth values are much noisier than those provided by laser scanners, and their field of view (∼ 60 ◦) is far more constrained than that of specialized cameras or laser scanners typically used for 3 D mapping (∼ 180 ◦). In our work, we use a camera developed by PrimeSense [10]. The key insights of this investigation are: first, that existing <b>frame</b> <b>matching</b> techniques are not sufficient to provide robust visual odometry with these cameras; second, that a tight integration of depth and color information can yield robust <b>frame</b> <b>matching</b> and loop closure detection; third, that building on best practice techniques in SLAM and computer graphics makes it possible to build and visualize accurate and extremely rich 3 D maps with such cameras; and, fourth, that it will be feasible to build complete robot navigation and interaction systems solely based on cheap depth cameras...|$|E
50|$|Mark Selby {{made three}} records in his 13-4 victory over Stephen Hendry. Selby {{became the first}} snooker player to compile six century breaks at a World Championship match in the Crucible. This was also a record for a best of 25 <b>frame</b> <b>match</b> and took the number of Selby's century breaks in the season to 54, a record {{previously}} held by Hendry.|$|R
50|$|In 1991 <b>Frame,</b> Set & <b>Match,</b> {{along with}} Frameworks, {{installed}} the first AVID in the country. Shortly afterwards the company changed locations {{and moved to}} a larger facility on Ridge St. During the seven years spent at the Ridge St. facility <b>Frame,</b> Set & <b>Match</b> transitioned into becoming a complete digital facility. In 1999 <b>Frame,</b> Set & <b>Match</b> moved to its current location in Northbridge.|$|R
40|$|A new {{generalization}} of the Hawking-Hayward quasilocal energy to scalar-tensor gravity is proposed without assuming symmetries, asymptotic flatness, or special spacetime metrics. The procedure followed is simple but powerful {{and consists of}} writing the scalar-tensor field equations as effective Einstein equations and then applying the standard definition of quasilocal mass. Comment: Corrected an error and added a section on Einstein <b>frame.</b> <b>Matches</b> version published in Class. Quantum Gra...|$|R
40|$|INTERSPEECH 2008 : 9 th Annual Conference of the International Speech Communication Association, September 22 - 26, 2008, Brisbane, Australia. This paper {{describes}} a simultaneous conversion technique of duration and spectrum {{based on a}} statistical model including time-sequence matching. Conventional GMM-based approaches cannot perform spectral conversion taking account of speaking rate because it assumes one to one <b>frame</b> <b>matching</b> between source and target features. However, speaker characteristics may appear in speaking rates. In order to perform duration conversion, we attach duration models to statistical models including timesequence matching (DPGMM). Since DPGMM can represent two different length sequences directly, the conversion of spectrum and duration can be performed within an integrated framework. In the proposed technique, each mixture component of DPGMM has different duration transformation functions, therefore durations are converted nonlinearly and dependently on spectral information. In the subjective DMOS test, the proposed method is superior to the conventional method...|$|E
40|$|Objective: In {{this paper}} a {{recognition}} and tracing scheme for moving objects by video monitoring system was studied. Methods: During moving objects recognition, Multi frame sampling method {{was used to}} establish the initial background. Edges of the moving objects were drawn according to the changes of the images, and the influence factors for edges drawing were eliminated. In the end, tracing for moving objects could be realized by recognition of morphological characteristics. Results: The experiments indicate that, for field environment, the number of collected frames between 120 to 180 could get better image background. The shadows of the moving objects are the main factor which influence detection of object edges, {{and they could be}} eliminated by Shadow edge detection operator. For vehicles tracing, adjacent <b>frame</b> <b>matching</b> method could be used to reflect the time-space transformation of the vehicles. Conclusion: This scheme could realize the recognition and tracing of moving objects by video monitoring system effectively...|$|E
40|$|Intelligent Virtual Environments {{integrate}} AI techniques with 3 D real-time environments. As such, {{they can}} support interactive problem solving, provided the underlying AI techniques can produce solutions within a time <b>frame</b> <b>matching</b> that of user interaction. In this paper, we describe an intelligent virtual environment based on Constraint Logic Programming (CLP), integrated in a real-time 3 D graphic environment. We {{have developed an}} event-based approach through which user interaction can be converted in real-time into appropriate solver queries which are then translated back into automatic reconfigurations of the Virtual Environment (VE). Additionally, this framework supports the interactive exploration of the solution space in which alternative solutions (configurations) can be found. We demonstrate the system behaviour on a configuration example. This example illustrates how solutions can be interactively refined by the user through direct manipulation of objects in the VE and how the interactive search of alternative solutions in the VE is supported by these type of systems...|$|E
40|$|Abstract — A new pattern {{filtering}} {{technique is}} developed {{to analyze the}} genomic sequence in this research based on gap sequences, in which {{the distance of the}} same symbol is recorded consecutively as a sequence of integer numbers. A joint decision is made upon a family of gap sequences generated using selected patterns to perform genomic sequence alignment and similarity check. The effects of basic operations on genomic sequences are studied under the gap sequence framework. Several tools are developed based on the the Poisson distribution approximation of gap value to analyze the gap sequences such as histogram-aided alignment, conditional entropy over gap knowledge, and unwanted segments merging. Simulation results show that the extension of gap match indicates the corresponding segment extension in the original genomic sequence. With the proposed algorithm, we are able to generalize the conventional sequence alignment methods in a more adaptive way. The match between the gap sequences is considered as a <b>frame</b> <b>match</b> while a true <b>match</b> requires both <b>frame</b> and stuffing <b>match.</b> Conditional entropy measurement has been proposed to predict the possibility of a true match conditioned on a <b>frame</b> <b>match.</b> Extensive experimental results will be presented to demonstrate the proposed method. Index Terms — Genomic signal process, pattern filtering, gap sequences, conditional entropy, Poisson approximation, histogram-aided sequence alignment, unwanted segment merging I...|$|R
50|$|In 2009 the Radish was {{launched}} by Xtracycle. It is a production long-tail bicycle with a low-standover height <b>frame</b> and <b>matching</b> FreeRadical.|$|R
50|$|There {{were four}} competitors: Joe Davis, Fred Davis, John Pulman and Walter Donaldson. Rather than 3-day <b>matches</b> of 37 <b>frames,</b> <b>matches</b> were over 13 frames {{on a single}} day with each playing the others three times. Originally the tournament was planned to take place over three {{consecutive}} weeks but {{the third week of}} matches were delayed for three weeks. Unlike previous News of the World tournaments there was no handicapping. All matches were played in Burroughes Hall, London.|$|R
40|$|Blunt-end {{palindromic}} DNA linkers with {{a central}} restriction site have been designed for the multiple reading frame Insertion (abbreviated MURFI) of a sense or nonsense codon Into DNA. We have utilized an amber MURFI linker, 5 'CTAG TCTAGA CTAG 3 ' to disrupt the lacZ gene, yielding truncated s-galac-tosidase proteins. Conditional disruption of the tetr gene 1 n ̂. coli has also been demonstrated. Nonsense codon MURFI linkers permit conditional fusion of multiple gene products while sense codon linkers can add structural elements (e. g. g-turn, cationic segment, hydrophobic segment) or a desired amino add to a protein (e. g. methionine, cysteine). Shotgun or alterna-tively site-directed insertion of the symmetric linkers is possible. The over-all length of the linker may be adjusted to retain the original reading <b>frame,</b> <b>matching</b> nucleotide additions or subtractions at recipient DNA sites. If a linker restriction site occurs elsewhere 1 n the target DNA, single linker copies may still be Inserted using non-phosphorylated linkers...|$|E
40|$|In {{this paper}} a {{recognition}} and tracing scheme for moving objects by video monitoring system was studied. During moving objects recognition, Multi frame sampling method {{was used to}} establish the initial background. Edges of the moving objects were drawn according to the changes of the images, and the influence factors for edges drawing were eliminated. In the end, tracing for moving objects could be realized by recognition of morphological characteristics. The experiments indicate that, for field environment, the number of collected frames between 120 to 180 could get better image background. The shadows of the moving objects are the main factor which influence detection of object edges, {{and they could be}} eliminated by Shadow edge detection operator. For vehicles tracing, adjacent <b>frame</b> <b>matching</b> method could be used to reflect the time-space transformation of the vehicles. This scheme could realize the recognition and tracing of moving objects by video monitoring system effectively. </p...|$|E
40|$|This paper {{presents}} the neural network (NN) speech recognition using processed LPC input features. But NN has a limitation {{that the network}} must have a fixed amount of input nodes. The input feature processing method will use <b>frame</b> <b>matching</b> based on Dynamic Time Warping (DTW) algorithm to fix the input size to a fix amount of input vectors. The LPC features are aligned between the input frames (test set) to the reference (training set) using our DTW fixing frame (DTW-FF) algorithm. This proper time normalization is needed since NN is designed to compare data of the same length, whilst same speech can varies in their length. By doing frame fixing or also known as time normalization, the test set and the training set frames are adjusted so that both sets {{will have the same}} number of frames according to the reference set. The neural network with back-propagation algorithm is used as the recognition engine at the back-end processing to enhance the recognition performance. The results compare DTW with LPC coefficients to back-propagation NN with LPC coefficients adjusted using DTW. 1...|$|E
50|$|The {{original}} two-story {{building was}} designed using Gothic Style architecture, {{which was then}} in vogue in the United States. The exterior was covered in light brown brick. The first floor has large arched windows framed with terra cotta. The color of the <b>frames</b> <b>matches</b> that of the quoins that reach {{to the top of}} the second floor. The second-floor windows are rectangular and separated by brick panels decorated with terra cotta torches. The second floor spandrels are made of buff-colored terra cotta tile.|$|R
40|$|A new pattern {{filtering}} {{technique is}} developed {{to analyze the}} genomic sequence in this research based on gap sequences, in which {{the distance of the}} same symbol is recorded consecutively as a sequence of integers. Sequence alignment and similarity testing can be performed on a family of gap sequences over selected patterns. The gap sequence offers a new way for sequence structural analysis. The match between the gap sequences is considered as a <b>frame</b> <b>match</b> while a true <b>match</b> requires both <b>frame</b> and stuffing <b>match.</b> Simulation results show that the extension of gap match indicates the corresponding segment extension in the original genomic sequence. Thus, we are able to generalize the conventional alignment and scoring methods in a more adaptive way. 1...|$|R
40|$|We {{determined}} the nucleotide {{sequence of the}} v-H-ras-related oncogene of BALB/c murine sarcoma virus. This oncogene contains an open reading frame of 189 amino acids that initiates and terminates entirely within the mouse cell-derived ras sequence. The protein encoded by this open reading <b>frame</b> <b>matches</b> the sequence predicted for the T 24 human bladder carcinoma oncogene product, p 21, in all but two positions. The presence of a lysine residue in position 12 of BALB/c murine sarcoma virus p 21 likely accounts for its oncogenic properties...|$|R
40|$|Abstract. This paper aims at the {{difficulty}} {{that lack of}} observation model and high-dimensional sampling in video tooning, proposes a method based on key <b>frame</b> <b>matching</b> and dual-directional Markov chain Monte Carlo sampling of video motion redirection. At first, after extracting the key frame of a given video, By affine transformation and linear superposition, the subject initializes the video’s space-time parameters and forms the observation model; Secondly, in each space-time, based on the bi-directional Markov property of each frame, This paper proposed a dual-directional Markov chain Monte Carlo sampling particle filter structure and takes {{full advantage of the}} relationship of the front and back frame of the parameters to estimate motion redirection parameters. At the same time, for high-dimensional sampling problem, the subject according to the directional parameters’ correlation implements classification of skeleton parameters-morphological parameters-physical parameters, proposes a hierarchical genetic strategy to optimize the output parameters and improves the efficiency of the algorithm. The research of this paper will produce an efficient and prominent animation expressive video motion redirection method and play an important role on video animation of the development...|$|E
40|$|Image {{matching}} {{approaches have}} been widely used in computer vision applications in which the image-level matching performance of matchers is critical. However, it has not been well investigated by previous works which place more emphases on evaluating local features. To this end, we present a uniform benchmark with novel evaluation metrics and a large-scale dataset for evaluating the overall performance of image matching methods. The proposed metrics are application-oriented as they emphasize application requirements for matchers. The dataset contains two portions for benchmarking video <b>frame</b> <b>matching</b> and unordered image matching separately, where each portion consists of real-world image sequences and each sequence has a specific attribute. Subsequently, we carry out a comprehensive performance evaluation of different state-of-the-art methods and conduct in-depth analyses regarding various aspects such as application requirements, matching types, and data diversity. Moreover, we shed light on how to choose appropriate approaches for different applications based on empirical results and analyses. Conclusions in this benchmark can be used as general guidelines to design practical matching systems and also advocate potential future research directions in this field...|$|E
40|$|In this paper, we {{describe}} our approaches and experiments in content-based copy detection (CBCD) and surveillance event detection pilot (SEDP) tasks of TRECVID 2008. We {{have participated in}} the video-only CBCD task and four of the SEDP events. The CBCD method relies on sequences of invariant global image features and efficiently matching and ranking of those sequences. The normalized Hu-moments are proven to be invariant to many transformations, as well as certain level of noise, and thus are the basis of our system. The most crucial property of proposed CBCD system is that it relies on the sequence matching rather than independent frame correspondences. The experiments have shown that this approach is quite useful for matching videos under extensive and strong transformations which make single <b>frame</b> <b>matching</b> a challenging task. This methodology is proven to be fast and produce high F 1 detection scores in the TRECVID 2008 task evaluation. We also submitted four individual surveillance event detection systems. “Person-Runs”, “Object-Put”, “Opposing-Flow ” and “Take-Picture ” are the four selected events. The systems rely on low level vision properties such as optical flow and image intensity as well as heuristics based on a given event and context...|$|E
50|$|McConachy {{had played}} in 1951/1952 News of the World Snooker Tournament from September 1951 to January 1952. This was the annual {{round-robin}} handicap tournament played by the leading professionals. McConachy had performed badly, losing all 8 matches and winning an average of 11 frames in each 37 <b>frame</b> <b>match.</b> He lost all three matches he played on level terms, 27-10 to Albert Brown, 29-8 to John Pulman and 26-11 to Sidney Smith. He lost 26-11 to Joe Davis, despite receiving a 21-point start in each frame.|$|R
5000|$|The {{score in}} the match between Mann and Cope {{includes}} [...] "dead" [...] <b>frames.</b> The <b>match</b> between Lawrence and Mann may also include [...] "dead" [...] frames.|$|R
5000|$|It {{turns out}} the {{equality}} between two boosts and a rotation followed or preceded by a single boost is correct: the rotation of <b>frames</b> <b>matches</b> the angular separation of the composite velocities, and explains how one composite velocity applies to one frame, while the other applies to the rotated frame. The rotation also breaks the symmetry in the overall Lorentz transformation making it nonsymmetric. For this specific rotation, let the angle be [...] and the axis be defined by the unit vector , so the axis-angle vector is [...]|$|R
40|$|In this paper, a Major Color Spectrum Histogram Representation (MCSHR) is {{introduced}} {{to represent a}} moving object by using a normalized geometric distance between two points in the RGB space. Then, an Incremental Major Color Representation Algorithm is proposed to cope with small pose changes occurring along the track. Finally, a two directional similarity measurement based on the major colors is {{used to measure the}} similarity of any two given moving objects in multiple integrated frames. Experimental results show that with a few (4 or 5) frames MCSHR integration, the proposed Incremental MCSHR algorithm can make matching more robust and reliable than single <b>frame</b> <b>matching,</b> especially for small pose changes. The major color representation algorithm based on the introduced color distance can represent moving objects accurately with a limited number of colors and the frequency of each major color. The similarity of a same moving object in two different tracks has improved from 85 % to 97 % with the number of integrated frames increasing from 1 to 5, while the similarity of two different moving objects has been kept as low as 9 % to 19 %. 1...|$|E
40|$|This paper {{focuses on}} the problem of how data represen-tation {{influences}} the generalization error of kernel based learning machines like Support Vector Machines (SVM) for classification. Frame theory provides a well founded mathematical framework for representing data in many dif-ferent ways. We analyze the effects of sparse and dense data representations on the generalization error of such learning machines measured by using leave-one-out error given a finite number of training data. We show that, in the case of sparse data representation, the generalization ca-pacity of an SVM trained by using polynomial or Gaussian kernel functions is equal to the one of a linear SVM. We show that sparse data representations reduce the general-ization error as long as the representation is not too sparse, {{as in the case of}} very large dictionaries. Very sparse rep-resentations increase drastically the generalization error of kernel based methods. Dense data representations, on the contrary, reduce the generalization error also in the case of very large dictionaries. We use two different schemes for representing data in overcomplete Haar and Gabor dic-tionaries, and measure SVM generalization error on bench mark data set. KEY WORDS Method of <b>frame,</b> <b>matching</b> pursuit, data representation, classification, kernel methods, machine learning. ...|$|E
40|$|This paper {{presents}} {{a method to}} extract existing speech features in dynamic time warping path which originally was derived from LPC. This extracted feature coefficients represent as an input for neural network back-propagation. The coefficients are normalized {{with respect to the}} reference pattern according to the average number of frames over the samples recorded. This is due to neural network (NN) limitation where a fixed amount of input nodes are needed for every input class. The new feature processing used the famous <b>frame</b> <b>matching</b> technique, which is Dynamic Time Warping (DTW) to fix the input size to a fix number of input vectors. The LPC features vectors are aligned between the source frames to the template using our DTW frame fixing (DTW-FF) algorithm. By doing frame fixing, the source and template frames are adjusted so that they have the same number of frames. The speech recognition is performed using the back-propagation neural network (BPNN) algorithm to enhance the recognition performance. The results compare DTW using LPC coefficients to BPNN with DTW-FF coefficients. Added pitch feature investigate the improvement made to the previous experiment using different number of hidden neurons...|$|E
40|$|We {{present a}} new {{approach}} to stochastic modeling of constraintbased grammars that is based on log-linear models and uses EM for estimation from unannotated data. The techniques are applied to an LFG grammar for German. Evaluation on an exact match task yields 86 % precision for an ambiguity rate of 5. 4, and 90 % precision on a subcat <b>frame</b> <b>match</b> for an ambiguity rate of 25. Experimental comparison to training from a parsebank shows a 10 % gain from EM training. Also, a new class-based grammar lexicalization is presented, showing a 10 % gain over unlexicalized models. ...|$|R
50|$|In 1996 the last-16 and quarter-final rounds were {{extended}} from 9 to 11 frames while the final was {{extended from}} 17 to 19 <b>frames.</b> Wild-card <b>matches</b> were extended from 9 to 11 frames in 1999.|$|R
40|$|We {{present a}} new {{approach}} to stochastic modeling of constraint-based grammars that is based on log-linear models and uses EM for estimation from unannotated data. The techniques are applied to an LFG grammar for German. Evaluation on an exact match task yields 86 % precision for an ambiguity rate of 5. 4, and 90 % precision on a subcat <b>frame</b> <b>match</b> for an ambiguity rate of 25. Experimental comparison to training from a parsebank shows a 10 % gain from EM training. Also, a new class-based grammar lexicalization is presented, showing a 10 % gain over unlexicalized models. Comment: 8 pages, uses acl 2000. st...|$|R
