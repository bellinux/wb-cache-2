2|10000|Public
40|$|A {{space heater}} for the {{interior}} of a building has a support enclosure containing a gas burner and a gas conduit connecting the burner to a source of combustible gas. An electronically controlled proportional valve is located in the gas conduit. A fan and motor assembly are in the enclosure for distributing heated air from the burner when gas is communicated through the conduit and to the burner for combustion. A control system and a PC interface of a PC are located in the support enclosure to receive a <b>data</b> <b>processing</b> <b>card</b> having a predetermined temperature set point relating to temperature conditions within the building. A control means comprises a part of the control system and is connected to the PC to be responsive to temperature sensors in the building to cause or cease ignition of gas at the burner when any of the temperature conditions in the building varied with the predetermined temperature set point to permit the production of heat by the burner to automatically bring the varied temperature conditions in the building back towards the temperature of the predetermined temperature set point...|$|E
40|$|This paper {{details the}} design architecture, design methodology, and the {{advantages}} of the SpaceCube v 2. 0 high performance data processing system for space applications. The purpose in building the SpaceCube v 2. 0 system is to create a superior high performance, reconfigurable, hybrid data processing system {{that can be used in}} a multitude of applications including those that require a radiation hardened and reliable solution. The SpaceCube v 2. 0 system leverages seven years of board design, avionics systems design, and space flight application experiences. This paper shows how SpaceCube v 2. 0 solves the increasing computing demands of space data processing applications that cannot be attained with a standalone processor approach. The main objective during the design stage is to find a good system balance between power, size, reliability, cost, and data processing capability. These design variables directly impact each other, and it is important to understand how to achieve a suitable balance. This paper will detail how these critical design factors were managed including the construction of an Engineering Model for an experiment on the International Space Station to test out design concepts. We will describe the designs for the processor card, power card, backplane, and a mission unique interface card. The mechanical design for the box will also be detailed since it is critical in meeting the stringent thermal and structural requirements imposed by the processing system. In addition, the mechanical design uses advanced thermal conduction techniques to solve the internal thermal challenges. The SpaceCube v 2. 0 processing system is based on an extended version of the 3 U cPCI standard form factor where each card is 190 mm x 100 mm in size The typical power draw of the processor card is 8 to 10 W and scales with application complexity. The SpaceCube v 2. 0 <b>data</b> <b>processing</b> <b>card</b> features two Xilinx Virtex- 5 QV Field Programmable Gate Arrays (FPGA), eight memory modules, a monitor FPGA with analog monitoring, Ethernet, configurable interconnect to the Xilinx FPGAs including gigabit transceivers, and the necessary voltage regulation. The processor board uses a back-to-back design methodology for common parts that maximizes the board real estate available. This paper will show how to meet the IPC 6012 B Class 3 A standard with a 22 -layer board that has two column grid array devices with 1. 0 mm pitch. All layout trades such as stack-up options, via selection, and FPGA signal breakout will be discussed with feature size results. The overall board design process will be discussed including parts selection, circuit design, proper signal termination, layout placement and route planning, signal integrity design and verification, and power integrity results. The radiation mitigation techniques will also be detailed including configuration scrubbing options, Xilinx circuit mitigation and FPGA functional monitoring, and memory protection. Finally, this paper will describe how this system is being used to solve the extreme challenges of a robotic satellite servicing mission where typical space-rated processors are not sufficient enough to meet the intensive data processing requirements. The SpaceCube v 2. 0 is the main payload control computer and is required to control critical subsystems such as autonomous rendezvous and docking using a suite of vision sensors and object avoidance when controlling two robotic arms...|$|E
40|$|An {{additional}} {{inner layer}} for the existing ATLAS Pixel Detector, called Insertable B-Layer (IBL), is under design. The front-end electronics features a new readout ASIC, named FeI 4, which requires new off-detector electronics, currently realized with two VME-based boards, which implement optical I/O functionality (BOC <b>card)</b> and <b>data</b> <b>processing</b> functionality (ROD <b>card),</b> plus a timing interface module (TIM). This paper presents {{a proposal for}} the IBL readout system, mainly focusing on the ROD board...|$|R
5000|$|Aeroflex Colorado Springs, a {{division}} of Aeroflex Microelectronic Solutions, is a manufacturer of integrated circuits for the aerospace, defense, medical, industrial, and security markets. It is located in Colorado Springs, Colorado. Aeroflex mixed-signal ASICs and standard products containing data acquisition, communication, and processing circuits are supplied for uses such as medical imaging, safety-critical industrial, point-of-sale, and secure <b>data</b> <b>processing</b> systems. Circuit <b>card</b> assembly is also available. [...] Fab-independent since 1997, Aeroflex uses commercial wafer foundries for multiple market segments. Aeroflex offers standard product analog and digital microprocessors, memory, logic, serial communication, clocks, analog multiplexers as well as multi-million gate semicustom mixed signal and digital solutions.|$|R
50|$|The openGear Terminal Equipment Platform is a modular {{platform}} for terminal equipment used for video, audio and <b>data</b> signal <b>processing</b> and {{distribution in the}} broadcast and production industries. Ross Video is {{the creator of the}} openGear platform and licenses it to other companies who then make openGear compliant signal <b>processing</b> <b>cards.</b> The development and sale of openGear compliant cards is royalty-free.|$|R
5000|$|CardProcess GmbH - credit <b>card</b> <b>processing,</b> debit <b>card</b> <b>processing,</b> POS network, POS {{acquiring}} ...|$|R
5000|$|A Kimball tag was a {{cardboard}} tag that included {{both human and}} machine-readable data to support punched <b>card</b> <b>processing.</b> [...] A Kimball tag was an early form of stock control label that, like its later successor the barcode, supported back office <b>data</b> <b>processing</b> functions. They were predominantly used by the retail clothing ("fashion") industry.|$|R
5000|$|The STD Bus uses 6.5" [...] by 4.5" [...] {{expansion}} card {{with an edge}} connector with 56 pins. Many different types of cards have been available for the STD Bus, from <b>processing</b> <b>cards,</b> RAM cards, I/O cards, and specialized cards for various applications.|$|R
5000|$|The {{company may}} be {{best known for its}} role in ATM network {{development}} having hosted the first successful ATM transaction over a shared network known as [...] "TYME" [...] or [...] "Take Your Money Everywhere". Other products offered by the company are core <b>data</b> <b>processing</b> for financial institutions, online banking products, credit card and debit <b>card</b> <b>processing,</b> and manufacture and network infrastructure support.|$|R
40|$|The CMS Level- 1 {{upgraded}} calorimeter trigger {{requires a}} powerful, flexible and compact <b>processing</b> <b>card.</b> The Calorimeter Trigger Processor Card (CTP 7) uses the Virtex- 7 FPGA as its primary data processor {{and is the}} first FPGA based <b>processing</b> <b>card</b> in CMS to employ the ZYNQ System-on-Chip (SoC) running embedded Linux to provide TCP/IP communication and board support functions. The CTP 7 was built {{from the ground up}} to support AXI infrastructure to provide flexible and modular designs with minimal time from project conception to final implementation...|$|R
50|$|Credit <b>Card</b> <b>Processing</b> Integrated credit <b>card</b> {{processor}} with swipe terminal.|$|R
40|$|The {{dissertation}} charts {{the changing}} use made {{of technology in}} business administration during the twentieth century, from the office managers and bookkeeping machines of the 1920 s to the chief information officers and personal computers of the 1990 s. As computers spread, from the 1950 s onward, corporate managers were more reliant than ever on administrative systems, but were forced to delegate their design and operation {{to a host of}} new specialist groups. Its primary focus is on the professional opportunities and organizational challenges arising from this influx of administrative technology. It examines the attempts of organized groups I refer to as “managerial technicians” to turn their expertise in the techniques and technologies of administrative systems into a claim to broad managerial authority. It pays particular attention to the emergence of the concept of information within corporate management, and to the use of appeals to “systems” expertise and to science to establish authority. The primary groups considered here are the office managers of the National Office Management Association, the “systems men” of the Systems and Procedures association, the punched card supervisors of the National Machine Accounting Association, <b>data</b> <b>processing</b> managers, operations research experts, management information systems specialists, and chief information officers. Each community united corporate staff with consultants, business school staff and technology suppliers. These were social movements within corporate society, as each community sought to raise its position on the organizational chart and establish itself as truly managerial rather than merely technical. This framing exposes many startling continuities, despite enormous changes in technology. Several chapters focus on attempts to create a professional identity for corporate computing staff, including the certification efforts of the <b>Data</b> <b>Processing</b> Management Association and the efforts of some within the Association for Computing Machinery to shape a broad identity I call “pan-computer professionalism. ” Other topics include: the original of entry of computers into corporate administration; the relationship between programming, systems analysis, and software engineering; office automation; office automation and personal computing in the 1980 s; corporate computing in the 1990 s; and changing labor practices in programming, <b>data</b> <b>processing,</b> and punched <b>card</b> work. ...|$|R
5000|$|International <b>Card</b> <b>Processing</b> Services - 80% Shareholding - This is a <b>card</b> <b>processing</b> {{unit that}} allows banks to {{outsource}} their <b>card</b> <b>processing</b> needs to achieve {{economies of scale}} and to provide their customers with the relevant card solutions ...|$|R
50|$|In 2002 Armenia adopted {{amendments}} to the Law of the Republic of Armenia on Licensing. The list of the organizations to be a subject of licensing included credit organizations, which involved in money transactions, clearing, <b>processing</b> <b>card</b> payments, and others.|$|R
5000|$|Memory: ROM size has {{apparently}} not been stated by Datawind, but {{is estimated to}} be either 256 MB or 2 GB. Both tablets have graphics <b>processing</b> <b>cards,</b> but the graphics memory size and GPU speed have not been stated [...]|$|R
5000|$|... {{a credit}} <b>card</b> <b>processing</b> tool, Payments by Wave, built {{initially}} on an integration with Stripe credit <b>card</b> <b>processing.</b>|$|R
50|$|Telecommunication access-aggregator {{equipment}} is another popular Channel-Link application. For example, second generation (2G) and 2.5G mobile phone base stations use Channel-Link to transfer data between radio <b>cards</b> and baseband <b>processing</b> <b>cards.</b> It also {{provides for the}} equivalent data transfers in DSL and multiservice access multiplexors.|$|R
40|$|<b>Data</b> <b>Processing</b> {{discusses}} the principles, practices, and associated tools in <b>data</b> <b>processing.</b> The book {{is comprised of}} 17 chapters that are organized into three parts. The first part covers the characteristics, systems, and methods of <b>data</b> <b>processing.</b> Part 2 deals with the <b>data</b> <b>processing</b> practice; this part {{discusses the}} data input, output, and storage. The last part discusses topics related to systems and software in <b>data</b> <b>processing,</b> which include checks and controls, computer language and programs, and program elements and structures. The text will be useful to practitioners of computer-re...|$|R
40|$|This paper {{proposes a}} {{conceptual}} matrix model with algorithms for biological <b>data</b> <b>processing.</b> The required elements for constructing a matrix model are discussed. The representative matrix-based methods and algorithms which have potentials in biological <b>data</b> <b>processing</b> are presented / proposed. Some application {{cases of the}} model in biological <b>data</b> <b>processing</b> are studied, which show the applicability of this model in various kinds of biological <b>data</b> <b>processing.</b> This conceptual model established a framework within which biological <b>data</b> <b>processing</b> and mining could be conducted. The model is also heuristic to other applications. <br /...|$|R
30|$|Quality <b>data</b> <b>processing</b> defines {{configuration}} {{and processing}} parameters, which are utilized {{in the evaluation}} process of quality attributes. Examples of configuration parameters include location of binary or configuration files, and environmental execution parameters (e.g. number of CPU cores, size of memory). Processing parameters refer to input data, which should be provided to <b>data</b> <b>processing</b> executables (e.g. Spark streaming). Supported quality <b>data</b> <b>processing</b> defines processing, which can be performed with a specific <b>data</b> <b>processing</b> tool. Especially, it can be specified what kind of quality attributes for a data source can be evaluated with a specific <b>data</b> <b>processing</b> tool.|$|R
50|$|Bandwidth pooling {{is used in}} network {{switches}} to optimize the use of network resources. It allows switch <b>processing</b> <b>cards</b> to be shared by physical interface cards. This innovation frees switch resources {{that would otherwise be}} stranded when lower-rate interface cards are deployed in an aggregation switch.|$|R
5000|$|Financial <b>processing</b> (credit <b>cards,</b> billing, {{payment on}} account) ...|$|R
40|$|Abstract. UnifiedViews is an Extract-Transform-Load (ETL) frame-work {{that allows}} users – publishers, consumers, or analysts – to define, execute, monitor, debug, schedule, and share RDF <b>data</b> <b>processing</b> tasks. The <b>data</b> <b>processing</b> tasks may use custom plugins created by users. UnifiedViews differs from other ETL {{frameworks}} by natively supporting RDF data and ontologies. The practical demonstration of UnifiedViews {{at the conference}} will (1) clearly demonstrate how UnifiedViews helps RDF/Linked Data users with RDF <b>data</b> <b>processing</b> (2) and show the real instance of UnifiedViews with tens of <b>data</b> <b>processing</b> tasks and DPUs motivated by real <b>data</b> <b>processing</b> use cases. ...|$|R
40|$|Significant {{numbers of}} {{physicians}} are using <b>data</b> <b>processing</b> services {{and a large}} number of firms are offering an increasing variety of services. This paper quantifies user dissatisfaction with office practice <b>data</b> <b>processing</b> systems and analyzes factors affecting dissatisfaction in large group practices. Based on this analysis, a proposal is made for a more structured approach to obtaining <b>data</b> <b>processing</b> services in order to lower the risks and increase satisfaction with <b>data</b> <b>processing...</b>|$|R
40|$|DE 102007026480 A 1 UPAB: 20081222 NOVELTY - The method {{involves}} attaching mobile <b>data</b> <b>processing</b> {{units to}} collection containers contained with products to be commissioned. The <b>data</b> <b>processing</b> units command over micro-controllers, local memory, sensor interfaces and wireless communication devices. The mobile <b>data</b> <b>processing</b> unit is addressed on the <b>data</b> <b>processing</b> {{system in a}} commissioning controlling system to identify the current collection containers. The numbers of products, which can be inferred, are indicated. DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for the execution of a method for the commissioning of goods. USE - Method for the commissioning of goods. ADVANTAGE - The method involves attaching mobile <b>data</b> <b>processing</b> units to collection containers contained with products to be commissioned, where the mobile <b>data</b> <b>processing</b> unit is addressed on the <b>data</b> <b>processing</b> system in a commissioning controlling system to identify the current collection containers, and hence ensures to simplify the commissioning work by retrofitting the existing stock option and shelving systems...|$|R
5000|$|Pure {{communications}} and pure <b>data</b> <b>processing</b> {{have very different}} characteristics that led to different policy results. The markets that the technology existed on assisted the FCC make its policy decisions. [...] "The pure <b>data</b> <b>processing</b> market was viewed as an innovative, competitive market with low barriers to entry and little chance of monopolization." [...] The FCC established that no additional regulation or safeguards where required for the pure <b>data</b> <b>processing</b> market. The pure communications market {{on the other hand}} was being managed by an incumbent monopoly. The FCC had four concerns about the incumbent telephone companies which were: [...] "the sale of <b>data</b> <b>processing</b> services by carriers should not hurt the provision of common carrier services, the costs of such <b>data</b> <b>processing</b> services should not be passed on to telephone rate payers, revenues derived from common carrier services should not be used to cross subsidize <b>data</b> <b>processing</b> services, and the furnishing of such <b>data</b> <b>processing</b> services by carriers should not hurt the competitive computer market." ...|$|R
50|$|The IEA <b>Data</b> <b>Processing</b> and Research Center (DPC) is the <b>data</b> <b>processing</b> and {{research}} department of IEA, located in Hamburg, Germany.|$|R
40|$|Moore's law {{was first}} {{postulated}} in 1968, and it loosely {{says that the}} cost of making calculations on a computer falls by 50 % each year. Securities markets are, in essence, a form of <b>data</b> <b>processing.</b> Consequently, Moore’s law has driven important changes in those markets over the past forty years. Faster <b>data</b> <b>processing</b> was essential for major changes in securities trading. Increased turnover of portfolios was a result of faster <b>data</b> <b>processing.</b> Consequently, the criticism of that turnover may be misplaced. The effectiveness of regulatory changes, such as the lowering of brokerage commissions and the reduction in bid ask spreads, depended on reduced <b>data</b> <b>processing</b> costs, that is on Moore's Law. Deregulation of brokerage commissions could not have reduced rates by as much as it did if we had not had decreasing costs of <b>data</b> <b>processing.</b> The reduction in bid ask spreads which followed decimalization of securities quotes depended on improved <b>data</b> <b>processing.</b> Continued reductions in <b>data</b> <b>processing</b> costs will require a new regulatory approach. Regulators should consider the improvements in <b>data</b> <b>processing</b> and <b>data</b> transmission when they establish capital requirements and haircuts. ...|$|R
40|$|<b>Data</b> <b>processing</b> complexity, partitionability, {{locality}} and provenance play {{a crucial}} role in the effectiveness of distributed <b>data</b> <b>processing.</b> Dynamics in <b>data</b> <b>processing</b> necessitates effective modeling which allows the understanding and reasoning of the fluidity of <b>data</b> <b>processing.</b> Through virtualization, resources have become scattered, heterogeneous, and dynamic in performance and networking. In this paper, we propose a new distributed <b>data</b> <b>processing</b> model based on automata where <b>data</b> <b>processing</b> is modeled as state transformations. This approach falls within a category of declarative concurrent paradigms which are fundamentally different than imperative approaches in that communication and function order are not explicitly modeled. This allows an abstraction of concurrency and thus suited for distributed systems. Automata give us a way to formally describe <b>data</b> <b>processing</b> independent from underlying processes while also providing routing information to route data based on its current state in a P 2 P fashion around networks of distributed processing nodes. Through an implementation, named Pumpkin, of the model we capture the automata schema and routing table into a <b>data</b> <b>processing</b> protocol and show how globally distributed resources can be brought together in a collaborative way to form a <b>processing</b> plane where <b>data</b> objects are self-routable on the plane...|$|R
40|$|This paper {{reviews the}} {{historical}} development of <b>data</b> <b>processing,</b> discerning three approximate decades of distinct evolutionary cycles. Each cycle {{is seen as}} forking, two contrasting styles of <b>data</b> <b>processing</b> forming and separating during the cycle. On this basis, a classification of the major general areas of <b>data</b> <b>processing</b> is suggested. For each decade, characteristic aspects are discussed and both the lines of development are described. Finally, some observations regarding the present decade and its requirements are given, and some predictions relating to the next decade and its prerequisites are made. DESCRIPTORS: Classification of <b>data</b> <b>processing.</b> Evolution of <b>data</b> <b>processing.</b> Philosophical implications. Computing milieu. Terminology. CR CATEGORIES: 1. 2, 1. 3, 2. ...|$|R
40|$|This paper {{describes}} {{the design of}} FPGA based signal <b>processing</b> <b>card.</b> An on board real time digital signal processing system is designed using FPGA. The platform can decode process of various kinds of digital and analog signals simultaneously. The design trend in this card is towards small size, high integration and fast real time processing. For the optimum performance a 16 bit 1 MSPS ADC is used which is interfaced with FPGA {{to make all the}} <b>data</b> <b>processing</b> onboard in real time. This card can be used in many signal processing based applications like audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications by interfacing several separate board using inbuilt I/O’s, each with a number of input channels that will communicate with each other in real time over a high speed communication link. The resulting images can be displayed directly on LCD or OLED panel displays using I/O’s peripherals. The project introduces many challenging issues, which are being addressed in turn with different prototype design. These issues are the ADC performance, interfacing the ADCs to the FPGA, implementing the flexible processing algorithms and high speed interconnection between the boards...|$|R
40|$|A {{system for}} {{assessing}} vestibulo-ocular function includes a motion sensor system adapted to be coupled to a user's head; a <b>data</b> <b>processing</b> system configured {{to communicate with}} the motion sensor system to receive the head-motion signals; a visual display system configured {{to communicate with the}} <b>data</b> <b>processing</b> system to receive image signals from the <b>data</b> <b>processing</b> system; and a gain control device arranged to be operated by the user and to communicate gain adjustment signals to the <b>data</b> <b>processing</b> system...|$|R
5000|$|Mivar-based {{technology}} of <b>data</b> <b>processing</b> {{is a method}} of creating logical inference system or automated algorithm construction from modules, services or procedures {{on the basis of}} active trained mivar network of rules with the linear computational complexity. Mivar-based {{technology of}} <b>data</b> <b>processing</b> is designed for <b>data</b> <b>processing</b> including logical inference, computational procedures and services.|$|R
5000|$|Roger Lee Sisson (June 24, 1926 [...] - [...] January 22, 1992) was {{an early}} <b>data</b> <b>processing</b> pioneer. Sisson worked on Project Whirlwind while a {{graduate}} student at MIT, co-founded the first consulting firm devoted to electronic <b>data</b> <b>processing,</b> and published a number of the earliest books and periodicals on computers and <b>data</b> <b>processing.</b>|$|R
40|$|Fourier {{transform}} spectrometry {{is a type}} {{of novel}} information obtaining technology, which integrated the functions of imaging and spectra, but the data that the instrument acquired is the interference data of the target, which is an intermediate data and couldn&# 39;t be used directly, so <b>data</b> <b>processing</b> must be adopted for the successful application of the interferometric data. In the present paper, <b>data</b> <b>processing</b> techniques are divided into two classes: general-purpose and special-type. First, the advance in universal interferometric <b>data</b> <b>processing</b> technique is introduced, then the special-type interferometric data extracting method and <b>data</b> <b>processing</b> technique is illustrated according to the classification of Fourier transform spectroscopy. Finally, the trends of interferogram <b>data</b> <b>processing</b> technique are discussed...|$|R
50|$|The term <b>Data</b> <b>Processing</b> (DP) {{has also}} been used {{previously}} {{to refer to a}} department within an organization responsible for the operation of <b>data</b> <b>processing</b> applications.|$|R
