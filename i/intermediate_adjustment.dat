8|19|Public
40|$|DE 1004052682 A UPAB: 20060602 NOVELTY - Industrial or {{laboratory}} mill has a self-sharpening cutting wheel with two-edged blades whose edges subtend an angle beta with each other. The blade has a core material with a first hardness and a coating that is distinctly {{harder than the}} first. The blades are sickle-shaped. USE - Industrial {{or laboratory}} mill self-cutting blades. ADVANTAGE - The cutter blades have longer service life than before and require not <b>intermediate</b> <b>adjustment...</b>|$|E
40|$|Search-theory {{has become}} the main {{paradigm}} for the micro-foundation of money. But no comprehensive business cycle analysis has been undertaken yet with a search-based monetary model. This paper extends the model with divisible goods and divisible money of Shi (JET, 1998) to allow for capital formation, analyses the monetary propagation mechanism and contrasts the model's implications with US business cycle stylized facts. The propagation mechanism based on a feedback between increased search intensity and depleted inventories only survives {{in the presence of}} non-negligible capital adjustment costs. With <b>intermediate</b> <b>adjustment</b> costs the model is able to replicate fairly well the volatility and cross-correlation with output of key US time series, including sales and inventory investment. ...|$|E
40|$|Objective: to {{describe}} the adequacy of prenatal care for high-risk pregnancy in a referral hospital. Methods: descriptive, retrospective and documentary study. The sample was 73 pregnant women who had a childbirth, during the collection period. The Kessner index {{was used to assess}} the quality of care, validated instrument in Brazil. For analysis of the information, descriptive statistics and distribution of relative frequencies were used. Results: among the 73 pregnant women, 47. 9 % were young adults, 50. 7 % were married, and 52. 0 % had only primary level. According to the Kessner Index, the <b>intermediate</b> <b>adjustment</b> prevailed. Conclusion: the main finding of this study was the intermediate adequacy of prenatal high risk. It was also found that pregnant women initiated prenatal care late in high risk, leading to reduced number of consultations, clinical procedures, obstetric and laboratory tests...|$|E
40|$|To {{overcome}} present {{difficulties in}} robotized food handling a force sensing robot gripper for flexible production is presented. A magnetic coupling {{is used to}} completely encapsulate the actuator mechanism, improving hygiene and enabling a future hose-down proof design. Product location, orientation and product type and width are extracted by a vision system to aid the gripping process. Knowing the product type the grip force is set individually for each product. In the paper data of achievable grip strength, positioning accuracy and gripping times for force controlled gripping are presented. Grip times of 410 – 530 ms for grip forces of 50 – 700 g respectively are realized. An initial microbiology study on a model system showed that an intermediate decontamination {{can be used to}} reduce the cross contamination of Listeria innocua (SIK 215) significantly. The gripper is further shown {{to be able to handle}} an in-feed mixture of tomatoes, apples, carrots, broccoli and grapes without <b>intermediate</b> <b>adjustments.</b> Industrial relevance: This paper covers the development and evaluation of a hygienically designed universal robot food gripper. The gripper enables an increased use of robots in the food industry and makes very flexible production with minimal changeover times possible...|$|R
40|$|Under {{conditions}} of reduced visual stimulation, the systems of accommodation and vergence tend towards physiological resting {{states that are}} intermediate within their functional range. The terms tonic accommodation (TA) and tonic vergence (TV) {{are used in the}} study to describe these stimulus-free, <b>intermediate</b> <b>adjustments</b> and to represent the systems as being in a state of innervational tonicity. The literature relating to TA and TV and the various experiments of this thesis are reviewed. Methodology has been developed enabling the determination of TA and TV under {{conditions of}} total darknessl laser optometry for TA and ~ernier-alignment for TV. The thesis describes a series of experiments designed to investigate various aspects of TA and TV, and their role in ametropia, binocular vision and their adaptation to sustained visual tasks. Measurements of TA were also utilised to investigate the effect of various autonomic effector drugs on the ciliary muscle. The effects of ethanol on binocular function are shown to be directly proportional to the. initial level of TVJ which is itself unaffected. These results support the concept of TV as the reference point for normal vergence responses. The results of the pharmacological investigations indicate the presence of a small but significant, beta-receptor mediated inhibitory sympathetic input to the ciliary muscle, and that the wide distribution in TA is a consequence of inter-observer variations in parasympathetic, rather than sympathetic tone. Following interaction with visual tasks of t 5 mins duration, the levels of TA and TV are found to be biased in the direction of, and proportional to, the task position: except during near-task viewing where the task-to-TA stimulus-distance exceeds 1. 5 D (for TA) and 3. 5 deg (for TV). Under these conditions the expected level of bias is attenuated, Adaptive models are discussed, proposing TA and TV as the reference points of the accommodative and vergence system...|$|R
40|$|Since 1997 {{government}} and industry in The Netherlands {{have been engaged in}} intensive policy discussions on how to design an emission trading program that would satisfy the Government’s policy objectives within the national and international regulatory framework and accommodate industry’s need for a flexible and cost-effective approach. Early on in the discussion the most promising solution was a rate-based approach, which dynamically allocated saleable emission credits based on a performance standard rate and actual energy used by facilities. All industrial facilities above a threshold of 20 MWth would be judged on their ability to meet this performance rate. Those “cleaner” than the standard can sell excess credits to others with an allocation that is less than their actual NOX emission. With some changes in law, such a design could be made to fit well into the national and EU legislative framework {{while at the same time}} uniquely meeting industry’s requirement of flexibility toward economic growth and facility expansion. (An analysis of the legislative changes required will be given in a separate paper by Chris Dekkers.) However, the environmental outcome of such a system is not as certain as under an absolute emission cap. At the request of the Netherlands Ministry of Housing, Spatial Planning and the Environment (VROM), Automated Credit Exchange (ACE), in close cooperation with the working group of {{government and}} industry representatives introduced a number of features into the Dutch NOX program allowing full exploitation of market mechanisms while allowing <b>intermediate</b> <b>adjustments</b> in the performance standard rates. The design is geared toward meeting environmental targets without jeopardizing the trading market the program intends to create. The paper discusses the genesis of the two-tier credit system ACE helped to design, explains the differences between primary (fixed) and secondary (variable) credits, and outlines how the Dutch system is expected to function once implemented in 2004. The paper also discusses the market trading simulation held in early 2001 to assess and test the trading program, and reviews also the current status of the market program development...|$|R
40|$|Abstract. The {{least mean squares}} (LMS) {{method for}} linear least squares {{problems}} differs from the steepest descent method in that it processes data blocks one-by-one, with <b>intermediate</b> <b>adjustment</b> of the parameter vector under optimization. This mode of operation often leads to faster convergence when far from the eventual limit and to slower (sublinear) convergence when close to the optimal solution. We embed both LMS and steepest descent, {{as well as other}} intermediate methods, within a one-parameter class of algorithms, and we propose a hybrid class of methods that combine the faster early convergence rate of LMS with the faster ultimate linear convergence rate of steepest descent. These methods are well suited for neural network training problems with large data sets. Furthermore, these methods allow the effective use of scaling based, for example, on diagonal or other approximations of the Hessian matrix. (1...|$|E
40|$|We {{consider}} {{a class of}} subgradient methods for minimizing a convex function that consists of the sum {{of a large number}} of component functions. This type of minimization arises in a dual context from Lagrangian relaxation of the coupling constraints of large scale separable problems. The idea is to perform the subgradient iteration incrementally, by sequentially taking steps along the subgradients of the component functions, with <b>intermediate</b> <b>adjustment</b> of the variables after processing each component function. This incremental approach has been very successful in solving large dierentiable least squares problems, such as those arising in the training of neural networks, and it has resulted in a much better practical rate of convergence than the steepest descent method. In this paper, we present convergence results and estimates of the convergence rate of a number of variants of incremental subgradient methods, including some that use randomization. The convergence rate estimates are c [...] ...|$|E
40|$|The LMS {{method for}} linear least squares {{problems}} di#ers from the steepest descent method {{in that it}} processes data blocks one-by-one, with <b>intermediate</b> <b>adjustment</b> of the parameter vector under optimization. This mode of operation often leads to faster convergence when far from the eventual limit, and to slower (sublinear) convergence when close to the optimal solution. We embed both LMS and steepest descent, {{as well as other}} intermediate methods, within a one-parameter class of algorithms, and we propose a hybrid class of methods that combine the faster early convergence rate of LMS with the faster ultimate linear convergence rate of steepest descent. These methods are well-suited for neural network training problems with large data sets. Furthermore, these methods allow the e#ective use of scaling based for example on diagonal or other approximations of the Hessian matrix. 1 Research supported by NSF under Grant 9300494 -DMI. 2 Dept. of Electrical Engineering and Computer Science, M [...] ...|$|E
40|$|Translation {{of target}} gene {{transcripts}} in Escherichia coli harboring UAG amber stop codons can be switched {{on by the}} amber-codon-specific incorporation of an exogenously supplied unnatural amino acid, 3 -iodo-L-tyrosine. Here, we report that this translational switch can control the translational efficiency at any <b>intermediate</b> magnitude by <b>adjustment</b> of the 3 -iodo-L-tyrosine concentration in the medium, as a tunable translational controller. The translational efficiency of a target gene reached maximum levels with 10 − 5 M 3 -iodo-L-tyrosine, and intermediate levels were observed with suboptimal concentrations (approximately spanning a 2 -log 10 concentration range, 10 − 7 – 10 − 5 M). Such intermediate-level expression was also confirmed in individual bacteria...|$|R
25|$|In {{order to}} save costs, an {{increasing}} number of polyester intermediate producers like spinning mills, strapping mills, or cast film mills are working on the direct use of the PET-flakes, from the treatment of used bottles, with a view to manufacturing {{an increasing number of}} polyester <b>intermediates.</b> For the <b>adjustment</b> of the necessary viscosity, besides an efficient drying of the flakes, it is possibly necessary to also reconstitute the viscosity through polycondensation in the melt phase or solid-state polycondensation of the flakes. The latest PET flake conversion processes are applying twin screw extruders, multi-screw extruders or multi-rotation systems and coincidental vacuum degassing to remove moisture and avoid flake pre-drying. These processes allow the conversion of undried PET flakes without substantial viscosity decrease caused by hydrolysis.|$|R
40|$|Global image {{orientation}} techniques aim at estimating camera rotations {{and positions}} {{for a whole}} set of images simultaneously. One of the main arguments for these procedures is an improved robustness against drifting of camera stations in comparison to more classical sequential approaches. Usually, the process consists of computation of absolute rotations and, in a second step, absolute positions for the cameras. Either the first or both steps rely on the network of transformations arising from relative orientations between cameras. Therefore, the quality of the obtained absolute results is influenced by tensions in the network. These may e. g. be induced by insufficient knowledge of the intrinsic camera parameters. Another reason can be found in local weaknesses of image connectivity. We apply a hierarchical approach with <b>intermediate</b> bundle <b>adjustment</b> to reduce these effects. We adopt efficient global techniques which register image triplets based on fixed absolute camera rotations and scaled relative camera translations but do not involve scene structure elements in the fusion step. Our variant employs submodels of arbitrary size, orientation and scale, by computing relative rotations and scales between - and subsequently absolute rotations and scales for - submodels and is applied hierarchically. Furthermore we substitute classical bundle adjustment by a structureless approach based on epipolar geometry and augmented with a scale consistency constraint...|$|R
40|$|The {{theory of}} the optimal {{investment}} decision is reexamined for {{a case in which}} the portfolio initialization problem is trivial but the portfolio adjustment decision presents some new and important problems. The investor is assumed to be a risk-averse expected utility maximizer whose portfolio consists of two risky assets. His objective is to maximize his expected utility at some time horizon, and there is a transaction cost for <b>intermediate</b> <b>adjustment</b> of the portfolio proportional to the value of assets traded. The solution for the optimum adjustment strategy consists of a set of pairs of control limits for the ratio of the amounts of the assets in the portfolio, one pair for each decision opportunity. The model falls naturally into the class of "cash balance" and dynamic portfolio selection models. The most important departure from both of these subclasses of models is the explicit consideration of more than one risky asset in the portfolio together with the transaction cost. The introduction of the transaction cost implies investor behavior which is systematically different from that implied by the no-transaction-cost dynamic portfolio selection models. The implied behavior is, however, quite similar in form to that implied by the cash-balance models, in which the objective is expected cost minimization. ...|$|E
40|$|Context. The International Astronomical Union (IAU) {{recommendations}} {{regarding the}} International Celestial Reference Frame (ICRF) realizations require {{the construction of}} radio sources catalogs obtained using very-long-baseline interferometry (VLBI) meth- ods. The improvement of these catalogs is a necessary procedure for the further densification of the ICRF over the celestial sphere. Aims. The different positions obtained from several catalogs using common sources to the ICRF make it necessary to critically revise the different methods employed in improving the ICRF from several radio sources catalogs. In this sense, a revision of the analytical and the statistical methods is necessary in line with their advantages and disadvantages. We have a double goal: first, we propose an adequate treatment of the residual of several catalogs to obtain a homogeneous catalog; second, we attempt to discern whether a combined catalog is homogeneous. Methods. We define homogeneity as applied to our problem in a dual sense: the first deals with the spatial distribution of the data over the celestial sphere. The second has a statistical meaning, as we consider that homogeneity exists when the residual between a given catalog and the ICRF behaves as a unimodal pure Gaussian. We use a nonparametrical method, which enables us to homogeneously extend the statistical properties of the residual over the entire sphere. This <b>intermediate</b> <b>adjustment</b> allows for subsequent computation of the coefficients for any parametrical adjustment model that has a higher accuracy and greater stability, and it prevents problems related with direct adjustments using the models. On the other hand, the homogeneity of the residuals in a catalog is tested using different weights. Our procedure also serves to propose the most suitable weights to maintain homogeneity in the final results. We perform a test using the ICRF-Ext 2, JPL, and USNO quasar catalogs. Results. We show {{that a combination of}} catalogs can only be homogeneous if we configure the weights carefully. In addition, we provide a procedure to detect inhomogeneities, which could introduce deformities, in these combined catalogs. Conclusions. An inappropriate use of analytical adjustment methods provides erroneous results. Analogously, {{it is not possible to}} obtain homogeneous-combined catalogs unless we use the adequate weights...|$|E
40|$|The {{cholesterol-lowering}} drug fluvastatin (FS) has an inhibitory {{effect on the}} growth of the pathogenic yeast Candida albicans that is dependent on the pH of the medium. At the low pH value of the vagina, FS is growth inhibitory at low and at high concentrations, while at intermediate concentrations (1 – 10 [*]mM), it has no inhibitory effect. Examination of the effect of the common antifungal drug fluconazole in combination with FS demonstrates drug interactions in the low concentration range. Determination of intracellular stress and the activity of the FS target enzyme HMG-CoA reductase confirm our hypothesis that in the <b>intermediate</b> dose range <b>adjustments</b> to the sterol biosynthesis pathway can compensate for the action of FS. We conclude that the pH dependent uptake of FS across yeast membranes might make FS combination therapy an attractive possibility for treatment of vaginal C. albicans infections...|$|R
40|$|This Selected Issues {{paper on}} Denmark {{underlies}} estimates of inefficiencies in {{the goods and}} labor markets. The IMF’s new macroeconomic model, the global economic model (GEM), {{has been used to}} provide estimates of the impact of successfully implementing the European Council’s ambitious Lisbon reform agenda. GEM incorporates markups in the goods and labor markets that are summary measures of the net impact of all the regulatory structures in an economy. The euro area goods market reform in the service sector is twice that required in Denmark, the euro area must also increase competition in manufacturing. Article IV consultations;Selected issues;inflation, dynamic <b>adjustment,</b> <b>intermediate</b> goods, real wages, tradable goods, relative price, inflation rates, nominal interest rate, perfect competition, relative prices, rate of inflation, adjustment process, domestic firms, monetary policy, rational expectations, nominal interest rates, maximum inflation, political economy, domestic savings, trade deficit, international trade, domestic demand, competitive pressures, distortionary taxes, equilibrium model, trading partner, elasticity of substitution, transition path, imperfect competition, world economy, monetary economics, member country...|$|R
40|$|Model {{parameterization}} through {{adjustment to}} ﬁeld data {{is a crucial}} step in the modeling and {{the understanding of the}} drainage network response to tectonic or climatic perturbations. Using as a test case a data set of 18 knickpoints that materialize the migration of a 0. 7 -Ma-old erosion wave in the Ourthe catchment of northern Ardennes (western Europe), we explore the impact of various data ﬁtting on the calibration of the stream power model of river incision, from which a simple knickpoint celerity equation is derived. Our results show that statistical least squares adjustments (or misﬁt functions) based either on the streamwise distances between observed and modeled knickpoint positions at time t or on differences between observed and modeled time at the actual knickpoint locations yield signiﬁcantly different values for the m and K parameters of the model. As there is no physical reason to prefer one of these approaches, an <b>intermediate</b> least-rectangles <b>adjustment</b> might at ﬁrst glance appear as the best compromise. However, the statistics of the analysis of 200 sets of synthetic knickpoints generated in the Ourthe catchment indicate that the timebased adjustment is the most capable of getting close to the true parameter values. Moreover, this ﬁtting method leads in all cases to an m value lower than that obtained from the classical distance adjustment (for example, 0. 75 against 0. 86 for the real case of the Ourthe catchment), corresponding to an increase in the non-linear character of the dependence of knickpoint celerity on dischargePeer reviewe...|$|R
40|$|Long-range travel {{forecasting}} commonly {{has been}} considered a two-step process. The first step involves development and calibration of a base-year model. The second step involves travel demand estimation using the calibrated base-year model {{in conjunction with a}} forecast year, that is, planning-year land use and socioeconomic data. The twostep process is {{based on the premise that}} the parameters for the base-year model are valid for the planning year. Reasonable results can be obtained using the above two-step travel forecasting process for fully developed communities or communities experiencing little or no growth. However, the twostep forecasting process is inappropriate for dynamic communities, that is, communities experiencing a major transition in land use and socioeconomic characteristics. Adjustment of model parameters to reflect changes in the planning-year land use and socioeconomic characteristics is a necessary <b>intermediate</b> step. The <b>adjustment</b> factors for the individual model parameters can be determined via a two-step process. First, the cause-effect relationships between the calibrated base-year model parameters (endogenous variables) and the socioeconomic, demographic or environmental variables (exogenous variables) should be established. Second, suitable analytical technique (for example, regression analysis, Delphi technique) should be used to determine the appropriate adjustment factors for the planning year...|$|R
40|$|Existential {{concerns}} about cancer {{have been studied}} extensively in palliative care but less so in curative settings. The present report aims to describe ways in which patients viewed the continuity or discontinuity of their identity {{in the face of}} the mortal threat of cancer. Twenty-eight patients with breast, prostate or lung cancer attending pre-treatment, treatment or follow-up appointments were interviewed about their emotional experiences following diagnosis. Qualitative analysis followed an inductive, constant comparative approach. Patients spoke of ‘getting back to normal’, but presented two distinct accounts of ‘normality’. Some, particularly those only recently diagnosed, maintained continuity to past identity by upholding previous routines, emphasising resilience and minimising the impact of cancer. Others talked of a new ‘normality’ discontinuous with their past. Most accounts, however, evidenced elements of continuity and discontinuity, often in ostensibly contradictory ways. We suggest that holding contradictory perspectives simultaneously characterises an <b>intermediate</b> stage of <b>adjustment</b> for some patients: between reliance on continuity with the past in the aftermath of diagnosis and, later, a sense of being a new person, changed by cancer. Practitioners should appreciate that patients' wishes for ‘normality’ can signify very different responses to cancer, and that holding such contradictory orientations is functional, not aberrant...|$|R
40|$|This paper reviews {{economic}} stabilization and growth in Portugal during the 1970 s. Following {{a decade of}} rapid growth with external equilibrium, the Portuguese economy in the early 1970 s suffered a series of major shocks. The paper highlights {{that the problem of}} managing economic growth with a balance-of-payments constraint was new to Portugal. The paper reviews the issues that had to be resolved to develop an effective program. The economic outturn is also critically examined in this paper. Economic growth;balance of payments, domestic credit, wages, credit expansion, domestic credit expansion, capital markets, international capital markets, current account, working capital, wage, capital formation, current account deficit, real wages, capital inflows, capital inflow, banking, banking system, domestic demand, international capital, money stock, workers? remittances, debt service, wage increases, inflation, imported goods, trading partners, fixed capital formation, foreign exchange, external position, inflation rate, domestic investment, capital goods, capital expenditures, bank deposits, capital movements, capital outflows, bank credit, balance of payments constraint, access to international capital, external borrowing, access to international capital markets, domestic saving, bank of portugal, balance of payments <b>adjustment,</b> <b>intermediate</b> goods, terms of trade, export markets, export volumes, free trade, gross domestic product, current account balance, investment bank, net capital, european investment bank, credit constraint, repayments, capital repatriation, debt servicing, foreign debt, resource allocation, debt servicing capacity, massive capital inflow, short-term debt, open economy, import costs, partner countries, domestic finance, domestic price, indirect taxes, exchange rate policies, export earnings, export sector, export industries, exporting countries, economic community, increasing competition, export prospects, current account surplus, external shocks, world price, competitive position, common market, external indebtedness, exchange rate policy, foreign currency, inflationary expectations, bank finance, bank for international settlements, deflationary effect, effective exchange rates, aggregate demand, domestic market, multilateral system, world markets, expenditure on consumption, expansion of trade, balance of payments crisis, protectionist pressures, unemployment rate...|$|R
40|$|Teerarat Tan-kam, 1 Chutamanee Suthisisang, 2 Chosita Pavasuthipaisit, 1 Penkhae Limsila, 1 Apichaya Puangpetch, 3 Chonlaphat Sukasem 31 Yuwaprasart Waithayopathum Child and Adolescent Psychiatric Hospital, Department of Mental Health Services, Ministry of Public Health, 2 Department of Pharmacology, Faculty of Pharmacy, Mahidol University, 3 Division of Pharmacogenomics and Personalized Medicine, Department of Pathology, Faculty of Medicine, Ramathibodi Hospital, Mahidol University, Bangkok, ThailandAbstract: This {{case report}} {{highlights}} the importance of pharmacogenetic testing in the treatment of attention deficit hyperactive disorder (ADHD). A 6 -year-old boy diagnosed with ADHD was prescribed methylphenidate 5 mg twice daily (7 am and noon) and the family was compliant with administration of this medication. On the first day of treatment, the patient had an adverse reaction, becoming disobedient, more mischievous, erratic, resistant to discipline, would not go to sleep until midnight, and had a poor appetite. The All-In-One PGX (All-In-One Pharmacogenetics for Antipsychotics test for CYP 2 D 6, CYP 2 C 19, and CYP 2 C 9) was performed using microarray-based and real-time polymerase chain reaction techniques. The genotype of our patient was identified to be CYP 2 D 6 * 2 /* 10, with isoforms of the enzyme consistent with a predicted cytochrome P 450 2 D 6 intermediate metabolizer phenotype. Consequently, the physician adjusted the methylphenidate dose to 2. 5 mg once daily in the morning. At this dosage, the patient had a good response without any further adverse reactions. Pharmacogenetic testing {{should be included in the}} management plan for ADHD. In this case, cooperation between the medical team and the patients&# 39; relatives was key to successful treatment. Keywords: attention deficit hyperactive disorder, pharmacogenomics, CYP 2 D 6, adverse drug reactions, dose <b>adjustment,</b> <b>intermediate</b> metabolize...|$|R
40|$|Model {{parameterization}} through {{adjustment to}} field data {{is a crucial}} step in the modelling and {{the understanding of the}} drainage network response to tectonic or climatic perturbations. Using a data set of 18 knickpoints that materialize the migration of a 0. 7 -Ma-old erosion wave in the Ourthe catchment of northern Ardennes (western Europe) as a test case, we explore the impact of various data fitting on the calibration of the detachment-limited stream power model of river incision, from which a simple knickpoint celerity equation is derived. Our results show that statistical least squares adjustments (or misfit functions) based either on the stream-wise distances between observed and modelled knickpoint positions at time t = 0. 7 Ma or on differences between observed (0. 7 Ma) and modelled time at the actual knickpoint locations yield significantly different values for the m (more exactly, m/n) and K parameters of the model. As there is no physical reason to prefer one or the other approach, we suggest that an <b>intermediate</b> least rectangles <b>adjustment</b> might be the best compromise. In the Ourthe case, this leads to a m/n value lower than that obtained from the classical distance adjustment (0. 79 against 0. 86), leading to an increase in the non linear character of the dependence of knickpoint celerity on discharge. If we now recall that m/n = c(1 -b) (Whipple & Tucker, 1999, JGR 104 B: 17661 - 17674), where c and b are the exponents of the power law relations respectively linking discharge to drainage area and channel width to discharge, we can compare the calculated m/n value with that derived from field measurements of channel width, discharge and drainage area in the presently graded sections of the rivers. Such data taken from Petit et al. (2005, BSGLg 46 : 37 - 50) allow us to derive m/n = 0. 48 at equilibrium. As c may be considered constant, the higher m=n value obtained from the knickpoint retreat modelling must be ascribed to a lower b, i. e., to a channel narrowing associated with the transient phase of knickpoint migration...|$|R
40|$|Abstract Background Adults {{spend about}} one third of their day at work and {{occupation}} may be {{a risk factor for}} obesity because of associated socioeconomic and behavioral factors such as physical activity and sedentary time. The aim {{of this study was to}} examine body mass index (BMI) and prevalence of overweight and obesity by occupation and explore the contributions of socioeconomic factors and lifestyle behaviors (including leisure time and commuting physical activity, diet, smoking, and alcohol) to occupational risk. Methods Secondary analyses of the National Health Survey in Australia (2005) were conducted for working age adults (20 to 64 years). Linear and logistic regression models using BMI as either dichotomous or continuous response were computed for occupation type. Model 1 was age-adjusted, Model 2 adjusted for age and socioeconomic variables and Model 3 adjusted for age, socioeconomic variables and lifestyle behaviours. All models were stratified by gender. Results Age-adjusted data indicated that men in associate professional (OR 1. 34, 95 % CI 1. 10 - 1. 63) and intermediate production and transport (OR 1. 24 95 % CI 1. 03 - 1. 50) occupations had a higher risk of BMI ≥ 25 kg/m 2 than those without occupation, and women in professional (OR 0. 71, 95 % CI 0. 61 - 0. 82), management (OR 0. 72, 95 % CI 0. 56 - 0. 92) and advanced clerical and service occupations (OR 0. 73 95 % CI 0. 58 - 0. 93) had a lower risk. After adjustment for socioeconomic factors no occupational group had an increased risk but for males, professionals, tradesmen, laborers and elementary clerical workers had a lower risk as did female associate professionals and <b>intermediate</b> clerical workers. <b>Adjustment</b> for lifestyle factors explained the lower risk in the female professional and associate professionals but failed to account for the lower odds ratios in the other occupations. Conclusions The pattern of overweight and obesity among occupations differs by gender. Healthy lifestyle behaviors appear to protect females in professional and associate professional occupations from overweight. For high-risk occupations lifestyle modification could be included in workplace health promotion programs. Further investigation of gender-specific occupational behaviors and additional lifestyle behaviors to those assessed in the current Australian Health Survey, is indicated. </p...|$|R
40|$|This {{study is}} part of the AMMA - African Multidisciplinary Monsoon Analysis- project and aims at a better {{understanding}} and modelling of the Donga catchment (580 km 2, Benin) behaviour in order to determine its spatially distributed water balance. For this purpose, we applied the REW concept proposed by Reggiani et al.  (1998, 1999), which allows the description of the main local processes at the sub-watershed scale. Such distributed hydrological models, which represent hydrological processes at various scales, should be evaluated not only on the discharge at the outlet but also on each of the represented processes and in several points of the catchment. This multi-criteria approach is required in order to assess the global behaviour of hydrological models. We applied such multi-criteria strategy to the Donga catchment (586 km 2), in Benin. The work was supported by an observation set up, undertaken since 1998 consisting in a network of 20 rain gauges, an automatic meteorological station, 6 discharge stations and 18 wells. The main goal {{of this study was to}} assess the model's ability to reproduce the discharge at the outlet, the water table dynamics in several points of the catchment and the vadose zone dynamics at the sub-catchment scale. We tested two spatial discretisations of increasing resolution. To test the internal structure of the model, we looked at its ability to represent also the discharge at <b>intermediate</b> stations. After <b>adjustment</b> of soil parameters, the model is shown to accurately represent discharge down to a drainage area of 100 km 2, whereas poorer simulation is achieved on smaller catchments. We introduced the spatial variability of rainfall by distributing the daily rainfall over the REW and obtained a very low sensitivity of the model response to this variability. Simulation of groundwater levels was poor and our results, in conjunction with new data available at the local scale, suggest that the representation of the processes in the unsaturated zone should first be improved, in order to better simulate soil water dynamics and represent perched water tables which were not included in this first modelling study...|$|R
40|$|This {{dissertation}} studies {{three main}} topics in macroeconomics: {{the impact of}} labor market frictions on labor supply and income inequality, the impact of goods market frictions on individuals' optimization decisions, and the housing market in the business cycle. In chapter one, I briefly review the research of this dissertation. Chapter two develops a dynamic general equilibrium model with progressive taxation, labor market search and heterogeneous households to study the impact of tax reform on labor supply and income inequality across educational groups. Households differ in their educational level and their time preference. I study the labor supply response to tax reform along both the intensive margin (hours worked) and the extensive margins (labor force participation). The quantitative results show that: (i) a tax reform which decreases the marginal tax rate by the same magnitude {{of that in the}} Tax Reform Act of 1986 (TRA- 86), has a significant impact on households' labor supply and that approximately 65 percent of the aggregate labor supply response is along the extensive margin; (ii) households' labor supply response to tax reform depends on their educational levels. Households with less education respond more significantly along both the intensive and extensive margin while the response of households with highest education is subtle. However, the income share of the highest educational group increases due to an increase in capital income after tax reform. These findings are consistent with the empirical literature studying the effects of TRA- 86 on labor supply. Chapter three introduces search frictions in the goods market into the classic income fluctuation problem and explores individuals' intertemporal optimization decisions. Individuals make their optimal choices when they face labor productivity shocks, borrowing constraints, and search frictions in the goods market. In this framework, individuals save not only for precaution but also for transaction-the higher asset holdings an individual has the shorter waiting time for getting the frictional goods. This provides an additional dimension to look at individuals' consumption and savings behavior. It also provides a possible channel to solve the problem encountered in the Aiyagari-Bewley model, which predicts a relatively low income inequality compared to the data observed. In the forth chapter, I examine the business cycle properties of the housing market in a multi-sector dynamic stochastic general equilibrium model with <b>intermediate</b> inputs and <b>adjustment</b> costs for capital and housing. The quantitative results replicate three main business cycle features of the housing market. First, GDP, consumption, non-residential investment, and residential investment co-move positively during the business cycle. Second, residential investment is twice as volatile as business investment. Finally, house prices and residential investment are positively correlated-a result rarely observed in models without demand side shocks...|$|R
40|$|Research on {{sickness}} absence {{has repeatedly}} {{been described as}} theoretically undeveloped. In this thesis the model of illness flexibility is introduced. In this model, sickness absence {{is assumed to be}} caused by people’s ability and motivation to work. Ability and motivation will in turn be affected by conditions met in and outside work. In the model, five basic components are discerned describing such conditions. Adjustment latitude describes opportunities to adjust work to health by e. g. choosing among work tasks. Attendance requirements describe negative consequences of being absent that may make a person attend work despite illness. Absence requirements are negative consequences by attending work as signals of not being wanted at work. Attendance incentives are positive consequences of attending work as stimulating work. Absence incentives are positive consequences of being absent as caring for relatives. The overall aim in the thesis is to test predictions from the illness flexibility model on sickness absence and sickness attendance. In Paper I adjustment latitude and attendance requirements were studied in relation to sickness absence and sickness attendance. In a cross-sectional design data based on self-reports from a questionnaire from inhabitants in the county of Stockholm were analysed. Low adjustment latitude, as predicted, increased women’s sickness absence. However it did not show any relation to men’s sickness absence and men’s and women’s sickness attendance. Attendance requirements were strongly associated to both men’s and women’s sickness absence and sickness attendance in the predicted way. In paper II the aim was to study whether return to work (RTW) after long-term sickness absence is affected by adjustment latitude, and whether this effect differed between those returning full-time and those returning part-time. A questionnaire was sent to salaried employees who had been on sick-leave for at least 90 days in 2000. The year after they received a questionnaire. For both men and women the likelihood to RTW increased, both among those returning part-time and full-time, with increasing number of opportunities to adjust. In paper III some components from the illness flexibility model was studied in relation to sickness absence on longitudinal data. In spring 2004 and in spring 2005 a random sample aged between 25 an 50 years from the Swedish population received questionnaires. The results showed that an <b>intermediate</b> level of <b>adjustment</b> latitude, compared to a high, was associated with an increased likelihood of being absent sick for between 1 - 6 days and 7 days or more. Work with little stimulation was associated with an increased likelihood of being absent sick for 7 days or more. Low or intermediate scores on attendance requirements on work were associated with an increased likelihood of being absent 7 days or more. Financial attendance requirements and demanding home tasks were not associated with the likelihood of being absent sick. In paper IV the social gradient in sickness absence was studied in relation to some components from the illness flexibility model. The sample is part of a panel originating from 1994 of inhabitants of Stockholm County which received a questionnaire 1994, 1998 and 2002. Only 2002 data was analysed. The social difference found in sickness absence 31 days or more a year decreased by 78 % for women and 67 % for men by adding characteristics from the illness flexibility model and health. In conclusion, the model of illness flexibility appears promising in increasing our understanding of sickness absence. Future studies should be directed to theoretical and methodological development of the components as well as future testing of predictions from the model. Such testing should be done with improved design and data as longitudinal design, register-based data of sickness absence, and tested measurements of the components of the illness flexibility model. Testing of the model should also be directed to different actions taken when ill as the inception of sickness absence, length of absence, RTW, and exclusion from the labour market...|$|R

