4811|2078|Public
25|$|Yakhnenko, O., and Honavar, V. (2011). Multi-Instance Multi-Label Learning for <b>Image</b> <b>Classification</b> with Large Vocabularies. In: Proceedings of the British Machine Vision Conference.|$|E
25|$|In 2014, Padma et al. used {{combined}} wavelet statistical texture {{features to}} segment and classify AD benign and malignant tumor slices. Zhang et al. found kernel {{support vector machine}} decision tree had 80% classification accuracy, with an average computation time of 0.022s for each <b>image</b> <b>classification.</b>|$|E
25|$|Recent {{approaches}} {{consider the}} use of high-quality microscopy images over which a statistical classification algorithm is used to perform automated cell detection and counting as an image analysis task. Generally performs with a constant error rate as an off-line (batch) type process. A range of <b>image</b> <b>classification</b> techniques can be employed for this purpose.|$|E
30|$|The {{experimental}} {{results showed that}} our proposal using SIFT/BoVW and MCRF-ODT has achieved more than 93  % accuracy for fingerprint <b>images</b> <b>classification.</b>|$|R
30|$|<b>Image</b> region <b>classification</b> is a {{research}} field that has been developed for many years. Generally speaking, {{there are two main}} approach directions to the problem: classic pixel-based image segmentation and <b>image</b> region <b>classification.</b>|$|R
30|$|The author Sachdeva et al. [11] used an {{artificial}} neural network and PCA–ANN for the multiclass brain tumor MRI <b>images</b> <b>classification,</b> segmentation with dataset of 428 MRI images and an accuracy of 75 – 90 % was achieved.|$|R
2500|$|In the [...] "recipe" [...] for <b>image</b> <b>classification,</b> {{groups of}} transformations are {{approximated}} with finite number of transformations. Such approximation {{is possible only}} when the group is compact.|$|E
2500|$|Upward-looking {{hemispherical}} {{photographs are}} typically acquired under uniform sky lighting, early or {{late in the}} day or under overcast conditions. [...] Known orientation (zenith and azimuth) is essential for proper registration with the analysis hemispherical coordinate system. [...] Even lighting is essential for accurate <b>image</b> <b>classification.</b> [...] A self-leveling mount (gimbals) can facilitate acquisition by ensuring that the camera is oriented to point straight up toward the zenith. [...] The camera is typically oriented such that north (absolute or magnetic) is oriented toward the top of the photograph.|$|E
2500|$|The {{hemispherical}} lens (also {{known as}} a fisheye or whole-sky lens) was originally designed by Robin Hill (1924) to view the entire sky for meteorological studies of cloud formation. [...] Foresters and ecologists conceived of using photographic techniques to study the light environment in forests by examining the canopy geometry. [...] In particular, Evans and Coombe (1959) estimated sunlight penetration through forest canopy openings by overlaying diagrams of the sun track on hemispherical photographs. [...] Later, Margaret Anderson (1964, 1971) provided a thorough theoretical treatment for calculating the transmission of direct and diffuse components of solar radiation through canopy openings using hemispherical photographs. [...] At that time hemispherical photograph analysis required tedious manual scoring of overlays of sky quadrants and the track of the sun. [...] With the advent of personal computers, researchers developed digital techniques for rapid analysis of hemispherical photographs (Chazdon and Field 1987, Rich 1988, 1989, 1990, Becker et al. 1989). [...] In recent years, researchers have started using digital cameras in favor of film cameras, and algorithms are being developed for automated <b>image</b> <b>classification</b> and analysis. [...] Various commercial software programs have become available for hemispherical photograph analysis, and the technique has been applied for diverse uses in ecology, meteorology, forestry, and agriculture.|$|E
40|$|AbstractThe {{effect of}} {{collinear}} context on the filter mediating {{the detection of}} a Gabor stimulus was investigated by using the <b>classification</b> <b>image</b> method. <b>Classification</b> <b>images</b> were estimated for a 1. 5 cpd horizontal Gabor target and the same target flanked by two collinear Gabors horizontally 1. 7 ° displaced from the target. The target was masked by a low-contrast white-noise mask. Obtained <b>classification</b> <b>images</b> were fitted by Gabor functions. The results show that collinear flankers increase {{the length of the}} <b>classification</b> <b>image</b> profiles along the collinear axis. At the same time, modest facilitory effects were observed in most subjects. The specificity and the amount of context-induced elongation in the <b>classification</b> <b>images</b> makes it hard to be explained by uncertainty reduction alone. In previous studies, collinear facilitation has been reported to abolish due to perceptual learning. We report a possibly related phenomenon: <b>classification</b> <b>image</b> data was re-analyzed in two parts consisting of the early and the late trials. In the latter trials, differences between the <b>classification</b> <b>images</b> in flankers and no-flankers condition are no longer significant...|$|R
40|$|Abstract. The {{problem of}} the <b>image</b> {{recognition}} and <b>classification</b> (IRC) based on the pattern recognition is of a paramount importance in lots of domains. The present paper discusses topics related with {{the complexity of the}} algorithms for <b>image</b> recognition and <b>classification.</b> This leads to some precise statements on the computational difficulty of the {{problem of the}} <b>image</b> recognition and <b>classification</b> (IRC). KEY WORDS: modeling, <b>image</b> recognition and <b>classification,</b> algorithm complexit...|$|R
40|$|Texture {{classification}} {{is one of}} {{the basic}} images processing tasks. In this paper we present some numerical characteristics to the images analysis and processing. It can be used at the solving of <b>images</b> <b>classification</b> problems, their recognition, problems of remote sounding, biomedical images analysis, geological researches...|$|R
5000|$|Calculate the {{posterior}} probabilities [...] and all labels [...] Get the <b>image</b> <b>classification</b> result.|$|E
5000|$|<b>Image</b> <b>Classification</b> — Categorization of pixels {{based on}} {{reflectance}} into different land cover classes (e.g. Supervised classification, Unsupervised classification and Object Oriented Classification) ...|$|E
5000|$|Yakhnenko, O., and Honavar, V. (2011). Multi-Instance Multi-Label Learning for <b>Image</b> <b>Classification</b> with Large Vocabularies. In: Proceedings of the British Machine Vision Conference.|$|E
40|$|In this thesis, a Synthetic Aperture Radar (SAR) image {{classifier}} {{based on}} the "Entropy Decomposition and Support Vector Machine" (EDSVM) is developed for classification of crop fields. The key parameters extracted from Entropy Decomposition (ED) are applied to Support Vector Machine (SVM) classifier and it performs efficient <b>image</b> <b>classifications...</b>|$|R
40|$|Abstract. Fracture <b>images</b> {{automatic}} <b>classification</b> {{and recognition}} {{is an important}} one of fracture failure intelligent diagnosis, and in which feature extraction is a key issue. In this paper, fractional cosine transform, which is a useful time-frequency analysis method, is used in feature extraction of fracture images, and then the classification of fatigue, dimples, intergranular and cleavage is performed by Hidden markov model (HMM). For metal fracture <b>images</b> <b>classification,</b> experiment shows that fractional cosine transform is better than the cosine transform in fracture images feature description, and the correct recognition rate can be achieved 98. 8 % based on HMM classification mode...|$|R
30|$|In {{order to}} check the superiority of our {{proposed}} R-CNNGSR, experiments are conducted for comparing it with four baseline <b>image</b> sentiment <b>classification</b> methods. In this paper, classification accuracy is used as the performance measure to compare different <b>image</b> sentiment <b>classification</b> methods. All our experiments are carried out on a NVIDIA GTX TITAN X GPU with 12  GB memory.|$|R
5000|$|... ilastik [...] is a {{user-friendly}} free {{open source}} software for <b>image</b> <b>classification</b> and segmentation. No previous experience in image processing is required to run the software.|$|E
5000|$|In the [...] "recipe" [...] for <b>image</b> <b>classification,</b> {{groups of}} transformations are {{approximated}} with finite number of transformations. Such approximation {{is possible only}} when the group is compact.|$|E
50|$|CrowdCrafting enables its {{participants}} {{to create and}} run projects where volunteers help with <b>image</b> <b>classification,</b> transcription, geocoding and more. The platform is powered by PyBossa software, a free and open-source framework for crowdsourcing.|$|E
40|$|In this paper, {{we discuss}} about hyperspectral image {{processing}} where it {{plays an important}} role in remote sensing, hyperspectral verses multispectral image processing and <b>image</b> <b>classifications.</b> Where these <b>classifications</b> includes <b>image</b> sensors, image preprocessing, object detection, object segmentation, feature extraction and object classification. Mainly there are two types of classifications we are describing they are supervised and unsupervised classifications...|$|R
30|$|In this paper, we {{proposed}} an information transferring approach to enhance remote sensing <b>images</b> <b>classification</b> performance. The main {{idea of the}} proposed method is that the texture feature information of auxiliary data set is transferred to the target data set, and then, the classification model is trained by using SVM or KNN classifier. And finally, experimental results show our approach is feasible.|$|R
40|$|The {{essence of}} {{principal}} components analysis {{and the problem of}} dimension reduction are described. A method of principal components calculation is presented, which is based on the covariance matrix eigenvalues determination. Practical implementations of {{principal components analysis}} are described, which are based on QR-algorithm. Application of principal components analysis in space <b>images</b> <b>classification</b> for the reduction of training samples dimension is discussed...|$|R
50|$|Caffe {{supports}} {{many different}} types of deep learning architectures geared towards <b>image</b> <b>classification</b> and image segmentation. It supports CNN, RCNN, LSTM and fully connected neural network designs. Caffe supports GPU based accleration using CuDNN of Nvidia.|$|E
50|$|CNNs use {{relatively}} little pre-processing {{compared to other}} <b>image</b> <b>classification</b> algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage.|$|E
50|$|Barlow {{also worked}} {{in the field of}} {{factorial}} codes. The goal was to encode images with statistically redundant components or pixels such that the code components are statistically independent. Such codes are hard to find but highly useful for purposes such as <b>image</b> <b>classification.</b>|$|E
40|$|Deep {{convolutional}} {{neural networks}} (CNNs) {{can be applied}} to malware binary detection through <b>images</b> <b>classification.</b> The performance, however, is degraded due to the imbalance of malware families (classes). To mitigate this issue, we propose a simple yet effective weighted softmax loss which can be employed as the final layer of deep CNNs. The original softmax loss is weighted, and the weight value can be determined according to class size. A scaling parameter is also included in computing the weight. Proper selection of this parameter has been studied and an empirical option is given. The weighted loss aims at alleviating the impact of data imbalance in an end-to-end learning fashion. To validate the efficacy, we deploy the proposed weighted loss in a pre-trained deep CNN model and fine-tune it to achieve promising results on malware <b>images</b> <b>classification.</b> Extensive experiments also indicate that the new loss function can fit other typical CNNs with an improved classification performance. Comment: 5 pages, 6 figure...|$|R
30|$|A Stratified Random Sampling (SRS) {{technique}} {{was used to}} plot 299 samples (30  m[*]×[*] 30  m) on various LC features e.g. forest, agriculture, grassland, built-up area, water body etc. GPS readings (latitude, longitude and altitude) were recorded with digital camera photographs against each sample, which were added into a geo-database for record keeping. These GPS points were also used as input for satellite <b>image</b> <b>classifications</b> and to measure accuracy.|$|R
40|$|Automatic <b>classification</b> of {{histology}} <b>images,</b> {{the objective}} of our research, is aimed at supporting the pathologists in their diagnosis. In this paper, we present a comparative study between 3 D spectral/spatial analysis (SSA) and 2 D spatial analysis (SA) for the classification of colon biopsy samples from their hyperspectral <b>images.</b> <b>Classification</b> results suggest that textural analysis of 2 D bands can achieve comparable performance to 3 D spectral/spatial analysis. ...|$|R
50|$|In 2014, Padma et al. used {{combined}} wavelet statistical texture {{features to}} segment and classify AD benign and malignant tumor slices. Zhang et al. found kernel {{support vector machine}} decision tree had 80% classification accuracy, with an average computation time of 0.022s for each <b>image</b> <b>classification.</b>|$|E
50|$|The Fisher kernel {{can also}} be applied to image {{representation}} for classification or retrieval problems. Currently, the most popular bag-of-visual-words representation suffers from sparsity and high dimensionality. The Fisher kernel {{can result in a}} compact and dense representation, which is more desirable for <b>image</b> <b>classification</b> and retrieval problems.|$|E
5000|$|A common {{evaluation}} set for <b>image</b> <b>classification</b> is the MNIST database data set. MNIST {{is composed}} of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size allows multiple configurations to be tested. A comprehensive list of results on this set is available.|$|E
40|$|Conducted {{analysis}} of existing methods suitable {{for evaluation of}} stereoscopic <b>images,</b> <b>classification</b> of these methods is presented and discussed experimental paradigm {{that can be used}} to measure and calculate as two-dimensional images and video sequences. Application of subjective methods for assessing the quality of stereoscopic images onscreen. A model of visual perception stereoscopic screen images that takes into account both positive and negative factors that affect the perception of stereoscopic images. ???????? ?????? ???????????? ??????? ????????? ??? ?????? ????????????????? ???????????, ???????????? ????????????? ???? ??????? ? ??????????? ????????????????? ?????????, ??????? ????? ???? ???????????? ??? ????????? ? ?????????? ???????? ????????? ??????????? ? ????????????????????????. ?????????? ?????????? ???????????? ??????? ??? ?????? ???????? ????????????????? ???????? ???????????. ???????????? ??????? ?????????, ??????? ????????? ??? ????????????? ??? ? ????????????? ???????, ???????? ?? ?????????? ????????????????? ???????????...|$|R
40|$|This paper {{examines}} {{different approaches}} to remote sensing <b>images</b> <b>classification.</b> Included in the study are statistical approach, in particular Gaussian maximum likelihood classifier, and two different neural networks paradigms: multilayer perceptron trained with EDBD algorithm, and ARTMAP neural network. These classification methods are compared on data acquired from Landsat- 7 satellite. Experimental results showed that to achieve better performance of classifiers modular neural networks and committee machines should be applied...|$|R
40|$|AbstractMedical <b>images</b> <b>classification</b> is a {{significant}} research area that receives growing attention from both the research community and medicine industry. It addresses the problem of diagnosis, analysis and teaching purposes in medicine. For these several medical imaging modalities and applications based on data mining techniques have been proposed and developed. Thus, the primary objective of medical <b>images</b> <b>classification</b> {{is not only to}} achieve good accuracy but to understand which parts of anatomy are affected by the disease to help clinicians in early diagnosis of the pathology and in learning the progression of a disease. This furnishes motivation from the advancement in data mining techniques and particularly in soft set, to propose a classification algorithm based on the notions of soft set theory. As a result, a new framework for medical imaging classification consisting of six phases namely: data acquisition, data pre-processing, data partition, soft set classifier, data analysis and performance evolution is presented. It is expected that soft set classifier will provide better results in terms of sensitivity, specificity, running time and overall classifier accuracy...|$|R
