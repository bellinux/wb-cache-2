1|2441|Public
50|$|The LeTV uses a Qualcomm 8060 Snapdragon dual-core {{processor}} {{running at}} 1.5 GHZ, 1 GB of RAM, 8GB of flash storage, and Android 4 ICS. The LeTV has a five-megapixel webcam built into its bezel. It has a remote and game controllers. The LeTV's remote features a microphone {{necessary for the}} TV's voice recognition functions and a track pad. The game controller has track pad, and <b>embedded</b> <b>motion</b> <b>sensor.</b>|$|E
40|$|The {{advent of}} {{advanced}} mobile, gaming and augmented reality devices provides users with novel interaction modalities. Speech, finger and hand gesture recognition or even gaze detection {{are commonly used}} technologies, often enriched with data from <b>embedded</b> <b>motion</b> <b>sensors.</b> This paper describes a common human-machine interface which seamlessly combines actions based on various modalities. It discusses potential use cases, benefits and limitations of those technologies {{in the field of}} accelerator operations and maintenance...|$|R
40|$|Today’s {{smartphones}} {{are shipped}} with various <b>embedded</b> <b>motion</b> <b>sensors,</b> {{such as the}} accelerometer, gyroscope, and orientation <b>sensors.</b> These <b>motion</b> <b>sensors</b> are useful in supporting the mobile UI innovation and motion-based commands. However, they also bring potential risks of leaking user’s private information as they allow third party applications to monitor the motion changes of smartphones. In this paper, we study the feasibility of inferring a user’s tap inputs to a smartphone with its integrated <b>motion</b> <b>sensors.</b> Specifically, we utilize an installed trojan application to stealthily monitor the movement and gesture changes of asmartphoneusingitson-boardmotionsensors. Whenthe user is interacting with the trojan application, it learns the motion change patterns of tap events. Later, when the user is performing sensitive inputs, such as entering passwords on the touchscreen, the trojan application applies the learnt pattern to infer the occurrence of tap events on the touchscreen {{as well as the}} tapped positions on the touchscreen. For demonstration, we present the design and implementation of TapLogger, a trojan application for the Android platform, which stealthily logs the password of screen lock and the numbers entered during a phone call (e. g., credit card and PIN numbers). Statistical results are presented to show the feasibility of such inferences and attacks...|$|R
40|$|The {{advent of}} {{advanced}} mobile, gaming and augmented reality devices provides users with novel interaction modalities. Speech, finger- and hand gesture recognition or even gaze detection {{are commonly used}} technologies, often enriched with data from <b>embedded</b> gyroscope-like <b>motion</b> <b>sensors.</b> This paper discusses potential use cases of those technologies {{in the field of}} accelerator controls and maintenance. It describes the conceptual design of an intuitive, single-user, multi-modal human-machine interface which seamlessly incorporates actions based on various modalities in a single API. It discusses the present implementation status of this interface (Web 2 cHMI) within the Web 2 cToolkit framework. Finally, an outlook to future developments and ideas is presented...|$|R
40|$|Today's {{smartphones}} {{and mobile}} devices typically <b>embed</b> advanced <b>motion</b> <b>sensors.</b> Due to their increasing market penetration, {{there is a}} potential for the development of distributed sensing platforms. In particular, {{over the last few years}} there has been an increasing interest in monitoring vehicles and driving data, aiming to identify risky driving maneuvers and to improve driver efficiency. Such a driver profiling system can be useful in fleet management, insurance premium adjustment, fuel consumption optimization or CO 2 emission reduction. In this paper, we analyze how smartphone sensors can be used to identify driving maneuvers and propose SenseFleet, a driver profile platform that is able to detect risky driving events independently from the mobile device and vehicle. A fuzzy system is used to compute a score for the different drivers using real-time context information like route topology or weather conditions. To validate our platform, we present an evaluation study considering multiple drivers along a predefined path. The results show that our platform is able to accurately detect risky driving events and provide a representative score for each individual driver...|$|R
40|$|The {{problem that}} is {{addressed}} in this thesis {{is the need to}} record the physical location of a contact based imaging probe and subsequent measurement, specifically for using diffuse optical spectroscopic imaging. A novel motion tracking system was developed using a combination of 3 D scanned surface and <b>embedded</b> inertial/optical <b>motion</b> <b>sensors.</b> The <b>motion</b> tracking system was used in combination with a fast CW DOSI system to decrease single point measurement speed. The combination system was able to increase the spatial resolution of optical absorption measurements as compared to previous generation DOSI system. The motion tracking system was calibrated to quantify the repeatability of each sensor type as well as the projection onto the 3 D surface. The displacement sensor had average percent errors of 1. 203 % and 1. 552 % over a flat surface at 50 mm, 100 mm respectively. The average percent error increased to 3. 640 % and 3. 126 % when repeated 50 mm and 100 mm displacement tests on human skin. The projection of motion paths on a flat optical phantom, exercise ball, and human lower leg was shown. The accuracy of unknown point estimation was shown with accuracy ranging from 21. 9 %- 60 %...|$|R
40|$|Nowadays {{smartphones}} come <b>embedded</b> {{with multiple}} <b>motion</b> <b>sensors,</b> {{such as an}} accelerometer, a gyroscope and an orientation sensor. With these sensors, apps can gather more information and therefore provide end users with more functionality. However, these sensors also introduce the potential risk of leaking a user's private information because apps can access these sensors without requiring security permissions. By monitoring a device's motion, a malicious app {{may be able to}} infer sensitive information about the owner of the device. For example, related work has shown that sensitive information entered by a user on a device's touchscreen, such as numerical PINs or passwords, can be inferred from accelerometer and gyroscope data. In this paper, we study these motion-based keystroke inference attacks to determine what information they need to succeed. Based on this study, we propose two novel approaches to defend against keystroke inference attacks: 1) Reducing sensor data accuracy; 2) Random keyboard layout generation. We present the design and the implementation of these two defences on the Android platform and show how they significantly reduce the accuracy of keystroke inference attacks. We also conduct multiple user studies to evaluate the usability and feasibility of these two defences. Finally, we determine the impact of the defences on apps that have legitimate reasons to access <b>motion</b> <b>sensors</b> and show that the impact is negligible. Comment: In Proceedings of the Third Workshop on Mobile Security Technologies (MoST) 2014 ([URL]...|$|R
40|$|This bachelor's {{thesis is}} dealing with used some <b>motion</b> <b>sensors</b> works at {{different}} physical principles, the dismantling of thein basic characteristics and design <b>motion</b> <b>sensor</b> with available optoelectronic components in area of infrared radiation. The proposed <b>motion</b> <b>sensor</b> is compared with commonly available pyroelectric sensor...|$|R
40|$|<b>Motion</b> <b>sensors</b> {{and cameras}} {{can be used}} {{together}} to build in-home video monitoring systems, where the cameras are only activated when the <b>motion</b> <b>sensors</b> detect <b>motion.</b> This saves both bandwidth (reduced video storage and/or transmission) as well as energy (if the cameras are battery-operated). However, <b>motion</b> <b>sensors</b> and cameras have different fields of view (FoV), and thus {{it is not clear}} that attaching <b>motion</b> <b>sensors</b> to cameras provides the most efficient system. Therefore, it is necessary to evaluate the performance of systems where the <b>motion</b> <b>sensors</b> are attached to the cameras (attached scenario) as well as where the <b>motion</b> <b>sensors</b> are detached from the cameras (detached scenario). We consider the <b>motion</b> <b>sensor</b> and camera placement problem under these two scenarios, with an additional hybrid scenario, and we formulate optimization problems to achieve the minimum energy consumption, longest network lifetime, or lowest cost. Simulation results show the tradeoffs between different objectives for all three scenarios. Peer ReviewedPostprint (published version...|$|R
40|$|The {{purpose of}} this study was to conduct a {{comprehensive}} evaluation of the effect that walking speed, gender, leg length, <b>motion</b> <b>sensor</b> tilt angle, brand, and placement have on <b>motion</b> <b>sensor</b> step-counting error. Fifty-nine participants performed treadmill walking trials at 6 speeds while wearing 5 <b>motion</b> <b>sensor</b> brands placed on the anterior (Digiwalker,DW; Walk 4 Life, WFL; New Lifestyles, NL; Omron, OM), midaxillary (DW; WFL; NL; ActiGraph, AG), and posterior (DW, WFL, NL) aspects of the waistline. The anterior-placed NL and midaxillary-placed AG were the most accurate <b>motion</b> <b>sensors.</b> <b>Motion</b> <b>sensor</b> step-count error tended to decrease at faster walking speeds, with lesser tilt angles,and with an anterior waistline placement. Gender and leg length had no effect on <b>motion</b> <b>sensor</b> step-count error. We conclude that the NL and AG yielded the most accurate step counts at a range of walking speeds in individuals with different physical characteristics...|$|R
40|$|Abstract—Motion {{sensors and}} cameras {{can be used}} {{together}} to build in-home video monitoring systems, where the cameras are only activated when the <b>motion</b> <b>sensors</b> detect <b>motion.</b> This saves both bandwidth (reduced video storage and/or transmission) as well as energy (if the cameras are battery-operated). However, <b>motion</b> <b>sensors</b> and cameras have different fields of view (FoV), and thus {{it is not clear}} that attaching <b>motion</b> <b>sensors</b> to cameras provides the most efficient system. Therefore, it is necessary to evaluate the performance of systems where the <b>motion</b> <b>sensors</b> are attached to the cameras (attached scenario) as well as where the <b>motion</b> <b>sensors</b> are detached from the cameras (detached scenario). We consider the <b>motion</b> <b>sensor</b> and camera placement problem under these two scenarios, with an additional hybrid scenario, and we formulate optimization problems to achieve the minimum energy consumption, longest network lifetime, or lowest cost. Simulation results show the tradeoffs between different objectives for all three scenarios. I...|$|R
40|$|Recognition of body {{posture and}} motion is an {{important}} physiological function that can keep the body in balance. Man-made <b>motion</b> <b>sensors</b> have also been widely applied for {{a broad array of}} biomedical applications including diagnosis of balance disorders and evaluation of energy expenditure. This paper reviews the state-of-the-art sensing components utilized for body motion measurement. The anatomy and working principles of a natural body <b>motion</b> <b>sensor,</b> the human vestibular system, are first described. Various man-made inertial sensors are then elaborated based on their distinctive sensing mechanisms. In particular, both the conventional solid-state <b>motion</b> <b>sensors</b> and the emerging non solid-state <b>motion</b> <b>sensors</b> are depicted. With their lower cost and increased intelligence, man-made <b>motion</b> <b>sensors</b> are expected to play an increasingly important role in biomedical systems for basic research as well as clinical diagnostics...|$|R
50|$|The {{heads-up display}} has an inventory, health and oxygen bars, and a <b>motion</b> <b>sensor.</b> The <b>motion</b> <b>sensor</b> {{displays}} alien creatures as red triangles and friendly humans or robots as green squares; it tracks their motion {{relative to the}} player, represented by a square in the middle whenever the player moves. The brightness of the middle square represents how still the player is and how well he can be tracked. On some levels the <b>motion</b> <b>sensor</b> is erratic due to magnetic artificial gravity fields.|$|R
40|$|With the {{development}} of motion sensing technology, <b>motion</b> <b>sensor</b> based services have been put into {{a wide range of}} applications in recent years. Demand of consuming such service on mobile devices has already emerged. However, as most <b>motion</b> <b>sensors</b> are specifically designed for some heavyweight clients such as PCs or game consoles, there are several technical challenges prohibiting <b>motion</b> <b>sensor</b> from being used by lightweight clients such as mobile devices, for example: There is no direct approach to connect the <b>motion</b> <b>sensor</b> with mobile devices. Most mobile devices don't have enough computational power to consume the <b>motion</b> <b>sensor</b> outputs. To address these problems, I have designed and implemented a framework for publishing general <b>motion</b> <b>sensor</b> functionalities as a RESTful web service that is accessible to mobile devices via HTTP connections. In the framework, a pure HTML 5 based interface is delivered to the clients to ensure good accessibility, a websocket based data transferring scheme is adopted to guarantee data transferring efficiency, a server side gesture pipeline is proposed to reduce the client side computational burden and a distributed architecture is designed to make the service scalable. Finally, I conducted three experiments to evaluate the framework's compatibility, scalability and data transferring performance...|$|R
30|$|Although we {{consider}} both our movement and linguistic models {{to be good}} estimates for deriving expert-level text entry rate predictions, they nevertheless show some limitations which {{are discussed in the}} following. The movement model relies on the user's motor characteristics, i.e. the time needed to complete the discrete-tilt action. This parameter was empirically determined within the respective experiment in which a single smartphone device was used for testing. Since different smartphone manufacturers do not necessarily <b>embed</b> the same <b>motion</b> <b>sensors</b> in their device models, a further study should investigate if discrete-tilt time is in fact device-independent. The testing application used in this work can be applied for evaluating discrete-tilt handling on various smartphones under the Android OS. When it comes to the linguistic model, {{it should be noted that}} it is limited to a 29 × 29 digraph matrix, and does not include uppercase letters, numbers, or supplementary symbols. However, unlike some previous work in this domain, the punctuation marks period and comma exist in the model. While numbers and supplementary symbols (such as ampersand, asterisk, backslash, etc.) are less frequent in the language corpus, uppercase letters are more common, hence their involvement could improve the accuracy of the linguistic model. Adding new 26 letters to the available character set would require a new calculation of digraph probabilities in a 55 × 55 matrix. The movement model would have to be modified then as well, with minimal number of tilts being calculated on the ground of alternating keyboard layouts (between lowercase and uppercase, via the shift function).|$|R
50|$|By using a <b>motion</b> <b>sensor,</b> the {{vertical}} {{movement of the}} flexible tube can be measured by observing the difference in distance of a particular point on the flexible tube. As the tube moves {{up and down the}} <b>motion</b> <b>sensor</b> will observe a repeating difference in distance.|$|R
50|$|Security: home {{intrusion}} <b>motion</b> <b>sensors</b> and perimeter surveillance.|$|R
5000|$|<b>Motion</b> <b>sensors</b> are {{devices that}} use {{various forms of}} {{technology}} to detect movement. The technology typically found in <b>motion</b> <b>sensors</b> to trigger an alarm includes infrared, ultrasonic, vibration and contact. Dual technology sensors combine two or more forms of detection {{in order to reduce}} false alarms as each method has its advantages and disadvantages. Traditionally <b>motion</b> <b>sensors</b> {{are an integral part of}} a home security system. These devices are typically installed to cover a large area as they commonly cover up to 40ft with a 135&#176; field of vision.|$|R
30|$|<b>Motion</b> <b>sensors</b> (e.g. radar gun, speedometer, mercury switches, tachometer).|$|R
5000|$|<b>Motion</b> <b>sensors,</b> light sensors, {{built-in}} timers {{and automatic}} sprinklers ...|$|R
50|$|The PlayStation Camera is a <b>motion</b> <b>sensor</b> {{and camera}} {{accessory}} for the PlayStation 4, developed by Sony Interactive Entertainment. It is {{the successor to}} the PlayStation Eye for the PlayStation 3, which was released in 2007. It is also the <b>motion</b> <b>sensor</b> used to track the PlayStation VR virtual reality headset.|$|R
50|$|The <b>motion</b> <b>sensor</b> {{can also}} be read by {{programs}} running on the Apple portables {{and a number of}} programs exist that use the <b>motion</b> <b>sensor</b> to make the computer tilt-aware http://osxbook.com/software/sms/. This way, tilting {{can be used as a}} human interface device for instance for scrolling or for controlling games.|$|R
50|$|<b>Motion</b> <b>sensor</b> {{lights at}} all entry points into the residence.|$|R
5000|$|<b>Motion</b> <b>sensors</b> (various {{technologies}} including: Audible sound, inaudible sound, infrared) ...|$|R
40|$|Smartwatches enable many novel {{applications}} and are fast gaining popularity. However, {{the presence of}} a diverse set of on-board sensors provides an additional attack surface to malicious software and services on these devices. In this paper, we investigate the feasibility of key press inference attacks on handheld numeric touchpads by using smartwatch <b>motion</b> <b>sensors</b> as a side-channel. We consider different typing scenarios, and propose multiple attack approaches to exploit the characteristics of the observed wrist movements for inferring individual key presses. Experimental evaluation using commercial off-the-shelf smartwatches and smartphones show that key press inference using smartwatch <b>motion</b> <b>sensors</b> is not only fairly accurate, but also comparable with similar attacks using smartphone <b>motion</b> <b>sensors.</b> Additionally, hand movements captured by a combination of both smartwatch and smartphone <b>motion</b> <b>sensors</b> yields better inference accuracy than either device considered individually...|$|R
40|$|Objective: Replacing {{physical}} activity with videogaming has {{been implicated in}} causing obesity. Studies have shown that using motion-sensing controllers with activity-promoting videogames expends energy comparable to aerobic exercise; however, effects of motion-sensing controllers have not been examined with traditional (non–exercise-promoting) videogames. Materials and Methods: We measured indirect calorimetry and heart rate in 14 subjects during rest and traditional videogaming using <b>motion</b> <b>sensor</b> and joystick controllers. Results: Energy expenditure was higher while subjects were playing with the <b>motion</b> <b>sensor</b> (1. 30 ± 0. 32 [*]kcal/kg/hour) than with the joystick (1. 07 ± 0. 26 [*]kcal/kg/hour; P< 0. 01) or resting (0. 91 ± 0. 24 [*]kcal/kg/hour; P< 0. 01). Oxygen consumption during videogaming averaged 15. 7 percent of predicted maximum for the <b>motion</b> <b>sensor</b> and 11. 8 percent of maximum for the joystick. Minute ventilation was higher playing with the <b>motion</b> <b>sensor</b> (10. 7 ± 3. 5 L/minute) than with the joystick (8. 6 ± 1. 8 L/minute; P< 0. 02) or resting (6. 7 ± 1. 4 L/minute; P< 0. 001), predominantly because of higher respiratory rates (15. 2 ± 4. 3 versus 20. 3 ± 2. 8 versus 20. 4 ± 4. 2 beats/minute for resting, the joystick, and the <b>motion</b> <b>sensor,</b> respectively; P< 0. 001); tidal volume did not change significantly. Peak heart rate during gaming was 16. 4 percent higher than resting (78. 0 ± 12. 0) for joystick (90. 1 ± 15. 0; P= 0. 002) and 17. 4 percent higher for the <b>motion</b> <b>sensor</b> (91. 6 ± 14. 1; P= 0. 002); mean heart rate did not differ significantly. Conclusions: Playing with a <b>motion</b> <b>sensor</b> burned significantly more calories than with a joystick, but the energy expended was modest. With both consoles, the increased respiratory rate without increasing tidal volume and the increased peak heart rate without increasing mean heart rate are consistent with psychological stimulation from videogaming, rather than a result of exercise. We conclude that using a <b>motion</b> <b>sensor</b> with traditional videogames does not provide adequate energy expenditure to provide cardiovascular conditioning...|$|R
25|$|A <b>motion</b> <b>sensor</b> {{which uses}} {{low-power}} microwave radar {{for the same}} effect.|$|R
5000|$|Simple ONE-NET {{devices such}} as <b>motion</b> <b>sensors</b> have modest host {{processor}} requirements: ...|$|R
40|$|This work {{considers}} <b>motion</b> <b>sensors</b> as {{parts of}} the smart lighting system on basis of Beaglebone microcomputer. Detection system is designed for the smart lighting system. Experimental investigations of the detection system were made with different <b>motion</b> <b>sensors.</b> Based on the results comparative analysis was performed and optimal conditions for the detection system operation were found...|$|R
40|$|The {{purpose of}} this review {{was to examine the}} utility and {{accuracy}} of commercially available <b>motion</b> <b>sensors</b> to measure step-count and time spent upright in frail older hospitalized patients. A database search (CINAHL and PubMed, 2004 – 2014) and a further hand search of papers’ references yielded 24 validation studies meeting the inclusion criteria. Fifteen <b>motion</b> <b>sensors</b> (eight pedometers, six accelerometers, and one sensor systems) have been tested in older adults. Only three have been tested in hospital patients, two of which detected postures and postural changes accurately, but none estimated step-count accurately. Only one <b>motion</b> <b>sensor</b> remained accurate at speeds typical of frail older hospitalized patients, but it has yet to be tested in this cohort. Time spent upright can be accurately measured in the hospital, but further validation studies are required to determine which, if any, <b>motion</b> <b>sensor</b> can accurately measure step-count...|$|R
30|$|Fitness {{trackers}} {{are usually}} equipped with <b>motion</b> <b>sensors</b> such as accelerometer and gyroscope.|$|R
50|$|Tilt Pak — A combo Rumble Pak and <b>Motion</b> <b>sensor</b> made by Pelican.|$|R
5000|$|... #Subtitle level 2: 360 degree <b>sensor</b> / 3D <b>Motion</b> <b>sensor</b> / HID device ...|$|R
40|$|Psychophysical {{experiments}} on feature tracking suggest {{that most of}} our sensitivity to chromatic motion and to second-order motion depends on feature tracking. There {{is no reason to}} suppose that the visual system contains <b>motion</b> <b>sensors</b> dedicated to the analysis of second-order motion. Current psychophysical and physio- logical data indicate that local <b>motion</b> <b>sensors</b> are selective for orientation and spatial frequency but they do not eliminate any of the three main models—the Reichardt de- tector, the motion-energy filter, and gradient-based sensors. Both psychophysical and physiological data suggest that both broadly oriented and narrowly oriented <b>motion</b> <b>sensors</b> are important in the early analysis of motion in two dimensions...|$|R
5000|$|Door opener - Automatic {{door opening}} device {{activated}} by <b>motion</b> <b>sensors</b> or pressure pads ...|$|R
40|$|Lighting and {{ventilation}} {{represent the}} majority of the air conditioning loads in office buildings in hot humid climates. Use of <b>motion</b> <b>sensors</b> is one way to minimize the energy used for these loads. This paper describes the methods used for simulating a case study building with <b>motion</b> <b>sensors</b> installed and the monitoring of system on-off statistics related to occupant patterns. It also describes the development of the Monte Carlo model used to predict the on-off status of sensors. The building using the <b>motion</b> <b>sensors</b> is compared to a building that controls the lights and ventilators by a conventional pre-programmed schedule. The conventional methods of simulation were shown to generate misleading information regarding electric demand charges and life-cycle costs of the building. When comparing to actual use patterns, the Monte Carlo process was shown to represent an adequate way to represent the on-off patterns. Computer simulations further demonstrate the potential life cycle cost savings from the use of the <b>motion</b> <b>sensors...</b>|$|R
