7|34|Public
50|$|In {{the central}} part of the {{southern}} wing is a hall with a flat ceiling and a Baroque style parquet floor. One of the best preserved rooms is called Johanna's room. On the outer side a manual lift (dumbwaiter) was used to transfer food from the kitchen to the rooms. Also of interest is the food distribution area with a small, well preserved, built-in cabinet and barrier, and a <b>distribution</b> <b>counter</b> with cupboards.|$|E
40|$|Abstract—This paper {{proposes a}} fair packet {{distribution}} scheme on a multi-interfaced mobile router (MMR) for mobile networks. In the proposed scheme, the MMR with multiple heterogeneous wireless network interfaces effectively and fairly distributes incoming packets over end-to-end multi-path. Each network interface {{is considered to}} have a <b>distribution</b> <b>counter</b> associated with corresponding end-to-end path. This <b>distribution</b> <b>counter</b> varied by both weighted capacity and distributed packets is used {{to determine if a}} network interface has enough credits to distribute incoming packets on corresponding end-to-end path. As a useful design parameter, the capacity unit can be shown to make the performance of the proposed scheme as good as possible. Through computer simulations, it is shown that the proposed scheme can distribute well randomly incoming packets over end-to-end multi-path and can outperform the simple weighted packet distribution scheme...|$|E
40|$|Abstract. Let {Ri; i ≥ 1 } be the {{sequence}} of record values generated from a sequence of i. i. d. continuous random variables, coming from a big class of distributions in the exponential family. In this paper we study the behavior of k-spacings of Ri, that is, Rk+i − Ri for i ≥ 1. We show that, under certain conditions, a normalized k-spacings empirically converges to a Gamma <b>distribution.</b> <b>Counter</b> examples show that the result is not valid when the conditions are violated. A strong law and a limiting distribution of the largest normalized spacings are also derived. In particular, these results conclude that the k-spacings go to infinity when the population distribution has heavy tail; the spacings go to zero when the tail is not heavy. Exact speeds of such convergence are obtained. ...|$|E
50|$|The {{cafeteria}} {{is composed}} of two halls. Both halls were used for special lunch time, but special lunch time has been eliminated, so now only one hall is used. Each hall has two Food <b>Distribution</b> <b>counters</b> and one station to return used utensils.|$|R
40|$|An {{important}} {{challenge in}} quantum science is {{to fully understand}} the efficiency of energy flow in networks. Here we present a simple and intuitive explanation for the intriguing observation that optimally efficient networks are not purely quantum, but are assisted by some interaction with a `noisy' classical environment. By considering the system's dynamics in both the site-basis and the momentum-basis, we show {{that the effect of}} classical noise is to sustain a broad momentum <b>distribution,</b> <b>countering</b> the depletion of high mobility terms which occurs as energy exits from the network. This picture predicts that the optimal level of classical noise is reciprocally related to the linear dimension of the lattice; our numerical simulations verify this prediction to high accuracy for regular 1 D and 2 D networks over a range of sizes up to thousands of sites. This insight leads to the discovery that dramatic further improvements in performance occur when a driving field targets noise at the low mobility components...|$|R
40|$|A set of {{examples}} is described {{which suggests that}} members of a certain class of Markov processes have infinitely divisible limit <b>distributions.</b> A <b>counter</b> example rilles out such a possibility and {{raises the question of}} what further restrictions are required to guarantee infinitely divisible limits. Some related examples illustrate the same occurrence of infinitely divisible limit distributions. For both settings, an easily checked necessary and sufficient condition is obtained for the existence of a limit distribution...|$|R
40|$|DISCOVER 1 (<b>DIStribution</b> <b>COunter</b> VERsion 1) is a {{new program}} that can {{identify}} DNA motifs occurring with a high deviation from the expected frequency. The program generates families of patterns, each family having {{a common set of}} defined bases. Undefined bases are inserted amongst the defined bases in different ways, thus generating the diverse patterns of each family. The occurrences of the different patterns are then compared and analysed within each family, assuming that all patterns should have the same probability of occurrence. An extensive use of computer memory, combined with the immediate sorting of counts by address calculation allow a complete counting of all DNA motifs on a single pass on the DNA sequence. This approach offers a very fast way to search for unusually distributed patterns and can identify inexact patterns as well as exact patterns...|$|E
40|$|Let {Ri; i ≥ 1 } be the {{sequence}} of record values generated from a sequence of i. i. d. continuous random variables, with distribution from the exponential family. In this paper we study the behavior of k-spacings of Ri, that is, Rk+i−Ri for i ≥ 1. We show that, under certain conditions, a normalized k-spacings empirically converges to a Gamma <b>distribution.</b> <b>Counter</b> examples show that the result is not valid when the conditions are violated. A strong law and a limiting distribution of the largest normalized spacings are also derived. In particular, these results conclude that the k-spacings go to infinity when the population distribution has heavy tail; the spacings go to zero when the tail is not heavy. Exact speeds of such convergence are obtained. 1 Introduction and main results The record values was first studied by Chandler (1952). For full account of history and references, see [1], [7] and [21]. A lot of properties on record values were understood: the joint distributions of record values was characterized, see, e. g., p. 165 in [21]; the limiting distributions of records were {{proved to be the}} extreme value distributions, see, e. g., p. 174 in [21]; the extremal process, whic...|$|E
40|$|To reuse ontologies of {{different}} types, ontology mediation {{is required to}} reconcile mismatches between heterogeneous ontologies. Ontology integration {{is one of the}} major kind of ontology mediations in which an ontology is selected to integrate either directly into an ontology development process if no other suitable ontology is available or into an ontology development process with other chosen ontology(ies). The integration methodology developed by Pinto and Martins has two major limitations in its design: 1) the methodology only focuses on how to find, select and integrate existing ontologies but fails to recognize integration itself is part of an ontology development process, and 2) the methodology also fails to be supported by any form of semi- or automatic tools especially in finding suitable knowledge modules from a group of candidate ontologies. To address the above limitations, this research proposes a new ontology integration methodology that provides a detailed description on how to incorporate and perform integration including elicitation of key terms, identification of source ontologies and their knowledge modules, and application of ontology integration. This research also proposes a semiautomatic tool called Integration-oriented Candidate Ontology Evaluation System (ICOES) that can be used to find suitable source ontologies from a group of candidate ontologies using as a single or a combination of matching techniques as well as concept <b>distribution</b> <b>counter.</b> Based on the matching results generated by the ICOES, the most appropriate candidate ontologies can be selected as source ontologies...|$|E
40|$|The {{emission}} of multiply-charged fragments (Z > 3) in nu. c lear rea ct ions was f ir st recorded by Perk ins (1) who studied disintegrations caused by cosmic rays. Subsequently {{the production of}} complex particles has been observed in many nuclear reactions induced by projectiles {{with a wide range}} of energies. The {{emission of}} these fragments has been investigated with respect to fragment yield, charge, energy, and angular <b>distribution,</b> using <b>counter,</b> radiochemical, and emulsion techniques...|$|R
50|$|Predictably, he ran {{up against}} the Population Council, who wanted {{complete}} control of IUD trials and <b>distribution.</b> Clarence <b>countered</b> by opening his own manufacturing plant in Hong Kong. By 1964, David Burleson had been brought in to supervise Pathfinder's worldwide IUD project, and Clarence was receiving reports on the IUD from 72 doctors in 32 countries. At {{the time of his}} death in 1966, The Pathfinder Fund was delivering IUDs to 504 doctors in 74 countries.|$|R
30|$|Summary. The results fully {{meet the}} {{expectations}} and backup our theoretical analysis. We {{have shown that}} our initial assumptions allow fundamental improvements over previous suggestions. Experiments {{have shown that the}} EHT performs as theoretically expected. This makes the EHT highly predictable and allows easy configuration for target applications. The effects of parameters on <b>counter</b> <b>distribution,</b> bucket load, <b>counter</b> and bucket overflows can easily be predicted. Evaluation shows, which hardware configurations are required for specific parameter sets. The effect of Huffman compression is much harder to predict, since all possible combinations of counter values per word would need to be predicted which is impractical. However, evaluation shows the effect of Huffman compression compared to no compression and simple word-based encoding.|$|R
40|$|Knowledge enables {{organizations}} to utilize and develop resources, enhance their competitiveness and develop sustainable competitive advantage. Knowledge management aims {{to manage and}} capitalize on knowledge by organizing formal and direct process to manage organizational knowledge in the workplace. Literature has shown {{that a number of}} knowledge management approaches have been developed with the purpose of managing organizational knowledge. However, these designs only focus on managing intra-organizational knowledge which is inadequate in the current business environment because users often require to access interorganizational knowledge from other knowledge sources in order to complete tasks in current knowledge explosion era. Furthermore, current knowledge management approaches also fail to make various knowledge management systems inter-operable and collaborative in nature due to individual knowledge management system is designed and developed based on business and knowledge management requirement. As a result, knowledge workers need to spend additional effort to search for relevant knowledge from various knowledge bases and knowledge engineers have {{to spend a lot of}} resources to create and update organizational knowledge which may also be available in other knowledge management systems. This research examines an ontology-based knowledge management approach to enable the interoperation of heterogeneous knowledge management systems in the domain of reusing inter-organizational knowledge. An ontology-based Collaborative Inter-organizational Knowledge Management Network is proposed that incorporates ontology and its mediation methods to reuse inter-organizational knowledge to support knowledge creation and dissemination in the organizational knowledge management process. This research also investigates a theoretical ontology mediation framework to develop an integrated ontology by reusing interorganizational ontologies. A Methodology of Integration-oriented Ontology Development is proposed to address the lack of details and insights in ontology integration in the current literature. The proposed methodology is designed to provide a detailed description of phases on how to incorporate and perform integration in its ontology development process. A semi-automatic tool called Integration-oriented Candidate Ontology Evaluation System is included as a component of the proposed methodology to assist in finding suitable source ontologies from a group of candidate ontologies using concept <b>distribution</b> <b>counter</b> and ontology matching techniques. In addition, a Design and Input-Specific Classification of Ontology Matching Technique is proposed to provide guidelines on designing a new mediation tool and method to identify appropriate matching technique and its related executive approach. This research makes research contributions in the area of applying ontology and its mediation methods to develop and manage inter-organizational knowledge management process...|$|E
40|$|Traditionally, the low doping {{efficiency}} in alpha -Si:H has been {{explained by the}} argument that dopant atoms are incorporated into under- or over-coordinated sites and, therefore, inert in such configurations. However, recent molecular dynamic simulations proved that this view is not generally correct. In the present paper we suggest a purely electronic analytic model explaining the low doping {{efficiency in}} amorphous semiconductors. The model shows that, in a random network of localized states, the Coulomb interaction between ionized dopant atoms and the resulting localized charge carriers leads {{to changes in the}} electronic density-of-states (DOS) <b>distribution</b> which <b>counter</b> the intended shift of the Fermi-level positionstatus: publishe...|$|R
30|$|We first {{evaluate}} {{the performance of}} the EHT with respect to lookups. To achieve deterministic lookup performance, it is crucial that <b>counter</b> value <b>distribution</b> and bucket loads behave as expected. <b>Counter</b> <b>distribution</b> affects the maximum allowed counter value, which in turn affects the effectiveness of summary compression and the number of entries that have to be moved to CAM due to counter overflows.|$|R
50|$|As {{a result}} of the report of the panel on United Nations Peace Operations (known as the Brahimi Report), SOG's {{functions}} expanded to bridge existing shortfalls in field security, specifically in strategic information services (intelligence gathering, analysis and <b>distribution),</b> operations training, <b>counter</b> terrorism, close protection of senior or specialist UN staff in high threat environments, special operations/projects, Civil-Military Co-operation (CIMIC), Rule of Law support and internal mission oversight.|$|R
50|$|Television {{and radio}} {{stations}} in the Philippines display the time, but varied from {{a few seconds to}} minutes. In September 2011, the Department of Science and Technology proposed to synchronise time nationwide in an effort to discourage tardiness. PAGASA installed a rubidium atomic clock, a GPS receiver, a time interval <b>counter,</b> <b>distribution</b> amplifier and a computer to help calculate the time difference with every satellite within its antenna’s field of view.|$|R
40|$|Ewald summation, {{which has}} become the de facto {{standard}} for computing electrostatic interactions in biomolecular simulations, formally requires that the simulation box is neutral. For non-neutral systems the Ewald algorithm implicitly introduces a uniform background charge distribution that e ectively neutralizes the simulation box. Because a uniform <b>distribution</b> of <b>counter</b> charges typically deviates from the spatial distribution of counterions in real systems, artifacts may arise, in particular in systems with an inhomogeneous dielectric constant. Here we derive an analytical expression for the e ect of using an implicit background charge instead of explicit counterions, on the chemical potential of ions in heterogeneous systems, which (i) provides a quantitative criterium for deciding if the background charge o ers an acceptable trade-o between artifacts arising from sampling problems and artifacts arising from the homogeneous background charge distribution; and (ii) {{can be used to}} correct this artifact in certain cases. Because the artifact is due to the di erence in charge density between the non-neutral system with a uniform neutralizing background charge and the real neutral system with a physically correct distribution of explicit counterions, our model quanti es the artifact in terms of this di erence. We show that for inhomogeneous systems, such as proteins and membranes in water, the artifact manifests itself by an overstabilization of ions inside the lower dielectric by tens to even hundreds kilojoules per mole. We have tested the accuracy of our model in molecular dynamics simulations and found that the error in the calculated free energy for moving a test charge from water into a hexadecane/water slab at di erent net charges of the system and di erent simulation box sizes, is correctly predicted by the model, con rming that the incorrect <b>distribution</b> of <b>counter</b> charges in the simulation box is solely responsible for the errors in the PMFs...|$|R
50|$|Wright {{had been}} an {{employee}} of Brøderbund when he first developed the concept, so Braun {{and he had to}} return there to clear the rights to SimCity. Brøderbund had just set up a new <b>distribution</b> office to <b>counter</b> the Electronic Arts (EA) Affiliated Label program. Brøderbund executives Gary Carlston and Don Daglow saw SimCity, recognized its potential and urged Braun to sign a distribution deal with Brøderbund for the game. Braun wanted the jet fighter game included in the deal, and Brøderbund agreed.|$|R
40|$|ABSTRACT: The {{relation}} between. <b>counter</b> ion <b>distribution,</b> ion {{mobility and}} degree of contraction has been studied on hydrobiotite (2 - 5 / ~ size), equilibrated with mixed RbCI-SrCle solutions. From X-ray data, isotopic exchange and chemical extraction, {{it appears that the}} counter ions of the contracted portions of the interlayers are not in equilibrium with the solution phase. The <b>distribution</b> of <b>counter</b> ions in the interlayer space follows a gradient from the margin of the mineral to the centre. This distribution {{is the result of the}} interruption of a diffusion process, caused by the contraction of layers during exchange. Isotopic exchange is rapid on the external surfaces and in the expanded portions of the interlayers, but very slow in the contracted part, where the rate of exchange amounts to only 0 " 002 - 0 " 02 m-eq/ 100 g/day, and decreases with time. On ex-change with MgCI 2 solutions, secondary expansion of the interlayer space occurs and some of the counter ions trapped in the contracted regions are released...|$|R
40|$|Most of today’s {{wireless}} LANs and PANs {{employ the}} use of the CSMA/CA protocol. In CSMA/CA, a randomly initialised counter is used to reduce the probability of nodes accessing the channel at the same time. In most implementations, this counter is suspended when the channel is idle. In this paper, we derive and verify through simulation the exact analytical expression for the <b>distribution</b> of this <b>counter’s</b> value. For further validation, we show how {{it can be used to}} obtain the protocol’s idle period distribution under saturation loads. For this latter distribution, we provide simulation results to show the accuracy of the formula compared to one derived using the de-facto first-order Markov channel state model...|$|R
40|$|This {{document}} {{provides a}} common implementation-independent {{basis for the}} interoperable application of the IP Flow Information Export (IPFIX) protocol to the handling of Aggregated Flows, which are IPFIX Flows representing packets from multiple Original Flows sharing some set of common properties. It does this through a detailed terminology and a descriptive Intermediate Aggregation Process architecture, including a specification of methods for Original Flow counting and <b>counter</b> <b>distribution</b> across intervals. Status of This Memo This is an Internet Standards Track document. This document {{is a product of}} the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
40|$|A {{new model}} for the residence-time <b>distribution</b> in a <b>counter</b> {{rotating}} twin-screw extruder is compared with experimental results obtained during the gelatinisation of starch and the grafting of polystyrene on starch. The model consists of a transfer function from which the first three moments can be derived {{and is based on}} physical principles without any adjustable parameters. In the model and during experiments, parameters like screw rotation, fully filled length and throughput have been varied. By comparing calculated residence-time distributions with the measurements conclusions about the extruder hold-up and the fully filled extruder length can be drawn. As an extra parameter, the density change of the extruded material was needed to model the residence-time distribution curve during the grafting of polystyrene on starch. ...|$|R
40|$|Approximate {{counting}} [18] {{is useful}} for data stream and database summarization. It can help in many settings that allow only one pass over the data, want low memory usage, and can accept some relative error. Approximate counters use fewer bits; we focus on 8 -bits but our results are general. These small counters represent a sparse sequence of larger numbers. Counters are incremented probabilistically based on the spacing between the numbers they represent. Our contributions are a customized <b>distribution</b> of <b>counter</b> values and efficient strategies for deciding when to increment them. At run-time, users may independently select the spacing (accuracy) of the approximate counter for small, medium, and large values. We allow the user to select the maximum number to count up to, and our algorithm will select the exponential base of the spacing. These provide additional flexibility over both classic and Csűrös’s [4] floating-point approximate counting. These provide additional structure, a useful schema for users, over Kruskal and Greenberg [13]. We describe two new and efficient strategies for incrementing approximate counters: use a deterministic countdown or sample from a geometric distribution. In Csűrös all increments are powers of two, so random bits rather than full random numbers can be used. We also provide the option to use powers-of-two but retain flexibility. We show when each strategy is fastest in our implementation. Categories and Subject Descriptors E. 4 [Coding and information theory]: Data compactio...|$|R
40|$|IN THIS STUDY WE IVESTIGATED THE PRESENCE OF BIOLOGICAL ACTIVE SUBSTANCES AT THE LIPIDS ΟF THE FISH S. SCOMRUS. AFTER THE EXTRACTION OF LIPIDS,SEPERATION IN NEUTRAL AND POLAR LIPIDS HAS BEEN ACHIEVED WITH CURRENT <b>COUNTER</b> <b>DISTRIBUTION.</b> EACH OF THE ABOVE LIPID CATEGORIES HAS BEEN SEPARATED INTO THEIR CLASSES WITH HPLC. EACH FRACTION DERIVED FROM HPLC SEPARATIONS HAS BEEN TESTED FOR BIOLOGICAL ACTIVITY. WE HAVE ISOLATED 23 ACTIVE FRACTIONS WHICH BELONG TO NEUTRAL LIPIDS THAT INHIBITED THE PAF-INDUCED AGGREGATION. IN RABBIT PLATELETS. IN TWO OF THESE FRACTIONS STRUCTURAL STUDIES(NMR,MS) WERE PERFORMED. WE HAVE ALSO DETECTED SIX POLAR LIPID FRACTIONS WITH INHIBITED PAF-INDUCED AGGREGATION. FOUR FRACTIONS,WHICH INDUCED WASHED PLATELET AGGREGATION HAVE BEEN DETECTED. IN TWO OF THE ABOVE FRACTIONS STRUCTURAL STUDIES WERE PERFORMED USING THE ES-MS TECHNIQUE AND THEY HAVE BEEN IDENTIFIED AS PAF ANALOGES. ADDIOTIONALLY WE DETECTED A SMALL NUMBER OF FRACTIONS WHICH WERE ELUTED IN THE REGION OF GANGLIOSIDES. THESE FRACTIONS WERE MAINLY MONO-SIALO-GANGLIOSIDES BEEN PRESENT AS PROTEOLIPID TYPE COMPLEX. ...|$|R
40|$|This thesis {{examines}} {{various groups}} of athletes {{to assess whether}} they are at risk with regard to kidney stone formation. Particle size <b>distribution</b> analysis (Coulter <b>counter),</b> ultra-structural analyses (SEM) and urine analysis were conducted. The background to various factors relating to stone formation is discussed {{as well as the}} general theory behind the techniques employed. The methods utilized and data obtained are described. Particle size distribution analysis and scanning electron· micrographs suggest that marathon runners and cyclists may be at risk with respect to stone formation. Dehydration and urinary tract trauma are thought to occur in the former whereas dehydration only is operative in the latter. Results obtained from Na/Ca ratio analyses are found to correspond with the particle size analyses thereby suggesting that this ratio may have potential as a useful index of stone-forming risk. The enormous spread of values amongst each class of athlete shows, however, that physical exertion is not the sole factor affecting the Na/Ca ratio...|$|R
30|$|Finally, {{it will be}} {{important}} to know the distribution of subsidy payments across firms. Several studies have found that participation in employer subsidies is highest among large firms, and that many small firms are unaware of the subsidy. Subsidy administrators need to know whether this is true in their case and if it is, to take corrective actions to inform nonparticipating companies. It will also {{be important}} to know the distribution of the subsidy across industries and geographic or political regions, since uneven <b>distribution</b> may run <b>counter</b> to national development goals. To the extent that data on firm size, location, and industry are not already available from government records, it is relatively easy to collect it from firms claiming the subsidy. In sum, for management purposes, a subsidy program needs not only a system for generating descriptive statistics from data flowing in from eligibility determinations and subsidy payments, but should also collect ancillary data from sample surveys of workers and firms, to answer questions that go beyond simple descriptions of subsidies paid and their recipients.|$|R
40|$|Abstract—Analytical {{modeling}} of the 802. 11 e enhanced dis-tributed channel access (EDCA) mechanism is today a fairly mature research area, considering {{the very large}} number of pa-pers that have appeared in the literature. However, most work in this area models the EDCA operation through per-slot statistics, namely probability of transmission and collisions referred to “slots. ” In so doing, they still share a methodology originally pro-posed for the 802. 11 Distributed Coordination Function (DCF), although they do extend it by considering differentiated transmis-sion/collision probabilities over different slots. We aim to show {{that it is possible to}} devise 802. 11 e models that do not rely on per-slot statistics. To this purpose, we introduce and describe a novel modeling methodology that does not use per-slot transmission/col-lision probabilities, but relies on the fixed-point computation of the whole (residual) backoff <b>counter</b> <b>distribution</b> occurring after a generic transmission attempt. The proposed approach achieves high accuracy in describing the channel access operations, not only in terms of throughput and delay performance, but also in terms of low-level performance metrics. Index Terms—MAC model, quality of service, WLAN. I...|$|R
40|$|Approved {{for public}} release; <b>distribution</b> is unlimitedIdentifying, <b>countering,</b> andpreventing {{operational}} obsolescence is a challenging but vital task for personnel {{involved in the}} design, acquisition and support of military equipment. In this thesis, I define the concept of operational obsolescence and show quantitative relationships between modernization funding timelines and operational obsolescence. Only if we truly understand obsolescence can we best combat its onset and effects. I use example data from both legacy and current Army Aviation Systems to draw conclusions about the impacts of particular modernization timelines on {{the various forms of}} obsolescence that cause operational obsolescence. I then make recommendations concerning the optimal modernization strategies for current and future aviation systems in order to facilitate the Army's ability to field and sustain the most tactically and logistically superior weapon systems possible. Using first principles, I construct Life Models based on hazard functions for each of the different forms of obsolescence. I then combine these models into an overall model, and discuss the design of a data system to estimate model parameters. [URL] Colonel, United States Arm...|$|R
40|$|Analytical {{modeling}} of the 802. 11 e enhanced distributed channel access (EDCA) mechanism is today a fairly mature research area, considering {{the very large}} number of papers that have appeared in the literature. However, most work in this area models the EDCA operation through per-slot statistics, namely probability of transmission and collisions referred to ??slots. ?? In so doing, they still share a methodology originally proposed for the 802. 11 Distributed Coordination Function (DCF), although they do extend it by considering differentiated transmission/collision probabilities over different slots. We aim to show {{that it is possible to}} devise 802. 11 e models that do not rely on per-slot statistics. To this purpose, we introduce and describe a novel modeling methodology that does not use per-slot transmission/collision probabilities, but relies on the fixed-point computation of the whole (residual) backoff <b>counter</b> <b>distribution</b> occurring after a generic transmission attempt. The proposed approach achieves high accuracy in describing the channel access operations, not only in terms of throughput and delay performance, but also in terms of low-level performance metrics...|$|R
40|$|Chandra {{high energy}} {{resolution}} observations {{have now been}} obtained from numerous non-peculiar O and early B stars. The observed X-ray emission line properties differ from pre-launch predictions, and the interpretations are still problematic. We present a straightforward analysis of a broad collection of OB stellar line profile data to search for morphological trends. X-ray line emission parameters and the spatial distributions of derived quantities are examined with respect to luminosity class. The X-ray source locations and their corresponding temperatures are extracted by using the He-like f/i line ratios and the H-like to He-like line ratios respectively. Our luminosity class study reveals line widths increasing with luminosity. Although {{the majority of the}} OB emission lines are found to be symmetric, with little central line displacement, there is evidence for small, but finite, blue-ward line-shifts that also increase with luminosity. The spatial X-ray temperature distributions indicate that the highest temperatures occur near the star and steadily decrease outward. This trend is most pronounced in the OB supergiants. For the lower density wind stars, both high and low X-ray source temperatures exist near the star. However, we find no evidence of any high temperature X-ray emission in the outer wind regions for any OB star. Since the temperature <b>distributions</b> are <b>counter</b> to basic shock model predictions, we call this the "near-star high-ion problem" for OB stars. By invoking the traditional OB stellar mass loss rates, we find a good correlation between the fir-inferred radii and their associated X-ray continuum optical depth unity radii. We conclude by presenting some possible explanations to the X-ray source problems that have been revealed by this study. Comment: Published in 2007, ApJ, 668, 456. An Erratum scheduled for publication in 2008, ApJ, 680, is included as an Appendix. The Erratum corrects some tabulated data in 5 tables and 2 figure...|$|R
40|$|Many {{physical}} experiments require {{analysis of}} the statistics of fluctuating radiation. In {{the case of an}} ideal single-photon detector, the contribution of photon noise to the statistics of the registered signal has been thoroughly examined. However, practical photon counters have a dead time, leading to miscounting of certain true events, and sometimes the counters generate false after-pulses. This study investigate the impact of these two effects, and it presents the theoretical relations between the statistical moments of the radiation and the registered counts while also accounting for dead time and the probability of after-pulses. Expressions for statistical moments of any order are obtained {{on the basis of the}} generalized Poisson <b>distribution</b> (GPD). For <b>counters</b> with paralyzable dead time, alternative relations for the mean and variance are derived using generally accepted formulas. As an example, the measurements of stellar scintillation and the result of simple experiment are considered. The results of the experimental verification of the theoretical expression confirm the need to account for the non-ideal nature of detectors in almost all similar measurements. Comment: Accepted for publication in JOSA A, 23 pages, 4 figure...|$|R
40|$|The {{purpose of}} this thesis {{is to develop a}} {{mathematical}} optimization model to assist the authorities of the airport of Copenhagen in allocating the different companies in the check-in counters. This model should assign each company to specific check-in counters where the airline will provide passenger check-in services. The problem is {{complicated by the fact that}} a lot of conditions have to be considered. Due to the large influx of passengers and baggage, it is important to set a lot of constraints in order to succeed in terms of comfort, security and operational framework. These constraints are concerning to the physical layout of the airport, the available free space for queuing, the capacity of the conveyor belts used to transport the baggage and the operational requirements of the airlines companies. The objective is to fulfill these constraints and minimize the queue excess as well as the amount of baggage double screened. The model has been implemented in GAMS and tested with the real data of the 25 th of June 2011. Key words: Check-in facilities, Airport of Copenhagen, optimization, Mixed integer programming (MIP), assignments, queue <b>distribution,</b> baggage management, <b>counter</b> allocation...|$|R
40|$|Aerosols {{that contain}} {{volatile}} species or condensable vapors may be altered {{by changes in}} temperature, pressure, and vapor concentration. When such changes occur within aerosol sampling instruments, the measured size distribution can be distorted significantly. The distortion of particle size distributions {{in a number of}} commonly used aerosol instruments, including cascade impactors, both conventional and low pressure instruments, and optical particle counters, is explored both theoretically and experimentally in this paper. Ammonium sulfate aerosols in humid atmospheres have been used to test the instruments. In a low pressure impactor in which the pressure is intentionally reduced to facilitate the collection of small particles, a water containing particle may shrink due to evaporation as the pressure is reduced. However, if the sample flow is also accelerated to high velocities, aerodynamic cooling can lead to condensation of water vapor and particle growth. Either of these competing effects may lead to erroneous estimates of the particle size <b>distribution.</b> Optical particle <b>counters</b> generally use a recirculated sheath airflow. Pumps and electrical dissipation heat this air, leading to a temperature increase that shifts the vapor equilibrium, causing a decrease in particle size due to evaporation. Modifications have been made to avoid this distortion in measured size distributions...|$|R
60|$|The {{room of the}} fourpence-halfpenny banquet had, {{like the}} lower room, a counter in it, on which were ranged {{a great number of}} cold {{portions}} ready for <b>distribution.</b> Behind this <b>counter,</b> the fragrant soup was steaming in deep cans, and the best-cooked of potatoes were fished out of similar receptacles. Nothing to eat was touched with his hand. Every waitress had her own tables to attend to. As soon as she saw a new customer seat himself at one of her tables, she took from the counter all his dinner--his soup, potatoes, meat, and pudding--piled it up dexterously in her two hands, set it before him, and took his ticket. This serving of the whole dinner at once, had been found greatly to simplify the business of attendance, and was also popular with the customers: who were thus enabled to vary the meal by varying the routine of dishes: beginning with soup-to-day, putting soup in the middle to-morrow, putting soup at the end the day after to-morrow, and ringing similar changes on meat and pudding. The rapidity with which every new-comer got served, was remarkable; and the dexterity with which the waitresses (quite new to the art a month before) discharged their duty, was as agreeable to see, as the neat smartness with which they wore their dress and had dressed their hair.|$|R
40|$|Forsterite (Mg 2 SiO 4) powder {{has been}} {{synthesized}} from talc (Mg 3 Si 4 O 10 (OH) 2) and magnesium carbonate (MgCO 3) by applying solid state reactions method. The raw materials mixture has been milled for 10 hours until nano powders have been obtained. This mixture was then thermally treated at various temperatures. The synthesized material was structurally characterized by X-ray diffraction. Forsterite represented the main crystalline {{phase in the}} samples fired to 1100 and 1200 °C, while at 1000 °C small amounts of enstatite and periclase were still identified. The particles size and morphology were investigated by TEM, SEM and AFM, and the grain size <b>distribution</b> with a <b>Counter</b> Coulter-type laser granulometer. A ratio of 75 % of the particles in the samples fired to 1000, and respectively 1100 °C were less than 25 nm, while the maximum size was 42 nm. For the samples fired at 1200 °C, most of the particles (74 %) were larger, about 6. 8 μm, with a maximum of 70 μm. In order to evaluate its bioactivity, we have immersed the forsterite powder into simulating body fluids (SBF). Following 28 days of experiment, the FTIR spectra collected on the forsterite nanopowder contained the specific hydroxylapatite bands, while {{in the case of}} the micro powder these bands are hardly visible...|$|R
