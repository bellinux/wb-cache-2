935|79|Public
5000|$|Optical <b>granulometry</b> {{for more}} {{information}} on the photoanalysis process ...|$|E
5000|$|... #Subtitle level 2: <b>Granulometry</b> {{generated}} by a structuring element ...|$|E
5000|$|In {{the above}} case (<b>granulometry</b> {{generated}} by a structuring element), [...]|$|E
40|$|Opening {{distributions}} for {{image analysis}} constitute an extremely useful tool in morphological tasks. Efficient techniques {{have been proposed}} to compute <b>granulometries</b> in greyscale images based on linear openings. Greyscale <b>granulometries</b> using opening distributions are equivalent to a contour extraction problem. These paper describes the use and implementation of algorithms for computing <b>granulometries</b> for texture based image retrieval in an image database. We present that the pattern spectra derived using <b>granulometries</b> from the images form a good basis for texture based image retrieval...|$|R
40|$|ABSTRACT: <b>Granulometries</b> {{with respect}} to a {{structuring}} element which has more than one free parameter are introduced. Various one-dimensional <b>granulometries</b> and related pattern spectra which can be derived from these multidimensional <b>granulometries</b> are indicated. The need for considering such <b>granulometries</b> is explained. The multiparametric pecstrum is introduced, based on which a multiparametric skeletal transform is defined. It is shown how this skeletal transform can enhance the data compaction capability of the one-parametric skeletal transform. Pattern recognition and artificial intelligence applications often require a parametric representation for abstract concepts like shape. It is of great importance to classify shape according to some features or parameters- and to include as much information about the shape in question in such...|$|R
40|$|We {{report on}} {{new form of}} multivariate <b>granulometries</b> based on {{rectangles}} of varying size and aspect ratio. These <b>granulometries</b> are used for describing visual similarity between document images. Rectangular <b>granulometries</b> are used to probe the layout structure of document images, and the rectangular size distributions derived from them are used as descriptors for each image. Feature selection is used to reduce the dimensionality and redundancy of the size distributions, while preserving {{the essence of the}} visual appearance of a document. Experimental results indicate that rectangular size distributions are an effective way to characterize visual similarity of document images, and provide insightful interpretation of classification results in the original image space...|$|R
5000|$|The <b>granulometry</b> {{function}} [...] is the cardinality (i.e., area or volume, {{in continuous}} Euclidean space, or number of elements, in grids) {{of the image}} : ...|$|E
5000|$|Optical <b>granulometry</b> is {{the process}} of {{measuring}} the different grain sizes in a granular material, based on a photograph. Technology has been created to analyze a photograph and create statistics based on what the picture portrays. This information is vital in maintaining machinery in various trades worldwide. Mining companies can use optical <b>granulometry</b> to analyze inactive or moving rock to quantify the size of these fragments. [...] Forestry companies can zero in on wood chip sizes without stopping the production process, and minimize sizing errors.|$|E
50|$|Area-based {{particle}} size: Area-based {{particle size}} equals {{the diameter of}} the sphere that has the same surface area as a given particle. Typically used in optical <b>granulometry</b> techniques.|$|E
40|$|A {{variant of}} {{morphological}} attribute filters is developed, {{in which the}} attribute on which filtering is based, {{is no longer a}} scalar, as is usual, but a vector. This leads to new <b>granulometries</b> and associated pattern spectra. When the vector-attribute used is a shape descriptor, the resulting <b>granulometries</b> filter an image based on a shape or shape family instead of one or more scalar values. ...|$|R
40|$|This {{research}} was conducted to evaluate the quality of pot gerbera in different <b>granulometries</b> of pine bark substrate. The experiment {{was carried out in}} protected environment, in the municipality of Botucatu, São Paulo state, Brazil. The experimental design was randomized blocks, in 5 x 2 factorial scheme (5 substrates and 2 cultivars) and 4 replicates. The substrate was pine bark separated into five <b>granulometries</b> [4 - 2 mm, 2 - 1 mm, < 4 mm, < 2 mm and < 1 mm (approximate aeration percentage of 40, 35, 25, 20 and 10 %, respectively) ]. The utilized cultivars of gerbera (Gerbera jamesonii) were Cherry and Golden Yellow. The pots were subjected to quality analysis, in which possible consumers received a form to evaluate the pots regarding the overall aspect of leaves, inflorescences and general aspect of the pot. Then, the following variables were evaluated: number of leaves, plant diameter, stem height, stem diameter, capitulum diameter, number of inflorescences, dry phytomass of shoots and inflorescences and qualitative analysis. Plant quality was directly influenced by the physical and chemical characteristics promoted by the pine bark <b>granulometries,</b> with best results in the substrates with <b>granulometries</b> < 2 mm and < 1 m...|$|R
40|$|Abstract. When {{comparing}} document images {{based on}} visual similarity {{it is difficult}} to determine the correct scale and features for document representation. We report on a new form of multivariate <b>granulometries</b> based on rectangles of varying size and aspect ratio. These rectangular <b>granulometries</b> are used to probe the layout structure of document images, and the rectangular size distributions derived from them are used as descriptors for document images. Feature selection is used to reduce the dimensionality and redundancy of the size distributions while preserving the essence of the visual appearance of a document. Experimental results indicate that rectangular size distributions are an effective way to characterize visual similarity of document images and provide insightful interpretation of classification and retrieval results feature space...|$|R
50|$|By using photoanalysis the {{fragmented}} {{materials can}} be monitored, offering pinpoint accuracy and allowing mine operators {{to make adjustments}} to future blasting procedures. See Optical <b>Granulometry</b> to view the automated sieving process.|$|E
5000|$|Screen/scroll {{centrifuges}} (Screen centrifuges, {{where the}} centrifugal acceleration allows the liquid {{to pass through}} a screen of some sort, through which the solids cannot go (due to <b>granulometry</b> larger than the screen gap or due to agglomeration)) ...|$|E
50|$|In {{geothermal}} engineering, Aphelion {{was used}} in project for the Soultz-sous-Forêts site in Alsace, France. It was used to study the distribution of quartz grains in a drill (<b>granulometry).</b> Crack networks have also been studies using thermal, hydraulic, and mechanical techniques.|$|E
40|$|This paper {{develops}} a multiscale connectivity theory for shapes {{based on the}} axiomatic definition of new generalized connectivity measures, which are obtained using morphology-based nonlinear scale-space operators. The concept of connectivity-tree for hierarchical image representation is introduced and used to define generalized connected morphological operators. This theoretical framework is then applied to establish a class of generalized <b>granulometries,</b> implemented at a particular problem concerning soilsection image analysis and evaluation of morphological properties such as size distributions. Comparative results demonstrate the power and versatility of the proposed methodology {{with respect to the}} application of typical connected operators (such as reconstruction openings). This multiscale connectivity analysis framework aims at a more reliable evaluation of shape/size information within complex images, with particular applications to generalized <b>granulometries,</b> connected operators, and segmentation...|$|R
40|$|When {{comparing}} documents images {{based on}} visual similarity it is di#cult {{to determine the}} correct scale and features for document representation. We report on new form of multivariate <b>granulometries</b> based on rectangles of varying size and aspect ratio. These rectangular <b>granulometries</b> are used to probe the layout structure of document images, and the rectangular size distributions derived from them are used as descriptors for document images. Feature selection is used to reduce the dimensionality and redundancy of the size distributions, while preserving {{the essence of the}} visual appearance of a document. Experimental results indicate that rectangular size distributions are an e#ective way to characterize visual similarity of document images and provide insightful interpretation of classification and retrieval results in the original image space rather than the abstract feature space...|$|R
40|$|Abstract. This paper {{develops}} a multiscale connectivity theory for shapes {{based on the}} axiomatic definition of new generalized connectivity measures, which are obtained using morphology-based nonlinear scale-space operators. The concept of connectivity-tree for hierarchical image representation is introduced and used to define generalized connected morphological operators. This theoretical framework is then applied to establish a class of generalized <b>granulometries,</b> implemented at a particular problem concerning soilsection image analysis and evaluation of morphological properties such as size distributions. Comparative results demonstrate the power and versatility of the proposed methodology {{with respect to the}} application of typical connected operators (such as reconstruction openings). This multiscale connectivity analysis framework aims at a more reliable evaluation of shape/size information within complex images, with particular applications to generalized <b>granulometries,</b> connected operators, and segmentation...|$|R
50|$|In {{order for}} optical <b>granulometry</b> to be {{completely}} successful, an accurate photo must be taken - under sufficient lighting, and using proper technology - to obtain quantified results. If these requirements are met, an image analysis system can be implemented.|$|E
5000|$|Limestone is {{extracted}} from quarries or mines. Part of the extracted stone, selected {{according to its}} chemical composition and optical <b>granulometry,</b> is calcinated at about 1000 C in different types of lime kilns to produce quicklime according to the reaction: ...|$|E
50|$|In {{mathematical}} morphology, <b>granulometry</b> is {{an approach}} to compute a size distribution of grains in binary images, using a series of morphological opening operations. It was introduced by Georges Matheron in the 1960s, and {{is the basis for}} the characterization of the concept of size in mathematical morphology.|$|E
40|$|<b>Granulometries</b> are {{powerful}} and versatile tools in image analysis and pattern spectra, or size distribulions, are a simple {{method of extracting}} information from an image using these <b>granulometries.</b> One of the drawbacks of the traditional pattern spectra, the lack of spatial information about connected components within images, is addressed in this project by introducing three extensions to the regular area pattern spectra: one based on moments, one based on translation of the components within the image, and one based on multi-scale connectivity. These three extensions are tested {{in the field of}} content-based image retrieval: are they able to retrieved images from an image-database, that are similar in some way to a certain, user-provided, query-image? This is a question that is interesting for fields like intelligent multimedia and web searches (search engines). ...|$|R
40|$|International audienceWe {{introduce}} a new, efﬁcient and adaptable algorithm to compute openings, <b>granulometries</b> and the component tree for one-dimensional (1 -D) signals. The algorithm requires only one {{scan of the}} signal, runs in place in per pixel, and supports any scalar data precision (integer or ﬂoating-point data). The algorithm is applied to two-dimensional images along straight lines, in arbitrary orientations. Oriented size distributions can thus be efﬁciently computed, and textures characterized. Extensive benchmarks are reported. They show that the proposed algorithm allows computing 1 -D openings faster than existing algorithms for data precisions higher than 8 bits, and remains competitive {{with respect to the}} algorithm proposed by Van Droogenbroeck when dealing with 8 -bit images. When computing <b>granulometries,</b> the new algorithm runs faster than any other method {{of the state of the}} art. Moreover, it allows efﬁcient computation of 1 -D component trees...|$|R
40|$|Circuit boards {{present in}} most {{electric}} and electronic devices {{are very important}} components, which should be removed during sorting and dismantling operations {{in order to allow}} further adequate treatment for recovering valuable metals such as copper, nickel, zinc, lead, tin and rare elements. This recovery can be made by physical and chemical processes being size reduction by shredding the first step. In this paper, the effect of particle size in physical and chemical processing of printed circuit boards is presented and discussed. Shredding using cutting-based equipment allowed the comminution of boards and the liberation of particles composed by different materials (mainly metals and resin). Particle sizes less than 1 mm seems to be appropriate to attain high liberation of materials, which is crucial for the physical separation using gravity or electrostatic processes. Concerning chemical treatment, hydrometallurgical processing involves a leaching operation which can be also influenced by particle size of shredded boards. Samples with different <b>granulometries</b> were leached with 1 M HNO 3 solutions, being leaching yields evaluated. It was concluded that particle size can be an important factor for the solubilization of some metals, but the effect is not similar for all elements. When average diameters change from 2. 0 to 0. 20 mm, nickel, aluminium and tin reactivity were not significantly affected, being this effect important for copper. Zinc behavior was very dependent from extreme particle sizes but was less affected in intermediate <b>granulometries.</b> Lead leaching showed also a peculiar behavior, exhibiting high and almost constant yields (80 - 90 %) for particle size of solids up to 1. 2 mm, and decreasing suddenly for higher <b>granulometries.</b> The effect of time on chemical reactivity for samples with different <b>granulometries</b> demonstrated that particle size affects reaction rates but eventually similar efficiencies can be obtained for long time periods. Therefore the relationship between results from shredding operation and chemical leaching step needs to be optimized, considering the balance between factors like consumption of energy during grinding operation and residence time in leaching...|$|R
50|$|Common filter packing {{materials}} include sawdust, wood chips, coir, bark, peat, and straw for organic packing. Gravel, quartz sand, river bed gravel, pumice, mud balls, glass balls, ceramsite and coal {{are commonly used}} for inert packing. Surface area and porosity of filter {{packing materials}} influence treatment performance. Thus materials with low <b>granulometry</b> and large surface area may improve {{the performance of the}} vermifilter.|$|E
50|$|During {{the rest}} of the 1960s and most of the 1970s, MM dealt {{essentially}} with binary images, treated as sets, and generated a large number of binary operators and techniques: Hit-or-miss transform, dilation, erosion, opening, closing, <b>granulometry,</b> thinning, skeletonization, ultimate erosion, conditional bisector, and others. A random approach was also developed, based on novel image models. Most of the work in that period was developed in Fontainebleau.|$|E
5000|$|Material {{fractures}} can be {{intergranular fracture}} or a transgranular fracture. There is an ambiguity with powder grains: a powder grain {{can be made}} of several crystallites. Thus, the (powder) [...] "grain size" [...] found by laser <b>granulometry</b> can {{be different from the}} [...] "grain size" [...] (or, rather, crystallite size) found by X-ray diffraction (e.g. Scherrer method), by optical microscopy under polarised light, or by scanning electron microscopy (backscattered electrons).|$|E
40|$|We {{indicate}} how <b>granulometries</b> {{may be useful}} in the analysis of random sets. After defining a size distribution function which may be used as a summary statistic in exploratory data analysis, we propose a Hanisch-type estimator and construct new Markov random set models which favour certain sizes above others. The models are illustrated by simulated realisations...|$|R
40|$|Pattern spectra are image histograms {{that feature}} the {{distribution}} of image details with respect to some attribute measure. They are typically computed from <b>granulometries</b> which provide the necessary set of conditions to ensure a notion of order. In this paper we investigate means of describing order {{in the absence of}} operators and thus <b>granulometries.</b> We provide a case study on the multi-scale segmentation transform of the image domain to sets of single linkage connected components based on some dissimilarity measure. The nesting of consequent partitions, computed along the dissimilarity measure range, leads to the notion of partition pyramids. These are multi-scale partition representation structures characterised by large redundancies due to component replicas at various scales. We constrain this to the compact representation of partition hierarchies based on which we can compute efficiently pattern spectra and other filtering/segmentation transforms. JRC. DG. G. 2 -Global security and crisis managemen...|$|R
40|$|One of {{the main}} {{environmental}} current concern is the metal(loid) s contaminated soils. Salicaceae, {{have been shown to}} be efficient for phytostabilization. The goals of this study were to investigate the effects of a various set of biochar and presenting different <b>granulometries</b> on soil properties, soil pore water characteristics and metal(loid) s availability and (ii) to assess the tolerance of Populus euramericana to arsenic and plumber...|$|R
50|$|Image {{analysis}} {{also helps}} to study composite polymers strengthen by glass fiber, and to measure {{the impact of the}} size of micro threads used to link soft fibers in the perpendicular direction. The size of the threads can modify the matrix distribution used to combine this material. The study of the distribution of metallic elements in composite materials and alloys, such as AlSiC is usually performed by <b>granulometry</b> involving image processing and analysis. Porosity of macromolecular materials as xerogel is sometime studied using 3D and X-ray microtomography.|$|E
50|$|Sediments {{can provide}} clues to reconstructing past natural and {{cultural}} processes {{in a similar manner}} as artifacts. Professionals that study geoarchaeology are trained to use changes in soils and geomorphology to interpret human behavior. By analyzing sediments, archaeologists can gather information regarding site chronology, supplement field descriptions, and test hypotheses related to site formation and function. Laboratories of sediments tend to focus on studying mineralogy, micromorphology, <b>granulometry,</b> pH, organic matter, calcium carbonate, and phosphorus levels. As with any material, specific methods used will depend on questions one is asking of the material. For example, both petrography and x-ray diffraction can be used to examine mineralogy, but the choice of method will depend on the specific minerals one aims to detect.|$|E
50|$|Synthetic {{screen media}} is used where wear life is an issue. Large {{producers}} such as mines or huge quarries {{use them to}} reduce the frequency of having to stop the plant for screen deck maintenance. Rubber is also used as a very resistant high-impact screen media material used on the top deck of a scalper screen. To compete with rubber screen media fabrication, polyurethane manufacturers developed screen media with lower Shore Hardness. To compete with self-cleaning screen media that is still primarily available in tensioned cloth, synthetic screen media manufacturers also developed membrane screen panels, slotted opening panels and diamond opening panels. Due to the 7-degree demoulding angle, polyurethane screen media users can experience <b>granulometry</b> changes of product during the wear life of the panel.|$|E
40|$|We {{indicate}} how <b>granulometries</b> {{may be useful}} in the analysis of random sets. We define a suitable size distribution function as a tool in exploratory data analysis and give a new Hanisch style estimator for it. New Markov random sets are constructed which favour certain sizes above others. A size-biased random set model is fitted to a data set concerning the incidence of heather (Diggle, Biometrics 37 (1981) 531 – 539) ...|$|R
40|$|<b>Granulometries</b> {{and pattern}} spectra are {{morphological}} tools {{used to obtain}} size distributions in images. This paper presents the application of these techniques to radar signals. It uses a new approach which is more appropriate for RF signals than the classical approach. It uses complex openings, closings and power measurements {{instead of the usual}} graytone operators and the Lebesgue measure. Examples for simulated and real radar signals are given. r 2006 Elsevier B. V. All rights reserved...|$|R
40|$|In {{this paper}} {{connected}} operators from mathematical morphology are extended {{to a wider}} class of operators, {{which are based on}} connectivities in higher dimension spaces, similar to scale spaces which will be called attribute spaces. Though some properties of connected filters are lost, <b>granulometries</b> can be defined under certain conditions, and pattern spectra in most cases. The advantage of this approach is that regions can be split into constituent parts before filtering more naturally than by using partitioning connectivities. ...|$|R
