9|309|Public
30|$|Here α is the <b>filtering</b> <b>factor.</b> Further on, the {{monitored}} KPI {{will also}} {{be referred to as}} the LTE or WLAN cell load.|$|E
30|$|The common {{attribute}} {{of the two}} methods {{is the use of}} context as the decision <b>filtering</b> <b>factor</b> but with different context elements in each case. Context Awareness in Recommendation Systems involves the use of data that characterizes an entity to be used as contextual information for the computation of recommendations, wherever this is needed.|$|E
40|$|Specular {{reflections}} from environments cause uncertainties to {{ultrasonic sensor}} range data. In this paper, {{we examine the}} application of evidential method for data integration using the specially designed sensor model to overcome the problem. Dempster’s rule of combination is used to fuse the sensor data to obtain the map defined on a 2 D evidence grid. The sensor model tries to reduce the uncertainties caused by specular reflections with a <b>filtering</b> <b>factor.</b> Experimental results have shown the usefulness of this method...|$|E
30|$|We {{can clearly}} {{see that the}} error of {{estimated}} radius {{is proportional to the}} height of such imperfection if it is not filtered out (the <b>filter</b> <b>factor</b> is too large). However, the form is fitted correctly for lower <b>filter</b> <b>factors</b> (such as 10 σ in this case). Nevertheless, the <b>filter</b> <b>factor</b> cannot be too small because too many points will be excluded from calculations. Thus some compromise must be made and the corresponding <b>filter</b> <b>factor</b> value is different for different aspheric surfaces and for different imperfections. In the case of min-max algorithm (e.g. in [8]) the form error is large if 0 % of points is excluded. However, it can be significantly smaller if some points are excluded (e.g. about 5 %). The parameters obtained from such fitting with a reasonable <b>filter</b> <b>factor</b> can be used to display surface deviations for all points and the standardized form error can be evaluated from these residuals.|$|R
50|$|The table below gives {{approximate}} <b>filter</b> <b>factors</b> for {{a variety}} of common photographic filters. It {{is important to note that}} <b>filter</b> <b>factors</b> are highly dependent on the spectral response curve of the film being used. Thus, <b>filter</b> <b>factors</b> provided by the film manufacturer should be preferred over the ones documented below. Furthermore, note well that these factors are for daylight color temperature (5600K); when shooting under a different color temperature of ambient light, these values will most likely be incorrect.|$|R
5000|$|... #Subtitle level 2: Converting between <b>filter</b> <b>factors</b> {{and stops}} ...|$|R
30|$|We {{adopt the}} notion of distance-based {{outliers}} proposed by Knorr and Ng [27] for data-mining applications: “An object in a dataset is an outlier if at least {{a fraction of the}} objects in this dataset lies in a larger distance from this object.” Our approach {{is based on the assumption}} that points belonging to building wall structures have normal distribution. Thus, we apply a double-threshold scheme: firstly, we reduce the impact of infrequent points in the model, the relative distances from which to the other points in the model are comparatively large. After eliminating such points, we estimate the second <b>filtering</b> <b>factor</b> based on the global mean over mean distances of each point’s neighborhood.|$|E
40|$|Sounds and murmurs {{have long}} been {{employed}} for qualitative diagnosis of cardiovascular disease. However, quantitative diagnosis has been hindered {{by the lack of}} understanding of the mechanisms of sound generation and transmission in the human circulation. Clinical phonoangiographic studies have shown that simple assumptions about low frequency sound transmission through tissue surrounding an artery are inadequate for obtaining meaningful quantitative diagnosis. Therefore, a theory is developed which relates internal turbulent flow in diseased peripheral arteries to the tissue vibration observed at the surface of the skin by means of assumptions of similarity and local axial homogeneity of the internal turbulence. It is found that the spectrum of pressure at the wall of the artery is related to the spectrum of the pressure at a no-displacement surface by a <b>filtering</b> <b>factor</b> approximately pro-portional to W. This arises not because of frequency-dependen...|$|E
40|$|Recent {{studies show}} that Cohen class {{bilinear}} time-frequency distribution methods do not have satisfactory denoising performance when analyzing multicomponent LFM signals. This paper has constructed a new adaptive time-frequency iltering factor and has proposed an adaptive time-frequency filtering algorithm based on generalized S-transform. Firstly, the time-frequency distribution is obtained by transforming the time domain signals to time-frequency domain by usinggeneralized Stransform, which is followed by calculating instantaneous frequency based on the phase information from the timefrequency distribution. Secondly, the time-frequency distribution regions occupied by clustered energy of effective signal are identified through time-frequency region extraction method and all time-frequency distribution spectrum out of the regions are removed. Thirdly, a novel TF <b>filtering</b> <b>factor</b> is constructed by the time-frequency concentration characteristic to restrain the random noise components in the regions of effective signal. Finally, the filtered signals are retrieved by using inverse generalized Stransform. Simulation results demonstrate that the proposed filtering algorithm has satisfactory performances for signal denoising which most features of original signal can be remained...|$|E
50|$|In photography, <b>filter</b> <b>factor</b> {{refers to}} the multiplicative amount of light a filter blocks.|$|R
50|$|The table below {{illustrates}} {{the relationship between}} <b>filter</b> <b>factor,</b> the amount of light that is allowed through the filter, {{and the number of}} stops this corresponds to.|$|R
40|$|Transport of Escherichia coli ATCC 11105 through porous {{media was}} {{investigated}} in this study using two sets of column experiments to quantify the attachment-related parameters (sticking efficiency, attachment rate coefficient and <b>filter</b> <b>factor).</b> The first set of experiments was performed in quartz sand under different ionic strength conditions (1, 20, 100, 200 mM) while the second experiments were carried out in quartz sand mixed with metal oxyhydroxide-coated sand (0, 5, 10, 25 %). The breakthrough curves of bacteria were obtained by monitoring effluent, and then bacterial mass recovery and attachment-related parameters were quantified from these curves. The first experiments showed that the mass recoveries were {{in the range of}} 13. 3 to 64. 7 %, decreasing with increasing ionic strength. In the second experiments, the mass recoveries were in the range of 15. 0 to 43. 4 %, decreasing with increasing coated sand content. The analysis indicated that the sticking efficiency, attachment rate coefficient and <b>filter</b> <b>factor</b> increased with increasing ionic strength and coated sand content. The value of <b>filter</b> <b>factor</b> in the first experiments ranged from 1. 45 e- 2 to 6. 72 e- 2 1 /cm while in the second experiments it ranged from 2. 78 e- 2 to 6. 32 e- 2 1 /cm. Our <b>filter</b> <b>factor</b> values are one order of magnitude lower than those from other studies. This discrepancy {{can be attributed to the}} size of sand used in the experiment. The analysis demonstrated that the travel distance of bacteria estimated using the <b>filter</b> <b>factor</b> can be varied greatly depending on the solution chemistry and charge heterogeneity of porous media...|$|R
40|$|Tenebrionidae {{are one of}} {{the largest}} {{families}} of beetles and are known for their adaptations to hot and dry climates. An increase in body size also increases the volume/ surface area ratio, which reduces transpiration, and hence water loss. If an increase in body size is an important adaptation in tenebrionids to cope with increasing aridity, we expect a correlation between body size and climatic gradients in the major tenebrionid clades. Alternatively, we can postulate that arid climates do not drive body size evolution, but rather select, from a wider fauna containing species of any size, those that have larger bodies. In this case we expect that drier regions will host faunas that contain, on average, larger species. To test the first hypothesis, we correlated inter-specific body size variation in the main tenebrionid clades with climatic gradients in Europe. We found only weak trends. To test the second hypothesis, we regressed mean body size of European country faunas against climatic characteristics. We found a strong increase in body size in southern faunas experiencing hot and dry climates. Therefore, increase in body size is not a major adaptation in tenebrionid evolution, but climate is an important <b>filtering</b> <b>factor</b> that determines a prevalence of larger species in southern Europe...|$|E
40|$|This {{paper is}} {{concerned}} with the image deconvolution problem. For the basic model, where the convolution matrix can be diagonalized by discrete Fourier transform, the Tikhonov regularization method is computationally attractive since the associated linear system can be easily solved by fast Fourier transforms. On the other hand, the provided solutions are usually oversmoothed and other regularization terms are often employed {{to improve the quality of}} the restoration. Of course, this weighs down on the computational cost of the regularization method. Starting from the fact that images have sparse representations in the Fourier and wavelet domains, many deconvolution methods have been recently proposed with the aim of minimizing the ℓ 1 -norm of these transformed coefficients. This paper uses the iteratively reweighted least squares strategy to introduce a diagonal weighting matrix in the Fourier domain. The resulting linear system is diagonal and hence the regularization parameter can be easily estimated, for instance by the generalized cross validation. The method benefits from a proper initial approximation that can be the observed image or the Tikhonov approximation. Therefore, embedding this method in an outer iteration may yield further improvement of the solution. Finally, since some properties of the observed image, like continuity or sparsity, are obviously changed when working in the Fourier domain, we introduce a <b>filtering</b> <b>factor</b> which keeps unchanged the large singular values and preserves the jumps in the Fourier coefficients related to the low frequencies. Numerical examples are given in order to show the effectiveness of the proposed method...|$|E
30|$|For the {{pre-filtering}} method the <b>filtering</b> <b>factor</b> that {{is taken}} into account {{is the type of}} the shape that it is used for the description of a requirement within the diagram. Using a specific type for a shape defines which subset of Design Patterns categories or subcategories should be retrieved using the Ontology model. For example for a “Server Side” requirement shape, after adding it to the canvas and giving to it a requirement description, a SPARQL query is executed retrieving from all defined data-sources through the ontology model all categories that contain Server Side Design Patterns, such as the “Classic (GoF), the Antipatterns” and the “Enterprise Application Architecture Patterns” and their subcategories. The retrieved subset of Design Patterns is then indexed as virtual documents having as content the descriptions of their attributes descriptions as they are defined by the corresponding source of retrieval. Then, the provided requirement description is processed and filtered by removing the stop words from the text and creating a words vector. The created vector is used as input to the TF-IDF algorithm and using the cosine similarity it returns the most relevant Design Patterns ranked {{based on the number of}} common words found in each Design Pattern’s attributes. In the case of the Text-based method the text that is taken into consideration during the computation is only the shape’s description but in the case of Utility-based method additional text is used, taken from the additional contextual elements that the user defined from the interface such as the Title of the diagram, its description, the parent shapes text and the children shapes text. For the Text-based filtering method the results are directly presented to the user, but for the Utility-based method the results are passed into a post filtering mechanism that performs additional filtering based on the weights of importance that user defined for each participating contextual factor.|$|E
50|$|The normal {{exposure}} will be increased by three stops with this filter. As {{a consequence of}} this relationship, <b>filter</b> <b>factors</b> should be multiplied together when such filters are stacked, as opposed to stop adjustments, which should be added together.|$|R
40|$|Abstract—A new {{approach}} to analog-to-digital conversion is proposed which combines unstable analog filters with digital Kalman filtering. The proposed approach subsumes sigma-delta converters, on which it offers a new perspective. Index Terms—Analog-to-digital conversion, Kalman <b>filter,</b> <b>factor</b> graphs, Gaussian message passing...|$|R
40|$|Application of the {{exposure}} value system {{requires that the}} system be extended to high brightness level and expanded to include <b>filter</b> <b>factors.</b> A minimum of four photographic factors {{are involved in the}} evaluation of an exposure which, when determined from tables of 1 -stop interval, could introduce noticeable error...|$|R
40|$|Polarization {{measurements}} {{were carried out}} in orange light for Phobos and Deimos on the Mariner 9 A-camera system at large phase angles. The presence of regoliths on the satellites is indicated by {{a comparison of the}} measurement data with the results of laboratory measurements on powdered rock samples. Four different sets of assumptions concerning the <b>filter</b> <b>factors</b> were taken into account in the data reduction process...|$|R
40|$|This {{research}} {{is presented in}} short presentation format for a research effort based on previous studies on Halal standards. In this study, researcher tried to modify previous study published by Medwell Journals. Researchers applied Multi Criteria Decision Making (MCDM) tool to <b>filter</b> <b>factors</b> of non-compliance of Halal standard among restaurant operations in Kuala Lumpur in cause and effect groups. In this study, researcher failed to prove his hypnotized conceptual model...|$|R
40|$|A {{convolutional}} factor-analysis {{model is}} developed, {{with the number}} of <b>filters</b> (<b>factors)</b> inferred via the beta process (BP) and hierarchical BP, for single-task and multi-task learning, respectively. The computation of the model parameters is implemented within a Bayesian setting, employing Gibbs sampling; we explicitly exploit the convolutional nature of the expansion to accelerate computations. The model is used in a multi-level (“deep”) analysis of general data, with specific results presented for image-processing data sets, e. g., classification. 1...|$|R
40|$|A {{computer}} {{program for the}} design and analysis of linear phase FIR raised cosine filters is described. It allows the design of traditional and equiripple FIR <b>filters</b> with roll-off <b>factors</b> between 0 and 1. In addition the program is capable of computing coefficients for the recently introduced raised cosine <b>filters</b> with <b>factor</b> > 1. The design algorithms are solved using linear programming. A number of filter examples are included...|$|R
30|$|Consequently, these <b>factors</b> <b>filter</b> out {{solution}} components {{pertaining to}} small singular values.|$|R
40|$|Abstract—A 2 -D {{electrical}} filter is introduced that {{is compatible with}} today’s conventional integrated circuit processes. The rich 2 -D propagation properties of the medium are used to introduce a novel high quality <b>factor</b> <b>filter</b> called an electrical prism. The pro-posed filter shows a quality factor {{much larger than the}} quality factor of the individual components at high millimeter-wave and terahertz frequencies. This structure also provides a negative ef-fective index in a low-pass lattice. Based on this idea, we show <b>filters</b> with quality <b>factors</b> of 130 at 230 GHz and 420 at 460 GHz consisting of elements with the quality factor of 10 and 20, respec-tively. The effect of component loss on the <b>filter</b> quality <b>factor</b> is discussed in this paper. The negative effective index and the filter behavior of the lattice is verified by measuring a prototype on a CMOS process at 32 – 40 GHz. There is good agreement among the theory, simulation, and experimental results. Index Terms—CMOS, dispersion, electrical prism, high quality <b>factor</b> <b>filter,</b> negative effective index, spatial filtering, terahertz, 2 -D electrical lattice. I...|$|R
40|$|Abstract—A hybrid silicon {{photonic}} integrated filter {{is proposed}} and demonstrated {{with a novel}} structure. This filter incorporates a ring resonator in one arm of a Mach–Zehnder interferometer {{making it possible to}} obtain a programmable filter response. The optical filter consists of a 5 -mm-long delay loop made of low-loss silicon waveguides with integrated thermal modulators resulting in a 0. 164 -nm free spectral range with absolute phase tunability and gain elements that allow for the tuning of the <b>filter</b> <b>factor.</b> The microwave response of this integrated filter is measured and display tunability of 20 GHz. Index Terms—Hybrid integrated circuits, microwave filters, op-tical waveguide components, photonic integrated circuits (PICs). I...|$|R
5000|$|This is {{also the}} {{bandwidth}} of the <b>filter.</b> The damping <b>factor</b> is given by ...|$|R
40|$|We {{introduce}} a new filtering method for approximate string matching called the suffix filter. It has some similarity with well-known filtration algorithms, which we call <b>factor</b> <b>filters,</b> and which {{are among the best}} practical algorithms for approximate string matching using a text index. Suffix filters are stronger, i. e., produce fewer false matches than <b>factor</b> <b>filters.</b> We demonstrate experimentally that suffix filters are faster in practice, too. ...|$|R
40|$|To {{the case}} k = 3 of the Berman`s {{approximation}} algorithm, the improved {{algorithm is proposed}} in this study. It constructs a Voronoi region to get the cost of triple subtree {{on the basis of}} using Fibonacci heap to count the shortest distance of each pair of points in the corresponding set. Then, to decrease useless triples by the topology analysis of Steinertree, it simplifies the topology and reduces the time complexity. In the experiment results, the <b>filter</b> <b>factor</b> � is above 0. 9 for each example, some even up to 0. 999. It shows that many useless triples have been filtered before the beginning of the evaluation phase and the construction phase...|$|R
30|$|Other {{researchers}} implemented adaptive FIR {{digital filter}} using least mean square (LMS) evaluation criterion {{to realize the}} filter performances to eliminate random noise frequencies and reconstruct mud pulse signals. This technique was adopted to reduce mud pump noise and improve surface received telemetry signal detection and reliability. However, the quality of reconstructed signal depends on the signal distortion factor, which relates to the <b>filter</b> step-size <b>factor.</b> Reasonably, chosen <b>filter</b> step-size <b>factor</b> reduces the signal distortion quality. Li and Reckmann (2009) research used the reference signal fundamental frequencies and simulated mud pump harmonic frequencies passed through the LMS filter design to adaptively track pump noises. This method reduced the pump noise signals by subtracting the pump noise approximation from the received telemetry signal. Shen et al. (2013 a) studied the impacts of filter step-size on signal-to-noise ratio (SNR) distortions. The study used the LMS control algorithm to adjust the adaptive filter weight coefficients on mud pulse signal modulated by differential phase shift keying (DPSK). In this technique, the same <b>filter</b> step-size <b>factor</b> numerical calculations showed that the distortion factor of reconstructed mud pressure QPSK signal is smaller {{than that of the}} mud pressure DPSK signal.|$|R
50|$|Frequently used {{methods for}} {{description}} <b>filtering</b> include <b>factor</b> analysis (e.g. by PCA), singular value decomposition (e.g. as latent semantic indexing in text retrieval) and the extraction {{and testing of}} statistical moments. Advanced concepts such as the Kalman filter are used for merging of descriptions.|$|R
40|$|Stochastic {{filtering}} {{concerns the}} estimation {{of the state of}} a randomly evolving system that is only indirectly observed and the observations are, furthermore, affected by noise. The primary examples in finance concern factor models, where some factors are not directly observable. We review stochastic filtering in discrete and continuous time in linear and nonlinear models and describe some applications to pricing and portfolio management. Key words: Incomplete information, stochastic filtering, Bayesian estimation, analytic filter solutions, particle <b>filters,</b> <b>factor</b> models, pricing, portfolio management. The filtering problem Consider a randomly evolving system, the state of which is denoted by xt and this state may not be directly observable. Denote by yt the observation at time t ∈ [0, T] (xt and yt may be vectorvalued) ...|$|R
40|$|In {{research}} with carbon arc-jets, a need arose to transpose the experimentally determined correct exposure settings for {{one set of}} conditions to others with the same exceedingly high light levels of the jet. It appeared that the transpositions could be accomplished more rapidly and accurately if the EV system could be expanded both in extent and detail. How this was accomplished is explained. The exposure value system or additive value system has been expanded to include <b>filter</b> <b>factors</b> and transmittance. In addition, the equations for photoflash and electronic flash photography are converted into a form compatible with the EV system. The photographic factors are presented in tabular form together with their corresponding values in the additive value system in 25 % steps or quarter stops to permit an ac-ceptable solution to be obtained more readily...|$|R
40|$|Linear discrimination, {{from the}} point of view of {{numerical}} linear algebra, can be treated as solving an ill-posed system of linear equations. In order to generate a solution that is robust in the presence of noise, these problems require regularization. Here, we examine the ill-posedness involved in the linear discrimination of cancer gene expression data with respect to outcome and tumor subclasses. We show that a <b>filter</b> <b>factor</b> representation, based upon Singular Value Decomposition, yields insight into the numerical ill-posedness of the hyperplane-based separation when applied to gene expression data. We also show that this representation yields useful diagnostic tools for guiding the selection of classifier parameters, thus leading to improved performance. Comment: 22 pages, 3 figures; uses journal's ws-jbcb. cls; submitted to Journal of Bioinformatics and Computational Biolog...|$|R
3000|$|... [*]kHz {{due to the}} use of a pulse shaping <b>filter</b> with {{roll-off}} <b>factor</b> 0.4. In HB transmission, {{the carrier}} frequency was [...]...|$|R
40|$|Maintenance {{has had a}} {{tremendous}} impact on company’s proficiency to optimize its production system in order to meet its long term objectives. Generally, a production system in which maintenance is not given attention may easily lead to the system producing defective product as a result of machine defect. The purpose of this thesis is to utilized tools and methods to analyze the impact of maintenance implementation in a production system. The analytical Hierarchy process was utilized to <b>filter</b> the defining <b>factors</b> and sub-factors considered {{to be related to the}} life length and performance of production equipment in the research which was carried out at SCA Packaging Sweden AB. Various cost associated with these factors were analyzed using the cost breakdown structure, an element of life cycle cost analysis. Finally, economic evaluation of the <b>filtered</b> <b>factors</b> was performed to show the benefits associated with implementing maintenance. The result shows that while investment on maintenance implementation might be a cost at the earlier stage of implementation because it is hard to measure and follow up its impact on company’s business. Nevertheless, its role in improving company productivity profitability is indispensable. Thus, maintenance is a profit centre rather than a cost centre...|$|R
40|$|A typical way {{to compute}} a {{meaningful}} solution of a linear {{least squares problem}} involves {{the introduction of a}} <b>filter</b> <b>factors</b> array, whose aim is to avoid noise amplification due to the presence of small singular values. Beyond the classical direct regularization approaches, iterative gradient methods can be thought as filtering methods, due to their typical capability to recover the desired components of the true solution at the first iterations. For an iterative method, regularization is achieved by stopping the procedure before the noise introduces artifacts, making the iteration number playing the role of the regularization parameter. In this paper we want to investigate the filtering and regularizing effects of some first-order algorithms, showing in particular which benefits can be gained in recovering the filters of the true solution by means of a suitable scaling matrix...|$|R
