180|10000|Public
5000|$|Again an {{algorithm}} {{that places}} the samples randomly, but then checks that any two {{are not too}} close. The end result is an even but random <b>distribution</b> <b>of</b> <b>samples.</b> However, the computational time required for this algorithm is too great to justify its use in real-time rendering unless the sampling itself is computationally expensive compared to the positioning the sample points or the sample points are not repositioned for every single pixel.|$|E
5000|$|A {{committee}} of the Space Science Board reviewed {{the idea of a}} lunar sample receiving laboratory and sought to address multiple concerns. One was the fear that creating a facility with too great a capacity to analyze the samples would discourage <b>distribution</b> <b>of</b> <b>samples</b> to outside researchers and effectively exclude them. [...] In addition, space biologists and the United States Public Health Service expressed concern about [...] "back contamination" [...] of Earth by extraterrestrial microorganisms brought back via returning spacecraft, (although many of the astronauts and scientists involved in the program were skeptical that non-terrestrial microorganisms could survive lunar conditions). To address these issues, the committee in 1965 recommended a laboratory with limited analytical capacity and an ability to quarantine the returning astronauts and samples.|$|E
5000|$|In machine learning, it {{is desired}} {{to have a}} {{training}} set that represents the true <b>distribution</b> <b>of</b> <b>samples.</b> This can be quantified using the notion of representativeness. Denote by P the probability distribution from which the samples are drawn. Denote by [...] the set of hypotheses (potential classifiers) and denote by [...] the corresponding set of error functions, i.e, for every , there is a function , that maps each training sample (features,label) to the error of the classifier [...] on that sample (for example, if we do binary classification and the error function is the simple 0-1 loss, then [...] is a function that returns 0 for each training sample on which [...] is correct and 1 for each training sample on which [...] is wrong). Define: ...|$|E
5000|$|In {{order to}} derive {{the formula for}} the one-sample {{proportion}} in the Z-interval, a <b>sampling</b> <b>distribution</b> <b>of</b> <b>sample</b> proportions {{needs to be taken}} into consideration. The mean <b>of</b> the <b>sampling</b> <b>distribution</b> <b>of</b> <b>sample</b> proportions is usually denoted as [...] and its standard deviation is denoted as [...] Since the value of [...] is unknown, an unbiased statistic [...] will be used for [...] The mean and standard deviation are rewritten as [...] and [...] respectively. Invoking the Central Limit Theorem, the <b>sampling</b> <b>distribution</b> <b>of</b> <b>sample</b> proportions is approximately normal.|$|R
5000|$|... #Subtitle level 4: Estimating the <b>distribution</b> <b>of</b> <b>sample</b> mean ...|$|R
5000|$|Generalized {{extreme value}} distribution, {{possible}} limit <b>distributions</b> <b>of</b> <b>sample</b> maximum (opposite question).|$|R
5000|$|Here weight {{decreases}} as distance increases {{from the}} interpolated points. Greater values of [...] assign greater influence to values {{closest to the}} interpolated point, with the result turning into a mosaic of tiles (a Voronoi diagram) with nearly constant interpolated value for large values of p. For two dimensions, power parameters [...] cause the interpolated values {{to be dominated by}} points far away, since with a density [...] of data points and neighboring points between distances [...] to , the summed weight is approximatelywhich diverges for [...] and [...] For N dimensions, the same argument holds for [...] For the choice of value for p, one can consider the degree of smoothing desired in the interpolation, the density and <b>distribution</b> <b>of</b> <b>samples</b> being interpolated, and the maximum distance over which an individual sample is allowed to influence the surrounding ones.|$|E
5000|$|The {{advertising}} provisions {{apply to}} any advertisement published {{for the business}} {{carried out by the}} advertiser which indicates he is willing to provide credit or provide goods to be hired. [...] "advertisement" [...] is taken to mean any form of advertisement, including a publication, television or radio broadcast, the display of signs, labels or goods, the <b>distribution</b> <b>of</b> <b>samples,</b> circulars, catalogues or price lists or the exhibition of picture, models or films, or in [...] "any other way". Previous legislation such as the Advertisements (Hire-Purchase) Act 1967 limited the definition of advertisement to visual advertisements and excluded oral communications and radio broadcasts, which are included by the Act. The test of whether an oral communication counts as an [...] "advertisement" [...] {{is whether or not the}} communication is made for drawing attention to the advertiser's business or for answering a specific enquiry without promoting the business. In R. v Delmayne 1970 2 QB 170 the High Court of Justice decided that even replying to an enquiry can amount to an advertisement if framed in such a way that it is calculated to attract business.|$|E
30|$|AdaBoost (AB). Boosting {{is a kind}} of {{ensemble}} learning algorithms that promote weak learner to strong learner. AB is a representative of this kind of boosting. Its training starts with a base learner and adjusts the <b>distribution</b> <b>of</b> <b>samples</b> based on the performance of the base learner. Then, it trains the next base learner based on the adjusted <b>distribution</b> <b>of</b> <b>samples</b> iteratively. Their outputs are given different weights that contribute to the final output of the boosted classifier. It {{is a kind of}} serial ensemble algorithm.|$|E
50|$|Asymptotic theory ("asymptotics") is used {{in several}} {{mathematical}} sciences. In statistics, asymptotic theory provides limiting approximations <b>of</b> the probability <b>distribution</b> <b>of</b> <b>sample</b> statistics, such as the likelihood ratio statistic and the expected value of the deviance. Asymptotic theory {{does not provide a}} method of evaluating the finite-sample <b>distributions</b> <b>of</b> <b>sample</b> statistics, however. Non-asymptotic bounds are provided by methods of approximation theory.|$|R
5000|$|Summarising {{probability}} <b>distributions</b> <b>of</b> <b>sample</b> data {{while making}} limited {{assumptions about the}} form <b>of</b> <b>distribution</b> that may be met ...|$|R
40|$|The joint <b>distributions</b> <b>of</b> <b>samples</b> from <b>distributions</b> {{chosen from}} a Dirichlet process with nonatomic {{parameter}} are given and the conditional <b>distributions</b> <b>of</b> the <b>samples</b> are derived, by the method different from Yamato [4]. By {{making use of}} the above result, the expectations of functions <b>of</b> the <b>samples</b> are evaluated...|$|R
3000|$|... where p (x_ 1 ^i) and q (x_ 1 ^i) are {{distributions}} {{associated with}} the initial state and the initial <b>distribution</b> <b>of</b> <b>samples</b> (both at k= 1).|$|E
30|$|This {{subsection}} first {{introduces the}} previous work of PC, and then presents an MPC strategy {{to overcome the}} drawback of PC without acquiring the spatial <b>distribution</b> <b>of</b> <b>samples,</b> finally, an HPC strategy combining hypergraph learning is proposed.|$|E
30|$|Data {{analysis}} and hypothesis testing were conducted through SPSS and partial least squares (PLS). PLS can test both the measurement and structure models, process small data samples, {{and does not}} require a normal <b>distribution</b> <b>of</b> <b>samples.</b> Hence, PLS was adopted for hypothesis verification and path analysis in this study.|$|E
50|$|Given the {{difficulty}} in specifying exact <b>distributions</b> <b>of</b> <b>sample</b> statistics, many methods {{have been developed for}} approximating these.|$|R
30|$|The CLT says that, {{even if a}} <b>distribution</b> <b>of</b> {{performance}} measurements is not normal, the <b>distribution</b> <b>of</b> the <b>sample</b> mean {{tends to}} a normal distribution as the sample size increases. For practical purposes, it is usually accepted that the resulting distribution is normally distributed when n â‰¥[*] 30 [30]. Experimenters often mistake <b>distribution</b> <b>of</b> performance measurements and <b>distribution</b> <b>of</b> <b>sample</b> means.|$|R
30|$|The {{descriptive}} {{analysis shows}} the <b>distribution</b> <b>of</b> <b>sample</b> papers per research methodology {{as well as}} the distribution with regard to the year of publication and the relevant journals.|$|R
40|$|According to the {{characteristic}} of the freeway, choosing three the most sensitive traffic parameters of AID(Automatic Incident Detection) as the feature vectors, an one-class classification based AID algorithm is proposed. The method establishes the regional distribution model of learning samples, and constructs the decision function in the feature space. When the detected data fall into the inner of the decision region, it will be judged as no incident happened, or else incidents happened. This method does not require any transcendental statistical hypothesis about the <b>distribution</b> <b>of</b> <b>samples,</b> even if the <b>distribution</b> <b>of</b> <b>samples</b> is non-convex and unconnected, it can gain better decision function. The experiment {{results show that the}} new algorithm can obtain a higher IR, and limit FIR effectively, so it is a new and potential method for AID. Key words: AID; One-class Classification;SVM;Freewa...|$|E
40|$|Cotyledon {{leaves of}} 81 samples of world gene pool of tartary {{buckwheat}} were investigated. Their linear parameters were measured; their morphological description was submitted. High positive corre-lation was established between linear parameters of cotyledon leaves {{and weight of}} 1000 grains. The <b>distribution</b> <b>of</b> <b>samples</b> on groups {{was conducted on the}} basis of these parameters...|$|E
3000|$|<b>Distribution</b> <b>of</b> <b>samples.</b> For given K central points (the mean {{points of}} the cluster samples), each sample is {{allocated}} in a cluster represented by the nearest mean point of its Euclidean distance, and the samples are divided into K clusters. Each sample can only be in a deterministic cluster to minimize the sum of squares within a group, i.e., each sample x [...]...|$|E
40|$|FIGURE 3. <b>Distribution</b> <b>of</b> <b>sampling</b> sites (histograms) {{according}} to elevation, water conductivity and pH. The sampling effort (circles) represents number <b>of</b> <b>sampling</b> sites standardized by {{the area of}} the respective elevational belt. Note that unequal number <b>of</b> <b>sampling</b> sites among plots reflects different availability of environmental data...|$|R
50|$|Although {{the values}} of the {{theoretical}} covariances and correlations are linked in the above way, the probability <b>distributions</b> <b>of</b> <b>sample</b> estimates <b>of</b> these quantities are not linked in any simple way and they generally need to be treated separately.|$|R
2500|$|The <b>distributions</b> <b>of</b> {{both the}} <b>sample</b> mean and the sample median were {{determined}} by Laplace. The <b>distribution</b> <b>of</b> the <b>sample</b> median from a population with a density function [...] is asymptotically normal with mean [...] and variance ...|$|R
40|$|Energy Technology {{undertook}} to coordinate an interlaboratory trial on {{the analysis of}} tributyltin in a water, a sediment and a biota sample. The CSIRO role included the preparation and <b>distribution</b> <b>of</b> <b>samples</b> to the participating laboratories, and the collation and analysis of results. The study involved seven laboratories in Australia and New Zealand: The following laboratories participated in the trial...|$|E
40|$|Figure 3 - Map {{of part of}} South America {{showing the}} {{geographic}} <b>distribution</b> <b>of</b> <b>samples</b> we confirmed as Lonchophylla inexpectata (black star [type locality] and square), Lonchophylla dekeyseri (circles), and Lonchophylla mordax (white star [type locality] and triangles). Localities 1, 2, 5 are in the Caatinga; localities 3, 4 are in the Caatingaâ€“Atlantic Forest ecotone; and localities 6 â€“ 8 are in the Cerrado...|$|E
30|$|Beta {{diversity}} analysis {{provides a}} measure of the distance between each sample. Both weighted and unweighted distance matrices were calculated and visualized with Principal coordinates analysis (PcoA) plots ([URL] and [URL] FigureÂ  2 C shows the weighted-distance <b>distribution</b> <b>of</b> <b>samples</b> in 3 D space. In this figure, both IBS (red) and noIBS (blue) samples are mixed, indicating that it was difficult to classify the samples according to the distance matrix.|$|E
40|$|As a {{fundamental}} task in computer architecture research, performance comparison has been continuously {{hampered by the}} variability of computer performance. In traditional performance comparisons, the impact of performance variability is usually ignored (i. e., the means of performance measurements are compared regardless of the variability), or in the few cases where it is factored in using parametric confidence techniques, the confidence is either erroneously computed based on the <b>distribution</b> <b>of</b> performance measurements (with the implicit assumption that it obeys the normal law), instead <b>of</b> the <b>distribution</b> <b>of</b> <b>sample</b> mean <b>of</b> performance measurements, or too few measurements are considered for the <b>distribution</b> <b>of</b> <b>sample</b> mean to be normal. We first illustrate how such erroneous practices can lead to incorrect comparisons. Then, we propose a non-parametric Hierarchical Performance Testing (HPT) framework for performance comparison, which is significantly more practical than standard parametric techniques {{because it does not}} require to collect a large number of measurements in order to achieve a normal <b>distribution</b> <b>of</b> the <b>sample</b> mean. This HPT framework has been implemented as an open-source software. ...|$|R
40|$|Equiprobable samples with {{replacements}} from Ð‡nite Abelian {{groups are}} con- sidered. Limit theorems are proved describing convergence <b>of</b> the <b>distribution</b> <b>of</b> {{the number of}} ordered subsamples meeting speciÐ‡ed linear relations to Poisson distributions. Basing on these theorems we construct a goodness-of-Ð‡t test which checks the hypothesis on the uniform <b>distribution</b> <b>of</b> <b>sample</b> elements...|$|R
50|$|Leon Isserlis (1881 - 1966) was a Russian-born British {{statistician}} {{known for}} his work on the exact <b>distribution</b> <b>of</b> <b>sample</b> moments, including Isserlisâ€™ theorem. He also {{brought to the attention of}} British statisticians the work of Russian mathematicians and statisticians, including Chebyshev and Chuprov.|$|R
40|$|FIGURE 4. The {{geographic}} <b>distribution</b> <b>of</b> <b>samples</b> {{examined in}} this study. A: Taibaishan; B: Wushan; C: Xingdoushan: D: Nanchuan; E: Markam; F: Baoxing; G: Zhongdian; H: Gongshan: I: Weixi; J: Bijiang; K: Pianma; L: Yaojiaping; M: Tengchong; N: Ailaoshan; O: Lijiang. : Omi San, Sichuan, type locality of N. a. andersoni; Ë”: Pianma, Lushui, Yunnan, type locality of N. a. pianmaensis; â€¤: Ailaoshan mountain, Yunnan, type locality of N. a. ailaoshanensis...|$|E
40|$|Abstract. Non-terminally {{separated}} (NTS) {{languages are}} a subclass of deterministic context free languages {{where there is}} a stable relationship between the substrings of the language and the non-terminals of the grammar. We show that when the <b>distribution</b> <b>of</b> <b>samples</b> is generated by a PCFG, based on the same grammar as the target language, the class of unambiguous NTS languages is PAC-learnable from positive data alone, with polynomial bounds on data and computation. ...|$|E
40|$|Two {{methods for}} urban noise mapping {{have been applied}} {{to the city of}} CÃ¡ceres (Spain). One of them is the usual grid method {{described}} in the ISO- 1996. The other one is the categorization method, recently described. A comparison between the results obtained for both methods is presented. For both methods the <b>distribution</b> <b>of</b> <b>samples</b> in intervals of Leq, and their relations with the flux of traffic have been studied, showing appreciable differences...|$|E
40|$|Under normality, an {{asymptotic}} <b>distribution</b> <b>of</b> <b>sample</b> covariance determinant will be derived. We {{show that}} this asymptotic distribution is more applicable in practice than the classical one. This will justify its usefulness in inferential study and other applications in a more comprehensive and accurate manne...|$|R
50|$|The <b>distribution</b> <b>of</b> the <b>sample</b> partial {{correlation}} {{was described by}} Fisher.|$|R
40|$|Abstract Under normality, an {{asymptotic}} <b>distribution</b> <b>of</b> <b>sample</b> covariance determinant will be derived. We {{show that}} this asymptotic distribution is more applicable in practice than the classical one. This will justify its usefulness in inferential study and other applications in a more comprehensive and accurate manner...|$|R
