138|831|Public
25|$|This is the {{principle}} of the camera, and of the human eye. The focusing adjustment of a camera adjusts S2, as using an <b>image</b> <b>distance</b> different from that required by this formula produces a defocused (fuzzy) image for an object at a distance of S1 from the camera. Put another way, modifying S2 causes objects at a different S1 to come into perfect focus.|$|E
2500|$|... are {{combined}} and solved for the <b>image</b> <b>distance</b> , {{the result is}} ...|$|E
2500|$|The <b>image</b> <b>{{distance}}</b> [...] {{is related}} to an object distance [...] by the thin lens equation ...|$|E
25|$|Focus {{is simply}} set to {{halfway between the}} near and far <b>image</b> <b>distances.</b>|$|R
2500|$|The <b>image</b> <b>distances</b> are {{measured}} from the camera's image plane to the lens's image nodal plane, {{which is not}} always easy to locate. The harmonic mean is always less than the arithmentic mean, but when the difference between the near and far <b>image</b> <b>distances</b> is reasonably small, the two means are close to equal, and focus can be set with sufficient accuracy using ...|$|R
2500|$|In {{practical}} terms, {{focus is}} set to halfway between the near and far <b>image</b> <b>distances.</b> The required f-number is ...|$|R
2500|$|A {{symmetrical}} lens {{is illustrated}} at right. The subject, at distance , is in focus at <b>image</b> <b>distance</b> [...] Point objects ...|$|E
2500|$|... where [...] is the <b>image</b> <b>distance</b> of the subject. For a defocused {{object with}} some {{characteristic}} dimension , the imaged size of that object is ...|$|E
2500|$|... at {{distances}} [...] and [...] {{would be}} in focus at image distances [...] and , respectively; at <b>image</b> <b>distance</b> , they are imaged as blur spots. The depth of field {{is controlled by the}} aperture stop diameter when the blur spot diameter is equal to the acceptable circle of confusion , the near and far limits of DOF are at [...] and [...] From similar triangles, ...|$|E
2500|$|... the {{harmonic}} {{mean of the}} near and far <b>image</b> <b>distances.</b> The basic image-side equations can also be combined and solved for , giving ...|$|R
2500|$|As {{with the}} {{approximate}} formula for , the approximate formulas for [...] require only the focus spread [...] {{rather than the}} absolute <b>image</b> <b>distances.</b>|$|R
40|$|A {{series of}} {{holograms}} is recorded by synchronizing a camera with laser pulses {{under the control}} of a digital delay generator. Amplitude and phase images are calculated while <b>image</b> <b>distances</b> are adjusted for the best focus on the object under observation. The amplitude and phase images are reconstructed while adjusting the <b>image</b> <b>distances</b> over a predetermined range to maintain the object in focus. Numerical superposition of a plurality of holographic fields taken with varying wavelengths provides high resolution microscopic three-dimensional imaging. Numerical reconstruction is based on an angular spectrum method that enables calculation of the <b>image</b> at any <b>distance</b> from the hologram plane. Wavelength scanning digital interference holography also enables image reconstruction along an arbitrarily tilted plane...|$|R
2500|$|In practice, these {{settings}} {{usually are}} determined {{on the image}} side of the lens, using measurements on the bed or rail with a view camera, or using lens DOF scales on manual-focus lenses for small- and medium-format cameras. If [...] and [...] are the image distances that correspond to the near and far limits of DOF, the required f-number is minimized when the <b>image</b> <b>distance</b> ...|$|E
2500|$|Therefore, if {{an object}} is placed at a {{distance}} [...] from a positive lens of focal length f, we will find an <b>image</b> <b>distance</b> S2 according to this formula. If a screen is placed {{at a distance}} S2 {{on the opposite side of}} the lens, an image is formed on it. This sort of image, which can be projected onto a screen or image sensor, is known as a real image.|$|E
5000|$|... #Subtitle level 3: Content {{comparison}} using <b>image</b> <b>distance</b> measures ...|$|E
5000|$|... where u′ and v′ are {{the object}} and <b>image</b> <b>{{distance}}s</b> {{along the line of}} sight and S is the distance from the line of sight to the Scheimpflug intersection at S. Again from Figure 7, ...|$|R
50|$|This formula {{requires}} only {{the difference between}} the near and far image distances.View camera users often refer to this difference as the focus spread;it usually is measured on the bed or focusing rail.Focus is simply set to halfway between the near and far <b>image</b> <b>distances.</b>|$|R
40|$|Gradient descent in <b>image</b> <b>distances</b> {{can lead}} a {{navigating}} agent {{to the goal}} location, but in environments with an anisotropic distribution of landmarks, gradient home vectors deviate from the true home direction. These deviations can be reduced by applying Newton’s method to matched-filter descent in <b>image</b> <b>distances</b> (MFDID). Based on several image databases we demonstrate that the home vectors produced by the Newton-based MFDID method are usually closer to the true home direction than those obtained from the original MFDID method. The greater accuracy of Newton-MFDID home vectors {{in the vicinity of}} the goal location would allow a navigating agent to approach the goal on straighter trajectories, improve the results of triangulation procedures, and enhance a robot’s ability to detect its arrival at a goal...|$|R
5000|$|... are {{combined}} and solved for the <b>image</b> <b>distance</b> , {{the result is}} ...|$|E
50|$|The {{most common}} method for {{comparing}} two images in content-based image retrieval (typically an example image and an {{image from the}} database) is using an <b>image</b> <b>distance</b> measure. An <b>image</b> <b>distance</b> measure compares the similarity of two images in various dimensions such as color, texture, shape, and others. For example, a distance of 0 signifies an exact match with the query, {{with respect to the}} dimensions that were considered. As one may intuitively gather, a value greater than 0 indicates various degrees of similarities between the images. Search results then can be sorted based on their distance to the queried image. Many measures of <b>image</b> <b>distance</b> (Similarity Models) have been developed.|$|E
5000|$|... where t is {{the total}} depth of focus, N is the lens f-number, c is the circle of confusion, v is the <b>image</b> <b>distance,</b> and f is the lens focal length. In most cases, the <b>image</b> <b>distance</b> (not to be {{confused}} with subject distance) is not easily determined; the depth of focus can also be given in terms of magnification m: ...|$|E
50|$|By optical convention, both {{object and}} <b>image</b> <b>distances</b> are {{positive}} for real images, {{so that in}} Figure 6, the object distance u increases {{to the left of}} the lens plane LP; the vertical axis uses the normal Cartesian convention, with values above the optical axis positive and those below the optical axis negative.|$|R
5000|$|The angle ψ {{increases}} with focus distance; when {{the focus is}} at infinity, the PoF is perpendicular to the image plane for any nonzero value of tilt. The distances u′ and v′ {{along the line of}} sight are not the object and <b>image</b> <b>distances</b> u and v used in the thin-lens formula ...|$|R
2500|$|... where [...] is the {{distance}} from the object to the lens, [...] is {{the distance}} from the lens to the image, and [...] is the focal length of the lens. In the sign convention used here, the object and <b>image</b> <b>distances</b> are positive if the object and image are {{on opposite sides of the}} lens.|$|R
5000|$|The <b>image</b> <b>{{distance}}</b> [...] {{is related}} to an object distance [...] by the thin lens equation ...|$|E
5000|$|... #Caption: A graph of the {{resolution}} limit of the pinhole camera {{as a function of}} focal length (<b>image</b> <b>distance).</b>|$|E
5000|$|By tracing these rays, the {{relationship}} between the object distance s and the <b>image</b> <b>distance</b> s′ can be shown to be ...|$|E
30|$|Drones: battery (power level), {{coordinate}} (GPS location), water depth, {{and power}} threshold, <b>image,</b> and <b>distance</b> flown.|$|R
50|$|The {{devices are}} {{typically}} about 30 cm long, and screw into an intermediate 't-mount' {{attached to the}} camera. The lens in the copier {{does not need to}} be complex, because the systems are usually stopped down to small f numbers (e.g. for the Makinon Zoom Unit, f/16 at 1:1 magnification, falling to f/22 at 3:1 magnification), and the object and <b>image</b> <b>distances</b> are similar, so that many aberrations are minimized.|$|R
30|$|The setup {{consists}} of several objects which are positioned {{in front of}} the sensors: boxes, cylinders, etc. Each scene is captured first with the laser scanner then with the two cameras, to exclude mutual interference. Then, the individual range camera measurements are compared to the reference <b>distance</b> <b>images</b> which have been generated from laser scanner data. For visualizing the measurement errors, we subtract the observed <b>distance</b> <b>image</b> from the virtual <b>distance</b> <b>image.</b>|$|R
5000|$|The {{relationship}} between the object distance u, the <b>image</b> <b>distance</b> v, and the lens focal length f is given by the thin-lens equation ...|$|E
5000|$|... where [...] is the <b>image</b> <b>distance</b> of the subject. For a defocused {{object with}} some {{characteristic}} dimension , the imaged size of that object is ...|$|E
5000|$|A {{symmetrical}} lens {{is illustrated}} at right. The subject, at distance , is in focus at <b>image</b> <b>distance</b> [...] Point objects at distances [...] and [...] {{would be in}} focus at image distances [...] and , respectively; at <b>image</b> <b>distance</b> , they are imaged as blur spots. The depth of field {{is controlled by the}} aperture stop diameter when the blur spot diameter is equal to the acceptable circle of confusion , the near and far limits of DOF are at [...] and [...] From similar triangles, ...|$|E
5000|$|... #Caption: In this simulation, {{adjusting}} {{the angle of}} view and distance of the camera while keeping the object in frame results in vastly differing <b>images.</b> At <b>distances</b> approaching infinity, the light rays are nearly parallel to each other, resulting in a [...] "flattened" [...] <b>image.</b> At low <b>distances</b> and high angles of view objects appear [...] "foreshortened".|$|R
2500|$|The <b>image</b> <b>distances</b> are {{measured}} from the camera's image plane to the lens's image nodal plane, {{which is not}} always easy to locate. In most cases, focus and f-number can be determined with sufficient accuracy using the approximate formulas above, which require only the difference between the near and far image distances; view camera users sometimes refer to the difference [...] as the focus spread (Hansma 1996, 55). Most lens DOF scales are based on the same concept.|$|R
40|$|Part 2 : Asian Conference on Availability, Reliability and Security (AsiaARES) International audienceIn this paper, PCA-based long {{distance}} face recognition algorithm {{applicable to the}} environment of intelligent video surveillance system is proposed. While the existing face recognition algorithm uses the short <b>distance</b> <b>images</b> for training images, the proposed algorithm uses face <b>images</b> by <b>distance</b> extracted from 1 m to 5 m for training images. Face <b>images</b> by <b>distance,</b> which are used for training images and test images, are normalized through bilinear interpolation. The proposed algorithm has improved face recognition performance by 4. 8 % in short distance and 16. 5 % in {{long distance}} so it is applicable to the intelligent video surveillance system...|$|R
