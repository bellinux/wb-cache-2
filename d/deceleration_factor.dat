14|11|Public
30|$|In {{order to}} model the way by which moving agents arrive in {{attractive}} areas, it is considered a parametric function that describes their velocities depending on the distance r to a center of force. The proposed model {{is based on a}} top speed from which the agent continuously experiments a deceleration according to a function inspired by the repulsive terms offered by [22, 25] and the <b>deceleration</b> <b>factor</b> described on [26].|$|E
40|$|AbstractCompared {{with the}} {{plentiful}} researches of the Hubble parameter and <b>deceleration</b> <b>factor,</b> {{the third time}} derivative of the scale factor a(t) in the FRW cosmology, namely, the jerk parameter j still lacks attention. In order to study the properties of j, we propose several kinds of parameterizations of j(z) {{as a function of}} the redshift z. By setting the standard ΛCDM model as the fiducial model, we constrain the jerk models with the observational Hubble parameter data (OHD) and Type Ia Supernovae (SNe) observations. We find that the perturbation of j(z) favors a value of nearly zero and the ΛCDM is well accommodated by the jerk reconstruction. We also compare the powers of OHD and SNe in constraining the jerk models in detail, and find that the newly released OHD measurement at z= 2. 3 can improve the constraint significantly, even tighter than the SNe one. Furthermore, we analyze the jerk models by calculating the Hubble parameter, equation of state, the <b>deceleration</b> <b>factor</b> and Om(z) diagnostic. Our results show that the universe is indeed undergoing an accelerated expansion phase following the matter-dominated one, which is consistent with the standard model by observations...|$|E
40|$|Compared {{with the}} {{plentiful}} researches of the Hubble parameter and <b>deceleration</b> <b>factor,</b> {{the third time}} derivative of the scale factor a(t) in the FRW cosmology, namely, the jerk parameter j still lacks attention. In order to study the properties of j, we propose several kinds of parameterizations of j(z) {{as a function of}} the redshift z. By setting the standard ΛCDM model as the fiducial model, we constrain the jerk models with the observational Hubble parameter data (OHD) and Type Ia Supernovae (SNe) observations. We find that the perturbation of j(z) favors a value of nearly zero and the ΛCDM is well accommodated by the jerk reconstruction. We also compare the powers of OHD and SNe in constraining the jerk models in detail, and find that the newly released OHD measurement at z= 2. 3 can improve the constraint significantly, even tighter than the SNe one. Furthermore, we analyze the jerk models by calculating the Hubble parameter, equation of state, the <b>deceleration</b> <b>factor</b> and Om(z) diagnostic. Our results show that the universe is indeed undergoing an accelerated expansion phase following the matter-dominated one, which is consistent with the standard model by observations. Comment: 18 pages, 11 figures, 4 table, version published in PL...|$|E
50|$|The {{greatest}} {{strength of the}} Pejsa model is that any projectile within a given flight regime (for example the supersonic flight regime) can be mathematically modeled well with only two velocity measurements, a distance between said velocity measurements, and a slope or <b>deceleration</b> constant <b>factor.</b> The model allows the drag curve to change slopes or curvature at three different points. Down range velocity measurement data can be provided around key inflection points allowing for more accurate calculations of the projectile retardation rate. The Pejsa model allows the slope factor to be tuned to account for subtle differences in the retardation rate of different bullet shapes and sizes. It ranges from 0.1 (flat-nose bullets) to 0.9 (very-low-drag bullets). If this slope or <b>deceleration</b> constant <b>factor</b> is unknown a default value of 0.5 will predict the flight behavior of most modern spitzer-type rifle bullets quite well. With the help of test firing measurements the slope constant for a particular bullet/rifle system/shooter combination can be determined. These test firings should preferably be executed at 60% and for extreme long range ballistic predictions also at 80% to 90% of the supersonic range of the projectiles of interest, staying away from erratic transonic effects. With this the Pejsa model can easily be tuned for the specific drag behavior of a specific projectile, making significant better (supersonic) ballistic predictions for ranges beyond 500 m (547 yd) possible. A practical downside of the Pejsa model is that accurate projectile specific down range velocity measurements to provide these better predictions {{can not be easily}} performed by the vast majority of shooting enthusiasts.|$|R
40|$|The {{phenomena}} of slow and stopped light have attracted a {{growing interest in}} recent years, not only in relation to fundamental physics but also due to the possibility to enhance the density of states over a broad bandwidth. In this thesis the effects of both loss and gain on slow and stopped light are investigated in a representative metamaterial and plasmonic waveguide setting, using both semi-analytic calculations and numerical time-domain simulations. Initially the influence of material loss {{on the ability to}} stop light in these passive structures is considered. By directly measuring the propagation of wavepackets it is demonstrated that extremely low group velocities, with <b>deceleration</b> <b>factors</b> of the order of 200, 000, can be achieved even in the presence of realistic material loss, resolving a previous dispute that this would not be possible. It is further shown that stopped light in the plasmonic waveguide is robust to low levels of surface roughness, currently a limiting factor in other slow light devices such as photonic crystal waveguides. The inclusion of gain materials into the waveguides is then investigated for loss compensation. Here full compensation of losses and even amplification of the modal fields is observed while maintaining zero group velocities. Importantly for the metamaterial waveguide it is found that the effective negative refractive index is maintained even in the amplification regime, as previously it had been suggested this would not be possible. Finally it is shown that in the amplification regime stopped light provides an inherent feedback mechanism leading to the dynamic formation of a lasing mode. The properties of these stopped-light lasing states are studied and it is shown that subwavelength localisation of the modal fields can be achieved, thus presenting a new route to creating nanoscale light sources. Open Acces...|$|R
40|$|In {{this paper}} {{we use the}} {{conformal}} teleparallel gravity to study an isotropic and homogeneous Universe which is settled by the FRW metric. We solve the field equations and we obtain the behavior of some cosmological parameters such as scale <b>factor,</b> <b>deceleration</b> parameter and the energy density of the perfect fluid which is the matter field of our model. The field equations, that we called modified Friedmann equations, allow us to define a dark fluid, with dark energy density and dark pressure, responsible for the acceleration in the Universe. Comment: Accepted in EPJ...|$|R
40|$|In this paper, the {{uncontrolled}} {{environmental factors}} are perturbed into {{the growth rate}} <b>deceleration</b> <b>factor</b> of the Gompertzian deterministic model. The growth process under Gompertz’s law is considered, thus lead to stochastic differential equations of Gompertzian with time delay. The Gompertzian deterministic model has proven to fit well with the clinical data of cancerous growth, however the performance of stochastic model towards clinical data {{is yet to be}} confirmed. The prediction quality of stochastic model is evaluated by comparing the simulated results with the clinical data of cervical cancer growth. The parameter estimation of stochastic models is computed by using simulated maximum likelihood method. 4 -stage stochastic Runge-Kutta is applied to simulate the solution of stochastic model. Low values of root mean-square error (RMSE) of Gompertzian model with random effect indicate good fits...|$|E
40|$|We {{study the}} slowing down of {{particle}} beams {{passing through the}} dusty plasma with power-law kappa-distributions. Three plasma components, electrons, ions and dust particles, can have different kappa-parameter. We derive the <b>deceleration</b> <b>factor</b> (the velocity moment equation) and the slowing down time of a test particle, and numerically study the slowing down properties of an electron beam, a proton beam and a dust particle beam, respectively, in the kappa-distributed dusty plasma. We show that the slowing down properties of particle beams depend strongly on the kappa-parameters of the plasma components, and the dust component plays a dominant role in the slowing down. And the slowing down also depends on mass and charge of the dust particles in the dusty plasma. More detailed results are shown in 17 numerical graphs. Comment: 20 pages, 17 figure...|$|E
40|$|We use the {{generalized}} Brans-Dicke theory, {{in which the}} Pauli metric is identified to be the physical space-time metric, to study the Universe in different epochs. Exact analytical expressions for dilaton field σ, cosmological radius R and density parameter Ω are obtained for k = + 1, 0, - 1 Universe in the radiation-dominated epoch. For matter dominated Epoch, exact analytical expressions for Hubble parameter H, cosmological radius, dilaton field, <b>deceleration</b> <b>factor</b> q, density parameter and the gravitational coupling of the ordinary matter are obtained for the flat Universe. Other important results are: (1) the density parameter Ω is always less than unity for the flat Universe because the dilaton field plays a role as an effective dark matter, and (2) the new Brans-Dicke parameter ω must be larger than 31. 75 in order to consistent with the observed data. link_to_subscribed_fulltex...|$|E
40|$|The general {{solution}} of the gravitational field equations for a full causal bulk viscous stiff cosmological fluid, with bulk viscosity coefficient proportional to the energy density to the power 1 / 4, is obtained in the flat Friedmann-Robertson-Walker geometry. The solution describes a non-inflationary Universe, which starts its evolution from a singular state. The time variation of the scale <b>factor,</b> <b>deceleration</b> parameter, viscous pressure, viscous pressure-thermodynamic pressure ratio, comoving entropy and Ricci and Kretschmann invariants is considered in detail. Comment: 6 pages, 6 figures, to appear in Int. J. Mod. Phys. ...|$|R
5000|$|In {{order to}} allow {{the use of a}} G1 {{ballistic}} coefficient rather than velocity data Dr. Pejsa provided two reference drag curves. The first reference drag curve is based purely on the Siacci/Mayevski retardation rate function. The second reference drag curve is adjusted to equal the Siacci/Mayevski retardation rate function at a projectile velocity of 2600 fps (792.5 m/s) using a [...]30-06 Springfield Cartridge, Ball, Caliber [...]30 M2 [...] rifle spitzer bullet with a slope or <b>deceleration</b> constant <b>factor</b> of 0.5 in the supersonic flight regime. In other flight regimes the second Pejsa reference drag curve model uses slope constant factors of 0.0 or -4.0. These <b>deceleration</b> constant <b>factors</b> can be verified by backing out Pejsa's formulas (the drag curve segments fits the form V(2 - N) / C and the retardation coefficient curve segments fits the form V2 / (V(2 - N) / C) = C * VN where C is a fitting coefficient). The empirical test data Pejsa used to determine the exact shape of his chosen reference drag curve and pre-defined mathematical function that returns the retardation coefficient at a given Mach number was provided by the US military for the Cartridge, Ball, Caliber [...]30 M2 bullet. The calculation of the retardation coefficient function also involves air density, which Pejsa did not mention explicitly. The Siacci/Mayevski G1 model uses the following deceleration parametrization (60 °F, 30 inHg and 67% humidity, air density ρ = 1.2209 kg/m3). Dr. Pejsa suggests using the second drag curve because the Siacci/Mayevski G1 drag curve does not provide a good fit for modern spitzer bullets. To obtain relevant retardation coefficients for optimal long range modeling Dr. Pejsa suggested using accurate projectile specific down range velocity measurement data for a particular projectile to empirically derive the average retardation coefficient rather than using a reference drag curve derived average retardation coefficient. Further he suggested using ammunition with reduced propellant loads to empirically test actual projectile flight behavior at lower velocities. When working with reduced propellant loads utmost care must be taken to avoid dangerous or catastrophic conditions (detonations) with can occur when firing experimental loads in firearms.|$|R
40|$|We {{reconsider the}} entropic-force {{model in which}} both kind of Hubble terms Ḣ and H^ 2 appear in the {{effective}} dark energy (DE) density affecting {{the evolution of the}} main cosmological functions, namely the scale <b>factor,</b> <b>deceleration</b> parameter, matter density and growth of linear matter perturbations. However, we find that the entropic-force model is not viable at the background and perturbation levels {{due to the fact that}} the entropic formulation does not add a constant term in the Friedmann equations. On the other hand, if on mere phenomenological grounds we replace the Ḣ dependence of the effective DE density with a linear term H without including a constant additive term, we find that the transition from deceleration to acceleration becomes possible but the recent structure formation data strongly disfavors this cosmological scenario. Finally, we briefly compare the entropic-force models with some related DE models (based on dynamical vacuum energy) which overcome these difficulties and are compatible with the present observations. Comment: 11 pages, 1 figure accepted for publication by Physical Review...|$|R
40|$|Texto completo: acesso restrito. p. 313 - 327 We {{investigate}} cosmological solutions of Brans–Dicke {{theory with}} both the vacuum energy density and the gravitational constant decaying linearly with the Hubble parameter. A particular class of them, with a constant <b>deceleration</b> <b>factor,</b> sheds light on the cosmological constant problems, leading to a presently small vacuum term, and to a constant ratio between the vacuum and matter energy densities. By fixing the only free parameter of these solutions, we obtain cosmological parameters in accordance with observations of both the relative matter density and the universe age. In addition, we have three other solutions, with Brans–Dicke parameter ω = − 1 and negative cosmological term, two of them with a future singularity of big-rip type. Although interesting from the theoretical point of view, {{two of them are}} not in agreement with the observed universe. The third one leads, in the limit of large times, to a constant relative matter density, being also a possible solution to the cosmic coincidence problem...|$|E
40|$|Abstract. The aim of {{this work}} is to study a non-homogenous {{extension}} of the Gompertz diffusion process (cf. [1], [8]), {{based on the fact}} that only the <b>deceleration</b> <b>factor</b> in the drift is a time-dependent function (this version can be considered as a Gompertz diffusion with exogenous factors). A particular case of this model has been considered (cf. [4]) in the study of the first passage time problem in the non-homogeneous diffusion process. The proposed extended non-homogeneous model is studied by the methodology based on Kolmogorov equations, whereas in [1, 8], the homogeneous process is studied by a methodology using Ito’s equations. Firstly, we obtain the probability density function (p. d. f.) of the process and its trend functions (non conditional and conditional). Then, the statistical inference in the model is achieved, estimating the parameters by the maximum likelihood method using discrete sampling, and obtaining the distributions of the resulting estimators and the confidence intervals of the parameters. Finally, the proposed model is applied to real data for electricity consumption in Morocco...|$|E
40|$|The aim of {{this work}} {{is the study of}} a non- {{homogenous}} extension of the Gompertz diffusion process (cf. [1], [2]), {{based on the fact that}} the <b>deceleration</b> <b>factor</b> in the drift is time depending function (this version can be considered like a Gompertz dif-fusion with exogenous factors). A particular case of this model has been considered (cf. [3]) in the study of the first passage time problem in non-homogenous diffusion process. The proposed extended non homogeneous model is studied by the methodol-ogy based on Kolmogorov equations, whereas in [1] and [2], the homogeneous process has been studied by the Ito equations methodology. Firstly we obtain the probability density function (p. d. f) of the process and their trend functions (non conditional and conditional). Later the statistical inference in the model is achieved: the parameters estimation by means of the maximum likelihood method using discrete sampling; the distributions of the resulting estimators and the confidence intervals of the parame-ters. Finally the proposed model is applied to real dat...|$|E
40|$|Background: Isokinetic dynamometry {{allows the}} {{measurement}} of several variables related to muscular performance, {{many of which are}} seldom used, while others are redundantly applied to the characterization of muscle function. Objectives: The present study aimed to establish the particular features of muscle function that are captured by the variables currently included in isokinetic assessment and to determine which variables best represent these features in order to achieve a more objective interpretation of muscular performance. Method: This study included 235 male athletes. They performed isokinetic tests of concentric knee flexion and extension of the dominant leg at a velocity of 60 &# 186;/s. An exploratory factor analysis was performed. Results: The findings demonstrated that isokinetic variables can characterize more than muscle torque production and pointed to the presence of 5 factors that enabled the characterization of muscular performance according to 5 different domains or constructs. Conclusions: The constructs can be described by torque generation capacity; variation of the torque generation capacity along repetitions; movement <b>deceleration</b> capacity; mechanical/physiological <b>factors</b> of torque generation; and acceleration capacity (torque development). Fewer than eight out of sixteen variables are enough to characterize these five constructs. Our results suggest that these variables and these 5 domains may lead to a more systematic and optimized interpretation of isokinetic assessments...|$|R
40|$|Productivity {{growth in}} {{agriculture}} {{is essential for}} the development of the sector. This paper has reviewed the developments in agricultural productivity related to the South Asian countries, namely Bangladesh, India, Nepal, Pakistan, and Sri Lanka. The TFP growth and its contribution in production growth have been summarised for South Asia over the past three decades. Crop-specific TFP growth figures have been updated for India by using more recent micro farm level data for three decades. A discussion and synthesis on changes in TFP and its sources of growth for the major crops, major crop systems, crops and livestock sectors for the countries of South Asia have also been presented. Methodological framework for computation of TFP and its growth has also been presented. Policies towards food-secure South Asia have been outlined under the sub-heads (i) Arresting <b>deceleration</b> in total <b>factor</b> productivity, (ii) Enhancing yield of major commodities, (iii) Accent on empowering the small farmers, (iv) Environment protection, and (v) Strengthening of national agricultural research system. This paper would provide useful information to the people interested in doing research on these issues. Some of the concerns raised in this paper on productivity would provide direction for future research in this area. Productivity Analysis,...|$|R
40|$|Studies of {{composite}} headway {{models and}} platooning are reviewed and further results on time headways distribution are given. It {{is suggested that}} a three-population model is more satisfactory than a two-population model when short headways are of primary importance. Platoons were shown to occur randomly {{and the distribution of}} platoon sizes can be closely represented by a modified geometric distribution. It was also found that the distribution of headways in platoons was independent of speed at a given site, and members of platoons were shown to follow too closely in terms of the Highway Code advice; this close following behaviour was shown to be relatively greater at higher speeds. Observations showed that the deceleration behaviour of driver in a major road approaching a rural T-junction was affected by the T-junction (a) being unoccupied, (b) having vehicles waiting to cross and (c) having vehicles actually crossing. The results in case (a) were used to deconvolute the effects due to background in cases (b) and (c). Empirical results on the relationship between a measure of <b>deceleration</b> and other <b>factors</b> are presented. The deconvoluted values together with other observed data were used as input into a conflict simulation model. The output of the model consists of the number of precautionary and severe model conflicts to be expected in various circumstances. Results on driver gap-acceptance behaviour in adverse weather conditions at T-junctions are presented in appendix. No evidence of more cautious behaviour in wet weather was found. <p...|$|R
40|$|We {{investigate}} cosmological solutions of Brans-Dicke {{theory with}} both the vacuum energy density and the gravitational constant decaying linearly with the Hubble parameter. A particular class of them, with constant <b>deceleration</b> <b>factor,</b> sheds light on the cosmological constant problems, leading to a presently small vacuum term, and to a constant ratio between the vacuum and matter energy densities. By fixing the only free parameter of these solutions, we obtain cosmological parameters in accordance with observations of both the relative matter density and the universe age. In addition, we have three other solutions, with Brans-Dicke parameter w = - 1 and negative cosmological term, two of them with a future singularity of big-rip type. Although interesting from the theoretical point of view, {{two of them are}} not in agreement with the observed universe. The third one leads, in the limit of large times, to a constant relative matter density, being also a possible solution to the cosmic coincidence problem. Comment: Minor changes, references added. Version accepted for publication in Classical and Quantum Gravit...|$|E
40|$|At {{the end of}} 1990 s, Danny Quah devoted several {{papers to}} the {{analysis}} of polarization and stratification in the convergence processes of economies, creating the image of the ‘convergence clubs’ and suggesting the importance of studying the distribution dynamics of the macroeconomic variables. As for the labour markets, Overman and Puga (2002) showed that a progressive polarization of unemployment was in fact occurring among the European regions in 1986 – 1996, causing a phenomenon of cross-border clusterization. Here we propose to analyse the evolution of the unemployment rates of the EU 27 regions {{in the last two decades}} assuming that the unemployment rates evolve according to a Gompertz stochastic process. The estimated parameters of the process – intrinsic growth rate, <b>deceleration</b> <b>factor,</b> volatility – represent the evolutionary path of the unemployment rate and allow for estimating the steady state of the process. A cluster analysis is performed on the steady state values of the unemployment rates. The analysis confirms the emergence of several ‘convergence clubs’ among the European regional labour markets, which are compared to the clusters resulting from the more traditional clusterization on the current unemployment rates...|$|E
40|$|Wenn Zeit in erwachsenenpädagogischen Kontexten thematisiert wird, stehen zumeist ihre formale Bereitstellung und die Frage ihrer bestmöglichen Ausnutzung im Vordergrund. Wie selbstverständlich wird allzu oft eine Zeitvorstellung unterlegt, die einer unternehmerischen Ordnung entspringt und in der Metapher »Ressource« ihren Ausdruck findet. Dagegen wäre daran zu erinnern, dass die Bildungszeit Erwachsener am wenigsten eine quantitative, vielmehr eine {{qualitative}} Größe ist, die inhaltlich gestaltet werden muss. Darin besitzt die "Bildungszeit" eine eigene Struktur, die als Moment der Verzögerung gefasst werden kann. Experience {{cannot be}} synthesised - it needs time. This aspect {{moves to the}} centre of attention when educational training time is not examined {{from the perspective of}} its exploitation, but rather in terms of its enablement. This article conceives of adults' educational time as a qualitative factor whose content requires structuring. The structure of educational training time {{is at the same time}} viewed as a <b>deceleration</b> <b>factor.</b> Deceleration is not understood here to mean passive non-activity, but rather a sought-after "activeness" to oppose the pressure of time. Against this backdrop, a temporal-phenomenological adult education must make deceleration processes possible. Applied didactically, the article presents various practices in deceleration using the examples of time organisation, repetition, discussions and breaks, art, question and answer structures and culture...|$|E
40|$|In deceleration, {{there are}} many factors that {{influent}} the <b>deceleration</b> performance. The <b>factors</b> are like brake system and the road condition. Other than that, how the driver pressed the brake pedal also influenced the deceleration performance and also the safety during braking. This must be considered during designed the brake system of the car. The objectives of this project are to collect the data of the passenger car during decelerates using the UMP’s test car under on-road and off-road driving condition and to analyze the deceleration performance of passenger car for difference deceleration test. This report describes the few type of deceleration by run the test. The test was divided into two sections which are on road and off road. For the on road test, the initial speed of the car before decelerate was varies and control the stopping distance. Base on the theory, the higher the initial speed of the car, the longest time and distance needed to stop safely but for this test, the stopping distance is constant so that the stopping time will decrease if the initial speed is increase. Other than that, the brake system also needs to absorb greater energy and power if the car decelerates from the high speed. For the off road test, the stopping time and stopping distance want to be study base on the initial speed of the car. Finally, some calculations need to be performed using related formulas and equations {{to know the difference}} between all the decelerations types. Some graphs was plotted to show the trends and pattern of the result. The results concluded that the braking techniques and ways to reduce the car speed will affect the stopping time, stopping distance, and power and energy absorb by the brake system. Therefore, the road condition also is the main factor that influent the deceleration performance of the passenger car. The results indicate difference deceleration behavior for passenger car under various speed in on-road and off-road condition, which is an important study to develop difference braking techniques...|$|R
40|$|BACKGROUND The past 10 to 15 {{years have}} {{witnessed}} substantial advances {{in our ability}} to controllably adjust, slow down, or accelerate the speed of light signals propagating through dispersive optical media. In the fields of optoelectronics and photonics, we have for decades been accustomed to using propagating or guided light waves with speeds only slightly less than the speed of light in a vacuum, c—usually by a factor of 2 to 4. We now know that the group velocity of light waves entering a highly dispersive medium can be reduced by a factor of millions, down to the “human” scale, by exploiting judicious interference effects at the atomic scale of the material. Light <b>decelerations</b> by a <b>factor</b> of a few hundred, with low losses, can be attained in periodic dielectric structures, such as photonic crystal and coupled-resonator optical waveguides. Enabled applications include all-optical tunable delays for routers and data synchronization, optical buffers, enhanced light-matter interaction and nonlinear effects, and miniaturized photonic devices, such as modulators and interferometers. However, such atomic- or dielectric-media–based “slow light” is still fundamentally limited by the wavelength of light, λ, to spatial dimensions larger than ~λ/ 2 (~ 300 nm for visible light) —i. e., it is still diffraction limited and cannot reach true nanoscopic dimensions (e. g., below ~ 30 nm). It is at this point that media featuring negative electromagnetic parameters, such as negative-permittivity plasmonic media or negative–refractive index metamaterials, come to the rescue. ADVANCES Light deceleration in these media arises from the presence of a negative (real part of) electric permittivity, ε, or refractive index, n, leading to antiparallel power flows in the negative-parameter medium and the surrounding dielectric host—thereby giving rise to energy and group velocities that can be reduced even down to zero for a suitable choice of optogeometric parameters. This mechanism for slowing down light is thus nonresonant, and as such it can be broadband, with typical bandwidths being on the order of ~ 1 to 10 THz. Most notably, these structures support ultraslow surface-plasmon or surface-phonon polaritons that can be concentrated tightly into the nanoscale, at nanovolumes (at least) thousands of times smaller than λ 3, upon suitable adiabatic tapering. This leads to large local field enhancements, of the order of 102 to 103, over small nanovolumes that can be exploited for a host of useful applications, including nanoimaging, biosensing and nanoscale chemical mapping, high-density magnetic data-storage recording, light harvesting, nanolasing, and nanoscale quantum and nonlinear optics. One must be mindful, though, of targeting applications (such as the ones mentioned above) for which dissipative losses, which are normally higher in these media compared to their dielectric counterparts, are not a prohibitive factor—i. e., applications for which energy efficiency is not the key figure-of-merit. OUTLOOK Thus far, this method of nanoscale, broadband slow light has relied on the use of uniform or nanostructured metals (plasmonic media), but continued advances in materials design and synthesis have recently enabled a transition to alternative media, such as doped semiconductors, graphene, hexagonal boron nitride, transition-metal dichalcogenides (such as TaS 2), van der Waals crystals, and heterostructures. There are important ongoing efforts to push the response of these alternative media, which is currently mainly in the mid- and near-infrared regimes, into the visible region as they allow for considerably lower losses and enhanced controllability (e. g., simply by application of a gate voltage). With these new material platforms, opportunities for new applications emerge, too, particularly those requiring nanoscale (and even atomic) confinements and ultrahigh field enhancements, such as low-threshold single-photon nonlinearities and applications relying on the generation and manipulation of nonclassical light, at ambient conditions...|$|R
40|$|Copyright © 2005 SAE International The {{equations}} of {{rotational motion}} {{used to calculate}} pre-impact vehicle speeds using the rotational displacement of the vehicles following a collision are well known. The technique uses the rotational momentum exchange during impact and the principle of conservation of rotational energy to calculate the post impact vehicle angular velocity from the energy dissipated during the vehicle’s rotation to a stop (product of torque and rotational displacement). Integral to the calculation of the stopping torque on the vehicle is {{the determination of the}} effective rotational coefficient of friction (fr) between the tires and the roadway. The interactions of the road with the tires to produce the rotational coefficient of friction (fr) are more complex and less understood than those of linear coefficient of friction (<b>deceleration</b> <b>factor).</b> A derivation of the post impact equations of motion and the kinematics of vehicles in rotation are examined. The resultant parameters of motion that affect the rotational coefficient of friction (fr) are presented. The effects of these various parameters on the rotational coefficient of friction (fr) were studied using EDSMACTM. Normalized coefficients, which can be multiplied by the roadway friction to obtain the rotational coefficient of friction (fr) under common accident scenarios, are presented. Use of equations of rotational motion supplements linear momentum equations in a momentum analysis. They are not a substitute for other accident reconstruction techniques, such as computer crash simulations...|$|E

