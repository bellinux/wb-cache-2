5|22|Public
50|$|Juice Jacking is a {{physical}} or <b>hardware</b> <b>vulnerability</b> specific to mobile platforms. Utilizing the dual purpose of the USB charge port, many devices have been susceptible to having data exfiltrated from, or malware installed onto a mobile device by utilizing malicious charging kiosks set up in public places or hidden in normal charge adapters.|$|E
40|$|Abstract—This paper {{introduces}} a hardware solution to password exposure problem caused by direct accesses to the keyboard hardware interfaces through which a possible attacker {{is able to}} grab user’s password even where existing countermeasures are deployed. Several researches have proposed reasonable software based {{solutions to the problem}} for years. However, recently introduced <b>hardware</b> <b>vulnerability</b> problems have neutralized the software approaches and yet proposed any effective software solution to the vulnerability. Hardware approach in this paper is expected as the only solution to the vulnerability. Keywords—Keyboard sniff, password exposure, <b>hardware</b> <b>vulnerability,</b> privacy problem, insider security. I...|$|E
40|$|The {{article is}} a brief survey of <b>hardware</b> <b>vulnerability</b> {{analysis}} methods that might be applicable against cryptographic algorithm implementations. Those methods are based on physical properties of a device processing the algorithm. Focusing on mathematical algorithm’s background the article would help mastering various implementation-based attacks...|$|E
30|$|Similar to the {{inevitable}} software <b>vulnerabilities,</b> <b>hardware</b> <b>vulnerabilities</b> broadly exist as well. Unsafe hardware architecture and complex production processes are two main factors of <b>hardware</b> <b>vulnerabilities.</b>|$|R
40|$|In today's {{scenario}} of banking operations, user identity protection, password protection {{is no longer}} safe to guard your personal information, {{in this paper we}} will try to explain different types of vulnerabilities and loose points which are attempted at the time of financial operations and generates fraud transactions due to fake entries and fake cards which makes the ATM vulnerable. Here we are presenting an analysis of little vulnerability over Auto Teller machine transactions. These vulnerabilities are categories in <b>hardware</b> <b>vulnerabilities,</b> software vulnerabilities, communication vulnerabilities and operational vulnerabilities. here we will discuss few types of vulnerabilities which makes the banking system unsecure and it results fake transactions over banking operations. Few vulnerabilities which we will cover in this paper are stand in time, skimming, Lebanese loop, pin entry vulnerabilities, etc. &# 13; &# 13; Keywords—auto teller machine, vulnerability, skimming, stand in time, pin entr...|$|R
5000|$|On the February 2017 RSA Conference Microsoft {{president}} Brad Smith suggested global rules - a [...] "Digital Geneva Convention" [...] - for cyber {{attacks that}} [...] "ban the nation-state hacking {{of all the}} civilian aspects of our economic and political infrastructures". He also stated that an independent organization could investigate and publicly disclose evidence that attributes nation-state attacks to specific countries. Furthermore, {{he said that the}} technology sector should collectively and neutrally work together to protect Internet users and pledge to remain neutral in conflict and not aid governments in offensive activity and to adopt a coordinated disclosure process for software and <b>hardware</b> <b>vulnerabilities.</b>|$|R
3000|$|... (2) Variety {{of attack}} means. The simple means of attack rely on unintentional yet harmful operations, such as {{downloading}} a program bundled with a Trojan. Next, worms and botnets {{are designed to}} self-replicate and spread. These attack means automatically exploit software vulnerabilities. The exploitation of software vulnerabilities has also evolved from code injection attacks to code reuse attacks such as ROP (Return-oriented programming) (Checkoway et al. 2010) and JOP (Jump-oriented programming) (Bletsch et al. 2011). Shifting the target from software to hardware, many side channel attacks exploit <b>hardware</b> <b>vulnerability.</b>|$|E
40|$|Security {{is one of}} {{the most}} if not the most {{important}} areas today. After the several attacks on the United States, security everywhere has heightened from airports to the communication among the military branches legionnaires. With advanced persistent threats (APT's) on the rise following Stuxnet, government branches and agencies are required, more than ever, to follow several standards, policies and procedures to reduce the likelihood of a breach. Attack vectors today are very advanced and are going to continue to get more and more advanced as security controls advance. This creates a need for networks and systems to be in an updated and secured state in a launch control system environment. FISMA is a law that is mandated by the government to follow when government agencies secure networks and devices. My role on this project is to ensure network devices and systems are in compliance with NIST, as outlined in FISMA. I will achieve this by providing assistance with security plan documentation and collection, system hardware and software inventory, malicious code and malware scanning, and configuration of network devices i. e. routers and IDS's/IPS's. In addition, I will be completing security assessments on software and <b>hardware,</b> <b>vulnerability</b> assessments and reporting, and conducting patch management and risk assessments. A guideline that will help with compliance with NIST is the SANS Top 20 Critical Controls. SANS Top 20 Critical Controls as well as numerous security tools, security software and the conduction of research will be used to successfully complete the tasks given to me. This will ensure compliance with FISMA and NIST, secure systems and a secured network. By the end of this project, I hope to have carried out the tasks stated above as well as gain an immense knowledge about compliance, security tools, networks and network devices, as well as policies and procedures...|$|E
5000|$|Software Security Assessments: The {{identification}} of <b>hardware</b> and software <b>vulnerabilities</b> through black box, white box, and gray box testing.|$|R
40|$|Abstract—Hardware {{is just as}} {{susceptible}} as {{software to}} “hacker attacks”, through inclusion of malicious logic; {{and the consequences of}} such an attack could be disastrous! The impact of software viruses has been felt, at one time or another, by the entire computerized world, through loss of productivity, loss of system resources or data, or mere inconvenience. However, the nature of malicious logic and defending against it is fundamentally different from its software counterpart. Malicious logic has the added dimension of not being removable once encapsulated in the system. This paper will identify <b>hardware</b> <b>vulnerabilities</b> and will outline an automated method, called Structural Checking, to detect and prevent malicious logic from becoming incorporated into an ASIC, which could cause catastrophic system failure, security breaches, or other dire consequences. I...|$|R
40|$|Telecommunication {{services}} are complex product packages {{that rely on}} a large and complex technical infrastructure. However, fraudulent use of such telecommunication services rarely exploits <b>hardware</b> <b>vulnerabilities.</b> Instead, most common exploits operate at a business level, capitalizing on the unexpected interaction between various product packages from multiple providers. As such, an assumption was made {{that in order to}} fully describe the scenarios, a modelling language capable of describing value transactions between actors is required. In order to validate this assumption, a business value modelling language, e 3 value was selected, generic (non-misuse) business models were created and four misuse scenarios were modelled. This report showcases the models, discusses strengths and limitations encountered during modelling and draws conclusions with regard to the applicability, usability and utility of e 3 value models in modelling (Telecom) fraud as well as more generally in Risk Assessment...|$|R
40|$|The 2013 Snowden revelations {{ignited a}} vehement {{debate on the}} {{legitimacy}} and breadth of intelligence operations that monitor the Internet and telecommunications worldwide. The ongoing invasion of the private sphere of individuals around the world by governments and companies {{is an issue that}} is handled inadequately using current technological and organizational measures. This article(1) argues that in order to retain a vital and vibrant Internet, its basic infrastructure needs to be strengthened considerably. We propose a number of technical and political options, which would contribute to improving the security of the Internet. It focuses on the debates around end-to-end encryption and anonymization, as well as on policies addressing software and <b>hardware</b> <b>vulnerabilities</b> and weaknesses of the Internet architectureThis work has been partially funded by the European Parliament, under the following contract number: 03210 - 02 - 00 / 5127 / 9840...|$|R
40|$|Hardware-based {{mechanisms}} for software isolation {{are becoming increasingly}} popular, but implementing these mechanisms correctly has proved difficult, undermining the root of security. This work introduces {{an effective way to}} formally verify important properties of such hardware security mechanisms. In our approach, hardware is developed using a lightweight security-typed hardware description language (HDL) that performs static information flow analysis. We show the practicality of our approach by implementing and verifying a simplified but realistic multi-core prototype of the ARM TrustZone architecture. To make the security-typed HDL expressive enough to verify a realistic processor, we develop new type system features. Our experiments suggest that information flow analysis is efficient, and programmer effort is modest. We also show that information flow constraints are an effective way to detect <b>hardware</b> <b>vulnerabilities,</b> including several found in commercial processors. This research has been sponsored by NSF grant 1513797 and NASA grant NNX 16 AB 09 G...|$|R
50|$|Security bug (security defect) is a {{narrower}} concept: there are vulnerabilities {{that are not}} related to software: <b>hardware,</b> site, personnel <b>vulnerabilities</b> are examples of vulnerabilities that are not software security bugs.|$|R
40|$|AbstractThe 2013 Snowden revelations {{ignited a}} vehement {{debate on the}} {{legitimacy}} and breadth of intelligence operations that monitor the Internet and telecommunications worldwide. The ongoing invasion of the private sphere of individuals around the world by governments and companies {{is an issue that}} is handled inadequately using current technological and organizational measures. This article 11 This article is based on research carried out {{at the request of the}} Science and Technology Option Assessment Panel (STOA) and the Committee for Civil Liberties, Justice and Home Affairs (LIBE) of the European Parliament [11, 9]. Its scope is therefore primarily European, however its implications are assumed to be generally applicable. argues that in order to retain a vital and vibrant Internet, its basic infrastructure needs to be strengthened considerably. We propose a number of technical and political options, which would contribute to improving the security of the Internet. It focuses on the debates around end-to-end encryption and anonymization, as well as on policies addressing software and <b>hardware</b> <b>vulnerabilities</b> and weaknesses of the Internet architecture...|$|R
40|$|Intelligent Buildings (IB) {{have become}} {{increasing}} popular {{during the past}} decade, driven through the need to reduce energy, have more reactive and safer buildings, and increase productivity. IB integrate many systems {{that were in the}} past isolated from each other, including fire and life safety, HVAC, lighting, security, etc. Facilities contain commercial-in-confidence material and other valued assets; however, IB are integrated through open and common data communication protocols and hardware, leaving facilities exposed to external and internal threats. The study presents an investigation into IB, based on a defeat evaluation methdology. IB vulnerabilities considered two areas, namely physical and software vulnerabilties. Physical <b>hardware</b> <b>vulnerabilities</b> included physical access to the automation devices or workstations, communication networks, wiretapping, remote connectivity, foreign devices and local field programming. Software vulnerabilities included common connectivity protocols, restricted encryption and limited security considerations. These vulnerabilities could result in such attacks as denial of service, covert facilty entry or espionage. IB risks are contextual, aligned with the facility’s threat exposure; nevertheless, there are generic mitigation strategies that can be taken to protect IB systems. Protection includes situational threat driven security risk management, understanding system criticalities, integration of departments, a degree of network isolation and greater awareness...|$|R
40|$|For any {{computing}} {{system to be}} secure, both hardware and software have to be trusted. If the hardware layer in a secure system is compromised, not only {{it would be possible}} to extract secret information about the software, but it would also be extremely hard for the software to detect that an attack is underway. In this work we detail a complete end-to-end fault-attack on a microprocessor system and practically demonstrate how <b>hardware</b> <b>vulnerabilities</b> can be exploited to target secure systems. We developed a theoretical attack to the RSA signature algorithm, and we realized it in practice against an FPGA implementation of the system under attack. Toperpetratethe attack,weinjecttransient faultsinthe target machine by regulating the voltage supply of the system. Thus, our attack does not require access to the victim system’s internal components, butsimply proximitytoit. Thepapermakesthreeimportantcontributions: first,wedevelop a systematic fault-based attack on the modular exponentiation algorithm for RSA. Second, we expose and exploit a severe flaw on theimplementationoftheRSAsignaturealgorithmonOpenSSL,a widelyusedpackage forSSLencryptionandauthentication. Third, we report onthe firstphysical demonstration of a fault-basedsecurity attack of a complete microprocessor system running unmodified production software: we attack the original OpenSSL authentication library running on a SPARC Linux system implemented on FPGA, and extract the system’s 1024 -bit RSA private key in approximately 100 hours. 1...|$|R
40|$|Cyber-Physical system devices {{nowadays}} {{constitute a}} mixture of Information Technology (IT) and Operational Technology (OT) systems that are meant to operate harmonically under a security critical framework. As security IT countermeasures are gradually been installed in many embedded system nodes, thus securing them from many well-know cyber attacks there is a lurking danger that is still overlooked. Apart from the software vulnerabilities that typical malicious programs use, {{there are some very}} interesting <b>hardware</b> <b>vulnerabilities</b> that can be exploited in order to mount devastating software or hardware attacks (typically undetected by software countermeasures) capable of fully compromising any embedded system device. Real-time microarchitecture attacks such as the cache side-channel attacks are such case but also the newly discovered Rowhammer fault injection attack that can be mounted even remotely to gain full access to a device DRAM (Dynamic Random Access Memory). Under the light of the above dangers that are focused on the device hardware structure, in this paper, an overview of this attack field is provided including attacks, threat directives and countermeasures. The goal of this paper is not to exhaustively overview attacks and countermeasures but rather to survey the various, possible, existing attack directions and highlight the security risks that they can pose to security critical embedded systems as well as indicate their strength on compromising the Quality of Service (QoS) such systems are designed to provide...|$|R
40|$|The {{technique}} {{known as}} ACE Analysis allows researchers to quantify a <b>hardware</b> structure’s Architectural <b>Vulnerability</b> Factor (AVF) using simulation. This allows researchers {{to understand a}} <b>hardware</b> structure’s <b>vulnerability</b> to soft errors and consider design tradeoffs when running specific workloads. AVF {{is only applicable to}} hardware, however, and no corresponding concept has yet been introduced for software. Quantifying <b>vulnerability</b> to <b>hardware</b> faults at a software, or program, level would allow researchers {{to gain a better understanding}} of the reliability of a program as run on a particular architecture (e. g., X 86, PowerPC), independent of the micro-architecture on which it is executed. This ability can provide a basis for future research into reliability techniques at a software level. In this work, we adapt the techniques of ACE Analysis to develop a new software-level vulnerability metric called the Program Vulnerability Factor (PVF). This metric allows insight into the vulnerability of a software resource to hardware faults in a micro-architecture independent way, and can be used to make judgments about the relative reliability of different programs. We describe in detail how to calculate the PVF of a software resource, and show that the PVF of the architectural register file closely correlates with the AVF of the underlying physical register file and can serve as a good predictor of relative AVF when comparing the AVF of two different programs...|$|R
40|$|The Internet {{has become}} a global {{computing}} phenomenon, and during the 1990 's has had more influence on the computer - communications industry than any other development in its history. There are two major issues effecting {{the development of the}} Internet for the 21 st century; performance and security. This thesis is concerned with the later; in particular the issues raised by the interconnection of TCP/IP based networks between trusted and untrusted network domains. Four main topics are addressed: the common threats and vulnerabilities that effect the TCP/IP protocol suite at the Network, Transport, and Application layers; the application of firewall architectures to counter the risks posed by TCP/IP based connections between trusted and untrusted network domains; the issue of independent firewall architecture evaluation and certification; and the application of Virtual Private Network (VPN) technology to protect traffic over untrusted networks. This thesis examines the common threats and vulnerabilities which effect the current TCP/IP protocol suite, and hence the Internet. A firewall architecture can be a powerful tool for preventing attacks based on TCP/IP vulnerabilities, however, it is only as effective as the security policy that it implements. Although firewalls can benefit computer and network security, they suffer from several significant limitations, including; the inability to protect network traffic; defending against insider abuse; and controlling the content of end-user access (e. g. virus infected files, Java applets, etc.) Firewalls are generally considered impregnable, however they are certainly not immune to software and <b>hardware</b> <b>vulnerabilities.</b> Therefore, this thesis examines independent evaluation and certification of firewall architectures with particular focus on New Zealand and Australian efforts. The final section of this thesis examines the use of VPNs for securing network traffic. The amalgamation of VPN and firewall technologies allows the security policy to be extended onto the network in the form of services, such as, confidentiality, integrity, non-repudiation, and strong authentication...|$|R
40|$|This brief {{deals with}} the problem of mathematically formalizing <b>hardware</b> circuits' <b>vulnerability</b> to side-channel attacks. We {{investigate}} whether spectral analysis is a useful analytical tool for this purpose by building a mathematically sound theory of the vulnerability phenomenon. This research was originally motivated by the need for deeper, more formal knowledge around vulnerable nonlinear circuits. However, while building this new theoretical framework, we discovered that it can consistently integrate known results about linear ones as well. Eventually, we found it adequate to formally model side-channel leakage in several significant scenarios. In particular, {{we have been able to}} find the vulnerability perimeter of a known cryptographic primitive (i. e., Keccak Bertoni: 2010 ug) and thus tackle the analysis of vulnerability when signal glitches are present. We believe the conceptual framework we propose will be useful for researchers and practitioners in the field of applied cryptography and side-channel attacks...|$|R
40|$|<b>Hardware</b> side channel <b>vulnerabilities</b> {{have been}} studied {{for many years in}} {{embedded}} silicon-security arena including SmartCards, SetTop-boxes, etc. However, because various recent security activities have goals of improving the software isolation properties of PC platforms, software side channels have become a subject of interest. Recent publications discussed cache-based software side channel vulnerabilities of AES and RSA. Thus, following the classical approach [...] - a new side channel vulnerability opens a new mitigation research path [...] - this paper starts to investigate e#cient mitigations to protect AES-software against side channel vulnerabilities. First, we will present several mitigation strategies to harden existing AES software against cache-based software side channel attacks and analyze their theoretical protection...|$|R
40|$|Over {{the past}} years, {{extensive}} research {{efforts have been}} made to improve roadside safety hardware to reduce injury to occupants of four-wheel vehicles and heavy trucks. In comparison, limited research has been conducted to address the safety of motorcycle riders when impacting roadside safety <b>hardware.</b> The <b>vulnerability</b> of motorcycle riders can lead to a high risk of injury for the rider, especially when impacting roadside barriers. In fact, motorcycle crashes were found to be the leading source of fatalities in guardrail crashes. Physical crash testing is essential to prove crashworthiness of roadside safety barriers. No current standards exist that require upright motorcycle crash testing of motorcycles against barriers. In real-world motorcycle crashes there is a wide range of impacts against other vehicles and barriers. Reproducing these different motorcycle crash scenarios through physical crash testing can be considerably costly and time consuming. Computer simulations are a great tool to address the wide range of impacts in real-world motorcycle crashes because they are significantly less expensive and quicker than performing full scale crash tests. Motorcycle simulation models have been developed since the 1970 ?s and have improved in complexity over the years. However, there is still a need to develop detailed motorcycle models that are geometrically accurate and can accurately predict motorcycle response behavior. This study plans to develop a finite element computer model of a motorcycle through reverse engineering {{that can be used to}} analyze impact between motorcycles and barriers...|$|R
40|$|In {{scheduling}} a {{large number}} of user jobs for parallel execution on an open-resource Grid system, the jobs are subject to system failures or delays caused by infected <b>hardware,</b> software <b>vulnerability,</b> and distrusted security policy. This paper models the risk and insecure conditions in Grid job scheduling. Three risk-resilient strategies, preemptive, replication, and delay-tolerant, are developed to provide security assurance. We propose six risk-resilient scheduling algorithms to assure secure Grid job execution under different risky conditions. We report the simulated Grid performances of these new Grid job scheduling algorithms under the NAS and PSA workloads. The relative performance is measured by the total job makespan, Grid resource utilization, job failure rate, slowdown ratio, replication overhead, etc. In addition to extending from known scheduling heuristics, we developed a new space-time genetic algorithm (STGA) based on faster searching and protected chromosome formation. Our simulation results suggest that, in a wide-area Grid environment, it is more resilient for the global job scheduler to tolerate some job delays instead of resorting to preemption or replication or taking a risk on unreliable resources allocated. We find that delay-tolerant Min-Min and STGA job scheduling have 13 - 23 percent higher performance than using risky or preemptive or replicated algorithms. The resource overheads for replicated job scheduling are kept at a low 15 percent. The delayed job execution is optimized with a delay factor, which is 20 percent of the total makespan. A Kiviat graph is proposed for demonstrating the quality of Grid computing services. These risk-resilient job scheduling schemes can upgrade Grid performance significantly at only a moderate increase in extra resources or scheduling delays in a risky Grid computing environment. © 2006 IEEE. published_or_final_versio...|$|R
40|$|Abstract. <b>Hardware</b> side channel <b>vulnerabilities</b> {{have been}} studied {{for many years in}} {{embedded}} silicon-security arena including SmartCards, SetTop-boxes, etc. However, because various recent security activities have goals of improving the software isolation properties of PC platforms, software side channels have become a subject of interest. Recent publications discussed cache-based software side channel vulnerabilities of AES and RSA. Thus, following the classical approach — a new side channel vulnerability opens a new mitigation research path — this paper starts to investigate efficient mitigations to protect AES-software against side channel vulnerabilities. First, we will present several mitigation strategies to harden existing AES software against cache-based software side channel attacks and analyze their theoretical protection. Then, we will present a performance and security evaluation of our mitigation strategies. For ease of evaluation we measured the performance of our code against the performance of the openSSL AES implementation. In addition, we also analyzed our code under various existing attacks. Depending on the level of the required side channel protection, the measured performance loss of our mitigations strategies versus openSSL (respectively best assembler) varies between factors of 1. 35 (2. 66) and 2. 85 (5. 83) ...|$|R
40|$|The {{maturation}} of the International Space Station (ISS) design {{from the}} proposed Space Station Freedom to today's current implementation resulted in external <b>hardware</b> redundancy <b>vulnerabilities</b> {{in the final}} design. Failure to compensate for or respond to these vulnerabilities could put the ISS in a posture to where it could no longer function as a habitable space station. In {{the first years of}} ISS assembly, these responses were to largely be addressed by the continued resupply and Extra-Vehicular Activity (EVA) capabilities of the Space Shuttle. Even prior to the decision to retire the Space Shuttle, it was realized that ISS needed to have its own capability to be able to rapidly repair or replace external hardware without needing to wait for the next cargo resupply mission. As documented in a previous publicatoin 5, in 2006 development was started to baseline Extra- Vehicular Activity (EVA, or spacewalk) procedures to replace hardware components whose failure would expose some of the ISS vulnerabilities should a second failure occur. This development work laid the groundwork for the onboard crews and the ground operations and engineering teams to be ready to replace any of this failed hardware. In 2010, this development work was put to the test when one of these pieces of hardware failed. This paper will provide a brief summary of the planning and processes established in the original Contingency EVA development phase. It will then review how those plans and processes were implemented in 2010, highlighting what went well as well as where there were deficiencies between theory and reality. This paper will show that the original approach and analyses, though sound, were not as thorough as they should have been in the realm of planning for next worse failures, for documenting Programmatic approval of key assumptions, and not pursuing sufficient engineering analysis prior to the failure of the hardware. The paper will further highlight the changes made to the Contingency EVA preparation team structure, approach, goals, and the resources allocated to its work after the 2010 events. Finally, the authors will overview the implementation of these updates in addressing failures onboard the ISS in 2012, 2013, and 2014. The successful use of the updated approaches, and the application of the approaches to other spacewalks, will demonstrate the effectiveness of this additional work and make a case for putting significant time and resources into pre-failure planning and analysis for critical hardware items on human-tended spacecraft...|$|R
40|$|A thesis {{submitted}} to the University of Bedfordshire, in partial fulfilment of the requirements for the degree of Doctor of PhilosophyIt is widely accepted that modern computer networks (often presented as a heterogeneous collection of functioning organisations, applications, software, and <b>hardware)</b> contain <b>vulnerabilities.</b> This research proposes a new methodology to compute a dynamic severity cost for each state. Here a state refers to the behaviour of a system during an attack; {{an example of a}} state is where an attacker could influence the information on an application to alter the credentials. This is performed by utilising a modified variant of the Common Vulnerability Scoring System (CVSS), referred to as a Dynamic Vulnerability Scoring System (DVSS). This calculates scores of intrinsic, time-based, and ecological metrics by combining related sub-scores and modelling the problem’s parameters into a mathematical framework to develop a unique severity cost. The individual static nature of CVSS affects the scoring value, so the author has adapted a novel model to produce a DVSS metric that is more precise and efficient. In this approach, different parameters are used to compute the final scores determined from a number of parameters including network architecture, device setting, and the impact of vulnerability interactions. An attack graph (AG) is a security model representing the chains of vulnerability exploits in a network. A number of researchers have acknowledged the attack graph visual complexity and a lack of in-depth understanding. Current attack graph tools are constrained to only limited attributes or even rely on hand-generated input. The automatic formation of vulnerability information has been troublesome and vulnerability descriptions are frequently created by hand, or based on limited data. The network architectures and configurations along with the interactions between the individual vulnerabilities are considered in the method of computing the Cost using the DVSS and a dynamic cost-centric framework. A new methodology was built up to present an attack graph with a dynamic cost metric based on DVSS and also a novel methodology to estimate and represent the cost-centric approach for each host’ states was followed out. A framework is carried out on a test network, using the Nessus scanner to detect known vulnerabilities, implement these results and to build and represent the dynamic cost centric attack graph using ranking algorithms (in a standardised fashion to Mehta et al. 2006 and Kijsanayothin, 2010). However, instead of using vulnerabilities for each host, a CostRank Markov Model has developed utilising a novel cost-centric approach, thereby reducing the complexity in the attack graph and reducing the problem of visibility. An analogous parallel algorithm is developed to implement CostRank. The reason for developing a parallel CostRank Algorithm is to expedite the states ranking calculations for the increasing number of hosts and/or vulnerabilities. In the same way, the author intends to secure large scale networks that require fast and reliable computing to calculate the ranking of enormous graphs with thousands of vertices (states) and millions of arcs (representing an action to move from one state to another). In this proposed approach, the focus on a parallel CostRank computational architecture to appraise the enhancement in CostRank calculations and scalability of of the algorithm. In particular, a partitioning of input data, graph files and ranking vectors with a load balancing technique can enhance the performance and scalability of CostRank computations in parallel. A practical model of analogous CostRank parallel calculation is undertaken, resulting in a substantial decrease in calculations communication levels and in iteration time. The results are presented in an analytical approach in terms of scalability, efficiency, memory usage, speed up and input/output rates. Finally, a countermeasures model is developed to protect against network attacks by using a Dynamic Countermeasures Attack Tree (DCAT). The following scheme is used to build DCAT tree (i) using scalable parallel CostRank Algorithm to determine the critical asset, that system administrators need to protect; (ii) Track the Nessus scanner to determine the vulnerabilities associated with the asset using the dynamic cost centric framework and DVSS; (iii) Check out all published mitigations for all vulnerabilities. (iv) Assess how well the security solution mitigates those risks; (v) Assess DCAT algorithm in terms of effective security cost, probability and cost/benefit analysis to reduce the total impact of a specific vulnerability...|$|R

