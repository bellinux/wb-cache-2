396|464|Public
25|$|In 2011, the <b>iris</b> <b>image</b> of Lee's eye was {{captured}} and artistically rendered {{to resemble a}} sand art gallery piece. His eye image with his autograph was auctioned off {{to raise funds for}} the Singapore Eye Research Institute.|$|E
50|$|Methods {{that have}} been {{suggested}} to provide some defence {{against the use of}} fake eyes and irises include changing ambient lighting during the identification (switching on a bright lamp), such that the pupillary reflex can be verified and the <b>iris</b> <b>image</b> be recorded at several different pupil diameters; analysing the 2D spatial frequency spectrum of the <b>iris</b> <b>image</b> for the peaks caused by the printer dither patterns found on commercially available fake-iris contact lenses; analysing the temporal frequency spectrum of the image for the peaks caused by computer displays.|$|E
50|$|In 2011, the <b>iris</b> <b>image</b> of Lees eye was {{captured}} and artistically rendered {{to resemble a}} sand art gallery piece. His eye image with his autograph was auctioned off {{to raise funds for}} the Singapore Eye Research Institute.|$|E
30|$|In {{terms of}} cross-spectral iris matching, the authors in [14] {{proposed}} an adaptive method {{to predict the}} NIR channel <b>image</b> from VL <b>iris</b> <b>images</b> using neural networks. Similarly, Burge and Monaco [23, 24] proposed a model to predict NIR <b>iris</b> <b>images</b> using features derived from the color {{and structure of the}} visible light <b>iris</b> <b>images.</b> Although the aforementioned approaches ([14, 23, 24]) achieved good results, their methods require the <b>iris</b> <b>images</b> to be fully registered. Unfortunately, this is not applicable in reality because {{it is very difficult to}} capture registered <b>iris</b> <b>images</b> from the same subject simultaneously.|$|R
40|$|This paper {{presents}} a framework to synthesize large realistic iris databases, providing {{an alternative to}} iris database collection. Firstly, iris patch {{is used as a}} basic element to characterize visual primitive of iris texture, and patch-based sampling is applied to create an iris prototype. Then a set of pseudo irises with intra-class variations are derived from the prototype. Qualitative and quantitative studies reveal that synthetic databases are well suited for evaluating iris recognition systems by achieving three goals: (1) the synthetic <b>iris</b> <b>images</b> bear a close resemblance to real <b>iris</b> <b>images</b> in terms of visual appearance; (2) the proposed framework is able to generate databases with large capacity; (3) statistical performance shows that the synthetic <b>iris</b> <b>images</b> hold all the major characteristics of real <b>iris</b> <b>images.</b> 1...|$|R
30|$|<b>Iris</b> <b>images</b> used in {{this paper}} are {{available}} from the National Institute of Standards and Technology (NIST). The database of <b>iris</b> <b>images</b> {{used in this}} research is the Iris Challenge Evaluation (ICE) 2005 database [6]. This iris database is composed of a total of 2953 <b>iris</b> <b>images,</b> collected from 132 subjects. Of these images, 1425 were of right eyes from 124 different individuals and 1528 were left eyes from 120 individuals. The images are all VGA resolution, 480 rows by 640 columns, with 8 -bit grayscale resolution.|$|R
50|$|Identity {{information}} is {{any and all}} data {{that could be used}} to identify a person. Such information can be in the form of name, date of birth, signature, credit card number, debit card number, SIN, or other information. The bill also would have included other identifiers such as biological identifiers, DNA, fingerprint, retinal image, <b>iris</b> <b>image,</b> and voice print. Early in 2008, the Province of British Columbia began testing the use of such biometrics in a new enhanced drivers license.|$|E
50|$|Pierre De Muelenaere {{original}} {{background is}} Integrated circuit design. During his PhD, {{he has developed}} new microprocessor architectures dedicated to very fast Image Processing and Recognition. A prototype of a complete OCR system was also built in the University labs, based on {{a new generation of}} custom Image Processing ICs.With the support of the Belgian holding Ackermans & van Haaren, and together with a fellow PhD student Jean-Didier Legat, Pierre founded <b>I.R.I.S.</b> (<b>Image</b> Recognition Integrated Systems) in April 1987, to bring this invention to the market, develop and market Optical character recognition (OCR) and Intelligent Document Recognition (IDR) products.|$|E
50|$|Passengers who {{participate}} in this system must first provide personal biographical information including name, address, phone number, citizenship status, and previous addresses, along with other information. The biographical information will be collected by a commercial Registered Traveler service provider. The biographical portion of the enrollment may be accomplished via a secure web site. Next, the applicant will proceed to the biometric phase of the enrollment process. During biometric enrollment applicants will present identification documents and fingerprints. Applicants may also choose to have an image of their iris taken {{if they wish to}} use an <b>iris</b> <b>image</b> as an alternative to a fingerprint scan at the security checkpoint. The <b>iris</b> <b>image</b> is totally non-invasive to the eye. Once the biometric enrollment is complete, the service provider submits the collected data to the TSA which performs a Security Threat Assessment (STA) of the applicant. If the assessment does not indicate that the applicant is suspected of posing a risk to aviation security, the TSA will return an approved STA result to the service provider. The service provider will then provide the passenger with a Registered Traveler card. The card will be a smartcard, containing biometric information to prevent the card from being used by unauthorized persons. This card will then be inserted into a verification kiosk at the special checkpoints, which will verify the passengers biometrics (fingerprint or iris scan) and acknowledge membership and clearance to proceed to RT screening.|$|E
40|$|As a standard, 512 byte IrisCode {{templates}} {{developed with}} specific algorithms {{are stored in}} databases and used in iris recognition process. Future tendencies are to use exclusively real <b>iris</b> <b>images</b> rather than IrisCode templates in the iris recognition process. Many of current iris recognition systems use portable devices (e. g. iris scanners) which are often required to transmit image or template over communication channel. Image compression {{can be used in}} order to reduce the transmission time and storage capacities. Classified Vector Quantization (CVQ) and ordinary Vector Quantization (VQ) are used for compression of greyscale <b>iris</b> <b>images</b> collected from one of the available public databases of <b>iris</b> <b>images.</b> Results show that both compression methods are significantly more effective when applied to <b>iris</b> <b>images</b> than when applied to average images from everyday environments since <b>iris</b> <b>images</b> are fairly uniform and contain low contrast levels. Originally, CVQ is used to improve the quality of edges of compressed images because they are the most important part of image for visual impression on humans. The paper presents the comparison and major advantage of CVQ over ordinary VQ in terms of significant time reduction needed for <b>iris</b> <b>images</b> to be coded, and therefore it highlights a new important application of CVQ...|$|R
5000|$|Face and <b>iris</b> <b>images</b> taken under varying {{illumination}} conditions ...|$|R
30|$|Segmenting {{noisy and}} {{partially}} occluded <b>iris</b> <b>images</b> [3 – 7].|$|R
50|$|Certain {{countries}} represented within ISO/IEC JTC 1/SC 37 {{have also}} adopted {{a number of}} the subcommittee’s standards. Two official documents of Spain, the electronic national identity card (DNIe) and the Spanish ePassport, store biometric data outlined in ISO/IEC JTC 1/SC 37’s standard data interchange format. In addition, the Planning Commission of the Unique Identification Authority of India (UIDAI) has also planned to use ISO/IEC JTC 1/SC 37’s biometric series of standards for fingerprints (ISO/IEC 19794-4:2005, Information technology - Biometric data interchange formats - Part 4: Finger image data), face (ISO/IEC 19794-5, Information technology - Biometric data interchange formats - Part 5: Face image data) and iris (ISO/IEC 19794-6:2005, Information technology - Biometric data interchange formats - Part 6: <b>Iris</b> <b>image</b> data) data interchange formats for the organization’s unique identity project. The UIDAI is currently developing the Aadhaar ("Foundation") system and also plans to incorporate a number of other standards developed and facilitated by ISO/IEC JTC 1/SC 37, including, ISO/IEC 19785 CBEFF (Common Biometric Exchange Formats Framework), which provides the common structure, metadata, and security block in packaging the biometric data.|$|E
30|$|<b>Iris</b> <b>image</b> {{encryption}} {{is different}} from general image encryption algorithms and has different indicators in algorithm evaluation. The evaluation indexes of <b>iris</b> <b>image</b> encryption algorithm mainly include the following.|$|E
30|$|The <b>iris</b> <b>image</b> {{encryption}} algorithm based on deep learning firstly performs normalization and other preprocessing on the collected <b>iris</b> <b>image</b> dataset and then uses the deep learning {{neural network model}} to extract {{the features of the}} <b>iris</b> <b>image.</b> The extracted feature vector is used for key generation, and finally, the XOR operation is performed on the key and the pixel value of the original image.|$|E
30|$|Unlike {{previous}} works [14, 23, 24] {{in which they}} require fully registered <b>iris</b> <b>images</b> and learn models that lack the ability of generalization, our framework does not require any training and works on unregistered <b>iris</b> <b>images.</b> This combination along with its decision level fusion achieved encouraging results as illustrated in the next section.|$|R
40|$|Abstract—This paper {{present a}} pupil detection/segmentation {{algorithm}} for <b>iris</b> <b>images</b> based on Structure Tensor analysis. Eigenvalues {{of the structure}} tensor matrix have been observed to be high in pupil boundaries and specular reflections of <b>iris</b> <b>images.</b> We exploit this fact to detect the specular reflections region and the boundary of the pupil in a sequential manner. Experimental results are given using the CASIA-IrisV 3 -Interval database (249 contributors, 396 different eyes, 2, 639 <b>iris</b> <b>images).</b> Results show that our algorithm works specially well in detecting the specular reflections (98. 98 % success rate) and pupil boundary detection is correctly done in 84. 24 % of the images. I...|$|R
30|$|To {{examine the}} {{effectiveness}} of our method dealing with non-ideal VL <b>iris</b> <b>images</b> (UBIRIS).|$|R
40|$|Abstract Iris {{recognition}} {{has been}} acknowledged {{as the most}} accurate method in biometrics {{that is one of}} main automated identification technologies. The <b>iris</b> <b>image</b> quality and iris verification of eyes in dark brown, regular brown, hazel, green, and blue was tested. The effects of eyeglasses and contact lenses on the <b>iris</b> <b>image</b> quality score and iris verification were investigated, respectively. The investigated results indicate that the iris verifications with eyeglasses or contact lenses can still be successful although both eyeglasses and contact lenses decrease <b>iris</b> <b>image</b> quality. Analysis of variance (ANOVA) for the <b>iris</b> <b>image</b> quality of three eye colors (dark brown, hazel, and blue) was conducted to study the difference in the image quality due to the eye colors. The ANOVA results show there is {{no significant difference in the}} <b>iris</b> <b>image</b> quality of eyes in dark brown, hazel, and blue at the 0. 05 level of significance...|$|E
30|$|In this paper, {{the deep}} {{learning}} algorithm is introduced {{to extract the}} <b>iris</b> <b>image.</b> Based on the original <b>iris</b> <b>image</b> encryption algorithm, a new <b>iris</b> <b>image</b> encryption algorithm based on deep learning is proposed. The image encryption function is realized by training the sample. The simulation experiments on the iris samples of the public iris database show that the proposed method can solve the inconsistency of iris features and improve the confidentiality of the encryption and decryption process.|$|E
40|$|<b>Iris</b> <b>image</b> quality {{assessment}} {{is an important}} part of iris recognition system because the qualities of iris images would largely influence the recognition results. In this paper, we analyze and compare several representative {{quality assessment}} methods, and then propose an effective method based on Laplacian of Gaussian operator for <b>iris</b> <b>image</b> assessment. Through computer simulations of several typical algorithms on our <b>iris</b> <b>image</b> database, SJTU-IDB, the proposed method is shown superior to the compared quality assessment methods. 1...|$|E
40|$|Iris {{recognition}} algorithms, {{especially with}} the emergence of large-scale iris-based identification systems, must be tested for speed and accuracy and evaluated {{with a wide range of}} templates – large size, long-range, visible and different origins. This paper presents the acquisition of eye-iris images of dark-skinned subjects in Africa, a predominant case of verydark- brown <b>iris</b> <b>images,</b> under near-infrared illumination. The peculiarity of these <b>iris</b> <b>images</b> is highlighted from the histogram and normal probability distribution of their grayscale image entropy (GiE) values, in comparison to Asian and Caucasian <b>iris</b> <b>images.</b> The acquisition of eye-images for the African iris dataset is ongoing and will be made publiclyavailable as soon as it is sufficiently populated...|$|R
40|$|Iris {{pattern is}} {{commonly}} {{regarded as a}} kind of phenotypic feature without relation to genes. In our previous work, we argued that iris texture is race related, and its genetic infor-mation is illustrated in coarse scale texture features, rather than preserved in the minute local features of state-of-the-art iris recognition algorithms. In this paper, we propose a novel ethnic classification method based on learning appearance primitives of <b>iris</b> <b>images.</b> So we not only confirm that iris texture is race related, but also try to find out which kinds of iris visual primitives make <b>iris</b> <b>images</b> look different between Asian and non-Asian. In our scheme, we learned a small finite vocabulary of micro-structures, which are called Iris-Textons, to represent visual primitives of <b>iris</b> <b>images.</b> Then we use Iris-Texton histogram to capture the difference be-tween iris textures. Finally <b>iris</b> <b>images</b> are grouped into two race categories, Asian and non-Asian, by Support VectorMa-chine(SVM). Based on the proposed method, we get a higher correct classification rate(CCR) of 91. 02 % than our previous method on a database containing 2400 iris samples. Index Terms — <b>Iris</b> recognition, SVM, <b>image</b> process-ing, ethnic classification...|$|R
40|$|A novel {{two-stage}} protection {{scheme for}} automatic iris recognition systems against masquerade attacks {{carried out with}} synthetically reconstructed <b>iris</b> <b>images</b> is presented. The method uses different characteristics of real <b>iris</b> <b>images</b> to differentiate them from the synthetic ones, thereby addressing important security flaws detected in state-of-the-art commercial systems. Experiments are carried out on the publicly available Biosecure Database and demonstrate {{the efficacy of the}} proposed security enhancing approach...|$|R
40|$|Iris {{recognition}} as a reliable method for personal identification has been well-studied with the objective to assign the class label of each <b>iris</b> <b>image</b> to a unique subject. In contrast, <b>iris</b> <b>image</b> classification aims to classify an <b>iris</b> <b>image</b> to an application specific category, e. g., iris liveness detection (classification of genuine and fake iris images), race classification (e. g., classification of iris images of Asian and non-Asian subjects), coarse-to-fine iris identification (classification of all iris images in the central database into multiple categories). This paper proposes a general framework for <b>iris</b> <b>image</b> classification based on texture analysis. A novel texture pattern representation method called Hierarchical Visual Codebook (HVC) is proposed to encode the texture primitives of iris images. The proposed HVC method is an integration of two existing Bag-of-Words models, namely Vocabulary Tree (VT), and Locality-constrained Linear Coding (LLC). The HVC adopts a coarse-to-fine visual coding strategy and takes advantages of both VT and LLC for accurate and sparse representation of iris texture. Extensive experimental results demonstrate that the proposed <b>iris</b> <b>image</b> classification method achieves state-of-the-art performance for iris liveness detection, race classification, and coarse-to-fine iris identification. A comprehensive fake <b>iris</b> <b>image</b> database simulating four types of iris spoof attacks is developed as the benchmark for research of iris liveness detection. © 2013 IEEE. Iris {{recognition as}} a reliable method for personal identification has been well-studied with the objective to assign the class label of each <b>iris</b> <b>image</b> to a unique subject. In contrast, <b>iris</b> <b>image</b> classification aims to classify an <b>iris</b> <b>image</b> to an application specific category, e. g., iris liveness detection (classification of genuine and fake iris images), race classification (e. g., classification of iris images of Asian and non-Asian subjects), coarse-to-fine iris identification (classification of all iris images in the central database into multiple categories). This paper proposes a general framework for <b>iris</b> <b>image</b> classification based on texture analysis. A novel texture pattern representation method called Hierarchical Visual Codebook (HVC) is proposed to encode the texture primitives of iris images. The proposed HVC method is an integration of two existing Bag-of-Words models, namely Vocabulary Tree (VT), and Locality-constrained Linear Coding (LLC). The HVC adopts a coarse-to-fine visual coding strategy and takes advantages of both VT and LLC for accurate and sparse representation of iris texture. Extensive experimental results demonstrate that the proposed <b>iris</b> <b>image</b> classification method achieves state-of-the-art performance for iris liveness detection, race classification, and coarse-to-fine iris identification. A comprehensive fake <b>iris</b> <b>image</b> database simulating four types of iris spoof attacks is developed as the benchmark for research of iris liveness detection. © 2013 IEEE...|$|E
30|$|Deep {{learning}} can learn by unsupervised, semi supervised, or supervised {{methods of the}} original data, and extract the advanced features contained in the information. It {{can be used for}} pattern recognition, classification, and other scenes. Compared with the traditional feature extraction methods, it can produce better accuracy and achieve better application results. It is necessary to extract the feature of the <b>iris</b> <b>image</b> by using the iris to generate the image encryption key. However, the traditional feature extraction method is based on the image processing or shallow learning, and the operation is cumbersome and the quality of feature extraction is poor. So the feature extraction of <b>iris</b> <b>image</b> is carried out by deep learning. The feature extraction of <b>iris</b> <b>image</b> based on deep learning refers to the calculation of <b>iris</b> <b>image</b> by deep learning and extraction of the feature matrix, which mainly includes <b>iris</b> <b>image</b> acquisition, image preprocessing, feature depth learning, and feature extraction.|$|E
40|$|In this paper, we {{describe}} {{a new approach}} of employing Nelder-Mead optimization (NMO) simplex method in <b>Iris</b> <b>image</b> segmentation. In this paper we are using modified way of Libor masek method. In modified Libor masek method mainly in preprocessing phase in segmentation we are using Nelder-Mead search method also called as simplex method for calculation of center coordinates, radius and threshold in <b>iris</b> <b>image.</b> Here we are using IIT Delhi database of Indian person’s iris for our <b>iris</b> <b>image</b> segmentation...|$|E
40|$|Uncooperative iris {{identification}} {{systems at}} a distance suffer from poor resolution of the captured <b>iris</b> <b>images,</b> which significantly degrades iris recognition performance. Superresolution techniques have been employed to enhance the resolution of <b>iris</b> <b>images</b> and improve the recognition performance. However, all existing super-resolution approaches proposed for the iris biometric super-resolve pixel intensity values. This paper considers transferring super-resolution of <b>iris</b> <b>images</b> from the intensity domain to the feature domain. By directly super-resolving only the features essential for recognition, and by incorporating domain specific information from iris models, improved recognition performance compared to pixel domain super-resolution can be achieved. This is the first paper to investigate the possibility of feature domain super-resolution for iris recognition, and experiments confirm {{the validity of the}} proposed approach...|$|R
30|$|To {{clear up}} doubts over the {{usefulness}} of the proposed method dealing with almost ideal NIR <b>iris</b> <b>images</b> (CASIA).|$|R
3000|$|A novel {{framework}} for cross-spectral iris recognition capable of matching unregistered <b>iris</b> <b>images</b> captured under different lighting conditions [...]...|$|R
40|$|Custom JPEG {{quantisation}} matrices {{are proposed}} {{to be used}} in the context of compressing iris polar images within iris recognition. These matrices are obtained by employing a Genetic algorithm for the corresponding optimisation. Superior matching results in iris recognition in terms of average Hamming distance and improved ROC are found as compared to the use of the default JPEG quantisation table. <b>Iris</b> <b>Image</b> Properties and JPEG Q-Tables Fig. 1 visualizes image properties of common images vs. polar <b>iris</b> <b>image</b> images. Obviously, there is more energy in the horizontal direction in case of polar <b>iris</b> <b>image...</b>|$|E
40|$|Abstract—This paper proposes {{algorithms}} for iris segmentation, quality enhancement, match score fusion, and indexing {{to improve}} both the accuracy {{and speed of}} iris recognition. A curve evolution approach is proposed to effectively segment a non-ideal <b>iris</b> <b>image</b> using the modified Mumford-Shah functional. Different enhancement algorithms are concurrently applied on the segmented <b>iris</b> <b>image</b> to produce multiple enhanced versions of <b>iris</b> <b>image.</b> A SVM based learning algorithm selects locally enhanced regions from each globally enhanced image and combines these good quality regions to create a single high quality <b>iris</b> <b>image.</b> Two distinct features are extracted from the high quality <b>iris</b> <b>image.</b> The global textural feature is extracted using 1 D log polar Gabor transform and the local topological feature is extracted using Euler numbers. An intelligent fusion algorithm combines the textural and topological matching scores to further improve the iris recognition performance and reduce the false rejection rate, while an indexing algorithm enables fast and accurate iris identification. The verification and identification performance of the proposed algorithms are validated and compared with othe...|$|E
40|$|This paper proposes {{algorithms}} for iris segmentation, quality enhancement, match score fusion, and indexing {{to improve}} both the accuracy {{and the speed}} of iris recognition. A curve evolution approach is proposed to effectively segment a nonideal <b>iris</b> <b>image</b> using the modified Mumford–Shah functional. Different enhancement algorithms are concurrently applied on the segmented <b>iris</b> <b>image</b> to produce multiple enhanced versions of the <b>iris</b> <b>image.</b> A support-vector-machine-based learning algorithm selects locally enhanced regions from each globally enhanced image and combines these good-quality regions to create a single high-quality <b>iris</b> <b>image.</b> Two distinct features are extracted from the high-quality <b>iris</b> <b>image.</b> The global textural feature is extracted using the 1 -D log polar Gabor transform, and the local topological feature is extracted using Euler numbers. An intelligent fusion algorithm combines the textural and topological matching scores to further improve the iris recognition performance and reduce the false rejection rate, whereas an indexing algorithm enables fast and accurate iris identification. The verification and identification performance of the proposed algorithms is validated and compared with other algorithms using the CASIA Version 3, ICE 2005, and UBIRIS iris databases...|$|E
30|$|To {{evaluate}} {{the efficiency of}} the proposed method on the <b>iris</b> <b>images</b> taken under both VL and NIR illumination (UBIRIS+CASIA).|$|R
40|$|Interesting {{results of}} color {{clustering}} for the <b>iris</b> <b>images</b> in the UBIRISv 1 database are presented. The iris colors {{are characterized by}} feature vectors with 80 components corresponding to histogram bins computed in the CIELAB color space. The feature extraction {{is applied to the}} first session eye images after undergoing an iris segmentation process. An agglomerative hierarchical algorithm is used to organize 1. 205 segmented <b>iris</b> <b>images</b> in 8 clusters based on their color content...|$|R
40|$|Iris {{recognition}} {{is one of}} the most reliable personal identification methods. The potential requirement of obtaining high accuracy is that users supply <b>iris</b> <b>images</b> with good quality. It is thus necessary for an iris recognition system to operate the possibly blurred <b>iris</b> <b>images</b> due to less cooperation of users and camera with low resolution. This paper proposes a new algorithm for resolution enhancement of <b>iris</b> <b>images</b> captured by the low resolution camera in less cooperative situations. The prior probability relation between the information of different frequency bands of iris features useful for {{recognition is}} firstly learned. Then, it is incorporated into resolution enhancement algorithms to recover the lost information for the seriously blurred images. A large number of experiments on the CASIA iris database demonstrate the validity of the proposed approach...|$|R
