63|165|Public
5000|$|... #Subtitle level 3: Apollo 11 {{broadcast}} <b>data</b> <b>restoration</b> project ...|$|E
50|$|A {{differential}} backup {{is a type}} of data backup that preserves data, saving only the difference in the data since the last full backup. The rationale in this is that, since changes to data are generally few compared to the entire amount of data in the data repository, the amount of time required to complete the backup will be smaller than if a full backup was performed every time that the organization or data owner wishes to back up changes since the last full backup. Another advantage, at least as compared to the incremental backup method of data backup, is that at <b>data</b> <b>restoration</b> time, at most two backup media are ever needed to restore all the data. This simplifies data restores as well as increases the likelihood of shortening <b>data</b> <b>restoration</b> time.|$|E
50|$|Dropbox {{has been}} the subject of {{criticism}} and controversy related to multiple incidents, including a June 2011 authentication problem that let accounts be accessed for several hours without passwords, a July 2011 Privacy Policy update with language suggesting Dropbox had ownership of users' data, concerns about Dropbox employee access to users' information, July 2012 email spam with recurrence in February 2013, leaked government documents in June 2013 with information that Dropbox was being considered for inclusion in the National Security Agency's PRISM surveillance program, a July 2014 comment from NSA whistleblower Edward Snowden criticizing Dropbox's encryption, the leak of 68 million account passwords on the Internet in August 2016, and a January 2017 accidental <b>data</b> <b>restoration</b> incident where years-old supposedly deleted files reappeared in users' accounts.|$|E
5000|$|... #Subtitle level 2: Comparison {{with other}} <b>data</b> backup and <b>restoration</b> {{techniques}} ...|$|R
50|$|Although true in {{the absence}} of noise, many of the {{expansions}} proposed by Shannon become ill-posed. An arbitrarily small amount of noise on the <b>data</b> renders <b>restoration</b> unstable. Such sampling expansions are not useful in practice since sampling noise, such as quantization noise, rules out stable interpolation and therefore any practical use.|$|R
40|$|The Apollo Lunar Surface Experiment Packages (ALSEPs), suites of {{instruments}} deployed by the Apollo 12. 14, 15, 16 and 17 astronauts on the lunar surface, still represent the only in-situ {{measurements of the}} Moon's environment taken over long time periods, Much of these data are housed at the National Space Science Data Center (NSSDC) at Goddard Space Flight Center but are in forms that are not readily usable, such as microfilm, hardcopy, and magnetic tapes with older, obsolete formats. The Lunar Data Node (LDN) has been formed {{under the auspices of}} the Planetary Data System (PDS) Geosciences Node to put relevant, scientifically important Apollo data into accessible digital form for use by researchers and mission planners. The LDN has prioritized the <b>restoration</b> of these <b>data</b> based on their scientific and engineering value and the level of effort required. We will report on progress made and plans for future <b>data</b> <b>restorations...</b>|$|R
50|$|Criticism of Dropbox {{centers around}} {{various forms of}} {{security}} and privacy controversies surrounding Dropbox, an American company specializing in cloud storage and file synchronization. Issues include a June 2011 authentication problem that let accounts be accessed for several hours without passwords, a July 2011 Privacy Policy update with language suggesting Dropbox had ownership of users' data, concerns about Dropbox employee access to users' information, July 2012 email spam with reoccurrence in February 2013, leaked government documents in June 2013 with information that Dropbox was being considered {{for inclusion in the}} National Security Agency's PRISM surveillance program, a July 2014 comment from NSA whistleblower Edward Snowden criticizing Dropbox's encryption, the leak of 68 million account passwords on the Internet in August 2016, and a January 2017 accidental <b>data</b> <b>restoration</b> incident where years-old supposedly deleted files reappeared in users' accounts.|$|E
40|$|Network <b>data</b> <b>restoration</b> {{technology}} includes five basic modules: network packet capture, packet unpack, IP fragment reassembly, TCP stream aggregation, and WEB business extraction. In {{a network}} <b>data</b> <b>restoration</b> process, it should first parse the key field information of packets according to TCP/IP standard protocol. Then effectively restructure the IP fragment {{in line with}} the fragmentation identification and fragmentation offset in the Flags field in IP protocol. And also complete the efficient aggregation of TCP flows by using SEQ and ACK fields in TCP protocol at the same time. Finally, it can extract WEB business from TCP stream aimed at HTTP protocol...|$|E
40|$|IRAS sky {{mapping data}} is being reconstructed as images, and an entropy-based {{restoration}} algorithm is being applied {{in an attempt}} to improve spatial resolution in extended sources. Reconstruction requires interpolation of non-uniformly sampled <b>data.</b> <b>Restoration</b> is accomplished with an iterative algorithm which begins with an inverse filter solution and iterates on it with a weighted entropy-based spectral subtraction...|$|E
40|$|The Apollo {{missions}} between 1969 and 1972 deployed {{scientific instruments}} on the Moon's surface which made in-situ {{measurements of the}} lunar environment. Apollo II had the short-term Early Apollo Surface Experiments Package (EASEP) and Apollos 12, 14, 15, 16, and 17 each set up an Apollo Lunar Surface Experiments Package (ALSEP). Each ALSEP package contained a different suite of instruments which took measurements and radioed the results back to Earth over periods from 5 to 7 years until they were turned off on 30 September 1977. To this day the ALSEP data remain the only long-term in-situ information on the Moon's surface environment. The Lunar Data Node (LDN) has been formed {{under the auspices of}} the Planetary Data System (PDS) Geosciences Node to put relevant, scientifically important Apollo data into accessible digital form for use by researchers and mission planners. We will report on progress made since last year and plans for future <b>data</b> <b>restorations...</b>|$|R
40|$|This study {{presents}} {{a practical solution}} for <b>data</b> collection and <b>restoration</b> to migrate a process written in high level stack-based languages such as C and Fortran over a network of heterogeneous computers. We study a logical data model which recognizes complex data structures in process address space. Then, novel methods are developed to incorporate the model into a process and to collect and restore data efficiently. We have implemented a prototype software and performed experiments on different programs. Experimental and analytical results show that (1) a user-level process can be migrated across different computing platforms, (2) semantic information of data structures in the process's memory space can be correctly collected and restored, (3) the costs of <b>data</b> collection and <b>restoration</b> depend on {{the complexity of the}} logical model representing the process's data structures and the amount of data involved, and (4) the implantation of the <b>data</b> collection and <b>restoration</b> mechanisms into the process is not a decisive factor of incurring execution overheads; with appropriate program analysis, we can achieve practically low overhead. ...|$|R
40|$|Application {{of various}} {{geomagnetic}} <b>data</b> to <b>restoration</b> of the heliospheric current sheet configuration {{in the past}} is discussed. Technique for such a restoration is proposed based on analysis of information on the interplanetary magnetic field polarity inferred from diurnal variation of the geomagnetic field in polar regions outer solar corona pictures resulting from solar eclipse observations are concerned with the heliospheric sheet configuration. So, days of past solar eclipses must serve as a kind of reference points {{in the course of the}} heliospheric sheet reconstruction...|$|R
40|$|<b>Data</b> <b>restoration</b> and {{archiving}} {{activities for}} this project {{have resulted in the}} restoration of 100 % of the original Mariner 9 raw data set as well as many of the secondary analysis data sets. These data sets have been submitted to the Planetary Data System (PDS) Atmospheric Node, long with their PDS labels and descriptive metadata...|$|E
40|$|Coded {{aperture}} {{imaging spectrometer}} {{based on the}} concept of compressed sensing can acquire the spectral diagram of object. Coded aperture spectral <b>data</b> <b>restoration</b> reconstructs three-dimensional data cube from two-dimensional coded image. The two-step iterative shrinkage/thresholding algorithms were derived from the iterative shrinkage threshold algorithm and weighted iterative shrinkage algorithm. Recovering coded aperture spectral data using the two-step iterative shrinkage/thresholding algorithms obtained the three-dimensional spectral data cube successfully...|$|E
40|$|The Acquisition and Curation Office at JSC has {{undertaken}} a 4 -year <b>data</b> <b>restoration</b> project effort for the lunar science community {{funded by the}} LASER program (Lunar Advanced Science and Exploration Research) to digitize photographs of the Apollo lunar rock samples and create high resolution digital images. These sample photographs are not easily accessible outside of JSC, and currently exist only on degradable film in the Curation Data Storage Facilit...|$|E
5000|$|Bare-metal restore is a {{technique}} {{in the field of}} <b>data</b> recovery and <b>restoration</b> where the backed up data is available in a form which allows one to restore a computer system from [...] "bare metal", i.e. without any requirements as to previously installed software or operating system.|$|R
25|$|There {{is further}} {{complication}} in that restoration ecologists {{who want to}} collect large scale <b>data</b> on <b>restoration</b> projects can face enormous hurdles in obtaining the data. Managers vary in how much data they collect, and how many records they keep. Some agencies keep {{only a handful of}} physical copies of data that make it difficult for the researcher to access. Many restoration projects are limited by time and money, so data collection and record keeping are not always feasible. However, this limits the ability of scientists to analyze restoration projects and give recommendations based on empirical data.|$|R
40|$|International audienceMemory {{expansions}} are classical {{means to}} extract parallelism from imperative programs. However, current techniques require some run-time mechanism to restore data flow when expansion maps two definitions reaching the same use to two different memory locations (e. g., phi {{functions in the}} SSA framework). This paper presents an expansion framework for any type of data structure in any imperative program, {{without the need for}} dynamic <b>data</b> flow <b>restoration.</b> The key idea is to group together definitions that reach a common use. We show that such an expansion boils down to mapping each group to a memory cell...|$|R
30|$|Hamrani et al. [11] use the radial basis {{function}} as the basic interpolation function {{to carry out the}} <b>data</b> <b>restoration</b> in WSN. Li et al. [12] propose a kd-tree based K-nearest neighbor (KNN) <b>data</b> <b>restoration</b> algorithm that uses weighted variance and weighted Euclidean distance to construct a binary search tree for k-dimensional non-missing data. The size of the weight is inversely proportional to the amount of data loss of the indicator and is proportional to the variance of the indicator. For time-dependent sampling jitter, Rahm et al. [13] aim at eliminating the non-uniform sampling time series and propose to eliminate the data error by using linear interpolation. During the execution of the algorithm, the linear function is calculated by intercepting the two previous and subsequent data of the problem data points in the time series, and the target data points are expected to obtain an estimate close to the true value at the correct sampling time. The inaccuracy of data due to node sampling jitter is eliminated with regular sampling of WSN datasets.|$|E
40|$|In this paper, {{a highly}} {{effective}} parallel filter for visual <b>data</b> <b>restoration</b> is presented. The filter is designed following a skeletal approach, using a newly proposed stencil-reduce, {{and has been}} implemented {{by way of the}} FastFlow parallel programming library. As a result of its high-level design, it is possible to run the filter seamlessly on a multicore machine, on multi-GPGPUs, or on both. The design and implementation of the filter are discussed, and an experimental evaluation is presented...|$|E
40|$|RFID {{is gaining}} {{significant}} thrust as the preferred choice of automatic identification {{and data collection}} system. However, there are various data processing and management problems such as missed readings and duplicate readings which hinder wide scale adoption of RFID systems. To this end we propose an approach that filters the captured data including both noise removal and duplicate elimination. Experimental results demonstrate that the proposed approach improves missed <b>data</b> <b>restoration</b> process {{when compared with the}} existing method. <br /...|$|E
5000|$|There {{is further}} {{complication}} in that restoration ecologists {{who want to}} collect large scale <b>data</b> on <b>restoration</b> projects can face enormous hurdles in obtaining the data. Managers vary in how much data they collect, and how many records they keep. Some agencies keep {{only a handful of}} physical copies of data that make it difficult for the researcher to access. Many restoration projects are limited by time and money, so data collection and record keeping are not always feasible. However, this limits the ability of scientists to analyze restoration projects and give recommendations based on empirical data.|$|R
40|$|A {{variety of}} {{esthetic}} restorative materials {{are available for}} restoring primary incisors. Each has distinct advantages and disadvantages and the clinical conditions of placement may be a strong determining factor so as to which material is utilized. Full coronal restoration of primary incisors may be indicated {{for a number of}} reasons. Crowns available for restoration of primary incisors include those that are directly bonded to the tooth which generally are made up of a resin material, and those crowns that are luted onto the tooth. This paper reviews the published <b>data</b> on <b>restorations</b> of primary anterior teeth and various forms of full coronal restorations for the same...|$|R
30|$|In conclusion, we {{determined}} that miR- 139 - 5 p is downregulated in CRC {{and appears to}} be a prognostic factor for CRC, and miR- 139 - 5 p inhibits CRC invasion and metastasis by targeting AMFR and NOTCH 1. These <b>data</b> suggest that <b>restoration</b> of miR- 139 - 5 p may be a promising therapeutic strategy for anti-metastasis treatment of CRC.|$|R
40|$|This paper {{presents}} adaptive subspace-based inverse projections via division into multiple sub-problems (ASIP-DIMS) {{for missing}} image <b>data</b> <b>restoration.</b> In the proposed method, a target problem for estimating missing image data {{is divided into}} multiple sub-problems, and each sub-problem is iteratively solved with constraints of other known image data. By projection into a subspace model of image patches, the solution of each subproblem is calculated, where we call this procedure “subspacebased inverse projection” for simplicity. The proposed method can use higher-dimensional subspaces for finding unique solutions in each sub-problem, and successful restoration becomes feasible since {{a high level of}} image representation performance can be preserved. This is the biggest contribution of this paper. Furthermore, the proposed method generates several subspaces from known training examples and enables derivation of a new criterion in the above framework to adaptively select the optimal subspace for each target patch. In this way, the proposed method realizes missing image <b>data</b> <b>restoration</b> using ASIP-DIMS. Since our method can estimate any kind of missing image data, its potential in two image restoration tasks, image inpainting and super-resolution, based on several methods for multivariate analysis is also shown in this paper...|$|E
40|$|This is {{an update}} of the {{progress}} of a 4 -year <b>data</b> <b>restoration</b> project effort funded by the LASER program to digitize photographs of the Apollo lunar rock samples and create high resolution digital images and undertaken by the Astromaterials Acquisition and Curation Office at JSC [1]. The project is currently in its last year of funding. We also provide {{an update on the}} derived products that make use of the digitized photos including the Lunar Sample Catalog and Photo Database[2], Apollo Sample data files for GoogleMoon[3]...|$|E
40|$|The {{objectives}} of satellites HISPASAT are oriented towards the search to satisfy necessities {{derived from the}} transport of television and radio signals. It tries the supplying of a basic and safe support of communications for the defence and security of the national territory, {{the creation of an}} infrastructure of channels for official networks, routes of <b>data,</b> <b>restoration</b> of connections, rural telephony. Also is wanted to foment the provision of television channels for the Hispanic community in the south and center of America and the broadcasting of services of television for people in general...|$|E
40|$|New Environmental Microbiology Lab Launched at WRRC, Source Water Assessment Project Wrapping Up, Neighbor Island Drinking Water Quality Assessment, Oahu Aquifers Generally OK, but Urban Streams Are Substantially Degraded, USGS Report Shows, Upcoming Conferences and Meetings, WRRC Participates in Ocean Radar Project, Shanghai Environmental Delegation Visits Honolulu, Statewide Watershed Project: Background <b>Data</b> for Watershed <b>Restoration</b> Plans, WRRC Faculty Helps State Science Fair Participan...|$|R
40|$|We propose data {{structures}} preparing {{shortest path}} routing, such as OSPF or IS-IS, for link failure. Each router can in constant time determine an outgoing link on a shortest {{path to a}} destination avoiding any given failed link. This is used to avoid inconsistent forwarding in the period where router tables are updated following a linkfailure. Keywords: OSPF, IS-IS, link-failure, <b>restoration,</b> <b>data</b> structures, routing...|$|R
40|$|Abstract—In this paper, {{the problem}} of {{denoising}} and occlusion restoration of 3 D range data based on dictionary learning and sparse representation methods for image denoising is explored. We apply these techniques after converting the noisy 3 D surface into one or more images. We present experimental results on the proposed approaches. Index Terms—Sparse modeling, range <b>data</b> denoising, occlusion <b>restoration,</b> range <b>data</b> resolution enhancement. I...|$|R
40|$|The hidden Markov chains (HMC), {{which are}} widely used in {{different}} <b>data</b> <b>restoration</b> problems, have recently been generalised to pairwise partially Markov chains (PPMC), in which {{the distribution of the}} observed chain conditional on the hidden one is of any form. In particular, longmemory noise cases can be dealt with. The aim {{of this paper is to}} propose a parameter estimation method and to show, via experiments, that unsupervised PPMC based image segmentation can perform better, when the noise is a long-memory one, than the classical HMC based methods...|$|E
40|$|Restoration {{of image}} data {{has become an}} {{essential}} part of the processing of medical images obtained by any system. The same applies in the case of optical coherence tomography. The aim of this work is to study the first restoration methods. Second, the description of the data representation from optical coherence tomography and subsequent discussions that restoration methods based on deconvolution would potentially find application in processing of Optical coherence tomography. Finally, the third to create a program solution of the OCT <b>data</b> <b>restoration</b> process in MATLAB environment and followed by discussion of effectiveness of the presented solutions...|$|E
40|$|<b>Data</b> <b>restoration</b> and {{archiving}} {{activities for}} this project {{have resulted in the}} restoration of 100 % of the original Mariner 9 raw data set as well as many of the secondary analysis data sets. These data sets have been submitted to the Planetary Data System (PDS) Atmospheric Node, along with their PDS labels and descriptive metadata. In addition, a useful visualization and analysis tool has also been developed which allows the user to compare these Mariner 1971 Ultraviolet spectral data with several choices of related data sets: Mariner 9 images, USGS geologic data, MGS MOLA topography, Viking images (Viking MDIM) and thermal inertia data (MGS TES) ...|$|E
40|$|International audienceMemory {{expansions}} are classical {{means to}} extract parallelism from imperative programs. However, for dynamic control programs with general memory accesses, such transformations either fail or require some run-time mechanism {{to restore the}} data flow. This paper presents an expansion framework for any type of data structure in any imperative program, {{without the need for}} dynamic <b>data</b> flow <b>restoration.</b> The key idea is to group together the write operations that participate in the flow of the same datum. We show that such an expansion boils down to mapping each group to a single memory cell. We give a practical algorithm for code transformation. This algorithm, however, is valid for (possibly non-affine) loops over arrays only...|$|R
40|$|This {{graduate}} project {{describes the}} analysis and design of a microprocessor control system for UHF television transmitters. The controller is designed specifically for the transmitter facility of KWHY-TV at Mount Wilson, California. Hardware includes a single-board computer, video display, printer, power supply, and the appropriate supplementary I/ 0 and interfacing. Software is written in Intel 8080 assembly mnemonics, with additional Z 80 instructions inserted to utilize Mode 2 interrupt structure. Code resides in 8 K of EPROM, with data storage provided by lK of RAM. System features include automatic logging of meter <b>data,</b> post-fault <b>restoration</b> of carriers, and continuous monitoring of selected transmitter parameters. A diagnostic software mode is provided to assist in performance of routine transmitter maintenance...|$|R
50|$|In {{addition}} to simplified definition of data forms, reports and procedures, DataEase for DOS provided facilities for defining an application's user access, navigational menus, multi-format importing {{of data from}} other sources, data exporting, <b>data</b> backup and <b>restoration,</b> system documentation and user help, backing up and restoring data and integrating external programs into the application. DataEase for DOS applications provided record-level locking meaning they could be accessed simultaneously by many other users.|$|R
