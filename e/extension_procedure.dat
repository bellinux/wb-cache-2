78|273|Public
50|$|Russia met its treaty {{obligations}} by destroying 1% of its chemical agents by the Chemical Weapons Convention's 2002 deadline, but requested technical and financial assistance and extensions on the deadlines of 2004 and 2007 {{due to the}} environmental challenges of chemical disposal. This <b>extension</b> <b>procedure</b> {{spelled out in the}} treaty has been utilized by other countries, including the United States. The extended deadline for complete destruction (April 2012) was not met. As of October 2011, Russia has destroyed 57% of its stockpile. Russia also destroyed all of its declared Category 2 (10,616 MTs) and Category 3 chemicals.|$|E
5000|$|The {{original}} {{commitment in}} Phase III required all countries to have 45 {{percent of the}} chemical stockpiles destroyed by April 2004. Anticipating the failure to meet this deadline, the Bush administration in September 2003 requested a new deadline of December 2007 for Phase III and announced a probable need for an extension until April 2012 for Phase IV, total destruction (requests for deadline extensions cannot formally be made until 12 months before the original deadline). This <b>extension</b> <b>procedure</b> {{spelled out in the}} treaty has been utilized by other countries, including Russia and the unnamed [...] "state party". Although April 2012 is the latest date allowed by the treaty, the U.S. also noted that this deadline may not be met due to environmental challenges and the U.S. decision to destroy leaking individual chemical shells before bulk storage chemical weapons.|$|E
30|$|Application of {{the phase}} <b>extension</b> <b>procedure</b> {{in this study}} is used to extend the phases to the highest {{resolution}} available from the X-ray data.|$|E
40|$|Three ARIMA {{forecast}} <b>extension</b> <b>procedures</b> for Census Bureau X- 11 concurrent seasona adjustment were empirically tested. Forecasts {{were obtained}} from fitted seasonal ARIMA models augmented with regression terms for ouffiers, trading day effects, and Easter effects. Revisions between initia 1 and fina seasonaIIy adjusted vaIues were computed. Ranked ANOVAs were used on various revision measures to determine the statistical significance {{of the differences between}} the <b>extension</b> <b>procedures.</b> The main concIusion was that extending the series with enough forecasts to apply a symmetric filter reduced the revisions over not extending the series and using asymmetric filters. This resuIt heId whether the mode 1 used was one carefully fit by the anaIyst or was a SimpIerJefauIt model. Extension of the series with only one year of forecasts was also examined...|$|R
40|$|Domain Decomposition (DD) is {{not only}} the basic tool for data {{partitioning}} but also a successful technique for constructing new parallel pde solvers. The efficiency of the solver essentially depends on the preconditioner. In the present paper, we consider finite element (f. e.) schemes approximating plane, symmetric, second-order elliptic boundary value problems (b. v. p.). We derive and analyse socalled Dirichlet DD preconditioners based on the non-overlapping DD, modified Schur-complement preconditioners, local multigrid methods and hierarchical <b>extension</b> <b>procedures.</b> The crucial point is the combination of the almost norm-preserving and quite cheap hierarchical <b>extension</b> <b>procedures</b> with local multigrid. The symmetric multiplicative version of the preconditioning algorithm seems to be especially well suited for this approach. The numerical experiments carried out on various multiprocessor systems confirm the high efficiency of the parallel DD solvers proposed. Keywords : Boundary value [...] ...|$|R
50|$|The {{objective}} of this International Standard {{is to provide a}} clear procedure for the description of digital geographic data-sets so that users will be able to determine whether the data in a holding will be of use to them and how to access the data. By establishing a common set of metadata terminology, definitions and <b>extension</b> <b>procedures,</b> this standard promotes the proper use and effective retrieval of geographic data.|$|R
40|$|We {{show that}} there are six {{different}} choice of tensor product of supersymmetric N=(1, 1) spectral data {{in the context of}} supersymmetric quantum theory and noncommutative geometry. We also show that the procedure of extending a supersymmetric N= 1 spectral data to N=(1, 1) spectral data respects only one tensor product among these. We refer this as the multiplicativity property of the <b>extension</b> <b>procedure.</b> Therefore, if we demand that the <b>extension</b> <b>procedure</b> is multiplicative then there is a unique choice of tensor product of N=(1, 1) spectral data. Comment: Substantially improved version. Section (2) rewritten. Main theorem [3. 13] in Section (3) strengthen. Abstract changed accordingl...|$|E
3000|$|... is countably additive, and so {{it defines}} a measure with the domain in the {{semi-ring}} ℛ. Using the Carathéodory <b>extension</b> <b>procedure</b> (see, for instance, Section 9.4 in [30]), we get that η can be extended to the σ-algebra of measurable sets {{with respect to the}} outer measure defined by [...]...|$|E
40|$|Given an n-{{dimensional}} natural Hamiltonian L on a Riemannian or pseudo-Riemannian manifold, we call "extension" of L the n+ 1 dimensional Hamiltonian $H=\frac 12 p_u^ 2 +\alpha(u) L+\beta(u) $ {{with new}} canonically conjugated coordinates $(u,p_u) $. For suitable L, the functions $\alpha$ and $\beta$ can be chosen depending on any natural number m such that H admits an extra polynomial first integral in the momenta of degree m, explicitly determined {{in the form}} of the m-th power of a differential operator applied to a certain function of coordinates and momenta. In particular, if L is maximally superintegrable (MS) then H is MS also. Therefore, the <b>extension</b> <b>procedure</b> allows the creation of new superintegrable systems from old ones. For m= 2, the extra first integral generated by the <b>extension</b> <b>procedure</b> determines a second-order symmetry operator of a Laplace-Beltrami quantization of H, modified by taking in account the curvature of the configuration manifold. The <b>extension</b> <b>procedure</b> can be applied to several Hamiltonian systems, including the three-body Calogero and Wolfes systems (without harmonic term), the Tremblay-Turbiner-Winternitz system and n-dimensional anisotropic harmonic oscillators. We propose here a short review of the known results of the theory and some previews of new ones. Comment: 4 pages. Talk presented at the International Conference on Mathematical Modeling in Physical Sciences September 1 - 5, 2013 Prague, Czech Republi...|$|E
40|$|Ontologies {{are widely}} used in text {{technology}} and artificial intelligence. The need to develop large ontologies for real-life applications provokes researchers to automate ontology <b>extension</b> <b>procedures.</b> Automatic updates without the control of a human expert can generate potential conflicts between original and new knowledge. As a consequence the resulting ontology can yield inconsistencies. We propose a procedure that models the process of adapting an ontology to new information by repairing several important types of inconsistencies...|$|R
40|$|AbstractSimultaneous rigid E-unification was {{introduced}} in 1987 by Gallier, Raatz and Snyder. It {{is used in the}} area of automated reasoning with equality in <b>extension</b> <b>procedures,</b> like the tableau method or the connection method. Many articles in this area assumed the existence of an algorithm for the simultaneous rigid E-unification problem. There were several faulty proofs of the decidability of this problem. In this paper we prove that simultaneous rigid E-unification is undecidable. As a consequence, we obtain the undecidability of the ℶ∗-fragment of intuitionistic logic with equality...|$|R
40|$|This {{document}} defines protocol <b>extensions</b> and <b>procedures</b> for BGP Provider/Customer Edge router iteration in BGP/MPLS IP VPNs. These <b>extensions</b> and <b>procedures</b> {{have the}} objective of making the usage of the BGP/MPLS IP VPN transparent to the customer network, as far as routing information is concerned. Status of This Memo This is an Internet Standards Track document. This document {{is a product of the}} Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
40|$|We {{describe}} an <b>extension</b> <b>procedure</b> for constructing new standardized time series procedures from existing ones. The approach {{is based on}} averaging over sample paths obtained by permuting path segments. Analytical and empirical results indicate that permuting improves standardized time series methods. We also propose a new standardized time series method based on maximums...|$|E
40|$|Australia has {{recently}} announced that it is to reform its patent laws to include a supplementary protection certificate <b>extension</b> <b>procedure</b> for pharmaceuticals. This paper describes why this reform is also necessary for New Zealand, by presenting evidence of effective patent life erosion {{in spite of the}} new 20 year patent term implemented in 1995. ...|$|E
40|$|We {{introduce}} {{the concept of}} parallelism in diagram geometry, we apply it to a new gluing concept that provides geometries of higher rank, we combine it with another recent <b>extension</b> <b>procedure</b> for geometries and collect many examples solving existence questions for geometries over specified diagrams. © 1994, Belgian Mathematical Society. All Rights Reserved. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|The present article {{returns to}} the new {{foundations}} of measure and integration due to the author. In this development the basic <b>extension</b> <b>procedures</b> lead from the so-called outer and inner premeasures to their unique maximal extensions. The initial version was for extended real valued set functions. In the sequel we want to achieve a major simplification, in that we develop the procedures - with no loss in the essentials - in the traditional frame of nonnegative set functions. The final section then will obtain an important extension theorem in the inner theories...|$|R
30|$|Using {{data from}} the ICTWSS Database on 25 European {{countries}} (adding Slovenia, Slovakia, Estonia, Latvia, Lithuania, the Czech Republic, Hungary, and Poland to the countries shown in Table  2) for the years 2000 – 2009, Visser (2013, p. 16) obtains a simple correlation coefficient of r[*]=[*] 0.80 between the level of employer organization (ranked as strong/medium/weak) and the bargaining coverage rate. The corresponding correlation coefficient between coverage and union density is r[*]=[*] 0.50. See also Visser (2016, pp. 9 – 11). His broader conclusion, however, is that coverage rates and employer organization move together rather than the latter causing the former. Thus, for example, both may be determined by <b>extension</b> <b>procedures.</b>|$|R
40|$|It {{is proven}} that the quadruple {{extension}} of a Lie algebra, obtained by adding two 2 -dim Lorentzian lattices, {{has to be}} a Borcherds algebra. The folding procedure is applied to the simply-laced triple extended Lie algebras, obtaining all the non-simply laced ones. Non standard <b>extension</b> <b>procedures</b> for a class of Lie algebras are proposed. It is shown that the 2 -extensions of E 8, with a dot simply linked to the Dynkin-Kac diagram of E 9, are rank 10 subalgebras of E 10. Finally the simple root systems of a set of rank 11 subalgebras of E 11, containing as sub-algebra E 10, are explicitly written...|$|R
40|$|This paper {{describes}} {{a strategy for}} {{the extension of the}} phonological lexicon in order that nonstandard forms which arise in fast speech may be processed by a speech recognition system. By way of illustration, an outline of the phonological processing of standard wordforms by the phonological parser (PhoPa) is given and then the <b>extension</b> <b>procedure</b> which is based on this phonological parser is discussed. The lexicon <b>extension</b> <b>procedure</b> has two stages: phonotactic extension which involves the introduction of additional restrictions into the phonotactic network for the standard language in the form of metarules describing phonological processes, and specialised word model construction whereby for each standard phonemic wordform a verification net which contains all variants of this standard form is compiled. The complete system serves as a phonologically oriented lexicon development tool, and its theoretical interest lies in its contribution to the field of speech variant learning. 1 Int [...] ...|$|E
40|$|The BLASTP (Basic Local Alignment Search Tool for Proteins) is {{a popular}} protein {{database}} search program. The BLASTP algorithm consists of three steps: (1) Constructing the set of neighbourhood words, (2) Scanning a database sequence for word hits, and (3) Extending a word hit. By using a reverse engineering approach, {{the architecture of the}} program that implements the algorithm is obtained and described. It was found that approximately 90 % of the program's execution time is spent doing the third step of the algorithm, extending word hits. This work describes three optimisations to the algorithm that significantly decrease the program's execution time. The optimisations are of two types: (1) Two new sequence representations that facilitate the extension step and are only used in the <b>extension</b> <b>procedure</b> and (2) A scanning procedure that restricts the number of invocations of the <b>extension</b> <b>procedure.</b> The first optim [...] ...|$|E
40|$|We {{perform a}} class of {{nonlinear}} extensions of the reparametrization algebra at arbitrary dimensions. Our extended algebras reproduce in the one-dimensional limit the well-known W-ones. We point out {{the existence of a}} family of reparametrization invariant functions for which this property is untouched by the <b>extension</b> <b>procedure.</b> This allows to calculate the improvement of the gravitational anomaly within the extended symmetry...|$|E
30|$|Unsurprisingly, {{administrative}} extension {{is often}} requested by unions in decline {{as a form}} of revitalization from above. Equivalently, the collapse of collective bargaining in New Zealand can be directly attributed to the abolition of statutory wage-fixing machinery and with it the <b>extension</b> <b>procedures</b> used to implement national awards of that nation’s Court of Arbitration. (Note that the arrangement whereby uncovered firms “orient” themselves to a collective agreement is briefly addressed below as a special case because it is not underwritten by law.) Also, as a referee reminded us, the history of the institutions of extension is that small- and medium-sized employers, and a coalition of Christian unions and parties, have pursued extension as a means of promoting self-regulation through collective bargaining and mitigate or lessen class conflict.|$|R
3000|$|... [...]. The <b>extension</b> of this <b>procedure</b> to {{a system}} with an {{arbitrary}} number of components and ports is straightforward.|$|R
40|$|Ontologies {{are widely}} used in text {{technology}} and artificial intelligence. The need to develop large ontologies for real-life applications provokes researchers to automatize ontology <b>extension</b> <b>procedures.</b> Automatic updates without the control of a human expert can generate potential conflicts between original and new knowledge. As a consequence the resulting ontology can contain inconsistencies. On the other hand, even if the information extracted from the external sources automatically {{is consistent with the}} original ontology it can be generalized unsystematically and conceptually wrong. This in turn can lead to mistakes in applications of the extended ontology. We propose an algorithm that models the process of the adaptation of an ontology to new information and regeneralizes the resulting ontology in a more intuitive way inserting additional knowledge where this is possible. ...|$|R
40|$|Texture {{analysis}} {{is an important}} characteristic for automatic visual inspection for surface and object identification from medical images and other type of images. This paper presents an application of wavelet extension and Gray level cooccurrence matrix (GLCM) for diagnosis of myocardial infarction tissue from echocardiography images. Many of applications approach have provided good result in different fields of application, but could not implemented at all when texture samples are small dimensions caused by low quality of images. Wavelet <b>extension</b> <b>procedure</b> is {{used to determine the}} frequency bands carrying the most information about the texture by decomposition images into multiple frequency bands and to form an image approximation with higher resolution. Thus, wavelet <b>extension</b> <b>procedure</b> offers the ability to robust feature extraction in images. The gray level co-occurrence matrices are computed for each sub-band. The feature vector of testing image and other feature vector as normal image classified by Mahalanobis distance to decide whether the test image is infarction or not...|$|E
40|$|We {{prove that}} any smooth Riemannian {{manifold}} of non-negative scalar curvature {{and with a}} strictly mean convex and compact boundary component can be (C^ 2) extended beyond the component to have non-negative scalar curvature and to enjoy anyone of the following three types of (new) boundary: strictly convex, totally geodesic or strictly concave. The <b>extension</b> <b>procedure</b> can be applied for instance to "positive mass" type of theorems...|$|E
40|$|The paper {{proposes to}} apply a {{combined}} measuring controller in order {{to solve a problem}} pertaining to redundancy of information transmitted from technical means which have passed  lifetime <b>extension</b> <b>procedure</b> at Atomic Power Stations (APS). The controller operates on the basis of digital and probabilistic forms of  information presentation that allows to obtain the best possible fit and combination of  accuracy, fast operation and hardware capacity.     </p...|$|E
40|$|We {{demonstrate}} {{how to handle}} equality in the inverse method using equality elimination. In the equality elimination method, proofs consist of two parts. In the first part we try to solve equations obtaining so called solution clauses. In the second part, we perform the usual sequent proof search by the inverse method. Our method is called equality elimination because we eliminate all occurrences of equality {{in the first part}} of the proof. Solution clauses are obtained by using a very strong strategy [...] basic superposition. Unlike the previous approach proposed by Maslov, we prove completeness of our method with most general substitutions and with ordering restrictions. We also note that these technique can be adapted to <b>extension</b> <b>procedures,</b> like the connection method. Unlike other approaches, we do not require the use of rigid or mixed E-unification...|$|R
40|$|AbstractA new {{approach}} to constructing generalised probabilities is proposed. It {{is based on the}} models using lower and upper previsions, or equivalently, convex sets of probability measures. Our approach uses sets of Markov operators in the role of rules preserving desirability of gambles. The main motivation being the operators of conditional expectations which are usually assumed to reduce riskiness of gambles. Imprecise probability models are then obtained in the ways to be consistent with those desirability preserving rules. The consistency criteria are based on the existing interpretations of models using imprecise probabilities. The classical models based on lower and upper previsions are shown to be a special class of the generalised models. Further, we generalise some standard <b>extension</b> <b>procedures,</b> including the marginal extension and independent products, which can be defined independently of the existing procedures known for standard models...|$|R
40|$|Simultaneous rigid E-unification {{has been}} {{introduced}} {{in the area of}} theorem proving with equality. It is used in <b>extension</b> <b>procedures,</b> like the tableau method or the connection method. Many articles in this area tacitly assume the existence of an algorithm for simultaneous rigid E-unification. There were several faulty proofs of the decidability of this problem. In this article we prove several results about the simultaneous rigid E-unification. Two results are reductions of known problems to simultaneous rigid E-unification. Both these problems are very hard. The word equation solving (unification under associativity) is reduced to the monadic case of simultaneous rigid E-unification. The variable-bounded semi-unification problem is reduced to the general simultaneous rigid E-unification. The word equation problem used in the first reduction is known to be decidable, but the decidability result is extremely non-trivial. As for the variablebounded semi-unification, its decidability is [...] ...|$|R
40|$|This paper {{introduces}} an isometric <b>extension</b> <b>procedure</b> for Riemannian manifolds with boundary, which preserves some lower curvature {{bound and}} produces a totally geodesic boundary. As immediate applications of this construction, one obtains in particular upper volume bounds, an upper intrinsic diameter {{bound for the}} boundary, precompactness, and a homeomorphism finiteness theorem for certain classes of manifolds with boundary, {{as well as a}} characterization up to homotopy of Gromov–Hausdorff limits of such a class...|$|E
40|$|The BLASTP (Basic Local Alignment Search Tool for Proteins) is {{a popular}} protein {{database}} search program. The BLASTP algorithm consists of three steps: (1) Constructing the set of neighbourhood words, (2) Scanning a database sequence for word hits, and (3) Extending a word hit. By using a reverse engineering approach, {{the architecture of the}} program that implements the algorithm is obtained and described. It was found that approximately 90 % of the program's execution time is spent doing the third step of the algorithm, extending word hits. This work describes three optimisations to the algorithm that significantly decrease the program's execution time. The optimisations are of two types: (1) Two new sequence representations that facilitate the extension step and are only used in the <b>extension</b> <b>procedure</b> and (2) A scanning procedure that restricts the number of invocations of the <b>extension</b> <b>procedure.</b> The first optimisation represents the query as a sequence of memory addresses. These addresses are those of the rows of the residue pair score matrix which correspond to a particular residue. This representation reduces the number of instructions executed per matrix access. The second optimisation represents the query and database sequence as a sequence of residue-doublets. A doublet consists of two adjacent residues. Extensions are done in steps of aligned residue-doublet pairs. The third optimisation counts the number of word hits per aligned segments of the query and database sequence. The <b>extension</b> <b>procedure</b> is invoked only if the number of hits per alignment meets a threshold criteria. Each optimised algorithm is implemented in the BLASTP version 1. 4 program. A comparison of performance data between each of the optimised programs and the unmodified program shows a performance increase of 15 %, 48 % and 63 % respectively...|$|E
40|$|This paper surveys topologies, called {{admissible}} group topologies, of {{the full}} group of self-homeomorphisms of a Tychonoff space, which yield continuity of both the group operations {{and at the same}} time provide continuity of the evaluation function or, in other words, make the evaluation function a group action of on. By means of a compact <b>extension</b> <b>procedure,</b> beyond local compactness and in two essentially different cases of rim-compactness, we show that the complete upper-semilattice of all admissible group topologies on admits a least element, that can be described simply as a set-open topology and contemporaneously as a uniform topology. But, then, carrying on another efficient way to produce admissible group topologies in substitution of, or in parallel with, the compact <b>extension</b> <b>procedure,</b> we show that rim-compactness is not a necessary condition for the existence of the least admissible group topology. Finally, we give necessary and sufficient conditions for the topology of uniform convergence on the bounded sets of a local proximity space to be an admissible group topology. Also, we cite that local compactness of is not a necessary condition for the compact-open topology to be an admissible group topology of...|$|E
40|$|We {{study the}} problem of quadruple {{extensions}} of simple Lie algebras. We find that, adding a new simple root + 4, {{it is not possible}} to have an extended Kac-Moody algebra described by a Dynkin-Kac diagram with simple links and no loops between the dots, while it is possible if + 4 is a Borcherds imaginary simple root. We also comment on the root lattices of these new algebras. The folding procedure is applied to the simply laced triple extended Lie algebras, obtaining all the non- simply laced ones. Nonstandard <b>extension</b> <b>procedures</b> for a class of Lie algebras are proposed. It is shown that the two-extensions of E 8, with a dot simply linked to the Dynkin-Kac diagram of E 9, are rank 10 subalgebras of E 10. Finally the simple root systems of a set of rank 11 subalgebras of E 11, containing as sub-algebra E 10, are explicitly written...|$|R
40|$|Simultaneous rigid E-unification {{has been}} {{introduced}} {{in the area of}} theorem proving with equality. It is used in <b>extension</b> <b>procedures,</b> like the tableau method or the connection method. Many articles in this area assume the existence of an algorithm for simultaneous rigid E-unification. There were several faulty proofs of the decidability of this problem. In this paper we prove that simultaneous rigid E-unification is undecidable. As a consequence we obtain the undecidability of the 9 -fragment of intuitionistic logic with equality. 1 Introduction Simultaneous rigid E-unification plays a crucial role in extending to first order languages with equality automatic proof methods based on sequent calculi, such as semantic tableaux [Fitting 88], the connection method [Bibel 82] (also known as the mating method [Andrews 81]), model elimination [Loveland 68] and a dozen other procedures. The usability of simultaneous rigid E-unification has been explained in [Bibel 87, GaRaSn 87]. Since [...] ...|$|R
5000|$|In the {{immediate}} future, <b>extension</b> of these <b>procedures</b> to {{systems that are}} infinite and periodic {{in one or more}} dimensions (polymers, slabs, nanotubes, solids), and to electronic transport.|$|R
