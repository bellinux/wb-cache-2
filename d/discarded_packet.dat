2|476|Public
50|$|IP header {{and first}} 64 {{bits of the}} {{original}} payload are used by the source host to match the time exceeded message to the discarded datagram. For higher level protocols such as UDP and TCP the 64 bit payload will include the source and destination ports of the <b>discarded</b> <b>packet.</b>|$|E
40|$|This paper {{proposes a}} hybrid medium access {{protocol}} named orthogonal coded {{medium access control}} (OrMAC), which extends the principle of distributed queuing collision avoidance protocol (DQCA) of {{wireless local area network}} (WLAN) to delay-sensitive machine-to-machine (M 2 M) networks. OrMAC pre-assigns orthogonal codes, which serve as the channel contention signals, to the nodes entering the network. The “pre-assignment” eliminates contention collisions since it guarantees that no two nodes share the same contention code. Moreover, OrMAC employs a prioritized channel access by allowing nodes to control the transmission power of the contention signal depending on the delay sensitivity of the data. The power at which a contention signal arrives at the access point reflects the urgency of the packets waiting for transmission in the buffer. A contention signal with a high received power is assigned a high priority and vice versa for a contention signal with a low received power. Numerical experiments are carried out to compare the performance of OrMAC to that of DQCA in terms of the packet delivery ratio, latency, <b>discarded</b> <b>packet</b> ratio, and throughput. The results show that OrMAC can outperform DQCA in all the aforementioned performance metrics...|$|E
30|$|<b>Discarded</b> <b>packets</b> {{detected}} in each interface, due to router congestion or link failure.|$|R
40|$|During network congestion, Internet routers <b>discard</b> {{or accept}} <b>packets</b> without any {{regard to the}} impact the <b>discarded</b> <b>packets</b> might have on the {{applications}} or the level of usefulness accepted packets might bring to the applications. Such indiscriminate <b>packet</b> <b>discarding</b> leads to less than desirable performance for the network and the network applications, especially when both multimedia and data communication applications share the same networking resources. The authors have previously proposed a bandwidth threshold based <b>packet</b> <b>discarding</b> algorithm which, instead of accepting packets at any rate during congestion, <b>discards</b> <b>packets</b> {{based on a minimum}} bandwidth threshold. If the router is unable to meet the minimum bandwidth requirement of an application, all packets from the application are dropped until more bandwidth is available. This paper presents simulation results of the bandwidth threshold based <b>packet</b> <b>discarding</b> algorithm. The results confirm the earlier claims that the proposed algorithm can eliminate "useless" packet forwarding for multimedia applications during congestion and improve the performance of data communication applications. 1...|$|R
50|$|Prior to its deprecation, the Type of Service {{field was}} defined as follows.Precedence was a 3 bit field which treats high {{priority}} packets as more important than other packets.If a router is congested and needs to <b>discard</b> some <b>packets,</b> it will <b>discard</b> <b>packets</b> having lowest priority first. Although precedence field was part of version 4, it was never used.|$|R
5000|$|Most {{firewalls}} (and routers {{for household}} use) can be configured to silently <b>discard</b> <b>packets</b> addressed to forbidden hosts or ports, resulting in small or large [...] "black holes" [...] in the network.|$|R
40|$|Networked {{applications}} require {{good performance}} from the network {{along with a}} high level of predictability. One of the factors that affects application performance is the packet dropping policy adopted in the switch or router. In this paper, we evaluate the absolute performance of various packet dropping policies, and also the predictability they can provide to an application. The packet dropping schemes studied are the Partial <b>Packet</b> <b>Discard</b> (PPD), Early <b>Packet</b> <b>Discard</b> (EPD), Age Priority <b>Packet</b> <b>Discarding</b> (APPD) and the Preemptive Partial <b>Packet</b> <b>Discard</b> (pPPD). Results are provided in multihop networks for different traffic types, including IP over ATM trace data...|$|R
50|$|AIMD {{requires}} a binary signal of congestion. Most frequently, packet loss {{serves as the}} signal; the multiplicative decrease is triggered when a timeout or acknowledgement message indicates a packet was lost. It is also possible for in-network mechanisms to mark congestion (without <b>discarding</b> <b>packets)</b> as in Explicit Congestion Notification (ECN).|$|R
40|$|We {{investigate}} <b>packet</b> <b>discarding</b> {{schemes for}} TCP over ATM with UBR service. In doing so, {{we tested the}} effective throughput of two existing schemes, Partial <b>Packet</b> <b>Discard</b> (PPD) and Early <b>Packet</b> <b>Discard</b> (EPD), {{as compared to the}} Random Cell Discard (RCD) scheme which discards any incoming cells after buffer overflow. We observed that PPD alleviates the effect of packet fragmentation so that it gets effective throughput enhancement over RCD, and EPD provides further enhancement over PPD. After closer investigation, we found that there is a sustained congestion problem other than packet fragmentation that causes the effective throughput to be degraded. We noted that sustained congestion resulted in the synchronization of TCP window expansion and shrinkage. Toprovide a solution for this problem, we propose the Early Selective <b>Packet</b> <b>Discard</b> (ESPD) policy, a strategy which makes sessions take turns in accessing network capacity by <b>discarding</b> <b>packets</b> from selected sessions rather than randomly. Our results shows that ESPD achieves throughput and fairness enhancement over EPD with only a modest increase in implementation complexity...|$|R
40|$|The {{performance}} {{analyses of}} selective packet dropping policies have usually been performed using homogeneous traffic sources and under one node scenarios. In this paper we focus our attention {{not only to}} heterogeneous sources but also heterogeneous environments. We present simulation results of application level performance for heterogeneous traffic sources under three different packet dropping schemes: Partial <b>Packet</b> <b>Discard</b> (PPD), Early <b>Packet</b> <b>Discard</b> (EPD), and Preemptive Partial <b>Packet</b> <b>Discard</b> (pPPD). In addition, we also present simulation results for homogeneous sources over multi-hop networks with heterogeneous packet dropping policies...|$|R
40|$|Previous {{papers have}} {{described}} and evaluated theperformance of the Early <b>Packet</b> <b>Discard</b> techniquefor maintaining <b>packet</b> integrity during overload inATM switches. In this paper a <b>packet</b> <b>discard</b> scheme is proposedwith the goal to provide both good performance interms of throughput and fairness {{in terms of}} band-width exploitation of the output link among all vir-tual circuits. In the scenarios here considered, theproposed discard scheme is shown to provide verygood results and to represent therefore a remarkableimprovement of the classical Early <b>Packet</b> <b>Discard.</b> Numerical results are reported and discussed forcomparing these two discarding schemes under dif-ferent operating conditions...|$|R
50|$|A {{negative}} {{side effect of}} the capture effect would be the idle time created due to stations backing off. Once one station is finished transmitting on the medium, large idle times are present because all other stations were continually backing off. In some instances, back-off can occur {{for so long that}} some stations actually <b>discard</b> <b>packets</b> because maximum attempt limits have been reached.|$|R
40|$|Under {{conditions}} of heavy traffic load or sudden traffic bursts, the peak processing throughput of network intrusion detection systems (NIDS) {{may not be}} sufficient for inspecting all monitored traffic, and the packet capturing subsystem inevitably drops excess arriving packets before delivering them to the NIDS. This impedes the detection ability {{of the system and}} leads to missed attacks. In this work we present selective <b>packet</b> <b>discarding,</b> a best effort approach that enables the NIDS to anticipate overload conditions and minimize their impact on attack detection. Instead of letting the packet capturing subsystem randomly drop arriving packets, the NIDS proactively <b>discards</b> <b>packets</b> that are less likely to affect its detection accuracy, and focuses on the traffic at the early stages of each network flow. We present the design of selective <b>packet</b> <b>discarding</b> and its implementation in Snort NIDS. Our experiments show that selective <b>packet</b> <b>discarding</b> significantly improves the detection accuracy of Snort under increased traffic load, allowing it to detect attacks that would have otherwise been missed...|$|R
40|$|Tree-based {{reliable}} multicast protocols provide scalability by distributing error-recovery tasks {{among several}} repair nodes. These repair nodes keep in their buffers all packets {{that are likely}} to be requested by any of its receiver nodes. We address the issue of deciding how long these packets should be retained and present a buffer management scheme taking into account the fact that most packet losses happen during short error bursts. Under our scheme, receiver nodes do not normally acknowledge correctly received packets and repair nodes routinely <b>discard</b> <b>packets</b> after a reasonable time interval. Whenever a receiver node detects a transmission error, its send a negative acknowledgement to its repair node and start acknowledging up to k correctly received packets. Whenever a repair node receives a retransmission request, it stops <b>discarding</b> <b>packets</b> that have not been properly acknowledged until it has received k consecutive acknowledgements from each node that had requested a packet retransmission. 1 I...|$|R
40|$|Selective <b>packet</b> <b>discarding</b> schemes have benn mostly {{developed}} and analyzed {{in the context}} of ATM networks. However, similar schemes could be applied to non-ATM or more general networks. The analysis of selective <b>packet</b> <b>discarding</b> schemes in a general packet switching environment has been limited to the basic dropping schemes, i. e., Partial <b>Packet</b> <b>Discard</b> (PPD) and Early <b>Packet</b> <b>Discard</b> (EPD), and for only the single traffic source case. In this paper, we extend the mathematical analysis of PPD and EPD for multiple sources and include simulation results to verify the analytical results. Finally, to place the performance of the generalized EPD and PPD {{in the context of}} other packet dropping schemes, we also provide simulation results of the Drop From Front (DFF), and Preemtive Partial <b>Packet</b> <b>Discard</b> (pPPD) schemes...|$|R
50|$|Then, {{the source}} {{broadcasts}} {{a batch of}} packets. Radios not on a <b>packet's</b> list <b>discard</b> the <b>packet.</b>|$|R
50|$|On network {{addresses}} is not {{a favored}} concept. Using cryptographic mechanisms most likely prevents attacks based on forged source addresses, {{under the assumption that}} the trusted repository containing all necessary credentials has not been subject to compromise in itself. These problems can be solved by conventional firewalls with corresponding rules for <b>discarding</b> <b>packets</b> at the network perimeter but will not prevent such attacks originating from inside the network policy domain.|$|R
40|$|An {{adaptive}} playout buffer {{to overcome}} jitter in VoIP is proposed. It based on forecasting {{of the future}} network state and allows maintaining the jitter buffer at the minimum level at which <b>packets</b> are not <b>discarded</b> by receiver, providing the optimal ratio {{between the amount of}} delay introduced by the jitter buffer and the number of <b>discarded</b> <b>packets.</b> The experimental results showed the fundamental possibility of predicting jitter for voice over IP networks. ????????? ?????? ??????????? ????????????? ??????? ?????? ? VoIP, ??????????? ??????? ???????? ????????? ????. ?? ????????? ???????????? ???????? ??????? ?????? ?? ??????????? ??????, ??? ??????? ??????????? ???????????? ??????? ?? ???????? ???????, ??????????? ??????????? ??????????? ????? ????????? ???????? ???????? ??????? ??????? ? ??????????? ????????????? ???????. ????????????????? ?????????? ???????? ?????????????? ??????????? ??????????????? ???????? ??? ???????? ?????? ? IP ?????...|$|R
40|$|Traffic {{clippers}} are devices which <b>discard</b> <b>packets</b> from {{a traffic}} stream as {{necessary in order}} to make the traffic stream conform to burstiness constraints. We present sample path results for traffic clippers, which bound the packet loss rates of clippers in terms of the loss rates of standard single server queues. We also demonstrate that traffic clippers in tandem can be used to enforce burstiness constraints, but such an enforcement is done in a non-optimal manner...|$|R
50|$|Sequence numbers allow {{receivers}} to <b>discard</b> duplicate <b>packets</b> {{and properly}} sequence reordered packets. Acknowledgments allow senders {{to determine when}} to retransmit lost packets.|$|R
40|$|In this paper, the {{simulation}} study of performance of packet TCP over ATM networks using NIST ATM simulator is presented. Two <b>packet</b> <b>discard</b> strategies are discussed, which alleviate {{the effects of}} fragmentation. Partial <b>packet</b> <b>discard,</b> in which remaining cells are discarded after one cell has been dropped from a packet, improves throughput somewhat. Then early <b>packet</b> <b>discard</b> is studied, a strategy that prevents fragmentation and brings throughput up to maximal levels by having the switch drop whole packets prior to buffer overflow...|$|R
40|$|Routers in IP packet-switched {{networks}} signal congestion to senders by <b>discarding</b> <b>packets.</b> Such <b>discards,</b> as a side-effect, {{are often}} the key factor determining the quality of network service perceived by users. For this reason network designers need techniques to explain, predict, and control the <b>packet</b> <b>discard</b> rate. This thesis explains the discard rate for TCP traffic {{in terms of the}} interaction between load and capacity. The key insights are that load should be measured as the number of senders actively competing for a bottleneck link, and capacity as the total network buffering available to those senders. The thesis shows how to predict discard rates using these measures. It also proposes a new queuing method that can limit the discard rate over a wide range of loads...|$|R
40|$|Tree-based {{reliable}} multicast protocols provide scalability by distributing error-recovery tasks {{among several}} repair nodes. These repair nodes integrate the status information of their receiver nodes and perform local error recovery for these nodes using the data stored in their buffers. NAKbased error control schemes provide scalable solution by shifting error detection tasks from the repair node to each receiver node. However, they provide no efficient mechanism to safely <b>discard</b> <b>packets</b> from the repair node buffers. This leaves the repair nodes with a difficult choice. They can {{err on the}} safety side and keep in their buffer packets {{that have already been}} correctly received by all nodes. Conversely, they can <b>discard</b> <b>packets</b> without knowing if they are still needed. Receiver nodes must then obtain these packets from their upper-stream repair node, which could result in a NAK implosion at these upperstream repair nodes and a much slower repair process. We propose an efficient retransmission control scheme without all the disadvantages of previous schemes. Under our scheme, most of additional retransmissions are performed within a local group. This feature satisfies the original goal of tree-based protocol. Simulation results indicate our scheme significantly reduces NAK implosion and provides fast recovery of transmission error. 1 I...|$|R
40|$|Abstract: In a {{traditional}} network stack, data is transmitted {{in the order}} that it is received. An algorithm is proposed where priority of packets and expiry times {{is used by the}} transport layer to reorder or <b>discard</b> <b>packets</b> to optimise the use of available bandwidth. This scheme is implemented and compared to unmodified Datagram Congestion Control Protocol (DCCP) using traffic modelled on video conferencing software. The results show improvement can be made during periods of congestion –more audio packets arrive on time and inmany cases video packet arrival rates also increase...|$|R
30|$|A {{transition}} from sub-chain 2 to sub-chain 1 happens once an isolated packet loss instance preceded by gmin successfully received packets is detected. Clark [5] developed an efficient packet loss driven algorithm that enables to calibrate at run-time the proposed model. A set of metrics can be extracted from Clark model {{at the end}} of a monitoring period, e.g., PLR during gap and bursty loss periods and their corresponding durations. As depicted in Figure S 4, Additional file 1, Clark accounted for the effect of <b>discarded</b> <b>packets</b> at the de-jittering buffer caused by late arrivals.|$|R
40|$|Secure {{scalable}} streaming (SSS) enables low-complexity, high-quality transcoding at intermediate, possibly untrusted, {{network nodes}} without compromising the end-to-end {{security of the}} system [1, 2]. SSS encodes, encrypts, and packetizes video into secure scalable packets {{in a manner that}} allows downstream transcoders to perform transcoding operations such as bitrate reduction and spatial downsampling by simply truncating or <b>discarding</b> <b>packets,</b> and without decrypting the data. Secure scalable packets have unencrypted headers that provide hints such as optimal truncation points to downstream transcoders. Using these hints, downstream transcoders can perform near-optimal secure transcoding...|$|R
30|$|At the MAC layer, the {{playback}} {{information can}} be estimated based on the feedback information from the clients. Considering the estimated playback information and the packet priority, we can calculate the importance of each packet. Based on the packet importance and the feedback CQIs (channel quality indicator), different RBs are assigned to different clients to maximize the system performance. We build a “ACK reconstruction module” to reconstruct the received ACK for concealing the <b>discarded</b> <b>packets</b> at the MAC layer. It depends on the received ACK information from the “ACK sending window” at the client and the packet scheduling strategy at the MAC layer. When we consider the packet utility during the resource allocation to maximize the sum utility of the scheduled packets, some packets with little utility will be discarded instead of wasting lots of time for their arrival at the client. The ACK of these <b>discarded</b> <b>packets</b> will be constructed and integrated with the received ACKs by the “ACK reconstruction module” and then sent to the “ACK receiving window” at the TCP layer. And thus, the dropped packets at the MAC layer are concealed during the TCP flow. In addition, at the MAC layer of eNodeB, {{we focus on the}} estimation of the playback time that the packets in MAC queue can support by using the estimated buffer status and the predicted transmission rate.|$|R
40|$|Higher bandwidths in {{computer}} networks have made application with real-time constraints, such as control, command, and interactive voice and video communication feasible. We describe two congestion control mechanisms that utilize properties of real-time applications. First, many real-time applications, such as voice and video, can tolerate some loss due to signal redundancy. We propose and analyze a congestion control algorithm {{that aims to}} <b>discard</b> <b>packets</b> if they stand little chance of reaching their destination in time as early on their path as possible. Dropping late and almost-late packets improves the likelihood that other packets will make their deadline. Secondly, in real-time sys [...] ...|$|R
30|$|If a node, {{which is}} neither {{in the target}} group { 6, 13, 10 } nor in the initial PS, {{receives}} the multicast packet (i.e., 5, 12), it should <b>discard</b> the <b>packet</b> directly.|$|R
5000|$|BCP 84 {{recommends}} that upstream providers of IP connectivity filter packets entering their networks from downstream customers, and <b>discard</b> any <b>packets</b> {{which have a}} source address which is not allocated to that customer.|$|R
40|$|Media {{delivery}} over packet networks {{is often}} plagued by packet losses which limit its utility to end users. Forward Error Correction (FEC) based techniques {{are important for}} overcoming this problem. This paper further develops an FEC-based technique [1] to maximize the expected received media quality by jointly choosing which packets to send and which packets to protect- including <b>discarding</b> <b>packets</b> to make additional room for protection. We describe a straight-forward implementation leveraging existing FEC system components. Comprehensive experiments demonstrate that significant gains inPSNR of several dB are achieved when sending H. 264 /MPEG- 4 AVC coded video over a packet erasure channel. Index Terms- Video streaming, forward error correction, FEC 1...|$|R
40|$|This paper {{presents}} a policy for guaranteeing or supporting voice ser-vice in converged LAN with Weighted Fair Queueing (WFQ). How {{to set the}} weight of voice traffic is related to how many voice users are served with the minimum delay in routers. This paper next presents two mech-anisms,active rerouting and selective dropping mechanisms, to cope with temporary overload condition. Active rerouting can be implemented with active network technology. Selective dropping <b>discards</b> <b>packets</b> to avoid burst losses of packets toward a certain subnet. Various simulation {{results show that the}} proposed QoS mechanisms in a converged LAN environment can offer the voice service of good quality...|$|R
40|$|The law of Conservation of Flow, {{which states}} that an input must either be absorbed or sent on as an output (possibly with modification), is an {{attractive}} tool with which to analyze network protocols for security properties. One of its uses is to detect disruptive network elements that launch Denial of Service attacks by absorbing or <b>discarding</b> <b>packets.</b> Its use requires several assumptions about the protocols being analyzed. In this paper, we examine the WATCHERS algorithm to detect misbehaving routers. We show that it uses Conservation of Flow without sufficient verification of its assumptions, and can consequently be defeated. We suggest improvements to make the use of Conservation of Flow valid...|$|R
40|$|AbstractÐHigh-speed {{local area}} {{networks}} �LANs) {{consist of a}} set of switches interconnected by point-to-point links,and hosts linked to those switches through a network interface card. High-speed LANs may change their topology due to switches being turned on/off, hot expansion,link remapping,and component failures. In these cases,a distributed reconfiguration protocol analyzes the topology, computes the new routing tables,and downloads them to the corresponding switches. Unfortunately,in most cases,user traffic is stopped during the reconfiguration process to avoid deadlock. These strategies are called static reconfiguration techniques. Although network reconfigurations are not frequent,static reconfiguration such as this may take hundreds of milliseconds to execute,thus degrading system availability significantly. Several distributed real-time applications have strict communication requirements. Distributed multimedia applications have similar,although less strict,quality of service �QoS) requirements [3],[4]. Both stopping <b>packet</b> transmission and <b>discarding</b> <b>packets</b> due to the reconfiguration process prevent the system from satisfying the above requirements. Therefore,in order to support hard real-time and distributed multimedia applications over a high-speed LAN,we need to avoid stopping user traffic and <b>discarding</b> <b>packets</b> when the topology changes. In this paper,we propose a new deadlock-free distributed reconfiguration protocol that is able to asynchronously update routing tables without stopping user traffic. This protocol is valid for any topology,including regular as well as irregular topologies. It is also valid for packet switching as well as for cut-through switching techniques and does not rely on the existence of virtual channels to work. Simulation results show that the behavior of our protocol is significantly better than for other protocols based on stopping user traffic. Index TermsÐInterconnection networks,irregular topologies,dynamic reconfiguration,deadlock avoidance,system availability. ...|$|R
40|$|In this paper, {{we propose}} a novel <b>packet</b> <b>discard</b> al- gorithm called QoS-sensitive <b>Packet</b> <b>Discard</b> (QPD) which {{considers}} the minimum QoS requirements of multimedia applications. By using network simulations, we evaluate the perceived QoS (in terms of intelligibility) {{of a real}} voice application (PCM encoded) over a IP network. Our simulation results show that QPD can improve TCP throughput without compromising the overall intelligibility of multimedia applications...|$|R
30|$|As {{mentioned}} in Section 6.2, MPMH-MRMC can better utilize MPMH than the MPMH-SRSC, {{which results in}} the decrease of delay. Compared with MPMH-SRSC, the average transmission delay of MPMH-MRMC decreases by about 74.20 % under uniform traffic and 70.91 % under random traffic with the traffic load ratio from 10 to 20. With the traffic load ratio from 10 to 20, MPMH-MRMC outperforms MPMH 2 by about 29.21 % under uniform traffic and 49.04 % under random traffic on average, respectively. The reason is identical with the one in network throughput. When the traffic load ratio is over 3, the number of <b>discarded</b> <b>packets</b> in TDMA exceeds MPMH and MPMH-SRSC, which leads to lower average delay in TDMA.|$|R
