2537|10000|Public
25|$|Second, {{for each}} <b>explanatory</b> <b>variable</b> of interest, {{one wants to}} know whether its {{estimated}} coefficient differs significantly from zero—that is, whether this particular <b>explanatory</b> <b>variable</b> in fact has explanatory power in predicting the response variable. Here the null hypothesis is that the true coefficient is zero. This hypothesis is tested by computing the coefficient's t-statistic, as {{the ratio of the}} coefficient estimate to its standard error. If the t-statistic is larger than a predetermined value, the null hypothesis is rejected and the variable is found to have explanatory power, with its coefficient significantly different from zero. Otherwise, the null hypothesis of a zero value of the true coefficient is accepted.|$|E
2500|$|Quasi-variance, used in linear {{regression}} when the <b>explanatory</b> <b>variable</b> is categorical ...|$|E
2500|$|Consider {{a linear}} model {{with more than}} a single <b>explanatory</b> <b>variable,</b> of the form ...|$|E
30|$|Many Big-Data {{researchers}} believe that, {{the larger the}} number of possible <b>explanatory</b> <b>variables,</b> the more useful is stepwise regression for selecting <b>explanatory</b> <b>variables.</b> The reality is that stepwise regression is less effective the larger the number of potential <b>explanatory</b> <b>variables.</b> Stepwise regression does not solve the Big-Data problem of too many <b>explanatory</b> <b>variables.</b> Big Data exacerbates the failings of stepwise regression.|$|R
30|$|RQ 1 {{implies that}} the results should contain many <b>explanatory</b> <b>variables</b> based on the {{measured}} metrics. However, we did not expect questions about class attitudes, Psychological Scales, and Difficulty Levels 3 and 4 (AOJ) to be included as <b>explanatory</b> <b>variables</b> because they showed low F-measures in the previous section. It is thought that these variables perform by combining with the former <b>explanatory</b> <b>variables.</b>|$|R
30|$|Suppose that a {{researcher}} has 100 possible <b>explanatory</b> <b>variables</b> {{and wants to}} choose up to 10 variables to include in a regression model. There are 19.4 trillion possible combinations to choose from. With 1000 possible <b>explanatory</b> <b>variables,</b> there are 2.66 [*]×[*] 1023 combinations of up to 10 variables. With one million possible <b>explanatory</b> <b>variables,</b> the number of possibilities grows to 2.76 [*]×[*] 1053.|$|R
2500|$|In statistics, linear {{regression}} is a linear approach for modeling {{the relationship between}} a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one <b>explanatory</b> <b>variable</b> is called simple {{linear regression}}. [...] For more than one <b>explanatory</b> <b>variable,</b> the process is called multiple linear regression. (This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.) ...|$|E
2500|$|... where [...] is the {{response}} variable, [...] is the <b>explanatory</b> <b>variable,</b> εi is a random error term, and [...] and [...] are parameters.|$|E
2500|$|The {{intuitive}} {{reason that}} using an additional <b>explanatory</b> <b>variable</b> cannot lower the R2 is this: Minimizing [...] {{is equivalent to}} maximizing R2. When the extra variable is included, the data always {{have the option of}} giving it an estimated coefficient of zero, leaving the predicted values and the R2 unchanged. The only way that the optimization problem will give a non-zero coefficient is if doing so improves the R2.|$|E
3000|$|... where Xkrepresents <b>explanatory</b> <b>variables</b> at {{the micro}} level, {{including}} educational attainment, income, entertainment, and cultural entertainment expenditure. Wj represents macro-level <b>explanatory</b> <b>variables,</b> such as GDP {{per capita in}} the county.|$|R
30|$|RQ 2 {{implies that}} the results should contain many <b>explanatory</b> <b>variables</b> based on the {{measured}} metrics. However, some <b>explanatory</b> <b>variables,</b> which show a low nDCG in the previous section, are included as an element of this combination. It is thought that these variables perform by combining with the former <b>explanatory</b> <b>variables.</b> Therefore, Psychological Scales and the questionnaire on class attitude are also effective in combination with metrics.|$|R
30|$|Steyerberg et al. [34] {{argue that}} {{stepwise}} models do poorly in small data sets, an argument they illustrate by applying stepwise regression to subsets of a data set with 4, 8, or 16 <b>explanatory</b> <b>variables</b> (whose estimated coefficients {{are assumed to}} be the “true” values). Derksen and Keselman [35] analyze 250 simulations of a Monte Carlo model with 12, 18, or 24 candidate <b>explanatory</b> <b>variables</b> and conclude that stepwise regression often chooses the wrong <b>explanatory</b> <b>variables.</b> Done decades ago, when computer capabilities were modest, these tests were understandably limited to a small number of <b>explanatory</b> <b>variables</b> and simulations.|$|R
2500|$|The {{expected}} value plays {{important roles in}} [...] a variety of contexts. In regression analysis, one desires a formula in terms of observed data that will give a [...] "good" [...] estimate of the parameter giving the effect of some <b>explanatory</b> <b>variable</b> upon a dependent variable. The formula will give different estimates using different samples of data, so the estimate it gives is itself a random variable. A formula is typically considered good in this context if it is an unbiased estimatorthat is, if the {{expected value}} of the estimate (the average value it would give over an arbitrarily large number of separate samples) can be shown to equal the true value of the desired parameter.|$|E
2500|$|If Huntington's imperatives are the {{independent}} variables, then the variable {{of civilian control}} becomes in turn an <b>explanatory</b> <b>variable</b> for military security. However, Huntington says that both societal imperatives, ideology and structure, are unchanging, {{at least in the}} American case. If that is the case, then the functional imperative is fully explanatory for changes in civilian control and subsequently military security. In short, if external threats are low, liberal ideology [...] "extirpates" [...] or eliminates military forces. If external threats are high, liberal ideology produces a [...] "transmutation" [...] effect that will re-create the military in accordance with liberalism, but in such a form that it will lose its [...] "peculiarly military characteristics." [...] Transmutation will work for short periods, such as to fight a war, but will not, over time, assure military security. This appears to explain well the pattern of American militarization and demobilization, at least until the initiation of the Cold War.|$|E
2500|$|The {{use of an}} {{adjusted}} R2 (one common notation is , pronounced [...] "R bar squared"; {{another is}} [...] ) {{is an attempt to}} take account of the phenomenon of the R2 automatically and spuriously increasing when extra explanatory variables are added to the model. It is a modification due to Henri Theil of R2 that adjusts for the number of explanatory terms in a model relative to the number of data points. The adjusted R2 can be negative, and its value will always be {{less than or equal to}} that of R2. Unlike R2, the adjusted R2 increases only when the increase in R2 (due to the inclusion of a new <b>explanatory</b> <b>variable)</b> is more than one would expect to see by chance. If a set of explanatory variables with a predetermined hierarchy of importance are introduced into a regression one at a time, with the adjusted R2 computed each time, the level at which adjusted R2 reaches a maximum, and decreases afterward, would be the regression with the ideal combination of having the best fit without excess/unnecessary terms. The adjusted R2 is defined as ...|$|E
40|$|AbstractThe {{logistic}} regression describes {{the relationship between}} a binary (dichotomous) response <b>variable</b> and <b>explanatory</b> <b>variables.</b> If there is multi collinearity among the <b>explanatory</b> <b>variables,</b> the estimation of model parameters may lead to invalid statistical inference. In this study, we have survey data for 2331 randomly selected customers which consists of highly correlated binary <b>explanatory</b> <b>variables</b> to model whether a customer's housing loan application has been approved or not. For this purpose, we present a categorical principal component analysis to deal with the multi collinearity problem among categorical <b>explanatory</b> <b>variables</b> while predicting binary response variable with {{logistic regression}}...|$|R
30|$|Researchers {{typically}} {{do not know}} with certainty which <b>explanatory</b> <b>variables</b> ought {{to be included in}} their multiple regression models. More than 50  years ago, stepwise regression was proposed as an efficient way to select the most useful <b>explanatory</b> <b>variables.</b> Despite widespread criticism, it never disappeared and has enjoyed a revival as a method for analyzing Big Data, where the number of potential <b>explanatory</b> <b>variables</b> can be very large. This paper uses a series of Monte Carlo simulations to demonstrate that stepwise regression is a poor solution to a surfeit of variables. In fact, the larger the number of potential <b>explanatory</b> <b>variables,</b> the more likely stepwise regression is to be misleading.|$|R
30|$|In the {{previous}} section, we considered {{the use of}} exponential power model to describe responses with no covariates (or <b>explanatory</b> <b>variables).</b> In practice, many situations involve heterogeneous populations, and to represent that heterogeneity, {{it is important to}} consider the relationship of failure time to other factors (or <b>explanatory</b> <b>variables).</b> In the present section, we focus our attention to the models containing <b>explanatory</b> <b>variables</b> namely, failure time regression models in the context of reliability.|$|R
50|$|In statistics, econometrics, {{epidemiology}} and related disciplines, {{the method of}} instrumental variables (IV) is used to estimate causal relationships when controlled experiments are not feasible or when a treatment is not successfully delivered to every unit in a randomized experiment. Intuitively, IV is used when an <b>explanatory</b> <b>variable</b> of interest is correlated with the error term. A valid instrument induces changes in the <b>explanatory</b> <b>variable</b> but has no independent effect on the dependent variable, allowing a researcher to uncover the causal effect of the <b>explanatory</b> <b>variable</b> on the dependent variable.|$|E
5000|$|The {{parametric}} Goldfeld-Quandt test {{offers a}} simple and intuitive diagnostic for heteroskedastic errors in a univariate or multivariate regression model. However some disadvantages arise under certain specifications or in comparison to other diagnostics, namely the Breusch-Pagan test, as the Goldfeld-Quandt test is somewhat of an ad hoc test. [...] Primarily, the Goldfeld-Quandt test requires that data be ordered along a known <b>explanatory</b> <b>variable.</b> The parametric test orders along this <b>explanatory</b> <b>variable</b> from lowest to highest. If the error structure depends on an unknown variable or an unobserved variable the Goldfeld-Quandt test provides little guidance. Also, error variance must be a monotonic function of the specified <b>explanatory</b> <b>variable.</b> For example, {{when faced with a}} quadratic function mapping the <b>explanatory</b> <b>variable</b> to error variance the Goldfeld-Quandt test may improperly accept the null hypothesis of homoskedastic errors.|$|E
50|$|In {{statistics}} and econometrics, a distributed lag {{model is a}} model for time series data in which a regression equation is used to predict current values of a dependent variable based on both the current values of an <b>explanatory</b> <b>variable</b> and the lagged (past period) values of this <b>explanatory</b> <b>variable.</b>|$|E
40|$|AbstractThis study {{identifies}} and quantifies {{the effects}} of different <b>explanatory</b> <b>variables</b> that increase the severity of drivers' injuries related to single-vehicle collisions involving light-duty vehicles. The research is based on utilizing logistic regression to analyze records of all traffic collisions that occurred in North Carolina for the years from 2007 to 2013. The study also investigates temporal stability of the identified <b>explanatory</b> <b>variables</b> throughout the analysis period. The identified <b>explanatory</b> <b>variables</b> include those related to the roadway, vehicle, driver, and environmental conditions. The <b>explanatory</b> <b>variables</b> related to the roadway include whether the roadway is divided or undivided, and whether it is in an urban or rural area. The <b>explanatory</b> <b>variables</b> related to the vehicle include vehicle's age, travel speed, {{and the type of}} the light-duty vehicle. The <b>explanatory</b> <b>variables</b> related to the driver include driver's age, gender, influence by alcohol or illicit drugs, and the use of seatbelt. The <b>explanatory</b> <b>variables</b> related to the environmental conditions include weather, lighting, and road surface conditions. Three of the investigated <b>explanatory</b> <b>variables</b> were found to be temporally unstable with significantly varying effects on the severity of drivers' injuries. Those temporally unstable variables include the travel speed, the type of the light-duty vehicle, and the age of the driver. All other investigated variables were found to be consistently significant throughout the analysis period. The findings of this research have the potential to help decision makers develop policies and countermeasures that reduce the severity of drivers' injuries by focusing on <b>explanatory</b> <b>variables</b> that consistently exhibit significant effects on the severity of drivers' injuries. The findings of this research also provide quantitative measures that may be used to determine the feasibility of implementing those countermeasures in reducing the severity of drivers' injuries related to single-vehicle collisions. Recommendations for future research are also provided...|$|R
3000|$|... on the <b>explanatory</b> <b>variables</b> {{included}} in model(2), the <b>explanatory</b> <b>variables</b> from model (2) squared and interaction {{terms of the}} <b>explanatory</b> <b>variables</b> from model (2). The variables are then tested (jointly) for significance and if they not found significant H 0 of no heteroscedasticity is rejected. In the present application, dummy variables for the counties were also {{included in}} the test in order to test for group wise differences in error variance. No indication of group wise differences were detected.|$|R
40|$|It {{is shown}} how one can {{effectively}} use microdata in modelling the {{change over time}} in an aggregate (e. g. mean consumption expenditure) of a large and heterogeneous population. The starting point of our aggregation analysis is a specification of <b>explanatory</b> <b>variables</b> on the micro-level. Typically, some of these <b>explanatory</b> <b>variables</b> are observable and others are unobservable. Based on certain hypotheses on the evolution over time of the joint distributions across the population of these <b>explanatory</b> <b>variables</b> we derive a decomposition {{of the change in}} the aggregate which allows a partial analysis: to isolate and to quantify the effect of a change in the observable <b>explanatory</b> <b>variables.</b> This analysis does not require an explicit treatment of the unobservable variables. ...|$|R
5000|$|The {{notion of}} [...] "{{interaction}}" [...] {{is closely related}} to that of [...] "moderation" [...] that is common in social and health science research: the interaction between an <b>explanatory</b> <b>variable</b> and an environmental variable suggests that the effect of the <b>explanatory</b> <b>variable</b> has been moderated or modified by the environmental variable.|$|E
5000|$|Quasi-variance, used in linear {{regression}} when the <b>explanatory</b> <b>variable</b> is categorical ...|$|E
5000|$|The {{interpretation}} of the βj parameter estimates is as the additive effect on the log of the odds for a unit change in the jth <b>explanatory</b> <b>variable.</b> In {{the case of a}} dichotomous <b>explanatory</b> <b>variable,</b> for instance gender, [...] is the estimate of the odds of having the outcome for, say, males compared with females.|$|E
5000|$|Residuals {{against the}} <b>explanatory</b> <b>variables</b> in the model. A {{non-linear}} relation between these variables {{suggests that the}} linearity of the conditional mean function may not hold. Different levels of variability in the residuals for different levels of the <b>explanatory</b> <b>variables</b> suggests possible heteroscedasticity.|$|R
40|$|I {{show how}} to {{identify}} and estimate the average partial effect of <b>explanatory</b> <b>variables</b> in a model where unobserved heterogeneity interacts with the <b>explanatory</b> <b>variables</b> and may be unconditionally correlated with the <b>explanatory</b> <b>variables.</b> To identify the populationaveraged effects, I use extensions of ignorability assumptions that are used for estimating linear models with additive heterogeneity and for estimating average treatment effects. New stimators are obtained for estimating the unconditional average partial effect {{as well as the}} average partial effect conditional on functions of observed covariates. ...|$|R
30|$|The <b>explanatory</b> <b>variables</b> were TBW {{technique}} characteristics.|$|R
5000|$|In a {{model with}} a single <b>explanatory</b> <b>variable,</b> RSS is given by: ...|$|E
5000|$|Consider {{a linear}} model {{with more than}} a single <b>explanatory</b> <b>variable,</b> of the form ...|$|E
5000|$|Authoritarianism {{appears to}} be the most {{important}} <b>explanatory</b> <b>variable</b> for both children's and parents' antisemitic attitudes.|$|E
50|$|The multinomial probit {{model is}} a {{statistical}} model {{that can be used}} to predict the likely outcome of an unobserved multi-way trial given the associated <b>explanatory</b> <b>variables.</b> In the process, the model attempts to explain the relative effect of differing <b>explanatory</b> <b>variables</b> on the different outcomes.|$|R
5000|$|Binary {{response}} {{model with}} continuous endogenous <b>explanatory</b> <b>variables</b> ...|$|R
5000|$|... where ci is the unobserved {{effect and}} xit {{contains}} only time-varying <b>explanatory</b> <b>variables.</b> [...] Rather than differencing out the unobserved effect ci, Chamberlain proposed {{to replace it}} with the linear projection of it onto the <b>explanatory</b> <b>variables</b> in all time periods. Specifically, this leads to the following equation ...|$|R
