0|10000|Public
5000|$|... #Caption: <b>Decision</b> <b>tree</b> <b>for</b> {{selecting}} a suitable spatial prediction model.|$|R
30|$|Develop {{different}} <b>decision</b> <b>trees</b> <b>for</b> each QP and use {{the corresponding}} <b>tree</b> <b>for</b> each case.|$|R
40|$|We prove an {{exponential}} {{lower bound}} {{on the size}} of (ternary) algebraic <b>decision</b> <b>trees</b> <b>for</b> the MAX Problem of finding maximum of n real numbers. This complements n Γ 1 lower bound (cf. M. O. Rabin [R 72]) on the depth of algebraic <b>decision</b> <b>trees</b> <b>for</b> this problem. The method yields also {{for the first time a}} lower size bound for a polyhedral decision problem MAX= of testing whether the ith number is the maximum among a list of n real numbers, and gives the first nonlinear size lower bound on algebraic <b>decision</b> <b>trees</b> <b>for</b> the selection problems...|$|R
40|$|Control of {{gastrointestinal}} worms {{is crucial}} to any pasture system for ruminants. To support the farmer's foresighted planning of pasturage and avoid excessive deworming four <b>decision</b> <b>trees</b> are created and put online. They are accessible free by www. weide-parasiten. de. There is one <b>decision</b> <b>tree</b> <b>for</b> young cattle in intensive dairy husbandry and young cattle in suckling-cow management {{as well as one}} <b>decision</b> <b>tree</b> <b>for</b> economically kept sheep and goats, respectivel...|$|R
5000|$|Flowcharts, e.g., {{a binary}} <b>decision</b> <b>tree</b> <b>for</b> {{deciding}} {{what is the}} etiology of chest pain ...|$|R
40|$|A Direct Sum Theorem {{holds in}} a model of computation, when for every problem solving some k input {{instances}} together is k times as expensive as solving one. We show that Direct Sum Theorems hold in the models of deterministic and randomized <b>decision</b> <b>trees</b> <b>for</b> all relations. We also note that a near optimal Direct Sum Theorem holds <b>for</b> quantum <b>decision</b> <b>trees</b> <b>for</b> boolean functions...|$|R
40|$|We prove an {{exponential}} {{lower bound}} {{on the size}} of any fixed-degree algebraic <b>decision</b> <b>tree</b> <b>for</b> solving MAX, the problem of finding the maximum of n real numbers. This complements the n - 1 lower bound of Rabin [R 72] on the depth of algebraic <b>decision</b> <b>trees</b> <b>for</b> this problem. The proof in fact gives an exponential lower bound on size for the polyhedral decision problem MAX= of testing whether the j-th number is the maximum among a list of n real numbers. Previously, except <b>for</b> linear <b>decision</b> <b>trees,</b> no nontrivial lower bounds {{on the size of}} algebraic <b>decision</b> <b>trees</b> <b>for</b> any familiar problems are known. We also establish an interesting connection between our lower bound and the maximum number of minimal cutsets for any rank-d hypergraphs on n vertices...|$|R
5000|$|Build a <b>decision</b> <b>tree</b> <b>for</b> the [...] removed {{vertices}} and classify all vertices {{by their}} neighbors in this set.|$|R
40|$|This note {{contains}} {{supplementary information}} for [DH 10 :SDT]. Specifically, [DH 10 :SDT] omitted detailed quality results <b>for</b> shared <b>decision</b> <b>trees</b> mined from some dataset pairs in many tables, {{and it did}} not contain the mined shared <b>decision</b> <b>trees</b> <b>for</b> most of the dataset pairs, in order to save space. This supplementary note contains the complete tables and the mined shared <b>decision</b> <b>trees</b> <b>for</b> all dataset pairs. The mined shared <b>decision</b> <b>trees</b> might be of interest to medical scientists who study the corresponding cancers (breast cancer, central nervous system embryonal tumor, diffuse large B-Cell lymphoma, lung cancer, and prostate cancer) and their treatment...|$|R
50|$|Group the {{vertices}} into blocks, build a <b>decision</b> <b>tree</b> <b>for</b> each block, and classify all vertices {{by their}} sets of neighbors within each block.|$|R
30|$|For the {{baseline}} system, a five-state multi-stream left-to-right without skip path MSD-HSMM was trained. A conventional maximum likelihood-based <b>decision</b> <b>tree</b> construction algorithm {{was used to}} tie HMM states. In the conventional HMM-based speech synthesis framework, a unique tying structure (<b>decision</b> <b>tree)</b> is normally incorporated for both voicing probabilities and F 0 output probabilities. As opposed to the conventional HMM-based synthesis system, the proposed method uses a soft <b>decision</b> <b>tree</b> structure <b>for</b> the output probability distribution and a hard <b>decision</b> <b>tree</b> <b>for</b> voicing probabilities; therefore, we cannot apply the same tying structure for both voicing and output probabilities in the proposed system. With a view to having a fair comparison, {{the baseline}} system was implemented with two different <b>decision</b> <b>trees</b> <b>for</b> F 0 trajectories, one for the voicing labels {{and the other for}} the output probability distributions.|$|R
40|$|We {{prove that}} the minimum average depth of a <b>decision</b> <b>tree</b> <b>for</b> sorting 8 {{pairwise}} different elements is equal to 620160 / 8 !. We show also that each <b>decision</b> <b>tree</b> <b>for</b> sorting 8 elements, which has minimum average depth (the number of such trees is approximately equal to 8. 548 × 10 ^ 326365), has also minimum depth. Both problems were considered by Knuth (1998). To obtain these results, we use tools based on extensions of dynamic programming which allow us to make sequential optimization of <b>decision</b> <b>trees</b> relative to depth and average depth, and to {{count the number of}} <b>decision</b> <b>trees</b> with minimum average depth...|$|R
50|$|For every integer r, it is {{possible}} to find optimal <b>decision</b> <b>trees</b> <b>for</b> all graphs on r vertices by brute-force search. This search proceeds in two steps.|$|R
40|$|The {{successful}} implementation of enteral feeding in critically ill patients is frequently impeded by several obstacles, which can often be anticipated. A standardized approach using systematic <b>decision</b> <b>trees</b> <b>for</b> the delivery of enteral feeding {{has been shown to}} increase the awareness of the caregivers toward nutritional issues and to improve the adequacy of nutrition delivery, when adapted to the local constraints. Hence, the use of <b>decision</b> <b>trees</b> <b>for</b> enteral nutrition should be widely promoted as an easy and cost-effective increase in the quality of care. SCOPUS: ch. binfo:eu-repo/semantics/publishe...|$|R
30|$|The {{authors would}} like to {{acknowledge}} Dr. Armando Segatori for the precious suggestions and explanations on the implementation of the distributed fuzzy <b>decision</b> <b>trees</b> <b>for</b> big data classification problems.|$|R
40|$|We {{study the}} depth of <b>decision</b> <b>trees</b> <b>for</b> {{diagnosis}} of constant faults in read-once contact networks over finite bases. This includes diagnosis of 0 - 1 faults, 0 faults and 1 faults. For any finite basis, we prove a linear upper bound on the minimum depth of <b>decision</b> <b>tree</b> <b>for</b> diagnosis of constant faults depending {{on the number of}} edges in a contact network over that basis. Also, we obtain asymptotic bounds on {{the depth of}} <b>decision</b> <b>trees</b> <b>for</b> diagnosis of each type of constant faults depending on the number of edges in contact networks in the worst case per basis. We study the set of indecomposable contact networks with up to 10 edges and obtain sharp coefficients for the linear upper bound for diagnosis of constant faults in contact networks over bases of these indecomposable contact networks. We use a set of algorithms, including one that we create, to obtain the sharp coefficients...|$|R
3000|$|... [...]) ideally require {{developing}} multiple {{versions of}} <b>decision</b> <b>trees</b> <b>for</b> various classification options, and then choosing the best according to recognition performance. Because {{we need a}} single <b>decision</b> <b>tree</b> <b>for</b> UG, the following choices are made {{according to the most}} recurring pronunciation in our corpus: ‘w’ and ‘y’ (vowels rather than glides), ‘l’ (glide rather thanϕ), ‘p’ (dental stop rather than glottal fricative), ‘|’ (glottal stop rather than vowel), ‘A’ (long vowel rather than glottal stop or ϕ), ‘F’, ‘N’, and ‘K’ (nasal rather than vowels). The DG <b>decision</b> <b>tree</b> is developed in a similar manner, with a grapheme followed by ‘~’ treated as a single geminated grapheme.|$|R
40|$|AbstractIn this paper, we prove {{two general}} lower bounds <b>for</b> {{algebraic}} <b>decision</b> <b>trees</b> which test {{membership in a}} set S⊆Rn which is defined by linear inequalities. Let rank(S) be the maximal dimension of a linear sub- space contained in the closure of S (in Euclidean topology). First we show that any <b>decision</b> <b>tree</b> <b>for</b> S which uses products of linear functions (we call such functions mlf-functions) must have depth at least n−rank(S). This solves an open question raised by A. C. Yao {{and can be used}} to show that mlf-functions are not really more powerful than simple comparisons between the input variables when computing the largest k out of n elements. Yao proved this result in the special case when products of at most two linear functions are allowed. Our proof also shows that any <b>decision</b> <b>tree</b> <b>for</b> this problem must have exponential size. Using the same methods, we can give an alternative proof of Rabin's theorem, namely that the depth of any <b>decision</b> <b>tree</b> <b>for</b> S using arbitrary analytic functions is at least n−rank(S) ...|$|R
30|$|The {{authors in}} [65] used <b>decision</b> <b>tree</b> <b>for</b> {{cognitive}} routing {{so that the}} nodes can learn their environment and adapt their parameters and decisions accordingly. A sender will then use the <b>decision</b> <b>tree</b> to select the most appropriate and reliable next hop neighbor.|$|R
40|$|Upper {{and lower}} bounds on minimal average {{weighted}} depth and minimal average depth of <b>decision</b> <b>trees</b> over arbitrary information systems are considered. In proofs methods of test theory and {{rough set theory}} are used. Keywords: Information system, <b>decision</b> <b>tree,</b> average weighted depth 1. Introduction In this paper we consider {{upper and lower bounds}} on minimal average weighted depth of <b>decision</b> <b>trees</b> <b>for</b> problems over information systems and, apparently, close to the unimprovable upper bounds on minimal average depth of <b>decision</b> <b>trees.</b> Except of ordinary finite information systems we also consider infinite information systems, which are widely used in discrete optimization, pattern recognition and computational geometry. In the paper we consider the local approach to investigation of <b>decision</b> <b>trees,</b> when only attributes from a problem description may be used in <b>decision</b> <b>trees</b> <b>for</b> this problem. The investigations of bounds on the average weighted depth of <b>decision</b> <b>trees</b> are most interes [...] ...|$|R
40|$|<b>Decision</b> <b>tree</b> {{ensemble}} {{can significantly}} improve the generalization ability of classification {{and has become}} a hot topic in the field of text classification. However, this kind of techniques usually employs all the trained <b>decision</b> <b>trees</b> <b>for</b> constructing ensembles, which can cost a lot of computational time. For improving the performance of <b>decision</b> <b>tree</b> ensemble, a rough set based <b>decision</b> <b>tree</b> ensemble algorithm <b>for</b> text classification, called RSDTE (Rough Set based <b>Decision</b> <b>Tree</b> Ensemble), is proposed in this paper. Experiment results show that RSDTE decreases the size of ensemble and outperforms existing methods...|$|R
30|$|The core {{algorithm}} <b>for</b> building <b>decision</b> <b>trees</b> named ID 3 by Quinlan which engages a top-down, {{greedy search}} through {{the space of}} possible branches with no backtracking. The ID 3 algorithm {{can be used to}} build a <b>decision</b> <b>tree</b> <b>for</b> regression by changing Information Gain with Standard Deviation Reduction.|$|R
3000|$|... [...]) in {{the form}} of a <b>decision</b> <b>tree</b> <b>for</b> {{predicting}} the value of C from the values taken by the predictive variables. The solution is obtained by partitioning the Ω space into q+ 1 disjoint sets, A [...]...|$|R
30|$|The first {{option is}} rather complex because {{it leads to}} the {{implementation}} of a lot of WEKA <b>decision</b> <b>trees.</b> The solution adopted was the second one, to develop a single <b>decision</b> <b>tree</b> <b>for</b> a QP and adjust the mean and the variance threshold used by the trees {{on the basis of the}} QP.|$|R
40|$|We {{investigate}} {{the relationship between}} the direc-tional and the undirectional complexity of read-once Boolean formulas on the randomized <b>decision</b> <b>tree</b> model. It was known that there is a read-once Boolean formula such that an optimal randomized al-gorithm to evaluate it is not directional. This was first pointed out by Saks and Wigderson (1986) and an explicit construction of such a formula was given by Vereshchagin (1998). We conduct a systematic search for a certain class of functions and provide an explicit construction of a read-once Boolean formula f on n variables such that the cost of the optimal directional randomized <b>decision</b> <b>tree</b> <b>for</b> f is Ω(nα) and the cost of the optimal randomized undirectional <b>decision</b> <b>tree</b> <b>for</b> f is O(nβ) with α−β> 0. 0101. This is the largest known gap so far...|$|R
30|$|The rest of {{this study}} is {{organized}} as follows.  Section 2 introduces Intuitionistic Fuzzy based <b>decision</b> <b>tree</b> in order to classify stroke, followed by Sect. 3 with the implementation of Intuitionistic Fuzzy Based <b>Decision</b> <b>Tree</b> <b>for</b> Stroke Diagnosis. Section 4 showed the results of the experiment. Finally the conclusions are given in Sect. 5.|$|R
40|$|Vehicle reidentification is {{the process}} of {{tracking}} a vehicle along a highway as it crosses inductive loop detectors. The present work uses <b>decision</b> <b>tree</b> induction to generate a specific <b>decision</b> <b>tree</b> <b>for</b> tracking vehicles along specific high sections. Initial experimental results show that this approach performs well specially when coupled with signature matching techniques...|$|R
50|$|<b>Decision</b> <b>trees</b> {{models are}} {{instrumental}} in establishing lower bounds for computational complexity for certain classes of computational problems and algorithms: the lower bound for worst-case computational complexity {{is proportional to}} the largest depth among the <b>decision</b> <b>trees</b> <b>for</b> all possible inputs for a given computational problem. The computation complexity of a problem or an algorithm expressed in terms of the <b>decision</b> <b>tree</b> model is called <b>decision</b> <b>tree</b> complexity or query complexity.|$|R
40|$|Upper {{and lower}} bounds on the minimal average {{weighted}} depth and minimal average depth of <b>decision</b> <b>trees</b> over arbitrary information systems are considered. In proofs methods of test theory and {{rough set theory}} are used. 1. INTRODUCTION In this paper we consider {{upper and lower bounds}} on minimal average weighted depth of <b>decision</b> <b>trees</b> <b>for</b> problems over information systems and close to unimprovable upper bounds on minimal average depth of <b>decision</b> <b>trees.</b> In addition to the bounds, which depends on parameters of concrete problem, we consider common bounds for some classes of problems. Except of ordinary finite information systems we also study infinite information systems, which are widely used in discrete optimization, pattern recognition and computational geometry. In the paper we consider the local approach to investigation of <b>decision</b> <b>trees,</b> when only attributes from problem description may be used in <b>decision</b> <b>trees</b> <b>for</b> this problem. The investigations of bounds on the average we [...] ...|$|R
40|$|In {{this paper}} we study fault {{localization}} techniques for identification of incompatible configurations and implementations in service-based applications. We propose an approach using pooled <b>decision</b> <b>trees</b> <b>for</b> localization of faulty service parameter and binding configurations, explicitly addressing temporary and changing fault conditions. I...|$|R
40|$|This paper {{evaluates the}} {{performance}} of boosted <b>decision</b> <b>trees</b> <b>for</b> tagging b-jets. It is shown, using a Monte Carlo simulation of WH → lνq¯q events that boosted <b>decision</b> <b>trees</b> outperform feed-forward neural networks. The results show that for a b-tagging efficiency of 60 % the light jet rejection given by boosted <b>decision</b> <b>trees</b> is about 35 % higher than that given by neural networks. ...|$|R
40|$|When Genetic Programming is used {{to evolve}} <b>decision</b> <b>trees</b> <b>for</b> data classification, search spaces tend to become {{extremely}} large. We present several methods using techniques {{from the field of}} machine learning to refine and thereby reduce the search space sizes <b>for</b> <b>decision</b> <b>tree</b> evolvers. We will show that these refinement methods improve the classification performance of our algorithms...|$|R
40|$|This paper {{investigates the}} {{induction}} of <b>decision</b> <b>trees</b> {{based on the}} theory of belief functions. This framework allows to handle training examples whose labeling is uncertain or imprecise. A former proposal to build <b>decision</b> <b>trees</b> <b>for</b> twoclass problems is extended to multiple classes. The method consists in combining trees obtained from various two-class coarsenings of the initial frame...|$|R
40|$|This {{thesis is}} devoted to the {{development}} of extensions of dynamic programming to the study of <b>decision</b> <b>trees.</b> The considered extensions allow us to make multi-stage optimization of <b>decision</b> <b>trees</b> relative to a sequence of cost functions, to count the number of optimal trees, and to study relationships: cost vs cost and cost vs uncertainty <b>for</b> <b>decision</b> <b>trees</b> by construction of the set of Pareto-optimal points for the corresponding bi-criteria optimization problem. The applications include study of totally optimal (simultaneously optimal relative to a number of cost functions) <b>decision</b> <b>trees</b> <b>for</b> Boolean functions, improvement of bounds on complexity of <b>decision</b> <b>trees</b> <b>for</b> diagnosis of circuits, study of time and memory trade-off for corner point detection, study of decision rules derived from <b>decision</b> <b>trees,</b> creation of new procedure (multi-pruning) for construction of classifiers, and comparison of heuristics <b>for</b> <b>decision</b> <b>tree</b> construction. Part of these extensions (multi-stage optimization) was generalized to well-known combinatorial optimization problems: matrix chain multiplication, binary search trees, global sequence alignment, and optimal paths in directed graphs...|$|R
40|$|Usually, {{data mining}} {{projects}} {{that are based on}} <b>decision</b> <b>trees</b> <b>for</b> classifying test cases will use the probabilities provided by these <b>decision</b> <b>trees</b> <b>for</b> ranking classified test cases. We have a need for a better method for ranking test cases that have already been classified by a binary <b>decision</b> <b>tree</b> because these probabilities are not always accurate and reliable enough. A {{reason for this is that}} the probability estimates computed by existing <b>decision</b> <b>tree</b> algorithms are always the same for all the different cases in a particular leaf of the <b>decision</b> <b>tree.</b> This is only one reason why the probability estimates given by <b>decision</b> <b>tree</b> algorithms can not be used as an accurate means of deciding if a test case has been correctly classified. Isabelle Alvarez has proposed a new method that could be used to rank the test cases that were classified by a binary <b>decision</b> <b>tree</b> [Alvarez, 2004]. In this paper we will give the results of a comparison of different ranking methods that are based on the probability estimate, the sensitivity of a particular case or both...|$|R
30|$|In [66], {{the authors}} used <b>decision</b> <b>tree</b> <b>for</b> video routing in CR mesh networks. They aimed {{to improve the}} peak {{signal-to-noise}} ratio (PSNR) of the received video by considering channel status, nodes supporting video frame quality of service, effects of spectrum stability, and bandwidth availability.|$|R
