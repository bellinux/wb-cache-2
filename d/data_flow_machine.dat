16|10000|Public
40|$|Functional {{languages}} do {{away with}} the current state paradigm and achieve referential transparency. They also exhibit inherent parallelism. These qualities fit very well on top of a data-driven architecture such as a <b>data</b> <b>flow</b> <b>machine.</b> In this paper, we propose a fully reconfigurable <b>data</b> <b>flow</b> <b>machine</b> for implementing functional programming languages. The design is based on smart memories and nodes interconnected via a hypercube. Important aspects of the proposed model are described and compared with other similar attempts. Advantages of our system include massive parallelism, reconfigurability, and amenability to higher-level, graphical programming. Current limitations are identified and extensions are suggested...|$|E
40|$|To get a {{clear picture}} of the earth crust the Helmholtz {{equation}} needs to be solved and a high wave number is needed in order to provide fine grain details. The Stabilised BiConjugate Gradient method needs to be implemented to solve the Helmholtz equation. This is done on a Maxeler <b>data</b> <b>flow</b> <b>machine</b> to improve calculation times. The algorithm is split into 3 parts and all of them use the same calculation kernel. An improvement in calculation time of 2. 4 times faster than in the literature is achieved and a two times faster calculation is expected with more modern hardware. Maxeler’s <b>data</b> <b>flow</b> <b>machine</b> shows great possibilities to decrease calculation times for high performance computing problems. <br/...|$|E
40|$|A {{computer}} musi c synthesis {{system is}} the most flexible of synthesis systems It offers a composer extensive control over {{the sound of his}} piece. A user of such a system describes his composition in some synthesis language. The computer uses this description to calculate samples of a voltage waveform that can be fed to D/A converters at a specified sampling rate. The D/As' outputs are in turn fed to loudspeakers that produce the sound of the user's composition. Real time performance is unattainable on existing computer synthesis systems due to the sequential nature of conventional computers. Unless the parallelism that is present in the sample calculation process is exploited, real time performance will remain unobtainable. This thesis presents a proposed computer syntlesis system that includes a <b>data</b> <b>flow</b> <b>machine,</b> a computer whose architecture is highly parallel. The Music- 11 synthesis system at MIT was used as a model in its design. An analysis of the algorithms used in the sample conversion process and how it would run on the <b>data</b> <b>flow</b> <b>machine</b> is presented. An example of how a compostion would be described in a synthesis language and how it would run on the proposed system is given...|$|E
50|$|Many {{digital systems}} are <b>data</b> <b>flow</b> <b>machines.</b> These are usually {{designed}} using synchronous register transfer logic, using hardware description languages such as VHDL or Verilog.|$|R
40|$|The direct {{execution}} of <b>data</b> <b>flow</b> graphs by <b>data</b> <b>flow</b> <b>machines</b> exposes {{the maximum amount}} of par-allelism in a computation. However, it also results in undesirable properties such as: high overhead due to data replication required to implement high fanouts in the <b>data</b> <b>flow</b> graph; poor instruction and data local-ity since the scheduling of ready instructions is not sensitive to data locality; and less efficient {{execution of}} sequentially dependent code sections and vector op-erations due the inability of the <b>data</b> <b>flow</b> <b>machines</b> to support deep pipelines. SINAN offers a novel ap-proach called argument forwarding that can eliminate much of the data fanout overhead and provides greatly improved locality. We show that vector operations and sequential segments can be efficiently handled with the dataflow paradigm by a novel approach that dynami-cally forms the activity templates. ...|$|R
40|$|The major {{advantages}} of parallel processing sys-tems are their great reliability and high perfor-mance. A class of massively parallel computing systems is the <b>data</b> <b>flow</b> <b>machines.</b> These machines {{work on the}} basis of <b>data</b> <b>flow</b> rather than control flow. This paper presents a reliability analysis of <b>data</b> <b>flow</b> <b>machines</b> using a graph theoretical ap-proach. Three machines are considered here. They are the MIT, DDP and LAU static <b>data</b> <b>flow</b> ma-chines. The <b>data</b> <b>flow</b> graph has been employed as a natural tool for representing that class of ma-chines. The isomorphism between Petri nets and <b>data</b> <b>flow</b> graphs has been exploited to detect whether the consistency constraints are satisfied during various operational conditions. Such a graph is extended so that a timed <b>data</b> <b>flow</b> model has been constructed. This model integrates both the reliability features dependent on the system structure and the performance characteristics dependent on the components behavior. More-over, a productivity index is introduced for evaluating the three machines...|$|R
40|$|This paper {{describes}} the modelling and simulation of the Nottingham MUSE (MUltiple Stream Evaluator) machine. MUSE is a <b>data</b> <b>flow</b> <b>machine</b> capable of supporting structured parallel computation. The simulator {{described in this}} paper was designed to enable alterations, improvements and additions {{to be made to}} the prototype MUSE architecture. The stages through which the model has progressed, and the implementation details of this model as a program, are discussed. The validation experiments are explained, and future plans for alterations and modifications to the basic model are suggested...|$|E
40|$|In {{this thesis}} we show the {{feasibility}} of Coarse Grained Data Flow Machines for high-throughput streaming non-manifest applications. The architecture of the Coarse Grained <b>Data</b> <b>Flow</b> <b>Machine</b> {{is derived from the}} classical data flow architecture and the scheduling of its processing elements is done dynamically in hardware. Since the implementation of such an architecture is strongly application dependent, a design flow and supporting software tools, are provided. This gives application designers the means by which the number of processing elements, buffer sizes and latencies of the architecture can be tuned...|$|E
40|$|AbstractThe {{concepts}} of a data flow and sequential computers are confronted using models {{written in the}} functional language Miranda. 11 Miranda is a trademark of Research Software Ltd. A unified approach to both schemes of processing is presented together with {{an example of a}} simple problem, unsolvable sequentially, but easy for a data flow computer. Although these models have been designed to explain the concepts to students, they can be also used by researchers in comparative studies and general experiments. The model of a <b>data</b> <b>flow</b> <b>machine</b> seems to be especially useful, as hardware implementations are not widely available...|$|E
40|$|Programs for <b>data</b> <b>flow</b> <b>machines</b> {{are written}} in {{functional}} languages, some of which require efficient support for dynamic procedure invocation to achieve high performance and programming flexibility. Among the proposed <b>data</b> <b>flow</b> <b>machines,</b> few support procedures in any generality. Our machine, which is a hardware realization of the U-interpreter for <b>data</b> <b>flow</b> languages, provides support {{for a variety of}} procedure calling conventions. Because the U-interpreter assigns a unique activity name to each instance of a computation (activity), an activity name may become arbitrarily large in the case of nested or recursive procedure calls. Hardware considerations, however, require that an activity name be represented by a fixed-size tag. We describe a mechanism that uses fixed-size, reusable tags in hardware. Like processor and memory resources, a group of tags is allocated and deallocated for each procedure activation. The proposed mechanism passes procedure arguments and results efficiently, given the distributed environment of our machine...|$|R
40|$|Proponents of <b>data</b> <b>flow</b> <b>machines</b> always {{emphasize}} the high potential for parallelization {{and the high}} performance on numerical applications reachable by that kind of architecture. On the other hand opponents critisize the additional overhead during run time and the difficulties of the memory management. In order to evaluate the cost effectiveness of dynamical <b>data</b> <b>flow</b> <b>machines</b> we compare a well known representative, the Monsoon designed at the MIT, with two vector processors, the Cray I and the Spark 2. 0. This comparison {{is based on a}} theoretical model, which provides measures for the run time and the cost of the machines. As numerical workload we have chosen some kernels from the Livermore Loops benchmark. In this paper we briefly review the evaluation model, we describe the machines under consideration and finally we present our results of the comparison...|$|R
40|$|Communication {{mechanisms}} within concurrent {{computer systems}} are extremely hostile to optimizing compilers. Also vector machines have fundamental performance bottlenecks [33][35] and their sustained average performance is by several {{orders of magnitude}} lower, than their peak rate [15, 33], even when creative coding techniques help the compiler [34]. VLIW (Very Long Instruction Word) architectures [11, 7] are much more optimizer-friendly by lower level of parallelism (at instruction level) [4, 27, 14] and relatively good optimization results have been reported for systolizable algorithms [4], but only for algorithms with only locally regular data dependencies (systolic algorithms or systolizable algorithms). VLIW architectures still have substantial drawbacks. Also <b>data</b> <b>flow</b> <b>machines</b> are optimizer-hostile, since indeterministic operation does not permit compile-time optimization. <b>Data</b> <b>flow</b> <b>machines</b> throughput is also affected by other drawbacks: several new kinds of bottlenecks have been introduced. Code causes an enormous addressing overhead and data accessing conflicts [13]. A higher degree of parallelism may b...|$|R
40|$|The {{architecture}} of a <b>data</b> <b>flow</b> <b>machine,</b> called DFM, is developed for parallel list processing. The DFM can maximally exploit parallelism inherent in list process-ing, {{due to its}} ultra-multi-processing mechanism, packet communication-based parallel and pipeline execution mechanism, and lenient cons mechanism. A practical DFM implementation is described. A DFM prototype machine is implemented and DFM performance is eval-uated in a simulation on the register transfer level using several benchmark programs. The DFM single processor system is shown to be about five times faster than con-ventional machines which use the same device technology, while a multi-processor DFM system is shown to achieve a linear speed-up ratio ofO. 6 ~ 0. 9. 1...|$|E
40|$|The {{mapping of}} array {{operations}} in VAI, programs on a static <b>data</b> <b>flow</b> <b>machine</b> with array memory is studied. The flow dependency graph is introduced {{as a model}} of array operations in VAL programs. The balancing and optimization of the flow dependency graphs is presented. The class of well-behaved VAL prograins which can be modeled by flow dependency graphs is specified. Schemes for pipelined mapping of forall and for-iter array operation constructs in well-behaved VAL programs are formulated Thesis Supervisor: Jack B. Dennis Title: Professor of Electrical Engineering and Computer Science key words:. parallel processing, flow dependency graph, pipelined computation, data flow architecture, functional programming, VAL...|$|E
40|$|Gives a brief {{overview}} of research and development being carried out in the KBCS nodal centre at the Indian Institute of Science. The centre has now built three machines. The first machine is a multidimensional multilink system. Three variations of this system with four, eight and nine computing elements are functional. The software environment for this machine provides a general purpose interface to any programming language. The second machine has been built using 16 CEs connected in a tree topology. This machine uses FIFO links for interprocessor communications. The third machine is a coarse grain <b>data</b> <b>flow</b> <b>machine</b> and has a dual token broadcast bus architecture. The centre has also developed systems software for PAR-C on a VAX cluster...|$|E
40|$|This paper {{discusses}} {{a formal}} architecture model which can {{cope with a}} wide range of architectures from CPU design to parallel supercomputers. The model is derived from circuit theory but it also comprises some technology parameters. In particular, it permits to evaluate the cost effectiveness of computer architectures and to analyze cost/time trade-offs with very reasonable effort. The paper also covers some of the results gained with this model, like the trade-off of hardwired and programmed control. Furthermore, it is shown that dynamic <b>data</b> <b>flow</b> <b>machines</b> can not compete with vector machines under current technology constraints. The <b>data</b> <b>flow</b> principle itself turns out to be the real problem...|$|R
40|$|Graduation date: 1982 The {{methodology}} of structured programming has enabled rapid progress {{in many areas}} of theoretical computer science. Structured programs are generally easier to debug, test, prove and analyse. The development of these achievements into commercially viable applications and products has been slower than expected. The primary reason {{is that most of the}} programs currently in use are unstructured and theories based on assumed structure are not relevant to them. This paper describes a procedure for associating statements in a program with the predicates that influence their execution. This association is independent of the structure of the program and it provides a characterization of the statements which corresponds to the property of nestedness in the control flow of structured programs. A set of axioms is introduced which facilitate the reduction of path expressions to forms in which the predicate influence at a given statement is readily identifiable. A second analytical tool is introduced in which programs are represented as compositions of predicate to predicate paths. These paths permit a tree-like representation of the program and can be used to convert unstructured code to structured code while preserving the logical structure of the original code. These two analytical techniques are applied to two unrelated areas of research. Firstly, they form a sound basis for the derivation of measures of the psychological complexity of programs. Quantifiable attributes of the control <b>flow</b> and the <b>data</b> <b>flow</b> in any program are defined. The behaviour of simple measures of these attributes when applied to some typical code segments is examined. In the second application we use these techniques to describe an alternate solution to a problem in the concurrent execution of programs using <b>data</b> <b>flow</b> <b>machines.</b> The problem concerns the timing of execution of a computation which references a variable that may have more than one value assigned to it in preceding code segments. A new set of symbols for the representation of programs as <b>data</b> <b>flow</b> <b>machines</b> is described, and their applicability to naturally-structured code is demonstrated...|$|R
40|$|This papers {{presents}} XL, a new {{platform for}} Web services. We have designed XL with three main goals in mind: (a) increase application developers productivity via high-level programming constructs for Web Services routine programming patterns, (b) achieve high scalability, security, and availability for Web services and (c) compliance with all W 3 C standards (e. g., XML, SOAP, WSDL) such that XL Web services can interact {{with any other}} Web services written in, say, Java or C#. We hope to achieve these objectives by providing the new XL programming model based on a simple core programming "algebra" that extends Milner's PI-calculus [21]. To optimize XL programs, we employ techniques from the design of database systems, compiler construction, and <b>data</b> <b>flow</b> <b>machines,</b> as well as techniques specially designed for Web Services. A demo of the platform has been shown at [14]...|$|R
40|$|The Dennis-Misunas Form 1 <b>Data</b> <b>Flow</b> <b>Machine</b> {{can best}} be {{described}} as a static and scalar machine. Despite these two limiting characteristics, it is still possible to translate the whole of the functional progrmnming language VAL into the base language of this machine. Methods for translating the various high level constructs of VAL are presented which exploit the parallelism inherent in programs written in VAL mainly by pipelining through a single expression (vertical parallelism) rather than employing many copies of that same expression (horizontal parallelism), although the latter is not ruled out. These methods are tested by translating two different versions of a vector dot product algorithm, and the results obtained from running these translations on an interpreter are analyzed...|$|E
40|$|A {{workshop}} {{was held}} {{in an attempt to}} program real problems on the MIT Static <b>Data</b> <b>Flow</b> <b>Machine.</b> Most of the architecture of the machine was specified but some parts were incomplete. The main purpose for the workshop was to explore principles for the evaluation of computer systems employing new architectures. Principles explored were: (1) evaluation must be an integral, ongoing part of a project to develop a computer of radically new architecture; (2) the evaluation should seek to measure the usability of the system as well as its performance; (3) users from the application domains must {{be an integral part of}} the evaluation process; and (4) evaluation results should be fed back into the design process. It is concluded that the general organizational principles are achievable in practice from this workshop...|$|E
40|$|The {{algorithms}} employed are computationally intensive and, as a result, increased performance (both algorithmic and architectural) {{is required}} to improve accuracy and to treat larger molecular systems. Several benchmark quantum chemistry codes are examined {{on a variety of}} architectures. While these codes are {{only a small portion of}} a typical quantum chemistry library, they illustrate many of the computationally intensive kernels and data manipulation requirements of some applications. Furthermore, understanding the performance of the existing algorithm on present and proposed supercomputers serves as a guide for future programs and algorithm development. The algorithms investigated are: (1) a sparse symmetric matrix vector product; (2) a four index integral transformation; and (3) the calculation of diatomic two electron Slater integrals. The vectorization strategies are examined for these algorithms for both the Cyber 205 and Cray XMP. In addition, multiprocessor implementations of the algorithms are looked at on the Cray XMP and on the MIT static <b>data</b> <b>flow</b> <b>machine</b> proposed by DENNIS...|$|E
40|$|This paper {{describes}} RAP, a Register Allocator that allocates registers {{over the}} Program Dependence Graph (PDG) {{representation of a}} program in a hierarchical manner. The PDG program representation has been used successfully for scalar optimizations, the detection and improvement of parallelism for vector machines, multiple processor machines, and machines that exhibit instruction level parallelism, as well as debugging, the integration of different versions of a program, and translation of imperative programs for <b>data</b> <b>flow</b> <b>machines.</b> By basing register allocation on the PDG, the register allocation phase may be more easily integrated and intertwined with other optimization analyses and transformations. In addition, the advantages of a hierarchical approach to global register allocation can be attained without constructing an additional structure used solely for register allocation. Our experimental results have shown that on average, code allocated registers via RAP executed 2. 7 % faster [...] ...|$|R
40|$|In {{this paper}} we {{address the problem of}} {{scheduling}} algorithms embodied with a mixture of nonmanifest-loops [1], variable-latency and fixed-latency units [2], [3] for high throughput DSP-applications. Nonmanifest loops are loops where the number of iterations needed for a calculation is data dependent and hence not known at compile time. The body of a non-manifest loop can either have fixed-latency or variable-latency. Variable latency units are hardware execution units, that will complete a given operation after a variable quantity of clock cycles. When designing an Application Specific Processor for high throughput applications, the task is to design the processor based on prior knowledge of the algorithm to be implemented. If the algorithm body can be represented as a directed acyclic graph, a static schedule can be obtained by assuming the worst case latency of the units. However such a schedule might be inefficient in terms of latency and throughput due to the worst case latency assumption. A dynamic hardware scheduler on the other hand can outperform a static scheduler by gaining those waisted clock cycles. In this paper we present a self scheduling hardware execution unit, based on ideas taken from dynamic <b>data</b> <b>flow</b> <b>machines.</b> This execution unit is capable of scheduling an algorithm body that contains a mixture of non-manifest loops, variable-latency and fixed-latency units without wasting any extra clock cycle...|$|R
40|$|Abstract — In {{this paper}} we {{address the problem of}} {{scheduling}} algorithms embodied with a mixture of non-manifest-loops [1], variable-latency and fixed-latency units [2], [3] for high throughput DSP-applications. Non-manifest loops are loops where the number of iterations needed for a calculation is data dependent and hence not known at compile time. The body of a non-manifest loop can either have fixed-latency or variable-latency. Variable latency units are hardware execution units, that will com-plete a given operation after a variable quantity of clock cycles. When designing an Application Specific Processor for high throughput applications, the task is to design the processor based on prior knowledge of the algorithm to be implemented. If the algorithm body can be represented as a directed acyclic graph, a static schedule can be obtained by assuming the worst case latency of the units. However such a schedule might be inefficient in terms of latency and throughput due to the worst case latency assump-tion. A dynamic hardware scheduler on the other hand can outperform a static scheduler by gaining those waisted clock cycles. In this paper we present a self scheduling hardware execution unit, based on ideas taken from dy-namic <b>data</b> <b>flow</b> <b>machines.</b> This execution unit is capable of scheduling an algorithm body that contains a mixture of non-manifest loops, variable-latency and fixed-latency units without wasting any extra clock cycles. Keywords—Non-manifest loop scheduling, variable la-tency functional units, dynamic hardware scheduling, self scheduling hardware units. I...|$|R
40|$|Teams of {{scientists}} studied data flow concepts, static <b>data</b> <b>flow</b> <b>machine</b> architecture, and the VAL language. Each team mapped its application onto {{the machine and}} coded it in VAL. The principal findings of the study were: (1) Five of the seven applications used the full power of the target machine. The galactic simulation and multigrid fluid flow teams found that a significantly smaller version of the machine (16 processing elements) would suffice. (2) A number of machine design parameters including processing element (PE) function unit numbers, array memory size and bandwidth, and routing network capability {{were found to be}} crucial for optimal machine performance. (3) The study participants readily acquired VAL programming skills. (4) Participants learned that application-based performance evaluation is a sound method of evaluating new computer architectures, even those that are not fully specified. During the course of the study, participants developed models for using computers to solve numerical problems and for evaluating new architectures. These models form the bases for future evaluation studies...|$|E
40|$|Data flow is {{a mode of}} {{parallel}} computation in which parallelism in a program can be exploited at the fine grained as well as macro level. A data flow computer executes a data dependency graph rather than the program counter controlled sequence of instructions executed by conventional machines. Nonprocedural languages appear to be especially appropriate high level languages for data flow computers. Nonprocedural languages have only two statement forms: data description and assertion. The assertions enumerate the relationships among the data. A data dependency graph is also a suitable representation for a nonprocedural language program (or specification). This research is concerned with translating the dependency graph form of a specification to a program graph for a <b>data</b> <b>flow</b> <b>machine.</b> Specifications in the MODEL language are translated into an intermediate form, the data flow template. The template is a language-independent representation of the specification. The template is then translated into a data flow language (Manchester Dataflow) for the Manchester University machine. The translation consists of creating an array graph to represent the specification; generating the data flo...|$|E
40|$|The {{design of}} the {{architectures}} of automobiles E/E (Electric/Electronic) systems consists in the allocation of the hardware platform {{and the distribution of}} the computing and the communication loads of the application software within the allocated hardware. This operation is called the partitioning. Following the actual model-driven design schemes, the input of the partitioning is generally a functional specification of the system under development in the form of communicating software components that must be mapped on the allocated hardware platform. However, even though these models are sufficient to describe the structure of a system, they are not good enough to support a CAD-supplied partitioning. They lack the facilities needed to support the analysis of the data flow and to investigate the closeness between the elements of the specification, thus to support the mapping. In this paper, we define the Components <b>Data</b> <b>Flow</b> <b>Machine</b> (CDFM), a modeling format that is def ined to support the design of automobiles E/E systems architectures. The CDFM defines the semantics of a synthesis model that results from a transformation of standard models like SysML, EAST ADL or AUTOSAR models...|$|E
40|$|AbstractA {{concurrent}} automaton (c. a.) A = (I, O, S, →) {{consists of}} sets of input- (I) and output-lines (O), states (S), and transitions {{of the type}} M, s → N, s′ for M ⊆ I, N⊆ O, s,s′ ϵ S. M, s → N,s′ means that A in state s may take off signals on input-lines M and send off signals on the output-lines N switching into state s′ without involving a clock. The c. a. forms a quite general model for concurrent, parallel computations just as sequential machines do in the sequential case. We prove the following: For most network-type models of concurrent computations (such as Petri nets, speed-independent modules of the MIT or Keller, e. g., <b>data</b> <b>flow</b> <b>machines,</b> asynchronous control modules, etc.) with a finite set B of basic components s. t. any c. a. can be simulated by a net with components only from the basic set B there holds: for any such set B of basic components, for any c. a. A with i input-lines, o output-lines, s states, and t transitions there exists a net NA of the given type s. t. (i) NA A, (ii) NA consists only of components of the given basis B, (iii) NA consists of O((i + o + s) × t) components (of B), and (iv) NA needs O(lg(t + i + o)) (micro-) steps to simulate one (macro-) transition of A...|$|R
40|$|We {{find that}} the {{processor}} response greatly depends on the cache configuration and main memory throughput. For simple cache design, the conflict misses reduce RT response below 55 %. The only way to guarantee RT performance in multithreaded processors {{is to increase the}} memory bandwidth by employing pipelining. This way misses are serviced faster and near 100 % performance can be achieved. Introduction Multithreading has been proposed as a technique for tolerating latency in computer systems. In uniprocessor systems, multithreading has been proposed by Hirata [4], Gupta [13], Eggers [11] and others, to tolerate the latency caused by a cache miss. Multithreading has also been studied both in multiprocessor systems such as the APRIL [5], the Tera Computer [6], and the HEP [14], as well as in <b>data</b> [...] <b>flow</b> <b>machines</b> such as the *T [3], the Monsoon [15], and others, to tolerate the latency caused by long memory access through interconnection networks. It will not be long before multithreaded p [...] ...|$|R
40|$|AbstractAn {{applicative}} language is introduced for representing concurrent programs and communicating {{systems in the}} form of mutually recursive systems of nondeterministic equations for functions and streams. Mathematical semantics is defined by associating particular fixed points with such systems. These fixed points are chosen using a combination of several complete partial orderings. Operational semantics is described {{in the form of}} term rewriting rules, consistent with the mathematical semantics. It represents data-driven reduction semantics for usual expressions and data-driven <b>data</b> <b>flow</b> semantics in the case of recursive stream equations. So the language allows to treat the basic semantic notions of nondeterminism, parallelism, communication, and concurrency for multiprogramming in a completely formal, applicative framework. In particular, it provides a semantic theory for networks of loosely coupled, nondeterministic, communicating, stream processing functions. Finally, the relationship of the presented language to partial recursive functions and nonconventional computational models such as <b>data</b> <b>flow</b> and reduction <b>machines</b> is shown...|$|R
40|$|The <b>data</b> <b>flow</b> <b>machine,</b> which {{represents}} {{a radical departure}} from the conventional von Neumann architecture, shows great potential as a candidate for the future generation of computers. The difficulty in the usage of data structures as well as the effective exploitation of parallelism are two issues which have not as yet been fully resolved {{within the framework of the}} data flow model. This thesis concentrates on these important problems in the following manner. Firstly, the role memory can play in a data flow system is examined. A new concept called "active memory" is introduced together with various new actors. It is shown that these enhancements make it possible to implement a limited form of shared memory which readily supports the use of data structures. Secondly, execution performance of data flow programs is examined in the context of conditional statements. Transformations applied to the data flow graph are presented which increase the degree of parallelism. Analysis, both theoretical and empirical, is performed, showing that substantial improvements are obtained with a minimal impact on other system components...|$|E
40|$|A {{new method}} of {{designing}} collaborative multimedia environments for computer assisted problem solving is described. These environments support computer mediated interaction between multiple physically separated users {{joined by a}} communication network. Users interact using application specific models and objects, text, audio, video and graphics. Computer mediation enables both synchronous and asynchronous interaction, empowering users to transcend barriers of space and time. ^ Proliferation of high performance multimedia workstations and high speed and capacity networks provides us with the mechansim to realize real-time multi-user tools for computer-supported cooperative work. However, development and deployment of groupware, and consequent popular adoption, has been impeded {{by the absence of}} general models and enabling infrastructures. This thesis is a step towards developing formalisms for designing and implementing collaborative systems and groupware. ^ Requirements for the infrastructure from the developer 2 ̆ 7 s and the user 2 ̆ 7 s perspectives are identified and previous work is surveyed to highlight lessons learned, and to isolate desired features that are lacking. Application models that are amenable to distributed and collaborative operation on heterogeneous platforms are then developed. In these models, software tools consist of contexts that are characterized by a state that is modified by events and {{can be thought of as}} event driven distributed <b>data</b> <b>flow</b> <b>machines.</b> These models are used to build an enabling infrastructure for rapid prototyping of real-time groupware. Mechanisms for routing events to different states and contexts are provided, as are mechanisms for distribution functionality like synchronous and asynchronous remote procedure calling, and collaboration functionality like session control, interaction control, and high level access regulation. Identified shortcomings of extant work are overcome and mechanisms to implement policies derived from related research efforts are provided. The solution is justified from the technical and human factors viewpoints. ^ In this dissertation, the models and the infrastructure are described. Details of an implemented collaborative multimedia environment are presented, demonstrating the viability of the infrastructure. Possible applications of this technology are identified, and the facilitation of groupware prototyping by the model and infrastructure is described. Open issues and possible research directions are identified. ...|$|R
40|$|Botnets {{have evolved}} {{to become one of}} the most serious threats to the Internet and there is {{substantial}} research on both botnets and botnet detection techniques. This survey reviewed the history of botnets and botnet detection techniques. The survey showed traditional botnet detection techniques rely on passive techniques, primarily honeypots, and that honeypots are not effective at detecting peer-to-peer and other decentralized botnets. Furthermore, the detection techniques aimed at decentralized and peer-to-peer botnets focus on detecting communications between the infected bots. Recent research has shown hierarchical clustering of <b>flow</b> <b>data</b> and <b>machine</b> learning are effective techniques for detecting botnet peer-to-peer traffic...|$|R
40|$|Abstract—Credit {{cards are}} key {{instruments}} in personal financial transactions. Credit card payment systems {{used in these}} transactions and operated by merchants are often targeted by hackers to steal the card data. To address this threat, the payment card industry establishes a mandatory security compliance standard for businesses that process credit cards. A central pre-requisite for this compliance procedure is to identify the credit card <b>data</b> <b>flow,</b> specifically, the stages of the card transaction processing and the server nodes that touch credit card data as they travel through the organization. In practice, this pre-requisite poses a challenge to merchants. As the payment infrastructure is implemented and later maintained, it often deviates from the original documented design. Without consistent tracking and auditing of changes, such deviations in many cases remain undocumented. Therefore building the credit card <b>data</b> <b>flow</b> for a given payment card processing infrastructure is considered a daunting task {{that at this point}} requires significant manual efforts. This paper describes a tool that is designed to automate the task of identifying the credit card <b>data</b> <b>flow</b> in commercial payment systems running on virtualized servers hosted in private cloud environments. This tool leverages virtual machine introspection technology to keep track of credit card <b>data</b> <b>flows</b> across multiple <b>machines</b> in real time without requiring intrusive instrumentation of the hypervisor, virtual machines, middleware or application source code. Effectiveness of this tool is demonstrated through its successful discovery of the credit card <b>data</b> <b>flow</b> of several open and closed source payment applications. Keywords-virtual machine; payment system; card data flow; compliance;private cloud I...|$|R
40|$|Introduction to the Theory of <b>Flow</b> <b>Machines</b> {{details the}} {{fundamental}} processes and the relations {{that have a}} significant influence in the operating mechanism of <b>flow</b> <b>machines.</b> The book first covers the general consideration in <b>flow</b> <b>machines,</b> such as pressure, stress, and cavitation. In the second chapter, the text deals with ducts; this chapter discusses the general remarks, types of flow, and mixing process. Next, the book tackles the types of cascades, along with its concerns. The closing chapter covers the <b>flow</b> <b>machine</b> and its components, such as turbine, wheels, engines, and propellers. Th...|$|R
50|$|Turbomachines {{are also}} {{categorized}} {{according to the}} type of flow. When the flow is parallel to the axis of rotation, they are called axial <b>flow</b> <b>machines,</b> and when <b>flow</b> is perpendicular to the axis of rotation, they are referred to as radial (or centrifugal) <b>flow</b> <b>machines.</b> There is also a third category, called mixed <b>flow</b> <b>machines,</b> where both radial and axial flow velocity components are present.|$|R
