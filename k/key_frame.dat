450|941|Public
25|$|Although {{the boy is}} less {{detailed}} than Trico, he {{was also}} animated via <b>key</b> <b>frame</b> animation. He places hands on nearby walls, and reaches to pet Trico without player interaction. Ueda felt these animations were necessary to help convince the player of the game world. The animation system uses layers of animation that mimic real-life physics, {{taking advantage of the}} greater processing power of the PlayStation 4. The team considered making the player character a girl, but felt it would not be realistic that a female character would have enough stamina to climb Trico.|$|E
500|$|Ico {{introduced}} several {{design and}} technical elements, including a story told with minimal dialogue, bloom lighting, and <b>key</b> <b>frame</b> animation, that have influenced subsequent games. Although not a commercial success, it was critically acclaimed for its art, original gameplay and story elements and received several awards, including [...] "Game of the Year" [...] nominations and three Game Developers Choice Awards. [...] Ico is listed on several overall top game lists, {{and is often}} considered a work of art. It was re-released in Europe in 2006, {{in conjunction with the}} release of Shadow of the Colossus, the spiritual successor to Ico.|$|E
500|$|After {{two years}} of development, the team ran into {{limitations}} on the PlayStation hardware and faced a critical choice: either terminate the project altogether, alter their vision to fit {{the constraints of the}} hardware, or continue to explore more options. The team decided to remain true to Ueda's vision, and began to use the Emotion Engine of the PlayStation 2, taking advantage of the improved abilities of the platform. [...] Character animation was accomplished through <b>key</b> <b>frame</b> animation instead of the more common motion capture technique. [...] Ico is {{recognized as one of the}} first games to incorporate bloom lighting into video games, a feature that is common in later seventh generation console video games. The game took about four years to create. [...] Ueda purposely left the ending vague, not stating whether Yorda was alive, whether she would travel with Ico, or if it was simply the protagonist's dream.|$|E
40|$|Abstract. <b>Key</b> <b>frames</b> {{play a very}} {{important}} role in video indexing and retrieval. In this paper, we propose a novel method to extract <b>key</b> <b>frames</b> based on information theory. We use improved Bayesian Information Criterion to determining the number of <b>key</b> <b>frames,</b> and then automatically extract <b>key</b> <b>frames</b> to represent video shot based on information bottleneck cluster method. Experimental results and the comparisons with other methods on various types of video sequences show the effectiveness of the proposed method...|$|R
30|$|Complexity {{reduction}} is initially obtained with temporal downsampling, since only the <b>key</b> <b>frames</b> are conventionally encoded. However, if the <b>key</b> <b>frames</b> {{were to be}} encoded as I-frames, a more significant complexity reduction can be achieved, since {{there will be no}} motion estimation at the encoder side. Note that if the <b>key</b> <b>frames</b> are selected as the reference frames and the WZ frames are the nonreference <b>frames,</b> then the <b>key</b> <b>frames</b> can be coded as conventional I-, P-, or reference B-frames, without drifting errors. This not only increases the performance in terms of RD, but also increases the complexity since motion estimation may be used for the <b>key</b> <b>frames</b> as well.|$|R
3000|$|... value {{selection}} procedure for the <b>key</b> <b>frames</b> assures an almost constant decoded video quality {{for the full}} set of <b>frames</b> (<b>key</b> <b>frames</b> and WZ frames) which is essential from the subjective quality point of view. Notice that distributing the same total bitrate {{in a different way}} between WZ and <b>key</b> <b>frames</b> may even lead to better RD performance, for example, by investing more bits in the <b>key</b> <b>frames</b> at the cost of a less stable video quality, but the resulting strong quality variations along time are highly undesirable. In Table  2, the QP [...]...|$|R
500|$|Leterrier cited Andy Serkis' {{motion capture}} portrayals of Gollum and King Kong in The Lord of the Rings and King Kong, respectively, as the {{standard}} he was aiming for. Norton and Roth filmed 2500 takes of different movements the monsters would make (such as the Hulk's [...] "thunder claps"). Phosphorescent face paint applied to the actors' faces and strobe lighting would help record the most subtle mannerisms into the computer. Others including Cyril Raffaelli provided motion capture for stunts and fights, after the main actors had done video referencing. Leterrier hired Rhythm and Hues to provide the CGI, rather than Industrial Light & Magic who created the visual effects for Ang Lee's Hulk. Visual effect company, Image Engine, spent over a year working on a shot where Banner's gamma-irradiated blood falls through three factory floors into a bottle. Overall 700 effects shots were created. Motion capture aided in placing and timing of movements, but overall <b>key</b> <b>frame</b> animation by Rhythm and Hues provided the necessary [...] "finesse [...] superhero quality". Many of the animators and Leterrier himself provided video reference for the climactic fight.|$|E
2500|$|Munárriz further explains, [...] "If you {{remember}} Prince of Persia or Another World, the animation technique used was rotoscoping; people are filmed {{first and then}} their movements are copied. Initially we did the same, recording ourselves on video. For this type of retro game, {{it was important that}} the animation was smooth. Characters needed to be dynamic, so we used <b>key</b> <b>frame.</b> If we had used motion capture, the game would have lost that 80s feel." ...|$|E
2500|$|Post-production {{took place}} in California, where Digital Domain {{received}} all data. Using Autodesk Softimage and proprietary software, they tracked Björk's movements from the two marker sets and then began <b>key</b> <b>frame</b> animation using Autodesk Maya, Autodesk Alias and Autodesk Softimage. By combining patch deformation and shape interpolation, the emerging bear head was created, composed of [...] "100 maneuverable platelets that rise up through the skin." [...] Finally, rendering was completed using Pixar's RenerMan, a holographic shader was {{used to make the}} bear skin colors change, and all the computer graphics were added to the live-action footage. According to The Wire, post-production work brought the costs of the video up to £250,000.|$|E
30|$|Then, the <b>key</b> <b>frames</b> are {{filtered}} with a {{low-pass filter}} {{and the high}} frequency content is obtained as {{a difference between the}} original <b>key</b> <b>frames</b> and their filtered version.|$|R
3000|$|L,FR 1 are {{regarded}} as <b>key</b> <b>frames,</b> and the remaining target frames apply the enhancement algorithm of AOBMC algorithm based on <b>key</b> <b>frames</b> to retrieve the lost information of I [...]...|$|R
40|$|Abstract — We {{present a}} <b>key</b> <b>frames</b> {{selection}} algorithm, {{which is very}} flexible on any changes of content descriptors, based on Iso-Content Distance and Iso-Distortion principles. In both of the cases, the equality principle provides to the selected <b>key</b> <b>frames</b> the property to be equivalent on content video summarization. The estimated <b>key</b> <b>frames</b> properties and the experimental results indicate the good performance of the proposed schemata. I...|$|R
2500|$|Principal {{photography}} {{took place}} entirely on sound stages at L.A. Center Studios in downtown Los Angeles. The animal characters were created entirely in <b>key</b> <b>frame</b> computer animation, {{with the assistance}} of footage of real animal movement, the actors recording their lines, and performance capture for reference. The production team underwent a thorough process to realistically convey the animals' speaking, while still making them perceptually believable to the audience. Favreau researched earlier films featuring anthropomorphic animals—including Walt Disney's animated features, such as Snow White and the Seven Dwarfs and Bambi, as well as modern films such as Babe—and adopted certain techniques from those films into The Jungle Book. Nearly 70 separate species of animals native to India are featured in the film, with several species being portrayed as [...] "150% larger" [...] than their actual counterparts.|$|E
2500|$|On June 16, 2011, it was {{announced}} that Smaug would be voiced and interpreted with performance capture by Benedict Cumberbatch in Peter Jackson's three-part adaptation of The Hobbit, wherein Smaug is presented with a long head, red-golden scales, and piercing yellow-red eyes. The dragon speaks with Received Pronunciation with an underlying growl; Cumberbatch's vocal performance was vocoded using alligator growls. Smaug's design was created with <b>key</b> <b>frame</b> animation, in addition to Cumberbatch's motion capture performance. Weta Digital employed its proprietary [...] "Tissue" [...] software which was honoured in 2013 with a [...] "Scientific and Engineering Award" [...] from the Academy of Motion Picture Arts and Sciences to make the dragon as realistic as possible. In addition, Weta Digital supervisor Joe Letteri said in an interview for USA Today that they used classic European and Asian dragons as inspirations to create Smaug.|$|E
2500|$|In Peter Jackson's The Lord of the Rings film trilogy, Gollum is a CGI {{character}} voiced {{and performed}} by actor Andy Serkis. He {{is smaller than}} both Frodo and Sam. Barely glimpsed in [...] (2001), he becomes a central character in [...] (2002) and [...] (2003). The CGI character was built around Serkis' facial features, voice, and acting choices. Serkis based the iconic [...] "gollum" [...] throat noise on {{the sound of his}} cat coughing up hairballs. Using a digital puppet created by Jason Schleifer and Bay Raitt at Weta Digital, animators created Gollum's performance using a mixture of motion capture data recorded from Serkis and the traditional animation process of <b>Key</b> <b>frame,</b> along with the laborious process of digitally rotoscoping Serkis' image and replacing it with the digital Gollum's in a technique coined rotoanimation. This work required a large number of digital artists. As in the animated depictions of the character, Gollum is shown as virtually naked save for a loincloth in the trilogy.|$|E
30|$|<b>Key</b> <b>frames</b> coding - The <b>key</b> <b>frames</b> are coded with H. 264 /AVC Intra in the Main profile {{since this}} is one of the best Intra coding schemes in terms of RD performance.|$|R
3000|$|... i[*]−[*] 1 are maximum local, {{joint and}} global entropies for frame i – 1, respectively. By {{employing}} MID values, the <b>key</b> <b>frames</b> extracted {{by the first}} step of the algorithm are further refined to extract more reliable <b>key</b> <b>frames.</b>|$|R
30|$|Target {{distortion}} evaluation. Since {{the target}} {{distortion of the}} WZ frame to be coded should {{be similar to the}} <b>key</b> <b>frames</b> distortion, this module evaluates the distortion for the temporal adjacent <b>key</b> <b>frames</b> (already coded) at DCT band level.|$|R
2500|$|Iggy Pop voices the in-game {{tutorials}} for the game, and lends {{his trademark}} shirtless image to a Lego avatar for the game. David Bowie, {{along with his}} band and a venue loosely based on his music video for [...] "Let's Dance", also appears in the game. The bands Queen, Blur, and Spinal Tap have Lego avatars for the game (in the Nintendo DS version, however, the Spinal Tap minifigures are not available). In the case of Queen guitarist Brian May, he had required that the developers represent his hair style on his Lego caricature. John Drake of Harmonix stated the presence of Pop and Bowie add [...] "rock credibility" [...] to the family-friendly title. TT Fusion opted to map the motions of the Lego mini-figurines to <b>key</b> <b>frame</b> animation instead of motion capture which had been used on previous Rock Band titles, as it allowed for them to animate more exaggerated motions and effects.|$|E
2500|$|Ueda {{found that}} people were drawn to games with lifelike creatures, and felt The Last Guardian needed {{something}} similar to attract a broad audience. He {{wanted to create a}} virtual creature that behaved as realistically as possible, avoiding the unnatural behavior of other virtual animals. He based much of Trico's behavior on his childhood experiences growing up in a home full of animals. The final version of Trico is an amalgam of several creatures; the design was [...] "deliberately unbalanced because looking strange was important", according to Ueda. The team wanted to avoid making the animal cute, and instead focused on realistic-looking behavior with [...] "animal-like expressions". Trico's ears react with a cat-like [...] "twitch" [...] if they touch ceilings or other tall features, using the game's mesh-based collision detection. [...] The team added the ability to summon lightning from Trico's tail to have players understand Trico's [...] "force and ferocity". Ueda described Trico as [...] "adolescent", allowing the developers to add humor through its actions. The team used programmed <b>key</b> <b>frame</b> animations instead of more common motion capture techniques, allowing them to capture subtleties that would be difficult using live animal subjects.|$|E
50|$|In {{non-linear}} {{digital video}} editing, {{as well as}} in video compositing software, a <b>key</b> <b>frame</b> is a frame used to indicate the beginning or end of a change made to a parameter. For example, a <b>key</b> <b>frame</b> could be set to indicate the point at which audio will have faded up or down to a certain level.|$|E
30|$|<b>Key</b> <b>frames</b> quality control. Determines the <b>key</b> <b>frames</b> {{quantization}} parameters (QPs), for example, at frame level, {{in order}} that the desired target quality is reached with the minimum bit rate; for this, an adequate distortion model has to be used.|$|R
40|$|Abstract — In many video {{compression}} systems, the frames are down-sampled before transmission. Also, in many scalable systems, the residual after down- and up-sampling is encoded and transmitted. Sometimes, a few frames are encoded at normal resolution (<b>key</b> <b>frames)</b> {{while the other}} frames are encoded at reduced resolution. Super resolution {{can be used to}} enhance the up-sampling process, using motion information to improve traditional interpolation. In this paper, we propose to use a super resolution method to up-sample the non-key <b>frames</b> using the <b>key</b> <b>frames</b> as reference. We build dictionaries on-the-fly using the <b>key</b> <b>frames</b> instead of the traditional off-line training images. The high-frequency data of matching blocks are added to the low-resolution blocks. Since the <b>key</b> <b>frames</b> are very similar to the non-key frames, the method is robust enough to allow successful super resolution of highly compressed (severely degraded) sequences. Results are presented for many predefined block sizes, <b>key</b> <b>frames</b> frequencies, and compression parameters. I...|$|R
30|$|H. 264 /AVC Intra encoder. Encodes the <b>key</b> <b>frames</b> {{using the}} QP {{determined}} by <b>key</b> <b>frames</b> quality control module; in this paper, the H. 264 /AVC Intra video codec {{has been selected}} {{since it is the}} most efficient video intracodec currently available.|$|R
50|$|Other works include <b>key</b> <b>frame</b> {{animation}} {{and story}} boards for Chevrolet commercial, illustration for Cartoon Network, product design and illustration for Universal's The Mummy.|$|E
5000|$|Frank Scheck of The Hollywood Reporter wrote [...] "The <b>key</b> <b>frame</b> animation, {{based on}} {{three-dimensional}} models, is rudimentary, {{with none of}} the characters proving visually arresting." ...|$|E
50|$|The {{traditional}} {{method of}} adding hand and finger motion is to <b>key</b> <b>frame</b> the fingers. This {{is a process}} similar to the old claymation process; move the finger, record the frame, move the finger again, record the frame. Key framing is easier using animation software where a beginning and an ending position can be set up, then the software fills in the motion in between. Even though software makes this easy it still takes a very talented artist to get realistic hands using the <b>key</b> <b>frame</b> method.|$|E
40|$|<b>Key</b> <b>frames</b> play an {{important}} role in video abstraction. Clustering is a popular approach for key-frame extraction. In this paper, we propose a novel method for key-frame extraction based on dominant-set clustering. Compared with the existing clustering-based methods, the proposed method dynamically decides the number of <b>key</b> <b>frames</b> depending on the complexity of video shots, produces <b>key</b> <b>frames</b> in a progressive manner and requires less computation. Experimental results on different types of video shots have verified the effectiveness of the method...|$|R
30|$|<b>Key</b> <b>frames</b> quantization. When no {{quality control}} is {{performed}} as proposed in this paper, the <b>key</b> <b>frames</b> are quantized with a constant QP (see Table 1) which allows reaching an average quality {{similar to the}} WZ frames average quality. Although this option does not maximize the overall RD performance (this would require benefiting the <b>key</b> <b>frames</b> in rate and quality), it corresponds to a more relevant practical solution from the user perspective since a smoother quality variation is provided, improving the subjective quality impact.|$|R
40|$|This paper {{presents}} a new method for selecting <b>key</b> <b>frames</b> from a given video sequence. It {{is characterized by}} the fact that the entire process works in a wavelet transform domain. At first, shot boundaries are detected to define initial <b>key</b> <b>frames.</b> Secondly, specified but any number of <b>key</b> <b>frames</b> are selected by clustering feature vectors. Its effectiveness is evaluated in terms of precision rates and processing speeds. The proposed method offers more satisfactory results and works faster than the other existing methods. 1...|$|R
5000|$|Sequence editor - {{this is an}} {{extension}} of the figure editor, allowing the use of <b>key</b> <b>frame</b> animation to animate individual bones with a degree of accuracy of 0.1°.|$|E
5000|$|For video compression, key {{frames are}} divided into macroblocks. The motion model is a {{disruption}} of a <b>key</b> <b>frame,</b> where each macroblock is translated by a motion vector given by the motion parameters.|$|E
50|$|A <b>key</b> <b>frame</b> {{is a way}} for animators {{to record}} an object's {{position}} and rotation at a given point in time. A series of key-frames will result in motion. Frame1=position1, frame2=position2, the time between them determines the speed.|$|E
5000|$|... #Subtitle level 2: Intra-coded (I) frames/slices (<b>key</b> <b>frames)</b> ...|$|R
30|$|Since the <b>key</b> <b>frames</b> {{have a more}} {{important}} role in the overall RD performance than the WZ frames as they determine the quality of the side information, (15) gives a distortion priority to the <b>key</b> <b>frames</b> (this means its quality is never lower than the estimated WZ frames quality).|$|R
30|$|Note {{that the}} {{original}} sequence of frames at a high resolution has both <b>key</b> <b>frames</b> and nonkey frames (WZ frames). The framework encodes the WZ frames at a lower resolution and the <b>key</b> <b>frames</b> at regular resolution. At the decoder, the video sequence is received at mixed resolution.|$|R
