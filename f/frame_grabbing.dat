12|328|Public
50|$|In {{recent years}} {{with the rise of}} {{personal}} video recorders like camcorders, mobile phones,etc. video and photo applications have gained ascending prominence. <b>Frame</b> <b>grabbing</b> is becoming very popular on these devices.|$|E
50|$|The {{exterior}} of the robot was designed by sculptor Gloria Erika Weimer and is made of a crystal clear plastic, its body is 1.97 m tall (6'5") and weighs 130 kg (290 lb). The robot has 28 degrees of freedom and was provided cameras for eyes. Don Cuco is capable of reading musical scores and play the music on a piano. To perform such tasks the robot required the application of <b>frame</b> <b>grabbing,</b> image processing, pattern recognition and interpretation or analysis of scene. The design team of 30 faculty 20 students at UAP consisted of physicists, physicians, electronic engineers, computer scientists, musicians and designers who worked 20 hours daily for six months to complete the project.|$|E
40|$|Real-time video {{stabilization}} is {{computed from}} point-to-line correspondences using linear-programming. The {{implementation of the}} stabilizer requires special techniques for (i) <b>frame</b> <b>grabbing,</b> (ii) computing point-to-line correspondences, (iii) linear-program solving and (iv) image warping. Timing and real-time profiling are also addressed...|$|E
40|$|Abstract—The paper {{presents}} {{a prototype of}} Image Acquisition Module (IAM) dedicated for plasma monitoring. The complete <b>frame</b> <b>grabber</b> together with camera controller, timing and communication interfaces is fitted in one Advanced Mezzanine Card (AMC) to maintain compatibility with the Micro Telecommunications Computing Architecture (µTCA) standard. Keywords—image acquisition, <b>frame</b> <b>grabber,</b> mtca, utca, am...|$|R
5000|$|... #Caption: A <b>frame</b> <b>grab</b> from Peculiar Penguins, a Silly Symphonies short.|$|R
50|$|An OEM asked Datacube if a <b>frame</b> <b>grabber</b> {{could be}} built on a Multibus board. At the time, a <b>frame</b> <b>grabber</b> was a large box with {{multiple}} boards. The VG120 was the first ever commercial single board frame grabber: based on programmable array logic (PAL), it had 320 x 240 x 6 bit resolution, grayscale video input and output.|$|R
40|$|A {{commercial}} CMOS {{image sensor}} was irradiated with heavy ion beams in the several MeV energy range. The image sensor {{is equipped with}} a standard video output. The data were collected on-line through <b>frame</b> <b>grabbing</b> and analysed off-line after digitisation. It was shown that the response of the image sensor to the heavy ion bombardment varied with the type and energy of the projectiles. The sensor will be used for the CMS Barrel Muon Alignment system...|$|E
40|$|The {{application}} of computer vision in {{industry has been}} increasing as greater use is made of flexible automation and robotics. Quality control and sorting can also be heavily dependent on artificial vision interfaced to an intelligent decision making system. Traditionally industrial tasks requiring computer vision are simplified to a 2 -D problem in a plane. This permits {{the use of a}} single camera and hence reduces the complexity of the procedures of <b>frame</b> <b>grabbing,</b> image processing and decision making. Such a solution is however not suitable when 3 -D information is vital in the control or decision making processes. Generation and processing of 3 -D images are required for such applications...|$|E
40|$|Aim of {{the project}} is the {{development}} of a laser diagnostic system (LDS) to apply the Planar Laserinduced Predissociation Fluorescence (PLIF) on Combustion Experiments under Mikrogravity Conditions at the Bremen drop tower. The system consists of a narrowbanded excimerlaser system, a system to achieve optical access to the dropping capsule, a pointing assembly for compensation of relative movements, a sheet forming optic, a two-stage intensfied high-speed camera (250 f/s) and a digital <b>frame</b> <b>grabbing</b> and recording system. The systems has been successfuly developed, installed, and its functionality has been verified. (orig.) SIGLEAvailable from TIB Hannover: DtF QN 1 (65, 33) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Bildung, Wissenschaft, Forschung und Technologie, Bonn (Germany); DLR Deutsches Zentrum fuer Luft- und Raumfahrt e. V., Bonn (Germany) DEGerman...|$|E
40|$|Studying out {{isochronous}} {{and automatic}} project about three-dimensional imaging system of dairy cow forming by computer, CCD video camera, <b>frame</b> <b>grabber,</b> photoelectric switch, SCM, automatic door, electric barrier etc. SCM detects signal of photoelectric switch, {{and it makes}} sure info of the orientation of dairy cow. Computer control <b>frame</b> <b>grabber</b> to grab image. The dynamic link libraries technology and multithreading technology are adopted to enhance {{the performance of the}} system. The experiment result shows image quality and imaging speed can satisfy the requirements of image processing after grabbing. ...|$|R
5000|$|A reverseable pixel clock for a <b>frame</b> <b>grabber</b> (a {{video capture}} device) in chunky modes (this only work with VRAM systems).|$|R
5000|$|Autovision I, 1981, {{designed}} for fast time to market, {{was based on}} Vision Module technology licensed from Stanford Research Institute (SRI). The AV I used an early Motorola 68000 KDM prototype board interfaced to a Unibus <b>frame</b> <b>grabber</b> board purchased from SRI. The <b>frame</b> <b>grabber</b> was {{designed for}} the General Electric TN-2200, an early solid state video camera with a 128 by 128 pixel array and C-mount lens. DECtape II drives were used for program and data storage.|$|R
40|$|Active contour models (snakes) can be {{used for}} contour {{description}} and extraction, as well as for object tracking in image sequences. Two unsolved problems for real time object tracking are the problem of an automatic initialization of the snake on the object and the proof of robustness of this object tracking method. In this paper we describe a two stage real time object tracking system. In the first stage, the moving object is detected and the active contour is initialized. In the second stage, the object is tracked by active contour models. The parameters of the camera and the <b>frame</b> <b>grabbing</b> device are continuously updated in such a way, that the moving object will always be kept {{in the center of the}} image. We show how features can be extracted out of the snake tracking the object which are used for detection of errors in the tracking stage. In this case the system switches back to the first stage for object localization. We illustrate through examples that a robust tracking over lo [...] ...|$|E
40|$|Hyperspectral imaging {{provides}} an alternative way {{of increasing the}} accuracy by adding another dimension: the wavelength. Recently, hyperspectral imaging is also finding its way into many more applications, ranging from medical imaging in endoscopy for cancer detection to quality control in the sorting of fruit and vegetables. But effective use of hyperspectral imaging requires {{an understanding of the}} nature and limitations of the data and of various strategies for processing and interpreting it. Also, the breakthrough of this technology is limited by its cost, speed and complicated image interpretation. We have therefore initiated work on designing real-time hyperspectral image processing to tackle these problems by using a combination of smart system design, and pseudo-real time image processing software. The main focus of this paper is the development of a camera-based hyperspectral imaging system for stationary remote sensing applications. The system consists of a high performance digital CCD camera, an intelligent processing unit, an imaging spectrograph, an optional focal plane scanner and a laptop computer equipped with a <b>frame</b> <b>grabbing</b> card. In addition, special software has been developed to synchronize between the frame grabber (video capture card), and the digital camera with different image processing techniques for both digital and hyperspectral data...|$|E
40|$|Recently, {{several authors}} and {{institutions}} proposed quality control procedures for 2 -D B-mode sonographic image analysis. The {{aim of this}} study was to assess if it is possible to deﬁne a range of acceptability of the diﬀerent parameters measured. Phantoms for 2 -D B-mode acquisitions were employed with 11 of the same model high-level ultrasound scanners. Uniformity, axial and lateral resolution, axial distance accuracy, geometric distortion, image contrast, dead zone and penetration depth were measured. All images were acquired by experienced operators and saved by <b>frame</b> <b>grabbing</b> the analog video output signal. A small subset of images was also saved directly in dicom 3. 0 format on a magneto optical disk. Images were analysed with in-house developed software. Quality control test results for 2 -D B-mode images were demonstrated to be related to the probe employed. We also found that the results were not dependant on the operator and type of imaging capture method used. By selecting data from the same type of scanner and dividing probes into two groups (convex medium-low frequency and linear medium-high frequency) it is possible to ﬁnd a reasonably narrow range of variability for almost all of the parameters studied. Mean values of the diﬀerent parameters measured, 95...|$|E
5000|$|Autovision IV, {{similar to}} AV II, {{but with a}} {{patented}} <b>frame</b> <b>grabber</b> using dual 68000s. Then-new Sony 3-1/2 inch floppy drives replaced DECtape.|$|R
30|$|This third {{camera was}} {{connected}} to the same <b>frame</b> <b>grabber</b> via the secondary Camera-Link base channel, which also provides a completely independent control path.|$|R
50|$|A line-scan camera {{traditionally}} {{has a single}} row of pixel sensors, instead of a matrix of them. The lines are continuously fed to a computer that joins them {{to each other and}} makes an image. This is most commonly done by connecting the camera output to a <b>frame</b> <b>grabber</b> which resides in a PCI slot of an industrial computer. The <b>frame</b> <b>grabber</b> acts to buffer the image and sometimes provide some processing before delivering to the computer software for processing.|$|R
40|$|This {{research}} {{was designed to}} evaluate the operational utility of airborne video for classification accuracy assessment of satellite imagery. There {{are a number of}} logistical advantages in utilizing airborne video data particularly in remote or large catchment regions where ground accessibility can be prohibitively expensive. In a study of land cover characteristics in the Barossa Valley, South Australia, comparisons of Landsat ETM+ classification accuracy assessments were derived from both airborne video and standard ground truthing point sampling techniques. The airborne video data was obtained by randomly <b>frame</b> <b>grabbing</b> 243 individual scenes along four predetermined flight lines and computing classification accuracies and error matrix statistics. These results were then compared with similar statistics derived from 180 randomly chosen ground sampling sites. The costs involved in obtaining both sets of data per sampling pont were also calculated. The results demonstrated that the airborne video data provided similar degrees of accuracy assessment at a cost of approximately one seventh that of the ground survey with the added advantages of increased data collection, overall improved site accessibility and the ability to continually store and review the data. The cost differentiation would become even more pronounced in more remote and inaccessible areas. In general the results of the unsupervised Landsat ETM+ classification were rather poor producing an overall general accuracy of 70 % and a Kappa coefficient of 0. 65, highlighting the classification difficulties encountered in using commercial satellite imagery for land cover assessments in an area with very heterogeneous fine grained land use patterns...|$|E
40|$|Spatial encoded {{video is}} used for {{a large number of}} mapping {{projects}} for various applications (McCarthy T., 1999). GPS data can be encoded onto the video or audio track using different techniques. One encoding/decoding hardware system, designed by Navtech (NavTech, 2007), enables 1 Hz GPS ASCII data strings to be encoded onto a single audio channel of any video recording format. Frequency shift keying modulation (FSK) (Miyagi M., 1968) techniques are used to encode GPS data stream onto audio stream during data acquisition. This GPS stream can be decoded using the same encoding hardware system during post processing whilst a frame-grabbing card is used to digitise single frames of video. Both image and GPS data streams are synchronised on GPS time and are saved to hard disk. These data-streams can be retrieved and analysed in a GIS for various mapping applications. Post processing of the data using frame-grabbing card has, to date, proved to be cumbersome and inefficient. This is due, for the most part, to the setup and operation of frame-grabbing cards. To overcome these limitations, a project was initiated with the key objective of simplifying this approach. This centred around development of a software decoder that can retrieve GPS data directly from the captured spatial video data files without the need for specialised hardware. An obvious advantage of this software algorithm is the ability to transfer audio video using any digital format, onto a PC desktop, using standard methods and systems. GPS can then be retrieved and displayed synchronised to the video stream using software, without the need for <b>frame</b> <b>grabbing</b> cards and cables...|$|E
40|$|Passenger comfort {{becomes more}} and more {{important}} in the automotive industries. Thus it is necessary to investigate the ventilation concepts realized in automotives e. g. inlet flows or interactions between the inlet-flow and linings. The here presented investigations aimed at the determination of the flow field between the left front air inlet and the left sidewindow of a mini-van by solving the Reynolds Averaged Navier Stokes Equation and the validation of these predictions comparison the predictions with flow field measurements. Therefore experimental and numerical investigations for a fixed flow-rate and 4 different inlet configurations were carried out at the facilities of the DLR in Göttingen. The configuration of the mini-van consists of standard interiours with carpets, instrument panels, and linings but without seats and passenger (dummies) for both numerical and experimental investigations. The calculations have been performed using the CFD codes of STAR-CD with the second-order differencing schemes MARS (monotone advection and reconstruction scheme) and CD (for density only) solving the Reynolds-averaged Navier-Stokes equations with various turbulent models and different meshing strategies. The differences of the predicted flow fields have been analysed in order to choose approach suited for such simulations. For a non-intrusive determination of the velocity components of the instantaneous flow-field the particle image velocimetry (PIV) technique in a 2 C- 2 D setup was employed. To illuminate the tracer particles a Nd:YaG Laser has been used. Imaging of the scattered light from the tracer particles was performed using a high-resolution CCD-Kamera with a <b>frame</b> <b>grabbing</b> rate of 0. 5 Hz. For any of the four inlet configurations 1000 image-pairs have been recorded. Experimental and numerical results show the interaction of the inflow-jet with the B-pillar of the respective side window for different inlet configuration. A quantitative comparison between numerical and experimental data in terms of the normalized differential vector (U_exp - U_cfd) /U_mean shows a good agreement in general, though a superior agreement if the experimental and numerical results was achieved if the k-omega LowRe turbulence model was used in the simulations. ...|$|E
50|$|After {{completing}} the plotting radar technique, the {{image from the}} radar can either be displayed, captured or recorded to a computer monitor using a <b>frame</b> <b>grabber.</b>|$|R
30|$|Two mirrors {{projected}} {{the light}} over the sample and provided the fine adjustment of the illumination angle. To acquire hyperspectral images, a monochrome charge-coupled device (CCD) camera (Hamamatsu ORCA C 4742 - 95 - 12 ER) was mounted normal to the sample so the specular component was excluded. The CCD camera had a spatial resolution of 1344 × 1024 pixels. Special modes of pixel combination (binning) were excluded. The camera also had an electronic shutter with a timer controlled by an external signal. A conventional objective {{was placed in the}} CCD camera. The images were acquired with a <b>frame</b> <b>grabber</b> (Matrox Meteor II digital PCI <b>frame</b> <b>grabber).</b> The <b>frame</b> <b>grabber</b> also provided the external signal to control the time shutter of the CCD camera. Setup, synchronization, and control of the <b>frame</b> <b>grabber,</b> the filter and the CCD camera were done using specific software in a PC. The illumination angle was fixed at 45 ° from surface normal, and the detection angle was at the normal. This is standard for measuring conditions in most commercial spectrophotometers (Commission Internationale de l'Éclairage, International Commission on Illumination CIE geometry 45 °/ 0 °). The entire hyperspectral system except the illumination source was shielded with dark opaque material and maintained in a dark room.|$|R
50|$|The current version {{supports}} bit rates up to 6.25 Gbit/s over {{a single}} coaxial cable from camera to <b>frame</b> <b>grabber.</b> A low speed uplink channel, operating at 20.833 Mbit/s from <b>frame</b> <b>grabber</b> to camera {{can be used}} for camera control or triggering. A 24 V power supply is also available over the coaxial cable to deliver up to 13 W to the camera. Applications requiring more than a 13 W power supply utilize a separate power supply. For higher bit rates, two or more coaxial cables can be used in parallel.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe imaging {{in real time}} of infrared background scenes with the Naval Postgraduate School Infrared Search and Target Designation (NPS-IRSTD) System was achieved through extensive software developments in protected mode assembly language on an Intel 80386 33 Mhz computer. The new software processes the 512 by 480 pixel images directly in the extended memory area of the computer where the DT- 2861 <b>frame</b> <b>grabber</b> memory buffers are mapped. Direct interfacing, through a JDR-PR 10 prototype card, between the <b>frame</b> <b>grabber</b> and the host computer AT bus enables each load of the <b>frame</b> <b>grabber</b> memory buffers to be effected under software control. The protected mode assembly language program can refresh the display of a six degree pseudo-color sector in the scanner rotation within the two second period of the scanner. A study of the imaging properties of the NPS-IRSTD is presented with preliminary work on image analysis and contrast enhancement of infrared background scenes. [URL] Canadian Force...|$|R
5000|$|Autovision II, 1982, used {{a custom}} {{designed}} Versabus 68000 processor with a custom 8-channel RS-170 Versabus <b>frame</b> <b>grabber</b> employing an AMD Am2900 bit slice micro-controller, packaged in an industrially hardened NEMA-12 enclosure.|$|R
40|$|This paper {{presents}} a low-cost <b>frame</b> <b>grabber,</b> which was specifically designed {{as part of}} a real-time motion detection system for high-resolution images. The <b>frame</b> <b>grabber</b> is FPGA-based to minimise size of the PCB and improve reliability of the system. It also acts as a backend add-on card for an IBM-PC compatible. The experimental tests carried out on different machines show that the board implemented meets all specifications required by the system, and performs well. The captured frames are clear, well contrasted and jitter-free in both live and still video modes and their quality is comparable to that available from equivalent commercial systems...|$|R
50|$|The Automatix AI-32 robot {{controller}} {{used the same}} processor, bus and RAIL language as the AV II, IV and 5, allowing <b>frame</b> <b>grabber</b> and processing boards to be added for integrated machine vision.|$|R
40|$|Approved {{for public}} release, {{distribution}} unlimitedA system to display images {{generated by the}} Naval Postgraduate School Infrared Search and Target Designation System (a modified AN/SAR- 8 Advanced Development Model) in near real time was developed using a 33 MHz NIC computer as the central controller. This computer was enhanced with a Data Translation DT 2861 <b>Frame</b> <b>Grabber</b> for image processing and an interface board designed and constructed at NPS to provide synchronization between the IRSTD and <b>Frame</b> <b>Grabber.</b> Images are displayed in false color in a video raster format on a 512 by 480 pixel resolution monitor. Using FORTRAN, programs h ave been written to acquire, unscramble, expand and display a 3 degrees sector of data. The time line for acquisition, processing and display has been analyzed and repetition periods of less than four seconds for successive screen displays have been achieved. This represents a marked improvement over previous methods necessitating slower Direct Memory Access transfers of data into the <b>Frame</b> <b>Grabber.</b> Recommendations are made for further improvements to enhance the speed and utility of images produced. [URL] United States Coast Guar...|$|R
40|$|An image {{processing}} system (fig. 1. 1) {{consists of a}} light source to illuminate the scene, a sensor system (usually a CCD-camera) and an interface between the sensor system and the computer. Among other things, the interface converts analog information into digital data which the computer can understand. This {{takes place in a}} special piece of illumination camera output device host 1. 1 : Components of an {{image processing}} system <b>frame</b> <b>grabber</b> hardware, the <b>frame</b> <b>grabber,</b> which also stores the image. Many types of <b>frame</b> <b>grabber</b> hardware are supplied with special signal processors, so that very calculation-intensive parts of the image processing programs can be run in a time-efficient way. Usually the <b>frame</b> <b>grabber</b> package contains a library of often-used routines which can be linked to the user’s program. The results of an image processing run will be transferred to the outside world by one or more I/O interfaces, the screen and the normal output devices like printer, disks etc. The classical configuration of image processing hardware is not a stand-alone system but has to be directed by a host computer. However, the newest developments are able to integrate the complete image processing system into the camera. In this module we will talk about the hardware components of image processing systems. You will receive the basics which will enable you to conceptualize an image processing system along with the knowledge necessary to be able to compare the capability and the compatibility of components offered by different companies You should be familiar with the terminology in the field of personal computers. In addition, som...|$|R
5000|$|In {{addition}} to the commercial product lines offered by Alacron, Sgro continued to perform basic research in integrating <b>frame</b> <b>grabber</b> technology with specialized systems for various disciplines. The company received SBIR grants where Sgro acted as principal investigators, including: ...|$|R
50|$|CoaXPress {{supports}} a low speed uplink channel from <b>frame</b> <b>grabber</b> to camera. This uplink channel has a fixed bit rate of 20.833 Mbit/s. The uplink channel uses 8b/10b encoding. The uplink {{can be used}} for camera control, triggering and firmware updates.|$|R
50|$|An {{alternative}} solution for capturing a screencast {{is the use}} of a hardware RGB or DVI <b>frame</b> <b>grabber</b> card. This approach places the burden of the recording and compression process on a machine separate from the one generating the visual material beingcaptured.|$|R
50|$|The {{most common}} {{application}} is to interface cameras to computers (via a <b>frame</b> <b>grabber)</b> on applications (such as Machine vision) which involve automated acquisition {{and analysis of}} images.Some cameras and frame grabbers have been introduced which support and utilize the CoaXPress interface standard.|$|R
5000|$|Historically, <b>frame</b> <b>grabber</b> {{expansion}} cards were the predominant way to interface cameras to PC's. Other interface methods have emerged since then, with frame grabbers (and in many case, cameras themselves) connecting to computers via interfaces such as USB, Ethernet and IEEE 1394 ("FireWire").|$|R
40|$|A SIP (Societe Genevoise d'Instruments de Physique) Trioptic {{coordinate}} {{measuring machine}} was modified for calibration of high quality single-axis glass standards to an uncertainty of {+-} 0. 000020 inch. The modification was accomplished through {{the addition of a}} <b>frame</b> <b>grabber</b> board, vision software, a high-resolution camera, stepper motors, a two-axis motor controller, and an HP-IB interface card. An existing temperature system (hygrometer, barometer, laser interferometer system, and optics) was retained as part of the system. An existing Hewlett Packard computer was replaced with a personal computer to accommodate the <b>frame</b> <b>grabber</b> board. Each component was integrated into the existing system using Visual Basic. The system was automated for unattended measurements by creating a machine programming language, which is recognized within the main program...|$|R
