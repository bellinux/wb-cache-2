224|116|Public
25|$|Barefoot v. Estelle, 463 U.S. 880 (1983), is a United States Supreme Court case. The Court {{ruled on}} the {{admissibility}} of clinical opinions given by two psychiatrists {{hired by the}} prosecution in answer to hypothetical questions regarding the defendant's future dangerousness and the likelihood that he would present a continuing threat to society in this Texas death penalty case. The American Psychiatric Association submitted an amicus curiae brief {{in support of the}} defendant's position that such testimony should be inadmissible and urging curtailment of psychiatric testimony regarding future dangerousness and a prohibition of such testimony based on <b>hypothetical</b> <b>data.</b>|$|E
5000|$|Many {{contemporary}} statistical disclosure control techniques, such as generalization {{and cell}} suppression, {{have been shown}} to be vulnerable to attack by a <b>hypothetical</b> <b>data</b> intruder. For example, Cox showed in 2009 that Complementary cell suppression typically leads to [...] "over-protected" [...] solutions because of the need to suppress both primary and complementary cells, and even then can lead to the compromise of sensitive data when exact intervals are reported.|$|E
50|$|Barefoot v. Estelle, 463 U.S. 880 (1983), is a United States Supreme Court case. The Court {{ruled on}} the {{admissibility}} of clinical opinions given by two psychiatrists {{hired by the}} prosecution in answer to hypothetical questions regarding the defendant's future dangerousness and the likelihood that he would present a continuing threat to society in this Texas death penalty case. The American Psychiatric Association submitted an amicus curiae brief {{in support of the}} defendant's position that such testimony should be inadmissible and urging curtailment of psychiatric testimony regarding future dangerousness and a prohibition of such testimony based on <b>hypothetical</b> <b>data.</b>|$|E
50|$|Universal memory {{refers to}} a <b>hypothetical</b> {{computer}} <b>data</b> storage device combining the cost benefits of DRAM, the speed of SRAM, the non-volatility of flash memory along with infinite durability. Such a device, if it ever becomes possible to develop, would have a far-reaching impact on the computer market.|$|R
3000|$|... (higher for the {{sequential}} {{procedure in}} this <b>hypothetical</b> example), the <b>data</b> would support that model even though empirical discriminability (pAUC) {{goes in the}} opposite direction.|$|R
40|$|In recent years, {{consumer}} choice {{has become}} {{an important element of}} public policy. One reason is that consumers differ in their tastes and needs, which they can express most easily through their own choices. Elements that strengthen consumer choice feature prominently in the design of public insurance markets, for instance in the United States in the recent introduction of prescription drug coverage for older individuals via Medicare Part D. For policy makers who design such a market, an important practical question in the design phase of such a new program is how to deduce enrollment and plan selection preferences prior to its introduction. In this paper, we investigate whether hypothetical choice experiments can serve as a tool in this process. We combine <b>data</b> from <b>hypothetical</b> and real plan choices, elicited {{around the time of the}} introduction of Medicare Part D. We first analyze how well the <b>hypothetical</b> choice <b>data</b> predict willingness to pay and market shares at the aggregate level. We then analyze predictions at the individual level, in particular how insurance demand varies with observable characteristics. We also explore whether the extent of adverse selection can be predicted using <b>hypothetical</b> choice <b>data</b> alone. ...|$|R
5000|$|On May 29, 2015, LaCour {{uploaded}} {{a response}} to the criticisms. LaCour admitted to some false statements and apologized for [...] "misrepresenting survey incentives and funding," [...] but denied intentionally falsifying the data itself (though he stated that he could not {{rule out the possibility that}} he had [...] "mistakenly mixed up" [...] <b>hypothetical</b> <b>data</b> with collected data). He disputed the timeline of events presented in Broockman et al. (2015). He argued that the failure of Broockman et al. to replicate LaCour and Green (2014) was likely the result of a failure to follow the respondent-driven sampling procedure used in LaCour and Green (2014). He stated that Broockman et al. had selected the [...] "incorrect variable" [...] from CCAP (2012) and then manipulated that variable to make the distribution look more like that in LaCour and Green (2014). LaCour claimed that when the [...] "correct" [...] variable is used, the distributions between the CCAP thermometer and the LaCour and Green (2014) thermometer are statistically distinguishable. LaCour said, [...] "selecting the incorrect variable may have been an oversight, but further manipulating that variable to make the distribution look more like LaCour and Green (2014) is a curious and possibly intentional 'error.'" [...] LaCour also claimed that an independent replication supported the main finding reported in LaCour and Green (2014).|$|E
40|$|In {{this paper}} {{we show that}} <b>hypothetical</b> <b>data</b> bases can be {{effectively}} supported by slight extensions to conventional view support mechanisms. Moreover, we argue that the resulting structure may well be quite efficient {{and that there are}} advantages to making <b>hypothetical</b> <b>data</b> bases central to the operation of a DBMS. ...|$|E
3000|$|... [...]. To {{the extent}} that the {{assumptions}} of the model are accurate, the estimate of underlying discriminability is also accurate. We actually generated the <b>hypothetical</b> <b>data</b> shown in Table 1 using the equal-variance model shown in Fig. 2 (with d' [...]...|$|E
40|$|An {{experimental}} rule-based {{system for}} optimizing user spacecraft communications configurations was developed at NASA to support mission planning for spacecraft that obtain telecommunications services through NASA's Tracking and Data Relay Satellite System. Designated Expert for Communications Configuration Optimization (ECCO), and {{implemented in the}} OPS 5 production system language, the system has shown the validity of a rule-based systems approach to this optimization problem. The development of ECCO and the incremental optimizatin method on which it is based are discussed. A test case using <b>hypothetical</b> mission <b>data</b> is included to demonstrate the optimization concept...|$|R
40|$|The aim of {{this study}} is to {{investigate}} about perceive differences among accounting students between auditors ethical dilemma in accounting. Two hundred and twenty eight respondents were participated in this research. Ethical perceived are measured by Multidimensional Ethics Scale with tens ethics 2 ̆ 7 characteristic from 5 constructs. Ethical dilemma in accounting is measured by two <b>hypothetical</b> cases. <b>Data</b> was analysis with independent t-test. These results showed there are differences among accounting students between auditors. The implications of the study are to increasing content of ethic in accounting curricula...|$|R
5000|$|The [...] "probability" [...] in {{coverage}} probability is interpreted {{with respect to}} a set of hypothetical repetitions of the entire data collection and analysis procedure. In these <b>hypothetical</b> repetitions, independent <b>data</b> sets following the same probability distribution as the actual data are considered, and a confidence interval is computed from each of these data sets; see Neyman construction.|$|R
40|$|Economists or econometricians use {{statistics}} to test economic theory, estimate the key parameters of a model, forecast {{the future and}} construct counterfactuals to simulate differ-ent policy scenarios and {{evaluate the effectiveness of}} different social programs. However, there are some fundamental difficulties in adapting statistical inferential tools to analyze economic data. In economics and most social sciences, one does not know the true data generating process. The data are not generated from laboratory setups. They are observed outcomes of the simultaneous working of many factors. Statistical inferences are obtained by postulating a <b>hypothetical</b> <b>data</b> generating process for the observed data. Given the inference is conditional on the <b>hypothetical</b> <b>data</b> generation process, validity of the infer-ence is conditional, conditional on the validity or close approximation of the <b>hypothetical</b> <b>data</b> generating process to the true data generating process. To avoid letting one’s prior dominate inference, there is a growing trend among economists to adopt the approach of letting data speak for itself. Statistical techniques using little prior information such as time series techniques of fitting a vector autoregressive form to a set of variables (e. g. Hsiao (1979, 1981), Sims (1980)) or estimating the relationships of a set of variables us...|$|E
40|$|The paper {{surveys the}} {{application}} of the stated preference technique to analyse freight transport demand. The objective is to identify the contribution of the analysis of <b>hypothetical</b> <b>data</b> to the understanding of freight transport markets as opposed to the results obtained by using observed, revealed preference data. 1...|$|E
30|$|We {{are aware}} that using data of real {{patients}} would be more interesting than simulation of <b>hypothetical</b> <b>data</b> of three patients. To overcome this shortage, we compare our results with those yielded by the model proposed by Ladynzinski et al. (Eq.  2), with k =  1.296  ×  10 − 9  l/(mmol * s).|$|E
50|$|One {{approach}} to risk assessment analysis of CST {{is to develop}} risk-analysis models that break the ‘‘process’’ of disease transmission into component parts. Processes and interactions {{that could lead to}} cross-species disease transmission are explicitly described as a <b>hypothetical</b> infection chain. <b>Data</b> from laboratory and field experiments is used to estimate the probability of each component, expected natural variation, and margins of error.|$|R
40|$|This article {{presents}} a new measure of chance-corrected interobserver agreement among multivariate ratings of many observers. Modifying an approach by Berry and Mielke, a new agreement measure is proposed. The important modificaton {{is to use}} the volume of simplex composed of data points as the disagreement masure. The proposed measure accounts agreement for multivariate interval observations among many observers. <b>Hypothetical</b> and real-life <b>data</b> sets are analyzed for illustrative purpose...|$|R
40|$|Objective: To {{identify}} {{key stakeholder}} preferences and priorities when considering a national healthcare-associated infection (HAI) surveillance programme {{through the use}} of a discrete choice experiment (DCE). Setting: Australia does not have a national HAI surveillance programme. An online web-based DCE was developed and made available to participants in Australia. Participants: A sample of 184 purposively selected healthcare workers based on their senior leadership role in infection prevention in Australia. Primary and secondary outcomes: A DCE requiring respondents to select 1 HAI surveillance programme over another based on 5 different characteristics (or attributes) in repeated <b>hypothetical</b> scenarios. <b>Data</b> were analysed using a mixed logit model to evaluate preferences and identify the relative importance of each attribute. Results: A total of 122 participants completed the survey (response rate 66...|$|R
40|$|We oer an {{algorithm}} for {{random generation}} of classier outputs with specied individual accuracies and pairwise dependencies. The outputs are binary vectors (correct/incorrect classication) for a <b>hypothetical</b> <b>data</b> set. The generated team output {{can be used}} to study the majority vote over multiple dependent classiers. Keywords: Multiple classier systems, ensemble diversity, dependency, Q statistic, output generating algorithm. ...|$|E
40|$|In this paper, {{we apply}} {{bootstrap}} methods to principal components. We use {{a set of}} <b>hypothetical</b> <b>data</b> to illustrate how the bootstrap methods can be employed in constructing confidence intervals dealing with the principal components analysis. We write a Mathematica program to handle the all process. Principle components analysis; Bootstrap; Bootstrap quantiles; Bootstrap, Confidence Intervals; Mathematica. ...|$|E
40|$|In this paper, a new Data Envelopment Analysis (DEA) model, {{which is}} {{restricted}} using correlation coefficients (the CCRCOR), was {{compared with the}} cross-efficiency evaluation model (the CEM) and some other models. We used two <b>hypothetical</b> <b>data</b> sets, which were generated by E. Thanassoulis (A comparison of regression analysis and data envel-opment analysis as alternative methods for performance assessments...|$|E
40|$|A {{three-dimensional}} ecoepidemiological {{model with}} delay is considered. We first investigate {{the existence and}} stability of the equilibria. We then study {{the effect of the}} time delay on the stability of the positive equilibrium. The existence of a Hopf bifurcation at the positive equilibrium is obtained through the study of an exponential polynomial equation with delay-dependent coefficients. Numerical simulation with a <b>hypothetical</b> set of <b>data</b> has been carried out to support the analytical findings...|$|R
40|$|Abstract. In this paper, a {{three-dimensional}} eco-epidemiological model with delay is considered. The {{stability of the}} two equilibria, the existence of Hopf bifurcation and the permanence are investigated. It is found that Hopf bifurcation occurs when the delay τ passes though a sequence of critical values. The estimation {{of the length of}} delay to preserve stability has also been calculated. Numerical simulation with a <b>hypothetical</b> set of <b>data</b> has been done to support the analytical findings. 1...|$|R
40|$|Abstract. We {{provide an}} {{interactive}} method for knowledge acquisition combining approaches from description logic and formal concept analysis. Based on present <b>data,</b> <b>hypothetical</b> rules are formulated and checked against a description logic theory. We propose an abstract framework (Logical Domain Exploration) {{for this kind}} of exploration technique before presenting a concrete instantiation: Relational Exploration. We give a completeness result and provide an overview about some application fields for our approach: machine learning, data mining, and ontology engineering. ...|$|R
40|$|<b>Hypothetical</b> <b>data</b> {{are used}} to {{illustrate}} calculations of sums of squares in the 2 -way crossed classification having unequal numbers of observations in the subclasses (unbalanced data) but all cells filled. Sums of squares are illustrated for the classical analyses of variance, for certain tests of hypotheses, and for certain restricted models that yield sums of squares usually found in other contexts. 1...|$|E
40|$|Several {{hypotheses}} {{have been}} suggested to account for spatial variations in the changing pattern of votes between elections. Unfortunately, data are not available to allow direct tests of these hypotheses. However, an entropy-maximizing procedure for providing the best estimates of the needed data is outlined, means of testing the hypotheses are suggested, {{and a set of}} analyses using a <b>hypothetical</b> <b>data</b> set are presented. ...|$|E
40|$|Least squares linear {{regression}} {{is a common}} tool in ecological research. One of the central assumptions of least squares {{linear regression}} is that the independent variable is measured without error. But this variable is measured with error whenever it is a sample mean. The significance of such contraventions is not regularly assessed in ecological studies. A simulation program was made to provide such an assessment. The program requires a <b>hypothetical</b> <b>data</b> set, and using estimates of S$ sp 2 $ it scatters the <b>hypothetical</b> <b>data</b> to simulate the effect of sampling error. A regression line is drawn through the scattered data, and SSE and r$ sp 2 $ are measured. This is repeated numerous times (e. g. 1000) to generate probability distributions for r$ sp 2 $ and SSE. From these distributions it is possible to assess the likelihood of the <b>hypothetical</b> <b>data</b> resulting in a given SSE or r$ sp 2 $. The method was applied to survey data used in a published TP-CHLa regression (Pace 1984). Beginning with a hypothetical, linear data set (r$ sp 2 $ = 1), simulated scatter due to sampling exceeded the SSE from the regression through the survey data about 30 % of the time. Thus chances are 3 out of 10 that the level of uncertainty found in the surveyed TP-CHLa relationship would be observed if the true relationship were perfectly linear. If this is so, more precise and more comprehensive models will only be possible when better estimates of the means are available. This simulation approach should apply to all least squares regression studies that use sampled means, and should be especially relevant to studies that use log-transformed values...|$|E
40|$|A common {{automatic}} seatbelt {{inertial sensor}} design, comprised of a constrained spherical pendulum, is modeled to study its motions and possible unintentional release during vehicle emergency maneuvers. The kinematics are derived {{for the system}} with the most general inputs: arbitrary pivot motions. The influence of forces due to gravity and constraint torque functions is developed. The equations of motion are then derived using Kane's method. The equations of motion are used in a numerical simulation with both actual and <b>hypothetical</b> automobile crash <b>data...</b>|$|R
40|$|In this paper, the {{dynamical}} {{behavior of}} an eco-epidemiological model with distributed delay is studied. Sufficient {{conditions for the}} asymptotical stability of all the equilibria are obtained. We prove that there exists a threshold value of the infection rate $b$ beyond which the positive equilibrium bifurcates towards a periodic solution. We further analyze the orbital stability of the periodic orbits arising from bifurcation by applying Poore's condition. Numerical simulation with some <b>hypothetical</b> sets of <b>data</b> {{has been done to}} support the analytical findings...|$|R
50|$|If the {{schizoaffective}} {{diagnosis is}} used less often, other diagnoses (like psychotic mood disorders and schizophrenia) {{are likely to}} be used more often; but this is <b>hypothetical</b> until real-world <b>data</b> arrive. Validity problems with the diagnosis remain and await further work in the fields of psychiatric genetics, neuroimaging, and cognitive science that includes the overlapping fields of cognitive, affective, and social neuroscience, which may change the way schizoaffective disorder is conceptualized and defined in future versions of the DSM and ICD.|$|R
40|$|The {{purpose of}} this paper is to {{demonstrate}} that the integration of locational considerations into product-diversification planning has the potential of supplying gains to the firm by providing hedges against both product-portfolio and location-portfolio risk. An efficient diversification frontier to region - product strategic planning is generated from <b>hypothetical</b> <b>data</b> for purposes of illustration. Results of the analysis are in agreement with Wahlroos's theory of the diversification of the firm. ...|$|E
40|$|We {{computer}} simulated a mark-recapture experiment {{where the}} population size, N, is known and the recapture frequencies follow the geometric distribution. Two methods described by Edwards and Eberhardt (l 967) -linear regression and maximum likelihood estimation (MLE) [...] were used with these <b>hypothetical</b> <b>data</b> to give estimates of N. The results were (1) regression gives biased estimates while MLE gives unbiased estimates; (2) both methods produce inaccurate confidence intervals for N...|$|E
40|$|Background: We {{describe}} {{an approach to}} estimating the cost-effectiveness of an intervention that changes health behaviour. The method captures the lifetime costs and benefits incurred by participants in an ongoing cluster-randomized controlled trial of an intervention that aims to change health behaviour. The existing literature only captures short-term economic and health outcomes. Methods: We develop a state-transition Markov model of how individuals move between different health behaviour states over time. We simulate <b>hypothetical</b> <b>data</b> to describe the costs and health benefits of the intervention, illustrate how the data collected in the ongoing randomized controlled trial can be used and demonstrate how incremental cost-effectiveness ratios are estimated. Results: On {{the basis of the}} simulated (i. e. <b>hypothetical)</b> <b>data,</b> we estimate the cost per quality-adjusted life year. The estimate reflects the lifetime health and economic consequences of the intervention. Discussion: The method used for the cost-effectiveness analysis described in this paper is appropriate for investigating whether interventions that change health behaviour in relation to chronic diseases represent good value for money as compared to alternative uses of scarce healthcare resources. No Full Tex...|$|E
40|$|A {{first order}} {{simulation}} {{analysis of the}} navigation accuracy expected from various Navigation Quick-Look data sets is performed. Here quick-look navigation data are observations obtained by <b>hypothetical</b> telemetried <b>data</b> transmitted on the fly during a Mars probe's atmospheric entry. In this simulation study, navigation data consists of 3 -axis accelerometer sensor and attitude information data. Three entry vehicle guidance types are studied: I. a Maneuvering entry vehicle (as with Mars 01 guidance where angle of attack and bank angle are controlled); II. Zero angle-of-attack controlled entry vehicle (as with Mars 98); and III. Ballistic, or spin stabilized entry vehicle (as with Mars Pathfinder);. For each type, sensitivity to progressively under sampled navigation data and inclusion of sensor errors are characterized. Attempts to mitigate the reconstructed trajectory errors, including smoothing, interpolation and changing integrator characteristics are also studied...|$|R
40|$|Much UK {{research}} and market practice on portfolio strategy and performance benchmarking {{relies on a}} sector‐geography subdivision of properties. Prior tests of the appropriateness of such divisions have generally relied on aggregated or <b>hypothetical</b> return <b>data.</b> However, the results found in aggregate may not hold when individual buildings are considered. This paper makes use of a dataset of individual UK property returns. A series of multivariate exploratory statistical techniques are utilised to test whether the return behaviour of individual properties conforms to their a priori grouping. The results suggest strongly that neither standard sector nor regional classifications provide a clear demarcation of individual building performance. This {{has important implications for}} both portfolio strategy and performance measurement and benchmarking. However, there do appear to be size and yield effects that help explain return behaviour at the property level...|$|R
40|$|In {{attempting}} {{to analyze the}} four-band IRAS images of interstellar dust emission, {{it is found that}} an inversion theorem recently developed by Chen (1990) enables distribution of the dust to be determined as a function of temperature and thus the total dust column density, for each line of sight. The method and its application to a <b>hypothetical</b> IRAS <b>data</b> set created by assuming a power-law dust temperature distribution, which is characteristic of the actual IRAS data for the Monoceros R 2 cloud, are reported. To use the method, the wavelength dependence of the dust emissivity is assumed and a simple function is fitted to the four intensity-wavelength data points. The method is shown to be very successful at retrieving the dust temperature distribution in this case and is expected to have wide applicability to astronomical problems of this type...|$|R
