22|8|Public
50|$|At {{least two}} {{units of the}} same type will be powered up, {{receiving}} {{the same set of}} inputs, performing identical computations and producing identical outputs in a nearly-synchronous manner. The outputs are typically physical outputs (individual ON/OFF type digital signals, or analog signals), or serial data messages wrapped in suitable protocols depending upon the nature of their intended use. Outputs from only one unit (designated as the master or on-line unit, via application logic) are used to control external devices (such as switches, signals, on-board propulsion/braking control devices, etc.) or simply to provide displays. The other unit is a hot-standby or a hot spare unit, ready to take over if the master unit fails. When the master unit fails, an automatic failover to the hot spare occurs within a very short time and the outputs from the hot spare, now the master unit, are delivered to the controlled devices and displays. The controlled devices and displays may experience a short blip or disturbance during the <b>failover</b> <b>time.</b> However, they can be designed to tolerate/ignore the disturbances so that the overall system operation is not affected.|$|E
40|$|SDN {{improves}} network flexibility {{which is}} constrained by network protocol {{in a conventional}} network by decoupling the control plane and the data plane of the network. This {{is the reason why}} many companies and universities migrate their network to SDN, there will be more SDN network in the future. Yet SDN network mainly depends on the controller in the control plane. Hence, SDN controller robustness becomes an important issue, because a controller failure will result to a network outage. OpenFlow is arguably the standard protocol for SDN network. Thus, it is necessary to investigate the robustness of the OpenFlow control plane. Several open source controllers such as OpenMul, Floodlight, Opendaylight, and ONOS have multiple controllers framework to tackle a controller failure. They provide failover mechanism, when there is a controller failure, a backup controller can take over to control the network. In this thesis a benchmark is conducted to measure how long the <b>failover</b> <b>time</b> of those open source controllers. Unfortunately their <b>failover</b> <b>time</b> is in order of seconds, which is way higher than 50 ms, the acceptable standard of carrier-grade recovery time. This thesis presents a solution that can improve SDN robustness: A Controller Robustness and Distribution Framework (ACRoDiF). ACRoDiF is compatible with several open source OpenFlow controllers such as Ryu, OpenMul, Floodlight, Opendaylight, and ONOS. ACRoDiF provides failover mechanism that has lower <b>failover</b> <b>time</b> than in the open source controllers: 76 ms. It can also eliminate <b>failover</b> <b>time</b> completely if using two active primary controllers...|$|E
40|$|A formal {{specification}} of primary-backup is presented. We then prove lower bounds {{on the degree}} of replication, <b>failover</b> <b>time,</b> and worst-case response time to client requests assuming different failure models. Finally, we outline primary-backup protocols and indicate which of our lower bounds are tight...|$|E
50|$|The Metro Ring Protocol (MRP) is a Layer 2 {{resilience}} protocol {{developed by}} Foundry Networks and currently being delivered in {{products manufactured by}} Brocade Communications Systems and Hewlett Packard. The protocol quite tightly specifies a topology in which layer 2 devices, usually {{at the core of}} a larger network, are configured and as such is able to achieve much faster <b>failover</b> <b>times</b> than other Layer 2 protocols such as Spanning Tree.|$|R
40|$|In this thesis, an {{overview}} on performed research {{is given to}} investigate possible enhancements and solutions to enable SDN as future network paradigm. Currently, beside robustness, problems exist on scalability and security with the application of SDN to current network infrastructures. On robustness, current research do not provide the necessary solutions to detect failures and activate protection schemes to failover to pre-configured backup paths within the set failover requirements. We will attempt {{to solve the problems}} to reduce the <b>failover</b> <b>times</b> on Ethernet IP networks with the application of active link monitoring and advanced capabilities of the OpenFlow protocol. To enable protection scheme, a routing algorithm is required that provides link-based protection. We propose a protection algorithm that guarantees protection, minimizes path cost on primary path and discovers protection paths for intermediate switches on the primary path with the main purpose to minimize <b>failover</b> <b>times,</b> optimize network traffic and reduce the need for crankback routing. In short, we provide a complete solution to increase the robustness of Ethernet IP networks to the level of carrier-grade and industrial networks with the application of a link-based protection scheme and optimal routing algorithm, combined into a Software Designed Networking solution. Network Architectures and ServicesIntelligent SystemsElectrical Engineering, Mathematics and Computer Scienc...|$|R
50|$|The Virtual Switch Redundancy Protocol (VSRP) is a {{proprietary}} network resilience protocol developed by Foundry Networks and currently being sold in {{products manufactured by}} both Brocade Communications Systems (formerly Foundry Networks) and Hewlett Packard. The protocol differs from many others in use as it combines Layer 2 and Layer 3 resilience - effectively doing the jobs of both Spanning tree protocol and the Virtual Router Redundancy Protocol at the same time. Whilst the restrictions on the physical topologies able {{to make use of}} VSRP mean that it is less flexible than STP and VRRP it does significantly improve on the <b>failover</b> <b>times</b> provided by either of those protocols.|$|R
40|$|We {{present a}} precise {{specification}} of the primary-backup approach. Then, {{for a variety}} of different failure models we prove lower bounds on the degree of replication, <b>failover</b> <b>time,</b> and worst-case blocking time for client requests. Finally, we outline primary-backup protocols and indicate which of our lower bounds are tight...|$|E
40|$|We {{present a}} formal {{specification}} of primary-backup. We then prove lower bounds {{on the degree}} of replication, <b>failover</b> <b>time</b> and worst-case response time to client requests assuming different failure models. Finally, we outline primary-backup protocols and indicate which of our lower bounds are tight. Keywords: Fault-tolerance, reliability, availability, primary-backup, lower bounds, optimal protocols...|$|E
40|$|This paper {{proposes a}} novel {{way to use}} virtual memory mapped {{communication}} (VMMC) to reduce the <b>failover</b> <b>time</b> on clusters. With the VMMC model, applications' virtual address space can be efficiently mirrored on remote memory either automatically or via explicit messages. When a machine fails, its applications can restart from the most recent checkpoints on the failover node with minimal memory copying and disk I/O overhead. This method requires little change to applications' source code. We developed two fast failover protocols: deliberate update failover protocol (DU) and automatic update failover protocol (AU). The rst can run on any system that supports VMMC, whereas the other requires special network interface support. We implemented these two protocols [...] ...|$|E
40|$|Voice over Internet Protocol (VoIP) {{applications}} {{are making their}} way into safety-critical environments. If voice data has to be transmitted in such environments, the connection must not fail and the network has to recover quickly. Additionally, the use of specialized systems that are tailored to a certain application is not a preferred solution. Instead, the use of commercial-off-the-shelf (COTS) hard- and software is required. This paper discusses the use of standardized hard- and software as well as network protocols to allow <b>failover</b> <b>times</b> {{within the range of}} milliseconds. A redundant end-system and its network coupling are presented. The Layer 3 protocol OSPF and the combination of OSPF with the protocol-independent Hello protocol BFD are investigated to fulfil...|$|R
40|$|Fault {{tolerance}} schemes {{can be used}} {{to increase}} the availability and reliability of network services. One aspect of such schemes is service failover — the reconfiguration of available resources and restoration of state required to continue providing the service despite the loss of some of the resources and corruption of parts of the state. We have previously presented CoRAL, a fault tolerance scheme for Web service based on a redundant standby backup server and logging. The focus of this paper is the implementation and evaluation of client-transparent failover for this scheme. In the event of a primary server failure, active client connections failover to a spare where their processing continues seamlessly. If extra server resources are available, a new server can be reintegrated into the system to reestablish fault-tolerant operation. Our performance results indicate short <b>failover</b> <b>times</b> and low overhead during fault-free operation...|$|R
40|$|Abstract—OpenFlow is {{expected}} to be an enabler that solves the problems of today’s network. Thanks to the centralized management with OpenFlow, agile network operation can be achieved with flexible programmability; however, the centralized management implies a significant impact of any outages of the OpenFlow controller. Hence, a high availability technology is indispensable for building the OpenFlow controller, and the high availability system should consider extraordinary events (e. g., power outage) affecting the entire data center as well as anticipated server failures within a local system. In this paper, the high-availability of the OpenFlow controller is investigated, and a redundant method considering both local and global (i. e., inter data-center) recoveries is proposed by using the multiple-controllers functionality that is defined in OpenFlow switch specification version 1. 2 and later. The proposed redundant scheme eliminates frontend server causing limitation of performance scalability, while it achieves competitive role change and <b>failover</b> <b>times.</b> Keywords-OpenFlow; controller; redundancy. I...|$|R
40|$|This article {{describes}} an architecture {{that allows a}} replicated service to survive crashes without breaking its TCP connections. Our approach does not require modifications to the TCP protocol, to the operating system on the server, or {{to any of the}} software running on the clients. Furthermore, it runs on commodity hardware. We compare two implementations of this architecture – one based on primary/backup replication and another based on message logging – focusing on scalability, <b>failover</b> <b>time,</b> and application transparency. We evaluate three types of services: a file server, a web server, and a multimedia streaming server. Our experiments suggest that the approach incurs low overhead on throughput, scales well as the number of clients increases, and allows recovery of the service in near-optimal time...|$|E
40|$|When using primary-backup replication, one checkpoints the primary’s {{state to}} reduce the <b>failover</b> <b>time</b> to a backup, upon failure of the primary. A {{trade-off}} is involved: by frequent checkpointing the response time for requests during “no-failure ” intervals is increased. On the other hand, when checkpointing frequency is low, failover takes longer. In this paper ¢ we provide a theoretical ground for computing the optimal checkpointing interval that minimizes the average response time of requests, given parameters such as load, failure rate and service rates. We use queuing theory for modelling the support for failover in a system where a logging server records client update operations. The novelty of the model is inclusion of the backlog processing time for requests accumulated during failover. Also, our model considers the waiting times in the queue of the logging server {{as well as the}} application server. ...|$|E
40|$|In {{a recent}} paper [2] we have {{proposed}} FT-TCP: an architecture {{that allows a}} replicated service to survive crashes without breaking its TCP connections. FT-TCP is attractive in principle {{because it does not}} require modifications to the TCP protocol and does not affect any of the software running on the clients; however, its practicality for realworld applications remains to be proven. In this paper, we report on our experience in engineering FT-TCP for two such applications—the Samba file server and a multimedia streaming server from Apple. We compare two implementations of FT-TCP, one based on primary-backup and another based on message logging, focusing on scalability, <b>failover</b> <b>time,</b> and application transparency. Our experiments suggest that FT-TCP is a practicable approach for replicating TCP/IP-based services that incurs low overhead on throughput, scales well as the number of clients increases, and allows recovery of the service in near-optimal time. ...|$|E
40|$|Abstract—OpenFlow is an {{important}} element for achieving Software Defined Networking (SDN) {{and is expected to}} be an enabler that solves the problems of today’s network. Thanks to the centralized management with OpenFlow, agile network operation can be achieved with flexible programmability; how-ever, the centralized management implies a significant impact of any outages of the OpenFlow controller. Hence, a high availability technology is indispensable for building the Open-Flow controller. To achieve the highly available system, we have to consider extraordinary events (e. g., power outage) af-fecting the entire data center as well as anticipated server fail-ures within a local system. In this paper, we review the issue in using the conventional redundancy method for OpenFlow con-trollers. Based on this observation, we propose a redundancy method considering both local and global (i. e., inter data-center) recoveries using the multiple-controllers capability that is defined in OpenFlow switch specification version 1. 2 and later. The proposed redundancy scheme eliminates virtual IP address-based redundancy and frontend server causing limita-tion of performance scalability, while it achieves competitive role change and <b>failover</b> <b>times.</b> Keywords-OpenFlow; controller; redundancy. I...|$|R
50|$|Normally, two System Service Processors {{were used}} per platform. One was {{configured}} as Main {{and the other}} as Spare. Only the SSP {{in the role of}} Main, could control the platform at any given <b>time.</b> <b>Failover</b> between Main and Spare was performed automatically by the SSP software.|$|R
40|$|Popular Web {{sites such}} as Google and Facebook must have an {{extremely}} large clients and providing such clients only with a single Web server is absolutely insufficient. To support service availability, two or more servers are required. This, however, needs a load balancing system. A load balancing server receives Web traffic and distributes the requests to such multiple servers. Load balancing can be implemented with special hardware, software {{or a combination of}} both. The purpose of this research is to develop a load balancing system with HAProxy as a software-based load balancer and Heartbeat as failover software and provides comparisons of the performance of several balancing algorithms on it. The results show that without a load balancer, the load cannot equally be distributed. The system average <b>failover</b> <b>time</b> when an active server down is 10 ms. The Leastconn algorithm, in general, outperformed the Round-Robin and Source algorithms in terms of connection rate, response time, throughput, and failed connection...|$|E
40|$|Availability in Process Support Systems (PSS) can be {{achieved}} by using standby mechanisms that allow a backup server to take over in case a primary server fails. These mechanisms, resembling the process pair approach used in operating systems, require the primary to send information about state changes to the backup on a regular basis. In PSS where all relevant state information is stored in a database, there are two principal strategies for synchronizing a primary [...] backup pair. One is to use the replication mechanisms provided by the DBMS. Another is to implement a message mechanism to exchange state information between servers above the database level. For both approaches, several variants exist that allow to trade run-time performance for <b>failover</b> <b>time.</b> This paper discusses the possible strategies and evaluates their performance based on an implementation within the OPERA process support kernel. Moreover, it is shown how the mechanisms can be used as the basis for implementing process migration in a distributed setting...|$|E
40|$|This paper {{presents}} {{a new approach}} to developing high availability (HA) server using Rapid Spanning Tree Algorithm and Protocol (RSTP) as specified in the IEEE 802. 1 w standard. The traditional approach requires the use of multiple IP addresses and complex management software to monitor multiple links. If there is a link failure, the management software requires to perform complex fail-over functions, including IP address binding, maintenance of stability and integrity of active applications, and synchronization of ARP tables on all clients. This new approach, built on RSTP, is 100 % transparent to applications and clients, and does not require any management software. Most importantly, the <b>failover</b> <b>time</b> and fall-back time is less than one second. We conducted extensive STP and RSTP experiments in the lab to prove the concept and demonstrate the functionality, and ran an RSTP simulation to demonstrate its performance (measured in fail-over time and fall-back time) for several failure scenarios...|$|E
40|$|We give primary [...] backup {{protocols}} {{for various}} models of failure. These protocols are optimal {{with respect to}} degree of replication, <b>failover</b> <b>time,</b> and response time to client requests. 1 Introduction One way to implement a fault-tolerant service is to employ multiple sites that fail independently. The state of the service is replicated and distributed among these sites, and updates are coordinated so that even when {{a subset of the}} sites fail, the service remains available. A common approach to structuring such replicated services is to designate one site as the primary and all the others as backups. Clients make requests by sending messages only to the primary. If the primary fails, then a failover occurs and one of the backups takes over. This service architecture is commonly called the primary-backup or the primary-copy approach [1]. In [5] we give lower bounds for implementingprimary-backup protocols under various models of failure. These lower bounds constrain the degree of [...] ...|$|E
40|$|Supporting high {{availability}} by checkpointing and {{switching to a}} backup upon failure of a primary has a cost. Trade-off studies help system architects to decide whether higher availability {{at the cost of}} higher response time is to strive for. The decision will lead to configuring a faulttolerant server for best performance. This paper provides a mathematical model employing queuing theory that helps to compute the optimal checkpointing interval for a primarybackup replicated server. The optimization criterion is system availability. The model guides towards the checkpointing interval that is short enough to give low <b>failover</b> <b>time,</b> but long enough to utilize most of the system resources for servicing client requests. The novelty of the work is the detailed modelling of service times, wait times for earlier calls in the queue, and priority of checkpointing calls over client calls within the queues. Studies on the model in Mathematica and validation of a modelling assumption through simulations are included. ...|$|E
40|$|Software-defined {{networking}} (SDN) offers {{greater flexibility}} than traditional distributed architectures, {{at the risk}} of the controller be-ing a single point-of-failure. Unfortunately, existing fault-tolerance techniques, such as replicated state machine, are insufficient to en-sure correct network behavior under controller failures. The chal-lenge is that, in addition to the application state of the controllers, the switches maintain hard state that must be handled consistently. Thus, it is necessary to incorporate switch state into the system model to correctly offer a “logically centralized ” controller. We introduce Ravana, a fault-tolerant SDN controller platform that processes the control messages transactionally and exactly once (at both the controllers and the switches). Ravana maintains these guarantees in the face of both controller and switch crashes. The key insight in Ravana is that replicated state machines can be ex-tended with lightweight switch-side mechanisms to guarantee cor-rectness, without involving the switches in an elaborate consensus protocol. Our prototype implementation of Ravana enables unmod-ified controller applications to execute in a fault-tolerant fashion. Experiments show that Ravana achieves high throughput with rea-sonable overhead, compared to a single controller, with a <b>failover</b> <b>time</b> under 100 ms. ...|$|E
40|$|In {{this paper}} we propose the use of multi-topology (MT) routing to achieve fault {{tolerance}} against failures of network elements which is also called network resilience. The shortest path routing trees seen from any node {{is calculated based on}} the link costs. To provide different routing topologies, an n-dimensional vector of different costs is provided for each link in the network and allows for the calculation of n different routing topologies. We suggest to set these vectors {{in such a way that}} any node has a valid path to any other destination in case of a link or router failure. If a router recognizes the outage of an interface, it can switch the traffic from a broken routing topology to a valid routing topology which leads to a very fast reaction time to failures. The <b>failover</b> <b>time</b> can be compared with MPLS solutions that are based on explicit routing. However, we change the implementation of MT routing also in such a way that the new concept is still based on the shortest path convergence mechanism. This offers the potential to maintain the robustness of the Internet routing in case of multiple failures...|$|E
40|$|The Stream Control Transmission Protocol (SCTP) was {{developed}} to support the transfer of telephony signaling over IP networks. One of the ambitions when designing SCTP was to offer a robust transfer of traffic between hosts. For this reason SCTP was designed to support multihoming, which gives the possibility to set up several paths between the same hosts in the same session. If the primary path between a source machine and a destination machine breaks down, the traffic may still {{be sent to the}} destination by utilizing one of the alternate paths. The failover that occurs when changing path is to be transparent to the application. Consequently, the time between occurrence of a break on the primary path until the traffic is run smoothly on one of the alternate paths is important. This paper presents experimental results concerning SCTP failover performance. The focus in this paper is to evaluate the impact of the SACK delay and link delay on the <b>failover</b> <b>time</b> {{as well as on the}} maximum transfer time for a single message, which complements earlier studies in this area. The results show a significant performance impact of the SACK delay as well as of the link delay. This suggests that the SACK delay is an important parameter to tune to enhance application transparency in failure situations...|$|E
40|$|More {{and more}} {{so-called}} soft real-time traffic is being sent over IP-based networks. The bursty, data-limited traffic pattern {{as well as}} the latency requirements from this traffic present challenges to the traditional communication techniques, designed for bulk traffic without considering latency. To meet the requirements from soft real-time traffic, in particular from telephony signaling, the Stream Control Transmission Protocol (SCTP) was designed. Its support for connectivity to multiple networks, i. e., multihoming, provides robustness and opens up for concurrent multipath transfer (CMT) over multiple paths. Since SCTP is a general transport protocol, it also enables for handover of media sessions between heterogeneous networks. Migrating an ongoing session to a new network, as well as CMT with minimal latency, requires tuning of several protocol parameters and mechanisms. This thesis addresses latency reduction for soft real-time traffic using SCTP multihoming from three perspectives. The first focus is on latency for signaling traffic in case of path failure, where a path switch, a failover, occurs. We regard quick failure detection as well as rapid startup on the failover target path. The results indicate that by careful parameter tuning, the <b>failover</b> <b>time</b> may be significantly reduced. The second focus in the thesis is on latency for signaling traffic using CMT. To this end, we address sender-side scheduling. We evaluate some existing schedulers, and design a dynamic stream-aware scheduler. The results indicate that the dynamic stream-aware scheduler may provide significantly improved latency in unbalanced networks. Finally, we target multihomed SCTP to provide for handover of a media session between heterogeneous wireless networks in a mobile scenario. We implement a handover scheme and our investigation shows that SCTP could provide for seamless handover of a media session at walking speed. So-called soft real-time traffic may be sent over IP-based networks. The bursty, data-limited traffic pattern and the latency requirements from this traffic present a challenge to traditional communication techniques. The Stream Control Transmission Protocol (SCTP), with support for multihoming, was designed to better meet the requirements from soft-real time traffic. Multihoming provides for robustness and for concurrent multipath transfer (CMT) as well as for handover of sessions between heterogeneous networks. Still, to meet the timeliness requirements, tuning of protocol parameters and mechanisms is crucial. This thesis addresses latency reduction for soft real-time traffic using SCTP multihoming. The first focus is on signaling traffic in case of path failure, where a path switch, a failover, occurs. We show that careful parameter tuning may reduce the <b>failover</b> <b>time</b> significantly. The second focus is on signaling traffic using CMT. We address sender-side scheduling and show that dynamic stream-aware scheduling may reduce latency when data is transmitted over asymmetric network  paths. The third focus is multihomed SCTP for handover between heterogeneous networks, where we show that SCTP could provide for seamless handover of a media session at walking speed. Paper 3 (Efficient Scheduling to Reduce Latency [...] .) ingick i avhandlingen som manuskript med samma namn. </p...|$|E
40|$|This paper {{proposes a}} novel {{way to use}} virtual memory-mapped {{communication}} (VMMC) to reduce the <b>failover</b> <b>time</b> on clusters. With the VMMC model, applications ’ virtual address space can be efficiently mirrored on remote mem-ory either automatically or via explicit messages. When a machine fails, its applications can restart from the most re-cent checkpoints on the failover node with minimal memory copying and disk I/O overhead. This method requires little change to applications ’ source code. We developed two fast failover protocols: deliberate update failover protocol (DU) and automatic update failover protoco 2 (AU). The first can run on any system that supports VMMC, whereas the other requires special network interface support. We implemented these two protocols on two different clusters that supported VMMC communication. Our re-sults with three transaction-based applications show that both protocols work quite well. The deliberate update pro-tocol imposes 4 - 21 % overhead when taking checkpoints ev-ery 2 seconds. If an application can tolerate 20 % overhead, this protocol can failover to another machine within 4 mil-liseconds in the best case and from 0. 1 to 3 seconds in the worst case. The failover performance can be further im-proved by using special network interface hardware. The automatic update protocol is able to take checkpoints every 0. 1 seconds with only 3 - 12 % overhead. If 10 % overhead is allowed, it can failover applications from 0. 01 to 0. 4 seconds in the worst case. ...|$|E
40|$|The {{most widely}} used {{approach}} to building replicated, fault-tolerant services is the primary-backup approach. In this approach, {{the state of the}} service is replicated across multiple servers, with one server designated as the primary and the rest as backups. Clients send requests only to the primary. However, in case the primary fails, one of the backups takes over as the new primary. Ever since it was introduced in 1976 by Alsberg and Day, the primary-backup approach has become the basis for building many practical fault-tolerant services. However, despite the widespread use, the approach has not been studied systematically, and little is known of the fundamental costs and tradeoffs of using the approach under various kinds of failures. Thus, there is a gap between theory and practice. In order to close this gap, this thesis analyzes the primary-backup approach, both from the theoretical perspective of specification, lower bounds and upper bounds, {{as well as from the}} practical viewpoint of performance tradeoffs in protocols. We identify three key cost metrics of primary-backup protocols [...] degree of replication, blocking time and <b>failover</b> <b>time</b> [...] and then show lower and upper bounds on these metrics for a hierarchy of failure models. We then implement an important subclass of our primary-backup protocols, called 0 -blocking protocols, and give performance figures. In addition to leading to the development of new, more efficient protocols, we believe that the work in this thesis has resulted in a better understanding of the properties of existing primary-backup protocols...|$|E
40|$|This thesis puts {{forward a}} new {{solution}} {{to provide the}} reliable network to the Internet Service Provider (ISP). This study mainly focuses on the ISPs network to provide reliability and the load balancing. It offers a guide line for the best reliable solution to the ISPs, individual organizations or other types of service providers which are engaged in providing reliable communications to their subscribers. These reliable services may be real time communications which include weather forecasts, tracking systems, online Internet protocol TV (IPTV) programs and many other ISPs services which are totally depend on the reliable network. With the appearance and expansion of Internet subscribers all over the world, ISPs services are becoming more popular. The rapid increase of connection-demand and highly traffic network {{is the main reason}} behind the need to scale reliable network. To offer better solutions, a new theoretical and practical approach should be considered that can cover the reliable network. The suggested network structure monitors the links, spreads the network traffic with multiple devices and takes a backup (redundant) link automatically when changes occur in the network topology. In order to support the redundancy, load balancing and reduce the <b>failover</b> <b>time,</b> the hot standby routing protocol (HSRP) is implemented on the suggested network. As we have analyzed that in any network, scalability bringing to raised the network traffic broadcast issue. Broadcast storms can be prevented by setting threshold values of traffic-filters. The threshold level helps to control broadcast traffic in networks. With regard to suggested solutions, it is necessary to observe the limitations and advantages of the recommended reliable network structure. Therefore, this research will include the advantages and limitations of the techniques used to offer ISP services such as scalability, security and IPv 6...|$|E

