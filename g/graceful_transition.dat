19|21|Public
60|$|An {{accessibility}} to {{the sentiments of}} others on subjects of importance often accompanies feeble minds, yet {{it is not the}} less a true and constituent part of practical greatness, when it exists wholly free from that passiveness to impression which renders counsel itself injurious to certain characters, and from that weakness of heart which, in the literal sense of the word, is always craving advice. Exempt from all such imperfections, say rather in perfect harmony with the excellences that preclude them, this openness to the influxes of good sense and information, from whatever quarter they might come, equally characterised both Lord Nelson and Sir Alexander Ball, though each displayed it in the way best suited to his natural temper. The former with easy hand collected, as it passed by him, whatever could add to his own stores, appropriated what he could assimilate, and levied subsidies of knowledge from all the accidents of social life and familiar intercourse. Even at the jovial board, and in the height of unrestrained merriment, a casual suggestion, that flashed a new light on his mind, changed the boon companion into the hero and the man of genius; and with the most <b>graceful</b> <b>transition</b> he would make his company as serious as himself. When the taper of his genius seemed extinguished, it was still surrounded by an inflammable atmosphere of its own, and rekindled at the first approach of light, and not seldom at a distance which made it seem to flame up self-revived. In Sir Alexander Ball, the same excellence was more an affair of system; and he would listen, even to weak men, with a patience, which, in so careful an economist of time, always demanded my admiration, and not seldom excited my wonder. It was one of his maxims, that a man may suggest what he cannot give; adding, that a wild or silly plan had more than once, from the vivid sense or distinct perception of its folly, occasioned him to see what ought to be done in a new light, or with a clearer insight. There is, indeed, a hopeless sterility, a mere negation of sense and thought, which, suggesting neither difference nor contrast, cannot even furnish hints for recollection. But on the other hand, there are minds so whimsically constituted, that they may sometimes be profitably interpreted by contraries, a process of which the great Tycho Brahe is said to have availed himself {{in the case of the}} little Lackwit, who used to sit and mutter at his feet while he was studying. A mind of this sort we may compare to a magnetic needle, the poles of which have been suddenly reversed by a flash of lightning, or other more obscure accident of nature. It may be safely concluded, that to those whose judgment or information he respected, Sir Alexander Ball did not content himself with giving access and attention. No! he seldom failed of consulting them whenever the subject permitted any disclosure; and where secrecy was necessary, he well knew how to acquire their opinion without exciting even a conjecture concerning his immediate object.|$|E
5000|$|It {{would be}} a good {{exercise}} in Green Theory to consider Derrick Jensen's [...] "Twenty Premises" [...] from his books [...] "Endgame: Volumes I & II" [...] (2006) with [...] "Agenda 21" [...] and its efforts to control humanity and the environment to produce security. Is a <b>graceful</b> <b>transition</b> from the present world to a greener future world possible? How possible? ...|$|E
5000|$|With the 1954 hit [...] "Little Things Mean a Lot", she {{was voted}} {{the most popular}} female singer in Billboard and Variety polls. AllMusic called the {{recording}} a [...] "monster hit", and music historian Jonny Whiteside said the song [...] "ably characterizes Kallenâ€™s impressive, and <b>graceful,</b> <b>transition</b> from classic big band swing to modern post-war pop." [...] She followed up the song with [...] "In the Chapel in the Moonlight", another million selling record, and a version of [...] "True Love" [...] for Decca.|$|E
25|$|A {{defining}} {{characteristic of}} acro is the smooth, <b>graceful</b> <b>transitions</b> between dance and acrobatic movements. Also, a dance must have {{a significant percentage of}} dance movement, with respect to its acrobatic content, in order for it to be categorized as acro. For example, a gymnastics floor exercise is not considered to be acro because it has little or no dance movement compared to its acrobatic content, and also because it lacks smooth transitions between dance and gymnastic movements.|$|R
40|$|We present MemEC, an erasure-coding-based in-memory {{key-value}} (KV) {{store that}} achieves high availability and fast recovery while keeping low data redundancy across storage servers. MemEC is {{specifically designed for}} workloads dominated by small objects. By encoding objects in entirety, MemEC is shown to incur 60 % less storage redundancy for small objects than existing replication- and erasure-coding-based approaches. It also supports <b>graceful</b> <b>transitions</b> between decentralized requests in normal mode (i. e., no failures) and coordinated requests in degraded mode (i. e., with failures). We evaluate our MemEC prototype via testbed experiments under read-heavy and update-heavy YCSB workloads. We show that MemEC achieves high throughput and low latency in both normal and degraded modes, and supports fast transitions between the two modes. Comment: Accepted by SYSTOR 201...|$|R
40|$|A {{generalized}} second law in string cosmology {{accounts for}} geometric and quantum entropy {{in addition to}} ordinary sources of entropy. The proposed generalized second law forbids singular string cosmologies, under certain conditions, and forces a <b>graceful</b> exit <b>transition</b> from dilaton-driven inflation by bounding curvature and dilaton kinetic energy...|$|R
5000|$|Jones made a <b>graceful</b> <b>transition</b> to the NBA {{with the}} ABA-NBA merger in June 1976, {{as did the}} rest of the Nuggets. Denver shocked the more {{established}} circuit by winning the Midwest Division that season and the next year as well. Thompson was an offensive machine, and Jones made solid contributions {{at both ends of the}} floor. In 1976-77 he averaged a career-high 15.1 points, ranked third in the league with a [...]570 field-goal percentage, and played in his first NBA All-Star Game. He also outpolled all other players in earning the first of eight straight selections to the NBA All-Defensive First Team. The following season Jones averaged 14.5 points, elevated his field-goal percentage to a league-leading [...]578, and returned to the All-Star Game.|$|E
40|$|This memo {{provides}} {{information for the}} Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (1998). All Rights Reserved. This document describes methods and procedures for the <b>graceful</b> <b>transition</b> from an ATMARP LIS[1] to an NHRP LIS[2] network model over ATM...|$|E
40|$|Gaits {{have become}} an {{integral}} part of the design method of robots heading to complex terrains. But research into optimal ways to transition between different gaits is still lacking, and is the primary motivation behind this research. An essential characteristic of gaits is periodicity, and considering that a novel notion of <b>graceful</b> <b>transition</b> is proposed: a <b>graceful</b> <b>transition</b> is one that has maximally persisting periodicity. This particular notion of persistence in the characteristic behavior can be generalized. Therefore, a comprehensive framework for the general problem of connecting any two trajectories of a dynamical system, with an underlying characteristic behavior, over a finite time interval and in a manner that the behavior persists maximally during the transition, is developed and presented. This transition is called the Gluskabi Raccordation, and the characteristic behavior is defined by a kernel representation. Along with establishing this framework, the kernel representations for some interesting characteristic behaviors are also identified. The problem of finding the Gluskabi Raccordations is then solved for different combinations of characteristic behaviors and dynamical systems, and compact widely applicable results are obtained. Lastly, the problem of finding graceful gait transitions is treated within this newly established broader framework, and these graceful gait transitions are obtained for the case of a two-piece worm model. Ph. D...|$|E
40|$|A {{generalized}} second law in string cosmology {{accounts for}} geometric and quantum entropy {{in addition to}} ordinary sources of entropy. The proposed generalized second law forbids singular string cosmologies, under certain conditions, and forces a <b>graceful</b> exit <b>transition</b> from dilaton-driven inflation by bounding curvature and dilaton kinetic energy. Comment: 11 pages, 3 figure...|$|R
40|$|There {{have been}} many {{attempts}} to support awareness and lightweight interactions using video and audio, but few have been built on widely available infrastructure. Text-based systems have become more popular, but few support awareness, opportunistic conversations, and mobility, three important elements of helping distributed groups coordinate. We built on the popularity of text-based Instant Messengers (IM) by building a mobile IM called Hubbub that tries to provide all three, notably {{through the use of}} musical sounds. In a 5. 5 -month use study, we found that Hubbub helped people feel connected to others in different locations and supported opportunistic interactions. Sound was a useful cue for helping people feel connected, although some found it annoying. It was more important to support <b>graceful</b> <b>transitions</b> between multiple fixed locations than to support wireless access, although both were useful...|$|R
40|$|Under low {{illumination}} conditions, such as moonlight, {{there simply}} {{are not enough}} photons present to create a high quality color image with integration times that avoid camera-shake. Consequently, conventional imagers are designed for daylight conditions and modeled on human cone vision. Here, we propose a novel sensor design that parallels the human retina and extends sensor performance to span daylight and moonlight conditions. Specifically, we describe an interleaved imaging architecture comprising two collections of pixels. One set of pixels is monochromatic and high sensitivity; a second, interleaved set of pixels is trichromatic and lower sensitivity. The sensor implementation requires new image processing techniques that allow for <b>graceful</b> <b>transitions</b> between different operating conditions. We describe these techniques and simulate the performance of this sensor under a range of conditions. We show that the proposed system is capable of producing high quality images spanning photopic, mesopic and near scotopic conditions...|$|R
40|$|I {{discuss the}} most recent model of {{inflation}}. In first-order inflation the inflationary epoch {{is associated with a}} first-order phase transition, with the most likely candidate being GUT symmetry breaking. The transition from the false-vacuum inflationary phase to the true-vacuum radiation-dominated phase proceeds through the nucleation and percolation of true-vacuum bubbles. The first successful and simplest model of first-order inflation, extended inflation, is discussed in some detail: evolution of the cosmic-scale factor, reheating, density perturbations, and the production of gravitational waves both from quantum fluctuations and bubble collisions. Particular attention is paid to the most critical issue in any model of first-order inflation: the requirements on the nucleation rate to ensure a <b>graceful</b> <b>transition</b> from the inflationary phase to the radiation-dominated phase...|$|E
40|$|Recent {{advances}} in optical networking technologies are setting {{the foundation for}} the next-generation data-centric networking paradigm, an "Optical Internet". This work addresses one of the most challenging issues facing today's service providers and data vendors; how will the SONET/SDH-based legacy infrastructure currently in place make a <b>graceful</b> <b>transition</b> to the next generation networking paradigm? A simplied, two-tiered architecture that requires two types of sub-systems will {{set the stage for a}} truly optical internet: service delivery platforms that enforce service policies; and transport platforms that intelligently deliver the necessary bandwidth to these service platforms. IfIP can be mapped directly onto the WDM layer, some of the unnecessary network layers can be eliminated, opening up new possibilities for the potential of collapsing today's vertically layered network architecture into a horizontal model where all network elements work as peers to dynamically establish optical paths through the network. This paper presents a balanced view of the vision of the next-generation optical internet...|$|E
40|$|The Large Hadron Collider (LHC) {{is one of}} the {{greatest}} technological challenges ever faced by accelerator builders. It is due for commissioning in 4 years and will have a lifetime well in excess of 10. The LHC will contain a completely heterogeneous mixture of industrial controls, both hardware and software, as well as dedicated, specialised, â€˜home â€™ built systems. As part of the control infrastructure of such a complex machine, a number of â€˜services â€™ will be essential as aids during operation, such as: logging / archiving, post-mortem, sequences, alarm system, etc. This paper describes the approach to be taken in order to define and provide the alarm service necessary for LHC. Details will be given of: the <b>graceful</b> <b>transition</b> from the current LEP alarm system; accommodating the SPS, PS and CERNâ€™s technical services; the technologies to be used; the approach of parallel investigations of industrial and â€˜home â€™ built systems to ensure the best possible solution; and an indication of time scales to provide an operational system...|$|E
40|$|The <b>graceful</b> exit <b>transition</b> from a dilaton-driven inflationary phase to a {{decelerated}} Friedmann-Robertson-Walker era requires certain {{classical and}} quantum corrections to the string effective action. Classical corrections can stabilize a high curvature string phase while the evolution {{is still in}} the weakly coupled regime, and quantum corrections can induce violation of the null energy condition, allowing evolution towards a decelerated phase...|$|R
40|$|Intellectual history {{demands of}} itâ€™s {{students}} {{a variety of}} areas in which they must acquire proficiency. One must learn to achieve a measure of philosophical, political and literary modalities, and cultivate the flexibility required for making <b>graceful</b> <b>transitions</b> between them. In {{the tradition of the}} enlightened man of the eighteenth century, the intellectual historian cannot seek refuge through specialization, an eighteenth century concept of immaturity, but must be a â€˜man of all seasonsâ€™ in daring to confront the truth in its diversities and thereby attain maturity by accepting the responsibility of autonomy. Most of the major philosophies of the Enlightenment commanded many areas of erudition not necessarily re 1 ated to that field which occupied a majority of their attention or benefited their primary vocation. And so, to a large and admittedly uncomfortable extent, this notion of universality in knowledge is more often than not thrust upon the students of the Enlightenment along with the hopeful expectancy that they fare reasonably well...|$|R
40|$|A {{classical}} and quantum mechanical generalized second law of thermodynamics in cosmology implies {{constraints on the}} effective equation of state of the universe {{in the form of}} energy conditions, obeyed by many known cosmological solutions, and is compatible with entropy bounds which forbid certain cosmological singularities. In string cosmology the second law provides new information about the existence of non-singular solutions, {{and the nature of the}} <b>graceful</b> exit <b>transition</b> from dilaton-driven inflation...|$|R
40|$|International audienceContent-Centric Networking (CCN) is a {{promising}} data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making {{support for a}} broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since {{it has all the}} potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a <b>graceful</b> <b>transition</b> from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCNTV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies...|$|E
40|$|This memo {{provides}} {{information for the}} Internet community. It does not specify an Internet standard. Distribution of this memo is unlimited. 1 Summary The Internet is approaching {{a situation in which}} the current IP address space is no longer adequate for global addressing and routing. This is causing problems including: (i) Internet backbones and regionals are suffering from the need to maintain large amounts of routing information which is growing rapidly in size (approximately doubling each year); (ii) The Internet is running out of IP network numbers to assign. There is an urgent need to develop and deploy an approach to addressing and routing which solves these problems and allows scaling to several orders of magnitude larger than the existing Internet. However, it is necessary for any change to be deployed in an incremental manner, allowing <b>graceful</b> <b>transition</b> from the current Internet without disruption of service. [1] This paper describes a simple proposal which provides a long-term solution to Internet addressing, routing, and scaling. This involves a gradual migration from the current Internet Suite (which is based on Internet applications, running over TCP or UDP, running over IP) to an updated suit...|$|E
40|$|The {{construction}} grammar framework {{provides a}} rich formalism for {{the characterization of}} development in language acquisition, {{in part because it}} allows for a <b>graceful</b> <b>transition</b> from idiom-like holophrases, to fully abstract argument constructions. From the perspective of learning complexity, this means that rather than mastering the grammar used by an adult to generate or understand an utterance, the child can exploit more direct correspondences between fixed utterances and their meanings in the form of holophrases, and then progressively apply procedures for generalization in order to develop an abstract argument construction repertoire. The current chapter presents a neuro-computational model that addresses aspects of the construction grammar formalism, and uses this model to explain a possible trajectory from idiom-like holophrases to progressively more abstract argument constructions. The goal of the current research is thus to test a theory of form to meaning mapping that takes substantial input from the proposals of usage based construction grammar (Goldberg 1995, 1998; Croft 2001; Clark 2003, Tomasello 1999, 2003) analogical mapping from sentence to meaning (Fisher 1996), and cue coalitions that specify or identify the mappings (Bates et al. 1982). In particular, the model will provide a functional framework for analysis of th...|$|E
40|$|A {{classical}} and quantum mechanical generalized second law of thermodynamics in cosmology implies {{constraints on the}} effective equation of state of the universe {{in the form of}} energy conditions, obeyed by many known cosmological solutions, and is compatible with entropy bounds which forbid certain cosmological singularities. In string cosmology the second law provides new information about the existence of non-singular solutions, {{and the nature of the}} <b>graceful</b> exit <b>transition</b> from dilaton-driven inflation. Comment: 12 pages, no figure...|$|R
5000|$|Roads to Judah was {{met with}} {{generally}} positive reviews. Shane Mehling of Decibel gave the album an eight out of ten, and praised it for pushing the boundaries of black metal. He wrote that, [...] "This band produces long, incredibly beautiful black metal that, aside from the buried shrieks of the vocalist, doesn't have a drop of evil of noticeable malice, and that Deafheaven is, [...] "sure as hell doing a lot more with the genre than the newest batch of gauntlet-wearing Darkthrone worshipers." [...] Graham Scala of RVA Magazine wrote that Deafheaven's songs are, [...] "all a series of <b>graceful</b> <b>transitions</b> and dynamic shifts in timbre, rather than marathon blastbeat sessions or one effects-laden crescendo after another. This is a distinction which not only separates them from {{the majority of their}} contemporaries, but has provided the basis for a memorable and compelling release." [...] However, Alex Deller of Rock Sound gave the album a six out of ten stating that Deafheaven's blend of black metal and shoegaze wasn't [...] "an entirely new proposition" [...] and compared the album to the music of Liturgy.|$|R
40|$|A string {{cosmology}} scenario ("pre-big-bang") postulates {{that the}} evolution of the Universe starts from a state of very small curvature and coupling, undergoes a long phase of dilaton-driven kinetic inflation and at some later time joins smoothly standard radiation dominated cosmological evolution, thus giving rise to a singularity free inflationary cosmology. I report on recent progress in understanding some outstanding issues such as initial conditions, <b>graceful</b> exit <b>transition</b> and generation of inhomogeneity perturbations. Comment: 11 pages, 1 eps figure, Latex, based on talk at COSMO 9...|$|R
40|$|Godwin's Memoirs of Mary Wollstonecraft are {{a mixture}} of {{innovation}} and tradition in eighteenth-century life writing. In his readings of Hume, Gibbon, Johnson or Boswell, he would have found a philosophical approach to biography similar to his own. This approach implied a condensation of universal characteristics in the delineation of one single character, and an inextinguishable defence of the formative nature of all literature, inclusive of biography. The fact that Wollstonecraft had provided a variety of what the times considered scandals is of no matter to Godwin. Her mind and acts were in his view a consequence of her social and personal contingency - a view anchored in Political Justice - and it all could teach an example. My article shows how Godwin drank in the biographical tradition of his day, but also how his distinctive Dissenting insistence on detail, and his reckless adherence to truth - also remnants from Political Justice - marked his Memoirs of Mary Wollstonecraft as typical in his canon. I point also at the author's struggle with style, as his new awareness {{of the importance of}} sentiment and conversation, which he had expressed in 'Of History and Romance', imply a revision of his old pompous diction. Although alert to these changes, Godwin is not always capable of the <b>graceful</b> <b>transition</b> needed for the Memoirs of Wollstonecraft...|$|E
40|$|Language {{designers}} seem {{to regard}} R as an ugly, inefficient language and hence find its popularity mystifying. See, for example, (Cook, 2012; Morandat et al., 2012). I present four examples {{from my own}} work, two large data analyses problems in fisheries, and two more abstract programming examples. Hopefully these will be of intrinsic interest, but together they encapsulate why I think useRs find R so invaluable. My thesis is that good data analysis and modelling require the practitioner to engage interactively with data, and that at some level programming becomes essential to this. This {{is essentially the same}} message as that presented in Chambers (1998, 2008), and the same idea implicitly underlies (Venables and Ripley, 2002). The popularity of R is primarily due to the way it provides support for this activity, making near optimal trade-offs. This view is mostly consistent with Cook (2012) but there are some important differences. (The claim that R is necessarily ugly is also disputed!) Although R may be well suited to meet many contemporary data analysis problems, it will not remain so indefinitely. I do not attempt to answer the existential question posed in the title, but rather suggest it as one we should be thinking about, now. I will present some thoughts on a SWOT assessment for R, and suggest ways we might prepare for a <b>graceful</b> <b>transition</b> to whatever becomes the next phase. Such a new phase, or phases, will inevitably come as data analysis itself rapidly evolves in both scope and scale...|$|E
30|$|The {{mean time}} between event {{boundaries}} was 16.74 Â s (SD[*]=[*] 5.73 Â s) for the 19 event boundaries extracted from preparing breakfast, 27.21 Â s (SD[*]=[*] 20.55 Â s) for the 12 event boundaries for setting up for a party, and 19.69 Â s (SD[*]=[*] 6.21 Â s) for the 17 event boundaries for planting window boxes. The first and last coarse boundary units {{were removed from the}} analysis because participants universally identify the entrance and exit of the actor in the video as event boundaries. Still pictures of the event boundaries and event midpoints were extracted for preparing breakfast (n[*]=[*] 19), setting up for a party (n[*]=[*] 12), and planting window boxes (n[*]=[*] 17) movies. The midpoints were identified as the temporal midpoint between successive event boundaries. In the one second preceding each boundary, the movie was slowed to 50 % speed in order to provide a <b>graceful</b> <b>transition</b> to the freezing of the movie frame, followed by a one-second still frame at the event boundary. Concurrent with the still frame, a bell rang and the object that the actor was interacting with was cued with a red arrow. The movie resumed with another second of 50 % speed and then continued at the normal rate. In some cases, the object could not be cued precisely when the event boundary was identified due to occlusion of objects (e.g., a refrigerator door blocking the view of the object to be cued). In these cases (n[*]=[*] 16 or 33 % of the objects cued), the time point closest to the boundary where the target object could be seen was selected (none of the objects were cued more than 2.5 Â seconds from the prescribed event boundary or midpoint). The same procedure was used to cue event middles, except that editing was done at the temporal midpoint between two event boundaries.|$|E
40|$|The <b>graceful</b> exit <b>transition</b> from a dilaton-driven inflationary phase to a {{decelerated}} Friedmann-Robertson-Walker era requires certain {{classical and}} quantum corrections to the string effective action. Classical corrections can stabilize a high curvature string phase while the evolution {{is still in}} the weakly coupled regime, and quantum corrections can induce violation of the null energy condition, allowing evolution towards a decelerated phase. Comment: 6 pages, LateX. Contribution to the proceedings of the workshop Modern Modified Theories of Gravitation and Cosmology, 29 - 30 June, 1997, Ben-Gurion University, Beer-Sheva, Israel and the International Europhysics Conference on High-Energy Physics, 19 - 26 August, 1997, Jerusalem, Israe...|$|R
40|$|We construct, for {{the first}} time, a model of <b>graceful</b> exit <b>transition</b> from a dilaton-driven inflationary phase to a {{decelerated}} Friedman-Robertson-Walker era. Exploiting a demonstration that classical corrections can stabilize a high curvature string phase while the evolution {{is still in the}} weakly coupled regime, we show that if additional terms of the type that may result from quantum corrections to the string effective action exist, and induce violation of the null energy condition, then evolution towards a decelerated Friedman-Robertson-Walker phase is possible. We also observe that stabilizing the dilaton at a fixed value, either by capture in a potential minimum or by radiation production, may require that these quantum corrections are turned off, perhaps by non-perturbative effects or higher order contributions which overturn the null energy condition violation. Comment: 17 pages including 9 figures, RevTeX. Uses epsfi...|$|R
40|$|String {{cosmology}} {{solutions are}} examined in a generalized phase-space including sources representing arbitrary corrections to lowest order string-dilatongravity effective action. We find {{a set of}} necessary conditions for a <b>graceful</b> exit <b>transition</b> from a dilaton-driven inflationary phase to a radiation dominated era. We show that sources allowing such a transition have to violate energy conditions similar to those appearing in singularity theorems of general relativity. Since familiar classical sources, excepting spatial curvature, obey these energy conditions we conclude that a generic graceful exit in string cosmology requires a new effective phase of matter. Our results clarify and generalize previous analyses and enable us to critically reexamine proposed Duality symmetries of string cosmology equations [1, 2, 3], suggest a mechanism [1, 4] for inflationary evolution. This mechanism {{is based on the}} fact that cosmological solutions to string dilaton-gravity come in duality-relate...|$|R
40|$|An {{integrated}} {{program is}} described, starting with muon {{experiments in the}} Booster era, continuing with a 2 MW target station, a 4 GeV Neutrino Factory and a 3 TeV Muon Collider, all driven by Project X. This idea provides an integrated approach to the Intensity and Energy Frontiers at Fermilab. Project X is a proposed high intensity proton facility intended to support a world-leading program in neutrino and flavor physics {{over the next two}} decades at Fermilab while also providing an upgrade path to drive a neutrino factory and/or a muon collider. Project X is an integral part of the Fermilab Roadmap as described in the Fermilab Steering Group Report of August 2007 and of the Intensity Frontier science program described in the P 5 report of May 2008. The primary elements of that research program to be supported by Project X include: (1) A neutrino beam for long baseline neutrino oscillation experiments. A new 2 megawatt proton source with proton energies between 50 and 120 GeV would produce intense neutrino beams, directed toward a large detector located in a distant underground laboratory. (2) Kaon and muon based precision experiments running simultaneously with the neutrino program. These could include a world leading muon-to-electron conversion experiment and world leading rare kaon decay experiments. (3) A path toward a muon source for a possible future neutrino factory and, potentially, a muon collider at the Energy Frontier. This path requires that the new proton source have significant upgrade potential beyond the initial uses. This paper suggests that an implementation of Project X based on a CW linac can be part of a continuous synergistic transition from a muon physics program in the 'Booster era' to the Neutrino Factory and Muon Collider. It then describes a possible staging of the planned muon experiments and of Project X to provide a <b>graceful</b> <b>transition</b> from the Intensity Frontier to the Energy Frontier...|$|E
40|$|Masked {{proportional}} routing is {{an improved}} procedure for choosing links between adjacent nodes {{of a network}} {{for the purpose of}} transporting an entity from a source node ("A") to a destination node ("B"). The entity could be, for example, a physical object to be shipped, in which case the nodes would represent waypoints and the links would represent roads or other paths between waypoints. For another example, the entity could be a message or packet of data to be transmitted from A to B, in which case the nodes could be computer-controlled switching stations and the links could be communication channels between the stations. In yet another example, an entity could represent a workpiece while links and nodes could represent, respectively, manufacturing processes and stages in the progress of the workpiece towards a finished product. More generally, the nodes could represent states of an entity and the links could represent allowed transitions of the entity. The purpose of masked proportional routing and of related prior routing procedures is to schedule transitions of entities from their initial states ("A") to their final states ("B") in such a manner as to minimize a cost or to attain some other measure of optimality or efficiency. Masked proportional routing follows a distributed (in the sense of decentralized) approach to probabilistically or deterministically choosing the links. It was developed to satisfy a need for a routing procedure that 1. Does not always choose the same link(s), even for two instances characterized by identical estimated values of associated cost functions; 2. Enables a <b>graceful</b> <b>transition</b> from one set of links to another set of links as the circumstances of operation of the network change over time; 3. Is preferably amenable to separate optimization of different portions of the network; 4. Is preferably usable in a network in which some of the routing decisions are made by one or more other procedure(s); 5. Preferably does not cause an entity to visit the same node twice; and 6. Preferably can be modified so that separate entities moving from A to B do not arrive out of order...|$|E
40|$|Ouvrage (Ã©diteur). Despite {{the fact}} that network {{operators}} and manufacturers face a major financial crisis, the size and importance of the Internet continue to grow at amazing speeds. At {{the core of the}} Internet, optical switches are replacing traditional switches, allowing data to flow at unprecedented speeds. At the edges, digital subscriber line (DSL) is becoming the technology of choice; within every home it is now possible to permanently connect multiple devices to the Internet. Wireless LAN (WLAN) hotspots are becoming commonplace, allowing people to connect to the Internet independent of whether they are flying in a plane, travelling on a train, or sitting on a terrace. Considering the importance of the Internet in our economic and daily life, it is remarkable that technologies to manage the Internet get limited attention. Since the late 1980 s, the Internet standard management framework has been based on the Simple Network Management Protocol (SNMP). In the ' 90 s, the Internet Engineering Task Force (IETF) defined several new versions; the latest one, SNMPv 3, has already been a full Internet standard for many years. However, despite its success, there is common agreement that SNMP technology will be unable to solve all future Internet management problems. Although it is likely that SNMP will remain the protocol of choice for many monitoring tasks, it is not the ideal technology for tasks such as configuration management. In fact, further progress in SNMP technology is unlikely to occur, and new versions of SNMP should no longer be expected. As argued in the October 2003 issue of IEEE Communications Magazine, the evolutionary approaches to enhancing SNMP failed, so it seems {{the time has come for}} revolutionary approaches. Of such approaches, the most promising ones build on Extensible Markup Language (XML) and Web services technologies. In this issue of this magazine, an overview of research and recent developments in that area will therefore be presented. The first article by George Pavlou et al. provides an overview of existing management technologies, such as open systems integration (OSI), SNMP, open distributed processing (ODP), and Common Object Request Broker Architecture (CORBA), and the potential of new technologies such as Web services. Based on the example of the TCP connection table, the authors show how to use these technologies for management purposes. Since there have been many discussions on the performance of XML and Web services technologies, the authors conclude with a performance comparison between SNMP, CORBA, and Web services. Of key importance in network and service management is the ability to define management information in a standardized way. In the past several languages have been defined for that purpose; examples are Guidelines for the Definition of Managed Objects (GDMO), Structure of Management Information (SMI), and MOF. Because of the existence of many tools, XML seems to be the most appropriate syntactic framework to define such information in the future. The second article, by Jorge E. LÃ³pez de Vergara et al., discusses the use of XML for that purpose and proposes the use of ontology languages to enhance the semantic expressiveness of management definitions. In particular, they propose the use of OWL, the Web Ontology Language. Even in revolutionary approaches, it remains important to allow <b>graceful</b> <b>transition</b> from current management information definitions toward future ones. The third article, by Torsten Klie and Frank StrauÎ², discusses such a transition and shows how existing SMI management information base (MIB) modules can be converted into new XML schema definitions. Furthermore, the article presents an SNMP-to-XML gateway that allows the retrieval of XML encoded management information in heterogeneous environments. The fourth article, by Mi-Jung Choi et al., discusses the use of XML to facilitate IP configuration management. This topic is the subject of current standardization within the IETF Net- Conf Working Group. The article therefore starts with an overview of NetConf, and continues with presenting the specific XML-based configuration management system that was designed and implemented by the authors. The fifth article, by Lawrence Menten, discusses experiences in exploring and designing XML-based network management solutions for products ranging from smallresource-limited devices to high-capacity server-hosted control plane monitoring systems. The article concludes that the adoption of XML representations and tools for device management will dramatically improve the completeness, flexibility, and robustness of the management infrastructure on devices with both large resources and small. The last article, by Raouf Boutaba et al., is a good example of the potential use of Web services technology. The article presents the design and implementation of a user-controlled lightpath management system, which internally relies on XML and other Web services technologies, like SOAP and WSDL. This article provides an excellent proof that XML-based management is not only a topic for future research, but has already become an operational reality. We would like to thank all authors who submitted articles to this feature topic. In total we received 35 articles, of which...|$|E
40|$|A {{classical}} and quantum mechanical generalized second law of thermodynamics in cosmology implies {{constraints on the}} effective equation of state of the universe {{in the form of}} energy conditions, obeyed by many known cosmological solutions, and is compatible with entropy bounds which forbid certain cosmological singularities. In string cosmology the second law provides new information about the existence of non-singular solutions, {{and the nature of the}} <b>graceful</b> exit <b>transition</b> from dilaton-driven inflation. Typeset using REVTEX 1 The existence of cosmological singularities and their nature has been intensely investigated, relying on the celebrated singularity theorems of Hawking and Penrose [1], who concluded that if sources in Einsteinâ€™s equations obey certain energy conditions, cosmological singularities are inevitable. Entropy considerations were brought in only much later, when Bekenstein [2] argued that if the entropy of a visible part of the universe obeys the usual entropy bound from nearly flat space situations [3], certain cosmological singularitie...|$|R
40|$|A {{generalized}} second law in string cosmology {{accounts for}} geometric and quantum entropy {{in addition to}} ordinary sources of entropy. The proposed generalized second law forbids singular string cosmologies, under certain conditions, and forces a <b>graceful</b> exit <b>transition</b> from dilaton-driven inflation by bounding curvature and dilaton kinetic energy. Typeset using REVTEX 1 String theory is a consistent theory of quantum gravity, {{with the power to}} describe high curvature regions of space-time [1], and as such we could expect it to teach us about the fate of cosmological singularities, with the expectation that singularities are smoothed and turned into brief epochs of high curvature. However, many attempts to seduce an answer out of string theory regarding cosmological singularities have failed so far, even after the wave of recent new developments and results [2]. The reason is probably that most recent technical advancements in string theory rely heavily on supersymmetry, but generic time dependent solutions break all supersymmetries, and therefore known methods are less powerful whe...|$|R
40|$|Traditional {{communication}} systems usually {{suffer from the}} threshold effect when channel signal-to-noise ratio (CSNR) fluctuates unpredictably in wireless and mobile scenarios. The SoftCast scheme, however, provides <b>graceful</b> quality <b>transition</b> in wide CSNR range. In SoftCast, input image is decorrelated by a transform and modulated directly to a dense constellation for transmission, leaving out the conventional quantization, entropy coding and channel coding. A key point of SoftCast is that the transmission power needs to be allocated among the transform coefficients unequally, according to the energy of coefficients. Importantly, the energy diversity used to guide power allocation should be shared between the sender and the receiver for correct decoding. This paper addresses the power distortion optimization problem, introducing a new adaptive chunk division scheme to describe the energy diversity among coefficients. A concrete algorithm is developed to determine the chunk boundaries that achieve optimal transmission power usage. Experimental {{results show that the}} proposed scheme can improve the performance of the original SoftCast by 4 âˆ¼ 8 dB using a smaller number of chunks. Â© 2013 IEEE...|$|R
