2|157|Public
50|$|The initial name of GESMES/TS was GESMES/CB (<b>GEneric</b> <b>Statistical</b> <b>MESsage</b> for Central Banks),but {{has been}} changed in order to reflect its wider application.The model and format are {{maintained}} {{under the auspices of}} the SDMX initiative.In this context, GESMES/TS is known as SDMX-EDI.|$|E
50|$|GESMES/TS (<b>GEneric</b> <b>Statistical</b> <b>MESsage</b> for Time Series) is a {{data model}} and message formatappropriate for {{performing}} standardised exchange of statistical data and related metadata.It {{is based on}} the GESMES message (a UN/CEFACT standard using the EDIFACT syntax).Its most common use is in the exchange of official statistics.|$|E
5000|$|The {{production}} process of official statistics comprises 9 phases, as {{documented in the}} <b>Generic</b> <b>Statistical</b> Business Process Model ...|$|R
40|$|A new {{statistical}} design {{environment is}} discussed, {{composed of the}} symbolic equation based IC design system called DONALD, developed at K. U. Leuven and the <b>generic</b> <b>statistical</b> design system called GOSSIP, developed at the Texas A&M University. Several problems of statistical IC design using this environment are discussed. status: publishe...|$|R
40|$|The paper {{presents}} a <b>generic</b> <b>statistical</b> {{model of the}} (total) modeling error for conventional space structures in their launch configuration. Modeling error {{is defined as the}} difference between analytical prediction and experimental measurement. It is represented by the differences between predicted and measured real eigenvalues and eigenvectors. Comparisons are made between pre-test and post-test models. Total modeling error is then subdivided into measurement error, experimental error and 'pure' modeling error, and comparisons made between measurement error and total modeling error. The <b>generic</b> <b>statistical</b> model presented in this paper is based on the first four global (primary structure) modes of four different structures belonging to the generic category of Conventional Space Structures (specifically excluding large truss-type space structures). As such, it may be used to evaluate the uncertainty of predicted mode shapes and frequencies, sinusoidal response, or the transient response of other structures belonging to the same generic category...|$|R
25|$|Johnson–Nyquist noise (thermal noise, Johnson noise, or Nyquist noise) is the {{electronic}} noise {{generated by the}} thermal agitation of the charge carriers (usually the electrons) inside an electrical conductor at equilibrium, which happens regardless of any applied voltage. The <b>generic,</b> <b>statistical</b> physical derivation of this noise is called the fluctuation-dissipation theorem, where generalized impedance or generalized susceptibility is used to characterize the medium.|$|R
40|$|We {{offer an}} {{integration}} {{of theory and}} method {{in the study of}} intergroup social associations. Specifically, we show that models for intergroup association tables developed using generic log-linear methods for categorical data analysis embody a general theoretical point of view on the driving force behind intergroup association, namely, as the outcome of a probabilistic process of repulsion from dissimilar others. We develop this argument and illustrate it with intermarriage data. We conclude by identifying the advantages that accrue to both theory and method when the theoretical assumptions underlying the application of a <b>generic</b> <b>statistical</b> methodology are clearly understood. Keywords social integration, intergroup association, log-linear models, rejection Most scholars would agree with Collins (1988 : appendix) that the use of <b>generic</b> <b>statistical</b> methods, such as regression analysis of linearly scaled variables or log-linear analysis of categorical frequency counts, involves implicit theoretical assumptions. Most would also agree that there is value in understanding what these assumptions are. In the study of inter...|$|R
50|$|SDMX message formats {{have two}} basic expressions, SDMX-ML (using XML syntax) and SDMX-EDI (using EDIFACT syntax {{and based on}} the GESMES/TS <b>statistical</b> <b>message).</b> The {{standards}} also include additional specifications (e.g. registry specification, web services). Version 1.0 of the SDMX standard has been recognised as an ISO standard in 2005. The RDF Data Cube vocabulary implements the cube model underlying SDMX as Linked Data.|$|R
40|$|A novel <b>generic</b> <b>statistical</b> measure S-time-distance {{complementing}} existing {{methods of}} analysis of time series data is briefly presented. The application to indicator analysis shows that the gap between compared units may be very different when compared with commonly used static measures and with time distance measure, leading to a special typology of indicators. Analysis of indicators like PC per 100 inhabitants and Internet users per capita will show the empirical results for EU countries...|$|R
40|$|We {{describe}} {{the role of}} information management in redesign programs: why it is needed, how it is at present being developed through international cooperation in the <b>Generic</b> <b>Statistical</b> Information Model (GSIM) project, and we give some examples how information management {{has been used in}} practice at Statistics Netherlands. We conclude that GSIM is necessary for more extensive usage of big data sources, for in-teroperability of statistical tools and for sharing tools between NSIs...|$|R
40|$|This review {{highlights}} {{recent examples}} of <b>generic</b> <b>statistical</b> scaling as departures from ideal Kolmogorov fluid turbulence {{as seen in}} the solar wind. Similarity analysis is first reviewed to set turbulence {{in the context of the}} wider class of observed phenomenology that show statistical scaling. Examples are provided that are characteristic of finite range MHD turbulent phenomenology-anisotropy, and generalized similarity as a finite range effect. This motivates the question as to whether the observed phenomonology are universal...|$|R
40|$|The annual {{number of}} diagnoses of sexually {{transmitted}} infections (STIs) has been rising, with highest STI rates continuing {{to be found}} among young people. Theory and research associate a greater perceived vulnerability to a health threat and higher behavioural intentions {{with an increase in}} the likelihood of enacting health behaviour. This study assessed the effects of health message format and health message frame on young people’s perceived vulnerability to become infected with an STI and their intention to use condoms. Young people between 18 and 29 years, who currently lived in Australia and thought of themselves as hetero- or bisexual (n = 167), completed the online study, in which they were {{randomly assigned to one of}} four conditions in a 2 (message format: testimonial or <b>statistical)</b> x 2 (<b>message</b> frame: gain or loss) factorial between-subjects design. Analyses of variance show that testimonial messages are significantly more effective than <b>statistical</b> <b>messages</b> in increasing both young people’s perceived vulnerability to become infected with an STI and their intention to use condoms. Moreover, a significant interaction between message frame and message format type on intention to use condoms was found. Results in particular suggest that message framing affects the effect of statistical messages; young people who read a <b>statistical</b> <b>message</b> in a loss-frame had a significant higher intention to use condoms than people who read a <b>statistical</b> <b>message</b> in a gain-frame. Furthermore, young people’s perceived vulnerability to become infected with an STI is positively associated with their intention to use condoms. Findings extend previous theorizing and research, and suggest that messages in a testimonial format are the most effective and safest mode in health communication to increase young people’s perceived vulnerability to become infected with an STI and their intention to use condoms. Health <b>messages</b> in a <b>statistical</b> format should focus on the losses one may experience by engaging in a risk behaviour, or not engaging in the health protective behaviour...|$|R
40|$|Improving the public's {{understanding}} of statistical information requires that producers or reporters of <b>statistical</b> <b>messages</b> are aware of: The nature of people's statistics literacy, The {{factors that affect}} the difficulty of statistics-related messages, The existence of individual or group differences in statistics literacy; and The information needs of different target audiences. Implications are discussed regarding the need to prepare different types of communicative products and formulate strategies for dissemination and public education...|$|R
40|$|Despite the {{enormous}} benefits of early-detection products, consumers {{are reluctant to}} use them. The authors explore this reluctance, testing alternative approaches to communicating the consequences of detection behaviors. The results suggest that anecdotal messages are more involving than <b>statistical</b> <b>messages</b> and that positive anecdotes (about gains from screening) are less persuasive than negative anecdotes (about the losses from failing to get screened); positive anecdotes appear to cause a “boomerang” effect. The authors discuss implications for promoting consumer risk-reduction behaviors...|$|R
40|$|We {{present a}} data and error {{analysis}} for semantic role labelling. In a first experiment, we build a <b>generic</b> <b>statistical</b> model for semantic role assignment in the FrameNet paradigm {{and show that}} there is a high variance in performance across frames. The main hypothesis of our paper is that this variance is to a large extent a result of differences in the underlying argument structure of the predicates in different frames. In a second experiment, we show that frame uniformity, which measures argument structure variation, correlates well with the performance figures, effectively explaining the variance. ...|$|R
40|$|We {{estimate}} <b>generic</b> <b>statistical</b> {{properties of}} a structural credit risk model by considering an ensemble of correlation matrices. This ensemble {{is set up}} by Random Matrix Theory. We demonstrate analytically {{that the presence of}} correlations severely limits the effect of diversification in a credit portfolio if the correlations are not identically zero. The existence of correlations alters the tails of the loss distribution considerably, even if their average is zero. Under the assumption of randomly fluctuating correlations, a lower bound for the estimation of the loss distribution is provided. ...|$|R
40|$|This {{research}} {{presents a}} new generic approach for defining a new query mode {{which is the}} intelligent <b>generic</b> <b>statistical</b> query mode for any database application. It is combined with the optimized intelligent generic query mode (IGSQM) for relational database applications. Since it is generic then {{it can be used}} in developing any database application without rewriting any source code. It is intelligent {{in the sense that it}} submits to user an enormous amount of statistical reports without the need or support of the application developer, actually the total number of those statistical reports depends on the database schema. The Interface of the new approach is very simple in use. The new approach saves time for developing the required statistical reports by the user. The developed applications which exploit the proposed intelligent <b>generic</b> <b>statistical</b> query mode will empower users and improve the quality and efficiency of service provided by those applications. IGSQM can be used widely in scientific statistical researches. It has been implemented using PowerBuilder (release 11. 5) as a front end tool and Adaptive Server Anywhere (one of Sybase products) as a database engine. This research describes the design of the optimized intelligent generic query mode and its interface. Keywords Query mode, entry mode, update mode, statistical query mode, relational database applications, optimizing query mode, generic query mode, intelligent query mode, database field, computed field. 1...|$|R
40|$|A major {{performance}} degrading {{factor in}} free space optical communication (FSO) systems is atmospheric turbulence. Spatial diversity techniques provide a promising approach to mitigate turbulence-induced fading. In this paper, we study the error rate performance of FSO links with spatial diversity over atmospheric turbulence channels {{described by the}} Double Generalized Gamma distribution which is a new <b>generic</b> <b>statistical</b> model covering all turbulence conditions. We assume intensity modulation/direct detection with on-off keying and present the BER performance of single-input multiple-output (SIMO), multiple-input single-output (MISO) and multiple-input multiple-output (MIMO) FSO systems over this new channel model. Comment: 6 Pages, 4 figure, IEEE ICC conference 201...|$|R
40|$|A global quantity, {{regardless}} of its precise nature, will often fluctuate according to a Gaussian limit distribution. However, in highly correlated systems, other limit distributions are possible. We have previously calculated one such distribution and have argued that this function should apply specifically, and in many instances, to global quantities that define a steady state. Here we demonstrate, for the first time, the relevance of this prediction to natural phenomena. The river level fluctuations of the Danube are observed to obey our prediction, which immediately establishes a <b>generic</b> <b>statistical</b> connection between turbulence, criticality and company growth statistics. Comment: 5 pages, 1 figur...|$|R
40|$|We {{consider}} particles on a one-dimensional lattice whose {{evolution is}} governed by nearest-neighbor interactions where particles that have reached size zero are removed from the system. Concentrating on configurations with infinitely many particles, we prove existence of solutions under a reasonable density assumption on the initial data and show that the vanishing of particles and the localized interactions can lead to non-uniqueness. Moreover, we provide a rigorous upper coarsening estimate and discuss the <b>generic</b> <b>statistical</b> properties {{as well as some}} non-generic behavior of the evolution by means of heuristic arguments and numerical observations. Comment: Extended non-uniqueness sectio...|$|R
40|$|Several recent {{initiatives}} {{related to}} the use of DDI in official statistics are now in progress, {{under the auspices of the}} UNECE’s High Level Group (HLG) on the Modernization of Statistical Production. This presentation will focus on the revised <b>Generic</b> <b>Statistical</b> Information Model (GSIM) 1. 1, the related Common Statistical Production Architecture (CSPA) and prototypes, and the mapping work relating these to DDI implementation. Relationships to other standards is also presented, including Statistical Data and Metadata eXchange (SDMX), the “syntax-neutral” expression and validation language being jointly developed by DDI and SDMX, and the related process models (GSBPM and its longitudinal equivalent developed by the DDI Alliance) ...|$|R
40|$|International Organizations and Machine Translation (MT) share a {{long history}} together; however, {{there is still some}} {{resistance}} to the introduction of MT tools into the institutional translation process. Additionally, organizations {{might not be able to}} select the tools that suit them better. Currently, a number of customizable statistical systems are being offered as additional tools for language support. This study describes the design and execution of a comparative context-oriented evaluation of statistical engines in the context of international organizations, with the purpose of proposing a short practical framework for MT quality assessment, corroborating assumptions about customizable and <b>generic</b> <b>statistical</b> systems, and stressing the links between MT and institutional translation...|$|R
40|$|Abstract. The {{presented}} work studies textual summaries, {{aiming to}} detect the qualities of human multi-document summaries, in contrast to automatically extracted ones. The measured features {{are based on a}} <b>generic</b> <b>statistical</b> regularity measure, named Symbol Sequence Statistical Regularity (SSSR). The measure is calculated over both character and word n-grams of various ranks, given a set of human and automatically extracted multi-document summaries from two different corpora. The results of the experiments indicate that the proposed measure provides enough distinctive power to discriminate between the human and non-human summaries. The results hint on the qualities a human summary holds, increasing intuition related to how a good summary should be generated. ...|$|R
40|$|Due to {{copyright}} restrictions, {{the access}} to {{the full text of}} this article is only available via subscription. A major performance degrading factor in free space optical communication (FSO) systems is atmospheric turbulence. Spatial diversity techniques provide a promising approach to mitigate turbulence-induced fading. In this paper, we study the error rate performance of FSO links with spatial diversity over atmospheric turbulence channels described by the Double Generalized Gamma distribution which is a new <b>generic</b> <b>statistical</b> model covering all turbulence conditions. We assume intensity modulation/direct detection with on-off keying and present the BER performance of single-input multiple-output (SIMO), multiple-input single-output (MISO) and multiple-input multiple-output (MIMO) FSO systems over this new channel model. TÜBİTA...|$|R
40|$|A new {{statistical}} {{design methodology}} is presented that uses symbolic methods {{to increase the}} efficiency of statistical IC design. The methodology is implemented in an environment that combines the symbolic design equation manipulation engine DONALD with the <b>generic</b> <b>statistical</b> design system GOSSIP. DONALD is used to generate the initial design and to create the symbolic computational plan that is used by GOSSIP for the actual statistical yield, Cp and Cpk optimization. The strengths and weaknesses of the proposed approach are iscussed, and its accuracy and speed are compared with the traditional method of using a SPICE-type circuit simulator in the inner loop of the statistical optimization. Overall, a significant speed-up of the statistical IC design efficiency is observed. status: publishe...|$|R
40|$|The Restricted Boltzmann Machine (RBM), an {{important}} tool used in machine learning in particular for unsupervized learning tasks, is investigated {{from the perspective of}} its spectral properties. Starting from empirical observations, we propose a <b>generic</b> <b>statistical</b> ensemble for the weight matrix of the RBM and characterize its mean evolution. This let us show how in the linear regime, in which the RBM is found to operate {{at the beginning of the}} training, the statistical properties of the data drive the selection of the unstable modes of the weight matrix. A set of equations characterizing the non-linear regime is then derived, unveiling in some way how the selected modes interact in later stages of the learning procedure and defining a deterministic learning curve for the RBM...|$|R
40|$|Abstract. This paper {{presents}} a system evaluated in the Surveillance Event Detection (SED) task of TRECVid 2010 campaign. We investigate a <b>generic</b> <b>statistical</b> approach applied to seven event classes {{defined by the}} SED task. Our video representation is based on local space-time descriptors which are vectorquantized and aggregated into histograms within short temporal windows and spatial regions defined by the prior. We use priors on the spatial localization of actions estimated from the spatio-temporal annotation of actions in the training data. To recognize actions, we learn one-against-all action classifiers using nonlinear SVMs. Each classifier is applied independently to localize temporal intervals of actions using window-scanning approach. We present results of six runs with variations in the two parameters: (i) classifier threshold and (ii) temporal extent of the scanning window. ...|$|R
40|$|The size {{distribution}} and growth rate dynamics of U. S. companieshave been extensively studied by many authors. In this paper,using the COMPUSTAT database, we extend the analysis todisaggregated data, studying 15 {{sectors of the}} U. S. manufacturing industry. The sectoral investigation reveals thepresence of general statistical properties that can be consideredvalid across all the studied sectors. In particular, theprobability density of firms growth rates invariably displays acharacteristic tent shape and {{the relation between the}} size of afirm and the variance of its rates of growth is characterized, indifferent sectors, by very similar scaling relations. Thepresence of characteristics that are robust and sectoral invarianthints at the existence of <b>generic</b> <b>statistical</b> properties shapingthe dynamic of firms across the whole industry. Copyright Kluwer Academic Publishers 2003 Firm growth, industrial sectors, Laplace distribution, power law,...|$|R
30|$|Thus, our {{claim that}} policymakers care only about AUC (not a theory-based measure of d') {{should not be}} {{construed}} as an indictment {{of the use of}} a <b>generic</b> Gaussian-based <b>statistical</b> model to parametrically estimate AUC (or pAUC in the case of lineups) when such an estimate could not otherwise be obtained.|$|R
40|$|We {{present in}} this article a {{detailed}} quantitative discussion of the measurement of the leptonic mixing angle theta_ 13 through currently scheduled reactor neutrino oscillation experiments. We thus focus on Double Chooz (Phase I & II), Daya Bay (Phase I & II) and RENO experiments. We perform a unified analysis, including systematics, backgrounds and accurate experimental setup in each case. Each identified systematic error and background impact has been assessed on experimental setups following published data when available and extrapolating from Double Chooz acquired knowledge otherwise. After reviewing the experiments, we present a new analysis of their sensitivities to sin^ 2 (2 theta_ 13) and study {{the impact of the}} different systematics based on the pulls approach. Through this <b>generic</b> <b>statistical</b> analysis we discuss the advantages and drawbacks of each experimental setup. Comment: 28 pages, 7 figures, 14 tables, one appendi...|$|R
40|$|We {{present a}} latent {{variable}} {{approach to the}} acoustic-toarticulatory mapping problem, where different vocal tract configurations can give rise to the same acoustics. In latent variable modelling, the combined acoustic and articulatory data are assumed to have been generated by an underlying low-dimensional process. A parametric probabilistic model is estimated and mappings are derived from the respective conditional distributions. This has the advantage over other methods, such as articulatory codebooks or neural networks, of directly addressing the nonuniqueness problem. We demonstrate our approach with electropalatographic and acoustic data from the ACCOR database. 1. INTRODUCTION Recently, {{there has been a}} growing awareness in the speech recognition field that blind science based on acoustical information alone might not tend to more improvements of state of the art computational methods of speech production [5]. Blind science means here the use of complex <b>generic</b> <b>statistical</b> mode [...] ...|$|R
40|$|A group 2 ̆ 7 s {{collective}} action is {{an outcome of}} the group 2 ̆ 7 s decision-making process, which may be reached by either averaging of the individual preferences or following the choices of certain members in the group. Our problem here is to decide which decision process the group has adopted given the data of the {{collective action}}s. We propose a <b>generic</b> <b>statistical</b> framework to infer the group 2 ̆ 7 s decision process from the spatio-temporal data of group trajectories, where each 2 ̆ 2 trajectory 2 ̆ 2 is a sequence of group actions. This is achieved by systematically comparing each agent type 2 ̆ 7 s influence on the group actions based on an array of spatio-temporal criteria. Results of those comparisons are then aggregated into a score to make inference about the group 2 ̆ 7 s decision process...|$|R
40|$|Abstract: This paper {{deals with}} the {{segmentation}} of the radar environment based on Bayesian statistical methods in order to process adaptively the received signal according to the local characteristics of the clutter. We used first statistical models for Doppler and polarimetric signal, so that the segmentation will run on the estimators of the parameters. We used then a generalized Hidden Markov Chain for the segmentation of clutter environment, by applying MPM rule for the estimation of the hidden states. The usual assumption of conditional independence of the observations is relaxed by {{taking into account the}} dependence with copulas. We propose a <b>generic</b> <b>statistical</b> estimation and restoration procedure. The methodology is illustrated with data coming from polarimetric studies. sensitive to abrupt changes in the signal (as CFAR) and can give poor performances near the frontiers. Hence, a good localization of these frontiers and estimation of the mean behavior in each area can improve the performance (in detection for instance) ...|$|R
40|$|Complex {{networks}} in natural, social, and technological systems generically exhibit {{an abundance of}} rich information. Extracting meaningful structural features from data {{is one of the}} most challenging tasks in network theory. Many methods and concepts have been proposed to address this problem such as centrality statistics, motifs, community clusters, and backbones, but such schemes typically rely on external and arbitrary parameters. It is unknown whether generic networks permit the classification of elements without external intervention. Here we show that link salience is a robust approach to classifying network elements based on a consensus estimate of all nodes. A wide range of empirical networks exhibit a natural, network-implicit classification of links into qualitatively distinct groups, and the salient skeletons have <b>generic</b> <b>statistical</b> properties. Salience also predicts essential features of contagion phenomena on networks, and points towards a better understanding of universal features in empirical networks that are masked by their complexity. Comment: Nature Communications 3 (2012...|$|R
40|$|Computational anatomy is an {{emerging}} discipline that aims at analyzing and modeling the individual anatomy of organs and their biological variability across a population. However, understanding and modeling {{the shape of}} organs is made difficult {{by the absence of}} physical models for comparing different subjects, the complexity of shapes, and the high number of degrees of freedom implied. Moreover, the geometric nature of the anatomical features usually extracted raises the need for statistics on objects like curves, surfaces and deformations that do not belong to standard Euclidean spaces. We explain in this chapter how the Riemannian structure can provide a powerful framework to build <b>generic</b> <b>statistical</b> computing tools. We show that few computational tools derive for each Riemannian metric can be used in practice as the basic atoms to build more complex generic algorithms such as interpolation, filtering and anisotropic diffusion on fields of geometric features. This computational framework is illustrated wit...|$|R
40|$|In {{this paper}} we propose several {{applications}} of the EM algorithm [...] a well-known algorithm for parameter estimation in <b>generic</b> <b>statistical</b> problems [...] in the different levels of a computer vision system, and discuss its relatively straightforward and efficient implementation in parallel distributed memory environments, under the message passing paradigm. We show, at least, an algorithm for each level of a generic computer vision system (low, medium and high level vision) with the common basis of the EM algorithm applied in parameter estimation for mixture statistical models. We present an efficient implementation in parallel {{for all of them}} under a common scheme. Also, we show an evaluation of a medium-level vision EM application in a cluster of PCs. The results we have obtained in terms of both speedup and execution time are very good. Moreover, the paper gives us the guidelines for extending the method for related problems, and, in general, for many applications with mixture parameter estimation with EM as its main task...|$|R
