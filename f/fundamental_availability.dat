2|19|Public
40|$|Analyses of Co, Ni and Se in pyrites {{and other}} {{minerals}} {{from a wide}} variety of Tasmanian ore deposits support a genetic relationship between the Mt. Lyell (pyritic - Cu) and Rosebery (banded In-Zn-Pb-Cu) deposits, and the Cambrian eugeosynclinal volcanic rocks in which they occur. The concentration trends for all the ores due to <b>fundamental</b> <b>availability</b> contain smaller-scale components due to depositional processes, which, except in one case, do not interfere with these trends. The components include impoverishment of Co (and Ni) during remobilization of sulphides, increase in Ni and decrease in Co away from the centre of zoned deposits, impoverishment of Ni (and Co) in replacement as compared with vein lodes, and regular and irregular partitioning of respectively Co-Ni and Se between coexisting minerals. The trends of Co-Ni in pyrite due to availability include the following: (a) The sedimentary-diagenetic pyrites generally contain Co/Ni < 0. 5, but show no correlation of Co-Ni values with rock type, age, or degree of recrystallization. (b) Pyrites in the Cambrian acid-intermediate igneous rocks have Co/Ni ratios ranging 1 - 150, and contain up to 0. 8...|$|E
40|$|A single {{trapped and}} laser-cooled radium ion, Ra+, is a {{promising}} candidate for high precision experiments, such as on atomic parity violation (APV) and atomic clocks. APV experiments provide a stringent {{test of the}} Standard Model of particles physics with high sensitivity for physics beyond. Ultra-narrow transitions in Ra+ can be employed for optical frequency standards, or “clocks”. As an important step towards such experiments excited-state laser spectroscopy was performed on short-lived trapped 209 - 214 Ra+ ions produced from the AGOR cyclotron at KVI. Hyperfine structure constants of Ra+ atomic states and isotope shifts of relevant transitions were studied, providing benchmarks for the required atomic theory at percent level accuracy. The measurement of a lower limit of the lifetime of the meta-stable 6 d 2 D 5 / 2 state provides an important confirmation of the <b>fundamental</b> <b>availability</b> of long coherence times in the trapped Ra+ system, required for high-quality clocks. The potential of the electric quadrupole transitions 7 s 2 S 1 / 2 - 6 d 2 D 3 / 2, 6 d 2 D 5 / 2 in Ra+ isotopes as single-ion optical frequency standards was explored. The frequency shifts of the clock transitions due to external fields and corresponding uncertainties were calculated. Several competitive candidates have been identified. In particular, the transition 7 s 2 S 1 / 2 (F= 2,mF= 0) - 6 d 2 D 3 / 2 (F= 0,mF= 0) in 223 Ra+ at 828 nm wavelength stands out because {{of the absence of}} linear Zeeman and electric quadrupole shifts. It could be exploited as a compact, robust, and low-cost atomic clock operating at a fractional frequency uncertainty of 10 - 17. With more experimental effort, the 223, 225, 226 Ra+ clocks could be pushed to a projected performance reaching even the 10 - 18 level. ...|$|E
40|$|In his article, Dr. O 2 ̆ 7 Keefle {{outlines}} the major proposals (both generic and specIfic) {{in the area}} of national health insurance. He then describes in depth the proposed Warren County Plan and the Foundation Concept in relation to three <b>fundamental</b> concepts: <b>availability,</b> utilization and financing of medical care...|$|R
30|$|The {{commercial}} obsidian trade {{played an}} important role during Neolithic period. Its characteristics favoured the exchange network. In this way the Mediterranean area was <b>fundamental.</b> The <b>availability</b> of significant numbers of obsidian samples has allowed to improve the knowledge about the trade and commercial routes. Obsidian samples from the Mediterranean (Aegean, Flegrean, North Latium, Sicily, Sardinia) and Near East (Anatolia) areas were directly collected on the sites and considered as reference. Almost 30 elements were analyzed by Instrumental Neutron Activation Analysis (INAA).|$|R
50|$|Two major {{challenges}} {{arise in}} the practical implementation of <b>fundamental</b> models: data <b>availability</b> and incorporation of stochastic fluctuations of the fundamental drivers. In building the model, we make specific assumptions about physical and economic relationships in the marketplace, and therefore the price projections generated by the models {{are very sensitive to}} violations of these assumptions.|$|R
40|$|This study {{utilizes}} the National Collegiate Athletic Association basketball point spread betting {{market to}} investigate whether differences in information availability across markets result in different relative efficiencies of price formation within those markets. Using intra-conference games of various conferences as clearly defined markets, we show that these markets are efficient given the information available in those markets. However, we also show that regression error variances are significantly smaller (greater) for those conferences with greater (lesser) information availability. This evidence supports previous stock market research suggesting that differential <b>fundamental</b> information <b>availability</b> across stock markets results in differential departures from equilibrium values. Copyright Blackwell Publishers Ltd 2001. ...|$|R
40|$|Abstract—In this paper, {{we shall}} {{describe}} about a fuzzy estimation theory {{based on the}} concept of set-valued op-erators, suitable for available operation of extremely com-plicated large-scale network systems. <b>Fundamental</b> condi-tions for <b>availability</b> of system behaviors of such network systems are clarified in a form of β-level fixed point the-orem for system of fuzzy-set-valued operators. Here, the proof of this theorem is accomplished in a weak topology introduced into the Banach space. 1...|$|R
40|$|BitTorrent, the {{immensely popular}} file {{swarming}} system, has a <b>fundamental</b> problem: <b>availability.</b> Although swarming scales well to tolerate flash crowds for popular content, {{it is less}} useful for unpopular or rare files as peers arriving after the initial rush find the content unavailable. Our primary contribution is a model to quantify content availability in swarming systems. We use the model to analyze the availability and the performance implications of bundling, a strategy commonly adopted by many BitTorrent publishers today. We find that even {{a limited amount of}} bundling exponentially reduces content unavailability. Furthermore, for swarms with highly unavailable publishers, the availability gain of bundling can result in a net improvement in download time, i. e., peers obtain more content in less time. We empirically confirm the model’s conclusions through experiments on PlanetLab using the mainline Bit-Torrent client...|$|R
40|$|Abstract — Capacitors {{are one of}} {{the most}} widely used forms of {{electronic}} components. A careful choice of a capacitor for a particular application and an adequate installation in the circuit will assure a good life service. Since half of the electric equipement failures are caused by capacitors degradation, interest for capacitor “Health monitoring ” function reveales to be very strong. Eventhough metallized polymer films capacitors proved to be more reliable components than cheap electrolytic capacitors in aerospace applicatitions, given the risk of infalamation in the case of a default, improving the dependability of these components and monitoring their health conditions are <b>fundamental</b> to the <b>availability</b> of systems in which they are employed. Two approaches should be considered: reliability and diagnostic. Th...|$|R
40|$|Availability in {{wireless}} visual sensor networks {{is a major}} design {{issue that}} {{is directly related to}} applications monitoring quality. For targets monitoring, visual sensors may be deployed to cover most or all of targets, and monitoring quality may be focused on how well a set of targets are being covered. However, targets may have different dimensions and it is expected that large targets may be only partially viewed by source nodes, which may affect coverage quality and lead to a state of unavailability. In this context, this article analyzes the effect of target’s size on effective coverage in wireless visual sensor networks. A new coverage metric, the Effective Target Viewing (ETV), is proposed to measure monitoring quality over a set of targets, which is exploited as a <b>fundamental</b> parameter for <b>availability</b> assessment. Results show that ETV {{can be used as a}} practical coverage metric when assessing availability in wireless visual sensor networks...|$|R
30|$|Achieving a {{representative}} sample of immigrant populations faces two <b>fundamental</b> problems: the <b>availability</b> of sample frames that correctly identify these populations and elevated fieldwork costs due to territorial dispersion, among other factors. Population registers provide the most updated and comprehensive sample frame on a country’s population, but they do not always contain the necessary categories to identify immigrant population, or their coverage of this target population is imperfect, which also hinders the representativeness and unbiased nature of samples obtained from these registers. This article focuses on the comparison of two similar migration contexts, Spain and Italy, and the specific challenges these countries encounter as recent destination countries with high levels of irregularity among their immigrant population. The population registers in both countries, Padrón and Anagrafe, respectively, have adapted differently to these changing realities. The paper discusses these differences and analyzes the methodological implications for sampling immigrant population in both countries and in comparative perspective.|$|R
40|$|The <b>fundamental</b> {{study on}} <b>availability</b> of ^ Au-colloid {{clearance}} test {{for evaluation of}} hepatic dysfunction {{was carried out by}} using the normal rats or the carbon tetrachloride (CCI_ 4) -treated rats. It appeared appropriate to administer gold in ^ Au-colloid at the dose of 100 μg/kg in order to obtaion an effective blood clearance curve of ^ Au-clloid. The blood clearance curve of ^ Au-clloid showed two-phase changes, i. e., ^ Au-colloid concentration in blood rapidly decreased for the first 10 minutes, and slowly later on. The disappearance rate of ^ Au-colloid from blood decreased with the increase in dose of CCI_ 4. The decrease in the blood clearance of ^ Au-colloid by CCI_ 4 administration might be the consequence of the decrease in the uptake ratio of ^ Au-colloid into the liver. The blood clearance test of ^ Au-colloid might be one of more useful methods for evaluation of hepatic dysfunction in rats, equally to the indocyanine green (ICG) test...|$|R
40|$|Regarding {{complexity}} of computation, randomness {{is a significant}} resource beside time and space. Particularly from a theoretical viewpoint, it is a <b>fundamental</b> question whether <b>availability</b> of random numbers gives any additional power. Most of randomized algorithms are analyzed {{under the assumption that}} independent and unbiased random bits are accessible. However, truly random bits are scarce in reality. In practice, pseudorandom generators are used in place of random numbers; usually, even the seed of the generator does not come from a source of true randomness. While things mostly work well in practice, there are occasional problems with use of weak pseudorandom generators. Further, randomized algorithms are not suited for applications where reliability is a key concern. Derandomization is the process of minimizing the use of random bits, either to small amounts or removing them altogether. We may identify two lines of work in this direction. There {{has been a lot of}} work in designing general tools for simulating randomness and making deterministic versions of randomized algorithms...|$|R
40|$|Abstract Resilience of a {{material}} is commonly {{understood as the}} ability of the material to absorb energy when deformed elastically and to return it when unloaded. However, in the domain of process systems, a formal definition and quantification of the magnitude of resilience is still elusive. The discussions and data provided in this paper illustrate that quantification of resilience for process systems is feasible and the quantitative model is aligned with fundamental concept of resilience. This paper provides general formulae for quantification of system resilience for many kinds of process systems. Based on the approach presented, it is possible to quantify resilience modulus, elastic modulus, and yield stress for an absorber column system. This work uses <b>fundamentals</b> of thermodynamic <b>availability</b> analysis for achieving this goal. It is found that resilience figure becomes considerably poor for increment of any operating variable from mid operating point vis-a-vis decrement of the same. Likewise {{a material}}, absorber system resilience modulus varies inversely with its modulus of elasticity. Additionally, a new efficiency parameter termed as “Thermodynamic Coefficient of Performance (THCOP) ” has been conceived. Finally, an example is described detailing the procedure of incorporating 50 % over capacity resiliency in the absorber by adding 4 new valve trays...|$|R
40|$|The Law on the Right to Health Care of Children and Pregnant Women was {{challenged}} before the Constitutional Court of Serbia {{in the part}} which relating to the obligation of providing specified medical data to the Republic Fund for Health Insurance. The evaluation was requested in relation to Article 42 of the Constitution of the Republic of Serbia {{as well as in}} relation to Article 8 of the European Convention on Human Rights and <b>Fundamental</b> Freedoms. The <b>availability</b> of specified health information as a condition of exercising the right to health care of separated categories of the population was considered in the context of alleged violation of the right to protection of personal data and the right to respect for private and family life. In other words, the question which was opened was a matter of collision of two rights that have different legal nature: the right to health care and the right to protection of personal data. The paper analyzes the decisions of the Constitutional Court on the conformity of the disputed provisions with Constitution and ratified international treaty, while the purpose of the analysis pointing to problematic places in the decision as well as the relevant constitutional issues in the decision-making procedure that have not been opened...|$|R
40|$|Distillers grains, a {{high-quality}} co-product from dry-grind ethanol production processes, is widely uses as a livestock feed both locally and internationally. However, the wet form of distillers grains deteriorates (i. e., undergoes dry matter loss-DML) rapidly during storage which affects overall management and utilization. There are several active research initiatives aimed at developing alternative preservation methods to retard storage losses thus extending the wet feed storage life {{to meet the}} <b>fundamental</b> principle of <b>availability</b> of feed during scarcity. And yet, data on wet distillers grains DML is highly limited. This study investigated the effect of 0. 1 % w/w CakeGuardTM preservative (propionic acid-based) and temperature (10 °C, 20 °C and 30 °C) on modified wet distillers grains with solubles (MWDGS) DML under aerobic conditions during storage for 21 days. There was significant difference in DML with preservative treatment at 20 °C and 30 °C. Effect of temperature treatment was significant. Preservative and temperature interaction effect on DML was significant. Treated MWDGS DML after 21 days averaged 3. 12 %, 16. 8 % and 19. 3 % DML whereas untreated samples averaged 3. 22 %, 21. 4 % and 28. 0 % DML at 10 °C, 20 °C and 30 °C respectively. Overall, the preservative helped maintain appearance and texture of the wet feed within the storage period. While further research is obviously necessary to define criteria for predicting storage losses, this study serves {{as a foundation for}} future investigations...|$|R
40|$|The present {{stage of}} {{development}} of society and in our country, also is abroad designated as time of active search of new ways of development of the personality, development of its creative initiative, independence, mobility. The tendency of formation of open model of the educational process which feature is integration of all ways of development by {{the person of the}} world is observed. For open education openness, a modularity, a continuity, efficiency, <b>availability,</b> <b>fundamental</b> nature, an individual approach are characteristic. This new quality of education based on coauthorship, cooperation, continuous search, formation of new reference points and the purposes, formation of creativity of participants of educational process. Creativity as ability to creativity is directly connected with such concept, as terminal value of creativity. Understanding of creativity not as tool value and as to terminal value will promote its positive realization self-sufficient, self-staticized. Creative people aspire to show the abilities in favourite business, possibility of creativity and self-realization gives them pleasure, is perceived as a source of pleasure and meaning of the life. As creativity - indispensable attribute of self-updating, it is shown in ability in everything to find possibility for creativity. Creative, focused on creativity and selfupdating people are psychologically ready to innovations in professional activity, are less subject to the professional "burning out" so often meeting presently. Both stressful, and monotonous, monotonous conditions of pedagogical activity don't lead at them to emergence of feeling of powerlessness and depression, indifference in relation to professional activity...|$|R
40|$|This thesis aims to {{establish}} a demand model for commodities that takes all crucial influencing factors into account. To begin with, we analyze the dependency of the demand on prices, market parameters, and specific characteristics of the customers {{in order to provide}} the mathematical framework for a general demand model. In particular, this approach takes account of effects that are caused by price-based substitution of products irrespective of their <b>availability.</b> <b>Fundamental</b> market models that include supply-demand interactions gain importance in the context of commodity pricing. We explicitly develop demand models for petrochemical products that are applicable within the profit maximization problem of a monopoly in order to determine optimal price and sales decisions. The solvability of the market optimization problem requires additional restrictions on the modeling. Basically, the model displays the nonlinear demand-price relationship. Model extensions incorporate the changes of macroeconomic indices, which quantify changes in the economic situation. Moreover, our approach to modeling demand comprises the impacts of varying prices of substitutable and complementary products, and establishes a connection to the characteristics of the consumer's side. Integrating the demand models to real market models necessitates the identification of the demand parameters. We discuss the difficulty to get reliable parameter estimates in the situation of incomplete data and investigate two methods based on additional assumptions in order to estimate the demand parameters. For the demand model that includes the dependency on the price and macroeconomic indices, a heuristic methodology firstly determines parameters based on market simulations. The second approach creates an inequality constrained parameter identification problem, where the constraints reflect additional assumptions on the shape of the demand model function. This problem can be solved using the generalized Gauss-Newton method. ...|$|R
40|$|Abstract This thesis {{explores the}} {{trajectory}} that the developing technological fields of Ambient Intelligence and Persuasive Technologies introduce new intricate relationships beyond <b>fundamental</b> use and <b>availability</b> because they change our abilities to act. Since its classic articulation by Hegel (1927) philosophical explication {{of the relationship}} between people and technology states that technology is a mediating factor between people and the world. Associated with this view, which has characterized the resulting phenomenology and philosophy of technology for nearly two decades, is an understanding of technology as a form of alienation. In this dissertation the author shows how this old interpretation {{of the relationship between}} a person and their tool has emphasized how the person is active whilst the tool is passive. This traditional distinction fails to grasp the complex interaction between people and technology in the contemporary world. The nature of new technologies and novel theoretical work in this field suggests that this critical framework is now inadequate. Today, technology mediates the relationship between people and the world in increasingly complex and often collective ways. McLuhan (1967) stated: “Media evoke in us unique ratios of sense perceptions. The extension of any one of these senses alters the way we think and act”. As Greenfield (2006) and Fogg (2002) also posit, certain Ambient Intelligence and Persuasive Technologies are in-principle shaping everyday human behaviours in radically new ways. In particular, I explore how new technologies like those developed in the Artificial Companions Project can impact on our understanding of intimacy and identity. Indeed, Ambient Intelligence Technologies may play the role of reference groups (Shibutani 1987), groups who are real or imaginary and whose standpoints are being used as the frame of reference for the human actor. Given that these technologies have continuously reconfigured identification and profiling practices, this analysis rephrases insight of philosophers like Paul Ricoeur (1990), George Herbert Mead (1959) and Helmuth Plessner (1975) to trace how: The construction of our identity is mediated by how we profile others as profiling us. Thus, new technologies can become reference groups, encroaching on our everyday activities and even affecting our moral decision-making processes. As genuine upgrades of our practical space, they are destined to play a larger formative role in people’s lives in the future. Following Heidegger in Das Ding (Heidegger 1951), Latour once framed the wider social role of technologies as res publica or ‘public things’ (Latour 2005). He pointed out that the old German word ‘ding’ etymologically did not only infer ‘material object’ but also to assembly as gathering space - that thing that can bring together what it separates. Following Latour, Verbeek states that technological ‘things’ do not only mediate our existence, but are places where these mediations are made explicit – therefore, Verbeek argues, they are the places where people have to start to discuss and criticise the quality {{of the ways in which}} these ‘things’ help to shape our daily lives (Verbeek 2008). This thesis attempts to offer a new approach to this criticism through theoretical comparison and transdisciplinary analysis...|$|R
40|$|In {{the last}} years, an {{increasing}} number of social robots have come out from science fiction novels and movies becoming reality. These social robots are interesting not only in the science fiction world but also in the scientific research field. Building socially intelligent robots in a human-centred manner can help us to better understand ourselves and the psychological and behavioural dynamics behind a social interaction. The primary and most important function of a social robot is to appear “believable” to human observers and interaction partners. This means that a social robot must be able to express its own state and perceive the state of its social environment in a human-like way in order to act successfully, i. e., it must possess a “social intelligence” for maintaining the illusion of dealing with a real human being. The term “social intelligence” includes aspects both of appearance and of behaviour that are factors tightly coupled with each other. For example, a social robot designed to be aesthetically similar to an animal is expected to have limited functionalities. Instead, a humanoid robot that physically resembles a human being elicits strong expectations about its behavioural and cognitive capabilities and if such expectations are not being met then a person is likely to experience disorientation and disappointment. The believability of a social robot is not only an objective matter but it also depends on a subjective evaluation of the person involved in the interaction. A social robot will be judged believable or not on the base of the individual experience and background of the person who interacts with the robot. Clearly, {{it is not possible to}} know what is really going on in the mind of that person during the interaction. Nevertheless it is possible to analyse and evaluate the psychophysiological and behavioural reactions of the subject to obtain useful cues for improving the quality and performance of the social interaction. Based on these considerations, this thesis aims to answer two research questions: (1) How can a robot be believable and behave in a socially acceptable manner? and (2) How to evaluate the social interaction of the subject with the robot?. This thesis presents the development of a novel software architecture for controlling a humanoid robot able to reproduce realistic facial expressions on one hand and the development of a software platform for analysing human-robot interaction studies from a point of view of the subject who interacts with the robot on the other hand. The architecture developed for controlling the robot is based on a hybrid Deliberative/Reactive paradigm to make the robot able to quickly react to the events, i. e., reactive behaviours, but even to perform more complex high-level tasks that require reasoning, i. e., deliberative behaviours. The integration of a deliberative system based on a rule expert system with the reactive system makes the robot controllable through a declarative language that is closer to the human natural way of thinking. An interactive graphical interface provides the user with a tool for controlling the behaviour of the robot. Thus, the robot becomes a research tool suitable for investigating its “being social and believable” and testing social behavioural models defined by set of rules. The hybrid architecture for controlling the robot has proven to be a good design for making the robot able to perform complex animations and convey emotional stimuli. The robot can perceive and interpret social cues of the environment, react emotionally to people in the surrounding and follow the person who attracted its attention. The platform developed for studying the subject’s psychophysiological and behavioural reactions during the interaction with a robot is designed to be modular and configurable. On the base of the experiment specifications, multiple and heterogeneous sensors with different hardware and software characteristics can be integrated into the platform. Collecting and fusing together complementary and redundant subject-related information makes possible to obtain an enriched scene interpretation. Indeed merging different types of data can highlight important information that may otherwise remain hidden if each type of data is analysed separately. The multimodal data acquisition platform was used in the context of a research project aimed at evaluating the interaction of normally developing and autistic children with social robots. The results demonstrated the reliability and effectiveness of the platform in storing different types of data synchronously. In multimodal data fusion systems, the problem of keeping the temporal coherence between data coming from different sensors is <b>fundamental.</b> The <b>availability</b> of synchronized heterogeneous data acquired by the platform such as self-report annotations, physiological measures and behavioural observations facilitated the analysis and evaluation of the interaction of the subjects with the robot...|$|R
40|$|This thesis {{explores the}} {{trajectory}} that the developing technological fields of Ambient Intelligence and Persuasive Technologies introduce new intricate relationships beyond <b>fundamental</b> use and <b>availability</b> because they change our abilities to act. Since its classic articulation by Hegel (1927) philosophical explication {{of the relationship}} between people and technology states that technology is a mediating factor between people and the world. Associated with this view, which has characterized the resulting phenomenology and philosophy of technology for nearly two decades, is an understanding of technology as a form of alienation. In this dissertation the author shows how this old interpretation {{of the relationship between}} a person and their tool has emphasized how the person is active whilst the tool is passive. This traditional distinction fails to grasp the complex interaction between people and technology in the contemporary world. The nature of new technologies and novel theoretical work in this field suggests that this critical framework is now inadequate. Today, technology mediates the relationship between people and the world in increasingly complex and often collective ways. McLuhan (1967) stated: “Media evoke in us unique ratios of sense perceptions. The extension of any one of these senses alters the way we think and act”. As Greenfield (2006) and Fogg (2002) also posit, certain Ambient Intelligence and Persuasive Technologies are in-principle shaping everyday human behaviours in radically new ways. In particular, I explore how new technologies like those developed in the Artificial Companions Project can impact on our understanding of intimacy and identity. Indeed, Ambient Intelligence Technologies may play the role of reference groups (Shibutani 1987), groups who are real or imaginary and whose standpoints are being used as the frame of reference for the human actor. Given that these technologies have continuously reconfigured identification and profiling practices, this analysis rephrases insight of philosophers like Paul Ricoeur (1990), George Herbert Mead (1959) and Helmuth Plessner (1975) to trace how: The construction of our identity is mediated by how we profile others as profiling us. Thus, new technologies can become reference groups, encroaching on our everyday activities and even affecting our moral decision-making processes. As genuine upgrades of our practical space, they are destined to play a larger formative role in people’s lives in the future. Following Heidegger in Das Ding (Heidegger 1951), Latour once framed the wider social role of technologies as res publica or ‘public things’ (Latour 2005). He pointed out that the old German word ‘ding’ etymologically did not only infer ‘material object’ but also to assembly as gathering space - that thing that can bring together what it separates. Following Latour, Verbeek states that technological ‘things’ do not only mediate our existence, but are places where these mediations are made explicit – therefore, Verbeek argues, they are the places where people have to start to discuss and criticise the quality {{of the ways in which}} these ‘things’ help to shape our daily lives (Verbeek 2008). This thesis attempts to offer a new approach to this criticism through theoretical comparison and transdisciplinary analysis. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R

