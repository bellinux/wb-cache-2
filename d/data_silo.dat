6|137|Public
50|$|This {{should not}} be {{confused}} with a <b>data</b> <b>silo</b> in computing, like application virtualization, operating-system-level virtualization, or a separation kernel.|$|E
40|$|The overall aim of Enrich is {{to improve}} the {{integration}} of Enlighten 3, the University of Glasgow’s institutional repository service with the institution’s Research System. We recognise that the repository cannot play the range of roles expected by its users and institution if it continues to exist as a separate and disconnected <b>data</b> <b>silo.</b> This project will place the role of the repository as one which is a natural part of the research management cycle rather one which is a separate and disconnected activity. This work will be done in partnership with a range of academic departments and the University’s Research and Enterprise Department...|$|E
40|$|Operationalizing machine {{learning}} based security detections is extremely challenging, {{especially in a}} continuously evolving cloud environment. Conventional anomaly detection does not produce satisfactory results for analysts that are investigating security incidents in the cloud. Model evaluation alone presents {{its own set of}} problems {{due to a lack of}} benchmark datasets. When deploying these detections, we must deal with model compliance, localization, and <b>data</b> <b>silo</b> issues, among many others. We pose the problem of "attack disruption" as a way forward in the security data science space. In this paper, we describe the framework, challenges, and open questions surrounding the successful operationalization of {{machine learning}} based security detections in a cloud environment and provide some insights on how we have addressed them. Comment: 10 pages, 9 figure...|$|E
40|$|The rise in use of {{the social}} web has forced web users to {{duplicate}} their identity in fragmented information spaces. Commonly these spaces contain rich identity representations hidden within walled garden <b>data</b> <b>silos.</b> This paper presents work to export social graphs from such <b>data</b> <b>silos</b> as RDF datasets, and provide linkage between these social graphs according to a graph matching paradigm. Our work contributes to the linked data movement by providing a decentralised social graph containing linked data describing fragmented identity components...|$|R
5000|$|Unify metadata: Extract schemas {{from the}} local data source, map them to a common format, and link the same identities from {{different}} <b>data</b> <b>silos</b> based on a unique identifier.|$|R
40|$|The {{decisions}} {{people make}} about medical treatments {{have a great}} impact on their lives. Health care practitioners, providers and patients often make decisions about medical treatments without complete understanding of the circumstances. The main {{reason for this is that}} medical data are available in fragmented, disparate and heterogeneous <b>data</b> <b>silos.</b> Without a centralised data warehouse structure to integrate these <b>data</b> <b>silos,</b> it is highly unlikely and impractical for the users to get all the information required on time to make a correct decision. In this research paper, a clinical data integration approach using SAS Clinical Data Integration Server tools is presented...|$|R
40|$|Recent Supreme Court {{cases on}} patent-eligible subject matter {{are likely to}} {{exacerbate}} the longstanding problem of biomedical data fragmentation. For each <b>data</b> <b>silo,</b> multiple overlapping legal claims and claimants must be addressed to achieve the benefits of pooling. Commentators who have discussed the data aggregation challenge have generally focused on possibilities created through public funding, through collective action by research participants, or through pressure by payers. This Article emphasizes {{the important role of}} risk regulators, most notably the precedent offered by risk regulation in the area of clinical trial data. While U. S. risk regulators have taken some positive steps, the recent actions of their European counterpart, the European Medicines Agency (EMA), have been particularly creative. Indeed, because data is a global public good, the EMA 2 ̆ 7 s actions create a global baseline for access. Private-sector data pooling spurred by threats of regulatory action is also a positive development. Finally, in those advanced economies that have such exclusivity, data exclusivity that runs concurrently with any patents emerges as an attractive mechanism for balancing the interests of initial and subsequent data generators. In elucidating the role of risk regulators, this Article contributes another chapter to the rich legal and economic literature discussing whether, and how, risk and social regulation can promote socially valuable innovation. As contrasted with much of this literature, however, the Article focuses not on innovation induced by efforts to comply with regulation but instead on regulation as a force for creating a data infrastructure for future innovation...|$|E
40|$|A Feasibility Report {{prepared}} by Centre for Agricultural Informatics in 1995 on establishing a Campus Network for Kerala Agricultural University’s (KAU) main campus (at Vellanikkara, Thrissur) and a state-of-the art Electronic Data Complex in its University Library premises. For {{the dissemination of}} topical awareness and global information to those in agricultural sector of the State, KAU needs to build a Campus LAN and state-of-the art Agricultural Digital Library and Data Complex within its central library. This can become a show case of the electronic age in agriculture and allied disciplines and will promote, propagate and catalogue the agricultural economy that India is so dependent on. The data complex will be a cached repository of agricultural information available worldwide, besides acting as a <b>data</b> <b>silo</b> for research forums, concurrent research, electronic publishing and global bulletin boards. The scattered campuses of KAU and allied institutions {{also need to be}} linked through electronic bridges that enable spontaneous exchange of information between the agricultural Diaspora of students, faculties, researchers, extension workers and administrators. The report covers mandate of the proposed system, detailed discussion on computer and communication stack that KAU Campus Wide Information System and Network needs, the architecture prescription, network design, MultiStack and DEChub 900 options available, host environment, financial terms, implementation methodology, installation support continuum, network synthesis and integration, systems engineering support, time frames and the administrative arrangements required. Open Network, with Protocol Switching and Networked Systems Management based on Digital's enVISN Networking Architecture and Enterprise Management Solutions is recommended. Detailed Technical literature and specifications of each and every item of computer and communication stack and solution recommended is appended to the report. Even though the report was prepared in 1995 it can be of interest for critical studies on history of ICT development in India especially in agricultural sector and for comparison of quality of systems and recommendations of a specific time in the past...|$|E
40|$|Open Data is {{produced}} and used {{at various levels}} in research, governance, policy making and civil society. So far though, conversation around its value and significance has tended to occur within an Open <b>Data</b> <b>silo,</b> existing in parallel with other open discussions around Open Educational Resources and Open Access. In our presentation we explore practices which make use of Open Data as OER, {{with a focus on}} the the opportunities and challenges inherent in this approach. For the OECD, “All citizens should have equal opportunities and multiple channels to access information, be consulted and participate. Every reasonable effort should be made to engage with as wide a variety of people as possible. ” A central challenge in higher education is to develop skills useful not only at subject/professional level, but which also engage students with real-word problems. The skills needed to participate in democratic discussions can be understood as transversal skills, defined by UNESCO (2015) as “Critical and innovative thinking, inter-personal skills; intra personal skills, and global citizenship”. If one of our goals as educators is to develop these transversal skills in students, towards enabling them to function as citizens, to actively participate in the discourse and debates of society, then we propose that Open Data can play a key role. Open Data has been understood as key to research, policy and governance development, and also heralded as a force for democratic discourse and participation, but in our view, this is not achieved by opening data alone. By using Open Data in research- and scenario- based learning activities, educators can enhance the information, digital, statistical and data analysis literacies that can empower students, and ultimately citizens and communities. Such pedagogic activities allow students to learn using the same raw materials researchers and policy- makers produce and use. Drawing from a series of case studies of the use of Open Data as OER, we suggest educators consider the following elements Focus: define the research problem and its relation to the environment students. Practicality: match technical applications and practices to expected solutions. Expectations: set realistic expectations for data analysis. Directions: support in finding data portals which contain appropriate information. Training: provide training materials for the software students will need to analyse the data. Location: use global, local and scientific data which is as granular as possible. Modelling: develop model solutions to guide students on the challenges and activities. Collaboration: support students to work collaboratively and at multidisciplinary level. Communication: support students in communicating their findings to local or wider communities...|$|E
40|$|Abstract. Enterprises are {{increasingly}} using {{a wide range}} of heteroge-neous information systems for executing and governing their business activities. Even if the adoption of service orientation has improved loose coupling and reusability, applications are still isolated <b>data</b> <b>silos</b> whose integration requires complex transformations and mediations. However, by leveraging Linked Data principles those <b>data</b> <b>silos</b> can now be seamlessly integrated, and this opens the door to new data-driven approaches for Enterprise Application Integration (EAI). In this paper we present LDP 4 j, an open souce Java-based framework for the develop-ment of interoperable read-write Linked Data applications, based on the W 3 C Linked Data Platform (LDP) specification...|$|R
50|$|In July 2010, Radiant Logic {{launched}} Context Browser, {{which lets}} users search structured information across <b>data</b> <b>silos,</b> and enables integration across specialized applications and databases. Radiant Logic also released ID-Connect, a free social networking interface based on Microsoft Silverlight that enables customizable views of system users.|$|R
40|$|Motivation: In recent years, {{the gulf}} between the mass of accumulating-research data and the massive {{literature}} describing and analyzing those data has widened. The need for intelligent tools to bridge this gap, to rescue the knowledge being systematically isolated in literature and <b>data</b> <b>silos,</b> is now widely acknowledged...|$|R
50|$|With the {{increase}} in user generated content, disparate <b>data</b> <b>silos,</b> and file formats, information architects and taxonomist {{will be required to}} allow users the ability to tag (classify) the data. This will ultimately cause a ripple effect where users will also be generating ad hoc navigation and information flows.|$|R
40|$|Linked Data {{has emerged}} as a principled, flexible, open {{standard}} based approach to share, integrate and link heterogenous and disparate data across tools, <b>data</b> <b>silos</b> within an organization, and across organizations. It leverages well-established web architecture concepts (e. g., resources identified by URI, and HTTP communication protocol), and introduces RDF as its fundamental data model an...|$|R
40|$|This Article {{discusses}} whether, and how, {{risk and}} social regulation can promote socially valuable innovation. The {{focus is on}} regulation as a force for creating a data infrastructure for future innovation. This Article briefly summarizes the history of overlapping and adjacent intellectual property rights in biomedical innovation. It then discusses {{the manner in which}} the Supreme Court’s reaction to such rights concentration may exacerbate legally-encumbered diagnostic <b>data</b> <b>silos.</b> It will go on to outlines the basic history of biopharmaceutical trial <b>data</b> <b>silos</b> as well as the core legal and policy arguments in favor of increasing access to the aggregated data held by risk regulators. It then discusses recent developments, including the stance taken by European risk regulators. Finally, it discusses lessons from the biopharmaceutical trial data experience and how some of these lessons may play out in current debates over diagnostic testing silos and overlapping rights...|$|R
40|$|Heterogeneous health data is a {{critical}} issue when managing health information for quality decision making processes. In this paper we examine the efficient aggregation of lifestyle information through a data warehousing architecture lens. We present a proof of concept for a clinical data warehouse architecture that enables evidence based decision making processes by integrating and organising disparate <b>data</b> <b>silos</b> in support of healthcare services improvement paradigms...|$|R
40|$|This paper {{describes}} {{the creation of}} an IoT driven architecture to support the realization of an OpenBMS approach to managing blocks of buildings. The objective is to overcome the complexities of integration, operation and management of heterogeneous building systems by leveraging existing IoT approaches. The goal is to eliminate vertical <b>data</b> <b>silos</b> and enable the holistic management of energy across existing and new building blocks...|$|R
50|$|Many Bio-Pharma {{companies}} {{are realizing that}} clinical data across multiple sites in a study, cannot exist in <b>data</b> <b>silos</b> and need a mechanism to harmonize and consolidate it to provide a unified data model and view. One way {{they are trying to}} address this is by requiring their CROs to build Clinical Data Warehouse for them. Other more IT savvy {{companies are}} building their own in-house.|$|R
50|$|Entity {{resolution}} is an operational intelligence process, typically powered by an entity resolution engine or middleware, whereby organizations can connect disparate data sources {{with a view}} to understanding possible entity matches and non-obvious relationships across multiple <b>data</b> <b>silos.</b> It analyzes all of the information relating to individuals and/or entities from multiple sources of data, and then applies likelihood and probability scoring to determine which identities are a match and what, if any, non-obvious relationships exist between those identities.|$|R
50|$|MaXware {{was best}} known for its two {{flagship}} products the Directory Synchronisation Engine (DSE) and Virtual Directory Server (MVD), which is designed specifically for deployment in high-volume, high-complexity environments. MaXware’s MVD acts as an abstraction layer, extracting identity and context information out of various application and <b>data</b> <b>silos.</b> By re-mapping the underlying sources and presenting the identity data in customized views for the needs of enterprise applications, MVD enabled authentication and fine-grained authorization for identity management and context-driven applications.|$|R
50|$|For example: Across {{different}} <b>data</b> <b>silos</b> - employee records, vendor data, watch lists, etc. - {{an organization}} may have several variations of an entity named ABC, {{which may or}} may not be the same individual. These entries may, in fact, appear as ABC1, ABC2, or ABC3 within those data sources. By comparing similarities between underlying attributes such as address, date of birth, or social security number, the user can eliminate some possible matches and confirm others as very likely matches.|$|R
40|$|Large {{volumes of}} {{heterogeneous}} health <b>data</b> <b>silos</b> pose {{a big challenge}} when exploring for information to allow for evidence based decision making and ensuring quality outcomes. In this paper, we present a proof of concept for adopting data warehousing technology to aggregate and analyse disparate health data {{in order to understand}} the impact various lifestyle factors on obesity. We present a practical model for data warehousing with detailed explanation which can be adopted similarly for studying various other health issues...|$|R
50|$|Due the {{mainstream}} embrace of cloud computing {{and the increasing}} desire for businesses to adopt more Big Data practices, the ITOA industry has grown significantly since 2010. A 2016 ExtraHop survey of large and mid-size corporations indicates that 65 percent of the businesses surveyed will seek to integrate their <b>data</b> <b>silos</b> either this year or the next. The current goals of ITOA platforms are to improve the accuracy of their APM services, facilitate better integration with the data, and to enhance their predictive analytics capabilities.|$|R
50|$|Data defined storage {{builds on}} the {{benefits}} of both object storage and software-defined storage technologies, however, object and software-defined storage can only be mapped to the first of data defined storage's three main pillars: media independent data storage, which enables a media agnostic infrastructure - utilizing any type of storage, including low cost commodity storage to scale out to petabyte-level capacities. Data defined storage unifies all data repositories and exposes globally distributed stores through the global namespace, eliminating <b>data</b> <b>silos</b> and improving storage utilization.|$|R
50|$|Radiant Logic is {{best known}} for its RadiantOne Federated Identity platform. The {{software}} line’s flagship product is the Virtual Directory Server Context Edition (VDS-CE), which is designed specifically for deployment in high-volume, high-complexity environments. RadiantOne’s VDS acts as an abstraction layer, extracting identity and context information out of various application and <b>data</b> <b>silos.</b> By re-mapping the underlying sources and presenting the identity data in customized views for the needs of enterprise applications, RadiantOne enables authentication and fine-grained authorization for identity management and context-driven applications.|$|R
50|$|Operational {{intelligence}} integrates information, supporting smarter {{decision making}} in time to maximize impact. By correlating a variety of events and data from both streaming feeds and historical <b>data</b> <b>silos,</b> operational intelligence helps organizations gain real-time visibility of information, in context, through dashboards, real-time insight into business performance, health and status so that immediate action based on business policies and processes can be taken. Operational intelligence applies the benefits of real-time analytics, alerts, and actions to {{a broad spectrum of}} use cases across and beyond the enterprise.|$|R
40|$|Abstract. Large {{universities}} tend {{to spread}} their services across several departments {{to serve their}} substantial student base. It is very common for this to result in developing different systems, which end up in creating many disconnected <b>data</b> <b>silos</b> within the organization. Data isolation {{is one of the}} main bottlenecks that prevent unlocking the full potential behind exploiting such data, to provide a better experience at the level of application deployment and data analysis. The Open University is in the process of connecting their <b>data</b> <b>silos</b> by relying on the Linked Data principles within the LUCERO project. We discuss in this paper three use-cases through which we consume Linked Data produced at the Open University: (1) a student services use-case showing how we exploit data connections to deliver learning material related to courses through the university’s main course information website; (2) a mobile course application that enables students to easily explore courses by subject, qualification or research topic; and (3) a Leanback TV service that provides students the ability to watch, with a degree of control, a set of podcasts grouped in different channels. Through these use cases, we highlight in this paper the advantages and effects of consuming Linked Data within an organization. ...|$|R
40|$|In this paper, authors {{apply the}} Linked Data Design Issues to {{describe}} and retrieve information that is semantically related to open educational resources related to the Engineering Education, that are accessible via the OCW Higher Institutions. Linked data have the potential of create bridges between OCW <b>data</b> <b>silos.</b> To {{assess the impact of}} Linked Data in OCW, the authors present an interface of faceted search for open educational content. The authors demonstrate that OCW resource metadata related to engineering open courses can be consumed and enriched using datasets hosted by the LinkedOpenData cloud...|$|R
40|$|While most {{institutions}} have data-based information systems in place, some fail {{to share and}} use data and information effectively, which often leads to missed opportunities in planning and forecasting and in day-to-day decision making. Reasons for the failure include: 1) the lack of integration among information systems, 2) unclear priorities {{in the collection of}} data, and 3) the creation of <b>data</b> <b>silos</b> that prevent the necessary links between functions and structures across the institution. This report looks at how business officers can encourage the collection and use of institutional data across campus functions...|$|R
5000|$|James Dixon, then chief {{technology}} officer at Pentaho allegedly coined the term to contrast it with data mart, which is a smaller repository of interesting attributes extracted from raw data. He argued that data marts have several inherent problems, and promoted data lakes. These problems are {{often referred to as}} information siloing. PricewaterhouseCoopers said that data lakes could [...] "put an end to <b>data</b> <b>silos.</b> In their study on data lakes they noted that enterprises were [...] "starting to extract and place data for analytics into a single, Hadoop-based repository." ...|$|R
5000|$|Many {{organizations}} {{struggle with}} HR <b>data</b> <b>silos,</b> disconnected technologies, and manual processes, {{the future of}} talent management is embodied in solutions designed {{from the ground up}} to provide business-centric functionality on a unified talent management platform. Talent management system recently have {{been at the forefront of}} growth in the software as a service (SaaS) delivery market following earlier iterations in the standard HR systems space via application service provider (ASP) delivery models. Traditional delivery via on-premises license sales still exist, but are much less prevalent in the competitive space ...|$|R
40|$|Abstract Cultural {{institutions}} and museums have real-ized that annotations contribute valuable metadata for search and retrieval, {{which in turn}} can increase the vis-ibility of the digital items they expose via their digital library systems. By exploiting annotations created by others, visitors can discover content they wouldn’t have found otherwise, which implies that annotations must be accessible and processable for humans and machines. Currently, however, there exists no widely adopted anno-tation standard that goes beyond specific media types. Most institutions build their own in-house annotation so-lution and employ proprietary annotation models, which are not interoperable {{with those of other}} systems. As a result, annotation data are usually stored in closed <b>data</b> <b>silos</b> and visible and processable only within the scope of a certain annotation system. As the main contribution of this paper, we present the LEMO Annotation Frame-work. It (i) provides a uniform annotation model for multimedia contents and various types of annotations, (ii) can address fragments of various content-types in a uniform, interoperable manner, and (iii) pulls annota-tions out of closed <b>data</b> <b>silos</b> and makes them available as interoperable, dereferencable Web resources. With the LEMO Annotation Framework annotations become part of the Web and can be processed, linked, and referenced by other services. This in turn leads to even higher visi-bility and increases the potential value of annotations...|$|R
40|$|Motivation: In recent years, {{the gulf}} between the mass of accumulating-research data and the massive {{literature}} describing and analyzing those data has widened. The need for intelligent tools to bridge this gap, to rescue the knowledge being systematically isolated in literature and <b>data</b> <b>silos,</b> is now widely acknowledged. Results: To this end, we have developed Utopia Documents, a novel PDF reader that semantically integrates visualization and data-analysis tools with published research articles. In a successful pilot with editors of the Biochemical Journal (BJ), the system {{has been used to}} transform static document features into objects that can be linked, annotated, visualized and analyzed interactivel...|$|R
40|$|International audienceToday {{the cloud}} plays {{a central role}} in storing, processing, and distributing data. Despite {{contributing}} to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated <b>data</b> <b>silos</b> and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer...|$|R
40|$|Combining and {{summarizing}} meta-data {{from various}} kinds of data sources is one possible solution to the data fragmentation we are suffering from. Multiple projects have addressed this issue already. This paper presents a new approach named Memacs. It automatically generates a detailed linked diary of our digital artifacts scattered across local files of multiple formats as well as <b>data</b> <b>silos</b> of the internet. Being elegantly simple and open, Memacs uses already existing visualization features of GNU Emacs and Org-mode to provide a promising platform for life-logging, Quantified Self movement, and people looking for advanced Personal Information Management (PIM) in general. Comment: 6 pages, 3 figures, 21 reference...|$|R
40|$|Effective Decision Support Systems (DSS) for {{building}} service managers require adequate performance data from many building <b>data</b> <b>silos</b> {{in order to}} deliver a complete view of building performance. Current performance analysis techniques {{tend to focus on}} a limited number of data sources, such as BMS measured data (temperature, humidity, C 02), excluding a wealth of other data sources increasingly available in the modern building, including weather data, occupant feedback, mobile sensors & feedback systems, schedule information, equipment usage information. This paper investigates the potential for using Linked Data and Semantic Web technologies to improve interoperability across AEC domains, overcoming many of the roadblocks hindering information transfer currently...|$|R
