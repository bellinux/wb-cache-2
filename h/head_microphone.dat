10|50|Public
5000|$|The Neumann KU100 is a dummy <b>head</b> <b>microphone</b> used {{to record}} in {{binaural}} stereo. [...] "It resembles the human head {{and has two}} microphone capsules built into the ears". The Neumann is a commonly used binaural microphone and features use by BBC R&D teams ...|$|E
50|$|He {{has also}} noted for {{creating}} original natural environment recordings {{through the use}} of binaural recording techniques with the Neumann KU-100 <b>head</b> <b>microphone.</b> He's produced an international world soundscapes series and also a 12-part series of Cape Cod recordings that are published at iTunes where there is also a free podcast.|$|E
50|$|Nady is {{credited}} with developing a number of innovations {{in the field of}} wireless audio. Its innovations include the first in-ear monitor system (1978), the first ultra-light wireless <b>head</b> <b>microphone</b> for professional stage performance (1984), the first wireless guitar and bass with built-in transmitter (1986), and the first PLL synthesized UHF frequency agile wireless system (1991).|$|E
50|$|Jonah endorses Sabian cymbals, DW {{drums and}} hardware, Vic Firth sticks, Evans <b>heads,</b> Audix <b>microphones</b> and Factory Metal percussion.|$|R
40|$|Spatial impulse {{response}} analysis techniques {{are commonly used}} {{in the field of}} acoustics, as they help to characterise the interaction of sound with an enclosed environment. This paper presents a novel approach for spatial analyses of binaural {{impulse response}}s, using a binaural model fronted neural network. The proposed method uses binaural cues utilised by the human auditory system, which are mapped by the neural network to the azimuth direction of arrival classes. A cascade-correlation neural network was trained using a multi-conditional training dataset of head-related impulse responses with added noise. The neural network is tested using a set of binaural impulse responses captured using two dummy <b>head</b> <b>microphones</b> in an anechoic chamber, with a reflective boundary positioned to produce a reflection with a known direction of arrival. Results showed that the neural network was generalisable for the direct sound of the binaural room impulse responses for both dummy <b>head</b> <b>microphones.</b> However, it was found to be less accurate at predicting the direction of arrival of the reflections. The work indicates the potential of using such an algorithm for the spatial analysis of binaural impulse responses, while indicating where the method applied needs to be made more robust for more general application...|$|R
50|$|A {{general way}} to {{implement}} 3d sound localization {{is to use}} the HRTF(Head-related transfer function). First, compute HRTFs for the 3D sound localization, by formulating two equations; one represents the signal of a given sound source and the other indicates the signal output from the robot <b>head</b> <b>microphones</b> for the sound transferred from the source. Monaural input data are processed by these HRTFs, and the results are output from stereo headphones. The disadvantage of this method is that many parametric operations are necessary for the whole set of filters to realize the 3D sound localization, resulting in high computational complexity.|$|R
5000|$|During {{a show in}} Dublin, Ireland, in September 2011, Sally Morgan {{was accused}} of {{receiving}} information about her audience members from an off-stage confederate, which she then repeated in her [...] "psychic readings". Following a show at the Grand Canal Theatre, several callers to radio network RTÉ {{reported that they had}} overheard a male voice relaying information to Morgan from the control room {{at the rear of the}} theatre. A caller said, [...] "The first half of the show went really well but when the second half started, we could clearly hear a man's voice coming from the window behind us. Everything he said, the psychic would say 10 seconds later. It was as if she was having the information relayed to her. On her website, Morgan responded to The Guardian report by denying the involvement of all Grand Canal Theatre employees and stating that her <b>head</b> <b>microphone</b> was a one-way device. The Daily Mail was later forced to pay £125,000 in damages after accepting that the earpiece claim was [...] "untrue".|$|E
40|$|Abstract: The higher {{cultural}} and social level of people affected by hypoacusis, leads to a growth of the request of high quality hearing aid systems: to achieve this quality enhancement, the evolution of technologies in the hearing aid and audiometric fields is moving towards the digital world. Even if digital audio prosthesis are not new, the algorithms for the enhancement of speech quality and intelligibility are always being improved. We propose a methodology {{for the evaluation of}} the perceived quality of hearing aids: the simulation of a real two-dimensional soundscape is done using a quadraphonic loudspeaker array, then a speech signal (extracted from the Italian Audiometric Vocal Audio Archive) is reproduced from a single loudspeaker placed in different positions around the virtual soundscape, and everything is recorded through a Dummy <b>Head</b> <b>microphone</b> system with hearing aids placed on the two ears. The analysis of the signal recorded in these simulations is carried out through a complex comparison of various parameters extracted from the signals in output from the Dummy <b>Head</b> <b>microphone</b> and from the hearing aids. 1...|$|E
40|$|This paper {{discloses}} {{the result}} of the experimental study which explores the feasibility and performance of manual auditory navigation system of a mobile robot. The navigation is based on the sensory capability of a human which is refered to as the sound source localization. The operator is instructed to navigate his mobile robot to the location where a sound source is located, based on the auditory cues given to the operator via three different sound playback devices for three different sound sources. The binaural sound which is fed to the operator is captured with a dummy <b>head</b> <b>microphone</b> mounted on the mobile robot. Experimental results indicate feasibility of the auditory navigation, provided that the interaural differences contained in the binaural signal are properly transmitted to the operator's ears...|$|E
5000|$|The {{stories were}} {{recorded}} with dummy head recording or [...] "Kunstkopf binaural sound". The Cabinet of Dr Fritz production used a Neumann Ku81 solid rubber <b>head</b> with <b>microphones</b> set inside {{the inner ear}} chambers, nicknamed [...] "Fritz".|$|R
5000|$|Live: Take No Prisoners was {{recorded}} during {{the series of}} albums where Reed employed {{the use of a}} binaural recording setup, using a dummy <b>head</b> with <b>microphones</b> in each ear. The back cover of the album notes: [...] "Produced by Lou Reed for Sister Ray Enterprises LTD. This is a binaural sound recording." ...|$|R
25|$|The {{supplies}} a drum group carries {{include the}} drum, rawhide headed, a cloth bag for padded drum sticks, the drum stand, folding chairs for sitting, and, in some cases, a public address system. The drum <b>head,</b> stand, <b>microphone</b> stands, and PA box are often decorated with paintings or eagle feathers, fur, flags, and strips of colored cloth.|$|R
40|$|An {{extensive}} set of head-related {{transfer function}} (HRTF 1) measurements of a KEMAR dummy <b>head</b> <b>microphone</b> {{has recently been}} completed. The measurements consist of {{the left and right}} ear impulse responses from a Realistic Optimus Pro 7 loudspeaker mounted 1. 4 meters from the KEMAR. Maximum length (ML) pseudo-random binary sequences were used to obtain the impulse responses at a sampling rate of 44. 1 kHz. In total, 710 different positions were sampled at elevations from- 40 degrees to + 90 degrees. Also measured were the impulse response of the speaker in free field and several headphones placed on the KEMAR. This data is being made available to the research community on the Internet via anonymous FTP and the World Wide Web. 1 Measurement technique Measurements were made using a Macintosh Quadra computer equipped with an Audiomedia II DSP card, which has 16 -bit stereo A/D and D/A converters that operate at a 44. 1 kHz sampling rate. One of the audio output channels was sent to an amplif [...] ...|$|E
40|$|We have {{investigated}} the effects of hypoxia in an altitude chamber on auditory localization. Ten volunteers were tested at 18, 000 ft (5, 486 m), and through 12, 000, 8, 000, and 5, 000 ft (3, 657, 2, 438, and 1, 524 m) with directional sounds recorded via a dummy <b>head</b> <b>microphone</b> and presented binaurally. The sequence encompassed the horizontal plane. We found large intersubject variation in the response to altitude but absolute error (unsigned error) was always increased: at 18, 000 ft the mean effect for the group was highly significant (p < 0. 00001). The effect persisted during descent (p < 0. 001 at 12, 000 ft). Directional bias (mean signed error) was also substantially affected in four subjects, in that sounds originally presented in the lateral quadrants were mislocated further to the rear (p < 0. 05). The incidence of front/behind confusion was not affected by altitude. We discuss these findings {{in relation to the}} proposed use of directional sounds for flight navigation and warning systems...|$|E
40|$|Presented at the 8 th International Conference on Auditory Display (ICAD), Kyoto, Japan, July 2 - 5, 2002. This paper {{describes}} {{the relation between}} physical / acoustic parameters and psychological scale for the sound fields {{in order to create}} an artificial impulse response of the room based on the perception. First, 19 specific words were chosen that expressing subjective impressions of the sound field from a Japanese language dictionary with 42, 000 vocabularies. To classify the 19 words, speech sounds are compared in the way of dichotic listening. The speech sounds are convolution of an anechoic speech and impulse responses of rooms measured by using a dummy <b>head</b> <b>microphone.</b> The words are clustered into 4 categories, 1) high tone timbre, 2) low tone timbre, 3) spaciousness and 4) naturalness or clearness. Then, the 'spatial impression' was selected among 19 words and a scale of it was obtained by way of Thurstone's case V since {{it is one of the}} important factors in the sound field design. Second, to create an impulse response corresponding to the 'spatial impression', we investigate the relation between the 'spatial impression' and physical/acoustic parameters. As a result, we found that the initial part of impulse response is an important part for controlling 'spatial impression'. The result is confirmed by listening test using artificial impulse responses. Finally, we propose a psychological approach for AEML(Acoustic Modeling Language) for Interactive Sound Field Network...|$|E
40|$|The most {{demanding}} test criterion {{for the quality}} of binaural simulations of acoustical environments is whether they can be perceptually distinguished from a real sound field. If the simulation provides natural interacting and sufficient spatial resolution, differences are predominantly perceived in terms of spectral distortions due to a non-perfect equalization of the transfer functions of the recording and reproduction systems (dummy <b>head</b> <b>microphones,</b> head-phones). In order to evaluate different compensation methods, several headphone transfer functions were measured on a dummy head. Based upon these measurements, the performance of different inverse filtering techniques re-implemented from literature was evaluated using auditory measures for spectral differences. Additionally, an ABC/HR listening test was conducted, using two different headphones and two different audio stimuli (pink noise, acoustical guitar). In the listening test, a real loudspeaker was directly compared to a binaural simulation with high spatial resolution, which was compensated using seven different equalization methods...|$|R
50|$|The robot’s <b>head</b> {{has four}} <b>microphones,</b> two HD cameras (in {{the mouth and}} forehead), and a 3-D depth sensor (behind the eyes). There is a {{gyroscope}} in the torso and touch sensors {{in the head and}} hands. The mobile base has two sonars, six lasers, three bumper sensors, and a gyroscope.|$|R
5|$|Gillan is {{a passionate}} {{football}} fan, supporting Queens Park Rangers. He {{is also a}} big fan of cricket. He is also known for his intolerance of aggressive crowd security personnel at concerts. On 15 August 1998, he was charged with assault after striking a security guard on the <b>head</b> with a <b>microphone.</b>|$|R
50|$|In {{binaural}} re-recording, a binaural microphone is used {{to record}} content being played over a multi-channel speaker set-up. The binaural <b>head,</b> or <b>microphone,</b> is therefore theoretically making a recording of how humans will hear multi-channel content. The soundtrack to a film for example will be recorded by the binaural microphone with all the environmental cues of the given location, as well as reverberations, including those commonly created by our own torso (assuming a HATS model is used). This method, like certain binaural recordings made with a Neumann KU100 or HATS model for example, can produce convincing 3D sound.|$|R
40|$|This is the {{audio-visual}} {{condition of}} the Aix Map Task corpus. Two participants sit face-to-face and complete the Map Task. They are native speakers of French. The audio was recorded on <b>head</b> mounted <b>microphones.</b> The video is recorded individually for each participant on MiniDV cameras. Due to image loss, the audio and video are synchronised using a method described in a paper submitted to the IEEE ICASSP 2015 conference in Brisbane. The data and scripts used for the synchonisation process {{can be found in}} the file “Segmentation_Audio_Video. zip“. Ceci est la condition audio-visuelle du corpus Aix Map task. Deux participants sont assis face-à-face et effectuent la Map Task...|$|R
5000|$|Bennett {{recalls that}} period, and recalls from memory other reports of Gray's other pugnacious altercations, the final one, the audible one, was what {{apparently}} impelled Gray's departure. Gray said himself as Bennett recalls the exciting live-broadcast event, [...] "I {{just hit the}} guy over the <b>head</b> with my <b>microphone,</b> folks." [...] In this case the victim had been the aggressor toward Gray.|$|R
50|$|Instead {{of using}} dedicated, hard-ware based VoIP devices, such as IP phones, analog {{telephone}} adapters, or integrated VoIP/Internet access routers, services are provided via a web page and the facilities of the user's computer or hand-held device for accessing and operating a locally attached <b>head</b> set, and <b>microphone.</b> This is assisted by various software components such as Flash, Active X, Silverlight, Java applet or browser plugins like NPAPI.|$|R
40|$|Acoustic maps {{created on}} the basis of the signals {{acquired}} by distributed networks of microphones allow to identify position and orientation of an active talker in an enclosure. In adverse situations of high background noise, high reverberation or unavailability of direct paths to the microphones, localization may fail. This paper proposes a novel approach to talker localization and estimation of head orientation based on the classification of Global Coherence Field (GCF) or Oriented GCF maps. Preliminary experiments with data obtained by simulated propagation as well as with data acquired in a real room show that the match with precalculated map models provides a robust behavior in adverse conditions. Index Terms — Speaker localization, <b>head</b> orientation, <b>microphone</b> arrays, room acoustics, distributed microphone networks...|$|R
40|$|This study {{assessed}} the within-subject variability of voice measures captured using different recording devices (i. e., smartphones and <b>head</b> mounted <b>microphone)</b> and software programs (i. e., Analysis of Dysphonia in Speech and Voice (ADSV), Multi-dimensional Voice Program (MDVP), and Praat).   Correlations between the software programs that calculated the voice measures were also analyzed.   Results demonstrated no significant within-subject variability across devices and software {{and that some}} of the measures were highly correlated across software programs.   The study suggests that certain smartphones may be appropriate to record daily voice measures representing the effects of vocal loading within individuals.   In addition, even though different algorithms are used to compute voice measures across software programs, some of the programs and measures share a similar relationship...|$|R
5000|$|A {{music video}} was {{released}} {{to promote the}} single, showing the band performing the song whilst special effects show a copy of Nielsen's head {{on the tip of}} the guitar, two copies of Carlos' head on the drumkit and at the end, a copy of Zander's <b>head</b> on the <b>microphone.</b> The video was later added to a bonus DVD which came with certain editions of the band's 2003 album [...] "Special One".|$|R
5000|$|At the band's August 12 show at Nikon at Jones Beach Theater in Wantagh, New York, Tyler accidentally hit Joe Perry in the <b>head</b> {{with his}} <b>microphone</b> stand during {{the end of}} [...] "Sweet Emotion", not realizing that Perry had {{approached}} the drum riser that Tyler was standing on. In the ensuing incident, the injured Perry threw down his guitar in anger while Tyler was {{checking to see if}} he was OK and stormed off the stage, but returned to finish the concert.|$|R
5000|$|GG {{was running}} {{in place as}} he waited for the show to start to keep it in. Predictably, the show itself came to a halt when Allin began it by defecating onstage before the set began, wearing only a jockstrap and dog collar. Two songs into the performance, GG began to toss his feces into the {{audience}} and hit a fan in the <b>head</b> with the <b>microphone</b> stand, with the club's owner ordering the bouncers to remove Allin from the club.|$|R
40|$|Abstract—This paper {{addresses}} {{learning and}} recognition of human behavior models from multimodal observation in a smart home environment. The proposed approach {{is part of a}} framework for acquiring a high-level contextual model for human behavior in an augmented environment. A 3 -D video tracking system cre-ates and tracks entities (persons) in the scene. Further, a speech activity detector analyzes audio streams coming from <b>head</b> set <b>microphones</b> and determines for each entity, whether the entity speaks or not. An ambient sound detector detects noises in the environment. An individual role detector derives basic activity like “walking ” or “interacting with table ” from the extracted entity properties of the 3 -D tracker. From the derived multimodal observations, different situations like “aperitif ” or “presentation” are learned and detected using statistical models (HMMs). The objective of the proposed general framework is two-fold: th...|$|R
40|$|This bachelor´s thesis {{deals with}} {{creating}} a computational model for acoustic wave propagation in vocal tract {{and the area}} near the head. The main objective of this work is to map the three-dimensional model of the human head as an additional acoustic environment for more accurate measurement of the human voice {{on the basis of}} data from computed tomography, the study of function of the vocal cords, biomechanics of the human voice and an overview of medical imaging techniques suitable for the display of biomechanical models. The grid for finite element method (FEM) will be created from solid geometry of the vocal tract (from the vocal cords to the lips) and the acoustic space near the human head. The grid will be created in order to obtain new knowledge about the different locations of a human <b>head</b> with <b>microphone...</b>|$|R
50|$|Early Antiseen {{performances}} featured bizarre theatrical stage props involving mannequins, fake {{blood and}} pyrotechnics. Such performances found the group often banned from clubs unused to such presentations. Eventually the group {{tired of the}} logistics and legalities involved with a theatrical stage presentation and phased it out of their act, while increasing the physical mayhem of their stage antics - often destroying their own equipment. Vocalist Clayton began employing acts of self-mutilation, often cutting his face or arms with shards of broken glass or pounding his <b>head</b> with a <b>microphone</b> drawing blood and abrasions.|$|R
30|$|From {{the images}} on the cards, the {{research}} team member asked questions like ‘where is the wolf?', so that MI could point to the correct drawing with her left hand; ‘The wolf is happy, {{does he want to}} sing?', and MI shook her head affirmatively; ‘Which card means singing?', but MI did not find the correct card because there was just a microphone drawn on it. Then, the designer drew an iconic <b>head</b> with a <b>microphone,</b> and this card was put on the table, together with the others. When the question about singing was repeated, MI pointed to the new card.|$|R
50|$|The {{recording}} of Street Hassle was notable in that Reed and his co-producer chose to employ an experimental microphone placement technique called binaural recording. In binaural recording, two microphones {{are placed in}} the studio {{in an attempt to}} mimic the stereo sound of actually being in the room with the performers/instruments. In the case of the recording sessions and concerts that composed Street Hassle, engineers used a mannequin <b>head</b> with a <b>microphone</b> implanted in each ear. Binaural recordings are generally only effective when the user listens to the album through headphones, and do not generally translate correctly through stereo speakers.|$|R
5000|$|A {{music video}} for [...] "I've Got a Feeling" [...] was created with an unknown release date. The video begins with Durand {{walking into a}} futuristic photo booth located in an open space {{surrounded}} by lanterns, while shots of the Ivy members, who are outside of the booth, are displayed. As Durand continues singing, several individuals enter and exit the room while getting their picture taken, each leaving with a CD in their hand. Durand sings into a microphone while Chase and Schlesinger play their guitars. For the final verse, Durand lowers her <b>head</b> to the <b>microphone</b> as the screen fades to black.|$|R
50|$|By World War II, {{an oxygen}} mask {{was added to}} the {{equipment}} as planes flew higher where thinner air required a breathable air supply to the pilots and crew. After World War II into the Korean War, the leather headpiece was gradually replaced with a hard helmet needed as head protection during bailing out (and later with high velocity ejection). Also, goggles were replaced by a visor that was incorporated to the helmet and tinted to protect against sun. Current head gear (appears after the Vietnam War) also includes communications equipment (<b>head</b> set and <b>microphones)</b> to let pilots communicate with ground operations and their crew.|$|R
40|$|Abstract—Sound-source {{localization}} systems typically comprise free-field microphone arrays. In nature, directional acoustic sensing {{evolved to}} rely on diffraction about the head with only two ears. For localization, the brain uses the resultant frequency-dependent acoustic phase and intensity {{differences between the two}} ears. We conceive a biomimetic artificial <b>head</b> with <b>microphones</b> placed on its surface. The interaural functions can be computed analytically by modeling the head as a sphere. We define a suitable metric between interaural functions, whose global minimum provides the true source direction. The natural configuration in which the two sensors are placed antipodally on the sphere has intrinsic rotational symmetry: it allows localization only up to a circle around the interaural axis. We describe two methods for breaking the detrimental symmetry in order to achieve full spherical localization capability. First, we consider rotation of the apparatus relative to the source and the information it adds to the localization metric. We derive analytically the gradient of the pressure field under rotation and compute the induced acoustic flow on the interaural localization functions. Second, we explore placing the sensors in configurations differing from antipodal. We show the efficacy of these methods through simulations. I...|$|R
500|$|A {{music video}} for [...] "I've Got a Feeling" [...] was created with an unknown release date. The video begins with Durand {{walking into a}} futuristic photo booth located in an open space {{surrounded}} by lanterns, while shots of the Ivy members, who are outside of the booth, are displayed. As Durand continues singing, several individuals enter and exit the room while getting their picture taken, each leaving with a CD in their hand. The Smashing Pumpkins guitarist James Iha makes a cameo appearance posing in the booth {{with members of the}} band. Durand sings into a microphone while Chase and Schlesinger play their guitars. For the final verse, Durand lowers her <b>head</b> to the <b>microphone</b> as the screen fades to black.|$|R
