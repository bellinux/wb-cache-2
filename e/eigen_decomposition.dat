113|39|Public
2500|$|... = eig(C); [...] % <b>eigen</b> <b>decomposition,</b> B==normalized eigenvectors ...|$|E
50|$|The {{corresponding}} <b>eigen</b> <b>decomposition</b> isHence the Frobenius covariants, manifestly projections, are withNote , as required.|$|E
50|$|The {{most common}} methods for {{frequency}} estimation involve identifying the noise subspace to extract these components. These methods {{are based on}} <b>eigen</b> <b>decomposition</b> of the autocorrelation matrix into a signal subspace and a noise subspace. After these subspaces are identified, a frequency estimation function is used to find the component frequencies from the noise subspace. The most popular methods of noise subspace based frequency estimation are Pisarenko's method, the multiple signal classification (MUSIC) method, the eigenvector method, and the minimum norm method.|$|E
3000|$|... {{are the two}} {{smallest}} eigen vectors {{obtained from}} the <b>eigen</b> vector <b>decomposition</b> applied on the normalised sensor responses.|$|R
40|$|International audienceShrinkage factors play an {{important}} role in the behaviour of biased estimators. In this paper, we first show that the only way to have bounded shrinkage factors on a subspace is to shrink uniformly on this subspace. Then, we characterize regressions on components that shrink uniformly on the subspaces spanned by their associated weight vectors. We show that this problem is equivalent to solving a set of linear equations involving two different projectors. We define a class of matrices whose <b>eigen</b> <b>decompositions</b> give the solution...|$|R
40|$|Abstract—Method for face {{identification}} {{based on}} <b>eigen</b> value <b>decomposition</b> together with tracing trajectories in the eigen space after the <b>eigen</b> value <b>decomposition</b> is proposed. The proposed method allows {{person to person}} differences due to faces in the different emotions. By using the well known action unit approach, the proposed method admits the faces in the different emotions. Experimental results show that recognition performance depends {{on the number of}} targeted peoples. The face identification rate is 80 % for four peoples of targeted number while 100 % is achieved for the number of targeted number of peoples is two. Keywords-face recognition; action unit; face identification. I...|$|R
50|$|MUSIC detects {{frequencies}} in {{a signal}} by performing an <b>eigen</b> <b>decomposition</b> on the covariance matrix of a data vector {{of the samples}} obtained from the samples of the received signal. When all of the eigenvectors {{are included in the}} clutter subspace (model order = 0) the EV method becomes identical to the Capon method. Thus the determination of model order is critical to operation of the EV method. The eigenvalue of the R matrix decides whether its corresponding eigenvector corresponds to the clutter or to the signal subspace.|$|E
5000|$|The heat {{diffusion}} equation over {{a compact}} Riemannian manifold [...] (possibly with a boundary) is given by,where [...] is the Laplace-Beltrami operator and [...] is the heat distribution {{at a point}} [...] at time [...] The solution to this equation can be expressed as,The <b>eigen</b> <b>decomposition</b> of the heat kernel is expressed as,where [...] and [...] are the [...] eigenvalue and eigenfunction of [...] The heat kernel fully characterizes a surface up to an isometry: For any surjective map [...] between two Riemannian manifolds [...] and , if [...] then [...] is an isometry, and vice versa. For a concise feature descriptor, HKS restricts the heat kernel only to the temporal domain,HKS, similar to the heat kernel, characterizes surfaces {{under the condition that}} the eigenvalues of [...] for [...] and [...] are non-repeating. The terms [...] can be intuited as a bank of low-pass filters, with [...] determining the cutoff frequencies.|$|E
30|$|Therefore, {{the mode}} {{parameters}} including frequency, damping {{and the corresponding}} mode shape may be identified by estimating the state matrix of the linearized power system, and its <b>eigen</b> <b>decomposition,</b> from measured data. With the data-driven SSI technique proposed in Section  3, mode parameters are obtained by identifying the state and output matrices firstly and then performing <b>eigen</b> <b>decomposition.</b>|$|E
40|$|In {{this report}} we first {{describe}} a background subtraction algorithm {{based on the}} use of <b>eigen</b> space <b>decomposition.</b> We then present a method to achive incremental modelling, which allows for faster computation and saving in memory requirements. We discuss the performanceof the algorithm and the issues related to the choice of parametersin details. We also provide a description of a real-time implementation which allows to update a model while being able to operate background subtraction at the same time...|$|R
40|$|Quantifying {{how close}} two {{datasets}} are {{to each other}} is a common {{thing to do in}} scientific research. The Pearson product-moment correlation coefficient r is a widely used measure of the strength between two data series but gives no indication of how similar these are in magnitude. Although a number of indexes have been proposed to compare a dataset with a reference, only few are available to compare two datasets of equivalent (or unknown) reliability. After a brief review and numerical tests of the metrics designed to accomplish this feat, this paper shows how an index proposed by Mielke can, with a minor modification, satisfy a series of desired properties, namely to be adimensional, bounded, symmetric, easy to compute and directly interpretable with respect to r. We thus show that this index can be considered as a natural extension to r that downregulates the value of r according to the bias between analysed datasets. The paper also proposes an effective way to disentangle the systematic and the unsystematic contribution to this agreement based on <b>eigen</b> <b>decompositions.</b> The use and value of the index is also illustrated on synthetic and real datasets. JRC. H. 7 -Climate Risk Managemen...|$|R
40|$|Computing the <b>Eigen</b> Value <b>Decomposition</b> (EVD) of a {{symmetric}} matrix is a frequently encountered problem in adaptive (or smart or software) antenna signal processing, for example, super resolution DOA (Direction Of Arrival) estimation algorithms such as MUSIC (MUltiple Signal Classification) and ESPRIT(Estimation of Signal Parameters via Rotational Invariance Technique). In this paper the hardware {{architecture of the}} fast EVD processor of a symmetric correlation matrix {{for the application of}} an adaptive antenna technology such as DOA estimation is proposed and the basic idea is also presented...|$|R
40|$|<b>Eigen</b> <b>decomposition</b> is {{a central}} {{mathematical}} tool in many pattern recognition and machine learning techniques. However, it becomes computationally infeasible {{in the presence of}} a large set of high-dimensional samples. Moreover, in highly dynamic domains with a continual supply of new samples, an incremental approach that keeps on updating the <b>eigen</b> <b>decomposition</b> will be more desirable than the traditional approach of simply re-computing the decomposition from scratch. In this paper, by using a method for updating singular value decompositions, we propose a procedure to obtain an approximate <b>eigen</b> <b>decomposition</b> by processing the samples in chunks or sequentially. On applying this to principal component analysis for image denoising, experimental results show that this restricted form of updating can still achieve comparable performance as the batch version...|$|E
40|$|In {{this paper}} we present an {{efficient}} algorithm {{to compute the}} <b>eigen</b> <b>decomposition</b> of a matrix that is a weighted sum of the self outer products of vectors such as a covariance matrix of data. A well known algorithm to compute the <b>eigen</b> <b>decomposition</b> of such matrices is though the singular value decomposition, which is available only if all the weights are nonnegative. Our proposed algorithm accepts {{both positive and negative}} weights...|$|E
3000|$|... can be also {{calculated}} using <b>eigen</b> <b>decomposition</b> of these matrices. Equations (10) and (11) {{show that in}} order to obtain [...]...|$|E
40|$|International audienceThis paper {{presents}} an asymptotic {{analysis of the}} <b>eigen</b> value <b>decomposition</b> (EVD) of the sample covariance matrix associated with independent identically distributed (IID) non necessarily circular and Gaussian data that extends the well known analysis presented in the literature for circular and Gaussian data. Closed-form expressions of the asymptotic bias and variance of the sample eigenvalues and eigenvectors are given. As an application of these extended expressions, the statistical performance analysis of the minimum description length (MDL) criterion applied to the detection {{of the number of}} noncircular or/and nonGaussian components is considere...|$|R
40|$|Abstract. The {{classification}} {{phase is}} computationally intensive and frequently recurs in tracking applications in sensor networks. Most related work uses traditional signal processing classifiers, such as Maximum A Posterior (MAP) classifier. Naïve formulations of MAP are not feasible for resource constraint sensornet nodes. In this paper, we study computationally efficient methods for classification. We propose to use one-sided Jacobi iterations for <b>eigen</b> value <b>decomposition</b> of the covariance matrices, the inverse {{of which are}} needed in MAP classifier. We show that this technique greatly simplifies the execution of MAP classifier and makes it a feasible and efficient choice for sensornet applications...|$|R
40|$|Broadband {{adaptive}} beamforming algorithms {{based on}} the least mean square (LMS) family are known to exhibit slow convergence, if the input is correlated. In this paper, we will utilised a recently proposed broadband <b>eigen</b> value <b>decomposition</b> method to provide strong spatial decorrelation, {{while at the same}} time reduces the subspace in which the beamforming algorithm operates. Additional temporal decorrelation is gained by operating the beamformer in oversampled filter banks. Hybrid structures which combine both spatial and temporal decorrelation demonstrate to provide faster convergence speed than the normalised LMS algorithm or either of the decorrelation approach on its own...|$|R
3000|$|By {{employing}} (17) and (18), {{estimate the}} modal parameters through the <b>eigen</b> <b>decomposition</b> {{of the state}} matrix A [...] d [...]...|$|E
40|$|In this paper, we {{introduce}} an algorithm {{for performing}} spectral clustering efficiently. Spectral clustering {{is a powerful}} clustering algorithm that suffers from high computational complexity, due to <b>eigen</b> <b>decomposition.</b> In this work, we first build the adjacency matrix of the corresponding graph of the dataset. To build this matrix, we only consider {{a limited number of}} points, called landmarks, and compute the similarity of all data points with the landmarks. Then, we present a definition of the Laplacian matrix of the graph that enable us to perform <b>eigen</b> <b>decomposition</b> efficiently, using a deep autoencoder. The overall complexity of the algorithm for <b>eigen</b> <b>decomposition</b> is $O(np) $, where $n$ is the number of data points and $p$ is the number of landmarks. At last, we evaluate the performance of the algorithm in different experiments. Comment: 8 Pages- Accepted in 14 th International Conference on Image Analysis and Recognitio...|$|E
30|$|Since {{the use of}} MSNWF in this {{technique}} realizes the subspace <b>eigen</b> <b>decomposition,</b> computation of inversion of the covariance matrix becomes unnecessary and thus reduces the complexity of computation; the MSNWF-DOA can be easily applied in hardware platform [23].|$|E
40|$|Abstract — We {{propose a}} novel {{approach}} to relational cluster-ing: Given a matrix of pairwise similarity values between ob-jects our algorithm computes a partition of the objects such that similar objects {{belong to the same}} cluster and dissimilar objects belong to different clusters. The proposed approach {{is based on the assumption}} that the given similarities are products of cluster membership variables. It is based on <b>eigen</b> vector <b>decomposition</b> and minimizes the squared error between the similarities and the products of membership vectors in an efficient, non–iterative way with guaranteed global optimality. In experiments with real world data we show superior performance to conventional iterative clustering approaches. I...|$|R
40|$|This paper {{introduces}} {{the concept of}} co-ordinate rotation into the conventional FastICA algorithm and proposes a low complexity 2 D FastICA and presents its corresponding architecture. Conventional FastICA uses a preprocessing step involving classical <b>Eigen</b> Value <b>Decomposition</b> problem which, in hardware, is widely solved using Co-ordinate Rotation Digital Computer (CORDIC) technique. The proposed co-ordinate rotation based 2 D FastICA algorithm opens up the opportunity to reuse the same CORDIC unit used for the preprocessing step and thus is capable of reducing the hardware complexity of the conventional FastICA algorithm. Along with the formulation and functionality validation of the proposed algorithm, a detailed hardware complexity analysis is also {{presented in this paper}} and compared with the already reported architectures...|$|R
40|$|International audienceIn {{the plethora}} of second-order {{statistics}} (SOS) based blind channel equalization techniques, only two algorithms are able to perform equalization with a pre-specified delay. Delay selection is a compelling feature {{in order to reduce}} noise enhancement of Zero-Forcing (ZF) equalizers. We show that channel output shifted correlation matrices with different time lags can be combined to obtain a rank-deficient SOS-based matrix whose kernel is made of ZF equalizers of a pre-determined delay. Contrarily to existing algorithms, such a ZF equalizer is obtained at a low complexity: It involves a single <b>Eigen</b> Vector <b>Decomposition</b> (EVD) and does not require prior knowledge nor estimation of the noise power. Such a straightforward estimation translates, also, into better equalization performance at low channel SNR, as confirmed by simulations...|$|R
40|$|Abstract This paper {{focuses on}} a new {{extension}} version of double Divide and Conquer (dDC) algorithm to <b>eigen</b> <b>decomposition.</b> Recently, dDC was proposed for singular value decomposition (SVD) of rectangular matrix. The dDC for SVD consists of two parts. One is Divide and Conquer (D&C) for singular value {{and the other is}} twisted factorization for singular vector. The memory usage of dDC is smaller than that of D&C. Both theoretical and running time are also shorter than those of D&C. In this paper, a new dDC for <b>eigen</b> <b>decomposition</b> is proposed. A shift of origin is introduced into our dDC. By some numerical tests, dDC is evaluated with respect to running time and accuracy...|$|E
40|$|The {{current surge}} of {{interest}} in search and comparison tasks in natural language processing has brought with it a focus on vector space approaches and vector space dimensionality reduction techniques. Presenting data as points in hyperspace provides opportunities to {{use a variety of}} welldeveloped tools pertinent to this representation. Dimensionality reduction allows data to be compressed and generalised. <b>Eigen</b> <b>decomposition</b> and related algorithms are one category of approaches to dimensionality reduction, providing a principled way to reduce data dimensionality that has time and again shown itself capable of enabling access to powerful generalisations in the data. Issues with the approach, however, include computational complexity and limitations on the size of dataset that can reasonably be processed in this way. Large datasets are a persistent feature of natural language processing tasks. This thesis focuses on two main questions. Firstly, in what ways can <b>eigen</b> <b>decomposition</b> and related techniques be extended to larger datasets? Secondly, this having been achieved, of what value is the resulting approach to information retrieval and to statistical language modelling at the ngram level? The applicability of <b>eigen</b> <b>decomposition</b> is shown to be extendable through the use of an extant algorithm; the Generalized Hebbian Algorithm (GHA), and the novel extension of this algorithm to paired data; the Asymmetric Generalized Hebbian Algorithm (AGHA). Several original extensions to the these algorithms are also presented, improving their applicability in various domains. The applicability of GHA to Latent Semantic Analysisstyle tasks is investigated. Finally, AGHA is used to investigate the value of singular value decomposition, an <b>eigen</b> <b>decomposition</b> variant, to ngram language modelling. A sizeable perplexity reduction is demonstrated...|$|E
40|$|Abstract. In {{this paper}} we {{proposed}} a new enhancement technique {{that is based on}} the integration of Decimation Free Directional responses of the Decimation Free Directional Filter Banks (DDFB), adaptive mean filtering and the <b>eigen</b> <b>decomposition</b> of the Hessian matrix. By decomposing the input fingerprint image into decimation free directional images, it is easy to remove the noise directionally by means of adaptive mean filtering and further <b>eigen</b> <b>decomposition</b> of the Hessian matrix was used for the segmentation purpose. As the input fingerprint image is not uniformly illuminated so we have used the bandpass filter for the elimination of non-uniform illumination and for the creation of frequency ridge image before giving it to DDFB. The final enhanced result is constructed on a block-by-block basis by comparing energy of all the directional images and picking one that provides maximum energy. ...|$|E
40|$|Paper {{presented}} to the 5 th Annual Symposium on Graduate Research and Scholarly Projects (GRASP) held at the Hughes Metropolitan Complex, Wichita State University, May 1, 2009. Research completed at the Department of Electrical and Computer Science Engineering, College of EngineeringIn this paper, a new blind Carrier Frequency Offset (CFO) estimation algorithm for Discrete Multi Tone (DMT) system is obtained by introducing the Propagator Method (PM) {{in conjunction with the}} wellknown MUSIC based high resolution searching algorithm. Furthermore, the PM does not require the <b>eigen</b> value <b>decomposition</b> (EVD) or singular value decomposition (SVD) of the covariance matrix of the received signals; computer simulations are also included to demonstrate the effectiveness of the proposed method in comparison with other conventional methods...|$|R
40|$|This paper {{considers}} the sum-rate of wireless broadcast systems with multiple antennas {{at the base}} station. In a conventional MIMO-BC system {{with a large number}} of users, selecting an optimal subset of users to maximizing the overall system capacity is a key design issue. This paper presents a novel approach to investigate the sum-rate using <b>Eigen</b> Value <b>Decomposition</b> (EVD). Particularly, we derive the lower bound on sum-rate of a conventional MIMO-BC using a completely different approach compared to the existing approaches. The paper formulates the rate maximization problem for any number of users and any number of transmitting antennas using EVD approach of the channel matrix. This also shows the impact of channel angle information on the sum-rate of conventional MIMO-BC. Numerical results confirm the benefits of our technique in various MIMO communication scenarios...|$|R
40|$|In Cognitive radio (CR) applicationsUltra-wideband (UWB) impulse radio (IR) signalscan be designedsuch as {{they can}} co-exist with {{licensed}} primary users. Thepulse shapeshould beadjusted such that thepower spectral characteristics not only meet the Federal Communications Commission (FCC) constrains,but also mitigate multiple narrow-band interference at the locations of existing primary users. In thispaper,the Parks-McClellan (PM) Algorithm and the <b>Eigen</b> Value <b>Decomposition</b> (EVD) approach forUWB impulse radio waveform shaping areconsidered. The power spectral density (PSD) and the bit-error-rate (BER) performance of the two methods are compared {{in the presence of}} single and doublenarrow-band interference (NBI). The interferencerejectioncapabilities of the two methods are evaluated andcompared for differentinterference and additive noise levels. In particular, the simulations considerthecoexistence of practical IEEE 802. 15. 4 a UWB systems with both IEEE 802. 11 wireless LAN systemsoperating at 5. 2 GHz and radio location services operating at 8. 5 GHz...|$|R
40|$|The Generalized Hebbian Algorithm {{is shown}} to be {{equivalent}} to Latent Semantic Analysis, and applicable {{to a range of}} LSAstyle tasks. GHA is a learning algorithm which converges on an approximation of the <b>eigen</b> <b>decomposition</b> of an unseen frequency matrix given observations presented in sequence. Use of GHA allows very large datasets to be processed. 1...|$|E
40|$|A simple theorem for Functional Observability is {{presented}} considering the observable and unobservable states {{of a system}} based on Kalman decomposition. The proposed theorem {{is also consistent with}} two other theorems on Functional Observability which was based on <b>eigen</b> <b>decomposition</b> [6]. The paper also reports a new definition for Functional Observability which is consistent with previously reported definitions and theorems [4], [5], [6]...|$|E
40|$|We {{extend a}} recent Sparse Representation-based Classification (SRC) {{algorithm}} for face recognition {{to work on}} 2 D images directly, aiming to reduce the computational complexity whilst still maintaining performance. Our contributions include: (1) a new 2 D extension of SRC algorithm; (2) an incremental computing procedure which can reduce the <b>eigen</b> <b>decomposition</b> expense of each 2 D-SRC for sequential input data; and (3) extensive numerical studies to validate the proposed methods...|$|E
40|$|Space Time Coding is a {{communication}} technique for wireless systems that employs multiple transmit antennas {{in addition to}} multiple receiver antennas. This is becoming a compulsory technology to reduce the operating region of signal to noise ratios. With the ever increasing demand for high data rate, these systems need to be implemented under frequency selective fading conditions, sometimes subject to severe Inter Symbol Interference (ISI). Therefore finding a means to use the existing Space Time Codes which were originally designed for frequency nonselective channels is essential. The real usage of these codes depends on the channel state information available at the receiver side for the decoding. Therefore channel estimation plays a vital role and finding a better method for channel estimation is an important problem. The use of Orthogonal Frequency Division Multiplexing (OFDM) together with Space Time Codes makes the frequency selective channels frequency nonselective due to the increased symbol duration of the OFDM symbols. Channel estimation could be done using several methods. Least Square (LS) Error based channel estimation and Minimum Mean square Error (MMSE) based channel estimation {{are some of the}} available channel estimation methods for Space Time Coded OFDM systems. MMSE estimation is more complex than LS but superior in performance. In this thesis we evaluate the performance and complexity of LS and MMSE channel estimation methods for Space Time Coded OFDM systems. This also considers the application of MMSE based channel estimation method to different Space Time Codes with different modulation schemes. The performance of this channel estimation method and the state of system complexity in the above mentioned situations were also evaluated. We have also considered a low complexity <b>Eigen</b> Vector <b>Decomposition</b> based channel estimation method. The performance of the system was simulated with two transmit and two receive antennas. It has been clearly shown that the MMSE channel estimation method performs better with higher number of states in the Space Time Codes and with higher modulation schemes. The <b>Eigen</b> Vector <b>Decomposition</b> base channel estimation brings a low complexity solution...|$|R
40|$|Abstract—the paper {{presents}} a modified approach of Principal Component Analysis (PCA) for an automatic classification of image database. Principal components are the distinctive or peculiar features of an image. PCA also holds {{information regarding the}} structure of data. PCA {{can be applied to}} all training images of different classes together forming universal subspace or to an individual image forming an object subspace. But if PCA is applied independently on the different classes of objects, the main direction will be different for them. Thus, they can be used to construct a classifier which uses them to make decisions regarding the class. Also the dimension reduction of feature vector is possible. Initially training image set is chosen for each class. PCA, using <b>eigen</b> vector <b>decomposition,</b> is applied to an individual class forming an individual and independent eigenspace for that class. If there are n classes o...|$|R
40|$|The {{focus of}} {{the paper is the}} problem of {{learning}} kernel operators from empirical data. We cast the kernel design problem as the construction of an accurate kernel from simple (and less accurate) base kernels. We use the boosting paradigm to perform the kernel construction process. To do so, we modify the booster so as to accommodate kernel operators. We also devise an efficient weak-learner for simple kernels that is based on generalized <b>eigen</b> vector <b>decomposition.</b> We demonstrate the effectiveness of our approach on synthetic data and on the USPS dataset. On the USPS dataset, the performance of the Perceptron algorithm with learned kernels is systematically better than a fixed RBF kernel. 1 Introduction and problem Setting The last decade brought voluminous amount of work on the design, analysis and experimentation of kernel machines. Algorithm based on kernels can be used for various machine learning tasks such as classification, regression, ranking, and principle componen...|$|R
