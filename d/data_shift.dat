24|1346|Public
5000|$|Line, {{column and}} bounds {{oriented}} copy, cut, <b>data</b> <b>shift,</b> find, paste, sort with picture strings ...|$|E
40|$|Project {{proposal}} (without effort tables) of the openEO project, see [URL]. openEO - A Common, Open Source Interface between Earth Observation Data Infrastructures and Front-End Applications is a H 2020 project funded under call EO- 2 - 2017 : EO Big <b>Data</b> <b>Shift,</b> under proposal number 776242. It {{will run}} from Oct 2017 to Sept 2020...|$|E
40|$|We {{report an}} error in The Construct Validity of Three Entry Level Personality Inventories Used in the UK: A Cautionary Case Study by Neil Anderson and Deniz S. Ones (European Journal of Personality, 2003, Vol. 17, S 39 -S 66). We also alert the reader to a {{potential}} <b>data</b> <b>shift</b> of one data row in the dataset reported on in Anderson and Ones (2003) and provide an alternate table...|$|E
30|$|The above {{three groups}} of {{constraints}} {{are the same as}} those of Model (13). Thus, the proposed <b>data</b> <b>shifts</b> do not influence the constraints in Model (13).|$|R
3000|$|Here, it is {{necessary}} to note that the proposed <b>data</b> <b>shifts</b> can be applied to any data set within our computational common sense. For example, in the single component case, x̃ = x + 100, 000 (i[*]= 1,…, m), g̃ = g + β [...] ([...] = 1) (r[*]= 1,…, s) and b̃ = b + δ ([...] [...] = 1) (f[*]= 1,…, h) are possible as the proposed <b>data</b> <b>shifts</b> (16). The shifts do not produce any mathematical difficulty to us. However, the large data (i.e., input) dominates the computational process Model (12) so often producing unreliable results. This is a computational problem, not a mathematical problem.|$|R
30|$|Equation (20) clearly {{indicate}} the translation invariance in the objective value of Model (13). Thus, the proposed <b>data</b> <b>shifts</b> from zero and/or negative to positive do not influence the objective value of Model (13). The proposition {{indicates that the}} proposed approach can solve the last pitfall.|$|R
40|$|We {{consider}} fundamental {{data manipulation}} operations such as broadcasting, prefix sum, data sum, <b>data</b> <b>shift,</b> data accumulation, consecutive sum, adjacent sum, sorting, and random access reads and writes, and show how {{these may be}} performed on the distributed memory bus computer (DMBC). In addition, we study two image processing applications: shrinking and expanding, and template matching. The DMBC algorithms are generally simpler than corresponding algorithms of the same time complexity developed for other reconfigurable bus computers...|$|E
40|$|<b>Data</b> <b>shift</b> {{blood flow}} {{anomalies}} {{can be obtained}} by observing the shift in frequency of ultrasonic imaging pulse echoes. Doppler Effect: History and Theory, by Paul A. Magnin The shift in the frequency of sound for moving sources and/or listeners is described with its application for medical analysis. 27 Johann Christian Doppler O H Power and Intensity Measurements for Ultrasonic Doppler Imaging Systems, by I James body Carefully controlling the acoustic energy transmitted into the human body requires accurate analysis methods...|$|E
40|$|This {{invention}} {{relates to}} learning decoders for decoding compatible convolutional codes. The decoder decodes signals {{which have been}} encoded by a convolutional coder and allows performance near the theoretical limit of performance for coded data systems. The decoder includes a sub-bit shift register wherein the received sub-bits are entered after regeneration and shifted in synchronization with a clock signal recovered from the received sub-bit stream. The received sub-bits are processed by a sub-bit decision circuit, entered into a sub-bit shift register, decoded by a decision circuit, entered into a <b>data</b> <b>shift</b> register, and updated to reduce data errors. The bit decision circuit utilizes stored sub-bits and stored data bits to determine subsequent data-bits. Data errors are reduced by using at least one up-date circuit...|$|E
50|$|In the USA, {{the time}} signal station WWVL began {{transmitting}} a 500 W signal on 20 kHz in August 1963. It used Frequency Shift Keying (FSK) to send <b>data,</b> <b>shifting</b> between 20 kHz and 26 kHz. The WWVL service was discontinued in July 1972.|$|R
40|$|Measurement of mid spatial {{frequency}} figure error {{is critical to}} large precision optics for missions such as TPF-C. This presentation introduces a technique for increasing the spatial sampling resolution to meet these requirements using conventional video resolution phase-measuring interferometer. Technique involves sub-pixel <b>data</b> <b>shifts,</b> interlaced stitching and PSF deconvolution...|$|R
40|$|As {{photovoltaic}} (PV) {{penetration of}} the power grid increases, it becomes vital to know how decreased power output may affect cost over time. In order to predict power delivery, the decline or degradation rates must be determined accurately. For non-spectrally corrected data several complete seasonal cycles (typically 3 - 5 years) are required to obtain reasonably accurate degradation rates. In a rapidly evolving industry such a time span is often unacceptable and the need exists to determine degradation rates accurately in a shorter period of time. Occurrence of outliers and <b>data</b> <b>shifts</b> are two examples of analytical problems leading to greater uncertainty and therefore to longer observation times. In this paper we compare three methodologies of data analysis for robustness {{in the presence of}} outliers, <b>data</b> <b>shifts</b> and shorter measurement time periods...|$|R
40|$|The {{adiabatic}} inhomogeneities of the scalar curvature {{lead to a}} {{compressible flow}} affecting {{the dynamics of the}} hydromagnetic nonlinearities. The influence of the plasma on the evolution of a putative magnetic field is explored with the aim of obtaining an effective description valid for sufficiently large scales. The bulk velocity of the plasma, computed in the framework of the LambdaCDM scenario, feeds back into the evolution of the magnetic power spectra leading to a (nonlocal) master equation valid in Fourier space and similar to the ones discussed in the context of wave turbulence. Conversely, in physical space, the magnetic power spectra obey a Schroedinger-like equation whose effective potential depends on the large-scale curvature perturbations. Explicit solutions are presented both in physical space and in Fourier space. It is argued that curvature inhomogeneities, compatible with the WMAP 7 yr <b>data,</b> <b>shift</b> to lower wavenumbers the magnetic diffusivity scale. Comment: 29 page...|$|E
40|$|A {{methodology}} for using remotely sensed data to both generate and evaluate a hydraulic model of floodplain inundation is presented for a rural {{case study in}} the United Kingdom: Upton-upon-Severn. Remotely sensed data have been processed and assembled to provide an excellent test data set for both model construction and validation. In order to assess {{the usefulness of the}} data and the issues encountered in their use, two models for floodplain inundation were constructed: one based on an industry standard one-dimensional approach and the other based on a simple two-dimensional approach. The results and their implications for the future use of remotely sensed data for predicting flood inundation are discussed. Key conclusions for the use of remotely sensed data are that care must be taken to integrate different data sources for both model construction and validation and that improvements in ground height <b>data</b> <b>shift</b> the focus in terms of model uncertainties to other sources such as boundary conditions. The differences between the two models are found to be of minor significance. ...|$|E
40|$|A {{new design}} method of {{distributed}} ultrasonic ranging {{system based on}} multi-processor for mobile robots is put forward. This system consists of a high-level work method control unit and a low-level intelligent ultrasonic sensor array acted as the subsystem. In the low-level sensor array, each sensor is controlled by an individual micro-processor which completes the functions such as real-time data processing, interference rejecting, malfunction alarming, parallel communication, and etc. The high-level control unit employs different control strategies to make the low-level sensors grouped for working in parallel way. In the design of software, data processing adopts threshold comparison, advanced <b>data</b> <b>shift</b> average filter, and fuzzy information processing technology. These methods have improved the real-time, precision performance, reliability of the system, and robustness of mobile robot control. To testify {{the performance of the}} ultrasonic ranging system, this paper presents an experiment of mobile robot&# 39;s moving object tracking based on active vision and ultrasonic information under an unknown, dynamic, unstructured complex environment. The experimental results show the proposed ranging system has high validity and reliability...|$|E
5000|$|This uncentred {{correlation}} coefficient is identical with the cosine similarity.Note that the above data were deliberately {{chosen to be}} perfectly correlated: y = 0.10 + 0.01 x. The Pearson {{correlation coefficient}} must therefore be exactly one. Centering the <b>data</b> (<b>shifting</b> x by E(x) = 3.8 and y by E(y) = 0.138) yields x = (−2.8, −1.8, −0.8, 1.2, 4.2) and y = (−0.028, −0.018, −0.008, 0.012, 0.042), from which ...|$|R
30|$|The three Greek {{symbols are}} {{specific}} positive numbers (e.g., 1 and 10) that are subjectively selected by a DEA user(s). As {{a result of}} these <b>data</b> <b>shifts,</b> all production and environmental factors of the jth DMU become x̃_ij > 0 (i[*]= 1,…, m), g̃_rj > 0 (r[*]= 1,…, s) and b̃_fj > 0 (f[*]= 1,…, h), where the symbol (>) implies strict positivity in all components of the three vectors for production factors.|$|R
40|$|Abstract. The Wavelet {{technique}} on 5 -min Rome neutron-monitor data (SVIRCO Observatory & TPL) {{were used}} to evaluate differences in cosmic ray periodicities by using two subsets of data, one before a Forbush decrease onset {{and the other one}} including it; each subset contains several time series of 7 -day <b>data,</b> <b>shifted</b> by one hour. The September 2005 Forbush decrease is investigated and a clear modulation in the about 8 -h periodicity is emerging from the pre-Forbush subsets...|$|R
40|$|Inflammation plays {{a pivotal}} role in all phases of atherosclerosis. High-sensitivity C-reactive protein (hsCRP), the best {{characterized}} biomarker of inflammation, is an independent predictor of future cardiovascular (CV) events and can add further insight to risk stratification. Assessment of hsCRP levels in clinical practice is feasible and inexpensive. Justification for the Use of Statins in Primary Prevention: An Intervention Trial Evaluating Rosuvastatin (JUPITER) was a landmark primary prevention trial that enrolled 17, 802 apparently healthy men and women with low-density lipoprotein cholesterol levels of less than 130 mg/dL and hsCRP levels of 2 mg/L or higher and randomly assigned them to rosuvastatin, 20 mg daily, or placebo. The trial demonstrated that treatment with statin was associated with significant lowering of hsCRP (37 %), with 44 % reduction in incident CV and 20 % reduction in all-cause mortality. These compelling data from the JUPITER trial should encourage changes in our approach toward primary prevention of CV disease and lipid-lowering therapy, as these <b>data</b> <b>shift</b> the focus toward a link between inflammation, statin therapy, and prevention of atherosclerotic CV diseases...|$|E
40|$|Abstract:- To {{improve the}} {{real-time}} and accuracy {{performance of the}} environment detecting system for autonomous mobile robots, and robustness of robot control, a new distributed real-time ultrasonic detecting system for autonomous mobile robot based on multi-processor is designed and manufactured. This system consists of a high-level work method control module and an intelligent ultrasonic sensor array acted as the subsystem. In the sensor array, each sensor is controlled by an individual micro-processor which completes the functions such as real-time data processing, interference rejection, malfunction alarm, parallel communication, and etc. Based on different control strategies, the high-level work method control module decides the sensors at different sides can be grouped to work in parallel way. In this system, data processing adopts “Threshold Comparison”, “Advanced <b>Data</b> <b>Shift</b> Average Filter ” and EERUF methods. These methods have improved the real-time, precision performance, reliability of the system, and robustness of mobile robot control. The simulation and experimental results show the proposed system has high validity and reliability. Key-Words:- ultrasonic sensor, multi-microprocessor, distributed system, interference rejection, autonomou...|$|E
40|$|Ubiquitous {{computing}} {{requires that}} data be handled across {{a very wide}} range of data rates and weights of associated meaning. A suitable system architecture is layered from event data through simple sensors, smart sensors, and smart environment agents. Upward through these layers the issues for representation {{and management of the}} <b>data</b> <b>shift</b> from the distribution and fast, bulk storage of very frequent simple data, to relatively infrequent logical deductions made against relatively complex models. The lower layers of systems for event data will be reused in different applications. In addition, abstract models of location may {{have a lot in common}} between different applications, which a common Location Authority can represent as a common model of the physical environment that changes only slowly (through manual administrative maintenance). On the other hand models of the devices and sensors within locations, and the moving population of people, are far more dynamic, require automatic updating, and different applications choose quite different attributes and relationships to model. We describe how the Merino/Personis architecture for an Intelligent Environment context supports the changes of representation of knowledge across this range and the different programming styles suited to the different levels. Full Tex...|$|E
40|$|A picture {{digitization}} grid {{based on}} logarithmic spirals rather than Cartesian coordinates is presented. Expressing this curvilinear grid as a conformal exponential mapping reveals useful image processing properties. The mapping induces a computational simplification that suggests parallel architectures {{in which most}} geometric transformations are effected by <b>data</b> <b>shifting</b> in memory rather than arithmetic on coordinates. These include fast, parallel noise-free rotation, scaling, and some projective transformations of pixel defined images. Conformality of the mapping preserves local picture-processing operations such as edge detection...|$|R
40|$|Abstract: Reversible logics are a {{promising}} application for low power computing, quantum computing and other emerging computing technologies. The application of multi-valued logic reduces {{the width of}} reversible and quantum computing gates. Barrel shifters are being used for high speed <b>data</b> <b>shifting.</b> In this paper, we propose a ternary bidirectional barrel shifter design which {{is a combination of}} Ternary Feynman and Modified Fredkin Gate. The proposed design is evaluated in terms of Operations, Garbage outputs, Quantum cost and the number of Ancilla inputs...|$|R
40|$|Discontinuities in {{the payoff}} {{function}} (or its derivatives) can cause inaccuracies for numerical schemes when pricing financial contracts. In particular, large errors may {{occur in the}} estimation of the hedging parameters. Three methods of dealing with discontinuities are discussed in this paper: averaging the initial <b>data,</b> <b>shifting</b> the grid, and a projection method. By themselves, these techniques are not sufficient to restore expected behaviour. However, when combined with a special timestepping method, high accuracy is achieved. Examples are provided for one and two factor option pricing problems. ...|$|R
40|$|This {{research}} concerns language {{maintenance and}} shift by adult speakers of Catalan and Spanish in Barcelona. Data has been collected through personal interviews and questionnaires {{with the aim}} of understanding individual sociolinguistic situations and language choices. In this paper language shift behavior by individual speakers is viewed as linguistic mobility. The paper discusses the concept of shift, what kinds of behaviors constitute shift and indications of shift in the present <b>data.</b> <b>Shift</b> behavior is reported by both L 1 Catalan speakers and L 1 Spanish speakers. The findings are also considered in relationship to the concept of linguistic markets (Bourdieu, 1977, 1982, 1991). 2. Theoretical considerations Language contact is a dynamic problem involving many factors, and many theoretical perspectives are useful in studying various aspects of the problem. However, it is difficult to approach researching the overall concerns of language contact, bilingualism, shift and language loss by using just one theoretical viewpoint. A theoretical framework based in the concept of linguistic markets, but with elaboration from other theories, is being developed {{for the purposes of this}} study (Simmons, 2000). The concept of linguistic markets (Bourdieu, 1977, 1982, 1991) provides a background where...|$|E
40|$|We discuss Generalised Least Squares (GLS) {{map-making}} for {{the data}} of the Herschel satellite's photometers, which is a difficult task, due to the many disturbances affecting the data, and requires appropriate pre- and post-processing. Taking an existing map-maker as a reference, we propose several advanced techniques, which can improve both {{the quality of the}} estimate and the efficiency of the software. As a main contribution we discuss two disturbances, which have not been studied yet and may be detrimental to the image quality. The first is a <b>data</b> <b>shift,</b> due to delays in the timing system or in the processing chain. The second is a random noise, termed pixel noise, due to the jitter and the approximation of the pointing information. For both these disturbances, we develop a mathematical model and propose a compensation method. As an additional contribution, we note that the performance can be improved by properly adapting the algorithm parameters to the data being processed and discuss an automatic setting method. We also provide a rich set of examples and experiments, illustrating the impact of the proposed techniques on the image quality and the execution spee...|$|E
30|$|The RAM {{units are}} {{constructed}} as a circular <b>data</b> <b>shift</b> register, {{so that it}} forwards the chosen weight and bias values to the feed-back path {{as well as to}} the multiplier in the feed-forward path [30]. Three 12 -element row vectors, nine 12 -element row vectors with one 9 -element column vector, and two 9 -element row vectors with one 2 -element column vector are the structure of the HL 1, HL 2, and OL memory, respectively. The input, synaptic weight, and bias value shifting are synchronized with the clock manager units that are controlled by the ‘weight_sht_ctrl 1 ’ and ‘bias_sht_ctrl 1 ’ signal for HL 1, the ‘weight_sht_ctrl 2 ’ and ‘bias_sht_ctrl 2 ’ signal for HL 2, and the ‘weight_sht_ctrl 3 ’ and ‘bias_sht_ctrl 3 ’ signal for OL. The weight and bias values are serially shifted to perform the input-weight multiplications, cumulative and bias addition operations to compute the net input of neuron ‘n 1 (.)’ in HL 1 and the weight are serially and bias are paralleley shifted to perform the multiply and accumulation and bias addition operations to compute the neuron net inputs ‘n 21 (.) to n 29 (.)’ and ‘n 31 (.) and n 32 (.)’ in HL 2 and OL, respectively.|$|E
40|$|Abstract—Barrel {{shifters}} {{are often}} required for performing <b>data</b> <b>shifting</b> and rotation in many key computer operations from address decoding to computer arithmetic. In this paper {{we present a}} comparative study of various parameters like delay, power and area, for a high performance 16 -bit barrel shifter VLSI implementations using three different logic design styles (conventional CMOS, transmission gate CMOS and Dual rail Domino CMOS logic) in 0. 6 mm, N-well CMOS process. The proposed barrel shifter implementations shows better performance as compared to implementation by R. Pereira [3]...|$|R
40|$|Abstract. Generalized Relevance Learning Vector Quantization (GRLVQ) is {{combined}} with correlation-based similarity measures. These are derived from the Pearson correlation coefficient in order to replace the adaptive squared Euclidean distance which is typically used for GRLVQ. Patterns can thus be used without further preprocessing and compared in a manner invariant to <b>data</b> <b>shifting</b> and scaling transforms. High accuracies are demonstrated for a reference experiment of handwritten character recognition and good discrimination ability is shown {{for the detection of}} systematic differences between gene expression experiments. Keywords. Prototype-based learning, adaptive metrics, correlation measure, Learning Vector Quantization, GRLVQ. ...|$|R
5000|$|... #Subtitle level 3: <b>Data</b> Validation: Chemical <b>Shifts,</b> NOEs, RDCs ...|$|R
40|$|Pattern {{recognition}} tasks often {{face the}} situation that training data are not fully representative of test data. This problem is well-recognized in speech recognition, where methods like cepstral mean normalization (CMN), vocal tract length normalization (VTLN) and maximum likelihood linear regression (MLLR) are used to compensate for channel and speaker differences. Speech emotion recognition (SER) is an important emerging field in human-computer interaction and faces the same <b>data</b> <b>shift</b> problems, a fact which has been generally overlooked in this domain. In this paper, we show that compensating for channel and speaker differences can give significant improvements in SER by modelling these differences as a covariate shift. We employ three algorithms from the domain of transfer learning that apply importance weights (IWs) within a support vector machine classifier to reduce the effects of covariate shift. We test these methods on the FAU Aibo Emotion Corpus, which {{was used in the}} Interspeech 2009 Emotion Challenge. It consists of two separate parts recorded independently at different schools; hence the two parts exhibit covariate shift. Results show that the IW methods outperform combined CMN and VTLN and significantly improve on the baseline performance of the Challenge. The best of the three methods also improves significantly on the winning contribution to the Challenge...|$|E
40|$|Purpose: To {{develop an}} in vivo {{dosimetry}} based investigative action level relevant for a corrective protocol for HDR brachytherapy boost treatment. Methods and materials The dose delivered to points within the urethra and rectum {{was measured using}} TLD in vivo dosimetry in 56 patients. Comparisons between the urethral and rectal measurements and TPS calculations showed differences, which {{are related to the}} relative position of the implant and TLD trains, and allowed shifts of implant position relative to the prostate to be estimated. Results and conclusions Analysis of rectal dose measurements is consistent with implant movement, which was previously only identified with the urethral <b>data.</b> <b>Shift</b> corrected doses were compared with results from the TPS. Comparison of peak doses to the urethra and rectum has been assessed against the proposed corrective protocol to limit overdosing these critical structures. An initial investigative level of 20 % difference between measured and TPS peak dose was established, which corresponds to 1 / 3 of patients which was practical for the caseload. These patients were assessed resulting in corrective action being applied for one patient. Multiple triggering for selective investigative action is outlined. The use of a single in vivo measurement in the first fraction optimizes patient benefit at acceptable cost...|$|E
40|$|In many {{business}} applications, large data workloads such as sales figures or process performance measures {{need to be}} monitored in real-time. The data analysts want to catch problems in flight to reveal {{the root cause of}} anomalies. Immediate actions need to be taken before the problems become too expensive or consume too many resources. In the meantime, analysts need to have the “big picture ” of what the information is about. In this paper, we derive and analyze two real-time visualization techniques for managing density displays: (1) circular overlay displays which visualize large volumes of data without <b>data</b> <b>shift</b> movements after the display is full, thus freeing the analyst from adjusting the mental picture of the data after each data shift; and (2) variable resolution density displays which allow users to get the entire view without cluttering. We evaluate these techniques with respect to a number of evaluation measures, such as constancy of the display and usage of display space, and compare them to conventional displays with periodic shifts. Our real time data monitoring system also provides advanced interactions such as a local root cause analysis for further exploration. The applications using a number of real-world data sets show the wide applicability and usefulness of our ideas. CR Categories and Subject Descriptors (according to ACM CSS) : I. 3. 3 [Computer Graphics]: Picture/Image Generatio...|$|E
50|$|Traditional LZ-based {{technologies}} {{make use}} of the repetitive characteristic of the data. The decompression process can be done simply by copying the repeated data from the search window according to an index in the compressed data. The data not found in the window is left uncompressed in the compressed data. The uncompressed <b>data</b> is then <b>shifted</b> into the search window for the next repetition and so on. The <b>data</b> is <b>shifted</b> into the window unconditionally without considering the statistical information. Because of limited size of the search window, the first-in <b>data</b> is <b>shifted</b> out unconditionally when the window is full. There are high possibilities that the window is occupied by the useless (non-repetitive) data while the useful (to be repeated) data is banished. To improve the compression ratio, larger search window should be used and hence more memory required in the decompressor.|$|R
40|$|Flight <b>data</b> were <b>shifted</b> in time {{by various}} {{increments}} {{to assess the}} effects of time shifts on estimates of stability and control derivatives produced by a maximum likelihood estimation method. Derivatives could be extracted from flight data with the maximum likelihood estimation method {{even if there was}} a considerable time <b>shift</b> in the <b>data.</b> Time <b>shifts</b> degraded the estimates of the derivatives, but the degradation was in a consistent rather than a random pattern. Time shifts in the control variables caused the most degradation, and the lateral-directional rotary derivatives were affected the most by time shifts in any variable...|$|R
40|$|This paper uses an {{exogenous}} {{change in}} the intrahousehold distribution of income, provided by a change in United Kingdom Family Allowance policy to test the income-pooling hypothesis implied by unitary household models. Expenditure shares are estimated {{for a wide range}} of goods using household-level <b>data.</b> <b>Shifts</b> in expenditure shares suggest that children and mothers benefited at the expense of fathers when this policy change shifted income within households from men to women. Similar shifts are not found among married-couple households with no children. This paper refutes income pooling, and confirms and extends results in Lundberg, Pollak, and Wales (1997). ...|$|R
