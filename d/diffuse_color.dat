35|51|Public
50|$|Similarly, the <b>diffuse</b> <b>color</b> is {{declared}} using Kd.|$|E
5000|$|Texture {{channels}} include <b>diffuse</b> <b>color,</b> reflection color, specular, reflection amount, embedded amount, anisotropy, opacity, smoothness, {{index of}} refraction, glow factor, bump, normal, shadow cast map and mask.|$|E
50|$|Real-time applications, such as video games, usually {{implement}} per-pixel lighting {{through the}} use of pixel shaders, allowing the GPU hardware to process the effect. The scene to be rendered is first rasterized onto a number of buffers storing different types of data to be used in rendering the scene, such as depth, normal direction, and <b>diffuse</b> <b>color.</b> Then, the data is passed into a shader and used to compute the final appearance of the scene, pixel-by-pixel.|$|E
5000|$|... #Caption: Visual {{illustration}} of the Phong equation: here the light is white, the ambient and <b>diffuse</b> <b>colors</b> are both blue, and the specular color is white, reflecting {{a small part of}} the light hitting the surface, but only in very narrow highlights. The intensity of the diffuse component varies with the direction of the surface, and the ambient component is uniform (independent of direction).|$|R
40|$|This paper proposes an {{effective}} color halftone image visual cryptography method to embed a binary secret pattern into dot <b>diffused</b> <b>color</b> halftone images, Data Hiding by Dual Color Conjugate Dot Diffusion (DCCDD). DCCDD considers inter-channel correlation {{in order to}} restrict the embedding distortions between different channels within an acceptable range. Compared to the previous method, the proposed method can hide a secret pattern into two halftone color images which come from different original multitone images. The experimental results show that DCCDD can embed a binary secret pattern into two color halftone images which can be generated from identical or different original multitone color images. When the two halftone images are overlaid, the secret pattern will be revealed...|$|R
50|$|The {{most common}} phosphenes are {{pressure}} phosphenes, caused by rubbing or applying pressure {{on or near}} the closed eyes. They have been known since antiquity, and described by the Greeks. The pressure mechanically stimulates the cells of the retina. Experiences include a darkening of the visual field that moves against the rubbing, a <b>diffuse</b> <b>colored</b> patch that also moves against the rubbing, a scintillating and ever-changing and deforming light grid with occasional dark spots (like a crumpling fly-spotted flyscreen), and a sparse field of intense blue points of light. Pressure phosphenes can persist briefly after the rubbing stops and the eyes are opened, allowing the phosphenes to be seen on the visual scene. Hermann von Helmholtz and others have published drawings of their pressure phosphenes. One example of a pressure phosphene is demonstrated by gently pressing the side of one's eye and observing a colored ring of light on the opposite side, as detailed by Isaac Newton.|$|R
5000|$|Shading {{addresses}} {{how different}} types of scattering are distributed across the surface (i.e., which scattering function applies where). Descriptions of this kind are typically expressed with a program called a shader. (Note {{that there is some}} confusion since the word [...] "shader" [...] is sometimes used for programs that describe local geometric variation.) A simple example of shading is texture mapping, which uses an image to specify the <b>diffuse</b> <b>color</b> at each point on a surface, giving it more apparent detail.|$|E
5000|$|The {{program can}} also be used to modify {{imported}} 3D models from a number of commercial 3D software products by means of plugins called Applinks. [...] Imported models can be converted into voxel objects for further refinement and for adding high resolution detail, complete UV unwrapping and mapping, as well as adding textures for displacement, bump maps, specular and <b>diffuse</b> <b>color</b> maps. A live connection to a chosen external 3D application can be established through the Applink pipeline, allowing for the transfer of model and texture information.|$|E
40|$|Figure 1 : Mix of {{the final}} {{illuminated}} picture, the <b>diffuse</b> <b>color</b> buffer and the normal buffer This paper presents the architecture of a rendering system designed for multithreaded rendering. The implementation of the architecture following a deferred rendering approach shows gains of 65 % on a dual core machine...|$|E
50|$|In {{order to}} create an {{illusion}} that characters and objects filmed {{are present in the}} intended background scene, the lighting in the two scenes must be a reasonable match. For outdoor scenes, overcast days create a <b>diffuse,</b> evenly <b>colored</b> light which can be easier to match in the studio, whereas direct sunlight needs to be matched in both direction and overall color based on time of day.|$|R
5000|$|Garson's {{music was}} used as {{incidental}} music during the television transmissions of the Apollo 11 manned moon landing by Neil Armstrong and Buzz Aldrin in 1969. He said: [...] "The only sounds {{that go along with}} space travel are electronic ones... The Apollo film shows different facets of the flight - blastoff, separation of the stages of the rocket, scenes of the moon at close range, of the astronauts playing games in the ship and of earthrise. music has to carry the film along. It has to echo the sound of the blastoff and even the static you hear on the astronauts' report from space. People are used to hearing things from outer space, not just seeing them. So I used a big, symphonic sound for the blastoff, some jazzy things for the zero-G game of catch, psychedelic music for a section that uses negatives and <b>diffuse</b> <b>colors</b> on shots taken inside the ship, and a pretty melody for the moon. After all, it's still a lovely moon." ...|$|R
50|$|Spectrophotometers {{are used}} to measure the {{specular}} reflectance of mirrors and the <b>diffuse</b> reflectance of <b>colored</b> objects. They {{are used to}} characterize the performance of sunglasses, laser protective glasses, and other optical filters. There are many other examples.|$|R
40|$|Specular {{reflections}} and interreflections produce strong high-lights {{in brightness}} images. These highlights can cause vi-sion algorithms, such as, segmentation, shape from shading, binocular stereo, and motion detection to produce erroneous results. We present an algorithm for separating the specu-lar and d i f i s e components of reflection from images. The method iises color and polarization, simultaneously, to ob-tain strong {{constraints on the}} reflection components at each image point. Polarization is used to locally determine the color oj the specular component, constraining the difSuse color at a pixel to a one dimensional linear subspace. This subspact> is used to find neighboring pixels whose color {{is consistent with the}} pixel. <b>Diffuse</b> <b>color</b> information from consistent neighbors is used to determine the <b>diffuse</b> <b>color</b> of the pixel. In contrast to previous separation algorithms, the proposed method can handle highlights that have a varying diffuse component as well as highlights that include regions with diffkrent reflectance and material properties. We present several txperimental results obtained by applying the algo-rithm to complex scenes with textured objects and strong interrejtrtions. ...|$|E
40|$|Abstract. In this paper, {{we propose}} {{a simple but}} {{effective}} specular highlight removal method using a single input image. Our method {{is based on a}} key observation- the maximum fraction of the <b>diffuse</b> <b>color</b> component (so called maximum diffuse chromaticity in the literature) in local patches in color images changes smoothly. Using this property, we can estimate the maximum diffuse chromaticity values of the specular pixels by directly applying low-pass filter to the maximum fraction of the color components of the original image, such that the maximum diffuse chromaticity values can be propagated from the diffuse pixels to the specular pixels. The <b>diffuse</b> <b>color</b> at each pixel can then be computed as a nonlinear function of the estimated maximum diffuse chromaticity. Our method can be directly extended for multi-color surfaces if edge-preserving filters (e. g., bilateral filter) are used such that the smoothing can be guided by the maximum diffuse chromaticity. But maximum diffuse chromaticity is to be estimated. We thus present an approximation and demonstrate its effectiveness. Recent development in fast bilateral filtering techniques enables our method to run over 200 × faster than the state-of-the-art on a standard CPU and differentiates our metho...|$|E
40|$|We {{present a}} single-image {{highlight}} removal method that incorporates illumination-based constraints into image inpainting. Unlike occluded image regions filled by traditional inpainting, highlight pixels contain some useful information for guiding the inpainting process. Constraints provided by observed pixel colors, highlight color analysis and illumination color uniformity {{are employed in}} our method to improve estimation of the underlying <b>diffuse</b> <b>color.</b> The inclusion of these illumination constraints allows for better recovery of shading and textures by inpainting. Experimental results are given to demonstrate the performance of our method. ...|$|E
40|$|Capturing surface {{appearance}} precisely is paramount for modeling realistic materials. Nevertheless, the spatially varying nature of most materials {{is difficult to}} measure. State-of-the-art methods often rely on complex apparatus and controlled environments, {{and even if they}} are able to acquire reliable SVBRDFs, the whole process usually takes a long time and generates a large amount of data, that is often redun- dant. In this work, we propose a method for fast and assisted acquisition of material properties on-site. The system has a simple setup, requiring only a generic camera and a light source. Consequently, it is also very portable and appropriate for a broad range of object sizes and scenarios. The system guides the acquisition process, allowing for a fast capture session {{while at the same time}} producing high-quality per vertex <b>diffuse</b> <b>colors.</b> To help in achieving a complete coverage it suggests missing light directions, reduc- ing the amount of necessary input images and the acquisition time. The system is designed to work in situ, therefore the whole acquisition process works with immediate feedback and interactive integration of new data. We show results for a variety of objects differing in size and materials...|$|R
2500|$|Hassam {{had moved}} to France to study figure drawing and {{painting}} at the prestigious Académie Julian. He {{took advantage of the}} formal drawing classes with Gustave Boulanger and Jules Joseph Lefebvre, but quickly moved on to self-study, finding that [...] "he Julian academy is the personification of routine... crushes all originality out of growing men. It tends to put them in a rut and it keeps them in it", preferring instead, [...] "my own method in the same degree". His first Parisian works were street scenes, employing a mostly brown palette. He sent these works back to Boston and their sale, combined with that of older watercolors, provided him with sufficient income to sustain his stay abroad. In the autumn of 1887, Hassam painted two versions of Grand Prix Day, employing a breakthrough change of palette. In this dramatic change of technique, he was laying softer, more <b>diffuse</b> <b>colors</b> to canvas, similar to the French Impressionists, creating scenes full of light, done with freer brush strokes. He was likely inspired by French Impressionist paintings which he viewed in museums and exhibitions, though he did not meet any of the artists. Hassam eventually became one of the group of American Impressionists known as [...] "The Ten".|$|R
40|$|Diffusion curves allow {{creating}} complex, smoothly shaded images by <b>diffusing</b> <b>colors</b> defined at curves. These methods typically {{require the}} solution of a global optimization problem (over either the pixel grid or an intermediate tessellated representation) to produce the final image, making fully parallel implementation challenging. An alternative approach, inspired by global illumination, uses 2 D ray tracing to independently compute each pixel value. This formulation allows trivial parallelism, but it densely computes values even in smooth regions and sacrifices support for instancing and layering. We describe a sparse, ray traced, multi-layer framework that incorporates many complementary benefits of these existing approaches. Our solution avoids {{the need for a}} global solve and trivially allows parallel GPU implementation. We leverage an intermediate triangular representation with cubic patches to synthesize smooth images faithful to the per-pixel solution. The triangle mesh provides a resolution-independent, vectorial representation and naturally maps diffusion curve images to a form natively supported by standard vector graphics and triangle rasterization pipelines. Our approach supports many features which were previously difficult to incorporate into a single system, including instancing, layering, alpha blending, texturing, local blurring, continuity control, and parallel computation. We also show how global diffusion curves can be combined with local painted strokes in one coherent system...|$|R
40|$|We {{present a}} method for {{separating}} highlight reflections on textured surfaces. In contrast to previous techniques that use <b>diffuse</b> <b>color</b> information from outside the highlight area to constrain the solution, the proposed method further capitalizes on the spatial distributions of colors to resolve ambiguities in separation that often arise in real images. For highlight pixels in which a clear-cut separation cannot be determined from color space analysis, we evaluate possible separation solutions based on their consistency with diffuse texture characteristics outside the highlight. With consideration of color distributions in both the color space and the image space, appreciably enhanced separation performance can be attained in challenging cases. ...|$|E
40|$|Object’s color {{information}} is not invariant information but is affected by surrounding environments including ambient lights. In this paper, we propsed a new method to acquire intrinsic color information without being affected by ambient lights. In our method, we use a projector as a light source, then capture multiple images with varied color of illumination. Combining these multiple images, we eliminate the influence of ambient lights with avoiding the dark current problem of CCD camera. We show how we treat with other problems caused by specular reflection and interreflection. In the experiments, we show that using our method we can acquire intrinsic <b>diffuse</b> <b>color</b> information without being affeted by ambient lights. ...|$|E
40|$|One of the {{challenges}} when imaging paintings is recording total appearance, that is, the object 2 ̆ 7 s color, surface microstructure (gloss), and surface macrostructure (topography). In this thesis, various systems were used to achieve this task, and a psychophysical paired comparison experiment was conducted to evaluate their performance. A pair of strobe lights arranged at 60 ° from the normal {{on either side of}} the painting captured color information where the strobes produced either directional or diffuse illumination geometry. By adding a third strobe, arranging them 120 ° apart annularly, and cross polarizing, <b>diffuse</b> <b>color</b> and surface normal maps were measured. A fourth strobe was added and the four lights were rearranged 90 ° apart annularly, capturing similar data. This system was augmented by two scanning linear light sources arranged perpendicularly, facilitating the measurement of spatially varying BRDF and specular maps. A laser scanner was used to capture surface macrostructure and was combined with the <b>diffuse</b> <b>color</b> maps from the four-light configuration. Finally, a dome illumination system was used with software developed by Conservation Heritage Imaging to produce color maps. In all, eight different configurations were achieved and used to image three small paintings with a range of appearance attributes. Twenty-five naive observers compared computer-graphic renderings to the actual painting and judged similarity in terms of total appearance, gloss/shininess, texture, and color. Although the rankings varied with painting, two general trends emerged. First, the four-light configuration with or without the independent laser scanning produced images visually equivalent to conventional strobe illumination. Second, diffuse illumination was always ranked lowest...|$|E
5000|$|Hassam {{had moved}} to France {{so that he could}} study figure drawing and {{painting}} at the prestigious Académie Julian. Although he took advantage of the formal drawing classes with Gustave Boulanger and Jules Joseph Lefebvre, he quickly moved on to self-study, finding that [...] "the Julian academy is the personification of routine...training crushes all originality out of growing men. It tends to put them in a rut and it keeps them in it", preferring instead, [...] "my own method in the same degree." [...] His first Parisian works were street scenes, employing a mostly brown palette, and he sent these works back to Boston for sale, which, combined with older watercolors, provided the couple with sufficient income to sustain their stay abroad. In the autumn of 1887, Hassam painted two versions of Grand Prix Day, employing a breakthrough change of palette. In this dramatic change of technique, he was laying softer, more <b>diffuse</b> <b>colors</b> to canvas, similar to the French Impressionists, creating scenes full of light, done with freer brush strokes. He was likely inspired by French Impressionist paintings which he viewed in museums and exhibitions, though he did not meet any of the artists. Hassam eventually became one of [...] "The Ten," [...] a group of American Impressionists.|$|R
40|$|Datum This thesis {{describes}} {{a method for}} approximative soft shadows and diffuse reflections in dynamic scenes, based on a method by Ren et al. [32]. An overview of precomputed radiance transfer and spherical harmonics is also presented, {{as well as a}} short introduction to global illumination. The proposed method uses a low-order spherical harmonics basis to represent incident radiance and visibility on the hemisphere of a receiver point. Diffuse reflecting geometry and shadow casting geometry is represented as sets of spheres. The spheres of an object approximate its shape and <b>diffuse</b> surface <b>color</b> as seen from any viewpoint. In a first pass, the direct illumination of an object is projected to its spheres and stored along with an approximation of the <b>diffuse</b> surface <b>color</b> as SH vectors defined over the surface of each sphere. In a second pass, the average color and the visibility for each sphere at a receiver point is found. The product of average color and visibility is used to approximate the incident radiance from diffuse reflections. Using a sphere set approximation instead of actual geometry for both soft shadows and diffuse reflections allows us to compute the visibility and diffuse reflections of an object on the fly at runtime. This text also {{describes a}} GPU implementation of the method and discusses obtaine...|$|R
40|$|The {{modeling}} of volumetric objects {{is still a}} difficult problem. Solid texture synthesis methods enable the design of volumes with homogeneous textures, but global features such as smoothly varying colors seen in vegetables and fruits are difficult to model. In this paper, we propose a representation called diffusion surfaces (DSs) to enable modeling such objects. DSs consist of 3 D surfaces with colors defined on both sides, such that the interior colors in the volume are obtained by <b>diffusing</b> <b>colors</b> from nearby surfaces. A straightforward way to compute color diffusion is to solve a volumetric Poisson equation with {{the colors of the}} DSs as boundary conditions, but it requires expensive volumetric meshing which is not appropriate for interactive modeling. We therefore propose to interpolate colors only locally at user-defined cross-sections using {{a modified version of the}} positive mean value coordinates algorithm to avoid volumetric meshing. DSs are generally applicable to model many different kinds of objects with internal structures. As a case study, we present a simple sketch-based interface for modeling objects with rotational symmetries that can also generate random variations of models. We demonstrate the effectiveness of our approach through various DSs models with simple non-photorealistic rendering techniques enabled by DSs. CR Categories: I. 3. 7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Color, shading, shadowing, and textur...|$|R
40|$|We {{present a}} new {{approach}} for generating global illumination renderings of hand-drawn characters using only a small set of simple annotations. Our system exploits the concept of bas-relief sculptures, {{making it possible to}} generate 3 D proxies suitable for rendering without requiring side-views or extensive user input. We formulate an optimization process that automatically constructs approximate geometry sufficient to evoke the impression of a consistent 3 D shape. The resulting renders provide the richer stylization capabilities of 3 D global illumination while still retaining the 2 D handdrawn look-and-feel. We demonstrate our approach on a varied set of handdrawn images and animations, showing that even in comparison to ground truth renderings of full 3 D objects, our bas-relief approximation is able to produce convincing global illumination effects, including self-shadowing, glossy reflections, and <b>diffuse</b> <b>color</b> bleeding...|$|E
40|$|Specular {{reflection}} removal {{is indispensable}} to many computer vision tasks. However, most existing methods fail or degrade in complex real scenarios for their individual drawbacks. Benefiting {{from the light}} field imaging technology, this paper proposes a novel and accurate approach to remove specularity and improve image quality. We first capture images with specularity by the light field camera (Lytro ILLUM). After accurately estimating the image depth, a simple and concise threshold strategy is adopted to cluster the specular pixels into "unsaturated" and "saturated" category. Finally, a color variance analysis of multiple views and a local color refinement are individually conducted on the two categories to recover <b>diffuse</b> <b>color</b> information. Experimental evaluation by comparison with existed methods based on our light field dataset together with Stanford light field archive verifies the effectiveness of our proposed algorithm...|$|E
40|$|Abstract—This paper {{presents}} an algorithm for {{the estimation of}} the Surface Light Field using video sequences acquired moving the camera around the object. Unlike other {{state of the art}} methods, it does not require a uniform sampling density of the view directions, but it is able to build an approximation of the Surface Light Field starting from a biased video acquisition: dense along the camera path and completely missing in the other directions. The main idea is to separate the estimation of two components: the <b>diffuse</b> <b>color,</b> computed using statistical operations that allow the estimation of a rough approximation of the direction of the main light sources in the acquisition environment; the other residual Surface Light Field effects, modeled as linear combination of spherical functions. From qualitative and numerical evaluations, the final rendering results show a high fidelity and similarity with the input video frames, without ringing and banding effects. I...|$|E
50|$|Shaders {{are created}} in C4 {{using one of}} two {{available}} methods, both of which isolate the user from the shader code required by the underlying graphics library. Simple shaders can be created by specifying a set of material attributes such as a <b>diffuse</b> reflection <b>color,</b> a specular reflection color, {{and a group of}} texture maps. The engine internally generates the necessary shader code for each combination of material and light type that it encounters when rendering a scene. Material attributes can be used to produce effects such as normal mapping, parallax mapping, horizon mapping, and bumpy reflections or refractions.|$|R
30|$|Generally, the hysteroscopic {{features}} {{associated with}} malignancy are: papillary aspect, size {{larger than a}} half of uterine cavity, irregular, and ulcerated surface, mixed <b>color,</b> <b>diffuse</b> vascularization with anarchical or slightly branched aspect, discordance between the main vascular axe and {{the direction of the}} lesion growth [8].These findings can be used as guide for visual diagnose during panoramic hysteroscopy.|$|R
5000|$|A {{very simple}} {{example of a}} {{complete}} OpenGEX file describing a green cube {{is shown in the}} listing below. It begins with a group of [...] structures that define the units of measurement and the global up direction. Those are followed by a single [...] structure that provides the name and transform for the cube. The geometric data for the cube is stored in the [...] structure that is referenced by the geometry node. The geometry object structure contains a single mesh of triangle primitives that includes per-vertex positions, normals, and texture coordinates. Finally, the [...] structure {{at the end of the}} file contains the green <b>diffuse</b> reflection <b>color.</b>|$|R
40|$|There {{has been}} {{considerable}} {{demand for the}} development of virtual spaces. When virtual spaces such as virtual cities or virtual offices are created, the material colors of 3 D models in these spaces greatly influence the appearance, so designers of virtual spaces must use proper material colors. Material colors of 3 D models can be specified with ambient color, <b>diffuse</b> <b>color,</b> specular color, emissive color, shininess and transparency. These values can be changed interactively by using a graphical user interface based on material editors, and the user can see the effects of those changes. Once the desired material colors have been created, users are required to store them into a personalized material color database. Since users often use subjective terms to describe material colors, it would be useful if the user could retrieve material colors by using subjective terms such as `romantic' and `warm. ' Since commercially available material color databases contain huge amounts of data, manu [...] ...|$|E
40|$|We {{present a}} {{statistical}} method for {{the estimation of}} the Spatially Varying Bidirectional Reflectance Distribution Function (SVBRDF) of an object with complex geometry, starting from video sequences acquired with fixed but general lighting conditions. The aim of this work is to define a method that simplifies the acquisition phase of the object surface appearance and allows to reconstruct an approximated SVBRDF. The final output is suitable {{to be used with}} a 3 D model of the object to obtain accurate and photo-realistic renderings. The method is composed by three steps: the approximation of the environment map of the acquisition scene, using the same object as a probe; the estimation of the <b>diffuse</b> <b>color</b> of the object; the estimation of the specular components of the main materials of the object, by using a Phong model. All the steps are based on statistical analysis of the color samples projected by the video sequences {{on the surface of the}} object. Although the method presents some limitations, the trade-off between the easiness of acquisition and the obtained results makes it useful for practical applications...|$|E
40|$|In {{this work}} we propose {{a method that}} {{facilitates}} transport of a material appearance between objects depicted in two different images. The approach consists of two steps performed on both the material and original images, capturing the object material, and the object of interest itself. The diffuse and specular reflection components are separated by removing specular highlights from the material image. The diffuse components of both images are then used to obtain the surface normals of depicted objects by application of shape from shading algorithm (SFS). The robustness of the method is limited mostly by precise estimations of surface normals and the light direction needed to acquire a reflectance of depicted objects. As this process contains some ambiguities, we do some assumptions about the scene depicted in these images. We assume the objects are lit by a single white directional light source, and object’s <b>diffuse</b> <b>color</b> is not a white. We also assume that there are specular highlights depicted within the images. We have validated the method by a transfer of a real car paints onto an image of abstract 3 D shape...|$|E
50|$|The {{wingspan}} is 12-13 mm. The forewings are dull dark fuscous (nearly black) {{with two}} round ochreous brown spots, one on {{middle of the}} cell and one {{at the end of}} the cell. Below, on the fold is a similarly <b>colored</b> <b>diffused</b> oblong spot touching the first discal spot and reaching down to the dorsal edge. The hindwings are light fuscous.|$|R
40|$|International audienceTwo Co 1 − x Mg x MoO 4 oxide {{compositions}} (x = 0 and x = 0. 4) {{were investigated}} as potential pressure indicators. The first order phase half-transition induced by pressure application from the β to the α form, i. e. {{from the high}} temperature/low pressure form to the high pressure/low temperature form, was studied thanks to the powder <b>diffuse</b> reflection (<b>color)</b> evolution versus the applied pressure. Three key parameters were analyzed: (i) the magnesium content, (ii) the powder grain sizes, (iii) the pressure application mode (uniaxial or isostatical). It was shown these three parameters allow tuning the transition pressure {{in a wide range}} from few bars to few kbars...|$|R
40|$|We {{present a}} grid of {{near-infrared}} (IR) synthetic images of pre-main-sequence stars {{at different stages of}} evolution, which we simulate by varying envelope mass, disk radius and mass, and outflow cavity shape. Our aim is to determine how variations in physical properties of young stellar objects (e. g., mass infall rate, disk size) affect their observed colors and morphology, and use this information to highlight observable differences between different evolutionary states. We show that the near-IR colors are a function of envelope mass infall rate and inclination; hence both parameters must be constrained if colors are to be used to infer a source's true evolutionary state. Sources with more opaque envelopes have redder <b>diffuse</b> <b>colors,</b> because the scattered light suffers reddening as it propagates through the envelope. Somewhat counterintuitively, colors are reddest at intermediate inclinations (i ~ 45 °- 70 °) and then become bluer edge-on, where light is ~ 100 % scattered. Thus a source with relatively blue colors could be an evolved source or a younger source oriented edge-on. Importantly, we find that at inclinations where scattered light dominates, it is erroneous to derive extinction A_V from observed colors; fully half of all objects will underestimate A_V by at least an order of magnitude. We use our models to interpret six protostellar sources in the Taurus-Auriga molecular cloud observed with HST NICMOS. Of the six young stellar objects modeled in this paper, five require an infalling envelope to match the colors and should thus be classified as young embedded sources. The remaining source, Haro 6 - 5 B, is a disk source, having already dispersed its envelope...|$|R
