596|1131|Public
5|$|The log {{discusses}} {{a telephone}} call made at 3:26am on 7 August to Chelmsford police station. According to the prosecution, this is the telephone call {{known to have been}} made by Bamber, the same call that is entered in the <b>event</b> <b>log.</b> There was only one call that night to the police station about the shooting, the prosecution says, and it was made by Bamber at or just before 3:26am. Bamber's defence team argues otherwise. They say that the radio log is not a duplicate log of Bamber's call, but that it shows Nevill also telephoned the police that night.|$|E
5|$|A Folding@home {{participant}} installs {{a client}} program {{on their personal}} computer. The user interacts with the client, which manages the other software components in the background. Through the client, the user may pause the folding process, open an <b>event</b> <b>log,</b> check the work progress, or view personal statistics. The computer clients run continuously in the background at a very low priority, using idle processing power so that normal computer use is unaffected. The maximum CPU use can be adjusted via client settings. The client connects to a Folding@home server and retrieves a work unit and may also download the appropriate core for the client's settings, operating system, and the underlying hardware architecture. After processing, the work unit is returned to the Folding@home servers. Computer clients are tailored to uniprocessor and multi-core processor systems, and graphics processing units. The diversity and power of each hardware architecture provides Folding@home {{with the ability to}} efficiently complete many types of simulations in a timely manner (in a few weeks or months rather than years), which is of significant scientific value. Together, these clients allow researchers to study biomedical questions formerly considered impractical to tackle computationally.|$|E
25|$|The {{removable}} media's capacity must be {{at least}} 256MB (250MB after formatting, Windows 7 reports in its <b>Event</b> <b>Log</b> a required minimum of 235MB).|$|E
40|$|This dataset {{comprises}} <b>event</b> <b>logs</b> (XES = Extensible Event Stream) {{regarding the}} {{activities of daily living}} performed by several individuals. The <b>event</b> <b>logs</b> were derived from sensor data which was collected in different scenarios and represent activities of daily living performed by several individuals. These include e. g., sleeping, meal preparation, and washing. The <b>event</b> <b>logs</b> show the different behavior of people in their own homes but also common patterns. The attached <b>event</b> <b>logs</b> were created with Fluxicon Disco () ...|$|R
40|$|<b>Event</b> <b>logs</b> are an {{important}} data source for identifying usability problems in websites. We present a web-based client-server application, Remote Web <b>Event</b> <b>Logging</b> System (RWELS), for <b>logging</b> user-interface <b>events</b> generated in the Microsoft Internet Explorer during a user’s interaction with {{the pages of a}} website. RWELS <b>logs</b> <b>events</b> without interfering with the user’s interaction – no additional interaction is required on part of a user to enable logging. RWELS is configurable and allows user-centric <b>event</b> <b>logging.</b> A usability analyst can choose the set of events to be captured and the pages of the website to be logged for a particular user. The <b>event</b> <b>logs</b> are dispatched through HTTP to the server where they are stored as text files. Users are identified uniquely and the <b>event</b> <b>logs</b> are associated with the user sessions...|$|R
40|$|Nowadays, {{information}} systems in organizations logged {{many kinds of}} <b>event</b> <b>logs.</b> These logs can be analyzed with process mining. The goal of process mining is to extract information from <b>event</b> <b>logs</b> {{and use it as}} an insights into the business process of the organizations. Unfortunately, most process mining techniques only consider process instance in isolatkategorialnfluence the analysis of the organizations. In this paper, we developed an approach to get insights in to context-related information based on <b>event</b> <b>logs,</b> such that useful insights can be easily obtained. Our approach has been evaluated through two case studies. The evaluation outcome confirms that most of the context-related information from <b>event</b> <b>logs</b> can be analyzed...|$|R
25|$|Server Explorer: The Server Explorer tool is used {{to manage}} {{database}} connections on an accessible computer. It {{is also used to}} browse running Windows Services, performance counters, Windows <b>Event</b> <b>Log</b> and message queues and use them as a datasource.|$|E
25|$|Windows Vista {{includes}} a completely overhauled and rewritten Event logging subsystem, known as Windows <b>Event</b> <b>Log</b> which is XML-based and allows applications to more precisely log events, offers better views, filtering and categorization by criteria, automatic log forwarding, centrally logging and managing events {{from a single}} computer and remote access.|$|E
25|$|Windows Vista {{includes}} an overhauled Task Scheduler that uses hierarchical folders of tasks. The Task Scheduler can run programs, send email, or display a message. The Task Scheduler can also now {{be triggered by}} an XPath expression for filtering events from the Windows <b>Event</b> <b>Log,</b> and can respond to a workstation's lock or unlock, and {{as well as the}} connection or disconnection to the machine from a Remote Desktop. The Task Scheduler tasks can be scripted in VBScript, JScript, or PowerShell.|$|E
50|$|Windows Vista {{includes}} {{a number of}} self-diagnostic features which help identify various problems and, if possible, suggest corrective actions. The <b>event</b> <b>logging</b> subsystem in Windows Vista also has been completely overhauled and rewritten around XML to allow applications to more precisely <b>log</b> <b>events.</b> Event Viewer has also been rewritten {{to take advantage of}} these new features. There are a large number of different types of <b>event</b> <b>logs</b> that can be monitored including Administrative, Operational, Analytic, and Debug log types. For instance, selecting the Application Logs node in the Scope pane reveals numerous new subcategorized <b>event</b> <b>logs,</b> including many labeled as diagnostic <b>logs.</b> <b>Event</b> <b>logs</b> can now be configured to be automatically forwarded to other systems running Windows Vista or Windows Server 2008. <b>Event</b> <b>logs</b> can also be remotely viewed from other computers or multiple <b>event</b> <b>logs</b> can be centrally logged and managed from a single computer. <b>Event</b> <b>logs</b> can be filtered by one or more criteria, and custom views can be created for one or more events. Such categorizing and advanced filtering allows viewing logs related only to a certain subsystem or an issue with only a certain component. Events can also be directly associated with tasks, via the redesigned Event Viewer.|$|R
40|$|A {{collection}} of artificial <b>event</b> <b>logs</b> describing 4 variants {{of a simple}} loan application process. Variant 1 is the most complex process with parallelism and choices. The other 3 variants have a simpler, more sequential, control flow and some activities of variant 1 are missing or split into 2. These <b>event</b> <b>logs</b> are used to test different approaches of discovering a configurable process model from a {{collection of}} <b>event</b> <b>logs...</b>|$|R
40|$|A set of 120 <b>event</b> <b>logs</b> {{was created}} to test {{the effect of the}} {{representational}} bias used and the effect of erratic and infrequent behavior added to highly regular behavior. For each log the underlying model is known. Therefore, such as “gold standard model” serves as a reference for the real process. For real-life <b>event</b> <b>logs</b> there is no such a reference model. Moreover, quality criteria like precision and generalization are still subject to discussion. Therefore, these synthetic <b>event</b> <b>logs</b> were created. The hope is that these <b>event</b> <b>logs</b> contribute to better process discovery tools that can deal with different representational biases and different types of noisy behavior...|$|R
25|$|Recently the National Fire Protection Association and ICC {{voted to}} allow for the {{elimination}} of the 30-day inspection requirement so long as the fire extinguisher is monitored electronically. According to NFPA, the system must provide record keeping {{in the form of an}} electronic <b>event</b> <b>log</b> at the control panel. The system must also constantly monitor an extinguisher’s physical presence, internal pressure and whether an obstruction exists that could prevent ready access. In the event that any of the above conditions are found, the system must send an alert to officials so they can immediately rectify the situation. Electronic monitoring can be wired or wireless.|$|E
500|$|One log {{shows that}} Bamber rang Chelmsford police station—rather than the {{emergency}} number (999)—and spoke to PC Michael West {{in the information}} room. As a result West began an [...] "event log". This states that Bamber's call came in at 3.36am on 7 August 1985. The timing is important; Bamber maintains that he telephoned 10 minutes after his father phoned him. But at trial it was accepted that West had misread a digital clock, and that the call had probably come in just before 3:26am, because that was when West asked a civilian dispatcher, Malcolm Bonnett, to send a car to the scene. The car, Charlie Alpha 5, was dispatched at 3:35 am. The <b>event</b> <b>log</b> noted a call from: ...|$|E
2500|$|PowerShell 5.1 is {{the first}} version to come in two editions of [...] "Desktop" [...] and [...] "Core". The [...] "Desktop" [...] edition is the {{continuation}} of the traditional Windows PowerShell that runs on full [...]NET Framework stack. The [...] "Core" [...] edition runs on [...]NET Core and is bundled with Windows Server 2016 Nano Server. In exchange for smaller footprint, the latter lacks some features such as the cmdlets to manage clipboard or join a computer to a domain, WMI version 1 cmdlets, <b>Event</b> <b>Log</b> cmdlets and profiles.|$|E
50|$|Introduced {{with the}} launch of the Cisco ASA 5580 products, NetFlow Security <b>Event</b> <b>Logging</b> {{utilizes}} NetFlow v9 fields and templates in order to efficiently deliver security telemetry in high performance environments. NetFlow Security <b>Event</b> <b>Logging</b> scales better than syslog while offering the same level of detail and granularity in <b>logged</b> <b>events.</b>|$|R
40|$|Process mining {{is a new}} {{emerging}} discipline {{related to}} process management, formal process models, and data mining. One of the main tasks of process mining is the model synthesis (discovery) based on <b>event</b> <b>logs.</b> A wide range of algorithms for process model discovery, analysis, and enhancement is developed. The real-life <b>event</b> <b>logs</b> often contain noise of different types. In this paper we describe the main causes of noise in the <b>event</b> <b>logs</b> and study the effect of noise {{on the performance of}} process discovery algorithms. The experimental results of application of the main process discovery algorithms to artificial <b>event</b> <b>logs</b> with noise are provided. Specially generated <b>event</b> <b>logs</b> with noise of different types were processed using the four basic discovery techniques. Although modern algorithms can cope with some types of noise, in most cases, their use does not lead to obtaining a satisfactory result. Thus, {{there is a need for}} more sophisticated algorithms to deal with noise of different types...|$|R
40|$|AbstractEvent logs are an {{important}} data source for identifying usability problems in websites. We present a web-based client-server application, Remote Web <b>Event</b> <b>Logging</b> System (RWELS), for <b>logging</b> user-interface <b>events</b> generated in the Microsoft Internet Explorer during a user's interaction with {{the pages of a}} website. RWELS <b>logs</b> <b>events</b> without interfering with the user's interaction — no additional interaction is required on part of a user to enable logging. RWELS is configurable and allows user-centric <b>event</b> <b>logging.</b> A usability analyst can choose the set of events to be captured and the pages of the website to be logged for a particular user. The <b>event</b> <b>logs</b> are dispatched through HTTP to the server where they are stored as text files. Users are identified uniquely and the <b>event</b> <b>logs</b> are associated with the user sessions...|$|R
2500|$|As {{described}} in U.S. Patent 6,233,389, TiVo claims {{a system for}} parsing real-time television metadata in an external ASIC. TiVo's system either uses the metadata embedded in an MPEG2 transport stream or generates similar metadata for analog broadcasts using the information provided by North American Broadcast Teletext Standard. The metadata is used to determine when specific events occur. Saving the <b>event</b> <b>log</b> {{makes it possible for}} the TiVo system to perform the following operations: [...] "reverse, fast forward, play, pause, index, fast/slow reverse play, and fast/slow play." [...] One novel aspect of TiVo's '389 patent is the ASIC implementation. By dedicating a specialized processing unit to event detection, the application processor can be used for other tasks. TiVo's patent refers to their event coprocessor as the [...] "MediaSwitch." ...|$|E
50|$|Event {{collection}} {{is the process}} of collecting event occurrences in a filtered <b>event</b> <b>log</b> for analysis. A filtered <b>event</b> <b>log</b> is logged event occurrences that can be of meaningful use in the future; this implies that event occurrences can be removed from the filtered <b>event</b> <b>log</b> if they are useless in the future. <b>Event</b> <b>log</b> analysis {{is the process of}} analyzing the filtered <b>event</b> <b>log</b> to aggregate event occurrences or {{to decide whether or not}} an event occurrence should be signalled. Event signalling is the process of signalling event occurrences over the event bus.|$|E
5000|$|Access a {{persistent}} <b>event</b> <b>log,</b> stored in protected memory. The <b>event</b> <b>log</b> is available OOB, {{even if the}} OS is down or the hardware has already failed.|$|E
40|$|Process {{discovery}} is the automated construction of structured process models from information system <b>event</b> <b>logs.</b> Such <b>event</b> <b>logs</b> often contain positive examples only. Without negative examples, it {{is a challenge}} to strike the right balance between recall and specificity, and to deal with problems such as expressiveness, noise, incomplete <b>event</b> <b>logs,</b> or the inclusion of prior knowledge. In this paper, we present a configurable technique that deals with these challenges by representing process discovery as a multi-relational classification problem on <b>event</b> <b>logs</b> supplemented with Artificially Generated Negative Events (AGNEs). This problem formulation allows using learning algorithms and evaluation techniques that are well-know in the machine learning community. Moreover, it allows users to have a declarative control over the inductive bias and language bias. <br/...|$|R
40|$|Process mining {{techniques}} {{allow for}} the analysis of business processes based on <b>event</b> <b>logs.</b> For example, the audit trails of a workflow management system, the transaction logs of an enterprise resource planning system, and the electronic patient records in a hospital can be used to discover models describing processes, organizations, and products. Moreover, such <b>event</b> <b>logs</b> {{can also be used to}} compare <b>event</b> <b>logs</b> with some a-priori model to see whether the observed reality conforms to some prescriptive or descriptive model. This chapter takes the MXML format as a starting point, i. e., a format that stores <b>event</b> <b>logs</b> in a unified manner. Based on this format, we will show how process mining techniques can be used to support decision making in business processes...|$|R
40|$|Abstract. Process mining is a {{relatively}} new field of computer science which deals with process discovery and analysis based on <b>event</b> <b>logs.</b> In this work we consider the problem of discovering workflow nets with cancellation regions from <b>event</b> <b>logs.</b> Cancellations occur in the majority of real-life <b>event</b> <b>logs.</b> In spite of huge amount of process mining techniques little has been done on cancellation regions discovery. We show that the state-based region algorithm gives labeled Petri nets with overcomplicated control flow structure for logs with cancellations. We propose a novel method to discover cancellation regions from the transition systems built on <b>event</b> <b>logs</b> and show the way to construct equivalent workflow net with reset arcs to simplify the control flow structure. ...|$|R
5000|$|Eventquery.vbs, Eventcreate.exe, EventTriggers.exe (<b>Event</b> <b>log)</b> ...|$|E
5000|$|Monitors {{local or}} remote Windows <b>Event</b> <b>Log</b> for {{specified}} messages.|$|E
5000|$|Right-click on the <b>Event</b> <b>Log</b> {{and select}} Filter Current Log...|$|E
5000|$|Windows <b>event</b> <b>logs</b> (logins, logouts, audit information, etc.) ...|$|R
40|$|Abstract. Past {{research}} revealed {{issues with}} artificial event data used for comparative analysis of process mining algorithms. The {{aim of this}} research is to design, implement and validate a framework for produc-ing artificial <b>event</b> <b>logs</b> which should increase discriminatory power of artificial <b>event</b> <b>logs</b> when evaluating process discovery techniques...|$|R
50|$|Major event {{subscribers}} {{include the}} Event Collector service and Task Scheduler 2.0. The Event Collector service can automatically forward <b>event</b> <b>logs</b> to other remote systems, running Windows Vista, Windows Server 2008 or Windows Server 2003 R2 on a configurable schedule. <b>Event</b> <b>logs</b> {{can also be}} remotely viewed from other computers or multiple <b>event</b> <b>logs</b> can be centrally logged and monitored agentlessly and managed from a single computer. Events can also be directly associated with tasks, which run in the redesigned Task Scheduler and trigger automated actions when particular events take place.|$|R
50|$|Conformance {{checking}} techniques take as input {{a process}} model and <b>event</b> <b>log</b> and return {{a set of}} differences between the behavior captured in the process model and the behavior captured in the <b>event</b> <b>log.</b> These differences may be represented visually (e.g. overlaid {{on top of the}} process model) or textually as lists of natural language statements (e.g., activity x is executed multiple times in the log, but this is not allowed according to the model). Some techniques may also produce a normalized measures (between 0 and 1) indicating to what extent the process model and the <b>event</b> <b>log</b> match each other.|$|E
50|$|Business process {{conformance}} checking (a.k.a. conformance {{checking for}} short) {{is a family}} of process mining techniques to compare a process model with an <b>event</b> <b>log</b> of the same process. It is used to check if the actual execution of a business process, as recorded in the <b>event</b> <b>log,</b> conforms to the model and vice versa.|$|E
5000|$|Persistent <b>event</b> <b>log,</b> {{stored in}} {{protected}} memory (not {{on the hard}} drive).|$|E
40|$|Abstract. Increasingly {{information}} systems log historic {{information in a}} systematic way. Workflow management systems, but also ERP, CRM, SCM, and B 2 B systems often provide a so-called “event log”, i. e., a log recording the execution of activities. Unfortunately, the information in these <b>event</b> <b>logs</b> is rarely {{used to analyze the}} underlying processes. Process mining aims at improving this by providing techniques and tools for discovering process, control, data, organizational, and social structures from <b>event</b> <b>logs.</b> This paper focuses on the mining social networks. This is possible because <b>event</b> <b>logs</b> typically record information about the users executing the activities recorded in the log. To do this we combine concepts from workflow management and social network analysis. This paper introduces the approach, defines metrics, and presents a tool to mine social networks from <b>event</b> <b>logs.</b> ...|$|R
40|$|<b>Event</b> <b>logs</b> are {{the first}} place where to find useful {{information}} about application failures. <b>Event</b> <b>logs</b> are available at different system levels, such as application, middleware and operating system. In this paper we analyze the failure reporting capability of <b>event</b> <b>logs</b> collected {{at different levels of}} an industrial system in the Air Traffic Control (ATC) domain. The study is based on a data set of 3, 159 failures induced in the system by means of software fault injection. Results indicate that the reporting ability of <b>event</b> <b>logs</b> collected at a given level is strongly affected by the type of failure observed at runtime. For example, even if operating system logs catch almost all application crashes, they are strongly ineffective in face of silent and erratic failures in the considered system...|$|R
40|$|Process mining is the {{research}} domain that {{is dedicated to}} the a posteriori analysis of business process executions. The techniques developed within this research area are specifically designed to provide profound insight by exploiting the untapped reservoir of knowledge that resides within <b>event</b> <b>logs</b> of information systems. Process discovery is one specific subdomain of process mining that entails the discovery of control-flow models from such <b>event</b> <b>logs.</b> Assessing the quality of discovered process models is an essential element, both for conducting process mining research {{as well as for the}} use of process mining in practice. In this paper, a multi-dimensional quality assessment is presented in order to comprehensively evaluate process discovery techniques. In contrast to previous studies, the major contribution of this paper is the use of eight real-life <b>event</b> <b>logs.</b> For instance, we show that evaluation based on real-life <b>event</b> <b>logs</b> significantly differs from the traditional approach to assess process discovery techniques using artificial <b>event</b> <b>logs.</b> In addition, we provide an extensive overview of available process discovery techniques and we describe how discovered process models can be assessed regarding both accuracy and comprehensibility. The results of our study indicate that the HeuristicsMiner algorithm is especially suited in a real-life setting. However, it is also shown that, particularly for highly complex <b>event</b> <b>logs,</b> knowledge discovery from such data sets can become a major problem for traditional process discovery techniques...|$|R
