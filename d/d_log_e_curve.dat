1|2876|Public
40|$|This thesis has two objectives. One {{is to see}} if in {{reversal}} films solarization {{has begun}} before reaching the maximum density in the negative image. Acetone semicarbazone {{was added to the}} emulsions, so that if solarization were significant, this halogen acceptor, by elimination of the solarization, would increase the maximum density. The films tested were KODAK PLUS-X Reversal Film Type 7276, TRI-X Reversal Film Type 7278, Fine Grain Release Positive Type 5302, and PANATOMIC-X. It is concluded that solarization does not {{have a significant effect on}} the maximum density, slope near the maximum density, or density scale of the negative <b>D</b> <b>Log</b> <b>E</b> <b>curve.</b> The second objective is a study to see what happens to the development rate and the sensitivity of the residual silver-halide emulsion after first exposure, first development, and bleaching as a function of the first exposure. The sensitivity is expected to drop quite dramatically with increasing first exposure and the results show it does. For the one film tested, PLUS-X Reversal, it was found that the development rate, corrected for change in Dmax, materially decreased with increasing first exposure. There was a decrease in development rate resulting from bleaching the first image with destruction of chemical sensitization; the effect of exposure was superimposed on this. The bleached film showed a large, unexplained increase in fog on second development...|$|E
40|$|A {{detailed}} description is given {{of the quality}} control program used in the photographic laboratory of the NASA-ERTS Ground Data Handling System. The product response variables measured include tone reproduction, resolution, and low spatial frequency noise. In addition to product response variables, certain performance parameters of the laboratory printers and processors are frequently measured {{in order to produce}} consistent duplications of archival photography. A description is given of the operation and use of a densitometer/computer interface which is used to calculate three tone reproduction response variables - film speed, average gradient, and base plus fog density. This procedure eliminates the need for any hand plotting of D <b>log</b> <b>E</b> <b>curves</b> to manually determine response variables...|$|R
40|$|The S-matrix for planar N = 4 super Yang-Mills {{theory can}} be {{computed}} as the correlation function for a holomorphic polygonal Wilson loop in twistor space. In an axial gauge, {{this leads to}} the construction of the all-loop integrand via MHV diagrams in twistor space. We show that at MHV, this formulation leads directly to expressions for loop integrands in <b>d</b> <b>log</b> form; i. <b>e.,</b> the integrand is a product of exterior derivatives of logarithms of rational functions. For higher MHV degree, it is in <b>d</b> <b>log</b> form multiplied by delta functions. The parameters appearing in the <b>d</b> <b>log</b> form arise geometrically as the coordinates of insertion points of propagators on the holomorphic Wilson loop or on MHV vertices. We discuss a number of examples at one and two loops and give a preliminary discussion of the evaluation of the 1 -loop MHV amplitude. ...|$|R
40|$|Quantum {{sensitivity}} is {{an important}} emulsion property for photographic image formation and is usually calculated from a fraction of grains developable vs. <b>log</b> exposure (F-log <b>E)</b> <b>curve.</b> In this thesis, a new method, the electrolytic grain-size analyzer (EGSA) technique has been developed that will allow one to obtain F-log <b>E</b> <b>curves</b> for each grain size class in polydisperse emulsions. The correctness of the F-log <b>E</b> <b>curve</b> obtained by this new method has been examined by comparing the F-log <b>E</b> <b>curve</b> with that calculated from the normalized D-log <b>E</b> <b>curve</b> {{in the case of}} monodisperse emulsions. The problems in EGSA measurement, such as 2 ̆ 2 noise 2 ̆ 2 and emulsion solubility, which affect the accuracy of F-log <b>E</b> <b>curves</b> obtained by such a method, have been solved and are discussed in detail. The technique has been applied to the case of an emulsion with a bimodal grain size distribution...|$|R
5000|$|Preconsolidation {{pressure}} {{cannot be}} measured directly, {{but can be}} estimated using {{a number of different}} strategies. Samples taken from the field are subjected to a variety of tests, like the constant rate of strain test (CRS) or the incremental loading test (IL). These tests can be costly due to expensive equipment and the long period of time they require. Each sample must be undisturbed and can only undergo one test with satisfactory results. [...] It is important to execute these tests precisely to ensure an accurate resulting plot. There are various methods for determining the preconsolidation pressure from lab data. The data is usually arranged on a semilog plot of the effective stress (frequently represented as σ'vc) versus the void ratio. This graph is commonly called the <b>e</b> <b>log</b> p <b>curve</b> or the consolidation curve.|$|R
40|$|The {{fragmentation}} {{function of}} quarks and gluons {{is measured in}} various three-jet topologies in Z decays collected with the Delphi detector between 1991 and 1994. The results are compared at different values of a transverse-momentum-like scale. Gluon jets are identified in three-jet events containing primary heavy quarks using impact parameter information. Comparable quark jet properties are obtained from light quark dominated three-jet events. The scale dependence of the fragmentation functions of quark and gluon jets shows the pattern typical of scaling violations. The scaling violation for quark jets {{is similar to that}} observed for all events in e + e Γ annihilation while that for gluon jets appears to be significantly stronger. The ratio of the logarithmic slopes of the fragmentation function for gluon to quark jets at large scaled hadron momentum allows a direct determination of the colour factor ratio CA=C F : <b>d</b> <b>log</b> D gluon <b>d</b> <b>log</b> <b>d</b> <b>log</b> D quark <b>d</b> <b>log</b> = 2 : 7 Σ 0 : 7 [...] ...|$|R
40|$|AbstractStable {{polynomial}} {{evaluation and}} interpolation at n Chebyshev or adjusted (expanded) Chebyshev points {{is performed using}} O(nlog 2 n) arithmetic operations, to be compared with customary algorithms either using {{on the order of}} n 2 operations or being unstable. We also evaluate a polynomial of degree d at the sets of n Chebyshev or adjusted (expanded) Chebyshev points using O(d <b>log</b> <b>d</b> <b>log</b> n) if n ≤ <b>d</b> or O((d <b>log</b> <b>d</b> + n) <b>log</b> <b>d)</b> arithmetic operations if n > d...|$|R
40|$|We {{show that}} { 0, 1 } d endowed with edit {{distance}} embeds into ℓ 1 with distortion 2 O(√ <b>log</b> <b>d</b> <b>log</b> <b>log</b> <b>d).</b> We further show efficient implementations of the embedding that yield solutions to various computational problems involving edit distance. These include sketching, communication complexity, nearest neighbor search. For all these problems, we improve upon previous bounds. ...|$|R
40|$|A {{radio network}} (RN, for short) is a {{distributed}} system populated by small, bulk-produced, handheld radio transceivers, running on batteries. Since recharging batteries {{may not be}} possible while on mission, it is important to design protocols that are highly energy-efficient. In this work we address the problem of energy-efficient routing in k-channel RNs. An important subproblem is that of permutation routing an instance of which involves p stations each storing n/p items. Since in the worst case each item must be transmitted at least once, every permutation routing protocol must take n/k time slots. Similarly, each station must be awake for at least n/p time slots. Our main contribution is to present an almost optimal energy-efficient permutation routing protocol on the k-channel, p-station RN that routes n items in at most (2 d+ 2 b+ 1) n/k +k time slots, with no station being awake for more than (4 d+ 7 b 1) n/p time slots, where <b>d</b> = <b>d</b> <b>log</b> p k <b>log</b> n p <b>e,</b> b = <b>d</b> <b>log</b> k log n p [...] ...|$|R
40|$|Abstract. It {{is shown}} that any multivariate {{polynomial}} of degree d {{that can be}} computed sequentially in C steps can be computed in parallel in O((log <b>d)</b> (<b>log</b> C + <b>log</b> <b>d))</b> steps using only (Cd) 1) processors. Key words, parallel computation, polynomials, complexity theory Introduction. Hyafil [6] showed that any polynomial q of degree d that can be computed sequentially in C {+,-, x}-steps can be computed in parallel in time proportional to (<b>log</b> <b>d)</b> (<b>log</b> C + <b>log</b> <b>d).</b> Unfortunately his method requires Cga pro-cessors in general. Thus even if C and d are both bounded polynomially {{in terms of the}} number of indeterminates the number of processors required would not be. I...|$|R
40|$|The {{date of receipt}} and {{acceptance}} will be inserted by the editor Abstract For hyper-rectangles in Rd Auer et al. [1] proved a PAC bound of O � 1 1 ε (<b>d</b> + <b>log</b> δ) �, where ε and δ are the accuracy and confidence parameters. It is still an open question whether one can obtain the same bound for intersection-closed concept classes of VC-dimension d in general. We present a step towards a solution of this problem showing on one hand a new PAC bound of O � 1 1 ε (<b>d</b> <b>log</b> <b>d</b> + <b>log</b> δ) � for arbitrary intersection-closed concept classes, complementing the well-known bounds O � 1 1 1 ε (<b>log</b> δ + <b>d</b> <b>log</b> ε) � and O � � <b>d</b> 1 ε <b>log</b> δ of Blumer et al. [4] and Haussler et al. [7]. Our bound is established using the closure algorithm, that generates as its hypothesis the intersection of all concepts {{that are consistent with}} the positive training examples. On the other hand, we show that many intersectionclosed concept classes including e. g. maximum intersection-closed classes satisfy an additional combinatorial property that allows a proof of the optimal bound of O � 1 1 ε (<b>d</b> + <b>log</b> δ) �. For such improved bounds the choice of the learning algorithm is crucial as there are consistent learning algorithms that need Ω � 1 1 1 ε (<b>d</b> <b>log</b> ε + log δ) � examples to learn some particular maximum intersection-closed concept classes. ...|$|R
40|$|We {{prove that}} if G is an (n, d, λ) -graph (a d-regular graph on n vertices, all of whose non-trivial {{eigenvalues}} are at most λ) {{and the following}} conditions are satisfied: 1. <b>d</b> λ ≥ (<b>log</b> n) 1 +ɛ for some constant ɛ> 0; 2. <b>log</b> <b>d</b> · <b>log</b> <b>d</b> λ ≫ <b>log</b> n, then the number of Hamilton cycles in G is n! (d n) n (1 + o(1)) ...|$|R
40|$|Let graph G = (V; E) and integer b 1 be given. A set S V {{is said to}} be b-independent if u; v 2 S implies dG (u; v) > b where dG (u; v) is the {{shortest}} distance between u and v in G. The b-independence number b (G) is the size of the largest b-independent subset of G. When b = 1 this reduces to the standard denition of independence number. We study this parameter in relation to the random graph G n;p; p = d=n. In particular, when d is a large constant. We show that whp that if d d;b, b (G n;p) 2 bn <b>d</b> b <b>log</b> <b>d</b> <b>log</b> <b>log</b> <b>d</b> b <b>log</b> 2 b b + 1 b n d b :...|$|R
3000|$|The {{derivative}} <b>d</b> <b>log</b> w/d log L will {{be called}} the “wage elasticity” of immigration. The short-run wage elasticity must be negative because c [...]...|$|R
40|$|We extend recent {{techniques}} for time-space tradeoff lower bounds using multiparty communication complexity ideas. Using these ar-guments, for inputs from large domains we prove larger tradeoff lower bounds than previously known for general branching pro-grams, yielding time lower bounds {{of the form}} T = (n log 2 n) when space S = n 1, up from T = (n log n) for the best previous results. We also prove the first unrestricted separation {{of the power of}} general and oblivious branching programs by proving that 1 GAP, which is trivial on general branching programs, has a time-space tradeoff of the form T = (n log 2 (n=S)) on oblivious branching programs. Finally, using time-space tradeoffs for branching programs, we improve the lower bounds on query time of data structures for near-est neighbor problems in d dimensions from (<b>d</b> = <b>log</b> n), proved in the cell-probe model [8, 5], to (d) or (<b>d</b> p <b>log</b> <b>d</b> = <b>log</b> <b>log</b> <b>d)</b> or even (<b>d</b> <b>log</b> <b>d)</b> (depending on the metric space involved) in slightly less general but more reasonable data structure models. 1...|$|R
40|$|International audienceWe {{give new}} simple {{algorithms}} for the fast computation of the quotient boot and the gcd of two polynomials, and obtain a complexity 0 (d(log(2) d) (2)), where d {{is the degree}} of the polynomials, similarly to Schonhage (1971), Moenck (1973). More precisely, denoting by M(d) {{the cost of a}} fast multiplication of polynomials of degree d, we reach the complexity (9 / 2 M(d) + 0 (<b>d))</b> <b>log</b> 2 <b>d</b> where d is the degree of the polynomials in the non-defective case (when degrees drop one by one), and (21 M(d) + 0 (<b>d))</b> <b>log</b> 2 <b>d</b> + 0 (M(d)) in the general case, improving the complexity bounds (respectively (10 M(d) + 0 (d)) log(2) d and (24 M(d) + 0 (<b>d))</b> <b>log</b> 2 <b>d</b> + 0 (M(d))) previously known for these problems (von zur Gathen and Gerhard, 1999, see Exercise 11. 7) ...|$|R
40|$|Abstract We give a {{recurrence}} relation for two-loop integrals {{encountered in the}} effective field theory of an infinitely heavy quark, Q, interacting with gluons and NL massless quarks, q, from which we obtain exact two-loop results, in any dimension and covariant gauge, for the propagator of Q and the vertex function of the heavylight current J ≡ QΓq, at zero q-momentum. The anomalous dimension of the Q-field agrees with the recent result of Broadhurst, Gray and Schilcher. The anomalous dimension of the current is ˜γJ ≡ <b>d</b> <b>log</b> ˜ ZJ <b>d</b> <b>log...</b>|$|R
40|$|We {{construct}} a pseudorandom generator which uses O(log m + <b>log</b> <b>d</b> + <b>log</b> 3 = 2 1 =ffl) bits and approximates {{the volume of}} any combinatorial rectangle in f 1; : : :; mg d to within ffl error. This improves on the previous construction by Armoni, Saks, Wigderson, and Zhou [3] using O(log m + <b>log</b> <b>d</b> + <b>log</b> 2 1 =ffl) bits. For a subclass of rectangles with at most t log 1 =ffl nontrivial dimensions and each dimension being an interval, we also give a pseudorandom generator using O(log <b>log</b> <b>d</b> + <b>log</b> 1 =ffl log 1 = 2 t log 1 =ffl) bits, which again improves the previous upper bound O(log <b>log</b> <b>d</b> + <b>log</b> 1 =ffl log t log 1 =ffl) by Chari, Rohatgi, and Srinivasan [4]. 1 Introduction Pseudorandom generators for combinatorial rectangles have been actively studied recently, because they {{are closely related to}} some fundamental problems in theoretical computer science, such as derandomizing RL, DNF approximate counting, and approximating the distributions of independent multivalued random variables. Le [...] ...|$|R
30|$|In {{addition}} to MFCC features, the energy-related feature, i.e., the logarithmic energy (<b>log</b> <b>E),</b> is also effective in discriminating different phonemes. For this reason, {{it is often}} appended to the MFCC features to further enhance recognition performance. However, similar to MFCC, the <b>log</b> <b>E</b> feature is vulnerable to noise. In many recent studies [33 – 35], {{it has been found}} that compensating the <b>log</b> <b>E</b> feature can improve the recognition accuracy significantly under noisy conditions. For example, in our previously proposed method, silence feature normalization (SFN) [35], high-pass-filtered <b>log</b> <b>E</b> is used as the indicator for speech/non-speech frame classification, and the <b>log</b> <b>E</b> features of non-speech frames are set to be small, while those of speech frames are kept nearly unchanged. We have shown that SFN is very effective despite its simplicity in implementation.|$|R
50|$|If f is a {{rational}} function of degree d, then T(r,f) ~ <b>d</b> <b>log</b> r; in fact, T(r,f) = O(log r) if {{and only if}} f is {{a rational}} function.|$|R
40|$|We {{consider}} {{problems of}} finding assorted rectilinear paths among rectilinear obstacles in a two-layer interconnection model {{according to the}} number of bends and the 1 -layer distance (y-distance). Using a horizontal wave-front approach, optimal /spl theta/(e <b>log</b> <b>e)</b> time algorithms are presented to find the shortest path and the minimum-bend path using linear space, and to find the shortest minimum-bend path and the minimum-bend shortest path using O(e <b>log</b> <b>e)</b> space, where e is the number of obstacle edges. By the same approach, we also derive an algorithm for finding a shortest two-layer distance (xy-distance) minimum-bend path in optimal /spl theta/(e <b>log</b> <b>e)</b> time using O(e <b>log</b> <b>e)</b> space...|$|R
40|$|We prove a Freiman-type theorem for locally compact abelian groups. If A is {{a subset}} of a locally compact abelian group with Haar measure m and m(nA) <b>d</b> <b>log</b> <b>d</b> then we {{describe}} A {{in a way which}} is tight up to logarithmic factors in d. Comment: 12 pp. Corrected typos. Updated references. Minor revisions...|$|R
40|$|We {{study the}} problem of {{computing}} the minimum volume enclosing ellipsoid containing a given point set S = {p 1, p 2, [...] ., pn} ⊆ R d. Using “core sets ” and a column generation approach, we develop a (1 + ɛ) -approximation algorithm. We prove {{the existence of a}} core set X ⊆ S of size at most |X | = α = O (<b>d</b> (<b>log</b> <b>d</b> + 1. We describe an algorithm that computes the set X and a (1 + ɛ) -approximation to ɛ) operations by using Khachiyan’s the minimum volume enclosing ellipsoid of S in O(nd 2 α + α 4. 5 <b>log</b> α <b>ɛ</b> algorithm to solve each subproblem. This result is an improvement over the previously known algorithms especially for input sets with n ≫ d and reasonably small values of ɛ. We also discuss extensions to the cases in which the input set consists of balls or ellipsoids...|$|R
40|$|ABSTRACT: Bulk density mad {{water content}} are defined and then {{related to one}} another and to void ratio by 7 {{polynomial}} regression equations based on 1680 measured bulk density and water content values of water-saturated sediments from the Atlantic and Pacific Oceans and other areas. Theoretical relationships between bulk density, water content, and void ratio for specific gravities between 2. 30 and 2. 85 are demonstrated. The average specific gravity of 2. 72 found for the data presented compares favorably to similar values reported in the literature. Use can be made of the regression equations to compute log b sedimentation-compression curves entirely determined from the hulk density of water-saturated sediment measured nondestructively b laboratory or in situ nuclear transmission densltometers. In an example showing the consolidation of a fine-grained calcareous ediment from the Exuma Sound, Bahamas, the all-nuclear laboratory method compares favorably with the conventional, non-nuclear method of constructing <b>e</b> <b>log</b> ~ <b>curves.</b> The combination of suitable regression equations and the all-nuclear method is eqnally applicable to other fine-grained water-saturated sediments...|$|R
40|$|How well can {{the maximum}} {{size of an}} {{independent}} set, or the minimum size of a dominating set of a graph in which all degrees are at most d be approximated by a randomized constant time algorithm? Motivated by results and questions of Nguyen and Onak, and of Parnas, Ron and Trevisan, we show that the best approximation ratio {{that can be achieved}} for the first question (independence number) is between Ω(d / <b>log</b> <b>d)</b> and O(d <b>log</b> <b>log</b> <b>d</b> / <b>log</b> <b>d),</b> whereas the answer to the second (domination number) is (1 + o(1)) ln d. ...|$|R
30|$|The VAD {{process that}} discriminates speech frames from non-speech frames in an {{utterance}} {{is based on}} two sources: the logarithmic magnitude spectrum (abbreviated as logMS) in Equation (10) and <b>log</b> <b>E</b> in Equation (11). Based on the observations made in Section ‘Effect of additive noise on the logarithmic magnitude spectrum in the frame sequences’, noise-corrupted speech segments possess {{a greater number of}} high (modulation) frequency components in the logMS and <b>log</b> <b>E</b> sequence than noise-only segments, and thus we expect that the high-pass-filtered logMS and <b>log</b> <b>E</b> sequences help to obtain more accurate VAD results.|$|R
40|$|AbstractWe {{describe}} routing algorithms on networks {{composed of}} optical busses. Using networks with short busses and small degree {{we are able}} to give very fast routing algorithms. First, we describe a leveled optical network and a routing algorithm for it. Next, we show how to simulate this network on high-dimensional meshes of optical busses (MOBs). We present algorithms for routing, e. g., h-relations with runtime being linear in h, doubly logarithmic in size and polynomial in the dimension of the mesh. Previous results are exponential in the dimension. E. g., routing an h-relation on a d-dimensional MOB of size N requires O (<b>d</b> 5 <b>log</b> <b>d</b> <b>log</b> <b>log</b> N + <b>d</b> 3 h) steps, with high probability...|$|R
40|$|Langmuir-like {{waves in}} the {{foreshock}} of Earth are characteristically bursty and irregular, and {{are the subject of}} a number of recent studies. Averaged over the foreshock, it is observed that the probability distribution is power-law P(bar) (<b>log</b> <b>E)</b> in the wave field E with the bar denoting this averaging over position, In this paper it is shown that stochastic growth theory (SGT) can explain a power-law spatially-averaged distributions P(bar) (<b>log</b> <b>E),</b> when the observed power-law variations of the mean and standard deviation of <b>log</b> <b>E</b> with position are combined with the log normal statistics predicted by SGT at each location...|$|R
40|$|Using the Faint Object Camera on the {{repaired}} Hubble Space Telescope, we {{have observed}} two {{fields in the}} globular cluster M 15 : the central density cusp, and a field at r = 20 ". These are the highest-resolution images ever taken of this cluster's dense core, and {{are the first to}} probe the distribution of stars well below the main-sequence turnoff. After correction for incompleteness, we measure a logarithmic cusp slope (<b>d</b> <b>log</b> σ / <b>d</b> <b>log</b> r) of - 0. 70 +- 0. 05 (1 -sigma) for turnoff (0. 8) stars over the radial range from 0. 3 " to 10 "; this slope is consistent with previous measurements. We also set an approximate upper limit of 1. 5 " (90...|$|R
40|$|ABSTRACT. R. Morris has {{proposed}} a probabilistic algorithm to count up to n using only about <b>log</b> <b>e</b> <b>log</b> <b>e</b> n bits. In this paper a slightly more general concept is introduced that allows to obtain a smoother average case behaviour. This concept is general {{enough to cover the}} analysis of an algorithm where the randomness is simulated by coin tossings. ...|$|R
40|$|Abstract. Evidence {{of secular}} {{dynamical}} evolution for detached active binary orbits are presented. First order decreasing rates of {{orbital angular momentum}} (OAM), systemic mass (M = M 1 + M 2) and orbital period of detached active binaries have been determined as J/J ˙ − 10 − 1 = − 3. 48 × 10 yr, ˙M/M = − 1. 30 × 10 − 10 yr− 1 and ˙ P/P = − 3. 96 × 10 − 10 yr− 1 from the kinematical ages of 62 field detached systems. The ratio of <b>d</b> <b>log</b> J/dlog M = 2. 68 implies that either there are mechanisms which amplify AM loss δ = 2. 68 times with respect to isotropic AM loss of hypothetical isotropic winds or there exist external causes contributing AM loss {{in order to produce}} this mean rate of decrease for orbital periods. Various decreasing rates of OAM (<b>d</b> <b>log</b> J/dt) and systemic mass (<b>d</b> <b>log</b> M/dt) determine various speeds of dynamical evolutions towards a contact configuration. According to average dynamical evolution with δ = 2. 68, the fraction of 11, 23 and 39 per cent of current detached sample is expected to be contact system within 2, 4 and 6 Gyr respectively...|$|R
40|$|Theorem 3 in Li et al. (2010). Write d = (d 1;:::; dp) and dc = (dc 1;:::; dcp). Let Gn(dc) {{denote the}} {{difference}} between the criterion values for the candidate and the true dimension vectors: Gn(dc) = logL(dc) − logL(d) + dc log n=[nh ~dcn (dc) ] − <b>d</b> <b>log</b> n=[nh ~dn(d) ]: Note that the set of candidate dimension vectors is finite. Thus, it is sufficient to show that for each vector dc not equal to d function Gn(dc) is positive with probability tending to one. Note that dc log n=[nh ~dc n (dc) ] − <b>d</b> <b>log</b> n=[nh ~dn(d) ] = O log n[n 4 =(~dc+ 4) + n 4 =(~d+ 4) ] = o(1) : If dcj c with probability tending to one, {{due to the lack of}} fit. It follows that Gn(dc) > 0 with probability tending to one. Now consider the remaining case of dcj ≥ dj for all j and dc> d. In this case dc log n=[nh ~dc n (dc) ] − <b>d</b> <b>log</b> n=[nh ~dn(d) ]> log n=[nh ~dcn (dc) ] for all sufficiently large n. On the other hand, logL(dc) − logL(d) = log(1 +L(dc) − L(d) L(d)) = log(1 +Op(1 =[n...|$|R
40|$|Thin {{films of}} {{amorphous}} silicon-carbon alloy (a-Si:C:H) were prepared by RF magnetron sputtering onto glass substrates maintained at room temperature. Aluminium (Al) electrodes {{were provided by}} thermal evaporation to form sandwich structures. The amorphous state of the films was confirmed by XRD analysis and their constituent was checked using FT-IR SystemSpectrum machine. Capacitance measurements indicate that the films have a relative permittivity value of 6. 93. A detailed study of dark current-voltage (I-V) characteristics clearly reveals the conduction mechanism as ohmic at low voltages and that of trap limited space charge limited conduction (SCLC) at higher voltages. Further evidence for space-charge-limited conduction process is provided by a linear dependence of log I on <b>log</b> <b>d,</b> <b>log</b> Vx on <b>log</b> <b>d</b> and <b>log</b> VTFL on <b>log</b> <b>d.</b> The trap density {{is found in the}} order of 1021 m- 3...|$|R
40|$|Rocchio's similarity-based {{relevance}} feedback algorithm, {{one of the}} most important query reformation methods in information retrieval, is essentially an adaptive learning algorithm from examples in searching for documents represented by a linear classifier. In spite of its popularity in various applications there is little rigorous analysis of its learning complexity in literature. In this paper, we prove for the first time that 2 the learning complexity of Rocchio's algorithm is O (<b>d</b> + <b>d</b> (<b>log</b> <b>d</b> + <b>log</b> n)) over the discretized vector d space { 0, L, n − 1 }, when the inner product similarity measure is used. The upper bound on the learning complexity for searching for documents represented by a monotone linear classifier (q, 0) ...|$|R
40|$|We give a {{recurrence}} relation for two-loop integrals {{encountered in the}} effective field theory of an infinitely heavy quark, Q, interacting with gluons and Nl massless quarks, q, from which we obtain exact two-loop results, in any dimension and covariant gauge, for the propagator of Q and the vertex function of the heavy-light current J = Q Gamma q, at zero q momentum. The anomalous dimension of the Q field agrees with the recent result of Broadhurst, Gray and Schilcher. The anomalous dimension of the current is gamma_J = <b>d</b> <b>log</b> Z_J / <b>d</b> <b>log</b> mu = - alpha_s/pi (1 + (127 + 56 zeta(2) - 10 Nl) / 72) alpha_s/pi + O(alpha_s^ 2)) which gives the new two-loop correction to the result of Voloshin and Shifman. Comment: Old preprin...|$|R
40|$|Abstract. We {{investigate}} Newton’s {{method for}} complex polynomials of arbitrary degree d, normalized {{so that all}} their roots are in the unit disk. For each degree d, we give an explicit set Sd of 3. 33 <b>d</b> <b>log</b> 2 d(1 +o(1)) points with the following universal property: for every normalized polynomial of degree d there are d starting points in Sd whose Newton iterations find all the roots. If the roots are uniformly and in-dependently distributed, we show {{that the number of}} iterations for these d starting points to reach all roots with precision ε is O(d 2 <b>log</b> 4 d+ <b>d</b> <b>log</b> | log ε|) (with prob-ability pd tending to 1 as d→∞). This is an improvement of an earlier result in [Sch], where the number of iterations is shown to be O(d 4 log 2 d+d 3 <b>log</b> 2 <b>d</b> | <b>log</b> ε|) in the worst case (allowing multiple roots) and O(d 3 log 2 d(log d+log δ) +d log | log ε|) for well-separated (so-called δ-separated) roots. Our result is almost optimal for this kind of starting points {{in the sense that the}} number of iterations can never be smaller than O(d 2) for fixed ε. 1...|$|R
