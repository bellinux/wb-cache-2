0|632|Public
50|$|The RGGI CO2 cap {{represents}} a regional budget for CO2 emissions {{from the power}} sector. The RGGI states include two <b>interim</b> <b>adjustments</b> to the RGGI cap to account for banked CO2 allowances. The cap declines 2.5 percent each year until 2020.|$|R
40|$|This {{paper is}} {{focussed}} on the quantizer step size <b>adjustment</b> <b>procedure</b> and the achieved sound quality {{obtained from the}} physiological ear model. Section 1 contains {{a brief review of}} the physiological ear model structure. The step size <b>adjustment</b> <b>procedure</b> is presented in Section 2. First results from the ISO/MPEG- 2 AAC implementation are reported in Section 3. Conclusions are drawn in the last Section...|$|R
30|$|Finally, {{we propose}} {{and discuss the}} merits of two {{enhanced}} <b>adjustment</b> <b>procedures</b> based on the fast adjustment algorithm. The fast <b>adjustment</b> <b>procedure</b> with bipolar probing signals achieves the isolation gain of the (much slower) gradient search algorithm {{at the expense of}} a mean penalty of 0.48 dB. We observe that the fast adjustment aided gradient algorithm requires 72 % less steps than the gradient search algorithm in our measurements.|$|R
30|$|Effects of {{alternative}} seasonal <b>adjustment</b> <b>procedures</b> on monetary policy, Journal of Econometrics, Elsevier, vol. 14 (1), pages 115 – 136, 1980.|$|R
40|$|The aim of {{this paper}} is to present a technique, called the safety stock <b>adjustment</b> <b>procedure</b> (SSAP), which enables the {{determination}} of safety stocks that ensure target service levels in simulation studies of inventory systems. The technique is based on a netting procedure constructed so that the net requirement process and the replenishment process are independent of the safety stock and that the inventory process satisfies an invariance relation. The procedure is presented for three kinds of service measures; namely the cycle service level, the fill rate and the ready rate. In a numerical example the benefits of using the safety stock <b>adjustment</b> <b>procedure</b> are shown. In this example three wellknown lot size models are compared assuming stochastic and time-varying demand. Moreover, we propose the safety stock <b>adjustment</b> <b>procedure</b> to be used in practical situations to set safety stock levels in companies for instance when demand is nonstationary. Keywords...|$|R
5000|$|McIntyre later commented:My {{original}} interest in GISS <b>adjustment</b> <b>procedures</b> {{was not an}} abstract interest, but a specific interest in whether GISS <b>adjustment</b> <b>procedures</b> were equal {{to the challenge of}} [...] "fixing" [...] bad data. If one views the above assessment as a type of limited software audit (limited by lack of access to source code and operating manuals), one can say firmly that the GISS software had not only failed to pick up and correct fictitious steps of up to 1 deg C, but that GISS actually introduced this error {{in the course of their}} programming. According to any reasonable audit standards, one would conclude that the GISS software had failed this particular test. While GISS can (and has) patched the particular error that I reported to them, their patching hardly proves the merit of the GISS (and USHCN) <b>adjustment</b> <b>procedures.</b> These need to be carefully examined.|$|R
40|$|The {{viability}} of many heuristic procedures strongly {{depends on the}} adequate adjustment of parameters. This work presents an <b>adjustment</b> <b>procedure</b> which was applied to a Genetic Algorithm. First, a preliminary analysis is performed, intended to obtain {{a better understanding of}} the behavior of the parameters, as for example to estimate how likely it is for the preceding adjustment of the parameters to remain in local minima. Special attention is paid on the variability of the solutions with respect to their repeatability. The four phases of the <b>adjustment</b> <b>procedure</b> are Rough-Adjustment, Repeatability, Clustering and Fine Adjustment...|$|R
3000|$|... s, {{the time}} between {{synchronization}} pulses is measured and used for software clock-rate adjustments on the FireFly node. This clock-rate <b>adjustment</b> <b>procedure</b> achieves a global synchronization accuracy within [...]...|$|R
40|$|High {{bandwidth}} {{environment is}} useful for sending large volumes of data within short period of time. As {{there is a growing}} demand for high bandwidth networks, data transfer must take place without any congestion. Hence {{attempts have been made to}} find a suitable window <b>adjustment</b> <b>procedure</b> for congestion avoidance. In TCP, since window size is usually increased by 1 MSS/RTT and halved upon packet losses in any network, it is not suitable for high speed network. In this paper a study is made on window <b>adjustment</b> <b>procedure</b> for high bandwidth networks using XCP protocol. The window <b>adjustment</b> <b>procedure</b> is based on the queue and admitted rate. This proposed idea will be useful for high bandwidth environment for congestion avoidance. Performance of bandwidth utilization and throughput is presented. Index terms-TCP/IP, congestion window, Explicit control, bandwidth-delay product, congestion control. As with increase in the amount of data transfer across the various networks, to achieve low delay, maximum throughput and predictable performance on an end-to-end basis [1], a hig...|$|R
40|$|Voltage {{balancing}} {{among the}} series connected wind turbines {{is one of}} the main technical challenges of offshore wind farms with DC series-parallel collection systems. Due to wake effect considerations, the power generated among the series connected wind turbines does not remain the same and the series connection causes the output voltages of the turbines to be distributed in proportion to their power output. Power curtailment is required in order to prevent the turbines being subjected to over-voltage and under-voltage conditions. In this paper, a voltage <b>adjustment</b> <b>procedure</b> is proposed to eliminate over-voltage and under-voltage of wind turbines. Based on the voltage <b>adjustment</b> <b>procedure</b> and the power generation model of wind turbines, the energy curtailment of a wind farm is analyzed with the consideration of wake effect due to series connection. A case study on several DC series-parallel collection configurations is presented to analyze the energy curtailment of wind farms using the voltage <b>adjustment</b> <b>procedure...</b>|$|R
40|$|Abstract. The {{uncertainty}} in {{the response of the}} thermohaline circulation to greenhouse forcing due to the use of flux adjustments in coupled ocean-atmosphere models is evaluated. This is done by using a different yet physically justifiable flux <b>adjustment</b> <b>procedure</b> and examining its effect on the thermohaline response to greenhouse forcing in a three dimensional primitive equations coupled ocean atmosphere general circulation model. It is found that while the initial thermohaline circulation weakening is robust, its eventual recovery which is seen in some coupled model simulations may be more sensitive to the details of the flux <b>adjustment</b> <b>procedure</b> and may therefore be less certain...|$|R
5000|$|Audi, Georges; Wang, Meng; Wapstra, Aaldert H.; Kondev, Filip G.; MacCormick, Marion; Xu, Xing; and Pfeiffer, Bernd; The AME2012 {{atomic mass}} {{evaluation}} (I). Evaluation of input data, <b>adjustment</b> <b>procedures,</b> Chinese Physics C36, 1287 (2012) ...|$|R
30|$|In this contribution, four {{automatic}} adjustment algorithms for leakage carrier cancellation {{in radio}} frequency identification (RFID) readers are compared: full search, gradient search, fast and direct I/Q algorithms. Further, we propose two enhanced <b>adjustment</b> <b>procedures.</b>|$|R
40|$|Abstract. Though it {{had been}} {{employed}} for limit analysis and integral safety assessment of pressure pipe and vessel, most of the elastic modulus <b>adjustment</b> <b>procedures</b> were applicable to simple structures because their load multiplier was mainly determined by stress. In this paper, a series of element bearing ratio (EBR) based load multiplier algorithms are given, in which the influence of both stress and material on limit load are included. The EBR based load multiplier algorithms are investigated, and two efficient algorithms are suggested. Then the two algorithms combined with the elastic modulus <b>adjustment</b> <b>procedure</b> of elastic modulus reduction method are applied to limit analysis and integral safety assessment of penstocks...|$|R
3000|$|The pipe {{can also}} be {{considered}} as a variable mass gas charging/discharging thermodynamic system, but its volume remains constant in the vehicle height and leveling <b>adjustment</b> <b>procedures,</b> thus the mechanism model of the pipe can be given as [...]...|$|R
50|$|Following {{the laws}} of error propagation, neither the {{receiver}} position nor the clock offset are computed exactly, but rather estimated through a least squares <b>adjustment</b> <b>procedure</b> known from geodesy.To describe this imprecision, so-called GDOP quantities have been defined: geometric dilution of precision (x,y,z,t).|$|R
50|$|Assume a rifle {{is being}} fired that shoots with the bullet drop table given in Table 1. This {{means that the}} rifle sight setting for any range from 0 to 500 meters is available. The sight <b>adjustment</b> <b>procedure</b> can be {{followed}} step-by-step.|$|R
40|$|The chroGPS package {{provides}} {{tools to}} generate intuitive maps {{to visualize the}} association between genetic elements, with emphasis on epigenetics. The approach is based on Multi-Dimensional Scaling. We provide several sensible distance metrics, and <b>adjustment</b> <b>procedures</b> to remove systematic biases typically observed whe...|$|R
40|$|Public {{performance}} measurement systems rarely use formal performance standards <b>adjustment</b> <b>procedures.</b> After weighing {{the pros and}} cons and describing processes, the authors recommend how public sector {{performance measurement}} systems can be improved and argue this is a rich area for experimentation and academic research...|$|R
40|$|In {{construction}} of estimators from survey data, one often encounters important issues arising from nonresponse. For establishment surveys, methods {{to address these}} issues generally must account for important features of the sample design and weighting structure. For any given nonresponse <b>adjustment</b> <b>procedure,</b> an analyst makes implicit or explicit use of models for the nonresponse phenomenon and the outcome variables of primary interest. The performance of the <b>adjustment</b> <b>procedure</b> then depends {{on the extent to which}} the data deviate from the assumed models, the impact of these deviations on estimator bias, and the inferential power of diagnostics designed to detect these deviations. This paper presents a simulation study to evaluate trade-offs among the issues of model deviations, estimator performance and detectability for establishment surveys...|$|R
40|$|The paper aims at {{analyzing}} the seasonal movements of consumer prices and wholesale prices {{with respect to}} different seasonal adjustment techniques. Suitability of different seasonal adjustment techniques will be tested for CPI, WPI, CPI excluding food prices, and WPI excluding agricultural prices. The literature on the analysis of seasonality is composed of different groups. One group treats the seasonality as a noise that contaminates the economic data. Another group treats seasonality as a more integrated part of the modeling strategy. However, the most well-known method among the seasonal <b>adjustment</b> <b>procedure</b> is the treatment {{to the problem of}} seasonality as a noise, and this is the method that has been widely applied by the statistical offices of different countries to create official seasonally adjusted data. In this respect, the most commonly applied official seasonal <b>adjustment</b> <b>procedure</b> has for many years been the X- 11 method developed at the US Bureau of the Census. The X- 11 procedure has been replaced by X- 12. Among the two methodology, in some countries and in the EU statistical office EUROSTAT, a program TRAMO/SEATS is applied as well in recent years. After comparing these different procedures, the paper concludes with the analysis of which seasonal <b>adjustment</b> <b>procedure</b> may better fit for the Turkish CPI and WPI indices...|$|R
3000|$|During {{the vehicle}} height and {{leveling}} <b>adjustment</b> <b>procedures,</b> the dynamic {{behaviors of the}} air springs are similar to a variable mass gas charging/discharging thermodynamic system. Based on the derivation of the relevant thermodynamic theories, the thermodynamic behaviors of the air spring are given as [25, 26] [...]...|$|R
40|$|Economic {{evaluations}} {{have become}} an important and much used tool in aiding decision makers in deciding on reimbursement or implementation of new healthcare technologies. Nevertheless, the impact of economic evaluations on reimbursement decisions has been modest; results of economic evaluations {{do not have a}} good record in predicting funding decisions. This is usually explained in terms of fairness; there is increasing awareness that valuations of QALYs may differ when the QALYs accrue to different patients. The problem, however, is that these equity concerns often remain implicit, and therefore frustrate explicitness and transparency in evidence-based decision making. It has been suggested that a so-called equity <b>adjustment</b> <b>procedure</b> may (partially) solve this problem. Typically this would involve the application of so-called equity weights, which can be used to recalculate the value of QALY gains for different patients. This paper explores such an equity <b>adjustment</b> <b>procedure,</b> using the equity concept of proportional shortfall. Proportional shortfall assumes that measurement of inequalities in health should concentrate on the fraction of QALYs that people lose relative to their remaining life expectancy, and not on the absolute number of QALYs lost or gained. It is the ratio of QALYs lost over the QALYs remaining. This equity concept combines elements of two popular but conflicting notions of equity: fair innings and severity-of-illness. We applied the concept of proportional shortfall to ten conditions and tentatively explored how an equity <b>adjustment</b> <b>procedure</b> using proportional shortfall might affect priority setting. Our equity <b>adjustment</b> <b>procedure</b> lowered In conclusion, our results suggest that equity can be measured and that integration of equity concerns into an economic evaluation improves the fit between economic models and reimbursement decisions. It is recommended that cost-effectiveness driven health policy systems consider equity adjustments. Cost-effectiveness, Cost-utility, Health-policy, Reimbursement...|$|R
50|$|Because people's buying habits {{had changed}} substantially, {{a new study}} was made {{covering}} expenditures in the years 1934-1936, which {{provided the basis for}} a comprehensively revised index introduced in 1940. During World War II, when many commodities were scarce and goods were rationed, the index weights were adjusted temporarily to reflect these shortages. In 1951, the BLS again made <b>interim</b> <b>adjustments,</b> based on surveys of consumer expenditures in seven cities between 1947 and 1949, to reflect the most important effects of immediate postwar changes in buying patterns. The index was again revised in 1953 and 1964.|$|R
30|$|As {{a robust}} control method, the FSMC {{technique}} {{can be used}} to ensure the vehicle height adjustment precision and stabilize the posture of the vehicle body during the vehicle height <b>adjustment</b> <b>procedure</b> of EAS system, i.e., the peak values of the roll and pitch angles can be decreased significantly.|$|R
30|$|For {{the above}} <b>adjustment</b> <b>procedures,</b> {{declination}} and inclination {{have been treated}} separately. However, methods have been proposed to vectorially align declination and inclination to either a master record (no or minimal distortions are assumed) (e.g., Denham 1981; McFadden 1982) or to the GAD field (e.g., Turner and Thompson 1981).|$|R
40|$|Description We provide {{intuitive}} maps {{to visualize}} the association between genetic elements, with emphasis on epigenetics. The approach is based on Multi-Dimensional Scaling. We provide several sensible distance metrics, and <b>adjustment</b> <b>procedures</b> to remove systematic biases typically observed when merging data obtained under different technologies or genetic backgrounds...|$|R
40|$|This report {{contains}} {{information on}} actions taken {{that affect the}} salaries for members of Congress, broken down by year and starting {{with the establishment of}} the Ethics Reform Act <b>adjustment</b> <b>procedure</b> (1990). It also provides background on the most recent developments and information on other related floor action...|$|R
40|$|This paper {{introduces}} a general procedure that tests {{the significance of}} the departures from utility maximization, departures defined as violations of the general axiom of revealed preference (GARP). This general procedure is based on (i) an <b>adjustment</b> <b>procedure</b> that computes the minimal perturbation in order to satisfy GARP by using the information content in the transitive closure matrix and (ii) a test procedure that checks {{the significance of the}} necessary <b>adjustment.</b> This <b>procedure</b> can be easily implemented and programmed, and we run Monte Carlo simulations to show that it is quite powerful. ...|$|R
40|$|Most test {{statistics}} for detecting spatial clustering cannot distinguish between low-value spatial clustering and high-value spatial clustering, and none {{is designed to}} explicitly detect high-value clustering, low-value clustering, or both. To fill this void in practice, we introduce an <b>adjustment</b> <b>procedure</b> that can supplement common twosided spatial clustering tests so that a one-sided conclusion can be reached. The procedure is applied to Moran’s I and Tango’s CG in both simulated and real-world spatial patterns. The {{results show that the}} <b>adjustment</b> <b>procedure</b> can account for the influence of low-value clusters on high-value clustering and vice versa. The procedure has little effect on the original global testing methods when there is no clustering. When there is a clustering tendency, the procedure can unambiguously distinguish the existence of high-value clusters or low-value clusters or both...|$|R
40|$|Determination of the mean-field Hamiltonian {{parameters}} {{can be seen}} as {{gathering information}} about all the single-particle states out of a very partial information on only a few experimentally known levels. This is exactly what the inverse problem in applied mathematics is about. We illustrate some of the related concepts in view of a preparation of the fully statistically significant parameter <b>adjustment</b> <b>procedures.</b> For this purpose we construct the exactly soluble inverse problems associated with the realistic and phenomenologically powerful nuclear Woods-Saxon Hamiltonian and we analyse a few both physical and mathematical aspects of such procedures. Presented illustrations suggest that to be able to discuss the predictive power of the mean-field Hamiltonians the parameter <b>adjustment</b> <b>procedures</b> must be based on a relatively complex statistical analysis partially addressed in Ref. (1...|$|R
3000|$|After the seeding {{procedure}} {{has been}} initiated and the marker traces been identified, the alignment is finally optimized through a bundle <b>adjustment</b> <b>procedure</b> by minimizing a reprojection error. This allows {{to refine the}} projection maps P_ω this technique has been extensively discussed {{in the context of}} electron tomography [16 – 18].|$|R
40|$|The {{actual size}} of the {{measuring}} gap in rotational rheometers has {{been a matter of}} discussions for a long time. In order to overcome the limitations of existing gap <b>adjustment</b> <b>procedures</b> a new patented system called TruGapTM was developed, which directly measures the actual gap size during the running experiment...|$|R
40|$|We {{present an}} {{improved}} crossover <b>adjustment</b> <b>procedure</b> to determine mean sea surface height using TOPEX, 35 -day repeat phase ERS- 1, Geosat, and 168 -day repeat phase ERS- 1 satellite altimeter data. The mean sea surface frame {{defined by the}} TOPEX data is imposed as certain constraints in our crossover <b>adjustment</b> <b>procedure</b> rather than held fixed as in some other procedures. The new procedure is discussed in detail. Equations are developed to incorporate the a priori information of Topex data {{as well as other}} satellite altimeter data. The numerical computation result shows that the rms crossover discrepancies are reduced by an order of 1 cm when the Topex data is not fixed. Furthermore, the computed mean sea surface is less noisy and more realistic than that computed by the traditional procedure. Department of Land Surveying and Geo-Informatic...|$|R
40|$|Access {{restricted}} to the OSU CommunityLight Detection And Ranging (LIDAR) provides a dense sampling and cost effective tool for the acquisition of discrete elevation data. The dataset is not errorfree and often requires some <b>adjustment</b> <b>procedure</b> to reduce or remove the effects of any unmodeled systematic errors. Many approaches organize the data into a Triangular Irregular Network (TIN) structure and perform linear interpolation of the triangular faces to extract surface information for the adjustment. This paper proposes an alternative approach to the interpolation procedure when the dataset represents the Earth's terrain and {{involves the use of}} the Thin Plate Spline (TPS) function. Experiments with synthetic data showed that the proposed approach outperformed the planar interpolation approach by about 35 % in cross validation and validation tests and by about 30 % in 3 D translation and 3 D similarity strip <b>adjustment</b> <b>procedures...</b>|$|R
40|$|In {{the last}} decade, {{intensive}} studies on modeling high frequency financial data at the transaction level have been conducted. In {{the analysis of}} high-frequency duration data, it is often {{the first step to}} remove the intraday periodicity. Currently the most popular <b>adjustment</b> <b>procedure</b> is the cubic spline procedure proposed by Engle and Russell (1998). In this article, we first carry out a simulation study and show that the performance of the cubic spline procedure is not entirely satisfactory. Then we define periodicity point processes rigorously and prove a time change theorem. A new intraday periodic <b>adjustment</b> <b>procedure</b> is then proposed and its effectiveness is demonstrated in the simulation example. The new approach is easy to implement and well supported by the point process theory. It provides an attractive alternative to the cubic spline procedure. © 2011 Elsevier B. V. ...|$|R
