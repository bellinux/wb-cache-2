73|167|Public
50|$|Vertex split (vsplit) is {{the inverse}} {{operation}} to the <b>edge</b> <b>collapse</b> that divides the vertex into two new vertexes. Therefore, a new edge {vt, vs} and two new triangles {vs, vt, vl} and {vt, vs, vr} arise.|$|E
5000|$|The data {{structure}} representing the mesh provides support for two basic operations, inserting triangles and removing triangles. It also supports an <b>edge</b> <b>collapse</b> operation that {{is useful in}} triangle decimation schemes. The structure provides no support for the vertex positions, but it does assume that each vertex is assigned a unique integer identifier, typically the index of that vertex {{in an array of}} contiguous vertex positions. A mesh vertex is defined by a single integer and is denoted by hvi. A mesh edge is defined by a pair of integers hv0,v1i, each integer corresponding to an end point of the edge. To support edge maps, the edges are stored so that v0 = min(v0,v1). A triangle component is defined by a triple of integers hv0,v1,v2i, each integer corresponding to a vertex of the triangle. To support triangle maps, the triangles are stored so that v0 = min(v0,v1,v2). Observe that hv0,v1,v2i and hv0,v2,v1i are treated as different triangles. An application requiring double-sided triangles must insert both triples into the {{data structure}}. For the sake of avoiding constant reminders about order of indices, in the remainder of the document the pair/triple information does not imply the vertices are ordering in any way (although the implementation does handle the ordering).Connectivity between the components is completely determined by the set of triples representing the triangles. A triangle t = hv0,v1,v2i has vertices v0, v1, and v2. It has edges e0 = hv0,v1i, e1 = hv1,v2i, and e2 = hv2,v0i. The inverse connections are also known. Vertex v0 is adjacent to edges e0 and e2 and to triangle t. Vertex v1 is adjacent to edges e0 and e1 and to triangle t. Vertex v2 is adjacent to edges e1 and e2 and to triangle t. All three edges e0, e1, and e2 are adjacent to t.How much of this information a data structure stores is dependent on the needs of an application. Moreover, the application might want to have additional information stored at the components. The information stored at a vertex, edge, or triangle {{is referred to as the}} vertex attribute, edge attribute, or triangle attribute. The abstract representations of these for the simple data structure described here are ...|$|E
40|$|This paper {{presents}} a new error bound simplification algorithm for complex geometric models. A lower polygon count approximation of the input model {{is generated by}} performing <b>edge</b> <b>collapse</b> operations. The collapse vertex is constrained to lie within a localised tolerance volume built around the <b>edge</b> <b>collapse</b> neighbourhood. This constraint ensures that all points on the simplified surface are within a user specified distance from the surface after the previous <b>edge</b> <b>collapse...</b>|$|E
40|$|Summary. The {{simplification}} of nonconvex tetrahedral meshes {{with the}} help of <b>edge</b> <b>collapses</b> (<b>edge</b> contractions) is considerably more complex than the corresponding simplification of convex meshes. In particular, <b>edge</b> <b>collapses</b> in nonconvex meshes may cause intersections of cells that are hard to detect, and therefore hard to avoid. More precisely spoken, the problem is quadratic in the number of cells. However, we show how to reduce the complexity of this problem by employing a preprocessing step, which was originally proposed in order to sort nonconvex meshes. Moreover, our method is able to handle meshes with topologically non-trivial boundaries and to control the modification of the topology of the meshâ€™s boundary. ...|$|R
40|$|We {{present a}} new {{solution}} to the well-known problems of <b>edge</b> <b>collapses</b> in nonconvex tetrahedral meshes. Additionally, our method is able to handle meshes with topologically non-trivial boundaries and to control the modification of the topology of the mesh's boundary. 1 Introduction In order to visualize today's huge data sets, hierarchical representations are often employed. The production of such representations of tetrahedral volume meshes requires a simplification of the original mesh. One way of performing this simplification is to apply a sequence of <b>edge</b> <b>collapses,</b> which are discussed in some detail in section 2 {{with an emphasis on}} the problems of <b>edge</b> <b>collapses</b> in nonconvex meshes. Our {{solution to the}}se problems consists of two parts: A preprocessing step [...] -originally suggested by Peter Williams in the context of sorting nonconvex meshes [...] -is briefly described in section 3. The second part [...] -edge collapses in the resultant meshes [...] -is discussed in section 4 with special atten [...] ...|$|R
40|$|This paper {{presents}} {{a method for}} enhancing photo-realistic models by creating a new multiresolution representation of models for use during display. From the original model, a lower resolution is calculated by <b>collapsing</b> an <b>edge</b> that connects two vertices in the model. The <b>edge</b> <b>collapsing</b> process is controlled in a pattern space. This process can be extended {{to take into account}} any information. This process computes the edge lengths in the feature space throughout the model and <b>collapses</b> the shortest <b>edge</b> to one vertex. At each step of the data reduction, a data structure known as dendogram is built allowing resolution selection during display. Hardware performance is computed during display and the most adequate resolution is selected to reach a desired frame rate. Multiple results of the <b>edge</b> <b>collapsing</b> process are presented in this paper. Finally, the fixed rate interactivity during display is illustrated. Keywords: <b>Edge</b> <b>collapsing,</b> mesh simplification, data reduction, data display...|$|R
30|$|According to the {{different}} geometric elements, mesh model simplification method is divided into vertex deletion, <b>edge</b> <b>collapse,</b> triangle deletion, and patch deletion. <b>Edge</b> <b>collapse</b> operation is based on half edge structure and an edge with the smallest triangular patch cost is collapsed {{in order to achieve}} the purpose of deleting the simplified model of triangular patch.|$|E
40|$|This paper {{presents}} a novel selective refinement scheme of progressive meshes. In previous schemes, topology {{information in the}} neighborhood of a collapsed edge is stored in the analysis phase. A vertex split or <b>edge</b> <b>collapse</b> transformation is possible in the synthesis phase only if the configuration of neighborhood vertices in the current mesh corresponds to the stored topology information. In contrast, the proposed scheme makes it possible to apply a vertex split or an <b>edge</b> <b>collapse</b> to any selected vertex or edge in the current mesh without a precondition. Our main observation is that the concept of a dual piece can be used to clearly enumerate and visualize the set of all possible selectively refined meshes for a given mesh. Our refinement scheme is truly selective in the sense that each vertex split or <b>edge</b> <b>collapse</b> can be performed without incurring additional vertex split and/or <b>edge</b> <b>collapse</b> transformations...|$|E
40|$|This paper {{deals with}} a hybrid {{simplification}} method for triangular meshes. Our approach {{is based on a}} first simplification step where vertices are clustered, followed by an iterative <b>edge</b> <b>collapse</b> step. More precisely, vertices are first clustered into surface patches through an adaptive segmentation process (using both absolute discrete curvature and principal component analysis); the <b>edge</b> <b>collapse</b> process is based on quadratic error metrics...|$|E
40|$|Abstract- The low-K {{films and}} higher {{multiple}} stacked layers would be widely applied for ultra large-scale integrated circuits [1][2]. However; for 8 " (200 mm) or 12 " (300 mm) wafer; the phenomena of wafer <b>edge</b> <b>collapsing</b> in higher interlayer low-K dielectric film causes from CMP polishing effect. (Shown in Fig. 1). Conventionally a {{amount of work}} has been developed in the optimization of different parameters, such as low pressure and high speed [3], metal dummy filling 141, harder pad used [4], and design of polishing head in order to resolve the problems. But these methods only engaged in design of experiment, not addressed in CMP theory of <b>edge</b> <b>collapsing</b> and controlling way. In this paper we will discuss the theory applied in Preston equation to explain the polishing behavior in wafer edge...|$|R
50|$|Geomorphing is a {{technique}} that reduces popping during LOD changes by adding approximations of the 3D model to serve as intermediate steps between two LODs to create a smooth transition. <b>Edge</b> <b>collapses</b> (removing vertices) and vertex splits (adding vertices) are the primary operations to modify the 3D model using this method.|$|R
40|$|Abstract- This paper {{presents}} {{a method for}} enhancing photo-realistic models by creating a new multiresolution representation of models for use during display. From the original model, a lower resolution is calculated by <b>collapsing</b> an <b>edge</b> that connects two vertices in the model. The <b>edge</b> <b>collapsing</b> process is controlled in a pattern space. This process can be extended {{to take into account}} any information. This process computes the edge lengths in the feature space throughout the model and <b>collapses</b> the shortest <b>edge</b> to one vertex. At each step of the data reduction, a data structure known as dendogram is built allowing resolution selection during display. Hardware performance is computed during display and the most adequate resolution is selected to reach a desired frame rate. Multiple results of the <b>edge</b> <b>collapsing</b> process are presented in this paper. Finally, the fixed rate interactivity during display is illustrated...|$|R
40|$|We {{address the}} problem of {{updating}} non-manifold mixed-dimensional objects, described by three-dimensional simplicial complexes embedded in 3 D Euclidean space. We consider two local update operations, <b>edge</b> <b>collapse</b> and vertex split, which are the most common operations performed for simplifying a simplicial complex. We examine the effect of such operations on a 3 D simplicial complex, and we describe algorithms for <b>edge</b> <b>collapse</b> and vertex split on a compact representation of a 3 D simplicial complex, that we call the Non-Manifold Indexed data structure with Adjacencies (NMIA). We also discuss how to encode the information needed for performing a vertex split and an <b>edge</b> <b>collapse</b> on a 3 D simplicial complex. The encoding of such information together with the algorithms for updating the NMIA data structure form the basis for defining progressive as well as multi-resolution representations for objects described by 3 D simplicial complexes and for extracting variable-resolution object descriptions...|$|E
40|$|Abstract In {{this paper}} we suggest a new <b>edge</b> <b>collapse</b> {{simplification}} method using the integral absolute mean curvature associated with area at each vertex u. We denote it simply. This plays roll of measuring the geometric error and preserving the global feature after processing. Discrete curvature norm defined by principal curvature preserve the characteristic {{features of the}} given models, which is the advantage contrary to distance norm. But it has deficiency in time complexity. Our algorithm preserve the advantage of discrete curvature norm, moreover it reduce the processing time massively. This follows <b>edge</b> <b>collapse</b> method and the mid-point of the collapsed edge is taken as new point. () LIAMC u 1...|$|E
40|$|It is {{of vital}} {{importance}} to generate multi-resolution TIN model dynamically and efficiently in 3 D visualization, virtual reality and GIS, {{due to the}} reason that multi-scale and large data volume to be processed. This paper proposes a method for compressing TIN model to create multi-resolution TIN model (LOD) dynamically. Here, multi-resolution TIN model means different level of details TIN model that can be transformed dynamically by the proposed solution, specifically based on TIN <b>edge</b> <b>collapse</b> and vertex split among different levels of TIN models. First, <b>edge</b> <b>collapse</b> and vertex split is determined according to the minimum distance to an average plane. An edge fulfill this requirement will be collapsed, in the same time, the angle between two triangles is used as an additional criterion for this judgment. Secondly, the vertex tree model is proposed to manage and store the vertex relationship between different level of TIN models. The corresponding encoding method is proposed based on the bracketing method (Donaghey, 1980) [...] each vertex is represented only with 0 or 1 to encode the position relationship in a tree. Thirdly, two new regulations for <b>edge</b> <b>collapse</b> and vertex split are defined to prevent the problem of surface foldovers during running time...|$|E
40|$|It is {{essential}} to generate multi-resolution triangulated irregular network (TIN) models dynamically and efficiently in three-dimensional (3 D) visualization, virtual reality (VR), and geographic information systems (GIS), because the data processed is multiple in scale and large in volume. This paper proposes a new approach, which extends the iterative <b>edge</b> <b>collapses</b> and vertex splits algorithm, to dynamically generate multi-resolution TIN models. Moreover, a new method was proposed to improve the efficiency of vertex topological relationships storing in multi-resolution TIN models. And {{a set of rules}} were defined to improve the validity judgment of vertex splits and <b>edge</b> <b>collapses.</b> To evaluate the performance of the proposed approach, the root mean square error (RMSE) of the elevation of vertex {{and the quality of the}} shapes of triangles were measured to evaluate the quality of a generated multi-resolution TIN model. The experimental results demonstrate that the proposed approach can generate multi-resolution TIN models with a higher accuracy and better time performance. Department of Land Surveying and Geo-Informatic...|$|R
40|$|Abstract. Based on {{interest}} point detection, a feature preserving mesh simplification algorithm is proposed. The Harris operator values of all vertices in the mesh were computed firstly. On {{the base of}} Garlandâ€™s simplification algorithm, we combine the Harris operator value with quadric error metric and change the order of <b>edge</b> <b>collapsing</b> in the simplification. The experimental {{results show that the}} proposed algorithm is effective and feature preserving...|$|R
50|$|This {{operation}} involves identifying an edge hvk,vti where vk {{is called}} the keep vertex and vt {{is called the}} throw vertex. The triangles that share this edge are removed from the mesh. The vertex vt is also removed from the mesh. Any triangles that shared vt have that vertex replaced by vk. Figure 1 shows a triangle mesh and a sequence of three <b>edge</b> <b>collapses</b> applied to the mesh.|$|R
40|$|International audienceThis paper {{presents}} a progressive compression method for generic surface meshes (non-manifold and/or polygonal). Two major contributions are proposed : (1) generic <b>edge</b> <b>collapse</b> and vertex split operators allowing surface simplication and renement of a mesh, whatever its connectivity; (2) a distortion-aware collapse clustering strategy that adapts the decima-tion granularity {{in order to}} optimize the rate-distortion tradeoff...|$|E
40|$|We {{present the}} use of mapping {{functions}} to automatically generate levels of detail with known error bounds for polygonal models. We develop a piece-wise linear mapping function for each simplification operation and use this function to measure deviation of the new current surface from both the previous level of detail and from the original surface. In addition, we use the mapping function to compute appropriate texture coordinates if the original map has texture coordinates at its vertices. Our overall algorithm uses <b>edge</b> <b>collapse</b> operations. We present rigorous procedures for the generation of local planar projections {{as well as for}} the selection of a new vertex position for the <b>edge</b> <b>collapse</b> operation. As compared to earlier methods, our algorithm is able to compute tight error bounds on surface deviation and other attributes and produce an entire continuum of levels of details with successive mapping. We [...] . demonstrate the effectiveness of our algorithm on several models: a Ford Bro [...] ...|$|E
40|$|We {{introduce}} {{the notion of}} image-driven simplification, a framework that uses images to decide which portions of a model to simplify. This is a departure from approaches that make polygonal simplification decisions based on geometry. As with many methods, we use the <b>edge</b> <b>collapse</b> operator to make incremental changes to a model. Unique to our approach, however, {{is the use of}} comparisons between images of the original model against those of a simplified model to determine the cost of an <b>edge</b> <b>collapse.</b> We use common graphics rendering hardware to accelerate the creation of the required images. As expected, this method produces models that are close to the original model according to image differences. Perhaps more surprising, however, is that the method yields models that have high geometric fidelity as well. Our approach also solves the quandary of how to weight the geometric distance versus appearance properties such as normals, color and texture. All of these tradeoffs are ba [...] ...|$|E
40|$|Simplification of {{tetrahedral}} meshes is {{an important}} tool to decrease the complexity of these datasets. Many visualization systems need the simplified version of a mesh to be fully interactive. This paper presents a rapid tetrahedral simplifier that works in three steps. First, {{the border of the}} tetrahedral mesh is simplified. Second, the interior of the mesh is point sampled such that the resulting point cloud contains the most important points. Third, the point cloud is tetrahedralized and constrained to the simplified border. Such a sequence of global operations exceeds the limitations of a sequence of local operations like <b>edge</b> <b>collapses.</b> The point sampling is steered by both a field and a space error such that direct volume renderings as well as isosurfaces are well approximated. For the border simplification, we present a triangle mesh simplifier that ensures an intersectionfree border after is has finished. It can be easily integrated into existing triangle mesh simplification software that is based on <b>edge</b> <b>collapses</b> or vertex contraction. We construct a hierarchy of bounding boxes which is used at simplification time to early reject intersection tests. ...|$|R
40|$|We {{present a}} {{geometric}} perspective on sparse filtrations used in topological data analysis. This new perspective leads to much simpler proofs, while also being more general, applying equally to Rips filtrations and CÌŒech filtrations for any convex metric. We also give an algo-rithm for finding the simplices {{in such a}} filtration and prove that the vertex removal can be implemented as a sequence of elementary <b>edge</b> <b>collapses.</b> A video illustrating this approach is available [7]. ...|$|R
40|$|This paper {{presents}} a parallel adaptation procedure (coarsening and refinement) for tetrahedral meshes in a distributed environment. Coarsening relies upon an <b>edge</b> <b>collapsing</b> tool. Refinement uses edge-based subdivision templates. Mesh optimization maintains {{the quality of}} the adapted meshes. Focus is given to the parallelization of the various components. Scalability requires repartitioning of the mesh before applying either coarsening or refinement. Relatively good speed-ups have been obtained for all phases of the proposed adaptation scheme...|$|R
40|$|In {{an earlier}} paper we {{introduced}} a new quadric metric for simplifying triangle meshes using the <b>edge</b> <b>collapse</b> operation. The quadric measures both the geometric accuracy of the simplified mesh surface and the fidelity of appearance fields defined on the surface (such as normals or colors). The minimization of this quadric metric involves solving a linear system of size (3 +m) (3 +m),wherem {{is the number of}} distinct appearance attributes. The system has only O(m) nonzero entries, so it can be solved in O(m 2) time using traditional sparse solvers such as the method of conjugate gradients. In this short addendum, we show that the special structure of the sparsity permits the system to be solved in O(m) time. 1 Introduction Complex triangle meshes arise naturally in many areas of computer graphics and visualization. In an earlier paper [2], we {{introduced a new}} quadric metric for simplifying such meshes using the <b>edge</b> <b>collapse</b> operation (Figure 1). The quadric measures both the geometric [...] ...|$|E
40|$|International {{audience}} We {{propose a}} practical iterative remeshing algorithm for multi-material tetrahedral meshes which is solely based on simple local topological operations, such as <b>edge</b> <b>collapse,</b> flip, split and vertex smoothing. To do so, we exploit an intermediate implicit feature complex which reconstructs piecewise smooth multi-material boundaries made of surface patches, feature edges and corner vertices. Furthermore, we design specific feature-aware local remeshing rules which, {{combined with a}} moving least square projection, result in high quality isotropic meshes representing the input mesh at a user defined resolution while preserving important features. Our algorithm uses only topology-aware local operations, which allows us to process difficult input meshes such as self-intersecting ones. We evaluate our approach on a collection of examples and experimentally show that it is fast and scales well. Graphical abstractDisplay Omitted HighlightsRobust tetrahedral remeshing: can process self-intersecting and poor quality meshes. Multi-material tetrahedral meshes: high-quality segemented meshes at any resolution. Using local operators: <b>edge</b> <b>collapse,</b> flip, split and vertex smoothing. Feature preserving: feature-aware local rules with a moving least square projection. </p...|$|E
40|$|Abstractâ€”This paper {{investigates the}} set of all {{selectively}} refined meshes that {{can be obtained from}} a progressive mesh. We call the set the transitive mesh space of a progressive mesh and present a theoretical analysis of the space. We define selective <b>edge</b> <b>collapse</b> and vertex split transformations, which we use to traverse all selectively refined meshes in the transitive mesh space. We propose a complete selective refinement scheme for a progressive mesh based on the transformations and compare the scheme with previous selective refinement schemes in both theoretical and experimental ways. In our comparison, we show that the complete scheme always generates selectively refined meshes with smaller numbers of vertices and faces than previous schemes for a given refinement criterion. The concept of dual pieces of the vertices in the vertex hierarchy plays {{a central role in the}} analysis of the transitive mesh space and the design of selective <b>edge</b> <b>collapse</b> and vertex split transformations. Index Termsâ€”Progressive mesh, selective refinement, selectively refined mesh, transitive mesh space, hierarchical partitioning property, dual piece, valid vertex front. ...|$|E
40|$|In {{this paper}} {{we present a}} {{technique}} for transforming a tetrahedral mesh into a progressive representation based on half <b>edge</b> <b>collapses.</b> This allows the efficient transmission of the mesh from a remote computer where the simulation was computed to a visualization computer. During the transmis-sion the user can start visualizing while the transmission is still in progress. We show a technique for progressively extracting isosurfaces from the progressive mesh. Starting with the base mesh an isosurface for a specific value is com-puted and will locally be improved where a vertex is in-serted to the mes...|$|R
40|$|Abstract. We {{study the}} {{simplification}} of triangular and tetrahedral meshes using techniques based on successive <b>edge</b> <b>collapses,</b> {{as well as}} the exploitation of the generated multiple levels of detail for the effec-tive processing of the models. Regarding triangular meshes, we present a method for the construction of progressive hulls, by suitable edge col-lapses; we use the generated hulls for the acceleration of intersection tests between the initial mesh and a line. Regarding tetrahedral meshes, we simplify meshes with associated vector fields; we construct progressive tetrahedral meshes by taking into account, while <b>collapsing</b> <b>edges,</b> both the geometry of the mesh and the associated field. Finally, we present an efficient algorithm for computing ray-tetrahedron intersection, which exploits PluÌˆcker coordinates to accelerate computations; this algorithm may be used for the efficient processing of progressive tetrahedral meshes. ...|$|R
40|$|We define constrictions on {{a surface}} as simple closed {{geodesic}} curves, i. e. curves whose length is locally minimal. They {{can be of}} great interests in order to cut the surface in smaller parts. In this paper, we present a method to detect constrictions on closed triangulated surfaces. Our algorithm {{is based on a}} progressive approach. First, the surface is simplified by repeated <b>edge</b> <b>collapses.</b> The simplification continues until we detect an <b>edge</b> whose <b>collapse</b> would change the topology of the surface. It happens when three edges of the surface form a triangle that does not belong to the surface. The three edges define what we call a seed curve and are used to initialize the search of a constriction. Secondly, the constriction is progressively constructed by incrementally refining the simplified surface until the initial surface is retrieved. At each step of this refinement process, the constriction is updated. Some experimental results are provided...|$|R
40|$|This work {{describes}} efficient {{race track}} rendering using OpenGL. It uses height map for terrain representation. The race track is rendered as polygonal model instanced on a curve using level of detail. An {{algorithm is proposed}} for using level of detail in real time even on mobile devices. Among described algorithms are dart throwing, Catmull-Rom spline, <b>edge</b> <b>collapse</b> simplification, view frustum culling. Part of this work is an application demonstrating the designed algorithm...|$|E
40|$|Mesh {{simplification}} {{is a key}} {{research area}} in scientific visualization and virtual reality. The paper presents a new method of polyhedral model simplification based on vision characteristic and <b>edge</b> <b>collapse.</b> This method determines model's vision characteristic by computing the maximum product of angle between normal of vertex and adjacent triangles with area of these triangles. It can achieve a high decimation rate, while keeping the details of vision. This algorithm can also be extended to triangle decimation criterion easily...|$|E
40|$|Part 1 : Decision Support Systems, Intelligent Systems and Artificial Intelligence ApplicationsInternational audienceBlade-type error, <b>edge</b> <b>collapse</b> cutaway, micro missing, four {{kinds of}} defect for RCF-type PCB mill {{production}} are deeply analyzed and their preventions measures are given detailed {{according to the}} authorâ€™s many yearâ€™s practice. These measures have been practiced and achieved good results. The research results can increase pass rate of such tools in the production and reduce production costs obviously, and owns with a special important using values and widely promoted significance...|$|E
40|$|This paper {{describes}} {{some fundamental}} issues for robust implementations of progressively refined tetrahedralizations generated through sequences of <b>edge</b> <b>collapses.</b> We address {{the definition of}} appropriate cost functions and explain on various tests which are necessary to preserve {{the consistency of the}} mesh when <b>collapsing</b> <b>edges.</b> Although being considered a special case of progressive simplicial complexes [10], the results of our method are of high practical importance and can be used in many different applications, such as finite element meshing, scattered data interpolation, or rendering of unstructured volume data. CR Categories: I. 3. 5 [Computer Graphics]: Computational Geometry and Object Modeling [...] surfaces and object representations. Keywords: mesh simplification, multiresolution, level-ofdetail, unstructured meshes, mesh generation. 1 INTRODUCTION Progressive meshes [7] and its generalizations to higher dimensions [10] proofed to be an extremely powerful notion for the effic [...] ...|$|R
50|$|The square pyramid {{can be seen}} as a {{degenerate}} triangular prism {{where one}} edge of its side <b>edges</b> is <b>collapsed</b> into a point, losing one edge and one vertex, and changing two squares into triangles.|$|R
40|$|We {{present an}} out-of-core mesh {{decimation}} algorithm that {{is able to}} handle input and output meshes of arbitrary size. The algorithm reads the input from a data stream {{in a single pass}} and writes the output to another stream while using only a fixed-sized in-core buffer. By applying randomized multiple choice optimization, we are able to use incremental mesh decimation based on <b>edge</b> <b>collapses</b> and the quadric error metric. The quality of our results is comparable to state-of-the-art highquality mesh decimation schemes (which are slower than our algorithm) and the decimation performance matches the performance of the most efficient out-of-core techniques (which generate meshes of inferior quality) ...|$|R
