105|463|Public
50|$|The model {{assumes that}} a perceptual signal within the {{participant}} represents {{the magnitude of}} the <b>input</b> <b>quantity</b> qi. (This has been demonstrated to be a rate of firing in a neuron, at least at the lowest levels.) In the tracking task, the <b>input</b> <b>quantity</b> is the vertical distance between the target position T and the cursor position C, and the random variation of the target position acts as the disturbance d of that <b>input</b> <b>quantity.</b> This suggests that the perceptual signal p quantitatively represents the cursor position C minus the target position T, as expressed in the equation p=C - T.|$|E
5000|$|The {{amplitude}} of the input is [...] This {{has the same}} units as the <b>input</b> <b>quantity.</b>|$|E
5000|$|Consider {{estimates}} , respectively, of {{the input}} quantities , obtained from certificates and reports, manufacturers' specifications, {{the analysis of}} measurement data, and so on. The probability distributions characterizing [...] are chosen such that the estimates , respectively, are the expectations of [...] Moreover, for the th <b>input</b> <b>quantity,</b> consider a so-called standard uncertainty, given the symbol , defined as the standard deviation of the <b>input</b> <b>quantity</b> [...] This standard uncertainty {{is said to be}} associated with the (corresponding) estimate [...]|$|E
5000|$|... on {{the basis}} of {{available}} knowledge, assigning probability distributions — Gaussian, rectangular, etc. — to the <b>input</b> <b>quantities</b> (or a joint probability distribution to those <b>input</b> <b>quantities</b> that are not independent).|$|R
3000|$|Given a {{quantity}} (described {{by a set}} of one or more output quantities) Q=([...] Q_ 1, [...] Q_ 2, [...]..., Q_m) that is calculated {{as a function of the}} <b>input</b> <b>quantities</b> p_ 1, [...] p_ 2, [...]..., p_n, let us assume that each of these <b>input</b> <b>quantities</b> are respectively measured as p_ 10, [...] p_ 20, [...]..., [...] p_n 0. Denoting the maper in the measurement of each of these <b>input</b> <b>quantities</b> by δ _ 1, [...] δ _ 2, [...]..., [...] δ _n, respectively—i.e., δ _i= _p_i∈ S_i| p_i-p_i 0 |, 1 < i< n; [...]...|$|R
5000|$|... {{developing}} a measurement model relating [...] to the <b>input</b> <b>quantities,</b> and ...|$|R
50|$|An {{integrator}} in {{measurement and}} control applications is an element whose output signal is the time integral of its input signal. It accumulates the <b>input</b> <b>quantity</b> over a defined time to produce a representative output.|$|E
5000|$|Knowledge {{about an}} <b>input</b> <b>quantity</b> [...] is {{inferred}} from repeated measured values ("Type A evaluation of uncertainty"), or scientific judgement or other {{information concerning the}} possible values of the quantity ("Type B evaluation of uncertainty").|$|E
50|$|They are {{implemented}} by active electronic components (transistors) having current-stable nonlinear output characteristic when driven by steady <b>input</b> <b>quantity</b> (current or voltage). These circuits behave as dynamic resistors changing their present resistance to compensate current variations. For example, if the load increases its resistance, the transistor decreases its present output resistance (and vice versa) {{to keep up}} a constant total resistance in the circuit.|$|E
30|$|The {{uncertainty}} {{evaluation of}} all the <b>input</b> <b>quantities</b> is discussed in the following sub-sections.|$|R
5000|$|An operand, then, is also {{referred}} to as [...] "one of the <b>inputs</b> (<b>quantities)</b> for an operation".|$|R
5000|$|... #Caption: An {{additive}} {{measurement function}} with two <b>input</b> <b>quantities</b> [...] and [...] characterized by rectangular probability distributions ...|$|R
50|$|Due to the DC-link storage element, {{there is}} the {{advantage}} that both converter stages are {{to a large extent}} decoupled for control purposes. Furthermore, a constant, AC line independent <b>input</b> <b>quantity</b> exists for the PWM inverter stage, which results in high utilization of the converter’s power capability. On the other hand, the DC-link energy storage element has a relatively large physical volume, and when electrolytic capacitors are used, {{in the case of a}} voltage DC-link, there is potentially a reduced system lifetime.|$|E
5000|$|If {{a voltage}} {{is applied to}} the BJT base-emitter {{junction}} as an <b>input</b> <b>quantity</b> and the collector current is taken as an output quantity, the transistor will act as an exponential voltage-to-current converter. By applying a negative feedback (simply joining the base and collector) the transistor can be [...] "reversed" [...] and it will begin acting as the opposite logarithmic current-to-voltage converter; now it will adjust the [...] "output" [...] base-emitter voltage so as to pass the applied [...] "input" [...] collector current.|$|E
5000|$|In Type A {{evaluations}} of measurement uncertainty, {{the assumption is}} often made that the distribution best describing an <b>input</b> <b>quantity</b> [...] given repeated measured values of it (obtained independently) is a Gaussian distribution. then has expectation equal to the average measured value and standard deviation equal to the standard deviation of the average.When the uncertainty is evaluated from {{a small number of}} measured values (regarded as instances of a quantity characterized by a Gaussian distribution), the corresponding distribution can be taken as a t-distribution.Other considerations apply when the measured values are not obtained independently.|$|E
5000|$|When the <b>input</b> <b>quantities</b> [...] contain dependencies, {{the above}} formula is {{augmented}} by terms containing covariances, which may {{increase or decrease}} [...]|$|R
40|$|In {{this paper}} the {{uncertainty}} of a robust photometer circuit (RPC) was estimated. Here, the RPC was considered as a measurement system, having <b>input</b> <b>quantities</b> that were inexactly known, and output quantities that consequently were also inexactly known. <b>Input</b> <b>quantities</b> represent information obtained from calibration certificates, specifications of manufacturers, and tabulated data. Output quantities describe the transfer function of the electrical part of the photodiode. <b>Input</b> <b>quantities</b> were the electronic components of the RPC, {{the parameters of the}} model of the photodiode and its sensitivity at 670 nm. The output quantities were the coefficients of both numerator and denominator of the closed-loop transfer function of the RPC. As an example, the gain and phase shift of the RPC versus frequency was evaluated from the transfer function, with their uncertainties and correlation coefficient. Results confirm the robustness of photodiode design...|$|R
50|$|The operand '3' {{is one of}} the <b>inputs</b> (<b>quantities)</b> {{followed}} by the addition operator, and the operand '6' is the other input necessary for the operation.|$|R
50|$|An {{alternative}} to ignoring uncertainty in quantiative decision models is to explicitly encode uncertainty {{as part of}} the model. With this approach, a probability distribution is provided for each input variable, rather than a single best guess. The variance in that distribution reflects the degree of subjective uncertainty (or lack of knowledge) in the <b>input</b> <b>quantity.</b> The software tools then use methods such as Monte Carlo analysis to propagate the uncertainty to result variables, so that a decision maker obtains an explicit picture of the impact that uncertainty has on his decisions, and in many cases can make a much better decision as a result.|$|E
5000|$|Environmental {{organizations}} such as the Natural Resources Defense Council (NRDC) also oppose the project due to its transportation of oil from oil sands. In its March 2010 report, the NRDC stated that [...] "the Keystone XL Pipeline undermines the U.S. commitment to a clean energy economy", instead [...] "delivering dirty fuel at high costs". On June 23, 2010, 50 Democrats in Congress in their letter to Secretary of State Hillary Clinton warned that [...] "building this pipeline has the potential to undermine America's clean energy future and international leadership on climate change", referencing the higher <b>input</b> <b>quantity</b> of fossil fuels necessary to take the tar {{and turn it into a}} usable fuel product in comparison to other conventionally derived fossil fuels.|$|E
50|$|The {{ability to}} {{simulate}} movement, such {{as could be}} encountered in ships, airplanes, or a terrestrial reactor during an earthquake becomes available in the 2013 release of RELAP5-3D. This capability allows the user to simulate motion through input, including translational displacement and rotation about the origin implied by {{the position of the}} reference volume. The transient rotation can be input using either Euler or pitch-yaw-roll angles. The movement is simulated using a combination of sine functions and tables of rotational angles and translational displacement. Since the gravitational constant is also an <b>input</b> <b>quantity,</b> this capability {{is not limited to the}} surface of the Earth. It allows RELAP5-3D to model reactor systems on space craft, a space station, the moon, or other extraterrestrial bodies.|$|E
40|$|In this paper, we {{consider}} the problem of uncertainty analysis of complex measurement systems with multiple axis motions and a measurand defined by non-linear combinations of <b>input</b> <b>quantities.</b> We demonstrate a method for obtaining {{the definition of the}} measurand using Homogeneous Transformation Matrices (HTM) to model the instrument and obtain the measurand {{as a function of the}} motion and sensing errors of the individual axes. The method is demonstrated by application to the laser ball bar (LBB), which is capable of measurement of spatial coordinates of a target over relatively large working volumes approaching 1 m 3. The first step in performing measurement uncertainty analyses is the definition of the measurand, or quantity being measured. In many cases, the measurand is not observed directly but is a mathematical function of other <b>input</b> <b>quantities.</b> The computation of measurement uncertainty from the uncertainties of the <b>input</b> <b>quantities</b> is then a relatively straightforwar...|$|R
30|$|On {{the other}} side, to {{determine}} the propagation of uncertainties when the measurand function is non-linear, a routine {{is to use a}} Monte Carlo simulation (BIPM 2008) to generate a probability density function (pdf) for the measurand from propagations of the pdf assigned to the <b>input</b> <b>quantities.</b> However, this probabilistic approach (i.e., distinct simulations of the same input data set may yield distinct output data) needs a pdf for the <b>input</b> <b>quantities,</b> and it also requires the joint distribution of correlated input variables, which is often unknown or difficult to simulate (Kacker et al. 2007).|$|R
40|$|Abstract − Modern {{uncertainty}} {{evaluation is}} based on both the knowledge about the measuring process and the <b>input</b> <b>quantities</b> contributing to the measurement result [1 - 2]. Very often, {{two or more of}} the <b>input</b> <b>quantities</b> are not independent from each other. The combined uncertainty can be enhanced or decreased by such correlation. In everyday practice, however, correlation is often ignored since the relevant uncertainty documents do not provide ready-for-use procedures for proper treatment of correlation. The paper provides practical techniques for identifying and quantifying correlation in measurements. Starting from a systematic modelling procedure [3 - 4], a concept is presented that allows to easily include correlation in the measurement model and to properly estimate correlation coefficients or correlated fractions of the related <b>input</b> <b>quantities</b> either from existing (statistical) data or from other (non-statistical, logical) knowledge [5 - 6]. Three possible ways to take correlation into consideration when evaluating measurement uncertainty are described and discussed...|$|R
5000|$|A sensor's {{sensitivity}} indicates {{how much}} the sensor's output changes when the <b>input</b> <b>quantity</b> being measured changes. For instance, if the mercury in a thermometer moves 1 cm when the temperature changes by 1 °C, the sensitivity is 1 cm/°C (it is basically the slope Dy/Dx assuming a linear characteristic). Some sensors can also affect what they measure; for instance, a room temperature thermometer inserted into a hot cup of liquid cools the liquid while the liquid heats the thermometer. Sensors are usually designed to have a small effect on what is measured; making the sensor smaller often improves this and may introduce other advantages.. [...] Technological progress allows more and more sensors to be manufactured on a microscopic scale as microsensors using MEMS technology. In most cases, a microsensor reaches a significantly higher speed and sensitivity compared with macroscopic approaches.|$|E
30|$|The {{second step}} is {{probability}} distribution and transfer. By the probability density {{function of the}} <b>input</b> <b>quantity,</b> the random number is obtained from the inverse transformation method. The output quantity is obtained by substituting the random number as the <b>input</b> <b>quantity</b> into the mathematical model. Repeat this step and stop when the experiment number is reached.|$|E
40|$|Abstract:Sensitivity {{coefficients}} {{are essentially}} conversion factors that allow one {{to convert the}} units of an <b>input</b> <b>quantity</b> into the units of the measurand. Sensitivity coefficients are also, and more importantly, measures of how much change is produced in the measurand by changes in an <b>input</b> <b>quantity.</b> Mathematically, Sensitivity coefficients are obtained from partial derivatives of the model function {{with respect to the}} input quantities [1]. Many laboratories use the value of the sensitivity coefficient equals one for every <b>input</b> <b>quantity</b> without performing the partial derivatives. They use the value one just to express the uncertainty of the <b>input</b> <b>quantity</b> as a percentage which is not true. The aim of this work is to demonstrate the difference in the uncertainty values calculated by using the sensitivity coefficient by the partial differential equations and by using percentage values through examples in hardness and tension tests. The examples show high difference between the two methods...|$|E
5000|$|Causality {{principle}} — {{the relation}} between a managerial objective's quantitative output and the <b>input</b> <b>quantities</b> that must be, or must have been, consumed if the output is to be achieved.|$|R
5000|$|Formally, {{the output}} quantity, denoted by , about which {{information}} is required, is often related to <b>input</b> <b>quantities,</b> denoted by , about which information is available, by a measurement {{model in the}} form of ...|$|R
40|$|We {{propose a}} method to {{consistently}} estimate production functions {{in the presence of}} input price dispersion when intermediate <b>input</b> <b>quantities</b> are not observed. We find that the traditional approach to dealing with unobserved <b>input</b> <b>quantities</b> [...] -using deflated expenditure as a proxy [...] -substantially biases the production estimates. In contrast, our method controls for heterogeneous input prices by exploiting the first order conditions of the firm's profit maximization problem and consistently recovers the production function parameters. Using our preferred method, we provide empirical evidence of significant input price dispersion and even wider productivity dispersion than is estimated using proxy methods...|$|R
40|$|Master's thesis in Industrial EconomicsThe framework: In both papers we {{introduce}} the new framework for analyzing model (output) uncertainty in models used in risk assessment. The framework applies when no experimental {{data are available}} {{at the time of the}} risk assessment, and the main features can be summarized as follows (a more detailed description can be found in Paper I and II and the references within) : The following concepts and distinctions are given in the framework: • The concepts and distinction between model error and model output uncertainty: The difference between a true value of interest to be realized in the future, Z, and the model outcome (prediction) G(X) is called the model error, ΔG(X) =Z-G(X). Model output uncertainty is the epistemic uncertainty about the magnitude of the model error, ΔG(X). • The concepts and distinction between structural model uncertainty and <b>input</b> <b>quantity</b> (parameter) uncertainty: The concept model output uncertainty is divided into structural model uncertainty and <b>input</b> <b>quantity</b> (parameter) uncertainty. The structural model uncertainty is the model output uncertainty about the magnitude of the model error conditional on the true <b>input</b> <b>quantity,</b> ΔG(XTrue), while the <b>input</b> <b>quantity</b> uncertainty is uncertainty about the true value of the <b>input</b> <b>quantity,</b> X. • The concept and distinctions regarding sources of uncertainty: Sources of uncertainty are classified as belonging to either the <b>input</b> <b>quantity</b> uncertainty or the structural model uncertainty. Sources of <b>input</b> <b>quantity</b> uncertainty are sources that give uncertainty about the value of X. While sources of structural uncertainty are typically assumptions and approximations underpinning the model. The framework also links the concept of model output uncertainty to the objectives of modeling and risk assessment and specifically model accreditation is given focus. Meaning that the models needs to have a certain level of quality for its intended use (the purpose) in the risk assessment and subsequent decision making process. In addition the framework is open for various tools to represent the epistemic uncertainties. [ [...] . ...|$|E
40|$|Controlling {{an inline}} Electron Beam Physical Vapor Deposition (eb-PVD) process {{requires}} mostly {{the identification of}} proper process models, even more if {{the distance between the}} measuring points of the process <b>input</b> <b>quantity</b> (e. g. the electron beam power) and output quantity (e. g. a layer thickness measurement) is large in comparison to the used substrate velocity. In this case, remarkable dead times between the quantities are common and therefore {{it is very hard to}} control such processes. If plasma enhanced eb-PVD process is used, it's possible to employ specific spectral emission lines of the plasma (e. g. captured by optical emissions spectroscopy [OES]) as controller auxiliary <b>input</b> <b>quantity</b> to speed up the controller's reaction on the process dynamics. In this article results of a investigation about the possibility of using the plasma spectral emission intensities as auxiliary <b>input</b> <b>quantity</b> to control the layer thickness are shown...|$|E
30|$|If the {{condition}} for profitability {{of the business}} holds, i.e., p > c/θ, {{it has to be}} evaluated whether an <b>input</b> <b>quantity</b> Q > D is preferable.|$|E
40|$|The {{subject of}} the paper is a {{demonstration}} of the probabilistic assessment method of a pressure pipeline damaged by a system of stress corrosion crack. The fracture criterion is {{based on the fact that}} in the instant of the fracture the magnitude of the J-integral is equal to its critical value. First the fracture criterion is evaluated deterministically for nominal values of <b>input</b> <b>quantities.</b> Then attention is paid to incorporation of the randomness <b>input</b> <b>quantities</b> and the quantification of its influence on the probability of failure calculated using SBRA method, utilizing the Monte Carlo simulation technique...|$|R
5000|$|The {{calculation}} stage {{consists of}} propagating the probability distributions for the <b>input</b> <b>quantities</b> through the measurement model {{to obtain the}} probability distribution for the output quantity , and summarizing by using this distribution to obtain ...|$|R
30|$|The quality {{evaluation}} of measurements {{is a fundamental}} problem to any field in which a quantity has to be measured. Direct measurements are usually evaluated by the standard uncertainty (BIPM 2008)—i.e., the standard deviation (SD). For quantities {{measured in terms of}} a set of <b>input</b> <b>quantities,</b> a common approach is to evaluate their measurement by the law of propagation of uncertainties, for details refer to BIPM (2008), Kacker et al. (2007). However, this law is generally used in its simplified form, which assumes a first-order Taylor series approximation of the measurand function (i.e., that the behavior of the quantity being measured is well described by a linear function) and that the <b>input</b> <b>quantities</b> are uncorrelated [this simplified formula is traditionally referred to as law of error propagation, a misnomer (Kacker et al. 2007)]. If higher order approximations are to be included, restrictive assumptions have to be made (Kacker et al. 2007). Meanwhile, the major reason for unreasonable uncertainty evaluations is the non-identification and, consequently, non-incorporation of the correlation between the <b>input</b> <b>quantities</b> (Kacker et al. 2007).|$|R
