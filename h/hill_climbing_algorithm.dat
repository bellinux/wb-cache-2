115|2116|Public
5000|$|When [...] {{is equal}} to one, the LORA {{algorithm}} {{is identical to the}} SP algorithm. Increasing the value of [...] will increase the bias towards less used routes. The optimal value of [...] can be calculated using the well-known <b>hill</b> <b>climbing</b> <b>algorithm.</b> The optimal values of [...] were between 1.1 and 1.2 in the proposal.|$|E
5000|$|Random-restart hill {{climbing}} is a meta-algorithm built {{on top of}} the <b>hill</b> <b>climbing</b> <b>algorithm.</b> It is also known as Shotgun {{hill climbing}}. It iteratively does hill-climbing, each time with a random initial condition [...] The best [...] is kept: if a new run of hill climbing produces a better [...] than the stored state, it replaces the stored state.|$|E
50|$|As {{a general}} rule of thumb genetic {{algorithms}} might be useful in problem domains that have a complex fitness landscape as mixing, i.e., mutation in combination with crossover, is designed to move the population away from local optima that a traditional <b>hill</b> <b>climbing</b> <b>algorithm</b> might get stuck in. Observe that commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).|$|E
5000|$|A Hann window {{multiplied by}} a Poisson window, {{which has no}} side-lobes, {{in the sense that}} its Fourier {{transform}} drops off forever away from the main lobe. It can thus be used in <b>hill</b> <b>climbing</b> <b>algorithms</b> like Newton's method. The Hann-Poisson window is defined by: ...|$|R
40|$|In this paper, we empirically {{evaluate}} {{effectiveness of}} structure learning of Bayesian Network when applying such networks to {{the domain of}} Keystroke Dynamics authentication. We compare four structure learning methods of Bayesian Network Classifier – Genetic, TAN, K 2, and <b>Hill</b> <b>Climbing</b> <b>algorithms,</b> on our authentication model, namel...|$|R
50|$|The {{most basic}} form of local search {{is based on}} {{choosing}} the change that maximally decreases {{the cost of the}} solution. This method, called <b>hill</b> <b>climbing,</b> proceeds as follows: first, a random assignment is chosen; then, a value is changed so as to maximally improve the quality of the resulting assignment. If no solution has been found after a given number of changes, a new random assignment is selected. <b>Hill</b> <b>climbing</b> <b>algorithms</b> can only escape a plateau by doing changes that do not change the quality of the assignment. As a result, they can be stuck in a plateau where the quality of assignment has a local maxima.|$|R
50|$|Consider a set {{of points}} in {{two-dimensional}} space. Assume a circular window centered at C and having radius r as the kernel. Mean shift is a <b>hill</b> <b>climbing</b> <b>algorithm</b> which involves shifting this kernel iteratively to a higher density region until convergence. Every shift is defined by a mean shift vector. The mean shift vector always points toward {{the direction of the}} maximum increase in the density. At every iteration the kernel is shifted to the centroid or the mean of the points within it. The method of calculating this mean depends on the choice of the kernel. In this case if a Gaussian kernel is chosen instead of a flat kernel, then every point will first be assigned a weight which will decay exponentially as the distance from the kernel's center increases. At convergence, there will be no direction at which a shift can accommodate more points inside the kernel.|$|E
5000|$|The {{relative}} {{simplicity of}} the algorithm makes it a popular first choice amongst optimizing algorithms. It is used widely in artificial intelligence, for reaching a goal state from a starting node. Choice of next node and starting node can be varied to give a list of related algorithms. Although more advanced algorithms such as simulated annealing or tabu search may give better results, in some situations hill climbing works just as well. Hill climbing can often produce a better result than other algorithms when {{the amount of time}} available to perform a search is limited, such as with real-time systems, so long as a small number of increments typically converges on a good solution (the optimal solution or a close approximation). At the other extreme, bubble sort {{can be viewed as a}} <b>hill</b> <b>climbing</b> <b>algorithm</b> (every adjacent element exchange decreases the number of disordered element pairs), yet this approach is far from efficient for even modest N, as the number of exchanges required grows quadratically.|$|E
30|$|HC(Random) and HC(Greedy): The HC(Random) use a {{randomly}} generated solution as {{the initial}} solution {{to run the}} <b>hill</b> <b>climbing</b> <b>algorithm,</b> while the HC(Greedy), uses a greedy solution as the initial solution to run the <b>hill</b> <b>climbing</b> <b>algorithm.</b> From an implementation standpoint, this translates to leaving outlines 12 - 15 (i.e., the else part of the if statement) of Algorithm 2.|$|E
40|$|AbstractHyper-heuristics {{operate at}} the level above {{traditional}} (meta-) heuristics that ‘optimise the optimiser’. These algorithms can combine low level heuristics to create bespoke algorithms for particular classes of problems. The lowlevel heuristics can be mutation operators or <b>hill</b> <b>climbing</b> <b>algorithms</b> and can include industry expertise. This paper investigates {{the use of a}} new hyper-heuristic basedon sequence analysis in the biosciences, to develop new optimisers that can outperform conventional evolutionary approaches. It demonstrates that the new algorithms develop high quality solutions on benchmark water distribution network optimisation problems efficiently, and can yield important information about the problem search space...|$|R
40|$|This paper {{describes}} a novel search <b>algorithm,</b> called dynamic <b>hill</b> <b>climbing,</b> that borrows ideas from genetic <b>algorithms</b> and <b>hill</b> <b>climbing</b> techniques. Unlike both genetic and <b>hill</b> <b>climbing</b> <b>algorithms,</b> dynamic <b>hill</b> <b>climbing</b> {{has the ability}} to dynamically change its coordinate frame during the course of an optimization. Furthermore, the algorithm moves from a coarse-grained search to a fine-grained search of the function space by changing its mutation rate and uses a diversity-based distance metric to ensure that it searches new regions of the space. Dynamic <b>hill</b> <b>climbing</b> is empirically compared to a traditional genetic algorithm using De Jong's well-known five function test suite [4] and is shown to vastly surpass the performance of the genetic algorithm, often finding better solutions using only 1 % as many function evaluations. 1 Introduction Genetic algorithms [13, 10] have been applied {{to a wide variety of}} optimization problems ranging from the traveling salesman problem [12, 16] to [...] ...|$|R
40|$|Generalized <b>hill</b> <b>climbing</b> (GHC) <b>algorithms</b> {{provide a}} {{framework}} for using local search algorithms to address intractable discrete optimization problems. Many well-known local search algorithms can be formulated as GHC algorithms, including simulated annealing, threshold accepting, Monte Carlo search, and pure local search (among others). This dissertation develops a mathematical framework for simultaneously addressing a set of related discrete optimization problems using GHC algorithms. The resulting algorithms, termed simultaneous generalized <b>hill</b> <b>climbing</b> (SGHC) <b>algorithms,</b> can be applied {{to a wide variety of}} sets of related discrete optimization problems. The SGHC algorithm probabilistically moves between these discrete optimization problems according to a problem generation probability function. This dissertation establishes that the problem generation probability function is a stochastic process that satisfies the Markov property. Therefore, given a SGHC algorithm, movement between these discrete optimization problems can b...|$|R
40|$|This paper {{presents}} {{a case study}} of search-based test generation for embedded system software units developed using the Function Block Diagrams (FBDs), a graphical language in the IEC 61131 - 3 standard aimed at programmable logic controllers (PLCs). We consider 279 different components from the train control software developed by Bombardier Transportation, a major rail vehicle manufacturer. The software is compiled into C code with a particular structure. We use a modified <b>hill</b> <b>climbing</b> <b>algorithm</b> for generating test data to maximize MC/DC coverage for assignments with logical expressions in the C code, while retaining the semantics of the original FBD implementation. An experimental evaluation for comparing the effectiveness (coverage rate) and the efficiency (required number of executions) of <b>hill</b> <b>climbing</b> <b>algorithm</b> with random testing is presented. The results show that random testing performs well for most units under test, while around 30 % of the artifacts significantly benefit from the <b>hill</b> <b>climbing</b> <b>algorithm.</b> Structural properties of the units that affect the performance of hill climbing and random testing are also discussed...|$|E
40|$|Load {{frequency}} {{control of the}} hybrid system consisting photovoltaic system and thermal generator is performed in this paper. In this paper Maximum Power Point Tracking is performed in photovoltaic using modified <b>hill</b> <b>climbing</b> <b>algorithm.</b> Modified hill climbing is performed by combining fuzzy logic with <b>hill</b> <b>climbing</b> <b>algorithm.</b> The converter used is Boost converter. DC output obtained is converted to AC output by using single phase inverter. Grid connection is performed by using sinusoidal pulse width modulation. Transfer function model of the whole system is created. Transfer function model of the thermal generator is interfaced with the photovoltaic system to create two area systems. Load {{frequency control}}s of this two area system are performed. The simulation of the entire system is performed in the MATLAB SIMULINK...|$|E
40|$|Stochastic <b>hill</b> <b>climbing</b> <b>algorithm</b> {{is adapted}} to rapidly find the {{appropriate}} start node in the application mapping of network-based many-core systems. Due to highly dynamic and unpredictable workload of such systems, an agile run-time task allocation scheme is required. The scheme is desired to map the tasks of an incoming application at run-time onto an optimum contiguous area of the available nodes. Contiguous and un-fragmented area mapping is to settle the communicating tasks in close proximity. Hence, the power dissipation, the congestion between different applications, and the latency of the system will be significantly reduced. To find an optimum region, we first propose an approximate model that quickly estimates the available area around a given node. Then the stochastic <b>hill</b> <b>climbing</b> <b>algorithm</b> {{is used as a}} search heuristic to find a node that has the required number of available nodes around it. Presented agile climber takes the steps using an adapted version of <b>hill</b> <b>climbing</b> <b>algorithm</b> named Smart Hill Climbing, SHiC, which takes the run-time status of the system into account. Finally, the application mapping is performed starting from the selected first node. Experiments show significant gain in the mapping contiguousness which results in better network latency and power dissipation, compared to state-of-the-art works...|$|E
40|$|The search problem, ACCESSIBILITY, {{asks whether}} a finite {{sequence}} of events can be found such that, starting with a specific initial event, a particular state can be reached. This problem is intractable, indicating the need for heuristics to address it. One difficulty when applying heuristics to ACCESSIBILITY is assessing a priori their effectiveness, and knowing how to best adjust them to improve performance. This paper introduces the false negative probability as a performance measure for generalized <b>hill</b> <b>climbing</b> <b>algorithms</b> applied to discrete optimization problems, using ACCESSIBILITY as the analysis framework. The false negative probability {{is also used to}} obtain necessary convergence conditions. The implications of these results on how GHC algorithms can be effectively applied are discussed...|$|R
40|$|We {{discuss the}} {{relationships}} between three approaches to greedy heuristic search: best-first, hill-climbing, and beam search. We consider the design decisions within each family and point out their oft-overlooked similarities. We consider the following best-first searches: weighted A*, greedy search, A ∗ ǫ, window A * and multi-state commitment k-weighted A*. For <b>hill</b> <b>climbing</b> <b>algorithms,</b> we consider enforced <b>hill</b> <b>climbing</b> and LSS-LRTA*. We also consider a variety of beam searches, including BULB and beam-stack search. We show how to best configure beam search {{in order to maximize}} robustness. An empirical analysis on six standard benchmarks reveals that beam search and best-first search have remarkably similar performance, and outperform hill-climbing approaches in terms of both time to solution and solution quality. Of these, beam search is preferable for very large problems and best first search is better on problems where the goal cannot be reached from all states...|$|R
40|$|Heuristic search {{planning}} eectively nds {{solutions for}} large planning problems, {{but since the}} estimates are either not admissible or too weak, optimal solutions are found in rare cases only. In contrast, heuristic pattern databases are known to signicantly improve lowerbound estimates for optimally solving challenging single-agent problems like the 24 -Puzzle or Rubik's Cube. This paper studies the eect of pattern databases {{in the context of}} deterministic planning. Given afixed state description based on instantiated predicates, we provide a general abstraction scheme to automatically create admissible domain-independent memory-based heuristics for planning problems, where abstractions are found in factorizing the planning space. We evaluate the impact of pattern database heuristics in A* and <b>hill</b> <b>climbing</b> <b>algorithms</b> for a collection of benchmark domains...|$|R
40|$|This paper {{investigates the}} ability of a tournament {{selection}} based genetic algorithm to find mutationally robust solutions to a simple combinatorial optimization problem. Two distinct algorithms (a stochastic hill climber and a tournament selection based GA) were used to search for optimal walks in several variants of the self avoiding walk problem. The robustness of the solutions obtained by the algorithms were compared, both {{with each other and with}} solutions obtained by a random sampling of the optimal solution space. The solutions found by the GA were, for most of the problem variants, significantly more robust than those found by either the <b>hill</b> <b>climbing</b> <b>algorithm</b> or random sampling. The solutions found by the <b>hill</b> <b>climbing</b> <b>algorithm</b> were often significantly less robust than those obtained through random sampling. Categories and Subject Descriptor...|$|E
40|$|This paper {{describes}} a stochastic <b>hill</b> <b>climbing</b> <b>algorithm</b> named SHCLVND to optimize arbitrary vectorial ! ! ! functions. It needs less parameters. It uses normal (Gaussian) distributions to represent probabilities {{which are used}} for generating more and more better argument vectors. The -parameters of the normal distributions are changed {{by a kind of}} Hebbian learning...|$|E
40|$|Abstract — This paper {{introduces}} a novel improved evolutionary algorithm, which combines genetic algorithms and hill climbing. Genetic Algorithms (GA) {{belong to a}} class of well established optimization meta-heuristics and their behavior are studied and analyzed in great detail. Various modifications were proposed by different researchers, for example modifications to the mutation operator. These modifications usually change the overall behavior of the algorithm. This paper presents a binary GA with a modified mutation operator, {{which is based on}} the well-known <b>Hill</b> <b>Climbing</b> <b>Algorithm</b> (HCA). The resulting algorithm, referred to as GAHC, also uses an elite tournament selection operator. This selection operator preserves the best individual from the GA population during the selection process while maintaining the positive characteristics of the standard tournament selection. This paper discusses the GAHC algorithm and compares its performance with standard GA. Index Terms — Elite tournament selection, HC mutation, <b>Hill</b> <b>climbing</b> <b>Algorithm,</b> Genetic Algorithm...|$|E
40|$|In this paper, {{we examine}} the results of major {{previous}} attempts to apply genetic and evolutionary computation (GEC) to image processing. In many problems, the accuracy (quality) of solutions obtained by GEC-based methods is better than that obtained by other methods such as conventional methods, neural networks and simulated annealing. However, the computation time required is satisfactory in some problems, whereas it is unsatisfactory in other problems. We consider the current problems of GEC-based methods and present the following measures to achieve still better performance: (1) utilizing competent GECs, (2) incorporating other search algorithms such as local <b>hill</b> <b>climbing</b> <b>algorithms,</b> (3) hybridizing with conventional image processing algorithms, (4) modeling the given problem with as smaller parameters as possible, and (5) using parallel processors to evaluate the fitness function. 1...|$|R
40|$|Join {{is one of}} the {{fundamental}} and most expensive operations in Database Management Systems (DBMSs). Although several techniques exist for computing multi-way joins in traditional databases, spatial joins involving more than two relations are not efficiently supported by current Spatial DBMSs and Geographic Information Systems (GISs). This paper proposes techniques for processing multi-way spatial joins by exploring their close correspondence with constraint satisfaction problems. In addition, it provides cost models and optimization methods that compute the execution plan using dynamic programming and <b>hill</b> <b>climbing</b> <b>algorithms.</b> Finally, it evaluates the efficiency of the proposed techniques and the accuracy of the cost models through extensive experimentation with several query and data combinations. Contact Author: Dimitris Papadias Tel: ++ 852 - 23586971 [URL] Fax: ++ 852 - 23581477 E-mail: dimitris@cs. ust. hk The Hong Kong University of Science & Technology Techni [...] ...|$|R
40|$|The k-means {{algorithm}} {{is one of}} the well-known and most popular clustering algorithms. K-means seeks an optimal partition of the data by minimizing the sum of squared error with an iterative optimization procedure, which belongs to the category of <b>hill</b> <b>climbing</b> <b>algorithms.</b> As we know <b>hill</b> <b>climbing</b> searches are famous for converging to local optimums. Since k-means can converge to a local optimum, different initial points generally lead to different convergence cancroids, which makes it important to start with a reasonable initial partition in order to achieve high quality clustering solutions. However, in theory, there exist no efficient and universal methods for determining such initial partitions. In this paper we tried to find an optimum initial partitioning for k-means algorithm. To achieve this goal we proposed a new improved version of downhill simplex search, and then we used it in order to find an optimal result for clustering approach and then compare this algorithm with Genetic Algorithm base (GA), Genetic K-Means (GKM), Improved Genetic K-Means (IGKM) and k-means algorithms. Comment: 4 Page...|$|R
40|$|This paper {{describes}} a stochastic <b>hill</b> <b>climbing</b> <b>algorithm</b> to optimize vectorial functions on real numbers. It uses normal (Gaussian) distributions to represent probabilities {{which are used}} for generating more and more better argument vectors. The ¯-parameters of the normal distributions are changed through a kind of Hebbian learning. To optimize a highly multimodal vectorial function on real numbers which were represented as bit vectors Kvasnicka et al. [Kvasnicka, 95] used Stochastic Hill Climbing with Learning (HCwL). We have tested the proposed algorithm by optimizations of the same and a similar function and show the results. In opposite to HCwL from [Kvasnicka, 95] this algorithm works directly on vectors of numbers and uses normal distributions instead of numbers to represent probabilities. Keywords: stochastic hill climbing, optimization, genetic algorithms, evolutionary strategies. 1 Introduction This paper {{describes a}} <b>hill</b> <b>climbing</b> <b>algorithm</b> to optimize vectorial functions o [...] ...|$|E
40|$|This paper studies {{about the}} {{mechanical}} part of wind turbine and wind generator operation stability. 1) It makes a com-parative study of two control methods for maximum power tracking: curve fitting method and <b>hill</b> <b>climbing</b> <b>algorithm,</b> sets up improved control modules in DIgSLIENT and makes comparison research, thus gets {{the conclusion that}} the im-proved control modules of <b>hill</b> <b>climbing</b> <b>algorithm</b> has good effect on MPPT, and it is more desirable in the condition of steady wind. 2) This paper sets up SVC and STATCOM models and improved control modules in DIgSLIENT, which are connected to wind power system, verifying the validity of SVC and STATCOM models, and verifying its influence on wind power plant and system. The results of the study show that STATCOM is more helpful in voltage recovery when large disturbance of three-phase short-circuit happened in wind power grid, reactive compensation is more effec-tive...|$|E
40|$|Abstract This paper {{presents}} new results {{showing that}} a very simple stochastic <b>hill</b> <b>climbing</b> <b>algorithm</b> is as good or better than more complex metaheuristic methods for solving an oversubscribed scheduling problem: scheduling communication contacts on the Air Force Satellite Control Network (AFSCN). The empirical results also suggest that the best neighborhood construction choices produce a search that is largely a greedy random walk of the graph induced by the complete neighborhood...|$|E
40|$|Recent {{research}} {{show that}} adaptive compiler can produce consistent improvement over a traditional fixed-sequence compiler by conducting feedback-directed searches for good compilation sequences for specific programs, machines and performance objectives. However, such improvement is usually achieved {{at very high}} search cost. This thesis proposes two approaches to accelerate the searches for a good compilation sequence in an adaptive compiler. First, a local search algorithm, Greedy Neighbor Exploration algorithm (GNE), is proposed. It uses optimistic greedy construction and cleanup procedures to generate a richer set of meaningful variations by randomized insertion and removal of transformations. Experimental results {{on a range of}} standard benchmark suites show that GNE finds better compilation sequences in {{less than a quarter of}} the evaluations required by current search algorithms, such as genetic and <b>hill</b> <b>climbing</b> <b>algorithms.</b> Second, code normalization techniques are developed to hash programs and detect equivalent code. This can avoid unnecessary runs of programs...|$|R
40|$|Certain {{adaptive}} optics systems do not employ a wave front sensor but rather maximise a photodetector signal by appropriate control of an adaptive element. The maximisation procedure must be optimised {{if the system}} is to work efficiently. Such optimisation is often implemented empirically, but further insight {{can be obtained by}} using an appropriate mathematical model. In many practical systems aberrations can be accurately represented by a small number of modes of an orthogonal basis, such as the Zernike polynomials. By heuristic reasoning we develop a model for the operation of such systems and demonstrate a link with the geometrical problems of sphere packings and coverings. This approach aids the optimisation of control algorithms and is illustrated by application to direct search and <b>hill</b> <b>climbing</b> <b>algorithms.</b> We develop an efficient scheme using a direct maximisation calculation that permits the measurement of N Zernike modes with only N + 1 intensity measurements...|$|R
40|$|The {{problem of}} {{programming}} an artificial ant {{to follow the}} Santa Fe trail is used as an example program search space. Analysis of shorter solutions shows they have many of the characteristics often ascribed to manually coded programs. Enumeration of {{a small fraction of}} the total search space and random sampling characterise it as rugged with many multiple plateaus split by deep valleys and many local and global optima. This suggests it is difficult for <b>hill</b> <b>climbing</b> <b>algorithms.</b> Analysis of the program search space in terms of fixed length schema suggests it is highly deceptive and that for the simplest solutions large building blocks must be assembled before they have above average fitness. In some cases we show solutions cannot be assembled using a fixed representation from small building blocks of above average fitness. These suggest the Ant problem is difficult for Genetic Algorithms. Random sampling of the program search space suggests on average the density of global optima change [...] ...|$|R
40|$|This paper {{describes}} the new t-way strategy based the Late Acceptance based <b>Hill</b> <b>Climbing</b> <b>algorithm,</b> called LAHC, for constraints t-way test generation. Unlike earlier competing work, LAHC {{does not require}} significant tuning {{in order to have}} it working. In fact, LAHC merely requires minor adjustment of the common controlling parameters involving iteration and population size depending on the given system configuration. Our benchmarking results have been promising as LAHC gives competitive results in most constraints configurations considered...|$|E
40|$|The paper {{describes}} an optimization procedure to synchronize traffic signals along an urban road artery. The solution procedure applies first a genetic algorithm {{and then a}} <b>hill</b> <b>climbing</b> <b>algorithm</b> for local adjustments. The fitness function is evaluated {{by means of a}} traffic model that simulates platoon progression along the links, their combination and possible queuing at nodes. The potential benefits of the synchronization procedure have been assessed by simulating a real urban artery through the micro-simulation model Transmodeler...|$|E
40|$|Abstract. Considering {{the soft}} output {{performance}} of automobile exhaust thermoelectric generator (AETEG), an AETEG using Buck based DC/DC converter were established, {{based on the}} duty ratio disturbance observation method, an improved {{maximum power point tracking}} algorithm(MPPT) named adaptive <b>hill</b> <b>climbing</b> <b>algorithm</b> was present, including its principle and flow diagram. The simulation result based on UDDS driving cycle proves that the practical power of AETEG can follow its theoretic maximum output power, the algorithm has advantages on the dynamic and steady performance of AETEG in the MPPT...|$|E
40|$|The credit on {{reduction}} theory {{goes back}} to the work of Lagrange, Gauss, Hermite, Korkin, Zolotarev, and Minkowski. Modern reduction theory is voluminous and includes the work of A. Lenstra, H. Lenstra and L. Lovasz who created the well known LLL algorithm, and many other researchers such as L. Babai and C. P. Schnorr who created significant new variants of basis reduction algorithms. In this paper, we propose and investigate the efficacy of new optimization techniques to be used along with LLL algorithm. The techniques we have proposed are: i) <b>hill</b> <b>climbing</b> (HC), ii) lattice diffusion-sub lattice fusion (LDSF), and iii) multistage hybrid LDSF-HC. The first technique relies on the sensitivity of LLL to permutations of the input basis B, and optimization ideas over the symmetric group S_m viewed as a metric space. The second technique relies on partitioning the lattice into sublattices, performing basis reduction in the partition sublattice blocks, fusing the sublattices, and repeating. We also point out places where parallel computation can reduce run-times achieving almost linear speedup. The multistage hybrid technique relies on the lattice diffusion and sublattice fusion and <b>hill</b> <b>climbing</b> <b>algorithms.</b> Comment: Keywords: Lattice basis, unimodular matrices, right permutations, LLL algorithm, random walk distributio...|$|R
40|$|Classifier ensembles, {{in which}} {{multiple}} predictive models are combined to produce predictions for new cases, generally perform {{better than a}} single classifier. Most existing methods construct static ensembles, in which one collection is used for all test cases. Recently, some researchers have proposed dynamic ensemble construction algorithms, which choose an ensemble specifically for each point from a large pool of classifiers. Ensemble performance is generally seen as having two factors: {{the accuracy of the}} individual classifiers and the diversity of the ensemble. In this study we employ heuristic optimization to examine the role of a third factor: the confidence of each classifier’s prediction on the specific data point. We experiment with genetic <b>algorithms</b> and various <b>hill</b> <b>climbing</b> <b>algorithms,</b> in both single- and multi-objective scenarios, to choose locally-optimal sets of 25 classifiers from a large pool to classify each new example. We focus on dynamic ensemble construction by analyzing how diversity, accuracy and confidence interact with each other and how they affect the performance of the ensemble on new examples. ...|$|R
40|$|Structural {{testing is}} one of the most {{important}} activities within software testing. Ideally, to achieve 100 % coverage of every conditions and decisions, tester must take an exhaustive approach. However, exhaustive testing is costly and time consuming. Addressing the aforementioned issues, researchers advocate the use of Multiple Condition/Decision Coverage (MC/DC) criteria for sampling of the test cases[1]. Owing the popularity of Search based Software Engineering; many researchers have recently treated MC/DC compliant test case generation as optimization problem. As a result, many meta-heuristic based strategy implementations have appeared in the literature. Most implementations have been focused on neighborhood-based meta-heuristics. In order to help test engineers to make informed decision on the best neighborhood based implementations, this paper investigates the size and time performance of two MC/DC test strategies re-implementation based on Simulated Annealing against two newly developed strategies based on Great Deluge and Late Acceptance <b>Hill</b> <b>Climbing</b> <b>algorithms</b> respectively. Experimental results demonstrate the strength and weakness of the algorithms, change of their behavior on different types of predicates, etc...|$|R
