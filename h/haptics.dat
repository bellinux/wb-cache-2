1234|7834|Public
25|$|Proxemics is {{one among}} several subcategories {{in the study}} of nonverbal communication, {{including}} <b>haptics</b> (touch), kinesics (body movement), vocalics (paralanguage), and chronemics (structure of time).|$|E
25|$|Courtship {{has five}} phases {{which include the}} {{attention}} phase, recognition phase, conversation phase, touching phase, and the love-making phase. <b>Haptics</b> takes place more {{during the last two}} phases.|$|E
25|$|Due to {{both the}} {{relative}} scarcity of cadavers {{to be used for}} surgical instruction and to the dwindling use of animals and patients who have not given consent, institutes may utilize medical animations as a way to teach doctors-to-be anatomical and surgical concepts. Such simulations may be viewed passively (as in the case of 3D medical animations included via CD-ROM in medical textbook packages) or using interactive controls. The stimulation of hand-eye skills using <b>haptics</b> is another possible use of medical animation technology, one that stems from the replacement of cadavers in surgical classrooms with task trainers and mannequins.|$|E
40|$|<b>Haptic</b> {{feedback}} {{plays an}} important role to recognize and manipulate objects in virtual environments. Recently, high quality <b>haptic</b> feedback devices have been commercially available. However, the basic software for <b>haptic</b> devices is not prepared sufficiently. In this paper, we propose <b>Haptic</b> Interface Platform(HIP) that is a common software library independent of the types of <b>haptic</b> devices to construct virtual environments with <b>haptic</b> feedback. HIP supports three types of <b>haptic</b> device types:Point Type, Surface Type and Texture Type. To generalize <b>Haptic</b> Interface Platform, we classified it into three functions: (1) device driver, (2) <b>haptic</b> Tenderer, (3) <b>haptic</b> simulation engines. HIP enables users to make complex virtual environments easily. Since HIP is compatible with many <b>haptic</b> displays, we will also be able to accumulate <b>haptic</b> software assets and reproduct software in making applications. In the last of this paper, we developed simple <b>haptic</b> models using HIP and experimented how humans would feel them for each <b>haptic</b> display. We verified that HIP made the similar sensation for each display...|$|R
40|$|<b>Haptic</b> aids {{have been}} largely used in manual control tasks to {{complement}} the visual information through the sense of touch. To analytically design a <b>haptic</b> aid, adequate knowledge is needed about how pilots adapt their visual response and the biomechanical properties of their arm (i. e., admittance) to a generic <b>haptic</b> aid. In this work, two different <b>haptic</b> aids, a direct <b>haptic</b> aid and an indirect <b>haptic</b> aid, are designed for a target tracking task, {{with the aim of}} investigating the pilot response to these aids. The direct <b>haptic</b> aid provides forces on the control device that suggest the right control action to the pilot, whereas the indirect <b>haptic</b> aid provides forces opposite in sign with respect to the direct <b>haptic</b> aid. The direct <b>haptic</b> aid and the indirect <b>haptic</b> aid were tested in an experimental setup with nonpilot participants and compared to a condition without <b>haptic</b> support. It was found that control performance improved with <b>haptic</b> aids. Participants significantly adapted both their admittance and visual response to fully exploit the <b>haptic</b> aids. They were more compliant with the direct <b>haptic</b> aid force, whereas they showed stiffer neuromuscular settings with the indirect <b>haptic</b> aid, as this approach required opposing the <b>haptic</b> forces...|$|R
40|$|<b>Haptic</b> {{guidance}} {{has previously}} been employed to improve human performance in control tasks. This paper presents an experiment to evaluate whether <b>haptic</b> feedback {{can be used to}} help humans learn a compensatory tracking task. In the experiment, participants were divided into two groups: the <b>haptic</b> group and the no-aid group. The <b>haptic</b> group performed a first training phase with <b>haptic</b> feedback and a second evaluation phase without <b>haptic</b> feedback. The no-aid group performed the whole experiment without <b>haptic</b> feedback. Results indicated that <b>haptic</b> group achieved better performance than the no-aid group during the training phase. Furthermore, performance of <b>haptic</b> group did not worsen in the evaluation phase when the <b>haptic</b> feedback was turned off. Moreover, the no-aid group needed more experimental trials to achieve similar performance to the <b>haptic</b> group. These findings indicate that <b>haptic</b> feedback helped participants learn the task quicker...|$|R
2500|$|... : {{contains}} {{a variety of}} nerve endings that react to heat and cold, touch, pressure, vibration, and tissue injury; see somatosensory system and <b>haptics.</b>|$|E
2500|$|A new {{teaching}} technique uses medical simulation as {{an alternative}} to cadaver training. High fidelity simulators range from those that use real surgical tools and passive <b>haptics,</b> such as VirtaMed's , to those that rely on active haptic feedback, such as the Arthro Mentor™ from Simbionix. When studied, passive <b>haptics</b> have shown [...] "high scores in terms of realism" [...] and the ability to differentiate between [...] "varying levels of arthroscopic experience". Reference material, such as the application developed by Touch Surgery, also contains visualization of minimally invasive techniques.|$|E
2500|$|Haptic {{communication}} is {{a branch of}} nonverbal communication that refers {{to the ways in}} which people and animals communicate, and interact via the sense of touch. Touch or <b>haptics,</b> from the ancient Greek word haptikos is extremely important for communication; it [...] is vital for survival. The sense of touch [...] allows one to experience different sensations such as: pleasure, pain, heat, or cold. [...] One of the most significant aspects of touch is the ability to convey and enhance physical intimacy. The sense of [...] touch is the fundamental component of haptic communication for interpersonal relationships.Touch can be categorized in many terms such [...] as positive, playful, control, ritualistic, task-related or unintentional. It can be both sexual (kissing is one example that some perceived as sexual), and platonic (such as hugging or a Handshake).|$|E
40|$|New 3 D video {{representations}} enable new modalities of interaction, such as <b>haptic</b> interaction, with 2 D and 3 D {{video for}} truly immersive media applications. <b>Haptic</b> interaction with video includes <b>haptic</b> structure and <b>haptic</b> motion for new immersive experiences. It {{is possible to}} compute <b>haptic</b> structure signals from 3 D scene geometry or depth information. This paper introduces the concept of <b>haptic</b> motion, {{as well as new}} methods to compute <b>haptic</b> structure and motion signals for 2 D video-plus-depth representation. The resulting <b>haptic</b> signals can be rendered using a <b>haptic</b> cursor attached to a 2 D or 3 D video display. Experimental results and a demo system are available...|$|R
40|$|<b>Haptic</b> {{algorithms}} compute {{forces from}} a virtual scene that are displayed via <b>haptic</b> interfaces to humans. This chapter focuses on suited algorithms and on control approaches for stable <b>haptic</b> interaction and highly transparent <b>haptic</b> rendering. In <b>haptic</b> control systems, a fixed update rate {{is crucial for}} stability of the control loop. Thus, <b>haptic</b> rendering has to fulfil the requirement of deterministic computation time. Furthermore, high transparency requires high spatial resolution of the device's sensors and of the <b>haptic</b> algorithm. <b>Haptic</b> rendering based on the Voxmap-PointShell approach {{has the advantage of}} guaranteed update rates for collision detection and high resolution models, and is therefore suitable for <b>haptic</b> interaction. Stability of <b>haptic</b> interaction limits the displayable stiffness of contacts in a virtual scene. Thus, a non-conservative stability condition is essential for high-transparent <b>haptic</b> interaction. The presented method is based on exact calculation of stability boundaries, which is in contrast to the widespread but conservative passivity-based approaches for <b>haptic</b> rendering. </p...|$|R
40|$|Abstract: In these paper basic {{concepts}} behind <b>haptic</b> technology which includes <b>haptic</b> interface and <b>haptic</b> rendering techniques {{and use of}} <b>haptic</b> technology in surgical simulation and medical training, and various issues and methods in generating tactile feedback are discussed. In experimental psychology and physiology, the word <b>haptic</b> refers {{to the sense of}} touch. So apart of senses like vision and audio one can feel the “sense of touch ” of things that are created in the virtual world. <b>Haptic</b> may imply <b>haptic</b> communication, <b>haptic</b> perception and <b>haptic</b> technology. <b>Haptic</b> communication is the way of response given by humans and other animals via touching. <b>Haptic</b> perception is the process of recognizing objects through touch. <b>Haptic</b> technology refers to tactile feedback, which means it provides feedback in the form of touch so one can feel the physical properties and movements of virtual objects created by computer. <b>Haptic</b> technology has wide range of applications in various fields and its implementation in medical field has been extremely useful. It helps to reduce the burden of the surgeon by providing efficient interaction through virtual reality...|$|R
5000|$|... #Caption: Fig 6 : Subluxated three piece IOL glued into place- Part 2. A- Second haptic {{is caught}} with the {{handshake}} technique. B- Both <b>haptics</b> externalized. C- Both <b>haptics</b> tucked in scleral pocket. D- Air in the AC, Fluid is switched off and glue applied. The air prevents any hypotony.|$|E
5000|$|Button devices used as teleporters or {{trackers}} (Global <b>Haptics</b> GeoOrb, ...).|$|E
5000|$|<b>Haptics</b> and Virtual Reality (Laboratory for Advanced User Interfaces and Virtual Reality) ...|$|E
40|$|It {{has been}} {{reported}} that there are separate representations of visual and <b>haptic</b> movements, and that the <b>haptic</b> process has a rotation-independent representation for movements. This finding suggests that movement representations are formed in a different manner from object representations through visual and <b>haptic</b> signals because signals from visual and <b>haptic</b> modalities are processed in a common multimodal representation for object perception. Here, we investigated how the rotation-independent representation specific to <b>haptic</b> movements is generated. Our results show that rotation-independent representations of <b>haptic</b> movements do not appear when <b>haptic</b> movements passively occur. We also confirmed that active <b>haptic</b> movements generate rotation-independent representations. These results suggest that active movements are required to generate rotation-independent representations for <b>haptic</b> movements...|$|R
40|$|Nowadays, {{providing}} a uniform development environment for <b>haptic</b> applications is {{considered as one}} of the critical issues in <b>haptic</b> technologies. Thus, to date, we have developed a component-based <b>haptic</b> authoring framework using a component capability extension mechanisms supported by Unity 3 D. Our aim is to develop a newly revised <b>haptic</b> component to extend our previous framework. The proposed component enables a user to design <b>haptic</b> interface such as <b>haptic</b> navigation, as well as to help simulate/investigate the effect of the <b>haptic</b> interaction. In this paper, we present a prototype system and its capabilities...|$|R
40|$|Application of <b>haptic</b> devices {{expanded}} to fields like virtual manufacturing, virtual assembly or medical simulations. Advances in development of <b>haptic</b> devices {{have resulted in}} a wide distribution of assymetric 6 / 3 -DOF <b>haptic</b> devices. However, current <b>haptic</b> rendering algorithms work correctly only for symmetric devices. This thesis analyzes 3 -DOF and 6 -DOF <b>haptic</b> rendering algorithms and proposes an algorithm for 6 / 3 -DOF <b>haptic</b> rendering involving pseudo-haptics. The 6 / 3 -DOF <b>haptic</b> rendering algorithm is implemented based on the previous analysis and tested in a user study...|$|R
5000|$|Taarlab's ongoing {{research}} {{areas in}} the field of <b>Haptics</b> are as follows: ...|$|E
5000|$|Demonstrated at <b>Haptics</b> Symposium 2010, the Tactile Gaming Vest [...] (TGV)is a haptic {{feedback}} device {{designed to increase}} the immersiveness of first- and third-person shooter games and was developed by Saurabh Palan and his team from the <b>Haptics</b> Lab at the University of Pennsylvania. The vest can simulate gunshots, slashing and blood flow sensations. Other sensations, such as punch/kick, body blows, and surrounding environment (temperature, impacts due to artilleries and ammunitions) are also being developed.|$|E
50|$|<b>Haptics</b> is {{the study}} of {{touching}} as nonverbal communication, and haptic communication refers to how people and other animals communicate via touching.|$|E
30|$|Our {{previous}} system [9, 12] has controlled the <b>haptic</b> force in an open-loop manner, {{based on the}} assumption that the <b>haptic</b> force is proportional to the square of the <b>haptic</b> voltage. As shown in the previous section, however, the assumption is not true due to the capacitance change; the <b>haptic</b> force fluctuates even when a constant <b>haptic</b> voltage is applied. Such behavior can be compensated by closed-loop control using the <b>haptic</b> force estimation, which is demonstrated in this section.|$|R
40|$|International audienceThis paper {{describes}} an experiment conducted to measure human's <b>haptic</b> sensitivity {{and the effects}} of <b>haptic</b> training with and without visual aid on a needle insertion task. The <b>haptic</b> training protocol consisted of a needle insertion task using dual-layer silicon samples. A visual aid was provided as a multimodal cue for <b>haptic</b> perception. Results show that for a novices' group, training with a visual aid inhibited <b>haptic</b> perception. Hence, <b>haptic</b> skills must be trained differently from visuo-motor skills...|$|R
40|$|The high force {{update rate}} {{is a key}} factor for {{achieving}} high performance of <b>haptic</b> rendering, which imposes a stringent real-time requirement upon the execution environment of the <b>haptic</b> system. To fulfil this requirement, <b>haptic</b> systems are often limited to simplified virtual environments (VEs) for reducing computational load. This paper presents a novel pipelined threading architecture, which uses several threads running consecutively for implementing <b>haptic</b> rendering algorithms. With the proposed method, the <b>haptic</b> forces updating rate is effectively increased, which leads to improved system performance and makes complex VE scenes possible in <b>haptic</b> rendering. Based on the 3 -DOF Delta <b>haptic</b> device, experiments with a virtual wall <b>haptic</b> system are carried out and verify the proposed method...|$|R
50|$|The Khatib group's {{present day}} {{interests}} include modeling human motor control, muscle actuated control, humanoid robotics, <b>haptics</b> in neuroimaging, and multi-contact control.|$|E
50|$|One of the {{key issues}} with virtual environments that utilize touch are the <b>haptics.</b> For example, {{utilizing}} virtual touch screen for medical training could cut costs down for training medical staff for touch delicate operations such as surgery. However, the <b>haptics</b> of such training does not provide sufficient physical touch feedback necessary for a virtually trained practitioner to perform a real surgery. Incorporating sufficient haptic feedback to virtual touch screen interactions is an active area of research.|$|E
5000|$|Commercial (large gaming areas sell gaming environments {{mixed with}} <b>haptics).</b> The Cheapnet, a free {{entry-level}} service offered by commercial vendors of gaming solutions, can in principle {{also be used}} to coordinate networked augmented reality representations across the globe. However, jitter and latency are considerable problems with this basic network when long distances are involved. In the novel, Robert Gu develops an algorithm that partially compensates for these technical deficiencies, and might ultimately allow the inclusion of <b>haptics.</b>|$|E
40|$|Multiple sensory {{modalities}} {{gather information}} about our surroundings to plan appropriate movements {{based on the}} properties of the environment and the objects within it. This study was designed to examine the sensitivity of visual and <b>haptic</b> information alone and together for detecting curvature. When both visual and <b>haptic</b> information were present, temporal delays in signal onset were used to determine the effect of asynchronous sensory information on the interference of vision on the <b>haptic</b> estimate of curvature. Even under the largest temporal delays where visual and <b>haptic</b> information were clearly disparate, the presentation of visual information influenced the <b>haptic</b> perception of curvature. The uncertainty associated with the unimodal vision condition was smaller than that in the unimodal <b>haptic</b> condition, regardless of whether the <b>haptic</b> information was procured actively or under robot assistance for curvature detection. When both visual and <b>haptic</b> information were available, the uncertainty was not reduced; it was equal to that of the unimodal <b>haptic</b> condition. The weighting of the visual and <b>haptic</b> information was highly variable across subjects with some subjects making judgments based largely on <b>haptic</b> information, while others tended to rely on visual information equally or to a larger extent than the <b>haptic</b> information...|$|R
40|$|This paper {{presents}} {{design and}} testing of a <b>haptic</b> keypad system using an array of <b>haptic</b> actuators. The research goals are to construct a prototype <b>haptic</b> keypad system using <b>haptic</b> actuators and to evaluate {{the performance of the}} prototype keypad for <b>haptic</b> rendering. To this end, an MR <b>haptic</b> actuator was designed and fabricated such that it can convey realistic force feedback to users. To demonstrate <b>haptic</b> applications of the MR actuator, a <b>haptic</b> keypad system was constructed, which consists of following components: (1) 3 × 3 array of <b>haptic</b> actuators, (2) 3 × 3 array of force sensing resistors (FSR), (3) a controller including a micro-processor, a current amplifier and a wireless communication module, (4) a graphic display unit with PC. After constructing a prototype keypad system, a <b>haptic</b> rendering technology was employed to interface the hardware keypad system with test software (virtual environment). The prototype system enabled human operators to interact with the target contents in a virtual environment more intuitively. The evaluation results show a feasibility of applications of MR fluids-based <b>haptic</b> actuators in real-world mobile applications...|$|R
40|$|We {{describe}} key affordances {{required by}} tools for developing <b>haptic</b> behaviors. <b>Haptic</b> icon design involves the envisioning, expression and iterative modification of <b>haptic</b> behavior representations. These behaviors are then rendered on a <b>haptic</b> device. For example, a sinusoidal force vs. position representation rendered on a <b>haptic</b> knob would produce {{the feeling of}} detents. Our contribution is twofold. We introduce a custom <b>haptic</b> icon prototyper that includes novel interaction features, and we then use the lessons learnt from its development plus our experiences {{with a variety of}} <b>haptic</b> devices to present and argue high-level design choices for such prototyping tools in general...|$|R
5000|$|European Space Agency Series of {{ergonomic}} exoskeletons for robotic teleoperation. The EXARM, X-Arm-2 and SAM exoskeletons of the ESA Telerobotics & <b>Haptics</b> Laboratory.|$|E
50|$|The EM30, {{releasing}} in August 2008, was the lower-end {{version of}} the E8 (see above), without the FastScroll navigation wheel and the <b>haptics</b> feel.|$|E
5000|$|... : {{contains}} {{a variety of}} nerve endings that react to heat and cold, touch, pressure, vibration, and tissue injury; see somatosensory system and <b>haptics.</b>|$|E
40|$|<b>Haptic</b> {{technology}} {{has the potential}} to enhance education, especially for those with severe visual impairments (those that are blind or who have low vision), by presenting abstract concepts through the sense of touch. Despite the advances in <b>haptic</b> research, little research has been conducted in the area of <b>haptic</b> user behavior toward the establishment of <b>haptic</b> interface development and design conventions. To advance <b>haptic</b> research closer to this goal, this study examines <b>haptic</b> user behavior data collected from 9 participants utilizing a <b>haptic</b> learning system, the Heat Temperature Module. ANOVA results showed that differences in the amount of <b>haptic</b> feedback result in significant differences in user behavior, indicating that higher levels of <b>haptic</b> friction feedback result in higher user interaction proportions of data. Results also suggested that minimal thresholds of friction <b>haptic</b> feedback can be established for a desired level of minimum user interaction data proportions, however; {{more research is needed to}} establish such thresholds...|$|R
50|$|A <b>haptic</b> suit (also {{known as}} tactile suit, gaming suit or <b>haptic</b> vest) is a {{wearable}} device that provides <b>haptic</b> {{feedback to the}} body.|$|R
40|$|Recent {{research}} in <b>haptic</b> systems {{has begun to}} focus on the generation of textures to enhance <b>haptic</b> simulations. Synthetic texture generation can be achieved through the use of stochastic modeling techniques to produce random and pseudo-random texture patterns. These models are based on techniques used in computer graphics texture generation and textured image analysis and modeling. The goal for this project is to synthesize <b>haptic</b> textures that are perceptually distinct. Two new rendering methods for <b>haptic</b> texturing are presented for implementation of stochastic based texture models using a 3 DOF point interaction <b>haptic</b> interface. The synthesized textures {{can be used in a}} myriad of applications, including <b>haptic</b> data visualization for blind individuals and overall enhancement of <b>haptic</b> simulations. Keywords: <b>haptic,</b> synthetic texture, stochastic models, visualization 1. INTRODUCTION <b>Haptic</b> rendering involves the computation of forces to be generated by a force-reflecting interface [...] ...|$|R
