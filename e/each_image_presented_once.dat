0|10000|Public
30|$|Table 1 {{summarizes}} the SNR of <b>each</b> of the <b>images</b> <b>presented</b> in Figures 7 and 8.|$|R
40|$|For the Sixth Annual Machine Learning for Signal Processing competition, {{sponsored}} by Nokia and PASCAL 2, entrants {{were asked to}} develop a classifier, with optional feature extraction, that uses electroencephalography (EEG) data collected during an image presentation (visual oddball) task and optimally determines whether <b>each</b> <b>image</b> <b>presented</b> to a user contains or does not contain a pre-specified target. In this paper, we (the organizers of the competition) briefly describe the application, the data, the rules, and the outcomes of the competition. A total of 35 teams entered the contest. Training data were provided. The entries were tested using disjoint test data. The three teams with the best performing entries describe the approach they used in three separate companion papers, all of which appear in this year’s conference proceedings. 1...|$|R
40|$|International audienceThis article {{presents}} a method aiming at quantifying the visual similarity between two images. This {{kind of problem}} is recurrent in many applications such as object recognition, image classification, etc. In this paper, we propose to use self-organizing feature maps (SOM) to measure image similarity. To reach this goal, we feed local signatures associated to salient patches into the neural network. At {{the end of the}} learning step, each neural unit is tuned to a particular local signature prototype. During the recognition step, <b>each</b> <b>image</b> <b>presented</b> to the network generates a neu-ral map that can be represented by an activity histogram. Image similarity is then computed by a quadratic distance between histograms. This scheme offers very promising results for image classification with a percentage of 84. 47 % of correct classification rates...|$|R
30|$|A desired {{feature of}} the {{visualization}} scheme is that all information concerning a movement direction be presented in a single <b>image.</b> Thus <b>each</b> <b>image</b> must <b>present</b> information about the orientation {{and the intensity of}} the velocity component. The color coding scheme is therefore defined as following: for each component, the color assigned to a voxel indicates the orientation of the movement, being either positive or negative, and the strength of the color indicates the intensity of the velocity vector in this direction.|$|R
40|$|Abstract—Content based image {{retrieval}} (CBIR) is {{a technique}} in which images are indexed by extracting their low level features or high level features or both. This paper presents performance & comparative study of the result obtained by the two different approaches of CBIR system. The resultant retrieved images by the CBIR system is based on two approaches. Both approaches of the system using two major processes one as feature extraction and other as search and retrieval. The first approach is based on extracting the features using binary tree structure, color & texture and the second approach is based on extracting shape features using Canny Edge Detection. In both the approaches the feature vector of the query image is compared with the feature vector of the <b>each</b> <b>image</b> <b>present</b> in the database. In the first approach the images are retrieved and arranged according to their matching score or rank value {{and in the second}} approach retrieved images are arranged according to their mean and correlation values. Keywords-Binary tree structure, Content Based Image Retrieval, canny edge detection, Mean, Correlation...|$|R
40|$|A very concise {{comparison}} {{technique for}} objective image quality assessment is described. The method {{is based on}} a angular edge coeherence measure defined by local image expansion into a set of harmonic angular functions. Using the angular edge coherence it is possible to estimate the relative quality of a reproduced image with respect to the original one comparing only the values of a single statistical index disjointly extracted from <b>each</b> <b>image.</b> The <b>present</b> contribution briefly illustrates the mathematical support of this technique and provides some significant experimental examples...|$|R
40|$|In the {{presence}} of ambiguous visual stimuli, cortical neu-rons will exhibit rivalry, normalization or winner-take-all dynamics. Binocular rivalry describes the oscillation of image perception that occurs when a different <b>image</b> is <b>presented</b> to <b>each</b> eye simultaneously [1]. However, rivalry only occurs if the two images are spatially co-localized. If the images are spatially separated then the neural activity will exhibit normalization, where the activity of a neuron is a sub-linear sum of the activities when <b>each</b> <b>image</b> is <b>presented</b> separately. Population rate models can repro-duce the these three phases [2] and phase transitions occur under changes in the mutual inhibition strength between neurons. Measured neuronal activity that is most strongly corre-lated with the observed percept is generally located i...|$|R
40|$|Basic {{procedures}} used in compositing photographic images {{to increase their}} information content are briefly discussed. A new method for calculating exposure time for <b>each</b> <b>image</b> is <b>presented.</b> A portion of the density coordinate of the characteristic curve of the film on which the exposures are to be made is divided into as many divisions as there are images to be superimposed. Lines are drawn from the intersections of these density increments with the characteristic curve to the log exposure for <b>each</b> <b>image.</b> A study of the ability of workers to superimpose plant images with a projected scale of one arcsec per millimeter has shown that image smearing due to alignment errors in a composite will not exceed about 0. 15 arcseconds if images are composited by an adept operator...|$|R
5000|$|In a 2013 article {{published}} by the Film Society of Lincoln Center, Erik Luers wrote of the film: [...] "The technical qualities of Let's Scare Jessica to Death are superb. With gorgeous cinematography and an audio track that takes {{on a life of}} its own, <b>each</b> sound and <b>image</b> <b>presents</b> a hazy version of reality. As the plot develops, we learn that the world around Jessica is scarier than anything her mind could concoct." ...|$|R
40|$|Increased {{pornography}} use {{has been}} a feature of contemporary human society, with technological advances allowing for high speed internet and relative ease of access via a multitude of wireless devices. Does increased pornography exposure alter general emotion processing? Research {{in the area of}} pornography use is heavily reliant on conscious self-report measures. However, increasing knowledge indicates that attitudes and emotions are extensively processed on a non-conscious level prior to conscious appraisal. Hence, this exploratory study aimed to investigate whether frequency of pornography use has an impact on non-conscious and/or conscious emotion processes. Participants (N = 52) who reported viewing various amounts of pornography were presented with emotion inducing images. Brain Event-Related Potentials (ERPs) were recorded and Startle Reflex Modulation (SRM) was applied to determine non-conscious emotion processes. Explicit valence and arousal ratings for <b>each</b> <b>image</b> <b>presented</b> were also taken to determine conscious emotion effects. Conscious explicit ratings revealed significant differences with respect to “Erotic” and “Pleasant” valence (pleasantness) ratings depending on pornography use. SRM showed effects approaching significance and ERPs showed changes in frontal and parietal regions of the brain in relation to “Unpleasant” and “Violent” emotion picture categories, which did not correlate with differences seen in the explicit ratings. Findings suggest that increased pornography use appears to have an influence on the brain’s non-conscious responses to emotion-inducing stimuli which was not shown by explicit self-report...|$|R
30|$|In object {{description}} with color, {{it could be}} possible to use different color space such as RGB (Red, Green, Blue) or HIS (Hue, Intensity, Saturation). Each of these color space has a three components. In the color space RGB, <b>each</b> <b>image</b> pixel will <b>present</b> with combination of three main color components Red (R), Green (G), and Blue (B). In HIS color space, each pixel will split into Hue (H), Intensity (I), and Saturation (S) components. Description of object with color histogram clearly specifies the location of object in <b>each</b> frame of <b>image</b> sequences.|$|R
30|$|Two ‘wisdom of crowds’ {{analyses}} were carried out, first by sampling {{teams from the}} entire group (n[*]=[*] 95), and another that sampled from participants who achieved an average score of above one standard deviation on session one face tests (n[*]=[*] 17). By comparing performance of selected and unselected teams we aimed to examine the combined effect of selecting high performers and aggregating their responses. For each analysis, we randomly sampled n participants and averaged their responses for <b>each</b> <b>image</b> pair <b>presented</b> in the FR-Task separately. This sampling procedure was repeated 1000 times for each value of n (2 to 12) and accuracy was computed at each iteration by calculating the group AUC, Hit rate and False Alarm rate. Aggregate accuracy for a given sample size was measured as the average performance across all iterations.|$|R
40|$|Abstract- Digital {{mammography}} allows {{detection of}} breast abnormalities {{in early stage}} of breast cancer development. One of the abnormalities that may indicate breast cancer in its early stage is bilateral asymmetry. This paper presents computer-aided detection algorithm for bilateral asymmetry that uses B-spline interpolation for breast alignment. Alignment of {{the right and left}} breast is important step in computer-aided detection algorithm in order to allow comparison of corresponding points in right and left breast. Differential analysis of breasts is based on simple subtraction technique. The results are highlighted with color in <b>each</b> <b>image</b> and <b>presented</b> on a computer monitor thereby indicating radiologist the regions that need to have a second look and be further investigated. We found that our approach can be a very useful tool for radiologists in detection and diagnosis of bilateral asymmetry...|$|R
40|$|This article {{presents}} a method aiming at quantifying the visual similarity between an image and a class model. This {{kind of problem}} is recurrent in many applications such as object recognition, image classification, etc. In this paper, we propose to label a Self-Organizing Map (SOM) to measure image similarity. To manage this goal, we feed local signatures associated to the regions of interest into the neural network. At {{the end of the}} learning step, each neural unit is tuned to a particular local signature prototype. During the labeling process, <b>each</b> <b>image</b> signature <b>presented</b> to the network generates an activity vote for its referent neuron. Facial recognition is then performed by a probabilistic decision rule. This scheme offers very promising results for face identification dealing with illumination variation and facial poses and expressions. 1...|$|R
40|$|Quantifying {{attention}} to social stimuli during the viewing of complex social scenes with eye tracking {{has proven to}} be a sensitive method in the diagnosis of autism spectrum disorders years before average clinical diagnosis. Rhesus macaques provide an ideal model for understanding the mechanisms underlying social viewing behavior, but to date no comparable behavioral task has been developed for use in monkeys. Using a novel scene-viewing task, we monitored the gaze of three rhesus macaques while they freely viewed well-controlled composed social scenes and analyzed the time spent viewing objects and monkeys. In each of six behavioral sessions, monkeys viewed a set of 90 images (540 unique scenes) with <b>each</b> <b>image</b> <b>presented</b> twice. In two-thirds of the repeated scenes, either a monkey or an object was replaced with a novel item (manipulated scenes). When viewing a repeated scene, monkeys made longer fixations and shorter saccades, shifting from a rapid orienting to global scene contents to a more local analysis of fewer items. In addition to this repetition effect, in manipulated scenes, monkeys demonstrated robust memory by spending more time viewing the replaced items. By analyzing {{attention to}} specific scene content, we found that monkeys strongly preferred to view conspecifics and that this was not related to their salience in terms of low-level image features. A model-free analysis of viewing statistics found that monkeys that were viewed earlier and longer had direct gaze and redder sex skin around their face and rump, two important visual social cues. These data provide a quantification of viewing strategy, memory and social preferences in rhesus macaques viewing complex social scenes, and they provide an important baseline with which to compare to the effects of therapeutics aimed at enhancing social cognition...|$|R
40|$|An {{image-based}} 3 D surface reconstruction technique {{based on}} simultaneous evaluation of reflectance and polarisation features is introduced in this paper. The proposed technique {{is suitable for}} single and multi-image (photopolarimetric stereo) analysis. It is especially suited for {{the difficult task of}} 3 D reconstruction of rough metallic surfaces with non-Lambertian reflectance. The reflectance and polarisation properties are used to determine the surface gradients individually for <b>each</b> <b>image</b> pixel. The <b>presented</b> multi-image technique is invariant to variations of the surface albedo. We evaluate our algorithm based on synthetic ground truth data as well as on a raw forged iron surface. The results we obtain for the real world example demonstrate the applicability of our method in the domain of industrial quality inspection. ...|$|R
40|$|My {{thesis is}} an {{exploration}} of my dual desires of creation/destruction and manipulation/transformation as realized through the remediation of botanical specimens gathered from my domestic environment and transformed into works of art. <b>Each</b> <b>image</b> questions and <b>presents</b> {{an understanding of the}} history of botanical representation, within Western art history, as symbols of nature and femininity and the domestic skill of needlework, a traditional skill learned by women as part of the feminine. I created a conceptual dialogue with those who preceded me, intrinsically linking the acts of sewing and botany as re-interpreted feminist acts. In this work, I attempt to reveal connections between the physical transformation of the plants and the historical bind of femininity. Thread is utilized symbolically to represent the weight and impact of the history of women...|$|R
40|$|Abstract—Segmenting {{the lungs}} in medical images is a {{challenging}} and important task for many applications. In particular, automatic segmentation of lung cavities from multiple magnetic resonance (MR) images is very useful for oncological {{applications such as}} radiotherapy treatment planning. However, distinguishing of the lung areas is not trivial due to largely changing lung shapes, low contrast and poorly defined boundaries. In this paper, we address lung segmentation problem from pulmonary magnetic resonance images and propose an automated method based on a robust regionaided geometric snake with a modified diffused region force into the standard geometric model definition. The extra region force gives the snake a global complementary view of the lung boundary information within the image which along with the local gradient flow, helps detect fuzzy boundaries. The proposed method {{has been successful in}} segmenting the lungs in every slice of 30 magnetic resonance images with 80 consecutive slices in <b>each</b> <b>image.</b> We <b>present</b> results by comparing our automatic method to manually segmented lung cavities provided by an expert radiologist and with those of previous works, showing encouraging results and high robustness of our approach. Keywords—Active contours, breast cancer, fuzzy c-means segmentation, treatment planning. I...|$|R
40|$|Abstract. We {{investigate}} {{models for}} content-based image retrieval with relevance feedback, in particular {{focusing on the}} exploration-exploitation dilemma. We pro-pose quantitative models for the user behavior and investigate implications of these models. Three search algorithms for efficient searches based on the user models are proposed and evaluated. In the first model a user queries a database for the most (or a sufficiently) relevant image. The user gives feedback to the system by selecting the most relevant image {{from a number of}} <b>images</b> <b>presented</b> by the system. In the second model we consider a filtering task where relevant images should be extracted from a database and presented to the user. The feedback of the user is a binary clas-sification of <b>each</b> <b>presented</b> <b>image</b> as relevant or irrelevant. While these models are related, they differ significantly in the kind of feedback provided by the user. This requires very different mechanisms to trade off exploration (finding out what the user wants) and exploitation (serving images which the system believes relevant for the user). ...|$|R
40|$|This Master's Thesis {{reports on}} the {{experiences}} of Type 2 Diabetes of Lesbian, Queer, and Women-Loving Women. The thesis examines the impact of sexual orientation on experiences with diabetes, and how this chronic disease affects the way a woman views herself, her health, and her body <b>image.</b> <b>Each</b> participant <b>presented</b> her narrative and world views in regards to her diabetes health care and management, stress and trauma, and management of relationships. Through narrative analysis, I have revealed differing mechanisms of coping and explanatory models; the many women of this study selectively chose to be more open about her sexual orientation than her diabetes status...|$|R
40|$|We {{present the}} two-user Responsive Workbench: a projectionbased virtual reality {{system that allows}} two people to {{simultaneously}} view individual stereoscopic image pairs from their own viewpoints. The system tracks the head positions of both users and computes four images - one for each eye of each person. To display the four images as two stereo pairs, we must ensure <b>each</b> <b>image</b> is correctly <b>presented</b> to the appropriate eye. We describe a hardware solution to this display problem as well as registration and calibration procedures. These procedures ensure that when two users point to the same location on a virtual object, their fingers will physically touch. Since the stereo pairs are independent, we {{have the option of}} displaying specialized views of the shared virtual environment to each user. We present several scenarios in which specialized views might be useful. CR Categories and Subject Descriptors: I. 3. 7 [Computer graphics]: Virtual Reality, I. 3. 1 [Computer graphics]: ThreeDimensi [...] ...|$|R
40|$|AbstractThe Block Truncation Coding (BTC) {{is one of}} the lossy image {{compression}} algorithm in which first and second order moments are preserved in <b>each</b> <b>image</b> block. The <b>present</b> work investigates <b>image</b> compression based on Absolute Moment Block Truncation Coding (AMBTC) and Clifford Algebra. Here we develop a technique to express a positive integer as a sum of largest perfect square of positive integer. The largest square is computed from the given integer, and then the same process is repeated from the residual part of the integer successively. The proposed method gives very good performance in terms of PSNR values when compared to the conventional BTC and AMBTC. To assess image quality some parametric measures bring into service such as: Peak Signal to Noise Ratio (PSNR), Weighted Peak Signal to Noise Ratio (WPSNR), Bit Rate (BR), and Structural SIMilarity Index (SSIM). The comparative result shows that proposed algorithm is the better than BTC and AMBTC...|$|R
30|$|Haxby dataset {{contains}} the fMRI scans of 6 subjects. The experiment has 12 trials, {{each of which}} lasts for about 24 s, separated by rest periods (see Fig.  1 b). In <b>each</b> trial, 8 <b>images</b> <b>presenting</b> 8 types of objects including houses, human faces, cats, and so on. Images were shown on the screen for 500 ms of each; the inter-stimulus interval is 1500 ms. The entire experiment was then partitioned into 12 × 8 = 96 samples from each individual with only one trial removed from subject 5 who was corrupted during this trial. The fMRI scans were collected in a space of 40 × 64 × 64 voxels, corresponding to a voxel size of 3.5 × 3.75 × 3.75 mm^ 3, and a volume repetition time of 2.5 s [4]. Similarly, instead of examining the whole brain, our study {{is focused on the}} visual cortex area which consists of up to 675 voxels based on the anatomical information of our subjects.|$|R
40|$|Reconstructions {{of digital}} {{holograms}} {{have a very}} shallow depth of focus. In order to obtain a perceptually greater depth of focus, we explored a computationally simple approach, suggested by Lehtimäki and Naughton [3 DTV Conference 2007; IEEE Press, New York (Kos, Greece) ], where the perceptual depth of focus is obtained by dichoptic viewing of near focused and far focused holographic reconstructions. In the dichoptic viewing arrangement one eye sees a near focused {{and the other a}} far focused image. Because of binocular fusion we see a blend of the two images, in which the perceptual sharpness is far more uniform than in <b>each</b> of the <b>images</b> alone. In this experiment, we sought an {{answer to the question of}} to what extent does <b>each</b> dichoptically <b>presented</b> <b>image</b> contribute to the perceived sharpness of the binocularly fused imag...|$|R
50|$|A visual {{comparison}} {{is to compare}} two or more things by eye. This might be done by placing them side by side; by overlaying them; by alternating an <b>image</b> or by <b>presenting</b> <b>each</b> <b>image</b> to a separate eye.|$|R
40|$|Abstract. The {{characteristic}} (or intrinsic) {{scale of}} a local image pattern is the scale parameter at which the Laplacian provides a local maximum. Nearly every position in an image will exhibit {{a small number of}} such characteristic scales. Computing a vector of Gaussian derivatives (a Gaussian jet) at a characteristic scale provides a scale invariant feature vector for tracking, matching, indexing and recognition. However, the computational cost of directly searching the scale axis for the characteristic scale at <b>each</b> <b>image</b> position can be prohibitively expensive. We describe a fast method for computing a vector of Gaussian derivatives that are normalised to the characteristic scale at each pixel. This method is based on a scale equivariant half-octave binomial pyramid. The characteristic scale for each pixel is determined by an interpolated maximum in the Difference of Gaussian as a function of scale. We show that interpolation between pixels across scales can be used to provide an accurate estimate of the intrinsic scale at <b>each</b> <b>image</b> point. We <b>present</b> an experimental evaluation that compares the scale invariance of this method to direct computation using FIR filters, and to an implementation using recursive filters. With this method we obtain a scale normalised Gaussian Jet at video rate for a 1 / 4 size PAL image on a standard 1. 5 Ghz Pentium workstation. ...|$|R
40|$|Abstract- The {{need for}} {{content-based}} image retrieval has increased with increment size and volume of digital images. This paper introduces the graph-based approach {{in order to}} retrieve the content-based image. In the proposed method, an <b>image</b> <b>presents</b> {{by a set of}} regions, while comparison of <b>images</b> are posing, <b>each</b> <b>image</b> represents by a graph, hence the estimation of the region correspondence transform into an graph matching problem. In addition, by using and image distance criteria, the difference between images obtained. Experimental results show that the proposed graph-theoretic image matching performance is acceptable...|$|R
40|$|This paper {{presents}} {{an approach to}} model content based metasearch engine which search all the content related <b>images</b> <b>present</b> in the dataset. Searching through the keywords in an image database {{require a lot of}} Meta data (keywords about the image) to be stored for <b>each</b> <b>image</b> in a separate database. This does not lead to an effective search mechanism. This mechanism basically works for the relevant output for the input query image. The process based on the image extraction by the implemented functions like “edge histogram”, “image feature extraction i. e. sharpness, smoothness, color etc...|$|R
40|$|An image {{matching}} system {{specifically designed}} to match dissimilar images is described. A set of blobs and ribbons is first extracted from <b>each</b> <b>image,</b> and then generalized Hough transform techniques are used to match these sets and compute the transformation that best registers the image. An example of {{the application of the}} approach to one pair of remotely sensed <b>images</b> is <b>presented...</b>|$|R
30|$|Each {{unfamiliar}} viewer rated 12 different {{images of}} 12 different people (144 <b>images</b> <b>presented</b> individually {{in a random}} order). This method resulted in a pre-determined sample size of 20 raters per image that was considered sufficient to provide a stable estimate of trait impressions (see Oosterhof & Todorov, 2008). Viewers were instructed to rate how attractive, trustworthy, dominant, confident, and competent the person appeared in <b>each</b> <b>image</b> {{on a scale from}} 1 (very low) to 9 (very high). These five ratings were made on separate rating scales and scales were presented concurrently on the same screen as the photos.|$|R
40|$|Clinical {{radiological}} {{judgments are}} increasingly being made on softcopy LCD monitors. These monitors are found throughout the hospital environment in radiological reading rooms, outpatient clinics and wards. This means that ambient lighting where clinical judgments from images are made can vary widely. Inappropriate ambient lighting has several deleterious effects: monitor reflections reduce contrast; veiling glare adds brightness; dynamic range and detectability of low contrast objects is limited. Radiological images displayed on LCDs are {{more sensitive to the}} impact of inappropriate ambient lighting and with these devices problems described above are often more evident. The current work aims to provide data on optimum ambient lighting, based on lesions within chest images. The data provided may be used for the establishment of workable ambient lighting standards. Ambient lighting at 30 cms from the monitor was set at 480 Lux (office lighting) 100 Lux (WHO recommendations), 40 Lux and < 10 Lux. All monitors were calibrated to DICOM part 14 GSDF. Sixty radiologists were presented with 30 chest images, 15 images having simulated nodular lesions of varying subtlety and size. Lesions were positioned in accordance with typical clinical presentation and were validated radiologically. <b>Each</b> <b>image</b> was <b>presented</b> for 30 seconds and viewers were asked to identify and score any visualized lesion from 1 - 4 to indicate confidence level of detection. At the end of the session, sensitivity and specificity were calculated. Analysis of the data suggests that visualization of chest lesions is affected by inappropriate lighting with chest radiologists demonstrating greater ambient lighting dependency. JAFROC analyses are currently being performed...|$|R
40|$|In {{this paper}} we present new {{observations}} of the gravitational lens system JVAS B 0218 + 357 made with a global very long baseline interferometry (VLBI) network at a frequency of 8. 4 GHz. Our maps have an rms noise of 30 muJy beam(- 1) and with these {{we have been able}} to image much of the extended structure of the radio jet in both the A and B images at high resolution (similar to 1 mas). The main use of these maps will be to enable us to further constrain the lens model for the purposes of H-o determination. We are able to identify several subcomponents common to both images with the expected parity reversal, including one which we identify as a counter-jet. We have not been successful in detecting either the core of the lensing galaxy or a third image. Using a model of the lensing galaxy we have back-projected both of the images to the source plane and find that they agree well. However, there are small, but significant, differences which we suggest may arise from multi-path scattering in the interstellar medium (ISM) of the lensing galaxy. We also find an exponent of the radial mass distribution of beta approximate to 1. 04, in agreement with lens modelling of published 15 -GHz VLBI data. Polarization maps of <b>each</b> <b>image</b> are <b>presented</b> which show that the distributions of polarization across images A and B are different. We suggest that this results from Faraday rotation and associated depolarization in the lensing, galaxy...|$|R
40|$|Image {{sequence}} analysis for 3 -D modeling is an aim of primary importance in Photogrammetry and Computer Vision. Both disciplines approach this issue, but with different procedures. The {{result is the}} reconstruction of a 3 -D model of the captured object featuring different characteristics in terms of accuracy and time needed to built it up. The goal of this work is the implementation of an algorithm which is capable of computing the orientation parameters of an image sequence in an automatic way. Input elements are the calibration parameters of the camera and the images. Particular attention must be paid during the sequence acquisition: <b>each</b> <b>image</b> must <b>present</b> a good overlap with the next images. The algorithm makes use of computer vision and photogrammetric techniques in an integrated approach for the sequence processing, {{in order to obtain}} the exterior orientation parameters and the 3 -D coordinates of the automatically matched points. The main advantage of a combined use of the methods of both these disciplines is the possibility to solve some typical problems of one with the other, and vice versa. The process starts with the automatic matching between image triplets by using a feature based matching followed by blunder removal through robust estimation methods of the camera poses. Then a progressive resection alternated to triangulation is carried out to join to the first triplet some further images belonging to other triplets. This task is performed by applying a “Structure & Motion ” technique based on collinearity equations. The developed algorithm has been successfully tested with synthetic and real data. 1...|$|R
40|$|Faces {{are special}} to infants. Infants look longer at faces than objects, human faces than {{non-human}} faces, and upright faces compared to inverted faces. The {{objective of this}} study was to see if infants demonstrated signs of pareidolia. Pareidolia is the ability to see a face in a non-face object, such as a face in a cloud. Previous research has shown that adults see faces in everyday objects, but less is known about infants 2 ̆ 7 perception of such <b>images.</b> In the <b>present</b> study, infants 7 - 9 months old (N = 47) were tested. Infants were shown eight images, which adults had ordered from most face-like to least face-like, over 16 trials. An upright and inverted version of <b>each</b> <b>image</b> was <b>presented</b> side by side to infants on each trial. Infants’ looking times to each side was recorded. It was reasoned that infants would show a reliable preference for the upright version of a stimulus if they perceived a face in that stimulus. It was found that infants showed an upright preference for three of the eight stimuli, two that were deemed most face-like (i. e., a color photo of a female face, and a black and white schematic face) and one grouped as moderately face-like (i. e., a black and white Mooney image that could be perceived as either a face or a man playing a saxophone). From these results, we conclude that infants can perceive a face, but only in images that are the most face-like. The results suggest that infants may experience some form of pareidolia but not to the same extent as adults do. Future studies should further investigate the development of pareidolia infants and children...|$|R
40|$|Binocular rivalry is an {{extraordinary}} visual phenomenon that has engaged investigators for centuries. Since its first report, there has been vigorous debate over how the brain achieves the perceptual alternations that occur when conflicting <b>images</b> are <b>presented</b> simultaneously, one to each eye. Opposing high-level/stimulus-representation models and low-level/eye-based models have been proposed to explain the phenomenon, recently merging into an amalgam view. Here, we provide evidence that during viewing of Dı´az-Caneja stimuli, coherence rivalry—in which aspects of <b>each</b> eye’s <b>presented</b> <b>image</b> are perceptually regrouped into rivalling coherent images—and eye rivalry operate via discrete neural mechanisms. We demonstrate that high-level brain activation by unilateral caloric vestibular stimulation shifts the predominance of perceived coherent images (coherence rivalry) but not half-field images (eye rivalry). This finding suggests that coherence rivalry (like conventional rivalry according to our previous studies) is mediated by interhemispheric switching at a high level, while eye rivalry is mediated by intrahemispheric mechanisms, most likely at a low level. Based on the present data, we further propose that Dı´az-Caneja stimuli induce ‘meta-rivalry’ whereby the discrete high- and low-level competitive processes themselves rival for visual consciousness...|$|R
40|$|Binocular rivalry (BR) is an {{intriguing}} phenomenon in which conflicting <b>images</b> are <b>presented,</b> one to each eye, resulting in perceptual alternations between <b>each</b> <b>image.</b> The rate of BR {{has been proposed}} as a potential endophenotype for bipolar disorder because (a) it is well established that this highly heritable psychiatric condition is associated with slower BR rate than in controls, and (b) an individual 2 ̆ 7 s BR rate is approximately 50...|$|R
