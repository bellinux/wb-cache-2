12|24|Public
50|$|PacketSquare-CapEdit {{works by}} <b>editing</b> <b>protocol</b> {{fields of the}} saved packet capture file and replaying. In {{addition}} to editing and replaying it supports many features for extrapolation of captured traffic.|$|E
5000|$|A {{dedicated}} server called Sobby is also provided, {{together with}} a script which could format saved sessions for the web (e.g. to provide logs of meetings with a collaboratively prepared transcript). The collaborative <b>editing</b> <b>protocol</b> is named Obby, {{and there are other}} implementations that use this protocol (e.g. Rudel, [...] a plugin for GNU Emacs). Gobby 0.5 replaces Sobby with a new server called infinoted.|$|E
40|$|The Local <b>Editing</b> <b>Protocol</b> {{allows a}} local {{programmable}} terminal {{to execute the}} most common editing commands on behalf of an extensible text editor on a remote system, thus greatly improving speed of response without reducing flexibility. The Line Saving Protocol allows the local system to save text which is not displayed, and display it again later when it is needed, {{under the control of}} the remote editor. Both protocols are substantially system and editor independent...|$|E
5000|$|In June 2003, Sam Ruby {{set up a}} wiki {{to discuss}} what makes [...] "a well-formed log entry". [...] This initial posting acted as a {{rallying}} point. People quickly started using the wiki to discuss a new syndication format to address the shortcomings of RSS. It also {{became clear that the}} new format could form the basis of a more robust replacement for blog <b>editing</b> <b>protocols</b> such as the Blogger API and LiveJournal XML-RPC Client/Server Protocol as well.|$|R
5000|$|Ben Dobie, Avril Mackintosh, and Olle Romo - <b>protocols</b> <b>editing</b> ...|$|R
50|$|MWM is a {{lightweight}} window manager, having robust compliance and {{configuration of the}} features it has. MWM first appeared on in the early-1980s, along with the Motif toolkit. MWM supports: Common User Interface (i.e., Alt-Tab is switch windows, a standard), some International support, Common Desktop Environment, X Resource Database (/home/app-defaults/ and runtime), X Session Manager <b>protocol,</b> X <b>Edited</b> Resource <b>Protocol</b> (<b>edit</b> widget data), desktop icons, optional use of images to decorate, and had supported Virtual desktop (removed since 2.1) but now supports non-virtual desktop panning. MWM is a window manager, not a full desktop environment, so it only manages windows; {{it is expected that}} configuration, programs, sound, are provided by other programs. A plain text file is parsed to customize menus, user input mappings, management features, and user made functions of the same.|$|R
40|$|International audienceThis article first lists {{reasons why}} - {{in the long}} term or when {{creating}} a new knowledge base (KB) for general knowledge sharing purposes - collaboratively building a well-organized KB does/can provide more possibilities, with on the whole no more costs, than the mainstream approach where knowledge creation and re-use involves searching, merging and creating (semi-) independent (relatively small) ontologies or semi-formal documents. The article lists elements required to achieve this and describes the main one: a KB <b>editing</b> <b>protocol</b> that keeps the KB free of automatically/manually detected inconsistencies while not forcing them to discuss or agree on terminology and beliefs nor requiring a selection committee...|$|E
40|$|This article first lists {{reasons why}} - {{in the long}} term or when {{creating}} a new knowledge base (KB) for general knowledge sharing purposes - collaboratively building a well-organized KB does/can provide more possibilities, with on the whole no more costs, than the mainstream approach where knowledge creation and re-use involves searching, merging and creating (semi-) independent (relatively small) ontologies or semi-formal documents. The article lists elements required to achieve this and describes the main one: a KB <b>editing</b> <b>protocol</b> that keeps the KB free of automatically/manually detected inconsistencies while not forcing them to discuss or agree on terminology and beliefs nor requiring a selection committee. Comment: 12 pages, 2 figures, journa...|$|E
40|$|Thesis (M. A., Education (Language and Literacy)) [...] California State University, Sacramento, 2009. The editing {{of writing}} is {{included}} {{as part of}} the writing process; however, this component of the process is problematic and often is not discussed. The editing of writing is often included {{as part of the}} revision process, when in actuality, they are two separate processes. For this reason, students struggle with how to edit which leads to the teacher editing the writing instead of the student. The purpose of the use of an <b>editing</b> <b>protocol</b> is to create independent self-editors during the writing process. Sources of Data 	A pre and post writing assessment was administered to both the experimental and control group. Writing convention errors were calculated on three samples between the pre and post writing assessments for the experimental group. Rubric scores measured improvement in the area of content and conventions. 	A student survey was administered to the experimental group, which consisted of 30 fourth grade students prior to the treatment period {{as well as at the}} conclusion of the treatment to ensure metalinguistic awareness development. Conclusions Reached 	The <b>editing</b> <b>protocol</b> allowed students to edit a peers writing as well as served as a reference tool when composing their own writing. The editing cards enabled students to edit their own work. The editing intervention treatment successfully reduced the number of editing errors in writing conventions in the experimental group. 	The results of the surveys indicated that students see the editing cards as a resource as well as a strategy in producing a well-written piece of writing. Following this intervention students also appeared to have a better, more realistic definition of what it takes to be a good writer and editor. Education (Language and Literacy...|$|E
40|$|Accurate and {{efficient}} genome editing is primarily {{dependent on the}} generation of a sequence-specific, genomic double-stranded DNA break (DSB) combined {{with the introduction of}} an exogenous DNA template into target cells. The exogenous template, called donor DNA, normally contains the foreign sequences flanked by DNA regions sharing sequence identity (“homologous”) to those bracketing the target site. The strategies for mediating the formation of DSBs at the predefined genomic loci, have been undergoing intense investigation since the introduction of sequence-customizable zinc-finger nuclease (ZFN) technology. More recently, prokaryotic protein-based transcription activator-like effector nucleases (TALENs) and RNA-guided nucleases (RGNs) derived from CRISPR-associated protein (Cas 9) complexes have substantially broadened the availability and applicability of designer nuclease-mediated genome editing. A potential alternative research line to the use of designer nucleases, is to investigate whether specific DNA structures can, by themselves, serve as triggers of the DNA damage response and, in doing so, elicit targeted gene repair. Such an approach would simplify genome <b>editing</b> <b>protocols,</b> such as, by reducing the number of reagents needed to be introduced into target cells. In this thesis, the roles of these secondary structures as well as designer nucleases and donor-DNA templates, delivered via adenoviral vectors, is described. Promotor: R. C. Hoeben, Co-Promotor: M. A. F. V. GonçalvesWith Summary in Dutc...|$|R
40|$|The {{existing}} component protocols, {{as well as}} new protocols {{introduced at}} runtime into NPSNET-V are written in their native programming language. As a result, they require authoring and compiling by a trained programmer. The long time frame required to change or introduce new protocols into NPSNET-V, a dynamically extensible virtual environment, detracts from the dynamicism of the virtual environment. Networking optimization thresholds to support NPSNET-V needed to be determined to ensure that the networking is performed efficiently, and system resources to other systems, such as graphics rendering, are maximized. This thesis implements component protocols described using Extensible Markup Language (XML) into NPSNET-V. These protocols are created with different fidelity resolutions for each protocol, which can be swapped at runtime based on the network state. Network testing was performed to find the ideal maximum packet rates based on the impact on CPU utilization and packet loss. By using XML, non-programmers can <b>edit</b> <b>protocols</b> for inclusion in a simulation at runtime. Important contributions include adding protocols to NPSNET-V with high-resolution and low-resolution versions, described by XML documents. Basic network optimization is added to NPSNET-V {{to take advantage of the}} protocolsÎ± resolution switching ability. The network testing revealed a linear correlation between the packet sending rate and CPU utilization, and a polynomial correlation between the packet sending rate and percentage packet loss. US Army (USA) autho...|$|R
40|$|Developmental {{and stem}} cell biology are {{certainly}} two hot topics in nowadays life sciences: Therefore an unrivalled resource, and a fascinating read, on these topics is wellcome. This {{is the case}} of the  Somatic stem cells. Methods and <b>protocols</b> <b>edited</b> by Prof. Shree Ram Singh (mouse cancer genetics program, National Cancer Institute, Frederick, MD, USA) [...] . ...|$|R
40|$|Innovative {{alphanumeric}} data entry and edit procedures {{are required for}} input-output devices that, constrained by size and usage considerations, are limited to functionality available with multi-character and limited function keys. Such an interface {{was developed by the}} authors for Martin Marietta in support of the US Army Single Channel Anti-jam Man-Portable (SCAMP) Program. Two character entry schemes and three message editing protocols were developed and evaluated using a Macintosh-based, Supercard-configured prototype whose conventions were assessed by twelve subjects in a counter-balanced experimental design. One character entry scheme proved to be statistically superior to the other scheme in terms of time and number of keystrokes required, and was universally favored by subjects. Although there was no clearly superior message <b>editing</b> <b>protocol</b> among the three alternatives, one convention was generally favored over the others in terms of performance and ease of operation...|$|E
40|$|Collaborative {{text editing}} systems allow users to {{concurrently}} edit a shared document, inserting and deleting elements (e. g., characters or lines). There {{are a number}} of protocols for collaborative text editing, but so far there has been no precise specification of their desired behavior, and several of these protocols have been shown not to satisfy even basic expectations. This paper provides a precise specification of a replicated list object, which models the core functionality of replicated systems for collaborative text editing. We define a strong list specification, which we prove is implemented by an existing protocol, as well as a weak list specification, which admits additional protocol behaviors. A major factor determining the efficiency and practical feasibility of a collaborative text <b>editing</b> <b>protocol</b> is the space overhead of the metadata that the protocol must maintain to ensure correctness. We show that for a large class of list protocols, implementing either the strong or the weak list specification requires a metadata overhead that is at least linear in the number of elements deleted from the list. The class of protocols to which this lower bound applies includes all list protocols that we are aware of, and we show that one of these protocols almost matches the bound. </p...|$|E
40|$|Just as we {{can work}} with {{two-dimensional}} floor plans to communicate 3 D architectural design, we can exploit reduced-dimension shadows to manipulate the higher-dimensional objects generating the shadows. In particular, {{by taking advantage of}} physically reactive 3 D shadow-space controllers, we can transform the task of interacting with 4 D objects to a new level of physical reality. We begin with a teaching tool that uses 2 D knot diagrams to manipulate the geometry of 3 D mathematical knots via their projections; our unique 2 D haptic interface allows the user to become familiar with sketching, editing, exploration, and manipulation of 3 D knots rendered as projected images on a 2 D shadow space. By combining graphics and collision-sensing haptics, we can enhance the 2 D shadow-driven <b>editing</b> <b>protocol</b> to successfully leverage 2 D penand-paper or blackboard skills. Building on the reduced-dimension 2 D editing tool for manipulating 3 D shapes, we develop the natural analogy to produce a reduced-dimension 3 D tool for manipulating 4 D shapes. By physically modeling the correct properties of 4 D surfaces, their bending forces, and their collisions in the 3 D haptic controller interface, we can support full-featured physical exploration of 4 D mathematical objects {{in a manner that is}} otherwise far beyond the experience accessible to human beings. As far as we are aware, this paper reports the first interactive system with force-feedback that provides “ 4 D haptic visualization ” permitting the user to model and interact with 4 D cloth-like objects...|$|E
40|$|The {{correct and}} timely {{creation}} of systems for coordination of group work {{depends on the}} ability to express, analyze, and experiment with protocols for managing multiple work threads. We presentanevolution of the Trellis model that provides a formal basis for prototyping the coordination structure of a collaboration system. In Trellis, group interaction protocols are represented separately from the interface processes use them for coordination. Since these protocols are interpreted (rather than being compiled into applications), group interactions can be changed as a collaborative task progresses. Changes can be made either by a person <b>editing</b> the <b>protocol</b> specification "on the fly" or by a silent "observation" process that participates in an application solely to perform behavioral adaptations. Trelli...|$|R
40|$|Medical imaging {{can involve}} {{different}} modalities, such as computed tomography (CT), {{magnetic resonance imaging}} (MRI), positron emission tomography (PET), and ultrasound. Each examination generated by these modalities has a set of unique instructions, the imaging protocol, which are imaging parameters determine the signal and contrast for creating a particular medical image. Properly managing imaging protocols is like systemically documenting an instruction handbook, which guarantees the quality of scans by providing the radiologist and technicians with appropriate procedures for a given indication. It also ensures patients’ safety by reducing repeated scans to acquire the desired image information. Radiology Protocols (RP) {{is a company that}} provides an online medical protocol database to improve protocol management. It recently developed RP Import, an imaging protocol import software, to automatically collecting elements from the medical imaging file – Digital Imaging and Communications in Medicine (DICOM) files, and mapping them to the specified protocol database. With the help of RP Import, protocol creation is much faster and eliminates manual definition of the parameters, thus this tool lays the foundation of the further development of imaging protocol management. Radiology Protocols also developed a series of Modality Calculators to assist radiologists and technicians to build or modify imaging protocols as they are needed. These calculators cover most of the essential medical parameter calculations associated with different modalities. By using them, computing specific parameters while <b>editing</b> <b>protocols</b> becomes more convenient, and determining the use and amount of certain medical parameters becomes more precise as well. In summary, RP Import and Modality Calculators are two meaningful tools in protocol management, and they also play very important roles in regulating procedure and dosage during the medical image practice...|$|R
40|$|The {{correct and}} timely {{creation}} of systems for coordination of group work {{depends on the}} ability to express, analyze, and experiment with protocols for managing multiple work threads. We present an evolution of the Trellis model that provides a formal basis for prototyping the coordination structure of a collaboration system. In Trellis, group interaction protocols are represented separately from the interface processes use them for coordination. Since these protocols are interpreted (rather than being compiled into applications), group interactions can be changed as a collaborative task progresses. Changes can be made either by a person <b>editing</b> the <b>protocol</b> specification "on the fly" or by a silent "observation" process that participates in an application solely to perform behavioral adaptations. Trellis uniquely mixes hypermedia browsing with collaboration support. We term this combination a hyperprogram, and we say that a hyperprogram integrates the description of a collaborative t [...] ...|$|R
40|$|A 17 th century private letter, {{written to}} his wife by a sailor who had escaped from a {{shipwreck}} in India, is taken here as a case-study. The idea is to build an argument for the archive search and massive edition of old manuscripts linked to the discourse of ordinary people. Such documentation is {{a useful tool for}} language historians since it belongs to a textual genre different from the literary and institutional data normally available for the study of language change. Cultural historians may likewise fi nd the data useful for the study of creative and destructive tactics practised by ordinary people in everyday life. Finally, the philological treatment of such documentation allows one to ponder the capacity of textual criticism to deal with different texts, different readerships and different modes of publication. This paper also serves to present a research project: CARDS, Cartas Desconhecidas - Unknown Letters, which aims to offer both academic and lay audiences an electronic edition of Portuguese private letters written before 1900. The edition is also a tagged corpus, so that various hypotheses emerging from its reading can be tested, especially concerning the ways ordinary men and women relate to culture, historical time and language issues. The letters are extracted from paper fi les in court archives being screened in an ongoing project. The <b>editing</b> <b>protocol</b> followed is compatible with both human and machine processing, while philological analysis of the texts takes into account the expected interests of different target audiences The documents are also contextualized within the micro-historical setting in which they were originally produced, and labelled with linguistic and historiographical keywords...|$|E
40|$|Making video {{recordings}} of large classroom lectures {{and putting them}} online is increasingly common in distance and blended learning courses. However, {{the best way to}} use lecture video is not well understood. Using long streams of one-way communication is not consistent with best practices in online learning. During lectures, students assume a largely passive role. They think faster than instructors speak, so boredom and daydreaming are common. Yet, when complex or novel ideas are presented, students may have inadequate time to encode, organize, and integrate the input with prior experience. Especially for students with low prior knowledge of the subject being discussed, the lecture is a cognitive and affective roller coaster ride that works at cross purposes with learning. Viewing a lecture that was recorded at an earlier time adds the element of temporal distance from the learning event, and changes the student’s role from participant to spectator. The present study investigated whether learning could be increased and perceptions of difficulty reduced when a captured lecture received a “makeover” before being put online. The makeover consisted of 1) editing the lecture video in accordance with the cognitive theory of multimedia learning; 2) processing the video using best practices for audio/video production; and 3) increasing the video playback speed. The research design for the study was quasiexperimental. The independent variable was captured lecture form (edited or unedited). The dependent variables were learning results for recognition and recall, and perceptions of difficulty. Data analysis employed independent-samples t-tests, multivariate analysis of variance (MANOVA), and repeated-measures MANOVA. Conclusions were that the <b>editing</b> <b>protocol</b> made no significant difference in learning gains for recognition or recall, and did not significantly affect perceptions of difficulty. However, editing did result in a 39 % reduction in the length of the lecture, raising the possibility that such a makeover might allow for faster learning when lecture video is used...|$|E
40|$|Diagrammatic Interaction). For full {{details of}} these languages, {{and of the}} {{underlying}} concepts of diagram elements and diagram viewing in ICD - Edit, the reader is referred to "ICD - <b>Edit's</b> Client-Server <b>Protocol</b> Version 1. 5 " [1] (or to any later version which may have become applicable). 1. 3 Assumptions Imposed by the ADI Protocol The ADI Protocol imports the following assumptions: (a) Client(s) and server(s) both maintain local copies of the shared diagram definition. Up to a point, the ICD - Edit server does this automatically and the `adi' tool does likewise for a Prolog client, but see (c) below. (b) Message receipt requires no confirmation. All incoming messages are commands, but a client may countermand received commands, e. g. a user-deleted node might be re-created by the client along with an apologetic alert composed of nodes. (c) Clients must take precautions to ensure convergence of multiple processes' diagram definitions. The ADI protocol does not ensure that both clie [...] ...|$|R
25|$|A similar {{trial in}} Switzerland {{took place at}} Basel. The Swiss Frontists Alfred Zander and Eduard Rüegsegger {{distributed}} the <b>Protocols</b> (<b>edited</b> by the German Gottfried zur Beek) in Switzerland. Jules Dreyfus-Brodsky and Marcus Cohen sued them for insult to Jewish honor. At the same time, chief rabbi Marcus Ehrenpreis of Stockholm (who also witnessed at the Berne Trial) sued Alfred Zander who contended that Ehrenpreis himself had said that the Protocols were authentic (referring to the foreword of the edition of the Protocols by the German antisemite Theodor Fritsch). On June 5, 1936 these proceedings ended with a settlement.|$|R
40|$|Clinical {{protocols}} {{and guidelines}} {{are widely used}} in the medical domain to improve disease management techniques. Different software systems are in development to support the design and the execution of such guidelines. The bottleneck in the guideline software developing process is {{the transformation of the}} textbased clinical guidelines into a formal representation, which can be used by the execution software. This paper introduces a method and a tool that was designed to provide a solution for that bottleneck. The so-called Guideline Markup Tool (GMT) facilitates the translation of guidelines into a formal representation written in XML. This tool enables the protocol designer to create links between the original guideline and its formal representation and ease the editing of guidelines applying design patterns in the form of macros. The usefulness of our approach is illustrated using GMT to <b>edit</b> Asbru <b>protocols.</b> We performed a usability study with eight participants to examine the usefulness of the GMT and of the Asbru macros, which showed that the proposed approach is very appropriate to author and maintain clinical guidelines...|$|R
30|$|The IAEA-DM <b>protocol</b> (<b>edited</b> 2011) is {{the most}} {{up-to-date}} guidance and is dedicated to digital mammography. The UK/IPEM, EC, IAEA-SF and ACR protocols are well-established documents originally developed for SFM that have been adopted in many countries worldwide. The EC guidelines were updated and an addendum on digital mammography was included [1, 17]. At the date of submission of this paper, {{an updated version of}} the ACR protocol is known to be in progress to include guidance specifically targeted at digital mammography. Also, as per information available on the EUREF website, a revised edition (5 th) of the EC Guidelines is in development [18].|$|R
40|$|In vitro disease {{modeling}} {{based on}} induced {{pluripotent stem cells}} (iPSCs) provides a powerful system to study cellular pathophysiology, especially in combination with targeted genome <b>editing</b> and <b>protocols</b> to differentiate iPSCs into affected cell types. In this study, we established zinc-finger nuclease-mediated genome editing in primary fibroblasts and iPSCs generated from a mouse model for radiosensitive severe combined immunodeficiency (RS-SCID), a rare disorder characterized by cellular sensitivity to radiation and the absence of lymphocytes due to impaired DNA-dependent protein kinase (DNA-PK) activity. Our results demonstrate that gene editing in RS-SCID fibroblasts rescued DNA-PK dependent signaling to overcome radiosensitivity. Furthermore, in vitro T-cell differentiation from iPSCs was employed to model the stage-specific T-cell maturation block induced by the disease causing mutation. Genetic correction of the RS-SCID iPSCs restored T-lymphocyte maturation, polyclonal V(D) J recombination of the T-cell receptor followed by successful beta-selection. In conclusion, we provide proof that iPSC-based in vitro T-cell differentiation is a valuable paradigm for SCID disease modeling, which can be utilized to investigate disorders of T-cell development and to validate gene therapy strategies for T-cell deficiencies. Moreover, this study emphasizes the significance of designer nucleases as a tool for generating isogenic disease models and their future role in producing autologous, genetically corrected transplants for various clinical applications...|$|R
40|$|Edit {{distance}} {{has been}} proven {{to be an important}} and frequently-used metric in many human genomic research, with Similar Patient Query (SPQ) being a particularly promising and attractive exam-ple. However, due to the widespread privacy concerns on revealing personal genomic data, the scope and scale of many novel use of genome edit distance are substantially limited. While the problem of private genomic edit distance has been studied by the research community for over a decade [5], the state-of-the-art solution [30] is far from even close to be applicable to real genome sequences. In this paper, we propose several private <b>edit</b> distance <b>protocols</b> that feature unprecedentedly high efficiency and precision. Our construction is a combination of a novel genomic edit distance ap-proximation algorithm and new construction of private set differ-ence size protocols. With the private edit distance based secure SPQ primitive, we propose GENSETS, a genome-wide, privacy-preserving similar patient query system. It is able to support search-ing large-scale, distributed genome databases across the nation. We have implemented a prototype of GENSETS. The experimental re-sults show that, with 100 Mbps network connection, it would take GENSETS less than 200 minutes to search through 1 million breast cancer patients (distributed nation-wide in 250 hospitals, each hav-ing 4000 patients), based on edit distances between their genomes of lengths about 75 million nucleotides each...|$|R
40|$|Nearly {{ten years}} ago the {{scientific}} community added another discipline to the big –omics family, peptidomics, i. e., “the study of the complement of peptides from a cell, organelle, tissue or organism”. This fact derives from the exceptional capacity to produce data by high-throughput techniques and machines {{that allow us to}} pass from proteomics analysis of complex biological systems to the capacity to resolve their peptides content even at the single cell level. Thus, the time is set to have this Peptidomics: Methods and <b>protocols</b> <b>edited</b> by Mikhail Soloviev. I think the editor did a great job; I was reading a very usefull book, a great collection of protocols (that widely range as for the organisms studied, from Bacteria to Man !) both for those are newcomer potential users, as I am, and for those are already acquiented to [...] ...|$|R
2500|$|The {{selling of}} the <b>Protocols</b> (<b>edited</b> by German antisemite Theodor Fritsch) by the National Front during a {{political}} manifestation in the Casino of Berne on June 13, 1933, {{led to the}} Berne Trial in the Amtsgericht (district court) of Berne, the capital of Switzerland, on October 29, 1934. The plaintiffs (the Swiss Jewish Association and the Jewish Community of Berne) were represented by Hans Matti and Georges Brunschvig, helped by Emil Raas. Working {{on behalf of the}} defense was German antisemitic propagandist Ulrich Fleischhauer. On May 19, 1935, two defendants (Theodore Fischer and Silvio Schnell) were convicted of violating a Bernese statute prohibiting the distribution of [...] "immoral, obscene or brutalizing" [...] texts while three other defendants were acquitted. The court declared the Protocols to be forgeries, plagiarisms, and obscene literature. Judge Walter Meyer, a Christian who had not heard of the Protocols earlier, said in conclusion, ...|$|R
40|$|A {{properly}} performed fiberoptic endoscopic {{evaluation of}} swallowing (FEES®) is comprehensive and time-consuming. Editing times of FEES protocols and attempts for efficiency maximization are unknown. Here, the <b>protocol</b> <b>editing</b> times of completed FEES examinations were determined. The present study reports the time savings and quality gains {{of a newly}} developed documentation system tailored to the FEES standard of Langmore. Four independent examiners analyzed twelve videos of FEES procedures, six without and six with the documentation system. Effectiveness of the documentation system was evaluated according to the times for total evaluation, interpretation, documentation, report writing, and for report completeness. The documentation system reduced editing times and increased report completeness with large effect sizes. Averaged total evaluation time decreased from 42 to 27 min, report completeness increased from 55 to 80 %. The use of the documentation system facilitates and improves {{the assessment of the}} swallowing process...|$|R
40|$|Alice and Bob possess strings x and y {{of length}} m and n {{respectively}} {{and want to}} compute the Levenshtein distance L(x, y) between the strings under privacy and communication constraints. The Levenshtein distance, or edit distance, has a dynamic programming formulation that solves a series of minimumfinding problems. Based on this formulation, there are known symmetric privacy-preserving protocols for the computation of L(x, y), {{in which the two}} parties incur equal protocol overhead. In this work, we propose an asymmetric two-party protocol in which a lightweight client Bob with a string y interacts with a single powerful server Alice containing string x in its database. We present a privacy-preserving minimum-finding protocol based on semantically secure homomorphic functions and additive secret sharing. This protocol is executed repeatedly, to enable private computation of the <b>edit</b> distance. Our <b>protocol</b> supports arbitrary finite insertion/deletion costs and a variety of substitution costs. While Alice requires similar effort as in previous approaches, the advantage is that Bob incurs far fewer ciphertext operations and transmissions, making the protocol well-suited for client-server querying applications...|$|R
40|$|The edit {{distance}} between two strings is the {{minimum number of}} delete, insert, and replace operations needed to convert one string into another. Computational biology tasks such as comparing genome sequences of two individuals rely heavily on the dynamic programming algorithm for computing edit distances {{as well as the}} algorithms for related string-alignment problems. A genome sequence may reveal a lot of sensitive information about an individual. Therefore, it is important to develop methods for analyzing and comparing such sequences that are both cryptographically secure and efficient for practical use. We present several protocols for securely computing the edit {{distance between}} two strings so that the owner of each string does not learn anything about the other string except the <b>edit</b> distance. Our <b>protocols</b> are provably secure in the standard multi-party computation paradigm of modern cryptography. Experimental evaluation of our prototype implementation demonstrates that it can be feasibly applied to strings of up to several hundred characters in length, which is sufficient for many practical scenarios. We also discuss how to generalize our protocol to other problems for which there exist efficient dynamic programming algorithms...|$|R
5000|$|The {{selling of}} the <b>Protocols</b> (<b>edited</b> by German antisemite Theodor Fritsch) by the National Front during a {{political}} manifestation in the Casino of Berne on June 13, 1933, {{led to the}} Berne Trial in the Amtsgericht (district court) of Berne, the capital of Switzerland, on October 29, 1934. The plaintiffs (the Swiss Jewish Association and the Jewish Community of Berne) were represented by Hans Matti and Georges Brunschvig, helped by Emil Raas. Working {{on behalf of the}} defense was German antisemitic propagandist Ulrich Fleischhauer. On May 19, 1935, two defendants (Theodore Fischer and Silvio Schnell) were convicted of violating a Bernese statute prohibiting the distribution of [...] "immoral, obscene or brutalizing" [...] texts while three other defendants were acquitted. The court declared the Protocols to be forgeries, plagiarisms, and obscene literature. Judge Walter Meyer, a Christian who had not heard of the Protocols earlier, said in conclusion, [...] I hope the time will come when nobody will be able to understand how in 1935 nearly a dozen sane and responsible men were able for two weeks to mock the intellect of the Bern court discussing the authenticity of the so-called Protocols, the very Protocols that, harmful as they have been and will be, are nothing but laughable nonsense.|$|R
40|$|The {{main task}} of this bachelor's thesis is to {{simulate}} the routing protocol OLSR (Optimized Link State Routing Protocol) in the OPNET Modeler environment, and to realize a scenario where {{it is possible to}} model protocol functionality and properties. The processing of each simulation is divided into three main parts and they are the description of a situation, configuration and the evaluation of results. In the first scenario there is shown the functionality of the protocol, in the second simulation there are scenarios with the nodes of different movement speed, and in the third simulation the energy requirements of the protocol from the perspective of quantity of the transmitted packets are evaluated. Furthermore, in this thesis there is analyzed the way of implementing the routing protocol OLSR in the OPNET Modeler environment. The implementation structure is divided into three levels: the level of a node, a manager and the routing protocol. At these levels the process models, transitions, code blocks, variables and key codes of functions are processed. Next, there is introduced the possibility of extending the protocol. In order to extent the OLSR protocol, the work focused on supporting services quality. The functions are <b>edited</b> for the <b>protocol</b> to create logs, read out the current transfer speed from the statistics, add it to the created pool and organise writing the logs. The results are evaluated and clearly described. This work provides the theoretical basics: it deals with the primary characteristics of Mobile Ad-hoc networks (MANET), describes in detail the OLSR routing protocol and provides information about the OPNET Modeler simulation environment...|$|R

