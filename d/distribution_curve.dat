676|1285|Public
25|$|In 2007, the {{curricula}} for Chinese and English were revised. The two subjects {{were no longer}} graded along the normal <b>distribution</b> <b>curve</b> but rather by criteria referencing (with {{the exception of the}} highest grade, the 5*). Numerical levels are used instead of the traditional letter grades.|$|E
25|$|From 1989 through 2001, Gauss's portrait, {{a normal}} <b>distribution</b> <b>curve</b> and some {{prominent}} Göttingen buildings were {{featured on the}} German ten-mark banknote. The reverse featured the approach for Hanover. Germany has also issued three postage stamps honoring Gauss. One (no. 725) appeared in 1955 on the hundredth anniversary of his death; two others, nos. 1246 and 1811, in 1977, the 200th anniversary of his birth.|$|E
25|$|Whatever the causes, however, psychoticism {{marks the}} two {{approaches}} apart, as the five factor model contains no such trait. Moreover, psychoticism, unlike {{any of the other}} factors in either approach, does not fit a normal <b>distribution</b> <b>curve.</b> Indeed, scores are rarely high, thus skewing a normal distribution. However, when they are high, there is considerable overlap with psychiatric conditions such as antisocial and schizoid personality disorders. Similarly, high scorers on neuroticism are more susceptible to sleep and psychosomatic disorders. Five factor approaches can also predict future mental disorders.|$|E
40|$|AbstractCardiovascular {{effects are}} {{considered}} frequent during drug safety testing. This investigation aimed {{to characterize the}} pharmacological response of the conscious telemetered rat in vivo model to known cardiovascular active agents. These effects were analyzed using statistical analysis and cloud representation with marginal <b>distribution</b> <b>curves</b> for the contractility index and heart rate as to assess the effect relationship between cardiac variables. Arterial blood pressure, left ventricular pressure, electrocardiogram and body temperature were monitored. The application of data cloud with marginal <b>distribution</b> <b>curves</b> to heart rate and contractility index provided an interesting tactic during the interpretation of drug-induced changes particularly during selective time resolution (i. e. marginal <b>distribution</b> <b>curves</b> restricted to Tmax). Taken together, the present data suggests that marginal <b>distribution</b> <b>curves</b> can be a valuable interpretation strategy when using the rat cardiovascular telemetry model to detect drug-induced cardiovascular effects. Marginal <b>distribution</b> <b>curves</b> could also be considered during the interpretation of other inter-dependent parameters in safety pharmacology studies...|$|R
50|$|Common {{examples}} are parametrized (families of) functions, probability <b>distributions,</b> <b>curves,</b> shapes, etc.|$|R
40|$|During a {{study on}} salt {{intrusion}} in {{the branches of the}} Po river, sevral boreholes were drilled over a relatively small area. Several samples of soil deposited in same sedimentary environment meant that an extensive series of laboratory data could be studied using a statistical approach. In particular, frequency <b>distribution</b> <b>curves</b> relative to 11 geotechinca properties and possible linear regressiona between pairs of the above variables were investigated. Othe properties observed were: high scatter of the data from means values, the general tendency of frequency <b>distribution</b> <b>curves</b> to fit Beta <b>distribution</b> <b>curves,</b> and a strong and statistically significant influence of the liquid limit on other getechnical properties...|$|R
25|$|From {{the decline}} in U.S. birth rates {{starting}} in 1958 {{and the introduction of}} the birth control pill in 1960, the Baby Boomer normal <b>distribution</b> <b>curve</b> is negatively skewed. The trend in birth rates from 1958 to 1961 show a tendency to end late in the decade at approximately 1969, thus returning to pre-WWII levels, with 12 years of rising and 12 years of declining birth rates. Pre-war birth rates were defined as anywhere between 1939 and 1941 by demographers such as the Taeuber's, Philip M. Hauser and William Fielding Ogburn.|$|E
5000|$|... #Caption: Number-fraction <b>distribution</b> <b>curve</b> for linear polymerization. Plot 1, p=0.9600; plot 2, p=0.9875; plot 3, p=0.9950.|$|E
5000|$|... #Caption: Normal <b>distribution</b> <b>curve</b> that {{illustrates}} standard deviations. This illustration {{just has}} the [...] "Wechsler" [...] scale added whereby the scores are scaled {{with a mean}} of 100 and standard deviation of 15.|$|E
50|$|Statistical graphs {{can also}} be generated: bar graphs, line graphs, normal <b>distribution</b> <b>curves,</b> {{regression}} lines.|$|R
40|$|A {{method is}} {{described}} for studying certain {{characteristics of the}} voids contained within a mass of aggregate particles. Measurements have been macle on void cells dissected from single size aggregate systems {{of a variety of}} particle shapes in dense and loose packings. The measurements refer to the critical ratio of occupation and the critical ratio of entrance. From these measurements occupation size <b>distribution</b> <b>curves</b> and entrance size <b>distribution</b> <b>curves</b> can be drawn, analogous to particle size <b>distribution</b> <b>curves.</b> The application of the results to the problem of the design of aggregate gradings to minimum or controlled void content, by pre-mixing or filtration techniques, and of the related problem of segregation of mixed aggregates is discussed. 1...|$|R
40|$|MacLeamy's time-effort <b>distribution</b> <b>curves</b> {{are among}} the most oft-cited sources for {{researchers}} interested in mainstreaming building information modeling (BIM) implementation in the architecture, engineering, and construction (AEC) industry. Succinctly, the curves offer a clever answer to the question: How can BIM benefit AEC processes? However, despite their significant theoretical and practical value, little previous research has been conducted to elaborate the time-effort <b>distribution</b> <b>curves</b> of any real-life projects. This research aims to demystify the time-effort <b>distribution</b> <b>curves</b> through comparison of a representative BIM project and a non-BIM project. Applying a set of innovative approaches, the actual time-effort <b>distribution</b> <b>curves</b> of two public housing construction projects in Hong Kong are produced and analyzed in-depth. The curves vividly show that BIM implementation increases the effort spent at design stage - that is, throughout the architecture and engineering processes - but the extra effort pays off at the building stage. Further, the curves are found to be a useful graphical analytic tool for other purposes, such as adjusting the fee structure among AEC processes and informing improved BIM adoption. postprin...|$|R
50|$|The {{basic curve}} for {{calculation}} is the Gauss error <b>distribution</b> <b>curve.</b> For calculation, an integral {{is necessary to}} determine the expectation of winnings. Only chess results against competitors with a DWZ are taken into account.|$|E
50|$|Because {{the normal}} <b>distribution</b> <b>curve</b> is symmetrical, probabilities for only {{positive}} values of Z are typically given. The user has {{to use a}} complementary operation on the absolute value of Z, as in the example below.|$|E
5000|$|... #Caption: [...] Sketches {{depicting}} surfaces {{with negative}} and positive skew. The roughness trace is on the left, the amplitude <b>distribution</b> <b>curve</b> is in the middle, and the bearing area curve (Abbott-Firestone curve) is on the right.|$|E
40|$|The key {{concepts}} (calibration, discrimination, and discordance) important in understanding and comparing risk models are best conveyed graphically. To illustrate this, models predicting death and acute kidney injury {{in a large}} cohort of PCI patients differing {{in the number of}} predictors included are presented. Calibration plots, often presented in the current literature, present the agreement between predicted and observed risk for deciles of risk. Risk <b>distribution</b> <b>curves</b> present the frequency of different levels of risk. Scatterplots of the risks assigned to individuals by different models show the discordance of the individual risk estimates. Increasing the number of predictors in these models produce increasingly disperse and progressively skewed risk <b>distribution</b> <b>curves.</b> These resemble the lognormal distributions expected when risk predictors interact multiplicatively. These changes in the risk <b>distribution</b> <b>curves</b> correlate with improved measures of discrimination. Comment: 14 pages, 7 figure...|$|R
40|$|The present {{paper is}} a short note on the {{relation}} between the abnormally severe damage to Japanese-style wooden houses in an area at a distance of about 400 km from the epicenter, Taisha Town, in the Nankai earthquake (M= 8. 3) that occurred on Dec. 21, 1944 and the period <b>distribution</b> <b>curves</b> of microtremors observed in the same area. As seen in Figs. 4 ～ 19, the shapes of the period <b>distribution</b> <b>curves</b> of microtremors observed in the severely damaged area are extremely flat...|$|R
40|$|Abstract. There {{are much}} complex {{internal}} microstructures of functionally graded materials, and the mechanical parameters of functionally graded materials structures varied {{with the space}} coordinates. Therefore, it is generally difficult to measure point by point macro <b>distributions</b> <b>curves</b> of functionally graded materials properties based on available experimental conditions. The prerequisite for various analyses of the functionally graded materials structures is the determination of macro <b>distributions</b> <b>curves</b> of materials properties parameters. In practice, only the spatial distributions of different ma-terial components can be controlled {{in the course of}} materials production. Therefore, the functionally graded <b>distributions</b> <b>curves</b> need inversing and identifying by the materials components. In the pre-sent paper, the inversion and identification technique was put forward based on the positive static and dynamic analyses by the microelement method, which was applied to do the scale-span analyses for macro responses of functionally graded materials structures based on the given materials components distributions in production...|$|R
50|$|Likewise, one of {{the most}} common {{measures}} of information seeking behavior, library circulation statistics, also follows the 80-20 rule. This suggests that information seeking behavior is a manifestation not of a normal <b>distribution</b> <b>curve,</b> but a power law curve.|$|E
50|$|In 2007, the {{curricula}} for Chinese and English were revised. The two subjects {{were no longer}} graded along the normal <b>distribution</b> <b>curve</b> but rather by criteria referencing (with {{the exception of the}} highest grade, the 5*). Numerical levels are used instead of the traditional letter grades.|$|E
5000|$|The prototypical Hubbert {{curve is}} a {{probability}} density {{function of a}} logistic <b>distribution</b> <b>curve.</b> It is not a gaussian function (which is used to plot normal distributions), but the two have a similar appearance. The density of a Hubbert curve approaches zero more slowly than a gaussian function: ...|$|E
40|$|ABSTRACT The study {{aimed to}} {{evaluate}} the water distribution from a medium-size sprinkler working in solid set sprinkler systems. Water <b>distribution</b> radial <b>curves</b> from the sprinkler operating under four nozzle diameter combinations (4. 0 x 4. 6; 5. 0 x 4. 6; 6. 2 x 4. 6 and; 7. 1 x 4. 6 mm) and four working pressures (196; 245; 294 and 343 kPa) were evaluated on the sprinkler test bench of the State University of Maringá, in Cidade Gaúcha, Paraná, Brazil. The sixteen water <b>distribution</b> <b>curves</b> were normalized and subjected to clustering analysis (K-Means algorithm), identifying the occurrence of normalized <b>distribution</b> <b>curves</b> with three different geometric shapes. A computer algorithm, in Visual Basic for Applications in Excel spreadsheet, was developed to simulate the water application uniformity (Christiansen's Coefficient - CU) from the sprinklers working with rectangular and triangular layouts in solid set sprinkler systems. For the three geometric shapes of the normalized water <b>distribution</b> <b>curves,</b> digital simulation results of water distribution uniformity for the sprinklers on mainline and lateral line spaced between 10 to 100 % of wetted diameter indicated that sprinkler spacings around 50 % of the wetted diameter provide acceptable CU values...|$|R
30|$|The a posteriori histograms fit the {{standardized}} normal <b>distribution</b> <b>curves</b> {{much better than}} that of a priori ones individually, which tells that the a posteriori estimated variances for the GNSS measurements were realistic.|$|R
30|$|For all {{methods and}} all datasets, {{cumulative}} error <b>distribution</b> <b>curves</b> were produced. For the BioID, 300 W, and the Menpo datasets, error curves indicating {{state of the}} art performance were overlayed and referenced.|$|R
50|$|Disruptive selection, {{also called}} diversifying selection, {{describes}} changes in population genetics in which extreme values for a trait are favored over intermediate values. In this case, {{the variance of}} the trait increases and the population {{is divided into two}} distinct groups. In this more individuals acquire peripheral character value {{at both ends of the}} <b>distribution</b> <b>curve.</b>|$|E
50|$|While some {{students}} may be concerned {{about their ability to}} demonstrate proficiency in an assessment that native speakers of Spanish also take, only the scores of students who study Spanish as a second language are factored when creating the <b>distribution</b> <b>curve</b> of scores 1-5. Native speakers or heritage language speakers of Spanish are then compared to non-native distribution and assigned a score accordingly.|$|E
50|$|From 1989 through 2001, Gauss's portrait, {{a normal}} <b>distribution</b> <b>curve</b> and some {{prominent}} Göttingen buildings were {{featured on the}} German ten-mark banknote. The reverse featured the approach for Hanover. Germany has also issued three postage stamps honoring Gauss. One (no. 725) appeared in 1955 on the hundredth anniversary of his death; two others, nos. 1246 and 1811, in 1977, the 200th anniversary of his birth.|$|E
40|$|For most {{applications}} of thin films, uniformity of film thickness over the substrate {{area is a}} necessary require-ment. An investigation is being {{carried out in the}} laboratory to obtain uniform films on optical com-ponents. During the course of investigation, i t was observed that reported values of geometrical parameters assumed for minimum variation in film thickness, based on the equation derived by Holland and Steckelmacher,' differ widely. Film thickness <b>distribution</b> <b>curves</b> pre-sented by R 4 acleod 2 are found to be in error. The corrected <b>distribution</b> <b>curves</b> are presented. Also the thickness <b>distribution</b> <b>curves</b> are presented in a form in which suitable geometrical parameters can be chosen readily to yield the desired uniformity in thickness over the area of the substrate. For a small area surface source the distribution of film thickness on a planar substrate is given by m h 2 (h 2 + p 2 + R 2) (1) t = -. ~p [(h 2 +p 2 +R 2) '- 4 p 2 R 2]) &apos...|$|R
40|$|We have {{performed}} an angle-resolved photoemission study of overdoped La 1. 78 Sr 0. 22 CuO 4, and have observed sharp nodal quasiparticle {{peaks in the}} second Brillouin zone that are comparable to data from Bi 2 Sr 2 CaCu 2 O 8 +d. The data analysis using energy <b>distribution</b> <b>curves,</b> momentum <b>distribution</b> <b>curves</b> and intensity maps all show evidence of an electron-like Fermi surface, which is well explained by band structure calculations. Evidence for many-body effects are {{also found in the}} substantial spectral weight remaining below the Fermi level around (pi, 0), where the band is predicted to lie above EF. Comment: 4 pages, 4 figure...|$|R
30|$|The {{grain size}} <b>distribution</b> <b>curves</b> of KTPS fly ash shows that {{major portion of}} fly ash are finer particle, i.e. silt {{fraction}} with some sand fraction {{which can be used}} as a fill material in road construction.|$|R
5000|$|... ==Step, touch, and mesh potentials== [...] "Step potential" [...] is {{the voltage}} between {{the feet of}} a person {{standing}} near an energized grounded object. It {{is equal to the}} difference in voltage, given by the voltage <b>distribution</b> <b>curve,</b> between two points at different distances from the [...] "electrode". A person could be at risk of injury during a fault simply by standing near the grounding point.|$|E
50|$|The {{probability}} of detection <b>distribution</b> <b>curve</b> for a chosen NDI method is superimposed to the crack growth curve, and the inspection interval is systematically changed to compute the cumulative {{probability of}} detection for a crack growing from the minimum to the critical size. The simulation is repeated several times, and a distribution of inspection interval versus structural reliability can be formed. To refine the randomization of the values, the Latin Hypercube procedure was also introduced.|$|E
50|$|In 2012 the New York City Department of Education (NYC DOE) {{adjusted}} its {{criteria for}} inferring {{gifted and talented}} needs of students in kindergarten through the third grade. Citing {{a disproportionate number of}} students scoring in the 99th percentile — the far right tail of the <b>distribution</b> <b>curve</b> — the NYC DOE replaced the Bracken (BSRA) with the Naglieri Nonverbal Ability Test (NNAT), and changed the weighting, lowering the OLSAT from two-thirds to one-third and giving the NNAT two-thirds.|$|E
40|$|Expressions {{are derived}} for higher-order {{skewness}} and excess coefficients using central moments and cumulants up to 8 th order. These coefficients are then calculated for three probability distributions: (1) Log-normal, (2) Rice-Nakagami, and (3) Gamma <b>distributions.</b> <b>Curves</b> {{are given to}} shown the variation of skewness with excess coefficients for these <b>distributions.</b> These <b>curves</b> are independent of the particular distribution parameters. This method is useful for studying fluctuating phenomena, which obey non-Gaussian statistics...|$|R
30|$|Graphically, the EEM {{method was}} the least {{effective}} to fit Weibull <b>distribution</b> <b>curves</b> for wind speed data from the region of Pernambuco and Rio Grande do Sul, respectively, using the data analyzed for the cities of Triunfo, Petrolina and São Martinho da Serra.|$|R
50|$|The {{stability}} of travel times and <b>distribution</b> <b>curves</b> {{over the past}} three decades gives a good basis for the application of aggregate trip distribution models for relatively long term forecasting. This is not to suggest that there exists a constant travel time budget.|$|R
