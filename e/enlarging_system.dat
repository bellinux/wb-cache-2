9|198|Public
50|$|For {{over half}} of century, the {{technology}} of microelectronics has been advancing by miniaturization, leading to significant increases in computing power and continuous decreases in manufacturing cost. In parallel, remarkable progress on <b>enlarging</b> <b>system</b> scale in recent years {{gives rise to a}} nascent field known as macroelectronics, in which microelectronic devices are distributed yet integrated over large area substrates with sizes much bigger than semiconductor wafers.|$|E
30|$|Massive multiple-input multiple-output (MIMO) {{techniques}} {{have the potential}} to bring tremendous improvements in spectral efficiency to future communication systems. Counterintuitively, the practical issues of having uncertain channel knowledge, high propagation losses, and implementing optimal non-linear precoding are solved more or less automatically by <b>enlarging</b> <b>system</b> dimensions. However, the computational precoding complexity grows with the system dimensions. For example, the close-to-optimal and relatively “antenna-efficient” regularized zero-forcing (RZF) precoding is very complicated to implement in practice, since it requires fast inversions of large matrices in every coherence period. Motivated by the high performance of RZF, we propose to replace the matrix inversion and multiplication by a truncated polynomial expansion (TPE), thereby obtaining the new TPE precoding scheme which is more suitable for real-time hardware implementation and significantly reduces the delay to the first transmitted symbol. The degree of the matrix polynomial can be adapted to the available hardware resources and enables smooth transition between simple maximum ratio transmission and more advanced RZF.|$|E
40|$|Comprehensive and {{reliable}} situation recording and monitoring are basic prerequisites to avoid collisions and groundings in the maritime traffic system. Due to the technical {{advance in the}} last century both tasks are more and more overtaken by a variety of sensors, services and systems. As a result, a steadily increasing number of data is provided to describe the current situation on board the ships and in traffic areas. This opened the door for the application of integrated data processing techniques to perform the analysis of situation up to identification of threats at the soonest. But with the <b>enlarging</b> <b>system</b> complexity the necessity arises to evaluate the current usability of components and data in use to avoid misinterpretations of the situation. Usability evaluation becomes feasible in real time, if suitable integrity monitoring functions can be applied. In consequence, the implementation of system and data integrity into the maritime traffic system is considered as high-level user need of e-Navigation, a framework initiated by the International Maritime Organization (IMO) to enhance the maritime traffic system. The article gives an overview about DLR’s project “Maritime Traffic Engineering” (2010 - 2014), which is pursued on the feasibility of integrity monitoring in the maritime position, navigation, and timing system (PNT) as well as during traffic situation assessment (TSA) ...|$|E
40|$|AbstractThe aim of {{this paper}} is to show how {{solutions}} to the one-dimensional compressible Euler equations can be approximated by solutions to an <b>enlarged</b> hyperbolic <b>system</b> with a strong relaxation term. The <b>enlarged</b> hyperbolic <b>system</b> is linearly degenerate and is therefore suitable to build an efficient approximate Riemann solver. From a theoretical point of view, the convergence of solutions to the <b>enlarged</b> <b>system</b> towards solutions to the Euler equations is proved for local in time smooth solutions. We also show that arbitrarily large shock waves for the Euler equations admit smooth shock profiles for the <b>enlarged</b> relaxation <b>system.</b> In the end, we illustrate these results of convergence by proposing a numerical procedure to solve the <b>enlarged</b> hyperbolic <b>system.</b> We test it on various cases...|$|R
40|$|In {{this paper}} the {{interaction}} of periodic parameter excitation with forced excitations of in general non commensurable basic frequencies is under consideration. The method of <b>enlarged</b> <b>systems</b> serves as a toolbox, where the central idea of the method {{and the structure of}} the <b>enlarged</b> <b>system</b> are in the same way derived as the complete homogeneous and the manifold of inhomogeneous solutions are discussed. The application to a realisation of a high speed twin-disc rotor-bearing-system of a textile spinning turbine illustrates the resonance effects that haven’t been characterized before...|$|R
40|$|The nonlocal {{symmetry}} of the generalized fifth order KdV equation (FOKdV) is first obtained {{by using the}} related Lax pair and then localized in a new <b>enlarged</b> <b>system</b> by introducing some new variables. On this basis, new Backlund transformation is obtained through Lie's first theorem. Furthermore, the general form of Lie point symmetry for the <b>enlarged</b> FOKdV <b>system</b> is found and new interaction solutions for the FOKdV equation are explored by using classical symmetry reduction method...|$|R
40|$|Large-scale {{multi-user}} multiple-input multiple-output (MIMO) {{techniques have}} the potential to bring tremendous improvements for future communication systems. Counter-intuitively, the practical issues of having uncertain channel knowledge, high propagation losses, and implementing optimal non-linear precoding are solved more-or-less automatically by <b>enlarging</b> <b>system</b> dimensions. However, the computational precoding complexity grows with the system dimensions. For example, the close-to-optimal regularized zero-forcing (RZF) precoding is very complicated to implement in practice, since it requires fast inversions of large matrices in every coherence period. Motivated by the high performance of RZF, we propose to replace the matrix inversion by a truncated polynomial expansion (TPE), thereby obtaining the new TPE precoding scheme which is more suitable for real-time hardware implementation. The degree of the matrix polynomial can be adapted to the available hardware resources and enables smooth transition between simple maximum ratio transmission (MRT) and more advanced RZF. By deriving new random matrix results, we obtain a deterministic expression for the asymptotic signal-to-interference-and-noise ratio (SINR) achieved by TPE precoding in large-scale MIMO systems. Furthermore, we provide a closed-form expression for the polynomial coefficients that maximizes this SINR. To maintain a fixed per-user rate loss as compared to RZF, the polynomial degree does not need to scale with the system, but it should be increased with the quality of the channel knowledge and the signal-to-noise ratio (SNR) ...|$|E
40|$|Massive multiple-input multiple-output (MIMO) {{techniques}} {{have the potential}} to bring tremendous improvements in spectral efficiency to future communication systems. Counterintuitively, the practical issues of having uncertain channel knowledge, high propagation losses, and implementing optimal non-linear precoding are solved more or less automatically by <b>enlarging</b> <b>system</b> dimensions. However, the computational precoding complexity grows with the system dimensions. For example, the close-to-optimal and relatively "antenna-efficient" regularized zero-forcing (RZF) precoding is very complicated to implement in practice, since it requires fast inversions of large matrices in every coherence period. Motivated by the high performance of RZF, we propose to replace the matrix inversion and multiplication by a truncated polynomial expansion (TPE), thereby obtaining the new TPE precoding scheme which is more suitable for real-time hardware implementation and significantly reduces the delay to the first transmitted symbol. The degree of the matrix polynomial can be adapted to the available hardware resources and enables smooth transition between simple maximum ratio transmission and more advanced RZF. By deriving new random matrix results, we obtain a deterministic expression for the asymptotic signal-to-interference-and-noise ratio (SINR) achieved by TPE precoding in massive MIMO systems. Furthermore, we provide a closed-form expression for the polynomial coefficients that maximizes this SINR. To maintain a fixed per-user rate loss as compared to RZF, the polynomial degree does not need to scale with the system, but it should be increased with the quality of the channel knowledge and the signal-to-noise ratio. Funding Agencies|ERC [305123]; Swedish Research Council</p...|$|E
40|$|An {{optical system}} was {{assembled}} {{for a study}} of spatial filtering and partial coherence. It was used to produce enlargements of microfilm images at a magnification of 12 -X. Enhancement of fine-detail contrast was obtained by means of a spatial filter that transmitted most of the light diffracted by the microfilm negative and absorbed about 60 of the undiffracted light. The filter increased the modulation transfer function (MTF) of the <b>enlarging</b> <b>system</b> by a factor of about 1. 5 measured at spatial frequencies lying in the region where the eye is most sensitive. At higher frequencies, the enhancement became greater than was expected, possibly because of phase effects. The optical system was partially coherent and produced coherent-noise blemishes in the enlargements. Consequently, a study was made of the effect of decreasing the degree of coherence by increasing the angular size of the light-source aperture. The 0. 8 mm aperture being used was replaced successively by larger ones (1, 3 5, 10, and 20 mm) and by a completely diffuse system. The 10 mm aperture (0. 04 radians), which gave a coherence interval of 14. 3 3 ̆eum on the negative, reduced the optical noise greatly and produced as good a result in terms of the system MTF as compared to apertures of higher coherence intervals. For the frequency range that is visually important for a 12 -X enlargement, it kept the MTF nearly equal to that of a coherent system and made it distinctly better than that obtained with the diffuse system. Spatial filtering with the 10 mm aperture is possible for enhancement at high frequencies that become important when enlargements much greater than 12 -X are used...|$|E
40|$|For the {{discretization}} of elliptic linear PDE's, {{instead of}} the usual nodal basis, we use a generating system that contains the nodal basis functions of the finest and all coarser levels. The Galerkin approach now results in an <b>enlarged</b> semidefinite linear <b>system</b> to be solved. Traditional iterative methods for that system turn out to be equivalent to modern multilevel methods for the fine grid system. Beside level-oriented iterative methods that lead to multilevel algorithms, other orderings of the unknowns of the <b>enlarged</b> <b>system</b> can be considered as well. A domain-wise block Gauss-Seidel iteration for the <b>enlarged</b> <b>system</b> results in a certain domain decomposition method with convergence rates independent of the mesh width of the fine grid. Furthermore, this approach directly leads to a O(1) -preconditioner for the Schur complement that arises in conventional domain decomposition methods. 1. The Generating System Consider a partial differential equation with linear, symmetric and elli [...] ...|$|R
50|$|Michael Joseph Savage is admired {{from many}} {{sides of the}} {{political}} spectrum and is known as the architect of the New Zealand welfare state. His Labour government provided the foundations of the post-war consensus, based upon the assumption that full employment would be maintained by Keynesian policies and that a greatly <b>enlarged</b> <b>system</b> of social services would be created.|$|R
40|$|AbstractWe {{consider}} an algorithm for analyzing bifurcation structure and for branch switching in solution branches of one-parameter dependent problems. Based on Liapunov-Schmidt methods and analyses of scales of solutions, we verify {{the existence of}} bifurcating solution branches successively via truncated Taylor expansions of the reduced bifurcation equations and an <b>enlarged</b> <b>system.</b> As examples, bifurcations of semilinear elliptic differential equations are studied on square and hexagon domains...|$|R
40|$|Today, {{environmentally}} responsible chemistry is of huge {{importance in the}} wake of sustainable production. In the field of the. ne chemical and pharmaceutical industry, preparative supercritical fluid chromatography (Prep-SFC) and preparative high performance liquid chromatography (Prep-HPLC) are widely used chiral separation techniques. Prep-SFC is often named as a green alternative for Prep-HPLC without having a thorough assessment of the greenness. However, if metrics are used for process selection with respect to green chemistry, they mainly show three shortcomings: (1) a narrow system boundary approach is used; (2) energy requirements are barely taken into account and (3) if energy requirements are considered, there is a differentiation in mass and energy inputs. Taking into account these shortcomings, Prep-HPLC and Prep-SFC are now compared and evaluated for their integral resource consumption. The evaluation is performed on a specific enantiomeric separation using exergetic life cycle analysis within <b>enlarging</b> <b>system</b> boundaries alpha, beta and gamma. Within the a system boundary (process level), Prep-HPLC requires 26. 3 % more resources quantified in exergy than the Prep-SFC separation due to its inherent higher use of organic solvents. Within the b system boundary (plant level), Prep-HPLC requires 29. 1 % more resources quantified in exergy than Prep-SFC. However, the Cumulative Exergy Extracted from the Natural Environment (CEENE) to deliver all mass and energy flows to the a and b system boundary via the overall industrial metabolism shows that Prep-SFC requires 34. 3 % more resources than Prep-HPLC. The poor score of Prep-SFC in the g system boundary is attributed to the high CEENE value related to the production of liquid carbon dioxide and the use of electricity for heating and cooling. It can be concluded that for this case, the most sustainable process as for the integral resource consumption is Prep-HPLC, unlike the general perception that Prep-SFC outperforms Prep-HPLC...|$|E
40|$|International audienceIntroduction: Sediments accumulating in {{waterways}} {{represent a}} triple threat: for fluvial navigation, for flooding hazards, {{and for their}} pollutant contents. Waterways dredging releases millions of m 3 of sediments, from which a large part is contaminated or even polluted enough to be considered as hazardous waste. Temporary or final storage on land {{is no longer a}} sustainable option. Methods: The GeDSeT decision support tool (DST) aims to provide sediment management options with quantitative data, in order to evaluate various scenarios taking into account cost and sustainability and consequently to highlight good practice. It allows to evaluate different scenarios of sediment management based on several indicators, in order to take into account all the consequences (effects, fig. 1) of the chosen options ("what-if" tools, [1]). As it is aimed at assessing all consequences of a chosen option (environmental, economic [...] .), the tool is based on multicriteria analysis [2]. Results: Scenarios were developed using databases and focused research results [2] through discussions with operators, communities and industries [3]. Scenario 1 : selective dredging is a 2 -phase scheme in which pollution hotspots are removed before bulk dredging, to improve reusability of sediment (fig. 2). Scenario 2 : on-site treatment implies processing as much as possible the sediment at a ship-borne plant. On-site dehydration benefits include output material with easier handling properties, and reduction of the dredged volume to be managed. Water can be returned to the waterway after treatment. Scenario 3 : selective treatment refers to directing sediment loads to a treatment procedure adequate for their pollutant contents (inorganic and/or organic). This scenario is applicable to sediment treatment facilities currently developed near canals. Treatment may be aimed at reducing contamination under critical levels for less polluted sediments, or at concentrating the pollutants in a low volume fraction for safe disposal. Reusable sediment loads may be shipped to reuse sites. Scenario 4 : alternative use of sediment Selectively dredged or treated sediments may be directed to reuse according to contamination level and regulatory constraints. Potential uses comprise: - bulk use where applicable (landfill cover, civil works, excavation backfill), - composite use (mix with concrete demolition aggregate), - use as an alternative mineral resource (cement production). Benefits include the reduction of primary minerals extraction and of sediment storage, hence increase of possible waterways dredging operations. Scenario 5 : alternative use of disposal sites. Sediment deposits are highly vegetated due to abundant organic matter, but they are unfit for food crops. Their use for energy crops (wood pellets, seeds) would reduce undesirable land use and allow energy crops on fertile soil without competition for land with food crops. All these scenarios are aimed at increasing the reuse of sediments, and reducing their disposal as waste. Scenarios 1 and 3 require the availability of field analytical methods, currently in development. Discussion: The benefits of alternative and novel scenarios (environmental, land use, employment and economic activity) are not properly accounted for if dredging projects are evaluated through a tendering process. Benefits are identified by <b>enlarging</b> <b>system</b> boundaries [1]. The benefits of sediments reuse, at constant budget, are to reduce land pressure and to improve waterways maintenance, offering therefore more possibilities to sustainable fluvial transport. Acknowledgements: This research was supported by the European InterReg IV program, by the Walloon region of Belgium, by the French Ministry of Research, the Nord Pas de Calais region, and the French Waterways (VNF). References: [1] Lemière, B. et al. (2012) The GeDSeT project: constitution of a decision support tool (DST) for the management and material recovery of waterways sediments in Belgium and Northern France. WASCON, Göteborg, www. swedgeo. se/wascon 2012. [2] Laboudigue, A., et al [...] , 2011. The GeDSeT Project: coupling multi-criteria analysis and knowledge improvement on sediment for a close-to-the-field Decision Support Tool. 7 th International SedNet conference, Venice. [3] Lemière, B, et al. (2012) L'outil d'aide à la décision GeDSeT. Recyclage et Valorisation (Société de l'Industrie Minérale, Paris) 36, 52 - 58...|$|E
40|$|Author Misnumbered pages, but all are present. Labled 55, 57, 55, 58. Thesis (M. A.) [...] Boston UniversityThe {{employment}} of miniature camera systems in high altitude photography {{has not been}} considered practical until very recently. In the past, the quality of lenses and films has been such that long focal length lenses and consequently large formats were necessary te record the desired ground detail. With recent advances in high speed optics and emulsion making, the potentialities of miniature camera systems have greatly increased. It is now possible to construct systems of this type having resolutian capabilities {{four or five times}} as great as conventional large format systems. The purpose of this work was to simulate certain aspects of high altitude photography, in order to study: 1) the potential of a 35 mm laboratory camera, 2) the photographic quality and amount of information that could be obtained on three different aero emulsions, 3) the effect of atmospheric haze on 2, and 4) to determine whether more information could be extracted by viewing a projected image of a negative or a print of that negative. An appraisal of the factors influencing the picture quality of aerial photographs was made. Such problems as aircraft motions, camera design and installation, atmospheric effects, and the brightness and contrast of scene detail was investigated. It was concluded that with proper installation and design of the camera system that three main factors influence the quality of high altitude photography of a given target scene. These factors are the quality of the camera lens, the ability of the film to record fine detail, and the amount of atmospheric haze. For this study a high acuity 35 mm laboratory camera was constructed. The lens used with this camera system was a 50 mm f/ 2. 8 Schneider "Xenotar". To provide an extremely fine and wide range of focus this lens was adapted to an interferometer table on which a Leica Focaslide assembly bad been mounted. Leiea If and Leica IIIc camera bodies were used with the system to provide a wide range of shutter speeds. The lens aperture was held constant at f/ 5. 6 throughout the experiment, an aperture at which the lens was essentially diffraction limited. Three Kodak films were used in this study; Micro-File, and two aerial emulsions, SO- 1213 and Plus-X Aerecon. MicroFile, a non-aerial film, was included in order to show what could be done with a high resolution film, although in practice its speed is so low as to require extremely fast optical systems. SO- 1213, a new experimental film, is one of the finest grained emulsions yet developed for aerial use. Plus-X Aerecon, just recently put into production, has a speed comparable ta Super-XX, but with much better image quality. Atmospheric haze was simulated by placing a diffusing disc inside the lens just behind the iris diaphragm. A circular hole, whose size corresponded with the diaphragm aperture at f/ 5. 6, was bored out of the center of this disc. By opening the diaphragm aperture beyond f/ 5. 6, the diffusing disc added a uniform "layer" of scattered light to the image, thus effectively simulating atmospheric haze. Three aperture settings were used in this work, f/ 5. 6, f/ 4, and f/ 2. 8. The following haze factors were obtained. at these apertures: 0, 0. 14, and 0. 36. Haze factor is defined here as the ratio of the haze brightness to the scene high-light brightness. The target scene consisted of four high quality positive transparencies of Boston, Mass. at a scale of 1 / 20, 000. A standard Air Force resolution target was inserted in a corner of one transparency. The target was illuminated by a light panel which had been specially constructed to provide a very even source of diffuse daylight illumination. The brightness range of the illuminated aerial scene was approximately 40 : 1. Photos were taken at distances such that the resultant scales on the 35 mm negatives were 1 / 100, 000, 1 / 200, 000, 1 / 400, 000, and 1 / 800, 000. The simulated altitudes were 5, 10, 20, and 40 miles, respectively. Thirty-six negatives were obtained using the above system, one for each film, at each scale, and at each haze setting. Care was taken to insure optimum focus. Using a high quality <b>enlarging</b> <b>system,</b> prints of each negative were made. All prints were enlarged to the same scale. The print enlargements for negatives at the fourscales, 1 / 100, 000, 1 / 200, 000, 1 / 400, 000, and 1 / 800, 000, was 3 X, 6 X, 12 X, and 24 X, respectively. Three methods were used in evaluating the results; 1) a microscopic examination of the negatives for resolution, 2) a microscopic examination of the prints for recognition and detection of certain scene detail, and 3) a qualitative examination of a greatly enlarged projected image of the negatives. The average resolution in lines per mm for the three films tested using haze factors of 0, 0. 14, and 0. 36, respectively, was found to be: For Micro-File: 174, 158, and 148; For SO- 1213 : 107, 93, and 80; and for Plus-X Aerecon: 57, 51, and 45. Microscopic investigation of the prints of the three films at the various scales for detection and recognition of scene detail revealed the following: At a scale of 1 / 100, 000 with Micro-File and SO- 1213 objects the size of automobiles could be detected. Aircraft and railroad cars could be easily recognized. The only difference between the two was that detail in the SO- 1213 prints was less sharp. At this scale with Plus-X Aerecon automobiles were just barely visible, recognition of aircraft was difficult, and the individual cars of trains could not be seen. At 1 / 200, 000 automobiles were barely detectable on the MicroFile prints. Trains and aircraft were still visible, but classification of aircraft type was questionable. Cars were no longer detectable on the SO- 1213 prints and aircraft was barely detectable. With Plus-X Aereeon neither cars nor trains were discernible. Aircraft was just barely detectable. Even small streets could not be seen. At 1 / 400, 000 with Micro-File large aircraft could just be detected and only relatively large buildings could be recognized. Street patterns were still plainly visible. On the SO- 1213 prints aircraft and the patterns of small streets were lest. Ships and large buildings could still be seen. At this scale (enlargement of 12 diameters) the prints of Plus-X Aerecon appeared very grainy. Only relatively large structures such as large streets and buildings could be recognized. At 1 / 800, 000 large buildings, bridges, ships, street patterns, wharfs and docks were still distinguishable on the Micro-File prints. With SO- 1213 only large buildings and the rough outline of harbor facilities could be recognized. Street patterns were only recognizable in high contrast regions of the scene. The Plus-X Aerecon prints at this scale revealed only very large roadways and buildings. Outlines of harbor facilities were very rough. Under the conditions of this study, relatively small loss of picture quality was caused by introduction of haze. On the Micro-File prints virtually no loss in quality was noticed even with a. 36 haze factor. On the SO- 1213 prints a slight loss could be detected at. 36 haze at the smaller scales in the low contrast regions of the scene. The prints most affected by haze were those of Plus-X Aerecon, the film having the lowest contrast of the three tested, and this was only noticeable at 36 % haze. It must be concluded that the majority of detail sizes in the negatives were such that the compression of brightness range by haze did not reduce the detail contrasts below the visual threshold. The high photographic contrasts of these emulsions is therefore valuable. Investigation of projected images of the negatives with a projector of moderate quality revealed that the same amount of information could be obtained as on the prints. However, this method presented the problem of having to view the image from an angle plus the problem of having to interpret a negative image. Results obtained using this method were purely qualitative and its importance is only one of interest. The final results indicate that high acuity miniature camera systems, in conjunction with high resolution emulsiens, offer information gathering capacity comparable to larger, heavier cameras using standard relatively coarse-grained emulsions...|$|E
40|$|We {{propose a}} {{reformulation}} of ideal magnetohydrodynamics {{written in the}} Lagrangian variable as an <b>enlarged</b> <b>system</b> of hyperelastic type, with a specific potential. We study the hyperbolicity of the model and prove that the acoustic tensor is positive for all directions which are non orthogonal to the magnetic field. The consequences for eulerian ideal magnetohydrodynamics and for numerical discretization are briefly discussed {{at the end of}} this work...|$|R
30|$|Cooperative {{diversity}} [1, 2] {{has been}} widely proposed for applications in wireless networks. In a wireless network consists {{of a collection of}} nodes, each having a single antenna, cooperative diversity assists to <b>enlarge</b> <b>system</b> coverage and increase link reliability. Cooperative diversity works by having the network nodes assist in data transmission, thus achieving a virtual antenna array. This occurs through having a number of nodes to transmit redundant signals over different paths, which allows the destination terminal to receive average channel variations.|$|R
40|$|A major {{field in}} {{research}} and development are open, distributed, communication-intense systems, which are currently characterized by increasing heterogeneity, in structure and technologies and by growing complexity and behavior dynamics. Autonomous systems are being investigated in order to return to manageable and stable systems whose operation and maintenance is affordable. By resolving the obstacles of current <b>systems</b> via <b>enlarged</b> <b>system</b> autonomy, the quality assurance of such dynamic, reconfigurable, adjustable systems becomes problematic. This keynote reviews requirements, methods and approaches for model-based quality assurance of autonomous systems...|$|R
5000|$|<b>Enlarging</b> {{existing}} dock <b>system</b> {{to accommodate}} larger vessels.|$|R
40|$|We {{propose a}} {{definition}} of determinism for a physical system that includes, besides the measured system, the measurement device and the surrounding environment. This <b>enlarged</b> <b>system</b> is assumed to follow a predefined trajectory starting from some (unknown) initial conditions that {{play the role of}} hidden variables for the experiment. These assumptions, which are different from realism, allow us to derive some Leggett-Garg inequalities, which are violated by Quantum Mechanics in the particular case of consecutive measurements on individual photon polarizations. Comment: 7 pages, 1 figure. arXiv admin note: substantial text overlap with arXiv: 1010. 504...|$|R
40|$|We {{propose a}} {{definition}} of determinism for a physical system that includes, besides the measurement device, the surrounding environment. This <b>enlarged</b> <b>system</b> is assumed to follow a predefined trajectory starting from some (unknown) initial conditions that {{play the role of}} hidden variables for the experiment. These assumptions, which are different from realism, allow us to derive a type of time Bell inequalities, which are violated by Quantum Mechanics. In order to illustrate this violation, we discuss the particular case of measurements on a spin 1 / 2 particle. Comment: 7 pages, 1 figur...|$|R
40|$|AbstractWe {{show how}} {{solutions}} to practical partial differential equations {{can be found}} by classical symmetry reductions of a larger system of equations including constraints that result in the <b>enlarged</b> <b>system</b> having a larger symmetry group or an identical symmetry group compared to the original target equation. Symmetry-enhancing constraints provide additional similarity solutions beyond those of the standard Lie algorithm for scalar equations. Symmetry-preserving constraints enable solutions to be found more easily, after reduction of variables. Examples are given for the cylindrical boundary layer equations and for a Navier–Stokes formulation of Schrödinger wave mechanics...|$|R
40|$|In {{this paper}} {{we present a}} perturbative {{procedure}} that allows one to numerically solve diffusive non-Markovian Stochastic Schrodinger equations, {{for a wide range}} of memory functions. To illustrate this procedure numerical results are presented for a classically driven two level atom immersed in a environment with a simple memory function. It is observed that as the order of the perturbation is increased the numerical results for the ensembled average state rho_{red}(t) approach the exact reduced state found via Imamo g-bar lu's <b>enlarged</b> <b>system</b> method [Phys. Rev. A. 50, 3650 (1994) ...|$|R
40|$|The Backlund {{transformation}} related symmetry is nonlocal, {{which is}} hardly to apply in constructing solutions for nonlinear equations. In this paper, we first localize nonlocal residual symmetry to Lie point symmetry by introducing multiple new variables and obtain new Baaklund transformation. Then, by solving out the general form of localized the residual symmetry, we reduce the <b>enlarged</b> <b>system</b> by classical symmetry approach and obtain the corresponding reduction solutions {{as well as}} related reduction equations. The localization procedure provides {{a new way to}} investigate interaction solutions between different waves...|$|R
2500|$|In other words, if the {{physical}} system is invariant under the continuous symmetry of time translation then its energy (which is canonical conjugate quantity to time) is conserved. [...] Conversely, systems {{which are not}} invariant under shifts in time (an example, systems with time dependent potential energy) do not exhibit conservation of energy– unless we consider them to exchange energy with another, external system so that {{the theory of the}} <b>enlarged</b> <b>system</b> becomes time invariant again. [...] Conservation of energy for finite systems is valid in such physical theories as special relativity and quantum theory (including QED) in the flat space-time.|$|R
30|$|In summary, we {{have devised}} an {{embedded}} quantum simulator for Rindler transformation of coordinates. This unphysical mathematical operation can be mapped to a physical observable in an enlarged Hilbert space, whose action {{is equivalent to}} the change of coordinates in the simulated space. Thus, we are able to analyse expectation values of observables of both the untransformed and transformed wavefunctions as well as correlations among them with measurements on the <b>enlarged</b> <b>system</b> only. This paves the way to the analysis of extreme accelerations and black hole horizons in quantum platforms such as trapped ions and superconducting circuits, within a single-particle relativistic quantum-mechanical approach.|$|R
40|$|The American Mobile Satellite Consortium (AMSC) Mobile Satellite Service (MSS) {{system is}} described. AMSC will use three {{multi-beam}} satellites to provide L-band MSS coverage to the United States, Canada and Mexico. The AMSC MSS system will have several noteworthy features, including a priority assignment processor that will ensure preemptive access to emergency services, a flexible SCPC channel scheme that will support a wide diversity of services, <b>enlarged</b> <b>system</b> capacity through frequency and orbit reuse, and high effective satellite transmitted power. Each AMSC satellite will {{make use of}} 14 MHz (bi-directional) of L-band spectrum. The Ku-band {{will be used for}} feeder links...|$|R
40|$|It is {{proved that}} the {{modified}} Boussinesq equation is consistent Riccati expansion (CRE) solvable; two types of special soliton-cnoidal wave interaction solution of the equation are explicitly given, which is difficult to be found by other traditional methods. Moreover, the nonlocal symmetry related to the consistent tanh expansion (CTE) and the residual symmetry from the truncated Painlevé expansion, {{as well as the}} relationship between them, are obtained. The residual symmetry is localized after embedding the original <b>system</b> in an <b>enlarged</b> one. The symmetry group transformation of the <b>enlarged</b> <b>system</b> is derived by applying the Lie point symmetry approach...|$|R
40|$|Bibliography: p. 297 - 302. The {{concept of}} Business Simulation Gaming is a {{relatively}} new term in the vocabulary of Business educators. This study adopts a Systems Approach to Business Simulation Gaming for the purpose of : (i) creating an overall awareness of the <b>Enlarged</b> Gaming <b>System</b> beyond the mere Implementation phase; and (ii) demonstrating its role as a valuable tool of learning. The four major components of this thesis, namely, the Rationale of Gaming, the Design Process, the Implementation Process and the Evaluation Process, combine to form an integrative whole - the <b>Enlarged</b> Gaming <b>System</b> - in contributing to the stated objectives...|$|R
40|$|This paper {{addresses}} {{the design of}} the inputs to a mixed logical dynamical system so as to satisfy some specification, while maximizing the number of non-influential inputs, i. e., those inputs that can take an arbitrary value within their admissible range without affecting the satisfaction of the specification. The problem can be rephrased as a reachability problem on an <b>enlarged</b> <b>system</b> and formulated as a robust mixed integer linear program. An iterative procedure that relies on the detection of non-influential inputs is proposed to simplify the solution to the problem for cascading systems. A numerical example shows the efficacy of the approach...|$|R
3000|$|... {{induced by}} (destructive or constructive) {{interference}} is repeated. Therefore, these revivals {{can be regarded}} as a finite-size effect induced by the periodic boundary conditions: <b>enlarging</b> the <b>system</b> size shifts these revivals to later times.|$|R
5000|$|The Parisian {{sewer system}} {{dates back to}} the year 1370 when the first {{underground}} system was constructed under [...] "rue Montmartre". Since then, consecutive French governments have <b>enlarged</b> the <b>system</b> to cover the city's population.|$|R
40|$|Experimental {{determination}} {{of an unknown}} quantum state usually requires several incompatible measurements. However, {{it is also possible}} to determine the full quantum state from a single, repeated measurement. For this purpose, the quantum system whose state is to be determined is first coupled to a second quantum system (the "assistant") {{in such a way that}} part of the information in the quantum state is transferred to the assistant. The actual measurement is then performed on the <b>enlarged</b> <b>system</b> including the original system and the assistant. We discuss in detail the requirements of this procedure and experimentally implement it on a simple quantum system consisting of nuclear spins. Comment: 11 pages, 6 figure...|$|R
40|$|We {{present a}} new method {{to measure the}} work $w$ {{performed}} on a driven quantum system and to sample its probability distribution $P(w) $. The method {{is based on a}} simple fact that remained unnoticed until now: Work on a quantum system can be measured by performing a generalized quantum measurement at a single time. Such measurement, which technically speaking is denoted as a POVM (positive operator valued measure) reduces to an ordinary projective measurement on an <b>enlarged</b> <b>system.</b> This observation not only demystifies work measurement but also suggests a new quantum algorithm to efficiently sample the distribution $P(w) $. This can be used, in combination with fluctuation theorems, to estimate free energies of quantum states on a quantum computer. Comment: 4 page...|$|R
40|$|In the Schrödinger equation, time plays {{a special}} rôle as an {{external}} parameter. We {{show that in}} an <b>enlarged</b> <b>system</b> where the time variable denotes an additional degree of freedom, solutions of the Schrödinger equation give rise to weights on the enlarged algebra of observables. States in the associated GNS representation correspond to states on the original algebra composed with a completely positive unit preserving map. Application of this map to {{the functions of the}} time operator on the large system delivers the positive operator valued maps which were previously proposed by two of us as time observables. As an example we discuss the application of this formalism to the Wheeler-DeWitt theory of a scalar field on a Robertson-Walker spacetime. 1...|$|R
40|$|We {{establish}} {{a connection between}} ground states of local quantum Hamiltonians and thermal states of classical spin systems. For any discrete classical statistical mechanical model in any spatial dimension, we find an associated quantum state such that the reduced density operator behaves as the thermal state of the classical system. We show that all these quantum states are unique ground states of a universal 5 -body local quantum Hamiltonian acting on a (polynomially <b>enlarged)</b> <b>system</b> of qubits arranged on a 2 D lattice. The only free parameters of the quantum Hamiltonian are coupling strengthes of two-body interactions, which allow one to choose the type and dimension of the classical model {{as well as the}} interaction strength and temperature. Comment: 4 pages, 1 figur...|$|R
