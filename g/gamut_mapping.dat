144|7|Public
25|$|Windows Color System {{is based}} on a {{completely}} new Color Infrastructure and Translation Engine (CITE). It is backed up by a new color processing pipeline that supports bit-depths more than 32 bits per pixel, multiple color channels (more than 3), alternative color spaces and high dynamic range coloring, using a technology named Kyuanos developed by Canon. The color processing pipeline allows device developers to add their own <b>gamut</b> <b>mapping</b> algorithm into the pipeline to customize the color response of the device. The new pipeline also uses floating point calculations to minimize round-off losses, which are inherent in integer processing. Once the color pipeline finishes processing the colors, the CITE engine applies a color transform according to a color profile, specific to a device to ensure the output color matches to what is expected.|$|E
2500|$|The {{following}} approximations {{assume a}} display device at gamma 2.2, using the sRGB color space. The further a display device deviates from these standards, the less accurate these swatches will be. Swatches {{are based on}} the average measurements of several lots of single-pigment watercolor paints, converted from Lab color space to sRGB color space for viewing on a computer display. Different brands and lots of the same pigment may vary in color. Furthermore, pigments have inherently complex reflectance spectra that will render their [...] greatly different depending on the spectrum of the source illumination; a property called metamerism. Averaged measurements of pigment samples will only yield approximations of their true appearance under a specific source of illumination. Computer display systems use a technique called chromatic adaptation transforms to emulate the correlated color temperature of illumination sources, and cannot perfectly reproduce the intricate spectral combinations originally seen. In many cases, the perceived color of a pigment falls outside of the gamut of computer displays and a method called <b>gamut</b> <b>mapping</b> is used to approximate the true appearance. <b>Gamut</b> <b>mapping</b> trades off any one of lightness, hue, or saturation accuracy to render the color on screen, depending on the priority chosen in the conversion's ICC rendering intent.|$|E
2500|$|The {{advent of}} digital {{photography}} gave hope for better solutions to this problem. One {{of the earliest}} algorithms employed by Land and McCann in 1971 was Retinex, inspired by theories of lightness perception [...]This method is inspired by the eye’s biological mechanisms of adaptation when lighting conditions are an issue. <b>Gamut</b> <b>mapping</b> algorithms were also extensively studied {{in the context of}} color printing. Computational models such as CIECAM02 or iCAM were used to predict color appearance. Despite this, if algorithms could not sufficiently map tones and colors, a skilled artist was still needed, {{as is the case with}} cinematographic movie post-processing.|$|E
5000|$|... #Caption: Fig 20b. The Adobe RGB <b>gamut</b> <b>mapped</b> in CIELAB space. Also {{notice that}} these two RGB spaces have {{different}} gamuts, and thus will have different HSL and HSV representations.|$|R
50|$|The Coloroid {{technical}} documentation defines the conceptual equations necessary {{to transform the}} Coloroid perceptual components VAT into the corresponding stimulus components, using the CIE XYZ 1931 colormatching functions with the D65 CIE illuminant. Hues are identified according to the hue angle ψ, measured on the CIE 1931 xy chromaticity plane. These stimulus attributes in turn must be standardized or <b>gamut</b> <b>mapped</b> into a specific colorant system or color reproduction technology in order to reproduce the Coloroid color space as physical color exemplars or a color atlas. However, a Coloroid Colour Atlas is available that provides color exemplars at 16 levels of lightness out {{to as many as}} 13 increments in saturation for each of for 48 hue planes.|$|R
40|$|Duotone {{refers to}} an image with various shades of a hue mapped in an vector or wedge through a color space. The colorant, the {{gradient}} curve, {{and the number of}} colorants used define the slice through the color space. The image is printed with two or more analogue colorants. The colorants may be custom formulated or selected from a named color system. Typically two colorants are placed on a substrate by a halftone procedure, and the visual result, the mixture of the two colorants, is a third color. A <b>gamut</b> <b>map</b> of the colorants requires an accurate model of the thrid color that results from halftoning and printing the two inks. Color management procedures convert this gamut model to a vector through a monitor RGB color space and then to CMYK for proofing. This paper describes such a color management procedure...|$|R
2500|$|The International Commission on Illumination (CIE) {{developed}} the XYZ model for describing {{the colors of}} light spectra in 1931, but its goal was to match human visual metamerism, rather than to be perceptually uniform, geometrically. In the 1960s and 70s, {{attempts were made to}} transform XYZ colors into a more relevant geometry, influenced by the Munsell system. These efforts culminated in the 1976 CIELUV and CIELAB models. The dimensions of these models— and , respectively—are cartesian, based on the opponent process theory of color, but both are also often described using polar coordinates— or [...] and also HCL, where L* is lightness, C* is chroma, and h* is hue angle. Officially, both CIELAB and CIELUV were created for their color difference metrics ∆E*ab and ∆E*uv, particularly for use defining color tolerances, but both have become widely used as color order systems and color appearance models, including in computer graphics and computer vision. For example, <b>gamut</b> <b>mapping</b> in ICC color management is usually performed in CIELAB space, and Adobe Photoshop includes a CIELAB mode for editing images. CIELAB and CIELUV geometries are much more perceptually relevant than many others such as RGB, HSL, HSV, YUV/YIQ/YCbCr or XYZ, but are not perceptually perfect, and in particular have trouble adapting to unusual lighting conditions.|$|E
5000|$|Qualcomm TruPalette display <b>gamut</b> <b>mapping,</b> color {{enhancement}} comprehensive {{control over}} colors ...|$|E
5000|$|ICtCp {{provides}} an improved color representation {{that is designed}} for high dynamic range (HDR) and wide color gamut (WCG). An improved constant luminance is an advantage for color processing operations such as chroma subsampling and <b>gamut</b> <b>mapping</b> where only color information is changed. ICtCp {{is based on a}} modification of IPT called ICaCb.|$|E
40|$|We {{propose a}} full {{reproduction}} workflow for printing color images on metallic substrates. It relies on an ink spreading enhanced cellular Yule-Nielsen modified spectral Neugebauer model, calibrated with 35 color samples {{printed on the}} metal film and measured under specular reflection. The calibration accounts for the different phenomena contributing to the reflectance of halftone prints on metal: specular reflection by the metal film substrate of light traveling across the inks, illumination and viewing geometry, shadowing effect induced by the ink and difference in surface structure between the inked and non-inked metal halftone elements. The model enables predicting printable colors with an average CIELAB ∆E 94 error of 1. 7. Thanks to the model, the metal print gamut is established and a 3 D table provides the correspondence between printable metallic colors viewed under specular reflection and the corresponding ink surface coverages. The input sRGB <b>gamut</b> is <b>mapped</b> into the print gamut. At halftone image generation time, surface coverages of the inks yielding the desired <b>gamut</b> <b>mapped</b> input colors are obtained from the 3 D table. These ink surface coverages yield the ink separations that are halftoned and printed. The resulting color images printed on a silver substrate viewed under specular reflection reproduce the hues at {{a high degree of}} fidelity. The luminance of metallic prints under specular observation is generally higher than the luminance of paper under the same illuminating conditions. Therefore, the printed metallic colors appear more colorful. Such metal prints are attractive for design, art and publicity. Their high brightness immediately strikes the observer and transmits the message incorporated into the reproduced picture or artwork...|$|R
40|$|Location Based Services (LBS) {{have become}} {{extremely}} popular {{and used by}} millions of users. Popular LBS run the entire <b>gamut</b> from <b>mapping</b> services (such as Google Maps) to restaurants (such as Yelp) and real-estate (such as Redfin). The public query interfaces of LBS can be abstractly modeled as a kNN interface over a database of two dimensional points: given an arbitrary query point, the system returns the k points in the database that are nearest to the query point. Often, k is set to a small value such as 20 or 50. In this paper, we consider the novel problem of enabling density based clustering over an LBS with only a limited, kNN query interface. Due to the query rate limits imposed by LBS, even retrieving every tuple once is infeasible. Hence, we seek to construct a cluster assignment function f(.) by issuing {{a small number of}} kNN queries, such that for any given tuple t in the database {{which may or may not}} have been accessed, f(.) outputs the cluster assignment of t with high accuracy. We conduct a comprehensive set of experiments over benchmark datasets and popular real-world LBS such as Yahoo! Flickr, Zillow, Redfin and Google Maps...|$|R
40|$|In {{this paper}} {{we present a}} novel two-scale {{framework}} to optimize the structure and the material distribution of an object given its functional specifications. Our approach utilizes multi-material microstructures as low-level building blocks of the object. We start by precomputing the material property gamut [...] the set of bulk material properties {{that can be achieved}} with all material microstructures of a given size. We represent the boundary of this material property gamut using a level set field. Next, we propose an efficient and general topology optimization algorithm that simultaneously computes an optimal object topology and spatially-varying material properties constrained by the precomputed <b>gamut.</b> Finally, we <b>map</b> the optimal spatially-varying material properties onto the microstructures with the corresponding properties in order to generate a high-resolution printable structure. We demonstrate the efficacy of our framework by designing, optimizing, and fabricating objects in different material property spaces on the level of a trillion voxels, i. e several orders of magnitude higher than what can be achieved with current systems. Comment: 19 pages, 25 figures, to appear in ACM Transactions on Graphics 201...|$|R
50|$|The IPT color {{appearance}} model excels at {{providing a}} formulation for hue where a constant hue value equals a constant perceived hue {{independent of the}} values of lightness and chroma (which is the general ideal for any color appearance model, but hard to achieve). It is therefore well-suited for <b>gamut</b> <b>mapping</b> implementations.|$|E
50|$|The perceptual and {{saturation}} intents {{are where}} the results really {{depend upon the}} profile maker. This is even how some of the competitors in this market differentiate themselves. These intents should be created by the profile maker so that pleasing images occur with the perceptual intent while eye-catching business graphics occur with the saturation intent. This is achieved {{through the use of}} different perceptual remaps of the data as well as different <b>gamut</b> <b>mapping</b> methods.|$|E
50|$|The {{following}} approximations {{assume a}} display device at gamma 2.2, using the sRGB color space. The further a display device deviates from these standards, the less accurate these swatches will be. Swatches {{are based on}} the average measurements of several lots of single-pigment watercolor paints, converted from Lab color space to sRGB color space for viewing on a computer display. Different brands and lots of the same pigment may vary in color. Furthermore, pigments have inherently complex reflectance spectra that will render their color appearance greatly different depending on the spectrum of the source illumination; a property called metamerism. Averaged measurements of pigment samples will only yield approximations of their true appearance under a specific source of illumination. Computer display systems use a technique called chromatic adaptation transforms to emulate the correlated color temperature of illumination sources, and cannot perfectly reproduce the intricate spectral combinations originally seen. In many cases, the perceived color of a pigment falls outside of the gamut of computer displays and a method called <b>gamut</b> <b>mapping</b> is used to approximate the true appearance. <b>Gamut</b> <b>mapping</b> trades off any one of lightness, hue, or saturation accuracy to render the color on screen, depending on the priority chosen in the conversion's ICC rendering intent.|$|E
40|$|This talk will {{consider}} the solo piano piece, Morning Music, from composer and performer perspectives. Morning Music is a memorial to the late Richard Hand, a fine guitarist and friend of both the composer and the work’s dedicatee, Nicola Meecham. The work is constructed from a pitch <b>gamut</b> that <b>maps</b> a cipher derived from Richard’s name onto the open strings of the guitar that, in turn, integrates four types of material; the construction of this pitch resource and the derivation of ideas therefrom will be discussed. In addition to this presentation of the work’s pre-compositional material the talk will illuminate the problem solving and decision making process underpinning the compositional process itself with recourse to the composer’s journal entries; in this way {{it is hoped that}} the ‘day to day’ aspects of compositional creativity will be usefully brought to the surface. Drawing on an interview conducted with Nicola Meecham the focus will be broadened to include Nicola’s interpretation of the score {{and the extent to which}} it is affected by the less determinate notational strategy adopted. This is important because one of the concerns of my recent compositional practice has been to acknowledge the creative nature of interpretation and to conceptualise it as an extension of the act of composition. In pursuit of this my recent scores have utilised varying degrees of indeterminacy in an attempt to liberate and expand the interpretative choices available to the performer. Such a strategy has affected change not only in notation but in the musical ideas themselves and this will be demonstrated through several scores that post-date Morning Music. The talk will include a performance of Morning Music and, it is hoped, the world premiere of a new work that builds on compositional and conceptual aspects of its predecessor...|$|R
5000|$|The goal in {{relative}} colorimetry {{is to be}} truthful to the specified color, with only a correction for the media. Relative colorimetry is useful in proofing applications, since you are using it {{to get an idea}} of how a print on one device will appear on a different device. Media differences are the only thing you really would like to adjust for. Obviously there has to be some <b>gamut</b> <b>mapping</b> going on also. Usually this is done in a way where hue and lightness are maintained at the cost of reduced saturation.|$|E
5000|$|The {{advent of}} digital {{photography}} gave hope for better solutions to this problem. One {{of the earliest}} algorithms employed by Land and McCann in 1971 was Retinex, inspired by theories of lightness perception [...]This method is inspired by the eye’s biological mechanisms of adaptation when lighting conditions are an issue. <b>Gamut</b> <b>mapping</b> algorithms were also extensively studied {{in the context of}} color printing. Computational models such as CIECAM02 or iCAM were used to predict color appearance. Despite this, if algorithms could not sufficiently map tones and colors, a skilled artist was still needed, {{as is the case with}} cinematographic movie post-processing.|$|E
50|$|ICTCP is near {{constant}} luminance, which improves chroma subsampling versus YCbCr. ICTCP also improves hue linearity {{compared with}} YCbCr which helps with compression performance and color volume mapping. When combined with adaptive reshaping ICTCP can improve compression performance by 10%. For CIEDE2000 color quantization errors 10-bit ICtCp would {{be equal to}} 11.5 bit YCbCr. Constant luminance is also improved with ICtCp which has a luminance relationship of 0.998 between the luma and encoded brightness while YCbCr has a luminance relationship of 0.819. An improved constant luminance is an advantage for color processing operations such as chroma subsampling and <b>gamut</b> <b>mapping</b> where only color information is changed. A draft document for ICtCp has been released by the JCT-VC.|$|E
5000|$|A {{side effect}} of {{printing}} with more than four primary inks is that it enables an improvement in [...] colour gamut of the printed image due {{to the use of}} secondary inks, which can be used for CCR (colour-component-replacement) similar to UCR (under-colour-removal) or GCR (gray-component-replacement) for black. The use of these multiple inks inflicts additional constraints in the printing system in the context of its modeling parameters such as ink-media interaction, total-ink-limit, halftoning with multiple-inks and the effect of ink overlay order. In terms of colour management, this multi-channel printing process mandates representation and manipulation of colours in the domain of spectral reflectivity of the scene. One such necessary manipulation includes spectral <b>gamut</b> <b>mapping.</b> Often, the methods used for such spectral colour management can also be employed for spectral reproduction on multi-primary display systems.|$|E
50|$|Windows Color System {{features}} a Color Infrastructure and Translation Engine (CITE) at its core. It is {{backed up by}} a color processing pipeline that supports bit-depths more than 32 bits per pixel, multiple color channels (more than three), alternative color spaces and high dynamic range coloring, using a technology named Kyuanos developed by Canon. The color processing pipeline allows device developers to add their own <b>gamut</b> <b>mapping</b> algorithm into the pipeline to customize the color response of the device. The new pipeline also supports floating point calculations to minimize round-off errors, which are inherent in integer processing. Once the color pipeline finishes processing the colors, the CITE engine applies a color translation according to a color profile, specific to a device to ensure the output color matches to what is expected.|$|E
5000|$|The display driver chip has an RGB to RGBW color {{vector space}} {{converter}} and <b>gamut</b> <b>mapping</b> algorithm, followed by metamer and subpixel rendering algorithms. In {{order to maintain}} saturated color quality, to avoid simultaneous contrast error between saturated colors and peak white brightness, while simultaneously reducing backlight power requirements, the display backlight brightness is under control of the PenTile driver engine. [...] When the image is mostly desaturated colors, those near white or grey, the backlight brightness is significantly reduced, often to less than 50% peak, while the LCD levels are increased to compensate. When the image has very bright saturated colors, the backlight brightness is maintained at higher levels. The PenTile RGBW also has an optional high brightness mode that doubles {{the brightness of the}} desaturated color image areas, such as black&white text, for improved outdoor view-ability.|$|E
50|$|Media Standard Print proposes three {{possible}} workflows: a ‘media neutral’ one, a ‘media specific’ {{one and a}} ‘classic media specific’ one. The media neutral workflow (RGB colours, Lab colours and so on; PDF/X-4) offers advantages if {{it has not yet}} been decided what press will be used for printing, allowing the black composition to be adjusted. The disadvantage of the ‘media neutral’ workflow is a degree of rendering uncertainty, since the <b>gamut</b> <b>mapping</b> should be carried out using the unstandardized perceptual Rendering intent. However, in practice this {{has turned out to be}} of little relevance. The media specific workflow (CMYK and spot colours; PDF/X-1a) offers a degree of production security, especially against unexpected conversions (RGB black in vector elements to CMYK deep black). Experts do not currently agree over which variant to prefer. As experience is gained, the majority of users are opting for the media neutral workflow, which entails considerably less effort during the design process. What remains to be seen is how fast this switch will take place.|$|E
5000|$|In {{nearly every}} {{translation}} process, {{we have to}} deal with the fact that the color gamut of different devices vary in range which makes an accurate reproduction impossible. They therefore need some rearrangement near the borders of the gamut. Some colors must be shifted to the inside of the gamut, as they otherwise cannot be represented on the output device and would simply be clipped. This so-called gamut mismatch occurs for example, when we translate from the RGB color space with a wider gamut into the CMYK color space with a narrower gamut range. In this example, the dark highly saturated purplish-blue color of a typical computer monitor’s [...] "blue" [...] primary is impossible to print on paper with a typical CMYK printer. The nearest approximation within the printer’s gamut will be much less saturated. Conversely, an inkjet printer’s [...] "cyan" [...] primary, a saturated mid-brightness greenish-blue, is outside the gamut of a typical computer monitor. The color management system can utilize various methods to achieve desired results and give experienced users control of the <b>gamut</b> <b>mapping</b> behavior.|$|E
5000|$|The International Commission on Illumination (CIE) {{developed}} the XYZ model for describing {{the colors of}} light spectra in 1931, but its goal was to match human visual metamerism, rather than to be perceptually uniform, geometrically. In the 1960s and 70s, {{attempts were made to}} transform XYZ colors into a more relevant geometry, influenced by the Munsell system. These efforts culminated in the 1976 CIELUV and CIELAB models. The dimensions of these models— and , respectively—are cartesian, based on the opponent process theory of color, but both are also often described using polar coordinates— or [...] and also HCL, where L* is lightness, C* is chroma, and h* is hue angle. Officially, both CIELAB and CIELUV were created for their color difference metrics ∆E*ab and ∆E*uv, particularly for use defining color tolerances, but both have become widely used as color order systems and color appearance models, including in computer graphics and computer vision. For example, <b>gamut</b> <b>mapping</b> in ICC color management is usually performed in CIELAB space, and Adobe Photoshop includes a CIELAB mode for editing images. CIELAB and CIELUV geometries are much more perceptually relevant than many others such as RGB, HSL, HSV, YUV/YIQ/YCbCr or XYZ, but are not perceptually perfect, and in particular have trouble adapting to unusual lighting conditions.|$|E
40|$|Abstract The <b>gamut</b> <b>mapping</b> {{algorithm}} {{is one of}} the most promising methods to achieve computational color constancy. However, so far, <b>gamut</b> <b>mapping</b> algorithms are restricted to the use of pixel values to estimate the illuminant. Therefore, in this paper, <b>gamut</b> <b>mapping</b> is extended to incorporate the statistical nature of images. It is analytically shown that the proposed <b>gamut</b> <b>mapping</b> framework is able to include any linear filter output. The main focus is on the local n-jet describing the derivative structure of an image. It is shown that derivatives have the advantage over pixel values to be invariant to disturbing effects (i. e. deviations of the diagonal model) such as saturated colors and diffuse light. Further, as the n-jet based <b>gamut</b> <b>mapping</b> has the ability to use more information than pixel values alone, the combination of these algorithms are more stable than the regular <b>gamut</b> <b>mapping</b> algorithm. Different methods of combining are proposed. Based on theoretical and experimental results conducted on large scale data sets of hyperspectral, laboratory and realworld scenes, it can be derived that (1) in case of deviations of the diagonal model, the derivative-based approach outperforms the pixel-based <b>gamut</b> <b>mapping,</b> (2) state-of-the-art algorithms are outperformed by the n-jet based <b>gamut</b> <b>mapping,</b> (3) the combination of the different n-jet based gamu...|$|E
40|$|In this paper, {{we present}} a novel {{approach}} of tone mapping as <b>gamut</b> <b>mapping</b> in a high-dynamic-range (HDR) color space. High- and low-dynamic-range (LDR) images as well as device gamut boundaries can simultaneously be represented within such a color space. This enables a unified transformation of the HDR image into the gamut of an output device (in this paper called HDR <b>gamut</b> <b>mapping).</b> An additional aim {{of this paper is}} to investigate the suitability of a specific HDR color space to serve as a working color space for the proposed HDR <b>gamut</b> <b>mapping.</b> For the HDR <b>gamut</b> <b>mapping,</b> we use a recent approach that iteratively minimizes an image-difference metric subject to in-gamut images. A psychophysical experiment on an HDR display shows that the standard reproduction workflow of two subsequent transformations - tone mapping and then <b>gamut</b> <b>mapping</b> - may be improved by HDR <b>gamut</b> <b>mapping...</b>|$|E
40|$|Color {{constancy}} aims {{to compute}} object colors despite {{differences in the}} color of the light source. Gamut-based approaches are very promising methods to achieve color constancy. In this paper, the <b>gamut</b> <b>mapping</b> approach is extended to incorporate higher-order statistics (derivatives) to estimate the illuminant. A major problem of <b>gamut</b> <b>mapping</b> is that in case of a failure of the diagonal model no solutions are found, and therefore no illuminant estimation is performed. Image value offsets are often used to model deviations from the diagonal model. Prior work which incorporated robustness to offsets for <b>gamut</b> <b>mapping</b> assumed a constant offset over the whole image. In contrast to previous work, we model these offsets to be position dependent, and show that for this case derivative-based <b>gamut</b> <b>mapping</b> yields a valid solution to the illuminant estimation problem. Experiments on both synthetic data and images taken under controlled laboratory settings reveal that the derivativebased and regular <b>gamut</b> <b>mapping</b> methods provide similar performance. However, the derivative-based method outperforms other methods on the more challenging task of color constancy for real-world images. 1...|$|E
40|$|We {{introduce}} a novel workflow that will hopefully open new directions of processing and improvement in image reproduction. Existing <b>gamut</b> <b>mapping</b> algorithms {{can be classified}} into two basic categories: image-independent algorithms and imagedependent algorithms. The latter algorithms produce better reproduction; however, because they are time consuming and mathematically complex, the image-independent approach is commonly used in most imaging workflows. We suggest a new workflow that attempts to approach the image-dependent mapping method without incurring significant computational drawbacks nor requiring changes in the imaging industrial standards. The proposed method attempts to choose an appropriate <b>gamut</b> <b>mapping</b> per image without reconstructing the image gamut itself and without constructing an imagespecific mapping on the fly, as required by image-dependent <b>gamut</b> <b>mapping</b> methods. Specifically, image characteristics are exploited for selection of a source gamut and a <b>gamut</b> <b>mapping</b> most appropriate for a given input image from a set of available mappings. Accordingly the proposed method is named image-guided <b>gamut</b> <b>mapping.</b> We show the practicability and advantages of the suggested workflow in several specific cases. We show that better image quality is achieved for 87 % of the tested images when using the suggested workflow...|$|E
40|$|ISBN 2 - 7261 - 1297 8 International audienceColor {{constancy}} aims {{to compute}} object colors despite {{differences in the}} color of the light source. Gamut-based approaches are very promising methods to achieve color constancy. In this paper, the <b>gamut</b> <b>mapping</b> approach is extended to incorporate higher-order statistics (derivatives) to estimate the illuminant. A major problem of <b>gamut</b> <b>mapping</b> is that in case of a failure of the diagonal model no solutions are found, and therefore no illuminant estimation is performed. Image value offsets are often used to model deviations from the diagonal model. Prior work which incorporated robustness to offsets for <b>gamut</b> <b>mapping</b> assumed a constant offset over the whole image. In contrast to previous work, we model these offsets to be position dependent, and show that for this case derivative-based <b>gamut</b> <b>mapping</b> yields a valid solution to the illuminant estimation problem. Experiments on both synthetic data and images taken under controlled laboratory settings reveal that the derivativebased and regular <b>gamut</b> <b>mapping</b> methods provide similar performance. However, the derivative-based method outperforms other methods on the more challenging task of color constancy for real-world images...|$|E
40|$|<b>Gamut</b> <b>mapping</b> {{deals with}} the need to adjust a color image to fit into the {{constrained}} color gamut of a given rendering medium. A typical use for this tool is the reproduction of a color image prior to its printing, such that it exploits best the given printer/medium color gamut, namely the colors the printer can produce on the given medium. Most of the classical <b>gamut</b> <b>mapping</b> methods involve a pixel by pixel mapping and ignore the spatial color configuration. Recently proposed spatial dependent approaches for <b>gamut</b> <b>mapping</b> are either based on heuristic assumptions or involve a high computational cost. In this paper we present a new variational approach for space [...] dependent <b>gamut</b> <b>mapping.</b> Our treatment starts with the presentation of a new measure for the problem, closely related to a recent measure proposed for Retinex. We also link our method to recent measures that attempt to couple spectral and spatial perceptual measures. It is shown that the <b>gamut</b> <b>mapping</b> problem leads to a quadratic programming formulation, guaranteed to have a unique solution if the gamut of the target device is convex. An e#cient numerical solution is proposed with promising results...|$|E
40|$|A spatial <b>gamut</b> <b>mapping</b> {{technique}} is proposed {{to overcome the}} shortcomings encountered with standard pointwise <b>gamut</b> <b>mapping</b> algorithms by preserving spatially local luminance variations in the original image. It does so by first processing the image through a standard pointwise <b>gamut</b> <b>mapping</b> algorithm. The difference between the original image luminance Y and gamut mapped image luminance Y ’ is calculated. A spatial filter is then applied to this difference signal, whose output is added back to the gamut mapped signal Y’. The filtering operation can cause some pixel colors which lie near the gamut boundary to be moved outside of the gamut, hence a second <b>gamut</b> <b>mapping</b> step is required to move these pixel colors back into the gamut. Finally, all pixels are processed through a color correction function for the output device, and rendered for that device. The algorithm is designed to reduce many of the artifacts arising from standard pointwise techniques. Psychophysical experiments indicated an observer preference for the proposed algorithm. ...|$|E
40|$|Abstract: There {{are very}} {{complicated}} nonlinear relations between input value and presentation color of digital prepress devices, {{as well as}} in the <b>gamut</b> <b>mapping</b> among different devices. Not all the relations can be described by linear model properly. In recent years, neural network and black box theory are introduced to describe the relations. In this research, the printer gamut is divided into micro space sections, a relative colorimetric rending mapping method is proposed based on BP neural network theory to complete the <b>gamut</b> <b>mapping</b> from monitor gamut to color printer. Experimental results show that the model reduces the color error of color blocks between the two devices, and the color rendering method can be used for <b>gamut</b> <b>mapping</b> of image with less continuous tone...|$|E
40|$|Abstract—Gamut mapping {{deals with}} the need to adjust a color image to fit into the {{constrained}} color gamut of a given rendering medium. A typical use for this tool is the reproduction of a color image prior to its printing, such that it exploits best the given printer/medium color gamut, namely the colors the printer can produce on the given medium. Most of the classical <b>gamut</b> <b>mapping</b> methods involve a pixel-by-pixel mapping and ignore the spatial color configuration. Recently proposed spatial-dependent approaches for <b>gamut</b> <b>mapping</b> are either based on heuristic assumptions or involve a high computational cost. In this paper, we present a new variational approach for space-dependent <b>gamut</b> <b>mapping.</b> Our treatment starts with the presentation of a new measure for the problem, closely related to a recent measure proposed for Retinex. We also link our method to recent measures that attempt to couple spectral and spatial perceptual measures. It is shown that the <b>gamut</b> <b>mapping</b> problem leads to a quadratic programming formulation, guaranteed to have a unique solution if the gamut of the target device is convex. An efficient numerical solution is proposed with promising results. I...|$|E
40|$|The White-Patch method, one of {{the first}} colour {{constancy}} methods, estimates the light source colour from the maximum response of the different colour channels. However, it has been eclipsed by the advent of more advanced physical or statistical methods, as well as complex learning based methods. Recently, a new independent line of work claims that the simple idea of using maximum pixel values is not as naive as it seems, but can also be made to perform very well via some manipulations. The bright areas of images can include highlights and specularity as well as white surfaces or light sources, and indeed all may be helpful in the illumination estimation process. In this paper, we define the White Patch Gamut as a new extension to the <b>Gamut</b> <b>Mapping</b> Colour Constancy method, comprising the bright pixels of the image. Adding new constraints based on the possible White Patch Gamut to the standard <b>gamut</b> <b>mapping</b> constraints, a new combined method outperforms <b>gamut</b> <b>mapping</b> methods as well as other wellknown colour constancy methods. The new constraints that are brought to bear are powerful, and indeed can be more discriminating than those in the original <b>gamut</b> <b>mapping</b> method itself...|$|E
40|$|Predicting colours across {{multiple}} display devices requires implementation of device characterization, <b>gamut</b> <b>mapping,</b> and perceptual models. This thesis studies characteristics of CRT, LCD monitors and projectors. It compares existing models and introduces {{a new model}} that improves existing calibration algorithms. <b>Gamut</b> <b>mapping</b> assigns a mapping between two different colour spaces. Previously, the focus of <b>gamut</b> <b>mapping</b> has been between monitor and printer, which have relatively different gamut shape. Implementation and result of existing models are compared and a new model is introduced that its output images {{are as good as}} the best available models but runs in less time. DLP projectors with a different technology require a more complex calibration algorithm. A new approach for calibrating DLP projectors is introduced with a significantly better performance on predicting RGB data given tristimulus values. At the end, a new calibration method, using Support Vector Regression is introduced...|$|E
