10000|10000|Public
5|$|In statistics, maximum spacing <b>estimation</b> (MSE or MSP), or maximum {{product of}} spacing <b>estimation</b> (MPS), {{is a method}} for {{estimating}} the parameters of a univariate statistical model. The method requires maximization of the geometric mean of spacings in the data, which are {{the differences between the}} values of the cumulative distribution function at neighbouring data points.|$|E
25|$|Kernel density <b>estimation</b> {{univariate}} kernel density <b>estimation.</b>|$|E
25|$|Sub-domains of {{computer}} vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose <b>estimation,</b> learning, indexing, motion <b>estimation,</b> and image restoration.|$|E
40|$|In this paper, we obtain {{some new}} <b>estimations</b> of Iyengar-type {{inequality}} in which quasi-convex(quasi-concave) functions are involved. These <b>estimations</b> are improvements of some recently obtained <b>estimations.</b> Some error <b>estimations</b> for the trapezoidal formula are given. Applications for special means are also provided. Comment: This {{study has been}} presented at "International Conference on Functional Equations, Geometric Functions and Applications(ICFGA 2012) " in 10 - 12 May 201...|$|R
50|$|His New York Times bestselling book Great <b>Estimations</b> and its sequel, Greater <b>Estimations,</b> teach {{children}} {{the skill of}} visually estimating large quantities.|$|R
30|$|The next theorem {{shows that}} the pth {{exponential}} <b>estimations</b> implies the almost surely asymptotic <b>estimations,</b> and we give an upper bound for the sample Lyapunov exponent.|$|R
25|$|Tasks {{that fall}} within the {{paradigm}} of unsupervised learning are in general <b>estimation</b> problems. The applications include clustering, the <b>estimation</b> of statistical distributions, compression and filtering.|$|E
25|$|Together with Ho's student Robert Lee at MIT, {{the paper}} A Bayesian {{approach}} to problems in stochastic <b>estimation</b> and control formulated a general class of stochastic <b>estimation</b> and control problems from a Bayesian Decision-Theoretic viewpoint.|$|E
25|$|Improves the accuracy/efficiency of <b>estimation.</b>|$|E
30|$|Additional {{socioeconomic}} {{variables are}} excluded from the analysis as they proved to be never significant in all <b>estimations.</b> Full <b>estimations</b> are available from authors upon request.|$|R
40|$|Linear {{polarization}} measurements {{provide access}} to two quantities, the degree (DOP) and the angle of polarization (AOP). The aim of this work is to give a complete and concise overview of how to analyze polarimetric measurements. We review interval <b>estimations</b> for the DOP with a frequentist and a Bayesian approach. Point <b>estimations</b> for the DOP and interval <b>estimations</b> for the AOP are further investigated with a Bayesian approach to match observational needs. Point and interval <b>estimations</b> are calculated numerically for frequentist and Bayesian statistics. Monte Carlo simulations are performed to clarify {{the meaning of the}} calculations. Under observational conditions, the true DOP and AOP are unknown, so that classical statistical considerations - based on true values - are not directly usable. In contrast, Bayesian statistics handles unknown true values very well and produces point and interval <b>estimations</b> for DOP and AOP, directly. Using a Bayesian approach, we show how to choose DOP point <b>estimations</b> based on the measured signal-to-noise ratio. Interval <b>estimations</b> for the DOP show great differences in the limit of low signal-to-noise ratios between the classical and Bayesian approach. AOP interval <b>estimations</b> that are based on observational data are presented for the first time. All results are directly usable via plots and parametric fits. Comment: 11 pages, 14 figures, 3 table...|$|R
40|$|International audienceThree {{experiments}} on loudness of sounds with linearly increasing levels were performed: global loudness {{was measured using}} direct ratings, loudness change was measured using direct and indirect <b>estimations.</b> Results revealed differences between direct and indirect <b>estimations</b> of loudness change, indicating that the underlying perceptual phenomena are not the same. The effect of ramp size is small for the former and important for the latter. A similar trend was revealed between global loudness and direct <b>estimations</b> of loudness change according to the end level, suggesting {{they may have been}} confounded. Measures provided by direct <b>estimations</b> of loudness change are more participant-dependent...|$|R
25|$|In physics or {{engineering}} education, a Fermi problem, Fermi quiz, Fermi question, Fermi estimate, {{or order}} <b>estimation</b> is an <b>estimation</b> problem {{designed to teach}} dimensional analysis, approximation, and such a problem is usually a back-of-the-envelope calculation. The <b>estimation</b> technique is named after physicist Enrico Fermi as he {{was known for his}} ability to make good approximate calculations with little or no actual data. Fermi problems typically involve making justified guesses about quantities and their variance or lower and upper bounds.|$|E
25|$|Least {{absolute}} deviation (LAD) regression is a robust <b>estimation</b> technique {{in that it}} is less sensitive to the presence of outliers than OLS (but is less efficient than OLS when no outliers are present). It is equivalent to maximum likelihood <b>estimation</b> under a Laplace distribution model for ε.|$|E
25|$|<b>Estimation</b> of gas {{quantities}} for reasonably foreseeable contingencies.|$|E
40|$|In {{this article}} the {{statistics}} {{of the higher}} order - the <b>estimations</b> of the mixed cumu-lant of the 4 th order for rates of exchange on the financial market are investigated. For construction of <b>estimations</b> the initial data are the prices of opening, closing, minimum, maximum for currency pair EUR/USD are used. Under this data {{the plot of the}} <b>estimations</b> of the mixed cumulant of the 4 th order and the density plot are constructed. The properties inherent in <b>estimations</b> of the mixed cumulant are revealed and some laws are traced. Researches are spent in package Mathematica...|$|R
40|$|This paper studied {{statistical}} analysis {{of a new kind}} of accelerated life testing which combined progressively and constantly life test. The point <b>estimations</b> of the parameters in Exponential distribution and acceleration equation are obtained based on type II progressively censored data. Furthermore, we give the interval <b>estimations</b> of the parameters by Bootstrap sample. Besides, the <b>estimations</b> of the failure rate, the reliability functions and mean life are given at normal stress level, as well as the approximated unbiased <b>estimations</b> of failure rate and mean life. In the end, an illustrative numerical example is examined by means of the Monte-Carlo simulation...|$|R
40|$|A {{series of}} four {{experiments}} {{were performed to}} examine the accuracy of <b>estimations</b> of economic growth by both experts and lay people, {{the factors that influence}} the accuracy of their <b>estimations,</b> and which procedures they use to make <b>estimations.</b> The results show that for actual growth rates higher than 1 %, both groups clearly underestimated growth, and the underestimation was lower for experts than for laypeople. The <b>estimations</b> became slightly better when the task was presented in a financial investment scenario. Incentives had no effect on the accuracy of the estimations: however, a positive influence of the need for cognition was observed. Male participants provided more accurate <b>estimations</b> than female participants. The common use of different, and inappropriate solution procedures, accounted for the under-estimators. (C) 2009 Elsevier B. V. All rights reserved...|$|R
25|$|While {{the tools}} of data {{analysis}} work best on data from randomized studies, they are also applied to other kinds of data – like natural experiments and observational studies – for which a statistician would use a modified, more structured <b>estimation</b> method (e.g., Difference in differences <b>estimation</b> and instrumental variables, among many others) that produce consistent estimators.|$|E
25|$|The {{development}} of a criterion that can be evaluated to determine when the solution with the minimum error has been achieved. Laplace tried to specify a mathematical form of the probability density for the errors and define a method of <b>estimation</b> that minimizes the error of <b>estimation.</b> For this purpose, Laplace used a symmetric two-sided exponential distribution we now call Laplace distribution to model the error distribution, and used the sum of absolute deviation as error of <b>estimation.</b> He felt these to be the simplest assumptions he could make, and {{he had hoped to}} obtain the arithmetic mean as the best estimate. Instead, his estimator was the posterior median.|$|E
25|$|Some of {{the more}} common <b>estimation</b> {{techniques}} for linear regression are summarized below.|$|E
40|$|Requirements {{management}} measures {{can help us}} to control changing software requirements and estimate the costs of changing requirements. This paper describes two small case studies, performed {{in the context of}} a team-project based software development course. In the first study, we compared intuitive cost <b>estimations</b> of changes to requirements to <b>estimations</b> based on historical data. In the second one, we studied whether even simple tools to support impact analysis affect the accuracy of cost <b>estimations.</b> Although the data we collected in these studies is not suitable for statistical analysis, we can present some interesting results and lessons learned. Our results suggest that <b>estimations</b> based on an impact analysis checklist are better than the intuitive <b>estimations</b> obtained in study one. However, study two is not yet completed therefore we cannot draw further conclusions. 1...|$|R
30|$|We give a new {{approach}} for the <b>estimations</b> of the eigenvalues of non-self-adjoint Sturm–Liouville operators with periodic and antiperiodic boundary conditions. Moreover, we give error <b>estimations,</b> and finally we present some numerical examples.|$|R
40|$|<b>Estimations</b> of serum copper, serum {{ceruloplasmin}} (immunochemical), and urinary amino-acids excretion (quantitative and chromatographic) in 44 healthy {{relatives of}} patients with Wilson's disease (39 from one family) are reported. Each technique revealed some abnormal individuals. Good agreement was obtained between the serum copper and serum ceruloplasmin <b>estimations</b> and between the quantitative and chromatographic <b>estimations</b> of amino-acid excretion. Some individuals were abnormal to one or other of the pairs of tests only...|$|R
25|$|Some of {{the theory}} behind maximum {{likelihood}} <b>estimation</b> was developed for Bayesian statistics.|$|E
25|$|Pakistan's yearly {{population}} from 1950 to 2014, with <b>estimation</b> since last census (1998).|$|E
25|$|Maximum spacing <b>estimation,</b> {{a related}} method {{that is more}} robust in many situations.|$|E
40|$|Authors have {{proposed}} {{method of estimating}} three dimentional wind velocity using only information on reflectivity detected conventional radar, and evaluated accuracy of <b>estimations</b> by the method using wind fields derived from dual Doppler observations. In this study, we evaluate accuracy of <b>estimations</b> more quantitatively, and investigate sensitivity of <b>estimations</b> to assumptions in the method. Moreover, based on results of the evaluation, the method is extended as a method which utilizes information on Doppler velocity detected by one Doppler radar. In order to evaluate accuracy of <b>estimations</b> by extended method, we calculate also horizontal wind field using information on Doppler velocity detected by dual Doppler radars. Using the calculated wind field, we evaluate accuracy of <b>estimations</b> by extended method qualitively and quantitably. In summary, the more severe the precipitation event is, the better skill the proposed methods show...|$|R
3000|$|... “In 50 of the 62 99 mTc-substances, the {{effective}} dose <b>estimations</b> give lower values than previous estimations.” Should be “In 38 of the 62 99 mTc-substances, {{the effective}} dose <b>estimations</b> give lower values than previous estimations.” [...]...|$|R
40|$|Measurement-based {{approaches}} {{with extreme}} value worst-case <b>estimations</b> {{are beginning to}} be proficiently considered for timing analyses. In this paper, we intend to make more formal extreme value theory applicability to safe worst-case execution time <b>estimations.</b> We outline complexities and challenges behind extreme value theory assumptions and parameter tuning. Including the knowledge requirements, {{we are able to}} conclude about safety of the probabilistic worst-case execution <b>estimations</b> from the extreme value theory, and execution time measurements...|$|R
25|$|Emphasis on {{statistical}} {{significance to the}} exclusion of <b>estimation</b> and confirmation by repeated experiments.|$|E
25|$|<b>Estimation</b> of {{application}} specific parameters, such as object pose or object size.|$|E
25|$|Ethylenediaminetetraacetic acid (EDTA) is {{used for}} <b>estimation</b> of Ca2+ and Mg2+ in hard water.|$|E
3000|$|... [...]. For {{positive}} user feedback, users try to {{tell the}} system their <b>estimations</b> by providing suggestion positions. Note that these <b>estimations</b> could {{be close to the}} true position (accurate feedback) or still far away from it (inaccurate feedback).|$|R
3000|$|... 9 The cutoff at 25, 000 DKK is {{somewhat}} arbitrary. The {{purpose is to}} include only non-trivial labor force participation in the <b>estimations.</b> <b>Estimations</b> made at cutoff at 12, 500 and 50, 000 DKK respectively produce qualitatively similar results.|$|R
50|$|The {{data are}} <b>estimations.</b>|$|R
