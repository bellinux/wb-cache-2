4|120|Public
30|$|Highway {{agencies}} allocate {{a significant}} amount of their resources to traffic counting programs. The traffic volume data collected are used for studying temporal and spatial variation of traffic and estimating important traffic parameters such as average annual daily traffic (AADT), <b>design</b> <b>hourly</b> <b>volume</b> (DHV), and average daily vehicle distance traveled (DVDT). Estimation of these parameters is needed for design, planning, control, operation, and management of the highway infrastructure. The most commonly implemented counting programs by highway agencies are: (1) Continuous counting programs by permanent traffic counters (PTCs) record traffic volume every hour of everyday throughout the year, and (2) Sample counting programs by short-duration counts (SDCs) are conducted periodically (e.g., seasonally) or sporadically every year for durations ranging from a few hours to several weeks.|$|E
40|$|<b>Design</b> <b>hourly</b> <b>volume</b> and the K-factor, first {{proposed}} by FHWA in the 1950 s, {{is based on}} the 30 th hourly traffic volume during a year (out of 8, 760 hours). It was used when surveying the traffic volume was laborious in the past and is still being used now although it leaves some to be desired for practical applications. More reasonable K-factor for better design, based on theoretical evidence, is needed. This paper proposes the knee searching method based on simple linear regression to find out the inflection point of the volume ranking curve that describe the annual 8, 760 hourly traffic volumes. The method was applied to the Chungcheong province's national highway, and the results were compared to the existing guidelines ’ values of K-factors. Identified design hourly traffic volumes ranked between 43 rd to 694 th, which is much lower than the 30 th volume, meaning that some overdesign examples are inevitable if the conventional 30 t...|$|E
40|$|ABSTRACT: Studies {{indicate}} that usually {{a large percentage}} of permanent traffic counts (PTCs) from highway agencies have missing values. It will be difficult to eliminate such {{a significant portion of the}} data from the analysis. The literature review shows that many highway agencies estimated missing values for their PTCs. Estimating missing values is known as data imputation. However, only limited research used factor or time series analysis models for predicting missing values. Moreover, studies of the effect of the imputations on traffic parameters estimations are not available. This study used factor models, genetically designed neural network and regression models, and autoregressive integrated moving average (ARIMA) models to update pseudo-missing values of six PTCs from Alberta, Canada. The six PTCs are from roads of different trip pattern groups and functional classes. The influences of these imputations on the estimations of annual average daily traffic (AADT) and <b>design</b> <b>hourly</b> <b>volume</b> (DHV) were studied. It was found that simple models usually resulted in large AADT and DHV estimation errors. For example, AADT estimation error for a simple factor model was 13. 54 %, and DHV estimation error was 18. 46 %. As models were refined, resultin...|$|E
50|$|The {{alignment}} of Route 185 originates as Alternative F-1 and G-1 of the Liberty Harbor - Route 169 Feeder Arterial, proposed in 1977 during {{the construction of}} the New Jersey Route 169. The alignment was supposed to fork off of Route 169 near Interchange 14A on the Newark Bay Extension, and parallel the extension through the Greenville Railroad Yards. The alignment would parallel Caven Point Road to the south and through the Metropolitan Tank Port before ending at Interchange 14B in Jersey City. The alignment. The original alignment proposed, Alternative G-4, was to have the freeway run along the {{alignment of}} Caven Point Road parallel to the Newark Bay Extension into the Metropolitan Tank Port, but prior to the Final Environmental Impact Statement, the proposal was dropped. The alignment was designed to help serve existing and proposed industry and divert truck traffic from local streets. The alignment of the new arterial was proposed to be 2.75 mi with four travel lanes (two in each direction) <b>designed</b> for <b>hourly</b> <b>volume</b> of 3090 vehicles.|$|R
30|$|In this study, <b>hourly</b> traffic <b>volume</b> factors (the {{ratio of}} <b>hourly</b> <b>volume</b> to AADT) were used {{rather than the}} <b>hourly</b> <b>volume</b> to remove the effect of monthly and yearly trends in traffic volumes from the analysis. It may {{be noted that the}} 12 -, 24 -, 48 -, and 72 -h traffic counts were limited only to weekday (Monday–Thursday) traffic. This was done to avoid the effect of weekend traffic on such counts. However, weekly counts {{included}} weekend traffic as well.|$|R
3000|$|... factor used {{to convert}} annual {{average daily traffic}} to a {{specified}} annual <b>hourly</b> <b>volume.</b> (K[*]=[*] 0.1 for rural roads).|$|R
40|$|Highway {{agencies}} collect traffic data {{to calculate}} traffic parameters such as Annual Average Daily Traffic (AADT), <b>Design</b> <b>Hourly</b> <b>Volume</b> (DHV) {{and then to}} use as input in the planning, operation and management of their highway systems. The traffic data are usually collected through traffic monitoring programs. In particular, the Weigh-in-Motion (WIM) system is one of data collection systems to capture configuration patterns of vehicle travelling on the detection area. It is learned from literatures that traffic monitoring devices are prone to be in malfunctioning and, consequently, providing erroneous or missing traffic data due to the adverse weather conditions in which they operate. It is very critical for transportation agencies {{to be able to}} estimate classified missing traffic data in high accuracy level because the truck traffic plays a crucial role in developing pavement design and evaluation long term pavement performance. Several imputation methods have been cited in the literature but none of them have been designed to impute classified traffic data missed during severe winter weather conditions. To do this, winter weather model is structured and then calibrated to relate classified traffic volume variation to weather factors (snowfall and temperature) with traffic data collected from WIM stations located on highway network of Alberta, Canada and weather data collected from weather stations nearby WIM stations. Performance of the developed weather model is compared with a nonparametric regression method namely k-Nearest Neighbour (k-NN) method in terms of several error measures. It is concluded that winter weather models show better performance in terms of error measures than k-NN method while imputing the missing classified traffic data...|$|E
40|$|The design hour volume (DHV) is {{the volume}} of traffic during one hour that is used as an {{acceptable}} operating condition for highway planning and design purposes. Traditionally, the determination of DHV {{involves the use of}} a graph showing the highest <b>hourly</b> <b>volumes</b> of the year according to rank. The selection of a particular highest <b>hourly</b> <b>volume</b> for <b>design</b> purpose is a compromise between adequate level of service for every (or almost every) hour of the year and economic efficiency. Customary practice in Canada and the United States is to base design on a...|$|R
40|$|Hourly {{proportions}} (or {{time of day}} factors) {{are often}} needed for estimating highway link <b>hourly</b> <b>volumes,</b> which are important for models in air quality estimation, vehicle crash prediction and transportation planning. Hence, {{it is a common}} task for researchers or engineers in transportation to estimate hourly proportion models. This task, however, is very challenging because there are many factors that affect the hourly proportions. These factors in general include: (1) geometric and operational features, socio-economic characteristics and land use patterns associated with the highway network, and (2) temporal factors, including hour, day of week and month. The temporal factors in the second group contrast from those in the first group further in that they have distinct cyclic effects. ^ These factors should all be taken into account in an hourly proportion model. However, factors in the second group are generally not considered or considered in a highly approximate way in previous models. This is because, in order to consider these factors, the number of model parameters can become extremely large and beyond the capacities of existing model building tools and computers. Consequently, only annual average hourly proportions are estimated using the previous models, which in turn result in annual average <b>hourly</b> <b>volume</b> estimates. In many cases, the accuracy of the estimated <b>hourly</b> <b>volumes</b> cannot satisfy the rapidly increasing demands of more detailed and accurate vehicle emissions, accident prediction, and transportation planning models. ^ This work is intended to learn how to obtain more accurate hourly proportion estimates. This is carried out by first thoroughly investigating the effects of hour, day of week and month using Analysis of Variance (ANOVA) statistical procedure. The issue of primary concern here is to identify whether these factors interact with each other. Procedures are then established to group these factors. This includes the use of Comparison of Means statistical procedure (along with an engineering criterion) and a grouping algorithm developed ad hoc. The purpose of these exercises is to reduce the model size and make it feasible to include hour, day of week and month, as well as other factors, in hourly proportion models. In addition, hourly proportion models are estimated considering only hour, day of week and month. The hourly proportions estimated using these models can be used to estimate volumes for a specific hour, day of week and month in a year at a highway location, which in turn can significantly improve the accuracy of the <b>hourly</b> <b>volume</b> estimates. ...|$|R
40|$|This study details a {{comprehensive}} {{set of guidelines}} and a work-plan that consists of nine elements {{that need to be}} developed in implementing a congesion management system. A procedure has been developed by means of which congestion on roadway links can be identified at a macroscopic level using daily volume counts (ADT) after which, links that are identified as being congested will be subjected to a more detailed microscopic study using <b>hourly</b> <b>volume</b> counts to determine extent, duration and severity of congestion...|$|R
5000|$|Where M is the <b>hourly</b> traffic <b>volume</b> {{from the}} traffic model (or new count) and C is the {{real-world}} hourly traffic count (or the old count) ...|$|R
30|$|Similar to the {{research}} work mentioned above, scientists have modeled various scenarios to highlight the effects and provided solutions to minimize the disturbance. In one study [9], the analysis of bad weather on the <b>hourly</b> traffic <b>volume</b> was done for Buffalo, New York, USA. The conclusion of the entailed that effect became more significant during peak hours as the percentage reduction in volume reached up to 34 %. Furthermore, study also showed that wind speed and temperature had the least impact on traffic while visibility had the highest influence on <b>hourly</b> traffic <b>volume.</b>|$|R
40|$|Average <b>hourly</b> ozone <b>volume</b> {{fractions}} {{from ten}} automatic monitoring {{stations in the}} Los Angeles and six in the Riverside area for the April through September season in the years 2000 to 2005 have been analysed {{on the basis of}} recently introduced photochemical pollution (PP) indicators. Although considerably high indicator values were found for almost all the stations, surprisingly, some (e. g. Palm Springs) exhibit low daily maximum-to-minimum ratios of hourly ozone values which is crucial for assessment of a low PP by the given indicator method, despite the overall high ozone concentrations recorded. At such stations, in contrast to elsewhere, a characteristic quasi normal distribution of all ozone <b>hourly</b> <b>volume</b> fractions exists which could be a consequence of poor vegetation or some special meteorological conditions there. Compared with a similar assessment in central Europe and the Mediterranean region, the present analysis shows that PP problems in California are significant. (doi: 10. 5562 /cca 2008...|$|R
5000|$|... {{in which}} DHV is the [...] "Design Hourly Volume," [...] the 30th highest <b>hourly</b> traffic <b>volume</b> (in both directions) {{in the year}} in which data was collected, by {{vehicles}} per hour.|$|R
40|$|AbstractTraditionally, {{traffic count}} {{statistics}} in Germany contain the so-called relevant <b>hourly</b> <b>volume,</b> which {{is defined as}} the 30 thhighest hour of the year when listing the <b>hourly</b> <b>volumes</b> in descending order. When the first edition of the German Highway Capacity Manual (HBS) was prepared in 2001, the Federal Government decided that this 30 th hour should be used {{as the basis for the}} level of service determination for all Federal freeways and trunk roads. While German freeways are quite well equipped with inductive loop detectors, there are much fewer counts on rural roads and almost no long-term data on urban roads. With the current redraft of the German HBS detailed advice will be given on how to estimate peak-hour demand (all vehicles and heavy vehicle portion), based on the n-th highest hour concept depending on the available traffic counts. As the HBS will be divided into three major parts: freeways, rural roads, and urban roads, three separate chapters for the peak-hour demand estimation will be provided. Whereas for freeways the task consists in finding the comparable site equipped with inductive loop detectors, for urban roads it is a matter of establishing which time periods of the year and weekdays are appropriate for manual short-term counts as estimation of the 30 th hour of the year. For all kind of traffic devices the requirements on traffic demand models for level of service calculations are described. © 2011 Published by Elsevier Ltd...|$|R
40|$|This paper {{focuses on}} the problem of {{estimating}} historical traffic volumes between sparsely-located traffic sensors, which transportation agencies need to accurately compute statewide performance measures. To this end, the paper examines applications of vehicle probe data, automatic traffic recorder counts, and neural network models to estimate <b>hourly</b> <b>volumes</b> in the Maryland highway network, and proposes a novel approach that combines neural networks with an existing profiling method. On average, the proposed approach yields 26 % more accurate estimates than volume profiles, which are currently used by transportation agencies across the US to compute statewide performance measures. The paper also quantifies the value of using vehicle probe data in estimating <b>hourly</b> traffic <b>volumes,</b> which provides important managerial insights to transportation agencies interested in acquiring this type of data. For example, results show that volumes can be estimated with a mean absolute percent error of about 20 % at locations where average number of observed probes is between 30 and 47 vehicles/hr, which provides a useful guideline for assessing the value of probe vehicle data from different vendors...|$|R
40|$|In the {{previous}} paper we have proposed {{two types of}} time-of-day traffic assignment models which can predict the <b>hourly</b> <b>volume</b> of traffic on each network link. In these models, however, the phnomenon of congestion over a network has not been treated explicitly enough. In this paper we propose an improved time-of-day traffic assignment model which can describe the congestion queues at bottlenecks in a network more explicitly and realistically by introducing new link performance functions. It is shown that this new model {{can be reduced to}} the variational inequality and can be solved by the use of the iteration method developed by M. Smith...|$|R
5000|$|For traffic {{modelling}} {{work in the}} [...] "baseline" [...] scenario, a GEH of {{less than}} 5.0 is considered a good match between the modelled and observed <b>hourly</b> <b>volumes</b> (flows of longer or shorter durations should be converted to hourly equivalents to use these thresholds). According to DMRB, 85% of the volumes in a traffic model should have a GEH less than 5.0. GEHs {{in the range of}} 5.0 to 10.0 may warrant investigation. If the GEH is greater than 10.0, there is a high probability {{that there is a problem}} with either the travel demand model or the data (this could be something as simple as a data entry error, or as complicated as a serious model calibration problem).|$|R
40|$|A {{methodology}} {{is proposed}} and simple models are developed that estimate on a macrolevel the traffic volume distribution in highways lanes. The {{testing of the}} methodology and the models' calibration were done for different <b>hourly</b> <b>volumes</b> with data collected from highways in the Greater Athens area in Greece. The transferability and predictability of the models were shown by applying them to different highway traffic conditions. Thus, a useful, simple tool for traffic management is developed for usage by transportation planners and highway engineers: based on a macrolevel utilization of each traffic lane by the vehicles, the pavement maintenance can be scheduled accordingly, and better design of intersections could be accomplished by {{taking into account the}} traffic volume estimated to use each lane, especially the right one...|$|R
40|$|Includes bibliographical {{references}} (pages 72 - 74) Described in {{this thesis}} is a method whereby the timing of stock determined with market purchases and sales may be a reasonable degree of accuracy by using a linear mathematical equation. The variable quantities employed in the equation are the hourly prices of the Dow-Jones Industrial Average, the corresponding <b>hourly</b> <b>volume</b> and total daily volume on the New York Stock Exchange. At the conclusion o f a sale transact ion, the gain or loss in the Dow Jones Industrial Average is noted. Each year an income statement is generated showing {{the results of the}} various transactions. In order to visualize the quantities generated and remove some of the day to day fluctuations, a 10 day and also a 20 day moving trend line are plotted on arithmetic paper. The decision to buy or sell stock is based on six empirical rules; no other factors are involved in the decision process...|$|R
40|$|The {{standard}} highway assignment {{model in}} the Florida Standard Urban Transportation Modeling Structure (FSUTMS) {{is based on the}} equilibrium traffic assignment method. This method involves running several iterations of all-or-nothing capacity-restraint assignment with an adjustment of travel time to reflect delays encountered in the associated iteration. The iterative link time adjustment process is accomplished through the Bureau of Public Roads (BPR) volume-delay equation. Since FSUTMS 2 ̆ 7 traffic assignment procedure outputs daily volumes, and the input capacities are given in <b>hourly</b> <b>volumes,</b> it is necessary to convert the hourly capacities to their daily equivalents when computing the volume-to-capacity ratios used in the BPR function. The conversion is accomplished by dividing the hourly capacity by a factor called the peak-to-daily ratio, or referred to as CONFAC in FSUTMS. The ratio is computed as the highest <b>hourly</b> <b>volume</b> of a day divided by the corresponding total daily volume. ^ While several studies have indicated that CONFAC is a decreasing function of the level of congestion, a constant value is used for each facility type in the current version of FSUTMS. This ignores the different congestion level associated with each roadway and is believed {{to be one of the}} culprits of traffic assignment errors. Traffic counts data from across the state of Florida were used to calibrate CONFACs as a function of a congestion measure using the weighted least squares method. The calibrated functions were then implemented in FSUTMS through a procedure that takes advantage of the iterative nature of FSUTMS 2 ̆ 7 equilibrium assignment method. ^ The assignment results based on constant and variable CONFACs were then compared against the ground counts for three selected networks. It was found that the accuracy from the two assignments was not significantly different, that the hypothesized improvement in assignment results from the variable CONFAC model was not empirically evident. It was recognized that many other factors beyond the scope and control of this study could contribute to this finding. It was recommended that further studies focus on the use of the variable CONFAC model with recalibrated parameters for the BPR function and/or with other forms of volume-delay functions. ...|$|R
40|$|Various {{approaches}} {{to the analysis of}} 10 -year continuous ozone mo-nitoring from the EUROTRAC-TOR network station Puntijarka near Zagreb are reported. The site has a rural character (45. 90 ° N; 15. 97 ° E, 980 m a. s. l.) and is representative of the lower troposphere of a wider region. Mean <b>hourly</b> ozone <b>volume</b> fractions measured from 1990 - 1999, autocorrelation plots for ali data and for data for summer periods (May-Sep.), box and whiskers representations of diurnal variations during winter (Nov. -March) and summer periods, mean monthly values and 12 -month moving averages, and the Fourier transform of the complete set of 94, 248 <b>hourly</b> mean ozone <b>volume</b> fractions are discussed. The data show no increase, or possibly a slight decrease, of the ozone volume fraction {{toward the end of the}} decade...|$|R
30|$|The {{main purpose}} of this study is (1) to {{investigate}} the influence of the winter conditions (snow, temperature) on different types of trucks and (2) to analyze the impact of winter weather conditions on daily and <b>hourly</b> truck <b>volume.</b> Two types of temporal variations of truck type distributions are investigated: (1) month-to-month variations and (2) season-to-season variations in which the months of November to March representing severe snowfall and cold conditions are grouped into winter months and the remaining months are grouped into non-winter months. Combined Chi squared (χ 2) and Binomial tests of statistical significance are conducted to investigate the variations for the three truck classes during winter weather conditions. Dummy-variable regression models are developed to define quantitatively the variations in daily and <b>hourly</b> truck <b>volumes</b> under different weather conditions. The study uses weigh-in-motion (WIM) data collected from Leduc site located on a provincial highway: highway 2 A in Alberta, Canada. The modeling work for the present research is carried out using CARPACKAGE, available in the statistical software R [3]; RDCT [4].|$|R
40|$|Increasing {{trends in}} traffic volume on {{specific}} ports may indicate {{new interest in}} a vulnerability associated with that port. This activity can be a precursor to internet-wide attacks. Port-specific behavior can also arise from stealthy applications that migrate to different ports in order to evade firewalls. But detecting this subtle activity among thousands of monitored ports requires careful statistical modeling as well as methods for controlling false positives. The analysis documented in this report is a large-scale application of statistical outlier detection for determining unusual port-specific network behavior. The method uses a robust correlation measure to cluster related ports and to control for the background baseline traffic trend. A scaled, median-corrected process, called a Z-score, is calculated for the <b>hourly</b> <b>volume</b> measurements for each port. The Z-score measures how unusual each port 2 ̆ 7 s behavior is {{in comparison with the}} rest of the ports in its cluster. The researchers discuss lessons learned from applying the method to the hourly count of incoming flow records for a carrier-class network over a period of three weeks...|$|R
40|$|The {{development}} of freeway crash prediction models using intelligent transportation systems (ITS) archived data {{could be a}} substantial advancement {{in the field of}} real-time traffic management. Such models not only are expected to improve safety but also may {{go a long way to}} improve freeway operations by reducing incident-related congestion. Because there is a need to use real-time traffic data emanating from loop detectors, the approach differs distinctly from previous studies estimating crash frequencies or rates on a certain freeway section through aggregate measures of flow (such as average daily traffic or <b>hourly</b> <b>volumes).</b> Although the authors try to establish a relationship between the patterns in precrash data from detectors surrounding the crash location, it is imperative that the time of the historical crashes is known with precision. This feature proposes a shockwave and rule-based methodology to estimate the time of the crash and then identifies how much time and distance ahead of crash occurrence loop data may be used to predict the impending hazard. The final objective is to predict the possibility of crashes on freeways using real-time loop data...|$|R
40|$|Accident ratios are {{analysed}} {{with regard}} to the variables road surface skidding resistance and <b>hourly</b> traffic <b>volume.</b> It is concluded that the multiplicative model describes the data better than the additive model. Moreover that there is no interaction between skidding resistance and traffic volume in their effect on accident ratios. The pictures of the relation between accident ratios and both variables are shown and the statistics regarding the contribution of the variables...|$|R
30|$|Although <b>designed</b> for <b>hourly</b> load data, the {{proposed}} anomaly detection method may be equally applicable to other scenarios of anomalies in time series data, {{such as the}} weather data and renewable generation data. Further investigations {{on the design of}} more effective model-based real-time anomaly detection methods or robust VSTLF techniques are also of particular importance to the field.|$|R
40|$|Slow-moving vehicles, {{including}} agricultural vehicles, on arterial highways {{can cause}} serious delays to other traffic {{as well as}} posing an extra safety risk. This paper elaborates on a small-scale solution for these problems: the passing bay. It investigates the impacts of a passing bay on the total delay for other motorized vehicles, the number of passing manoeuvres and hindered vehicles, and the mean delay per hindered vehicle. The latter is also {{considered to be an}} indicator for traffic safety. The calculations are performed for two characteristic trips with a slow-moving vehicle. The passing bay is an effective solution to reducing delays on arterial highways when two-way <b>hourly</b> <b>volumes</b> exceed 600 ¿ 1000 vehicles. The effects depend on the trip length and speed of the slow-moving vehicle, and on the passing sight distance limitations of the road. A distance of 2 ¿ 4 ?km between the passing bays seems an acceptable compromise between the reduction of delay for other motorized vehicles and the extra discomfort and delay for drivers of slow-moving vehicles. This result also shows that passing bays are not effective in regions where slow-moving vehicles mainly make trips shorter than this distanc...|$|R
40|$|This study {{dealt with}} {{estimating}} AADT which serves the important basic data in transportation sector. AADT estimation {{is fundamental to}} the analysis of transportation data sets and the management of transportation systems. AADT is estimated using short-term traffic counts at most sites because permanent traffic counts is installed at limited sites. To estimate AADT, an adjustment factor application model was proposed on FHWA's Traffic Monitoring Guide in the United States. This model uses monthly or weekly adjustment factors to estimate AADT. Additionally, grouping with monthly factor, weekly factor and <b>hourly</b> <b>volume</b> pattern was proposed, but these methods don’t reflect characteristics of daily pattern. So this study used daily factor to estimate AADT and compared with advanced research. Daily factor is produced 365 factors on one permanent traffic count. Accuracy of AADT was enhanced using daily factor because it reflects daily characteristics as compared to monthly or weekly factors. But it is most important to assign a site to its similar site, because unsimilar assignment carries the greatest potential for significant estimation error. Assigning a short term traffic count to permanent traffic counts to apply adjustment factor will be investigated as a future study...|$|R
40|$|Three {{years of}} 300 kHz {{acoustic}} doppler current profiler data {{collected in the}} central Ligurian Sea are analysed to investigate the variability of the zooplankton biomass and the diel vertical migration in the upper thermocline. After a pre-processing phase aimed at avoiding the slant range attenuation, <b>hourly</b> <b>volume</b> backscattering strength time series are obtained. Despite the lack of concurrent net samples collection, different migration patterns are identified and their temporal variability examined by means of time–frequency analysis. The effect {{of changes in the}} environmental condition is also investigated. The highest zooplankton biomasses are observed in April–May just after the peak of surface primary production in March–April. The main migration pattern found here points to a "nocturnal" migration, with zooplankton organisms occurring deeper in the water column during the day and shallower at night. Also, twilight migration is highlighted during this study. The largest migrations are recorded in November–December, corresponding to lowest backscattering strength values and they are likely attributable to larger and more active organisms (i. e. euphausiids and mesopelagic fish). The results suggest further applications of the available historical acoustic doppler current profiler time series...|$|R
30|$|Hourly traffic {{data were}} {{obtained}} from two sources: Ministry of Transportation, Ontario (MTO) COMPASS system and permanent data count stations (PDCS). Both COMPASS and PDCS use loop detectors for collecting traffic data such as volume, speed, and density. The raw data from the sources were screened for any outliers caused by detector malfunction and then merged into <b>hourly</b> traffic <b>volume</b> data. In cases where multiple readings are available for a segment (e.g., from both sources and/or multiple detectors), average values are used.|$|R
30|$|This {{model was}} applied to a section of Kobe Route (Nishnomiya to Awaza), Hanshin expressway, Japan. Besides <b>hourly</b> traffic <b>volume</b> data, {{incident}} data for the entire year 2006 were collected and multiple linear regression analysis for entire year data was initially performed to know the functional and significance relation between the input and output variable. Further SRSM analysis {{has been carried out}} for working days data. Results shows that travel time distribution obtained using SRSM model is better than distribution obtained by the regression model.|$|R
40|$|Current duct design {{methods for}} {{variable}} air volume (VAV) systems {{are based on}} the use of peak constant airflow. However, VAV systems operate much of the time at an off-peak load condition and the impact of varying airflow rates to the sizing of duct systems has not been considered. This and a companion paper introduce an optimum duct design proce-dure for VAV systems to investigate the importance of the vary-ing airflows to the system <b>design.</b> <b>Hourly</b> airflow requirements, part-load fan characteristics, and duct static pressure control are incorporated into the problem formulation. Constraints, such as discrete duct sizes and velocity limitations, are incor-porated into the duct design procedure. In part 1, the domain of a VAV optimization problem is analyzed to define the prob-lem characteristics and to suggest an optimization procedure. In part 2, the VAV duct design procedure is fully developed and applied to several VAV duct systems with different parameter values. The results are analyzed to compare duct design meth-ods, and the effect of several factors that influence optimal design are investigated...|$|R
40|$|AbstractThe {{installation}} of calming measures {{on a road}} network is systematically planned way in general to reduce driving speeds, but also reduces the volume of through traffic on local and residential streets. When the demands of traffic calming exceed city resources, {{there is a need}} to prioritize or rank them. Asian countries, like Japan, Korea, Bangladesh and etc., do not have a prioritization system to apply in such cases. The objective of this research is to develop a point ranking system to prioritize traffic calming projects. Firstly paired comparison method was employed to obtain residents' opinions about the streets severity and needs of traffic calming treatment. A binary logistic regression model was developed to identify the factors of selecting streets for traffic calming. This model also explored the weight of variables during developing the point ranking system. The weights used in the point ranking system include vehicle speed, pedestrian generation, sidewalk condition and <b>hourly</b> vehicle <b>volume</b> per width (m) of street. Results suggest that the severity of street largely depends on the absence of sidewalks, which has a weight of 45 %, and high <b>hourly</b> vehicle <b>volume</b> of traffic per width (m) of street, which has a weight of 38 %. These outcomes are significant to develop the state of traffic safety in Japan and other Asian countries...|$|R
40|$|To {{assess the}} {{accident}} impacts of eliminating flashing traffic signal operations at intersections, a before-and-after study was {{undertaken by the}} Oakland County (Michigan) Road Commission. The study, designed to update and validate a preliminary study conducted in 1983, 1 analyzed accident data at intersections for the “before ” period, which had flashing signal operations at nighttime, and the “after ” period, which had 24 -hour full-cycle signal operations. The conclusions of the 1983 study included: 1. Right-angle accidents are significantly over-represented at four-Iegged arterial intersections when signals are in a flashing mode during nighttime hours. 2. Rear-end accident rates at flashing signal locations do not differ significantly from rear-end accident rates at full-cycle locations during late night hours. 3. Arterial intersections with nighttime <b>hourly</b> <b>volume</b> ratios of 2 : 1 or less have a significantly greater number of right-angle accidents than those with volume ratios of 4 : 1 or greater. 4. Drinking involvement in nighttime right-angle accidents at flashing signal locations is over-represented relative to full-cycle locations. 5. The freauency of right-angle accidents at flashi_ngsig~al loc~tions diminishes after 3 : 00 a. m. The major conclusion of the 1983 study was that eliminating nighttime flashing signal operations at four-legged intersections of two arterial roads appears {{to be effective in}} reducing rightangle accident frequency. As a result of this finding, the Board of Oaklan...|$|R
40|$|The {{installation}} of calming measures {{on a road}} network is systematically planned way in general to reduce driving speeds, but also reduces the volume of through traffic on local and residential streets. When the demands of traffic calming exceed city resources, {{there is a need}} to prioritize or rank them. Asian countries, like Japan, Korea, Bangladesh and etc., do not have a prioritization system to apply in such cases. The objective of this research is to develop a point ranking system to prioritize traffic calming projects. Firstly paired comparison method was employed to obtain residents' opinions about the streets severity and needs of traffic calming treatment. A binary logistic regression model was developed to identify the factors of selecting streets for traffic calming. This model also explored the weight of variables during developing the point ranking system. The weights used in the point ranking system include vehicle speed, pedestrian generation, sidewalk condition and <b>hourly</b> vehicle <b>volume</b> per width (m) of street. Results suggest that the severity of street largely depends on the absence of sidewalks, which has a weight of 45 %, and high <b>hourly</b> vehicle <b>volume</b> of traffic per width (m) of street, which has a weight of 38 %. These outcomes are significant to develop the state of traffic safety in Japan and other Asian countries...|$|R
