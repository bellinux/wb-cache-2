6|23|Public
5000|$|Separated columns: In {{the above}} example, {{individual}} columns are separated using whitespace characters. This is also called indentation or [...] "fixed-width" [...] data formatting. Another common convention is to separate columns using {{one or more}} <b>delimiter</b> <b>characters.</b> More complex solutions are markup and programming languages.|$|E
50|$|Formats {{that use}} delimiter-separated values (also DSV) store {{two-dimensional}} arrays of data by separating the values in each row with specific <b>delimiter</b> <b>characters.</b> Most database and spreadsheet programs {{are able to}} read or save data in a delimited format. Due to their wide support, DSV files {{can be used in}} data exchange among many applications.|$|E
50|$|Although principally {{used as a}} {{mechanism}} for text encoding of binary data,ASCII armoring is a programming and systems administration technique that also helps to avoid delimiter collision in some circumstances. This technique is contrasted from the other approaches described above {{because it is more}} complicated, and therefore not suitable for small applications and simple data storage formats. The technique employs a special encoding scheme, such as base64, to ensure that <b>delimiter</b> <b>characters</b> do not appear in transmitted data.|$|E
5000|$|... {{eliminates}} text searching (for the <b>delimiter</b> <b>character)</b> {{and therefore}} requires significantly less overhead ...|$|R
5000|$|D {{supports}} a few quoting delimiters, with such strings starting with [...] {{and ending with}} [...] or similarly for other <b>delimiter</b> <b>character</b> (any of (...) <> {} or [...] ). D also supports here document-style strings via similar syntax.|$|R
5000|$|There {{are many}} utility {{programs}} on Unix-style systems that {{can deal with}} at least some CSV files. Many such utilities {{have a way to}} change the <b>delimiter</b> <b>character,</b> but lack support for any other variations (or for Unicode). Some of the useful programs are: ...|$|R
5000|$|In {{canonical}} mode, {{data are}} accumulated {{in a line}} editing buffer, and do not become [...] "available for reading" [...] until line editing has been terminated by the user (at the terminal) sending a line delimiter character. Line <b>delimiter</b> <b>characters</b> are special characters, and they are end of file, end of line, and linefeed (ASCII [...] ). The former two are settable programmatically, whilst the latter is fixed. The latter two {{are included in the}} line editing buffer, whilst the former one is not.|$|E
5000|$|Within these general constraints, many {{variations}} are in use. Therefore, without {{additional information}} (such as whether RFC 4180 is honored), a file claimed {{simply to be}} in [...] "CSV" [...] format is not fully specified. As a result, many applications supporting CSV files allow users to preview the first few lines of the file and then specify the <b>delimiter</b> <b>character(s),</b> quoting rules, etc. If a particular CSV file's variations fall outside what a particular receiving program supports, it is often feasible to examine and edit the file by hand (i.e., with a text editor) or write a script or program to produce a conforming format.|$|E
3000|$|This grammar generates {{different}} {{variations of}} SQL injection attacks. It consists in inserting a tautology inside an expression evaluated by a WHERE clause, {{in such a}} way that this expression becomes a tautology itself. To inject the tautology, the initial expression is splitted into several pieces. The TAUTAG rules are examples of such tautologies and the INJECTION rules express how the tautology is included in an initial expression, (1) by closing the expression with <b>delimiter</b> <b>characters</b> (’, ~, or [...])), (2) by inserting the tautology (through a disjunction), and (3) by opening a new expression using the same <b>delimiter</b> <b>characters.</b>|$|E
50|$|Because {{delimiter}} collision is a {{very common}} problem, various methods for avoiding it have been invented. Some authors may attempt to avoid the problem by choosing a <b>delimiter</b> <b>character</b> (or sequence of characters) that {{is not likely to}} appear in the data stream itself. This ad hoc approach may be suitable, but it necessarily depends on a correct guess of what will appear in the data stream, and offers no security against malicious collisions. Other, more formal conventions are therefore applied as well.|$|R
50|$|A record {{oriented}} file {{has several}} advantages. After a program writes {{a collection of}} data as a record the program that reads that record has the understanding of that data as a collection. Although it is permitted to read {{only the beginning of}} a record, the next sequential read returns the next collection of data (record) that the writer intended to be grouped together. Another advantage is that the record has a length and there is no restriction on the bit patterns composing the data record, i.e. there is no <b>delimiter</b> <b>character.</b>|$|R
50|$|Most such files avoid {{delimiter}} collision {{either by}} surrounding all data fields in double quotes, or only quoting those data fields that contain the <b>delimiter</b> <b>character.</b> One problem with tab-delimited text files is that tabs {{are difficult to}} distinguish from spaces; therefore, there are sometimes problems with the files being corrupted when people try to edit them by hand. Another set of problems occur due to errors in the file structure, usually during import of file into a database (in the example above, such error may be a pupil's first name missing).|$|R
5000|$|In addition, {{the term}} [...] "CSV" [...] also denotes some closely related delimiter-separated formats that use {{different}} field delimiters. These include tab-separated values and space-separated values. A delimiter {{that is not}} present in the field data (such as tab) keeps the format parsing simple. These alternate delimiter-separated files are often even given a [...]csv extension despite {{the use of a}} non-comma field separator. This loose terminology can cause problems in data exchange. Many applications that accept CSV files have options to select the <b>delimiter</b> <b>character</b> and the quotation character.|$|R
5000|$|Since version 2.0, D has {{support for}} here document-style strings using the 'q' prefix character. These strings begin with [...] {{followed}} immediately by a newline (for an arbitrary identifier IDENT), {{and end with}} [...] {{at the start of}} a line.int main (...) { string list = q"IDENT1. Item One2. Item Two3. Item ThreeIDENT"; writef( [...] list [...] );}D also supports a few quoting delimiters, with similar syntax, with such strings starting with [...] and ending with [...] or similarly for other <b>delimiter</b> <b>character</b> (any of (...) <> {} or [...] ).|$|R
50|$|Using delimiters incurs some {{overhead}} {{in locating}} them {{every time they}} are processed (unlike fixed-width formatting), which may have performance implications. However, use of <b>character</b> <b>delimiters</b> (especially commas) is also a crude form of data compression which may assist overall performance by reducing data volumes — especially for data transmission purposes. Use of <b>character</b> <b>delimiters</b> which include a length component (Declarative notation) is comparatively rare but vastly reduces the overhead associated with locating the extent of each field.|$|R
50|$|Escape {{sequences}} are {{a general}} technique for represent characters that are otherwise difficult to represent directly, including <b>delimiters,</b> nonprinting <b>characters</b> (such as backspaces), newlines, and whitespace characters (which are otherwise impossible to distinguish visually), {{and have a}} long history. They are accordingly widely used in string literals, and adding an escape sequence (either to a single character or throughout a string) is known as escaping.|$|R
50|$|Atomic: The Sample UHID {{consists}} of a sixteen (16) digit sequential identifier, a one (1) <b>character</b> <b>delimiter,</b> a six (6) digit check-digit and a six (6) digit encryption scheme. It can function as a single compound data element.|$|R
5000|$|All {{printable}} ASCII {{characters are}} permitted in the attribute value. No characters {{need to be}} quoted with a [...] "`". In other words, the first unquoted equals sign in the TXT record is the name/value <b>delimiter.</b> All subsequent <b>characters</b> {{are part of the}} value.|$|R
50|$|Because of its escape sequences, and {{furthermore}} because its escape <b>delimiters</b> are printable <b>characters</b> in ASCII, it is {{fairly easy to}} construct attack byte sequences that round-trip from HZ to Unicode and back. Use of HZ encoding is thus treated as suspicious by malware protection suites.|$|R
5000|$|Option [...] {{specified}} {{a single}} <b>character</b> <b>delimiter</b> (in the example above it is a colon) {{which serves as}} field separator. Option [...] which specifies range of fields included in the output (here fields range from five till the end). Option [...] presupposes usage of option [...]|$|R
40|$|This paper {{studies the}} {{information}} {{content of the}} chromosomes of twenty-three species. Several statistics considering different number of bases for alphabet character encoding are derived. Based on the resulting histograms, word <b>delimiters</b> and <b>character</b> relative frequencies are identified. The knowledge of this data allows moving along each chromosome while evaluating the flow of characters and words. The resulting flux of information is captured by means of Shannon entropy. The results are explored in the perspective of power law relationships allowing a quantitative evaluation of the DNA of the species...|$|R
5000|$|When {{entering}} a regex in a programming language, {{they may be}} represented as a usual string literal, hence usually quoted; this is common in C, Java, and Python for instance, where the regex [...] is entered as [...] However, they are often written with slashes as delimiters, as in [...] for the regex [...] This originates in ed, where [...] is the editor command for searching, and an expression [...] {{can be used to}} specify a range of lines (matching the pattern), which can be combined with other commands on either side, most famously [...] as in grep ("global regex print"), which is included in most Unix-based operating systems, such as Linux distributions. A similar convention is used in sed, where search and replace is given by [...] and patterns can be joined with a comma to specify a range of lines as in [...] This notation is particularly well-known due to its use in Perl, where it forms part of the syntax distinct from normal string literals. In some cases, such as sed and Perl, alternative delimiters can be used to avoid collision with contents, and to avoid having to escape occurrences of the <b>delimiter</b> <b>character</b> in the contents. For example, in sed the command [...] will replace a [...] with an , using commas as delimiters.|$|R
5000|$|The Code 39 {{specification}} defines 43 characters, {{consisting of}} uppercase letters (A through Z), numeric digits (0 through 9) {{and a number}} of special characters (-, [...], $, /, +, %, and space). An additional character (denoted '*') is used for both start and stop <b>delimiters.</b> Each <b>character</b> is composed of nine elements: five bars and four spaces. Three of the nine elements in each character are wide (binary value 1), and six elements are narrow (binary value 0). The width ratio between narrow and wide is not critical, and may be chosen between 1:2 and 1:3.|$|R
50|$|Comma-separated {{values is}} a data format that pre-dates {{personal}} computers {{by more than}} a decade: the IBM Fortran (level H extended) compiler under OS/360 supported them in 1972. List-directed ("free form") input/output was defined in FORTRAN 77, approved in 1978. List-directed input used commas or spaces for <b>delimiters,</b> so unquoted <b>character</b> strings could not contain commas or spaces.|$|R
40|$|Creative Commons Attribution License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. This paper studies the information {{content of the}} chromosomes of twenty-three species. Several statistics considering different number of bases for alphabet character encoding are derived. Based on the resulting histograms, word <b>delimiters</b> and <b>character</b> relative frequencies are identified. The knowledge of this data allows moving along each chromosome while evaluating the flow of characters and words. The resulting flux of information is captured by means of Shannon entropy. The results are explored in the perspective of power law relationships allowing a quantitative evaluation of the DNA of the species. 1...|$|R
50|$|These {{versions}} of MLX shared a format consisting of six data bytes in decimal format, plus a seventh byte {{which served as}} a checksum. Although each line began with the memory address, and bytes were separated with commas, these {{did not have to}} be typed; the program auto-incremented the address and automatically printed the comma <b>delimiters</b> every three <b>characters.</b> Invalid keystrokes were filtered out. When a line was completely typed, it was automatically verified against the checksum value. If it matched, the user would be prompted for the next line. If not, a warning buzzer would sound and the invalid input would be discarded so that the user could retype the line. Several keyboard keys were redefined to create a makeshift numeric keypad.|$|R
50|$|On Unix platforms, the ISO 2022 7-bit {{encodings}} {{were replaced}} {{by a set of}} 8-bit encoding schemes, the Extended Unix Code: EUC-JP, EUC-CN and EUC-KR. Instead of distinguishing between the multiunit sequences and the singletons with escape sequences, which made the encodings stateful, multiunit sequences were marked by having the most significant bit set, that is, being in the range 80-FF (hexadecimal), while the singletons were in the range 00-7F alone. The lead units and trail units were in the range A1 to FE (hexadecimal), that is, the same as their range in the ISO 2022 encodings, but with the high bit set to 1. These encodings were reasonably easy to work with provided all your <b>delimiters</b> were ASCII <b>characters</b> and you avoided truncating strings to fixed lengths, but a break {{in the middle of a}} multibyte character could still cause major corruption.|$|R
40|$|AbstractGenotype list (GL) Strings use {{a set of}} {{hierarchical}} <b>character</b> <b>delimiters</b> {{to represent}} allele and genotype ambiguity in HLA and KIR genotypes in a complete and accurate fashion. A RESTful web service called genotype list service was created to allow users to register a GL string and receive a unique identifier for that string {{in the form of}} a URI. By exchanging URIs and dereferencing them through the GL service, users can easily transmit HLA genotypes in a variety of useful formats. The GL service was developed to be secure, scalable, and persistent. An instance of the GL service is configured with a nomenclature and can be run in strict or non-strict modes. Strict mode requires alleles used in the GL string to be present in the allele database using the fully qualified nomenclature. Non-strict mode allows any GL string to be registered as long as it is syntactically correct. The GL service source code is free and open source software, distributed under the GNU Lesser General Public License (LGPL) version 3 or later...|$|R
40|$|The {{main goal}} of this {{contribution}} is to present a program that allows the com-position of variable-sized curved symbols such as those occurring in mathemat-ics. This application, called CurExt, extends {{the capabilities of the}} well-known system TEX designed by D. E. Knuth for typesetting. Big delimiters, such as brackets, or special curved symbols, such as the Arabic mathematical symbol of sum, can be built automatically according to the size and the shape of the con-cerned mathematical expression. CurExt will make it possible to stretch Arabic letters according to calligraphic rules in order to draw the kashida. It follows a useful tool for justifying texts written with Arabic alphabet. Unlike in Latin alphabet based writing, where the justication is done through inserting small blanks among characters, cursive writing lls in the space between characters with the kashida. The problem Variable-sized symbols Besides xed size symbols, such as characters of Latin alphabet in a given font or basic mathematical symbols (e. g., +, ¡), there are symbols with a context dependant size. Some mathematical symbols, such as <b>delimiters</b> or Arabic <b>characters,</b> are examples of these variable-sized symbols. The variation of size can concern: the width of the symbol, such as in: the various parts of some symbols (e. g.,E or,)). A horizontal stretching, according to the expression covered by the operator, is sometimes necessary; the kashida for some characters of the Arabic alphabet (e. g.,,) or certain Arabic mathematical symbols such as th-ose found in the abbreviations of usual fun-ctions (e. g.,,,) in mathematical expressions. The kashida, a small curve, is used to stretch some characters in order to cover the concerned mathematical expression or to break the line when the left margin is reached; some diacritics or accents (e. g., abc; abc; cabc; fabc;Ã¡abc;¡!abc; z}|{abc; abc|{z} o...|$|R

