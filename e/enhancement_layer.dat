378|261|Public
50|$|For example, {{the figure}} depicts a {{layering}} scheme with QPSK base layer, and a 16QAM <b>enhancement</b> <b>layer.</b> The first layer is 2 bits (represented by the green circles). The signal detector only needs to establish which quadrant the signal is in, {{to recover the}} value (which is '10', the green circle in the lower right corner). In better signal conditions, the detector can establish the phase and amplitude more precisely, to recover four more bits of data ('1101'). Thus, the base layer carries '10', and the <b>enhancement</b> <b>layer</b> carries '1101'.|$|E
50|$|MDC {{is a form}} of data partitioning, thus {{comparable}} to layered coding as it is used in MPEG-2 and MPEG-4. Yet, in contrast to MDC, layered coding mechanisms generate a base layer and n enhancement layers. The base layer is necessary for the media stream to be decoded, enhancement layers are applied to improve stream quality. However, the first <b>enhancement</b> <b>layer</b> depends on the base layer and each <b>enhancement</b> <b>layer</b> n + 1 depends on its subordinate layer n, thus can only be applied if n was already applied. Hence, media streams using the layered approach are interrupted whenever the base layer is missing and, as a consequence, the data of the respective enhancement layers is rendered useless. The same applies for missing enhancement layers. In general, this implies that in lossy networks the quality of a media stream is not proportional to the amount of correctly received data.|$|E
50|$|For a hierarchically-modulated symbol with QPSK {{base layer}} and 16QAM <b>enhancement</b> <b>layer,</b> the base-layer {{throughput}} loss {{is up to}} about 1.5bits/symbol with the total receive signal-to-noise ratio (SNR) at about 23 dB, about the minimum needed for the comparable non-hierarchical modulation, 64QAM. But unlayered 16QAM with the same SNR would approach full throughput. This means, due to ILI, about 1.5/4 = 37.5% loss of the base-layer achievable throughput. Furthermore, due to ILI and the imperfect demodulation of base-layer symbols, the demodulation error rate of higher-layer symbols increases too.|$|E
30|$|A {{scalable}} bitstream {{consists of}} a number of layers, including a base layer and one or more <b>enhancement</b> <b>layers</b> [9]. The base layer can be decoded independently and provides the elementary video quality. A higher quality can be obtained by decoding the base <b>layer</b> plus <b>enhancement</b> <b>layers,</b> improving the perception of the decoded sequence as more <b>enhancement</b> <b>layers</b> are used. There are three modes of video scalability: spatial scalability, temporal scalability, and quality or signal-noise-ratio (SNR) scalability.|$|R
30|$|SVC {{combined}} with an AMC scheme provides an excellent solution to wireless multicast video streaming [18 – 23]. An SVC stream has one base layer and one or more <b>enhancement</b> <b>layers.</b> The base layer provides the minimum quality, frame rate, and resolution of the video, while the <b>enhancement</b> <b>layers</b> represent the same video with gradually increasing quality, frame rate, or resolution. To {{address the issue of}} the low data rate due to the users with the worst channel quality, we can apply the different modulation and coding sets to the different layers of the scalable video sequence, such that the users in good channel conditions receive more <b>enhancement</b> <b>layers</b> to obtain better video quality, while the users in bad channel conditions receive fewer <b>enhancement</b> <b>layers</b> {{on the top of the}} basic video quality.|$|R
5000|$|Progressive <b>enhancement,</b> <b>layering</b> {{technologies}} such that more features are added for successively more powerful clients.|$|R
5000|$|... 2D Plus Delta (AKA 2D+Delta) is {{a method}} of {{encoding}} 3D image listed {{as a part of}} MPEG2 and MPEG4 standards, specifically on the H.264 implementation of Multiview Video Coding extension. This technology originally started as a proprietary method for Stereoscopic Video Coding and content deployment that utilizes the Left or Right channel as the 2D version and the optimized difference or disparity (Delta) between that image channel view and a second eye image view is injected into the videostream as user_data, secondary stream, independent stream, <b>enhancement</b> <b>layer</b> or NALu for deployment. The Delta data can be either a spatial stereo disparity, temporal predictive, bidirectional or optimized motion compensation.|$|E
5000|$|... x265 {{supports}} the Main, Main 10, Main 12 and Main Still Picture profiles of HEVC (including intra-only profiles), utilizing a bit depth of either 8 bits or 10 {{bits per sample}} YCbCr with 4:2:0, 4:2:2 or 4:4:4 chroma subsampling. x265 supports most {{of the features of}} x264 including all rate control modes (Constant QP, Constant Rate Factor, Average Bit Rate, 2-pass or multi-pass and Video Buffering Verifier rate control). Visual quality algorithms include CU-Tree (the successor to x264's macroblock-tree), adaptive quantization, b-pyramid, weighted prediction and psycho-visual optimizations (psy-rd and psy-rdoq). A fully lossless mode is also supported. Temporal scalability is supported, allowing for a video to be encoded into a base layer HEVC bitstream that is half the frame rate of the input video frame rate, and an <b>enhancement</b> <b>layer</b> that can be decoded along with the base layer to enable playback at the full frame rate.|$|E
50|$|This codec {{has been}} {{designed}} to provide better quality and more flexibility than the existing ITU-T G.729 speech coding standard.G.729.1 is scalable in bit rate, acoustic bandwidth and complexity.In addition it offers various encoder and decoder modes, including the support of both 8 and 16 kHz input/output sampling frequency, compatibility with G.729B, and reduced algorithmic delay.The bitstream of G.729.1 is structured into 12 hierarchical layers.The first layer (or core layer) at 8 kbit/s follows the G.729 format.The second layer (adds 4 kbit/s for a total of 12 kbit/s) is a narrowband <b>enhancement</b> <b>layer.</b> The third layer (2 kbit/s for a total of 14 kbit/s) is a bandwidth extension layer. Further layers (in 2 kbit/s steps) are wideband enhancement layers.The G.729.1 output bandwidth is 50-4000 Hz at 8 and12 kbit/s, and 50-7000 Hz from 14 to 32 kbit/s. G.729.1 is also known as G.729 Annex J and G.729EV where EV stands for Embedded Variable (bit rate).|$|E
3000|$|CMTMultiReliable. CMT-SCTP transmission, with {{base and}} <b>enhancement</b> <b>layers</b> using {{different}} streams, both with reliable transmission [...]...|$|R
3000|$|SCTPReliable. Baseline SCTP transmission, with {{base and}} <b>enhancement</b> <b>layers</b> {{using the same}} stream with {{reliable}} transmission [...]...|$|R
3000|$|RTPMulti. RTP transmission, with {{base and}} <b>enhancement</b> <b>layers</b> being sent {{through the first}} and second interfaces, {{respectively}} [...]...|$|R
3000|$|... {{equal to}} one {{normalized}} unit which is 512 kbps. The transmission {{rates of the}} base layer, the first <b>enhancement</b> <b>layer,</b> and the second <b>enhancement</b> <b>layer</b> are equal to 2, 1, and 1 units, respectively. We set the QoS requirements, which are successful transmission probabilities, to 0.90, 0.80, and 0.70 for the base layer, the first <b>enhancement</b> <b>layer,</b> and the second <b>enhancement</b> <b>layer,</b> respectively. Therefore, each s-d pair transmits four sublayers, [...]...|$|E
40|$|This paper proposes an <b>enhancement</b> <b>layer</b> {{truncation}} {{scheme for}} the Fine-Granularity-Scalability (FGS) video. Our target is {{to minimize the}} quality variation of different parts within each frame when the last transmitted <b>enhancement</b> <b>layer</b> is truncated according to the available network bandwidth. This paper proposes an <b>enhancement</b> <b>layer</b> truncation scheme for the Fine-Granularity-Scalability (FGS) video. Our target is to minimize the quality variation of different parts within each frame when the last transmitted <b>enhancement</b> <b>layer</b> is truncated according to the available network bandwidth...|$|E
40|$|Abstract—Lossless coding is {{necessary}} especially for profes-sional applications like medical imaging. Furthermore, often scalable lossless transmission is desired. In this paper, {{a method for}} lossless compression of an <b>enhancement</b> <b>layer</b> called “Sample-based weighted prediction for <b>Enhancement</b> <b>Layer</b> Coding” (SELC) is proposed. While the base layer is formed by lossy HEVC coding, the <b>enhancement</b> <b>layer</b> consists of the recon-struction residual of the base layer, which is compressed using intra picture prediction and entropy coding. This allows to send the <b>enhancement</b> <b>layer</b> for particular selected pictures only. Experimental results show that SELC achieves up to 7. 3 % bitrate saving for the compressed <b>enhancement</b> <b>layer</b> compared to the SHVC test model SHM- 2. 1 (5. 3 % on average). Furthermore, the encoding {{as well as the}} decoding times using the SELC approach are considerably faster. I...|$|E
30|$|Quality (SNR) scalability. The {{base layer}} is coded {{at a low}} quality. By adding <b>enhancement</b> <b>layers,</b> {{the quality of the}} decoded {{sequences}} can be increased.|$|R
30|$|Spatial scalability. The {{base layer}} is coded {{at a low}} spatial {{resolution}}. By adding <b>enhancement</b> <b>layers,</b> {{the resolution of the}} decoded sequence can be increased.|$|R
40|$|SURVEILLANCE APPLICATIONS Surveillance codestreams coded by H. 264 /SVC (scalable video cod-ing), which {{consists}} of one base layer and one or more <b>enhancement</b> <b>layers,</b> supply flexible and various quality, resolution, and temporal (sub) codestreams such that clients with different network bandwidth and terminal devices can seamlessly access them. In this paper, we present a robust authentication scheme for {{them in order to}} in-sure the integrity of SVC surveillance codestreams, named AUSSC (Authenticating SVC Surveillance Codestreams). AUSSC exploits cryptographic-based authentication for base layer and content-based authentication for <b>enhancement</b> <b>layers.</b> For content-based authen...|$|R
40|$|Abstract—A novel estimation-theoretic (ET) {{approach}} is developed for optimal <b>enhancement</b> <b>layer</b> prediction, in spatially scalable video coding (SVC), which incorporates motion compensation at the <b>enhancement</b> <b>layer,</b> with both current and future information from the base layer. It is inspired by the early ET framework (originated in our group) for quality (SNR) scalability, which achieved optimal <b>enhancement</b> <b>layer</b> prediction by fully accounting for information from the current base layer (e. g., the quantization intervals) and the <b>enhancement</b> <b>layer,</b> to efficiently calculate the conditional expectation that forms the optimal predictor. Central to that approach {{was the fact that}} all layers reconstruct approximations to the same original transform coefficient. This, however, is not the case in spatial scalability, where the layers encode different resolution versions of the signal. To approach optimal <b>enhancement</b> <b>layer</b> prediction, the current work departs from existing spatial SVC schemes that employ pixel-domain resampling and causal prediction. Instead, it integrates a transform domain resampling technique that makes the base layer quantization intervals and reconstructions accessible to and usable at the <b>enhancement</b> <b>layer.</b> The {{approach is}} extended for an SVC framework that allows delay in <b>enhancement</b> <b>layer</b> coding relative to the base layer, and achieves optimal delayed prediction, in conjunction with spatial SVC. Simulations provide experimental evidence that the overall proposed approach substantially outperforms existing spatially scalable coders. I...|$|E
40|$|In this paper, {{we propose}} a new algorithm, which {{utilizes}} the <b>enhancement</b> <b>layer</b> prediction to further improve the coding efficiency of current Fine Granularity Scalability (FGS) defined in MPEG- 4. The proposed algorithm adaptively uses (1) the previously reconstructed <b>enhancement</b> <b>layer</b> macroblock after motion compensation along with (2) current reconstructed base layer macroblock and (3) {{the combination of}} both to form the predicted marcoblock for current <b>enhancement</b> <b>layer.</b> The new algorithm is designed so that other error drifting reduction methods {{can be used to}} avoid drifting problem due to prediction from the <b>enhancement</b> <b>layer.</b> In addition, the proposed algorithm can re-use the implemented B-frame hardware to form the <b>enhancement</b> <b>layer</b> predicted frame. Simulation results show that about 1 dB gain in PSNR can be achieved while comparing to the current FGS algorithm at moderate to high bit rates. Thus, the proposed algorithm is a cost efficient solution to improve the coding efficiency of fine granularity scalability. 1...|$|E
40|$|A {{video encoder}} system {{includes}} a base layer and an <b>enhancement</b> <b>layer</b> for encoding video data. The base layer encodes a reduced quality {{version of the}} video data to obtain base layer data. The <b>enhancement</b> <b>layer</b> encodes the video data using energy-concentrating transform operations, nested scalar quantization, and Raptor encoders. The base layer data and <b>enhancement</b> <b>layer</b> data are transmitted through a channel to a video decoder system. The decoder system decodes the base layer data to recover {{an estimate of the}} reduced quality video and decodes the <b>enhancement</b> <b>layer</b> data (using the reduced quality video as side information) to obtain blocks of coset indices. The decoder system then operates on the blocks of coset indices to generate estimates of the original video data...|$|E
40|$|A {{scalable}} video coding (SVC) codestream {{consists of}} one base layer and possibly several <b>enhancement</b> <b>layers.</b> The base layer, which contains the lowest quality and resolution images, {{is the foundation of}} the SVC codestream and must be delivered to recipients, whereas <b>enhancement</b> <b>layers</b> contain richer contour/texture of images in order to supplement the base layer in resolution, quality, and temporal scalabilities. This paper presents a novel hybrid authentication (HAU) scheme. The HAU employs both cryptographic authentication and content-based authentication techniques to ensure integrity and authenticity of the SVC codestreams. Our analysis and experimental results indicate that the HAU is able to detect malicious manipulations and locate the tampered image regions while is robust to content-preserving manipulations for <b>enhancement</b> <b>layers.</b> Although our focus in this paper is on authenticating H. 264 /SVC codestreams, the proposed technique is also applicable to authenticate other scalable multimedia contents such as MPEG- 4 fine grain scalability and JPEG 2000 codestreams...|$|R
40|$|Surveillance codestreams coded by H. 264 /SVC (scalable video coding), which {{consists}} of one base layer and one or more <b>enhancement</b> <b>layers,</b> supply flexible and various quality, resolution, and temporal (sub) codestreams such that clients with different network bandwidth and terminal devices can seamlessly access them. In this paper, we present a robust authentication scheme for {{them in order to}} insure the integrity of SVC surveillance codestreams, named AUSSC (Authenticating SVC Surveillance Codestreams). AUSSC exploits cryptographic-based authentication for base layer and content-based authentication for <b>enhancement</b> <b>layers.</b> For content-based authentication, AUSSC extracts full features from the first frame of each GOP (group of picture) and partial features from “active” macroblocks of other frames. Performance analysis indicates that AUSSC is robust to content-preserving manipulations and sensitive to content-changing manipulations of <b>enhancement</b> <b>layers.</b> Compared with cryptographic-based and watermarking-based authentication schemes, experimental results show that AUSSC causes less computation complexity and smaller compression overhead. Thus, it appears that AUSSC is suitable for real time SVC surveillance applications...|$|R
3000|$|In our {{allocation}} model, we take D^i={D_ 1 ^i,D_ 2 ^i,...,D_M_i^i} as the weigh and {{the value}} for items of base <b>layer</b> and <b>enhancement</b> <b>layers.</b> We regard set A=A [...]...|$|R
40|$|Abstract. Intra 4 × 4 mode {{decision}} has correlation between <b>enhancement</b> <b>layer</b> and base layer in {{scalable video coding}} (SVC). In this paper, a new intra mode decision algorithm is proposed based on this correlation and the proximity of prediction directions of nine Intra 4 × 4 prediction modes. This method is used in <b>enhancement</b> <b>layer</b> to decrease the mode numbers in <b>enhancement</b> <b>layer.</b> Experiments show that the proposed algorithm can save 27. 52 % encoding time on average with negligible PSNR change and small bit-rate loss...|$|E
40|$|This paper {{focuses on}} {{prediction}} optimality in spatially scalable video coding. It {{is inspired by}} the earlier estimation-theoretic prediction framework developed by our group for quality (SNR) scalability, which achieved optimality by fully accounting for relevant information from the current base layer (e. g., quantization intervals) and the <b>enhancement</b> <b>layer,</b> to efficiently calculate the conditional expectation that forms the optimal predictor. It was central to that approach that all layers reconstruct approximations to the same original transform coefficient. In spatial scalability, however, the layers encode different resolution versions of the signal. To approach optimality in <b>enhancement</b> <b>layer</b> prediction, the current work departs from existing spatially scalable codecs that employ pixel-domain resampling to perform inter-layer prediction. Instead, it incorporates a transform-domain resampling technique that ensures that the base layer quantization intervals are accessible and usable at the <b>enhancement</b> <b>layer,</b> which in conjunction with prior <b>enhancement</b> <b>layer</b> information, enable optimal prediction. Simulations provide experimental evidence that the proposed approach achieves substantial <b>enhancement</b> <b>layer</b> coding gains over the standard. Index Terms — Spatial scalability, scalable video coding, estimation-theoretic prediction, transform domain resampling 1...|$|E
40|$|A video coder {{performs}} a motion-compensated prediction {{both in the}} base layer and in an <b>enhancement</b> <b>layer</b> to determine motion data of the <b>enhancement</b> <b>layer</b> by using the motion data from the base layer and/or to predict sequences of residual error pictures after the motion-compensated prediction in the <b>enhancement</b> <b>layer</b> by using sequences of residual error pictures from the base layer via an intermediate layer predictor. On the decoder side, an intermediate layer combiner is used for canceling this intermediate layer prediction. Thereby, the data rate is improved compared to scalability schemes without intermediate layer prediction with the same picture quality...|$|E
30|$|Network coding {{has shown}} great {{potential}} to improve throughput, delay, {{and quality of}} services in wireless networks [1 – 10]. These merits of network coding make it an attractive candidate for multimedia applications [7 – 9]. In this paper, {{we are interested in}} utilizing network coding in real-time scalable video applications [11, 12], which compress video frames in the form of one base <b>layer</b> and several <b>enhancement</b> <b>layers.</b> The base layer provides the basic video quality, and the <b>enhancement</b> <b>layers</b> provide successive improved video qualities. Using such a scalable video stream, the sender adapts the video bit rate compatible to the available network bandwidth by sending the base layer and as many <b>enhancement</b> <b>layers</b> as possible. Moreover, the real-time scalable video has two distinct characteristics. First, it has a hard deadline before which the video layers need to be decoded to be usable at the application. Second, the video layers exhibit a hierarchical order such that a video layer can be decoded only if this layer and all its lower layers are received. Even though scalable video can tolerate the loss of one or more <b>enhancement</b> <b>layers,</b> this adversely affects the video quality experienced by viewers. Therefore, it is desirable to design network coding schemes so that the received packets before the deadline contribute to decoding the maximum number of video layers.|$|R
40|$|In the Scalable Video Coding (SVC) standard, a {{multi-layer}} based {{structure is}} utilised to support scalability. However {{in the latest}} Joint Scalable Video Model (JSVM) reference software, the rate control algorithm is implemented only in the base <b>layer,</b> and the <b>enhancement</b> <b>layers</b> are not equipped with a rate control scheme. In this work, a novel rate control algorithm is proposed for when inter-layer prediction is employed. Firstly, a Rate-Quantisation (R-Q) model, which considers the coding properties of different prediction modes, is described. Secondly, an improved Mean Absolute Difference (MAD) prediction model for the spatial <b>enhancement</b> <b>layers</b> is proposed, in which the encoding results from the base layer are used to assist the linear MAD prediction in the spatial/CGS <b>enhancement</b> <b>layers.</b> Simulation results show that, on average, rate control accuracy is maintained to within 0. 07 %. Compared with the default JVT-G 012 rate control scheme employed in SVC, the proposed rate control algorithm achieves higher coding efficiency, namely an improvement of up to 0. 26 dB in PSNR and a saving of 4. 66 % in bitrate...|$|R
40|$|In Scalable Video Coding (SVC), {{inter-layer}} {{prediction is}} utilized {{to improve the}} coding efficiency of the <b>enhancement</b> <b>layers.</b> However the rate control scheme in the Joint Scalable Video Model (JSVM) software lacks consideration {{of the implications of}} inter-layer prediction as it was designed for non-scalable video encoders. In this work, a novel rate control algorithm is proposed for when inter-layer prediction is employed in SVC. Firstly, a Rate-Quantization (R-Q) model for inter-layer prediction coding of the spatial <b>enhancement</b> <b>layers</b> is developed. Secondly, an optimized Mean Absolute Difference (MAD) prediction model for spatial <b>enhancement</b> <b>layers</b> is proposed, that considers the MAD from previous temporal frames and previous spatial frames together. Simulation results show that rate control accuracy is maintained to within 0. 07 % on average. Compared with the default rate control algorithm employed in SVC, namely the JVT-G 012 rate control scheme, the proposed algorithm improves the average PSNR by up to 0. 26 dB or produces an average saving in bit rate of up to 4. 66 %...|$|R
40|$|This paper proposes an <b>enhancement</b> <b>layer</b> {{truncation}} {{scheme for}} the Fine-Granularity-Scalability (FGS) video. Our target is {{to minimize the}} quality variation of different parts within each frame when the last transmitted <b>enhancement</b> <b>layer</b> is truncated according to the available network bandwidth. We propose to redistribute the bits in the <b>enhancement</b> <b>layer</b> {{that can only be}} partially kept with the available bit-budget so that it is able to cover the whole frame area to raise the quality of different parts uniformly. Simulation results confirm the effectiveness of the proposed method in improving the decoded visual quality and reducing the intra-frame quality variation...|$|E
30|$|The <b>enhancement</b> <b>layer</b> is {{designed}} {{based on the}} CD and SD saliency.|$|E
40|$|Leaky {{prediction}} layered video coding (LPLC) partially {{includes the}} <b>enhancement</b> <b>layer</b> in the motion compensated prediction loop, {{by using a}} leaky factor between 0 and 1, to balance the coding efficiency and error resilience performance. In this paper, rate distortion functions are derived for LPLC from rate distortion theory. Closed form expressions are obtained for two scenarios of LPLC, one where the <b>enhancement</b> <b>layer</b> stays intact and the other where the <b>enhancement</b> <b>layer</b> suffers from data rate truncation. The rate distortion performance of LPLC is then evaluated with respect to different choices of the leaky factor, demonstrating that the theoretical analysis well conforms with the operational results...|$|E
40|$|In this paper, {{we present}} a {{rate-distortion}} optimal hybrid scalable/multiple-description video codec. Traditional scalable codecs produce bitstreams which can be partitioned into layers that form a hierarchy. Thus, {{in order for a}} particular layer to be useful to the decoder, all hierarchically higher layers also need to be available. Conversely, traditional multiple description codecs produce layers with no hierarchy. Thus, any of the layers can be decoded by itself and produce a video sequence of a certain quality. The more layers are available to the decoder, the better the corresponding video quality. The drawback of multiple description coding is that layers need to be correlated at the expense of compression efficiency. We propose a hybrid scalable/multiple description codec which produces a base layer and two multiple description <b>enhancement</b> <b>layers.</b> The base layer is required for decoding. If {{one or two of the}} multiple description <b>enhancement</b> <b>layers</b> are also received, the SNR of the received video sequence is improved. There is no hierarchy in the multiple description <b>enhancement</b> <b>layers.</b> The layers are constructed using a rate-distortion optimal partitioning of the DCT coefficients. Experimental results are presented and conclusions are drawn...|$|R
40|$|We {{propose to}} improve the packet loss {{resilience}} of scalable video coding. An algorithm for optimal coding mode selection for the base and <b>enhancement</b> <b>layers</b> is developed, which limits error propagation due to packet loss, while retaining compression efficiency. We first derive a method to estimate the overall decoder distortion, which includes the effects of quantization, packet loss and error concealment employed at the decoder. The estimate accounts for temporal and spatial error propagation due to motion compensated prediction, and computes the expected distortion precisely per pixel. The distortion estimate is incorporated within a rate-distortion framework to optimally select the coding mode as well as quantization step size for the macroblocks in each layer. Simulation results show substantial performance gains for both base and <b>enhancement</b> <b>layers...</b>|$|R
40|$|Although very {{effective}} when addressing some given setup requirements, this standard is not suited {{to deal with}} heterogeneous networks and devices. Current video transmitting services have to face various decoding contexts, with various device screen sizes, computing abilities and network bandwidths. Existing solutions re-encode one specific video stream for each target set-up, causing storage and bandwidth wastage. The new MPEG- 4 Scalable Video Coding (SVC) standard [10] provides more flexible video streams, which contain several layers. A base layer is first encoded, then improved using spatial, temporal and fidelity/quality <b>enhancement</b> <b>layers.</b> Spatial <b>enhancement</b> <b>layers</b> increase the frame resolution and address variable screen sizes. Temporal layers {{increase the number of}} frames per second and add smoothness to the video motion. Qualit...|$|R
