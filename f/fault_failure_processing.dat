0|965|Public
40|$|Abstract — Within {{the last}} few years, smart grid {{has been one of}} major trends in the {{electric}} power industry and has gained popularity in electric utilities, research institutes and communication companies. As applications for smart grid become more distributed and complex, the probability of faults undoubtedly increases. This fact has motivated to construct dependable distributed systems for smart grid. However, dependable distributed systems are difficult to build. They present challenging problems to system designers. In this paper, we first examine the question of dependability and identify major challenges during the construction of dependable systems. Next, we attempt to present a view on the fault tolerance techniques for dependable distributed systems. As part of this view, we present the distributed tolerance techniques for the construction of dependable distributed applications in smart grid. Subsequently, we propose a systematic solution based on the middleware that supports dependable distributed systems for smart grid and study the combination of reflection and dependable middleware. Finally, we draw our conclusions and points out the future directions of research. Index Terms—smart grid, dependability, dependable middleware, fault-tolerance, <b>fault,</b> error, <b>failure,</b> error <b>processing,</b> <b>fault</b> treatment, replication, distributed recovery, partitioning, open implementation, reflection, inspection, adaptation I...|$|R
40|$|Abstract. Arc {{suppression}} coil {{has been}} applied widely in power system. It focuses on the fault that arc suppression coil often appears in the process, and divides {{to the nature of}} the faults. We also take corresponding treatment methods for different faults at the same time. This article introduces the <b>failure</b> <b>processing</b> methods of the arc suppression coil in detail, expounding respectively that the general <b>failure</b> <b>processing</b> methods, the abnormal <b>failure</b> <b>processing</b> methods of arc suppression coil, the action <b>failure</b> <b>processing</b> methods and the discontinued <b>failure</b> <b>processing</b> methods...|$|R
40|$|A Turing {{machine with}} <b>faults,</b> <b>failures</b> and {{recovery}} (TMF) is described. TMF is (weakly) non-deterministic Turing machine consisting of five semi-infinite tapes (Master Tape, Synchro Tape, Backup Tape, Backup Synchro Tape, User Tape) and four controlling components (Program, Daemon, Apparatus, User). Computational process {{consists of three}} phases (Program Phase, Failure Phase, Repair Phase). C++ Simulator of a Turing machine with <b>faults,</b> <b>failures</b> and recovery has been developed. Comment: 8 pages; C++ Simulator has been develope...|$|R
40|$|International audienceIn this paper, an {{evaluation}} approach of recoverable performance for post-fault quadrotors is investigated. Both propeller <b>faults</b> and <b>failures</b> are considered, such as loss of partial propeller effectiveness {{and loss of}} one or more propellers. The main contribution is to propose a method to compute recoverable set for different faulty conditions using sum of squares (SOS). The recoverable set is an invariant set and it is the set of initial states, which can be driven to the equilibrium point while respecting propeller <b>faults,</b> <b>failures</b> and rotating speed limits. Before computing the set, feasible equilibrium points are calculated to guarantee relaxed hover solutions against different faulty cases. Simulations illustrate the effectiveness of proposed approach with nonlinear quadrotor dynamics under various <b>fault</b> and <b>failure</b> conditions...|$|R
40|$|In {{software}} companies today {{we see a}} trend of changing development processes, as well as test processes, {{in order to reduce}} the number of faults in their software; and by reducing the number of faults, reducing the number of failures. It is hard to know if a change to a process has a positive or negative effect on the <b>faults</b> and <b>failures</b> of the software. Measuring the total number of <b>faults</b> and <b>failures</b> is a way of telling if the process has been changed for better or worse. The problem with measuring all faults in a software project is that it takes a lot of reviewing and testing. To know how many failures can be provoked from the software, the software needs to be run for a long time after release. In both these instances the information on the total number of <b>faults</b> or <b>failures</b> of the software is simply available too late. The use of <b>fault</b> and <b>failure</b> prediction and estimation methods allows project members and managers to get information about the total number of <b>faults</b> and <b>failures</b> of the software. The predictions and estimations can be repeated at different points during a development project. The contribution of the thesis consists of models and methods for <b>fault</b> and <b>failure</b> prediction and estimation. In this thesis three new methods of easy, early and cost-efficient <b>fault</b> and <b>failure</b> prediction and estimation are presented. The methods are created to take in new information as it becomes available, and are not meant for point estimates or predictions, but to continuously follow-up the estimates and predictions. The three methods presented are a first step towards the creation of a framework for <b>fault</b> and <b>failure</b> estimation and prediction. The framework consists of estimation and prediction models used at different points throughout a project. The goal of the framework is to be able to follow, and continuously improve the estimates and predictions of <b>faults</b> and <b>failures</b> in software projects...|$|R
40|$|Forecasting <b>fault</b> <b>failure</b> is a {{fundamental}} but elusive goal in earthquake science. Here we show that by listening to the acoustic signal emitted by a laboratory fault, machine learning can predict the time remaining before it fails with great accuracy. These predictions are {{based solely on the}} instantaneous physical characteristics of the acoustical signal, and do not make use of its history. Surprisingly, machine learning identifies a signal emitted from the fault zone previously thought to be low-amplitude noise that enables failure forecasting throughout the laboratory quake cycle. We hypothesize that applying this approach to continuous seismic data may lead to significant advances in identifying currently unknown signals, in providing new insights into fault physics, and in placing bounds on <b>fault</b> <b>failure</b> times. Comment: 17 pages, 4 figure...|$|R
5000|$|Enables the {{assessment}} of multiple, co-existing <b>faults</b> and <b>failures</b> ...|$|R
40|$|In this paper, an {{evaluation}} approach of recoverable performance for post-fault quadrotors is investigated. Both propeller <b>faults</b> and <b>failures</b> are considered, such as loss of partial propeller effectiveness {{and loss of}} one or more propellers. The main contribution is to propose a method to compute recoverable set for different faulty conditions using sum of squares (SOS). The recoverable set is an invariant set and it is the set of initial states, which can be driven to the equilibrium point while respecting propeller <b>faults,</b> <b>failures</b> and rotating speed limits. Before computing the set, feasible equilibrium points are calculated to guarantee relaxed hover solutions against different faulty cases. Simulations illustrate the effectiveness of proposed approach with nonlinear quadrotor dynamics under various <b>fault</b> and <b>failure</b> conditions. European Union; Ministerio de Economia y Competitividad; Research Center for Sypervision, Safety and Automatic Control (CS 2 AC); Universitat Politecnica de Catalunya (UPC...|$|R
40|$|Abstract: We {{present an}} {{overview}} of current research in automotive software metrics data collection, focusing on efforts underway in the software development in terms of <b>faults,</b> <b>failures</b> and changes. Using some new techniques, {{we are able to}} collect accurate data so that we can easily measure our project errors free and also taking very less time and efforts. Such new techniques can be used by software analyst/engineer can easily extract and evaluate data in flexible manner. Generally, raw data concern with most common problems such as faults, errors, defects, anomalies and bugs. In this regards we apply some new automotive techniques for software metrics data collection so that we can easily define data and collect data in appropriate way. In this research paper we also define some observation of software development, testing, system operation and maintenance problems in terms of <b>faults,</b> <b>failures</b> and changes. Whenever a problem is observed, its key elements are automatically recorded, and finally we can investigate causes and cures in appropriate way...|$|R
40|$|This paper {{presents}} {{a case study}} of <b>fault</b> and <b>failure</b> data from two consecutive releases of a large telecommunication system. In this context {{it is important to have}} clear interpretations of errors, <b>faults</b> and <b>failures.</b> Thus, we would like to make the following distinction between them. Errors are made by humans, which may result in faults in the software. The faults may manifest themselve...|$|R
40|$|International audienceAn {{intelligent}} transmitter reliability {{study has}} to deal with several issues: various interactions between both material elements and functions; behaviors of components as programmable units and software which are difficult to predict when <b>faults</b> or <b>failures</b> occur, as well as the consequences on functions processing. A “ 3 -step model” is therefore proposed to include both functional and material aspects, using Goal Tree–Success Tree (GTST), and setting <b>faults</b> and <b>failures</b> as a third full part. Then, Master Logic Diagrams (MLD) aim to represent several types of relationships between <b>faults</b> or <b>failures,</b> material elements, and functions. Probabilities are used for MLD components to take the indeterminate relationships into account. Quantitative assessments are then performed, using an infrared gas transmitter as an example: total relationships between any <b>fault</b> or <b>failure</b> and any function, probabilities of malfunction and failure modes. Moreover, uncertainty analyses show that even if input relationship data are uncertain, precise results can be obtained. These properties make the proposed model especially suitable for evaluating the reliability of intelligent transmitters. Finally, some design issues are discussed, taking advantage of the proposed model...|$|R
40|$|Assembly process-induced {{dimensional}} variation {{has a significant}} impact on product quality and functionality. The complexity of modern products coupled with part compliance/flexibility frequently results in ill-conditioned assembly systems further adding to the challenges of process control and <b>fault</b> <b>failure</b> diagnosis. This paper proposes an enhanced piecewise least squares (EPLS) -based approach for dimensional <b>fault</b> <b>failure</b> diagnosis of ill-conditioned multistation assembly systems. In this approach, predetermined fault patterns derived from an inverse stiffness matrix of assembly structures and fault patterns obtained from product measurement data are used to detect and isolate dimensional failures caused by fixturing error(s). The EPLS-based diagnostic methodology searches for a set of components called latent vectors with thesearch constrained by assembly response function, the stream of variation analysis (SOVA) model of an assembly system, which performs decomposition of response based on the end-of-line measurements. The verification of the proposed methodology is conducted based on a beam-based model of a multistation assembly process with compliant parts and includes diagnosis of both single and multiple fault scenarios. © IMechE 2012...|$|R
40|$|An {{intelligent}} transmitter reliability {{study has}} to deal with several issues: various interactions between both material elements and functions; behaviors of components as programmable units and software which are difficult to predict when <b>faults</b> or <b>failures</b> occur, as well as the consequences on functions processing. A “ 3 -step model ” is therefore proposed to include both functional and material aspects, using Goal Tree–Success Tree (GTST), and setting <b>faults</b> and <b>failures</b> as a third full part. Then, Master Logic Diagrams (MLD) aim to represent several types of relationships between <b>faults</b> or <b>failures,</b> material elements, and functions. Probabilities are used for MLD components to take the indeterminate relationships into account. Quantitative assessments are then performed, using an infrared gas transmitter as an example: total relationships between any <b>fault</b> or <b>failure</b> and any function, probabilities of malfunction and failure modes. Moreover, uncertainty analyses show that even if input relationship data are uncertain, precise results can be obtained. These properties make the proposed model especially suitable for evaluating the reliability of intelligent transmitters. Finally, some design issues are discussed, taking advantage of the proposed model. 1...|$|R
50|$|Failures in {{hardware}} can {{be caused}} by random faults or systematic <b>faults,</b> but <b>failures</b> in software are always systematic.|$|R
5000|$|Fault management, {{where the}} Stateflow chart {{is used to}} control how the system {{responds}} to <b>faults</b> and <b>failures</b> within a system ...|$|R
50|$|Finally, a PST cannot always {{differentiate}} between different <b>faults</b> or <b>failures</b> within the valve and actuator assembly thus limiting the diagnostic capability.|$|R
40|$|The <b>fault</b> and <b>failure</b> {{models as}} well as their {{semantics}} within the VLSI and the distributed systems/algorithms community are quite different. Pointing out the mismatch of those <b>fault</b> respectively <b>failure</b> models is the main part of this work. The impact of the implemented failure model in terms of hardware effort and system complexity will be shown on different VLSI implementations of distributed algorithms. However, still, {{there are a lot of}} open questions left mostly related to the coverage analysis of hardware implemented fault-tolerant algorithms...|$|R
40|$|The {{interlocking}} {{systems are}} typically resisting against hazardous <b>faults.</b> <b>Failure</b> {{effect on the}} system can be determined directly by monitoring the original system installation, by simulation of the system operation using its model, or by computing or theoretical reasoning. The process of system ageing can be described {{with the help of}} the random failure time. Essential majorities of computer-based interlocking system elements are electronic elements that are not exposed to mechanical wear. The failure distribution of these elements is assumed to be exponential.      </p...|$|R
40|$|Wireless Sensor Networks (WSNs) aretypically resource-constrained {{and battery}} driven. Theyare usually {{deployed}} in hostile and inaccessibleenvironments to perform monitoring and tracking. Therefore, {{due to their}} physical deployment locationsensor nodes are very prone to <b>faults</b> and <b>failures.</b> Inrecent years, much {{work has been done}} on the variousaspects of the WSNs, especially fault management. Fault management is concerned with detecting,diagnosing, isolating and resolving <b>faults</b> and <b>failures.</b> Thereby, a network's management system with anefficient fault management platform makes the networkfault tolerant in the events of <b>faults</b> and <b>failures.</b> In thiscontext, many solutions have been proposed for faultmanagement in WSNs. However, hierarchicalarchitecture based schemes have proven to be moreefficient as compare to centralized and distributedschemes. This paper aims to overview hierarchicalarchitecture based schemes for fault management inWSNs. We critically analyze their effectiveness andshort comings for large-scale WSNs. We believethrough such an exercise provides a great backgroundto establish new and effective fault managementsolutions for WSNs...|$|R
30|$|Avoiding system/component {{malfunctions}} {{and failures}} {{because of the}} difficulties in detecting, diagnosing, and mitigating hardware <b>faults</b> and <b>failures</b> in-flight with the existing technologies. These failures can imply catastrophic accidents.|$|R
5000|$|... #Subtitle level 2: Recalls, engine <b>failures,</b> <b>faults</b> and {{problems}} ...|$|R
40|$|Peer to peer {{systems are}} the {{networks}} {{consisting of a}} group of nodes possible to be as wide as the Internet. These networks are required of evaluation mechanisms and distributed control and configurations, so each peer will be able to communicate with other peers. Resilience to <b>faults,</b> <b>failures</b> and attacks, are the main requirements of most communication systems and networks today. Thus, since P 2 P networks can be individually used as an infrastructure and an alternative for many other communication networks, they have to be more reliable, and resilient to the <b>faults,</b> <b>failures</b> and attacks compared to the client and server approach. In this work, we present a detailed study on the behavior of various P 2 P networks toward <b>faults</b> and <b>failures,</b> and focus on fault-tolerance subject. We consider two different static failure scenarios: a) a random strategy in which nodes or edges of the network will be removed with an equal probability and without any knowledge of the networks infrastructure, b) a targeted strategy that uses some information about the nodes, and in which the nodes with the highest degree have the most priority to be attacked. By static faults, we mean a situation where the nodes or components encounter some faults before the network starts to work or through its operation, and will remain faulty {{to the end of the}} work session. Our goal is to introduce various measures to analyzing P 2 P networks evaluating their vulnerability rate. The presented criteria can be used for evaluating the reliability and vulnerability of P 2 P networks toward both random and targeted failures. There is no limit to the number and types of failures, the presented measures are able to be used for different types of failures and even a wide range of networks...|$|R
5000|$|Exception Handling [...] - [...] where <b>failures</b> in <b>processing</b> {{can result}} in an {{alternate}} pipeline being processed ...|$|R
40|$|International audienceThis paper {{proposes a}} {{reliable}} control allocation scheme for fault tolerant control {{to guarantee the}} dependability of the system. The reliability of the actuators {{is used by the}} control allocation scheme to redistribute the control signals to the remaining actuators when a <b>fault</b> or <b>failure</b> occurs. The paper provides a presentation of the reliability importance measures and degradation model used to represent the reliability. The control allocation scheme shows that actuators <b>faults</b> and/or <b>failures</b> can be handled easily. A benefit of incorporate the reliability indicators on the over-actuated control system design is to improve the safety of the system...|$|R
40|$|Metadata only entryThis paper proposes {{an on-line}} {{sliding mode control}} {{allocation}} scheme for fault tolerant control. The effectiveness level of the actuators {{is used by the}} control allocation scheme to redistribute the control signals to the remaining actuators when a <b>fault</b> or <b>failure</b> occurs. The paper provides an analysis of the sliding mode control allocation scheme and determines the nonlinear gain required to maintain sliding. The on-line sliding mode control allocation scheme shows that faults and even certain total actuator failures can be handled directly without reconfiguring the controller. The simulation results show good performance when tested on different <b>fault</b> and <b>failure</b> scenarios...|$|R
5000|$|Automatic or manual? Some {{tools are}} {{built into a}} product, to {{automatically}} collect data when a <b>fault</b> or <b>failure</b> occurs. Other tools have to be specifically invoked to start the data collection process.|$|R
40|$|Journal ArticleThis paper proposes {{an on-line}} {{sliding mode control}} {{allocation}} scheme for fault tolerant control. The effectiveness level of the actuators {{is used by the}} control allocation scheme to redistribute the control signals to the remaining actuators when a <b>fault</b> or <b>failure</b> occurs. The paper provides an analysis of the sliding mode control allocation scheme and determines the nonlinear gain required to maintain sliding. The on-line sliding mode control allocation scheme shows that faults and even certain total actuator failures can be handled directly without reconfiguring the controller. The simulation results show good performance when tested on different <b>fault</b> and <b>failure</b> scenarios. © 2008 Elsevier Ltd. All rights reserved. EPSR...|$|R
5000|$|Adequate {{labor for}} PMS {{diagnostics}} or <b>fault</b> indicators for <b>failure</b> modes that lack PMS ...|$|R
30|$|Fault tolerance: {{refers to}} the ability of the {{protocol}} to continue work or operate even under some <b>faults</b> or <b>failures</b> properly. This can be done through adding new entities (multi-LMA or multi-home-agent) to prevent the point of failure.|$|R
40|$|In this paper, we {{investigate}} production induced microseismicity based on modelling material failure from coupled fluid-flow and geomechanical simulation. The {{model is a}} graben style reservoir characterized by two normal faults subdividing a sandstone reservoir into three compartments. The results are analysed in terms of spatial and temporal variations in distribution of material failure. We observe that material failure and hence potentially microseismicity is sensitive to not only fault movement but also fluid movement across faults. For sealing <b>faults,</b> <b>failure</b> is confined to the volume {{in and around the}} well compartment, with shear failure localized along the boundaries of the compartment and shear-enhanced compaction failure widespread throughout the reservoir compartment. For non-sealing <b>faults,</b> <b>failure</b> is observed within and surrounding all three reservoir compartments as well as a significant distribution located near the surface of the overburden. All shear-enhanced compaction failures are localized within the reservoir compartments. Fault movement leads to an increase in shear-enhanced compaction events within the reservoir as well as shear events located within the side-burden adjacent to the fault. We also evaluate the associated moment tensor mechanisms to estimate the pseudo scalar seismic moment of failure {{based on the assumption that}} failure is not aseismic. The shear-enhanced compaction events display a relatively normal and tight pseudo scalar seismic moment distribution centred about 106 Pa, whereas the shear events have pseudo scalar seismic moments that vary over three orders of magnitude. Overall, the results from the study indicate that it may be possible to identify compartment boundaries based on the results of microseismic monitoring...|$|R
40|$|Abstract. The {{vacuum system}} control {{strategy}} based on event-driven approach is considered for monitoring startup status, stable operation status, shutdown status and <b>failure</b> <b>processing</b> of {{transmission electron microscope}} (TEM). Hierarchical structure is adopted so as to reasonably compartmentalize the vacuum control tasks. For startup operation, control logic flow of vacuum system is designed by event-based control mode. Finally, through the actual operation of the test {{results indicate that the}} vacuum control system fulfills design requirements and the event-based control mode is effective. 1...|$|R
40|$|We {{describe}} {{a set of}} seismological observations on the foreshock sequence preceding the April 6 th 2009, Mw 6. 3, L’Aquila earthquake. The dense configuration of the seismic network in the epicenter area and the occurrence of a long foreshock sequence provide {{the opportunity for a}} detailed reconstruction of the preparatory phase of the main shock. Approaching the earthquake, we observe clear variations of the seismic wave propagation properties. The elastic properties of rocks in the fault region undergo a sharp change about a week before the earthquake. From our observations we infer that a complex sequence of dilatancy-diffusion processes takes place and that fluids {{play a key role in}} the <b>fault</b> <b>failure</b> process...|$|R
40|$|Metadata only entryThis paper {{considers}} a model reference based {{sliding mode control}} allocation scheme for fault tolerant control. The scheme uses equal distribution of the control signals to all actuators even when a <b>fault</b> or <b>failure</b> occurs, and assumes no FDI is available. The paper analyzes the scheme and determines conditions under which closed-loop stability is retained for a certain class of <b>faults</b> and <b>failures.</b> It is shown that faults and even certain total actuator failures can be handled directly without reconfiguring the controller. The results obtained from implementing the controller on the SIMONA research flight simulator, configured to represent a large transport aircraft under the ELAL flight 1862 scenario, shows good performance in both nominal and failure scenarios...|$|R
40|$|Abstract: Today most of {{the people}} depend on {{electronic}} devices or handheld devices. With rapid changes in hardware and software, it affects cost, size, complexity and features of system. Due to increase complexity, <b>faults</b> and <b>failures</b> also increase/decrease in a same manner. Various disaster and the accidents are the examples of failure software. Author focus on the causes of failure and try to build chain models for various error, <b>fault</b> and <b>failure.</b> Software reliability are used for different purposes: system reliability estimation during development, decision making, maintenance recommendation and proposed for new version. In this paper, author tried to collect all the information related to failure of the software and establish the various chain models...|$|R
40|$|In this paper, {{we propose}} a {{statistical}} theoretical framework for incorporation of sensor and actuator faults in dynamic simulations of wastewater treatment operation. Sensor and actuator <b>faults</b> and <b>failures</b> are often neglected in simulations for control strategy development and testing, {{although it is}} well known that they represent a significant obstacle for realising control at full-scale facilities. The framework for incorporating <b>faults</b> and <b>failures</b> is based on Markov chains and displays the appealing property of easy transition of sensor and actuator history into a model for fault generation. The paper briefly describes Markov theory and how this is used together with models for sensor and actuator dynamics to achieve a realistic simulation of measurements and actuators...|$|R
40|$|This report {{gives an}} {{introduction}} to reliability assessment of crane operations. It defines the reliability of cranes, the reliability indices for cranes and their parts, as well as possible <b>faults,</b> <b>failure</b> and errors. Moreover, it describes {{the basic elements of}} crane configurations and the main components of crane safety systems. This involves error identification, error classification, error causes, reliability analysis, task analysis, event trees and fault tree analysis. Some standard analysis models are presented. The report focuses on the reliability of both physical cranes and crane operators. A systematic approach to error influence modelling is presented as well. Furthermore, some foundational aspects of failure interpretation are discussed. REPORT NO. ROSS (NTNU) 20070...|$|R
