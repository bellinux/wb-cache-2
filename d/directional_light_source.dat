26|10000|Public
2500|$|Version 0.7.3 was {{the first}} public release of Kerbal Space Program, and was {{released}} on 24 June 2011. It was downloaded over 5,000 times. The version lacked many features present in later versions, such as a stability assist mode. Kerbin did not rotate, {{and the sun was}} simply a <b>directional</b> <b>light</b> <b>source.</b> There were no fuel flow mechanics, no control surfaces, and no other celestial bodies. Later versions added additional planets and moons, as well as the ability to load and save collections of parts, known as [...] "subassemblies". Tutorials were also added at this stage.|$|E
50|$|A <b>directional</b> <b>light</b> <b>source</b> {{illuminates}} {{all objects}} equally from a given direction, like an area light of infinite size and infinite {{distance from the}} scene; there is shading, but cannot be any distance falloff.|$|E
5000|$|Version 0.7.3 was {{the first}} public release of Kerbal Space Program, and was {{released}} on 24 June 2011. It was downloaded over 5,000 times. The version lacked many features present in later versions, such as a stability assist mode. Kerbin did not rotate, {{and the sun was}} simply a <b>directional</b> <b>light</b> <b>source.</b> There were no fuel flow mechanics, no control surfaces, and no other celestial bodies. Later versions added additional planets and moons, as well as the ability to load and save collections of parts, known as [...] "subassemblies". Tutorials were also added at this stage.|$|E
40|$|We {{present a}} novel {{approach}} for estimating <b>lighting</b> <b>sources</b> from a single image of a scene that is illuminated by near point <b>light</b> <b>sources,</b> <b>directional</b> <b>light</b> <b>sources</b> and ambi-ent <b>light.</b> We propose to employ a pair of reference spheres as light probes and introduce the difference sphere that we acquire by differencing the intensities of two image regions of the reference spheres. Since the effect by <b>directional</b> <b>light</b> <b>sources</b> and ambient <b>light</b> is eliminated by differencing, the key advantage of considering the difference sphere is that it enables us to estimate near point <b>light</b> <b>sources</b> including their radiance, which {{has been difficult to}} achieve in previ-ous efforts where only distant <b>directional</b> <b>light</b> <b>sources</b> were assumed. We also show that analysis of gray level contours on spherical surfaces facilitates separate identification of multiple combined <b>light</b> <b>sources</b> and is well suited to the dif-ference sphere. Once we estimate point <b>light</b> <b>sources</b> with the difference sphere, we update the input image by elim-inating their influence and then estimate other remaining <b>light</b> <b>sources,</b> that is, <b>directional</b> <b>light</b> <b>sources</b> and ambient <b>light.</b> We demonstrate the effectiveness of the entire algo-rithm with experimental results. 1...|$|R
40|$|We {{propose a}} {{framework}} that captures multiple high dynamic range environment maps and decomposes them into sets of <b>directional</b> <b>light</b> <b>sources</b> in real-time. The environment maps, captured and processed on stand-alone devices (e. g. Nokia N 900 smartphone), are available to rendering engines via a server that provides wireless access. We compare three different importance sampling techniques {{in terms of the}} quality of sampling pattern, temporal coherence, and performance. Furthermore, we propose a novel idea of merging the <b>directional</b> <b>light</b> <b>sources</b> from multiple cameras by interpolation. We then discuss the pros and cons when using multiple cameras...|$|R
50|$|OpenGL is {{used for}} {{rendering}} due to its high efficiency in managing small batches, storing each model in a display list thus avoiding communication overheads. Additional vertex load is given by applying two <b>directional</b> <b>light</b> <b>sources</b> ideally located infinitely far away.|$|R
30|$|In this study, we aim a {{general-purpose}} {{quality evaluation}} that {{is independent of}} shading and material properties. Therefore, information about the material properties, light sources, etc. are not available. A <b>directional</b> <b>light</b> <b>source</b> from left-above of the scene is assumed {{in accordance with the}} human visual system’s assumptions ([21], section 24.4. 2).|$|E
40|$|Abstract — The {{research}} work reported here deals with landscape illumination techniques. We describe {{a new technique}} for computing the terrain shadows (illumination). We try to augment the realism without augmenting considerably the algorithm’s complexity and without using global illumination model. In this paper we will first discuss the main {{research work}}s made in the landscape lighting area, we will explain the outdoor lighting of terrain in the real world, and give two techniques for simulating these lighting in real time; the first is very fast but not realistic, the second one treat the sun as a simple <b>directional</b> <b>light</b> <b>source,</b> except {{for the possibility of}} partial occlusion but a very heavy phase to calculate the horizon angles is necessary. We present after our approach...|$|E
30|$|The {{study of}} a coin’s {{features}} has traditionally been conducted by direct hands-on examination, employing magnification tools and a strong <b>directional</b> <b>light</b> <b>source.</b> By holding the coin under the light, and tilting it relative to the viewing direction, the surface features may be discerned. Unfortunately, security concerns due to the ease of concealment, lack of unique identification, and often high resale value severely limit opportunities for this method of examination. When coins are secured in glass cabinets, even those employing mirrors and magnifying optics, the ability to perceive surface relief is significantly reduced. The quality of numismatic {{information that can be}} gleaned from a coin decreases further if in-person examination is not possible. Traditional photographic documentation conveys only a subset of the information discernible through direct physical inspection [4].|$|E
50|$|The {{laser diode}} {{is the most}} common type of laser {{produced}} with a wide range of uses that include fiber optic communications, barcode readers, laser pointers, CD/DVD/Blu-ray Disc reading and recording, laser printing, laser scanning and increasingly <b>directional</b> <b>lighting</b> <b>sources.</b>|$|R
40|$|The effects {{produced}} in an image by cast shadows {{can be quite}} complex, especially when light comes from all directions. This {{makes it difficult to}} recover the illumination from a scene and recognize objects from the images. In this paper, we show that such images can be well approximated using much simpler lighting represented by a combination of low frequency spherical harmonics, and a small number of directional sources. Therefore, the illumination of the scene can be recovered by summing the spherical harmonic lighting and a small number of <b>directional</b> <b>light</b> <b>sources.</b> To demonstrate the effectiveness of the proposed method, we have successfully tested it by using sets of synthesized images rendered by <b>directional</b> <b>light</b> <b>sources</b> or environment maps with different objects...|$|R
40|$|We {{present a}} novel {{approach}} for estimating <b>light</b> <b>sources</b> from a single image of a scene that is illuminated by major near point <b>light</b> <b>sources,</b> a few <b>directional</b> <b>light</b> <b>sources</b> and ambient <b>light.</b> We propose to employ a pair of reference spheres as light probes and introduce the difference sphere that we acquire by differencing the inten-sities of two image regions of the reference spheres. Because the effect by <b>directional</b> <b>light</b> <b>sources</b> and ambient <b>light</b> is eliminated by differencing, the key advantage of considering the difference sphere is that it enables us to identify near point <b>light</b> <b>sources</b> including their radiant intensities. We also show that analysis of gray level contours on spherical surfaces facilitates separate identification of multiple combined <b>light</b> <b>sources</b> and is well suited to the difference sphere. We demonstrate the effec-tiveness of the entire algorithm with experimental results while also investigating the applicability to an open scanner in indoor scene. Key words: Difference sphere, inverse <b>lighting,</b> near <b>light</b> <b>source,</b> contour representation, open scanner PACS:...|$|R
40|$|We {{present a}} new {{technique}} which enables direct volume rendering based on 3 D texture mapping hardware, enabling shading as well as classification of the interpolated data. Our technique supports accurate lighting for a one <b>directional</b> <b>light</b> <b>source,</b> semi-transparent classification, and correct blending. To circumvent the limitations of one general classification, we introduce multiple classification spaces which are very valuable to understand the visualized data, and even mandatory to comprehensively grasp the 3 D relationship of different materials present in the volumetric data. Furthermore, we illustrate how multiple classification spaces can be realized using existing graphics hardware. In contrast to previously reported algorithms, our technique is capable of performing all the above mentioned tasks within the graphics pipeline. Therefore, it is very efficient: The three dimensional texture needs to be stored only once and no load is put onto the CPU. Besides using standard OpenGL [...] ...|$|E
40|$|More {{details on}} [URL] The {{original}} publication {{is available at}} www. springerlink. comInternational audienceIn this paper, we present a complete framework for recovering an object shape, estimating its reflectance properties and light sources from a set of images. The whole process is performed automatically. We use the shape from silhouette approach proposed by R. Szeliski in [40] combined with image pixels for reconstructing a triangular mesh according to the marching cubes algorithm. A classification process identifies regions of the object having the same appearance. For each region, a single point or <b>directional</b> <b>light</b> <b>source</b> is detected. Therefore, we use specular lobes, lambertian regions of the surface or specular highlights seen on images. An identification method jointly (i) decides what light sources are actually significant and (ii) estimates diffuse and specular coefficients for a surface represented by the modi- fied Phong model [25]. In order to validate our algorithm ef- ficiency, we present a case study with various objects, light sources and surface properties. As shown in the results, our system proves accurate even for real objects images obtained with an inexpensive acquisition system...|$|E
40|$|Most {{illuminant}} estimation algorithms {{work with}} the assumption of one specific type of the light source (e. g. point light source or <b>directional</b> <b>light</b> <b>source).</b> This assumption brings up two main limitations which significantly restrict {{the applicability of the}} algorithms: First, the knowledge about the type of the light source presented in the scene is needed a priori; second, it can not handle complex scenes where multiple different types of light sources co-exist. To overcome these limitations, we remove the assumption about the source type and develop a general light source model for all different types of light sources. Based on this general light source model, we propose a unified framework to estimate multiple illuminants of different types. Within the framework, we use an experiment setup where a calibration sphere with a specular surface is utilized to probe the scene illuminants and a novel ray tracing and matching algorithm is devised to estimate the light source parameters. Experiment results demonstrate the accuracy of our method on a variety of real images. ...|$|E
40|$|Návrh rendrovací {{pipeline}} pro syntézu digitálních hologramů podporující trojúhelníkové sítě, směrová světla, textury a pokročilé osvětlovací modely. This paper {{describes a}} rendering pipeline for digital hologram synthesis. The pipeline {{is capable of}} handling triangle meshes, <b>directional</b> <b>light</b> <b>sources,</b> texture coordinates and advanced illumination models. Due to the huge computational requirements of hologram synthesis only the HPO holograms are considered...|$|R
40|$|This paper {{describes}} a rendering pipeline for digital hologram synthesis. The pipeline {{is capable of}} handling triangle meshes, <b>directional</b> <b>light</b> <b>sources,</b> texture coordinates and advanced illumination models. Due to the huge computational requirements of hologram synthesis only the HPO holograms are considered. Categories and Subject Descriptors (according to ACM CCS) : line/surface removal; Color, shading, shadowing, and textur...|$|R
40|$|Most {{illuminant}} estimation algorithms {{worked on}} point <b>light</b> <b>sources</b> or <b>directional</b> <b>light</b> <b>sources.</b> Little attempt has been made, however, to estimate area <b>light</b> <b>sources.</b> In this paper, {{we present a}} novel scheme that estimates the size and location of multiple area <b>light</b> <b>sources</b> using a set of stereo images of a sphere with a shiny surface. The parameters of the area <b>light</b> <b>source</b> are estimated by a novel algorithm which minimizes the matching error between the corresponding specular patches. Experiments on real images show that our method is accurate and robust in estimating {{the parameters of the}} area <b>light</b> <b>source...</b>|$|R
40|$|In this paper, {{we present}} a {{complete}} framework for recovering an object shape, estimating its reflectance properties and light sources from a set of images. The whole process is performed automatically. We use the shape from silhouette approach proposed by R. Szeliski (1993) combined with image pixels for reconstructing a triangular mesh according to the marching cubes algorithm. A classification process identifies regions of the object having the same appearance. For each region, a single point or <b>directional</b> <b>light</b> <b>source</b> is detected. Therefore, we use specular lobes, lambertian regions of the surface or specular highlights seen on images. An identification method jointly (i) decides what light sources are actually significant and (ii) estimates diffuse and specular coefficients for a surface represented by the modified Phong model (Lewis, 1994). In order to validate our algorithm efficiency, {{we present a}} case study with various objects, light sources and surface properties. As shown in the results, our system proves accurate even for real objects images obtained with an inexpensive acquisition system...|$|E
40|$|In {{this work}} we propose {{a method that}} {{facilitates}} transport of a material appearance between objects depicted in two different images. The approach consists of two steps performed on both the material and original images, capturing the object material, and the object of interest itself. The diffuse and specular reflection components are separated by removing specular highlights from the material image. The diffuse components of both images are then used to obtain the surface normals of depicted objects by application of shape from shading algorithm (SFS). The robustness of the method is limited mostly by precise estimations of surface normals and the light direction needed to acquire a reflectance of depicted objects. As this process contains some ambiguities, we do some assumptions about the scene depicted in these images. We assume the objects are lit by a single white <b>directional</b> <b>light</b> <b>source,</b> and object’s diffuse color is not a white. We also assume that there are specular highlights depicted within the images. We have validated the method by a transfer of a real car paints onto an image of abstract 3 D shape...|$|E
40|$|We {{present a}} theory that {{addresses}} the problem of determining shape from the (small or differential) motion of an object with unknown isotropic reflectance, under arbitrary unknown distant illumination, for both orthographic and perpsective projection. Our theory imposes fundamental limits on the hardness of surface reconstruction, independent of the method involved. Under orthographic projection, we prove that three differential motions suffice to yield an invariant that relates shape to image derivatives, regardless of BRDF and illumination. Under perspective projection, we show that four differential motions suffice to yield depth and a linear constraint on the surface gradient, with unknown BRDF and lighting. Further, we delineate the topological classes up to which reconstruction may be achieved using the invariants. Finally, we derive a general stratification that relates hardness of shape recovery to scene complexity. Qualitatively, our invariants are homogeneous partial differential equations for simple lighting and inhomogeneous for complex illumination. Quantitatively, our framework shows that the minimal number of motions required to resolve shape is greater for more complex scenes. Prior works that assume brightness constancy, Lambertian BRDF or a known <b>directional</b> <b>light</b> <b>source</b> follow as special cases of our stratification. We illustrate with synthetic and real data how potential reconstruction methods may exploit our framework. 1...|$|E
40|$|Realism in image {{synthesis}} increases signicantly when real-world lighting captured into environment maps (EM) {{is used to}} illumi-nate rendered scenes. Tremendous {{progress in}} the development and accessibility of high dynamic range (HDR) video cameras enable direct capturing of HDR video environment maps (VEM). In this work we present an interactive system for fully dynamic lighting of a scene using captured HDR VEM. The key component of our system is an algorithm for efcient decomposition of HDR VEM into a set of representative <b>directional</b> <b>light</b> <b>sources,</b> which can be used for the direct lighting computation with shadows on graphics hardware. The resulting lights have favorable properties in terms of ickering reduction and their number can be adaptively changed to keep a constant framerate while good spatial distribution (strati-cation) properties are maintained. We can handle a large number of <b>light</b> <b>sources</b> with shadows using novel techniques, which reduce the cost of BRDF-based shading and visibility computations. VEM Decomposition into <b>Directional</b> <b>Light</b> <b>Sources</b> For the HDR VEM acquisition we use a photometrically calibrated HDRC VGAx (IMS CHIPS) camera with a sh-eye lens. We de-compose each captured EM into a set of <b>directional</b> <b>light</b> <b>sources,</b> which are well suited for the shadow computation and shading us-ing graphics hardware. In our decomposition approach we treat the pixel luminance values in the EM as a discrete 2 D probabil-ity density function (PDF) and we draw samples (<b>light</b> <b>source</b> di-rections) from this distribution following procedures established in the Monte Carlo literature. For this purpose we select our inverse transform method [HDS 03], which exhibits unique continuity and uniformity properties that are desirable in our application. The method guarantees the bicontinuity property for any non-negative PDF, which means that a small change in the input sample position over the unit square is always transformed into a small change in the resulting position of <b>light</b> <b>source</b> over the EM hemisphere. The uniformity property is important to achieve a good stratication of the resulting <b>light</b> <b>source</b> directions...|$|R
40|$|In this paper, {{we present}} a novel, hardwareaccelerated {{approach}} to compute the visibility between surface points and <b>directional</b> <b>light</b> <b>sources.</b> Thus, our method provides a first-order approximation of the rendering equation in graphics hardware. This is done by accumulating depth tests of vertex fragments as seen {{from a number of}} light directions. Our method does not need any preprocessing of the scene elements and introduces no memory overhead. Besides of the handling of large polygonal models, it is suitable for deformable or animated objects under time-varying high-dynamic range illumination at interactive frame rates. ...|$|R
40|$|For highly diffuse rendering, some {{materials}} {{like snow}} are commonly accomplished {{through the use}} of simplified local illumination models for ambient and diffuse light. In reality, however, for a given point on a surface, the incident light is not only contributed from <b>directional</b> <b>light</b> <b>sources,</b> but also from backscattering from nearby surfaces. To account for this effect, a new technology has been developed, using Curvature Maps for Rendering. This rendering algorithm integrates normal mapping with curvature mapping into a local illumination model to solve the previous mentioned problem. In this report, I will derive different measures to calculate curvature maps from normal maps and I evaluate their suitability for rendering...|$|R
40|$|Plasmonic {{nanostructures}} {{are known}} to influence the emission of near-by emitters. They can enhance the absorption and modify the external quantum efficiency of the coupled system. To evaluate {{the possibility of using}} plasmonics to enhance the light emission of a phosphor-converted LED device and create an efficient <b>directional</b> <b>light</b> <b>source,</b> regular arrays of aluminium nanoparticles covered with a red dye layer are investigated. In arrays of aluminum nanocylinders with a diameter of ca 140 nm combined with a thin (650 nm) layer of luminescent material, very narrow resonances have been observed, which lead to large enhancement factors of up to 70 and 20 for excitation with a directional blue laser source and a lambertian LED respectively, in a small spectral range for particular angles. The measured resonances agree very well with finite-difference time-domain numerical simulations. These changes in the angular emission profile of the red dye as well as the spectral shape of its emission can help to optimize the efficacy of phosphor-converted LED modules and increase the amount of useable light in a certain angular cone. Using Fourier microscopy, large modifications of the angular emission profile as well as spectral shaping are observed for these plasmonic LED devices if compared to reference samples without plasmonic nanostructures...|$|E
40|$|Although remote {{phosphor}} technology outperforms conformal phosphor {{technology for}} midpower applications, {{one of the}} limiting factors due to {{its impact on the}} total cost is the amount of phosphor required. Furthermore, an important loss mechanism in remote phosphor light-emitting diode (LED) technology is the reabsorption of recycled, downconverted light by the phosphor. An obvious solution to this issue is to enable a light path for the converted light, such that further interactions with the phosphor element are avoided. We propose a spot phosphor concept to achieve this goal. To explore this configuration, a simulation model of a phosphor element is devised and validated. The optical input parameters are based on experimental data and the application of the inverse adding-doubling method. The resulting configuration, along with a long-pass filter, is shown to be a potential solution for reduction of phosphor usage. The moderate decrease in the light extraction ratio (LER) when applying the spot concept is partly attributed to the losses in the secondary optics needed to narrow the LED beam; the combination of the spot concept configuration with a <b>directional</b> <b>light</b> <b>source</b> such as a laser diode is shown to be a powerful combination for the enhancement of the LERstatus: publishe...|$|E
40|$|SummaryCiliary {{membranes}} {{have a large}} {{repertoire of}} receptors and ion channels that act to transduce information from the environment to the cell. Chlamydomonas offers a tractable system for dissecting the transport and function of ciliary and flagellar membrane proteins. Isolation of ergosterol and sphingolipid-enriched Chlamydomonas flagellar membrane domains identified potential signaling molecules by mass spectroscopy. These include a membrane protein and a matrix flavodoxin protein that are encoded by the AGG 2 and AGG 3 genes, respectively. Agg 2 p localizes to the proximal flagellar membrane near the basal bodies. Agg 3 p is distributed throughout the flagellar matrix, with an increased concentration in the proximal regions where Agg 2 p is located. Chlamydomonas cells sense light by using a microbial-type rhodopsin [1], transduce a signal from the cell body to the flagella, and alter the waveform of the flagella to turn a cell toward the light. Protein depletion by RNA interference reveals that both AGG gene products play roles in the orientation of cells to a <b>directional</b> <b>light</b> <b>source.</b> The depleted strains mimic the phenotype of the previously identified agg 1 mutant, which swims away from light. We propose that the localization of Agg 2 p and Agg 3 p to the proximal region of the flagella may be important for interpreting light signals...|$|E
40|$|Recent {{advances}} in nonlinear fiber optics and compact pulsed lasers {{have resulted in}} creation of broadband <b>directional</b> <b>light</b> <b>sources.</b> These supercontinuum laser <b>sources</b> produce <b>directional</b> broadband <b>light</b> using cascaded nonlinear optical interactions in an optical fibre framework. This system is used to simultaneously measure distance and reflectance to demonstrate a technique capable of distinguishing between a vegetation target and inorganic material using the Normalized Difference Vegetation Index (NDVI) parameters, while the range {{can be obtained from}} the waveform of the echoes. A two-channel, spectral range-finding system based on a supercontinuum laser source was used to determine its potential application of distinguishing the NDVI for Norway spruce, a coniferous tree, and its three-dimensional parameters at 600 nm and 800 nm. A prototype system was built using commercial components...|$|R
40|$|We {{introduce}} a new, integrated approach to uncalibrated photometric stereo. We perform 3 D reconstruction of Lambertian objects using multiple images produced by unknown, <b>directional</b> <b>light</b> <b>sources.</b> We show how {{to formulate a}} single optimization that includes rank and integrability constraints, allowing also for missing data. We then solve this optimization using the Alternate Direction Method of Multipliers (ADMM). We conduct extensive experimental evaluation on real and synthetic data sets. Our integrated approach is particularly valuable when performing photometric stereo using as few as 4 - 6 images, since the integrability constraint is capable of improving estimation of the linear subspace of possible solutions. We show good improvements over prior work in these cases...|$|R
40|$|We {{present an}} {{interactive}} system for fully dynamic scene lighting using captured {{high dynamic range}} (HDR) video environment maps. The key component of our system is an algorithm for efficient decomposition of HDR video environment map captured over hemisphere into a set of representative <b>directional</b> <b>light</b> <b>sources,</b> {{which can be used}} for the direct lighting computation with shadows using graphics hardware. The resulting lights exhibit good temporal coherence and their number can be adaptively changed to keep a constant framerate while good spatial distribution (stratification) properties are maintained. We can handle a large number of <b>light</b> <b>sources</b> with shadows using a novel technique which reduces the cost of BRDF-based shading and visibility computations. We demonstrate the use of our system in a mixed reality application in which real and synthetic objects are illuminated by consistent lighting at interactive framerates...|$|R
40|$|Inverse caustic problem, that is {{computing}} {{the geometry}} of a reflector and/or refractor based on a given caustic pattern, is currently not widely studied. In this paper, we propose a technique to solve the inverse caustic problem in which we compute {{the geometry of}} a semi-transparent homogeneous refractive object (caustic object) given a <b>directional</b> <b>light</b> <b>source</b> {{and a set of}} caustic patterns (each pattern is considered to be formed at a specified distance from the caustic object). We validate the results by using mental ray (software rendering). The novelty of our research is that we consider a set of caustic patterns whereas existing techniques only consider one caustic pattern. We employ a stochastic approach to simulate the refracted light beam paths that can approximately reconstruct the input caustic patterns. Working backward, from the computed refracted light beam paths we compute the geometry of the caustic object that can produce such light beam paths. Due to having multiple caustic patterns as the inputs, it is a challenge to reconstruct the input caustic patterns because of the differences in their shapes and intensities. We solve this problem by using a two-step optimization algorithm in which we adjust the position and size of the caustic regions in the first step and we adjust the caustic shapes in the second step. Our technique is able to construct a caustic object for a various types of input caustic patterns. Keywords: caustics, photon, reconstruction, inverse problem, stochastic...|$|E
40|$|Phototropism, the bending {{response}} of plant organs to {{or away from}} a <b>directional</b> <b>light</b> <b>source,</b> {{is one of the}} best studied blue light responses in plants. Although phototropism has been studied for more than a century, recent advances have improved our understanding of the underlying signaling mechanisms involved. The NPH 1 gene of Arabidopsis thaliana encodes a blue light-dependent autophosphorylating protein kinase with the properties of a photoreceptor for phototropism. NPH 1 apoprotein noncovalently binds FMN to form the holoprotein nph 1. The N-terminal region of the protein contains two LOV (light, oxygen, or voltage) domains that share homology with sensor proteins from a diverse group of organisms. These include the bacterial proteins NIFL and AER, both of which bind FAD, and the phy 3 photoreceptor from Adiantium capillus-veneris. The LOV domain has therefore been proposed to reflect a flavin-binding site, regulating nph 1 kinase activity in response to blue light-induced redox changes. Herein we demonstrate that the LOV domains of two nph 1 proteins and phy 3 bind stoichiometric amounts of FMN when expressed in Escherichia coli. The spectral properties of the chromopeptides are similar to the action spectrum for phototropism, implying that the LOV domain binds FMN to function as a light sensor. Thus, our findings support the earlier model that nph 1 is a dual-chromophoric flavoprotein photoreceptor regulating phototropic responses in higher plants. We therefore propose the name phototropin to designate the nph 1 holoprotein...|$|E
40|$|Title from PDF {{of title}} page (University of Missouri [...] Columbia, viewed on November 18, 2010). The entire thesis text is {{included}} in the research. pdf file; the official abstract appears in the short. pdf file; a non-technical public abstract appears in the public. pdf file. Dissertation advisor: Dr. Emmanuel Liscum. Vita. Includes bibliographical references (p. 307 - 321). Ph. D. University of Missouri [...] Columbia 2008. Dissertations, Academic [...] University of Missouri [...] Columbia [...] Biological sciences. [ACCESS RESTRICTED TO THE UNIVERSITY OF MISSOURI AT AUTHOR'S REQUEST. ] Plants being immobile have developed various adaptive responses to interpret and utilize light directionality, quantity and quality. One such adaptive response is phototropism where the plant organs bend towards a <b>directional</b> <b>light</b> <b>source.</b> In Arabidopsis, NPH₃ protein is absolutely required for phototropism and it interacts with the phot 1 photoreceptor. Given the unique properties of this critical protein mediating phototropism, yet little is known about how phot 1 signals through NPH₃. This dissertation presents results that address a better understanding on the workings of NPH₃ in mediating phototropism. In brief, it has been demonstrated that NPH₃ has reversible phosphorylation states and dephosphorylation of NPH₃ is dependent on phot 1. Lastly, my dissertation work has led to the identification of three more novel components of the phototropic pathway: 1) CUL₃ (directly interacts with NPH₃); 2) a protein kinase that phosphorylates NPH₃ in dark; and 3) a protein phosphatase that dephosphorylates NPH₃ in light...|$|E
40|$|Scenes with cast shadows {{can produce}} complex sets of images. These images cannot be well {{approximated}} by lowdimensional linear subspaces. However, {{in this paper}} we show that the set of images produced by a Lambertian scene with cast shadows can be efficiently represented by a sparse set of images generated by <b>directional</b> <b>light</b> <b>sources.</b> We first model an image with cast shadows as composed of a diffusive part (without cast shadows) and a residual part that captures cast shadows. Then, we express the problem in an ℓ 1 -regularized least squares formulation, with nonnegativity constraints. This sparse representation enjoys an effective and fast solution, thanks to recent advances in compressive sensing. In experiments on both synthetic and real data, our approach performs favorably in comparison to several previously proposed methods. 1...|$|R
40|$|International audienceIn this paper, {{we propose}} {{a method for}} taking into account {{lighting}} conditions for photometric stereo. Indeed, with its classic form, the photometric stereo requires <b>directional</b> <b>light</b> <b>sources</b> and uniform intensity to determine the geometry and albedo of a surface from a reverse illumination model. These constraints are usually not realistic in practice for compact systems, our formulation thus takes account all lighting system properties. We use an iterative process to include the geometry of the surface in the reverse illumination model. Each iteration provides a refined reconstruction and significantly improves the results. Our method {{does not require a}} new illumination models and the iteration number is small. It allows to quickly recover geometry and albedo. To evaluate the performance of our method, we compare it to classical photometric stereo by simulation and on real surfaces...|$|R
40|$|A new shading {{model for}} linear <b>light</b> <b>source</b> is presented. It {{accounts}} for both diffuse reflection and specular {{reflection of the}} illuminated surface. By regarding a linear <b>light</b> <b>source</b> as a <b>directional</b> rectangular <b>light</b> <b>source</b> with infinitesimal width, a simple formula is derived for calculating the diffuse reflection component. The specular reflection component is represented by an integration taking Phong's specular model as the kernel and evaluated by a linear approximation. Finally, an efficient shadow detection algorithm for linear <b>light</b> <b>source</b> is proposed. The images rendered with the shading model are very photo realistic...|$|R
