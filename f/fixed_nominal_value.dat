2|3235|Public
40|$|This paper {{deals with}} the problem of robust {{absolute}} stability analysis for nonlinear Lur'e control systems in the presence of system parameter variations. The well known Popov criterion for absolute stability is used in order to characterize the boundary of the region of absolute stability in the parameter plane when the coefficients of the transfer function of the linear plant are polynomial functions of the uncertain parameters. For a scalar parameter, a method is given to determine the maximal interval of variation around a <b>fixed</b> <b>nominal</b> <b>value</b> preserving absolute stability. This result is also used to derive a technique for checking absolute stability of Lur'e systems with parameters in given planar uncertainty sets. Numerical examples showing the application of the method are reported...|$|E
40|$|International audienceThe {{problem of}} {{controlling}} induction machine speed {{has generally been}} dealt with using standard models i. e. those {{based on the assumption}} that the magnetic characteristic is linear. In coherence with this assumption, most control strategies involved rotor flux regulation around a <b>fixed</b> <b>nominal</b> <b>value.</b> As a matter of fact, optimal performance operation (e. g. maximal efficiency, maximal torque, unitary power factor [...] .) are not achievable using constant flux reference especially when facing wide range load variations. But, control strategies involving wide range flux reference variations can not be obtained without accounting for the nonlinearity of the machine magnetic characteristic. In the present work, we propose a new speed control strategy based on a new machine model that accounts for the magnetic characteristic hysteresis and saturation. A speed controller is designed using a nonlinear design technique. The performances of the proposed control strategy are formally analysed and their supremacy with respect to the standard control solution is illustrated through a simulation study, using a 7. 5 KW machine...|$|E
3000|$|... in (8) costs N 3 + N 2 complex multiplications if RH(l)H(l)and SNR {{are assumed}} to be known {{beforehand}} or are set to <b>fixed</b> <b>nominal</b> <b>values</b> [23]. In what follows, the LS estimate of [...]...|$|R
40|$|Constructs {{a simple}} neoclassical growth {{model in which}} {{financial}} factors play an important role. The model demonstrates that the injunction against fixed interest payments induces the monetary authority in the Islamic economy to develop and innovate alternative financial instruments {{that do not have}} <b>fixed</b> <b>nominal</b> <b>values</b> and do not bear predetermined rates of return. The model also proves that financial innovation is welfare enhancing, while inflation reduces welfare and hampers growth. The model further proves that the government in an Islamic economy can effectively coordinate its fiscal and monetary policies to finance the budget using the Zakat and seigniorage. Economics, Finance, Inflation, Innovation, Loss, Profit sharing...|$|R
3000|$|... [...]. The {{influence}} {{of all the}} other parameters in the variability of the model output is small. Therefore, they can be <b>fixed</b> to their <b>nominal</b> <b>values.</b> This greatly reduces the dimensionality of the model retaining most of its probabilistic features.|$|R
40|$|A new {{approach}} to low-complexity channel estimation in orthogonal-frequency division multiplexing (OFDM) systems is described. A low-rank approximation is applied to a linear minimum mean-squared error (LMMSE) estimator that uses the frequency correlation of the channel. By using the singular-value decomposition (SVD) an optimal low-rank estimator is derived, where performance is essentially preserved - even for low computational complexities. A <b>fixed</b> estimator, with <b>nominal</b> <b>values</b> for channel correlation and signal-to-noise ratio (SNR), is analysed. Analytical mean-squared error (MSE) and symbol-error rates (SER) are presented for a 16 -QAM OFDM system. Godkänd; 1996; 20080220 (ysko...|$|R
40|$|Abstract—Reducing test cost by {{minimizing}} the overall test time {{remains one of}} the main goals of System-on-Chip (SoC) testing. Power-aware strategies optimize the overall test time of a SoC for a global peak power budget. Test time and test power can be regulated by VDD and test clock frequency to optimize SoC test schedules for a given power budget. Dynamic voltage and frequency scaling (DVFS) techniques have been used in the past to optimize energy efficiency in SoCs. In this paper, we extend the concept of DVFS to optimize the test scheduling of SoC. We adopt a sessionless test scheduling strategy and provide a simple heuristic approach for its optimization. The proposed idea is implemented on several ITC 02 benchmarks. Results show significant test time reduction over sessionless reference test schedules for which VDD and clock frequency are <b>fixed</b> at <b>nominal</b> <b>values.</b> I...|$|R
40|$|We {{present an}} update of our {{estimates}} for the power deposition arising from the electron-cloud effect in the dipole bending magnets in the arcs of the LHC. In addition, we present the estimate of the power deposition in the field-free regions in the arcs. We hold the number of particles per bunch and the bunch spacing <b>fixed</b> at their <b>nominal</b> <b>values,</b> and we assume throughout a high photon reflectivi ty. We explore the dependence of the power deposition on the photoelectric efficiency and on secondary emission yield parameters. We find a marked sensitivity to parameters that characterize secondary emission {{on the scale of}} 5 - 10 eV...|$|R
40|$|The MATLAB® RSTool is here used {{in order}} to derive an {{analytic}} expression of the shielding effectiveness (SE) of a device obtained by stacking a variable number of CVD graphene planes (GP) on poly-methyl methacrylate (PMMA). The range [1 - 9] of GP/PMMA number of stacking is explored taking in to account available experimental results. This parameter is considered as “controllable parameter” whereas the electrical conductivity of the GP as “uncontrollable parameter” with <b>fixed</b> <b>nominal</b> and tolerance <b>value,</b> since it is a new-generation material and its fabrication intrinsically suffers from heavy uncertainties. Moreover, {{the thickness of the}} PMMA, which <b>nominal</b> <b>value</b> can be changed, is also considered as “uncontrollable parameter” due to the technological limitation to control it. A quadratic expression of the SE is derived by interpolating a few number of numerical solution obtained by FEM-solving the electromagnetic problem in particular points of the parameter space, choosen according to a Design of Experiment (DoE) approach. Vertex Analysis, applied on the equation obtained for a fixed number of layers, is used to assess the sensitivity of the device with respect to the heavy and not avoidable uncertainties that affect the production process...|$|R
30|$|There are few {{examples}} of sensitivity analysis studies in fire research literature, nearly all of which involve what {{is referred to as}} a “local approach” (e.g., Bevins and Martin 1978, Trevitt 1991, Bessie and Johnson 1995, Hargrove et al. 2000, Miller and Yool 2002, Cruz et al. 2003). Local approaches estimate the effect of the variation of a single input or parameter by keeping all the others <b>fixed</b> at their <b>nominal</b> <b>values.</b> Local methods are well established and are familiar to most modelers (Campolongo et al. 2000). Local SA serves as an ad-hoc stability analysis, providing a measure of how stable the model is around the best estimates for the inputs (Turanyi and Rabitz 2000). The local approach is not recommended for investigating the sensitivity of non-linear models in which the uncertainty in the output associated with the uncertainty in each input may be of different orders of magnitude (Cukier et al. 1973).|$|R
40|$|Sensitivity {{analysis}} and uncertainty estimation {{are crucial to}} the validation and calibration of numerical models. In this paper we present the application of sensitivity analyses, parameter estimations and Monte-Carlo uncertainty analyses on TEPHRA, an advection-diffusion model for the description of particle dispersion and sedimentation from volcanic plumes. The model and the related sensitivity analysis are tested on two sub-plinian eruptions: the 22 July 1998 eruption of Etna volcano (Italy) and the 17 June 1996 eruption of Ruapehu volcano (New Zealand). Sensitivity analyses are key to (1) constrain crucial eruption parameters (e. g., total erupted mass) (2) {{reduce the number of}} variables by eliminating non-influential parameters (e. g., particle density) and (3) investigate the interactions among all input parameters (plume height, total grain-size distribution, diffusion coefficient, fall-time threshold and mass-distribution parameter). For the two test cases, we found that the total erupted mass significantly affects the model outputs and, therefore, it can be accurately estimated from field data of the fallout deposit, whereas the particle density can be <b>fixed</b> at its <b>nominal</b> <b>value</b> because it has negligible effects on the model predictions...|$|R
40|$|Ordinary {{differential}} equation (ODE) models {{are often used}} to quantitatively describe and predict the dynamic responses of biological and other systems. Models with many parameters, limited measurement data {{and in need of}} quantification are typically unidentifiable from available input/output data. Even models that are structurally identifiable can be difficult to quantify in practice from limited data. For overparameterized models (OPMs), it is often helpful to simplify the model, by rationally reducing the dimensionality of the parameter space. This is done by finding a set of "key parameters" to estimate, a subset that best represents the dominant model dynamic responses. OPMs are often characterized by pairwise parameter correlations close to 1 in magnitude and at least some unacceptably large parameter estimation variances. The goal is to get the best fit possible with a smaller number of parameters, each with acceptable variances. Several published methods for selecting the key parameter subset are based on parameter sensitivity analysis and/or analysis of the parameter covariance matrix estimated from the input/output data. We apply a combination of these methods to an overparameterized candidate model of tumor suppressor protein p 53. The model comprises of 4 ODEs, 23 unknown parameters, and noisy output measurements of the 4 state variables and the input. Three least sensitive and highly correlated parameters were isolated from the analysis and <b>fixed</b> to <b>nominal</b> <b>values.</b> This reduced the parameter search space and yielded substantially improved numerical identifiability properties for the resulting simplified model which fitted the data equally well, using both global and local search algorithms...|$|R
40|$|We {{submitted}} the semi-empirical, process-based wind-risk model ForestGALES to a variance-based sensitivity analysis {{using the method}} of Sobol for correlated variables proposed by Kucherenko et al. (2012). Our results show that ForestGALES is able to simulate very effectively the dynamics of wind damage to forest stands, as the model architecture reflects the significant influence of tree height, stocking density, dbh, and size of an upwind gap, on the calculations of the critical wind speeds of damage. These results highlight the importance of accurate knowledge {{of the values of}} these variables when calculating the risk of wind damage with ForestGALES. Conversely, rooting depth and soil type, i. e. the model input variables on which the empirical component of ForestGALES that describes the resistance to overturning is based, contribute only marginally to the variation in the outputs. We show that these two variables can confidently be <b>fixed</b> at a <b>nominal</b> <b>value</b> without significantly affecting the model's predictions. The variance-based method used in this study is equally sensitive to the accurate description of the probability distribution functions of the scrutinised variables, as it is to their correlation structure. JRC. C. 3 -Energy Security, Distribution and Market...|$|R
40|$|The paper {{deals with}} a {{simulation}} model, developed in Matlab Simulink®, of a small-scale Combined Heat and Power (CHP) plant based on a recuperated micro gas turbine (mGT). A minimum data set, mainly obtainable from datasheets, was defined, that allows the model to simulate different mGT plants in the small-scale range with a good accuracy. The model implements the mass, energy and momentum equations of {{the main components of}} the power plant. A double control system has also been developed, with the aim of maintaining the rotational speed of the turbine /compressor assembly at the <b>nominal</b> <b>fixed</b> <b>value,</b> and at limiting the Exhaust Gas Temperature (EGT) below the limit value. The model has been validated by means of experimental data obtained from a commercial mGT (100 kWel, 170 kWth), installed at the Politecnico di Torino, whose energetic characterization has been performed both at rated and at partial load conditions. The layout and the characteristics of the measurement system are also described in the paper...|$|R
40|$|The {{monetary}} {{theory of}} G. F. Knapp was so shocking {{in the moment}} of its announcement that it was rejected. Yet, demonetarization of gold is presently materialized and the authoress made an attempt at the study of that theory. Her task was to present main theses of G. F. Knapp and to examine whether the theory found its application in the modern monetary systems. Upon presentation of main theses of G. F. Knapp references were made to the theories of John Law, L. Walras. J. M. Keynes. The differences between metalism and nominalism were indicated. In the answer to the query the immediate interest of G. F. Knapp theses was emphasised. Applications of his theory in current international monetary system is brought forward. It was proved by G. F. Knapp that money is always an autonomous tender. Moneyed function is its, essence. Money is always numéraire. Substantional value od money is unnecessary and so are gold parity and par value system. State can <b>fix</b> a <b>nominal</b> <b>value</b> of its currency, as a compulsory legal tender and secure a future purchasing power as means of exchange. The exchange rate is a price of foreign currency expressed in a domestic unit. In cannot be fixed arbitrarily, as it is formed by the whole of state policies and international exchange. According to the Knappian pantopolical theory of exchange rate, a state has to run the monetary policy both inland and with reference to the foreign relations. All fundamental Knappian theses are presently fully realised in monetary system of many countries. In the international monetary system it is used in basket currency introduced by the IMF in 1974 as well as in establishing principles of central rate. Digitalizacja i deponowanie archiwalnych zeszytów RPEiS sfinansowane przez MNiSW w ramach realizacji umowy nr 541 /P-DUN/ 201...|$|R
40|$|This paper {{focuses on}} {{tolerance}} synthesis, which involves {{the allocation of}} the specified assembly tolerances among the component dimensions of an assembly to ensure a specified yield. Even though the issue of tolerance synthesis has been discussed widely, most research often assumes that component alternatives have equal <b>nominal</b> <b>values.</b> Therefore, the <b>nominal</b> <b>values</b> are negligible. However, there may be situations where the <b>nominal</b> <b>values</b> are different. In such cases, the <b>nominal</b> <b>values</b> should be considered. This paper attempts to include stackup and component <b>nominal</b> <b>values</b> to the deterministic tolerance synthesis. The objective {{of this paper is}} to integrate the <b>nominal</b> <b>values</b> of aomponent and assemblies within the framework of tolerance synthesis. A numerical example is given to illustrate the model. Keyrvords: quality engineering, tolerance synthesis, <b>nominal</b> <b>values,</b> Taguchi's loss function Tolerances are defined as the range between a specification limit and the nominal dimension. Traditionally, to assign tolerances t...|$|R
50|$|The {{distinction}} between real <b>value</b> and <b>nominal</b> <b>value</b> occurs in many fields. From a philosophical viewpoint, <b>nominal</b> <b>value</b> represents an accepted condition, {{which is a}} goal or an approximation, {{as opposed to the}} real value, which is always present. Often a <b>nominal</b> <b>value</b> is de facto rather than an exact, typical, or average measurement.|$|R
40|$|The use of {{composite}} materials is increasing in many fields of production. Composite manufacturing, {{as well as}} other fields of production, suffers from uncertainties resulting in products that deviate from the specification. Geometry assurance is a common procedure used to keep the variations in product assemblies under control. However, the methods used to simulate the variation are not developed for composites. In this thesis, two methods are presented that address typical uncertainties within composite production. The method presented in Paper I focuses on the variation of fiber orientation and ply thickness within fibrous laminae. Variation simulation for the fiber orientation and ply thickness parameters is combined with a traditional such method. The combined variation simulation is carried out so {{that it is possible to}} study the effects of including perturbations in these composite parameters. In Paper II, a method that captures a special type of deviation common for composites, called spring-in, is presented. These deviations are seen especially in T-beam structures and occur during the curing step of production, i. e., hardening in an oven. A FEM thermal expansion simulation is performed on the anisotropic composite laminate as a part of the traditional variation simulation method. The curing temperature is one parameter, along with the standard geometric parameters, within the proposed method. The two methods proposed are tested on subassemblies originating from automotive and aviation industry, respectively. Applying the method presented in Paper I to the test case gives a resulting variation where the variance is increased by a factor of 10 %. No structural differences are seen. Hence, these results indicate that traditional variation simulation is sufficient with the inclusion of a correction factor for composites. The method presented in Paper II is a new contribution to the field of geometry assurance. In addition, the results show an increase by a factor 4 in the resulting variation for the test case between keeping the curing temperature <b>fixed</b> at <b>nominal</b> <b>value</b> and letting it vary...|$|R
5000|$|... {{equity capital}} amounts to UAH 230,000,000 and 22,984,203 {{ordinary}} registered shares with a <b>nominal</b> <b>value</b> of UAH 10 per share. There are also 15 797 preferred stocks with a <b>nominal</b> <b>value</b> of UAH 10 per share.|$|R
50|$|Graduated {{pipettes}} {{are classified}} into three types: Type 1, Type 2, and Type 3. Type 1 and Type 3 pipettes have the <b>nominal</b> <b>value</b> {{at the bottom}} (Zero at the top). For Type 1, the solution is delivered partially for all volume. For type 3, the solution is delivered totally only at the <b>nominal</b> <b>value.</b> Type 2 pipettes have the <b>nominal</b> <b>value</b> at the top (Zero at the bottom) and the solution is delivered totally for any volume.|$|R
50|$|In 1924, coins {{were put}} into {{circulation}} in {{the territory of the}} Soviet Union. These were in <b>nominal</b> <b>value</b> 1, 2, 3 and 5 kopecks in copper; 10, 15, 20 kopecks in base-alloy silver; and 50 kopecks and 1 ruble in silver. Copper coins of the smallest <b>nominal</b> <b>value</b> of half kopeck were minted in 1925 - 1928.In 1923, the first Soviet gold coin (1 chervonets in <b>nominal</b> <b>value)</b> was minted. This conformed in all its features to the gold coin worth of 10 rubles of Russian Empire. It almost never appeared in circulation and was only used in foreign trade transactions.Starting from 1926, coins in <b>nominal</b> <b>value</b> 1, 2, 3 and 5 were made of bronze; starting from 1931, coins in <b>nominal</b> <b>value</b> 10, 15 and 20 kopecks were made of cuprum-nickel alloy.There has been a great variety of the first Soviet banknotes. In circulation were the Soviet chervonets (10 rubles) and the rubles designed to portray the symbols of the Soviet ideology. The types of banknotes of this period were often replacing each other.A monetary reform was passed in 1947 with a key objective to promote to a quick recovery of the war-suffered economy, withdrawal of counterfeit money from circulation and replacement of the old samples with new ones.The monetary reform of 1961 was aimed to change the price scale (10:1), improve the money cycle and issue banknotes of new design. New series of coins in <b>nominal</b> <b>value</b> 1, 2, 3, 5, 10, 15, 20, 50 kopecks and 1 ruble {{were put into}} circulation. The series of banknotes consisted of 1, 3, 5, 10, 25, 50 and 100 rubles in nominal value.In 1991, to regulate the money cycle, banknotes in <b>nominal</b> <b>value</b> 50 and 100 rubles were withdrawn from circulation and substituted by new ones - banknotes of the 1991 series in <b>nominal</b> <b>value</b> 50 and 100 rubles (two different types). Later on, banknotes of the 1991 series in <b>nominal</b> <b>value</b> 1, 3, 5, 10, 200, 500 and 1000 rubles were put into circulation. Since February 1992, prices were liberalized, which led to the rise in prices and devaluation of the ruble. Banknotes of the 1992 series in <b>nominal</b> <b>value</b> 50, 200, 500, 1000, 5000 and 10000 rubles were put into circulation.|$|R
50|$|On November 22, 1993, {{the local}} currency, the Dram, {{was put into}} {{circulation}} in <b>nominal</b> <b>value</b> 10, 25, 50, 100, 200 and 500 drams, using an exchange rate of 200 rubles for one Dram. Banknotes of the former Soviet Union, in <b>nominal</b> <b>value</b> 1-500 rubles of the 1961-1992 issue were allowed to co-circulate with the Dram up until March 17, 1994.Coins in <b>nominal</b> <b>value</b> 10, 20, 50 luma and 1, 3, 5, 10 drams of aluminum alloy were put into circulation since February 21, 1994.Banknotes in <b>nominal</b> <b>value</b> 1000 and 5000 drams were put into circulation since October 24, 1994 and September 6, 1995, respectively.Starting 1998, banknotes of the second series in <b>nominal</b> <b>value</b> 50, 100, 500, 1000, 5000 and 20000 drams were put into circulation. The banknotes of this series meet modern requirements in terms of security, endurance, quality and design.On June 4, 2001, the commemorative banknote in <b>nominal</b> <b>value</b> 50000 drams dedicated to 1700th anniversary of adoption of Christianity in Armenia was put into circulation.In the period 2004 - 2005, the banknotes in <b>nominal</b> <b>value</b> 50 and 100 drams of the 1993-1995 series and the 1998 series were withdrawn from circulation. These have been {{ceased to be a}} legal tender in the Republic of Armenia yet are allowed to be exchanged at their par in commercial banks and the Central Bank of Armenia, without limitation. In the period 2003 - 2004, the coins of the second series in <b>nominal</b> <b>value</b> 10, 20, 50, 100, 200 and 500 drams were put into circulation.Since August 24, 2009, the banknote in <b>nominal</b> <b>value</b> 100000 drams was put into circulation. The banknote depicts the king Abgar the Fifth of Edessa. According to accounts of Armenian historians, Abgar was the first king of Armenian origin to have adopted Christianity. He has been venerated by the Armenian Apostolic Church.Since August 1994, Central Bank of Armenia has issued a few dozen of commemorative coins made of gold, silver and cupronickel.|$|R
50|$|In measurement, a <b>nominal</b> <b>value</b> {{is often}} a value {{existing}} in name only; it is assigned as a convenient designation rather than calculated by data analysis or following usual rounding methods. The use of <b>nominal</b> <b>values</b> can be based on de facto standards or some technical standards.|$|R
25|$|Manufacturing {{employment}} and <b>nominal</b> <b>value</b> added {{shares of the}} economy {{have been in a}} steady decline since World War II. In the late 1960s manufacturing's share of both {{employment and}} <b>nominal</b> <b>value</b> added was about 26%, falling to about 11% and 12% respectively {{by the end of the}} century.|$|R
5000|$|Real values can {{be found}} by {{dividing}} the <b>nominal</b> <b>value</b> by the growth factor of a price index. Using the price index growth factor as a divisor for converting a <b>nominal</b> <b>value</b> into a real value, the real value in year t relative to the base year 0 is: ...|$|R
50|$|A company {{incorporated}} in England and Wales {{can be created}} with any number of shares of any <b>nominal</b> <b>value,</b> expressed in any currency. For example, there may be 10,000 shares with a <b>nominal</b> <b>value</b> of 1p, or 100 shares of £1 each. In each case the share capital would be £100.|$|R
50|$|The coins had a <b>nominal</b> <b>value</b> {{of eight}} reales ("royals").|$|R
30|$|Tolerance can {{be defined}} as the {{physical}} or chemical properties (e.g. size, weight, strength and the combination of components) or geometric characteristics (e.g. dimensions, position, shape and surface finish of some part features). As one cannot manufacture many components with the same <b>nominal</b> <b>value,</b> the deviation from <b>nominal</b> <b>value</b> will be inevitable. That is why tolerance is allowed. If a component has a high deviation from the <b>nominal</b> <b>value,</b> its quality will suffer. Consequently, the design engineers define the maximal permissible specification limits, called tolerance, with the purpose of hampering the degradation in the performance of the product (Devor et al. 2007).|$|R
50|$|In 1798, 15 {{years after}} the end of the Revolutionary War and the signing of the Treaty of Paris, Manning wrote his most famous text, The Key of Liberty. In it, he further defined the {{distinction}} between the Few and the Many. The Few, according to him, did not produce labor, and their incomes relied primarily on interests, rents, salaries and fees <b>fixed</b> on the <b>nominal</b> <b>value</b> of money. He also said that they preferred money to be scarce and labor to be produced at as low of a cost as possible. Manning wrote in his text, “For instance if the prices of labour & produce should fall one halfe if would be just the same to the few as if their rents fees & salleryes ware doubled, all which they would git out of the many.” On the other hand, Manning continued, if the Many doubled the prices of labor and produce, they would pay off their debts and enjoy not being financially dependent on the Few. Some of the biggest threats to the Many, however, were people working in the judicial and executive branches of federal government, especially lawyers. He said that they were continuously interested in having money scarce and their people in distress. The scarcer the money, they believed, the lower the cost of produce and the more distressed the people became, the better. It, therefore, not only doubled the <b>nominal</b> <b>value</b> of their fees and salaries, Manning said, but also doubled and tripled their income, forcing the people to beg for forgiveness, patience and forbearance. Manning wrote, “This gratifyes both their pride & covetousness, when on the other hand when money is plenty & prices high they have little or nothing to do. This is the Reason why they aught to be kept intirely from the Legislative Body....” In Manning’s earlier text, an article titled “Some Proposals,” of which he harped on his loathing of Hamilton’s financial policy, he merely explained the difference between the Few and the Many as a fight over monetary policy, whereas in Libberty, he explained it as disputes between labor, property and free government.|$|R
50|$|By taking {{advantage}} of the two principles covered above, one is able to optimise a system so that the <b>nominal</b> <b>value</b> of a systems output is kept at its desired level while also minimising the likelihood of any deviation from that <b>nominal</b> <b>value.</b> This is despite the presence of random variability within the input variables.|$|R
50|$|The <b>nominal</b> <b>value</b> of {{this unit}} would rise with {{inflation}} in each economy. Moreover, the <b>nominal</b> <b>value</b> of this unit would rise if other currencies {{represented in the}} basket appreciate against the US dollar. Savers purchasing such bonds would not only enjoy protection against inflation, but would benefit from the diversification of exchange risks.|$|R
500|$|The <b>nominal</b> <b>value</b> of {{the input}} {{impedance}} {{of a radio}} frequency antenna ...|$|R
5000|$|Moving one input variable, keeping {{others at}} their {{baseline}} (<b>nominal)</b> <b>values,</b> then, ...|$|R
30|$|Frequency offset in IR-UWB {{communication}} system arises {{due to the}} clocks at the transmitter and receiver that run independently at slightly different frequencies, albeit close to a common <b>nominal</b> <b>value.</b> Deviations from the <b>nominal</b> <b>value</b> {{are referred to as}} clock frequency offsets. Moreover, Doppler fading also {{plays a key role in}} causing frequency offset in IR-UWB {{communication system}}s.|$|R
50|$|<b>Nominal</b> <b>values</b> for the {{presetting}} {{serve as}} a default in the measuring process with a tool presetting machine. The exact position of the tool and the measuring method can be specified, {{in addition to the}} <b>nominal</b> <b>values</b> of the geometry, so that, for example, the left or right corner has to be measured for a grooving tool.|$|R
40|$|We {{developed}} the estimation system of electric parameters. For the non-magnetic materials, the estimated relative permeability {{was the same}} as the <b>nominal</b> <b>values.</b> For the ferromagnetic materials, the estimated relative permeability varied 0 % to 30 % from the <b>nominal</b> <b>values.</b> For both types of materials, the estimated conductivities were 0 % to 9. 8 % different from <b>nominal</b> <b>values.</b> Next, we apply our estimation method to shielding sheets, and we can estimate the electric parameters for items such as thin cloths. Then, we estimate the dielectric constant for liquid materials. The accuracy is such that the estimated value is different from the <b>nominal</b> <b>value</b> by less than 2 %. These results show that we have successfully developed an estimation system of electric parameters for these cases. Using our estimation system, we can estimate considering the frequency characteristics for electric parameters in about 2 minutes...|$|R
