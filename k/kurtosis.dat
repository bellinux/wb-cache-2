5131|0|Public
25|$|The excess <b>kurtosis</b> {{is defined}} as <b>kurtosis</b> minus3. There are 3 {{distinct}} regimes as described below.|$|E
25|$|The sample <b>kurtosis</b> is {{a useful}} measure of {{whether there is a}} problem with {{outliers}} in a data set. Larger <b>kurtosis</b> indicates a more serious outlier problem, and may lead the researcher to choose alternative statistical methods.|$|E
25|$|Applying band-pass filters {{to digital}} images, <b>kurtosis</b> values {{tend to be}} uniform, {{independent}} {{of the range of}} the filter. This behavior, termed <b>kurtosis</b> convergence, can be used to detect image splicing in forensic analysis.|$|E
25|$|Explicit {{expressions}} for the skewness and <b>kurtosis</b> are lengthy.|$|E
25|$|C: raised cosine distribution, cyan curve, excess <b>kurtosis</b> = −0.593762...|$|E
25|$|Pearson's {{definition}} of <b>kurtosis</b> {{is used as}} an indicator of intermittency in turbulence.|$|E
25|$|These {{tests of}} {{normality}} {{can be applied}} if one faces <b>kurtosis</b> risk, for instance.|$|E
25|$|U: uniform distribution, magenta curve (shown {{for clarity}} as a {{rectangle}} in both images), excess <b>kurtosis</b> = −1.2.|$|E
25|$|There is no {{upper limit}} to the excess <b>kurtosis</b> of a general {{probability}} distribution, {{and it may be}} infinite.|$|E
25|$|Pearson {{distribution}} — a four-parameter {{family of}} probability distributions that extend the normal law to include different skewness and <b>kurtosis</b> values.|$|E
25|$|D'Agostino's K-squared test is a goodness-of-fit {{normality}} test {{based on}} a combination of the sample skewness and sample <b>kurtosis,</b> as is the Jarque–Bera test for normality.|$|E
25|$|Note that {{in these}} cases the {{platykurtic}} densities have bounded support, whereas the densities with positive or zero excess <b>kurtosis</b> are supported on the whole real line.|$|E
25|$|Values of ν = α + β {{such that}} ν ranges {{from zero to}} infinity, 0 < ν < ∞, span the whole region of the beta {{distribution}} in the plane of excess <b>kurtosis</b> versus squared skewness.|$|E
25|$|Alternative {{measures}} of <b>kurtosis</b> are: the L-kurtosis, {{which is a}} scaled version of the fourth L-moment; measures based on four population or sample quantiles. These are analogous to the alternative {{measures of}} skewness that are not based on ordinary moments.|$|E
25|$|On {{the other}} hand, the plot shows that for extreme skewed cases, where the mean is located near {{one or the}} other end (μ = 0 or μ = 1), the {{variance}} is close to zero, and the excess <b>kurtosis</b> rapidly approaches infinity when the mean of the distribution approaches either end.|$|E
25|$|In statistics, D’Agostino’s K2 test, {{named for}} Ralph D'Agostino, is a goodness-of-fit measure of {{departure}} from normality, {{that is the}} test aims to establish {{whether or not the}} given sample comes from a normally distributed population. The test is based on transformations of the sample <b>kurtosis</b> and skewness, and has power only against the alternatives that the distribution is skewed and/or kurtic.|$|E
25|$|The sample extrema can be {{used for}} a simple {{normality}} test, specifically of kurtosis: one computes the t-statistic of the sample maximum and minimum (subtracts sample mean and divides by the sample standard deviation), and if they are unusually large for the sample size (as per the three sigma rule and table therein, or more precisely a Student's t-distribution), then the <b>kurtosis</b> of the sample distribution deviates significantly from that of the normal distribution.|$|E
25|$|A Bayesian account can {{be found}} in Gelman et al. The degrees of freedom {{parameter}} controls the <b>kurtosis</b> of the distribution and is correlated with the scale parameter. The likelihood can have multiple local maxima and, as such, it is often necessary to fix the degrees of freedom at a fairly low value and estimate the other parameters taking this as given. Some authors report that values between 3 and 9 are often good choices. Venables and Ripley suggest that a value of 5 is often a good choice.|$|E
25|$|These models {{rely on the}} {{assumption}} that asset price fluctuations are the result of a well-behaved random or stochastic process. This is why mainstream models (such as the famous Black-Scholes model) use normal probabilistic distributions to describe price movements. For all practical purposes, extreme variations can be ignored. Mandelbrot thought this was an awful way to look at financial markets. For him, the distribution of price movements is not normal and has the property of <b>kurtosis,</b> where fat tails abound. This is a more faithful representation of financial markets: the movements of the Dow index for the past hundred years reveals a troubling frequency of violent movements. Still, conventional models used {{by the time of the}} 2008 financial crisis ruled out these extreme variations and considered they can only happen every 10,000 years. An obvious conclusion from Mandelbrot’s work is that greater regulation in financial markets is indispensable. Other contributions of his work for the study of stock market behaviour are the creation of new approaches to evaluate risk and avoid unanticipated financial collapses.|$|E
2500|$|Given a sub-set {{of samples}} from a population, the sample excess <b>kurtosis</b> above is a biased {{estimator}} {{of the population}} excess <b>kurtosis.</b> An alternative estimator of the population excess <b>kurtosis</b> is defined as follows: ...|$|E
2500|$|The exact {{interpretation}} of the Pearson measure of <b>kurtosis</b> (or excess <b>kurtosis)</b> used to be disputed, but is now settled. As Westfall (2014) notes, [...] "...its only unambiguous interpretation {{is in terms of}} tail extremity; i.e., either existing outliers (for the sample <b>kurtosis)</b> or propensity to produce outliers (for the <b>kurtosis</b> of a probability distribution)." [...] The logic is simple: <b>Kurtosis</b> is the average (or expected value) of the standardized data raised to the fourth power. Any standardized values that are less than 1 (i.e., data within one standard deviation of the mean, where the [...] "peak" [...] would be), contribute virtually nothing to <b>kurtosis,</b> since raising a number that is less than 1 to the fourth power makes it closer to zero. The only data values (observed or observable) that contribute to <b>kurtosis</b> in any meaningful way are those outside the region of the peak; i.e., the outliers. Therefore <b>kurtosis</b> measures outliers only; it measures nothing about the [...] "peak." ...|$|E
2500|$|The <b>kurtosis</b> of any {{univariate}} {{normal distribution}} is3. [...] It {{is common to}} compare the <b>kurtosis</b> of a distribution to this value. [...] Distributions with <b>kurtosis</b> less than3 {{are said to be}} platykurtic, although this does not imply the distribution is [...] "flat-topped" [...] as sometimes reported. Rather, it means the distribution produces fewer and less extreme outliers than does the normal distribution. An example of a platykurtic distribution is the uniform distribution, which does not produce outliers. [...] Distributions with <b>kurtosis</b> greater than 3 are said to be leptokurtic. [...] An example of a leptokurtic distribution is the Laplace distribution, which has tails that asymptotically approach zero more slowly than a Gaussian, and therefore produces more outliers than the normal distribution. It is also common practice to use an adjusted version of Pearson's <b>kurtosis,</b> the excess <b>kurtosis,</b> which is the <b>kurtosis</b> minus 3, to provide the comparison to the normal distribution. [...] Some authors use [...] "kurtosis" [...] by itself to refer to the excess <b>kurtosis.</b> [...] For the reason of clarity and generality, however, this article follows the non-excess convention and explicitly indicates where excess <b>kurtosis</b> is meant.|$|E
2500|$|... where γ2 {{denotes the}} {{population}} excess <b>kurtosis.</b> The excess <b>kurtosis</b> may be either known beforehand for certain distributions, or estimated from the data.|$|E
2500|$|The beta {{distribution}} {{has been applied}} in acoustic analysis to assess damage to gears, as the <b>kurtosis</b> of the {{beta distribution}} {{has been reported to}} be a good indicator of the condition of a gear. <b>Kurtosis</b> has also been used to distinguish the seismic signal generated by a person's footsteps from other signals. As persons or other targets moving on the ground generate continuous signals in the form of seismic waves, one can separate different targets based on the seismic waves they generate. <b>Kurtosis</b> is sensitive to impulsive signals, so it's much more sensitive to the signal generated by human footsteps than other signals generated by vehicles, winds, noise, etc. [...] Unfortunately, the notation for <b>kurtosis</b> has not been standardized. Kenney and Keeping [...] use the symbol γ2 for the excess <b>kurtosis,</b> but Abramowitz and Stegun [...] use different terminology. [...] To prevent confusion [...] between <b>kurtosis</b> (the fourth moment centered on the mean, normalized by the square of the variance) and excess <b>kurtosis,</b> when using symbols, they will be spelled out as follows: ...|$|E
2500|$|... (Excess <b>kurtosis</b> is {{negative}} for the beta distribution with zero skewness, ranging from -2 to 0, so that [...] -and therefore the sample shape parameters- is positive, ranging from zero when the shape parameters approach zero and the excess <b>kurtosis</b> approaches -2, to infinity when the shape parameters approach infinity and the excess <b>kurtosis</b> approaches zero).|$|E
2500|$|An {{example of}} a beta {{distribution}} near the upper boundary (excess <b>kurtosis</b> − (3/2) skewness2 = 0) is given by α = 0.1, β = 1000, for which the ratio (excess kurtosis)/(skewness2) = 1.49835 approaches the upper limit of 1.5 from below. An {{example of a}} beta distribution near the lower boundary (excess <b>kurtosis</b> + 2 − skewness2 = 0) is given by α= 0.0001, β = 0.1, for which values the expression (excess <b>kurtosis</b> + 2)/(skewness2) = 1.01621 approaches the lower limit of 1 from above. In the infinitesimal limit for both α and β approaching zero symmetrically, the excess <b>kurtosis</b> reaches its minimum value at −2. [...] This minimum value occurs at {{the point at which}} the lower boundary line intersects the vertical axis (ordinate). (However, in Pearson's original chart, the ordinate is <b>kurtosis,</b> instead of excess <b>kurtosis,</b> and it increases downwards rather than upwards).|$|E
2500|$|All densities in {{this family}} are symmetric. The kth moment exists {{provided}} m>(k+1)/2. For the <b>kurtosis</b> to exist, we require m>5/2. Then the mean and skewness exist and are both identically zero. Setting a2=2m−3 makes the variance equal to unity. Then the only free parameter is m, which controls the fourth moment (and cumulant) and hence the <b>kurtosis.</b> [...] One can reparameterize with , where [...] is the excess <b>kurtosis</b> as defined above. This yields a one-parameter leptokurtic family with zero mean, unit variance, zero skewness, and arbitrary non-negative excess <b>kurtosis.</b> The reparameterized density is ...|$|E
2500|$|The {{average of}} these values is 18.05 and the excess <b>kurtosis</b> is thus 18.05−3=15.05. [...] This example {{makes it clear}} that data near the [...] "middle" [...] or [...] "peak" [...] of the {{distribution}} do not contribute to the <b>kurtosis</b> statistic, hence <b>kurtosis</b> does not measure [...] "peakedness." [...] It is simply a measure of the outlier, 999 in this example.|$|E
2500|$|For non-zero sample {{skewness}} {{one needs}} to solve a system of two coupled equations. Since the skewness and the excess <b>kurtosis</b> are independent of the parameters , the parameters [...] can be uniquely determined from the sample skewness and the sample excess <b>kurtosis,</b> by solving the coupled equations with two known variables (sample skewness and sample excess <b>kurtosis)</b> and two unknowns (the shape parameters): ...|$|E
2500|$|It {{follows that}} {{the sum of}} two random {{variables}} can have <b>kurtosis</b> different from 3 (...) even if both random variables are have <b>kurtosis</b> of 3 in isolation ( [...] and [...] ).|$|E
2500|$|In {{probability}} theory and statistics, <b>kurtosis</b> (from , kyrtos or kurtos, meaning [...] "curved, arching") {{is a measure}} of the [...] "tailedness" [...] of the probability distribution of a real-valued random variable. In a similar way to the concept of skewness, <b>kurtosis</b> is a descriptor of the shape of a probability distribution and, just as for skewness, there are different ways of quantifying it for a theoretical distribution and corresponding ways of estimating it from a sample from a population. Depending on the particular measure of <b>kurtosis</b> that is used, there are various interpretations of <b>kurtosis,</b> and of how particular measures should be interpreted.|$|E
2500|$|Many {{incorrect}} {{interpretations of}} <b>kurtosis</b> that involve notions of peakedness have been given. One is that <b>kurtosis</b> measures both the [...] "peakedness" [...] {{of the distribution}} and the heaviness of its tail. Various other incorrect interpretations have been suggested, such as [...] "lack of shoulders" [...] (where the [...] "shoulder" [...] is defined vaguely as the area between the peak and the tail, or more specifically as the area about one standard deviation from the mean) or [...] "bimodality". Balanda and MacGillivray assert that the standard definition of <b>kurtosis</b> [...] "is a poor measure of the <b>kurtosis,</b> peakedness, or tail weight of a distribution" [...] and instead propose to [...] "define <b>kurtosis</b> vaguely as the location- and scale-free movement of probability mass from the shoulders of a distribution into its center and tails".|$|E
2500|$|A {{reason why}} some authors favor the excess <b>kurtosis</b> is that cumulants are {{extensive}}. [...] Formulas {{related to the}} extensive property are more naturally {{expressed in terms of}} the excess <b>kurtosis.</b> [...] For example, let X1, ..., X'n be independent random variables for which the fourth moment exists, and let Y be the random variable defined by the sum of the X'i. [...] The excess <b>kurtosis</b> of Y is ...|$|E
2500|$|... where κ is the <b>kurtosis,</b> var (...) is the {{variance}} and E (...) is the expectation operator. The <b>kurtosis</b> {{can now be}} seen to be a measure of the dispersion of Z2 around its expectation. Alternatively it can {{be seen to be}} a measure of the dispersion of Z around +1 and−1. κ attains its minimal value in a symmetric two-point distribution. In terms of the original variable X, the <b>kurtosis</b> {{is a measure of the}} dispersion of X around the two values μ±σ.|$|E
2500|$|The sample {{skewness}} g1 and <b>kurtosis</b> g2 {{are both}} asymptotically normal. However, {{the rate of}} their convergence to the distribution limit is frustratingly slow, especially for g2. For example even with [...] observations the sample <b>kurtosis</b> g2 has both the skewness and the <b>kurtosis</b> of approximately 0.3, which is not negligible. In order to remedy this situation, {{it has been suggested}} to transform the quantities g1 and g2 {{in a way that makes}} their distribution as close to standard normal as possible.|$|E
2500|$|W: Wigner {{semicircle}} distribution, blue curve, excess <b>kurtosis</b> = −1 ...|$|E
