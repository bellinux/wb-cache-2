48|939|Public
2500|$|If {{the data}} for a channel does not {{represent}} an integer number of blocks then the encoder must fill the remaining area of the incomplete blocks with some form of dummy <b>data.</b> <b>Filling</b> the edges with a fixed color (for example, black) can create ringing artifacts along the visible part of the border; ...|$|E
50|$|A digital {{printing}} system {{is attached to}} a computer database and many similar pages, called forms, are printed; each, for example, with a different person's <b>data</b> <b>filling</b> the form such as a monthly telephone or cable bill.|$|E
50|$|If {{the data}} for a channel does not {{represent}} an integer number of blocks then the encoder must fill the remaining area of the incomplete blocks with some form of dummy <b>data.</b> <b>Filling</b> the edges with a fixed color (for example, black) can create ringing artifacts along the visible part of the border;repeating the edge pixels is a common technique that reduces (but does not necessarily completely eliminate) such artifacts, and more sophisticated border filling techniques can also be applied.|$|E
40|$|Problem statement: Data {{entry form}} is a {{convenient}} and successful tool for information collection by {{filling in the}} sheets using pen and handwriting. One {{of the most important}} fields in these forms is the <b>data</b> <b>filled</b> boxes. Extracting the handwriting from the data entry forms is important for many purposes such as in documenting and archiving. The extraction process is also important in situations such as when it is necessary to the handwritten recognition process. Approach: A simple and effective approach is presented to extract handwritten characters, including digits and letters of any language from <b>data</b> <b>filled</b> boxes of <b>data</b> entry form and to deal with cases of overlaps between the handwritten characters and boxes lines. The proposed approach is based on line shape characteristic by detecting and removing the vertical and horizontal straight boxes lines, while preserving the curved lines which represent the handwritten characters. The problem of the handwritten characters overlapping with the <b>data</b> <b>filled</b> boxes line is solved using morphology dilation to reconstruct the broken characters after the removal of the boxes lines. Results: Experimental results have demonstrated that the proposed approach can extract handwriting from <b>data</b> <b>filled</b> boxes with overall 94. 052 % for data collection of 150 forms. Conclusion: The proposed algorithm has been successfully implemented and tested to achieve the objectives of handwritten extraction of any language from <b>data</b> <b>filled</b> boxes. However, this work could not deal with situations whereby the characters touch other immediate characters...|$|R
40|$|Data {{entry form}} is a {{convenient}} and successful too l for information collection by {{filling in the}} sheets using pen and h andwriting. One {{of the most important}} fields in the se forms is the <b>data</b> <b>filled</b> boxes. Extracting the hand writing from the data entry forms is important for many purposes such as in documenting and archiving. The extraction process is also important in situations such as when it is necessary to the hand written recognition process. Approach: A simple and effective approach is presented to extract hand written characters, including digits and letters of any language from <b>data</b> <b>filled</b> boxes of <b>data</b> entry f orm and to deal with cases of overlaps between the handwritten characters and boxes’ lines. The propos ed approach is based on line shape characteristic by detecting and removing the vertical and horizont al straight boxes’ lines, while preserving the curved lines which represent the handwritten charac ters. The problem of the handwritten characters overlapping with the <b>data</b> <b>filled</b> boxes’ line is sol ved using morphology dilation to reconstruct the broken characters after the removal of the boxes’ l ines. Results: Experimental results have demonstrated that the proposed approach can extract handwriting from <b>data</b> <b>filled</b> boxes with overall 94. 052 % for data collection of 150 forms. Conclusion: The proposed algorithm has been successfully implemented and tested to achieve the objectives of handwritten extraction of any language from <b>data</b> <b>filled</b> boxes. However, this work could not deal wit h situations whereby the characters touch other immediate characters...|$|R
50|$|<b>Data</b> <b>filled</b> in an XFA form may be {{submitted}} to a host using HTTP POST operation in XDP format, PDF format, XFDF format, XML 1.0 format or as an URL-encoded format.|$|R
30|$|We propose an {{alternative}} <b>data</b> <b>filling</b> approach for prediction of missing data in soft sets (ADFIS). The novelty of ADFIS is that, unlike the previous approach that used probability, we {{focus more on}} reliability of association between parameters.|$|E
30|$|Hence, {{from above}} {{associative}} comparison visualized in Table  7, {{we conclude that}} DFIS is more suitable than Zou et al. and Kong et al. approaches for prediction of missing values in soft set. However, in reviewing DFIS, accuracy is still its main problem. Therefore, the following section discusses an alternative <b>data</b> <b>filling</b> approach for prediction of missing data in soft sets, namely ADFIS.|$|E
40|$|Taxi passanger’s {{safety and}} {{security}} are main issues regarding to the daily commuting routine of people who use taxi. This research is aimed to give a mobile solution to the passangers. The application will be run on Android mobile phone. Android is chosen as the platform for its widely and globally use. The application development uses Rational Unified Process as the methodology in development. <b>Data</b> <b>filling</b> is done using QR code to save time...|$|E
40|$|We used {{flow cytometry}} to {{investigate}} intercellular distribution of E. coli tryptophanase, the enzyme that synthesize indole. The <b>data</b> <b>fill</b> {{the gap in}} studies of tryptophanase and corroborated previous works by other groups. We found that tryptophanase level in individual cells is highly heterogeneous...|$|R
30|$|The {{outcome of}} the {{questionnaire}} <b>data</b> <b>filled</b> in by the patients after the procedure showed that women are very motivated to be sterilised by this route, since they prevent an admission of more one day, the use of general anaesthesia, occurrence of postoperative pains, nausea and incompetence one day after {{and they do not}} have small scars on the abdominal skin.|$|R
5000|$|Data {{store of}} {{existing}} data and/or web page to collect <b>data</b> to <b>fill</b> onto forms ...|$|R
40|$|We {{present a}} machine {{learning}} approach for estimating missing temporal attributes in genealogical data. Genealogy analyses have been commonly focused on understanding generational relations. The importance of temporal analyses {{has often been}} suppresed in genealogical research. We have observed that temporal attributes of an individual, birth, death, marriage and divorce dates, are frequently missing in genealogical <b>data.</b> <b>Filling</b> out those attributes allows users to reconstruct temporal streams of their family stories, which in turn make fruitful genealogy analyses possible...|$|E
40|$|Abstract. This article {{analyzes}} the methods for project supervision in the geological prospecting industry at present, and proposes an embedded supervisal system of geological prospecting designed with the mobile terminals {{as an assistant}} supervisal measure, {{to increase the efficiency}} of project supervision. Supervisal indicators are categorized and studied, and an indicator system for the geological prospecting is introduced. The method for implementing AMF protocol based system is presented to solve huge <b>data</b> <b>filling</b> in the field...|$|E
30|$|Soft {{set theory}} is a {{mathematical}} approach that provides solution {{for dealing with}} uncertain data. As a standard soft set, it can be represented as a Boolean-valued information system, and hence {{it has been used}} in hundreds of useful applications. Meanwhile, these applications become worthless if the Boolean information system contains missing data due to error, security or mishandling. Few researches exist that focused on handling partially incomplete soft set and none of them has high accuracy rate in prediction performance of handling missing data. It is shown that the <b>data</b> <b>filling</b> approach for incomplete soft set (DFIS) has the best performance among all previous approaches. However, in reviewing DFIS, accuracy is still its main problem. In this paper, we propose an alternative <b>data</b> <b>filling</b> approach for prediction of missing data in soft sets, namely ADFIS. The novelty of ADFIS is that, unlike the previous approach that used probability, we focus more on reliability of association among parameters in soft set. Experimental results on small, 04 UCI benchmark data and causality workbench lung cancer (LUCAP 2) data shows that ADFIS performs better accuracy as compared to DFIS.|$|E
30|$|<b>Data</b> cleaning: <b>Fill</b> in missing values, smooth noisy data, {{identify}} {{or remove}} outliers, and resolve inconsistencies.|$|R
40|$|A {{methodology}} {{was developed}} to analyze discrete data obtained from the global distribution of ozone. Statistical analysis techniques were applied to describe the distribution of data variance in terms of empirical orthogonal functions and components of spherical harmonic models. The effects of uneven data distribution and missing data were considered. <b>Data</b> <b>fill</b> based on the autocorrelation structure of the data is described. Computer coding of the analysis techniques is included...|$|R
40|$|The {{striking}} {{development in}} the 9, 500 year adaptation of the maritime culture to San Clemente Island is the increasing-importance of kelp bed fishing. This evolution can be traced through faunal and artifact records. The artifact assemblage has been clarified by {{the discovery of a}} sea-grass bag containing a complete fisherman's kit. This "tackle box" was examined by tomography to define artifact provenience prior to dissection. The resulting <b>data</b> <b>fill</b> an important void in California Island archaeology...|$|R
40|$|The {{community}} of researchers studying {{global climate change}} is preparing to launch the first Earth Observing System (EOS) satellite, EOS AM- 1. The satellite will generate huge amounts of <b>data,</b> <b>filling</b> gaps in the information available to address critical questions about Earth's climate. But many data handling and data analysis problems must be solved {{if we are to}} make best use of the new measurements. In key areas, the experience and expertise of the statistics community could be of great help. sfatuhcs rlrcccf rdr...|$|E
30|$|Of the {{variables}} in our dataset, the series for {{roads and motorways}} were the ones subject to the most <b>data</b> <b>filling.</b> This was mostly to complete the series before 1980 although the limited availability of other data was a constraint in these regressions: only the equation for Denmark made use of the pre- 1980 data, although after then there were some countries (notably the Netherlands), for which one or two data points at a time had to be filled. Overall, relatively few of the series actually made use of the filled data.|$|E
40|$|Abstract—Mixed Raster Content (MRC) coding is an {{efficient}} way of coding compound images. The layered model used {{gives rise to}} missing data in the foreground and background layers. When using a block-based transform for coding, the usual solution has been {{to fill in the}} missing data using some form of interpolation. In this paper we instead present a method using matching pursuit to find the transform coefficents. The presented method gives a gain of up to 1 dB on the tested images, compared to common <b>data</b> <b>filling</b> methods. I...|$|E
40|$|This {{application}} uses to displaying searching name, {{in search}} of name all <b>data</b> <b>fill</b> in the linked list, linked list consisting of nim, name, address and phone. Linked list itself has the advantage in the allocation of memory, so the data can be accommodated {{as much as we}} want. This application also use Hash table for to accelerate the search time. Hash Table also can accommodate data alphabet to match the existing data in the linked list...|$|R
40|$|User manual Strategies for {{grouping}} {{chemicals to}} <b>fill</b> <b>data</b> gaps to assess {{acute aquatic toxicity}} endpoints For the latest news and the most up-todate information, please consult the ECHA website. User Manual Strategies for grouping chemicals to <b>fill</b> <b>data</b> gaps to assess acute aquatic toxicity endpoints Document history Versio...|$|R
500|$|In the 1970s, the Hawaiian {{seafloor}} was mapped using ship-based sonar. Computed SYNBAPS (Synthetic Bathymetric Profiling System) <b>data</b> <b>filled</b> holes {{between the}} ship-based sonar bathymetric measurements. From 1994 to 1998 the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) mapped Hawaii in detail and studied its ocean floor, {{making it one}} of the world's best-studied marine features. The JAMSTEC project, a collaboration with USGS and other agencies, utilized manned submersibles, remotely operated underwater vehicles, dredge samples, and core samples. The Simrad EM300 multibeam [...] side-scanning sonar system collected bathymetry and backscatter data.|$|R
40|$|To efficIyf'jVMwycyI rasterizedcasteri docerized anencMq' must bec'wAAIyf'jVMwyc Content {{adaptivity}} may beacBxxMy {{by employing}} a layeredapproacA Insuc anapproacy ac'jwVqy image is segmented into layers so that appropriateencopri cc be used tocyAxM'I these layers individually. A major facry in using standard encdard efficardyqBI tomatc the layers'c'yABxIIyfjxqx {{to those of}} theencjMBV byusing data fillingtecgyqI'x to fill-in the initiallysparse layers. In this work we present a review of methods dealing with <b>data</b> <b>filling</b> and propose also a suboptimal non-linear projecaryA scoje thatefficAIVIyfjV'Ixy the baseline JPEG cEGy inc'xBwwyfjV bacBwwyfj layers, leading to smaller files with better image quality...|$|E
30|$|In {{this section}} an {{alternative}} approach for <b>data</b> <b>filling</b> of incomplete soft sets (ADFIS) is presented. The previous approach DFIS preferred association between parameters to predict missing values than probability and we discussed that association results in more accurate values than probability. But DFIS itself is unable to precisely consider all possible associations for getting more accurate results. In contrast to DFIS, we revise the association calculating method to consider all possible associations precisely and predict maximum possible number of unknowns through it. The novelty of ADFIS is that, it focuses more on reliability of association than DFIS.|$|E
40|$|We {{propose a}} novel {{gap-filling}} technique, {{based on the}} em-pirical mode decomposition (EMD). The idea is that a signal with missing data can be decomposed into a set of intrinsic mode functions (IMFs) with missing <b>data.</b> <b>Filling</b> the gaps in each IMF should be easier than filling the gaps in the original signal. This is because each IMF varies much more slowly than the original signal, and also because the IMFs {{are known to have}} useful regularity properties. We demonstrate the per-formance of our technique on environmental pollutant data. Index Terms — Signal reconstruction, signal restoration, interpolation, signal processing algorithm...|$|E
40|$|Objectifs : Better {{knowledge}} {{of the evolution of}} the snow cover In mountain areas Gaspésie vs. French Alps Similar latitudes Both sides of the Atlantic Ocean Same time period : Winter months 1969 - 2011 Methods : Continuous series over the same period with Mean daily temperatures Daily total precipitations Snow depth (if available) Modeling of the snow cover evolution over the year (daily) : Snow water equivalent Snow depth Liquid precipitation Solid precipitation Missing <b>data</b> <b>filled</b> in based on the output of the model Trend analysis on the winter period only (December to April...|$|R
40|$|The {{proposed}} research {{uses the}} electron beam ion trap at the Lawrence Livermore National Laboratory (LLNL) to study X-ray emission from charge-exchange recombination of highly charged ions with neutral gases. The resulting <b>data</b> <b>fill</b> a void in existing experimental and theoretical {{understanding of this}} atomic physics process, and are needed to explain {{all or part of}} the observed X-ray emission from the soft X-ray background, stellar winds, the Galactic Center, supernova ejecta, and photoionized nebulae. Progress made during the first year of the grant is described, as is work planned for the second year...|$|R
50|$|In the 1970s, the Hawaiian {{seafloor}} was mapped using ship-based sonar. Computed SYNBAPS (Synthetic Bathymetric Profiling System) <b>data</b> <b>filled</b> holes {{between the}} ship-based sonar bathymetric measurements. From 1994 to 1998 the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) mapped Hawaii in detail and studied its ocean floor, {{making it one}} of the world's best-studied marine features. The JAMSTEC project, a collaboration with USGS and other agencies, utilized manned submersibles, remotely operated underwater vehicles, dredge samples, and core samples. The Simrad EM300 multibeam side-scanning sonar system collected bathymetry and backscatter data.|$|R
40|$|Incomplete {{information}} in a soft set restricts the usage of the soft set. To make the incomplete soft set more useful, in this paper, we propose a <b>data</b> <b>filling</b> approach for incomplete soft set in which missing data is filled {{in terms of the}} association degree between the parameters when stronger association exists between the parameters or in terms of the probability of objects appearing in the mapping sets of parameters when no stronger association exists between the parameters. An illustrative example is employed to show the feasibility and validity of our approach in practical applications...|$|E
40|$|The Magellan radar mapping {{mission is}} in the process of {{producing}} a global, high-resolution image and altimetry data set of Venus. Despite initial communications problems, few data gaps have occurred. Analysis of Magellan data {{is in the}} initial stages. The radar system data are of high quality, and the planned performance is being achieved in terms of spatial resolution and geometric and radiometric accuracy. Image performance exceeds expectations, and the image quality and mosaickability are extremely good. Future plans for the mission include obtaining gravity <b>data,</b> <b>filling</b> gaps in the initial map, and conducting special studies with the radar...|$|E
40|$|To {{efficiently}} compress rasterized compound documents, an encoder must be content-adaptive. Content adaptivity may {{be achieved}} by using a layered approach. In such an approach, a compound image is segmented into layers and then, the appropriate encoders are employed to compress these layers individually. A major factor in using these standard encoders efficiently is to match the layers’ characteristics to these of the encoder by using <b>data</b> <b>filling</b> techniques to fill-in the initially sparse layers. In this work we propose a sub-optimal non-linear projections scheme that efficiently matches the baseline JPEG coder in compressing background layers, leading to smaller files with better image quality. 1...|$|E
30|$|Another common {{approach}} for building PIOTs incorporates LCA data for individual sectors, {{similar to the}} tiered hybrid LCA approach (Crawford et al. 2018; Suh et al. 2004), where a subset of sectors is modeled with LCA and EIO <b>data</b> <b>fills</b> in for the rest. Nevertheless, the LCA data in physical units are often used to generate a new IOT in the IO-based hybrid LCA method (Malik et al. 2014; Wolfram et al. 2016; Teh et al. 2017). This approach offers good precision, validation, and comprehensive mass flows and environmental impacts. Yet, the opacity of the LCA datasets limits reproducibility, continuity and usefulness in long-term decision-making.|$|R
40|$|The first {{theoretical}} transition probabilities {{are obtained}} {{for a set}} of 46 Pm ii transitions of astrophysical interest. These <b>data</b> <b>fill</b> in a gap in astrophysics and will allow to establish, on a firmer basis, the presence of some lines of this radioactive element in the spectra of chemically peculiar stars and, consequently, a quantitative investigation of the stellar Pm abundance. A search for Pm ii lines in Przybylski's star (HD 101065) and in HR 465 is reported and discussed, supporting the detection of this ion. A more detailed quantitative analysis is awaiting the availability of dedicated model atmospheres for these stars. Peer reviewe...|$|R
40|$|In {{the good}} old times shop manager knew their {{customers}} personally {{and were able to}} tailor offerings to their needs and desires. But how can we create meaningful moments for connected consumers in global markets? Yasmeen Ahmad explains how in digital times <b>data</b> <b>fill</b> in. Smart algorithms help generate insights and enable real time action to provide the right product and service to the right customer at the right time. Companies that don’t want to be left behind a digital elite need to remain close to their customers across multiple digital touchpoints. Being capable of reading, interpreting and acting upon consumers` traces is a prerequisite...|$|R
