1|10000|Public
40|$|We {{extend our}} earlier work on deep-structured {{conditional}} random field (DCRF) and develop deep-structured hidden conditional random field (DHCRF). We investigate {{the use of}} this new sequential <b>deep-learning</b> <b>model</b> <b>for</b> phonetic recognition. DHCRF is a hierarchical model in which the final layer is a hidden conditional random field (HCRF) and the intermediate layers are zero-th-order conditional random fields (CRFs). Parameter estimation and sequence inference in the DHCRF are developed in this work. They are carried out layer by layer so that the time complexity is linear to the number of layers. In the DHCRF, the training label is available only at the final layer and the state boundary is unknown. This difficulty is addressed by using unsupervised learning for the intermediate layers and lattice-based supervised learning for the final layer. Experiments on the standard TIMIT phone recognition task show small performance improvement of a three-layer DHCRF over a two-layer DHCRF; both are significantly better than the single-layer DHCRF and are superior to the discriminatively trained tri-phone hidden Markov model (HMM) using identical input features. Index Terms: hidden conditional random field, conditional random field, deep structure, phone recognition, TIMI...|$|E
40|$|Predicting the {{stability}} of crystals {{is one of the}} central problems in materials science. Today, density functional theory (DFT) calculations are the computational tool of choice to obtain energies of crystals with quantitative accuracy. Despite algorithmic and computing advances, DFT calculations remain comparatively expensive and scale poorly with system size. Here we show that deep neural networks utilizing just two descriptors - the Pauling electronegativity and ionic radii - can predict the DFT formation energies of C 3 A 2 D 3 O 12 garnets with extremely low mean absolute errors of 7 - 8 meV/atom, an order of magnitude improvement over previous machine learning models and well within the limits of DFT accuracy. Further extension to mixed garnets with little loss in accuracy can be achieved using a binary encoding scheme that introduces minimal increase in descriptor dimensionality. Our results demonstrate that generalizable <b>deep-learning</b> <b>models</b> <b>for</b> quantitative crystal stability prediction can be built on a small set of chemically-intuitive descriptors. Such models provide the means to rapidly transverse vast chemical spaces to accurately identify stable compositions, accelerating the discovery of novel materials with potentially superior properties. Comment: 4 figure...|$|R
40|$|Computational {{methods that}} {{automatically}} extract knowledge from data {{are critical for}} enabling data-driven materials science. A reliable identification of lattice symmetry is a crucial first step for materials characterization and analytics. Current methods require a user-specified threshold, and are unable to detect "average symmetries" for defective structures. Here, we propose a new machine-learning-based approach to automatically classify structures by crystal symmetry. First, we represent crystals by a diffraction image, and then construct a <b>deep-learning</b> neural-network <b>model</b> <b>for</b> classification. Our approach is able to correctly classify a dataset comprising more than 80, 000 structures, including heavily defective ones. The internal operations of the neural network are unraveled through attentive response maps, demonstrating that it uses the same landmarks a materials scientist would use, although never explicitly instructed to do so. Our study paves the way for crystal-structure recognition in computational and experimental big-data materials science...|$|R
40|$|This work explores <b>deep-learning</b> <b>model</b> to {{classify}} drug resistance for Mycobacterium tuberculosis. We applied an end-to-end model on DNA mutations of the pathogen and lab-based phenotyping results. The model first stacks 3 auto-encoders, and then applies multiple classifiers {{to classify}} resistance for four first-line drugs. The results is promising {{and show the}} potential of the <b>model</b> <b>for</b> drug resistance analysis...|$|R
40|$|The advancements of {{technology}} continuously rising {{over the years}} has seen many applications that are useful in providing users with sufficient information to make better journey plans on their own. However, commuters still find themselves going through congested routes every day to get to their destinations. This paper attempts to delineate the possibilities of improving urban mobility through big data processing and <b>deep-learning</b> <b>models.</b> Essentially, through a predictive model to predict congestion and its duration, this paper aims to develop and validate a functional journey planning mobile application that can predict traffic conditions, allowing road users to make better informed decisions to their travel plans. This paper proposes a Multi-Layered Perceptron (MLP) deep learning <b>model</b> <b>for</b> congestion prediction and supplements a Linear Regression (LR) model to predict its duration. The proposed MLP-LR model performed reasonably well with an accuracy of 63 % in predicting an occurrence of congestion. Some critical discussions on further research opportunities stemming from this study is also presented...|$|R
40|$|As first-person {{cameras in}} head-mounted {{displays}} become increasingly prevalent, {{so does the}} problem of infringing user and bystander privacy. To address this challenge, we present PrivacEye, a proof-of-concept system that detects privacysensitive everyday situations and automatically enables and disables the first-person camera using a mechanical shutter. To close the shutter, PrivacEye detects sensitive situations from first-person camera videos using an end-to-end <b>deep-learning</b> <b>model.</b> To open the shutter without visual input, PrivacEye uses a separate, smaller eye camera to detect changes in users' eye movements to gauge changes in the "privacy level" of the current situation. We evaluate PrivacEye on a dataset of first-person videos recorded in the daily life of 17 participants that they annotated with privacy sensitivity levels. We discuss {{the strengths and weaknesses}} of our proof-of-concept system based on a quantitative technical evaluation as well as qualitative insights from semi-structured interviews. Comment: 13 pages, 10 figure...|$|R
40|$|Although various {{techniques}} {{have been proposed}} to generate adversarial samples for white-box attacks on text, {{little attention has been}} paid to a black-box attack, which is a more realistic scenario. In this paper, we present a novel algorithm, DeepWordBug, to effectively generate small text perturbations in a black-box setting that forces a deep-learning classifier to misclassify a text input. We develop novel scoring strategies to find the most important words to modify such that the deep classifier makes a wrong prediction. Simple character-level transformations are applied to the highest-ranked words in order to minimize the edit distance of the perturbation. We evaluated DeepWordBug on two real-world text datasets: Enron spam emails and IMDB movie reviews. Our experimental results indicate that DeepWordBug can reduce the classification accuracy from 99 % to around 40 % on Enron data and from 87 % to about 26 % on IMDB. Also, our experimental results strongly demonstrate that the generated adversarial sequences from a <b>deep-learning</b> <b>model</b> can similarly evade other deep models...|$|R
40|$|As {{a typical}} <b>deep-learning</b> <b>model,</b> Convolutional Neural Networks (CNNs) can be {{exploited}} to automatically extract features from images using the hierarchical structure inspired by mammalian visual system. For image classification tasks, traditional CNN models employ the softmax function for classification. However, {{owing to the}} limited capacity of the softmax function, there are some shortcomings of traditional CNN models in image classification. To deal with this problem, a new method combining Biomimetic Pattern Recognition (BPR) with CNNs is proposed for image classification. BPR performs class recognition by a union of geometrical cover sets in a high-dimensional feature space and therefore can overcome some disadvantages of traditional pattern recognition. The proposed method is evaluated on three famous image classification benchmarks, that is, MNIST, AR, and CIFAR- 10. The classification accuracies of the proposed method for the three datasets are 99. 01 %, 98. 40 %, and 87. 11 %, respectively, which are much higher {{in comparison with the}} other four methods in most cases...|$|R
40|$|Generating videos from text {{has proven}} to be a {{significant}} challenge <b>for</b> existing generative <b>models.</b> We tackle this problem by training a conditional generative model to extract both static and dynamic information from text. This is manifested in a hybrid framework, employing a Variational Autoencoder (VAE) and a Generative Adversarial Network (GAN). The static features, called "gist," are used to sketch text-conditioned background color and object layout structure. Dynamic features are considered by transforming input text into an image filter. To obtain a large amount of data <b>for</b> training the <b>deep-learning</b> <b>model,</b> we develop a method to automatically create a matched text-video corpus from publicly available online videos. Experimental results show that the proposed framework generates plausible and diverse videos, while accurately reflecting the input text information. It significantly outperforms baseline models that directly adapt text-to-image generation procedures to produce videos. Performance is evaluated both visually and by adapting the inception score used to evaluate image generation in GANs...|$|R
40|$|We present DeepPicar, a {{low-cost}} {{deep neural network}} (DNN) based autonomous car platform. DeepPicar is a small scale replication of a real self-driving car called Dave- 2 by NVIDIA, which drove on public roads using a {{deep convolutional neural network}} (CNN), that takes images from a front-facing camera as input and produces car steering angles as output. DeepPicar uses the exact same network architecture [...] - 9 layers, 27 million connections and 250 K parameters [...] -and can be trained to drive itself, in real-time, using a web camera and a modest Raspberry Pi 3 quad-core platform. Using DeepPicar, we analyze the Pi 3 's computing capabilities to support end-to-end deep learning based real-time control of autonomous vehicles. We also systematically compare other contemporary embedded computing platforms using the DeepPicar's CNN based real-time control software as a workload. We find all tested platforms, including the Pi 3, are capable of supporting deep-learning based real-time control, from 20 Hz up to 100 Hz depending on hardware platform. However, shared resource contention remains an important issue that must be considered in applying <b>deep-learning</b> <b>models</b> on shared memory based embedded computing platforms. Comment: 10 pages, 15 figures, 3 table...|$|R
40|$|How {{does the}} brain {{represent}} visual {{information from the}} outside world? Here, we approach this question with a {{deep convolutional neural network}} that mimics neuronal circuitry and coding, and learns to solve computer vision tasks. Using this network as a computational model of the visual cor-tex, we develop novel encoding and decoding mod-els to describe the bi-directional relationships be-tween visual input and cortical activity measured with functional magnetic resonance imaging. Test-ing these models with imaging data from humans watching natural movies, we show that the encod-ing model can predict cortical responses and re-trieve visual representations at individual brain lo-cations, and that the decoding model can decipher the measured cortical activity to reconstruct the visual and semantic experiences. Both the encod-ing and decoding models utilize cortical representa-tions of hierarchical, invariant, and nonlinear visual features. Being self-contained, efficient, and gener-alizable, these models constitute a computational workbench for high-throughput investigation of all stages of visual processing. We also anticipate that the general strategy for neural encoding and decod-ing via <b>deep-learning</b> <b>models</b> will be applicable to other sensory or cognitive experiences, e. g. speech, imagery, memories and dreams. Comment: 16 pages, 8 figures, 1 tabl...|$|R
40|$|Indexes are models: a B-Tree-Index {{can be seen}} as a {{model to}} map a key to the {{position}} of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of <b>models,</b> including <b>deep-learning</b> <b>models,</b> which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70 % in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible...|$|R
40|$|Recognition of {{different}} genomic signals and regions (GSRs) in the DNA is helpful in gaining knowledge to understand genome organization and gene regulation {{as well as}} gene function. Accurate recognition of GSRs enables better genome and gene annotation. Although many methods {{have been developed to}} recognize GSRs, their pure computational identification remains challenging. Moreover, various GSRs usually require a specialized set of features for developing robust recognition <b>models.</b> Recently, <b>deep-learning</b> (DL) methods have been shown to generate more accurate prediction models than the ‘shallow’ methods without the need to develop specialized features for the problems in question. Here, we explore the potential use of DL for the recognition of GSRs. We developed DeepGSR, an optimized DL architecture for the prediction {{of different}} types of GSRs. The performance of the DeepGSR structure is evaluated on the recognition of polyadenylation signals (PAS) and translation initiation sites (TIS) of different organisms: human, mouse, bovine and fruit fly. The results show that DeepGSR outperformed the state-of-the-art methods, reducing the classification error rate of the PAS and TIS prediction in the human genome by up to 29 % and 86 %, respectively. Moreover, the cross-organisms and genome-wide analyses we performed, confirmed the robustness of DeepGSR and provided new insights into the conservation of examined GSRs across species. README: DeepGSR: An optimized deep-learning structure for the recognition of genomic signals and regions. Version 1. 1 13 /Dec/ 2017 WHAT IS IT? [...] - DeepGSR is a <b>deep-learning</b> <b>model</b> {{that can be used for}} the recognition of genomic signals and regions with Eukaryotic DNA. It has been applied to polyadenylation signals (PAS) and translation initiation site (TIS). It uses fasta format DNA Sequences as input. But you can process the data using the provided code. COMMAND LINE VERSION [...] Here we include the source code of DeepGSR written in Python language and using Keras library with Theano backend. INSTALLATION [...] DeepGSR is able to run on any linux platform. To run DeepGSR: 	Install scikit-learn ([URL] keras ([URL] and cuda for if you want faster processing using GPUs. 	The data that were used in the paper found in the (Data) folder. 	There are two types of DeepGSR usage, either for testing using pre-trained <b>models</b> or <b>for</b> training new models; each of these types found in a separate folder. 	Open a new terminal, then go to the directory that contains the python code. For example: cd Testing/ or cd Training/DeepGSR- 2 DCNN 	Running DeepGSR, command line options: python CNN_Testing. py –h or python 2 DCNN. py –h EXAMPLE: [...] Note: all required data is included in this package Train DeepGSR on human genome for PAS recognition: python 2 DCNN. py [...] inputFile [...] / [...] /Data/Human/PAS_processed/hs_mixAATAAA_polyA. txt [...] DataName human_AATAAA [...] FileName human_AATAAA Train DeepGSR on human genome for TIS recognition: python 2 DCNN. py [...] inputFile [...] / [...] /Data/Human/TIS_processed/hs_mixATG_TIS. txt [...] DataName human_ATG [...] FileName human_ATG Test DeepGSR on mouse genome using human trained <b>model</b> <b>for</b> PAS recognition: python CNN_Testing. py [...] inputFile [...] / [...] /Data/Mouse/PAS_processed/mm_mixAATAAA_polyA. txt –inputModel [...] /human_AATAAA_Model. h 5 [...] DataName mouse_AATAAA [...] FileName mouse_human_AATAAA Test DeepGSR on mouse genome using human trained <b>model</b> <b>for</b> TIS recognition: python CNN_Testing. py [...] inputFile [...] / [...] /Data/Mouse/TIS_processed/mm_mixATG_TIS. txt [...] inputModel [...] /human_ATG_Model. h 5 [...] DataName mouse_ATG [...] FileName mouse_human_ATG CONTACTS [...] 	If you want to report bugs or have general queries email to: 	 		manal. kalkatawi@kaust. edu. s...|$|R
40|$|In recent years, many <b>deep-learning</b> based <b>models</b> are {{proposed}} <b>for</b> text classification. This kind of models well fits the training set from the statistical point of view. However, {{it lacks the}} capacity of utilizing instance-level information from individual instances in the training set. In this work, we propose to enhance neural network models {{by allowing them to}} leverage information from $k$-nearest neighbor (kNN) of the input text. Our model employs a neural network that encodes texts into text embeddings. Moreover, we also utilize $k$-nearest neighbor of the input text as an external memory, and utilize it to capture instance-level information from the training set. The final prediction is made based on features from both the neural network encoder and the kNN memory. Experimental results on several standard benchmark datasets show that our model outperforms the baseline model on all the datasets, and it even beats a very deep neural network model (with 29 layers) in several datasets. Our model also shows superior performance when training instances are scarce, and when the training set is severely unbalanced. Our model also leverages techniques such as semi-supervised training and transfer learning quite well...|$|R
40|$|Scene Text Localization and Recognition methods nd {{all areas}} in an image or a video {{that would be}} {{considered}} as text by a human, mark boundaries of the areas and output a sequence of characters associated with its content. They are used to process images and videos taken by a digital camera or a mobile phone and to " the content of each text area into a digital format, typically a list of Unicode character sequences, that can be processed in further applications. Three di erent methods for Scene Text Localization and Recognition were proposed {{in the course of}} the research, each one advancing the state of the art and improving the accuracy. The rst method detects individual characters as Extremal Regions (ER), where the probability of each ER being a character is estimated using novel features with O(1) complexity and only ERs with locally maximal probability are selected across several image projections for the second stage, where the classi cation is improved using more computationally expensive features. The method was the rst published method to address the complete problem of scene text localization and recognition as a whole - all previous work in the literature focused solely on di erent subproblems. Secondly, a novel easy-to-implement stroke detector was proposed. The detector is signi cantly faster and produces signi cantly less false detections than the commonly used ER detector. The detector e ciently produces character strokes segmentations, which are exploited in a subsequent classi cation phase based on features e ectively calculated as part of the segmentation process. Additionally, an e cient text clustering algorithm based on text direction voting is proposed, which as well as the previous stages is scale- and rotation- invariant and supports wide variety of scripts and fonts. The third method exploits a <b>deep-learning</b> <b>model,</b> which is trained for both text detection and recognition in a single trainable pipeline. The method localizes and recognizes text in an image in a single feed-forward pass, it is trained purely on synthetic data so it does not require obtaining expensive human annotations for training and it achieves state-of-the-art accuracy in the end-to-end text recognition on two standard datasets, whilst being an order of magnitude faster than the previous methods - the whole pipeline runs at 10 frames per second. Katedra kybernetik...|$|R
40|$|Preface <b>Modeling</b> <b>for</b> Heat Flow Process Fluid and Fluid Mechanics Two Phases Flow and Vapor Bubble Dynamic <b>Modeling</b> <b>for</b> Heat and Mass Transfer Vapor Pressure and Saturation Temperature Finite Difference and Method of Characteristics for Transitional Flow Lagrangian and Eulerian Transitional Flow Dynamic <b>Modeling</b> <b>for</b> Water Flow <b>Modeling</b> <b>for</b> Flow Process Dynamic <b>Modeling</b> <b>for</b> Mass and Momentum Transport Index</P...|$|R
50|$|At age 13, Liza was scouted as a <b>model</b> <b>for</b> JJ {{and started}} <b>modeling</b> <b>for</b> the magazine. After that, she became an {{exclusive}} <b>model</b> <b>for</b> the Oggi magazine.|$|R
40|$|In {{the last}} decades several {{preclinical}} <b>models</b> <b>for</b> sepsis {{have been used to}} study the pathophysiologic processes during sepsis. Although these studies revealed promising immunomodulating agents for the treatment of sepsis, clinical trials evaluating the efficacy of these new agents in septic patients were disappointing. It should be realized that most of the preclinical <b>models</b> <b>for</b> sepsis lack a localized infectious source from which the infection disseminates. Studies on the effects of several immunomodulating strategies have demonstrated strikingly opposite results when using <b>models</b> <b>for</b> sepsis with a more natural route of infection, such as pneumonia, and when using <b>models</b> <b>for</b> sepsis lacking an infectious focus. In this review we will compare <b>models</b> <b>for</b> sepsis and <b>models</b> <b>for</b> pneumonia. We advise to use a combination of <b>models,</b> including <b>models</b> <b>for</b> sepsis and <b>models</b> <b>for</b> localized infections, to test new immunomodulating strategies before starting any clinical trial evaluating a new immunomodulating therap...|$|R
40|$|Fixed {{effects in}} the <b>model</b> <b>for</b> backfat {{thickness}} and the time on test were evaluated. Data records from large scale farm in period from January 1998 to December 2007 were analyzed. Two models were developed. Fixed effects of genotype, season and weight {{were included in the}} <b>model</b> <b>for</b> backfat thickness. The <b>model</b> <b>for</b> time on test was simpler than <b>model</b> <b>for</b> backfat thickness, containing only fixed effects of genotype and season. Choice of the model was based on coefficient of regression and degrees of freedom. The <b>model</b> <b>for</b> backfat thickness explained 56 % of the variability, while the <b>model</b> <b>for</b> time on test explained 65 % of variability. The results of this investigation will be useful in future development of the <b>model</b> <b>for</b> prediction of breeding values for gilts in field test...|$|R
40|$|Multivariate {{challenges}} 3 Non-stationary extremes Penalised B-splines Quantile regression <b>model</b> <b>for</b> {{extreme value}} threshold Poisson <b>model</b> <b>for</b> rate of threshold exceedance Generalised Pareto <b>model</b> <b>for</b> size of threshold exceedance Return values 4 Current developments Extremal dependence Conditional extreme...|$|R
40|$|A {{comparison}} {{was made}} among the CEAS crop reporting district (CRD), agrophysical unit (APU), and state level multiple regression yield <b>models</b> <b>for</b> {{corn and soybeans}} in Iowa and barley and spring wheat in North Dakota. The best predictions {{were made by the}} state <b>model</b> <b>for</b> North Dakota spring wheat, by the APU <b>models</b> <b>for</b> barley, by the CRD <b>models</b> <b>for</b> Iowa soybeans, and by APU covariance <b>models</b> <b>for</b> Iowa corn. Because of this lack of consistency of model performance, CRD models would be recommended due to the availability of the data...|$|R
40|$|This paper {{describes}} a dataset containing small images of text from everyday scenes. The {{purpose of the}} dataset is to support {{the development of new}} automated systems that can detect and analyze text. Although much research has been devoted to text detection and recognition in scanned documents, relatively little attention has been given to text detection in other types of images, such as photographs that are posted on social-media sites. This new dataset, known as COCO-Text-Patch, contains approximately 354, 000 small images that are each labeled as "text" or "non-text". This dataset particularly addresses the problem of text verification, which is an essential stage in the end-to-end text detection and recognition pipeline. In order to evaluate the utility of this dataset, it has been used to train two deep convolution neural networks to distinguish text from non-text. One network is inspired by the GoogLeNet architecture, and the second one is based on CaffeNet. Accuracy levels of 90. 2 % and 90. 9 % were obtained using the two networks, respectively. All of the images, source code, and <b>deep-learning</b> trained <b>models</b> described in this paper will be publicly availableComment: Accepted in the 12 th International Symposium on Visual Computing (ISVC' 16...|$|R
50|$|Also to <b>modeled</b> <b>for</b> various {{recognized}} magazines. In 2013, {{she became}} <b>model</b> <b>for</b> the Italian lingerie label Intimissimi.|$|R
5000|$|Škoda 06 T - {{bidirectional}} <b>model</b> <b>for</b> Cagliari, Italy; Škoda 19 T - bidirectional <b>model</b> <b>for</b> Wrocław, Poland ...|$|R
40|$|AbstractUsing {{discrete}} time process algebra {{with relative}} timing, a <b>model</b> <b>for</b> the I 2 C-bus is designed. The {{model of the}} I 2 C-bus {{is divided into three}} parts: a <b>model</b> <b>for</b> the bus lines, a <b>model</b> <b>for</b> the master interfaces and a <b>model</b> <b>for</b> the slave interfaces. The model of the bus lines is based on a <b>model</b> <b>for</b> a wired-AND. <b>For</b> the <b>models</b> of the interfaces, the approach is to start from a high level bus protocol and refine it step by step. First, a single master without timing constraints is considered. Then the model is adapted to deal with the timing constraints. Then also the restriction to a single master is relaxed. It turns out that the <b>model</b> <b>for</b> the slave interfaces can be based on the <b>model</b> <b>for</b> the master interfaces. The use of the model obtained is discussed and illustrated...|$|R
40|$|A {{mathematical}} <b>model</b> <b>for</b> a lit cigarette is derived, which predicts pressure, flow velocity, {{temperature and}} gas concentrations {{inside and outside}} the cigarette. It consists of a continuum-mechanical <b>model</b> <b>for</b> the flow and a discrete <b>model</b> <b>for</b> the chemical reactions occurring in the tobacco particles...|$|R
50|$|His {{research}} {{focused on}} stochastic <b>modelling</b> <b>for</b> business {{and led to}} influential results in option theory (with David M. Kreps, 1980).Later he studied Brownian network <b>models</b> <b>for</b> logistics and <b>models</b> <b>for</b> optimizing telephone call centers. More recently he has studied dynamic pricing and revenue management.|$|R
50|$|She has <b>modeled</b> <b>for</b> Sports Illustrated. She {{has also}} <b>modeled</b> <b>for</b> Joanne Gair's body {{painting}} works in these editions.|$|R
5000|$|... #Caption: Graziella Curreli with <b>model</b> <b>for</b> Kenau-Ripperda {{monument}} from 2009 and Kenau <b>model</b> <b>for</b> Kenau Hasselaer Prijs from 2008 ...|$|R
40|$|Various <b>models</b> <b>for</b> {{interacting}} spherical {{bubbles in}} a compressible liquid based on delay differential equations are considered. It is shown that most previously proposed <b>models</b> <b>for</b> interacting spherical bubbles in a compressible liquid {{based on the}} Keller-Miksis and Gilmore-Akulichev <b>models</b> are unstable <b>for</b> closely spaced bubbles. A new <b>model</b> <b>for</b> a single spherical bubble in a compressible liquid is proposed and used to derive a stable <b>model</b> <b>for</b> interacting bubbles. A qualitative comparison {{to the results of}} direct numerical integration of the fluid equations of motion suggests that the new model provides more accurate results than the standard Keller-Miksis or Gilmore-Akulichev <b>models</b> <b>for</b> single bubble dynamics. Comment: 13 pages, 4 figure...|$|R
40|$|The {{information}} systems with incomplete attribute values and fuzzy decisions commonly exist in practical problems. On {{the base of}} the notion of variable precision rough set <b>model</b> <b>for</b> incomplete information system and the rough set <b>model</b> <b>for</b> incomplete and fuzzy decision information system, the variable rough set <b>model</b> <b>for</b> incomplete and fuzzy decision information system is constructed, which is the generalization of the variable precision rough set <b>model</b> <b>for</b> incomplete information system and that of rough set <b>model</b> <b>for</b> incomplete and fuzzy decision information system. The knowledge reduction and heuristic algorithm, built on the method and theory of precision reduction, are proposed...|$|R
50|$|She {{negotiated}} the contract for Dan Carter as a <b>model</b> <b>for</b> Jockey Underwear, and supplies every <b>model</b> <b>for</b> Farmers advertisements.|$|R
50|$|Richardson {{has been}} a <b>model</b> <b>for</b> Versace. He also <b>modeled</b> <b>for</b> Vogue and is a brand {{ambassador}} for TAG Heuer.|$|R
50|$|In 2009 Ui was an {{exclusive}} <b>model</b> <b>for</b> the magazine JJ. She is later a <b>model</b> <b>for</b> Ray and Spring.|$|R
30|$|As {{the figure}} suggests, the {{accounting}} <b>model</b> <b>for</b> a given resource is an aggregation of three elementary models: a <b>model</b> <b>for</b> traffic consumption, a <b>model</b> <b>for</b> operation consumption and a <b>model</b> <b>for</b> resource consumption. In particular, the accounting {{model of a}} particular resource will be strongly consumer–centric if all the three of its elementary models are strongly consumer-centric. These elementary models operate independently from each other, thus they can be specified and examined separately.|$|R
40|$|Vector autoregressive (VAR) <b>models</b> <b>for</b> {{stationary}} {{and integrated}} variables are reviewed. Model specification and parameter estimation are discussed and various uses of these <b>models</b> <b>for</b> forecasting and economic analysis are considered. For integrated and cointegrated variables {{it is argued}} that vector error correction models offer a particularly convenient parameterization both <b>for</b> <b>model</b> specification and <b>for</b> using the <b>models</b> <b>for</b> economic analysis. VAR, vector autoregressive models...|$|R
