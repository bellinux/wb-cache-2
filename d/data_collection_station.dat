4|10000|Public
40|$|Copyright © 2014 Ammar Hawbani et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. In accor-dance of the Creative Commons Attribution License all Copyrights © 2014 are reserved for SCIRP {{and the owner of}} the intellectual property Ammar Hawbani et al. All Copyright © 2014 are guarded by law and by SCIRP as a guardian. Due to the limited communication range of WSN, the sensor is unable to establish direct connection to the <b>data</b> <b>collection</b> <b>station,</b> therefore the collaborative work of nodes is highly necessary. The data routing {{is one of the most}} fundamental processes exploring how to transmit data from the sensing field to the <b>data</b> <b>collection</b> <b>station</b> via the least possible number of intermediate nodes. This paper addresses the problem of data routing based on the sensors grouping; it provides a deep insight on how to divide the sensors of a network into separate inde-pendent groups, and how to organize these independent groups in order to make them work collaboratively and accomplish the process of data routing within the network...|$|E
40|$|The {{installation}} of environmental data collection systems at several remotely located sites in {{islands in the}} Pacific Ocean is summarized. The effort was designed to enhance the ability to collect hydrological information. The <b>data</b> <b>collection</b> <b>station</b> consists of a data acquisition system for handling data, a transmitter for uplinking information to the GOES-W geostationary satellite, {{and a variety of}} environmental sensors for data accumulation. Each system was assembled, tested, and deployed on designated islands. The concept of using microprocessors for handling data at remote sites and relaying it via a satellite link is a cost effective approach. Such systems require high reliability and proven performance in the field...|$|E
40|$|The 1971 Apollo 14 Mission to Fra Mauro, a lunar {{highland}} area, {{is highlighted}} in this video. The mission's primary goal was {{the collection of}} lunar rocks and soil samples and lunar exploration. The soil and rock sampling was for the geochronological determination of the Moon's evolution and its comparison with that of Earth. A remote <b>data</b> <b>collection</b> <b>station</b> was assembled on the Moon and left for continuous data collection and surface monitoring experiments. The Apollo 14 astronauts were Alan B. Shepard, Edgar D. Mitchell, and Stuart A. Rossa. Astronauts Shepard and Mitchell landed on the Moon (February 5, 1971) and performed the sampling, the EVA, and deployment of the lunar experiments. There is film-footage of the lunar surface, of the command module's approach to both the Moon and the Earth, Moon and Earth spacecraft launching and landing, in-orbit command- and lunar-module docking, and of Mission Control...|$|E
40|$|Bibliography) Bibliography. Also shows hydrologic <b>data</b> <b>collection</b> <b>stations.</b> Also covers Orlando region. Includes text, inset "Map of Seminole County showing {{dissolved}} solids content of water [...] .," 2 graphs, and location map. (Funding) Map series (Florida. Bureau of Geology);(Statement of Responsibility) by C. H. Tibbals; prepared by United States Geological Survey {{in cooperation with}} Florida Department of Natural Resources and Seminole County Commissioners...|$|R
40|$|Provides {{real-time}} {{water temperature}} data and average monthly temperatures from stations along coastal U. S. Clickable map or links {{take you to}} Atlantic coast, Gulf and selected Caribbean sites, Pacific coast, Alaska, Hawaii and selected Pacific Islands. Some entries connect directly to <b>data</b> <b>collection</b> <b>stations</b> with additional <b>data</b> available. NODC also provides other oceanographic data, from waves and currents to plankton and other biological parameters. Educational levels: High school...|$|R
40|$|The {{potential}} {{market for a}} <b>data</b> <b>collection</b> system was investigated {{to determine whether the}} user needs would be sufficient to support a satellite relay <b>data</b> <b>collection</b> system design. The activities of 107, 407 <b>data</b> <b>collections</b> <b>stations</b> were studied to determine user needs in agriculture, climatology, environmental monitoring, forestry, geology, hydrology, meteorology, and oceanography. Descriptions of 50 distinct <b>data</b> <b>collections</b> networks are described and used to form the user data base. The computer program used to analyze the station data base is discussed, and results of the analysis are presented in maps and graphs. Information format and coding is described in the appendix...|$|R
40|$|The extreme {{temperature}} trends are analyzed for a meteorological <b>data</b> <b>collection</b> <b>station</b> in Jeddah, Saudi Arabia over approximately last four decades stretching between years 1970 and 2006. The long-term change in temperature has been assessed by Mann-Kendell rank statistics and linear trend analysis. The study {{also includes the}} estimation of hot and cold days and nights frequencies and finally the temperature anomalies on yearly basis. The ratio between the seasonal mean temperatures (Tmmean) of the daily mean of hottest (July) and coldest (January) months was 1. 032. Similarly the ratios between the seasonal mean temperature of daily maximum (Tmmax) of hottest and coldest months was 1. 033 while for seasonal mean temperature of daily minimum (Tmmin) was 1. 030. Significant increase was observed in hot days per year and relatively smaller decrease in hot nights. Significant increase in summer time temperatures was confirmed by both linear regression analysis and M-K rank statistics. The monthly and annual mean maximum temperatures have increased more than the mean and mean minimum temperatures...|$|E
5000|$|Monthly Climatic Data for the World (MCDW) is {{a monthly}} {{publication}} of the National Climatic Data Center (NCDC) division of the National Environmental Satellite, Data, and Information Service (NESDIS) division of the National Oceanic and Atmospheric Administration (NOAA) of the United States. According to the website, each monthly issue [...] "contains monthly mean temperature, pressure, precipitation, vapor pressure, and sunshine for approximately 2,000 surface <b>data</b> <b>collection</b> <b>stations</b> worldwide and monthly mean upper air temperatures, dew point depressions, and wind velocities for approximately 500 observing sites. This is the final quality controlled copy and generally has a 4 - 6 month time lag." ...|$|R
5000|$|... (e) The term [...] "remote sensing activities" [...] {{means the}} {{operation}} of remote sensing space systems, primary <b>data</b> <b>collection</b> and storage <b>stations,</b> and activities in :processing, interpreting and disseminating the processed data.|$|R
40|$|Abstract. There {{are many}} {{applications}} of large scale sensor networks {{in which both}} the stimulus and the <b>data</b> <b>collection</b> <b>stations</b> are mobile (i. e. animal tracking, battlefield chasing). TTDD is a scalable and energy-efficient data dissemination model designed {{for this type of}} scenarios. However, TTDD only focused on handling mobile sinks. In this paper, we extend TTDD to deal with both mobile sources and sinks and evaluate the effectiveness of two potential extended TTDD schemes. Simulation results are presented to compare their performance in terms of energy consumption, delay and success rate. It is shown that the two schemes have similar performance when the moving speeds of the phenomena objects are slow. However, when the phenomena objects moving exceed certain speed, the advantages of one scheme over the other become unneglectable...|$|R
40|$|This {{video is}} the post-flight {{presentation}} by the astronauts of the STS- 67 Space Shuttle Mission. The astronauts were: Steve Oswald (Mission Commander), Bill Gregory (Shuttle Pilot), John Grunsfeld (Mission Specialist), Sam Durrance (Payload Specialist), Ron Parise (Payload Specialist), and Tammy Jernigan (Payload Commander). Footage includes: pre-launch suitup and launch (liftoff), {{the deployment of}} the telescope package payload (Hopkins UV telescope, Wisconsin UV polarimeter, and Astrostar Tracker) for their astronomical observations of different stellar objects, inside Shuttle shots of <b>data</b> <b>collection</b> <b>stations,</b> protein crystal growth experiments, medical BSO of head and eye functions in microgravity environment, storm activity over the United States and other Earth observation shots, Mid-deck Act Control Experiments, school-Shuttle direct radio communication, and descent and landing footage. This launch was a night launch and the flight was a 17 day flight (extended two days from original flight plan) ...|$|R
40|$|PLTMH {{generating}} system {{integrated with}} PLTS {{located on the}} campus of University of Muhammadiyah Malang III characteristics during the summer when the water flow is reduced, which causes power capacity supplied with PLTMH decreased. Power supply capacity will be improved by solar, solar power generator only interconnected to the PLTMH in phase S. PLTMH distribution network aided by the power of electricity {{to meet the needs of}} the campus load GKB 1 building and ICT. Load flow analysis aims to obtain information on the flow of active power, reactive power, and voltage on the bus at the time of integration generator full load condition. To know the power and voltage then conducted <b>data</b> <b>collection</b> <b>stations</b> and network capacity. ETAP Power Station 7. 0. 0 program used to determine the output power and voltage distribution network is PLTMH interconnected with PLN or interconnected with Genset. Repairs performed power flow allocation in the placement of capacitor banks to improve cosphi GKB 1 panel on the network of plants...|$|R
40|$|This paper {{utilizes}} three hourly {{measured values}} of wind speed and direction from seven buoys <b>data</b> <b>collection</b> <b>stations</b> in Aegean Sea {{to study the}} wind speed and power characteristics applying the Weibull shape and scale parameters. Specifically, the site dependent, annual and monthly mean patterns of mean wind speed, Weibull parameters, frequency distribution, most probable wind speed, maximum energy carrying wind speed, wind power density and wind energy density characteristics have been studied. The Weibull distribution was found to represent the wind speed distribution with more than 90 % accuracy {{in most of the}} cases. Slightly decreasing trends were observed in annual mean wind speed values at Lesvos and increasing at Mykonos. The mean values of wind speed, scale parameter, most probable wind speed, maximum energy carrying wind speed, wind power and wind energy density values showed higher values during winter time and lower in summer time. Mykonos was found to be the best site from wind power harnessing point of view. Moreover, the correlation between the percentages of times the wind speed was above cut-in-speed and the measured mean wind speed for the three selected sites and the correlation between the aforementioned percentages and the scale parameter c were examined and were found linear. [URL]...|$|R
50|$|In addition, the {{observatory}} {{is one of}} the 110 <b>Data</b> <b>Collection</b> Platform (D.C.P.) <b>stations</b> of the Aeronautica Militare Italiana for automatic weather data gathering and transmission to the METEOSAT satellite.Since 1976 this station has also been equipped for Ionospheric research and it is the most southern station of its kind in Europe. Real time ionograms are recorded by the INGV own developed AIS-INGV ionosonde installed at the station and reported on the INGV ionospheric website.|$|R
40|$|This is {{the final}} report of a short Laboratory Directed Research and Development (LDRD) project at Los Alamos National Laboratory (LANL). Data on {{atmospheric}} trace constituents and the vertical structure of stratus clouds from a 1996 expedition to the central Arctic reveal mechanisms of vertical mixing {{that have not been}} observed in mid-latitudes. Time series of the altitude and thickness of summer arctic stratus have been observed using an elastic backscatter lidar aboard an icebreaker. With the ship moored to the pack ice during 14 <b>data</b> <b>collection</b> <b>stations</b> and the lidar staring vertically, the time series represent advected cloud fields. The lidar data reveal a significant amount of vertical undulation in the clouds, strongly suggestive of traveling waves in the buoyantly damped atmosphere that predominates in the high Arctic. Concurrent observations of trace gases associated with the natural sulfur cycle (dimethyl sulfide, SO{sub 2 }, NH{sub 3 }, H{sub 2 }O{sub 2 }) and aerosols show evidence of vertical mixing events that coincide with a characteristic signature in the cloud field that may be called dropout or lift out. A segment of a cloud deck appears to be relocated from the otherwise quasicontinuous layer to another altitude a few hundred meters lower or higher. Atmospheric models have been applied to identify the mechanism that cause the dropout phenomenon and connect it dynamically to the surface layer mixing...|$|R
40|$|Powell Boulevard is a {{prime example}} of a {{congested}} urban arterial; this roadway connects US- 26 to downtown Portland, Oregon. This facility is one of the most congested arterial corridors in the Portland-metropolitan region. The City of Portland implemented the Sydney Coordinated Adaptive Traffic System (SCATS) in October 2011 in order to improve the operations of the corridor. SCATS has been implemented in a few US cities with mixed results so far. A properly calibrated system can have a significant positive impact on the performance of the traffic signals but its impact on transit performance has not been documented. This was the first SCATS implementation to integrate transit signal priority (TSP) and adaptive traffic systems in the United States and possibly in the world. The unique contributions of this study are: the evaluation of SCATS and bus transit performance utilizing permanent <b>data</b> <b>collection</b> <b>stations</b> monitoring traffic and transit signal priority. This work presents results and the methodology to evaluate transit performance with and without adaptive traffic signal control system on Powell Boulevard. The analysis examined the effect of SCATS on bus performance at the stop level and for the entire corridor by using a variety of performance measures. Statistically significant differences were observed in terms of travel times and SCATS related regression parameters. Overall, the travel time changes or improvements related to SCATS seem to depend greatly on the direction of travel and the time of day...|$|R
40|$|The study {{utilized}} {{wind speed}} measurements made at three heights and the Weibull parameters {{to study the}} wind speed characteristics and assess the wind power potential of seven sites in Saudi Arabia. Weibull shape and scale parameters were estimated using maximum likelihood method. These parameters were found to fit the actual wind frequency distributions with acceptable coefficient of determination (> 0. 95) for all the sites considered in this study. The annual mean wind speed varied between 4. 30 m/s and 5. 9 m/s at 40 m above ground level corresponding to Gassim and Dhulom <b>data</b> <b>collection</b> <b>stations.</b> The local wind shear exponent calculated using measured wind speed values at 20, 30, and 40 m and the power law were established for future use and were found to vary from 0. 06 to 0. 34 corresponding to Gassim and Yanbo, respectively. The Weibull shape and scale parameters increased more at 30 m compared to at 40 m with increase in height from 20 to 30 m and 30 to 40 m. No regular monthly trends could be detected whereas monthly mean wind speed, shape, and scale parameters, most probable wind speed, and maximum energy carrying wind speed was concerned. The most windy sites (Dhulom, Arar, Juaymah, Rawdat Ben-Habbas, and Dhahran) were suggested for wind power development in Saudi ArabiaThe authors acknowledge {{the support of the}} Research Institute of King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia[URL] and Aeronautical Engineerin...|$|R
40|$|This thesis {{evaluates the}} {{performance}} of a vehicle detection technology, Automated License Plate Recognition (ALPR) camera systems, with regards to its ability to produce real-time travel time information in active work zones. A literature review was conducted to investigate the ALPR technology as well as to identify other research that has been conducted using ALPR systems to collect travel time information. Next, the ALPR technology was tested in a series of field deployments in both an arterial and a freeway environment. The goal of the arterial field deployment was to evaluate the optimal ALPR camera angles that produce the highest license plate detection rates and accuracy percentages. Next, a series of freeway deployments were conducted on corridors of I- 285 in Atlanta, Georgia in order to evaluate the ALPR system in active work zone environments. During the series of I- 285 freeway deployments, ALPR data was collected in conjunction with data from Bluetooth and radar technologies, as well as from high definition video cameras. The data collected during the I- 285 deployments was analyzed to determine the ALPR vehicle detection rates. Additionally, a script was written to match the ALPR reads across two <b>data</b> <b>collection</b> <b>stations</b> to determine the ALPR travel times through the corridors. The ALPR travel time data was compared with the travel time data produced by the Bluetooth and video cameras with a particular focus on identifying travel time biases associated with each given technology. Finally, based on the knowledge gained, recommendations for larger-scale ALPR work zone deployments as well as suggestions for future research are provided. M. S...|$|R
40|$|Solar {{radiation}} {{is an important}} input for various land-surface energy balance models. Global solar radiation data retrieved from the Japanese Geostationary Meteorological Satellite 5 (GMS- 5) /Visible and Infrared Spin Scan Radiometer (VISSR) has been widely used in recent years. However, due {{to the impact of}} clouds, aerosols, solar elevation angle and bidirectional reflection, spatial or temporal deficiencies often exist in solar radiation datasets that are derived from satellite remote sensing, which can seriously affect the accuracy of application models of land-surface energy balance. The goal of reconstructing radiation data is to simulate the seasonal variation patterns of solar radiation, using various statistical and numerical analysis methods to interpolate the missing observations and optimize the whole time-series dataset. In the current study, a reconstruction method based on data assimilation is proposed. Using a Kalman filter as the assimilation algorithm, the retrieved radiation values are corrected through the continuous introduction of local in-situ global solar radiation (GSR) provided by the China Meteorological Data Sharing Service System (Daily radiation dataset_Version 3) which were collected from 122 radiation <b>data</b> <b>collection</b> <b>stations</b> over China. A complete and optimal set of time-series data is ultimately obtained. This method is applied and verified in China’s northern agricultural areas (humid regions, semi-humid regions and semi-arid regions in a warm temperate zone). The results show that the mean value and standard deviation of the reconstructed solar radiation data series are significantly improved, with greater consistency with ground-based observations than the series before reconstruction. The method implemented in this study provides a new solution for the time-series reconstruction of surface energy parameters, which can provide more reliable data for scientific research and regional renewable-energy planning...|$|R
40|$|The main {{objective}} of this project is to evaluate the feasibility of re-identifying commercial trucks based on vehicle-attribute data automatically collected by sensors installed at traffic <b>data</b> <b>collection</b> <b>stations.</b> To support this work, archived data from weigh-in-motion (WIM) stations in Oregon are used for developing, calibrating, and testing vehicle re-identification algorithms. The vehicle re-identification methods developed in this research consist of two main stages. In the first stage, each vehicle from the downstream station is matched to the most “similar” upstream vehicle by using a Bayesian model. In the second stage, several methods are introduced to screen out those vehicles that cross the downstream site but not the upstream site and to tradeoff accuracy versus {{the total number of}} vehicles being matched. These methods involve calculating both the highest and the second highest similarity measures for each vehicle being matched. It is demonstrated that the proposed screening approach improves the accuracy of the re-identification methods significantly. The models are applied to the truck data collected by WIM sensors at three stations in Oregon, which together create two different “links” that are 125 and 145 miles long, respectively. It is observed that the algorithms can match trucks with approximately 90 % accuracy while the total number of trucks being matched at this accuracy level is about 95 % of the actual common trucks that cross both upstream and downstream sites. These methods allow the user to trade-off the accuracy vs. total vehicles being matched by adjusting a threshold parameter. For example, trucks can be matched with 98 % accuracy if one is willing to match about 40 % of all common trucks. It is also found that when travel times of vehicles between the upstream and downstream sites exhibit larger variation, mismatch rate increases. Overall, for estimating travel times and origin-destination flows between two WIM sites, the methods developed in this project can be used to effectively match commercial vehicles crossing two <b>data</b> <b>collection</b> sites that are separated by long distances...|$|R
40|$|Delay Tolerant Networking (DTN) is {{well suited}} to {{challenging}} environments, defined {{by the lack of}} reliable end-to-end communication paths to the destination. However, the available energy is not considered in the majority of existing DTN routing protocols when they make forwarding decisions. This limits both delivery probabilities and the network lifetimes in energy-constrained applications. This paper investigates energy-aware routing protocols for wildlife tracking application to transmit data from attached sensors on the animal’s back to <b>data</b> <b>collection</b> base <b>stations.</b> We propose three new network protocol strategies to extend common DTN routing protocols, and consider the available energy to achieve efficient utilization of the node’s energy in transmission and sensing. These strategies enhance packet delivery rates up to 13 % by carefully using the limited energy resources. We simulate two different animal tracking scenarios and show that the new strategies provide significant performance improvement under different scenarios...|$|R
40|$|The Elko District Bureau of Land Management (BLM), {{located in}} Northeastern Nevada, {{has a long}} and well {{documented}} history of managing livestock grazing for recovery of stream and riparian habitats. Field surveys which include permanent photo and <b>data</b> <b>collection</b> <b>stations</b> were established on more than 1, 000 miles of perennial streams beginning in 1977. Virtually all of these waterways have been re-surveyed at least {{four or five times}} at intervals of three to ten years between the late 1970 ’s and today. Over the course of last 30 plus years, BLM personal have been working with livestock permittees and other partners to develop and apply prescriptive livestock grazing protocols for improvement of stream and riparian habitat conditions for native fish and other species of wildlife. Like many agencies and offices all over the west, we started managing riparian areas by constructing small exclosures in the 1980 ’s and excluding all livestock. By the 1990 ’s, we were learning how to apply principles of managing time and timing of grazing over a larger area. In more recent years, we have come to understand the importance of managing both uplands and riparian areas at a watershed scale and of incorporating principles of adaptive management into grazing plans. Our long-term database, combined with use of remote sensing techniques for monitoring, has allowed us to tell a compelling story of how riparian systems have changed over time in response to livestock grazing practices and to changes in the environment. Although this is still a story in progress, grazing practices which promote functionality at a watershed scale are yielding impressive results in terms of water quality, water retention and storage, habitat for wildlife and even sustainability for livestock operations during periods of drought. Such an approach seems critical in the context of rapid social, environmental and political change...|$|R
40|$|Chinese Academy of Sciences KZZD-EW- 08 ；Chinese Earthquake Administration 201208018 - 3  Solar {{radiation}} {{is an important}} input for various land-surface energy balance models. Global solar radiation data retrieved from the Japanese Geostationary Meteorological Satellite 5 (GMS- 5) /Visible and Infrared Spin Scan Radiometer (VISSR) has been widely used in recent years. However, due {{to the impact of}} clouds, aerosols, solar elevation angle and bidirectional reflection, spatial or temporal deficiencies often exist in solar radiation datasets that are derived from satellite remote sensing, which can seriously affect the accuracy of application models of land-surface energy balance. The goal of reconstructing radiation data is to simulate the seasonal variation patterns of solar radiation, using various statistical and numerical analysis methods to interpolate the missing observations and optimize the whole time-series dataset. In the current study, a reconstruction method based on data assimilation is proposed. Using a Kalman filter as the assimilation algorithm, the retrieved radiation values are corrected through the continuous introduction of local in-situ global solar radiation (GSR) provided by the China Meteorological Data Sharing Service System (Daily radiation dataset_Version 3) which were collected from 122 radiation <b>data</b> <b>collection</b> <b>stations</b> over China. A complete and optimal set of time-series data is ultimately obtained. This method is applied and verified in China's northern agricultural areas (humid regions, semi-humid regions and semi-arid regions in a warm temperate zone). The results show that the mean value and standard deviation of the reconstructed solar radiation data series are significantly improved, with greater consistency with ground-based observations than the series before reconstruction. The method implemented in this study provides a new solution for the time-series reconstruction of surface energy parameters, which can provide more reliable data for scientific research and regional renewable-energy planning...|$|R
40|$|We {{propose to}} form a {{non-profit}} research venture to utilize and gradually improve {{the state of the}} art of modeling-forecasting technology, and to develop an automated network- service / information-clearinghouse capable of reliably predicting consequences of large scale human activities and interactions with the environment. The exemplar is the weather forecasting service used to predict potential climatological catastrophes. While initially emphasizing the problem of potential destructive conflicts between human populations, this service / clearinghouse will gradually be expanded to cover the full range of interrelated global environmental and social behaviors and changes. A network of <b>data</b> <b>collection</b> ('monitoring') <b>stations,</b> and the central analysis and dissemination of results, will in turn be funded by subscription open to all groups and persons, public and private. These subscribers will receive regular ongoing forecasts of probable political, social, economic, and environmental trends in areas of interest. They can also obtain (for an extra fee) special assessment reports analyzing probable responses to proposed actions of the subscriber by all communities in an area of interest. Subscribers ar...|$|R
40|$|International audienceThe EGNOS Signal In Space (SIS) {{performance}} {{is defined in}} terms of accuracy, integrity, continuity of service and availability. For Civil Aviation, those four components of the performance shall fulfill ICAO requirements (particularly stringent for the integrity). EGNOS is expected to be operational by the first quarter of 2004. One of the major issues for Civil aviation in the perspective of operating EGNOS, is to prove that the system is safe to use. In this context, the demonstration of the EGNOS compliance with the integrity requirements is of the utmost importance. This raises the following question : How to assess the integrity performance of the EGNOS SIS ? In the frame of Eurocontrol work supporting the operational validation of EGNOS, a number of techniques are under investigation to evaluate measurement data and provide an assessment of the integrity achieved. It is not expected, even using a combination of different techniques that compliance with integrity requirement will be exhaustively demonstrated as this would require an amount of data that is impracticable to collect. The main contributor to the integrity validation is the analysis performed during the system design. However, it is necessary to use techniques such as the one presented in this paper to examine the behavior of the protection level in relation to the position error in order {{to gain a better understanding}} of how the system is performing. This technique will also help to identify when the system is not performing as it should be, even during times when it appears to be functioning correctly. The aim of the work presented in this paper is to develop a methodology for the assessment of the EGNOS Vertical Protection Level (VPL). The presented analysis is based on the processing of data from the EGNOS System Test Bed that is received by a network of <b>data</b> <b>collection</b> <b>stations</b> distributed throughout Europe. The objective is to make a statistical analysis of the Vertical Position Error (VPE) that can be measured at the output of the <b>data</b> <b>collection</b> receivers. An estimated VPL can be computed from the position error data enabling an evaluation to be made as to whether the VPL provided by the EGNOS system is a conservative bound on the VPE or not. For a given processed data set, a confidence level in the VPL is defined as an estimated probability that the VPL is a bound of the VPE. The analysis aims to provide the confidence levels as indicators of the quality of the VPL over selected data sets...|$|R
40|$|Surface {{and water}} columnmeasurements {{of the total}} {{alkalinity}} and the pHwere recorded in the Mediterranean Sea and in the Southern Tyrrhenian Sea fromMay–June 2007 and fromNovember 2006 and February 2008, respectively. The measurements were conducted {{within the framework of}} the Italian VECTOR Research Project activities. The total alkalinity was measured using a potentiometric titration with an open cell system. The pH was also determined using a potentiometric method, with a combination of glass/reference electrode with an NTC temperature sensor. The total alkalinity varied linearly with the salinity in the Mediterranean Sea and the measure rangedbetween 2431 and 2638 μmol kg− 1,withthe lowest values in the upper layer of thewesternmost data stations (2431 – 2439 μmol kg− 1). This pattern resulted from the influence of less salty water with lowalkalinity intruding fromthe nearby Atlanticwaters. With respect to the seasonal variation, the data collected in the Southern Tyrrhenian Sea did not have any statistically significant differences for the alkalinity parameter in the water column layers. The measured pH exhibited high and variable values in the surface layer and an increasing gradient from the western to the eastern Mediterranean <b>data</b> <b>collection</b> <b>stations,</b> particularly at intermediate depths around 300 – 500 m. The minimum pH and the maximum of the total alkalinity were commonly found at mid-depth in correspondence of the core of Levantine Intermediate Water. The pCO 2 valueswere calculated fromthe directmeasurements of the alkalinity and the pH. During the summer of 2007, the pCO 2 in the surface water of the Mediterranean was, on average, above the equilibrium with the atmospheric pCO 2, thus implying that the CO 2 was escaping the sea. Seasonalmeasurements at theVTMstation in the Southern Tyrrhenian Sea indicated that the pCO 2 surface values ranged from 323 to 430 ppm,with the lowest values in February 2007 and 2008, when the VTM station represented a sink for the atmospheric CO 2. The Tracer combining Oxygen, inorganic Carbon and total Alkalinity (TrOCA) was used to estimate the distribution of the anthropogenic CO 2. The results show that the entire water column has already been invaded by the anthropogenic CO 2 throughout the Mediterranean Sea. Generally, the concentrations of the anthropogenic CO 2 in the intermediate and deep layers were higher than those measured in the Atlantic waters...|$|R
40|$|Abstract [...] Process {{measurement}} and control systems are used in many industrial sectors {{in order to achieve}} production improvement, process optimization and accuracy of measurements. In this paper we propose an innovative and tested system that monitors and controls the quality of surface, underground and sea waters. Developed under the use of PLC and SCADA technologies, it is an advanced way to provide prompt and reliable information and an essential instrument for public services, local government organizations, scientific bodies and private companies that manage, control and/or utilize any form of water resources, such as lakes and catchments areas, rivers or torrents, sea and underground waters. The system monitors environmental, hydrological and meteorological conditions in real time with a wireless communication system for instant update and prompt forecast. Consists of a local monitoring station that reside in specific point of interest, which host several sensors for measuring water quality and meteorological parameters, and a <b>data</b> <b>collection</b> central <b>station</b> that collects sensor measurements, stores them persistently, enables users to visualize them, and finally, set and receive alarms when certain measurements exceed some predefined limits. The system is the core of an intelligent system for monitoring and predicting the quality of waters that will be used by the authorities for protecting public health against water pollution. Index Term [...] PLC, SCADA, Environmental supervisio...|$|R
40|$|Climate {{data has}} become {{increasingly}} scrutinized for its accuracy {{because of the need}} for reliable predictions about climate change. The U. S. has taken great strides {{to keep up with the}} demand for accurate climate data. Over the last thirty years, vast improvements to instrumentation, <b>data</b> <b>collection,</b> and <b>station</b> siting have created more accurate data records. This study is to explore the accuracy of existing networks. This study analyzes three climate networks used in Nebraska: the U. S. Historical Climatology Network (HCN), the Automated Weather Data Network (AWDN), and the newest network, the U. S. Climate Reference Network (CRN). Each of these networks has its own instrumentation, <b>collection</b> methods and <b>station</b> sites. Maximum and minimum surface temperature from the three networks and the spatial structure of temperature variations at the surface are compared. Two different timeframes, 2005 - 2009 and 1985 - 2005, were used to include the newest network, CRN, in the analysis. Daily data were collected from each of these networks within the specified timeframe. Root mean square error (RMSE) between each candidate station and the surrounding stations within 500 kilometers were calculated and evaluated to determine spatial accuracy of the network. This study found that in the 5 year analysis, CRN versus AWDN, the two networks were not significantly different enough to denote the network with high spatial accuracy. For the 21 year analysis, HCN versus AWDN, AWDN stations showed higher spatial accuracy (smaller error) than HCN stations for the variable of maximum temperature. The error for the two networks were not significantly different enough to decipher the network with the higher spatial accuracy. Advisors: Kenneth G. Hubbard 2 ̆ 6 David B. Mar...|$|R
40|$|Climate {{data are}} {{increasingly}} scrutinized for accuracy {{because of the}} need for reliable input for climaterelated decision making and assessments of climate change. Over the last 30 years, vast improvements to U. S. instrumentation, <b>data</b> <b>collection,</b> and <b>station</b> siting have created more accurate data. This study explores the spatial accuracy of daily maximum and minimum air temperature data in Nebraska networks, including the U. S. Historical Climatology Network (HCN), the Automated Weather Data Network (AWDN), and the more recent U. S. Climate Reference Network (CRN). The spatial structure of temperature variations at the earth’s surface is compared for timeframes 2005 – 09 for CRN and AWDN and 1985 – 2005 for AWDN and HCN. Individual root-mean-square errors between candidate station and surrounding stations were calculated and used to determine the spatial accuracy of the networks. This study demonstrated that in the 5 -yr analysis CRN and AWDN were of high spatial accuracy. For the 21 -yr analysis the AWDN proved to have higher spatial accuracy (smaller errors) than the HCN for both maximum and minimum air temperature and for all months. In addition, accuracy was generally higher in summer months and the subhumid area had higher accuracy than did the semiarid area. The findings of this study can be used for Nebraska as an estimate of the uncertainty associated with using a weather station’s data at a decision point some distance from the station...|$|R
40|$|Background: Inadequacies of drug {{labeling}} {{have been}} frequently reported among Malaysian healthcare institutes, {{in which the}} Hospital Information System (HIS) is used. Objective: To identify potential areas to improve the existing labels used for pediatric liquid medications. Methods: This study was qualitative in nature, whereby focus group discussions (FGDs), face-to-face interviews (FTFIs), and onsite observation were used for <b>data</b> <b>collection.</b> Pharmacists <b>stationed</b> at three units (outpatient, inpatient and clinical pharmacy) of a tertiary hospital were targeted. Both FGDs and FTFIs were facilitated using a semi-structured interview guide, video-recorded and transcribed verbatim. All transcripts were thematically analyzed using content analysis approach. Results: Thirteen pharmacists participated in FGDs, while five were approached for FTFIs. Data analysis resulted in four major themes: format of labels, presentation of medication instructions, insufficiency of information, {{and the need for}} external aids and education. Participants unanimously agreed on the need for enlarging font sizes of key information. Suggestions were made to use more specific instructions for administration times and pictograms to illustrate important directions. The absence of information about storage, stability and handling of liquid medications was also highlighted. While discussion mainly focused on improving drug labeling, participants consistently stressed the need for an instruction sheet and pharmacist-based, one-to-one education regarding medication instructions. Conclusion: This study provides important insights into critical shortcomings in current labeling practice, underlying the need for developing a new label that incorporates a new format, additional information and pictograms for pediatric liquid medications...|$|R
40|$|In many {{wireless}} {{sensor network}} applications, the <b>data</b> <b>collection</b> sink (base <b>station)</b> needs to find the aggregated statistics of the network. Readings from sensor nodes are aggregated at intermediate nodes to reduce the communication cost. However, the previous optimally secure in-network aggregation protocols against multiple corrupted nodes require two round-trip communications between each node and the base station The architecture of two-tiered sensor networks, where storage nodes serve as an intermediate tier between sensors and a sink for storing data and processing queries, has been widely adopted because {{of the benefits of}} power and storage saving for sensors as well as the efficiency of query processing. SafeQ also allows a sink to detect compromised storage nodes when they misbehave. To preserve privacy, SafeQ uses a novel technique to encode both data and queries such that a storage node can correctly process encoded queries over encoded data without knowing their values. Our protocol achieves one round-trip communication to satisfy optimal security without the result-checking phase, by conducting aggregation along with the verification...|$|R
30|$|The {{deployment}} {{problem for}} sensor nodes was studied extensively for terrestrial sensor networks [8]. The closest to our {{work from the}} placement strategies in terrestrial networks are those for relay node and multi-tier sensor network architecture [9 – 11]. However, most terrestrial deployment problems assume a static two-dimensional (2 D) architecture, and not much attention was received for multi-gateway deployment in UWSN. A triangular-grid deployment pattern for 2 D UWSN was proposed in [12]. The objective is to minimize the number of sensors needed to achieve the sensing and communication coverage of a target area. An interesting attempt to formulate the 3 D UWSN point-coverage deployment problem as an integer linear program (ILP) is presented in [13]. The solution of the ILP decides relay node deployment, routing, and link scheduling. Throughout this work, {{it is assumed that}} there is a single sink for the entire UWSN deployment and only the overall power consumption is used as an optimization objective. Neither of these two studies considers the multiple-sink network architecture. The only research study in the frame of multiple sinks we found is [7], in which Seah and Tan investigated the use of multi-sink architecture to enhance the underwater sensor network reliability. In this study, the same message is directed to more than one of the multiple sinks, with the assumption that if any of the sinks gets the message, then it is considered delivered successfully. The simulation results showed that high-reliability benefits can be achieved at the cost of reasonable increase in energy consumption. The surface gateway (i.e., sink) deployment problem was not considered in this work. In a parallel research effort, [14] studied the problem of placing multiple mobile data collectors in both delay-tolerant and delay-constrained underwater acoustic sensor networks. The authors defined candidate <b>data</b> <b>collection</b> <b>stations</b> as the maximal overlapping regions (MORs) of surface circles corresponding to underwater node communication ranges. They developed an O(n 2 logn) algorithm for finding MORs. An earlier work in [15] was the first to address the underwater surface gateway deployment problem and formulate it as an optimization problem. The problem of surface-level gateway placement has been addressed by later research effort in[16]. The authors used surface gateways deployment as a mean to guarantee connectivity and survivability (tolerance to single node failure). They proposed an approximation algorithm for choosing a minimal subset of candidate locations where SGs may be deployed. An effort by the authors in [17] addressed the deployment for a mobile multiple-sink architecture in UWSN. They used a prediction-based deployment strategy to cater for the mobility of underwater nodes. However, our work differs from all above by formulating the problem to find the best candidate locations that satisfies a set of flow conservation constraints, interference constraints, number of gateway constraints, and performance constraints in addition to a set of delay and energy-consumption objectives.|$|R
40|$|This {{report was}} a class project for Civil Engineering 529 - Applied Hydrology taught by Professor Peter C. Klingeman. No hydrologic study has {{previously}} {{been made of the}} South Slough Estuary drainage basin. Yet, since freshwater runoff is paramount to an estuary, it would seem that such a study is vital to the proper understanding [...] and hence management [...] of the estuary. Therefore, a brief hydrologic analysis of the South Slough basin has been conducted as part of a class project at Oregon State University. The results are presented on the following pages. This analysis consists of two major parts: (1) The freshwater streamflow that enters the estuary from the drainage basin; and (2) the mixing of that fresh I'/ater within the estuary. It should be noted that hydrologic data for the South Slough basin are made conspicuous by their absence. For this reason, <b>data</b> from nearby <b>collection</b> <b>stations</b> outside the basin have been used in the analyses made for South Slough. This has permitted an estimate of precipitation and runoff. But the results presented here can in no way take the place of the analysis of data collected in the drainage basin itself. Nor should these results, based on monthly averages of precipitation, be compared indiscriminately with measured daily values...|$|R
40|$|Environment Observation (LJZO) {{measurement}} {{system and the}} tools available for Diict Offices to implement their own LEO <b>data</b> <b>collection</b> program. LEO provides low-cost coastal data for the planning, design, operation, and maintenance of coastal works. LEO consists of systematic coktion of wind, wave, and current data visually obtained by vohrnteer observers. LEO data are collected primkly at sites where little or no wave data exist, where resources are not available for instaMion of recording instruments, or where daily measurements such as beach width are desired. Over 360 LEO <b>collection</b> <b>stations</b> have been established on U. S. coasts. Data fkom previous LEO <b>data</b> <b>collection</b> efforts are available at each District office and some limited LEO data {{are available in the}} CEDARS database (reference CETN-I- 23). TYPES OF LITIYORAL VARIABLES OBSERVED AND RECORDED The LEO field m easurements typically recorded are shown. in Figures 1 and 2 (LEO recording form). Visual estimatesare made of the wave period, breaker height, wave type, and width of surf zone. A protractor, shown in Figure 2, is used to estimate the direction f?om which the waves are approaching. The wind direction is noted on an 8 -point compass. Wmdspeed i...|$|R
30|$|L. van den Haak contributed the following: {{project development}}, <b>data</b> <b>collection,</b> <b>data</b> analysis, and {{manuscript}} writing. J.P.T. Rhemrev contributed the following: project development, <b>data</b> <b>collection,</b> <b>data</b> analysis, and manuscript writing. M.D. Blikkendaal contributed the following: <b>data</b> <b>collection,</b> <b>data</b> analysis, and manuscript writing. A.C.M. Luteijn contributed the following: <b>data</b> <b>collection,</b> and <b>data</b> analysis. J.J. van den Dobbelsteen contributed the following: project development and data analysis. S.R.C. Driessen contributed the following: <b>data</b> <b>collection,</b> <b>data</b> analysis, and manuscript writing. F.W. Jansen contributed the following: project development, <b>data</b> <b>collection,</b> <b>data</b> analysis, and manuscript writing.|$|R
25|$|In May 1995, China {{shuts down}} all blood/plasma <b>collection</b> <b>stations.</b>|$|R
