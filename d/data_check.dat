50|2342|Public
25|$|The {{national}} fiscal {{accounts for}} the previous full calendar year are released each year in April (next time 23 April 2015). As the compliance check for both the debt and deficit criteria always awaits this release in a new calendar year, the first possible month to request a compliance check will be April, which {{would result in a}} <b>data</b> <b>check</b> for the HICP and interest rates during the reference year from 1 April to 31 March. Any EU member state may also ask the European Commission to conduct a compliance check, at any point of time during the remainder of the year, with HICP and interest rates always checked for the past 12 months – while debt and deficit compliance always will be checked for the three-year period encompassing the last completed full calendar year and the two subsequent forecast years. As of 10 August 2015, none of the remaining euro derogation states without an opt-out had entered ERM-II, which makes it highly unlikely that any of them will request that the European Commission conduct an extraordinary compliance check ahead of the publication of the next regular convergence report scheduled June 2016.|$|E
5000|$|Channel control checkPoOps {{indicates}} a channel malfunction other than Channel <b>data</b> <b>check</b> or Interface control check.|$|E
50|$|Refine {{the design}} - Analyze {{the design for}} errors. Create tables and add a few records of sample <b>data.</b> <b>Check</b> if results come from the tables as expected. Make {{adjustments}} to the design, as needed.|$|E
40|$|Data {{quality is}} {{critical}} to reaching correct research conclusions. Previous {{research has demonstrated that}} some methods of <b>data</b> <b>checking</b> are better than others, but not all researchers use the best methods. The {{purpose of this study was}} to examine the relationship between perceived data quality and actual data quality. A total of 29 participants completed this study. Participants checked that letters and numbers had been entered correctly into the computer using one of three randomly assigned <b>data</b> <b>checking</b> methods. Afterwards, they rated the quality of their <b>data</b> <b>checking</b> method. The sample correlations between perceived and actual data quality were small to moderate and confidence intervals for the population correlations did not include high values. We conclude that the relationship between actual and perceived data quality is not high. Researchers should not trust their subjective evaluations <b>data</b> <b>checking</b> effectiveness: They need empirical evidence of the quality of their <b>data</b> <b>checking...</b>|$|R
5000|$|... <b>data</b> <b>checks</b> {{could be}} {{implemented}} during data entry, preventing some errors altogether and immediately prompting for resolution of other errors ...|$|R
5000|$|Consistent use of REST {{interfaces}} {{to exchange}} data between {{the client and}} server for all transfers of data including as-you-type <b>data</b> <b>checking</b> and suggest functions ...|$|R
50|$|Historical <b>data</b> <b>check</b> {{verification}} {{services that}} use {{a national network}} with a negative check database can be difficult for consumers and businesses to remove themselves from once they get on, even {{in the case of}} errors.|$|E
50|$|The {{national}} fiscal {{accounts for}} the previous full calendar year are released each year in April (next time 23 April 2015). As the compliance check for both the debt and deficit criteria always awaits this release in a new calendar year, the first possible month to request a compliance check will be April, which {{would result in a}} <b>data</b> <b>check</b> for the HICP and Interest rates during the reference year from 1 April to 31 March. Any EU Member State may also ask the European Commission to conduct a compliance check, at any point of time during the remainder of the year, with HICP and interest rates always checked for the past 12 months - while debt and deficit compliance always will be checked for the 3-year period encompassing the last completed full calendar year and the two subsequent forecast years. As of 12 September 2014, all of the remaining euro derogation states without an opt-out, had not yet entered ERM-II, which mean its highly unlikely any of them will ask the European Commission to conduct an extraordinary compliance check ahead of the publication of the next regular convergence report (scheduled for release in May/June 2016).|$|E
40|$|The {{insecticides}} and fumigants {{listed in}} this circular were registered {{for use in}} Nebraska as of June 1, 1984. Recommendations {{are subject to change}} as dictated by Federal and State regulations and receipt of new efficacy <b>data.</b> <b>Check</b> with your local Extension Agent for current status of these recommendations...|$|E
40|$|Remote <b>data</b> <b>checking</b> protocols, such as provable data {{possession}} (PDP) [1], allow {{clients that}} outsource data to untrusted servers {{to verify that}} the server continues to correctly store the data. Through the careful integration of forward error-correcting codes and remote <b>data</b> <b>checking,</b> a system can prove possession with arbitrarily high probability. We formalize this notion in the robust data possession guarantee. We distill the key performance and security require-ments for integrating forward error-correcting codes into PDP and describe an encoding scheme and file organization for robust data possession that meets these requirements. We give a detailed anal-ysis of this scheme and build a Monte-Carlo simulation to evaluate tradeoffs in reliability, space overhead, and performance. A prac-tical way to evaluate these tradeoffs is an essential input to sys-tem design, allowing the designer to choose the encoding and <b>data</b> <b>checking</b> protocol parameters that realize robust data possession...|$|R
3000|$|Furthermore, <b>data</b> <b>checking</b> and {{completion}} {{towards the}} analysis were conducted. Using the database information, multiple <b>data</b> <b>checks</b> and supplements were applied {{as well as}} classifications of the infrastructure improvements and of the sites treated were carried out, in order to define the types of infrastructure improvements suitable for safety evaluation. For each treatment type to be considered, a list of sites treated in this manner presenting the [...] "treatment group", the sites {{to be used as}} a comparison-group, accident types to be examined and the periods of analysis, were assigned.|$|R
50|$|Unlike range <b>checks,</b> <b>data</b> are <b>checked</b> for one limit only, upper OR lower, e.g., data {{should not}} be greater than 2 (<=2).|$|R
40|$|Abstract. A PID {{temperature}} control system was designed with the LabVIEW graphical programming language and the PID toolkit. Data collection, PID control, data record and <b>data</b> <b>check</b> were experimented to the practicable instrument with the purchased programming power supply and data collection record system. Operate the hardware and software of the computer with the virtual instrument and realize the smooth control of the system temperature with the accuracy of 1 ‰...|$|E
40|$|In this paper, {{we propose}} a SaaS service which {{prevents}} shoplifting using image analysis and ERP. In Japan, total damage of shoplifting reaches 450 billion yen. Based on cloud and data analysis technology, we propose a shoplifting prevention service with image analysis of security camera and ERP <b>data</b> <b>check</b> for small shops. We evaluated movie analysis. Comment: 2 pages, 2 figures, IEEE Consumer Communications and Networking Conference (CCNC 2017), pp. 1021 - 1022, Jan. 201...|$|E
40|$|To {{manage and}} process {{a large amount}} of oceanographic data, users must have {{powerful}} tools that simplify these tasks. The VODC for PC is software designed to assist in managing oceanographic data. It based on 32 bits Windows operation system and used Microsoft Access database management system. With VODC for PC users can update data simply, convert to some international data formats, combine some VODC databases to one, calculate average, min, max fields for some types of <b>data,</b> <b>check</b> for valid data...|$|E
50|$|The ACIA is {{designed}} for maximum programmed control from the microprocessor (MPU) to simplify hardware implementation. Three separate registers permit an MPU to easily select the W65C51N operating modes, <b>data</b> <b>checking</b> parameters and determine operational status.|$|R
5000|$|PDP (provable <b>data</b> possession) <b>checking</b> is a {{class of}} {{efficient}} and practical methods that provide {{an efficient way to}} <b>check</b> <b>data</b> integrity on untrusted servers: ...|$|R
2500|$|ZFS has no tool {{equivalent}} to fsck (the standard Unix and Linux <b>data</b> <b>checking</b> and repair tool for file systems). [...] Instead, ZFS {{has a built-in}} scrub function which regularly examines all data and repairs silent corruption and other problems. Some differences are: ...|$|R
30|$|Privacy leakage {{detected}} by the TaintChaser system has socket communication interface, Https encryption communication interface, Bluetooth, short message, etc. For {{each type of}} privacy leakage, because interface of data sent {{is not the only}} one we need to process all the function related, first, according to the length and its memory address of transmitted <b>data,</b> <b>check</b> in taint storage table whether the data is tainted data, if it is, it will be recorded including content and destination address of sent data, etc. other related information [21, 22].|$|E
30|$|Three wind lidars (Windcube- 200, Leosphere) are {{installed}} at the Bucheon, Gwanghwamun, and Jungnang Stations, to the west, in the center, and {{to the east of}} Seoul, respectively (Fig.  1). They provide a vertical profile of wind speed and direction at 50 -m intervals up to maximum 6  km (typically to the boundary-layer height) with a 10 -min temporal resolution. The following quality check procedure is applied to remove noisy data: carrier-to-noise check, data availability check, and vertical gradient of horizontal wind check in addition to the basic missing <b>data</b> <b>check</b> (Park and Choi 2016).|$|E
40|$|This Web site {{includes}} {{shares the}} images, stories and discoveries {{that emerge from}} NASA Earth science research, including its satellite missions, in-the-field research and climate models. View global maps of NASA <b>data,</b> <b>check</b> out the Image of the Day and images of current events, and read feature articles and blogs. Also includes special collections of NASA images, including the World of Change series, which documents how our planet’s land, oceans, atmosphere and Sun are changing over time. Educational levels: High school, Undergraduate lower division, Undergraduate upper division, Graduate or professional, Informal education, General public...|$|E
50|$|Each {{user can}} create a job (that is, a string of TPT commands) {{that allows them to}} perform operations, such as {{heterogeneous}} data access, <b>data</b> integrity <b>checks,</b> <b>data</b> merging, and data loads in batch or interactive.|$|R
40|$|This {{article is}} {{the survey of}} author's work on dialog shells over {{interpreting}} systems. Aspects of the shell for the computational algebra package Bergman are presented: the solved task, homogenization algorithm, input <b>data</b> <b>checking,</b> approaches to implementation. The shell automatizes and strongly simplifies data preparation and monitoring of the Bergman package...|$|R
50|$|Locus {{offers a}} mobile {{application}} that gives users {{the capability to}} collect and upload field data remotely. Locus Mobile eliminates duplicate input, reduces transcription time, performs <b>data</b> <b>checks</b> and validation {{at the point of}} collection, and maintains a complete audit trail including the geo-reference on who collected what, when and where.|$|R
40|$|In this paper, {{we propose}} a SaaS service which {{prevents}} shoplifting using image analysis and ERP. In Japan, total damage of shoplifting reaches 450 billion yen {{and more than}} 1000 small shops gave up their businesses because of shoplifting. Based on recent cloud technology and data analysis technology, we propose a shoplifting prevention service with image analysis of security camera and ERP <b>data</b> <b>check</b> for small shops. We evaluated stream analysis of security camera movie using online machine learining framework Jubatus. Comment: 4 pages, in Japanese, 2 figures, IEICE Technical Report, SC 2016 - 14, Aug. 201...|$|E
40|$|The PRO program {{constitutes}} a role reversal for peer review {{because of the}} DRG system. When price per diagnosis is fixed, only quality can vary. Meager funding forces the PRO to rely on computer data, but the data set contains little that is useful in assessing quality. Furthermore, the PRO must depend on fiscal intermediaries, planning organizations and state welfare agencies to provide the <b>data,</b> <b>check</b> it for accuracy, and supply it in a timely fashion. Since the other organizations have been either indifferent or hostile to the peer review process, the PRO data program {{has more to do}} with organizational politics than with computers...|$|E
40|$|The Cockpit Oriented Display of Aircraft Configurations (CODAC) {{package is}} an {{interactive}} FORTRAN 77 graphics program which produces high quality publication grade hidden line images of three dimensional wireframe objects. The term, Cockpit Oriented, is used because CODAC rotates objects {{relative to the}} changing aircraft axis system (rather than about a fixed global axis system) and uses the more familiar directions of yaw, roll, and pitch. In addition, CODAC accepts geometry data {{in a variety of}} formats (LaWGS, Craidon, Hess, and FVS <b>data</b> <b>check),</b> and automatically selects the appropriate panel driver. Finally, CODAC makes full use of the Precision Visuals' DI- 3000 metafile option, allowing users to save, edit, and print images for group presentations or research publications...|$|E
5000|$|... {{inferential}} statistics - {{the part of}} statistics that draws conclusions from data (using some model for the data): For example, {{inferential statistics}} involves selecting {{a model for the}} <b>data,</b> <b>checking</b> whether the <b>data</b> fulfill the conditions of a particular model, and with quantifying the involved uncertainty (e.g. using confidence intervals).|$|R
40|$|There {{are about}} 46 {{weigh-in-motion}} (WIM) stations in Indiana. When operating properly, they provide valuable information on traffic volumes, vehicle classifications, and axle weights. Because {{there are great}} amounts of WIM data collected everyday, the quality of these data should be monitor without further delay. The first objective {{of this study is}} to develop effective and efficient methods to identify missing or erroneous WIM data. The second objective is to develop a data imputation method to update the missing or erroneous data. This report describes the WIM <b>data</b> <b>checking</b> process on both a monthly and a daily basis. The Weigh-In-Motion Daily <b>Data</b> <b>Checking</b> (WDDC) program is introduced. The whole procedure requires very little human intervention, and provides a convenient way to <b>check</b> daily summary <b>data.</b> This report also describes several imputation methods in the experiment of imputing 7 -day data...|$|R
5000|$|The {{solution}} {{must provide}} an integrated environment to perform <b>data</b> integrity <b>checks</b> ...|$|R
30|$|The {{training}} {{data in this}} study area includes 25  % (50, 000 cells) of all the data, which 36  % of these {{training data}} (18, 000 cells) were entered (ANFIS, ANN and LR) to train and estimate the bias and the rest 64  % (32, 000 cells) were used as the <b>data</b> <b>check.</b> The training data (50, 000 cells) were 25  % of the 1987 image data which {{have been used for}} calibrating the models as training and checking for ANN and ANFIS models and calculating LR parameters. The training data have been chosen from all the image area in a random manner which guarantees there is no bias in the selection. Then, after the selection of the sample data, the models are calibrated.|$|E
40|$|Abstract [...] AODV is very simple, {{effective}} and useful and efficient protocol in the Mobile Ad-hoc Network. It borrows the advantageous concept from DSR and DSDV algorithm. Obtain the routes purely on-demand makes AODV {{a very useful}} and desired algorithm for MANET. During the data transmission Between the nodes in the mobile ad-hoc network energy are used from the battery. so when the node will reach at the minimum power at that time they lost the packet data which are transmitted from the one node to another. So to overcome from this problem before the transmission of the packet <b>data</b> <b>check</b> {{the energy of the}} node. This paper shows how to improve the throughput of the AODV protocol Keywords [...] Mobile AD-Hoc Network, AODV protocol, Routing tabl...|$|E
40|$|The {{goal of this}} {{bachelor}} {{thesis is}} a design and realization of an application, which would automatically check the hiking trails managed by Czech Tourist Club (Czech: Klub českých turistů, KČT) in the OpenStreetMap (hereinafter OSM) project's data. In this technical report is described the OSM project and its way of community mapping, data storage and the OSM data distribution. To map the hiking trails in the Czechia we use so called OpenTrackMap. In the following part are described the possibilities of the manual and automatic OSM <b>data</b> <b>check.</b> The part of the technical report is a design of the OSM data checking application. In {{the end of this}} work is described the implementation of the application and there is also attached the manual for the application...|$|E
30|$|MR {{contributed to}} the data collection, {{statistical}} analyses, and manuscript draft. GJ is the research supervisor, {{contributed to the}} statistical analyses and English revision, and is the project idealizer. VL and FV contributed to {{the writing of the}} discussion. DG contributed to the <b>data</b> <b>checking,</b> manuscript draft, and corrections. All authors read and approved the final manuscript.|$|R
40|$|This paper {{describes}} the jet target, the superconducting spectrometer and the polarimeter {{used to measure}} the recoil proton polarization in an Indiana University experiment at the Fermi National Accelerator Laboratory. Analysis procedures and <b>data</b> <b>checks</b> are explained and preliminary results are presented and compared with model predictions. The future plans of the experiment are also discussed...|$|R
5000|$|Error {{correcting}} memory uses additional parity bits {{to check}} for and possibly correct corrupted data. Since radiation effects damage the memory content even when {{the system is not}} accessing the RAM, a [...] "scrubber" [...] circuit must continuously sweep the RAM; reading out the <b>data,</b> <b>checking</b> the parity for data errors, then writing back any corrections to the RAM.|$|R
