7277|10000|Public
5|$|Plan 9 proponents and {{developers}} {{claim that the}} problems hindering its adoption have been solved, that its original goals as a <b>distributed</b> <b>system,</b> development environment, and research platform have been met, and that it enjoys moderate but growing popularity. Inferno, through its hosted capabilities, has been a vehicle for bringing Plan 9 technologies to other systems as a hosted part of heterogeneous computing grids.|$|E
5|$|Plan 9 {{demonstrated}} that an integral concept of Unix—that every system interface could be {{represented as a}} set of files—could be successfully implemented in a modern <b>distributed</b> <b>system.</b> Some features from Plan 9, like the UTF-8 character encoding of Unicode, have been implemented in other operating systems. Unix-like operating systems such as Linux have implemented 9P, Plan 9's file system, and have adopted features of rfork, Plan 9's process creation mechanism. Additionally, in Plan 9 from User Space, several of Plan 9's applications and tools, including the sam and acme editors, have been ported to Unix and Linux systems and have achieved some level of popularity. Several projects seek to replace the GNU operating system programs surrounding the Linux kernel with the Plan 9 operating system programs. The 9wm window manager was inspired by 8½, the older windowing system of Plan 9; wmii is also heavily influenced by Plan 9.|$|E
25|$|So far {{the focus}} has been on {{designing}} a <b>distributed</b> <b>system</b> that solves a given problem. A complementary research problem is studying the properties of a given <b>distributed</b> <b>system.</b>|$|E
40|$|Scalability {{is one of}} {{the major}} {{features}} of <b>Distributed</b> <b>Systems</b> Scalability is contributing a lot for popularity and increasing usage of <b>Distributed</b> <b>Systems.</b> Dynamic Service Discovery is a concept which emerged with the Service Oriented Architecture (SOA) and it helps to identify the services while systems are running and interact with these services which arc discovered by the Dynamic Service Discovery. The combination of <b>Distributed</b> <b>Systems</b> and Dynamic Service Discovery provides a highly scalable <b>Distributed</b> <b>systems</b> implementation mechanism for <b>distributed</b> <b>systems</b> designers and architects. We have implemented a highly scalable <b>distributed</b> <b>systems</b> prototype using the Dynamic Service Discovery...|$|R
40|$|The <b>Distributed</b> <b>Systems</b> Annex (DSA) was {{designed}} for general-purpose <b>distributed</b> <b>systems</b> programming. This paper explores the practical use of the DSA in terms of high-integrity real-time <b>distributed</b> <b>systems.</b> In particular, it defines ahigh-integrity subset of the DSA and considers how such asubset can be implemented using SPARK and Ravenscar...|$|R
40|$|Awareness of {{the need}} for {{robustness}} in <b>distributed</b> <b>systems</b> increases as <b>distributed</b> <b>systems</b> {{become an integral part of}} day-to-day systems. Tolerating Byzantine faults and possessing self-stabilizing features are sensible and important requirements of <b>distributed</b> <b>systems</b> in general, and of a fundamental task such as clock synchronization in particular. There are efficient solutions [...] ...|$|R
25|$|There {{are many}} {{cases in which}} the use of a single {{computer}} would be possible in principle, but the use of a <b>distributed</b> <b>system</b> is beneficial for practical reasons. For example, it may be more cost-efficient to obtain the desired level of performance by using a cluster of several low-end computers, in comparison with a single high-end computer. A <b>distributed</b> <b>system</b> can provide more reliability than a non-distributed system, as there is no single point of failure. Moreover, a <b>distributed</b> <b>system</b> may be easier to expand and manage than a monolithic uniprocessor system.|$|E
25|$|The {{main focus}} is on {{coordinating}} the operation of an arbitrary <b>distributed</b> <b>system.</b>|$|E
25|$|A <b>distributed</b> <b>system</b> {{may have}} a common goal, such as solving a large {{computational}} problem; the user then perceives the collection of autonomous processors as a unit. Alternatively, each computer may have its own user with individual needs, {{and the purpose of}} the <b>distributed</b> <b>system</b> is to coordinate the use of shared resources or provide communication services to the users.|$|E
40|$|International audienceOPODIS 2015 is an {{open forum}} for the {{exchange}} of knowledge on distributed computing and <b>distributed</b> computer <b>systems.</b> All aspects of <b>distributed</b> <b>systems</b> are {{within the scope of}} OPODIS, including theory, specification, design, performance, and system building. With strong roots in the theory of <b>distributed</b> <b>systems,</b> OPODIS covers nowadays the whole range between the theoretical aspects and practical implementations of <b>distributed</b> <b>systems,</b> as well as experimentation and quantitative assessments...|$|R
40|$|Abstract- The paper {{presents}} {{information on}} past, {{present and future}} research activities in IICT-BAS {{in the field of}} ICT security. The main directions of these activities are: critical infrastructure cyberattacks protection, security of <b>distributed</b> <b>systems,</b> security of social networks and dependability of <b>distributed</b> <b>systems.</b> Keywords:ICT security, critical infrastructure security, <b>distributed</b> <b>systems</b> security, dependability, social network...|$|R
40|$|An {{extension}} of the Chandy-Lamport algorithm ([Chan 84]) to find global states of <b>distributed</b> <b>systems</b> is presented where benign failures of processes and channels are permitted. The scope of the algorithm in detecting stable properties in <b>distributed</b> <b>systems</b> is discussed. As an application, an algorithm to detect deadlocks in failure-prone <b>distributed</b> <b>systems</b> is presented...|$|R
25|$|Traditional {{computational}} problems {{take the}} perspective that we ask a question, a computer (or a <b>distributed</b> <b>system)</b> processes {{the question for}} a while, and then produces an answer and stops. However, there are also problems where {{we do not want}} the system to ever stop. Examples of such problems include the dining philosophers problem and other similar mutual exclusion problems. In these problems, the <b>distributed</b> <b>system</b> is supposed to continuously coordinate the use of shared resources so that no conflicts or deadlocks occur.|$|E
25|$|A {{computer}} program that {{runs in a}} <b>distributed</b> <b>system</b> is called a distributed program, and distributed programming {{is the process of}} writing such programs. There are many alternatives for the message passing mechanism, including pure HTTP, RPC-like connectors and message queues.|$|E
25|$|In {{order to}} perform coordination, {{distributed}} systems employ {{the concept of}} coordinators. The coordinator election problem is to choose a process from {{among a group of}} processes on different processors in a <b>distributed</b> <b>system</b> to act as the central coordinator. Several central coordinator election algorithms exist.|$|E
40|$|With {{the advent}} of <b>distributed</b> <b>systems,</b> {{mechanisms}} that support efficient resource sharing are necessary to exploit a distributed architecture. One of the key resources UNIX provides is a hierarchical file system. Early efforts supported <b>distributed</b> UNIX <b>systems</b> by copying files and sending mail between individual machines. The desire to provide transparent mechanisms on which <b>distributed</b> <b>systems</b> access resources has propelled the development of <b>distributed</b> file <b>systems.</b> This thesis presents {{a brief history of}} the development of <b>distributed</b> <b>systems</b> based on UNIX, and surveys recent implementations of <b>distributed</b> file <b>systems</b> based on UNIX. The IBIS <b>distributed</b> file <b>system</b> {{is an example of the}} latter. The original capabilities of IBIS are discussed and modifications that enhance these capabilities described...|$|R
30|$|Consensus [1] {{and other}} {{equivalent}} problems, such as atomic broadcast {{and group membership}} are used to implement dependable <b>distributed</b> <b>systems</b> [2, 3]. However, given the FLP impossibility [4], i.e., consensus {{can not be solved}} deterministically in asynchronous <b>distributed</b> <b>systems</b> in which even a single process can fail by crashing, deploying high-available <b>distributed</b> <b>systems</b> on the Internet is a challenge. In order to circumvent the impossibility of solving consensus in asynchronous <b>distributed</b> <b>systems,</b> Chandra and Toueg introduced failure detectors based on timeouts [5 – 7].|$|R
40|$|The {{study of}} <b>distributed</b> <b>systems</b> is {{increasingly}} fundamental to a Computer Science curriculum. Yet, {{the design of}} applications to run over <b>distributed</b> <b>systems</b> is complex and mastery of fundamental concepts is challenging for students. In order to assist in <b>distributed</b> <b>systems</b> instruction, we have developed ConcurrentMentor, a visualization <b>system</b> for <b>distributed</b> programming. This <b>system</b> reveals {{the behavior of a}} distributed program and its underlying communication protocols while the program executes. Input to the visualization system is generated by an accompanying communication library that closely follows abstractions of communication found in <b>distributed</b> <b>systems</b> literature. No program instrumentation is required...|$|R
25|$|A {{challenge}} for producers of IoT applications is to clean, process {{and interpret the}} vast amount of data which is gathered by the sensors. There is a solution proposed for the analytics of {{the information referred to}} as Wireless Sensor Networks. These networks share data among sensor nodes that are send to a <b>distributed</b> <b>system</b> for the analytics of the sensory data.|$|E
25|$|A {{distributed}} {{operating system}} manages {{a group of}} distinct computers and makes them {{appear to be a}} single computer. The development of networked computers that could be linked and communicate with each other gave rise to distributed computing. Distributed computations are carried out on more than one machine. When computers in a group work in cooperation, they form a <b>distributed</b> <b>system.</b>|$|E
25|$|The {{situation}} is {{further complicated by}} the traditional uses of the terms parallel and distributed algorithm that do not quite match the above definitions of parallel and distributed systems (see below for more detailed discussion). Nevertheless, {{as a rule of}} thumb, high-performance parallel computation in a shared-memory multiprocessor uses parallel algorithms while the coordination of a large-scale <b>distributed</b> <b>system</b> uses distributed algorithms.|$|E
40|$|Abstract. <b>Distributed</b> <b>systems</b> {{are often}} safety- and security-critical systems and have strong {{qualitative}} and quantitative formal requirements, equally important time-critical performance-based quality of service properties, and need to dynamically adapt to changes in a potentially hostile and often probabilistic environment. These aspects make <b>distributed</b> <b>systems</b> complex and hard to design, build, test, and verify. To tackle this challenge, we propose a formal pattern-based approach and framework {{for the design of}} correct-, secure-, and safe-by-construction <b>distributed</b> <b>systems.</b> Key words: formal patterns, meta-object pattern, statistical model checking, rewriting logic, <b>distributed</b> <b>systems,</b> cloud computing...|$|R
40|$|The role of {{time has}} been {{neglected}} for long, in <b>distributed</b> <b>systems.</b> Outside the real-time arena, {{time has been}} ignored, mostly {{on account of the}} asynchronous nature of the models currently used in <b>distributed</b> <b>systems</b> research. Even in real-time systems, time provision has for long stayed in the realm of centralised, unique system clocks. The situation is changing, though. In this paper, we do an overview of the role of time in <b>distributed</b> <b>systems.</b> We address the issue of the utility of time, that is, why and where time is used, namely its relationship with order and ordering protocols. We report on recent evolutions that may drastically change the current scenario of the use of time <b>distributed</b> <b>systems.</b> 1 Introduction The role of time has been neglected for long, in <b>distributed</b> <b>systems.</b> Outside the real-time arena, time has been ignored, on account of the asynchronous nature of the models currently used in <b>distributed</b> <b>systems</b> research. Another, not less important reason, has to do w [...] ...|$|R
40|$|Large scale {{integration}} of today's aerospace systems is achievable {{through the use}} of <b>distributed</b> <b>systems.</b> Validating the safety of <b>distributed</b> <b>systems</b> is significantly more difficult as compared to centralized systems because of the complexity of the interactions between simultaneously active components. Integrated hazard analysis (IHA), a process used to identify unacceptable risks and to provide a means of controlling them, can be applied to either centralized or <b>distributed</b> <b>systems.</b> IHA, though, must be tailored to fit the particular <b>system</b> being analyzed. <b>Distributed</b> <b>systems,</b> for instance, must be analyzed for hazards in terms of the functions that rely on them. This paper will describe systems-oriented IHA techniques (as opposed to traditional failure-event or reliability techniques) that should be employed for <b>distributed</b> <b>systems</b> in aerospace environments. Special considerations will be addressed when dealing with specific <b>distributed</b> <b>systems</b> such as active thermal control, electrical power, command and data handling, and software systems (including the interaction with fault management systems). Because of the significance of second-order effects in large scale <b>distributed</b> <b>systems,</b> the paper will also describe how to analyze secondary functions to secondary functions {{through the use of}} channelization...|$|R
25|$|This {{complexity}} {{measure is}} closely related to the diameter of the network. Let D be the diameter of the network. On the one hand, any computable problem can be solved trivially in a synchronous <b>distributed</b> <b>system</b> in approximately 2D communication rounds: simply gather all information in one location (D rounds), solve the problem, and inform each node about the solution (D rounds).|$|E
25|$|Moreover, a {{parallel}} algorithm {{can be implemented}} either in {{a parallel}} system (using shared memory) or in a <b>distributed</b> <b>system</b> (using message passing). The traditional boundary between parallel and distributed algorithms (choose a suitable network vs. run in any given network) does not lie {{in the same place}} as the boundary between parallel and distributed systems (shared memory vs. message passing).|$|E
25|$|IBM defines grid {{computing}} as “the ability, using {{a set of}} open {{standards and}} protocols, {{to gain access to}} applications and data, processing power, storage capacity and a vast array of other computing resources over the Internet. A grid is a type of parallel and <b>distributed</b> <b>system</b> that enables the sharing, selection, and aggregation of resources distributed across ‘multiple’ administrative domains based on their (resources) availability, capacity, performance, cost and users' quality-of-service requirements”.|$|E
40|$|Society, {{as we know}} it today, is {{completely}} dependent on computer networks, Internet and <b>distributed</b> <b>systems,</b> which place at our disposal the necessary services to perform our daily tasks. Moreover, and unconsciously, all services and <b>distributed</b> <b>systems</b> require network management systems. These systems allow us to, in general, maintain, manage, configure, scale, adapt, modify, edit, protect or improve the main <b>distributed</b> <b>systems.</b> Their role is secondary and is unknown and transparent to the users. They provide the necessary support to maintain the <b>distributed</b> <b>systems</b> whose services we use every day. If we don’t consider network management systems during the development stage of main <b>distributed</b> <b>systems,</b> then there could be serious consequences or even total failures {{in the development of the}} <b>distributed</b> <b>systems.</b> It is necessary, therefore, to consider the management of the systems within the design of <b>distributed</b> <b>systems</b> and systematize their conception to minimize the impact of the management of networks within the project of <b>distributed</b> <b>systems.</b> In this paper, we present a formalization method of the conceptual modelling for design of a network management system through the use of formal modelling tools, thus allowing from the definition of processes to identify those responsible for these. Finally we will propose a use case to design a conceptual model intrusion detection system in network. This work was performed as part of the Smart University Project financed by the University of Alicante...|$|R
5000|$|Distributed Computer and Computer Networks Systems (Modeling and Analysis, <b>Distributed</b> and Wireless <b>Systems,</b> <b>Distributed</b> Servers, Parallel and <b>Distributed</b> <b>Systems,</b> Networks) ...|$|R
40|$|Large {{scientific}} collaborations {{are moving}} towards service oriented architectures for implementation and deployment of globally <b>distributed</b> <b>systems.</b> Clarens {{is a high}} performance, easy to deploy Web Service framework that supports the construction of such globally <b>distributed</b> <b>systems.</b> This paper discusses some of the core functionality of Clarens that the authors believe is important for building <b>distributed</b> <b>systems</b> based on Web Services that support scientific analysis. 1...|$|R
25|$|Chronoception {{refers to}} how {{the passage of time}} is {{perceived}} and experienced. Although the sense of time is not associated with a specific sensory system, the work of psychologists and neuroscientists indicates that human brains do have a system governing the perception of time, composed of a highly <b>distributed</b> <b>system</b> involving the cerebral cortex, cerebellum and basal ganglia. One particular component, the suprachiasmatic nucleus, is responsible for the circadian (or daily) rhythm, while other cell clusters appear to be capable of shorter-range (ultradian) timekeeping.|$|E
25|$|A {{distributed}} {{hash table}} (DHT) is {{a class of}} a decentralized <b>distributed</b> <b>system</b> that provides a lookup service similar to a hash table: (key, value) pairs are stored in a DHT, and any participating node can efficiently retrieve the value associated with a given key. Responsibility for maintaining the mapping from keys to values is distributed among the nodes, {{in such a way}} that a change in the set of participants causes a minimal amount of disruption. This allows a DHT to scale to extremely large numbers of nodes and to handle continual node arrivals, departures, and failures.|$|E
25|$|The {{figure on}} the right {{illustrates}} the difference between distributed and parallel systems. Figure (a) is a schematic view of a typical distributed system; the system is represented as a network topology in which each node is a computer and each line connecting the nodes is a communication link. Figure (b) shows the same <b>distributed</b> <b>system</b> in more detail: each computer has its own local memory, and information can be exchanged only by passing messages from one node to another by using the available communication links. Figure (c) shows a parallel system in which each processor has a direct access to a shared memory.|$|E
40|$|The article {{analyzes}} and standardizes {{methods for}} profiling <b>distributed</b> <b>systems</b> {{that focus on}} simulation to conduct experiments and build a graph model of the system. The theory of queueing networks is used for simulation modeling of <b>distributed</b> <b>systems,</b> receiving and processing user requests. To automate the above method of profiling <b>distributed</b> <b>systems</b> the software application was developed with a modular structure and similar to a SCADA-system...|$|R
30|$|This topic {{focuses on}} the third great {{challenge}} related to complex <b>distributed</b> <b>systems,</b> that of the very large-scale of many modern <b>distributed</b> <b>systems</b> (building on the dimensions of heterogeneity and adaptation as considered above).|$|R
40|$|This paper {{develops}} {{a theory of}} control for <b>distributed</b> <b>systems</b> (i. e., those defined by systems of constant coefficient partial differential operators) via the behavioral approach of Willems. The study here is algebraic {{in the sense that}} it relates behaviors of <b>distributed</b> <b>systems</b> to submodules of free modules over the polynomial ring in several indeterminates. As in the lumped case, behaviors of <b>distributed</b> ARMA <b>systems</b> can be reduced to AR behaviors. This paper first studies the notion of AR controllable <b>distributed</b> <b>systems</b> following the corresponding definition for lumped systems due to Willems. It shows that, as in the lumped case, the class of controllable AR systems is precisely the class of MA systems. It then shows that controllable 2 -D <b>distributed</b> <b>systems</b> are necessarily given by free submodules, whereas this is not the case for n-D <b>distributed</b> <b>systems,</b> n greater than or equal to 3. This therefore points out an important difference between these two cases. This paper then defines two notions of autonomous <b>distributed</b> <b>systems</b> which mimic different properties of lumped autonomous systems. Control is the process of restricting a behavior to a specific desirable autonomous subbehavior. A notion of stability generalizing bounded input{bounded output stability of lumped systems is proposed and the pole placement problem is defined for <b>distributed</b> <b>systems.</b> This paper then solves this problem for a class of distributed behaviors...|$|R
