817|523|Public
25|$|Geometrically, {{the linear}} {{constraints}} define the feasible region, {{which is a}} convex polyhedron. A linear function is a convex function, which implies that every local minimum is a global minimum; similarly, a linear function is a concave function, which implies that every local maximum is a <b>global</b> <b>maximum.</b>|$|E
25|$|Rugged, {{epistatic}} fitness landscapes {{also affect}} the trajectories of evolution. When a mutation {{has a large}} number of epistatic effects, each accumulated mutation drastically changes the set of available beneficial mutations. Therefore, the evolutionary trajectory followed depends highly on which early mutations were accepted. Thus, repeats of evolution from the same starting point tend to diverge to different local maxima rather than converge on a single <b>global</b> <b>maximum</b> as they would in a smooth, additive landscape.|$|E
500|$|Steiner's problem asks to {{find the}} <b>global</b> <b>maximum</b> for the {{function}} ...|$|E
2500|$|... as a {{potential}} refines the Nash equilibriums (eliminates local <b>maximums</b> that aren't <b>global</b> <b>maximums),</b> statistical mechanics can refine the potential by singling out multiple <b>global</b> <b>maximums</b> via spontaneous symmetry breaking (much as minimum free-energy [...] "all up" [...] or [...] "all down" [...] can be selected in a ferromagnet).|$|R
5000|$|... #Caption: Local and <b>global</b> <b>maxima</b> and minima for cos(3&pi;x)/x, 0.1&le; x &le;1.1 ...|$|R
5000|$|The {{function}} cos(x) has infinitely many <b>global</b> <b>maxima</b> at 0, ±2, ±4, ..., and infinitely many {{global minima}} at ±&pi;, ±3&pi;, ….|$|R
500|$|... the <b>global</b> <b>maximum</b> for {{positive}} [...] occurs at [...] for any {{and the global}} minimum occurs at [...] for any [...]|$|E
2500|$|The mode is {{the point}} of <b>global</b> <b>maximum</b> of the {{probability}} density function. [...] In particular, it solves the equation : ...|$|E
2500|$|Therefore, the [...] {{objective}} function attains the <b>global</b> <b>maximum</b> (subject to the constraints) at [...] {{and the global}} minimum at [...] The point [...] is a local minimum of f and [...] is a local maximum of f, as may be determined by consideration of the Hessian matrix of [...]|$|E
30|$|Most of the {{critical}} points will be maxima or minima. However, we cannot be assured directly that those critical points are <b>global</b> <b>maxima</b> or minima, we shall need to work a bit harder to obtain that.|$|R
40|$|Registration of {{two images}} {{requires}} interpolation {{to generate a}} new image on a transformed grid, and the optimal transformation that maps an image to the other is found by maximizing a similarity measure. Similarity surfaces are subject to scalloping artifacts due to interpolation that give local maxima, and, in some cases, erroneous <b>global</b> <b>maxima.</b> We propose a new linear filter that is applied to input images and which removes scalloping artifacts from cross-correlation and mutual-information similarity surfaces. The computational burden is sufficiently low {{that it can be}} used in every iteration of an optimization process. In addition, this new filter generates image data with constant variance after linear interpolation, making measurements of signal change more reliable. Following filtering of MR images, similarity surfaces are smoothed with removal of local <b>maxima</b> and biased <b>global</b> <b>maxima...</b>|$|R
40|$|The {{function}} on the Teichmueller {{space of}} complete, orientable, finite-area hyperbolic surfaces of a fixed topological type that assigns to a hyperbolic surface its maximal injectivity radius has no local maxima {{that are not}} <b>global</b> <b>maxima.</b> Comment: Dramatically shortened (now 12 pp.), and introductory material simplified, following a referee's suggestion...|$|R
2500|$|The {{solution}} for player 2 is equivalent. Using numerical values , , , this example transforms into a simple {{battle of the}} sexes, as shown in Figure 2. The game has two pure Nash equilibria, [...] and [...] These are also the local maxima of the potential function (Figure 3). The only stochastically stable equilibrium is , the <b>global</b> <b>maximum</b> of the potential function.|$|E
2500|$|The glasnost {{political}} {{reforms in the}} late 1980s and the subsequent dissolution of the USSR led {{to the release of}} a large amount of formerly classified archival documents, including new demographic and NKVD data. Analysis of the official GULAG statistics by Western scholars immediately demonstrated that, despite their inconsistency, they do not support previously published higher estimates. Importantly, the released documents made possible to clarify terminology used to describe different categories of forced labour population, because the use of the terms [...] "forced labour", [...] "GULAG", [...] "camps" [...] interchangeably by early researchers led to significant confusion and resulted in significant inconsistencies in the earlier estimates. Archival studies revealed several components of the NKVD penal system in the Stalinist USSR: prisons, labor camps, labor colonies, as well as various [...] "settlements" [...] (exile) and of non-custodial forced labour. Although most of them fit the definition of forced labour, only labour camps, and labour colonies were associated with punitive forced labour in detention. Forced labour camps ("GULAG camps") were hard regime camps, whose inmates were serving more than three-year terms. As a rule, they were situated in remote parts of the USSR, and labour conditions were extremely hard there. They formed a core of the GULAG system. The inmates of [...] "corrective labour colonies" [...] served shorter terms; these colonies were located in less remote parts of the USSR, and they were run by local NKVD administration. Preliminary analysis of the GULAG camps and colonies statistics (see the chart on the right) demonstrated that the population reached the maximum before the World War II, then dropped sharply, partially due to massive releases, partially due to wartime high mortality, and then was gradually increasing until the end of Stalin era, reaching the <b>global</b> <b>maximum</b> in 1953, when the combined population of GULAG camps and labour colonies amounted to 2,625,000.|$|E
2500|$|If all {{mutations}} are additive, {{they can}} be acquired in any order and still give a continuous uphill trajectory. The landscape is perfectly smooth, with only one peak (<b>global</b> <b>maximum)</b> and all sequences can evolve uphill to it by the accumulation of beneficial mutations in any order. Conversely, if mutations {{interact with one another}} by epistasis, the fitness landscape becomes rugged as the effect of a mutation depends on the genetic background of other mutations. At its most extreme, interactions are so complex that the fitness is ‘uncorrelated’ with gene sequence and the topology of the landscape is random. This is referred to as a rugged fitness landscape and has profound implications for the evolutionary optimisation of organisms. If mutations are deleterious in one combination but beneficial in another, the fittest genotypes can only be accessed by accumulating mutations in one specific order. This makes it more likely that organisms will get stuck at local maxima in the fitness landscape having acquired mutations in the 'wrong' order. [...] For example, a variant of TEM1 β-lactamase with 5 mutations is able to cleave cefotaxime (a third generation antibiotic). However, of the 120 possible pathways to this 5-mutant variant, only 7% are accessible to evolution as the remainder passed through fitness valleys where the combination of mutations reduces activity. In contrast, changes in environment (and therefore the shape of the fitness landscape) have been shown to provide escape from local maxima. In this example, selection in changing antibiotic environments resulted in a [...] "gateway mutation" [...] which epistatically interacted in a positive manner with other mutations along an evolutionary pathway, effectively crossing a fitness valley. This gateway mutation alleviated the negative epistatic interactions of other individually beneficial mutations, allowing them to better function in concert. Complex environments or selections may therefore bypass local maxima found in models assuming simple positive selection.|$|E
40|$|Abstract. In this note, we {{show that}} some F-harmonic maps into spheres are <b>global</b> <b>maxima</b> of the {{variations}} of their energy functional on the conformal group of the sphere. Our result extends partially those obtained in [15] and [17] for harmonic and p-harmonic maps. hal- 00747787, version 1 - 1 Nov 2012 1...|$|R
50|$|Applications that don't involve sorting {{would be}} in finding the mean, {{standard}} deviation, skewness and kurtosis of a statistical distribution, and in finding the integral and <b>global</b> <b>maxima</b> and minima of difficult deterministic functions. Subrandom numbers {{can also be used}} for providing starting points for deterministic algorithms that only work locally, such as Newton-Raphson iteration.|$|R
40|$|In {{this paper}} we {{characterize}} the local maxima of a continuous global optimization formulation for finding the independence number of a graph. Classical Karush-Kuhn-Tucker conditions and simple combinatorial arguments are found sufficient to deduce several interesting {{properties of the}} local and <b>global</b> <b>maxima.</b> These properties can be utilized in developing new approaches to the maximum independent set problem...|$|R
5000|$|... 4. Any {{local maximum}} of a concave {{function}} {{is also a}} <b>global</b> <b>maximum.</b> A strictly concave function will have at most one <b>global</b> <b>maximum.</b>|$|E
50|$|In {{both the}} global and local cases, {{the concept of}} a strict {{extremum}} can be defined. For example, x&lowast; is a strict <b>global</b> <b>maximum</b> point if, for all x in X with x ≠ x&lowast;, we have f(x&lowast;) > f(x), and x&lowast; is a strict local maximum point if there exists some &epsilon; > 0 such that, for all x in X within distance &epsilon; of x&lowast; with x ≠ x&lowast;, we have f(x&lowast;) > f(x). Note that a point is a strict <b>global</b> <b>maximum</b> point if and only if it is the unique <b>global</b> <b>maximum</b> point, and similarly for minimum points.|$|E
5000|$|Steiner's problem asks to {{find the}} <b>global</b> <b>maximum</b> for the {{function}} ...|$|E
40|$|In {{this paper}} we explore loops of {{non-autonomous}} Hamiltonian diffeomorphisms with degenerate fixed maxima. We show that such loops can not have totally degenerate fixed <b>global</b> <b>maxima.</b> This has applications for the Hofer geometry {{of the group of}} Hamiltonians for certain symplectic 4 manifolds and also gives criteria for certain 4 manifolds to be uniruled. Comment: 13 page...|$|R
40|$|Unsupervised {{learning}} algorithms {{based on}} Expectation Maximization (EM) are often straightforward to implement and provably converge {{on a local}} likelihood maximum. However, these algorithms often do not perform well in practice. Common wisdom holds that they yield poor results because they are overly sensitive to initial parameter values and easily get stuck in local (but not <b>global)</b> <b>maxima...</b>|$|R
40|$|Some {{results on}} {{positive}} solutions of equations including the p-Laplacian operator were discussed. The {{problem of a}} priori estimate {{and the existence of}} positive solution methods to the problem were analyzed. It was found that while applying the blow-up result, a key point was the location of some <b>global</b> <b>maxima</b> of the solutions. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
50|$|Hill {{climbing}} {{will not}} necessarily find the <b>global</b> <b>maximum,</b> but may instead converge on a local maximum. This problem does not occur if the heuristic is convex. However, as many functions are not convex hill climbing may often fail to reach a <b>global</b> <b>maximum.</b> Other local search algorithms try to overcome this problem such as stochastic hill climbing, random walks and simulated annealing.|$|E
5000|$|The {{function}} [...] has {{a unique}} <b>global</b> <b>maximum</b> at x = e. (See figure at right) ...|$|E
5000|$|The {{function}} x−x has {{a unique}} <b>global</b> <b>maximum</b> over the positive real numbers at x = 1/e.|$|E
50|$|In mathematics, the {{arguments}} of the maxima (abbreviated arg max or argmax) are the points of the domain of some function at which the function values are maximized. In contrast to <b>global</b> <b>maxima,</b> referring to the largest outputs of a function, arg max refers to the inputs, or arguments, at which the function outputs are as large as possible.|$|R
40|$|It {{is often}} {{important}} to check whether the maximum max B f {{of a given}} function f on a given set B is smaller than a given number C. Empirical evidence shows that different instances of this checking problem have different relative complexity: the larger the difference C Γ max B f, the easier the problem. In general, the fewer <b>global</b> <b>maxima,</b> the easier the problem; and finally, the further away <b>global</b> <b>maxima</b> from each other, the easier the problem. It is difficult to formalize this empirical difference in complexity in standard complexity theory terms, because all these cases are NP-hard. In this paper, we use the analysis of mathematical optimization problems emerging from fuzzy optimization to propose a new "robust" formalization of relative complexity which takes into consideration numerical inaccuracy. This new formalization enables us to theoretically explain the empirical results on relative complexity...|$|R
2500|$|... <b>global</b> daily <b>maximum</b> {{maps and}} hourly clear-sky {{forecast}} graphs, plus observations from Finland ...|$|R
5000|$|The {{function}} 2 cos(x) − x has infinitely {{many local}} maxima and minima, but no <b>global</b> <b>maximum</b> or minimum.|$|E
5000|$|The mode is {{the point}} of <b>global</b> <b>maximum</b> of the {{probability}} density function. In particular, it solves the equation : ...|$|E
5000|$|The [...] inside Q-star {{moves from}} a <b>global</b> <b>maximum</b> of the {{potential}} changing the mass of fermions and making them bound.|$|E
3000|$|..., {{a certain}} number of {{particles}} is required in order to find its <b>global</b> <b>maxima</b> instead of a local one. It has been proved in [18] that the amount of particles required by a standard PF algorithm to achieve a successful tracking follows an exponential law with the number of dimensions. Articulated motion tracking typically employs state spaces with dimension [...]...|$|R
40|$|We derive high-probability finite-sample uniform {{rates of}} {{consistency}} for $k$-NN regression that are optimal up to logarithmic factors under mild assumptions. We moreover show that $k$-NN regression adapts to an unknown lower intrinsic dimension automatically. We then apply the $k$-NN regression rates to establish new results about estimating the level sets and <b>global</b> <b>maxima</b> of a function from noisy observations...|$|R
40|$|Abstract — This work {{examines}} a novel {{method that}} provides a parallel search {{of a very large}} network space consisting of fisheries management data. The parallel search solution is capable of determining <b>global</b> <b>maxima</b> of the search space using brute force search, compared to local optima located by machine learning solutions such as evolutionary computation. The actual solutions from the best machine learning technique, called Probabilistic Adaptive Mapping Developmental Genetic Algorithm, are compared by a fisheries expert to the <b>global</b> <b>maxima</b> solutions returned by parallel search. In addition, the time required for parallel search, for both CPU and GPU-optimized solutions, are compared to those required for machine learning solutions. The GPU parallel computing solution was found to have a speedup of over 10, 000 x, in excess of most similar performance comparison studies in the literature. An expert found that overall the machine learning solutions pro-duced more interesting results by locating local optima than global optima determined by parallel processing. I...|$|R
