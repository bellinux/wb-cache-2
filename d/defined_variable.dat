35|3070|Public
50|$|Representing {{continuous}} optimization variables by uniform distributions without variable interactions, variance based {{sensitivity analysis}} quantifies {{the contribution of}} the optimization variables for a possible improvement of the model responses. In contrast to local derivative based sensitivity methods, the variance based approach quantifies the contribution with respect to the <b>defined</b> <b>variable</b> ranges.|$|E
5000|$|The nm command {{identifies}} weak {{symbols in}} object files, libraries, and executables. On Linux a weak function symbol is marked with [...] "W" [...] if a weak default definition is available, and with [...] "w" [...] {{if it is}} not. Weakly <b>defined</b> <b>variable</b> symbols are marked with [...] "V" [...] and [...] "v". On Solaris [...] "nm" [...] prints [...] "WEAK" [...] instead of [...] "GLOB" [...] for a weak symbol.|$|E
50|$|The {{application}} {{of different types}} of encoding schemes have been explored to encode variant bases and genomic coordinates. Fixed codes, such as the Golomb code and the Rice code, are suitable when the variant or coordinate (represented as integer) distribution is well <b>defined.</b> <b>Variable</b> codes, such as the Huffman code, provide a more general entropy encoding scheme when the underlying variant and/or coordinate distribution is not well-defined (this is typically the case in genomic sequence data).|$|E
40|$|Temporal {{schedules}} {{of negative}} reinforcement were derived {{in a manner}} analogous to those for positive reinforcement, and two parametric {{studies were carried out}} with two of the three <b>defining</b> <b>variables.</b> With some limiting values of the <b>defining</b> <b>variables,</b> escape schedules result and data obtained at these values were similar to those obtained in escape studies. At other values of the <b>defining</b> <b>variables</b> avoidance behavior was generated...|$|R
5000|$|TScript {{implements}} {{concepts of}} inheritance and code encapsulation through <b>defined</b> <b>variables.</b> For example the following code snippet show a <b>defined</b> <b>variables</b> Foo and Bar that supports a constructor.variable Bar{ Integer minimum, maximum; Bar (...) { this.minimum = 1; }}variable Foo extends Bar{ WString name; Foo(WString name){ this.name = name; this.Bar (...) }}public main (...) { Foo foo(L"Goo"); System::MessageBox(foo.ToString (...) [...] );} ...|$|R
40|$|The aimed {{this study}} was to {{describe}} the increase of studentsâ€™ skill in controlling <b>variables</b> and <b>defining</b> <b>variables</b> operationally on Learning Cycle three-phase (LC- 3 E). The model was applied pretest-posttest control group design. The participants included two clsses at the second year sains of SMA N 1 Way Jepara, Lampung Timur. The increase of studentsâ€™ skill in controlling <b>variables</b> and <b>defining</b> <b>variables</b> operationally measured on the difference of a significant normalized gain (n-Gain). The results show that mean value of n-Gain controlling variables skill in control and experimental classes were 0. 15 and 0. 47, and the mean value of n-Gain <b>defining</b> <b>variables</b> operationally skill in control and experimental classes were 0. 23 and 0, 50. Based on hypothesis testing using t-test and n-Gain, it was concluded that the LC 3 E learning model can increasing studentsâ€™ skill in controlling <b>variables</b> and <b>defining</b> <b>variable</b> operationally...|$|R
50|$|Since H is a {{mechanically}} <b>defined</b> <b>variable</b> {{that is not}} conserved, then {{like any}} other such variable (pressure, etc.) it will show thermal fluctuations. This means that H regularly shows spontaneous increases from the minimum value. Technically {{this is not an}} exception to the H theorem, since the H theorem was only intended to apply for a gas with {{a very large number of}} particles. These fluctuations are only perceptible when the system is small and the time interval over which it is observed is not enormously large.|$|E
40|$|The GVSU Offshore Wind Assessment Project buoy generates {{approximately}} 20 gigabytes of raw, {{longitudinal data}} each year. It {{has been running}} {{from the end of}} 2011 to early 2014 with potentially continuing operation for several years. Our data warehousing measures receives the data as unindexed files with loosely <b>defined</b> <b>variable</b> sets to an organized database with standardized message types and date span folders. In order to utilize and share our large data most efficiently, we created a streamlined database file structure for internal analytical use and a web based data retrieval system for portable external environment use...|$|E
3000|$|The {{next step}} in the {{development}} of this BN structure is the identification of the causality relations among the defined random variables and the construction of the respective DAG, which represents these relations. For identifying the causality relations, the definition of causation based on the concept of manipulation is adopted [15]. The latter states that for a given pair of random variables, namely X and Y, variable X has a causal influence on Y if a manipulation of the values of X leads to a change in the probability distribution of Y. Making use of the aforementioned definition of causation, it can be easily observed that each <b>defined</b> <b>variable</b> [...]...|$|E
5000|$|<b>Defining</b> <b>variable</b> F as {{convection}} mass flux {{and variable}} D as diffusion conductance ...|$|R
30|$|In {{the next}} section we discuss some {{descriptive}} measures of the previously <b>defined</b> <b>variables.</b>|$|R
5000|$|... {{built in}} - Pre <b>defined</b> <b>variables</b> that have values {{relevant}} to the current firing probe ...|$|R
40|$|Bence Jones protein from {{a patient}} (SUT) who had {{multiple}} myeloma and amyloidosis had specificity for X-light chains of the chemically <b>defined</b> <b>variable</b> (V) region X-chain subgroup XVI. Sequence analyses of protein SUT and of five other X-light chains recognized immunologically as of the VAVI subgroup revealed that all six proteins had the N-terminal sequence charac-teristic for prototype XVI proteins. The isotypic nature of the VAVI subgroup was demonstrated immunochem-ically: XVI molecules were detected among light chains isolated from the IgG proteins of each of 12 normal individuals and XVI antigenic determinants were also detectable on the intact IgG proteins. The frequency of XVI molecules among X-type light chains is esti-mated to be- 5...|$|E
40|$|One {{decisive factor}} {{for the success of}} {{symbolic}} search using BDDs {{is whether or not the}} variable ordering is good. A gen-eral intuition is that smaller BDDs result if inter-dependent variables are close together. The most common means to cap-ture variable dependencies in planning are causal graphs, and consequently previous work <b>defined</b> <b>variable</b> orders based on these. Starting from the observation that the two concepts of “dependency ” are actually quite different, we introduce a framework for assessing the strength of variable ordering heuristics in sub-classes of planning. It turns out that causal graph based variable orders may be exponentially worse than optimal even for very simple planning tasks. Experiments with a broad range of such variable ordering variants indicate that they are mediocre at best...|$|E
40|$|AbstractIn this paper, {{a fairly}} general {{framework}} for reasoning from inconsistent propositional bases is <b>defined.</b> <b>Variable</b> forgetting {{is used as}} a basic operation for weakening pieces of information so as to restore consistency. The key notion is that of recoveries, which are sets of variables whose forgetting enables restoring consistency. Several criteria for defining preferred recoveries are proposed, depending on whether the focus is laid on the relative relevance of the atoms or the relative entrenchment of the pieces of information (or both). Our framework encompasses several previous approaches as specific cases, including reasoning from preferred consistent subsets, and some forms of information merging. Interestingly, the gain in flexibility and generality offered by our framework does not imply a complexity shift compared to these specific cases...|$|E
50|$|A macro {{is used to}} <b>define</b> <b>variables</b> or procedures, {{to allow}} code reuse, or to design domain-specific languages.|$|R
5000|$|Now let us <b>define</b> <b>variables</b> F and D to {{represent}} the convection mass flux and diffusion conductance at cell faces, ...|$|R
50|$|Sass allows <b>variables</b> to be <b>defined.</b> <b>Variables</b> {{begin with}} a dollar sign ($). Variable {{assignment}} is done with a colon (:).|$|R
40|$|For a given Lovelock order N, {{it turns}} out that static fluid {{solutions}} of the pure Lovelock equation for a star interior have the universal behavior in all n≥ 2 N+ 2 dimensions relative to an appropriately <b>defined</b> <b>variable</b> and the Vaidya-Tikekar parameter K, indicating deviation from sphericity of 3 -space geometry. We employ the Buchdahl metric ansatz which encompasses almost all the known physically acceptable models including in particular the Vaidya-Tikekar and Finch-Skea. Further for a given star radius, the constant density star, always described by the Schwarzschild interior solution, defines the most compact state of distribution while the other end is marked by the Finch-Skea model, and all the other physically tenable models lie in between these two limiting distributions. Comment: 18 pages, 7 figure...|$|E
40|$|Using a hadron {{and string}} cascade model, JPCIAE, {{the energy and}} {{centrality}} dependences of charged particle pseudorapidity density in relativistic nuclear collisions were studied. Within the framework of this model, both the relativistic $p+\bar p$ experimental data and the PHOBOS and PHENIX $Au+Au$ data at $\sqrt s_{nn}$= 130 GeV could be reproduced fairly well without retuning the model parameters. The predictions for full RHIC energy $Au+Au$ collisions and for $Pb+Pb$ collisions at the ALICE energy were given. Participant nucleon distributions were calculated based on different methods. It {{was found that the}} number of participant nucleons, $ $, is not a well <b>defined</b> <b>variable</b> both experimentally and theoretically. Therefore, it is inappropriate to use charged particle pseudorapidity density per participant pair as a function of $ $ for distinguishing various theoretical models. Comment: 10 pages, 4 figures, submitted to Phy. Lett. ...|$|E
40|$|The {{energy and}} {{centrality}} dependences of charged particle pseudorapidity density in relativistic nuclear collisions were studied using a hadron and string cascade model, JPCIAE. Both the relativistic p+p̅ experimental {{data and the}} PHOBOS and PHENIX Au+Au data at RHIC energy could be fairly reproduced {{within the framework of}} JPCIAE model and without retuning the model parameters. The predictions for Pb+Pb collisions at the LHC energy were also given. We computed the participant nucleon distributions using different methods. It was found that the number of participant nucleons is not a well <b>defined</b> <b>variable</b> both experimentally and theoretically. Thus it may be inappropriate to use the charged particle pseudorapidity density per participant pair {{as a function of the}} number of participant nucleons for distinguishing various theoretical models. A discussion for the effect of different definitions in nuclear radius (diffused or sharp) was given. Comment: 15 pages, 7 figure...|$|E
5000|$|After one {{of these}} {{declarations}} (but not both), [...] {{can be used as}} follows to create newly <b>defined</b> <b>variables</b> of the [...] datatype: ...|$|R
50|$|Less allows <b>variables</b> to be <b>defined.</b> <b>Variables</b> in Less {{are defined}} with an at sign (@). Variable {{assignment}} {{is done with}} a colon (:).|$|R
3000|$|... is a vector of variables, A(j), j = 1,…,p, is the {{coefficient}} matrix <b>defining</b> <b>variable</b> contributions at step t−j and E(t) is the vector of prediction errors.|$|R
40|$|Meningococcal FetA is an iron-regulated, {{immunogenic}} outer {{membrane protein}} and vaccine component. The most diverse region of this protein is a previously <b>defined</b> <b>variable</b> region (VR) {{that has been}} shown to be immunodominant. In this analysis, a total of 275 Neisseria lactamica isolates, collected during studies of nasopharyngeal bacterial carriage in infants, were examined for the presence of a fetA gene. The fetA VR nucleotide sequence was determined for 217 of these isolates, with fetA apparently absent from 58 isolates, the majority of which belonged to the ST- 624 clonal complex. The VR in N. lactamica was compared to the same region in N. meningitidis, N. gonorrhoeae, and a number of other commensal Neisseria. Identical fetA variable region sequences were identified among commensal and pathogenic Neisseria, suggesting a common gene pool, differing from other antigens in this respect. Carriage of commensal Neisseria species, such as N. lactamica, that express FetA may be involved in the development of natural immunity to meningococcal disease...|$|E
40|$|Vacuum {{fluctuation}} {{was measured}} using three different vacuum control methods. Firstly, the use was made of a control valve delivered by the manufacturer; then, an additionally installed frequency converter was used. Lastly, a frequency converter fitted with the stabilisation device prototype was used. First, control sensitivity according to ISO was measured in all the three alternatives. Then, vacuum fluctuation during milking was measured. To conduct the measurements under objectively identified conditions, another measurement was conducted with air feed during milking being replaced with a precisely <b>defined</b> <b>variable</b> flow rate. The conducted measurement confirmed {{the fact that when}} the frequency converter is used, vacuum fluctuation in stabilised condition is at the same level as when the control valve is used. If there are sudden changes in flow rate and the frequency converter is used, vacuum fluctuation increases. The proposed stabilisation device prototype can reduce the fluctuation in small milking plant but it is not suitable in large milking parlours...|$|E
40|$|The {{existence}} of fixed point in self-similar Lennard-Jones (L-J) potentials {{has been proved}} based on the mosaic geometric structure theory of glass transition (GT) [J. L. Wu, Soft Nanoscience letters, 1, 3 – 86 (2011) ]. A geometric local-global mode-coupling recursive equation, different from the current Mode-Coupling Theories, has been introduced {{to find out the}} non-integrable induced potential structure of boson peak at GT. The recursively <b>defined</b> <b>variable</b> in reduced recursive equation is the potential fluctuation of reduced L-J potentials associated with reduced geometric phase potentials. A series of results have been deduced directly at GT. (i) There are only 8 orders of molecule-clusters. (ii) Two orthogonally fast-slow reduced phase potentials, 3 / 8 and 5 / 8, are accompanied with density fluctuation and clusters hop-delocalization along 8 geodesics. (iii) The stability condition of potential fluctuation is the Lindemann ratio. (iv) A new reduced attractive potential of – 17 / 16, lower than reduced potential well energy – 1, occurs...|$|E
50|$|As {{can be seen}} in Figure 1 {{the process}} of {{defining}} common requirements is a parallel process with <b>defining</b> <b>variable</b> requirements. Both activities take place at the same time.|$|R
40|$|This article {{describes}} {{an application of}} genetic algorithms {{to the analysis of}} spatially referenced data. A genetic algorithm is used to refine the specification of an hedonic regression model of spatially distributed residential property prices. The process of refinement concerns the search for good definitions of spatially <b>defined</b> <b>variables.</b> The fitness function for the genetic algorithm is provided by the coefficient of determination of the model. The regression results produced by the refined model are compared with those produced by a model containing a set of spatially <b>defined</b> <b>variables</b> based on information provided by an expert on local property prices...|$|R
3000|$|By {{using the}} <b>defined</b> <b>variables</b> and {{detailing}} the informal hypothesis, we postulate eight pairs of statistical hypotheses (null and alternative): three pairs evaluating the techniques {{at each level}} of number of test cases that fail (e.g. H [...]...|$|R
40|$|AbstractThe coreceptor {{usage of}} HIV- 1 {{envelope}} proteins (Env) is mainly {{dependent on a}} <b>defined</b> <b>variable</b> region within the V 3 -loop of Env. Thus, retroviral vectors derived from murine leukemia virus (MLV), which have been pseudotyped with HIV- 1 envelope proteins holding different V 3 -loops, enable selective gene delivery into either CXCR 4 or CCR 5 positive cultured cells. Here, we tested the distribution of CD 4 /CCR 5 -tropic [MLV(HIV) ]-pseudotype vectors in transgenic mice expressing CD 4 and either CXCR 4 or CCR 5 of human origin. The specificity of gene transfer was analyzed by ex vivo transduction of spleen cells as well as after i. v. or i. p. injection of transgenic mice. Expression of the transferred marker gene EGFP and vector sequences could be detected exclusively in lymphocytes expressing (hu) CD 4 and (hu) CCR 5, whereas MLV vectors pseudotyped with the VSV-G envelope glycoprotein mediated gene transfer in mice of all genotypes investigated. These data demonstrated that cell-specific gene delivery via [MLV(HIV) ]-pseudotyped vectors, as previously shown for cultured cells, is also achievable in vivo...|$|E
40|$|Abstract: Over {{the last}} two decades, philosophers, statisticians, and {{computer}} scientists have converged on the fundamental outline of a theory of causal representation and causal inference (Spirtes, Glymour, and Scheines, 2000; Pearl, 2000). Some conditions and assumptions under which reliable inference {{about the effects of}} manipulations is possible have been precisely characterized; other conditions and assumptions under which reliable inference about the effects of manipulation is impossible have also been characterized. However, the theory of inference about the effects of manipulations that has been developed does not consider the problem of “defined variables”. In causal modeling, sometimes variables are deliberately introduced as defined functions of others variables. More interestingly, sometimes two or more measured variables are deterministic functions of one another, not deliberately, but because of redundant measurements. In these cases, manipulation of an observed <b>defined</b> <b>variable</b> may actually be an ambiguous description of a manipulation of some underlying variables, although the manipulator does not know that this is the case. In this article we revisit the question of precisely characterizing conditions and assumption under which reliable inference about the effects of manipulations is possible, even when the possibility of “ambiguous manipulations ” is allowed. ...|$|E
40|$|This paper {{argues that}} the term “social capital ” is an {{inappropriate}} terminology that is unsuited for theory or scientific empirical research. The arguments challenge the metaphor and definition by revealing the phrase to be dehumanizing, oxymoronic, anachronistic, and demeaning, which makes it incorrect, and even immoral, for proper use. It is also argued that the term is 1984 -ish vis-à-vis Doublethink and New-speak. It is recommended that the metaphors for “social capital ” and its related term, “human capital,” should be dropped from use. It is further recommended, {{for the purpose of}} increased clarity for theory building and for empirical research, and to avoid using dehumanizing terminology, that it is more appro-priate to retain the term “social networking ” as the general name for the process; such that, when at-tempting to measure related social networking concepts, researchers should specify operationally <b>defined</b> <b>variable</b> names that are more suited to proper scientific measurement of the research domains. For exam-ple, if “friends ” are studied as helpers in a social network, that term may be used as a variable name, but under no circumstances should one’s friends, or other people, be referred to or regarded as “capital. ...|$|E
5000|$|... void liang_barsky_clipper(float xmin, float ymin, float xmax, float ymax, float x1, float y1, float x2, float y2) { // <b>defining</b> <b>variables</b> float p1 = -(x2 - x1); float p2 = -p1; float p3 = -(y2 - y1); float p4 = -p3; ...|$|R
50|$|NoteTab {{does not}} {{currently}} include support for Unicode documents.NoteTab only has syntax highlighting for HTML documents and NoteTab clip/scripts; {{and not for}} other languages.Clip language does allow local <b>variables.</b> All <b>defined</b> <b>variables</b> are global in scope.There is no provision for compiling macros.|$|R
40|$|In {{this paper}} we <b>define</b> <b>variable</b> {{exponent}} Sobolev spaces associated with Jacobi expansions. We prove that our generalized Sobolev spaces {{can be characterized}} as variable exponent potential spaces and as variable exponent Triebel-Lizorkin type spaces. Comment: 30 pages, small typos corrected in the introductio...|$|R
