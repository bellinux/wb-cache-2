2|5|Public
50|$|The foot-lambert is {{also used}} in the flight {{simulation}} industry to measure the <b>highlight</b> <b>brightness</b> of visual display systems. The minimum required <b>highlight</b> <b>brightness</b> varies based on the type and level of Flight Simulation Training Device (FSTD), but is generally 3-6 foot-lamberts for most devices qualified under Federal Aviation Administration (FAA) or Joint Aviation Authorities (JAA) regulations.|$|E
40|$|Includes bibliographical {{references}} (pages 48 - 49) This report {{describes the}} result of a research study whose goal was the evaluation of the effects of television display size, (2) display degradation, (3) observer viewing distance, and (4) target motion rate upon target identification performance. Appendices to the report describe (1) a reconnaissance transparency projection system used to simulate the televisual air to surface tactical target attacks used as test material in this study and (2) a rating procedure used to compare target briefing photographs in terms of qualities important for target identification. The target ratings are then used to predict target identification performance in the simulated target attacks. Major conclusions are as follows: 1. There was neither practical nor statistically significant difference in target identification performance among any of the monitor sizes investigated. (3 - 1 / 2 -, 5 -, and 8 -inch diagonals). 2. There was neither practical nor statistically significant difference in target identification performance between a degraded and an undegraded 8 -inch monitor. Degradation consisted of reduction of grey-shade rendition form 9 - 8, and reduction of <b>highlight</b> <b>brightness</b> from 55 to 42 foot-lamberts. 3. The visual angle subtended by displays is of major importance in predicting the target subtended angle at identification. As one moved closer to all of the displays used in the study, the diagonal target size at the eye of the observer required for target identification increased almost linearly with the ratio, TV height/viewing distance, which is the tangent of the angle subtended by the height of the display. 4. After the tangent function effect has been removed, 12 degree and 15 degree display viewing angle heights provide slightly better operational performance than do 6 -degree, 9 -degree, or 18 -degree viewing angle heights. 5. Higher target motion rates require slightly larger target sizes for target identification to take place. 6. Factors which contribute to rapid target identification are large size, high contrast, low jaggedness, and low blur in that order. The same factors except for large size result in smaller target diagonal subtended angles at the eye of the observer when identification occurs. 7. By using the rating procedures outlined herein to evaluate reconnaissance photographs of targets, untrained observers can make accurate reliable cooperative judgments of target characteristics related to ease of target identification. 8. Target ratings on contrast, blur, and jaggedness can be used to explain about half of the total variance described by the 32 targets "attacked??? during the simulation study. 9. Improving target contrast offers greater improvement in target identification performance than does reducing target blur...|$|E
50|$|The {{most obvious}} case of burning is when an image's {{contrast}} is raised too much, {{and the result}} contains obvious black or white blobs, where {{there used to be}} detail in the shadows or the highlights. In this case, the brightness can be adjusted in parallel, and in this way the artist decides whether to preserve detail in the shadows (increase brightness) or in the <b>highlights</b> (decrease <b>brightness),</b> at the expense of detail in the opposite.|$|R
50|$|Computer-aided design (CAD) {{programs}} use specular highlights as {{visual cues}} {{to convey a}} sense of surface curvature when rendering 3D objects. However, many CAD programs exhibit problems in sampling specular highlights because the specular lighting computations are only performed at the vertices of the mesh used to represent the object, and interpolation is used to estimate lighting {{across the surface of the}} object. Problems occur when the mesh vertices are not dense enough, resulting in insufficient sampling of the specular lighting. This in turn results in <b>highlights</b> with <b>brightness</b> proportionate to the distance from mesh vertices, ultimately compromising the visual cues that indicate curvature. Unfortunately, this problem cannot be solved simply by creating a denser mesh, as this can greatly reduce the efficiency of object rendering.|$|R
40|$|The present {{experiment}} employed target detection {{tasks to}} investigate attentional deployment during visual search for target aircraft symbols on a cockpit display of traffic information (CDTI). Targets were defined by either a geometric property (aircraft {{on a collision}} course with Ownship) or a textual property (aircraft with associated altitude tags indicating an even altitude level). Effects of target location and target <b>brightness</b> (<b>highlighting)</b> were examined. Target location was systematically related to target detection time, and this interacted with the target's defining property (collision geometry or associated text). Highlighting (which was not linked to whether an aircraft symbol was the target) did not influence target detection time...|$|R
40|$|In {{computer}} graphics, {{the process}} of {{improving the quality of}} a digitally stored image by manipulating the image with software is called image enhancement. Advanced image enhancement software also supports many filters for altering images in various ways. We may be forced to apply one or more features of the image enhancement to the low quality photos to improve them for further photogrammetric use. This could be due to some of the unexpected photographic environment, which affect the images quality and needs something to be done to enhance the images for a better view. Applying such features may affect the accuracy in close range photogrammetric measurements. To find out the effect of these features in the close range photogrammetric measurements accuracy, a theoretical study on applying some of the image enhancement features were studied using CAD environment (3 D Studio software), which can be used as an excellent tool for accuracy studies. Eight of Image enhancement feature were studied, re-size, sharpen, blur, midtone, contrast, <b>highlight,</b> shadow, and <b>brightness.</b> The original images were created using 3 D studio MAX as a CAD environment, which enable us to get errorless image for a computer model as a tes...|$|R
40|$|Many {{commonly}} occurring substances are somewhat translucent (e. g. wax, jade, fruit-flesh, and cheese). When light strikes a translucent material, {{it passes through}} the surface and scatters {{a number of times}} within the body of the object before re-emerging. This causes light to ‘bleed’ through translucent objects, giving them a distinctive visual softness and glow. What image cues are responsible for this characteristic appearance? How do we distinguish between translucent and opaque materials? Here we use a combination of image statistics and psychophysics to study the perception of translucent materials. There has been a large amount of previous work on the perception of materials that transmit light. Almost all of this work is based on simple physical models of transparency, (e. g. the episcotister model of Metelli, 1974), in which the object of interest is a thin filter or screen. However, recent advances in computer graphics (Jensen et al. 2001; Jensen and Buhler, 2002) make it possible to simulate the complex physics of solid translucent objects. We have used this model to study how a wide range of factors influence the perception of translucency, including <b>highlights,</b> colour, contrast, <b>brightness,</b> blurriness, and conditions of illumination. Our main findings are as follows: (1) We have found {{that it is possible to}} enjoy a vivid impression of translucency even when many of the cues that were traditionally believed to be important for the perception of transparency (e. g. X-Junctions, contrast conditions) are absent from the display. (2) We argue that sub-surface light scattering is too complex for the visual system to infer translucency by inverse optics. Accordingly we suggest that the visual system tracks low-level image statistics that reliably correlate with changes in translucency. (3) We find that perceived translucency varies dramatically with conditions of illumination. We compare how well a number of candidate cues can predict these variations. In conclusion, there is a wide range of materials that have not been studied before, and which we are only just beginning to understand. Many intuitions that we have about which cues are crucial for recovering opacity turn out to be at best incomplete...|$|R

