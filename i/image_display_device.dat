12|6712|Public
50|$|A {{document}} camera needs an <b>image</b> <b>display</b> <b>device</b> {{to show the}} information to the audience. Modern motherboards have a variety of connections to ensure flexibility of use. In addition to HDMI, DVI, VGA ports for connecting to displays, (projectors, monitors and video conferencing systems) there are also several interfaces provided to facilitate connection to a computer or interactive whiteboard. These interfaces are most commonly USB, Network (LAN) and serial.|$|E
5000|$|Computer {{screens and}} other {{electronic}} display devices provide {{an alternative approach}} to contact printing. A permanent image (negative, positive film or transparency, or translucent original) is not used, instead the light sensitive material is exposed directly to the display device {{in a dark room}} for a controllable duration. The resulting image generated by this mixed digital/analogue technique has been coined [...] "laptopogram". While limited by the <b>image</b> <b>display</b> <b>device</b> resolution, which can be much inferior to film negatives, the widespread use of electronic displays provides great potential to this unorthodox contact printing method.|$|E
5000|$|Although {{the phase}} {{information}} in an image {{is generally not}} made available to a human observer of an <b>image</b> <b>display</b> <b>device,</b> it can be preserved numerically, and sometimes allows certain additional features of targets to be recognized. Unfortunately, the phase differences between adjacent image picture elements ("pixels") also produce random interference effects called [...] "coherence speckle", which {{is a sort of}} graininess with dimensions on the order of the resolution, causing the concept of resolution to take on a subtly different meaning. This effect is the same as is apparent both visually and photographically in laser-illuminated optical scenes. The scale of that random speckle structure is governed {{by the size of the}} synthetic aperture in wavelengths, and cannot be finer than the system's resolution. Speckle structure can be subdued at the expense of resolution.|$|E
40|$|Methods, systems, and {{techniques}} for an medical image-based information system are provided. The medical image-based information system comprises: a processing unit for providing medical image data and interactive functions for {{interacting with the}} medical image data; one or more <b>image</b> data <b>display</b> <b>devices</b> for <b>displaying</b> the medical <b>image</b> data provided by the processing unit; and a mobile multi-touch <b>display</b> <b>device.</b> The medical image-based information system is adapted to <b>display</b> the medical <b>image</b> data provided by the processing unit on an <b>image</b> data <b>display</b> <b>device</b> of {{the one or more}} <b>image</b> data <b>display</b> <b>devices</b> and to make the interactive functions provided by the processing unit available to a user via the mobile multi-touch <b>display</b> <b>device.</b> The medical image-based information system can be operated in a simple, flexible and space-saving manner via the mobile multi-touch <b>display</b> <b>device...</b>|$|R
50|$|The claim {{does not}} mention the bid entry devices, bid signals, {{telecommunication}} links, <b>image</b> signals. <b>display</b> <b>devices,</b> or the like, described in the preceding section.|$|R
40|$|This Report replaces IPEM Report 77 and {{provides}} essential guidance for anyone responsible for diagnostic X-Ray equipment. This document gives clear advice on which routine performance tests are essential {{and which are}} desirable, where to get {{information on how to}} do them, who should be doing them and how often they should be done. For many tests it also gives guidance as to when the results indicate further action should be taken. This second edition takes into account the introduction of new technologies in medical imaging including CR, DDR and <b>image</b> <b>display</b> <b>devices...</b>|$|R
40|$|The {{invention}} {{relates to}} {{a method for}} the computer-controlled display of speed information, which represents the movement speed of a real moving object relative to the surroundings of the object, using an <b>image</b> <b>display</b> <b>device.</b> The speed information is displayed by generating one or more visually perceptible moving graphical patterns using the <b>image</b> <b>display</b> <b>device,</b> wherein the movement speed of the real moving object is reproduced {{by one or more}} graphical patterns in a qualitative manner. The invention further relates to a device for the computer-controlled display of speed information, to a flying object with such a device, and to a computer program for this purpose...|$|E
40|$|An <b>image</b> <b>display</b> <b>device</b> {{includes}} an autostereoscopic screen for simultaneously displaying {{a plurality of}} different images which are visible from in each case {{at least one of}} different laterally offset viewing zones and a control unit for controlling the screen in dependence on image information of the different images, wherein the screen has a matrix screen with a plurality of pixels arranged in columns and rows as well as a grating arranged in front of the matrix screen and having a structure orientated parallel to the columns to direct light emanating from the pixels of the matrix screen into the different viewing zones. The <b>image</b> <b>display</b> <b>device</b> furthermore has a tracking device for detecting two respective eye positions of at least two viewers of the screen, wherein the control unit is configured for inputting input commands...|$|E
40|$|An <b>image</b> <b>display</b> <b>device</b> has {{a matrix}} screen having a {{plurality}} of pixels arranged in columns and a periodic grating arranged {{in front of the}} matrix screen having a structure extending parallel to the columns. A lateral direction grating period corresponds to a whole number multiple of adjacent column spacing of the matrix screen. In a use of this <b>image</b> <b>display</b> <b>device,</b> at least two different viewing positions are detected and disjunctive excerpts of columns of the matrix screen are determined in accordance with the detected viewing positions such that a respective excerpt is associated with each of the detected viewing positions, this excerpt including all columns at least partly visible through the grating from this viewing position, wherein the matrix screen is controlled in dependence with image information of at least two different images such that exactly one of the images is displayed on each of the excerpts...|$|E
40|$|Conventional <b>image</b> <b>display</b> <b>devices</b> and <b>image</b> {{acquisition}} devices {{consist of}} regularly located pixels. The pixels {{are located in}} a matrix for ease of implementation. Matrix placement of pixels intrinsically has directional singularity in the representation of images. The clarity of represented images is significantly dependent on the directions that objects in the image, such as lines, are facing. For example, horizontal lines are perfectly represented by matrix pixels, while the slanted lines have the jagged edges. We developed a pseudorandom pixel placement architecture that has no directional singularity in the representation of images, and we evaluated its characteristics and layout implementation...|$|R
40|$|We present {{techniques}} for combining high-performance computing with feedback {{to enable the}} correction of imperfections in the alignment, optical system, and fabrication of very high-resolution <b>display</b> <b>devices.</b> The key idea relies on the measurement of relative alignment, rotation, optical distortion, and intensity gradients of an aggregated set of low-cost <b>image</b> <b>display</b> <b>devices</b> using a precision low cost reference. Use of the reference allows {{the construction of a}} locally correct map relating the coordinate system of the aggregate display to the coordinate systems of the individual projectors composing the display. This idea provides a new technology for linearly scalable, bright, seamless, high-resolution large-scale self-calibrating displays (seamless video walls). Such a largescale display was constructed using the techniques described in this dissertation. Low-cost computation coupled with feedback is used to provide the precision necessary to create these displays. Digital photogr [...] ...|$|R
40|$|Self-illuminating {{displays}} comprising two-dimensional {{arrays of}} micro-emitters are superior over conventional backlight-illuminated liquid-crystal displays (LCD) in many aspects, including lower power consumptions, thinner profiles, higher image contrasts, wider viewing angles, and broader operating temperatures. There still are several technical challenges prevent self-illuminating organic light-emitting diodes (OLEDs) {{from becoming a}} dominant commercial product {{in the field of}} <b>image</b> <b>display</b> <b>devices,</b> such as limited lifespans, susceptibility to water damages and poor performance under high ambient lighting. In particular, blue OLEDs have lifetimes of only few thousand hours, which is much lower than those of LCDs or plasma displays. Self-illuminating displays based on III-nitride semiconductor materials are potentially an alternative solution, owing to their intrinsic advantages of stabilities, efficiencies and reliabilities [...] . postprin...|$|R
40|$|This paper {{describes}} a very light wearable display so light {{that you can}} forget that you are actually wearing it. It is a virtual <b>image</b> <b>display</b> <b>device</b> consists of a prism with two total internal reflection surfaces and a holographic optical element. The sophisticated display is only 3. 4 ram thick, weighs 25 grams, and has high transparency, providing comfort to wear all day long. Also, its size and weight is small enough {{to be put on}} cellular phones. Optical design and experimental results are described...|$|E
40|$|A {{technique}} is presented for discriminating different cloud types through an image subtraction of visible and infrared SMS/GOES picture pairs. The technique emphasizes how one could separate snow from clouds and identify cirrus by the subtraction method. Quantitative threshold values are shown {{which can be}} used in an objective manner to make this separation. Use is made of an all-digital <b>image</b> <b>display</b> <b>device</b> allowing such mathematical operations to be performed on satellite data. Techniques such as this can be made operational through the interfacing of the image analysis system with a direct-readout SMS/GOES ground station and distribution network...|$|E
40|$|Part 8 : Multimedia SecurityInternational audienceFace {{recognition}} technology, {{unlike other}} biometric methods, is conveniently accessible {{with the use}} of only a camera. Consequently, it has created an enormous interest in a variety of applications, including face identification, access control, security, surveillance, smart cards, law enforcement, human computer interaction. However, face recognition system is still not robust enough, especially in unconstrained environments, and recognition accuracy is still not acceptable. In this paper, to measure performance reliability of face recognition systems, we expand performance comparison test between real faces and face images from the recognition perspective and verify the adequacy of performance test methods using an <b>image</b> <b>display</b> <b>device...</b>|$|E
40|$|A photon {{accurate}} {{model of}} individual cones {{in the human}} eye perceiving <b>images</b> on digital <b>display</b> <b>devices</b> is presented. Playback of streams of pixel video data is modeled as individual photon emission events from within the physical substructure of each display pixel. The thus generated electromagnetic wavefronts are refracted through a four surface model of the human cornea and lens, and diffracted at the pupil. The position, size, shape, and orientation {{of each of the}} five million photoreceptor cones in the retina are individually modeled by a new synthetic retina model. Photon absorption events map the collapsing wavefront to photon detection events in a particular cone, resulting in images of the photon counts in the retinal cone array. The custom rendering systems used to generate sequences of these images takes a number of optical and physical properties of the image formation into account, including wavelength dependent absorption in the tissues of the eye, and the motion blur caused by slight movement of the eye during a frame of viewing. The creation of this new model {{is part of a larger}} framework for understanding how changes to computer graphics rendering algorithms and changes in <b>image</b> <b>display</b> <b>devices</b> are related to artifacts visible to human viewers...|$|R
30|$|Most of the 3 D key-frame {{extraction}} methods {{proposed in}} the literature until now {{are focused on the}} extraction rather than in the presentation of key-frame sets to the viewers. So far only Assa et al. and Lee et al. proposed in [17] and [25] two presentation solutions distinct from the static storyboard used in association with most of 3 D key-frame extraction methods [10, 18, 19, 22, 41, 51]. In this scenario, with only two presentation solutions, it is foreseeable that the development of new 3 D video and <b>image</b> <b>display</b> <b>devices</b> will lead to the creation of new methods to display 3 D video summaries or key-frame collages providing the user with more immersive and more meaningful ways to observe these types of time-condensed video representations.|$|R
40|$|In digital <b>image</b> <b>display</b> <b>devices,</b> {{data are}} {{typically}} presented via a spatial subsampling procedure implemented as a color filter array, a physical construction whereby each light emitting element controls the intensity level {{of only a}} single color. In this paper, we examine the problem of color filter array design with respect to spatial resolution and human vision; in doing so we quantify the fundamental limitations of existing designs by explicitly considering the spectral wavelength representation induced by the choice of array pattern, and propose a framework for designing and analyzing alternative patterns that minimize aliasing. An empirical evaluations on standard color test image confirms our theoretical results, and indicates the potential of these patterns to significantly increase spatial resolution {{while at the same}} time improving color image fidelity. Index Terms — <b>Displays,</b> color measurement, <b>image</b> sampling 1...|$|R
40|$|The {{geodetic}} {{accuracy of}} an MSS or TM scene is assessed using a minicomputer and appropriate software, a digitizer, and an <b>image</b> <b>display</b> <b>device.</b> The calculated image {{location of a}} selected feature is compared with the actual image location obtained though visual inspection of {{the image on the}} display. Measurements of 15 to 20 features evenly distributed throughout the image provide an estimate of the geodetic accuracy of the scene. Tests of two system-corrected MSS scenes measured geodetic registration root-mean-square (RMS) errors of approximately 3, 200 m or 57 pixels. Tests of two TM system-corrected scenes measured RMS errors of approximately 1, 250 and 1, 000 m, or 44 and 35 pixels, respectively. All errors were primarily translational, implying good internal scene registration of both MSS and TM data. The one MSS GCP-corrected scene which was evaluated had an RMS error of approximately 325 m or 6 pixels...|$|E
40|$|ABSTRACT: Our {{research}} team {{has developed a}} 2 D micro <b>image</b> <b>display</b> <b>device</b> that can potentially overcome the size reduction limits while maintaining the high-image resolution and field of view obtained by mirror-based display systems. The basic design of the optical scanner includes a microfabricated SU- 8 cantilever waveguide that is electromechanically deflected by a piezoelectric actuator. From the distal tip of the cantilever waveguide, a light beam is emitted and the direction of propagation is displaced along two orthogonal directions. The waveforms for the actuator and the LED light modulation are generated and controlled using a field programmable gate array. Our recent study is an update to the previously-reported mechan-ical scanner, replacing the hand-built PZT scanner and fiber waveguide with a microfabricated system incorporating aerosol-deposited PZT thin film and a polymeric SU- 8 wave guide. In this article, {{we report on the}} design and fabrication of a prototype miniaturized 2 D scanner, discuss optical and mechanical the modeling of the system’s properties and present the exper-imental results...|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 2015 In recent years, {{miniature}} scanner technologies, including {{micro-electro-mechanical system}} (MEMS) scanners, {{have started to}} appear on the market. Most miniature scanner technologies utilize MEMS scanner mirrors. However, this approach has many limitations. In the meanwhile, a competing technology called fiber optic resonant scanner (FORS) has also been developed in order to obtain forward image. An off-the-shelf piezoelectric actuator at the base to create transverse vibrations of a resonating optical fiber has shown to be an effective method for generating 1 D and 2 D laser line scans. We previously developed a 2 D micro <b>image</b> <b>display</b> <b>device</b> that utilized MEMS-based waveguide to replace the optical fiber, which can potentially overcome the size limitations of mirror-based display. In this research, an improved waveguide scanner system using a fully integrated MEMS-based push-pull actuator is presented. This prototype features monolithic integration of the waveguide, actuator, and light source, and removes the dependence on external actuators used by the previous design. The transmission efficiency is low and cantilever is slightly under tensile stress due to inherent imperfection in the process imperfection and tooling in fabrication. Nevertheless, 2 D light scanning pattern is successfully demonstrated using 1 D push-pull actuation...|$|E
40|$|Many <b>image</b> <b>display</b> <b>devices</b> allow only {{a limited}} number of colors to be {{simultaneously}} displayed. Usually, this set of available colors, called a color palette, may be selected by a user from a wide variety of available colors. Such device restrictions make it particularly difficult to <b>display</b> natural color <b>images</b> since these images usually contain a wide range of colors which must then be quantized by a palette with limited size. This color quantization problem is considered in two parts: the selection of an optimal color palette and the optimal mapping of each pixel of the image to a color from the palette. This paper develops algorithms for the design of hierarchical tree structured color palettes incorporating performance criteria which reflect subjective evaluations of image quality. Tree structured color palettes greatly reduce the computational requirements of the palette design and pixel mapping tasks, while allowing colors to be properly allocated to densely populated areas of [...] ...|$|R
40|$|The Image Reduction and Analysis Facility (IRAF) is {{a general}} purpose {{software}} system for the reduction and analysis of scientific data. The IRAF system provides a good selection of programs for general image processing and graphics applications, plus a large selection of programs for the reduction and analysis of optical astronomy data. The system also provides a complete modern scientific programming environment, making it straightforward for institutions using IRAF to add their own software to the system. Every effort {{has been made to}} make the system as portable and device independent as possible, so that the system may be used {{on a wide variety of}} host computers and operating systems with a wide variety of graphics and <b>image</b> <b>display</b> <b>devices.</b> 1. Introduction The IRAF project began in earnest in the fall of 1981 at Kitt Peak National Observatory (NOAO did not yet exist at that time). The preliminary design of the system was completed early in 1982, and the first versions of the comm [...] ...|$|R
40|$|This {{dissertation}} presents {{procedures for}} systematic and quantitative evaluations of {{both physical and}} psychophysical performance of <b>image</b> <b>display</b> <b>devices.</b> A mathematical expression for the visual luminance response function is derived, which permits developing an optimum display function for <b>display</b> <b>devices.</b> Direct quantitative relations between the physical and the psychophysical parameters are established. It is concluded that in {{the present state of}} modern CRTs, the spatial noise due to phosphor granularity offers the major limit to the contrast resolution, and that trying to decrease the spatial noise of a CRT is a more effective approach to increase the perceived dynamic range of the CRT among other considerations. A systematic procedure is developed to optimize the display function such that the contrast information transfer through the display device/human vision system is maximized. The presently derived result indicates that the optimum display function is the inverse of the scaled visual response function determined from the Just-Noticeable-Difference (JND) curve, and is independent of the object size and the noise level (RMS) of the <b>display</b> <b>device.</b> The optimum <b>display</b> function perceptually linearizes the <b>display</b> <b>device</b> in that equal changes in grey level produce changes in luminance that are perceptually equal throughout the entire dynamic range of the <b>display</b> <b>device.</b> This dissertation also presents a novel adaptive contrast enhancement algorithm, called JND-Guided Adaptive Contrast Enhancement (JGACE), to compensate for the limited contrast capability of <b>display</b> <b>devices</b> and {{to improve the quality of}} <b>image</b> <b>display.</b> Existing methods for image contrast enhancement focus entirely on the properties of the image to be processed without consideration of the human visual characteristics. The presented algorithm quantitatively achieves an adequate amount of contrast enhancement in terms of the human visual JNDs, and effectively eliminates two common drawbacks of many existing contrast enhancement techniques: ringing artifacts around sharp edges and enhancement of background noise. JGACE can be applied to a variety of images and provides a superior performance compared to previously available techniques. In particular, it offers considerable benefits in digital radiography applications where the objective is to increase the diagnostic utility of images...|$|R
40|$|The {{design is}} given of an {{interactive}} image database system IMDB, {{which allows the}} user to create, retrieve, store, <b>display,</b> and manipulate <b>images</b> through the facility of a high-level, interactive image query (IQ) language. The query language IQ permits the user to define false color functions, pixel value transformations, overlay functions, zoom functions, and windows. The user manipulates the images through generic functions. The user can direct <b>images</b> to <b>display</b> <b>devices</b> for visual and qualitative analysis. Image histograms and pixel value distributions can also be computed to obtain a quantitative analysis of images...|$|R
40|$|This paper {{investigates the}} {{presentation}} of moving stereo <b>images</b> on different <b>display</b> <b>devices.</b> We address three important issues. First, we propose temporal compensation for the Pulfrich effect when using anaglyph glasses. Second, we describe, how content-adaptive capture protocols can reduce false motion-in-depth sensation for time-multiplexing based displays. Third, we conclude with a recommendation how to improve rendering of synthetic stereo animations...|$|R
40|$|With {{interest}} in {{high dynamic range}} imaging mounting, techniques for <b>displaying</b> such <b>images</b> on conventional <b>display</b> <b>devices</b> are gaining in importance. Conversely, high dynamic range display hardware is creating the need for display algorithms that prepare <b>images</b> for such <b>displays.</b> In this paper, the current state-of-the-art in dynamic range reduction and expansion is reviewed, and in particular we assess the theoretical and practical need to structure tone reproduction as {{a combination of a}} forward and a reverse pass. ...|$|R
40|$|Abstract 1 Many <b>image</b> <b>display</b> <b>devices</b> allow only {{a limited}} number of colors to be {{simultaneously}} displayed. Usually, this set of available colors, called a color palette, may be selected by a user from a wide variety of available colors. Such device restrictions make it particularly dicult to <b>display</b> natural color <b>images</b> since these images usually contain a wide range of colors which must then be quantized by a palette with limited size. This color quantization problem is considered in two parts: the selection of an optimal color palette and the optimal mapping of each pixel of the image to a color from the palette. This paper develops algorithms for the design of hierarchical tree structured color palettes incor-porating performance criteria which reflect subjective evaluations of image quality. Tree structured color palettes greatly reduce the computational requirements of the palette design and pixel map-ping tasks, while allowing colors to be properly allocated to densely populated areas of the color space. The algorithms produce higher quality <b>displayed</b> <b>images</b> and require less computations than previously proposed methods. Error diusion techniques are commonly used for <b>displaying</b> <b>images</b> which have been quantized to very few levels. This paper studies problems related to the application of error diusion tech-niques to the <b>display</b> of color <b>images.</b> A modied error diusion technique is proposed for resolving these problems. The new error diusion techinque is shown to be easily implemented using the tree structured color palettes developed earlier...|$|R
40|$|The {{increase}} in the interaction between man and machine has made <b>display</b> <b>devices</b> indispensable for visual communication. The informa-tion {{which is to be}} communicated from a machine can be often in the form of color <b>images.</b> Electrochromic <b>display</b> <b>device</b> (ECD) {{is one of the most}} powerful candidate for this purpose and has various merits such as multicolor, high contrast, optical memory, and no visual dependence on viewing angle. A large number of electrochromic materials are available from almost all branches of synthetic chemistry. In this review, we have tried to describe the fundamentals of such electrochromic materials and their use in EDDs. The most important examples from major classes of electrochromic materials namely transition metal oxides, Prussian blue, phthalocyanines, viologens, fullerenes, dyes and con-ducting polymers (including gels) are described. Examples of their use in both prototype and commercial electrochromic devices are given...|$|R
40|$|DE 1004009367 A UPAB: 20050527 NOVELTY - The device has an {{ultrasonic}} head (2) for connection via a connecting arrangement to an ultrasonic {{device that}} drives the head to emit ultrasonic waves and converts the ultrasonic signals generated by the head into image signals that can be displayed on a portable <b>display</b> <b>device</b> (6) for connection to {{the head by a}} reversible firm connection so that the <b>display</b> <b>device</b> and the head form an operating unit. USE - For local representation of ultrasonic images. ADVANTAGE - Enables a physician to detect the spatial relationship between an ultrasonic <b>image</b> on a <b>display</b> <b>device</b> and the actual spatial position of the ultrasonic head in one view...|$|R
25|$|One of the {{original}} goals of tone mapping was {{to be able to}} reproduce a given scene or <b>image</b> onto a <b>display</b> <b>device</b> such that the brightness sensation of the image to a human viewer closely matches the real-world brightness sensation. However, a perfect match for this problem is never possible and thus the output <b>image</b> on a <b>display</b> is often built from a tradeoff between different image features. Choosing between features is often based on the necessary application, and given appropriate metrics for the application, one possible solution is to treat the issue as an optimization problem.|$|R
40|$|Conference paperTo {{bridge the}} {{mismatch}} between {{the sizes of}} <b>images</b> and <b>display</b> <b>devices,</b> we present an efficient and automatic algorithm to create an adaptive image representation called SmartNail. Given a digital <b>image</b> and rectangular <b>display</b> frame smaller than the image, we define the SmartNail as an appropriately cropped part of a suitably scaled-down image. We choose the SmartNail-defining parameters - down-scaling factor and cropping location - to maximize a bit-allocation-based cost function that quantifies the visual importance of the image content in the SmartNail. For JPEG 2000 -encoded images, the SmartNail parameters can be determined using just the header information available in the encoded file. Hence only the wavelet coefficients required to reconstruct the SmartNail need to be decoded from the entire JPEG 2000 code stream. Consequently, the SmartNail construction requires minimal computations and memory requirements. Simulations demonstrate the effectiveness of SmartNail representations...|$|R
40|$|We {{present a}} new dynamic range {{compression}} method for {{the reproduction of}} high dynamic range digital <b>images</b> on conventional <b>display</b> <b>devices.</b> The proposed technique is computationally efﬁcient and easily adjustable with few parameters. Novel contributions of this work include an edge preserving smoother for the extraction of the visual adaptation level which avoids the formation of halo artifacts in the resulting image and a technique for contrast mapping which improves the visibility of the image details. The algorithm is ﬁnally evaluated {{by means of an}} objective measure proving its effectiveness...|$|R
40|$|Restricted AccessIn one embodiment, {{a method}} {{a method of}} <b>displaying</b> an <b>image</b> on a <b>display</b> <b>device</b> is described. The <b>display</b> <b>device</b> {{includes}} a plurality of clusters. Each cluster has a plurality of pixels and an independent light source associated therewith. Each of the plurality of clusters are illuminated with their associated independent light source. The plurality of pixels in a cluster are refreshed with bits of gray scale. Simultaneously with the refreshing, the light source associated with the cluster where the plurality of pixels are being refreshed is switched off. When the plurality of pixels have been refreshed, the light source is switched on with a predetermined intensity of light. Each of the clusters are refreshed {{at a rate that}} is fast enough to eliminate flicker...|$|R
50|$|Color {{quantization}} {{reduces the}} number of colors used in an image; this is important for <b>displaying</b> <b>images</b> on <b>devices</b> that support {{a limited number of}} colors and for efficiently compressing certain kinds of images. Most bitmap editors and many operating systems have built-in support for color quantization. Popular modern color quantization algorithms include the nearest color algorithm (for fixed palettes), the median cut algorithm, and an algorithm based on octrees.|$|R
40|$|This paper {{deals with}} the {{extension}} of information theory to the assessment of visual communication from scene to observer. The mathematical development rigorously unites the electro-optical design of <b>image</b> gathering and <b>display</b> <b>devices</b> with the digital processing algorithms for image coding and restoration. Results show that: ffl End-to-end system analysis closely correlates with measurable and perceptual performance characteristics, such as data rate and image quality, respectively. ffl The goal of producing the best possible image at the lowest data rate can be realized only if (a) the electro-optical design of the image-gathering device is optimized for the maximum-realizable information rate and (b) the image-restoration algorithm properly accounts for the perturbations in the visual communication channel. 1. INTRODUCTION Modern visual communication channels increasingly combine <b>image</b> gathering and <b>display</b> with digital <b>image</b> coding and restoration (Fig. 1). So far, however, the [...] ...|$|R
