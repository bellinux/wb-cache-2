5|20|Public
40|$|AbstractThis {{paper is}} devoted to characterizing the Riemann–Stieltjes {{operators}} and pointwise multipliers acting on Möbius invariant spaces Qp, which unify BMOA and Bloch space in the scale of p. The boundedness and compactness of these operators on Qp spaces are determined {{by means of an}} embedding theorem, i. <b>e.</b> <b>Qp</b> spaces boundedly embedded in the non-isotropic tent type spaces Tq∞...|$|E
40|$|Abstract:- Popular H. 26 L video coding {{standard}} employ UVLC {{as one of}} its entropy coding technique, since it provides an easy way to encode all syntax elements in a regular form. However, the disadvantage of the UVLC is that it failed to conform the symbol probability distribution to get the best coding result, specially with small quantization parameter (i. <b>e.</b> <b>QP)</b> values. We propose a navel approach with Probability Distribution Matching (PDM) which has advantage of obtaining the configuration for encoder and decoder in the same way without having any overhead information. More over, PDM is used to choose the most suitable configuration from a predetermined configuration table according to already encoded symbol probability distribution. Experimental results convince that the use of PDM for UVLC is a convenient method to adjust the configuration. Thus, the proposed method is beneficial for almost most of the configurable Variable Length video coding applications...|$|E
40|$|For m,n ∈N, m≥ 1 and a given {{function}} f : R^m⟶R the polynomial interpolation problem (PIP) is {{to determine}} a generic node set P ⊆R^m and the coefficients of the uniquely defined polynomial Q∈R[x_ 1, [...] .,x_m] in m variables of degree deg(Q) ≤ n ∈N that fits f on P, i. <b>e.,</b> <b>Q(p)</b> = f(p), ∀ p ∈ P. We here show that in general, i. e., for arbitrary m,n ∈N, m ≥ 1, there exists an algorithm that determines P and computes the N(m,n) =#P coefficients of Q in O(N(m,n) ^ 2) time using O(mN(m,n)) storage, without inverting the occurring Vandermonde matrix. We provide such an algorithm, termed PIP-SOLVER, based on a recursive decomposition {{of the problem and}} prove its correctness. Since the present approach solves the PIP without matrix inversion, it is computationally more efficient and numerically more robust than previous approaches. We demonstrate this in numerical experiments and compare with previous approaches based on matrix inversion and linear systems solving...|$|E
40|$|The aim of {{this note}} is to {{describe}} how the “fudge factors ” in the Birch and Swinnerton-Dyer conjecture vary {{in a family of}} quadratic twists (see Proposi-tion 5, which follows directly from Tate’s algorithm [T]). We illustrate with two examples. Definition 1. If E is an elliptic curve over Q and p is a prime, the fudge factor (or Tamagawa factor) cp(E) is defined by cp(E) = [E(Qp) : <b>E</b> 0 (<b>Qp)</b> ] where <b>E</b> 0 (<b>Qp)</b> is the subgroup of E(Qp) consisting of those points whose re-duction modulo p (on a minimal model of E) is nonsingular. The fundamental method for computing the fudge factors is Tate’s al-gorithm. This algorithm, originally described in a 1965 letter to Cassels, was published in [T] and essentially reproduced in §IV. 9 of [S]. Stan-dard number theoretic computer packages, such as PARI/GP (available a...|$|R
40|$|We {{demonstrate}} that for two canonically conjugate operators q̂,p̂,the global correlation 〈q̂p̂ + p̂q̂〉 - 2 〈q̂〉〈p̂〉, {{and the local}} correlations 〈q̂〉 (p) - 〈q̂〉 and 〈p̂〉 (q) -〈p̂〉 can be measured exactly by Von Neumann-Arthurs-Kelly joint quadrature measurements. These correlations provide a sensitive experimental test of quantum phase space probabilities quite distinct from the probability densities of <b>q,p.</b> <b>E.</b> g. for EPR states, and entangled generalized coherent states, phase space probabilities which reproduce the correct position and momentum probability densities have to be modified to reproduce these correlations as well. Comment: 5 pages, 1 figur...|$|R
40|$|We present Quantum-Monte-Carlo {{results for}} the {{momentum}} and frequency dependent spectral weight A(~ k; !) showing the evolution from insulating to metallic behavior in the two-dimensional Hubbard model. As observed in recent photoemission experiments for cuprates, in both undoped and doped cases the electronic excitations display two rather similar general features, i. <b>e.</b> a quasiparticle (<b>QP)</b> -like dispersive band of small width {{of the order of}} the exchange interaction J and a broad valence- and conduction-band background. Arguments for one and the same manybody physics namely the continuous reduction of the spin-spin correlation length and related changes in the QP-spin correlations behind the continuous evolution to the metallic QP dispersion are given...|$|R
40|$|Hilton [3] and Fielder [1] have {{presented}} formulas {{for the number}} of spanning trees of a labelled wheel or fan in terms of Fibonacci and Lucas numbers. Each of them has also counted thejiumber of spanning trees in one of these graphs which contain a specified edge. The purpose of this note is to generalize some of their results. The graph theory terminology used will be consistent with that in [2], Fk denotes the k th Fibonacci number, and Lk denotes the k f Lucas number. All graphs will be connected, and ST(G) will denote the number of spanning trees of labelled graph, or multigraph, G. A fan on k vertices, denoted N^, is the graph obtained from path Pk-i = 2, 3, •••, k by making vertex 1 adja— cent to every vertex oiPk [...] /. The wheel on k vertices, denoted W^, is obtained by adding edge (2,k) to/l/^. That is, Wk = Nk + (2,k). Aplanar qraph G is one that can be drawn in the plane so that no two edges intersect; G is outerplanar if it can be drawn in the plane so that no two edges intersect, and all its vertices lie on the same face; and a maximal outerplanar graph G is an outerplanar graph for which G + (u,v) is not outerplanar for any pair^/, 1 / of vertices of G such that edge (u,v) is not already in G. For example, each fan is a maximal outerplanar graph because, as will be used in the proof of Proposition 1, an outerplanar graph on k vertices is maximal outerplanar if and only if it has 2 k- 3 edges. Figure 1 Three Graphs on Six Vertices As shown in Hilton [3],ST(Nf<) = F 2 k- 2 a n d ST(Wk) = L. 2 k- 2 - 2 - Let OP J k denote the set of maximal outerplanar graphs with k vertices, of which exactly / are of degree two. Note that/I/ ^ <b>e</b> <b>QP...</b>|$|E
40|$|The Sacramento-San Joaquin River Delta in California becomes {{inadequate}} {{in fresh}} water resources, while the water demand in California keeps increasing. Large-scale numerical flow models, for example Delta Simulation Model II (DSM 2) and River, Estuary, And Land Model (REALM), used as crucial {{water resources management}} tools, are capable of providing critical information about tidal forcing and salinity transport in the bays and channels of the Delta. Reliable flow estimation and prediction of these models, however, largely depend on an accurate representation of open boundary conditions and initial conditions, which are usually calibrated against historical data sets acquired from Eulerian measurements near the boundaries. In large watershed, unfortunately, these measurements have demonstrated many intrinsic limitations, for example small spatial coverage and sparse temporal sampling. Also, existing Eulerian sensors have many recorded failures, such as broken gauges, sensor drifts, process leaks, improper measuring devices, and many other random sources. More importantly, if the hydraulic system is radically altered, {{as in the case}} of extensive levee failures, the historical data sets can be of limited usage. In this dissertation, a sensing-modeling system featuring rapidly deployed Lagrangian drifters is developed. The system is capable of predicting regional flows and transport in the Delta in a real-time mode, without dependence on historical data. Lagrangian data is obtained when floating drifters move along with the flow and report their locations. The data provides instant information about the flow, including flow advections and eddy dispersions, and is further assimilated into underlying shallow water equation (SWE) models to characterize the flow state. Different approaches to facilitate the flow estimation have been investigated in this dissertation. First, a variational assimilation method (Quadratic Programming) is applied to a 1 D SWE model (Linearized Saint-Venant equations). The assimilation method poses the problem of estimating the flow state in a channel network as a quadratic programming by minimizing a quadratic cost function [...] the norm of the difference between the drifter observations and the model velocity predictions [...] and expressing the constraints in terms of linearized equalities and inequalities. The problem is then efficiently solved using a fast and robust algorithm. The approach is easy to implement and low in computation costs. Later, a sequential assimilation method (Ensemble Kalman Filtering) is implemented to a 2 D SWE model (depth-integrated Navier-Stokes equations). The assimilation method involves a series of state analysis and updates, where the observed Lagrangian data is incorporated into the state one step at a time to incrementally correct the model prediction. The implementation of this method demands powerful computation ability, and is achieved on high-performance computing clusters at NERSC. To assess the performance of the proposed data assimilation methods, we investigated a distributed network of channels, subject to quasi-periodic tidal forcing, in the Sacramento-San Joaquin River Delta. Field operational experiments were carried out with a fleet of over 70 floating drifters, deployed within approximately 0. 55 km 2 of the river network. During the experiments, more than 325, 000 GPS readings were taken from the floating drifters and collected, in real time, onto a central server. It is the first experiment of this kind conducted at such scale, where high-density Lagrangian data have been collected in a real river environment and successfully assimilated over a full tidal cycle. It is demonstrated that both of the proposed assimilation methods (i. <b>e.,</b> <b>QP</b> in 1 D SWE model and EnKF in 2 D SWE model) can handle the Lagrangian data with sufficiently accurate estimations. In many practical cases, the 1 D flow estimation is adequate for water resource management to retrieve critical flow characteristics in a prompt and efficient manner. In the case of complex channel geometry, however, the 2 D flow estimation is vital to describe the hydraulic system...|$|E
40|$|Let E be a cyclic {{algebraic}} number field of a prime degree. We prove an identity which lifts an exponential sum {{similar to the}} Kloosterman sum to an exponential sum taken over certain algebraic integers in E. 1. Introduction. Based on the relative trace formula for GL(2) (Ye [13] and Jacquet and Ye [8]) and inspired by early work of Zagier [15], Ye [14] established a lifting identity of Kloosterman sums. Let <b>E</b> = <b>Q(p</b> ø) be a quadratic field with a square-free integer ø, and let c be a positive odd integer with (c; ø) = 1. Assume that for any prime factor p of c we have i ø p j = Γ 1. Then for any nonzero integers m and n with (m; c) = (n; c) = 1 we have X 1 xc; (x;c) = 1 e 2 ßi(xm+¯xn) =c = (Γ 1) c) X 1 ac; 1 bc; a 2 b 2 jmn(mod c) e 4 ßia=c (1) where ¯ x is the inverse of x modulo c. HereΩΓ c) {{is the number of}} prime factors of c counting multiplicity. Note that the exponential sum {{on the right side of}} (1) is actually a sum taken over so [...] ...|$|R
40|$|Symmetry is the {{essential}} element of lifted inference that has recently demon- strated the possibility to perform very efficient inference in highly-connected, but symmetric probabilistic models models. This raises the question, whether this holds for optimisation problems in general. Here we show that for a large class of optimisation methods this is actually the case. More precisely, we introduce the concept of fractional symmetries of convex quadratic programs (QPs), which {{lie at the heart}} of many machine learning approaches, and exploit it to lift, i. <b>e.,</b> to compress <b>QPs.</b> These lifted QPs can then be tackled with the usual optimization toolbox (off-the-shelf solvers, cutting plane algorithms, stochastic gradients etc.). If the original QP exhibits symmetry, then the lifted one will generally be more compact, and hence their optimization is likely to be more efficient...|$|R
40|$|Abstract. Let (QP) be a mixed integer {{quadratic}} {{program that}} consists of minimizing a quadratic function subject to linear constraints. In this paper, we present a convex reformulation of (<b>QP),</b> i. <b>e.</b> we reformulate (<b>QP)</b> into an equivalent program, with a convex objective function. Such a reformulation can be solved by a standard solver that uses a branch and bound algorithm. This reformulation, that we call MIQCR (Mixed Integer Quadratic Convex Reformulation), is the best one within a convex reformulation scheme, from the continuous relaxation point of view. It {{is based on the}} solution of an SDP relaxation of (QP). Computational experiences were carried out with instances of (QP) with one equality constraint. The results show that most of the considered instances, with up to 60 variables, can be solved within 1 hour of CPU time by a standard solver...|$|R
40|$|In this paper, {{we propose}} power {{efficient}} motion estimation (ME) us-ing multiple imprecise sum absolute difference (SAD) metric com-putations. We extend recent work in [18] by providing analytical solutions based on modelling of computation errors due to voltage over scaling (VOS) and sub-sampling (SS). Results show that our so-lutions provide significantly better {{performance in the}} sense of rate increase for fixed <b>QP,</b> <b>e.</b> g., less than 5 % increase, while in [18] the rate increase could be as high as 20 %. Our analysis also allows us to compare different ME algorithms (e. g., full search vs. a fast al-gorithm) and SAD computation architectures (parallel vs. serial) in terms of their robustness to imprecise metric computations and their power efficiency. Finally, we demonstrate that additional power sav-ings can be achieved by removing redundancy between the various computations. Index Terms — voltage over scaling (VOS), error tolerance (ET), matching metric computation (MMC), imprecise computation 1...|$|R
40|$|In this paper, we {{investigate}} {{the consequences of}} using outcome-based versus ex ante-based cost-sharing mechanisms in terms of competing firms' profitability and total welfare. We consider two firms making a joint expenditure, which can positively affect firms' demand and/or unit operating costs, while competing in the final market by setting either price or quantity. We compare two outcome-based cost-sharing mechanisms, i. <b>e.,</b> Quantity Proportional (<b>QP)</b> and Total Margin proportional (TM), with the more competitive Fixed Share (FS) mechanism where cost-sharing is set up on an ex ante basis. We show that outcome-based mechanisms, and even a fully collusive behavior induced by the optimal cost-sharing mechanism, might actually enhance total welfare {{as compared with the}} more competitive FS mechanism. We also find that, although the FS mechanism is never more preferable than the TM mechanism, it can lead to higher profits than the QP mechanism when competition is mild. These results can support firms cooperating with competitors in the choice of the cost-sharing mechanism as well as provide important implications to policy makers...|$|R
40|$|In this paper, {{we propose}} an optimal {{strategy}} for the transmission of scalable video over packet-based multiple-input multiple-output (MIMO) systems. The scalable extension of H. 264 /AVC that provides a combined temporal, quality and spatial scalability is used. For given channel conditions, we develop a method for the estimation of the distortion of the received video and propose different error concealment schemes. We show the accuracy of our distortion estimation algorithm in comparison with simulated wireless video transmission with packet errors. In the proposed MIMO system, we employ orthogonal space-time block codes (O-STBC) that guarantee independent transmission of different symbols within the block code. In the proposed constrained bandwidth allocation framework, we use the estimated end-to-end decoder distortion to optimally select the application layer parameters, i. <b>e.,</b> quantization parameter (<b>QP)</b> and group of pictures (GOP) size, and physical layer parameters, i. e., rate-compatible turbo (RCPT) code rate and symbol constellation. Results show the substantial performance gain by using different symbol constellations across the scalable layers as compared to a fixed constellatio...|$|R
40|$|The Scope of quantificational phrases (QPs) {{is often}} not {{represented}} in surface structures, {{in the sense that}} a constituent that is, on the surface, sister to a QP is not necessarily interpreted as its argument semantically. QPs can take wider or narrower scope than their surface position (Scope Widening and Scope Narrowing). Based on the fact that when an elided constituent contains a variable that takes part in a particular type of binding dependency, the biggest deletable constituent must be elided, Chapter 2 argues that the presence of this maximization effect in the context of Scope Widening is straightforwardly explained by syntactic approaches, in which QPs undergo movement to widen their scope, rather than by semantic approaches, which adopt type shifting rules to deal with Scope Widening. Chapter 3 defends the copy theory of movement, which captures the effects of Scope Narrowing in a simple way, by developing a new theory of the counter-cyclic merger, which accounts for the facts that seem challenging to this theory. Those facts have been taken to indicate that movement sometimes leaves a trace. I propose that restrictors of determiners can merge with them counter-cyclically. Copies of determiners without their restrictors turn into syntactic objects that receive the same interpretation as that assigned to a trace. (cont.) This is done by the independently motivated procedure that converts movement chains into interpretable objects. Chapter 3 demonstrates that together with other properties of grammar, this approach explains the challenging facts, and yet is compatible with the copy theory. Chapter 4 investigates the nature of the scope assignment mechanism by examining the fact that the scopal possibilities of comparative <b>QPs</b> (<b>e.</b> g., more than three books) are more restricted than other QPs. It demonstrates that this fact is captured by the interplay of the decompositional approach, in which comparative QPs are decomposed into two <b>QPs</b> (<b>e.</b> g., -er than three and many books), and independently motivated constraints on the scope assignment (e. g., locality and Scope Economy in Fox 2000). Thus, their peculiar scopal behavior can be taken as additional evidence for the core properties of the scope assignment mechanism. by Shoichi Takahashi. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Linguistics and Philosophy, 2006. Includes bibliographical references (p. 198 - 210) ...|$|R
40|$|We propose an {{efficient}} {{strategy for the}} transmission of scalable video over multiple-input multiple-output (MIMO) wireless systems. In this paper, we use the latest scalable H. 264 codec (SVC), which provides combined temporal, quality and spatial scalability. At the transmitter, we estimate the decoded video distortion for given channel conditions {{taking into account the}} effects of quantization, packet loss and error concealment. The proposed scalable decoder distortion algorithm offers low delay and low complexity. The performance of this method is validated using experimental results. In our proposed system, we use a MIMO system with orthogonal space-time block codes (O-STBC) that provides spatial diversity and guarantees independent transmission of different symbols within the block code. The bandwidth constrained allocation problem considered here is simplified and solved for one O-STBC symbol at a time. Furthermore, we take the advantage of the hierarchical structure of SVC to attain the optimal solution for each group of pictures (GOP) of the video sequence. We incorporate the estimated decoder distortion to optimally select the application layer parameter, i. <b>e.,</b> quantization parameter (<b>QP),</b> and physical layer parameters, i. e., channel coding rate and modulation type for wireless video transmissio...|$|R
40|$|Quando tomamos o valor absoluto usual e o completamento de Q em relação à métrica induzida por ele, o resultado é o corpo IR dos números reais; fazendo o mesmo processo com qualquer outro valor absoluto definido em Q, obtemos um dos corpos p-ádicos QP. O propósito deste trabalho é explorar a convergência de séries em <b>QP</b> <b>e</b> em IR, construindo algumas séries de números racionais com propriedades de convergência surpreendentes. Provamos também que é possível construir uma série de números racionais que {{converge}} em qualquer completamento de Q para um valor pré-fixado de Q e de R. When {{we consider}} the completion of Q {{with respect to the}} usual absolute value we obtain the field of the real numbers R But if we do the same with respect to any other absolute value of Q we obtain the field of the p -adie numbers QP, where p is a prime. In this work {{we consider the}} convergence of series in QP and in lR and construct series of racional numbers with amazing convergence properties. We also prove {{that it is possible to}} obtain a series of rational numbers that converges in all completions of Q even if we prescribe its sum in each completion...|$|R
40|$|The {{study of}} {{chlorophyll}} fluorescence (CF) parameters i. e. : Fo, Fm, Fv/Fm, Y, qP, qN, Fo, F {{was conducted in}} two strawberry cultivars Honeoye and Teresa. Measurements of their values were done twice: in an early autumn and late spring. Fluorescence of five dark-adapted mature leaves derived from each cultivar was measured in the laboratory at room temperature {{with the use of}} a portable pulse amplitude modulation (PAM) fluorometer in 15. replicates for each parameter. Statistical analysis of the obtained results showed significant differences between values of CF parameters in both cultivars. Mean values of CF, excluding Fo and F were significantly higher in cv. Teresa when compared with cv. Honeoye. In both cultivars, the values of Fo, Fo, Fm, F were significantly higher in the spring measurements. In cv. eresathe CF parameters i. <b>e.</b> Fv/Fm, Y, <b>qP</b> and qN achieved the higher values in the autumnal measurement, but in cv. Honeoyevalues of these parameters except Y, were significantly higher in the spring. In the conclusion, it could be emphasized, that cv. Teresa distinguished a more efficient photosynthetic apparatus than cv. oneoyeand the significant differences observed between the autumnal and spring CF values in the analyzed cultivars revealed the different, dependent on the genotype, response in the functioning of this apparatus to the various environmental conditions characterizing both seasons of the year...|$|R
40|$|Abstract—Algorithms are {{presented}} for fully automatic three-dimensional (3 -D) tracing of neurons that are imaged by fluorescence confocal microscopy. Unlike previous voxel-based skeletonization methods, the present approach works by recur-sively following the neuronal topology, using {{a set of}} R directional kernels (<b>e.</b> g., a <b>QP),</b> guided by a generalized 3 -D cylinder model. This method extends our prior work on exploratory tracing of retinal vasculature to 3 -D space. Since the centerlines are of primary interest, the 3 -D extension {{can be accomplished by}} four rather than six sets of kernels. Additional modifications, such as dynamic adaptation of the correlation kernels, and adaptive step size estimation, were introduced for achieving robustness to photon noise, varying contrast, and apparent discontinuity and/or hollowness of structures. The end product is a labeling of all somas present, graph-theoretic representations of all dendritic/axonal structures, and image statistics such as soma volume and centroid, soma interconnectivity, the longest branch, and lengths of all graph branches originating from a soma. This method is able to work directly with unprocessed confocal images, without expensive deconvolution or other preprocessing. It is much faster that skeletonization, typically consuming less than a minute to trace a 70 -MB image on a 500 -MHz computer. These properties make it attractive for large-scale automated tissue studies that require rapid on-line image analysis, such as high-throughput neurobiology/angiogenesis assays, and initiatives such as the Human Brain Project. Index Terms—Aotomated morphometry, micrograph analysis, neuron tracint, three-dimensional (3 -D) image filtering, three-dimensional (3 -D) vectorization. I...|$|R
40|$|This thesis aims {{to develop}} and {{implement}} both nonlinear and linear distributed optimization methods that are applicable, but not restricted to the optimal control of distributed systems. Such systems are typically large scale, thus the well-established centralized solution strategies may be computationally overly expensive or impossible and the application of alternative control algorithms becomes necessary. Moreover, it is often desired that the information on the coupled subsystems inner dynamics is kept local, making the deployment of a centralized optimal control scheme impossible in practice. In such a case, optimization approaches based on some limited exchange of information remain the only possible option. In {{the first part of this}} thesis, we consider nonlinear optimal control problems with distributed structure, for which we design an efficient distributed shooting method resulting in up to 19 times faster integration time when compared to the conventional approaches. The first part reports the testing of the proposed method on two different dynamic optimization problems. The second part of this thesis investigates linear optimal control problems with quadratic cost functions, i. <b>e.</b> quadratic programs (<b>QP).</b> An overview of dual decomposition based approaches is given, followed by the development of a novel dual decomposition scheme. The proposed method employs second-order derivatives. Experimental results suggest that it requires up to 152 times less local optimization steps than classical first-order schemes. Furthermore, as a part of this thesis, an open-source QP solver (PyDQP) with 11 different dual decomposition based methods is implemented. A set of large scale distributed quadratic programs is set up and released for benchmarking purposes. nrpages: 176 status: publishe...|$|R
40|$|AbstractIn {{relation}} to technological development in all branches of industry, {{the requirements for}} properties of structural materials and for their various combinations are constantly increasing. For instance, the types of advanced materials are sought which would have low procurement costs and high ultimate tensile strength and yield strength while retaining sufficient levels of elongation and toughness. Normally, ductility of materials declines with increasing strength. In some types of steels, special heat treatment {{can be used to}} achieve excellent combination of strength, elongation and toughness when compared to conventional treatment processes. One of such advanced heat treatment techniques is the Q-P (Quenching and Partitioning) process. It consists in austenitizing and rapid quenching of the steel between Ms and Mf temperatures to prevent the martensitic transformation from propagating through the entire volume of the workpiece. The subsequent heating causes tempering of martensite and diffusion of excess carbon from martensite to retained austenite, thereby increasing the stability of the austenite. The aim of the QP process is to produce very fine martensite micro structure with retained austenite between martensite plates. The experiment was performed on high-strength low-alloyed steel containing 0. 2 % carbon and a higher amount of silicon about 1. 5 %. Higher silicon content contributes to stabilization of retained austenite by suppressing formation of carbides. This grade of steel is a very cost-effective material thanks to its low amount of alloying elements. The entire group of these low-alloyed steels, if heat treated or thermomechanically treated in a suitable manner, offers a favourable combination of strength, elongation and toughness. Thanks to these properties and a low content of alloying elements (i. <b>e.</b> low price), <b>QP</b> steels are used primarily in the automotive industry. The present paper deals with the relationship between parameters of the Q-P process, the austenitizing temperature, the partial quenching temperature and the tempering temperature, mechanical properties and resulting micro structure of the CMnSiMo experimental steel...|$|R
40|$|Engineered {{mammalian}} (CHO, NS 0 and SP 2 / 0) {{cells are}} commonly used for large-scale production of recombinant therapeutic antibodies. Increased antibody production in these commercial manufacturing systems is often achieved through systematic empirical optimisation of culture environment and improved expression vectors. To date, our a priori knowledge of the molecular mechanisms of antibody manufacture in these expression systems is very limited. As a result, genetic engineering of mammalian host cells to improve product yields have often produced mixed results, further indicating {{the need for a}} more exploratory approach to understanding glycoprotein production. Identification of coordinated changes specifically related to one particular phenotype (i. <b>e.</b> cell-specific productivity; <b>qP)</b> at a clonal level will improve our understanding of the rate limiting steps or intracellular processes related to that phenotype. Using quantitative two-dimensional polyacrylamide gel electrophoresis, differences in the host cell proteome were assessed between murine myeloma NS 0 cells producing a recombinant monoclonal antibody at varying cell-specific production rates. Furthermore the variation in synthesis and abundance of these proteins were evaluated during fed-batch culture. Conserved and coordinated changes in specific proteins known to interact with antibody folding and assembly were identified, as were changes in the intracellular abundance of recombinant heavy and light chain polypeptides. Conserved changes in the abundance of proteins as functional categories (chaperones, metabolic and mitochondrial, cytoskeletal and cell signaling) also demonstrated correlation with enhanced cell-specific productivity between clonal cell lines. However, variation in the synthesis and abundance of these proteins (individually and in categories) during a fed-batch process did not demonstrate the same coordinated changes with qP observed between clonal cell lines. In conclusion these data suggest that cell performance in production processes is de- fined primarily by the basal phenotype selected after transfection. Bioprocess manipulations modulate management of host cellular processes altering metabolism and recombinant gene transcription or translation, but only {{within the confines of the}} host cell machinery selected post-transfection. Pre-screening of cells prior to selection for coordinated changes associated with improved qP will reduce the variation in transfected cell phenotypes, reducing the time to select cells with good performance characteristics...|$|R
40|$|The {{purpose of}} this thesis {{is to show that}} despite their {{superficial}} differences, languages are the same at a deeper level. The languages we deal with in the thesis are Korean, Japanese, and English, but the conclusions we draw from them are not limited to them. For this purpose, we take up two issues: the distribution of negative polarity items and scope phenomena. It has been observed that there are many differences in the behavior of negative polarity items (NPIs) in Korean, Japanese, and English (Suh (1990), etc.). Among them, the most heralded one is the different locality requirement between an NPI and its licenser among these languages. There is a strict locality requirement, often called clausemate condition, between an NPI and its licenser (negation) in the first two languages, while there is no such condition in English. Adopting the minimalist program (Chomsky, 1993), we provide a unified account for this parametric difference between these two types of languages, by proposing that the (Neg) feature of Korean and Japanese NPIs is strong while that of English NPIs is weak. Another well-known difference among these languages, the subject/object asymmetry in NPI licensing only attested in English is attributed to the different clausal architecture of these languages. It will be argued that Japanese and Korean can have a subject below negation while English only allows a subject in the position higher than negation (cf. Ahn (1991)). ^ Also, this thesis tries to provide a unified account for the scope phenomena in all of these languages. Departing from a prevalent belief that there are a great many differences between Korean/Japanese and English with respect to scope, we show that there are surprising similarities in their scope phenomena. First of all, we show that rigidity effects obtain not only in Japanese and Korean, but in English (Lasnik and Saito (1992)). Next, we derive these rigidity effects from economy considerations. We propose that at LF, a quantifier phrase (QP) adjoins to the closest maximal projection to take scope. Given this, economy dictates that when a QP undergoes A'-movement in overt syntax, the first A'-adjunction site of that QP is the position where it takes scope (cf. Abe (1993)). The reason is that the moved QP becomes lighter by discharging the feature(s) responsible for its quantificational force, thus obeying economy. Related to this, we also provide an account for why only in Japanese and Korean, overt movement (i. <b>e.</b> scrambling) of <b>QP</b> can override the rigidity effects, crucially relying on Mahajan (1990) and Saito (1992). ^ In conclusion, this thesis confirms the main claim of the minimalist program, that is, there is Universal Grammar which we are born with, and that the superficial differences among them result from the choice of different parameter(s). ...|$|R
40|$|Neste estudo, as espécies capim-setária (Setaria anceps Stapf.), capim-hemárthria (Hemarthria altissima [Poir] Stapf. & Hubbard), capim-do-nilo (Acroceras macrum Stapf.) e capim-angola (Brachiaria purpurascens [Raddi] Henr.) foram submetidos à deficiência hídrica moderada a seca com o objetivo de avaliar o efeito do déficit hídrico sobre as características de fluorescência da clorofila. O experimento foi realizado em casa de vegetação, em blocos ao acaso, constituídos pelas quatro espécies cultivadas sob dois regimes hídricos (irrigado e não-irrigado), em três repetições. Durante a indução da deficiência hídrica, foram monitoradas as seguintes variáveis de fluorescência da clorofila a: fluorescência inicial (F 0), fluorescência máxima (Fm), rendimento quântico máximo do PSII (Fv/Fm), taxa relativa de transporte de elétrons (ETR), {{quenching}} fotoquímico (<b>qP)</b> <b>e</b> quenching não fotoquímico (qN). Após dez dias de submissão ao estresse hídrico, os valores de Fo e Fm decresceram em todas as espécies. Os menores valores de Fv/Fm foram encontrados no capim-do-nilo e no capim-setária, o que configura baixo rendimento fotoquímico nessas espécies sob déficit hídrico, ao contrário do capim-hemárthria, que apresentou valores similares em ambos os tratamentos. Os valores mais altos de qN foram registrados no capim-hemárthria e no capim-angola, demonstrando boa capacidade dessas espécies em dissipar a energia luminosa absorvida em excesso para manter baixo estado de redução nos aceptores primários de elétrons do PSII. Em geral, as curvas de ETR em resposta ao fluxo de fótons fotossintéticos mostraram-se distintas entre os tratamentos, sendo mais pronunciadas no capim-do-nilo. Nessa espécie, a eficiência dos transportadores de elétrons do PSII foi seriamente comprometida pelo déficit hídrico. In this study, {{individuals of}} setariagrass (Setaria anceps Stapf.), limpograss (Hemarthria altissima [Poir] Stapf. & Hubbard), nilograss (Acroceras macrum Stapf.) and angola grass (Brachiaria purpurascens [Raddi] Henr.) were submitted to moderate drought. The characteristics of chlorophyll a fluorescence (inicial fluorescence, Fo; maximum fluorescence, Fm; photochemistry efficiency, Fv/F­m; photochemical quenching, qP; non-photochemical quenching, qN and relative electron transport rate, ETR) were investigated {{in an experiment}} carried out in greenhouse, using plastic pots. The experimental treatments were allocated in a randomized complete blocks design, with three replications. The values of Fo and Fm decreased in all species after 10 days of drought, this effect being more evident in nilograss and setariagrass. The Fv/Fm values for nilograss and setariagrass decreased dramatically while that one for hemarthriagrass {{did not differ from}} the control. This results suggest a lower photochemical efficiency of photosynthesis in nilograss and setariagrass under water stress compared to hemarthriagrass and to the hea,lthy plants. The highest values of qN were observed for hemarthriagraas and angolagrass. This showed that the increased capacity to dissipate the excessive energy to drive photosynthesis was satisfactory to maintain a low reduction state of the primary electron acceptor of the photosystem II (measured as qP). In general, ETR curves in response to increasing photosynthetic photon flux differed from control to stressed plants, especially for nilograss. In this species, a serious damage caused by water stress provoked a significant reduction to the efficiency of the electron transporters of PSII...|$|R
40|$|Este estudo avaliou se relações entre os componentes do estímulo modelo complexo exerceriam controle condicional em tarefas de matching-to-sample simultâneo. Na Fase 1, 3 crianças com necessidades especiais de ensino foram expostas ao treino das relações A 1 B 1 e A 2 B 2 e ao teste das respectivas relações simétricas. Em seguida, as contingências de treino exigiram respostas de observação diferenciais que consistiram no estabelecimento de relações condicionais de identidade entre estímulos complexos (relações AB-AB) precedendo o acesso ao treino das relações condicionais ABX. Neste treino, diante de estímulos modelos complexos cujos componentes sustentavam condicionalidade treinada (A 1 B 1 e A 2 B 2), X 1 foi o estímulo de escolha correto; X 2 exerceu esta função quando os componentes do estímulo modelo não sustentavam tal relação (A 1 B 2 e A 2 B 1). Na Fase 2, ocorreria o treino PQ, testes <b>QP</b> <b>e</b> PQX que avaliariam a extensão do controle condicional definido pelas relações entre os estímulos P e Q. As três crianças registraram a aprendizagem das relações AB, a emergência das relações simétricas e índices elevados de acerto nas respostas de observação diferenciais, ou seja, no estabelecimento das relações condicionais de identidade com estímulos complexos. Contudo, as três demonstraram relações de controle distintas das previstas no treino ABX, sendo, portanto, o experimento finalizado na Fase 1. Tais resultados sugerem uma independência funcional entre as habilidades discriminativas exigidas nas duas contingências de ensino de relações condicionais com estímulos modelo complexos. This study {{evaluated}} if {{relations between}} components of complex sample stimuli would have controlled conditional responding in identity and arbitrary simultaneous matching-to-sample tasks. In Phase 1, 3 children with educational special needs {{were trained to}} select stimulus B 1 {{in the presence of}} stimulus A 1, and select B 2 in the presence of A 2 (AB conditional relations); then symmetrical BA relations BA were tested. Afterwards they were exposed to differential observing response procedure that prompted children to make simultaneous identity matching responses with complex sample and comparison stimuli (AB-AB relations). In the sequence, the ABX conditional relations were trained. One stimulus in set A and another in set B appeared together as a sample, and two novel stimuli were the comparisons. Selection of X 1 was reinforced if the two stimuli in the AB complex sample had been related in the previous training, and selection of X 2 was reinforced if the components of AB sample had not been conditionally related. In Phase 2, PQ and QP conditional relations had been trained and tested, respectively. The aim of PQX tests was evaluated if selection of X 1 and X 2 would have been controlled by conditional or non-conditional relations between P and Q stimuli as complex sample. All children who learned AB conditional relations, showed BA symmetrical emergency, and obtained high accuracy level at differential observing response, namely they demonstrated AB-AB identity matching-to-sample. Differently neither of them met learning criterion on ABX training. Then the experiment was stopped in Phase 1. In addition to literature data, these results demonstrated functional independency between discriminative skills required by the two teaching contingencies of conditional relations with complex stimuli...|$|R

