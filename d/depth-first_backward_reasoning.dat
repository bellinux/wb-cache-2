0|143|Public
40|$|Abstract. Based on P-law <b>reasoning,</b> <b>backward</b> P-law <b>reasoning</b> and its {{structure}} are presented, Next, the relation and relation theorems between <b>backward</b> P-law <b>reasoning</b> and general reasoning are given. Using the theory results, {{the application of}} <b>backward</b> P-law <b>reasoning</b> in the information image camouflage-reduction is given...|$|R
40|$|This study investigates {{strategies}} in reasoning about mental states of others, {{a process that}} requires theory of mind. It {{is a first step}} in studying the cognitive basis of such reasoning, as strategies affect tradeoffs between cognitive resources. Participants were presented with a two-player game that required reasoning about the mental states of the opponent. Game theory literature discerns two candidate strategies that participants could use in this game: either forward <b>reasoning</b> or <b>backward</b> <b>reasoning.</b> Forward reasoning proceeds from the first decision point to the last, whereas <b>backward</b> <b>reasoning</b> proceeds in the opposite direction. <b>Backward</b> <b>reasoning</b> is the only optimal strategy, because the optimal outcome is known at each decision point. Nevertheless, we argue that participants prefer forward reasoning because it is similar to causal reasoning. Causal reasoning, in turn, is prevalent in human reasoning. Eye movements were measured to discern between forward and backward progressions of fixations. The observed fixation sequences corresponded best with forward reasoning. Early in games, the probability of observing a forward progression of fixations is higher than the probability of observing a backward progression. Later in games, the probabilities of forward and backward progressions are similar, which seems to imply that participants were either applying <b>backward</b> <b>reasoning</b> or jumping back to previous decision points while applying forward reasoning. Thus, the game-theoretical favorite strategy, <b>backward</b> <b>reasoning,</b> does seem to exist in human reasoning. However, participants preferred the more familiar, practiced, and prevalent strategy: forward reasoning. © 2012 Meijering et al...|$|R
40|$|Abduction* is {{the genus}} with {{deduction}} and induction as species. Modus tollens is <b>backward</b> <b>reasoning</b> as an unknown proposition is inferred from a known proposition. Reductio ad absurdum is abductive because the conclusion is inferred by deriving a contradiction from an assumption. Inductive reasoning from effect to cause is also <b>backward</b> <b>reasoning.</b> But abduction* consists of forward reasoning as well. The generic structure of abductive* argumentation is universal among all cultures, occupations and disciplines...|$|R
40|$|Objective: The role of {{planning}} in binge eating episodes is unknown. We investigated the characteristics {{of planning}} associated with food cues in binging patients. We studied planning based on <b>backward</b> <b>reasoning,</b> reasoning that determines a sequence of actions back to front from the final outcome. Method: A cross-sectional {{study was conducted with}} 20 healthy participants, 20 bulimia nervosa (BN), 22 restrictive (ANR) and 23 binging anorexia nervosa (ANB), without any concomitant impulsive disorder. In neutral/relaxing, binge food and stressful conditions, <b>backward</b> <b>reasoning</b> was assessed with the Race game, promotion of delayed large rewards with an intertemporal discounting task, attention with the Simon task, and repeating a dominant behavior with the Go/No-go task. Results: BN and to a lower extent ANB patients succeeded more at the Race game in food than in neutral condition. This difference discriminated binging from non-binging participants. <b>Backward</b> <b>reasoning</b> in the food condition was associated with lower approach behavior toward food in BN patients, and higher food avoidance in ANB patients. Enhanced <b>backward</b> <b>reasoning</b> in the food condition related to preferences for delayed large rewards in BN patients. In BN and ANB patients the enhanced success rate at the Race game in the food condition was associated with higher attention paid to binge food. Conclusion: These findings introduce a novel process underlying binges: planning based on <b>backward</b> <b>reasoning</b> is associated with binges. It likely aims to reduce craving for binge foods and extend binge refractory period in BN patients, and avoid binging in ANB patients. Shifts between these goals might explain shifts between eating disorder subtypes...|$|R
40|$|This study {{examines}} whether forward reasoning {{provides a more}} appropriate framework for describing audit judgment than <b>backward</b> <b>reasoning.</b> Identifying the appropriate framework is important for future research because forward and <b>backward</b> <b>reasoning</b> are influenced differently by task and knowledge variables. A forward-reasoning framework is presented and evaluated using results from published studies and data from a computerized process-tracing experiment. Findings suggest that auditors rely heavily on forward reasoning, which challenges the assumption that generating and testing hypotheses is {{the primary focus of}} diagnostic reasoning during audit judgment...|$|R
40|$|Audit {{judgement}} {{research has}} widely assumed that auditors rely primarily on <b>backward</b> <b>reasoning</b> during analytical procedures but the relative use of forward reasoning {{has not been}} directly examined. The present study explains how auditors use <b>backward</b> and forward <b>reasoning</b> during analytical procedures, discusses evidence from other research suggesting that forward reasoning could be more prevalent, and examines the relative use of forward reasoning during analytical procedures with data from a computerised process-tracing field study. Results suggest that auditors rely extensively on forward reasoning when using analytical procedures. Findings motivate future research that examines when forward and <b>backward</b> <b>reasoning</b> are most effective. Copyright 2004 Accounting and Finance Association of Australia and New Zealand. ...|$|R
5000|$|However, the <b>backward</b> <b>reasoning</b> technique, {{implemented}} by SLD resolution, used {{to solve problems}} in logic programming languages such as Prolog, treats programs as goal-reduction procedures. Thus clauses of the form: ...|$|R
5000|$|With <b>backward</b> <b>reasoning,</b> an {{inference}} engine can determine whether Fritz is green in four steps. To start, the query is phrased {{as a goal}} assertion {{that is to be}} proved: [...] "Fritz is green".|$|R
50|$|Backward {{chaining}} (or <b>backward</b> <b>reasoning)</b> is an inference {{method that}} can be described colloquially as working backward from the goal(s). It is used in automated theorem provers, inference engines, proof assistants and other artificial intelligence applications.|$|R
50|$|An {{opportunistic}} {{reasoning system}} may combine {{elements of both}} forward and <b>backward</b> <b>reasoning.</b> It is useful {{when the number of}} possible inferences is very large and the reasoning system must be responsive to new data that may become known.|$|R
40|$|Abstract. Focusing is {{traditionally}} {{seen as a}} means of reducing inessential non-determinism in backward-reasoning strategies such as uniform proof-search or tableaux systems. In this paper we construct a form of focused derivations forpropositional linear logic that is appropriate for forward reasoning in the inverse method. We show that the focused inverse method conservatively generalizes theclassical hyperresolution strategy for Horn-theories, and demonstrate through a practical implementation that the focused inverse method is considerably fasterthan the non-focused version. 1 Introduction Strategies for automated deduction can be broadly classified as <b>backward</b> <b>reasoning</b> orforward <b>reasoning.</b> Among the <b>backward</b> <b>reasoning</b> strategies we find tableaux and matrix methods; forward reasoning strategies include resolution and the inverse method. The approaches seem fundamentally di fficult to reconcile because the state of a back-ward reasoner is global, while a forward reasoner maintains locally self-contained state...|$|R
50|$|In 1978 Elstein, Shulman and Sprafka applied {{cognitive}} science methods to investigate physicians’ clinical competence, developing {{a model of}} hypothetico-deductive reasoning which proposed that physicians reason by generating and testing a set of hypotheses to explain clinical data. This {{is an example of}} <b>backward</b> (hypothesis-to-data) <b>reasoning.</b> In 1986, Patel and Groen demonstrated that experts who accurately diagnosed complex clinical problems used forward reasoning (data to hypothesis), in contrast to novice subjects who used <b>backward</b> <b>reasoning</b> and misdiagnosed or partially diagnosed the same problems.|$|R
40|$|Isar {{offers a}} {{high-level}} proof (and theory) language for Isabelle. We give various examples of Isabelle/Isar proof developments, ranging from simple demonstrations of certain language features to {{a bit more}} advanced applications. The “real ” applications of Isabelle/Isar are found elsewhere. Contents 1 Basic logical reasoning 3 1. 1 Pure <b>backward</b> <b>reasoning</b> [...] 3 1. 2 Variations of <b>backward</b> vs. forward <b>reasoning</b> [...] . 4 1. 3 A few examples from “Introduction to Isabelle ” [...] ...|$|R
25|$|The {{fact that}} Horn clauses {{can be given}} a {{procedural}} interpretation and, vice versa, that goal-reduction procedures {{can be understood as}} Horn clauses + <b>backward</b> <b>reasoning</b> means that logic programs combine declarative and procedural representations of knowledge. The inclusion of negation as failure means that logic programming is a kind of non-monotonic logic.|$|R
40|$|In this paper, {{we propose}} {{diagnosis}} of steady-state process behaviour using rules {{derived from the}} signed directed graph(SDG) representing the interaction among the process variables. All abnormalities are correlated using <b>backward</b> <b>reasoning</b> through rules to yield a diagnosis. These rules can be added with experimental rules which are obtained from experts on plant operation...|$|R
40|$|We study {{access control}} to web {{services}} in virtual organizations. Accessing a service requires {{a set of}} credentials which is established {{by means of an}} interaction between client and server. We formalize argumentation framework. In the proposed framework goals are derived from desires by forward reasoning, and plans are derived from goals and planning rules by <b>backward</b> <b>reasoning.</b> ...|$|R
5000|$|Abductive logic {{programming}} is a computational framework that extends normal {{logic programming}} with abduction. It separates the theory [...] into two components, {{one of which}} is a normal logic program, used to generate [...] by means of <b>backward</b> <b>reasoning,</b> the other of which is a set of integrity constraints, used to filter the set of candidate explanations.|$|R
40|$|We {{present a}} proof {{procedure}} that combines <b>backward</b> <b>reasoning</b> with logic programs and forward reasoning with integrity constraints. We illustrate {{the use of}} the proof procedure as the inference engine underlying agents. Roughly speaking, the <b>backward</b> <b>reasoning</b> component of the proof procedure is responsible for the deliberative behaviour of agents, whereas the forward reasoning component is responsible for their reactive behaviour. 1 Introduction Recent years have seen a shift in the treatment of agents in artificial intelligence. In conventional approaches, intelligent agents reason and plan within a closed environment, producing a complete plan before they start executing it. In more recent, and arguably more realistic approaches, intelligent agents reason and plan while reacting to and interacting with the external environment (e. g., see [15]). The agent architecture of [6 [...] 8] combines rational, deliberative behaviour and reactivity to the external environment. At the heart of th [...] ...|$|R
40|$|We {{propose a}} logic-based {{language}} for programming agents that can reason {{about their own}} beliefs {{as well as the}} beliefs of other agents and can communicate with each other. The agents can be reactive, rational/deliberative or hybrid, combining both reactive and rational behaviour. We illustrate the language by means of examples. 1 Introduction Kowalski & Sadri [12] propose an approach to agents within an extended logic programming framework. In the remainder of the paper we will refer to their agents as KS-agents. KS-agents are hybrid in that they exhibit both rational (or deliberative) and reactive behaviour. The reasoning core of KS-agents is a proof procedure that combines forward and <b>backward</b> <b>reasoning.</b> <b>Backward</b> <b>reasoning</b> is used primarily for planning, problem solving and other deliberative activities. Forward reasoning is used primarily for reactivity to the environment, possibly including other agents. The proof procedure is executed within an observe-thinkact cycle that all [...] ...|$|R
40|$|This paper {{explores the}} {{relationship}} between verification of logic programs and imperative programs {{with the aim of}} uncovering the kinds of reasoning used to construct logic programs. We discuss forward reasoning, such as that used for verifying imperative programs using the inductive assertion method, and <b>backward</b> <b>reasoning,</b> such as that used for verifying imperative programs using subgoal induction and logic programs using consequence verification. We argue that consequence verification is often inadequate for Prolog programs because programmers make implicit assumptions about how procedures are called. These assumptions can be made explicit using general type declarations. Verification of logic programs with type declarations can be done in two steps. We show that one corresponds to subgoal induction and the other corresponds to the inductive assertion method. Thus two existing verification methods are combined. The forward and <b>backward</b> <b>reasoning</b> inherent in this method of verificat [...] ...|$|R
40|$|This paper {{develops}} a bi-directional prediction approach {{to predict the}} production parameters and performance of differential fibers based on neural networks and a multi-objective evolutionary algorithm. The proposed method does not require accurate description and calculation for the multiple processes, different modes and complex conditions of fiber production. The bi-directional prediction approach includes the forward prediction and <b>backward</b> <b>reasoning.</b> Particle swam optimization algorithms with K-means algorithm are used to minimize the prediction error of the forward prediction results. Based on the forward prediction, <b>backward</b> <b>reasoning</b> uses the multi-objective evolutionary algorithm to find the reasoning results. Experiments with polyester filament parameters of differential production conditions indicate that the proposed approach obtains good prediction results. The results {{can be used to}} optimize fiber production and to design differential fibers. This study also has important value and widespread application prospects regarding the spinning of differential fiber optimization...|$|R
40|$|We {{study the}} problem of endowing logic-based agents that can reason about their own beliefs {{as well as the}} beliefs of other agents with {{communication}} skills. We show how communication performatives from existing agent communication languages as well as their preconditions and eects can be expressed within logic-based agents in terms of the agents' beliefs. We illustrate the resulting language for programming logic-based agents by means of examples. 1 Introduction In an earlier paper [6], we propose an approach to logic-based agents by combining the approach to agents by Kowalski and Sadri [11] and the approach to meta-reasoning by Costantini et al. [5, 4]. Similarly to Kowalski and Sadri's agents, the agents in [6] are hybrid in that they exhibit both rational (or deliberative) and reactive behaviour. The reasoning core of the agents is a proof procedure that combines forward and <b>backward</b> <b>reasoning.</b> <b>Backward</b> <b>reasoning</b> is used primarily for planning, problem solving and other deliber [...] ...|$|R
40|$|With the {{advances}} in sensor and platform technologies, the capability for collecting geospatial data has significantly increased. Large volumes of data {{have been collected}} using remote sensing. While those data are potentially valuable {{for the benefit of}} society, they must be converted to geospatial knowledge before they are useful. The traditional methods — only geospatial experts analyze data — fall far short of today’s increased demands for geospatial knowledge. As a result, significant amounts of data have not even once been analyzed after collection. Recent progress in the geospatial semantic Web has shown promise for developing automatic geospatial knowledge discovery methods for solving application problems, which otherwise require considerable resources. This paper presents an approach for automatically solving geospatial problems in the geospatial semantic Web environment. The approach simulates the process used by geospatial experts who first use <b>backward</b> <b>reasoning</b> from the required knowledge to the available raw data to select a set of available geo-processing functions, and then execute the functions sequentially, starting from raw data, to derive the desired knowledge. This <b>backward</b> <b>reasoning</b> effectively creates a path from raw geospatial data to the desired geospatial knowledge. With rich semantic descriptions of services and the support of ontology, the path can be formed automatically through <b>backward</b> <b>reasoning</b> from the desired result to raw geospatial data using semantic Web services. Such a path can be instantiated to become an executable workflow to generate the result automatically. A prototypical system is implemented to demonstrate the above concept and approach...|$|R
40|$|This paper {{focuses on}} a linguistic-valued {{temporal}} logic based reasoning formalism for dynamically modelling and merging information under uncertainty in some real world systems where the state of a system evolves over time and the transition through states depends on uncertain conditions. We provide forward and <b>backward</b> <b>reasoning</b> algorithms which, respectively, support simulation and query answering. These algorithms are then explained through several examples based on Smart Homes applications...|$|R
40|$|The {{problem of}} {{detecting}} feature interactions in telephone systems design is addressed. The method proposed involves specification {{of the features}} in LOTOS, and uses an analysis technique called <b>backward</b> <b>reasoning.</b> This is is implemented in LOTOS {{by a combination of}} backward and forward execution. A tool to help carry out backward execution is presented. A detailed example of the use of the technique is given, involving the three-way-calling and call-waiting features...|$|R
50|$|Many {{reasoning}} systems employ deductive reasoning to draw inferences from available knowledge. These inference engines support forward <b>reasoning</b> or <b>backward</b> <b>reasoning</b> {{to infer}} conclusions via modus ponens. The recursive reasoning methods they employ are termed ‘forward chaining’ and ‘backward chaining’, respectively. Although reasoning systems widely support deductive inference, some systems employ abductive, inductive, defeasible {{and other types}} of reasoning. Heuristics may also be employed to determine acceptable solutions to intractable problems.|$|R
40|$|The goal of {{this paper}} is to present a theorem prover able to perform both forward and <b>backward</b> <b>reasoning</b> {{supported}} by a well defined formal system. This system for bidirectional reasoning has been proved equivalent to Gentzen's classical system of propositional natural deduction. This paper, primarily aimed at developing a deeper theoretical understanding of bidirectional reasoning, provides basic concepts to be incorporated into an innovative theorem prover to support interactive proofs construction in general domains. ...|$|R
40|$|Isar o#ers a {{high-level}} proof (and theory) language for Isabelle. We give various examples of Isabelle/Isar proof developments, ranging from simple demonstrations of certain language features to more advanced applications. Contents 1 Basic logical reasoning 2 1. 1 Pure <b>backward</b> <b>reasoning....................</b> 2 1. 2 Variations of <b>backward</b> vs. forward <b>reasoning.........</b> 4 1. 3 A few examples from "Introduction to Isabelle"........ 7 1. 3. 1 A propositional proof.................. 7 1. 3. 2 A quantifier proof.................... 8 1. 3. 3 Deriving rules in Isabelle................ 9 2 Cantor's Theorem 9 3 Peirce's Law 11 4 Correctness {{of a simple}} expression compiler 13 4. 1 Binary operations......................... 13 4. 2 Expressions............................ 13 4. 3 Machine.............................. 14 4. 4 Compiler. [...] ...|$|R
40|$|Abstract. Tropos is an agent-oriented {{software}} methodology {{proposed in}} [1, 2]. The methodology {{is founded on}} the notions of agent and goal, and goal analysis is used extensively to support software development during different phases. This paper adopts a formal goal model defined and analyzed in [9, 15] to make the goal analysis process concrete {{through the use of}} forward and <b>backward</b> <b>reasoning</b> for goal models. The formal goal analysis is illustrated through examples, using an implemented goal reasoning tool...|$|R
40|$|We {{present the}} theory and {{implementation}} of a theorem prover for first-order intuitionistic linear logic based on the inverse method. The central proof-theoretic insights underlying the prover concern resource management and focused derivations, {{both of which are}} traditionally understood in the domain of <b>backward</b> <b>reasoning</b> systems such as logic programming. We illustrate how resource management, focusing, and other intrinsic properties of linear connectives affect the basic forward operations of rule application, contraction, and forward subsumption. We also present some preliminary experimental results obtained with our implementation...|$|R
40|$|International audienceFirst of all, a goal-guiding graphic {{reasoning}} {{approach that}} based on the predicate/transition system has been proposed for the first-order predicate logic. In process of reasoning, the premise is separated from the conclusion, which has been taken {{as the beginning of}} the <b>backward</b> <b>reasoning</b> that is purposeful and effective as well. Next, this reasoning approach has been applied in the agriculture expert system to present a method of solving problem, providing a new way for studying the reasoning mechanism of the agriculture expert system...|$|R
40|$|Abstract. We {{present the}} theory and {{implementation}} of a theorem prover for first-order intuitionistic linear logic based on the inverse method. The central proof-theoretic insights underlying the prover concern resource management and focused derivations, {{both of which are}} traditionally understood in the domain of <b>backward</b> <b>reasoning</b> systems such as logic programming. We illustrate how resource management, focusing, and other intrinsic properties of linear connectives affect the basic forward operations of rule application, contraction, and forward subsumption. We also present some preliminary experimental results obtained with our implementation. ...|$|R
5000|$|Here [...] is a meta-predicate and the {{variable}} [...] ranges over fluents. The predicates , [...] and [...] {{correspond to the}} predicates , , and [...] respectively. The left arrow [...] is half of the equivalence [...] The other half is implicit in {{the completion of the}} program, in which negation is interpreted as negation as failure. Induction axioms are also implicit, and are needed only to prove program properties. <b>Backward</b> <b>reasoning</b> as in SLD resolution, which is the usual mechanism used to execute logic programs, implements regression implicitly.|$|R
40|$|We {{introduce}} a probabilistic language and a fast inference algorithm for state estimation in hybrid dynamic relational domains with {{an unknown number}} of objects. More specifically, we apply Particle Filters to distributional clauses. The particles represent (partial) interpretations of possible worlds (with discrete and/or continuous variables) and the filter recursively updates its beliefs about the current state. We use <b>backward</b> <b>reasoning</b> to determine which facts {{should be included in the}} partial interpretations. Experiments show that our framework can outperform the classical particle filter and is promising for robotics applications. status: publishe...|$|R
40|$|Abstract Temporality and {{uncertainty}} are important features of many real world systems. Solving problems in such systems requires {{the use of}} formal mechanism such as logic systems, statistical methods or other reasoning and decision-making methods. In this paper, we propose a linguistic truth-valued temporal reasoning formalism to enable the management of both features concurrently using a linguistic truth valued logic and a temporal logic. We also provide a <b>backward</b> <b>reasoning</b> algorithm which allows the answering of user queries. A simple but realistic scenario in a smart home application is used to illustrate our work. 1...|$|R
40|$|Abstract. Since its introduction, the Event Calculus (EC) {{has been}} {{recognized}} for being an excellent framework to reason about time and events, {{and it has been}} applied to a variety of domains. However, its use inside logic-based frameworks has been mainly a-posteriori, based on specific queries and <b>backward</b> <b>reasoning.</b> This has somehow limited its applicability in dynamic environments. We fill this gap by proposing a Reactive and logic-based implementation of the EC, called REC. We give an axiomatization of REC inside the SCIFF Abductive Logic Programming framework, and study its formal properties. ...|$|R
