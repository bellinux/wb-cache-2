4|25|Public
5000|$|Since 1970 {{researchers}} at the Communications Research Centre (CRC) in Ottawa {{had been working on}} a set of [...] "picture description instructions", which encoded graphics commands as a text stream. Graphics were encoded as a series of instructions (graphics primitives) each represented by a single ASCII character. <b>Graphic</b> <b>coordinates</b> were encoded in multiple 6 bit strings of XY coordinate data, flagged to place them in the printable ASCII range so that they could be transmitted with conventional text transmission techniques. ASCII SI/SO characters were used to differentiate the text from graphic portions of a transmitted [...] "page". In 1975, the CRC gave a contract to Norpak to develop an interactive graphics terminal that could decode the instructions and display them on a colour display, which was successfully up and running by 1977.|$|E
5000|$|The Canadian Communications Research Centre (CRC), {{based in}} Ottawa, {{had been working}} on various {{graphics}} systems since the late 1960s, much of it led by Herb Bown. Through the 1970s they turned their attention to building out a system of [...] "picture description instructions", which encoded graphics commands as a text stream. Graphics were encoded as a series of instructions (graphics primitives) each represented by a single ASCII character. <b>Graphic</b> <b>coordinates</b> were encoded in multiple 6 bit strings of XY coordinate data, flagged to place them in the printable ASCII range so that they could be transmitted with conventional text transmission techniques. ASCII SI/SO characters were used to differentiate the text from graphic portions of a transmitted [...] "page". These instructions were decoded by separate programs to produce graphics output, on a plotter for instance. Other work produced a fully interactive version. In 1975, the CRC gave a contract to Norpak to develop an interactive graphics terminal that could decode the instructions and display them on a color display.|$|E
40|$|Abstracts: Visual LISP {{language}} is favored {{by many people}} for its simple and practical. Because of most CAD teaching materials centre on introducing concrete languages ’ use and single symbol making, lack of a comprehensive description of {{the whole process of}} developing professional symbols library, it is very difficult for People having mastery of LISP languages to developing professional symbol library by this language. In this article, the authors develop a symbols library for common Topographic Maps and design an environment to transfer and input the symbols with the aid of Visual LISP language, including defining <b>graphic</b> <b>coordinates</b> systems, coordinates transformations, putting library files in order, calling user-defined file etc. This paper provides great help for people who Devote oneself to map symbol library system development...|$|E
5000|$|There is a {{wide array}} of {{commands}} available for making <b>graphics.</b> <b>Coordinates</b> in PSTricks are always represented in parentheses, as the following example (scaled) illustrates: ...|$|R
40|$|The dynamic {{behavior}} of the tetranuclear zinc(II) –dysprosium(III) complex of the hexaimine [3 + 3] macrocycle (LPr) 6 − under an external DC field (1500  Oe) indicates {{that it is a}} single-molecule magnet (SMM). It is the first to contain a single lanthanide ion (in orange, see <b>graphic)</b> <b>coordinated</b> inside the cavity of a single macrocyclic ligand and thus represents a new class of SMM. status: publishe...|$|R
40|$|Uniform {{sampling}} in metrology {{has known}} drawbacks such as coherent spectral aliasing {{and a lack}} of efficiency in terms of measuring time and data storage. The requirement for intelligent sampling strategies has been outlined over recent years, particularly where the measurement of structured surfaces is concerned. Most of the present research on intelligent sampling has focused on dimensional metrology using coordinate-measuring machines with little reported on the area of surface metrology. In the research reported here, potential intelligent sampling strategies for surface topography measurement of structured surfaces are investigated by using numerical simulation and experimental verification. The methods include the jittered uniform method, low-discrepancy pattern sampling and several adaptive methods which originate from computer <b>graphics,</b> <b>coordinate</b> metrology and previous research by the authors. By combining the use of advanced reconstruction methods and feature-based characterization techniques, the measurement performance of the sampling methods is studied using case studies. The advantages, stability and feasibility of these techniques for practical measurements are discussed...|$|R
40|$|Czechoslovak {{topographic}} maps in a {{scale of}} 1 : 100 000 in S- 46 coordinate system on the Bessel ellipsoid represent relativelyunknown state map work. This state map series originated in Czechoslovakia in the years 1949 - 1953 as a provisional work. The paper deals with planimetric accuracy of maps determined by comparing positional deviations of control points. Controlpoints are both measured in the maps themselves and in reference maps (cadastral maps, digital raster equivalents of topographic maps 1 : 25 000). The principle of transferring <b>graphic</b> <b>coordinates</b> to S- 46 is based on sequence of Euclidean and affine transformations. Transformation removes the influence of inaccuracies of plotted S- 46 grid points (which are used as identical) to control pointsand further suppress {{the influence of the}} map shrinkage. Calculated sets of variations are then statistically tested and analyzed...|$|E
5000|$|Between 1987 - 1988 {{he worked}} for The World & I, Washington Times Publication.2850; New York Ave. Ne. Washington DC [...]Art Director: Responsible for the overall look of theMagazine, support with the {{conceptual}} design & productionfor all <b>graphic</b> materials, <b>coordinate</b> the Art departmentactivities with the editorial & production depts [...]Photo directing and select, evaluate photographs,Illustrationsfor the cover magazine and page design for specialreports,assign work to Illustrators & Photographers.|$|R
40|$|Abstract—Scientists {{increasingly}} use ensemble {{data sets}} to explore relationships present in dynamic systems. Ensemble data sets combine spatio-temporal simulation results generated using multiple numerical models, sampled input conditions and perturbed parameters. While ensemble data sets are {{a powerful tool}} for mitigating uncertainty, they pose significant visualization and analysis challenges due to their complexity. In this article, we present Ensemble-Vis, a framework consisting of a collection of overview and statistical displays linked through a high level of interactivity. Ensemble-Vis allows scientists to gain key scientific insight into the distribution of simulation results as well as the uncertainty associated with the scientific data. In contrast to methods that present large amounts of diverse information in a single display, we argue that combining multiple linked displays yields a clearer presentation of the data and facilitates a greater level of visual data analysis. We demonstrate our framework using driving problems from climate modeling and meteorology and discuss generalizations to other fields. Index Terms—Ensemble data, uncertainty, statistical <b>graphics,</b> <b>coordinated</b> and linked views. I...|$|R
40|$|Fitting {{circles and}} ellipses to given {{points in the}} plane {{is a problem that}} arises in many {{application}} areas, e. g. computer <b>graphics</b> [1], <b>coordinate</b> metrology [2], petroleum engineering [11], statistics [7]. In the past, algorithms have been given which fit circles and ellipses in some least squares sense without minimizing the geometric distance to the given points [1], [6]. In this paper we present several algorithms which compute the ellipse for which the sum of the squares of the distances to the given points is minimal. These algorithm...|$|R
50|$|By 1984, both Bell Labs and Carnegie Mellon University had working multi-touch-screen prototypes - both {{input and}} {{graphics}} - that could respond interactively {{in response to}} multiple finger inputs. The Bell Labs system was based on capacitive coupling of fingers, whereas the CMU system was optical. In 1985, the canonical multitouch pinch-to-zoom gesture was demonstrated, with <b>coordinated</b> <b>graphics,</b> on CMU's system.|$|R
5000|$|The {{editor in}} chief of the {{newspaper}} was George Tutoveanu who also wrote the editorials of each issue and the responses to letters from readers. Other important contributors were G. Tutoveanu, George Pallady, D. Fărcăşanu, Syilvia Pan (Natalia Paşa), Zoe G. Frasin, N.N. Lenguceanu, Virgil Duiculescu, Vasile Damaschin (who also had the responsibility of the newspaper's <b>graphics</b> and also <b>coordinated</b> the [...] "Literary discussions"), Ştefan Cosma, George Nedelea, George Damaschin, Olga Alexa, G. G. Ursu, Z. Letin, N. Bogescu, C. Crişan and I.A. Basarabescu ...|$|R
40|$|This paper aims {{to look at}} the paraprofessionals in NTU Libraries and {{the various}} {{responsibilities}} that the paraprofessionals take on. They bring with them various technical skills to support the professional librarians. These paraprofessionals – where some of them belong to the younger generation- also take on roles to engage the majority of the users – the students. Besides the roles in their respective divisions, the paraprofessionals are involved in engaging users in other ways such as using social web applications, <b>graphic</b> design, <b>coordinating</b> submissions to the institutional repository, etc. The paraprofessionals in NTU Libraries- mainly young people – also strive to engage the users by promoting the library and providing the service. This paper will look into how these young and young-at-heart paraprofessionals work together with the librarians to ensure that consistent service is provided and assist the professional librarians in the development of new projects...|$|R
40|$|Fitting {{circles and}} ellipses to given {{points in the}} plane {{is a problem that}} arises in many {{application}} areas, e. g. computer <b>graphics</b> [1], <b>coordinate</b> metrology [2], petroleum engineering [11], statistics [7]. In the past, algorithms have been given which fit circles and ellipses in some least squares sense without minimizing the geometric distance to the given points [1], [6]. In this paper 1 we present several algorithms which compute the ellipse for which the sum of the squares of the distances to the given points is minimal. These algorithms are compared with classical simple and iterative methods. Circles and ellipses may be represented algebraically i. e. by an equation of the form F (x) = 0. If a point is on the curve then its coordinates x are a zero of the function F. Alternatively, curves may be represented in parametric form, which is well suited for minimizing the sum of the squares of the distances. Keywords. least squares, curve fitting, singular value decomposition [...] . ...|$|R
50|$|While {{there are}} {{a large number of}} papers about {{parallel}} coordinates, there are only few notable software publicly available to convert databases into parallel <b>coordinates</b> <b>graphics.</b> Notable software are ELKI, GGobi, Macrofocus High-D, Mondrian, Orange and ROOT. Libraries include Protovis.js, D3.js provide basic examples, while more complex examples are also available. D3.Parcoords.js (a D3-based library) and Macrofocus High-D API (a Java library) specifically dedicated to ||-coords graphic creation have also been published. The Python data structure and analysis library Pandas implements parallel coordinates plotting, using the plotting library matplotlib. The R package GGally, among others, implements parallel coordinates plotting.|$|R
50|$|With the {{introduction}} of Windows XP, GDI was complemented by the C++-based GDI+ subsystem. GDI+ adds anti-aliased 2D <b>graphics,</b> floating point <b>coordinates,</b> gradient shading, more complex path management, intrinsic support for modern graphics-file formats like JPEG and PNG, and support for composition of affine transformations in the 2D view pipeline. GDI+ uses ARGB values to represent color. Use of these features is apparent in Windows XP's user interface and several of its applications such as Microsoft Paint, Windows Picture and Fax Viewer, Photo Printing Wizard, and My Pictures Slideshow screensaver, and {{their presence in the}} basic graphics layer greatly simplifies implementations of vector-graphics systems such as Flash or SVG.|$|R
25|$|Ivan Sutherland {{developed}} Sketchpad in 1963, {{widely held}} {{as the first}} graphical computer-aided design program. It used a light pen to create and manipulate objects in engineering drawings in realtime with <b>coordinated</b> <b>graphics.</b> In the late 1960s, researchers at the Stanford Research Institute, led by Douglas Engelbart, developed the On-Line System (NLS), which used text-based hyperlinks manipulated with a then new device: the mouse. In the 1970s, Engelbart's ideas were further refined and extended to graphics by researchers at Xerox PARC and specifically Alan Kay, who went beyond text-based hyperlinks and used a GUI as the main interface for the Xerox Alto computer, released in 1973. Most modern general-purpose GUIs are derived from this system.|$|R
40|$|Deformation {{is a key}} {{component}} in many applications including virtual surgery and the animation of digital characters in the movie industry. Previous deformation methods either require non-intuitive ways of specifying the deformation or have been too expensive to compute in real-time. We focus on three methods for creating intuitive deformations of 3 D shapes. The first method is a new, smooth volumetric subdivision scheme that allows the user to specify deformations using conforming collections of tetrahedra, which generalizes the widely used Free-Form Deformation method. The next technique extends a fundamental interpolant in Computer <b>Graphics</b> called Barycentric <b>Coordinates</b> and lets the user manipulate low-resolution polygon meshes to control deformations of high-resolution shapes. Finally, we conclude with our work on creating deformations described by collections of points using Moving Least Squares...|$|R
40|$|This paper {{describes}} a multilingual graphic editor for creation of circuits, drafts and graphics in such subject areas {{where it is}} possible to pre-define the composite graphic elements. The database with testing questions stores only the indices of the composite <b>graphic</b> elements, their <b>coordinates,</b> size and the connections among them. As a result we have a substantial decrease {{of the size of the}} database, the data transferred to the learners and, consequently, the time required for visualization of the testing questions on-line. Another important contribution is the opportunities to dynamically generate circuits, drafts and graphics in a number of cases, thus decreasing the number of questions, authored in advance. The graphic editor is developed as an extension to the Dynamic Test Development Tool in Distributed e-Testing Cluster. It is multilingual, i. e. all the elements of the user interface (menus and buttons) are parameterized, with the actual texts of the supported languages stored in the database. 1...|$|R
40|$|Multimodal {{interfaces}} combining, e. g., {{natural language}} and graphics {{take advantage of}} both the individual strength of each communication mode {{and the fact that}} several modes can be employed in parallel, e. g., in the text-picture combinations of illustrated documents. It is an important goal of this research not simply to merge the verbalization results of a natural language generator and the visualization results of a knowledge-based graphics generator, but to carefully <b>coordinate</b> <b>graphics</b> and text {{in such a way that}} they complement each other. We describe the architecture of the knowledge-based presentation system WIP * which guarantees a design process with a large degree of freedom that can be used to tailor the presentation to suit the specific context. In WIP, decisions of the language generator may influence graphics generation and graphical constraints may sometimes force decisions in the language production process, In this paper, we focus on the influence of graphical constraints on text generation. In particular, we describe the generation of cross-modal references, the revision of text due to graphical constraints and the clarification of graphics through text...|$|R
40|$|ABSTRACT: Space-Time Constraint {{optimization}} {{techniques have}} been used very effectively {{in the field of}} <b>graphics</b> animation for <b>coordinating</b> real and animated characters, including motion retargeting. Using a script from, say, a ballerina, animated characters (including Coke cans!) can be made to dance the script in a convincingly realistic manner. We argue that the same underlying technology can be employed to coerce interoperation between two or more component simulations, even if they are different resolution (i. e. multi-resolution) representations of the same phenomenon. We describe our approach as it applies to military operations other than war, in particular military operations in urban terrain (MOUT), where we use as our script the behavior of an individual simulated soldier, and then apply it to guide the behavior of a simulated special operations force. We argue that our approach is better than one that coerces the internals of component simulations to be consistent, because it involves less work, and it captures what is important to the end user. Also, we describe a process for creating a robust model, based on interoperating component models, using the space-time technology we describe here. 1...|$|R
40|$|The {{nucleotide}} {{sequence of the}} cDNA of bovine lens beta s-crystallin has been determined, and the derived amino acid sequence has been confirmed by amino acid compositions and partial sequences of the tryptic peptides of this monomeric protein. beta s-Crystallin has a length of 177 residues, corresponding to a mol. wt. of 20 773, and a blocked N-terminal serine. Comparison of beta s with the known sequences of other beta- and gamma-crystallins, and computer construction of a phylogenetic tree of these sequences, shows beta s to be {{more closely related to}} the monomeric gamma-crystallins than to the oligomeric beta-crystallins. Also the tertiary structure of beta s modelled by interactive computer <b>graphics</b> on the <b>coordinates</b> of gamma II-crystallin, revealed similarities with the gamma-crystallins which might explain its monomeric behavior: the presence of a very short N-terminal 'arm' as compared with the beta-crystallins; a distribution of charged residues on the surface as in the gamma-crystallins; and finally the nature of certain residues of its inter-domain contacts. beta s-Crystallin seems to be an old and isolated offshoot of the gamma-family, and, considering its ancient origin, might well be present in other, non-mammalian, vertebrate classes...|$|R
40|$|The {{aim of this}} {{exercise}} is to {{raise the level of}} our expertise about boating and boat building, its principles, tectonics, design and construction processes as well as its rich history. To that end, we will produce a book of sorts that will serve as a resource to our class throughout the semester. We will break up into groups of two or three and divide the categories below. Each group will be responsible for producing a “file ” which includes a synopsis on the sub-topic, as well as copies of salient articles, graphics, bibliographies, web sites etc. (In the interest of saving trees, try to compress the material as much as possible.) Given the breadth of the topics, the goal is to provide an overview of the sub-topic, while going into sufficient depth in those areas that appear most directly related to our studio. Please edit accordingly. Our TA, who will compile the entire document for distribution amongst class members next Tuesday, and will <b>coordinate</b> <b>graphic</b> standards for each “file”. Please submit your final research by Monday evening or Tuesday morning (TA will confirm the time). In addition, you will be asked to give a presentation next Tuesday on your findings. You may use PowerPoint, or simply Xerox acetates of your files and use an overhead projector. Research Clusters...|$|R
40|$|Structured {{surfaces}} are increasingly popular in manufacturing {{due to their}} ability to affect the function of a component, for example paintability and adhesiveness. Structured surfaces usually have complex geometrical structures on the micrometre to nanometre scale. These complex surface structures are challenging in terms of their measurement. For example, one widely recognised challenge comes from the increasingly high requirement of both measuring efficiency and measuring accuracy. Intelligent sampling is regarded as part of the solution to this challenge. In this research, statistical sampling and signal sampling are investigated for the measurement of structured surfaces. Firstly, the widely used technique of uniform sampling is reviewed. Determination criteria for the sampling conditions of uniform sampling, i. e. the sampling intervals and lengths, are discussed. Four types of efficient (intelligent) sampling techniques, which were initially developed for the fields of statistics, computer <b>graphics</b> and <b>coordinate</b> metrology, are investigated. The intelligent techniques include: jittered uniform sampling, low-discrepancy sampling, model-based sampling and adaptive sampling. However, there are issues when applying these techniques to practical instruments; for example, they do not consider the measuring principles, such as the sensing mode or scanning method. Considering the measurement of surface topography, a sequential profiling adaptive sampling technique is proposed for raster scan-based stylus profilometers. Numerical evidence shows that the adaptive technique is promising for the measurement of linear patterns and tessellated structured surfaces. To examine the performance of these intelligent sampling techniques, reconstruction techniques and error evaluation approaches are studied. A boundary segmentation algorithm has been developed to characterise the feature boundaries of surface features. With a sampling test toolbox, developed as part of the project, a sampling performance test is carried out in which the performance of seven selected sampling techniques is analysed. The experimental results show that adaptive sampling and model-based sampling methods have significant advantages over other methods. The proposed sequential profiling adaptive sampling has good performance in the measurement of linear patterned surfaces. However, there are difficulties in fully enabling intelligence sampling for practical measurements. For example, the relationship between sampling and reconstruction has not been clearly understood. If the difficulties can be successfully addressed, intelligent sampling can be of promise in the next generation of measurement techniques...|$|R
40|$|The {{information}} {{presented in this}} Acceptance Test Plan document shows {{the current status of}} the General Mission Analysis Tool (GMAT). GMAT is a software system developed by NASA Goddard Space Flight Center (GSFC) in collaboration with the private sector. The GMAT development team continuously performs acceptance tests in order to verify that the software continues to operate properly after updates are made. The GMAT Development team consists of NASA/GSFC Code 583 software developers, NASA/GSFC Code 595 analysts, and contractors of varying professions. GMAT was developed to provide a development approach that maintains involvement from the private sector and academia, encourages collaborative funding from multiple government agencies and the private sector, and promotes the transfer of technology from government funded research to the private sector. GMAT contains many capabilities, such as integrated formation flying modeling and MATLAB compatibility. The propagation capabilities in GMAT allow for fully coupled dynamics modeling of multiple spacecraft, in any flight regime. Other capabilities in GMAT inclucle: user definable coordinate systems, 3 -D <b>graphics</b> in any <b>coordinate</b> system GMAT can calculate, 2 -D plots, branch commands, solvers, optimizers, GMAT functions, planetary ephemeris sources including DE 405, DE 200, SLP and analytic models, script events, impulsive and finite maneuver models, and many more. GMAT runs on Windows, Mac, and Linux platforms. Both the Graphical User Interface (GUI) and the GMAT engine were built and tested on all of the mentioned platforms. GMAT was designed for intuitive use from both the GUI and with an importable script language similar to that of MATLAB...|$|R
40|$|Background & aims: Malnutrition (over and under-nutrition) {{is highly}} {{prevalent}} in patients admitted to hospital {{and it is}} a well-known risk factor for increased morbidity and mortality. Nutritional problems are often misdiagnosed, and especially the coexistence of over and undernutrition is not usually recognized. We aimed to develop and validate a screening tool for the easy detection and reporting of both undernutrition and overnutrition, specifically identifying the clinical conditions where the two types of malnutrition coexist. Methods: The study consisted of three phases: 1) selection of an appropriate study population (estimation sample) and of the hospital admission parameters to identify overnutrition and undernutrition; 2) combination of selected variables to create a screening tool to assess the nutritional risk in case of undernutrition, overnutrition, or the copresence of both the conditions, to be used by non-specialist health care professionals; 3) validation of the screening tool in a different patient sample (validation sample). Results: Two groups of variables (12 for undernutrition, 7 for overnutrition) were identified in separate logistic models for their correlation with the outcome variables. Both models showed high efficacy, sensitivity and specificity (overnutrition, 97. 7 %, 99. 6 %, 66. 6 %, respectively; undernutrition, 84. 4 %, 83. 6 %, 84. 8 %). The logistic models were used to construct a two-faced test (named JaNuS - Just A Nutritional Screening) fitting into a two-dimension Cartesian <b>coordinate</b> <b>graphic</b> system. In the validation sample the JaNuS test confirmed its predictive value. Internal consistency and test-retest analysis provide evidence for the reliability of the test. Conclusion: The study provides a screening tool for the assessment of the nutritional risk, based on parameters easy-to-use by health care personnel lacking nutritional competence and characterized by excellent predictive validity. The test might be confidently applied in the clinical setting to determine the importance of malnutrition (including the copresence of over and undernutrition) as a risk factor for morbidity and mortality. © 2013 Elsevier Ltd and European Society for Clinical Nutrition and Metabolism...|$|R
40|$|In this diploma thesis a {{geographical}} information system (GIS), ESRI® ArcGIS® Desktop 9. 0 with the 3 D-Analyst® extension, has been integrated with the current DCV system to enhance the visualization of geopositioned information. Decision-centered visualization (DCV) is an approach to adaptive, interactive visualization {{at the intersection of}} knowledge engineering and information visualization. DCV suggests the use of decision and task models as well as knowledge of the information environment in an application domain to guide the human-machine interface and the visualization system in order to produce timely, knowledge-based presentations. The objective is to reduce the information workload and to provide information visualization that enables decision-makers to quickly achieve situation awareness during their tasks and to make informed decisions under time pressure. To achieve this, a DCV system can utilize the machine-readable representation of information and knowledge of a domain to present to the human user filtered information specific to the current task. The user interface of the current DCV prototype consists of two visualization areas, one each for 2 D and 3 D presentation, as well as further information areas for selected information. The GIS-related user interface functionality is made available over the ArcObjects® interface. ArcGIS® replaces the previous solution of the map and terrain presentation in 2 D and 3 D. The user interface of DCV is now controlled by a map control that employs a Scene Control and a Toolbar Control to load and handle ArcMap® and ArcScene® documents. The Toolbar Control offers the appearance and functionalities of ArcMap® and ArcScene®. Moreover, important GIS functions such as rotation, zoom or selections of geographical data are available. By means of the representation of geographical information on the basis of individual layers, the use for several areas of application is ensured, e. g. city maps as basic layers for emergency management applications. Depending upon the need, further layers can be loaded according to the desired information. Layers can now be used for static information within the DCV system. These layers can be faded in or out depending on the current situation. Dynamic objects are employed for the temporary representation in <b>graphics</b> containers. A <b>coordinated</b> representation makes the interfaces accessible to the GIS functionality of ESRI® and the additional DCV-specific linkage of map and terrain, making it possible, for example, to automatically set the camera in the 3 D terrain to the position that was clicked in the 2 D map. Thus, high-quality, original maps and terrains can now be visualized with the necessary geopositioned information in 2 D and in 3 D through the successful integration of DCV and ArcGIS®...|$|R
40|$|With the ever-expanding use of {{technology}} for communications, the demand for strong cryptographic methods is continually growing. The implementation of cryptographic algorithms in modern networked systems is crucial to ensure the security and confidentiality of data. Standardized encryption algorithms have emerged to allow users and developers a quantifiable and thoroughly tested level of security within their systems. While much {{research has been done}} to improve the security of traditional ciphers such as the Advanced Encryption Standard (AES) and the now-defunct Rivest Cipher 4 (RC 4), there are opportunities for the development and improvement of alternative ciphers based on graphic methods. Encryption using graphic methods, such as Visual Cryptography (VC) and Elliptic Curve Cryptography (ECC), give high levels of security, and demonstrate alternative approaches to achieve secure methods for the ever-expanding online world. This thesis proposes an alternative word-oriented symmetric stream cipher based on <b>graphic</b> methods called <b>Coordinate</b> Matrix Encryption (CME), which offers quantifiably high levels of security and a non-singular mapping of plaintext to ciphertext. The focus of this thesis was to explore the security offered by alternative graphic methods, in comparison to traditional classical methods, as well as the difficulties faced in implementing these alternative systems. It is hypothesized that graphic-based methods would offer higher levels of security with lower overheads than classical methods, and that the proposed CME system would prove secure against attack. The proposed system was implemented in Java along with four comparable algorithms, both graphic-based and traditional, which were AES, RC 4, ECC, and VC. The algorithms were all tested for security and efficiency, and the comparative results show the high levels of security achievable by alternative graphic-based ciphers. The resistance of the proposed 8 -bit CME system to brute force attacks was shown to be 157, 899 orders of magnitude higher than that of a 128 -bit key in traditional ciphers such as AES. Examination of the avalanche effect of the CME scheme showed that less than 0. 5 % of all bytes within the ciphertext remained in the same position when a single bit of the plaintext was altered. While the RC 4 scheme offered the best efficiency in terms of time required to encrypt and decrypt the data, the CME scheme had lower memory requirements and was faster in the setup execution. Further research into alternative graphic methods is required to explore the applications of alternative systems such as CME. The security offered by the proposed CME scheme makes it an ideal candidate for post-quantum cryptographic research. The system?s alternative key structure and non-singular mapping allow for resistance to known and chosen plaintext attacks, and these features require further exploration. Further comparative analysis between traditional and graphic-based ciphers is required to determine whether alternative graphic methods are able to offer higher security for lower overheads. Optimization of the CME scheme requires further testing, to ensure it has competitive advantage, and it is able to be implemented in application development. There is currently little standardisation in stream ciphers to replace RC 4, and as such the opportunity exists for an optimized version of CME to assist in this particular space in applications such as TLS that utilize stream ciphers for encryption on a day-to-day basis...|$|R

