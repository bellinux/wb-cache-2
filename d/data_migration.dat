688|1238|Public
25|$|CoSort Version 9 releases, {{begun in}} 2007, can {{simultaneously}} transform, convert, report, and/or protect data for ETL, business intelligence, change data capture, database load and query, application development, and <b>data</b> <b>migration</b> activities. Version 10 releases {{are expected to}} begin in 2015.|$|E
25|$|NextForm is a <b>data</b> <b>migration</b> {{spin-off}} from CoSort functionality {{designed to}} convert between structured file formats such as CSV, ISAM, LDIF, and XML, plus data types such as ASCII, EBCDIC, Unicode, and Packed Decimal. Newer NextForm editions can structure data in unstructured sources, convert COBOL Vision files, and facilitate database migration.|$|E
50|$|<b>Data</b> <b>migration</b> is {{the process}} of {{transferring}} data between computer storage types or file formats. It is a key consideration for any system implementation, upgrade, or consolidation. <b>Data</b> <b>migration</b> is usually performed programmatically to achieve an automated migration, freeing up human resources from tedious tasks. <b>Data</b> <b>migration</b> occurs for a variety of reasons, including server or storage equipment replacements, maintenance or upgrades, application migration, website consolidation and data center relocation.|$|E
5000|$|In June 2010, Capgemini {{announced}} {{the acquisition of}} Plaisir Informatique, a French company specializing in complex <b>data</b> <b>migrations</b> in the banking and insurance sector.|$|R
30|$|A secure {{process to}} gather and {{recreate}} contextualization <b>data</b> after <b>migration</b> or other events.|$|R
5000|$|ICICI Bank {{received}} the Dataquest Technology Innovation Awards 2012 for <b>Data</b> center <b>migration</b> by Dataquest.|$|R
5000|$|One-way <b>data</b> <b>migration</b> {{to easily}} move data onto Storwize V3700 ...|$|E
5000|$|Replication and <b>data</b> <b>migration</b> only {{possible}} locally to that host ...|$|E
50|$|Simple {{process of}} <b>data</b> <b>migration</b> between {{assigned}} segments of predefined storage tiers.|$|E
40|$|In the {{literature}} on housing market areas, different approaches can be found to defining them, for example, using travel-to-work areas and, more recently, making use of <b>migration</b> <b>data.</b> Here we propose a simple exercise {{to shed light on}} which approach performs better. Using regional data from Catalonia, Spain, we have computed housing market areas with both commuting <b>data</b> and <b>migration</b> <b>data.</b> In order to decide which procedure shows superior performance, we have looked at uniformity of prices within areas. The main finding is that commuting algorithms present more homogeneous areas in terms of housing prices. ...|$|R
40|$|Securely {{deleting}} {{invalid data}} from secondary storage {{is critical to}} protect users’ data privacy against unauthorized accesses. However, secure deletion is very costly for solid state drives (SSDs), which unlike hard disks do not support in-place update. When applied to SSDs, both erasure-based and cryptography-based secure deletion methods inevitably incur large amount of valid <b>data</b> <b>migrations</b> and/or block erasures, which not only introduce extra latency and energy consumption, but also harm SSD lifetime...|$|R
25|$|In October 2010 {{the company}} was named one of Computerworld's Top 12 Green-IT Organizations for its {{large-scale}} <b>data</b> center <b>migration</b> effort.|$|R
50|$|GroveSite is a DabbleDB {{alternative}} {{and offers a}} <b>data</b> <b>migration</b> service to former DabbleDB customers.|$|E
5000|$|Network Migrator —Policy-based tiered {{storage and}} data {{lifecycle}} management automated tiered storage with <b>data</b> <b>migration</b> ...|$|E
5000|$|Service Manager, {{which publishes}} and runs {{services}} {{on behalf of}} users and which executes <b>data</b> <b>migration.</b>|$|E
40|$|Software {{components}} {{developed with}} modern tools and middleware infrastructures undergo considerable reprogramming {{before they become}} reusable. Tools and methodologies are needed {{to cope with the}} evolution of software components. We present some basic concepts and architectures to handle the impacts of the evolution of UML models. With the proposed concepts a infrastructure to support model evolution, <b>data</b> schema <b>migration,</b> and <b>data</b> instance <b>migration</b> based on UML models can be realized. To describe the evolution path we use XML/XMI files...|$|R
3000|$|Alecke et al. (2010) augment Blanchard and Katz’s (1992) {{model with}} a <b>migration</b> equation. Unfortunately, <b>data</b> on <b>migrations</b> is not {{available}} for Spain at quarterly frequencies.|$|R
3000|$|Data {{confidentiality}} during migrating the VM: In {{order to}} prevent a man-in-the-middle attack from getting any sensitive information, all <b>data</b> during <b>migration</b> must be encrypted [...]...|$|R
50|$|Sunopsis {{products}} provide {{solutions for}} data warehousing, data integration, <b>data</b> <b>migration,</b> data synchronization and Master data management.|$|E
50|$|On October 14, 2010, GE {{announced}} {{the acquisition of}} <b>data</b> <b>migration</b> & SCADA simulation specialists Opal Software.|$|E
5000|$|Replication and <b>data</b> <b>migration</b> only {{possible}} across the connected controllers and same vendors device for long distance support ...|$|E
40|$|Since its release, Spring Framework has {{transformed}} virtually {{every aspect of}} Java development including web applications, security, aspect-oriented programming, persistence, and messaging. Spring Batch, one of its newer additions, now brings the same familiar Spring idioms to batch processing. Spring Batch addresses the needs of any batch process, from the complex calculations performed in the biggest financial institutions to simple <b>data</b> <b>migrations</b> that occur with many software development projects. Pro Spring Batch is intended to answer three questions: *What? What is batch processing? Wha...|$|R
5000|$|<b>Data</b> {{classification}} and <b>migration</b> using TSM automation features ...|$|R
50|$|Managed {{services}} include dedicated servers, <b>data</b> center <b>migrations,</b> {{switch and}} router maintenance, VMware, storage, high-availability load balancers, backup and recovery, remote hands, firewalls, and application, service, and infrastructure monitoring.|$|R
50|$|To {{achieve an}} {{effective}} <b>data</b> <b>migration</b> procedure, {{data on the}} old system is mapped to the new system utilising a design for data extraction and data loading. The design relates old data formats to the new system's formats and requirements. Programmatic <b>data</b> <b>migration</b> may involve many phases but it minimally includes data extraction where data is read from the old system and data loading where data is written to the new system.|$|E
50|$|Data Verification is {{a process}} in which {{different}} types of data are checked for accuracy and inconsistencies after <b>data</b> <b>migration</b> is done.|$|E
50|$|Most {{implementations}} {{will provide}} {{some form of}} back-out procedure and with the <b>data</b> <b>migration</b> services {{it is at least}} possible, but time consuming.|$|E
5000|$|<b>Data</b> on <b>migration</b> and {{remittance}} flows: The {{focus here}} is on improving the availability, accessibility, {{and scope of}} data collection as well as establishing and harmonizing data and quality standards.|$|R
30|$|To obtain <b>data</b> about <b>migration</b> of {{impurity}} ions and intrinsic {{defects in}} the disordered area of MCT heteroepitaxial layer, the authors performed a model experiment by applying program packages TRIM_ 2008.|$|R
40|$|Includes bibliographyThis {{paper is}} to assist governments and other {{concerned}} parties in the subregion to identify, at the national and regional levels, already existing mechanisms for <b>migration</b> <b>data</b> collection, management and sharing and to provide guidance on how to identify and bridge the still existing information gaps on <b>migration</b> <b>data</b> in the subregio...|$|R
5000|$|SanXfer by InQuinox is an {{automated}} server and <b>data</b> <b>migration</b> tool for P2V, V2P, and P2P with complete (server and storage) hardware independence.|$|E
50|$|There {{are many}} {{day to day}} tasks a storage {{administrator}} has to perform that can be simply and concurrently performed using <b>data</b> <b>migration</b> techniques.|$|E
5000|$|CUBRID Migration Toolkit {{is a tool}} {{which allows}} <b>data</b> <b>migration</b> from MySQL and {{previous}} versions of CUBRID databases to the latest CUBRID database server ...|$|E
50|$|Long-term storage systems {{require the}} timely {{planning}} and regular performance of <b>data</b> <b>migrations,</b> {{in order to}} keep information available in the changing technical landscape. As storage technologies fall into disuse, information must be moved to newer forms of storage, so that the stored information remains accessible using contemporary systems. For example, data stored on floppy disks becomes essentially unusable, if floppy disk drives are no longer readily available; migrating the data stored on floppy disks to Compact Discs preserves not only the data but the ability to access it. This ongoing process is called continuous migration.|$|R
40|$|This {{paper is}} to make further {{research}} on facilitating the large-scale scientific computing on the grid and the desktop grid platform. The related issues include the programming method, the overhead of the high-level program interface based middleware, and the <b>data</b> anticipate <b>migration.</b> The block based Gauss Jordan algorithm as a real example of large-scale scientific computing is used to evaluate those issues presented above. The {{results show that the}} high-level based program interface makes the complex scientific applications on large-scale scientific platform easier, though a little overhead is unavoidable. Also, the <b>data</b> anticipation <b>migration</b> mechanism can improve the efficiency of the platform which needs to process big data based scientific applications...|$|R
2500|$|Level 1C (regional) {{represents}} repository <b>data</b> {{ready for}} <b>migration</b> {{to the state}} repository level ...|$|R
