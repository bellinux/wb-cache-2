9|177|Public
25|$|A {{working group}} {{consisting}} of van de Kerkhof, Stoll, Italian Leonardo Chiariglione (CSELT VP for Media), Frenchman Yves-François Dehery, German Karlheinz Brandenburg, and American James D. Johnston (United States) took ideas from ASPEC, integrated the filter bank from Layer II, added {{some of their}} own ideas such as the <b>joint</b> <b>stereo</b> <b>coding</b> of MUSICAM and created the MP3 format, which was designed to achieve the same quality at 128kbit/s as MP2 at 192kbit/s.|$|E
50|$|This {{reduces the}} data rate to 66 kbit/s (half that of LP2), partly by using <b>joint</b> <b>stereo</b> <b>coding</b> and a lowpass filter around 13.5 kHz. It allows 324 minutes to be {{recorded}} on an 80-minute MiniDisc, with the same padding required as LP2.|$|E
50|$|The bitrate of the {{standard}} SP mode is 292 kbit/s, and it uses separate stereo coding with discrete left and right channels. LP2 mode uses a bitrate of 132 kbit/s and also uses separate stereo coding. The last mode, LP4, has a bitrate of 66 kbit/s and uses <b>joint</b> <b>stereo</b> <b>coding.</b> The sound quality is noticeably poorer than the first two modes, but is sufficient for many uses.|$|E
50|$|This form of <b>joint</b> <b>stereo</b> uses a {{technique}} known as joint frequency encoding, which functions {{on the principle}} of sound localization. Human hearing is predominantly less acute at perceiving the direction of certain audio frequencies. By exploiting this characteristic, intensity <b>stereo</b> <b>coding</b> can reduce the data rate of an audio stream with little or no perceived change in apparent quality.|$|R
50|$|The idea is {{to merge}} a given {{frequency}} range of multiple sound channels together so that the resulting encoding will preserve the sound information of that range not as a bundle of separate channels but as one homogeneous data stream. This will destroy the original channel separation permanently, as the information cannot be accurately reconstructed, but will greatly lessen the amount of required storage space. Only some forms of <b>joint</b> <b>stereo</b> use the <b>joint</b> frequency encoding technique, such as intensity <b>stereo</b> <b>coding.</b>|$|R
40|$|In this paper, we {{investigated}} {{the influence of}} <b>stereo</b> <b>coding</b> on Japanese speech localized in 3 -D virtual space. We encoded localized speech using <b>Joint</b> <b>Stereo</b> and Parametric Stereo modes within the HE-AAC (High-Efficiency Advanced Audio Coding) encoder at identical data rates. First, the sound quality of the localized speech signal was checked using MUSHRA subjective tests. The result showed that the speech quality for <b>Joint</b> <b>Stereo</b> is higher than Parametric Stereo when localized at 45 (where 0 refers to localization {{directly in front of}} the listener) by 20 to 30 MUSHRA score points. The scores for <b>Joint</b> <b>Stereo</b> were relatively proportional to bit rate. However, Parametric Stereo scores were not proportional to bit rate, and remained fairly constant with bit rate. Next, the Japanese word intelligibility tests were conducted using the Japanese Diagnostic Rhyme Tests (JDRT). Test speech was localized in front, while competing noise were localized at various angles. The result showed that speech could not be separated from the noise for <b>Joint</b> <b>Stereo</b> when the noise was in located in the frontal region, from 45 to 45, and intelligibility degrades significantly. However at other azimuth, the intelligibility improves dramatically. On the other hand, intelligibility with Parametric Stereo remained constant, at about 70 to 80 %. 1...|$|R
50|$|A {{working group}} {{consisting}} of van de Kerkhof, Stoll, Italian Leonardo Chiariglione (CSELT VP for Media), Frenchman Yves-François Dehery, German Karlheinz Brandenburg, and American James D. Johnston (United States) took ideas from ASPEC, integrated the filter bank from Layer II, added {{some of their}} own ideas such as the <b>joint</b> <b>stereo</b> <b>coding</b> of MUSICAM and created the MP3 format, which was designed to achieve the same quality at 128 kbit/s as MP2 at 192 kbit/s.|$|E
40|$|Applying <b>joint</b> <b>stereo</b> <b>coding</b> {{techniques}} {{for the low}} bitrate coding of audio signals can lead to significant improvements in the perceived sound quality. Nevertheless, some pitfalls {{for the use of}} these techniques should be taken into account in order to avoid coding artifacts. The combined (MS/Intensity) <b>joint</b> <b>stereo</b> <b>coding</b> techniques implemented in Layer III of the ISO/MPEG/Audio coder will be described...|$|E
30|$|Since 1990, <b>joint</b> <b>stereo</b> <b>coding</b> {{algorithm}} {{has been}} widely used in the two-channel audio coding. Various techniques {{have been developed for}} compressing stereo or multichannel audio signals. Recently, the ISO/MPEG standardization group has published a new audio standard, that is, MPEG Surround, which is a feature-rich open standard compression technique for multichannel audio signals [1]. MPEG Surround coding can be regarded as an enhancement of the <b>joint</b> <b>stereo</b> <b>coding</b> and an extension of BCC [[2, 5]]. BCC exploits binaural cue parameters for capturing the spatial image of multichannel audio and enables low-bit-rate transmission by transmitting mono signals plus side information in relation to binaural perception.|$|E
40|$|Presented at the 15 th International Conference on Auditory Display (ICAD 2009), Copenhagen, Denmark, May 18 - 22, 2009 In this paper, we {{investigated}} {{the influence of}} <b>stereo</b> <b>coding</b> on Japanese speech localized in 3 -D virtual space. We encoded localized speech using <b>Joint</b> <b>Stereo</b> and Parametric Stereo modes within the HE-AAC (High-Efficiency Advanced Audio Coding) encoder at identical data rates. First, the sound quality of the localized speech signal was checked using MUSHRA subjective tests. The result showed that the speech quality for <b>Joint</b> <b>Stereo</b> is higher than Parametric Stereo when localized at 45 (where 0 refers to localization {{directly in front of}} the listener) by 20 to 30 MUSHRA score points. The scores for <b>Joint</b> <b>Stereo</b> were relatively proportional to bit rate. However, Parametric Stereo scores were not proportional to bit rate, and remained fairly constant with bit rate. Next, the Japanese word intelligibility tests were conducted using the Japanese Diagnostic Rhyme Tests (JDRT). Test speech was localized in front, while competing noise were localized at various angles. The result showed that speech could not be separated from the noise for <b>Joint</b> <b>Stereo</b> when the noise was in located in the frontal region, from 45 to 45, and intelligibility degrades significantly. However at other azimuth, the intelligibility improves dramatically. On the other hand, intelligibility with Parametric Stereo remained constant, at about 70 to 80 %...|$|R
5000|$|Layer II {{can also}} {{optionally}} use intensity <b>stereo</b> <b>coding,</b> {{a form of}} <b>joint</b> <b>stereo.</b> This means that the frequencies above 6 kHz of both channels are combined/down-mixed into one single (mono) channel, but the [...] "side channel" [...] information on the relative intensity (volume, amplitude) of each channel is preserved and encoded into the bitstream separately. On playback, the single channel is played through left and right speakers, with the intensity information applied to each channel to give the illusion of stereo sound. This perceptual trick is known as stereo irrelevancy. This can allow further reduction of the audio bitrate without much perceivable loss of fidelity, but is generally not used with higher bitrates as it does not provide very high quality (transparent) audio.|$|R
50|$|When used {{within the}} MP3 {{compression}} process, <b>joint</b> <b>stereo</b> normally employs multiple techniques, and can switch between them for each MPEG frame. Typically, a modern encoder's <b>joint</b> <b>stereo</b> mode uses M/S stereo for some frames and L/R stereo for others, whichever method yields the best result. Encoders use different algorithms {{to determine when}} to switch and how much space to allocate to each channel; quality can suffer if the switching is too frequent or if the side channel doesn't get enough bits. With some encoding software, {{it is possible to}} force the use of M/S stereo for all frames, mimicking the <b>joint</b> <b>stereo</b> mode of some early encoders like Xing. Within the LAME encoder, this is known as forced <b>joint</b> <b>stereo.</b>|$|R
40|$|Spatial audio coding is {{the most}} recent {{parametric}} extension to waveform coding. This paper describes the ideas behind this technique, starting with {{a brief review of}} the basic concept of using parametric tools for waveform coder enhancement followed by a more detailed description of spatial audio coding, outlining its relation to existing schemes for reproduction of multi-channel audio via transmission of non-multi-channel material. Furthermore the evolution of traditional techniques for <b>joint</b> <b>stereo</b> <b>coding</b> towards spatial audio coding for multi channel audio will be summarized. The paper provides some performance data of this type of technology and describes first commercial applications. Ongoing activities of the ISO/MPEG standardization group in this field will be reported...|$|E
40|$|Perceptual coder {{promise to}} deliver true {{transparent}} coding. The listener {{should not be}} able to hear any difference between original and reconstructed signal. The main elements of perceptual coders are a filterbank to map the time domain input signal to a time-frequency domain representation (i. e., the masked threshold) and the quantization and coding step that should include proper noise shaping according to the psychoacoustic model. An overview of current and future audio coding systems is given. The completion of ISO/IEC 11172 - 3 (the MPEG- 1 audio coding standard) marks the end of the work on the first generation of audio coding systems. While audio coding is on the way to widespread application, topics for the new coding systems include <b>joint</b> <b>stereo</b> <b>coding</b> of two or more channels, different analysis-by-synthesis systems, and improved psychoacoustic models...|$|E
40|$|This {{analysis}} of the audio quality of DAB has been made independently of the broadcasting companies and aims at balancing their information. Through measurement of the audio signal and through informal listening, {{we have found that}} DAB suffers from several problems: • The stereo image is smeared due to heavy use of <b>joint</b> <b>stereo</b> <b>coding.</b> Often the stereo image lacks focus and gives incorrect localization of instruments, in certain cases there is also incorrect balance between a vocalist and the background music. • The treble cut-off frequency is usually as low as 14 kHz and the result is a lack of brightness and a veiled sound stage. In particular young people will notice this degradation. As young people are the target group for some of these stations, such as P 3, this must be considered to be very undesirable. The reason is that the bit rates for all the channels in the Norwegian DAB network today are much lower than what scientific evaluation of audio quality has recommended, i. e. lower than 192 - 256 kbps which was projected when DAB was debated in Stortinget (Norwegian Parliament) in 1998. When the capacity is fully utilized, stations with music in the Oslo area use these bit rates: • Three stations use 160 kbps with an audio quality similar to FM: P 2, Alltid Klassisk 1 and P 4 • Twelve stations use 128 kbps with lower quality than FM, incl. P 1 and P 3. • Two stations transmit in mono at rates of 80 and 96 kbps (Radio 2 Digital Moox and NRK Barn 2) It would have been desirable to stop using 128 kbps as the standard bit rate for music, and use 160 kbps instead. More demanding material should have the same quality as mp 3 at 128 kbps, i. e. 192 kbps in DAB. As of today, there is not capacity to increase bit rates to these levels, so the DAB network has too low capacity with respect to requirements for decent audio quality. The broadcast companies want us to make a choice between FM, with the best audio quality in stationary receivers, and DAB which is best in a car. Today this is an unnecessary choice as there are no technological problems in making a digital radio which is better than FM on all accounts: • Reception without garbling in cars • Capacity for all the stations one wants • Audio with near-CD qualit...|$|E
5000|$|M/S <b>stereo</b> <b>coding</b> {{transforms}} {{the left and}} right channels into a mid channel and a side channel. The mid channel is the sum of {{the left and right}} channels, or [...] The side channel is the difference of the left and right channels, or [...] Unlike intensity <b>stereo</b> <b>coding,</b> M/S coding is a special case of transform coding, and retains the audio perfectly without introducing artifacts. Lossless codecs such as FLAC or Monkey's Audio use M/S <b>stereo</b> <b>coding</b> because of this characteristic.|$|R
25|$|<b>Joint</b> <b>stereo</b> is {{done only}} on a frame-to-frame basis.|$|R
5000|$|More {{flexible}} <b>joint</b> <b>stereo</b> (different {{methods can}} be used in different frequency ranges) ...|$|R
50|$|The term <b>joint</b> <b>stereo</b> {{has become}} {{prominent}} as the Internet has {{allowed for the}} transfer of relatively low bit rate, acceptable-quality audio with modest Internet access speeds. <b>Joint</b> <b>stereo</b> refers to any number of encoding techniques used for this purpose. Two forms are described here, {{both of which are}} implemented in various ways with different codecs, such as MP3, AAC and Ogg Vorbis.|$|R
50|$|In {{addition}} to Layer II's intensity encoded <b>joint</b> <b>stereo,</b> MP3 can use middle/side (mid/side, m/s, MS, matrixed) <b>joint</b> <b>stereo.</b> With mid/side stereo, certain frequency ranges of both channels are merged {{into a single}} (middle, mid, L+R) mono channel, while the sound difference between {{the left and right}} channels is stored as a separate (side, L-R) channel. Unlike intensity stereo, this process does not discard any audio information. When combined with quantization, however, it can exaggerate artifacts.|$|R
30|$|Since most audio {{material}} {{is produced in}} <b>stereo,</b> an efficient <b>coding</b> tool should also exploit the redundancies and irrelevancies of both channels simultaneously. Since it is not straightforward to use standard <b>stereo</b> <b>coding</b> tools like mid/side stereo [51] and intensity stereo [52] in conjunction with parametric coding, and since the aim also {{was to develop a}} general <b>stereo</b> <b>coding</b> tool for low bit rates, the novel Parametric Stereo (PS) tool was developed where the <b>stereo</b> image is <b>coded</b> on the basis of spatial cues. The PS tool as standardized in MPEG was developed in 2003 and primarily aimed to enhance the performance of SSC and HE-AAC at low bit rates.|$|R
50|$|As with MP3, Ogg Vorbis stereo files can employ either L/R <b>stereo</b> or <b>joint</b> <b>stereo.</b> When using <b>joint</b> <b>stereo,</b> both M/S {{stereo and}} {{intensity}} stereo methods may be used. As opposed to MP3 where M/S stereo (when used) is applied before quantization, an Ogg Vorbis encoder applies M/S stereo to samples {{in the frequency}} domain after quantization, making application of M/S stereo a lossless step. After this step, any frequency area {{can be converted to}} intensity stereo by removing the corresponding part of the M/S signal's side channel. Ogg Vorbis' floor function will take care of the required left-right panning.|$|R
50|$|MoonShell plays videos at 20fps (higher frame {{rates are}} {{possible}} but slowdown may occur, especially in video scenes {{with a lot}} of motion), with <b>joint</b> <b>stereo</b> sound at a sample rate of 32.768 kHz.|$|R
50|$|HE-AAC profile {{was first}} {{standardized}} in ISO/IEC 14496-3:2001/Amd 1:2003. HE-AAC v2 profile (HE-AAC with Parametric Stereo) was first specified in ISO/IEC 14496-3:2005/Amd 2:2006. The Parametric <b>Stereo</b> <b>coding</b> tool used by HE-AAC v2 was standardized in 2004 and published as ISO/IEC 14496-3:2001/Amd 2:2004.|$|R
50|$|AAC-LD {{can also}} process stereo signals {{by using the}} {{advanced}} <b>stereo</b> <b>coding</b> tools of AAC. Thus {{it is possible to}} transmit a stereo signal with a bandwidth of 7 kHz via one ISDN line or with a bandwidth of 15 kHz via two ISDN lines.|$|R
50|$|Lossless data {{compression}} {{is used in}} many applications. For example, it {{is used in the}} ZIP file format and in the GNU tool gzip. It is also often used as a component within lossy {{data compression}} technologies (e.g. lossless mid/side <b>joint</b> <b>stereo</b> preprocessing by the LAME MP3 encoder and other lossy audio encoders).|$|R
40|$|The method {{involves}} {{grouping of}} the stereo audio spectral values in scale factor bands, before coding via an intensity-stereo method, {{so that one}} channel carries the intensity-stereo <b>coded</b> <b>stereo</b> audio spectral values and the other channel carries stereo audio spectral values equal to zero. The intensity-stereo <b>coded</b> <b>stereo</b> audio <b>coded</b> values are decoded for each scale factor band and a prediction method is used to provide the <b>coded</b> <b>stereo</b> audio spectral values for the other channel. ADVANTAGE - Reduced bit rate for increased data transmission rate without impaired quality...|$|R
40|$|Significant perceptual {{improvements}} can {{be gained}} in the coding of stereoscopic videos, as is illustrated here by modifying the adaptive quantization of an MPEG- 2 codec. Applying human visual properties to MPEG- 2 's temporal scalability framework, a perceptual adaptive quantization approach to stereoscopic video coding is presented. To optimize the perceived picture {{quality of the}} reconstructed stereo images, binocular visibility of <b>stereo</b> <b>coding</b> artifacts is investigated, including image fusion and visual masking. Four normalized indicators are introduced to account for 3 D visual artifacts, and are incorporated to determine the quantization parameters. They are (1) prediction accuracy, (2) prediction correlation, (3) fusion indicator, and (4) texture intensity. Simulations indicate the importance of perceptual <b>stereo</b> <b>coding,</b> with improvements in overall stereo quality and reductions in binocular artifacts. 1. INTRODUCTION Motivated {{by the idea of}} a combination 3 D system and HDTV, we [...] ...|$|R
5000|$|... theJazz started test {{transmissions}} {{on all the}} platforms {{it would}} broadcast on in December 2006. The test transmissions consisted of Lindos Electronics test tones and an announcement of the forthcoming launch. From the commencement of broadcast to December 2007, it broadcast on DAB at a bit rate of 96 kbit/s in mono. From December 2007, this was increased to 128 kbit/s in <b>joint</b> <b>stereo.</b>|$|R
40|$|Abstract — Wyner-Ziv coding, {{also known}} as {{distributed}} video coding, is currently a very hot research topic in video coding due to the new opportunities it opens. This paper applies the distributed video <b>coding</b> principles to <b>stereo</b> video <b>coding,</b> to propose a practical solution for Wyner-Ziv <b>stereo</b> <b>coding</b> based on mask-based fusion of temporal and spatial side informations. The architecture includes a low-complexity encoder and avoids any communication between the cameras/encoders. While the rate-distortion (RD) performance strongly depends on the motion-based frame interpolation (MBFI) and disparity-based frame estimation (DBFE) solutions, first {{results show that the}} proposed approach is promising and there are still issues to address. ...|$|R
50|$|HE-AAC version 1 was {{standardized}} as {{a profile}} of MPEG-4 Audio in 2003 by MPEG and published as part of MPEG-4 in document ISO/IEC 14496-3:2001/Amd 1:2003. The HE-AAC version 2 profile was standardized in 2006 as ISO/IEC 14496-3:2005/Amd 2:2006.A parametric <b>stereo</b> <b>coding</b> tool used in HE-AAC v2 was standardized in 2004 by MPEG and published in document ISO/IEC 14496-3:2001/Amd 2:2004.|$|R
40|$|Almost all voice {{communications}} {{are based}} on monophonic narrowband speech. Wideband stereophonic communications provide a more natural sounding environment. This holds especially true for teleconferencing applications, where the localization information in the stereo signal adds {{a new dimension to}} the communication. As of today, there is no standardized speech codec with full stereo support. Statistical analysis shows that there exists correlation between left and right channels of a stereo speech signal. Instead of coding both channels independently (2 x mono bitrate) stereo parameters are extracted which, combined with the mono signal, allows for low bit rate stereo reproduction. This thesis report describes a parametric <b>stereo</b> <b>coding</b> algorithm. The algorithm, which is targeted at conversational applications such as teleconferencing, reproduces the stereo signal from a down-mixed mono signal and additional stereo parameters. During the thesis work, different <b>stereo</b> <b>coding</b> methods have been studied and evaluated. Given design constraints such as low complexity, low delay and low bit rate...|$|R
40|$|The ISO/MPEG phases 1 and 2 audio {{compression}} is receiving {{a wide range}} of applications. In the encoding process of MPEG, the psychoacoustic model exploits audio irrelevancy which is the key role to achieve high compression ratio without losing audio quality. However, the Fourier transform (FT) which has been used by the two psychoacoustic models suggested in standard draft requires high computational complexity which leads to high hardware and software cost for real-time applications. This paper presents a new design named the hybrid filter bank to replace the FT. The hybrid filter bank can be integrated with the psychoacoustic models and provides a much lower complexity than the FT. Also, this paper shows that the hybrid filter is more suitable for the <b>stereo</b> <b>coding</b> and hence can provide a better quality for the intensity <b>stereo</b> <b>coding,</b> which is the key technology for the MPEG 1 to achieve near transparent quality lower than 96 x 2 Kbits for two stereo channels...|$|R
50|$|If the {{difference}} between the left and right channels is small, the side channel will be small, which will offer as much as a 50% bitrate savings, and associated quality improvement. If {{the difference}} between left and right is large, standard (discrete, left/right) stereo encoding may be preferred, as mid/side <b>joint</b> <b>stereo</b> will not provide any benefits. An MP3 encoder can switch between m/s stereo and full stereo on a frame-by-frame basis.|$|R
40|$|The coding {{method has}} the stereo audio {{spectral}} values grouped into scale factor bands (28), with formation of sections each containing {{at least one}} scale factor band. The audio spectral values are coded within each section using a coding table selected {{from a number of}} coding tables. Each coding table is identified by a coding table number transmitted alongside the <b>coded</b> <b>stereo</b> audio spectral values. An additional coding table number is transmitted for an intensity <b>stereo</b> <b>coding</b> method, or an adaptive Huffman coding method for the stereo audio spectral values. ADVANTAGE - Provides compression of audio digital signals without quality degradation...|$|R
40|$|This thesis {{presents}} a <b>stereo</b> <b>coding</b> architecture for the ITU-T G. 719 fullband mono codec. G. 719 {{is suitable for}} teleconferencing applications with a competitive audio quality for speech and audio signals that are encoded at 32, 48 and 64 kbps. The proposed stereo architecture comprises parametric <b>stereo</b> <b>coding</b> where the spatial properties of the stereo channels are modeled {{with the use of}} parameters, which are encoded and transmitted to the decoder together with an encoded downmix of the stereo channels. The stereo architecture has been implemented in MATLAB with an external mono coding using a floating point ANSI-C implementation of the ITU-T G. 719 codec. Two parametric stereo models have been implemented in a framework operating in the complex-valued Modified Discrete Fourier Transform (MDFT) domain. The first model is based on the inter-channel cues that represent level differences, time differences and coherences between the stereo channels. The cues approximate the corresponding interaural cues that characterize our localization of sound in space. The second model is based on the Karhunen-Loève Transform (KLT) with the associated rotation angles, the inter-channel time differences and the residual scaling parameters. An improved MDFT domain extraction of the inter-channel time difference between the stereo channels has been used for both stereo models. The extracted stereo parameters have been non-uniformly quantized based on the spatial accuracy and the frequency dependency of the human auditory system. The data rate of the stereo parameters has been estimated for each model to around 4 kbps. As a result G. 719 {{has been used as a}} core codec at 44 and 60 kbps in order to subjectively evaluate the performance of the fullband stereo codec at 48 and 64 kbps. In the comparison with G. 719 dual mono coding, i. e. independent mono <b>coding</b> of the <b>stereo</b> channels, the evaluation showed a higher performance of the proposed stereo models for complex clean and reverberant speech signals. However, no consistent gain of the parametric <b>stereo</b> <b>coding</b> was revealed for noisy speech, mixed content and music signals. In addition, the first stereo model showed consistently a slightly higher performance than the second model in the subjective evaluation but with no significant difference. The results revealed a high potential for parametric <b>stereo</b> <b>coding</b> using the ITU-T G. 719 codec. In comparison to the existing stereo codecs 3 GPP AMR-WB+ and 3 GPP eAAC+ the average performance was better at the equal bitrate of 48 kbps...|$|R
