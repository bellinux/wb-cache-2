2|247|Public
40|$|In {{this paper}} we study the {{behavior}} of local <b>descriptor</b> <b>object</b> recognition methods with respect to 3 D geometric transformations and image resolution variations. As expected performance decreases with accentuated perspective and decrease in resolution. To improve performance and robustness, we propose a scheme to fuse color and gradient local descriptors. This approach is motivated by the discriminative power of color in man-made object recognition. The problem of color feature extraction is addressed {{as well as the}} considerations on the fusion process and steps to train such fusion. We used SOIL- 47 A database for experiments and shown a 7 % to 10 % relative improvement when compared with state-of-the-art gradient based descriptors. 1...|$|E
40|$|Abstract—In the {{diagnosis}} of skin melanoma by analyzing histopathological images, the detection of the melanocytes in the epidermis area is an important step. However, the detection of melanocytes in the epidermis area is difficult because other ker-atinocytes that {{are very similar to}} the melanocytes are also present. This paper proposes a novel computer-aided technique for segmen-tation of the melanocytes in the skin histopathological images. In order to reduce the local intensity variant, a mean-shift algorithm is applied for the initial segmentation of the image. A local re-gion recursive segmentation algorithm is then proposed to filter out the candidate nuclei regions based on the domain prior knowl-edge. To distinguish the melanocytes from other keratinocytes in the epidermis area, a novel descriptor, named local double ellipse descriptor (LDED), is proposed to measure the local features of the candidate regions. The LDED uses two parameters: region elliptic-ity and local pattern characteristics to distinguish the melanocytes from the candidate nuclei regions. Experimental results on 28 dif-ferent histopathological images of skin tissue with different zoom-ing factors show that the proposed technique provides a superior performance. Index Terms—Histopathological image analysis, image segmen-tation, local <b>descriptor,</b> <b>object</b> detection, pattern recognition. I...|$|E
40|$|<b>Object</b> <b>descriptor</b> {{has become}} one of the key factors for a robust and {{accurate}} tracker. In this paper, we propose an <b>object</b> <b>descriptor</b> combining color information and motion detection. A tracked object can be described by its hue histogram excluding the background pixels around the tracked object for restraining the disturbing of complex background environments. During the tracking process, we model the <b>object</b> <b>descriptor</b> by Gaussian Mixture Model for adapting the appearance variation of the tracked object. Tracking experiments in the frame of particle filter show that our proposed <b>object</b> <b>descriptor</b> can effectively improve the robustness and accuracy of object tracking under the situations of complex environments and appearance variations...|$|R
5000|$|... object table {{identifies}} the system's collection of active <b>object</b> <b>descriptors</b> ...|$|R
40|$|Abstract—We {{present an}} {{algorithm}} for tracking video objects {{which is based}} on a hybrid strategy. This strategy uses both object and region information to solve the correspondence problem. Low-level descriptors are exploited to track object’s regions and to cope with track management issues. Appearance and disappearance of objects, splitting and partial occlusions are resolved through inter-actions between regions and objects. Experimental results demon-strate that this approach has the ability to deal with multiple de-formable objects, whose shape varies over time. Furthermore, it is very simple, because the tracking is based on the descriptors, which represent a very compact piece of information about regions, and they are easy to define and track automatically. Finally, this proce-dure implicitly provides one with a description of the objects and their track, thus enabling indexing and manipulation of the video content. Index Terms—Indexing, low level <b>descriptors,</b> <b>object</b> segmenta-tion, object tracking. I...|$|R
40|$|In today’s {{object-oriented}} programming languages {{the relations between}} objects are often implicit and scattered over multiple classes. This creates a gap between design, where relationships are more explicit, and implementation. Programs become not only harder to understand but also more difficult to modify. We present a programming technique that allows programmers to make relationships explicit by assigning roles to participating objects and dynamically mixing new fields and methods into existing objects with delegation semantics. Our approach builds upon commonly available language constructs and is implemented as a Scala library, such {{that it can be}} easily adopted in practical settings. Categories and Subject <b>Descriptors</b> <b>object...</b>|$|R
40|$|Detection and {{recognition}} of moving objects using statistical motion detection and Fourier <b>descriptors</b> <b>Object</b> recognition, i. e. classification of objects into one of several known object classes, generally is a difficult task. In this paper we {{address the problem of}} detecting and classifying moving objects in image sequences from traffic scenes recorded with a static camera. In the first step, a statistical, illumination invariant motion detection algorithm is used to produce binary masks of the scene–changes. Next, Fourier descriptors of the shapes from the refined masks are computed and used as feature vectors describing the different objects in the scene. Finally, a feed–forward neural net is used to distinguish between humans, vehicles, and background clutters. ...|$|R
50|$|The {{objects that}} an {{application}} made available through its AEOM support were {{arranged in a}} hierarchy. At the top was the application itself, referenced via a null <b>object</b> <b>descriptor.</b> Other <b>objects</b> were referenced by (recursively) specifying their parent object, together with other information identifying it as a child of that parent, all collected in an AERecord. An iterator was provided by parents to enumerate their children, or children of a certain class, allowing applications to address a set of elements. The system was generally similar to the Document Object Model used in XML, although with some differences in access patterns.|$|R
30|$|With less {{feature vector}} size, the {{proposed}} <b>descriptor</b> enables the <b>object</b> recognition {{system to be}} efficient with less APT and AFDR measures.|$|R
40|$|We {{present a}} {{multiple}} object tracking algorithm working with occlusions. Firstly, for each detected object we compute feature points using FAST algorithm [1]. Secondly, for each feature point we build a descriptor based on Histogram of Oriented Gradients (HOG) [2]. Thirdly, we track feature points using these <b>descriptors.</b> <b>Object</b> tracking is possible even if objects are occluded. If few objects are merged and detected {{as a single}} one, we assign newly detected feature points in such single object {{to one of these}} occluded objects. We apply a probabilistic method for this task using information from the previous frames like object size and motion (speed and orientation). We use multi resolution images to decrease the processing time. Our approach is tested on the synthetic video sequence, the KTH dataset [3] and the CAVIAR dataset [4]. All tests confirm the effectiveness of our approach. ...|$|R
40|$|We {{present an}} {{approach}} for automatic annotation of commercial videos from an arts-and-crafts domain {{with the aid}} of textual descriptions. The main focus is on recognizing both manipulation actions (e. g. cut, draw, glue) and the tools that are used to perform these actions (e. g. markers, brushes, glue bottle). We demonstrate how multiple visual cues such as motion <b>descriptors,</b> <b>object</b> presence, and hand poses can be combined with the help of contextual priors that are automatically extracted from associated transcripts or online instructions. Using these diverse features and linguistic information we propose several increasingly complex computational models for recognizing elementary manipulation actions and composite activities, as well as their temporal order. The approach is evaluated on a novel dataset of comprised of 27 episodes of PBS Sprout TV, each containing on average 8 manipulation actions. 1...|$|R
40|$|International audienceWe present SOS, the {{operating}} system for SOMIW (Secure Open Multimedia Integrated Workstation). The SOS is object-structured; all services and communication is {{expressed in terms of}} passive objects with procedural interfaces. Resources are accessed by clients via a local (to the client) proxy object. The possibly distributed or group nature of the resource is hidden behind the proxy interface. The service and its representatives form a single distributed object (or group); any communication protocol is hidden, as part of its internal representation. The proxy is a programmable capability and may be different per-client. This approach also allows the programmer of a resource to cope with the heterogeneous nature of its clients. The OS is based on a kernel which implements contexts, processes, memory segments and <b>object</b> <b>descriptors.</b> <b>Object</b> invocation normally occurs within one context, but may trap transparently into an other context...|$|R
40|$|International audienceWe {{present an}} {{algorithm}} for tracking multiple objects through occlusions. Firstly, for each detected object we compute feature points using the FAST algorithm [1]. Secondly, for each feature point we build a descriptor {{based on the}} Histogram of Oriented Gradients (HOG) [2]. Thirdly, we track feature points using these <b>descriptors.</b> <b>Object</b> tracking is possible even if objects are occluded. If few objects are merged and detected as a single one, we assign each newly detected feature point in such single object {{to one of these}} occluded objects. We apply probabilistic methods for this task, using information from the previous frames like object size and motion (speed and orientation). We use multi resolution images to decrease the processing time. Our approach is tested on the synthetic video sequence, the KTH dataset [3] and the CAVIAR dataset [4]. All tests confirm the effectiveness of our approach...|$|R
40|$|Thesis (MScEng (Electrical and Electronic Engineering)) [...] University of Stellenbosch, 2006. This thesis {{relates to}} the {{development}} of an automated sorting cell as part of a flexible manufacturing line, with the use of object recognition. Algorithms for each of the individual subsections creating the cell, recognition, position calculation and robot integration were developed and tested. The Fourier <b>descriptors</b> <b>object</b> recognition technique is investigated and used. Invariance to scale, rotation or translation of the boundary of an object recognition. Stereoscopy with basic trigonometry is used to calculate the position of recognised objects, after which they are handled by a robot. Integration of the robot into the project environment is done with trigonometry as well as Euler angles. It is shown that a successful, automated sorting cell can be constructed with object recognition. The results show that reliable sorting can be done with available hardware and the algorithms development...|$|R
5000|$|Shape {{context is}} a feature <b>descriptor</b> used in <b>object</b> recognition. Serge Belongie and Jitendra Malik {{proposed}} {{the term in}} their paper [...] "Matching with Shape Contexts" [...] in 2000.|$|R
5000|$|In this journal, authors {{proposed}} {{a new approach}} to use SIFT <b>descriptors</b> for multiple <b>object</b> detection purposes. The proposed multiple object detection approach is tested on aerial and satellite images.|$|R
40|$|A deep {{understanding}} of human activity is key to successful human-robot interaction (HRI). The translation of sensed human behavioural signals/cues and context descriptors into an encoded human activity remains a challenge because of the complex nature of human actions. In this paper, we propose a multilayer framework for the understanding of human activity to be implemented in a mobile robot. It consists of a perception layer which exploits a D-RGB-based skeleton tracking output used to simulate a physical model of virtual human dynamics in order {{to compensate for the}} inaccuracy and inconsistency of the raw data. A multi-support vector machine (MSVM) model trained with features describing the human motor coordination through temporal segments in combination with environment <b>descriptors</b> (<b>object</b> affordance) is used to recognize each sub-activity (classification layer). The interpretation of sequences of classified elementary actions is based on discrete hidden Markov models (DHMMs) (interpretation layer). The framework assessment was performed on the Cornell Activity Dataset (CAD- 120) [1]. The performances of our method are comparable with those presented in [2] and clearly show the relevance of this model-based approach...|$|R
40|$|Motivated by the discriminative {{ability of}} shape {{information}} and local patterns in object recognition, this paper proposes a window-based <b>object</b> <b>descriptor</b> that integrates both cues. In particular, contour templates representing object shape {{are used to}} derive a set of so-called key points at which local appearance features are extracted. These key points are located using an improved template matching method that utilises both spatial and orientation information in a simple and effective way. At each of the extracted key points, a new local appearance feature, namely non-redundant local binary pattern (NR-LBP), is computed. An <b>object</b> <b>descriptor</b> is formed by concatenating the NR-LBP features from all key points to encode the shape {{as well as the}} appearance of the <b>object.</b> The proposed <b>descriptor</b> was extensively tested in the task of detecting humans from static images on the commonly used MIT and INRIA datasets. The experimental results have shown that the proposed descriptor can effectively describe non-rigid objects with high articulation and improve the detection rate compared to other state-of-the-art <b>object</b> <b>descriptors...</b>|$|R
40|$|Abstract. We {{describe}} the architecture and key {{features of the}} MPEG- 4 Systems specification, {{as well as the}} encoding methodology of its various components: scene description and BIFS, animation streams, <b>object</b> <b>descriptors,</b> <b>object</b> content infonnation, as well as delivery and multiplexing. We also {{describe the}} MPEG- 4 reference software as well as our own prototype software for MPEG- 4 authoring, streaming, aDd playback. Finally, we briefly compare MPEG- 4 Systems with a number of currently available alternative standards and commercial solutions. Keywords: MPEG- 4 systems, object-based representation, digital audio and video, interactive multimedia I. Introduction (1994 - 95), the Internet and the Web started to gain significant momentum in the United States and abroad. MPEG- 4 [1 - 3] is a standardization effort under the aus- This affected MPEG- 4 in several ways, although the pices ofISO/IEC [4] being developed by MPEG (Mov- focus remained on audiovisual applications. A brief ing Picture Experts Group) [5], the committee that also history of MPEG- 4, including a timeline of its deve...|$|R
40|$|A good object {{representation}} or <b>object</b> <b>descriptor</b> {{is one of}} the {{key issues}} in object based image analysis. To effectively fuse color and texture as a unified <b>descriptor</b> at <b>object</b> level, this paper presents a novel method for feature fusion. Color histogram and the uniform local binary patterns are extracted from arbitrary-shaped image-objects, and kernel principal component analysis (kernel PCA) is employed to find nonlinear relationships of the extracted color and texture features. The maximum likelihood approach is used to estimate the intrinsic dimensionality, which is then used as a criterion for automatic selection of optimal feature set from the fused feature. The proposed method is evaluated using SVM as the benchmark classifier and is applied to object-based vegetation species classification using high spatial resolution aerial imagery. Experimental results demonstrate that great improvement can be achieved by using proposed feature fusion method...|$|R
40|$|A novel local {{intensity}} distribution (LID) <b>descriptor</b> for <b>object</b> detection is proposed. By capturing {{the distribution of}} local intensity difference effectively, the LIS descriptor is insensitive to illumination changes while being more compact and discriminative compared with the popular local binary pattern. Two LID descriptors can be efficiently compared using the Kullback-Leibler distance. The efficacy and efficiency of the proposed descriptor have been verified in the task of detecting humans from static images...|$|R
30|$|In this on-line phase, scene-model {{matching}} is performed. Based on the PP results, local FV is created. Then {{the local}} FV is correlated with reference <b>object</b> <b>descriptors.</b> The thresholding step {{leads to the}} final decision about object presence.|$|R
40|$|Given {{an image}} region of pixels, second order {{statistics}} {{can be used}} to construct a <b>descriptor</b> for <b>object</b> representation. One example is the covariance matrix descriptor, which shows high discriminative power and good robustness in many computer vision applications. However, operations for the covariance matrix on Riemannian manifolds are usually computationally demanding. This paper proposes a novel second order statistics based region descriptor, named "Sigma Set", {{in the form of a}} small set of vectors, which can be uniquely constructed through Cholesky decomposition on the covariance matrix. Sigma Set is of low dimension, powerful and robust. Moreover, compared with the covariance matrix, Sigma Set is not only more efficient in distance evaluation and average calculation, but also easier to be enriched with first order statistics. Experimental results in texture classification and object tracking verify the effectiveness and efficiency of this novel <b>object</b> <b>descriptor.</b> 1...|$|R
50|$|The FILE data {{structure}} in the C standard I/O library usually includes a low level file <b>descriptor</b> for the <b>object</b> in question on Unix-like systems. The overall {{data structure}} provides additional abstraction and is instead known as a file handle.|$|R
40|$|Determining if {{two images}} {{acquired}} {{at different times}} and under different viewing conditions contain the same scene is a difficult problem in computer vision. We demonstrate an approach that utilizes spatial relationships among the objects in the two scenes that ultimately produces a mapping of objects from one view to the other, and as a bonus, recovers the viewing transformation parameters. The core of the system relies on capturing spatial relationship information through Force Histograms, affine-invariant image <b>descriptors.</b> <b>Object</b> mapping across images is performed by finding the best correspondence map (FMAP) between force histograms in the two images. The major {{problem is that the}} number of potential FMAPS is huge, even for modest numbers of scene objects. Hence, some optimization is required. Similar feature vectors are observed from F-histogram matching defined in the best correspondence map. Therefore, dense regions in the feature space are suspected to contain these vectors. Possibilistic C-Means clustering (PCM) is used to find these dense regions. The centroids of these dense regions are used to generate an FMAP using a nearest-neighbor like approach. The best FMAP is selected and translated into an object map identifying the correspondences between objects in the two images...|$|R
40|$|Abstract. A {{system is}} {{presented}} to detect and match any objects with mobile cameras collaborating with fixed cameras observing the same scene. No training data is needed. Various <b>object</b> <b>descriptors</b> are studied based on grids of region descriptors. Region descriptors such as histograms of oriented gradients and covariance matrices of different set of features are evaluated. A detection and matching approach is presented based on a cascade of descriptors outperforming previous approaches. The <b>object</b> <b>descriptor</b> is robust to any changes in illuminations, viewpoints, color distributions and image quality. Objects with partial occlusion are also detected. The dynamic {{of the system is}} taken into consideration to better detect moving objects. Qualitative and quantitative results are presented in indoor and outdoor urban scenes. ...|$|R
40|$|A new approach, {{based on}} control charts, is {{presented}} {{for the task}} of recognition of events and scenarios in video image sequences. For each image in the sequence, low level image processing and feature extraction steps result in feature <b>descriptors</b> for <b>objects</b> of interest detected in the images. Control charts analysis is then explored to classify {{the nature of the}} activity depicted by the temporal changes in these features over the image sequence. Scenario recognition with higher accuracy is achieved using this simple approach. 1...|$|R
30|$|We use region {{covariance}} <b>descriptor</b> {{to model}} <b>objects</b> appearance, the edge-like information more robust to the illumination changes than the image grayscale can be simultaneously considered {{with the image}} grayscale information and pixel spatial information, and the consequence is the quite robust tracking results as seen in Figure 7.|$|R
30|$|Leibe et al. {{proposed}} an implicit object model based on local invariant descriptors that jointly learns the discriminant <b>descriptors</b> for an <b>object</b> and their spatial relationships [31]. Once again, this approach implies an existing spatial {{layout of the}} object parts which {{does not exist in}} the case of scenes.|$|R
50|$|These {{algorithms}} {{have been}} used, for example, for perception in robotics to filter outliers from noisy data, stitch 3D point clouds together, segment relevant {{parts of a}} scene, extract keypoints and compute <b>descriptors</b> to recognize <b>objects</b> in the world based on their geometric appearance, and create surfaces from point clouds and visualize them.|$|R
40|$|Co-occurrence histograms of {{oriented}} gradients (CoHOG) {{are powerful}} <b>descriptors</b> in <b>object</b> detection. In this paper, we propose to utilize {{a very large}} pool of CoHOG features with variable-location and variable-size blocks to capture salient characteristics of the object structure. We consider a CoHOG feature as a block with a special pattern described by the offset. A boosting algorithm is further introduced to select the appropriate locations and offsets to construct an efficient and accurate cascade classifier. Experimental results on public datasets show that our approach simultaneously achieves high accuracy and fast speed on both pedestrian detection and car detection tasks...|$|R
50|$|Unfortunately, Symbian C++ {{programming}} has a steep learning curve, as Symbian C++ {{requires the}} use of special techniques such as <b>descriptors,</b> active <b>objects</b> and the cleanup stack. This can make even relatively simple programs initially harder to implement than in other environments. It is possible that the techniques, developed for the much more restricted mobile hardware and compilers of the 1990s, caused extra complexity in source code because programmers are required to concentrate on low-level details instead of more application-specific features. As of 2010, these issues are no longer the case when using standard C++, with the Qt SDK.|$|R
5000|$|<b>Object</b> <b>descriptors</b> {{allowed the}} {{identification}} of objects in various ways. The most interesting one was using a where-clause (which translated into AppleScript terminology as a filter expression). For instance, the AppleScript 1.0 SDK shipped with the source code for an example application called the Scriptable Text Editor, which would respond to scripts such as: ...|$|R
40|$|Digital visual {{libraries}} have {{currently available}} {{huge amounts of}} content in unstructured, nonindexed form. Since these collections keep growing fast, retrieving specific images is becoming extremely difficult. It is too slow to linearly search all the stored feature vectors to find those that satisfy the query criteria. Scalability is crucial for an image retrieval system to be practical and realistic. In this paper a simple hierarchical <b>object</b> <b>descriptor</b> scheme which is compact, flexible, and inherently suited for hierarchical search is described. By integrating a suitable segmentation algorithm into the descriptor generation schema, the proposed approach becomes object oriented. Basically, features used for the extraction of image regions belonging to single physical objects {{are used in the}} definition of <b>object</b> <b>descriptors.</b> The resulting technique generates compact scalable descriptions for each object in the database. Experimental results show the performance of the presented schema in terms of accuracy and scalability. 1...|$|R
40|$|Convexity {{represents}} a fundamental <b>descriptor</b> of <b>object</b> shape. This paper presents a new convexity measure for both open and closed simple contours. Given such a contour this measure extracts two corresponding open convex hulls. The shape similarity {{between these two}} hulls and the original contour is then computed and normalized to give a measure of convexity. The time complexity of the proposed technique is O(n). The authors believe this technique represents the first measure of convexity which uses shape similarity and which {{can be applied to}} both open and closed contours. The proposed technique is shown to provide similar or greater performance relative to two other state of the art techniques. ...|$|R
40|$|Introduction Since Video Objects have no {{well-defined}} objective qualities, {{the ability}} to query by shape provides an interface between human being and an video database to allow for search of video object via robust comparisons between <b>objects</b> <b>descriptors</b> of shape. In the MPEG- 7 framework [1], shape is only one criterion of query which {{in and of itself}} may have multiple descriptors. We will introduce a <b>object</b> <b>descriptor</b> that represents a concept of "internal structure" as the feature of a object, i. e. the shape's contour implies its skeletal structure. Considering only shapes that are described by a simple closed contour, we can derive this implied structure from an infinite string of Voronoi cells. Robust comparison of shapes is found by aligning the implicit structure of the two shapes. Furthermore, this representation can tolerate warping and variations in shape that do not change the implicit structure, allows for intuitive manipulation and temporal description, and prov...|$|R
