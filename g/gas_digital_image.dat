0|10000|Public
40|$|This paper {{addresses}} physical print permanence issues beyond lightfastness and <b>gas</b> fastness for <b>digital</b> <b>image</b> hardcopy. Most image-life {{claims are}} based on time to unacceptable fade during high intensity exposure extrapolated to time under assumed display conditions in homes, offices, and other public areas. This neglects the potential for images to decay by other mechanisms (chemical or physical) which may, during actual use, be manifested before significant light-induced decay. Therefore, current practices of advertising image longevity by display-life have been woefully inadequate and potentially seriously misleading. The experimental work shows that inkjet prints can be sensitive to abrasion, surface cracking, and adherence to plastic page protectors in albums and glass in frames...|$|R
50|$|Microsoft <b>Digital</b> <b>Image</b> came {{in three}} {{different}} editions: <b>Digital</b> <b>Image</b> Standard, which offered tools for editing <b>images,</b> <b>Digital</b> <b>Image</b> Suite, which added <b>Digital</b> <b>Image</b> Library for organizing <b>images</b> and <b>Digital</b> <b>Image</b> Suite Plus, which included tools from <b>Digital</b> <b>Image</b> Suite and the video editing tools of Pinnacle Studio. <b>Digital</b> <b>Image</b> had support for Adobe Photoshop plugins. Later versions also included Photo Story 3.1.|$|R
5000|$|Image:Channel <b>digital</b> <b>image</b> RGB color.jpg|Image:Channel <b>digital</b> <b>image</b> cyan.jpg|The CYAN {{channel of}} the {{original}} CMYK imageImage:Channel <b>digital</b> <b>image</b> magenta.jpg|The MAGENTA channel {{of the original}} CMYK imageImage:Channel <b>digital</b> <b>image</b> yellow.jpg|The YELLOW channel of the original CMYK imageImage:Channel <b>digital</b> <b>image</b> black.jpg|The KEY (black) channel of the original CMYK image ...|$|R
40|$|Abstract—With the {{development}} of technology, <b>digital</b> <b>image</b> tampering technology is becoming mature. It is difficult to directly determine from the naked eye whether a <b>digital</b> <b>image</b> has been modified. Furthermore, many digital watermarking in <b>digital</b> <b>images</b> cannot be identified, since the importance of it is neglect. In view of the wide use of <b>digital</b> <b>image,</b> such as evidence in court, a series of algorithms are designed to detect whether the <b>digital</b> <b>image</b> has been tampered. Keywords- <b>digital</b> <b>image,</b> tampering algorithms, <b>digital</b> watermarking I...|$|R
30|$|The <b>digital</b> <b>image</b> {{protection}} {{method is}} image encryption technology [9 – 13], and its basic principle is to encrypt the digital {{information contained in}} the <b>digital</b> <b>image,</b> and get the completely different encrypted images of the appearance and the original <b>digital</b> <b>image,</b> so that {{the content of the}} <b>digital</b> <b>image</b> cannot be viewed directly. When the <b>digital</b> <b>image</b> is needed for viewing or using, the corresponding decryption algorithm is used to calculate and decrypt the encrypted image to restore the original content of the <b>digital</b> <b>image,</b> which is an important means for <b>digital</b> <b>image</b> content protection in a distributed environment with high security requirements.|$|R
40|$|The term <b>Digital</b> <b>Image</b> Processing {{denotes the}} process of <b>digital</b> <b>images</b> {{with the use of}} digitalcomputer. <b>Digital</b> <b>image</b> {{processing}} is used in various types of application areas. The problem of imageenhancement is considered as a problem of quality improvement. <b>Digital</b> <b>images</b> are contains various types ofnoises which are reduces the quality of images. Noises can be removed by various enhancement techniques. Filtering is the process used to remove the noise in the <b>digital</b> <b>images.</b> <b>Digital</b> <b>images</b> can be either spatialdomain or frequency domain. This paper investigates various techniques used in spatial domain imageprocessing...|$|R
5000|$|<b>Digital</b> <b>Image</b> 2006 and <b>Digital</b> <b>Image</b> 2006 Anniversary Edition (2006) ...|$|R
40|$|My {{principal}} area {{of research}} is <b>digital</b> <b>image</b> and video processing, specifically it includes: • <b>Digital</b> <b>image</b> and video compression and transmission • Perceptual-based visual processing and coding • Visual quality assessment • <b>Digital</b> <b>image</b> and video segmentation and analysis • <b>Digital</b> <b>image</b> and video enhancement and restoration • Computer Vision • Biomedical imagin...|$|R
40|$|Background: Adoption of <b>digital</b> <b>images</b> for {{pathological}} specimens {{has been}} slower than adoption of <b>digital</b> <b>images</b> in radiology, despite {{a number of}} anticipated advantages for <b>digital</b> <b>images</b> in pathology. In this paper, we explore the factors that might explain this slower rate of adoption. Materials and Method: Semi-structured interviews on barriers and facilitators {{to the adoption of}} <b>digital</b> <b>images</b> were conducted with two radiologists, three pathologists, and one pathologist′s assistant. Results: Barriers and facilitators to adoption of <b>digital</b> <b>images</b> were reported in the areas of performance, workflow-efficiency, infrastructure, integration with other software, and exposure to <b>digital</b> <b>images.</b> The primary difference between the settings was that performance with the use of <b>digital</b> <b>images</b> as compared to the traditional method was perceived to be higher in radiology and lower in pathology. Additionally, exposure to <b>digital</b> <b>images</b> was higher in radiology than pathology, with some radiologists exclusively having been trained and/or practicing with <b>digital</b> <b>images.</b> The integration of <b>digital</b> <b>images</b> both improved and reduced efficiency in routine and non-routine workflow patterns in both settings, and was variable across the different organizations. A comparison of these findings with prior research on adoption of other health information technologies suggests that the barriers to adoption of <b>digital</b> <b>images</b> in pathology are relatively tractable. Conclusions: Improving performance using <b>digital</b> <b>images</b> in pathology would likely accelerate adoption of innovative technologies that are facilitated by the use of <b>digital</b> <b>images,</b> such as electronic imaging databases, electronic health records, double reading for challenging cases, and computer-aided diagnostic systems...|$|R
40|$|What is <b>digital</b> <b>image</b> processing? What is <b>digital</b> <b>image</b> processing? An image may {{be defined}} as a 2 D {{function}} f(x,y) where x, y: spatial coordinates amplitude of f(x,y) is called the intensity or gray level <b>Digital</b> <b>image</b> <b>Digital</b> <b>image</b> processing Processing <b>digital</b> <b>images</b> by means of a digital computer. The element of a <b>digital</b> <b>image</b> Picture elements, image elements, pixel What is <b>digital</b> <b>image</b> processing? (cont.) Three types computerized processes: Low level Basic operations such as noise reduction, contrast enhancement, and image sharpening. Mid-level Segmentation, classification High-level Understand the meaning of the recognized objects. 應用實例 醫學影像處理 From clinical point of view, Single-modality-based diagnose Outlining of boundaries of organs and tumors Segmenting the suspiciously lesion. Multi-modality-based diagnose Image transformation Image registration The useful technologies for medical image processing: 影像對 位 (Image registration) Image fusio...|$|R
5000|$|Picture It! Premium 10, <b>Digital</b> <b>Image</b> Pro 10 and <b>Digital</b> <b>Image</b> Suite 10 (2005) ...|$|R
5000|$|Picture It! Premium 9, <b>Digital</b> <b>Image</b> Pro 9 and <b>Digital</b> <b>Image</b> Suite 9 (2004) ...|$|R
2500|$|<b>Digital</b> <b>image</b> {{processing}} [...] the use {{of computer}} algorithms to perform <b>image</b> processing on <b>digital</b> <b>images.</b>|$|R
30|$|Digital {{watermarking}} technology, namely Digital Watermarking Technology. The technology adopts {{the signature}} processing of <b>digital</b> <b>images</b> and adds custom watermark {{information to the}} original <b>digital</b> <b>images</b> to protect the copyright of <b>digital</b> <b>images.</b> It {{is one of the}} important technical means for image security protection in the Internet. However, the disadvantage of digital watermarking technology is that the visibility of <b>digital</b> <b>images</b> cannot be avoided. Usually, only the copyright of the image is not infringed, and when the content of the <b>digital</b> <b>image</b> needs to be protected, there is nothing that can be done.|$|R
40|$|The WWW (World Wide Web) is {{a superb}} sales and {{distribution}} medium for <b>digital</b> <b>image</b> assets, but official document compliance and important {{data can be}} a call to prove or justify it. Present days, <b>digital</b> <b>image,</b> audio and video used all over world with or without agreement. In <b>digital</b> <b>image</b> watermarking answer let you add extra layer of protection (added logo) to your <b>digital</b> <b>image.</b> By using Singular Value Decomposition- Discrete Cosine Transfer we are finding Normalization Cross Correlation coefficient value of attacking (rotational attack) on <b>digital</b> <b>image</b> watermarking. The Normalization Cross Correlation coefficient value depended on step size of <b>digital</b> <b>image.</b> If you change the value of step size than our results are different...|$|R
40|$|AbstractTo {{evaluate}} the progress in wound healing, wound assessment is mandatory. Epithelialization is traditionally assessed subjectively by the clinician. In a previous study, subjective assessment of epithelialization {{was shown to}} be reliable. In this study, reliability of epithelialization measured by <b>digital</b> <b>image</b> analysis was investigated and then, we validated the subjective evaluation by comparing this assessment to measurements with <b>digital</b> <b>image</b> analysis. Clinicians assessed epithelialization in 50 burn wounds that were treated with a split skin graft. Epithelialization of these wounds was also measured by three observers using <b>digital</b> <b>image</b> analysis. Reliability of <b>digital</b> <b>image</b> analysis was tested using the intraclass correlation (IC). To test validity, subjective clinical assessment was correlated with <b>digital</b> <b>image</b> analysis (IC). The results showed that interobserver reliability of epithelialization measured by <b>digital</b> <b>image</b> analysis was good (IC coefficient 0. 74). Subjective clinical assessment of epithelialization showed a strong correlation with <b>digital</b> <b>image</b> analysis (IC coefficient 0. 80). In conclusion, subjective clinical evaluation of wound epithelialization {{is as good as}} an objective measure, in this study <b>digital</b> <b>image</b> analysis. Since <b>digital</b> <b>image</b> analysis is more time-consuming, we recommend the use of the subjective evaluation for daily practice...|$|R
40|$|Abstract We {{consider}} {{the problem of}} exact histogram spec-ification for <b>digital</b> (quantized) <b>images.</b> The goal is to trans-form the input <b>digital</b> <b>image</b> into an output (also <b>digital)</b> <b>image</b> that follows a prescribed histogram. Classical his-togram modification methods are designed for real-valued images where all pixels have different values, so exact his-togram specification is straightforward. <b>Digital</b> <b>images</b> typ-ically have numerous pixels which share the same value. If one imposes the prescribed histogram to a <b>digital</b> <b>image,</b> usually there are numerous ways of assigning the prescribed values to the quantized values of the image. Therefore, ex-act histogram specification for <b>digital</b> <b>images</b> is an ill-posed problem. In order to guarantee that any prescribed histogram will be satisfied exactly, all pixels of the input <b>digital</b> <b>image</b> must be rearranged in a strictly ordered way. Further, the obtained strict ordering must faithfully account for the spe-cific features of the input <b>digital</b> <b>image.</b> Such a task can be realized if {{we are able to}} extract additional representativ...|$|R
40|$|International audienceWe {{consider}} {{the problem of}} exact histogram specification for <b>digital</b> (quantized) <b>images.</b> The goal is to transform the input <b>digital</b> <b>image</b> into an output (also <b>digital)</b> <b>image</b> that follows a prescribed histogram. Classical histogram modification methods are designed for real-valued images where all pixels have different values, so exact histogram specification is straightforward. <b>Digital</b> <b>images</b> typically have numerous pixels which share the same value. If one imposes the prescribed histogram to a <b>digital</b> <b>image,</b> usually there are numerous ways of assigning the prescribed values to the quantized values of the image. Therefore, exact histogram specification for <b>digital</b> <b>images</b> is an ill-posed problem. In order to guarantee that any prescribed histogram will be satisfied exactly, all pixels of the input <b>digital</b> <b>image</b> must be rearranged in a strictly ordered way. Further, the obtained strict ordering must faithfully account for the specific features of the input <b>digital</b> <b>image.</b> Such a task can be realized if {{we are able to}} extract additional representative information (called auxiliary attributes) from the input <b>digital</b> <b>image.</b> This is a real challenge in exact histogram specification for <b>digital</b> <b>images.</b> We propose a new method that efficiently provides a strict and faithful ordering for all pixel values. It is based on a well designed variational approach. Noticing that the input <b>digital</b> <b>image</b> contains quantization noise, we minimize a specialized objective function whose solution is a real-valued image with slightly reduced quantization noise, which remains very close to the input <b>digital</b> <b>image.</b> We show that all the pixels of this real-valued image can be ordered in a strict way with a very high probability. Then transforming the latter <b>image</b> into another <b>digital</b> <b>image</b> satisfying a specified histogram is an easy task. Numerical results show that our method outperforms by far the existing competing methods...|$|R
40|$|Abstract — Advancements {{in digital}} imaging {{technologies}} has elevated many new {{issues and challenges}} concerning the authenticity and integrity of <b>digital</b> <b>images.</b> <b>Digital</b> <b>images</b> can now be easily captured and edited for creating forgery without leaving any obvious clues of such operations. These capabilities undermine the credibility of <b>digital</b> <b>images</b> in all aspects. <b>Digital</b> <b>image</b> forensics is has gained tremendous importance in last one decade among the research community. <b>Digital</b> <b>Image</b> Forensics (DIF) aims at determining the origin and potential authenticity of a <b>digital</b> <b>images.</b> One of the fundamental problems <b>digital</b> <b>image</b> forensics techniques attempt to solve is {{the identification of the}} source of a <b>digital</b> <b>image.</b> In case if the image is challenged in the court of the law {{it is very important to}} prove and identify the original image from the tampered and forged one. In this paper we present an active approach which is based on Independent Component Analysis (ICA). The experiments carried out proves that the ICA can be used as an effective and robust tool for identifying the original image from the forged one...|$|R
40|$|In today’s {{digital word}} {{it is very}} common to {{distribute}} <b>digital</b> <b>image</b> {{as a part of}} multimedia technology by use of the Internet. Security of this digital data over the Internet is very popular field among researchers. Watermarking is a process that embeds data or watermark inside data such that it cannot be easily accessed by authorized person. Watermarking provides copyright protection of <b>digital</b> data. <b>Digital</b> <b>Image</b> Water marking is a subfield of Digital watermarking, and it concerns with protection of <b>digital</b> <b>image</b> from unauthorized reproduction and modification. In digital watermarking, a secondary image is a watermark and this watermark lied into the host image and provides protection. Different <b>Digital</b> <b>Image</b> watermarking methods have been proposed in this field to maintain content authentication, copyright protection, tamper protection and many other application. This paper presents a model for <b>digital</b> <b>image</b> watermarking, properties and applications. Moreover, this paper present a survey on different types of <b>digital</b> <b>Image</b> watermarks. This paper reviews different aspects of <b>digital</b> <b>image</b> watermarking for protecting digital data and provide review of <b>digital</b> <b>image</b> watermarking methods named: Least Significant Bit (LSB) ...|$|R
40|$|Watermark is a {{technique}} of information concealment into digital data. One of the aims to give watermark to the <b>digital</b> <b>image</b> is copyrights protection. Before process or duplicate the digital image,needed some watermark detection to know the existence of watermarking in the <b>digital</b> <b>image.</b> We did it to appreciate the copyrights of someone for the ownership of <b>digital</b> <b>image.</b> The detection is done {{to know what is}} the <b>digital</b> <b>image</b> has been lable with watermark or not. In this research, detection watermark existence done with discrete fractional fourier transform (DFRFT). To know the existence from the watermark inside the <b>digital</b> <b>image</b> done with comparing the detection value with threshold. At simulation has done to attack process using rotation, noise, and cropping. The result of this research is giving information to user about the existence of watermark in the <b>digital</b> <b>image.</b> Key word : watermark, <b>digital</b> <b>image,</b> DFRFT, threshold...|$|R
5000|$|The Stanford University Libraries <b>Digital</b> <b>Image</b> Collections is {{an online}} {{collection}} of <b>digital</b> <b>images</b> called Image Gallery {{maintained by the}} Stanford University Libraries. The site provides access to over 50,000 <b>digital</b> <b>images</b> scanned from collections owned by the Stanford Libraries. Users can search image metadata, browse collections and view images at high resolutions.|$|R
30|$|In {{this article}} we study the fixed point {{properties}} of <b>digital</b> <b>images.</b> Moreover, we prove the Lefschetz fixed point theorem for a <b>digital</b> <b>image.</b> We then give some examples about the fixed point property. We conclude that sphere-like <b>digital</b> <b>images</b> have the fixed point property.|$|R
50|$|<b>Digital</b> <b>image</b> {{authentication}} is {{an issue}} for the providers and producers of <b>digital</b> <b>images</b> {{such as health care}} organizations, law enforcement agencies and insurance companies. There are methods emerging in forensic photography to analyze a <b>digital</b> <b>image</b> and determine if it has been altered.|$|R
40|$|To {{evaluate}} the progress in wound healing, wound assessment is mandatory. Epithelialization is traditionally assessed subjectively by the clinician. In a previous study, subjective assessment of epithelialization {{was shown to}} be reliable. In this study, reliability of epithelialization measured by <b>digital</b> <b>image</b> analysis was investigated and then, we validated the subjective evaluation by comparing this assessment to measurements with <b>digital</b> <b>image</b> analysis. Clinicians assessed epithelialization in 50 burn wounds that were treated with a split skin graft. Epithelialization of these wounds was also measured by three observers using <b>digital</b> <b>image</b> analysis. Reliability of <b>digital</b> <b>image</b> analysis was tested using the intraclass correlation (IC). To test validity, subjective clinical assessment was correlated with <b>digital</b> <b>image</b> analysis (IC). The results showed that interobserver reliability of epithelialization measured by <b>digital</b> <b>image</b> analysis was good (IC coefficient 0. 74). Subjective clinical assessment of epithelialization showed a strong correlation with <b>digital</b> <b>image</b> analysis (IC coefficient 0. 80). In conclusion, subjective clinical evaluation of wound epithelialization {{is as good as}} an objective measure, in this study <b>digital</b> <b>image</b> analysis. Since <b>digital</b> <b>image</b> analysis is more time-consuming, we recommend the use of the subjective evaluation for daily practice. © 2012 Elsevier Ltd and ISBI. All rights reserved...|$|R
50|$|Microsoft <b>Digital</b> <b>Image</b> was a <b>digital</b> <b>image</b> {{editing program}} created by Microsoft. It was a {{successor}} to Microsoft Picture It!.|$|R
40|$|Digital imaging {{techniques}} are often useful to measure bidimensional surface displacements and deformations. One {{of these techniques}} is the <b>digital</b> <b>image</b> correlation which correlates <b>digital</b> <b>images</b> of speckle patterns to calculate displacements and strains. In this work is presented the application of <b>digital</b> <b>image</b> correlation {{to the analysis of}} the local behaviour under load of composite materials. Applications of the technique to numerically generated <b>digital</b> <b>images,</b> useful to evaluate globally the technique, are also reported...|$|R
40|$|A <b>digital</b> <b>image</b> {{compression}} preprocessor {{for use in}} {{a discrete}} cosine transform-based <b>digital</b> <b>image</b> compression device is provided. The preprocessor includes a gathering mechanism for determining discrete cosine transform statistics from input <b>digital</b> <b>image</b> data. A computing mechanism is operatively coupled to the gathering mechanism to calculate a image distortion array and a rate of image compression array based upon the discrete cosine transform statistics for each possible quantization value. A dynamic programming mechanism is operatively coupled to the computing mechanism to optimize the rate of image compression array against the image distortion array such that a rate-distortion-optimal quantization table is derived. In addition, a discrete cosine transform-based <b>digital</b> <b>image</b> compression device and a discrete cosine transform-based <b>digital</b> <b>image</b> compression and decompression system are provided. Also, a method for generating a rate-distortion-optimal quantization table, using discrete cosine transform-based <b>digital</b> <b>image</b> compression, and operating a discrete cosine transform-based <b>digital</b> <b>image</b> compression and decompression system are provided...|$|R
40|$|Over {{the past}} decade <b>digital</b> <b>images</b> has become a very popular way to communicate, store and process information. With the rapid {{advancement}} and easy availability of technology, there is a flood of devices {{that are able to}} capture, store and create <b>digital</b> <b>images.</b> Over the past years image processing techniques have been developed that makes it really easy to tamper images. From journalism to social media edited images are appearing everywhere with increasing frequency. Authentication of images is very necessary as visual data effects what people perceive and believe. <b>Digital</b> <b>image</b> Forensics is an emerging field that uses intrinsic and extrinsic methods to authenticate <b>digital</b> <b>images.</b> Passive techniques extract and analyze inherent patterns introduced by various image processing steps and use these artifacts to associate the image with source device as well as to detect tampering of the <b>digital</b> <b>images.</b> This paper gives an overview of passive techniques of <b>Digital</b> <b>Image</b> Forensics which are based on intrinsic fingerprints inherent in <b>digital</b> <b>images...</b>|$|R
5000|$|Many modern <b>digital</b> <b>image</b> editing {{programs}} have [...] "dodge" [...] and [...] "burn" [...] tools that mimic {{the effect on}} <b>digital</b> <b>images.</b>|$|R
40|$|The {{usage of}} <b>digital</b> <b>image</b> becomes ubiquitous. Also, the <b>digital</b> <b>images</b> are {{processed}} using digital devices. There are many mathematical techniques available {{to estimate the}} Gaussian noise of reproduced <b>digital</b> <b>image.</b> Assessing quantity of the Gaussian noise in a <b>digital</b> <b>image</b> is a difficult task. There are few factors affecting the process of digitizing images. The electronic devices used for acquiring images are {{the cause of the}} Gaussian noise. In this paper, a mathematical technique is proposed to estimate the Gaussian noise in the reproduced <b>digital</b> <b>image.</b> The proposed technique estimates quantity of the Gaussian noise in the reproduced image in a better way. The proposed technique i...|$|R
40|$|Section I Introduction to <b>Digital</b> <b>Image</b> Processing and AnalysisDigital Image Processing and AnalysisOverviewImage Analysis and Computer VisionImage Processing and Human VisionKey PointsExercisesReferencesFurther ReadingComputer Imaging SystemsImaging Systems OverviewImage Formation and SensingCVIPtools SoftwareImage RepresentationKey PointsExercisesSupplementary ExercisesReferencesFurther ReadingSection II <b>Digital</b> <b>Image</b> Analysis and Computer VisionIntroduction to <b>Digital</b> <b>Image</b> AnalysisIntroductionPreprocessingBinary Image AnalysisKey PointsExercisesSupplementary ExercisesReferencesFurther Rea...|$|R
40|$|We {{consider}} {{the problem of}} exact histogram specification for <b>digital</b> (quantized) <b>images.</b> The goal is to transform the input <b>digital</b> <b>image</b> into an output (also <b>digital)</b> <b>image</b> that follows a prescribed histogram. Classical histogram modification methods are designed for real-valued images where all pixels have different values, so exact histogram specification is straightforward. <b>Digital</b> <b>images</b> typically have numerous pixels which share the same value. If one imposes the prescribed histogram to a <b>digital</b> <b>image,</b> usually there are numerous ways of assigning the prescribed values to the quantized values of the image. Therefore, exact histogram specification for <b>digital</b> <b>images</b> is an ill-posed problem. In order to guarantee that any prescribed histogram will be satisfied exactly, all pixels of the input <b>digital</b> <b>image</b> must be rearranged in a strictly ordered way. Further, the obtained strict ordering must faithfully account for the specific features of the input <b>digital</b> <b>image.</b> Such a task can be realized if {{we are able to}} extract additional representative information (called auxiliary attributes) from the input <b>digital</b> <b>image.</b> This is a real challenge in exact histogram specification for <b>digital</b> <b>images.</b> We propose a new method that efficiently provides a strict and faithful ordering for all pixel values. It is based on a well designed variational approach. Noticing that the input <b>digital</b> <b>image</b> contains quantization noise, we minimize a specialized objective function whose solution is a real-valued image with slightly reduced quantization noise, which remains very close to the input <b>digital</b> <b>image.</b> We show that all the pixels of this real-valued image can be ordered in a strict way with a very high probability. Then transforming the latter <b>image</b> into another <b>digital</b> <b>image</b> satisfying a specified histogram is an easy task. Numerical results show that our method outperforms by far the existing competing methods. Key words: Exact histogram specification, strict-ordering, variational methods, restoration from quantization noise, smooth nonlinear optimization, convex minimization, perturbation analysis. I...|$|R
40|$|In {{this paper}} an Automatic System for <b>Image</b> <b>Digital</b> Capturing (ASIDC) is described. The aim of ASIDC {{is to create}} high {{resolution}} <b>digital</b> <b>images</b> depicting paintings of large size. The system creates a set of N <b>digital</b> <b>images</b> presenting sequential frames of the total picture. By using software we proceed to the mosaicing (pasting) of the images producing the complete detailed <b>digital</b> <b>image...</b>|$|R
40|$|The {{main task}} of <b>digital</b> <b>image</b> {{processing}} {{is to recognize}} properties of real objects based on their <b>digital</b> <b>images.</b> These images are obtained by some sampling device, like a CCD camera, and represented as finite sets of points that are assigned some value in a gray-level or color scale. Based on technical properties of sampling devices, these points are usually assumed to form a square grid and are modeled as finite subsets of Z 2. Therefore, a fundamental question in <b>digital</b> <b>image</b> processing is which features in the <b>digital</b> <b>image</b> correspond, under certain conditions, to properties of the underlying objects. In practical applications this question is mostly answered by visually judging the obtained <b>digital</b> <b>images.</b> In this paper we present a comprehensive {{answer to this question}} with respect to topological properties. In particular, we derive conditions relating properties of real objects to the grid size of the sampling device which guarantee that a real object and its <b>digital</b> <b>image</b> are topologically equivalent. These conditions also imply that two <b>digital</b> <b>images</b> of a given object are topologically equivalent. This means, for example, that shifting or rotating an object or the camera cannot lead to topologically different images, i. e., topological properties of obtained <b>digital</b> <b>images</b> are invariant under shifting and rotation. ...|$|R
5000|$|... 2D {{computer}} graphics are the computer-based generation of <b>digital</b> <b>images</b> - mostly from models, such as <b>digital</b> <b>image,</b> and by techniques specific to them.|$|R
