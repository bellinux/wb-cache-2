16|8|Public
3000|$|... [...]) {{has a high}} implied cost, or to the flows which {{currently}} have worse <b>end-to-end</b> <b>blocking</b> probability.|$|E
40|$|In this paper, we {{consider}} an optimization problem in networks with storage servers for providing multimedia service. The design involves assigning communication link capacity, sizing the multimedia servers and distributing di#erenttypes of contentateachserver, while guaranteeing an upper {{limit on the}} individual <b>end-to-end</b> <b>blocking</b> probability. We consider alternate methods for obtaining the <b>end-to-end</b> <b>blocking</b> probabilitywithlow computation time and present optimization procedures to obtain an optimal solution. Under a linear cost structure, our numerical investigations consider di#erent scenarios that might be helpful in understanding how to distribute multimedia content for a cost-optimized solution...|$|E
3000|$|..., giving {{preference}} (concerning {{the potential}} value {{in changing the}} routes when seeking to improve the QoS(BE) traffic revenue) to the flows for which the first route has a low implied cost and the second route has a high implied cost, or to the flows which currently have worse <b>end-to-end</b> <b>blocking</b> probability.|$|E
40|$|Abstract. The paper {{deals with}} tree-structured {{point-to-multipoint}} networks, where users from infinite user populations at the leaf nodes {{subscribe to a}} variety of channels, offered by one source. The users joining the network form dynamic multicast connections that share the network resources. An exact algorithm for calculating <b>end-to-end</b> call <b>blocking</b> probabilities for dynamic connections is devised for this multicast model. The algorithm is based on the well-known algorithm for calculating blocking probabilities in hierarchical multiservice access networks, where link occupancy distributions are alternately convolved and truncated. The resource sharing of multicast connections requires the modification of the algorithm by using a new type of convolution, the OR-convolution. The exact algorithm for <b>end-to-end</b> call <b>blocking</b> probabilities enables us to study the accuracy of earlier results based on Reduced Load Approximation. The model is further extended to include background traffic, allowing the analysis of networks carrying mixed traffic e. g. multicast and unicast traffic. ...|$|R
40|$|This memo defines an Experimental Protocol for the Internet community. It {{does not}} specify an Internet {{standard}} of any kind. Discussion {{and suggestions for}} improvement are requested. Distribution of this memo is unlimited. IESG Note This RFC is not a candidate for any level of Internet Standard. The IETF disclaims any knowledge of the fitness of this RFC for any purpose and in particular notes {{that the decision to}} publish is not based on IETF review for such things as security, congestion control, or inappropriate interaction with deployed protocols. The RFC Editor has chosen to publish this document at its discretion. Readers of this document should exercise caution in evaluating its value for implementation and deployment. See RFC 3932 for more information. This document describes the <b>end-to-end</b> protocol, <b>block</b> formats, and abstract service description for the exchange of messages (bundles) in Delay Tolerant Networking (DTN). This document was produced within the IRTF’s Delay Toleran...|$|R
40|$|The cost {{efficient}} design of ATM networks {{is considered to}} be a challenging problem due to the heterogenity of services, the statistical muliplexing gain resulting from the resource sharing of variable bitrate (VBR) connections and the possibility of resource separation through virtual paths (VPs). Most proposals in literature are well suited for small problems only. For that before developing a new algorithm we take a look at large scale design techniques known from telephone network dimensioning. It turns out that the well known Unified Algorithm (UA) of G. Ash [1] is a good basis for an ATM network design method. So we extend and improve the UA in order to cope with the following multihour multiservice ATM network design problem: Find the minimum cost VP network structure on top of a given physical network and the design hour individual optimal VC routing sequences according to <b>end-to-end</b> call <b>blocking</b> constraints. Beside transmission costs also virtual path/virtual channe [...] ...|$|R
40|$|Accurate {{performance}} evaluation {{has always been}} an important issue in network design and analysis. Discrete event simulation has been known to be accurate but very time consuming. A particular performance metric of interest is the <b>end-to-end</b> <b>blocking</b> probability in a circuit-switched loss network. Various analytical approaches and approximation schemes have been suggested and among them, the fixed-point method, or reduced load method, has been receiving much attention. However, most of these schemes either consider only single traffic rate situations or multi-rate traffic under fixed routing. We develop an approximation scheme to estimate <b>end-to-end</b> <b>blocking</b> probability in a multi-rate multi-hop network with an adaptive routing scheme. The approximation results are compared with that of discrete event simulation. An example of application is also provided in which the proposed scheme is linked to the optimization tool CONSOL-OPTCAD to get network design trade-offs. This paper was presented at the "ATIRP ARL Federal Laboratory 2 nd Annual Conference," February 5 - 6, 1998, University of Maryland, College Park campus...|$|E
40|$|Abstract — The {{tradeoffs}} {{involving the}} use of multi-fiber multihop networks such {{as the number of}} fibers, number of wavelengths, conversion options, and the different switch configurations are examined, and their impact on <b>end-to-end</b> <b>blocking</b> and throughput performance is evaluated. Models relating network parameters to end-to-end performance of circuit switched alloptical networks are developed. The performance gain due to {{the use of}} multiple fibers with or without conversion proved to be superior to the single fiber case, when the total number of wavelength are the same, for traffic that traverses multiple hops between source and destination nodes. I...|$|E
40|$|This paper {{proposes a}} novel and highly {{scalable}} multistage packet-switch design based on Networks-on-Chip (NoC). In particular, we describe a three-stage packet-switch fabric with a Round-Robin packets dispatching scheme where each central stage module is an Output-Queued Unidirectional NoC (OQ-UDN), {{instead of the}} conventional single-hop crossbar. We test the switch performance under different traffic profiles. In addition to experimental results, we present an analytical approximation for the theoretical throughput of the switch under Bernoulli i. i. d arrivals. We also provide an upper-bound estimation of the <b>end-to-end</b> <b>blocking</b> probability in the proposed switch to help predict performance and to optimize the design...|$|E
30|$|The {{aim of this}} {{numerical}} {{approach is}} to analyse the multi-layered and real-time properties of the coding schemes described in Section “Forward error correcting coding schemes for safety data dissemination”. The transport protocol used for the safety messages is the user datagram protocols (UDP) that has minimal latency as compared to normal data transfer using transmission control protocol (TCP). In TCP, reliability is usually provided by retransmission and congestion control mechanisms. However in safety broadcast applications using UDP transport, reliability {{is measured by the}} average frame (source block) packet reception rate pSB, which is an estimate of the probability that a vehicle will successfully receive at least one ACN safety message. Latency is measured by average <b>end-to-end</b> source <b>block</b> delay, τSB which is defined as the total time from when the ACN packet is generated by the tagged vehicle until it is successfully received at the receiver. Measurements in [37] show that the processing delay from raptor encoding and decoding procedure is no longer than 1 ms and fast implementations of raptor codes chipsets are readily available on the market. Thus, this processing delay is not taken into consideration for the raptor codes end-to-end delay calculation. Throughput is not of primary importance for short length VANETs safety messages and therefore it is not used as a performance metric in this analysis.|$|R
40|$|Data Center {{switches}} need guarantee high throughput, resiliency and scalability {{for large-scale}} networks with constantly floating requirements. Multistage packet switches {{have been a}} pervasive solution to implement high-capacity Data Center Networks (DCNs) switches and routers. Yet, classical multistage switching architectures with their Space-Memory variants have shown limited performance. Most proposals prove either too complex to implement or not cost effective. In this paper, we present a highly scalable packet-switch for the DCN environment, in which we exploit the Network-on-Chip (NoC) design paradigm to replace the single-hop crossbars with multi-hop Switching Elements (SEs). In particular, we describe a three-stage switch with Output-Queued Unidirectional NoCs (OQ-UDN) in the central stage of the Clos-network. The design has several advantages over conventional multistage switches. First, it uses a simple Round-Robin (RR) packet dispatching scheme and avoids the need for complex and costly input modules. Besides, it offers better load balancing, a pipelined scheduling and more path-diversity. We assess {{the performance of the}} switch in terms of throughput, <b>end-to-end</b> latency and <b>blocking</b> probability using Markov chain analysis, and we propose an analytical model that integrates the various design parameters. Through extensive simulations, we show that the switching architecture achieves high performance under different types of traffic, and that both the analytical and experimental results correlate over wide range of evaluation settings...|$|R
40|$|Clusters {{have become}} {{prevalent}} as a cost-effective solution for building scalable parallel platforms to power diverse workloads. Symmetric multiprocessors of multicore chips {{are commonly used}} as building blocks for clustered systems, when combined with high performance interconnection networks, such as Myrinet. The increasing use of clusters for data-intensive workloads, {{in combination with the}} trend for ever-increasing cores per processor die, poses significant load on the I/O subsystem. Thus, its performance becomes decisive in determining overall system throughput. To meet the challenge, we need low-overhead mechanisms for transporting large datasets efficiently between compute cores and storage devices. In the case of SMP systems, this means reduced CPU, memory bus and peripheral bus contention. This work explores the implications of resource contention in SMP nodes used as commodity storage servers. We study data movement in a block-level storage sharing system over Myrinet and find its performance suffers due to memory and peripheral bus saturation. To alleviate the problem, we propose techniques for building efficient data paths between the storage and the network on the server side, and the network and processing cores on the client side. We present gmblock, a system for shared block storage over Myrinet which supports a direct disk-to-NIC server-side data path, bypassing the host CPU and memory bus. To improve handling of large requests and support intra-request overlapping of network- and disk-I/O with minimal host CPU involvement, we introduce synchronized send operations as extensions to standard Myrinet/GM sends; their semantics support synchronization with an agent external to the NIC, e. g., a storage controller utilizing the direct-to-NIC data path. On the client side, the proposed system exploits NIC programmability to support protected direct placement of incoming fragments into buffers dispersed in physical memory. This enables <b>end-to-end</b> zero-copy <b>block</b> transfers directly from remote storage to client memory over the peripheral bus and cluster interconnect. Experimental evaluation of the proposed techniques demonstrates significant increases in remote I/O rate and reduced interference with server-side local computation. A prototype deployment of the OCFS 2 shared-disk filesystem over gmblock shows gains for various application benchmarks, provided I/O scheduling can eliminate the disk bottleneck due to concurrent access. ...|$|R
40|$|The dual-cross {{scenario}} of the hybrid {{wireless sensor networks}} (WSNs) is studied and a novel MIMO Cluster Cooperative Assignment Cross Layer Scheduling Scheme (MCCA-CLSS) is proposed in this paper. The comparison and the predominance of the proposed scheme are demonstrated, the clusters are optimized. With {{the help of the}} simulations, the relative energy consumption and the <b>end-to-end</b> <b>blocking</b> probability are all improved. The addressing ratio of success in the condition of the unchanged parameters and external information can be increased and the network can tolerate more hops to support reliable transportation by the proposed scheme. Comment: 4 figures, 9 th International Symposium on Communication and Information Technology 2009 (ISCIT 2009), September 28 - 30, 2009, South Kore...|$|E
40|$|Abstract—The {{realisation}} of cost-efficient Optical Burst Switching (OBS) networks can {{be greatly}} facilitated from minimising {{the number of}} contention resolution resources required at congested network nodes. In this paper we present a Fibre Delay Line (FDL) optimal allocation scheme where the total cost associated to the employment of FDLs is minimised subject to performance requirements {{defined in terms of}} maximum tolerable <b>end-to-end</b> <b>blocking</b> probability. The optimal buffer configuration is achieved by means of a constraint-handling genetic algorithm. We additionally increase the accuracy of our analysis by considering the non-Poissonian traffic characteristics of the OBS network under study. Results show that our method permits to identify an optimal FDL configuration that minimises the total buffer installation cost and simultaneously satisfies the network blocking probability requirements...|$|E
40|$|In this paper, we {{consider}} {{a class of}} loss networks where multiple traffic classes are present, each has different bandwidth requirement, and each traffic stream is routed according to an adaptive routing scheme. The performance metric of interest is the end-to-end call blocking probability. Blocking probabilities in a loss network have been studied quite extensively but very few considered multiple traffic classes and rates together with adaptive state dependent routing. We propose a fixed-point method, a. k. a. reduced load approximation, to estimate the <b>end-to-end</b> <b>blocking</b> probability in a multihop multirate loss network with adaptive routing. Simulation results are provided to {{compare with that of}} approximations. The approximation scheme is shown to be asymptotically correct in a natural limiting regime, and it gives conservative estimates of blocking probabilities under heavy traffic load...|$|E
40|$|This {{dissertation}} studied real-time interaction {{over the}} Internet (RTI 2) {{in the context}} of remote experimentation where there is typically a person at the client side interacting with physical equipments at the server side. Remote experimentations of mechatronic equipment have strong real-time constraints due to the dynamical evolution of the behaviors to be observed and controlled. The objective of this dissertation is to propose solutions that provide the best possible feedback to the user such that the drawbacks inherent to the distance between the client and the remote equipment are minimized while providing sufficient information about the equipment state and its operational conditions. In the ideal solution, the information representing the state of the remote equipment are rendered at the same pace it has been acquired, with a minimal time delay between the acquisition phase and the rendering phase. Solutions are proposed to approach as closely as possible to this ideal solution despite the inherent variability of the Internet and the versatility of the devices used by the clients. To characterize the feedback provided to the user, a definition for the RTI 2 Quality of Service is proposed which includes three properties: the level of interaction, the accuracy of dynamic rendering and the wealth of semantic content. As these three properties cannot be directly measured, three related metrics are defined. The metrics definition relies on two abstractions; the first one defines a block as a unit of information that fully describes the state and the conditions of operation of the remote equipment at a given time. The second abstraction defines an end-to-end structure that includes the communication link and both the server and the client devices. The estimated metrics are the <b>block</b> <b>end-to-end</b> round trip time, the block duration ratio and the block size ratio. To guarantee a given quality of service, a cascade end-to-end adaptation structure is proposed. This control scheme is designed to track the block round trip time by adapting the block size. The adaptation scheme and the underlying model are validated with real-world measurements. A mechanism called TCP Most-Recent is proposed as an enhancement to the TCP protocol. It alleviates the problem related to the TCP buffering mechanism, thus improving the data transmission delay. This mechanism is especially useful for applications that send perishable data as in RTI 2. Perishable data are data with limited time validity, thus resending this outdated data is useless and inefficient. The tradeoff in using TCP-MR is to accept possible losses in order to gain interactivity. Such a tradeoff can be limited if the adaptation, carried out at the application level, chooses the data to be discarded according to some criteria specified at the user level. This dissertation proposes a broad but consistent foundation for studying RTI 2 {{in the context of}} remote experimentation. It is build around three main contributions. First, based on the identified objectives of a successful interaction, the quality of service for RTI 2 in the context of remote experimentation is defined. The associated metrics and abstractions permitting to work at the right level are also defined. Second, using the provided metrics and abstractions, an adaptation scheme to enforce the QoS provided to the user is proposed and successfully validated. Third, a mechanism called TCP Most-Recent has been proposed to improve the information transmission delay without breaking the Internet best practice...|$|R
40|$|This {{special issue}} of the Journal of Networks is {{dedicated}} to the performance modeling and evaluation of computer and telecommunication systems, and includes extended versions of selected best papers accepted and presented at the 2011 International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS 2011). Seven papers were selected based on their excellent review scores. Their authors were invited to submit extended versions, which have undergone a second review process to guarantee that all the papers included in this Special Issue have been rigorously peer-reviewed. This selection includes empirical evaluations, simulation modeling and theoretical studies addressing a variety of topics related to the Performance Evaluation of Computer and Telecommunication Systems. The first paper is entiled “An Empirical Evaluation of Web System Access for Smartphone Clients”, authored by Scott Fowler, Katrin Hameseder and Anders Peterson. This paper identifies and studies methods that reduce the amount of web service data being transferred via wireless links to and from a web service client. Measurements were performed in a real environment based on a web service prototype providing public transport information for the city of Hamburg in Germany, using actual wireless links with a mobile Smartphone. REST (Representational State Transfer) based web services using the data Exchange formats JSON, XML and Fast Infoset were evaluated against the existing SOAP based web service. The overall results of the performance tests have proven that the use of REST leads to an improvement in terms of transferred data, serialisation/deserialization time and request–response time. The second paper entitled, “Decreasing the Call Blocking Probability of Broadband IPTV Services in Stationary and Peak-hour Scenarios”, is authored by Junyu Lai, Bernd E. Wolfinger and Stephan Heckmüller. In this paper, a state-vector-based simulation model is proposed to evaluate the <b>end-to-end</b> call <b>blocking</b> probability (E 2 E CBP) in an Internet Protocol TV (IPTV) delivery network with tree topology. The simulation model is then applied to both stationary and peak-hour scenarios, obtaining significant differences between the E 2 E CBPs evaluated in the two different scenarios. In addition, an extended TV channel admission control (TCAC) scheme is presented. The simulation experiments illustrate the potential of the extended TCAC scheme to enhance the IPTV quality of experience by significantly decreasing the E 2 E CBP (up to 25 %) in both stationary and peak-hour scenarios of the system studied. In the third paper entiled, “An On Demand Interference Aware Routing Protocol for VANETS”, Peppino Fazio, Floriano De Rango and Cesare Sottile propose an interference aware routing scheme for multi-radio vehicular networks. In order to relieve the effects of the co-channel interference perceived by mobile nodes, transmission channels are switched {{on the basis of a}} periodical Signal-to-Interference Ratio (SIR) evaluation. A new metric is also proposed, based on the maximization of the average SIR level of the connection between source and destination. This solution has been integrated with the AODV routing protocol to design an enhanced Signal-to-Interference-Ratio-AODV (SIR-AODV). NS- 2 has been used for implementing and testing the proposed idea. Despite a negligible increase in terms of protocol overhead, simulation results have shown that there are good enhancements in terms of throughput, packet delivery ratio and normalized SIR. The fourth paper, authored by Kishore Angrishi and Ulrich Killat, is entitled “A Node Operating Point Approach for Stochastic Analysis with Network Calculus”. In this paper, the concepts of effective bandwidth and effective capacity are used to describe independent stochastic arrival and service processes, respectively, and to identify node operating point to perform stochastic analysis with network calculus. The use of operating point (from large deviations theory) to perform stochastic analysis provides insight into the queue dynamics. Furthermore, using effective bandwidth and effective capacity functions within the framework of statistical network calculus allows efficient evaluation of performance bounds, which accuracy is investigated by comparing them with the exact results from queuing theory. The fifth paper, “Client-Side Framework for Automated Evaluation of Mechanisms to Improve HTTP Performance”, is authored by Paul Davern, Noor Nashid, Cormac J Sreenan and Ahmed Zahran. They present a multi-user client-side framework for evaluating HTTP performance named HTTP-Automated Evaluation (HTTP-AE). Three HTTP acceleration mechanisms deployed in an emulated satellite system are considered as case studies: using multiple connections to retrieve HTTP content over satellite, using different TCP slow-start congestion control algorithms, and HTTP Performance Enhancing Proxy (PEP), a mechanism introduced by the authors in a previous work. These case studies show that the framework can be used to test different design aspects that may affect HTTP performance. This way the advantages and limitations of different network design configurations can be determined. In the sixth paper, “Multicast Gain for IPTV Transmission in WiMAX Multi-hop Relay Networks”, by Alireza Abdollahpouri and Bernd E. Wolfinger, the multicast gain is introduced as a performance criterion to compare multicast and unicast efficiency in terms of required slots. Based on this measure, the benefits of multicasting in tree-structured IEEE 802. 16 j mobile multi-hop relay (MMR) networks are analyzed. Multicast support, wide coverage range, high bandwidth and mobility support make WiMAX a suitable solution for IPTV services to mobile users. Different scenarios and the effects of number of users, link qualities, user density and user distribution on multicast gain are evaluated. Several interesting results are presented, including the unexpected result that for some scenarios unicast is able to outperform multicast. Finally, the seventh paper, authored by Antonio Bueno, Pere Vila and Ramon Fabregat, is entitled “Charging Multicast Services: A Cost Distribution Scheme Comparative Study”. In this paper, the problem of cost distribution in a real-time multicast service across network domains is addressed. Assuming each domain that participates in the service can express their cost in terms of QoS parameters, the application of charging schemes that combine such unicast cost functions is studied. Several charging schemes are implemented and compared: Equal Link Split (ETS), Equal Link Split Downstream (ELSD), Normalized Unicast Cost (NUC), and MXUCS (Multicast eXtension of Unicast Charging Schemes, previously proposed by the same authors. While all of the charging schemes discussed present some positive aspects, MXUCS shows the best behaviour in terms of usage sensitivity and fairness. The guest editors would like to thank all the authors and reviewers for their valuable contributions to this special issue. We hope that the papers selected in this special issue will become useful resources for researchers and practitioners in the area of Performance Modeling and Evaluation of Computer and Telecommunication Systems. Finally, we would like the editors and editorial assistants for their help and support.  </p...|$|R
40|$|We {{consider}} {{the calculation of}} blocking probabilities in multicast trees with dynamic membership. We extend the work by Karvo et al., where an approximate algorithm based on the reduced load approximation (RLA) was given to calculate <b>end-to-end</b> <b>blocking</b> for infinite sized user populations in multicast networks. The new algorithm for calculating end-to-end call blocking exactly for an arbitrary sized user population {{is based on the}} known blocking probability algorithm in hierarchical multiservice access networks, where link occupancy distributions are alternately convolved and truncated. We show that the algorithm can be applied to multicast trees embedded in a network with an arbitrary topology carrying also non-multicast traffic. The resource sharing of multicast connections, however, requires the modification of the algorithm by introducing a new type of convolution, the OR-convolution. In addition, we discuss several different user population models for which the algorithm is applicable...|$|E
40|$|Effective {{traffic control}} in multirate {{networks}} is vital, because a small {{increase in the}} carried traffic may significantly increase the operator's revenue {{and at the same}} time enhance the user's satisfaction. Therefore evaluation of <b>end-to-end</b> <b>blocking</b> probabilities and carried traffic when combining different routing and link allocation strategies is important. A broad spectrum of different routing and link allocation procedures is available in the literature; unfortunately most of the analytical models are either constrained by the network topology, or of high computational complexity. This paper (1) presents analytical and simulation results on a variety of combinations of routing and link allocation algorithms and (2) proposes an optimization model in which the revenue or carried traffic in multi-rate loss networks is optimized with respect to load sharing parameters or an optimal partitioning between bandwidth classes is found. With respect to routing we consider non-alternate, s [...] ...|$|E
40|$|Absrrucr-In {{this paper}} {{we present a}} {{hierarchical}} loss network model for estimating the <b>end-to-end</b> <b>blocking</b> probabilities of large networks. As networks grow in size, nodes tend to form clusters geographically and hi-erarchical routing schemes are more commonly used. Loss network and reduced load models are often used to approximate end-to-end call block-ing probabilities and hence throughput. However so far all work being done {{in this area is}} for flat networks with flat routing schemes. We aim at developing a more efficient approximation method for networks that have a natural hierarchy and/or when some form of hierarchical routing policy is used. We present two hierarchical models in detail for fixed hi-erarchical routing and dynamic hierarchical routing policies, respectively, via the notion of network abstraction, route segmentation, traffic segrega-tion and aggregation. Computation is done separately within each cluster (local) and among clusters (global), and the fixed point is obtained by it-eration between local and global computations. We present results from both numerical experiments and discrete event simulations. I...|$|E
40|$|In this paper, we {{consider}} {{a class of}} loss networks where multipletraffic classes are present, each has different bandwidth requirement,and each traffic stream is routed according to an adaptive routingscheme. We propose a fixed-point method, a. k. a. reduced load approximation,to estimate the <b>end-to-end</b> <b>blocking</b> probability for such networks. The approximation scheme is shownto be asymptotically correct in a natural limiting regime, and it givesconservative estimates of blocking probabilities under heavy trafficload. Simulation results are provided to compare performance estimatesobtained from our analytical approximation scheme and discrete eventsimulations. We also show how this analytical approximation scheme can be linked withnumerical mathematical programming tools to help design a network,by selecting network design parameters via trade-off analysis, evenwith several design objectives. In one application we use the multi-objective optimization toolCONSOL-OPTCAD to design trunk reservation parameters and balance linkcapacity. In another application we use automatic differentiationto get sensitivities of blocking probabilities w. r. t. offered trafficload...|$|E
40|$|In {{this paper}} {{we present a}} {{hierarchical}} loss network model for estimating the <b>end-to-end</b> <b>blocking</b> probabilities for large networks. As networks grow in size, nodes tend to form clusters geographically and hierarchical routing schemes are more commonly used. Loss network and reduced load models are often used to approximate end-to-end call blocking probabilities and hence throughput. However so far all work being done {{in this area is}} for flat networks with flat routing schemes. We aim at developing a more efficient approximation method for networks that have a natural hierarchy and/or when some form of hierarchical routing policy is used. We present two hierarchical models in detail for fixed hierarchical routing and dynamic hierarchical routing policies, respectively, via the notion of network abstraction, route segmentation, traffic segregation and aggregation. Computation is done separately within each cluster (local) and among clusters (global), and the fixed point is obtained by iteration between local and global computations. We also present numerical results for the first case...|$|E
40|$|In {{this paper}} we {{consider}} {{a class of}} loss networks that have arbitrary topologies and routes of arbitrary length. Multiple traffic classes are present, each with different bandwidth requirement, and each routed according to a state-dependent routing scheme. In particular, we consider the least loaded routing method generalized to routes of arbitrary number of hops. The connection level performance metric of interest is the <b>end-to-end</b> <b>blocking</b> probability. We are interested in developing fast evaluation methods to provide reasonably accurate estimates of the blocking probability, especially under heavy traffic load. Our algorithms {{are based on the}} fixed-point method framework, also known as the reduced load approximation. In addition to what commonly examined by previous work, two more factors contribute to the complexity of the computation in the scenario under consideration in this paper. One is the state-dependent nature of the routing mechanism, the other is the possible overlapping between routes due to the general multihop topology of the network. We present two fast approximation algorithms to evaluate the blocking probability with state-dependent routing by simplifying the route overlapping computation. We discuss the computational complexity of our algorithms as well as sources of approximation error. We then compare the numerical results with that of simulation and show that our algorithms provide fairly accurate blocking probability estimates especially under heavy traffic load...|$|E
40|$|The {{design of}} {{congestion}} controls for ATM-based telecommunication networks {{is a problem}} of much recent interest. Preventive controls attempt to restrain the development of congestion by shaping or filtering the incoming cell streams at the user-network interface, independently of the dynamics of the network itself. Preventive controls have a policing function, to protect the network from overload due to malice or malfunction on the user side of the interface, and a regulating function, to smooth the demand on network storage and bandwidth in the hope of improving network performance. We study the regulating function in simple ATM systems in which the transmission line buffers are depleted in FIFO (first in, first out) order. Our point of departure is the observation, formulated as a theorem, that regulation controls the location, rather than the amplitude, of network-induced impairments, moving cell losses from inside the network to the network boundary, but at the price of increased overall loss or delay. We display the tradeoff between interior and <b>end-to-end</b> <b>blocking</b> for the Leaky Bucket regulator applied to Poisson sources, showing how efficiency, measured in different ways, diminishes with the number of sources. We examine the interplay between cell loss rate and worst case delay, again for Poisson sources, and assuming that the Leaky Bucket has been optimized for one of the two criteria, subject to a constraint on the other. Our results suggest that worst-case delay bounds can be very conservative in a variety of settings, and that FIFO networks using preventive controls only, and on a per-session basis, will be under-controlled...|$|E

