17|10000|Public
50|$|Information {{management}} {{is closely related}} to, and overlaps with, the management of <b>data,</b> <b>systems,</b> <b>technology,</b> processes and - where the availability of information is critical to organisational success - strategy. This broad view {{of the realm of}} information management contrasts with the earlier, more traditional view, that the life cycle of managing information is an operational matter that requires specific procedures, organisational capabilities and standards that deal with information as a product or a service.|$|E
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1995 / Riviera Hotel, Las Vegas, NevadaTo support {{initiatives}} for cheaper, faster, better ground telemetry systems, the <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) at NASA Goddard Space Flight Center {{is developing}} a new Very Large Scale Integration (VLSI) Application Specific Integrated Circuit (ASIC) targeted to dramatically {{lower the cost of}} telemetry frame synchronization. This single VLSI device, known as the Parallel Integrated Frame Synchronizer (PIFS) chip, integrates most of the functionality contained in high density 9 U VME card frame synchronizer subsystems currently in use. In 1987, a first generation 20 Mbps VMEBus frame synchronizer based on 2. 0 micron CMOS VLSI technology was developed by <b>Data</b> <b>Systems</b> <b>Technology</b> Division. In 1990, this subsystem architecture was recast using 0. 8 micron ECL & GaAs VLSI to achieve 300 Mbps performance. The PIFS chip, based on 0. 7 micron CMOS technology, will provide a superset of the current VMEBus subsystem functions at rates up to 500 Mbps at approximately one-tenth current replication costs. Functions performed by this third generation device include true and inverted 64 bit marker correlation with programmable error tolerances, programmable frame length and marker patterns, programmable search-check-lock-flywheel acquisition strategy, slip detection, and CRC error detection. Acquired frames can optionally be annotated with quality trailer and time stamp. A comprehensive set of cumulative accounting registers are provided on-chip for data quality monitoring. Prototypes of the PIFS chip are expected in October 1995. This paper will describe the architecture and implementation of this new low-cost high functionality device...|$|E
40|$|Software reuse {{has become}} a major goal in the {{development}} of space systems, as a recent NASA-wide workshop on the subject made clear. The <b>Data</b> <b>Systems</b> <b>Technology</b> Division of Goddard Space Flight Center has been working on tools and techniques for promoting reuse, in particular in the development of satellite ground support software. One of these tools is the Experiment in Libraries via Incremental Schemata and Cobweb (ElvisC). ElvisC applies machine learning to the problem of organizing a reusable software component library for efficient and reliable retrieval. In this paper we describe the background factors that have motivated this work, present the design of the system, and evaluate the results of its application...|$|E
40|$|Critical {{steps in}} the systems {{analysis}} process for NASA's <b>data</b> <b>system</b> planning are: (1) compilation of future user/mission requirements, (2) development of alternative overall <b>data</b> <b>system</b> concepts which satisfy requirements, (3) assessment of future development and availability of <b>data</b> <b>system</b> <b>technology,</b> and (4) cost/performance tradeoff studies of the alternative concepts for systems optimization. Tasks within the NEEDS (NASA End-to-End <b>Data</b> <b>System)</b> Program, which correspond to the critical steps in this systems analysis process are examined...|$|R
40|$|Approximately 213 {{citations}} {{from the}} international literature which concern {{the development of the}} optical <b>data</b> storage <b>system</b> <b>technology</b> are presented. Topics covered include holographic computer storage devices, crystal, magneto, and electro-optics, imaging techniques, in addition to optical data processing and storage...|$|R
40|$|Progress is {{summarized}} for {{the following}} tasks: Natural gas reservoir <b>data</b> <b>system</b> development; <b>Technology</b> transfer; Software enhancement; and Supplemental reservoir studies and data collection. GASIS is a national database of geological, engineering, production, and ultimate recovery data for US gas reservoirs...|$|R
40|$|The transfer, processing, {{and use of}} {{satellite}} data are discussed. Topics relating to simulation and processing techniques include computer design assessments through simulation, data system dynamic simulation, and future timing accuracy requirements and procedures for data processing. Subjects relevant to data base management systems and users and their needs include an image-based information system architecture for correlation satellite and topological data base, efficient searching and sorting applications using an associative array processor, analysis of user's needs for a large technical data base, and variable length data formats. The technology development outlook was considered with attention to <b>data</b> <b>systems</b> <b>technology</b> outlook for supporting NASA programs, a user-oriented interactive information extraction system, and flow control and sorting techniques for telemetry packets...|$|E
40|$|The {{content and}} status of the {{evolving}} Space Station Data System (SSDS) development program are presented. High level system requirements and schedules are reviewed, and the challenges of SSDS development are discussed. Present content of the program consists of three major activities: (1) two contracted parallel Space Station Data System architecture studies; (2) the space station phase B definition studies to be awarded in early 1985; and (3) a test bed project for the evaluation and proof-of-concept of <b>data</b> <b>systems</b> <b>technology</b> for space station applications and for the advanced development of long-lead hardware and software for the initial and growth space station configurations. An overview of the present SSDS concept is provided, and the roles of NASA centers in this activity are summarized...|$|E
40|$|International Telemetering Conference Proceedings / October 27 - 30, 1997 / Riviera Hotel and Convention Center, Las Vegas, NevadaTo {{support the}} {{processing}} of International Space Station (ISS) Payloads, the Kennedy Space Center (KSC) had {{the need to develop}} specialized test and validation equipment to quickly identify interface problems between the payload or experiment under test and the communication and telemetry downlink systems. To meet this need, the Payload Data Analyzer (PDA) System was developed by the <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) of NASAâ€™s Goddard Space Flight Center (GSFC) to provide a suite of troubleshooting tools and data snapshot features allowing for diagnosis and validation of payload interfaces. The PDA System, in conjunction with the Payload Data Generator (PDG) System, allow for a full set of programmable payload validation tools which can quickly be deployed to solve crucial interface problems. This paper describes the architecture and tools built in the PDA which help facilitate Space Station Payload Processing...|$|E
40|$|Papers {{from the}} fourth annual NASA Symposium on VLSI Design, co-sponsored by the IEEE, are presented. Each year this {{symposium}} is organized by the NASA Space Engineering Research Center (SERC) at the University of Idaho and is held {{in conjunction with a}} quarterly meeting of the NASA <b>Data</b> <b>System</b> <b>Technology</b> Working Group (DSTWG). One task of the DSTWG is to develop new electronic technologies that will meet next generation electronic <b>data</b> <b>system</b> needs. The symposium provides insights into developments in VLSI and digital systems which can be used to increase <b>data</b> <b>systems</b> performance. The NASA SERC is proud to offer, at its fourth symposium on VLSI design, presentations by an outstanding set of individuals from national laboratories, the electronics industry, and universities. These speakers share insights into next generation advances that will serve as a basis for future VLSI design...|$|R
40|$|Using a structured, experienced-based approach, Goddard Space Flight Center (GSFC) has {{assessed}} the generic functional requirements for a lunar mission control and <b>data</b> delivery (CDD) <b>system.</b> This analysis {{was based on}} lunar mission requirements outlined in GSFC-developed user traffic models. The CDD <b>system</b> will facilitate <b>data</b> transportation among user elements, element operations, and user teams by providing functions such as data management, fault isolation, fault correction, and link acquisition. The CDD system for the lunar missions must not only satisfy lunar requirements but also facilitate and provide early development of <b>data</b> <b>system</b> <b>technologies</b> for Mars. Reuse and evolution of existing <b>data</b> <b>systems</b> can help to maximize system reliability and minimize cost. This paper presents a set of existing and currently planned NASA <b>data</b> <b>systems</b> that provide the basic functionality. Reuse of such systems {{can have an impact}} on mission design and significantly reduce CDD and other system development costs...|$|R
40|$|Continuing {{advances}} {{in space and}} Earth science requires increasing amounts of data to be gathered from spaceborne sensors. NASA expects to launch sensors {{during the next two}} decades which will be capable of producing an aggregate of 1500 Megabits per second if operated simultaneously. Such high data rates cause stresses in all aspects of end-to-end <b>data</b> <b>systems.</b> <b>Technologies</b> and techniques are needed to relieve such stresses. Potential solutions to the massive data rate problems are: data editing, greater transmission bandwidths, higher density and faster media, and data compression. Through four subpanels on Science Payload Operations, Multispectral Imaging, Microwave Remote Sensing and Science Data Management, recommendations were made for research in data compression and scientific data applications to space platforms...|$|R
40|$|With {{the market}} {{conditions}} becoming tougher and tougher, due to more competition through {{the implementation of}} the European market, a greater sensitivity for environmental protection with its ensuing impact on planning conditions, project controlling has become more important than ever. One aim of this paper is developing an integrated system of project controlling, i. e. the integration of time planning, cost planning and capacity planning in one single system. It is based on the algorithms of critical path analysis, providing the basic components for time planning. However, to make such a system practical graphic presentations and control mechanisms are required above all. Besides, additional components for deadline and cost checks at any given time plus actual and target comparisons for the past or planning variants are needed. This paper focuses on optimising the use of production facilities. This very field is the least developed in intermediate <b>data</b> <b>systems</b> <b>technology.</b> One essential {{reason for this is that}} the computing procedures used so far take so much time even on large computers that they are hardly used in practice. M. Bartusch's thesis and T. Falck's paper outline a method that finds the shortest project duration/span by variations of scheduling with the number of production facilities given. This method has been adapted to computers of intermediate <b>data</b> <b>systems</b> <b>technology.</b> It is supplemented by an exact method providing the lowest number of production facilities by leveling with the project duration given. In addition a target function has been derived additionally smoothing the operation curve of production facilities by applying special heuristics. Wile dealing with these curves it became manifest that a certain flexibility in determining the curve is more often required rather than a minimum number of production facilities. Heuristics in connection with the assessed target function is able to cope with this demand. Maximum use of production facilities as defined by the users can be traced. Tests have demostrated the high quality of heuristic planning results, often identical with the optimum solution. This paper makes available to modern management a system which now in addition to time scheduling and cost budgeting also deals with capacity planning and optimizing in one integrated system...|$|E
40|$|NASA's {{environment}} {{mirrors the}} {{changes taking place}} in the nation at large, i. e. workers are being asked to do more work with fewer resources. For software developers at NASA's Goddard Space Flight Center (GSFC), the effects of this change are that we must continue to produce quality code that is maintainable and reusable, but we must learn to produce it more efficiently and less expensively. To accomplish this goal, the <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) at GSFC is trying a variety of both proven and state-of-the-art techniques for software development (e. g., object-oriented design, prototyping, designing for reuse, etc.). In order {{to evaluate the effectiveness of}} these techniques, the Software Process Assessment (SPA) program was initiated. SPA was begun under the assumption that the effects of different software development processes, techniques, and tools, on the resulting product must be evaluated in an objective manner in order to assess any benefits that may have accrued. SPA involves the collection and analysis of software product and process data. These data include metrics such as effort, code changes, size, complexity, and code readability. This paper describes the SPA data collection and analysis methodology and presents examples of benefits realized thus far by DSTD's software developers and managers...|$|E
40|$|International Telemetering Conference Proceedings / October 25 - 28, 1993 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe Small Explorer (SMEX) Program at NASA's Goddard Space Flight Center (GSFC) is {{the first}} set of Goddard {{missions}} to employ Consultative Committee for Space Data Systems (CCSDS) recommended standards(1) (2) for telemetry data transmission. These international standards form the basis for much of NASA's future telemetry data system development. The GSFC's <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) has been heavily involved with the development of systems for both flight and ground system application of these standards since 1985 (3). The result of this effort is the development of an approach which provides basic subsystem and system solutions which meet these standards. Based on this approach, a number of generic telemetry processing systems have been adapted to meet applications for the SMEX Program. Some of these applications include: the initial capture, processing, and distribution of CCSDS data for the integration and testing of the SMEX spacecraft before launch; the ground station data acquisition, processing, and transmission; local science data distribution; and other applications involving ground system testing and verification. The {{purpose of this paper is}} to describe a number of these applications and to show how generic system elements were configured and adapted to meet all of the requirements for these applications...|$|E
40|$|Welcome to {{the third}} annual NASA Symposium on VLSI Design, co-sponsored by the IEEE. Each year this {{symposium}} is organized by the NASA Space Engineering Research Center (SERC) at the University of Idaho and is held {{in conjunction with a}} quarterly meeting of the NASA <b>Data</b> <b>System</b> <b>Technology</b> Working Group (DSTWG). One task of the DSTWG is to develop new electronic technologies that will meet next generation electronic <b>data</b> <b>system</b> needs. The symposium provides insights into developments in VLSI and digital systems which can be used to increase <b>data</b> <b>systems</b> performance. The NASA SERC is proud to offer, at its third symposium on VLSI design, presen-tations by an outstanding set of individuals from national laboratories, the electronics industry and universities. These speakers share insights into next generation advances that will serve as a basis for future VLSI design. interest in the conference has increased with 46 papers in 8 categories included in this years proceedings. National Labor_itories are represented by Lawrence Livermor...|$|R
40|$|Architectural {{modeling}} and analysis {{is a critical}} phase in developing large and complex software systems. The usefulness of multiple views has likewise long been recognized. In this experience report, we explain how we used two ADLs to model a system initially described in UML. The system (SCRover) is designed and built in close collaboration with NASAâ€™s Jet Propulsion Laboratory, using their Mission <b>Data</b> <b>System</b> <b>technology.</b> We describe (a) the processes {{that we used to}} extract architectural models from the UML description, (b) the way in which each ADL was used to model the system, (c) a classification of the architectural defects we uncovered, and (d) a comparison of the relative benefits of the two ADLs in terms of the different classes of defects they uncovered. 1...|$|R
40|$|The {{use of the}} <b>data</b> base {{management}} <b>system</b> ADABAS and {{the companion}} software NATURAL and COM-PLETE at the Langley Research Center is evaluated. A brief overview of <b>data</b> base management <b>system</b> <b>technology</b> is provided as well as system upgrading, user requirements, {{and use of the}} system for administrative support...|$|R
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1995 / Riviera Hotel, Las Vegas, NevadaThe Earth Observing System-AM (EOS-AM) {{spacecraft}}, {{the first}} in a series of spacecraft for the EOS, is scheduled for launch in June of 1998. This spacecraft will carry high resolution instruments capable of generating large volumes of earth science data at rates up to 150 Mbps. Data will be transmitted in a packet format based upon the Consultative Committee for Space Data Systems (CCSDS) Advanced Orbiting Systems (AOS) recommendations. The <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) at NASA's Goddard Space Flight Center (GSFC) has developed a set of high performance CCSDS return-link processing systems to support testing and verification of the EOS-AM spacecraft. These CCSDS processing systems use Versa Module Eurocard bus (VMEBus) Very Large Scale Integration (VLSI) -based processing modules developed for the EOS ground segment to acquire and handle the high rate EOS data. Functions performed by these systems include frame synchronization, Reed-Solomon error correction, fill frame removal, virtual channel sorting, packet service processing, and data quality accounting. The first of the systems was delivered in October 1994 to support testing of the onboard formatting equipment. The second and third systems, delivered in April 1995, support spacecraft checkout and verification. This paper will describe the function and implementation of these systems...|$|E
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1989 / Town & Country Hotel & Convention Center, San Diego, CaliforniaOver {{the last}} four years, NASA's Goddard Space Flight Center <b>Data</b> <b>Systems</b> <b>Technology</b> Division has {{designed}} and developed a number of standard VLSI telemetry data system components and subsystems to meet NASA's high performance telemetry processing needs. Integrated into the standard VME open bus architecture and supported by real time operating system components, these systems presently support sustained data rates to 20 Mbps. While these systems greatly reduce the basic costs for high performance data acquisition and processing, the expected future widespread acceptance and use of distributed telemetry processing will require an even greater reduction in both size and cost per station while maintaining high performance specifications. To meet this need, GSFC, together with Clemson University, has begun development of the Transportable Telemetry Workstation (TTW). This system consists primarily of the adaptation of GSFC's VLSI components and system architecture to the Apple Macintosh II/IIx personal computer and its NuBus architecture. The actual telemetry acquisition and processing components of the TTW function independently from the main user workstation environment (the Macintosh). NuBus cards, augmented by a separate telemetry processing bus system structure to support high data rates, perform telemetry functions. The Macintosh II acts as the user workstation providing control, status, and data exchange through its NuBus backplane to the telemetry processing system. The Macintosh II will provide additional processing of data (quick look data), user control and display services, and network (Ethernet) services as required...|$|E
40|$|This {{document}} {{described the}} ongoing effort at Goddard Space Flight Center in the TRENDS project to apply advanced {{technology to the}} problem of Trend Analysis (TA) of spacecraft. The overall problem of trend analysis is outlined as a case of diagnosis with certain exceptional circumstances. The Model-Based approach to Diagnosis (MBD) and TA is described, compared with other methods, and the argument made for the MBD approach to TA. Various modeling methods are reviewed, including discrete event, qualitative, adaptive, and hybrids of these. Technology integration in the project used in the project is described, including the Data Analysis and Systems Modeling Environment (DASME) implementation of the Discrete EVent Systems (DEVS) method for discrete event modeling; the Generic Trend Analysis System (GTAS), GENSAA, and COTS products. Finally, the historical development of the applications considered will be reviewed, including battery modeling, the EUVE transponder failure data, and an antenna-slewing laboratory example. Keywords: trend analysis, model-based diagnosis, case-based reasoning, qualitative modeling, adaptive modeling, hybrid modeling, discrete event modeling GSFC BI-i 08 / 28 / 01 Acronyms and Abbreviations BM behavior model COTS Commercial Off-The-Shelf CGE Configurable Graphical Editor DIG ? TROY DASME Data Analysis and System Modeling Environment DEVS Discrete EVent System DSTL <b>Data</b> <b>Systems</b> <b>Technology</b> Laboratory EUVE Extreme UltraViolet Explorer FGM fault generation model FOT Flight Operations Team GENSAA GENeric Spacecraft Analyst Assistant GOTS Government Off-The-Shelf GSFC Goddard Space Flight Center GTAS Generic Trend Analysis System GUI graphical user interface MAST ? TROY MBD model-based diagnostics NASA National Aeronautics and Space Administratio [...] ...|$|E
40|$|Abstract. Based {{upon the}} resume of {{information}} system integration, this paper sets forth the <b>system</b> integration <b>technologies,</b> such as <b>system</b> architecture <b>technology,</b> collective design <b>technology,</b> <b>system</b> integration design <b>technology,</b> <b>data</b> sharing <b>technology,</b> <b>system</b> integration validation <b>technology,</b> <b>system</b> {{modeling and simulation}} technology and integration engineering management technology, and puts forward the integration effect analysis. Thenceforth a primary prospect is presented...|$|R
50|$|Over-the-counter data (OTCD) is {{a design}} {{approach}} used in <b>data</b> <b>systems,</b> particularly educational <b>technology</b> <b>data</b> <b>systems,</b> {{in order to}} increase the accuracy of users' data analyses by better reporting data. The approach involves adhering to standards that are organized by five components: Label, Supplemental Documentation, Help System, Package/Display, and Content.|$|R
40|$|The {{current status}} of the Active Controls Technology (ACT) for the {{advanced}} subsonic transport project is investigated through analysis of the <b>systems</b> technical <b>data.</b> Control <b>systems</b> <b>technologies</b> under examination include computerized reliability analysis, pitch axis fly by wire actuator, flaperon actuation system design trade study, control law synthesis and analysis, flutter mode control and gust load alleviation analysis, and implementation of alternative ACT systems. Extensive analysis of the computer techniques involved in each system is included...|$|R
40|$|International Telemetering Conference Proceedings / October 26 - 29, 1998 / Town & Country Resort Hotel and Convention Center, San Diego, CaliforniaThe {{advent of}} {{adaptive}} computers built from re-programmable logic devices presents a potential solution {{for meeting the}} data processing requirements of the new era of Earth monitoring satellites to be launched by the National Aeronautics and Space Administration (NASA) Earth Science Enterprise project. The Earth Observing System (EOS) AM- 1 spacecraft, the first satellite of this new era, will produce in only six months as much data as NASA has collected to this date. As a consequence, the Earth Science Data and Information System (ESDIS) project is building high performance and highly costly parallel processing systems to address the real-time data production requirements. Together with the high performance front-end ingest and level 0 processing microcircuits developed in-house at the Goddard Space Flight Centerâ€™s (GSFC) <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD), adaptive computers present a possible alternative to traditional CPU-based systems to increase the performance while reducing the cost of satellite telemetry processing systems. The Adaptive Scientific Data Processing (ASDP) project has been investigating the use of adaptive computers {{in the implementation of}} space borne scientific data processing systems. An order of magnitude processing speed acceleration over high-end workstations has been demonstrated for both level 1 and level 3 algorithms. This paper discusses the use of adaptive computing in satellite telemetry processing systems, level 1 and beyond. Primarily, it describes the efforts and presents the results of two prototypes developed by the ASDP project. The limitations of {{the current state of the}} technology are discussed and the expected improvements to facilitate the adoption of adaptive computers are presented. Finally, future work of the ASDP project is discussed...|$|E
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1995 / Riviera Hotel, Las Vegas, NevadaOver {{the last}} several years, the <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) at Goddard Space Flight Center (GSFC) has {{developed}} software tools to generate simulated spacecraft data to support the development, test, and verification of prototype and production of its Very Large Scale Integration (VLSI) telemetry data systems. Recently, these data simulation tools have demonstrated their versatility and flexibility in the testing and deployment of several very high performance Level Zero Processing (LZP) systems. Because LZP involves the wide scale reordering of transmitted telemetry data, the data simulation tools were required to create {{a number of very}} large and complex simulated data sets to effectively test these high rate systems. These data sets simulated spacecraft with numerous instrument data sources downlinking out-of-sequence and errored data streams. Simulated data streams were encapsulated in Consultative Committee for Space Data Systems (CCSDS) packet and NASCOM data formats. The knowledge and expertise gained {{in the development of the}} current simulation tools has been used to develop a new generation data simulation tool, known as the Simulated Telemetry Generation (STGEN) package. STGEN is a menu driven software package running on UNIX platforms that can implement dynamic test scenarios with very fast turn around times from the data set design to the data set generation. The error options and locations in the telemetry data stream are fed via simple programs which are in turn script-driven. Scripts are used to manipulate packets, frames, and permit error insertion more easily and quickly. This paper first describes the STGEN software package and its test data design strategies. It then provides an example of STGEN 's first usage in the testing of systems to support EOS-AM spacecraft. Finally, a description of future planned improvements and uses of STGEN are provided...|$|E
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1995 / Riviera Hotel, Las Vegas, NevadaThe wide use of {{standard}} packet telemetry protocols {{based on the}} Consultative Committee for Space Data Systems (CCSDS) recommendations in future space science missions has created a large demand for low-cost ground CCSDS processing systems. Some of the National Aeronautics and Space Administration (NASA) missions using CCSDS telemetry include Small Explorer, Earth Observing System (EOS), Space Station, and Advanced Composite Explorer. For each mission, ground telemetry systems are typically used {{in a variety of}} applications including spacecraft development facilities, mission control centers, science data processing sites, tracking stations, launch support equipment, and compatibility test systems. The future deployment of EOS spacecraft allowing direct broadcast of data to science users will further increase demand for such systems. For the last ten years, the <b>Data</b> <b>Systems</b> <b>Technology</b> Division (DSTD) at NASA Goddard Space Flight Center (GSFC) has been applying state-of-the-art commercial Very Large Scale Integration (VLSI) Application Specific Integrated Circuit (ASIC) technology to further reduce the cost of ground telemetry data systems. As a continuation of this effort, a new desktop CCSDS processing system is being prototyped that offers up to 150 Mbps performance at a replication cost of less than 20 K. This system acts as a gateway that captures and processes CCSDS telemetry streams and delivers them to users over standard commercial network interfaces. This paper describes the development of this prototype system based on the Peripheral Component Interconnect (PCI) bus and 0. 6 micron complementary metal oxide semiconductor (CMOS) ASIC technology. The system performs frame synchronization, bit transition density decoding, cyclic redundancy code (CRC) error checking, Reed-Solomon decoding, virtual channel sorting/filtering, packet extraction, and quality annotation and accounting at data rates up to and beyond 150 Mbps...|$|E
5000|$|In January 2014, Avella Specialty Pharmacy named Rebecca Shanahan as its new CEO. That same year, Avella {{became a}} {{registered}} Outsourcing Facility through the U.S. Food and Drug Administration. In March 2015, Avella was approved to register a [...]pharmacy domain name which identifies safe and legal pharmacies online. That same month, Avella partnered with Sentry <b>Data</b> <b>Systems,</b> a <b>technology</b> <b>systems</b> producer for hospitals and clinics, to extend coverage of entities {{participating in the}} 340B drug discount program. In 2015, Inc. named Avella to the Inc. 5000 list for the ninth time.|$|R
40|$|The Global Change Technology Initiative (GCTI) was {{established}} to develop technology which will enable use of satellite systems of Earth observations on a global scale, enable use of the observations to predictively model Earth's changes, and provide scientists, government, business, and industry with quick access to the resulting information. At LaRC, a GCTI Architecture Trade Study was undertaken to develop and evaluate the architectural implications {{to meet the requirements}} of the global change studies and the eventual implementation of a global change system. The output of the trade study are recommended technologies for the GCTI. That portion of the study concerned with the information <b>data</b> <b>system</b> is documented. The information <b>data</b> <b>system</b> for an earth global change modeling system can be very extensive and beyond affordability in terms of today's costs. Therefore, an incremental approach to gaining a system is most likely. An options approach to levels of capability versus needed technologies was developed. The primary drivers of the requirements for the information <b>data</b> <b>system</b> evaluation were the needed science products, the science measurements, the spacecraft orbits, the instruments configurations, and the spacecraft configurations and their attendant architectures. The science products requirements were not studied here; however, some consideration of the product needs were included in the evaluation results. The information <b>data</b> <b>system</b> <b>technology</b> items were identified from the viewpoint of the desirable overall information system characteristics...|$|R
40|$|The FAILSAFE {{project is}} {{developing}} concepts and prototype implementations for software health management in mission- critical, real-time embedded systems. The project unites {{features of the}} industry-standard ARINC 653 Avionics Application Software Standard Interface and JPL s Mission <b>Data</b> <b>System</b> (MDS) <b>technology</b> (see figure). The ARINC 653 standard establishes requirements for the services provided by partitioned, real-time operating <b>systems.</b> The MDS <b>technology</b> provides a state analysis method, canonical architecture, and software framework that facilitates the design and implementation of software-intensive complex <b>systems.</b> The MDS <b>technology</b> {{has been used to}} provide the health management function for an ARINC 653 application implementation. In particular, the focus is on showing how this combination enables reasoning about, and recovering from, application software problems...|$|R
40|$|The {{use of the}} Transportable Applications Executive (TAE) for {{prototyping}} {{user interfaces}} has been the prime force behind the new TAE research and development work. The <b>Data</b> <b>Systems</b> <b>Technology</b> Division at GSFC is developing prototypes of user interfaces for different functions involved in the operation, analysis and data communication of space station payloads. TAE is a valuable prototyping tool because it enables a developer to build an entire application user interface model and run it without writing a single line of application code. One force driving new development {{is the need to}} update TAE's user interface to support the latest interactive graphic device technology. The current TAE, TAE Classic, uses interface techniques designed for an 80 x 24 character monochrome alphanumeric terminal, but does not effectively utilize features such as windowing, graphics, color, and selection devices available on newer workstations. To meet our needs, development of a TAE Plus began in FY- 86 and involves augmenting TAE with three different sets of tools: a user interface toolkit; an application toolkit; and run-time service subroutines. A phased approach is being used to develop TAE Plus. In the first phase, we have met the needs of the user community and provided some support for rapid prototyping by developing a TAE Facelift, which adds an enhanced TAE interface (with windowing, mouse interaction, pull-down menus, etc.) to a select set of graphic workstations. The TAE Facelift allows many new concepts to be tested quickly for feedback and performance. In the second phase, a fully-integrated user interface management system, TAE Plus, will be built that supports the separation of interface from application, with the concomitant ability to prototype and rapidly change interfaces. This robust functionality will support, in an integrated manner, an application's development cycle from the prototype step through to the fully operational system...|$|E
40|$|International Telemetering Conference Proceedings / November 04 - 07, 1991 / Riviera Hotel and Convention Center, Las Vegas, NevadaNASAâ€™s {{reaction}} to {{requirements for the}} Space Station Freedom eraâ€™s telemetry data systems has been the continuing effort to combine a modular design approach with stateof-the-art VLSI technology for developing telemetry data processing systems. As part of this effort, NASAâ€™s <b>Data</b> <b>Systems</b> <b>Technology</b> Division, in cooperation with Clemson University, is developing a Macintosh II based Telemetry and Command (MacTAC) system. This system performs telemetry data processing functions including frame synchronization, Reed-Solomon decoding, and packet reassembly at moderate data rates of 5 Mbps (20 Mbps burst). The MacTAC is a low-cost, transportable, easy to use, compact system designed to meet requirements specified by the Consultative Committee for Space Data Systems (CCSDS) while remaining flexible enough to support {{a wide variety of}} other user specific telemetry processing requirements (e. g., TDM data). In addition, the MacTAC can accept or generate forward data (such as spacecraft commands), calculate and append a Polynomial Check Code (PCC), and output this data to NASCOM to provide full Telemetry and Command (TAC) capability. Semi-custom VLSI gate arrays perform the return link functions of NASCOM deblocking, correlation, and frame synchronization. Reed-Solomon decoding (for error detection) and packet reassembly are also performed by modern microprocessor and semi-custom VLSI components. The local user interface is a standard Macintosh application with the wellknown look and feel of the Macintosh environment. A remote interface is possible via Ethernet which allows the system to be completely controlled from any location capable of generating the required remote operating commands. Return link data may be viewed in real time on the local or remote user interface screen in a variety of formats along with system status information. In addition, data may also be archived on SCSI disks for later retrieval and analysis as needed. This paper describes the general architecture and functionality of this MacTAC system including the particular custom telemetry cards, the various input/output interfaces, and the icon driven user interface...|$|E
40|$|With the {{tremendous}} growth of digital multimedia <b>data,</b> multimedia <b>systems</b> and <b>technologies</b> are evolving rapidly {{to meet this}} challenge. The evolution {{can be described as}} one in which the technology focus is moving from treating multimedia content as signals to more advanced extraction and processing of multimedia features, semantics and knowledge...|$|R
25|$|In {{addition}} to brands selling assembled vehicles, GM {{has also had}} various automotive-component and non-automotive brands, many of which it divested in the 1980s through 2000s. These have included Euclid and Terex (earthmoving/construction/mining equipment & vehicles); Electro-Motive Diesel (locomotive, marine, and industrial diesel engines); Detroit Diesel (automotive and industrial diesel engines); Allison (aircraft engines, transmissions, gas turbine engines); Frigidaire (appliances including refrigeration and air conditioning); New Departure (bearings); Delco Electronics and ACDelco (electrical and electronic components); GMAC (finance); General Aviation and North American Aviation (airplanes); GM Defense (military vehicles); and Electronic <b>Data</b> <b>Systems</b> (information <b>technology).</b>|$|R
40|$|A {{historical}} background on windmill use, {{the nature of}} wind, wind conversion <b>system</b> <b>technology</b> and requirements, the economics of wind power and comparisons with alternative <b>systems,</b> <b>data</b> needs, <b>technology</b> development needs, and an implementation plan for wind energy are presented. Considerable progress {{took place during the}} 1950 's. Most of the modern windmills feature a wind turbine electricity generator located directly {{at the top of their}} rotor towers...|$|R
2500|$|Although the {{decision}} to spin off the company's analytical instruments division pre-dated her arrival, {{one of her first}} major responsibilities as chief executive was overseeing the separation of the unit into the stand-alone Agilent Technologies. Fiorina proposed the acquisition of the technology services arm of PricewaterhouseCoopers for almost 14billion, but withdrew the bid after a lackluster reception from Wall Street. Following the collapse of the dot-com bubble, the PwC consulting arm was acquired by IBM for less than 4billion. [...] HP later acquired Electronic <b>Data</b> <b>Systems,</b> another <b>technology</b> services company, which some considered a validation of Fiorina's strategy.|$|R
