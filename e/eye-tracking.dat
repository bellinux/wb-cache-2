2886|3|Public
5|$|Measurement of {{predictive}} visual tracking {{is being}} studied as a screening technique to identify mild traumatic brain injury. A head-mounted display unit with <b>eye-tracking</b> capability shows a moving object in a predictive pattern {{for the person}} to follow with their eyes. People without brain injury {{will be able to}} track the moving object with smooth pursuit eye movements and correct trajectory while it is hypothesized that those with mild traumatic brain injury cannot.|$|E
5|$|A {{study by}} Sanchez and Wiley showed that seductive details caused poor {{learning}} outcomes because they take {{up some of}} the limited space in working memory. The experiment compared people's ability to control their attention to scientific text that contained either seductive images, relevant images, or no images. The study showed that people with low working memory capacity were especially vulnerable to the seductive details effect. Sanchez and Wiley also did an experiment where <b>eye-tracking</b> was monitored to evaluate how people were reading the same seductively illustrated scientific text. The results showed that people with low working memory looked at the seductive illustrations more often and for longer than those with high working memory capacity. It could be argued that differences in performance between high- and low- working memory capacity individuals is really due to general reading ability, an attribute that has been correlated with working memory capacity in other studies.|$|E
5|$|It was {{the first}} LS with {{continuous}} controlled Adaptive Variable Suspension (AVS). The addition of an automated parallel parking assist feature, {{the first of its}} kind in the U.S., allowed the LS 460 to steer itself into preselected parking spaces. Other drive-assist features included a brake-hold system, radar cruise control, electric variable gear ratio power steering, and electronically controlled braking. The new stability control system was improved to anticipate skids and alter steering assist and gear ratios. The suite of new safety features extended from an <b>eye-tracking</b> Driver Monitoring System to a lane departure warning system. The pre-collision system added the first production image processing chip in a car capable of identifying vehicles and pedestrians in real time, along with millimeter-wavelength radar, stereo cameras, and infrared night vision projectors. A rear pre-collision system with whiplash-preventing active seat headrests and dual-chamber front airbags was also introduced.|$|E
25|$|Active in {{the field}} of Artificial Neural Networks since 1989. Current {{research}} programmes within the group are focused on the improvement of man-machine-interfaces, robot-force-control, <b>eye-tracking</b> experiments, machine vision, virtual reality and distributed systems.|$|E
25|$|Kensinger argues {{there are}} two {{trade-off}}s: central/peripheral trade-off of details and a specific/general trade-off. Emotional memories may include increased emotional details often with the trade-off of excluding background information. Research has shown that this trade-off effect cannot be explained exclusively by overt attention (measured by <b>eye-tracking</b> directed to emotional items during encoding) (Steinmetz & Kensinger, 2013).|$|E
25|$|A {{hardware}} revision, New Nintendo 3DS, {{was unveiled}} in August 2014. It {{is produced in}} a standard-sized model and a larger XL model; both models feature upgraded processors and additional RAM, an <b>eye-tracking</b> sensor to improve {{the stability of the}} autostereoscopic 3D image, colored face buttons, and near-field communication support for native use of Amiibo products. The standard-sized model also features slightly larger screens, and support for faceplate accessories.|$|E
25|$|In {{recent years}} {{researchers}} have developed various eye-movement simulation models {{in order to}} support, explain, and guide empirical research (the studies that collect data from experiments on human reading behaviours). Computational models can help test existing hypothesis, and also generate further predictions for empirical research to investigate. Building a reading model based on empirical data allows researchers to inspect and manipulate various assumptions of cognitive processes within the model, {{and see how the}} interactions between these elements influence the simulated reading behaviours, and hence informs further empirical studies. On the other hand, empirical research in eye-movements using <b>eye-tracking</b> {{is one of the most}} delicate measurement of human behaviours, which serves as a productive test bed for computer models of cognition. Below is a brief summary of these reading models as classified by Nuthmann (2014).|$|E
25|$|There are {{problems}} that may hinder the development the modeling of reading behaviours. First, computer models in reading {{tend to make}} assumptions of direct links between lexical properties and saccade attributes (by putting a formula linking the two into the model). These links are descriptive generalizations of existing empirical data and normally do not survive new data. In search for new data to support their models, researcher might have to keep adding and adjusting lexical process assumptions {{and are likely to}} ignore possible parsimonious process that underlies these assumptions. Caution should be taken when adding assumptions of how lexical processes affect saccade programming because reading is not what humans are evolved to do. The modeling of eye-movements in reading should treat reading as special case of visual perception and take into account more basic oculomotor properties(e.g., split fovea, depth perception) before making assumptions about the link between lexical processes and eye movements. Another problem is {{that there has been a}} lack of comparison between models on the same data set. Researcher teams tend to focus on the development of their own model and might not be able to fully appreciate the merits of other models due to the technical difficulties in sharing programs. In the future we might see unifying model that both explains complex reading behaviors well and is parsimonious enough to be generalizable to other <b>eye-tracking</b> fields such as visual search, scene viewing.|$|E
500|$|Rapid {{progress}} in {{hardware and software}} development continued, including projects funded by the European Community. [...] The first commercially available dynamic screen speech generating devices were developed in the 1990s. Software programs were developed that allowed the computer-based production of communication boards. High-tech devices have continued to become smaller and lighter, while increasing accessibility and capability; communication devices can be accessed using <b>eye-tracking</b> systems, perform as a computer for word-processing and Internet use, and as an environmental control device for independent access to other equipment such as TV, radio and telephones.|$|E
500|$|As of 2010, {{the use of}} {{predictive}} visual tracking measurement {{to identify}} mild traumatic brain injury was being studied. [...] In visual tracking tests, a head-mounted display unit with <b>eye-tracking</b> capability shows an object moving in a regular pattern. People without brain injury are able to track the moving object with smooth pursuit eye movements and correct trajectory. [...] The test requires both attention and working memory which are difficult functions for people with mild traumatic brain injury. The question being studied, is whether results for people with brain injury will show visual-tracking gaze errors relative to the moving target.|$|E
500|$|It has {{additional}} software features, expanded hardware, and a redesigned physique {{from its}} predecessor, the Samsung Galaxy SII. The [...] "SIII" [...] employs an intelligent personal assistant (S Voice), <b>eye-tracking</b> ability, and increased storage. Although a wireless charging option was announced, {{it never came}} to fruition. However there are third party kits which add support for wireless charging. Depending on country, the [...] smartphone comes with different processors and RAM capacity, and 4G LTE support. The device was launched with Android 4.0.4 [...] "Ice Cream Sandwich", was updated to Android 4.3 [...] "Jelly Bean", and can be updated to Android 4.4 [...] "KitKat" [...] on variants with 2 GB of RAM. The phone's successor, the Samsung Galaxy S4, was announced on 14 March 2013 and was released the following month.|$|E
2500|$|Display {{motion blur}} on moving objects caused by slow {{response}} times (>8 ms) and <b>eye-tracking</b> on a sample-and-hold display, unless a strobing backlight is used. However, this strobing can cause eye strain, as is noted next: ...|$|E
2500|$|A 2010 {{follow-up}} study, {{under the}} same conditions but using an improved measurement method with use of <b>eye-tracking</b> equipment, indicates: [...] "While results indicate no difference in accuracy between the two styles, subjects recognize identifiers in the underscore style more quickly." ...|$|E
2500|$|Some {{studies have}} shown that people who are {{homophobic}} {{are more likely to have}} repressed homosexual desires. In 1996, a controlled study of 64 heterosexual men (half said they were homophobic by experience, with self-reported orientation) at the University of Georgia found that men who were found to be homophobic (as measured by the Index of Homophobia) were considerably more likely to experience more erectile responses when exposed to homoerotic images than non-homophobic men. Another study in 2012 arrived at similar results when researchers found that students who came from [...] "the most rigid anti-gay homes" [...] were most likely to reveal repressed homosexual attraction. The researchers said that this explained why some religious leaders who denounce homosexuality are later revealed to have secret homosexual relations. They noted that [...] "these people are at war with themselves and are turning this internal conflict outward." [...] A 2016 <b>eye-tracking</b> study showed that heterosexual men with high negative impulse reactions toward homosexuals gazed for longer periods at homosexual imagery than other heterosexual men.|$|E
50|$|In 2015, MSI {{teamed up}} with <b>eye-tracking</b> tech firm Tobii for the {{creation}} of <b>eye-tracking</b> gaming laptops.|$|E
5000|$|An <b>eye-tracking</b> {{study of}} online {{shopping}} {{to understand how}} customers use ELM in their e-commerce experience.|$|E
50|$|From {{a system}} {{analysis}} point of view, <b>eye-tracking</b> applications should {{be distinguished from}} diagnostic or interactive system. In diagnostic mode, the eye-tracker provides data about the observer’s visual search and attention processes. In interactive mode, the eye-tracker is used as an input device. From a general point of view, an interactive system responds to the observer’s actions and interacts with him. Gaze-contingency paradigm can be classified an interactive <b>eye-tracking</b> applications (Duchowski 2007).|$|E
50|$|Keith Rayner (June 20, 1943 - January 21, 2015) was a {{cognitive}} psychologist {{best known for}} pioneering modern <b>eye-tracking</b> methodology in reading and visual perception.|$|E
50|$|He {{developed}} {{corporate and}} technology strategy at Eyegaze, a contractor and marketer of <b>eye-tracking</b> systems that enable quadriplegics to type {{and communicate with}} only their eyes.|$|E
50|$|SYNCTHINK, Inc. is a neuro-technology {{company with}} {{foundational}} intellectual property in <b>eye-tracking</b> metrics and devices. The Company {{was founded in}} 2008 and is headquartered in Boston, Massachusetts.|$|E
5000|$|... #Caption: An <b>eye-tracking</b> head-mounted display. Each eye has an LED {{light source}} (gold-color metal) {{on the side}} of the display lens, and a camera under the display lens.|$|E
50|$|Fictive motion {{has since}} been {{investigated}} by cognitive scientists interested in whether and how it evokes dynamic imagery. Methods of investigation have included reading tasks, <b>eye-tracking</b> tasks and drawing tasks.|$|E
5000|$|Active in {{the field}} of Artificial Neural Networks since 1989. Current {{research}} programmes within the group are focused on the improvement of man-machine-interfaces, robot-force-control, <b>eye-tracking</b> experiments, machine vision, virtual reality and distributed systems.|$|E
5000|$|Bombari, D., Mora, B., Schaefer, S.C., Mast, F.W. & Lehr, H.-A. (2012). What was I thinking? <b>Eye-tracking</b> {{experiments}} {{underscore the}} bias that architecture exerts on nuclear grading in prostate cancer, PLoS ONE 7(5): e38023. doi:10.1371/journal.pone.0038023 ...|$|E
5000|$|Display {{motion blur}} on moving objects caused by slow {{response}} times (>8 ms) and <b>eye-tracking</b> on a sample-and-hold display, unless a strobing backlight is used. However, this strobing can cause eye strain, as is noted next: ...|$|E
50|$|Born out of Necessity, a {{collaborative}} artwork by Watson and other artists, {{involves the use}} of <b>eye-tracking</b> technology to allow a graffiti artist afflicted with amyotrophic lateral sclerosis to create virtual tags; it is in the collection of MoMA.|$|E
5000|$|<b>Eye-tracking</b> {{offers several}} {{benefits}} over the polygraph: lower cost, 1/5th {{of the time}} to conduct, subjects {{do not need to}} be [...] "hooked up" [...] to anything, and it does not require qualified polygraph examiners to give the test.|$|E
5000|$|A 2010 {{follow-up}} study, {{under the}} same conditions but using an improved measurement method with use of <b>eye-tracking</b> equipment, indicates: [...] "While results indicate no difference in accuracy between the two styles, subjects recognize identifiers in the underscore style more quickly." ...|$|E
50|$|Because of {{the lack}} of {{technology}} at the time, naked-eye observations were used to observe eye movement, until later in the late 19th and mid-20th century <b>eye-tracking</b> experiments were conducted in an attempt to discover a pattern regarding eye fixations while reading.|$|E
5000|$|The 1980s {{also saw}} the birth of using eye {{tracking}} to answer questions related to human-computer interaction. Specifically, researchers investigated how users search for commands in computer menus. [...] Additionally, computers allowed researchers to use <b>eye-tracking</b> results in real time, primarily to help disabled users.|$|E
50|$|The OpenBCI {{has been}} used to control a HexBug robot using SSVEPs (Steady State Visually Evoked Potentials). Locked in {{graffiti}} artist Tempt One has used the OpenBCI and the low-cost Eyewriter <b>eye-tracking</b> system to continue to draw after being diagnosed with the degenerative nerve disorder ALS.|$|E
50|$|Consumer {{neuroscience}} employs sophisticated bio-metric sensors, such as electroencephalography (EEG), functional {{magnetic resonance}} imaging (fMRI) and <b>eye-tracking,</b> to study the ways that consumers respond to specific stimuli such as product displays, brands, packaging information or other marketing signals. Such tests reveal stimuli that trigger the brain’s pleasure centre.|$|E
50|$|In 1991, J.T. Lin, Ph.D. (a Chinese Physicist) {{was granted}} a US patent for a new {{technology}} using a flying-spot for customized LASIK currently used worldwide. The first US patent using an <b>eye-tracking</b> device to prevent decentration in LASIK procedures was granted to another Chinese Physicist, Dr. S. Lai in 1993.|$|E
50|$|The Golden Triangle in {{internet}} marketing depicts the triangular viewing pattern on a webpage which {{is created by}} tracking eye activity of users. It is an <b>eye-tracking</b> heat-mapping that shows that people look and click on a specific area on a page of search results, which gives rise to an “F” form.|$|E
50|$|The Proceedings of the National Academy of Sciences (2009) {{describes}} the {{research conducted by}} Agnes Melinda Kovacs and Jacques Mehler on the cognitive gains in seven-month-old bilingual infants. In three <b>eye-tracking</b> studies, Kovacs and Mehler found that infants, reared with two languages from birth, display improved cognitive control abilities compared with matched monolinguals.|$|E
50|$|SEF {{research}} is conducted mainly in monkey models. Typically trained rhesus macaque monkeys are used and surgically implanted with recording chambers. In this fashion, spike and local field potential (LFP) {{data can be}} acquired from SEF neurons, using microelectrodes in the recording chamber. Eye movements can also be monitored using <b>eye-tracking</b> camera equipment.|$|E
