203|365|Public
25|$|In 2010, the UNDP {{reacted to}} the {{criticism}} and updated the thresholds to classify nations as low, medium, and high human development countries. In a comment to The Economist in early January 2011, the Human Development Report Office responded to a 6 January 2011 article in the magazine which discusses the Wolff et al. paper. The Human Development Report Office states that they undertook a systematic revision of {{the methods used for}} the calculation of the HDI and that the new methodology directly addresses the critique by Wolff et al. in that it generates a system for continuously updating the human development categories whenever formula or <b>data</b> <b>revisions</b> take place.|$|E
5000|$|Frank T. Denton and Ernest H. Oksanen, 1972. “A Multi-Country Analysis of the Effects of <b>Data</b> <b>Revisions</b> on an Econometric Model,” Journal of the American Statistical Association, vol. 67(338), pp. 286-291.|$|E
50|$|A {{debate over}} how to {{reconcile}} climate model predictions that upper air (tropospheric) warming should be greater than observed surface warming, some of which appeared to show otherwise, was resolved in favour of the models, following <b>data</b> <b>revisions.</b>|$|E
40|$|Event history {{calendars}} (EHC) {{have proven}} to be a useful tool to collect retrospective autobiographic life course data. One problem is that they are only standardized to some extent. This limits their applicability in large-scale surveys. However, in such surveys a modularized retrospective CATI design can be combined with EHC. This <b>data</b> <b>revision</b> module is directly integrated into the interview and used as a <b>data</b> <b>revision</b> module. Hereby insights from cognitive psychology are applied. The <b>data</b> <b>revision</b> module stimulates the respondent's memory retrieval by detecting both temporal inconsistencies, such as gaps, and overlapping or parallel events. This approach was implemented in the IAB-ALWA study (Work and Learning in a Changing World), a large-scale representative telephone survey with 10, 000 respondents. By comparing the uncorrected data with the final <b>data</b> after <b>revision,</b> we investigate to what extent the application of this <b>data</b> <b>revision</b> module improves <b>data</b> quality or more precisely, time consistency and dating accuracy of individual reports. " (Author's abstract, IAB-Doku) ((en)) Biografieforschung - Methode, empirische Sozialforschung, Lebenslauf...|$|R
40|$|A {{positive}} view of data-mining {{has been}} recently {{presented in a}} Journal of Economic Methodology (JEM) symposium. This is {{in stark contrast to}} the stance normally taken. In this note consideration of the Bayesian philosophy of science literature and the impact of <b>data</b> <b>revision</b> extends the analysis of data-mining. Introduction of these issues is seen to provide support for the arguments presented in the JEM symposium. Data-MINING, <b>Data</b> <b>Revision,</b> Bayeasian Philosophy Of Science, Prediction And Accommodation,...|$|R
40|$|The current {{implementation}} of the Fan Chart displays equal tail probability bands and do {{not take into account}} that the variable of interest may be subject to <b>data</b> <b>revision.</b> In this note I propose the use of Highest Probability Density, HPD, bands and include flexibility to display the risks related to <b>data</b> <b>revision.</b> Click here to obtain a Visual Basic for Excel routine. Please save the the as FanChartGdpGrowth. xls and enable Macros to run the program. ...|$|R
50|$|In {{order to}} {{understand}} the accuracy of economic data and the possible impact of data errors on macroeconomic decision-making, the Federal Reserve Bank of Philadelphia has published a dataset that records both initial real-time data estimates, and subsequent <b>data</b> <b>revisions,</b> for a large number of macroeconomic series. A similar dataset for Europe has been developed by the Euro-Area Business Cycle Network.|$|E
5000|$|Keane's {{papers with}} David Runkle (1990, 1998) are {{considered}} fundamental {{contributions in the}} literature on how people form expectations. These papers showed that the widespread empirical failure of [...] "rational expectations" [...] was in fact due to a set of econometric and data problems (such as the failure to account for aggregate economic shocks and the effects of <b>data</b> <b>revisions).</b>|$|E
50|$|In 2010, the UNDP {{reacted to}} the {{criticism}} and updated the thresholds to classify nations as low, medium, and high human development countries. In a comment to The Economist in early January 2011, the Human Development Report Office responded to a 6 January 2011 article in the magazine which discusses the Wolff et al. paper. The Human Development Report Office states that they undertook a systematic revision of {{the methods used for}} the calculation of the HDI and that the new methodology directly addresses the critique by Wolff et al. in that it generates a system for continuously updating the human development categories whenever formula or <b>data</b> <b>revisions</b> take place.|$|E
2500|$|... svn:mergeinfo : Used {{to track}} merge <b>data</b> (<b>revision</b> numbers) in Subversion 1.5 (or later). This {{property}} is automatically {{maintained by the}} merge command, {{and it is not}} recommended to change its value manually.|$|R
30|$|Introduction Ventilator-associated {{pneumonia}} {{is a major}} iatrogenic problem {{since it}} is a cause of hospital morbidity, mortality and increase of health care costs. It has been studied many times, but <b>data’s</b> <b>revision</b> is always necessary. Our study aimed to describe epidemiology of ventilator-associated pneumonia and identify local causative pathogens.|$|R
50|$|Schema {{structure}} includes <b>data</b> <b>revision</b> {{and change}} tracking support, and life-cycle status detail, so applications {{can be developed}} to monitor data alterations over time and maintain records throughout the life-cycle of an equipment item. Units of measurement are also supported by the schemas, so AEX cfiXML can be used within the US or internationally.|$|R
5000|$|The {{second wave}} of {{research}} on the returns differentials literature, written during pre-crisis times and published during the crisis, emerged due to criticism of how the data was handled. This criticism alleged inconsistencies in <b>data</b> <b>revisions</b> between stocks and flows, which were then (mis-)attributed to [...] "Other changes". Consequently, it was argued that this estimation approach would not calculate capital gains, but rather the sum of capital gains and other changes. Another problem is the extent of gains in the FDI category, wherein data is estimated. The second wave addresses these issues and finds substantially smaller differentials, ranging from -0.7% to 0.6%, using the second research approach.|$|E
5000|$|The noted ongoing EDPs will be abrogated, {{as soon as}} the {{concerned}} state for the period encompassing the last completed fiscal year (based on final notified data) and for the current and next year (based on forecast data), succeeds in delivering a general government account in full compliance with the SGP's deficit criteria (budget deficit no more than 3.0% of GDP) and the debt criterion (debt&#8209;to&#8209;GDP ratio below 60% - or sufficiently declining towards this level). The deadlines for EDP abrogations will only be extended if extraordinary circumstances occur - like a recession or severe economic downturn. As part of the increased surveillance efforts introduced by the Sixpack, all EDP's are now evaluated three times per year, based upon data from the Commission's economic outlook reports published in February, May and November. Member states involved in bailout programs are evaluated even more frequently and more in depth, through the so-called [...] "Programme Reviews". EDP abrogations are normally announced in June, as they always await final notified data for the last completed fiscal year (being published in early May), but can occasionally also be announced later in the year (due to later arriving positive <b>data</b> <b>revisions</b> for recorded data or subsequent improvements materializing for its forecast data). The SGP and Fiscal Compact feature identical debt criteria, so they only differ compliance wise for the deficit criteria, where the Fiscal Compact sets the additional structural deficit criteria to be met as a main criteria (elevating its importance from the additional but less binding MTO adjustment path criteria).|$|E
40|$|In {{the past}} ten years, {{researchers}} have explored the impact of <b>data</b> <b>revisions</b> in many different contexts. Researchers have examined the properties of <b>data</b> <b>revisions,</b> how structural modeling is affected by <b>data</b> <b>revisions,</b> how <b>data</b> <b>revisions</b> affect forecasting, the impact of <b>data</b> <b>revisions</b> on monetary policy analysis, {{and the use of}} real-time data in current analysis. This paper summarizes many of the questions for which real-time data analysis has provided answers. In addition, researchers and institutions have developed better real-time data sets around the world. Still, additional research is needed in key areas and research to date has uncovered even more fruitful areas worth exploring. (JEL C 52, C 53, C 80, E 01) ...|$|E
30|$|GAE: study design, data interpretation, {{manuscript}} preparation. TS: study design, animal experiments, MRI studies, <b>data</b> interpretation, manuscript <b>revision.</b> RJvdG; <b>data</b> analysis, manuscript <b>revision.</b> PS: study design, <b>data</b> interpretation, manuscript <b>revision.</b> PPK: study design, animal experiments, MRI studies, manuscript revision. ZL: animal experiments, MRI studies, manuscript revision. RK: study design, animal experiments, MRI studies. DW: histopathology, <b>data</b> interpretation, manuscript <b>revision.</b> BCB: study design, animal model, manuscript revision. AVS: study design, animal model, MRI studies, manuscript drafting, revision. All authors {{read and}} approved the final manuscript.|$|R
40|$|I {{appreciate}} the useful comments of three anonymous referees and the editor, Roger Gordon, {{as well as}} Richard Anderson, David Papell, Glenn Rudebusch, and participants at the Workshop on Using Euro Area Data and the Workshop on Macroeconomic Forecasting, Analysis and Policy with <b>Data</b> <b>Revision.</b> Thanks to Tom Stark for many discussions about real-time data issues ove...|$|R
40|$|This paper {{places the}} <b>data</b> <b>revision</b> model of Jacobs and van Norden (2011) within {{a class of}} trend-cycle decompositions {{relating}} directly to the Beveridge-Nelson decomposition. In both these approaches identifying restrictions on the covariance matrix under simple and realistic conditions may produce a smoothed estimate of the underlying series which is more volatile than the observed series...|$|R
40|$|In this paper, using recent {{empirical}} results {{regarding the}} statistical properties of macroeconomic <b>data</b> <b>revisions,</b> we study the e¤ects of <b>data</b> <b>revisions</b> {{in a general}} equilibrium framework. We …nd {{that the presence of}} <b>data</b> <b>revisions,</b> or data uncertainty, creates a precautionary motive and causes signi…cant changes in the decisions of agents. We also …nd that the model with revisions captures some aspects of the business cycle dynamics of the US data better than the benchmark model with no revisions. Using our model we measure the cost of having <b>data</b> <b>revisions</b> to be about $ 33 billion, $ 5 billion of which can be recovered by eliminating the predictability of revisions. Comparing these numbers with the budgets of the major statistical agencies in the US, we conclude that any money spent on the improvement of data collection would be well worth it...|$|E
40|$|This paper tracks <b>data</b> <b>revisions</b> in the Personal Consumption Expenditure {{using the}} exclusions-from-core {{inflation}} persistence model. Keeping {{the number of}} observations the same, the regression parameters of earlier vintages of real-time data, beginning with vintage 1996 :Q 1, are tested for coincidence against the regression parameters of the last vintage of real-time data used in this paper, which is vintage 2008 :Q 2 in a parametric and two nonparametric frameworks. The effects of <b>data</b> <b>revisions</b> are not detectable {{in the vast majority}} of cases in the parametric model, but the flexibility of the two nonparametric models is able to utilize the <b>data</b> <b>revisions.</b> ...|$|E
40|$|Recent {{research}} examining U. S. macroeconomic data suggests that revisions {{may be much}} more important than traditionally assumed. This paper extends the analysis to Chinese data, where there has been substantial debate about data quality for some time. The key finding in this paper is that indeed the Chinese macroeconomic <b>data</b> <b>revisions</b> are not well-behaved, but that they are not much different from U. S. macroeconomic <b>data</b> <b>revisions...</b>|$|E
40|$|Global {{temperature}} {{increase on}} Earth, due to climate change, indicates {{the need for}} a <b>data</b> <b>revision</b> pertaining to outdoor design temperature and number of degree – days. In this paper, based on the relevant data pertaining to tempereture mesurements in Sarajevo for a period of ten years (since 2001 to 2010), new outdoor design temperature- 13 °C is defined, instead of applicable temperature- 18 °C and number of degree days 2381 °C-ann, instead of applicable 3077 °C-ann. The results of calculation show that requirement for thermal energy is 22 % less for outdoor design temperature of- 13 °C. Therefore, there is the need for <b>data</b> <b>revision</b> pertaining to outdoor design temperature and number of degree – days, wich could lead to a correction in the heating systems. As a consequence, atmospheric CO 2 emmision will be less in the building sector, which can {{play a key role in}} combating climate change...|$|R
30|$|All authors {{critically}} {{revised the}} manuscript for important intellectual content and approved the final manuscript. Please find below {{a detailed description}} of the role of each author. JRZ contributed to the conception and design, acquisition, and assembly of data, analysis and interpretation of <b>data,</b> drafting and <b>revision</b> of the manuscript and final approval of the version to be published. DHS contributed to the conception and design, interpretation of data and results, drafting and revision of the manuscript, and final approval of the version to be published. TBA contributed to the conception and design, acquisition and assembly of <b>data,</b> drafting and <b>revision</b> of the manuscript, and final approval of the version to be published. KS contributed to the conception and design, acquisition and assembly of <b>data,</b> <b>revision</b> of the manuscript, and final approval of the version to be published. AB contributed to the conception and design, interpretation of <b>data,</b> drafting and <b>revision</b> of the manuscript, and final approval of the version to be published. PHF contributed to the conception and design, analysis and interpretation of <b>data,</b> drafting and <b>revision</b> of the manuscript, and final approval of the version to be published. All authors read and approved the final manuscript.|$|R
40|$|Real-time {{macroeconomic}} data refl ect {{the information}} available to market participants, whereas fi nal data-containing revisions and released with a delay-overstate the information set available to them. We document that the in-sample and out-of-sample Treasury return predictability is signifi cantly diminished when real-time as opposed to revised macroeconomic data are used. In fact, much of the predictive information in macroeconomic time series {{is due to the}} <b>data</b> <b>revision</b> and publication lag components...|$|R
40|$|Traditionally, {{researchers}} have used linear regression models when work-ing with real-time <b>data</b> <b>revisions.</b> In this paper, we forecast real-time <b>data</b> <b>revisions</b> {{with a wide}} set of models including linear, structural break and regime-switching models with and without heteroskedasticity. We address {{the issues raised by}} the presence of model uncertainty through the use of Bayesian model averaging (BMA). Using UK data, we calculate predictive densities for real-time <b>data</b> <b>revisions</b> which average over the model space and compare them with the single best model and the linear model. We also present evidence about whether the revision process is unbiased and calcu-late various functions of the predictive density which might be of interest to a statistical agency. In contrast to the BMA approach, the traditional linear model yields very misleading predictives...|$|E
40|$|This paper {{analyzes}} forward-looking {{rules for}} Swiss monetary policy {{in a small}} structural VAR model consisting of four variables taking into account <b>data</b> <b>revisions</b> for GDP. First, the paper develops an analytical method to analyze the effect of data revision errors in GDP on the ex ante or conditional inflation-output-growth volatility trade-off and applies it to Swiss data. Second, the effects of different targets in a forward-looking monetary policy on ex post or unconditional volatility of inflation and output growth is explored by a simulation exercise. In general, the results obtained suggest that focusing monetary policy on GDP growth instead on inflation may lead to an inefficient policy with both increased medium term inflation and GDP growth volatility {{in the presence of}} GDP <b>data</b> <b>revisions.</b> Structural VAR, forward-looking monetary policy, efficiency frontier, GDP <b>data</b> <b>revisions...</b>|$|E
40|$|Model-based {{estimates}} of future uncertainty are generally {{based on the}} in-sample fit of the model, as when Box-Jenkins prediction intervals are calculated. However, this approach will generate biased uncertainty estimates in real time when there are <b>data</b> <b>revisions.</b> A simple remedy is suggested, and used to generate more accurate prediction intervals for 25 macroeconomic variables, {{in line with the}} theory. A simulation study based on an empirically-estimated model of <b>data</b> <b>revisions</b> for US output growth is used to investigate small-sample properties...|$|E
40|$|In this paper, we {{take into}} {{consideration}} some {{issues related to the}} use of a nonlinear structural econometric model {{in the presence of a}} <b>data</b> <b>revision</b> process. We analyse the consequences on the parameter estimation (consistency is still attainable) and on forecast. In the latter case, we show that the asymptotic bias and mean squared prediction error of the deterministic and Monte Carlo predictors have new elements with respect to the traditional analysis in the absence of data uncertainty. ...|$|R
40|$|A {{well-documented}} {{property of}} the Beveridge-Nelson trend-cycle decomposition is the perfect negative correlation between trend and cycle innovations. This paper gives a novel explanation for this negative correlation originating from the Jacobs-van Norden (2011) <b>data</b> <b>revision</b> model. Trend shocks may enter the equation for the cycle or cyclical shocks may enter the trend equation. We discuss economic interpretations and implications, including ltering and smoothing properties. We illustrate the idea with simulations based on the Morley, Nelson and Zivot (2003) outcome...|$|R
40|$|This paper {{tests the}} {{rationality}} of individual price forecasts in {{a panel of}} professional forecasters. Here, unlike in most previous studies, rationality is not rejected. The results here differ because (1) using individual forecasts avoids aggregation bias, (2) comparison of forecasts to initial data avoids bias due to <b>data</b> <b>revision,</b> (3) the professional forecasters have economic incentives to state their expectations accurately, and (4) a new covariance matrix estimator consistent when forecast errors are correlated across individuals is used. Copyright 1990 by American Economic Association. ...|$|R
40|$|Realistic {{modeling}} of <b>data</b> <b>revisions</b> {{can play an}} impor-tant role in policy formulation. A common way to model <b>data</b> <b>revisions</b> {{is to set up}} a state-space model with sep-arate blocks for measurement errors and the dynamics of ”true ” values. However, empirical work suggests that measurement errors typically have much more complex dynamics than such models allow. This paper describes a state-space model with richer dynamics in these mea-surement errors, including the noise, news and spillover effects documented in this literature. The result is a uni-fied and flexible framework that allows for more realism in the model of data revision and optimal real-time es-timation of trends and cycles in real time. We illustrate the application of this framework with an analysis of real-time data on U. S. real output. KEY WORDS: real-time analysis, <b>data</b> <b>revisions,</b> state-space model...|$|E
40|$|Forecasts {{are only}} as good as the data behind them. But {{macroeconomic}} data are revised, often significantly, as time passes and new source data become available and conceptual changes are made. How is forecasting influenced by the fact that data are revised? To answer this question, we begin with the example of the index of leading economic indicators to illustrate the real-time data issues. Then we look at the data that have been developed for U. S. <b>data</b> <b>revisions,</b> called the "Real-Time Data Set for Macroeconomists" and show their basic features, illustrating the magnitude of the revisions and thus motivating their potential influence on forecasts and on forecasting models. The data set consists of a set of data vintages, where a data vintage refers to a date at which someone observes a time series of data; so the data vintage September 1974 refers to all the macroeconomic time series available to someone in September 1974. Next, we examine experiments using that data set by Stark and Croushore (2002), Journal of Macroeconomics 24, 507 - 531, to illustrate how the <b>data</b> <b>revisions</b> could have affected reasonable univariate forecasts. In doing so, we tackle the issues of what variables are used as "actuals" in evaluating forecasts and we examine the techniques of repeated observation forecasting, illustrate the differences in U. S. data of forecasting with real-time data as opposed to latest-available data, and examine the sensitivity to <b>data</b> <b>revisions</b> of model selection governed by various information criteria. Third, we look at the economic literature on the extent to which <b>data</b> <b>revisions</b> affect forecasts, including discussions of how forecasts differ when using first-available compared with latest-available data, whether these effects are bigger or smaller depending on whether a variable is being forecast in levels or growth rates, how much influence <b>data</b> <b>revisions</b> have on model selection and specification, and evidence on the predictive content of variables when subject to revision. Given that data are subject to revision and that <b>data</b> <b>revisions</b> influence forecasts, what should forecasters do? Optimally, forecasters should account for <b>data</b> <b>revisions</b> in developing their forecasting models. We examine various techniques for doing so, including state-space methods. The focus throughout this chapter is on papers mainly concerned with model development - trying to build a better forecasting model, especially by comparing forecasts from a new model to other models or to forecasts made in real time by private-sector or government forecasters. ...|$|E
40|$|This paper {{analyzes}} the relative performance of multi-step forecasting methods {{in the presence}} of breaks and <b>data</b> <b>revisions.</b> Our Monte Carlo simulations indicate that the type and the timing of the break affect the relative accuracy of the methods. The iterated method typically performs the best in unstable environments, especially if the parameters are subject to small breaks. This result holds regardless of whether <b>data</b> <b>revisions</b> add news or reduce noise. Empirical analysis of real-time U. S. output and inflation series shows that the alternative multi-step methods only episodically improve upon the iterated method. ...|$|E
30|$|TW was {{involved}} in the conception, data collection, analysis, manuscript writing and revision. MB and LR performed {{the main part of the}} data collection and were involved in the <b>data</b> analysis and <b>revision.</b> CT prepared the theoretical background and {{was involved}} in editing the manuscript. KF performed the <b>data</b> analysis and <b>revision.</b> HA {{was involved in}} all aspects of this study, including conception, data collection, <b>data</b> analysis, and <b>revision.</b> RL {{was involved in the}} conception of the study, manuscript writing, and critical revision. All authors read and approved the final manuscript.|$|R
40|$|Previous {{versions}} of this paper have been presented at the workshop on Macroeconomic Forecasting, Analysis and Policy with <b>Data</b> <b>Revision</b> (Montreal, 2006), the 22 th Annual Congress of the European Economic Association (Budapest, 2007) and the CSEF seminar series (Napoli, 2008). This paper assesses the role of surveys for the early estimates of GDP in the euro area in a model-based automated procedures which exploits the timeliness of their release. The analysis is conducted using both an historical evaluation and a real time case study on the current conjuncture...|$|R
40|$|This Selected Issues paper {{examines}} {{national accounts}} revisions {{and the economic}} cycle for the United Kingdom. The paper concludes that upward <b>revisions</b> to GDP <b>data</b> are positively correlated with economic activity, in particular, with growth in its domestic component. The paper suggests that although revisions may have become smaller in recent years, the procyclical bias in the <b>data</b> <b>revision</b> has not been eliminated. The regression model employed also suggests that GDP growth in 1996 â€”currently estimated at 2. 4 percentâ€”could {{be as much as}} a 0. 6 percentage point higher than that estimate. ...|$|R
