10000|10000|Public
5|$|Since its launch, the Allen Institute for Brain Science {{has taken}} a Big Science and Open Science {{approach}} to tackle projects. The institute makes research tools available to the scientific community using an open <b>data</b> <b>model.</b>|$|E
25|$|A <b>data</b> <b>model,</b> {{based on}} Transmodel.|$|E
25|$|There exist two {{underlying}} {{models in}} each OT system: the <b>data</b> <b>model</b> {{that defines the}} way data objects in a document are addressed by operations, and the operation model that defines the set of operations that can be directly transformed by OT functions. Different OT systems may have different data and operation models. For example, the <b>data</b> <b>model</b> of the first OT system is a single linear address space; and its operation model consists of two primitive operations: character-wise insert and delete. The basic operation model has been extended to include a third primitive operation update to support collaborative Word document processing and 3D model editing. The basic OT <b>data</b> <b>model</b> has been extended into a hierarchy of multiple linear addressing domains, which is capable of modeling {{a broad range of}} documents. A data adaptation process is often required to map application-specific data models to an OT-compliant <b>data</b> <b>model.</b>|$|E
50|$|<b>Data</b> <b>models</b> {{formally}} define <b>data</b> {{objects and}} relationships among data objects for a domain of interest. Some typical applications of <b>data</b> <b>models</b> include supporting {{the development of}} databases and enabling the exchange of data for a particular area of interest. <b>Data</b> <b>models</b> are specified in a <b>data</b> <b>modeling</b> language. EXPRESS is a <b>data</b> <b>modeling</b> language defined in ISO 10303-11, the EXPRESS Language Reference Manual.|$|R
50|$|This {{article is}} a {{comparison}} of <b>data</b> <b>modeling</b> tools which are notable, including standalone, conventional <b>data</b> <b>modeling</b> tools and <b>modeling</b> tools supporting <b>data</b> <b>modeling</b> {{as part of a}} larger modeling environment.|$|R
40|$|There {{are many}} <b>data</b> <b>modelling</b> {{languages}} used in today’s information systems engineering environment. Some of the <b>data</b> <b>modelling</b> languages used {{have a degree}} of hype surrounding their quality and applicability. We would like to understand exactly what makes some <b>data</b> <b>modelling</b> languages successful and in some way suggest how useful <b>data</b> <b>modelling</b> languages {{will be in the}} context of an organisation and why. We are also interested in a theory capable of unifying the disparate range of languages. To do these things we select a theory based on ontology using which <b>data</b> <b>modelling</b> languages can be investigated. In this context theory should allow us to understand, compare, evaluate, and strengthen <b>data</b> <b>modelling</b> languages. The theory may also be used to suggest how useful various <b>data</b> <b>modelling</b> languages may be in an organisational setting. In this paper we present Chisholm’s ontology which we use to investigate <b>data</b> <b>modelling</b> languages. We show how Chisholm’s ontology can be used as a unifying theory of <b>data</b> <b>models,</b> develop methods for comparing <b>data</b> <b>modelling</b> languages based on this theory and summarise our findings. In conclusion, we evaluate the methods and the theory and examine avenues for future research. In this paper we present a deeper understanding of method together with analysis of new <b>data</b> <b>modelling</b> languages...|$|R
25|$|ISO 28560-2 : {{specifies}} encoding {{standards and}} <b>data</b> <b>model</b> {{to be used}} within libraries.|$|E
25|$|The W3C {{published}} a specification of RDF's <b>data</b> <b>model</b> and an XML serialization as a recommendation in February 1999.|$|E
25|$|Figure 2.1.3 is {{the process}} <b>data</b> <b>model</b> of the control sub-process. It shows the {{integration}} of the two models. The dotted arrows indicate the concepts that are created or adjusted in the corresponding activities.|$|E
5000|$|<b>Data</b> <b>modeling</b> {{resource}} site offers <b>data</b> <b>models</b> {{built in}} System Architect ...|$|R
50|$|Patterns {{are common}} <b>data</b> <b>modeling</b> {{structures}} {{that occur in}} many <b>data</b> <b>models.</b>|$|R
40|$|Abstract—Apache Cassandra is {{a leading}} {{distributed}} database of choice {{when it comes to}} big data management with zero downtime, linear scalability, and seamless multiple data center deployment. With increasingly wider adoption of Cassandra for online transaction processing by hundreds of Web-scale companies, there is a growing need for a rigorous and practical <b>data</b> <b>modeling</b> approach that ensures sound and efficient schema design. This work i) proposes the first query-driven big data mod-eling methodology for Apache Cassandra, ii) defines important <b>data</b> <b>modeling</b> principles, mapping rules, and mapping patterns to guide logical <b>data</b> <b>modeling,</b> iii) presents visual diagrams for Cassandra logical and physical <b>data</b> <b>models,</b> and iv) demonstrates a <b>data</b> <b>modeling</b> tool that automates the entire <b>data</b> <b>modeling</b> process. Keywords—Apache Cassandra, <b>data</b> <b>modeling,</b> automation, KDM, database design, big data, Chebotko Diagrams, CQL I...|$|R
25|$|With {{a variety}} of data loading tools available, {{and the ability to}} {{fine-tune}} the extract, transform, load (ETL) code to the particular <b>data</b> <b>model,</b> load times are generally much shorter than with the automated MOLAP loads.|$|E
25|$|XML Information Set or XML Infoset is an {{abstract}} <b>data</b> <b>model</b> for XML documents {{in terms of}} information items. The infoset is commonly used in the specifications of XML languages, for convenience in describing constraints on the XML constructs those languages allow.|$|E
25|$|The Resource Description Framework (RDF) is {{a family}} of World Wide Web Consortium (W3C) {{specifications}} originally designed as a metadata <b>data</b> <b>model.</b> It {{has come to be}} used as a general method for conceptual description or modeling of information that is implemented in web resources, using a variety of syntax notations and data serialization formats. It is also used in knowledge management applications.|$|E
40|$|Abstract. <b>Data</b> <b>modeling</b> {{patterns}} is {{an emerging}} {{field of research}} in the <b>data</b> <b>modeling</b> area. Its aims are to create a body of knowledge to help understand <b>data</b> <b>modeling</b> problems better and to create better <b>data</b> <b>models.</b> Current <b>data</b> <b>modeling</b> patterns are generally discussed at the instance level (only applicable in a specific domain, e. g. a business situation) and with an Entity-Relationship Modeling (ERM) way of thinking. This paper discusses <b>data</b> <b>modeling</b> patterns using the expressive power of Fully Communication Oriented Information Modeling (FCO-IM), a Dutch fact oriented modeling (FOM) method. We also consider more abstract higher level data patterns – meta level patterns – and de-scribe a few basic meta level <b>data</b> <b>modeling</b> patterns in brief as well as a meta level pattern in content versioning. ...|$|R
40|$|This paper {{discusses}} various <b>data</b> <b>models.</b> The prominent <b>data</b> <b>models</b> like Entity Relationship (ER) and Unified Modelling Language (UML) have industry standards. Various {{other types}} of data cannot adopt ER and UML models. Hence {{there is a need}} for another type of <b>data</b> <b>modelling.</b> The different systems and the relevant <b>data</b> <b>models</b> are discussed. There is a need for data interoperability for sharing data with various systems or devices. Possible solutions in this direction are discussed. Finally the relevance of these <b>data</b> <b>models</b> to IT education is discussed...|$|R
40|$|This paper gives a {{selective}} review {{on the recent}} developments of nonparametric and semiparametric panel <b>data</b> <b>models.</b> We focus on the conventional panel <b>data</b> <b>models</b> with one-way error component structure, partially linear panel <b>data</b> <b>models,</b> varying coe ¢ cient panel <b>data</b> <b>models,</b> nonparametric panel <b>data</b> <b>models</b> with multi-factor error structure, and nonseparable nonparametric panel <b>data</b> <b>models.</b> For each area, we discuss the basic models and ideas of estimation, and comment on the asymptotic properties of di¤erent estimators and speci…cation tests. Much theoretical and empirical research is needed in this emerging area. KEY WORDS: Cross section dependence; …xed e¤ects; hypothesis testing; nonadditive model; nonparametric GMM; nonseparable model; partially linear panel data model; random e¤ects; varying coe ¢ cient model...|$|R
25|$|A DOI name {{differs from}} {{commonly}} used Internet pointers to material, {{such as the}} Uniform Resource Locator (URL), in that it identifies an object itself as a first-class entity, rather than the specific place where the object is located at a certain time. It implements the Uniform Resource Identifier (Uniform Resource Name) concept and adds to it a <b>data</b> <b>model</b> and social infrastructure.|$|E
25|$|The RDF <b>data</b> <b>model</b> {{is similar}} to {{classical}} conceptual modeling approaches (such as entity–relationship or class diagrams). It {{is based on the}} idea of making statements about resources (in particular web resources) in expressions of the form subject–predicate–object, known as triples. The subject denotes the resource, and the predicate denotes traits or aspects of the resource, and expresses a relationship between the subject and the object.|$|E
25|$|A {{collection}} of RDF statements intrinsically represents a labeled, directed multi-graph. This in theory makes an RDF <b>data</b> <b>model</b> {{better suited to}} certain kinds of knowledge representation than are other relational or ontological models. However, in practice, RDF data is often stored in relational database or native representations (also called Triplestores—or Quad stores, if context such as the named graph is also stored for each RDF triple).|$|E
40|$|Semantic <b>data</b> <b>models</b> {{have emerged}} from a {{requirement}} for more expressive conceptual <b>data</b> <b>models.</b> Current generation <b>data</b> <b>models</b> lack direct support for relationships, data abstraction, inheritance, constraints, unstructured objects, and the dynamic properties of an application. Although the need for <b>data</b> <b>models</b> with richer semantics is widely recognized, no single approach has won general acceptance. This paper describes the generic properties of semantic <b>data</b> <b>models</b> and presents a representative selection of models that have been proposed since the mid- 1970 s. In addition to explaining {{the features of the}} individual models, guidelines are offered for the comparison of models. The paper concludes with a discussion of future directions in the area of conceptual <b>data</b> <b>modeling...</b>|$|R
30|$|By {{adopting}} this model-driven development process, we have automated {{the process}} from <b>data</b> <b>modeling</b> to <b>data</b> distribution. We have defined the national <b>data</b> <b>models</b> which comply to INSPIRE <b>data</b> <b>models,</b> thus we maximize the re-use of national spatial {{data for the}} INSPIRE services.|$|R
40|$|Based on {{the results}} of a 3 -day {{workshop}} at the Brown University (2012) this white paper tries to sum up important topics and problems which came up in the presentations and discussions and to outline some general aspects of <b>data</b> <b>modeling</b> in digital humanities. Starting with an attempt to define <b>data</b> <b>modeling</b> it introduces distinctions like curation-driven vs. research-driven for a more general description of <b>data</b> <b>modeling.</b> The second part discusses specific problems and challenges of <b>data</b> <b>modeling</b> in the Humanities, while the third part outlines practical aspects, like the creation of <b>data</b> <b>models</b> or their evaluation...|$|R
25|$|This {{mechanism}} for describing resources {{is a major}} component in the W3C's Semantic Web activity: an evolutionary stage of the World Wide Web in which automated software can store, exchange, and use machine-readable information distributed throughout the Web, in turn enabling users {{to deal with the}} information with greater efficiency and certainty. RDF's simple <b>data</b> <b>model</b> and ability to model disparate, abstract concepts has also led to its increasing use in knowledge management applications unrelated to Semantic Web activity.|$|E
500|$|Radiometric dating {{was used}} to {{determine}} the age of rock samples from Lōʻihi. The Hawaii Center for Volcanology tested samples recovered by various expeditions, notably the 1978 expedition, which provided 17 dredge samples. Most of the samples were found to be of recent origin; the oldest dated rock is around 300,000 years old. Following the 1996 event, some young breccia was also collected. Based on the samples, scientists estimate Lōʻihi is about 400,000 years old. The rock accumulates at an average rate of [...] per year near the base, and [...] near the summit. If the <b>data</b> <b>model</b> from other volcanoes such as Kīlauea holds true for Lōʻihi, 40% of the volcano's mass formed within the last 100,000 years. Assuming a linear growth rate, Lōʻihi is 250,000 years old. However, as with all hotspot volcanoes, Lōʻihi's level of activity has increased with time; therefore, it would take at least 400,000 years for such a volcano to reach Lōʻihi's mass. As Hawaiian volcanoes drift northwest {{at a rate of about}} [...] a year, Lōʻihi was [...] southeast of its current position at the time of its initial eruption.|$|E
2500|$|... the <b>data</b> <b>model</b> of the OT system: {{whether the}} data in each {{operation}} is character-wise (an individual object), string-wise (a sequence of objects), hierarchical, or other structures.|$|E
5000|$|<b>Data</b> <b>modeling</b> during systems {{analysis}}: In {{systems analysis}} logical <b>data</b> <b>models</b> are created {{as part of}} the development of new databases.|$|R
40|$|Many {{proposals}} using object-oriented <b>data</b> <b>models</b> {{for engineering}} objects {{have appeared in}} the literature. These <b>data</b> <b>models</b> try to represent the data in engineering systems more naturally by organizing it logically and/or physically into objects relevant to the engineering applications using the database. The article reviews and examines several of these proposed <b>data</b> <b>models</b> to identify important properties of the models. It shows that none of the <b>data</b> <b>models</b> excels in all areas, but each has desirable propertie...|$|R
40|$|Interoperability of {{e-government}} {{systems is}} suggested to increase transparency, efficiency, effectiveness, {{and customer service}} in the public sector. Generic <b>data</b> <b>models</b> are often seen {{as a way for}} achieving especially semantic interoperability. To assess how the contemporary <b>data</b> <b>models</b> support semantic egovernment interoperability, we reviewed literature on <b>data</b> <b>models</b> suggested for the public sector in light of four features: standard modelling language, entityrelationship <b>modelling,</b> vocabulary for <b>data</b> exchange and methodology. The review contributes previous research by introducing a four-feature framework for assessing capability of e-government <b>data</b> <b>models</b> to enhance interoperability and by providing an up-to-date review of the generic <b>data</b> <b>models</b> for this purpose. Godkänd; 2014; 20141105 (terpai) </p...|$|R
2500|$|BIBFRAME in 2011, a <b>data</b> <b>model</b> for bibliographic {{description}} {{to provide a}} foundation for those depending on bibliographic data shared by the Library with partners on the web and in the broader networked world; ...|$|E
2500|$|The {{development}} of a computer-based information system includes a system analysis phase. This helps produce the <b>data</b> <b>model,</b> a precursor to creating or enhancing a database. There {{are a number of}} different approaches to system analysis. When a computer-based information system is developed, system analysis (according to the Waterfall model) would constitute the following steps: ...|$|E
2500|$|Two {{persistent}} misunderstandings about RDF {{developed at}} this time: firstly, {{due to the}} MCF influence and the RDF [...] "Resource Description" [...] acronym, the idea that RDF was specifically for use in representing metadata; secondly that RDF was an XML format rather than a <b>data</b> <b>model,</b> and only the RDF/XML serialisation being XML-based. RDF saw little take-up in this period, but there was significant work done in Bristol, around ILRT at Bristol University and HP Labs, and in Boston at MIT. RSS 1.0 and FOAF became exemplar applications for RDF in this period.|$|E
5000|$|Information Systems (<b>Data)</b> Continuum <b>Model</b> (<b>data</b> <b>modeling</b> and <b>data</b> flow) ...|$|R
40|$|Many {{organizations}} now {{purchase and}} customize software rather than build information systems. In this light, {{some argue that}} high-level <b>data</b> <b>modeling</b> no longer has a role. In this paper, we examine the contemporary relevance of high-level <b>data</b> <b>modeling.</b> We addressed this issue by asking 21 experienced data-modeling practitioners {{to reflect on their}} work and to give their opinions on trends and future directions in high-level <b>data</b> <b>modeling.</b> We analyzed transcripts of our interviews with them using Klein and Myers’s (1999) framework for qualitative research. We found considerable variation in the practice of high-level <b>data</b> <b>modeling.</b> We also found that high-level <b>data</b> <b>modeling</b> is still considered important, even though organizations ultimately may purchase off-the-shelf software. The reason is that high-level <b>data</b> <b>modeling</b> assists organizations to obtain clarity about IT project scope and requirements, thereby reducing the risk that costly implementation mistakes will be made...|$|R
40|$|Conceptual <b>data</b> <b>modelling</b> {{techniques}} aim at {{the representation}} of data {{at a high level}} of abstraction. This implies that conceptual <b>data</b> <b>modelling</b> techniques should not only be capable of naturally representing complex structures, but also the rules (constraints) that must hold for these structures. Contemporary <b>data</b> <b>modelling</b> techniques however, do not provide a language, which on the one hand has a formal semantics {{and on the other hand}} leads to natural looking expressions, for formulating these constraints. In this paper such a language is defined for an existing <b>data</b> <b>modelling</b> technique (PSM), which is a generalisation of object-role models (such as ER or NIAM). In this language not only constraints, but also queries and updates can be expressed on a conceptual level. 1 Introduction Currently, many conceptual <b>data</b> <b>modelling</b> techniques exist. Conceptual <b>data</b> <b>modelling</b> techniques {{aim at the}} representation of data at a high level of abstraction. The Conceptualisation Principl [...] ...|$|R
