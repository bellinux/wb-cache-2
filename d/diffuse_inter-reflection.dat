6|9|Public
50|$|These {{algorithms}} model <b>diffuse</b> <b>inter-reflection</b> {{which is}} {{a very important part of}} global illumination; however most of these (excluding radiosity) also model specular reflection, which makes them more accurate algorithms to solve the lighting equation and provide a more realistically illuminated scene.|$|E
50|$|Theoretically, reflections, refractions, {{and shadows}} are all {{examples}} of global illumination, because when simulating them, one object affects the rendering of another (as {{opposed to an}} object being affected only by a direct light). In practice, however, only the simulation of <b>diffuse</b> <b>inter-reflection</b> or caustics is called global illumination.|$|E
50|$|Arnold {{is based}} on Monte Carlo Ray Tracing. Thus its engine is {{optimized}} to send billions of spatially incoherent rays throughout a scene. It often uses one level of <b>diffuse</b> <b>inter-reflection</b> so that light can bounce off of a wall or other object and indirectly illuminate a subject. For complex scenes such as the space station in Elysium, it makes heavy use of instancing. It uses the Open Shading Language to define the materials and textures.|$|E
40|$|Abstract In {{this paper}} {{we present a}} novel {{real-time}} algorithm to compute the global illumination of dynamic scenes with arbitrarily complex dynamic illumination. We use a virtual point light (VPL) illumination model on the volume representation of the scene. Unlike other dynamic VPL-based real-time approaches, our method handles occlusion (shadowing and masking) caused by the interference of geometry {{and is able to}} estimate <b>diffuse</b> <b>inter-reflections</b> from multiple light bounces. ...|$|R
40|$|In {{this paper}} {{we present a}} novel {{real-time}} algorithm to compute the global illumination of scenes with dynamic geometry and arbitrarily complex dynamic illumination. We use a virtual point light (VPL) illumination model on the volume representation of the scene. Light is propagated in void space using an iterative diffusion approach. Unlike other dynamic VPL-based real-time approaches, our method handles occlusion (shadowing and masking) caused by the interference of geometry {{and is able to}} estimate <b>diffuse</b> <b>inter-reflections</b> from multiple light bounces...|$|R
40|$|This paper {{presents}} a multi-computer, parallel {{version of the}} recently-proposed "Density Estimation" (DE) global illumination method, designed for computing solutions of environments with high geometric complexity (as many as {{hundreds of thousands of}} initial surfaces). In addition to the <b>diffuse</b> <b>inter-reflections</b> commonly handled by conventional radiosity methods, this new method can also handle energy transport involving arbitrary non-diffuse surfaces. Output can either be Gouraud-shaded elements for interactive walkthroughs, or ray-traced images for higher quality still frames. The key difference of the DE algorithm from conventional radiosity, in terms of its ability to parallelize efficiently, is its microscopic view of energy transport, which avoids the O(n 2) pairwise surface interactions of most previous macroscopic radiosity algorithms (i:e:, those without clustering). Parallel DE is implemented as two separate parallel programs which perform different phases of the DE metho [...] ...|$|R
5000|$|In {{real-time}} 3D graphics, the <b>diffuse</b> <b>inter-reflection</b> {{component of}} global illumination is sometimes approximated by an [...] "ambient" [...] {{term in the}} lighting equation, which is also called [...] "ambient lighting" [...] or [...] "ambient color" [...] in 3D software packages. Though this method of approximation (also known as a [...] "cheat" [...] because it's not really a global illumination method) is easy to perform computationally, when used alone it does not provide an adequately realistic effect. Ambient lighting is known to [...] "flatten" [...] shadows in 3D scenes, making the overall visual effect more bland. However, used properly, ambient lighting can be {{an efficient way to}} make up for a lack of processing power.|$|E
40|$|National audienceThis report builds upon {{existing}} work on Virtual Light Fields (VLF). A previous VLF implementation allows interactive walkthrough of {{a static}} globally illuminated scene on a modern desktop computer. This report outlines enhancements to this implementation which allow movable geometry {{to be added}} to existing VLF solutions. Two diffuse shading modes are implemented for the dynamic geometry. A fast simple mode which approximates the emitters in the VLF using OpenGL light sources and a slower advanced mode which approximates the <b>diffuse</b> <b>inter-reflection</b> and soft shadows received on the dynamic geometry using information from the VLF. In both modes the dynamic geometry casts hard shadows onto existing diffuse geometry in the scene. Both modes can achieve interactive rates on a high specification modern desktop computer, although advanced mode is limited to simple dynamic objects due to the expensive diffuse gathering step. Potential optimisations are discussed...|$|E
40|$|Graduation date: 2014 Realistic (ideally photorealistic) {{real-time}} rendering {{has remained}} an elusive goal in computer graphics. While photorealistic rendering {{has certainly been}} achieved {{at the expense of}} tremendous computational resources and corresponding rendering times; real-time rendering typically must accept a great number of compromises to achieve adequate performance, such as aliasing artifacts, the absence of secondary illumination effects such as <b>diffuse</b> <b>inter-reflection</b> and realistic specular reflections, and a lack of geometric detail. This dissertation demonstrates solutions which reduce the computational cost of solving the rendering equation through a series of strategic approximations which are well suited to the massively parallel nature of current consumer GPUs and their integrated filtering hardware. Firstly, we discretize scene geometry, using a novel and highly efficient voxelization technique. From the voxelization, we efficiently generate a hierarchical representation of scene geometry. We then use this hierarchical representation as a proxy for computation of indirect illumination using a technique called Voxel Cone Tracing. Finally we explore the storage of both isotropic and anisotropic functions within our hierarchical scene proxy, and evaluate the usage of low order spherical harmonics as a more suitable approximation of radiance...|$|E
40|$|Abstract. We show that, under {{spatially}} varying illumination, {{the light}} transport of diffuse scenes can be decomposed into direct, near-range (subsurface scattering and local inter-reflections) and far-range transports (<b>diffuse</b> <b>inter-reflections).</b> We show that these three component transports are redundant {{either in the}} spatial or the frequency domain and can be separated using appropriate illumination patterns. We propose a novel, efficient method to sequentially separate and acquire the component transports. First, we acquire the direct transport by extending the direct-global separation technique from floodlit images to full transport matrices. Next, we separate and acquire the near-range transport by illuminating patterns sampled uniformly in the frequency domain. Finally, we acquire the far-range transport by illuminating lowfrequency patterns. We show that theoretically, our acquisition method achieves the lower bound our model places on the required number of patterns. We quantify the savings in number of patterns over the brute force approach. We validate our observations and acquisition method with rendered and real examples throughout. ...|$|R
40|$|We present primal-dual coding, a {{photography}} {{technique that}} enables direct fine-grain control over which light paths {{contribute to a}} photo. We achieve this by projecting a sequence of patterns onto the scene while the sensor is exposed to light. At the same time, a second sequence of patterns, derived from the first and applied in lockstep, modulates the light received at individual sensor pixels. We show that photography in this regime is equivalent to a matrix probing operation in which {{the elements of the}} scene's transport matrix are individually re-scaled and then mapped to the photo. This makes it possible to directly acquire photos in which specific light transport paths have been blocked, attenuated or enhanced. We show captured photos for several scenes with challenging light transport effects, including specular <b>inter-reflections,</b> caustics, <b>diffuse</b> <b>inter-reflections</b> and volumetric scattering. A key feature of primal-dual coding is that it operates almost exclusively in the optical domain: our results consist of directly-acquired, unprocessed RAW photos or differences between them. Alfred P. Sloan Foundation (Research Fellowship) United States. Defense Advanced Research Projects Agency (DARPA Young Faculty Award) Massachusetts Institute of Technology. Media Laboratory (Consortium Members...|$|R
40|$|Figure 1 : Left to right: Scene under white {{illumination}}, global illumination component {{captured in}} just a single RAW photograph (no processing), and direct component from subtracting the middle image from the left image. The global image was captured using 512 primal and dual patterns during one 30 -second exposure. Notice that the objects embedded within the wax disk are only visible in the global image. We present primal-dual coding, a photography technique that enables direct fine-grain control over which light paths contribute to a photo. We achieve this by projecting a sequence of patterns onto the scene while the sensor is exposed to light. At the same time, a second sequence of patterns, derived from the first and applied in lockstep, modulates the light received at individual sensor pixels. We show that photography in this regime is equivalent to a matrix probing operation in which {{the elements of the}} scene’s transport matrix are individually re-scaled and then mapped to the photo. This makes it possible to directly acquire photos in which specific light transport paths have been blocked, attenuated or enhanced. We show captured photos for several scenes with challenging light transport effects, including specular <b>inter-reflections,</b> caustics, <b>diffuse</b> <b>inter-reflections</b> and volumetric scattering. A key feature of primal-dual coding is that it operates almost exclusively in the optical domain: our results consist of directly-acquired, unprocessed RAW photos or differences between them...|$|R
40|$|International audienceWhile many methods {{exist for}} {{simulating}} <b>diffuse</b> light <b>inter-reflections,</b> relatively {{few of them}} are adapted to dynamic scenes. Despite approximations made on the formal rendering equation, managing dynamic environments at interactive or real-time frame rates still {{remains one of the}} most challenging problems. This paper presents a lighting simulation system based on photon streaming, performed continuously on the central processor unit. The power corresponding to each photon impact is accumulated onto predefined points, called virtual light accumulators (or VLA). VLA are used during the rendering phase as virtual light sources. We also introduce a priority management system that automatically adapts to brutal changes during lighting simulation (for instance due to visibility changes or fast object motion). Our system naturally benefits from multi-core architecture. The rendering process is performed in real time using a graphics processor unit, independently from the lighting simulation process. As shown in the results, our method provides high framerates for dynamic scenes, with moving viewpoint, objects and light sources...|$|R
40|$|Real-time {{rendering}} {{can benefit}} from global illumination methods to make the three-dimensional environ-ments look more convincing and lifelike. On the other hand, the conventional global illumination algorithms for the estimation of the <b>diffuse</b> surface <b>inter-reflection</b> make heavy usage of intra- and inter-object visibility calculations, so they are time consuming, and using them in real-time graphics applications can be prohibitive for complex scenes. Modern illumination approximations, such as ambient occlusion variants, use pre-calculated or frame-dependent data to reduce the problem to a local shading one. This paper presents a fast real-time method for visibility sampling using volumetric data {{in order to produce}} accurate inter- and intra-object ambient occlusion. The proposed volume sampling technique disassociates surface representation data from the visibility calculations, and therefore makes the method suitable for both primitive-order or screen-order rendering, such as deferred rendering. The sampling mechanism can be used in any application that performs visibility queries or ray marching...|$|R
40|$|Figure 1 : Our {{visibility}} caching significantly {{speeds up}} tracing of secondary rays, here from 0. 15 MRays/s (reference) to 0. 70 MRays/s (with the visibility cache). The images were rendered using path tracing {{where some of}} the rays (highlighted by green in the illustrations; solid and dashed lines represent path segments and shadow rays, resp.) were traced using our visibility cache with 2000 shadow maps achieving 4. 7 × higher throughput of secondary rays per second. Rendering realistic images requires exploring the vast space of all possible paths that light can take between emit-ters and receivers. Thanks to the advances in rendering we can tackle this problem using different algorithms; but in general, we will likely be evaluating many expensive visibility queries. In this paper, we leverage the ob-servation that certain kinds of visibility calculations {{do not need to be}} resolved exactly and results can be shared efficiently among similar queries. We present a visibility caching algorithm that significantly accelerates compu-tation of <b>diffuse</b> and glossy <b>inter-reflections.</b> By estimating the visibility correlation between surface points, the cache automatically adapts to the scene geometry, placing more cache records in areas with rapidly changing visibility. We demonstrate that our approach is most suitable for progressive algorithms delivering approximate but fast previews as well as high quality converged results...|$|R

