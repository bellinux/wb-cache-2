1|1570|Public
40|$|International Telemetering Conference Proceedings / October 10 - 12, 1972 / International Hotel, Los Angeles, CaliforniaRedundant area coding was {{proposed}} in an Air Force patent, James Maier inventor, {{to relieve the}} long integration time required to transmit a reconnaissance photograph through narrow-band communication circuits where upper limits of 4800 to 9600 bits/second prevail. Further development by Radiation Systems Division was funded by Rome Air Development Center’s Reconnaissance and Intelligence Division. Mr. Lawrence Gardenhire developed the analysis curves used. As redundant area coding was conceived, unimportant areas were reduced by applying different orders of resolution throughout one frame of imagery, by blanking redundant areas, or by applying encoding so one frame could consist of areas basically unchanged and areas coded to represent special land such as Forest or desert. What evolved were techniques of applying redundant reduction algorithms in both areas, producing a low/ high resolution picture. Where 3 to 1 reduction ratios were optimum for an average “busy” picture, reduction ratios exceeding 10 to I have been realized. A 9 x 9 inch, 2000 x 2000, 6 -bit <b>grey</b> <b>level</b> <b>picture</b> that required 42 minutes to send at a 9600 -bit/ second rate, or about 14 minutes for a 3 to 1 reduction, can now be sent in 5 to 6 minutes. A 10 to 1 reduction ratio makes transmitting imagery through existing ground circuits more of a reality and fulfills user requirements...|$|E
40|$|An {{efficient}} {{data compression}} system is presented for satellite <b>pictures</b> and two <b>grey</b> <b>level</b> <b>pictures</b> derived from satellite pictures. The compression techniques take {{advantages of the}} correlation between adjacent picture elements. Several source coding methods are investigated. Double delta coding is presented and shown {{to be the most}} efficient. Both predictive differential quantizing technique and double delta coding can be significantly improved by applying a background skipping technique. An extension code is constructed. This code requires very little storage space and operates efficiently. Simulation results are presented for various coding schemes and source codes...|$|R
40|$|International audienceThis paper aims at {{describing}} an inflation {{test protocol}} {{on a human}} liver capsule using stereo-correlation. The biaxial tension created by the inflation test {{is comparable to the}} type of loading the capsule would be subjected to during a liver compression. Confocal microscopy associated to an anti-collagen coloration reveals that the tissue is isotropic at the meso-scale. Stereo-correlation provides the strain field of the capsule during the test. It emphasizes the boundary condition effects on the strain field. The measurement of the shape of the capsule is used to determine the parameters of two hyperelastic (polynomial and exponential) homogeneous models. The ultimate first principal strain before failure is measured locally and its value is 50. 5 %± 10. 8 %. In this protocol, the light goes throughout the sample and makes the heterogeneities of the material appear as darker <b>grey</b> <b>levels</b> on the <b>pictures.</b> These heterogeneities also appear on the strain fields, so we can assume that they have different material properties...|$|R
40|$|We {{address in}} this paper {{automatic}} face verification from 3 D (3 -dimensional) facial surface and <b>grey</b> <b>level</b> analysis. 3 D acquisition is performed by a structured light system, adapted to face capture and allowing <b>grey</b> <b>level</b> acquisition in alignment. The 3 D facial shapes are compared and the residual error after 3 D matching {{is used as a}} first similarity measure. A second similarity measure is derived from <b>grey</b> <b>level</b> comparison. As expected, fusing 3 D and <b>grey</b> <b>level</b> information increases verification performances. The acquisition system, the 3 D and <b>grey</b> <b>level</b> comparison algorithms were designed to be integrated in security applications in which individuals cooperate...|$|R
3000|$|... (i,j[*]=[*] 0,…,G- 1) {{represents}} a {{probability of occurrence}} in a ROI {{of a pair of}} pixels in which: the first pixel has a <b>grey</b> <b>level</b> i, and the second one -- a <b>grey</b> <b>level</b> j [35]. G is the number of <b>grey</b> <b>levels</b> that can be encoded in an image. A matrix dimension is therefore G[*]×[*]G. Like in the GLDM-based method, four pixel alignment directions and several distances between pixels could be considered. In contrast to the previous method, a COM-based one focuses on all the possible combinations of <b>grey</b> <b>levels</b> in pairs.|$|R
30|$|Endometrial primary tumours were {{contoured}} {{with the}} iterative thresholding algorithm implemented in PET-VCAR software (GE Healthcare Milwaukee, WI, USA). On each volume of interest (VOI), 75 features were computed: SUVmax, SUVmean, metabolic tumour volume (MTV) and total lesion glycolysis (TLG); 6 geometrical shape features; 7 first-order features {{based on the}} <b>grey</b> <b>level</b> histogram; and 58 texture features. As to texture features, the freely available CGITA software [24] was used. <b>Grey</b> <b>levels</b> inside each VOI were resampled in N[*]=[*] 64 quantization levels [25] and nine texture matrices were computed in 3 D with a 26 -voxel connectivity: <b>grey</b> <b>level</b> co-occurrence matrix (GLCM) and normalized <b>grey</b> <b>level</b> co-occurrence matrix (NGLCM) [26 – 28]; voxel alignment matrix (VAM) [29]; <b>grey</b> <b>level</b> size zone matrix (GLSZM) [29, 30]; neighbourhood grey tone difference matrix (NGTDM) [31]; texture spectrum (TS) [32]; texture feature coding matrix (TFCM) and texture feature coding co-occurrence matrix (TFCCM) [33]; and neighbourhood <b>grey</b> <b>level</b> dependence matrix (NGLDM) [34]. Texture features were computed on these texture matrices.|$|R
30|$|The first-order {{features}} are {{based only on}} the distribution of pixel <b>grey</b> <b>levels</b> and do not consider the relationships between neighboring pixels. They could contain some useful information in terms of tissue differentiation. They provide knowledge on the most frequent and the least frequently occurring <b>grey</b> <b>levels,</b> on the concentration of the <b>grey</b> <b>levels</b> around their average, or on the degree of asymmetry in their distribution.|$|R
30|$|The most known features, {{proposed}} in the above paper, are: the short run emphasis, the long run emphasis, the <b>grey</b> <b>level</b> non-uniformity (distribution), the run length non-uniformity (distribution), and the fraction of image in runs. Two additional parameters were {{proposed in}} [38]: low <b>grey</b> <b>level</b> runs emphasis, and high <b>grey</b> <b>level</b> runs emphasis. Finally, in [39], a run length entropy {{was used as a}} texture feature.|$|R
30|$|The {{correlation}} between the <b>grey</b> <b>levels</b> of neighboring pixels can be expressed by the normalized autocorrelation coefficients [32]. It is {{the function of the}} vertical (Δx) and the horizontal (Δy) distance between the considered pixels in pairs, and can be defined as follows: γ(Δx,Δy)[*]=[*]A(Δx,Δy)/A(0, 0). A(Δx,Δy) is the average product of pairs of <b>grey</b> <b>levels</b> corresponding to all the pairs of pixels belonging to a ROI, and spaced from one another by a distance (Δx,Δy). To make the autocorrelation coefficient independent of the image brightness, the <b>grey</b> <b>level</b> mean can be extracted from each <b>grey</b> <b>level</b> before calculating the above formula.|$|R
40|$|A Bayesian {{probability}} based tissue segmentation {{method is}} presented, which {{makes use of}} the <b>grey</b> <b>level</b> information in the images and also the local <b>grey</b> <b>level</b> slope. The <b>grey</b> <b>level</b> distributions are modelled as a combination of Gaussian distributions and triangle-Gaussian convolutions. The local <b>grey</b> <b>level</b> slope distribution is modelled as a linear combination of Rician distributions. The parameters are fitted and used to provide the information required to constructed a Bayesian tissue classifier. Results presented for a synthetic data set illustrate that the model distributions describe well the distribution of <b>grey</b> <b>levels</b> and local <b>grey</b> <b>level</b> slope in a 2 D image. Application of the method to an MR image of a human brain demonstrate how the segmentation method removes commonly occuring artifacts in partial volume probability maps. Summary This work addresses the problem of partial volume estimation, where a mixture {{of two or more}} tissues combine to produce the image intensity value for a particular voxel. Bayes theory is used to generate probability maps for each segmented tissue which estimates the most likely tissue volume fraction within each voxel as opposed to previous approaches which attempt to compute how likely it is that a certain <b>grey</b> <b>level</b> would be generated by a particula...|$|R
40|$|The {{object of}} this bachelor‘s thesis is create an {{application}} for editing the histogram. The program is realized by programming language C++ and programming tool Microsoft Visual C++ 2005 Express Edition. It defines fundamental terms for this work as histogram or transformation of <b>grey</b> <b>level</b> scale. Above all, it analyses individual <b>grey</b> <b>level</b> transformations, which used for editing the histogram. It describes designing and realization of application. Input data of program is any input digital image, which user order, selected <b>grey</b> <b>level</b> transformation and its parameters. Output data are input image in <b>grey</b> <b>levels,</b> histogram input image, transformed input image and its histogram. Output images can be saved...|$|R
30|$|The grey-level {{transformation}} step starts by linearly normalizing {{the intensity}} between levels 0 and 1. Next, the pixels are assigned a <b>grey</b> <b>level.</b> This {{is done by}} sequentially visiting each granule pixel and examining its local neighborhood. If all neighbors are within 98 % of the granularity, they are assigned to the same <b>grey</b> <b>level,</b> else they will be assigned to a different granulation. After this transformation, a morphological opening is performed to decrease scattered <b>grey</b> <b>levels.</b>|$|R
30|$|This method {{allows the}} {{calculation}} of first-order features, based only {{on the distribution of}} <b>grey</b> <b>levels</b> (or intensities) of pixels within an analyzed ROI. Such features provide knowledge on the most and the least occurring <b>grey</b> <b>levels,</b> on the concentration of the <b>grey</b> <b>levels</b> around their average, or on the degree of asymmetry in their distribution. Contrariwise, they contain no information on the relationship between neighboring pixels, on the possible direction of the texture, its structure, and other properties resulting from these relationships.|$|R
40|$|Complex optical {{properties}} of plagioclase, such as twinning, present a particularly difficult challenge to image processing techniques. Conventional image processing methods attempt to recognize mineral grain boundaries by <b>grey</b> <b>level</b> gradients {{and are likely}} to classify optical twin zones as different grains. To overcome this problem, automated <b>grey</b> <b>level</b> processing of small areas under different orientations of cross polarization is used to identify both twinned and un-twinned plagioclase areas as seeds. In an interactive procedure, seeds are projected onto polarized images and are built-up to individual grains. An independent <b>grey</b> <b>level</b> utility supplements automatic processing, allowing <b>grey</b> <b>level</b> profiling down to groups of a few pixels, providing a means for preliminary examinations of thin sections, and to establish typical differences between grain types...|$|R
40|$|In this paper, {{we present}} an {{original}} unsupervised segmentation scheme which splits a <b>grey</b> <b>level</b> image into {{different sets of}} connected pixels whose <b>grey</b> <b>levels</b> are homogeneous. This approach {{is based on an}} analysis of a triangular table denoted ”Normalized connectivity degrees pyramid”. This method is used in order to detect cytomegalovirus retinitis lesions by fundus image analysis. First, we determine the number of pixels classes and their cores. The core of each class � � is represented by an interval of <b>grey</b> <b>levels</b> �Ñ�Ò�� � Ñ�Ü� � ℄. For classification purpose, the pixels whose <b>grey</b> <b>level</b> belongs to such an interval are labelled to the corresponding class. The other pixels are assigned by comparison of their conditional probability to belong to the different classes. ...|$|R
25|$|According to Fanti and Moroni, after {{comparing}} the histograms of 256 different <b>grey</b> <b>levels,</b> {{it was found}} that the image obtained with a bas-relief has grey values included between 60 and 256 levels, but it is much contrasted with wide areas of white saturation (levels included between 245 and 256) and lacks of intermediate <b>grey</b> <b>levels</b> (levels included between 160 and 200). The face image on the Shroud instead has grey tonalities that vary in the same values field (between 60 and 256), but the white saturation is much less marked and the histogram is practically flat in correspondence of the intermediate <b>grey</b> <b>levels</b> (levels included between 160 and 200).|$|R
3000|$|The method {{consists}} {{in studying the}} absolute values of differences between the <b>grey</b> <b>levels</b> of pixels in pairs belonging to a ROI [34]. Four pixel alignment directions, θ (0 °, 45 °, 90 °, and 135 °), and different distances, d, between the pixels in pairs can be considered. The most often, d takes small values. A combination (d,θ) determines the relative position of pixels composing the pairs to analyze. For a specified combination (d,θ), all possible absolute differences in <b>grey</b> <b>levels</b> that can be encoded in the image are taken into account. For each absolute difference, the probability of occurrence {{of a pair of}} pixels with just such a difference in the <b>grey</b> <b>levels</b> is calculated. The probabilities sorted in increasing order of corresponding absolute <b>grey</b> <b>level</b> differences form a vector l(d,θ)[*]=[*][l [...]...|$|R
30|$|Skewness: {{measures}} of the asymmetry of the grey-level histogram. It expresses a deviation of the grey-level distribution, compared to a symmetric one. It is equal to zero for the symmetric histograms, negative for right oriented ones (high <b>grey</b> <b>levels</b> are more frequent) and positive for a left oriented histograms (more frequent low <b>grey</b> <b>levels).</b>|$|R
40|$|An {{automatic}} {{procedure to}} estimate proportions of components from <b>grey</b> <b>level</b> histograms is proposed. This procedure {{is based on}} statistical methods for parameter estimation in mixtures of normal distributions by maximum likelihood. The major advantage is that proportions of components can be estimated properly even when the <b>grey</b> <b>level</b> distributions of the components overlap considerably. ...|$|R
40|$|A {{method of}} {{identifying}} fingerprints, the method including the steps of: acquiring a test image (20) formed {{by a number}} of test points characterized by different <b>grey</b> <b>levels</b> defining a test surface; determining significant points (21) in the test image; and verifying the similarity (22) between regions surrounding the significant points and corresponding regions of a reference image whose points present different <b>grey</b> <b>levels</b> defining a reference surface. The similarity between the regions (22) is verified by computing the integral norm of portions of the test and reference surfaces; and the integral norm is computed using flash cells (42, 43) programmed with a threshold value correlated to the value of the <b>grey</b> <b>levels</b> in the reference region, by biasing (56) the flash cells with a voltage value correlated to the <b>grey</b> <b>level</b> in the test region, and measuring the charge flowing through the flash cells...|$|R
30|$|Variance of grey levels: {{characterizes the}} {{distribution}} of <b>grey</b> <b>levels</b> around the mean.|$|R
5000|$|Area (for binary images) or sum of <b>grey</b> <b>level</b> (for greytone images): M00 ...|$|R
40|$|The {{feasibility}} of realising a low cost wearable face recognition aid {{based on a}} robust correlation algorithm is investigated. The aim {{of the study is}} to determine the limiting spatial and <b>grey</b> <b>level</b> resolution of the probe and gallery images that would support successful prompting of the identity of input face images. Low spatial and <b>grey</b> <b>level</b> resolution images are obtained from good quality image data algorithmically. The tests carried out on the XM 2 VTS database demonstrate that robust correlation is very resilient to degradations of spatial and <b>grey</b> <b>level</b> image resolution. Correct prompts have been generated in 98 % cases even for severely degraded images...|$|R
40|$|We {{present an}} {{automated}} {{system for the}} analysis of edge based structure for use in morphomet-ric studies. The current work takes a <b>grey</b> <b>level</b> image of a Drosophila wing as input and extracts the coordinates of 15 landmarks. The proposed method extracts the ridges (linear features such as wing veins) using the knowledge of their known <b>grey</b> <b>level</b> profile and the noise character...|$|R
40|$|The {{problems}} of character recognition are today mainly due to imperfect thresholding and segmentation. In this paper {{a new approach}} to text recognition is presented which attempts to avoid these problems by working directly on <b>grey</b> <b>level</b> images and treating an entire word at the time. The features are found from the <b>grey</b> <b>levels</b> of the image, and a hidden Markov model is defined for each character. During recognition the most probable combination of models is found for each word by the use of dynamic programming. 1 Introduction One of the remaining problems in character recognition, is segmentation. Both segmentation of text from background in the <b>grey</b> <b>level</b> image, and segmentation of the constituents of each character in the binary image, is a problem. In this paper we present a method which attempts at avoiding these segmentation problems by working directly on the <b>grey</b> <b>level</b> image and perform recognition word by word instead of character by character. Little work has been done in [...] ...|$|R
5000|$|... where [...] {{represents}} the <b>grey</b> <b>level,</b> [...] the mean value and [...] the standard deviation.|$|R
30|$|Several {{methods of}} image {{post-processing}} {{have been developed}} for Texture Analysis of Magnetic Resonance images (MRI-TA) and have already demonstrated stimulating results in a large range of pre-clinical or clinical applications [1]; MRI-TA usually provides much more clinical discrimination than visual analysis of MR images by the radiologist [2]; visual analysis (about 100 <b>grey</b> <b>level</b> can be discriminated) is ten times less sensitive to fine and local <b>grey</b> <b>level</b> changes than computer analysis (about 1000 <b>grey</b> <b>level</b> by using computer detection). There is presently no well-established consensus concerning the limits of texture visual perception {{but it is clear that}} texture represented by higher orders statistics can only be discriminated by computerized image analysis.|$|R
40|$|In this paper, an {{interactive}} technique for extracting cartographic features from aerial and spatial images is presented. The method is essentially {{an interactive}} method of image region segmentation based on pixel <b>grey</b> <b>level</b> and texture information. The underlying segmentation method is seeded region growing. The criterion for growing regions is based on both texture and <b>grey</b> <b>level,</b> where texture is quantified using cooccurrence matrices. The Kullback distance is utilised with co-occurrence matrices in order to describe the image texture, then the Theory of Evidence is applied to merge the information coming from texture and <b>grey</b> <b>level</b> image from the RGB bands. Several results from aerial and spatial images that support the technique are presente...|$|R
40|$|Today face {{recognition}} {{capability of the}} human visual system {{plays a significant role}} in day to day life due to numerous important applications for automatic {{face recognition}}. One of the problems with the recent image classification and recognition approaches are they have to extract features on the entire image and on the large <b>grey</b> <b>level</b> range of the image. The present paper overcomes this by deriving an approach that reduces the dimensionality of the image using Shape primitives and reducing the <b>grey</b> <b>level</b> range by using a fuzzy logic while preserving the significant attributes of the texture. The present paper proposed an Image Dimensionality Reduction using shape Primitives (IDRSP) model for efficient face recognition. Fuzzy logic is applied on IDRSP facial model to reduce the <b>grey</b> <b>level</b> range from 0 to 4. This makes the proposed fuzzy based IDRSP (FIDRSP) model suitable to <b>Grey</b> <b>level</b> co-occurrence matrices. The proposed FIDRSP model with GLCM features are compared with existing face recognition algorithm. The results indicate the efficacy of the proposed method...|$|R
40|$|Abstract-Typically, the co-occurrence {{features}} for image processing are calculated {{by using a}} <b>grey</b> <b>level</b> co-occurrence matrix (GLCM). This method is computationally intensive since the matrix is usually sparse leading to many unnecessary calculations involving zero probabilities. An improvement on the GLCM method is to utilize a <b>grey</b> <b>level</b> co-occurrence linked list (GLCLL) to store only the non-zero co-occurring probabilities. The GLCLL suffers since, to achieve preferred computational speeds, the list should be sorted. This paper presents a <b>grey</b> <b>level</b> co-occurrence hybrid structure (GLCHS) based on an integrated hash table and linked list approach. Texture features obtained using this technique are identical to those obtained using the GLCM and GLCLL. Based on a Brodatz test image, the GLCHS method is demonstrated to be a superior technique when compared across various window sizes and <b>grey</b> <b>level</b> quantizations. The GLCHS method required, on average, 33. 4 % of the computational time (σ = 3. 08 %) required by the GLCLL. Significant computational gains are made using the GLCHS method. Index Terms-Texture features, hash table, linked list, co-occurrence probabilities, remote sensing imagery...|$|R
40|$|The {{apparatus}} has a {{video camera}} (1) to which is connected a downstream image analysis unit (2). The image analysis unit (2) is arranged to automatically carry out a <b>grey</b> <b>level</b> analysis {{of the image of}} the level crossing observed by the video camera (1), to detect objects of at least a predetermined minimum size in the dangerous area. The image analyser (1) may carry out an individual image analysis for object detection, in which several test lines are provided transverse to the tracks. The <b>grey</b> <b>level</b> profile of an individual image is detected along each test line. The images are smoothed to eliminate the narrow <b>grey</b> <b>level</b> pulses. Jumps in the <b>grey</b> <b>levels</b> greater than a predetermined threshold may then be analysed as an object to be detected. The video camera is preferably arranged over the middle area of the level crossing, with an image depth device running parallel to the tracks. ADVANTAGE - Detects presence of objects on level crossing, such as cars on track when crossing gates are closed...|$|R
40|$|Textural {{patterns}} {{can often}} be used to recognize familiar objects in an image or retrieve images with similar texture from a database. Texture patterns can provide significant and abundance of texture and shape information. One of the recent significant and important texture features called Texton represents the various patterns of image which is useful in texture analysis. However sometimes the textured image obtained may not be of good quality and this may lead to improper detection of significant patterns. To enhance the quality or better illumination or contrast or sharpening effect, the present paper applied various local <b>grey</b> to <b>grey</b> <b>level</b> preprocessing steps on textured data. <b>Grey</b> to <b>grey</b> <b>level</b> preprocessing is required because the patterns on textons can be evaluated only on <b>grey</b> <b>level</b> textures. The present paper evaluated the occurrence behavior of various texton patterns based on the various <b>grey</b> to <b>grey</b> <b>level</b> pre processing methods, for an efficient rotationally invariant texture classification. The experimental results on various stone textures indicate {{the efficacy of the}} proposed method when compared to other methods...|$|R
40|$|A good {{watermarking}} technique embeds {{information into}} a carrier image with virtually imperceptible {{modification of the}} image. The present paper found a novel fact that by inserting the watermark using Least Significant Bit (LSB), the grey value of the image pixel either remains same or increases or decreases to one. The present paper is focused on this issue and found that such ambiguity of <b>grey</b> <b>level</b> values by LSB method comes between successive even and odd <b>grey</b> <b>level</b> values only. The proposed method inserts hidden message on m x m windows, based on their <b>grey</b> <b>level</b> values and coordinate positions. The present approach allows high robustness, embedding capacity and enhanced security. A detailed algorithm is furnished along {{with the results of}} its application on some sample images...|$|R
40|$|By {{making use}} of <b>grey</b> <b>level</b> {{dependence}} matrix methods, digitized images of the froth phases in a copper flotation plant were reduced to feature vectors without losing essential information {{of the characteristics of}} the froth. Classification of features extracted by means of both spatial <b>grey</b> <b>level</b> dependence matrix (SGLDM) methods, as well as neighbouring <b>grey</b> <b>level</b> dependence matrix (NGLDM) methods was investigated. By using a learning vector quantization (LVQ) neural net it was shown that froth structures could be classified satisfactorily when either NGLDM or SGLDM methods were used. When these feature sets were combined, however, the success rate of classification improved to almost 90 %. This is sufficiently accurate to enable incorporation of the neural net classifier into on-line plant control systems. © 1995. Articl...|$|R
3000|$|... where σ is {{a spread}} parameter: the larger σ, the slower the <b>grey</b> <b>level</b> values {{decrease}} aside the center circle.|$|R
5000|$|... "Investigating the {{relationship}} between <b>grey</b> <b>levels</b> and linear attenuation coefficients in order to derive Hounsfield units in CBCT" [...] OnDemand3D ...|$|R
