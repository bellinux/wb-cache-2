35|373|Public
5000|$|Trigger a CPU-serviced {{interrupt}} routine, {{called the}} [...] "Vertical Blank Interrupt", {{at the end}} of the <b>display</b> <b>frame.</b>|$|E
50|$|A webcam (Namuga 1.3 megapixel) {{is built}} into the <b>display</b> <b>frame,</b> as well as a microphone. Together with the {{built-in}} stereo speakers, the NC20 can be used for audio/video conferences (e.g. using Skype), albeit only with moderate call-quality. The webcam picture becomes relatively noisy under low-light conditions and the microphone produces audible noise and picks up vibrations from the harddisk or when typing.|$|E
50|$|Because the {{algorithm}} operates on single pixels {{and has no}} conditional statements, it is very fast and suitable for real-time transformations. Additionally, because {{the location of the}} dithering patterns stays always the same relative to the <b>display</b> <b>frame,</b> it is less prone to jitter than error-diffusion methods, making it suitable for animations. Because the patterns are more repetitive than error-diffusion method, an image with ordered dithering compresses better. Ordered dithering is more suitable for line-art graphics as it will result in straighter lines and fewer anomalies.|$|E
50|$|By {{changing}} the <b>display</b> <b>frames</b> halfway through, over 2400 frames of material were shown.|$|R
50|$|The cover {{claimed the}} Best Art Vinyl Award 2008, an annual award, {{organized}} by Artvinyl.com, {{a company that}} manufactures <b>display</b> <b>frames</b> for record albums.|$|R
25|$|Mode $02 <b>displays</b> Freeze <b>Frame</b> data.|$|R
50|$|In late 2002, Game Park {{introduced}} the frontlight unit (FLU) as a factory modified (by Hahotech) {{version of the}} NLU. It provides its own illumination via a transparent panel between the LCD display and the plastic screen cover. The extra hardware resulted in a slightly raised <b>display</b> <b>frame</b> {{when compared to the}} NLU and BLU variants. The frontlight could be turned off with a switch mounted {{on the back of the}} GP32 case (to save battery).The GP32 FLU's name was derived from a sticker added to the front of the GP32 packaging differentiating it from the standard non-light versions.|$|E
50|$|Auburn was {{designed}} specifically {{to take advantage of}} (and promote) the use of AGP interface, during the time when many competing 3D accelerators (notably, 3dfx Voodoo Graphics) still used the PCI connection. A unique characteristic, which set the AGP version of the card apart from other similar devices on the market, was the use of on-board memory exclusively for the <b>display</b> <b>frame</b> buffer, with all textures being kept in the computer system's main RAM. At the time, most accelerators used the CPU for triangle setup and geometry calculations, then handed the data off to the card to apply texture mapping and bilinear filtering. By leaving this data in main memory, and giving the graphics card a high-speed channel to the data, performance could be improved while also reducing the total amount of memory in the system.|$|E
50|$|In general, it {{is easier}} for {{consumers}} in PAL/SECAM countries to view NTSC DVDs than vice versa. Almost all DVD players sold in PAL/SECAM countries are capable of playing both kinds of discs, and most modern PAL TVs can handle the converted signal. However, most NTSC players cannot play PAL discs, and most NTSC TVs do not accept 576i video signals as used on PAL/SECAM DVDs. Those in NTSC countries, such as the United States, generally require both a region-free, multi-standard player and a multi-standard television to view PAL discs, or a converter box, whereas those in PAL countries generally require only a region-free player to view NTSC discs. There are also differences in pixel aspect ratio (720 × 480 vs. 720 × 576 with the same image aspect ratio) and <b>display</b> <b>frame</b> rate (29.97 vs. 25).|$|E
50|$|NTSC {{television}} {{images are}} scanned at roughly 60 Hz, with two interlaced fields per <b>frame,</b> <b>displayed</b> at 30 <b>frames</b> per second.|$|R
50|$|Visitors to Ashbourne can now {{view the}} series of wooden <b>display</b> <b>frames</b> {{carrying}} the names that are updated yearly at the new Ashbourne Library on Compton. The boards were originally in the entrance foyer of the function room at the Green Man, but were removed from there after the hotel shut in 2012.|$|R
5000|$|In 2D {{computer}} animation, moving {{objects are}} {{often referred to}} as [...] "sprites." [...] A sprite is an image that has a location associated with it. The location of the sprite is changed slightly, between each <b>displayed</b> <b>frame,</b> to make the sprite appear to move. The following pseudocode makes a sprite move from left to right: ...|$|R
5000|$|... #Caption: The {{evolution}} of the Datalink line shown with metal bands for easy comparison (left to right in order of chronological appearance): Datalink model 50 (1994), Ironman Triathlon, with the Ironman Triathlon logo on {{the upper part of}} the face (1997) and Datalink USB sports edition (2003). The small lens is seen on both model 50 and the Ironman. Note also the inverted circular arch digital <b>display</b> <b>frame</b> design on the model 50, compared to the frame design of the other two models. The Microsoft logo appears at the top, while the Datalink logo appears at the bottom for model 50. The lower button arrangement and platform is the same for both model 50 and Ironman triathlon, but Ironman sports an additional start/split button on its face, indicating its additional chronograph functions. All three models are water resistant to 100 m. The model 50 (Timex models 70502/70518) was worn by astronaut James H. Newman on STS-88.|$|E
40|$|One of {{the quality}} of service (QOS) factors in video-ondemand (VOD) {{applications}} is to provide high resolution quality to end users. One way to achieve this is to provide a constant <b>display</b> <b>frame</b> rate (e. g., 30 frames/sec) at the display station. However, {{due to the nature of}} video files and compression technique applied, video frame sizes vary significantly from frame to frame. Therefore, although the <b>display</b> <b>frame</b> rate is fixed, data retrieval is a variable bit rate process. Conventional VOD storage servers assume a peak rate retrieval of video files. Therefore, the number of concurrent requests to the VOD server cannot be maximized. In this paper, we consider a VOD storage server which can support a fixed frame rate at the display and at the same time, variable bit rates retrieval of compressed video files. We describe 1) video files layout strategy, 2) request scheduling algorithm, 3) buffering issues and, 4) various VCR features support such that the number of concurrent request [...] ...|$|E
40|$|Abstract. With current {{extensive}} {{usage of}} mobile computing techniques and small display units, navigation systems have also obtained widespread usage. For better navigation systems {{it is important}} to develop map transformation techniques where all map objects in the user’s focus areas are projected onto the small <b>display</b> <b>frame.</b> In this paper we develop a map transformation technique, which includes all map objects that enjoy the user’s focus within the <b>display</b> <b>frame,</b> while still maintaining the topological relationships of the map. It impslements two distinct functions (1) Scale control – Map objects within the user’s focus area are displayed at a higher scale while the scale of other objects are controlled so as to maintain the topological relationships of the map, (2) Visual Programming Tool – This is used to visually specify the location and scale of objects in the focus area of the user. We explain in detail the implementation methods of both these functions in two phases. Experimental results show the feasibility and the effectiveness of this proposed transformation method...|$|E
50|$|NOTE: To {{avoid this}} bug in the CEA-708 {{standard}} some encoders encode captions only on one frame type, such as only P frames, or only I frames, since {{if only one}} frame type is used, the <b>frame</b> <b>display</b> and <b>frame</b> encoded order are the same.|$|R
50|$|In {{analogue}} 49 additional lines without image content {{are added}} to the <b>displayed</b> <b>frame</b> of 576 lines to allow time for older cathode ray tube circuits to retrace for the next frame, giving 625 lines per frame. Digital information not to be displayed as part of the image can be transmitted in the non-displayed lines; teletext and other services and test signals are often implemented.|$|R
50|$|Markings {{and visual}} {{elements}} {{can be called}} chartjunk {{if they are not}} part of the minimum set of visuals necessary to communicate the information understandably. Examples of unnecessary elements that might be called chartjunk include heavy or dark grid lines, unnecessary text, inappropriately complex or gimmicky font faces, ornamented chart axes, and <b>display</b> <b>frames,</b> pictures, backgrounds or icons within data graphs, ornamental shading and unnecessary dimensions.|$|R
40|$|Display systems {{typically}} {{operate at}} a minimum rate of 60 Hz. However, existing VR-architectures generally produce application updates at a lower rate. Consequently, the display is not updated by the application every <b>display</b> <b>frame.</b> This causes a number of undesirable perceptual artifacts. We describe an architecture that provides a programmable display layer (PDL) in order to generate updated display frames. This replaces the default display behavior of repeating application frames until an update is available. We will show three benefits of the architecture typical to VR. First, smooth motion is provided by generating intermediate display frames by per-pixel depth-image warping using 3 D motion fields. Smooth motion eliminates various perceptual artifacts due to judder. Second, we implement fine-grained latency reduction at the <b>display</b> <b>frame</b> level using a synchronized prediction of simulation objects and the viewpoint. This improves the average quality and consistency of latency reduction. Third, a crosstalk reduction algorithm for consecutive display frames is implemented, which improves the quality of stereoscopic images. To evaluate the architecture, we compare image quality and latency {{to that of a}} classic level-of-detail approach...|$|E
40|$|The image {{compositing}} {{stages in}} cluster-parallel rendering for gathering and combining partial rendering results into a final <b>display</b> <b>frame</b> are fundamentally limited by node-to-node image throughput. Therefore, efficient image coding, compression and transmission {{must be considered}} to minimize that bottleneck. This paper studies the different performance limiting factors such as image representation, region-of-interest detection and fast image compression. Additionally, we show improved compositing performance using lossy YUV subsampling and we propose a novel fast region-of-interest detection algorithm that can improve in particular sort-last parallel rendering...|$|E
40|$|We {{developed}} a single-panel LCD microdisplay system using a field-sequential color (FSC) driving method and an organic light-emitting diode (OLED) as {{a backlight unit}} (BLU). The 0. 76 ′′ OLED BLU with red, green, and blue (RGB) colors was fabricated by a conventional UV photolithography patterning process and by vacuum deposition of small molecule organic layers. The field-sequential driving frequency was set to 255 [*]Hz to allow each of the RGB colors to be generated without color mixing at the given <b>display</b> <b>frame</b> rate. A prototype FSC LCD microdisplay system consisting of a 0. 7 ′′ LCD microdisplay panel and the 0. 76 ′′ OLED BLU successfully exhibited color display and moving picture images using the FSC driving method...|$|E
40|$|The newer {{active matrix}} display {{technologies}} such as TFT-LCD, DMD, PDP maintain their pixel values through the entire frame time, presenting a 100 % temporal fill factor, {{in contrast to the}} duty cycle produced by the phosphor impulse response of the CRT. This sample-and-hold characteristic can be exploited to lower the <b>displayed</b> <b>frame</b> rate without affecting visual quality. The lower frame rate results in significantly lower transmission bandwidth, power, and cost...|$|R
50|$|As the VBI will be {{generated}} {{at the start}} of every <b>displayed</b> <b>frame</b> (50 Hz for PAL, 60 Hz for NTSC), it is also a useful timebase in systems lacking an interrupt from a programmable or fixed interval timer. Regular software functions like scanning a keyboard, reading a joystick or maintaining a time or date measurement can be carried out. This {{can also be used to}} implement a basic form of multitasking.|$|R
30|$|On the decoder side, the {{incoming}} stream of video data is buffered in a source decoder buffer. Once the source decoder starts <b>displaying</b> the <b>frames,</b> the delay constraint becomes operational. If T denotes the upper bound for end-to-end delay of the system, a frame entering the encoder {{at time t}} must be displayed at the decoder at time (t+T), and all the video data corresponding to this particular frame must be available at the decoder accordingly. A video frame that {{is not able to}} meet its delay constraint is useless and is considered lost. We assume that the source decoder has knowledge of the frame numbers skipped by the source encoder and that it holds over the immediately preceding <b>displayed</b> <b>frame</b> and <b>displays</b> it in place of the skipped frame.|$|R
40|$|Background We have {{developed}} a digital display method that stabilizes the motion of a stenosis in sequential frames of a coronary angiogram, allowing it to be scrutinized at high <b>display</b> <b>frame</b> rates. The {{purpose of this study}} was to deter-mine whether this technique improves visual detection of low-contrast luminal morphological features. Methods and Results An observer detection study was con-ducted using computer-simulated arterial segments containing known target features, inserted into clinical digital coronary angiograms. Four observers performed a forced-choice detec-tion of a simulated filling defect in each of 320 angiograms using the conventional and stenosis-stabilized dynamic dis-plays (at 7. 5, 15, and 32 frames per second) and a single-frame static display (total of 8960 detections). In a second simulated clinical task, three observers detected a bridging stenoti...|$|E
40|$|When {{observations}} are made using uninhabited air vehicles (UAVs) a distinction {{can be made}} between human factors {{problems associated with the}} perceptual quality of the display and those associated with the searching of large spaces. This article summarises the findings of behavioural experiments that investigated both these domains, using a UAV simulator. Participants ’ performance when detecting targets improved when the <b>display</b> <b>frame</b> rate was reduced, meaning that performance improved when less information was transmitted from a UAV, and this finding was replicated under conditions when the images from the UAV were subject to a severe amount of jitter. In large spaces, active camera control (where a joystick was used to control the orientation of the cameras) allowed rapid searching, but at the expense of some accuracy. Training is required if operators are to exploit the full potential of such control systems. ...|$|E
40|$|Our {{vision is}} an {{environment}} that allows (ordinary) PC-clients to profit from a rich collection of multimedia programs such as selected TV channels, video on demand, teleported lectures etc. In this article, we present the design and implementation of a corresponding local infrastructure both from a hard- and software perspective. Innovation highlights are (a) a switch-based network with guaranteed transmission bandwidth for audio/video streams, built-in multicast support and globally accessible <b>display</b> <b>frame</b> buffers, (b) a system for the integrated display of remotely generated video streams at the client site and (c) a central server {{for the management of}} the available multimedia programs. Keywords: client/server multimedia system, quality of service, networked peripherals, Oberon. 1. Introduction Thanks to the power, versatility and low cost of today's personal computers multimedia has become an attractive and widespread field of application. The unique combination of high-quali [...] ...|$|E
50|$|Brossette, {{a sister}} company, is a {{finishing}} division for both {{indoor and outdoor}} <b>displays,</b> aluminium, <b>frames,</b> Light-Gauge Steel Trusses and pre-fabricated Structures.|$|R
50|$|A DynaScan 360 is a {{cylindrical}} LED display device, {{designed to}} minimize the number of light-emitting diodes used to <b>display</b> image <b>frames.</b>|$|R
40|$|This paper {{describes}} {{a method for}} enhancing the privacy of computer displays in public and semipublic areas. By operating the display at a higher-than-usual frame rate and alternately <b>displaying</b> <b>frames</b> of an arbitrary private image and a computed mask image, unauthorized viewers perceive one image, while authorized viewers with appropriately keyed shutterglasses see an entirely different (and private) image. Although the technique can be defeated, it provides a measure of privacy against casual and opportunistic privacy penetrations...|$|R
40|$|Conference paperTo {{bridge the}} {{mismatch}} between {{the sizes of}} images and display devices, we present an efficient and automatic algorithm to create an adaptive image representation called SmartNail. Given a digital image and rectangular <b>display</b> <b>frame</b> smaller than the image, we define the SmartNail as an appropriately cropped part of a suitably scaled-down image. We choose the SmartNail-defining parameters - down-scaling factor and cropping location - to maximize a bit-allocation-based cost function that quantifies the visual importance of the image content in the SmartNail. For JPEG 2000 -encoded images, the SmartNail parameters can be determined using just the header information available in the encoded file. Hence only the wavelet coefficients required to reconstruct the SmartNail need to be decoded from the entire JPEG 2000 code stream. Consequently, the SmartNail construction requires minimal computations and memory requirements. Simulations demonstrate the effectiveness of SmartNail representations...|$|E
40|$|In {{this paper}} {{we present a}} general {{technique}} for real-time display of very large models. We combine methods for culling and level-ofdetail management with wire-frame representations, generated dynamically from a hierarchy of bounding volumes. Smoothly moving boundary planes ensure that changes of representation do not lead to distracting popping effects. Context-sensitive landmark objects are added to support navigation, with a minimal impact on <b>display</b> <b>frame</b> rates. The method uses four dynamically-managed, overlapping zones to control level of detail. Results from user evaluation experiments are presented {{to demonstrate that the}} technique is effective for very large models on a modestly priced PC. 1 Introduction This paper describes a technique for real-time display of massive models. Although illustrated with respect to one particular application [...] process plant walk-through [...] the method is general, although its effectiveness will depend on the type of application. Process plants [...] ...|$|E
40|$|Dynamic {{viewpoint}} tethering is {{an innovative}} display technique {{which has been}} proposed to support effective navigation in large-scale virtual environments, by integrating information from different frames of reference. The present study examines the effect of dynamic viewpoint tethering on performance, with respect to both local guidance and global awareness measures, in comparison with three conventional display formats: egocentric, exocentric and rigidly tethered displays. Participants were instructed to control an aircraft-shaped cursor navigating in a virtual tunnel and {{to answer questions about}} the environment. The results confirmed that global awareness performance decreased with increased egocentricity in the <b>display</b> <b>frame</b> of reference. The two tethered displays (dynamic and rigid) supported the best local guidance performance. No significant performance {{differences were found between the}} two tethered displays. Key Words: Dynamically tethered displays, virtual environments, local guidance, global awareness, navigation, virtual cameras INTRODUCTION guidance concurrently. To achieve this goal, a tethered viewpoint has been proposed...|$|E
40|$|This {{dissertation}} {{addresses the}} problem of displaying live continuous media (e. g., digital audio and video) with low latency {{in the presence of}} delay jitter, where delay jitter is defined as variation in processing and transmission delay. Display in the presence of delay jitter requires a tradeoff between two goals: <b>displaying</b> <b>frames</b> with low latency and <b>displaying</b> every <b>frame.</b> Applications must choose a display latency that balances these goals. The driving problem for my work is workstation-based videoconferencing using conventional data networks. I propose a two-part approach. First, delay jitter at the source and destination should be controlled, leaving network transmission as the only uncontrolled source. Second, the remaining delay jitter should be accommodated by dynamically adjusting display latency in response to observed delay jitter. My thesis is that this approach is sufficient to support the low-latency display of continuous media transmitted over building-sized networks [...] ...|$|R
30|$|To {{exhibit the}} AR visual object, users can capture the video <b>frames</b> from the <b>display</b> monitor via digital camera or mobile phone. The camera {{normally}} can process and capture the <b>display</b> <b>frames</b> even the flicker frequency higher than 60  Hz. That is, a mobile camera can capture frames with an AR tag. However, human visual perception {{is incapable of}} distinguishing the embedded AR <b>frames</b> from the <b>display</b> monitor with higher than 60 -Hz flicker frequency. The phenomenon {{is based on the}} differences between the human eyes and the digital camera image formation.|$|R
50|$|Easel {{painting}} {{is a term}} in art history {{for the type of}} midsize painting that would have been painted on an easel, as opposed to a fresco wall painting, a large altarpiece or other piece that would have been painting resting on the floor, a small cabinet painting, or a miniature created sitting at a desk, though perhaps also on an angled support. It does not refer to the way the {{painting is}} meant to be displayed; most easel paintings are intended for <b>display</b> <b>framed</b> and hanging on a wall.|$|R
