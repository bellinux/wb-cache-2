586|918|Public
5000|$|Condition 2. The group <b>decision</b> <b>function</b> treats each voter identically. (anonymity) ...|$|E
50|$|Methods of {{constructing}} a <b>decision</b> <b>function</b> include themaximum likelihood rule, themaximum a posteriori rule, and theminimum distance rule.|$|E
5000|$|Condition 1. The group <b>decision</b> <b>function</b> sends {{each set}} of {{preferences}} to a unique winner. (resolute, unrestricted domain) ...|$|E
40|$|AbstractWe are {{interested}} in the formulation of multi-criteria <b>decision</b> <b>functions</b> based on the use of a measure over the space of criteria. Specifically the relationship between the criteria is expressed using a fuzzy measure. We then use the Choquet integral to construct <b>decision</b> <b>functions</b> based on the measure. We look at a number of different <b>decision</b> <b>functions</b> generated from specific classes of measure...|$|R
40|$|In both {{classical}} and Bayesian approaches, statistical inference is unified and generalized by the corresponding decision theory. This {{is not the}} case for the likelihood approach to statistical inference, in spite of the manifest success of the likelihood methods in statistics. The goal of the present work is to fill this gap, by extending the likelihood approach in order to cover decision making as well. The resulting <b>decision</b> <b>functions,</b> called likelihood <b>decision</b> <b>functions,</b> generalize the usual likelihood methods (such as ML estimators and LR tests), in the sense that these methods appear as the likelihood <b>decision</b> <b>functions</b> in particular <b>decision</b> problems. In general, the likelihood <b>decision</b> <b>functions</b> maintain some key properties of the usual likelihood methods, such as equivariance and asymptotic optimality. By unifying and generalizing the likelihood approach to statistical inference, the present work offers a new perspective on statistical methodology and on the connections among likelihood methods. ...|$|R
40|$|This thesis {{presents}} an adaptive technique that uses feedback to provide practical information during a planar near-field measurement scan. The feedback {{is used to}} decide with certainty when to terminate the planar near-field measurement process. The developed adaptive planar near-field method utilizes a rectangular spiral-type acquisition pattern to acquire the near-field measurements. At {{the end of each}} scan iteration, a set of <b>decision</b> <b>functions</b> are rapidly calculated which provide a quality measurement of the resulting far-zone transformation. The <b>decision</b> <b>functions</b> are based on the far-zone radiated patterns, directivity, and the fractional plane wave spectrum error. The <b>decision</b> <b>functions</b> were evaluated using actual planar near-field data set of five different antennas. These experiments have identified those <b>decision</b> <b>functions</b> that are directly related to antenna performance measures and would allow for the termination of the planar near-field test based on a set of relevant stopping conditions...|$|R
5000|$|The {{function}} [...] {{in these}} equations can be either the <b>decision</b> <b>function</b> of the classifier or its real-valued output.|$|E
5000|$|For a scalar {{parameter}} θ, a <b>decision</b> <b>function</b> whose output [...] is {{an estimate}} of θ, and a quadratic loss function ...|$|E
5000|$|Condition 3. The group <b>decision</b> <b>function</b> treats both {{outcomes}} the same, in that reversing {{each set}} of preferences reverses the group preference. (neutrality) ...|$|E
40|$|We {{develop a}} {{framework}} {{that allows us to}} emulate standard results from the “agreeing to disagree” literature with generalised <b>decision</b> <b>functions</b> (e. g. Bacharach (1985)) in a manner the avoids known incoherences pointed out by Moses and Nachum (1990). Avoiding the incoherences requires making some sacrifices: For example, we must require the <b>decision</b> <b>functions</b> to be independent of interactive information, and, the language in which the states are described must be “rich” - in some well-defined sense. Using weak additional assumptions, we also extend all previous results to allow agents to base their decisions on possibly false information. Finally, we provide agreement theorems in which the <b>decision</b> <b>functions</b> are not required to satisfy the Sure-Thing Principle (a central assumption in the standard results). ...|$|R
40|$|In this paper, we {{introduce}} {{the concept of}} stage-dependent <b>decision</b> <b>functions.</b> The latter exploit {{the improvement of the}} soft-decisions' reliability with increasing number of stages to take more hard-decisions and thus cancels more noise from stage to stage. We prove that if the stage-dependent thresholds can be optimized at each stage then the nonlinear SIC can approach the single user bound. Simulation results show significant BER improvement compared to the SIC using stage-independent <b>decision</b> <b>functions...</b>|$|R
40|$|This paper {{explores the}} {{possibility}} to replace the usual thresholding decision rule of log likelihood ratios used in speaker verification systems by more complex and discriminant <b>decision</b> <b>functions</b> based for instance on Linear Regression models or Support Vector Machines. Current speaker verification systems, based on generatire models such as HMMs or GMMs, can indeed easily be adapted to use such <b>decision</b> <b>functions.</b> Experiments on both text dependent and text independent tasks always yielded performance improvements and sometimes significantly...|$|R
50|$|Theorem: A group <b>decision</b> <b>function</b> with an {{odd number}} of voters meets {{conditions}} 1, 2, 3, and 4 {{if and only if}} it is the simple majority method.|$|E
5000|$|Bayesian {{approaches}} put priors on the kernel {{parameters and}} learn the parameter values from the priors and the base algorithm. For example, the <b>decision</b> <b>function</b> can be written as ...|$|E
50|$|The goal of {{the noisy}} channel model {{is to find the}} {{intended}} word given thescrambled word that was received. The <b>decision</b> <b>function</b> is a function that, given a scrambled word, returnsthe intended word.|$|E
5000|$|P. Faratin, C. Sierra and N. Jennings (1997): Negotiation <b>Decision</b> <b>Functions</b> for Autonomous Agents in Int. Journal of Robotics and Autonomous Systems, 24(3-4):159-182 ...|$|R
3000|$|... {{optimizations}} and obtains {{the same}} number of <b>decision</b> <b>functions</b> of the form (14). When given an example to predict, the algorithm proceeds by ballot: it evaluates the <b>decision</b> <b>functions</b> one by one on the example and adds a vote to the one category (out of two) in which it is predicted to be. At the end, the example is assigned to the category with the most votes; should there be a tie between two classes, the program arbitrarily selects that with the smallest label.|$|R
30|$|Originally, SVMs have {{essentially}} {{been developed for}} the two classes problems. However, several approaches {{can be used for}} extending SVMs to multi-class problems. The method we use in this communication, is called one against one. Instead of learning N <b>decision</b> <b>functions,</b> each class is discriminated here from another one. Thus, N(N- 1)/ 2 <b>decision</b> <b>functions</b> are learned and each of them makes a vote for the affectation of a new point x. The class of this point x becomes then to the majority class after the voting.|$|R
5000|$|It {{may include}} a Policy <b>Decision</b> <b>Function</b> (PDF), which authorizes media plane {{resources}} e.g., {{quality of service}} (QoS) over the media plane. It is used for policy control, bandwidth management, etc. The PDF {{can also be a}} separate function.|$|E
5000|$|ReLU is the {{abbreviation}} of Rectified Linear Units. This layer {{applies the}} non-saturating activation function [...] It increases the nonlinear {{properties of the}} <b>decision</b> <b>function</b> and of the overall network without affecting the receptive fields of the convolution layer.|$|E
5000|$|Note that [...] {{should be}} the [...] "raw" [...] output of the classifier's <b>decision</b> <b>function,</b> not the {{predicted}} class label. For instance, in linear SVMs, , where [...] are {{the parameters of the}} hyperplane and [...] is the point to classify.|$|E
40|$|In {{this paper}} we analyze the {{relationship}} between acyclic social <b>decision</b> <b>functions</b> and fixed agenda social choice correspondences which verify some rationality conditions (such as Pareto, independence, monotonicity or neutrality). This enables us to translate known sesults of monlotonicity or neutrality). This enables us to translate known sesults of existence of individuals with veto from the social <b>decision</b> <b>functions</b> context into the fixed agenda framework, such as t. hose of Blau anad Deb (1977), Blair and Pollak (1982),... Veto; Fixed Agenda SSC; Acyclic SDF...|$|R
40|$|In {{this paper}} we extend some recent results on an operatorial {{approach}} to the description of alliances between political parties interacting among themselves and with a basin of electors. In particular, we propose and compare three different models, deducing the dynamics of their related <b>decision</b> <b>functions,</b> i. e.  the attitude of each party to form or not an alliance. In the first model the interactions between each party and their electors are considered. We show that these interactions drive the <b>decision</b> <b>functions</b> toward certain asymptotic values depending on the electors only: {{this is the perfect}} party, which behaves following the electors’ suggestions. The second model is an extension of the first one in which we include a rule which modifies the status of the electors, and of the <b>decision</b> <b>functions</b> as a consequence, at some specific time step. In the third model we neglect the interactions with the electors while we consider cubic and quartic interactions between the parties and we show that we get (slightly oscillating) asymptotic values for the <b>decision</b> <b>functions,</b> close to their initial values. This is the real party, which does not listen to the electors. Several explicit situations are considered in details and numerical results are also shown. © 201...|$|R
40|$|This paper {{presents}} a new adaptive sampling technique {{for the construction}} of locally refined explicit <b>decision</b> <b>functions.</b> The <b>decision</b> <b>functions</b> can be used for both deterministic and probabilistic optimization, and may represent a constraint or a limit-state function. In particular, the focus of this paper is on reliability-based design optimization (RBDO). Instead of approximating the responses, the method is based on explicit design space decomposition (EDSD), in which an explicit boundary separating distinct regions in the design space is constructed. A statistical learning tool known as support vector machine (SVM) is used to construct the boundaries. A major advantage of using an EDSD-based method lies in its ability to handle discontinuous responses. A separate adaptive sampling scheme for calculating the probability of failure is also developed, which is used within the RBDO process. The update methodology is validated through several test examples with analytical <b>decision</b> <b>functions.</b> I...|$|R
5000|$|The {{parameterized}} {{joint distribution}} {{can be written}} as [...] by using the Chain rule. Each parameter vector [...] {{is associated with a}} <b>decision</b> <b>function</b> [...] The parameter is then chosen based on fit to both the labeled and unlabeled data, weighted by : ...|$|E
5000|$|The {{link between}} the two {{can be seen by}} observing that the <b>decision</b> <b>function</b> for naive Bayes (in the binary case) can be rewritten as [...] "predict class [...] if the odds of [...] exceed those of [...] ". Expressing this in log-space gives: ...|$|E
5000|$|... i.e., a {{logistic}} {{transformation of}} the classifier scores , where [...] and [...] are two scalar parameters that are learned by the algorithm. Note that predictions can now be made according to [...] iff if , the probability estimates contain a correction compared to the old <b>decision</b> <b>function</b> [...]|$|E
5000|$|As in Church encodings, {{there is}} no need for an IFTHENELSE {{function}} as one can just use raw -typed terms as <b>decision</b> <b>functions.</b> However, if one is requested: ...|$|R
40|$|Bayesian network {{classifiers}} are {{a powerful}} machine learning tool. In order {{to evaluate the}} expressive power of these models, we compute families of polynomials that sign-represent <b>decision</b> <b>functions</b> induced by Bayesian network classifiers. We prove that those families are linear combinations of products of Lagrange basis polynomials. In absence of V -structures in the predictor sub-graph, we are also able to prove that this family of polynomials does indeed characterize the specific classifier considered. We then use this representation to bound the number of <b>decision</b> <b>functions</b> representable by Bayesian network classifiers with a given structure...|$|R
40|$|Support vector {{machines}} (SVM's) construct <b>decision</b> <b>functions</b> {{that are}} linear combinations of kernel evaluations on the training set. The samples with non-vanishing coefficients are called support vectors. In this work we establish lower (asymptotical) bounds {{on the number}} of support vectors. On our way we prove several results which are of great importance for the understanding of SVM's. In particular, we describe to which "limit" SVM <b>decision</b> <b>functions</b> tend, discuss the corresponding notion of convergence and provide some results on the stability of SVM's using subdifferential calculus in the associated reproducing kernel Hilbert space...|$|R
50|$|The {{final step}} in object {{recognition}} using histogram of oriented gradient descriptors is {{to feed the}} descriptors into some recognition system based on supervised learning. The support vector machine (SVM) classifier is a binary classifier which looks for an optimal hyperplane as a <b>decision</b> <b>function.</b> Once trained on images containing some particular object, the SVM classifier can make decisions regarding {{the presence of an}} object, such as a human, in additional test images.|$|E
5000|$|Semisupervised {{learning}} {{approaches to}} multiple kernel learning {{are similar to}} other extensions of supervised learning approaches. An inductive procedure has been developed that uses a log-likelihood empirical loss and group LASSO regularization with conditional expectation consensus on unlabeled data for image categorization. We can define the problem as follows. Let [...] be the labeled data, and let [...] be the set of unlabeled data. Then, we can write the <b>decision</b> <b>function</b> as follows.|$|E
5000|$|One {{problem with}} the kernel perceptron, as {{presented}} above, {{is that it does}} not learn sparse kernel machines. Initially, all the [...] are zero so that evaluating the <b>decision</b> <b>function</b> to get [...] requires no kernel evaluations at all, but each update increments a single , making the evaluation increasingly more costly. Moreover, when the kernel perceptron is used in an online setting, the number of non-zero [...] and thus the evaluation cost grow linearly in the number of examples presented to the algorithm.|$|E
40|$|AbstractWe are {{concerned}} with the problem of uncertain decision making. The paradigm of decision making using minimization of maximal regret (MMR) is introduced. We compare this technique with the classic Max–Min valuation method of decision making. We discuss a generalization of the MMR method leading to a parameterized family of minimal regret methods. We study this class in detail. An approach to decision making which combines valuation type <b>decision</b> <b>functions</b> with regret based <b>decision</b> <b>functions</b> is introduced. We apply the minimal regret method of decision making to situations in which our uncertainty profile is represented by a Dempster–Shafer belief structure...|$|R
50|$|There {{are also}} tools that {{generate}} EPC diagrams from operational data, such as SAP logs. EPC diagrams use symbols of several kinds {{to show the}} control flow structure (sequence of <b>decisions,</b> <b>functions,</b> events, and other elements) of a business process.|$|R
40|$|Following from Tarbush (2011 a), {{we explore}} the {{implications}} of using two different definitions of informativeness over kens; one that ranks objective, and the other subjective information. With the first, we create a new semantic operation {{that allows us to}} derive agreement theorems even when <b>decision</b> <b>functions</b> are based on interactive information (for any r ≥ 0). Effectively, this operation, unlike information cell union captures the notion of an agent becoming “more ignorant” for all modal depths. Using the definition that ranks subjective information however, we show an impossibility result: In generic models, agreement theorems using the standard Sure-Thing Principle do not hold when <b>decision</b> <b>functions</b> depend on interactive information (when r > 0). ...|$|R
