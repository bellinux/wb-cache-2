10000|10000|Public
25|$|The November main analysis, {{which showed}} an early arrival time of 57.8nanoseconds, was {{conducted}} blind to avoid observer bias, whereby those running the analysis might inadvertently fine-tune the result toward expected values. To this end, old and incomplete values for distances and delays {{from the year}} 2006 were initially adopted. With the final correction needed not yet known, the intermediate expected result was also an unknown. Analysis of the measurement data under those 'blind' conditions gave an early neutrino arrival of 1043.4nanoseconds. Afterward, the <b>data</b> <b>were</b> <b>analyzed</b> again taking into consideration the complete and actual sources of errors. If neutrino and light speed were the same, a subtraction value of 1043.4nanoseconds should have been obtained for the correction. However, the actual subtraction value amounted to only 985.6nanoseconds, corresponding to an arrival time 57.8nanoseconds earlier than expected.|$|E
25|$|Early visual {{observations}} {{contributing to}} the phase curve of Mercury were obtained by G. Muller in the 1800s and by André-Louis Danjon in the mid-twentieth century. W. Irvine and colleagues used photoelectric photometry in the 1960s. Some of these early <b>data</b> <b>were</b> <b>analyzed</b> by G. de Vaucouleurs, summarized by D. Harris and used for predicting apparent magnitudes in the Astronomical Almanac for several decades. Highly accurate new observations covering the widest range of phase angles to date (2 to 170°) were carried out by A. Mallama, D. Wang and R. Howard using the Large Angle and Spectrometric Coronograph (LASCO) on the Solar and Heliospheric Observatory (SOHO) satellite. They also obtained new CCD observations from the ground. These data are now {{the major source of}} the phase curve used in the Astronomical Almanac for predicting apparent magnitudes.|$|E
5000|$|A {{very small}} data set (Table 1) {{illustrates}} {{the operation and}} outputs of the FAMD [...] Six individuals are described by three quantitative variables and three qualitatives variables. <b>Data</b> <b>were</b> <b>analyzed</b> using the R package function FAMD FactoMineR [...]|$|E
30|$|This study {{collected}} and analyzed both {{quantitative and qualitative}} <b>data.</b> Quantitative <b>data</b> <b>was</b> <b>analyzed</b> using descriptive statistics, multiple regressions, and Pearson's correlation coefficient (r). Qualitative <b>data</b> <b>was</b> <b>analyzed</b> using content analysis.|$|R
30|$|<b>Data</b> <b>was</b> <b>analyzed</b> using SPSS v. 17.|$|R
30|$|<b>Data</b> <b>was</b> <b>analyzed</b> using SPSS for MAC OS version 20.|$|R
50|$|In 2008, funding {{data was}} {{obtained}} by the Center for Public Integrity from PEPFAR's own information system COPRS. The data were obtained after CPI sued the U.S. State Department {{to gain access to}} the data. The <b>data</b> <b>were</b> <b>analyzed</b> by the HIV/AIDS Monitor team at the Center for Global Development, who also share the full dataset.|$|E
5000|$|In 1968, {{the group}} of Alvarez used spark {{chambers}} with a digital read out for their Pyramid experiment. Tracking data from the apparatus was onto magnetic tape in the Belzoni Chamber, then the <b>data</b> <b>were</b> <b>analyzed</b> by the IBM 1130 computer, and later by the CDC 6600 computer located at Ein Shams University and Lawrence Radiation Laboratory, respectively. [...] Strictly speaking these were not real time measurements.|$|E
5000|$|To {{determine}} {{the factor structure}} of the SAS at the culture level Bond, Leung et. al. (2004) collected and analyzed SAS scores from 41 cultures. The <b>data</b> <b>were</b> <b>analyzed</b> at both the individual and country level. While the individual data yielded the expected five-factor structure, the country-level analysis yielded only a two-factor solution. Almost all items in one factor are contained in the original factor Social cynicism, so the factor was named Societal cynicism. The other factor contains items from the other four original factors. It was named Dynamic externality, combining both the [...] "external" [...] aspects of religiosity and fate control, and the [...] "dynamic" [...] aspects of Reward for application. Only one item from Social complexity appeared.|$|E
30|$|After {{collecting}} relevant data {{using the}} topic-filtered web harvesting, the <b>data</b> <b>is</b> <b>analyzed.</b> The {{first part of}} the analysis is to identify all aliases that are present in the collected data. Thereafter the <b>data</b> <b>is</b> <b>analyzed</b> using techniques described in the previous section while searching for indicators for intent of committing an act of terror.|$|R
50|$|<b>Data</b> <b>is</b> <b>analyzed</b> after testing <b>is</b> complete. This {{analysis}} is called performance evaluation.|$|R
5000|$|... <b>data</b> <b>are</b> <b>analyzed</b> and <b>are</b> interesting, {{but are not}} {{presented}} to decision makers; ...|$|R
50|$|The <b>data</b> <b>were</b> <b>analyzed</b> {{separately}} for Hong Kong and Venezuela using cluster analysis {{as well as}} exploratory factor analysis and confirmatory factor analysis {{to see if there}} were patterns of relationship among the beliefs within each culture. The analysis pointed to a five factor solution - five clusters of beliefs that seem to be interrelated. The five factors overlapped substantially between the Hong Kong and Venezuelan samples, indicating that they were valid for both cultures. For a second analysis, the scores from both cultures were combined, and principal components analysis was used. Five factors were again obtained. The survey was shortened by eliminating items that had low factor loadings or were inconsistent with the meaning of their factors, resulting in a final survey of 60 questions.|$|E
50|$|A set of {{assembled}} transcripts {{allows for}} initial gene expression studies. Prior {{to the development}} of transcriptome assembly computer programs, transcriptome <b>data</b> <b>were</b> <b>analyzed</b> primarily by mapping on to a reference genome. Though genome alignment is a robust way of characterizing transcript sequences, this method is disadvantaged by its inability to account for incidents of structural alterations of mRNA transcripts, such as alternative splicing. Since a genome contains the sum of all introns and exons that may be present in a transcript, spliced variants that do not align continuously along the genome may be discounted as actual protein isoforms. Even if a reference genome is available, de novo assembly should be performed, as it can recover transcripts that are transcribed from segments of the genome that are missing from the genome assembly.|$|E
50|$|In March 1949, the Operational Service (OS) is constituted, {{this being}} the first {{designation}} of the prison Security (Securitate), on the initiative of Gheorghe Pintilie, head of the Securitate. Its first commander was Iosif Nemeș. The Operational Service was subordinated to the Securitate, {{and not to the}} General Penitenciary Directorate(GPD). The GPD was handling the administrative responsibilities, under direct watch of the Securitate, while the OS was responsible with gathering intelligence from the political prisoners. After the entire intelligence structure was completed, the information flow was as follows: once retrieved from the informants, it reached the political officer of the incarceration unit, who personally handed them {{to the head of the}} OS. The <b>data</b> <b>were</b> <b>analyzed</b> and the summary, together with the original files, were handed over to the Securitate.|$|E
30|$|In this section, {{in order}} to apply the {{established}} framework, China’s provincial-level IO <b>data</b> <b>are</b> <b>analyzed.</b>|$|R
30|$|<b>Data</b> <b>was</b> <b>analyzed</b> using R® {{statistical}} software with the nparLD, nparcomp, and COIN packages (Version 3.1. 3.).|$|R
5000|$|... <b>data</b> <b>are</b> <b>analyzed</b> and presented, but are {{not used}} for {{decision-making}} because of internal or external factors ...|$|R
50|$|Early visual {{observations}} {{contributing to}} the phase curve of Mercury were obtained by G. Muller in the 1800s and by André-Louis Danjon in the mid-twentieth century. W. Irvine and colleagues used photoelectric photometry in the 1960s. Some of these early <b>data</b> <b>were</b> <b>analyzed</b> by G. de Vaucouleurs, summarized by D. Harris and used for predicting apparent magnitudes in the Astronomical Almanac for several decades. Highly accurate new observations covering the widest range of phase angles to date (2 to 170°) were carried out by A. Mallama, D. Wang and R. Howard using the Large Angle and Spectrometric Coronograph (LASCO) on the Solar and Heliospheric Observatory (SOHO) satellite. They also obtained new CCD observations from the ground. These data are now {{the major source of}} the phase curve used in the Astronomical Almanac for predicting apparent magnitudes.|$|E
50|$|The November main analysis, {{which showed}} an early arrival time of 57.8 nanoseconds, was {{conducted}} blind to avoid observer bias, whereby those running the analysis might inadvertently fine-tune the result toward expected values. To this end, old and incomplete values for distances and delays {{from the year}} 2006 were initially adopted. With the final correction needed not yet known, the intermediate expected result was also an unknown. Analysis of the measurement data under those 'blind' conditions gave an early neutrino arrival of 1043.4 nanoseconds. Afterward, the <b>data</b> <b>were</b> <b>analyzed</b> again taking into consideration the complete and actual sources of errors. If neutrino and light speed were the same, a subtraction value of 1043.4 nanoseconds should have been obtained for the correction. However, the actual subtraction value amounted to only 985.6 nanoseconds, corresponding to an arrival time 57.8 nanoseconds earlier than expected.|$|E
30|$|<b>Data</b> <b>were</b> <b>analyzed</b> using SPSS for Windows (SPSS 17.0; SPSS, Inc. Chicago, IL, USA). All {{statistical}} {{tests were}} performed two-sided, with 5 % significance level. Normally distributed continuous <b>data</b> <b>were</b> <b>analyzed</b> using a two-sided independent samples Student’s t test and, when paired, the paired samples t test. Categorical <b>data</b> <b>were</b> <b>analyzed</b> using Pearson’s chi-square test.|$|E
30|$|The <b>data</b> <b>was</b> <b>analyzed</b> {{using the}} R {{software}} version 3.2. 2 (R Core Team, 2015) on Linux/Ubuntu 12.04.|$|R
5000|$|... "The structuring, staffing, {{and funding}} of the {{processes}} by which our raw intelligence <b>data</b> <b>are</b> <b>analyzed</b> and interpreted." ...|$|R
30|$|The {{experimental}} <b>data</b> <b>was</b> <b>analyzed</b> using SPSS software, {{tested with}} F-test means. Results were compared based on Duncan method (L.S.R).|$|R
30|$|Categorical <b>data</b> <b>were</b> <b>analyzed</b> with {{chi-square}} test, {{and continuous}} <b>data</b> <b>were</b> <b>analyzed</b> with the Mann-Whitney test for two independent groups. P < 0.05 {{was used to}} indicate statistical significance.|$|E
30|$|The qualitatively derived <b>data</b> <b>were</b> <b>analyzed</b> thematically. The {{summary of}} {{findings}} {{is presented in}} the tables. Quantitatively derived <b>data</b> <b>were</b> <b>analyzed</b> using descriptive statistics and are presented in graphs.|$|E
30|$|SPSS {{was used}} for the {{statistics}} analysis. Categorical <b>data</b> <b>were</b> <b>analyzed</b> with the Chi-square test. Continuous <b>data</b> <b>were</b> <b>analyzed</b> using the t-test. Differences were considered to be significant when the P-value was below 0.05.|$|E
30|$|Time-varying bicoherence {{obtained}} on the <b>data</b> <b>is</b> <b>analyzed</b> at different frequencies and over different channels {{and as a}} function of time.|$|R
30|$|First, {{classified}} <b>data</b> <b>was</b> <b>analyzed</b> {{using the}} PCA algorithm and features with low discriminations were eliminated {{to accelerate the}} detection process.|$|R
3000|$|This <b>data</b> <b>was</b> <b>analyzed</b> by Halloran et al. ([2003]) and Chu and Halloran ([2004]). Assuming {{the binary}} {{probability}} model for P [...]...|$|R
30|$|<b>Data</b> <b>were</b> <b>analyzed</b> {{statistically}} following ANOVA technique using Minitab 16.0 software. Significant variations and comparisons among <b>data</b> <b>were</b> <b>analyzed</b> through ANOVA (Fisher’s test) and paired t test. Other {{calculations and}} graphs were prepared using Microsoft Excel 2010.|$|E
30|$|SPSS 22.0 {{software}} (IBM, NY) {{was used}} for data analysis. All the data were expressed as mean[*]±[*]standard deviation (SD). Quantitative <b>data</b> <b>were</b> <b>analyzed</b> by independent-samples Student t test. Non-parametric <b>data</b> <b>were</b> <b>analyzed</b> by Mann-Whitney U test. Qualitative <b>data</b> <b>were</b> <b>analyzed</b> by chi-square test. Receiver operating curve (ROC) was {{used to calculate the}} optimal cutoff values with their respective sensitivity, specificity, accuracy, positive predictive value (PPV), negative predictive value (NPV) and area under curve (AUC). Significance level value was set at p[*]<[*] 0.05.|$|E
40|$| the {{obtained}} <b>data</b> <b>were</b> <b>analyzed</b> by Fisher|$|E
3000|$|The <b>data</b> <b>was</b> <b>analyzed</b> by the {{software}} of Statistical Product and Service Solution (SPSS) {{which can be}} used to do correlation analysis and cluster analysis. Through the K-S test by SPSS, most of the indexes indicated the expression levels in this study conform to a skewed distribution. The expression <b>data</b> distribution <b>was</b> <b>analyzed</b> by GraphPad Prism.|$|R
30|$|The <b>data</b> <b>was</b> <b>analyzed</b> using simple {{descriptive}} statistics {{derive from the}} information about the mean of the infestation level and prevalence percentage of infected animals.|$|R
30|$|All {{parameters}} and experimental results were obtained with means[*]±[*]SD of parallel tests. The <b>data</b> <b>was</b> <b>analyzed</b> by Statistix 9.0 software (Analytical Software, Tallahassee, FL, USA).|$|R
