211|3488|Public
2500|$|For example, , is a {{well-formed formula}} of second-order {{arithmetic}} that is arithmetical, has one free set variable X and one bound <b>individual</b> <b>variable</b> n (but no bound set variables, as {{is required of}} an arithmetical formula)mdash&whereas [...] is a well-formed formula that is not arithmetical, having one bound set variable X and one bound <b>individual</b> <b>variable</b> n.|$|E
2500|$|A {{formula is}} called bounded arithmetical, or Δ00, when all its quantifiers {{are of the}} form ∀n<t or ∃n<t (where n is the <b>individual</b> <b>variable</b> being {{quantified}} and t is an individual term), where ...|$|E
2500|$|A {{formula is}} called Σ01 (or {{sometimes}} Σ1), respectively Π01 (or sometimes Π1) when it {{of the form}} ∃m•(φ), respectively ∀m•(φ) where φ is a bounded arithmetical formula and m is an <b>individual</b> <b>variable</b> (that is free in φ). [...] More generally, a formula is called Σ0n, respectively Π0n when it is obtained by adding existential, respectively universal, individual quantifiers to a Π0n1, respectively Σ0n1 formula (and Σ00 and Π00 are all equivalent to Δ00). [...] By construction, all these formulas are arithmetical (no class variables are ever bound) and, in fact, by putting the formula in Skolem prenex form one can see that every arithmetical formula is equivalent to a Σ0n or Π0n formula for all large enough n.|$|E
40|$|Researchers often predict {{individual}} behavior using {{a combination}} of <b>individual</b> and aggregate <b>variables</b> (e. g., zip code means). We show that in a linear model coefficients associated with <b>individual</b> <b>variables</b> will be inconsistently estimated if those variables are correlated with the underlying <b>individual</b> <b>variables</b> summarized to obtain the aggregate group means. Consistent estimates can be obtained if the group means are conditioned on observed <b>individual</b> <b>variables.</b> We introduce an approach to infer group level joint distributions to obtain such conditional estimates. The approach is illustrated in an application predicting the profitability of a bank’s customers...|$|R
30|$|In theory, the <b>individual</b> <b>variables</b> of {{the index}} could receive a {{different}} weight according to their relevance for overall richness of habitats and associated species. Here, the index was calculated with unweighted variables because we had no prior information whether <b>individual</b> <b>variables</b> of forest structure {{were more or less}} important than others, e.g. for species richness within certain taxonomic groups. To test whether the assignment of different weightings to <b>individual</b> <b>variables</b> has a significant influence on the distribution of index values across inventory plots, a sensitivity analysis was performed, using for each variable random weightings between 0 and 2, which were repeated 100, 000 times.|$|R
40|$|It is {{in general}} {{challenging}} to provide confidence intervals for <b>individual</b> <b>variables</b> in high-dimensional regression without making strict or unverifiable assumptions {{on the design}} matrix. We show here that a "group-bound" confidence interval can be derived without making any assumptions on the design matrix. The lower bound for the regression coefficient of <b>individual</b> <b>variables</b> can be derived via linear programming. The idea also generalises naturally to groups of variables, where we can derive a one-sided confidence interval for the joint effect of a group. While the confidence intervals of <b>individual</b> <b>variables</b> are {{by the nature of}} the problem often very wide, it is shown to be possible to detect the contribution of groups of highly correlated predictor variables even when no variable individually shows a significant effect. The assumptions necessary to detect the effect of groups of variables are shown to be weaker than the weakest known assumptions to detect the effect of <b>individual</b> <b>variables.</b> Comment: 24 pages, 3 figure...|$|R
5000|$|For example, , is a {{well-formed formula}} of second-order {{arithmetic}} that is arithmetical, has one free set variable X and one bound <b>individual</b> <b>variable</b> n (but no bound set variables, as {{is required of}} an arithmetical formula) - whereas [...] is a well-formed formula that is not arithmetical, having one bound set variable X and one bound <b>individual</b> <b>variable</b> n.|$|E
5000|$|On Formulas {{in which}} no <b>Individual</b> <b>Variable</b> occurs more than Twice, Journal of Symbolic Logic, 31, 1966, pp. 1-6) ...|$|E
5000|$|This type of idol {{stems from}} the {{particular}} life experiences of the <b>individual.</b> <b>Variable</b> educations can lead the individual to a preference for specific concepts or methods, which then corrupt their subsequent philosophies. Bacon himself gives the example of Aristotle, [...] "who made his natural philosophy a mere slave to his logic". (Aphorism 54.) ...|$|E
30|$|The {{detailed}} income decompositions allow further decomposing {{the overall}} gaps just established into the <b>individual</b> explanatory <b>variables</b> from the Mincer income regressions, discussed earlier. To help better facilitate interpretation, however, results {{are reported in}} groups of <b>individual</b> <b>variables</b> (e.g., aggregating up the contribution from all the ownership variables).|$|R
30|$|Here, {{we focus}} on a single factor {{sensitivity}} analysis to study how the variation (uncertainty) in <b>individual</b> <b>variables</b> affects {{the performance of the}} model.|$|R
30|$|While {{the overall}} {{earnings}} decompositions {{examined in the}} previous section already add to the story {{about the nature of the}} formal-informal sector gap in Serbia established in its “raw” form in Table  8, additional insights may be had from going one step further and additionally decomposing these overall decompositions into the contribution coming from the <b>individual</b> explanatory <b>variables</b> from the Mincer earnings regressions—which, again, can be done both for the two- and three-fold decompositions. To help better facilitate interpretation, however, results are reported in groups of <b>individual</b> <b>variables</b> (for example, aggregating up the contribution from all the education variables) rather than separately for all the <b>individual</b> <b>variables</b> (for example, for each educational level).|$|R
50|$|In {{mathematics}} and logic, plural quantification is {{the theory that}} an <b>individual</b> <b>variable</b> x may take on plural, as well as singular, values. As well as substituting individual objects such as Alice, the number 1, the tallest building in London etc. for x, we may substitute both Alice and Bob, or all the numbers between 0 and 10, or all the buildings in London over 20 stories.|$|E
5000|$|A Segregated Fund or Seg Fund {{is a type}} of {{investment}} fund administered by Canadian insurance companies in the form of <b>individual,</b> <b>variable</b> life insurance contracts offering certain guarantees to the policyholder such as reimbursement of capital upon death. As required by law, these funds are fully segregated from the company's general investment funds, hence the eponym. A segregated fund is synonymous with the U.S. insurance industry [...] "separate account" [...] and related insurance and annuity products.|$|E
5000|$|Social drives ({{affiliation}}). The {{demand for}} affiliation is an <b>individual</b> <b>variable</b> and adjusted through early experiences. It {{needs to be}} satisfied in regular intervals by external legitimacy signals (provided by other agents as a signal of acceptance and/or gratification) or internal legitimacy signals (created by the fulfillment of social norms). It is increased by social frustration (anti-legitimacy signals) or supplicative signals (demands of other agents for help, which create both a suffering by frustration of the affiliation urge, and a promise of gratification).|$|E
3000|$|... 41 Compared to {{aggregate}} controls, individual controls play a minor role since they alleviate {{the problem of}} omitted <b>individual</b> <b>variables,</b> which is anyway tackled by IV.|$|R
50|$|Interaction between adding {{sugar to}} coffee and {{stirring}} the coffee. Neither {{of the two}} <b>individual</b> <b>variables</b> has much effect on sweetness but {{a combination of the}} two does.|$|R
40|$|The road {{improvement}} prioritizing system currently utilized by the Virginia Department of Transportation {{is similar to}} the method utilized by many states: it is a sufficiency rating system that evaluates proposed projects on the basis of points assigned for a number of variables. Although this type of system is commonly used, it has several limitations, including its lack of sensitivity to <b>individual</b> <b>variables,</b> the difficulty in assigning and interpreting a point total based on multiple heterogeneous variables, and the rigidity of the system after the point structure is established. In this report, an alternative method is introduced that consists of sorting projects in sequential ranking steps based on ranges of <b>individual</b> <b>variables.</b> The proposed method is simpler, more flexible, and requires less data manipulation than the present rating system. <b>Individual</b> <b>variables</b> have greater impact on the prioritizing process, and the resulting prioritizing ratings correlate well with results obtained from the previous rating method. 17. Key Worda Prioritizing, planning, administratio...|$|R
50|$|If X is one-dimensional, {{a partial}} {{sweeping}} replaces {{the variance of}} X by its negative inverse and multiplies the inverse with other elements. If X is multidimensional, the operation involves the inverse of the covariance matrix of X and other multiplications. A swept matrix obtained from a partial sweeping on a subset of variables can be equivalently obtained by a sequence of partial sweepings on each <b>individual</b> <b>variable</b> in the subset and {{the order of the}} sequence does not matter. Similarly, a fully swept matrix is the result of partial sweepings on all variables.|$|E
50|$|This was {{the engine}} in six-cylinder {{variants}} of the BA Falcon/XT/Futura, Xr6, Fairmont/Ghia, Fairlane, and Territory SUV and were produced between late 2002 and mid-2005. This {{was the first}} Falcon engine that came standard with DOHC and dual <b>individual</b> <b>variable</b> cam timing. This contributed to the significant jump in output over the base 157 kW SOHC Intech engine in the previous generation AU Falcon and a 11 kW gain over the Tickford enhanced VCT motor's 171kw. It also kept Ford's engine ahead of the low powered Holden Ecotec and L67 supercharged motors found in the contemporary Commodore.|$|E
50|$|A {{formula is}} called Σ01 (or {{sometimes}} Σ1), respectively Π01 (or sometimes Π1) when it {{of the form}} ∃m•(φ), respectively ∀m•(φ) where φ is a bounded arithmetical formula and m is an <b>individual</b> <b>variable</b> (that is free in φ). More generally, a formula is called Σ0n, respectively Π0n when it is obtained by adding existential, respectively universal, individual quantifiers to a Π0n&minus;1, respectively Σ0n&minus;1 formula (and Σ00 and Π00 are all equivalent to Δ00). By construction, all these formulas are arithmetical (no class variables are ever bound) and, in fact, by putting the formula in Skolem prenex form one can see that every arithmetical formula is equivalent to a Σ0n or Π0n formula for all large enough n.|$|E
50|$|Ecological fallacy {{can refer}} to the {{following}} statistical fallacy: the correlation between <b>individual</b> <b>variables</b> is deduced from the correlation of the variables collected for the group to which those individuals belong.|$|R
40|$|We propose an {{approach}} for dependence tree structure learning via copula. A nonparametric algorithm for copula estimation is presented. Then a Chow-Liu like method based on dependence measure via copula is proposed to estimate maximum spanning bivariate copula associated with bivariate dependence relations. The main {{advantage of the}} approach is that learning with empirical copula focuses on dependence relations among random variables, without the {{need to know the}} properties of <b>individual</b> <b>variables</b> as well as without the requirement to specify parametric family of entire underlying distribution for <b>individual</b> <b>variables.</b> Experiments on two real-application data sets show the effectiveness of the proposed method...|$|R
5000|$|... {{the result}} is logically {{equivalent}} to what you started with. Repeated application of De Morgan's theorem to parts of a function {{can be used to}} drive all complements down to the <b>individual</b> <b>variables.</b>|$|R
3000|$|..., {{where an}} <b>individual</b> <b>variable</b> is {{introduced}} for every considered modality. More specifically, random variable CL [...]...|$|E
40|$|In {{multiple}} regression problems when covariates can be naturally grouped, {{it is important}} to carry out feature selection at the group and within-group <b>individual</b> <b>variable</b> levels simultaneously. The existing methods, including the lasso and group lasso, are designed for either variable selection or group selection, but not for both. We propose a group bridge approach that is capable of simultaneous selection at both the group and within-group <b>individual</b> <b>variable</b> levels. The proposed approach is a penalized regularization method that uses a specially designed group bridge penalty. It has the oracle group selection property, in that it can correctly select important groups with probability converging to one. In contrast, the group lasso and group least angle regression methods in general do not possess such an oracle property in group selection. Simulation studies indicate that the group bridge has superior performance in group and <b>individual</b> <b>variable</b> selection relative to several existing methods. Copyright 2009, Oxford University Press. ...|$|E
40|$|A {{randomization}} {{method for}} the assessment of statistical significance for best subsets regression is given. The procedure takes into account the number of potential predictors and the inter-dependence between predictors. The approach corrects a non-trivial problem with Type I errors and can be used to assess <b>individual</b> <b>variable</b> significance...|$|E
25|$|Two {{other common}} {{interpretation}}s of the values are true or false and yes or no. Under any interpretation of the two values, the <b>individual</b> <b>variables</b> X'i may be called Bernoulli trials with parameter p.|$|R
3000|$|The {{lowest level}} of {{validity}} and a minimum requirement for data fusion is that the marginal distributions of the <b>individual</b> <b>variables</b> in the original surveys be preserved after the statistical match. Formally, if [...]...|$|R
50|$|Two {{other common}} {{interpretation}}s of the values are true or false and yes or no. Under any interpretation of the two values, the <b>individual</b> <b>variables</b> Xi may be called Bernoulli trials with parameter p.|$|R
40|$|In this article, {{we propose}} a {{variable}} selection {{approach in the}} Cox model {{when there is a}} group structure in a diverging number of covariates. Most of the existing variable selection methods are designed for either <b>individual</b> <b>variable</b> selection or group selection, but not for both. The proposed methods are capable of simultaneous group selection and <b>individual</b> <b>variable</b> selection within selected groups. Computational algorithms are developed for the proposed bi-level selection methods, and the properties of the proposed selection methods are established. The proposed group bridge penalized methods are able to correctly select the important groups and variables simultaneously with high probability in sparse models. Simulation studies indicate that the proposed methods work well and two examples are provided to illustrate the applications of the proposed methods to scientific problems. Department of Applied Mathematic...|$|E
3000|$|... 0, {{that is the}} {{unemployment}} rate at graduation affects early non-employment but {{not the other way}} around. We exclude the possibility of reverse causality since the instrument and the endogenous regressor are measured at the provincial and individual level, respectively, and an aggregate variable cannot be caused by an <b>individual</b> <b>variable.</b>|$|E
40|$|In article the {{algorithm}} of power (active/reactive) distribution between generating aggregates and optimal operating equipment selection (considering spinning reserve) is proposed. The algorithm realization is performed {{for the time}} period where were given load values on the nodes, {{and is based on}} <b>individual</b> <b>variable</b> variation. As criteria of optimization task we use profit maximization function...|$|E
5000|$|... {{in such a}} {{way that}} the <b>individual</b> <b>variables</b> of t {{considered}} over the data set successively inherit the maximum possible variance from x, with each loading vector w constrained to be a unit vector.|$|R
30|$|The {{reason of}} using factor {{analysis}} with special transformation {{is that this}} procedure makes possible to determine the weight and the rank of importance of the <b>individual</b> <b>variables</b> influencing the target variable, namely the current daily pollen counts. At the same time, when using autocorrelation, time dependent associations with the target variable can be determined; however, {{the weight of the}} <b>individual</b> influencing <b>variables</b> in the current pollen counts cannot be specified.|$|R
40|$|A {{frequently}} encountered {{challenge in}} high-dimensional regression is {{the detection of}} relevant variables. Variable selection suffers from instability {{and the power to}} detect relevant variables is typically low if predictor variables are highly correlated. When taking the multiplicity of the testing problem into account, the power diminishes even further. To gain power and insight, it can be advantageous to look for influence not at the level of <b>individual</b> <b>variables</b> but rather at the level of clusters of highly correlated variables. We propose a hierarchical approach. Variable importance is first tested at the coarsest level, corresponding to the global null hypothesis. If possible, the method tries then to attribute any effect to smaller sub-clusters or even <b>individual</b> <b>variables.</b> The smallest possible clusters which still exhibit a significant influence on the response variable are retained. It is shown that the proposed testing procedure controls the family-wise error rate at a prespecified level, simultaneously over all resolution levels. The method has comparable power to Bonferroni-Holm on the level of <b>individual</b> <b>variables</b> and dramatically larger power for coarser resolution levels. The best resolution level is selected adaptively...|$|R
