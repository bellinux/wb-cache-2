38|9776|Public
25|$|In 2009, the third-generation Cirrus SR22 GTS came {{equipped}} with a new <b>enhanced</b> <b>vision</b> <b>system</b> (EVS), a sophisticated dual-wavelength instrument that offers both infrared and synthetic vision.|$|E
5000|$|... 2004 - Gulfstream Aerospace for the {{development}} of the G550, the first civil aircraft to include an <b>enhanced</b> <b>vision</b> <b>system</b> as standard equipment.|$|E
50|$|In 2009, the third-generation Cirrus SR22 GTS came {{equipped}} with a new <b>enhanced</b> <b>vision</b> <b>system</b> (EVS), a sophisticated dual-wavelength instrument that offers both infrared and synthetic vision.|$|E
50|$|Modern glass cockpits {{might include}} Synthetic <b>Vision</b> (SVS) or <b>Enhanced</b> <b>Vision</b> <b>systems</b> (EVS). Synthetic <b>Vision</b> <b>systems</b> display a {{realistic}} 3D {{depiction of the}} outside world (similar to a flight simulator), based on a database of terrain and geophysical features in conjunction with the attitude and position information gathered from the aircraft navigational <b>systems.</b> <b>Enhanced</b> <b>Vision</b> <b>systems</b> add real-time information from external sensors, such as an infrared camera.|$|R
40|$|A {{number of}} {{projects}} {{have been developed to}} increase flight safety and economy of aviation. The development and validation of systems for pilot assistance is also one field of interest. To improve the situational awareness of an aircrew during poor visibility, different approaches emerged during the past few years. <b>Enhanced</b> <b>vision</b> <b>systems</b> (EVS – based on sensor images) are one of those. Typically, <b>Enhanced</b> <b>vision</b> <b>systems</b> consist of two main parts- sensor vision and Synthetic vision. Sensor vision uses weather penetrating forward looking image sensors such as Forward Looking Infrared Radar (FLIR) and HiVision Millimeter Wave Radar (HiVision MMWR). The main contribution {{of this paper is to}} set up the procedure based on literature survey to model the HiVision Millimeter Wave Radar for <b>Enhanced</b> <b>Vision</b> <b>Systems</b> functionalities...|$|R
2500|$|Honeywell, Thales and Elbit Systems {{supplies}} avionics with 9 X 12 in multifunction displays, electronic flight bags, synthetic <b>vision</b> and <b>enhanced</b> <b>vision</b> <b>systems</b> ...|$|R
50|$|The Gulfstream G500 has {{a reduced}} fuel capacity. Introduced in 2004 as a shorter 5800 nmi km range version, {{it has the}} same {{exterior}} appearance, as well as the PlaneView cockpit, but Visual Guidance System (HUD) and <b>Enhanced</b> <b>Vision</b> <b>System</b> (EVS) are options.|$|E
50|$|The G1000 is {{compatible}} with the latest <b>enhanced</b> <b>vision</b> <b>system</b> (EVS) technology. Enhanced vision systems use thermal and infrared cameras to see real-time images and help turn obscurants such as bad weather, night time, fog, dust and brownouts into better images that can see 8-10 times farther than the naked eye.|$|E
50|$|By 2014, Honeywell is {{expected}} to be shipping a combined vision display (CVS) system called SmartView that overlays an <b>enhanced</b> <b>vision</b> <b>system</b> (EVS) onto a synthetic vision system (SVS). This gives the pilot a primary flight display that combines infrared, visual and sensor views into a single cockpit view comparable to an augmented reality view.|$|E
40|$|To {{improve the}} {{situational}} awareness of an aircrew during poor visibility, different approaches {{emerged during the}} past few years. <b>Enhanced</b> <b>vision</b> <b>systems</b> (EVS – based on sensor images) are one of those. Typically, <b>Enhanced</b> <b>vision</b> <b>systems</b> concept is a combination of sensor data, environmental variables, internal and external state data and material database of the given geographical area. EVS uses weather penetrating forward looking image sensors such as Forward Looking Infrared Radar (FLIR) and HiVision Millimeter Wave Radar (HiVision MMWR). To generate the backscatter image from the imaging sensors, it is much important to develop a material classified database of the given geographical area. But development ofsuch material classified database requires various image processing tasks. Hence the main contribution of this paper is the implementation of GUI based toolbox which is capable of developing material database for both MMWR and FLIR by using different material properties for <b>Enhanced</b> <b>Vision</b> <b>Systems</b> functionalities. ...|$|R
50|$|FAR 91.175 {{requires}} that a pilot decide 200 feet before landing if their ground visibility {{is good enough}} to land or whether to circle around for another try. <b>Enhanced</b> <b>Vision</b> <b>Systems</b> (EVS) allow them to hold off until 100-150 feet.|$|R
50|$|Some long-wave cameras require their {{detector}} to be cryogenically cooled, typically {{for several}} minutes before use, although some moderately sensitive infrared cameras do not require this. Many thermal imagers, including some forward-looking infrared cameras (such as some LWIR <b>Enhanced</b> <b>Vision</b> <b>Systems</b> (EVS)) are also uncooled.|$|R
50|$|A forward-looking {{infrared}} <b>enhanced</b> <b>vision</b> <b>system</b> (EVS) camera {{provides an}} enhanced terrain view in low-visibility conditions. The EVS imagery is {{displayed on the}} HUD for low altitude flying, demonstrating its value for flying tactical missions at night or in cloud. EADS and Thales provides the new Multi-Colour Infrared Alerting Sensor (MIRAS) missile warning sensor for the A400M.|$|E
5000|$|Other sensor types {{have been}} flown for {{research}} purposes, including active and passive millimeter wave radar. In 2009, DARPA provided funding to develop [...] "Sandblaster", a millimeter wave radar based <b>enhanced</b> <b>vision</b> <b>system</b> installed on helicopters which enables the pilot {{to see and}} avoid obstacles in the landing area that may be obscured by smoke, sand, or dust.|$|E
5000|$|Compared to the Gulfstream V, drag {{reduction}} details boost range by [...] {{and increase}} fuel efficiency.MTOW is increased by 500 lb and Takeoff performance is enhanced.A seventh pair of windows is added and the entry door is moved 2 ft. forward to increase usable cabin length.The PlaneView flight deck features cursor control devices, Honeywell Primus Epic avionics, standard head-up guidance system by Rockwell Collins and <b>enhanced</b> <b>vision</b> <b>system</b> by Elbit, improving situational awareness in reduced visibility conditions.|$|E
50|$|The 550 was {{developed}} from the earlier Eclipse 500, enabled by Sikorsky Aircraft's investment in Eclipse Aerospace in 2010. It retains the 500's airframe and PW610F engines, but incorporates an improved avionics package, including satellite phones, autothrottles, synthetic <b>vision</b> and <b>enhanced</b> <b>vision</b> <b>systems,</b> as well as anti-skid brakes.|$|R
50|$|The {{resulting}} aircraft bears {{little resemblance}} to the original TG-8. Installation of the twin-boom pods permits the carriage of more sensors. The left-hand pod houses an AN/APN-215(V) color multi-function X-band sea search radar with mapping capabilities. The right-hand pod houses the AN/AAQ-15 forward looking infrared (FLIR) and Low-Light TV <b>enhanced</b> <b>vision</b> <b>systems.</b>|$|R
50|$|A {{night vision}} device (NVD) is a device {{comprising}} an {{image intensifier tube}} in a rigid casing, commonly used by military forces. Lately, night vision technology has become more widely available for civilian use. For example, <b>enhanced</b> <b>vision</b> <b>systems</b> (EVS) have become available for aircraft to help pilots with situational awareness and avoid accidents. These systems {{are included in the}} latest avionics packages from manufacturers such as Cirrus and Cessna. The US Navy has begun procurement of a variant integrated into a helmet-mounted display, produced by Elbit Systems.|$|R
50|$|In 2003, Gulfstream {{acquired}} a service {{center at the}} London-Luton Airport, the first Gulfstream-owned service center to be operated outside the United States. Also, in 2003, the long-range Gulfstream G450 was introduced. The large-cabin, mid-range G350 was presented a year later. In 2004, Gulfstream was awarded the 2003 Collier Trophy {{for the development of}} the G550. It was the second time in less than a decade that Gulfstream had won the award. The G550 is the first civil aircraft to receive a Type Certificate issued by the Federal Aviation Administration (FAA) that includes an <b>Enhanced</b> <b>Vision</b> <b>System</b> (EVS) as standard equipment on an aircraft. The aircraft also contained the first cockpit to incorporate PlaneView®, an integrated avionics suite featuring four 14-inch (36 cm) liquid crystal displays in landscape format.|$|E
50|$|Night vision {{systems have}} been {{available}} to pilots of military aircraft for many years. More recently business jets have added similar capabilities to aircraft to enhance pilot situational awareness in poor visibility due to weather or haze, and at night. The first civil certification of an <b>enhanced</b> <b>vision</b> <b>system</b> on an aircraft was pioneered by Gulfstream Aerospace using a Kollsman IR camera. Originally offered as an option on the Gulfstream V aircraft, it was made standard equipment in 2003 when the Gulfstream G550 was introduced and followed on the Gulfstream G450 and Gulfstream G650. As of 2009, Gulfstream has delivered over 500 aircraft with a certified EVS installed. Other aircraft OEMs followed, with EVS now available on some Bombardier and Dassault business jet products. Boeing has begun offering EVS on its line of Boeing business jets {{and is likely to}} include it as an option on the B787 and B737 MAX.|$|E
40|$|This {{article focuses}} {{on the use of}} thermal imaging in aviation. In the never ending pursuit of lower costs, the Thermal Imaging offers shorter {{inspection}} times thanks to its application in aircraft inspections and can reduce the number of costly goarounds using the <b>Enhanced</b> <b>Vision</b> <b>System,</b> which also increases safety {{in one of the most}} dangerous parts of flight. Thermal Imaging also offers solutions for Airport Perimeter Security and it can be used for construction of ground surveillance system...|$|E
50|$|The FAA grants some {{additional}} operating minimums to aircraft equipped with certified <b>enhanced</b> <b>vision</b> <b>systems</b> allowing Category I approaches to Category II minimums. Typically an operator {{is permitted to}} descend to lower altitudes closer to the runway surface (typically as low as 100 ft) in poor visibility {{in order to improve}} the chances of spotting the runway environment prior to landing. Aircraft not equipped with such systems {{would not be allowed to}} descend as low and often would be required to execute a missed approach and fly to a suitable alternate airport.|$|R
50|$|In recent years, {{other types}} of <b>vision</b> <b>systems</b> have been {{introduced}} primarily on business jets. Both <b>Enhanced</b> <b>Vision</b> <b>Systems</b> (EVS) and Synthetic <b>vision</b> <b>system</b> (SVS) have become standard equipment on many larger business jets such as those manufactured by Gulfstream, Bombardier, Dassault, and most recently, Embraer. However, EVS typically provides the pilot(s) with an infrared video image, usually displayed on the HUD, which overlays the pilot view {{of the outside world}} through the windscreen. SVS is a computer generated version of the outside world created from an onboard terrain database. SVS can also be displayed conformally on the HUD, but it is not real time in that anything that {{is not part of the}} static terrain database cannot be displayed.|$|R
40|$|<b>Enhanced</b> <b>Vision</b> <b>Systems</b> (EVS) are {{currently}} developed {{with the goal}} to alleviate restrictions in airspace and airport capacity in low-visibility conditions. EVS relies on weather penetrating forward-looking sensors that augment the naturally existing visual cues in the environment and provide a real-time image of prominent topographical objects that may be identified by the pilot. In this paper an automatic analysis of millimetre wave radar images for <b>Enhanced</b> <b>Vision</b> <b>Systems</b> is presented. The core {{part of the system}} is a fuzzy rule based inference machine which controls the data analysis based on the uncertainty in the actual knowledge in combination with a-priori knowledge. Compared with standard TV or IR images the quality of MMW images is rather poor and data is highly corrupted with noise and clutter. Therefore, one main task of the inference machine is to handle uncertainties as well as ambiguities and inconsistencies to draw the right conclusions. The output of different sensor data analysis processes are fused and evaluated within a fuzzy/possibilistic clustering algorithm whose results serve as input to the inference machine. The only a-priori knowledge used in the presented approach is the same pilots already know from airport charts which are available of almost every airport. The performance of the approach is demonstrated with real data acquired during extensive flight tests to several airports in Northern Germany...|$|R
40|$|<b>Enhanced</b> <b>Vision</b> <b>System</b> (EVS) {{technology}} has been developing since 1980 s. The research itself has been mainly focused on controlling Unmanned Aerial Vehicles (UAVs). In this area, some methods were successfully tested, from take-off to landing. This paper {{is meant to be}} an introduction for further research and testing within general aviation area for use of EVS technology by high experienced as well as low experienced pilots in order to increase the level of safety during critical stages of flight...|$|E
40|$|In this presentation, the {{applicability}} of various aircraft navigation sensors to <b>enhanced</b> <b>vision</b> <b>system</b> design is discussed. First, the accuracy requirements of the FAA for precision landing systems are presented, followed by the current navigation systems and their characteristics. These systems include Instrument Landing System (ILS), Microwave Landing System (MLS), Inertial Navigation, Altimetry, and Global Positioning System (GPS). Finally, the use of navigation system data to improve enhanced vision systems is discussed. These applications include radar image rectification, motion compensation, and image registration...|$|E
40|$|Over {{the last}} few years NASA Langley Research Center (LaRC) has been {{developing}} an <b>Enhanced</b> <b>Vision</b> <b>System</b> (EVS) to aid pilots while flying in poor visibility conditions. The EVS captures imagery using two infrared video cameras. The cameras are placed in an enclosure that is mounted and flown forward-looking underneath the NASA LaRC ARIES 757 aircraft. The data streams from the cameras are processed in real-time and displayed on monitors on-board the aircraft. With proper processing the camera system can provide better-than- human-observed imagery particularly during poor visibility conditions. However, to obtain this goal requires several different stages of processing including enhancement, registration, and fusion, and specialized processing hardware for real-time performance. We are using a real-time implementation of the Retinex algorithm for image enhancement, affine transformations for registration, and weighted sums to perform fusion. All of the algorithms are executed on a single TI DM 642 digital signal processor (DSP) clocked at 720 MHz. The image processing components were added to the EVS system, tested, and demonstrated during flight tests in August and September of 2005. In this paper we briefly discuss the EVS image processing hardware and algorithms. We then discuss implementation issues and show examples of the results obtained during flight tests. Keywords: <b>enhanced</b> <b>vision</b> <b>system,</b> image enhancement, retinex, digital signal processing, sensor fusio...|$|E
50|$|The {{aircraft}} has {{a flight}} management {{system with a}} worldwide satellite-based Global Positioning System. The C-37A is capable of cruising at 51000 ft. Features include enhanced weather radar, autopilot and head-up display for the pilot. Safety features include <b>Enhanced</b> <b>Vision</b> <b>Systems</b> that allows increased visibility in adverse environments. The aircraft is also equipped with commercial and military communications equipment to provide secure voice and data capability. The U.S. Air Force equips the C-37A with a basic crew of two pilots, one flight engineer, one communications systems operator, and one flight attendant. It accommodates 5 crew and 12 passengers.|$|R
40|$|This paper reviews recent {{human factors}} {{research}} {{studies conducted in}} the Aerospace Human Factors Research Division at NASA Ames Research Center related to the development and usage of <b>Enhanced</b> or Synthetic <b>Vision</b> <b>Systems.</b> Research discussed includes studies of field of view (FOV), representational differences of infrared (IR) imagery, head-up display (HUD) symbology, HUD advanced concept designs, sensor fusion, and sensor/database fusion and evaluation. Implications for the design and usage of <b>Enhanced</b> or Synthetic <b>Vision</b> <b>Systems</b> are discussed...|$|R
40|$|The Fifth (and Final) Combined Manufacturers' and Technologists' Airborne Windshear Review Meeting was hosted {{jointly by}} the NASA Langley Research Center (LaRC) and the Federal Aviation Administration (FAA) in Hampton, Virginia, on September 28 - 30, 1993. The purpose of the meeting was {{to report on the}} highly {{successful}} windshear experiments conducted by government, academic institutions, and industry; to transfer the results to regulators, manufacturers, and users; and to set initiatives for future aeronautics technology research. The formal sessions covered recent developments in windshear flight testing; windshear modeling, flight management, and ground-based systems; airborne windshear detection systems; certification and regulatory issues; development and applications of sensors for wake vortex detection; and synthetic and <b>enhanced</b> <b>vision</b> <b>systems...</b>|$|R
40|$|This paper {{provides}} {{research and}} development carried out to apply fuzzy logic system (type 1 and type 2) of image fusion. It covers fuzzy logic operator/operations in context of image fusion. Color and infrared images obtained from <b>Enhanced</b> <b>Vision</b> <b>System</b> prototype are utilized for the study. The fused image is evaluated for various design cases for fuzzy logic system type 1 and Interval type 2 fuzzy logic systems. Based on qualitative and analytical analysis, it is concluded that Interval type 2 fuzzy logic system performs better than fuzzy logic system type 1 and in general Sugeno based fuzzy logic systems are better than Mamdani based fuzzy logic system...|$|E
40|$|This paper {{presents}} {{the implementation of}} image fusion techniques {{by means of an}} image fusion application “C#ImFuse”, developed in C#. NET. C# programming language is a simple, type-safe, object-oriented language that allows programmers to build a variety of applications. C#ImFuse application implements four fusion methods viz., Alpha Blending (AB), Principle Component Analysis (PCA), Laplacian Pyramid (LP), and Discrete Wavelet Transform (DWT) for a visual and a thermal image (still images) and for real-time images of the <b>Enhanced</b> <b>Vision</b> <b>System</b> (EVS). The performance of these fusion techniques is evaluated using fusion performance metrics. LP based image fusion technique proved to provide better fusion when compared to the other techniques. Source code is provided so that the reader can understand the techniques and use for his research work...|$|E
40|$|The use of {{enhanced}} vision {{systems in}} civil aircraft {{is projected to}} increase rapidly as the Federal Aviation Administration recently changed the aircraft operating rules under Part 91, revising the flight visibility requirements for conducting approach and landing operations. Operators conducting straight-in instrument approach procedures may now operate below the published approach minimums when using an approved enhanced flight vision system that shows the required visual references on the pilot's Head-Up Display. An experiment was conducted to evaluate the complementary use of synthetic vision systems and <b>enhanced</b> <b>vision</b> <b>system</b> technologies, focusing on new techniques for integration and/or fusion of synthetic and enhanced vision technologies and crew resource management while operating under these newly adopted rules. Experimental results specific to flight crew response to non-normal events using the fused synthetic/enhanced vision system are presented...|$|E
40|$|The Fifth Combined Manufacturers' and Technologists' Airborne Windshear Review Meeting was {{hosted by}} the NASA Langley Research Center and the Federal Aviation Administration in Hampton, Virginia, on September 28 - 30, 1993. The purpose was {{to report on the}} highly {{successful}} windshear experiments conducted by government, academic institutions, and industry; to transfer the results to regulators, manufacturers, and users; and to set initiatives for future aeronautics technology research. The formal sessions covered recent developments in windshear flight testing, windshear modeling, flight management, and ground-based systems, airborne windshear detection systems, certification and regulatory issues, and development and applications of sensors for wake vortices and for synthetic and <b>enhanced</b> <b>vision</b> <b>systems.</b> This report was compiled to record and make available the technology updates and materials from the conference...|$|R
40|$|Research {{literature}} are reviewed and summarized {{to evaluate the}} awareness and detection of traffic and obstacles when using Synthetic <b>Vision</b> <b>Systems</b> (SVS) and <b>Enhanced</b> <b>Vision</b> <b>Systems</b> (EVS). The study identifies the critical issues influencing the time required, accuracy, and pilot workload associated with recognizing and reacting to potential collisions or conflicts with other aircraft, vehicles and obstructions during approach, landing, and surface operations. This work considers the effect of head-down display and head-up display implementations of SVS and EVS {{as well as the}} influence of single and dual pilot operations. The influences and strategies of adding traffic information and cockpit alerting with SVS and EVS were also included. Based on this review, a knowledge gap assessment was made with recommendations for ground and flight testing to fill these gaps and hence, promote the safe and effective implementation of SVS/EVS technologies for the Next Generation Air Transportation Syste...|$|R
50|$|Astronics Max-Viz is an American company {{founded in}} Portland, Oregon on May 31, 2001 as Max-Viz, Inc. to design, {{manufacture}} and certify <b>Enhanced</b> <b>Vision</b> <b>Systems</b> (“EVS”) primarily {{for use in}} the aerospace industry. Max-Viz EVS devices present real-time images of the external environment on aircraft cockpit monitors to improve pilot situational awareness under circumstances where visibility is impaired by weather or darkness. The company objective is to help the pilot see clearly and fly safely by providing visual information about where they are, where they are going and what is in their way. The Max-Viz EVS captures and enhances thermal infrared signals and can be combined with visible light as well as other electromagnetic energy sources. The company's systems are designed to be integrated with a variety of displays already in the aircraft cockpit.|$|R
