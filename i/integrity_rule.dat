12|159|Public
5000|$|Entity {{integrity}} {{concerns the}} concept of a primary key. Entity integrity is an <b>integrity</b> <b>rule</b> which states that every table must have a primary key and that the column or columns chosen to be the primary key should be unique and not null.|$|E
50|$|As of 2016, the DRC {{ranked as}} the poorest {{country in the}} world {{according}} to indexmundi based on the Gross Domestic Product per capita. At the same time, the country ranked near-last according to the UN Development Programme (UNDP) Human Development Index despite abundant natural resources. He believes, based on experience, that the path to shared prosperity is rooted in good governance, <b>integrity,</b> <b>rule</b> of law, human rights, equality, and opportunity for all.|$|E
50|$|A key {{constraint}} {{applies to}} the set of tuples in a table at any given point in time. A key {{is not necessarily a}} unique identifier across the population of all possible instances of tuples that could be stored in a table but it does imply a data <b>integrity</b> <b>rule</b> that duplicates should not be allowed in the database table. Some possible examples of unique keys are Social Security Numbers, ISBNs, vehicle registration numbers or user login names.|$|E
40|$|Abstract An {{aspect of}} {{information}} security is the information’s integrity. An {{important aspect of}} integrity is that the information must retain its appropriate meaning. Semantic <b>integrity</b> <b>rules</b> specify requirements for ensuring that information maintains its meaning. It is believed that certain reoccuring themes are present in these semantic <b>integrity</b> <b>rules.</b> Pattern languages are often used to present solutions to such regularly occurring problems. This paper will therefore investigate semantic integrity from a pattern-based perspective. In doing so, the paper {{will argue that the}} implementation of certain semantic <b>integrity</b> <b>rules</b> can be aided through identifying patterns...|$|R
40|$|Rules based {{approaches}} for data quality solutions often use business <b>rules</b> or <b>integrity</b> <b>rules</b> for data monitoring purpose. <b>Integrity</b> <b>rules</b> are constraints on data derived from business rules into a formal form {{in order to}} allow computerization. One of challenges of these approaches is rules discovering, which is usually manually made by business experts or system analysts based on experiences. In this paper, we present our rule-based approach for data quality analyzing, in which we discuss a comprehensive method for discovering dynamic <b>integrity</b> <b>rules.</b> Comment: International conference on Computer Systems and Technologies, 2010. 6 page...|$|R
40|$|This paper {{addresses}} <b>integrity</b> <b>rules</b> {{that are}} embedded within engineering design applications and that apply between applications. A representation for <b>integrity</b> <b>rules</b> that {{are embedded in}} applications is presented {{and a set of}} related methods developed for: (a.) maintaining the integrity condition of application developed data, (b) managing the precedence order between applications, in the context of (c.) changing the schema and the associated mix of applications and (d.) iterated execution of applications and change propagation. Both <b>integrity</b> <b>rules</b> literally embedded within external applications and others required to be embedded within a database are considered. The techniques are demonstrated with an extensive example...|$|R
50|$|Concurrency control {{mechanisms}} firstly need {{to operate}} correctly, i.e., to maintain each transaction's integrity rules (as related to concurrency; application-specific <b>integrity</b> <b>rule</b> {{are out of}} the scope here) while transactions are running concurrently, and thus the integrity of the entire transactional system. Correctness needs to be achieved with as good performance as possible. In addition, increasingly a need exists to operate effectively while transactions are distributed over processes, computers, and computer networks. Other subjects that may affect concurrency control are recovery and replication.|$|E
5000|$|Referential {{integrity}} {{concerns the}} concept of a foreign key. The referential <b>integrity</b> <b>rule</b> states that any foreign-key value can only be in one of two states. The usual state of affairs is that the foreign-key value refers to a primary key value of some table in the database. Occasionally, and this will depend on the rules of the data owner, a foreign-key value can be null. In this case we are explicitly saying that either there is no relationship between the objects represented in the database or that this relationship is unknown.|$|E
30|$|The <b>integrity</b> <b>rule</b> was {{proposed}} to identify undesired chopping {{of the main}} subject. The great drawback of this rule is {{the high cost of}} precisely detecting the subject in a photo. The use of anthropometric measures were shown to be effective to subjects in an upright frontal position. Using some reliable information, such as the coordinates, and the dimensions of a detected face [18, 139], it is possible to infer the position {{of the rest of the}} subject body, and detect possible chops.|$|E
5000|$|Support for: <b>Integrity</b> <b>rules,</b> Derivation rules, Production {{rules and}} Reaction rules; ...|$|R
50|$|In 1997, after {{a three-year}} {{investigation}} the federal Office of Research <b>Integrity</b> <b>ruled</b> that Fisher was innocent of any scientific misconduct.|$|R
40|$|Abstract. Data {{quality in}} {{populated}} spatial databases {{has been of}} great concern over the last decade. Much work has gone into means of incorporating spatial “business rules ” in GIS with the ultimate aim of reducing errors in data entry, or detecting them after they are made. This paper reviews means by which spatial <b>integrity</b> <b>rules</b> have been modeled in the GIS literature, and {{with the aid of}} a case study described one approach to modeling and using <b>integrity</b> <b>rules</b> in practice. 1...|$|R
40|$|This paper {{presents}} {{an approach to}} image analysis based on three photographic composition rules: Rule-of-Thirds, Zoom Rule and <b>Integrity</b> <b>Rule.</b> These rules are commonly used by experienced photographers as an important step for creating attractive photos. The proposed approach assumes {{there is only one}} person in the image and considers the use of a face detector to locate the photograph’s main subject. The composition analysis computes a set of numerical measures from an input image. These measures are then combined to produce an estimate for the overall composition quality. Experiments involving a subjective evaluation by human observers have demonstrated promising results, given that some correlation has been observed between labelling by expert users and the proposed automatic analysis in up to 85 % of a test set of images...|$|E
40|$|In {{this paper}} {{we present a}} method based on {{abduction}} for explaining and repairing the errors detected {{in the analysis of}} natural language sentences. This method builds the most plausible corrections for any unrecognised sentence. It is a declarative approach and, as such, departs from the traditional heuristic relaxation based approaches. In the proposed method, the ungrammaticality of a sentence is viewed as a diagnosis problem and abductive reasoning is used to obtain the explanations for the detected errors. The problem is represented as an abduction problem and is implemented using logic programming with explicit negation and with integrity constraints. The existence of an error in a sentence will cause a contradiction to become apparent due to the violation of an <b>integrity</b> <b>rule.</b> Contradictions are removed according to a revision process developed for contradictory programs {{in the sense of the}} well founded semantics for extended logic programs. A contradiction can b [...] ...|$|E
40|$|Driven by the {{dominance}} of the relational model and the requirements of modern applications, we revisit the fundamental notion of a key in relational databases with NULL. In SQL, primary key columns are NOT NULL, and UNIQUE constraints guarantee uniqueness only for tuples without NULL. We investigate the notions of possible and certain keys, which are keys that hold in some or all possible worlds that originate from an SQL table, respectively. Possible keys coincide with UNIQUE, thus providing a semantics for their syntactic definition in the SQL standard. Certain keys extend primary keys to include NULL columns and can uniquely identify entities whenever feasible, while primary keys may not. In addition to basic characterization, axiomatization, discovery, and extremal combinatorics problems, we investigate the existence and construction of Armstrong tables, and describe an indexing scheme for enforcing certain keys. Our experiments show that certain keys with NULLs occur in real-world data, and related computational problems can be solved efficiently. Certain keys are therefore semantically well founded and able to meet Codd’s entity <b>integrity</b> <b>rule</b> while handling high volumes of incomplete data from different formats...|$|E
5000|$|<b>Integrity</b> or {{validation}} <b>rules,</b> {{also known}} as constraints, restrict the set of facts and the transitions between the permitted sets of facts to those that are considered useful. In terms of data quality, <b>integrity</b> <b>rules</b> are used to guarantee {{the quality of the}} facts.|$|R
50|$|Universal Market <b>Integrity</b> <b>Rules</b> (UMIR) are the set {{of rules}} {{governing}} financial market integrity in Canada that are defined by the Investment Industry Regulatory Organization of Canada (IIROC).|$|R
50|$|If a {{relational}} {{system has}} a low-level (single-record-at-a-time) language, that low level {{cannot be used}} to subvert or bypass the <b>integrity</b> <b>rules</b> and constraints expressed in the higher level relational language (multiple-records-at-a-time).|$|R
40|$|This report {{describes}} the basis, results, and related risk implications of an analysis performed by {{an ad hoc}} working group of the U. S. Nuclear Regulatory Commission (NRC) to assess the containment bypass potential attributable to steam generator tube rupture (SGTR) induced by severe accident conditions. The SGTR Severe Accident Working Group, comprised of staff members from the NRC`s Offices of Nuclear Reactor Regulation (NRR) and Nuclear Regulatory Research (RES), undertook the analysis beginning in December 1995 to support a proposed steam generator <b>integrity</b> <b>rule.</b> The work drew upon previous risk and thermal-hydraulic analyses of core damage sequences, with a focus on the Surry plant as a representative example. This analysis yielded new results, however, derived by predicting thermal-hydraulic conditions of selected severe accident scenarios using the SCDAP/RELAP 5 computer code, flawed tube failure modeling, and tube failure probability estimates. These results, in terms of containment bypass probability, form the basis for the findings presented in this report. The representative calculation using Surry plant data indicates that some existing plants could be vulnerable to containment bypass resulting from tube failure during severe accidents. To specifically identify the population of plants that may pose a significant bypass risk would require more definitive analysis considering uncertainties in some assumptions and plant- and design-specific variables. 46 refs., 62 figs., 37 tabs...|$|E
40|$|Purpose – The {{purpose of}} this paper is to {{emphasize}} that East Asia and South East Asia, despite enormous economic advances, have a deficit on rule of law, analysed as either judicial autonomy and legal <b>integrity</b> (<b>rule</b> of law I) or as voice and accountability (rule of law II). Design/methodology/approach – First, a distinction is made between two key aspects of rule of law; second, these two aspects are measured by data from the World Bank Governance project, relating them to various measures on socio-economic development and economic growth. Findings – It is not generally true that development leads to or entails freedom, as several countries in the ASEAN + 3 region display low scores on either one of the dimensions of rule of law or both. Practical implications – In both research and in practice, one needs to devote more effort into understanding how rapid economic development may be possible without strong rule of law, either as legal integrity and judicial autonomy, or as voice and political accountability. In the process of globalisation, demands for more of rule of law in this region appear justifiable. Originality/value – This paper provides useful information on economic development and political development, which is highly relevant for understanding the implication of economic growth in the countries in ASEAN + 3. Affluence, ASEAN region (10 + 3), Economic freedom indices, Economic growth, Gross national product, Human development index, World Bank Governance indices on rule of law I and rule of law II, ASEAN region (10 + 3) ...|$|E
50|$|Consistency - Every {{transaction}} {{must leave}} the database in a consistent (correct) state, i.e., maintain the predetermined <b>integrity</b> <b>rules</b> of the database (constraints upon {{and among the}} database's objects). A transaction must transform a database from one consistent state to another consistent state (however, {{it is the responsibility}} of the transaction's programmer to make sure that the transaction itself is correct, i.e., performs correctly what it intends to perform (from the application's point of view) while the predefined <b>integrity</b> <b>rules</b> are enforced by the DBMS). Thus since a database can be normally changed only by transactions, all the database's states are consistent.|$|R
40|$|Abstract. The {{conventional}} use of databases {{is commonly}} {{restricted to the}} re-trieval of factual data {{in the form of}} tuples or records. However most databases also contain metadata in the form of <b>integrity</b> <b>rules</b> which can provide a rich source of additional information not normally available to the user. <b>Integrity</b> <b>rules</b> define what data values and relationships may exist within the database and so their interrogation can provide answers as to whether a certain database state is possible. Our paper describes how this may be achieved and specifies a formal approach to implementing such an enquiry system. ...|$|R
50|$|The {{legislature}} and judiciary, {{as well as}} the media and civil society, are weak in comparison to the executive. Transparency and accountability are weaker in local Georgian governments than in the national government. Unsalaried city council members are exempt from <b>integrity</b> <b>rules</b> that apply to national officials.|$|R
50|$|For {{business}} applications, {{data validation}} {{can be defined}} through declarative data <b>integrity</b> <b>rules,</b> or procedure-based business rules. Data that does not conform to these rules will negatively affect business process execution. Therefore, data validation should start with business process definition and set of business rules within this process. Rules can be collected through the requirements capture exercise.|$|R
50|$|Data {{integrity}} contains {{guidelines for}} data retention, specifying or guaranteeing {{the length of}} time data can be retained in a particular database. In order to achieve data <b>integrity,</b> these <b>rules</b> are consistently and routinely applied to all data entering the system, and any relaxation of enforcement could cause errors in the data. Implementing checks on the data {{as close as possible to}} the source of input (such as human data entry), causes less erroneous data to enter the system. Strict enforcement of data <b>integrity</b> <b>rules</b> causes the error rates to be lower, resulting in time saved troubleshooting and tracing erroneous data and the errors it causes algorithms.|$|R
40|$|Abstract: The semantical {{integrity}} of business data {{is of great}} importance {{for the implementation of}} business applications. Model-Driven Software Development (MDSD) allows for specifying the relevant domain concepts, their interrelations and their concise semantics using a plethora of modelling languages. Since model trans-formations enable an automatic mapping of platform independent models (PIMs) to platform specific models (PSMs) and code, it is reasonable to utilise them to derive data schemas and <b>integrity</b> <b>rules</b> for business applications. Most current approaches only focus on transforming structural descriptions of software systems while seman-tical specifications are neglected. However, to preserve also the semantical <b>integrity</b> <b>rules</b> we propose a Query Code Generation Framework that enables Model-Driven Integrity Engineering. This framework allows for mapping UMLmodels to arbitrary data schemas and for mapping OCL invariants to sentences in corresponding declar-ative query languages, enforcing semantical data integrity on implementation level. This supersedes the manual translation of integrity constraints and, thus, decreases development costs while increasing software quality...|$|R
40|$|A constraint-based {{generalized}} {{object-oriented database}} model {{is adapted to}} manage spatio-temporal information. The presented adaptation {{is based on the}} definition of a new data type, which is suited to handle both temporal and spatial information. Generalized constraints are used to describe spatio-temporal data, to enforce <b>integrity</b> <b>rules</b> on databases, to specify the semantics of a database scheme and to impose selection criteria in flexible database querying...|$|R
50|$|In ArcGIS, a {{data model}} {{a set of}} {{database}} design specifications for objects in a GIS application. A data model describes the thematic layers used in the applications (for example, hamburger stands, roads, and counties); their spatial representation (for example, point, line, or polygon); their attributes; their <b>integrity</b> <b>rules</b> and relationships (for example, counties must nest within states); their cartographic portrayal; and their metadata requirements.|$|R
40|$|The EcrinsDesign {{system is}} a {{graphical}} tool for data schema design. It {{is based on the}} Ecrins semantic data model. It supports interactive data schema design by direct manipulation of graphical objects. Its main contribution is the definition and the management of the dynamic aspects of the graphical representation: the type of each object may evolve, depending on the user's actions and conforming to a set of <b>integrity</b> <b>rules...</b>|$|R
50|$|The figure {{illustrates}} the way data models are developed and used today. A conceptual data model is developed {{based on the}} data requirements for the application that is being developed, perhaps {{in the context of}} an activity model. The data model will normally consist of entity types, attributes, relationships, <b>integrity</b> <b>rules,</b> and the definitions of those objects. This is then used as the start point for interface or database design.|$|R
40|$|An {{important}} {{activity in}} the design of a particular database application consists in identifying the integrity constraints that must hold on the database, and that are used to detect and evaluate inconsistencies. It is possible to improve data quality by imposing constraints upon data entered into the database. These constraints must be identified and recorded at the database design level. However, it is clear that modeling geographic data requires models which are more specific and capable of capturing the semantics of geographic data. Within a geographic context, topological relations and other spatial relationships are fundamentally important in the definition of spatial <b>integrity</b> <b>rules.</b> This paper discusses the relationship that exists between the nature of spatial information, spatial relationships, and spatial integrity constraints, and proposes the use of OMT-G, an extension of the OMT model for geographic applications, at an early stage in the specification of integrity constraints in spatial databases. OMT-G provides adequate primitives for representing spatial data, supports spatial relationships, and allows topological, semantic and user <b>integrity</b> <b>rules</b> to be specified in the database schema...|$|R
40|$|A formal {{framework}} for a generalised object-oriented database model is presented, which {{is able to}} cope with fuzzy and uncertain information. This model is obtained as a generalisation of a crisp object-oriented database model, which is consistent with the ODMG de facto standard and is built upon an algebraic type system and a constraint system. Generalised constraints have been used to enforce <b>integrity</b> <b>rules</b> and to specify the formal semantics of the database model...|$|R
50|$|Shaw was {{suspended}} by the AFL in July 2011 {{after it was}} found that he had paid $10 to a friend to bet on teammate Nick Maxwell to be the first goal scorer in Collingwood's Round 9 match against Adelaide. AFL <b>integrity</b> <b>rules</b> prohibit all players and club officials from participating in any form of betting on football matches. He was fined $20,000 and suspended for 8 weeks, as well as a six-week suspended sentence.|$|R
5000|$|... #Caption: The data {{modeling}} process. The figure illustrates the way data models are developed and used today. A conceptual data model is developed {{based on the}} data requirements for the application that is being developed, perhaps {{in the context of}} an activity model. The data model will normally consist of entity types, attributes, relationships, <b>integrity</b> <b>rules,</b> and the definitions of those objects. This is then used as the start point for interface or database design.|$|R
50|$|The ESRI White Paper GIS Topology {{explains}} that topology operations {{are used to}} manage shared geometry, define and enforce data <b>integrity</b> <b>rules,</b> support topological relationship queries and navigation, and build more complex shapes such as polygons, from primitive ones such as lines. A GIS for Educators worksheet at Linfiniti adds the detection and correction of digitising errors and carrying out network analysis. Topological error correction is explained in more detail in a paper by Ubeda and Egenhofer.|$|R
50|$|Leegte {{resigned}} as {{member of the}} House of Representatives on 24 March 2015 after having had an additional paid job {{for over a year}} at an organisation which was subjected to his parliamentary portfolio. Leegte did not enter the job in the register, nor reported the earnings, he also used his parliamentary emailadress for the additional job. Leegte felt this conflicted with the <b>integrity</b> <b>rules</b> of the People's Party for Freedom and Democracy and thus resigned.|$|R
