44|10000|Public
500|$|The lateral zone, {{which in}} humans {{is by far}} the largest part, {{constitutes}} the cerebrocerebellum, also known as neocerebellum. It receives input exclusively from the cerebral cortex (especially the parietal lobe) via the pontine nuclei (forming cortico-ponto-cerebellar pathways), and sends output mainly to the ventrolateral thalamus (in turn connected to motor areas of the premotor cortex and primary motor area of the cerebral cortex) and to the red nucleus. There is disagreement about the best way to describe the functions of the lateral cerebellum: It is thought to be involved in planning movement that is about to occur, in evaluating sensory <b>information</b> <b>for</b> <b>action,</b> and in a number of purely cognitive functions, such as determining the verb which best fits with a certain noun (as in [...] "sit" [...] for [...] "chair").|$|E
50|$|Rebatet {{was born}} and died in Moras-en-Valloire, Drôme. As a young man, Rebatet was educated in Saint-Chamond, Loire. From 1923 to 1927 he studied at the Sorbonne, after which he became an {{insurance}} agent. It was only in 1929 that {{he began his career}} as a writer, becoming a music and film critic (the latter under the pseudonym François Vinneuil) for the far right integralist Action Française newspaper. In 1932 Rebatet became a contributor to the right-wing newspaper Je suis partout, for which he wrote until the Allied liberation in 1944. In 1938 he became head of <b>information</b> <b>for</b> <b>Action</b> Française and worked closely with the movement's founder, Charles Maurras.|$|E
5000|$|The lateral zone, {{which in}} humans {{is by far}} the largest part, {{constitutes}} the cerebrocerebellum, also known as neocerebellum. It receives input exclusively from the cerebral cortex (especially the parietal lobe) via the pontine nuclei (forming cortico-ponto-cerebellar pathways), and sends output mainly to the ventrolateral thalamus (in turn connected to motor areas of the premotor cortex and primary motor area of the cerebral cortex) and to the red nucleus. There is disagreement about the best way to describe the functions of the lateral cerebellum: It is thought to be involved in planning movement that is about to occur, in evaluating sensory <b>information</b> <b>for</b> <b>action,</b> and in a number of purely cognitive functions, such as determining the verb which best fits with a certain noun (as in [...] "sit" [...] for [...] "chair").|$|E
2500|$|Bhopal Group <b>for</b> <b>Information</b> and <b>Action</b> (BGIA). Letter July 16, 1993 ...|$|R
40|$|Fast interceptive actions, such as {{catching}} a ball, rely upon accurate and precise information from vision. Recent models rely on flexible combinations of visual angle and its rate of expansion {{of which the}} tau parameter is a specific case. When an object approaches an observer, however, its trajectory may introduce bias into tau-like parameters that render these computations unacceptable as the sole source of <b>information</b> <b>for</b> <b>actions.</b> Here we show that observer knowledge of object size influences their action timing, and known size combined with image expansion simplifies the computations required to make interceptive actions and provides a route for experience to influence interceptive action...|$|R
40|$|Abstract: This study {{focuses on}} {{improving}} the routine reporting of health data {{by identifying the}} challenges associated with timely reporting of routine data from the primary health facilities to the district and determines how mobile phones {{can be used to}} overcome the problem and thus enhance <b>information</b> use <b>for</b> <b>action</b> at al...|$|R
40|$|We {{consider}} {{the problem of}} recognizing human actions from still images. We propose a novel approach that treats the pose of {{the person in the}} image as latent variables that will help with recognition. Different from other work that learns separate systems for pose estimation and action recognition, then combines them in an ad-hoc fashion, our system is trained in an integrated fashion that jointly considers poses and actions. Our learning objective is designed to directly exploit the pose <b>information</b> <b>for</b> <b>action</b> recognition. Our experimental results demonstrate that by inferring the latent poses, we can improve the final action recognition results. 1. ...|$|E
30|$|Multi-camera {{systems can}} provide more <b>information</b> <b>for</b> <b>action</b> recognition. Liu et al. (2015) {{proposed}} a unified single/multi-view human action recognition method via regularized multi-task learning. Gao et al. (2015) proposed a multi-view discriminative and structured dictionary learning method with group sparsity and a graph model to fuse different views and recognize human actions. Junejo et al. (2011) presented an action descriptor {{to capture the}} structure of the temporal similarities and dissimilarities in action sequences. The latent kernelized structural SVM was proposed by Wu and Jia (2012) for view-invariant action recognition. These methods of multi-views have good performance. However, the methods cannot be applied to real scenes due to the high computation complexity and difficultly in correlating information among different views.|$|E
40|$|In this paper, {{we explore}} {{the idea of}} using only human pose, without {{utilizing}} any temporal <b>information,</b> <b>for</b> <b>action</b> recognition. In contrast to the other studies using complex action representations, we propose a simple method, which relies on extracting “key poses ” from action sequences. Our contribution is two-fold. Firstly, representing the pose in a frame as a collection of line-pairs, we propose a matching scheme between two frames to compute their similarity. Secondly, after grouping the frames by k-medoids clustering to extract candidate key poses, we rank the potentiality of each candidate becoming a key pose, by means of a learning algorithm. Our experimental results on KTH dataset have shown that pose information by itself is quite effective in grasping the nature of an action and sufficient to distinguish one from the others. 1...|$|E
5000|$|Waiter Boldt — Per Pallesen Background {{character}} who serves mostly as comic relief and an incurable gossip, which at times {{turns out to}} be decisive <b>information</b> <b>for</b> other characters' <b>actions.</b>|$|R
40|$|We {{challenge}} Firestone & Scholl's (F&S's) narrow {{conceptualization of}} what perception is and – most important – {{what it is}} for. Perception guides our (inter) actions with the environment, with attention ensuring that the actor is attuned to <b>information</b> relevant <b>for</b> <b>action.</b> We dispute F&S's misconceived (and counterfactual) view of perception as a module that functions independently from cognition, attention, and action...|$|R
50|$|No {{criminal}} or terrorism {{investigation of}} the person need be in play at time of the Directive. All that need be required is that the target be related to an official desire <b>for</b> intelligence <b>information</b> gathering <b>for</b> <b>actions</b> on part of persons involved in surveillance to be granted full immunity from U.S. criminal or civil procedures, under Section 105B(l) of the Act.|$|R
40|$|In the Brentano {{version of}} the Müller-Lyer {{illusion}} one part looks longer and the other looks shorter than it really is. We asked participants to make saccadic eye movements along these parts of the figure and between positions on the figure and a position outside the illusion. By showing that saccades from outside the figure are not influenced by the illusion, we demonstrate that the reason that saccades along the figure are influenced is that the incorrectly judged length is used to plan the amplitude of the saccade. This finding contradicts several current views {{on the use of}} visual <b>information</b> <b>for</b> <b>action.</b> We conclude that actions are influenced by visual illusions, but that such influences are only apparent if the action is guided by the attribute that is fooled by the illusion. © 2006 Springer-Verlag...|$|E
40|$|Using {{surveillance}} data as <b>information</b> <b>for</b> <b>action,</b> collaborative efforts in Alaska {{have been very}} successful in applying the insights gained from surveillance to the prevention of occupational mortality and serious injury. Specifically, epidemiologic analysis has been effectively applied toward reducing mortality in Alaska's rapidly expanding helicopter logging industry, and has played an important supportive role in tracking the continuing progress made in reducing the mortality rate in Alaska's commercial fishing industry. However, data has also shown that problems persist with prevention of falls overboard in the fishing industry, and other injuries related to the work processes on fishing vessels and fishing vessels stability. Interagency efforts are ongoing to address these factors. " - NIOSHTIC- 2 "May 2002. "Also available via the World Wide Web. Includes bibliographical references (p. 45 - 47) ...|$|E
40|$|Action {{requires}} {{knowledge of}} our body location in space. Here we asked if {{interactions with the}} external world prior to a reaching action influence how visual location information is used. We investigated if the temporal synchrony between viewing and feeling touch modulates the integration of visual and proprioceptive body location <b>information</b> <b>for</b> <b>action.</b> We manipulated the synchrony between viewing and feeling touch in the Rubber Hand Illusion paradigm prior to participants performing a ballistic reaching task to a visually specified target. When synchronous touch was given, reaching trajectories were significantly shifted compared to asynchronous touch. The direction of this shift suggests that touch influences the encoding of hand position for action. On {{the basis of this}} data and previous findings, we propose that the brain uses correlated cues from passive touch and vision to update its own position for action and experience of self-location. 7 page(s...|$|E
40|$|The {{perception}} of risk can provide valuable <b>information</b> <b>for</b> effective <b>action</b> to prevent and mitigate the effects of natural disasters and better development of educational strategies. With this goal has created a test to measure the {{perception of}} volcanic risk. What is the perception of volcanic risk by the people? How are "seen" the Italian volcanoes? These are the questions that have inspired this work...|$|R
40|$|International audienceDepth {{information}} improves skeleton detection, thus skeleton based {{methods are}} the most popular methods in RGB-D action recognition. But skeleton detection working range is limited in terms of distance and viewpoint. Most of the skeleton based action recognition methods ignore fact that skeleton may be missing. Local points-of-interest (POIs) do not require skeleton detection. But they fail if they cannot detect enough POIs e. g. amount of motion in action is low. Most of them ignore spatial-location of features. We cope with the above problems by employing people detector instead of skeleton detector. We propose method to encode spatial-layout of features inside bounding box. We also introduce descriptor which encodes static <b>information</b> <b>for</b> <b>actions</b> with low amount of motion. We validate our approach on: 3 public data-sets. The results show that our method is competitive to skeleton based methods, while requiring much simpler people detection instead of skeleton detection...|$|R
50|$|Verma {{was also}} a member of the Bhopal Group <b>for</b> <b>Information</b> and <b>Action,</b> and participated in every anniversary rally to mark the disaster, as his health deteriorated.|$|R
40|$|In this paper, {{we propose}} an {{effective}} method to recognize human actions from sequences of depth maps, which provide additional body shape and motion <b>information</b> <b>for</b> <b>action</b> recognition. In our approach, we project depth maps onto three orthogonal planes and accumulate global activities through entire video sequences {{to generate the}} Depth Motion Maps (DMM). Histograms of Oriented Gradients (HOG) are then computed from DMM as the representation of an action video. The recognition results on Microsoft Research (MSR) Action 3 D dataset show that our approach significantly outperforms the state-of-the-art methods, although our representation is much more compact. In addition, we investigate how many frames are required in our framework to recognize actions on the MSR Action 3 D dataset. We observe that a short sub-sequence of 30 - 35 frames is sufficient to achieve comparable results to that operating on entire video sequences...|$|E
40|$|In {{the wake}} of the {{economic}} crisis, IT companies being totally dependent on project-based business, need to find ways to score higher profit with minimum resources usage. Measuring business performance and presenting the resulting <b>information</b> <b>for</b> <b>action</b> is one aspect of achieving business success. This paper presents an efficiency measurement model for products produced by organization that has been developed based on a non-parametric technique, called Data Envelopment Analysis. The model optimizes a ratio of multiple weighted outputs to a multiple weighted inputs, where the efficient unit will have a score of one, and the inefficient unit will have a score less than one. The model is simple and practical in implementation. It is hope that the projects which act as the decision making unit can later be used to determine the efficiency of the company department/unit that housed the projects. Projection for inefficient projects has also been provided...|$|E
40|$|One of the {{fundamental}} challenges of human action recognition is accounting for the variability that arises during video capturing. For a specific action class, the 2 D observations of different instances might be extremely different due to varying viewpoint when the sequences are captured by moving cameras. The situation is even worse if the actions are executed at different rates. In this paper, a novel view-invariant human action recognition method is proposed based on non-rigid factorization and Hidden Markov Models (HMMs). By assuming that the execution of an action can be approximated by dynamic linear combination {{of a set of}} basis shapes, we show that the weight coefficients of basis shapes by measurement matrix non-rigid factorization contain crucial <b>information</b> <b>for</b> <b>action</b> recognition regardless of the viewpoint. Based on the extracted discriminative features, the HMMs is used for action modeling and classification. The performance of the proposed method has been successfully demonstrated experimentally using real sequences. 1...|$|E
50|$|The court {{directed}} its {{office to}} send {{copies of the}} judgment {{to the federal government}} and provincial and Islamabad high courts <b>for</b> <b>information,</b> necessary <b>action</b> and compliance.|$|R
5000|$|The plaintiffs' {{reports and}} {{recommendations}} {{were held to}} be [...] "clearly time-sensitive" [...] {{by virtue of the}} fact that the plaintiffs' clients used the <b>information</b> <b>for</b> their <b>actions</b> in anticipation of stock price movement. Moreover, the time-sensitivity was especially important as the plaintiffs expended resources to be the first to communicate these findings to the client and generate commissions revenue. The defendant did not dispute that the plaintiffs' reports and recommendations were time-sensitive.|$|R
40|$|Emerging {{infectious}} diseases {{and the growth}} of information technology have produced new demands and possibilities for disease surveillance and response. Increasing numbers of outbreak reports must be assessed rapidly so that control efforts can be initiated and unsubstantiated reports can be identified to protect countries from unnecessary economic damage. The World Health Organization has set up a process for timely outbreak verification to convert large amounts of data into accurate <b>information</b> <b>for</b> suitable <b>action.</b> We describe the context and processes of outbreak verification and information dissemination...|$|R
40|$|Existing {{classification}} {{schemes and}} thesauri are lacking in well-defined semantics and structural consistency. Empowering end users in searching collections of ever increasing magnitudes with performance far exceeding plain free-text searching (as {{used in many}} Web search engines), and developing systems that not only find but also process <b>information</b> <b>for</b> <b>action,</b> requires far more powerful and complex knowledge organization systems (KOSs). The paper presents a conceptual structure and transition procedure to support the shift from a traditional KOS towards a full-fledged and semantically rich KOS. The proposed structure also complies with other interoperability approaches like RDFS and XML in the Web environment. AGROVOC, a traditional thesaurus developed and maintained by the Food and Agriculture Organization (FAO) of the United Nations, serves {{as a case study}} for exploring the reengineering of a traditional thesaurus into a fully-fledged ontology. We start the process of developing an inventory of specific relationship types with well-defined semantics for the agricultural domain and explore the rules-as-you-go approach to streamlining the reengineering process...|$|E
40|$|Extended Markov Tracking (EMT) is a {{computationally}} tractable {{method for}} the online estimation of Markovian system dynamics. In this paper, we present our initial experimentation with EMT-based control applied to robotic motion. In our experiments, a robot uses a predetermined mapping {{of the world}} onto an abstract model, over which EMT Control is applied; this dictates the choice of an abstract action, {{which in turn is}} mapped back into actual robot operation. Simulations in which a robot was constrained to follow a target show that although the abstract model was (intentionally) only weakly coherent with the real dynamics of the robot’s world, EMT Control was able to provide reasonable performance. We also demonstrate that EMT-provided data provides sensible <b>information</b> <b>for</b> <b>action</b> model calibration. We do so by constructing a calibration scheme based on a training technique and simple data statistics. The scheme is then validated by carrying out additional robot motion control simulations, using the calibrated abstract model. ...|$|E
40|$|In this paper, we {{determine}} whether incomplete videos {{that are often}} discarded carry useful <b>information</b> <b>for</b> <b>action</b> recognition, and if so, how one can represent such mixed collection of video data (complete versus incomplete, and labeled versus unlabeled) in a unified manner. We propose a novel framework to handle incomplete videos in action classification, and make three main contributions: (1) We cast the action classification problem for a mixture of complete and incomplete data as a semi-supervised learning problem of labeled and unlabeled data. (2) We introduce a two-step approach to convert the input mixed data into a uniform compact representation. (3) Exhaustively scrutinizing 280 configurations, we experimentally show on our two created benchmarks that, even the videos are extremely sparse and incomplete, {{it is still possible}} to recover useful information from them, and classify unknown actions by a graph based semi-supervised learning framework. Index Terms — Action classification, sparse video, tensor decomposition, semi-supervised learnin...|$|E
40|$|The authors {{provide the}} {{centralized}} {{data about the}} Romanian caves with endemic fauna, based on all reliable bibliographic sources (as quoted in text and cited in the chapter references) and based on their research activity. The complete list of the Romanian caves with endemic cave-dwelling arthropod species identified up to the subspecies level is presented. The aim of the present paper is to provide {{an easy way to}} consult the aforementioned species list and reliable <b>information</b> <b>for</b> future <b>actions</b> to protect the caves, based on biospeleological data in Romania...|$|R
40|$|This paper {{exploits}} {{the high}} order co-occurrence <b>information</b> <b>for</b> human <b>action</b> representation. Based on the bag-of-words (BoW) model, visual words are mapped into a co-occurrence space through latent semantic analysis (LSA). High order co-occurrence {{of the visual}} words is well captured and therefore the representation of actions in the co-occurrence space becomes more informative and compact. Since the representation is effective and efficient, and is less affected by the sizes of the codebook, it can be easily integrated into models based on BoW. Evaluations on the benchmark KTH dataset and the realistic HMDB 51 dataset demonstrates that the proposed approach significantly improves the baseline BoW model and therefore is promising <b>for</b> human <b>action</b> recognition...|$|R
40|$|In {{line with}} the Theory of Event Coding (Hommel et al., 2001), action {{planning}} {{has been shown to}} affect perceptual processing—an effect that has been attributed to a so-called intentional weighting mechanism (Memelink & Hommel, in press; Wykowska, Schub&# 246;, & Hommel, 2009), whose functional role is to provide <b>information</b> <b>for</b> open parameters of online action adjustment (Hommel, 2010). The aim {{of this study was to}} test whether different types of action representations induce intentional weighting to various degrees. To meet this aim, we introduced a paradigm in which participants performed a visual search task while preparing to grasp or to point. The to-be performed movement was signaled either by a picture of a required action or a word cue. We reasoned that picture cues might trigger a more concrete action representation that would be more likely to activate the intentional weighting of perceptual dimensions that provide <b>information</b> <b>for</b> online <b>action</b> control. In contrast, word cues were expected to trigger a more abstract action representation that would be less likely to induce intentional weighting. In two experiments, preparing <b>for</b> an <b>action</b> facilitated the processing of targets in an unrelated search task if they differed from distractors on a dimension that provided <b>information</b> <b>for</b> online <b>action</b> control. As predicted, however, this effect was observed only if action preparation was signaled by picture cues but not if it was signaled by word cues. We conclude that picture cues are more efficient than word cues in activating the intentional weighting of perceptual dimensions, presumably by specifying not only invariant characteristics of the planned action but also the dimensions of action-specific parameters...|$|R
30|$|Representing the {{features}} {{of different types of}} human action in unconstrained videos is a challenging task due to camera motion, cluttered background, and occlusions. This paper aims to obtain effective and compact action representation with length-variable edge trajectory (LV-ET) and spatio-temporal motion skeleton (STMS). First, in order to better describe the long-term motion <b>information</b> <b>for</b> <b>action</b> representation, a novel edge-based trajectory extracting strategy is introduced by tracking edge points from motion without limiting the length of trajectory; the end of the tracking is depending not only on the optical flow field but also on the optical flow vector position in the next frame. So, we only make use of a compact subset of action-related edge points in one frame to generate length-variable edge trajectories. Second, we observe that different types of action have their specific trajectory. A new trajectory descriptor named spatio-temporal motion skeleton is introduced; first, the LV-ET is encoded using both orientation and magnitude features and then the STMS is computed by motion clustering. Comparative experimental results with three unconstrained human action datasets demonstrate the effectiveness of our method.|$|E
30|$|The methods {{discussed}} above {{are independent of}} human action recognition. The concept of using context <b>information</b> <b>for</b> <b>action</b> recognition has been widely adopted in recent studies. Object detection and pose estimation play important roles {{in the process of}} recognizing human action. Yao and Fei-Fei (2012) proposed a mutual context model to jointly model objects and human poses in human–object interaction activities. Ikizler-Cinbis and Sclaroff (2010) proposed an approach for human action recognition that integrates multiple feature channels from several entities, such as objects, scenes, and humans. Burghouts et al. (2014) used object tracking trajectories as the context for improving threat recognition. Marszalek et al. (2009) proposed the context of natural dynamic scenes for action recognition. The scene information of the video was extracted from the movie script rather than from image sequences. Similarly, in the proposed method, 3 SMF is regarded as the context information of the STIP to recognize human action. In the proposed method, 3 SMF and STIP are extracted to model action. A probability inference algorithm is used to determine the action categories.|$|E
40|$|We {{demonstrate}} that right-handed participants make speeded classification responses to pairs {{of objects that}} appear in standard co-locations for right-handed actions relative to when they appear in reflected locations. These effects are greater when participants "weight" <b>information</b> <b>for</b> <b>action</b> when deciding if 2 objects are typically used together, compared with deciding if objects typically occur in a given context. The effects are enhanced, and affect both types of decision, when an agent is shown holding the objects. However, the effects are eliminated when the objects are not viewed from the first-person perspective and when words are presented rather than objects. The data suggest that (a) participants are sensitive to whether objects are positioned correctly for their own actions, (b) the position information is coded within an egocentric reference frame, (c) the critical representation involved is visual and not semantic, and (d) the effects are enhanced {{by a sense of}} agency. The results can be interpreted within a dual-route framework for action retrieval in which a direct visual route is influenced by affordances for action...|$|E
40|$|The present (third edition) of “Research at the JRC in Support of EU Climate Change Policy Making” {{provides}} {{overview of}} the Joint Research Centre research activities in support of EU climate change policy making. This document also presents activities, coordinated within the JRC’s Climate Change Priority Area, that will contribute to a sound foundation of scientific <b>information</b> <b>for</b> future policy <b>actions...</b>|$|R
40|$|The bicoded {{cognitive}} maps {{described by}} Jeffery et al. are compared to metric perceptual representations. Systematic biases in perceptual experience of egocentric distance, height, and surface orientation may reflect information processing choices to retain <b>information</b> critical <b>for</b> immediate <b>action</b> (Durgin et al. 2010 a). Different information processing goals (route planning vs. immediate action) require different metric information...|$|R
40|$|This chapter {{presents}} {{a new high}} level methodology for the analysis and design of information systems specifically to support routine action at the operational level of organizations. The authors argue that traditional methods fail to adequately address the unique requirements of support <b>for</b> routine operational <b>action.</b> The main innovation of the methodology {{is the use of}} an action-centred approach derived from recent work on the nature of purposeful human action, and as such, emphasises both the <b>information</b> requirements <b>for</b> <b>action</b> and the dependence of action upon appropriately structured environments. A brief case study illustrates how using the methodology can sensitize the analyst to opportunities to increase human efficiency and effectiveness through lighter weight information systems...|$|R
