118|148|Public
50|$|Particle {{filters and}} Feynman-Kac {{particle}} methodologies find application in signal and image processing, Bayesian <b>inference,</b> <b>machine</b> learning, risk analysis and rare event sampling, engineering and robotics, artificial intelligence, bioinformatics, phylogenetics, computational science, Economics and mathematical finance, molecular chemistry, computational physics, pharmacokinetic and other fields.|$|E
50|$|Knowledge {{retrieval}} (KR) {{seeks to}} return {{information in a}} structured form, consistent with human cognitive processes as opposed to simple lists of data items. It draws {{on a range of}} fields including epistemology (theory of knowledge), cognitive psychology, cognitive neuroscience, logic and <b>inference,</b> <b>machine</b> learning and knowledge discovery, linguistics, and information technology.|$|E
50|$|The same {{principle}} of prediction error minimization {{has been used}} to provide an account of behavior in which motor actions are not commands but descending proprioceptive predictions. In this scheme of active inference, classical reflex arcs are coordinated so as to selectively sample sensory input in ways that better fulfill predictions, thereby minimizing proprioceptive prediction errors (Friston, 2009). Indeed, Adams et al. (2013) review evidence suggesting that this view of hierarchical predictive coding in the motor system provides a principled and neurally plausible framework for explaining the agranular organization of the motor cortex. This view suggests that “perceptual and motor systems should not be regarded as separate but instead as a single active <b>inference</b> <b>machine</b> that tries to predict its sensory input in all domains: visual, auditory, somatosensory, interoceptive and, {{in the case of the}} motor system, proprioceptive” (Adams, Shipp, & Friston, 2013).|$|E
40|$|R. Freivalds and C. H. Smith [FS 92] {{proved that}} {{probabilistic}} limited memory inductive <b>inference</b> <b>machines</b> can learn some classes of total recursive functions with a probability I which cannot be learned by deterministic limited memory inductive <b>inference</b> <b>machines.</b> We introduce quantum limited memory inductive <b>inference</b> <b>machines</b> as quantum finite automata used as inductive <b>inference</b> <b>machines.</b> Our main result below shows that quantum limited memory inductive <b>inference</b> <b>machines</b> can learn classes of total recursive functions not learnable by any deterministic and even by probabilistic limited memory inductive <b>inference</b> <b>machines...</b>|$|R
40|$|AbstractFreivalds and Smith [R. Freivalds, C. H. Smith Memory limited {{inductive}} <b>inference</b> <b>machines,</b> Springer Lecture Notes in Computer Science 621 (1992) 19 – 29] {{proved that}} probabilistic limited memory inductive <b>inference</b> <b>machines</b> can learn with probability  1 certain classes of total recursive functions, which cannot be learned by deterministic limited memory inductive <b>inference</b> <b>machines.</b> We introduce quantum limited memory inductive <b>inference</b> <b>machines</b> as quantum finite automata acting as inductive <b>inference</b> <b>machines.</b> These machines, we show, can learn classes of total recursive functions not learnable by any deterministic, nor even by probabilistic, limited memory inductive <b>inference</b> <b>machines...</b>|$|R
50|$|In the mid-1980s, Integrated <b>Inference</b> <b>Machines</b> (IIM) built prototypes of Lisp {{machines}} named Inferstar.|$|R
40|$|Abstract—Based on the {{research}} of the intelligent cataract ultrasonic emulsification instrument, mainly discusses the principle of design and inference algorithm of the <b>inference</b> <b>machine</b> of intelligent ultrasonic emulsification instrument. Designing the cataract expert knowledge base {{by the use of}} relational database, the <b>inference</b> <b>machine</b> can simulate the real doctor thinking features effectively; at the same time, according to the patient's cataract symptoms, it can make intelligent judgment to select the ultrasonic energy level for the emulsifying needle, and effectively control the release of energy. The inference strategy is the combined of deductive reasoning, certainty and forward inference, so as to improve the efficiency of <b>inference</b> <b>machine.</b> Through the verification tests, the system obtains better inference results...|$|E
40|$|Ph. D. ThesisInductive {{inference}} is {{a process}} of hypothesizing a general rule from examples. As a successful inference criterion for inductive inference of formal languages and models of logic programming, we have mainly used Gold 2 ̆ 7 s identification in the limit. An <b>inference</b> <b>machine</b> M is said to infer a concept L in the limit, if the sequence of guesses from M which is successively fed a sequence of examples of L converges to a correct expression of L, that is, all guesses from M become a unique expression in a finite time and that the expression is a correct one. A class, or a hypothesis space, is said to be inferable in the limit, if there is an <b>inference</b> <b>machine</b> M which infers every concept in the class. In the present thesis, we mainly investigate three criteria related to the identification in the limit. As we will see, they are necessary for practical applications of machine learning or machine discovery. The first criterion requires an <b>inference</b> <b>machine</b> to produce a unique guess. That is, we apply so-called finite identification to concept learning. As stated above, ordinary inductive inference is an infinite process. Thus we can not decide in general whether a sequence of guesses from an <b>inference</b> <b>machine</b> has converged or not at a certain time. To the contrary, in the criterion of finite identification, if an <b>inference</b> <b>machine</b> produces a guess, then it is a conclusive answer. The second criterion requires an <b>inference</b> <b>machine</b> to refute a hypothesis space in question, if a target concept is not in the hypothesis space. In the ordinary inductive inference, the behavior of an <b>inference</b> <b>machine</b> is not specified, when we feed examples of a target concept not belonging to the hypothesis space. That is, we implicitly assume that every target concept belongs to the hypothesis space. As far as data or facts are presented according to a concept that is unknown but guaranteed to be in the hypothesis space, the machine will eventually identify the hypothesis. However this assumption is not appropriate, if we want an <b>inference</b> <b>machine</b> to infer or to discover an unknown rule which explains examples or data obtained from scientific experiments. Thus we propose a successful inference criterion where, if there is no concept in the hypothesis space which coincides with a target concept, then an <b>inference</b> <b>machine</b> explicitly tells us this and stops in a finite time. The third criterion requires an <b>inference</b> <b>machine</b> to infer a minimal concept within the hypothesis space concerned. In actual applications of inductive inference, there are many cases where we want an <b>inference</b> <b>machine</b> to infer an approximate concept within the hypothesis space, even when there is no concept which exactly coincides with the target concept. Here we take a minimal concept as an approximate concept within the hypothesis space, and discuss inferability of a minimal concept of the target concept which may not belong to the hypothesis space. That is, we force an <b>inference</b> <b>machine</b> to converge to an expression of a minimal concept of the target concept, if there is a minimal concept of the target concept within the hypothesis space. In the present thesis, we discuss inferability of recursive concepts under the above three criteria, and show some necessary and sufficient conditions for inferability and some comparisons between inferable classes. Furthermore as practical and concrete hypothesis spaces, we take the classes definable by so-called lengt h-bounded elementary formal systems (EFS 2 ̆ 7 s, for short) and discuss their inferability in the above three criteria. In 1990, Shinohara showed that the classes definable by length-bounded EFS 2 ̆ 7 s with at most n axioms are inferable in the limit from positive data for any n 2 : 1. In the present thesis, we show that the above classes are also refutably inferable from complete data, i. e. positive and negative data, as well as minimally inferable from positive data. This means that there are rich hypothesis spaces that are refutably inferable from complete data or minimally inferable from positive data...|$|E
40|$|Abstract. In {{ordinary}} learning paradigm, {{a target}} concept, whose examples are fed to an <b>inference</b> <b>machine,</b> {{is assumed to}} belong to a hypothesis space which is given in advance. However this assumption is not appropriate, if we want an <b>inference</b> <b>machine</b> to infer or to discover an unknown rule which explains examples or data obtained from scientific experiments. In their previous paper, Mukouchi and Arikawa discussed both refut ability and inferability of a hypothesis space from examples. In this paper, we take a minimal concept as an approximate concept within a hypothesis space, and discuss inferability of a minimal concept of the target concept which may not belong to the hypothesis space. That is, we force an <b>inference</b> <b>machine</b> to converge to a minimal concept of the target concept, if there are minimal concepts of the target concept within the hypothesis space. We also show that there are some rich hypothesis spaces that are minimally inferable from positive data. 1...|$|E
40|$|Inductive <b>inference</b> <b>machines</b> are {{algorithmic}} devices which {{attempt to}} synthesize (in the limit) programs for a function while they examine {{more and more}} of the graph of the function. There are many possible criteria of success. We study the inference of nearly minimal size programs. Our principal results imply that nearly minimal size programs can be inferred (in the limit) without loss of inferring power provided we are willing to tolerate a finite, but not uniformly, bounded, number of anomalies in the synthesized programs. On the other hand, there is a severe reduction of inferring power in inferring nearly minimal size programs if the maximum number of anomalies allowed is any uniform constant. We obtain a general characterization for the classes of recursive functions which can be synthesized by inferring nearly minimal size programs with anomalies. We also obtain similar results for Popperian inductive <b>inference</b> <b>machines.</b> The exact tradeoffs between mind change bounds on inductive <b>inference</b> <b>machines</b> and anomalies in synthesized programs are obtained. The techniques of recursive function theory including the recursion theorem are employed...|$|R
40|$|AbstractDegrees of inferability {{have been}} {{introduced}} to measure the learning power of inductive <b>inference</b> <b>machines</b> which have access to an oracle. The classical concept of degrees of unsolvability measures the computing power of oracles. In this paper we determine the relationship between both notions...|$|R
40|$|We examine uniform {{procedures}} {{for improving the}} scientific competence of inductive <b>inference</b> <b>machines.</b> Formally, such procedures are construed as recursive operators. Several senses of improvement are considered, including (a) enlarging the class of functions on which success is certain, and (b) transforming probable success into certain success...|$|R
40|$|Abstract. The paper {{introduces}} {{a method of}} transition from TIL into Prolog system and vice versa, in order to utilize Prolog <b>inference</b> <b>machine</b> in the deductive system of TIL. We specify {{a subset of the}} set of TIL constructions the elements of which can be encoded in Prolog language, and introduce the method of translation from TIL into Prolog. Since Prolog is less expressive than TIL, we have to build up a TIL functional overlay that makes it possible to realize the reverse transition from Prolog into TIL in a near to equivalent way. Key words: TIL, T IL-Script language, <b>inference</b> <b>machine,</b> Prolog...|$|E
40|$|Ground {{investigations}} {{often use}} trial pits and borehole cores on construction sites {{to determine the}} strata likely to be encountered at various depths. The data obtained from trial pits can be coded into a form {{that can be used}} as sample observations for input to a grammatical <b>inference</b> <b>machine.</b> A grammatical <b>inference</b> <b>machine</b> is a black box, which when presented with a sample of observations of some unknown source language, produces a grammar which is compatible with the sample. This article presents a heuristic model for a grammatical <b>inference</b> <b>machine,</b> which takes as data sentences and non-sentences identified as such, and is capable of inferring grammars in the class of context-free grammars expressed in Chomsky Normal Form. An algorithm and its corresponding software implementation have been developed based on this model. The software takes, as input, coded representations of ground investigation data, and produces as output a grammar which describes and classifies the geotechnical data observed in the area, and also promises the possibility of being able to predict the likely configuration of strata across the site...|$|E
40|$|All {{processes}} in a software implemented <b>inference</b> <b>machine</b> are called fuzzy processes. These processes are fuzzification, fuzzy inference and defuzzification, executed in that order. The implementation itself {{is called a}} fuzzy <b>inference</b> <b>machine</b> or a fuzzy logic system. This thesis describes such a system in a parallel implementation with a specific approach, where complex operations are broken down into multiple simpler ones. We used the CUDA architecture, which allows us the usage of general purpose parallel computing on modern GPU’s. At the end we tested this implementation, {{in comparison with the}} sequential implementation on the CPU, by comparing the precision of the computational results and the needed times of operation algorithms...|$|E
50|$|Five running Parallel <b>Inference</b> <b>Machines</b> (PIM) were {{eventually}} produced: PIM/m, PIM/p, PIM/i, PIM/k, PIM/c. The project also produced applications {{to run on}} these systems, such as the parallel database management system Kappa, the legal reasoning system HELIC-II, and the automated theorem prover MGTP, as well as applications to bioinformatics.|$|R
40|$|The {{aggregation}} {{problem is}} to design an inferential agent that makes intelligent use of the theories offered {{by a team of}} inductive <b>inference</b> <b>machines</b> working in a common environment. The present paper formulates several versions of the aggregation problem and investigates them from a recursion theoretic point of view...|$|R
40|$|Contents 1 Introduction 5 1. 1 Scope of course..................................... 5 1. 2 Computers as <b>inference</b> <b>machines...........................</b> 6 1. 3 References........................................ 6 1. 4 Acknowledgement.................................... 6 2 Simulation 7 2. 1 Introduction....................................... 7 2. 2 Issues in simulation................................... 7 2. 3 Buffon's Needle..................................... 7 2. 4 Raw ingredients..................................... 10 2. 5 Simulating from {{specified}} distributions........................ 10 2. 5. 1 Inversion....................... ...|$|R
30|$|Step 4 - 2 Otherwise, {{the score}} shall be calculated. In this paper, {{the design of}} the QoE score is {{accomplished}} by employing intelligent <b>inference</b> <b>machine</b> method to avoid the constraint by linear method, and directly reasoning {{on the basis of the}} parameter indexes.|$|E
40|$|In {{this paper}} we {{describe}} fuzzy rules {{used in the}} developed prototype of a “fuzzy music interpretation system ” [4]. The core of this system consists of two essential units, the rule base and the <b>inference</b> <b>machine.</b> The rule base contains general IF–THEN interpretation rules, formulated by an experienced pianist. The <b>inference</b> <b>machine</b> contains both conventional and advanced fuzzy information processing strategies. Once the system is fed with the information—the notes and special signs such as “ppp ” and “legato”, coded {{in accordance with the}} MIDI format—contained in the score of Beethoven’s “Für Elise”, it generates an interpretation of this piece of music and renders it {{in the form of a}} MIDI file. Certain refinement parameters allow us to modify the character of the interpretation. 1...|$|E
40|$|We outline an {{abstract}} <b>inference</b> <b>machine</b> for producing discourse models in natural language understanding. This machine has tableaux as its central data structure and can operate in model generation and theorem proving modes. Search spaces {{are controlled by}} keeping track of NP saliences and equipping proof rules with costs...|$|E
40|$|Degrees of inferability {{have been}} {{introduced}} to measure the learning power of inductive <b>inference</b> <b>machines</b> which have access to an oracle. The classical concept of degrees of unsolvability measures the computing power of oracles. In this paper we determine the relationship between both notions. 1 Introduction We consider learning of classes of recursive functions {{within the framework of}} inductive inference [21]. A recent theme is the study of inductive <b>inference</b> <b>machines</b> with oracles ([8, 10, 11, 17, 24] and tangentially [12]; cf. [10] for a comprehensive introduction and a collection of all previous results.) The basic question is how the information content of the oracle (technically: its Turing degree) relates with its learning power (technically: its inference degree [...] -depending on the underlying inference criterion). In this paper a definitive answer is obtained for the case of recursively enumerable oracles and the case when only finitely many queries to the oracle are allo [...] ...|$|R
50|$|Variational Bayesian methods, {{a family}} of {{techniques}} for approximating intractable integrals arising in Bayesian <b>inference</b> and <b>machine</b> learning.|$|R
40|$|AbstractThree {{kinds of}} {{restrictions}} on inductive <b>inference</b> <b>machines</b> (IIMs) are considered: postdictive completeness, postdictive consistency, and reliability. It is shown that postdictively consistent IIMs can be effectively replaced with post-dictively complete IIMs that succeed {{to at least}} the same degree. Various loosenings of the notions of postdictive completeness and reliability are considered, {{and a pair of}} related triangular hierarchies is exhibited; IIMs higher (or to the right) in the hierarchies are less restricted and capable of learning more than IIMs lower or to the left. Various conjectures and older results are obtained as corollaries...|$|R
40|$|Enhanced Vision Systems (EVS) are {{currently}} developed {{with the goal}} to alleviate restrictions in airspace and airport capacity in low-visibility conditions. EVS relies on weather penetrating forward-looking sensors that augment the naturally existing visual cues in the environment and provide a real-time image of prominent topographical objects that may be identified by the pilot. In this paper an automatic analysis of millimetre wave radar images for Enhanced Vision Systems is presented. The core {{part of the system}} is a fuzzy rule based <b>inference</b> <b>machine</b> which controls the data analysis based on the uncertainty in the actual knowledge in combination with a-priori knowledge. Compared with standard TV or IR images the quality of MMW images is rather poor and data is highly corrupted with noise and clutter. Therefore, one main task of the <b>inference</b> <b>machine</b> is to handle uncertainties as well as ambiguities and inconsistencies to draw the right conclusions. The output of different sensor data analysis processes are fused and evaluated within a fuzzy/possibilistic clustering algorithm whose results serve as input to the <b>inference</b> <b>machine.</b> The only a-priori knowledge used in the presented approach is the same pilots already know from airport charts which are available of almost every airport. The performance of the approach is demonstrated with real data acquired during extensive flight tests to several airports in Northern Germany...|$|E
40|$|AbstractThe {{notion of}} an {{inductive}} <b>inference</b> <b>machine</b> aggregating a team of inference machines models the problem of making use of several explanations for a single phenomenon. This article investigates {{the amount of information}} necessary for a successful aggregation of the theories given by a team of inference machines. Variations of using different kinds of identification and aggregation are investigated...|$|E
40|$|In {{this article}} we {{formally}} specify and implement a diagnostic agent based on extended logic programming. Motivated by the application of decentralised diagnosis of distributed systems we develop an architecture for such agents that consists of a deliberative layer with a knowledge base, an <b>inference</b> <b>machine</b> and a reactive layer for communication and control. Throughout the layers we employ logic and logic programming to solve these tasks: the knowledge base uses extended logic programming to specify the agent's behaviour and its knowledge about the system to be diagnosed. The <b>inference</b> <b>machine,</b> which provides algorithms to compute diagnoses, {{as well as the}} reactive layer, that realises a meta interpreter for the agent behaviour, are implemented in PVMProlog, wich enhances standard Prolog with message passing facilities. Keywords: Model-based Diagnosis, Multi Agent Systems, Distributed Logic Programming 1 Introduction Real-world diagnosis problems are usually complex, large, and dis [...] ...|$|E
40|$|AbstractA natural ωpLω+ 1 {{hierarchy}} of successively more general criteria of success for inductive <b>inference</b> <b>machines</b> is described {{based on the}} size of sets of anomalies in programs synthesized by such machines. These criteria are compared to others in the literature. Some of our results are interpreted as tradeoff results or as showing the inherent relative-computational complexity of certain processes and others are interpreted from a positivistic, mechanistic philosophical stance as theorems in philosophy of science. The techniques of recursive function theory are employed including ordinary and infinitary recursion theorems...|$|R
40|$|This is {{a report}} of the {{application}} of the Model Generation Theorem Prover developed at ICOT to problems in the theory of finite quasigroups. Several of the problems were previously open. In this paper, we discuss our theorem proving methods, related to those of the existing provers SATCHMO (Manthey, Bry) and OTTER (McCune), and note how parallel processing on the ICOT Parallel <b>Inference</b> <b>Machines</b> was used to obtain high speeds. We then present and discuss our machine-aided investigation of seven problems concerning the existence of types of quasigroup. The field of finite algebra is rich in problems suitabl...|$|R
40|$|This paper {{addresses}} {{the problem of}} semantic segmentation of 3 D point clouds. We extend the <b>inference</b> <b>machines</b> framework of Ross et al. by adding spatial factors that model mid-range and long-range dependencies inherent in the data. The new model is able to account for semantic spatial context. During training, our method automatically isolates and retains factors modelling spatial dependencies between variables that are relevant for achieving higher prediction accuracy. We evaluate the proposed method by using it to predict 17 -category semantic segmentations on sets of stitched Kinect scans. Experimental {{results show that the}} spatial dependencies learned by our method significantly improve the accuracy of segmentation. They also show that our method outperforms the existing segmentation technique of Koppula et al. 1...|$|R
40|$|A model-based optical {{processor}} is introduced for the acquisition and tracking of a satellite {{in close proximity}} to an imaging sensor of a space robot. The type of satellite is known in advance, and a model of the satellite (which exists from its design) is used in this task. The model base is used to generate multiple smart filters of the various parts of the satellite, which are used in a symbolic multi-filter optical correlator. The output from the correlator is then treated as a symbolic description of the object, which is operated upon by an optical inference processor to determine the position and orientation of the satellite and to track it as a function of time. The knowledge and model base also serves to generate the rules used by the <b>inference</b> <b>machine.</b> The <b>inference</b> <b>machine</b> allows for feedback to optical correlators or feature extractors to locate the individual parts of the satellite and their orientations...|$|E
40|$|Bayesian {{reasoning}} {{has been}} applied formally to statistical <b>inference,</b> <b>machine</b> learning and analyzing scientific method. Here I apply it informally to more common forms of inference, namely natural language arguments. I analyze a variety of traditional fallacies, deductive, inductive and causal, and find more merit in them than is generally acknowledged. Bayesian principles {{provide a framework for}} understanding ordinary arguments which is well worth developing...|$|E
40|$|Introduction Computational vision can {{perceived}} of as {{the process}} of using an <b>inference</b> <b>machine</b> to infer information on {{a higher level of}} abstraction from the information given in terms of images. Images are typically represented as a list of numbers. The higher level of abstraction is defined in terms of an output space. Examples of output spaces are the set of all possible depth maps, a list of physical objects which are to be recognised, a list of possible actions for a robot, or any other set of possible results of a visual process. Common for all these different types of output is that they have an interpretation in 3 D space. We can interpret the output of the <b>inference</b> <b>machine</b> in the same domain as the input. Thereby, the inference loop is closed, which is necessary to construct a machine performing inference. In computer vision, we measure in 3 D space and infer knowledge of structures in 3 D space. We need a machine which can infer from the input space into the output sp...|$|E
40|$|Meta-programming is a {{well-known}} technique widely used in logic programming and artificial intelligence. Meta-interpreters are powerful tools especially for writing expert systems in general and for writing their <b>inference</b> <b>machines</b> in particular. While the classical approach to meta-interpretation {{is based on the}} syntactic definition of a meta-interpreter, new approach presented in this paper corresponds more to the meaning of the prefix meta. We analyze the structure of expert systems (problem solvers) to specify a general description of a meta-interpreter. On that basis, we define the concept of a generalized meta-interpreter which we call a mega-interpreter. The mega-interpreter is divided into two parts – the kernel and its extension. While the kernel codes the functions that are common to most interpreters, the extension specifies the domain-specific functions of a particular interpreter. 1...|$|R
40|$|Parallel <b>inference</b> <b>machines</b> {{reduce the}} {{evaluation}} time in object recognition tasks. However, the exploding search space restricts {{the use of}} parallel search methods for complex demands. Intelligent software agents as concurrently working units are able to coordinate their capacity for work. Thus, agent-based object recognition is able to concentrate the available resources on regions of the environment with high interest. This paper describes an agent-based system architecture that combines the flexibility of cooperating software agents with the advantages of parallel image recognition. Key words: Computer Vision, Intelligent Agents, Distributed Artificial Intelligence, Parallel Processing 1 INTRODUCTION Since {{the inclusion of the}} second stream in agent theory in the early nineties the agent paradigm becomes an interesting aspect in many applications [5]. However, to apply agent-based techniques a problem should have some basic characteristics. E. g., agents are suitable to model c [...] ...|$|R
40|$|Exploitation of {{architectural}} support for Prolog-like languages takes {{one of two}} main paths: compiler-based or interpreter-based. The former scheme enforces the transformation from a logic program {{to a set of}} instructions tailored for Prolog to accommodate the instruction-driven von Neumann processor, while the latter implements a complicated inference procedure as a microinterpreter to realize the relation-driven paradigm of logic programming. In this paper, we present a new sequential control model developed {{in the design of the}} LI-Engine. The control unit of LI-Engine is designed by fully exploiting the simplicity of the relation-driven paradigm. The proposed algorithm adopts the post-choice method and involves only four basic cache operations, ten assignments and four iterators controlled by simple Boolean tests. We believe that this research offers another possible direction for developing high performance logic <b>inference</b> <b>machines.</b> 1 Introduction In the last ten years, many archi [...] ...|$|R
