55|15|Public
40|$|The {{introduction}} of in vitro methodologies in the toxicological risk assessment process requires {{a number of}} prerequisites regarding both the toxicodynamics and the biokinetics of the compounds under study. In vitro systems {{will need to be}} relevant for measuring those structural and physiological changes that are good indicators for adverse effects. Furthermore, the <b>dose</b> <b>metric</b> found to have an effect in the in vitro system should be relevant. One element in defining the appropriate <b>dose</b> <b>metric</b> is related to the kinetic behavior of the compound in the in vitro system: binding to proteins, binding to plastic, evaporation, and the interaction between the culture medium and the cells. Ways to measure and model "in vitro biokinetics" are described. Second, the appropriate <b>dose</b> <b>metric</b> in vitro, e. g., the effective concentration, will need to be extrapolated to relevant in vivo exposure scenarios. The application of physiologically based biokinetic modelling is essential in such extrapolations. The parameters needed to build these models often can be estimated based on nonanimal data, namely chemical properties (QSARs) and in vitro experiments...|$|E
40|$|Nano{{particles}} are particles with {{a maximum}} size of 100 nm {{in at least one}} dimension. Nanoparticles are released by both natural and anthropogenic sources. Up until now only exposure limit values are present for bulk size substances. However, nanoparticles might have different health effects and or dose-response relationships. It is believed that small particles might have greater reactivity potential, e. g. inflammatory effects per unit mass. Since nanoparticles might have different health effects and or dose-response relationships compared with bulk size (micrometer size and above) particles, {{there is a need to}} evaluate the feasibility of deriving exposure limit values for these type of particles. Inhalation exposure to nanoparticles can cause, among others, local inflammatory effects. These effects are partly dependent on location of deposition of the particles in the lungs, which dependents on particle size. Physical phenomena like agglomeration and aggregation of nanoparticles can change the particle size and thereby the location deposition. Agglomeration/aggregation can also include several different substances, increasing the complexity of the exposure, but also the complexity of the health effect. Exposure limits are determined by combining exposure and hazard parameters. It is essential that both factors are available. Hazardous substances are identified and the effect is quantified in a dose-response relationship. Exposure assessment focuses on the possible concentrations present during exposure scenarios. The research of both exposure assessment and toxicology for nano particles is in the developing stage. First attempts are made to derive exposure limit values for nano sized materials. Surface area is a metric which is believed to be important when nanoparticles are involved. However, more than one type of surface area metrics can be defined, which may vary in biological relevancy and complexity, dependent on several biological processes. Lung deposited surface area concentration and lung fluid available surface area seem to be the most relevant metrics. The concept of surface area is only believed to be relevant for insoluble particles, as soluble particles will dissolve in the lung fluid, making mass concentration the only relevant metric. At this moment, there is no consensus about surface area as a <b>dose</b> <b>metric</b> or an exposure metric. In toxicology, surface area as a <b>dose</b> <b>metric</b> is not yet accepted to be the most relevant <b>dose</b> <b>metric,</b> leaving only few studies with surface area as the <b>dose</b> <b>metric.</b> Toxicological studies using this type of <b>dose</b> <b>metric</b> often do not use a surface area per volume metric, but only total or calculated surface area, or surface area, normalized for lung weight. Surface area as the <b>dose</b> <b>metric</b> in exposure limits has potency as efforts are made to increase knowledge on dose-response relationships and exposure assessment methods based on surface area. At present however, data lacks in order to derive exposure limits with surface area as the <b>dose</b> <b>metric...</b>|$|E
40|$|Nanoparticles (NPs) exhibit special {{physicochemical}} properties {{compared to}} bulk particles. The difference in properties could, in principle, produce different effects on organisms. It is therefore important {{to determine the}} relationship between the physicochemical characteristics of NPs and their toxicity profile, by means of experimental testing. Experimental toxicity testing data {{can also be used to}} find the best <b>dose</b> <b>metric</b> for the responses induced by NPs, which was the purpose of the research presented in this thesis. Furthermore, this thesis aims to move forward from toxicity testing primarily in animal models to computational <b>dose</b> <b>metric</b> modeling. Promotor: W. J. G. M. Peijnenburg, Co-promotor: M. G. VijverWith summary in Dutc...|$|E
40|$|The {{biological}} consequences upon {{exposure of}} cells in culture to {{a dose of}} xenobiotic are not only dependent on biological variables, but also the physical aspects of experiments e. g. cell number and media volume. Dependence on physical aspects is often overlooked due to the unrecognized ambiguity in the dominant metric used to express exposure, i. e. initial concentration of xenobiotic delivered to the culture medium over the cells. We hypothesize that for many xenobiotics, specifying dose as moles per cell will reduce this ambiguity. Dose as moles per cell can also provide additional information not easily obtainable with traditional dosing metrics. Here, 1, 4 -benzoquinone and oligomycin A are used as model compounds to investigate moles per cell as an informative <b>dosing</b> <b>metric.</b> Mechanistic insight into reactions with intracellular molecules, differences between sequential and bolus addition of xenobiotic {{and the influence of}} cell volume and protein content on toxicity are also investigated. When the dose of 1, 4 -benzoquinone or oligomycin A was specified as moles per cell, toxicity was independent of the physical conditions used (number of cells, volume of medium). When using moles per cell as a dose-metric, direct quantitative comparisons can be made between biochemical or biological endpoints and the dose of xenobiotic applied. For example, the toxicity of 1, 4 -benzoquinone correlated inversely with intracellular volume for all five cell lines exposed (C 6, MDA-MB 231, A 549, MIA PaCa- 2, and HepG 2). Moles per cell is a useful and informative <b>dosing</b> <b>metric</b> in cell culture. This <b>dosing</b> <b>metric</b> is a scalable parameter that: can reduce ambiguity between experiments having different physical conditions; provides additional mechanistic information; allows direct comparison between different cells; affords a more uniform platform for experimental design; addresses the important issue of repeatability of experimental results, and could increase the translatability of information gained from in vitro experiments...|$|R
40|$|Propofol is an {{intravenous}} {{anaesthetic agent}} {{used for the}} induction and maintenance of general anaesthesia and sedation. Current strategies for dosing propofol incorporate either total body weight (TBW) or inaccurate measures of body composition in their calculations, which result in excessive doses in the obese. The global aim of this thesis was to explore the use of lean body weight (LBW) to describe propofol clearance (CL), and thus investigate its potential {{to be used as}} a propofol <b>dosing</b> <b>metric</b> across the whole adult population. The thesis begins with a review of the literature and introduction in Chapter 1, including a background on obesity, pharmacokinetic-pharmacodynamic (PKPD) analysis and covariate selection, body size metrics and a review of propofol PK and PD. The chapter concludes with a statement of the specific research aims. This is followed by a commentary in Chapter 2 on the inadequacy of current methods of propofol dosing for the obese population and encouragement for development of universal dosing strategies that consider body composition. Chapter 3 describes a simulation-estimation study in which LBW was substituted as a covariate for a nonlinear TBW relationship on CL in a prior PK model for propofol. This was performed as a preliminary study to explore the ability of LBW to describe a reported nonlinear increase in CL with TBW in the absence of original PK data. Results showed that the LBW model had similar predictive properties to the empirically derived original model, suggesting that LBW may provide a mechanistic explanation for a nonlinear increase in propofol CL with TBW. Simulations using this updated model demonstrate that LBW as a <b>dosing</b> <b>metric</b> may help to normalise plasma concentrations across a range of subject TBW. A population pharmacokinetic analysis of propofol is presented in Chapter 4. In this study, three covariate models were developed using data obtained from the Open TCI Initiative for 408 adult subjects (including 30 obese) : a model including the best statistical size covariate on CL, a model including LBW to describe CL and another with TBW describing CL. Results showed that the LBW model described the data as well as the best statistical model, which included body surface area on CL, and was superior to the TBW model, which overpredicted CL in the obese subset. Given that LBW provides a mechanistic explanation for an increase in CL with size, it is proposed that LBW may be suitable for use as a linear propofol infusion <b>dosing</b> <b>metric.</b> Target controlled infusion simulations across a range of subject TBW were also performed to demonstrate the difference between infusion rates calculated using the LBW model and those calculated using two other PK models currently used in clinical practice that overdose the obese. Chapter 5 presents a pharmacodynamic analysis and simulation study that explores the use of different body size metrics including TBW, LBW and an empirical ‘corrected weight’ (CW) for dosing. CW has been suggested for propofol dose normalisation in obese patients because of concerns that a linear dose per kg TBW strategy may result in overdose. Respiratory depression upon induction of anaesthesia and time to awakening at end of dosing were compared between dose strategies, both of which cause concern for anaesthetists when dosing their obese patients. Results showed that dosing according to TBW resulted in increased respiratory depression and increased time to awakening in the obese compared to healthy TBW subjects, whereas CW and LBW dosing resulted in improved PD profiles, reducing the extent of respiratory depression and normalising time to awakening in the obese subject group. It is proposed that the success of CW for dosing obese patients is due to its correlation with LBW, but that LBW is superior as a <b>dosing</b> <b>metric</b> due to its mechanistic nature and applicability to the whole adult population. Evidence for the LBW hypothesis for drug CL arose, in part, from the findings of a literature review that specifically investigated the use of body size metrics for describing CL in the obese population. Chapter 6 builds upon this work, describing a literature survey from 2000 to 2007 that aimed to explore the use of covariates for describing CL in PK analyses performed in any patient group. In particular, the success of different body size metrics as covariates on CL is explored. The work presented in this thesis provides evidence for the use of LBW as a <b>dosing</b> <b>metric</b> for propofol and may help contribute to development of optimised dose strategies that are appropriate for use across the whole adult population. This is of great importance given the increasing prevalence of obesity worldwide...|$|R
40|$|Basic health science research, which {{includes}} cell culture, typically underpins clinical and toxicological research. The results {{are used to}} predict biological effects of xenobiotics, e. g. environmental toxins and drugs, in humans. A goal of this research program was to apply aspects of quantitative redox biology to three separate, but interrelated projects that address improvements {{that can be made}} to evidence-based biological and toxicological research. This includes using absolute quantitation: to improve the specification of dose of xenobiotics added to cell culture systems; to determine absolute differences between the antioxidant capacity of tumor and normal cells; and to predict the implications of this new knowledge on the use of pharmacological ascorbate as an adjuvant in cancer therapy. Dose is a central parameter in determining the biological consequences of a xenobiotic; however, the dose of a xenobiotic at which these consequences are observed is dependent not only on biological variables, but also the physical aspects of cell culture experiments (i. e. cell number, medium volume). This is often overlooked due to the unrecognized ambiguity in the dominant metric used to express dose, i. e. initial concentration of xenobiotic. We hypothesized that specifying the dose of xenobiotics absolutely (as moles of xenobiotic per cell; mol cell- 1) will reduce this ambiguity and provide additional information that is difficult to discern when traditional dosing metrics (initial concentration) are used. We investigated the use of mol cell- 1 as an informative <b>dosing</b> <b>metric</b> using two model compounds: 1, 4 -benzoquinone and oligomycin A. When the dose of these two compounds was specified as mole cell- 1, the toxicity observed was independent of the physical conditions used (i. e. number of cells, volume of medium). This makes it a scalable <b>dosing</b> <b>metric</b> that reduces ambiguity between experiments having different physical conditions; allows direct comparison between different cell types; addresses the important issue of repeatability of experimental results, and could increase the translatability of information gained from in vitro experiments. We utilized quantitative methods to explore the absolute differences in the ability of tumor vs. normal cells to remove H 2 O 2 and how this impacts the use of pharmacological ascorbate as an adjuvant in cancer therapy. Ascorbate (AscH-, vitamin C) functions as a versatile reducing agent. At pharmacological doses (P-AscH-, plasma levels ≥ 20 mM), achievable through IV delivery, the oxidation of ascorbate can produce a high flux of H 2 O 2 in tumors. We hypothesized that the increased sensitivity of tumor cells to P-AscH- compared to normal cells (i. e. non-transformed) is due to their lower capacity to remove H 2 O 2. The rate constants (kcell) for removal of H 2 O 2 revealed a differential in the capacity of cells to remove H 2 O 2, with the average kcell for normal cells (N = 10) being twice that of tumor cells (N = 15). The ED 50 of P-AscH- correlated directly with the capacity of cells to remove H 2 O 2. Quantitation made it possible to make comparisons across very different cell lines on an absolute basis. These results indicate that the capacity of cells to remove H 2 O 2 varies widely and in vivo measurement of this may predict which tumors may respond best to P-AscH- therapy. By designing experiments that begin with a quantitative <b>dosing</b> <b>metric</b> and utilize quantitation to produce absolute information from the results of experiments, we can better leverage data. We propose that this will lead to better predictions from such experiments. These enhancements to in vitro cell culture studies will increase the success in translation of data from in vitro experiments to in vivo animal studies and ultimately impact the success of extrapolation of basic science research to human clinical studies...|$|R
40|$|A {{number of}} studies have shown that {{induction}} of pulmonary toxicity by nanoparticles of the same chemical composition depends on particle size, which is likely in part due to differences in lung deposition. Particle size mostly determines whether nanoparticles reach the alveoli, and where they might induce toxicity. For the risk assessment of nanomaterials, there is need for a suitable <b>dose</b> <b>metric</b> that accounts for differences in effects between different sized nanoparticles of the same chemical composition. The aim of the present study is to determine the most suitable <b>dose</b> <b>metric</b> to describe the effects of silver nanoparticles after short-term inhalation. Rats were exposed to different concentrations (ranging from 41 to 1105 μg silver/m 3 air) of 18, 34, 60 and 160 nm silver particles for four consecutive days and sacrificed at 24 h and 7 days after exposure. We observed a concentration-dependent increase in pulmonary toxicity parameters like cell counts and pro-inflammatory cytokines in the bronchoalveolar lavage fluid. All results were analysed using the measured exposure concentrations in air, the measured internal dose in the lung and the estimated alveolar dose. In addition, we analysed the results based on mass, particle number and particle surface area. Our study indicates that using the particle surface area as a <b>dose</b> <b>metric</b> in the alveoli, the dose-response effects of the different silver particle sizes overlap for most pulmonary toxicity parameters. We conclude that the alveolar dose expressed as particle surface area is the most suitable <b>dose</b> <b>metric</b> to describe the toxicity of silver nanoparticles after inhalation...|$|E
40|$|AbstractTo quantitatively {{assess the}} {{effectiveness}} of proton therapy for individual patients, we developed a prototype for an online platform for proton decision support (PRODECIS) comparing photon and proton treatments on <b>dose</b> <b>metric,</b> toxicity and cost-effectiveness levels. An evaluation was performed with 23 head and neck cancer datasets...|$|E
40|$|Over {{the past}} few years, the "critical body residue" {{approach}} for assessing toxicity based on bioaccumulated chemicals {{has evolved into a}} more expansive consideration of tissue residues as the <b>dose</b> <b>metric</b> when defining dose-response relationships,evaluating mixtures, developing protective guidelines, and conducting risk assessments. Hence, scientists refer to "tissue residue approach for toxicity assessment" or "tissue residue-effects approach" (TRA) when addressing ecotoxicology issues pertaining to tissue (or internal) concentrations. This introduction provides an overview of a SETAC Pellston Workshop held in 2007 to review the state of the science for using tissue residues as the <b>dose</b> <b>metric</b> in environmental toxicology. The key findings of the workshop are presented, along with recommendations for research to enhance understanding of toxic responses within and between species, and to advance the use of the TRA in assessment and management of chemicals in the environment...|$|E
50|$|From 1999 to 2002, PetMed Express and SaveMax {{were charged}} with violating the {{pharmaceutical}} law in several states. In one instance it was fined by the Environmental Protection Agency for selling drugs in <b>metric</b> <b>doses,</b> and has also received a warning letter from the FDA for selling misbranded drugs.|$|R
40|$|OLD {{and small}} and quaint. The eighteenth edition {{of this book}} first {{published}} in 1882, is 7 X 10 O. 6 X 1. 4 cm. in size and weighs 90 G. It fits the smallest pocket in my waistcoat. <b>Doses</b> are all <b>metric.</b> Prescriptions and remedies are listed rather arbitarily under disease headings-both sciatica and scurvey come under "General and Metabilic Diseases "- and I {{found it difficult to}} find what I wanted because drugs are nol listed in the index. There is a section on "Some Modern Remedies " which includes some proprietory preparations which would be better omitted and there is another section rather quaintly entitled "Selected National Formulae": I had hoped this would contain the medical equivalent of Mrs. Beeton's Scottish haggis and Italian risotto; it contains a selection of monographs from the British National formulary. I think the British National Formulary is better value an...|$|R
40|$|Objective: To {{assess how}} well the defined daily <b>dose</b> (DDD) <b>metric</b> {{reflects}} opioid utilisation among chronic non-cancer pain patients. Design: Descriptive, cross-sectional study, utilising a 7 -day medication diary. Setting: Community-based treatment settings, Australia. Subjects: A sample of 1101 people prescribed opioids for chronic non-cancer pain. Methods: Opioid dose data was collected via a self-completed 7 -day medication diary capturing names, strengths and doses of each medication taken in the past week. Median daily dose was calculated for each opioid. Comparisons {{were made to the}} World Health Organization 2 ̆ 7 s (WHO) DDD metric. Results: WHO DDDs ranged from 0. 6 to 7. 1 times the median opioid doses used by the sample. For transdermal fentanyl and oral hydromorphone, the median dose was comparable with the DDD. The DDD for methadone was 0. 6 times lower than the median doses used by this sample of chronic pain patients. In contrast, the DDD for oxycodone and transdermal buprenorphine, the most commonly used strong opioids for chronic pain in Australia, was two to seven times higher than actual doses used. Conclusions: For many opioids, there are key differences between the actual doses used in clinical practice and the WHO 2 ̆ 7 s DDDs. The interpretation of opioid utilisation studies using population-level DDDs may be limited, and a recalibration of the DDD for many opioids or the reporting of opioid utilisation in oral morphine equivalent doses is recommended. Copyrigh...|$|R
40|$|To quantitatively {{assess the}} {{effectiveness}} of proton therapy for individual patients, we developed a prototype for an online platform for proton decision support (PRODECIS) comparing photon and proton treatments on <b>dose</b> <b>metric,</b> toxicity and cost-effectiveness levels. An evaluation was performed with 23 head and neck cancer datasets. (C) 2016 The Authors. Published by Elsevier Ireland Ltd...|$|E
40|$|The paper {{presents}} a case-study of skin fibromas among male rats in the 2 -year cancer bioassay of methyleugenol that {{was conducted by}} the US National Toxicology Program (NTP). In animal carcinogenicity experiments such as this one, tumour rates are often compared with the Cochran-Armitage (CA) trend test. The operating characteristics of the CA test, however, can be adversely affected by survival differences across groups and by the assumed <b>dose</b> <b>metric.</b> Survival-adjusted generalizations of the CA test have been proposed, {{but they are still}} sensitive to the choice of scores that are assigned to the dose groups. We present an alternative test, which outperforms the survival-adjusted CA test which is currently used by the NTP to compare incidence rates. Simulated data {{from a wide range of}} realistic situations show that the operating characteristics of the test proposed are superior to those of the NTP's survival-adjusted CA test, especially for rare tumours and wide logarithmic spacings of the <b>dose</b> <b>metric.</b> Copyright 2005 Royal Statistical Society. ...|$|E
40|$|AbstractIn {{this study}} we provide {{guidance}} on the biologically most relevant <b>dose</b> <b>metric</b> for pulmonary toxicity of biopersistent, spherical nanoparticles (NPs). A retrospective analysis of nine in vivo studies on particle-induced, acute pulmonary toxicity in animal models (mouse, rat) was performed encompassing five different types of nanomaterials (polystyrene, titanium dioxide, carbonaceous materials, transition metal oxides (Co, Ni, Zn) and hydrothermally synthesized α-quartz) {{with a wide range}} of primary particle diameters (9 – 535 nm) and mass-specific BET surface areas (6 – 800 m 2 /g). The acute influx of polymorphonuclear neutrophils (PMNs) into the lungs after intratracheal instillation of NPs was chosen as a toxicological endpoint for acute lung inflammation. The allometrically scaled toxicological data were investigated with respect to various dose metrics, namely (primary) particle number, joint length, BET and geometric surface area, volume and mass. Surface area is identified as the biologically most relevant <b>dose</b> <b>metric</b> for spherical NPs explaining about 80 % of the observed variability in acute pulmonary toxicity (R 2 = 0. 77). None of the other dose metrics explains more than 50 % of the observed variability in pulmonary inflammation. Moreover, using surface area as the <b>dose</b> <b>metric</b> allows identification of material-based toxicity classes independent of particle size. Typical materials without intrinsic toxicity – here referred to as low-solubility, low-toxicity (LSLT) materials – show low surface-specific toxicity with an EC 50 dose of 175 m 2 /g-lung (geometric mean; σg= 2. 2), where EC 50 represents the dose inducing 50 % of the maximum effect (here 30 % PMN). In contrast, transition metal oxides (here Co, Ni, Zn) – materials known for their intrinsic toxicity – display a 12 -fold enhanced surface-specific toxicity compared to LSLT particles (EC 50 = 15 m 2 /g-lung). This analysis implies that surface-related modes of action are driving acute pulmonary toxicity for the types of NPs investigated here. The relevance of other dose metrics such as number and volume is acknowledged in the context of different modes of action, namely shape-induced toxicity (fiber paradigm) and extremely high particle lung burden (overload conditions), respectively. So which <b>dose</b> <b>metric</b> should be monitored by aerosol scientists involved in health related aerosol exposure measurements? The short answer is – all of them (except length), but there is a strong preference towards surface area...|$|E
40|$|AbstractThere is {{debate about}} the utility of {{clinical}} data warehouses for research. Using a clinical warfarin dosing algorithm derived from research-quality data, we evaluated the data quality of both a general-purpose database and a coagulation-specific database. We evaluated the functional utility of these repositories by using data extracted from them to predict warfarin dose. We reasoned that high-quality clinical data would predict doses nearly as accurately as research data, while poor-quality clinical data would predict doses less accurately. We evaluated the Mean Absolute Error (MAE) in predicted weekly <b>dose</b> as a <b>metric</b> of data quality. The MAE was comparable between the clinical gold standard (10. 1 mg/wk) and the specialty database (10. 4 mg/wk), but the MAE for the clinical warehouse was 40 % greater (14. 1 mg/wk). Our {{results indicate that the}} research utility of clinical data collected in focused clinical settings is greater than that of data collected during general-purpose clinical care...|$|R
40|$|Radiation therapy aims at {{delivering}} a prescribed amount of radiation dose to cancerous targets while sparing dose to normal organs. Treatment planning and delivery in modern radiotherapy are highly complex. To ensure {{the accuracy of}} the delivered dose to a patient, a quality assurance (QA) procedure is needed before the actual treatment delivery. This dissertation aims at developing computational and physical tools to facilitate the QA process. In Chapter 2, we have developed a fast and accurate computational QA tool using a graphics processing unit based Monte Carlo (MC) dose engine. This QA tool aims at identifying any errors in the treatment planning stage and machine delivery process by comparing three dose distributions: planned dose computed by a treatment planning system, planned dose and delivered dose reconstructed using the MC method. Within this tool, several modules have been built. (1) A denoising algorithm to smooth the MC calculated dose. We have also investigated the effects of statistical uncertainty in MC simulations on a commonly used <b>dose</b> comparison <b>metric.</b> (2) A linear accelerator source model with a semi-automatic commissioning process. (3) A fluence generation module. With all these modules, a web application for this QA tool with a user friendly interface has been developed to provide users with easy access to our tool, facilitating its clinical utilizations. Even after an initial treatment plan fulfills the QA requirements, a patient may experience inter-fractional anatomy variations, which compromise the initial plan optimality. To resolve this issue, adaptive radiotherapy (ART) has been proposed, where treatment plan is redesigned based on most recent patient anatomy. In Chapter 3, we have constructed a physical deformable head and neck (HN) phantom with in- vivo dosimetry capability. This phantom resembles HN patient geometry and simulates tumor shrinkage {{with a high level of}} realism. The ground truth deformation field can be measured from built-in surface markers, which is then used to verify the accuracy of an important ART step of deformable image registration. Our experiments also demonstrate the feasibility of using this phantom as an end-to-end ART QA phantom with an emphasis on testing the dose deliver accurac...|$|R
40|$|Recently, {{researchers}} have been investigating {{the use of a}} new imaging modality called dedicated breast CT as a means of alleviating the problem of tissue superposition that comes from acquiring a two-dimensional image of a three-dimensional object in conventional mammography. Several groups have investigated the optimal spectrum for this new imaging modality using the dose efficiency as the FOM, but results are inconsistent. None of these groups have employed the use of bowtie filtration in their optimal spectrum studies. Given the right design, the inclusion of bowtie filtration will lead to improved dose efficiency as well as consistency in the metric independent of position in a given phantom. Bowtie filters can improve performance in several ways, including DR reduction, scatter reduction, patient dose reduction, and reduction of beam-hardening effects. In this dissertation, three different filter types with different choices for the tradeoffs between the performance improvements listed above are described. Examples of each type of bowtie filter are created for computational and Monte Carlo analyses, and two designs were fabricated for experimental analysis. Studies analyzing the material selection for each bowtie filter design and characterizing the scatter were also completed. Verification of the performance of the designs was done by calculating/measuring the HVL, intensity, and µeff behind the phantom as a function of fan-angle. The performance of the designs depended only weakly on incident spectrum and tissue composition. With various breast diameters, the calculated parameters varied the most, but the variation was substantially less than the no-bowtie filter case. For all designs, the DR requirement on the detector was reduced compared to the no-bowtie filter case. Simulation and experimental data showed that the use of our bowtie filters can reduce the peripheral dose to the breast by 61 %, and provide uniform noise and CNR distributions. The best performing bowtie filter design was implemented in simulation studies analyzing the optimal spectrum through calculation of the <b>dose</b> efficiency <b>metric.</b> The results from this study show the improvement and consistency that can be obtained with the inclusion of the proper bowtie filter, and provide the research community with a methodology that will help lead to more consistent optimal spectrum results...|$|R
40|$|Abstract Background The {{production}} {{and use of}} nanoparticles is growing rapidly due to the unique {{physical and chemical properties}} associated with their nano size and large surface area. Since nanoparticles have unique physicochemical properties, their bioactivity upon exposure to workers or consumers is of interest. In this study, the issue of what <b>dose</b> <b>metric</b> (mass dose versus surface area dose) is appropriate for toxicological studies has been addressed. Rats were exposed by intratracheal instillation to various doses of ultrafine or fine TiO 2. At 1, 7, or 42 days post-exposure, inflammatory and cytotoxic potential of each particle type was compared on both a mass dosage (mg/rat) as well as an equal surface area dosage (cm 2 of particles per cm 2 of alveolar epithelium) basis. Results The findings of the study show that on a mass basis the ultrafine particles caused significantly more inflammation and were significantly more cytotoxic than the fine sized particles. However, when doses were equalized based on surface area of particles delivered, the ultrafine particles were only slightly more inflammogenic and cytotoxic when compared to the fine sized particles. Lung burden data indicate that ultrafine TiO 2 appears to migrate to the interstitium to a much greater extent than fine TiO 2. Conclusion This study suggests that surface area of particles may be a more appropriate <b>dose</b> <b>metric</b> for pulmonary toxicity studies than mass of particles. </p...|$|E
40|$|BackgroundThe {{production}} {{and use of}} nanoparticles is growing rapidly due to the unique {{physical and chemical properties}} associated with their nano size and large surface area. Since nanoparticles have unique physicochemical properties, their bioactivity upon exposure to workers or consumers is of interest. In this study, the issue of what <b>dose</b> <b>metric</b> (mass dose versus surface area dose) is appropriate for toxicological studies has been addressed. Rats were exposed by intratracheal instillation to various doses of ultrafine or fine TiO 2. At 1, 7, or 42 days post-exposure, inflammatory and cytotoxic potential of each particle type was compared on both a mass dosage (mg/rat) as well as an equal surface area dosage (cm 2 of particles per cm 2 of alveolar epithelium) basis. ResultsThe findings of the study show that on a mass basis the ultrafine particles caused significantly more inflammation and were significantly more cytotoxic than the fine sized particles. However, when doses were equalized based on surface area of particles delivered, the ultrafine particles were only slightly more inflammogenic and cytotoxic when compared to the fine sized particles. Lung burden data indicate that ultrafine TiO 2 appears to migrate to the interstitium to a much greater extent than fine TiO 2. ConclusionThis study suggests that surface area of particles may be a more appropriate <b>dose</b> <b>metric</b> for pulmonary toxicity studies than mass of particles...|$|E
40|$|AbstractPhotodynamic therapy (PDT) is {{generally}} {{based on the}} generation of highly reactive singlet oxygen (1 O 2) through interactions of photosensitizer, light, and oxygen (3 O 2). These three components are highly interdependent and dynamic, resulting in variable temporal and spatial 1 O 2 dose deposition. Robust dosimetry that accounts for this complexity could improve treatment outcomes. Although the 1270  nm luminescence emission from 1 O 2 provides a direct and predictive PDT <b>dose</b> <b>metric,</b> {{it may not be}} clinically practical. We used 1 O 2 luminescence (or singlet oxygen luminescence (SOL)) as a gold-standard metric to evaluate potentially more clinically feasible dosimetry based on photosensitizer bleaching. We performed in vitro dose-response studies with simultaneous SOL and photosensitizer fluorescence measurements under various conditions, including variable 3 O 2, using the photosensitizer meta-tetra(hydroxyphenyl) chlorin (mTHPC). The results show that SOL was always predictive of cytotoxicity and immune to PDT's complex dynamics, whereas photobleaching-based dosimetry failed under hypoxic conditions. However, we identified a previously unreported 613  nm emission from mTHPC that indicates critically low 3 O 2 levels and can be used to salvage photobleaching-based dosimetry. These studies improve our understanding of PDT processes, demonstrate that SOL is a valuable gold-standard <b>dose</b> <b>metric,</b> and show that when used judiciously, photobleaching can serve as a surrogate for 1 O 2 dose...|$|E
40|$|Quantitative {{studies of}} global {{radiation}} damage are presented for {{two different types}} of experiments in structural biology: macromolecular crystallography (MX) and small angle X-ray scattering (SAXS) MX is the most common technique to elucidate the atomic resolution structures of biological macromolecules. However, these molecules undergo radiation induced changes during the experiment that undesirably affect the data. Global radiation damage, which is characterised by an overall loss in the diffracted intensity of Bragg reflections, limits the amount of useful data that can be collected from a single crystal in an experiment. Furthermore, for experimental phasing experiments, the radiation induced intensity changes can be so significant that the phasing signal becomes undetectable, thereby hindering successful structure determination. This thesis investigates methods to track and correct the diffraction data that are affected as a result of global radiation damage. First, extensions to the diffraction weighted <b>dose</b> (DWD) <b>metric</b> are investigated for the ability of DWD to track the overall intensity decay of reflections. This metric then is combined with a new mathematical model of intensity decay to perform zero-dose extrapolation. An additional probabilistic extrapolation approach is incorporated into the traditional regression based approach to allow extrapolation of low multiplicity reflections. As an alternative approach, a new hidden Markov model representation of the data collection experiment is developed that allows the time-resolved calculation of structure factor amplitudes, with error estimates calculated explicitly. This method gives comparable refinement statistics to that obtained from data processed with the current data reduction pipeline, and improvements to the algorithm are proposed. SAXS, on the other hand, is a complementary structural technique that results in low resolution information about macromolecules. However it still requires the probing of the macromolecules with ionising radiation, so radiation induced changes are still a problem. Unfortunately the tools for assessing radiation damage in SAXS experiments are not mature enough for them to be used routinely. This thesis presents extensions to RADDOSE- 3 D to perform dose calculations for SAXS samples. Additionally, a free, open source Python library has been developed to allow the exploration and visualisation of the results of a similarity analysis of frames within a dataset. These tools are then used to determine the efficacy of various radioprotectant compounds at different concentrations to mitigate radiation damage effects. </p...|$|R
40|$|Purpose: Several {{groups are}} {{exploring}} {{the integration of}} magnetic resonance (MR) image guidance with radiotherapy to reduce tumor position uncertainty during photon radiotherapy. The therapeutic gain from reducing tumor position uncertainty using intrafraction MR imaging during radiotherapy could be partially offset if {{the negative effects of}} magnetic field-induced dose perturbations are not appreciated or accounted for. The authors hypothesize that a more rotationally symmetric modality such as helical tomotherapy will permit a systematic mediation of these dose perturbations. This investigation offers a unique look at the dose perturbations due to homogeneous transverse magnetic field during the delivery of Tomotherapy® Treatment System plans under varying degrees of rota- tional beamlet symmetry. Methods: The authors accurately reproduced treatment plan beamlet and patient configurations using the Monte Carlo code geant 4. This code has a thoroughly benchmarked electromagnetic particle transport physics package well-suited for the radiotherapy energy regime. The three approved clinical treatment plans for this study were for a prostate, head and neck, and lung treatment. The <b>dose</b> heterogeneity index <b>metric</b> was used to quantify the e↵ect of the dose perturbations to the target volumes. Results: The authors demonstrate the ability to reproduce the clinical dose–volume histograms (DVH) to within 4 % dose agreement at each DVH point for the target volumes and most planning structures, and therefore, are able to confidently examine the effects of transverse magnetic fields on the plans. The authors investigated field strengths of 0. 35, 0. 7, 1, 1. 5, and 3 T. Changes to the dose heterogeneity index of 0. 1 % were seen in the prostate and head and neck case, reflecting negligible dose perturbations to the target volumes, a change from 5. 5 % to 20. 1 % was observed with the lung case. Conclusions: This study demonstrated that the effect of external magnetic fields can be mitigated by exploiting a more rotationally symmetric treatment modality...|$|R
40|$|Since the {{description}} of sepsis by Schottmüller in 1914, the amount on knowledge available on sepsis and its underlying pathophysiology has substantially increased. Epidemiologic examinations of abdominal septic shock patients show the potential for high risk posed by and the extensive therapy situation {{in the intensive care}} unit (ICU) (5). Unfortunately, until now it has not been possible to significantly reduce the mortality rate of septic shock, which is as high as 50 - 60 % worldwide, although PROWESS' results (1) are encouraging. This paper summarizes the main results of the MEDAN project and their medical impacts. Several aspects are already published, see the references. The heterogeneity of patient groups and the variations in therapy strategies is seen as one of the main problems for sepsis trials. In the MEDAN multi-center study of 71 intensive care units in Germany, a group of 382 patients made up exclusively of abdominal septic shock patients who met the consensus criteria for septic shock (3) was analysed. For use within scores or stand-alone experiments variables are often studied as isolated variables, not as a multidimensional whole, e. g. a recent study takes a look at the role thrombocytes play (15). To avoid this limitation, our study compares several established scores (SOFA, APACHE II, SAPS II, MODS) by a multi-dimensional neuronal network analysis. For outcome prediction the data of 382 patients was analysed by using most of the commonly documented vital parameters and <b>doses</b> of medicine (<b>metric</b> variables). Data was collected in German hospitals from 1998 to 2001. The 382 handwritten patient records were transferred to an electronic database giving the amount of 2. 5 million data entries. The metric data contained in the database is composed of daily measurements and doses of medicine. We used range and plausibility checks to allow no faulty data in the electronic database. 187 of the 382 patients are deceased (49 %) ...|$|R
40|$|Publicly {{available}} data can potentially {{examine the relationship}} between environmental exposure and public health, however, it has not yet been widely applied. Arsenic is of environmental concern, and previous studies mathematically parameterized exposure duration to create a link between duration of exposure and increase in risk. However, since the <b>dose</b> <b>metric</b> emerging from exposure duration is not a linear or explicit variable, it is difficult to address the effects of exposure duration simply by using mathematical functions. To relate cumulative <b>dose</b> <b>metric</b> to public health requires a lifetime physiologically-based pharmacokinetic (PBPK) model, yet this model is not available at a population level. In this study, the data from the U. S. total diet study (TDS, 2006 – 2011) was employed to assess exposure: daily dietary intakes for total arsenic (tAs) and inorganic arsenic (iAs) were estimated to be 0. 15 and 0. 028 μg/kg/day, respectively. Meanwhile, using National Health and Nutrition Examination Survey (NHANES, 2011 – 2012) data, the fraction of urinary As(III) levels (geometric mean: 0. 31 μg/L) in tAs (geometric mean: 7. 75 μg/L) was firstly reported to be approximately 4 %. Together with Bayesian technique, the assessed exposure and urinary As(III) concentration were input to successfully optimize a lifetime population PBPK model. Finally, this optimized PBPK model was used to derive an oral reference dose (Rfd) of 0. 8 μg/kg/day for iAs exposure. Our study also suggests the previous approach (by using mathematical functions to account for exposure duration) may result in a conservative Rfd estimation...|$|E
40|$|AbstractDecamethylcyclopenta{{siloxane}} (D 5) is a low-molecular-weight cyclic siloxane {{used primarily}} {{as an intermediate}} {{in the production of}} several widely-used industrial and consumer products and intentionally added to consumer products, personal products and some dry cleaning solvents. The global use requires consideration of consumer use information and risk assessment requirements from various sources and authoritative bodies. A global “harmonized” risk assessment was conducted to meet requirements for substance-specific risk assessments conducted by regulatory agencies such as USEPA's Integrated Risk Information System (IRIS), Health Canada and various independent scientific committees of the European Commission, as well as provide guidance for chemical safety assessments under REACH in Europe, and other relevant authoritative bodies. This risk assessment incorporates global exposure information combined with a Monte Carlo analysis to determine the most significant routes of exposure, utilization of a multi-species, multi-route physiologically based pharmacokinetic (PBPK) model to estimate internal dose metrics, benchmark modeling to determine a point of departure (POD), and a margin of safety (MOS) evaluation to compare the estimates of intake with the POD. Because of the specific pharmacokinetic behaviors of D 5 including high lipophilicity, high volatility with low blood-to-air partition coefficients and extensive metabolic clearance that regulate tissue dose after exposure, the use of a PBPK model was essential to provide a comparison of a <b>dose</b> <b>metric</b> that reflects these processes. The characterization of the potential for adverse effects after exposure to D 5 using a MOS approach based on an internal <b>dose</b> <b>metric</b> removes the subjective application of uncertainty factors that may be applied across various regulatory agencies and allows examination of the differences between internal dose metrics associated with exposure and those associated with adverse effects...|$|E
40|$|BACKGROUND: Little {{is known}} about the {{mechanisms}} involved in lung inflammation caused by the inhalation or instillation of nanoparticles. Current research focuses on identifying the particle parameter that can serve as a proper <b>dose</b> <b>metric.</b> OBJECTIVES: The {{purpose of this study was}} to review published dose–response data on acute lung inflammation in rats and mice after instillation of titanium dioxide particles or six types of carbon nanoparticles. I explored four types of dose metrics: the number of particles, the joint length—that is, the product of particle number and mean size—and the surface area defined in two different ways. FINDINGS: With the exception of the particle size–based surface area, all other parameters worked quite well as dose metrics, with the particle number tending to work best. The apparent mystery of three equally useful dose metrics could be explained. Linear dose–response relationships were identified at sufficiently low doses, with no evidence of a dose threshold below which nanoparticle instillation ceased to cause inflammation. In appropriately reduced form, the results for three different sets of response parameters agreed quite well, indicating internal consistency of the data. The reduced data revealed particle-specific differences in surface toxicity of the carbon nanoparticles, by up to a factor of four, with diesel soot being at the low end. CONCLUSIONS: The analysis suggests that the physical characterization of nanoparticles and the methods to determine surface toxicity have to be improved significantly before the appropriate <b>dose</b> <b>metric</b> for lung inflammation can be identified safely. There is also a need for refinements in quantifying response to exposure. KEY WORDS: joint length, lung inflammation, particle mass, particle number, saturation effects, specific surface area, ultrafine carbon particles. Environ Health Perspect 114 : 187 – 194 (2006) ...|$|E
40|$|Proposed is {{a method}} for {{investigating}} optimal acquisition parameters in NSECT, neutron stimulated emission computed tomography, for good image quality and low dose for diagnosing liver and breast cancers. These parameters include the number of angles, number of translations per angle, beam width, and beam width spacing. These parameters will affect dose, which will increase with increasing total neutron flux. Therefore, a balance must be achieved for the parameters mentioned above, to yield a desired dose limit and tolerable spatial resolution necessary for liver and breast cancer diagnosis. Using Monte Carlo simulation toolkit GEANT 4, the effects of beam spread due to neutron elastic scatter was explored. Then, a geometrical water torso phantom with slanted edge solid iron phantom was run for different acquisition parameters, and an MTF was taken to determine resolution for each set. For dose considerations, two anthropomorphic voxelized phantoms, one with liver cancer lesions, and one with breast cancer lesions, were scanned with the same parameter sets, and organ doses and DVHs, dose volume histograms, was computed for each set. In addition, images of the phantom in the lesion plane were reconstructed for those parameter sets showing best resolution and lowest dose. It is found that beam spread due to elastic scatter off of Hydrogen atoms is negligible for all beam widths. For optimal resolution in the primary breast phantom, {{it was found that}} acquisition parameters of a 5 mm beam, with no gaps, with any of the five angles provided the superior resolution. For the optimal resolution in the liver, it was found that down sampling angles and introducing gaps between projections greatly affected image accuracy and resolution. Also, the 5 mm beam width provided better geometrical accuracy, but the 1 cm bream width provided slightly better resolution. Organ doses are computed for the primary organ and organs at risk for each parameter set at 500 K neutrons per projection. For a scan of the full volume of the liver, liver organ doses ranged from 25. 83 to 0. 19 mSv. For the same scan, the organ doses for the heart ranged from 0. 18 to 0. 05 mSv. For a scan with the same pool of acquisition parameters of the full volume of the breast, breast organ doses ranged from 49. 87 to 0. 38 mSv. Furthermore, the DVHs for both scans showed a very steep drop-off at low dose bins for secondary organs at risk and a reasonable drop-off for the primary organ. In choosing the optimal acquisition parameters using both resolution and <b>dose,</b> a <b>metric</b> equal to resolution times dose is used, in which low values are optimal. An upper threshold for the metric was chosen based on dose values in currently used medical imaging modalities. A pool of optimal parameter sets was then identified using the metric. To further identify the optimum, a metric estimating geometrical accuracy of the reconstructed square was used. For the breast scan, the optimal parameter set was a 1 cm beam width, with 0 mm a gap, with 12 angles. For the liver scan, the optimal parameter set was a 1 cm beam width, with a 0 mm gap, with 36 angles. Finally, reconstructed images of the anthropomorphic scans using the super sampled geometry in the liver scan showed one lesion, using images of iron and phosphorous. With more degraded image quality, reconstructed images of the breasts using the super sampled geometry showed only the three cm lesion accurately. The images reconstructed from the optimal set identified for liver scans also showed the larger lesion, except with some noise from the presence of iron and phosphorous in other organs. The images reconstructed from the optimal set identified for the breast scans had a similar result to that of the super-sampled case, albeit with lower contrast. The least sampled case for both scans were found to be diagnostically useless. From these anthropomorphic images, this work demonstrates that in-vivo imaging of breast and liver cancers may be potentially possible with NSECT at a low dose. Thesi...|$|R
40|$|Modern {{radiation}} oncology {{is constantly}} improving and becoming more complex. Novel dosimetric planning, delivery and dosimetry techniques have allowed for im- proved plan quality {{and confidence in}} delivery. This thesis is {{an investigation into the}} impacts of novel radiotherapy planning and delivery techniques and the efficacy of novel dosimetry methods for modern, complex radiotherapy. The first part of the thesis involved investigation into novel treatment planning optimisation techniques for prostate cancer radiotherapy. Advantages and disadvantages of IMRT for simple prostate radiotherapy in the Australian clinical setting is investigated, showing small gains compared with high quality conformal radiotherapy. The use of a radiobiological parameter, specifcally the generalised Equivalent Uniform Dose (gEUD) was investigated for prostate IMRT optimisation to reduce rectal <b>dose.</b> The gEUD <b>metric</b> was found to be a useful optimisation objective that provided rectal dose reductions over the full dose range. The result of the optimisation was heavily dependent on the value of a (describing organ architecture), with a lower value of a resulting in the largest reductions in rectal dose. A commercial Volumetric Modulated Arc Radiotherapy (VMAT) tool was investigated for prostate radiotherapy. Single arc VMAT plans were compared to static gantry angle IMRT plans for prostate cancer cases. It was found that VMAT resulted in equivalent target coverage with reductions in rectal V 25 Gy. The VMAT plans required on average 18. 6 % fewer monitor units and were theoretically up to 3. 75 times faster to delivery compared with static gantry angle IMRT. The second part of the thesis looked at using modern radiation detectors for verification of treatment dose in regions of electronic disequilibrium. Rectal balloons filled with air are used for prostate immobilisation and rectal dose reduction in prostate photon radiotherapy. This introduces an air cavity into the patient, immediately adjacent to the target. Radiochromic film was used to show that two commercial convolution/superposition dose calculation algorithms slightly over-predict the anterior rectal wall dose and under-predict the posterior rectal wall dose. The feasibility of a novel MOSFET detector, the MOSkin, coupled to a commercial rectal balloon was investigated for real time in vivo rectal wall dose verification. In this phantom study, the MOSkin was shown to be an excellent real time dosimeter, with minimal angular response and reproducible sensitivity. The MOSkin was then used with radiochromic film to verify the dose delivered to the skin during total scalp irradiation with helical tomotherapy. It was shown that the helical tomotherapy RTPS accurately calculated the dose to surface voxels and that the dose delivered to the skin is less than the prescription dose, which suggests a bolus may be required to achieve prescription dose to the skin. Finally, the dosimetric effect of end leaf leakage was investigated for a commercial multileaf collimator for wide-field IMRT. It was shown that end leaf leak- age can contribute significant doses to treatment fields, but provided the effects are quantified it is reasonable to accept these as the allowance of wide fields avoids complicated dual overlapping field feathering. The commercial RTPS investigated slightly under-predicts the magnitude of these end leaf leakage dose contributions...|$|R
40|$|Computed Tomography (CT) {{has been}} one of the leading imaging {{modalities}} in today's practice of Radiology. Since its introduction in 1970 s, its unique tomographic capability has not only prevented countless number of unnecessary surgeries but also saved lives by early detection of disease. Radiation dose from CT has been estimated to contribute to almost 50 % of all medical radiation exposures. Concerns about radiation-induced carcinogenesis have resulted in efforts that encourage monitoring and reporting radiation dose from CT examinations. It has been suggested that the most appropriate quantity for assessing risk of carcinogenesis from x-ray imaging procedures is the radiation dose to individual patients. Currently employed dose metrics used to report patient dose are CTDI vol and DLP, neither of which is patient-specific dose, let alone dose to individual organs. CTDI vol is dose to a homogenous cylindrical phantom, which is defined for fixed tube current CT exams. With the implementation of Tube Current Modulation (TCM) feature in almost all clinical CT protocols as an intended means for dose reduction, while maintaining an appropriate diagnostic image quality, CTDI vol definition was standardized across scanners to reflect dose to CTDI phantom based on the average tube current across the entire scan length. Depending on the type of CT exam, the average tube current used to report a CTDI vol value may or may not represent the actual tube current at a specific table location. In addition to not taking into account variation of the tube current across a single exam, CTDI vol is size-independent, i. e. patients with different sizes have the same CTDI vol value if scanned using the same imaging parameters. To adjust CTDI vol for size, AAPM Task Group 204 was established and subsequently published a report containing conversions as a function of effective diameter which can be applied to scanner-reported CTDI vol to adjust for patient size. However, the generated conversion factors were based on fixe tube current measurements and Monte Carlo simulations and failed to take into account TCM. Additionally, the size metric used in TG 204 was entirely based on patients' physical dimensions and does not take into account variations in composition and density among patients, let alone within a single patient; i. e. differences between chest and abdomen in terms of attenuation properties could not be explained with a simple measure of dimension such as effective diameter. Instead attenuation-based metrics need to be implemented to explain these differences. The overall purpose of this dissertation was to improve organ dose estimation from Computed Tomography exams by: (a) taking into account the commonly used feature in CT protocols, Tube Current Modulation (TCM), (b) employing a more appropriate way of reporting CTDI for TCM exams and (c) using a patient size descriptor capable of describing the attenuation properties of individual patients. For this dissertation a validated Monte Carlo based MDCT model capable of simulating organ dose was utilized to estimate organ dose to voxelized patient models undergoing tube current modulated CT examinations. Both detailed TCM and z-axis-only modulation information were used in the simulations in case raw projection data was not accessible. In addition to simulated organ doses different CTDI vol values based on the type of patient model, abdomen versus chest, were calculated. These CTDI vol values included regional CTDI vol,regional and organ-specific CTDI vol,organ along with scanner-reported CTDI vol, referred to as global CTDI vol,global. Furthermore different size metrics, such as effective diameter and attenuation-based metrics, were calculated for every axial CT image within a series and averaged corresponding to the same regions and images used to calculated the above mentioned regional and organ-specific CTDI vol values. Using an approach similar to previous efforts and AAPM Task Group 204, the estimated organ doses were normalized by CT Dose Index (CTDI vol) values. However, for TCM scans normalized organ doses by CTDI vol,global were observed to not have a strong correlation with patient size. This result was quite different from that observed previously for fixed tube current exams. In contrast, when regional descriptors of scanner output (CTDI vol,regional and CTDI vol,organ) were used as a modified normalization factor, the results demonstrated significantly improved correlations with patient size. Additionally, an attenuation-based patient size metric, the water equivalent diameter (WED), was investigated in terms of its ability to describe the effects of patient size on organ dose. WED was compared to the size metric introduced in TG 204, effective diameter, which is based only on patient morphology (e. g. perimeter) and not on attenuation. Results of the comparisons demonstrated no statistically significant improvements of correlation between normalized organ <b>doses</b> and size <b>metric</b> once WED was utilized, except for normalized lung dose. Although there were no statistically significant improvements, the correlation of determination, R 2, increased for almost all organs once WED was employed. Similarly, there was no statistically significant difference between differently averaged size metrics, i. e. global average of size metrics versus regional average of size metrics, except for normalized lung dose, which showed a statistically significant improvement in R 2 once a regional WED was employed as a size metric compared to global WED. Using improved normalization quantity and patient size metric for tube current modulated CT examinations, Generalized Linear Models were used to generate a predictive model capable of estimating dose from TCM exams using regional CTDI vol) and WED. Different models based on scanners and organs were generated to establish the level of accuracy of each model and to determine the level of specification needed to achieve best organ dose estimates. Additionally, models with different response variables, normalized organ dose versus actual organ dose, were explored and compared. When tested using a separate test set, investigated models with regional CTDI vol) either as a predictor or normalization factor resulted in very similar results while models created with global CTDI vol) as a predictor resulted in underestimation of organ dose across all organs. Additionally, it was shown that a model based on pooled data was not significantly different than scanner and organ-specific models since the pooled-data model resulted in employing significant categorical predictors such as scanners and organs. This observation confirms the fact that TCM algorithms are different across scanners and regional CTDI vol) is not capable of eliminating these differences, but it can eliminate differences among TCM functions across a single CT scanner. Predictive organ dose estimates using generated models resulted in a mean percent difference of less than 10 % when compared to actual Monte Carlo simulated organ doses. The improvement of the newly generated model was also compared against currently used dose metrics, CTDI vol), SSDE, and ImPACT. While comparisons with actual Monte Carlo simulated organ doses resulted in statistically significant differences between conventional dose metrics and simulated organ doses, comparisons with organ estimates from the newly developed model resulted in no difference from Monte Carlo simulated organ doses. This work demonstrated the feasibility of estimating organ dose from tube current modulated scans from three major CT manufacturers using an improved descriptor of tube current modulated scans as normalization quantity or predictor and a patient size metric based on patients attenuation properties...|$|R
40|$|BackgroundNanoparticles are {{characterized}} by having a high surface area per mass. Particulate surface area {{has been reported to}} play an important role in determining the biological activity of nanoparticles. However, recent reports have questioned this relationship. This study was conducted to determine whether mass of particles or surface area of particles is the more appropriate <b>dose</b> <b>metric</b> for pulmonary toxicity studies. In this study, rats were exposed by intratracheal instillation to various doses of ultrafine and fine carbon black. At 1, 7, or 42 days post-exposure, inflammatory and cytotoxic potential of each particle type was compared on both a mass dosage (mg/rat) as well as an equal surface area dosage (cm 2 of particles per cm 2 of alveolar epithelium). In an additional study, the pulmonary responses to instillation of ultrafine carbon black were compared to equivalent particle surface area doses of ultrafine titanium dioxide. ResultsUltrafine carbon black particles caused a dose dependent but transient inflammatory and cytotoxic response. On a mass basis, these responses were significantly (65 fold) greater than those for fine sized carbon black. However, when doses were equalized based on surface area of particles given, the ultrafine carbon black particles were only slightly (non-significantly) more inflammogenic and cytotoxic compared to the fine sized carbon black. At one day post-exposure, inflammatory potencies of the ultrafine carbon black and ultrafine titanium dioxide particles were similar. However, while the pulmonary reaction to ultrafine carbon black resolved with time, the inflammatory effects of ultrafine titanium dioxide were more persistent over a 42 day post-exposure period. ConclusionThese results indicate that for low toxicity low solubility materials, surface area of particles administered rather than mass burden of particles may be a more appropriate <b>dose</b> <b>metric</b> for pulmonary toxicity studies. In addition, ultrafine titanium dioxide appears to be more bioactive than ultrafine carbon black on an equivalent surface area of particles delivered basis...|$|E
40|$|Purpose: A dosimetric margin (DM) is {{the margin}} in a {{specified}} direction between a structure and a specified isodose surface, corresponding to a prescription or tolerance dose. The dosimetric margin distribution (DMD) is {{the distribution of}} DMs over all directions. Given a geometric uncertainty model, representing inter- or intrafraction setup uncertainties or internal organ motion, the DMD {{can be used to}} calculate coverage Q, which is the probability that a realized target or organ-at-risk (OAR) <b>dose</b> <b>metric</b> Dv exceeds the corresponding prescription or tolerance dose. Postplanning coverage evaluation quantifies the percentage of uncertainties for which target and OAR structures meet their intended dose constraints. The goal of the present work is to evaluate coverage probabilities for 28 prostate treatment plans to determine DMD sampling parameters that ensure adequate accuracy for postplanning coverage estimates...|$|E
40|$|Cytotoxicity in {{the nasal}} {{epithelium}} is frequently observed in rodents exposed to volatile organic acids and esters by inhalation. An interspecies, hybrid {{computational fluid dynamics}} and physi-ologically based pharmacokinetic (CFD-PBPK) dosimetry model for inhaled ethyl acrylate (EA) is available for estimating internal dose measures for EA, its metabolite acrylic acid (AA), and EA-mediated reductions in tissue glutathione (GSH). Nasal tissue concentrations of AA were previously used as the <b>dose</b> <b>metric</b> for a chronic Reference Concentration (RfC) calculation with this compound. However, EA was more toxic than expected, based on calculated tissue AA concentrations. Unlike AA, EA causes deple-tion of tissue GSH. We have developed an RfC for EA using tissue GSH depletion in the olfactory epithelium as the primary measure of nasal tissue dose. The hybrid CFD-PBPK model was refined to improve the accuracy of simulations for GSH in rat olfactor...|$|E
40|$|Abstract Background Nanoparticles are {{characterized}} by having a high surface area per mass. Particulate surface area {{has been reported to}} play an important role in determining the biological activity of nanoparticles. However, recent reports have questioned this relationship. This study was conducted to determine whether mass of particles or surface area of particles is the more appropriate <b>dose</b> <b>metric</b> for pulmonary toxicity studies. In this study, rats were exposed by intratracheal instillation to various doses of ultrafine and fine carbon black. At 1, 7, or 42 days post-exposure, inflammatory and cytotoxic potential of each particle type was compared on both a mass dosage (mg/rat) as well as an equal surface area dosage (cm 2 of particles per cm 2 of alveolar epithelium). In an additional study, the pulmonary responses to instillation of ultrafine carbon black were compared to equivalent particle surface area doses of ultrafine titanium dioxide. Results Ultrafine carbon black particles caused a dose dependent but transient inflammatory and cytotoxic response. On a mass basis, these responses were significantly (65 fold) greater than those for fine sized carbon black. However, when doses were equalized based on surface area of particles given, the ultrafine carbon black particles were only slightly (non-significantly) more inflammogenic and cytotoxic compared to the fine sized carbon black. At one day post-exposure, inflammatory potencies of the ultrafine carbon black and ultrafine titanium dioxide particles were similar. However, while the pulmonary reaction to ultrafine carbon black resolved with time, the inflammatory effects of ultrafine titanium dioxide were more persistent over a 42 day post-exposure period. Conclusion These results indicate that for low toxicity low solubility materials, surface area of particles administered rather than mass burden of particles may be a more appropriate <b>dose</b> <b>metric</b> for pulmonary toxicity studies. In addition, ultrafine titanium dioxide appears to be more bioactive than ultrafine carbon black on an equivalent surface area of particles delivered basis. </p...|$|E
40|$|High {{requirements}} and challenges formed by legislations like REACH and the 7 th amendment of cosmetics have accelerated {{the development of}} new alternative toxicology testing methods. In vitro cell systems combined with in silico methods have been deemed good alternatives for toxicology testing, aiming to reduce or even replace conventional animal toxicity experiments. Unfortunately these methods are not ready to replace animal based toxicity assays yet for several reasons. One of the issues as mainly discussed in this thesis, is the lack of a standardised <b>dose</b> <b>metric</b> for use in dose-response relationships that are to be extrapolated f om in vitro cell systems to in vivo. Often total or nominal concentrations are used to express in vitro derived toxicity while these do not account for possible reductions in bioavailability, thus reducing the biologically effective dose through evaporation, binding to well plastic, serum, cell membranes etc. Differences in exposure media between in vitro assays and between in vitro and in vivo, may cause differences in the biologically effective dose even though nominal concentrations are equal. This can subsequently lead to different predictions of in vivo responses. Therefore this thesis discusses numerous alternative dose metrics available that may be used to improve the in vivo predictions. It is recommended to first choose the right external <b>dose</b> <b>metric,</b> either nominal or freely dissolved based on the physiological parameters of the test compound. Additionally, a choice can be made for an internal concentration, closer to the target site to improve the extrapolation of in vitro effect concentrations to equivalent in vivo doses. Finally the chosen metric can be integrated (AUC) or weighted (TWA) in the case of prolonged exposure and depending on the mechanisms of action. Further research needs to focus on whether internal concentrations are truly worth measuring and what cut-off value in bioavailability reduction should be used to choose between either free or nominal concentrations...|$|E
30|$|Figure  4 {{indicates}} that TLG corresponds better to the dose given compared to SUVpeak, which demonstrates no strong {{trend in the}} data, and thus {{may be a more}} appropriate metric to use in practice (Fig.  4 a, b). SUVpeak was chosen due to its robustness as a quantitative metric, as opposed to SUVmax or SUVmean, which may suffer from spurious single pixel fluctuations or partial volume effects, respectively. The use of D 70 as a <b>dose</b> <b>metric</b> may be more optimal than Davg when comparing to response, as seen by a tighter clustering of points around the curve; however, the difference is subtle. The data (Fig.  4 a) suggest that the Davg threshold of 50  Gy is applicable when predicting lesions that will respond to radioembolisation with resin microspheres. Furthermore, the data also suggest that lesions receiving less than 20  Gy will not respond to treatment.|$|E
