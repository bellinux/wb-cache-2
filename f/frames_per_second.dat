3658|10000|Public
5|$|Ebert was {{a strong}} {{advocate}} for Maxivision 48, in which the movie projector runs at 48 <b>frames</b> <b>per</b> <b>second,</b> {{as compared to the}} usual 24 <b>frames</b> <b>per</b> <b>second.</b> He was opposed to the practice whereby theatres lower the intensity of their projector bulbs in order to extend the life of the bulb, arguing that this has little effect other than to make the film harder to see. Ebert was skeptical of the recent resurgence of 3D effects in film, which he found unrealistic and distracting.|$|E
5|$|In October 2014 Elgato {{released}} {{a new version}} called HD 60. It recorded in 60 <b>frames</b> <b>per</b> <b>second</b> and 1080p high definition video, whereas typical low-end video game recording devices capture in 720p and 30 <b>frames</b> <b>per</b> <b>second.</b> The Telegraph gave it {{four out of five}} stars. A review in Gizmodo said that it captured extremely high-quality footage, but it may be higher-end than needed for many gamers that would be satisfied with the recording features built into the console.|$|E
5|$|Delay issues aside, the {{development}} team encountered further {{challenges in the}} creation of the game. Implementing the top-down perspective became a particular issue and resulted in a lot of trial and error. With a true top-down view, players would be unable to see characters' faces and bodies. To circumvent this issue, objects in the world were tilted at an angle so that they were more visible in the top-down view. Mouri requested that the game run at sixty <b>frames</b> <b>per</b> <b>second</b> instead of thirty to stabilise the stereoscopic 3D and smoothen movement animations. While doubling the frame rate increased the processing load, it allowed the developers to implement a feature where players could select items by dragging and dropping them from their inventory using the Nintendo 3DS's touchscreen and stylus; at thirty <b>frames</b> <b>per</b> <b>second</b> this feature felt too sluggish for the stylus's movement.|$|E
5000|$|Built-in 8 <b>frame</b> <b>per</b> <b>second</b> {{motor drive}} (up from 5.7 frame/s on the F4).|$|R
30|$|The second module {{listens to}} the {{feedback}} messages send by the client for adjusting the video bit rate by changing the quality parameters (resolution, <b>frame</b> <b>per</b> <b>second,</b> and etc.).|$|R
40|$|Abstract: Problem statement: Shadows {{are most}} {{important}} effect to make realistic games and visually appealing images, but they are poor in <b>frame</b> <b>per</b> <b>second.</b> Silhouette detection is most important phases to create real-time shadow. Approach: Present study describes a real-time shadow generated with volume shadow algorithm using Visible-Non Visible algorithm (VNV) in virtual environment illuminated by a movable light source to improve the <b>frame</b> <b>per</b> <b>second.</b> Silhouette detection that is most expensive part of shadow creation was described. Triangular method and VNV method were compared. An improved algorithm for volume shadow was proposed and volume shadow using both methods in C++ Opengl implemented. Results: The VNV algorithm increases the number of <b>Frame</b> <b>Per</b> <b>Second</b> (FPS) {{and as a result}} decreases the cost of implementation. Conclusion: A verified algorithm for volume shadow makes it easy to understand by everyone how to produce real-time shadow in outdoor and indoor virtual environment. It is possible to use it in current commercial games or other virtual reality systems...|$|R
5|$|Principal {{gameplay}} involves one-on-one 2.5D style fighting. Mortal Kombat uses {{a single}} two-dimensional fighting plane (at 60 <b>frames</b> <b>per</b> <b>second),</b> although characters are rendered in three-dimensional fashion, {{intended to give}} depth and range to portrayals of various projectiles. Unlike previous Mortal Kombat games, four buttons on the game controller represent attacks and are each linked to a corresponding limb.|$|E
5|$|The Windows {{version of}} the game had a more mixed reception, with {{criticism}} aimed mostly at the technical issues present {{at the time of}} the game's release, ultimately leading to sales being suspended. On June 23, 2015, the launch day for Arkham Knight, thousands of users reported major technical flaws and performance problems with the Windows {{version of the}} game, with some saying it seemed like the optimization phase of the game's development was skipped. Steam users immediately wrote scathing reviews of the game's performance, including reports of frame rate being capped at 30 <b>frames</b> <b>per</b> <b>second</b> (which could be raised, though with potential side effects) and dropping as low as 10 <b>frames</b> <b>per</b> <b>second</b> while gliding or using the Batmobile.|$|E
5|$|The {{video was}} {{directed}} by British directing duo James Frost & Alex of The Artists Company. It was shot at 50 <b>frames</b> <b>per</b> <b>second,</b> twice the regular speed. At the shoot, Chris Martin had to sing the song at double speed so that the audio and visual content would be in sync, a common yet difficult practice of music videos. The final product is slowed to 25 <b>frames</b> <b>per</b> <b>second,</b> giving the slow motion effect of the video. The transition of the video from night to day was achieved during the telecine process. During the transfer from film to videotape, an operator manually adjusted the amount of lighting for blue in the beginning, red in the middle, and yellow {{at the end of}} the video.|$|E
50|$|Usually there's {{an audio}} POP that play 48 frames (2 <b>seconds</b> at 24 <b>frame</b> <b>per</b> <b>second)</b> before first <b>frame</b> of action (FFOA) {{that helps to}} sync audio and video during {{printing}} processes or postproduction.|$|R
40|$|Problem statement: Shadows {{are most}} {{important}} effect to make realistic games and&# 13; visually appealing images, but they are poor in <b>frame</b> <b>per</b> <b>second.</b> Silhouette detection is most&# 13; important phases to create real-time shadow. Approach: Present study describes a real-time shadow&# 13; generated with volume shadow algorithm using Visible-Non Visible algorithm (VNV) in virtual&# 13; environment illuminated by a movable light source to improve the <b>frame</b> <b>per</b> <b>second.</b> Silhouette&# 13; detection that is most expensive part of shadow creation was described. Triangular method and VNV&# 13; method were compared. An improved algorithm for volume shadow was proposed and volume&# 13; shadow using both methods in C&plus; Opengl implemented. Results: The VNV algorithm increases&# 13; the number of <b>Frame</b> <b>Per</b> <b>Second</b> (FPS) {{and as a result}} decreases the cost of implementation. &# 13; Conclusion: A verified algorithm for volume shadow makes it easy to understand by everyone how to&# 13; produce real-time shadow in outdoor and indoor virtual environment. It is possible to use it in current&# 13; commercial games or other virtual reality systems. </div...|$|R
50|$|Phase Alternating Line (PAL) is a colour {{encoding}} {{system for}} analogue television used in broadcast television systems {{in most countries}} broadcasting at 625-line / 50 field (25 <b>frame)</b> <b>per</b> <b>second</b> (576i). Other common colour encoding systems are NTSC and SECAM.|$|R
5|$|God of War III Remastered {{was first}} {{released}} in North America on July 14, 2015, for the PlayStation 4—the franchise's first {{appearance on the}} platform. It is a remastered version of God of War III, and it features full 1080p support targeted at 60 <b>frames</b> <b>per</b> <b>second</b> and a photo mode. The game's announcement and release was in celebration of the franchise's tenth anniversary. It was ported by Wholesale Algorithms.|$|E
5|$|God of War: Origins Collection {{features}} native 1080p high-definition video, anti-aliased graphics at 60 <b>frames</b> <b>per</b> <b>second,</b> DualShock 3 rumble features, Trophies, and is {{the only}} God of War release to feature Stereoscopic 3D. The God of War–Game Directors Live documentary, Kratos Legionnaire bonus skin, and Forest of the Forgotten combat arena (originally pre-order bonuses for Ghost of Sparta) are also included with the Origins Collection.|$|E
5|$|The Rolling Stones {{were the}} first major {{recording}} artists to broadcast a concert over the Internet; a 20-minute video was broadcast on 18 November 1994 using the Mbone at 10 <b>frames</b> <b>per</b> <b>second.</b> The broadcast, engineered by Thinking Pictures and financed by Sun Microsystems, {{was one of the}} first demonstrations of streaming video; while it was not a true webcast, it introduced many to the technology.|$|E
40|$|A {{relatively}} simple {{system has been}} built for automatically scanning any rectangular array of spark chamber views on film. It has been successfully used to scan an experiment with 24 views {{at the rate of}} about one <b>frame</b> <b>per</b> <b>second.</b> The optics, electronics, programming and the principles of operation are discussed...|$|R
50|$|The device {{would be}} the largest {{telescope}} ever built - {{twice the size of}} the ground-based twin 10 m Keck telescopes. It could see about 40 percent of the Earth's surface and could image a 10 x 10 km area at a 1 m resolution and generate videos at one <b>frame</b> <b>per</b> <b>second.</b>|$|R
50|$|The {{standard}} also defines nominal bitrates of 3 Gbit/s, for 50/60 <b>frame</b> <b>per</b> <b>second</b> 1080P applications. This {{version of}} the interface is not used (and has not been commercially implemented); instead, either a dual-link extension of SMPTE 292M known as SMPTE 372 or a version running twice as fast known as SMPTE 424 is used for e.g. 1080p60 applications.|$|R
5|$|The four-minute ride uses 85-foot IMAX Dome {{screens and}} Sony Projectors. There are 24 ride cars, each seating eight people, and {{approximately}} 2000 people can ride it per hour. The projection system uses four overlapping Sony SXRD 4K resolution projectors on each dome, using custom-made semi-circular fisheye lenses to project undistorted images {{at a rate}} of 60 <b>frames</b> <b>per</b> <b>second</b> (in comparison, most feature films project at 24 <b>frames</b> <b>per</b> <b>second).</b> The video is projected onto two dome screens which are made of 416 panels (each 4feet by two feet) and are approximately 80feet tall and 85feet wide. The animation in the ride uses computer generated 3D animation rendered by Blur Studio and Reel FX, rather than the traditional 2-D animation seen on The Simpsons and the queue and pre-show of the ride. The animation reference was provided by Film Roman, the animation studio that animates the series. Each car contains 12 speakers and a Dolby 6.1 surround sound, while the domes contain an additional 90 speakers.|$|E
5|$|Nintendo first {{announced}} on May 11, 2005 that {{they planned to}} release a Mario Kart game for the Nintendo DS, releasing some gameplay video footage at the same time. The company offered the game {{for the public to}} play {{for the first time at}} the 2005 Game Developers Conference, where the game's wireless feature was also showcased. Mario Kart DS was produced by Hideki Konno, who also worked on 2005's Nintendogs. The game runs at a consistent 60 <b>frames</b> <b>per</b> <b>second</b> and uses full 3D characters and environments.|$|E
5|$|The Windows {{version of}} Remastered {{was criticized for}} {{suffering}} {{from a number of}} technical issues in the multiplayer, with players also being dissatisfied with the game's available settings for PC. On Steam, it received mostly negative user reviews, with complaints including poor performance, a locked 90 <b>frames</b> <b>per</b> <b>second,</b> inadequate mouse support, numerous hackers, and a low player count. Some users suggested that the multiplayer of Modern Warfare would be a more suitable alternative, which still attracted a sizable amount of players and offered better options for performance, modding and customization.|$|E
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Issued also on microfiche from Lange Micrographics. This thesis presents an algorithm which processes a sequence of digital images to look like a sequence of film-originated images. The algorithm alters frame rate by compressing the original thirty <b>frame</b> <b>per</b> <b>second</b> sequence into a twenty-four <b>frame</b> <b>per</b> <b>second</b> sequence and can, if the user wishes, add grain and/or filmic artifacts such as scratches, bumps, and flicker. Interlacing artifacts associated with video are removed through the use of blurring. The algorithm is tested on a computer-generated sequence of images and a digitized video sequence. The results are then analyzed based on the author's subjective criteria...|$|R
50|$|The movie {{image size}} can be set, {{as well as}} the <b>frame</b> rate <b>per</b> <b>second,</b> and {{compression}} method.|$|R
50|$|All formats {{designed}} for digital cinematography are progressive scan, and capture usually {{occurs at the}} same 24 <b>frame</b> <b>per</b> <b>second</b> rate established as the standard for 35mm film. Some films such as The Hobbit: An Unexpected Journey have a High Frame Rate of 48 fps, although in some theatres it was also released in a 24 fps version which many fans of traditional film prefer.|$|R
5|$|To avoid violating Edison's patents, Biograph cameras from 1895 to 1902 used a large-format film {{measuring}} 2-23/32 inches (68mm) wide, with {{an image}} area of 2 × 2½ inches, four times that of Edison's 35mm format. Biograph film was not ready-perforated; the camera itself punched a sprocket hole {{on each side of}} the frame as the film was exposed at 30 <b>frames</b> <b>per</b> <b>second.</b> Sherlock Holmes Baffled ran to 86.56 metres in length, giving the film a running time of 30 seconds (although in practice, due to the hand-cranked gearing of the Mutoscope this would have varied).|$|E
5|$|Cockroaches {{are among}} the fastest insect runners and, at full speed, adopt a bipedal run to reach a high {{velocity}} in proportion to their body size. As cockroaches move very quickly, {{they need to be}} video recorded at several hundred <b>frames</b> <b>per</b> <b>second</b> to reveal their gait. More sedate locomotion is seen in the stick insects or walking sticks (Phasmatodea). A few insects have evolved to walk {{on the surface of the}} water, especially members of the Gerridae family, commonly known as water striders. A few species of ocean-skaters in the genus Halobates even live on the surface of open oceans, a habitat that has few insect species.|$|E
5|$|God of War and God of War II were ported by Bluepoint Games {{and feature}} high-definition 720p {{anti-aliased}} graphics at 60 <b>frames</b> <b>per</b> <b>second</b> and Trophies. The bonus materials {{of the original}} two-disc PlayStation 2 version of God of War II are included with the Blu-ray version of the collection. The port was produced {{as a result of}} feedback from fans of the series and was viewed as a means of introducing new players to the series before God of War III was released. The God of War III game demo from E3 2009 was included with early copies of the collection. Sanzaru Games was responsible for porting the collection to the Vita.|$|E
5000|$|On August 22, 2005, Canon {{announced}} {{the successor to}} the EOS 1D Mark II. The new Canon EOS-1D Mark II N features the same 8.2 megapixel CMOS sensor, DIGIC II image processor and 8.5 <b>frame</b> <b>per</b> <b>second</b> shooting speed of its predecessor. The primary changes are a new 2.5" [...] wide viewing angle LCD monitor, an improved buffer, and new 'Picture Style' image parameters.|$|R
30|$|This picture changes however, when {{considering}} image signing and timestamping {{as described in}} Section 5.3. Table 3 shows the runtime for the TPM_TickStampBlob operation on the Atmel I 2 C TPM is about 800 ms without overheads. This runtime clearly {{makes it impossible to}} sign and timestamp every single image delivered by the camera since the effective framerate would be reduced to little more than one <b>frame</b> <b>per</b> <b>second.</b>|$|R
5000|$|The {{duration}} of the text being displayed depends on the frame rate of the corresponding video file. For example, if the frame rate of the corresponding video file is 25 <b>frames</b> <b>per</b> <b>seconds</b> and the subtitle file in last example is accompanied with, [...] "Hello!" [...] is displayed for one second.The software the MicroDVD Player expects the subtitle file {{to begin with the}} tag BEGIN, and end with the tag END.|$|R
5|$|In June 2014, YouTube {{introduced}} videos {{playing at}} 60 <b>frames</b> <b>per</b> <b>second,</b> {{in order to}} reproduce video games with a frame rate comparable to high-end graphics cards. The videos play back at a resolution of 720p or higher. YouTube videos are available {{in a range of}} quality levels. The former names of standard quality (SQ), high quality (HQ), and high definition (HD) have been replaced by numerical values representing the vertical resolution of the video. The default video stream is encoded in the VP9 format with stereo Opus audio; if VP9/WebM is not supported in the browser/device or the browser's user agent reports Windows XP, then H.264/MPEG-4 AVC video with stereo AAC audio is used instead.|$|E
5|$|Knowles rehearsed {{the pole}} dancing using two ballet bars, which {{was when it}} was decided to add a pole above her head to form an arc. Though she is from Texas, she had never {{previously}} been on mechanical bull. There were no problems during warm-ups, but the man operating the bull during the video shoot programmed it to go faster, causing Knowles to fall off when she tried to perform tricks such as lifting up her foot, leaning back and turning around. To minimize the time Knowles spent on the bull, the director shot the sequence at twelve <b>frames</b> <b>per</b> <b>second</b> (see frame rate) and Knowles sang twice as quickly, but it wasn't until 4:00am that they completed work.|$|E
5|$|The Agni's Philosophy tech demo {{was running}} at 60 <b>frames</b> <b>per</b> <b>second,</b> used 1.8 GB of texture data per frame, and pushed ten million polygons per frame, with {{approximately}} 300,000 to 400,000 polygons for each character model. The entire {{city in the}} demo was tessellated. There is a scene where 100,000 illuminated firefly-like insects appear on screen, each one a full polygon mesh model with body and wings, which proceed to merge to generate a summoned monster. Production for the demo began in June 2011, and was initially produced as pre-rendered CGI animation by Visual Works before Square Enix attempted to reproduce it entirely in real-time with the Luminous Studio engine, using the same assets as the CGI version.|$|E
40|$|Abstract — Human face {{detection}} and recognition finds various application in domain like Surveillance, Law Enforcement, Interactive game application etc. These application requires fast image processing {{in real time}} however with the proposed work earlier does not gives that capability. In this paper we have proposed technique that process image for face {{detection and}} recognition in parallel on NVIDIA GeForce GTX 770 GPU which has compute Capability of 3. 0. We have used Viola and Jones for face detection and PCA Eigenfaces algorithm for face recognition. The viola and jones shown result of processing the faces at 15 <b>frame</b> <b>per</b> <b>second</b> but our method shown approximately 109 <b>frame</b> <b>per</b> <b>second</b> in CUDA (Compute Unified Device Architecture) development framework. The algorithm are implemented to process data in parallel and made some practical optimization changes to work fast in C based programming model from NVIDIA. We have tested our proposed work on static images, video frame {{as well as on}} live camera frames captured device. We also tested that our system works robustly in extremely illumination condition. This work is done by PG students i...|$|R
40|$|Usually photogrammetrist used {{still image}} for {{measurement}} and modeling of object. Videogrametry refers to video images taken using camcorder or movie function on digital still camera. Video movie consists of sequences of images (or frames). If video speed is 25 fps (<b>frame</b> <b>per</b> <b>second)</b> and taken for 1 minute (i. e. 60 seconds), there are 25 <b>frame</b> <b>per</b> <b>second</b> or overall 1500 image. This paper highlights {{the capabilities of}} video {{as a tool for}} 3 D measurement and modeling, as well as still image. Several advantages are discusses in detail. This paper discusses an on-going research to develop a real time video capturing software and procedure for high-accuracy real-time data capture and image analysis. The development also focuses on the optimization, in terms of method, procedure, low-cost and accurate results. The research methodology consists of real time video capturing, image analysis, bundle adjustment, motion detection, motion tracking and 3 D coordinate movement on each frame. With this development, it can be applied to measure moving object such as sport analysis, metrology, inspection, and model the motion of human for medical purposes...|$|R
40|$|Abstract—The {{calculation}} {{on three}} dimensions must retrieve the whole {{data on the}} three dimensions plane surface. It calculates the vertex data plentifully while the previous method uses many resources. It has {{an easy way to}} solve the problem by upgrading hardware of the computer. This paper proposes a new model which are energy radiation model and Linear-Coordinate Projection for three dimensions calculate reduction as it has more efficiency than the previous method. This paper proposes the calculate reduction for real-time rendering. These methods use multi-procedure to decrease working process of CPU and increase <b>frame</b> <b>per</b> <b>second</b> rate. It has details different with form LOD. The calculate reduction tries to ignore the calculation in every component both object factor and system processing which weight value weight can compensate. It points out to total of systematization which is related. The efficiency measurements use number of <b>frame</b> <b>per</b> <b>second</b> spending in real-time rendering. Result of the experiment is three dimensions programming uses Energy Radiation and LCP model in cooperate with another calculate reduction method succeed in the speed of rendering that quickly than normality 62 %- 116 % or 1. 675 - 3. 135 times. Keywords—Energy radiation, simulation, dimension rendering. I...|$|R
