225|10000|Public
25|$|The MM II missile was {{deployed}} with a D-37C disk computer. Autonetics also programmed functional simulators and {{the code}} inserter verifier {{that was used}} at Wing headquarters to <b>generate</b> <b>and</b> <b>test</b> the flight program codes {{to go into the}} airborne computer.|$|E
2500|$|Since [...] is a {{connected}} and locally compact Lie group, {{we have a}} simple standard criterion for uniformity, namely that the distribution be unchanged when composed with any arbitrary rotation (a Lie group [...] "translation"). This definition corresponds to what is called Haar measure. [...] show {{how to use the}} Cayley transform to <b>generate</b> <b>and</b> <b>test</b> matrices according to this criterion.|$|E
50|$|The MM II missile was {{deployed}} with a D-37C disk computer. Autonetics also programmed functional simulators and {{the code}} inserter verifier {{that was used}} at Wing headquarters to <b>generate</b> <b>and</b> <b>test</b> the flight program codes {{to go into the}} airborne computer.|$|E
50|$|Another {{approach}} {{followed was}} the generate-and-test approaches where a trial route is <b>generated</b> <b>and</b> <b>tested</b> for satisfaction of constraints. This also leads to unpredictable results where each route {{has to be}} validated.|$|R
40|$|In this document, {{we define}} an {{object-oriented}} class structure for <b>generating</b> <b>and</b> <b>testing</b> random number generators. The structure {{is intended to}} provide a uniform, {{easy to use and}} easy to extend system for investigating random number generators. Implementations including a variety of generators <b>and</b> <b>tests</b> is available on the net...|$|R
5000|$|Physical {{models of}} atomistic systems have played an {{important}} role in understanding chemistry <b>and</b> <b>generating</b> <b>and</b> <b>testing</b> hypotheses. Most commonly there is an explicit representation of atoms, though other approaches such as soap films and other continuous media have been useful. There are several motivations for creating physical models: ...|$|R
50|$|In {{computer}} science, brute-force search or exhaustive search, {{also known}} as <b>generate</b> <b>and</b> <b>test,</b> is a very general problem-solving technique that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement.|$|E
5000|$|Trial {{and error}} {{is also a}} {{heuristic}} method of problem solving, repair, tuning, or obtaining knowledge. In the field of computer science, the method is called <b>generate</b> <b>and</b> <b>test.</b> In elementary algebra, when solving equations, it is [...] "guess and check".|$|E
5000|$|The rapid cyclic {{nature of}} the discovery, re-engineer, <b>generate</b> <b>and</b> <b>test</b> cycle used in this {{approach}} means that solutions can be refined iteratively {{in terms of their}} logical and physical definitions as more of the constraints become known and the solution architecture is refined.|$|E
40|$|This work {{deals with}} {{testability}} analysis of digital circuits and fault coverage. It contains a desription of digital systems, their diagnosis, {{a description of}} tools for <b>generating</b> <b>and</b> applying <b>tests</b> <b>and</b> sets of benchmark circuits. It describes the <b>testing</b> of circuits <b>and</b> experimentation in tool TASTE for testability analysis and commercial tool for <b>generating</b> <b>and</b> applying <b>tests.</b> The experiments are focused on increase the testability of circuits...|$|R
25|$|Genetically {{engineered}} {{organisms are}} <b>generated</b> <b>and</b> <b>tested</b> {{in the laboratory}} for desired qualities. The most common modification is to add one or more genes to an organism's genome. Less commonly, genes are removed or their expression is increased or silenced {{or the number of}} copies of a gene is increased or decreased.|$|R
5000|$|C++Builder 2009 {{introduces}} a [...] "Precompiled Header Wizard" [...] which parses all source modules {{of the project}} for included header files, classifies them (i.e. excludes header files if {{they are part of}} the project or do not have an Include guard) <b>and</b> <b>generates</b> <b>and</b> <b>tests</b> a precompiled header for the specified files automatically.|$|R
50|$|Collaborative {{filtering}} such as recommender systems, <b>generate</b> <b>and</b> <b>test</b> {{methods such as}} A/B testing, {{and machine}} learning techniques such as clustering and classification that are used on a website do not make it an adaptive website. They are all tools and techniques {{that may be used}} toward engineering an adaptive website.|$|E
50|$|Experimental {{archaeology}} (also called experiment {{archaeology and}} experiential archaeology) {{is a field}} of study which attempts to <b>generate</b> <b>and</b> <b>test</b> archaeological hypotheses, usually by replicating or approximating the feasibility of ancient cultures performing various tasks or feats. It employs a number of methods, techniques, analyses, and approaches, based upon archaeological source material such as ancient structures or artifacts.|$|E
50|$|In {{computer}} science, bogosort (also permutation sort, stupid sort, slowsort, shotgun sort or monkey sort) is {{a highly}} ineffective sorting algorithm based on the <b>generate</b> <b>and</b> <b>test</b> paradigm. The algorithm successively generates permutations of its input until it finds one that is sorted. It is not useful for sorting, but {{may be used for}} educational purposes, to contrast it with more efficient algorithms.|$|E
30|$|Addressing second-order {{interactions}} will be challenging. It {{will likely}} begin with visualising and formulating potential interactions, followed by <b>generating</b> <b>and</b> <b>testing</b> hypotheses concerning {{the nature and}} drivers of the interactions. <b>Testing</b> the hypotheses <b>and</b> <b>generating</b> new ones, however, will surely be helped by the large volumes of new types of data that can now be collected using remote-sensing and new laboratory-assay technologies.|$|R
50|$|The SMS Book Series is {{published}} {{in cooperation with}} Wiley-Blackwell and focuses on cutting edge concepts/topics in strategic management theory and practice. The books emphasize building and maintaining bridges {{between theory and practice}} in strategic management. The work published <b>generates</b> <b>and</b> <b>tests</b> theories of strategic management and it demonstrates how to learn, understand and apply these theories in practice.|$|R
50|$|Korol’s {{work on the}} {{evolution}} of sex and recombination includes developing theoretical models to explain the factors responsible for sex and recombination maintenance, their role in adaptation and genome evolution. In addition, Korol’s group has <b>generated</b> <b>and</b> <b>tested</b> empirical evidences based on assessment of DNA sequence variation in natural populations aiming at the ecological-genetic regulation of recombination and mutation.|$|R
5000|$|Since [...] is a {{connected}} and locally compact Lie group, {{we have a}} simple standard criterion for uniformity, namely that the distribution be unchanged when composed with any arbitrary rotation (a Lie group [...] "translation"). This definition corresponds to what is called Haar measure. [...] show {{how to use the}} Cayley transform to <b>generate</b> <b>and</b> <b>test</b> matrices according to this criterion.|$|E
50|$|While at Yale, she {{encountered}} several {{other people who}} would be leaders in psychology in the future, such as Mark Zanna, Michael Storms, Ellen Langer, Carol Dweck, James Cutting, Henry Roediger, and Robert Kraut. A very significant person in Taylor's academic career was Kenneth Kensington, a psychiatrist at the Yale School of Medicine. He typically did not work with psychology graduate students, but after some persuasion, he taught Taylor and some other students about using interviews as a tool to <b>generate</b> <b>and</b> <b>test</b> hypotheses.|$|E
50|$|In any vector space, {{and more}} {{generally}} in any matroid, a minimum weight basis {{may be found}} by a greedy algorithm that considers potential basis elements one at a time, in sorted order by their weights, and that includes an element in the basis when it is linearly independent of the previously chosen basis elements. Testing for linear independence {{can be done by}} Gaussian elimination. However, an undirected graph may have an exponentially large set of simple cycles, so it would be computationally infeasible to <b>generate</b> <b>and</b> <b>test</b> all such cycles.|$|E
40|$|Annotations of enzyme {{function}} provide critical {{starting points}} for <b>generating</b> <b>and</b> <b>testing</b> biological hypotheses, {{but the quality}} of functional annotations is hindered by uncertain assignments for uncharacterized sequences and by the relative sparseness of validated experimental data. Given the relentless increase in genomic data, new thinking and validation methods are urgently needed to provide high confidence in enzyme functional assignments...|$|R
40|$|In {{developmental}} psycholinguistics, we have, {{for many}} years, been <b>generating</b> <b>and</b> <b>testing</b> theories that propose both descriptions of adult representations and explanations of how those representations develop. We have learnt that restricting ourselves {{to any one}} methodology yields only incomplete data {{about the nature of}} linguistic representations. We argue that we need a multi-method approach to the study of representation...|$|R
50|$|Scientific dissent is dissent from {{scientific}} consensus. Disagreements can {{be useful}} for finding problems in underlying assumptions, methodologies, and reasoning, {{as well as for}} <b>generating</b> <b>and</b> <b>testing</b> new ways of tackling the unknown. In modern times, with the increased role of science on the society and the politicization of science, a new aspect gained prominence: effects of scientific dissent on public policies.|$|R
5000|$|Another {{aspect of}} {{enhanced}} discovery learning is allowing the learner to generate ideas about a topic {{along the way}} and then having students explain their thinking (Marzano, 2011). A teacher who asks the students to generate their own strategy for solving a problem may be provided with examples in how to solve similar problems ahead of the discovery learning task. [...] "A student might {{come up to the}} front of the room to work through the first problem, sharing his or her thinking out loud. The teacher might question students and help them formulate their thinking into general guidelines for estimation, such as [...] "start by estimating the sum of the highest place-value numbers." [...] As others come {{to the front of the}} room to work their way through problems out loud, students can <b>generate</b> <b>and</b> <b>test</b> more rules" [...] (Marzano, 2011, p. 87).|$|E
50|$|The main {{disadvantage}} of the brute-force method is that, for many real-world problems, {{the number of}} natural candidates is prohibitively large. For instance, if we look for the divisors of a number as described above, the number of candidates tested will be the given number n. So if n has sixteen decimal digits, say, the search will require executing at least 1015 computer instructions, which will take several days on a typical PC. If n is a random 64-bit natural number, which has about 19 decimal digits on the average, the search will take about 10 years. This steep {{growth in the number}} of candidates, as the size of the data increases, occurs in all sorts of problems. For instance, if we are seeking a particular rearrangement of 10 letters, then we have 10! = 3,628,800 candidates to consider, which a typical PC can <b>generate</b> <b>and</b> <b>test</b> in less than one second. However, adding one more letter — which is only a 10% increase in the data size — will multiply the number of candidates by 11 — a 1000% increase. For 20 letters, the number of candidates is 20!, which is about 2.4×1018 or 2.4 quintillion; and the search will take about 10 years. This unwelcome phenomenon is commonly called the combinatorial explosion, or the curse of dimensionality.|$|E
40|$|Fixturing, i. e. {{the process}} of immobilizing a {{workpiece}} for manufacturing or assembly operations, is a fundamental task in manufacturing. Fixtures can either be fabricated from scratch or assembled from a toolkit of modular components; the latter approach is termed modular fixturing. Recently, many researchers have proposed <b>generate</b> <b>and</b> <b>test</b> fixture design algorithms for minimal modular fixture toolkits where minimal fixture toolkits incorporate a single degree of freedom and constrain fixture elements to {{a finite number of}} locations. <b>Generate</b> <b>and</b> <b>test</b> strategies have succeeded because minimal fixture toolkits can only fixture generic workpieces in a finite number of ways. In this paper, we present alternative minimal toolkits and two generic fixture design algorithms: a complete enumeration algorithm based upon the <b>generate</b> <b>and</b> <b>test</b> paradigm, and an efficacious heuristic hill climbing algorithm. Our <b>generate</b> <b>and</b> <b>test</b> design algorithm is based upon a duality we observed between fixture [...] ...|$|E
40|$|When {{stimulated by}} chemoattractants, {{eukaryotic}} cells respond {{through a combination}} of temporal and spatial dynamics. These responses come about because of the interaction {{of a large number of}} signaling components. The complexity of these systems makes it hard to understand without a means of systematically <b>generating</b> <b>and</b> <b>testing</b> hypotheses. Computer simulations have proved to be useful in testing conceptual models. Here we outline the steps required to develop these models...|$|R
30|$|The {{additional}} calibration antenna <b>generates</b> <b>and</b> transmits a <b>test</b> signal.|$|R
40|$|Abstract. Many feature {{selection}} and feature ranking {{methods have been}} proposed. Using real and artificial data an attempt {{has been made to}} compare some of these methods. The "feature relevance index " used seems to have little effect on the relative ranking. For continuous features discretization and kernel smoothing are compared. Selection of subsets of features using hashing techniques is compared with the "golden standard " of <b>generating</b> <b>and</b> <b>testing</b> all possible subsets of features. ...|$|R
40|$|The {{revolution}} in neuroscientific data acquisition is creating an analysis challenge. We propose leveraging cloud-computing technologies to enable large-scale neurodata storing, exploring, analyzing, and modeling. This utility will empower scientists globally to <b>generate</b> <b>and</b> <b>test</b> theories of brain function and dysfunction...|$|E
40|$|We {{present a}} {{computer}} package designed to <b>generate</b> <b>and</b> <b>test</b> norm-conserving pseudo-potentials within Density Functional Theory. The generated pseudo-potentials {{can be either}} non-relativistic, scalar relativistic or fully relativistic and can explicitly include semi-core states. A wide range of exchange-correlation functionals is included. Program summary[URL]...|$|E
40|$|In the {{proposed}} demo, {{a new approach}} to e-learning environments for deaf people is illustrated. Using a fully iconic web-based environment, a tutor can define, <b>generate</b> <b>and</b> <b>test</b> e-learning courses for deaf people, which are automatically managed, published and served by the system itself. © 2012 Authors...|$|E
30|$|Naturally {{occurring}} metastable {{chemical and}} physical states {{can serve as}} testable information carriers. In {{the presence of a}} substantial thermodynamic disequilibrium, information is constantly <b>generated</b> <b>and</b> <b>tested,</b> representing a new view of chemical reaction models where reactants are observed in terms of survivability. Pre-biotic chemical evolution does not require replication with explicit heredity but, rather only needs information addition, diffusion, and an exergy source. A form of informational ‘heredity’ in terms of an exploitation search is required, however.|$|R
40|$|Data {{collected}} {{by a single}} observer on 147 schizophrenic patients were subjected to clustering analysis. The results produced the hypothesis that schizophrenic illnesses directly after childbirth are a separate disease entity. This hypothesis was not disproved by experimental testing. Several disease entities may {{be included in the}} term schizophrenia. If this is so, the methods used in <b>generating</b> <b>and</b> <b>testing</b> the hypothesis that puerperal schizophrenia is a separate disease may provide a systematic method of classifying the various illnesses...|$|R
40|$|This paper {{discusses}} the algorithms and implementations of three Mathematica packages {{for the study}} of integrability and the computation of closed-form solutions of nonlinear polynomial PDEs. The first package, PainleveTest. m, symbolically performs the Painleve integrability test. The second package, PDESpecialSolutions. m, computes exact solutions expressible in hyperbolic or elliptic functions. The third package, PDERecursionOperator. m, <b>generates</b> <b>and</b> <b>tests</b> recursion operators. Comment: 15 pages for the CRM Proceedings of the Workshop on Group Theory and Numerical Method...|$|R
