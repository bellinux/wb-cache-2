711|446|Public
5|$|New {{information}} presents {{improvements in}} multithreading, resilency improvements (Intel Instruction Replay RAS) and few new instructions (thread priority, integer <b>instruction,</b> <b>cache</b> prefetching, and data access hints).|$|E
25|$|MIPS16 is an Application-Specific Extension for MIPS I {{through to}} V {{designed}} by LSI Logic and MIPS Technologies, announced on 21 October 1996 alongside its first implementation, the LSI Logic TinyRISC processor. MIPS16 was subsequently licensed by NEC Electronics, Philips Semiconductors, and Toshiba (among others); and implemented {{as an extension}} to the MIPS I, II, an III architectures. MIPS16 decreases the size of application by up to 40% by using 16-bit instructions instead of 32-bit instructions' and also improves power efficiency, the <b>instruction</b> <b>cache</b> hit rate, and is equivalent in performance to its base architecture. It is supported by hardware and software development tools from MIPS Technologies and other providers.|$|E
25|$|The SIMD vector {{processor}} (VMX128) was modified for the Xbox {{to include a}} dot-product instruction. The dot-product instruction took far less latency than discrete instructions. The VMX128 was also modified {{by the addition of}} direct 3D (D3D) compressed data format. This led to an approximate 50 percent savings in required band-width and memory footprint making the CPU having a theoretical peak performance of 115.2GFLOPS, being capable of 9.6 billion dot products per second. Each core of the CPU was capable of simultaneous multithreading and was clocked at 3.2GHz. However, to reduce CPU die size, complexity, cost, and power demands, the processor used in-order execution in contrast to the Intel Coppermine 128-based Pentium III used in the original Xbox, which used more complex out of order execution. The original chip used a 90nm process, although a newer 65nm process SOI revision was implemented on later models, which was in-turn superseded by a 45nm combined CPU and GPU chip. A 21.6GB/s front side bus, aggregated 10.8GB/s upstream and downstream, connected Xenon with the graphics processor/northbridge. Xenon was equipped with an 8th way set associative 1MB Level 2 cache on-die running at half CPU clock speed. This cache was shared amongst the three CPU cores. Each core had separate L1 caches, each containing a two-way set associative 32-Kbyte L1 <b>instruction</b> <b>cache</b> and a four-way set associative 32-Kbyte L1 data cache. The write-through data cache did not allocate cache lines on writes. The CPU also contained ROM storing Microsoft private encrypted keys, used to decrypt game data. The heat sink implemented to cool the Xenon CPU was composed of aluminum fins with a copper base, and a heat pipe. Newer revisions, which had a smaller core, do not feature the heat pipe or copper base. The heat sink was cooled by two 70mm fans {{at the rear of the}} console on original-style consoles, while a single fan mounted on the side of the consoles was used in Xbox 360 S consoles. There were several types of fan used in Xbox 360s, which were produced by Nidec, Sunon and Delta Electronics.|$|E
5000|$|... 4 KiB {{data and}} <b>instruction</b> <b>caches</b> (Level 1). No Level 2 cache ...|$|R
30|$|This paper aims {{to combine}} {{state-of-the-art}} mechanisms intended for <b>instruction</b> and data <b>caches</b> in a two-level hierarchy (with separated <b>instruction</b> and data <b>caches</b> for both levels) {{resulting in a}} combined optimization mechanism that determines the most suitable relation between energy consumption and performance applications. Comparisons between previously reported optimization mechanisms were analyzed {{in terms of their}} specialties for data and <b>instruction</b> <b>caches</b> and some results are shown in the next section.|$|R
40|$|An {{accurate}} and reliable estimation of a task's worst case execution time (WCET) {{is crucial for}} scheduling of real-time tasks. However, <b>instruction</b> <b>caches,</b> which are extensively used in computer systems today, impose a serious problem in analyzing the WCETs of tasks. The problem {{stems from the fact}} that the cache hit or miss of an instruction reference can be known only after the worst case execution path has been found and the worst case execution path, on the other hand, can be located only after the cache hit or miss of every instruction reference is known. This cyclic dependency, in many cases, leads to a pessimistic estimation of WCETs. This paper proposes an analysis technique that is immune from the above cyclic dependency and accurately predicts the WCETs of tasks in the presence of <b>instruction</b> <b>caches.</b> The key to the proposed technique is an extension of the timing schema[16] so that the timing variation due to <b>instruction</b> <b>caches</b> can be accurately accounted for. This paper also [...] ...|$|R
500|$|Physically, the Dreamcast {{measures}} [...] {{and weighs}} [...] [...] The Dreamcast's main CPU is a two-way 360MIPS superscalar Hitachi SH-4 32-bit RISC clocked at 200MHz with an 8 Kbyte <b>instruction</b> <b>cache</b> and 16 Kbyte data cache and a 128-bit graphics-oriented floating-point unit delivering 1.4GFLOPS. Its 100MHz NEC PowerVR2 rendering engine, {{integrated with the}} system's ASIC, is capable of drawing more than 3 million polygons per second and of deferred shading. Sega estimated that the Dreamcast was theoretically capable of rendering 7 million raw polygons per second, or 6 million with textures and lighting, but noted that [...] "game logic and physics reduce peak graphic performance." [...] Graphics hardware effects include trilinear filtering, gouraud shading, z-buffering, spatial anti-aliasing, per-pixel translucency sorting and bump mapping. The system can output approximately 16.77 million colors simultaneously and displays interlaced or progressive scan video at 640×480 video resolution. Its 67MHz Yamaha AICA sound processor, with a 32-bit ARM7 RISC CPU core, can generate 64 voices with PCM or ADPCM, providing ten times {{the performance of the}} Saturn's sound system. [...] The Dreamcast has 16 MB main RAM, along with an additional 8 MB of RAM for graphic textures and 2 MB of RAM for sound. [...] The system reads media using a 12x speed Yamaha GD-ROM Drive. In addition to Windows CE, the Dreamcast supports several Sega and middleware application programming interfaces. In most regions, the Dreamcast included a removable modem for online connectivity, which was modular for future upgrades. The original Japanese model and all PAL models had a transfer rate of 33.6kbit/s, while consoles sold in the US and in Japan after September 9, 1999 featured a 56 kbit/s dial-up modem.|$|E
2500|$|PPE {{consists}} of three main units: Instruction Unit (IU), Execution Unit (XU) and vector/scalar execution unit (VSU). IU contains L1 <b>instruction</b> <b>cache,</b> branch prediction hardware, instruction buffers and dependency checking login. XU contains integer execution units (FXU) and load-store unit (LSU). VSU contains all of the execution resources for FPU and VMX. [...] Each PPE can complete two double precision operations per clock cycle using a scalar fused-multiply-add instruction, which translates to 6.4GFLOPS at 3.2GHz; or eight single precision operations per clock cycle with a vector fused-multiply-add instruction, which translates to 25.6GFLOPS at 3.2GHz.|$|E
5000|$|There can be {{incoherent}} <b>instruction</b> <b>cache</b> pipeline, {{which prevents}} self-modifying code from being executed without special <b>instruction</b> <b>cache</b> flush/reload instructions.|$|E
5000|$|STn8820 Based on ARM11, {{released}} in 2008 with 32KiB data and <b>instruction</b> <b>caches</b> and 256KiB level 2 cache, clocked at 528 MHz. It was manufactured in 65 nanometer silicon technology.|$|R
40|$|CMOS devices {{suffer from}} wearout {{mechanisms}} resulting in reliability issues. Negative bias temperature instability (NBTI) {{is one of}} the dominant ageing effects that can cause threshold voltage shift on PMOS devices and subsequently impact circuit performance. The static noise margin (SNM) of an SRAM cell may be sharply reduced with unbalanced NBTI stress. This will impact SRAM read stability. From our observations of <b>instruction</b> <b>caches,</b> NBTI stress duty cycles for each cache line generally have similar but unbalanced patterns even when running very different programs. Based on the patterns, we propose an algorithm to evaluate the lifetime of <b>instruction</b> <b>caches</b> by running SPICE simulation. The results predict 6 and 7 years NBTI lifetimes of <b>instruction</b> <b>caches</b> for ARM and MIPS architectures respectively. One of the practical solutions is periodically flipping each cell to balance the degradation rate. However the performance benefits in terms of lifetime are not actually proven before. Using the stress patterns and lifetime evaluation algorithm, our work for the first time prove this technique can extend the lifetime of the cache by two orders of magnitude...|$|R
40|$|As {{microprocessor}} complexities {{and costs}} skyrocket, designers {{are looking for}} ways to simplify their designs to reduce costs, improve energy efficiency, or squeeze more computational elements on each chip. This is particularly true for the embedded domain where cost and energy consumption are paramount. Software <b>instruction</b> <b>caches</b> have the potential to provide the required performance while using simpler, more efficient hardware. A software cache consists of a simple array memory (such as a scratchpad) and a software system that is capable of automatically managing that memory as a cache. Software caches have several advantages over traditional hardware caches. Without complex cache-management logic, the processor hardware is cheaper and easier to design, verify and manufacture. The reduced access energy of simple memories can result in a net energy savings if management overhead is kept low. Software caches can also be customized to each individual program's needs, improving performance or eliminating unpredictable timing for real-time embedded applications. The greatest challenge for a software cache is providing good performance using general-purpose <b>instructions</b> for <b>cache</b> management rather than specially-designed hardware. This thesis designs and implements a working system (Flexicache) on an actual embedded processor and uses it to investigate the strengths and weaknesses of software <b>instruction</b> <b>caches.</b> Although both data and <b>instruction</b> <b>caches</b> can be implemented in software, very different techniques are used to optimize performance; this work focuses exclusively on software <b>instruction</b> <b>caches.</b> The Flexicache system consists of two software components: a static off-line preprocessor to add caching to an application and a dynamic runtime system to manage memory during execution. Key interfaces and optimizations are identified and characterized. The system is evaluated in detail from the standpoints of both performance and energy consumption. The results indicate that software <b>instruction</b> <b>caches</b> can perform comparably to hardware caches in embedded processors. On most benchmarks, the overhead relative to a hardware cache is less than 12 % and can be as low as 2. 4 %. At the same time, the software cache uses up to 6 % less energy. This is achieved using a simple, directly-addressed memory and without requiring any complex, specialized hardware structures. by Jason Eric Miller. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2007. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Includes bibliographical references (p. 185 - 193) ...|$|R
50|$|On {{architectures}} without coupled {{data and}} <b>instruction</b> <b>cache</b> (some ARM and MIPS cores) the cache synchronization must be explicitly {{performed by the}} modifying code (flush data cache and invalidate <b>instruction</b> <b>cache</b> for the modified memory area).|$|E
50|$|The R4200 has a 16 KB <b>instruction</b> <b>cache</b> and an 8 KB data cache. Both caches are direct-mapped. The <b>instruction</b> <b>cache</b> has a 32-byte line size, {{whereas the}} data cache has 16-byte line size. The data cache uses the {{write-back}} write protocol.|$|E
50|$|A {{variant of}} {{prefetch}} for the <b>instruction</b> <b>cache.</b>|$|E
40|$|Abstract — Traditional level-one <b>instruction</b> <b>caches</b> {{and data}} caches for {{embedded}} systems typically {{have the same}} capacities. Configurable caches either shut down {{a part of the}} cache to suit applications needing a small cache or employ a large cache and high associativity for applications needing to reduce miss rate and energy. However, increasing associativity is energy-costly compared with increasing capacity. We have extended the traditional configurable cache and made the whole on-chip cache memory capacity available to both <b>instruction</b> and data <b>caches.</b> The capacity can then be co-allocated between the data and the <b>instruction</b> <b>caches.</b> Compared with way shutdown and way concatenation, the capacity co-allocation cache provides a better solution than increasing associativity. Four out of 17 benchmarks from Mibench benefit from the capacity coallocation cache. Energy reduction can be up to 24 %, with an average of 5 %, compared to a traditional configurable cache. ...|$|R
5000|$|STn8815 Based on ARM926EJ-S, {{released}} in 2008 with 16KiB data and <b>instruction</b> <b>caches</b> and 128KiB level 2 cache, clocked at 334 MHz. This SoC {{was used in}} Nokia 6788 and N96, {{as well as in}} Samsung SGH-L870. It was manufactured in 90 nanometer silicon technology.|$|R
40|$|On-chip caches {{represent}} a sizeable {{fraction of the}} total power consumption of microprocessors. Although large caches can significantly improve performance, they have the potential to increase power consumption. As feature sizes shrink, the dominant component of this power loss will be leakage. In our previous work we have shown how the drowsy circuit—a simple, state-preserving, low-leakage circuit that relies on voltage scaling for leakage reduction— can be used to reduce the total energy consumption of data caches by more than 50 %. In this paper, we extend the architectural control mechanism of the drowsy cache to reduce leakage power consumption of <b>instruction</b> <b>caches</b> without significant impact on execution time. Our results show that data and <b>instruction</b> <b>caches</b> require different control strategies for efficient execution. To enable drows...|$|R
5000|$|... 8/16/32/64 KB <b>Instruction</b> <b>cache,</b> 8/16/32/64/128 KB Data cache ...|$|E
50|$|As the {{predictor}} RAM can be 5-10% {{of the size}} of the <b>instruction</b> <b>cache,</b> the fetch happens much faster than the <b>instruction</b> <b>cache</b> fetch, and so this recurrence is much faster. If it were not fast enough, it could be parallelized, by predicting target addresses of target branches.|$|E
50|$|The R10000 has {{two large}} (for 1996) on-chip caches, a 32 KB <b>instruction</b> <b>cache</b> and a 32 KB data cache. The <b>instruction</b> <b>cache</b> is two-way set-associative {{and has a}} 128-byte line size. Instructions are {{partially}} decoded by appending four bits to each instruction (which have a length of 32 bits) before they are placed in the cache.|$|E
40|$|As {{the issue}} width of superscalar {{processors}} is increased, instruction fetch bandwidth requirements will also increase. It will become necessary to fetch multiple basic blocks per cycle. Conventional <b>instruction</b> <b>caches</b> hinder this effort because long instruction sequences {{are not always}} in contiguous cache locations. We propos...|$|R
50|$|Support for Harvard cache, i.e. split {{data and}} <b>instruction</b> <b>caches,</b> {{as well as}} support for unified caches. Memory {{operations}} are strictly load/store, but allow for out-of-order execution. Support for both big and little-endian addressing with separate categories for moded and per-page endianness. Support for both 32-bit and 64-bit addressing.|$|R
50|$|The R3000 CPU {{does not}} include its own level 1 cache. Instead, the {{processor}} has an on-chip cache controller which controls separate external data and <b>instruction</b> <b>caches.</b> The size of each external cache can be as large as 256 KB. The CPU can access both caches during the same CPU cycle.|$|R
5000|$|The 68010, {{released}} in 1982, has a [...] "loop mode" [...] {{which can be}} considered a tiny and special-case <b>instruction</b> <b>cache</b> that accelerates loops that consist of only two instructions. The 68020, {{released in}} 1984, replaced that with a typical <b>instruction</b> <b>cache</b> of 256 bytes, being the first 68k series processor to feature true on-chip cache memory.|$|E
5000|$|Double the L1 <b>instruction</b> <b>cache</b> (from 8KB to 16KB), {{double the}} L2 {{associativity}} ...|$|E
5000|$|The {{capacity}} of the level 0 (L0) <b>instruction</b> <b>cache</b> was doubled to 8 KB.|$|E
50|$|Cache {{prefetching}} {{can either}} fetch data or <b>instructions</b> into <b>cache.</b>|$|R
40|$|Embedded {{microprocessor}} cache memories {{suffer from}} limited observability and controllability creating problems during in-system tests. This paper presents a procedure to transform traditional march tests into software-based self-test programs for set-associative cache memories with LRU replacement. Among {{all the different}} cache blocks in a microprocessor, testing <b>instruction</b> <b>caches</b> represents a major challenge due to limitations in two areas: 1) test patterns which must be composed of valid instruction opcodes and 2) test result observability: the results can only be observed through the results of executed instructions. For these reasons, the proposed methodology will concentrate on the implementation of test programs for <b>instruction</b> <b>caches.</b> The main contribution of this work lies {{in the possibility of}} applying state-of-the-art memory test algorithms to embedded cache memories without introducing any hardware or performance overheads and guaranteeing the detection of typical faults arising in nanometer CMOS technologie...|$|R
40|$|Power {{consumption}} is {{becoming one of}} the most important constraints in the VLSI field in nano-meter scale technologies. Especially, as a transistor for supply voltage and threshold voltage are scaled down, leakage energy {{consumption is}} increased even when the transistor is not switching. This paper proposes to use various techniques in reducing the static power as well as dynamic power consumption by using different cache techniques and various types of RAM. Keywords:- Caches, <b>instruction</b> <b>caches,</b> loop caches, low power, power gating, spin-transfer torque RAM (STT-RAM), power efficiency, static power and dynamic power...|$|R
5000|$|Redundant {{instruction}} storage between trace cache and <b>instruction</b> <b>cache</b> {{and within}} trace cache itself.|$|E
5000|$|... 16 KB L1 <b>instruction</b> <b>cache,</b> 16 KB L1 data cache, 256 KB L2 cache ...|$|E
5000|$|... 16 KB L1 <b>instruction</b> <b>cache,</b> 16 KB L1 data cache, 32 KB {{general-purpose}} SRAM ...|$|E
40|$|This paper proposes an {{architecture}} for low-power direct-mapped <b>instruction</b> <b>caches,</b> called “history-based tag-comparison (HBTC) cache”. The HBTC cache attempts {{to detect and}} omit unnecessary tag checks at run time. Execution footprints are recorded in an extended BTB (Branch Target Buffer), and are used to know the cache residence of target <b>instructions</b> before starting <b>cache</b> access. In our simulation, {{it is observed that}} our approach can reduce the total count of tag checks by 90 %, resulting in 15 % of cache-energy reduction, with less than 0. 5 % performance degradation...|$|R
5000|$|Query {{recycling}} is an architecture for reusing the byproducts of the operator-at-a-time paradigm {{in a column}} store DBMS. Recycling makes use of the generic idea of storing and reusing the results of expensive computations. Unlike low-level <b>instruction</b> <b>caches,</b> query recycling uses an optimizer to pre-select <b>instructions</b> to <b>cache.</b> The technique is designed to improve query response times and throughput, while working in a self-organizing fashion. The authors from the CWI Database Architectures group, composed of Milena Ivanova, Martin Kersten, Niels Nes and Romulo Goncalves, won the [...] "Best Paper Runner Up" [...] at the ACM SIGMOD 2009 conference for their work on Query Recycling.|$|R
50|$|This {{generation}} {{introduced the}} Thumb 16-bit instruction set providing improved code density compared to previous designs. The {{most widely used}} ARM7 designs implement the ARMv4T architecture, but some implement ARMv3 or ARMv5TEJ. ARM7TDMI has 37 registers(31 GPR and 6 SPR). All these designs use a Von Neumann architecture, thus the few versions comprising a cache do not separate data and <b>instruction</b> <b>caches.</b>|$|R
