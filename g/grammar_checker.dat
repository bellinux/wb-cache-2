89|13|Public
25|$|These {{and similar}} {{electronic}} typewriters were in essence dedicated word processors with either single-line LCD displays or multi-line CRT displays, built-in line editors in ROM, a spelling and <b>grammar</b> <b>checker,</b> a few kilobytes of internal RAM and optional cartridge, magnetic card or diskette external memory-storage devices for storing text and even document formats. Text could be entered a line or paragraph {{at a time}} and edited using the display and built-in software tools before being committed to paper.|$|E
50|$|OpenTaal also {{provides}} grammar rules {{which are used}} in the <b>grammar</b> <b>checker</b> LanguageTool. This is offering grammar checking via its own website but is also used by OpenOffice.org and Thunderbird. This <b>grammar</b> <b>checker</b> also identifies possible false friends.|$|E
5000|$|Lightproof, a Python-based <b>grammar</b> <b>checker</b> {{embedded}} in LibreOffice ...|$|E
40|$|This paper {{presents}} a <b>grammar</b> and style <b>checker</b> demonstrator for Spanish native writers developed within the project GramCheck. Besides a grammar and style error typology for Spanish, a linguistically motivated approach to detection and diagnosis is presented. The demonstrator includes full coverage for agreement errors and certain head-argument relation issues. It also provides correction {{by means of}} an analysis-transfer-synthesis cycle...|$|R
50|$|Ginger Page {{operates}} as an online service and supports MS-Word, MS-Outlook, MS-PowerPoint, Internet Explorer, Chrome and Firefox, and {{functions as a}} writing enhancement app for Android and iOS mobile devices. Its main feature is the <b>grammar</b> and spelling <b>checker</b> that runs seamlessly with the different user interfaces. It also has an advanced paraphrasing tool, contextual synonyms and definitions, multi-language translation and a text-to-speech function that enables users to hear sentences before and after correction.|$|R
40|$|This paper {{argues that}} any {{system that has}} {{adequate}} Natural Language Processing resources to perform the basic tasks of a <b>grammar</b> and style <b>checker</b> can be augmented with a rule definition facility that, largely making use of those same resources, would be radically more usable than any existing system. The proposed approach is crucially dependent on the modular representation of system knowledge, and incorporates techniques from Knowledge Representation, Human Computer Interaction, and Machine Learning...|$|R
5000|$|The {{implementation}} of a <b>grammar</b> <b>checker</b> makes use of natural language processing ...|$|E
50|$|In the 2013 Best Online <b>Grammar</b> <b>Checker</b> Comparisons and Reviews, Grammarly won the TopTenReviews Gold Award, with {{a rating}} of 8.88.|$|E
5000|$|WSC {{works in}} a {{separate}} pop-up window and automatically returns corrected text to the form. It is also extended with English <b>Grammar</b> <b>Checker</b> and Thesaurus functionality.|$|E
40|$|This paper {{presents}} a <b>grammar</b> and style <b>checker</b> demonstrator for Spanish and Greek native writers developed within the project GramCheck. Besides a brief grammar error typology for Spanish, a linguistically motivated approach to detection and diagnosis is presented, {{based on the}} generalized use of PROLOG extensions to highly typed unification-based grammars. The demonstrator, currently including full coverage for agreement errors and certain head-argument relation issues, also provides correction {{by means of an}} analysis-transfer-synthesis cycle. Finally, future extensions to the current system are discussed. ...|$|R
40|$|We {{present a}} simple yet {{powerful}} syntax error checker {{that can be}} automatically generated from an input Conterxt-Free <b>grammar.</b> This <b>checker</b> tests every two consecutive tokens of a source computer program for their syntactic legitimacy. Such a checker {{can be incorporated into}} the scanner of a compiler before the parser can perform a full-blown complete syntax checking. We generate the checker as a boolean matrix simply by compositions of some binary relations we define that specifies whether or not two given ordered tokens of a source language can ever legitimately appear in that order in any program of the source language. Although clearly such a matrix only represents a minimum syntax requirement that any syntactically correct program must satisfy, such a checker will provide some benefits including an earlier syntax error detection and the reduction of a burden imposed on the parser...|$|R
40|$|This paper {{presents}} an implemented hybrid approach to grammar and style checking, combining an industrial patternbased <b>grammar</b> and style <b>checker</b> with bidirectional, large-scale HPSG grammars for German and English. Under this approach, deep processing is applied selectively {{based on the}} error hypotheses of a shallow system. We have conducted a comparative evaluation of the two components, supporting an integration scenario where the shallow system is best used for error detection, whereas the HPSG grammars add error correction for both grammar and controlled language style errors. ...|$|R
50|$|Although grammar {{checkers}} {{have largely}} been concentrated on ensuring grammatical writing, {{majority of them are}} modelled after native writers, neglecting the needs of non-native language users. Much research have attempted to tailor grammar checkers to the needs of non-native language users. Granska, a Swedish <b>grammar</b> <b>checker,</b> has been greatly worked upon by numerous researchers in the investigation of grammar checking properties for foreign language learners. The Universidad Nacional de Educación a Distancia has a computerised <b>grammar</b> <b>checker</b> for native Spanish speakers of EFL to help identify and correct grammatical mistakes without feedback from teachers.|$|E
50|$|LanguageTool is a {{free and}} open-source, {{cross-platform}} spell and <b>grammar</b> <b>checker</b> {{which can be used}} as an extension in LibreOffice/OpenOffice, Vim, Emacs, Firefox and Thunderbird, or as a stand-alone desktop application. It can also be integrated on websites.|$|E
50|$|True grammar {{checking}} is more complex. While {{a computer}} programming language {{has a very}} specific syntax and grammar, {{this is not so}} for natural languages. One can write a somewhat complete formal grammar for a natural language, but there are usually so many exceptions in real usage that a formal grammar is of minimal help in writing a <b>grammar</b> <b>checker.</b> One of the most important parts of a natural language <b>grammar</b> <b>checker</b> is a dictionary of all the words in the language, along with the part of speech of each word. The fact that natural words can take many different parts of speech greatly increases the complexity of any grammar checker.A <b>grammar</b> <b>checker</b> will find each sentence in a text, look up each word in the dictionary, and then attempt to parse the sentence into a form that matches a grammar. Using various rules, the program can then detect various errors, such as agreement in tense, number, word order, and so on. It is also possible to detect some stylistic problems with the text. For example, some popular style guides such as The Elements of Style deprecate excessive use of the passive voice. Grammar checkers may attempt to identify passive sentences and suggest an active-voice alternative.|$|E
40|$|Composition studies lacks a {{comprehensive}} theory of error, one which successfully defines {{error in writing}} and offers a pedagogical response to ostensible errors that neither ignores nor pathologizes them. Electronic text-critiquing technologies offer some promise of helping writers notice and correct errors, but they are under-researched in composition and rarely well-integrated into pedagogical praxis. This research on the <b>grammar</b> and style <b>checker</b> in Microsoft Word considers the program as an electronic checklist for making decisions about what counts as an error in a given rhetorical situation. This study also offers a theory of error grounded {{in the idea of}} attention, or cognitive load, some of which an electronic checker can relieve in its areas of its greatest effectiveness, which this research quantifies. The proposed theory of error forms the basis for a pedagogy of register, understood as typified style, and establishes that error itself can be a strategic style move...|$|R
40|$|This paper {{presents}} an English <b>grammar</b> and style <b>checker</b> for non-native English speakers. The main characteristic of this checker {{is the use}} of an Internet search engine. As the number of web pages written in English is immense, the system hypothesises that a piece of text not found on the Web is probably badly written. The system also hypothesises that the Web will provide examples of how the content of the text segment can be expressed in a grammatically correct and idiomatic way. Thus, when the checker warns the user about the odd nature of a text segment, the Internet engine searches for contexts that can help the user decide whether he/she should correct the segment or not. By means of a search engine, the checker also suggests use of other expressions that appear on the Web more often than the expression he/she actually wrote...|$|R
5000|$|Transcription and {{transposition}} errors {{may also}} occur in syntax when computer programming or programming, within variable declarations or coding parameters. This should be checked by proofreading; some syntax errors {{may also be}} picked up by the program the author is using to write the code. Common desktop publishing and word processing applications use spell checkers and grammar checkers, which may pick up on some transcription/transposition errors; however, these tools cannot catch all errors, as some errors form new words which are grammatically correct. For instance, if the user wished to write [...] "The fog was dense", but instead put [...] "The dog was dense", a <b>grammar</b> and spell <b>checker</b> would not notify the user because both phrases are grammatically correct, as is the spelling of the word [...] "dog". Unfortunately, this situation is likely to get worse before it gets better, as workload for users and workers using manual direct data entry (DDE) devices increases.|$|R
50|$|The AbiWord project {{includes}} a US English-only grammar checking plugin using Link Grammar. AbiWord had grammar checking before any other open source word processor, although a <b>grammar</b> <b>checker</b> was later added to OpenOffice.org. Link Grammar {{is both a}} theory of syntax and an open source parser which is now developed by the AbiWord project.|$|E
50|$|MindNet is {{the name}} of several {{automatically}} acquired databases of lexico-semantic relations developed by members of the Natural Language Processing Group at Microsoft Research during the 1990s. The underlying technology is based on the same parser used in the Microsoft Word <b>grammar</b> <b>checker</b> and was deployed in the natural language query engine in Microsoft's Encarta 99 encyclopedia.|$|E
5000|$|A <b>grammar</b> <b>checker,</b> in {{computing}} terms, is a program, {{or part of}} a program, {{that attempts}} to verify written text for grammatical correctness. Grammar checkers are most often implemented as a feature of a larger program, such as a word processor, but are also available as a stand-alone application that can be activated from within programs that work with editable text.|$|E
40|$|The {{following}} report aims to give {{insight into}} the design and implementation of a statically typed functional language for the Erlang virtual machine, discussing how such an implementation may be approached and whether {{it appears to be}} feasible. The primary goal of the project was to design a grammar specification and implement a compiler for such a language. Over the course of the project a prototype language and a compiler for that language were developed. The project followed an iterative development process with Scrum as a basis. Notable modules of the compiler are the parser generated from a BNF <b>grammar,</b> the type <b>checker</b> implementing a Hindley-Milner type system and the code generator generating Core Erlang source code. The result of the project is Hopper, a basic functional programming language with an accompanying compiler, featuring polymorphic algebraic data types (ADTs), pattern matching and lambdas. The language also has a module system and some integration with Erlang. In conclusion, the project was largely successful in its mission to create a typed functional language on the Erlang VM and {{has the potential to be}} developed further...|$|R
40|$|In {{this paper}} we present an English <b>grammar</b> and style <b>checker</b> for {{non-native}} English speakers. The main characteristic of this checker {{is the use}} of an Internet search engine. As the number of web pages written in English is immense, the system hypothesizes that a piece of text not found on the Web is probably badly written. The system also hypothesizes that the Web will provide examples of how the content of the text segment can be expressed in a gramatical and idiomatic way. So, after the checker warns the user about the odd character of a text segment, the Internet engine searches for contexts that will be helpful for the user to decide whether he/she corrects the segment or not. By means of a search engine, the checker also suggests the writer to use expressions which are more frequent on theWeb other than the expression he/she actually wrote. Although the system is currently being developed for teachers of the Open University of Catalonia, the checker can also be useful for second-language learners, translators, and post-editors. 1...|$|R
40|$|This paper {{presents}} an algorithm for correcting language errors typical of second-language learners. We focus on preposition errors, {{which are very}} common among second-language learners but are not addressed well by current commercial grammar correctors and editing aids. The algorithm takes as input a sentence containing a preposition error (and possibly other errors as well), and outputs the correct preposition for that particular sentence context. We use a two-phase hybrid rule-based and statistical approach. In the first phase, rule-based processing is used to generate a short expression that captures the context of use of the preposition in the input sentence. In the second phase, Web searches are {{used to evaluate the}} frequency of this expression, when alternative prepositions are used instead of the original one. We tested this algorithm on a corpus of 133 French sentences written by intermediate second-language learners, and found that it could address 69. 9 % of those cases. In contrast, we found that the best French <b>grammar</b> and spell <b>checker</b> currently on the market, Antidote, addressed only 3 % of those cases. We also showed that performance degrades gracefully when using a corpus of frequent n-grams to evaluate frequencies. 1...|$|R
50|$|Aspen Software of Albuquerque, NM {{released}} the earliest {{version of a}} diction and style checker for personal computers, Grammatik, in 1981. Grammatik was first available for a Radio Shack - TRS-80, and soon had versions for CP/M and the IBM PC. Reference Software of San Francisco, CA, acquired Grammatik in 1985. Development of Grammatik continued, and it became an actual <b>grammar</b> <b>checker</b> that could detect writing errors beyond simple style checking.|$|E
50|$|Theoretically, the {{functions}} of a conventional spell checker {{can be incorporated into}} a <b>grammar</b> <b>checker</b> entirely and this is likely the route that the language processing industry is working towards. In reality, internationally available word processors such as Microsoft Word have difficulties combining spell checkers and grammar checkers due to licensing issues; various proofing instrument mechanisms for a certain language would have been licensed under different providers at different times.|$|E
5000|$|... "Lernout & Hauspie Michelle" [...] and [...] "Lernout & Hauspie Michael" [...] are text-to-speech voices {{created by}} L&H and {{included}} in Microsoft Office 2003. L&H speech recognition {{was used in}} the [...] "Speech" [...] option in the control panel of Microsoft Windows XP abbreviated as LH. In addition, Microsoft Office uses certain elements of a <b>grammar</b> <b>checker</b> previously owned by L&H, which is mentioned in the About window.|$|E
40|$|Natural {{language}} processing (NLP) means the computer-aided processing of language {{produced by a}} human. But human language is inherently irregular and the most reliable results are obtained when a human is involved {{in at least some}} part of the processing. However, manual workis time-consuming and expensive. This thesis focuses on what can be accomplished in NLP when manual workis kept to a minimum. We describe the construction of two tools that greatly simplify the implementation of automatic evaluation. They are used to implement several supervised, semi-supervised and unsupervised evaluations by introducing artificial spelling errors. We also describe the design of a rule-based shallow parser for Swedish called GTA and a detection algorithm for context-sensitive spelling errors based on semi-supervised learning, called ProbCheck. In {{the second part of the}} thesis, we first implement a supervised evaluation scheme that uses an error-free treebankto determine the robustness of a parser when faced with noisy input such as spelling errors. We evaluate the GTA parser and determine the robustness of the individual components of the parser as well as the robustness for different phrase types. Second, we create an unsupervised evaluation procedure for parser robustness. The procedure allows us to evaluate the robustness of parsers using different parser formalisms on the same text and compare their performance. Five parsers and one tagger are evaluated. For four of these, we have access to annotated material and can verify the estimations given by the unsupervised evaluation procedure. The results turned out to be very accurate with few exceptions and thus, we can reliably establish the robustness of an NLP system without any need of manual work. Third, we implement an unsupervised evaluation scheme for spell checkers. Using this, we perform a very detailed analysis of three spell checkers for Swedish. Last, we evaluate the ProbCheck algorithm. Two methods are included for comparison: a full parser and a method using tagger transition probabilities. The algorithm obtains results superior to the comparison methods. The algorithm is also evaluated on authentic data in combination with a <b>grammar</b> and spell <b>checker.</b> QC 2010090...|$|R
50|$|These {{and similar}} {{electronic}} typewriters were in essence dedicated word processors with either single-line LCD displays or multi-line CRT displays, built-in line editors in ROM, a spelling and <b>grammar</b> <b>checker,</b> a few kilobytes of internal RAM and optional cartridge, magnetic card or diskette external memory-storage devices for storing text and even document formats. Text could be entered a line or paragraph {{at a time}} and edited using the display and built-in software tools before being committed to paper.|$|E
50|$|Grammatik was {{the first}} grammar {{checking}} program developed for home computer systems. Aspen Software of Albuquerque, NM, released the earliest version of this diction and style checker for personal computers, in 1981. Grammatik was first available for a Radio Shack - TRS-80, and soon had versions for CP/M and the IBM PC. Reference Software of San Francisco, California, acquired Grammatik in 1985. Development of Grammatik continued, and it became an actual <b>grammar</b> <b>checker</b> that could detect writing errors beyond simple style checking.|$|E
50|$|Until 1992, grammar {{checkers}} {{were sold}} as add-on programs. There were {{a large number}} of different word processing programs available at that time, with WordPerfect and Microsoft Word the top two in market share. In 1992, Microsoft decided to add grammar checking as a feature of Word, and licensed CorrecText, a <b>grammar</b> <b>checker</b> from Houghton Mifflin that had not yet been marketed as a standalone product. WordPerfect answered Microsoft's move by acquiring Reference Software, and the direct descendant of Grammatik is still included with WordPerfect.|$|E
50|$|Originally the company’s {{business}} model {{was a free}} 2-day trial followed by an option to purchase the user license after the trial expired. On 15 January 2012, the company changed its {{business model}} by releasing its freemium version. The freemium version consists of the contextual-based grammar and spelling checker which users could download and keep for free. The premium version was also available for purchase. Its features include Ginger Text Reader and Personal Trainer a progress report analysis tool, along with unlimited access to <b>Grammar</b> <b>Checker,</b> the grammar and spelling checker, and Sentence Rephraser the rephrasing tool.|$|E
5000|$|Grammar {{checkers}} {{are considered}} {{as a type of}} foreign language writing aid which non-native speakers can use to proofread their writings as such programs endeavor to identify syntactical errors. However, as with other computerized writing aids such as spell checkers, popular grammar checkers are often criticized when they fail to spot errors and incorrectly flag correct text as erroneous. The linguist Geoffrey K. Pullum has argued that they are generally so inaccurate as to do more harm than good: [...] "for the most part, accepting the advice of a computer <b>grammar</b> <b>checker</b> on your prose will make it much worse, sometimes hilariously incoherent." ...|$|E
5000|$|Kučera {{wrote one}} of the first spell {{checkers}} over Christmas break, 1981, in PL/I for VAX machines, at the behest of Digital Equipment Corporation. It was a simple, rapid spelling verifier. Further development resulted in [...] "International Correct Spell", a spell checking program which was used on word processing systems such as WordStar and Microsoft Word as well as numerous small computer applications. Kučera later oversaw the development of Houghton-Mifflin’s Correct Text <b>grammar</b> <b>checker,</b> which also drew heavily on statistical techniques for analysis. He founded Language Systems Incorporated (LSI), later Language Systems Software Incorporated (LSSI), to manage his software programs and updates until the patents expired in 2002.|$|E
5000|$|Dr. Lehal {{has been}} working for more than fifteen years on {{different}} projects related to computerization of Punjabi, Hindi, Urdu and Sindhi languages {{and has been a}} pioneer in developing technical solutions for these languages. For the first time, many new technologies have been developed by him including Intelligent Predictive Roman-Gurmukhi transliteration techniques for simplifying Punjabi typing, Punjabi spell checker, Intelligent Punjabi and Hindi font converter, bilingual Gurmukhi/Roman OCR and Sindhi-Devnagri transliteration [...] Many other products for popularizing Punjabi and breaking the script and language barriers have been developed under his leadership. Some of these products which are being widely used include a multi-media based website for Punjabi teaching, Gurmukhi-Shahmukhi transliteration utility, Punjabi-Hindi translation software, Urdu-Hindi transliteration software, Punjabi Search Engine, Punjabi Text-to-Speech Synthesis System, Punjabi text summarization system and Punjabi <b>grammar</b> <b>checker</b> ...|$|E
40|$|Abstract — Applications like word {{processors}} and other writing tools typically include a <b>grammar</b> <b>checker.</b> The {{purpose of a}} <b>grammar</b> <b>checker</b> is to identify sentences that are grammatically incorrect based on the syntax of the language. The proposed <b>grammar</b> <b>checker</b> is a rule-based system to identify sentences that {{are most likely to}} contain errors. The set of rules are automatically generated from a part of speech tagged corpus. The results from the <b>grammar</b> <b>checker</b> is a list of error sentences, error descriptions, and suggested corrections. A <b>grammar</b> <b>checker</b> for other languages can be similarly constructed, given a tagged corpus and a set of stop words. I...|$|E
