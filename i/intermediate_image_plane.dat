24|4023|Public
50|$|A phase {{telescope}} or Bertrand lens is {{an optical}} device used in aligning the various optical {{components of a}} light microscope. In particular it allows observation of the back focal plane of the objective lens and its conjugate focal planes. The phase telescope/Bertrand lens is inserted into the microscope in place of an eyepiece to move the <b>intermediate</b> <b>image</b> <b>plane</b> {{to a point where}} it can be observed.|$|E
50|$|In {{order to}} test the {{alignment}} of components on the light source image plane, the eyepiece must be removed to allow observation of the <b>intermediate</b> <b>image</b> <b>plane</b> (the position of the eyepiece diaphragm) either directly or by using a phase telescope/Bertrand lens. The light source (e.g. the bulb filament) and {{the edges of the}} condenser diaphragm should appear in focus. Any optical components at the back focal plane of the objective (e.g. the phase ring for phase contrast microscopy) and at the condenser diaphragm (e.g. the annulus for phase contrast microscopy) should also appear in focus.|$|E
40|$|The {{invention}} {{relates to}} a device (1) for limiting a transmitted optical power, comprising {{at least one}} focusing optical unit (11) which images incident light onto an <b>intermediate</b> <b>image</b> <b>plane</b> (21), wherein at least one first protective element (10) is arranged in the <b>intermediate</b> <b>image</b> <b>plane,</b> characterized in that the device (1) furthermore contains a beam shaping unit (15) designed to generate a predefineable distribution of the intensity relative {{to the location of}} the incident light. Furthermore, the invention relates to a distance measuring apparatus comprising such a device, and to a method for limiting an optical power...|$|E
40|$|Optical {{diagnostics}} {{are currently}} being designed to analyze high-energy density physics experiments at the National Ignition Facility (NIF). Two independent line-imaging Velocity Interferometer System for Any Reflector (VISAR) interferometers have been fielded to measure shock velocities, breakout times, and emission of targets having sizes of 1 – 5 mm. An 8 -inch-diameter, fused silica triplet lens collects light at f/ 3 inside the 30 -foot-diameter NIF vacuum chamber. VISAR recordings use a 659. 5 -nm probe laser. By adding a specially coated beam splitter to the interferometer table, light at wavelengths from 540 to 645 nm is spilt into a thermal-imaging diagnostic. Because fused silica lenses {{are used in the}} first triplet relay, the <b>intermediate</b> <b>image</b> <b>planes</b> for different wavelengths separate by considerable distances. A corrector lens on the interferometer table reunites these separated wavelength planes to provide a good image. Thermal imaging collects light at f/ 5 from a 2 -mm object placed at Target Chamber Center (TCC). Streak cameras perform VISAR and thermal-imaging recording. All optical lenses are on kinematic mounts so that pointing accuracy of the optical axis may be checked. Counter-propagating laser beams (orange and red) are used to align both diagnostics. The red alignment laser is selected to be at the 50 percent reflection point of the beam splitter. This alignment laser is introduced at the recording streak cameras for both diagnostics and passes through this special beam splitter on its way into the NIF vacuum chamber...|$|R
40|$|A two-photon {{fluorescence}} microscope {{has been developed}} {{for the study of}} biophysical phenomena. Two-photon microscopy is a novel form of laser-based scanning microscopy that enables three-dimensional imaging without many of the problems inherent in confocal microscopy. Unlike one-photon optical microscopy, two-photon microscopy utilizes the simultaneous nonlinear absorption of two near-infrared photons. However, the efficiency of two-photon absorption is much lower than that of one-photon absorption, so an ultra-fast pulsed laser source is typically employed. On the other hand, the critical energy threshold for two-photon absorption leads to fluorophore excitation that is intrinsically localized to the focal volume. Consequently, two-photon microscopy enables optical sectioning and confocal performance without the need for a signal-limiting pinhole. In addition, there is a reduction (relative to one-photon optical microscopy) in photon-induced damage because of the longer excitation wavelength. This reduction is especially advantageous for in vivo studies. Relative to confocal microscopy, there is also a reduction in background fluorescence, and, because of a reduction in Rayleigh scattering, there is a 4 increase of penetration depth. The prohibitive cost of a commercial two-photon fluorescence-microscope system, as well as a need for modularity, has led to the construction of a custom-built system (see Figure 1). This system includes a coherent mode-locked titanium: sapphire laser emitting 120 -fs-duration pulses at a repetition rate of 80 MHz. The pulsed laser has an average output power of 800 mW and a wavelength tuning range of 700 to 980 nm, enabling the excitation of a variety of targeted fluorophores. The output from the laser is attenuated, spatially filtered, and then directed into a confocal scanning head that has been modified to provide for side entry of the laser beam. The laser output coupler has been replaced with a dichroic filter that reflects the longer-wavelength excitation light and passes the shorter-wavelength fluorescence light. Also, the confocal pinhole has been removed to increase the signal strength. The laser beam is scanned by a twoperpendicular- axis pair of galvanometer mirrors through a pupil transfer lens into the side port of an inverted microscope. Finally, the beam is focused by a 63 -magnification, 1. 3 -numerical- aperture oil-immersion objective lens onto a specimen. The pupil transfer lens serves to match the <b>intermediate</b> <b>image</b> <b>planes</b> of the scanning head and the microscope, and its location is critical. In order to maximize the quality of the image, (that is, the point spread function of the objective lens for all scan positions), the entire system was modeled in optical-design software, and the various free design parameters (the parameters of the spatial-filter components as well as the separations of all of the system components) were determined through an iterative optimization process. A modular design was chosen to facilitate access to the optical train for future fluorescence correlation spectroscopy and fluorescence-lifetime experiments...|$|R
5000|$|... {{to obtain}} the final {{equation}} for the <b>image</b> <b>plane</b> field in terms of <b>image</b> <b>plane</b> coordinates and <b>image</b> <b>plane</b> wavenumbers as: ...|$|R
40|$|A {{head up display}} (HUD) with laser {{backlight}} unit has two principle problems; one is laser speckles {{and the other is}} distortion. In this study, we propose that a rotating diffuser set at the <b>intermediate</b> <b>image</b> <b>plane</b> of the HUD projection system can simultaneously solve these problems. The conditions of speckle reduction and de-distortion are als...|$|E
40|$|Light that is {{scattered}} from {{lenses and}} mirrors in an optical system produces {{a halo of}} stray light around bright objects {{within the field of}} view. The angular distribution of scattered light from any one component is usually described by the Harvey model. This paper presents analytic expressions for the scattered irradiance at a focal plane from optical components that scatter light in accordance with the Harvey model. It is found that the irradiance is independent of the location of an optical element within the system, provided the element is not located at or near an <b>intermediate</b> <b>image</b> <b>plane.</b> It is also found that the irradiance has little or no dependence on the size ofthe element...|$|E
40|$|A new {{interferometric}} {{technique for}} Michelson wide-field interferometry is presented {{that consists of}} a Michelson pupil-plane combination scheme in which a wide field of view can be achieved in one shot. This technique uses a stair-shaped mirror in the <b>intermediate</b> <b>image</b> <b>plane</b> of each telescope in the array, allowing for simultaneous correction of the differential delay for the on-axis and off-axis image positions. Experimental results in a laboratory setup show {{that it is possible}} to recover the fringes of on-axis and off-axis stars with an angular separation of 1 arc min simultaneously and with a similar contrast. This new technique represents a considerable extension of the field of view of an interferometer without the need for extra observation time. Imaging Science and TechnologyApplied Science...|$|E
3000|$|The correct {{position}} determination in the <b>image</b> <b>plane</b> is important. A {{method to}} obtain an autofocused image has been proposed [18]. However, we will present a method to elegantly find the position in the <b>image</b> <b>plane</b> of simple objects recorded in the hologram, such as the polystyrene sphere beads. In our method, we use the diffraction effect that results from {{the distance between the}} <b>image</b> <b>plane</b> and the hologram being very long. The principle of the method is that if the object is located at the <b>image</b> <b>plane,</b> no diffraction pattern appears around the image; however, if the image is located at a position away from the <b>image</b> <b>plane,</b> a ring-shaped diffraction pattern appears around the image. Therefore, the position of the <b>image</b> <b>plane</b> can be elegantly determined by observing the diffraction patterns (the <b>image</b> <b>plane</b> Z [...]...|$|R
5000|$|... #Caption: Figure 1. Depiction of the N-localizer and its {{intersection}} {{with the}} computed tomography (CT) <b>image</b> <b>plane.</b> (A) Side {{view of the}} N-localizer. The CT <b>image</b> <b>plane</b> intersects two vertical rods and one diagonal rod. (B) CT image. The intersection of the CT <b>image</b> <b>plane</b> with the N-localizer creates two fiducial circles and one fiducial ellipse. The relative spacing between the ellipse and the two circles varies according to the height at which the CT <b>image</b> <b>plane</b> intersects the diagonal rod. Measuring this spacing permits calculation of {{the point where the}} CT <b>image</b> <b>plane</b> intersects the diagonal rod.|$|R
5000|$|When the <b>image</b> <b>plane</b> is {{parallel}} to two world-coordinate axes, lines {{parallel to}} the axis which is cut by this <b>image</b> <b>plane</b> will meet at infinity i.e. at the vanishing point. Lines parallel {{to the other two}} axes will not form vanishing points as they are parallel to the <b>image</b> <b>plane.</b> This is one-point perspective. Similarly, when the <b>image</b> <b>plane</b> intersects two world-coordinate axes, lines parallel to those planes will meet at infinity and form two vanishing points. This is called two-point perspective. In three-point perspective the <b>image</b> <b>plane</b> intersects the , , and [...] axes and therefore lines parallel to these axes intersect, resulting in three different vanishing points.|$|R
40|$|By {{inserting}} a microlens array at the <b>intermediate</b> <b>image</b> <b>plane</b> of an optical microscope, one can record 4 D light fields of biological specimens {{in a single}} snapshot. Unlike a conventional photograph, light fields permit manipulation of viewpoint and focus after the snapshot has been taken, subject to {{the resolution of the}} camera and the diffraction limit of the optical system. By {{inserting a}} second microlens array and video projector into the microscope’s illumination path, one can control the incident light field falling on the specimen in a similar way. In this paper we describe a prototype system we have built that implements these ideas, and we demonstrate two applications for it: simulating exotic microscope illumination modalities and correcting for optical aberrations digitally. 1...|$|E
40|$|We {{describe}} a two-beam interference structured illumination fluorescence microscope. The novelty of the presented system {{lies in its}} simplicity. A programmable electro-optical spatial light modulator in an <b>intermediate</b> <b>image</b> <b>plane</b> enables precise and rapid control of the excitation pattern in the specimen. The contrast of the projected light pattern is strongly influenced by the polarization state of the light entering the high NA objective. To achieve high contrast, we use a segmented polarizer. Furthermore, a mask with six holes blocks unwanted components in the spatial frequency spectrum of the illumination grating. Both these passive components serve their purpose in a simpler and almost as efficient way as active components. We demonstrate a lateral resolution of 114. 2 +- 9. 5 nm at a frame rate of 7. 6 fps per reconstructed 2 D slice...|$|E
40|$|We {{investigated}} the experimental performance of an afocal scan engine employing two off-axis parabolic reflectors {{and it was}} found not to introduce astigmatism when compared to a freely propagated beam. The performance of the new afocal engine {{is very similar to}} an ideal single-mirror scan engine in terms of spot size and beam spot profile (or point spread function) and has an improved flatness of field over other two-dimensional laser scan engines. The parabolic scan engine is contrasted with a comparable spherical mirror arrangement and found to produce superior performance at the <b>intermediate</b> <b>image</b> <b>plane</b> when focused through a scan lens. Further modeling and experimentation point toward volume scanning applications. The significant performance improvement provided by this design, now verified experimentally, will result in superior image quality for fast scanning confocal and two-photon microscopy in particular...|$|E
40|$|This paper {{presents}} an efficient keyframeless image-based rendering technique. An <b>intermediate</b> <b>image</b> {{is used to}} exploit the coherences among neighboring frames. The pixels in the <b>intermediate</b> <b>image</b> are first rendered by a ray-casting method and then warped to the <b>intermediate</b> <b>image</b> at the current viewpoint and view direction. We use an offset buffer to record the precise positions of these pixels in the <b>intermediate</b> <b>image.</b> Every frame is generated in three steps: warping the <b>intermediate</b> <b>image</b> onto the frame, filling in holes, and selectively rendering a group of ”old ” pixels. By dynamically adjusting {{the number of those}} ”old ” pixels in the last step, the workload at every frame can be balanced. The pixels generated by the last two steps make contributions to the new <b>intermediate</b> <b>image.</b> Unlike occasional keyframes in conventional image-based rendering which need to be totally rerendered, <b>intermediate</b> <b>images</b> only need to be partially updated at every frame. In this way, we guarantee more stable frame rates and more uniform <b>image</b> qualities. The <b>intermediate</b> <b>image</b> can be warped efficiently by a modified incremental 3 D warp algorithm. As a specific application, we demonstrate our technique with a voxel-based terrain rendering system. Keywords: Image-based rendering, ray casting, voxel-based modeling, terrain rendering. ...|$|R
3000|$|... i {{is the sum}}med voxel {{intensity}} for the <b>image</b> <b>plane,</b> Σi {{is the sum of}} all <b>image</b> <b>planes</b> in {{the respective}} dimensions, x [...]...|$|R
5000|$|A {{high-speed}} framing camera which records {{images on}} multiple <b>image</b> <b>planes</b> or multiple locations {{on the same}} <b>image</b> <b>plane</b> (generally film or a network of CCD cameras), ...|$|R
40|$|In {{this section}} we will briefly {{describe}} {{the basic principles}} of operation and alignment of a microscope. These notes are based on [1], [4] and the microscopy introductory lectures by Rudi Rottenfusser at the 2005 MBL Physiology Course. In figure 1 we present the basic elements required for magnification. The specimen lies on the focal plane of the objective lens, which focuses it to infinity. The tube lens then focuses the parallel rays on the <b>intermediate</b> <b>image</b> <b>plane.</b> The obtained real image is now a magnified version of the sample. A second round of magnification, which gets multiplied to the previously described one, is obtained by focusing this real image to infinity once again using the eyepiece. This creates a new image focused to infinity, a condition to which the eye is adapted for viewing. eye or camera eyepiece intermediate image plan...|$|E
40|$|In the paper, we {{describe}} an optical system which {{is capable of}} providing external access to both the sensor and the lens aperture (i. e., projection center) of a conventional camera. The proposed optical system is attached {{in front of the}} camera, and is the equivalent of adding externally accessible <b>intermediate</b> <b>image</b> <b>plane</b> and projection center. The system offers controls of the response of each pixel which could be used to realize many added imaging functions, such as high dynamic range imaging, image modulation, and optical computation. The ability to access the optical center could enable a wide variety of applications by simply allowing manipulation of the geometric properties of the optical center. For instance, panoramic imaging can be implemented by rotating a planar mirror about the camera axis; and small base-line stereo can be implemented by shifting the camera center. We have implemented a bench setup to demonstrate some of these functions. The experimental results are included. 1...|$|E
40|$|Coronagraphy {{is a very}} {{efficient}} technique for identifying and characterizing extra-solar planets orbiting in the habitable zone of their parent star, especially when used in a space environment. An important family of coronagraphs is based on phase plates located at an <b>intermediate</b> <b>image</b> <b>plane</b> of the optical system, that spread the starlight outside the "Lyot" exit pupil plane of the instrument. In this communication we present a set of candidate phase functions generating a central null at the Lyot plane, and study how it propagates to the image plane of the coronagraph. These functions include linear azimuthal phase ramps (the well-known optical vortex), azimuthally cosine-modulated phase profiles, and circular phase gratings. Numerical simulations of the expected null depth, inner working angle, sensitivity to pointing errors, effect of central obscuration located at the pupil or image planes, and effective throughput including image mask and Lyot stop transmissions are presented and discussed. The preliminary conclusion is that azimuthal cosine functions appear as an interesting alternative to the classical optical vortex of integer topological charge. Comment: 12 page...|$|E
40|$|A {{mobile robot}} {{intercepts}} a target {{identified in the}} <b>image</b> <b>plane</b> of a fixed camera without prior knowledge of camera viewpoint or geometry. The target may be identified manually or autonomously. When the robot moves within the camera <b>image</b> <b>plane,</b> the system develops a table of mappings between the <b>image</b> <b>plane</b> and the ground plane in which the robot moves. The robot is identified in the <b>image</b> <b>plane</b> via background subtraction and localized in the ground plane using a particle filter. This adds the potential for robotic intervention to surveillance using fixed camera systems. ...|$|R
40|$|The device (100) has a micro-lens array (103) with {{multiple}} micro-lenses (107 a to 107 n) which are grouped in multiple micro-lens groups (105). Multiple pixel arrays (109) are arranged {{at a distance}} from each other. Each micro-lens is designed to form associated regions (111 a to 111 n) of an <b>intermediate</b> <b>image</b> (101) on a partial region of pixel arrays associated to micro-lens groups. The pixel arrays are laterally less extensive than the associated micro-lens groups. USE: Device for receiving an <b>intermediate</b> <b>image</b> generated by a main lens of a focused-type plenoptic camera (Claimed). ADVANTAGE: The device has a micro-lens array {{with multiple}} micro-lenses which are grouped in multiple micro-lens groups, where multiple pixel arrays are arranged {{at a distance from}} each other, and hence ensures an improved <b>intermediate</b> <b>image</b> receiving device with enhanced depth resolution and reduced minimum possible depth of focus, where manufacturing cost of the <b>intermediate</b> <b>image</b> receiving device is reduced. The drawing shows schematic sectional view of an <b>intermediate</b> <b>image</b> receiving device. 100 : <b>Intermediate</b> <b>image</b> receiving device 101 : <b>Intermediate</b> <b>image</b> 103 : Micro-lens array 105 : Micro-lens groups 107 a to 107 n : Micro-lenses 109 : Pixel arrays 111 a to 111 n : Associated regions...|$|R
5000|$|... "Tilt-shift" [...] {{encompasses}} {{two different}} types of movements: rotation of the lens plane relative to the <b>image</b> <b>plane,</b> called tilt, and movement of the lens parallel to the <b>image</b> <b>plane,</b> called shift.|$|R
40|$|This chapter {{provides}} information on how microscopes work and discusses some of the microscope issues {{to be considered in}} using a video camera on the microscope. There are two types of microscopes in use today for research in cell biology-the older finite tube-length (typically 160 mm mechanical tube length) microscopes and the infinity optics microscopes that are now produced. The objective lens forms a magnified, real image of the specimen at a specific distance from the objective known as the <b>intermediate</b> <b>image</b> <b>plane.</b> All objectives are designed to be used with the specimen at a defined distance from the front lens element of the objective (the working distance) so that the image formed is located at a specific location in the microscope. Infinity optics microscopes differ from the finite tube-length microscopes in that the objectives are designed to project the image of the specimen to infinity and do not, on their own, form a real image of the specimen. Three types of objectives are in common use today-plan achromats, plan apochromats, and plan fluorite lenses. The concept of mounting video cameras on the microscope is also presented in the chapter...|$|E
40|$|The High Resolution Dynamics Limb Sounder is described, with {{particular}} {{reference to the}} atmospheric {{measurements to be made}} and the rationale behind the measurement strategy. The demands this strategy places on the filters {{to be used in the}} instrument and the designs to which this leads to are described. A second set of filters at an <b>intermediate</b> <b>image</b> <b>plane</b> to reduce "Ghost Imaging" is discussed together with their required spectral properties. A method of combining the spectral characteristics of the primary and secondary filters in each channel are combined together with the spectral response of the detectors and other optical elements to obtain the system spectral response weighted appropriately for the Planck function and atmospheric limb absorption. This method is used to demonstrate whether the out-of-band spectral blocking requirement for a channel is being met and an example calculation is demonstrated showing how the blocking is built up for a representative channel. Finally, the techniques used to produce filters of the necessary sub-millimetre sizes together with the testing methods and procedures used to assess the environmental durability and establish space flight quality are discussed...|$|E
40|$|This {{dissertation}} describes three computational sensors. The first sensor is a scanning multi-spectral aperture-coded microscope {{containing a}} coded aperture spectrometer that is vertically scanned through a microscope <b>intermediate</b> <b>image</b> <b>plane.</b> The spectrometer aperture-code spatially encodes the object spectral data and nonnegative least squares inversion {{combined with a}} series of reconfigured two-dimensional (2 D spatial-spectral) scanned measurements enables three-dimensional (3 D) (x, y, &# 955) object estimation. The second sensor is a coded aperture snapshot spectral imager that employs a compressive optical architecture to record a spectrally filtered projection of a 3 D object data cube onto a 2 D detector array. Two nonlinear and adapted TV-minimization schemes are presented for 3 D (x,y,&# 955) object estimation from a 2 D compressed snapshot. Both sensors are interfaced to laboratory-grade microscopes and applied to fluorescence microscopy. The third sensor is a millimeter-wave holographic imaging system that is used to study the impact of 2 D compressive measurement on 3 D (x,y,z) data estimation. Holography is a natural compressive encoder since a 3 D parabolic slice of the object band volume is recorded onto a 2 D planar surface. An adapted nonlinear TV-minimization algorithm is used for 3 D tomographic estimation from a 2 D and a sparse 2 D hologram composite. This strategy aims to reduce scan time costs associated with millimeter-wave image acquisition using a single pixel receiver. Dissertatio...|$|E
5000|$|If v′ is the {{distance}} {{along the line}} of sight from the <b>image</b> <b>plane</b> {{to the center of the}} lens, the angle ψ between the <b>image</b> <b>plane</b> and the PoF is given by ...|$|R
5000|$|... 16 {{of these}} become <b>image</b> <b>planes</b> {{with the other}} 8 used as {{moveable}} [...] "overlay" [...] planes. Another 2 hardware colormaps become available, providing 2 for the <b>image</b> <b>planes</b> and 2 for the overlay planes.|$|R
5000|$|... #Caption: Figure 3. Depiction {{of three}} N-localizers and their {{intersection}} with the computed tomography (CT) <b>image</b> <b>plane.</b> The quadrilateral represents the CT <b>image</b> <b>plane.</b> The oval and the arch represent the stereotactic instrument. The vertical and diagonal lines that {{are attached to}} the oval represent the three N-localizers. The three points where the CT <b>image</b> <b>plane</b> intersects the diagonal rods are depicted by the dots. These points of intersection determine the spatial orientation of the CT <b>image</b> <b>plane</b> relative to the stereotactic instrument, and permit the transfer of patient information from the two-dimensional coordinate system of the planar image into the three-dimensional coordinate system of the stereotactic instrument.|$|R
40|$|Recently, {{efforts to}} improve optical {{characteristics}} in canonical mirror systems, including aspherical surfaces and corrective aberration capabilities. At the same time, much {{attention is paid to}} the development of new optical schemes of two-mirror objectives. Development measures to protect the image plane from stray light and harmful flows with minimal vignetting and screening {{is one of the most}} perspective ways for improving the image quality objectives. The only method to eliminate or even reduce these non-constructive rays is to set glare stops. The aim of the work was an improving method for constructing a glare stop to protect the image plane and the creation of a calculation algorithm of glare stop for protecting the image plane based on two-mirror extra-focal objectives. The study was conducted in two stages. In the course of the first stage, the positions of screening and <b>intermediate</b> <b>image</b> <b>plane</b> were obtained, as well as the central screening coefficient. At the second stage, an arrangement for the position of glare stop is proposed using the algorithm calculation. Thus, mathematical expressions were achieved by geometric constructions. The relation of the screening coefficient with the distance between the surfaces of the mirrors and the height of the paraxial rays is established. А representation of vignetting diagram for two-mirror extra-focal objective with  D / f ´ = 1 : 1, 3 and 2 ω = 4 ° was realized. The Q estimation of vignetting of inclined light beams is  k = 0, 56. </p...|$|E
40|$|Wide field {{interferometry}} {{has become}} a subject of increasing interest in the recent years. New methods have been suggested {{in order to avoid}} the drawbacks of the standard wide field method (homothetic mapping) which is not applicable when the aperture is highly diluted; for this reason imaging with non-homothetic arrays is being extensively studied 1, 2. The field of view of a pupil plane interferometer or a densified array consists only of a few resolution elements; in order to improve these systems, we developed a new method consisting of a Michelson pupil-plane combination scheme where a wide field of view can be achieved in one shot. This technique, called "staircase mirror" approach, has been described in a previous paper 3 and uses a stair-shaped mirror in the <b>intermediate</b> <b>image</b> <b>plane</b> of each telescope in the array, allowing for simultaneous correction of the differential delay for the on and off-axis image positions. Experimental results have been obtained recovering the fringes of off-axis stars with an angular separation of approximately 1 arcmin simultaneously, and with a contrast similar to that of the on-axis reference star. With this example, we demonstrate an increase of the field of view by a factor of five, with no need of extra observation time. An algorithm to recover the visibilities from the stars focused on the edge of the steps is described and experimental results are shown that prove that a continuous wide field of view can be acquired in one shot. Imaging Science and TechnologyApplied Science...|$|E
40|$|Thermal imaging is an important, though challenging, {{diagnostic}} for shockwave experiments. Shock-compressed materials undergo {{transient temperature}} changes that cannot be recorded with standard (greater than ms response time) infrared detectors. A further complication arises when optical elements near the experiment are destroyed. We have designed a thermal-imaging system for studying shock temperatures produced inside a gas gun at Sandia National Laboratories. Inexpensive, diamond-turned, parabolic mirrors relay {{an image of}} the shocked target to the exterior of the gas gun chamber through a sapphire vacuum port. The 3000 – 5000 -nm portion of this image is directed to an infrared camera which acquires a snapshot of the target with a minimum exposure time of 150 ns. A special mask is inserted at the last <b>intermediate</b> <b>image</b> <b>plane,</b> to provide dynamic thermal background recording during the event. Other wavelength bands of this image are split into high-speed detectors operating at 900 – 1700 nm, and at 1700 – 3000 nm for timeresolved pyrometry measurements. This system incorporates 90 -degree, off-axis parabolic mirrors, which can collect low f/# light over a broad spectral range, for high-speed imaging. Matched mirror pairs must be used so that aberrations cancel. To eliminate image plane tilt, proper tip-to-tip orientation of the parabolic mirrors is required. If one parabolic mirror is rotated 180 degrees about the optical axis connecting the pair of parabolic mirrors, the resulting image is tilted by 60 degrees. Different focal-length mirrors cannot be used to magnify the image without substantially sacrificing image quality. This paper analyzes performance and aberrations of this imaging diagnostic...|$|E
50|$|Most wiggle images {{use only}} two images, {{yielding}} a jerky image. A smoother image can be composed by using several <b>intermediate</b> <b>images</b> {{and using the}} left and right images as end images of the <b>image</b> sequence. If <b>intermediate</b> <b>images</b> are not available, approximate images can be computed from the end images using techniques known as view interpolation. The two end images may be displayed for a longer time than the <b>intermediate</b> <b>images</b> to allow inspection of details in {{the left and right}} images.|$|R
50|$|Microscopes using Köhler {{illumination}} must be routinely {{checked for}} correct alignment. The realignment procedure tests whether the correct optical components are in focus {{at the two}} sets of conjugate image planes; the light source <b>image</b> <b>planes</b> and the specimen <b>image</b> <b>planes.</b>|$|R
5000|$|... #Caption: Two {{parallel}} {{projections of}} a cube. In an orthographic projection (at left), the projection lines are {{perpendicular to the}} <b>image</b> <b>plane</b> (pink). In an oblique projection (at right), the projection lines are at a skew angle to the <b>image</b> <b>plane.</b>|$|R
