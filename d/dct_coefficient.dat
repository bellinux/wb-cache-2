205|1131|Public
2500|$|... which {{closely resembles}} the {{original}} <b>DCT</b> <b>coefficient</b> matrix for the top-left portion.|$|E
2500|$|Using this {{quantization}} matrix with the <b>DCT</b> <b>coefficient</b> matrix from above results in: ...|$|E
2500|$|Taking the <b>DCT</b> <b>coefficient</b> matrix (after {{adding the}} {{difference}} of the DC coefficient back in) ...|$|E
40|$|A general {{method for}} {{recovering}} missing <b>DCT</b> <b>coefficients</b> in DCT-transformed images {{is presented in}} this work. We model the <b>DCT</b> <b>coefficients</b> recovery problem as an optimization problem and recover all missing <b>DCT</b> <b>coefficients</b> via linear programming. The visual quality of the recovered image gradually decreases {{as the number of}} missing <b>DCT</b> <b>coefficients</b> increases. For some images, the quality is surprisingly good even when more than 10 most significant <b>DCT</b> <b>coefficients</b> are missing. When only the DC coefficient is miss-ing, the proposed algorithm outperforms existing methods according to experimental results conducted on 200 test images. The proposed recovery method can be used for cryptanalysis of DCT based selec-tive encryption schemes and other applications. 1...|$|R
30|$|Compute the <b>DCT</b> <b>coefficients</b> of {{the noisy}} signal y. (This step is omitted {{in the case}} the noisy signal is given {{in terms of its}} <b>DCT</b> <b>coefficients).</b>|$|R
3000|$|... {{contains}} all nonzero rounded <b>DCT</b> <b>coefficients.</b> According to Equation (17), only the nonzero <b>DCT</b> <b>coefficients</b> (i.e., set C) have the corresponding informative coefficients {{and can be}} used for hiding data.|$|R
5000|$|... which {{closely resembles}} the {{original}} <b>DCT</b> <b>coefficient</b> matrix for the top-left portion.|$|E
5000|$|Using this {{quantization}} matrix with the <b>DCT</b> <b>coefficient</b> matrix from above results in: ...|$|E
5000|$|Taking the <b>DCT</b> <b>coefficient</b> matrix (after {{adding the}} {{difference}} of the DC coefficient back in) ...|$|E
30|$|Read the <b>DCT</b> <b>coefficients</b> {{from the}} JPEG file. Permute them using the secret key K and {{utilized}} pseudo-random generator. Remove the DC coefficients. Obtain {{the stream of}} nonzero <b>DCT</b> <b>coefficients</b> C.|$|R
30|$|Stego JSteg {{selection}} ratio: {{denotes the}} ratio of the <b>DCT</b> <b>coefficients</b> used by JSteg in the ‘non-zero’ subset to the <b>DCT</b> <b>coefficients</b> used by JSteg in the ‘residual noise’ set from a stego image.|$|R
40|$|Image {{up-sampling}} in the discrete cosine transform (DCT) domain is {{a challenging}} problem because <b>DCT</b> <b>coefficients</b> are de-correlated, {{such that it}} is nontrivial to estimate directly high-frequency <b>DCT</b> <b>coefficients</b> from observed low-frequency <b>DCT</b> <b>coefficients.</b> In the literature, DCT-based up-sampling algorithms usually pad zeros as high-frequency <b>DCT</b> <b>coefficients</b> or estimate such coefficients with limited success mainly due to the nonadaptive estimator and restricted information from a single observed image. In this paper, we tackle the problem of estimating high-frequency <b>DCT</b> <b>coefficients</b> in the spatial domain by proposing a learning-based scheme using an adaptive k-nearest neighbor weighted minimum mean squares error (MMSE) estimation framework. Our proposed scheme makes use of the information from precomputed dictionaries to formulate an adaptive linear MMSE estimator for each DCT block. The scheme is able to estimate high-frequency <b>DCT</b> <b>coefficients</b> with very successful results. Experimental {{results show that the}} proposed up-sampling scheme produces the minimal ringing and blocking effects, and significantly better results compared with the state-of-the-art algorithms in terms of peak signal-to-noise ratio (more than 1 dB), structural similarity, and subjective quality measurements. Department of Electronic and Information Engineerin...|$|R
5000|$|Dividing the <b>DCT</b> <b>coefficient</b> matrix element-wise {{with this}} {{quantization}} matrix, and rounding to integers results in: ...|$|E
30|$|The {{analysis}} in Section 3 {{shows that the}} <b>DCT</b> <b>coefficient</b> distribution of SDJPEG patches follows a weighted summation of Gaussian components with the same standard deviation (as shown in (7) and Figure  5). However, in order to detect SDJPEG patches based on (7), two questions have to be addressed: (i) How to obtain discriminative features that capture {{the differences in the}} (m,n)th <b>DCT</b> <b>coefficient</b> distributions between SDJPEG and SSJPEG patches? (ii) How to select DCT modes which provide high discriminative power since the differences in the <b>DCT</b> <b>coefficient</b> distributions of SDJPEG and SSJPEG patches would vary for different DCT mode? In the following, we will address these questions.|$|E
30|$|In Eq. (5), α is the Laplacian {{distribution}} parameter for each <b>DCT</b> <b>coefficient</b> and Δ is the quantization bin size.|$|E
3000|$|... }, 1 [*]≤[*]k,l[*]≤[*] 8, we denote D(b)[*]=[*]DCT(P(b))./Q the raw (non-rounded) {{values of}} <b>DCT</b> <b>coefficients.</b> Here, the {{operation}} ′./′ is an elementwise division of matrices and DCT(.) is the DCT transform {{used in the}} JPEG compressor. Furthermore, we denote X(b)[*]= [D(b)] the quantized <b>DCT</b> <b>coefficients</b> rounded to integers. We use the symbols D and X to denote the arrays of all raw and quantized <b>DCT</b> <b>coefficients</b> when arranging all blocks D(b) and X(b) {{in the same manner}} as the 8 [*]×[*] 8 pixel blocks in the uncompressed image. We will use the symbol J- 1 (X) for the JPEG image represented using quantized <b>DCT</b> <b>coefficients</b> X when decompressed to the spatial domaind.|$|R
30|$|The <b>DCT</b> <b>coefficients</b> X and Y are {{visually}} undistinguished if Ew (X - Y) < max (Ew(X)/ 16, Ew (Y)/ 16), where Ew (X)/ 16 is a masking effect Em of <b>DCT</b> <b>coefficients</b> X (normalizing factor 16 {{has been selected}} experimentally).|$|R
3000|$|In the Mohanty's method {{the used}} {{watermark}} is embedded into the original image by fusing the <b>DCT</b> <b>coefficients</b> of used watermark blocks with the corresponding {{blocks of the}} selected subimage. In the other hand, the <b>DCT</b> <b>coefficients</b> of each [...]...|$|R
40|$|Image {{compression}} {{based on}} quantizing {{the image in}} the discrete cosine transform (DCT) domain can generate blocky artifacts in the output image. It is possible to reduce these artifacts and RMS error by adjusting measures of block edginess and image roughness, while restricting the <b>DCT</b> <b>coefficient</b> values to values {{that would have been}} quantized to those of the compressed image. We also introduce a <b>DCT</b> <b>coefficient</b> amplitude adjustment that reduces RMS error...|$|E
3000|$|... {{where the}} channel-selection {{decision}} statistic Λ_cs(u_k,l) = Λ(u_k,l)· w_k,l {{for a single}} <b>DCT</b> <b>coefficient</b> is given, and a weighting factor w [...]...|$|E
3000|$|..., so in {{this region}} it becomes {{beneficial}} to estimate more than just one <b>DCT</b> <b>coefficient.</b> Hence, the optimal number of estimated coefficients [...]...|$|E
30|$|To {{make the}} {{scrambled}} contents and the incomplete decoding contents of JPEG, we have selected the quantized <b>DCT</b> <b>coefficients</b> {{to implement the}} incomplete cryptography. There are two reasons for choosing of the <b>DCT</b> <b>coefficients.</b> The first one {{is that it is}} easy to control the quality of the JPEG image. The second one is that it is flexible by selecting a luminance component (Y component) or two chrominance components (UV component) in the quantized <b>DCT</b> <b>coefficients</b> in order to implement our proposedmethod.|$|R
3000|$|... block <b>DCT</b> <b>coefficients</b> of {{compressed}} watermark are {{mapped to}} the interval [0, 255] by fixed linear transform and the mapped values of <b>DCT</b> <b>coefficients</b> {{are embedded in}} pixel values of each block of original image. As result, because the embedding is done in special domain, the robustness of this method is decreased {{and the quality of}} watermarked image is low (see Section 4.3). Also, mapping the <b>DCT</b> <b>coefficients</b> to the interval [0, 255] may be caused distortion in the extracted watermark.|$|R
3000|$|... {{is equal}} {{or close to}} the minimum requirement, the RMSE of the {{reconstruction}} is high compared to the case where higher number of <b>DCT</b> <b>coefficients</b> is used. Above this range, including more <b>DCT</b> <b>coefficients</b> in IPRM, does not improve the reconstructed signal. For the piecewise smooth signalf 2 (x), we virtually encounter the same scenario as in the noise free case. In other words, as we {{increase the number of}} <b>DCT</b> <b>coefficients</b> used for IPRM, we achieve a more accurate reconstruction.|$|R
3000|$|Here, we show {{an example}} for {{processing}} of incomplete cryptography. In {{order to make a}} scrambled content, the quantized <b>DCT</b> <b>coefficient</b> S [...]...|$|E
3000|$|The DCT {{coefficients}} {{of the entire}} WZ frame are grouped together, according to the position occupied by each <b>DCT</b> <b>coefficient</b> within the [...]...|$|E
40|$|Abstract—In {{this paper}} the {{watermarking}} programs {{based on the}} discrete cosine transform (DCT) domain DC component (DC) is adopted. Through adjusting the block <b>DCT</b> <b>coefficient</b> of the image the watermarks are hidden. And blocking the selected image according to 8 × 8 pixel, then dividing the selected image into four non-overlapped sub image blocks according to 4 × 4 pixel, and thus the watermarks are embedded through adjusting their <b>DCT</b> <b>coefficient.</b> The experimental {{results show that the}} method has strong robust...|$|E
30|$|After {{performing}} CIM-based DCT computation, {{the following}} steps for the compression of the image are carried out. The <b>DCT</b> <b>coefficients</b> are quantized to a pre-determined level to reduce psycho-visual redundancy. Zigzag scanning ensures the scanning of high-frequency <b>DCT</b> <b>coefficients,</b> and the scanned coefficients are encoded to reduce coding redundancy.|$|R
30|$|<b>DCT</b> <b>coefficients</b> are {{calculated}} from lips ROI, and 10 [*]×[*] 10 coefficients in the low-frequency region are retained. The mean vector of these <b>DCT</b> <b>coefficients</b> is {{considered as a}} model for closed lips. By applying this model to all images, a threshold that distinguishes closed lips and open lips is obtained. For each new image, <b>DCT</b> <b>coefficients</b> of ROI are first calculated and then compared with the model. Images with distance less than a threshold are considered to be closed lips and thus will be skipped by the HD-CTM.|$|R
30|$|To summarize, the shifted JPEG {{compression}} will {{induce a}} zero-mean Gaussian-distributed quantization error {{for all the}} <b>DCT</b> <b>coefficients,</b> and for different <b>DCT</b> <b>coefficients,</b> the standard deviations of the shifted quantization error are different and can be calculated when the quality factor and the coordinate shift of the compression are known.|$|R
40|$|A {{model is}} {{developed}} to approximate visibility thresholds for discrete cosine transform (<b>DCT)</b> <b>coefficient</b> quantization error {{based on the}} peak-to-peak luminance of the error image. Experimentally measured visibility thresholds for R, G, and B DCT basis functions can be predicted by a simple luminance-based detection model. This model allows <b>DCT</b> <b>coefficient</b> quantization matrices to be designed for display conditions other {{than those of the}} experimental measurements: other display luminances, other veiling luminances, and other spatial frequencies (different pixel spacings, viewing distances, and aspect ratios) ...|$|E
30|$|This {{paper is}} {{organized}} as follows. Section 2 gives {{a description of}} the ‘crop-and-paste’ image tampering problem and introduces current approaches. Section 3 gives an in-depth analysis on the <b>DCT</b> <b>coefficient</b> variations caused by shifted JPEG compression and describes the <b>DCT</b> <b>coefficient</b> histogram model for SDJPEG patches. In Section 4, a new discriminative feature is introduced to detect SDJPEG patches. An adaptive DCT mode selection method and a tampering detection algorithm are also given. Section 5 presents the experimental results comparing our approach with several state-of-the-art techniques. Finally, Section 6 draws the conclusion.|$|E
30|$|The {{frame rate}} of the visual data was 30 fps. The lip image size was 130 × 80 pixels. For visual features, 50 -dimensions of the <b>DCT</b> <b>coefficient</b> of the lip motion images of the source speaker’s {{utterance}} were used. We introduced segment features for the <b>DCT</b> <b>coefficient</b> that consist of consecutive frames (two frames before and two frames after). Therefore, the total dimension of the visual feature was 250. For the weights of the audio-visual feature, α was 1, and β was changed to 10 from 1.|$|E
30|$|Discrete cosine {{transform}} (DCT) Each WZ {{frame is}} decomposed into sub-blocks which undergo DCT transformation and generate <b>DCT</b> <b>coefficients.</b> These <b>DCT</b> <b>coefficients</b> {{are assigned to}} different bands according to {{their position in the}} DCT block. Thereafter, each DCT band is quantized into a number of quantization levels via a uniform scalar quantizer.|$|R
40|$|We {{propose a}} method of {{reducing}} the computational complexity of iterative video post-processing algorithms that {{make use of the}} convex quantization constraint set. Rather than constraining all <b>DCT</b> <b>coefficients</b> in a block, this method constrains only a subset of a block's <b>DCT</b> <b>coefficients,</b> and hence eliminates the need to evaluate all coefficients...|$|R
5000|$|... #Caption: mozjpeg tries several partitionings of the {{spectrum}} of <b>DCT</b> <b>coefficients</b> ...|$|R
