313|34|Public
25|$|Used {{primarily}} in ultrasound imaging, capturing the image {{produced by a}} medical imaging device is required for archiving and telemedicine applications. In most scenarios, a <b>frame</b> <b>grabber</b> is used in order to capture the video signal from the medical device and relay it to a computer for further processing and operations.|$|E
50|$|An OEM asked Datacube if a <b>frame</b> <b>grabber</b> {{could be}} built on a Multibus board. At the time, a <b>frame</b> <b>grabber</b> was a large box with {{multiple}} boards. The VG120 was the first ever commercial single board frame grabber: based on programmable array logic (PAL), it had 320 x 240 x 6 bit resolution, grayscale video input and output.|$|E
5000|$|A reverseable pixel clock for a <b>frame</b> <b>grabber</b> (a {{video capture}} device) in chunky modes (this only work with VRAM systems).|$|E
5000|$|... #Caption: A <b>frame</b> <b>grab</b> from Peculiar Penguins, a Silly Symphonies short.|$|R
50|$|In {{recent years}} {{with the rise of}} {{personal}} video recorders like camcorders, mobile phones,etc. video and photo applications have gained ascending prominence. <b>Frame</b> <b>grabbing</b> is becoming very popular on these devices.|$|R
40|$|Real-time video {{stabilization}} is {{computed from}} point-to-line correspondences using linear-programming. The {{implementation of the}} stabilizer requires special techniques for (i) <b>frame</b> <b>grabbing,</b> (ii) computing point-to-line correspondences, (iii) linear-program solving and (iv) image warping. Timing and real-time profiling are also addressed...|$|R
5000|$|Autovision I, 1981, {{designed}} for fast time to market, {{was based on}} Vision Module technology licensed from Stanford Research Institute (SRI). The AV I used an early Motorola 68000 KDM prototype board interfaced to a Unibus <b>frame</b> <b>grabber</b> board purchased from SRI. The <b>frame</b> <b>grabber</b> was {{designed for}} the General Electric TN-2200, an early solid state video camera with a 128 by 128 pixel array and C-mount lens. DECtape II drives were used for program and data storage.|$|E
5000|$|Autovision IV, {{similar to}} AV II, {{but with a}} {{patented}} <b>frame</b> <b>grabber</b> using dual 68000s. Then-new Sony 3-1/2 inch floppy drives replaced DECtape.|$|E
50|$|A line-scan camera {{traditionally}} {{has a single}} row of pixel sensors, instead of a matrix of them. The lines are continuously fed to a computer that joins them {{to each other and}} makes an image. This is most commonly done by connecting the camera output to a <b>frame</b> <b>grabber</b> which resides in a PCI slot of an industrial computer. The <b>frame</b> <b>grabber</b> acts to buffer the image and sometimes provide some processing before delivering to the computer software for processing.|$|E
40|$|This paper {{describes}} a teaching exercise which demonstrates {{the design and}} analysis of a simple mechanism used to pour beer from a bottle into a glass. Video <b>frame</b> <b>grabs,</b> of the manual pouring process, provide a motion template by which students synthesise a six-bar linkage which replicates the task. The teaching method along with typical outcomes of the project are presented...|$|R
50|$|The Comiclopedia {{features}} biographical {{information and}} illustrations, comic strip images, album covers, <b>frame</b> <b>grabs,</b> and memorabilia about each individual artist. All artists are alphabetized and can both be looked up by name or by their nationality. The emphasis is mostly on comics artists, though cartoonists, caricaturists, animators, illustrators and/or celebrities who once drew comics themselves are also listed. Visitors can mail suggestions for new names, additions or corrections.|$|R
40|$|FIGURE 6. In situ {{photographs}} of two individuals of Symphurus maculopinnis, n. sp., observed on Volcano – 19, Tonga Arc, West Pacific, featuring different asymmetries. A. Specimen with sinistral asymmetry photographed at ca. 439 m. B. <b>Frame</b> <b>grab</b> of specimen featuring reversed (dextral) asymmetry videographed at ca. 560 m. Note also posture of both fish with raised caudal regions displaying prominent spots on posterior dorsal and anal fins as they swim over the bottom...|$|R
50|$|After {{completing}} the plotting radar technique, the {{image from the}} radar can either be displayed, captured or recorded to a computer monitor using a <b>frame</b> <b>grabber.</b>|$|E
50|$|The current version {{supports}} bit rates up to 6.25 Gbit/s over {{a single}} coaxial cable from camera to <b>frame</b> <b>grabber.</b> A low speed uplink channel, operating at 20.833 Mbit/s from <b>frame</b> <b>grabber</b> to camera {{can be used}} for camera control or triggering. A 24 V power supply is also available over the coaxial cable to deliver up to 13 W to the camera. Applications requiring more than a 13 W power supply utilize a separate power supply. For higher bit rates, two or more coaxial cables can be used in parallel.|$|E
5000|$|Autovision II, 1982, used {{a custom}} {{designed}} Versabus 68000 processor with a custom 8-channel RS-170 Versabus <b>frame</b> <b>grabber</b> employing an AMD Am2900 bit slice micro-controller, packaged in an industrially hardened NEMA-12 enclosure.|$|E
40|$|A {{commercial}} CMOS {{image sensor}} was irradiated with heavy ion beams in the several MeV energy range. The image sensor {{is equipped with}} a standard video output. The data were collected on-line through <b>frame</b> <b>grabbing</b> and analysed off-line after digitisation. It was shown that the response of the image sensor to the heavy ion bombardment varied with the type and energy of the projectiles. The sensor will be used for the CMS Barrel Muon Alignment system...|$|R
40|$|FIGURE 2. Telopathes magna (A) in situ {{photograph}} of colony, side view, showing vertical branching pattern or first plane. (B) in situ {{photograph of}} colony, top view, showing horizontal branching pattern or second plane. (C – D) Line drawings of A and B, respectively, showing branching pattern; Ba = {{base of the}} colony, 1 ° = primary branch, 2 ° = secondary branch. (E) in situ video <b>frame</b> <b>grab</b> of colony, top view, showing horizontal branching pattern in second plane (indicated by arrow). (F) Line drawing of cross section of corallum, showing two primary branches in two planes. Scale 10 cm...|$|R
40|$|The {{application}} of computer vision in {{industry has been}} increasing as greater use is made of flexible automation and robotics. Quality control and sorting can also be heavily dependent on artificial vision interfaced to an intelligent decision making system. Traditionally industrial tasks requiring computer vision are simplified to a 2 -D problem in a plane. This permits {{the use of a}} single camera and hence reduces the complexity of the procedures of <b>frame</b> <b>grabbing,</b> image processing and decision making. Such a solution is however not suitable when 3 -D information is vital in the control or decision making processes. Generation and processing of 3 -D images are required for such applications...|$|R
50|$|The Automatix AI-32 robot {{controller}} {{used the same}} processor, bus and RAIL language as the AV II, IV and 5, allowing <b>frame</b> <b>grabber</b> and processing boards to be added for integrated machine vision.|$|E
5000|$|In {{addition}} to the commercial product lines offered by Alacron, Sgro continued to perform basic research in integrating <b>frame</b> <b>grabber</b> technology with specialized systems for various disciplines. The company received SBIR grants where Sgro acted as principal investigators, including: ...|$|E
50|$|CoaXPress {{supports}} a low speed uplink channel from <b>frame</b> <b>grabber</b> to camera. This uplink channel has a fixed bit rate of 20.833 Mbit/s. The uplink channel uses 8b/10b encoding. The uplink {{can be used}} for camera control, triggering and firmware updates.|$|E
50|$|The {{exterior}} of the robot was designed by sculptor Gloria Erika Weimer and is made of a crystal clear plastic, its body is 1.97 m tall (6'5") and weighs 130 kg (290 lb). The robot has 28 degrees of freedom and was provided cameras for eyes. Don Cuco is capable of reading musical scores and play the music on a piano. To perform such tasks the robot required the application of <b>frame</b> <b>grabbing,</b> image processing, pattern recognition and interpretation or analysis of scene. The design team of 30 faculty 20 students at UAP consisted of physicists, physicians, electronic engineers, computer scientists, musicians and designers who worked 20 hours daily for six months to complete the project.|$|R
40|$|Aim of {{the project}} is the {{development}} of a laser diagnostic system (LDS) to apply the Planar Laserinduced Predissociation Fluorescence (PLIF) on Combustion Experiments under Mikrogravity Conditions at the Bremen drop tower. The system consists of a narrowbanded excimerlaser system, a system to achieve optical access to the dropping capsule, a pointing assembly for compensation of relative movements, a sheet forming optic, a two-stage intensfied high-speed camera (250 f/s) and a digital <b>frame</b> <b>grabbing</b> and recording system. The systems has been successfuly developed, installed, and its functionality has been verified. (orig.) SIGLEAvailable from TIB Hannover: DtF QN 1 (65, 33) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Bildung, Wissenschaft, Forschung und Technologie, Bonn (Germany); DLR Deutsches Zentrum fuer Luft- und Raumfahrt e. V., Bonn (Germany) DEGerman...|$|R
50|$|Boerwinkle {{was drafted}} as the fourth {{pick of the}} 1968 NBA Draft and played with the Bulls until 1978. Although largely unappreciated during his playing days, Boerwinkle was a very {{efficient}} player, using his brawny seven-foot <b>frame</b> to <b>grab</b> rebounds and set picks while teammates like Jerry Sloan, Chet Walker and Bob Love {{did most of the}} scoring.|$|R
50|$|An {{alternative}} solution for capturing a screencast {{is the use}} of a hardware RGB or DVI <b>frame</b> <b>grabber</b> card. This approach places the burden of the recording and compression process on a machine separate from the one generating the visual material beingcaptured.|$|E
50|$|The {{most common}} {{application}} is to interface cameras to computers (via a <b>frame</b> <b>grabber)</b> on applications (such as Machine vision) which involve automated acquisition {{and analysis of}} images.Some cameras and frame grabbers have been introduced which support and utilize the CoaXPress interface standard.|$|E
5000|$|Historically, <b>frame</b> <b>grabber</b> {{expansion}} cards were the predominant way to interface cameras to PC's. Other interface methods have emerged since then, with frame grabbers (and in many case, cameras themselves) connecting to computers via interfaces such as USB, Ethernet and IEEE 1394 ("FireWire").|$|E
50|$|Hidden Agenda is a 1988 {{computer}} strategy {{game with}} menu-driven interface and early, {{black and white}} graphics whose scenario was designed and written by Jim Gasperini, with input from project consultant Eric Ehrmann. While the scenario was implemented in text form, the game made use of an innovative graphical interface, with naturalistic characters, settings, and digital video interstitials. The narrative simulation system was designed and implemented by Greg Guerin and Ron Martinez (who also produced the game). Ron Martinez also designed and implemented the front end user experience, in the process inventing {{one of the first}} implementations of digital video with <b>frames</b> <b>grabbed</b> from a hacked four-head VCR. The game was intended to simulate the conditions of a post-revolutionary Central American country. It is considered a forerunner of the Games for Change movement, alongside other early Macintosh games including Chris Crawford's Balance of Power.|$|R
40|$|The Monterey Bay Aquarium Research Institute {{operates}} two Remotely Operated Vehicles that routinely {{explore the}} depths of the ocean at sites around the north eastern Pacific Ocean. Our growing archive of observations – which include high frequency navigation and environmental records, video <b>frame</b> <b>grabs,</b> sampling events, annotations of the video record, and multi-beam sonar bathymetric maps of the dive areas – represents a rich resource for scientific studies. Recent advances in commodity 3 D computer graphics hardware and tools created by the GeoVRML working group have enabled efficient and easy-to-use visualizations of these data via a standard web browser. Visualizations of MBARI’s 3, 000 -plus ROV dives are now available via our internal web-based Expedition database. The GeoVRML implementation allows for geospatially accurate representation of any ROV dive made anywhere on the globe. The system has been in place at MBARI for over two years and use of it is growing. According to people who have used it the system is not just cool but also useful...|$|R
40|$|Active contour models (snakes) can be {{used for}} contour {{description}} and extraction, as well as for object tracking in image sequences. Two unsolved problems for real time object tracking are the problem of an automatic initialization of the snake on the object and the proof of robustness of this object tracking method. In this paper we describe a two stage real time object tracking system. In the first stage, the moving object is detected and the active contour is initialized. In the second stage, the object is tracked by active contour models. The parameters of the camera and the <b>frame</b> <b>grabbing</b> device are continuously updated in such a way, that the moving object will always be kept {{in the center of the}} image. We show how features can be extracted out of the snake tracking the object which are used for detection of errors in the tracking stage. In this case the system switches back to the first stage for object localization. We illustrate through examples that a robust tracking over lo [...] ...|$|R
50|$|Frame {{grabbers}} {{may be used}} {{in security}} applications. For example, when a potential breach of security is detected, a <b>frame</b> <b>grabber</b> captures an image or a sequence of images, and then the images are transmitted across a digital network where they are recorded and viewed by security personnel.|$|E
50|$|With Dunn's help, Simmons {{developed}} the VG123 Multibus and Q-bus <b>frame</b> <b>grabber</b> boards. During this development, Paul Bloom {{was killed in}} what was apparently a gangland style murder. The mystery of why this happened has never been solved. Dave Erickson was promoted to engineering manager to replace Bloom.|$|E
50|$|Used {{primarily}} in ultrasound imaging, capturing the image {{produced by a}} medical imaging device is required for archiving and telemedicine applications. In most scenarios, a <b>frame</b> <b>grabber</b> is used in order to capture the video signal from the medical device and relay it to a computer for further processing and operations.|$|E
40|$|Recently, {{several authors}} and {{institutions}} proposed quality control procedures for 2 -D B-mode sonographic image analysis. The {{aim of this}} study was to assess if it is possible to deﬁne a range of acceptability of the diﬀerent parameters measured. Phantoms for 2 -D B-mode acquisitions were employed with 11 of the same model high-level ultrasound scanners. Uniformity, axial and lateral resolution, axial distance accuracy, geometric distortion, image contrast, dead zone and penetration depth were measured. All images were acquired by experienced operators and saved by <b>frame</b> <b>grabbing</b> the analog video output signal. A small subset of images was also saved directly in dicom 3. 0 format on a magneto optical disk. Images were analysed with in-house developed software. Quality control test results for 2 -D B-mode images were demonstrated to be related to the probe employed. We also found that the results were not dependant on the operator and type of imaging capture method used. By selecting data from the same type of scanner and dividing probes into two groups (convex medium-low frequency and linear medium-high frequency) it is possible to ﬁnd a reasonably narrow range of variability for almost all of the parameters studied. Mean values of the diﬀerent parameters measured, 95...|$|R
30|$|To {{evaluate}} the designed system, an experiment was achieved in a corridor of our lab. <b>Frames</b> have been <b>grabbed</b> at 30 fps with 320 × 240 resolution. Odometer data were sampled at 30 Hz. During the experiment, references are periodically {{drawn on the}} ground by an embedded marker.|$|R
40|$|This {{research}} {{was designed to}} evaluate the operational utility of airborne video for classification accuracy assessment of satellite imagery. There {{are a number of}} logistical advantages in utilizing airborne video data particularly in remote or large catchment regions where ground accessibility can be prohibitively expensive. In a study of land cover characteristics in the Barossa Valley, South Australia, comparisons of Landsat ETM+ classification accuracy assessments were derived from both airborne video and standard ground truthing point sampling techniques. The airborne video data was obtained by randomly <b>frame</b> <b>grabbing</b> 243 individual scenes along four predetermined flight lines and computing classification accuracies and error matrix statistics. These results were then compared with similar statistics derived from 180 randomly chosen ground sampling sites. The costs involved in obtaining both sets of data per sampling pont were also calculated. The results demonstrated that the airborne video data provided similar degrees of accuracy assessment at a cost of approximately one seventh that of the ground survey with the added advantages of increased data collection, overall improved site accessibility and the ability to continually store and review the data. The cost differentiation would become even more pronounced in more remote and inaccessible areas. In general the results of the unsupervised Landsat ETM+ classification were rather poor producing an overall general accuracy of 70 % and a Kappa coefficient of 0. 65, highlighting the classification difficulties encountered in using commercial satellite imagery for land cover assessments in an area with very heterogeneous fine grained land use patterns...|$|R
