0|10000|Public
40|$|Abstract. Both the Local Binary Pattern (LBP) and the Coordinated Clusters Representation (CCR) are {{two methods}} used {{successfully}} in the classification and segmentation <b>of</b> <b>images.</b> They look very similar at first sight. In this work we analyze {{the principles of the}} two methods and show that the methods are not reducible to each other. Topologically they are as different as a sphere and a torus. In <b>extracting</b> <b>of</b> <b>image</b> <b>features,</b> the LBP uses a specific technique <b>of</b> binarization <b>of</b> <b>images</b> with the local threshold, defined by the central pixel of a local binary pattern <b>of</b> an <b>image.</b> Then, the central pixel is excluded of each local binary pattern. As a consequence, the mathematical basis of the LBP method is more limited than that of the CCR. In particular, the scanning window of the LBP has always an odd dimensions, while the CCR has no this restriction. The CCR uses a binarization as a preprocessing <b>of</b> <b>images,</b> so that a global or a local threshold can be used for that purpose. We show that a classification based on the CCR <b>of</b> <b>images</b> is potentially more versatile, even though the high performance of both methods was demonstrated in various applications...|$|R
40|$|Abstract- This paper {{presents}} {{an overview of}} some of the recent theory and application of stochastic minimal graphs in the context of entropy estimation for imaging applications. Stochastic graphs which span a set <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> can be constructed to yield consistent estimators of Jensen's entropy difference for between pairs <b>of</b> <b>images.</b> Unlike traditional plug-in entropy estimates based on density estimation, stochastic graph methods provide direct estimates of these quantities. We review the stochastic graph approach to entropy estimation, compare convergence rates to that of plug-in estimators, and discuss a geo-registration application. I...|$|R
40|$|Abstract. Advanced {{semantic}} {{description of}} multimedia data significantly improves representing, labeling, and retrieving multimedia-based contents. In this paper we present an intelligent framework for attaching semantic annotations to image contents {{based on the}} extraction of elementary low-level features, user’s relevance feedback and the usage of ontology knowledge. This approach facilitates image annotation by proposing a set of most likely relevant content descriptors as a result <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> and the prior annotation <b>of</b> similar <b>images.</b> We illustrate how the specific components of our architecture interact {{in order to provide}} a flexible annotation schema and a learning-based annotation mechanism. ...|$|R
40|$|This paper {{describes}} {{the participation of}} MIRACLE research consortium at the ImageCLEF Medical <b>Image</b> Annotation task <b>of</b> ImageCLEF 2007. Our areas of expertise do not include image analysis, thus we approach this task as a machine-learning problem, regardless of the domain. FIRE {{is used as a}} black-box algorithm to <b>extract</b> different groups <b>of</b> <b>image</b> <b>features</b> that are later used for training different classifiers based on kNN algorithm in order to predict the IRMA code. The main idea behind the definition of our experiments is to evaluate whether an axis-by-axis prediction is better than a prediction by pairs of axes or the complete code, or vice versa...|$|R
40|$|Abstract — This paper {{presents}} {{an overview of}} some of the recent theory and application of stochastic minimal graphs in the context of entropy estimation for imaging applications. Stochastic graphs which span a set <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> can be constructed to yield consistent estimators of Jensen’s entropy difference for between pairs <b>of</b> <b>images.</b> Unlike traditional plug-in entropy estimates based on density estimation, stochastic graph methods provide direct estimates of these quantities. We review the stochastic graph approach to entropy estimation, compare convergence rates to that of plug-in estimators, and discuss a geo-registration application. An extended version of this paper is the technical report [4]. I...|$|R
40|$|Visual {{attention}} region prediction {{has been}} paid much attention by researchers in intelligent systems recent years 	because it can make the interaction between human and intelligent agents to be more convenient. In this paper, the prediction method of the visual attention region inferred by using fuzzy neural network (FNN) after <b>extracting</b> and computing <b>of</b> <b>images</b> <b>feature</b> maps and saliency maps was proposed. A method for training FNN is also proposed. A user experiment was conducted to evaluate the prediction effect of proposed method by making surveys for the prediction results. The results indicated that prediction method proposed by us has a better performance {{in the level of}} attention regions position prediction according to different images...|$|R
40|$|Abstract. In this paper, an {{effective}} relevance feedback (RF) approach is proposed in content-based image retrieval (CBIR). In the first stage, {{according to the}} user’s marked images, we get theirs predictive probabilities based-on Bayesian methodology which yields the posteriori <b>of</b> the <b>images</b> in the database; second via justify the weight of elements in each <b>feature</b> <b>extracted</b> <b>of</b> <b>images,</b> we refine <b>features</b> by logistic regression with positive features which get from the first stage. Then we rank the images according to the probability <b>of</b> the <b>images</b> in the database. The retrieval system is repeating until the user is satisfied with the feedback results or the target image has been found. Experimental results are shown to evaluate the method on a large image database in terms of precision and recall...|$|R
40|$|Barcode {{technology}} {{is essential in}} automatic identification, and is used {{in a wide range}} of real-time applications. Different code types and applications impose special problems, so there is a continuous need for solutions with improved performance. Several methods exist for code localization, that are well characterized by accuracy and speed. Particularly, high-speed processing places need reliable automatic barcode localization, e. g. conveyor belts and automated production, where missed detections cause loss of profit. Our goal is to detect automatically, rapidly and accurately the barcode location with the help <b>of</b> <b>extracted</b> <b>image</b> <b>features.</b> We propose a new algorithm variant, that outperforms in both accuracy and efficiency other detectors found in the literature using similar ideas, and also improves on the detection performance in detecting 2 D codes compared to our previous algorithm...|$|R
40|$|Aerial images {{constitute}} an important data source for Geo-Information Systems. In {{order to get}} actual data at reasonable costs, the development of (semi-) automatic tools has been an active research topic in photogrammetry and image processing in the recent years. Based on established techniques for low level syntactic operators such as filters, feature extraction, line detectors and simple pattern matchers, nowadays there is strong interest in explicit models {{in order to improve}} the identification of semantically meaningful objects. From the pixel to the object level several representation formalisms such as graphs <b>of</b> <b>extracted</b> <b>image</b> <b>features,</b> aspect graphs and constructive solid geometry (CSG) are applied. Constraint Logic Programming has been identified as an adequate representation formalism and implementation language for building the necessary experimental environment, specifying the models on the different levels, expressing strong heuristics and approaching the complex search pr [...] ...|$|R
40|$|Abstract. Barcode {{technology}} {{is essential in}} automatic identification, and is used {{in a wide range}} of real-time applications. Different code types and applications impose special problems, so there is a continuous need for solutions with improved performance. Several methods exist for code localization, that are well characterized by accuracy and speed. Particularly, high-speed processing places need reliable automatic barcode localization, e. g. conveyor belts and automated production, where missed detections cause loss of profit. Our goal is to detect automatically, rapidly and accurately the barcode location with the help <b>of</b> <b>extracted</b> <b>image</b> <b>features.</b> We propose a new algorithm variant, that outperforms in both accuracy and efficiency other detectors found in the literature using similar ideas, and also improves on the detection performance in detecting 2 D codes compared to our previous algorithm. Keywords:barcode detection, morphological operations, bottom-hat filter, distance map...|$|R
40|$|The {{presence}} of clustered microcalcifications {{is one of}} the earliest signs in breast cancer detection. Although there exist many studies broaching this problem, most of them are nonreproducible due to the use <b>of</b> proprietary <b>image</b> datasets. We use a known subset of the currently largest publicly available mammography database, the Digital Database for Screening Mammography (DDSM), to develop a computer-aided detection system that outperforms the current reproducible studies on the same mammogram set. This proposal is mainly based on the use <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> obtained by independent component analysis, but we also study the inclusion of the patient’s age as a nonimage feature which requires no human expertise. Our system achieves an average of 2. 55 false positives per image at a sensitivity of 81. 8 % and 4. 45 at a sensitivity of 91. 8 % in diagnosing the BCRP_CALC_ 1 subset of DDSM...|$|R
40|$|Content Based Image Retrieval (CBIR) is {{a method}} <b>of</b> <b>extracting</b> <b>image</b> <b>features</b> and {{calculate}} visual similarity based on these features. Lot of research activity is continuing for optimizing and improving the feature extraction methods focusing on colour, texture and shape features to minimize the semantic gap. Relevant Feedback (RF) is one variant of CBIR wherein the user provides feedback by selecting the most relevant image from retrieved images {{and make it a}} query image for the subsequent iterations. The RF methods improved the performance of the overall system in multiple iterations but the time taken for the total process increases on the other hand. This paper attempts to address the semantic gap problem by having the user interface in the forward path by adding some more key requirements of the user for narrowing down the search options thereby increasing the system performance and reducing the retrieval time...|$|R
40|$|Abstract — This paper {{presents}} {{an overview of}} some of the recent the- formation method outlined in [6]. However, for unknown� ory and application of stochastic minimal graphs in the context of entropy and unknown�the existence of consistent minimal-graph es-estimation for imaging applications. Stochastic graphs which span a set <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> can be constructed to yield consistent estimatimators of�«���is an open problem. This paper will be tors of Jensen’s entropy difference for between pairs <b>of</b> <b>images.</b> Unlike concerned with an alternative dissimilarity function, called the traditional plug-in entropy estimates based on density estimation, stochas«-Jensen difference, which {{is a function of the}} joint entropy of tic graph methods provide direct estimates of these quantities. We review�and�. As will be shown below, this function can be esti-the stochastic graph approach to entropy estimation, compare convergence rates to that of plug-in estimators, and discuss a geo-registration applicamated using minimal graph entropy estimation techniques an...|$|R
40|$|This thesis {{describes}} a probabilistic approach to imagesegmentation and interpretation. The {{focus of the}} investigation {{is the development of}} a systematic way of combining color, brightness, texture and geometric features extracted from an image to arrive at a consistent interpretation for each pixel in the <b>image.</b> The contribution <b>of</b> this thesis is thus the presentation of a novel framework for the fusion <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> producing a segmentation <b>of</b> an <b>image</b> into relevant regions. Further, a solution to the sub-pixel mixing problem is presented based on solving a probabilistic linear program. This work is specifically aimed at interpreting and digitizing multi-spectral aerial imagery of the Earth's surface. The features of interest for extraction are those of relevance to environmental management, monitoring and protection. The presented algorithms are suitable for use within a larger interpretive system. Some results are presented and contrasted with other techniques. The integration of these algorithms into a larger system is based firmly on a probabilistic methodology and the use of statistical decision theory to accomplish uncertain inference within the visual formalism of a graphical probability model...|$|R
40|$|Copyright © 2012 R. Gallardo-Caballero et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The presence of clustered microcalcifications {{is one of the}} earliest signs in breast cancer detection. Although there exist many studies broaching this problem, most of them are nonreproducible due to the use <b>of</b> proprietary <b>image</b> datasets. We use a known subset of the currently largest publicly available mammography database, the Digital Database for Screening Mammography (DDSM), to develop a computer-aided detection system that outperforms the current reproducible studies on the same mammogram set. This proposal is mainly based on the use <b>of</b> <b>extracted</b> <b>image</b> <b>features</b> obtained by independent component analysis, but we also study the inclusion of the patient’s age as a nonimage feature which requires no human expertise. Our system achieves an average of 2. 55 false positives per image at a sensitivity of 81. 8 % and 4. 45 at a sensitivity of 91. 8 % in diagnosing the BCRP CALC 1 subset of DDSM. 1...|$|R
40|$|This paper {{describes}} {{the participation of}} MIRACLE research consortium at the ImageCLEF Medical <b>Image</b> Annotation task <b>of</b> ImageCLEF 2007. Our areas of expertise do not include image analysis, thus we approach this task as a machine-learning problem, regardless of the domain. FIRE {{is used as a}} black-box algorithm to <b>extract</b> different groups <b>of</b> <b>image</b> <b>features</b> that are later used for training different classifiers in order to predict the IRMA code. Three types of classifiers are built. The first type is a single classifier that predicts the complete IRMA code. The second type is a two level classifier composed of four classifiers that individually predict each axis of the IRMA code. The third type is similar to the second one but predicts a combined pair of axes. The main idea behind the definition of our experiments is to evaluate whether an axis-by-axis prediction is better than a prediction by pairs of axes or the complete code, or vice versa. We submitted 30 experiments to be evaluated and results are disappointing compared to other groups. However, the main conclusion that can be drawn from the experiments is that, irrespective <b>of</b> the selected <b>image</b> <b>features,</b> the axis-by-axis prediction achieves more accurate results not only than the prediction of a combined pair of axes but also, in turn, than the prediction of the complet...|$|R
40|$|As one of {{the most}} popular deep {{learning}} models, convolution neural network (CNN) has achieved huge success in image information extraction. Traditionally CNN is trained by supervised learning method with labeled data and used as a classifier by adding a classification layer in the end. Its capability <b>of</b> <b>extracting</b> <b>image</b> <b>features</b> is largely limited due to the difficulty of setting up a large training dataset. In this paper, we propose a new unsupervised learning CNN model, which uses a so-called convolutional sparse auto-encoder (CSAE) algorithm pre-Train the CNN. Instead of using labeled natural images for CNN training, the CSAE algorithm can be used to train the CNN with unlabeled artificial images, which enables easy expansion of training data and unsupervised learning. The CSAE algorithm is especially designed for extracting complex features from specific objects such as Chinese characters. After the <b>features</b> <b>of</b> articficial <b>images</b> are <b>extracted</b> by the CSAE algorithm, the learned parameters are used to initialize the first CNN convolutional layer, and then the CNN model is fine-Trained by scene image patches with a linear classifier. The new CNN model is applied to Chinese scene text detection and is evaluated with a multilingual image dataset, which labels Chinese, English and numerals texts separately. More than 10 % detection precision gain is observed over two CNN models...|$|R
40|$|In this paper, {{we apply}} and {{evaluate}} a modified Gaussian-test-based hierarchical clustering method for high-resolution satellite images. The {{purpose is to}} obtain homogeneous clusters within each hierarchy level which later allow the classification and annotation <b>of</b> <b>image</b> data ranging from single scenes up to large satellite data archives. After cutting a given image into small patches and feature extraction from each patch, k -means are used to split sets <b>of</b> <b>extracted</b> <b>image</b> <b>feature</b> vectors to create a hierarchical structure. As <b>image</b> <b>feature</b> vectors usually fall into a high-dimensional feature space, we test different distance metrics, to tackle the “curse of dimensionality” problem. By using three different synthetic aperture radar (SAR) and optical image datasets, Gabor texture and Bag-of-Words (BoW) features are extracted, and the clustering results are analyzed via visual and quantitative evaluations. We also compared our approach with other classic unsupervised clustering methods. The most important contributions of this paper are the discussion and evaluation of cluster homogeneity by comparing various datasets, feature descriptors, evaluation measures, and clustering methods, {{as well as the}} analysis of the clustering performances under various distance metrics. The results show that the Gaussian-test-based hierarchical patch clustering method is able to obtain homogeneous clusters, while Gabor texture features perform better than the BoW features. In addition, it turns out that a distance parameter ranging from 1. 2 to 2 performs best. Also indicated by [1], our modified G-means algorithm is faster than the original algorithm...|$|R
40|$|Within {{the fields}} of visual effects and animation, humans have {{historically}} spent countless painstaking hours mastering the skill of drawing frame-by-frame animations. One such animation technique that has been widely used in the animation and visual effects industry is called 2 ̆ 2 rotoscoping 2 ̆ 2 and has allowed uniquely stylized animations to capture the motion of real life action sequences, however {{it is a very}} complex and time consuming process. Automating this arduous technique would free animators from performing frame by frame stylization and allow them to concentrate on their own artistic contributions. This thesis introduces a new artificial system based on an existing neural style transfer method which creates artistically stylized animations that simultaneously reproduce both the motion of the original videos that they are derived from and the unique style of a given artistic work. This system utilizes a convolutional neural network framework to <b>extract</b> a hierarchy <b>of</b> <b>image</b> <b>features</b> used for generating images that appear visually similar to a given artistic style {{while at the same time}} faithfully preserving temporal content. The use of optical flow allows the combination of style and content to be integrated directly with the apparent motion over frames of a video to produce smooth and visually appealing transitions. The implementation described in this thesis demonstrates how biologically-inspired systems such as convolutional neural networks are rapidly approaching human-level behavior in tasks that were once thought impossible for computers. Such a complex task elucidates the current and future technical and artistic capabilities of such biologically-inspired neural systems as their horizons expand exponentially. Further, this research provides unique insights into the way that humans perceive and utilize temporal information in everyday tasks. A secondary implementation that is explored in this thesis seeks to improve existing convolutional neural networks using a biological approach to the way these models adapt to their inputs. This implementation shows how these pattern recognition systems can be greatly improved by integrating recent neuroscience research into already biologically inspired systems. Such a novel hybrid activation function model replicates recent findings in the field of neuroscience and shows significant advantages over existing static activation functions...|$|R
40|$|The {{extraction}} of meaningful <b>features</b> from an <b>image</b> forms an important area <b>of</b> <b>image</b> analysis. It enables {{the task of}} understanding visual information to be implemented in a coherent and well defined manner. However, {{although many of the}} traditional approaches to feature extraction have proved to be successful in specific areas, recent work has suggested that they do not provide sufficient generality when dealing with complex analysis problems such as those presented by natural images. This thesis considers the problem <b>of</b> deriving an <b>image</b> description which could form the basis of a more general approach to feature extraction. It is argued that an essential property of such a description is that it should have locality in both the spatial domain and in some classification space over a range of scales. Using the 2 -d Fourier domain as a classification space, a number <b>of</b> <b>image</b> transforms that might provide the required description are investigated. These include combined representations such as a 2 -d version of the short-time Fourier transform (STFT), and multiscale or pyramid representations such as the wavelet transform. However, it is shown that these are limited in their ability to provide sufficient locality in both domains and as such do not fulfill the requirement for generality. To overcome this limitation, an alternative approach is proposed {{in the form of the}} multiresolution Fourier transform (MFT). This has a hierarchical structure in which the outermost levels are the image and its discrete Fourier transform (DFT), whilst the intermediate levels are combined representations in space and spatial frequency. These levels are defined to be optimal in terms of locality and their resolution is such that within the transform as a whole there is a uniform variation in resolution between the spatial domain and the spatial frequency domain. This ensures that locality is provided in both domains over a range of scales. The MFT is also invertible and amenable to efficient computation via familiar signal processing techniques. Examples and experiments illustrating its properties are presented. The problem <b>of</b> <b>extracting</b> local <b>image</b> <b>features</b> such as lines and edges is then considered. A multiresolution image model based on these features is defined and it is shown that the MET provides an effective tool for estimating its parameters [...] The model is also suitable for representing curves and a curve extraction algorithm is described. The results presented for synthetic and natural images compare favourably with existing methods. Furthermore, when coupled with the previous work in this area, they demonstrate that the MFT has the potential to provide a basis for the solution <b>of</b> general <b>image</b> analysis problems...|$|R
40|$|ACRONYM IS a {{comprehensive}} domain independent modelbased system for vision and manipulation related tasks. Many of its sub-modules and representations {{have been described}} elsewhere. Here the derivation and use <b>of</b> invariants for <b>image</b> <b>feature</b> prediction is described. We describe how predictions <b>of</b> <b>image</b> <b>features</b> and their relations are made and how instructions are generated which tell the interpretation algorithms how to make use <b>of</b> <b>image</b> <b>feature</b> measurments to derive three dimensional sizes and structural and spatial constraints on the original three-dimensional models. Some preliminary examples of ACRONYM'S interpretations <b>of</b> aerial <b>images</b> are shown. 1...|$|R
40|$|The video {{presents}} {{a novel approach}} for vision-based topological localisation in dynamic indoor environments. In contrast to other approaches that rely on static <b>image</b> <b>features,</b> our method explicitly models the temporal dynamics of the visibility <b>of</b> <b>image</b> <b>features.</b> The proposed spatio-temporal world model is able to predict the visibility <b>of</b> <b>image</b> <b>features</b> {{at different times of}} day, which allows to construct time-specific environment appearance models. This approach improves the robot localisation capabilities during long-term operations...|$|R
40|$|In {{traditional}} compressed sensing MRI methods, single sparsifying transform {{limits the}} reconstruction quality because it cannot sparsely represent all types <b>of</b> <b>image</b> <b>features.</b> Based {{on the principle}} of basis pursuit, a method that combines sparsifying transforms to improve the sparsity <b>of</b> <b>images</b> is proposed. Simulation results demonstrate that the proposed method can well recover different types <b>of</b> <b>image</b> <b>features</b> and can be easily associated with total variation. This work was partially supported by NNSF of China under Grants (10774125 and 10605019) ...|$|R
3000|$|The {{first term}} models the part {{appearance}} with a convolution <b>of</b> <b>image</b> <b>feature</b> vector ϕ_i(I,l_i) [...] with trained detector w [...]...|$|R
40|$|Abstract:- In {{this paper}} we explore the use of {{orthogonal}} functions as generators of representative, compact descriptors <b>of</b> <b>image</b> content. In Image Analysis and Pattern Recognition such descriptors {{are referred to as}} <b>image</b> <b>features,</b> and there are some useful properties they should possess such as rotation invariance and the capacity to identify different instances of one class <b>of</b> <b>images.</b> We exemplify our algorithmic methodology using the family of Daubechies wavelets, since they form an orthogonal function set. We benchmark the quality <b>of</b> the <b>image</b> <b>features</b> generated by doing a comparative OCR experiment with three different sets <b>of</b> <b>image</b> <b>features.</b> Our algorithm can use a wide variety of orthogonal functions to generate rotation invariant features, thus providing the flexibility to identify sets <b>of</b> <b>image</b> <b>features</b> that are best suited for the recognition of different classes <b>of</b> <b>images...</b>|$|R
40|$|Abstract—In {{describing}} <b>image</b> <b>features</b> it {{is important}} to consider the fact that the appearance of a feature depends on the scale or resolution at which it is observed. Existing robust <b>image</b> <b>feature</b> detectors address the issue by selecting a characteristic scale for each detected feature and subsequently describing the feature as it appears at its characteristic scale. A new method is presented for the multi-scale analysis <b>of</b> derivative based <b>image</b> <b>features</b> that represents a 2 D <b>image</b> <b>feature</b> by its locus in scalespace. An algorithm is also presented for efficiently producing the discrete loci representations <b>of</b> <b>image</b> <b>features</b> through clustering features detected at multiple scales. This new method provides an entry point to potential multi-scale descriptions <b>of</b> <b>image</b> <b>features,</b> as well as new possibilities for feature set reduction and filtering. I...|$|R
5000|$|The Pyramid Match Kernel: Discriminative Classification with Sets <b>of</b> <b>Image</b> <b>Features.</b> K. Grauman and T. Darrell. International Conference on Computer Vision (ICCV), 2005 ...|$|R
40|$|We {{describe}} {{a novel approach}} of spatio-temporal mapping <b>of</b> local <b>image</b> <b>features,</b> {{to reduce the number}} of input data for further object categorization. The main focus of our work is the selection of good features to learn, by achieving a precise mapping <b>of</b> <b>image</b> <b>features</b> either related to static objects or to background. This can be done by initial camera motion estimation, subsequent structure estimation and final clustering of the 3 D points. Experimental results show that our method achieves a significant reduction <b>of</b> processed <b>image</b> <b>features,</b> which yields a better performance in subsequent learning modules. ...|$|R
40|$|We {{studied the}} informativeness <b>of</b> <b>image</b> <b>features</b> ex-tracted from {{different}} lengths <b>of</b> <b>image</b> transform chains {{for the purpose}} <b>of</b> <b>image</b> classification. <b>Image</b> <b>features</b> were ex-tracted from the raw images, image transforms, and second, third and fourth order <b>of</b> compound <b>image</b> transforms. The transforms {{used in this study}} are Fourier, Chebyshev, and Wavelet (symlet 5) transform. Experimental results show that <b>image</b> <b>features</b> extracted from first and second order <b>of</b> compound <b>image</b> transforms can in some cases be more in-formative than the <b>image</b> <b>features</b> extracted from the raw pixels, and can significantly contribute to the classifica-tion accuracy. However, chains of transforms longer than two do not improve the classification accuracy <b>of</b> the <b>image</b> datasets used in this study. 1...|$|R
40|$|One of {{the goals}} <b>of</b> <b>image</b> <b>feature</b> {{extraction}} is to extract <b>features</b> from an <b>image</b> that are dependent on the scene, rather than the image, which also includes intensity information. In theory, a logarithmic transformation allows the extraction of many di#erent types <b>of</b> <b>image</b> <b>features,</b> with the magnitude <b>of</b> the <b>extracted</b> feature being more representative of the scene property. Unfortunately, {{the magnitude of the}} e#ect is usually dominated by quantisation and image noise. This paper outlines the theory and demonstrates the special cases where there is an advantage to using the log transform...|$|R
40|$|Abstract- A mixed-mode neuro-fuzzy {{accelerator}} {{is proposed}} for keypoint localization <b>of</b> <b>image</b> <b>features</b> <b>of</b> Scale Invariant Feature Transform (SIFT) algorithm. To reduce processing time of keypoint localization with low power consumption, analog Adaptive Neuro-Fuzzy Inference System (ANFIS) and digital controller are implemented together. It is implemented in O. 13 J. 1. m CMOS process and achieves 1. 15 mW power consumption. Compared {{to the conventional}} digital standalone system, O. 733 mm 2 neuro-fuzzy accelerator achieves 43 % processing time reduction and also results in 19. 4 % time reduction <b>of</b> <b>image</b> <b>feature</b> extraction process. I...|$|R
40|$|The self-localization for {{a mobile}} robot is very {{important}} at indoor environments. In this paper, we propose a relative self-localization estimation algorithm based on relative locations and orientation changes <b>of</b> <b>image</b> <b>features.</b> We also analyze errors caused {{by a variety of}} factors to estimate the relative self-localization of a mobile robot and discuss a few techniques to remove them. The proposed relative self-localization algorithm is based on the facts that the global orientation and location <b>of</b> <b>image</b> <b>features</b> are not altered by changing <b>of</b> <b>images.</b> We show that the proposed algorithm is valuable through some simulation examples...|$|R
40|$|An {{interactive}} method <b>of</b> <b>image</b> <b>feature</b> extraction {{based on}} B-Spline curves is proposed. B-Splines are piecewise polynomial curves that are {{guided by a}} sequence of points called the control points. The proposed method differs from traditional one in that the <b>features</b> <b>of</b> an <b>image</b> are <b>extracted</b> automatically according to a limited sequence of control points inserted by user in an interactive way, and the extracted <b>image</b> <b>features</b> are described {{as a series of}} B-Spline curves. Consequentially, the analysis <b>of</b> <b>image</b> <b>features</b> becomes easy and effective because of the specific properties of the B-Spline curves, {{and at the same time}} a significant data compression is achieved. An <b>image</b> <b>feature</b> extraction software package based on the proposed method has been realized in C language...|$|R
40|$|Image {{registration}} (IR) aims to geometrically match {{one image}} to another. It is extensively {{used in many}} imaging applications. Among many existing IR methods, one widely used group of methods are feature-based. By a feature-based method, a number <b>of</b> relevant <b>image</b> <b>features</b> are first extracted from the two images, respectively, and then a geometric matching transformation is found to best match {{the two sets of}} features. However, proper identification and extraction <b>of</b> <b>image</b> <b>features</b> {{turns out to be a}} challenging task. Generally speaking, a good <b>image</b> <b>feature</b> extraction method should have the following two properties: (i) the identified <b>image</b> <b>features</b> should provide us proper information to approximate the geometric matching transformation accurately, and (ii) they should be easy to identify by a computer algorithm so that the entire feature extraction procedure is computer automatic. In this paper, a new type <b>of</b> <b>image</b> <b>features</b> is studied, which has the two properties described above. Together with the widely used thin platespline(TPS) geometrictransformationmodel,itisshownthatourfeature-basedIRmethod works effectively in various cases...|$|R
30|$|Final output image time-frequency {{composite}} weighted image signalWuu(a,[*]b). Therefore, {{compared with}} the traditional time-domain, c extraction technique <b>of</b> <b>image</b> <b>features</b> can be better realized by the time-frequency composite weighting algorithm.|$|R
50|$|The {{system can}} be {{employed}} with phone numbers. One would typically make up multiple words, preferably a sentence, or an ordered sequence <b>of</b> <b>images</b> <b>featuring</b> the owner <b>of</b> the number.|$|R
