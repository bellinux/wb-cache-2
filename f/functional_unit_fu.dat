56|5768|Public
30|$|The <b>functional</b> <b>unit</b> (<b>FU)</b> {{selected}} here {{is defined}} as 1  km guardrail. The system boundaries for the LCA of the guardrail include raw material extraction, production, maintenance, and transportation from the manufacturing plant to the construction site.|$|E
30|$|According to IEC 62351 - 4, the {{authenticity}} of MMS is provided by peer entity authentication that occurs at association set up time. The authentication is implemented through association control service element (ACSE) security as follows: enabling sender-ACES-requirements field and responder-ACSE-requirement field of the authentication <b>functional</b> <b>unit</b> (<b>FU)</b> of ACSE, defining the data structure MMS_Authentication-value where the signature value is stored.|$|E
30|$|Visualization is an {{important}} aspect {{in the analysis of}} EEG coherence, especially for multichannel EEG coherence networks. Since conventional methods either suffer from reduced spatial information or visual clutter, they have inherent limitations when applied to EEG coherence networks. We developed a visualization approach based on the <b>functional</b> <b>unit</b> (<b>FU)</b> concept that attempts to preserve spatial relationships between functional brain regions and allows analysis of functional connectivity within and between regions.|$|E
40|$|This paper {{presents}} a new algorithm for computing lower bounds {{on the number}} of <b>functional</b> <b>units</b> (<b>FU's)</b> required to schedule a data flow graph in a specified number of control steps. We use a formal approach to compute the bounds that can can be proven to be tighter than those produced by existing methods, and that considers the interdependencies of the bounds on the different FU-types. This quick yet accurate estimation of the number of FU's is used to generate resource constraints for a design, and thus reduce the design space. 1 Introduction In this paper, we discuss the problem of computing the minimum number of <b>functional</b> <b>units</b> (<b>FU)</b> required to schedule a data flow graph in a given number of control steps. The general problem is NP-hard; however, we present an efficient methodology that produces provably tight lower bounds {{on the number of}} FU's. Computing tight lower bounds on the number of FU's is important for several reasons. Timeconstrained scheduling algorithms have to expl [...] ...|$|R
40|$|A novel {{technique}} is introduced to reduce power consumption in <b>Functional</b> <b>Units</b> (<b>FU).</b> Extra slower FU with lower per-execution energy consumption are added into a processor. Thus, through code scheduling, instructions whose {{results are not}} immediately referenced after completion are issued to these power-frugal FU. Simulation suggests a prospect of saving 20 % to 30 % energy consumption in addition instructions while still improving the performance...|$|R
50|$|A slot {{comprises}} the operation issue and data paths machinery surrounding {{a collection of}} one or more <b>functional</b> <b>units</b> (<b>FUs)</b> which share these resources. The term slot is common for this purpose in the VLIW world where the relationship between operation in an instruction and pipeline to execute it is explicit. In dynamically scheduled machines the concept is more commonly called an execute pipeline.|$|R
40|$|<b>Functional</b> <b>Unit</b> (<b>FU)</b> {{ensures the}} {{consideration}} of comparable product quantities to provide reliable Life Cycle Assessment (LCA) results. Although the definition of this FU is essential, it receives only a few attention in the normative texts. A high part of subjectivity is let to the LCA practitioner. In this paper variability sources of the FU definition are identified to propose a more structured and adapted approach. Literature references and data collected among 8 LCA experts on 5 case studies allow us to draw first recommendations towards a more structured FU definition framework...|$|E
40|$|Abstract — DSP {{processors}} provide dedicated address generation units (AGUs) {{that are}} capable of performing address arithmetic in parallel to the main data path. Address assignment, optimization of memory layout of program variables to reduce address arithmetic instructions by taking advantage of the capabilities of AGUs, has been studied extensively for single <b>functional</b> <b>unit</b> (<b>FU)</b> processors. In this paper, we exploit address assignment and scheduling for multiple-FU processors. We propose an efficient address assignment and scheduling algorithm for multiple-FU processors. Experimental results show that our algorithm can greatly reduce schedule length and address operations on multiple-FU processors compared with the previous work. Index Terms — address assignment, scheduling, multiple functional units, AGU, DSP...|$|E
40|$|Abstract — Two {{algorithms}} {{that combine}} {{the operations of}} scheduling and recovery-point insertion for high-level synthesis of recoverable microarchitectures are presented. The first uses a prioritized cost function in which <b>functional</b> <b>unit</b> (<b>FU)</b> cost is minimized first and register cost second. The second algorithm minimizes a weighted sum of FU and register costs. Both algorithms are optimal according to their respective cost functions and require less than 10 min of central processing unit (CPU) time on widely used high-level synthesis benchmarks. The best previous result reported several hours of CPU time {{for some of the}} same benchmarks on a computer of similar computational power. Index Terms — High-level synthesis, micro-rollback, optimization, recovery, scheduling...|$|E
40|$|The MPEG RVC {{framework}} is currently under development by MPEG {{as part of}} MPEG-B and MPEG-C standards. RVC aims at providing a model of specifying existing or completely decoder is built as a block diagram in which blocks define processing entities called <b>Functional</b> <b>Units</b> (<b>FUs)</b> and connections represent the data path. RVC provides both a normative standard library of FUs {{and a set of}} decoder descriptions exhal- 00336516...|$|R
40|$|Within Philips Research Labs, we are {{investigating}} the 64 bit VLIW core for future TriMedia processors. We have performed an extensive Design Space Exploration (DSE) on this core using quantitative analysis, using a benchmark suite of applications which are representative for multimedia processing. We have explored, among others, the configurations of the different <b>functional</b> <b>units</b> (<b>FUs)</b> of the 64 -bit VLIW core. We show the merit of our approach and of the environment that we have developed for design space exploration. 1...|$|R
40|$|The word-length of <b>Functional</b> <b>Units</b> (<b>FU)</b> has a {{great impact}} on design costs. This paper {{addresses}} the problem of choosing different word-lengths for each FU while considering circuit area and power consumption. A high-level synthesis tool is used to minimize the circuit area and power consumption by selecting an optimal word-length for each FU in the system. Our results demonstrate that by customizing word lengths to nonstandard sizes, savings can be made in the overall area and power without losing accuracy...|$|R
40|$|The {{quest for}} higher {{performance}} {{within a certain}} power budget {{in the fields of}} embedded computing demands unconventional architectural approaches. To this end, in this paper we present synZEN (sZ) : a (micro-) architecture that combines features of very long instruction word (VLIW) and transport triggered architectures (TTAs) to cover the needs of different applications. SynZEN features a distributed register file (RF) (i. e., each <b>functional</b> <b>unit</b> (<b>FU)</b> has its own RF) and a wide memory connection to exploit spatial data locality. FPGA synthesis results demonstrate that due to the distributed RF the sZ design can be implemented in less area (in terms of FPGA slices) than existing TTA and VLIW designs. Furthermore, using two micro-benchmarks we show that because of the wide memory connection, sZ outperforms both the TTA as well as the VLIW design...|$|E
40|$|A highly {{parallel}} and scalable Deblocking Filter (DF) hardware architecture for H. 264 /AVC and SVC video codecs {{is presented}} in this paper. The proposed architecture mainly consists on a coarse grain systolic array obtained by replicating a unique and homogeneous <b>Functional</b> <b>Unit</b> (<b>FU),</b> in which a whole Deblocking-Filter unit is implemented. The proposal is also based on a novel macroblock-level parallelization strategy of the filtering algorithm which improves the final performance by exploiting specific data dependences. This way communication overhead is reduced and a more intensive parallelism {{in comparison with the}} existing state-of-the-art solutions is obtained. Furthermore, the architecture is completely flexible, since the level of parallelism can be changed, according to the application requirements. The design has been implemented in a Virtex- 5 FPGA, and it allows filtering 4 CIF (704 × 576 pixels @ 30 fps) video sequences in real-time at frequencies lower than 10. 16 Mhz...|$|E
40|$|In {{this paper}} {{we present a}} genetic {{scheduling}} algorithm to support the synthesis of structured data paths {{with the aim of}} producing designs with a predictable layout structure and conserving on-chip wiring resources. The data path is organized as architectural blocks (A-block) with local <b>functional</b> <b>unit</b> (<b>FU),</b> memory elements and internal interconnections. The A-blocks are interconnected by a few global buses. Our scheduling algorithm delivers the schedule of operations, the A-block in which each operation is scheduled and also the schedule of transfers over the buses, including transfers required to define variables in the basic block which remain live after its execution, all satisfying specified architectural constraints. The make up of the FUs in each A-block in terms of specific implementations of operators from a module database is also provided. Keywords Scheduling, Allocation, High-Level Synthesis (HLS), Genetic Algorithm (GA). 1 INTRODUCTION Initial work on DPS led to the de [...] ...|$|E
40|$|If a VLSI chip is {{partitioned}} into <b>functional</b> <b>units</b> (<b>FU's)</b> and redundant FU's are added, error correcting codes may {{be employed}} to increase the yield and/or reliability of the chip. Acceptable testing is defined to be testing the chip with the error corrector functioning, thus obtaining the maximum increase in yield afforded by the error correction. The acceptable testing theorem shows {{that the use of}} coding and error correction in conjunction with acceptable testing can significantly increase the yield of VLSI chips without seriously compromising their reliability...|$|R
40|$|Continuous {{technology}} scaling {{has resulted}} {{in an increase in}} both, the power density as well as the variation in device dimensions (process variations) of the manufactured processors. Both power density and process variations {{have a significant impact on}} the leakage power. Therefore, power optimization techniques should be sensitive to the variation in leakage power due to both temperature as well as process variations. Operation to <b>Functional</b> <b>Units</b> Binding Mechanism (OFBM) is the mechanism to dynamically issue operations to <b>Functional</b> <b>Units</b> (<b>FUs)</b> in superscalar processors. We propose a Leakage-Aware OFBM (LA-OFBM), which is both temperature and process variation aware. Our experimental results demostrate that LA-OFBM reduces the mean and standard deviation of the total energy consumption of ALUs by 18 %, and 46 % respectively, as compared to the traditional OFBM, without any performance penalty. 1...|$|R
40|$|The Video Tool Library (VTL) {{is one of}} {{the major}} {{normative}} components of the Reconfigurable Video Coding (RVC) standard. It specifies the set of <b>functional</b> <b>units</b> (<b>FUs)</b> that may be interchangeably combined and connected to form different video codecs, with various compression performances and implementation complexities. In this paper, an efficient AVC baseline encoder that is described in CAL is introduced. The encoder is composed of many modules that also exist in other codecs of the same or different standards. This makes them highly reusable within the RVC framework. The main modules of the designed encoder include: Inter Prediction, Intra Prediction, and Entropy Coding. Brief descriptions of the designed modules, accompanied with CAL design issues are provided...|$|R
40|$|A <b>functional</b> <b>unit</b> (<b>FU)</b> that is {{well suited}} to high computational-intensive DSP systems, and {{combines}} several techniques to achieve high energy efficiency is presented. This FU consists of a datapath enabling parallel operations within it. A user configurable RAM memory specifies the operations required and gives the user and system programmer great flexibility in executing algorithms. Not only multiply accumulator operations can be performed by the FU, but other necessary instructions of a general DSP such as the hamming distance are also implemented. The operation flow is controlled using a self-timed circuit style to further reduce power and spread the circuit switching. Post-layout simulation of our full-custom FU implemented on 0. 18 m operating at 1. 8 V with an area 0. 36 mm 2 shows a large energy improvement {{by a factor of}} 10 compared to the original design whilst performance results show that using four-way parallelism DSP yields a high throughout rate of equivalent to 800 MHz. 1...|$|E
30|$|In {{the field}} of {{freshwater}} analysis, the established methods of LCA and LCC were used for a quantitative assessment of potential environmental impacts and costs along the life cycle (LC) of products and services—or, specifically in this project, of different technologies—to provide valid information to realize optimization potentials and for appropriate decision support. LCA and LCC are relevant tools within sustainability assessments, because the LC perspective helps to avoid a shift of burden between life-cycle phases or to future generations. Specifically, with LCA and LCC, the inputs and outputs of a product (e.g., materials, energy, costs and emissions, and costs/revenues, respectively) are analyzed for all phases of raw material production, manufacturing, use of products, recycling, and disposal. This LC perspective {{as well as the}} reference to the so-called <b>functional</b> <b>unit</b> (<b>fU)</b> distinguishes LCA and LCC from other existing environmental and economic assessment methods. The fU is the “quantified” function, which serves as reference unit for calculations and allows for assessing alternative products and services by assigning them the same function (ISO 2006 a, b; Hunkeler et al. 2008; Swarr et al. 2011).|$|E
40|$|Abstract — As {{the feature}} size of {{transistors}} becomes smaller, delay variations become {{a serious problem}} in VLSI design. In many cases, the hold constraint, {{as well as the}} setup constraint, becomes critical for latching a correct signal under delay variations. One approach to ensure the hold constraint under delay variations is to enlarge the minimum-path delay between registers, which is called minimum-path delay compensation (MDC) in this paper. MDC can be done by inserting delay elements mainly in non-critical paths of a <b>functional</b> <b>unit</b> (<b>FU).</b> This paper is the first attempt to discuss an optimization problem to minimize the number of FUs which require MDC in datapath synthesis. One of our contributions is to show that the problem is NP-hard in general, and it is in the class P if the number of FUs is a constant. In addition, a polynomial time algorithm for the latter is another contribution. The proposed method generates a datapath having (1) robustness against delay variations, which is ensured partly by MDC technique and partly b...|$|E
40|$|Abstract- We propose an {{integrated}} architectural/physicalplanning approach named priority assignment optimization {{to minimize the}} current surge in high performance power efficient clock-gated microprocessors. The proposed approach balances the current demands across the floorplan by assigning optimized priorities to the <b>functional</b> <b>units</b> (<b>FUs).</b> Two complementary methods – physical planning with soft modules and issue pattern management – to enhance our proposed approach are also discussed for various applications. Experimental {{results show that the}} proposed approach reduces the peak noise by 11. 75 % and consequently, the decoupling capacitance (Decap) requirement by 24. 22 % without any degradation in IPC (Instruction Per Cycle). We also show that our approach does not increase the clock period for the 0. 18 µm technology and beyond...|$|R
40|$|GPU {{acceleration}} of compute-intensive applications {{has emerged as}} a new research frontier with phenomenal success- rates. Such applications are characterized by large data-sets being processed by singular <b>functional</b> <b>units</b> (<b>FUs)</b> often described as SIMD (Single Instruction Multiple Data) computing. Moreover, with the proliferation of internet and its easy access on myriad devices, has resulted in huge amount of data generation. Initially, such data was considered disconnected and not related. But with the advent of semantic web, data {{has been found to be}} highly co- related and relevant. Organizing such huge amount of data and subsequently processing requires parallel processing framework that is both distributed and scalable. Graphical processing units (GPUs) are being actively probed in the domain of Big Data analysis, machine learning, and augmente...|$|R
40|$|In {{order to}} meet the high {{throughput}} requirements of applications exhibiting high ILP, VLIW ASIPs may increasingly include large numbers of <b>functional</b> <b>units</b> (<b>FUs).</b> Unfortunately, `switching' data through register files shared by large numbers of FUs quickly becomes a dominant cost/performance factor suggesting that clustering smaller number of FUs around local register files may be beneficial even if data transfers are required among clusters. With such machines in mind, we propose a compiler transformation, predicated switching, which enables aggressive speculation while leveraging the penalties associated with inter-cluster communication to achieve gains in performance. Based on representative benchmarks, we demonstrate that this novel technique is particularly suitable for application specific clustered machines aimed at supporting high ILP as compared to state-of-the-art approaches...|$|R
40|$|As {{the feature}} size of {{transistors}} becomes smaller, delay variations become {{a serious problem}} in VLSI design. In many cases, the hold constraint, {{as well as the}} setup constraint, becomes critical for latching a correct signal under delay variations. One approach to ensure the hold constraint under delay variations is to enlarge the minimum-path delay between registers, which is called minimum-path delay compensation (MDC) in this paper. MDC can be done by inserting delay elements mainly in non-critical paths of a <b>functional</b> <b>unit</b> (<b>FU).</b> This paper is the first attempt to discuss an optimization problem to minimize the number of Fus which require MDC in datapath synthesis. One of our contributions is to show that the problem is NP-hard in general, and it is in the class P if the number of Fus is a constant. In addition, a polynomial time algorithm for the latter is another contribution. The proposed method generates a datapath having (1) robustness against delay variations, which is ensured partly by MDC technique and partly by SRV-based register assignment, and (2) the minimum possible numbers of MDCs and registers...|$|E
40|$|Glycopeptides, {{isolated}} from a trypsinolysate of <b>functional</b> <b>unit</b> (<b>FU)</b> RtH 2 -e of Rapana thomasiana hemocyanin subunit 2, were analysed by electrospray ionization mass spectrometry and MS/MS. From the molecular mass observed after deglycosylation, it was inferred that all glycopeptides {{shared the same}} peptide stretch 92 143 of FU RtH 2 - 3 with a glycosylation site at Asn- 127. Besides the core structure Man(3) GlcNAc(2) for N-glycosylation, structures with a supplementary GlcNAc linked to either the Man(α 1 3) or the Man(α 1 6) arm and/or an additional tetrasaccharide unit connected to the other Man arm were observed. indicating the existence of microheterogeneity at the glycan level. The tetrasaccharide unit contains a central fucose moiety substituted with 3 -O-rnethylgalactose and N-acetylgalactosamine. and linked to GlcNAc at the reducing end. This structure represents a novel N-glycan motif {{and is likely to}} be immunogenic. A second potential site for N-glycosylation in FU RtH 2 -e at Asn- 17 was shown to be not glycosylated. © 2005 Elsevier Inc. All rights reserved. status: publishe...|$|E
40|$|Switching {{activity}} and schedule length {{are the two}} of the most important factors in power dissipation. This paper studies the scheduling problem that minimises both schedule length and switching activities for applications with loops on multiple functional unit architectures. We show that, to find a schedule that has the minimal switching activities among all minimum latency schedules with or without resource constraints is NP-complete. Although the minimum latency scheduling problem is polynomial time solvable if there is no resource constraint or only one <b>functional</b> <b>unit</b> (<b>FU),</b> the problem becomes NP-complete when switching activities are considered as the second constraint. An algorithm, Power Reduction Rotation Scheduling (PRRS), is proposed. The algorithm attempts to minimise both switching activities and schedule length while performing scheduling and allocation simultaneously. Compared with the list scheduling, PRRS shows an average of 20. 1 % reduction in schedule length and 52. 2 % reduction in bus switching activities. Our algorithm also shows better performance than the approach that considers scheduling and allocation in separate phases. Department of Computin...|$|E
40|$|AbstractTo technologically {{achieve the}} {{transformation}} from functional requirements (FRs) to design parameters (DPs) in the axiomatic design (AD) theory, this paper employed the basic hypothesis, definitions and model developed in PART 1 {{of our study}} to establish an algorithm for <b>functional</b> <b>unit</b> chain set (FUCS) generation. This algorithm is established on two mappings from the developed conceptual foundation to the graph theory, i. e. treating <b>functional</b> <b>units</b> (<b>FUs)</b> as nodes, and treating connections between FUs as edges. With this two mappings, a graph consisting of FUs can be created, which is called the <b>functional</b> <b>unit</b> graph (FUG). Based on the depth-first search (DFS) strategy in the graph theory, the algorithm generating FUCSs from the FUG was finally established. As an additional function, a preliminary evaluation for the generated FUCSs was also proposed. To prove the feasibility of this algorithm, a solar-powered wiper blades, and the load module of a friction-abrasion testing machine were designed as illustrations...|$|R
40|$|In recent years, LDPC {{codes are}} gaining {{a lot of}} {{attention}} among researchers. Its near-Shannon performance combined with its highly parallel architecture and lesser complexity compared to Turbo-codes has made LDPC codes {{one of the most popular}} forward error correction (FEC) codes in most of the recently ratified wireless communication standards. This thesis focuses on one of these standards, namely the DVB-S 2 standard that was ratified in 2005. In this thesis, the design and architecture of a FPGA implementation of an LDPC decoder for the DVB-S 2 standard are presented. The decoder architecture is an improvement over others that are published in the current literature. Novel algorithms are devised to use a memory mapping scheme that allows for 360 <b>functional</b> <b>units</b> (<b>FUs)</b> used in decoding to be implemented using the Sum-Product Algorithm (SPA). The <b>functional</b> <b>units</b> (<b>FU)</b> are optimized for reduced hardware resource utilization on a FPGA with a large number of configurable logic blocks (CLBs) and memory blocks. A novel design of a parity-check module (PCM) is presented that verifies the parity-check equations of the LDPC codes. Furthermore, a special characteristic of five of the codes defined in the DVB-S 2 standard and their influence on the decoder design is discussed. Three versions of the LDPC decoder are implemented, namely the 360 -FU decoder, the 180 -FU decoder and the hybrid 360 / 180 -FU decoder. The decoders are synthesized for two FPGAs. A Xilinx Virtex-II Pro family FPGA is used for comparison purposes and a Xilinx Virtex- 6 family FPGA is used to demonstrate the portability of the design. The synthesis results show that the hardware resource utilization and minimum throughput of the decoders presented are competitive with a DVB-S 2 LDPC decoder found in the current literature that also uses FPGA technology...|$|R
40|$|Energy {{optimization}} is {{very important}} for portable and battery-driven embedded systems. With the shrinking of transistor sizes, reducing leakage power becomes a significant issue. In this paper, we propose a novel prediction approach to predict idleness of <b>functional</b> <b>units</b> for leakage energy management. Using a state-based predictor, historical utilization information of <b>functional</b> <b>units</b> (<b>FUs)</b> is exploited to adjust the state of the predictor so as to enhance the accuracy of prediction; based on it, the idleness of the FUs are predicted and utilized for leakage reduction by applying power gating. We design two prediction algorithms, the prediction with fixed threshold (PFT) and the prediction with dynamic threshold (PDT), respectively. We implement our algorithms based on SimpleScalar and conduct experiments with a suite of fourteen benchmarks from Trimaran. The experimental results show that our algorithms achieve better results compared with the previous work. Department of Computin...|$|R
40|$|Abstract—In this paper, {{we propose}} an {{integrated}} architectural and physical planning approach {{to minimize the}} current surge in high-performance clock-gated microprocessors. In our approach, we use priority assignment optimization (PAO) and dynamic <b>functional</b> <b>unit</b> (<b>FU)</b> selection (DFS) to balance current demand in the floorplan. Two complementary methods—FU ordering with submodule design and issue pattern management—are also proposed to enhance the above techniques. Experimental results show that at the 0. 18 - m technology node, the PAO can reduce the peak noise by 11. 75 % and consequently, the decoupling capacitance (Decap) requirement by 24. 22 % without any degradation in instructions per cycle (IPC). Moreover, an enhanced DFS reduces the peak noise by 13. 39 % as well as Decap requirement by 29. 58 %. Experiments at the 90 -nm technology node show that our methodology can further reduce the peak noise and the Decap requirement by 16. 57 % and 44. 85 % with PAO, or 18. 16 % and 47. 58 % with DFS. We also show that our approach does not increase the clock period for 0. 18 - m technology and beyond. Index Terms—Circuit reliability, computer architecture, integrated circuit noise, power demand...|$|E
40|$|Abstract: In {{this paper}} {{we present a}} novel {{approach}} to synthesizing polymorphic hardware from functional-level Object-Oriented (OO) models. Our proposed target architecture {{is intended to be}} subsequently used in co-design of hardware and software from a single OO source model, and hence, in order to be consistent with software compilers uses a global memory to store the objects data. The target architecture enables inheritance and polymorphism; it consists of a method-invocation unit (MIU), a <b>functional</b> <b>unit</b> (<b>FU)</b> per class method, and an object-management unit (OMU). The MIU, FU, and OMU functionalities are presented, along with the details of modeling and synthesis of a traffic-light controller to demonstrate the concepts and approach. Moreover, experimental results of modeling and implementing some case studies are presented and analyzed. Synthesis results show some area overhead compared to traditional methodologies; however, we show that this overhead is constant for all applications having the same class hierarchy and moreover is independent of the number of objects in the system. Therefore this overhead is ignorable, or even not present, for large designs or designs with several objects where OO shows its best. Key-Words: hardware synthesis, object-oriented synthesis, synthesis of polymorphism, hardware/software co-design, functional-level object-oriented modelin...|$|E
40|$|During last decades, {{a lot of}} {{research}} has been aimed at mechanical characteristics improvements of materials and roads pavements, taking into account traffic requirements and service time for the initial construction. Besides, environmental impacts linked to roads are still seen today throughout regulation and focused on the use phase. Regulation imposes environmental impact studies (EIE) mainly in relation with nature and people protection. Then, studies are performed before roads construction, mainly devoted on roads location and on local effects of roads exploitation. On the other hand, since the 90 ’s, Life Cycle Analysis (LCA) has been considered by road civil engineers and public institutions workers as a possible way to improve road design at the international level. Life Cycle Analysis is a standardized environmental assessment method, which has been developed for products manufacturing improvement by USA chemical industries (SETAC). LCA proved to be well adapted for large numbers of manufactured products. It requires the use of a <b>functional</b> <b>unit</b> (<b>FU)</b> that accurately defines the product properties and functionalities to consider for a given service time. Moreover, it gives a relative assessment using a reference case, which has to be defined for each study...|$|E
30|$|The use of {{scalable}} parallelism {{to obtain}} chips with small areas for DVB-S 2 {{has been proposed}} for technologies ranging from 0.13 µ m down to 65 nm [5 – 7, 15, 16] based on the processing of sub-sets of the Tanner graph, which guarantee the minimum necessary throughput of 90 Mbps required by the standard [8]. The design of partial-parallel solutions generates systems with lower areas, but also implies lower throughputs, comparing to full-parallel architectures in a SoC. One of the architectures initially proposed by Kienle et al. [5] uses M = 360 processor nodes, also referred in this text as <b>Functional</b> <b>Units</b> (<b>FU).</b> They work in parallel and share control signals, that process both CN nodes (in CN mode) and IN nodes (in BN mode) according to a flooding schedule approach.|$|R
40|$|In this paper, a novel {{algorithm}} is proposed for assigning supply voltages to serially executing <b>functional</b> <b>units</b> (<b>FUs)</b> in a digital system such that the overall dynamic energy consumption is minimized for a given timing constraint. Novel closed form expressions for optimum supply voltage values are presented. The computation time of the {{algorithm is}} O(N) for N FUs in series. An extension of the O(N) {{algorithm is proposed}} for optimizing the acyclic data flow graph associated with any given task. Given the number of FUs available for the task, the operations required for the task are scheduled on the FUs. Voltages are then assigned to the FUs on each path of the flow graph using the O(N) algorithm. Energy savings of 10 - 60 % are achieved on DSP filter designs using the proposed high-level optimization methodology over single supply voltage designs. 1...|$|R
40|$|In {{real-time}} {{digital signal}} processing (DSP) architectures using heterogeneous <b>functional</b> <b>units</b> (<b>FUs),</b> {{it is critical to}} select the best FU for each task. However, some tasks may not have ﬁxed execution times. This paper models each var ied execution time as a probabilistic random variable and solves heterogeneous assignment with probability (HAP) problem. The solutions to the HAP problem are useful for both hard real time and soft real time systems. We propose optimal algorithms for the HAP problem when the input is a tree or a simple path. The experiments show that our algorithms can effectively obtain the optimal solutions to simple paths and trees. For example, with our algorithms, we can obtain an average reduction of 32. 5 % on total cost with 90 % conﬁdence probability compared with the previ ous work using worst-case scenario. Department of ComputingRefereed conference pape...|$|R
