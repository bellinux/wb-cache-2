718|1276|Public
25|$|The baby-step giant-step {{algorithm}} is a <b>generic</b> <b>algorithm.</b> It works for every finite cyclic group.|$|E
25|$|When the {{bottleneck}} is localized, optimization usually {{starts with}} a rethinking of the algorithm used in the program. More often than not, a particular algorithm can be specifically tailored to a particular problem, yielding better performance than a <b>generic</b> <b>algorithm.</b> For example, the task of sorting a huge list of items is usually done with a quicksort routine, {{which is one of}} the most efficient generic algorithms. But if some characteristic of the items is exploitable (for example, they are already arranged in some particular order), a different method can be used, or even a custom-made sort routine.|$|E
50|$|The Great Deluge {{algorithm}} (GD) is a <b>generic</b> <b>algorithm</b> {{applied to}} optimization problems. It {{is similar in}} many ways to the hill-climbing and simulated annealing algorithms.|$|E
40|$|<b>Generic</b> <b>{{algorithms}}</b> are algorithms using abstract data types. Multiple <b>generic</b> <b>algorithms</b> can {{be linked}} together in a directed acyclic graph (generic DAG) so that more complex <b>generic</b> <b>algorithms</b> can be formed. Views describe relationships between dierent data types. By compilation, specialized <b>generic</b> <b>algorithms</b> can be created from the generic DAGs. Views allow the specialized algorithm to manipulate actual data types used by the current applications instead of the abstract data types. This specialization process allows the <b>generic</b> DAG <b>algorithms</b> to work on dierent object descriptions of the same abstract data type, thus achieving greater software reuse...|$|R
40|$|<b>Generic</b> <b>{{algorithms}}</b> are algorithms {{designed to}} work with a variety of data structures. A software library in which most <b>algorithms</b> are <b>generic</b> can thus provide very extensive capabilities with a relatively small amount of source code. The high initial cost of applying formal methods to generic components becomes reasonable when amortized over the many different uses that can later be made. This paper is an attempt to provide a foundation for formal specification and verification of <b>generic</b> <b>algorithms,</b> paying particular attention to supporting the techniques by which generality is achieved in the C++ Standard Template Library. Axioms and inference rules are presented that support reasoning about essentially all the C++ language features and STL programming techniques used in the library's <b>generic</b> <b>algorithms.</b> Examples of applications to several simple STL <b>generic</b> <b>algorithms</b> are given. Categories and Subject Descriptors: D. 2. 2. [Software Engineering]: Tools and Techniques [...] -software librar [...] ...|$|R
40|$|It is {{well-known}} that data abstractions {{are crucial to}} good software engineering practice. We argue that algorithmic abstractions, or <b>generic</b> <b>algorithms,</b> are perhaps even more important for software reusabil-i ty. <b>Generic</b> <b>algorithms</b> are parameterized procedural schemata that are completely independent of the un-derlying data representation and are derived from con-crete, efficient algorithms. We discuss this notion with illustrations from the structure of an Ada library of reusable software components we are presently devel-oping. ...|$|R
5000|$|Traditionally, {{instead of}} using the wedge product, Cramer's rule is usually {{presented}} as a <b>generic</b> <b>algorithm</b> {{that can be used}} to solve linear equations of the form [...] (or equivalently to invert a matrix). Namely ...|$|E
5000|$|One of {{the main}} uses of the generic group model is to analyse {{computational}} hardness assumptions. An analysis in the generic group model can answer the question: [...] "What is the fastest <b>generic</b> <b>algorithm</b> for breaking a cryptographic hardness assumption". A <b>generic</b> <b>algorithm</b> is an algorithm that only makes use of the group operation, and does not consider the encoding of the group. This question was answered for the discrete logarithm problem by Victor Shoup using the generic group model. Other results in the generic group model are for instance. The model can also be extended to other algebraic structures, such as, e.g., rings.|$|E
50|$|Bursztein's {{research}} on CAPTCHAs aims {{to make the}} puzzles easier for humans to solve and harder for computers to crack. His main contributions are an easier captcha for Human used by Recaptcha and a <b>generic</b> <b>algorithm</b> to break text-based captcha.|$|E
5000|$|... lack of compile-time {{generics}} {{leads to}} code duplication, metaprogramming cannot be statically checked {{and the standard}} library cannot offer <b>generic</b> <b>algorithms</b> ...|$|R
40|$|Abstract In this paper, {{we present}} <b>generic</b> <b>algorithms</b> {{to ensure the}} {{consistency}} of mutual-exclusion and binding constraints in a business process context. We repeatedly identified {{the need for such}} <b>generic</b> <b>algorithms</b> in our real-world projects. Thus, the algorithms are a result of the experiences we gained in analyzing, designing, and implementing a number of corresponding software systems and tools. In particular, these algorithms check corresponding consistency requirements to prevent constraint conflicts and to ensure the design-time and runtime compliance of a process-related role-based access control (RBAC) model. ...|$|R
40|$|We {{continue}} the recent {{line of research}} studying information dissemination problems in adversarial dynamic radio networks. We give two <b>generic</b> <b>algorithms</b> which allow to transform generalized version of single-message broadcast algorithms into multi-message broadcast algorithms. Based on these <b>generic</b> <b>algorithms,</b> we obtain multi-message broadcast algorithms for dynamic radio networks {{for a number of}} different dynamic network settings. For one of the modeling assumptions, our algorithms are complemented by a lower bound which shows that the upper bound is close to optimal. Comment: appears in ALGOSENSORS 201...|$|R
50|$|Multi-objective {{optimization}} {{has been}} increasingly employed in chemical engineering. In 2009, Fiandaca and Fraga used the multi-objective <b>generic</b> <b>algorithm</b> (MOGA {{to optimize the}} pressure swing adsorption process (cyclic separation process). The design problem involved the dual maximization of nitrogen recovery and nitrogen purity. The results provided a good approximation of the Pareto frontier with acceptable trade-offs between the objectives.|$|E
5000|$|With CO {{the desired}} {{serializability}} property {{is achieved by}} committing transactions only in chronological order that {{is compatible with the}} precedence order (as determined by chronological orders of operations in conflicts) of the respective transactions. To enforce CO some implementation of the Generic local CO algorithm needs to be utilized. The patent abstract quoted above describes a general implementation of the algorithm with a pre-determined commit order (this falls into the category of [...] "CO <b>generic</b> <b>algorithm</b> with real-time constraints").|$|E
5000|$|The push-relabel {{algorithm}} {{is considered one}} of the most efficient maximum flow algorithms. The <b>generic</b> <b>algorithm</b> has a strongly polynomial [...] time complexity, which is asymptotically more efficient than the [...] Edmonds-Karp algorithm. Specific variants of the algorithms achieve even lower time complexities. The variant based on the highest label node selection rule has [...] time complexity and is generally regarded as the benchmark for maximum flow algorithms. Subcubic [...] time complexity can be achieved using dynamic trees, although in practice it is less efficient.|$|E
40|$|Abstract. The {{study of}} energy landscapes of biopolymers and their models is an {{important}} field in bioinformatics [1 – 6]. For instance the investigation of kinetics or folding simulations are done using methods {{that are based on}} sampling or exhaustive enumeration [7 – 11]. Most of such algorithms are independent of the underlying landscape model. Therefore frameworks for <b>generic</b> <b>algorithms</b> to investigate the landscape properties is needed. Here, we present the Energy Landscape Library (ELL) that allows such a model-independent formulation of <b>generic</b> <b>algorithms</b> dealing with discrete states. The ELL is a completely object-oriented C++ library that is highly modular, easy to extend, and freely available online. It can be used for a fast and easy implementation of new <b>generic</b> <b>algorithms</b> (possibly based on the provided basic method pool) or as a framework to test their properties for different landscape models, which can be formulated straightforward. ...|$|R
40|$|STL {{addresses}} {{several problems}} with previous C++ container libraries {{in a new}} and innovative way. The basic tenents of STL are: Flexibility The use of <b>generic</b> <b>algorithms</b> allows algorithms to be applied to many different structures. STL's <b>generic</b> <b>algorithms</b> work on native C++ data structures such as strings and vectors. Efficiency STL containers are very close to the efficiency of handcoded, type-specific containers. Easy-to-learn structure The library is quite small owing to the high degree of genericity. Theoretical foundation The library bases its theoretical foundation a "semiformal" specification of the library components...|$|R
40|$|Dynamic {{verification}} is a {{new approach}} to formal verification, applicable to <b>generic</b> <b>algorithms</b> such as those found in the Standard Template Library (STL, part of the Draft ANSI/ISO C++ Standard Library). Using behavioral abstraction and symbolic execution techniques, verifications are carried out at a meta-level such that the results {{can be used in a}} variety of instances of the <b>generic</b> <b>algorithms</b> without repeating the proofs. This is achieved by substituting for type parameters of <b>generic</b> <b>algorithms</b> special data types that model generic concepts by accepting symbolic inputs and deducing outputs using inference methods. By itself, this symbolic execution technique supports testing of programs with symbolic values at a meta-level. For formal verification we also need to generate multiple program execution paths and use assertions (to handle while loops, for example), but we show how this can be achieved via directives to a conventional debugger program and an analysis database. The asse [...] ...|$|R
5000|$|The philosopher of mind Daniel Dennett, in his 1995 book Darwin's Dangerous Idea, {{developed}} {{the idea of}} a Darwinian process, involving variation, selection and retention, as a <b>generic</b> <b>algorithm</b> that is substrate-neutral and could be applied to many fields of knowledge outside of biology. He described the idea of natural selection as a [...] "universal acid" [...] that cannot be contained in any vessel, as it seeps through the walls and spreads ever further, touching and transforming ever more domains. He notes in particular the field of memetics in the social sciences.|$|E
5000|$|Next, the {{identification}} of genomic regions with open chromatin, is done by using a peak calling algorithm. Different tools offer packages to do this, like ChIPOTle ZINBA and MACS2 [...] ). ChIPOTle uses a sliding window of 300bp to identify statistically significant signals. In contrast, MACS2 identifies the enriched signal by combining the parameter callpeak with other options like 'broad', 'broad cutoff', 'no model' or 'shift'. ZINBA is a <b>generic</b> <b>algorithm</b> for detection of enrichment in short read dataset. It thus helps in the accurate detection of signal in complex datasets having low signal-to noise ratio.|$|E
50|$|When the {{bottleneck}} is localized, optimization usually {{starts with}} a rethinking of the algorithm used in the program. More often than not, a particular algorithm can be specifically tailored to a particular problem, yielding better performance than a <b>generic</b> <b>algorithm.</b> For example, the task of sorting a huge list of items is usually done with a quicksort routine, {{which is one of}} the most efficient generic algorithms. But if some characteristic of the items is exploitable (for example, they are already arranged in some particular order), a different method can be used, or even a custom-made sort routine.|$|E
40|$|Although generic {{programming}} founds {{more and}} more attention [...] nowadays generic programming languages as well as generic libraries exist [...] there are hardly approaches for the verification of <b>generic</b> <b>algorithms</b> or <b>generic</b> libraries. This thesis deals with <b>generic</b> <b>algorithms</b> {{in the field of}} computer algebra. We propose the Mizar system as a theorem prover capable of verifying <b>generic</b> <b>algorithms</b> on an appropriate abstract level. The main advantage of the Mizar theorem prover is its special input language that enables textbook style presentation of proofs. For generic versions of Brown/Henrici addition and of Euclidan's algorithm we give complete correctness proofs written in the Mizar language. Moreover, we do not only prove algorithms correct in the usual sense. In addition we show how to check, using the Mizar system, that a <b>generic</b> algebraic <b>algorithm</b> is correctly instantiated with a particular domain. Answering this question that especially arises if one wants to implement generic programming languages, in the field of computer algebra requires non trival mathematical knowledge. To build a verification system using the Mizar theorem prover, we also implemented a generator which almost automatically computes for a given algorithm a set of theorems that imply the correctness of this algorithm...|$|R
50|$|Copy and pasting is {{also done}} by {{experienced}} programmers, who often {{have their own}} libraries of well tested, ready-to-use code snippets and <b>generic</b> <b>algorithms</b> that are easily adapted to specific tasks.|$|R
3000|$|... [...]. These {{potential}} {{solutions are}} {{tested in the}} line 5 of Algorithm 2. As such, Algorithm 2 still involves some exhaustive search and can clearly not solve ECDLP faster than <b>generic</b> <b>algorithms.</b>|$|R
5000|$|Adherents {{of object}} {{oriented}} methodologies further {{object to the}} [...] "code library" [...] use of copy and paste. Instead of making multiple mutated copies of a <b>generic</b> <b>algorithm,</b> an object oriented approach would abstract the algorithm into a reusable encapsulated class. The class is written flexibly, with full support of inheritance and overloading, so that all calling code can be interfaced to use this generic code directly, rather than mutating the original. As additional functionality is required, the library is extended (while retaining backward compatibility). This way, if the original algorithm has a bug to fix or can be improved, all software using it stands to benefit.|$|E
50|$|The {{development}} on Hopsan first began in 1977 at the Division of Hydraulics and Pneumatics at Linköping University. The first version {{was written in}} FORTRAN, with a drag-and-drop graphical user interface written in Visual Basic. In addition to the simulation capability it also had features for simulation based optimization. This used the COMPLEX direct search optimization method or a <b>generic</b> <b>algorithm</b> (GA). It also had features for frequency analysis and transfer function analysis, on simulated results. It also supported co-simulation under Simulink. Component models were written as FORTRAN subroutines. A separate tool called COMPGEN, written in Mathematica,was also developed, {{which can be used}} to generate component models in a more straightforward way. In 1991 the method of bi-directional delay lines (or transmission line modelling TLM) was introduced for system simulation.|$|E
5000|$|The <b>generic</b> <b>algorithm</b> for image {{segmentation}} using MAP is given below: 1. Define {{the neighborhood of}} each feature (random variable in MRF terms). Generally this includes 1st order or 2nd order neighbors. 2. Set initial probabilities i for each feature as 0 or 1, where i is the set containing features extracted for pixel [...] and define an initial set of clusters. 3. Using the training data compute the mean (li) and variance (li) for each label. This is termed as class statistics. 4. Compute the marginal distribution for the given labeling scheme ii using Bayes' theorem and the class statistics calculated earlier. A Gaussian model {{is used for the}} marginal distribution. [...] 5. Calculate the probability of each class label given the neighborhood defined previously. Clique potentials are used to model the social impact in labeling. 6. Iterate over new prior probabilities and redefine clusters such that these probabilities are maximized. This is done using a variety of optimization algorithms described below. 7. Stop when probability is maximized and labeling scheme does not change. The calculations can be implemented in log likelihood terms as well.|$|E
40|$|Generic {{programming}} {{has recently}} {{emerged as a}} paradigm for developing highly reusable software libraries, most notably in C++. We have designed and implemented a constrained generics extension for C++ to support modular type checking of <b>generic</b> <b>algorithms</b> and to address other issues associated with unconstrained generics. To be as broadly applicable as possible, <b>generic</b> <b>algorithms</b> are defined with minimal requirements on their inputs. At the same time, to achieve {{a high degree of}} efficiency, <b>generic</b> <b>algorithms</b> may have multiple implementations that exploit features of specific classes of inputs. This process of algorithm specialization relies on non-local type information and conflicts directly with the local nature of modular type checking. In this paper, we review the design and implementation of our extensions for generic programming in C++, describe the issues of algorithm specialization and modular type checking in detail, and discuss the important design tradeoffs in trying to accomplish both. We present the particular design that we chose for our implementation, with the goal of hitting the sweet spot in this interesting design space...|$|R
40|$|Generic {{programming}} {{centers around}} the idea of abstracting from concrete ef cient <b>algorithms</b> to obtain <b>generic</b> <b>algorithms</b> that can be combined with dierent data representations to produce {{a wide variety of}} useful software For example a class of <b>generic</b> sorting <b>algorithms</b> can be dened which work with nite sequences but which can be instantiated in dierent ways to produce algorithms working on arrays or linked lists Four kinds of abstractiondata algorithmic structural and representational are discussed with examples of their use in building an Ada library of software components The main topic discussed is <b>generic</b> <b>algorithms</b> and an approach to their formal specication and verication with illustration in terms of a partitioning algorithm such as is used in the quicksort algorithm It is argued that generically programmed software component libraries oer important advantages for achieving software productivity and reliabilit...|$|R
50|$|The STL {{was created}} {{as the first}} library of <b>generic</b> <b>algorithms</b> and data {{structures}} for C++, with four ideas in mind: generic programming, abstractness without loss of efficiency, the Von Neumann computation model, and value semantics.|$|R
40|$|Abstract. Subscription {{propagation}} enables efficient content-based routing in publish/subscribe {{systems and}} is a challenging problem when it is required to support reliable delivery in networks with redundant routes. We have designed a generic model and a highly-asynchronous algorithm accomplishing these goals. Existing algorithms can be inter-preted as different encodings and optimizations of the <b>generic</b> <b>algorithm</b> and hence their correctness {{can be derived from}} the <b>generic</b> <b>algorithm.</b> ...|$|E
40|$|World Congress on Neural NetworksWe {{simulated}} an {{associative memory}} with mutually connected neural network, and successfully {{made the connection}} matrix learn some binary patterns only by means of <b>generic</b> <b>algorithm.</b> Although the memory capacity is about 12 % {{of the number of}} neurons, {{the fact that it was}} made without any learning algorithm like Hebbian rule is very interesting. The structure of connection matrics we obtained is quite different from that of Hopfield network. Our overall goal for this research is two fold. One is to know if we can use <b>generic</b> <b>algorithm</b> as a more effective learning method than that proposed so far, and another is to understand this learning mechanism of <b>generic</b> <b>algorithm...</b>|$|E
40|$|AbstractWe {{present a}} <b>generic</b> <b>algorithm</b> that {{provides}} a unifying scheme for the comparison of abstraction refinement algorithms. It is centered around the notion of refinement cue which generalizes counterexamples. It is demonstrated how the essential features of several refinement algorithms can be captured as instances. We argue that the <b>generic</b> <b>algorithm</b> does not limit the completeness of instances, and show that the proposed generalization of counterexamples is necessary for completeness — thus addressing a shortcoming of more limited notions of counterexample-guided refinement...|$|E
5000|$|He {{has proved}} (while at IBM Zurich) a lower {{bound to the}} {{computational}} complexity of <b>generic</b> <b>algorithms</b> for solving the discrete logarithm problem, a problem in group theory which is of considerable importance to public-key cryptography.|$|R
40|$|This paper {{presents}} a methodology for solving interdependent, multidomain networks with <b>generic</b> <b>algorithms.</b> The methodology enables modelling of very large systems. <b>Generic</b> <b>algorithms</b> enable the system solver {{to be written}} such that it is independent of the system type. The solution of the system equations is implemented with Graph Trace Analysis (GTA), where traces through the directed graph of the system are implemented with iterators. The solution technique incorporates a binary search algorithm for the solution of looped systems. Example electrical and fluid systems are solved. graph trace analysis; GTA; distributed processing; generic algorithms; critical infrastructures; interdependent multidomain networks; binary search algorithms; looped systems; electrical systems; fluid systems...|$|R
40|$|In a first phase, {{this talk}} {{presents}} {{an extension of}} the framework for classifying global constraints that was introduced in 2000. This is concretely illustrated by showing how constraints like alldifferent, cumulative, cutset, cycle, diffn, element, global cardinality, lexicographic ordering, soft alldifferent, or stretch fit into this framework. In a second phase, this talk motivates the need for <b>generic</b> filtering <b>algorithms</b> from different viewpoints. Finally it gives some preliminary hints of how such <b>generic</b> <b>algorithms</b> could be developed...|$|R
