15|62|Public
40|$|Long {{instrumental}} climate records {{suffer from}} inhomogeneities due to, e. g., relocations of the stations or changes in instrumentation, which may introduce sudden {{jumps into the}} time series. These inhomogeneities may mask or strengthen true trends. Relative homogenization algorithms use the difference time series of a candidate station with neighboring stations to identify such breaks (changepoints). Modern multiple breakpoint methods search for the optimum segmentation, which is characterized by minimum <b>internal</b> <b>variance</b> within the segments and maximum external variance between the segment means. We analyze the accuracy of these homogenization methods and concentrate on the uncertainty {{in the position of}} the break. Due to unavoidable random noise in the difference time series, the segmentation method may find a shifted break position, which attains a higher external variance than the true one. Different lengths of potentially exchanged subsegments are considered; that one providing the largest external variance will be chosen as possibly erroneous optimum. We will show that the variances of shifted segmentations can be described as Brownian motion with drift, where the signal-to-noise ratio (SNR) defines the drift size. Available formulae for one-sided and continuous Brownian motion with drift are expanded to two-sided and discrete processes as they occur in praxis. The error probability increases strongly for SNRs lower than 1. Thus when the <b>internal</b> <b>variance</b> is larger than the variance introduced by the breaks, the probability of finding the right break position is small...|$|E
40|$|This paper {{describes}} an automated image segmentation technique that subdivides regions of homogeneous texture. The method utilizes a level set analysis of scaled Gabor filter responses. Scaling is achieved via an area morphological process. Each scaled, filtered image is examined to locate important connected components based on minimal. total <b>internal</b> <b>variance</b> and maximal edge localization. The candidate segments are selected using a granulometry of the gradient magnitude evaluated {{at the level}} lines of the connected. components. The level,set analysis avoids the high computational cost associated with conventional level set approaches by sampling only the significant level sets for processing. The target application for this segmentation technique is content based image retrieval...|$|E
40|$|A {{method of}} {{separating}} the contributions from slowly varying boundary forcing and internal dynamics (e. g. intraseasonal oscillations) that determine the predictability {{of the monthly}} mean tropical climate is presented. Based on 33 years of daily low level wind observations and 24 years of satellite observations of outgoing long wave radiation,we show that the Indian monsoon climate is only marginally predictable,as {{the contribution of the}} boundary forcing in this region is relatively low and that of the internal dynamics is relatively large. It is also shown that excluding the Indian monsoon region,the redictable region is larger and predictability is higher in the tropics during northern summer. Even though the boundary forced variance is large during northernwinter,the predictable region is smaller as the <b>internal</b> <b>variance</b> is larger and covers a larger region during that period (due to stronger intraseasonal activity) ...|$|E
40|$|This thesis explores how postcolonial critics {{figure the}} {{centrality}} of imperialism to the cultures and socio-politics of those societies at the hegemonic apex of today’s geopolitical hierarchy. I begin by addressing the discipline’s homogenisation of ‘the West’, which I attribute to a totalist articulation of the category, whether as a geopolitical agency, a geojuridical bloc, a polity, an identity, or a central ideologeme within colonial discourse and contemporary imperialist ideology. I argue that this totalisation elides variances of consciousness, purpose, and practice that cut across whatever unity obtains within and among the constituent societies of the ‘geopolitical West’. I then look to the thought of Antonio Gramsci, Raymond Williams, Claude Lefort, Ernesto Laclau and Chantal Mouffe, and Jacques Rancière for a way of understanding that unity {{in light of these}} <b>internal</b> <b>variances.</b> Moreover, drawing on Rancière’s notion of ‘dis-identification’ and Gayatri Chakravorty Spivak’s of occupying ‘a position without identity’, I establish how if we are to challenge the hegemonic ascendancy of ‘Western’ imperialism, then we must acknowledge these variances. I then explore how literary representations of ‘Westerners’ by Jamaica Kincaid, V. S. Naipaul, Gil Courtemanche, Bret Easton Ellis, and Nadine Gordimer variously question the claim that anyone that benefits from contemporary imperialism cannot ever oppose it with integrity...|$|R
40|$|Abstract — A feature {{detection}} {{system has been}} developed for real-time identification of lines, circles and legs from laser data. A new method suitable for arc/circle detection is proposed: the <b>Internal</b> Angle <b>Variance</b> (IAV). Lines are detected using a recursive line fitting method. The people leg detection is based on geometrical constrains. The system was implemented as a fiducial driver in Player, a mobile robot server. Real results are presented to verify {{the effectiveness of the}} proposed algorithms in indoor environment with moving objects. Index Terms — Arc/circle detection, leg detection, laser {{feature detection}}, Player, mobile robot navigatio...|$|R
40|$|The present {{work has}} used recent {{processing}} techniques to classify vegetation patterns in Landsat 5 /TM images. The study area {{is located in}} a transition zone between the Amazonian Forest and Cerrado. The procedure consists in a preliminary evaluation of the scene materials and comprehends three steps: a) Conversion of TM digital numbers to exoatmospheric reflectance, b) use of a spectral grouping algorithm and c) end members identification. Three main groups were identified by the spectral grouping algorithm. They were mostly varied by photosynthetic and non-photosynthetic vegetation and biomass. The <b>internal</b> spectral <b>variance</b> of each group was evaluated by a specific index. This methodology enabled the evaluation of the main patterns of vegetation in the study area. Pages: 2679 - 268...|$|R
40|$|An {{improved}} {{model of}} scenes for image analysis purposes, a nested-hierarchical approach which explicitly acknowledges multiple scales of objects or categories of objects, is presented. A multiple-pass, region-based segmentation algorithm improves the segmentation of images from scenes better modeled as a nested hierarchy. A multiple-pass approach allows slow and careful growth of regions while interregion distances are below a global threshold. Past the global threshold, a minimum region size parameter forces development of regions {{in areas of}} high local variance. Maximum and viable region size parameters limit the development of undesirably large regions. Application of the segmentation algorithm for forest stand delineation in TM imagery yields regions corresponding to identifiable features in the landscape. The use of a local variance, adaptive-window texture channel in conjunction with spectral bands improves the ability to define regions corresponding to sparsely stocked forest stands which have high <b>internal</b> <b>variance...</b>|$|E
40|$|Multi-scale image {{segmentation}} produces high level object features {{at more than}} one level, compared to single scale segmentation. Objects generated from this type of segmentation hold additional attributes such as mean values per spectral band, distances to neighbouring objects, size, and texture, as well as shape characteristics. However, the accuracy of these high level features depends on the choice of segmentation scale parameters. Several studies have investigated techniques for scale parameter selection. These proposed approaches do not consider the different objects’ size variability found in complex scenes such as urban scene as they rely upon arbitrary object size measures, introducing instability errors when computing image variances. A technique to select optimal segmentation scale parameters based on image variance and spatial autocorrelation is presented in this paper. Optimal scales satisfy simultaneously the conditions of low object <b>internal</b> <b>variance</b> and high inter-segments spatial autocorrelation. Applied on three Cape Town urban scenes, the technique produced visually promising results that would improve object extraction over urban areas...|$|E
40|$|The Community Climate Model (CCM 3) {{from the}} National Center for Atmospheric Research (NCAR) {{is used to}} {{investigate}} {{the effect of the}} South Atlantic sea surface temperature (SST) anomalies on interannual to decadal variability of South American precipitation. Two ensembles composed of multidecadal simulations forced with monthly SST data from the Hadley Centre for the period 1949 to 2001 are analysed. A statistical treatment based on signal-to-noise ratio and Empirical Orthogonal Functions (EOF) is applied to the ensembles {{in order to reduce the}} internal variability among the integrations. The ensemble treatment shows a spatial and temporal dependence of reproducibility. High degree of reproducibility is found in the tropics while the extratropics is apparently less reproducible. Austral autumn (MAM) and spring (SON) precipitation appears to be more reproducible over the South America-South Atlantic region than the summer (DJF) and winter (JJA) rainfall. While the Inter-tropical Convergence Zone (ITCZ) region is dominated by external variance, the South Atlantic Convergence Zone (SACZ) over South America is predominantly determined by <b>internal</b> <b>variance,</b> which makes it a difficult phenomenon to predict. Alternatively, the SACZ over western South Atlantic appears to be more sensitive to the subtropical SST anomalies than over the continent. An attempt is made to separate the atmospheric response forced by the South Atlantic SST anomalies from that associated with the El Niño – Southern Oscillation (ENSO). Results show that both the South Atlantic and Pacific SSTs modulate the intensity and position of the SACZ during DJF. Particularly, the subtropical South Atlantic SSTs are more important than ENSO in determining the position of the SACZ over the southeast Brazilian coast during DJF. On the other hand, the ENSO signal seems to influence the intensity of the SACZ not only in DJF but especially its oceanic branch during MAM. Both local and remote influences, however, are confounded by the large <b>internal</b> <b>variance</b> in the region. During MAM and JJA, the South Atlantic SST anomalies affect the magnitude and the meridional displacement of the ITCZ. In JJA, the ENSO has relatively little influence on the interannual variability of the simulated rainfall. During SON, however, the ENSO seems to counteract the effect of the subtropical South Atlantic SST variations on convection over South America...|$|E
40|$|In {{this work}} is {{presented}} modules for intelligent robot navigation. Feature de-tection, people tracking, and navigation are essential abilities that allow robots to interact with their surrounding and with persons. The feature detection uses fast algorithms: Recursive line fitting and IAV (<b>Internal</b> Angle <b>Variance),</b> the latter being a inovative method developed in this project to accurately de-tect arcs/circles. A new people tracking methodology makes use of heuristics and closest pairs are applied to legs {{in order to keep}} track of persons. Scene interpretation is achieved so that architectural landmarks are recognized. A visualization tool was developed to better understand the results. Navigation is performed by an implementation of the dynamic window approach, in or-der to allow safe navigation in unknown environments, taking into account the dynamic and kinematic constrains of the robot. Resumo Neste trabalho são apresentados módulos para navegação robótica inteligente...|$|R
40|$|We {{propose a}} novel {{algorithm}} for blue noise sampling {{inspired by the}} Smoothed Particle Hydrodynamics (SPH) method. SPH is a well-known method in fluid simulation [...] it computes particle distributions to minimize the <b>internal</b> pressure <b>variance.</b> We found that this results in sample points (i. e., particles) with a high quality blue-noise spectrum. Inspired by this, we tailor the SPH method for blue noise sampling. Our method achieves fast sampling in general dimensions for both surfaces and volumes. By varying a single parameter our method can generate a variety of blue noise samples with different distribution properties, ranging from Lloyd's relaxation to Capacity Constrained Voronoi Tessellations ({CCVT}). Our method is fast and supports adaptive sampling and multi-class sampling. We have also performed experimental studies of the SPH kernel and its influence on the distribution properties of samples. We demonstrate with examples that our method can generate a variety of controllable blue noise sample patterns, suitable for applications such as image stippling and re-meshing...|$|R
40|$|This paper {{describes}} some {{modifications to}} the raking ratio estimation technique first proposed in a paper by Deming and Stephen in 1940 [1]. It discusses continuing research being conducted to improve the Corporation Statistics of Income (SOI) programs at the <b>Internal</b> Revenue Service. <b>Variance</b> and bias properties of the new estimates are examined, and some results from their application are provided. The material is divided into five sections, into major groups and industrial divisions. As {{can be seen in}} this representative example, Industrial Division 61, Wholesale Trade, is comprised of 3 Major Groups, 33 through 35, each of which is comprised of one or more mino...|$|R
40|$|Simulants {{are used}} by the lunar {{engineering}} community to develop and test technologies for In Situ Resource Utilization (ISRU), excavation and drilling, and for mitigation of hazards to machinery and human health. Working with the United States Geological Survey (USGS), other NASA centers, private industry and academia, Marshall Space Flight Center (MSFC) is leading NASA s lunar regolith simulant program. There are two main efforts: simulant production and simulant evaluation. This work requires a highly detailed understanding of regolith particle type, size, and shape distribution, and of bulk density. The project has developed Figure of Merit (FoM) algorithms to quantitatively compare these characteristics between two materials. The FoM {{can be used to}} compare two lunar regolith samples, regolith to simulant, or two parcels of simulant. In work presented here, we use the FoM algorithm to examine the variance of particle type in Apollo 16 highlands regolith core and surface samples. For this analysis we have used internally consistent particle type data for the 90 - 150 m fraction of Apollo core 64001 / 64002 from station 4, core 60009 / 60010 from station 10, and surface samples from various Apollo 16 stations. We calculate mean modal compositions for each core and for the group of surface samples and quantitatively compare samples of each group to its mean as a measurement of within-group variance; we also calculate an FoM for every sample against the mean composition of 64001 / 64002. This gives variation with depth at two locations and between Apollo 16 stations. Of the tested groups, core 60009 / 60010 has the highest <b>internal</b> <b>variance</b> with an average FoM score of 0. 76 and core 64001 / 64002 has the lowest with an average FoM of 0. 92. The surface samples have a low but intermediate <b>internal</b> <b>variance</b> with an average FoM of 0. 79. FoM s calculated against the 64001 / 64002 mean reference composition range from 0. 79 - 0. 97 for 64001 / 64002, from 0. 41 - 0. 91 for 60009 / 60010, and from 0. 54 - 0. 93 for the surface samples. Six samples fall below 0. 70, and they are also the least mature (i. e., have the lowest I(sub s) /FeO). Because agglutinates are the dominant particle type and the agglutinate population increases with sample maturity (I(sub s) /FeO), the maturity of the sample relative to the reference is a prime determinant of the particle type FoM score within these highland samples...|$|E
40|$|The {{potential}} predictability of {{the monthly}} and seasonal means during the Northern Hemisphere summer and winter is studied by estimating the signal-to-noise ratio. Based on 33 years of daily low-level wind observations and 24 years of satellite observations of outgoing long wave radiation, the predictability of the Asian summer monsoon region is contrasted with that over other tropical regions. A method of separating the contributions from slowly varying boundary forcing and internal dynamics (e. g., intraseasonal oscillations) that determine the predictability {{of the monthly}} mean tropical climate is proposed. We show that the Indian monsoon climate is only marginally predictable in monthly time scales as {{the contribution of the}} boundary forcing in this region is relatively low and that of the internal dynamics is relatively large. It is shown that excluding the Indian monsoon region, the predictable region is larger and predictability is higher in the tropics during northern summer. Even though the boundary forced variance is large during northern winter, the predictable region is smaller as the <b>internal</b> <b>variance</b> is larger and covers a larger region during northern winter (due to stronger intraseasonal activity). Consistent with the esti-mates of predictability of monthly means, estimates of potential predictability on seasonal time scales also indicate that predictability of seasonal mean Indian monsoon is limited. 1...|$|E
40|$|ABSTRACT Responses of brisk-sustained cat retinal {{ganglion}} {{cells were}} examined using {{receiver operating characteristic}} (ROC) analysis. Stimuli were brief luminance changes superimposed upon a weak steady pedestal ranging from 27 to 47, 000 quanta (507 nm) per second at the cornea. Overall quantum efficiencies of cells ranged up to ^- 13 % and were compatible with previous estimates at absolute threshold. The main work was done on on-center cells, but {{a small sample of}} off-center units behaved similarly. Experimental ROC curves verified a set of qualitative predictions based on a theoretical treatment of performance, assuming that response variability resulted solely from quantum fluctuations. However, quantitative predictions were not fulfilled. The discrepancy could be resolved by postulating a source of added <b>internal</b> <b>variance,</b> R, the value of which could then be deduced from the experimental measurements. A ganglion cell model limited by a fixed amount of added variance from physiological sources and having access to a fixed fraction of incident quanta can account quantitatively for (a) slopes of ROC curves, (b) variation of detectability with magnitude of both increments and decrements, and (c) performance over a range of pedestal intensities. Estimates of the proportion of incident quanta used ranged up to 29 % under some conditions, a figure approximately matching estimates of the fraction of corneal quanta that isomerize rhodopsin in the cat...|$|E
40|$|This study {{investigates the}} effect of mode of {{administration}} of the Raven Standard Progressive Matrices test on distribution, accuracy, and meaning of raw scores. A ran-dom sample {{of high school students}} take counterbalanced paper-and-pencil and computer-based administrations of the test and answer a questionnaire surveying pre-ferences for computer-delivered test administrations. Administration mode effect is studied with repeated measures multivariate analysis of <b>variance,</b> <b>internal</b> consistency reliability estimates, and confirmatory factor analysis approaches. Results show a lack of test mode effect on distribution, accuracy, and meaning of raw scores. Participants indicate their preferences for the computer-delivered administration of the test. The article discusses findings in light of previous studies of the Raven Standard Progressive Matrices test...|$|R
40|$|The {{objective}} of the reported study was to reassess {{the factor structure of}} the Developmental Behaviour Checklist (DBC) in a large cross-cultural sample representing all levels of intellectual disability. Parent and teacher DBC ratings on a combined sample of 1536 Dutch and Australian children and adolescents (ages 3 - 22) with mild to profound intellectual disability were used. Principal components analyses produced five subscales: Disruptive/Antisocial, Self-Absorbed, Communication Disturbance, Anxiety, and Social Relating, explaining 43. 7 % of the total <b>variance.</b> <b>Internal</b> consistencies of these subscales ranged from. 66 to. 91. The revised factor structure of the DBC appears to be an improved and useful tool for assessing emotional and behavioral problems in children with intellectual disabilities...|$|R
30|$|After {{the sparse}} {{representation}} X is {{obtained by the}} OMP algorithm, since X represents some features of the internal structure of the human image, and is related to a certain atom of the dictionary A, the categories to which human images belong can be quickly determined based on the non-zero coefficients in X. In the process of face recognition, noise and occlusion are common problems affecting face recognition, but these interference factors are mainly concentrated in high-frequency face images. The researchers found that the CAB model can handle face images with noise well and can accurately identify face images with 60 % noise. Studies have shown that if {{the resolution of the}} face image is infinite, then the <b>internal</b> element <b>variance</b> of the dictionary A will be low enough. It means that when the infinite reduction of the coefficient X approaches 1, the error rate corrected by the CAB model will infinity approach 100 %. Therefore, the identification of the high-frequency part of the face by the sparse representation method can make up for the shortcoming that after wavelet transform, only the low-frequency part is face recognized and the high-frequency part is ignored.|$|R
40|$|The authors {{assume that}} {{individuals}} adapt rationally to a utility function given constraints imposed by their cognitive architecture {{and the local}} task environment. This assumption underlies {{a new approach to}} modeling and understanding cognition—cognitively bounded rational analysis—that sharpens the predictive acuity of general, integrated theories of cognition and action. Such theories provide the necessary computational means to explain the flexible nature of human behavior but in doing so introduce extreme degrees of freedom in accounting for data. The new approach narrows the space of predicted behaviors through analysis of the payoff achieved by alternative strategies, rather than through fitting strategies and theoretical parameters to data. It extends and complements established approaches, including computational cognitive architectures, rational analysis, optimal motor control, bounded rationality, and signal detection theory. The authors illustrate the approach with a reanalysis of an existing account of psychological refractory period (PRP) dual-task performance and the development and analysis of a new theory of ordered dual-task responses. These analyses yield several novel results, including a new understanding of the role of strategic variation in existing accounts of PRP and the first predictive, quantitative account showing how the details of ordered dual-task phenomena emerge from the rational control of a cognitive system subject to the combined constraints of <b>internal</b> <b>variance,</b> motor interference, and a response selection bottleneck...|$|E
40|$|The {{inclusion}} of carbon cycle processes within CMIP 5 Earth system models {{provides the opportunity}} to explore {{the relative importance of}} differences in scenario and climate model representation to future land and ocean carbon fluxes. A two-way analysis of variance (ANOVA) approach was used to quantify the variability owing to differences between scenarios and between climate models at different lead times. For global ocean carbon fluxes, the variance attributed to differences between representative concentration pathway scenarios exceeds the variance attributed to differences between climate models by around 2025, completely dominating by 2100. This contrasts with global land carbon fluxes, where the variance attributed to differences between climate models continues to dominate beyond 2100. This suggests that modeled processes that determine ocean fluxes are currently better constrained than those of land fluxes; thus, one can be more confident in linking different future socioeconomic pathways to consequences of ocean carbon uptake than for land carbon uptake. The contribution of <b>internal</b> <b>variance</b> is negligible for ocean fluxes and small for land fluxes, indicating that there is little dependence on the initial conditions. The apparent agreement in atmosphere-ocean carbon fluxes, globally, masks strong climate model differences at a regional level. The North Atlantic and Southern Ocean are key regions, where differences in modeled processes represent an important source of variability in projected regional fluxes. Department of Applied Mathematic...|$|E
40|$|Responses of brisk-sustained cat retinal {{ganglion}} {{cells were}} ex-amined using {{receiver operating characteristic}} (ROC) analysis. Stimuli were brief luminance changes superimposed upon a weak steady pedestal ranging from 27 to 47, 000 quanta (507 nm) per second at the cornea. Overall quantum efficiencies of cells ranged up to ^- 13 % and were compatible with previous estimates at absolute threshold. The main work was done on on-center cells, but {{a small sample of}} off-center units behaved similarly. Experimental ROC curves verified a set of qualitative predictions based on a theoretical treatment of performance, assuming that response variability resulted solely from quantum fluctuations. However, quantitative predictions were not fulfilled. The discrep-ancy could be resolved by postulating a source of added <b>internal</b> <b>variance,</b> R, the value of which could then be deduced from the experimental measurements. A ganglion cell model limited by a fixed amount of added variance from physiological sources and having access to a fixed fraction of incident quanta can account quantitatively for (a) slopes of ROC curves, (b) variation of detect-ability with magnitude of both increments and decrements, and (c) performance over a range of pedestal intensities. Estimates of the proportion of incident quanta used ranged up to 29 % under some conditions, a figure approximately matching estimates of the fraction of corneal quanta that isomerize rhodopsin in the cat...|$|E
40|$|The main {{features}} of three atmospheric general circulation models forced with monthly-mean, observed sea surface temperature for the 1979 - 1995 period are analyzed and compared with observational data. The ensemble means and intra-ensemble {{standard deviations of}} several variables were investigated for the two seasons December-January-February and June-July-August. Correlations of the ensemble mean anomalies with observational data and with the indices Nino- 3 and the Atlantic Dipole were also calculated. The probability distribution function of the precipitation at different regions was also examined, {{as well as the}} <b>internal</b> and external <b>variance</b> of the precipitation in the three models. No model has uniformly better characteristics than the others. On the contrary, each model has strengths and weaknesses that depend on the region and season...|$|R
40|$|Depth-time {{records of}} isopycnal {{vertical}} strain {{have been collected}} from intensive CTD profiling programs on the research platform (R/P) Floating Instrument Platform (FLIP). The associated vertical wavenumber frequency spectrum of strain, when viewed in an isopycnal-following frame, displays a clear spectral gap at low vertical wavenumber, separating the quasigeostrophic (vortical) strain field and the superinertial internal wave continuum. This gap enables both model and linear-filter-based methods for separating the submesoscale and internal wave strain fields. These fields are examined independently in six field programs spanning the period 1983 - 2002. Vortical and <b>internal</b> wave strain <b>variances</b> are often comparable in the upper thermocline, of order 0. 2. However, vortical strain tends to decrease with increasing depth (decreasing buoyancy frequency as N 2 = -g/ρ(dρ/dz) ~(N 2) 1 / 2, while <b>internal</b> wave strain <b>variance</b> increases as ~(N 2) 1 / 2, exceeding vortical variance {{by a factor of}} 5 - 10 at depths below 500 m. In contrast to strain, the low-frequency spectral gap in the shear spectrum is largely obscured by Doppler-smeared near-inertial motions. The vertical wavenumber spectrum of anticyclonic shear exceeds the cyclonic shear and strain spectra at all scales greater than 10 m. The frequency spectrum of anticyclonic shear exceeds that of both cyclonic shear and strain to frequencies of 0. 5 cph, emphasizing the importance of lateral Doppler shifting of near-inertial shear. The limited Doppler shifting of the vortical strain field implies surprisingly small submesoscale aspect ratios: k H /k z ~ 0. 001, Burger numbers Br = k H N/k z f ~ 0. 1. Submesoscale potential vorticity is dominated by vertical straining rather than the vertical component of relative vorticity. The inferred rms fluctuation of fluid vorticity is far less for the vortical field than for the internal wavefield. © 2014 American Meteorological Society...|$|R
40|$|ABSTRACT. The {{purpose of}} this study was to {{evaluate}} a brief version of the Alcohol Expectancy Questionnaire-Adolescent (AEQ-A; Brown, Christiansen, & Goldman, 1987). The original AEQ-A was reduced to seven items (called the AEQ-AB). Principal Components Analysis (PCA) was performed and two factors emerged (General Positive Effects and Potential Negative Effects) accounting for 46 % of the <b>variance.</b> <b>Internal</b> consistencies are comparable to those of the original AEQ-A (0. 50). Scales correlate with criterion variables such as average drinks per week and average number of drinks per heavy drinking day (p < 0. 05). It is concluded that this questionnaire may be useful to clinicians providing brief assessment and intervention. Cross-validation in other samples and other settings is recommended. doi: 10. 1300 /J 029 v 16 n 02 _ 06 [Article copie...|$|R
40|$|While El Nino/Southern Oscillation (ENSO) {{phenomenon}} can {{be predicted}} {{with some success}} using coupled oceanic-atmospheric models, the skill of predicting the tropical monsoons is low regardless of the methods applied. The low skill of monsoon prediction may be either because the monsoons are not defined appropriately or {{because they are not}} influenced significantly by boundary forcing. The latter characterizes the importance of internal dynamics in monsoon variability and leads to many eminent chaotic features of the monsoons. In this study, we analyze results from nine AMIP-type ensemble experiments with the NASA/GEOS- 2 general circulation model to assess the potential predictability of the tropical climate system. We will focus on the variability and predictability of tropical monsoon rainfall on seasonal-to-interannual time scales. It is known that the tropical climate is more predictable than its extratropical counterpart. However, predictability is different from one climate subsystem to another within the tropics. It is important to understand the differences among these subsystems in order to increase our skill of seasonal-to-interannual prediction. We assess potential predictability by comparing the magnitude of internal and forced variances as defined by Harzallah and Sadourny (1995). The <b>internal</b> <b>variance</b> measures the spread among the various ensemble members. The forced part of rainfall variance is determined by the magnitude of the ensemble mean rainfall anomaly and by the degree of consistency of the results from the various experiments...|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 2017 Uncertainties {{in climate}} {{projections}} {{at the regional}} scale are inevitably larger than those for global mean quantities. Here, focusing on western North American regional climate, several approaches are taken to quantifying uncertainties starting with the output of global climate model projections. <b>Internal</b> <b>variance</b> {{is found to be}} {{an important component of the}} projection uncertainty up and down the west coast. To quantify <b>internal</b> <b>variance</b> and other projection uncertainties in existing climate models, we evaluate different ensemble configurations. Using a statistical framework to simultaneously account for multiple sources of uncertainty, we find internal variability can be quantified consistently using a large ensemble or an ensemble of opportunity that includes small ensembles from multiple models and climate scenarios. The latter offers the advantage of also producing estimates of uncertainty due to model differences. We conclude that climate projection uncertainties are best assessed using small single-model ensembles from as many model-scenario pairings as computationally feasible. We then conduct a small single-model ensemble of simulations using the Model for Predic- tion Across Scales with physics from the Community Atmosphere Model Version 5 (MPAS- CAM 5) and prescribed historical sea surface temperatures. In the global variable resolution domain, the finest resolution (at 30 km) is in our region of interest over western North Amer- ica and upwind over the northeast Pacific. In the finer-scale region, extreme precipitation from atmospheric rivers (ARs) is connected to tendencies in seasonal snowpack in mountains of the Northwest United States and California. In most of the Cascade Mountains, winters with more AR days are associated with less snowpack, in contrast to the northern Rockies and California’s Sierra Nevadas. In snowpack observations and reanalysis of the atmospheric circulation, we find similar relationships between frequency of AR events and winter season snowpack in the western United States. In spring, however, there is not a clear relationship between number of AR days and seasonal mean snowpack across the model ensemble, so caution is urged in interpreting the historical record in the spring season. Finally, the representation of the El Niño Southern Oscillation (ENSO) — an important source of interannual climate predictability in some regions — is explored in a large single- model ensemble using ensemble Empirical Orthogonal Functions (EOFs) to find modes of variance across the entire ensemble at once. The leading EOF is ENSO. The principal components (PCs) of the next three EOFs exhibit a lead-lag relationship with the ENSO signal captured in the first PC. The second PC, with most of its variance in the summer season, is the most strongly cross-correlated with the first. This approach offers insight into how the model considered represents this important atmosphere-ocean interaction. Taken together these varied approaches quantify the implications of climate projections regionally, identify processes that make snowpack water resources vulnerable, and seek insight into how to better simulate the large-scale climate modes controlling regional variability...|$|E
40|$|This {{research}} {{examines the}} zone between environment and interior, the architectural facade, {{for the potential}} {{to develop a new}} form of composition based on kinetic pattern. Within contemporary architecture there is a growing interest in kinetics. Intelligent facades for example, manifest kinetics {{in the form of a}} responsive skin that adapts to changing environment conditions and user occupancy, continuing the trajectory of functionalism. Media facades by contrast, are driven by an interest in the recasting of architectural surface as a zone of interactivity, with the potential to engage users with public art works or embed socio-cultural information. Regardless of the design intent, the emerging field of kinetic facades offers the challenge of developing a sophisticated approach to the design of motion. As evidenced by a review of theory and practice, there is a lack of fundamental knowledge about the possibilities offered by kinetics. Through the lens of morphology, this thesis explores the possibilities of kinetic composition afforded by facades in motion. The emphasis is on the underlying structure of kinetic form, independent of physical scale or materiality. Kinetics is defined in spatial terms: actual movement through geometric transformation in space (translation, rotation, scaling); or through controlling material properties of elasticity and mass to produce movement. Composition is analyzed in terms of pattern, defined as the relative movement of individual kinetic parts in time and space - the way in which multiple singular kinetic events cluster, or propagate, across a facade over time. A morphology of pattern is developed by three interrelated questions. What design variables influence kinetics, what is the theoretical range, and what nomenclature may robustly describe a morphology of pattern? An original framework for conceiving design variables is proposed. The framework revolves around diverse approaches to data sampling and control systems, alongside the typical architectural emphasis on the design of the physical components. These three interrelated design activities are conceived in terms of 'decision planes'. Specification of variables on each plane and in relation to time, determine the spatio-temporal limits, or what is termed as the 'variable space', from which patterns will emerge. This conceptual framework has been used to structure a methodical series of computer animations, which explore range of pattern. In a similar vein to the tradition of facade study drawings, a diagrammatic approach to animation has been developed. The adoption of a non-realistic mode bf representation is intended to focus attention on ' movement itself ', independent of physical scale, materiality or figurative associations. Through analysis and discussion of the animations, it is proposed that morphology of kinetic pattern is robustly described through a nomenclature based on state change. It is proposed that three recognizable states reoccur - waves, folds and fields. State change is based on the principle of <b>internal</b> <b>variance</b> within these three simple states, and intermediate states that allow transition by degree and kind. Similar to the nomenclature for describing clouds, this provides a robust and extendable approach, allowing multiple intermediate states to be conceived in relation to the wave, fold and field definitions. The framework for conceiving variables that influence pattern and the state change morphology provide the means to improve understanding in the particular realm of kinetic facade composition. The framework is presented in generic form and a particular instance is developed based on an analysis of key references. This provides a model to conceive the multiple variables that influence kinetic composition, while the morphology provides a low resolution map for designers, identifying the most distinctive forms and providing a scaffold for research by design. Further work on extending these contributions to knowledge is outlined, including the description of a simulation environment calibrated to the physical constraints of materials and technologyRestricted Access: University of Melbourne Staff and Students Onl...|$|E
40|$|The {{main purpose}} of the study was to examine the psychometric {{properties}} of a Smoking Abstinence Self-Efficacy Scale with Korean men in the US. The scale was modified to reflect the Korean cultural practice of smoking behavior and was cross-culturally validated with a panel of 10 professionals. An 11 -item Korean version of the scale was administered twice over a one-month period. Data were analyzed for internal consistency reliability, stability, and construct validity. After the deletion of one item, an exploratory factor analysis yielded two factors, which explained 62 % of the <b>variance.</b> <b>Internal</b> consistency was satisfactory for the total scale (. 89), Factor I (. 88), and Factor II (. 80) but intraclass correlation coefficient for the total scale (. 57) was low. Nicotine dependence and nicotine withdrawal showed modest but statistically significant correlations with the scale...|$|R
40|$|Twenty-four {{nursery school}} {{teachers}} were given Levenson's (1974) questionnaire on control beliefs and rating scales referring to {{their belief in}} nature's and nurture's contributions to the child's development. They were then involved in a semistructured play situation with children of their class, 31 to 52 months old, in a small group setting. The entire situation was videorecorded In a structured interview, the teachers had to respond to several questions referring to development and education and the interview was submitted to content analysis. Finally, the teachers' educational action was rated from the video recordings as io distancing and directive strategies. Internal control beliefs, agreement with nature's contribution to the child's development, {{and the proportion of}} references to cognitive-developmental processes predicted educational action aggregated from distancing and directive strategies and explained a high percentage of <b>variance.</b> <b>Internal</b> control was the most powerful predictor...|$|R
40|$|The aim of {{this study}} was to analyze the psychometric {{properties}} of the Spanish translation of the List of Social Situation Problems (LSSP; S. H. Spence, 1980). The questionnaire was administered to a sample of 388 adolescents between the ages of 12 and 18. Exploratory factor analysis identified four factors: Social Anxiety, Adult Oppositional, Assertiveness, and Making Friends, which accounted for 26. 64 % of the <b>variance.</b> <b>Internal</b> consistency of the total scale was high (agr =. 86). Correlations between the LSSP and two self-report measures of social anxiety, the Questionnaire about Interpersonal Difficulties for Adolescents (r =. 45) and the Social Phobia and Anxiety Inventory (r =. 48), were statistically significant. A significant difference was found between LSSP total scores for adolescents with and without social anxiety (d = 1. 14), supporting the construct validity of the scale. No Full Tex...|$|R
40|$|Objective To {{investigate}} {{the psychometric properties}} of the objective structured clinical examination (OSCE) conducted in the final year of a pre-professional osteopathy program. A variety of metrics are used to determine {{the reliability and validity of}} the examination. Methods Data from the OSCE conducted in 2011 was collated and analysed to establish the pass/fail rates, cost of the examination, <b>internal</b> consistency, and <b>variance</b> components. The examination was conducted over two days with students completing 5 stations on day 1 and 4 stations on day 2. Each station was of 15 min duration and there were 2 examiners per station. Results Forty-eight students and 31 examiners were involved in the examination. Twenty-six students failed at least one station with six students failing three or more stations. Cronbach's alpha was greater than 0. 80 for all stations indicating that each is internally consistent and over 50...|$|R
40|$|Abstract. We discuss {{variance}} reduced simulations for an individual-based {{model of}} chemotaxis of bacteria with <b>internal</b> dynamics. The <b>variance</b> reduction is achieved via a coupling {{of this model}} with a simpler process associated with a kinetic description. Using probabilistic techniques, we first prove a pathwise version of the diffusive asymptotics, showing that both processes converge towards the same advection-diffusion process. Subsequently, we couple the jump times of both processes and analyze the variance {{of the difference between}} the two solutions. We show that this coupling yields an asymptotic variance reduction (control variate), in the sense that, in the diffusive asymptotics, {{the difference between the two}} processes has a variance which vanishes according to the small parameter. Finally, this coupling is used to construct a hybrid scheme with reduced variance, by first computing a deterministic solution of the kinetic density description, and then simulating the coupled processes to evaluate the difference with the exact solution with internal dynamics...|$|R
40|$|This study {{highlights}} the importance of primary school science teachers who help students build up the knowledge as guides in the constructivist approach. For this purpose, a five-point Likert type scale was developed to get the opinions of the pre-service science teachers who will use constructivism in their classes. 600 pre-service science teachers from the faculty of education at ten different universities located different areas in Turkey have participated in the study and the data from 465 pre-service teachers were taken into account excluding the empty and inconsistent items of the participants. Expert opinions were taken for content validity; and item analysis, factor analysis and the reliability analysis were conducted in the process of the development of the scale. According to the results, the scale has one factor structure and accounts for 51. 18 % of the total <b>variance.</b> <b>Internal</b> consistency coefficient and half-split reliability of the scale showed that this scale can be used for the future studies...|$|R
40|$|To {{identify}} factors limiting {{performance in}} multitone intensity discrimination, we presented sequences of five pure tones alternating in level between loud (85 dB SPL) and soft (30, 55, or 80 dB SPL). In the "overall-intensity task", listeners detected a level increment {{on all of}} the five tones. In the "masking task", the level increment was imposed only on the soft tones, rendering the soft tones targets and loud tones task-irrelevant maskers. Decision weights quantifying the importance of the five tone levels for the decision were estimated using methods of molecular psychophysics. Compatible with previous studies, listeners placed higher weights on the loud tones than on the soft tones in the overall-intensity condition. In the masking task, the decisions were systematically influenced by the to-be-ignored loud tones (maskers). Using a maximum-likelihood technique, we estimated the <b>internal</b> noise <b>variance</b> and tested whether the internal noise was higher in the alternating-level five-tone sequences than in sequences presenting only the soft or only the loud tones. For the overall-intensity task, we found no evidence for increased internal noise, but listeners applied suboptimal decision weights. These results are compatible with the hypothesis that the presence of the loud tones does not impair the precision of the representation of the intensity of the soft tones available at the decision stage, but that this information is not used in an optimal fashion due to a difficulty in attending to the soft tones. For the masking task, in some cases our data indicated an increase in internal noise. Additionally, listeners applied suboptimal decision weights. The maximum-likelihood analyses we developed should also be useful for other tasks or other sensory modalities...|$|R
40|$|The {{internal}} noise {{present in a}} linear system can be quantified by the equivalent noise method. By measuring the effect that applying external noise to the system’s input has on its output one can estimate the <b>variance</b> of this <b>internal</b> noise. By applying this simple “linear amplifier” model to the human visual system, one can entirely explain an observer’s detection performance {{by a combination of}} the <b>internal</b> noise <b>variance</b> and their efficiency relative to an ideal observer. Studies using this method rely on two crucial factors: firstly that the external noise in their stimuli behaves like the visual system’s {{internal noise}} in the dimension of interest, and secondly that the assumptions underlying their model are correct (e. g. linearity). Here we explore the effects of these two factors while applying the equivalent noise method to investigate the contrast sensitivity function (CSF). We compare the results at 0. 5 and 6 c/deg from the equivalent noise method against those we would expect based on pedestal masking data collected from the same observers. We find that the loss of sensitivity with increasing spatial frequency results from changes in the saturation constant of the gain control nonlinearity, and that this only masquerades as a change in internal noise under the equivalent noise method. Part of the effect we find {{can be attributed to the}} optical transfer function of the eye. The remainder can be explained by either changes in effective input gain, divisive suppression, or a combination of the two. Given these effects the efficiency of our observers approaches the ideal level. We show the importance of considering these factors in equivalent noise studies...|$|R
40|$|International audienceWe discuss {{variance}} reduced simulations for an individual-based {{model of}} chemotaxis of bacteria with <b>internal</b> dynamics. The <b>variance</b> reduction is achieved via a coupling {{of this model}} with a simpler {{process in which the}} internal dynamics {{has been replaced by a}} direct gradient sensing of the chemoattractants concentrations. In the companion paper limits, we have rigorously shown, using a pathwise probabilistic technique, that both processes converge towards the same advection-diffusion process in the diffusive asymptotics. In this work, a direct coupling is achieved between paths of individual bacteria simulated by both models, by using the same sets of random numbers in both simulations. This coupling is used to construct a hybrid scheme with reduced variance. We first compute a deterministic solution of the kinetic density description of the direct gradient sensing model; the deviations due to the presence of internal dynamics are then evaluated via the coupled individual-based simulations. We show that the resulting variance reduction is asymptotic, in the sense that, in the diffusive asymptotics, the difference between the two processes has a variance which vanishes according to the small parameter...|$|R
