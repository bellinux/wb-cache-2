61|41|Public
2500|$|In 1946, as {{pressure}} was building from Malan's reactionary National Party, Smuts sought {{to devise a}} comprehensive United Party position on the so-called native question. For this purpose he appointed the independent Native Laws Commission, with Fagan as its head, to investigate changes to the system of segregation. When the Commission reported in 1948, it stated that the total segregation or apartheid envisaged by the National Party was [...] "utterly impracticable", since South Africa's racial groups were inevitably interdependent, and the 'reserves' set aside for black South Africans were far too small to support them. It therefore recommended that 'influx control' measures be relaxed, allowing black South Africans to move to cities with relative freedom and the <b>incremental</b> <b>integration</b> of the races. Yet the report did not favour racial equality, and rejected the full social or political integration of black people as unacceptable. It recommended liberalisation primarily {{on the basis that}} it would benefit the white population economically, and recommended accordingly that only those black persons who would benefit industry should be allowed to stay in the cities.|$|E
5000|$|Although Edwards, Nugent, and Marr had all {{recommended}} full integration, {{reasoning that}} it was not only socially just but that segregation was inefficient and could never be made efficient, the Air Force adopted an <b>incremental</b> <b>integration</b> plan modeled on that of the U.S. Navy, which already had an official racial equality policy formulated by Navy Secretary James Forrestal during World War II. The Navy's racial problem stemmed from its limited compliance with its own policy, caused by diverting 62% of its blacks into the Steward's Branch, but where black sailors served in the fleet, complete integration within units, including living quarters, had already taken place. The numbers, however, were very small. Even so, Edwards and the civilian leadership of the Air Force announced that Air Force policy unequivocally endorsed Truman's order and demanded [...] "ungrudging compliance" [...] with it. Edwards made clear to local commanders that they would be held personally and officially responsible for the smooth implementation of the Air Force plan.|$|E
5000|$|In 1946, as {{pressure}} was building from Malan's reactionary National Party, Smuts sought {{to devise a}} comprehensive United Party position on the so-called native question. For this purpose he appointed the independent Native Laws Commission, with Fagan as its head, to investigate changes to the system of segregation. When the Commission reported in 1948, it stated that the total segregation or apartheid envisaged by the National Party was [...] "utterly impracticable", since South Africa's racial groups were inevitably interdependent, and the 'reserves' set aside for black South Africans were far too small to support them. It therefore recommended that 'influx control' measures be relaxed, allowing black South Africans to move to cities with relative freedom and the <b>incremental</b> <b>integration</b> of the races. Yet the report was avowedly not egalitarian, and rejected the full social or political integration of black people as unacceptable. It recommended liberalisation primarily {{for the reason that}} it would benefit the white population economically, and recommended accordingly that only those black persons who would benefit industry should be allowed to stay in the cities.Nevertheless, the Commission had firmly rejected the principles on which the National Party's official policy of apartheid was based, and therefore raised its ire. Hendrik Verwoerd was especially critical. And a declaration signed by a prominent group of Stellenbosch academics angrily pointed out that if Fagan's racial integration were allowed this would lead inevitably to gelykstelling (social levelling) and, as a result of pressure to give blacks equal civil rights, the political marginalisation of the Afrikaners; both would mean the death of the Afrikaner volk. Though they were angry, the Nationalists had not been caught unprepared: in fact, Malan had already set up a rival commission headed by his closest confidante, Paul Sauer, and staffed by three NP parliamentarians, and which had reported in 1947. The Sauer Commission had given added detail and heft to the Nationalists' policy of apartheid, recommending that influx control measures be strengthened to prevent any mixing between the races, with black people consigned to the reserves. It was this hard-line view which triumphed when Malan's National Party won the 1948 general election.|$|E
50|$|The anatomies are {{especially}} useful in development of large complex systems in <b>incremental</b> and <b>integration</b> driven development, {{and as a}} means to coordinate agile development teams.|$|R
50|$|Material {{requirements}} planning (MRP) {{and manufacturing}} resource planning (MRPII) are both <b>incremental</b> information <b>integration</b> business process {{strategies that are}} implemented using hardware and modular software applications linked to a central database that stores and delivers business data and information.|$|R
50|$|A project anatomy (also {{integration}} anatomy or organic integration plan) is a {{tool for}} integration planning that visualizes dependencies between work items in development projects. It is mainly used in <b>incremental</b> development and <b>Integration</b> Driven Development projects.|$|R
40|$|It is {{essential}} {{to reduce the cost}} of integrating information sources and to provide a path that allows for <b>incremental</b> <b>integration</b> that can be responsive to users' demands. This paper presents an approach to integrating disparate heterogeneous information sources that uses context logic. Our use of context logic reduces the up-front cost of integration, provides an <b>incremental</b> <b>integration</b> path, and allows semantic conflicts within a single information sources or between information sources to be expressed and resolved...|$|E
40|$|In {{development}} processes multiple {{tools are}} used to describe {{different aspects of the}} developed product. The resulting information is stored in heterogeneous documents that are technically independent but whose contents are closely related on the semantic level. Thus, if one document is changed, these changes have to be propagated to dependent documents in order to restore mutual consistency. Therefore, {{there is a need for}} <b>incremental</b> <b>integration</b> tools which assist developers in consistency maintenance. Driven by this need, we realized a framework for building <b>incremental</b> <b>integration</b> tools which is currently being used in the chemical engineering domain. Integration tools are based on models of the related documents and their mutual relationships. These models are defined in the Unified Modeling Language (UML) ...|$|E
40|$|Abstract:- Estimating {{effort is}} an {{important}} component of planning software engineering tasks. Preventive <b>incremental</b> <b>integration</b> software testing is one of such tasks. In the moment when this testing begins software design already exists and can be used in effort estimating. Seven design metrics already proposed in the literature on software engineering have been selected in this paper in order to analyze their applicability to estimating effort of <b>incremental</b> <b>integration</b> testing. A number of programs has been developed to collect the data needed for this analysis. In addition, the conditions under which these data have been collected are shown. Based upon the data, the metrics have been analyzed by using the correlation between each of the metrics and the actual effort spent on this testing. The results point to best metrics to be used for the estimation purpose...|$|E
50|$|String metrics {{are used}} heavily in {{information}} integration and are currently used in areas including fraud detection, fingerprint analysis, plagiarism detection, ontology merging, DNA analysis, RNA analysis, image analysis, evidence-based machine learning, database data deduplication, data mining, <b>incremental</b> search, data <b>integration,</b> and semantic knowledge integration.|$|R
40|$|Distributed Data Mining is {{the process}} of extracting hidden {{knowledge}} from distributed data sources. A number of DDM architectures are proposed during the last few years. Recently, Optimized <b>Incremental</b> Knowledge <b>Integration</b> Distributed Data Mining model is proposed. It is a mobile-agent based model that overcomes the drawbacks of the traditional models. In this paper, the classification mining is formulated using this new model {{in order to make it}} scalable to large amounts of data. The proposed model uses meta-learning methodology to integrate the generated knowledge...|$|R
40|$|Source Integration {{is one of}} {{the core}} {{problems}} in Data Warehousing. Two critical factors for the design and maintenance of applications requiring Source Integration, and in particular Data Warehouse applications, are conceptual modeling of the domain, and reasoning support over the conceptual representation. We present a novel approach to conceptual modeling for Source Integration, which allows for suitably modeling the global concepts of the application, the individual information sources, and the constraints among different sources. Our methodological framework relies on the reasoning services associated with the modeling formalism to support an <b>incremental</b> Source <b>Integration</b> phase within the Data Warehouse design process. 1...|$|R
40|$|It is {{essential}} {{to reduce the cost}} of integrating information sources and to provide a path that allows for <b>incremental</b> <b>integration</b> that can be responsive to users' demands. This paper presents an approach to integrating disparate heterogeneous information sources that uses context logic. Our use of context logic reduces the up-front cost of integration, provides an <b>incremental</b> <b>integration</b> path, and allows semantic conflicts within a single information sources or between information sources to be expressed and resolved. Introduction The number of online network-accessible information sources grows daily. The information promises to provide tremendous value for individuals and corporations. The promise will remain unfulfilled, however, until it is possible to integrate and assimilate information from multiple heterogeneous sources. Because it is impossible to predict the users and patterns of usage in our changing information environment, information providers are not willing to pay a [...] ...|$|E
40|$|The paper {{focuses on}} the <b>incremental</b> <b>integration</b> of the {{chunking}} stage for robust deeper syntactic analyses. It first describes a base NP chunker for Bulgarian, which is hand-made, sensitive to lexical information and implemented as a cascaded regular expression grammar within the CLARK system. The problems, related to the NP chunker are discussed from both points of view - linguistic and implemental. Then a mapping scheme between the output chunks and dependency relations is considered with respect to deeper parsing within HPSG...|$|E
40|$|Triple graph grammars, an {{extension}} of pair graph grammars, were introduced for the specification of graph translaters. We developed a framework which constitutes an industrial application of triple graph grammars. It solves integration problems in a specific domain, namely design processes in chemical engineering. Here, different design representations of a chemical plant have to be kept consistent with each other. <b>Incremental</b> <b>integration</b> tools assist in propagating changes and performing consistency analysis. The integration tools are driven by triple rules which define relationships between design documents...|$|E
40|$|Pre-integrated volume {{rendering}} is {{an effective}} technique for generating high-quality visualizations. The precomputed lookup tables used by this method are slow to compute and can not include truly pre-integrated lighting due to space constraints. The lighting for pre-integrated rendering is therefore {{subject to the same}} sampling artifacts as in standard volume rendering. We propose methods to speed up lookup table generation and minimize lighting artifacts. The <b>incremental</b> subrange <b>integration</b> method we describe allows interactive lookup table generation in O   n 2 ¡ time without the need for approximation or hardware assistance. The interpolated preintegrated lighting algorithm eliminates discontinuities by linearly interpolating illumination along the view direction. Both methods are applicable to any pre-integrated rendering method, including cell projection, ray casting, and hardware-accelerated algorithms. 1...|$|R
40|$|In larger organizations, {{multiple}} {{teams of}} data scientists have to integrate data from heterogeneous data sources as preparation for data analysis tasks. Writing effective analytical queries requires data scientists to have in-depth {{knowledge of the}} existence, semantics, and usage context of data sources. Once gathered, such knowledge is informally shared within a specific team of data scientists, but usually is neither formalized nor shared with other teams. Potential synergies remain unused. We therefore introduce a novel approach which extends data management systems with additional knowledge-sharing capabilities to facilitate user collaboration without altering established data analysis workflows. Relevant collective knowledge from the query log is extracted to support data source discovery and <b>incremental</b> data <b>integration.</b> Extracted knowledge is formalized and provided at query time. Comment: in Germa...|$|R
3000|$|The coupled model {{described}} in “Process description and physics modeling” section involves three primary unknown fields, the temperature T([...] x, t), the pressure P([...] x,t) and the curing degree α ([...] x,t). The viscosity field, η ([...] x, t), {{can be obtained}} as a post-processing of the temperature and curing degree fields. The nonlinearity associated to the coupling can be efficiently addressed by using a semi-implicit <b>incremental</b> time <b>integration,</b> and treating all coupling terms explicitly, therefore allowing for decoupling of the different problems. Thanks to this strategy, {{we are able to}} define different simulation modules, described below, one for each physics involved in the manufacturing process. This approach is particularly effective in the context of ROM, because it allows applying the most suitable techniques depending {{on the nature of the}} equations.|$|R
40|$|Among the key {{characteristics}} of cyber-physical systems are {{the ability to}} adapt to changes during operation, the multidimensional complexity of multi-functionality and the underlying heterogeneous distributed architecture, as well as resource use efficiency. In this paper, we propose a compositional multi-modal approach to modeling, analyzing, and designing such systems. We introduce a general framework for modeling and compositional analysis of multi-mode systems on a distributed architecture that facilitates adaptivity, efficient use of resources, and <b>incremental</b> <b>integration.</b> We present some preliminary results, and we describe some of the remaining challenges and future directions...|$|E
40|$|In this paper, {{the authors}} present an {{approach}} for the capitalisation of switching knowledge centred around {{the creation of}} structured knowledge models {{in order to provide}} switching support for transmission networks. With this iterative process, the role of additional knowledge in the overall problem solving behaviour can be explicitly identified in the resulting models. This approach facilitates the <b>incremental</b> <b>integration</b> of knowledge that has originated from different sources, into a centralised framework which can be used for different purposes such as reference documentation, or specification of support systems...|$|E
40|$|This paper {{assesses the}} nature and degree of {{bilateral}} economic integration preceding and following {{the implementation of the}} Canada- U. S. Free Trade Agreement (CUSTA). Various price-based and quantity- based indicators of economic integration are assessed. Results vary depending upon the indicator; however, on balance, the results provide only modest evidence of <b>incremental</b> <b>integration</b> in the post-CUSTA period. The findings serve as a caution against managers and policymakers assuming that regional integration is an inevitable dynamic and basing strategies and policies around this assumption. economic integration; free trade agreements; trade, foreign direct investment; price convergence. ...|$|E
40|$|This paper {{introduces}} {{the concept of}} Intersection Schemas {{in the field of}} heterogeneous data integration and dataspaces. We introduce a technique for incrementally integrating heterogeneous data sources by specifying semantic overlaps between sets of extensional schemas using bidirectional schema transformations, and automatically combining them into a global schema at each iteration of the integration process. We propose an <b>incremental</b> data <b>integration</b> methodology that uses this technique and that aims {{to reduce the amount of}} up-front e↵ort required. Such approaches to data integration are often described as pay-as-you-go. A demonstrator of our technique is described, which utilizes a new graphical user tool implemented using the AutoMed heterogeneous data integration system. A case study is also described, and our technique and integration methodology are compared with a classical data integration strategy...|$|R
40|$|This article scrutinises the {{application}} of collective political identity construction as a political concept {{to the process of}} European integration. As a starting point for my approach I take the recurring demands for a European identity which reflects a strong link between democratic legitimacy and the EU. Given the sui generis nature of the European integration process, I argue that these perceptions derive from the nation-building processes of the 18 th and 19 th centuries rather than reflecting the experience of an <b>incremental</b> political <b>integration</b> process. Contrary to the generalised assumption that identity construction is a prerequisite for political integration in Europe or the ‘missing link’, my argument is that European identity should rather be treated as a possible end product. Applying a strong pathdependence model to European integration risks stepping into an ‘identity trap’, which constrains indispensable systemic flexibility...|$|R
40|$|Abstract—Designing user {{interfaces}} involves several iterations for usability design and evaluation {{as well as}} <b>incremental</b> functionality <b>integration</b> and testing. This paper reports on the methodological approach for the design and implementation of an application that is used for search and retrieval of sociallyaware digital content. It presents the archivist view of professional media organizations and the specific requirements for successful retrieval of content. The content derived from the social media analysis is enormous and appropriate actions {{need to be taken}} to avoid irrelevant and/or repeated social information in the displayed results as well as overinformation. The archivist feedback reveals the way humans address the social information as presented in the form of metadata along with the archived raw content and how this drives the design of a dedicated search and retrieval application. Keywords-search and retrieval {{user interfaces}}; social network information; archiving; preservation; user interface design; usability I...|$|R
40|$|The {{process of}} {{understanding}} spoken language requires the efficient processing of ambiguities that arise {{by the nature}} of speech. This paper presents an approach that allows the efficient <b>incremental</b> <b>integration</b> of speech recognition and language understanding using Tomita´s generalized LR-parsing algorithm. For this purpose the GLR-lattice-parsing-algorithm is revised so that an agenda mechanism can be used to control the flow of computation of the parsing process. Subsequently the HMM-evaluations of the word models are combined with a stochastical language model to do a beam search similar to where chartparsers are used to do the job...|$|E
40|$|Integration testing plays {{a crucial}} role in component-based {{software}} development. In complementary to the existing works on the selection of test cases and measurement of test adequacy in integration testing, this paper focuses on questions about how to observe the behaviours of a large and complicated system during dynamic testing. We first analyse the structure of white-box integration testing and propose a family of integration testing methods. We then discuss and formalise the requirements of proper uses of test drivers and component stubs in <b>incremental</b> <b>integration.</b> Finally, we propose a set of axioms for integration testing of concurrent systems. 1...|$|E
40|$|In {{the course}} of the {{construction}} of a software system, software documents (requirements definitions, software architectures, module implementations, etc.) are produced which are written in different languages and describe (parts of) the system from different points of view. While the construction of structure-oriented editors for such documents seems to be well understood, the construction of tools for the integration between them has severely been neglected. In this paper, we present a formal approach to the semi-automatic construction of <b>incremental</b> <b>integration</b> tools which provide both passive and active support for inter-document dependencies (consistency analyses and generation/updating of templates for dependent documents, respectively) ...|$|E
40|$|International audienceThe {{normalization}} of semi-formal modeling methods, {{such as the}} UML, leads to re-visit the problem of early 00 integration test planning. Integration is often conducted under some <b>incremental</b> steps. <b>Integration</b> test planning aims at ordering the components to be integrated and tested in relationships with the already tested part of the system. This paper presents a modeling of the test integration problem from a UML design, then details existing integration strategies and proposes two integration strategies: a deterministic one called Triskell and an original semi-random one, based on genetic algorithms called Genetic. Strategies are compared in detail (algorithmic cost and optimization choices) and {{a large part of}} the paper is dedicated to an experimental comparison of each strategy on 6 real-world case studies of various complexities (from a "small" telecommunication software to the Swing Java library). Results show that a good modeling of this optimization problem associated with well-chosen algorithms induce a significant gain in terms of testing effort and duration...|$|R
40|$|Current Manufacturing Support Systems (MSS), such as Computer-aided Manufacturing (CAM) Systems, Computer-aided Design (CAD) Systems, Computer Integrated Manufacturing (CIM) Systems, Material Resource Planning (MRP) Systems, and Manufacturing Accounting Control (MAC) Systems, {{are mostly}} {{independent}} {{systems that are}} operated in limited decision spaces, provide mainly formal and quantitative information, and thus pursue a goal of local optimization. To assist modern manufacturing in meeting the needs for integration, communication, collaboration, and decision making, we introduce the concept of integrating MSS with Distributed Group Support System (DGSS) into a Distributed Manufacturing Support System (DMSS). A rigorous system design approach is taken to model the manufacturing information requirements from a global perspective and pattern decision making processes within the structural (organizational design) and infrastructural (information system design) elements of manufacturing. The result is a conceptual DMSS design that provides an intelligent interface, accommodates <b>incremental</b> manufacturing <b>integration,</b> offers controllable message exchange facilities, and allows configurable communication networks. distributed group support systems group decision support systems computer-aid communication systems manufacturing support systems...|$|R
40|$|Abstract. Efficient video content {{analysis}} is an unsolved problem, especially for real-life surveillance videos {{due to their}} low resolution and illustration variations. A novel framework to efficiently and robustly convert a surveillance video clip into one abstraction image containing the integrated contour of inter-ested objects is proposed. It has the following novelties: 1) an improved w-SIFT algorithm for Y-axis frames offset calculation, 2) a trapezoid-based compensa-tion algorithm for X-axis perspective distortion correction, and 3) an <b>incremental</b> video content <b>integration</b> approach. Experimental results show that our method is robust for real-life low resolution videos and efficient for real-time analysis...|$|R
40|$|Workflow {{management}} systems support the eficient, largely automated execution of business processes. However; using a workflow management system typically requires implementing the application's control flow exclusively by the workflow management system. This approach is powerful if the control flow is specified and implemented from scratch, {{but it has}} severe drawbacks if a workflow management system is to be integrated within environments with existing solutions for implementing control flow. Usually, the existing solutions are too complex to be substituted by the workflow management system at once. Hence, the workflow management system must support an <b>incremental</b> <b>integration,</b> i. e. the reuse of existing implementations of control flow {{as well as their}} incremental substitution. Extending the workflow management system's functionality according to future application needs, e. g. by worklist and history management, must also be possible. In particular at the beginning of an <b>incremental</b> <b>integration</b> process, only a limited amount of a workflow management system's functionality is actually exploited by the workflow application. Later on, as the integration proceeds, more advanced requirements arise and demand the customization of the workfow management system to the evolving application needs. In this paper; we present the architecture and implementation of a light-weight workflow management system, coined Mentor-lite, which aims to overcome the above mentioned shortcomings of conventional workflow {{management systems}}. Mentor-lite supports an easy integration of workflow functionality into an existing environment, and can be tailored to specific workflow application needs...|$|E
40|$|While {{getting close}} to the {{customer}} is widely recommended as an obvious way of serving the customer better, {{there is no clear}} demarcation between being close to the customer and being customer-driven. No longer content with the ability to anticipate customer demand, many suppliers are seeking to influence this demand, moving from being reactive to gently proactive. Increasing involvement in the customer's business may help lock in the customer, but it also leads to increasing involvement of the customer in the supplier's business, locking in the supplier as much as the customer. This <b>incremental</b> <b>integration</b> has important strategic implications that firms must examine carefully...|$|E
40|$|Sustainable {{development}} has been accepted as a conceptual framework for local planning. However, there continues to be difficulty incorporating {{the full range of}} its components (i. e., balanced consideration of environment, economy, and equity) into local planning in the form of policies and pro-grams. Apart of the reason for this difficulty is the continuing competition between two worldviews, the expansionist and ecological. The author proposes the <b>incremental</b> <b>integration</b> of the two worldviews through an overall strategy of action and the use of a decision model that incorporates project and context information to identify appropriate method and role. As the ecological worldview becomes more institutionalized, it is likely that its components will be increasingly reflected in community development strategies...|$|E
40|$|Learning {{by reading}} systems, {{designed}} to acquire episodic (instance based) knowledge, ultimately have to integrate that knowledge into an underlying memory. In order to effectively integrate new knowledge with existing knowledge {{such a system}} {{needs to be able}} to resolve references to the instances (agents, locations, events, etc.) it is reading about with those already existing in memory. This is necessary to extend existing memory structures, and to avoid incorrectly producing duplicate memories. Direct Memory Access Parsing (DMAP) leverages existing knowledge and performs reference resolution and memory integration in the early stages of parsing natural language text. By performing <b>incremental</b> memory <b>integration</b> our system can reduce the number of ambiguous sentence interpretations and coreference mappings it will explore in-depth, however this savings is currently canceled out by the run-time cost of reference resolution algorithm. This paper supports the continued investigation of this line of research, which is to identify and evaluate the extent to which semantic and episodic memory can facilitate natural language understanding, especially when used early in the language understanding process...|$|R
40|$|The European Commission has {{spelled out}} its policy {{ambition}} for EU energy {{cooperation with the}} southern neighbourhood with plans {{for the establishment of}} an ‘Energy Community’. Its communications make clear that an Energy Community should be based on regulatory convergence with the EU acquis communautaire, much in the same vein as the existing institution carrying the same name; the Energy Community with Southeast Europe. It is puzzling that the Commission insists on repackaging this enlargement concept in a region with very different types of relationships vis-à-vis the EU, especially when considering the lukewarm position of key stakeholders in the field. According to them, any attempt to introduce a political integration model in this highly sensitive issue area in the politically fragmented MENA region might run the risk of hurting the <b>incremental</b> technical <b>integration</b> process that has slowly emerged over the past few years. Funded by the European Research Council (ERC) within the 7 th Framework Programme, the BORDERLANDS project is hosted at the Robert Schuman Centre for Advanced Studies, European University Institute, and directed by Professor Raffaella A. Del Sarto...|$|R
40|$|Today’s data {{integration}} systems must be {{flexible enough to}} support the typical iterative and <b>incremental</b> process of <b>integration,</b> and may need to scale to hundreds of data sources. In this work we present a novel {{data integration}} system that offers great flexibility and scalability. Our approach to data integration is unique in that it executes mapping rules at query runtime using annotations. On top, we have built the People People People application. It allows users to search for people, display information about people, and browse through a network of related people, where the data is integrated from local and remote data sources. The demo presents all features of our underlying data integration engine {{through a set of}} motivating scenarios. 1...|$|R
