1|63|Public
40|$|Open {{integrated}} architectures such as AUTOSAR or IMA {{offer an}} increased modularity and flexibility over more established federated architectures. Using such a design, system developers can reuse and exchange applications and execution platforms more flexibly, as costs for migration and integration decrease. However, when developing {{systems that are}} safety-critical, the traditionally monolithic approach of safety engineering poses threats to the modularity {{that comes with the}} new architecture. In fact, the safety has to be re-evaluated and argued whenever the system changes. As a consequence, significant costs are incurred every time a component is reused or replaced, which decreases the desired flexibility of the open integrated architecture. To address this problem, this thesis introduces a technique that allows for the partial automation of the safety-related integration process. The technique is built of three components: The foundation of our approach is a model-based specification language allowing developers to define the conditions for the valid integration of platforms and applications. Our language follows a modular, contract based approach for the specification of demands and guarantees, which together form a safety interface between application and platform. The demands are specified by the application developer and define the safety-related behavior of the platform as required for the safe execution of the application. The guarantees, on the other hand, are specified by the platform developer and define the actual safety-related capabilities of the platform at hand. Based on this language, we define a mediation algorithm that is capable of automatically checking if the conditions specified in the safety interfaces are met for a given application-platform deployment. This automation decreases the effort for integrating safety-critical applications and platforms, which sustains the flexibility of the design. However, in order to perform the automated <b>integration</b> <b>check,</b> our mediation algorithm requires the deployment of applications and platforms as an input. To assist the integrator in identifying a valid deployment, we present an objective function for evaluating safety related deployment criteria as a third and final component of our solution approach...|$|E
40|$|Abstract. The {{embedded}} software industry clearly needs objective and reproducible means for early evaluation of software products. Formal methods can potentially fill the void, however industry is reluctant in applying these methods. In {{this study we}} investigate the difficulties that arise when integrating formal methods with the typical software engineering practice. More particular {{we look at the}} <b>integration</b> of model <b>checking</b> techniques in the requirement engineering and architecture design phases of the software development lifecycle. The results indicate some specific shortcomings of the currently available technology that prevent easy <b>integration</b> of model <b>checking</b> techniques in an industrial software development process...|$|R
40|$|International audienceWe are {{interested}} in the preservation of local properties of timed components during their integration in a timed system. Timed components are modeled as timed automata or timed automata with deadlines. Properties considered are all safety and liveness properties which can be expressed with the timed linear logic Mitl (Metric Interval Linear Logic), as well as non-zenoness and deadlock-freedom. Integration of components is a kind of incremental development which consists in checking locally the properties of the components, before integrating them in the complete system, using some composition operator. Of course, established properties have to be preserved by this <b>integration.</b> <b>Checking</b> preservation can be achieved by means of the verification of timed tau-simulation relations. Composability, compatibility and compositionality of these relations w. r. t. composition operators are properties which allow to reduce the cost of this verification. We examine these properties when integration is achieved with two different timed composition operators: the classic operator usually taken for timed systems and which uses a CSP-like composition paradigm, and a non-blocking operator closer to the CCS paradigm...|$|R
50|$|Funding {{options include}} {{automated}} funding through bank account,credit/debit card, and payroll deduction, and manual funding using those {{as well as}} cash and <b>check.</b> <b>Integration</b> with most major POS systems keeps FreedomPay Stored Value system adoption costs at a minimum.|$|R
30|$|After {{the patch}} is committed, the Mozilla <b>integration</b> server <b>checks</b> out the code from Mozilla-central, builds it for {{multiple}} platforms and runs automated tests. The whole process takes hours to complete, and developers who commit code to Mozilla-central {{are expected to}} wait and see if the build was successful and all tests pass. If this is the case, the developer should change the issue resolution to FIXED. Otherwise, the developer is expected to backout his commit. A backout that occurs before a successful build is called an early backout.|$|R
40|$|Modern {{medical imaging}} {{analyses}} often involve the concatenation of multiple steps, and neuroimaging analysis is no exception. The Java Image Science Toolkit (JIST) {{has provided a}} framework for both end users and engineers to synthesize processing modules into tailored, automatic multi-step processing pipelines (“layouts”) and rapid prototyping of module development. Since its release, JIST has facilitated substantial neuroimaging research and fulfilled much of its intended goal. However, key weaknesses must be addressed for JIST to more fully realize its potential and become accessible to an even broader community base. Herein, we identify three core challenges facing traditional JIST (JIST-I) and present the solutions {{in the next generation}} JIST (JIST-II). First, in response to community demand, we have introduced seamless data visualization; users can now click „show this data ‟ through the program interfaces and avoid the need to locating files on the disk. Second, as JIST is an open-source community effort by-design; any developer may add modules to the distribution and extend existing functionality for release. However, the large number of developers and different use cases introduced instability into the overall JIST-I framework, causing users to freeze on different, incompatible versions of JIST-I, and the JIST community began to fracture. JIST-II addresses the problem of compilation instability by performing continuous <b>integration</b> <b>checks</b> nightly to ensure community implemented changes do not negatively impact overall JIST-II functionality. Third, JIST-II allows developers and users to ensure that functionality is preserved by running functionality checks nightly using the continuous integratio...|$|R
30|$|The {{usage of}} a {{simulation}} environment preliminary to a waveform integration {{paves the way}} to target integration. In fact, simulation tools really help to hammer down misunderstandings and issues reducing integration risks. It {{is true that the}} differences of the simulation environment and the real operating environment need adjustment but the simulation environment step allows breaking down the overall integration in two levels: a) the initial <b>integration</b> to <b>check</b> the functional behavior and the interfacing between software components developed independently and b) target integration with real-time constraints. The positive experience of this approach can be reused as a working scheme to support the design of new SDR waveform developments.|$|R
40|$|The {{definition}} of software development methods encompasses the {{definition of}} syntax and static semantics of formal languages. These languages determine {{documents to be produced}} during the application of a method. Developers demand language-based tools that provide document production support, check syntax and static semantics of documents and thus implement methods. Method integration must determine inter-document consistency constraints between documents produced in the various tasks. Tools must, therefore, be integrated to implement the required method <b>integration</b> and <b>check</b> or even preserve inter-document consistency. The focus of this paper is on the specification of such integrated tools and outlines the main concepts of the object-oriented tool specification language GTSL...|$|R
5000|$|... 20-sim {{models can}} be {{simulated}} using {{state of the}} art numerical <b>integration</b> methods. After <b>checking</b> and processing, models are directly converted into machine code, resulting in high speed simulations. Unlike Simulink, simulation results are shown in 20-sim in a separate window called the Simulator. The simulator is versatile: plots can be displayed horizontally and vertically as time and frequency based plots and 3D animations.|$|R
40|$|Techniques {{and support}} {{software}} for the efficient performance of simulation validation are discussed. Overall validation software structure, the performance of validation at various levels of simulation <b>integration,</b> guidelines for <b>check</b> case formulation, methods for real time acquisition and formatting of data from an all up operational simulator, and methods and criteria for comparison and evaluation of simulation data are included. Vehicle subsystems modules, module integration, special test requirements, and reference data formats are also described...|$|R
40|$|The CMS Silicon Strip Tracker is {{the largest}} {{tracking}} system made of silicon devices ever built for a High Energy Physics experiment. Such a complex detector required a long period for the production and qualification of each component and a system test to verify that the expected performance is met. The Tracker Inner Barrel (TIB) is the central sub-detector consisting of four cylindrical layers centered around the beam pipe. The status of construction of the TIB will be described, focusing on the procedures defined to assemble the hardware components and on the tests performed during the <b>integration</b> to <b>check</b> for their functionality. The database system used to select components and keep track of them is also briefly described. The performance of a TIB subsystem read out with the final DAQ have been analysed in different operating conditions and preliminary results are presented...|$|R
40|$|The {{main goal}} of this work was an {{investigation}} of the dynamical stability of potential additional terres-trial planets in the habitable zone 1 (HZ) of systems in the solar neighbourhood (< 30 pc). Therefore we in-vestigated the long-term evolution of fictitious planets in the full three-body problem. We performed a para-metric study, where the gas giant’s eccentricity, semi-major axis and mass were varied as well as the mass and the inclination of the fictitious planets. We used straight forward numerical <b>integrations</b> and <b>checked</b> the stability {{with the help of the}} maximum eccentricty. Additionally we used the Relative Lyapunov Indica-tor (RLI) as a chaos indicator. The {{goal of this}} work is to investigate possible target systems of upcoming space missions in which already one extrasolar planet has been found. We will be able to exclude all systems in which no additional terrestrial planet can move on stable orbits inside the HZ. 1...|$|R
40|$|Abstract. One of {{the most}} {{important}} reasoning tasks on queries is checking containment, i. e., verifying whether one query yields necessarily a subset of the result of another one. Query containment, is crucial in several contexts, such as query optimization, query reformulation, knowledge-base verification, information <b>integration,</b> integrity <b>checking,</b> and cooperative answering. Containment is undecidable in general for Datalog, the fundamental language for expressing recursive queries. On the other hand, it is known that containment between monadic Datalog queries and between Datalog queries and unions of conjunctive queries are decidable. It is also known that containment between unions of conjunctive two-way regular path queries (UC 2 RPQs), which are queries used in the context of semistructured data models containing a limited form of recursion in the form of transitive closure, is decidable. In this paper we combine the automata-theoretic techniques at the base of these two decidability results to show that containment of Datalog in UC 2 RPQs is decidable in 2 EXPTIME. ...|$|R
40|$|Abstract. In {{the last}} 25 years, {{the notion of}} {{performing}} software verification with logic model checking techniques has evolved from intellectual curiosity to accepted technology with significant potential for broad practical application. In this paper we {{look back at the}} main steps in this evolution and illustrate how the challenges have changed over the years, as we sharpened our theories and tools. Next we discuss a typical challenge in software verification that we face today – and that perhaps we can look back on in another 25 years as having inspired the next logical step towards a broader <b>integration</b> of model <b>checking</b> into the software development process...|$|R
40|$|In {{this paper}} we discuss the {{exploration}} of a model checker's counterexample trace using model-based debugging techniques. We show that a diagnosis model obtained from a single counterexample run in an event-driven simulation is not appropriate for localizing a failures real cause in general. Notably, modeling VHDL's event and process semantics as originally defined hampers the integration of today's model checkers with our event-centered diagnosis approach considerably. Therefore, we propose a static but still event-centered and a data-driven approach for debugging hardware description languages. Both models do not exhibit the restrictions of the event-driven simulation approach with respect to <b>integration</b> of model <b>checking</b> tools...|$|R
50|$|Lemonade uses {{behavioral}} economics {{research to}} displace fraud and conflict while aligning interests to remove motivation for not paying claims {{and keeping the}} inclination to defraud an insurer in <b>check.</b> <b>Integration</b> of these principles are found in Lemonade’s policy purchase and claims processes, with users signing their name on a digital pledge of honesty {{at the start of}} the claims process - rather than the end - and speaking into a camera to file a claim rather than using forms. The company is also applying principles of behavioral science to itself, publishing articles on data surrounding customer growth, and bank account balances, among other topics.|$|R
40|$|This paper {{introduces}} {{an analysis}} and synthesis system (XS) which aids users in performing statistical analyses. In any large study, the dataset itself grows and changes dramatically over its life-course. Important datasets are often analyzed {{by many people}} over extended periods of time. Effective analysis of these large datasets depends to a large part in integrating past inferences and analytical decisions into current analyses. XS provides statistical expertise to answer current problems, but it also makes available the results of past analyses available for potential <b>integration</b> and consistency <b>checking.</b> In addition, XS permits the integration of knowledge outside {{the confines of the}} dataset with statistical results and user input in order to make analytical decisions...|$|R
40|$|Abstract — Knowledge {{generation}} from scientific database {{has received}} increasing attentions recently since huge repositories used {{for development of}} digital database and internet world. In a corpus of scientific database such as a digital library, scientific articles, scientific subject and so on. At present, the stored information is increasing tremendously day by day. The sudden increase {{in the amount of}} texts on the web, it was almost impossible for people to keep up-to-date information. Knowledge generation from textual database referred generally to the process of extracting interesting or non-retrieval patterns or knowledge from unstructured text documents. Using the technique such as information extraction, information retrieval, natural language processing, text mining can be easily found from the corpus of documents set. Knowledge generation in databases is the nontrivial process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data. The development of proposed work is the acquirization or selection of target data set, <b>integration</b> and <b>checking</b> of data set, data cleaning, preprocessing and development of transformation model and selection of algorithm which gives generated knowledge as result interpretation, visualization, testing, verification and maintenance. Text Mining is the automatic discovery of previously unknown information by extracting information from text...|$|R
40|$|One of {{the most}} {{important}} reasoning tasks on queries is checking containment, i. e., verifying whether one query yields necessarily a subset of the result of another one. Query containment is crucial in several contexts, such as query optimization, query reformulation, knowledge-base verification, information <b>integration,</b> integrity <b>checking,</b> and cooperative answering. Containment is undecidable in general for Datalog, the fundamental language for expressing recursive queries. On the other hand, it is known that containment between monadic Datalog queries and between Datalog queries and unions of conjunctive queries are decidable. It is also known that containment between unions of conjunctive two-way regular path queries, which are queries used in the context of semistructured data models containing a limited form of recursion in the form of transitive closure, is decidable. In this paper, we combine the automata-theoretic techniques at the base of these two decidability results to show that containment of Datalog in union of conjunctive two-way regular path queries is decidable in 2 EXPTIME. By sharpening a known lower bound result for containment of Datalog in union of conjunctive queries we show also a matching lower bound. (c) 2004 Elsevier B. V. All rights reserved...|$|R
40|$|Automated {{verification}} of distributed programs is a challenging problem. Since {{the behavior of}} a distributed program encompasses the behavior of the network, possible configurations of the network have to be investigated during verification. This leads to very large state spaces, and automated verification becomes infeasible. We present a framework that addresses this problem by decoupling the behavior of distributed programs from the behavior of the network. Our framework is based on a set of stub classes that replace native methods used in network communication and enables {{verification of}} distributed Java applications by isolating their behavior from the network. The framework supports two modes of verification: unit verification and integration verification. <b>Integration</b> verification <b>checks</b> multiple interacting distributed application components by running them in a single JVM and simulating the behavior of the network within the same JVM via stub classes. Unit verification targets a single component of a distributed application and requires that the user write an event generator class that utilizes the API exported by the framework. While unit verification only checks a single application component, it benefits from a greatly reduced state space compared do that of integration verification. 1...|$|R
40|$|AbstractOne of {{the most}} {{important}} reasoning tasks on queries is checking containment, i. e., verifying whether one query yields necessarily a subset of the result of another one. Query containment is crucial in several contexts, such as query optimization, query reformulation, knowledge-base verification, information <b>integration,</b> integrity <b>checking,</b> and cooperative answering. Containment is undecidable in general for Datalog, the fundamental language for expressing recursive queries. On the other hand, it is known that containment between monadic Datalog queries and between Datalog queries and unions of conjunctive queries are decidable. It is also known that containment between unions of conjunctive two-way regular path queries, which are queries used in the context of semistructured data models containing a limited form of recursion in the form of transitive closure, is decidable. In this paper, we combine the automata-theoretic techniques at the base of these two decidability results to show that containment of Datalog in union of conjunctive two-way regular path queries is decidable in 2 EXPTIME. By sharpening a known lower bound result for containment of Datalog in union of conjunctive queries we show also a matching lower bound...|$|R
40|$|The paper {{discusses}} {{the use of}} symbolic computation for model formulation, model <b>integration,</b> model <b>checking,</b> and model analysis. The zero dynamics {{plays an important role}} in the areas of modeling, analysis, and control of linear and nonlinear systems. The zero dynamics gives additional insight in the structure of the model employed and is an aid in modifying a model to satisfy some needs of the modeler. For nonlinear systems the analytical calculations to get the zero dynamics by paper and pencil may be quite involved. Symbolic computation has been used to overcome this difficulty. For a reasonable class of systems the computation can be performed without human aid or intervention, making the zero dynamics procedure a feasible and valuable addition to the toolbox of the modeler, analyst, or control system designer. For system models that are more than moderately complex symbolic computation cannot be fully enjoyed due to the complexity of parts of the algorithms that is (double) exponential in some measure of the problem size, or due to expression swell that cannot be easily eliminated. This implies that symbolic computation will not replace other tools, like those based on numerics, but will complement them...|$|R
40|$|The {{original}} publication can {{be found}} at www. springerlink. comMinimal change is a fundamental principle for modelling system dynamics. In this paper, we study the issue of minimal change for Computational Tree Logic (CTL) model update. We first consider five primitive updates which capture the basic update operations in the CTL model. Based on these primitive updates, we then define the minimal change criteria for CTL model update and develop formal algorithms that embed the underlying minimal change principle. We also present the well known microwave oven scenario to demonstrate our update algorithms. Our work presented in this paper can be viewed as the first formalization towards an <b>integration</b> of model <b>checking</b> and model updating for system modification. Yulin Ding and Yan Zhan...|$|R
40|$|In 1990, Germany {{began the}} reunification of two {{separate}} research systems. In this study, we explore the factors predicting the East-West integration of academic fields by examining the evolution of Germany's co-authorship network between 1974 and 2014. We find that the unification of the German research network accelerated rapidly during the 1990 s, but then stagnated at an intermediate level of integration. We then study {{the integration of the}} 20 largest academic fields (by number of publications prior to 1990), finding an inverted U-shaped relationship between each field's East or West "dominance" (a measure of the East-West concentration of a field's scholarly output prior to 1990) and the fields' subsequent level of <b>integration.</b> We <b>checked</b> for the robustness of these results by running Monte Carlo simulations and a differences-in-differences analysis. Both methods confirmed that fields that were dominated by either West or East Germany prior to reunification integrated less than those whose output was balanced. Finally, we explored the origins of this inverted U-shaped relationship by considering the tendency of scholars from a given field to collaborate with scholars from similarly productive regions. These results shed light on the mechanisms governing the reintegration of research networks that were separated by institutions. Comment: 24 pages, 11 figure...|$|R
40|$|The inverse {{relationship}} between the value of U. S. dollar and that of gold {{is one of the}} most talked about relationships in currency markets. The present study is an attempt to understand the impact of recession of 2008 on relationship between exchange rate of US dollar in INR and gold prices in India. The study uses Johansen Co- <b>Integration</b> test to <b>check</b> the long term association between exchange rate of US dollar in INR and gold prices in India and it further uses the Granger Causality Test to check the lead lag relationship between the variables. A separate pre, during and post recession analysis of the variables is done to understand the impact of recession on this relationship. The study highlights how this relationship has changed since the global turmoil. </div...|$|R
40|$|Subject guide 2. 0 {{is defined}} as those created by Web 2. 0 technologies. Some of its {{features}} include multimedia, multi-formats, collaboration, ease of use, global change, search box, browsing, link <b>checking,</b> <b>integration</b> with social bookmarking sites, RSS feed, tagging, interactivity, user input, blog or wiki, and statistics reporting. This paper discusses each feature in great detail. To help librarians who plan to create subject guides 2. 0, {{an overview of the}} tools is provided, covering LibGuides, open source software, blogs, wikis, and course management systems. The discussion includes pros and cons of each tool and how much subject guide 2. 0 features each tool can provide. By reading this paper, audience will know what subject guide 2. 0 is and the choices they have. 頁次： 90 - 98 </p...|$|R
40|$|The {{original}} publication can {{be found}} at www. springerlink. comComputational Tree Logic (CTL) model update is a new system modification method for software verification. In this paper, a case study is described to show how a prototype model updater is implemented based on the authors’ previous work of model update theoretical results [4]. The prototype is coded in Linux C and contains model checking, model update and parsing functions. The prototype is applied to the well known microwave oven example. This case study also illustrates some key features of our CTL model update approach such as the five primitive CTL model update operations and the associated minimal change semantics. This case study can be viewed as the first step towards the <b>integration</b> of model <b>checking</b> and model update for practical system modifications. Yulin Ding and Yan Zhan...|$|R
40|$|Several {{initiatives}} have offered personalized electronic services for digital library users. However, {{most of these}} services do not provide users with personalized shared Web environment, recommender system <b>integration,</b> Web link <b>checking</b> mechanism and tools that extend the functionality of Web browsers. MyLibrary at Los Alamos National Laboratory (LANL) provides digital library users (as individuals or groups) with a personalized Web environment while offering all these features. MyLibrary @LANL {{is the result of}} a project sponsored by LANL Research Library, which provides electronic services to LANL users (scientists, students, staff, external users, etc). This article explains the motivations for the design and development of the system, presents an overview of the MyLibrary @LANL initiative, summarizes MyLibrary's features, briefly discusses the technical solutions adopted, describes how the system is perceived by its users and addresses some of the directions for future developments of the product...|$|R
40|$|Model {{checking}} {{is usually}} applied at the design phase {{to verify that}} preliminary high–level design specifications conform to their requirements. Source code analysis, on the other hand, is used to check for correctness of implementation once it is realized from the design specifications. However, the current practice of validating a design and its implementation in isolation makes it necessary to employ rigorous testing analysis to empirically ensure that the implementation satisfies the design specification. This article describes a formal framework that allows design models to contain embedded partial implementations as components; these models are then formally analyzed to ensure that global requirements are satisfied. This framework can be utilized to incrementally develop and ensure correctness of the design and the corresponding implementation. Realization of this framework requires consolidation and expansion of traditional formal verification techniques by <b>integration</b> of model <b>checking,</b> program analysis and constraint solving. ...|$|R
40|$|Reasoning on queries is a {{basic problem}} both in {{knowledge}} representation and databases. A fundamental form of reasoning on queries is checking containment, i. e., verifying whether one query yields necessarily {{a subset of the}} result of another query. Query containment is crucial in several contexts, such as query optimization, knowledge base verification, information <b>integration,</b> database integrity <b>checking,</b> and cooperative answering. In this paper we address the problem of query containment in the context of semistructured knowledge bases, where the basic querying mechanism, namely regular path queries, asks for all pairs of objects that are connected by a path conforming to a regular expression. We consider conjunctive regular path queries with inverse, which extend regular path queries with the possibility of using both the inverse of binary relations, and conjunctions of atoms, where each atom specifies that one regular path query with inverse holds between two v [...] ...|$|R
40|$|While {{autonomous}} systems offer {{great promise}} {{in terms of}} capability and flexibility, their reliability is particularly hard to assess. This paper describes research {{in the use of}} model checking to support the development of reliable autonomy software. In particular, it presents tools and techniques that we are developing to facilitate the <b>integration</b> of model <b>checking</b> into the main software development cycle. The basic approach is to translate highlevel models used by autonomy systems into the specification language of the SMV model checker, verify them using SMV, translate diagnostics back to the source language and visualize and explain those diagnostics. This approach has been applied to MPL models for the Livingstone fault diagnosis system and to TDL task descriptions for mobile robot systems. 1 Introduction Autonomous systems rely on intelligent inference capabilities {{to be able to take}} appropriate actions even in unforeseen circumstances. They enable a whole range of new applic [...] ...|$|R
40|$|A {{big part}} of life long {{learning}} is the move from residential lectures to distance education. Distance education falls under the multi-modal policy of the teaching institution and thereby a change in student contact. The lecturer facilitating the distance education course is also faced with a problem where the quality and originality of submitted assignments need to be checked. This {{has always been a}} difficult task, as going through practical assignments and looking for similarities is a tedious job. Software checkers are available, but as yet, have not been integrated into popular online e-learning systems. If closer contact and warning to students are given at an early stage the problem is minimized as they know they are being closely monitored. As will be shown in this article, plagiarism is a current problem with online practical submissions. We will also show how this problem can be minimized through the <b>integration</b> of plagiarism <b>checking</b> tools and other checking methods into e-learning systems. 1...|$|R
40|$|UML {{has become}} the 'quasi' {{standard}} modeling language {{in a wide range}} of system domains, ranging from e-business to safety critical embedded systems, especially with the current trend in component-based system development. Various UML diagrams enable developers to specify various aspects of a system component, including component interfaces, their abstract/detailed behavior, and thus, the use of UML in a component-based system development methodology, known as KobrA. Nevertheless, the use of different UML diagrams introduces potential inconsistency problems. The iterative nature of the KobrA method is also subject to additional inconsistency issues at different levels of abstraction. In this paper, we define consistency problems in the context of component-based development with the KobrA method, and suggest a checking mechanism using environment modeling. Our approach emphasizes the <b>integration</b> of the <b>checking</b> mechanism into the development process and is general enough to be adapted towards other modeling approaches. We illustrate our checking approach with examples and demonstrate its automation using the SPIN model checker...|$|R
40|$|We {{propose a}} new method for view {{updating}} in deductive databases. The method {{is based on}} events and transition rules, which explicitly define the insertions and deletions induced by a database update. Using these rules, {{an extension of the}} SLDNF procedure allows us to obtain all valid translations of view update requests. The main advantages of the method are its simplicity, the uniform treatment of insert and delete requests and the <b>integration</b> of integrity <b>checking</b> during the derivation process. The method has the full power of the methods developed so far, without some of their limitations. 1. Introduction The view update problem of relational and deductive databases has attracted a lot of research during the past years [1, 2, 5, 6, 7, 8, 9, 11, 13, 16]. The aim is to provide effective methods for translating view updates into (correct) database updates. Two basic approaches have been proposed to solve the problem. The first suggests treating views as abstract data types, so that the defin [...] ...|$|R
40|$|Manyinteresting {{examples}} in view maintenance involve semijoin and outerjoin queries. In this paper we develop algebraic change propagation algorithms {{for the following}} operators: semijoin, anti-semijoin, left outerjoin, right outerjoin, and full outerjoin. 1 Motivation View maintenance algorithms are important for data warehouses, database <b>integration,</b> and e#cient <b>checking</b> of integrity constraints #BLT 86, CGL + 96, GL 95, GLT 97, GJM 97, GMS 93, HZ 96, QW 91, RSS 96, ZGHW 95, QGMW 96 #. Many practical examples of view maintenance involve semijoin and outerjoin queries. Algorithms for incremental maintenance of such queries was presented by Gupta et. al in #GJM 97 #. That paper presented procedural algorithms, but left open as a challenge their algebraic formulation {{in the style of}} Gri#n et. al #GL 95,GLT 97 #. In this paper we develop algebraic change propagation algorithms for the following operators: semijoin, anti-semijoin, left outerjoin, right outerjoin, and full outerjoin. There are severa [...] ...|$|R
40|$|AbstractTo {{understand}} {{the behavior of}} difference schemes on nonlinear differential equations, it seems desirable to extend the standard linear stability theory into a nonlinear theory. As a step in that direction, we investigate the stability properties of Euler-related <b>integration</b> algorithms by <b>checking</b> how they preserve and violate the dynamical structure of the logistic differential equation. Among the schemes considered are two linearly implicit nonstandard schemes which are adjoint to each other. We find that these schemes are superior to explicit schemes when they are stable and the blow-up time has not passed: for these λh-values they are dynamically faithful. When these schemes ‘turn unstable’, however, they have much less desirable properties than explicit or fully implicit schemes: they become simultaneously superstable and unstable. This is {{explained by the fact}} that these schemes are not self-adjoint: the linearly implicit self-adjoint scheme is dynamically faithful in an Euler-typical range of step sizes and gives correct stability for all step sizes...|$|R
