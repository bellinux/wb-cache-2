35|680|Public
40|$|Camera {{calibration}} {{methods are}} commonly evaluated on cumulative reprojection error metrics, on disparate one-dimensional da-tasets. To evaluate calibration of cameras in two-dimensional arrays, assessments {{need to be}} made on two-dimensional datasets with constraints on camera parameters. In this study, accuracy of several multi-camera calibration methods has been evaluated on camera parameters that are affecting view projection the most. As input data, we used a 15 -viewpoint two-dimensional dataset with intrinsic and <b>extrinsic</b> <b>parameter</b> constraints and extrinsic ground truth. The assessment showed that self-calibration methods using structure-from-motion reach equal intrinsic and <b>extrinsic</b> <b>parameter</b> estimation accuracy with standard checkerboard calibration algorithm, and surpass a well-known self-calibration toolbox, BlueCCal. These results show that self-calibration is a viable approach to calibrating two-dimensional camera arrays, but improvements to state-of-art multi-camera feature matching are necessary to make BlueCCal as accurate as other self-calibration methods for two-dimensional camera arrays...|$|E
40|$|This paper {{presents}} an improvement for an automatic <b>extrinsic</b> <b>parameter</b> calculation between a monocular camera and single line laser range finder. The {{focus of this}} work is a further reduction of calibration errors compared to other existing methods, and the unique and automatic identification and detection of a calibration object under usage of the remission measurements of the laser scanner data. The use of the remission measurements leads to a reduction of the edge effect, which leads to error measurements {{at the edges of}} a measured object, if distance measurements are used exclusively. Further, the usage of the remission measurements enables the unique identification of a new calibration object with a significant remission signature. The result is an automatic <b>extrinsic</b> <b>parameter</b> calculation which works reliably with a high accuracy. The performance of the proposed method was verified in simulation and experiments. In order to classify the results of simulation and experiments, they were compared to other existing methods...|$|E
40|$|Abstract: The pose {{measurement}} of cannon barrel (vertical angle and azimuth angle) is a difficulty and {{emphasis in the}} precision analysis of SPAAG fire control system. To solve this problem, this paper presents a contactless measuring method based on computer vision. Before measurement, fix a checked planar faceplate on the cannon barrel as a marker. Firstly, get the coordinate of X corner points using Harris Corner Detection Algorithm to calibrate the camera, and chalk up the camera’s intrinsic parameters based on Extended Kalman Filter. Secondly, get the corner points from the image of test position, then calculate the <b>extrinsic</b> <b>parameter</b> matrix of the corresponding position combining with LSE algorithm. Finally, according to the motion model of cannon barrel and the position relative to the marker, derive the constraint equations between <b>extrinsic</b> <b>parameter</b> and vertical angle and azimuth angle, then figure out the two angles. Experiment validate the maneuverability and veracity of this method, and {{the results indicate that}} the measuring precision of this method is less than 1 mil...|$|E
30|$|The system {{calibration}} procedure has three steps: (1) computing <b>extrinsic</b> <b>parameters</b> (RL, TL) {{of the left}} pair; (2) computing the relationship (R 0, T 0) between the left camera coordinate system and right camera coordinate system; and (3) determining the <b>extrinsic</b> <b>parameters</b> of the right pair. Parameters RL, TL, R 0, and T 0 are already known from a previous calibration process, and hence <b>extrinsic</b> <b>parameters</b> (RR, TR) of the right pair is determined.|$|R
40|$|Multi camera systems become {{increasingly}} important in computer vision. For many applications, however, the system has to be calibrated, i. e. the intrinsic and <b>extrinsic</b> <b>parameters</b> of the cameras have to be determined. We present a method for calibrating the <b>extrinsic</b> <b>parameters</b> without any scene knowledge or user interaction. In particular, we assume known intrinsic parameters and one image from each camera as input...|$|R
40|$|Fusion of {{heterogeneous}} extroceptive sensors is {{the most}} effient and effective way to representing the environment precisely, as it overcomes various defects of each homogeneous sensor. The rigid transformation (aka. <b>extrinsic</b> <b>parameters)</b> of heterogeneous sensory systems should be available before precisely fusing the multisensor information. Researchers have proposed several approaches to estimating the <b>extrinsic</b> <b>parameters.</b> These approaches require either auxiliary objects, like chessboards, or extra help from human to select correspondences. In this paper, we proposed a novel extrinsic calibration approach for the extrinsic calibration of range and image sensors. As far as we know, {{it is the first}} automatic approach with no requirement of auxiliary objects or any human interventions. First, we estimate the initial <b>extrinsic</b> <b>parameters</b> from the individual motion of the range finder and the camera. Then we extract lines in the image and point-cloud pairs, to refine the line feature associations by the initial <b>extrinsic</b> <b>parameters.</b> At the end, we discussed the degenerate case which may lead to the algorithm failure and validate our approach by simulation. The results indicate high-precision extrinsic calibration results against the ground-truth...|$|R
40|$|An {{extraction}} {{method for}} small-signal model parameters of Silicon-on-Insulator (SOI) MOS transistors is presented. This technique allows {{to obtain the}} intrinsic and <b>extrinsic</b> <b>parameter</b> values for a high frequency small-signal model directly from scattering parameter measurements. Only two sets of measured S-parameters are required, one set in the zero-bias condition at relatively high frequency to obtain values of series parasitic elements (RG, RD and R S) {{and the other in}} the frequency band and the bias conditions of interest to determine the parallel elements of the equivalent circuit...|$|E
40|$|A new FET <b>extrinsic</b> <b>parameter</b> {{extraction}} {{method is}} proposed, {{in which all}} the extrinsic elements can be determined directly from the S-parameters at pinch-off bias. It utilizes the measurement data of various gate-width FET's and the simple scaling property of each equivalent circuit parameters, eliminating some complex measurement steps such as forward gate bias measurement. Since the gate-width scaling characteristics are taken into account, the proposed method can be utilized for the MMIC design where the optimization of the FET gate-width is important. The proposed method was successfully applied to the modeling of 0. 25 um GaAs P-HEMT...|$|E
40|$|A new {{extrinsic}} {{network and}} <b>extrinsic</b> <b>parameter</b> extraction methodology is developed for high power RF LDMOS transistor modeling. This new method uses accurate manifold deembedding using electromagnetic simulation, and optimization of the extrinsic network parameter values over a broad frequency range. The new extrinsic network accommodates feedback effects which are observed in high power transistors. This improved methodology {{allows us to}} achieve a good agreement between measured and modeled S-parameters in the frequency range of 0. 5 to 6 GHz for different bias conditions. Large-signal verification of this new model shows a very good match with measurements at 2. 14 GHz. © 2008 IEEE...|$|E
3000|$|... are <b>extrinsic</b> <b>parameters</b> {{describing}} {{the attitude of}} the camera in the scene with respect to a reference coordinate system.|$|R
3000|$|... we {{recover the}} {{remaining}} <b>extrinsic</b> <b>parameters</b> of the i th image aligning the camera principal direction to d [...]...|$|R
30|$|The <b>extrinsic</b> <b>parameters</b> of {{the left}} pair are {{calibrated}} using a unique world coordinate system for the two cameras and the projector. The intrinsic parameters of the projector and left camera have already been calibrated using a calibration plate with discrete markers on the surface, as described in Section 2 B. The <b>extrinsic</b> <b>parameters</b> are computed using the same coordinate position of the calibration plate to guarantee {{they are in the}} same world coordinate system.|$|R
40|$|Let V 0 be {{a smooth}} and compact real variety {{given by a}} reduced regular {{sequence}} of polynomials f 1, [...] ., fp. This paper {{is devoted to the}} algorithmic problem of finding efficiently for each connected component of V 0 a representative point. For this purpose we exhibit explicit polynomial equations which describe for generic variables the polar varieties of V 0 of all dimensions. This leads to a procedure which solves our algorithmic problem in time that is polynomial in the (extrinsic) description length of the input equations f 1, [...] ., fp and in a suitably introduced geometric (<b>extrinsic)</b> <b>parameter,</b> called the degree of the real interpretation of the given equation system f 1, [...] ., fp...|$|E
40|$|Vanishing {{points of}} an image contain {{important}} information for camera calibration. Various calibration techniques have been introduced using the properties of vanishing points to find intrinsic and extrinsic calibration parameters. This pa-per revisits the vanishing points geometry and suggests a simple <b>extrinsic</b> <b>parameter</b> estimation algorithm which uses a single rectangle. The comparison with the Camera Cali-bration Toolbox for Matlab ® shows that the proposed algo-rithm is highly competitive. The suggested technique is also applied to a realtime pose estimation for an unmanned air vehicle’s navigation in an urban environment. We present a realtime vanishing point extraction algorithm and a pose estimation procedure. The experimental result on a real flight video clip is presented. 1...|$|E
40|$|Let $V_ 0 $ be {{a smooth}} and compact real variety {{given by a}} reduced regular {{sequence}} of polynomials $f_ 1, [...] ., f_p$. This paper {{is devoted to the}} algorithmic problem of finding efficiently for each connected component of $V_ 0 $ a representative point. For this purpose we exhibit explicit polynomial equations which describe for generic variables the polar varieties of $V_ 0 $ of all dimensions. This leads to a procedure which solves our algorithmic problem in time that is polynomial in the (extrinsic) description length of the input equations $f_ 1, [...] .,f_p$ and in a suitably introduced geometric (<b>extrinsic)</b> <b>parameter,</b> called the degree of the real interpretation of the given equation system $f_ 1, [...] .,f_p$...|$|E
40|$|Abstract—In this paper, we {{describe}} {{a method to}} photogrammetrically estimate the intrinsic and <b>extrinsic</b> <b>parameters</b> of fish-eye cameras using the properties of equidistance perspective, particularly vanishing point estimation, {{with the aim of}} providing a rectified image for scene viewing applications. The estimated intrinsic parameters are the optical center and the fish-eye lensing <b>parameter,</b> and the <b>extrinsic</b> <b>parameters</b> are the rotations about the world axes relative to the checkerboard calibration diagram. Index Terms—Fish-eye, calibration, perspective...|$|R
3000|$|... where <b>extrinsic</b> <b>parameters</b> are {{expressed}} by the 3 × 3 rotation matrix R and by the 1 × 3 translation vector T.|$|R
5000|$|There {{are many}} {{different}} approaches to calculate the intrinsic and <b>extrinsic</b> <b>parameters</b> for a specific camera setup. The most common ones are: ...|$|R
40|$|Time-of-Flight camera {{can help}} a service robot to sense its 3 D {{environment}}. The modeled environment information {{can be used by}} motion planning algorithms to plan a collision free movement for the robot, or by grasp planning algorithms to find feasible grasps for an a priori unknown object in the scene. To guarantee that the models used by the planning algorithms are consistent with the real world, calibration of the Time-of-Flight camera is necessary. In this article the intrinsic and <b>extrinsic</b> <b>parameter</b> calibration procedures applied in the DESIRE project are presented. A segmentation using GPU calculation is used to seperate the sensed model and a priori information of the environment. We use a motion planning algorithm based on Probabilistic Road to plan collision free movement for DESIRE platform...|$|E
30|$|A dual camera-one {{projector}} {{structured light}} system has been developed to avoid the camera occlusions of a single-camera system. A method to simplify the calibration for dual-camera structured illumination profiling system is proposed to decrease the number of captured images. For the method, the left camera-projector pair is firstly calibrated. Then, the parameters of both cameras are determined. Subsequently, {{the relationship between the}} projector and the right camera is calculated according to the results from the previous steps. Finally, 3 D results from both views are merged by the variant ICP (Iterative Closest Point) algorithm to enlarge the measuring range after giving it an initial estimate obtained by the <b>extrinsic</b> <b>parameter</b> calibration results. Five criteria have been proposed to reject outliers and invisible data automatically at each iterative step. Experiments show the performance of the proposed calibration method.|$|E
40|$|In this paper, {{we present}} a new fully {{automatic}} method for the geometric calibration of a video projector combining structured light projection and a RGBD camera. The projection surface {{does not need to}} be planar and is supposed to be unknown. Intrinsic and <b>extrinsic</b> <b>parameter</b> are computed without a scale factor uncertainty or any prior knowledge about the projector. Our method is based on the Heikkila’s camera calibration algorithm. It combines Gray coded structured light patterns and a RGBD camera. While the structured light gives pixel to pixel correspondences between the projector and the camera, the depth map provides the 3 D coordinates of the projected points. Couples of pixel coordinates and their corresponding 3 D coordinates are established and used as input for the Heikkila’s algorithm. The implementation has given conclusive results. The calibration is used to reproject information from the RGBD camera in real-time...|$|E
3000|$|..., {{which are}} {{determined}} {{only by the}} <b>extrinsic</b> <b>parameters</b> of the onboard camera, as the estimated position of the vanishing point and use variance [...]...|$|R
5000|$|... are the <b>extrinsic</b> <b>parameters</b> which {{denote the}} {{coordinate}} system transformations from 3D world coordinates to 3D camera coordinates. Equivalently, the <b>extrinsic</b> <b>parameters</b> define {{the position of}} the camera center and the camera's heading in world coordinates. [...] is {{the position of the}} origin of the world coordinate system expressed in coordinates of the camera-centered coordinate system. [...] is often mistakenly considered the position of the camera. The position, , of the camera expressed in world coordinates is [...] (since [...] is a rotation matrix).|$|R
3000|$|This paper {{presents}} a new algorithm for extrinsically calibrating a multi-sensor system including multiple cameras and a 2 D laser scanner. On {{the basis of}} the camera pose estimation using AprilTag, we design an AprilTag array as the calibration target and employ a nonlinear optimization to calculate the single-camera <b>extrinsic</b> <b>parameters</b> when multiple tags are in the field of view of the camera. The <b>extrinsic</b> <b>parameters</b> of camera–camera and laser–camera are then calibrated, respectively. A global optimization is finally used to refine all the <b>extrinsic</b> <b>parameters</b> by minimizing a re-projection error. This algorithm is adapted to the extrinsic calibration of multiple cameras even if there is non-overlapping field of view. For algorithm validation, we have built a micro-aerial vehicle platform with multi-sensor system to collect real data, and the experiment results confirmed that the proposed algorithm yields great performance.|$|R
40|$|Abstract — Oblique-viewing {{endoscopes}} (oblique scopes) {{are widely}} used in minimally invasive surgery. The viewing direction of an oblique endoscope can be changed by rotating the scope cylinder, which enables a larger field of view, but makes the scope calibration process more difficult. The calibration is a critical step for incorporating oblique scope into computer assisted surgical procedures (robotics, navigation, augmented reality), though few calibration methods of oblique endoscopes has been developed. Yamaguchi et al. [1] first modelled and calibrated the oblique scope. They directly tracked the camera head and formulated the scope cylinder’s rotation to the camera model as an <b>extrinsic</b> <b>parameter.</b> Their method requires five additional parameters to be estimated. In this work, we track the scope cylinder instead. Since {{the rotation of the}} camera head with respect to the cylinder only causes the rotation of the image plane, less parameter needs to be estimated. Experiments demonstrate the ease, simplicity and accuracy of our method. I...|$|E
40|$|Zinc oxide (ZnO) is a {{versatile}} material having various applications in different disciplines. ZnO {{is an excellent}} alternative for TiO 2 for the photodegradation of environmental pollutants. However, pure ZnO has some drawbacks, which limits photodegradation applications. ZnO photocatalytic activity {{is limited to the}} UV region. Moreover, ZnO gets agglomerated in aqueous media. To overcome such defects, some strategies have been suggested. For instance, simultaneous doping and usage of a suitable surface modifier changes the surface chemistry of ZnO. This chapter reviews the tailoring characteristics of ZnO through doping and surface modification. Synthesis is described with emphasis on the hydrothermal technique. The importance of organic pollutants such as azo dyes and industrial pollutants are discussed. We also review the characterization of nanomaterials, using for example powder X-ray diffraction, Fourier transmission infrared spectra, scanning electron microscopy, zeta potential, UV-Vis spectroscopy, and dynamic light scattering. Moreover, different intrinsic and <b>extrinsic</b> <b>parameter</b> affecting fabrication and application of nanomaterials are explained in detail...|$|E
40|$|Abstract—Stereo {{vision is}} useful {{for a variety of}} {{robotics}} tasks, such as navigation and obstacle avoidance. However, recovery of valid range data from stereo depends on accurate calibration of the extrinsic parameters of the stereo rig, i. e., the 6 -DOF transform between the left and right cameras. Stereo selfcalibration is possible, but, without additional information, the absolute scale of the stereo baseline cannot be determined. In this paper, we formulate stereo <b>extrinsic</b> <b>parameter</b> calibration as a batch maximum likelihood estimation problem, and use GPS measurements to establish the scale of both the scene and the stereo baseline. Our approach is similar to photogrammetric bundle adjustment, and closely related to many structure from motion algorithms. We present results from simulation experiments using a range of GPS accuracy levels; these accuracies are achievable by varying grades of commercially-available receivers. We then validate the algorithm using stereo and GPS data acquired from a moving vehicle. Our results indicate that the approach is promising. I...|$|E
30|$|If {{both the}} {{intrinsic}} and <b>extrinsic</b> <b>parameters</b> {{of the camera}} setup are known, the resulting reconstruction is called Euclidean, that is, the reconstruction is metric.|$|R
40|$|ACCV 2006 : 7 th Asian Conference on Computer Vision, Jan 13 - 16, 2006, Hyderabad, IndiaThis paper {{describes}} a novel method for estimating <b>extrinsic</b> camera <b>parameters</b> using both feature points on an image sequence and sparse position data acquired by GPS. Our method {{is based on}} a structure-from-motion technique but is enhanced by using GPS data so as to minimize accumulative estimation errors. Moreover, the position data are also used to remove mis-tracked features. The proposed method allows us to estimate <b>extrinsic</b> <b>parameters</b> without accumulative errors even from an extremely long image sequence. The validity of the method is demonstrated through experiments of estimating <b>extrinsic</b> <b>parameters</b> for both synthetic and real outdoor scenes...|$|R
40|$|Abstract — This study {{describes}} {{a method of}} estimating the intrinsic parameters of a perspective camera. In previous calibration methods for perspective cameras, the intrinsic and <b>extrinsic</b> <b>parameters</b> are estimated simultaneously during calibration. Thus, the intrinsic parameters depend on the estimation of the <b>extrinsic</b> <b>parameters,</b> which is inconsistent {{with the fact that}} intrinsic parameters are independent of extrinsic ones. Moreover, in a situation where the <b>extrinsic</b> <b>parameters</b> are not used, only the intrinsic parameters need to be estimated. In this case, an intrinsic parameter, such as focal length, is not sufficiently robust to combat the image processing noise, that is absorbed by both parameter types, during calibration. We therefore propose a new method that allows the estimation of intrinsic parameters without estimating the <b>extrinsic</b> <b>parameters.</b> In order to calibrate the intrinsic parameters, the proposed method observes parallel light pairs that are projected on different points. This is accomplished by applying the constraint that the relative angle of two parallel rays is constant irrespective of where the rays are projected. This method focuses only on intrinsic parameters and the calibrations are sufficiently robust as demonstrated in this study. Moreover, our method can visualize the error of the calibrated result and the degeneracy of the input data. I...|$|R
40|$|This paper {{describes}} the design, build, automatic self-calibration and eval-uation of a 3 D Laser sensor using conventional parts. Our {{goal is to}} design a system, which is {{an order of magnitude}} cheaper than commercial sys-tems, with commensurate performance. In this paper we adopt point cloud “crispness ” as the measure of system performance that we wish to optimise. Concretely, we apply the information theoretic measure known as Rényi Quadratic Entropy to capture the degree of organisation of a point cloud. By expressing this quantity as a function of key unknown system param-eters, we are able to deduce a full calibration of the sensor via an online optimisation. Beyond details on the sensor design itself, we fully describe the end-to-end <b>extrinsic</b> <b>parameter</b> calibration process, the estimation of the clock skews between the four constituent microprocessors and analyse the effect our spatial and temporal calibrations have on point cloud quality. 1 Introduction and Related wor...|$|E
40|$|The aim of {{this letter}} is to {present {{analytical}} method to} quantitatively address {{the influence of a}} focusing illumination on the transmission /reflection properties of a {metasurface illuminated by a finite-size beam}. In fact, most theoretical and numerical studies are performed by considering an infinite periodic structure illuminated by a plane wave. In practice, one deals with a finite-size illumination and structure. Combination of the angular spectrum expansion with a monomodal modal method is performed to determine the beam size needed to acquire efficient properties of a Metasurface that behaves as Anisotropic Plate MAP Interesting results show that the beam-size can be as small as 5 X 5 periods to recover the results of a plane wave. Other results also show that the beam-size could be used as an <b>extrinsic</b> <b>parameter</b> to enhance the MAP performance and to finely adjust its expected properties (birefringence and/or transmission coefficient). Comment: 13 pages, five figures, Paper under submissio...|$|E
40|$|Catastrophic {{failure of}} {{materials}} and structures due to unstable crack growth could be prevented if facture toughness could be enhanced at will through structural design, but {{how can this be}} possible if fracture toughness is a material constant related to energy dissipation in the vicinity of a propagating crack tip. Here we draw inspiration from the deformation behavior of biomolecules in load bearing biological materials, which have been evolved with a large extensibility and a high breaking strength beyond their elastic limit, and introduce an effective biomimetic strategy to enhance fracture toughness of a structure through an intrinsic to extrinsic (ITE) transition. In the ITE transition, toughness starts as an intrinsic parameter at the basic material level, but by designing a protein-like effective stress-strain behavior the toughness at the system level becomes an <b>extrinsic</b> <b>parameter</b> that increases with the system size without bound. This phenomenon is demonstrated through a combination of numerical simulations, analytic modeling and experiments, and leads to a biomimetic strategy which can be broadly adopted to enhance fracture toughness in engineering systems...|$|E
3000|$|... [...]. We aim at {{calculating the}} {{received}} {{power as a}} function of all intrinsic and <b>extrinsic</b> <b>parameters</b> of the imaging system, comprising light source, medium and receiver.|$|R
3000|$|... as a {{function}} of all intrinsic and <b>extrinsic</b> <b>parameters</b> (optical constants, area and angular field of view of the receiver, etc.), we need to provide a suitable expression for [...]...|$|R
30|$|Finally, {{from the}} known {{intrinsic}} and <b>extrinsic</b> <b>parameters</b> of our stereoscopic system, the 3 D coordinates of {{a cloud of}} points laying at the surface were computed as explained above.|$|R
