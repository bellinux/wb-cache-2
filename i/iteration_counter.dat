71|10|Public
5000|$|Set <b>iteration</b> <b>counter</b> , {{and make}} an initial guess [...] for the minimum ...|$|E
5000|$|... shared: {{the data}} within a {{parallel}} region is shared, which means visible and accessible by all threads simultaneously. By default, all {{variables in the}} work sharing region are shared except the loop <b>iteration</b> <b>counter.</b>|$|E
5000|$|... where [...] is the <b>{{iteration}}</b> <b>counter.</b> As the iteration converges and , {{the terms}} from the coarse method cancel out and Parareal reproduces the solution that is {{obtained by the}} serial execution of the fine method only.It can be shown that Parareal converges after a maximum of [...] iterations.For Parareal to provide speedup, however, it has to converge {{in a number of}} iterations significantly smaller than the number of time slices, that is [...]|$|E
3000|$|..., {{which is}} the peak {{amplitude}} of the zero phase pilot symbols and the <b>iteration</b> <b>counters</b> t (total number of iterations) and [...]...|$|R
5000|$|... private: {{the data}} within a {{parallel}} region is private to each thread, which means each thread {{will have a}} local copy {{and use it as}} a temporary variable. A private variable is not initialized and the value is not maintained for use outside the parallel region. By default, the loop <b>iteration</b> <b>counters</b> in the OpenMP loop constructs are private.|$|R
40|$|International audienceTwo {{types of}} {{physical}} attacks are considered as important threats for embedded crypto-processors: observation attacks (or side channel attacks) and perturbation attacks (or fault injection attacks). In this work, {{we focus on}} protections against both types of attacks simultaneously for scalar multiplication in elliptic curve cryptography (ECC). A common protection against fault attacks on ECC is to verify if the current egular scalar multiplication using verifications at various frequency checking for some coordinate types. To protect the scalar, we added various methods based on <b>iteration</b> <b>counters.</b> We combined and tested these two countermeasures on different coordinates types for Weierstrass curves...|$|R
5000|$|... 1. mu:=-6; sigma2:=100; t:=0; maxits=100; // Initialize {{parameters}} 2. N:=100; Ne:=10; // 3. while t < maxits and sigma2 > epsilon // While maxits {{not exceeded}} and not converged 4. X = SampleGaussian(mu,sigma2,N); // Obtain N samples from current sampling distribution 5. S = exp(-(X-2)^2) + 0.8 exp(-(X+2)^2); // Evaluate objective function at sampled points 6. X = sort(X,S); // Sort X by objective function values (in descending order) 7. mu = mean(X(1:Ne)); sigma2=var(X(1:Ne)); // Update parameters of sampling distribution 8. t = t+1; // Increment <b>iteration</b> <b>counter</b> 9. return mu // Return mean of final sampling distribution as solution ...|$|E
30|$|Set {{generation}} counter T= 1, <b>iteration</b> <b>counter</b> in {{each generation}} M= 0.|$|E
30|$|Initialize {{probability}} of crossover p_c, {{probability of}} mutation p_m, upper limit of <b>iteration</b> <b>counter</b> M_ 0, population size N.|$|E
40|$|Application of process-based models {{beyond the}} {{research}} commu-nity has been limited, {{in part because}} they do not operate in an in-tuitive graphical user-friendly environment. This article describes the procedure of adapting a spatially explicit biological-process model, MAESTRA (Multi-Array Evaporation Stand Tree Radiation A), to run in a standard graphical user interface (GUI). The methods used to adapt the MAESTRA model are generally applicable to other indi-vidual tree process-based models and, therefore, should simplify other coupling attempts. The three primary changes to MAESTRAwere the placement of the MAESTRA code inside a Microsoft Windows API (application programming interface) function called WINMAIN, rear-rangement of the input file structure to fit the hierarchical file structure used by the Graphical User Interface for Crop Simulations (GUICS), and the addition of <b>iteration</b> <b>counters</b> to read array-based data read fo...|$|R
25|$|Loop {{counters}} {{change with}} each iteration of a loop, providing a unique value {{for each individual}} <b>iteration.</b> The loop <b>counter</b> is used to decide when the loop should terminate and for the program flow to continue to the next instruction after the loop.|$|R
40|$|International audienceThe most {{efficient}} branch predictors proposed in academic literature exploit both global branch history and local history. However, local history predictors introduce major design challenges, {{particularly for the}} management of speculative histories. The wormhole (WH) branch predictor was recently introduced to exploit branch outcome correlation via multidimensional histories. For some branches encapsulated in a multidimensional loop, their outcomes are correlated with those of the same branch in neighbor iterations, but in the previous outer loop iteration. Unfortunately, the practical implementation of the WH predictor is even more challenging than the implementation of local history predictors. In this paper, we introduce a practical, cost-effective mechanism for capturing multidimensional branch correlations: the Inner Most Loop <b>Iteration</b> (IMLI) <b>counter...</b>|$|R
30|$|Step 1 : Set {{the maximum}} level of system power {{security}} violation under {{the worst-case scenario}} ε^RO and the <b>iteration</b> <b>counter</b> k =  1.|$|E
30|$|Step 3.4 The {{solutions}} are ranked {{according to their}} objective values, then the best solution is assigned. The <b>iteration</b> <b>counter</b> increases (Lines 16 – 18).|$|E
3000|$|Exploration Search (Inner Loop). Repeat this {{inner loop}} steps until a {{predefined}} number of consecutive inner iterations fail to obtain improvement or the inner loop <b>iteration</b> <b>counter</b> exceeds a predefine maximum number.|$|E
40|$|This {{technical}} report explores workload characterization using processor hardware counter sampling. We {{assume that we}} are measuring a set of hardware counter events greater {{than the number of}} physical counters on the processor, i. e., the counters are set to measure different events after every measurement. We characterize workloads on typical time scales between 5 and 30 minutes, with different phasing properties. We evaluate two competing strategies, a short sample time strategy designed to minimize overhead and a long sample time strategy designed to get better averaging. We find that both strategies are likely to produce accurate results, independent of underlying workload phasing, but neither strategy is ideal. We find that the optimal strategy is a fairly short sample time combined with continuous <b>iteration</b> over the <b>counter</b> set...|$|R
40|$|International audienceThe most {{efficient}} branch predictors proposed in academic literature exploit both global branch history and local branch history. However, local history branch predictor components introduce major design challenges, {{particularly for the}} management of speculative histories. Therefore, most effective hardware designs use only global history components and very limited forms of local histories such as a loop predictor. The wormhole (WH) branch predictor was recently introduced to exploit branch outcome correlation in multidimen-sional loops. For some branches encapsulated in a multidi-mensional loop, their outcomes are correlated with those of the same branch in neighbor iterations, but in the previous outer loop iteration. Unfortunately, the practical implementation of the WH predictor is even more challenging than the implementation of local history predictors. In this paper, we introduce practical predictor components to exploit this branch outcome correlation in multidimen-sional loops: the IMLI-based predictor components. The iteration index of the inner most loop in an application can be efficiently monitored at instruction fetch time using the Inner Most Loop <b>Iteration</b> (IMLI) <b>counter.</b> The outcomes of some branches are strongly correlated with the value of this IMLI counter. A single PC+IMLI counter indexed table, the IMLI-SIC table, added to a neural component of any recent predictor (TAGE-based or perceptron-inspired) captures this correlation. Moreover, using the IMLI counter, one can efficiently manage the very long local histories of branches that are targeted by the WH predictor. A second IMLI-based component, IMLI-OH, allows for tracking the same set of hard-to-predict branches as WH. Managing the speculative states of the IMLI-based pre-dictor components is quite simple. Our experiments show that augmenting a state-of-the-art global history predictor with IMLI components outperforms previous state-of-the-art academic predictors leveraging local and global history at much lower hardware complexity (i. e., smaller storage budget, smaller number of tables and simpler management of speculative states) ...|$|R
40|$|Traditional Serial-Serial {{multiplier}} {{addresses the}} high data sampling rate. It is effectively considered {{as the entire}} partial product matrix with n data sampling cycle for n×n multiplication function instead of 2 n cycles in the conventional multipliers. The existing Serial-Serial multiplier is the first bit serial structure. Newly developed serial-serial multiplier design is capable of processing input data at (GBs) without buffering and with reduced total number of computational cycle. This multiplication of partial products by considering two series inputs among which one is starting from LSB the other from MSB. Using this feed sequence and accumulation technique it takes only n cycle to complete the partial products. It achieves high bit sampling rate by replacing conventional full adder and highest 5 : 3 counters. Here asynchronous 1 ’s counter is presented. This counter takes critical path is limited to only an AND gate and D flip-flops. Accumulation is integral part of serial multiplier design. 1 ’s counter is used to {{count the number of}} ones {{at the end of the}} nth <b>iteration</b> in each <b>counter</b> produces. The proposed multiplier consists of a serial-serial data accumulator module and carries save adder that occupies less silicon area than the full carry save adder. In this paper we proposed model address for the 8 bit 2 ’s complement implementing the Baugh-wooley algorithm and unsigned multiplication implementing the proposed architecture for 8 × 8 Serial-Serial unsigned multiplication. We can able to extend the 16 bit multiplication...|$|R
3000|$|... where {{superscript}} i is the <b>iteration</b> <b>counter.</b> Steps (18) and (20) {{are completely}} decentralized, and hence, {{they can be}} carried out independently in parallel in each BS. Note that each component of z [...]...|$|E
30|$|Step 1 The {{standard}} cuckoo search algorithm {{starts with}} the initial values of population size n, probability p_a ∈ [0, 1], maximum number of iterations Max_itr and the initial <b>iteration</b> <b>counter</b> t (Lines 1 – 2).|$|E
3000|$|Steps 9 and 11 {{update the}} best {{solution}} found and reset the counter {{of the number of}} iterations without improvement, respectively. The global <b>iteration</b> <b>counter</b> is updated in step 13. Note that, the mean [...]...|$|E
3000|$|Step 1 : Initialization. Set LB and UB bounds to - [...] ∞ and + [...] ∞, respectively. Set the <b>iteration</b> <b>counter</b> to v = 0. Set attacker’s {{variables}} x̂_i,v^A = 0, ŷ_ij,v^A = 0, ẑ_g,v^A = 0.|$|E
30|$|Initialization step. Let {{the initial}} <b>iteration</b> <b>counter</b> k:= 0, the initial set of active nodes Λ_ 0 ={Ω^ 0 }, the initial upper bound f=+∞, the {{convergent}} error ε > 0, {{and the initial}} collection of feasible points F:=∅.|$|E
30|$|Under Condition 2.1, He et al. [28] {{established}} the convergence results of ProAlo, including the global convergence, the worst-case O(1 /t) convergence rate in ergodic or nonergodic sense, where {{t is the}} <b>iteration</b> <b>counter.</b> See Theorems 3.3, 4.2, 4.5 in [28].|$|E
3000|$|... is also {{performed}} by the FFT algorithm {{in a similar manner}} to the measurement process. One may stop the iterations of the CoSaMP algorithm if the norm of updated samples is sufficiently small or the <b>iteration</b> <b>counter</b> reaches a predetermined value.|$|E
3000|$|... (Initialization) Reformulate {{the initial}} problem as the {{equivalent}} form described in problem (Q), then choose a feasible point x^(0) and x_ 0 ^(0) (if necessary) {{as the starting}} point, give out the solution accuracy ϑ> 0, and set <b>iteration</b> <b>counter</b> k:= 0.|$|E
30|$|Step 1 : Initialization. The ants whose {{number is}} m {{are placed in}} the start point, setting <b>iteration</b> <b>counter</b> N_c = 0, {{the maximum number of}} {{iterations}} N_c max, the number of ants N, attenuation coefficient and update coefficient of the pheromone.|$|E
40|$|Melanoma is {{considered}} the most dangerous type of skin cancer. Early and accurate diagnosis depends mainly on important issues, accuracy of feature extracted and efficiency of classifier method. This paper presents an automated method for melanoma diagnosis applied {{on a set of}} dermoscopy images. Features extracted are based on gray level Co-occurrence matrix (GLCM) and Using Multilayer perceptron classifier (MLP) to classify between Melanocytic Nevi and Malignant melanoma. MLP classifier was proposed with two different techniques in training and testing process: Automatic MLP and Traditional MLP. Results indicated that texture analysis is a useful method for discrimination of melanocytic skin tumors with high accuracy. The first technique, Automatic <b>iteration</b> <b>counter</b> is faster but the second one, Default <b>iteration</b> <b>counter</b> gives a better accuracy, which is 100 % for the training set and 92 % for the test set...|$|E
30|$|The vector d(0) is {{assigned}} to d^(0)_∗, where the vector d^(p)_∗ is used to store the best (highest metric) vector obtained at the p-th iteration. A set S is defined to store the associated indices of the active channel taps at each iteration. Initialize <b>iteration</b> <b>counter</b> to p= 0 and index vector to S={}.|$|E
30|$|In this section, {{we first}} {{describe}} the symmetric {{version of the}} generalized alternating direction method of multipliers (SGADMM) for VI(W,F,θ) formally, and then we prove its global convergence in a contraction perspective and establish its worst-case O(1 /k) convergence rate in both the ergodic and the non-ergodic senses step by step, where k denotes the <b>iteration</b> <b>counter.</b>|$|E
3000|$|In each iteration, we firstly {{determine}} the available set Ω−Λ and generate the vector \(h^{l}=[{{{\| {B_{{l_{ 1 }},:}^{l}} \|}_{ 1 }}, \ldots,{{\| {B_{{l_{d}},:}^{l}} \|}_{ 1 }}}]\), where Ω={ 1,·,n}, d=|Ω−Λ| and l denotes <b>iteration</b> <b>counter.</b> According {{to the experimental}} results in [14] and the property \({{\| {B_{{l_{i}},:}^{l}} \|}_{ 1 }} \leq \sqrt m \cdot {{\| {B_{{l_{i}},:}^{l}} \|}_{ 2 }}\), we conclude that the elements of h [...]...|$|E
3000|$|Step 2 : Update the <b>iteration</b> <b>counter,</b> v ← v + 1. Solve {{the master}} problem (13)–(21), using optimal values of {{attacker}} variables x̂_i,v - 1 ^A, ŷ_ij,v - 1 ^A, ẑ_g,v - 1 ^A attained from Step 3 (or initialization) {{to be given}} parameter. Obtain optimal solution value of variables ^M *. Update LB as LB = η^* (the optimal solution denoted by ([...] ·)^* for the variables).|$|E
30|$|Through experiments, we {{measured}} an s-sparse signal x, where the s nonzero entries are either + 1 or - 1, and their positions and signs are chosen uniformly at random. For signal reconstruction, the FFT-based CoSaMP algorithm {{was applied to}} a total of 2, 000 sample vectors measured by the three sensing matrices. In Algorithm 1, the iterations are stopped if either ||v||[*]<[*] 10 - 4 or the <b>iteration</b> <b>counter</b> reaches the sparsity level s.|$|E
40|$|In {{this paper}} we propose two {{modifications}} to Nesterov's algorithms for minimizing convex functions in relative scale. The first {{is based on a}} bisection technique and leads to improved theoretical iteration complexity, and the second is a heuristic for avoiding restarting behavior. The fastest of our algorithms produces a solution within relative error O(1 /k) of the optimum, with k being the <b>iteration</b> <b>counter.</b> © 2011 Society for Industrial and Applied Mathematics...|$|E
40|$|We propose an {{efficient}} distributed randomized coordinate descent method for minimizing regularized non-strongly convex loss functions. The method attains the optimal $O(1 /k^ 2) $ convergence rate, where $k$ is the <b>iteration</b> <b>counter.</b> The {{core of the}} work is the theoretical study of stepsize parameters. We have implemented the method on Archer - the largest supercomputer in the UK - and show that the method is capable of solving a (synthetic) LASSO optimization problem with 50 billion variables...|$|E
40|$|Abstract. In {{this paper}} we propose two {{modifications}} to Nesterov’s algorithms for minimizing convex functions in relative scale. The first {{is based on a}} bisection technique and leads to improved theoretical iteration complexity and the second is a heuristic for avoiding restarting behavior. The fastest of our algorithms produces a solution within relative error O(1 /k) of the optimum, with k being the <b>iteration</b> <b>counter.</b> Key words. convex optimization, relative scale, sublinearity, Nesterov’s smoothing technique, Löwner-John ellipsoid...|$|E
