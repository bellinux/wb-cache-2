149|135|Public
5|$|Some NTFS {{features}} are not supported in ReFS, including object IDs, short names, <b>file</b> <b>compression,</b> file level encryption (EFS), user data transactions, hard links, extended attributes, and disk quotas. Sparse files are supported. Support for named streams is not implemented in Windows 8 and Windows Server 2012, {{though it was}} later added in Windows 8.1 and Windows Server 2012 R2. ReFS does not itself offer data deduplication. Dynamic disks with mirrored or striped volumes are replaced with mirrored or striped storage pools provided by Storage Spaces. In Windows Server 2012, automated error-correction with integrity streams is only supported on mirrored spaces; automatic recovery on parity spaces was added in Windows 8.1 and Windows Server 2012 R2. Booting from ReFS is not supported either.|$|E
25|$|Other {{specifications}} {{that were}} commonly used provided for echomail, different transfer protocols and handshake methods (e.g.: Yoohoo/Yoohoo2u2, EMSI), <b>file</b> <b>compression,</b> nodelist format, transfer over reliable connections such as the Internet (Binkp), and other aspects.|$|E
500|$|Malware {{removal and}} {{blocking}} performed well, setting or meeting records in PC Magazine testing. It achieved a detection rate of 98%. The highest out of 12 tested antivirus products. The exception was blocking commercial keyloggers, where Norton made an above average score. File operations took 2 percent longer, and the <b>file</b> <b>compression</b> and extraction test took 4 percent longer. The only area where Norton introduced a significant delay {{was when the}} system was booting, the beta version of the suite added 31 percent to the boot time, significantly longer than prior versions. According to the Norton performance comparison website, Norton Internet Security scans 31 percent faster, is 70 percent lighter, and installs 76 percent faster than the leading Anti-virus product. According to AV-comparatives, Norton Internet Security was [...] "Best Product of 2009", Bronze award for 98.6% detection rate in 2010 [...] and Norton Internet Security 2010 blocked 99/100 internet threats from infecting the user's computer.|$|E
30|$|In {{the past}} for a long time, people thought that a file’s entropy is the upper bound for the <b>file’s</b> {{lossless}} <b>compression</b> until the dictionary-based approach [33] was proposed.|$|R
40|$|In fact a {{few years}} ago, the maximum {{telephone}} line MODEM speed was 9600 bps, now it has 14400 bps or 28800 bps for a technological innovation in recently. We tried to make an experiment of data transfer with V. 32 bis MODEM on a telephone line; that used English text file, Japanese text files, NOAA ATP image files and MS-DOS execute files. A transmission control protocol used the normal mode, the YMODEM-g and the ZMODEM. The object of this experiment, {{we would like to}} data of transmission and receiving in detail with V. 32 bis MODEM and to confirm the cmmunication efficiency. Done results were as follows; 1) A MODEM speed 14400 bps of data transfer rate was about 150 - 200 % with none <b>compression</b> <b>files</b> and <b>compression</b> <b>files</b> 130 - 160 % more than 9600 bps. 2) When the <b>compression</b> <b>files</b> used to increase communication efficiency that was 130 - 160 % more than none <b>compression</b> <b>files.</b> 3) It has used A transmission control protocol with YMODEM-g or ZMODEM to increase communication efficiency. 今回のモデムの伝送実験より次の点が明らかになった。 1. 非圧縮ファイルにおいて,V 32 bisで 14400 bpsでは, 9600 bpsの約 1. 5 ～ 1. 9 倍の量のデータの伝送が可能である。 2. 圧縮ファイルでは, 9600 bpsの約 1. 3 ～ 1. 6 倍の量のデータ伝送が可能である。 3. 14400 bsの通信速度で,YMODEMまたはZMODEMによりデータを圧縮して伝送した場合,非圧縮時より単位時間当たり 1. 1 ～ 1. 6 倍のデータ量が伝送可能であり通信効率が向上する。 4. 英文,和文ファイルのようなテキストファイルは,画像ファイルやバイナリファイルのMS-DOS EXEファイルより通信効率が高い。 5. ファイル伝送プロトコルは,YMODEM-gまたはZMODEMを使用した場合通信効率が高い。しかし通信の三要素である迅速,確実および正確を期するならZMODEMの使用が望ましい...|$|R
50|$|This may be usable on some {{situations}} like <b>compression</b> <b>file</b> system.|$|R
2500|$|The {{game was}} {{publicly}} announced first at E3 2005, {{by means of}} a humorous and slightly abstract gag machinima using characters from Metal Gear Solid 3, under the slogan of [...] "No Place to Hide". The title was described as [...] "essentially finished" [...] by January 2008, and went through extensive beta testing. At Destination PlayStation on February 26, 2008, Sony announced that MGS4 would be released worldwide on June 12, 2008, along with the special MGS4 PlayStation 3 bundle. It was announced that Guns of the Patriots is the first PlayStation 3 game that uses a 50GB dual layer Blu-ray Disc even with the use of <b>file</b> <b>compression.</b>|$|E
2500|$|A CD {{software}} release can contain up to 700megabytes of data, which presented challenges when sending over the Internet, {{particularly in the}} late 1990s when broadband was unavailable to most home consumers. These challenges apply to an even greater extent for a single-layer DVD release, which can contain up to 4.7GB of data. The warez scene made it standard practice to split releases up into many separate pieces, called disks, using several <b>file</b> <b>compression</b> formats: (historical TAR, LZH, ACE, UHA, ARJ), ZIP, and most commonly RAR. The original purpose of these [...] "disks" [...] was so that each [...]rar file could fit on a single 1.44MB 3½ inch floppy disk. With the growing size of games, {{this is no longer}} feasible, as hundreds of disks would need to be used. The average size of disks released by groups today are 50megabytes or 100megabytes, however it is common to find disks up to 200megabytes.|$|E
5000|$|FCX <b>file</b> <b>compression</b> is a <b>file</b> <b>compression</b> {{utility and}} file format. [...] It is {{supported}} {{on a large}} number of platforms. [...] It is published by Compact Data Works and was originally released in 1988 for VAX/VMS.|$|E
5000|$|... {{optimisation}} of the Huffman coding {{layer of}} a JPEG <b>file</b> to increase <b>compression,</b> ...|$|R
5000|$|RAR - (partially documented) archive and <b>compression</b> <b>file</b> format {{owned by}} Alexander L. Roshal ...|$|R
40|$|Evaluating a query {{can involve}} {{manipulation}} of {{large volumes of}} temporary data. When the volume of data becomes too great, activities such as joins and sorting must use disk, and cost minimisation involves complex trade-offs. In this paper, we explore the effect of compression {{on the cost of}} external sorting. Reduction in the volume of data potentially allows costs to be reduced (through reductions in disk traffic and numbers of temporary <b>files),</b> but on-the-fly <b>compression</b> can be slow and many compression methods do not allow random access to individual records. We investigate a range of compression techniques for this problem, and develop successful methods based on common letter sequences. Our experiments show that, for a given memory limit, the overheads of compression outweigh the benefits for smaller data volumes, but for large <b>files</b> <b>compression</b> can yield substantial gains, of one-third of costs in the best case tested. Even when the data is stored uncompressed, our results show that incorporation of compression can significantly accelerate query processing...|$|R
50|$|See Lossless {{compression}} benchmarks {{for a list}} of <b>file</b> <b>compression</b> benchmarks.|$|E
50|$|There are {{two types}} of image <b>file</b> <b>compression</b> algorithms: {{lossless}} and lossy.|$|E
5000|$|Audio <b>file</b> <b>compression</b> to {{save time}} and space (30 to 60% savings).|$|E
50|$|Batching is {{supported}} for converting multiple PDF documents {{at the same}} time or for combining multiple PDF documents into a single <b>file</b> and <b>compression</b> options allow users {{to reduce the size of}} a PDF, optimizing it for a variety of media.|$|R
40|$|Abstract. With {{the fast}} {{development}} of multi-core processors, automatic parallelization becomes increasingly important. In this work, {{we focus on}} the parallelization of utility programs, a class of commonly used applications including compilers, transcoding utilities, <b>file</b> <b>compressions,</b> and databases. They take a series of requests as inputs and serve them one by one. Their high input dependence poses a challenge to parallelization. We use active profiling to find behavior phase boundaries and then automatically detect run-time dependences through profiling. Using a unified framework, we manually parallelize programs at phase boundaries. We show that for two programs, the technique enables parallelization at large granularity, which may span many loops and subroutines. The parallelized programs show significant speedup on multi-processor machines. ...|$|R
5000|$|Uses the ZIP format, making ZIP {{part of the}} standard. Due to <b>compression,</b> <b>files</b> {{are smaller}} than current binary formats.|$|R
5000|$|PKZIP, the {{compression}} utility that {{quickly became the}} standard in <b>file</b> <b>compression.</b>|$|E
50|$|Transparent <b>file</b> <b>compression</b> {{was also}} supported, {{although}} this {{had a significant}} impact on the performance of file serving.|$|E
5000|$|... 6 {{red book}} audio discs {{for the price}} of one Yellow Book (CD-ROM), {{depending}} on <b>file</b> <b>compression</b> rates ...|$|E
25|$|A {{structured}} {{storage system}} to bundle these elements and any associated content {{into a single}} <b>file,</b> with data <b>compression</b> where appropriate.|$|R
50|$|ICER is a wavelet-based image <b>compression</b> <b>file</b> format {{used by the}} NASA Mars Rovers. ICER {{has both}} lossy and {{lossless}} compression modes.|$|R
50|$|NTFS, {{introduced}} {{with the}} Windows NT operating system in 1993, allowed ACL-based permission control. Other features also supported by NTFS include hard links, multiple file streams, attribute indexing, quota tracking, sparse <b>files,</b> encryption, <b>compression,</b> and reparse points (directories working as mount-points for other file systems, symlinks, junctions, remote storage links).|$|R
5000|$|Version 9 enables {{support for}} <b>file</b> <b>compression,</b> deduplication, and {{partition}} directories. Version 9 {{was introduced in}} VxFS 6.0.|$|E
50|$|WinZip 16.5 {{supports}} OpenCL acceleration to <b>file</b> <b>compression</b> {{engine for}} AMD Fusion processors and AMD Radeon users, streamlined interface.|$|E
5000|$|... lzop {{is a free}} {{software}} <b>file</b> <b>compression</b> tool which implements the LZO algorithm and is licensed under the GPL.|$|E
5000|$|... gzip {{is not to}} be {{confused}} with the ZIP archive format, which also uses DEFLATE. The ZIP format can hold collections of files without an external archiver, but is less compact than compressed tarballs holding the same data, because it compresses files individually and cannot take advantage of redundancy between <b>files</b> (solid <b>compression).</b>|$|R
40|$|As the anti-viruses run in {{a trusted}} kernel level any {{loophole}} in the anti-virus program can enable attackers to take full control over the computer system and steal data or do serious damages. Hence the anti-virus engines must be developed with proper security in mind. The ant-virus {{should be able to}} any type of specially created executable <b>files,</b> <b>compression</b> packages or documents that are intentionally created to exploit the anti-virus weakness. Viruses are present in almost every system even though there are anti-viruses installed. This is because every anti-virus, however good it may be, leads to some extent of false positives and false negatives. Our faith on the anti-virus system often makes us more careless about hygienic habits which increases the possibility of infection. It is necessary for an anti-virus to detect and destroy the malware before its own files are detected and destroyed by the malware. Comment: 8 page...|$|R
50|$|Wavelet {{compression}} {{is a form}} of {{data compression}} well suited for image compression (sometimes also video compression and audio compression). Notable implementations are JPEG 2000, DjVu and ECW for still images, CineForm, and the BBC's Dirac. The goal is to store image data in as little space as possible in a <b>file.</b> Wavelet <b>compression</b> can be either lossless or lossy.|$|R
50|$|There is no <b>file</b> <b>compression,</b> and {{therefore}} these load {{very quickly and}} without much programming when displayed in native mode.|$|E
5000|$|G.722 is a freely {{available}} {{file format}} for audio <b>file</b> <b>compression.</b> The files are often named with the extension [...] "722".|$|E
5000|$|CNET rated it 4/5 {{stars and}} wrote, [...] "Easy program {{operation}} sets this freeware <b>file</b> <b>compression</b> tool {{apart from the}} crowded genre." ...|$|E
50|$|For {{some data}} {{compressors}} {{it is possible}} to compress the corpus smaller by combining the inputs into an uncompressed archive (such as a tar <b>file)</b> before <b>compression</b> because of mutual information between the text files. In other cases, the compression is worse because the compressor handles nonuniform statistics poorly. This method was used in a benchmark in the online book Data Compression Explained by Matt Mahoney.|$|R
5000|$|WinZip 19.5 was {{released}} May 7, 2015. Adds SmartShare, share via clipboard (cloud links), view thumbnails, auto-hide scroll bars, slide-in action pane. Enterprise adds VMware file support and VHD <b>files</b> with NTFS <b>compression.</b>|$|R
40|$|Abstract. Evaluating a query {{can involve}} {{manipulation}} of large vol-umes of temporary data. When {{the volume of}} data becomes too great, activities such as joins and sorting must use disk, and cost minimisation involves complex trade-offs. In this paper, we explore the effect of com-pression {{on the cost of}} external sorting. Reduction in the volume of data potentially allows costs to be reduced – through reductions in disk traffic and numbers of temporary files – but on-the-fly compression can be slow and many compression methods do not allow random access to individual records. We investigate a range of compression techniques for this prob-lem, and develop successful methods based on common letter sequences. Our experiments show that, for a given memory limit, the overheads of compression outweigh the benefits for smaller data volumes, but for large <b>files</b> <b>compression</b> can yield substantial gains, of one-third of costs in the best case tested. Even when the data is stored uncompressed, our results show that incorporation of compression can significantly accelerate query processing. ...|$|R
