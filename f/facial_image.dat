768|1318|Public
25|$|Robert Zemeckis {{insisted that}} the {{character}} Beowulf resemble depictions of Jesus, believing that a correlation could be made between Christ's face and a universally accepted appeal. Zemeckis used Alan Ritchson for the physical model, <b>facial</b> <b>image</b> and movement for the title character of Beowulf.|$|E
25|$|The {{additional}} obligations imposed by European law on national border authorities {{when it comes}} to processing travellers who are third-country nationals (e.g. the obligation to stamp their travel documents) should not prevent the development of automated border control systems which are made available to such travellers. As shown by the examples listed above of automated border control systems which have been developed at external border crossing points of the Schengen Area, national border authorities have been able to adapt the design of their automated border control systems to allow third-country nationals to make use of them. One solution is to have a border guard physically positioned next to the automated border gates who can stamp travel documents where required: this approach has been adopted by the Finnish Border Guard at the automated border gates in Helsinki Airport, where eligible users (who are required to receive a passport stamp) include holders of Australian, Canadian, Japanese, New Zealand, South Korean and United States biometric passports, {{as well as by the}} Portuguese Serviço de Estrangeiros e Fronteiras at the automated border gates in Lisbon Airport where eligible users (who are required to receive a passport stamp) include holders of Angolan and Brazilian passports and holders of diplomatic/service passports. A similar but slightly different solution has been adopted by the Dutch Royal Marechaussee at the Privium iris recognition automated border gates at Amsterdam Schiphol Airport (where eligible users include registered EU/EEA/Swiss citizens, US citizens who are Global Entry members, and all nationals who are holders of diplomatic passports), as well as by the German Federal Police at the ABG Plus iris recognition automated border gates at Frankfurt Airport (where eligible users include registered EU/EEA/Swiss citizens and US citizens who are Global Entry members): when eligible third-country nationals use Privium/ABG Plus, after their iris is scanned and verified, a different gate opens to that for EU/EEA/Swiss citizens and the third-country national is directed to a lane which leads them to the front of the queue for manual passport checks at immigration desks, where the border officer stamps the user's passport. Another possible solution would be to design the automated border gates to print a paper slip with an entry or exit stamp on it, as well as the traveller's name and travel document number, whenever the user is a traveller who is subject to the requirement to have his or her travel document stamped. At the Port of Helsinki, the Finnish Border Guard has adapted the design of the automated border gates there to widen eligibility to include Russian citizens (who, as Annex I nationals, are required to have a visa) by requiring them to scan both the biodata page and the visa inside their passport, then to step into the gate for a <b>facial</b> <b>image</b> and fingerprint recognition, and after the gate opens to approach a border officer to have their passport stamped.|$|E
2500|$|Since e-passports {{are issued}} to all Chinese {{citizens}} and e-gates have been installed {{in most of}} the international airports in China, returning Chinese citizens do not need to line up at the immigration check points for entry stamps as foreigners do. Instead, they can go through an e-gate by scanning their e-passport and finger(s) all by themselves with the whole process taking only 10 seconds at most. Entry information and their <b>facial</b> <b>image</b> will be stored automatically in a database. (No entry stamps will be left in their e-passport, but any passport holder could request gratis entry or exit records.) E-gates are not only used for fast entry for Chinese e-passport holders, but they have also [...] been tested for fast-exit in Beijing Capital Airport Terminal 2. In the future, Chinese e-passport holders can both exit and enter China by e-gate.|$|E
40|$|Methods for the {{synthesis}} of new three-dimensional <b>facial</b> <b>images</b> from a database of texture-mapped laser-scanned surfaces are described. Four methods are used to create new <b>facial</b> <b>images.</b> The first constructs average <b>facial</b> <b>images</b> from a sample of faces. The second exaggerates {{the difference between a}} subject and an average to create a caricature. The third method captures the difference between tw...|$|R
40|$|Abstract. Emotion {{recognition}} from <b>facial</b> <b>images</b> {{is a very}} active research topic in human computer interaction (HCI). However, most of the previous approaches only focus on the frontal or nearly frontal view <b>facial</b> <b>images.</b> In contrast to the frontal/nearly-frontal view images, emotion {{recognition from}} non-frontal view or even arbitrary view <b>facial</b> <b>images</b> {{is much more difficult}} yet of more practical utility. To handle the emotion recognition problem from arbitrary view <b>facial</b> <b>images,</b> in this paper we propose a novel method based on the regional covariance matrix (RCM) representation of <b>facial</b> <b>images.</b> We also develop a new discriminant analysis theory, aiming at reducing the dimensionality of the facial feature vectors while preserving the most discriminative information, by minimizing an estimated multiclass Bayes error derived under the Gaussian mixture model (GMM). We further propose an efficient algorithm to solve the optimal discriminant vectors of the proposed discriminant analysis method. We render thousands of multi-view 2 D <b>facial</b> <b>images</b> from the BU- 3 DFE database and conduct extensive experiments on the generated database to demonstrate the effectiveness of the proposed method. It is worth noting that our method does not require face alignment or facial landmark points localization, making it very attractive. ...|$|R
40|$|A {{working face}} {{recognition}} system requires {{the ability to}} represent <b>facial</b> <b>images</b> {{in such a way}} that permits efficient and accurate processing. The human visual system effectively stores, recognises and classifies familiar <b>facial</b> <b>images</b> under a wide variety of viewing conditions, albeit with various degrees of accuracy. We describe a system which automatically determines a representation for pose-varying <b>facial</b> <b>images</b> - a representation with inherent classification, an ability to generalise from one viewing condition to another, and which uses fast computational procedures...|$|R
50|$|Products include ID {{capture and}} {{auto-fill}} software, ID authentication, biometric facial recognition, <b>facial</b> <b>image</b> matching, and CHIP/RFID reading. Partners include start-ups, Fortune 500 and FTSE 350 organizations.|$|E
5000|$|... 1998: Digital <b>facial</b> <b>image</b> {{rather than}} a {{laminated}} photograph, and intaglio or raised printing {{on the inside of}} the covers. Children under 16 are no longer included on new adult passports.|$|E
50|$|Qiang Ji {{from the}} Rensselaer Polytechnic Institute, Troy, NY was named Fellow of the Institute of Electrical and Electronics Engineers (IEEE) in 2015 for {{contributions}} to automatic <b>facial</b> <b>image</b> processing and affective computing.|$|E
30|$|SHR is {{developed}} for low-resolution images. Because {{there are no}} large low-resolution face databases, we used the FRGCv 2 database and created low-resolution <b>facial</b> <b>images</b> by low-pass filtering and subsequent downsampling. Using low-resolution <b>facial</b> <b>images</b> makes the comparison {{of the performance of}} our face recognition methods with {{the state of the art}} difficult, because these are primarily focussed on high-resolution <b>facial</b> <b>images.</b> Also, landmark-based registration methods work poorly on these resolutions. For this reason, we performed the landmark finding on high-resolutions images, thus given them an advantage over SHR.|$|R
30|$|Given this {{apparent}} expertise in showing face, {{it might be}} expected that people would also be experts in choosing face: {{they would be more}} adept at selecting favorable <b>facial</b> <b>images</b> of themselves than they would be at selecting favorable <b>facial</b> <b>images</b> of unfamiliar people. However, our results clearly argue against any such self-expertise.|$|R
40|$|Abstract: Holistic Principal Component Analysis (PCA) and {{holistic}} Independent Component Analysis (ICA) methods require long training {{times and}} large storage spaces for {{the recognition of}} <b>facial</b> <b>images.</b> These drawbacks can be avoided by using partitioning-based methods, namely partitioned PCA (pPCA) and partitioned ICA (pICA), which yield similar performance for pPCA and improved performance for pICA method compared to the holistic counterparts of these methods for the recognition of frontal <b>facial</b> <b>images.</b> This paper demonstrates the sensitivity analysis of pPCA and pICA methods on several types and sizes of occlusions for the recognition of <b>facial</b> <b>images</b> with similar <b>facial</b> expressions. The recognition rates for pPCA and pICA over occlusions are contrary to the recognition rates of these methods on occlusion-free <b>facial</b> <b>images</b> with different <b>facial</b> expressions. Key-words: face recognition, PCA, ICA, multiple classier systems, classifier combination, face occlusion 1...|$|R
50|$|Xilin Chen {{from the}} Institute of Computing Technology, Beijing, China was named Fellow of the Institute of Electrical and Electronics Engineers (IEEE) in 2016 for {{contributions}} to machine vision for <b>facial</b> <b>image</b> analysis and sign language recognition.|$|E
50|$|In {{biometric}} security systems, capture is {{the acquisition of}} or the process of acquiring and identifying characteristics such as finger image, palm image, <b>facial</b> <b>image,</b> iris print or voice print which involves audio data and the rest all involves video data.|$|E
5000|$|... 2. Besinger, A., Sztynda, T., Lal, S., Duthoit, C.J., Agbinya, J.I., Jap, B., Eager, D.M. & Dissanayake, G.2010, 'Optical flow based {{analyses}} to detect emotion from human <b>facial</b> <b>image</b> data', Expert Systems with Applications, vol. 37, no. 12, pp. 8897-8902.|$|E
40|$|Abstract: The authors {{describe}} their experiences creating technology to automatically capture <b>facial</b> <b>images</b> from patients during triage and registration for {{integration into the}} electronic medical record (EMR) to reduce data retrieval and data entry errors. The prototype system was tested {{across a variety of}} ethnicities with <b>facial</b> <b>images</b> captured successfully in 100 % of cases with a median time to capture of 0. 75 seconds. Objective: Despite the use of electronic medical record (EMR) technology and computerized physician order entry (CPOE) systems, medical error remains pervasive. In particular, patient-identity errors are particularly persistent (i. e. technically accurate orders written for the wrong patient). Patient identity errors can account for as many as 35 % of all medical errors [1, 2, 3, 4, 5, 6]. Augmenting existing EMR textual identifiers with patient <b>facial</b> <b>images</b> may decrease patient identification errors. <b>Facial</b> <b>images</b> could be captured through manual, volitional processes- however, automated methods have several potential advantages including: faster throughput during triage or registration, consistency of image resolution and capture quality, and enhanced compliance by triage personnel. The authors share their experience building a prototype to automatically capture patient <b>facial</b> <b>images</b> directly into an EMR during triage or registration...|$|R
40|$|In this paper, a multilinear {{approach}} {{based on}} image texture for face recognition is present. First, we extract the texture {{features of the}} <b>facial</b> <b>images</b> using the Local Binary Pattern (LBP) algorithm. Then, we apply the High-order Orthogonal Iteration (HOOI) algorithm, the algebra of higher-order tensors, to obtain a compact and effective representation of the <b>facial</b> <b>images</b> based on the texture features. Our representation yields improved facial recognition rates relative to standard eigenface and tensorface especially when the <b>facial</b> <b>images</b> are confronted {{by a variety of}} viewpoints and illuminations. To evaluate the validity of our approach, a series of experiments are performed on the CMU PIE facial databases. 1...|$|R
40|$|Introduction This paper {{summarizes}} {{our efforts}} {{to prepare for the}} Face Recognition Technology (FERET) Phase III test which was successfully operated in February 1997. This test is the third of a series of tests conducted by US Army Research Laboratory (ARL). Duplicate <b>facial</b> <b>images</b> are defined here as two or more images which contain a face of the same individual but taken at different times. They contain many disturbances against correct recognition which correspond to uncontrolled real world <b>facial</b> <b>images</b> in the scope of this paper. Highly precise recognition of such duplicate <b>facial</b> <b>images</b> are also keys for a successful application for security systems with facial identification technology and bi-directional computer-user interfaces which are the application domains our current face recognition system is approaching to. The results of Phase I and Phase II show that our system performed highly successful over controlled <b>facial</b> <b>images.</b> [2][3] It was our next challenge to impr...|$|R
50|$|Movie {{credits include}} {{a role in}} the 2006 film The Butcher, as well as a minor role in 2009's Fired Up! In 2007, {{director}} Robert Zemeckis used Ritchson for his <b>facial</b> <b>image,</b> physique and movement for actor Ray Winstone of the title character of Beowulf.|$|E
50|$|Robert Zemeckis {{insisted that}} the {{character}} Beowulf resemble depictions of Jesus, believing that a correlation could be made between Christ's face and a universally accepted appeal. Zemeckis used Alan Ritchson for the physical model, <b>facial</b> <b>image</b> and movement for the title character of Beowulf.|$|E
50|$|On 31 August 2007, {{the program}} began to include <b>facial</b> <b>image</b> data to help enhance searches. The 14 million images kept by federal {{immigration}} authorities are {{being used in the}} program, and the government is in talks with some states to cross reference with state drivers license records.|$|E
40|$|Countless <b>facial</b> <b>images</b> are {{generated}} everyday through digital and cell phone cameras, surveillance video systems, webcams, and traditional film and broadcast video. As a result, {{law enforcement and}} intelligence agencies have numerous opportunities to acquire and analyze images that depict persons of interest. Computer-Aided Forensic Facial Comparison is a comprehensive exploration of the scientific, technical, and statistical challenges facing researchers investigating courtroom identification from <b>facial</b> <b>images...</b>|$|R
40|$|The authors {{describe}} their experiences creating technology to automatically capture <b>facial</b> <b>images</b> from patients during triage and registration for {{integration into the}} electronic medical record (EMR) to reduce data retrieval and data entry errors. The prototype system was tested {{across a variety of}} ethnicities with <b>facial</b> <b>images</b> captured successfully in 100 % of cases with a median time to capture of 0. 75 seconds...|$|R
40|$|Abstract-This paper investigates {{framework}} of face annotation by mining faintly labeled <b>facial</b> <b>images</b> which are freely or easily available on World Wide Web (WWW). There is one challenging problem for face annotation scheme {{is that how}} to perform annotation effectively by {{making full use of}} list which contain most similar <b>facial</b> <b>images</b> and whose labeling is faint having noisy and incomplete. To avoid this problem, we propose an Unsupervised label refinement (ULR) approach for refining the labels of web <b>facial</b> <b>images</b> using machine learning techniques. We propose one another system to speed up that is a clustering based approximation algorithm for improve the scalability. We develop optimization algorithms for solving the learning task of large-scale...|$|R
50|$|FaceRecognition {{is used to}} {{identify}} or verify a person from a digital image or a video source using a stored face database. visage|SDK face recognition algorithm is capable of measuring similarity between people and recognizing a person’s identity from frontal <b>facial</b> <b>image</b> (yaw angle approximately from -20 to 20 degrees) by comparing it to faces previously stored in a gallery.|$|E
50|$|The Egyptian Government has, from 5 February 2007, {{introduced}} the electronic Passport (e-Passport) and electronic Document of Identity for Visa Purposes (e-Doc/I) which are compliant {{with the standard}} of the International Civil Aviation Organization (ICAO). Digital data including holder's personal data and <b>facial</b> <b>image</b> will be contained in the contactless chip embedded in the back cover of e-Passport and e-Doc/I.|$|E
5000|$|This {{method was}} {{proposed}} by Wang and Tang [...] and it uses an eigentransformation. This method sees the solution as a transformation between {{different styles of}} image and uses a principal component analysis (PCA) applied to the low-resolution face image. By selecting the number of [...] "eigenfaces", we can extract amount of <b>facial</b> <b>image</b> information of low resolution and remove the noise.|$|E
40|$|The paper {{addresses}} {{the problem of}} face recognition under arbitrary pose. A hi-erarchical MRF-based image matching method for finding pixel-wise correspondences between <b>facial</b> <b>images</b> viewed from different angles is proposed and used to densely reg-ister a pair of <b>facial</b> <b>images.</b> The goodness-of-match between two faces is then {{measured in terms of}} the normalized energy of the match which is a combination of both structural differences between faces as well as their texture distinctiveness. The method needs no training on non-frontal images and circumvents the need for geometrical normalization of <b>facial</b> <b>images.</b> It is also robust to moderate scale changes between images. The proposed approach is evaluated on the CMU PIE database and promising results are obtained. ...|$|R
3000|$|..., LOO {{cross-validation}} {{will perform}} S− 1 validation experiments. In each experiment i, <b>facial</b> <b>images</b> of subject S [...]...|$|R
40|$|Abstract — In this paper, {{we explore}} {{new methods to}} improve the {{modeling}} of <b>facial</b> <b>images</b> under different types of variations like pose, ambient illumination and facial expression. We investigate the intuitive assumption that the parameters for the distribution of <b>facial</b> <b>images</b> change smoothly with respect to variations in the face pose angle. A Markov Random Field is defined to model a smooth prior over the parameter space and the maximum a posteriori solution is computed. We also propose extensions to the view-based face recognition method by learning how to traverse between different subspaces so we can synthesize <b>facial</b> <b>images</b> with different characteristics for the same person. This allow us to enroll a new user with a single 2 D image. I...|$|R
50|$|Visitors {{applying}} for most types of UK visas (including a visitor's visa and an EEA Family Permit) {{are required to}} submit biometric identifiers (all fingerprints and a digital <b>facial</b> <b>image)</b> {{as part of the}} visa application process. However, diplomats, foreign government ministers and officials and members of Commonwealth Forces are exempt from the requirement to submit biometric identifiers. Applicants who have obtained a new passport and are merely requesting a transfer of their visa vignette from their old passport to their new passport are not required to re-submit biometric identifiers. In addition, applicants who are travelling directly to the Channel Islands or Gibraltar without passing through the UK or the Isle of Man are exempt from providing biometric information. Children must be accompanied by an adult when their biometric identifiers are taken. Biometric identifiers may be shared with foreign governments. Biometric identifiers are destroyed 10 years after the last date a person's fingerprints and digital <b>facial</b> <b>image</b> were captured.|$|E
50|$|The card is credit-card sized and {{contains}} a 2.86 megabyte optical stripe and a contact chip to store data, {{as well as}} finger prints and a <b>facial</b> <b>image.</b> The card does contain a barcode, but no machine-readable zone. All fields of the card are in Arabic except for the texts National ID Card and Kingdom of Saudi Arabia, Ministry of Interior, which is also present in English.|$|E
50|$|The common {{algorithms}} usually perform two steps: {{the first}} step generates global face image which keeps {{the characteristics of the}} face using probabilistic method maximum a posteriori (MAP). The second step produces residual image to compensate the result of {{the first step}}. Furthermore, all the algorithms are based on a set of high- and low-resolution training image pairs, which incorporates image super-resolution techniques into <b>facial</b> <b>image</b> synthesis.|$|E
40|$|We {{would like}} {{subjects}} {{to rate the}} facial similarity of {{a small number of}} <b>facial</b> <b>images</b> and utilize these ratings to obtain a functional mapping which will generalize human facial similarity judgements to a distinct, larger set of <b>facial</b> <b>images.</b> <b>Facial</b> Rating Confounds: Triplet ratings are time-consuming. Metric ratings are too subjective. Hierarchy Algorithm (1) Find two most similar images, connect them to form a group. (2) Find the next two most similar images not within the same group and connect them. (3) Continue from 2 until all images are connected...|$|R
30|$|On the one hand, data {{imbalance}} in the prevailing facial datasets {{should be one}} possible explanation for this phenomenon. Despite most of the face recognition training datasets contain large amount of identities, they still suffer from the deficiency of difficult <b>facial</b> <b>images</b> with partial occlusions such as sunglasses, hats, and hairs. An intuitive solution to this problem is that more occluded <b>facial</b> <b>images</b> should be included into the training process of the CNN framework.|$|R
40|$|We have {{proposed}} a method for estimating the subjective age of a person; that is, a method that yields a person 2 ̆ 7 s age {{on the basis of}} estimations made by that person about the age of other people by observing their <b>facial</b> <b>images.</b> Thus far, experiments have shown that Japanese people tend to underestimate their subjective age. In this study, we focus on the socio-psychological effects that may influence the underestimation of subjective age. We conducted an international comparative study. In this study, experiments were performed in which American and Japanese participants viewed American facial images; in addition, the American participants also viewed Japanese <b>facial</b> <b>images.</b> Through these experiments, it was confirmed that the subjective age generally tended toward the negative direction despite differences in the nationalities and cultures of the Japanese and American participants and their <b>facial</b> <b>images.</b> Moreover, it was found that nationality and culture may have some effects on the estimation; for example, American males did not exhibit the tendency to underestimate the age, unlike Japanese male. When estimating <b>facial</b> <b>images</b> of different nationalities, the variance generally tended to be larger, although the average was similar. This study suggests that the underestimation of age occurs despite differences in Japanese and American societies and cultures; however, the tendency of underestimation of age is not related to <b>facial</b> <b>images</b> but to social and cultural factors that influence the participants...|$|R
