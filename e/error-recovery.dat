85|1|Public
5000|$|SAS <b>error-recovery</b> and error-reporting uses SCSI commands, {{which have}} more {{functionality}} than the ATA SMART commands used by SATA drives.|$|E
50|$|Historically, Fidonet {{traffic was}} {{transferred}} mainly over serial (RS-232) modem connections which {{might not have}} an error correction layer. These dial-up-oriented protocols for transferring Fidonet traffic like EMSI or Zmodem had to implement <b>error-recovery.</b> When the members of Fidonet started to use TCP/IP to transfer Fidonet traffic, this <b>error-recovery</b> overhead became unnecessary. Assuming that the connection is reliable {{makes it possible to}} eliminate error-checking and unnecessary synchronization steps, achieving both ease of implementation and improved performance. The major advantage of binkp vs EMSI and Zmodem is achieved over connections with large delays and low bandwidth.|$|E
50|$|When {{the target}} needs {{to perform a}} long <b>error-recovery</b> {{procedure}} (typically one that lasts more than one second) it can enter the extended contingent allegiance condition. This may be necessary in high performance systems or in cases {{where there is a}} danger that initiator may reset the target after a short timeout interval, thereby aborting the <b>error-recovery</b> procedure. As in the contingent allegiance condition, the target is allowed to use the busy response to incoming commands and to suspend servicing of any recent commands that are still in its execution queue.|$|E
40|$|The minimalist {{approach}} (Carroll, 1990 a) advocates {{the development}} of a radically different type of manual when compared to a conventional one. For example, the manual should proceed almost directly to procedural skills development rather than building a conceptual model first. It ought to focus on authentic tasks practised in context, as opposed to mock exercises and isolated practice. In addition, it should stimulate users to exploit their knowledge and thinking, as opposed to imposing the writer's view and discussing everything that users should see or know. In {{the first part of the}} paper the construction of a tutorial based on the minimalist principles is described. A parallel is drawn with constructivism with which minimalism shares important notions of instruction. In the second part, an experiment is described in which the minimal manual was tested against a conventional one. The outcome favoured the new manual. For example, minimal manual users completed about 50 % more tasks successfully on a performance test and displayed significantly more self-reliance (e. g. more self-initiated <b>error-recoveries,</b> and fewer manual consultations) ...|$|R
50|$|Under {{the mandate}} of list-decoding, for {{worst-case}} errors, the decoder is allowed to output a small list of codewords. With some context specific or side information, {{it may be possible}} to prune the list and recover the original transmitted codeword. Hence, in general, this seems to be a stronger <b>error-recovery</b> model than unique decoding.|$|E
50|$|HTML {{versions}} 4 {{and earlier}} left error handling undefined. Over time pages started relying on unspecified <b>error-recovery</b> implemented in popular browsers. This caused difficulties for vendors of less-popular browsers who {{were forced to}} reverse-engineer and implement bug compatible error recovery. This has led to de facto standard (i.e. HTML5) that was {{much more complicated than}} it could have been if this behavior was specified from the start.|$|E
40|$|Abstract. An <b>error-recovery</b> {{method for}} {{embedded}} multi-processor systems on SRAM-based FPGAs is proposed. This method is effective against soft-errors in the configuration memory, {{such as the}} errors caused by hIgh energy radiation also known as Single Event Upsets. The <b>error-recovery</b> algorithm performs on-line test of the ~PGA configuration memory and recovers errors using dynamic partial reconfiguration. Processor cores perform a dIstributed recovery procedure. If a failure occurs in the processor currently runOing the recovery algOrithm, another processor core takes the role and performs reconfiguration. Presented case study demonstrates {{the advantage of the}} proposed approach...|$|E
40|$|Most of the parser (transducer) writing systems {{found in}} the {{literature}} concern the mechanical production of batch parsers (transducers). The generation scheme discussed in this paper produces interactive transducers in the form of Ada programs, with an underlying parser that is of type ELL(1). The emphasis here is on error recovery in interactive parsers. A generation scheme is proposed containing powerful <b>error-recovery</b> generation capabilities. Also, the interaction between syntactic and semantic error recovery is briefly discussed. The generation scheme has been implemented as part of the MIRA transducer writing system. With MIRA, a number of industrial case studies have been worked out from which considerable feedback has been obtained to test and improve the adopted <b>error-recovery</b> strategy. One of the case studies worked out with MIRA consists of the design and implementation of an interactive software package called ABACUS. A subset called MINI-ABACUS is used as an illustration of the <b>error-recovery</b> principles discussed throughout this paper. status: publishe...|$|E
40|$|A {{low power}} impulse ultra-wideband (UWB) {{transceiver}} for DC- 960 MHz band is proposed in this paper. It features a digital pulse-shaping transmitter, a DC power-free pulse discriminator and an <b>error-recovery</b> phase-frequency detector. The developed transceiver in 90 nm CMOS achieves the lowest energy consumption of 2. 2 pJ/bit (TX) and 1. 9 pJ/bit (RX) at 100 Mbps...|$|E
40|$|Background Medical {{errors are}} common in {{intensive}} care units. Nurses are uniquely positioned to identify, interrupt, and correct medical errors and to minimize preventable adverse outcomes. Nurses are increasingly recognized as {{playing a role in}} reducing medical errors, but only recently have their <b>error-recovery</b> strategies been described. Objectives To describe <b>error-recovery</b> strategies used by critical care nurses. Methods Data were collected by audio taping focus groups with 20 nurses from 5 critical care units at 2 urban university medical centers and 2 community hospitals on the East and West coasts of the United States. Transcript content was ana-lyzed as recommended by Krueger and Casey. Results Analysis of focus group data revealed that nurses in critical care settings use 17 strategies to identify, interrupt, and correct errors. Nurses used 8 strategies to identify errors: knowing the patient, knowing the “players, ” knowing the plan of care, surveillance, knowing policy/procedure, double-checking, using systematic processes, and questioning. Nurses used 3 strategies to interrupt errors: offering assistance, clarifying, and verbally interrupting. Nurses used 6 strategies to correct errors: persevering, being physically present, reviewing or confirming the plan of care, offering options, referencing standards or experts, and involving another nurse or physician. Conclusions These results reflect the pivotal role that critical care nurses play in the recovery of medical errors and ensuring patient safety. Several <b>error-recovery</b> strategies identified in this study were also reported by emergency nurses, providing further empirical support for nurses ’ role in the recovery of medical errors as proposed in the Eindhoven model. (America...|$|E
30|$|Important {{improvements}} {{have been}} recently proposed {{to increase the}} realism of simulations: the new features include mobility patterns matching real maps [9], detailed receiver models accounting for Viterbi <b>error-recovery</b> [10] and obstruction models accounting {{for the presence of}} buildings [3 – 5] and for the impact of vehicles acting themselves as obstacles [11]. According to [10], the impact of obstructions appears to be the most relevant.|$|E
40|$|In {{this paper}} we {{describe}} two <b>error-recovery</b> approaches for MPEG encoded video over ATM networks. The first approach aims at reconstructing each lost pixel by spatial interpolation {{from the nearest}} undamaged pixels. The second approach recovers lost macroblocks by minimizing intersample variations within each block and across its boundaries. Moreover, a new technique for packing ATM cells with compressed data is also proposed. 1...|$|E
40|$|The {{definition}} of reliable multicast has varied widely, going from requirements for absolute data reliability, strong group membership control, strong ordering guarantees, multiple senders, and small group sizes, to protocols with weaker data reliability, {{little or no}} group membership control, no ordering guarantees, single senders, and large to very large group sizes. The first group tends to have a flat <b>error-recovery</b> structure, and the second group tends to use a hierarchical <b>error-recovery</b> structure. A review of 8 representative "reliable multicast" protocols, each with a different {{definition of}} reliability, has {{identified a number of}} common characteristics, and distinct differences. As a step towards the definition of a protocol that is applicable to a wider range of applications, a new architecture is proposed in this thesis. It combines a central core operating as a fully-reliable, many-to-many protocol, providing communication among a group of "significant receivers", with a hierarchical, scalable, one-to-many protocol, providing distribution of the core data to a set of "simple receivers". The protocol is designed as a set of mechanisms to be invoked, or ignored, as needed. A mapping of the architecture to the representative protocols is presented...|$|E
40|$|High {{error rates}} and long {{propagation}} delays in underwater sensor networks call for efficient <b>error-recovery</b> schemes. We believe network coding is a promising technique {{for this purpose}} because of the broadcast nature of acoustic channels and computation capabilities at the sensor nodes. In this paper, we design a network coding scheme for underwater sensor networks and explore its performance through simulation. Our initial results indicate the benefits of using network coding for error recovery and the gains from coding at the source...|$|E
40|$|The current strong {{drive toward}} a {{ubiquitous}} communication world includes wireless networks on the Internet. Wireless communication {{has a significant}} frame loss rate due to bit errors, that often burst to very high rates because of environmental conditions, terrestrial obstructions, and reflections. Each terminal attached to wireless links has to support communication protocols that have <b>error-recovery</b> functions and window-based flow control (denoted as reliable-transmission window-based protocols: RWPs), such as HDLC and TCP, to guarantee high-quality services for reliable applications. Th...|$|E
40|$|Q-MED is an {{automated}} history-taking system that uses speaker-independent continuous speech as its main interface modality. Q-MED {{is designed to}} allow a patient to enter her basic symptoms by engaging in a dialog with the program. <b>Error-recovery</b> mechanisms help to eliminate findings resulting from misrecognitions or incorrect parses. An evaluation of the natural language parser that Q-MED uses to map user utterances to findings showed an overall semantic accuracy of 87 percent; Q-MED asks more specific questions to capture findings that were not volunteered, or that were unable to be parsed in their initial, open-ended form...|$|E
40|$|Abstract. Before {{the wide}} {{deployment}} of underwater sensor networks becomes a reality, {{one of the}} challenges that needs to be resolved is efficient error recovery in the presence of high error rates, node mobility and long propagation delays. In this paper, we propose an efficient <b>error-recovery</b> scheme that carefully couples network coding and multipath routing. Through an analytical study, we provide guidance on how to choose parameters in our scheme and demonstrate that our scheme is efficient in both error recovery and energy consumption. We evaluate the performance of our scheme using simulation and our simulation confirms the results from the analytical study. ...|$|E
40|$|The imprecise {{computation}} technique {{can be used}} in {{a natural}} way to enhance fault tolerance. By providing a usable, approximate result whenever a failure or overload prevent the system from producing the desired, precise result, we can increase the availability of data and services, reduce the need for <b>error-recovery</b> operations, and minimize the costs in replication. This paper describes the domain-specific fault tolerance mechanisms that are needed to support the provision and correct usage of imprecise results for several representative application domains. The elements of an application-domain-independent architecture that can effectively integrate these domain-specific mechanisms are also described...|$|E
40|$|Abstract — Transmission efficiency, {{defined as}} the the ratio of {{successfully}} transmitted information bits to overall bits trans-mitted, {{can be used for}} evaluating the transmission performance of wireless links. As a function of received signal to noise ratio (SNR), transmission efficiency is determined by physical layer technologies, such as channel coding, interleaving, modulation and other <b>error-recovery</b> techniques of wireless links. In this paper we first analyze the form of transmission efficiency function in wireless links, then based on that we propose an adaptive coding scheme that maximizes the transmission efficiency ac-cording to wireless channel conditions (received SNR). Simulation results show that with the proposed adaptive coding, transmission efficiency of wireless links can be significantly enhanced. I...|$|E
40|$|Parser {{is one of}} {{the most}} {{important}} parts in compiler since Syntax-Directed Translation is often used. This approach means that parser controls semantic actions and generation of syntax tree. When the input contains an error, parser cannot continue and the whole compiler has to stop. Therefore, it is important to have parser with error recovery, so when error occurs parser is able to continue. There are several <b>error-recovery</b> strategies and methods. In this paper is described Acceptable-sets derived from continuations specifically continuation in LL parsers. However it is not so well known method it is easy to explain and to implement. It can be used in the lesson to demonstrate error recovery in top-down parser...|$|E
40|$|URL] audienceThe {{experiment}} {{control system}} {{is in charge of}} the configuration, control and monitoring of the different subdetectors and of all areas of the online system. The building blocks of the control system are based on the PVSS SCADA System complemented by a control Framework developed in common for the 4 LHC experiments. This framework includes an "expert system" like tool called SMI++ which is used for the system automation. The experiment's operations are now almost completely automated, driven by a top-level object called Big-Brother, which pilots all the experiment's standard procedures and the most common <b>error-recovery</b> procedures. The architecture, tools and mechanisms used for the implementation as well as some operational examples will be described...|$|E
30|$|To tackle this challenge, {{a crucial}} {{observation}} can be made: When such a transient failure occurs during the deployment phase, in many cases, one only needs {{to repeat the}} deployment scripts that failed in order to overcome it. For example, {{take the case of}} installing new software packages to a newly allocated VM: If one wants to download a software package (e.g., through apt) and a network glitch occurs, all one has {{to do in order to}} overcome this error is to repeat the download command until the glitch vanishes. Evidently, the transient nature implies that the cloud user does not have control over it. Hence, an optimistic <b>error-recovery</b> policy would aim at repeating the script execution until the error disappears.|$|E
40|$|Abstract — Motivated by an <b>error-recovery</b> {{locomotion}} problem, {{we propose}} a control technique for a complex mechanical system by decomposing the system dynamics into {{a collection of}} simplified models. The robot considered, The Rocking and Rolling Robot (RRRobot), is a highcentered round-bodied robot that locomotes on a plane by swinging its legs and rocking on its shell. We identify the elements contributing to locomotion through two steps: 1) decoupling the leg-body rotation dynamics from the body-plane contact kinematics, and 2) decoupling the body rotational dynamics into dynamics along each rotational axis. We show, using simulation, that such decoupling provides a good approximation to RRRobot’s locomotion and use these models to find an approximate control solution for RRRobot: a mapping between planar translation and leg motions. I...|$|E
40|$|Abstract — One {{problem with}} {{communication}} {{system is that}} information is altered and lost due to noise in the channel. Impact of the data and information loss is disastrous for transmission of video and image signal as the harm to compressed bit stream leads to subjective and visual distortion at the decoder end. Further due to the real time needs which {{do not include the}} employment of certain <b>error-recovery</b> techniques for some of the process. The paper proposes the method for concealing error in the images and further improving the quality of images. The method of directional interpolation has been employed on images using thresholding technique and then the PSNR (peak signal to noise ratio) of image has been improved with image enhancement technique...|$|E
40|$|Abstract Motivated by an <b>error-recovery</b> {{locomotion}} problem, {{we propose}} a control technique for a complex mechanical system by decomposing the system dynamics into {{a collection of}} simplied models. The robot considered, The Rocking and Rolling Robot (RRRobot), is a high-centered round-bodied robot that locomotes on a plane by swinging its legs and rocking on its shell. We identify the elements contributing to locomotion through two steps: 1) decoupling the leg-body rotation dynamics from the body-plane contact kinematics, and 2) decoupling the body rotational dynamics into dynamics along each rotational axis. We show, using simulation, that such decoupling pro-vides a good approximation to RRRobot’s locomotion and use these models to nd an approximate control solution for RRRobot: a mapping between planar translation and leg motions. I...|$|E
40|$|Concern {{over the}} limited intravehicular {{activity}} time {{has increased the}} interest in performing in-space assembly and construction operations with automated robotic systems. A technique being considered at LaRC is a supervised-autonomy approach, which can be monitored by an Earth-based supervisor that intervenes only when the automated system encounters a problem. A test-bed to support evaluation of the hardware and software requirements for supervised-autonomy assembly methods was developed. This report describes {{the design of the}} software system necessary to support the assembly process. The software is hierarchical and supports both automated assembly operations and supervisor <b>error-recovery</b> procedures, including the capability to pause and reverse any operation. The software design serves {{as a model for the}} development of software for more sophisticated automated systems and as a test-bed for evaluation of new concepts and hardware components...|$|E
40|$|We {{focus on}} {{developing}} {{an account of}} user behavior under error conditions, working with annotated data from real human-machine mixed initiative dialogs. In particular, we examine categories of error perception, user behavior under error, effect of user strategies on error recovery, {{and the role of}} user initiative in error situations. A conditional probability model smoothed by weighted ASR error rate is proposed. Results show that users discovering errors through implicit confirmations are less likely {{to get back on track}} (or succeed) and take a longer time in doing so than other forms of error discovery such as system reject and reprompts. Further successful user <b>error-recovery</b> strategies included more rephrasing, less contradicting, and a tendency to terminate error episodes (cancel and startover) than to attempt at repairing a chain of errors...|$|E
40|$|Traffic {{transmission}} {{over the}} radio channel requires appropriate techniques to preserve information integrity while maintaining the desired QoS and energy constraints. In this paper, we focus on a possible configuration of the ARQ protocol defined in 3 GPP (Third Generation Partnership Project) technical specifications. A Markov model is developed in order to study the protocol behavior as channel characteristics change. Through this model, we evaluate {{the impact of the}} 3 GPP ARQ scheme on the QoS of traffic services such as data file transfer and IP telephony. In the case of data transfer, a trade-off between loss probability and energy efficiency is derived. In the case of IP telephony, we investigate the possibility to guarantee low maximum delay and low jitter by adopting the ARQ protocol as <b>error-recovery</b> scheme...|$|E
40|$|We {{propose to}} build a large {{low-cost}} computer cluster in order to study error recovery techniques for today and tomorrow’s large computer clusters. The Xbox game console is an inexpensive computer whose internal architecture {{is very close to}} that of a conventional Intel-based personal computer. In addition, it can be rebooted as a Linux computing node through software exploits without having to purchase any additional hardware or even opening the Xbox. We built a four-node cluster consisting of four unmodified Xboxes running Debian Linux and found out that a cluster of Xboxes linked by a Fast Ethernet would constitute a scaled down version of a current generation supercomputer with the same number of nodes. As a result, it would provide a cost-effective testbed for investigating novel distributed <b>error-recovery</b> algorithms and testing how they would scale up...|$|E
40|$|Abstract—One {{approach}} to achieving scalability in reliable multicast {{is to use}} a hierarchy. A hierarchy can be established at the application level, or by using router-assist. With router-assist we have more fine-grain control over the placement of <b>error-recovery</b> functionality, therefore, a hierarchy produced by assistance from the routers is expected to have better performance. In this paper, we test this hypothesis by comparing two schemes, one that uses an application-level hierarchy (ALH) and another that uses router-assisted hierarchy (RAH). Contrary to our expectations, we find that the qualitative performance of ALH is comparable to RAH. We do not model the overhead of creating the hierarchy nor the cost of adding router-assist to the network. Therefore, our conclusions inform rather than close the debate of which approach is better. Index Terms—Reliable multicast, router-assist for reliable multicast. I...|$|E
40|$|Concern over limited extravehicular and intravehicular activitiy {{time has}} {{increased}} the interest in performing in-space assembly and construction operations with automated robotic systems. A technique being considered at Langley Research Center is a supervised-autonomy approach, which can be monitored by an Earth-based supervisor that intervenes only when the automated system encounters a problem. A test-bed to support evaluation of the hardware and software requirements for supervised-autonomy assembly methods has been developed. This report describes {{the design of the}} software system necessary to support the assembly process. The system is implemented and successfully assembles and disassembles a planar tetrahedral truss structure. The software is hierarchical and supports both automated assembly operations and supervisor <b>error-recovery</b> procedures, including the capability to pause and reverse any operation. The software design serves as a mode l for the development of software for m [...] ...|$|E
40|$|In this paper, {{we address}} the issue of how to design IVR {{interfaces}} for the developing world. Against the backdrop of the following idiosyncratic observations including, the majority of users being either semi-literate or non-literate, and the impact of a different set of social-cultural, linguistic, and domestic challenges, amongst others, we advocate the enculturation of IVR interfaces different from the developed world. This requires the tailoring of functionalities and interactive modalities to the cultural values and context of use. Thus, we propose a dialog (user interface) design model consisting of three components: Get input, <b>Error-recovery,</b> and Play results (output). These are shown to be critical for implementing usable and culturally-suitable IVR interfaces for low-literacy user populations. KEY WORDS Interactive Voice Response (IVR), speech and natural language interfaces, user interface development, low literacy, developing world, localisation. 1...|$|E
40|$|This paper {{presents}} {{a mechanism for}} modeling timing, precedence, and data-consistency constraints on concurrently executing processes. The model allows durations and intervals between events to be specified. An algorithm is provided to detect schedules which may be unsafe {{with respect to the}} constraints. This work, motivated by the design and validation of autonomous <b>error-recovery</b> strategies on the Galileo spacecraft, appears to be applicable to a variety of asynchronous real-time systems. I. INTRODUCTION This paper {{presents a}} technique for detecting unsafe schedules involving the asynchronous software processes responsible for error recovery onboard spacecraft. These autonomous processes are constrained at the event level by timing, precedence, and data-consistency rules. A schedule (ordering of events) that violates these constraints can jeopardize the spacecraft and is labeled unsafe. Safety involves those correctness properties required by the static portions of the specification [...] ...|$|E
40|$|This paper {{describes}} how the transformational framework developed in [Liu 91, LJ 92] is applied to backward <b>error-recovery</b> in asynchronous communicating systems. A physical fault is modelled as an atomic action which performs state transformations {{in the same way}} as any other program action. The possible effects of a set of faults on the execution of a program are described by a transformation of the program into its fault-affected version. Fault-tolerance is provided by using transformations to add recovery actions to a non-fault-tolerant program, so that the fault-affected version of the transformed program will then satisfy a required specification. Refinement transformations can be used in the development of a fault-tolerant program. This paper provides a feasible and formal way to consider existing backward recovery techniques in terms of simple transformations. Keywords: transformations, faults, checkpoints, recovery propagation...|$|E
40|$|Abstract. A finite-state {{automaton}} is adopted {{as a model}} for Discrete Event Dynamic Systems (DEDS), Stabdity is defined as wslting a given set E mtinitely often. Stabilizability is defined as choosing state feedback such that the closed loop system is stable. These notions are proposed as properties of resiliency or <b>error-recovery.</b> An important ingredient in stability is shown to be a notion of transitionfunction-invariance. Relations between our notions of stability and invariance, and the notions of safety, fairness, hvelock, deadlock, etc., in computer science literature are pointed out. Connections are established between our notions of invariance and the classical notions of A-Invariance and (A. 11) -invariance of linear systems. Polynomial algorithms for testing stability and stabilizabdity, and for constructing a stabilizing control law are also presented. Categories and Subject Descriptors: F. 2. 2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems—computations on discrete structures; sequencing an...|$|E
40|$|When {{transmitting}} images over practical communication channels, {{they are}} subject to packet loss and random errors due to the noisy nature of the channel. Errors and data loss are customarily recovered by means of error correction coding/decoding. In this paper, robust <b>error-recovery</b> algorithms are developed by utilizing the redundancy inherent in frame expansions. A new class of wavelet-type frames in signal space using (anti) symmetric waveforms is presented. The construction employs interpolatory filters with rational transfer functions. These filters have linear-phase. They are amenable to fast cascading or parallel recursive implementation. Experimental results recover images when (as much as) 60 % of the packets are either lost or corrupted. The proposed approach inflates the size of the image through framelet expansion thus providing redundant representation of the image; this transform may be followed by compression. Finally, the frame-based error recovery algorithm is compared with a classical coding approach. ...|$|E
