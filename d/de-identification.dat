311|0|Public
5000|$|<b>De-Identification</b> Maturity Model - The <b>De-Identification</b> Maturity Model is {{a formal}} {{framework}} {{with which to}} evaluate maturity of <b>de-identification</b> services in an organization. It gauges the level of an organization's readiness and experience in relation to people, processes, technologies and consistent measurement practices with respect to <b>de-identification</b> {{with the goal of}} improving compliance, facilitating access, and scaling support services.|$|E
5000|$|Higher {{standards}} and uniform definition of <b>de-identification</b> while retaining data utility: {{the definition of}} <b>de-identification</b> should balance privacy protections to reduce re-identification risk with the refusal of companies to delete data ...|$|E
5000|$|<b>De-identification</b> is {{the process}} used to prevent a person's {{identity}} from being connected with information. Common uses of <b>de-identification</b> include human subject research {{for the sake of}} privacy for research participants. Common strategies for de-identifying datasets include deleting or masking personal identifiers, such as name and social security number, and suppressing or generalizing quasi-identifiers, such as date of birth and zip code. The reverse process of defeating <b>de-identification</b> to identify individuals is known as re-identification. Several successful re-identifications attempts [...] have purported to doubt on the effectiveness of <b>de-identification</b> in protecting individuals' privacy. A systematic review of the evidence found that published re-identification attacks were performed on data sets that were not de-identified properly (using recognized standards).|$|E
5000|$|... #Caption: Privacy Analytics', {{the health}} data <b>de-identification</b> experts, logo ...|$|E
5000|$|... #Subtitle level 2: <b>De-identification</b> {{laws in the}} United States of America ...|$|E
5000|$|The {{safe harbor}} method uses a list {{approach}} to <b>de-identification</b> {{and has two}} requirements: ...|$|E
50|$|K. El Emam: Guide to the <b>De-Identification</b> of Personal Health Information. Auerbach Publications (CRC Press), 2013.|$|E
50|$|<b>De-identification</b> is {{an attempt}} to divide a {{collection}} of information about a particular person so that all information which identifies the person is removed, and with intent to distribute whatever information is left. The closer the data is to anonymization the less valuable the data is to those who want it, so in general, data is only de-identified somewhat and rarely anonymized. There are many controversies in <b>de-identification.</b>|$|E
50|$|Pseudonyms and {{acronyms}} {{are often}} employed in medical research to protect subjects' identities {{through a process}} known as <b>de-identification.</b>|$|E
50|$|In big data, <b>de-identification</b> {{is widely}} adopted by {{individuals}} and organizations. With {{the development of}} social media, e-commerce and big data, <b>de-identification</b> is required and used for data privacy when users' personal data are collected for analyzing by companies or third-party organizations. Social network sites collect and save their users' data for analysis of user behavior. They adopt this approach to protect their users' privacy. Those online shopping websites adopt this method as well.|$|E
50|$|Research into <b>de-identification</b> {{is driven}} mostly for {{protecting}} health information. Some libraries have adopted methods {{used in the}} healthcare industry to preserve their readers' privacy.|$|E
50|$|Dr. Khaled El Emam is {{the founder}} and CEO of Privacy Analytics. Dr El Emam is also a senior {{scientist}} at the Children’s Hospital of Eastern Ontario (CHEO) Research Institute and Director of the multi-disciplinary Electronic Health Information Laboratory (EHIL), conducting academic research on <b>de-identification</b> and re-identification risk. He is an expert in statistical <b>de-identification</b> and re-identification risk. He is {{one of only a handful}} of individual experts in North America qualified to certify the anonymization of Protected Health Information under the HIPAA privacy law.|$|E
5000|$|Privacy Analytics Risk Monitor Privacy Analytics Risk Monitor is a privacy risk {{assessment}} tool that provides visibility into {{the effectiveness of}} your current <b>de-identification</b> and masking strategy.|$|E
5000|$|Discovery {{of hidden}} {{sensitive}} data {{such as the}} last four digits of a social security number hidden in another user id {{as part of a}} data masking or <b>de-identification</b> project ...|$|E
50|$|Common {{strategies}} of <b>de-identification</b> are masking personal identifiers and generalizing quasi-identifiers. Pseudonymization {{is the main}} technique used to mask personal identifiers from data records and k-anonymization is usually adopted for generalizing quasi-identifiers.|$|E
50|$|PHI {{is often}} sought out in {{datasets}} for <b>de-identification</b> before researchers share the dataset publicly. When researchers remove PHI from a dataset {{they do so}} {{in an attempt to}} preserve privacy for research participants.|$|E
5000|$|Data Re-Identification is the {{practice}} of matching de-identified data with publicly available information, or auxiliary data, in order to discover the individual to which the data belongs to. This is a concern because companies with privacy policies, health care providers, and financial institutions may release the data they collect after the data has gone through the <b>de-identification</b> process. The <b>de-identification</b> process involves masking, generalizing or deleting both direct and indirect identifiers; the definition {{of this process is}} not universal, however. Information in the public domain, even seemingly anonymized, may thus be re-identified in combination with other pieces of available data and basic computer science techniques. The Common Rule Agencies, a collection of multiple U.S. federal agencies and departments including the U.S. Department of Health and Human Services, speculate that re-identification is becoming gradually easier because of [...] "big data" [...] - the abundance and constant collection and analysis of information along the evolution of technologies and the advances of algorithms. However, others have claimed that <b>de-identification</b> is a safe and effective data liberation tool and do not view re-identification as a concern.|$|E
50|$|<b>De-identification</b> {{is adopted}} {{as one of}} the main {{approaches}} of data privacy protection. It is commonly used in fields of communications, multimedia, biometrics, big data, cloud computing, data mining, internet, social networks and audio-video surveillance.|$|E
5000|$|... identification, {{which can}} mean {{breaking}} the <b>de-identification</b> of items of data by putting {{it through a}} de-anonymization process, thus making facts which were intended to not name particular people to become associated with those people ...|$|E
50|$|Some {{researchers}} {{have suggested that}} it is not reasonable to ever promise participants in genetics research that they can retain their anonymity, but instead such participants should be taught the limits of using coded identifiers in a <b>de-identification</b> process.|$|E
50|$|There {{are several}} types of data that {{researchers}} must to protect when collecting, handling, storing and sharing data to safeguard the confidentiality of contributors. There are three primary types of information. Personally identifiable information includes any data that allows the identity of an individual to whom the information applies to be realistically deduced by either direct or indirect means. Protected health information includes individually identifiable health information transmitted or maintained in any form or medium by a covered entity. Other sensitive information that should be protected include data {{that if it were}} disclosed would have a significant likelihood to cause psychological, social, emotional, physical, or reputation harm. A common approach for data sharing that includes confidential material is through <b>de-identification</b> or anonymization. There are numerous techniques for the <b>de-identification</b> of data including simply removing specific variables or by using statistical techniques such as top-coding, collapsing or combining, sampling, swapping, or disturbing the data. For qualitative data, redaction can be used to hide data elements that cannot be made public. However, it is important that future research requirements be taken into consideration when developing a <b>de-identification</b> or anonymization plan.|$|E
5000|$|A {{focus on}} the process of {{creating}} data-release policies: making sure <b>de-identification</b> rhetoric is accurate, drawing up contracts that prohibit re-identification attempts and dissemination of sensitive information, establishing data enclaves, and utilizing data-based strategies to match required protection standards to the level of risk.|$|E
5000|$|The United States President's Council of Advisors on Science and Technology {{and others}} have {{recently}} deemed <b>de-identification</b> [...] "somewhat useful as an added safeguard" [...] but not [...] "a useful basis for policy" [...] as [...] "it is not robust against near‐term future re‐identification methods".|$|E
50|$|An {{example of}} {{application}} of Pseudonymization procedure is creation of datasets for <b>De-identification</b> research by replacing identifying words with {{words from the}} same category (e.g. replacing a name with a random name from the names dictionary), however, {{in this case it}} is in general not possible to track data back to its origins.|$|E
5000|$|Privacy Analytics, Inc. is a 2007 {{spin-off}} {{from the}} Electronic Health Information Laboratory, {{a collection of}} active academic authors working {{in the area of}} health data risk mitigation and <b>de-identification.</b> It is headquartered in Ottawa, Ontario with a secondary office in Toronto. [...] They were purchased by IMS Health on May 26, 2016.|$|E
50|$|Privacy Analytics Inc. is a Canadian {{technology}} {{firm that}} claims to offer the only commercially available integrated data masking and <b>de-identification</b> product on the market today. Its products and services are used by hospitals and other health providers, universities and research groups, public health programs, registries, HMOs, pharmaceutical companies, insurance claims processors, and health information technology vendors.|$|E
5000|$|A online {{shopping}} website {{wants to know}} its users' preferences and shopping habits. It decides to retrieve customers' data from its database and do analysis on them. The personal data information including personal identifiers were collected directly when customers created their accounts. The website needs to pre-handle the data by <b>de-identification</b> techniques before analyzing data records to avoid violating customers' privacy.|$|E
5000|$|Expert Determination takes a risk-based {{approach}} to <b>de-identification</b> that applies current standards and best practices {{from the research}} to determine {{the likelihood that a}} person could be identified from their protected health information. This method requires that a person with appropriate knowledge of and experience with generally accepted statistical and scientific principles and methods render the information not individually identifiable. It requires: ...|$|E
50|$|Towards {{the more}} {{implementation}} levels, privacy engineering employs privacy enhancing technologies to enable anonymisation and <b>de-identification</b> of data. Privacy engineering requires suitable security engineering practices to be deployed, and some privacy aspects {{can be implemented}} using security techniques. A privacy impact assessment is another tool within this context and its use {{does not imply that}} privacy engineering is being practiced.|$|E
5000|$|Participant {{medical history}} is {{maintained}} at a centralized governmental database (RAMQ) allowing researchers to track these individuals {{for the duration}} of the study and monitor all medical events, prescriptions of drugs and deaths. [...] The personal information connecting medical records to the patient identification undergoes <b>de-identification</b> and is coded by CARTaGENE, but handled and managed by the RAMQ ensuring patient confidentiality.|$|E
50|$|The HIPAA Privacy Rule {{provides}} {{mechanisms for}} using and disclosing health data responsibly {{without the need}} for patient consent. These mechanisms center on two HIPAA <b>de-identification</b> standards - Safe Harbor and the Expert Determination Method. Safe Harbor relies on the removal of specific patient identifiers (e.g. name, phone number, email address, etc.) while the Expert Determination Method requires knowledge and experience with generally accepted statistical and scientific principles and methods to render information not individually identifiable.|$|E
50|$|De-{{identified}} data is coded, with {{a link to}} the original, fully identified {{data set}} kept by an honest broker. Links exist in coded de-identified data making the data considered indirectly identifiable and not anonymized. Coded de-identified data is not protected by the HIPAA Privacy Rule, but is protected under the Common Rule. The purpose of <b>de-identification</b> and anonymization is to use health care data in larger increments, for research purposes. Universities, government agencies, and private health care entities use such data for research, development and marketing purposes.|$|E
50|$|Anonymization {{refers to}} irreversibly {{severing}} a data set from {{the identity of}} the data contributor in a study to prevent any future re-identification, even by the study organizers under any condition. <b>De-identification</b> is also a severing of a data set from {{the identity of the}} data contributor, but may include preserving identifying information which can only be re-linked by a trusted party in certain situations. There is a debate in the technology community of whether data that can be re-linked, even by a trusted party, should ever be considered de-identified.|$|E
50|$|In {{terms of}} {{university}} records, authorities {{both on the}} state and federal level have shown an awareness about issues of privacy in education and a distaste for institutions' disclosure of information. The U.S. Department of Education has provided guidance about data discourse and identification, instructing educational institutions {{to be sensitive to the}} risk of re-identification of anonymous data by cross-referencing with auxiliary data, to minimize the amount of data in the public domain by decreasing publication of directory information about students and institutional personnel, and to be consistent in the processes of <b>de-identification.</b>|$|E
50|$|Since 2012, Anonos {{has been}} {{developing}} technology that transforms data at the data element level enabling dynamic data obscurity that preserves the value of underlying data. Specifically, Anonos <b>de-identification</b> and dynamic data obscurity risk management tools provide trusted party control for data subjects enabling them to share information {{in a controlled manner}} to receive information, services and offerings truly personalized for them, while protecting misuse of their data. Dynamic data obscurity can facilitate improved healthcare, medical research and personalized medicine by enabling aggregation of patient level data without revealing the identity of patients.|$|E
50|$|Carns {{retired from}} the United States Air Force in July 1994. After {{retiring}} from the U.S. Air Force, he served as the Managing Director of a small healthcare firm for one year, followed by over four years as Executive Director of a New York-based policy research firm that specialized in Pacific Rim security {{in the areas of}} international capital flows and international energy demands. He is currently the Vice Chairman of PrivaSource, Inc., a small software firm specializing in the security and <b>de-identification</b> of large, sensitive databases, in Weston, Massachusetts. Carns is also currently serves on the Board of Directors for VirtualAgility, Inc. and M-International, Inc.|$|E
