2|3818|Public
40|$|Many {{disciplines}} of multimedia and communication go towards ubiquitous computing and <b>hand</b> <b>free</b> <b>interaction</b> with computers. Application domains {{in this direction}} involve virtual reality, augmented reality, wearable computing, and smart spaces. This paper presents two main approaches to developing and testing these interfaces using gestures. It presents the important issues in gesture communication, from a technological viewpoint {{as well as a}} user viewpoint such as the technological complexity, learning rate, ergonomics, and intuition. These issues {{must be taken into account}} when choosing the gesture vocabulary. A procedure is proposed which includes those issues in the selection of gestures, and to test the resulting set of gestures. The procedure is tested and demonstrated on an example application with a small test group. The procedure is concluded to be useful and time consuming. The importance of using theory from ergonomics is also concluded...|$|E
40|$|The {{shortage}} of physicians afflicting developed countries encourages engineers and doctors to collaborate towards {{the development of}} telemedicine. In particular, robotic systems {{have the potential for}} helping doctors making examination. A very common examination that can be the goal of a robotic system is palpation. Most of the robotics systems that have been developed for palpation present interesting features such as integrating augmented reality environments or allowing for <b>hand</b> <b>free</b> <b>interaction.</b> In this paper we present a novel palpation system that allows us to perform virtual palpation of real objects by means of a haptic and an augmented reality feedback. This system features an encountered-type haptic interface in which the haptic feedback is calculated by a collision detection algorithm that is based on online recording of the surface to be touched. The system allows the users to remove their hand from the haptic interface end-effector that follows the user?s hand thanks to the tracking performed by a Leap Motion. We show that the system provides a natural interaction during the contact-non contact switch, a suitable force during indentation, and it allows to discriminate objects within the body through the haptic channel...|$|E
40|$|This paper {{presents}} {{a study that}} explores the issues of mobile multimodal interactions {{while on the move}} in the real world. Because multimodal interfaces allow new kinds of eyes and <b>hands</b> <b>free</b> <b>interactions,</b> usability issues while moving through different public spaces becomes an important issue in user experience and acceptance of multimodal interaction. This study focuses on these issues by deploying an RSS reader that participants used during their daily commute every day for one week. The system allows participants on the move to access news feeds eyes free through headphones playing audio and speech and <b>hands</b> <b>free</b> through wearable sensors attached to the wrists. The results showed participants were able to interact with the system on the move and became more comfortable performing these interactions as the study progressed. However, participants were far more comfortable gesturing on the street than on public transport, which was reflected in the number of interactions and the perceived social acceptability of the gestures in different contexts...|$|R
40|$|This paper {{describes}} {{recent advances}} {{on the use}} of HMM based technology, for speaker independent continuous speech recognition, in noisy environment, under <b>hands</b> <b>free</b> <b>interaction</b> mode. For this purpose an array of four ominidirectional microphones is employed as acquisition system. The processing of phase information in the Cross-power Spectrum provides the capability both of locating talker position and of reconstructing an enhanced speech spectrum. Here, two enhancement techniques are described, that allow recognition improvement in the case of clean input speech as well as under different adverse conditions. Results refer to the use of a new multichannel corpus, collected in real environment by microphone array as well as close-talk microphone. 1. INTRODUCTION The ability of speech recognition systems to deal with diversified environmental conditions, speaker interaction modes, and acquisition channels is still far to be achieved. When there is mismatch in training and testing cond [...] ...|$|R
40|$|Abstract. With {{dwell time}} activation, {{completely}} <b>hands</b> <b>free</b> <b>interaction</b> may {{be achieved by}} tracking the user’s gaze positions. The first study presented compares typing by mouse click with dwell time typing on Danish on-screen keyboard with 10 large buttons which change according to character prediction. The second study compares mouse and eye-gaze dwell input on a similar Japanese keyboard, but without dynamic changes. In the first study, dwell time selections {{tend to be a}} little slower and the overproduction is higher than with click selections. In the second study, mouse and gaze is almost equally fast, but mouse is far more precise than gaze. Consequently, the productivity in terms of characters per minute is 33 % higher. The results suggest that users can be productive from the first encounter with dwell time activation, but productivity depends on their familiarity with the input structure and the input mode (i. e. hand or eye) ...|$|R
40|$|Eye {{tracking}} is {{a process}} that allows an observers gaze to be determined in real time by measuring their eye movements. Recent work has examined the possibility of using gaze control as an alternative input modality in interactive applications. Alternative means of interaction are especially important for disabled users for whom traditional techniques, such as mouse and keyboard, may not be feasible. This paper proposes a novel combination of gaze and voice commands as a means of <b>hands</b> <b>free</b> <b>interaction</b> in a paint style program. A drawing application is implemented which is controllable by input from gaze and voice. Voice commands are used to activate drawing which allow gaze to be used only for positioning the cursor. In previous work gaze has also been used to activate drawing using dwell time. The drawing application is evaluated using subjective responses from participant user trials. The main result indicates that although gaze and voice o ered less control that traditional input devices, the participants reported that it was more enjoyable...|$|R
40|$|Haptic {{interaction}} with virtual objects is typically tool mediated, or in alternative it constraints userpsilas body in someway, like {{it happens in}} exoskeletons that cannot be totally transparent. Encounter type haptic interfaces aim at <b>hands</b> <b>free</b> haptic <b>interaction,</b> that is more natural and can be applied in contexts in which the user moves in the space around the interface. This paper presents a system that allows a palm based haptic interaction in a large workspace using the principle of encountered haptics. The system is evaluated in a surface exploration task and compared against the same task performed with a standard haptic interface. In this type of task this type of interface is better suited, providing a smoother feedback to the hand during the movement over the surface...|$|R
40|$|While mobile {{devices have}} {{experienced}} important accessibility {{advances in the}} past years, people with visual impairments still face important barriers, especially in specific contexts when both their <b>hands</b> are not <b>free</b> to hold the mobile device, like when walking outside. By resorting to a multimodal combination of body based gestures and voice, we aim to achieve full <b>hands</b> and vision <b>free</b> <b>interaction</b> with mobile devices. In this article, we describe this vision and present {{the design of a}} prototype, inspired by that vision, of a text messaging application. The article also presents a user study where the suitability of the proposed approach was assessed, and a performance comparison between our prototype and existing SMS applications was conducted. Study participants received positively the prototype, which also supported better performance in tasks that involved text editing...|$|R
40|$|Abstract. Distant {{displays}} such as interactive Public Displays (IPD) or Interactive Television (ITV) require new {{interaction techniques}} as traditional input devices {{may be limited}} or missing in these contexts. <b>Free</b> <b>hand</b> <b>interaction,</b> as sensed with computer vision techniques, presents a promising interaction technique. This paper presents the adaptation of three menu techniques for <b>free</b> <b>hand</b> interaction: Linear menu, Marking menu and Finger-Count menu. The first study based on a Wizard-of-OZ protocol focuses on Finger-Counting postures in front of interactive television and public displays. It reveals that participants do choose the most efficient gestures neither before nor after the experiment. Results are used to develop a Finger-Count recognizer. The second experiment shows that all techniques achieve satisfactory accuracy. It also shows that Finger-Count requires more mental demand than other techniques...|$|R
40|$|Part 1 : Long and Short PapersInternational {{audience}} Distant displays such as interactive Public Displays (IPD) or Interactive Television (ITV) require new {{interaction techniques}} as traditional input devices {{may be limited}} or missing in these contexts. <b>Free</b> <b>hand</b> <b>interaction,</b> as sensed with computer vision techniques, presents a promising interaction technique. This paper presents the adaptation of three menu techniques for <b>free</b> <b>hand</b> interaction: Linear menu, Marking menu and Finger-Count menu. The first study based on a Wizard-of-OZ protocol focuses on Finger-Counting postures in front of interactive television and public displays. It reveals that participants do choose the most efficient gestures neither before nor after the experiment. Results are used to develop a Finger-Count recognizer. The second experiment shows that all techniques achieve satisfactory accuracy. It also shows that Finger-Count requires more mental demand than other techniques. </p...|$|R
40|$|Traversing large {{open spaces}} is a {{challenging}} task for blind cane users, as such spaces are often devoid of tactile fea-tures {{that can be}} followed. Consequently, in such spaces cane users may veer from their intended paths. Wearable de-vices have great potential for assistive applications for users who are blind as they typically feature a camera and sup-port <b>hands</b> and eye <b>free</b> <b>interaction.</b> We present HEADLOCK, a navigation aid for an optical head-mounted display that helps blind users traverse large open spaces by letting them lock onto a salient landmark across the space, such as a door, and then providing audio feedback to guide the user towards the landmark. A user study with 8 blind users eval-uated the usability and effectiveness of two types of audio feedback (sonification and text-to-speech) for guiding a user across an open space to a doorway. Qualitative results are reported, which may inform the design of assistive wearable technology for users who are blind...|$|R
40|$|The {{number of}} artists who express {{themselves}} through mu-sic in an unconventional way is constantly growing. This trend strongly depends on the high diffusion of laptops, which proved to be powerful and flexible musical devices. However laptops still lack in flexible interface, specifically designed for music creation in live and studio performances. To resolve this issue many controllers have been developed, taking into account not only the performer’s needs and habits during music creation, but also the audience desire to visually understand how performer’s gestures {{are linked to the}} way music is made. According to the common need of adaptable visual interface to manipulate music, in this pa-per we present a custom tridimensional controller, based on Open Sound Control protocol and completely designed to work inside Virtual Reality: simple geometrical shapes can be created to directly control loop triggering and parameter modification, just using <b>free</b> <b>hand</b> <b>interaction...</b>|$|R
40|$|This paper {{reports on}} the design and {{evaluation}} of direct 3 D gesture interaction with a full horizontal parallax light field display. A light field display defines a visual scene using directional light beams emitted from multiple light sources {{as if they are}} emitted from scene points. Each scene point is rendered individually resulting in more realistic and accurate 3 D visualization compared to other 3 D displaying technologies. We propose an interaction setup combining the visualization of objects within the Field Of View (FOV) of a light field display and their selection through freehand gesture tracked by the Leap Motion Controller. The accuracy and usefulness of the proposed interaction setup was also evaluated in a user study with test subjects. The results of the study revealed high user preference for <b>free</b> <b>hand</b> <b>interaction</b> with light field display as well as relatively low cognitive demand of this technique. Further, our results also revealed some limitations and adjustments of the proposed setup to be addressed in future work...|$|R
40|$|AbstractShould Shera and Eagan who whose social {{epistemology}} phenomenon for {{the first}} time in Librarianship literature, happen to still have chance to continue their studies today, they would, beyond doubt, find social media as a topic worthy of study. Shera and Eagan emphasized the role of bibliographic tools as tools for intellectual sharing of information as well as the need for scrutinizing their social effects. We observe the printed communication sources which drew attention and were very effective in creation and intellectual sharing of information by the beginning of 20 th Century, have nowadays been replaced by social media. Thanks to richness of second generation information technologies (Web 2. 0), creation and sharing of the information take place at a faster pace and in a much more participative scale. On the other <b>hand,</b> <b>free</b> and unchecked <b>interaction</b> of the information, paved the road for emergence of ‘disinformation’, ‘misinformation’, ‘uncontrolled information’ and ‘manipulated information’. While, on one hand, use of information and knowledge is encouraged, on the other hand, both these phenomena became fully integrated into consumerist culture by transforming into a commodity, which is easily consumed by the society. In this paper this current situation shall be debated and a descriptive analysis shall be made...|$|R
40|$|For {{a better}} {{understanding}} of how different diseases (e. g. neurovascular diseases, neurodegenerative diseases, and musculoskeletal pain conditions) affect human motor function, a uniform, standardized and objective evaluation is a desirable goal expressed within the clinical community. We explore the capabilities of an augmented reality (AR) game that uses <b>free</b> <b>hand</b> <b>interaction</b> to facilitate an objective assessment of the upper extremity motor dysfunction. First, the design process of the game and the system architecture are described. Second, a study about usability of the AR framework and game engagement is presented based on an experiment we conducted with five patients and ten healthy people. Lastly, a short analysis of the accuracy of the hand data when participants performed “fingers tapping” gesture is done. The results of the study show that even though users experienced the system as physically and mentally demanding, it was engaging enough to make them complete the game. The study also shows that hand data captured is accurate enough to allow a high degree (95 %) of pinching gesture recognition. Electrical Engineering, Mathematics and Computer ScienceSystem Engineerin...|$|R
40|$|<b>HAND</b> <b>FREE?</b> ??? ??????? ???????? ?????????? ????????. ????????, ?? ???????? ???? ???? ???????? ?????? ???????????? ????????? ??????? ???????? ???????. ?????????????, ?? ??????????? ????????? ?????? ??????? ????? ?????????? ?????? ?<b>HAND</b> <b>FREE?</b> ????? ??????????? ?? ????????? ???????????? ???????, ????????? ????? ??????????? ? ??????????? ??????????????? ????????? ??????????? ??????????. The {{problem of}} saving the ? <b>HAND</b> <b>FREE</b> ? {{function}} of numeral telephones, when there?s a protection set, is considered. It is shown, {{that the problem}} can be solved {{at the expense of}} transformation of a control signal of a protective system. It is marked, that after completion of a ? <b>HAND</b> <b>FREE</b> ? session it is possible to provide warranted insert of a condition of a guard {{with the help of a}} special giving warning signal which parameters are selected in view of regularities of mutual ultrasonic masking...|$|R
50|$|Headlamps/head torches {{that provide}} <b>hands</b> <b>free</b> lighting.|$|R
60|$|Arms and <b>hands,</b> <b>free</b> use of, {{indirectly}} {{correlated with}} diminution of canines.|$|R
5000|$|<b>Hands</b> <b>Free</b> Liftgate (Standard mid {{year into}} the 2015 model year, {{optional}} on LT) ...|$|R
5000|$|Instigators: [...] "53rd State", [...] "The Blood is on Your <b>Hands,</b> <b>Free</b> (You're Not)" ...|$|R
50|$|Made to <b>Hands</b> <b>Free,</b> Mobile phone Charger, FM Transmitter, Fixed Terminal Phone and Ear phone.|$|R
5000|$|General Motors OnStar: {{provides}} subscription-based telecommunication, in-vehicle security, <b>hands</b> <b>free</b> calling, navigation, {{and remote}} diagnostics.|$|R
60|$|She {{snatched}} her <b>hand</b> <b>free</b> from Alison's, {{and fled}} {{out of the}} room, into the hallway.|$|R
50|$|Many {{cordless}} telephones have a handset speakerphone {{as well as}} a base speakerphone. The handset speakerphone allows <b>hands</b> <b>free</b> conversations {{away from}} the base unit. The base speakerphone is located in the base unit. The user must be at the base unit, but still gets the added benefits of having <b>hands</b> <b>free</b> conversations. Most base speakerphones have a secondary keypad for dialing calls on the base unit.|$|R
50|$|Mobile Safety Steps, {{sometimes}} called warehouse steps, differ from Ladders {{in that they}} are completely self-supporting structures with a platform and are mobile, using wheels or castors making them easy to move. They have the advantage over standard ladders in that the operative can have one <b>hand</b> <b>free</b> when moving up and down the steps and both <b>hands</b> <b>free</b> if there is a top level platform.|$|R
50|$|SY Telecom (hangul:에스와이 텔레콤) is a <b>Hands</b> <b>free</b> and {{earphone}} manufacturer. It is {{headquartered in}} Incheon, Korea.|$|R
5000|$|Wristlet: {{a type of}} wallet {{that can}} be secured to the wrist, to keep one's <b>hands</b> <b>free.</b>|$|R
50|$|Ingle's fighters {{relied on}} {{footwork}} and reflexes for defence, leaving the <b>hands</b> <b>free</b> for offensive activity. In accordance with Ingle's doctrine, stance was optimised to provide leverage for punches and the unorthodox defence posture left the <b>hands</b> <b>free</b> for powerful punching {{from a wide}} variety of often unusual angles. This significantly increased tactical options for Ingle-trained boxers while reducing the scope for the opposing fighters to anticipate attacks.|$|R
50|$|<b>Free</b> <b>interaction</b> time: the swimmer has the {{opportunity}} to establish free and open contact with dolphins.|$|R
40|$|Previous {{observations}} that fin-generated interactions are quasi-conical in nature were further confirmed by surface pressure measurements spanning Mach 2. 5 - 3. 5, which encompassed unseparated through strongly separated interactions. For strongly separated interactions {{in which the}} shock wave is bifurcated into a lambda-foot structure, the conical <b>free</b> <b>interaction</b> hypothesis was validated through an appropriate scaling of the far-field surface pressure distribution. The behavior of the lambda-foot structure, such as the decrease of {{the slope of the}} separation shock with interaction strength, was explained by invoking the conical <b>free</b> <b>interaction</b> hypothesis. Through the conical <b>free</b> <b>interaction</b> hypothesis, it was further shown that the triple-shock intersection behaves in a complicated manner with changes in interaction strength...|$|R
50|$|Goli {{fast food}} chain {{products}} are prepared in fully automated ‘HACCP’ certified <b>hands</b> <b>free</b> plant frozen at -18 degree Celsius.|$|R
50|$|In 1985 and 1986 {{she was an}} {{assistant}} professor in Design 07 and Taller Ventrillon (<b>hand</b> <b>free</b> drawing) at Universidad Central.|$|R
40|$|Tracheo-esophageal {{speech with}} manual versus {{automatic}} stoma occlusion: A multidimensional comparison. Annelies Labaere 1, Jan Vanderwegen 2, Frans Debruyne 1 1 Department of Otorhinolaryngology, Head and Neck Surgery, University Hospitals Leuven, Belgium 2 Antwerp University Hospital, Department of Otorhinolaryngology, Antwerp, Belgium Annelies. Labaere@uz. kuleuven. ac. be Objectives: The {{objective of this}} study was to make a qualitative comparison between tracheo-esophageal speech with manual stoma occlusion and <b>hands</b> <b>free</b> tracheo-esophageal speech with the Provox FreeHands device. Patients/Materials and Methods: Both Manual and handsfree tracheo-esophageal speech were compared in 13 patients who were regular users of Provox Freehands for at least four months. Evaluation of speech material consisted of objective analysis using the KayPentax CSL, perceptual ratings by a group of experienced listeners and patients own perceptual judgment. In addition, data concerning user-friendliness, additional values and inconveniences of the FreeHands device were gathered using questionnaires. The Voice Handicap Index (VHI) was used to evaluate the relation between voice related QOL and method of stoma occlusion. Therefore a control group of TE-speakers who did not use <b>hands</b> <b>free</b> speech, was selected. Results: Objective analysis revealed significant differences (p< 0. 05) for parameters fluency (i. e. the number of syllables produced on one intake of breath) and maximal phonation time, to the detriment of <b>hands</b> <b>free</b> speech. There were no significant differences found for the dynamic characteristics Perceptual judgements of running speech were rated higher in the manual occlusion condition for most patients, but there were interrater differences. Subjective impressions showed that the majority of patients preferred <b>hands</b> <b>free</b> speech to manual stoma occlusion, noticably for voice quality, fatigability, attractivity and feelings of self-confidence. Major inconveniences of <b>hands</b> <b>free</b> speech were a significantly decreased duration of sticker adhesion, the occurrence of disturbing noises and the need for continued effort. The VHI scores were significantly higher in the group of <b>hands</b> <b>free</b> speakers compared to the control group. Conclusions: This clinical study showed that in selected patients the Provox FreeHands shows important subjective benefits. Improvements however are necessary to make the device a useful rehabilitation device for a larger group of laryngectomized patients. Keywords: tracheo-esophageal speech, <b>hands</b> <b>free</b> speech, automatic tracheostoma valvestatus: publishe...|$|R
50|$|Skullcandy Inc. is a Park City, Utah-based {{company that}} markets headphones, earphones, <b>hands</b> <b>free</b> devices, audio backpacks, MP3 players, and other products.|$|R
5000|$|<b>Hand</b> <b>free</b> valve {{should be}} able to open within one second and remains open until it is {{manually}} close (Section 4.2, 4.1.5) ...|$|R
60|$|JOB ARTHUR. We {{know what}} we're going to do. Once {{we can get}} our <b>hands</b> <b>free,</b> we know what we're going to do.|$|R
