327|59|Public
2500|$|... : {{contains}} {{a variety of}} nerve endings that jump to heat and cold, touch, pressure, vibration, and tissue injury (see somatosensory system and <b>haptic</b> <b>perception).</b>|$|E
5000|$|Gibson {{defined the}} haptic system as [...] "The {{sensibility}} {{of the individual}} to the world adjacent to his body by use of his body". Gibson and others emphasized the close link between <b>haptic</b> <b>perception</b> and body movement: <b>haptic</b> <b>perception</b> is active exploration. The concept of <b>haptic</b> <b>perception</b> is related to the concept of extended physiological proprioception according to which, when using a tool such as a stick, perceptual experience is transparently transferred {{to the end of the}} tool.|$|E
5000|$|Gibson (1966) {{defined the}} haptic system as [...] "the {{sensibility}} {{of the individual}} to the world adjacent to his body by use of his body". Gibson and others further emphasized what Weber had realized in 1851: the close link between <b>haptic</b> <b>perception</b> and body movement, and that <b>haptic</b> <b>perception</b> is active exploration.|$|E
40|$|We {{describe}} {{a number of}} research projects at Lund Univer- sity Cognitive Science. The first project focuses on visual attention. The second area is <b>haptic</b> <b>perceptions</b> by robots. The third area is anticipation in groups of robots. The final research area concerns building computa- tional tools {{that can be used}} to design large-scale cognitive models which will ultimately allow results from the different project areas to be merged into a single cognitive architecture...|$|R
40|$|International audienceWe explore here, {{through three}} {{complementary}} experiments on virtual objects, how intimate active relations with multisensory audiovisual and <b>haptics</b> <b>perceptions</b> allow to the cognitive {{creation of new}} believable and plausible objects than can be different of the virtual ones objectively implemented. The three experiments are based on "Pebble boxes" and consist in the exploration and the manipulation of multiple moving multisensory objects (the Pebbles). They show how an inferred scene is constructed from experience, as assumed in the cognitive Enactive concept, by means of three complementary strategies: "the Emergent Exploratory Procedures (EEP), the "Dynamic Manipulation Adaptation" (DMA), the "Adaptive Experimental Learning" (AEL). It shows also the complementarity between the ergotic and the semiotic situation on the strategies to infer a believable and plausible scene...|$|R
30|$|Selection {{of control}} {{strategies}} for manipulating objects with power-assist is very challenging [29]. Large inertia, friction and dynamic effects are expected while manipulating heavy objects, {{which can be}} compensated and positional accuracy can be provided by admittance controls [12]. Admittance parameters (e.g., virtual mass, damping and stiffness) can affect HRI and manipulation performance. For example, for large admittance parameters, large load force is required to move the object and the user feels more heaviness that may cause fatigue. The movement may also be slow due to low acceleration. However, {{it may be possible}} to achieve precise (e.g., smooth, fine) manipulation. On the contrary, low admittance parameters may need less human force to accelerate the object that may result in low fatigue, but precision in manipulation may reduce due to the reason that the robot is more reactive. These are the disadvantages of fixed admittance control that indicate the necessity of variable admittance control [13]. In [13], a variable admittance control strategy was proposed where a virtual mass varied to adjust acceleration and precision in power-assisted manipulation. However, the effects of excessive acceleration generating from user’s error in the programming of load force due to difference in perception between visual and haptic weights were not mitigated. Furthermore, changes in virtual mass (the mass value used in the dynamics) change acceleration [19], but it may also alter <b>haptic</b> <b>perceptions</b> [5]. Consequently, HRI and manipulation performance may be affected adversely [19]. Hence, a novel variable admittance control strategy seems to be necessary to modulate the kinematics (acceleration) and <b>haptic</b> <b>perceptions</b> differently in power-assisted manipulation to achieve better HRI and performance. However, such novel strategy has not been proposed and validated yet properly [19].|$|R
50|$|<b>Haptic</b> <b>perception</b> is {{the process}} of {{recognizing}} objects through touch. It involves a combination of somatosensory perception of patterns on the skin surface (e.g., edges, curvature, and texture) and proprioception of hand position and conformation. People can rapidly and accurately identify three-dimensional objects by touch. This involves exploratory procedures, such as moving the fingers over the outer surface of the object or holding the entire object in the hand. <b>Haptic</b> <b>perception</b> relies on the forces experienced during touch.|$|E
5000|$|... : {{contains}} {{a variety of}} nerve endings that jump to heat and cold, touch, pressure, vibration, and tissue injury (see somatosensory system and <b>haptic</b> <b>perception).</b>|$|E
50|$|Somatic senses are {{sometimes}} referred to as somesthetic senses, with the understanding that somesthesis includes the sense of touch, proprioception (sense of position and movement), and (depending on usage) <b>haptic</b> <b>perception.</b>|$|E
40|$|The present work aims to {{overcome}} human's instability of stereopsis depth perception in virtual environment provided with stereo graphics. We investigated {{the possibility of}} integrating both haptic sensation and stereopsis cues to improve the task of localizing and manipulating objects in virtual environment. Keywords Stereopsis, <b>Haptic,</b> Depth <b>perception,</b> Stereogram...|$|R
40|$|We explore here, {{through three}} {{complementary}} experiments on virtual objects, how intimate active relations with multisensory audio-visual and <b>haptics</b> <b>perceptions</b> allow to the cognitive {{creation of new}} believable and plausible objects than can be different of the virtual ones objectively implemented. The three experiments are based on “Pebble boxes ” and consist in the exploration and the manipulation of multiple moving multisensory objects (the Pebbles). They show how an inferred scene is constructed from experience, as assumed in the cognitive Enactive concept, by means of three complementary strategies: “the Emergent Exploratory Procedures (EEP), the “Dynamic Manipulation Adaptivity ” (DMA), the “Adaptive Experimental Learning ” (AEL). It shows also the complementarity between the ergotic and the semiotic situation on the strategies to infer a believable and plausible scene. I...|$|R
40|$|Our {{group is}} {{interested}} in using haptic display for training tool use. Applications include training doctors to use tools during surgery, and training astronauts to use tools during EVA. This paper describes some of the challenges of creating realistic <b>haptic</b> <b>perceptions</b> of tool use. Many of these challenges stem from the importance of unilateral constraints during tool use. Unilateral constraints occur whenever rigid bodies collide, resisting the interpenetration of the bodies, but not holding the bodies together. To identify unilateral constraints, a tool/environment simulation must perform collision detection. To respond properly to a collision, the simulation must estimate the forces that ensue, and integrate the equations of motion. All of these computations must occur in real time, and the simulation as a whole must be stable (to ensure the user’s safety). Approaches to these problems are described. 1...|$|R
5000|$|<b>Haptic</b> <b>perception</b> {{relies on}} the forces {{experienced}} during touch. This research allows the creation of [...] "virtual", illusory haptic shapes with different perceived qualities, which has clear application in haptic technology.|$|E
50|$|In his work, Benussi {{conducted}} {{numerous studies}} on optical illusions, visual and <b>haptic</b> <b>perception,</b> spatial perception, {{as well as}} the perception of time. He also developed one of the first lie detection tests.|$|E
50|$|The {{concept of}} <b>haptic</b> <b>perception</b> {{is related to}} the concept of {{extended}} physiological proprioception, according to which when a tool such as a stick is used, perceptual experience is transparently transferred {{to the end of the}} tool.|$|E
40|$|Laparoscopic surgery (LS) {{has become}} the {{standard}} in procedures such as cholecystectomy and splenectomy. However, LS imposes limitations in visual and <b>haptic</b> <b>perceptions,</b> and create challenges unique {{to this type of}} surgery: reduced depth perception of the operative field caused by the use of 2 D monitors; poor hand-eye coordination as a result of location of the monitor, variable amplification, mirrored movement, and misorientation; motion limitations due to trocar-induced invariant points, and reduced haptic feedback from the use of long and slender surgical instruments. One of the major concerns with laparoscopic surgery is potential for tissues damage, possibly caused by inappropriate use of force. Providing force feedback, either direct or augmented by visual/audio means, has the potential to improve laparoscopic surgical performance by reducing the peak force used during LS, and in turn reduce intra-operative injury to patients...|$|R
40|$|In recent years, {{wearable}} haptic systems (WHS) {{have gained}} increasing attention as a novel and exciting paradigm for human-robot interaction (HRI). These systems can be worn by users, carried around, and integrated in their everyday lives, thus enabling a more natural manner to deliver tactile cues. At the same time, the design {{of these types of}} devices presents new issues: the challenge is the correct identification of design guidelines, with the two-fold goal of minimizing system encumbrance and increasing the effectiveness and naturalness of stimulus delivery. Fabrics can represent a viable solution to tackle these issues. They are specifically thought “to be worn”, and could be the key ingredient to develop wearable haptic interfaces conceived for a more natural HRI. In this paper, the author will review some examples of fabric-based WHS that can be applied to different body locations, and elicit different <b>haptic</b> <b>perceptions</b> for different application fields. Perspective and future developments of this approach will be discussed...|$|R
40|$|The {{present study}} {{examined}} {{sex differences in}} haptic orientation representation using three tasks: a bimanual parallel-setting task comprising <b>haptic</b> orientation <b>perception</b> and motor matching action, and two unimanual tasks focusing on the perception and action elements separately. A verbal judgment task focused on haptic orientation perception: participants were to assign a number of minutes to a felt orientation. An orientation production task required the rotation of a bar to match a verbally presented number of minutes. Although {{both male and female}} performance was systematically biased we found that males are more accurate in parallel-setting and verbal judgment of orientation, suggesting differences in <b>haptic</b> orientation <b>perception,</b> in particular. Increasing allocentric reference frame involvement by delaying the action in the parallel-setting task did not affect the sex difference found. In addition to a male advantage over tasks, performance on both unimanual tasks suggests sex differences in lateralization of haptic orientation processing; a dependence on hand orientation was found only for right hand performance in males...|$|R
5000|$|Although it {{was known}} that finger kinesthesia relies on skin sensation, recent {{research}} has found that kinesthesia-based <b>haptic</b> <b>perception</b> relies strongly on the forces experienced during touch. This research allows the creation of [...] "virtual", illusory haptic shapes with different perceived qualities.|$|E
50|$|Assocreation is a {{group of}} fine artists founded in Vienna, Austria in 1997. Its works are {{primarily}} based on <b>haptic</b> <b>perception</b> and conscious temporal motion in space. In seeking to inspire reflection and insight through motion and sensory experiences, Assocreation works primarily with interactive installations and public happenings. Ground and floor {{play an important role in}} its works.|$|E
50|$|Some {{measures}} of size {{may also be}} determined by sound. Visually impaired humans often use echolocation to determine features of their surroundings, such as the size of spaces and objects. However, even humans who lack this ability can tell if a space that {{they are unable to}} see is large or small from hearing sounds echo in the space. Size can also be determined by touch, which is a process of <b>haptic</b> <b>perception.</b>|$|E
40|$|What {{would be}} worse, losing your sight or {{your sense of}} touch? Although touch (more generally, somesthesis) is {{commonly}} underrated, major somesthetic loss can’t be adequately compensated for by sight. It results in catastrophic impairments of hand dexterity, <b>haptic</b> capabilities, walking, <b>perception</b> of lim...|$|R
40|$|International audienceIn this paper, {{we propose}} a novel visuo-haptic {{interaction}} paradigm called the "Virtual Mitten" for simulating the 3 D manipulation of objects. Our approach introduces an elastic handheld device {{that provides a}} passive haptic feedback through the fingers and a mitten interaction metaphor that enables to grasp and manipulate objects. The grasping performed by the mitten is directly correlated with the grip force applied on the elastic device and a supplementary pseudo-haptic feedback modulates the visual feedback of the interaction in order to simulate different <b>haptic</b> <b>perceptions.</b> The Virtual Mitten allows natural interaction and grants users with an extended freedom of movement compared with rigid devices with limited workspaces. Our approach has been evaluated within two experiments focusing both on subjective appreciation and perception. Our results show that participants were able to well perceive different levels of effort during basic manipulation tasks thanks to our pseudo-haptic approach. They could also rapidly appreciate how to achieve different actions with the Virtual Mitten such as opening a drawer or pulling a lever. Taken together, our results suggest that our novel interaction paradigm {{could be used in}} a wide range of applications involving one or two-hand haptic manipulation such as virtual prototyping, virtual training or video games...|$|R
40|$|International audienceThe {{specific}} {{attention paid}} to the quality perceived through the senses of costumers when touching a product {{has led to a}} rapid growth in the industrial interest for the field of haptics. Controlling the quality of products with such expectations has become a challenge for manufacturers, especially considering the current lack of a generic method to standardize control specifications and provide efficient control tools, whether a manual or automated control is considered. This study provides a new insight on the definition of control specifications regarding perceived quality control. Smart systems have proven useful and efficient {{in a number of other}} domains, but has never been applied in a generic manner to the control of the quality related to the sense of touch. Therefore, a system based on formalized knowledge on <b>haptic</b> <b>perceptions</b> and its relations with quality control is proposed. This paper presents the proposed approach for the standardization of haptic quality control specifications, along with an example of a manufacturing application. The structure of the proposed knowledge model is detailed, as well as the semantic approach that enabled the development of a formalized haptic sensation vocabulary. An experimental method was used to model the influence of exploration on perception, considering the application case...|$|R
5000|$|Emily W. Bushnell (born 1950) is a {{professor}} of psychology at Tufts University in Medford, Massachusetts, USA. Her areas of professional interest include child development, infant perception, <b>haptic</b> <b>perception</b> and acquisition of perceptual-motor skills. She has written or co-authored more than 30 articles in professional publications [...] and sits on the editorial board of the professional journal Child Development. Professor Bushnell received her Ph.D. from University of Minnesota in 1979. She served as chair of the Tufts Psychology Department from 1993 to 1996.|$|E
5000|$|<b>Haptic</b> <b>perception</b> (haptόs [...] "palpable", haptikόs [...] "suitable for touch") means {{literally}} the ability [...] "to grasp something". Perception {{in this case}} is achieved through the active exploration of surfaces and objects by a moving subject, as opposed to passive contact by a static subject during tactile perception. The term Haptik was coined by the German Psychologist Max Dessoir in 1892, when suggesting a name for academic research into the sense of touch in the style of that in [...] "acoustics" [...] and [...] "optics".|$|E
50|$|Stereognosis (also {{known as}} <b>haptic</b> <b>perception</b> or tactile gnosis) {{is the ability}} to {{perceive}} and recognize the form of an object in the absence of visual and auditory information, by using tactile information to provide cues from texture, size, spatial properties, and temperature, etc. In humans, this sense, along with tactile spatial acuity, vibration perception, texture discrimination and proprioception, is mediated by the posterior column-medial lemniscus pathway of the central nervous system. Stereognosis tests determine whether or not the parietal lobe of the brain is intact. Typically, these tests involved having the patient identify common objects (e.g. keys, comb, safety pins) placed in their hand without any visual cues.Stereognosis is a higher cerebral associative cortical function.|$|E
40|$|Pseudo-haptic {{feedback}} is a haptic illusion {{based on a}} mismatch of <b>haptic</b> and visual <b>perception.</b> It is well known from applications in virtual environments. In this work, we discuss the usabiliy {{of the principle of}} pseudo-haptic feedback for teleoperation. Using pseudo-haptic feedback can ease the design of haptic medical tele-operation systems...|$|R
40|$|International audienceIn {{this paper}} we study how the visual {{animation}} of a self-avatar can be artificially modified in real-time {{in order to}} generate different <b>haptic</b> <b>perceptions.</b> In our experimental setup, participants could watch their self-avatar in a virtual environment in mirror mode while performing a weight lifting task. Users could map their gestures on the self-animated avatar in real-time using a Kinect. We introduce three kinds of modification of the visual animation of the self-avatar according to the effort delivered by the virtual avatar: 1) changes on the spatial mapping between the user's gestures and the avatar, 2) different motion profiles of the animation, and 3) changes in the posture of the avatar (upper-body inclination). The experimental task consisted of a weight lifting task in which participants had to order four virtual dumbbells according to their virtual weight. The user had to lift each virtual dumbbells {{by means of a}} tangible stick, the animation of the avatar was modulated according to the virtual weight of the dumbbell. The results showed that the altering the spatial mapping delivered the best performance. Nevertheless, participants globally appreciated all the different visual effects. Our results pave the way to the exploitation of such novel techniques in various VR applications such as sport training, exercise games, or industrial training scenarios in single or collaborative mode...|$|R
40|$|For able-bodied {{people within}} the art and design discipline, access to Computer Aided Design (CAD) and visual graphic {{interface}} is a well-defined iterative process. However for non-sighted people or people with impaired vision, {{this is a difficult}} process to facilitate. Often this issue excludes and/or limits access for people with vision impairments to fully utilise CAD systems, web interface, and any other visually led interface which mainly communicates through graphical or pictorial cues and image-based metaphors. This paper presents an ongoing inclusively designed multimodal system. Whereby the use of digitally adapted haptic technology is explored via a clinically established and valid fine motor skills test: 'Wade's Nine-Hole- Peg-Test' (NHPT). Particular attention is paid to assess whether non-sighted participants can gain a level of speed and efficacy of NHPT task by using the haptic technology together with their own tacit <b>haptic</b> <b>perceptions</b> compared to a subject group of healthy sighted participants. The results indicate better performance of non-sighted participants when compared to the sighted, while also showing that implemented multimodal cues assist the performance of both participant groups based on insertion time. Given these results, future work will focus on analysing collision data from haptic insertion of the pegs in holes to compare performance based on recorded error. Additionally, these findings will be used towards providing tools for more inclusive interfaces to be used in pedagogic practice...|$|R
5000|$|Problem: much {{education}} disseminated {{over long}} or short distances, {{but not in}} a physical classroom, lacks some, or all of the educational modalities required by a very large of group of students with disabilities, namely, for the blind or learning disabled, ways of receiving information by touch, (the somatosensory system), and /or tactile manipulation, for example. [...] To arrive at, perhaps, a potential solution/direction of a solution, to the problem, Treviranus conducted research that examined the understanding of spatial ideas like geography by using a number of non-visual techniques: haptics (haptic technology, haptic communication, <b>haptic</b> <b>perception,</b> haptic poetry, and haptic media), 3D real world sounds and talking to figure out the best ways to communicate various kinds of data.|$|E
50|$|Wolter was {{responsible}} for creating model and software for the haptic/tactile renderer of the visuo-haptic-tactile Virtual Reality (VR) system HAPTEX - HAPtic sensing of virtual TEXtiles, developed as multinational EU-project (2004-2007). (Haptic and tactile perception are considered as different with tactile referring to perception obtained via mechano receptors in the skin from lightly touching a surface while <b>haptic</b> <b>perception</b> caused by more forceful mechanical interaction with an object perhaps deforming it). HAPTEX {{appears to be the}} only VR-System allowing simultaneously a combined haptic and tactile perception of multi point haptic interaction with computer generated deformable objects, c.f. Under Wolter's guidance research on the haptic and tactile renderer of HAPTEX resulted in two doctoral theses of his students published as monographies by Springer, cf.|$|E
5000|$|Stereotaxy (from stereo meaning [...] "solidity", and tactile meaning [...] "touch") {{refers to}} any {{technique}} {{that involves the}} recording and reproduction of three-dimensional haptic information or creating an illusion of depth {{to the sense of}} touch within an otherwise-flat surface. Unlike the current trend in haptic technology to provide <b>haptic</b> <b>perception</b> of simulated, virtual objects within an [...] augmented-reality (that is, within a mostly-realistic) setting, stereohapty, which, when applied as a field of study, is known as stereohaptics or stereotactics, stereotaxy aims to provide an illusion of three-dimensional depth to the sense of touch by the human body. This resembles how stereoscopy, its visual counterpart, is meant to provide a visual illusion of depth to otherwise-flat images (such as 3-D films), a process known as stereopsis.|$|E
40|$|We {{describe}} a force feedback scheme that {{is able to}} provide for <b>haptic</b> depth <b>perception</b> for use during the static 2 d viewing of 3 d angiograms. The scheme returns 2 d horizontal forces that bear some analogy with forces that {{would be needed to}} glide a virtual proxy on the vessel center lines. The display system was evaluated by asking subjects to determine the relative depth of randomly selected points on vessel segments. The results indicate that subjects were able to discriminate the relative depth in an average time of 12 seconds and with an accuracy of 95 %...|$|R
40|$|In {{studies on}} <b>haptic</b> rod length <b>perception,</b> {{participants}} conventionally report their length estimates {{by placing a}} visual landmark at a position equal to the rod’s perceived endpoint. We hypothesized that this visual aspect substantially increases the variability of the recorded length judgments. To examine this, we developed a virtual reality length judgment apparatus that provides better visual information. Participants performed a rod length perception task in both the conventional apparatus and the virtual reality apparatus. The variability of the length judgments {{was found to be}} higher in the conventional apparatus. We determined that between half and two-thirds {{of the variance in the}} conventional apparatus is haptic variance. Thus, vision accounts for between one-third and half of the variance that was previously thought to be haptic variance. Our finding implies that the virtual reality apparatus may be more suitable for studying subtle effects in <b>haptic</b> rod length <b>perception...</b>|$|R
40|$|Figure 1 : Visuo-haptic {{manipulation}} as enabled by our novel approach {{called the}} “Virtual Mitten”. Each hand holds an elastic device {{to control a}} corresponding virtual mitten (in gray) and to grasp virtual objects in a bimanual scenario. The grip force applied by the user is measured to generate pseudo-haptic feedback. In this paper, we propose a novel visuo-haptic interaction paradigm called the “Virtual Mitten ” for simulating the 3 D manipulation of objects. Our approach introduces an elastic handheld device that provides a passive haptic feedback through the fingers and a mit-ten interaction metaphor that enables to grasp and manipulate ob-jects. The grasping performed by the mitten is directly correlated with the grip force applied on the elastic device and a supplemen-tary pseudo-haptic feedback modulates the visual feedback of the interaction in order to simulate different <b>haptic</b> <b>perceptions.</b> The Virtual Mitten allows natural interaction and grants users with an extended freedom of movement compared with rigid devices with limited workspaces. Our approach has been evaluated within two experiments focusing both on subjective appreciation and percep-tion. Our results show that participants were able to well perceive different levels of effort during basic manipulation tasks thanks to our pseudo-haptic approach. They could also rapidly appreciate how to achieve different actions with the Virtual Mitten such as opening a drawer or pulling a lever. Taken together, our results sug-gest that our novel interaction paradigm {{could be used in}} a wide range of applications involving one or two-hand haptic manipula-tion such as virtual prototyping, virtual training or video games...|$|R
