386|1218|Public
25|$|Since each <b>image</b> <b>block</b> {{requires}} its own {{local color}} table, a GIF file having lots of image blocks {{can be very}} large, limiting the usefulness of full-color GIFs. Additionally, not all GIF rendering programs handle tiled or layered images correctly. Many rendering programs interpret tiles or layers as animation frames and display them in sequence as an endless animation with most web browsers automatically displaying the frames with a delay time of 0.1 seconds or more.|$|E
25|$|To {{render a}} full-color {{image as a}} GIF, the {{original}} image must {{be broken down into}} smaller regions having no more than 255 or 256 different colors. Each of these regions is then stored as a separate <b>image</b> <b>block</b> with its own local palette and when the image blocks are displayed together (either by tiling or by layering partially transparent image blocks) the complete, full-color image appears. For example, breaking an image into tiles of 16 by 16 pixels (256 pixels in total) ensures that no tile has more than the local palette limit of 256 colors, although larger tiles may be used and similar colors merged resulting in some loss of color information.|$|E
2500|$|Although GIF {{is almost}} never used for true color images, it is {{possible}} to do so. A GIF image can include multiple image blocks, each of which can have its own 256-color palette, and the blocks can be tiled to create a complete image. Alternatively, the GIF89a specification introduced the idea of a [...] "transparent" [...] color where each <b>image</b> <b>block</b> can include its own palette of 255 visible colors plus one transparent color. A complete image can be created by layering image blocks with the visible portion of each layer showing through the transparent portions of the layers above.|$|E
30|$|Since DCT can {{depict the}} {{periodic}} signals very well, {{we use the}} AC energy of DCT coefficients to classify <b>image</b> <b>blocks</b> into three morphological components, i.e., smooth, texture, and contour. For the same <b>block</b> size, the <b>image</b> <b>blocks</b> with smooth component have the minimum AC energy followed by the <b>image</b> <b>blocks</b> with texture component and the <b>image</b> <b>blocks</b> with contour component. Experimental results have shown the robustness of our proposed algorithm to noise. Also, our proposed algorithm can achieve better denoising results than both BM 3 D and BM 3 D-SAPCA, in terms of PSNR and MSSIM values as well as visual inspection.|$|R
40|$|Abstract — This paper aims {{to provide}} {{different}} approaches to text dependent speaker identification using DCT, Walsh and Haar transform along with use of spectrograms. Spectrograms obtained from speech samples are used as image database for the study undertaken. This image database is then subjected to various transforms. Using Euclidean distance as measure of similarity, most appropriate speaker match is obtained and is declared as identified speaker. Each transform is applied to spectrograms in two different ways: on full image and on <b>image</b> <b>blocks.</b> In both the ways, effect of different number of coefficients of transformed image is observed. Haar transform on full image reduces multiplications required by DCT and Walsh by 28 times whereas applying Haar transform on <b>image</b> <b>blocks</b> requires 18 times less mathematical computations as compared to DCT and Walsh on <b>image</b> <b>blocks.</b> Transforms when applied to <b>image</b> <b>blocks,</b> yield better or equal identification rates with reduced computational complexity...|$|R
30|$|Now, {{the cover}} image will {{be divided into}} a number of 8 pixels <b>image</b> <b>blocks.</b>|$|R
50|$|Since each <b>image</b> <b>block</b> {{requires}} its own {{local color}} table, a GIF file having lots of image blocks {{can be very}} large, limiting the usefulness of full-color GIFs. Additionally, not all GIF rendering programs handle tiled or layered images correctly. Many rendering programs interpret tiles or layers as animation frames and display them in sequence as an endless animation with most web browsers automatically displaying the frames with a delay time of 0.1 seconds or more.|$|E
50|$|The {{user can}} specify Widow and Orphan for blocks {{or for the}} flow itself, and allow the {{attributes}} to cascade into child blocks. Additionally, blocks can be specified to be kept together on a single page. For example, an <b>image</b> <b>block</b> and the description of that image can be set to never be separated. The FO processor will do its best to adhere to these commands, even if it requires creating {{a great deal of}} empty space on a page.|$|E
5000|$|Although the GIF {{format is}} almost never used for True Color images, it is {{possible}} to do so. A GIF image can include multiple image blocks, each of which can have its own 256-color palette, and the blocks can be tiled to create a complete image. Alternatively, the GIF89a specification introduced the idea of a [...] "transparent" [...] color where each <b>image</b> <b>block</b> can include its own palette of 255 visible colors plus one transparent color. A complete image can be created by layering image blocks with the visible portion of each layer showing through the transparent portions of the layers above.|$|E
5000|$|Block {{matching}} {{can be seen}} as the [...] "cutting and pasting" [...] of <b>image</b> <b>blocks.</b>|$|R
40|$|In print forensics, {{copy paper}} brand source {{identification}} {{can be used}} to expose the copy paper source of the forged contracts or official documents. In this study, a novel method for identifying the copy paper brand is proposed for forensics application using only a commodity scanner and without modifying the document. The scanned document image margin is cut into <b>image</b> <b>blocks.</b> After the <b>image</b> preprocessing, 114 -D texture features are extracted from these <b>image</b> <b>blocks</b> including Gray Level Co-occurrence Matrix (GCM) features and Fourier spectrum features. The decision for each piece of paper is given by voting the decision results of the <b>image</b> <b>blocks.</b> The experimental results are provided finally to demonstrate the feasibility of the proposed method...|$|R
50|$|In {{digital image}} processing, {{the sum of}} {{absolute}} differences (SAD) {{is a measure of}} the similarity between <b>image</b> <b>blocks.</b> It is calculated by taking the absolute difference between each pixel in the original block and the corresponding pixel in the block being used for comparison. These differences are summed to create a simple metric of block similarity, the L1 norm of the difference image or Manhattan distance between two <b>image</b> <b>blocks.</b>|$|R
50|$|To {{render a}} full-color {{image as a}} GIF, the {{original}} image must {{be broken down into}} smaller regions having no more than 255 or 256 different colors. Each of these regions is then stored as a separate <b>image</b> <b>block</b> with its own local palette and when the image blocks are displayed together (either by tiling or by layering partially transparent image blocks) the complete, full-color image appears. For example, breaking an image into tiles of 16 by 16 pixels (256 pixels in total) ensures that no tile has more than the local palette limit of 256 colors, although larger tiles may be used and similar colors merged resulting in some loss of color information.|$|E
30|$|Extract texture {{features}} {{from each}} <b>image</b> <b>block.</b>|$|E
40|$|Abstract. A hybrid {{algorithm}} {{based on}} mean coding and vector quantization {{is presented in}} this paper. The smooth <b>image</b> <b>block</b> is coded with the mean coding algorithm, which can reduce the vector quantization (VQ) search computation and improve the compression ratio effectively, and this method is called the basic blended algorithm (BBA). On this base, an adaptive partitioned algorithm (APA) algorithm based on 16 × 16 pixels <b>image</b> <b>block</b> is proposed, the optional <b>image</b> <b>block</b> sizes are 16 × 8, 8 × 16, 8 × 8, 8 × 4, 4 × 8, 4 × 4 pixels, the image is coded adaptively at different levels. The size of mean coding is chosen adaptively according {{to the size of}} the smooth <b>image</b> <b>block,</b> the Not-smooth 4 × 4 pixels <b>image</b> <b>block</b> is coded by VQ. In addition, the improved APA (IAPA) is also given in this paper. Simulations show that the APA and IAPA proposed in this paper are proven to have great performance for different kinds of images, especially significant for those have large areas of static background and little details. Compared with BBA, the compression rati...|$|E
40|$|This paper {{presents}} {{research findings}} {{on the use of}} Deep Belief Networks (DBNs) for face recognition. Experiments were conducted to compare the performance of a DBN trained using whole images with that of several DBN trained using <b>image</b> <b>blocks.</b> <b>Image</b> <b>blocks</b> are obtained when the face images are divided into smaller blocks. The objective of using <b>image</b> <b>blocks</b> is to improve the performance of the present DBN to visual variations. To test this hypothesis, the proposed block-based DBN was tested on different databases, which contain a variety of visual variations. Simulation results on these databases show that the proposed block-based DBN is effective against lighting variation. The proposed approach is also compared with other illumination invariant methods and was found to demonstrate higher recognition accuracies...|$|R
40|$|The {{conventional}} LBG; (Linde-Buzo-Cray) algorithm consumes a {{great amount}} of mailing time to generate a codebook In addition, it gives more codewords for describing the image regions with higher pixel intensity variance, but, fewer codewords for depicting those with lower pixel intensity variance. This paper proposes a group-based VQ codebook generation method (GBVQCG method) to build a codebook It classified the <b>image</b> <b>blocks</b> of an <b>image</b> into groups and determines the number of desired codewords which will be extracted from the <b>image</b> <b>blocks</b> in each group according to the standard deviation and the number of <b>image</b> <b>blocks</b> in the group. The experimental results show that the GBVQCG method generally performs much better in. terms of the running, time {{and the quality of the}} decompressed image, compared with the LBG compression metho...|$|R
50|$|<b>Image</b> <b>blocking</b> {{modeling}} errors: The Inverse ISAR transform currently {{assumes that}} scatterers {{are on a}} planar surface and cannot block other scatterers.|$|R
30|$|The {{classification}} algorithm mainly aims at categorizing {{the whole}} image blocks (i.e., range and domain blocks) into three discrete classes. From the spatial domain, {{a block of}} image could be transformed to the frequency domain by means of DCT transformation. Within the frequency domain, the DCT coefficient that is situated in the upper left of the <b>image</b> <b>block</b> signifies the image block's low-frequency information and its rough contour, whereas the DCT coefficient that is situated in the lower right of the <b>image</b> <b>block</b> signifies the image block's high-frequency information and its fine texture. Therefore, we can explore the class of the <b>image</b> <b>block</b> by considering its lower-higher frequency DCT coefficients.|$|E
40|$|Image {{compression}} operator based on discrete cosine transform was brought up. A securer scrambling locational operator was put forward {{based on the}} concept of anti-tamper radius. The basic idea of the algorithm is that it first combined <b>image</b> <b>block</b> compressed data with eigenvalue of <b>image</b> <b>block</b> and its offset block, then scrambled or encrypted and embeded them into least significant bit of corresponding offset block. This algorithm could pinpoint tampered <b>image</b> <b>block</b> and tampering type accurately. It could recover tampered block with good image quality when tamper occured within the limits of the anti-tamper radius. It could effectively resist vector quantization and synchronous counterfeiting attacks on self-embedding watermarking schemes. </span...|$|E
3000|$|... <b>image</b> <b>block</b> {{with the}} {{proposed}} pattern substitution method. The image is firstly {{divided into four}} nonoverlapped [...]...|$|E
30|$|In recent years, a {{morphological}} {{component analysis}} method [41] {{has been proposed}} and widely used in image processing. The main idea of morphological component analysis is to divide the image contents into different components, such as smooth, texture, and contour. As DCT is a tool that can effectively depict periodic signals, we perform DCT on <b>image</b> <b>blocks</b> and then classify the <b>image</b> <b>blocks</b> into different morphological components according to their respective energies of the alternating current (AC) coefficients.|$|R
40|$|Digital image {{steganography}} is {{an emerging}} technique in secure communication {{for the modern}} connected world. It protects {{the content of the}} message without arousing suspicion in a passive observer. A novel steganography method is presented to hide text in digital images. A compact dictionary is designed to efficiently communicate all types of secret messages. The sorting order of pixels in <b>image</b> <b>blocks</b> are chosen as the carrier of embedded information. The high correlation in image pixel values means reordering within <b>image</b> <b>blocks</b> do not cause high distortion. The image is divided into blocks and perturbed to create non repeating sequences of intensity values. These values are then sorted according to the message. At the receiver end, the message is read from the sorting order of the pixels in <b>image</b> <b>blocks.</b> Only those <b>image</b> <b>blocks</b> with standard deviation lesser than a given threshold are chosen for embedding to alleviate visual distortion. Information Security is provided by shuffling the dictionary according to a shared key. Experimental Results and Analysis show that the method is capable of hiding text with more than 4000 words in a 512 × 512 grayscale image with a peak signal to noise ratio above 40 decibels...|$|R
30|$|Considering the {{disadvantages}} of computing saliency image using local contrast, we can obtain the saliency image using global contrast method. Zhai and Shah et al. [40] use the MZ algorithm {{to calculate the}} contrast of each pixel in the whole image. Inspired by this, Fenget et al. [48] used the sliding window to calculate the global contrast. Margolin et al. [49] obtain the saliency of <b>image</b> <b>blocks</b> by using the statistical information of image and linearly fusing the color contrast of <b>image</b> <b>blocks.</b>|$|R
40|$|This thesis {{presents}} {{several new}} blocking effect reduction techniques based on DCT for very {{low bit rate}} DCT-coded images. Some common techniques, such as POCS, {{the use of an}} interleaved <b>image</b> <b>block</b> before encoding, and the application of a linear space invariant low-pass filter over the decoded image, developed in these two decades. However, there are some drawbacks in each of the existing methods. These include a very long convergence time for POCS, the difficulty of adopting the international standard for using an interleaved <b>image</b> <b>block</b> before encoding, and blurring of the image details for using a linear space invariant filter. Because of these drawbacks, we develop a new algorithm to reduce the blocking effect. Our algorithm is fast, simple and straightforward, retains the original bit rate, and preserves the varying characteristics within the image. Our algorithm can be used to change some of the DCT AC coefficients of the shifted <b>image</b> <b>block,</b> and then apply IDCT to obtain a processed image. There are two proposed methods to change the DCT coefficients. One involves setting some of the DCT AC coefficients to zero. This is called the zero-masking technique. The other method is to multiply the DCT AC coefficients by certain weighting. This is called DCT coefficients weighting technique. Also, we propose two methods for shifting the <b>image</b> <b>block.</b> One method involves shifting, individually, the image horizontally and vertically. That is, to first shift the image blocks either horizontally or vertically, applying the zero-masking technique or DCT coefficients weighting technique on the shifted <b>image</b> <b>block</b> and, finally, repeating the above procedure in another direction. We call this processing method the one-dimensional processing technique. Another way to shift the <b>image</b> <b>block</b> is to do in both horizontally and vertically at the same time. Similarly, we apply the processing technique on this shifted <b>image</b> <b>block</b> and obtain the processed image. We call this processing method the two-dimensional processing technique. A lot of simulations prove that our proposed algorithms give both qualitative and quantitative improvements...|$|E
30|$|The {{successes of}} both BM 3 D-SAPCA and SA-BM 3 D are {{primarily}} {{by the use of}} shape-adaptive image patches/neighborhoods. But, the procedure for computing local adaptive shapes is relatively complex. For example, PCA often needs greater calculation time than the two-dimensional orthogonal transformation, and thus the whole operation of BM 3 D-SAPCA is time-consuming. Most importantly, it is difficult to make shapes adaptive, when the noise level is relatively high. To address these issues, in this paper, we propose an improved block-size-adaptive BM 3 D method for image denoising. First, DCT is performed on the reference <b>image</b> <b>block</b> before conducting the block matching. Then, all image blocks can be divided into three morphological components (namely, smooth, texture, and contour regions) based on the regional energy of alternating current (AC) component in the DCT coefficients. For different morphological component, the size of the reference <b>image</b> <b>block</b> will be enlarged or reduced. For example, the size for smooth-component <b>image</b> <b>block</b> will be enlarged appropriately, and the size for the contour-component <b>image</b> <b>block</b> will be reduced, while the size for the texture-component <b>image</b> <b>block</b> will be kept as the original size. Experimental results show that our proposed method can achieve better image denoising results than both BM 3 D and BM 3 D-SAPCA, in terms of PSNR and MSSIM values, and can also preserve better image details and introduce less image artifacts.|$|E
40|$|In {{order to}} develop an {{accurate}} computer-aided diagnosis system for the automatic detection of microcalcification clusters in mammograms. In this study, we presented a new microcalcification clusters detection method by using Gaussian Markov Random Fields (GMRFs) representation. The design and evaluation of the algorithm involved three main phases. In {{the first phase of}} the algorithm, a training dataset is employed to train and get the GMRF texture features of each <b>image</b> <b>block</b> and then the cluster center and bias are obtained. In the second phase of the algorithm, we use GMRFs to get it texture feature with a given <b>image</b> <b>block.</b> And finally, the distance between the given <b>image</b> <b>block</b> GMRFs features and the cluster center to make a decision whether it contains a microcalcification cluster or not...|$|E
3000|$|... by {{adjusting}} the number of data points, which {{is the number of}} <b>image</b> <b>blocks</b> by random sampling in our case, and the distortion rate [...]...|$|R
40|$|A fragile {{watermarking}} {{scheme for}} authenticating images {{based on the}} Yeung-Mintzer scheme is proposed in this paper. This scheme does provide a better protection against all the attacks proposed for Yeung-Mintzer scheme. A polar set derived from the <b>image</b> <b>blocks</b> {{is used in the}} embedding process. The center pixel values of <b>image</b> <b>blocks</b> are perturbed by small quantities {{in such a way that}} the perceptual quality of the image is not modified. This paper also analyse the security level with respect to other attacks...|$|R
40|$|In {{this paper}} {{the problem of}} image {{restoration}} (denoising and inpainting) is approached using sparse approximation of local <b>image</b> <b>blocks.</b> The local <b>image</b> <b>blocks</b> are extracted by sliding square windows over the <b>image.</b> An adaptive <b>block</b> size selection procedure for local sparse approximation is proposed, which affects the global recovery of underlying image. Ideally the adaptive local block selection yields the {{minimum mean square error}} (MMSE) in recovered image. This framework gives us a clustered image based on the selected block size, then each cluster is restored separately using sparse approximation. The results obtained using the proposed framework are very much comparable with the recently proposed image restoration techniques...|$|R
40|$|In {{order to}} satisfy the {{requirement}} of identification and tracking the elliptical artificial targets fast and accurately for the image sequences from videogrammetric measurement for structural health monitoring, this paper proposes a systemic algorithm to identify and track the elliptical targets using the <b>image</b> <b>block</b> technique. The proposed method extracts the <b>image</b> <b>block</b> from original images {{to reduce the amount}} of data processing for the oval targets tracking. The mathematical morphology and elliptical geometric characteristics are integrated to eliminate the non-elliptical edge information to extract the elliptical contour in the range of <b>image</b> <b>block.</b> At last, the sub-pixel center location for elliptical artificial targets is acquired by the least square algorithm. The experimental results show that RMS error of 0. 025 pixel can be achieved by the proposed method, furthermore, compared with the random Hough transform and template recognition algorithm, the tracking efficiency is improved over 5 times...|$|E
40|$|A novel image {{steganography}} method using chaotic map {{and human}} visual model {{is presented in}} DCT domain. Firstly each 8 × 8 <b>image</b> <b>block</b> is performed Discrete Cosine Transform, then the location of <b>image</b> <b>block</b> that is embedded secret message {{is determined by the}} chaotic map. Finally the secret message is em-bedded adaptively in the usable middle frequency co-efficient pairs judged by Just Noticeable Differ-ence(JND). Simulation results show that the algorithm has a high capacity and a good invisibility, moreover it is robust for the common image processing like JPEG compression and cropping...|$|E
30|$|Before deep {{learning}} {{was applied to}} computer vision, researchers typically used methods such as TextonForest and Random Forest to build semantic-partitioned classifiers. Later, with the extensive application of {{deep learning}}, <b>image</b> <b>block</b> classification techniques utilize the image blocks surrounding each pixel to classify each pixel into a corresponding category. In 2014, Long et al. proposed FCN [15], which promoted the original CNN structure and spatially densely predicted without full connectivity layer. Compared with the <b>image</b> <b>block</b> classification, FCN can generate any size of the split map and improve the processing speed.|$|E
40|$|This paper aims {{to provide}} {{different}} approaches to text dependent speaker identification using DCT, Walsh and Haar transform along with use of spectrograms. Spectrograms obtained from speech samples are used as image database for the study undertaken. This image database is then subjected to various transforms. Using Euclidean distance as measure of similarity, most appropriate speaker match is obtained and is declared as identified speaker. Each transform is applied to spectrograms in two different ways: on full image and on imageblocks. In both the ways, effect of different number of coefficientsof transformed image is observed. Haar transform on full image reduces multiplications required by DCT and Walsh by 28 times whereas applying Haar transform on <b>image</b> <b>blocks</b> requires 18 times less mathematical computations as compared to DCT and Walsh on <b>image</b> <b>blocks.</b> Transforms when applied to <b>image</b> <b>blocks,</b> yield better or equal identification rates with reduced computational complexity...|$|R
3000|$|... block. Next, a Dynamic Fuzzy Inference System (DFIS) is used {{to select}} the number of {{original}} <b>image</b> <b>blocks</b> for embedding watermark. Finally, DC value of each [...]...|$|R
3000|$|... regions {{according}} to their values. This is equivalent with the <b>image</b> <b>blocks</b> preclassification proposed in [16]. Our classification criterion {{is the same as}} that proposed in [17].|$|R
