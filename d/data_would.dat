3361|4223|Public
5|$|Many planned {{elements}} were never filmed, due to production time constraints. Moore {{had hoped for}} an extended battle scene in which <b>Data</b> <b>would</b> be electrocuted, and Wesley Crusher blown up in an explosion. Production of the episode ended on December 19.|$|E
5|$|However, {{without the}} ability to {{effectively}} track weak laser signals, collection of atmospheric <b>data</b> <b>would</b> be relegated to times of day where the sun's electromagnetic emissions did not drown out the laser's signal. The addition of an atomic line filter to the LIDAR equipment effectively filters interference to the laser's signal {{to the point where}} LIDAR data can be collected at any time of the day. For the past decade, Faraday filters have been used to do this. Consequently, scientists know significantly more today about the Earth's middle atmosphere than they did before the advent of the FADOF.|$|E
5|$|The US {{government}} {{was aware of}} these activities in Cambodia, but refrained from taking overt military action within Cambodia in hopes of convincing the mercurial Sihanouk to alter his position. To accomplish this, President Lyndon B. Johnson authorized covert cross-border reconnaissance operations conducted by the secret Studies and Observations Group in order to gather intelligence on PAVN/NLF activities in the border regions (Project Vesuvius). This intelligence <b>data</b> <b>would</b> then {{be presented to the}} prince in an effort to change his mind.|$|E
50|$|In statistics, quasi-likelihood {{estimation}} {{is one way}} {{of allowing}} for overdispersion, that is, greater variability in the <b>data</b> than <b>would</b> be expected from the statistical model used. It is most often used with models for count data or grouped binary data, i.e. <b>data</b> that <b>would</b> otherwise be modelled using the Poisson or binomial distribution.|$|R
5000|$|On-train <b>data</b> {{recorders}} <b>would</b> {{make the}} finding of evidence easier following railway accidents.|$|R
50|$|Billings P. DNA <b>data</b> banks <b>would</b> taint justice. Boston Globe 1999; Jan 14 (A):19.|$|R
5|$|The {{first test}} would {{probably}} be a ground burst, but consideration was also given to an explosion in a ship to measure the effect of a ship-borne atomic bomb on a major port. Such <b>data</b> <b>would</b> complement that obtained about an underwater explosion by the American Operation Crossroads nuclear test in 1946, and would therefore be of value to the Americans. Seven Canadian sites were assessed, the most promising being Churchill, Manitoba, but the waters were too shallow to allow ships to approach close to shore.|$|E
5|$|Most of the non-player {{characters}} (NPCs) that {{inhabit the}} open world were motion captured. The developers contacted casting agencies, and asked {{their friends and}} families if {{they would like to}} appear as extras in the game. Over 75 people were scanned in a three-day period. They were seated in chairs and told not to move or smile, and a high-definition digital camera captured a 3D model of their faces. The camera sent out strobe light patterns to capture the volume and shape of each face. A 360-degree setup captured the actors' moving bodies, but mannequins were also used to help capture different clothing styles. Data collected from the cameras was used by the designers to render digital models, each composed of roughly 1.4 million polygons—any blank spots on the models would be digitally filled in by the designers. To render the models in the game, the <b>data</b> <b>would</b> be compressed by reducing the polygon count.|$|E
25|$|ZFS is a 128-bit file system, so it {{can address}} 1.84× 1019 times more data than 64-bit systems such as Btrfs. The maximum limits of ZFS are {{designed}} to be so large that they should never be encountered in practice. For instance, fully populating a single zpool with 2128 bits of <b>data</b> <b>would</b> require 1024 3TB hard disk drives.|$|E
5000|$|If all {{sensor data}} were {{recorded}} in LHC, the <b>data</b> flow <b>would</b> be extremely hard to work with. The <b>data</b> flow <b>would</b> exceed 150 million petabytes annual rate, or nearly 500 exabytes per day, before replication. To put the number in perspective, this is equivalent to 500 quintillion (5×1020) bytes per day, almost 200 times {{more than all the}} other sources combined in the world.|$|R
5000|$|Using {{different}} {{tools to}} extract and analyse larger amounts of <b>data</b> that <b>would</b> not be manageable otherwise.|$|R
50|$|The {{diagrams}} show estimated {{critical data}} of hydrocarbons together with experimental <b>data.</b> An estimation <b>would</b> be perfect if all <b>data</b> points <b>would</b> lie {{directly on the}} diagonal line. Only the simple correlation of the Klincewicz method with the moelcular weight and the atom count {{have been used in}} this example.|$|R
25|$|Conversely, {{the symbol}} width could be set at 8, {{even if only}} values 0 and 1 are used; these <b>data</b> <b>would</b> only require a 2-color table. Although {{there would be no}} point in {{encoding}} the file that way, something similar typically happens for bi-color images: the minimum symbol width is 2, even if only values 0 and 1 are used.|$|E
25|$|One {{approach}} to capture {{most of the}} information present in <b>data</b> <b>would</b> be to use many statistics, but the accuracy and stability of ABC appears to decrease rapidly with an increasing numbers of summary statistics. Instead, a better strategy is to focus on the relevant statistics only—relevancy depending on the whole inference problem, on the model used, and on the data at hand.|$|E
25|$|From their {{original}} data, Howlett and Majerus (1987) concluded that peppered moths generally rest in unexposed positions, using three main types of site. Firstly, {{a few inches}} below a branch-trunk joint on a tree trunk where the moth is in shadow; secondly, {{on the underside of}} branches and thirdly on foliate twigs. The above <b>data</b> <b>would</b> appear to support this.|$|E
50|$|On October 15, Microsoft {{said they}} had been able to recover most or all <b>data</b> and <b>would</b> begin to restore them.|$|R
30|$|Data set feature {{processing}} scheme includes feature collection, feature {{conversion and}} reservation. The filter feature of <b>data</b> set <b>would</b> be pre-fetched. The classification characteristics of data set {{could be obtained}} based on the classification accuracy of data set. According to {{the characteristics of the}} data set, the crowd filter would select the appropriate crowd incentive strategy. Based on the complexity characteristics of the data set classification, the transformation of the subset of the <b>data</b> set <b>would</b> be completed.|$|R
30|$|In {{the file}} name {{convention}} the new <b>data</b> type <b>would</b> be denoted by the letter “q” as a valid code for the data type.|$|R
25|$|Terman planned later follow-ups, {{and in his}} {{lifetime}} <b>data</b> <b>would</b> be collected in 1928, 1936, 1940, 1945, 1950, and 1955. At his death, the study was directed by Melita Oden, who collected additional data in 1960. Robert Richardson Sears later {{took charge of the}} study and collected data in 1972, 1977, 1982, and 1986. Moreover, many study participants corresponded with Terman or visited Stanford University in order to keep him updated on their lives.|$|E
25|$|The CAB, upon {{reviewing}} available weather data, {{determined that}} the Pan Am meteorologist {{should have been able}} to predict, with some amount of certainty, that there would be severe turbulence at lower altitude and high winds. This <b>data</b> <b>would</b> have been available for the meteorologist to make such a prediction prior to or shortly after Flight 923's departure from Seattle. Such a forecast would have warned the crew of the weather conditions they encountered when they decided to abort their landing at Annette Island airport.|$|E
25|$|In one typical usage scenario, {{the system}} will load the SPEs with small {{programs}} (similar to threads), chaining the SPEs together to handle each step in a complex operation. For instance, a set-top box might load programs for reading a DVD, video and audio decoding, and display, and the <b>data</b> <b>would</b> be passed off from SPE to SPE until finally ending up on the TV. Another possibility is to partition the input data set and have several SPEs performing {{the same kind of}} operation in parallel. At 3.2GHz, each SPE gives a theoretical 25.6 GFLOPS of single precision performance.|$|E
50|$|In March 2013, JustOrbit {{introduced}} an interesting feature which provided recommendations and statistical <b>data</b> which <b>would</b> {{add to the}} decision making of the travelers.|$|R
30|$|The {{straightforward}} {{solution is}} to consider {{a large number of}} users. This would increase simulation runtime, and large <b>data</b> rates <b>would</b> not occur at all.|$|R
5000|$|Figure {{out how the}} {{contents}} of the <b>data</b> base <b>would</b> need to be presented—by asking experts, potential non-professional users and comparing that with existing databases ...|$|R
25|$|Preliminary {{design work}} was {{completed}} by July 1956 and the scientific tasks {{to be carried out}} by the satellite were defined. These included measuring the density of the atmosphere and its ion composition, the solar wind, magnetic fields, and cosmic rays. These <b>data</b> <b>would</b> be valuable in the creation of future artificial satellites. A system of ground stations was to be developed to collect data transmitted by the satellite, observe the satellite's orbit, and transmit commands to the satellite. Because of the limited time frame, observations were planned for only 7 to 10 days and orbit calculations were not expected to be extremely accurate.|$|E
25|$|Some {{scientists}} propose using brain imaging to help {{decide which}} soon-to-be-released offenders are {{at greater risk}} for reoffending. The brain imaging <b>data</b> <b>would</b> be used along with common factors like age, prior arrests, and marital status. To support this idea, in a 2013 study, Professor Kent Kiehl from the University of New Mexico studying the population of 96 male offenders in the state’s prisons found that offenders with low activity in the anterior cingulate cortex where twice as likely to commit an offense in the four years after their release as those who had high activity in this region. Similarly, Dustin Pardini conducted that which shows that men with a smaller amygdala are {{three times more likely to}} commit violence three years after their release.|$|E
25|$|In {{most parts}} of the world, {{medication}} is dispensed in blister packaging. It is relatively simple to equip blister packages with printed conductive trace grids. These grids are then connected to an electronic module. The electronic monitor records the time a trace has been broken and can then transmit this information to an NFC smart phone or even be GSM enabled to transmit the information immediately if a suitable data network is available. A more reasonable solution at the moment would be to connect the package to a hub, handheld device, tablet or smart watch via low power Bluetooth. In this case the package <b>data</b> <b>would</b> be sent whenever the medication blister is in close proximity to the bluetooth receiver. It avoids the huge effort required to equip every single blister with a SIM module and expensive monthly data subscription.|$|E
25|$|By {{decoupling}} {{the data}} storage from the multi-dimensional model, {{it is possible}} to successfully model <b>data</b> that <b>would</b> not otherwise fit into a strict dimensional model.|$|R
50|$|S3DB {{was first}} {{proposed}} in 2006, following the argumentation {{the previous year}} that omics <b>data</b> sets <b>would</b> be more easily managed if stored as RDF triples.|$|R
5000|$|By {{decoupling}} {{the data}} storage from the multi-dimensional model, {{it is possible}} to successfully model <b>data</b> that <b>would</b> not otherwise fit into a strict dimensional model.|$|R
25|$|A {{strategic}} {{cooperation with}} Norcontrol started in November 1967, when Norsk Data bought shares for NOK200,000 in Norcontrol, which again bought shares for NOK70,000 in Norsk Data. Norcontrol placed {{the first order}} for a Norsk Data computer on 26 January 1968. Shortly afterwards computers were ordered by the Central Institute for Industrial Research and the Chr. Michelsen Institute. Norsk Data and Kongsberg signed a market sharing agreement on 23 April 1968, in which Kongsberg would deliver computers to the military industry while Norsk <b>Data</b> <b>would</b> deliver to the civilian sector. In the early years, Kongsberg {{would continue to be}} Norsk Data's main competitor as the only other Norwegian manufacturer of minicomputers. Additional Norsk Data shares were issued in May 1968, bringing the share capital to NOK894,000. New investors included Norsk Elektrisk & Brown Boveri (NEBB), Habberstad and Tharald Brøvig.|$|E
25|$|As of 2010, Canada’s {{sovereignty}} over the region’s waters {{is still a}} contentious issue. Many other potential infringements of Canada’s territorial claims (especially by military vessels, which sometimes operate under secrecy) were committed after the controversy. Despite this, the U.S. Coast Guard has remained respectful of the agreement resulting from the controversy, which has helped to foster cooperation with the Canadian coast guard in protecting {{the interests of the}} two countries in the Arctic and solving this dispute once and for all. This cooperation notably includes an ongoing joint program with the goal of gathering geological data that could help in delineating the continental shelf. This <b>data</b> <b>would</b> in turn help towards the preparation of a submission to the United Nations Commission on the Limits of the Continental Shelf for 2013 with the intention of fixing precise limits on where Canada may exercise sovereignty in the region.|$|E
25|$|Skeptics {{suggest that}} the palaeomagnetic data could be {{corrupted}} if Earth's ancient magnetic field was substantially different from today's. Depending on the rate of cooling of Earth's core, {{it is possible that}} during the Proterozoic, the magnetic field did not approximate a simple dipolar distribution, with north and south magnetic poles roughly aligning with the planet's axis as they do today. Instead, a hotter core may have circulated more vigorously and given rise to 4, 8 or more poles. Palaeomagnetic <b>data</b> <b>would</b> then have to be re-interpreted, as the sedimentary minerals could have aligned pointing to a 'West Pole' rather than the North Pole. Alternatively, Earth's dipolar field could have been oriented such that the poles were close to the equator. This hypothesis has been posited to explain the extraordinarily rapid motion of the magnetic poles implied by the Ediacaran palaeomagnetic record; the alleged motion of the north pole would occur around {{the same time as the}} Gaskiers glaciation.|$|E
5000|$|Based on {{the same}} <b>data</b> that <b>would</b> give U. squamata species rank, the {{southern}} Baja California populations could arguably be split off (as Uta elegans), too.|$|R
50|$|Consulting {{multiple}} independent {{sources is}} a common technique for detecting errors and deception, as any divergences or contradictions between statements, or <b>data</b> samples, <b>would</b> likely indicate one of these.|$|R
50|$|Following LCM Partners’ {{consultations}} it {{was decided}} that the European <b>Data</b> Warehouse <b>would</b> receive the loan-level data from the originators and would then check it for compliance against the ECB templates.|$|R
