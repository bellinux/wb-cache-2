2|34|Public
40|$|Abstract. In this {{contribution}} {{we propose}} a 3 D-deblocking method for macroblock loss recovery in block-based video decoding systems. For a lost macroblock, the motion vector is estimated. Using the estimated motion vector a deblocking filter recovers the lost macroblock by the corresponding motion compensated image {{samples of the}} previous <b>frame.</b> <b>Macroblock</b> borders are filtered, if block artifacts are estimated by this deblocking filter. It is shown that in case of transmission errors this restoration technique can successfully be used in block-based video decoding systems. Index Terms Error concealment, video restoration, video coding and transmission...|$|E
40|$|A novel motion {{activity}} descriptor and its extraction from a compressed MPEG (MPEG- 1 / 2) {{video stream}} are presented. The descriptor {{consists of two}} parts, a temporal descriptor and a spatial descriptor. To get the temporal descriptor, the "motion intensity" is first computed based on P <b>frame</b> <b>macroblock</b> information. Then the motion intensity histogram is generated for a given video unit as the temporal descriptor. To get the spatial descriptor, the average magnitude of the motion vector in a P frame is used to threshold the macro-blocks into "zero" and "non-zero" types. The average magnitude of the motion vectors and three types of runs of zeros in the frame are then taken as the spatial descriptor. Experimental {{results show that the}} proposed descriptor is fast, and that the combination of the temporal and spatial attributes is effective. Key elements of the intensity parameter, spatial parameters and the temporal histogram of the descriptor have been adopted by the draft MPEG- 7 standard [10]...|$|E
30|$|In summary, {{the method}} {{proposed}} above determines, for each key <b>frame,</b> at <b>macroblock</b> level, the QP {{to reach a}} certain selected quality at the minimum rate cost. In the following, the proposed solution considering both the H. 264 /AVC Intra encoder and key frames quality control modules will be called quality controlled H. 264 /AVC Intra encoder.|$|R
5000|$|For video compression, key {{frames are}} divided into macroblocks. The motion model is a {{disruption}} of a key <b>frame,</b> where each <b>macroblock</b> is translated by a motion vector given by the motion parameters.|$|R
5000|$|Macroblock-adaptive frame-field (MBAFF) coding, using a {{macroblock}} pair structure for pictures coded as <b>frames,</b> allowing 16×16 <b>macroblocks</b> in field mode (compared with MPEG-2, where field mode processing {{in a picture}} that is coded as a frame results in the processing of 16×8 half-macroblocks).|$|R
40|$|Abstract—This paper {{presents}} an optimized MPEG 2 video codec implementation, which drastically reduces {{the number of}} computations and memory accesses required for video compression. Unlike traditional scheme, we reuse data stored in frame memory to omit unnecessary coding operations and memory read/writes for unchanged macroblocks. Due to dynamic memory sharing among reference <b>frames,</b> data-driven <b>macroblock</b> characterization and selective macroblock processing, we perform less than 15 % of the total operations required by a conventional coder while maintaining high picture quality. Keywords—Data reuse, adaptive processing, video coding, MPEG I...|$|R
40|$|International Symposium on Intelligent Signal Processing and Communication Systems, ISPACS 2003 This paper {{presents}} an architectural enhancement for reducing memory requirements of MPEG video coding based on incremental memory sharing between the reconstructed picture frames. The method exploits the temporal locality of block-based hybrid coding by dynamically replacing the processed macroblocks {{of the previously}} reconstructed picture <b>frame</b> with <b>macroblocks</b> of a newly reconstructed picture frame. Simulation results show that using this method we can reduce the total memory size by a 13 %- 32 % for bidirectional prediction and almost half for unidirectional prediction schemes without any impact on image quality and throughput...|$|R
40|$|Abstract — Due to the {{multi-frame}} {{motion estimation}} (ME), H. 264 /AVC requires ultra high memory bandwidth. Conventional Multiple Reference <b>frames</b> Single Current <b>macroblock</b> (MRSC) scheme only considers the data reuse within one frame, requiring on-chip memory size and off-chip memory bandwidth in {{proportional to the}} number of reference frames. In this paper, a Single Reference <b>frame</b> Multiple Current <b>macroblocks</b> (SRMC) scheme is presented to further exploit the data reuse between multiple frames. With rescheduling of the macroblock (MB) procedures at frame level, one loaded search window can be utilized by multiple current MBs in different frames. The demanded memory size and bandwidth for multi-frame ME can thus be reduced to those of MRSC scheme with only one reference frame. Moreover, based on SRMC, a system architecture for H. 264 /AVC encoding is proposed. For HDTV specifications, 62. 21 KB (74. 8 %) of SRAM and 364. 3 MB/s (62. 6 %) of system bandwidth are saved in comparison with MRSC scheme. I...|$|R
40|$|Abstract—Due to the {{multiple}} reference frame motion estimation (MRF-ME), an H. 264 /AVC encoder requires ultrahigh memory bandwidth. Conventional multiple reference <b>frames</b> single current <b>macroblock</b> (MRSC) scheme only considers the data reuse within one frame, and requires on-chip memory size and off-chip memory bandwidth in {{proportional to the}} reference frame number. In this paper, a single reference <b>frame</b> multiple current <b>macroblocks</b> (SRMC) scheme is presented to further exploit the data reuse at frame level. With frame-level rescheduling of the motion estimation ME procedures in different reference frames, one loaded search window can be utilized by multiple current MBs in different original frames. The demanded on-chip memory size and off-chip memory bandwidth for MRF-ME can thus be reduced to those supporting only one reference frame. Moreover, based on SRMC scheme, an architecture prototype with two-stage mode decision flow is proposed. For HDTV specifications, 62. 21 KB (74. 8 %) of SRAM and 364. 3 MB/s (62. 6 %) of system bandwidth are saved {{in comparison with the}} MRSC scheme...|$|R
40|$|Abstract- Video {{sequences}} are compressed by processing individual <b>macroblocks</b> within <b>frames.</b> Traditional <b>macroblock</b> {{order of}} processing is linear {{from the left}} to the right, and from the top to the bottom. In this paper, an alternative order of macroblock processing is considered. Proposed is the spiral scan beginning at the centre of an image, or more general, in the centre of interest that is often placed in the centre of an image by a person who shots the video. The paper shows that such a change of processing order does not influence compression performance but it is profitable in scalable video coding {{where it can be}} used in the enhancement layers by SNR scalability. The paper provides the respective experimental results for lowcomplexity efficient SNR scalability with fine granularity...|$|R
30|$|H. 264 {{includes}} many profiles, levels and feature definitions. There are seven sets of capabilities, {{referred to as}} profiles, targeting specific classes of applications: Baseline Profile (BP) for low-cost applications with limited computing resources, which is widely used in videoconferencing and mobile communications; Main Profile (MP) for broadcasting and storage applications; Extended Profile (XP) for streaming video with relatively high compression capability; High Profile (HiP) for high-definition television applications; High 10 Profile (Hi 10 P) going beyond present mainstream consumer product capabilities; High 4 [*]:[*] 4 [*]:[*] 2 Profile (Hi 422 P) targeting professional applications using interlaced video; High 4 [*]:[*] 4 [*]:[*] 4 Profile (Hi 444 P) supporting up to 12 bits per sample and efficient lossless region coding and an integer residual color transform for RGB video. The levels in H. 264 are defined as Level 1 to 5, {{each of which is}} for specific bit, <b>frame</b> and <b>macroblock</b> (MB) rates to be realized in different profiles.|$|R
40|$|Rate {{control is}} a {{complicated}} problem in the H. 264 /AVC coding standard, extra computation is usually needed for the existing rate control schemes to estimate the complexity of <b>frames</b> or <b>macroblocks</b> (MBs). However, during transcoding, information from precoded video {{could be used to}} simplify the rate control. In this paper, we propose a low-complexity rate control scheme for transcoding from H. 263 to H. 264 /AVC. The relationship between the rate of the precoded video and both the rate and distortion of the transcoded video are studied. By using only the rate information from the precoded video, we introduce a row-layer bit allocation and perform average rate shaping across a row of MBs. Estimation error diffusion is also introduced. The proposed scheme has sufficiently lower computational complexity than other methods as there is no explicit complexity measurement of MBs and complicated parameters updating. Experimental results show the effectiveness of the proposed scheme. Index Terms — Video coding, video signal processing 1...|$|R
40|$|Abstract—This paper {{presents}} a scalable rate control (SRC) {{scheme based on}} a more accurate second-order rate-distortion model. A sliding-window method for data selection is used to mitigate {{the impact of a}} scene change. The data points for updating a model are adaptively selected such that the statistical behavior is improved. For video object (VO) shape coding, we use an adaptive threshold method to remove shape-coding artifacts for MPEG- 4 applications. A dynamic bit allocation among VOs is implemented according to the coding complexities for each VO. SRC achieves more accurate bit allocation with low latency and limited buffer size. In a single framework, SRC offers multiple layers of controls for objects, <b>frames,</b> and <b>macroblocks</b> (MBs). At MB level, SRC provides finer bit rate and buffer control. At multiple VO level, SRC offers superior VO presentation for multimedia applications. The proposed SRC scheme has been adopted as part of the International Standard of the emerging ISO MPEG- 4 standard [1], [2]. Index Terms—Bit allocation, MPEG, multiple video object, rat...|$|R
40|$|On {{the basis}} of the {{rate-distortion}} theory, a new projection of the macroblock mode about the inner and mutual compiling frame is presented in this paper, and the MSE distortion computation is built. This method can acquire the optimal control point in the rate-distortion curve under the code error environment from the global optimization perspective, not only self-adaptively adjusting the quantization parameter under given network bandwidth but also refreshing inner <b>macroblock</b> <b>frame</b> according to the current probability of loss of network package, and can {{play an important role in}} counteracting the channel code error, which has a good reference value in the way of transmitting robust video code in wireless environment and allocating resources...|$|R
30|$|Due {{to heavy}} {{computation}} demands of video coding, parallel {{implementation of the}} basic operations of this computation is necessary for satisfying the real time constraints usually imposed in multimedia applications. Fortunately, motion estimation within each macroblock, {{which is the most}} computation intensive task in video coding, exhibits data parallelism, that is, different data can be processed concurrently by multiple processors. Nevertheless, the use of previous <b>frames</b> or previous <b>macroblocks</b> in the same frame for encoding the current <b>frame</b> or <b>macroblock,</b> respectively makes video coding an inherently sequential procedure at a higher level, limiting the degree of parallelism that can be achieved. Yet, for limiting the effect of data loss in a frame due to transmission errors in all subsequent frames, or for providing random access capability in the encoded video, most video coding standards define segments within video that can be processed independently, that is, they do not depend on previously decoded parts of the video. Specifically, the frame sequence can be spit into a number of group of pictures (GOPs), each of which contains consecutive frames which can be encoded/decoded independently of other groups. In addition, each frame can be divided into a number of slices each containing a number of consecutive <b>macroblocks</b> of the <b>frame.</b> Again, each slice can be encoded/decoded independently of other slices. Although, the aim for these partitioning techniques was not to facilitate parallel processing, the fact that GOPs and slices can be processed independently can also be exploited for effective parallel implementation. Also, in contrast to the previous video coding standards where parallel processing was only an afterthought, in the latest standard, HEVC (Sullivan et al. 2012), parallel processing is considered {{in the first place and}} additional partitioning schemes (tiling) or pipeline-based techniques (wavefront processing) are introduced (Pourazad et al. 2012). In tiling, each frame is partitioned into rectangular regions (tiles) separated by vertical and horizontal boundaries. Each tile can be processed independently of other tiles thereby enabling parallel processing. In wavefront processing, the processing of the current frame proceeds in raster scan order but the processing of a block in a row can start as soon as two neighboring blocks in the row above have been processed.|$|R
40|$|Current systems often assume “worst-case ” {{resource}} utilization for {{the design}} and implementation of compression techniques and standards, thereby neglecting the fact that multimedia coding algorithms require time-varying resources, which differ significantly from the “worst-case ” requirements. To enable adaptive resource management for multimedia systems, resource-estimation mechanisms are needed. Previous research demonstrated that on-line adaptive linear prediction techniques typically exhibit superior efficiency to other alternatives for resource prediction of multimedia systems. In this paper, we formulate the problem of adaptive linear prediction of video decoding resources by analytically expressing the possible adaptation parameters for a broad class of video decoders. The resources are {{measured in terms of}} the time required for a particular operation of each decoding unit (e. g. motion compensation or entropy decoding of a video frame). Unlike prior research that mainly focuses on estimation of execution time based on previous measurements (i. e. based on autoregressive prediction or platform and decoder-specific off-line training), we propose the use of generic complexity metrics (GCMs) as the input for the adaptive predictor. GCMs represent the number of times the basic building blocks are executed by the decoder and depend on the source characteristics, decoding bit-rate and the specific algorithm implementation. Different GCM granularities (e. g. per video <b>frame</b> or <b>macroblock...</b>|$|R
40|$|In {{order to}} allow users to use {{handheld}} devices accessing video information, such as downloading and playing video files, {{there is a need}} to downscale the compressed video into lower spatial resolution and lower transmission bit rate. In this work, transcoding the compressed H. 263 video into low spatial-resolution is discussed and realized. To reduce the computation cost, motion vectors from the incoming video stream are resampled and reused. We propose a novel approach to refine motion vectors adaptively according to the motion of every <b>frame</b> or every <b>macroblock</b> in a <b>frame.</b> The proposed approach can improve the video quality and reduce predictive residues of every frame, hence reduce the transmission bit rate. Implementation results suggest that the proposed approach produces better image quality and lower transmission bit rate than a number of previous approaches...|$|R
40|$|Transmission {{of hybrid}} coded video {{including}} motion compensation and spatial prediction over error-prone channels {{results in the}} well-known problem of spatio-temporal error propagation at the decoder. A widely accepted standard-compliant technique to {{enhance the quality of}} the decoded video significantly is the more frequent introduction of intra-coded macroblocks. However, intra-coded information generally requires more bit rate. Therefore, a careful selection of intra-updates in terms of rate and distortion is necessary. A flexible and robust rate-distortion optimization technique is presented to select coding mode and reference <b>frame</b> for each <b>macroblock.</b> The channel statistics are included in the optimization process. We derive a method to obtain an estimate of the decoder pixel distortion at the encoder. The presented techniques are verified within the new H. 26 L/JVT video coding standard based on common test conditions. ...|$|R
40|$|ABSTRACT: In this article, {{we present}} a {{scalable}} video compression algorithm to deliver higher compression efficiency with limited drifting error. MPEG- 4 Fine Granularity Scalability (FGS) compresses the video into a base layer and an enhancement layer. Currently, because the enhancement layer is predicted from the poor-quality base layer, the compression efficiency is low. To improve the compression effi-ciency, we construct enhancement-layer predictors from (1) macrob-locks of current reconstructed base-layer <b>frame,</b> (2) <b>macroblocks</b> of previously reconstructed enhancement-layer frame, and (3) the aver-age of previous two. On the other hand, the unpredictable receiving manner of enhancement layer could cause predictor mismatch error. The predictor mismatch error further results in drifting error. To min-imize the drifting error, we create an adaptive mode-selection algo-rithm, in the encoder, which first smartly estimates possible drifting error of the decoder side and then uses the best macroblock modes wisely. In this article, we show that predictors constructed jointly from the base-layer frame and the enhancement-layer frame can reduce the drifting error. And, predictors constructed from the base-layer frame can stop the drifting error. As compared to other advance FGS schemes, our algorithm shows 0. 3 – 0. 5 dB PSNR improvement with a less complex structure. Although compared to MPEG- 4 FGS, more than 1 – 1. 5 dB quality improvement can be gained. © 2004 Wiley Peri...|$|R
40|$|In this article, {{we present}} a {{scalable}} video compression algorithm to deliver higher compression efficiency with limited drifting error. MPEG- 4 Fine Granularity Scalability (FGS) compresses the video into a base layer and an enhancement layer. Currently, because the enhancement layer is predicted from the poor-quality base layer, the compression efficiency is low. To improve the compression efficiency, we construct enhancement-layer predictors from (1) macroblocks of current reconstructed base-layer <b>frame,</b> (2) <b>macroblocks</b> of previously reconstructed enhancement-layer frame, and (3) the average of previous two. On the other hand, the unpredictable receiving manner of enhancement layer could cause predictor mismatch error. The predictor mismatch error further results in drifting error. To minimize the drifting error, we create an adaptive mode-selection algorithm, in the encoder, which first smartly estimates possible drifting error of the decoder side and then uses the best macroblock modes wisely. In this article, we show that predictors constructed jointly from the base-layer frame and the enhancement-layer frame can reduce the drifting error. And, predictors constructed from the base-layer frame can stop the drifting error. As compared to other advance FGS schemes, our algorithm shows 0. 3 [...] 0. 5 dB PSNR improvement with a less complex structure. Although compared to MPEG- 4 FGS, more than 1 [...] 1. 5 dB quality improvement can be gained...|$|R
40|$|Multiple {{reference}} frame motion estimation (MRF ME) increases the video coding efficiency {{at the expense}} of increased computational complexity and energy consumption. Therefore, in this paper, a low complexity H. 264 MRF ME algorithm and a low energy adaptive hardware for its real-time implementation are proposed. The proposed MRF ME algorithm reduces the computational complexity of MRF ME by using a dynamically determined number of reference <b>frames</b> for each <b>Macroblock</b> (MB) and early termination. The proposed H. 264 MRF ME hardware is implemented in Verilog HDL. The proposed H. 264 MRF ME hardware has 29 - 72 % less energy consumption than an H. 264 MRF ME hardware using 5 {{reference frame}}s for all MBs with a negligible PSNR loss. Therefore, it can be used in consumer electronics products that require real-time video processing or compression with low power consumption...|$|R
40|$|Abstract—The H. 264 /AVC video coding {{standard}} aims to enable significantly improved compression performance compared to all existing video {{coding standard}}s. In {{order to achieve}} this, a robust rate-distortion optimization (RDO) technique is employed to select the best coding mode and reference <b>frame</b> for each <b>macroblock.</b> As a result, the complexity and computation load increase drastically. This paper presents a fast mode decision algorithm for H. 264 /AVC intraprediction based on local edge information. Prior to intrapre-diction, an edge map is created and a local edge direction histogram is then established for each subblock. Based {{on the distribution of}} the edge direction histogram, {{only a small part of}} intrapredic-tion modes are chosen for RDO calculation. Experimental results show that the fast intraprediction mode decision scheme increases the speed of intracoding significantly with negligible loss of peak signal-to-noise ratio...|$|R
40|$|We {{investigate}} video classification via a two-stream convolutional {{neural network}} (CNN) design that directly ingests information extracted from compressed video bitstreams. Our approach begins with the observation that all modern video codecs divide the input <b>frames</b> into <b>macroblocks</b> (MBs). We demonstrate that selective access to MB motion vector (MV) information within compressed video bitstreams can also provide for selective, motion-adaptive, MB pixel decoding (a. k. a., MB texture decoding). This in turn allows for the derivation of spatio-temporal video activity regions at extremely high speed in comparison to conventional full-frame decoding followed by optical flow estimation. In order to evaluate the accuracy of a video classification framework based on such activity data, we independently train two CNN architectures on MB texture and MV correspondences and then fuse their scores to derive the final classification of each test video. Evaluation on two standard datasets shows that the proposed approach is competitive to the best two-stream video classification approaches found in the literature. At the same time: (i) a CPU-based realization of our MV extraction is over 977 times faster than GPU-based optical flow methods; (ii) selective decoding is up to 12 times faster than full-frame decoding; (iii) our proposed spatial and temporal CNNs perform inference at 5 to 49 times lower cloud computing cost than the fastest methods from the literature. Comment: Accepted in IEEE Transactions on Circuits and Systems for Video Technology. Extension of ICIP 2017 conference pape...|$|R
40|$|Rate control plays a {{key role}} in video coding standards. Its goal is to achieve a good quality at a given target bit-rate. In H. 264 /AVC, rate control {{algorithm}} for both Intra and Inter-frames suffers from some defects. In the Intra-frame rate control, the initial quantization parameter (QP) is mainly adjusted according to a global target bit-rate and length of GOP. This determination is inappropriate and generates errors in the whole of video sequence. For Inter coding unit (<b>Frame</b> or <b>Macroblock),</b> the use of MAD (Mean Average Differences) as a complexity measure, remains inefficient, resulting in improper QP values because the MAD handles locally images characteristics. QP miscalculations may also result from the linear prediction model which assumes similar complexity from coding unit to another. To overcome these defects, we propose in this paper, a new Rate-Quantization (R-Q) model resulting from extensive experiments. This latter is divided into two models. The first one is an Intra R-Q model used to determine an optimal initial quantization parameter for Intraframes. The second one is an Inter R-Q model that aims at determining the QP of Inter coding unit according to the statistics of the previous coded ones. It does not use any complexity measure and substitutes both linear and quadratic models used in H. 264 /AVC rate controller. Objective and subjective simulations have been carried out using JM 15. 0 reference software. Compared to this latter, the global R-Q model (Intra and Inte...|$|R
40|$|In the {{new video}} coding standard, MPEG- 4 AVCIJVTIH. 264, motion {{estimation}} {{is allowed to}} use multiple reference frames. The reference software adopts full search scheme, and the increased computation is {{in proportion to the}} number of searched reference frames. However, the reduction of prediction residues is lughly dependent on the nature of sequences, not on the number of searched frames. In this paper, we present a method to speed up the matching process for multiple reference <b>frames.</b> For each <b>macroblock.</b> we analyze the available information after intra prediction and motion estimation from previous one frame to determine whether it is necessary to search more frames. The information we use includes selected mode, inter prediction residues, intra prediction residues, and motion vectors. Simulation results show that the proposed algorithm can save up to 90 % of unnecessary frames while keeping the average miss rate of optimal frames less than 4 %. 1...|$|R
40|$|The recent JVT video {{coding scheme}} (MPEG- 4 AVC/H. 264) is a {{promising}} technique {{due to its}} high coding efficiency. Hypothetical Reference Decoder (HRD) {{is a very important}} part in JVT video coding, which represents a set of normative requirements on bitstream for the purpose of avoiding buffer overflow and underflow. The problem of HRD requirements can be solved by rate control. This paper proposes an effective rate control scheme for JVT video coding with HRD considerations. First, bit allocation with HRD constraints is presented, and second, based on a simple rate distortion model, a single pass rate control is implemented on both <b>frame</b> level and <b>macroblock</b> level. Experimental results show that the proposed rate control algorithm can achieve the target bit rate with very little bit rate or image quality fluctuation, and meanwhile it can well meet the HRD requirements. Furthermore, the proposed algorithm is so simple that it only introduces little computation complexity. Therefore, it can be used in real time video coding. 1...|$|R
30|$|Many {{researchers}} {{have been working on}} parallel algorithms. The popular parallel algorithms that are proposed are at the GOP, <b>frame,</b> slice, and <b>macroblock</b> levels. Many {{researchers have}} implemented macroblock-level parallelism [3 – 10], but all the proposed methods so far have scalability issues. In [4], a method using SIMD instructions has been proposed to improve the encoding time of H. 264. However, this approach is too complex to implement on personal computers. The parallel algorithm using wave-front technique reported in [5] splits a <b>frame</b> into <b>macroblocks</b> and maps these blocks to different processors along the horizontal axis. This technique requires data communication among the parallel processing blocks (except for the outer blocks of a frame), slowing down the encoding process. The speedup values achieved with this implementation are 3.17 and 3.08 for quarter common intermediate format (QCIF) and common intermediate format (CIF) video formats, respectively [5]. The macroblock region partition (MBRP) algorithm proposed in [6] adopts wave-front technique and focuses on reducing the data communication between processors using a new data partitioning method. This data partitioning method assigns a specific macroblock region for each processor, so that neighboring macroblocks are mostly handled by the same processor. However, in this implementation, the waiting time of the processors before starting to encode a new macroblock is high [6]. The speedup values achieved with this method are 3.32 and 3.33, respectively, for CIF and standard definition (SD) video formats. The MBRP algorithm has not been applied to higher resolutions such as high-definition (HD) and full high-definition (FHD). A new macroblock-level parallelism method has been reported in [7]. In this method, the data partitioning on the macroblocks eliminates the dependency among the macroblocks {{at the beginning of the}} encoding process. Encoding the subsequent frames is initiated only when the reconstructed macroblocks constitute more than half of a frame. Thus, this method increases the concurrency of the thread-level parallelism to process multiple frames. The speedup values achieved with this method for CIF, SD, and HD video resolutions are around 3.8 ×. However, in this implementation, the authors have used only I and P frames and they have not included B frames. The dynamic data partition algorithm proposed in [8] for macroblock-level parallelism reduces data communication overhead and improves concurrency. The dynamic data partition algorithm achieves speedup values of 3.59 for CIF, 3.88 for 4 CIF, and 3.89 for HD resolution video formats. Even though good speedup values are obtained, these values are not consistent with different video formats. Various thread-level techniques have been proposed in [9] to effectively utilize a multicore processor. We have adopted some of these techniques in the proposed algorithm to improve the encoding time.|$|R
40|$|International audienceRate control plays a {{key role}} in video coding standards. Its goal is to achieve a good quality at a given target bit-rate. In H. 264 /AVC, rate control {{algorithm}} for both Intra and Inter-frames suffers from some defects. In the Intra-frame rate control, the initial quantization parameter (QP) is mainly adjusted according to a global target bit-rate and length of GOP. This determination is inappropriate and generates errors in the whole of video sequence. For Inter coding unit (<b>Frame</b> or <b>Macroblock),</b> the use of MAD (Mean Average Differences) as a complexity measure, remains inefficient, resulting in improper QP values because the MAD handles locally images characteristics. QP miscalculations may also result from the linear prediction model which assumes similar complexity from coding unit to another. To overcome these defects, we propose in this paper, a new Rate-Quantization (R-Q) model resulting from extensive experiments. This latter is divided into two models. The first one is an Intra R-Q model used to determine an optimal initial quantization parameter for Intra-frames. The second one is an Inter R-Q model that aims at determining the QP of Inter coding unit according to the statistics of the previous coded ones. It does not use any complexity measure and substitutes both linear and quadratic models used in H. 264 /AVC rate controller. Objective and subjective simulations have been carried out using JM 15. 0 reference software. Compared to this latter, the global R-Q model (Intra and Inter models combined) improves the coding efficiency in terms of PSNR, objectively (up to + 2. 01 dB), subjectively (by psychophysical experiments) and in terms of computational complexity...|$|R
40|$|An error {{resilient}} H. 264 {{coding scheme}} using SP/SI macroblocks {{is presented in}} this work. It is able to generate alternative SP macroblocks utilizing multiple reference frames [2] and the concealed versions of the corrupted frames [3]. These alternative macroblocks are used to replace the original ones in the output video stream {{to protect them from}} being affected by previous errors detected at the decoder side. The introduced bit bate is further reduced by adjusting quantization levels adaptively. Specifically, different versions of alternative SP macroblocks can be coded using different quantization levels, which is associated with different levels of error resilience performance and different bit rate consumptions. A proper alternative version is encoded according to the importance of the macroblock. The importance of the macroblock is measured by its influence on subsequent <b>frames</b> if the <b>macroblock</b> is not correctly reconstructed. Accordingly, fewer bits are used to replace those macroblocks with less importance. Simulation results demonstrate the proposed approach achieves an excellent error resilient capability and an improvement in reducing the bit rate overhead. Keywords: H. 264, video transmission, error resilience, error recovery, error concealment, SP/SI macroblocks 1...|$|R
40|$|We {{propose a}} scheme for Systematic Lossy Error Protection (SLEP) of an H. 264 /AVC {{compressed}} video bit-stream, using standard compatible {{features such as}} redundant slices, and flexible macroblock ordering. The systematic portion consists of a conventional H. 264 /AVC bit-stream. For error resilience, an additional Wyner-Ziv bit-stream is also transmitted. The Wyner-Ziv bit-stream allows the decoding of a coarsely quantized description of the original video signal, and is efficiently generated by using H. 264 /AVC redundant slices in conjunction with Reed-Solomon coding. The Wyner-Ziv bit-stream is decoded in order to recover the redundant video descriptions, which are used in lieu of portions lost from the original video signal due to channel errors. SLEP allows the video quality to degrade gracefully with worsening channel conditions, and provides a flexible trade-off between the achieved error resilience and the coarseness of the redundant description. The performance can be improved, especially for low motion video sequences, by applying SLEP to a region-of-interest in the video <b>frame,</b> using Flexible <b>Macroblock</b> Ordering (FMO). We provide experimental results for two video transmission scenarios, which demonstrate the advantages of SLEP over FEC as an error resilience scheme. Keywords: Wyner-Ziv coding, distributed video coding, side information, systematic source-channel coding, redundant slices, flexible macroblock ordering. 1...|$|R
40|$|In {{this paper}} we propose a scheme for Systematic Lossy Error Protection (SLEP) of an H. 264 /AVC {{compressed}} video bit-stream, using standard compatible features such as redundant slices, and flexible macroblock ordering. In this scheme, the systematic transmission consists of a conventional H. 264 /AVC bit-stream. For error resilience, an additional bit-stream known as the Wyner-Ziv bit-stream is also transmitted. The Wyner-Ziv bit-stream allows the decoding of a coarsely quantized description of the original video signal, and is efficiently generated by using H. 264 /AVC redundant slices in conjunction with Reed-Solomon coding. The Wyner-Ziv bit-stream is decoded in order to recover the redundant video descriptions, which are used in lieu of portions lost from the original video signal due to channel errors. SLEP allows the video quality to degrade gracefully with worsening channel conditions, and provides a flexible trade-off between the achieved error resilience and the coarseness of the redundant description. The performance can be improved, especially for low motion video sequences, by applying SLEP to a region-of-interest in the video <b>frame,</b> using Flexible <b>Macroblock</b> Ordering (FMO). We provide experimental results for two video transmission scenarios, which demonstrate the advantages of SLEP over FEC as an error resilience scheme...|$|R
40|$|A fast intra skip {{detection}} algorithm {{based on}} the rate-distortion (RD) cost for an inter frame (P-slices) is proposed for H. 264 /AVC video encoding. In the H. 264 /AVC coding standard, a robust rate-distortion optimization technique is used to select the best coding mode and reference <b>frame</b> for each <b>macroblock</b> (MB). There are three types of intra predictions according to profiles. These are 16 × 16 and 4 × 4 intra predictions for luminance and an 8 × 8 intra prediction for chroma. For the high profile, an 8 × 8 intra prediction has been added for luminance. The 4 × 4 prediction mode has 9 prediction directions with 4 directions for 16 × 16 and 8 × 8 luma, and 8 × 8 chrominance. In addition to the inter mode search procedure, an intra mode search causes {{a significant increase in}} the complexity and computational load for an inter frame. To reduce the computational load of the intra mode search at the inter frame, the RD costs of the neighborhood MBs for the current MB are used and we propose an adaptive thresholding scheme for the intra skip extraction. We verified the performance of the proposed scheme through comparative analysis of experimental results using joint model reference software. The overall encoding time was reduced up to 32 % for the IPPP sequence type and 35 % for the IBBPBBP sequence type...|$|R
40|$|Includes bibliographical {{references}} (pages 45 - 46). The Rate Control module in {{the reference}} video codec software Joint Model (JM), developed by Joint Video Team (JVT) of H. 264 /AVC video coding standard, {{is responsible for}} assigning bits to each coding unit such that the available bit budget is efficiently utilized. Different parameters are considered to assign a Quantization Parameter (QP) and hence have a check over the number of bits allocated to a coding unit (16 x 16 macroblock, unless partitioned). The flexible macroblock ordering (FMO) feature in H. 264 /AVC enables customized ordering of the macroblocks for the encoding. This thesis implements an algorithm by combining the rate control scheme and the FMO feature to selectively {{enhance the quality of}} Regions of Interest (ROI) in a video frame which is called the ROI video coding. Such kind of video coding is particularly helpful in applications like video conferencing or transportation of surveillance videos over wireless channels. These applications require video encoding schemes which exploit the fact that the entire frame is not important and hence different parts of the frame should/can be encoded with varying qualities. ROI coding is to be enabled by making appropriate changes in the rate control module to accommodate some regions in a frame with relatively higher importance. The algorithm employs FMO Type 2 which is meant to divide macroblocks into foreground and background regions in a frame. The coordinates for the ROI comes from a tracking algorithm and is updated for every <b>frame.</b> Later the <b>macroblocks</b> in the non-ROI/background (region other than the ROI) slice group are assigned a relatively higher QP. Then the bits allocated for the frame is divided in a manner aiding this disproportionate QP assignment within a fram...|$|R
40|$|MPEG {{digital video}} is {{becoming}} ubiquitous for video storage and communications. It is often desirable to perform various video cassette recording (VCR) {{functions such as}} backward playback in MPEG videos. However, the predictive processing techniques employed in MPEG severely complicate the backward-play operation. A straightforward implementation of backward playback is to transmit and decode the whole group-of-picture (GOP), store all the decoded frames in the decoder buffer, and play the decoded frames in reverse order. This approach requires a significant buffer in the decoder, which depends on the GOP size, to store the decoded frames. This approach could not be possible in a severely constrained memory requirement. Another alternative is to decode the GOP up to the current frame to be displayed, {{and then go back}} to decode the GOP again up to the next frame to be displayed. This approach does not need the huge buffer, but requires much higher bandwidth of the network and complexity of the decoder. In this paper, we propose a macroblock-based algorithm for an efficient implementation of the MPEG video streaming system to provide backward playback over a network with the minimal requirements on the network bandwidth and the decoder complexity. The proposed algorithm classifies macroblocks in the requested <b>frame</b> into backward <b>macroblocks</b> (BMBs) and forward/backward macroblocks (FBMBs). Two macroblock-based techniques are used to manipulate different types of macroblocks in the compressed domain and the server then sends the processed macroblocks to the client machine. For BMBs, a VLC-domain technique is adopted {{to reduce the number of}} macroblocks that need to be decoded by the decoder and the number of bits that need to be sent over the network in the backward-play operation. We then propose a newly mixed VLC/DCT-domain technique to handle FBMBs in order to further reduce the computational complexity of the decoder. With these compressed-domain techniques, the proposed architecture only manipulates macroblocks either in the VLC domain or the quantized DCT domain resulting in low server complexity. Experimental results show that, as compared to the conventional system, the new streaming system reduces the required network bandwidth and the decoder complexity significantly. Department of Electronic and Information Engineerin...|$|R
40|$|The {{recently}} developed H. 264 / MPEG- 4 Part 10 video compression standard achieves better video compression efficiency than previous video compression standards {{at the expense}} of increased computational complexity and power consumption. Multiple reference frame (MRF) Motion Estimation (ME) is the most computationally intensive and power consuming part of H. 264 video encoders. Therefore, in this thesis, we designed and implemented a reconfigurable baseline H. 264 video encoder hardware for real-time portable applications in which the number of reference frames used for MRF ME can be configured based on the application requirements in order to trade-off video coding efficiency and power consumption. The proposed H. 264 video encoder hardware is based on an existing low cost H. 264 intra frame coder hardware and it includes new reconfigurable MRF ME, mode decision and motion compensation hardware. We first proposed a low complexity H. 264 MRF ME algorithm and a low energy adaptive hardware for its real-time implementation. The proposed MRF ME algorithm reduces the computational complexity of MRF ME by using a dynamically determined number of reference <b>frames</b> for each <b>Macroblock</b> and early termination. The proposed MRF ME hardware architecture is implemented in Verilog HDL and mapped to a Xilinx Spartan 6 FPGA. The FPGA implementation is verified with post place & route simulations. The proposed H. 264 MRF ME hardware has 29 - 72 % less energy consumption on this FPGA than an H. 264 MRF ME hardware using 5 reference frames for all MBs with a negligible PSNR loss. We then designed the H. 264 video encoder hardware and implemented it in Verilog HDL. The proposed video encoder hardware is mapped to a Xilinx Virtex 6 FPGA and verified with post place & route simulations. The bitstream generated by the proposed video encoder hardware for an input frame is successfully decoded by H. 264 Joint Model reference software decoder and the decoded frame is displayed using a YUV Player tool for visual verification. The FPGA implementation of the proposed H. 264 video encoder hardware works at 135 MHz, it can code 55 CIF (352 x 288) frames per second, and its power consumption ranges between 115 mW and 235 mW depending on the number of reference frames used for MRF ME...|$|R
40|$|Three-dimensional (3 D) videos are {{becoming}} popular {{not only in}} commercial cinemas but also home entertainment systems, such as TVs, DVDs, Blu-ray and games. Because of the radical development of 3 DTV technologies, the broadcasting of high-definition 3 D videos is in great demand which is growing rapidly in the mass consumer market. In spite of increasing consumer interest, poor quality, cross-talk or side effects and visual quality degradation due to packet loss during transmission has hampered the advancement of 3 D visualization. Determining the impacts of transmission losses and assessing the quality of distorted 3 D videos are crucial for the design and arrangement of advanced immersive media distribution platforms, a topic {{which is at the}} centre of this work. The impacts of network errors and their concealment in 2 D videos ensured that error-resilient video transmission was widely discussed in the past. However, the scenario is different for 3 D videos as distortions in one or both views are perceived quite differently and create detrimental effects which lead to binocular rivalry. This strongly degrades the Quality of Experience (QoE) as it produces visual discomfort which can cause visual fatigue, eye strain, headaches and nausea. Since the Human Visual System (HVS) is more sensitive to 3 D perceptions, the impacts of transmission errors, such as delays or packet losses, need to be carefully analyzed, with proper error concealment methods and their effects on a viewer’s perception needing to be defined. In this dissertation, the main focus is ensuring error-resilient video communication and increasing the opportunity to more effectively fuse 3 D video content in order to improve the overall QoE of users. A key contribution of this work is the decision to assess the success of all proposed techniques using formal subjective testing. The first effort to address these challenges was to review state-of-the-art 3 D error concealment strategies and propose a low-complexity frame-loss concealment method for a video decoder. Subjective testing of common 3 D video sequences demonstrated the proposed methods’ efficiency for stereoscopic video error concealment in terms of visual comfort and video quality. Various statistical comparisons with previously proposed methods were performed to define this technique’s significance in terms of its full frame-loss concealment and feasibility for real-time video transmission applications. Binocular rivalry is a visual phenomenon that {{has been the subject of}} intensive investigations of stereo visual perception for many years. The next part of this study is to attempt to quantify the detrimental effects of binocular rivalry. Existing approaches, in which one or more <b>frames</b> or <b>macroblocks</b> are lost in one or both views because of packet losses during transmission, were applied for error concealment. Then, standard numbers of subjects were engaged in subjective testing on common error concealed 3 D video sequences. The evaluations provided by these subjects were then combined and analyzed using a standard student t-test which allowed the impact of binocular rivalry to be compared with that of monocular viewing. 	Finally, based on the criteria of the human visual system (HVS) and the impact of binocular rivalry, novel Quality Assessment (QA) metrics for quantifying the perceived quality of transmitted and degraded stereoscopic videos were proposed. The extracted features were accumulated according to the binocular suppression theory, with the disparity index modelled by taking into account the similar features of stereo videos and edge masking employed to quantify the suppression of binocular vision and impairments due to packet losses in the network. Based on the evidence obtained by subjective evaluations, the psychovisual effect of binocular rivalry was integrated to improve the overall QA and the robustness of our approach to reflect human visual sensitivity in terms of stereo vision. This kind of distortion measure or impairment metric is useful for enabling an improved QA of a stereo video without the need for formal subjective evaluation tests...|$|R
