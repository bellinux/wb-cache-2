18|62|Public
60|$|But {{how soon}} these raptures abated, when {{after a brief}} <b>idle</b> <b>interval,</b> we were again set to work, and I had a vile {{commission}} {{to clean out the}} chicken coops, and make up the beds of the pigs in the long-boat.|$|E
30|$|To {{meet the}} Quality of Service (QoS) {{required}} by cloud {{users in the}} context of fluctuating IT workloads, data center operators usually over-provision the computing resource according to the peak workload. As a result, the IT resource is extremely underutilized (20 − 30 % [18] in typical data centers). Staggeringly, server energy consumption is out of proportion to its utilization, and energy consumed by an idle server is about 60 % of a fully utilized counterpart [19]. Controlling the sleep/active state of servers is proved to be an effective way to save IT energy. Meisner et al. [19] presented an energy conservation approach named PowerNap, which switches the operation state of servers between active and sleep modes to cater for the fluctuating workload. However, when the actual <b>idle</b> <b>interval</b> is less than the wake-up latency, the frequent switch between active and sleep modes may be negative for energy saving. To address this issue, Duan et al. [20] proposed a prediction scheme, which dynamically estimates the length of CPU <b>idle</b> <b>interval</b> and thereby intelligently picks out the most cost-efficient operation mode to effectively cut down idle energy.|$|E
30|$|The DCF {{access method}} imposes an <b>idle</b> <b>interval</b> between {{consecutive}} frames, {{which is called}} the Interframe Space (IFS). Different IFSs are defined in order to impose different priorities to multiple frame types as following: SIFS (Short Interframe Space), PIFS (PCF Interframe Space), DIFS (Distributed Interframe Space), and EIFS (Extended Interframe Space). SIFS is the shortest of the interframe spaces and it is used for ACK frames. Only stations operating under the Point Coordination Function (PCF) will use PIFS. DIFS is used by stations operating under the DCF mechanism to transmit data frames and management frames. EIFS is used in communication-error conditions.|$|E
40|$|Abstract — While Dynamic Voltage Scaling (DVS) is an {{efficient}} technique {{in reducing the}} dynamic energy consumption of a CMOS processor, methods that employ DVS without considering leakage current are quickly becoming less efficient when considering the processor’s overall energy consumption. A leakage conscious DVS voltage schedule may require the processor to run at a higher-than-necessary speed to execute a given set of real-time tasks, which {{can result in a}} large number of <b>idle</b> <b>intervals.</b> To effectively reduce the energy consumption during these <b>idle</b> <b>intervals,</b> and therefore the overall energy consumption, the DVS schedule must dictate that the processor both enter and leave the power down state during these <b>idle</b> <b>intervals,</b> while carefully considering the time and energy cost of doing so. In this paper, we present a scheduling technique that can effectively reduce the overall energy consumption for hard real-time systems scheduled according to a fixed priority (FP) scheme. Experimental results demonstrate that a processor using our strategy consumes as less as 15 % of the idle energy of a processor employing the conventional strategy. I...|$|R
2500|$|Power saver: reduces {{performance}} by adjusting power settings for energy efficiency; reduces display brightness, enables a shorter display <b>idle</b> timeout <b>interval,</b> and enables a shorter <b>idle</b> timeout <b>interval</b> before allowing {{a system to}} enter sleep mode ...|$|R
40|$|Leakage energy {{consumption}} {{is an increasing}} concern in current and future CMOS technology generations. Procrastination scheduling, where task execution can be delayed to maximize the duration of <b>idle</b> <b>intervals,</b> has been proposed to minimize leakage energy drain. We address dynamic slack reclamation techniques under procrastination scheduling to minimize the static and dynamic {{energy consumption}}. In addition to dynamic task slowdown, we propose dynamic procrastination which seeks to extend <b>idle</b> <b>intervals</b> through slack reclamation. While using the entire slack for either slowdown or procrastination need {{not be the most}} efficient approach, we distribute the slack between slowdown and procrastination to exploit maximum energy savings. Our simulation experiments show that dynamic slowdown results on an average 10 % energy gains over static slowdown. Dynamic procrastination can extend the averag...|$|R
3000|$|... 0 − 1] where i is {{the number}} of {{retransmission}} attempt and is known as a back-off stage. The entire procedure of channel access is repeated. If the CTS is received, the channel is reserved for the particular transmission and the node proceeds with transmission of data packet, followed by ACK from a receiver. The four frames RTS, CTS, DATA, and ACK are separated by Short Inter-Frame Space (SIFS) while ACK frame is followed by DCF Inter-Frame Space (DIFS). In case of IEEE 802.11 g radios, every frame is followed by signal extension, which is <b>idle</b> <b>interval</b> of 6 μs, necessary for proper reception of signal. The nodes other than the transmitter and receiver that correctly receive the RTS or CTS frame set the NAV for remaining period of transmission and freeze their activity on the channel.|$|E
40|$|TCP's {{burstiness}} {{is usually}} regarded as harmful, or at best, inconvenient. Instead, this thesis suggests {{a new perspective}} and examines whether TCP's burstiness is useful for certain applications. It claims that burstiness can be harnessed to insulate traffic from packet reordering caused by route change. We introduce the use of flowlets, a new abstraction for a burst of packets from a particular flow followed by an <b>idle</b> <b>interval.</b> We apply flowlets to the routing of traffic along multiple paths and develop a scheme using flowlet-switching to split traffic across multiple parallel paths. Flowlet switching is an ideal technique for load balancing traffic across multiple paths as it achieves the accuracy of packet-switching and the robustness to packet reordering of flow-switching. This research evaluates the accuracy, simplicity, overhead and robustness to reordering flowlet switching entails. Using a combination of trace analysis and network simulation, we demonstrate the feasibility of implementing flowlet-based switching...|$|E
40|$|Leakage {{power is}} a growing concern in current and future {{microprocessors}}. Functional units of microprocessors are responsible for a major fraction of this power. Therefore, reducing functional unit leakage has received much attention in the recent years. Power gating {{is one of the most}} widely used techniques to minimize leakage energy. Power gating turns off the functional units during the idle periods to reduce the leakage. Therefore, the amount of leakage energy savings is directly proportional to the idle time duration. This paper focuses on increasing the <b>idle</b> <b>interval</b> for the higher SIMD lanes. The applications are profiled dynamically, in a HW/SW co-designed environment, to find the higher SIMD lanes usage pattern. If the higher lanes need to be turned-on for small time periods, the corresponding portion of the code is devectorized to keep the higher lanes off. The devectorized code is executed on the lowest SIMD lane. Our experimental results show average SIMD accelerator energy savings of 12...|$|E
40|$|Energy {{optimization}} is {{a critical}} design concern for embedded systems. Combining DVFS+DPM is considered as one preferable technique to reduce energy consumption. There have been optimal DVFS+DPM algorithms for periodic independent tasks running on uni-processor in the literature. Optimal combination of DVFS and DPM for periodic dependent tasks on multi-core systems is however not yet reported. The challenge of this {{problem is that the}} <b>idle</b> <b>intervals</b> of cores are not easy to model. In this paper, a novel technique is proposed to directly model the <b>idle</b> <b>intervals</b> of individual cores such that both DVFS and DPM can be optimized at the same time. Based on this technique, the energy optimization problem is formulated by means of mixed integrated linear programming. We also present techniques to prune the exploration space of the formulation. Experimental results using real-world benchmarks demonstrate the effectiveness of our approach compared to existing approaches...|$|R
40|$|Networked video sensors need {{to execute}} two {{dependent}} periodic tasks: video encoding and transmission. The de-pendency and periodicity often result in small idle inter-vals of CPU and wireless {{network interface card}} (WNIC). In this paper, we present a sender-buffering approach to ex-ploit such <b>idle</b> <b>intervals</b> for energy saving. Specifically, a video sensor encodes frames in a timely fashion, but buffers encoded frames and transmits them in bursts at longer in-tervals. In doing so, it (1) accumulates short WNIC idle in-tervals into longer ones, during which the WNIC can enter the lower-power sleep mode, and (2) slows down the CPU by avoiding CPU <b>idle</b> <b>intervals,</b> which are resulted from both early completion of frame encoding and waiting for frame transmission. Our experimental {{results show that the}} buffering approach can save 32 - 80 % CPU energy and 35 - 54 % WNIC energy, while increasing the overall end-to-end transmission delay by at most 2 frames. 1...|$|R
40|$|Temporal {{dependence}} {{has been}} identified as an important characteristic in workloads processed by multi-tier architectures, disk drives, and communication networks. In this paper, we discuss how to use the knowledge of temporal dependence in flows to forecast the length of <b>idle</b> <b>intervals</b> in storage systems. We design a new background scheduling policy to determine when and for how long idle times can be used for serving background tasks, without violating pre-defined performance targets of foreground jobs. Our analysis shows that if idle times have low variability, then {{it is not necessary to}} idle wait before starting a background job. Only if idle times are highly variable, then idle waiting is necessary to minimize the impact of background activity on foreground performance. We further show that if there is burstiness in addition to high variability in <b>idle</b> <b>intervals,</b> then it is possible to predict accurately the length of incoming idle times and use that information to serve more background jobs without affecting foreground performance. 1...|$|R
40|$|WLANs {{have become}} {{increasingly}} popular and widely deployed. The MAC protocol {{is one of the}} important technology of the WLAN and affects communication efficiency directly. In this paper, focusing on MAC protocol, we propose a novel protocol that network nodes dynamically optimize their backoff process to achieve high throughput while supporting satisfied QoS. Distributed model MAC protocol has an advantage that no infrastructure such as access point is necessary. On the other hand, total throughput decreases heavily and cannot guarantee QoS under a high traffic load, which needs to be improved. Through theoretical analysis, we find that the average <b>idle</b> <b>interval</b> can represent current network traffic load and can be used together with estimated number of nodes for setting optimal CW. Since necessary indexes can be obtained through direct measurement from channel, our scheme will not increase any added load to networks, which makes our schemes simpler and more effective. Through simulation comparison with conventional method, we show that our scheme can greatly enhance the throughput and the QoS no matter the network is in saturated or non-saturated case, while maintaining good fairness...|$|E
40|$|Asynchronous {{transfer}} mode (ATM) is the technology chosen for implementing the Broadband Integrated Services Digital Network (B-ISDN). The performance of Internet protocols over ATM {{is an extremely}} important research area. As web traffic forms {{a major portion of}} the Internet traffic, we model world wide web (WWW) servers and clients running over an ATM network using the available bit rate (ABR) service. The WWW servers are modeled using a variant of the SPECweb 96 benchmark, while the WWW clients are based on a model proposed in [2]. The traffic generated is typically bursty, having active and idle transmission periods. A timeout occurs after a certain <b>idle</b> <b>interval.</b> During idle periods, the underlying TCP congestion windows remain large until the timer expires. When the application becomes active again, these large windows may be used to send data in a burst. This raises the possibility of large queues at the switches, if the source rates are not controlled by ABR. We study this problem and show that ABR scales well to a large number of bursty TCP sources in the system...|$|E
30|$|The senders A and B {{of the two}} {{flows in}} this {{category}} (and all subsequent categories) are not within the transmission range of each other. Therefore, the RTS frame transmitted by sender A is not successfully decoded by sender B and vice versa. However, the channel is sensed busy during RTS transmission, preventing the other sender from initiating a transmission. This is different from SIS category proposed by Garetto et al. [5] where senders {{are assumed to be}} outside the sensing range and cannot sense the RTS transmitted by sender of the alternate flow. The receivers of both flows are within the transmission range of the alternate senders, i.e., interference interactions Ab and aB are connected. This means that the receivers can successfully decode the RTS frame transmitted by the alternate senders resulting in setting NAV at alternate receiver. Similarly, senders can successfully decode the CTS packet transmitted by the alternate receivers. Therefore, collision can only occur if one sender starts transmission of RTS during the <b>idle</b> <b>interval</b> between RTS and CTS transmission of the alternate flow.|$|E
40|$|While {{the dynamic}} voltage scaling (DVS) {{techniques}} are efficient {{in reducing the}} dynamic energy consumption for the processor, varying voltage alone becomes less effective for the overall power reduction as the leakage power is growing rapidly, i. e., five times per technical generation as predicted. In this paper, we study the problem of reducing both the static and dynamic power consumption {{at the same time}} for the hard real-time system scheduled by the earliest deadline first (EDF) strategy. To balance the dynamic and leakage energy consumption, higher-than-necessary processor speeds may be required when executing real-time tasks, which can result in a large number of <b>idle</b> <b>intervals.</b> To effectively reduce the energy consumption during these <b>idle</b> <b>intervals,</b> we propose a technique that can effectively merge these scattered intervals into larger ones without causing any deadline miss. Simulation studies demonstrate the effectiveness of our approach. Specifically, our experiments show that the proposed technique can lead up to more than 80 % idle energy savings than that by the previous ones...|$|R
40|$|Optical Burst Switching(OBS) is a {{promising}} paradigm for the next-generation Internet. In OBS, a key {{problem is to}} schedule bursts on wavelength channels whose bandwidth may become fragmented with the so-called void (or <b>idle)</b> <b>intervals</b> with both fast and bandwidth efficient algorithms so as to reduce burst loss. To date, only two scheduling algorithms, called Horizon and LAUC-VF, have been proposed, which trade off bandwidth efficiency for fast running time and vice versa, respectively...|$|R
40|$|URL : [URL] audienceIn {{this paper}} we present {{negative}} results for global scheduling of implicit deadlines periodic systems under EDF. We reconsider {{the definition of}} the <b>idle</b> <b>intervals</b> from the uniprocessor case to the multiprocessor case. Unfortunately, this new definition does not provide feasibility results for these systems. We prove that the periodicity of an EDF-feasible schedule does not hold from the uniprocessor case to the multiprocessor case. A discussion for calculating this instant is provided...|$|R
40|$|This thesis {{deals with}} shop {{scheduling}} problems. After introducing the basic denitions and notation, {{we continue with}} a short survey of known complexity results for open shop, ow shop and job shop scheduling problems. Then we focus more on open shop and especially on a subclass of open shop with at most two non-zero length operations per job denoted Om|mj = 2 |Cmax in standard notation. Besides some minor lemmas and observations, four major new results concerning this subclass are presented. The rst one is an observation, that any schedule in this class can be transformed in polynomial time to a schedule with same length and only one <b>idle</b> <b>interval</b> on each machine. The second one is a proof of a well known conjecture about so-called dense schedules for the subclass. The third one is modication of a known greedy algorithm to obtain schedules no longer then 3 / 2 of the optimal length, {{and the last one}} is a modication of a known polynomial approximation scheme which guarantees a better performance for instances from the above described subclass...|$|E
40|$|TCP's {{burstiness}} {{is usually}} regarded as harmful, or at best, inconvenient. Instead, this thesis suggests {{a new perspective}} and examines whether TCP's burstiness is useful for certain applications. It claims that burstiness can be harnessed to insulate traffic from packet reordering caused by route change. We introduce the use of flowlets, a new abstraction for a burst of packets from a particular flow followed by an <b>idle</b> <b>interval.</b> We apply flowlets to the routing of traffic along multiple paths and develop a scheme using flowlet-switching to split traffic across multiple parallel paths. Flowlet switching is an ideal technique for load balancing traffic across multiple paths as it achieves the accuracy of packet-switching and the robustness to packet reordering of flow-switching. This research evaluates the accuracy, simplicity, overhead and robustness to reordering flowlet switching entails. Using a combination of trace analysis and network simulation, we demonstrate the feasibility of implementing flowlet-based switching. by Shantanu K. Sinha. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, February 2005. Includes bibliographical references (p. 63 - 67) ...|$|E
40|$|Abstract — TCP’s {{burstiness}} {{is usually}} regarded as harmful, or at best, inconvenient. This paper adopts {{a new perspective}} and examines whether TCP’s burstiness is useful for certain applications. It shows that the burstiness can be harnessed to make TCP more robust to packet reordering caused by route change. We define a flowlet as a burst of packets from the same flow followed by an <b>idle</b> <b>interval.</b> We develop a scheme that uses flowlets to split traffic across multiple parallel paths. We show that flowlet switching is an ideal technique for load balancing traffic across multiple paths as it has the accuracy of packet switching, combined with the robustness of flow switching to packet reordering. The accuracy, simplicity, and low-overhead of flowlet switching makes it a strong candidate for replacing the current hash-based schemes used in routers for splitting traffic across multiple links. In particular, when the desired split ratios vary over time, flowlet switching accurately splits traffic across multiple paths whereas current hash-based schemes are highly inaccurate. Hence flowlet switching provides a key component for research {{in the areas of}} realtime adaptive multipath routing and fine-grained traffic engineering. I...|$|E
40|$|Processor-level dynamic thermal {{management}} techniques have long targeted worst-case thermal margins. We examine the thermalperformance trade-offs in average-case, preventive {{thermal management}} by actively degrading application performance to achieve long-term thermal control. We propose Dimetrodon, {{the use of}} idle cycle injection, a flexible, per-thread technique, as a preventive thermal management mechanism and demonstrate its efficiency compared to hardware techniques in a commodity operating system on real hardware under throughput and latency-sensitive real-world workloads. Compared to hardware techniques that also lack flexibility, Dimetrodon achieves favorable trade-offs for temperature reductions up to 30 % due to rapid heat dissipation during short <b>idle</b> <b>intervals...</b>|$|R
40|$|As {{multimedia}} {{applications are}} used increasingly in many embedded systems, power efficient {{design for the}} applications becomes more important than ever. This paper proposes a simple dynamic voltage scheduling technique, which suits the multimedia applications well. The proposed technique fully utilizes the <b>idle</b> <b>intervals</b> with buffers in a variable speed processor. The main theme {{of this paper is}} to determine the minimum buffer size to achieve the maximum energy saving in three cases: single-task, multiple subtasks, and multi-task. Experimental results show that the proposed technique is expected to obtain significant power reduction for several real-world multimedia applications. 1...|$|R
40|$|Abstract—We {{present a}} robust {{framework}} that aims at harvesting future <b>idle</b> <b>intervals</b> for power savings within strict constraints: first, {{it is imperative}} to contain the delays in service of IO requests that occur during power savings since the time to bring up the disk is not negligible and second, ensure that the power saving mechanism is triggered few times only, such that the disk wear out due to powering up and down does not compromise its lifetime. Extensive experimentation on a set of enterprise storage traces illustrates frameworks effectiveness. Keywords- disk drive wear out; power saving; performance guarantee; histogram; idleness I...|$|R
40|$|A primary {{criterion}} of {{wireless sensor network}} is energy efficiency. Focused onthe energy problem of target tracking in wireless sensor networks, this paper proposes acluster-based dynamic energy management mechanism. Target tracking problem isformulated by the multi-sensor detection model as well as energy consumption model. Adistributed adaptive clustering approach is investigated to form a reasonable routingframework which has uniform cluster head distribution. DijkstraÃ¢Â€Â™s algorithm is utilized toobtain optimal intra-cluster routing. Target position is predicted by particle filter. Thepredicted target position is adopted to estimate the <b>idle</b> <b>interval</b> of sensor nodes. Hence,dynamic awakening approach is exploited to prolong sleep time of sensor nodes so that theoperation energy consumption of wireless sensor network can be reduced. The sensornodes around the target wake up on time and act as sensing candidates. With the candidatesensor nodes and predicted target position, the optimal sensor node selection is considered. Binary particle swarm optimization is proposed to minimize the total energy consumptionduring collaborative sensing and data reporting. Experimental results verify that theproposed clustering approach establishes a low-energy communication structure while theenergy efficiency of wireless sensor networks is enhanced by cluster-based dynamic energymanagement...|$|E
40|$|Various {{activities}} that intend to enhance performance, reliability, {{and availability of}} storage systems are scheduled with low priority and served during idle times. Under such conditions, idleness becomes a valuable “resource ” {{that needs to be}} efficiently managed. A common approach in system design is to be nonwork conserving by “idle waiting”, that is, delay the scheduling of background jobs to avoid slowing down upcoming foreground tasks. In this article, we complement “idle waiting ” with the “estimation ” of background work to be served in every <b>idle</b> <b>interval</b> to effectively manage the trade-off between the performance of foreground and background tasks. As a result, the storage system is better utilized without compromising foreground performance. Our analysis shows that if idle times have low variability, then idle waiting is not necessary. Only if idle times are highly variable does idle waiting become necessary to minimize the impact of background activity on foreground performance. We further show that if there is burstiness in idle intervals, then it is possible to predict accurately the length of incoming idle intervals and use this information to serve more background jobs without affecting foreground performance...|$|E
40|$|A {{multitude}} of different hard disk power management algorithms exists—applied to real systems or {{proposed in the}} literature. Energy savings can only be achieved if the hard disk is idle for a minimum period of time. These algorithms try to predict the length of each <b>idle</b> <b>interval</b> at runtime and decide whether the disk should be switched to a lowpower mode or not. In this paper, we claim {{that there is no}} general-purpose policy that maximizes energy savings for every workload and present system services that dynamically switch between different, specialized power management algorithms. The operating system automatically learns which policy performs best for a specific workload. Therefore, hard disk accesses are monitored and fed into a simulator that estimates the drive’s energy consumption under different lowpower algorithms. In order to recognize workloads at runtime, the system additionally monitors a set of I/O-related parameters. Using techniques from machine learning, a set of rules can be derived automatically which enable a power management daemon to identify the current workload and its optimum low-power algorithm on-line. Furthermore, the user can train the system to consider application-specific performance requirements. A prototype implementation for Linux is presented and evaluated through experiments with two different hard disks. 1...|$|E
40|$|The max / / C idle no F - {{problem is}} solved by a {{branch and bound}} algorithm, or a mixed integer {{programming}} solver. This problem {{is known to be}} NP-hard. The noidle flow-shop configuration, where machines work continuously without <b>idle</b> <b>intervals</b> is an interesting manufacturing environment in many industries. The idle characteristic is a very strong constraint and it affects seriously the value of makespan (max C). Under some circumstances we can authorise some idle periods. But, we should choose the best location that maximises the degradation of the max C and the order on which an idle will be inserted...|$|R
40|$|Power {{efficient}} {{design of}} real-time embedded systems based on programmable processors {{becomes more important}} as system functionality is increasingly realized through software. This paper presents a power optimization method for real-time embedded applications on a variable speed processor. The method combines off-line and on-line components. The off-line component determines the lowest possible maximum processor speed while guaranteeing deadlines of all tasks. The on-line component dynamically varies the processor speed or bring a processor into a power-down mode according {{to the status of}} task set in order to exploit execution time variations and <b>idle</b> <b>intervals.</b> Experimental results show that the proposed method obtains a significant power reduction across several kinds of applications. ...|$|R
40|$|International audienceThe three stage no-idle flow-shop configuration, where {{machines}} work continuously without <b>idle</b> <b>intervals,</b> is {{an interesting}} manufacturing environment in many industries. Few researches have investigated this type of systems. The idle characteristic {{is a very strong}} constraint and it affects seriously the value of makespan (C max) criterion. We treat here the scheduling problem of three stage permutation flow-shop configuration with no-idle machines in order to minimise the makespan Full-size image (< 1 K) An easily implementing heuristic is proposed to solve this problem with Full-size image (< 1 K) complexity. It finds optimal solutions for several cases. A computational study shows the result quality...|$|R
40|$|Abstract: A primary {{criterion}} of {{wireless sensor network}} is energy efficiency. Focused on the energy problem of target tracking in wireless sensor networks, this paper proposes a cluster-based dynamic energy management mechanism. Target tracking problem is formulated by the multi-sensor detection model as well as energy consumption model. A distributed adaptive clustering approach is investigated to form a reasonable routing framework which has uniform cluster head distribution. Dijkstra’s algorithm is utilized to obtain optimal intra-cluster routing. Target position is predicted by particle filter. The predicted target position is adopted to estimate the <b>idle</b> <b>interval</b> of sensor nodes. Hence, dynamic awakening approach is exploited to prolong sleep time of sensor nodes so that the operation energy consumption of wireless sensor network can be reduced. The sensor nodes around the target wake up on time and act as sensing candidates. With the candidate sensor nodes and predicted target position, the optimal sensor node selection is considered. Binary particle swarm optimization is proposed to minimize the total energy consumption during collaborative sensing and data reporting. Experimental results verify that the proposed clustering approach establishes a low-energy communication structure while the energy efficiency of wireless sensor networks is enhanced by cluster-based dynamic energy management...|$|E
30|$|The {{transmission}} opportunity {{loss ratio}} is {{the ratio of}} the interval that the SU does not transmit and for the interval in which the PU is idle within the measurement interval when the sensor node cannot detect the idle state of PU. In (31), the numerator is the probability where PU is idle when SU do not use the vacant time and the denominator is the probability where PU is idle in the measurement window. First, we calculate the conditional probabilities and sum of them that the PU is idle for each sensing results (D 0, D 1) in the <b>idle</b> <b>interval</b> of SU (SUoff) to estimate the probability of the interval in which the SU does not transmit despite the idle PU as shown in (32). In order to estimate the probability of the interval in which the PU is idle, we sum up the conditional probabilities of the PUs idle (H 0) for each of the sensing results (D 0, D 1) in intervals in which the SU operates and IA-based sensing is operated and in which the SU is idle and performs non-IA-based sensing. The estimate for the probability in the measurement window in which the PU is idle is expressed in the denominator of (31) as the sum of (32) and (33).|$|E
40|$|One of {{the biggest}} {{challenges}} in high-performance computing is to reduce the power and energy consumption. Research in energy efficiency has focused mainly on energy consumption at the node level. Less attention has been given to the interconnect, which is becoming a significant source of energy-inefficiency. Although supercomputers undoubtedly require a high-performance interconnect, previous work has shown that network links have low average utilization. It is therefore possible to save energy using low-power modes, but link wake-up latencies must not lead to a loss in performance. This paper proposes the Self-tuned Pattern Prediction System (SPPS), a self-tuned algorithm for energy proportionality, which reduces interconnect energy consumption without needing any application-specific configuration parameters. The algorithm uses prediction to discover repetitive patterns in the application's communication, and it is implemented inside the MPI library, so that existing MPI programs {{do not need to be}} modified. We build on previous work, which showed how the application structure can be successfully exploited to predict the communication idle intervals. The previous work, however, required the manual adjustment of a critical <b>idle</b> <b>interval</b> length, whose value depends on the application and has a major effect on energy savings. The new technique automatically discovers the optimal value of this parameter, resulting in a self-tuned algorithm that obtains large interconnect energy savings at little performance cost. We study the effectiveness of our approach using ten real applications and benchmarks. Our simulations show average energy savings in the network links of up to 21 %. Moreover, the link wake-up latencies and additional computation times have a negligible effect on performance, with an average penalty less than 1 %. Peer ReviewedPostprint (published version...|$|E
40|$|Abstract — The {{relatively}} {{high power consumption}} of wireless network interfaces represents an important detriment in multimedia streaming for mobile devices. The IEEE 802. 11 built-in power saving mode was designed for transfers of different nature and {{is not able to}} take advantage of the short <b>idle</b> <b>intervals</b> and continuous, periodic transmissions inherent in multimedia streaming. We propose an annotation based approach to wireless network power management that analyzes the variations in data transfer bandwidth during playback and uses the results to buffer data into larger burst transmissions with longer idle periods when the network card is transitioned into a lower power, sleep mode. Annotations allow for energy savings of up to 75 % for the network interface, with practically no quality degradation or packet loss, only a small delay due to the buffer. I...|$|R
40|$|Power-efficient {{design of}} {{multimedia}} applications {{becomes more important}} as they are used in-creasingly in many embedded systems. We propose a simple dynamic voltage scheduling (DVS) technique, which suits multimedia applications well and, in case of soft real-time applications, allows all <b>idle</b> <b>intervals</b> of the processor to be fully exploited by using buffers. Our main theme {{is to determine the}} minimum buffer size to maximize energy saving in three cases: (i) single task, (ii) multiple subtask, and (iii) multitask. We also present a technique of adjusting task deadlines for further reducing energy consumption in the multiple-subtask and multitask cases. Unlike other DVS techniques using buffers, we guarantee to meet the real-time latency constraint. Experimen-tal results show that the proposed technique does indeed achieve significant power reduction in real-world multimedia applications...|$|R
40|$|The {{relatively}} {{high power consumption}} of wireless network interfaces represents an important detriment in multimedia streaming for mobile devices. The IEEE 802. 11 built-in power saving mode was designed for transfers of different nature and {{is not able to}} take advantage of the short <b>idle</b> <b>intervals</b> and continuous, periodic transmissions inherent in multimedia streaming. We propose an annotation based approach to wireless network power management that analyzes the variations in data transfer bandwidth during playback and uses the results to buffer transmissions into larger burst transmissions with longer idle periods when the network card is transitioned into a lower power, sleep mode. Annotations allow for energy savings of up to 75 % for the network interface, with practically no quality degradation or packet loss, only a small delay due to the buffer. ...|$|R
