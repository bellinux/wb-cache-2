824|0|Public
2500|$|An {{experienced}} {{user can}} create realistic and accurate families ranging from furniture to lighting fixtures, {{as well as}} import existing models from other programs. Revit families can be created as parametric models with dimensions and properties. This lets users modify a given component by changing predefined parameters such as height, width or number {{in the case of}} an array. In this way a family defines a geometry which is controlled by parameters, each combination of parameters can be saved as a type, and each occurrence (instance in Revit) of a type can also contain further variations. [...] For example, a swing door may be a Family. It may have types describing different sizes, and the actual building model will have instances of those types placed in walls where <b>instance-based</b> parameters could specify the door hardware uniquely for each occurrence of the door.|$|E
50|$|It {{is called}} <b>instance-based</b> because it {{constructs}} hypotheses {{directly from the}} training instances themselves.This means that the hypothesis complexity can grow with the data: in the worst case, a hypothesis {{is a list of}} n training items and the computational complexity of classifying a single new instance is O(n). One advantage that <b>instance-based</b> learning has over other methods of machine learning is its ability to adapt its model to previously unseen data. <b>Instance-based</b> learners may simply store a new instance or throw an old instance away.|$|E
5000|$|First class sprites (in {{other words}} prototype-oriented <b>instance-based</b> classless programming), ...|$|E
5000|$|In <b>Instance-based</b> learning, regularization can be {{achieved}} varying the mixture of prototypes and exemplars.|$|E
5000|$|David Plaisted University of North Carolina at Chapel Hill. Complexity results, {{contributions}} to rewriting and completion, <b>instance-based</b> theorem proving.|$|E
50|$|Netlists can be {{physical}} or logical, <b>instance-based</b> or net-based, and flat or hierarchical. The latter {{can be either}} folded or unfolded.|$|E
50|$|In {{computer}} science, cloning {{refers to}} the making of an exact copy of an object, frequently under the paradigm of <b>instance-based</b> programming, or object-oriented programming (OOP).|$|E
50|$|In machine {{learning}}, <b>instance-based</b> learning (sometimes called memory-based learning) is {{a family}} of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.|$|E
5000|$|... k-NN {{is a type}} of <b>instance-based</b> learning, or lazy learning, {{where the}} {{function}} is only approximated locally and all computation is deferred until classification. The k-NN algorithm is among the simplest of all machine learning algorithms.|$|E
50|$|Examples of <b>instance-based</b> {{learning}} algorithm are the k-nearest neighbor algorithm, kernel {{machines and}} RBF networks. These store (a subset of) their training set; when predicting a value/class {{for a new}} instance, they compute distances or similarities between this instance and the training instances to make a decision.|$|E
50|$|Prototype-based {{programming}} is {{a style of}} object-oriented programming in which behaviour reuse (known as inheritance) is performed via a process of reusing existing objects via delegation that serve as prototypes. This model can also be known as prototypal, prototype-oriented, classless, or <b>instance-based</b> programming. Delegation is the language feature that supports prototype-based programming.|$|E
50|$|Plaisted's {{research}} interests include term rewriting systems, automated theorem proving, logic programming, and algorithms. His research accomplishments in theorem proving include work on the recursive path ordering, the associative path ordering, abstraction, the simplified and modified problem reduction formats, ground reducibility,nonstandard clause form translations, rigid E-unification, Knuth-Bendix completion, replacement rules in theorem proving, <b>instance-based</b> theorem proving strategies, and semantics in theorem proving.|$|E
50|$|Instance based netlists usually {{provide a}} list of the {{instances}} used in a design.Along with each instance, either an ordered list of net names is provided, or {{a list of}} pairs provided, of an instance port name, along with the net name to which that port is connected.In this kind of description, the list of nets can be gathered from the connection lists, and there is no place to associate particular attributes with the nets themselves.SPICE is an example of <b>instance-based</b> netlists.|$|E
5000|$|Kernel {{methods can}} be thought of as <b>instance-based</b> learners: rather than {{learning}} some fixed set of parameters corresponding to the features of their inputs, they instead [...] "remember" [...] the -th training example [...] and learn for it a corresponding weight [...] Prediction for unlabeled inputs, i.e., those not in the training set, is treated by the application of a similarity function , called a kernel, between the unlabeled input [...] and each of the training inputs [...] For instance, a kernelized binary classifier typically computes a weighted sum of similarities ...|$|E
5000|$|There are {{two major}} flavors of {{algorithms}} for Multiple Instance Learning: <b>instance-based</b> and metadata-based,or embedding-based algorithms. The term [...] "instance-based" [...] denotes that the algorithm attempts to find a set of representative instances based on an MI assumption and classify future bags from these representatives. By contrast, metadata-based algorithms make no assumptions {{about the relationship between}} instances and bag labels, and instead try to extract instance-independent information (or metadata) about the bags in order to learn the concept. For a survey of some of the modern MI algorithms see Foulds and Frank ...|$|E
50|$|Godfried T. Toussaint is a Professor of Computer Science and the Head of the Computer Science Program at New York University Abu Dhabi (NYUAD) in Abu Dhabi, United Arab Emirates. He does {{research}} on {{various aspects of}} computational geometry, discrete geometry, and their applications: pattern recognition (k-nearest neighbor algorithm, cluster analysis), motion planning, visualization (computer graphics), knot theory (stuck unknot problem), linkage (mechanical) reconfiguration, the art gallery problem, polygon triangulation, the largest empty circle problem, unimodality (unimodal function), and others. Other interests include meander (art), compass and straightedge constructions, <b>instance-based</b> learning, music information retrieval, and computational music theory.|$|E
5000|$|The <b>Instance-Based</b> Learning Theory (IBLT) is {{a theory}} of how humans make {{decisions}} in dynamic tasks developed by Cleotilde Gonzalez, Christian Lebiere, and Javier Lerch. The theory has been extended to two different paradigms of dynamic tasks, called sampling and repeated-choice, by Cleotilde Gonzalez and Varun Dutt. Gonzalez and Dutt [...] have shown that in these dynamic tasks, IBLT provides the best explanation of human behavior and performs better than many other competing models and approaches. According to IBLT, individuals rely on their accumulated experience to make decisions by retrieving past solutions to similar situations stored in memory. Thus, decision accuracy can only improve gradually and through interaction with similar situations.|$|E
50|$|An {{experienced}} {{user can}} create realistic and accurate families ranging from furniture to lighting fixtures, {{as well as}} import existing models from other programs. Revit families can be created as parametric models with dimensions and properties. This lets users modify a given component by changing predefined parameters such as height, width or number {{in the case of}} an array. In this way a family defines a geometry which is controlled by parameters, each combination of parameters can be saved as a type, and each occurrence (instance in Revit) of a type can also contain further variations. For example, a swing door may be a Family. It may have types describing different sizes, and the actual building model will have instances of those types placed in walls where <b>instance-based</b> parameters could specify the door hardware uniquely for each occurrence of the door.|$|E
5000|$|Standard {{assumption}} {{might be}} viewed as too strict, and therefore in the recent years, researchers tried to relax that position, which gave rise to other more loose assumptions. Reason {{for this is the}} belief that standard MI assumption is appropriate for the Musk dataset, but since MLI can be applied to numerous other problems, some different assumptions could probably be more appropriate. Guided by that idea, Weidmann [...] formulated a hierarchy of generalized <b>instance-based</b> assumptions for MIL. It consists of the standard MI assumption and three types of generalized MI assumptions, each more general than the last, , with the count-based assumption being the most general and the standard assumption being the least general. One would expect an algorithm which performs well under one of these assumptions to perform at least as well under the less general assumptions.|$|E
5000|$|The {{ultimate}} goal of the PRAC system is to make knowledge about everyday activities from websites like wikihow.com available for service robots, such that they can autonomously acquire new high-level skills by browsing the Web. PRAC addresses the problem that natural language is inherently vague and unspecific. To this end, PRAC maintains probabilistic first-order knowledge bases over semantic networks represented in Markov logic networks. As opposed to other semantic learning initiatives like NELL or IBM's Watson, PRAC does not aim at answering questions in natural language, but to disambiguate and infer information pieces that are missing in natural-language instructions, such {{that they can be}} executed by a robot. [...] "This problem formulation is substantially different to the problem of text understanding for question answering or machine translation. In those reasoning tasks, the vagueness and ambiguity of natural-language expressions can often be kept and translated into other languages. In contrast, robotic agents have to infer missing information pieces and disambiguate the meaning of the instruction in order to perform the instruction successfully." [...] In addition to probabilistic relational models, PRAC uses the prinicples of analogical reasoning and <b>instance-based</b> learning to infer completions of roles in semantic networks.|$|E
40|$|The <b>instance-based</b> {{data model}} (IBDM) was {{recently}} proposed by Parsons and Wand [2000]. One {{of the key}} contributions of this model is class independence. The IBDM separates the storage of information about instances from the organization of a schema using classes. This thesis transforms the IBDM from concept to real world implementation. It develops and analyzes possible base data structures for implementing an <b>instance-based</b> DBMS, and creates a flexible query language iQL (<b>instance-based</b> query language) for the data model. Two proofs of concept DBMSs are implemented (one for each of two base data structures) {{in order to test}} and verify the analytical results of the research. Also, the <b>instance-based</b> database model is compared with the relational database model to obtain a clear understanding of the advantages provided by the <b>instance-based</b> database model...|$|E
40|$|Objective: To align pharmacologic {{classes in}} ATC and MeSH with lexical and <b>instance-based</b> techniques. Methods: Lexical alignment: we map {{the names of}} ATC classes to MeSH through the UMLS, {{leveraging}} normalization and additional synonymy. <b>Instance-based</b> alignment: we associate ATC and MeSH classes through the drugs they share, using the Jaccard coefficient to measure class-class similarity. We use a metric to distinguish between equivalence and inclusion mappings. Results: We found 221 lexical mappings, as well as 343 <b>instance-based</b> mappings, with a limited overlap (61). From the 343 <b>instance-based</b> mappings we classify 113 as equivalence mappings and 230 as inclusion mappings. A limited failure analysis is presented. Conclusion: Our <b>instance-based</b> approach to aligning pharmacologic classes has the prospect of effectively supporting {{the creation of a}} mapping of pharmacologic classes between ATC and MeSH. This exploratory investigation needs to be evaluated in order to adapt the thresholds for similarity...|$|E
40|$|AbstractA {{method of}} <b>instance-based</b> {{learning}} is introduced which {{makes use of}} possibility theory and fuzzy sets. Particularly, a possibilistic version of the similarity-guided extrapolation principle underlying the <b>instance-based</b> learning paradigm is proposed. This version is compared to the commonly used probabilistic approach from a methodological point of view. Moreover, aspects of knowledge representation such as the modeling of uncertainty are discussed. Taking the possibilistic extrapolation principle {{as a point of}} departure, an <b>instance-based</b> learning procedure is outlined which includes the handling of incomplete information, methods for reducing storage requirements and the adaptation of the influence of stored cases according to their typicality. First theoretical and experimental results showing the efficiency of possibilistic <b>instance-based</b> learning are presented as well...|$|E
40|$|Abstractâ€”This paper tackles {{the stroke}} {{recovery}} problem, {{which is a}} typical ill-posed reverse problem, by an <b>instance-based</b> method. The basic idea of the <b>instance-based</b> stroke re-covery is {{to refer to the}} drawing order of a similar instance. The <b>instance-based</b> method has a strong merit that it can deal with multi-stroke characters and other complex characters without any special consideration. However, it requires a sufficient numbers of instances to cover those various characters. As an initial trial of the <b>instance-based</b> stroke recovery method, this paper describes the principle of the method and then provides several experimental results. The experimental results indicate the potential of the proposed method on recovering the drawing order of complex characters, as expected. Keywords-handwriting; stroke recovery; instance base; time series; big data; I...|$|E
40|$|Under {{consideration}} for other conferences (specify) ? INLG 02 In spoken language {{applications such as}} conversation systems where not only the speech waveforms but also {{the content of the}} speech (the text) need to be generated automatically, a Concept-to-Speech (CTS) system is needed. In this paper, we address several issues on designing a speech corpus to facilitate an <b>instance-based</b> integrated CTS platform. Both the <b>instance-based</b> CTS generation approach and the corpus design process are new topics and they have not been addressed systematically in previous researches. Designing a Speech Corpus for <b>Instance-based</b> Spoken Language Generation Paper-ID: P 0293 In spoken language applications such as conversation systems where not only the speech waveforms but also the content of the speech (the text) need to be generated automatically, a Concept-to-Speech (CTS) system is needed. In this paper, we address several issues on designing a speech corpus to facilitate an <b>instance-based</b> integrated CTS platform. Both the <b>instance-based</b> CTS generation approach and the corpus design process are new topics and they have not been addressed systematically in previous researches. ...|$|E
40|$|Current {{databases}} {{are typically}} designed for particular predetermined purposes. However, users {{may need to}} use the same dataset for multiple and changing purposes, some of which may not be known when the database is designed. To handle multiple purposes in traditional data models, it is often necessary to construct multiple databases or views. When new information needs arise, additional databases or views may need to be constructed. [...] The <b>instance-based</b> data model (IBDM) supports instances independent of any classes to which those instances might be assigned. The model adopts a two-layer approach to data organization (instance layer and class layer), so that an instance may belong to more than one class or, alternatively, none of classes defined in a database schema. The model makes it possible to construct multiple and flexible schemas for a dataset to support multiple and changing needs of users. However, previous research on the <b>instance-based</b> model does not address a number of issues related to the strengths of separating instance and class layers in the IBDM in fulfilling the needs of particular applications, including supporting database administration issues such as providing more flexible security policies. [...] In this thesis, we propose theoretical and practical enhancements to the <b>instance-based</b> model. First, we extend the semantics and implementation methods of data expressed in the <b>instance-based</b> model. The semantic extension of components of the <b>instance-based</b> model clarifies the definition of the model and the implementation of the components simplifies applications to real database systems. Second, we provide a theoretical comparison and an empirical simulation to show that the <b>instance-based</b> model is more efficient than the relational model on some typical queries. Third, we propose a security model to address security issues in multilevel security applications using the <b>instance-based</b> approach. To ensure the model's security, we also provide operating methods and rules for the proposed model. Finally, we evaluate the proposed model and prove that the model is secure. By applying the <b>instance-based</b> model to the multilevel security area, the research forms the foundation for using the <b>instance-based</b> model to construct multiple schemas and to support multiple applications...|$|E
40|$|Thesis (Ph. D.) [...] Memorial University of Newfoundland, 2011. Computer ScienceBibliography: leaves 157 - 163. Current {{databases}} {{are typically}} designed for particular predetermined purposes. However, users {{may need to}} use the same dataset for multiple and changing purposes, some of which may not be known when the database is designed. To handle multiple purposes in traditional data models, it is often necessary to construct multiple databases or views. When new information needs arise, additional databases or views may need to be constructed. [...] The <b>instance-based</b> data model (IBDM) supports instances independent of any classes to which those instances might be assigned. The model adopts a two-layer approach to data organization (instance layer and class layer), so that an instance may belong to more than one class or, alternatively, none of classes defined in a database schema. The model makes it possible to construct multiple and flexible schemas for a dataset to support multiple and changing needs of users. However, previous research on the <b>instance-based</b> model does not address a number of issues related to the strengths of separating instance and class layers in the IBDM in fulfilling the needs of particular applications, including supporting database administration issues such as providing more flexible security policies. [...] In this thesis, we propose theoretical and practical enhancements to the <b>instance-based</b> model. First, we extend the semantics and implementation methods of data expressed in the <b>instance-based</b> model. The semantic extension of components of the <b>instance-based</b> model clarifies the definition of the model and the implementation of the components simplifies applications to real database systems. Second, we provide a theoretical comparison and an empirical simulation to show that the <b>instance-based</b> model is more efficient than the relational model on some typical queries. Third, we propose a security model to address security issues in multilevel security applications using the <b>instance-based</b> approach. To ensure the model's security, we also provide operating methods and rules for the proposed model. Finally, we evaluate the proposed model and prove that the model is secure. By applying the <b>instance-based</b> model to the multilevel security area, the research forms the foundation for using the <b>instance-based</b> model to construct multiple schemas and to support multiple applications...|$|E
40|$|Semantic Query Optimization has {{traditionally}} relied upon scheme-based integrity constraints that are valid for all instances of a database. <b>Instance-based</b> constraints, which are only valid for certain states of a database, contain {{more information than}} scheme-based constraints because they are specific to the current contents of the database. This makes <b>instance-based</b> constraints more useful to semantic query optimization. However, <b>instance-based</b> constraints are highly sensitive to any changes made to the database and must therefore be updated and validated {{before they can be}} applied. A Metadata View Graph (MVG) is a metadatabase that stores <b>instance-based</b> constraints, along with statistical and structural metadata, for logical views of the database. Constraints at this level are even more useful to semantic query optimization because they are specifically tailored to the intermediate results of a query. This paper reviews existing methods for constraint discovery, describes how cons [...] ...|$|E
40|$|In recent years, ranking {{approaches}} to Natural Language Generation {{have become increasingly}} popular. They abandon the idea of generation as a deterministic decisionmaking process in favour of approaches that combine overgeneration with ranking at some stage in processing. In this thesis, we investigate the use of <b>instance-based</b> ranking methods for surface realization in Natural Language Generation. Our approach to <b>instance-based</b> Natural Language Generation employs two basic components: a rule system that generates a number of realization candidates from a meaning representation and an <b>instance-based</b> ranker that scores the candidates according to their similarity to examples taken from a training corpus. The <b>instance-based</b> ranker uses information retrieval methods to rank output candidates. Our approach is corpus-based in that it uses a treebank (a subset of the Penn Treebank II containing management succession texts) in combination with manual semantic markup to automatically produce a generation grammar. Furthermore, the corpu...|$|E
40|$|Abstract. This paper {{presents}} an inductive learning system called the Genetic <b>Instance-Based</b> Learning (GIBL) system. This system combines <b>instance-based</b> learning approaches with evolutionary computation {{in order to}} achieve high accuracy in the presence of irrelevant or redundant attributes. Evolutionary computation is used to find a set of attribute weights that yields a high estimate of classification accuracy. Results of experiments on 16 data sets are shown, and are compared with a non-weighted version of the <b>instance-based</b> learning system. The results indicate that the generalization accuracy of GIBL is somewhat higher than that of the non-weighted system on regular data, and is significantly higher on data with irrelevant or redundant attributes. 1...|$|E
40|$|A common {{practice}} in cognitive modeling is to develop new models specific to each particular task. We question this approach and draw on an existing theory, <b>instance-based</b> learning theory (IBLT), to explain learning behavior in three different choice tasks. The same <b>instance-based</b> learning model generalizes accurately to choices in a repeated binary choice task, in a probability learning task, and in a repeated binary choice task within a changing environment. We assert that, although the three tasks are different, the source of learning is equivalent and therefore, the cognitive process elicited should be captured by one single model. This evidence supports previous findings that <b>instance-based</b> learning is a robust learning process that is triggered {{in a wide range}} of tasks from the simple repeated choice tasks to the most dynamic decision making tasks. Copyright # 2010 John Wiley & Sons, Ltd. key words <b>instance-based</b> learning; repeated choice; decisions from experience; model comparison; probability learning; model generalizatio...|$|E
40|$|A {{method of}} <b>instance-based</b> {{learning}} is introduced which {{makes use of}} possibility theory and fuzzy sets. Particularly, a possibilistic version of the similarity-guided extrapolation principle underlying the instancebased learning paradigm is proposed. This version is compared to the commonly used probabilistic approach from a methodological point of view. Moreover, aspects of knowledge representation such as the modeling of uncertainty are discussed. Taking the possibilistic extrapolation principle {{as a point of}} departure, an <b>instance-based</b> learning procedure is outlined which includes the handling of incomplete information, methods for reducing storage requirements and the adaptation of the influence of stored cases according to their typicality. First theoretical and experimental results showing the e#ciency of possibilistic <b>instance-based</b> learning are presented as well...|$|E
40|$|Abstract. In {{this paper}} {{we aim to}} show that <b>instance-based</b> {{classification}} can replace the classifier component of a rule learner and of maximum-entropy modeling, thereby improving the generalization accuracy of both algorithms. We describe hybrid algorithms that combine rule learning models and maximum-entropy modeling with <b>instance-based</b> classification. Experimental results show that both hybrids are able to outperform the parent algorithm. We analyze and compare the overlap in errors and the statistical bias and variance of the hybrids, their parent algorithms, and a plain <b>instance-based</b> learner. We observe that the successful hybrid algorithms have a lower statistical bias component in the error than their parent algorithms; the fewer errors they make are also less systematic. ...|$|E
40|$|Abstract. Ontology {{matching}} is {{a promising}} step towards {{the solution to}} the interoperability problem of the Semantic Web. <b>Instance-based</b> methods have the advantage of focusing on the most active parts of the ontologies and reflect concept semantics as they are actually being used. Previous <b>instance-based</b> mapping techniques were only applicable to cases where a substantial set of instances shared by both ontologies. In this paper, we propose to use a lexical search engine to map instances from different ontologies. By exchanging concept classification information between these mapped instances, an artificial set of common instances is built, on which existing <b>instance-based</b> methods can apply. Our experiment results demonstrate the effectiveness and applicability of this method in broad thesaurus mapping context. ...|$|E
40|$|This {{paper is}} a {{practical}} guide to the application of <b>instance-based</b> machine learning techniques to the solution of a financial problem. A broad class of <b>instance-based</b> families is considered for classification using the WEKA software package. The problem selected for analysis is a common one in financial and econometric work: the use of publicly available economic data to forecast future changes in a stock market index. This paper examines various stages {{in the analysis of}} this problem including: identification of the problem, considerations in obtaining and preprocessing data, model and parameter selection, and interpretation of results. Finally, the paper offers suggestions of areas of future study for applying <b>instance-based</b> machine learning in the setting of solving financial problems. 1...|$|E
40|$|Adaptive {{clustering}} uses {{reinforcement learning}} to learn the reward values of successive data clusterings. Adaptive clustering applies when external feedback exists for a clustering task. It supports the reuse of clusterings by memorizing what worked well in a previous context. It explores multiple paths in a reinforcement learning environment when {{the goal is to}} find better cluster representatives based on arbitrary environmental feedback. Our experiments apply adaptive clustering to <b>instance-based</b> learning relying on a distance function modification approach. The results show that adaptive clustering can find better representatives, if compared with traditional <b>instance-based</b> learning, such as k-nearest neighbor classifiers. Moreover, we introduce as a by-product a new <b>instance-based</b> learning technique that classifies examples by solely using cluster representatives; the technique shows high promise in our experimental evaluation...|$|E
