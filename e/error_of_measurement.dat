956|10000|Public
25|$|Thus more {{information}} implies less <b>error</b> <b>of</b> <b>measurement.</b>|$|E
500|$|Because all IQ {{tests have}} <b>error</b> <b>of</b> <b>measurement</b> in the test-taker's IQ score, a test-giver should always inform the test-taker of the {{confidence}} interval around the score obtained {{on a given}} occasion of taking each test. IQ scores are ordinal scores and are not expressed in an interval measurement unit. Besides the inherent error band around any IQ test score because tests are a [...] "sample of learned behavior", IQ scores can also be misleading because test-givers fail to follow standardized administration and scoring procedures. In cases of test-giver mistakes, the usual result is that tests are scored too leniently, giving the test-taker a higher IQ score than the test-taker's performance justifies. Some test-givers err by showing a [...] "halo effect", with low-IQ individuals receiving IQ scores even lower than if standardized procedures were followed, while high-IQ individuals receive inflated IQ scores.|$|E
2500|$|The frequentist {{view has}} its own problems. It is of course {{impossible}} to actually perform an infinity of repetitions of a random experiment to determine the probability of an event. But if only {{a finite number of}} repetitions of the process are performed, different relative frequencies will appear in different series of trials. If these relative frequencies are to define the probability, the probability will be slightly different every time it is measured. But the real probability should be the same every time. If we acknowledge the fact that we only can measure a probability with some <b>error</b> <b>of</b> <b>measurement</b> attached, we still get into problems as the <b>error</b> <b>of</b> <b>measurement</b> can only be expressed as a probability, the very concept we are trying to define. This renders even the frequency definition circular; see for example “” ...|$|E
30|$|This {{process was}} {{repeated}} 25 times. Wilcoxon duplicate determination was performed, and the <b>errors</b> <b>of</b> <b>measurement</b> were established.|$|R
40|$|The effects <b>of</b> random <b>errors</b> <b>of</b> <b>measurement</b> on {{a variety}} of basic multivariate {{procedures}} are discussed. For some procedures, the effect is one of attenuation (i. e., simply reducing the estimated strength of association). For others, the effect may be to alter the apparent direction of association. Some proposed solutions to the problems caused by <b>errors</b> <b>of</b> <b>measurement</b> are presented, and areas requiring further research are pointed out...|$|R
30|$|And third, the use {{and make}} data have <b>errors</b> <b>of</b> <b>measurement</b> [4, 5, 11, 12, 14, 16, 22, 23, 26].|$|R
2500|$|An {{important}} difference between CTT and IRT is {{the treatment of}} measurement error, indexed by the standard <b>error</b> <b>of</b> <b>measurement.</b> [...] All tests, questionnaires, and inventories are imprecise tools; we can never know a person's true score, but rather only have an estimate, the observed score. There is some amount of random error which may push the observed score higher or lower than the true score. [...] CTT assumes {{that the amount of}} error is the same for each examinee, but IRT allows it to vary.|$|E
2500|$|Item {{response}} theory models {{the relationship}} between latent traits and responses to test items. Among other advantages, IRT provides a basis for obtaining {{an estimate of the}} location of a test-taker on a given latent trait as well as the standard <b>error</b> <b>of</b> <b>measurement</b> of that location. For example, a university student's knowledge of history can be deduced from his or her score on a university test and then be compared reliably with a high school student's knowledge deduced from a less difficult test. Scores derived by classical test theory do not have this characteristic, and assessment of actual ability (rather than ability relative to other test-takers) must be assessed by comparing scores to those of a [...] "norm group" [...] randomly selected from the population. In fact, all measures derived from classical test theory are dependent on the sample tested, while, in principle, those derived from item response theory are not.|$|E
2500|$|Psychometricians {{generally}} regard IQ {{tests as}} having high statistical reliability. A high reliability implies that – although test-takers may have varying scores when taking the same test on differing occasions, {{and although they}} may have varying scores when taking different IQ tests at the same age – the scores generally agree {{with one another and}} across time. Like all statistical quantities, any particular estimate of IQ has an associated standard error that measures uncertainty about the estimate. For modern tests, the standard <b>error</b> <b>of</b> <b>measurement</b> is about three points. Clinical psychologists generally regard IQ scores as having sufficient statistical validity for many clinical purposes. In a survey of 661 randomly sampled psychologists and educational researchers, published in 1988, Mark Snyderman and Stanley Rothman reported a general consensus supporting the validity of IQ testing. [...] "On the whole, scholars with any expertise in the area of intelligence and intelligence testing (defined very broadly) share a common view of the most important components of intelligence, and are convinced that it can be measured with some degree of accuracy." [...] Almost all respondents picked out abstract reasoning, ability to solve problems and ability to acquire knowledge as the most important elements.|$|E
30|$|IRT {{applications}} provide different standard <b>errors</b> <b>of</b> <b>measurement</b> {{at different}} trait levels. Because standard <b>errors</b> <b>of</b> <b>measurement</b> {{are used in}} score interpretations, {{it is possible to}} easily create confidence intervals to interpret individual scores (Embretson, 1996). So, one can have a range (around the reached score) associated with a probability. The smaller the errors at some level, the smaller the confidence bands. This does not happen with classical methods that nearly always assume the same standard error applies at all trait levels.|$|R
30|$|Extended Kalman filter is used {{so that it}} is able to {{deal with}} <b>errors</b> <b>of</b> <b>measurements</b> and able to be {{implemented}} on a powerless computers.|$|R
50|$|<b>Errors</b> <b>of</b> <b>measurement</b> are {{composed}} <b>of</b> both random <b>error</b> and systematic error. It represents the discrepancies between scores obtained on tests {{and the corresponding}} true scores.|$|R
6000|$|Having these undoubted {{examples}} of {{error in the}} dimensions of Orangs, {{it is not too}} much to conclude that Mr. St. John's friend made a similar <b>error</b> <b>of</b> <b>measurement,</b> or rather, perhaps, of memory; for we are not told that the dimensions were noted down at the time they were made. The only figures given by Mr. St. John on his own authority are that [...] "the head was 15 inches broad by 14 inches long." [...] As my largest male was 13 1/2 broad across the face, measured as soon as the animal was killed, I can quite understand that when the head arrived at Sarawak from the Batang-Lupar, after two or three days' voyage, it was so swollen by decomposition as to measure an inch more than when it was fresh. On the whole, therefore, I think it will be allowed, that up to this time we have not the least reliable evidence of the existence of Orangs in Borneo more than 4 feet 2 inches high.|$|E
5000|$|The {{standard}} <b>error</b> <b>of</b> <b>measurement</b> is {{the variation}} in scores due to unreliability of the scale or measure used. Thus a change smaller than the standard <b>error</b> <b>of</b> <b>measurement</b> {{is likely to be}} the result of measurement error rather than a true observed change. Patients achieving a difference in outcome score of at least one standard <b>error</b> <b>of</b> <b>measurement</b> would have achieved a minimal clinically important difference.|$|E
50|$|Thus more {{information}} implies less <b>error</b> <b>of</b> <b>measurement.</b>|$|E
50|$|Reliability theory {{shows that}} the {{variance}} of obtained scores is simply {{the sum of the}} variance of true scores plus the variance <b>of</b> <b>errors</b> <b>of</b> <b>measurement.</b>|$|R
30|$|Therefore, {{it seems}} that a {{commonly}} and desirable guide to proceed in order to construct technical coefficients matrices would consist in applying the commodity technology assumption, using afterward location methods for <b>errors</b> <b>of</b> <b>measurement</b> (although these adjustments may be rejected statistically, {{they are supposed to}} be accepted by industrial experts) or negatives as indicators <b>of</b> <b>errors</b> <b>of</b> <b>measurement</b> and/or aggregation problems. Once these problems are solved, no more negatives should arise. It is desirable to use the industry technology assumption just in the needed cases.|$|R
5000|$|... 1. Validity 2. Reliability and <b>Errors</b> <b>of</b> <b>Measurement</b> 3. Test Development and Revision 4. Scales, Norms, and Score Comparability 5. Test Administration, Scoring, and Reporting 6. Supporting Documentation for Tests ...|$|R
50|$|Iteman {{provides}} {{an index of}} decision consistency {{as well as a}} classical estimate of the conditional standard <b>error</b> <b>of</b> <b>measurement</b> at the cutscore, which is often requested for accreditation of a testing program.|$|E
5000|$|In {{order to}} {{determine}} the statistical significance of the indirect effect, a statistic based on the indirect effect must be compared to its null sampling distribution. The Sobel test uses the magnitude of the indirect effect compared to its estimated standard <b>error</b> <b>of</b> <b>measurement</b> to derive a t statistic ...|$|E
5000|$|The frequentist {{view has}} its own problems. It is of course {{impossible}} to actually perform an infinity of repetitions of a random experiment to determine the probability of an event. But if only {{a finite number of}} repetitions of the process are performed, different relative frequencies will appear in different series of trials. If these relative frequencies are to define the probability, the probability will be slightly different every time it is measured. But the real probability should be the same every time. If we acknowledge the fact that we only can measure a probability with some <b>error</b> <b>of</b> <b>measurement</b> attached, we still get into problems as the <b>error</b> <b>of</b> <b>measurement</b> can only be expressed as a probability, the very concept we are trying to define. This renders even the frequency definition circular; see for example “What is the Chance of an Earthquake?” ...|$|E
40|$|The {{regularity}} {{of movement}} of a mobile {{part of the}} differentiative gyro in acoustic medium is established at sound effect and the estimation of a degree of its(her) influencing on <b>error</b> <b>of</b> <b>measurements</b> is conducted. ??????????? ?????????????? ??????????? ????????? ????? ????????????????? ????????? ? ???????????? ????? ??? ???????? ??????????? ? ????????? ?????? ??????? ?? ??????? ?? ??????????? ?????????...|$|R
50|$|Price, L. R., Raju, N., Lurie, A., Wilkins, C., & Zhu, J. (2006). Conditional {{standard}} <b>errors</b> <b>of</b> <b>measurement</b> for composite {{scores on}} the wechsler preschool and primary scale of intelligence-third edition. Psychological reports, 98(1), 237-252.|$|R
30|$|Different factors {{affecting}} {{the accuracy of}} fault location. Generally, the main factors considered as: fault type and location; fault resistance; power flow; source impedance; line parameter; transient and steady <b>errors</b> <b>of</b> <b>measurement</b> system (including CT saturation), etc.|$|R
5000|$|The {{effect size}} {{is a measure}} {{obtained}} by dividing {{the difference between the}} means of the baseline and posttreatment scores by the SD of the baseline scores. An effect size cut off point can be used to define MCID {{in the same way as}} the one half standard deviation and the standard <b>error</b> <b>of</b> <b>measurement.</b>|$|E
50|$|In particular, the {{standard}} error {{of a sample}} statistic (such as sample mean) is the actual or estimated standard deviation of the error in {{the process by which}} it was generated. In other words, it is the actual or estimated standard deviation of the sampling distribution of the sample statistic. The notation for standard error can be any one of SE, SEM (for standard <b>error</b> <b>of</b> <b>measurement</b> or mean), or SE.|$|E
5000|$|The item {{selection}} algorithm utilized {{depends on}} the termination criterion. Maximizing information at the cutscore is more appropriate for the SPRT because it maximizes {{the difference in the}} probabilities used in the likelihood ratio. [...] Maximizing information at the ability estimate is more appropriate for the confidence interval approach because it minimizes the conditional standard <b>error</b> <b>of</b> <b>measurement,</b> which decreases the width of the confidence interval needed to make a classification.|$|E
40|$|It {{is shown}} that the {{influence}} of temperature oscillations on the <b>error</b> <b>of</b> <b>measurements</b> <b>of</b> parameters {{in the case of}} the application of microwave resonator meters on the basis of a voltage-controlled oscillator (VCO) can be minimized by software using a special algorithm of VCO frequency setting correction. An algorithm of VCO frequency setting correction for triangle control voltage is proposed...|$|R
40|$|The {{analysis}} and <b>error</b> estimate <b>of</b> <b>measurements</b> <b>of</b> spektrocolorimeter with interference filters is made. It is shown that basic {{contribution to the}} <b>error</b> <b>of</b> <b>measurements</b> is brought about by systematic one that it is cause <b>of</b> the <b>error</b> <b>of</b> the used standards. For devices with a source A an error does not exceed 1, 2 %, during work with the source ? 65 it is in limits of ? 2 %. As compared to similar devices with a diffraction grate, spektrocolorimeter with interference filters does not yield to them on exactness <b>of</b> <b>measurements,</b> however, considerably cheaper (in three-four times) and it is simpler in the use. ????????? ?????? ? ?????? ???????????? ????????? ?????????????????? ? ?????????????????? ??????????????. ????????, ??? ???????? ????? ? ?????? ????????? ?????? ??????????????? ????????????, ????????????? ???????????? ???????????? ????????? ????????. ??? ???????? ? ?????????? ???? ? ??????????? ?? ????????? 1, 2 %, ??? ?????? ? ?????????? ? 65 ??? ????????? ? ???????? ? 2 %. ?? ????????? ? ???????????? ????????? ? ????????????? ????????, ?????????????????? ? ?????????????????? ????????? ?? ???????? ?? ?? ???????? ?????????, ??????, ??????????? ??????? (? ???-?????? ????) ? ????? ? ?????????????...|$|R
40|$|The article {{describes}} the use <b>of</b> modeling in <b>measurements</b> and control, which {{can be regarded as}} “metrological modeling” <b>of</b> the <b>measurement</b> objects, measuring process and measuring techniques in general. Metrological simulation allows to estimate the projected <b>errors</b> <b>of</b> <b>measurement</b> procedures and techniques to optimize the measuring control design stage. </p...|$|R
50|$|Methods of item {{selection}} {{fall into}} two categories: cutscore-based and estimate-based. Cutscore-based methods (also known as sequential selection) maximize the {{information provided by the}} item at the cutscore, or cutscores if there are more than one, regardless of the ability of the examinee. Estimate-based methods (also known as adaptive selection) maximize information at the current estimate of examinee ability, regardless of the location of the cutscore. Both work efficiently, but the efficiency depends in part on the termination criterion employed. Because the sequential probability ratio test only evaluates probabilities near the cutscore, cutscore-based item selection is more appropriate. Because the confidence interval termination criterion is centered around the examinees ability estimate, estimate-based item selection is more appropriate. This is because the test will make a classification when the confidence interval is small enough to be completely above or below the cutscore (see below). The confidence interval will be smaller when the standard <b>error</b> <b>of</b> <b>measurement</b> is smaller, and the standard <b>error</b> <b>of</b> <b>measurement</b> will be smaller when there is more information at the theta level of the examinee.|$|E
50|$|Iteman is a {{commercial}} program {{specifically designed for}} classical test analysis, producing rich text (RTF) reports with graphics, narratives, and embedded tables. It calculates the proportion and point biserial of each item, as well as high/low subgroup proportions, and detailed graphics of item performance. It also calculates typical descriptive statistics, including the mean, standard deviation, reliability, and standard <b>error</b> <b>of</b> <b>measurement,</b> for each domain and the overall tests. It is only available from Assessment Systems Corporation.|$|E
50|$|An {{important}} difference between CTT and IRT is {{the treatment of}} measurement error, indexed by the standard <b>error</b> <b>of</b> <b>measurement.</b> All tests, questionnaires, and inventories are imprecise tools; we can never know a person's true score, but rather only have an estimate, the observed score. There is some amount of random error which may push the observed score higher or lower than the true score. CTT assumes {{that the amount of}} error is the same for each examinee, but IRT allows it to vary.|$|E
30|$|In {{these studies}} {{longitudinal}} data {{were created by}} aggregation of data to the country level. However, aggregation of data brings other advantages as well. For example, mechanisms that, at the individual level, are responsible for reverse causality, such as compensatory resource allocation, {{are unlikely to be}} present at the country level (Gustafsson 2008). Aggregated data also have the advantage of not being as severely influenced by <b>errors</b> <b>of</b> <b>measurement,</b> compared to individual data. Thus, while student responses to single questionnaire items typically are highly unreliable, estimates of country means are very reliable when sample sizes are large (Jones and Norrander 1996). Therefore, the downward biasing effect <b>of</b> <b>errors</b> <b>of</b> <b>measurement</b> is less <b>of</b> an issue with aggregated data than with individual data.|$|R
40|$|AbstractThe task on {{studying}} the thermal conditions of small-sized long-stroke low-speed stages of piston compressors is solved. The bead thermistors are {{applied for a}} placement of a temperature sensor with small diameters of cylinders. Calibration of a given sensor is executed, the <b>error</b> <b>of</b> <b>measurements</b> is defined...|$|R
40|$|The paper {{considers}} a hardware-software complex for research of characteristics of accuracy and noise immunity of a near navigation {{system based on}} pseudolites. The complex is implemented {{on the basis of}} the “National Instruments” hardware platform and “LabView” coding environment. It provides a simulated navigation field, the analysis of the received signals, the determination <b>of</b> the <b>errors</b> <b>of</b> <b>measurement</b> <b>of</b> navigation parameters for pseudolites signals, comparing the measured error with the characteristics of a standard GNSS receiver...|$|R
