441|2453|Public
25|$|Sylvania Electronics Systems was {{selected}} to develop the first ground-based command and control system using a programmable computer. They developed the software, the message processing and control unit for Wing 6. To support the deployment of the Wing 6 system, TRW, Inc. developed the <b>execution</b> <b>plan</b> program (EPP) from a mainframe computer at SAC and performed an independent checkout of the command and control software. The EPP assisted in assigning targets and launch time for the missiles.|$|E
5000|$|Added {{document}} types for Intermodal Freight Management: Goods Item Itinerary, Transport <b>Execution</b> <b>Plan,</b> Transport <b>Execution</b> <b>Plan</b> Request, Transport Progress Status, Transport Progress Status Request, Transport Service Description, Transport Service Description Request, Transportation Status, Transportation Status Request ...|$|E
5000|$|... query syntax analysis, {{optimization}} and <b>execution</b> <b>plan</b> generation ...|$|E
50|$|Oracle cMRO {{consists}} of 4 main modules, Configuration, <b>Execution,</b> <b>Planning</b> and Engineering.|$|R
5000|$|... (used {{to store}} {{metadata}} for stored outlines for stable query-optimizer <b>execution</b> <b>plans.)</b> ...|$|R
40|$|We {{address the}} {{generation}} of <b>execution</b> <b>plans</b> for object-oriented database queries. This is a challenging area of study because, unlike the relational algebra, a uniformly accepted set of object algebra operators has not been defined. Additionally, a standardized object manager interface analogous to storage manager interfaces of relational systems does not exist. We define the interface to an object manager whose operations are the executable elements of query <b>execution</b> <b>plans.</b> Parameters to the object manager interface are streams of tuples of object identifiers. The object manager can apply methods and simple predicates to the objects identified in a tuple. Two algorithms for generating <b>execution</b> <b>plans</b> for queries expressed in an object algebra are presented. The first algorithm runs quickly but may produce inefficient plans. The second algorithm enumerates all possible <b>execution</b> <b>plans</b> and presents them in an efficient, compact representation. 1 Introduction There is significant inte [...] ...|$|R
5000|$|The rewrite's {{output is}} the <b>execution</b> <b>plan.</b> This phase {{distributes}} relational query optimization and suitable native SQL generation.The phase of rewriting covers: ...|$|E
50|$|A query plan (or query <b>execution</b> <b>plan)</b> is an {{ordered set}} of steps used to access {{data in a}} SQL {{relational}} database management system. This is a specific case of the relational model concept of access plans.|$|E
5000|$|Cannonlake (formerly Skymont) is Intel's codename for the 10-nanometer die shrink of the Coffee Lake microarchitecture. As a die shrink, Cannonlake is a {{new process}} in Intel's [...] "Process-Architecture-Optimization" [...] <b>execution</b> <b>plan</b> as {{the next step in}} {{semiconductor}} fabrication.|$|E
5000|$|The query optimizer can use indexes {{to produce}} faster <b>execution</b> <b>plans</b> using methods such as: ...|$|R
5000|$|Oklahoma Killer Is Put To Death - <b>Execution</b> <b>Planned</b> in Illinois. The New York Times (1990-09-11). Retrieved on 2007-11-13.|$|R
40|$|Text is {{ubiquitous}} and, not surprisingly, {{many important}} applications rely on textual data {{for a variety}} of tasks. As a notable example, information extraction applications derive structured relations from unstructured text; as another example, focused crawlers explore the web to locate pages about specific topics. <b>Execution</b> <b>plans</b> for text-centric tasks follow two general paradigms for processing a text database: either we can scan, or "crawl," the text database or, alternatively, we can exploit search engine indexes and retrieve the documents of interest via carefully crafted queries constructed in task-specific ways. The choice between crawl- and query-based <b>execution</b> <b>plans</b> can have a substantial impact on both execution time and output "completeness" (e. g., in terms of recall). Nevertheless, this choice is typically ad-hoc and based on heuristics or plain intuition. In this article, we present fundamental building blocks to make the choice of <b>execution</b> <b>plans</b> for text-centric tasks in an informed, cost-based way. Towards this goal, we show how to analyze query- and crawl-based plans in terms of both execution time and output completeness. We adapt results from random-graph theory and statistics to develop a rigorous cost model for the <b>execution</b> <b>plans.</b> Our cost model reflects the fact that the performance of the plans depends on fundamental task-specific properties of the underlying text databases. We identify these properties and present efficient techniques for estimating the associated parameters of the cost model. We also present two optimization approaches for text-centric tasks that rely on the cost-model parameters and select efficient <b>execution</b> <b>plans.</b> Overall, our optimization approaches help build efficient <b>execution</b> <b>plans</b> for a task, resulting in significant efficiency and output completeness benefits. We complement our results with a large-scale experimental evaluation for three important text-centric tasks and over multiple real-life data sets. ...|$|R
50|$|Terraform is an {{infrastructure}} as code software by HashiCorp. It {{allows users to}} define a datacenter infrastructure in a high-level configuration language, from which it can create an <b>execution</b> <b>plan</b> to build the infrastructure in a service provider such as AWS.|$|E
50|$|A query <b>execution</b> <b>plan</b> cache is {{implemented}} on the broker {{in order to}} skip most of the compilation steps on often used queries. Because the queries are parametrized during parsing, two queries that differ only by the values of literal constants share the same cache entry.|$|E
50|$|The library cache stores shared SQL, caching the {{parse tree}} and the <b>execution</b> <b>plan</b> for every unique SQL statement. If {{multiple}} applications issue the same SQL statement, each application can access the shared SQL area. This reduces the amount of memory needed and reduces the processing-time used for parsing and execution planning.|$|E
50|$|Squiz has {{recently}} focused on developing its Business Transformation consulting practice through providing digital strategy, vision and <b>execution</b> <b>planning</b> and coaching.|$|R
40|$|Answering queries over a {{federation}} of SPARQL endpoints requires combining data {{from more than}} one data source. Optimizing queries in such scenarios is particularly challenging not only because of (i) the large variety of possible query <b>execution</b> <b>plans</b> that correctly answer the query but also because (ii) there is only limited access to statistics about schema and instance data of remote sources. To overcome these challenges, most federated query engines rely on heuristics to reduce the space of possible query <b>execution</b> <b>plans</b> or on dynamic programming strategies to produce optimal plans. Nevertheless, these plans may still exhibit a high number of intermediate results or high execution times because of heuristics and inaccurate cost estimations. In this paper, we present Odyssey, an approach that uses statistics that allow for a more accurate cost estimation for federated queries and therefore enables Odyssey to produce better query <b>execution</b> <b>plans.</b> Our experimental results show that Odyssey produces query <b>execution</b> <b>plans</b> that are better in terms of data transfer and execution time than state-of-the-art optimizers. Our experiments using the FedBench benchmark show execution time gains of at least 25 times on average. Comment: 16 pages, 10 figure...|$|R
5000|$|Memory is {{allocated}} for data, <b>execution</b> <b>plans,</b> procedure cache, and [...] It is much faster to access data in memory than data on storage, so maintaining a sizable cache of data makes activities perform faster. The same consideration {{is given to}} work space. Caching <b>execution</b> <b>plans</b> and procedures means that they are reused instead of recompiled when needed. It is important to take as much memory as possible, while leaving enough for other processes and the OS to use without excessive paging of memory to storage.|$|R
5000|$|In 2012, Medine {{signed with}} the Creative Artists Agency, an {{entertainment}} talent agency headquartered in Los Angeles, California. In an interview with The Business of Fashion, Medine said: [...] "I think they are great at representing individuals and {{they know how to}} execute. We have the ideas, we just need an <b>execution</b> <b>plan</b> and that's where they come in really well." ...|$|E
50|$|One {{way that}} DAM can prevent SQL {{injection}} is by monitoring the application activity, generating a baseline of “normal behavior”, and identifying an attack {{based on a}} divergence from normal SQL structures and normal sequences. Alternative approaches monitor {{the memory of the}} database, where both the database <b>execution</b> <b>plan</b> and the context of the SQL statements are visible, and based on policy can provide granular protection at the object level.|$|E
5000|$|Optimizer: Performs various transformations on the <b>execution</b> <b>plan</b> {{to get an}} {{optimized}} DAG. Transformations can be aggregated together, such as converting {{a pipeline}} of joins to a single join, for better performance. It can also split the tasks, such as applying a transformation on data before a reduce operation, to provide better performance and scalability. However, the logic of transformation used for optimization used can be modified or pipelined using another optimizer.|$|E
40|$|This work {{addresses}} {{the problem of}} sharing <b>execution</b> <b>plans</b> for queries that continuously cluster streaming data to provide an evolving summary of the data stream. This is challenging since clustering is an expensive task, there might be many clustering queries running simultaneously, each continuous query has a long life time span, and the <b>execution</b> <b>plans</b> often overlap. Clustering is similar to conventional grouped aggregation but cluster formation is more expensive than group formation, which makes incremental maintenance more challenging. The goal of this work is to minimize response time of continuous clustering queries with limited resources through multi-query optimization. To that end, strategies for sharing <b>execution</b> <b>plans</b> between continuous clustering queries are investigated and the architecture of a system is outlined that optimizes the processing of multiple such queries. Since there are many clustering algorithms, the system should be extensible to easily incorporate user defined clustering algorithms...|$|R
40|$|Internet Marketplaces have {{recently}} been proposed as a new and interesting model to make data and computational services available to a broad public. Unlike electronic commerce where services are only requested over the Internet, Internet Marketplace services are both requested and delivered through the Internet. The key idea of Internet Marketplaces is that providers make a range of services available on the Internet and customers rent them whenever necessary. We argue in this paper that such a market model offers a range of advantages over conventional marketplaces and that is attractive for both customers and providers. For Spatial Internet Marketplaces it has been proposed {{that there should be}} some support for automatic <b>execution</b> <b>planning.</b> Since <b>execution</b> <b>planning</b> in federated database systems is closely related to <b>execution</b> <b>planning</b> in Internet Marketplaces, we first compare those paradigms. Our analysis shows that the former can be considered as special case of the latter. Next w [...] ...|$|R
30|$|Given {{a set of}} matched views, {{there could}} be {{multiple}} ways (i.e., <b>execution</b> <b>plans)</b> to execute a relevant query. For instance, to compute Q 2 in Figure 6, we could either compute the result in region B∪C and merge it with that of Q 2 −(B∪C), or merge the results of region Q 2 −C with that of C, or Q 2 −B with B. The query optimizer of DCMS {{should be able to}} list the different <b>execution</b> <b>plans</b> and choose one with the lowest expected cost. Obviously, those plans that do not involve any views should also be evaluated for comparison. For this purpose, a cost model for each query type is designed to quantify the time needed to accomplish a plan. Factors that are considered in the model include: area/volume of the relevant regions involved, expected number of data points in these regions, costs to resolve views with overlapping BRs (e.g., costs to compute the query in B∪C, which can be used to solve Q 2), and existence of indexes. For queries with a small number of <b>execution</b> <b>plans,</b> the decision on which plan to choose can be made by evaluating the costs of all the plans. We {{are in the process of}} designing heuristic algorithms to help make decisions with reasonable response time in facing a large number of <b>execution</b> <b>plans.</b>|$|R
50|$|Sylvania Electronics Systems was {{selected}} to develop the first ground-based command and control system using a programmable computer. They developed the software, the message processing and control unit for Wing 6. To support the deployment of the Wing 6 system, TRW, Inc. developed the <b>execution</b> <b>plan</b> program (EPP) from a mainframe computer at SAC and performed an independent checkout of the command and control software. The EPP assisted in assigning targets and launch time for the missiles.|$|E
5000|$|... "During the {{engagement}} we killed {{some of the}} squaws through mistake. It was a great misfortune to those miserable squaws and children, {{that they did not}} carry into <b>execution</b> <b>plan</b> they had formed {{on the morning of the}} battle -- that was, to come and meet us, and surrender themselves prisoners of war. It was a horrid sight to witness little children, wounded and suffering the most excruciating pain, although they were of the savage enemy, and the common enemy of the country." ...|$|E
5000|$|Kundra {{published}} a 25-point implementation plan to reform how {{the federal government}} manages information technology. The <b>execution</b> <b>plan</b> follows his decision to reevaluate some of the government's most troubled IT projects. Of 38 projects reviewed, four have been canceled, 11 have been rescoped, and 12 have cut the time for delivery of functionality down by more than half, from {{two to three years}} down to an average of 8 months, achieving a total of $3 billion in lifecycle budget reductions, according to whitehouse.gov ...|$|E
40|$|Abstract. This paper {{presents}} a two-stage handwriting recognizer for classification of isolated characters that exploits explicit knowledge on characters’ shapes and <b>execution</b> <b>plans.</b> The first stage performs prototype extraction {{of the training}} data using a Fuzzy ARTMAP based method. These prototypes are able to improve {{the performance of the}} second stage consisting of LVQ codebooks by means of providing the aforementioned explicit knowledge on shapes and <b>execution</b> <b>plans.</b> The proposed recognizer has been tested on the UNIPEN international database achieving an average recognition rate of 90. 15 %, comparable to that reached by humans and other recognizers found in literature. ...|$|R
40|$|Abstract – Performant {{execution}} of data-parallel jobs needs good <b>execution</b> <b>plans.</b> Certain {{properties of the}} code, the data, and the interaction between them are crucial to generate these plans. Yet, these properties are difcult to estimate due to the highly distributed nature of these frameworks, the freedom that allows users to specify arbitrary code as operations on the data, and since jobs in modern clusters have evolved beyond single map and reduce phases to logical graphs of operations. Using xed apriori estimates of these properties to choose <b>execution</b> <b>plans,</b> as modern systems do, leads to poor performance in several instances. We present RoPE, a rst step towards re-optimizing data-parallel jobs. RoPE collects certain code and data properties by piggybacking on job execution. It adapts <b>execution</b> <b>plans</b> by feeding these properties to a query optimizer. We show how this improves the future invocations of the same (and similar) jobs and characterize the scenarios of bene t. Experiments on Bing’s production clusters show up to × improvement across response time for production jobs at th the percentile while using. × fewer resources. 1...|$|R
5000|$|DoD Agency Financial Report/Performance and Accountability Report This report {{provides}} {{our government}} branches and the American public with {{an overview of}} the Department of Defense's financial condition. Published annually, it outlines the Department's financial <b>execution,</b> <b>plans,</b> and accomplishments.|$|R
5000|$|Compiler: Performs {{compilation}} of the HiveQL query, which converts the query to an <b>execution</b> <b>plan.</b> This plan contains the tasks and steps {{needed to be}} performed by the Hadoop MapReduce to get the output as translated by the query. The compiler converts the query to an abstract syntax tree (AST). After checking for compatibility and compile time errors, it converts the AST to a directed acyclic graph (DAG). The DAG divides operators to MapReduce stages and tasks based on the input query and data.|$|E
5000|$|A SELECT {{statement}} retrieves zero or more rows {{from one}} or more database tables or database views. In most applications, [...] is {{the most commonly used}} data query language (DQL) command. As SQL is a declarative programming language, [...] queries specify a result set, but do not specify how to calculate it. The database translates the query into a [...] "query plan" [...] which may vary between executions, database versions and database software. This functionality is called the [...] "query optimizer" [...] as it is responsible for finding the best possible <b>execution</b> <b>plan</b> for the query, within applicable constraints.|$|E
50|$|Overhead: Because stored {{procedure}} {{statements are}} stored {{directly in the}} database, they may remove {{all or part of}} the compiling overhead that is typically needed in situations where software applications send inline (dynamic) SQL queries to a database. (However, most database systems implement statement caches and other methods to avoid repetitively compiling dynamic SQL statements.) Also, while they avoid some pre-compiled SQL, statements add to the complexity of creating an optimal <b>execution</b> <b>plan</b> because not all arguments of the SQL statement are supplied at compile time. Depending on the specific database implementation and configuration, mixed performance results will be seen from stored procedures versus generic queries or user defined functions.|$|E
50|$|GCCS {{supports}} six mission areas (operations, mobilization, deployment, employment, sustainment, and intelligence) {{through eight}} functional areas: threat identification and assessment, strategy planning aids, {{course of action}} development, <b>execution</b> <b>planning,</b> implementation, monitoring, risk analysis, and a common tactical picture.|$|R
40|$|The query optimizer in MySQL chooses {{from the}} {{available}} query <b>execution</b> <b>plans</b> by estimating {{the cost of}} <b>execution</b> for each <b>plan.</b> In this project, MySQL will be extended to record the actual cost of executing each query. By performing queries and analyzing the estimated and actual costs of execution for each query plan, {{the validity of the}} query optimizers estimates and choices will be determined. </p...|$|R
30|$|Step 6 : <b>Execution</b> of <b>plan.</b>|$|R
