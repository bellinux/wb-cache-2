0|60|Public
40|$|In Wolke et al. [1] {{we compare}} the {{efficiency}} of different resource allocation strategies experimentally. We focused on dynamic environments where virtual machines need to be allocated and <b>deallocated</b> <b>to</b> servers over time. In this companion paper, we describe the simulation framework and how to run simulations to replicate experiments or run new experiments within the framework...|$|R
40|$|The {{concurrent}} memory reclamation {{problem is}} that of devising a way for a <b>deallocating</b> thread <b>to</b> verify that no other concurrent threads hold references to a memory block being <b>deallocated.</b> <b>To</b> date, {{in the absence of}} automatic garbage collection, there is no satisfactory solution to this problem. Existing tracking methods like hazard pointers, reference counters, or epoch-based techniques like RCU, are either prohibitively expensive or require significant programming expertise, to the extent that implementing them efficiently can be worthy of a publication. None of the existing techniques are automatic or even semi-automated. In this paper, we take a new approach to concurrent memory reclamation: instead of manually tracking access to memory locations as done in techniques like hazard pointers, or restricting shared accesses to specific epoch boundaries as in RCU, our algorithm, called ThreadScan, leverages operating system signaling to automatically detect which memory locations are being accessed by concurrent threads. Initial empirical evidence shows that ThreadScan scales surprisingly well and requires negligible programming effort beyond the standard use of Malloc and Free...|$|R
40|$|In this paper, we {{describe}} temporal invariants, which are class invariants that are qualified by the operators eventually, always, never, or already. Temporal invariants can capture assertions {{that may not}} be valid initially but, as the program continues, must eventually become valid. Moreover, temporal invariants can indicate references to memory that should eventually be <b>deallocated.</b> <b>To</b> facilitate incorporation of temporal invariants as a maintenance or reengineering activity, we weave invariants into the system as aspects. In our case study of a C++ system, the aspects are woven into join points using policies. We investigate the effectiveness of temporal invariants and we compare the performance of our aspect-oriented implementation with several other approaches...|$|R
5000|$|In C++, it is {{possible}} to have a dangling pointer, a stale reference to an object that has already been <b>deallocated.</b> Attempting <b>to</b> use a dangling pointer typically results in program failure. In Java, the garbage collector will not destroy a referenced object.|$|R
50|$|It {{may also}} refer, more specifically, to a garbage {{collection}} algorithm that uses these reference counts <b>to</b> <b>deallocate</b> objects which {{are no longer}} referenced.|$|R
30|$|Decentralized {{methods are}} {{considered}} in [107], which proposes a self-organizing approach to provide robust and scalable solutions for service deployment, resource provisioning, and load balancing {{in a cloud}} infrastructure. The algorithm developed has the additional benefit to leverage Cloud elasticity <b>to</b> allocate and <b>deallocate</b> resources <b>to</b> help services to respect contractual SLAs.|$|R
25|$|In {{all of the}} overloads, {{the first}} {{parameter}} to the operator delete function is of type , which is {{the address of the}} storage <b>to</b> <b>deallocate.</b>|$|R
5000|$|In {{all of the}} overloads, {{the first}} {{parameter}} to the [...] function is of type void *, which is {{the address of the}} storage <b>to</b> <b>deallocate.</b>|$|R
40|$|A {{reconfigurable}} parallel processor {{under development}} at Kyushu University is a MIMD-type multipurpose multiprocessor system. This {{system can be}} tailored to {{a broad range of}} applications. Its operating system under development considers it as a tightly coupled multiprocessor. Its kernel is based on the message oriented method to implement data-parallel processing. The operating system provides users with functions of the light weight process (thread) as a parallel processing model for tightly coupled multiprocessor system. The overhead of the thread switching can be reduced by our scheduling schedule where processors are allocated and <b>deallocated</b> <b>to</b> each process. The spin lock mechanism with time-out facility is employed to realize more flexible scheduling than coscheduling. We evaluate two methods where address mapping table is copied and it is not copied. As a result, the latter is employed. We propose a method of lazy ceation of stack to have fast access to a stack...|$|R
5000|$|The {{corresponding}} [...] member function accepts any pointer {{that was}} {{returned from a}} previous invocation of the [...] member function {{and the number of}} elements <b>to</b> <b>deallocate</b> (but not destruct).|$|R
5000|$|Memory leaks: Failure <b>to</b> <b>deallocate</b> memory using [...] {{leads to}} buildup of {{non-reusable}} memory, {{which is no}} longer used by the program. This wastes memory resources {{and can lead to}} allocation failures when these resources are exhausted.|$|R
5000|$|The code below {{illustrates}} how memory objects are dynamically <b>deallocated,</b> i.e., returned <b>to</b> the heap or free store. The standard C library provides the function [...] for deallocating a previously allocated memory block and returning {{it back to}} the heap.|$|R
50|$|Garbage {{collection}} is often portrayed as {{the opposite of}} manual memory management, which requires the programmer to specify which objects <b>to</b> <b>deallocate</b> and return <b>to</b> the memory system. However, many systems {{use a combination of}} approaches, including other techniques such as stack allocation and region inference. Like other memory management techniques, garbage collection may take a significant proportion of total processing time in a program and, as a result, can have significant influence on performance. With good implementations, enough memory, and depending on application, garbage collection can be faster than manual memory management, while the opposite can also be true and has often been the case in the past with sub-optimal GC algorithms.|$|R
50|$|If a child process {{receives}} a signal, a waiting parent will then continue execution leaving an orphan process behind. Hence {{it is sometimes}} needed to check the argument set by wait, waitpid or waitid and, in the case that WIFSIGNALED is true, wait for the child process again <b>to</b> <b>deallocate</b> resources.|$|R
5000|$|Awareness and {{discipline}} are also necessary to avoid memory [...] "leaks" [...] (failure <b>to</b> <b>deallocate</b> {{within the scope}} of the allocation) and to avoid references to stale handles after release (which usually resulted in a hard crash - annoying on a single-tasking system, potentially disastrous if other programs are running).|$|R
40|$|A Mobile Ad hoc NETwork (MANET) is an infrastructure-less, spontaneous, and {{arbitrary}} multi-hop wireless network, {{consisting of}} group of mobile nodes. The topology {{of the network}} changes randomly due to unpredictable mobility of nodes. In order to allow truly spontaneous and infrastructure-less networking, a protocol for dynamic allocation of unique addresses is needed, The pre-configuration of addresses is not a possibility in MANET and every node must configure its network interface with a unique address in order to communicate with other nodes so that the packets can be relayed hop by hop and delivered ultimately to the destination. Allocating addresses in mobile ad hoc network is a challenging task. In recent years, various address autoconfiguration protocols have been proposed in the literature to solve this problem. However, address autoconfiguration in mobile ad hoc networks is still an unresolved issue. The main task of an address autoconfiguration protocol is to manage the resource address space. When a node leaves the network, the corresponding address must eventually be <b>deallocated</b> <b>to</b> prevent exhaustion of the address space. This paper proposes a spanning tree based variable length dynamic address autoconfiguration, a novel method {{to solve the problem}} of address autoconfiguration of mobile ad hoc networks. Network partitioning and merging as well as duplicate address detection are well supported by our approach...|$|R
5000|$|Conversely, a child process whose {{parent process}} terminates before it does becomes an orphan process. Such {{situations}} are typically handled {{with a special}} [...] "root" [...] (or [...] "init") process, which is assigned as the new parent of a process when its parent process exits. This special process detects when an orphan process terminates and then retrieves its exit status, allowing the system <b>to</b> <b>deallocate</b> the terminated child process.|$|R
5000|$|Whiley also {{supports}} reference lifetimes which {{are similar to}} those found in Rust. Lifetimes can be given when allocating new objects to indicate when they can be safely <b>deallocated.</b> References <b>to</b> such objects must then include lifetime identifier to prevent dangling references. Every method has an implicit lifetime referred to by [...] A variable of type [...] represents a reference to an object of type [...] which is deallocated with the enclosing method. Subtyping between lifetimes is determined by the outlives relation. Thus, [...] is a subtype of [...] if lifetime [...] statically outlives lifetime [...] A lifetime whose scope encloses another is said to outlive it. Lifetimes in Whiley differ from Rust in that they do not currently include a concept of ownership.|$|R
5000|$|Zeroing weak {{references}} is {{a feature}} in Objective-C ARC that automatically clears (sets to [...] ) weak-reference local variables, instance variables, and declared properties immediately before the object being pointed <b>to</b> starts <b>deallocating.</b> This {{ensures that the}} pointer goes to either a valid object or , and avoids dangling pointers. Prior {{to the introduction of}} this feature, [...] "weak references" [...] referred to references that were not retaining, but were not set to [...] when the object they pointed <b>to</b> was <b>deallocated</b> (equivalent <b>to</b> [...] in ARC), thus possibly leading to a dangling pointer. The programmer typically had to ensure that all possible weak references to an object were set to nil manually when it was being deallocated. Zeroing weak references obviates the need to do this.|$|R
30|$|In addition, Mijumbi et al. [312] use FNN {{to predict}} future {{resource}} requirements for each VNF component (VNFC) in a service function chain [313]. Each VNFC is modeled using {{a pair of}} supervised FNNs that learn the trend of resource requirements for the VNFC by combining historical local VNFC resource utilization information with the information collected from its neighbors. The first FNN learns the dependence of the resource requirements {{for each of the}} VNFCs, which is used by the second FNN to forecast the resource requirements for each VNFC. The predictions are leveraged to spin-up and configure new VNFCs or <b>deallocate</b> resources <b>to</b> turn off VNFCs. Evaluation based on real-time VoIP traffic traces on a virtualized IP Multimedia Subsystem (IMS) reveals a prediction accuracy of approximately 90 %.|$|R
50|$|Garbage, in {{the context}} of {{computer}} science, refers to objects, data, or other regions of the memory of a computer system (or other system resources), which will not be used in any future computation by the system, or by a program running on it. As computer systems all have finite amounts of memory, it is frequently necessary <b>to</b> <b>deallocate</b> garbage and return it to the heap, or memory pool, so the underlying memory can be reused.|$|R
50|$|One {{solution}} to the upwards funarg problem is to simply allocate all stack frames from the heap instead of the stack, and rely on some form of garbage collection or reference counting <b>to</b> <b>deallocate</b> the stack frames when {{they are no longer}} needed. Managing stack frames on the heap is much less efficient than on the stack, so this strategy may significantly degrade performance. Moreover, because most functions in typical programs do not create upwards funargs, much of this overhead is unnecessary.|$|R
50|$|In such statically typed {{languages}} as C(C++) {{there is}} no specific notion of a value undefined at runtime. Arithmetically undefined expressions invoke exceptions and crash the program, if uncaught. Undefined (means, unpredictable) data in C and similar languages may appear in poorly designed programs or {{as a result of}} an unexpected fault, and represent a severe danger, particularly pointers <b>to</b> <b>deallocated</b> memory and null pointers to arrays or structures. Even an attempt to read a value, which a garbage pointer refers to, can crash a program.|$|R
50|$|Pointers {{can also}} be used <b>to</b> {{allocate}} and <b>deallocate</b> dynamic variables and arrays in memory. Since a variable will often become redundant after it has served its purpose, it is a waste of memory to keep it, and therefore it is good practice <b>to</b> <b>deallocate</b> it (using the original pointer reference) when it is no longer needed. Failure to do so may result in a memory leak (where available free memory gradually, or in severe cases rapidly, diminishes because of an accumulation of numerous redundant memory blocks).|$|R
40|$|Two techniquesfor managingmemoryon a {{parallel}} randomaccess machine(PRAM) are presented. One is a scheme for an n/log n processor EREW PRAM that dynamically allocates and <b>deallocates</b> up <b>to</b> n {{records of the}} same size in O(log n) time. The other is a simulation of a PRAM with initialized memory by one with uninitialized memory. A CREW PRAM variant of the technique justifies the assumption that memory can be assumed to be appropriately initialized with no asymptotic increase in time but a factor of n increase in space. An EREW PRAM solution incurs a factor of O(log n) increase in time but only a constant factor increase in space. Keywords: Parallel Algorithms, PRAM, Memory Management, Memory Initialization. 1. Introduction Procedures for memory management are commonly assumed tools for algorithms that maintain dynamic data structures. Such tools have been thoroughly studied for sequential machines for decades. This paper presents two techniques for managing memory on {{a parallel}} random ac [...] ...|$|R
40|$|Efficientmemorymanagementofdynamicnon-blockingdata {{structures}} {{remains an}} important open question. Existing methods either sacrifice the ability <b>to</b> <b>deallocate</b> objects or reduce performance notably. In this paper, {{we present a}} novel technique, called Drop the Anchor, which significantly reduces the overhead associated with the memory management while reclaiming objects even {{in the presence of}} thread failures. We demonstrate this memory management scheme on the common linked list data structure. Using extensive evaluation, we show that Drop the Anchor significantly outperforms Hazard Pointers, the widely used technique for non-blocking memory management. Categories andSubjectDescriptors E. 1 [Data]: DataStructures—lists, stacks, and queues; D. 1. ...|$|R
40|$|Lately, {{there is}} a growing {{interest}} in the use of cloud computing for scientific applications, including scientific workflows. Key attractions of cloud include the pay-as-you-go model and elasticity. While the elasticity offered by the clouds can be ben-eficial for many applications and use-scenarios, it also imposes significant challenges in the development of applications or services. For example, no general framework exists that can enable a scientific workflow to execute in a dynamic fashion with QOS (Quality of Service) support, i. e. exploiting elasticity of clouds and automati-cally allocating and <b>deallocating</b> resources <b>to</b> meet time and/or cost constraints while providing the desired quality of results the user needs. This thesis presents a case-study in creating a dynamic cloud workflow implemen-tation with QOS of a scientific application. We work with MassMatrix, an application which searches proteins and peptides from tandem mass spectrometry data. In order to use cloud resources, we first parallelize the search method used in this algorithm. Next, we create a flexible workflow using the Pegasus Workflow Management Syste...|$|R
25|$|The {{placement}} delete {{functions are}} called from placement new expressions. In particular, {{they are called}} if the constructor of the object throws an exception. In such a circumstance, {{in order to ensure}} that the program does not incur a memory leak, the placement delete functions are called. A placement new expression first calls the placement operator new function, then calls the constructor of the object upon the raw storage returned from the allocator function. If the constructor throws an exception, it is necessary <b>to</b> <b>deallocate</b> that storage before propagating the exception back to the code that executed the placement new expression, and that is the purpose of the placement delete functions.|$|R
40|$|Abstract. Traditionally, radio {{resources}} are released in cellular networks by statically configured inactivity timers, causing substantial resource inefficiencies. We propose a novel system RadioProphet (RP), which dynamically and intelligently determines {{in real time}} when <b>to</b> <b>deallocate</b> radio resources by predicting the network idle time based on traffic history. We evaluate RP using 7 -month-long real-world cellular traces. Properly configured, RP correctly predicts 85. 9 % of idle time instances and achieves radio energy savings of 59. 1 % {{at the cost of}} 91. 0 % of signaling overhead, outperforming existing proposals. We also implement and evaluate RP on real Android devices, demonstrating its negligible runtime overhead. ...|$|R
5000|$|The {{placement}} delete {{functions are}} called from placement [...] expressions. In particular, {{they are called}} if the constructor of the object throws an exception. In such a circumstance, {{in order to ensure}} that the program does not incur a memory leak, the placement delete functions are called. A placement new expression first calls the placement [...] function, then calls the constructor of the object upon the raw storage returned from the allocator function. If the constructor throws an exception, it is necessary <b>to</b> <b>deallocate</b> that storage before propagating the exception back to the code that executed the placement new expression, and that is the purpose of the placement delete functions.|$|R
5000|$|Most modern {{languages}} provide language-level {{support to}} prevent such leaks; see detailed discussion at resource management. Most commonly this is done via unwind protection, which ensures that certain code is guaranteed to be run when execution exits a block; this is a structured alternative to having a cleanup block and a [...] This is most often known as [...] and considered a part of exception handling. Various techniques exist to encapsulate resource management. An alternative approach, found primarily in C++, is Resource Acquisition Is Initialization, which uses normal stack unwinding (variable deallocation) at function exit to call destructors on local variables <b>to</b> <b>deallocate</b> resources.|$|R
5000|$|When an unused {{object is}} never {{released}} {{back to the}} free store, {{this is known as}} a memory leak. In some cases, memory leaks may be tolerable, such as a program which [...] "leaks" [...] a bounded amount of memory over its lifetime, or a short-running program which relies on an operating system <b>to</b> <b>deallocate</b> its resources when it terminates. However, in many cases memory leaks occur in long-running programs, and in such cases an unbounded amount of memory is leaked. When this occurs, the size of the available free store continues to decrease over time; when it is finally exhausted, the program then crashes.|$|R
40|$|Typed {{assembly}} languages usually support heap allocation safely, {{but often}} rely on an external garbage collector <b>to</b> <b>deallocate</b> {{objects from the}} heap and prevent unsafe dangling pointers. Even if the external garbage collector is provably correct, verifying {{the safety of the}} interaction between TAL programs and garbage collection is nontrivial. This paper introduces a typed assembly language whose type system is expressive enough to type-check a Cheney-queue copying garbage collector, so that ordinary programs and garbage collection can co-exist and interact inside a single typed language. The only built-in types for memory are linear types describing individual memory words, so that TAL programmers can define their own object layouts, method table layouts, heap layouts, and memory management techniques. 1...|$|R
40|$|Linear type systems permit programmers <b>to</b> <b>deallocate</b> or {{explicitly}} recycle memory, but {{are severely}} restricted {{by the fact}} that they admit no aliasing. This paper describes a pseudo-linear type system that allows a degree of aliasing and memory reuse as well as the ability to de ne complex recursive data structures. Our type system can encode conventional linear data structures such as linear lists and trees as well as more sophisticated data structures including cyclic and doubly-linked lists and trees. In the latter cases, our type system is expressive enough to represent pointer aliasing and yet safely permit destructive operations such as object deallocation. We demonstrate the exibility ofour type system by encoding two common space-conscious algorithms: destination-passing style and Deutsch-Schorr-Waite or -reversal &quot; traversal algorithms. ...|$|R
40|$|This paper {{presents}} an analysis and transformation for individual object reclamation in Java programs. First, we propose a uniqueness inference algorithm that identifies variables and object fields that hold unique references. The algorithm performs an intraprocedural analysis of each method, and then builds and solves {{a set of}} inter-procedural uniqueness dependencies to find the global solution. Second, our system uses the uniqueness information to automatically instrument programs with explicit deallocation of individual objects. A key feature of the transformation is its ability <b>to</b> <b>deallocate</b> entire heap structures, including recursive structures, when their root objects are freed. This is achieved by generating object destructors that recursively free all of the unique object fields. Our experiments show that the analysis is effective at reclaiming a large fraction of the objects at a low analysis cost...|$|R
40|$|Use-after-free {{vulnerabilities}} exploiting so-called dangling pointers <b>to</b> <b>deallocated</b> {{objects are}} just as dangerous as buffer overflows: they may enable arbitrary code execution. Unfortunately, state-of-the-art defenses against use-after-free vulnerabilities require compiler support, pervasive source code modifications, or incur high performance overheads. This paper presents and evaluates Cling, a memory allocator designed to thwart these attacks at runtime. Cling utilizes more address space, a plentiful resource on modern machines, to prevent typeunsafe address space reuse among objects of different types. It infers type information about allocated objects at runtime by inspecting the call stack of memory allocation routines. Cling disrupts a large class of attacks against use-after-free vulnerabilities, notably including those hijacking the C++ virtual function dispatch mechanism, with low CPU and physical memory overhead even for allocation intensive applications. ...|$|R
