51|58|Public
5000|$|In November 2013, Sheriff Mirkarimi {{publicly}} {{apologized for}} his department's slow and <b>incomplete</b> <b>search</b> for Lynne Spalding, a San Francisco General Hospital patient whose {{body was found}} in a stairwell by a hospital engineer two weeks after she went missing from her hospital bed. The Sheriff's Department is responsible for securing the hospital and its patients. Mirkarimi said his department waited nine days after Lynne Spalding was reported missing to begin a hospital-wide search for the 57-year-old patient, and the search did not locate her. [...] "She could have been anyone's loved one, which is why the gravity of the situation is not lost on any of us," [...] the Sheriff said. [...] "What happened to Miss Spalding Ford should not have happened to anyone." [...] Mirkarimi did not say why deputies didn't check the stairwell where Spalding was found.|$|E
5000|$|In 2006, the Papers began a {{comprehensive}} search of records at the National Archives and Records Administration building in College Park, MD (Archives II). In 2011, project staff completed searching the records at Archives II. They located and scanned 29,217 documents written from and to Lincoln. By comparison, {{the editors of}} The Collected Works of Abraham Lincoln identified 455 documents among the records currently housed at Archives II. [...] In 2008, project director, Daniel Stowell, reached {{an agreement with the}} National Archives to digitize Lincoln documents from the Archives' vault.Also in 2008, staff began searching the records at the National Archives Building in Washington, DC (Archives I). As of 2016, the project had two full-time assistant editors identifying and digitizing records at Archives I. In May 2017 the Abraham Lincoln Presidential Library Foundation ended a long-standing agreement with the University of Illinois-Springfield involving the employment of project staff and also announced that the <b>incomplete</b> <b>search</b> at the National Archives would be indefinitely suspended effective July 1, 2017. The financially troubled State of Illinois ended its limited funding for the project in 2015 and some federal support has also been denied casting the project's future in doubt.|$|E
40|$|Abstract. In this paper, {{we present}} a major {{improvement}} in the search procedures in constraint programming. First, we integrate various search procedures from AI and OR. Second, we parallelize the search on shared-memory computers. Third, we add an object-oriented extensible control language to implement complex complete and <b>incomplete</b> <b>search</b> procedures. The result is a powerful set of tools which offers both brute force search using simple search procedures and parallelism, and finely tuned search procedures using that expressive control language. With this, we were able both to solve difficult and open problems using complete search procedures, and to quickly produce good results using <b>incomplete</b> <b>search</b> procedures. ...|$|E
40|$|In this paper, {{we propose}} an {{extension}} of three <b>incomplete</b> depthfirst <b>search</b> techniques, namely depth-bounded backtrack search, credit search, and iterative broadening, towards producing incomplete solutions. We also propose a new cutoff strategy for <b>incomplete</b> depth-first <b>search</b> motivated by a human style of problem solving. This technique, called limited assignment number (LAN) search, is based on {{limiting the number of}} attempts tried to assign a value to the variable. A linear worst-case time complexity of LAN Search leads to promising stable time behavior in all accomplished experiments. The techniques are studied in the context of constraint satisfaction problems...|$|R
40|$|There {{are many}} {{difficulties}} with online searching using the International Patent Classification Codes (IPC) and relying {{on them for}} a subject search can often result in <b>incomplete</b> <b>searches.</b> The European Classification system (ECLA) is the classification system of the European Patent Office (EPO) {{which is used to}} classify their internal search documentation. Although the ECLA classification is used internally by the EPO, it is available and searchable on a number of patent databases on Questel. While the ECLA codes are based on the IPC system, they are more specific and overcome many of the IPC's weaknesses, and can be used to increase recall in subject searches. ...|$|R
50|$|The EP reached 119 on the Billboard 200 albums chart, despite {{relatively}} little promotion. The low-resolution album art is intentional, {{as to make}} the EP resemble a bootleg recording. The back of the sleeve features an <b>incomplete</b> word <b>search</b> whose letters contain hidden details of the recording.|$|R
40|$|A {{recent article}} (Peña-García et al., 2015) {{presented}} conclusions regarding {{the benefits of}} road lighting for pedestrians. Here it is demonstrated that those conclusions were drawn from incomplete evidence, in one case because the experimental designs leads only to a trivial solution and in a second case because of an <b>incomplete</b> <b>search</b> of the literature...|$|E
40|$|A {{competitive}} rent-seeking club (CRSC) {{offers its}} members {{the chance of}} winning a prize (status, position, privilege) by being selected, typically, by a civil servant or a politician. The selector replaces in our setting the usual contest success function; instead of determining the winner {{on the basis of}} the club-members' efforts, he selects the winner on the basis of quality. This paper focuses on the effect of <b>incomplete</b> <b>search</b> of the selector on the efficiency of democratic self-governing and decentralized RSC's that control admittance to the club and its transparency, assuming that quality of their members is fixed. The <b>incomplete</b> <b>search</b> of the selector is assumed to take the simple form of fixed random sampling of the contestants - the members of the CRSC. Our results imply that, even when active rent-seeking expenditures are disregarded, the decisions of CRSC's regarding their composition and transparency tend to reduce quality and are therefore inefficient...|$|E
40|$|We {{investigate}} <b>incomplete</b> <b>search</b> algorithms in {{a search}} space constrained by a dominance criterion. We propose a new genetic algorithm for the Multiple Knapsack Problem (MKP) which searches a space of candidates which are not dominated according to a dominance criterion. We compare the new algorithm to previous heuristics for the MKP, as well as alternative algorithms, and show experimentally that our new algorithm yields the best performance on difficult instances where item weights and profits are highly correlated. ...|$|E
40|$|Markush {{formulae}} {{are beyond}} any doubt {{the most efficient}} way of claiming a generic group of compounds. Indeed they are necessary to give applicants adequate protection for their invention. However, due to their complex nature, it is not always straightforward to determine their exact scope. The present paper looks at two extremes of Markush structures, which are unsearchable as such, the so-called "A-B-C type molecules" and "too simple compounds". Appropriate patentability search strategies, including non-unity and <b>incomplete</b> <b>searches,</b> are defined. Frequently, claimed Markush formulae partially overlap with prior art generic structures. Criteria for selecting the most relevant documents in such cases are discussed, including novelty and inventive step aspects of selection inventions. In a case study, the use of different search tools is compared. Markush formulae Unsearchable molecules Partially overlapping formulae Selection inventions REGISTRY CAPLUS MARPAT BEILSTEIN...|$|R
40|$|In practice, an <b>incomplete</b> {{heuristic}} <b>search</b> {{nearly always}} finds better solutions {{if it is}} allowed to search deeper, i. e., expand and heuristically evaluate more nodes in the search tree. On the rare occasions when searching deeper is not beneficial, a curious phenomenon called “search pathology ” occurs. In this paper we study the pathology and gain of a deeper search of the minimin algorithm in the 8 -puzzle, a domain often used for evaluating single-agent search algorithms. We have analyzed the influence of various properties of the search tree and the heuristic evaluation function on the gain and the pathology. In order to investigate {{a broad range of}} the properties, the original 8 -puzzle was extended with diagonal moves, yielding a larger variety of search trees. It turned out that in the 8 -puzzle a substantial proportion of the solvable positions is pathological under various parameters. More importantly, the search parameters that enable the highest gains are quite consistent in pathological and non-pathological positions alike, thus pointing to potentially successful search strategies. Key words: search pathology, 8 -puzzle, heuristic function, <b>incomplete</b> heuristic <b>search</b> 1...|$|R
40|$|In <b>incomplete</b> single-agent <b>search,</b> it is {{generally}} accepted that deeper searches produces better results. It has recently been discovered, though, {{that this is not}} always the case – such behavior has been termed pathological. This paper identifies two properties of search trees that cause pathological behavior and explains how they produce the pathology. A number of different heuristic functions were also investigated, focusing on admissibility and consistency. Consistency was most effective at preventing the pathology, while admissibility helped only in some cases. ...|$|R
40|$|Constraint Satisfaction Problem (CSP) is a {{discrete}} combinatorial problem and hence search algorithms {{belong to the}} main constraint satisfaction techniques. There exist local search techniques exploring complete but inconsistent assignments and depth-first search techniques extending partial consistent assignments towards complete assignments. For most problems {{it is impossible to}} explore complete search space so incomplete techniques are used. In this paper, we survey incomplete depth-first search techniques, in particular, generic <b>incomplete</b> <b>search</b> techniques and discrepancy-based search techniques...|$|E
40|$|Software {{documents}} {{are used to}} capture and communicate knowledge in software projects. It is important that this knowledge can be retrieved efficiently and effectively, to prevent wasted time and errors that negatively {{affect the quality of}} software. In this paper we investigate how software professionals search for knowledge in documentation. We studied the search behaviour of professionals in industry. Prior knowledge helps professionals to search software documents efficiently and effectively. However, it can also misguide professionals to an <b>incomplete</b> <b>search...</b>|$|E
40|$|Abstract. We present randoCoP, a {{theorem prover}} for {{classical}} firstorder logic, which integrates randomized search techniques into the connection prover leanCoP 2. 0. By randomly reordering the axioms {{of the problem}} and the literals within its clausal form, the <b>incomplete</b> <b>search</b> variants of leanCoP 2. 0 can be improved significantly. We introduce details of the implementation and present comprehensive practical results by comparing the performance of randoCoP with leanCoP and other theorem provers on the TPTP library and problems involving large theories. ...|$|E
40|$|In {{a recent}} paper, Focacci, Laburthe and Lodi (2002) {{surveyed}} the integration between Local Search and Constraint Programming {{which seems to}} be suitable to address real-world combinatorial optimization problems. In this paper, we focus on the integration of the machinery developed in the Tabu <b>Search</b> context into <b>incomplete</b> global <b>search</b> algorithms based on CP. The main issue is to re-interpret the techniques developed within Tabu Search for complete solutions so as to apply them to internal nodes of a tree search, i. e., to partial solutions...|$|R
500|$|Singapore's {{response}} {{was that it}} did not have copies of the letters. Its archives were <b>incomplete,</b> and <b>searches</b> for them in other archives had been in vain. Furthermore, the letters {{were more likely to be}} in Malaysia's possession as the Governor had sent them to the Johor rulers. In his rebuttal of Malaysia's case on 19 November 2007, Singapore's Deputy Prime Minister and Minister for Law S. Jayakumar expressed disappointment with Malaysia's insinuation that Singapore had concealed the letters from the Court, which he termed [...] "most disturbing", [...] "baseless" [...] and [...] "distracting".|$|R
40|$|Declarative {{description}} {{of problems with}} – Variables bl which hi h range over (fi (finite) i sets of values – Constraints over subsets of variables which restrict possible value combinations – A solution ti is a value assignment ig which hi h satisfies ti fi all ll constraints • Constraint propagation/reasoning – Removing inconsistent i values for variables bl – Detect failure if constraint can not be satisfied – Interaction of constraints via shared variables – <b>Incomplete</b> • <b>Search</b> – User controlled assignment of values to variables – Each step triggers constraint propagatio...|$|R
40|$|Abstract. In this paper, {{we present}} an {{approach}} for fault-tolerant synthesis by combining predefined patterns for fault-tolerance with algorithmic game solving. A non-fault-tolerant system, {{together with the}} relevant fault hypothesis and fault-tolerant mechanism templates in a pool are translated into a distributed game, and we perform an <b>incomplete</b> <b>search</b> of strategies to cope with undecidability. The result {{of the game is}} translated back to executable code concretizing fault-tolerant mechanisms using constraint solving. The overall approach is implemented to a prototype tool chain and is illustrated using examples. ...|$|E
40|$|The theoretical-multiple {{approach}} tp {{the classification}} of the statistical classes has been developed, the invariant fuzzy measures on the finite algebras have been investigated, the method for variational construction of the optimal closeness measures of the metrizable relations has been developed, the class of defining functions and cost functions for obtaining the generalized solutions has been investigated, the general mathematical models for optimal <b>incomplete</b> <b>search</b> of the solutions have been developed. Available from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|International audienceThis article compares two {{branching}} {{schemes for}} the parallel machine scheduling problem with release dates and tails. Both branching schemes {{can be used}} for either complete or <b>incomplete</b> <b>search</b> tree based algorithms. In particular, our study aims to prove the robustness of each of them for several search methods. We experimentally compare the efficiency of the two branching schemes when they are used in a branch-and-bound (BnB) method, in a limited discrepancy search, in a branch-and-greed (BnG) method or in a beam search (BS) ...|$|E
5000|$|Singapore's {{response}} {{was that it}} did not have copies of the letters. Its archives were <b>incomplete,</b> and <b>searches</b> for them in other archives had been in vain. Furthermore, the letters {{were more likely to be}} in Malaysia's possession as the Governor had sent them to the Johor rulers. In his rebuttal of Malaysia's case on 19 November 2007, Singapore's Deputy Prime Minister and Minister for Law S. Jayakumar expressed disappointment with Malaysia's insinuation that Singapore had concealed the letters from the Court, which he termed [...] "most disturbing", [...] "baseless" [...] and [...] "distracting".|$|R
40|$|Abstract — Many robotic task {{specifications}} can be naturally {{expressed by}} boolean combinations of arbitrary constraints. This allows {{a separation of}} problem description and solu-tion strategy. In this paper, we present a novel approach to solve non-linear constraint systems based on Satisfiability Modulo Theories. While most SMT-based techniques emphasize completeness, we intentionally use an <b>incomplete</b> local <b>search</b> strategy. Despite this incompleteness, the presented solution is {{able to deal with}} many real world problems like task allocation or robot positioning. We show that our approach is able to exploit the logical structure to solve highly complex tasks almost in real-time. I...|$|R
40|$|Fitzgerald's implied {{contention}} {{that we are}} exposed to {{a greater variety of}} toxins in 2006 fails to note the greater quantity of them in 1906 (pp. 62 - 87). Our great-grandparents breathed wood smoke, coal smoke, paint fumes, kerosene fumes, ozone and NOx from early electric motors, as well as barnyard fumes. lOOYL {{is an example of how}} not to use science to guide decisions. From non-specifically cited references written by non-scientists to <b>incomplete</b> literature <b>searches</b> to rank chemophobia leading to rampant errors, a scattered dozen of almost accidentally valid conclusions, in my opinion, does not make this book worthwhile...|$|R
30|$|In an ODB system, the CSP {{refers to}} a “semi-honest-but-curious” server. That is, the CSP may not {{honestly}} follow the proposed protocol but return <b>incomplete</b> <b>search</b> result and/or execute only partial search operations honestly. Thus, two types of attacker are considered: (1) external attacker: a party which wants to obtain knowledge on the database beyond what the party is authorized to obtain, i.e., a revoked user or hacker. (2) internal attacker: a party may have some knowledge about database (i.e., the CSP). The goal of the attacker is to return incomplete/incorrect search results without being detected.|$|E
40|$|Symmetry {{breaking}} and implied constraints can speed up both exhaustive search {{and the search}} for a single solution. We experiment with both types of constraint, using three search algorithms (backtracking, local and hybrid) to find single solutions for SAT encodings of three combinatorial problems (clique, set cover and balanced incomplete block design generation). Both show strong positive and negative effects, depending on the problem class and algorithm. However, symmetry breaking constraints consistently {{have a negative effect on}} the <b>incomplete</b> <b>search</b> algorithms. This suggests an opposite strategy when applying stochastic search: maximising symmetry in the constraint model...|$|E
40|$|The Pattern self-Assembly Tile set Synthesis (PATS) problem, which {{arises in}} the theory of {{structured}} DNA self-assembly, is to determine a set of coloured tiles that, starting from a bordering seed structure, self-assembles to a given rectangular colour pattern. The task of finding minimum-size tile sets is known to be NP-hard. We explore several complete and <b>incomplete</b> <b>search</b> techniques for finding minimal, or at least small, tile sets and also assess the reliability of the solutions obtained according to the kinetic Tile Assembly Model. Comment: 1 + 36 pages, 18 figures. arXiv admin note: text overlap with arXiv: 0911. 292...|$|E
40|$|In a {{model of}} {{competition}} with imperfect consumer price information and <b>incomplete</b> price <b>search,</b> some consumers may end up comparing prices originating from the same supplier: either because one firm sets multiple prices or because a group of firms colludes. This leads to added monopoly power for these firms, and average prices in the mixed strategy equilibrium become higher. There is a shift in welfare from consumers to producers, both with exogenous and endogenous consumer search behaviour. However consumers might search more or less with multiple prices. The implications for the price-setting equilibrium, competition policy and recent judgements are considered. ...|$|R
40|$|An {{overview}} of some methods of statistical physics {{applied to the}} analysis of algorithms for optimization problems (satisfiability of Boolean constraints, vertex cover of graphs, decoding, [...] .) with distributions of random inputs is proposed. Two types of algorithms are analyzed: complete procedures with backtracking (Davis-Putnam-Loveland-Logeman algorithm) and <b>incomplete,</b> local <b>search</b> procedures (gradient descent, random walksat, [...] .). The study of complete algorithms makes use of physical concepts such as phase transitions, dynamical renormalization flow, growth processes, [...] . As for local search procedures, the connection between computational complexity and the structure of the cost function landscape is questioned, with emphasis on the notion of metastability. Comment: 28 pages, 23 figure...|$|R
40|$|Current {{state-of-the-art}} planners solve problems, {{easy and}} hard alike, by search, expanding {{hundreds or thousands}} of nodes. Yet, given the ability of people to solve easy problems and to explain their solutions, it seems that an essential inferential component may be missing. The reasons expressed by people for selecting actions appear to be related to causal chains: sequences of causal links ai → pi+ 1, i = 0, [...] ., n − 1, such that a 0 is applicable in the current state, pi is a precondition of action ai, and pn is a goal. Some of these causal chains or paths appear to be good, some bad, others appear to be impossible. In this work, we focus on such paths and develop three techniques for performing inference over them from which a path-based planner is obtained. We define the conditions under which a path is consistent, provide an heuristic estimate of the cost of achieving the goal along a consistent path, and introduce a planning algorithm that uses paths as decomposition backbones. The resulting planner, called C 3, is not complete and does not perform as well as recent planners that carry extensive but extremely efficient searches such as LAMA, but is competitive with FF and in particular, with FF running in EHC mode which yields very focused but <b>incomplete</b> <b>searches,</b> and thus provides, a more apt comparison. Moreover, many domains are solved backtrack-free, with no search at all, suggesting that planning with paths may be a meaningful idea both cognitively and computationally...|$|R
40|$|In this paper, {{we present}} an {{approach}} for fault-tolerant synthesis by combining predefined patterns for fault-tolerance with algorithmic game solving. A non-fault-tolerant system, {{together with the}} relevant fault hypothesis and fault-tolerant mechanism templates in a pool are translated into a distributed game, and we perform an <b>incomplete</b> <b>search</b> of strategies to cope with undecidability. The result {{of the game is}} translated back to executable code concretizing fault-tolerant mechanisms using constraint solving. The overall approach is implemented to a prototype tool chain and is illustrated using examples. Comment: The extended version of the paper "Synthesis of Fault-Tolerant Embedded Systems using Games: from Theory to Practice" in VMCAI' 1...|$|E
40|$|In this paper, we analyze medical searching {{behavior}} {{performed by}} a typical medical searcher. We broadly classify a typical medical searcher as: non-medical professionals or medical professionals. We use behavioral signals to study how task difficulty affects medical searching behavior. Using simulated scenarios, we gathered data from an exploratory survey of 180 search sessions performed by 60 participants. Our research study provides a deep understanding of how task difficulty affects medical search behavior. Non-medical professionals and medical professionals demonstrate similar search behavior when searching on an easy task. Longer queries, more time and more <b>incomplete</b> <b>search</b> sessions are observed for an easy task. However, they demonstrate different results evaluation behavior based on task difficulty...|$|E
40|$|Admissible and {{consistent}} heuristic functions are usually preferred in single-agent heuristic search as they guarantee optimal solutions with complete search {{methods such as}} A * and IDA*. Larger problems, however, frequently make a complete search intractable due to space and/or time limitations. In particular, a path-planning agent in a realtime strategy game may need to take an action before its complete search has the time to finish. In such cases, <b>incomplete</b> <b>search</b> techniques (such as RTA*, SRTA*, RTDP, DTA*) can be used. Such algorithms conduct a limited ply lookahead and then evaluate the states envisioned using a heuristic function. The action {{selected on the basis}} of such evaluations can be suboptimal due to the incompleteness of search and inaccuracies in the heuristic. It is usually believed that deeper lookahead increases the chances of taking the optimal action. In this paper, we demonstrate that this is not necessarily the case, even when admissible {{and consistent}} heuristic functions are used. 1 Lookahead Pathologies in Real-time Single-agent Search Complete search methods such as A * [Hart et al, 1968] and IDA * [Korf, 1985] produce optimal solutions when based on an admissible and monotonic heuristic function. The primary drawbacks are the exponential running time and the necessity to wait until the search completes before the first action can be taken [Korf, 1990], This limits the applicability of complete search in practice as the deliberation time per action can be severely limited [Higgins, 2002], the domain model can be expensive [Bulitko and Wilkins, 2002], the goal states can be difficult to recognize [Levner et al, 2002]. Consequently, despite numerous advances in improving heuristic functions [Korf and Taylor, 1996; Culberson and Schaeffer, 1994; Reinefeld, 1993; Korf, 1997], incomplete real-time/on-line search methods remain the practical choice for complex reallife problems. Various <b>incomplete</b> <b>search</b> methods have been propose...|$|E
40|$|Abstract. Admissibility is {{a desired}} {{property}} of heuristic evaluation functions, because when these heuristics are used with complete search methods, such as A * and RBFS, they guarantee that an optimal solution will be found. Since every optimistic heuristic function is admissible, optimistic functions are widely used. We show, however, that with <b>incomplete,</b> real-time <b>search,</b> optimistic functions lose their appeal, {{and in fact}} they may hinder the search under quite reasonable conditions. Under these conditions the exact opposite is to be preferred, i. e. pessimistic heuristic functions that never underestimate {{the difficulty of the}} problem. We demonstrate that such heuristics behave better than optimistic ones of equal quality on a standard testbed using RTA * search method. ...|$|R
40|$|Problems of {{incomplete}} information {{include a}} component of unknown information. We investigate such problems through {{a study of the}} bidding phase in the game of Bridge. In particular, we would like to apply genetic algorithms to the Bridge bidding problem. Genetic algorithms, however, require a fitness function appropriate for the problem. Therefore, in this paper, we first attack the optimization problem of finding the maximum number of tricks that can be taken in a bridge hand with optimal play and with complete information. Solutions from this optimization problem will subsequently be used as fitness functions in applying genetic algorithms to the bidding problem. Key words: artificial intelligence, problems of <b>incomplete</b> information, <b>search</b> methods, game of bridg...|$|R
40|$|Note: This {{work should}} be seen as {{preliminary}} and <b>incomplete.</b> In <b>Search</b> of a Fair Bet in the Lottery ABSTRACT: Although state-operated lotto games have the worst average expected payoffs among common games of chance, because the jackpot can accumulate, the maximum expected payoff is potentially unlimited. It is possible, therefore, that lotto can exhibit a positive expected return. This paper examines 18, 000 drawings in 34 American lotteries and finds approximately 1 % of these drawings provided players with a fair bet. Furthermore, if it were possible for a bettor to purchase every possible combination, most lotteries commonly experience circumstances where such a purchase would provide a positive return with 11 % of the drawings providing a fair bet to the player...|$|R
