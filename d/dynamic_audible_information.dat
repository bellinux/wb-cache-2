0|41|Public
5000|$|Printed sound, {{a system}} for {{generating}} <b>audible</b> <b>information</b> from a sound track printed on paper ...|$|R
5000|$|A user plugs a {{standard}} headset into the jack, and can hear instructions such as [...] "press 1 for withdrawal", [...] "press 2 for deposit." [...] There is an audible orientation {{for first time}} users, and <b>audible</b> <b>information</b> describing the location of features such as the number keypad, deposit slot, and card slot.|$|R
30|$|Thus, {{the deaf}} and LIBRAS {{researchers}} considered {{that use of}} avatar is a valid alternative, {{in the sense that}} the use of avatars would allow access to a TV program’s <b>audible</b> <b>information,</b> especially when a human interpreter is not available. In Sect.  6, we will discuss some results obtained from tests with users to verify this fact.|$|R
50|$|A Talking ATM {{is a type}} of {{automated}} teller machine (ATM) {{that provides}} audible instructions so that persons who cannot read an ATM screen can independently use the machine. All <b>audible</b> <b>information</b> is delivered privately through a standard headphone jack {{on the face of the}} machine or a separately attached telephone handset. Information is delivered to the customer either through pre-recorded sound files or via text-to-speech speech synthesis.|$|R
50|$|A talking ATM {{is a type}} of ATM that {{provides}} audible instructions so that people who cannot read a screen can independently use the machine, therefore effectively eliminating the need for assistance from an external, potentially malevolent source. All <b>audible</b> <b>information</b> is delivered privately through a standard headphone jack {{on the face of the}} machine. Alternatively, some banks such as the Nordea and Swedbank use a built-in external speaker which may be invoked by pressing the talk button on the keypad. Information is delivered to the customer either through pre-recorded sound files or via text-to-speech speech synthesis.|$|R
40|$|Sound is a well-suited {{means to}} {{increase}} the bandwidth of man-machine-communication. Especially in combination with graphics it can help significantly to interprete the visual presentation and cut down operators'response times. Sonification - turning data into <b>audible</b> <b>information</b> - can be successfully applied to scientific visualization as well as virtual reality applications. An implementation of sonification modules and tools within the apE dataflow visualization systems and the integration of sound in a development platform for virtual worlds demonstrate {{the application of the}} introduced concepts and tools. As print media are ill-suited for aural presentations a video supplement of the results is provided and an integral part of this work...|$|R
50|$|That this vestigial {{response}} occurs {{even before}} becoming consciously {{aware of a}} startling noise would explain why the function of ear-perking had evolved in animals. The mechanism serves to give a split-second advantage to a startled animal - possibly an animal being stalked and hunted. The evolutionary advantage of the ear-perking response could spell {{the difference between life}} and death. The perking response serves to gather and focus that much more <b>audible</b> <b>information</b> that is fed into the brain and on its way to being analyzed even before the animal actually becomes aware of the sound. This fraction-of-a-second advantage would explain the evolutionary selection for this response.|$|R
40|$|It is {{difficult}} to view multipage, high resolution documents on devices with small displays. As a solution, we introduce a Multimedia Thumbnail representation, which {{can be seen as}} a multimedia clip that provides an automated guided tour through a document. Multimedia Thumbnails are automatically generated by taking a document image as input and first performing visual and <b>audible</b> <b>information</b> analysis on the document to determine salient document elements. Next, the time and information attributes for each document element are computed by taking into account the display and application constraints. An optimization routine, given a time constraint, selects elements to be included in the Multimedia Thumbnail. Last, the selected elements are synthesized into animated images and audio to create the final multimedia representation. 1...|$|R
50|$|After the {{political}} change, {{the facade of}} the station building was restored. The building is for sale. With the installation of modern platform displays the remaining staff were withdrawn from the station in May 2009. The visual and <b>audible</b> passenger <b>information</b> systems have since been operated from Rostock.|$|R
40|$|Visualization is {{a widely}} {{acknowledged}} discipline to explore vast numerical data by interactive analysis of their visual representations. General-purpose dataflow visualization systems haveproven their flexibility in many different application domains. Sonification - turning data into <b>audible</b> <b>information</b> - increases the bandwidth of man-machine-communication by one dimension towards a perceptualization platform, which allows the affection of all human senses. The integration of sonification tools in a dataflow visualization system unites the advantages of both directions to a powerful universal visual, aural or audiovisual environment. In this paper a detailled concept for the integration of sonification tools in dataflow systems is presented. An implementation within the apE system and several examples demonstrate {{the application of the}} introduced concepts and tools. As print media are ill-suited for aural presentations a video supplement of the results is provided and an integral par t of his work...|$|R
40|$|This paper {{focuses on}} high-fidelity {{multichannel}} audio coding {{based on an}} enhanced adaptation of the well-known sinusoidal plus noise model (SNM). Sinusoids cannot be used per se for high-quality audio modeling {{because they do not}} represent all the <b>audible</b> <b>information</b> of a recording. The noise part has also to be treated to avoid an artificial sounding resynthesis of the audio signal. Generally, the encoding process needs much higher bitrates for the noise part than the sinusoidal one. Our objective is to encode spot microphone signals using the SNM, by taking advantage of the interchannel similarities to achieve low bitrates. We demonstrate that for a given multichannel audio recording, the noise part for each spot microphone signal (before the mixing stage) can be obtained by using its noise envelope to transform the noise part of just one of the signals (the so-called ”reference signal”, which is fully encoded). 1...|$|R
50|$|The Standard Class {{carriages}} {{have improved}} passenger seating and leg room. They also have electronic visual and <b>audible</b> passenger <b>information</b> systems, electronic seat reservation displays, CCTV, {{air conditioning and}} additional space for luggage. Power sockets are supplied on all Standard and Citygold Class coaches. Citygold cars have ergonomic, electronically adjustable seats, multi-channel ear phone jack sockets and individual overhead lighting.|$|R
40|$|Haptic {{technology}} {{provides the}} ability for a system to recreate the sense of touch to a human operator, and as such offers wide reaching advantages. The ability {{to interact with the}} human 2 ̆ 7 s tactual modality introduces haptic human-machine interaction to replace or augment existing mediums such as visual and <b>audible</b> <b>information.</b> A distinct advantage of haptic human-machine interaction is the intrinsic bilateral nature, where information can be communicated in both directions simultaneously. This paper investigates the bilateral nature of the haptic interface in controlling the motion of a remote (or virtual) vehicle and presents the ability to provide an additional dimension of haptic information to the user over existing approaches [1 - 4]. The 3 D virtual haptic cone offers the ability to not only provide the user with relevant haptic augmentation pertaining to the task at hand, as do existing approaches, however, to also simultaneously provide an intuitive indication of the current velocities being commanded. <br /...|$|R
40|$|This paper {{presents}} an ongoing research project, SpeechText, {{in which a}} special means of communication, ‘print interpreting’, is studied. This communication mode, also called typing/writing interpreting, captioning or real-time writing, means the translation of spoken language and any accompanying significant <b>audible</b> <b>information</b> into written text simultaneously with the speech. Print interpreting is needed as a communication support for people with a hearing disability {{in order to give}} them access to speech. The project investigates the process of print interpreting and the comprehensibility of the interpretation as well as develops new technologies and methods for both print interpreters and research purposes. This paper describes the method of print interpreting used in Finland and presents the research project, its objectives and methods. What is print interpreting? Print interpreting is the most commonly used communication support for people with a hearing disability in Finland. The clients are hard-of-hearing and late-deafened people who have lost their hearing to some extent in the adulthood but have usually maintained their ability to speak. Othe...|$|R
40|$|AIMS—To {{investigate}} (1) whether colic cries are acoustically {{distinct from}} pre-feed "hunger" cries; (2) {{the role of}} the acoustic properties of these cries versus their other properties in accounting for parents' concerns about colic.  DESIGN—From a community sample, infants were selected who met Wessel colic criteria for amounts of crying and whose mothers identified colic bouts. Using acoustic analyses, the most intense segments of nine colic bouts were compared with matched segments from pre-feed cries presumed to reflect hunger.  RESULTS—The colic cries did not have a higher pitch or proportion of dysphonation than the pre-feed cries. They did contain more frequent shorter utterances, but these resembled normal cries investigated in other studies. There is no evidence that colic cries have distinct acoustic features that are reproducible across samples and studies, which identify a discrete clinical condition, and which are identified accurately by parents.  CONCLUSIONS—The most reliable finding is that colic cries convey diffuse acoustic and <b>audible</b> <b>information</b> that a baby is highly aroused or distressed. Non-acoustic features, including the prolonged, hard to soothe, and unexplained nature of the cries may be specific to colic cries and more important for parents. These properties might reflect temperament-like dispositions. ...|$|R
50|$|Like all SPT {{rolling stock}} of the period, the Class 320s were painted in orange/black livery until 1997, when the carmine/cream livery was {{progressively}} phased in. Between 2002 and 2004, the Class 320 fleet were given a major interior refurbishment, with new seat covers, floor coverings, improved interior saloon lighting diffusers and electronic and <b>audible</b> destination <b>information</b> systems installed. The units were given a revised SPT carmine & cream livery upon its refurbishment, the most noticeable being the passenger doors being all cream.|$|R
40|$|As small {{portable}} devices are becoming standard personal equipments, {{there is a}} great need for the adaptation of information content to small displays. Currently, no good solutions exist for viewing formatted documents, such as pdf documents, on these devices. Adapting content of web pages to small displays is usually achieved by complete redesign of a page or automatically reflowing text for small displays. Such techniques may not be applicable to documents whose format needs to be preserved. To address this problem, we propose a new document representation called Multimedia Thumbnail. Multimedia Thumbnail uses the visual and audio channels of small {{portable devices}} to communicate document information in form of a multimedia clip, which {{can be seen as a}} movie trailer for a document. Generation of such a clip includes a document analysis step, where salient document information is extracted, an optimization step, where the document information to be included in the thumbnail is determined based on display and time constraints, and a synthesis step, where visual and <b>audible</b> <b>information</b> are formed into a playable Multimedia Thumbnail. We also present user study results that evaluate an initial system design and point to further modification on analysis, optimization, and user interface components...|$|R
6000|$|These words, [...] "You {{will never}} come back!" [...] were {{literally}} the last that I heard on quitting my country. They were uttered in a prophetic tone, and under circumstances that were of a nature to produce an impression. I thought of them often, when standing on the western verge of Europe, and following {{the course of the}} sun toward the land in which I was born; I remembered them from the peaks of the Alps, when the subtle mind, outstripping the senses, would make its mysterious flight westward across seas and oceans, to recur to the past, and to conjecture the future; and when the allotted five years were up, and found us still wanderers, I really began to think, what probably every man thinks, in some moment of weakness, that this call from the passing ship was meant to prepare me for the future. The result proved in my case, however, as it has probably proved in those of most men, that Providence did not consider me of sufficient importance to give me <b>audible</b> <b>information</b> of what was about to happen. So strong was this impression to the last, notwithstanding, that on our return, when the vessel passed the spot where the evil-omened prediction was uttered, I caught myself muttering involuntarily, [...] "---- is a false prophet; I have come back!" ...|$|R
40|$|Figure 1 : Sonification {{pipeline}} to convert text messages. Clip arts are provided under CC 0 by openclipart. org. Copyright {{is held by}} the author/owner(s). MobileHCI’ 12, Sept. 21 – 24, 2012, San Francisco, CA, USA. ACM 978 - 1 - 4503 - 1443 - 5 / 12 / 09. Mobile phones offer great potential for personalization. Besides apps and background images, ringtones are the major form of personalization. They are most often {{used to have a}} personal sound for incoming texts and calls. Furthermore, ringtones are used to identify the caller or sender of a message. In parts, this function is utilitarian (e. g., caller identification without looking at the phone) {{but it is also a}} form of self-expression (e. g., favorite tune as standard ringtone). We investigate how audio can be used to convey richer information. In this demo we show how sonifications of SMS can be used to encode informa-tion about the sender’s identity as well as the content and intention of a message based on flexible, user-generated mappings. We present a platform that allows arbitrary mappings to be managed and apps to be connected in order to create a sonification of any message. Using a background app on Android, we show the utility of the approach for mobile devices. Author Keywords Sonification; text messages; rich <b>audible</b> <b>information...</b>|$|R
5000|$|Every stop {{along the}} line {{received}} some level of improvement, with the degree of investment determined by the ridership. All stops were enhanced with new concrete, RapidRide signage, and a new bus stop flag featuring route information, a solar-powered area light, and a stop request strobe light, to signal to drivers that a passenger is waiting. Additionally, moderately busy stops received new shelters, benches and trash cans. The busiest stops were improved into [...] "stations" [...] with large shelters and a [...] "tech pylon" [...] with an electronic real-time arrival sign, <b>audible</b> arrival <b>information,</b> a backlit route map, and an ORCA reader for off-board fare payment.|$|R
40|$|The {{display of}} map data on mobile devices is {{currently}} under intensive attention, especially {{because of the}} recent introduction {{of the concept of}} Location Based Services (LBS). Many useful location-aware services can be built without map display on the mobile terminal and a few service categories can be realized even completely without access to spatial data resources. However, in some service types a significant improvement can be achieved in the usability if map data can be utilized. Map displays are most useful e. g. in various guidance and navigation services. A fundamental design principle for this kind of service is that map display must be brought to the terminal via a wireless network connection on the moment the service is accessed. A service architecture based on pre-loaded map data, does not seem appropriate in the context of dynamic mobile services. The limited computing facilities available in current mobile devices sets significant limitations for the map display. The processing power can be assumed to be constantly increasing, {{but on the other hand}} in the future even smaller devices will probably be introduced. So limited capacity terminals will be used also in the future. This kind of devices can typically display map data only as raster images or in the form of textual or <b>audible</b> <b>information.</b> An example of the latter would be a navigational service based on audible turning-point instructions. In mobile services up-to-date information is vital. Access to current data, independently of the time of the day o...|$|R
30|$|There {{was only}} minor effect of hearing loss on the {{question}} of how important hearing is for different transportation modes, Moderate HL rated hearing as more important when walking and for public transportation than NH. Possibly, for individuals with normal hearing, {{it is difficult to imagine}} how <b>audible</b> <b>information</b> is needed in these situations. There was a strong effect of gender, such that women experience that hearing is more important for all modes of transportation, which corresponds with the women being more anxious and thinking more about safety c.f. [3]. In general, the effect of hearing on driver abilities was higher rated by NH and Mild HL than by Profound HL and in some cases also than by Severe HL, which is a new finding. One explanation could be that a higher degree of hearing loss forces the individuals to use different forms of coping strategies, which can be seen as a sort of adaptation. Tactical compensation (e.g. timing, distance, avoidance) is a known coping strategy among older drivers, proven to support mobility and reduce accident risk. By adopting slower speed and longer following distance, mental workload is reduced and attention allocated to process relevant information to the driving task [1]. For individuals with hearing loss, Andersson and Hägnebo [2] have shown that strategic problem solving and self-controlling coping strategies are more frequently used than escape or avoidance. This is in line with hearing loss having no effect on avoidance of any specific traffic situations or environments. A general feature of avoidance was correlated with age c.f. [3]. Women reported avoidance of more situations than men did c.f. [3, 9, 11].|$|R
40|$|According to {{statistics}} from the Federal Highway Administration (FHWA), each year approximately 17 % of all work zone fatalities are pedestrians. People {{who are visually impaired}} often encounter physical and information barriers that limit their accessibility and mobility. A survey was conducted among 10 visually impaired participants as a starting point to understand their challenges and what types of information are helpful in providing bypass or routing instructions to them around work zones. The survey results were incorporated into development of guiding documents in determining information elements that are essential and useful for providing routing instructions to the visually impaired around work zones. Building on our previous efforts to provide geometry and signal timing to the visually impaired at signalized intersections, a smartphone-based navigation system was developed and integrated with navigational <b>audible</b> <b>information</b> to alert pedestrians at decision points prior to their arrival at a work zone. The recommended message elements from survey results were implemented in a smartphone app that uses GPS and Bluetooth technologies to determine a user’s location. When a work zone is detected, the smartphone will vibrate to alert users and the app will then announce a corresponding audible message to users. The visually impaired users can perform a single tap on the smartphone to repeat the messages, if needed. Functionality testing and system validation of the smartphone app were performed by attaching four Bluetooth beacons to light posts near a construction site in St. Paul, MN. Additional research is needed to conduct experiments with visually impaired users and evaluate system reliability and usefulness. Minnesota Traffic Observatory Laboratory Department of Civil Engineerin...|$|R
40|$|Although audio guides {{are widely}} {{established}} in many museums, they suffer from several drawbacks compared to state-of-the-art multimedia technologies: First, they provide only <b>audible</b> <b>information</b> to museum visitors, while {{other forms of}} media presentation, such as reading text or video could be beneficial for museum guidance tasks. Second, they are not very intuitive. Reference numbers have to be manually keyed in by the visitor before information about the exhibit is provided. These numbers are either displayed on visible tags that are located near the exhibited objects, or are printed in brochures {{that have to be}} carried. Third, offering mobile guidance equipment to visitors leads to acquisition and maintenance costs that have to be covered by the museum. With our project PhoneGuide we aim at solving these problems by enabling the application of conventional camera-equipped mobile phones for museum guidance purposes. The advantages are obvious: First, today’s off-the-shelf mobile phones offer a rich pallet of multimedia functionalities [...] -ranging from audio (over speaker or head-set) and video (graphics, images, movies) to simple tactile feedback (vibration). Second, integrated cameras, improvements in processor performance and more memory space enable supporting advanced computer vision algorithms. Instead of keying in reference numbers, objects can be recognized automatically by taking non-persistent photographs of them. This is more intuitive and saves museum curators from distributing and maintaining a large number of physical (visible or invisible) tags. Together with a few sensor-equipped reference tags only, computer vision based object recognition allows for the classification of single objects; whereas overlapping signal ranges of object-distinct active tags (such as RFID) would prevent the identification of individuals that are grouped closely together. Third, since we assume that museum visitors {{will be able to use}} their own devices, the acquisition and maintenance cost for museum-owned devices decreases...|$|R
40|$|Using key {{principles}} of perceptual theory, the researchers examined new instructional methods for presenting visual images of historic costume (in three 5 -year increments) to students for analysis and categorization. In addition, {{principles of}} cognitive theory provided {{the basis for}} examining the effectiveness of the stimuli for each learner. Visual images consisted of different compositions: fashion plates with five figures, single figures, or segments (close-up images of upper, middle, or lower part). The historic costume lesson was developed using hypermedia technology which combines computers and videodiscs allowing for the integration of text, visual images, and <b>audible</b> <b>information.</b> Seventy-nine undergraduate students completed a Learning Style Profile and an achievement test after using the lesson. During the lesson students chose visual images (56 %) more often than written descriptions (30 %) or audio messages (14 %) for acquiring information about historic costume. The visual composition selected most often was the single figure, followed in order by 5 -figure fashion plates, and last, segments. The type of media selected correlated strongly with a student’s analytical skills. Strong analytical learners used text significantly more frequently than students with average or weak analytical skills (p =. 0029). The t-test revealed that for all students the mean scores for the ending achievement test increased significantly (p =. 01) over the scores for the preliminary test. In addition, high analytical skills had a significant interaction (F 2, 76) = 5. 21, p =. 008) with high achievement scores. This study lends support to the recommendation that various compositions of visual images are an effective strategy for assimilating information about historic costume. Visual images are highly important but not to the exclusion of text and audio. Key Words: historic costume, hypermedia, cognitive theory, perceptio...|$|R
5000|$|Primarily {{begun in}} the 1960s, diverse composers have {{employed}} divergent methods and styles of process. [...] "A 'musical process' as Christensen defines it is a highly complex <b>dynamic</b> phenomenon involving <b>audible</b> structures that evolve {{in the course of}} the musical performance ... 2nd order audible developments, i.e., audible developments within audible developments" [...] These processes may involve specific systems of choosing and arranging notes through pitch and time, often involving a long term change with a limited amount of musical material, or transformations of musical events that are already relatively complex in themselves.|$|R
40|$|International audienceThis paper {{deals with}} the {{simulation}} of a high gain triode stage of a guitar amplifier. Triode models taking into account various "secondary phenomena" are considered and their relevance on the stage is analyzed. More precisely, both static and dynamic models (including parasitic capacitances) are compared. For each case, the stage can be modeled by a nonlinear differential algebraic system. For static triode models, standard explicit numerical schemes yield efficient stable simulations of the stage. However, the effect due to the capacitances in <b>dynamic</b> models is <b>audible</b> (Miller effect) and must be considered. The problem becomes stiff and {{requires the use of}} implicit schemes. The results are compared for all the models and corresponding VST plug-ins have been implemented...|$|R
40|$|Natural gas is an {{odourless}} {{one which}} consists of compounds made of two elements: carbon and hydrogen called hydrocarbons. Sometimes, due to an accident or if the valve is not properly closed, the gas leaks. This system is aimed at detecting the leakage and sounding an alert so that occupants in the building can maintain optimal ventilation and turn off all electrical appliances or evacuate the vicinity until a redress is made. An MQ- 9 chemical sensor coupled with an Integrated Circuit was used to build the system and on testing, the system gave adequate visual <b>information,</b> <b>audible</b> and timely alert on detecting a gas leakage...|$|R
40|$|In this paper, a {{model for}} the {{interaction}} of the strings with the frets in a guitar or other fretted string instruments is introduced. In the two-polarization representation of the string oscillations it is observed that the string interacts with the fret in different ways. While the vertical oscillation is governed by perfect or imperfect clamping of the string on the fret, the horizontal oscillation is subject to friction of the string over the surface of the fret. The proposed model allows, in particular, for the accurate evaluation of the elongation of the string in the two modes, which gives rise to <b>audible</b> <b>dynamic</b> detuning. The realization of this model into a structurally passive system for use in digital waveguide synthesis is detailed. By changing the friction parameters, the model can be employed in fretless instruments too, where the string directly interacts with the neck surface...|$|R
40|$|The {{purpose of}} the present study was to examine the {{benefits}} of providing audible speech to listeners with sensorineural hearing loss when the speech is presented in a background noise. Previous studies have shown that when listeners have a severe hearing loss in the higher frequencies, providing audible speech (in a quiet background) to these higher frequencies usually results in no improvement in speech recognition. In the present experiments, speech was presented in a background of multitalker babble to listeners with various severities of hearing loss. The signal was low-pass filtered at numerous cutoff frequencies and speech recognition was measured as additional high-frequency speech information was provided to the hearing-impaired listeners. It was found in all cases, regardless of hearing loss or frequency range, that providing audible speech resulted in an increase in recognition score. The change in recognition as the cutoff frequency was increased, along with the amount of <b>audible</b> speech <b>information</b> in each condition (articulation index), was used to calculate the "efficiency" of providing audible speech. Efficiencies were positive for all degrees of hearing loss. However, the gains in recognition were small, and the maximum score obtained by an listener was low, due to the noise background. An analysis of error patterns showed that due to the limited speech audibility in a noise background, even severely impaired listeners used additional speech audibility in the high frequencies to improve their perception of the "easier" features of speech including voicin...|$|R
40|$|Echolocation allows bats {{to orient}} and {{localize}} prey in complete darkness. The sonar beam {{of the big}} brown bat, Eptesicus fuscus, is directional but broad enough to provide <b>audible</b> echo <b>information</b> from within a 60 – 90 deg. cone. This suggests that the big brown bat could interrogate a natural scene without fixating each important object separately. We tested this idea by measuring the directional aim and duration of the bat's sonar beam as it performed in a dual task, obstacle avoidance and insect capture. Bats were trained to fly through one of two openings in a fine net to take a tethered insect at variable distances behind the net. The bats sequentially scanned {{the edges of the}} net opening and the prey by centering the axis of their sonar beam with an accuracy of ∼ 5 deg. The bats also shifted the duration of their sonar calls, revealing sequential sampling along the range axis. Changes in duration and directional aim were correlated, showing that the bat first inspected the hole, and then shifted its gaze to the more distant insect, before flying through the net opening. Contrary to expectation based on the sonar beam width, big brown bats encountering a complex environment accurately pointed and shifted their sonar gaze to sequentially inspect closely spaced objects {{in a manner similar to}} visual animals using saccades and fixations to scan a scene. The findings presented here from a specialized orientation system, echolocation, offer insights into general principles of active sensing across sensory modalities for the perception of natural scenes...|$|R
40|$|The report {{sets out}} a number of actions {{government}} will pursue in relation to improving access to TV, Cinema, DVD and internet downloads for people who are hearing or vision impaired. Media access includes the availability of captions, which assist Deaf people and people with a hearing impairment to access media, and audio description. Audio description provides <b>audible</b> background <b>information</b> about what is happening visually on a screen or TV in order to assist blind people or people with low vision to better understand the action. This final report follows on from two earlier consultation reports in 2008 and 2009 which sought views on a range of issues including the adequacy of captioning and audio description services, future targets and regulatory frameworks. In its submissions on the earlier reports the Commission focused on clarifying the rights of people with disability to access electronic media under existing discrimination law and the Australian Governments responsibilities to take all appropriate measures to ensure public and private bodies comply with the UN Convention on the Rights of Persons with Disabilities. The Government recommendations include: A move towards 100 % captioning on free to air TV between 6 am and 12 midnight by 2014 Establishing captioning levels for subscription TV following further discussion Amending the Broadcasting Services Act to better address captioning for both free to air and subscription TV Strengthening the power of ACMA to investigate complaints Improving access to emergency service announcements Trialing audio description on the ABC Providing online information for consumers on access features of set-top boxe...|$|R
40|$|The {{simulation}} of the dynamical behavior of pedestrians and crowds in spatial structures is a consolidated research and application context that still presents challenges for researchers in different fields and disciplines. Despite currently available commercial systems {{for this kind}} of simulation are growingly employed by designers and planners for the evaluation of alternative solutions, this class of systems is generally not integrated with existing monitoring and control infrastructures, usually employed by crowd managers and field operators for security reasons. This paper introduces the essentials and the related computational frame- work of an Integrated Crowd Management Support System based on a Collective Artificial Intelligence approach encompassing (i) interfaces from and to monitored and controlled environments (respectively, sen- sors and actuators), (ii) a set of software tools supporting the analysis of pedestrians and crowd phenomena taking place in the environment to feed a (iii) faster than real-time {{simulation of}} the plausible evolution of the current situation in order to support forms of inference provid- ing decision support to crowd managers, potentially directly controlling elements of the environment (e. g. blocking turnstiles, escalators), com- municating orders to operators on the field or trying to influence the pedestrians by means of <b>dynamic</b> signage or <b>audible</b> messages. Comment: 8 pages, 1 figur...|$|R
40|$|Physiological mechano-acoustic signals, {{often with}} {{frequencies}} and intensities {{that are beyond}} those associated with the <b>audible</b> range, provide <b>information</b> of great clinical utility. Stethoscopes and digital accelerometers in conventional packages can capture some relevant data, but neither is suitable {{for use in a}} continuous, wearable mode, and both have shortcomings associated with mechanical transduction of signals through the skin. We report a soft, conformal class of device configured specifically for mechano-acoustic recording from the skin, capable of being used on nearly any part of the body, in forms that maximize detectable signals and allow for multimodal operation, such as electrophysiological recording. Experimental and computational studies highlight the key roles of low effective modulus and low areal mass density for effective operation in this type of measurement mode on the skin. Demonstrations involving seismocardiography and heart murmur detection in a series of cardiac patients illustrate utility in advanced clinical diagnostics. Monitoring of pump thrombosis in ventricular assist devices provides an example in characterization of mechanical implants. Speech recognition and human-machine interfaces represent additional demonstrated applications. These and other possibilities suggest broad-ranging uses for soft, skin-integrated digital technologies that can capture human body acoustics...|$|R
40|$|Die vorliegende Arbeit stellt ein modulares Navigationssystem für die dentale Implantologie vor. Dentale Implantate sind Verankerungen im Knochen eines Patienten für Zahnprothesen. Die wichtigsten Anforderungen beim Setzen von Implantaten sind ein möglichst fester Sitz der Implantate im Knochen, die Schonung sensibler Strukturen, z. B. Nerven und Kieferhöhle, eine möglichst ästhetische Prothetik, eine hohe Langzeithaltbarkeit der Implantate im Knochen, die Möglichkeit der Sofortversorgung, schnell und genau durchführbare Eingriffe und ein Qualitätsnachweis der Versorgung. Navigationssysteme stellen dem Implantologen {{visuelle}} und akustische Informationen zur Verfügung, die ihm eine Positionierung und Ausrichtung des Bohrers zu präoperativ geplanten Implantaten ermöglichen. Die Planung der Implantlagen erfolgt auf der Grundlage von 3 D Bilddaten. Zur Generierung der Informationen für den Implantologen erfolgt während des Eingriffs die Messung der relativen Position und Ausrichtung des Bohrers zum Patienten. Dazu sind sowohl am Patienten als auch am Winkelstück (Bohrmaschine) des Implantologen Tracker (Lokalisatoren) angebracht. Durch die vollständige dreidimensionale Positions- und Ausrichtungsdarstellung bieten die Systeme eine umfangreiche intraoperative Unterstützung. Im Rahmen dieser Arbeit wurde das erste modulare, tragbare Navigationssystem für die dentale Navigation entwickelt und medizinisch zugelassen. Alle Komponenten des Systems, die mit dem Patienten in Berührung kommen, sind autoklavierbar (sterilisierbar). Das System ist Laptop basiert und im Gegensatz zu allen am Markt befindlichen Systemen unterschiedlich konfigurierbar und leicht zu transportieren (tragbar). Dieses Navigationssystem kann als Schulungssystem konfiguriert werden und ermöglicht somit einen breiten Zugang zu dieser Technologie. Die Ermittlung der Genauigkeit der Umsetzung von Planungsdaten bezüglich ihrer Winkel- und Positionsgenauigkeit ist Bestandteil des Systems. Die klinische Gesamtgenauigkeit wurde durch Messungen in postoperativ aufgenommen Röntgenbildern ermittelt. Durch die Realisierung eines konfigurierbaren Systems mit vollständig autoklavierbaren und ergonomischen Lokalisatoren ist die Praxistauglichkeit im Hinblick auf vergleichbare Systeme deutlich gestiegen. Im Rahmen einer internationalen multizentrischen klinischen Studie wurde die Qualität von navigiert gesetzten Implantaten nachgewiesen. Die vorgestellten Ergebnisse zeigen, dass das realisierte modulare Navigationssystem einen wichtigen Beitrag zur weiteren Etablierung dentaler Navigationssysteme im klinischen Alltag liefern kann. Des Weiteren können die in dieser Arbeit vorgestellten Konzepte und Realisierungen Anregungen für die weitere Entwicklung von computerassistierten Systemen in anderen Bereichen der computerassistierten Chirurgie geben. Timo Krüger, im Sommer 2006 This thesis {{presents a}} modular navigation system for dental implantology. Dental implants are anchors {{in the bone}} of a patient meant for dental prostheses. The main requirements for placing implants are a preferably firm fit in the jaw, the protection of sensitive structures, e. g. nerves and maxillary sinus, an aesthetic prosthodontics, a long term durability of the implants in the jaw, the possibility of immediate load, quick and precise feasible interventions and a verification {{of the quality of}} the medical care. Navigation systems provide the implantologist with visual and <b>audible</b> <b>information</b> that enables him to position and align the dental burr with respect to pre-operatively planned implants. The planning of the implant poses is based on 3 d image data. The pose information for the implantologist is generated by measuring the relative position and orientation of the burr during the intervention with regard to the patient. For that, trackers (localizer) are fit to the patient as well as to the surgical instrument (drill). Due to the complete three-dimensional visualization of position and orientation the systems provide wide inter-operative support. Within the scope of this work the first modular, portable navigation system for dental implantology has been developed and approved according to the medical device directive. All system components that are likely to contact the patient are autoclavable (sterilizable). The system is laptop based and in contrast to all other commercial systems, it can be configured variable and is easy to transport. The presented navigation system can be set up as training system, thus, offering a broad access to this technology. Accuracy determination of the transference of the implant planning regarding angulation and position accuracy is provided by the system. The clinical overall accuracy has been found by comparative measurements in post-operative projection images. With the accomplishment of a configurable system with completely autoclavable and ergonomic localizers the suitability for daily use has been increased noticeably as to comparable systems. The quality of implants placed with navigation support has been demonstrated within the scope of an international multicenter clinical study. The presented results show that the accomplished modular navigation system contributes considerably to the further establishment of navigation technology in the clinical routine of dental implantology. In addition, the concepts and implementations presented in this work can animate other developments of assist systems for computer assisted surgery in different clinical fields. Timo Krüger, Summer 200...|$|R
50|$|In South America, {{they are}} used in Quito, São Paulo, Curitiba, Santiago and Bogotá.In Adelaide, Australia, {{articulated}} buses are used on the O-Bahn guided busway, reaching speeds of 100 km/h. The first articulated buses to use it were the Mercedes-Benz O305G buses; however, three MAN SG280H buses are also equipped for O-Bahn use. In recent years, it has proven problematic to find suitable low-floor articulated buses to replace the 1984-manufactured Mercedes buses, because {{the design of the}} O-Bahn track unfortunately precludes the use of most modern articulated buses. Sydney, Australia has seen the operation of articulated buses for many years. Currently it operates a fleet of various models with eighty Volvo B12BLEA buses joining the Sydney Buses fleet in 2005 and 2006, increasing capacity along many of the busy corridors. A number of prototype vehicles were delivered in 2008 & 2009 to operate on Sydney Buses' first Metrobus route, the M10 from Leichhardt to Kingsford and Maroubra Junction. The buses feature different chassis, body types, and internal layouts. The articulated Volvo B12BLEA buses are fully wheelchair-accessible, air-conditioned, and have visual and <b>audible</b> next-stop passenger <b>information</b> systems installed. The buses feature air-conditioning, large electronic destination displays and cloth seating. Additionally, each bus features a stepless entry, which will assist less-mobile passengers. Flip-up seats in the front part of the bus allow easy accommodation for passengers in wheelchairs and with strollers and prams. In 2009-2010 150 new Volvo B12BLEA articulated buses have been introduced into the Sydney Buses fleet, many of these part of the expanded Metrobus program.|$|R
