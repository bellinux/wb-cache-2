95|203|Public
50|$|In {{a random}} dot {{autostereogram}}, the 3D image is usually {{shown in the}} middle of the autostereogram against a background <b>depth</b> <b>plane</b> (see the shark autostereogram). It may help to establish proper convergence first by staring at either the top or the bottom of the autostereogram, where patterns are usually repeated at a constant interval. Once the brain locks onto the background <b>depth</b> <b>plane,</b> it has a reference convergence degree from which it can then match patterns at different depth levels {{in the middle of}} the image.|$|E
50|$|The {{following}} autostereogram shows {{three rows}} of repeated patterns. Each pattern is repeated {{at a different}} interval to place it on a different <b>depth</b> <b>plane.</b> The two non-repeating lines {{can be used to}} verify correct wall-eyed viewing. When the autostereogram is correctly interpreted by the brain using wall-eyed viewing, and one stares at the dolphin {{in the middle of the}} visual field, the brain should see two sets of flickering lines, as a result of binocular rivalry.|$|E
50|$|When one moves one's {{attention}} from one <b>depth</b> <b>plane</b> to another (for instance, {{from the top}} row of the chessboard to the bottom row), the two eyes need to adjust their convergence to match the new repeating interval of patterns. If the level of change in convergence is too high during this shift, sometimes the brain can lose the hard-earned decoupling between focusing and convergence. For a first-time viewer, therefore, it may be easier to see the autostereogram, if the two eyes rehearse the convergence exercise on an autostereogram where the depth of patterns across a particular row remains constant.|$|E
50|$|Unlike {{the simple}} <b>depth</b> <b>planes</b> created by simple {{wallpaper}} autostereograms, subtle changes in spacing {{specified by the}} depth map can {{create the illusion of}} smooth gradients in distance. This is possible because the grayscale depth map allows individual pixels to be placed on one of 2n <b>depth</b> <b>planes,</b> where n is the number of bits used by each pixel in the depth map. In practice, the total number of <b>depth</b> <b>planes</b> is determined by the number of pixels used for the width of the pattern image. Each grayscale value must be translated into pixel space in order to shift pixels in the final autostereogram. As a result, the number of <b>depth</b> <b>planes</b> must be smaller than the pattern width.|$|R
40|$|Visual {{search is}} often {{conducted}} in 3 -D space. However, {{little is known}} about search behaviour in 3 -D space. Two different hypotheses have been put forward as to how stereoscopic depth cues can be used to enhance search efficiency: either by splitting the visual scene into <b>depth</b> <b>planes,</b> which are subsequently searched in turn (Nakayama and Silverman, 1986 Nature 320 264 - 265), or by grouping of similar visual information (even across 3 -D space) into 'kernels', which are then searched in turn (Chau and Yeh, 1995 Perception Psychophysics 57 1032 - 1044). We contrasted these two hypotheses by studying two conjunctive searches with stereoscopic depth and colour. In experiment 1 this search was conducted across two <b>depth</b> <b>planes</b> and in experiment 2 across six <b>depth</b> <b>planes.</b> The six <b>depth</b> <b>planes</b> were subdivided into two triplets of <b>depth</b> <b>planes,</b> with the relative disparity 'within' a triplet being smaller than 'between' the two triplets, so that the two triplets appeared as two perceptually different kernels with similar chromatic and stereoscopic depth information. If the visual system splits up the visual scene into <b>depth</b> <b>planes</b> (as suggested by Nakayama and colleagues), search performance should be higher with six <b>depth</b> <b>planes</b> than with two. In contrast, if the visual system uses the chromatic and stereoscopic depth information to group similar visual information into kernels, visual-search performance should not differ appreciably between the two experiments (as suggested by Chau and Yeh, 1995 loco cit.), given that both displays consist of two perceptually different kernels. Our results indicate that search performance did not differ significantly between the experiments and search times were unaffected by the number of <b>depth</b> <b>planes.</b> Our data, thus, supports the hypothesis that the visual system groups similar visual information into kernels and then searches these kernels in turn...|$|R
50|$|Remember {{that color}} numbers are formed by pixels in the {{destination}} bitmap (<b>depth</b> <b>planes</b> deep) {{not in the}} source bitmap (numPlanes planes deep).|$|R
5000|$|While {{there are}} six dolphin {{patterns}} in the autostereogram, the brain should see seven [...] "apparent" [...] dolphins on {{the plane of the}} autostereogram. This is a side effect of the pairing of similar patterns by the brain. There are five pairs of dolphin patterns in this image. This allows the brain to create five apparent dolphins. The leftmost pattern and the rightmost pattern by themselves have no partner, but the brain tries to assimilate these two patterns onto the established <b>depth</b> <b>plane</b> of adjacent dolphins despite binocular rivalry. As a result, there are seven apparent dolphins, with the leftmost and the rightmost ones appearing with a slight flicker, not dissimilar to the two sets of flickering lines observed when one stares at the 4th apparent dolphin.|$|E
40|$|Four {{experiments}} investigated whether directing {{attention to}} a particular plane in depth enables observers to filter out information from another <b>depth</b> <b>plane.</b> Observers viewed stereoscopic displays and searched for a red line segment among green line segments. The results showed that directing {{attention to a}} particular <b>depth</b> <b>plane</b> cannot prevent attentional capture from another <b>depth</b> <b>plane</b> when {{the colors of the}} target and distractor are identical. However, it can prevent attentional capture by a singleton from another <b>depth</b> <b>plane</b> when the colors of the target and distractor are different. These results indicate that only when both color and depth information are selective in guiding attention to the target singleton can attentional capture by irrelevant singletons be prevented. The results also suggest that retinal disparity does not have the same special status as location information in two dimensions and should be considered as just another feature along which selection may occu...|$|E
40|$|Depth {{sensitivity}} enhanced computational integral imaging with structured illumination is proposed. Two sets of the elemental {{images are}} picked up under structured and normal illumination. Modified computational integral imaging technique {{is applied to}} the captured elemental images to reconstruct the <b>depth</b> <b>plane</b> images of the objects. Simulation results show that the proposed system detects the correct <b>depth</b> <b>plane</b> images of the objects effectively. 1...|$|E
40|$|AbstractA {{generally}} accepted notion in binocular vision {{is that we}} see the world as if viewed by a single eye, the cyclopean eye. A consequence of seeing the world from a single point in space is that the outlines of occluding and occluded surfaces have the same shape. We designed stereograms in which subjects aligned binocularly visible lines to each other. The lines were lying in different <b>depth</b> <b>planes.</b> In the vicinity of occluded areas, binocular alignment was achieved by alignment of the lines in the eye that viewed the monocularly visible details. Stereograms in which shapes of surfaces lying in different <b>depth</b> <b>planes</b> were compared to each other show that occluding and occluded surfaces {{do not have the}} same shape: a square surface occludes rectangular surfaces in other <b>depth</b> <b>planes</b> of which the horizontal widths are smaller than the vertical widths. This difference in perceived shape is not possible if the centre of binocular direction has a fixed position in the head. Copyright © 1996 Elsevier Science Ltd...|$|R
40|$|AbstractIn four experiments, {{participants}} had to detect symmetries or repetitions distributed over two <b>depth</b> <b>planes,</b> under presentation times of 200 – 1000 ms. Structurally corresponding elements {{were placed in}} different planes (Experiments 1 a and 1 b) or in the same plane (Experiments 2 a and 2 b). Results suggest (a) an ongoing interaction between regularity cues and depth cues, and (b) that efficient detection of symmetry but not of repetition depends on structural correspondences within <b>depth</b> <b>planes.</b> The latter confirms the idea that, to perceptual organization, symmetry is a cue {{for the presence of}} one object, whereas repetition is a cue for the presence of multiple objects...|$|R
40|$|Many {{activities}} necessitate {{the deployment}} of attention to specific distances and directions in our three-dimensional (3 D) environment. However, most research on how attention is deployed is conducted with two dimensional (2 D) computer displays, leaving a large gap in our understanding about {{the deployment of}} attention in 3 D space. We report how each of four parameters of 3 D visual space influence visual search: 3 D display volume, distance in depth, number of <b>depth</b> <b>planes,</b> and relative target position in depth. Using a search task, we find that visual search performance depends on 3 D volume, relative target position in depth, and number of <b>depth</b> <b>planes.</b> Our results demonstrate an asymmetrical preference for targets {{in the front of}} a display unique to 3 D search and show that arranging items into more <b>depth</b> <b>planes</b> reduces search efficiency. Consistent with research using 2 D displays, we found slower response times to find targets in displays with larger 3 D volumes compared with smaller 3 D volumes. Finally, in contrast to the importance of target depth relative to other distractors, target depth relative to the fixation point did not affect response times or search efficiency...|$|R
40|$|When {{one pair}} of dots is located in an object, the {{perceived}} space between those two dots {{is larger than the}} space of two dots which have same interval and are placed out of object. This is space distortion. Two experiments were performed to investigate the effect of binocular disparities on space distortion. The <b>depth</b> <b>plane</b> of surrounding object (in experiment 1) and of two pairs of dots (in experiment 2) was manipulated. The results showed that when objects or dots were perceived on a different <b>depth</b> <b>plane</b> from an original <b>depth</b> <b>plane,</b> the strength of space distortion was reduced. These results imply that space distortion is more related to early visual processing than attention...|$|E
30|$|One {{commonly}} used advantage of 3 D {{is the ability}} to portray motion in the <b>depth</b> <b>plane</b> (e.g., motion toward or away from the viewer). This effect is often used in production. However, fast depth motion can lead to visual discomfort [16, 17]. The non-translational motion behavior (i.e., motion in the <b>depth</b> <b>plane)</b> challenges video coding algorithms, causing the appearance of different artifacts in the two views, which often results in binocular rivalry.|$|E
40|$|Selective {{attention}} modulates perceptual {{learning in}} motion speed, but previous studies {{were unable to}} answer whether selective attention modulates learning by enhancing the attended signal, suppressing the ignored signal, {{or a combination of}} the two. We investigated this question by separating the attended/ignored signals in two disparity-defined depths. The learning stimuli contain speed change in one specific direction (target direction) at one specific <b>depth</b> <b>plane</b> (target depth), with another <b>depth</b> <b>plane</b> (non-target depth) containing either nothing (control group), or distractor dots moving in random direction random-direction group) or orthogonal to target direction (orthogonal-direction group). Observers' 80 %-correct motion coherence detection thresholds at two depth planes were measured before and after six hourly sessions of speed discrimination. After learning, observers' motion sensitivity increased by an average 23 % at target <b>depth</b> <b>plane</b> at all tested directions in all three conditions, {{as well as at the}} non-target <b>depth</b> <b>plane</b> when no distractors were present (control condition) (21 %). At conditions where clearly visible moving distractors in either non-specific (random) or specific (orthogonal) direction, there is a clear disadvantage at the distractor direction(s) (6 %, 0 %). Our results strongly suggest that selective attention modulates motion speed learning largely by suppressing visible irrelevant stimuli. The 32 nd European Conference on Visual Perception, Regensburg, Germany, 24 - 28 August 2009. In Perception, v. 38, abstract suppl., p. 13...|$|E
50|$|Parallax {{scanning}} depth enhancing imaging methods rely on discrete parallax differences between <b>depth</b> <b>planes</b> in a scene. The differences {{are caused by}} a parallax scan. When properly balanced (tuned) and displayed, the discrete parallax differences are perceived by the brain as depth.|$|R
40|$|One {{objective}} of painterly rendering is to convert photographic images into renderings that {{look as if}} they have been painted by an artist. Previous research has drawn inspiration from a variety of artists, but we believe that further advances require an in depth exploration of a particular artist. We describe a new painterly rendering algorithm modeled after Cezanne's methodology. Our system takes an input image and user defined <b>depth</b> <b>planes,</b> and with these creates a "painting. " We use a combination of image processing techniques to mimic Cezanne's process. The main steps are choosing a subject, defining <b>depth</b> <b>planes,</b> selecting a color palette, defining outlines, creating and applying strokes, and tracing the outlines. Modeling our system after a painter's methods provides a road map to take us from a subject to a painting. The painters we copy introduce us to new painting techniques, in our case the use of color planes. By combining images with <b>depth</b> <b>planes,</b> we are able to create paintings that have arbitrary complexity and depth. The concept of a painter's palette is introduced, along with a technique for choosing the colors. A new brush model gives strokes the natural shape and texture variation typical of hand painted strokes. iii Acknowledgments I would like to thank my advisor John Hughes for his guidance and valuable feedback. I would als...|$|R
40|$|We use {{a single}} phase-only spatial light {{modulator}} and an iterative phase retrieval method to directly modulate the light at multiple planes inside the eye. By changing the focal length of the eye, images at different <b>depth</b> <b>planes</b> are sharply projected onto the retina, with which we mimic the accommodation of natural vision...|$|R
40|$|Two {{experiments}} {{were conducted to}} investigate how color and stereoscopic depth information are used to segregate objects for visual search in three-dimensional (3 -D) visual space. Eight observers {{were asked to indicate}} the alphanumeric category (letter or digit) of the target which had its unique color and unique <b>depth</b> <b>plane.</b> In Experiment 1, distractors sharing a common <b>depth</b> <b>plane</b> or a common color appeared in spatial contiguity in the xy plane. The results suggest that visual search for the target involves examination of kernels formed by homogeneous items sharing the same color and depth. In Experiment 2, the xy contiguity of distractors sharing a common color or a common <b>depth</b> <b>plane</b> was varied. The results showed that when target-distractor distinction becomes more difficult on one dimension, the other dimension becomes more important in performing visual search, as indicated by a larger effect on search time. This suggests that observers can make optimal use of the information available. Finally, color had a larger effect on search time than did stereoscopic depth. Overall, the results support models of visual processing which maintain that perceptual segregation and selective attention are determined by similarity among objects in 3 -D visual space on both spatial and nonspatial stimulus dimensions. © 1995 Psychonomic Society, Inc. link_to_subscribed_fulltex...|$|E
30|$|The layer-based {{representation}} {{is an extension}} of the EPI line concept. The representation partitions the multiview data into homogenous regions, where each layer is a collection of EPI lines modelled by a constant <b>depth</b> <b>plane.</b> An example of a layer-based {{representation is}} shown in Figure 1.|$|E
40|$|Disparity-evoked vergence is {{studied in}} stereograms showing {{one or two}} depth planes which are defined by {{isolated}} dots of varying density and contrast. Vergence position immediately after stimulus presentation was measured using a psychophysical technique (dichoptic nonius lines). In the unequivocal stimuli (one <b>depth</b> <b>plane),</b> elicited vergence was in accordance with earlier findings. If two depth planes are presented, elicited vergence lies between the two planes, approaching the plane with higher dot density and/or dot contrast. In quantitative measurements, we show that the involved depth averaging mechanism uses signal power per <b>depth</b> <b>plane</b> as a weight. Therefore, the relative pulling strength of dot density as compared to dot contrast follows a power law with exponent 2. We propose a population code for vergence control based on disparity-tuned pools of units...|$|E
40|$|Abstract- Recently, {{a variety}} of {{stereoscopic}} contents have been provided to academic and industrial fields for broadcasting, movies and mobile materials. However, few works {{have been interested in}} the adjustment of 3 D contents for diverse displays. For instance, movie contents suited to large screen frequently do not deliver the same 3 D perception to small-size screen such as mobile phone, tabular PCs, etc. For this, this paper presents an adjustment method of stereoscopic contents. 2 D+Depth is one of popular methods with which stereoscopic images are generated. For this, <b>depth</b> <b>planes</b> are derived based on a depth histogram. By adjusting <b>depth</b> <b>planes,</b> a new <b>depth</b> map is made. Then 2 D+Depth produces a stereoscopic image. Experiments performed on various 2 D+Depth images validate that the proposed methods deliver more enhanced 3 D depth based on subjective evaluation experiments...|$|R
40|$|Stereoscopic {{vision is}} {{extremely}} precise in detecting minute differences between adjacent <b>depth</b> <b>planes,</b> but quite imprecise in estimating absolute depth. In this paper, we {{address the issue}} of the spatial acuity (and not the stereo acuity) of stereopsis. Static RDS (random dot stereograms) stimuli were used to find the spatial grain in which human stereoscopic vision operates...|$|R
5000|$|Smallgantics is {{a digital}} image process that {{accurately}} simulates miniature {{depth of field}} (DOF) on full-scale filmed subjects via a [...] "hand-made" [...] digital application. Artificial <b>depth</b> <b>planes,</b> up to 8 layers, are generated by the artist, which distort with each frame of a sequence, giving the artist complete control of a simulated miniature DOF scenario.|$|R
40|$|Gratings with {{different}} disparities are sometimes seen as transparent surfaces, {{each with a}} distinct depth, when they are superimposed, and sometimes they {{are seen as a}} coherent plaid confined to a single depth plane—stereo analogs of transparent and coherent motion. Briefly presented sinusoidal gratings of similar spatial frequencies are seen to cohere in depth. The resulting plaid generally appears in a <b>depth</b> <b>plane</b> different from that of either component grating viewed separately; the plaid may even appear on the oppose side of fixation from the component gratings. Under similar viewing conditions, squarewave gratings are typically seen as transparent. Objective measures, gathered here using depth-order discriminations, show that the perception of transparency between squarewave gratings requires a minimum disparity difference that varies with the gratings ’ orientations. Gratings that are near orthogonal in orientation, or that give the plaid a near-horizontal disparity, favor the perception of coherence. Gratings that form a plaid having a large ratio of vertical to horizontal disparities favor the perception of transparency. The data are consistent with a Bayesian prior favoring single surfaces when disparities are small and near-horizontal. Disparities that are large or non-horizontal {{are more likely to be}} aperture disparities that result from viewing separate but overlapping surfaces. The sinewave-squarewave difference leads to the conclusion that coherence between components is required both for seeing a broadband pattern in a single <b>depth</b> <b>plane</b> and for seeing it in a different <b>depth</b> <b>plane</b> from other superimposed patterns...|$|E
40|$|Selective {{attention}} {{determines the}} effectiveness of implicit contextual learning (e. g., Jiang & Leung, 2005). Visual foreground-background segmentation, on the other hand, is a key process in the guidance of attention (Wolfe, 2003). In the present study, we examined the impact of foreground-background segmentation on contextual cueing of visual search in three experiments. A visual search display, consisting of distractor ‘L’s and a target ‘T’, was overlaid on a task-neutral cuboid on the same <b>depth</b> <b>plane</b> (Experiment 1), on stereoscopically separated depth planes (Experiment 2), or spread over the entire display on the same <b>depth</b> <b>plane</b> (Experiment 3). Half of the search displays contained repeated target-distractor arrangements, whereas the other half was always newly generated. The task-neutral cuboid was constant during an initial training session, but was either rotated by 90 º or entirely removed in the subsequent test sessions. We found that the gains resulting from repeated presentation of display arrangements during training (i. e., contextual-cueing effects) were diminished when the cuboid was changed or removed in Experiment 1, but remained intact in Experiments 2 and 3 when the cuboid {{was placed in a}} different <b>depth</b> <b>plane,</b> or when the items were randomly spread over the whole display but not on the edges of the cuboid. These findings suggest that foreground-background segmentation occurs prior to contextual learning, and only objects/arrangements that are grouped as foreground are learned over the course of repeated visual search...|$|E
40|$|AbstractDisparity-evoked vergence is {{studied in}} stereograms showing {{one or two}} depth planes which are defined by {{isolated}} dots of varying density and contrast. Vergence position immediately after stimulus presentation was measured using dichoptic nonius lines. Since the stimulus was not visible after {{the onset of the}} vergence movement, the experiment accesses the initiation of vergence rather than its eventual result. In the unequivocal stimuli (one <b>depth</b> <b>plane),</b> elicited vergence tends to reduce disparity. Disparities of 0. 5 – 1 deg are most effective which is in accordance with earlier findings. If two depth planes are presented, elicited vergence lies between the two planes, approaching the plane with higher dot density and/or dot contrast. In quantitative measurements, we show that the depth-averaging mechanism uses signal power per <b>depth</b> <b>plane</b> as a weight. Therefore, the relative pulling strength of dot density compared with dot contrast follows a power law with exponent 2. We propose a population code for vergence control based on disparity-tuned pools of units. Copyright © 1996 Elsevier Science Ltd...|$|E
40|$|AbstractThe {{relative}} importance of contrast and assimilation for determining the perceived brightness was estimated. Assimilation decreased when a test spot had such a binocular disparity that the spot and its background appeared on different <b>depth</b> <b>planes</b> respectively. However, contrast was not affected by the binocular depth cue. These {{results indicate that the}} cortex takes an important role in assimilation process...|$|R
40|$|Purpose. Recent {{computational}} and neurophysiological {{findings suggest}} {{the existence of}} binocular complex cells that jointly encode motion and stereoscopic depth. Dichoptically presented gratings flickering in spatio-temporal quadrature can induce directional motion perception but {{the existence of an}} early binocular motion system is a debated issue. Here we investigated perception of dichoptic motion for stimuli defined on different <b>depth</b> <b>planes.</b> Methods. Stimuli were presented to the left and right eye on a calibrated CRT display with a refresh rate of 120 Hz using a split-screen Wheatstone configuration. On each trial Ss verged on a fixation-cross flanked by nonius lines before two vertical sine-wave gratings of 1. 1 c/deg were presented in dichoptic view. The gratings were displayed in a circular aperture for 200 msec flickering in temporal quadrature. After each presentation Ss indicated whether direction of motion was left or right. In three conditions disparity of the stimulus was set to − 8, 0, or + 8 arc min whereas spatial phase offset between gratings varied between pi/ 2 and 3 pi/ 2 in randomly intermixed trials. Spatial and temporal phase of the gratings were randomised across trials. Results. Although stimuli appeared on different <b>depth</b> <b>planes</b> psychometric functions shifted systematically with disparity. Discrimination of motion direction was best when phase offset together with horizontal disparity resulted in spatial quadrature. No reliable discrimination performance was obtained for stimuli with static pedestal, flicker frequencies beyond 4 Hz, and disparities outside Panum's fusional area. Conclusions. The present result does not support the notion of an early binocular motion system that can integrate dichoptic motion at different <b>depth</b> <b>planes...</b>|$|R
40|$|This paper {{presents}} {{a method of}} stereoscopic panoramic video generation including techniques for panorama projection, stitching and calibration for various <b>depth</b> <b>planes.</b> The methods described {{can be used on}} video sequences captured by an arrangement of multiple pairs of cameras or multiple stereoscopic cameras mounted on a regular polygonal shaped camera rig. Algorithms can also be used in combination or separately, for generating both stereoscopic and monoscopic video and still panoramas...|$|R
30|$|Fast {{motion was}} already {{mentioned}} for 2 D sequences (e.g., include one high motion clip). Fast planar motion (i.e., motion {{parallel to the}} screen) becomes an important feature for 3 D, because it can introduce visual discomfort in 3 D viewing [18, 19]. The magnitude of visual discomfort caused by objects moving in the <b>depth</b> <b>plane</b> depends on the position {{and size of the}} object, as well as its motion amplitude and speed [20].|$|E
40|$|AbstractWe {{examined}} visual {{search for}} letters that were distributed across both 3 dimensional space, and time. In Experiment 1, when participants had foreknowledge of the <b>depth</b> <b>plane</b> and time interval where targets could appear, search was more efficient if the items could be segmented either by depth or by time (with a 1000 ms preview), {{and there were}} increased benefits when the two cues (depth and time) were combined. In Experiments 2 and 3 the target <b>depth</b> <b>plane</b> was always unknown to the participant. In this case, depth cues alone did not facilitate search, though they continued to increase the preview benefit. In Experiment 4 new items in preview search could fall at the same depth as preview items or a new depth. There was a substantial cost to search if the target appeared at a previewed depth. Experiment 5 showed that this cost remained even when participants knew the target would appear at the old depth on 75 % of trials. The results indicate that spatial (depth) and temporal cues combine to enhance visual segmentation and selection, and this is accomplished by inhibition of distractors in irrelevant depth planes...|$|E
40|$|Three-month-olds are {{sensitive}} to orientation changes of line drawings {{when they have a}} three-dimensional (3 -D) interpretation and when the changes are defined by both 3 -D depth and two-dimensional (2 -D) picture plane cues [Bhatt, R. S., & Bertin, E. (2001). Pictorial cues and three-dimensional information processing in early infancy. Journal of Experimental Child Psychology, 80, 315 - 332]. In the current study, we examined whether 3 -month-olds {{are sensitive}} to pictorial line junction cues that signal orientation changes solely in the 3 -D <b>depth</b> <b>plane.</b> The results revealed that infants discriminated a misoriented elongated cube in an array when the stimuli contained both shading and lines (Experiment 2) but not when only lines depicted the elongated cubes (Experiment 1). Testing with comparable 2 -D images revealed that, even in the presence of shading information, detection of orientation changes is specific to images that have a 3 -D interpretation. Together, the results suggest that 3 -month-olds {{are sensitive to}} pictorial line junction cues that signal orientation changes in the 3 -D <b>depth</b> <b>plane</b> to adults provided that shading information is available and the images have a 3 -D interpretation...|$|E
40|$|International audienceIn {{studies of}} 2 D visual attention, {{eye-tracking}} data show a so-called "center-bias", {{which means that}} fixationsare biased towards the center of 2 D still images. However, in stereoscopic visual attention, depth is anotherfeature having great influence on guiding eye movements. Relatively {{little is known about}} the impact of depth. Several studies mentioned that people tend to look at the objects at certain <b>depth</b> <b>planes.</b> Therefore, it isreasonable to suppose the existence of a "depth-bias". But studies proving or quantifying this depth-bias arestill limited. We conducted a binocular eye-tracking experiment by showing synthetic stimuli on a stereoscopicdisplay. Observers were required to do a free-viewing task through active shutter glasses. Gaze positions ofboth eyes were recorded for obtaining the depth of fixation. Stimuli were well designed in order to let thecenter-bias and depth-bias affect eye movements individually. Results showed that the number of fixationsvaried as a function of <b>depth</b> <b>planes.</b> There was also a relationship between the duration of fixation and thedepth plane where the objects were located...|$|R
5000|$|The optical <b>depth</b> of a <b>plane</b> {{parallel}} {{cloud layer}} {{is given by}} ...|$|R
50|$|However, icons {{in a row}} do {{not need}} to be {{arranged}} at identical intervals. An autostereogram with varying intervals between icons across a row presents these icons at different <b>depth</b> <b>planes</b> to the viewer. The depth for each icon is computed from the distance between it and its neighbor at the left. These types of autostereograms are designed to be read in only one way, either cross-eyed or wall-eyed. All autostereograms in this article are encoded for wall-eyed viewing, unless specifically marked otherwise. An autostereogram encoded for wall-eyed viewing will produce inverse patterns when viewed cross-eyed, and vice-versus. Most Magic Eye pictures are also designed for wall-eyed viewing.|$|R
