140|220|Public
2500|$|In general, DNA polymerases {{are highly}} accurate, with an <b>intrinsic</b> <b>error</b> rate {{of less than}} one mistake for every 107 {{nucleotides}} added. [...] In addition, some DNA polymerases also have proofreading ability; they can remove nucleotides {{from the end of}} a growing strand in order to correct mismatched bases. Finally, post-replication mismatch repair mechanisms monitor the DNA for errors, being capable of distinguishing mismatches in the newly synthesized DNA strand from the original strand sequence. Together, these three discrimination steps enable replication fidelity of less than one mistake for every 109 nucleotides added.|$|E
50|$|Algorithm error: is the <b>intrinsic</b> <b>error</b> of the {{algorithm}} {{used for the}} solution of the approximating problem.|$|E
5000|$|... #Caption: The Jalali {{calendar}} {{was introduced}} by Omar Khayyám alongside other Mathematicians and Astronomers in Nishapur, today {{it is one of}} the oldest calendars in the world as well as the most accurate solar calendar in use today. Since the calendar uses astronomical calculation for determining the vernal equinox, it has no <b>intrinsic</b> <b>error,</b> but this makes it an observation based calendar.|$|E
40|$|Summary. This {{contribution}} {{provides an}} introduction to the concept of drift and diffusion functions for complex dynamical systems such as wind energy converters. These functions easily can be estimated from measured data. However, one has to be aware about <b>intrinsic</b> <b>errors</b> in the estimation procedure that are discussed in the following. ...|$|R
40|$|AbstractWe {{discuss the}} {{trade-off}} between sampling and quantization in signal processing {{for the purpose}} of minimizing the error of the reconstructed signal subject to the constraint that the digitized signal fits in a given amount of memory. For signals with different regularities, we estimate the <b>intrinsic</b> <b>errors</b> from finite sampling and quantization, and determine the sampling and quantization resolutions...|$|R
40|$|An {{important}} {{objective in}} the evaluation of algorithms with sensory inputs is the development of measures characterizing the <b>intrinsic</b> <b>errors</b> in the results. <b>Intrinsic</b> are those <b>errors</b> which are caused by noise in the input data. The particular application which we consider is 3 -D reconstruction from stereo. We demonstrate that a radiometric correction of the images could improve signi cantly the accuracy. We propose a con dence interval approach for quantifying the precision. We also illustrate the use of the con dence intervals for the rejection of unreliable 3 D points...|$|R
5000|$|In general, DNA polymerases {{are highly}} accurate, with an <b>intrinsic</b> <b>error</b> rate {{of less than}} one mistake for every 107 {{nucleotides}} added. [...] In addition, some DNA polymerases also have proofreading ability; they can remove nucleotides {{from the end of}} a growing strand in order to correct mismatched bases. Finally, post-replication mismatch repair mechanisms monitor the DNA for errors, being capable of distinguishing mismatches in the newly synthesized DNA strand from the original strand sequence. Together, these three discrimination steps enable replication fidelity of less than one mistake for every 109 nucleotides added.|$|E
5000|$|The Solar Hijri (Persian) {{calendar}} {{is one of}} {{the oldest}} calendars in the world, as well as the most accurate solar calendar in use today. Since the calendar uses astronomical calculation for determining the vernal equinox, it has no <b>intrinsic</b> <b>error,</b> but this makes it an observation based calendar. [...] Ahmad Birashk proposed an alternative means of determining leap years. His technique avoids the need to determine the moment of the astronomical equinox, replacing it with a very complex leap year structure. Years are grouped into cycles which begin with four normal years after which every fourth subsequent year in the cycle is a leap year. Cycles are grouped into grand cycles of either 128 years (composed of cycles of 29, 33, 33, and 33 years) or 132 years, containing cycles of 29, 33, 33, and 37 years. A great grand cycle is composed of 21 consecutive 128-year grand cycles and a final 132 grand cycle, for a total of 2820 years. The pattern of normal and leap years which began in 1925 will not repeat until the year 4745.|$|E
40|$|<b>Intrinsic</b> <b>error</b> {{field on}} EAST is {{measured}} using the 'compass scan' technique with different n[*][*]=[*][*] 1 magnetic perturbation coil configurations in ohmically heated discharges. The <b>intrinsic</b> <b>error</b> field measured using a non-resonant dominated spectrum with even connection {{of the upper}} and lower resonant magnetic perturbation coils is of the order b_r 2, 1 /B_T≃ 10 ^- 5 and the toroidal phase of <b>intrinsic</b> <b>error</b> field is around 60 ^^∘. A clear difference between the results using the two coil configurations, resonant and non-resonant dominated spectra, is observed. The 'resonant' and 'non-resonant' terminology is based on vacuum modeling. The penetration thresholds of the non-resonant dominated cases are much smaller than that of the resonant cases. The difference of penetration thresholds between the resonant and non-resonant cases is reduced by plasma response modeling using the MARS-F code...|$|E
40|$|In this work, a novel type of nanolens {{based on}} super {{oscillation}} {{theory has been}} developed and fabricated. A self-aligned nanolithography process is developed to achieve error-free structured nanolens without the need of complex registration which always carries <b>intrinsic</b> <b>errors.</b> This fabrication technique significantly simplifies the process and reduces the production costs consequently. The success of this process {{will enable us to}} achieve focusing and imagining beyond diffraction limit, which will be presented in other communications...|$|R
2500|$|Also, {{it must be}} {{stressed}} that the Heisenberg formulation is not {{taking into account the}} <b>intrinsic</b> statistical <b>errors</b> [...] and [...] [...] There is increasing experimental evidence ...|$|R
40|$|Any {{measurement}} system has imperfections and any act of measurement {{is liable to}} errors. Measurement errors either originate from system deficiencies (for instance system noise, quantization, and drift), or are due to environmental influences such as thermal, electromagnetic, and mechanical interference. Manufacturers of measuring instruments try to minimize such <b>intrinsic</b> <b>errors</b> by a proper design of the instrument structure; the remaining imperfections should be given in the data sheets of the system. The user of a {{measurement system}} should minimize additional errors that could arise from improper use and faulty interfacing...|$|R
40|$|The aim of {{the present}} study was to assess the {{clinical}} relevance of the potential mechanical error (<b>intrinsic</b> <b>error)</b> caused by the cylinder-burr gap in a 'single type' stereolithographic surgical template in implant guided surgery. 129 implants were inserted in 12 patients using 18 templates. The pre- and postoperative computed tomography (CT) scans were matched allowing comparison of the planned implants with the placed ones. Considering only the angular deviation values, the t test was used to determine the influence of the guide fixation and the arch of support on accuracy values. The Pearson correlation coefficient was used to correlate angular deviation and bone density. The <b>intrinsic</b> <b>error</b> was mathematically evaluated. t test results indicated that the use of fixing screws (P = 009) and the upper arch support (P = 027) resulted in better accuracy. The Pearson correlation coefficient (0. 229) indicated a significant linear correlation between angular deviations and bone density (P = 009). A mean <b>intrinsic</b> <b>error</b> of 2. 57 was mathematically determined considering only the angular deviation, as it was not influenced by other variables. The <b>intrinsic</b> <b>error</b> is a significant factor compared to all the variables that could potentially affect the accuracy of computer-aided implant placement. © 2012 International Association of Oral and Maxillofacial Surgeons...|$|E
30|$|In {{order to}} {{compensate}} for the <b>intrinsic</b> <b>error</b> caused by the nonuniform internal electric field, while still keeping the other assumptions used in the linear model, Wei et al. [13] suggested the following nonlinear model.|$|E
30|$|To give {{an idea of}} the <b>intrinsic</b> <b>error</b> {{resilience}} of distributed source coding, in this section we present a simple explicative example. In this example, a predictive and a distributed coding systems are compared in terms of resilience to channel errors.|$|E
40|$|This paper {{reports on}} the {{experimental}} implementation of the quantum baker's map via a three bit nuclear magnetic resonance (NMR) quantum information processor. The experiments tested {{the sensitivity of the}} quantum chaotic map to perturbations. In the first experiment, the map was iterated forward and then backwards to provide benchmarks for <b>intrinsic</b> <b>errors</b> and decoherence. In the second set of experiments, the least significant qubit was perturbed in between the iterations to test the sensitivity of the quantum chaotic map to applied perturbations. These experiments are used to investigate previous predicted properties of quantum chaotic dynamics. Comment: submitted to PR...|$|R
40|$|AbstractIn {{order to}} {{identify}} and quantify <b>intrinsic</b> <b>errors</b> in the atmosphere–land and ocean–sea ice model components of the Community Earth System Model version 1 (CESM 1) and {{their contributions to the}} tropical Atlantic sea surface temperature (SST) bias in CESM 1, we propose a new method of diagnosis and apply it to a set of CESM 1 simulations. Our analyses of the model simulations indicate that both the atmosphere–land and ocean–sea ice model components of CESM 1 contain large errors in the tropical Atlantic. When the two model components are fully coupled, the <b>intrinsic</b> <b>errors</b> in the two components emerge quickly within a year with strong seasonality in their growth rates. In particular, the ocean–sea ice model contributes significantly in forcing the eastern equatorial Atlantic warm SST bias in early boreal summer. Further analysis shows that the upper thermocline water underneath the eastern equatorial Atlantic surface mixed layer is too warm in a stand-alone ocean–sea ice simulation of CESM 1 forced with observed surface flux fields, suggesting that the mixed layer cooling associated with the entrainment of upper thermocline water is too weak in early boreal summer. Therefore, although we acknowledge the potential importance of the westerly wind bias in the western equatorial Atlantic and the low-level stratus cloud bias in the southeastern tropical Atlantic, both of which originate from the atmosphere–land model, we emphasize here that solving those problems in the atmosphere–land model alone does not resolve the equatorial Atlantic warm bias in CESM 1...|$|R
40|$|We {{demonstrate}} accurate single-qubit {{control in}} an ensemble of atomic qubits trapped in an optical lattice. The qubits are driven with microwave radiation, and their dynamics tracked by optical probe polarimetry. Real-time diagnostics {{is crucial to}} minimize systematic errors and optimize the performance of single-qubit gates, leading to fidelities of 0. 99 for single-qubit pi rotations. We show that increased robustness to large, deliberately introduced errors can be achieved {{through the use of}} composite rotations. However, during normal operation the combination of very small <b>intrinsic</b> <b>errors</b> and additional decoherence during the longer pulse sequences precludes any significant performance gain in our current experiment. Comment: 9 pages, 7 figure...|$|R
40|$|A COMPARISON IS GIVEN BETWEEN THE EXPERIMENTAL DETECTION LIMITS OBTAINED FOR LEAD AND THALLIUM ATOMS BY THE TECHNIQUE OF LASER INDUCED FLUORESCENCE WITH ELECTROTHERMAL ATOMISATION AND THOSE CALCULATED UNDER THE ASSUMPTION THAT THE LIMITING NOISE IS DUE TO THE <b>INTRINSIC</b> <b>ERROR</b> IN THE SIGNAL ITSELF (INTRINSIC DETECTION LIMIT). NA-NOT AVAILABL...|$|E
30|$|While the {{advantages}} {{in terms of}} reduced computational complexity may be partially mitigated by hardware technological advances, the expected <b>intrinsic</b> <b>error</b> resilience {{may turn out to}} be an attractive aspect in the application scenarios prone to continuously varying channel characteristics, for which traditional FEC (forward error correcting codes) fails to be effective.|$|E
3000|$|..., clean water, Rayleigh {{scattering}} regime), {{there is}} no appreciable difference between VH and VV configurations. During the scans, the measured phase remains nearly constant within a range of 0.25 °, which represents the <b>intrinsic</b> <b>error</b> of the apparatus operating at the described conditions (Figure 10 (a)). This occurs because the light backscattered by the tap-water column (optical thickness [...]...|$|E
40|$|The International Ultraviolet Explorer {{observations}} of interstellar zinc toward 10 stars are examined. It is found that zinc is at most only slightly depleted in the interstellar medium; its abundance {{may serve as}} a tracer of the true metallicity in the gas. The local interstellar medium has abundances that apparently are homogeneous to within a factor of two, when integrated over paths of about 500 pc, and this result is important for understanding the history of nucleosynthesis in the solar neighborhood. The <b>intrinsic</b> <b>errors</b> in detecting weak interstellar lines are analyzed and suggestions are made as to how this error limit may be lowered to 5 mA per target observation...|$|R
40|$|An {{important}} {{objective in}} the evaluation of algorithms with sensory inputs is the development of measures characterizing the <b>intrinsic</b> <b>errors</b> in the results. <b>Intrinsic</b> are those <b>errors</b> which are caused by noise in the input data. The particular application which we consider is 3 -D reconstruction from stereo. We demonstrate that a radiometric correction of the images could improve significantly the accuracy. We propose a confidence interval approach for quantifying the precision. We also illustrate the use of the confidence intervals for the rejection of unreliable 3 D points. 1 Introduction 1. 1 Motivation Our work is inspired by the call in the computer vision community for performance evaluation methods [11, 12, 32]. In this paper we discuss errors in 3 -D reconstructions from stereo induced by sensor noise. Such <b>errors</b> we call <b>intrinsic.</b> Any undesired feature causing discrepancies in the digital image is considered noise. Systematic noise (errors) effect the accuracy of the vision al [...] ...|$|R
40|$|Revised (B-V) _ 0 -Mg_ 2 {{data for}} 402 {{elliptical}} galaxies {{are given to}} test reddening predictions which can also tell us both what the <b>intrinsic</b> <b>errors</b> are in this relationship among gE galaxy stellar populations, as well as details of nearby structure in the interstellar medium (ISM) of our Galaxy and of the <b>intrinsic</b> <b>errors</b> in reddening predictions. Using least-squares fits, the explicit 1 -sigma errors in the Burstein-Heiles (BH) and the Schlegel et al. (IR) predicted reddenings are calculated, {{as well as the}} 1 -sigma observational error in the (B-V) _ 0 -Mg_ 2 for gE galaxies. It is found that, in directions with E(B-V) = 0. 100 mag, significantly better than those of the BH predictions (0. 024 - 0. 025). Gas-to-dust variations that vary by a factor of 3, both high and low, exist along many lines-of-sight in our Galaxy. The approx 0. 02 higher reddening zero point in E(B-V) previously determined by Schlegel et al. is confirmed, primarily at the Galactic poles. Despite this, both methods also predict many directions with E(B-V) < 0. 015 mag. Independent evidence of reddening at the North Galactic pole is reviewed, with the conclusion that there still exists directions at the NGP that have E(B-V) << 0. 01. Two lines of evidence suggest that IR reddenings are overpredicted in directions with high gas-to-dust ratios. As high gas-to-dust directions in the ISM also include the Galactic poles, this overprediction is the likely cause of the E(B-V) = 0. 02 mag larger IR reddening zero point. Comment: 5 figure...|$|R
40|$|When the DC {{magnetization}} curve (B-H) of nonoriented material {{is measured in}} a ring specimen, there is an <b>intrinsic</b> <b>error</b> due to {{the assumption that the}} mean magnetic path length is equal to the mean geometric path length. A novel method for determining the B-H curve accurately is proposed. The validity of the method is verified by experiments</p...|$|E
40|$|In {{this study}} {{we look at the}} SALT-II model of Type IA {{supernova}} analysis, which determines the distance moduli based on the known absolute standard candle magnitude of the Type IA supernovae. We {{take a look at the}} determination of the shape and color parameter coefficients, {alpha} and {beta} respectively, in the SALT-II model with the <b>intrinsic</b> <b>error</b> that is determined from the data. Using the SNANA software package provided for the analysis of Type IA supernovae, we use a standard Monte Carlo simulation to generate data with known parameters to use as a tool for analyzing the trends in the model based on certain assumptions about the <b>intrinsic</b> <b>error.</b> In order to find the best standard candle model, we try to minimize the residuals on the Hubble diagram by calculating the correct shape and color parameter coefficients. We can estimate the magnitude of the intrinsic errors required to obtain results with {chi}{sup 2 }/degree of freedom = 1. We can use the simulation to estimate the amount of color smearing as indicated by the data for our model. We find that the color smearing model works as a general estimate of the color smearing, and that we are able to use the RMS distribution in the variables as one method of estimating the correct intrinsic errors needed by the data to obtain the correct results for {alpha} and {beta}. We then apply the resultant <b>intrinsic</b> <b>error</b> matrix to the real data and show our results...|$|E
40|$|We {{propose that}} certain brain systems, {{such as those}} of neocortex, exploit a fusion of ideas from neural {{networks}} and evolutionary computation, and that several previously puzzling features of thalamocortical circuitry and physiology can be understood as consequences of this fusion. The starting point is a consideration of anatomical errors in the recently described digital strengthening of synaptic connections, which are analogous to mutations. A mathematical model of this process shows the equivalence of the <b>intrinsic</b> <b>error</b> rate and a “correlation ratio ” which re ects the spatial variation in the degree of synchrony of neural ring. The correlation ratio plays a similar role to tness ratios in genetic algorithms. It is arguedthat a major trendin brain evolution has been decreases in the <b>intrinsic</b> <b>error</b> rate, allowing increases in circuit complexity, but that biophysical limits to this tren dhave forced the neocortex to adopt a virtual error-reduction strategy. This requires online measurement of correlation ratios andcontrol of the plasticity of the connections formed by individua...|$|E
40|$|A low {{accuracy}} in the force calculation per time step {{of a few}} percent for each particle pair is sufficient for collisionless N-body simulations. Higher accuracy is made meaningless by the dominant discreteness noise {{in the form of}} two-body relaxation, which can be reduced only by increasing the number of particles. Since an N-body simulation is a Monte Carlo procedure in which each particle-particle force is essentially random, i. e., carries an error of about 1000 percent, the only requirement is a systematic averaging-out of these <b>intrinsic</b> <b>errors.</b> We illustrate these assertions with two specific examples in which individual pairwise forces are deliberately allowed to carry significant errors: tree-codes on supercomputers and algorithms on special-purpose machines with low-precision hardware...|$|R
40|$|A deep-level {{transient}} spectroscopy (DLTS) {{technique is}} reported {{for determining the}} capture cross-section activation energy directly. Conventionally, the capture activation energy is obtained from the temperature dependence of the capture cross section. Capture cross-section measurement is often very doubtful due to many <b>intrinsic</b> <b>errors</b> and is more critical for nonexponential capture kinetics. The essence of this technique is to use an emission pulse to allow the defects to emit electrons and the transient signal from capture process due to a large capture barrier was analyzed, {{in contrast with the}} emission signal in conventional DLTS. This technique has been applied for determining the capture barrier for silicon-related DX centers in $Al_xGa_{ 1 -x}As$ for different AlAs mole fractions...|$|R
40|$|An {{objective}} of DSP testing {{should be to}} ensure that any errors due to missed faults are infrequent compared to a circuit's <b>intrinsic</b> <b>errors,</b> such as overflow. A method is proposed for quantifying test quality for digital filters by measuring the risk associated with any untested faults. Techniques for finding upper bounds on fault activation rates under worst-case operating conditions are described. These techniques enable test designers to objectively discriminate significant missed faults from near-redundant faults, which {{are unlikely to be}} activated in normal operation of the device. This complements fault coverage as a measure of test quality, providing a means of locating high-risk missed faults even in very high coverage test regimes...|$|R
40|$|We {{have studied}} the {{energetics}} of vacancy formation and diffusion in fcc cobalt using periodic density functional theory, both with and without including the surface <b>intrinsic</b> <b>error</b> corrections. Aggregation of vacancies {{is found to be}} energetically favorable. The vacancy formation energies, with (without) corrections, are computed to be 2. 34 (1. 71) eV for an isolated vacancy and 2. 28 – 1. 92 (1. 65 – 1. 29) eV per vacancy for two to six coalesced vacancies, respectively. The corrected (uncorrected) diffusion barrier of an isolated vacancy is 1. 19 (0. 98) eV. We have found that vacancy formation energies are over-predicted for Co, Fe and Ni when surface <b>intrinsic</b> <b>error</b> corrections are applied. We have also studied substitutional tungsten diffusion in Co. We have identified two sequential vacancy-mediated W diffusion mechanisms in Co. Corrected (uncorrected) energy barriers for the steps in these mechanisms lie in the range 1. 09 – 1. 44 (0. 88 – 1. 23) eV...|$|E
40|$|Part I. We have {{developed}} a technique for measuring the depth time history of rigid body penetration into brittle materials (hard rocks and concretes) under a deceleration of 10 5 g. The technique includes bar-coded projectile, sabot-projectile separation, detection and recording systems. Because the technique can give very dense data on penetration depth time history, penetration velocity can be deduced. Error analysis shows that the technique has a small <b>intrinsic</b> <b>error</b> of 3 - 4...|$|E
40|$|We {{investigate}} the <b>intrinsic</b> <b>error</b> sensitivity of photoacoustic experiments in obtaining reliable and accurate {{information on the}} inhomogeneous thermal conductivity below the surface. The analysis is based on thermal wave properties and {{does not depend on}} any approximate inversion technique. As an example, the theory is applied to the important class of monotonic profiles. The theory can help us in choosing the lower frequency limit in an actual experiment. (C) 1997 American Institute of Physics. status: publishe...|$|E
40|$|The {{prediction}} {{of breast cancer}} intrinsic subtypes has been introduced as a valuable strategy to determine patient diagnosis and prognosis, and therapy response. The PAM 50 method, based on the expression levels of 50 genes, uses a single sample predictor model to assign subtype labels to samples. <b>Intrinsic</b> <b>errors</b> reported within this assay demonstrate the challenge of identifying and understanding the breast cancer groups. In this study, we aim to: a) identify novel biomarkers for subtype individuation by exploring the competence of a newly proposed method named CM 1 score, and b) apply an ensemble learning, {{as opposed to the}} use of a single classifier, for sample subtype assignment. The overarching objective is to improve class prediction...|$|R
40|$|The {{main purpose}} of this work is to lead an {{assessment}} of the day ahead forecasting activity of the power production by photovoltaic plants. Forecasting methods can play a fundamental role in solving problems related to renewable energy source (RES) integration in smart grids. Here a new hybrid method called Physical Hybrid Artificial Neural Network (PHANN) based on an Artificial Neural Network (ANN) and PV plant clear sky curves is proposed and compared with a standard ANN method. Furthermore, the accuracy of the two methods has been analyzed in order to better understand the <b>intrinsic</b> <b>errors</b> caused by the PHANN and to evaluate its potential in energy forecasting applications. © 2015 by the authors; licensee MDPI, Basel, Switzerland...|$|R
40|$|In {{this work}} the dose {{rates on the}} surface of and one meter far from a {{standard}} package of the radiopharmaceutical FDG (fluordeoxyglucose) produced by IEN's RDS 111 cyclotron are estimated using two distinct methods: an anlaytic method and a Monte Carlo computer-based simulation method. The values obtained through both methods are then compared with experimental data. The results obtained are analyzed and interpreted, taking into account some features, such as: non-conformities in the measuring procedures, <b>intrinsic</b> <b>errors</b> of the radiation detectors, non-homogeneity of the shielding material, etc. This work is useful to evaluate and anticipate dose rates, as well as to optimize measuring, packing and expedition procedures in order to reduce doses and promote the implementation of ALARA principle...|$|R
