834|1|Public
25|$|The design {{principles}} {{developed for}} the AGC by MIT Instrumentation Laboratory, directed in late 1960s by Charles Draper, became foundational to software engineering—particularly {{for the design of}} more reliable systems that relied on asynchronous software, priority scheduling, testing, and <b>human-in-the-loop</b> decision capability. When the design requirements for the AGC were defined, necessary software and programming techniques did not exist so it had to be designed from scratch.|$|E
50|$|Although <b>human-in-the-loop</b> {{simulation}} {{can include}} a computer simulation {{in the form}} of a synthetic environment, computer simulation is not necessarily a form of <b>human-in-the-loop</b> simulation, and is often considered as human-out-of-the loop simulation. In this particular case, a computer model’s behavior is modified according to a set of initial parameters. The results of the model differ from the results stemming from a true <b>human-in-the-loop</b> simulation because the results can easily be replicated time and time again, by simply providing identical parameters.|$|E
5000|$|... #Subtitle level 2: <b>Human-in-the-loop</b> {{simulation}} within virtual simulation taxonomy ...|$|E
50|$|Certain {{types of}} {{training}} that require objectively quantifiable measures of {{success can be}} incompatible with the variability of using a <b>human-in-the-loop.</b>|$|E
5000|$|Perona and Serge Belongie {{lead the}} Visipedia project, which {{facilitates}} research on visual knowledge representation, visual search, and <b>human-in-the-loop</b> machine learning systems.|$|E
50|$|Both ATK and SpaceX {{have been}} {{developing}} autonomous flight termination systems. Both systems use a GPS-aided, computer controlled system to terminate an off-nominal flight - supplementing or replacing {{the more traditional}} <b>human-in-the-loop</b> monitoring system.|$|E
5000|$|System {{integration}} testing (SIT) involves the overall testing {{of a complete}} system of many subsystem components or elements. The system under test may be composed of hardware, or software, or hardware with embedded software, or hardware/software with <b>human-in-the-loop</b> testing.|$|E
5000|$|Virtual - A {{simulation}} involving {{real people}} operating simulated systems. Virtual simulations inject a <b>Human-in-the-Loop</b> into {{a central role}} by exercising motor control skills (e.g., flying jet or tank simulator), decision making skills (e.g., committing fire control resources to action), or communication skills (e.g., {{as members of a}} C4I team).|$|E
50|$|The C4ISR {{experiment}} provided {{input to}} the FCS Analysis of Alternatives and the Operational and Objective (O&O) analysis {{to support the}} FCS Milestone B decision. The experiment was conducted in a <b>human-in-the-loop,</b> simulation supported, secure environment. The experiment focused {{on the issues of}} battle command and how it affected measures of force effectiveness.|$|E
50|$|OpenEaagles is an {{open source}} {{framework}} designed to support the rapid construction of virtual (<b>human-in-the-loop)</b> and constructive simulation applications. It has been used extensively to build DIS compliant distributed simulation systems. It is based upon Eaagles, a popular simulation framework developed and maintained by the U.S. Air Force to support a multitude of simulation activities.|$|E
50|$|The first MWTB site manager, Dick Garvey, {{established}} a strong focus on measurement of battlefield effects from <b>Human-in-the-Loop</b> (HITL) simulation. This was {{in marked contrast}} with the then-prevalent approach of using highly scripted, closed-form simulations, where the outcome was defined by the scenario designer. HITL provided an opportunity to evaluate new systems and concepts whose application was not yet fully understood.|$|E
50|$|The design {{principles}} {{developed for}} the AGC by MIT Instrumentation Laboratory, directed in late 1960s by Charles Draper, became foundational to software engineering—particularly {{for the design of}} more reliable systems that relied on asynchronous software, priority scheduling, testing, and <b>human-in-the-loop</b> decision capability. When the design requirements for the AGC were defined, necessary software and programming techniques did not exist so it had to be designed from scratch.|$|E
5000|$|<b>Human-in-the-loop</b> {{allows the}} user to change the outcome of an event or process. HITL is {{extremely}} effective {{for the purposes of}} training because it allows the trainee to immerse themselves in the event or process [...] The immersion effectively contributes to a positive transfer of acquired skills into the real world. This can be demonstrated by trainees utilizing flight simulators in preparation to become pilots.|$|E
50|$|By {{providing}} abstract {{representations of}} system components (that the object-oriented design philosophy promotes), multiple levels of fidelity {{can be easily}} intermixed and selected for optimal runtime performance. Abstract representations of systems allow a developer to tune the application to run efficiently so that <b>human-in-the-loop</b> interaction latency deadlines can be met. On the flip side, constructive-only simulation applications that {{do not need to}} meet time-critical deadlines can use models with even higher levels of fidelity.|$|E
50|$|Although the JDL Model (Level 1-4) {{is still}} in use today, it is often criticized for its {{implication}} that the levels necessarily happen in order and also for its lack of adequate representation {{of the potential for}} a <b>human-in-the-loop.</b> The DFIG model (Level 0-5) explored the implications of situation awareness, user refinement, and mission management. Despite these shortcomings, the JDL/DFIG models are useful for visualizing the data fusion process, facilitating discussion and common understanding, and important for systems-level information fusion design.|$|E
50|$|<b>Human-in-the-loop</b> or HITL {{is defined}} as a model that {{requires}} human interaction. HITL is associated with modeling and simulation (M&S) in the live, virtual, and constructive taxonomy. HITL models may conform to human factors requirements {{as in the case of}} a mockup. In this type of simulation a human is always part of the simulation and consequently influences the outcome in such a way that is difficult if not impossible to reproduce exactly. HITL also readily allows for the identification of problems and requirements that may not be easily identified by other means of simulation.|$|E
5000|$|Set in the near-future, {{artificial}} intelligence {{is depicted in}} the novel as having failed in its goal of creating software capable of passing the Turing Test, therefore it is renamed [...] "pseudo-intelligence". As a result, virtual reality entertainments are augmented by role-players skilled {{in the use of}} digital puppetry who don motion capture suits and perform as interactive avatars within virtual environments. These <b>human-in-the-loop</b> simulations are known as [...] "ractives" [...] (an abbreviation of [...] "interactives"), and the performers who drive them are called [...] "ractors" [...] (an abbreviation of [...] "interactors").|$|E
50|$|As {{with most}} processes, {{there is always}} the {{possibility}} of human error, which can only be reproduced using HITL simulation. Although much can be done to automate systems, humans typically still need to take the information provided by a system to determine the next course of action based on their judgment and experience. Intelligent systems can only go so far in certain circumstances to automate a process; only humans in the simulation can accurately judge the final design. Tabletop simulation may be useful in the very early stages of project development for the purpose of collecting data to set broad parameters, but the important decisions require <b>human-in-the-loop</b> simulation.|$|E
50|$|Rahwan {{coined the}} term Society-in-the-loop as a {{conceptual}} extension of <b>Human-in-the-Loop</b> systems. Whereas HITL systems embed an individual's judgement into a narrowly defined control system, SITL is more about embedding the judgement of {{society as a whole}} in to system. He cites an AI that controls billions of self driving cars (and decides who is worth saving in certain cases), or a news filtering algorithm with the potential to influence the ideology of millions of citizens (that decides what content the users shall see). Rahwan highlights the importance of articulating ethics and social contracts in ways that machines can understand, towards building new governance algorithms.|$|E
50|$|The {{reliability}} and the trust people put in computer simulations {{depends on the}} validity of the simulation model, therefore verification and validation are of crucial importance in the development of computer simulations. Another important aspect of computer simulations is that of reproducibility of the results, meaning that a simulation model should not provide a different answer for each execution. Although this might seem obvious, this is a special point of attention in stochastic simulations, where random numbers should actually be semi-random numbers. An exception to reproducibility are <b>human-in-the-loop</b> simulations such as flight simulations and computer games. Here a human is part of the simulation and thus influences the outcome {{in a way that is}} hard, if not impossible, to reproduce exactly.|$|E
5000|$|The [...] "Golden Citron" [...] (אתרוג זהב, [...] ) truck-mounted net-centric open systems {{architecture}} Battle Management Command, Control, Communication & Intelligence Center can control up to 14 intercepts simultaneously. As of 2007 {{it was one of}} the world's most advanced net-centric systems. The system provides fully automatic as well as <b>Human-in-the-Loop</b> options at every stage of battle operation management. It is also capable of interoperability with other theater missile defense systems and C3I systems. Notably Link 16, TADIL-J, communications were being altered to allow interoperability with Patriot fire control units. Assigned targets can be handed over to the Patriot's AN/MPQ-53 fire control radar. Tests carried out by the U.S and Israel have successfully linked the Arrow with both U.S and Israeli versions of the Patriot.|$|E
50|$|Human {{performance}} models predict {{human behavior}} in a task, domain, or system. However, these models must be based upon and compared against empirical <b>human-in-the-loop</b> data {{to ensure that the}} human performance predictions are correct. As human behavior is inherently complex, simplified representations of interactions are essential to the success of a given model. As no model is able to capture the complete breadth and detail of human performance within a system, domain, or even task, details are abstracted away to these keep models manageable. Although the omission of details is an issue in basic psychological research, it is less of a concern in applied contexts such as those of most concern to the human factors profession. This is related to the internal-external validity trade-off. Regardless, development of a human performance model is an exercise in complexity science. Communication and exploration of the most essential variables governing a given process are often {{just as important as the}} accurate prediction of an outcome given those variables.|$|E
50|$|Modeling and {{simulation}} (M&S) {{refers to}} using models - physical, mathematical, or otherwise logical {{representation of a}} system, entity, phenomenon, or process - {{as a basis for}} simulations - methods for implementing a model (either statically or) over time - to develop data as a basis for managerial or technical decision making.M&S supports analysis, experimentation, and training. As such, M&S can facilitate understanding a system's behavior without actually testing the system in the real world. For instance, to determine which type of spoiler would improve traction the most while designing a race car, a computer simulation of the car could be used to estimate the effect of different spoiler shapes on the coefficient of friction in a turn. Useful insights about different decisions in the design could be gleaned without actually building the car. In addition, simulation can support experimentation that occurs totally in software, or in <b>human-in-the-loop</b> environments where simulation represents systems or generates data needed to meet experiment objectives. Furthermore, simulation can be used to train persons using a virtual environment that would otherwise be difficult or expensive to produce.|$|E
50|$|When a modeler {{builds a}} network {{model of a}} task, {{the first step is}} to {{construct}} a flow chart decomposing the task into discrete sub-tasks - each sub-task as a node, the serial and parallel paths connecting them, and the gating logic that governs the sequential flow through the resulting network. When modeling human-system performance, some nodes represent human decision processes and.or human task execution, some represent system execution sub-tasks, and some aggregate human/machine performance into a single node. Each node is represented by a statistically specified completion time distribution and a probability of completion. When all these specifications are programmed into a computer, the network is exercised repeatedly in Monte Carlo fashion to build up distributions of the aggregate performance measures that are of concern to the analyst. The art in this is in the modeler's selection of the right level of abstraction at which to represent nodes and paths and in estimating the statistically defined parameters for each node. Sometimes, <b>human-in-the-loop</b> simulations are conducted to provide support and validation for the estimates.. Detail regarding this, related, and alternative approaches may be found in Laughery, Lebiere, and Archer (2006) and in the work of Schwieckert and colleagues, such as Schweickert, Fisher, and Proctor (2003).|$|E
30|$|These {{devices are}} managed under human {{supervision}} rather than <b>human-in-the-loop</b> operation. That is, these devices should be automated to enable real-time transactions and control.|$|E
30|$|The main {{contributions}} {{of this article}} are three-fold: first, we show how using the <b>human-in-the-loop</b> approach, we can outperform an approach that relies only on expert annotation without the human in the loop. Second, we demonstrate that even with a little amount of annotation, a good performance for annotation suggestion can be reached, resulting in a substantial annotation speedup. Third, we exemplify how the <b>human-in-the-loop</b> approach in text annotation allows the customization of entities and relation types for the user’s need. Part {{of this article was}} already presented in a shorter form in [15].|$|E
40|$|The {{purpose of}} this design process is to apply Human Engineering (HE) {{requirements}} and guidelines to hardware/software and to provide HE design, analysis and evaluation of crew interfaces. The topics include: 1) Background/Purpose; 2) HE Activities; 3) CASE STUDY: Net Habitable Volume (NHV) Study; 4) CASE STUDY: Human Modeling Approach; 5) CASE STUDY: Human Modeling Results; 6) CASE STUDY: Human Modeling Conclusions; 7) CASE STUDY: <b>Human-in-the-Loop</b> Evaluation Approach; 8) CASE STUDY: Unsuited Evaluation Results; 9) CASE STUDY: Suited Evaluation Results; 10) CASE STUDY: <b>Human-in-the-Loop</b> Evaluation Conclusions; 11) Near-Term Plan; and 12) In Conclusio...|$|E
40|$|This work {{analyzes}} <b>human-in-the-loop</b> robotic {{systems to}} determine where human input can be most beneficial to a collaborative task. This is accomplished by implementing a pick-and-place task using a <b>human-in-the-loop</b> robotic system and determining which segments of the task, when replaced by human guidance, provide the most improvement to overall task performance and require the least cognitive effort. The first experiment entails implementing a pick and place task on a commercial robotic arm. Initially, we look at a pick-and-place task that is segmented into two main areas: coarse approach towards a goal object and fine pick motion. For the fine picking phase, {{we look at the}} importance of user guidance in terms of position and orientation of the end effector. Results from this initial experiment show that the most successful strategy for our <b>human-in-the-loop</b> system is the one in which the human specifies a general region for grasping, and the robotic system completes the remaining elements of the task. We extend this study to include a second experiment, utilizing a more complex robotic system and pick-and-place task to further analyze human impact in a <b>human-in-the-loop</b> system in a more realistic setting. In this experiment, we use a robotic system that utilizes an Xbox Kinect as a vision sensor, a more cluttered environment, and a pick-and-place task that we segment in a way similar to the first experiment. Results from the second experiment indicate that allowing the user to make fine tuned adjustments to the position and orientation of the robotic hand can improve task success in high noise situations in which the autonomous robotic system might otherwise fail. The experimental setups and procedures used in this thesis can be generalized and used to guide similar analysis of human impact in other <b>human-in-the-loop</b> systems performing other tasks...|$|E
40|$|In this work, we {{analyze the}} {{pick and place}} task for a <b>human-in-the-loop</b> robotic system to {{determine}} where human input can be most beneficial to a collaborative task. This is accomplished by implementing a pick and place task on a commercial robotic arm system and determining which segments of the task, when replaced by human guidance, provide the most improvement to overall task performance and require the least cognitive effort. The pick and place task can be segmented into two main areas: coarse approach towards goal object and fine pick motion. For the fine picking phase, {{we look at the}} importance of user guidance in terms of position and orientation of the end effector. Results from our experiment show that the most successful strategy for our <b>human-in-the-loop</b> system is the one in which the human specifies a general region for grasping, and the robotic system completes the remaining elements of the task. Our experimental setup and procedures could be generalized and used to guide similar analysis of human impact in other <b>human-in-the-loop</b> systems performing other tasks...|$|E
40|$|A {{key element}} in the {{development}} and innovation of future aviation concepts and systems is research flight simulation. Research flight simulation is applied when the performance and perception of human pilots is a key measure of the overall assessment. This paper will give an overview of the research simulation set-up of the National Aerospace Laboratory (NLR), Amsterdam, the Netherlands, which is used for the <b>human-in-the-loop</b> evaluation of future operational concepts. Special attention is given to the research topic of Airborne Separation Assurance; often referred to as Free Flight. The presented set-up {{has proven to be a}} flexible evaluation tool for assessing <b>human-in-the-loop</b> performance when operating in a simulated future autonomous aircraft environment...|$|E
40|$|NASA Ames Research Center is {{developing}} a concept for managing flight operations on airport surfaces. The goal of the concept, named the Spot and Runway Departure Advisor (SARDA), is to reduce delays, emissions, noise, and fuel consumption. In 2010, <b>human-in-the-loop</b> simulations of the SARDA concept were conducted. 1 Results showed that for the 2008 heavy traffic scenario SARDA reduced departure delays and fuel consumption, while imposing little impact on perceived controller workload. The 2008 normal traffic scenario did not show measurable benefits. The <b>human-in-the-loop</b> simulations analyzed only two traffic scenarios and were costly. To efficiently expand the research of SARDA so that it included analysis of more traffic scenarios, adaptation to more airports, and investigation of changes to the concept, a fast-time simulation capability was needed. This paper documents the first attempt at fast-time simulation analysis of the SARDA concept. A fast-time simulation of traffic at Dallas/Fort Worth International Airport being autonomously managed by a delay-optimal runway scheduler was conducted. Although the simulation was meant to analyze {{the benefits of the}} SARDA concept, there were differences between how traffic was managed in the fast-time simulation and the <b>human-in-the-loop</b> simulations. Th...|$|E
30|$|FLC uses {{heuristic}} {{information for}} control applications. The FLC uses rule-base derived through an operator’s experience and thus {{acts as a}} <b>human-in-the-loop</b> controller providing human experience to achieve high performance (Kalaivani et al. 2014; Taskin et al. 2017; Huang and Chao 2000).|$|E
40|$|This {{presentation}} discusses {{an overview}} of the surface traffic management research conducted by NASA Ames. The concept and <b>human-in-the-loop</b> simulation of the Spot and Runway Departure Advisor (SARDA), an integrated decision support tool for the tower controllers and airline ramp operators, is also discussed...|$|E
40|$|We {{developed}} {{a prototype of}} <b>human-in-the-loop</b> simulator of inter- and intra-agency communication and coordination in disaster response. The base simulation is a multi-agent simulation of emergency response in which each organization (group, section, or organization) is implemented one cognitive agent and thus simulation o...|$|E
40|$|The author {{describes}} an Airway Facilities (AF) simulator for <b>human-in-the-loop</b> research and training. The AF simu-lator is a flexible, self-contained system. A simuator {{of this type}} and complexity is unique {{in the realm of}} <b>human-in-the-loop</b> simulation. It {{can be used as a}} platform for scientific research in human factors concepts, testing and validation of behavioral and performance measures, and as a potential training tool. The self-contained nature of the simulator al-lows for increased experimental control of research and generalizability of results. Because the system is self-contained, it is portable. This document provides an overview of the system com-ponents that comprise the AF simulator. The author pro-poses various performance and behavioral measures and discusses the potential for use of the AF simulator as a training platform...|$|E
40|$|The paper {{reports on}} an {{experimental}} work environment for simulating remote control of regional airports and initial results obtained by high fidelity <b>human-in-the-loop</b> simulations. At the Institute of Flight Guidance of the German Aerospace Centre a concept for remote control of regional airports was developed since 2002 and a corresponding experimental testbed realized, consisting of facilities for field testing at the Braunschweig research airport and a tower simulator extension for operational remote tower (RTO) simulations with controllers. <b>Human-in-the-loop</b> simulations were conducted, simulating Braunschweig airport {{to show the}} operational feasibility of the new working environment. Therefore two tower controllers handled traffic scenarios using a common 200 -degree tower simulator, but also using the new work environment, the RTO (Remote Tower Operation) -Console. This setting allows a direct comparison of {{an evaluation of the}} RTO-Console and the tower simulator as work environment. Augmented vision aspects were implemented in the simulation runs at the RTO-Console. Moreover, a zoom camera with an automatic tracking function integrated in the work environment for remote control was evaluated. Subjective data from questionnaires and free interviews were gathered for each simulation run. Objective eye data were recorded for the simulation runs using the RTO-Console. The main result from the questionnaires depicts the work environment of the RTO-Console to be comparable with working in a tower simulator. The eye data show that most of the time (53 %) the tower controller is looking at the area of interest in the simulated far view, which is in line with former work analyses. The results of the <b>human-in-the-loop</b> simulation suggest the feasibility of tower operation using the RTO-Console. For the operational deployment of remote control of small airports a stepwise validation using <b>human-in-the-loop</b> simulations is indispensable...|$|E
