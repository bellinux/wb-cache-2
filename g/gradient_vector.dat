785|319|Public
25|$|The {{pressure}} <b>gradient</b> <b>vector</b> is {{only made}} by the component along the trajectory tangent s.|$|E
25|$|Pressure force. This is {{the action}} on the parcel arising from the spatial {{differences}} of atmospheric pressure p around it. (Temporal changes are of no interest here.) The spatial change of pressure is visualised through isobars, that are contours joining the locations where the pressure has a same value. In the figure this is simplistically shown by equally spaced straight lines. The pressure force acting on the parcel is minus the <b>gradient</b> <b>vector</b> of p (in symbols: grad p) - drawn in the figure as a blue arrow. At all points, the pressure gradient points to the direction of maximum increase of p and is always normal to the isobar at that point. Since the flow packet feels a push from the higher to the lower pressures, the effective pressure vector force {{is contrary to the}} pressure gradient, whence the minus sign before the <b>gradient</b> <b>vector.</b>|$|E
25|$|If {{the edges}} of the {{framework}} are assumed to be rigid bars that can neither expand nor contract (but can freely rotate) then any motion respecting this rigidity must preserve the lengths of the edges: the derivative of length, {{as a function of the}} time over which the motion occurs, must remain zero. This condition may be expressed in linear algebra as a constraint that the <b>gradient</b> <b>vector</b> of the motion of the vertices must have zero inner product with the row of the rigidity matrix that represents the given edge. Thus, the family of gradients of (infinitesimally) rigid motions is given by the nullspace of the rigidity matrix. For frameworks that are not in generic position, it is possible that some infinitesimally rigid motions (vectors in the nullspace of the rigidity matrix) are not the gradients of any continuous motion, but this cannot happen for generic frameworks.|$|E
2500|$|... are the {{respective}} gradients. The constant [...] is required because {{although the two}} <b>gradient</b> <b>vectors</b> are parallel, the magnitudes of the <b>gradient</b> <b>vectors</b> are generally not equal. This constant is called the Lagrange multiplier. (In some conventions [...] is preceded by a minus sign).|$|R
40|$|International audienceThis paper {{describes}} a skeletonization process for grayscale or color images {{based on the}} diffusion of the color <b>gradient</b> <b>vectors</b> by using a simple iterative regularization scheme. We propose to diffuse the original color <b>gradient</b> <b>vectors</b> to obtain the skeleton of the main contrasted objects. Contrary to a distance transform or thinning based skeleton, the <b>gradient</b> <b>vectors</b> diffusion is a straightforward, simple and efficient approach to compute the skeleton, which {{does not require the}} localization of the contours curvatures or a distance map. In comparison to other approaches based on potential field functions, our method does not require the segmentation of the objects or the precise localization of the contours. Our approach is very simple to implement and can be applied to natural noisy color images of old documents...|$|R
40|$|We {{propose a}} robust quantization-based image {{watermarking}} scheme, called the gradient direction watermarking (GDWM). This {{is based on}} the uniform quantization of the direction of <b>gradient</b> <b>vectors.</b> In GDWM, the watermark bits are embedded by quantizing the angles of significant <b>gradient</b> <b>vectors</b> at multiple wavelet scales. The proposed scheme has the following advantages: 1) Increased invisibility of the embedded watermark because the watermark is embedded in significant <b>gradient</b> <b>vectors,</b> 2) robustness to amplitude scaling attacks because the watermark is embedded in the angles of the <b>gradient</b> <b>vectors,</b> and 3) increased watermarking capacity as the scheme uses multiple-scale embedding [...] This watermarking technique is more Robust tovarious sizes of watermark Images. we construct a discrete-domain multiresolution and multidirectional expansion using non-separable filter banks, {{in much the same way}} that wavelets were derived from filter banks. This construction results in a flexible mutiresolution, local, and directional image expansion using contour segments, and thus it is named the contourlettransform. The discrete contourlet transform has a fast iterated filter bank algorithm that requires order N operations for N-pixel images. Finally, we show simulation results using contourlet denoising method over wavelet...|$|R
500|$|Derivatives may be {{generalized}} to functions of several real variables. In this generalization, the derivative is reinterpreted as a linear transformation whose graph is (after an appropriate translation) the best linear approximation to the graph of the original function. The Jacobian matrix is the matrix that represents this linear transformation {{with respect to the}} basis given by the choice of independent and dependent variables. [...] It can be calculated in terms of the partial derivatives with respect to the independent variables. [...] For a real-valued function of several variables, the Jacobian matrix reduces to the <b>gradient</b> <b>vector.</b>|$|E
2500|$|By contrast, a {{covariant}} vector has {{components that}} change oppositely to the coordinates or, equivalently, transform like the reference axes. [...] For instance, {{the components of}} the <b>gradient</b> <b>vector</b> of a function ...|$|E
2500|$|The Milnor number μ of a {{singularity}} is {{the degree}} of the mapping [...] on the small sphere of radius ε, {{in the sense of}} the topological degree of a continuous mapping, where gradf is the (complex) <b>gradient</b> <b>vector</b> field of f. It is related to δ and r by the Milnor-Jung formula, ...|$|E
40|$|This paper {{presents}} a coin recognition system based completely {{on the direction}} of the <b>gradient</b> <b>vectors.</b> To optimally align two coins we search for a rotation such that as most as possible corresponding <b>gradient</b> <b>vectors</b> point into the same direction. After discretizing the gradient directions this can be done quickly by the use of the Fast Fourier Transform. The classification is done by a simple nearest neighbor search followed by several rejection criteria to meet the demand of a low false positive rate. ...|$|R
40|$|Watermarking {{refers to}} the hiding of a message in a host message {{in such a way}} that if this signal is altered; the hidden message still survives if the host survives. Watermarking used for covert communication, Authentication, {{broadcast}} monitoring, tamper proofing, etc. This paper proposes an improved image watermarking scheme based on log polar mapping (LPM) and angle quantization index modulation (AQIM). To keep the watermark robust to translation, rotation and scaling attacks, Log Polar mapping followed by Fast Fourier transform is performed on the original unwater marked image before embedding the watermark. Using AQIM, the watermark is embedded in the <b>gradient</b> <b>vectors</b> of large magnitudes by quantizing the angle. <b>Gradient</b> <b>vectors</b> are obtained in the form of Discrete Wavelet Transform (DWT) coefficients. To makes the watermark robust to amplitude scaling attacks, this method Embeds watermark in the vector angle. Imperceptibility is increased by embedding watermark in the <b>gradient</b> <b>vectors</b> with large magnitudes. Increase in the watermarking capacity, is achieved by employing multiple levels DWT...|$|R
40|$|The {{structure}} tensor yields {{an excellent}} {{characterization of the}} local dimensionality and the corresponding orientation for simple neighborhoods, i. e. neighborhoods exhibiting a single orientation. We show that we can disentangle crossing structures if the tensor scale is {{much larger than the}} gradient scale. Mapping the <b>gradient</b> <b>vectors</b> to a continuous orientation representation yields a D(D+ 1) dimensional feature vector per pixel. Clustering of the vectors in this new space allows identification of multiple orientations. Each cluster of <b>gradient</b> <b>vectors</b> can be analyzed separately using the structure tensor approach. Proper clustering yields an unbiased estimate of the underlying orientations. 1...|$|R
2500|$|A Morse {{function}} [...] induces {{a handle}} decomposition of W, i.e., {{if there is}} a single critical point of index k in , then the ascending cobordism [...] is obtained from [...] by attaching a k-handle. The goal of the proof is to find a handle decomposition with no handles at all so that integrating the non-zero <b>gradient</b> <b>vector</b> field of f gives the desired diffeomorphism to the trivial cobordism.|$|E
5000|$|Given that S is convex, it is {{minimized}} {{when its}} <b>gradient</b> <b>vector</b> is zero (This follows by definition: if the <b>gradient</b> <b>vector</b> is not zero, {{there is a}} direction {{in which we can}} move to minimize it further - see maxima and minima.) The elements of the <b>gradient</b> <b>vector</b> are the partial derivatives of S with respect to the parameters: ...|$|E
5000|$|... #Caption: A contour plot of , {{showing the}} <b>gradient</b> <b>vector</b> in green, and the unit vector [...] scaled by the {{directional}} derivative {{in the direction}} of [...] in orange. The <b>gradient</b> <b>vector</b> is longer because the gradient points {{in the direction of}} greatest rate of increase of a function.|$|E
3000|$|... 1 but in {{addition}} consists of <b>gradient</b> <b>vectors</b> of the multipath time delays from the other two walls, and is straightforward to compute. The linear system in (28) is overdetermined with Δ x [...]...|$|R
5000|$|Note {{that the}} average of the {{gradient}} [...] inside the window is not a good indicator of anisotropy. Aligned but oppositely oriented <b>gradient</b> <b>vectors</b> would cancel out in this average, whereas in the structure tensor they are properly added together.|$|R
30|$|A {{solution}} is reached when the <b>gradient</b> <b>vectors</b> of (7) and (8) {{are within the}} tolerance margin. If any of the variables listed in (5) is outside the allowable limits, the inequality constraint is enforced according to the criteria given in [24].|$|R
5000|$|... #Caption: Representation {{of all the}} {{components}} of the gravitational <b>gradient</b> <b>vector</b> ...|$|E
5000|$|The <b>gradient</b> <b>vector</b> flow (GVF) snake model {{addresses}} {{two issues}} with snakes: ...|$|E
5000|$|... where [...] is the <b>gradient</b> (<b>vector)</b> and the dot is {{the inner}} product.|$|E
30|$|The {{functions}} f_j(x) (j ∈ I ∪ J) are all {{first order}} continuously differentiable, and there exists an index l_x∈ I(x) for each x ∈ X {{such that the}} <b>gradient</b> <b>vectors</b> {∇ f_i(x) - ∇ f_l_x(x), i ∈ I(x){ l_x};∇ f_j(x),j ∈ J(x)} are linearly independent.|$|R
40|$|The {{described}} {{collection of}} subroutines developed for calculation of values of multivariate normal, Dirichlet and gamma distribution functions and their <b>gradient</b> <b>vectors</b> is an unique tool {{that can be}} used e. g. to compute the Loss-of-Load Probability of electric networks and to solve optimization problems with a reliability constraint...|$|R
50|$|Perlin {{noise is}} most {{commonly}} implemented as a two-, three- or four-dimensional function, {{but can be}} defined {{for any number of}} dimensions. An implementation typically involves three steps: grid definition with random <b>gradient</b> <b>vectors,</b> computation of the dot product between the distance-gradient vectors and interpolation between these values.|$|R
5000|$|... {{which follows}} from the cross product {{expression}} above, substituting components of the <b>gradient</b> <b>vector</b> operator (nabla).|$|E
5000|$|... an {{integral}} {{curve of the}} <b>gradient</b> <b>vector</b> field of the Green's function on neighborhood of infinity ...|$|E
50|$|Any Morse {{function}} f on {{a compact}} Riemannian manifold M defines a <b>gradient</b> <b>vector</b> field. If one imposes {{the condition that}} the unstable and stable manifolds of the critical points intersect transversely, then the <b>gradient</b> <b>vector</b> field and the corresponding smooth flow form a Morse-Smale system. The finite set of critical points of f forms the non-wandering set, which consists entirely of fixed points.|$|E
40|$|In {{this paper}} we {{describe}} a robust estimator for {{the orientation of}} linear textures. The proposed estimator is the robust version of a well-known orientation estimator based on the structure tensor that {{is related to the}} covariance matrix of the ensemble of <b>gradient</b> <b>vectors</b> that are observed in a local neighborhood...|$|R
5000|$|In {{order to}} negate the {{expensive}} process of computing new gradients for each grid node, some implementations use a hash and lookup {{table for a}} finite number of precomputed <b>gradient</b> <b>vectors.</b> [...] The use of a hash also permits the inclusion of a random seed where multiple instances of Perlin noise are required.|$|R
5000|$|For each {{evaluation}} of the noise function, the dot product of the position and <b>gradient</b> <b>vectors</b> must be evaluated at each node of the containing grid cell. Perlin noise therefore scales with complexity [...] for [...] dimensions. Alternatives to Perlin noise producing similar results with improved complexity scaling include simplex noise and OpenSimplex noise.|$|R
50|$|Mathematically, the {{gradient}} of a two-variable function (here {{the image}} intensity function) at each image {{point is a}} 2D vector with the components given by the derivatives in the horizontal and vertical directions. At each image point, the <b>gradient</b> <b>vector</b> points {{in the direction of}} largest possible intensity increase, and the length of the <b>gradient</b> <b>vector</b> corresponds to the rate of change in that direction.|$|E
5000|$|Stability of Parameterized Families of <b>Gradient</b> <b>Vector</b> Fields, with F. Takens, Annals of Mathematics 118, 1983 (383-421).|$|E
50|$|In {{differential}} topology, {{a mathematical}} discipline, {{and more specifically}} in Morse theory, a gradient-like vector field is a generalization of <b>gradient</b> <b>vector</b> field.|$|E
30|$|Note that {{if there}} exists a point {{belonging}} to the set X̃, namely, x̂∈X̃, and the active constraint <b>gradient</b> <b>vectors</b> {∇ g_j(x̂), j∈ I(x̂)} are linearly independent, then one can yield a point x^ 0 ∈X̃_̃ 0 ̃ by simple computation, e.g., execute line search on g starting with x̂ along direction d̂=-N̂(N̂ ^TN̂)^- 1 e, where N̂=∇ g_I(x̂)(x̂) and e=(1,..., 1)^T.|$|R
40|$|Constraining the {{gradient}} field enables {{to enhance}} specific image features. The Gradient Line Detector (GLD) for example, {{is based on}} the scalar product of the gradient at pixels taken symmetrically around the current pixel; as <b>gradient</b> <b>vectors</b> are pointing in opposite directions at each side of a line, the GLD is a good indication of the line-shape of the underlying intensity. In practice, the investigation of the four nearest neighbour pairs is sufficient to determine the presence of a line and its local direction. Exploring a larger neighbourhood enables to get an approximation of the contrast and width of the line. Bright lines can be distinguished from dark lines, by checking if the <b>gradient</b> <b>vectors</b> point towards each other or not. As for the edge detection process, a non-maximum suppression and a line following are necessary in order to generate one pixel wide line elements. The Gradient Corner Detector (GCD) on the other hand, uses the cross product of displaced gradient vecto [...] ...|$|R
40|$|A set of {{necessary}} {{conditions for the}} choice of diffusion <b>gradient</b> <b>vectors</b> to make the linear equations nonsingular for the estimation of the diffusion matrix are given in a coordinate free manner. The conditions assert that the initial step {{in the design of}} a DTI experiment with six or more acquisitions must be to select six valid diffusion gradients first and then add new ones...|$|R
