2|8|Public
40|$|Purpose - Based on a three-level digital {{preservation}} framework, {{the purpose of}} this paper is to suggest a solution for long-term {{digital preservation}} for the public administration sector, in the form of a centralised <b>intermediate</b> <b>repository,</b> on the basis of the concept of cloud computing. Design/methodology/approach - By means of a thorough review of the literature in this area and an analysis of the current state of the art, the paper investigates a three-level digital preservation framework with a focus on the public sector. It cross-links this framework with the cloud computing concept, in order to propose an appropriate solution. Findings - The mapping of six factors of digital preservation to three levels of digital preservation shows that using appropriate steps supported by suitable strategies and policies enables the public administration sector to take advantage of modern information technology and solve the demanding and critical problem of digital preservation. Practical implications - The paper suggests an organisational and technological solution in the form of a centralised digital preservation repository within a cloud computing framework, to aid both organisations of the public sector which deal with active life cycle document phases and archives and libraries which deal with passive phases of documents and records. Originality/value - The paper addresses the difficulties of digital preservation implementation in the public administration sector. The findings indicate that while developing and implementing digital preservation, the public administration sector should formulate common policies and solutions based on the suggested results of this paper and, in doing so, maximise the benefits of current technologies...|$|E
40|$|The {{interlinear}} glossed text (IGT) is {{a complex}} object, the complexity of its structure depending on factors such as origin, intended use, languages involved etc. Developing tools and workflows for integrated linguistic analysis environments calls for particular attention to those aspects which in many common cases can be disregarded as insignificant; thus, collaborating for ELAN–FLEx integration was particularly motivating for this paper. IGT is often conceived of as a tree: the root node corresponds to the whole text, subdivided into smaller units (sentences, words, morphemes). Each unit {{has a number of}} associated annotations, generally one per information type, like sentence translation, part-of-speech label, morpheme gloss. However, an IGT can easily amount to a large set of trees. Unresolved ambiguities of all kinds are one reason for it. Each pair of alternative analyses (e. g. two concurrent parses of a word) implies two distinct trees, identical except for the node in question and all its descendants. The more ambiguities arise, the more underlying trees should be posited. Still, all trees in such a tree family stem from a single analyzed object (transcript, original orthographic representation). Storing entire trees for each combination of relevant alternatives being utterly inefficient, a more compact storage model is needed. Turning to the media dimension, an accurate transcript of a spontaneous discourse is most often unsuitable for a grammatical analysis without some preprocessing (normalization) dealing with various speech errors, incomprehensible fragments etc. to produce a grammatically correct and coherent text for subsequent grammatical analysis – whereas the “raw” transcript feeds phonological and possibly discourse analysis. We thus get two distinct texts, interconnected but giving rise to independent (families of) analysis trees; only one of them is linked directly to the media timeline. In some scenarios, more than one media-based timeline emerge which need to be interlinked (cf. BOLD framework: sound annotations to sound events; retelling experiments, e. g. pear stories; sign languages translated from/into spoken languages). The reference axis may not be properly a timeline (text, path through a complex graphic image). One should mention further complicating factors such as multi-speaker and multi-lingual settings, collaboration and versioning. The overall structure (an XML sketch will be presented) might grow unreasonably complex for any specialized analysis component to handle. It may thus be efficient to use an <b>intermediate</b> <b>repository,</b> e. g. a unified underlying RDF representation [Nakhimovsky et al. 2012], to which all changes made in specific tools are merged. References Bow, Cathy, Baden Hughes and Steven Bird. 2003. Towards a General Model of Interlinear Text. Nakhimovsky, Alexander, Jeff Good, Tom Myers. 2012. Interoperability of Language Documentation Tools and Materials for Local Communities // Digital Humanities 2012...|$|E
40|$|In {{distributed}} systems users often {{need to share}} sensitive data with other users based on the latter’s ability to satisfy various policies. In many cases the data owner may not even know {{the identities of the}} data recipients, but deems it crucial that they are legitimate; i. e., satisfy the policy. Enabling such data sharing over the Internet faces the challenge of (1) securely associating access policies with data and enforcing them, and (2) protecting data as it traverses untrusted proxies and <b>intermediate</b> <b>repositories.</b> Furthermore, it is desirable to achieve properties such as: (1) flexibility of access policies; (2) privacy of sensitive access policies; (3) minimal reliance on trusted third parties; and (4) efficiency of access policy enforcement. Often schemes enabling controlled data sharing need to trade one property for another. In this dissertation, we propose two complimentary policy-based data sharing schemes that achieve different subsets of the above desired properties. In {{the first part of this}} dissertation, we focus on CiphertextPolicy Attribute-Based Encryption (CP-ABE) schemes that specify and enforce access policies cryp-tographically and eliminate trusted mediators. We motivate the need for flexi...|$|R
40|$|AbstractFor the {{development}} of an <b>intermediate</b> radioactive waste <b>repository,</b> two different types of reinforced concrete were analyzed in terms of durability: one made with ordinary portland cement and the other one made with pozzolanic cement. The values for compressive strength, sorptivity and air permeability demonstrate that the formulations are compatible with the required application. The corrosion rate of rebar up to about 300 days of monitoring and obtained with sensors is below the threshold value required for this type of facilities, except when temperatures are high. The value for the same parameter monitored by the galvanostatic pulse technique using superficial counter electrode and guard electrode is always lower than the threshold value. Additionally, when applying the galvanostatic pulse technique using embedded electrodes, this parameter is comparable to the guard electrode method only when the polarization resistance is calculated through non-linear fitting...|$|R
40|$|The Greater than Class C (GTCC) Environmental Impact Statement (EIS) {{evaluated}} the potential impacts from {{the construction and}} operation of a new facility or facilities, or use of an existing facility, employing various disposal methods (geologic <b>repository,</b> <b>intermediate</b> depth borehole, enhanced near surface trench, and above grade vault) at six federal sites and generic commercial locations. For three of the locations being considered as possible locations, consulting tribes were brought in to comment on their perceptions on how GTCC low level radioactive waste would affect Native American resources (land, water, air, plants, animals, archaeology, etc.) short and long term. The consulting tribes produced essays that were incorporated into the EIS and these essays are in turn included in this collection. This essay was produced {{by members of the}} culturally affiliated tribes to Los Alamos National Lab...|$|R
40|$|Laser {{ablation}} ICP-MS U–Pb {{analyses were}} conducted on detrital zircons of Triassic sandstone and conglomerate from the Lusitanian basin in order to: i) document the age spectra of detrital zircon; ii) compare U–Pb detrital zircon ages with previous published data obtained from Upper Carboniferous, Ordovician, Cambrian and Ediacaran sedimentary rocks of the pre-Mesozoic basement of western Iberia; iii) discuss potential sources; and iv) test the hypothesis of sedimentary recycling. U–Pb dating of zircons established a maximum depositional age for this deposit as Permian (ca. 296 Ma),which is about sixty million years older compared to the fossil content recognized in previous studies (Upper Triassic). The distribution of detrital zircon ages obtained points to common source areas: the Ossa–Morena and Central Iberian zones that outcrop in {{and close to the}} Porto–Tomar fault zone. The high degree of immaturity and evidence of little transport of the Triassic sediment suggests that granite may constitute primary crystalline sources. The Carboniferous age of ca. 330 Ma for the best estimate of crystallization for a granite pebble in a Triassic conglomerate and the Permian–Carboniferous ages (ca. 315 Ma) found in detrital zircons provide evidence of the denudation of Variscan and Cimmerian granites during the infilling of continental rift basins in western Iberia. The zircon age spectra found in Triassic strata are also the result of recycling from the Upper Carboniferous Buçaco basin,which probably acted as an <b>intermediate</b> sediment <b>repository.</b> U–Pb data in this study suggest that the detritus from the Triassic sandstone and conglomerate of the Lusitanian basin is derived fromlocal source areas with features typical of Gondwana,with no sediment from external sources from Laurussia or southwestern Iberia...|$|R
40|$|As part of {{the license}} for SFR 1 a renewed safety {{assessment}} should be carried out at least every ten years for the continued operation of the SFR 1 repository. SKB has at mid-year 2001 finalised their renewed safety assessment (project SAFE) which evaluates {{the performance of the}} SFR 1 repository system. As part of SKI’s own capability to perform radionuclide transport calculations a need to develop a database for the near-field of SFR 1 repository was identified. Purpose of the project The purpose of this project is to make a compilation of physical and chemical data for the engineered barriers plus near-field rock of the SFR 1 repository. Results The parameters in the SFR 1 vault database has successfully been used in SKI’s own radionuclide transport calculations and in the review of SKB’s safety assessment for SFR 1. Effect on SKI’s work This project has given SKI not only an updated parameter database for SFR 1 but also partly an useful database for the low and <b>intermediate</b> level waste <b>repository</b> SFL 3 - 5. Project information Responsible at SKI has been Bo Strömberg. SKI ref. : 14. 9 - 991010 / 9913...|$|R
40|$|The International Atomic Energy Agency (IAEA) Coordinated {{research}} program ''Improvement of Safety Assessment Methodologies for Near Surface Disposal Facilities'' (ISAM) has developed improved safety assessment methodology for near surface disposal facilities. The {{program has been}} underway {{for three years and}} has included around 75 active participants from 40 countries. It has also provided examples for application to three safety cases [...] vault, Radon type and borehole radioactive waste disposal facilities. The program has served as an excellent forum for exchange of information and good practices on safety assessment approaches and methodologies used worldwide. It also provided an opportunity for reaching broad consensus on the safety assessment methodologies to be applied to near surface low and <b>intermediate</b> level waste <b>repositories.</b> The methodology has found widespread acceptance and the need for its application on real waste disposal facilities has been clearly identified. The ISAM was finalized by the end of 2000, working material documents are available and an IAEA report will be published in 2002 summarizing the work performed during the three years of the program. The outcome of the ISAM program provides a sound basis for moving forward to a new IAEA program, which will focus on practical application of the safety assessment methodologies to different purposes, such as licensing radioactive waste repositories, development of design concepts, upgrading existing facilities, reassessment of operating repositories, etc. The new program will also provide an opportunity for development of guidance on application of the methodology that will be of assistance to both safety assessors and regulators...|$|R
40|$|Hindered amine light {{stabilisers}} (HALS) are {{one class}} of additive {{known to be}} effective in retarding polymer degradation and have been deployed in a range of polymer-based surface coating applications. The use of HALS significantly improves gloss and colour retention of coatings in addition to maintaining surface integrity – resulting in a superior commercial product. Despite their demonstrable efficacy, the precise mechanism by which HALS protect coatings remains an open discussion. It is widely believed that HALS operate as chain-breaking antioxidants whereby, initially, the parent compound undergoes sacrificial oxidation of a heterocyclic amine to form an aminoxyl radical. It is this persistent aminoxyl radical that acts as a free radical scavenging intermediate and is thought to be involved in converting harmful free radicals to less harmful evenelectron species. In theory, this process could repeat indefinitely but empirical evidence suggests HALS become less effective over time suggesting that further investigation of their mechanism of action is required. The overarching goal of this research was to identify molecular-level changes in HALS within polymer systems. To achieve this required the development of new analytical methods that were sensitive to changes in molecular structure and abundance of HALS present in polymer-based surface coatings. The scope of this PhD project encompassed two major objectives. Firstly, to develop ambient ionisation mass spectrometric methods capable of interrogating additives within polymer-based surface coatings. Traditional mass spectrometry (MS) methods have long been employed for the characterisation of both polymers H vi and polymer additives but recent developments in the field suggest new approaches could provide distinct advantages for polymer analysis. Notable among these technological advancements are a class of desorption/ionisation methods capable of analysing solid and liquid material in its native state, under ambient conditions. These ambient ionisation MS methods are distinct from traditional MS in that they permit direct desorption and ionisation of analytes {{from a wide variety of}} substrates with minimum sample preparation, i. e., extraction, pre-concentration, and chromatographic separation are not required. Uncovering the true potential of these ambient sampling and ionisation methods for MS of synthetic polymers and their components is a major focus of the research undertaken for this thesis. The second objective was to use these optimised techniques to characterise changes in molecular structure and abundance of HALS in different polymers - mostly polyester and polyacrylate surface coatings - induced by different preparations and in-service conditions Results reported herein accomplish the objectives of method development and application. Three ambient ionisation mass spectrometry methods have been developed for polymer and polymer additive analysis. These are desorption electrospray ionisation (DESI), liquid extraction surface analysis (LESA), and paint spray ionisation – a new technique developed as a part of this PhD project. All three techniques are capable of detecting HALS directly from within the bulk polymer, removing laborious sample preparation steps required with traditional MS. Each technique is able to provide complementary information on the spatial distribution and change in molecular structure of HALS compounds. Applying these methods to polyester paint samples led to the discovery that all N-functionalised HALS (N-CH 3, N-C(O) CH 3, and N-OR) generate a substantial population of secondary amine (N-H). Detection of this molecular-level change represents key experimental evidence for a major role for secondary amines as intermediates in mechanisms of HALS stabilisation of polymers. These findings are consistent with the results of recent high-level computational studies that also identify secondary amines as a critical reaction <b>intermediate</b> and <b>repository</b> of active HALS (G. Gryn 2 ̆ 7 ova, K. Ingold and M. L. Coote, J. Am. Chem. Soc., 2012, 134, 12979 - 12988). The study suggested formation of secondary amines from N-OR functionalised HALS would primarily occur by hydrogen abstraction and subsequent β-scission under normal service temperatures (25 - 80 °C). At low radical concentrations or at high temperatures associated with curing (260 °C), secondary amine formation via direct N-OR bond homolysis may become competitive. Both mechanisms are consistent with the observed experimental presented data and the combination of these results represents a significant advancement in understanding the mechanisms of protection of polymers by HALS...|$|R
40|$|A dissertação é um estudo terminológico multilingue baseado na investigação realizada no Centre de Recherche en Terminologie et Traduction (CRTT) entre outubro de 2013 e fevereiro de 2014. Este pretende fornecer contributos para a tradução de textos de especialidade do domínio dossubprodutos animais não destinados ao consumo humano, com base na análise de umRegulamento comunitário. O corpus legislativo foi retirado da base de dados jurídica europeia, EUR-Lex. Destaca-se no enquadramento teórico da Terminologia a Teoria Comunicativa da Terminologia (TCT), essencial na extração, ordenaçãoe tratamento da terminologia através da valorização semasiológica do corpus. Os candidatos a termo são extraídos através da ferramenta de processamento de texto, AntConc 3. 2. 4, e em seguida validados pelasua interfuncionalidade e caráter linguístico. Recorre-se igualmente à {{consulta}} de definições a fim de esclarecer e confirmar o sistema concetual linguisticamente elaborado. Os dados obtidos pelo processamento terminológico do corpus são armazenados em dois produtos terminográficos com fins diferentes. Por um lado, o repositório de fichas terminológicas facilita a leitura do corpus e estrutura dados linguísticos e concetuais. Por outro lado, o conjunto de mapas concetuais, construídos no programa CmapTools,representa graficamente a organização do conhecimento. A elaboração e a leitura dos produtos terminográficos são apresentadas por extenso num capítulo específico. A dissertação reúne duas partes essenciais, a metodologia e a consulta do especialista do domínio. Abstract: This dissertation {{project is}} a multilingual study on Terminology based on the research made in Centre de Recherche en Traduction et Terminology (CRTT), between October 2013 and February 2014. This study intends {{to contribute to the}} translation of specialized textsin the field of animal by-products not intended for human consumption based on the analysis of a European Community Regulation. The legislative corpus was extracted from a European judicial database, the EUR-Lex. The Communicative Theory of Terminology (CTT), distinguished from the Terminology theoretical frame, isessential for the extraction and organization, and the overall treatment of the terminology field by the semasiological approach to the corpus. The term candidates are extracted with thetextprocessing tool, AntConc 3. 2. 4 and then validated according to their interfunctionality and linguistic character. We also searched for definitions in order to clarify and confirm the conceptual system that was linguistically developed. The data obtained from terminological the processing of the corpus are stored in two terminographic products with different use. On one hand, the terminological files <b>repository</b> <b>intermediates</b> the corpus comprehension and structures linguistic and conceptual data. On the other hand, we have the set of conceptual maps, made in CmapTools programme, which illustrates the organization of the knowledge. The development of the terminological products is fully presented in one specific chapter. This dissertation project puts together two essential parts, the methodology and the consulting of the specialist...|$|R

