878|121|Public
5|$|Topological sorting is the {{algorithmic}} {{problem of}} finding a topological ordering of a given DAG. It can be solved in linear time. Kahn's algorithm for topological sorting builds the vertex ordering directly. It maintains a list of vertices that have no incoming edges from other vertices that have not already {{been included in the}} partially constructed topological ordering; initially this list consists of the vertices with no incoming edges at all. Then, it repeatedly adds one vertex from this list {{to the end of the}} partially constructed topological ordering, and checks whether its neighbors should be added to the list. The algorithm terminates when all vertices have been processed in this way. Alternatively, a topological ordering may be constructed by reversing a postorder numbering of a <b>depth-first</b> <b>search</b> graph traversal.|$|E
25|$|Every finite {{connected}} {{undirected graph}} {{has at least}} one Trémaux tree. One can construct such a tree by performing a <b>depth-first</b> <b>search</b> and connecting each vertex (other than the starting vertex of the search) to the earlier vertex from which it was discovered. The tree constructed in this way is known as a <b>depth-first</b> <b>search</b> tree. If uv is an arbitrary edge in the graph, and u is the earlier of the two vertices to be reached by the search, then v must belong to the subtree descending from u in the <b>depth-first</b> <b>search</b> tree, because the search will necessarily discover v while it is exploring this subtree, either from one of the other vertices in the subtree or, failing that, from u directly. Every finite Trémaux tree can be generated as a <b>depth-first</b> <b>search</b> tree: If T is a Trémaux tree of a finite graph, and a <b>depth-first</b> <b>search</b> explores the children in T of each vertex prior to exploring any other vertices, it will necessarily generate T as its <b>depth-first</b> <b>search</b> tree.|$|E
25|$|Even in {{countable}} graphs, a <b>depth-first</b> <b>search</b> {{might not}} succeed in eventually exploring the entire graph, and not every normal spanning tree can be generated by a depth-first search: to be a <b>depth-first</b> <b>search</b> tree, a countable normal spanning tree must have only one infinite path or one node with infinitely many children (and not both).|$|E
50|$|Chapter 5. Fractal {{dust and}} {{infinite}} words - Schottky limit sets regarded as fractals; computer generation of these fractals using <b>depth-first</b> <b>searches</b> and iterated function systems.|$|R
50|$|IDDFS {{combines}} <b>depth-first</b> <b>search's</b> space-efficiency and breadth-first search's completeness (when the {{branching factor}} is finite). It is optimal when the path cost is a non-decreasing {{function of the}} depth of the node.|$|R
30|$|With {{one of the}} {{parameters}} as the starting point, such as delay, <b>depth-first</b> <b>searching</b> for historical data information in media database is carried out to select the historical evaluation data matching the database.|$|R
25|$|In depth-first order, {{we always}} attempt {{to visit the}} node {{farthest}} from the root node that we can, but with the caveat {{that it must be}} a child of a node we have already visited. Unlike a <b>depth-first</b> <b>search</b> on graphs, {{there is no need to}} remember all the nodes we have visited, because a tree cannot contain cycles. Pre-order is a special case of this. See <b>depth-first</b> <b>search</b> for more information.|$|E
25|$|A Trémaux tree {{exists in}} every graph with countably many vertices, even when an {{infinite}} form of <b>depth-first</b> <b>search</b> would {{not succeed in}} exploring every vertex of the graph.|$|E
25|$|The {{backtracking}} <b>depth-first</b> <b>search</b> program, {{a slight}} improvement on the permutation method, constructs the search tree by considering one {{row of the}} board at a time, eliminating most nonsolution board positions {{at a very early}} stage in their construction.|$|E
40|$|Iterative-deepening {{searches}} mimic a breadth-first node expansion with {{a series}} of <b>depth-first</b> <b>searches</b> that operate with successively extended search horizons. They have been proposed as a simple way to reduce the space complexity of best-first searches like A* from exponential to linear in the search depth. But her...|$|R
40|$|Depth-first iterative-deepening mimics a {{breadth-first search}} {{with a series}} of <b>depth-first</b> <b>searches</b> that operate with {{successively}} extended search horizons. It has been proposed as a simple way to reduce the space complexity of best-first searches like A*, thereby making the space complexity linear instead of exponential. But ther...|$|R
40|$|Users manual {{describes}} {{computer program}} SWITCH that schedules {{use of resources}} - by appliances switched on and off and use resources while they are on. Plans schedules according to predetermined goals; revises schedules when new goals imposed. Program works by <b>depth-first</b> <b>searching</b> with strict chronological back-tracking. Proceeds to evaluate alternatives as necessary, sometimes interacting with user...|$|R
25|$|Trémaux {{trees are}} named after Charles Pierre Trémaux, a 19th-century French author {{who used a}} form of <b>depth-first</b> <b>search</b> as a {{strategy}} for solving mazes. They have also been called normal spanning trees, especially {{in the context of}} infinite graphs.|$|E
25|$|It is {{possible}} to test whether a graph is bipartite, and to return either a two-coloring (if it is bipartite) or an odd cycle (if it is not) in linear time, using <b>depth-first</b> <b>search.</b> The main idea is to assign to each vertex the color that differs from the color of its parent in the <b>depth-first</b> <b>search</b> forest, assigning colors in a preorder traversal of the depth-first-search forest. This will necessarily provide a two-coloring of the spanning forest consisting of the edges connecting vertices to their parents, {{but it may not}} properly color some of the non-forest edges. In a <b>depth-first</b> <b>search</b> forest, one of the two endpoints of every non-forest edge is an ancestor of the other endpoint, and when the depth first search discovers an edge of this type it should check that these two vertices have different colors. If they do not, then the path in the forest from ancestor to descendant, together with the miscolored edge, form an odd cycle, which is returned from the algorithm together with the result that the graph is not bipartite. However, if the algorithm terminates without detecting an odd cycle of this type, then every edge must be properly colored, and the algorithm returns the coloring together with the result that the graph is bipartite.|$|E
25|$|In finite graphs, {{although}} <b>depth-first</b> <b>search</b> {{itself is}} inherently sequential, Trémaux trees {{can be constructed}} by a randomized parallel algorithm in the complexity class RNC. They {{can be used to}} define the tree-depth of a graph, and as part of the left-right planarity test for testing whether a graph is a planar graph.|$|E
30|$|<b>Depth-first</b> {{parameter}} <b>searching.</b> <b>Depth-first</b> <b>searching</b> {{method for}} big {{data in the}} database is adopted to process QoE evaluation parameters depending on the service type of the server, with the sensitive parameters as the initial conditions. That is to say, one of the parameters is taken {{as a starting point}} for traverse search, which will not stop until all the required evaluation parameters are found out. Then, the historical evaluation information on database is obtained. The historical data are stored in media database in a linear way, including service type, delay, jitter, packet loss rate, and bandwidth, relay node types, users’ expectations, as well as service score.|$|R
50|$|Hybrids {{of these}} DCOP {{algorithms}} also exist. BnB-Adopt, for example, changes the search strategy of Adopt from best-first <b>search</b> to <b>depth-first</b> branch-and-bound <b>search.</b>|$|R
30|$|Normally run a <b>depth-first</b> {{constrained}} tree <b>search</b> through n levels.|$|R
25|$|In graph theory, a Trémaux tree of an {{undirected graph}} G is a {{spanning}} tree of G, rooted {{at one of}} its vertices, with the property that every two adjacent vertices in G are {{related to each other}} as an ancestor and descendant in the tree. All <b>depth-first</b> <b>search</b> trees and all Hamiltonian paths are Trémaux trees.|$|E
25|$|Note that 'iterative repair', {{unlike the}} 'backtracking' search {{outlined}} above, {{does not guarantee}} a solution: like all hillclimbing (i.e., greedy) procedures, it may get stuck on a local optimum (in which case the algorithm may be restarted with a different initial configuration). On the other hand, it can solve problem sizes that are several orders of magnitude {{beyond the scope of}} a <b>depth-first</b> <b>search.</b>|$|E
25|$|Some hobbyists have {{developed}} computer {{programs that will}} solve Sudoku puzzles using a backtracking algorithm, which {{is a type of}} brute force search. Backtracking is a <b>depth-first</b> <b>search</b> (in contrast to a breadth-first search), because it will completely explore one branch to a possible solution before moving to another branch. Although it has been established that approximately 6.67 x 1021 final grids exist, a brute force algorithm can be a practical method to solve Sudoku puzzles.|$|E
40|$|A new {{algorithm}} to test {{an arbitrary}} graph for 3 -edge-connectivity is proposed, implemented and tested. It is {{a modification of}} the classic linear algorithm of Hopcroft and Tarjan for dividing a graph into 3 -connected components. The algorithm uses three <b>depth-first</b> <b>searches</b> to locate separation pairs. It runs in time O(m + n), where m {{is the number of}} edges and n is the number of vertices in the graph. Testing was done on simple graphs and Feynman diagrams. The results show good agreement with the time complexity analysis, validating the algorithm design and implementation...|$|R
40|$|Abstract: The {{purpose of}} this {{research}} was to apply machine learning techniques to automate rule generation in the construction of Intelligent Tutoring Systems. By using a pair of somewhat intelligent iterative-deepening, <b>depth-first</b> <b>searches,</b> we were able to generate production rules from a set of marked examples and domain background knowledge. Such production rules required independent searches for both the “if ” and “then ” portion of the rule. This automated rule generation allows generalized rules with a small number of sub-operations to be generated in a reasonable amount of time, and provides non-programmer domain experts with a tool for developing Intelligent Tutoring Systems. ...|$|R
40|$|In this paper, {{we present}} a search {{algorithm}} called real-time search for solving combinatorial optimization problems under real-time constraints. The problems we study are NP-hard and have good heuristic algorithms for generating feasible solutions. The algorithm we develop aims at finding the best possible solution in a given deadline. Since this objective is generally not achievable without first solving the problem, we use an alternative heuristic objective that looks for the solution with the best ascertained approximation degree. Our algorithm schedules a sequence of guided <b>depth-first</b> <b>searches,</b> each searching for a more accurate solution (based on the approximation degree set), or solutions deeper in the search tree (based on the threshold set), {{or a combination of}} both. Five versions of the RTS algorithm for setting approximation degrees and/or thresholds are formulated, evaluated, and analyzed. We develop an exponential model for characterizing the relationship between the app [...] ...|$|R
25|$|It is P-complete to {{find the}} Trémaux tree that would be found by a {{sequential}} <b>depth-first</b> <b>search</b> algorithm, in which the neighbors of each vertex are searched in order by their identities. Nevertheless {{it is possible to}} find a different Trémaux tree by a randomized parallel algorithm, showing that the construction of Trémaux trees belongs to the complexity class RNC. As of 1997, it remained unknown whether Trémaux tree construction could be performed by a deterministic parallel algorithm, in the complexity class NC.|$|E
25|$|Prolog is not purely declarative: {{because of}} {{constructs}} like the cut operator, a procedural reading of a Prolog program {{is needed to}} understand it. The order of clauses in a Prolog program is significant, as the execution strategy of the language depends on it. Other logic programming languages, such as Datalog, are truly declarative but restrict the language. As a result, many practical Prolog programs are written to conform to Prolog's <b>depth-first</b> <b>search</b> order, rather than as purely declarative logic programs.|$|E
25|$|Alternatively, {{a similar}} {{procedure}} {{may be used}} with breadth-first search in place of <b>depth-first</b> <b>search.</b> Again, each node is given the opposite color to its parent in the search forest, in breadth-first order. If, when a vertex is colored, there exists an edge connecting it to a previously-colored vertex with the same color, then this edge together with the paths in the breadth-first search forest connecting its two endpoints to their lowest common ancestor forms an odd cycle. If the algorithm terminates without finding an odd cycle in this way, then it must have found a proper coloring, and can safely conclude that the graph is bipartite.|$|E
40|$|This work is {{to explain}} some of the big ideas in the field of {{artificial}} intelligence as it relates to chess. It starts with a brief history of the development over the centuries starting with the Automaton in the 18 th century and following up until the famous match between Deep Blue and Gary Kasparov. Then, the work moves into the techniques in use today. Among the techniques talked about are the minimax algorithm, alpha-beta pruning, parallel processing, iterativedeepening <b>depth-first</b> <b>searching,</b> opening move databases, endgame databases, and evaluation functions. Exact methods for implementing the methods is not discussed, but key concepts of each are presented in a simple manner. 1...|$|R
5000|$|Perl {{uses the}} list of classes to inherit from as an ordered list. The {{compiler}} uses the first method it finds by <b>depth-first</b> <b>searching</b> of the superclass list or using the C3 linearization of the class hierarchy. Various extensions provide alternative class composition schemes. The order of inheritance affects the class semantics. In the above ambiguity, class [...] and its ancestors would be checked before class [...] and its ancestors, so the method in [...] would be inherited through [...] This is shared with Io and Picolisp. In Perl, this behavior can be overridden using the [...] or other modules to use C3 linearization or other algorithms.|$|R
50|$|Proceed {{from that}} node using either <b>depth-first</b> or breadth-first <b>search,</b> {{counting}} all nodes reached.|$|R
500|$|The {{transitive}} closure {{of a given}} DAG, with [...] vertices and [...] edges, may be constructed in time [...] by using either breadth-first search or <b>depth-first</b> <b>search</b> to test reachability from each vertex. Alternatively, it can be solved in time [...] where [...] is the exponent for fast matrix multiplication algorithms; this is a theoretical improvement over the [...] bound for dense graphs.|$|E
2500|$|A single {{spanning}} tree of a graph {{can be found}} in linear time by either <b>depth-first</b> <b>search</b> or breadth-first search. Both of these algorithms explore the given graph, starting from an arbitrary vertex v, by looping through the neighbors of the vertices they discover and adding each unexplored neighbor to a data structure to be explored later. They differ in whether this data structure is a [...] stack (in the case of <b>depth-first</b> <b>search)</b> or a [...] queue (in the case of breadth-first search). In either case, one can form a {{spanning tree}} by connecting each vertex, other than the root vertex v, to the vertex from which it was discovered. This tree is known as a <b>depth-first</b> <b>search</b> tree or a breadth-first search tree according to the graph exploration algorithm used to construct it. <b>Depth-first</b> <b>search</b> trees are a special case of a class of spanning trees called Trémaux trees, named after the 19th-century discoverer of <b>depth-first</b> <b>search.</b>|$|E
2500|$|The Fraysseix–Rosenstiehl {{planarity}} criterion gives a characterization {{based on}} the existence of a bipartition of the cotree edges of a <b>depth-first</b> <b>search</b> tree. It is central to the left-right planarity testing algorithm; ...|$|E
40|$|The Mission Analysis Division of the Systems Analysis and Integration Laboratory at the Marshall Space Flight Center has {{developed}} a robust automatic scheduler which can produce detailed schedules for the multi-step activities required for payload operations on the Space Station. This scheduler, {{a part of the}} Expert Scheduling Program (ESP 2), has five components: the bookkeeper, checker, loader, selector, and explainer. The bookkeeper maintains the usage profiles for nondepletable resources, consumables, equipment, crew, and the times of all the steps for the payload activities for several different schedules simultaneously. The checker searches the data maintained by the bookkeeper and finds times when the constraints of each step of an activity are satisfied. The loader is an expert system that uses the techniques of forward chaining, <b>depth-first</b> <b>searching,</b> and backtracking to manage the workings of the checker so that activities are placed in the schedule without violating constraints (such as crew, resources, and orbit opportunities). The checker searches the data maintained by the bookkeeper and finds times when the constraints of each step of an activity are satisfied. The loader is an expert system which uses the techniques of forward chaining, <b>depth-first</b> <b>searching,</b> and backtracking to manage the workings of the checker so that activities are placed in the schedule without violating the constraints. The selector has several methods of choosing the next activity for the loader to schedule. The explainer shows the user why an activity was or was not scheduled at a certain time; it offers a unique graphical explanation of how the expert system (the loader) works...|$|R
50|$|Beam Search Using Limited Discrepancy Backtracking (BULB) is {{a search}} {{algorithm}} that combines limited discrepancy search with beam search and thus performs non-chronological backtracking, which often outperforms the chronological backtracking done by Beam Stack <b>Search</b> and <b>Depth-First</b> Beam <b>Search.</b>|$|R
40|$|This {{research}} {{examines the}} pattern of Web information seeking in four groups of nurses with different combinations of domain expertise and Web expertise. Protocols were gathered as the nurses carried out information-seeking tasks {{in the domain of}} osteoporosis. Domain and Web novices searched breadth-first and did little or no evaluation of the results. Domain expert/Web novices also searched breadth-first but evaluated information more thoroughly using osteoporosis knowledge. Domain novice/Web experts searched in a mixed, breadth-first/depth-first pattern and attempted to evaluate information using general criteria. Domain expert/Web experts carried out <b>depth-first</b> <b>searches,</b> following deep trails of information and evaluated information based on the most varied and sophisticated criteria. The results suggest that there are distinct differences in searching patterns related to expertise. Implications of these findings and suggestions for future research are provided...|$|R
