140|1696|Public
5|$|Culture {{and context}} in infants’ {{linguistic}} environment shape their vocabulary development. English learners {{have been found}} to map novel labels to objects more reliably than to actions compared to Mandarin learners. This early noun bias in English learners is caused by the culturally reinforced tendency for English speaking caregivers to engage in a significant amount of ostensive labelling as well as noun-friendly activities such as picture book reading. Adult speech provides children with grammatical input. Both Mandarin and Cantonese languages have a category of grammatical <b>function</b> <b>word</b> called a noun classifier, which is also common across many genetically unrelated East Asian languages. In Cantonese, classifiers are obligatory and specific in more situations than in Mandarin. This accounts for the research found on Mandarin-speaking children outperforming Cantonese-speaking children in relation to the size of their vocabulary.|$|E
5000|$|... lèih/làih (v. come, {{sometimes}} <b>function</b> <b>word)</b> Standard Chinese: ...|$|E
5000|$|... ge (genitive, {{similar to}} 's; {{sometimes}} <b>function</b> <b>word)</b> Standard Chinese: ,, ...|$|E
50|$|Words {{that are}} not <b>function</b> <b>words</b> are called content words (or open class words or lexical words or autosemantic words): these include nouns, verbs, adjectives, and most adverbs, {{although}} some adverbs are <b>function</b> <b>words</b> (e.g., then and why). Dictionaries define the specific meanings of content words, but can only describe the general usages of <b>function</b> <b>words.</b> By contrast, grammars describe the use of <b>function</b> <b>words</b> in detail, but treat lexical words in general terms only.|$|R
40|$|A {{large number}} of {{auditory}} studies explored the role of <b>function</b> <b>words</b> in syntactic processing, but few researched <b>function</b> <b>words</b> in written input. The present study probed the role of <b>function</b> <b>words</b> in word skipping, sentence compacting, chunking preference and the detection mechanism of grammatical incongruence by means of number estimation across 4 syntactic conditions (grammatical sentences, scrambled sentences, sentences with agreement errors and sentences with structural errors), 3 sentence lengths (6 or 7 words, 8 or 9 words, 10 or 11 words) and 3 ratios of <b>function</b> <b>words</b> and content words. We find that appropriate usage of <b>function</b> <b>words</b> highly facilitates syntactic analysis though <b>function</b> <b>words</b> are always skipped in proficient reading. Adjacent <b>function</b> <b>words</b> and content words in grammatical sentences {{are more likely to}} be processed as chunks, and this effect of chunking make sentences significantly more compact than scrambled sentences. In addition, the detection mechanism of grammatical incongruence is attributed to resolving the conflicts with prediction...|$|R
50|$|<b>Function</b> <b>words</b> {{might be}} prepositions, pronouns, {{auxiliary}} verbs, conjunctions, grammatical articles or particles, {{all of which}} belong {{to the group of}} closed-class words. Interjections are sometimes considered <b>function</b> <b>words</b> but they belong to the group of open-class <b>words.</b> <b>Function</b> <b>words</b> might or might not be inflected or might have affixes.|$|R
5000|$|... m̀h (adv. not, no, cannot; {{originally}} a <b>function</b> <b>word)</b> Standard Chinese: ...|$|E
5000|$|... saai (<b>function</b> <b>word</b> {{complete}} e.g., [...] moved all, finished moving) Standard Chinese: , ...|$|E
50|$|That is a <b>function</b> <b>word</b> {{used in the}} English {{language}} for several grammatical purposes.|$|E
50|$|All {{words can}} be {{classified}} as either content or <b>function</b> <b>words,</b> {{although it is not}} always easy to make the distinction. With only around 150 <b>function</b> <b>words,</b> 99.9% of words in the English language are content words. Although small in numbers, <b>function</b> <b>words</b> are used at a disproportionately higher rate and make up about 50% of any English text. This is due to the conventional patterns of words usage which bind <b>function</b> <b>words</b> to content words almost every time they are used, creating an interdependence between the two word groups.|$|R
50|$|Below {{are rules}} {{about the number}} of n’s in <b>function</b> <b>words,</b> which do not decline nor conjugate. Various <b>function</b> <b>words</b> which {{indicate}} movement end with -an and never -ann.|$|R
40|$|International audienceAuthorship {{attribution}} is {{the task}} of identifying {{the author of a}} given document. Various style markers have been proposed in the literature to deal with the authorship attribution task. Frequencies of <b>function</b> <b>words</b> {{have been shown to be}} very reliable and effective for this task. However, despite the fact that they are state-of-the-art, they basically rely on the invalid bag-of-words assumption, which stipulates that text is a set of independent words. In this contribution, we present a comparative study on using two different types of style marker based on <b>function</b> <b>words</b> for authorship attribution. We compare the effectiveness of using sequential rules of <b>function</b> <b>words</b> as style marker that do not relay on the bag-of-words assumption to that of the frequency of <b>function</b> <b>words</b> which does. Our results show that the frequencies of <b>function</b> <b>words</b> outperform the sequential rules...|$|R
50|$|The word functor was {{borrowed}} by mathematicians {{from the}} philosopher Rudolf Carnap, {{who used the}} term in a linguistic context;see <b>function</b> <b>word.</b>|$|E
50|$|The {{descriptor}} lexical {{is applied}} to the words of a language's lexicon, often to indicate a content word, as distinct from a <b>function</b> <b>word.</b>|$|E
5000|$|In late Quenya moods (other {{than the}} indicative) are {{expressed}} by particles, a short <b>function</b> <b>word</b> {{that does not}} belong to any of the inflected grammatical word classes: ...|$|E
40|$|One of {{the main}} issues in a word {{alignment}} task is the difficulty of handling <b>function</b> <b>words</b> {{that do not have}} direct translations which we call unique <b>function</b> <b>words.</b> They are often aligned to some words in the other language incorrectly. This is prominent in language pairs with very different sentence structures. In this paper, we propose a novel approach for handling unique <b>function</b> <b>words.</b> The proposed model monolingually derives unique <b>function</b> <b>words</b> from bilin-gually generated treelet pairs. The monolingual derivation prevents incorrect alignments for unique <b>function</b> <b>words.</b> The derivation probabilities are estimated from a large monolingual corpus, which is much easier to acquire than a parallel corpus. Also, the proposed alignment model uses semantic-head dependency trees where dependency relations between words be-come similar in each language. Experimental results on an English-Japanese corpus show that the proposed model achieves better alignment and translation quality compared with the baseline models...|$|R
40|$|In a {{regression}} study of conversational speech, {{we show that}} frequency, contextual predictability and repetition have separate contributions to word duration, despite their substantial correlations. Moreover, content- and function-word durations are affected differently by their frequency and predictability. Content words are shorter when more frequent, and shorter when repeated, while <b>function</b> <b>words</b> are not so affected. <b>Function</b> <b>words</b> have shorter pronunciations, after controlling for frequency and predictability. While both content and <b>function</b> <b>words</b> are strongly affected by predictability from the word following them, sensitivity to predictability from the preceding word is largely limited to very frequent <b>function</b> <b>words.</b> The results {{support the view that}} content and <b>function</b> <b>words</b> are accessed differently in production. We suggest a lexical-access-based model of our results, in which frequency or repetition lead to shorter or longer word durations by causing faster or slower lexical access, mediated by a general mechanism that coordinates the pace of higher-level planning and the execution of the articulatory plan...|$|R
40|$|In {{the present}} paper, we propose the {{effective}} usage of <b>function</b> <b>words</b> to generate generalized translation rules for forest-based translation. Given aligned forest-string pairs, we extract composed tree-to-string translation rules {{that account for}} multiple interpretations of both aligned and unaligned target <b>function</b> <b>words.</b> In order to constrain the exhaustive attachments of <b>function</b> <b>words,</b> we limit to bind them to the nearby syntactic chunks yielded by a target dependency parser. Therefore, the proposed approach can not only capture source-tree-to-target-chunk correspondences but can also use forest structures that compactly encode an exponential number of parse trees to properly generate target <b>function</b> <b>words</b> during decoding. Extensive experiments involving large-scale English-to-Japanese translation revealed a significant improvement of 1. 8 points in BLEU score, as compared with a strong forest-to-string baseline system. ...|$|R
50|$|Each <b>function</b> <b>word</b> either {{gives some}} {{grammatical}} information on other {{words in a}} sentence or clause, and cannot be isolated from other words, or it may indicate the speaker's mental model {{as to what is}} being said.|$|E
5000|$|In grammar {{the term}} {{particle}} (abbreviated [...] ) has a traditional meaning, {{as a part}} of speech that cannot be inflected, and a modern meaning, as a <b>function</b> <b>word</b> associated with another word or phrase to impart meaning.|$|E
5000|$|The {{original}} {{motivation for}} the DP-analysis {{came in the form}} of parallelism across phrase and clause. The DP-analysis provides a basis for viewing clauses and phrases as structurally parallel. The basic insight runs along the following lines: since clauses have functional categories above lexical categories, noun phrases should do the same. The traditional NP-analysis has the drawback that it positions the determiner, which is often a pure <b>function</b> <b>word,</b> below the lexical noun, which is usually a full content word. The traditional NP-analysis is therefore unlike the analysis of clauses, which positions the functional categories as heads over the lexical categories. The point is illustrated by drawing a parallel to the analysis of auxiliary verbs. Given a combination such as will understand, one views the modal auxiliary verb will, a <b>function</b> <b>word,</b> as head over the main verb understand, a content word. Extending this type of analysis to a phrase like the car, the determiner the, a <b>function</b> <b>word,</b> should be head over car, a content word. In so doing, the NP the car becomes a DP. The point is illustrated with simple dependency-based hierarchies: ...|$|E
40|$|In this paper, we {{show some}} {{properties}} of <b>function</b> <b>words</b> in dependency trees. <b>Function</b> <b>words</b> are grammatical words, such as articles, prepositions, pronouns, conjunctions, or auxiliary verbs. These words are often short and very frequent in texts and therefore {{many of them}} can be easily recognized. We formulate a hypothesis that <b>function</b> <b>words</b> tend to have a fixed number of dependents and we prove this hypothesis on treebanks. Using this hypothesis, we are able to improve unsupervised dependency parsing and outperform previously published state-of-the-art results for many languages...|$|R
5000|$|Grammatical words, as a class, {{can have}} {{distinct}} phonological properties from content words. Grammatical words sometimes {{do not make}} full use of all the sounds in a language. For example, {{in some of the}} Khoisan languages, most content words begin with clicks, but very few <b>function</b> <b>words</b> do. In English, very few <b>words</b> other than <b>function</b> <b>words</b> begin with voiced th [...] (see Pronunciation of English th); English <b>function</b> <b>words</b> may have fewer than three letters 'I', 'an', 'in' while non-function words usually have three or more 'eye', 'Ann', 'inn' (see three letter rule).|$|R
5000|$|Other <b>function</b> <b>words</b> (...) are {{separated}} from other words, including: ...|$|R
5000|$|Between the Hackensack and Passaic Rivers, Labov finds {{speakers}} typically {{lack the}} <b>function</b> <b>word</b> constraint. Thus, am, can (the verb), an, and and all typically result with tense [...] Labov also reports variable tensing in open syllables, resulting in potential tensing of planet and fashionable.|$|E
50|$|Labov {{finds the}} {{remnants}} of the New York split system present in the now-declining traditional dialect of Cincinnati, with similar variations to Northern New Jersey and Albany. Like in Albany, the open syllable constraint is completely absent. However, the <b>function</b> <b>word</b> and is reported as being lax.|$|E
50|$|In linguistics, a pro-form {{is a type}} of <b>function</b> <b>word</b> or {{expression}} that stands in for (expresses the same content as) another word, phrase, clause or sentence where the meaning is recoverable from the context. They are used either to avoid repetitive expressions or in quantification (limiting the variables of a proposition).|$|E
5000|$|Unstressed: {{unstressed}} syllables of polysyllabic words; monosyllabic <b>function</b> <b>words.</b>|$|R
50|$|Below {{are some}} Mantauran Rukai <b>function</b> <b>words</b> from Zeitoun (2007).|$|R
40|$|<b>Function</b> <b>words</b> are lexical {{units with}} {{generally}} lit-tle semantic weight that often {{play a role}} of “gram-matical ” elements in a sentence, introducing or modifying content words. These include prepo-sitions (with), determiners (some), pronouns (she) and conjunctions (furthermore). Complex <b>function</b> <b>words</b> are <b>function</b> <b>words</b> made up of several to-kens, like complex prepositions (in front of), de-terminers (a lot of) and conjunctions (as long as). This abstract discusses the representation and detection of ADV+que constructions, a type of complex conjunction in French. These construc-tions are formed by adverbs like bien (well) or ainsi (likewise) followed by subordinative con-junction que (which) ...|$|R
5000|$|The bǎ {{construction}} is a grammatical {{construction in the}} Chinese language. In a bǎ construction, {{the object of a}} verb is placed after the <b>function</b> <b>word</b> [...] (or, in more formal writing, [...] ), and the verb placed after the object, forming a subject-object-verb (SOV) sentence. [...] Linguists commonly analyze bǎ as a light verb construction, or as a preposition.|$|E
5000|$|There {{are very}} few counterexamples that proceed further, and they {{required}} special circumstances to occur. One {{is found in the}} development of Irish Gaelic with the origin of the first-person-plural pronoun muid (a <b>function</b> <b>word)</b> from the inflectional suffix -mid (as in táimid [...] "we are") because of a reanalysis based on the verb-pronoun order of the other persons of the verb.|$|E
50|$|Each time, the catena {{in green}} is the matrix predicate. Each of these predicates is a periphrastic form insofar {{at least one}} <b>function</b> <b>word</b> is present. The b-predicates are, however, more periphrastic than the a-predicates since they contain more words. The closely similar meaning of these predicates across the a- and b-variants is {{accommodated}} in terms of catenae, since each predicate is a catena.|$|E
50|$|The list of <b>function</b> <b>words</b> {{below is}} sourced from Adelaar (1997).|$|R
5000|$|<b>Function</b> <b>words</b> help in modifying meaning {{considered}} the following sentence - ...|$|R
50|$|While it is {{generally}} recognised that writer invariants exist, it is not agreed what properties of a text should be used. Among the first ones used was distribution of word lengths; other proposed invariants include average sentence length, average word length, noun, verb or adjective usage frequency, vocabulary richness, and frequency of <b>function</b> <b>words,</b> or specific <b>function</b> <b>words.</b>|$|R
