47|37|Public
50|$|The {{multichannel}} processing scheme {{described by}} 6-11 produces one <b>dimensional</b> <b>output</b> trace. A velocity filter, {{on the other}} hand, is a two-dimensional filter which produces a two-dimensional output record.|$|E
50|$|In {{geophysical}} applications sensors {{are used}} to measure and record the seismic signals. Many filtering techniques are available in which one output waveform is produced with a higher signal-to-noise ratio than the individual sensor recordings. Velocity filters are designed to remove interfering signals by exploiting {{the difference between the}} travelling velocities of desired seismic waveform and undesired interfering signals. In contrast to the one <b>dimensional</b> <b>output</b> produced by multi-channel filtering, velocity filters produce a two-dimensional output.|$|E
40|$|Dehmelt's Lambda-experiment for a three-level atom with {{simultaneously}} driven {{strong and}} weak transition is studied within quantum stochastic calculus approach. The statistics of the emitted photons is {{found by the}} method of generating functional of the corresponding two <b>dimensional</b> <b>output</b> counting process. In particular, the average waiting times for a count are calculated. Comment: 10 pages, 1 figur...|$|E
40|$|Given an {{observable}} system (C,A) € K^(mxn) X K^(nxn) with K=R or C, {{the set of}} (C,A) -invariant subspaces {{having the}} restricted system fixed observability indices is a smooth manifold embedded on the corresponding Grassmannian. We obtain an explicit parametrization of it {{by means of an}} atlas of corresponding charts. As an application we obtain the set of maximal <b>dimensional</b> <b>outputs</b> making solvable a generic Disturbance Decoupling Problem...|$|R
30|$|For {{real-time}} applications during tunnel construction, the FE model must {{be substituted}} by a fast surrogate model which {{is able to}} approximate the physical behaviour of all relevant components involved in the simulation model for mechanised tunnelling. The surrogate model is developed to predict time variant settlement fields, which is realised by a mapping of time constant and time variant low dimensional inputs onto time variant high <b>dimensional</b> <b>outputs.</b> For this mapping, a hybrid surrogate modelling strategy is proposed in the next section.|$|R
40|$|Several {{manufacturers}} are adopting six sigma programs {{in efforts to}} reduce stamping variation. This requires the crucial step of establishing dimensional relationships for the stamping <b>dimensional</b> <b>outputs</b> that become key process inputs to the assembly process. This paper describes a methodology {{used to determine the}} root cause of dimensional changes in a front door assembly. Among the key findings in this study are the importance of understanding the effects of the datum-locating scheme and the significant influence of assembly processing variables, rather than stamping variability, on the final door assembly dimensional quality...|$|R
40|$|We {{consider}} {{in this report}} non-linear models that map an input D-dimensional column vector x into a single <b>dimensional</b> <b>output</b> f(x). The non-linear mapping f(·) is implemented {{by means of a}} Gaussian process (GP) or a Relevance Vector Machine (RVM), see for example [Rasmussen, 1996] and [Tipping, 2001]. We are given a training data set D...|$|E
40|$|We propose an {{iterative}} method for approximating {{the capacity of}} classical-quantum channels with a discrete input alphabet and a finite <b>dimensional</b> <b>output,</b> possibly under additional constraints on the input distribution. Based on duality of convex programming, we derive explicit {{upper and lower bounds}} for the capacity. To provide an ε-close estimate to the capacity, the presented algorithm requires O((N ∨ M) M^ 3 (N) ^ 1 / 2 ε), where N denotes the input alphabet size and M the output dimension. We then generalize the method for the task of approximating the capacity of classical-quantum channels with a bounded continuous input alphabet and a finite <b>dimensional</b> <b>output.</b> For channels with a finite dimensional quantum mechanical input and output, the idea of a universal encoder allows us to approximate the Holevo capacity using the same method. In particular, we show that the problem of approximating the Holevo capacity can be reduced to a multidimensional integration problem. For families of quantum channels fulfilling a certain assumption we show that the complexity to derive an ε-close solution to the Holevo capacity is subexponential or even polynomial in the problem size. We provide several examples to illustrate the performance of the approximation scheme in practice. Comment: 36 pages, 1 figur...|$|E
40|$|In this paper, we are {{concerned}} with the chaotic behavior of a class of control systems described by partial differential equations. By means of finite <b>dimensional</b> <b>output</b> feedback control, it is shown that the flow on the global attractor is topologically equivalent to that of a finite dimensional difference system. In addition, an example is given to illustrate that the chaotic behavior of the flow on the global attractor can be determined by computing the Lyapunov exponent of an associated finite dimensional difference system. Department of Applied Mathematic...|$|E
40|$|Abstract. Classification of hyperspectral data is {{challenging}} {{because of high}} dimensionality inputs coupled with possible high <b>dimensional</b> <b>outputs</b> and scarcity of labeled information. Previously, a multiclassifier system was formulated in a binary hierarchical framework to group classes for accurate, rapid discrimination. In order to improve performance for small sample sizes, a new approach was developed that utilizes a feature reduction scheme which adaptively adjusts {{to the amount of}} labeled data available, while exploiting the fact that certain adjacent hyperspectral bands are highly correlated. The resulting best-basis binary hierarchical classifier (BB-BHC) family is thus able to address the “small sample size ” problem, as evidenced by experimental results obtained from analysis of AVIRIS and Hyperion data acquired over Kennedy Space Center...|$|R
40|$|Abstract. In {{order to}} detect fertilized chicken eggs nondestructively to improve {{hatching}} rate, this paper uses {{the method of}} image processing and optimizing BP neural network by particle swarm to identify fertilized chicken eggs. Firstly, we use image collection device to collect images of the unfertilized and fertilized chicken eggs, to extract the feature of egg image, and then determine the input and output vector, while optimized neural network by particle swarm is 5 dimensional input and 1 <b>dimensional</b> <b>outputs.</b> Finally, we use particle swarm algorithm to optimize the weights and threshold of neural network, {{which can be used}} to predict the condition of fertilization. The experiment shows that, compared with the traditional BP neural network, it is more accurate to recognize the fertilized chicken eggs when using optimized BP neural network by particle swarm. The rate can reach 98. 21 %, which meets the requirements of recognizing fertilized chicken eggs...|$|R
40|$|Given an {{observable}} system (C; A) 2 K mn K nn with K = R or C, {{the set of}} (C; A) -invariant subspaces {{having the}} restricted system xed observability indices is a smooth manifold embedded on the corresponding Grassmannian. We obtain an explicit parametrization of it {{by means of an}} atlas of coordinate charts. As an application we obtain the set of maximal <b>dimensional</b> <b>outputs</b> making solvable a generic Disturbance Decoupling Problem. Key words: Conditioned invariant subspace, smooth manifold, coordinate chart, Brunovsky bases, disturbance decoupling problem. e-mail: puerta@ma 1. upc. es. Partially supported by the CAICYT, Proyecto de Investigacion PB 97 - 0599 CO 3 - 03 y e-mail: coll@ma 1. upc. es. Partially supported by the CAICYT, Proyecto de Investigacion PB 97 - 0599 CO 3 - 03 z e-mail: izaballa@picasso. lc. ehu. es. Partially supported by the CAICYT, Proyecto de Investigacion PB 97 - 0599 -CO 3 - 01 1 A coordinate atlas of the manifold of observable conditioned invariant subspaces 2 1 Intro [...] ...|$|R
40|$|Abstract — This paper {{presents}} {{a new approach}} to sensor based condition monitoring feature selection using a self-organizing map. Self-Organizing Maps perform classification in a non-supervised fashion performing vector quantization and therefore place similar vectors close together in the two <b>dimensional</b> <b>output</b> space. The unsupervised process leads to the self organization of modeling with no previous knowledge of what is being modeled and therefore it does not model a predetermined environment. Taking the above into account feature selection was performed by analyzing the contributions of different sensor based features towards tool wear classification. It was found that some of the features, not previously evaluated and justified, have a strong contribution towards tool wear classification...|$|E
40|$|A {{network of}} highly {{interconnected}} linear neuron-like processing units and a simple, local, unsupcrvised rule for the modification of connection strengths between these units are proposed. After training the network {{on a high}} (m) dimensional distribution of input vectors, the lower (n) <b>dimensional</b> <b>output</b> will be a projection into the subspace of the n largest principal components (the subspace spanned by the n eigenvectors of largest eigenvalues of the input covariance matrix) and maximize the mutual information between the input and the output {{in the same way}} as principal component analysis does. The purely local natu of the synaptic modification rule (simple Hebbian and anti-Hebbian) makes the implementation of the network easier, faster and biologically more plausible than rules depending on error propagation...|$|E
40|$|Models {{of urban}} housing markets were {{originally}} developed with simplified assumptions. For example, urban form in these models {{is a single}} <b>dimensional</b> <b>output</b> {{in the shape of}} housing density. Subsequent empirical developments using hedonic price modelling and sub-market models have not attempted to link inputs or outputs to urban form. This paper explores the nature of urban form and the relationship between urban form and local housing markets. It first reviews the theoretical inter-relationships and develops a set of hypotheses. The hypotheses are then empirically tested on housing markets in three British cities – Leicester, Oxford and Sheffield. House price data from HM Land Registry are combined with information from the Census on the physical attributes of neighbourhoods as well as dwellings. ...|$|E
40|$|Following the {{approach}} described by A. V. Kryazhimskii and Yu. S. Osipov, {{we present a}} recursive algorithm which {{can be applied to}} solve the deconvolution problem of linear finite <b>dimensional</b> input <b>output</b> systems. The method gives an on line approximation of the unknown input, based on approximate samples of the output. Key features of this approach are the introduction of an associated singularly perturbed system and the use of a quasi canonical form due to Morse...|$|R
30|$|Up to date, {{numerical}} simulations in tunnelling {{are restricted}} to the design stage of a project. The support of the steering of TBMs during construction mainly relies upon the interpretation of monitoring data during the construction by experienced experts. If results from large scale numerical models are to be used during construction to provide additional information on the potential consequences of decisions taken for the steering of the TBM (e.g., the surface settlement field ahead of the tunnel face), a real-time system response is required. However, performing large scale, computationally expensive models on site is unrealistic for real-time applications, which demand obtaining the system response {{in the range of}} seconds to minutes. To accomplish the step from large-scale computational analysis to real-time predictions of expected settlements during tunnel construction, model reduction strategies are required to substitute the original numerical model by surrogate models. Recently, the authors have proposed a hybrid surrogate model [1], which employs a combination of two different techniques: recurrent neural network (RNN) and proper orthogonal decomposition (POD), aiming to exploit the advantages of both methods. While RNNs are well suited for predictions using extrapolation of data (see [2]), the POD is able to deal with high <b>dimensional</b> <b>outputs,</b> see, e.g., [3, 4].|$|R
40|$|This paper {{deals with}} the problem of {{estimating}} the initial state of a distributed field on the basis of measurements generated by sensors. The original ill-posed problem is regularized here through an auxiliary "guaranteed estimation" problem. This yields a stable numerical procedure and also allows to establish a unified "systems-theoretic" framework for treating regularizers in general. Particularly the important point is that for finite <b>dimensional</b> sensor <b>outputs</b> a necessary condition for the existence of a stable numerical solution is the observability property which ensures existence of solution in the absence of measurement noise...|$|R
40|$|International audienceState-of-the-art pattern {{recognition}} methods have difficulty dealing with problems where {{the dimension of}} the output space is large. In this article, we propose a new framework based on deep architectures (e. g. Deep Neural Networks) {{in order to deal}} with this issue. Deep architectures have proven to be efficient for high dimensional input problems such as image classification, due to their ability to embed the input space. The main contribution of this article is the extension of the embedding procedure to both the input and output spaces in order to easily handle high <b>dimensional</b> <b>output</b> problems. Using this extension, inter-output dependencies can be modelled efficiently. This provides an interesting alternative to probabilistic models such as HMM and CRF. Preliminary experiments on tay datasets and USPS character reconstruction show promising results...|$|E
40|$|Because {{conventional}} optimal {{linear regulator}} theory {{results in a}} controller which requires the capability of measuring and/or estimating the entire state vector, it is of interest to consider procedures for computing controls which are restricted to be linear feedback functions of a lower <b>dimensional</b> <b>output</b> vector and which {{take into account the}} presence of measurement noise and process uncertainty. To this effect a stochastic linear model has been developed that accounts for process parameter and initial uncertainty, measurement noise, and a restricted number of measurable outputs. Optimization with respect to the corresponding output feedback gains was then performed for both finite and infinite time performance indices without gradient computation by using Zangwill's modification of a procedure originally proposed by Powell. Results using a seventh order process show the proposed procedures to be very effective...|$|E
40|$|In this paper, Isomap and kernel Isomap {{are used}} to {{dramatically}} reduce the dimensionality of the output space to efficiently construct a Gaussian process emulator of parametrized partial differential equations. The output space consists of spatial or spatio-temporal fields that are functions of multiple input variables. For such problems, standard multi-output Gaussian process emulation strategies are computationally impractical and/or make restrictive assumptions regarding the correlation structure. The method we develop can be applied without modification to any problem involving vector-valued targets and vector-valued inputs. It also extends a method based on linear dimensionality reduction to response surfaces that cannot be described accurately by a linear subspace of the high <b>dimensional</b> <b>output</b> space. Comparisons to the linear method are made through examples that clearly demonstrate the advantages of nonlinear dimensionality reduction. ...|$|E
40|$|International audienceWe {{investigate}} a state estimation problem for an infinite dimensional system appearing in population dynamics. More precisely, given a linear model for age-structured populations with spatial diffusion, we assume the initial distribution to be unknown {{and that we}} have at our disposal an observation locally distributed in both age and space. Using Luenberger observers, we solve the inverse problem of recovering asymp-totically in time the distribution of population. The observer is designed using a finite <b>dimensional</b> stabilizing <b>output</b> injection operator, yielding an effective reconstruction method. Numerical experiments are provided showing the feasibility of the proposed reconstruction method...|$|R
40|$|Alice is {{a visual}} {{programming}} language. Alice is an object based language. The objects in Alice are 3 <b>dimensional</b> models. The <b>output</b> of Alice programs are 3 dimensional movies. 3 Visual Programming Programming {{is done by}} pointing and clicking, dragging and dropping, selecting from menus, and some typing Syntax errors removed from the equation no braces, no semi colon...|$|R
30|$|With {{the need}} for depth cues, shape understanding, and {{avoidance}} of projective ambiguity, coordinating the locations of mechanical, electrical, and plumbing pipes is a demanding task. On one hand, depth cues and shape understanding require a 3 D display, while a standard 3 D display presents issues of projective ambiguity. The issue is averted in a physical model where subjects benefit from depth cues and shape understanding of a 3 D display and avoiding projective ambiguity from a true three <b>dimensional,</b> haptic <b>output.</b> However, 77 % of practitioners preferred a 3 D computer model, while 15 % and 8 % chose 2 D drawings and a physical model respectively.|$|R
40|$|We study {{mechanism}} {{design in}} a context where communicational constraints prevent the use of revelation mechanisms, and agents behave strategically. We examine a setting with multiple agents, each producing (or purchasing) a single <b>dimensional</b> <b>output</b> with single-dimensional cost (or valuation) parameter satisfying a standard single-crossing property. Necessary and sufficient conditions for Bayesian implementation in arbitrary dynamic communication protocols are obtained. Optimal mechanisms are shown to maximize the Principals objective (with ‘virtual ’ types replacing true types) subject to communication feasibility alone. This implies delegating production (or purchase) decisions to agents strictly dominates centralized decisions. Optimal communication protocols involve multiple rounds of communication in which agents simultaneously send binary messages, if communication costs depend on total time delay. They involve sequential reports when communication costs depend instead on {{the total number of}} information bits sent...|$|E
40|$|State-of-the-art pattern {{recognition}} methods have difficulty dealing with problems where {{the dimension of}} the output space is large. In this article, we propose a new framework based on deep architectures (e. g. Deep Neural Networks) {{in order to deal}} with this issue. Deep architectures have proven to be efficient for high dimensional input problems such as image classification, due to their ability to embed the input space. The main contribution of this article is the extension of the embedding procedure to both the input and output spaces in order to easily handle high <b>dimensional</b> <b>output</b> problems. Using this extension, interoutput dependencies can be modelled efficiently. This provides an interesting alternative to probabilistic models such as HMM and CRF. Preliminary experiments on toy datasets and USPS character reconstruction show promising results. 1...|$|E
40|$|Abstract—A {{wealth of}} {{different}} feature sets for analysing {{music has been}} proposed and employed in several different Music Information Retrieval applications. In many cases, the feature sets are compared with each other based on benchmarks in supervised machine learning, such as automatic genre classification. While this approach makes features comparable for specific tasks, it doesn’t reveal much detail on the specific musical characteristics captured by the single feature sets. In this paper, we thus perform an analytic comparison of several different audio feature sets by means of Self-Organising Maps. They perform a projection from a high dimensional input space (the audio features) to a lower <b>dimensional</b> <b>output</b> space, often a two-dimensional map, while preserving the topological order of the input space. Comparing the stability of this projection allows to draw conclusions on the specific properties of the single feature sets. I...|$|E
40|$|Serial Concatenation of Two <b>Dimensional</b> Soft <b>Output</b> Viterbi Algorithm (2 D-SOVA) {{and regular}} Viterbi Algorithm (VA) for 2 D {{equalisation}} and detection of Shingled Magnetic Recording (SMR) media provides excellent performance {{as compared to}} the use of 1 Dimensional (1 D) maximum likelihood detector. In this paper, we implement and evaluate the performances of two versions of it. The first version performs 2 D SOVA along the tracks to eliminate the effect of inter-symbol interference (ISI) and then the Viterbi detector across the tracks to remove inter-track interference (ITI). The second version carries out 2 D-SOVA across the tracks and VA along the tracks. The results for high ITI and ISI show a better performance when using 2 D-SOVA across the track with a small difference in computational complexity in favour of 2 D-SOVA across the tracks...|$|R
40|$|We {{propose a}} novel {{application}} of the Simultaneous Orthogonal Matching Pursuit (S-OMP) procedure to perform variable selection in ultra-high <b>dimensional</b> multiple <b>output</b> regression problems, {{which is the first}} attempt to utilize multiple outputs to perform fast removal of the irrelevant variables. As our main theoretical contribution, we show that the S-OMP can be used to reduce an ultra-high number of variables to below the sample size, without losing relevant variables. We also provide formal evidence that the modified Bayesian information criterion (BIC) can be used to efficiently select the number of iterations in the S-OMP. Once the number of variables has been reduced to a manageable size, we show that a more computationally demanding procedure can be used to identify the relevant variables for each of the regression outputs. We further provide evidence on the benefit of variable selection using the regression outputs jointly, as opposed to performing variable selection for each output separately. The finite sample performance of the S-OMP has been demonstrated on extensive simulation studies. ...|$|R
40|$|This paper {{describes}} a web-based interactive {{framework for the}} analysis and visualization of gene expressions and protein structures. The formulation of the proposed framework was encountered by many challenges due to {{the wide range of}} relevant analysis and visualization techniques, in addition to the existence of a diversity of biological data types, on which these techniques operate. The main challenges that guided the formulation of the present framework are: (a) the integration of data from heterogeneous resources, such as expert-driven data from text, public domain databases and diverse large scale experimental data sets, and (b) difficulty in integrating the most recent analysis and visualization tools {{due to the lack of}} standard I/O. Therefore, the fundamental innovation in the proposed framework is the integration of the state-of-the-art techniques of both analysis and visualization for gene expressions and protein structures through a unified workflow. In addition, it supports a wide range of input data types and exports three <b>dimensional</b> interactive <b>outputs</b> using Virtual Reality Modeling Language (VRML) to be ready for exploration via off-the-shelf monitors as well as immersive, 3 D, stereo display environments. </p...|$|R
30|$|Notice {{that the}} formal {{specification}} {{of the edge}} covering problem as a triple 〈Ĩ,G̃,Δ̃〉, depends {{on the number of}} robots, and indeed we defined it above for A,B. To go beyond two robots, to three robots, it is necessary to add to triangles to the graphs, representing positions of three robots A,B,C, and more generally, simplices of n vertices, labeled with distinct robot ids. Then, the wait-free solvability theorem [25] is about general dimension combinatorial topology simplicial complexes. Roughly speaking, edge covering (and in general non-colorless tasks) is more difficult that graph convergence, because of a seemingly innocuous, but surprisingly “difficult” requirement: the simplicial decision map δ is color-preserving. Namely, while in a colorless task, robots can always adopt each other outputs (δ can send simplexes to lower <b>dimensional</b> <b>output</b> simplexes), this is not possible in general tasks (δ sends a final state’s algorithm simplex to an output simplex of the same dimension).|$|E
40|$|Degradable quantum {{channels}} {{are among the}} only channels whose quantum and private classical capacities are known. As such, determining the structure of these channels is a pressing open question in quantum information theory. We give {{a comprehensive review of}} what is currently known about the structure of degradable quantum channels, including a number of new results as well as alternate proofs of some known results. In the case of qubits, we provide a complete characterization of all degradable channels with two <b>dimensional</b> <b>output,</b> give a new proof that a qubit channel with two Kraus operators is either degradable or anti-degradable and present a complete description of anti-degradable unital qubit channels with a new proof. For higher output dimensions we explore the relationship between the out-put and environment dimensions (dB and dE respectively) of degradable chan-nels. For several broad classes of channels we show that they can be modeled with a environment that is “small ” in the sense dE ≤ dB. Such channels in...|$|E
40|$|The {{recognition}} of similarities in high dimensional input spaces and their visualization in low <b>dimensional</b> <b>output</b> spaces {{is a highly}} demanding application area for unsupervised artificial neural networks. Some of the problems inherent to structuring high dimensional input data may be shown with an application such as text document classification. One {{of the most prominent}} ways to represent text documents is by means of keywords extracted from the full-text of the documents and thus, document collections represent high dimensional input spaces by nature. We use a growing and splitting neural network as the underlying model for document classification. The apparent advantage of such a neural network is the adaptive network architecture that develops according to the specific requirements of the actual input space. As a consequence, the class structure of the input data becomes visible due to the separation of units into disconnected areas. The results from a growing and splitting neur [...] ...|$|E
40|$|Multi-section, {{semiconductor}} lasers {{have traditionally}} been designed and optimized for a single type of output. For example: narrow linewidth, cw; or, short duration pulses at high repetition frequency, including mode-locked pulses; or, broadband, high <b>dimensional</b> chaotic <b>output</b> have been achieved. Herein we discuss how recent results from high resolution mapping of the nonlinear dynamics of a multi-section laser suggests new thinking {{on the design of}} such multi-section laser sources. They can be designed to provide several types of output in different regions of a parameter space for a device. Thus, a single design has the potential to support several different applications. This also presents an opportunity to the photonics and optoelectronics community to think creatively about what new and significant applications might benefit from sources with multiple types of output. Also, such a motivation can focus thinking on what functions can be added to the library of "sections" that can be integrated into multi-section devices, and how these functions can be further tailored using different materials and fabrication methods. 4 page(s...|$|R
40|$|Abstract—This paper {{describes}} a web-based interactive {{framework for the}} analysis and visualization of gene expressions and protein structures. The formulation of the proposed framework was encountered by many challenges due to {{the wide range of}} relevant analysis and visualization techniques, in addition to the existence of a diversity of biological data types, on which these techniques operate. The main challenges that guided the formulation of the present framework are: (a) the integration of data from heterogeneous resources, such as expert-driven data from text, public domain databases and diverse large scale experimental data sets, and (b) difficulty in integrating the most recent analysis and visualization tools {{due to the lack of}} standard I/O. Therefore, the fundamental innovation in the proposed framework is the integration of the state-ofthe-art techniques of both analysis and visualization for gene expressions and protein structures through a unified workflow. In addition, it supports a wide range of input data types and exports three <b>dimensional</b> interactive <b>outputs</b> using Virtual Reality Modeling Language (VRML) to be ready for exploration via off-the-shelf monitors as well as immersive, 3 D, stereo display environments. Index Terms—computer visualization, bioinformatics, gene expressions, protein structures I...|$|R
40|$|The Tetris game {{is one of}} {{the most}} popular {{computer}} games ever created. As the years go, there are many developers that develop the tetris game due to the people in the world needs something new in the game. This project will implement the concept of tetris game and make the game more complicated by modify the directions of the falling tetrominoes and modify the meeting point of the tetrominoes. This project was made using the Java programming language and the data will be transformed from binary numbers into a shape of the tetrominoes using the two <b>dimensional</b> array. The <b>output</b> will be a tetris game which has four directions of the falling tetrominoes and will be met together in the center of the board gam...|$|R
