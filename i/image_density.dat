109|781|Public
25|$|Radiographic {{density is}} the measure of overall darkening of the <b>image.</b> <b>Density</b> is a {{logarithmic}} unit that describes the ratio between light hitting the film and light being transmitted through the film. A higher radiographic density represents more opaque areas of the film, and lower density more transparent areas of the film.|$|E
50|$|Reciprocity law {{failure is}} a {{phenomenon}} where {{the same amount of}} exposure (irradiance multiplied by duration of exposure) produces different <b>image</b> <b>density</b> when the irradiance (and thus duration) is varied.|$|E
5000|$|There {{are cases}} that density superadditivity holds without rate superadditivity. Note {{that the term}} superadditive {{development}} is usually not used to mean density superadditivity: the <b>image</b> <b>density</b> obtained from the combined agents {{is greater than the}} sum of the density from each agent used alone.|$|E
40|$|The {{emphasis}} {{of this paper}} is on a particular type of <b>images,</b> <b>density</b> <b>images.</b> Because of the <b>density</b> interpretation of <b>images,</b> a procedure to segmentate the <b>density</b> <b>images</b> has been developed. This procedure is based on a generate-and-test idea. The hypotheses are generated by ordinary segmentation methods. The generated regions are then tested and combined by inference. The results have been promising...|$|R
40|$|We {{consider}} a nonlinear fourth-order diffusion equation that arises in denoising of <b>image</b> <b>densities.</b> We propose an alternative direction implicit (ADI) splitting method for its numerical solution. To treat the high-order and mixed derivative {{terms in the}} equation we adopt an ADI method by Hundsdorfer and Verwer to the present setting. The paper is furnished with numerical results {{for the evolution of}} simple <b>densities</b> and for <b>image</b> denoising...|$|R
40|$|We {{consider}} a nonlinear fourth-order diffusion equation that arises in denoising of <b>image</b> <b>densities.</b> We propose an implicit time-stepping scheme that employs a primal-dual method for computing the subgradient {{of the total}} variation seminorm. The constraint on the dual variable is relaxed by adding a penalty term, depending on a parameter that determines {{the weight of the}} penalisation. The paper is furnished with some numerical examples showing the denoising properties of the model considered. ...|$|R
50|$|Radiographic {{density is}} the measure of overall darkening of the <b>image.</b> <b>Density</b> is a {{logarithmic}} unit that describes the ratio between light hitting the film and light being transmitted through the film. A higher radiographic density represents more opaque areas of the film, and lower density more transparent areas of the film.|$|E
5000|$|Noise is {{a random}} {{variation}} of <b>image</b> <b>density,</b> visible as grain in film and pixel level variations in digital images. It {{arises from the}} effects of basic physics— the photon nature of light and the thermal energy of heat— inside image sensors. Typical noise reduction (NR) software reduces the visibility of noise by smoothing the image, excluding areas near contrast boundaries. This technique works well, but it can obscure fine, low contrast detail.|$|E
50|$|Likewise, if part of {{an image}} {{receives}} less than the beginning threshold level of exposure, which depends upon the film's sensitivity to light—or speed—the film there will have no appreciable <b>image</b> <b>density,</b> and {{will appear on the}} print as a featureless black. Some photographers use their knowledge of these limits to determine the optimum exposure for a photograph; for one example, see the Zone System. Most automatic cameras instead try to achieve a particular average density.|$|E
30|$|Sensitivity for lesion {{detection}} was {{impacted by}} lesion size and intensity (Table  2). Sensitivity for lesions ≤ 10  mm was consistently {{lower than that}} for cancers larger than 10  mm for all acquisition types and significantly lower for reader 2. Sensitivity for mild-intensity lesions was significantly lower than that for moderate or marked intensity lesions for all acquisition types for both readers. No significant difference in sensitivity was observed between studies with starting low <b>image</b> count <b>density</b> at 10  min-per-view compared to studies with starting intermediate or high <b>image</b> count <b>density</b> for any acquisition type. However, the effect of <b>image</b> count <b>density</b> on lesion detection {{is reflected in the}} decreased sensitivity for lesion detection with proportional halving of the count <b>density</b> as <b>image</b> acquisition duration was halved from 10 to 5  min-per-view.|$|R
40|$|We present {{methods for}} {{estimating}} forces which drive motion observed in <b>density</b> <b>image</b> sequences. Using these forces, we also present methods for predicting velocity and density evolution. To do this, we formulate and apply a Minimum Energy Flow (MEF) method which {{is capable of}} estimating both incompressible and compressible flows from time-varying <b>density</b> <b>images.</b> Both the MEF and force-estimation techniques are applied to experimentally obtained <b>density</b> <b>images,</b> spanning spatial scales from micrometers to several kilometers. Using <b>density</b> <b>image</b> sequences describing cell splitting, for example, we show that cell division is driven by gradients in apparent pressure within a cell. Using <b>density</b> <b>image</b> sequences of fish shoals, we also quantify 1) intershoal dynamics such as coalescence of fish groups over tens of kilometers, 2) fish mass flow between different parts of a large shoal, and 3) the stresses acting on large fish shoals. United States. Office of Naval ResearchAlfred P. Sloan FoundationNational Oceanographic Partnership Program (U. S. ...|$|R
30|$|In {{terms of}} performance, we {{explored}} {{the performance of}} the proposed method against other techniques using images from various sources with different <b>image</b> sizes and <b>densities.</b> The experimental results show that the proposed method is faster than all other techniques except for [3] that performed slightly faster for low <b>density</b> <b>images.</b> The analyses of the results are also described in Section 5. Based on our findings, we conclude that the proposed method improves the performance of connected components labeling and is particularly more effective for the high <b>density</b> <b>images.</b>|$|R
5000|$|... #Caption: Plot of <b>image</b> <b>density</b> (D) vs. log {{exposure}} (H), {{yields a}} characteristic S-curve (H&D curve) {{for each type}} of film to determine its sensitivity. Changing the emulsion properties or the processing parameters will move the curve to the left or right. Changing the exposure will move along the curve, helping to determine what exposure is needed for a given film. Note the non-linear response at the far left ("toe") and right ("shoulder") of the curve.|$|E
50|$|SilhouetteFX {{is named}} for the art form {{associated}} with Étienne de Silhouette (July 8, 1709 - 1767). The fundamental output of a rotoscoping program is a matte which when viewed appears as a silhouette of an object to be treated in isolation of the remainder of an image. The <b>image</b> <b>density</b> of the matte determines how a compositing operation effect will be applied. Image pixels corresponding to brighter pixels in the matte will be treated differently than image pixels corresponding to darker pixels in the matte.|$|E
50|$|Relatively {{insensitive}} film, with a correspondingly {{lower speed}} index, requires more exposure to light {{to produce the}} same <b>image</b> <b>density</b> as a more sensitive film, and is thus commonly termed a slow film. Highly sensitive films are correspondingly termed fast films. In both digital and film photography, the reduction of exposure corresponding to use of higher sensitivities generally leads to reduced image quality (via coarser film grain or higher image noise of other types). In short, the higher the sensitivity, the grainier the image will be. Ultimately sensitivity {{is limited by the}} quantum efficiency of the film or sensor.|$|E
30|$|No {{studies of}} any {{acquisition}} type received an image quality score of 1. Of the 82 studies performed at 10  min-per-view, only one received an image quality score of 2 from one reader; <b>image</b> count <b>density</b> {{in that study}} was 739 counts/cm 2. In the corresponding 82 studies at 5  min-per-view, a total of 12 patients were assigned with image quality scores of 2 by the combination of results from both readers; average <b>image</b> count <b>density</b> in those studies was 612 counts/cm 2, ranging from 264 to 1, 009 counts/cm 2.|$|R
30|$|<b>Image</b> count <b>density</b> was {{measured}} with a region of interest including all breast tissues, excluding lesions, in craniocaudal views of the left breast of each patient and expressed in counts/cm 2.|$|R
40|$|The {{appearance}} of heterochromatin is generally {{accepted as a}} useful tool for the evaluation of the cell state including pathology; however, information on the heterochromatin DNA condensation state expressed by the <b>image</b> optical <b>density</b> in interphase nuclear regions and mitotic chromosomes with silent genes is very limited. Since human proliferating myeloblasts are a very convenient model, they were studied in the bone marrow of leukemic patients and established cell cultures using computer assisted image densitometry at the single cell level after heterochromatin visualization by a simple but sensitive cytochemical procedure for demonstration of DNA. As was expected, a high DNA <b>image</b> optical <b>density</b> was noted in central heterochromatin regions in contrast to the nuclear periphery at the nuclear envelope. Similarly, a high nuclear DNA <b>image</b> optical <b>density</b> was also expressed in mitotic chromosomes. Thus the possibility exists that the large heterochromatin DNA condensation expressed by the large <b>image</b> optical <b>density</b> in central nuclear regions, as in mitotic chromosomes, is related to silent gene locations. The similar width of mitotic chromosomes and chromatin fibrils in the heterochromatin regions in the interphase nuclei supports that explanation. The chromatin DNA fibrils in the central heterochromatin nuclear regions of interphase cells might just represent masked silent chromosomal segments. Such a conclusion is in harmony with “classical” cytology {{in the first part of}} the last century, which suggests the chromosome continuity from the mitotic division to the interphase where each chromatin region (“Kernbezirk”) actually represents a chromosomal territory...|$|R
50|$|Photographic {{paper is}} a paper {{coated with a}} {{light-sensitive}} chemical formula, used for making photographic prints. When photographic paper is exposed to light it captures a latent image that is then developed to form a visible image; with most papers the <b>image</b> <b>density</b> from exposure can be sufficient to not require further development, aside from fixing and clearing, though latent exposure is also usually present. The light-sensitive layer of the paper is called the emulsion. The most common chemistry was based on silver salts (the focus of this page) but other alternatives have also been used.|$|E
5000|$|Local {{contrast}} and density of {{various parts of}} the print can be easily controlled. Changing the amount of light exposing the paper in various areas will change the <b>image</b> <b>density</b> in those areas. A mask with a hole can be used to add extra light to an area [...] "burning", which will have the effect of darkening the regions with additional exposure, while the use of a small wand to reduce the total exposure to a region is called [...] "dodging" [...] and has the effect of lightening the regions with reduced exposure. The tool is kept moving to avoid producing a sharp edge at the region boundary. Using these techniques it is possible to make significant changes to the mood or emphasis of a photographic print. Similar methods are available with contact printing, but it is more difficult to see the image as it is being manipulated.|$|E
50|$|By 1902, {{the paper}} prints had {{accumulated}} to 1413 {{according to the}} Annual Report of the Librarian of Congress. By {{the time of their}} rediscovery in the early 1940s, over 3000 were stored within a vault of the copyright office. Librarian Howard Walls made the discovery and described the scene this way,That vault had been open to all kinds of weather, but the grating was over a shaft so it never rained in there, it never snowed in there. And the successive wrappings on these paper rolls protected them. Each time it was wrapped around, the picture underneath was protected.Walls recruited a National Archives (NARA) motion picture engineer, Carl Louis Gregory, to help get the movies back into shape for screening. Gregory observed the fragile state of the paper, some of which had sprocket perforations punched through. Sprocket holes or not, the paper could never travel through a projector or automated printer without being shredded.Gregory designed a system that adopted many of the traits involved with shooting animation in that era. He “modified a process optical printer” and was able to exchange sprocket heads and pull down pins that were necessary to advance the film and yet not tear it to pieces. An adjustable aperture plate was added to frame images that had been produced by a variety of cameras without any uniform standardization. The transfer of the paper prints was done at one exposure setting without any consideration for the variations in <b>image</b> <b>density</b> of the negative, so Gregory adjusted his lighting that reflected off the print to maximize the information captured to a new film negative. There is no record of the film format used to recapture the paper prints.|$|E
40|$|Photographic images {{enhanced}} by the method of Thiourea-S 35 autoradiography are evaluated in terms of signal-to-noise ratio, detective quantum efficiency (DQE), and Wiener spectrum analysis using digitized images. It is determined that the original signal-to-noise ratio is not degraded by the intensification process which allows {{an increase in the}} practical working DQE as a function of density. These results apply at all spatial frequencies that were tested. The advantage given by autoradiography is the ability to produce usable images from emulsions originally exposed to the low densities corresponding to maximum DQE and movement of faint <b>image</b> <b>densities</b> above the level of the threshold for detection...|$|R
5000|$|Transrating & Transizing, {{transforming}} an <b>image</b> {{size and}} <b>density</b> {{appropriate to the}} destination device ...|$|R
40|$|In {{this work}} we present Carrier <b>Density</b> <b>Imaging</b> {{as a tool}} for the {{assessment}} of the recombitation activity of defects in multicrystal line silicon. A model for the excess minority carrier density in areas with homogenously distributed dislocations is developed. The correlation of carrier <b>density</b> <b>images</b> with etch pit density and grain boundary maps allows an assessment of the recombination activity of dislocations and grain boundaries...|$|R
40|$|In Particle Image Velocimetry (PIV), {{the number}} of {{particle}} images per interrogation region, or particle <b>image</b> <b>density,</b> impacts {{the strength of the}} correlation and, as a result, {{the number of}} valid vectors and the measurement uncertainty. Therefore, any a-priori estimate of the accuracy and uncertainty of PIV requires knowledge of the particle <b>image</b> <b>density.</b> An autocorrelation-based method for estimating the local, instantaneous, particle <b>image</b> <b>density</b> is presented. Synthetic images were used to develop an empirical relationship based on how the autocorrelation peak magnitude varies with particle <b>image</b> <b>density,</b> particle image diameter, illumination intensity, interrogation region size, and background noise. This relationship was then tested using images from two experimental setups with different seeding densities and flow media. The experimental results were compared to image densities obtained through using a local maximum method as well as manual particle counts and are found to be robust. The effect of varying particle image intensities was also investigated and is found to affect the particle <b>image</b> <b>density...</b>|$|E
40|$|A {{comparison}} of three commonly used antifoggants was made. Their {{effect on the}} formation of fog and <b>image</b> <b>density</b> development was studied using a rate factor of development. This rate factor {{is defined as the}} slope of the curve for density-log development time. Bromide and benzotriazole were found to have no effect on the rate of development whereas 1 -phenyl- 5 -mercaptotetrazole was found to significantly reduce the rate of development. Bromide and benzotriazole were found to cause a suppression of <b>image</b> <b>density</b> only by increasing the time before density formation begins...|$|E
40|$|An {{overview}} {{is given}} {{of the novel}} Lagrangian particle tracking method 'Shake-The-Box', which allows particle tracking at high particle <b>image</b> <b>density.</b> The regularized interpolation of the discrete tracking information onto an Eulerian grid (FlowFit) shows an unprecedented spatial resolution. Application of the methods on two different experimental cases is briefly outlined...|$|E
40|$|In this study, {{images of}} {{nonuniform}} and uniform electric current density in conductor phantoms, which contain magnetic resonance active nuclei, are produced using Magnetic Resonance Imaging (MRI). A standard spin echo pulse sequence is used, {{with the addition}} of a bipolar current pulse. The flux density parallel to the main magnetic eld, generated by the current pulse, is encoded in the phase of the complex MR image. The spatial distribution of magnetic flux density is extracted from the phase <b>image.</b> Current <b>density</b> is calculated using the magnetic flux density. This fairly recent technique is known as Magnetic Resonance Current <b>Density</b> <b>Imaging</b> (MRCDI). In this paper, images of magnetic flux density, generated by uniform and nonuniform current flow, and the current <b>density</b> <b>image</b> of a uniform current flow are given. Current density levels as low as 1 A=mm 2 are measured. Eects of current density on k-space data are also discussed. 1...|$|R
40|$|The {{author has}} {{identified}} the following significant results. Both LANDSAT imagery and digital data were studied for usefulness in surveying water conditions of Minnesota lakes. Initial consideration {{was given to}} analysis of LANDSAT <b>image</b> <b>densities</b> because of the low technologic and cost requirements. The techniques employed, however, yield inconsistent and unreliable results. A set of criteria are given for using LANDSAT data in identification of three categories of particulate contaminants in Lake Superior. A linear transformation giving {{the relationship between the}} residual LANDSAT intensities and concentrations of three contaminants was obtained from correlation of remote sensing data with insitu measurements. LANDSAT imagery was found useful in placing peat bogs and fens in their respective geologic settings. Artificial disturbances and drainageways in peatlands could be recognized and classified...|$|R
5000|$|... {{hot water}} to make 1 liter (add {{powdered}} water color pigment, according to the <b>image</b> color and <b>density</b> required ...|$|R
40|$|We {{introduce}} {{a new approach to}} absolute continuity of laws of Poisson functionals. It is based on the energy <b>image</b> <b>density</b> property for Dirichlet forms. The associated gradient is a local operator and gives rise to a nice formula called the lent particle method which consists in adding a particle and taking it back after some calculation...|$|E
40|$|A {{nondestructive}} autoradiographic {{method is}} described which {{can provide a}} verification that rods {{in the interior of}} unirradiated LWR fuel assemblies contain low-enriched uranium. Sufficient absorber must be used to reduce contributions to <b>image</b> <b>density</b> by beta radiation from uranium- 238 daughters. When appropriate absorbers are used, the density of the image of a uranium-containing fuel rod is proportional to the uranium- 235 enrichment in that rod. Exposure times as short as 1. 5 hours can be achieved by using fast film and intensifying screens. Methods are discussed for reducing contributions to the <b>image</b> <b>density</b> of any single rod from radiation produced by all other rods in the assembly. The technique is useful for detecting missing rods, dummy rods, and rods containing depleted uranium. These defects can be detected by visual inspection of the autoradiographs. In its present state of development, the technique is not sensitive enough to reliably detect the difference between the various uranium- 235 enrichments encountered in current BWR fuel assemblies. Results are presented for field tests of the technique at BWR and PWR facilities...|$|E
40|$|In making radiographs often {{differences}} {{exposure factors}} used when using moving of horizontal and vertical. This study aims {{to determine the}} comparative value of {{the density of the}} resulting image when using a moving grid of horizontal and vertical position. So that research results can be applied in an effort {{to improve the quality of}} the radiograph. The study begins with the initial test without the grid to determine density value, the second initial test using a moving grid both horizontally and vertically without the use of material / objects. Research continued with three aluminum thickness variation are 1 mm, 3 mm and 5 mm. Then using acrylic material three thickness variation are 1 cm, 2 cm and 3 cm. Results of <b>image</b> <b>density</b> measured using a densitometer. Results are then analyzed the data. The results of research show value of the image using horizontal grid density has smaller values than the vertical but still within the range of values density using vertical grid. Thus it can be said that the <b>image</b> <b>density</b> values using moving grid horizontal position is not different with density of the image using a vertical grid at the same exposure factors...|$|E
30|$|In this paper, the human-computer {{interaction}} is coordinated and assembled in an indoor environment {{where the light}} intensity is relatively stable and the camera angle is relatively fixed. The research in this paper {{is based on the}} <b>image</b> offset <b>density</b> distribution. First, the <b>image</b> upper level <b>density</b> feature is modeled and analyzed with an infinite Dirichlet process model. Then, the image middle-density feature is modeled and analyzed with a Gaussian process classifying model. Finally, the two-level density features are fused by a binary Gaussian process classification. Experiments are carried out to verify the feasibility of the process.|$|R
40|$|PROBLEM: Conventional {{decoding}} techniques tend {{to operate}} {{exclusively in the}} space domain and often rely on code-specific “finder features,” ECC, high-resolution imaging, image resampling (a “lossy” process), encoded data “clues” and low code <b>density</b> relative to <b>image</b> resolution (see EASY examples below). This limits {{the amount of information}} that can be reliably encoded into a given area. RESEARCH OBJECTIVES: Recover randomly-oriented 2 D bit fields without resampling, without reliance on finder features, and without dependency on encoding or data content. Decode at <b>image</b> <b>densities</b> that produce aliasing of primary grid frequencies – alias disambiguation (see HARD example below). Provide linear code density improvement of 1. 5 : 1 to 2 : 1 over conventional techniques, resulting in an increase in data density per unit area of 2. 25 : 1 to 4 : 1...|$|R
40|$|The {{author has}} {{identified}} the following significant results. Analysis of ERTS- 1 imagery with underflight aerial photo support including U- 2, in the Sierra Nevada Mountains of California, indicates promising possibilities of detecting and monitoring forest insect outbreaks visually with some mechanical support utilizing the VP- 8 image analyzer. Visually, {{it is possible}} at a scale of 1 : 1, 000, 000 to discriminate between large areas of damaged and undamaged forests; timbered and non-timbered areas; pasture land and cultivated fields; desert and riparian vegetation. At a scale of 1 : 80, 000 {{it is possible to}} distinguish among three classes of tree mortality; defoliated and undefoliated areas; non-host mixed conifers; and mountain meadows, rock domes, lakes and glaciers. Machine tests showed significant differences in <b>image</b> <b>densities</b> among various bands and mortality areas...|$|R
