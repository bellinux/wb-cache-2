795|10000|Public
5000|$|From 1960 to 1969 he {{was first}} the {{engineering}} manager and then Program Manager for development and delivery of the IBM 1350 Photo <b>Image</b> <b>Retrieval</b> <b>System</b> / 1360 Photo-Digital Storage System. The IBM 1360 was the first [...] "trillion-bit" [...] data storage system (about 160 GB). It was developed for the Atomic Energy Commission.|$|E
50|$|Based on {{this kind}} of image representation, we can then use text {{retrieval}} techniques to design an <b>image</b> <b>retrieval</b> <b>system.</b> However, since all text retrieval systems depend on terms, the user’s query images must be converted into a set of visual terms in the system. Then, it will compare these visual terms with all visual terms in the database.|$|E
50|$|He {{has carried}} out {{work with the}} Biomedical Informatics Group and the Computer Science Database Group at Stanford that makes {{possible}} the retrieval of specific images from databanks of images. He has co-developed the SIMPLIcity semantics-sensitive <b>image</b> <b>retrieval</b> <b>system,</b> the ALIPR automatic linguistic indexing of pictures system, and the ACQUINE visual aesthetics rating system. These systems have been applied to several domains including biomedical image analysis, satellite imaging, Web image filtering, and art and cultural imaging. The SIMPLIcity system has been sought after and obtained by researchers from more than 100 institutions.|$|E
40|$|Digital image {{collections}} are expanding day by day, and <b>image</b> <b>retrieval</b> becomes even harder. Both individuals and institutions encounter serious problems when building their image archives and later when retrieving the archived images. Visual information cannot be fully expressed in words and normally depends on intuitive human perception. Consequently, this causes {{us to find}} the plain text-based information inadequate, and as a result, increases {{the value of the}} visual content. However describing, storing and retrieving the visual content is not simple. The research activities in this area, which escalated in the 90 ’s, have brought several solutions to the understanding, design and development of the <b>image</b> <b>retrieval</b> <b>systems.</b> This article reviews the studies on <b>image</b> <b>retrieval</b> <b>systems</b> in general, and content-based <b>image</b> <b>retrieval</b> <b>systems</b> specifically. The article also examines the features of content-based <b>image</b> <b>retrieval</b> <b>systems...</b>|$|R
40|$|With the {{widespread}} dissemination of picture archiving and communication systems (PACSs) in hospitals, {{the amount of}} imaging data is rapidly increasing. Effective <b>image</b> <b>retrieval</b> <b>systems</b> are required to manage these complex and large image databases. The authors reviewed the past development and {{the present state of}} medical <b>image</b> <b>retrieval</b> <b>systems</b> including textbased and content-based systems. In order to provide a more effective <b>image</b> <b>retrieval</b> service, the intelligent content-based <b>retrieval</b> <b>systems</b> combined with semantic systems are required...|$|R
50|$|There are {{evaluation}} {{workshops for}} <b>image</b> <b>retrieval</b> <b>systems</b> aiming {{to investigate and}} improve the performance of such systems.|$|R
5000|$|An <b>image</b> <b>retrieval</b> <b>system</b> is a {{computer}} system for browsing, searching and retrieving images from a large database of digital images. Most traditional and common methods of image retrieval utilize some method of adding metadata such as captioning', keywords, or descriptions to the images so that retrieval can be performed over the annotation words. Manual image annotation is time-consuming, laborious and expensive; to address this, {{there has been a}} large amount of research done on automatic image annotation. Additionally, the increase in social web applications and the semantic web have inspired the development of several web-based image annotation tools.|$|E
50|$|At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard, and John Collomosse {{extended}} the HOG descriptor {{for use in}} sketch based image retrieval (SBIR). A dense orientation field was extrapolated from dominant responses in the Canny edge detector under a Laplacian smoothness constraint, and HOG computed over this field. The resulting gradient field HOG (GF-HOG) descriptor captured local spatial structure in sketches or image edge maps. This enabled the descriptor to be used within a content-based <b>image</b> <b>retrieval</b> <b>system</b> searchable by free-hand sketched shapes. The GF-HOG adaptation was shown to outperform existing gradient histogram descriptors such as SIFT, SURF, and HOG by around 15 percent at the task of SBIR.|$|E
5000|$|When Walnut was {{successfully}} delivered in 1961, the San Jose lab turned {{its attention to}} commercializing the system under the project name [...] "Cypress". A direct analog of Walnut for document storage became the 1350 Photo <b>Image</b> <b>Retrieval</b> <b>System,</b> while the same basic system storing computer data became the 1360 Photo-Digital Storage System. Both systems used the same photographic cards and automated film development system originally developed for Walnut, but replacing the diazo film with longer-lasting conventional silver halide films. The system used pneumatics to move the film cards between the more complex developer system, the reader/copier, and a much larger store.Jack Harker was the Program Manager for the development and delivery of the systems.|$|E
40|$|A {{major problem}} {{in the field of}} {{content-based}} <b>image</b> <b>retrieval</b> is the lack of a common performance measure which allows the researcher to compare different <b>image</b> <b>retrieval</b> <b>systems</b> in a quantitative and objective manner. We analyze different proposed performance evaluation measures, select an appropriate one, and give quantitative results for four different, freely available <b>image</b> <b>retrieval</b> tasks using combinations of features. This work gives a concrete starting point for the comparison of content-based <b>image</b> <b>retrieval</b> <b>systems.</b> An appropriate performance measure and a set of databases are proposed and results for different retrieval methods are given...|$|R
40|$|This papers {{presents}} CIRES, a new online <b>system</b> for content-based <b>retrieval</b> {{in digital}} <b>image</b> libraries. Contentbased <b>image</b> <b>retrieval</b> <b>systems</b> have traditionally used {{color and texture}} analyses. These analyses have not always achieved adequate level of performance and user satisfaction. The growing need for robust <b>image</b> <b>retrieval</b> <b>systems</b> {{has led to a}} need for additional retrieval methodologies. CIRES addresses this issue by using image structure in addition to color and texture. The efficacy of using structure in combination with color and texture is demonstrated...|$|R
40|$|Traditional <b>image</b> <b>retrieval</b> <b>systems</b> {{are content}} based <b>image</b> <b>retrieval</b> <b>systems</b> which rely on {{low-level}} features for indexing and <b>retrieval</b> of <b>images.</b> CBIR <b>systems</b> {{fail to meet}} user expectations because of {{the gap between the}} low level features used by such systems and the high level perception of images by humans. Semantics based methods have been used to describe images according to their high level features. In this paper, we performed experiments to identify the failure of existing semantics-based methods to retriev...|$|R
50|$|Let’s {{consider}} that the pixels of an image, which are the smallest parts in a digital images (can not be divided into smaller ones), are like the letters of an alphabetical language. Then, a set of pixels in an image (patches or arrays of pixels) is a word. Each word can then be re-processed into a morphological system to extract a term related to that word. Then, several words can share a same meaning, each one will refer to the same term (like in any language). More than one words shared the same meaning and its {{belong to the same}} term (have same information). By this view, researchers can take advantage from text retrieval techniques to apply them to <b>image</b> <b>retrieval</b> <b>system.</b>|$|E
5000|$|The {{company was}} founded by Tom and Jim Waschura, {{identical}} twins who formerly worked for Ampex Corporation in Redwood City, California. Tom Waschura's electrical engineering degree from M.I.T. landed him a job at Ampex's Data Systems division working on tape recording and early parallel-transfer disk drives. Jim Waschura's software engineering background proved useful in Ampex's Video Systems division, working on 'still stores' used for broadcast television, especially news production. Tom left Ampex and the brothers created a partnership called Designware Associates to assist a fledgling company called Systems West create the first polar-orbiting satellite <b>image</b> <b>retrieval</b> <b>system</b> for commercial boating and fishing. Bob's electrical engineering degree from RPI helped him head up marketing and sales. Later, Tom recalled a senior engineer at Ampex, John Corcoran, working to add digital communications channels to analog tape recorders that Ampex manufactured. John and Tom employed a device known as a Bit Error Rate tester (BERT) that generated a pseudo-random series of bits to record and later to be played-back into the BERT device that verified that the bits had been reproduced correctly. This effort was undertaken {{about the same time}} early personal computers were becoming available, known as [...] "PC/AT" [...] or 80286-based personal computers. Whereas the BERT device indicated the number of bits that were incorrectly reproduced, {{it became clear that the}} effort of implementing a digital communications channel on an analog tape recorder would be greatly helped if it were clear which bits were in error—not just the quantity of the erred bits—and it seemed the new powerful personal computers ought to be able to do this. This became the genesis of Error Location Analysis technology that was later patented and implemented in all BitAlyzer and BERTScope products, and that was licensed to Hewlett Packard Company (later called Agilent Technologies, and now called Keysight) who implemented it in their popular 86130 3.0 Gbit/s BERT instrument.|$|E
40|$|Abstract. In the page, {{we discuss}} {{relevance}} feedback techniques in <b>image</b> <b>retrieval</b> <b>system,</b> and then {{focus on the}} SVM-based relevance feedback. Using SVM-based relevance feedback, the precision rate of <b>image</b> <b>retrieval</b> <b>system</b> is satisfied. In order {{to better understand the}} effectiveness of SVM-based relevance feedback in <b>image</b> <b>retrieval</b> <b>system,</b> some well-designed experiments are taken out...|$|E
40|$|This work {{proposes a}} new method called Center Symmetric Local Binary Pattern Grey Level Co-occurrence Matrix (CSLBPGLCM) {{for the purpose}} of extracting second order {{statistical}} texture features in ultrasound kidney images. These features are then feed into ultrasound kidney <b>images</b> <b>retrieval</b> <b>system</b> for the point of medical applications. This new GLCM matrix combines the benefit of CSLBP and conventional GLCM. The main intention of this CSLBPGLCM is {{to reduce the number of}} grey levels in an image by not simply accumulating the grey levels but incorporating another statistical texture feature in it. The proposed approach is cautiously evaluated in ultrasound kidney <b>images</b> <b>retrieval</b> <b>system</b> and has been compared with conventional GLCM. It is experimentally proved that the proposed method increases the retrieval efficiency, accuracy and reduces the time complexity of ultrasound kidney <b>images</b> <b>retrieval</b> <b>system</b> by means of second order statistical texture features...|$|R
40|$|Purpose: With {{the rapid}} growing volume of images in medical databases, {{development}} of efficient <b>image</b> <b>retrieval</b> <b>systems</b> to retrieve relevant or similar images to a query image {{has become an}} active research area. Despite many {{efforts to improve the}} performance of techniques for accurate <b>image</b> <b>retrieval,</b> its success in biomedicine thus far has been quite limited. This article presents an adaptive content-based <b>image</b> <b>retrieval</b> (CBIR) <b>system</b> for improving the performance of <b>image</b> <b>retrieval</b> in mammographic databases...|$|R
40|$|Abstract—We {{introduce}} a benchmark {{for evaluating the}} performance of large scale sketch-based <b>image</b> <b>retrieval</b> <b>systems.</b> The necessary data is acquired in a controlled user study where subjects rate how well given sketch/image pairs match. We suggest {{how to use the}} data for evaluating the performance of sketch-based <b>image</b> <b>retrieval</b> <b>systems.</b> The benchmark data as well as the large image database are made publicly available for further studies of this type. Furthermore, we develop new descriptors based on the bag-of-features approach and use the benchmark to demonstrate that they significantly outperform other descriptors in the literature...|$|R
40|$|AbstractThis paper {{highlights}} content based <b>image</b> <b>retrieval</b> <b>system</b> using {{alignment of}} ontologies. The traditional contents-based image retrieval systems using single ontology retrieve imprecise images. To overcome this weakness, proposed <b>image</b> <b>retrieval</b> <b>system</b> designed using core semantic multiple ontology which merges feature ontology, semantic feature ontology, user ontology and metadata ontology. Proposed content based <b>image</b> <b>retrieval</b> <b>system</b> reduce semantic gap and provides highly accurate, {{efficient and effective}} image retrieval result...|$|E
40|$|Abstract — Many {{areas of}} commerce, government, academia, and {{hospitals}} create large collections of digital images. Digital image databases {{open the way}} to content-based searching. One of the tool that is essential for electronic publishing is a powerful <b>image</b> <b>retrieval</b> <b>system.</b> Most commercial <b>image</b> <b>retrieval</b> <b>system...</b>|$|E
40|$|In this study, {{we suggest}} {{a method to}} adapt an <b>image</b> <b>retrieval</b> <b>system</b> into a {{configurable}} one. Basically, original feature space of a content-based retrieval system is nonlinearly transformed into a new space, where {{the distance between the}} feature vectors is adjusted by learning. The transformation is realized by Artificial Neural Network architecture. A cost function is defined for learning and optimized by simulated annealing method. Experiments are done on the texture <b>image</b> <b>retrieval</b> <b>system,</b> which use Gabor Filter features. The results indicate that configured <b>image</b> <b>retrieval</b> <b>system</b> is significantly better than the original system. 1...|$|E
40|$|<b>Image</b> <b>retrieval</b> {{has been}} one of the most {{interesting}} and vivid research areas in the field of computer vision. Content-based <b>image</b> <b>retrieval</b> (CBIR) <b>systems</b> are used in order to automatically index, search, retrieve and browse image databases. Colour and texture features are important properties in content-based <b>image</b> <b>retrieval</b> <b>systems.</b> In this paper we have mentioned detailed classification of CBIR system. We have discussed the efficiency of different techniques and the combination of them to improve the performance. </p...|$|R
40|$|Color {{features}} {{are important to}} pictures and {{they are easy to}} calculate. Therefore, the {{features are}} widely used in Content Base <b>Image</b> <b>Retrieval.</b> The color correlogram is a simple statistics descriptor of a color image that has been widely used for content base <b>image</b> <b>retrieval</b> <b>systems.</b> To measure similarity between two images using the correlogram, the conventional approaches use the relative distance. Here to improve performance of the content base <b>image</b> <b>retrieval</b> <b>systems,</b> the inner product metric is used to measure similarity of images instead of the relative distance. Results of experiments proved that the content base <b>image</b> <b>retrieval</b> using the inner product metric has better performance than the one using the relative distance...|$|R
40|$|A {{growing number}} of clinicians, educators, researchers, and others use digital images in their work and search for them via <b>image</b> <b>retrieval</b> <b>systems.</b> Yet, this area of {{information}} retrieval is much less understood and developed than searching for text-based content, such as biomedical literature and its derivations. The goal of the ImageCLEF medical <b>image</b> <b>retrieval</b> task (ImageCLEFmed) is to improve understanding and system capability in search for medical images. In this paper, we describe the {{development and use of}} a medical image test collection designed to facilitate research with <b>image</b> <b>retrieval</b> <b>systems</b> and their users. We also provide baseline results with the new collection and describe them in the context of past research with portions of the collection...|$|R
40|$|Abstract: <b>Image</b> <b>retrieval</b> <b>system</b> {{becoming}} a more popular {{in all the}} disciplines of image search. In real-time, interactive <b>image</b> <b>retrieval</b> <b>system</b> has become more accurate, fast and scalable to large collection of image databases. This paper presents a unique method for an <b>image</b> <b>retrieval</b> <b>system</b> based on firefly algorithm, which improve the accuracy and computation time of the <b>image</b> <b>retrieval</b> <b>system.</b> The firefly algorithm is utilized to optimize the image retrieval process via search for nearly optimal combinations between the corresponding features as well as finding out approximate optimized weights for similarities {{with respect to the}} features. The proposed method is able to dynamically reflect the user’s intention in the retrieval process by optimizing the objective function. The Efficiency of the proposed method is compared with other existing image retrieval methods through precision and recall. The performance of the method is experimented on the Corel and Caltech database images. 1...|$|E
40|$|This report investigates four data {{structures}} {{intended to}} store (intermediate) search {{results in the}} Eff 2 <b>Image</b> <b>Retrieval</b> <b>System.</b> Eff 2 <b>Image</b> <b>Retrieval</b> <b>System</b> is a research project that involves developing a prototype of an <b>image</b> <b>retrieval</b> <b>system</b> based on local descriptors. This projects goal {{was to find a}} data structure that supports fast display of data to client interface but has as little influence on the efficiency of the search process as possible when polled frequently. Three different data structures where implemented and experiments conducted on them (data structures B,C and D). The fourth data structure studied is the one used in the Eff 2 <b>Image</b> <b>Retrieval</b> <b>System</b> (data structure A). The results indicate that data structure A is well suited when polling is not frequent. If the time between polling intervals drops and is lower than 3 - 5 seconds then data structure D shows best results. 1...|$|E
40|$|An <b>image</b> <b>retrieval</b> <b>system</b> is a {{computer}} system for browsing, searching and retrieving image using the actual content of image like visual features of an image as color, texture, shape, rotation, scaling factor and spatial layout. Now a days, retrieval of image from a large database are based on their visual similarity. The proposed <b>Image</b> <b>retrieval</b> <b>system</b> allows automatic extraction of target image according to object feature of the image itself. The proposed system {{is to improve the}} performance of <b>image</b> <b>retrieval</b> <b>system</b> using image classification. To improve existing <b>image</b> <b>retrieval</b> <b>system,</b> image decomposition, feature extraction and image matching mechanism should be improved. For image decomposition, modified Haar Wavelet Transform and D 4 Wavelet Transform, to decompose color image into multilevel scale and for the conversion of wavelet coefficients has been used. Furthermore, progressive image retrieval strategy to achieve flexible CBIR is incorporated. The image feature are extracted by using Scale Invariant Feature Transform (SIFT). This approach relies on the choice of several parameters which directly impact its effectiveness when applied to retrieve image. Image matching is done by using NNS algorithm in KD-tree. The proposed system has demonstrated a improved <b>image</b> <b>retrieval</b> <b>system</b> on various database include WANG, MirFlickr, CLEF that containing approximately 15, 000 color images...|$|E
40|$|We {{present a}} novel machine {{learning}} based approach to de- termining the semantic relevance of community contributed image annotations {{for the purposes}} of <b>image</b> <b>retrieval.</b> Cur- rent large scale community <b>image</b> <b>retrieval</b> <b>systems</b> typically rely on human annotated tags which are subjectively assigned and may not provide useful or semantically meaningful la- bels to the images. Homogeneous tags which fail to distin- guish between are a common occurrence, which can lead to poor search effectiveness on this data. We described a method to improve text based <b>image</b> <b>retrieval</b> <b>systems</b> by eliminating generic or non relevant image tags. To classify tag relevance, we propose a novel feature set based on statistical information available for each tag within a collection of geotagged images harvested from Flickr. Using this feature set machine learning models are trained to classify the relevance of each tag to its associated image. The goal of this process is to allow for rich and accurate captioning of these images, with the objective of improving the accuracy of text based <b>image</b> <b>retrieval</b> <b>systems.</b> A thorough evaluation is carried out using a human annotated benchmark collection of Flickr tags...|$|R
40|$|Combining {{low-level}} {{features that}} represent the content of medical images with high level features that are saved with images would allow the expansion of text queries submitted to Content Based <b>Image</b> <b>Retrieval</b> (CBIR) <b>systems.</b> Expanding these text queries would allow CBIR systems to respond more effectively to specific queries when retrieving medical images. We hypothesized that adding an automatic classification method to the current retrieval process would help improve {{the performance of the}} University at Buffalo Medical Text and <b>Images</b> <b>Retrieval</b> <b>System</b> (UBMedTIRS). This paper illustrates the results of our approach and its implications for expanding query statements in medical <b>image</b> information <b>retrieval</b> (IR) <b>systems...</b>|$|R
40|$|In {{this paper}} we {{introduce}} imageFARMER, {{a framework that}} allows information retrieval researchers and educators to develop and customize domain-specific content-based <b>image</b> <b>retrieval</b> <b>systems</b> with ease while developing {{a deeper understanding of}} the underlying representation of domainspecific image data. imageFARMER incorporates different aspects of image processing and content-based information <b>retrieval,</b> such as: <b>image</b> representation via image parameter extraction, validation via image parameters, analysis of multiple dissimilarity measures for accurate data analysis, testing of dimensionality reduction methods for storage and processing optimization, and indexing algorithms for fast and efficient querying. The unique capabilities of this framework have not been available together as an open-source software package designed for research, while offering enhanced knowledge discovery and validation of all steps involved when creating large-scale content-based <b>image</b> <b>retrieval</b> <b>systems.</b> General Terms <b>Image</b> <b>retrieval,</b> content-based <b>image</b> <b>retrieval,</b> open-source software applications, evaluation framework. Keywords Content-based <b>image</b> <b>retrieval,</b> retrieval, attribute evaluation, dimensionality reduction. 1...|$|R
40|$|Tony Stone Images have {{designed}} a textual classification structure and an <b>image</b> <b>retrieval</b> <b>system</b> to store and retrieve pictures within the stock photography domain. The <b>image</b> <b>retrieval</b> <b>system</b> {{has been designed}} from the stock photography domain-specifics with facilities to search for different objects and their attributes within an image, and on relations between these objects. The retrieval system is text-based {{with a set of}} 12, 000 controlle...|$|E
30|$|Figure 3 {{illustrates}} the proposed <b>image</b> <b>retrieval</b> <b>system</b> frame work and algorithm {{for the same}} is given below.|$|E
40|$|AbstractA {{scalable}} content based <b>image</b> <b>retrieval</b> <b>system</b> {{for large-scale}} www database is designed and implemented. Million images on internet is big challenge for accurate and efficient image retrieval as per user requirement. Proposed system exploits semantic binary code generation techniques with semantic hashing function, fine and coarse similarity measure technique, automatic and manual relevance feedback technique which improve accuracy, speed of image retrieval. With dramatic growth of internet technology, scalable <b>image</b> <b>retrieval</b> <b>system</b> {{is a need}} of recent web based image retrieval applications such as biomedical imaging, medical diagnosis, space science application etc. Proposed system accomplish requirement of scalable, accurate and swift <b>image</b> <b>retrieval</b> <b>system.</b> Experimental result clearly shows that performance of image retrieval is improved in term of accuracy, efficiency and retrieval time...|$|E
40|$|Content-Based <b>Image</b> <b>Retrieval</b> (CBIR) is {{also known}} as Query By Image Content (QBIC) is the {{application}} of computer vision techniques and it gives solution to the <b>image</b> <b>retrieval</b> problem such as searching digital images in large databases. The need to have a versatile and general purpose Content Based <b>Image</b> <b>Retrieval</b> (CBIR) <b>system</b> for a very large image database has attracted focus of many researchers of information-technology-giants and leading academic institutions for development of CBIR techniques. Due to the development of network and multimedia technologies, users are not fulfilled by the traditional information retrieval techniques. So nowadays the Content Based <b>Image</b> <b>Retrieval</b> (CBIR) are becoming a source of exact and fast retrieval. Texture and color are the important features of Content Based <b>Image</b> <b>Retrieval</b> <b>Systems.</b> In the proposed method, images can be retrieved using color-based, texture-based and color and texture-based. Algorithms such as auto color correlogram and correlation for extracting color based images, Gaussian mixture models for extracting texture based images. In this study, Query point movement is used as a relevance feedback technique for Content Based <b>Image</b> <b>Retrieval</b> <b>systems.</b> Thus the proposed method achieves better performance and accuracy in retrieving images...|$|R
40|$|Texture is {{commonly}} used feature {{in most of the}} content-based <b>image</b> <b>retrieval</b> <b>systems.</b> This texture <b>retrieval</b> ability can be also applied to rock texture. The retrieval of the rock texture is a demanding task because of special character of rock. In this paper some existing contentbased <b>image</b> <b>retrieval</b> <b>systems</b> are tested with a sample set representing clearly different rock images. The recall ability of these systems is measured based on the retrieval experiments. Texture retrieval has also been made using some well-known classifying features, which are extracted from the textures. The extracted features are based on second order statistics (cooccurrence matrix) and texture directionality. These features proved to be powerful in the sample texture retrieval. 1...|$|R
40|$|Abstract- As the {{diversity}} and size of digital image collections grow exponentially, efficient <b>image</b> <b>retrieval</b> is becoming increasingly important. In general, current automatic <b>image</b> <b>retrieval</b> <b>systems</b> can be characterized into two categories: textbased and image content-based. For text-based <b>image</b> <b>retrieval,</b> the <b>images</b> are searched using the annotated text. In this framework, manual image annotation is extremely laborious and the visual content of images are difficult to be described precisely by a limited set of text terms. To overcome these difficulties, content-based <b>image</b> <b>retrieval</b> <b>systems</b> index <b>images</b> by their visual content, such as color, shape, texture, etc. It is a remarkable fact that, neither searching the images based {{on the content of}} the image nor searching the images using the annotated text may lead to an accurate result but jointly they tend to produce a perfect result; this is probably because the writers o...|$|R
