1605|266|Public
25|$|Knowledge Engineering Environment (KEE) used {{an object}} system called UNITS and {{integrated}} {{it with an}} <b>inference</b> <b>engine</b> and a truth maintenance system (ATMS).|$|E
25|$|Knowledge {{representation}} {{goes hand in}} {{hand with}} automated reasoning because one of the main purposes of explicitly representing knowledge is to be able to reason about that knowledge, to make inferences, assert new knowledge, etc. Virtually all knowledge representation languages have a reasoning or <b>inference</b> <b>engine</b> as part of the system.|$|E
25|$|Expert systems {{gave us the}} {{terminology}} still in use today where AI systems are divided into a Knowledge Base with facts about the world and rules and an <b>inference</b> <b>engine</b> that applies the rules to the knowledge base in order to answer questions and solve problems. In these early systems the knowledge base tended to be a fairly flat structure, essentially assertions about the values of variables used by the rules.|$|E
40|$|Ubiquitous {{computing}} services {{started taking}} advantage of the reasoning capabilities of <b>inference</b> <b>engines</b> to acquire hidden and potentially useful contextual information. However, performance evaluations of the <b>inference</b> <b>engines</b> have been limited to the domain of static information reasoning; evaluations of requirements pertaining to ubiquitous computing environment have been largely neglected. This paper aims to examine how different types of <b>inference</b> <b>engines</b> perform by applying them to realistic ubiquitous computing scenarios. Based on the scenarios, three measurement criteria are proposed and measured including scalability as data set gets large, responsiveness for user’s requests, and adaptability to frequent inference requests...|$|R
40|$|Abstract. Existing {{constraint}} programming systems offer a fixed set of <b>inference</b> <b>engines</b> implementing search {{strategies such as}} single, all, {{and best}} solution search. This is unfortunate, since new engines cannot be integrated by the user. The paper presents first-class computation spaces as abstractions with which the user can program <b>inference</b> <b>engines</b> at a high level. Using computation spaces, the paper covers several <b>inference</b> <b>engines</b> ranging from standard search strategies to techniques new to constraint programming, including limited discrepancy search, visual search, and saturation. Saturation is an inference method for tautologychecking used in industrial practice. Computation spaces have shown their practicability in the constraint programming system Oz. ...|$|R
50|$|Programming {{languages}} such as Prolog, Knowledge Machine and ECLiPSe support {{backward chaining}} within their <b>inference</b> <b>engines.</b>|$|R
2500|$|The {{integration}} of Frames, rules, and object-oriented programming was significantly driven by commercial ventures such as KEE and Symbolics spun off from various research projects. At {{the same time}} as this was occurring, there was another strain of research which was less commercially focused and was driven by mathematical logic and automated theorem proving. [...] One of the most influential languages in this research was the KL-ONE language of the mid 80's. KL-ONE was a frame language that had a rigorous semantics, formal definitions for concepts such as an Is-A relation. KL-ONE and languages that were influenced by it such as Loom had an automated reasoning engine that was based on formal logic rather than on IF-THEN rules. This reasoner is called the classifier. A classifier can analyze a set of declarations and infer new assertions, for example, redefine a class to be a subclass or superclass of some other class that wasn't formally specified. In this way the classifier can function as an <b>inference</b> <b>engine,</b> deducing new facts from an existing knowledge base. The classifier can also provide consistency checking on a knowledge base (which in the case of KL-ONE languages is also referred to as an Ontology).|$|E
5000|$|OntoBroker is an <b>inference</b> <b>engine</b> {{with native}} {{reasoning}} over F-Logic, ObjectLogic, RIF, and OWL. (https://www.w3.org/2001/sw/wiki/OntoBroker, W3C-listed <b>inference</b> <b>engine)</b> ...|$|E
5000|$|Cyc <b>inference</b> <b>engine,</b> {{a forward}} and {{backward}} chaining <b>inference</b> <b>engine</b> with numerous specialized modules for high-order logic. (http://research.cyc.com/ ResearchCyc) (http://opencyc.org/ OpenCyc) ...|$|E
5000|$|Be Informed Suite (Commercial {{tool for}} {{building}} large ontology based applications. Includes visual editors, <b>inference</b> <b>engines,</b> export to standard formats) ...|$|R
40|$|Solutions to {{combinatorial}} search {{problems can}} benefit from custom-made constraint-based <b>inference</b> <b>engines</b> that go beyond depthfirst search. Several constraint programming systems support the programming of such <b>inference</b> <b>engines</b> through programming abstractions. For example, the Mozart system for Oz comes with several engines, extended in dimensions such as interaction, visualization, and optimization. However, so far such extensions are monolithic in their software design, not catering for systematic reuse of components. We present an object-oriented modular architecture for building <b>inference</b> <b>engines</b> that achieves high reusability and supports rapid prototyping of search algorithms and their extensions. For the sake of clarity, we present the architecture {{in the setting of}} a C++ constraint programming library. The SearchToolKit, a search library for Oz based on the presented architecture, provides evidence for the practicality of the design...|$|R
5000|$|As {{expert systems}} evolved, many new {{techniques}} {{were incorporated into}} various types of <b>inference</b> <b>engines.</b> Some {{of the most important}} of these were: ...|$|R
50|$|An <b>inference</b> <b>engine</b> is a {{computer}} program that tries to derive answers from a knowledge base.The Cyc <b>inference</b> <b>engine</b> performs general logical deduction (including modus ponens, modus tollens, universal quantification and existential quantification).|$|E
50|$|An {{expert system}} {{is divided into}} two subsystems: the <b>inference</b> <b>engine</b> and the {{knowledge}} base. The knowledge base represents facts and rules. The <b>inference</b> <b>engine</b> applies the rules to the known facts to deduce new facts. Inference engines can also include explanation and debugging abilities.|$|E
5000|$|Perform inferences as {{a forward}} {{chaining}} FOPL <b>inference</b> <b>engine.</b>|$|E
40|$|Abstract. Good {{tree search}} {{algorithms}} {{are a key}} requirement for <b>inference</b> <b>engines</b> of rule languages. As Prolog exemplifies, <b>inference</b> <b>engines</b> based on traditional uninformed search methods with their well-known deficiencies are prone to compromise declarativity, the primary concern of rule languages. The paper presents a new family of uninformed search algorithms that combine {{the advantages of the}} traditional ones while avoiding their shortcomings. Moreover, the paper introduces a formal framework based on partial orderings, which allows precise and elegant analysis of such algorithms. ...|$|R
40|$|Agent {{systems that}} search the Semantic Web {{are seen as}} killer {{applications}} for description logic (DL) <b>inference</b> <b>engines.</b> The guiding examples for the Semantic Web involve information and document retrieval tasks. The instance retrieval inference service of description logic <b>inference</b> <b>engines</b> {{can be used as}} a basic machinery for implementing agent-based retrieval systems. However, since information is permanently added to information sources, usually agents need to return to previously visited servers in order to get updates for their queries over time...|$|R
40|$|Good {{tree search}} {{algorithms}} {{are a key}} requirement for <b>inference</b> <b>engines</b> of rule languages. As Prolog exemplifies, <b>inference</b> <b>engines</b> based on traditional uninformed search methods with their well-known deficiencies are prone to compromise declarativity, the primary concern of rule languages. The paper presents a new family of uninformed search algorithms that combine {{the advantages of the}} traditional ones while avoiding their shortcomings. Moreover, the paper introduces a formal framework based on partial orderings, which allows precise and elegant analysis of such algorithms. ...|$|R
50|$|In {{the field}} of Artificial Intelligence, <b>inference</b> <b>engine</b> is a {{component}} of the system that applies logical rules to the knowledge base to deduce new information. The first inference engines were components of expert systems. The typical expert system consisted of a knowledge base and an <b>inference</b> <b>engine.</b> The knowledge base stored facts about the world. The <b>inference</b> <b>engine</b> applies logical rules to the knowledge base and deduced new knowledge. This process would iterate as each new fact in the knowledge base could trigger additional rules in the <b>inference</b> <b>engine.</b> Inference engines work primarily in one of two modes either special rule or facts: forward chaining and backward chaining. Forward chaining starts with the known facts and asserts new facts. Backward chaining starts with goals, and works backward to determine what facts must be asserted so that the goals can be achieved.|$|E
5000|$|Non-classical logic: Dienes-Rescher <b>inference</b> <b>engine</b> (also Rescher-Dienes implication); Rescher-Manor {{consequence}} relation ...|$|E
50|$|Reasoning {{can be done}} by {{translating}} graphs into logical formulas, then {{applying a}} logical <b>inference</b> <b>engine.</b>|$|E
40|$|This paper {{proposes a}} {{lightweight}} mechanism to combine deductive and inductive <b>inference</b> <b>engines</b> and describes an application {{in which the}} resulting functionality is shown to add significant value. Within the unified setting of deductive database technology and inductive logic programming, the combination of <b>inference</b> <b>engines</b> is much easier and the resulting systems much better integrated. This combination is important, e. g., if software agents are indeed to become widespread in the technical context of pervasive distributed computing that the web promises...|$|R
25|$|Examples of {{knowledge}} representation formalisms include semantic nets, systems architecture, frames, rules, and ontologies. Examples of automated reasoning <b>engines</b> include <b>inference</b> <b>engines,</b> theorem provers, and classifiers.|$|R
40|$|Firstly, {{this paper}} {{presents}} fuzzy logic based approaches for building a tool for measuring ereadiness of a country. This paper proposes fuzzy logic for realizing the measuring tool as fuzzy logic allows processing of heterogeneous indicators and imprecise values assigned for them. The tool is constructed by using one or more fuzzy logic based <b>inference</b> <b>engines.</b> Secondly, due to the problems in constructing pure fuzzy logic based <b>inference</b> <b>engines,</b> this paper also proposes some hybrid techniques for performance improvement; the hybrid techniques combines fuzzy logic with array-based logic...|$|R
5000|$|Robert Kowalski {{developed}} the connection graph theorem-prover and SLD resolution, the <b>inference</b> <b>engine</b> that executes logic programs.|$|E
5000|$|With forward reasoning, the <b>inference</b> <b>engine</b> can derive that Fritz {{is green}} {{in a series}} of steps: ...|$|E
50|$|The <b>inference</b> <b>engine</b> is an {{automated}} reasoning system that evaluates {{the current state}} of the knowledge-base, applies relevant rules, and then asserts new knowledge into the knowledge base. The <b>inference</b> <b>engine</b> may also include abilities for explanation, so that it can explain to a user the chain of reasoning used to arrive at a particular conclusion by tracing back over the firing of rules that resulted in the assertion.|$|E
50|$|<b>Inference</b> <b>engines,</b> e.g., {{rule-based}} reasoning engines, typically produce inferred {{information in}} artificial intelligence. However, {{they do not}} usually produce new information {{in the form of}} complex (i.e., inferred) events.|$|R
50|$|Illyria is {{the name}} {{for a piece of}} {{software}} running in interpreted mode under Lisp programming language. It is primarily used in educational institutions to demonstrate the principles of <b>inference</b> <b>engines.</b>|$|R
50|$|Backward {{chaining}} (or backward reasoning) is an inference {{method that}} can be described colloquially as working backward from the goal(s). It is used in automated theorem provers, <b>inference</b> <b>engines,</b> proof assistants and other artificial intelligence applications.|$|R
5000|$|ROOP's <b>inference</b> <b>engine</b> can be redefined by the programmer, {{something}} which is usually not feasible in other logical languages.|$|E
50|$|This {{derivation}} therefore {{allows the}} <b>inference</b> <b>engine</b> {{to prove that}} Fritz is green. Rules #2 and #4 were not used.|$|E
50|$|It is the low-level, {{efficient}} {{language that}} is used to implement the Cyc <b>inference</b> <b>engine,</b> and knowledge base lookup and matching algorithms.|$|E
50|$|SHINE was {{independently}} {{evaluated by}} UC Berkeley and {{was shown to}} significantly outperform commercially available <b>inference</b> <b>engines</b> such as RTI and ART. It executes approximately 500,000,000 plus rules a second running on a standard Windows PC.|$|R
50|$|Services {{that are}} able to {{retrieve}} additional semantic information about the content based on the semantic information retrieved via content enhancement.The Stanbol Reasoners component provides a set of services that take advantage of automatic <b>inference</b> <b>engines.</b>|$|R
40|$|Abstract — We {{show that}} agent {{programming}} patterns are well {{expressed in terms}} of an object oriented layer extended with a generalized inheritance mechanism and independent logic programming based <b>inference</b> <b>engines.</b> Instead of proposing yet another agent programming “model ” we simply derive key agent programming patterns as the natural result of a set of programming language constructs. The suggested equation: Agents = Objects + Logic + <b>Inference</b> <b>Engines</b> + Coordination + Remote Action provides orthogonal agent composition mechanisms which are expressive and highly reusable. The approach described in this paper has emerged in the process of building Agent classes as extensions to our industria...|$|R
