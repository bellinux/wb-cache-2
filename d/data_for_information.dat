79|10000|Public
25|$|Morgan hired nearly 50 {{engineers}} {{to analyze the}} Miami Valley watershed and precipitation patterns and to determine the flood volume. They analyzed European flood <b>data</b> <b>for</b> <b>information</b> about general flooding patterns. Based on this analysis, Morgan presented eight different flood control plans to the City of Dayton officials in October 1913. The city selected a plan based on the flood control system in the Loire Valley in France. It consisted of five earthen dams and modifications to the river channel through Dayton. The dams would have conduits to release {{a limited amount of}} water, and a wider river channel would use larger levees supported by a series of training levees. Flood storage areas behind the dams would be used as farmland between floods. Morgan's goal was to develop a flood plan that would handle 140 percent of the water from the 1913 flood. The analysis had determined the river channel boundaries for the expected 1,000-year major floods, and all businesses located in that area were to be relocated.|$|E
50|$|DOCSIS Set-top Gateway (or DSG) is a {{specification}} {{describing how}} out-of-band data is delivered to a cable set-top box. Cable set-top boxes need a reliable source {{of out of}} band <b>data</b> <b>for</b> <b>information</b> such as program guides, channel lineups, and updated code images.|$|E
50|$|The U.S. federal {{government}} can then compare states based on the core questions to allocate funding and focus interventions. The states themselves also use the survey results to focus interventions for the public and to decide what is worth their while to focus on. City, county, tribal, and local governments also rely on BRFSS <b>data</b> <b>for</b> <b>information</b> about their jurisdictions.|$|E
5000|$|Improved <b>data</b> {{standards}} <b>for</b> <b>information</b> sharing {{using the}} National Information Exchange Model (www.niem.gov).|$|R
50|$|The most {{employed}} {{usage of}} railML data is timetable <b>data</b> <b>for</b> passenger <b>information,</b> duty planning <b>for</b> conductors and drivers and timetable simulation.|$|R
30|$|To inform STAs of {{subchannel}} allocation results, a QoS-Fi AP broadcasts a Q-CRP frame. The Q-CRP frame {{consists of}} two consecutive OFDM symbols: one for conveying the signature of a contention winner, and the other <b>for</b> <b>data</b> rate <b>information</b> <b>for</b> future <b>data</b> transmission, <b>for</b> each subchannel.|$|R
50|$|Funded by the European Commission in the 6th Framework Programme for Research (FP 6) the CHILL-ON project aims {{to improve}} quality, safety, {{transparency}} and traceability of the chilled/frozen supply chain. To reach the goal, cost-effective technologies, devices and approaches for continuous monitoring and recording of relevant data and processing the <b>data</b> <b>for</b> <b>information</b> management {{throughout the entire}} supply chain are under way. As fish and poultry are very prominent in the European food market and belong to the most sensitive goods with regard to food poisoning, the chilled and frozen fish and poultry supply chain has been selected as test cases.|$|E
50|$|Morgan hired nearly 50 {{engineers}} {{to analyze the}} Miami Valley watershed and precipitation patterns, and to determine the flood volume. They analyzed European flood <b>data</b> <b>for</b> <b>information</b> about general flooding patterns. Based on this analysis, Morgan presented eight different flood control plans to the City of Dayton officials in October 1913. The city selected a plan based on the flood control system in the Loire Valley in France. It consisted of five earthen dams and modifications to the river channel through Dayton. The dams would have conduits to release {{a limited amount of}} water, and a wider river channel would use larger levees supported by a series of training levees. Flood storage areas behind the dams would be used as farmland between floods. Morgan's goal was to develop a flood plan that would handle 140 percent of the water from the 1913 flood. The analysis had determined the river channel boundaries for the expected 1,000-year major floods, and all businesses located in that area were to be relocated.|$|E
30|$|A {{comprehensive}} overview that achieves state-of-the-art status in geoprocessing Web architecture and technologies, combined with {{examination of the}} most current developments in recent years, is undertaken by Zhao et al. (2012). These authors state that light-weight protocols, crowdsourcing capability, and the potential to process real-time geospatial data sources provided by sensors enables distributed, interoperable, and collaborative processing of geospatial <b>data</b> <b>for</b> <b>information</b> and knowledge discovery.|$|E
3000|$|... e The authors wish {{to thank}} the C.C.I.A.A. of Sassari for {{allowing}} us to collect the <b>data.</b> <b>For</b> more <b>information</b> about the Register of the Companies and data, see [URL] [...]...|$|R
40|$|Master’s thesis {{deals with}} {{implementation}} of a European standard DATEX II. This standard specifies the <b>data</b> format <b>for</b> <b>information</b> transmission in road transport. The road traffic is flowing streams of current <b>information.</b> <b>For</b> the work was selected network of meteorological stations, which will publish the measured data, ie weather conditions of road transport. Measured data {{will be available to}} consumers in the format DATEX II. Implementation will be operational in its entirety meteorological station from design to the actual web service that will produce <b>data</b> <b>information</b> <b>for</b> consumers...|$|R
5000|$|Outer encoding: a BCH code, capable {{to correct}} 10 or 12 errors per FECFRAME, {{is used to}} compute parity <b>data</b> <b>for</b> the <b>information</b> <b>data</b> field. The BCH {{generator}} polynomial is of the 160th, 168th, or 192nd grade ...|$|R
30|$|In {{the above}} context, recent {{emergence}} of Cloud computing promises solutions to such challenges by facilitating big data storage and delivering {{the capacity to}} process, visualise and analyse city <b>data</b> <b>for</b> <b>information</b> and knowledge generation. Such a solution can also facilitate the decision makers in meeting the QoS requirements by providing an integrated information processing and analytic infrastructure for variety of smart cities applications to support decision-making for urban governance.|$|E
40|$|A revisitation of the Yeb {{archives}} {{with an eye}} to {{the question}} of cult statuary. The present article inventories the state of the question and makes several constructive suggestions. Its primary contributions are: to address the Yeb evidence, even preliminarily, to the debate over Yhwh statuary in the Jerusalem temple; to make a fresh interpretation of TAD A 4. 7 / 8; and to reread other key textual <b>data</b> <b>for</b> <b>information</b> about statuary...|$|E
40|$|We exploit a {{relationship}} between the Structure Functions of nucleons, the physical deuteron and of a deuteron, composed of point-nucleons to compute angular distributions of inclusive cross sections of 4. 05 GeV electrons. We report general agreement with data and interpret the remaining discrepancies. We discuss the potential of the <b>data</b> <b>for</b> <b>information</b> on neutron structure functions $F_k^n(x,Q^ 2) $ and the static form factor $G_M^n(Q^ 2) $. Comment: 9 pages, 1 Fig., PS fil...|$|E
5000|$|How {{administrative}} staff uses technology, accessing <b>data</b> <b>for</b> decision making, <b>information</b> system reporting, communication tools, information gathering, and record keeping ...|$|R
30|$|Although {{performance}} clearly improves over training, it is {{not clear}} if the efficiency with which individuals use the fused imagery improves from the mean RT and accuracy <b>data.</b> <b>For</b> this <b>information,</b> we need the capacity results, which are presented in the next section.|$|R
50|$|Surveyors help {{determine}} the placement of roads, railways, reservoirs, dams, pipelines, retaining walls, bridges, and buildings. They establish the boundaries of legal descriptions and political divisions. They also provide advice and <b>data</b> <b>for</b> geographical <b>information</b> systems (GIS) that record land features and boundaries.|$|R
40|$|A data {{compression}} technique for multitemporal Landsat imagery which extracts phenological growth pattern information for agricultural crops is described. The principal component greenness transformation {{was applied to}} multitemporal agricultural Landsat <b>data</b> <b>for</b> <b>information</b> retrieval. The transformation was favorable for applications in agricultural Landsat data analysis because of its physical interpretability {{and its relation to}} the phenological growth of crops. It was also found that the first and second greenness eigenvector components define a temporal small-grain trajectory and nonsmall-grain trajectory, respectively...|$|E
40|$|This thesis {{deals with}} the use of {{accounting}} <b>data</b> <b>for</b> <b>information</b> support of small and medium-sized enterprises users. This thesis covers not only technical and procedural aspects of reporting. The first part of the thesis provides broader insight into SME and their limitation factors, future development of accounting and accounting profession and also insight into data presentation. In the second part there are examples of statements, which could be part of specific accounting systems for SME and could be used by internal users...|$|E
40|$|In {{this article}} we present a semi-supervised {{algorithm}} for pattern discovery in information extraction from textual data. The patterns that are discovered {{take the form of}} regular expressions that generate regular languages. We term our approach `semi-supervised' because it requires significantly less effort to develop a training set than other approaches. From the training data our algorithm automatically generates regular expressions that can be used on previously unseen <b>data</b> <b>for</b> <b>information</b> extraction. Our experiments show that the algorithm has good testing performance on many features that are important in the fight against terrorism...|$|E
50|$|The Human Web is now {{integrated}} into the anti-tracking tool Ghostery. The participation to contribute <b>data</b> remains voluntary <b>for</b> <b>information</b> about trackers and websites.|$|R
50|$|People Finder Interchange Format (PFIF) is {{a widely}} used open <b>data</b> {{standard}} <b>for</b> <b>information</b> about missing or displaced people. PFIF was designed to enable information sharing among governments, relief organizations, and other survivor registries to help people find and contact their family and friends after a disaster.|$|R
5000|$|Defined {{standard}} <b>data</b> format <b>for</b> personal <b>information</b> management {{applications to}} store calendar, address, task and note entries, accessible by third-party applications.|$|R
3000|$|... “Well, it {{definitely}} needs dedicated resource {{to do it}} properly, it’s very challenging, tricky work and it can, yes, if we get the technology right it can streamline it but you still need someone to be the face of it, to lead it, to drive it, to do the analysis, to write reports, to deliver presentations about what the findings are, to make the changes and do all the change management around that so it’s not just about capturing data, it’s about the outcomes and use of that <b>data</b> <b>for</b> <b>information</b> for change.” (Non-clinical professional 1).|$|E
40|$|Information {{available}} from open-source mediums {{such as the}} web and social media are increasingly being used to aid the response to emergent crimes and reinforce existing Law Enforcement Agency intelligence capability. In this paper we discuss the rationale for, and development of, a framework for crawling open-source <b>data</b> <b>for</b> <b>information</b> regarding, and indicators of, Human Trafficking. The three-Level model presented aims to add value to the modelling, and increase the understanding of Human Trafficking {{in order to facilitate}} the detection and analysis of indicators to ultimately increase the value and range of information available to decision makers...|$|E
40|$|Published in 2014, this is {{an ideal}} guide to the {{essentials}} of what is DATA; what we are currently doing with it that is fundamentally different than in the past; and finally speculation and ramifications of both BIG and OPEN <b>DATA</b> <b>for</b> <b>information</b> systems. Broken into several chapters [...] . {{it occurs to me}} that this is the perfect outline for a complete overhaul of a DATA Lecture I've tried to sandwich between Intro to Vector and Raster Model Lectures! Often Introductory GIS courses really don't consider Geo Data in depth; much less DATA itself as a stand-alone lecture topic; so this is a bit o...|$|E
5000|$|Data {{modeling}} {{in software}} engineering {{is the process}} of creating a <b>data</b> model <b>for</b> an <b>information</b> system by applying certain formal techniques.|$|R
40|$|In {{the article}} {{a method of}} {{preparation}} operands at the synthesis of machine code commands in compilers is discussed. A generalization of the <b>data</b> model <b>for</b> <b>information</b> resources is proposed. It?s developed a fundamentally new scheme of the synthesis of optimal machine code programs for the target computer...|$|R
5000|$|Shneiderman, Ben. [...] "The {{eyes have}} it: A task by <b>data</b> type {{taxonomy}} <b>for</b> <b>information</b> visualizations." [...] Visual Languages, 1996. Proceedings., IEEE Symposium on. IEEE, 1996.|$|R
40|$|Abstract. For {{making the}} web of linked data grow, {{information}} extraction meth-ods are a good alternative to manual dataset curation, since there is an abundance of semi-structured and unstructured information which can be harvested that way. At the same time, existing Linked Data sets {{can be used for}} training and evalu-ating such information extraction systems. In this paper, we introduce the Linked <b>Data</b> <b>for</b> <b>Information</b> Extraction Challenge 2014. Using the example of person data in Microformats, we show how training and testing data can be curated at large scale. Furthermore, we discuss results achieved in the challenge, as well as open problems and future directions for the challenge...|$|E
40|$|The use {{of machine}} {{learning}} techniques to automatically analyse <b>data</b> <b>for</b> <b>information</b> {{is becoming increasingly}} widespread. In this paper we examine the use of Genetic Programming and a Genetic Algorithm to pre-process data before it is classified by an external classifier. Genetic Programming is combined with a Genetic Algorithm to construct and select new features from those available in the data, a potentially significant process for data mining since it gives consideration to hidden relationships between features. We then examine techniques to improve the human readability of these new features and extract {{more information about the}} domain. Categories and Subject Descriptors I. 2. 2 [Artificial Intelligence]: Automatic Programming...|$|E
40|$|Networking (MOTION) service {{platform}} {{that we have}} designed and implemented addresses an emerging requirement in the daily business of large, distributed enterprises: support for mobile teamwork. Employees are often on the move and use {{a wide range of}} computing devices such as WAP phones, PDAs, notebooks and desktop computers. The service architecture that we have developed supports mobile teamwork by providing multi-device service access, XML meta <b>data</b> <b>for</b> <b>information</b> sharing and locating, and the XML Query Language (XQL) for distributed searches and publish/subscribe. We present the solution that we adopted in our prototype, analyze the shortcomings of this approach and based on our evaluation experiences, list the requirements for a publish-subscribe middleware for collaborative mobile working...|$|E
5000|$|How do you select, collect, align, and {{integrate}} <b>data</b> and <b>information</b> <b>for</b> tracking daily operations? ...|$|R
5000|$|Includes the {{description}} of the Space Engineering Information Model (SEIM), a conceptual <b>data</b> model <b>for</b> all <b>information</b> needed to conduct concurrent design sessions ...|$|R
5000|$|A {{configuration}} management database (CMDB) is a repository {{that acts as}} a <b>data</b> warehouse <b>for</b> <b>information</b> technology (IT) installations. It holds data relating to a collection of IT assets (commonly referred to as configuration items (CI)), as well as to descriptive relationships between such assets. The repository provides a means of understanding: ...|$|R
