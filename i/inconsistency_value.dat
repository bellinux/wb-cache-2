7|109|Public
40|$|In this paper, {{we explore}} {{the links between}} {{measures}} of inconsistency for a belief base and the minimal inconsistent subsets of that belief base. The minimal inconsistent subsets {{can be considered as}} the relevant part of the base to take into account to evaluate the amount of inconsistency. We define a very natural <b>inconsistency</b> <b>value</b> from these minimal inconsistent sets. Then we show that the <b>inconsistency</b> <b>value</b> we obtain is a particular Shapley <b>Inconsistency</b> <b>Value,</b> and we provide a complete axiomatization of this value in terms of five simple and intuitive axioms. Defining this Shapley <b>Inconsistency</b> <b>Value</b> using the notion of minimal inconsistent subsets allows us to look forward to a viable implementation of this value using SAT solvers...|$|E
40|$|International audienceIn {{this paper}} we show {{how to build}} a {{reasoning}} platform us- ing an <b>inconsistency</b> <b>value.</b> The idea is to use an <b>inconsistency</b> <b>value</b> for evaluating how much each formula of the belief base is responsible of the inconsistency of the base. Then this evaluation allows us to obtain a strati cation (total pre-order) of the base, that can be used as the preferential input for di erent reasoning tasks, such as inference, belief revision, or conciliation. We show that the obtained operators are interesting and have good logical properties. We use as <b>inconsistency</b> <b>value,</b> the MI Shapley <b>inconsistency</b> <b>value,</b> that is known to have good properties, and that can be computed from minimal inconsistent subsets. We developed a java-based platform, that use the Sat 4 j library for computing the minimal inconsistent subsets, and that allows to have an e ective way to compute the MI Shapley inconsistent subsets. We implemented also several inference, revision and conciliation methods, that use this <b>inconsistency</b> <b>value.</b> So this provides a complete reasoning platform, {{that can be used for}} instance for academic purposes...|$|E
40|$|Nowadays, many real {{problems}} can be solved using local search strategies. These algorithms incrementally alter <b>inconsistency</b> <b>value</b> assignments to all the variables using a repair or hill climbing metaphor to move towards more and more complete solutions. Furthermore, if the problem can be modeled as a distributed problem, the advantages can be even greater...|$|E
40|$|In this {{preliminary}} study, we investigate how inconsistency {{in a network}} intrusion detection rule set can be measured. To achieve this, we first examine the structure of these rules {{which are based on}} Snort and incorporate regular expression (Regex) pattern matching. We then identify primitive elements in these rules in order to translate the rules into their (equivalent) logical forms and to establish connections between them. Additional rules from background knowledge are also introduced to make the correlations among rules more explicit. We measure the degree of inconsistency in formulae of such a rule set (using the Scoring function, Shapley <b>inconsistency</b> <b>values</b> and Blame measure for prioritized knowledge) and compare the *This is a revised and significantly extended version of [1]...|$|R
40|$|Abstract—In this {{preliminary}} case study, we investigate how inconsistency {{in a network}} intrusion detection rule set can be measured. To achieve this, we first examine the structure of these rules which incorporate regular expression (Regex) pattern matching. We then identify primitive elements in these rules in order to translate the rules into their (equivalent) logical forms and to establish connections between them. Additional rules from background knowledge are also introduced to make the correla-tions among rules more explicit. Finally, we measure the degree of inconsistency in formulae of such a rule set (using the Scoring function, Shapley <b>inconsistency</b> <b>values</b> and Blame measure for prioritized knowledge) and compare the informativeness of these measures. We conclude that such measures are useful for the network intrusion domain assuming that incorporating domain knowledge for correlation of rules is feasible. Index Terms—Network intrusion detection, inconsistency mea-sures. I...|$|R
40|$|Sea ice drift was {{measured}} by Surface Velocity Profiler 2016 P 37 drifting on Arctic sea ice. The buoy was deployed on first year ice without drogue during POLARSTERN cruise PS 101 (ARK-XXX/ 3). The time series describes {{the position of the}} buoy between 24 Sep 2016 and 07 Oct 2016 in sample intervals of 5 minutes. The data set has been processed, including the removal of obvious <b>inconsistencies</b> (missing <b>values)</b> ...|$|R
40|$|Abstract. Hunter and Konieczny {{explored}} {{the relationships between}} measures of in-consistency for a belief base and the minimal inconsistent subsets of that belief base in several of their papers. In particular, an <b>inconsistency</b> <b>value</b> termed MIVC, defined from minimal inconsistent subsets, {{can be considered as}} a Shapley <b>Inconsistency</b> <b>Value.</b> Moreover, it can be axiomatized completely in terms of five simple axioms. MinInc, one of the five axioms, states that each minimal inconsistent set has the same amount of conflict. However, it conflicts with the intuition illustrated by the lottery paradox, which states that as the size of a minimal inconsistent belief base increases, the degree of inconsistency of that belief base becomes smaller. To address this, we present two kinds of revised inconsistency measures for a belief base from its minimal inconsistent subsets. Each of these measures considers the size of each minimal inconsistent subset as well as the number of minimal inconsistent subsets of a belief base. More specifically, we first present a vectorial measure to capture the inconsistency for a belief base, which is more discriminative than MIVC. Then we present a family of weighted inconsistency measures based on the vectorial inconsistency measure, which allow us to capture the inconsistency for a belief base in terms of a single numerical value as usual. We also show that each of the two kinds of revised inconsistency measures can be considered as a particular Shapley <b>Inconsistency</b> <b>Value,</b> and can be axiomatically characterized by the corresponding revised axioms presented in this paper...|$|E
40|$|In this paper, {{we present}} a method to {{estimate}} {{the shape of a}} three dimensional (3 D) object by enforcing color consistency in the views of object points in images acquired from different viewpoints. The estimated shape and color information of the object can be used to render new views of the object. We first construct a 3 D voxel space and assign to each voxel a photo <b>inconsistency</b> <b>value,</b> and then represent this voxel space using a node capacitated graph. We use s-t node cut to obtain a surface that minimizes the summation of photo inconsistency values of surface voxels. Experimental results for simulated and real objects are provided. We also simulate how the calibration errors of camera intrinsic and extrinsic parameters affect the performance of our algorithm. 1...|$|E
40|$|The {{conditions}} of Jepara furniture industry {{when compared with}} the boom in 1997 tended to decline and unstable. Problems such as the declining quality of human resources which causes a decrease in the quality of products, the threat of competitors furniture from other areas, as well as the penetration is large-scale furniture from outside the area to the district of Jepara causing endangerment business continuity, especially businesses Small and Medium Industries (SMI) furniture in the district Jepara. This study aims to examine the SME development policy strategy Furniture Jepara. {{the purpose of this study}} is expected to provide an overview menegenai condition furniture industry is mainly small industries and Medium Enterprises (SMEs) Furniture Jepara, analyze alternative-aternatif program in upayaa develop and enhance the competitiveness of SMEs furniture Jepara and define alternative most suitable program applied to SMEs Furniture Jepara. The data used in this study are primary data obtained from the relevant agencies as well as from actors IKM Furniture and browsing the internet website as a supporter. While the methods of analysis used is the analysis method Hierarchy Process (AHP). The results of this study indicate AHP analysis overall respondents key person and businesses IKM furniture can be concluded that both chose Aspect Quality Improvement of Human Resources with alternative criteria Training program Technical Skills as a main alternative of the entire fifteen alternative program criteria in the development of SME Furniture in Jepara regency pick <b>inconsistency</b> <b>value</b> ratio of ≤ 0. 1 which means that the results of the analysis are consistent and acceptable and can be implemented as a program to achieve the target with weight value 0. 181 to 0. 234 respondents and the key person for the respondent businesses IKM Furniture...|$|E
40|$|Sea ice drift, surface temperature, and {{barometric}} pressure were measured by Surface Velocity Profiler 2015 P 1 drifting on Antarctic sea ice. The buoy was deployed on first year ice without drogue during POLARSTERN cruise PS 89 (ANT-XXX/ 2). The time series describes {{the position and}} additional parameters of the buoy between 03 Jan 2015 and 19 Mar 2015 in sample intervals of 1 hour. The data set has been processed, including the removal of obvious <b>inconsistencies</b> (missing <b>values)</b> ...|$|R
40|$|Sea ice drift, surface temperature, {{barometric}} pressure, humidity, {{wind speed}} and wind direction were {{measured by the}} Polar Area Weather Station (PAWS) 2015 A 1 drifting on Arctic sea ice. The buoy was deployed on first year ice during POLARSTERN cruise PS 94 (ARK-XXIX/ 3). The time series describes the position and additional parameters of the buoy between 23 Sep 2015 and 16 Oct 2016 in sample intervals of 3 hours. The data set has been processed, including the removal of obvious <b>inconsistencies</b> (missing <b>values)</b> ...|$|R
40|$|Feral cats (Felis catus) are {{abundant}} {{in many parts}} of the world and pose a threat to native wildlife. Human–wildlife conflicts regarding how feral cats should be managed have increased recently. In Hawaii, previous research has revealed that most residents would like to see the feral cat abundance reduced, but opinions differ regarding which techniques are acceptable for achieving this. This paper describes an analytical hierarchy process that combines rankings of decision criteria by Hawaii’s residents with expert knowledge of the costs and benefits associated with 7 techniques (live-capture and adoption, live-capture and lethal injection, live-capture and lethal gunshot, trap-neuter-release [TNR]), lethal traps, predatorproof fence, and sharpshooter) for reducing feral cat abundance. We used a state-wide survey with 1, 369 respondents and in-person surveys with 11 wildlife professionals to gather data for the model. <b>Inconsistency</b> <b>values</b> were below 0. 1 for data from both the state-wide survey and the survey of wildlife professionals. Sensitivity analysis revealed that the model was not sensitive to changes in the public’s ranking of the decision criteria, because when data were averaged all decision criteria became equally important. The final ranking of the management techniques was dominated by the costs and benefits of each technique. Lethal traps were ranked as the best technique, and TNR was ranked as the worst technique...|$|R
40|$|Sea ice drift {{and surface}} {{temperature}} were {{measured by the}} Compact Air-Launched Ice Beacon (CALIB) 2015 C 10 drifting on Arctic sea ice. The buoy was deployed on first year/second year ice during MELTEX-II 2015 (Impact of sea ice thickness, sea ice topography and MELT ponds on the energy and momentum EXchange between atmosphere and sea ice). The time series describes the position and additional parameters of the buoy between 03 Jul 2015 and 12 Oct 2015 in sample intervals of 10 minutes. The data set has been processed, including the removal of obvious <b>inconsistencies</b> (missing <b>values)</b> ...|$|R
40|$|Data Quality {{is defined}} in [TB 98] as fitness for use, which implies that quality is {{relative}} {{to the use of}} data. Problems with data quality tend to fall into two categories: inconsistency among systems and inconsistency with reality. Format/syntax, semantic and <b>value</b> <b>inconsistencies</b> are representative of inconsistency among systems whereas incorrect and missing values are representative of inconsistencies with reality...|$|R
30|$|This study {{utilised}} wireline {{logs and}} drilling data from two onshore wells. The data were quality controlled and corrected for any <b>inconsistency.</b> GR cut-off <b>value</b> for shale varies from well to well {{and can be}} misleading especially on Onshore Niger Delta; thus, threshold was applied {{in addition to the}} GR API range. In this case, sand cut-offs were normally removed from the density log. The generated data are required input to enable proper interpretation and shale pressure estimation.|$|R
40|$|Quantification of {{artemisinin}} {{purity and}} amount in plant material and extracts {{to date has}} been characterized by a considerable <b>inconsistency</b> in <b>values.</b> This {{is likely to be}} due to the adoption of varied analytical procedures and use of inappropriate to the specific applications analytical techniques. In this paper we are attempting to further develop artemisinin analysis to the point where a universally acceptable reference method is available to the research and end-users communities. Thus, we have developed and validated an HPLC-RI method and optimized an HPLC-ELSD method. We used the gradient HPLC-UV method recommended by the current artemisinin monograph as a comparison for the method improvements presented herein, and show the limitations for its application scope. The data reported should help to allow more reliable laboratory analysis of artemisinin in both pure samples and in Artemisia annua extracts...|$|R
40|$|The {{stability}} of the TAP mean field equations is reanalyzed with {{the conclusion that the}} exclusive reason for the breakdown at the spin glass instability is an <b>inconsistency</b> for the <b>value</b> of the local susceptibility. A new alternative approach leads to modified equations which are in complete agreement with the original ones above the instability. Essentially altered results below the instability are presented and the consequences for the dynamical mean field equations are discussed. Comment: 7 pages, 2 figures, final revised version to appear in Europhys. Let...|$|R
40|$|A {{constraint}} satisfaction problem may not admit a complete solution; {{in this case}} a good partial solution may be acceptable. This paper presents new techniques for organizing search with branch and bound algorithms so that maximal partial solutions (those having the maximum possible number of satisfied constraints) can be obtained in reasonable time for moderately sized problems. The key feature is a type of variable-ordering heuristic that combines width at a node of the constraint graph (number of constraints shared with variables already chosen) with factors such as small domain size that lead to <b>inconsistencies</b> in <b>values</b> of adjacent variables. Ordering based on these heuristics leads to a rapid rise in branch and bound’s cost function together with local estimates of future cost, which greatly enhances lower bound calculations. Roth retrospective and prospective algorithms based on these heuristics are dramatically superior to earlier branch and bound algorithms developed for this domain...|$|R
30|$|<b>Inconsistency</b> of lease <b>value</b> {{setting is}} still persisting. The SCBRMP {{was the biggest}} {{fisheries}} management project in Bangladesh. Fixation of land revenue in the SCBRMP’s waterbodies {{has not been made}} in a transparent manner; this procedure neither followed criteria based on bio-logical productivity nor waterbody area. This poverty alleviation project has had to pay the incremental lease value along with value added tax, thus Table  4 shows a wide variation of lease value among waterbodies, with the result that some lease values are very high while others are very low.|$|R
30|$|The need {{to assign}} prices to {{benefits}} and costs that cannot be traded in a marketplace, such as social and environmental externalities, {{has given rise to}} methods that try to ascertain the marginal utility loss associated with marginal unit of environmental damage or social harm, for example, through contingent valuation methods or hedonic pricing (Fujiwara and Campbell, 2011; Defra, 2012). There are a number of inherent problems with these approaches including: users’ ability to appreciate the systemic benefits, <b>inconsistencies</b> in <b>value</b> attribution, behavioural factors such as loss aversion, and the implied ability to trade-off between economic, social and environmental values (Fujiwara and Campbell, 2011; Dunn, 2012). Furthermore, positive social and environmental externalities, e.g. spillover or co-benefits such as contributions to positive health or welfare outcomes, are also often not valued (Garrod and Willis 1999, Nakamura, 2000). Our concern here is principally with the stage in the process at which these methods can usefully be applied.|$|R
40|$|Willingness-to-pay (WTP) {{is being}} used {{increasingly}} in health technology assessment, although a number of methodological issues remain unresolved. Using data obtained from a randomised questionnaire survey, we investigated the metrical properties of two WTP formats, the open-ended question versus the payment scale, {{in the context of}} screening for colorectal cancer. Approximately, 2800 responses were analysed. Household income, attitudes toward health promotion and personal risk perceptions were the principal determinants of the nature and value of response. In comparison with the open-ended format, the payment scale achieved a higher completion rate and generated higher valuations. We believe that a framing effect is the most plausible explanation for these differences in performance. In contrast to previous findings, we do not find subjects' perceptions of the resource cost of interventions to be a convincing explanation for either their WTP <b>values</b> or <b>inconsistencies</b> between <b>values</b> and preferences. Although a proportion of respondents protested at the notion of valuation, the majority offer positive valuations, although typically of a lower value that non-protesters...|$|R
40|$|Most federal second {{chambers}} give subunits equal representation. A few apply {{per capita}} representation, like most first chambers. Only Germany and Canada compromise between territorial and per capita representation. Both broadly allocate seats following Si=SPi n/∑Pk n, the only simple format without internal <b>inconsistencies.</b> Two <b>values</b> {{have been proposed}} for n. The rigid n= 0. 5 approximates the Canadian pattern but does not fit the German system. The flexible n=[1 /logT- 1 /logS]/[1 /logT- 1 /logP] {{takes into account the}} number of subunits (T) and total seats (S), for given total population (P). The flexible model better predicts seat allocation both in Canada and Germany. This model has been shown to apply to the European Parliament and the EU Council. Hence it may express what countries intuitively grope for when trying to strike a compromise between representations per capita and per subunit. As such, it does not fit the seat allocation of administrative subunits in unitary states, France and Italy...|$|R
40|$|Snow {{height and}} air {{temperature}} were measured by an autonomous platform, deployed on sea ice. The resulting time series describes {{the evolution of}} snow height {{as a function of}} place and time in sample intervals of 1 hour. The Snow Buoy consists of four independent sonar measurements representing the area (approx. 10 m²) around the buoy. In addition to snow height and air temperature, geographic position (GPS), barometric pressure, and an internal ice temperature were measured. Negative values of snow height occur if surface ablation continues into the sea ice. Thus, all snow height measurements describe the surface elevation relative to the original snow-ice interface. Differences between single sensors indicate small-scale variability of the snow pack around the buoy. The data sets has been processed, including the removal of obvious <b>inconsistencies</b> (missing <b>values).</b> Records without snow height data may still be used for sea ice drift analyses. Some data sets contain only relative changes in snow height, because no initial readings of absolute snow height are available...|$|R
40|$|The authors examine {{impacts of}} {{immigration}} on parent-adolescent value similarity, consistency of parents’ value messages, {{and the value}} transmission process. Thirty-four former Soviet immigrant families to Israel and 68 matched Israeli families participated. Group mean comparisons revealed generational effects for openness and conservation values: adolescents resembled one another more than their own parents. Immi-gration further increased adolescent-parent value distance. For self-transcendence and self-enhancement values, there were no effects. Correlations between parent and adolescent group means, across 11 values, suggest that immigration reduces parent-adolescent similarity in value priorities. Within-family analyses showed no immigration effects on parent-adolescent value similarity or on accuracy in perceiving parents’ values, and greater acceptance of parental values in immigrant families. Value messages of immigrant par-ents were less consistent. <b>Inconsistency</b> undermined <b>value</b> transmission, differently in immigrant and vet-eran families. The authors discuss why group versus within-family analyses can yield contradictory results and why findings depend on the specific values studied...|$|R
40|$|This paper {{comments}} {{on a recent}} paper by Ernesto Screpanti (2003), in this journal, on Marxian theories of value and exploitation. The paper argues, in opposition to Screpanti, that the labour theory of value is the most suitable foundation for a realistic and historically determined vision of society; that labour values provide a unique coherent conceptual framework for understanding the nature of profit; that the <b>inconsistency</b> of labour <b>values</b> is only apparent, as it disappears with a judicious choice of numeraire; and that prices of production explain much less than labour values and are therefore an inadequate substitute for the latter. ...|$|R
40|$|The Bean {{model is}} almost solely used to {{interpret}} ac {{losses in the}} powder-in-tube processed composite conductor, Bi{sub 2 }Sr{sub 2 }Ca{sub 2 }Cu{sub 3 }O{sub 10 }/Ag. In order to examine {{the limits of the}} applicability of the model, a detailed comparison was made between the values of critical current density J{sub c} for Bi(2223) /Ag tapes which were determined by standard four-probe-dc measurement, and which were deduced from the field dependence of the ac losses utilizing the model. A significant <b>inconsistency</b> between these <b>values</b> of J{sub c} were found, particularly at high fields. Possible sources of the discrepancies are discussed...|$|R
2500|$|Critics of {{traditional}} Jewish and Christian belief have {{also argued that}} <b>inconsistencies</b> undermine the <b>value</b> of scripture. The Deist Minister Joseph Barker, speaking in 1854, described the Bible as [...] "the most inconsistent, the most monstrous and blasphemous representations of God that can possibly be conceived by the human mind" [...] and argued that [...] "The book that contradicts science and contradicts itself is a book of no authority whatsoever". A modern Islamic critic writes that if the Bible can {{be shown to be}} inconsistent, [...] "then those who preach the Bible and read the Bible must seriously reconsider their source of information concerning their faith." ...|$|R
40|$|Data {{editing and}} {{imputation}} (E&I) in complex sample business surveys {{is a task}} which is usually split into two steps to gain efficiency {{in terms of time}} and human resources: first selective editing techniques are applied to the primary target estimates variables in order to identify a potential set of influential errors that require usually manual editing and a second part of automatic identification and imputation of <b>inconsistencies</b> and missing <b>values.</b> Within this framework, the present paper reviews the Italian top-down data editing strategy adopted and automated imputation showing the experience applied to 2013 Farm Structure Survey livestock data. In this edition this process has been entirely carried out in the R environment by means of different R packages...|$|R
40|$|This paper {{presents}} a CSPs filtering method combining arc-consistency and dual Lagrangean relaxation techniques. First, we model the constraint satisfaction problem as a 0 / 1 linear integer program (IP); then, {{the consistency of}} a value is defined as an optimization problem on which a dual Lagrangean relaxation is defined. While solving the dual Lagrangean relaxation, <b>values</b> <b>inconsistencies</b> may be detected (dual Lagrangean inconsistent values); the constraint propagation of this inconsistency can be performed by arc-consistency. After having made the CSP arc-consistent, the process iteratively selects values of variables which may be dual Lagrangean inconsistent. Computational experiments performed over randomly generated problems show {{the advantages of the}} hybrid filtering technique combining arc-consistency and dual Lagrangean relaxation...|$|R
40|$|Research Findings: The {{purpose of}} this study was to examine {{associations}} between parental socialization <b>values</b> (including <b>inconsistency</b> in <b>values),</b> parenting practices, and parental involvement in their children's education. Altogether 242 Estonian mothers and fathers of first-grade children participated in the study. We found that mothers were overall more involved in their children's education than fathers. Whereas emphasis on social values at home was related to paternal and (marginally) to maternal home-based academic involvement, emphasis on self-direction values at home among mothers was related to their home-based general involvement. Also, inconsistency in family socialization values had a negative impact on paternal involvement. Finally, positive practices were most consistently related to all types of involvement among mothers and fathers. Practice or Policy: The findings of the present study emphasize the importance of concordance in mother-father values. For teachers, it emphasizes the need to cooperate with both spouses and to discuss broader topics, including their values and practices. The results additionally indicate the importance of finding ways to enhance collaboration with less-educated parents. The results have practical implications for teachers who can potentially help parents to become more involved in their children's education. © 2014 Copyright Taylor and Francis Group, LLC...|$|R
40|$|In mass appraisal, Location Value Response Surface (LVRS) {{modeling}} {{has proven}} to be a powerful and sophisticated tool in the analysis of the influence of location on the values of single-family houses in the United States. The technique uses a “smoothed ” response surface as a function of location adjustment, representing the relative variation of location value within the whole area geographically. Unlike traditional approaches such as geographical stratification, the LVRS removes the location <b>value</b> <b>inconsistency</b> problem at neighbourhood boundaries. This paper proposes to illustrate in a case study, how the technique can be used to value high-rise office units for rating purposes in Hong Kong by adopting a standardisation method to derive the location factor. The prediction of property values is improved using the model...|$|R
40|$|This article {{reports on}} the liquid phase {{adsorption}} of flavour esters onto granular activated carbon. Ethyl propionate, ethyl butyrate, and ethyl isovalerate were used as adsorbates, and Filtrasorb 400 activated carbon {{was chosen as the}} adsorbent. Sips, Toth, Unilan, and Dubinin-Radushkevich isotherm equations which are generally used for heterogeneous adsorbents were used to fit the data. Although satisfactory in fitting the data, <b>inconsistency</b> in parameter <b>values</b> indicated these models to be inadequate. On the other hand the Dubinin-Radushkevich model gave more consistent and meaningful parameter values and adsorption capacities. By employing the Dubinin-Radushkevich equation, the limiting volume of the adsorbed space, which equals the accessible micropore volume, was determined, and found to correlate with the value from carbon dioxide adsorption...|$|R
5000|$|Proponents of the TSSI {{contend that}} these {{allegations}} are false:“We have {{never said that}} Marx’s contested insights are necessarily true [...] [...] [...] [...] We simply say the claims that his value theory is necessarily wrong, because it is logically invalid, are false.”Similarly, Andrew Kliman distinguishes between internal consistency on the one hand, and truth or correctness on the other, at least nine different times. For instance, he writes that the TSSI's ability to eliminate the apparent <b>inconsistencies</b> in Marx's <b>value</b> theory does not imply [...] "that Marx’s theoretical conclusions are necessarily correct. It does imply, however, that empirical investigation is {{needed in order to}} determine whether they are correct or not. There is no justification for disqualifying his theories a priori, on logical grounds." ...|$|R
40|$|Abstract. The QAOOSE 2007 {{workshop}} brought together, {{for half}} day, researchers working on several aspects related to quantitative evaluation of software artifacts developed with the object-oriented paradigm and related technologies. Ideas and experiences were shared and discussed. This report includes {{a summary of}} the technical presentations and subsequent discussions raised by them. Exceptionally this year, {{one of the founders of}} the workshop, Horst Zuse, gave a keynote on the Theoretical Foundations of Object-Oriented Measurement. Three out of the four submitted position papers were presented, covering different aspects such as measuring <b>inconsistencies,</b> visualizing metric <b>values,</b> and assessing the subjective quality of systems. In the closing session, the participants discussed open issues and challenges arising from researching in this area and tried to forecast what will be hot research topics in the short and medium terms. ...|$|R
40|$|A pattern {{database}} (PDB) is a heuristic function {{stored as}} a lookup table. Symmetries {{of a state}} space are often used to enable multiple values to be looked up in a PDB for a given state. This paper introduces an additional PDB lookup, called the dual PDB lookup. A dual PDB lookup is always admissible but can return inconsistent values. The paper also presents {{an extension of the}} well-known pathmax method so that <b>inconsistencies</b> in heuristic <b>values</b> are propagated in both directions (childto-parent, and parent-to-child) in the search tree. Experiments show that the addition of dual lookups and bidirectional pathmax propagation can reduce the number of nodes generated by IDA * by over one order of magnitude in the TopSpin puzzle and Rubik’s Cube, and by about a factor of two for the sliding tile puzzles. ...|$|R
40|$|The "take-them-in-or-leave-them-out" {{of prior}} probabilities {{is a key}} problem in {{uncertain}} reasoning. The EMYCIN uncertain reasoning model is inconsistent with probability theory, due to `leaving them out', whereas the PROSPECTOR uncertain reasoning model is substantially consistent with probability theory, due to `taking them in'. However, in the PROSPECTOR model, there are the following problems: 1) prior probabilities need to be supplied with values by human experts, {{which is a very}} arduous task; 2) to overcome the problem of the <b>inconsistency</b> among the <b>values</b> of prior probabilities, the formula for sequential propagation used in this model is a pseudo-probability formula, which weakens the theoretical basis of the model; and 3) the semantics of rule strength is dicult to understand. This paper presents a PROSPECTOR-like uncertain reasoning model for solving the above three problems. Moreover, we illustrate our discussion with an example...|$|R
