0|10000|Public
3000|$|... 2  =  10.4  %, Pfor heterogeneity: 0.350). However, when <b>stratified</b> by <b>sample</b> <b>size</b> and {{assessment}} of tooth loss, a nonsignificant association was detected.|$|R
40|$|Abstract—The {{survey of}} {{expressway}} service level in China awaits upgrading nowadays. This article proposes that respondents herein cover drivers of travelers and goods transport, transport managerial, passengers, sedan drivers etc, {{in the view}} of consumers of road commodity networking. And the respondent weight is determined by questionnaire numbers and difficulty level for sample taking. The preliminary survey, proceeded with on-the-spot questionnaire and discussions with transport enterprises, suggests a focus of investigation upon consummation and satisfaction of services in transit, toll station, traffic information, along with placement of service area and its parking lot, and customer convenience. Finally, a survey cost forecasting model is put forward, according to the optimal allocation out of <b>stratified</b> <b>sampling,</b> and the <b>stratified</b> <b>sample</b> <b>size</b> is affirmed. Namely, the response rate renders the bulk sample coordination. The proposed investigation measure provingly reveals the factual expressway service status, based on its low cost, high availability and easy usage. 4 tabs, 1 fig, 5 refs...|$|R
40|$|We {{consider}} a weighted, nonparametric density estimator for <b>stratified</b> <b>samples.</b> We derive the optimal bandwidth using information on within-stratum variances and means. We provide a plug-in bandwidth when all strata are normally distributed. We {{show that the}} optimal <b>sampling</b> scheme is <b>stratified</b> <b>sampling</b> proportional to <b>size,</b> irrespective of the stratum-specific densities. ...|$|R
40|$|The {{sampling}} of teachers for nationwide surveys offers a challenging endeavor in obtaining a representative and adequate sample to truly represent {{opinions of the}} teachers. Ten national surveys of public school teachers conducted betweer 1980 and 1985 are presented {{with respect to their}} sampling design and procedures. Concepts and theoretical considarations provide the background of the critical review. This paper discusses adequacy and representativeness as criteria of a good sample, sample design, bias, sampling error, sampling frame and unit, multistage and <b>stratified</b> <b>sampling,</b> and <b>sample</b> <b>size</b> allocation. Problems associated with prevailing sampling practices include: (1) lack of sampling frame or list of all public school teachers from which a sample may be drawn; (2) the question of assurance that the sample drawn is representative of the target population of public school teachers; (/) tt&apos...|$|R
40|$|M. Tech. Business AdministrationThe key {{objective}} {{of the study was}} to identify and quantify factors that affect the perception held by the general public on the quality of services provided by dental practitioners in the Gauteng Province. It was based on a <b>stratified</b> random <b>sample</b> of <b>size</b> n= 100 respondents who were selected from the dental industry in the Gauteng Province...|$|R
40|$|Our Research project {{paper title}} is ‘A study on employees’ {{perception}} towards women leadership’. The study topic been chosen {{due to the}} issue arise such poor judgment women leader where people are not believes on their capabilities in administration such lack of commitment to lead employees and organization and also have lower level of self confidence. The objective {{of this research is}} to determine among the four factors; communication, usage of power, decision making and personal character, which is the most contribute to employees’ perception towards women leadership. Recommendations are suggested in order for women leaders may improve themselves in influenced their employees’ perception. The target population in this study comprises of the employees’ in Malacca Historic City Council (MBMB) whose work under a women leader. From 14 departments there are only 9 departments that have women as a top leader and the total population on this study was 353 employees’. By using the sampling technique of Disproportionate <b>Stratified</b> <b>Sampling,</b> the <b>sample</b> <b>size</b> for this study was only 181 employees’ as the respondents. Data been analyzed using the statistical correlations between measured variables...|$|R
40|$|A sample spacing up to 22 cm over a {{distance}} of several metres is just sufficient to collect information about preferential flow paths in a water-repellent sandy soil. When larger sample spacings were used, the water content distributions became more horizontally <b>stratified.</b> Increasing the <b>sample</b> <b>size</b> by pooling pairs of adjacently taken 100 cm 3 soil samples over {{a distance}} of several metres still allowed preferential flow paths to be detected. Preferential flow paths were no longer observed for larger <b>sample</b> <b>sizes.</b> Enlarging the <b>sample</b> <b>size</b> reduces the calculated standard deviation and coefficient of variation. Sampling strategies must be flexible in design...|$|R
40|$|In this paper, we {{consider}} the non-parametric, kernel estimate of the density, f(x), for data drawn from <b>stratified</b> <b>samples.</b> Much of the data used by social scientists is gathered in some type of complex survey violating the usual assumptions of independently and identically distributed data. Such effects induced by the survey structure are rarely considered {{in the literature on}} non-parametric density estimation, yet they may have serious consequences for our analysis, as shown in this paper. A weighted estimator is developed which provides asymptotically unbiased density estimation for <b>stratified</b> <b>samples.</b> A data-based method for choosing the optimal bandwidth is suggested, using information on withinstratum variances and means. The weighted estimator and proposed bandwidth are shown to give smaller mean squared error for <b>stratified</b> <b>samples</b> than an un-weighted estimator and a commonly used method of choosing the bandwidth. Surprisingly, the single bandwidth outperforms optimally choosing stratum-specific bandwidths in some cases. Several illustrations from simulation are provided. We also show that the optimal sampling scheme in this case is always <b>stratified</b> <b>sampling</b> proportional to <b>size,</b> irrespective of the stratum-specific densities...|$|R
30|$|We measure size by yearly market capitalization, C_i,t (provided by Datastream {{and updated}} at the {{beginning}} of each year), and liquidity by the bid-ask spread, S_i,t. Size and liquidity effects are interrelated. Stocks of large firms are likely to be more liquidly traded than smaller stocks. The correlation between market capitalization and bid-ask spread is - 0.27 in our <b>sample.</b> <b>Stratifying</b> the <b>sample</b> by <b>size</b> shows that correlation is highest for the smallest (- 0.24) and the largest quintiles (- 0.16). The magnitude of this correlation is not high enough to raise concerns about multicollinearity problems, but it may be difficult to clearly separate size from liquidity effects.|$|R
40|$|M. Tech. Business Administration. This {{study was}} {{conducted}} in order to identify and quantify factors that are responsible for the high rate of failure in SMMEs in the Vaal Triangle region. The study was based on a <b>stratified</b> random <b>sample</b> of <b>size</b> n= 133. <b>Stratified</b> random <b>sampling</b> was used for collecting data by using a structured, pre-tested and validated questionnaire of study. Five strata were used (central, east, west, north and west) for conducting the study in the Vaal Triangle. A combination of quantitative and qualitative methods of data collection and analyses were used in the study. The variables used for quantitative analysis were socioeconomic variables that were associated with the viability of SMMEs operating in the Vaal Triangle region of Gauteng Province...|$|R
40|$|PURPOSE:To re-evaluated {{the clinic}} {{efficacy}} of ureteroscopic lithotripsy (URS) and {{extracorporeal shock wave lithotripsy}} (ESWL) on ureteral calculi with Cochrane systematic reviews in this paper. METHODS: We searched clinical randomized controlled trials and prospective controlled trials in databases such as Cochrane library, Medline, Springer, Elsevier Science Direct, PubMed. Pooled estimate of risk ratios (RRs), standard mean difference (SMD) with 95 % confidence intervals (CIs) {{were used as}} measure of effect sizes. Summary effect estimates were also <b>stratified</b> by <b>sample</b> <b>size,</b> study design and study region. The overall effect sizes were derived using a random-effects model or fixed-effects model when appreciated, and meta-analysis were conducted with software RewMan 5. 0. RESULTS:The meta-analysis suggested that there were significant differences of post-treatment stone free rate, repeat treatment rate, patients' satisfaction, incidence of postoperative complications, operation time and hospital stays between ESWL treatment cases and URS treatment cases. But in the <b>sample</b> <b>sizes</b> analysis, {{there were no significant differences}} of the post-treatment stone free rate and repeat treatment rate when the <b>sample</b> <b>sizes</b> were less than 100. CONCLUSIONS: Compared to the ureteroscopic lithotripsy treatment, extracorporeal shock wave lithotripsy treatment provided a significantly lower post-treatment stone free rate, but it also obviously brought out less postoperative complications, shorter operation time and hospital stays...|$|R
40|$|In {{this paper}} we propose a general {{framework}} to deal with the presence of covariate mea-surement error in endogenous stratifield samples. Using Chesher?s (2000) methodology, we develop approximately consistent estimators for the parameters of the structural model, in the sense that their inconsistency is of smaller order than that of the conventional estimators which ignore the existence of covariate measurement error. The approximate bias corrected estimators are obtained by applying the generalized method of moments (GMM) to a modifeld version of the moment indicators suggested by Imbens and Lancaster (1996) for endogenous <b>stratified</b> <b>samples.</b> Only the specification of the conditional distribution of the response vari-able given the latent covariates and the classical additive measurement error model assumption are required, the availability of information on both the marginal probability of the strata in the population and the variance of the measurement error not being essential. A score test to detect the presence of covariate measurement error arises as a by-product of this approach. Monte Carlo evidence is presented which suggests that, in endogenous <b>stratified</b> <b>samples</b> of moderate <b>sizes,</b> the modified GMM estimators perform well. endogenous <b>stratified</b> <b>samples,</b> covariate measurement error, generalized method of moments estimation, score tests...|$|R
50|$|In {{sampling}} theory, {{sampling fraction}} is {{the ratio of}} <b>sample</b> <b>size</b> to population size or, {{in the context of}} <b>stratified</b> <b>sampling,</b> the ratio of the <b>sample</b> <b>size</b> {{to the size of the}} stratum.The formula for the sampling fraction iswhere n is the <b>sample</b> <b>size</b> and N is the population <b>size.</b> If the <b>sampling</b> fraction is less than 5% or 0.05, then the finite population multiplier might be ignored.|$|R
40|$|Abstract. Animal {{distribution}} maps serve many purposes such as estimating transmission risk of zoonotic pathogens to both {{animals and}} humans. The reliability and usability of such maps is {{highly dependent on}} the quality of the input data. However, decisions on how to perform livestock surveys are often based on previous work without considering possible consequences. A better understanding of the impact of using different sample designs and processing steps on the accuracy of livestock distribution estimates was acquired through iterative experiments using detailed survey. The importance of <b>sample</b> <b>size,</b> <b>sample</b> design and aggregation is demonstrated and spatial interpolation is presented as a potential way to improve cattle number estimates. As expected, results show that an increasing <b>sample</b> <b>size</b> increased the precision of cattle number estimates but these improvements were mainly seen when the initial <b>sample</b> <b>size</b> was relatively low (e. g. a median relative error decrease of 0. 04 % per sampled parish for <b>sample</b> <b>sizes</b> below 500 parishes). For higher <b>sample</b> <b>sizes,</b> the added value of further increasing the number of samples declined rapidly (e. g. a median relative error decrease of 0. 01 % per sampled parish for <b>sample</b> <b>sizes</b> above 500 parishes. When a two-stage <b>stratified</b> <b>sample</b> design was applied to yield more evenly distributed samples, accuracy levels were higher for low sample densities and stabilised at lower <b>sample</b> <b>sizes</b> compared to one-stage <b>stratified</b> <b>sampling.</b> Aggregating the resulting cattle number estimates yielded significantly more accurate results because of averaging under- and over-estimates (e. g. when aggregating cattle number estimates from subcounty to district level, P < 0. 009 based on a sample of 2, 077 parishes using one-stage <b>stratified</b> <b>samples).</b> During aggregation, area-weighted mea...|$|R
40|$|Animal {{distribution}} maps serve many purposes such as estimating transmission risk of zoonotic pathogens to both {{animals and}} humans. The reliability and usability of such maps is {{highly dependent on}} the quality of the input data. However, decisions on how to perform livestock surveys are often based on previous work without considering possible consequences. A better understanding of the impact of using different sample designs and processing steps on the accuracy of livestock distribution estimates was acquired through iterative experiments using detailed survey. The importance of <b>sample</b> <b>size,</b> <b>sample</b> design and aggregation is demonstrated and spatial interpolation is presented as a potential way to improve cattle number estimates. As expected, results show that an increasing <b>sample</b> <b>size</b> increased the precision of cattle number estimates but these improvements were mainly seen when the initial <b>sample</b> <b>size</b> was relatively low (e. g. a median relative error decrease of 0. 04 % per sampled parish for <b>sample</b> <b>sizes</b> below 500 parishes). For higher <b>sample</b> <b>sizes,</b> the added value of further increasing the number of samples declined rapidly (e. g. a median relative error decrease of 0. 01 % per sampled parish for <b>sample</b> <b>sizes</b> above 500 parishes. When a two-stage <b>stratified</b> <b>sample</b> design was applied to yield more evenly distributed samples, accuracy levels were higher for low sample densities and stabilised at lower <b>sample</b> <b>sizes</b> compared to one-stage <b>stratified</b> <b>sampling.</b> Aggregating the resulting cattle number estimates yielded significantly more accurate results because of averaging under- and over-estimates (e. g. when aggregating cattle number estimates from subcounty to district level, P < 0. 009 based on a sample of 2, 077 parishes using one-stage <b>stratified</b> <b>samples).</b> During aggregation, area-weighted mean values were assigned to higher administrative unit levels. However, when this step is preceded by a spatial interpolation to fill in missing values in non-sampled areas, accuracy is improved remarkably. This counts especially for low <b>sample</b> <b>sizes</b> and spatially even distributed samples (e. g. P < 0. 001 for a sample of 170 parishes using one-stage <b>stratified</b> <b>sampling</b> and aggregation on district level). Whether the same observations apply on a lower spatial scale should be further investigated...|$|R
40|$|Much {{attention}} has been given to sampling design, and the sampling method chosen directly affects the sampling accuracy. The development of spatial sampling theory has lead to the recognition of the importance of taking spatial dependency into account when sampling. This text uses the new Sandwich Spatial Sampling and Inference (SSSI) software as a tool to compare the relative error, coefficient of variation (CV), and design effect with five sampling models – simple random <b>sampling,</b> <b>stratified</b> <b>sampling,</b> spatial random <b>sampling,</b> spatial <b>stratified</b> <b>sampling,</b> and sandwich spatial sampling. The five models are simulated 1000 times each with a range of <b>sample</b> <b>sizes</b> from 10 to 80. SSSI includes six models in all, but systematic sampling is not used here because the sample positions are fixed. The dataset consists of 84 points measuring soil heavy metal content in Shanxi Province, China. The whole area is stratified into four layers by soil type、hierarchical cluster and geochronology, and three layers by geological surface. The research shows that the accuracy of spatial simple random <b>sampling</b> and spatial <b>stratified</b> <b>sampling</b> is better than simple random <b>sampling</b> and <b>stratified</b> <b>sampling</b> because the soil content is spatially continuous, and stratified models are more efficient than non-stratified models. Stratification by soil type yields higher accuracy than by geochronology in the case of smaller <b>sample</b> <b>sizes,</b> but lower accuracy in larger <b>sample</b> <b>sizes.</b> Based on spatial <b>stratified</b> <b>sampling,</b> sandwich sampling develops a report layer composed of the user’s final report units, allowing the user to obtain the mean and variance of each report unit with high accuracy. In the case of soil sampling, SSSI was a useful tool for evaluating the accuracy of different sampling techniques. 1...|$|R
5000|$|<b>Stratified</b> <b>sampling</b> is {{not useful}} when the {{population}} cannot be exhaustively partitioned into disjoint subgroups.It {{would be a}} misapplication of the technique to make subgroups' <b>sample</b> <b>sizes</b> proportional {{to the amount of}} data available from the subgroups, rather than scaling <b>sample</b> <b>sizes</b> to subgroup sizes (or to their variances, if known to vary significantly -- e.g. by means of an F Test). Data representing each subgroup are taken to be of equal importance if suspected variation among them warrants <b>stratified</b> <b>sampling.</b> If subgroup variances differ significantly and the data needs to be stratified by variance, {{it is not possible to}} simultaneously make each subgroup <b>sample</b> <b>size</b> proportional to subgroup size within the total population. For an efficient way to partition sampling resources among groups that vary in their means, variance and costs, see [...] "optimum allocation".The problem of <b>stratified</b> <b>sampling</b> in the case of unknown class priors (ratio of subpopulations in the entire population) can have deleterious effect on the performance of any analysis on the dataset, e.g. classification. In that regard, minimax sampling ratio can be used to make the dataset robust with respect to uncertainty in the underlying data generating process.|$|R
30|$|If a {{population}} {{from which a}} sample is to be drawn constitute a heterogeneous group (for our case, members and nonmembers of agricultural cooperatives), <b>stratified</b> <b>sampling</b> is applied. The main advantages of <b>stratified</b> <b>sampling</b> are (i) more reliable information {{can be obtained from}} the same <b>sample</b> <b>size</b> if the population is stratified than from the population as a whole and (ii) comparisons between the two groups are easy as a separate but similar survey is done in each group.|$|R
40|$|Applied {{statistics}} research plays {{pivotal role}} in diverse problems of social sciences, agricultural sciences, health sciences, and business research. Many investigations are conducted by survey research. The technique of sampling and determination of <b>sample</b> <b>size</b> have crucial role in survey-based research problems in applied statistics. Specific sampling techniques are used for specific research problems because one technique may not be appropriate for all problems. Similarly, if the <b>sample</b> <b>size</b> is inappropriate it may lead to erroneous conclusions. The present paper gives an overview of some commonly used terms and techniques such as <b>sample,</b> random <b>sampling,</b> <b>stratified</b> random <b>sampling,</b> power of the test, confidence interval {{that need to be}} specified for a <b>sample</b> <b>size</b> calculation and some techniques for determination of <b>sample</b> <b>size,</b> and also describes some sampling methods such as purposive random <b>sampling,</b> random <b>sampling,</b> <b>stratified</b> random <b>sampling,</b> systematic random sampling and quota sampling for specific research purposes...|$|R
40|$|Organization theory often {{focuses on}} stakeholders’ {{interests}} {{as well as}} the organization's social responsibility and while the focus is normally more on private organizations, but these issues must be considered in public organizations as well. People expect the public organizations to think and to act more generally. The {{purpose of this study is}} to compare the tendencies of private and public organizations in the field of social responsibility. This is an applied research and is a descriptive-survey study in terms of research method. The statistical population of this study covers all 670 managers of private and public organizations of city of Tehran, Iran. Using Morgan table and by conducing <b>stratified</b> <b>sampling,</b> a <b>sample</b> <b>size</b> of 140 was selected. Data gathering tool was a questionnaire consisted of 18 items. To confirm the questionnaire validity, we obtained the experts’ opinions on acceptable face validity and content validity. To evaluate the questionnaire reliability, the Cronbach's alpha was used (alpha coefficient =. 88). Research hypotheses were tested using independent t-test and all of them were confirmed...|$|R
25|$|There are, however, some {{potential}} drawbacks to using <b>stratified</b> <b>sampling.</b> First, identifying strata and implementing {{such an approach}} can increase the cost and complexity of sample selection, as well as leading to increased complexity of population estimates. Second, when examining multiple criteria, stratifying variables {{may be related to}} some, but not to others, further complicating the design, and potentially reducing the utility of the strata. Finally, in some cases (such as designs with a large number of strata, or those with a specified minimum <b>sample</b> <b>size</b> per group), <b>stratified</b> <b>sampling</b> can potentially require a larger sample than would other methods (although in most cases, the required <b>sample</b> <b>size</b> would be no larger than would be required for simple random sampling).|$|R
5000|$|With more {{complicated}} sampling techniques, such as <b>stratified</b> <b>sampling,</b> the sample {{can often be}} split up into sub-samples. Typically, if there are H such sub-samples (from H different strata) then each of them will have a <b>sample</b> <b>size</b> nh, h = 1, 2, ..., H. These nh must conform to the rule that n1 + n2 + ... + nH = n (i.e. that the total <b>sample</b> <b>size</b> is given by {{the sum of the}} sub-sample sizes). Selecting these nh optimally can be done in various ways, using (for example) Neyman's optimal allocation.|$|R
40|$|The {{objective}} of sampling is to estimate population parameters, such as incidence or prevalence, from {{information contained in}} a sample. In this paper, the authors describe sources of error in sampling; basic probability sampling designs, including simple random <b>sampling,</b> <b>stratified</b> <b>sampling,</b> systematic sampling, and cluster sampling; estimating a population size if unknown; and factors influencing <b>sample</b> <b>size</b> determination for epidemiological studies in veterinary medicine...|$|R
40|$|Background: P 53 is a tumor {{suppressor}} gene and plays {{important role in the}} etiology of breast cancer. Intron 3 sixteen-bp duplication polymorphism of p 53 has been reported to be associated with breast cancer risk. However, the reported results remain conflicting rather than conclusive. Methods: A meta-analysis including 19 case-control studies was performed to address this issue. Odds ratios (ORs) with 95 % confidence intervals (CIs) were adopted to evaluate the association. Results: The overall results suggested that the variant genotypes were associated with a significantly increased breast cancer risk (Del/Ins vs Del/Del: OR = 1. 18, 95 % CI: 1. 00 – 1. 40; Ins/Ins vs Del/Del: OR = 1. 42, 95 % CI = 1. 09 – 1. 84; Ins/Ins+Del/Ins vs Del/Del: OR = 1. 21, 95 % CI = 1. 03 – 1. 41). When <b>stratifying</b> by <b>sample</b> <b>size</b> of studies, a significantly elevated risk was also observed among large sample studies (. 500 subjects) but not among small sample studies (# 500 subjects). Conclusion: These results suggested that the 16 -bp duplication polymorphism of p 53 may contribute to susceptibility t...|$|R
5000|$|Sampling design {{specification}} - What {{is the total}} population? What <b>sample</b> <b>size</b> is necessary for this population? What sampling method to use?- examples: Probability Sampling:- (cluster <b>sampling,</b> <b>stratified</b> <b>sampling,</b> simple random sampling, multistage sampling, systematic sampling) & Nonprobability sampling:- (Convenience Sampling,Judgement Sampling, Purposive Sampling, Quota Sampling, Snowball Sampling, etc. [...] ) ...|$|R
40|$|In this study, {{comparison}} {{has been}} made for different sampling designs, using the HIES data of North West Frontier Province (NWFP) for 2001 - 02 and 1998 - 99 collected from the Federal Bureau of Statistics, Statistical Division, Government of Pakistan, Islamabad. The performance of the estimators has also been considered using bootstrap and Jacknife. A two-stage <b>stratified</b> random <b>sample</b> design is adopted by HIES. In the first stage, enumeration blocks and villages are treated as the first stage Primary Sampling Units (PSU). The sample PSU’s are selected with probability proportional to <b>size.</b> Secondary <b>Sampling</b> Units (SSU) i. e., households are selected by systematic sampling with a random start. They have used a single study variable. We have compared the HIES technique with some other designs, which are: <b>Stratified</b> Simple Random <b>Sampling.</b> <b>Stratified</b> Systematic <b>Sampling.</b> <b>Stratified</b> Ranked Set <b>Sampling.</b> <b>Stratified</b> Two Phase <b>Sampling.</b> Ratio and Regression methods were applied with two study variables, which are: Income (y) and Household sizes (x). Jacknife and Bootstrap are used for variance replication. Simple Random <b>Sampling</b> with <b>sample</b> <b>size</b> (462 to 561) gave moderate variances both by Jacknife and Bootstrap. By applying Systematic Sampling, we received moderate variance with <b>sample</b> <b>size</b> (467). In Jacknife with Systematic Sampling, we obtained variance of regression estimator {{greater than that of}} ratio estimator for a <b>sample</b> <b>size</b> (467 to 631). At a <b>sample</b> <b>size</b> (952) variance of ratio estimator gets greater than that of regression estimator. The most efficient design comes out to be Ranked set sampling compared with other designs. The Ranked set sampling with jackknife and bootstrap, gives minimum variance even with the smallest <b>sample</b> <b>size</b> (467). Two Phase sampling gave poor performance. Multi-stage sampling applied by HIES gave large variances especially if used with a single study variable...|$|R
40|$|This paper {{provides}} {{an attempt to}} utilize the geometric programming approach in multivariate <b>stratified</b> <b>sample</b> surveys in case of non-response. The problem has been solved in two phases. In first phase the multivariate <b>stratified</b> <b>sample</b> surveys in case of non-response has been formulated as geometric programming problem (GPP) and the solution is obtained. The obtained solution is the dual solution of the formulated GPP. In second phase {{with the help of}} dual solutions of formulated GPP and primal-dual relationship theorem the optimum allocation of <b>sample</b> <b>sizes</b> of respondents and non respondents are obtained. A numerical example is given to illustrate the procedure...|$|R
40|$|This paper {{discusses}} {{the importance of}} sampling in Geographic Information Systems (GIS), and briefly summarizes the classical sampling theories of simple random sampling, systematic <b>sampling</b> and <b>stratified</b> <b>sampling.</b> The main {{purpose of this paper}} is to introduce the architecture of spatial sampling software named as Sandwich Spatial Sampling Package. In this software, the steps of sampling include calculating <b>sampling</b> <b>size,</b> distributing <b>samples,</b> calculating and displaying sampling results. The first step can be divided into four parts: setting configuration files, selecting sampling fields and relative parameters, inputting parameters to calculate <b>sampling</b> <b>sizes</b> and displaying calculated results to help users choose the best function to calculate <b>sampling</b> <b>size...</b>|$|R
40|$|Optimal {{allocation}} {{problem of}} <b>sample</b> <b>size</b> in <b>stratified</b> <b>sampling</b> is discussed. The unitary costs {{are described as}} uncertain random variables. Two chance models of optimal allocation of <b>sample</b> <b>size</b> are constructed. The crisp equivalence of the proposed models are provided when the unitary costs are chosen as some special uncertain random variables. Due to the converted programming problem includes standard normal distribution in objective function and constraint conditions, Genetic algorithm is used to solve the converted optimal allocation problems. To finish, an example is demonstrated the feasibility of the method...|$|R
40|$|There are {{circumstances}} under which <b>stratified</b> <b>sampling</b> is worse than simple random sampling, even if the allocation of the <b>sample</b> <b>sizes</b> is optimal. This phenomenon was discovered more than sixty years ago, but is not as widely known as one might expect. We provide it with lower and upper bounds for its badness {{as well as with}} an explanation. Comment: 11 page...|$|R
40|$|Recent {{research}} advocates applying sampling {{to accelerate}} microarchitecture simulation. Simple random sampling offers accurate performance estimates (with a high quantifiable confidence) {{by taking a}} large number (e. g., 10, 000) of short performance measurements over {{the full length of}} a benchmark. Simple random sampling does not exploit the often repetitive behaviors of benchmarks, collecting many redundant measurements. By identifying repetitive behaviors, we can apply <b>stratified</b> random <b>sampling</b> to achieve the same confidence as simple random sampling with far fewer measurements. Our oracle limit study of optimal <b>stratified</b> <b>sampling</b> of SPEC CPU 2000 benchmarks demonstrates an opportunity to reduce required measurement by 43 x over simple random sampling. Using our oracle results as a basis for comparison, we evaluate two practical approaches for selecting strata, program phase detection and IPC profiling. Program phase detection is attractive because it is microarchitecture independent, while IPC profiling directly minimizes stratum variance, therefore minimizing <b>sample</b> <b>size.</b> Unfortunately, our results indicate that: (1) program phase stratification falls far short of optimal opportunity, (2) IPC profiling requires expensive microarchitecturespecific analysis, and (3) both methods require large <b>sampling</b> unit <b>sizes</b> to make strata selection feasible, offsetting their reductions of <b>sample</b> <b>size.</b> We conclude that, without better stratification approaches, <b>stratified</b> <b>sampling</b> does not provide a clear advantage over simple random sampling. 1...|$|R
40|$|The paper {{examines}} optimal sampling {{techniques for}} obtaining accurate spatial averages of soil moisture, at various depths and for cell sizes {{in the range}} 2. 5 - 40 acres, with a minimum number of samples. Both simple random <b>sampling</b> and <b>stratified</b> <b>sampling</b> procedures are used to reach a set of recommended <b>sample</b> <b>sizes</b> for each depth and for each cell size. Major conclusions from statistical sampling test results are that (1) the number of samples required decreases with increasing depth; (2) when {{the total number of}} samples cannot be prespecified or the moisture in only one single layer is of interest, then a simple random sample procedure should be used which is based on the observed mean and SD for data from a single field; (3) when the total number of samples can be prespecified and the objective is to measure the soil moisture profile with depth, then <b>stratified</b> random <b>sampling</b> based on optimal allocation should be used; and (4) decreasing the sensor resolution cell size leads to fairly large decreases in <b>samples</b> <b>sizes</b> with <b>stratified</b> <b>sampling</b> procedures, whereas only a moderate decrease is obtained in simple random sampling procedures...|$|R
40|$|AbstractIn finite {{sampling}} it {{is widely}} believed that the probability sampling distribution is irrelevant for inference from a given sample. A super-population model in <b>stratified</b> <b>sampling</b> is investigated to show that the probability sampling distribution is relevant. It is proved that the traditional estimator of a linear combination of strata means, which is admissible and minimax when the vector of <b>sample</b> <b>sizes</b> is fu;ed, is inadmissible when the vector of <b>sample</b> <b>sizes</b> is random. Two alternative estimators are investigated. Based on analysis which is partly analytical and partly numerical, it appears that both of them are better than the traditional estimator...|$|R
2500|$|Probability {{sampling}} includes: Simple Random <b>Sampling,</b> Systematic <b>Sampling,</b> <b>Stratified</b> <b>Sampling,</b> Probability Proportional to <b>Size</b> <b>Sampling,</b> and Cluster or Multistage Sampling. These {{various ways}} of probability sampling have {{two things in}} common: ...|$|R
40|$|The {{experiments}} were conducted for monitoring crop area by spatial sampling methods in a winter wheat main production region {{with a size}} of 42 Km× 42 Km in Hengshui City, Hebei Province in China to optimize designs of the frameworks and elements (<b>sample</b> <b>size,</b> sample-square dimension), based on Remote Sensing (RS) and Geographical Information System (GIS) techniques. 5 sample-square dimension levels (3000 m× 3000 m, 2000 m× 2000 m, 1000 m× 1000 m, 500 m× 500 m and 300 m× 300 m) were selected and 3 sampling techniques (simple random sampling, systematic <b>sampling</b> and <b>stratified</b> <b>sampling)</b> were applied. The experimental results demonstrate that the <b>sampling</b> efficiency by <b>stratified</b> <b>sampling</b> was the maximal (the average relative error was 0. 15 %, the average <b>sample</b> <b>size</b> varied from 9 to 10); {{and that of the}} systematic sampling was inferior (the average relative error varies from 0. 74 %~ 2. 06 %, the average <b>sample</b> <b>size</b> is 229); the sampling efficiency by simple random sampling was the minimum (the average relative error is 2. 04 %, the average <b>sample</b> <b>size</b> is 229) among 3 sampling techniques. Sampling relative error decreased with sample-square dimension simultaneously. When the sample-square dimension was reduced to a certain extent (the <b>size</b> of <b>sample</b> is 500 m× 500 m), the error was not declining any more. The sampling relative error was the minimum using the sample-square with a size of 500 m× 500 m among 5 sample-square dimension levels. 1...|$|R
30|$|<b>Sample</b> <b>size</b> was {{calculated}} assuming a 50 % prevalence ratio for any characteristic to be estimated with a 95 % confidence interval. This assumption {{leads to the}} highest <b>sample</b> <b>size</b> with a precision of 1.9 %. A total of 2, 707 subjects, 1, 302 males and 1, 405 females, were randomly selected according to multistage <b>stratified</b> cluster <b>sampling</b> design.|$|R
