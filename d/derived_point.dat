32|1092|Public
5000|$|... #Caption: A z-projection of an {{osteosarcoma}} cell phalloidin stained to visualise actin filaments. The {{image was}} {{taken on a}} confocal microscope and the subsequent deconvolution was done using an experimentally <b>derived</b> <b>point</b> spread function.|$|E
5000|$|... #Caption: An {{example of}} an {{experimentally}} <b>derived</b> <b>point</b> spread function from a confocal microscope using a 63x 1.4NA oil objective. It was generated using Huygens Professional deconvolution software. Shown are views in xz, xy, yz and a 3D representation.|$|E
50|$|The point spread {{function}} of the pinhole is an ellipsoid, several times {{as long as it}} is wide. This limits the axial resolution of the microscope. One technique of overcoming this is 4 microscopy where incident and or emitted light are allowed to interfere from both above and below the sample to reduce the volume of the ellipsoid. An alternative technique is confocal theta microscopy. In this technique the cone of illuminating light and detected light are at an angle to each other (best results when they are perpendicular). The intersection of the two point spread functions gives a much smaller effective sample volume. From this evolved the single plane illumination microscope. Additionally deconvolution may be employed using an experimentally <b>derived</b> <b>point</b> spread function to remove the out of focus light, improving contrast in both the axial and lateral planes.|$|E
40|$|Short view over {{peripheral}} areas contemporary development concepts {{is used as}} a <b>deriving</b> <b>point</b> to expose a complex evaluation of {{peripheral areas}} through the concept of civilization development stages. The most severe development problems and development potentials of four peripheral areas in Slovenia are defined...|$|R
40|$|A {{method for}} <b>deriving</b> <b>point</b> {{estimates}} of percentiles in the extreme-value distribution conditioned on the ancillary information is given. The resulting conditional median unbiased estimate {{is the same}} regardless of the arbitrary choice of equivariant estimators. The conditional median unbiased estimator is also shown to be optimal with respect to Pitman Nearness. Weibull failure model median unbiased estimators Pitman Nearness...|$|R
40|$|This paper {{presents}} estimations of {{the generalized}} Rayleigh distribution model based on grouped and censored data. The maximum likelihood method {{is used to}} <b>derive</b> <b>point</b> and asymptotic con¯dence estimates of the unknown parameters. The results obtained in this paper generalize some of those available in the literature. Finally, we test whether the current model ¯ts a set of real data better than other models...|$|R
50|$|Slightly {{east of the}} Great Mill, at {{the banks}} of the Motława river, a stronghold was built in the 1060s. This stronghold {{encompassed}} roughly the area now enclosed by the Rycerska and Sukiennicza streets, and in the 11th century was located at the confluence of the Motława and Vistula rivers. The stronghold consisted of a fort and a suburbium covering 2.7 ha which may have held 2,200 to 2,500 inhabitants. Timber from trees cut between 1054 and 1063 was used for buildings of {{the first phase of the}} stronghold's construction, timber from trees cut around 1090 was used to construct the buildings of the subsequent phase. A first rampart enclosing the stronghold was built with timber from trees cut in the 1060s. Starting in 1112, according to dendrodates, the stronghold was first leveled and subsequently transformed. This corresponds with written sources mentioning the subduction of Pomerelia by Piast Polish king Boleslaw III Wrymouth between 1112 and 1116. The youngest examined layers from which dendrodates could be <b>derived</b> <b>point</b> at around 1135.|$|E
30|$|A scale bar is a {{calibrated}} pole {{built out}} of a material with little thermal expansion where the distance between two markers (yellow arrows in Fig.  3) is known. The scale bar {{can be used to}} scale the measurements and the <b>derived</b> <b>point</b> cloud into the metric system (in metres). It is possible to transform this local system into a global system using the coordinates of the laser scanning control points which are also visible in the images (blue arrows in Fig.  3).|$|E
40|$|This paper {{presents}} a practical {{framework for the}} integration of unmanned aerial vehicle (UAV) based photogrammetry and terrestrial laser scanning (TLS) with application to open-pit mine areas, which includes UAV image and TLS point cloud acquisition, image and cloud point processing and integration, object-oriented classification and three-dimensional (3 D) mapping and monitoring of open-pit mine areas. The proposed framework was tested in three open-pit mine areas in southwestern China. (1) With respect to extracting the conjugate points of the stereo pair of UAV images and those points between TLS point clouds and UAV images, some feature points were first extracted by the scale-invariant feature transform (SIFT) operator and the outliers were identified and therefore eliminated by the RANdom SAmple Consensus (RANSAC) approach; (2) With respect to improving the accuracy of geo-positioning based on UAV imagery, the ground control points (GCPs) surveyed from global positioning systems (GPS) and the feature points extracted from TLS were integrated in the bundle adjustment, and three scenarios were designed and compared; (3) With respect to monitoring and mapping the mine areas for land reclamation, an object-based image analysis approach {{was used for the}} classification of the accuracy improved UAV ortho-image. The experimental results show that by introduction of TLS <b>derived</b> <b>point</b> clouds as GCPs, the accuracy of geo-positioning based on UAV imagery can be improved. At the same time, the accuracy of geo-positioning based on GCPs form the TLS <b>derived</b> <b>point</b> clouds is close to that based on GCPs from the GPS survey. The results also show that the TLS <b>derived</b> <b>point</b> clouds can be used as GCPs in areas such as in mountainous or high-risk environments where it is difficult to conduct a GPS survey. The proposed framework achieved a decimeter-level accuracy for the generated digital surface model (DSM) and digital orthophoto map (DOM), and an overall accuracy of 90. 67 % for classification of the land covers in the open-pit mine...|$|E
40|$|A {{new method}} of {{constructing}} arcs in projective space is given. It is a generalisation {{of the fact}} that a normal rational curve can be given by the complete intersection of a set of quadrics. The non-classical 1 O-arc of PG(4, 9) together with its special point is the set of <b>derived</b> <b>points</b> of a. cubic primal. This property is shared with the normal rational curve of this space...|$|R
50|$|In general terms, having {{specified}} {{the criteria}} and categories {{for a given}} value model, {{the challenge is to}} <b>derive</b> <b>point</b> values that accurately reflect the relative importance of the criteria and categories to the decision-maker. Deriving valid and reliable point values is arguably the most difficult task when creating a value model. The PAPRIKA method does this based on decision-makers’ preferences as expressed using pairwise rankings of alternatives.|$|R
30|$|Finally, {{we showed}} some {{relation}} of multivalued mappings and fuzzy mappings, whichcan be utilized to <b>derive</b> fixed <b>point</b> for multivalued mappings.|$|R
40|$|We {{consider}} two {{marked point}} processes [Phi] and [Psi] {{on the real}} half-line such that [Psi] is an -predictable thinning and marking of [Phi]. Using the method of the probability of reference we derive linear and non-linear filtering equations for the conditional distribution, where {gt} is a certain -adapted process. In particular, we will apply our results to the filtering of a partially observed semi-Markov process. In that case, the conditional distribution of the last jumptime before t [greater-or-equal, slanted] 0 and the corresponding jumpvalue can be expressed explicitly {{in terms of a}} solution of a Markov renewal equation. marked point process <b>derived</b> <b>point</b> process filtering partially observed semi-Markov process...|$|E
40|$|Minimax regret is {{an exact}} method for {{deriving}} a recommendation {{based on a}} small sample. It can incorporate costs in its measurement of opportunity loss (regret) in terms of not making the best choice. In this paper we present the methodolgy and implement it in four examples from di¤erent …elds: medicine, development policy, experimental game theory and macro economics. We focus on the comparison between two treatments with unknown response. Recommendations based on the binomial average rule, the correlated binomial average rule and on the empirical success rule are <b>derived.</b> <b>Point</b> estimates of the treatment e¤ect round o ¤ the picture. Key words: correlated binomial average rule, empirical success rule, estimation, minimmax regret, treatment e¤ect. JEL classi…cation numbers: C 44, D 81, C 72, C 90. 1...|$|E
30|$|A three-parameters {{continuous}} distribution, namely, Power Lomax distribution (POLO) {{is proposed}} and studied for remission times of bladder cancer data. POLO distribution accommodate both inverted bathtub and decreasing hazard rate. Several statistical and reliability properties are <b>derived.</b> <b>Point</b> estimation via {{method of moments}} and maximum likelihood and the interval estimation are also studied. The simulation schemes are calculated to examine the bias and mean square error of the maximum likelihood parameter estimators. Finally, a real data application about the remission time of bladder cancer is used to illustrate {{the usefulness of the}} proposed distribution in modelling real data application. The characteristics of the fitting data using the proposed distribution are compared with known extensions of Lomax distribution. The comparison showed that the POLO distribution outfit most well-known extensions of Lomax distribution.|$|E
2500|$|Retarded {{potentials}} {{can also}} be <b>derived</b> for <b>point</b> charges, and the equations are known as the Liénard–Wiechert potentials. The scalar potential is: ...|$|R
40|$|We {{present a}} method to <b>derive</b> the {{relative}} <b>pointing</b> offsets for SPIRE Fourier-Transform Spectrometer (FTS) solar system object (SSO) calibration targets, which were observed regularly throughout the Herschel mission. We construct ratios of the spectra for all observations of a given source {{with respect to a}} reference. The reference observation is selected iteratively to be the one with the highest observed continuum. Assuming that any pointing offset leads to an overall shift of the continuum level, then these ratios represent the relative flux loss due to mispointing. The mispointing effects are more pronounced for a smaller beam, so we consider only the FTS short wavelength array (SSW, 958 - 1546 GHz) to <b>derive</b> a <b>pointing</b> correction. We obtain the relative pointing offset by comparing the ratio to a grid of expected losses for a model source at different distances from the centre of the beam, under the assumption that the SSW FTS beam can be well approximated by a Gaussian. In order to avoid dependency on the point source flux conversion, which uses a particular observation of Uranus, we use extended source flux calibrated spectra to construct the ratios for the SSOs. In order to account for continuum variability, due to the changing distance from the Herschel telescope, the SSO ratios are normalised by the expected model ratios for the corresponding observing epoch. We confirm the accuracy of the <b>derived</b> <b>pointing</b> offset by comparing the results with a number of control observations, where the actual pointing of Herschel is known with good precision. Using the method we <b>derived</b> <b>pointing</b> offsets for repeated observations of Uranus (including observations centred on off-axis detectors), Neptune, Ceres and NGC 7027. The results are used to validate and improve the point-source flux calibration of the FTS. Comment: 17 pages, 19 figures, accepted for publication in Experimental Astronom...|$|R
40|$|Abstract [...] This paper {{presents}} estimations of {{the modified}} Weibull distribution model based on grouped and censored data. The maximum likelihood method is utilized to <b>derive</b> <b>point</b> and asymptotic {{estimates of the}} unknown parameters. confidence and Further, the asymptotic confidence intervals for the parameters are derived from the Fisher information matrix. The likelihood ratio test is applied to test the goodness of fit of the modified Weibull distribution. To illustrate the application of this new distribution, a set of real data is analyzed. Index Term [...] modified weibull distribution, grouped data, maximum likelihood method...|$|R
40|$|The {{possible}} pathways for microstructural development under nonequilibrium condition by {{the rapid}} solidification of alloys containing liquid miscibility gap {{have been studied}} using Zn-Bi binary alloys as a model system. The primary aim is to explore {{the possibility of the}} intermediate formation of a thermodynamically unstable solid solution as a precursor phase which can spontaneously decompose to yield nanodispersions. It is shown that the information of crystallographic shape of the nanosized dispersions obtained by transmission electron microscopy and the <b>derived</b> <b>point</b> groups can be utilized to arrive at a definite conclusion of this possibility. Our results establish the formation of such a solid solution owing to the kinetic process of nonequilibrium trapping in spite of a very strong clustering tendency. The latter leads to the spontaneous decomposition of the solid solution during quenching to yield nanodispersions...|$|E
40|$|According to today's {{appreciation}} of geodesy, determination of a vector field of <b>derived</b> <b>point</b> displacements {{should not only}} be the sole objective, but moreover a tool for the comprehension of the total complex of cause, transfer process and effect. This extended interdisciplinary context allows a profound analysis and interpretation of deformation processes. The integration algorithm to be used {{on the base of}} system theory is a KALMAN-filter, so that the considerations focus mainly on the resulting potentiality by combining this approach with methods from mechanics and geodesy for parametric identification of deformation processes. These considerations establish the 'Hannover filter', whose principal thoughts and characteristics are summarized in the work. Within this filter the already used quasi-static and kinematic approaches can be seen as special cases of a further evolved dynamic concept. (orig. /AKF) SIGLEAvailable from TIB Hannover: ZS 299 A(208) +a/b/c / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|E
40|$|We {{have used}} the High Resolution Imager (HRI) on ROSAT to image PSR 0656 + 14 at soft X-ray energies. With a net observing time of 10, 326 s, we {{obtained}} a source event rate of 0. 382 +/- 0. 007 counts/s. Comparing the radial distribution of these counts between 15 and 100 arcsec to an empirically <b>derived</b> <b>point</b> spread function for HRI soft sources, we find {{no evidence of a}} spatially extended X-ray nebula to a limiting surface brightness of 1. 67 x 10 exp - 6 counts/s/sq arcsec, corresponding to a limit of 14 percent of the observed flux out to a radius of 100 arcsec. The X-ray emission of the pulsar is pulsed at the 0. 385 s period of the radio pulsar, with a pulse fraction of 7 +/- 2. 2 percent and a FWHM of 0. 10 s. We discuss some models of the X-ray radiation of PSR 0656 + 14 compatible with both the HRI and PSPC results...|$|E
40|$|Statistical {{inference}} for {{the parameters}} in three competing risks models is considered in this paper. It {{is assumed that}} there are more than two causes of failure. The maximum likelihood procedure is used to <b>derive</b> <b>point</b> and asymptotic confidence interval estimates of the unknown parameters. The risks due to each cause of failure are investigated. Two sets of data are analyzed in order to (1) illustrate how the model can be applied and (2) test the hypothesis that the causes of failure follow the Chen distribution rather than the exponential distribution, or the Weibull distribution...|$|R
30|$|One {{also proved}} some fixed point theorems for such {{mappings}} on complete metric spacesand showed that these {{results can be}} utilized to <b>derive</b> fixed <b>point</b> theorems inpartially ordered metric spaces.|$|R
50|$|The name 'spear' mint <b>derives</b> {{from the}} <b>pointed</b> leaf tips.|$|R
40|$|Lending is {{associated}} with credit risk. Modelling the loss stochastically, the cost of credit risk is the expected loss. In credit business {{the probability that the}} debtor will default in payments within one year, often is the only reliable quantitative parameter. Modelling the time to default as continuous variable corresponds to an exponential distribution. We calculate the expected loss of a trade with several cash flows, even if the distribution is not exponential. Continuous rating migration data show that the exponential distribution is not adequate in general. The distribution can be calibrated using rating migrations without a parametric model. A practitioner, however, will model time as a discrete variable. We show that the expected loss in the discrete model is a linear approximation of the expected loss in the continuous model and discuss the consequences. Finally, as costs for the expected loss cannot be charged up-front, the credit spread over risk-free interest is <b>derived.</b> <b>Point</b> process, credit valuation, hazard rate, kernel smoothing test...|$|E
40|$|Automatically extracting rooftop {{information}} from aerial photographs using point cloud generations tools and point cloud plane segmentation algorithms is a interesting and challenging topic. Previous studies on rooftop extraction have used airborne Light Detection And Ranging (LiDAR) <b>derived</b> <b>point</b> clouds or point clouds generated from photographs taken specifically for point cloud generation. We have used photographs {{taken from the}} Swedish National Land Survey database to generate point clouds using stereo-matching for rooftop segmentation. Aerial imagery from this data is both cheap and has nationwide coverage. Point cloud generation tools are evaluated based on coverage, point cloud size, geographical precision and point density. We propose a novel combination of property map clipping and rooftop plane segmentation algorithms derived from aerial photography via point cloud generation after comparing promising segmentation algorithms. We conclude that the point clouds generated from the aerial imagery are not sufficient for the implemented method for completely extracting all rooftop segments on a building in an urban environment...|$|E
40|$|Abstract. Nonlinear image {{registration}} {{is a prerequisite}} for a variety of medical image analysis tasks. A frequently used registration method is based on manually or automatically <b>derived</b> <b>point</b> landmarks leading to a sparse displacement field which is densified in a thin-plate spline (TPS) framework. A large problem of TPS interpolation/approximation is the requirement for evenly distributed landmark correspondences over the data set which can rarely be guaranteed by landmark matching algorithms. We propose to overcome this problem by combining the sparse correspondences with intensity-based registration in a generic nonlinear registration scheme based on the calculus of variations. Missing landmark information is compensated by a stronger intensity term, thus combining the strengths of both approaches. An explicit formulation of the generic framework is derived that constrains an intra-modality intensity data term with a regularization term from the corresponding landmarks and an anisotropic image-driven displacement regularization term. An evaluation of this algorithm is performed comparing it to an intensity- and a landmark-based method. Results on four synthetically deformed and four clinical thorax CT data sets at different breathing states are shown. ...|$|E
50|$|Cicero (and the <b>points</b> <b>derived</b> from cicero) {{was used}} {{in the early days of}} {{typography}} in continental Europe. In modern times, all computers use pica (and the <b>points</b> <b>derived</b> from pica) as font size measurement - alongside millimeters in countries using the metric system - for line length and paper size measurement.|$|R
30|$|As an {{additional}} {{check for the}} presence of endogeneity bias resulting from unobserved culture, we use a non-parametric difference-in-difference estimator to <b>derive</b> <b>point</b> estimates for the effect on the change in the post- 9 / 11 national environment on racial self-identification of Arab and Islamic Americans. All Arab and Islamic Americans received the same treatment associated with the Al Qaeda attacks of 9 / 11, but the treatment is likely to be much less effective for the elderly than for working-age and school-age persons. Hence, we treat elderly Arab and Islamic Americans as the control group.|$|R
40|$|We {{present a}} novel method for {{estimating}} {{the number of}} defects contained in a document using {{the results of an}} inspection of the document. The method is empirical, being based on observations made during past inspections of comparable documents. The method yields an interval estimate, that is, a whole range of values which is likely to contain the true value of the number of defects in the document. We also <b>derive</b> <b>point</b> estimates from the interval estimate. The method is validated using a known empirical inspection dataset and clearly outperforms existing approaches for estimating the defect content after inspections. 1...|$|R
40|$|The {{extraction}} of geometric and semantic information from image and range data {{is one of}} the main research topics. Between the different geomatics products, 3 D city models have shown to be a valid instrument for several applications. As a consequence, the interest for automated solutions able to speed up and reduce the costs for 3 D model generation is greatly increased. Image matching techniques can nowadays provide for dense and reliable point clouds, practically comparable to LiDAR ones in terms of accuracy and completeness. In this paper a methodology for the geometric reconstruction of roof outlines (eaves, ridges and pitches) from aerial images is presented. The approach keeps in count the fact the usually photogrammetrically <b>derived</b> <b>point</b> clouds and DSMs are more noisy with respect to LiDAR data. A data driven approach is used in order to keep the maximum flexibility and to achieve satisfying reconstructions with different typologies of buildings. Some tests and examples are reported showing the suitability of photogrammetric DSM for this topic and the performances of the developed algorithm in different operative conditions. 1...|$|E
40|$|The Far-Infrared Surveyor (FIS) {{is one of}} two {{focal plane}} {{instruments}} on the AKARI satellite. FIS has four photometric bands at 65, 90, 140, and 160 um, and uses two kinds of array detectors. The FIS arrays and optics are designed to sweep the sky with high spatial resolution and redundancy. The actual scan width is more than eight arcmin, and the pixel pitch is matches the diffraction limit of the telescope. <b>Derived</b> <b>point</b> spread functions (PSFs) from observations of asteroids are similar to the optical model. Significant excesses, however, are clearly seen around tails of the PSFs, whose contributions are about 30 % of the total power. All FIS functions are operating well in orbit, and its performance meets the laboratory characterizations, except for the two longer wavelength bands, which are not performing as well as characterized. Furthermore, the FIS has a spectroscopic capability using a Fourier transform spectrometer (FTS). Because the FTS takes advantage of the optics and detectors of the photometer, it can simultaneously make a spectral map. This paper summarizes the in-flight technical and operational performance of the FIS. Comment: 23 pages, 10 figures, and 2 tables. Accepted for publication in the AKARI special issue of the Publications of the Astronomical Society of Japa...|$|E
40|$|We present newly <b>derived</b> <b>point</b> source {{absolute}} flux calibrations for the COS FUV modes at {{both the}} original and second lifetime positions. The analysis includes observa-tions through the Primary Science Aperture (PSA) of the standard stars WD 0308 - 565, GD 71, WD 1057 + 729 and WD 0947 + 857 obtained as part of two calibration programs. Data were were obtained {{for all of the}} gratings at all of the original CENWAVE settings {{at both the}} original and second lifetime positions and for the G 130 M CENWAVE = 1222 at the second lifetime position. Data were also obtained with the FUVB segment for the G 130 M CENWAVE = 1055 and 1096 setting at the second lifetime position. We also present the derivation of L-flats that were used in processing the data and show that {{the internal consistency of the}} primary standards is ≤ 1 %. The accuracy of the absolute flux calibrations over the UV are estimated to be 1 – 2 % for the medium resolution gratings, and 2 – 3 % over most of the wavelength range of the G 140 L grating, although the uncertainty can be as large as 5 % or more at some G 140 L wavelengths. We note that these errors are all relative to the optical flux nea...|$|E
40|$|Hedonic {{property}} value models {{are often used}} to <b>derive</b> <b>point</b> estimates for identifying the relationship between environmental quality and property prices. The measurement of the environmental quality variable is often selected based on convenience, but variables reflecting different perceptions about environmental quality may result in implicit prices that vary substantially. This case study derives implicit prices for nine measures of water clarity using hedonic {{property value}} models of lakefront properties in Maine. Results show that water clarity variables based on different perceptions may result in differences in implicit prices large enough to potentially affect policy decisions. ...|$|R
5000|$|... #Caption: The {{irreducible}} representation as <b>derived</b> {{from the}} <b>point</b> group's operations ...|$|R
40|$|Abstract—This letter <b>derives</b> the {{two-dimensional}} <b>point</b> target spectrum for {{an arbitrary}} bistatic {{synthetic aperture radar}} configuration. The method described makes use of series reversion, the method of stationary phase, and Fourier transform pairs to <b>derive</b> the <b>point</b> target spectrum. The accuracy of the spectrum is controlled by keeping enough terms in the two series expansions, and is verified with a point target simulation. Index Terms—Bistatic SAR, point target spectrum, SAR simulation, series reversion, synthetic aperture radar (SAR). I...|$|R
