2|19|Public
50|$|Parsed corpora {{are large}} {{databases}} containing detailed <b>grammatical</b> <b>tree</b> structures. One {{of the consequences}} of forming large collections of valuable linguistic data is a pressing need for methods and tools to help researchers and other users make the most of them. So in parallel with the parsing of natural language data, the Survey team have carried out research and development of software tools to help linguists use these corpora. The ICECUP research platform uses an intuitive grammatical query representation called Fuzzy Tree Fragments (FTFs) to search parsed corpora.|$|E
40|$|Existing opinion {{retrieval}} techniques do {{not provide}} contextdependent relevant results. Most of the approaches used by state-ofthe-art techniques are based on frequency of query terms, such that all documents containing query terms are retrieved, regardless of contextual relevance to {{the intent of the}} human seeking the opinion. However, in a particular opinionated document, words could occur in different contexts, yet meet the frequency attached to a certain opinion threshold, thus explicitly creating a bias in overall opinion retrieved. In this paper we propose a sentence-level contextual model for opinion retrieval using <b>grammatical</b> <b>tree</b> derivations and approval voting mechanism. Model evaluation performed between our contextual model, BM 25, and language model shows that the model can be effective for contextual opinion retrieval such as faceted opinion retrieval...|$|E
40|$|A simple left part {{property}} {{for a set}} of <b>grammatical</b> <b>trees</b> is introduced. The class of left part grammars, a subclass of the class of context-free grammars, is defined. It is shown that the set of <b>grammatical</b> <b>trees</b> of a context-free grammar satisfies this left part property if and only if the context-free grammar is a left part grammar. Some properties of leftpart grammars are considered...|$|R
40|$|A {{method is}} {{presented}} for obtaining a simple deterministic pushdown transducer which {{acts as a}} parser for simple chain grammars. It is shown that a simple deterministic grammar can be constructed which covers the simple chain grammar. To obtain both the simple deterministic pushdown transducer and the cover result, {{a new type of}} parse is introduced which differs from the left and right parses which are common for the usual one pass no back-tracking parsing algorithms. For the simple chain grammars this parse, the so-called left part parse, follows from a simple left part property which is satisfied by the <b>grammatical</b> <b>trees</b> of simple chain grammars...|$|R
40|$|With {{syntactically}} annotated corpora {{becoming increasingly}} {{available for a}} variety of languages and <b>grammatical</b> frameworks, <b>tree</b> query tools have proven invaluable to linguists and computer scientists for both data exploration and corpusbased research. We provide a combined engine for tree query (Tregex) and manipulation (Tsurgeon) that can operate on arbitrary tree data structures with no need for preprocessing. Tregex remedies several expressive and implementational limitations of existing query tools, while Tsurgeon is to our knowledge the most expressive tree manipulation utility available. 1...|$|R
40|$|Paradigm {{issues of}} {{syntactic}} pattern recognition {{are presented in}} the chapter. Main open problems are identified and methodological principles are defined with respect to three basic models of this approach. The issues of enhancement of string models' generative power, <b>grammatical</b> inference for <b>tree</b> models, and parsing/induction for graph models are discussed...|$|R
2500|$|... c-command (constituent command) is a {{relationship}} between the nodes of <b>grammatical</b> parse <b>trees.</b> It is closely associated with the phrase structure grammars of the Chomskyan tradition (Government and Binding, Minimalist Program), and may not be valid or applicable to the tree structures of other theories of syntax, such as dependency grammars. The relation of c-command has served as the basis for many explorations and explanations of phenomena of syntax. It has been taken to be the basic configurational relation underlying binding, and has {{played a central role in}} the analysis of diverse syntactic mechanisms, such as parasitic gaps and the scope of quantifiers.|$|R
5000|$|Parsing: (see also: Stochastic grammar) Determine the parse <b>tree</b> (<b>grammatical</b> analysis) {{of a given}} sentence. The grammar {{for natural}} {{languages}} is ambiguous and typical sentences have multiple possible analyses. In fact, perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human).|$|R
50|$|Processes {{related to}} {{functional}} decomposition are prevalent throughout {{the fields of}} knowledge representation and machine learning. Hierarchical model induction techniques such as Logic circuit minimization, decision <b>trees,</b> <b>grammatical</b> inference, hierarchical clustering, and quadtree decomposition are all examples of function decomposition. A review of other applications and function decomposition {{can be found in}} , which also presents methods based on information theory and graph theory.|$|R
40|$|We {{review a}} family of closely related query {{learning}} algorithms for unweighted and weighted tree automata, {{all of which are}} based on adaptations of the minimal adequate teacher (MAT) model by Angluin. Rather than presenting new results, the goal is to discuss these algorithms in sufficient detail to make their similarities and differences transparent to the reader interested in <b>grammatical</b> inference of <b>tree</b> automata...|$|R
40|$|Practical machine {{translation}} {{must be considered}} from a heuristic point of view rather than from a purely rigid analytical linguistic method. An English-into-Japanese translation system named ATHENE based on a Heuristic Parsing Model (HPM) has been developed. The experiment shows some advantageous points such as simplification of transforming and generating phase, semi-localization of multiple meaning resolution, and extendability for future grammatical refinement. HPM-base parsing process, parsed <b>tree,</b> <b>grammatical</b> data representation, and translation results are also described...|$|R
40|$|State-of-art {{systems for}} grammar error {{correction}} often correct errors based on word sequences or phrases. In this paper, we describe a grammar error correction system which corrects <b>grammatical</b> errors at <b>tree</b> level directly. We cluster all error {{into two groups}} and divide our system into two modules correspondingly: the general module and the special module. In the general module, we propose a TreeNode Language Model to correct errors related to verbs and nouns. The TreeNode Lan-guage Model is easy to train and the de-coding is efficient. In the special module, two extra classification models are trained to correct errors related to determiners and prepositions. Experiments show that our system outperforms the state-of-art sys-tems and improves the F 1 score. ...|$|R
40|$|There is {{considerable}} interest among computational linguists in lexicalized <b>grammatical</b> frame-works; lexicalized <b>tree</b> adjoining grammar (LTAG) is one widely studied example. In this paper, we investigate how derivations in LTAG {{can be viewed}} not as manipulations of trees but as manipulations of tree descriptions. Changing the way the lexicalized formalism is viewed raises questions as to the desirability of {{certain aspects of the}} formalism. We present a new formalism, d-tree substitution grammar (DSG). Derivations in DSG involve the composition of d-trees, special kinds of tree descriptions. Trees are read off from derived d-trees. We show how the DSG formalism, which is designed to inherit many of the characterestics of LTAG, can be used to express a variety of linguistic analyses not available in LTAG. 1...|$|R
40|$|Key words Web {{information}} extraction, wrapper induction, <b>grammatical</b> inference, <b>tree</b> automata, monadic queries. Abstract We {{develop new}} algorithms for learning monadic node selection queries in unranked trees from annotated examples, and {{apply them to}} visually interactive Web information extraction. We propose to represent monadic queries by bottom-up deterministic Node Selecting Tree Transducers (Nstts), a particular class of tree automata that we introduce. We prove that deterministic Nstts capture the class of queries definable in monadic second order logic (Mso) in trees, which Gottlob and Koch (2002) argue {{to have the right}} expressiveness for Web information extraction, and prove that monadic queries defined by Nstts can be answered efficiently. We present a new polynomial time algorithm in Rpni-style that learns monadic queries defined by deterministic Nstts from completely annotated examples, where all selected nodes are distinguished. In practice, users prefer to provide partial annotations. We propose to account for partial annotations by intelligent tree pruning heuristics. We introduce pruning Nstts- a formalism that shares many advantages of Nstts. This leads us to an interactive learning algorithm for monadic queries defined by pruning Nstts, which satisfies a new formal active learning model in the style of Angluin (1987). We have implemented our interactive learning algorithm and integrated it into a visually interactive Web information extraction system – called Squirrel – by plugging it into the Mozilla Web browser. Experiments on A previous version of this article was published in Machine Learning 66,...|$|R
40|$|Background: A {{fundamental}} goal {{of human}} genetics is {{the discovery of}} polymorphisms that predict common, complex diseases. It is hypothesized that complex diseases are due to a myriad of factors including environmental exposures and complex genetic risk models, including gene-gene interactions. Such epistatic models present an important analytical challenge, requiring that methods perform not only statistical modeling, but also variable selection to generate testable genetic model hypotheses. This challenge is amplified by recent advances in genotyping technology, {{as the number of}} potential predictor variables is rapidly increasing. Methods: Decision trees are a highly successful, easily interpretable data-mining method that are typically optimized with a hierarchical model building approach, which limits their potential to identify interacting effects. To overcome this limitation, we utilize evolutionary computation, specifically grammatical evolution, to build decision trees to detect and model gene-gene interactions. In the current study, we introduce the <b>Grammatical</b> Evolution Decision <b>Trees</b> (GEDT) method and softwar...|$|R
40|$|This paper {{proposes a}} <b>grammatical</b> tool, called <b>tree</b> adjunct grammar with tag for RNA (denoted by TAG 2 RNA), for {{representing}} secondary structures of RNAs, and shows some example TAG 2 RNA grammars for fairly complicated RNA secondary structures. We then demonstrate {{the appropriateness of}} the grammars for modeling RNA secondary structures by discussing its formal language and/or graph theoretic properties, including closure properties of TAG 2 RNA and graph planarity of secondary structures generated by TAG 2 RNA, the latter of which would provide a biologically reasonable constraint. 1 Introduction Due to the rapid increase of biological knowledge that strongly supports that the structure of nucleotide sequences of RNAs {{plays an important role in}} the splicing process or the translation process of RNAs, it is of great interest to propose a computational model for representing the structure of RNAs or to pursue an efficient method for predicting RNA secondary structural fe [...] ...|$|R
40|$|A {{major goal}} of human {{genetics}} is the discovery and validation of genetic polymorphisms that predict common, complex diseases. It is hypothesized that complex diseases {{are due to}} a myriad of factors including environmental exposures and complex genetic models. This etiological complexity, coupled with rapid advances in genotyping technology present enormous theoretical and practical concerns for statistical and computational analysis. Specifically, the challenge presented by epistasis, or gene-gene interactions, has sparked {{the development of a}} multitude of statistical techniques over the years. Subsequently, pattern matching and machine learning approaches have been explored to overcome the limitations of traditional computational methods. Grammatical Evolution Neural Networks (GENN) uses grammatical evolution to optimize neural network architectures and better detect and analyze gene-gene interactions. Motivated by good results shown by GENN to identify epistasis in complex datasets, we have developed a new method of <b>Grammatical</b> Evolution Decision <b>Trees</b> (GEDT). GEDT replaces the black-box approach of neural networks with the white-box approach of decision trees improving understandability and interpretability. We provide a detailed technical understanding of coupling Grammatical Evolution wit...|$|R
40|$|AbstractGrammatical {{codes of}} trees provide {{a way to}} encode ordered trees into strings over a finite {{alphabet}} {{in such a way}} that the length of each code-word is precisely the number of leaves of the coded tree. Such codes are grammatical because they result by applying production rules of a grammar G to a tree t which becomes then a derivation tree t′ in G and the yeild of this derivation tree t′ becomes the code-word for t. Grammatical codes were investigated in [2, 3], see also [1]. In this note we present two topics related to binary grammatical codes. The first topic (see Section 2) is grammatical codes of binary trees with a minimal code alphabet. It is shown that the only binary codes that are minimal in this sense are the so-called “strict” binary codes (as considered in [3]). The second topic (see Section 3) concerns the extension of binary grammatical codes to <b>grammatical</b> codes for <b>trees</b> of arbitrary degree. We make comparisons between classes of codes obtained in this way and the classes from [2, 3]. In Section 1 we recall (from [2, 3]) some notions and results concerning grammatical codes...|$|R
40|$|Abstract Background A {{fundamental}} goal {{of human}} genetics is {{the discovery of}} polymorphisms that predict common, complex diseases. It is hypothesized that complex diseases are due to a myriad of factors including environmental exposures and complex genetic risk models, including gene-gene interactions. Such epistatic models present an important analytical challenge, requiring that methods perform not only statistical modeling, but also variable selection to generate testable genetic model hypotheses. This challenge is amplified by recent advances in genotyping technology, {{as the number of}} potential predictor variables is rapidly increasing. Methods Decision trees are a highly successful, easily interpretable data-mining method that are typically optimized with a hierarchical model building approach, which limits their potential to identify interacting effects. To overcome this limitation, we utilize evolutionary computation, specifically grammatical evolution, to build decision trees to detect and model gene-gene interactions. In the current study, we introduce the <b>Grammatical</b> Evolution Decision <b>Trees</b> (GEDT) method and software and evaluate this approach on simulated data representing gene-gene interaction models of a range of effect sizes. We compare the performance of the method to a traditional decision tree algorithm and a random search approach and demonstrate the improved performance of the method to detect purely epistatic interactions. Results The results of our simulations demonstrate that GEDT has high power to detect even very moderate genetic risk models. GEDT has high power to detect interactions with and without main effects. Conclusions GEDT, while still in its initial stages of development, is a promising new approach for identifying gene-gene interactions in genetic association studies. </p...|$|R

