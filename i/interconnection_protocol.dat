14|58|Public
50|$|DIXIE is an {{obsolete}} {{protocol for}} accessing X.500 directory services. DIXIE {{was intended to}} provide a lightweightmeans for clients to access X.500 directory services. DIXIE allowed TCP/IP clients to connect a DIXIE-to-DAP gateway which would provide access to the X.500 Directory Service. This design allows the client to access the directory without requiring it to support the cumbersome Open Systems <b>Interconnection</b> <b>protocol</b> stack.|$|E
50|$|In 1991, Argentina and Chile {{concluded}} the Gas <b>Interconnection</b> <b>Protocol.</b> For {{the implementation of}} this protocol several pipeline projects were proposed. The GasAndes Pipeline project was proposed by the consortium of NOVA Corporation of Canada, Chilean companies Gasco and Gener, and Argentine companies Compañía General de Combustibles and Techint Compañía Ténica Internacional. The feasibility study of the pipeline was concluded in 1994. The pipeline was commissioned in 1997.|$|E
50|$|The Directory Assistance Service (DAS) is an {{obsolete}} {{protocol and}} service for accessing X.500 directory services. DAS {{was intended to}} provide a lightweightmeans for clients to access X.500 directory services via a split-Directory User Agent model. Here the Directory User Agent (DUA) (the directory client) is split into a Directory Assistance (DA) client and a Directory Assistant. The directory user would interact with the DA-client, the DA-Client would communicate with the Directory Assistant using the DA protocol, and the Directory Assistant would communicate with the Directory Service using the X.500 Directory Access Protocol (DAP). That is, the Directory Assistant is a Directory Assistance protocol to DAP gateway. This design allows the DA-client to access the directory without requiring it to support the cumbersome Open Systems <b>Interconnection</b> <b>protocol</b> stack.|$|E
50|$|In 1990-1992, Mohen was a {{committee}} member for setting standards for Open Systems <b>Interconnections</b> <b>Protocols,</b> {{with representatives from}} computer and telecommunications organizations from around the world.|$|R
5000|$|The Open Systems <b>Interconnection</b> <b>protocols</b> are {{a family}} of {{information}} exchange standards developed jointly by the ISO and the ITU-T. The standardization process began in 1977.|$|R
50|$|Because the Open Systems <b>Interconnection</b> <b>protocols</b> are {{challenging}} to implement, the original MMS stack never became popular. In 1999, Boeing {{created a new}} version of MMS using Internet protocols instead of the bottom four layers of the original stack plus RFC 1006 ("ISO Transport over TCP") in the transport layer. The top three layers use the same OSI protocols as before.|$|R
40|$|Abstract: This paper {{describes}} {{a system that}} helps HCI practitioners and researchers manage and conduct experiments involving context-sensitive handheld applications, particularly related to navigation assistance. The system provides a software framework in which application, user interface and interaction monitoring components can be plugged, offering a simple <b>interconnection</b> <b>protocol</b> and minimising the programming overheads of implementation. We have focused our attention on dealing with the challenges presented by the limited memory and processing of handheld devices and the variety of data sources for mobile context-sensitive applications. In this paper we give {{an overview of the}} system’s functionality and architecture, discuss key challenges of supporting field-based experiments on handhelds and consider further developments of the system. Key words: evaluation of user interfaces and tools, mobile applications, usage monitoring 1...|$|E
40|$|Service Level Agreement between Interconnecting Wireless Service Providers and {{charging}} {{should be in}} collaboration with the resource allocation and QoS together with the usage of an <b>interconnection</b> <b>protocol</b> and a database to store the Users ’ Parameters information needed for the charging / pricing as well as the authentication and the authorization of the end user. Cost Estimation depends on two major factors: The resources availability and the technology factors. This paper discusses SLA factors that should be defined in order {{to take advantage of the}} interconnection of the wireless networks in a cost effective way from the telecom provider’s part as well as the mobile user part. In addition reviews various pricing {{and charging}} methods that are used these days by several Wireless Service Providers...|$|E
40|$|Rapid {{progress}} {{in research and}} development of wireless networking and communication technologies has created different types of wireless systems (e. g., Bluetooth, IEEE 802. 11, UMTS, and satellite networks). These systems are envisioned to coordinate with each other to provide ubiquitous high-datarate services to mobile users. In this article a novel architecture, Architecture for Ubiquitous Mobile Communications (AMC), is introduced that integrates these heterogeneous wireless systems. AMC eliminates the need for direct service level agreements among service providers by using a third party, a network interoperating agent. Instead of deploying a totally new infrastructure, AMC extends the existing infrastructure to integrate heterogeneous wireless systems. It uses IP as the <b>interconnection</b> <b>protocol.</b> By using IP as the gluing protocol, transparency to the heterogeneities of the individual systems is achieved in AMC. Third-party-based authentication and billing algorithms are designed for AMC. New mobility management protocols are also developed to support seamless roaming between different wireless systems...|$|E
50|$|Data General's {{proprietary}} networking architecture {{was known}} as Xodiac. Data General software packages supporting Xodiac included Comprehensive Electronic Office (CEO). In 1987, Data General announced its intention to replace Xodiac with the Open Systems <b>Interconnection</b> (OSI) <b>protocol</b> suite.|$|R
40|$|The main {{elements}} and requirements of advanced space data networks are identified. The communication protocol {{standards for use}} on space missions during the coming decades are described. In particular, the blending of high-performance space-unique data transmission techniques with off-the-shelf open systems <b>interconnection</b> (OSI) <b>protocols</b> is described...|$|R
50|$|Despite clear primary {{references}} and normative standards documents, the internet layer is often improperly called network layer. This is done because the internet {{layer of the}} TCP/IP model is easily compared directly with the network layer (layer 3) in the Open Systems <b>Interconnection</b> (OSI) <b>protocol</b> stack.|$|R
40|$|Abstract—Wireless Sensor Networks (WSNs) are at {{high speed}} gaining in popularity. Because of this {{increased}} adoption, the need for integration with existing technologies becomes more prominent. In practice, a WSN is often deployed in environments where both wired and wireless data networks are also present. Consider for instance a WSN which acts as a climate monitoring or fire detection system in a large office building. As WSNs are typically networks with high constraints regarding resource efficiency, it would be beneficial if they could use the available data networks as additional transport medium for their internal data. In this paper we describe an <b>interconnection</b> <b>protocol</b> and associated sensor gateway design which enables the transparent use of both wired and wireless data networks by WSNs. Through this setup, the WSN will detect the non-sensor devices as virtual sensor nodes and consider them when determining the optimal routing paths. Index Terms—gateway design, integration, internet protocol, protocol architecture, wireless sensor network...|$|E
40|$|The National Center for Biotechnology Information (NCBI) {{has created}} a {{database}} collection that includes several protein and nucleic acid sequence databases, a biosequencespecific subset of MEDLINE, as well as value-added information such as links between similar sequences. Information in the NCBI database is modeled in Abstract Syntax Notation 1 (ASN. 1), an Open Systems <b>Interconnection</b> <b>protocol</b> designed {{for the purpose of}} exchanging structured data between software applications rather than as a data model for database systems (ISO, 1987 a, ISO, 1987 b). While the NCBI database is distibuted with an easyto -use information retrieval system, Entrez, the ASN. 1 data model currently lacks an ad hoc query language for general purpose data access. For that reason, we have developed a software package, Sortez, that transforms the ASN. 1 database (or other databases with nested data structures) to a relational data model and subsequently to a relational database management system (Sybase) where i [...] ...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis {{provides an overview}} of the Defense Message System (DMS) and the messaging related components of the Coast Guard Telecommunications System (CGTS). Also addressed are the seven-layer Open Systems Interface (OSI) Reference Model, the Government Open System <b>Interconnection</b> <b>Protocol,</b> and various interface devices such as bridges, routers and gateways. The DMS Program is composed of a baseline architecture and three phases that will result in the transition from baseline systems and networks to a target architecture, with a goal for complete writer-to-reader messaging services. DMS baseline components, such as the Automatic Digital Network and components of the Defense Data Network, will either be phased out or transitioned into new architectures that will lead to the target architecture. The Coast Guard telecommunications organization is addressed as well as the broad aspects of the CGTS. A key issue of this thesis is to emphasize the importance of interoperability between the DMS and the CGTS through the use of approved standards and protocols. [URL] Commander, United States Coast Guar...|$|E
40|$|In {{order to}} achieve higher levels of {{abstraction}} in architectural design, we investigate extensions to parallel program design based {{on the use of}} explicit state variables to accommodate the action-based discipline of interaction that is typical of architecture description languages. Our study focus on primitives that support non-determinism, choice and fairness in guarded-command based languages, and on refinement principles that are compositional with respect to interconnection. 1 Introduction Formal approaches for describing software architectures tend to use process-based languages. Typical examples are the architecture description languages WRIGHT [2], based on CSP, Darwin [16], based on the p-calculus, and Rapide [15], based on partially ordered sets of events. The fact that software architectures address the structure of systems in terms of components and <b>interconnection</b> <b>protocols</b> between them suggests the adoption of formalisms in which interaction is event-based. For [...] ...|$|R
40|$|The work is {{concerned}} with the distributed information-computer systems (DICS). The aim of the work is to solve the problems of developing tools for computer-aided design of optimum structure in the self-diagnosed DICS. The cluster theoretical-graph model of DICS diagnostics has been improved and investigated. The characterization problem of test ability property for given level of the DICS structure has been solved. The optimum clusterization method on base of which the optimum structure of DICS is constructed has been developed. The DICS <b>interconnection</b> <b>protocols</b> providing the correct operation of system in the failure conditions have been developed. The tools of designing optimum structure have been made on base of the proposed method. The investigation results have been introduced into the practice of DICS design and support at the industrial enterprise. Application field: integrated computer systemsAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
50|$|A DCS {{typically}} uses custom-designed processors as controllers, {{and uses}} either proprietary <b>interconnections</b> or standard <b>protocols</b> for communication.Input and output modules form the peripheral {{components of the}} system.|$|R
40|$|As {{information}} technologies evolve, computing environments become more distributed and heterogeneous. More and more software applications written in different programming languages running on different platforms with different operating systems {{are required to}} {{communicate with one another}} over different computer networks. Conflicts resulting from having heterogeneous and distributed computing environments require strategies for software interoperability. The emerging middleware technologies, including CORBA, COM/DCOM,. NET, J 2 EE, and Enterprise JavaBeans offer an industrial defacto standard communication infrastructure to support the interoperability of heterogeneous applications in components. However, the implementation of a component suffers from high interaction complexities in the component that seriously degrades the application independence. Software components should be built to be independent of the context in which they are used, allowing them to be reused in many different computing environments. In this paper, we are presenting an adapter in the Adapter Layer of an <b>interconnection</b> <b>protocol</b> model to isolate, encapsulate, and manage a component’s interactions outside the component. The dynamic interface binding was designed to allow the adapter to examine the signature of the requested services at runtime such as operation names, parameter orders, parameter types, and parameter sizes. In addition, the interface language mapping allows an interface in a specific programming language to be automatically generated from an IDL interface. The use of adapters increases the reusability of components and also simplifies the integration of the components to an application...|$|E
40|$|In {{the next}} years, {{the market for}} low value online content, like music and videos, is {{expected}} to grow substantially. To allow "pay-per-use" of such content, micropayment systems are expected to play an important role. Since there are already many competing micropayment systems on the market, customers and merchants are forced to use multiple systems. To overcome the problems associated with using multiple systems (e. g., learn the usage of several systems, manage multiple accounts and e-wallets, remember multiple passwords, trust different micropayment system operators), in this thesis, we propose a hybrid payment system that allows customers and merchants to use their micropayment system of choice, while still being able to pay each other in a seamless manner regardless the choice of the other party. The core component of our system is the Payment Gateway, which is responsible for interconnecting the existing (and future) micropayment systems. To become successful, such a system needs to have global acceptance and penetration, a high micropayment volume, high trust level and secure money transfer. The main objective of this thesis is to develop an architecture of the hybrid payment system. To solve the micropayment system interconnection problem, we propose a generic and systematic interconnection method for existing micropayment systems. This method is to harmonize the payment services of existing systems to a uniform level, called the uniform payment service, and interconnect these uniform payment services. We call a system that provides the uniform payment service a uniform payment system. Using this method, the number of mapping rules and the amount of information that must be stored will remain limited, which makes this method scalable and the design and realization of the Payment Gateways will become much easier. A prerequisite for this method is that the harmonization of existing (and future) micropayment systems to the uniform payment service is possible. We will define the uniform payment service such {{that the vast majority of}} existing payment systems can comply with this service without changing their functionality. We will also prove this fact by presenting two case studies. The compliance of current payment systems with the uniform payment service also means that they can be interconnected without changing their functionality. The uniform payment service could guide the design of future electronic payment systems such that new systems can be interconnected easily with existing systems. In this way, the uniform payment service, possibly extended with interactions that have only local significance, could become a de facto standard for micropayment systems. On top of the uniform payment systems, we design a hybrid payment (or <b>interconnection)</b> <b>protocol.</b> This protocol bridges the gap between the hybrid and uniform payment services. This protocol will be designed such that (1) the threats for the normal operation and security of the protocol are not considerably bigger than that of the existing systems, (2) hardly any money loss situations will occur, (3) commonly used security techniques can be employed to secure the interactions between the various components of the hybrid payment systems, and (4) that the protocol will be optimized in case no interconnection is needed. This thesis begins with presenting the research context, problem definition, possible solutions, objective, related research questions and approach followed (Chapter 1). We start our research with studying the payment function within the context of (product) accounting (Chapter 2). We then analyse the structure and functionality of existing electronic payment systems, identify the business roles within these systems, define their main functional characteristics and present an overview of these systems (Chapter 3). Afterwards, the requirements for the hybrid payment system will be derived from the viewpoints of end-users (customer and merchant), stakeholders (operators of micropayment systems and Payment Gateways), legal and regulatory frameworks (Chapter 4). The main functional characteristics of existing payment systems and the requirements will guide the design of the hybrid payment system. The design will be structured in three phases: (1) formulate the functional requirements for the hybrid system, (2) design the hybrid payment service, (3) discuss the most suitable interconnection method and design the <b>interconnection</b> <b>protocol</b> (Chapter 5 and Chapter 6). The uniform payment systems and <b>interconnection</b> <b>protocol</b> will be demonstrated to be implementable, which implies that an implementation of the hybrid payment system is achievable. Besides this demonstration, the design of the hybrid payment system will be evaluated to verify whether the hard requirements from Chapter 4 are satisfied (Chapter 7). Finally, the conclusions of our work will be drawn and some research topics for future work will be formulated (Chapter 8) ...|$|E
40|$|This paper {{describes}} the Flexible <b>Interconnection</b> <b>Protocol,</b> or FLIP, whose main {{goal is to}} allow interconnection of heterogeneous devices with varying power, processing, and communication capabilities, ranging from simple sensors to more powerful computing devices such as laptops and desktops. The vision is that FLIP {{will be used to}} interconnect such devices forming clouds in the farthest branches/leaves of the Internet, while still providing connectivity with the existing IP-based Internet infrastructure. Through its flexible, customizable headers FLIP integrates just the functions required by a given application and that can be handled by the underlying device. Simple devices like sensors will benefit from incurring close to optimal overhead saving not only bandwidth, but, more importantly, energy. More sophisticated devices in the cloud can be responsible for implementing more complex functions like reliable/ordered data delivery, communication with other device clouds and with the IP infrastructure. FLIP is designed to provide a basic substrate on which to build network- and transport-level functionality. In heterogeneous environments, FLIP allows devices with varying capabilities to coexist and interoperate under the same network infrastructure. We present the basic design of FLIP and describe its implementation under Linux. We also report on FLIP’s performance when providing IPv 4 and IPv 6 as well as transport-layer functionality a la TCP and UDP. We show FLIP’s energy efficiency in different sensor network scenarios. For example, we use FLIP to implement the directed diffusion communication paradigm and obtain an improvement of 50 % in energy savings over an existing directed diffusion implementation. Finally, we showcase FLIP’s flexibility by demonstrating its ability to incorporate new protocol function...|$|E
5000|$|... By open {{standard}} is understood any communication, <b>interconnection</b> or interchange <b>protocol,</b> and any interoperable data format whose specifications are public {{and without any}} restriction in their access or implementation.|$|R
50|$|X.500 {{directory}} {{services were}} traditionally accessed via the X.500 Directory Access Protocol (DAP), which required the Open Systems <b>Interconnection</b> (OSI) <b>protocol</b> stack. LDAP was {{originally intended to}} be a lightweight alternative protocol for accessing X.500 directory services through the simpler (and now widespread) TCP/IP protocol stack. This model of directory access was borrowed from the DIXIE and Directory Assistance Service protocols.|$|R
5000|$|... 1990 - The US {{specification}} requiring Open Systems <b>Interconnection</b> (OSI) <b>protocols</b> {{was first}} published as Federal Information Processing Standards document FIPS 146-1. The requirement for US Government vendors to demonstrate their support for this profile led them to join the formal interoperability and conformance testing for networking products, which had been done by industry professionals at the annual InterOp show since 1980.|$|R
40|$|Institute for Computing Systems ArchitectureRAID systems (Redundant Arrays of Inexpensive Disks) have {{dominated}} backend storage systems {{for more than}} two decades and have grown continuously in size and complexity. Currently they face unprecedented challenges from data intensive applications such as image processing, transaction processing and data warehousing. As the size of RAID systems increases, designers are faced with both performance and reliability challenges. These challenges include limited back-end network bandwidth, physical interconnect failures, correlated disk failures and long disk reconstruction time. This thesis studies the scalability of RAID systems in terms of both performance and reliability through simulation, using a discrete event driven simulator for RAID systems (SIMRAID) developed as part of this project. SIMRAID incorporates two benchmark workload generators, based on the SPC- 1 and Iometer benchmark specifications. Each component of SIMRAID is highly parameterised, enabling it to explore a large design space. To improve the simulation speed, SIMRAID develops a set of abstraction techniques to extract the behaviour of the <b>interconnection</b> <b>protocol</b> without losing accuracy. Finally, to meet the technology trend toward heterogeneous storage architectures, SIMRAID develops a framework that allows easy modelling of different types of device and interconnection technique. Simulation experiments were first carried out on performance aspects of scalability. They were designed to answer two questions: (1) given a number of disks, which factors affect back-end network bandwidth requirements; (2) given an interconnection network, how many disks can be connected to the system. The results show that the bandwidth requirement per disk is primarily determined by workload features and stripe unit size (a smaller stripe unit size has better scalability than a larger one), with cache size and RAID algorithm having very little effect on this value. The maximum number of disks is limited, as would be expected, by the back-end network bandwidth. Studies of reliability have led to three proposals to improve the reliability and scalability of RAID systems. Firstly, a novel data layout called PCDSDF is proposed. PCDSDF combines the advantages of orthogonal data layouts and parity declustering data layouts, so that it can not only survivemultiple disk failures caused by physical interconnect failures or correlated disk failures, but also has a good degraded and rebuild performance. The generating process of PCDSDF is deterministic and time-efficient. The number of stripes per rotation (namely the number of stripes to achieve rebuild workload balance) is small. Analysis shows that the PCDSDF data layout can significantly improve the system reliability. Simulations performed on SIMRAID confirm the good performance of PCDSDF, which is comparable to other parity declustering data layouts, such as RELPR. Secondly, a system architecture and rebuilding mechanism have been designed, aimed at fast disk reconstruction. This architecture is based on parity declustering data layouts and a disk-oriented reconstruction algorithm. It uses stripe groups instead of stripes as the basic distribution unit so that it can make use of the sequential nature of the rebuilding workload. The design space of system factors such as parity declustering ratio, chunk size, private buffer size of surviving disks and free buffer size are explored to provide guidelines for storage system design. Thirdly, an efficient distributed hot spare allocation and assignment algorithm for general parity declustering data layouts has been developed. This algorithm avoids conflict problems in the process of assigning distributed spare space for the units on the failed disk. Simulation results show that it effectively solves the write bottleneck problem and, at the same time, there is only a small increase in the average response time to user requests...|$|E
25|$|He {{earned his}} Ph.D. from UCLA in 1972. At UCLA {{he worked in}} Professor Leonard Kleinrock's {{networking}} group that connected the first two nodes of the ARPANET {{and contributed to the}} ARPANET host-to-host protocol. Cerf was an assistant professor at Stanford University from 1972–1976, where he conducted research on packet network <b>interconnection</b> <b>protocols</b> and co-designed the DoD TCP/IP protocol suite with Bob Kahn. He was a program manager for the Advanced Research Projects Agency (ARPA) from 1976 to 1982. Cerf was instrumental in the formation of both the Internet Society and Internet Corporation for Assigned Names and Numbers (ICANN), serving as founding president of the Internet Society from 1992–1995 and in 1999 as Chairman of the Board and as ICANN Chairman from 2000 to 2007. His many awards include the National Medal of Technology, the Turing Award, the Presidential Medal of Freedom, and membership in the National Academy of Engineering and the Internet Society's Internet Hall of Fame.|$|R
5000|$|XNS {{also helped}} to {{validate}} {{the design of the}} 4.2BSD network subsystem by providing a second protocol suite, one which was significantly different from the Internet protocols; by implementing both stacks in the same kernel, Berkeley researchers demonstrated that the design was suitable for more than just IP. [...] Additional BSD modifications were eventually necessary to support the full range of Open Systems <b>Interconnection</b> (OSI) <b>protocols.</b>|$|R
5000|$|The cross-layer network {{architecture}} of CN in is also named as Embedded Wireless Interconnection (EWI) {{as opposed to}} Open System <b>Interconnection</b> (OSI) <b>protocol</b> stack. The CN architecture {{is based on a}} new definition of wireless linkage. The new abstract wireless links are redefined as arbitrary mutual co-operations among a set of neighboring (proximity) wireless nodes. In comparison, traditional wireless networking relies on point-to-point [...] "virtual wired-links" [...] with a predetermined pair of wireless nodes and allotted spectrum.|$|R
40|$|Abstract—Tactical {{military}} networks require efficient interop-eration. This {{is critical}} in multiple coalition deployments where mission coordination relies on intercommunications. This is also a major challenge since different coalitions may operate with heterogeneous <b>protocols.</b> The existing <b>interconnection</b> <b>protocols</b> designed for the Internet (e. g., BGP) are not adequate for mobile MANETs. In this paper, we present a novel Inter-MANET Routing solution called InterMR {{which is designed to}} withstand coalition deployment challenges. The first contribution offered by InterMR is an Inter-MANET address scheme based on a generalized node naming scheme (e. g., symbolic name, property, etc.) rather than strictly the traditional IP address; this allows dynamic merge/split of MANETs and also removes the need for a centralized Name Server. Our second contribution is to provide a seamless routing mechanism across heterogeneous MANETs without modifying the internal routing mechanisms in each MANET. The third contribution is efficient, transparent adap-tation to MANET topology changes by dynamically assigning the gateway functionalities. We show by packet-level simulation, that the performance of InterMR can be improved by as much as 195 % using adaptive gateway assignment. We show by analysis that the control O/H is modest, making InterMR quite scalable to large tactical interconnects. I...|$|R
40|$|Abstract—The advancements {{of diverse}} radio {{technologies}} and emerging applications have spawned increasing heterogeneity in mobile ad hoc networks (MANETs). But the collaborative nature of communications and operations often requires that these heterogeneous MANETs to be interoperable. Nonetheless, the ex-isting <b>interconnection</b> <b>protocols</b> {{designed for the}} Internet (namely inter-domain routing protocol such as BGP) are not adequate for handling the unique challenges in MANETs. In this paper, we present a novel Inter-MANET Routing protocol called InterMR that can handle the heterogeneity and dynamics of MANETs. Our first contribution is an Inter-MANET address scheme based {{on a variety of}} node attributes (e. g., symbolic name, property, etc.); this allows dynamic merging/split of network topologies without a separate Name Server. Our second contribution is to provide a seamless routing mechanism across heterogeneous MANETs without modifying the internal routing mechanisms in each MANET. The proposed scheme can transparently adapt to topological changes due to node mobility in MANETs by dynamically assigning the gateway functionalities. We show, by packet-level simulation, that the performance of InterMR can be improved by up to 112 % by adaptive gateway assignment functionalities. We also show that InterMR is scalable with only modest overhead by analysis. I...|$|R
40|$|Abstract: Due to {{the usage}} of MANETs and some kinds of {{collaborative}} applications (P 2 P), current distributed systems are becoming increasingly dynamic; i. e., {{it is difficult to}} manage membership information and to forecast the accessibility of each system node. Moreover, dependable applications for static distributed systems also need to provide good adaptability levels (to different request arrival rates, usage patterns, classes of requests, [...] .) and good scalability; a case to study is the cloud computing paradigm. Development of dependable applications in dynamic and adaptive systems is not trivial, since both dynamism and adaptability may compromise algorithm liveness or may complicate the design of such algorithms, specially those best suited for static systems. Strate-gies for building adaptable and scalable dependable services (based on “cloud systems”) will be surveyed and improved. Moreover, an efficient support for dependable applications in dynamic systems will be provided, combining three different approaches: relaxed consistency models, <b>interconnection</b> <b>protocols</b> (for supporting both consistency and multicasting) and reconciliation strategies. Last but not least, also the usage and support for integrity constraints in replicated systems will be analyzed and improved for dynamic systems. ...|$|R
40|$|Catalog Description: Basic {{concepts}} of signals and information transmission. Fundamental features of transmission channels. Switching techniques for computer communication. Frequency and {{time division multiplexing}} for communication networks. Code division multiple access (CDMA) technique. Modulation, modems, and error detection. Types of transmission media. Wireless communication technology. ATM technology. Basic Reference Model of Open Systems <b>Interconnection.</b> TCP/IP <b>protocol</b> family. Internet core protocols. Routing of datagrams in the Internet. Basic services of Internet. Local Area Networks (LANs). Fundamentals of Ethernet LANs. Wireless LANs. Wireless ATM. New trends in computer communication and computer networks. (Pre-requisite: CMPE 343...|$|R
40|$|Today’s Aeronautical Telecommunications Network (ATN), {{which is}} based on the Open Systems <b>Interconnection</b> (OSI) <b>protocol</b> standard, is lagging behind in {{technology}} as there is lack of support for it from the industry. This aspect of ATN brings about cost and upgrade related issues. These issues have motivated the aviation industry to consider the next generation networking standard i. e. IPv 6 as a possible means for ATN communications. With the possible advent of IPv 6 various services and issues arise, which needs to be considered. This paper describes some of these services and issues based on tests carried out on a...|$|R
5000|$|ISO/IEC 8073/ITU-T Recommendation X.224, [...] "Information Technology - Open Systems <b>Interconnection</b> - <b>Protocol</b> for {{providing}} the connection-mode transport service", defines five classes of connection-mode transport protocols designated class 0 (TP0) to class 4 (TP4). Class 0 contains no error recovery, and {{was designed for}} use on network layers that provide error-free connections. Class 4 is closest to TCP, although TCP contains functions, such as the graceful close, which OSI assigns to the session layer. All OSI connection-mode protocol classes provide expedited data and preservation of record boundaries. Detailed characteristics of the classes are shown in the following table: ...|$|R
50|$|In {{computer}} networking, {{the transport}} layer is a conceptual division of methods in the layered architecture of protocols {{in the network}} stack in the Internet Protocol Suite and the Open Systems <b>Interconnection</b> (OSI). The <b>protocols</b> of the layer provide host-to-host communication services for applications. It provides services such as connection-oriented data stream support, reliability, flow control, and multiplexing.|$|R
40|$|Digital {{commodities}} {{are delivered}} worldwide through a Global Supply Chain Network of providers. These are usually interconnected via Local Supply Chain Networks, based around Internet Exchange Points, the physical places where most digital exchanges take place. Providers compete both {{for business and}} final customers, while cooperating the exchanges of information flows composing the digital commodities, to provide a complete, end to end, service to final users. A myriad of interconnection decisions form the connectivity's architecture of this Global Supply Chain Network, designing {{the rules of the}} business game played by the operators. This paper, using a dataset of <b>interconnection</b> <b>protocols</b> over 195 Internet Exchange Points across the World, focuses on the relationship between a provider's connectivity and clustering: the mutual connectivity among the operators this provider is connected to. The strategic relevance of this relationship between connectivity and clustering is clear: the better connected a provider is, the easier it is to deliver the digital commodities with high quality and low costs and, when the neighbours of a provider are less interconnected among themselves, it is easier, for the provider, to exert its bargaining power over them. We estimate an econometric model finding that the continental location of an Internet Exchange Point has a significant effect on the sign of the elasticity between clustering and connectivity. This indicates that Local Supply Chain Networks display significant differences in their clusters of integration, hierarchical organization and complexity, depending on whether they are based in Europe, North America or Rest of the World...|$|R
