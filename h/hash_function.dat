3401|2325|Public
5|$|Linear probing {{can provide}} high {{performance}} {{because of its}} good locality of reference, but is {{more sensitive to the}} quality of its <b>hash</b> <b>function</b> than some other collision resolution schemes. It takes constant expected time per search, insertion, or deletion when implemented using a random <b>hash</b> <b>function,</b> a 5-independent <b>hash</b> <b>function,</b> or tabulation hashing. However, good results can be achieved in practice with other hash functions such as MurmurHash.|$|E
5|$|Because linear probing is {{especially}} sensitive to unevenly distributed hash values, {{it is important}} to combine it with a high-quality <b>hash</b> <b>function</b> that does not produce such irregularities.|$|E
5|$|Along with {{quadratic}} probing {{and double}} hashing, linear probing {{is a form}} of open addressing. In these schemes, each cell of a hash table stores a single key–value pair. When the <b>hash</b> <b>function</b> causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there. Lookups are performed in the same way, by searching the table sequentially starting at the position given by the <b>hash</b> <b>function,</b> until finding a cell with a matching key or an empty cell.|$|E
40|$|Polynomial <b>hash</b> <b>functions</b> {{are well}} studied and {{widely used in}} various applications. They have gained {{popularity}} because of certain performances they exhibit. It {{has been shown that}} even linear <b>hash</b> <b>functions</b> are expected to have such performances. However, quite often we would like the <b>hash</b> <b>functions</b> to be reliable, meaning that they perform well with high probability; for some certain important properties even higher degree polynomials were not known to be reliable. We show that for certain important properties linear <b>hash</b> <b>functions</b> are not reliable. We give indication that quadratic <b>hash</b> <b>functions</b> might not be reliable. On the positive side, we prove that cubic <b>hash</b> <b>functions</b> are reliable. In a more general setting, we show that higher degree of the polynomial <b>hash</b> <b>functions</b> translates into higher reliability. We also introduce a new class of <b>hash</b> <b>functions,</b> which enables to reduce the universe size in an efficient and simple manner. The reliability results and the new class of <b>hash</b> <b>functions</b> are used for some fundamental applications: improved and simplified reliable algorithms for perfect <b>hash</b> <b>functions</b> and real-time dictionaries, which use significantly less random bits, and tighter upper bound for the program size of perfect <b>hash</b> <b>functions...</b>|$|R
5000|$|... 2-choice hashing {{utilizes}} two <b>hash</b> <b>functions</b> h1(x) and h2(x) which work as <b>hash</b> <b>functions</b> {{are expected}} to work (i.e. mapping integers from the universe into a specified range). The two <b>hash</b> <b>functions</b> should be independent and have no correlation to each other. Having two <b>hash</b> <b>functions</b> allows any integer x to have up to two potential locations to be stored based on {{the values of the}} respective outputs, h1(x) and h2(x). It is important to note that, although there are two <b>hash</b> <b>functions,</b> there is only one table; both <b>hash</b> <b>functions</b> map to locations on that table.|$|R
40|$|Perceptual <b>hash</b> <b>functions</b> {{have been}} {{recently}} proposed as cryptographic primitives for multimedia security applications. However, {{many of these}} <b>hash</b> <b>functions</b> have been designed with signal processing robustness issues and have not addressed the key issues of confusion and diffusion that {{are central to the}} security of conventional <b>hash</b> <b>functions.</b> In this paper we give a definition for confusion and diffusion for perceptual <b>hash</b> <b>functions</b> and show how many common perceptual <b>hash</b> <b>functions</b> do not display desirable confusion/diffusion properties...|$|R
5|$|Linear probing {{provides}} good locality of reference, {{which causes}} it to require few uncached memory accesses per operation. Because of this, for low to moderate load factors, {{it can provide}} very high performance. However, compared to some other open addressing strategies, its performance degrades more quickly at high load factors because of primary clustering, a tendency for one collision to cause more nearby collisions. Additionally, achieving good performance with this method requires a higher-quality <b>hash</b> <b>function</b> than for some other collision resolution schemes. When used with low-quality hash functions that fail to eliminate nonuniformities in the input distribution, linear probing can be slower than other open-addressing strategies such as double hashing, which probes a sequence of cells whose separation is determined by a second <b>hash</b> <b>function,</b> or quadratic probing, where the size of each step varies depending on its position within the probe sequence.|$|E
5|$|For {{implementing}} associative arrays, hash tables, a {{data structure}} that maps keys to records using a <b>hash</b> <b>function,</b> are generally faster than binary search on a sorted array of records; most implementations require only amortized constant time on average. However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, {{as the only}} information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. In addition, all operations possible on a sorted array can be performed—such as finding the smallest and largest key and performing range searches.|$|E
5|$|Another {{method of}} {{constructing}} hash functions with both high quality and practical speed is tabulation hashing. In this method, the hash value for a key {{is computed by}} using each byte of the key as an index into a table of random numbers (with a different table for each byte position). The numbers from those table cells are then combined by a bitwise exclusive or operation. Hash functions constructed this way are only 3-independent. Nevertheless, linear probing using these hash functions takes constant expected time per operation. Both tabulation hashing and standard methods for generating 5-independent hash functions are limited to keys that have a fixed number of bits. To handle strings or other types of variable-length keys, {{it is possible to}} compose a simpler universal hashing technique that maps the keys to intermediate values and a higher quality (5-independent or tabulation) <b>hash</b> <b>function</b> that maps the intermediate values to hash table indices.|$|E
40|$|Abstract. Cryptographic <b>hash</b> <b>functions</b> are an {{important}} building block {{for a wide range}} of applications such as digital signatures. In this paper, we give an overview of cryptographic hash functions; classification, definitions, and their basic security. We give special emphasis on cryptographic dedicated <b>hash</b> <b>functions</b> with summarizing the recent attacks on MD 5 and SHA- 1. Finally, we discuss the design and security of the <b>hash</b> <b>functions</b> SHA-family. Key words and phrases: <b>hash</b> <b>functions,</b> digital signature, dedicated <b>hash</b> <b>functions</b> 1...|$|R
5000|$|Knapsack-based <b>hash</b> <b>functions</b> - A {{family of}} <b>hash</b> <b>functions</b> {{based on the}} Knapsack problem.|$|R
40|$|Dedicated <b>hash</b> <b>functions</b> are cryptographically secure {{compression}} functions {{which are}} {{designed specifically for}} hashing. They intend to form a practical alternative for <b>hash</b> <b>functions</b> based on another cryptographic primitive like a block cipher or modular squaring. About a dozen of dedicated <b>hash</b> <b>functions</b> have been proposed in the literature. This paper discusses the design principles on which these <b>hash</b> <b>functions</b> are based...|$|R
25|$|Cuckoo hashing, another {{technique}} for implementing hash tables, guarantees constant time per lookup (regardless of the <b>hash</b> <b>function).</b> Insertions into a cuckoo hash table may fail, causing the entire table to be rebuilt, but such failures are sufficiently {{unlikely that the}} expected time per insertion (using either a truly random <b>hash</b> <b>function</b> or a <b>hash</b> <b>function</b> with logarithmic independence) is constant. With tabulation hashing, on the other hand, the best bound known on the failure probability is higher, high enough that insertions cannot be guaranteed to take constant expected time. Nevertheless, tabulation hashing is adequate to ensure the linear-expected-time construction of a cuckoo hash table for a static set of keys that does not change as the table is used.|$|E
25|$|There {{is no need}} {{to provide}} a <b>hash</b> <b>function</b> or to change hash {{functions}} as more keys are added to a trie.|$|E
25|$|From this list, {{the server}} picks a cipher and <b>hash</b> <b>function</b> {{that it also}} {{supports}} and notifies the client of the decision.|$|E
40|$|<b>Hash</b> <b>functions</b> are {{important}} in cryptography due to their use in data integrity and message authentication. Different cryptographicimplementations rely on the performance and strength of <b>hash</b> <b>functions</b> to answer the need for integrity and authentication. This paper gives an overview of cryptographic <b>hash</b> <b>functions</b> used or evaluated today. <b>Hash</b> <b>functions</b> selected in NESSIE and CRYPTREC projects are shortly presented. SHA- 3 selection initiative is alsointroduced...|$|R
50|$|In {{particular}} k-means <b>hash</b> <b>functions</b> {{are better}} in practice than projection-based <b>hash</b> <b>functions,</b> {{but without any}} theoretical guarantee.|$|R
50|$|Most modern {{cryptographic}} <b>hash</b> <b>functions</b> process {{messages in}} fixed-length blocks; {{all but the}} earliest <b>hash</b> <b>functions</b> include some sort of padding scheme. It is critical for cryptographic <b>hash</b> <b>functions</b> to employ termination schemes that prevent a hash from being vulnerable to length extension attacks.|$|R
25|$|The square {{roots of}} small {{integers}} {{are used in}} both the SHA-1 and SHA-2 <b>hash</b> <b>function</b> designs to provide nothing up my sleeve numbers.|$|E
25|$|SSL 2.0 has a weak MAC {{construction}} {{that uses the}} MD5 <b>hash</b> <b>function</b> with a secret prefix, making it vulnerable to length extension attacks.|$|E
25|$|This logic has applications, {{for example}} a {{cryptographic}} attack called the birthday attack, which uses this probabilistic model {{to reduce the}} complexity of finding a collision for a <b>hash</b> <b>function.</b>|$|E
3000|$|Similar to {{cryptographic}} <b>hash</b> <b>functions,</b> robust <b>hash</b> <b>functions</b> for image authentication should satisfy 4 major requirements [10] (where [...]...|$|R
40|$|In {{the paper}} the author {{considers}} hardware {{implementation of the}} GRACE-H family general cellular automata based cryptographic <b>hash</b> <b>functions.</b> VHDL {{is used as a}} language and Altera FPGA as a platform for hardware implementation. Performance and effectiveness of the FPGA implementations of GRACE-H <b>hash</b> <b>functions</b> were compared with Keccak (SHA- 3), SHA- 256, BLAKE, Groestl, JH, Skein <b>hash</b> <b>functions.</b> According to the performed tests, performance of the hardware implementation of GRACE-H family <b>hash</b> <b>functions</b> significantly (up to 12 times) exceeded performance of the hardware implementation of previously known <b>hash</b> <b>functions,</b> and effectiveness of that hardware implementation was also better (up to 4 times) ...|$|R
50|$|Message {{authentication}} codes (MACs) (also called keyed <b>hash</b> <b>functions)</b> {{are often}} built from <b>hash</b> <b>functions.</b> HMAC {{is such a}} MAC.|$|R
25|$|Because of {{its high}} degree of independence, {{tabulation}} hashing is usable with hashing methods that require a high-quality <b>hash</b> <b>function,</b> including linear probing, cuckoo hashing, and the MinHash technique for estimating the size of set intersections.|$|E
25|$|In 2009, in {{cooperation}} with Meredith L. Patterson and Len Sassaman, Kaminsky discovered numerous flaws in the SSL protocol. These {{include the use of}} the weak MD2 <b>hash</b> <b>function</b> by Verisign in one of their root certificates and errors in the certificate parsers in a number of Web browsers that allow attackers to successfully request certificates for sites they don't control.|$|E
25|$|Word 2007 {{offers a}} {{significantly}} more secure document protection which utilizes the modern Advanced Encryption Standard (AES) that converts a password to a 128-bit key using a SHA-1 <b>hash</b> <b>function</b> 50000 times. It makes password removal impossible (as of today, no computer that can pick {{the key in}} reasonable amount of time exists), and drastically slows the brute-force attack speed down to several hundreds of passwords per second.|$|E
30|$|In Fig. 1, the Bloom filter is 32  bits per item (m/n[*]=[*] 32). At this point, 22 <b>hash</b> <b>functions</b> {{are used}} to {{minimize}} the false positive rate. However, adding <b>hash</b> <b>functions</b> does not significantly reduce the error rate when more than 10 <b>hash</b> <b>functions</b> have been used.|$|R
40|$|We survey {{theory and}} {{applications}} of cryptographic <b>hash</b> <b>functions,</b> such as MD 5 and SHA- 1, especially their resistance to collision-finding attacks. We review definitions, design principles, trace genealogy of standard <b>hash</b> <b>functions,</b> discuss generic attacks, attacks on iterative <b>hash</b> <b>functions,</b> and recent attacks on specific functions. ...|$|R
40|$|Abstract. Stringent {{power and}} {{performance}} constraints, coupled with detailed {{knowledge of the}} target applications of a processor, allows for application-specific processor optimizations. It {{has been shown that}} application-specific reconfigurable <b>hash</b> <b>functions</b> eliminate a large number of cache conflict misses. These <b>hash</b> <b>functions</b> minimize conflicts by modifying the mapping of cache blocks to cache sets. This paper describes an algorithm to compute optimal XOR-functions, a particular type of <b>hash</b> <b>functions</b> based on XORs. Using this algorithm, we set an upper bound on the conflict reduction achievable with XORfunctions. We show that XOR-functions perform better than other reconfigurable <b>hash</b> <b>functions</b> studied in the literature such as bit-selecting functions. The XOR-functions are optimal for one particular execution of a program. However, we show that optimal XOR-functions are less sensitive to the characteristics of the execution than optimal bit-selecting <b>hash</b> <b>functions.</b> This again underlines that XOR-functions are the best known <b>hash</b> <b>functions</b> to implement reconfigurable <b>hash</b> <b>functions.</b> ...|$|R
25|$|Lemire {{shows that}} no scheme {{of this type}} can be 3-independent. Nevertheless, he shows {{that it is still}} {{possible}} to achieve 2-independence. In particular, a tabulation scheme that interprets the values T (where x'i is, as before, the ith block of the input) as the coefficients of a polynomial over a finite field and then takes the remainder of the resulting polynomial modulo another polynomial, gives a 2-independent <b>hash</b> <b>function.</b>|$|E
25|$|Looking up {{data in a}} trie {{is faster}} in the worst case, O(m) time (where m is {{the length of a}} search string), {{compared}} to an imperfect hash table. An imperfect hash table can have key collisions. A key collision is the <b>hash</b> <b>function</b> mapping of different keys to the same position in a hash table. The worst-case lookup speed in an imperfect hash table is O(N) time, but far more typically is O(1), with O(m) time spent evaluating the hash.|$|E
25|$|Digest access {{authentication}} {{is one of}} the agreed-upon methods a {{web server}} can use to negotiate credentials, such as username or password, with a user's web browser. This can be used to confirm the identity of a user before sending sensitive information, such as online banking transaction history. It applies a <b>hash</b> <b>function</b> to the username and password before sending them over the network. In contrast, basic access authentication uses the easily reversible Base64 encoding instead of hash digest, making it non-secure unless used in conjunction with TLS.|$|E
40|$|In Cuckoo Hashing, we achieve {{expected}} O(1) amortized time {{per operation}} for dynamic hashing by using two <b>hash</b> <b>functions</b> {{and maintaining the}} property that each key is hashed to the value indicated by either of the <b>hash</b> <b>functions</b> [1]. This result is known {{as long as the}} <b>hash</b> <b>functions</b> are chosen independently and have O(lg n) -independence. In this paper, we show that only one of the <b>hash</b> <b>functions</b> must exhibit O(lg n) -independence, and the other only needs to be 2 -independent. We also show that 5 -independence or less for both <b>hash</b> <b>functions</b> is insufficient. Furthermore, if the <b>hash</b> <b>functions</b> are not chosen independently of one another but still satisfy a condition that we call joint-independence, Ω(lg n) -joint-independence is both necessary and sufficient to guarantee that Cuckoo Hashing will work. ...|$|R
40|$|We analyse the {{security}} of iterated <b>hash</b> <b>functions</b> that compute an input dependent checksum which is processed {{as part of the}} hash computation. We show that a large class of such schemes, including those using non-linear or even one-way checksum functions, is not secure against the second preimage attack of Kelsey and Schneier, the herding attack of Kelsey and Kohno and the multicollision attack of Joux. Our attacks also apply to a large class of cascaded <b>hash</b> <b>functions.</b> Our second preimage attacks on the cascaded <b>hash</b> <b>functions</b> improve the results of Joux presented at Crypto’ 04. We also apply our attacks to the MD 2 and GOST <b>hash</b> <b>functions.</b> Our second preimage attacks on the MD 2 and GOST <b>hash</b> <b>functions</b> improve the previous best known short-cut second preimage attacks on these <b>hash</b> <b>functions</b> by factors of at least 226 and 254, respectively. Our herding and multicollision attacks on the <b>hash</b> <b>functions</b> based on generic checksum functions (e. g., one-way) are a special case of the attacks on the cascaded iterated <b>hash</b> <b>functions</b> previously analysed by Dunkelman and Preneel and are not better than their attacks. On <b>hash</b> <b>functions</b> with easily invertible checksums, our multicollision and herding attacks (if the hash value is short as in MD 2) are more efficient than those of Dunkelman and Preneel...|$|R
40|$|The {{idea of a}} {{universal}} class of <b>hash</b> <b>functions</b> is due to Carter and Wegman. The goal is to define a collection of <b>hash</b> <b>functions</b> {{in such a way}} that a random choice of a function in the class yields a low probability that any two distinct inputs will collide. In this paper, we present some characterizations of universal classes of <b>hash</b> <b>functions</b> in terms of combinatorial designs such as resolvable balanced incomplete block designs and orthogonal arrays. The two classes of <b>hash</b> <b>functions</b> that we study are called optimally universal and strongly universal. We show that optimally universal classes of <b>hash</b> <b>functions</b> are equivalent to resolvable balanced incomplete block designs and strongly universal classes are equivalent to orthogonal arrays. Consequently, known classes of combinatorial designs yield new, small, and efficient classes of universal <b>hash</b> <b>functions...</b>|$|R
