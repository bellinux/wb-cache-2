1812|4901|Public
5|$|Bob Muglia (born 1959) is an American {{business}} {{executive and}} research and development specialist. He is currently the Chief Executive Officer of Snowflake Computing, a <b>data</b> <b>warehousing</b> startup. Muglia is known for managing divisions at Microsoft that supported the Microsoft Office Suite, Windows Server and MSN Network product families. He {{was one of four}} presidents that reported directly to Microsoft CEO Steve Ballmer.|$|E
5|$|Miamisburg-based Teradata is the world's largest <b>data</b> <b>warehousing</b> and {{enterprise}} analytics company, and Richfield-based OEConnection is the world's largest online {{automotive parts}} exchange, or OPSX. One Call Now, headquartered in Troy, is the nation's largest information notification service {{and part of}} INC Magazine's fastest-growing companies list {{three years in a}} row, while OneCommand, headquartered in Mason, is the nation's leading integrated and automated, personalized communications firm.|$|E
25|$|Analytics Platform System (APS): Formerly Parallel Data Warehouse (PDW) A massively {{parallel}} processing (MPP) SQL Server appliance optimized for large-scale <b>data</b> <b>warehousing</b> such {{as hundreds of}} terabytes.|$|E
40|$|<b>Data</b> <b>warehouses</b> {{are complex}} systems {{consisting}} of many components which store highlyaggregated data for decision support. Due {{to the role}} of the <b>data</b> <b>warehouses</b> in the daily business work of an enterprise, the requirements for the design and the implementation are dynamic and subjective. Therefore, <b>data</b> <b>warehouse</b> design is a continuous process which has to reflect the changing environment of a <b>data</b> <b>warehouse,</b> i. e. the <b>data</b> <b>warehouse</b> must evolve in reaction to the enterprise 's evolution. Based on existing meta models for the architecture and quality of a <b>data</b> <b>warehouse,</b> we propose in this paper a <b>data</b> <b>warehouse</b> process model to capture the dynamics of a <b>data</b> <b>warehouse.</b> The evolution of a <b>data</b> <b>warehouse</b> is represented as a special process and the evolution operators are linked to the corresponding architecture components and quality factors they affect. We show the application of our model on schema evolution in <b>data</b> <b>warehouses</b> and its consequences on <b>data</b> <b>warehouse</b> [...] ...|$|R
40|$|Scope of this master&# 8217;s thesis {{contains}} agile <b>data</b> <b>warehouse</b> design. It {{begins with}} a brief demonstration of <b>data</b> <b>warehouse</b> issues, shows the architectures dimensional <b>data</b> <b>warehouse,</b> corporate information factory and data vault. Furthermore, the thesis introduces agile methodologies suitable for <b>data</b> <b>warehouses.</b> Main part of this thesis focuses on the <b>data</b> <b>warehouse</b> design and development in Kentico Software s. r. o. using the modelstorming, shows implementation of universal ETL process for loading dimensional <b>data</b> <b>warehouse,</b> designs ETL processes, <b>data</b> <b>warehouse</b> storage and presentation layer. In the end, the thesis discusses future extensions to the <b>data</b> <b>warehouse</b> such as knowledge discovery module or large-scale data expansion...|$|R
40|$|Abstract-A <b>data</b> <b>warehouse</b> (DW) is a {{collection}} of technologies aimed at enabling the decision maker to make better and faster decisions. <b>Data</b> <b>warehouses</b> differ from operational databases in that they are subject oriented, integrated, time variant, non volatile, summarized, larger, not normalized, and perform OLAP. The generic <b>data</b> <b>warehouse</b> architecture consists of three layers (data sources, DSA, and primary <b>data</b> <b>warehouse).</b> During the ETL process, data is extracted from an OLTP databases, transformed to match the <b>data</b> <b>warehouse</b> schema, and loaded into the <b>data</b> <b>warehouse</b> databas...|$|R
25|$|Fast Track: SQL Server Fast Track is {{specifically}} for enterprise-scale <b>data</b> <b>warehousing</b> storage and business intelligence processing, and runs on reference-architecture hardware that is optimized for Fast Track.|$|E
25|$|SQL Server Integration Services (SSIS) {{provides}} ETL capabilities for SQL Server {{for data}} import, data integration and <b>data</b> <b>warehousing</b> needs. Integration Services includes GUI tools to build workflows such as extracting data from various sources, querying data, transforming data—including aggregation, de-duplication, de-/normalization and merging of data—and then exporting the transformed data into destination databases or files.|$|E
25|$|Microarray {{data was}} found to be more useful when {{compared}} to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. A number of open-source <b>data</b> <b>warehousing</b> solutions, such as InterMine and , have been created for the specific purpose of integrating diverse biological datasets, and also support analysis.|$|E
40|$|The article {{describes}} approach to design of <b>data</b> <b>warehouses</b> based on <b>data</b> structuredness and user queries to the <b>data</b> <b>warehouses.</b> The concept of multibase <b>data</b> <b>warehouse</b> is introduced, its mathematical model is built and two-phase building algorithm for multibase <b>data</b> <b>warehouses</b> which uses genetic algorithm is suggested...|$|R
40|$|Abstract — <b>Data</b> <b>Warehouse</b> systems aim at {{integrating}} {{data from}} multiple heterogeneous, distributed, autonomous data sources. Due to changing business needs the <b>data</b> <b>warehouse</b> systems are {{never meant to}} be static. Changes in the data source structure or business requirements would result in the evolution of <b>data</b> <b>warehouse</b> schema structure. When <b>data</b> <b>warehouse</b> schema evolves the dependent modules such as its mappings, queries and views gets affected. The existing works on <b>data</b> <b>warehouse</b> evolution focus only on schema evolution at the physical level. As ontology seems to be a promising solution in <b>data</b> <b>warehouse</b> research, the proposed framework handles <b>data</b> <b>warehouse</b> schema evolution at ontological level. Moreover, it analyses the impact of the dependent modules and proposes methods to automatically adapt to changes. Keywords-Datawarehouse schema evolution; Multidimensional schema evolution,;Impact of <b>data</b> <b>warehouse</b> evolution I...|$|R
40|$|Abstract—Data {{warehouse}} {{is one of}} the {{key information}} technology (IT) infrastructures. <b>Data</b> <b>warehouse</b> involves a huge financial undertaking. It is important that <b>data</b> <b>warehouse</b> performance is measured in terms of some key aspects. A balanced scorecard (BSC) approach could be applied to measure the performance of <b>data</b> <b>warehouse</b> operations. This article discusses measurements of performance that provides a comprehensive view of <b>data</b> <b>warehouse</b> operations. These measures include user perspective, internal process perspective, financial perspective, and innovation and growth perspective. The motivation behind using a balanced scorecard is to make sure <b>data</b> <b>warehouse</b> environment is efficient and stable; <b>data</b> <b>warehouse</b> programmers do a great job in writing efficient code and continuously make progress in terms of innovation and learning; <b>data</b> <b>warehouse</b> project continuously helps IT department in adding business value and enable cost avoidance; and <b>data</b> <b>warehouse</b> team provides business executives quality information at the right time to support making strategic business decisions. We have highlighted the performance measurement criteria for <b>data</b> <b>warehouses</b> that academics, <b>data</b> <b>warehouse</b> architects and IT managers might find beneficial...|$|R
25|$|Data {{mining and}} <b>data</b> <b>warehousing</b> {{research}} at Tarleton is improving crop insurance for farmers. At the Center for Agribusiness Excellence (CAE), researchers seek {{to improve the}} integrity of the U.S. Department of Agriculture Risk Management Agency’s delivery of services to farmers. Data mining research has identified patterns and schemes for cheating the system that are then reported to the Compliance Branch of the agency. In addition, systematic mistakes causing farmers’ claims to be underpaid are reported for corrective action. To date, more than $300 million in cost savings has been attributed to CAE research.|$|E
25|$|Frank Buytendijk (The Hague, 1969) is a Dutch {{author of}} {{management}} books. He studied business {{and information technology}} at the Hogeschool Utrecht (University of Applied Sciences Utrecht), was a consultant at various firms in his home country, was a research analyst and held executive positions in various large, medium and small software companies. He has a background in business intelligence, corporate performance management and business process management. Buytendijk is also a visiting fellow at Cranfield University School of Management. In 2012, he was appointed fellow at The <b>Data</b> <b>Warehousing</b> Institute (TDWI). Currently, Buytendijk is a research vice president at analyst firm Gartner, where he served before as well between 2001 and 2006.|$|E
2500|$|... {{the sheer}} volume of data and the ability to share it (<b>Data</b> <b>warehousing)</b> ...|$|E
40|$|This thesis {{focuses on}} {{developing}} methodics for performance comparison of <b>data</b> <b>warehouse</b> systems. Firstly, the thesis defines <b>data</b> <b>warehouses</b> in various development stages of organization BI and describes knowledge about <b>data</b> <b>warehouses.</b> Methodics {{developed in the}} thesis describes architecture of standardized <b>data</b> <b>warehouse,</b> <b>data</b> flow between areas of <b>data</b> <b>warehouse</b> and processes in <b>data</b> <b>warehouse.</b> Understanding of these concepts is crucial for assurance of methodics applicability. Methodics offer logical progression of steps, which start and include testing of <b>data</b> <b>warehouse</b> systems. The contribution of the thesis is in having guide, {{what needs to be}} done when organization must do while testing various systems for <b>data</b> <b>warehouses.</b> Also it describes how this testing should be done on middle level detail, which is the absolute minimum level of abstraction that can be done due to wide applicability of methodics. Methodics offers solution to the problem of performance comparison when organization need to answer question - Which <b>data</b> <b>warehouse</b> system should we use in our organization? However, methodics expects already some knowledge about <b>data</b> <b>warehouse</b> content...|$|R
40|$|<b>Data</b> <b>warehouse</b> systems {{integrate}} <b>data</b> from heterogeneous sources. These {{sources are}} autonomous {{in nature and}} change independently of a <b>data</b> <b>warehouse.</b> Owing to changes in data sources, the content and the schema of a <b>data</b> <b>warehouse</b> {{may need to be}} changed for accurate decision making. Slowly changing dimensions and temporal <b>data</b> <b>warehouses</b> are the available solutions to manage changes in the content of the <b>data</b> <b>warehouse.</b> Multiversion <b>data</b> <b>warehouses</b> are capable of managing changes in the content and the structure simultaneously however, they are relatively complex and not easy to implement. In this paper, we present a logical model of a multiversion <b>data</b> <b>warehouse</b> which is capable of handling schema changes independently of changes in the content. We also introduce a new hybrid table version approach to implement the multiversion <b>data</b> <b>warehouse.</b> © 2014 Springer International Publishing. SCOPUS: cp. kinfo:eu-repo/semantics/publishe...|$|R
40|$|This paper {{presents}} {{the evaluation of}} the architecture of healthcare <b>data</b> <b>warehouse</b> specific to cancer diseases. This <b>data</b> <b>warehouse</b> containing relevant cancer medical information and patient <b>data.</b> The <b>data</b> <b>warehouse</b> provides the source for all current and historical health data to help executive manager and doctors to improve the decision making process for cancer patients. The evaluation model based on Bill Inmon's definition of <b>data</b> <b>warehouse</b> is proposed to evaluate the Cancer <b>data</b> <b>warehouse.</b> Comment: 5 page...|$|R
5000|$|Inmon's {{association}} with <b>data</b> <b>warehousing</b> {{stems from the}} fact that he wrote the first book on <b>data</b> <b>warehousing</b> he held the first conference on <b>data</b> <b>warehousing</b> (with Arnie Barnett), he wrote the first column in a magazine on <b>data</b> <b>warehousing,</b> he has written over 1,000 articles on <b>data</b> <b>warehousing</b> in journals and newsletters, he created the first fold out wall chart for <b>data</b> <b>warehousing</b> and he conducted the first classes on <b>data</b> <b>warehousing.</b>|$|E
5000|$|... 1995 - The <b>Data</b> <b>Warehousing</b> Institute, {{a for-profit}} {{organization}} that promotes <b>data</b> <b>warehousing,</b> is founded.|$|E
50|$|The International Journal of <b>Data</b> <b>Warehousing</b> and Mining (IJDWM) is a {{quarterly}} peer-reviewed academic journal covering <b>data</b> <b>warehousing</b> and data mining. It {{was established in}} 2005 and is published by IGI Global. The editor-in-chief is David Taniar (Monash University, Australia).|$|E
50|$|He is the {{principal}} {{author of the best-selling}} books The <b>Data</b> <b>Warehouse</b> Toolkit, The <b>Data</b> <b>Warehouse</b> Lifecycle Toolkit, The <b>Data</b> <b>Warehouse</b> ETL Toolkit and The Kimball Group Reader, published by Wiley and Sons.|$|R
40|$|<b>Data</b> <b>warehouse</b> {{has a very}} {{important}} role in assisting of decision making, where the <b>data</b> <b>warehouse</b> became the core. Data in the <b>data</b> <b>warehouse</b> provide valuable information for its users. By using <b>data</b> <b>warehouse,</b> governance institutions can conduct data analyzes in order to build new strategies to make benefits for all stakeholders. This paper discusses about the design of <b>data</b> <b>warehouse</b> in Balai Besar Riset Sosial Ekonomi dan Kelautan. <b>Data</b> <b>warehouse</b> design using dimensional model approach introduced by Kimball. The information required by management at Balai Besar Riset Sosial Ekonimi dan Kelautan are divided into three groups: income, consumption and commerce. With the <b>data</b> <b>warehouse</b> organizations can easily perform analyses and generate reports, which can be viewed from various scopes, including time, region, fishermen and fisheries. </p...|$|R
40|$|In {{this paper}} a <b>data</b> <b>warehouse</b> {{framework}} that supports <b>data</b> <b>warehouse</b> evolution is presented. The framework {{is able to}} handle not only changes in data sources, but also direct changes in a <b>data</b> <b>warehouse</b> schema. In the framework the <b>data</b> <b>warehouse</b> versions are supported in the development environment {{as well as in}} reports in the user environment. ...|$|R
5000|$|<b>Data</b> <b>Warehousing,</b> Information Lifecycle Management, Transformational Outsourcing ...|$|E
5000|$|... #Article: International Journal of <b>Data</b> <b>Warehousing</b> and Mining ...|$|E
5000|$|Systems Research and Development - {{real-time}} <b>data</b> <b>warehousing</b> ...|$|E
40|$|The {{maintenance}} of <b>data</b> <b>warehouses</b> {{is becoming an}} increasingly important topic due to the growing use, derivation and integration of digital information. Most previous work has dealt with one centralized <b>data</b> <b>warehouse</b> (DW) only. In this paper, we now focus on environments with multiple <b>data</b> <b>warehouses</b> that are possibly derived from other <b>data</b> <b>warehouses.</b> In such a large-scale environment, data updates from base sources may arrive in individual <b>data</b> <b>warehouses</b> in different orders, thus resulting in inconsistent <b>data</b> <b>warehouse</b> extents. We propose a registry-based solution strategy that addresses this problem by employing a registry agent responsible for establishing one unique order for the propagation of updates from the base sources to the <b>data</b> <b>warehouses.</b> With this solution, individual <b>data</b> <b>warehouse</b> managers can still maintain their respective extents autonomously and independently from each other, thus allowing them to apply any of the existing incremental maintenance algo [...] ...|$|R
40|$|Abstract. This paper {{describes}} how software language engineering {{is applied to}} the process of <b>data</b> <b>warehouse</b> creation. The creation of a <b>data</b> <b>warehouse</b> is a complex process and therefore costly. My approach decomposes the <b>data</b> <b>warehouse</b> creation process into different aspects. These aspects are described with different languages which are integrated by a metamodel. Based on this metamodel, large parts of the <b>data</b> <b>warehouse</b> creation process can be generated. With my approach <b>data</b> <b>warehouses</b> are created more comfortable in less time. ...|$|R
40|$|AbstractAs <b>Data</b> <b>Warehouse</b> store {{huge amount}} of data with the span of more than decades, the {{security}} of this huge information base is crucial for the sustainability and reliability of <b>data</b> <b>warehouse.</b> Since its advent the <b>data</b> <b>warehouse</b> has gone through various technological changes, which has prompted changes in the security strategies as well. This article, is taking a deep look at the various changes in the security mechanisms of the <b>Data</b> <b>Warehouse,</b> along with {{the changes in the}} strategies for the <b>data</b> <b>warehouse</b> development. It helps in understanding the various security aspects related to <b>Data</b> <b>Warehouse,</b> in coherence with the different methodologies employed for its development and functioning...|$|R
5000|$|... #Subtitle level 3: <b>Data</b> <b>warehousing</b> and {{business}} intelligence ...|$|E
50|$|See also IBM Linux Solution Optimizes Enterprise <b>Data</b> <b>Warehousing.</b>|$|E
5000|$|<b>Data</b> <b>warehousing</b> (central {{repository}} for data, including legacy data) ...|$|E
40|$|<b>Data</b> <b>warehouses</b> using {{a multidimensional}} view of data {{have become very}} popular in both {{business}} and science in recent years. <b>Data</b> <b>warehouses</b> for scientific purposes such as medicine and bio-chemistry pose several great challenges to existing <b>data</b> <b>warehouse</b> technology. <b>Data</b> <b>warehouses</b> usually use pre-aggregated data to ensure fast query response. However, pre-aggregation cannot be used in practice if the dimension structures or the relationships between facts and dimensions are irregular. A technique for overcoming this limitation and some experimental results are presented. Queries over scientific <b>data</b> <b>warehouses</b> often need to reference data that is external to the <b>data</b> <b>warehouse,</b> e. g., <b>data</b> that is too complex to be handled by current <b>data</b> <b>warehouse</b> technology, <b>data</b> that is "owned" by other organizations, or data that is updated frequently. An exampl...|$|R
40|$|The aim of {{this paper}} is to bring {{together}} two research areas, i. e. <b>Data</b> <b>Warehouses</b> and Temporal Databases, involving representation of time. In order to achieve this goal, <b>data</b> <b>warehouse</b> and temporal database research results have been surveyed. Looking at temporal aspects within a <b>data</b> <b>warehouse,</b> more similarities than differences between temporal databases and <b>data</b> <b>warehouses</b> have been found. Postprint (published version...|$|R
40|$|Metadata {{represents}} {{the information about}} data to be stored in <b>Data</b> <b>Warehouses.</b> It is a mandatory element of <b>Data</b> <b>Warehouse</b> to build an efficient <b>Data</b> <b>Warehouse.</b> Metadata helps in data integration,lineage,data quality and populating transformed <b>data</b> into <b>data</b> <b>warehouse.</b> Spatial <b>data</b> <b>warehouses</b> are based on spatial data mostly collected from Geographical Information Systems(GIS) and the transactional systems that are specific to an application or enterprise. Metadata design and deployment is the most critical phase in building of <b>data</b> <b>warehouse</b> where it is mandatory to bring the spatial information and data modeling together. In this paper,we present a holistic metadata framework that drives metadata creation for spatial <b>data</b> <b>warehouse.</b> Theoretically, the proposed metadata framework improves the efficiency of accessing of data in response to frequent queries on SDWs. In other words, the proposed framework decreases the response time of the query and accurate information is fetched from <b>Data</b> <b>Warehouse</b> including the spatial information...|$|R
