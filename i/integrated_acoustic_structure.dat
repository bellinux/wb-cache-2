0|843|Public
5000|$|... Directional Pad Having <b>Integrated</b> <b>Acoustic</b> System And Lighting System ...|$|R
30|$|Electronic sound {{synthesis}} continues to offer huge potential {{possibilities for the}} creation of new musical instruments. The traditional approach is, however, seriously limited in that it incorporates only auditory feedback and it will typically make use of a {{sound synthesis}} model (e.g., additive, subtractive, wavetable, and sampling) that is inherently limited and very often nonintuitive to the musician. In a direct attempt to challenge these issues, this paper describes a system that provides tactile as well as acoustic feedback, with real-time synthesis that invokes a more intuitive response from players since it is based upon mass-spring physical modelling. Virtual instruments are set up via a graphical user interface in terms of the physical properties of basic well-understood sounding objects such as strings, membranes, and solids. These can be interconnected to form complex <b>integrated</b> <b>structures.</b> <b>Acoustic</b> excitation can be applied at any point mass via virtual bowing, plucking, striking, specified waveform, or from any external sound source. Virtual microphones can be placed at any point masses to deliver the acoustic output. These aspects of the instrument are described along with the nature of the resulting acoustic output.|$|R
5000|$|Engineer (sequence design & <b>acoustic</b> <b>structures)</b> - The Movement ...|$|R
40|$|<b>Integrated</b> <b>acoustics</b> systems {{providing}} {{navigation and}} communications and conducting acoustic measurements {{in support of}} science applications are, in concept, analogous to the Global Positioning System, but rely on acoustics because the ocean is opaque to electromagnetic waves and transparent to sound. A series of nested systems is envisioned, from small- to regional- to basin-scale. A small number of acoustic sources sending coded, low power signals can service unlimited numbers of inexpensive receivers. Drifting floats with receivers can be tracked accurately while collecting ocean circulation and heat content data, as well as ambient sound data about wind, rain, marine mammals, seismic T-phases, and anthropogenic activity. The sources can also transmit control data from users to remote instruments, and if paired with receivers enable two-way acoustic communications links. Acoustic-based instrumentation that shares the acoustic bandwidth completes the concept of <b>integrated</b> <b>acoustics</b> systems. The ocean observatories and ocean observing systems presently in the planning and implementation stages will require these <b>integrated</b> <b>acoustics</b> systems...|$|R
40|$|Much of {{the cost}} and effort of new ocean {{observatories}} {{will be in the}} infrastructure that directly supports sensors, such as moorings and mobile platforms, which in turn connect to a “backbone” infrastructure. Four elements of this sensor network infrastructure are in various stages of development, presented here: (1) a cable-connected mooring system with a profiler under real-time control with inductive battery charging; (2) a glider with <b>integrated</b> <b>acoustic</b> communications and broadband receiving capability; (3) an <b>integrated</b> <b>acoustic</b> navigation and communication network with tomography on various scales; and (4) a satellite uplink and feedback system. We also present initial results from field experiments, as well as from studies on communication performance of the underwater sensor network system under development...|$|R
50|$|February 1990: VP-6 {{became the}} ﬁrst patrol {{squadron}} at NAS Barbers Point {{to receive the}} ﬁrst P-3C Update II.5 aircraft. This update had improved electronics systems, new IACS (<b>Integrated</b> <b>Acoustic</b> Communication System), improved MAD, standardized wing pylons and improved wing fuel tank venting.|$|R
40|$|Abstract – Much of {{the cost}} and effort of new ocean {{observatories}} {{will be in the}} infrastructure that directly supports sensors, such as moorings and mobile platforms, which in turn connect to a “backbone ” infrastructure. Four elements of this sensor network infrastructure are in various stages of development, presented here: (1) a cable-connected mooring system with a profiler under real-time control with inductive battery charging; (2) a glider with <b>integrated</b> <b>acoustic</b> communications and broadband receiving capability; (3) an <b>integrated</b> <b>acoustic</b> navigation and communication network with tomography on various scales; and (4) a satellite uplink and feedback system. We also present initial results from field experiments, as well as from studies on communication performance of the underwater sensor network system under development. I...|$|R
40|$|<b>Integrated</b> <b>acoustic</b> echo and {{background}} noise suppression technique based on soft decision Yun-Sik Park 1 and Joon-Hyuk Chang 2 * In this paper, we propose an efficient <b>integrated</b> <b>acoustic</b> echo and noise suppression algorithm using the combined power of acoustic echo {{and background}} noise within a soft decision framework. The combined {{power of the}} acoustic echo and noise is adopted to the integrated suppression algorithm based on soft decision to address the artifacts such as the nonlinear distortion and the disturbed noise introduced from the conventional methods. Specifically, in the unified frequency domain architecture, the acoustic echo and noise signal are efficiently able to be suppressed through the acoustic echo suppression algorithm based on soft decision {{without the help of}} the additional noise reduction technique. ...|$|R
5000|$|McCowan B, Reiss D, and Gubbins CM. (1998). Social {{familiarity}} influences whistle <b>acoustic</b> <b>structure</b> {{in adult}} female bottlenose dolphins (Tursiops truncatus). Aquatic Mammals 24:21-40.|$|R
50|$|October 1994: VP-68 {{received}} its first P-3C UII.5 aircraft and began transition training while the remaining seven assigned P-3C UI aircraft were being replaced. The P-3C UII.5 had improved electronics systems, new <b>Integrated</b> <b>Acoustic</b> Communication System, improved MAD, standardized wing pylons and improved wing fuel tank venting.|$|R
40|$|Modem {{instrumentation}} systems require a transducer {{to convert the}} physical property of interest into a form which is ultimately usable to the scientist. In that sense, an increasing interest {{in the development of}} <b>integrated</b> <b>acoustic</b> sensors has been demonstrated in recent decades. Most of them use either bulk (BAW) [I], surfac...|$|R
40|$|Long {{calls are}} highly stereotyped calls used by {{primates}} to communicate across distances; {{the function of}} these calls has been debated. Goustard (1983 : 405) defines them as 2 ̆ 2 [...] . an extended utterance which has {{a high degree of}} structural organization. 2 ̆ 2 Habitat structure has been considered a shaping force of the <b>acoustic</b> <b>structure</b> of nonhuman primate long calls as part of the local adaptation hypothesis (Brown et al. 1995). This study examines the effect of phylogeny, habitat density, diet, and social and mating systems as seen through the structure of the fundamental frequency (the lowest frequency of the call; Rogers 2000; Ey, Pfefferle, and Fischer 2007). Results of ANOVA and post hoc tests indicate there are both phylogenetic and habitat-related influences in the <b>acoustic</b> <b>structure</b> of the first phrase (first part of the long call separated from the next by a discrete break). Dietary preferences and social and mating systems are also correlated with <b>acoustic</b> <b>structure...</b>|$|R
40|$|A coaxial {{research}} {{dump combustor}} {{was used to}} investigate the <b>acoustic</b> modes <b>structure</b> {{and its effect on}} the inlet shock system. <b>Acoustic</b> wave <b>structure</b> was determined including the amplitude, frequency, and phase as a function of position. Inlet shock position, shock displacement, shock displacement frequency, and phase relative to <b>acoustic</b> wave <b>structure</b> were also defined. All results were compared to with one dimensional modeling...|$|R
50|$|KCF Technologies {{provides}} {{custom product}} development {{as well as}} noise and vibration consulting services. Its primary {{focus is on the}} optimal design of structures using hybrid computer programs that <b>integrate</b> <b>acoustic</b> modeling and FEM programs with high-speed optimization routines. Others include modeling particle damping in tire vibration and optimal design of sound reduction enclosures for noise control.|$|R
50|$|Rainbow {{acoustic}} monitoring provides noninvasive {{and continuous}} measurement of respiration rate using an adhesive sensor with an <b>integrated</b> <b>acoustic</b> transducer that {{is applied to}} the patient's neck. Researchers have evaluated acoustic respiration rate (RRa) and found the acceptable accuracy and significantly fewer false alarms than traditional respiration rate monitoring methods, end-tidal carbon dioxide (EtCO2) and impedance pneumography.|$|R
40|$|We {{consider}} {{the problem of}} the construction of the <b>acoustic</b> <b>structure</b> of arbitrary geometry with prescribed desired properties. We use optimization approach for the solution of this problem and minimize the Tikhonov functional on adaptively refined meshes. These meshes are refined locally only in places where the <b>acoustic</b> <b>structure</b> should be designed. Our special symmetric mesh refinement strategy together with interpolation procedure allows the construction of the symmetric acoustic material with prescribed properties. Efficiency of the presented adaptive optimization algorithm is illustrated on the construction of the symmetric acoustic material in two dimensions. Comment: 25 pages, 82 figures. arXiv admin note: substantial text overlap with arXiv: 1606. 0173...|$|R
50|$|The {{main purpose}} of calls in Barbary macaques is to alert other group members to {{possible}} dangers such as predators. Barbary macaques can discriminate calls by individuals in their own group from those by individuals in other groups of conspecific macaques. Neither genetic variation nor habitat differences are likely causes of acoustic variation in the calls of different social groups. Instead, minor variations in <b>acoustic</b> <b>structure</b> among groups similar to the vocal accommodation seen in humans are the likely cause. However, acoustic characteristics such as pitch and loudness are varied based on the vocalizations of individuals they associate with, and social situations {{play a role in}} the <b>acoustic</b> <b>structure</b> of calls.|$|R
40|$|In {{contrast}} to the cries of human infants, sounds made by non-human infants in different stressful behavioral contexts (hunger or physical discomfort, isolation, capture by humans or predators) are usually treated as distinct types of vocalizations. However, if distress vocalizations produced by different species and in different contexts share a common motivational state and associated neurochemical pathways, we can expect them to share a common <b>acoustic</b> <b>structure</b> and adaptive function, showing only limited variation that corresponds to the infant’s level of arousal. Based on this premise, we review the <b>acoustic</b> <b>structure</b> and adaptive function of two types of distress calls, those given when infants were isolated from their mothers (isolation calls) or captured by humans (capture calls). We conducted a within-context comparison examining the two call types across a diverse selection of mammalian species and other vertebrate groups, followed by a comparison of how <b>acoustic</b> <b>structure</b> and function differs between these contexts. In addition, we assessed acoustic traits that are critical to the response of caregivers. Across vertebrate species, distress vocalizations produced in these two behavioral contexts tend to be tonal with a simple chevron, flat or descending pattern of frequency modulation. Reports that both isolation and capture calls of vertebrate infants serve to attract caregivers are universal, and the fundamental frequency of infant vocalizations is often critical to this response. The results of our review {{are consistent with the}} hypothesis that differences in the <b>acoustic</b> <b>structure</b> of isolation and capture distress vocalizations reflect differences in arousal, and not discrete functions. The similarity in <b>acoustic</b> <b>structure</b> and caregiver response observed across vertebrates adds support to the hypothesis that the production and processing of distress vocalizations are part of a highly-conserved system of social vocal behaviour in vertebrates. Bioacoustic research may move forward by recognizing the commonality among different forms of infant solicitations that attract caregivers, and the commonality of these solicitations with vocalizations that attract conspecifics in still other behavioral contexts [Current Zoology 58 (5) : 698 - 726, 2012]...|$|R
40|$|Modern {{instrumentation}} systems require a transducer {{to convert the}} physical property of interest into a form which is ultimately usable to the scientist. In that sense, an increasing interest {{in the development of}} <b>integrated</b> <b>acoustic</b> sensors has been demonstrated in recent decades. Most of them use either bulk (BAW) [1], surface (SAW) [2], plate (or Lamb) [3], or thin rod [4] acoustic waves...|$|R
40|$|Audio-visual speech {{recognition}} is a promising approach to tackling {{the problem of}} reduced recognition rates under adverse acoustic conditions. However, finding an optimal mechanism for combining multi-modal information remains a challenging task. Various methods are applicable for <b>integrating</b> <b>acoustic</b> and visual information in Gaussian-mixture-model-based {{speech recognition}}, e. g., via dynamic stream weighting. The recent advances of deep neural network (DNN) -based speech recognition promise improved performance when using audio-visual information. However, {{the question of how}} to optimally <b>integrate</b> <b>acoustic</b> and visual information remains. In this paper, we propose a state-based integration scheme that uses dynamic stream weights in DNN-based audio-visual speech recognition. The dynamic weights are obtained from a time-variant reliability estimate that is derived from the audio signal. We show that this state-based integration is superior to early integration of multi-modal features, even if early integration also includes the proposed reliability estimate. Furthermore, the proposed adaptive mechanism is able to outperform a fixed weighting approach that exploits oracle knowledge of the true signal-to-noise ratio...|$|R
40|$|We {{studied the}} {{advertisement}} signals in two clades of North American hylid frogs {{in order to}} characterize the relationships between signal <b>acoustic</b> <b>structure</b> and underlying behavior. A mismatch {{was found between the}} <b>acoustic</b> <b>structure</b> and the mechanism of sound production. Two separate sets of phylogenetic characters were coded following acoustic versus mechanistic criteria, and exploratory treatments were made to compare their respective phylogenetic content in comparison with the molecular phylogeny (Faivovich et al., 2005). We discuss the consequences of the acoustic ⁄mechanistic mismatch in terms of significance of acoustic characters for phylogenetic and comparative studies; and the evolution of vocalizations in North American treefrogs. Considering only the <b>acoustic</b> <b>structure</b> of frog vocalizations can lead to misleading results in terms of both phylogenetic signal and evolution of vocalizations. In contrast, interpreting the acoustic signals with regard to the mechanism of sound production results in consistent phylogenetic information. The mechanistic coding also provides strong homologies for use in comparative studies of frog vocalizations, and to derive and test evolutionary hypotheses. The Willi Hennig Society 2006. Many animals depend on acoustic communication for reproductive success and survival. Both field and labor-atory studies have shown the importance of signals o...|$|R
50|$|The {{architectural}} methodology {{includes a}} green approach that neatly <b>integrates</b> with <b>acoustic</b> {{goals for the}} property, a spa retreat hotel.|$|R
30|$|The {{relative}} {{acoustic impedance}} map {{is computed by}} integrating the attribute across the given time window. For example, the attribute can be integrated between two interpreted horizons. Physically, this {{is related to the}} logarithm of the acoustic impedance contrast. Variations in the <b>integrated</b> <b>acoustic</b> impedance attributes map are related by density variation, porosity, lithology and other features. Thus, the relative acoustic impedance map is used for reservoir characterisation (Taner et al. 1979).|$|R
40|$|It {{is known}} that {{macroscopic}} objects can be levitated for few to several hundred micrometers by near-field acoustic field and this phenomenon is called near-field acoustic levitation (NFAL). Although there are various experiments conducted to measure <b>integrated</b> <b>acoustic</b> pressure on the object surface, up to now there was no direct method to measure pressure distribution. In this study we measured the acoustic radiation pressure of the near-field acoustic levitation via pressure-sensitive paint...|$|R
40|$|We are {{developing}} a system which learns words from co-occurring spoken and visual input. The goal is to automatically segment continuous speech atword boundaries without a lexicon, and to form visual categories which correspond to spoken words. Mutual information is used to <b>integrate</b> <b>acoustic</b> and visual distance metrics in order to extract an audio-visual lexicon from raw input. We report results of experiments with a corpus of infant-directed speech and images. 1...|$|R
50|$|January 1994: VP-65 began {{transition}} to the P-3C UII.5 Orion airframe. Update II.5 had improved electronics systems, new <b>Integrated</b> <b>Acoustic</b> Communication System (IACS), improved MAD, standardized wing pylons and improved wing fuel tank venting. Throughout {{the remainder of the}} year, detachments from VP-65 deployed to NAF Kadena, Japan; NAS North Island, California; and NAS Barbers Point, as part of the increased integration of reserves into active duty Navy operations and exercises under CTF-72.|$|R
40|$|SummaryOne {{standout}} {{feature of}} human language is {{our ability to}} reference external objects and events with socially learned symbols, or words. Exploring the phylogenetic origins of this capacity is therefore key to a comprehensive understanding {{of the evolution of}} language. While non-human primates can produce vocalizations that refer to external objects in the environment, it is generally accepted that their <b>acoustic</b> <b>structure</b> is fixed and a product of arousal states [1]. Indeed, {{it has been argued that}} the apparent lack of flexible control over the structure of referential vocalizations represents a key discontinuity with language [2]. Here, we demonstrate vocal learning in the <b>acoustic</b> <b>structure</b> of referential food grunts in captive chimpanzees. We found that, following the integration of two groups of adult chimpanzees, the <b>acoustic</b> <b>structure</b> of referential food grunts produced for a specific food converged over 3 years. Acoustic convergence arose independently of preference for the food, and social network analyses indicated this only occurred after strong affiliative relationships were established between the original subgroups. We argue that these data represent the first evidence of non-human animals actively modifying and socially learning the structure of a meaningful referential vocalization from conspecifics. Our findings indicate that primate referential call structure is not simply determined by arousal and that the socially learned nature of referential words in humans likely has ancient evolutionary origins...|$|R
40|$|Abstract – In {{many areas}} of Earth science, {{including}} climate change research and operational oceanography, {{there is a need}} for near real-time integration of data from heterogeneous and spatially distributed sensors, in particular in-situ and space-based sensors. The data integration, as provided by a smart sensor web, enables numerous improvements, namely, 1) adaptive sampling for more efficient use of expensive space-based and in situ sensing assets, 2) higher fidelity information gathering from data sources through integration of complementary data sets, and 3) improved sensor calibration. Our ocean-observing smart sensor web presented herein is composed of both mobile and fixed underwater insitu ocean sensing assets and Earth Observing System satellite sensors providing larger-scale sensing. An acoustic communications network forms a critical link in the web, facilitating adaptive sampling and calibration. We report on the development of various elements of this smart sensor web, including (a) a cable-connected mooring system with a profiler under real-time control with inductive battery charging; (b) a glider with <b>integrated</b> <b>acoustic</b> communications and broadband receiving capability; (c) an <b>integrated</b> <b>acoustic</b> navigation and communication network; (d) satellite sensor elements; and (e) a predictive model via the Regional Ocean Modeling System interacting with satellite sensor control. 1 I...|$|R
40|$|Some nonhuman {{primates}} {{have demonstrated}} the capacity to communicate about external objects or events, suggesting primate vocalizations can function as referential signals. However, there is little convincing evidence for functionally referential communication in any great ape species. Here, the authors demonstrate that wild chimpanzees (Pan troglodytes schweinfurthii) of Budongo forest, Uganda, give acoustically distinct screams during agonistic interactions depending on the role they play in a conflict. The authors analyzed the <b>acoustic</b> <b>structure</b> of screams of 14 individuals, {{in the role of}} both aggressor and victim. The authors found consistent differences in the <b>acoustic</b> <b>structure</b> of the screams, across individuals, depending on the social role the individual played during the conflict. The authors propose that these 2 distinct scream variants, produced by victims and aggressors during agonistic interactions, may be promising candidates for functioning as referential signals...|$|R
40|$|Microelectromechanical {{resonators}} {{include a}} resonator body anchored to a substrate {{by at least}} one tether containing a coupled-ring linear <b>acoustic</b> bandgap <b>structure</b> therein. The coupled-ring linear <b>acoustic</b> bandgap <b>structure</b> can include a plurality of piezoelectric-on-semiconductor rings connected together by a plurality of piezoelectric-on-semiconductor tether segments. A first electrode may also be provided, which extends on the resonator body and the coupled-ring linear <b>acoustic</b> bandgap <b>structure.</b> This resonator body, which may be suspended opposite a recess in the substrate, may include a semiconductor (e. g., silicon) body having a piezoelectric layer (e. g., AlN) thereon, which extends between the semiconductor body and the first electrode. The coupled-ring linear <b>acoustic</b> bandgap <b>structure</b> may be a periodic structure, where a pitch between each of the plurality of piezoelectric-on-semiconductor rings in the at least one tether is equivalent, or a non-periodic structure. Georgia Tech Research Corporatio...|$|R
5000|$|In [...] "From Here to Ear" [...] (1999), {{the artist}} used pack of zebra finches and piano strings for <b>acoustic</b> <b>structure</b> {{creation}} form {{of which was}} defined with behavior of birds. In view of Cage's practice, Boursier-Mougenot's method lies first of all in transliterations of natural structure, aural identification of certain realities which are not seen for eyes.|$|R
40|$|Field {{observations}} and acoustic analyses {{have shown that}} suricate (Suricata suricatta) alarm calls vary in their <b>acoustic</b> <b>structure</b> depending on predator type. In this study, we tested whether receivers respond appropriately when hearing a call {{in the absence of}} a predator. Although the only way for suricates to escape from predators is to retreat to boltholes, responses to playbacks could be divided into distinct categories. The subjects responded differently to alarm calls given in response to aerial or terrestrial predators and to recruitment calls emitted in response to snakes and deposits on the ground. Suricates also showed rather distinct responses to low, medium and high urgency aerial calls. Differences in the responses were less obvious for different levels of urgency in the terrestrial and recruitment calls. Suricate receivers thus gain information about both the predator type and level of urgency from the <b>acoustic</b> <b>structures</b> of their calls...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Issued also on microfiche from Lange Micrographics. I recorded vocalizations of allopatric populations of Western Scrub-Jays (Aphelocoma californica texana and A. c. woodhouseii) and Mexican Jays (A. ultramarine couchii) at eight sites in Texas. While many call types were inconsistent in structure and tended to intergrade, I identified two structurally distinct call types (the flight call and the rattle call) as shared by all taxa at all sites. Differences in <b>acoustic</b> <b>structure</b> of both call types were greatest between species. Subspecies showed less distinct <b>acoustic</b> <b>structure,</b> with unique <b>acoustic</b> <b>structures</b> occasionally being shared with the nearest population of another subspecies. Morphometric acoustic analysis revealed a similar pattern, with the most differentiation at the specific level, followed by subspecific and, lastly, by populational differentiation. Of particular interest was a small, isolated population of A. californica found in the Texas panhandle. Although breeding populations may have existed for only two or three decades, morphometric analysis of both call types showed marked vocal differentiation from other Texas Scrub-Jays. Analysis of one call type suggested morphometric acoustic separation from the other populations of Scrub-Jays at the subspecific level, while the other call type suggested separation at the specific level...|$|R
40|$|Surface {{acoustic}} wave resonators {{have been used}} in a number of applications: high‐Q frequency filtering, very accurate frequency sources, etc. A major disadvantage of conventional resonators is their large dimensions, which makes them inadequate for <b>integrated</b> <b>acoustics</b> applications. In order to overcome these size limitations a new type of microresonator was designed, developed, and tested. In this paper, theoretical calculations and measurements on two kinds of such devices (a corrugated waveguide filter and a microresonator structure) are presented and their possible applications are discussed...|$|R
40|$|We {{performed}} an <b>integrated</b> <b>acoustic</b> and GPR {{study of the}} Cheko Lake area (101 o E, 62 o N) during summer 1999. The GPR study aimed at imaging lake bottom and shallow sedimentary layers to plan coring of sediments coeval with the catastrophic 1908 explosion. The water of the Cheko Lake strongly attenuates radar waves. Therefore, the central and northern sectors of the lake (30 m average depth) were surveyed by means of <b>acoustic</b> techniques only. <b>Integrated</b> <b>acoustic</b> and GPR techniques {{were used in the}} shallow southern sector. More than 5 km of radar profiles were obtained in the lake, using 50 MHz and 100 MHz antennas. 150 metres of 200 MHz multi-fold profiles were obtained across the only accessible sectors on land. The GPR profiles processed to date successfully image discontinuities at depths greater than 700 cm. Comparison with acoustic results shows that GPR provides high resolution images of the depth range of interest (0 - 500 cm) which complement the information obtained from sub-bottom profilers and can be calibrated by the gravity cores. A deep (700 cm) flat sub-horizontal reflector, shallow (0 - 200 cm) dipping layers, sigmoidal structures and local chaotic lenses are the primary features imaged by GPR in the lake...|$|R
40|$|Methods for {{utterance}} verification (UV) {{and their}} integration into statistical language modeling and spoken language understanding formalisms {{for a large}} vocabulary spoken understanding system are presented. The paper consists of three parts. First, a set of acoustic likelihood ratio based utterance verification techniques are described and applied {{to the problem of}} rejecting portions of a hypothesized word string that may have been incorrectly decoded by a large vocabulary continuous speech recognizer. Second, a procedure for <b>integrating</b> the <b>acoustic</b> level confidence measures with the statistical language model is described. Finally, the effect of <b>integrating</b> <b>acoustic</b> level confidence into the spoken language understanding unit (SLU) in a call [...] type classification task is discussed. These techniques were evaluated on utterances collected from a highly unconstrained call routing task performed over the telephone network. They have been evaluated in terms of their ability to classify u [...] ...|$|R
