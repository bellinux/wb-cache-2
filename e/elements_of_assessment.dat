29|10000|Public
5000|$|Assessment {{of motor}} control may involve several health {{professionals}} {{depending on the}} affected individual's situation, and the severity of their condition. This may include physical therapists, physicians (including neurologists and psychiatrists [...] ) and rehabilitation physicians, orthotists, occupational therapists, and speech-language pathologists. Assessment is needed of the affected individual's goals, their function, and any symptoms that {{may be related to}} the movement disorder, such as pain. A thorough assessment then uses a clinical reasoning approach to determine why difficulties are occurring. <b>Elements</b> <b>of</b> <b>assessment</b> will include analysis of posture, active movement, muscle strength, movement control and coordination, and endurance, as well as muscle tone and spasticity. Impaired muscles typically demonstrate a loss of selective movement, including a loss of eccentric control (decreased ability to actively lengthen); this decreased active lengthening of a muscle is a key factor that limits motor control. While multiple muscles in a limb are usually affected in the Upper Motor Neuron Syndrome, there is usually an imbalance of muscle activity (muscle tone), such that there is a stronger pull on one side of a joint, such as into elbow flexion. Decreasing the degree of this imbalance is a common focus of muscle strengthening programs. Impaired motor control also typically features a loss of stabilisation of an affected limb or the head from the trunk, so a thorough assessment requires this to be analysed as well, and exercise to improve proximal stability may be indicated.|$|E
40|$|Fifteen {{historical}} and contemporary curriculum designs were analyzed for <b>elements</b> <b>of</b> <b>assessment</b> that support student learning and inform instructional decisions. Educational researchers are purposely {{paying attention to the}} role assessment plays in a well-designed planning and teaching process. Assessment is a vital component to educational planning and teaching because it is a way to gather accurate evidence of student learning and information to inform instructional decisions. The purpose of this review was to analyze 100 years of curriculum designs to uncover <b>elements</b> <b>of</b> <b>assessment</b> that will support teachers in their desire to improve student learning. Throughout this research the author seeks to answer the question: Do {{historical and}} contemporary curriculum designs include <b>elements</b> <b>of</b> <b>assessment</b> that help teachers improve student learning? The results of the review reveal that assessment elements were addressed in all of the curricular designs analyzed, but not all <b>elements</b> <b>of</b> <b>assessment</b> were identified using similar terminology. Based on the analysis of this review, it is suggested that teachers not be particular about the terminology used to describe assessment elements, as all curriculum models discussed use one or more elements similar to the context of pre, formative, and summative assessments...|$|E
30|$|This study {{adopted a}} {{qualitative}} approach to investigate the essential <b>elements</b> <b>of</b> <b>assessment</b> literacy for Iranian EFL secondary school teachers {{in light of the}} recent English curriculum briefly described above.|$|E
40|$|The {{purpose of}} the study was to {{determine}} whether or not elementary classroom teachers 2 ̆ 7 exploration of an integrated theoretical model <b>of</b> formative <b>assessment</b> would change participants 2 ̆ 7 understandings <b>of</b> formative <b>assessment</b> and whether or not participants would apply this newly-acquired knowledge to their classroom assessment practices. After exploring <b>elements</b> <b>of</b> formative <b>assessment</b> in a collaborative study group, participants applied new understandings to their classroom assessment practices. The model <b>of</b> formative <b>assessment</b> explored by the study group included these elements: the articulation of clear learning outcomes, the alignment <b>of</b> instruction and <b>assessment</b> to learning outcomes; the providing of feedback to students and using feedback to plan future instruction; and the involvement of students in classroom assessment practices. Previous research on formative assessment has demonstrated the importance <b>of</b> individual <b>elements</b> <b>of</b> formative <b>assessment.</b> This case study provided teachers with an integrated theoretical model that included all <b>of</b> the <b>elements</b> <b>of</b> formative <b>assessment</b> identified in the research literature and used this model as the basis for professional development to change teachers 2 ̆ 7 classroom practice. Data were gathered through surveys, study group transcripts, participant reflections, classroom observations, interviews with students and documents from individual classrooms. Data were analyzed using a constant comparative method in an effort to identify categories and themes that emerged for changes in teachers 2 ̆ 7 understandings and classroom practices for each <b>of</b> the <b>elements</b> <b>of</b> formative <b>assessment.</b> Results <b>of</b> the study indicate that the collaborative study group changed teachers 2 ̆ 7 understandings <b>of</b> the <b>elements</b> <b>of</b> formative <b>assessment,</b> the important relationships among the elements and the teachers 2 ̆ 7 classroom formative assessment practices. The collaborative study group also provided participants with a supportive environment in which to share their experiences as they attempted to implement new assessment practices in their classrooms...|$|R
40|$|Extensive {{research}} {{exists on}} formative assessment {{in higher education}} (Irons, 2008; Rieg 2 ̆ 6 Wilson, 2009; Tan, 2008). Prior research primarily focuses on feedback as the core <b>element</b> <b>of</b> formative <b>assessment</b> (Irons, 2008; Rieg 2 ̆ 6 Wilson, 2009; Tan, 2008; Yorke 2001, 2003). There is, however, a lack of research examining college faculty members 2 ̆ 7 perspectives regarding the four core <b>elements</b> <b>of</b> formative <b>assessment</b> for instruction (Heritage, 2007; Yorke, 2001, 2003). ^ The {{purpose of this study}} was to explore the perspectives of college faculty using the <b>elements</b> <b>of</b> formative <b>assessment</b> in the classroom. Research indicates that educators 2 ̆ 7 perspectives are integral to understanding the effective utilization <b>of</b> formative <b>assessment</b> (Black, Harrison, Lee, Marshall, 2 ̆ 6 Wiliam, 2003; Black 2 ̆ 6 Wiliam, 1998). The research question that guided this study was: How do college faculty members describe utilizing the four core <b>elements</b> <b>of</b> formative <b>assessment</b> in classroom instruction? ^ A qualitative descriptive methodology utilizing 10 (N = 10) in-depth semi-structured interviews, document analyses of 16 syllabi, and five (N = 5) reflective questionnaires garnered faculty insights into the four core <b>elements</b> <b>of</b> formative <b>assessment.</b> Exploration <b>of</b> the faculty members 2 ̆ 7 experiences followed the Heritage (2007) framework on the four core <b>elements</b> <b>of</b> formative <b>assessment,</b> which was used to guide the research question and interview protocol. ^ Findings reveal that: (1) faculty members perceive the prerequisites required for each course as determinates of the background knowledge students possess, (2) self- and peer assessment are important but there is a lack of time and the knowledge needed to implement the strategies effectively, (3) feedback must be provided quickly, citing the use of Blackboard and surveys as the most common methods of providing feedback to inform learning and pedagogy respectively; and (4) the content requirements set by program administrators and professional standards primarily guide the development of student learning progressions. ^ These findings may benefit educators who implement the formative assessment practices. Improving the use <b>of</b> formative <b>assessment</b> practices warrants continuous and consistent professional development (Brancato, 2003). The results of the study may inform faculty training and pedagogy in formative assessment. ...|$|R
30|$|As can be seen, {{the coarse}} {{algorithm}} QS-SVM delivered lower SROCC scores than the FR indices, {{although the results}} are promising. Of course, QS-SVM is not trained on DMOS scores, hence does not fully capture the perceptual <b>elements</b> <b>of</b> blur <b>assessment.</b>|$|R
30|$|They lack a {{monitoring}} system by third parties. Every Region has made monitoring compulsory by law. But - especially {{in cases where}} the law already provides for a regional non-financial line dedicated to the DA - there are no actual evaluations of effectiveness of the method, nor even homogeneous surveys able to present more generalised <b>elements</b> <b>of</b> <b>assessment.</b>|$|E
40|$|We know {{assessment}} is cursed from below, {{but is it}} also blessed from above? Recognizing that {{assessment is}} the current dirty word in higher education, this paper explores whether assessment has Biblical foundations. Seven key principles that emerge from best practices in assessment are outlined and their foundations in Scriptural truths and texts are explored using an intensive study of topics from the Leadership Bible. This paper finds that the seven key <b>elements</b> <b>of</b> <b>assessment</b> do have a basis in scripture—assessment is indeed as blessed from above, as it is cursed from below...|$|E
40|$|Organizations contemplating {{standardized}} technology adoption {{are confronted}} {{both by the}} potential for internal capability gains and by inter-organizational forces. Although such technologies may appear imitable and non-strategic, they can enable idiosyncrasies and strategic gains through their interaction with other resources possessed by firms. Based on Barney’s original 1991 thesis on the resource-based view, Abrahamson and Rosenkopf’s 1997 analytical framework is reconceptualized and extended to capture {{both internal and external}} <b>elements</b> <b>of</b> <b>assessment</b> and IT value generation. An analytical experiment is conducted on the extended model to illustrate how technology diffusion is simply one artifact of a general cycle of resource enablement that can be viewed as driving idiosyncratic strategic gains and facilitating interorganizational dynamics...|$|E
50|$|K. El Emam and N. H. Madhavji (eds.): <b>Elements</b> <b>of</b> Software Process <b>Assessment</b> and Improvement. IEEE Computer Society Press, 1999.|$|R
50|$|RPL {{has been}} the {{mainstay}} <b>of</b> all <b>assessments</b> conducted under national vocational education and training systems since the late 1980s and continues to evolve as different VET systems evolve. It was first introduced into the UK by Susan Simosko, a consultant with the National Council for Vocational Qualifications, who adapted it as the central <b>element</b> <b>of</b> all competency-based <b>assessments.</b> A similar process was adopted by all countries during {{the development of their}} own vocational education and training systems, some aligned solely with the need to assess competence in line with the needs of private and public sector organizations, and others as a critical <b>element</b> <b>of</b> the <b>assessment</b> <b>of</b> skills and knowledge in order to grant vocational qualifications.|$|R
40|$|This article {{provides}} a brief review {{on the science}} assessment in the National <b>Assessment</b> <b>of</b> Educational Progress (NAEP) of USA {{in the last decade}} (1996, 2000 and 2005). It focuses on some key <b>elements</b> <b>of</b> the <b>assessment</b> framework and <b>assessment</b> criteria <b>of</b> NAEP and critically examines certain assessment items as selected from those three rounds <b>of</b> <b>assessment</b> exercise. Besides, there is a concise analysis on the educational implications of NAEP...|$|R
40|$|Student {{surveys are}} often {{important}} <b>elements</b> <b>of</b> <b>assessment</b> in higher education, but alumni surveys {{can play a}} substantial role as well. However, {{little is known about}} how responses from these two groups compare to one another. Combining data from the Strategic National Arts Alumni Project (SNAAP) and the National Survey of Student Engagement (NSSE), this study examines self-reported college experiences and skill development of seniors and alumni who majored in the arts. Results suggest that alumni rate their overall experience higher, while students judge specific aspects of their institutional experience and their skill development more positively. Given these differences, it is recommended that institutions survey both students and alumni to achieve a more complete picture of the educational experience...|$|E
40|$|This paper {{describes}} {{the process for}} creating and validating an assessment test that measures the effectiveness of instruction by probing how well that instruction causes students in a class to think like experts about specific areas of science. The design principles and process are laid out and it is shown how these align with professional standards that have been established for educational and psychological testing and the <b>elements</b> <b>of</b> <b>assessment</b> called for in a recent National Research Council study on assessment. The importance of student interviews for creating and validating the test is emphasized, and the appropriate interview procedures are presented. The relevance and use of standard psychometric statistical tests are discussed. Additionally, techniques for effective test administration are presented...|$|E
40|$|This {{paper is}} to examine the {{assessment}} needs of students studying in hospitality management degrees at Australian universities. The paper investigates the concept of flexible delivery, and contextualising flexible assessment. It determines the size and scope of the population of hospitality programs in Australia and the efficient methodological approach. The findings indicated that the programs were only significantly different in the negotiation of the due date of an assessment item. The results revealed that both flexible and traditional programs failed to address the assessment needs of the students when examining the <b>elements</b> <b>of</b> <b>assessment</b> that they would have liked to be able to negotiate. The study suggests that the students should be provided with the option of negotiating the various assessment elements even though they might wish to change the offered alternatives...|$|E
50|$|Other {{countries}} {{adopted the}} same processes when {{developing their own}} competency-based vocational education and training systems, some aligned solely {{with the need to}} assess competence in line with the needs of private and public sector organizations, and others as a critical <b>element</b> <b>of</b> the <b>assessment</b> <b>of</b> skills and knowledge in order to grant vocational qualifications. The National Training Board in Australia {{was one of the first}} outside of the UK to develop such a system as a framework for the transition towards the implementation of new apprentice programs and workplace training and assessment under the National Training Reform Agenda. RPL was incorporated under the National Framework for the Recognition of Training and has since remained an important <b>element</b> <b>of</b> all competency-based <b>assessments.</b>|$|R
40|$|Information {{literacy}} {{is becoming an}} increasingly {{important component of the}} higher education curriculum, with many disciplines incorporating <b>elements</b> <b>of</b> information literacy training within their traditional teaching. This article will highlight lessons learned during attempts formally to embed information literacy into Politics modules at Cardiff University. In particular, it will address the issue of whether information literacy sessions should include an <b>element</b> <b>of</b> formal <b>assessment...</b>|$|R
40|$|The general {{objective}} {{was to make a}} continuing <b>assessment</b> <b>of</b> current automotive technology development programs and of the prospects for new concepts. The study embraced alternative engines, advanced powertrain components, and related energy conserving vehicle modifications which could be implemented {{by the end of this}} century. Vehicle level projections of the fuel economy and emissions potential of alternative power systems were key <b>elements</b> <b>of</b> this <b>assessment...</b>|$|R
3000|$|As {{observed}} by Pellegrino et al. (2003); see also Wilson (2005), the triadic <b>elements</b> <b>of</b> <b>assessment,</b> curriculum, and instruction {{all have to}} be integrally connected. New or changed learning content and learning forms must also be reflected in the assessment, and vice versa. Additionally, the results of recent studies on final examinations point to the need to redesign assessments: Herzog (2013), for example, speaks about the “gauging of education,” and criticizes trends in schools whereby teachers align their lessons too strongly with external tests, notably with respect to content, task dimensions, and the methodological structure of the lesson. A test that is closely geared to real professional situations, in respect of content and type of work, could diminish the theory–practice gap: “teaching to the test” would, at the same time, be regarded as “teaching to the job.” [...]...|$|E
40|$|It {{is widely}} {{accepted}} that {{in higher education}} internationally, assessment drives students’ learning. As a consequence, students become ever more strategic, and only put energy into things that count towards their overall assessment. This article suggests a practical way of setting about reflecting on the assessment processes and instruments you use. Many institutions have now adopted ‘assessment for learning ’ approaches, to make better links between assessment and learning. In this paper, I argue {{that we can go}} even further and work towards ‘assessment as learning ’ where all of our <b>elements</b> <b>of</b> <b>assessment</b> are designed with learning in mind. The paper provides you with a scoring grid, using which you can interrogate your own assessment elements, and determine how well they measure up to a combination of ‘assessment for learning ’ and ‘assessment as learning’. Keyword(s) : learning, assessment...|$|E
40|$|Monitoring programmes, by necessity, must be {{commensurate}} with the socio-economic and technical and scientific development {{of the country where}} they are implemented. For example the extent of development of national legislation and co-ordinating or oversight programmes will affect activities undertaken. Similarly, more complex analytical variables require highly trained technicians and costly laboratory facilities. In general terms, it is possible to distinguish three levels into which monitoring programmes can be classified (Table 3. 1). All <b>elements</b> <b>of</b> <b>assessment,</b> from objective setting to data interpretation, are related to these three levels. The aim is to progressively develop monitoring operations from the basic level to the more comprehensive levels. Each level is associated with increasing demands on staff (expertise and numbers), inspection and fieldwork (complexity and frequency), laboratory facilities (range of analysis, throughput) and data management and reporting capacity. Table 3. 1 Levels of monitoring competence in relation to resource requirement...|$|E
40|$|Despite major {{discussion}} and consideration <b>of</b> authentic <b>assessment</b> through the 1990 s, little progress {{appears to have}} been made towards its widespread adoption in higher education. Universities often serve to limit the use of authentic approaches in learning tasks and assessment, through restrictive policies. In this paper, we briefly review the literature and summarise the characteristic <b>elements</b> <b>of</b> authentic <b>assessment,</b> and argue that task, assessment and university policies must be aligned for truly effective use <b>of</b> authentic <b>assessment</b> to occur in higher education...|$|R
40|$|Describes the Philosophy Department's {{assessment}} {{activities for}} the academic year 2008 - 2009 The Philosophy Department's annual assessment report to the College for the Office <b>of</b> Academic <b>Assessment.</b> The report details action taken regarding the three <b>elements</b> <b>of</b> their <b>assessment</b> plan: beginning to involve the history of philosophy courses that {{play a role in}} the philosophy major in the assessment process, including PHIL 230 is assessment, and conferring with the previous assessment liaison...|$|R
40|$|Laboratory-based {{practical}} exercises, {{which are}} an important and time-consuming part of many science degree courses, may be directed towards a variety of learning objectives. Some of these have traditionally been assessed by staff marking the student's written account of the laboratory experiment (the laboratory write-up) but increasing student numbers, which may have doubled or quadrupled on some modules, have {{made it difficult to}} sustain this approach. In addition, there is evidence that the formative <b>element</b> <b>of</b> the <b>assessment</b> (i. e. the comments written by staff on the laboratory write-up) is not fully utilized by students who are often only interested in the mark given. This paper reports on experience with the various strategies which may be used to cope with the increased marking load while maintaining or improving the learning gain from the formative <b>element</b> <b>of</b> the <b>assessment.</b> The adoption <b>of</b> a balanced mixture of strategies may present the best solution to the problem but must be tailored to local circumstances...|$|R
40|$|Observing {{that many}} faculty within the Theater Department at the University of Hawaiʻi at Mānoa lacked a strong {{understanding}} of the assessment process, I developed a plan intending to “advertise” <b>elements</b> <b>of</b> <b>assessment,</b> making visible what is currently in place and seeking to spotlight several of these assessment components. However, because I was representing theatre, it seemed appropriate to use performance techniques to accomplish this. Using Augusto Boal’s suggestion of “Invisible Theatre” I have subtly tried to spark a conversation about assessment with {{a group that is}} not always eager to “color in the lines. ” Invisible Theatre is a play that is played in a public space without informing anyone that it is a piece of theatre. In this poster, I showcase many of the scripts used in this “visible/invisible” project and display the department’s new SLO layout, curriculum map and assessment rubric...|$|E
40|$|Evaluation designs {{assessing}} community coalitions must balance {{measures of}} how coalitions {{do their work}} and evidence that the coalitions are making a difference. The Allies cross-site evaluation attempts to determine the combined effects of the seven coalitions’ work at the individual, organizational, and community levels. Principal components considered are (a) contextual factors of the coalition community, (b) coalition processes and structure, (c) planning and planning products, (d) implementation actions, (e) activities and collaborations, (f) anticipated intermediate outcomes, and (g) expected asthma related health outcomes. Measurements are quantitative and qualitative, and data generated by these methods are used as ends in themselves and {{as a way to}} confirm or inform other measures. Evaluation has been {{an integral part of the}} planning and implementation phases of the Allies coalition work, with a priority of involving all of the partners in conceiving of and deciding upon the <b>elements</b> <b>of</b> <b>assessment.</b> ...|$|E
40|$|Environmental {{assessments}} generate and/or collect {{individual research}} efforts to answer policy-relevant questions and otherwise provide technical advice to decision-makers, typically legislators, international negotiators and regulators. Though {{one might think}} first of assessments {{in terms of the}} reports that they often produce, the implications of scientific assessment are better understood by viewing assessments as a social processes, rather than principally as a document. Assessment processes are embedded in different sorts of institutional settings, within which scientists, decision-makers, and advocates communicate to define relevant questions for analysis, mobilize certain kinds of experts and expertise, and interpret findings in particular ways. This social process perspective on assessment directs attention beyond the content of assessment reports to encompass questions the design of the social process. In this paper, we focus on four <b>elements</b> <b>of</b> <b>assessment</b> design that are too frequently under-appreciated: assessment context and initiation, science–policy interaction, participation in assessment processes, and assessment capacity. We show how widely these elements vary across five different assessments and discuss the implications of this variation. # 2001 Elsevier Science Ltd. All rights reserved. 1...|$|E
40|$|The paper {{presents}} {{a comparison of}} realized wastewater sludge disposal processes in six municipal wastewater treatment plants with a pe of 50 000 to 400 000. For that evaluation, {{quantity and quality of}} raw wastewater, functioning line of sludge disposal, {{the quantity and quality of}} the produced sludge and their utilization were the important issues. A significant <b>element</b> <b>of</b> the <b>assessment</b> was also action in introducing modern technologies in the aspect of reducing the sludge storage...|$|R
50|$|Proponents of {{personalized}} learning {{say that}} many <b>elements</b> <b>of</b> curriculum, <b>assessment</b> and instructional design must be present in classrooms for students to succeed and often use software systems to manage and facilitate student-led instruction. Proponents argue that classroom learning activities must build upon students' prior knowledge and teachers need to allocate time for practice. Advocates argue that teachers must continuously assess student learning against clearly defined standards and goals and student input into the assessment process is integral.|$|R
40|$|In {{paper the}} main {{problems}} and objectives <b>assessment</b> <b>of</b> the current technical {{condition of the}} machine-building equipment are considered. Modern measuring systems used in engineering analysis. The paper considers a phase-chronometric information technology-metrological support {{for the evaluation of}} the technical condition of the synchronous electromechanical systems on the example of turbine CHP. Analysis of the main problems in the diagnosis of electromechanical systems is given. Phase-chronometric method as a basis for building a new system of diagnosis of electromechanical systems reviewed. The paper describes the main <b>elements</b> <b>of</b> technology, <b>assessment</b> <b>of</b> the economic effects of its introduction in the industry...|$|R
40|$|This study {{investigated}} beginning secondary teachers' perceptions {{and experiences of}} student assessment. Three aspects were explored: beginning teachers' perceptions of assessment, the <b>elements</b> <b>of</b> <b>assessment</b> beginning teachers find most challenging {{and the extent to}} which professional support is addressing beginning teachers' needs, in relation to assessment. In-depth interviews were conducted with six beginning secondary teachers. Participants ranged from less than one to five years experience and represented a range of subject methods. Assessment was perceived as a means to improve student learning, by providing a form of feedback concerning students' understanding and progress. Beginning secondary teachers however, did not perceive assessment as a means to critique and evaluate their own teaching practice. Beginning teachers also expressed a strong pedagogical belief that assessments should be interesting and engaging, however time constraints often inhibit the implementation of such assessments. The design phase of assessment proves to be the most challenging element of assessment. It appears that a teacher's tenure will determine what aspect of designing an assessment proves most challenging. In terms of professional support, there is a lack of professional development devoted to assessment and reporting. Generally beginning secondary teachers rely on advice from experienced colleagues...|$|E
40|$|The paper {{reports on}} a study {{conducted}} with final year undergraduates on a product design course, in the UK, to attempt to better understand how they both interpret and respond to feedback on their academic work. The starting point {{for this study was}} the relatively poor scores attained for the <b>elements</b> <b>of</b> <b>assessment</b> and feedback in the National Student Survey (NSS) results for this course. The paper draws upon an existing body of literature around assessment and feedback related to the NSS results nationally. Based upon the literature an intervention relating to an element of assessment was made with these students and data collected on the students’ response to this intervention. The results of analyzing this data suggest that while students’ responded positively to some aspects of the intervention it is apparent that students’ still struggle to understand how to deploy the feedback to improve their work. This study is part of a longitudinal study, the next part of which involves a second intervention with the same student cohort that will attempt to ascertain what they would like to receive in terms of feedback...|$|E
40|$|The {{purpose of}} this article is to {{describe}} the designand implementation of the Robert Wood JohnsonFoundation’s (RWJF) Allies Against Asthma cross-site evaluation. The Allies Against Asthma (Allies) program consists of seven coalition sites, each com-prising various stakeholders such as local health care providers, schools and day care centers, community advocacy groups, businesses, local government organiza-tions, managed care organizations, academic institutions, parent groups, and other community-based organizations, which aim to combat pediatric asthma. The evaluation approach for Allies was designed collaboratively by Evaluation designs assessing community coalitions must balance measures of how coalitions do their work and evidence that the coalitions are making a differ-ence. The Allies cross-site evaluation attempts to deter-mine the combined effects of the seven coalitions ’ work at the individual, organizational, and community levels. Principal components considered are (a) con-textual factors of the coalition community, (b) coalition processes and structure, (c) planning and planning products, (d) implementation actions, (e) activities and collaborations, (f) anticipated intermediate outcomes, and (g) expected asthma related health outcomes. Measurements are quantitative and qualitative, and data generated by these methods are used as ends in themselves and as a way to confirm or inform other measures. Evaluation has been an integral part of the planning and implementation phases of the Allies coalition work, with a priority of involving all of the partners in conceiving of and deciding upon the <b>elements</b> <b>of</b> <b>assessment...</b>|$|E
40|$|The article {{discusses}} current {{approaches to}} the process of assessing rural development governance, reveals its advantages and disadvantages. The article as well presents performance system indicators of governance process by means <b>of</b> two <b>elements</b> <b>of</b> dynamics <b>assessment,</b> rural development (economic, financial, and social sphere, ecology and population health) and management process (<b>assessment</b> <b>of</b> strategic plan (concept) of development, program of socioeconomic development of rural areas, current activity of local authorities), in particular. More over, it is suggested to use typology of approaches (objective (evolutionary), command and control, economic (infrastructural), complex, and qualitative) to definition of process essence of rural development governance and correlation of traditional functions, performed by the subjects of the governance process of rural development (state authorities institutions, local authorities institutions, economic entities, and community). Adjusting traditional functions, performed by governance subjects of local development, their supplementing with new ones, relevant to the present-to-date model of «shared governance» is an important <b>element</b> <b>of</b> analysis <b>of</b> <b>assessment</b> tools for effectiveness of rural development governance. In addition, the author defines functioning of two forms of rural population involvement in{{to the process of}} rural development governance: active and passive. Active one suggests that rural population participate in making and implementing governance decisions (public meetings, organization of social discussions, and development of territory community self-governance); passive one suggests that the emphasis is placed only on information distribution among population (meetings with parliament members, direct phone lines with territory governors, publication of normative and legal acts and reports on budget execution) </em...|$|R
3000|$|Extensive {{knowledge}} of toxicity pathways {{will present a}} particular problem for the methodology applied today to assess the risks of and determine limit values for chemical substances and mixtures. The [...] "no observed effect level" [...] and the [...] "lowest observed effect concentration" [...] are core <b>elements</b> <b>of</b> such <b>assessments.</b> In view <b>of</b> biochemical or cellular changes and disturbances far below an adverse effect observable [...] "from outside", it seems obvious that the taxonomy of the adversity concept should be updated.|$|R
40|$|This article {{considers}} {{the role and}} nature of evaluation in training human relations professionals and some core <b>elements</b> <b>of</b> the <b>assessment</b> process, defined here as an inter-subjective, contractual, and negotiated pro-cess aimed at promoting growth. The author also considers ethics in relation to evaluation processes and the role trust plays in protect-ing the relational bond. ______ In training human relations professionals, evaluation includes assessing the learner’s learn-ing as well as estimating the contribution, posi-tively or negatively, of the curriculum conten...|$|R
