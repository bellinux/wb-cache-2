16|2556|Public
5000|$|August 1953 - July 1954: Commander, Air Task Group 7.4, Kirtland Air Force Base, New Mexico, with {{temporary}} duty on Eniwetok Island <b>during</b> <b>operational</b> <b>phase</b> of Operation Castle ...|$|E
40|$|AbstractThe risk {{simulation}} model of aero engine failure {{has been developed}} based on Monte Carlo method. The model has been established to predict and evaluate the failure risk of aero engine <b>during</b> <b>operational</b> <b>phase</b> to ensure the reliability and security. Risk assessment of a particular engine {{was conducted on the}} basis of the failure events hazard level and the corresponding risk guidelines. During the assessment, three reasonable corrective actions have been developed and estimated to analyze the effect of different maintenance methods and inspectional intervals on the failure risk factor...|$|E
40|$|Quality of any {{software}} system mainly {{depends on how}} much time testing take place, what kind of testing methodologies are used, the complexity of software and the amount of efforts put by software developers subject to the cost and time constraint. More time developers spend on testing more errors can be removed leading to better reliable software. On the contrary, if testing time is too short, the software cost could be reduced, but in that case the customers may take a higher risk of buying unreliable software. However, this will increase the cost <b>during</b> <b>operational</b> <b>phase</b> since it is more expensive to fix an error <b>during</b> <b>operational</b> <b>phase</b> than during testing phase. Therefore it is essentially important to decide when to stop testing and release the software to customers based on cost and reliability assessment. In this paper we present a mechanism of when to stop testing process and release the software to end-user by developing software cost model with risk factor. Based on the proposed method we specifically address the issues of how to decide that now we should stop testing and release the software that is based on three-tier client server architecture which would facilitates software developers to ensure on-time delivery of a software product matching the criteria of attaining a predefined level of reliability and minimizing the cost. A numerical example has been cited to illustrate the experimental results showing significant improvements over the conventional statistical models based on NHPP...|$|E
30|$|A full {{lifecycle}} {{approach would}} be needed to conclude the operative energy demand of the given shelters. Including heating energy demand would raise the impact of shelters that are located in a cool climate. Most likely, shelters from Pakistan and Peru would show more PE demand <b>during</b> their <b>operational</b> <b>phase.</b>|$|R
5000|$|Once the SIL {{level is}} {{determined}} this specifies the required performance {{level of the}} safety systems <b>during</b> the <b>operational</b> <b>phase</b> of the plant. The metric for measuring {{the performance of a}} safety function is called the average probability of failure on demand (or PFDavg) and this correlates to the SIL level as follows ...|$|R
40|$|NDT {{techniques}} {{have been developed}} for performing in-process evaluations for material variability and for process control. Several of these techniques show considerable promise for evaluating the reusable surface insulation <b>during</b> the <b>operational</b> <b>phase</b> of the shuttle. Considered are radiographic dosimetry, sonic velocity and modulus sounding, infrared coating evaluation, and beta backscatter monitoring of coating thickness...|$|R
40|$|AbstractOperational Profile {{is found}} to be an {{important}} technique for critical fault removal. Software Operational Profile (SOP) plays a vital role in reliability estimation, quality valuation, performance analysis and test case allocation of software. However, some problems are detected by software experts with the development of SOP as data resources are very limited and large effort is required to convert gathered data into point estimate. Also uncertainty is involved with SOP as it often changes <b>during</b> <b>operational</b> <b>phase.</b> Software operational profile plays a crucial role in improving the software quality. Therefore, in this paper, software test case allocation using fuzzy logic based on operational profile based is proposed and it takes usage data in terms of linguistic variable. The model is validated with the existing literature. Validation result is satisfactory...|$|E
40|$|This paper {{investigates the}} {{challenges}} for Resource Allocation (RA) that can allow reconfigurable systems {{to adapt the}} limited resources in a multi-sensor network <b>during</b> <b>operational</b> <b>phase</b> to changing missions, users and/or environments. Nodes can have multiple different radar frontends, but also electro-optic and acoustic front-ends. Using a hierarchical model to explain what RA is {{in order to avoid}} ambiguity of terminology, this paper gives a novel insight into the RA challenges: the limited resources should be successfully allocated to the operational tasks while satisfying certain quality criteria and considering task importance. To understand the nature of the RA challenges, the resources and capabilities are discussed and basic principles for resource allocation are present. Although the benefits of a heterogeneous ad-hoc sensor network are clear, it is certain that allocating the resources to maximize mission success is a major challenge...|$|E
40|$|The {{management}} of natural hazards occurring over a territory entails two main phases: a preoperational—or pre-event—phase, whose {{objective is to}} relocate resources closer to sites characterized by the highest hazard, and an operational—during the event—phase, {{whose objective is to}} manage in real time the available resources by allocating them to sites where their intervention is needed. Obviously, the two phases are closely related, and demand a unified and integrated treatment. This work presents a unifying framework that integrates various decisional problems arising in the {{management of}} different kinds of natural hazards. The proposed approach, which is based on a mathematical programming formulation, can support the decisionmakers in the optimal resource allocation before (preoperational phase) and <b>during</b> (<b>operational</b> <b>phase)</b> an emergency due to natural hazard events. Different alternatives of modeling the resources and the territory are proposed and discussed according to their appropriateness in the preoperational and operational phases. The proposed approach {{can be applied to the}} management of any natural hazard and, from an integration perspective, may be particularly useful for risk management in civil protection operations. An application related to the management of wildfire hazard is presented...|$|E
40|$|This paper {{gives an}} insider’s {{perspective}} on the management approaches used to manage the 2010 Census <b>during</b> its <b>operational</b> <b>phase.</b> The approaches used, the challenges faced (in particular, difficulties faced in automating data collection), and the solutions applied to meet those challenges are described. Finally, six management lessons learned are presented. Census, Program Management, Risk Management...|$|R
40|$|Quantitative {{measures}} of reliability for operational software in embedded avionics computer systems are presented. Analysis {{is carried out}} on data collected during flight testing and from both static and dynamic simulation testing. Failure rate {{is found to be}} a useful statistic for estimating software quality and recognizing reliability trends <b>during</b> the <b>operational</b> <b>phase</b> of software development...|$|R
40|$|Accurate {{prediction}} of release times, {{reliability and availability}} of a software product requires the formulation of a reliability model which captures in a quantitative manner critical elements of the software testing process such as: (i) test coverage and (ii) the effect of operational profiles. This paper presents a Non-Homogeneous Poisson Process(NHPP) based model which accounts explicitly for test coverage and can make predictions about the <b>operational</b> <b>phase.</b> The model provides, also, for defective fault detection and test coverage <b>during</b> testing and <b>operational</b> <b>phases.</b> The model yields reliability and availability functions which utilize test and operational data for making performance predictions <b>during</b> the <b>operational</b> <b>phase.</b> Stopping rules are developed for determining optimal software release times subject to various constraints such as cost, operational reliability and operational availability requirements. Index Terms: Software reliability modeling; Test coverage; Software [...] ...|$|R
40|$|AbstractProduct-Service Systems (PSS) {{represent}} a business proposition with potential {{to provide a}} wide range of economic, environmental, and social benefits, allowing achievingthe sustainability. However, PSS does not necessarily lead to sustainable solutions and this potential must be assessed in each case. In this sense, the aim {{of this paper is to}} investigate sustainable aspects of a ‘result oriented PSS’(a reverse osmosis water filter system) available in Brazil and compares it with the conventional product, the bottled water. Some aspects from the literature, mentioned as important in each sustainability dimension, were selected to analyze the PSS under study. A qualitative analysis was performed and demonstrates that in comparison with bottled water, the water filter PSS is competitive, satisfy customer needs, and has a relatively lower environmental impact. However, besides conceiving sustainable solutions, is necessary to identify which factors drive the implementation and diffusion of PSS. Some findings of this study suggest that the effects caused by unexpected consumer behavior and incorrect PSS application may compromise PSS sustainable performance <b>during</b> <b>operational</b> <b>phase.</b> An analysis of these effects during transition process is essential to successful sustainable strategies. The study aimed to contribute to the PSS empirical knowledge and to assist building a theoretical basis regarding PSS and sustainability...|$|E
40|$|The Waste Isolation Pilot Plant (WIPP), {{located in}} Carlsbad, New Mexico, USA, {{is a deep}} {{geologic}} repository for (TRU) wastes. Although the TRU waste shipping, handling, and disposal processes do not involve significant levels of radiation exposure, protecting workers, the public, and the environment from radiological harms {{has always been a}} high priority at WIPP. “Start Clean and Stay Clean ” is the operational philosophy of the repository. Before the repository was opened for waste disposal, extensive environmental measurements were performed to characterize the radiation background of the disposal site and its surrounding areas. Radiobioassay analyses were also conducted to determine the baseline radioactivity in WIPP workers and random samples of the general population in Carlsbad. ALARA (maintaining radiation doses at levels that are as low as reasonably achievable) has been an integral part of WIPP facility design and operational processes. The repository is continuously striving for radiation exposure minimization. This paper describes the safety measures of the TRU waste transportation process, baseline radiobioassay and environmental background measurements. It also discusses the radiological control and environmental protection programs <b>during</b> <b>operational</b> <b>phase.</b> The effectiveness of these programs is evaluated, based on the radiological safety results since the WIPP began its disposal operations in March 1999...|$|E
40|$|Product-Service Systems (PSS) {{represent}} a business proposition with potential {{to provide a}} wide range of economic, environmental, and social benefits, allowing achieving the sustainability. However, PSS does not necessarily lead to sustainable solutions and this potential must be assessed in each case. In this sense, the aim {{of this paper is to}} investigate sustainable aspects of a "result oriented PSS" (a reverse osmosis water filter system) available in Brazil and compares it with the conventional product, the bottled water. Some aspects from the literature, mentioned as important in each sustainability dimension, were selected to analyze the PSS under study. A qualitative analysis was performed and demonstrates that in comparison with bottled water, the water filter PSS is competitive, satisfy customer needs, and has a relatively lower environmental impact. However, besides conceiving sustainable solutions, is necessary to identify which factors drive the implementation and diffusion of PSS. Some findings of this study suggest that the effects caused by unexpected consumer behavior and incorrect PSS application may compromise PSS sustainable performance <b>during</b> <b>operational</b> <b>phase.</b> An analysis of these effects during transition process is essential to successful sustainable strategies. The study aimed to contribute to the PSS empirical knowledge and to assist building a theoretical basis regarding PSS and sustainability...|$|E
40|$|System on Chip devices {{include an}} {{increasing}} number of embedded memory cores, whose test <b>during</b> the <b>operational</b> <b>phase</b> is often a strict requirement, especially for safety-critical applications. This paper proposes a new memory test method combining the characteristics of hardware and software solutions: the test is performed by the microcontroller/processor, while the code of the test instructions to be executed is generated on-the-fly by an ad hoc module, also in charge of checking the memory behavior. The solution is modular and does not require any modification either in the memory cores or in the processor. Moreover, it is well suited to be used for test <b>during</b> the <b>operational</b> <b>phase.</b> Experimental results, gathered by implementing some representative March elements and algorithms, show that the method guarantees higher defect coverage than software BIST and a test time comparable with that of traditional hardware BIST solutions with a reduced hardware cos...|$|R
30|$|As expected, {{there is}} a slight {{increase}} in the RMS differences and best-fit y-intercept with respect to the reference model (Table 4). However, this modification has very little effect on the squared correlation coefficient, MSC, or best-fit gradient. It should be noted that <b>during</b> the <b>operational</b> <b>phase,</b> the Fast-Track Core-Field Model will be used in addition to the Comprehensive or Dedicated Core-Field models.|$|R
40|$|Abstract—Nowadays, an {{increasing}} number of systems needs to be kept running for long periods without showing failures, but several factors compromise their correct behavior <b>during</b> the <b>operational</b> <b>phase.</b> Logs play a key role to address dependability issues of current systems and to enable proactive actions against failures (e. g., proactive maintenance, failure prediction). Never-theless, they may lack any information in case of software faults, which escape the testing phase and are activated on the field by complex environmental conditions. In this paper, we evaluate built-in logging capabilities of a software system, namely the Apache Web Server, by means of an extensive software fault injection campaign. We experience that, in most of cases, software faults lead to failures without leaving any information in Apache logs. For this reason, we provide a few guidelines for developers that can be used during the development cycle, in order to improve the effectiveness of logs <b>during</b> the <b>operational</b> <b>phase...</b>|$|R
40|$|A lined {{pipeline}} {{consists of}} an outer main load-bearing pipe of Carbon-Manganese steel, termed backing steel, and an inner corrosion resistant alloy layer, termed liner. The purpose of the liner is {{to serve as a}} membrane; protect the backing steel from the sour contents owing inside and thus prevent internally corrosion. The main challenge of lined pipelines arise because of its low bending capacity due to local buckling of the liner, termed wrinkling. In installation as well as in operation, the pipeline will be exposed to bending and wrinkling of the liner may occur if the imposed curvature is su cient. Based on previous work in a joint industry project[5], nite element basis for mechanical behaviour of lined pipelines in installation and operation have been developed in present the project. Di erent parameters that in uence the wrin- kling phenomena in installation have been studied. The nite element model - established in the present task - is able to predict the post-buckling behaviour of the liner. This open the possibility to determine a limiting bending strain/cur- vature on lined pipelines based on wrinkling height. The wrinkling behaviour <b>during</b> <b>operational</b> <b>phase</b> is brie y discussed. The analyses indicate that both existing wrinkles from installation and new wrinkles in the operation phase, did not grow when subjected to cycles of operational load conditions. wrinkles during cycles of operational load conditions...|$|E
40|$|Effectiveness {{of quality}} {{management}} {{in the effort to}} satisfy customers' expectations has been questioned both by academicians and practitioners. In the course of the evolution of quality, very important theories have been developed in the field but failed to satisfy customers' expectation. The aim {{of this paper is to}} examine the challenge and develop a new method to address it. Following a literature review on the evolution of the concept of quality, confusions and limitations in the present paradigm are clarified. Then the future quality paradigm is proposed, and two practical cases are presented to substantiate the new approach. Quality management evolved from product inspection at the final stages of the production process. Basically, manufacturers take care of quality up to the point where a product is delivered to a customer. Product failure occurs due to various reasons after purchase. However, this happened or discovered <b>during</b> <b>operational</b> <b>phase</b> of the product which subsequently result in dissatisfaction for the users after purchase. To address this misalignment, all inclusive approach called Lifecycle Quality came into being as the future generation's paradigm. Misalignment between the manufacturer and the customer's desire in the operational phases of a product life - time leads to market loss to the former and dissatisfaction to the latter. Considering lifecycle quality of the product will definitely resolve the occurrence of such undesired outcomes affecting the two parties...|$|E
40|$|Research {{activities}} of Vinca Institite {{have been based}} on two heavy water research reactors: 10 MW one, RA and zero power RB. Reactor RA was operational from 1962 to 1982. In 2010, spent fuel have been sent to the country of origin, and reactor now is in decommissioning. <b>During</b> <b>operational</b> <b>phase</b> of the reactor there were no recorded accidental releases into the environment just operational ones. Results of the environmental impact assessment, of the assumed emission of radionuclides, from the ventilation of nuclear reactor "RA" in Vinca, to the atmospheric boundary layer are presented in this paper. Evaluation was done by using the Gaussian straight-line diffusion model and taking into account characteristics of the reactor ventilation system, the assumed emission release of radioactivity (from the literature), site-specific meteorological data for six-year period and local topography around nuclear reactor, and corresponding dose factors for inventory of radionuclides. Based on the described approach, and assuming that the range of appropriate meteorological data for six year period for the application of described mathematical model is enough for this kind of analysis, it can be concluded that the nuclear reactor "RA", in the course of its work from 1962 to 1982, had no influence on the surrounding environment through the air above regulatory limits. [Projekat Ministarstva nauke Republike Srbije, br. III 45003...|$|E
50|$|Optimization and {{troubleshooting}} {{information is}} more typically used {{to aid in}} finding specific problems during the rollout phases of new networks or to observe specific problems reported by consumers <b>during</b> the <b>operational</b> <b>phase</b> of the network lifecycle. In this mode drive testing data is used to diagnose {{the root cause of}} specific, typically localized, network issues such as dropped calls or missing neighbour cell assignments.|$|R
30|$|Note {{that with}} either UHF or UWB signaling, readers {{synchronization}} is obtained <b>during</b> the system <b>operational</b> <b>phase</b> then, better performance {{can be obtained}} if compared with the token ring approach that defers reader activation over time in a TDMA fashion.|$|R
40|$|Long-Term Service Concession (LTSC) projects, {{including}} Public-Private Partnerships and Alliance Projects {{have been}} used since the mid- 1990 s to procure facilities and services associated with social and economic infrastructure, at state and national levels. A key feature of LTSC projects is that they generally require a group of organisations associated with the construction and ongoing delivery of services to form a Special Purpose Vehicle (SPV) whose role is to provide sufficiently compelling evidence of technical and financial competence as to win the right to run the concession for the client over an extended period. The primary considerations driving such procurement are to achieve value for money, significant innovation, appropriate risk transfer and superior whole oflife outcomes - frequently questions of value for money and whole-life outcomes are raised <b>during</b> the <b>operational</b> <b>phase</b> of a facility. It is apparent that such concessions assume a fundamentally different nature pre-and post-asset delivery once the service delivery phase commences, and that the composition of project players/responsibility for value delivery {{is at the heart}} of this change. This paper reports the preliminary findings of a multiple perspective study of key LTSC stakeholders to surface dimensions associated with the role of facility management that enable value maximisation. It concludes that, contrary to expectations based upon theory, the facility management function is often underutilised during asset feasibility and design stages and that this inevitably has a negative effect upon value maximisation <b>during</b> the <b>operational</b> <b>phase</b> of a LTSC. Further, a level of uncertainty can exist as to who will ultimately deliver concession services <b>during</b> the <b>operational</b> <b>phase,</b> and what their eventual scope will encompass...|$|R
40|$|The French {{national}} {{radioactive waste}} management agency (Andra) research program is dedicated to preparing the construction and operation of a deep geological disposal facility for high-level and intermediate-level long-lived radioactive waste (HL, IL-LLW) in the Callovo-Oxfordian claystone (COx). The characterization of the COx thermo-hydro-mechanical (THM) behavior, at different scales of interest, must gradually give relevant data for design and safety calculations. The effects of saturation and desaturation of COx claystone are studied in laboratory conditions (sample scale) and in situ (drift scale), {{in order to improve}} knowledge on ventilation effect at gallery wall as galleries will remains open <b>during</b> <b>operational</b> <b>phase</b> (more than 100 years for some specific galleries) in the repository. The Saturation Damaged Zone (SDZ) experiment is outlined and its results are discussed. This experimentation aims to change the relative humidity in an isolated portion of a gallery in order to follow the HM behavior of the surrounding rock mass. Drying and wetting cycles could induce in certain cases cracks and swelling and modify the hydromechanical behavior of the claystone around the gallery (Young modulus, strength, creep…). The long term behavior of the COx claystone at the vicinity of gallery is then studied by performing climatic, hydraulic, geological and geomechanical measurements. Results of the in situ experiment are discussed with respect to the identified process on samples. The discussion given on this paper intends to highlights the inputs from 7 years of an in situ experiment to better understand the unsaturated behavior of the COx claystone...|$|E
40|$|Virtual {{execution}} {{environments and}} middleware {{are required to}} be extremely reliable because applications running {{on top of them}} are developed assuming their correctness, and platform-level failures can result in serious and unexpected application-level problems. Since software platforms and middleware are often executed for long time without any interruption, large part of the testing process is devoted to investigate their behavior when long and stressful executions occur (these test cases are called workloads). When a problem is identified, software engineers examine log files to find its root cause. Unfortunately, since of the workloads length, log files can contain a huge amount of information and manual analysis is often prohibitive. Thus, de-facto, the identification of the root cause is mostly left to the intuition of the software engineer. In this paper, we propose a technique to automatically analyze logs obtained from workloads to retrieve important information that can relate the failure to its cause. The technique works in three steps: (1) during workload executions, the system under test is monitored; (2) logs extracted from workloads that have been successfully completed are used to derive compact and general models of the expected behavior of the target system; (3) logs corresponding to workloads terminated unsuccessfully are compared with the inferred models to identify anomalous event sequences. Anomalies help software engineers to identify failure causes. The technique can also be used <b>during</b> <b>operational</b> <b>phase,</b> to discover possible causes of unexpected failures by comparing logs corresponding to failing executions with models derived at testing time. Preliminary experimental results conducted on the Java Virtual Machine indicate that several bugs can be rapidly identified thanks to the feedbacks provided by our technique...|$|E
40|$|In 21 st century, {{convergences}} {{of technologies}} {{and services in}} heterogeneous environment have contributed multi-traffic. This scenario will affect computer network on learning system in higher educational Institutes. Implementation of various services can produce different types of content and quality. Higher educational institutes should have a good computer network infrastructure to support usage of various services. The ability of computer network should consist of i) higher bandwidth; ii) proper network design; and iii) higher performance of communication devices/servers. Thus, presently there is no software to plan and help network administrator in determine ability of network services during introduce a new service. Current approach using by network administrators are planning computer network performance via prediction and measure ability of real network performance using hardware/software network analyzer. This approach can influence several problems such as prediction without software always inaccurate {{and most of the}} software/hardware network analyzer in real network is limited by network interfaces. Therefore, to encounter these problems, network administrators need software that can plan and measure additional network resources. Thus, this study presents a novel approach for measurement and planning network performance management in heterogeneous environment. The main objectives of this research is to i) identify which approach and problem occurs in Malaysia higher educational institutes; ii) create simulation model that able to plan and measure network performance for various services; iii) software network analyzer development based on simulation model design; and iv) conduct an evaluation of simulation model and software development with real network. These objectives can achieve as follows: i) conduct a survey; ii) select appropriate mathematical formula to create simulation model; iii) select appropriate modeling application for software development; and iv) conduct verification and validation technique for simulation modeling and evaluation of software network analyzer. The results from survey show that most of the network administrators are using hardware/software network analyzer to measure network performance <b>during</b> <b>operational</b> <b>phase.</b> The minimum size of bandwidth capacity has contributed higher network utilization usage. It can generate network congestion and network service failure in higher educational institutes. We create suitable models to evaluate the network performance using Little Law and Queuing theory that can represent similar to hardware/software network analyzer. In order to get accuracy results on the performance of simulation model, we measure (verify and validate) data from lab experiment and real network environment. Development of software network analyzer is based on simulation model architecture. This software will undergo evaluation process using qualitative technique. As a result, this software prototyping can provide a good approximation of real functionality observed in the real network environment. In addition the software is capable of approximating the performance within a minimum error rate. This software network analyzer can significantly enhance to analyze and propose solution on computer network performance. Future work is to develop software network analyzer for planning, suggestion and analyzing computer network performance on wireless transmission (WLAN, WWAN and WiMax) and Ipv 6 protocol. We investigate how preparation and planning phases can be applied to heterogeneous environment in order to better utilize network resources. Our software network analyzer prototyping development is based on Fluke Optiview Network Analyzer. Before we develop any software prototype, it should define the following criteria: i) establish prototype objectives; ii) define prototype functionality; iii) develop prototype; and iv) evaluate prototype. Software network analyzer prototype consists of two phases: analyzing computer network performance under optimum condition and without optimum condition. Software network analyzer prototype was developed to measure and predict network activities based on offline condition. We use qualitative technique to measure our software network analyzer prototype to identify this software is able to plan, propose and analyze computer network performance. Evaluation of software network analyzer prototype is based on focus groups in University of Kuala Lumpur (UniKL). Six evaluators are experienced in education and industrial sector will select to complete the survey and interview task. Three evaluators will select who are experienced in industrial sector only, while, another three evaluators experienced in academic and industrial sector. All evaluators have experienced more than 6 to 13 years in network management field. All evaluators need to complete the following task such as: acceptance test, performance test, loading test, network responsive test and repetition test. A common strategy is to design, test, evaluate and then modify the design based on analysis of the prototype...|$|E
40|$|Dynamic {{modeling}} {{of the spacecraft}} and Saturn system, tracking data, including radio-metric and optical navigation data, and measurement modeling associated with the final trajectory analysis are described. Navigation predictions produced <b>during</b> the <b>operational</b> <b>phase</b> are compared with the final trajectory {{in order to gain}} insight into navigation performance and maneuver execution errors. Special attention is given to refinement of the dynamical environment of Saturn, particularly Titan, during the first two orbits...|$|R
50|$|The Green Star {{rating system}} assesses the {{sustainability}} of projects at all stages of the built environment lifecycle. Ratings can be achieved at the planning phase for communities, during the design, construction or fitout phase of buildings, or <b>during</b> the ongoing <b>operational</b> <b>phase.</b>|$|R
40|$|Abstract. The {{methods for}} {{extending}} binary support vectors machines (SVMs) can be broadly {{divided into two}} categories, namely, 1 -v-r (one versus rest) and 1 -v- 1 (one versus one). The 1 -v-r approach tends to have higher training time, while 1 -v- 1 approaches tend to create {{a large number of}} binary classifiers that need to be analyzed and stored <b>during</b> the <b>operational</b> <b>phase.</b> This paper describes how rough set theory may help in reducing the storage requirements of the 1 -v- 1 approach in the <b>operational</b> <b>phase.</b> ...|$|R
40|$|Concerning {{socio-economic}} {{development of}} Bhutan, Hydropower development plays a vital role. Envisaging a total theoretical potential of 30, 000 MW, according to Power System Master Plan, 2002, the government now {{has taken up}} measures for accelerated development to harness 11777 MW by year 2020, and more beyond this time frame. Nevertheless, {{there is always a}} difficulty to harness the great hydropower potential due to the uncertainties and challenges faced in tunneling through Himalayan Geology. The challenges {{can be attributed to the}} difficulty in obtaining a reliable & better early investigation results due to inaccessibility of the area. The unpredictable geological conditions in the Himalayan region in general, and the difficulty for geotechnical studies have been the greatest setbacks to find better options for locating and aligning the underground openings. These have caused severe stability problems during construction of underground cavities or tunnels in Bhutan, mainly related to rock mass quality and rock stresses. Tala Hydroelectric Project with an installed capacity of 1020 MW on the river Wangchu Basin of Western Bhutan is so far the biggest project constructed (1997 – 2007). This project has suffered rock engineering problems during construction to post construction phases and continuing still in the operation period. The constructions of almost all the major components of the project have met with stability challenges. The machine and transformer caverns are still experiencing two main problems: i) the failure of rock bolts which fly out of caverns’ walls and, ii) convergence of walls, since the construction period and are continuing <b>during</b> <b>operational</b> <b>phase</b> too. These are serious problematic issues, creating hazardous situations and uncertain long term stability may affect the operation of the plant. In this thesis, efforts have been made to study the problems encountering in the machine hall of Tala Hydroelectric Project and finally determined the main causes of the resulting instabilities of the case. After having addressed the problems in Tala, this work started on reviewing the case based mainly on geology, rock mass quality, in-situ stresses, geometry, and excavation & supports. Chukha Hydroelectric Project lying 2 km upstream of Intake for Tala, along the same river basin (1974 – 1988), on the other hand, has not faced such problems during operation period. A review study is conducted in a similar manner on Chukha project as well. The works throughout are focused on machine halls of the two projects. Qualitative studies of the machine halls of two projects have been carried out to compare and identify the most likely aspects of stability problems. The work involves theoretical study and application of engineering geology and rock engineering in reviewing of the cases. The engineering geological investigations of respective phases have been reviewed and through evaluation of deviations, the causes of the instabilities are ascertained. It is found that Tala Cavern is located in closer proximity to MCT and narrower valley than Chukha powerhouse, which signifies high stress regime. Weak rocks such as phyllite & quartzitic phyllite dominate the rock mass in Tala, while Chukha cavern constitutes better grade of metamorphic rock like biotite gneisses. The joints are normally clean in Chukha but infilling materials prevail in Tala with puckered and folded foliations. All the rock mass properties and classifications reveal weaker rock mass quality in Tala than the later project. Based on the above studies, this thesis presents a discussion on the probable reasons of stability problems being faced in Tala cavern. It is evaluated that the powerhouse is constructed in a high stress regime influenced due to tectonic activity, topography and overburden. Besides, the rock mass quality is found to be poor and deteriorated further during excavation. The failures of rock bolts in sections are mainly due to excessive overburden loads and existing weak rock mass conditions in folds enabling development of stresses under compression and tension in varying depth. The creeping nature of the rock mass prevail due to high horizontal stress, time-dependent behavior of highly jointed weak rock mass, reduced shear strength and unfavorable orientation of the cavern with respect to discontinuities. Geometry for shape and dimensions play important roles for the stability of the underground caverns. Beyond qualitative analysis, Examine 2 D program has been used to investigate the influence of geometry and induced stresses due to excavation. The analysis results indicated higher relative stress regime situation and more relative deformations for Tala compared to Chukha, which has quite favorable stress regime with negligible elastic deformation along the walls. The zones of influence of induced stresses and failure trajectories expand in larger area and in fact they intersect between the two caverns of Tala. At the end, some recommendations are put forth which may be used for successful construction and implementation of future projects under similar conditions in the vicinity of tectonic thrusts. This study has found that fixing location of underground cavity must be studied and options to be explored through qualitative judgment of investigations. The results of the investigation phases show great variations. These make the input parameters for any analysis unreliable and uncertain to a greater extent. An attempt to improve the quality judgment through involvement of experienced and right professional is mandatory for any future project. The designs pertaining to shapes and dimensioning under such conditions need serious attention. Most importantly, proper sequential and careful excavation must be incorporated at all times in such geology. Implementation of any future project must be documented properly and experiences from such cases may be made available to achieve successful tunneling in the Himalayan region. </p...|$|E
50|$|AG Real Estate {{is active}} {{both as an}} equity {{investor}} {{as well as a}} debt investor across the entire risk spectrum. The company provides financing solutions for mature real estate holdings as well as development projects. The assets it finances are primarily office buildings and retail space located in France and the Benelux. AG Real Estate especially focuses on providing long-term financing solutions, particularly <b>during</b> the <b>operational</b> <b>phase</b> of its projects, in the form of public-private partnerships (PPP).|$|R
40|$|During a {{dedicated}} two-year-long research effort, the CTBUH analyzed all life phases {{of a tall}} building’s structural system: the extraction and production of its materials, transportation to the site, construction operations, final demolition of the building, and the end-of-life of the materials. The impact of the building structure <b>during</b> the <b>operational</b> <b>phase</b> (i. e., impact on daily energy consumption, maintenance, and suitability to changes) was also investigated, but no significant impacts were identified during this phase...|$|R
40|$|To {{guarantee}} safety <b>during</b> the <b>operational</b> <b>phase</b> {{of a final}} repository sensing {{systems for}} monitoring safety relevant parameters in underground cavities are indispensable. At the same time long-term safety analyses performed prior to the construction and operation can be verified to a certain extend by the measurements obtained <b>during</b> the <b>operational</b> <b>phase.</b> In a salt environment a major task is the thermomechanical monitoring due to the heat produced by the high level waste, {{which leads to a}} higher convergence of the cavities. Of great interest is also the monitoring of gas occurrence, especially for harmful gases like methane and carbon dioxide. In the framework of a current research project sensors based on fibre optic technology are under development, which could be the basis for such a monitoring system. Glass fibre technology offers definite advantages. Optical fibres not only withstand chemical corrosion and high temperatures, but their immunity to electromagnetic interference and radiation ensure high reliability and superior performance. The state-of-the-art, the planned future system development, and a draft concept of a monitoring system for a German deep geological repository are given in the presentation...|$|R
40|$|A {{kinesthetic}} tactual display may {{be effectively}} {{used as a}} control aid per previous flight tests. Angle of attack information would be continuously presented to a pilot, via this display, <b>during</b> critical <b>operational</b> <b>phases</b> where stalls are probable. A two phase plan for evaluating this concept is presented. A first development phase would encompass: (1) display fabrication for a conventional control yoke; (2) its installation, together with other necessary instrumentation, in an experimental aircraft; and (3) preliminary flight testing by experienced pilots...|$|R
40|$|International Telemetering Conference Proceedings / November 19 - 21, 1979 / Town and Country Hotel, San Diego, CaliforniaThe {{launch and}} orbital {{phase of the}} Shuttle is {{comparable}} to the Apollo flight. The entry phase, on the other hand, presents many new challenges to a reusable vehicle. To explore this area and provide more detailed data than that required for flight, the Shuttle technology flight instrumentation (TFI) system was proposed. This paper discusses the TFI, which records flight data <b>during</b> the <b>operational</b> <b>phase</b> of the Space Shuttle. It also deals with pertinent background information, such as Shuttle operation, flight verification, and instrumentation provided for the developmental and <b>operational</b> <b>phase...</b>|$|R
