48|10000|Public
50|$|An {{end-to-end}} protocol {{built on}} top of that provided a reliable transport service, {{on top of}} which applications were built. It provided a reliable sequence of user-visible data units called letters, rather than the reliable byte stream of TCP. The transport protocol was able to deal with out-of-order and unreliable delivery of datagrams, using the now-standard mechanisms of end-end acknowledgments and timeouts; it also featured sliding windows and <b>end-to-end</b> <b>flow</b> <b>control.</b>|$|E
50|$|TCP uses an <b>end-to-end</b> <b>flow</b> <b>control</b> {{protocol}} {{to avoid having}} the sender send data too fast for the TCP receiver to receive and process it reliably. Having a mechanism for flow control is essential {{in an environment where}} machines of diverse network speeds communicate. For example, if a PC sends data to a smartphone that is slowly processing received data, the smartphone must regulate the data flow {{so as not to be}} overwhelmed.|$|E
50|$|CPorts {{also contain}} state {{variables}} {{that can be}} used to track how much buffer space the peer or connected CPort has. This is used to prevent the situation whereby a CPort sends segments to a CPort which has insufficient buffer space to hold the data, thus leading to stalled data traffic. Unless resolved fast, this traffic jam at the destination quickly grows into a network-wide gridlock. This is highly undesirable as it can greatly affect network performance for all users or, worse, can lead to deadlock situations. The described L4 mechanism is known as <b>end-to-end</b> <b>flow</b> <b>control</b> (E2E FC) because it involves the endpoints of a connection.|$|E
40|$|Many <b>end-to-end</b> {{feedback}} <b>flow</b> <b>control</b> protocols {{experience the}} rate oscillations caused by latency phase shift (LPS). This problem comes from time-varying bandwidth and non-zero feedback latency. A temporal <b>flow</b> <b>control</b> (TFC) protocol called MTS (Multiple-Time-Scale) was proposed to {{significantly reduce the}} oscillations in our earlier publication [2]. In this paper, the class of temporal <b>flow</b> <b>control</b> is further studied and a fundamental theorem relating LPS rate oscillations to the ratio of feedback latency to available bandwidth window duration is proved. The MTS protocol is generalized and two propositions showing {{the advantages of the}} generic MTS protocol is proved. Simulation results show MTS significantly improves network performance in terms of stability, throughput and cell loss. In particular, MTS smoothens the output traffic very effectively, thus further reducing the traffic fluctuations. 1 Introduction Rate-based <b>end-to-end</b> feedback <b>flow</b> <b>control</b> (FC) protocol [...] ...|$|R
40|$|Abstract. We {{consider}} {{the problem of}} logical data erasure, contrasting with physical erasure {{in the same way}} that <b>end-to-end</b> information <b>flow</b> <b>control</b> contrasts with access control. We present a semantic hierarchy for erasure policies, using a possibilistic knowledge-based semantics to define policy satisfaction such that there is an intuitively clear upper bound on what information an erasure policy permits to be retained. Our hierarchy allows a rich class of erasure policies to be expressed, taking account of the power of the attacker, how much information may be retained, and under what conditions it may be retained. While our main aim is to specify erasure policies, the semantic framework allows quite general information-flow policies to be formulated for a variety of semantic notions of secrecy. ...|$|R
40|$|The {{demand for}} Internet {{bandwidth}} has grown {{rapidly in the}} past few years. A new generation of broadband satellite constellations promise to provide high speed Internet connectivity to areas not served by optical fiber, cable or other high speed terrestrial connections. However, using satellite links to supply high bandwidth has been difficult due to problems with inefficient performance of the Internet's TCP/IP protocol suite over satellite. We describe an architecture for improving the performance of TCP/IP protocols over heterogeneous network environments, especially networks containing satellite links. The end-to-end connection is split into segments, and the protocol on the satellite segment is optimized for the satellite link characteristics. TCP congestion control mechanisms are maintained on each segment, with some coupling between the segments to produce the effect of <b>end-to-end</b> TCP <b>flow</b> <b>control.</b> We have implemented this design and present results showing that using such [...] ...|$|R
40|$|Data centers {{traffic is}} {{composed}} by numerous latency-sensitive "mice" flows, which is consisted of only several packets, {{and a few}} throughput-sensitive "elephant" flows, which occupy more than 80 % of overall load. Generally, the short-lived "mice" flows induce transient congestion and the long-lived "elephant" flows cause persistent congestion. The network congestion is a major performance inhibitor. Conventionally, the hop-by-hop and <b>end-to-end</b> <b>flow</b> <b>control</b> mechanisms are employed to relief transient and persistent congestion, respectively. However, in face {{of the mixture of}} elephants and mice, we find the hybrid congestion control scheme including hop-by-hop and <b>end-to-end</b> <b>flow</b> <b>control</b> mechanisms suffers from serious performance impairments. As a step further, our in-depth analysis reveals that the hybrid scheme performs poor at latency of mice and throughput of elephant. Motivated by this understanding, we argue for isolating mice and elephants in different queues, such that the hop-by-hop and <b>end-to-end</b> <b>flow</b> <b>control</b> mechanisms are independently imposed to short-lived and long-lived flows, respectively. Our solution is readily-deployable and compatible with current commodity network devices and can leverage various congestion control mechanisms. Extensive simulations show that our proposal of isolation can simultaneously improve the latency of mice by at least 30 % and the link utilization to almost 100 %...|$|E
40|$|A Network on Chip (NoC) with <b>end-to-end</b> <b>flow</b> <b>control</b> is {{modelled}} by a cyclo-static dataflow graph. Using {{the proposed}} model together with existing analysis algorithms, we size the buffers {{in the network}} interfaces. We show, {{for a range of}} NoC designs, that buffer sizes are determined with a run time comparable to existing analytical methods, and results comparable to exhaustive simulation. ...|$|E
40|$|Despite {{improvements}} in network interfaces and software messaging layers, software communication overhead still dominates the hardware routing cost in most systems. In this study, we identify {{the sources of}} this overhead by analyzing software costs of typical communication protocols built atop the active messages layer on the CM- 5. We show that up to 50 – 70 % of the software messaging costs are {{a direct consequence of}} the gap between specific network features such as arbitrary delivery order, finite buffering, and limited fault-handling, and the user communication requirements of in-order delivery, <b>end-to-end</b> <b>flow</b> <b>control,</b> and reliable transmission. However, virtually all of these costs can be eliminated if routing networks provide higher-level services such as in-order delivery, <b>end-to-end</b> <b>flow</b> <b>control,</b> and packet-level fault-tolerance. We conclude that significant cost reductions require changing the constraints on messaging layers: we propose designing networks and network interfaces which simplify or replace software for implementing user communication requirements. ...|$|E
40|$|The {{existing}} Ethernet and Token Ring based networks, {{known as}} legacy LANs, {{are no longer}} able to satisfy the constantly growing demand for more bandwidth and better quality of service. However, switching technology is a solution that seems to be able to cope with further expanding requirements. Introducing switches with new <b>flow</b> <b>control</b> schemes makes the networks faster and more efficient but, at the same time, this can cause other problems. An example is the interaction between the well-established endto -end TCP <b>flow</b> <b>control</b> and the hop-by-hop switch <b>flow</b> <b>control.</b> The interaction between these two <b>flow</b> <b>control</b> mechanisms is too complex to be solved using theoretical analysis and hence simulation modelling has been used. The advantages and drawbacks of using both <b>flow</b> <b>control</b> schemes firstly independently and secondly together has been investigated and the results are presented and discussed in the paper. Keywords <b>End-to-end,</b> hop-by-hop, TCP, <b>flow</b> <b>control,</b> 802. 3, switched LANs 1 INT [...] ...|$|R
30|$|In {{addition}} to finding suboptimal {{solutions for the}} original max-weight optimization problem, utility optimization based protocol design using the back-pressure framework has also being extensively studied. In [30], Georgiadis et al. claimed that the back-pressure algorithm performs within O(1 /V) of optimal throughput utility, with O(V) average delay, where V is a control parameter that can be chosen as large as desired. This gives an explicit [O(1 /V),O(V)] utility-delay tradeoff. With different definitions of the utility functions, [31 - 33] proposed different back-pressure policies that may jointly consider power control, fairness, <b>end-to-end</b> delay, and <b>flow</b> <b>control.</b>|$|R
40|$|Supporting data {{applications}} over networks comprising both wireless and wireline links is {{of increasing}} importance for both military and commercial systems. Many standard data applications on current wireline networks {{are based on}} TCP/IP, the <b>end-to-end</b> <b>flow</b> and congestion <b>control</b> protocol widely used on the Internet, {{so that it is}} of crucial importance to devise network level controls that enable TCP to perform well when the path from source to destination includes one or more wireless links. Since TCP has been recently shown to perform poorly in the presence of random loss, its performance over a lossy wireless link subject to deep fades and other impairments may be unsatisfactory. In this paper, we show that a suitable link level error recovery mechanism can "hide" the fluctuations of the wireless medium from TCP, and we provide an analytical framework for predicting TCP performance {{as a function of the}} wireless channel characteristics and the size of the wireless-wireline interface [...] ...|$|R
40|$|Be {{faced with}} {{the rapid growth of}} the Internet, we are now finding efficient, {{distributed}} and dynamic network control mechanisms that can avoid network congestion and adapt to the complexity of the Internet environment. In this paper, from the viewpoint of evolutionary game theory, we proposed an <b>end-to-end</b> <b>flow</b> <b>control</b> mechanism using evolutionary strategies. Theoretical analysis and simulation results show the property and validity of this mechanism...|$|E
40|$|This paper {{examines}} a hop-by-hop {{flow control}} scheme and compares {{it with the}} operation of TCP <b>end-to-end</b> <b>flow</b> <b>control.</b> The individual link control scheme is described. Both schemes are simulated under bursty traffic in a network with 50 nodes and 96 links. It is found that the hop-by-hop scheme results in similar levels of utilization to TCP, but that the average queue size is 30 times smaller...|$|E
40|$|Abstract — In this paper, {{we study}} a cross-layer optimiza-tion {{problem for a}} network that {{consists}} of one wireline core network and multiple wireless access networks. We consider four layers among five layers in the network layering architecture: application characteristics through the utility function and {{quality of service requirements}} in the application layer; <b>end-to-end</b> <b>flow</b> <b>control</b> in the transport layer; opportunistic scheduling in the data link layer; adaptive modulation and coding in the physical layer. We formulate a stochastic optimization problem considering above four layers and both wireline and wireless parts of the network jointly that results in a utility-based joint <b>end-to-end</b> <b>flow</b> <b>control</b> and opportunistic scheduling problem for the integrated wireless and wireline network. We solve the problem by using a dual approach and a stochastic sub-gradient algorithm. The developed algorithm can be implemented in a distributed way: vertically among four layers and horizontally among all entities in the network, clearly showing what should be done in each layer and each entity and what parameters should be exchanged between layers vertically and between network entities horizontally. I...|$|E
40|$|This paper {{studies the}} problem of {{congestion}} control on wireless networks. A dynamical model for the <b>end-to-end</b> network <b>flow</b> <b>control</b> is proposed, which exploits the differentiation between congestion loss and physical channel error loss. The introduction of a specific wireless model is motivated by the distinctive presence of channel errors, which are often not known exactly. We assume that each wireless link is associated with an additional error function {{that depends on the}} current flow along the link and which accounts for the packet loss rate caused by the physical channel. This leads to a new dynamic <b>flow</b> <b>control</b> scheme that naturally extends a known mathematical model for the fluid flow approximation of the Transmission Control Protocol for wireline networks. The main objective of this work is to study the dynamical properties of the new model: we analyze its nonlinear dynamics, derive its stability properties, and study its robustness to delays. We also present and discuss some ns- 2 simulations of its dynamics. This work additionally looks at the actual implementation of the proposed scheme: by requiring only modifications to the application layer rather than the transport one, no alterations to the network infrastructure or transport protocols are needed. The article argues that the new scheme appears to be not only theoretically meaningful but also practically relevant for an application layer implementation. Copyright c © 2011 John Wiley & Sons, Ltd. key words: Nonlinear systems, stability, robustness, systems with delays, transport protocols...|$|R
40|$|Abstract — In this paper, {{we develop}} a novel {{analytical}} framework for modeling and quantifying {{the performance of}} windowcontrolled multimedia flows in a hybrid wireless/wired network. The framework captures the traffic characteristics of windowcontrolled flows and is applicable to various wireless links and packet transmission schemes. We show analytically {{the relationship between the}} sender window size, the wireless link throughput distribution, and the delay distribution. We then substantiate the analysis by demonstrating how to statistically bound the <b>end-to-end</b> delay of <b>flows</b> <b>controlled</b> by a TCP-like Datagram Congestion Control Protocol (DCCP) over an M-state Markovian wireless link. Simulation results validate the analysis and demonstrate the effectiveness and efficiency of the proposed delay control scheme. The scheme can also be applied to other window-based transport layer protocols. Index Terms — Communication system performance, protocols, modeling, algorithms, resource management, multimedia systems...|$|R
40|$|International audienceSecurity {{engineering}} must {{be integrated}} with {{all stages of}} application specification and development to be effective. Doing this properly is increasingly critical as organisations rush to offload their software services to cloud providers. Service-level agreements (SLAs) with these providers currently focus on performance-oriented parameters, which {{runs the risk of}} exacerbating an impedance mismatch with the security middleware. Not only do we want cloud providers to isolate each of their clients from others, we also want to have means to isolate components and users within each client's application. We propose a principled approach to designing and deploying end-to-end secure, distributed software by means of thorough, relentless tagging of the security meaning of data, analogous to what is already done for data types. The aim is to guarantee that [...] above a small trusted code base [...] data cannot be leaked by buggy or malicious software components. This is crucial for cloud infrastructures, in which the stored data and hosted services all have different owners whose interests are not aligned (and may even be in competition). We have developed data tagging schemes and enforcement techniques that can help form the aforementioned trusted code base. Our big idea [...] cloud-hosted services that have <b>end-to-end</b> information <b>flow</b> <b>control</b> [...] preempts worries about security and privacy violations retarding the evolution of large-scale cloud computing...|$|R
40|$|The {{price we}} pay for using TCP This paper {{examines}} a hop-by-hop flow control scheme and compares it with the operation of TCP <b>end-to-end</b> <b>flow</b> <b>control.</b> The individual link control scheme is described. Both schemes are simulated under bursty traffic in a network with 50 nodes and 96 links. It is found that the hop-by-hop scheme results in similar levels of utilization to TCP, but that the average queue size is 30 times smaller...|$|E
40|$|IRMA is a {{reliable}} multicast architecture that guarantees reliable, sequenced, and loosely synchronized delivery of multicast streams. IRMA provides ACK-based reliability, hybrid local server-initiated and sender-initiated loss recovery, {{and support for}} <b>end-to-end</b> <b>flow</b> <b>control</b> and congestion control. Unlike most contemporary work, IRMA supports TCP as the reliable multicast transport protocol at the end host without modifications. IRMA has been instantiated in a laboratory testbed, and its performance has been measured in various scenarios. Preliminary performance results show that IRMA is efficient and adaptive to {{the dynamics of the}} network...|$|E
40|$|Networks are {{emerging}} as a possible solution for future on-chip interconnects. In this chapter, we show how networks on chip (NoC) are similar to and differ from both off-chip networks (e. g., computer networks) and current on-chip interconnects (e. g., buses). We re-examine their communication services {{in the context of}} NoCs. To enable a clean separation between the NoC and IP blocks, we provide services that abstract from network implementations. We define a request-response transaction model similar to bus protocols, to make our approach backward compatible. To exploit the full power of NoCs, we also provide connection-oriented communication with differentiated services. Examples are bandwidth guarantees, transaction orderings, and <b>end-to-end</b> <b>flow</b> <b>control...</b>|$|E
40|$|Voice over IP {{and video}} {{applications}} {{continue to increase}} the amount of traffic over the Internet. These applications utilize the UDP protocol because TCP is not suitable for streaming applications. The <b>flow</b> and congestion <b>control</b> mechanisms of TCP can change the connection transmission rate too drastically, affecting the user-perceived quality of the transmission. Also, the TCP protocol provides a level of reliability that may waste network resources, retransmitting packets that have no value. On the other hand, the use of <b>end-to-end</b> <b>flow</b> and congestion <b>control</b> mechanisms for streaming applications has been acknowledged as an important measure to ease or eliminate the unfairness problem that exist when TCP and UDP share the same congested bottleneck link. Actually, router-based and end-to-end solutions have been proposed to solve this problem. This thesis introduces a new end-to-end protocol based on TCP SACK called SF-SACK that promises to be smooth enough for streaming applications while implementing the known <b>flow</b> and congestion <b>control</b> mechanisms available in TCP. Through simulations, it is shown that in terms of smoothness the SF-SACK protocol is considerably better than TCP SACK and only slightly worse than TFRC. Regarding friendliness, SF-SACK is not completely fair to TCP but considerably fairer than UDP. Furthermore, if SF-SACK is used by both streaming and data-oriented applications, complete fairness is achieved. In addition, SF-SACK only needs sender side modifcations and it is simpler than TFRC...|$|R
30|$|To {{improve the}} {{congestion}} collapse problem, the early TCP protocol prompted {{the study of}} end-to-end congestion avoidance and control algorithms [1]. Recently, several applications, such as IPTV and VoIP, using User Datagram Protocol (UDP) without employing <b>end-to-end</b> <b>flow</b> and congestion <b>control,</b> are increasingly being deployed over the Internet. When UDP coexists with TCP, it induces not only a congestion collapse problem but also an unfairness problem that each flow cannot get the same treatment, causing an unstable Internet and lower link utilization. The congestion control methodologies can be categorized as the Primal and the Dual [2]. The Primal congestion control is the source node dynamically adjusting the sending rate or window sizes depending on the indication information fed back from the Internet. Due to the limitations of Prime methodology, the Dual plays a more important role through assisting {{in the provision of}} more accurate and quick feedback. The congest control algorithm for Dual is implemented in routers gathering traffic flow information, such as flow numbers and traffic load, and sends implicit or explicit feedback to the sender or receiver node for revising the sending rate or making active queue management.|$|R
40|$|This paper {{analyzes}} {{the performance of}} an optical packet switch architecture with highly distributed control, designed for interconnection of cluster switches in a simulated data center traffic environment. The system under development can be scaled up to a very large ports count, in the thousand order, enabling interconnection of {{a great number of}} servers. An important feature of this optical packet switch is the few nanoseconds reconfiguration time, regardless of the port count. This characteristic is essential to minimize the <b>end-to-end</b> latency. <b>Flow</b> <b>control</b> is employed to regulate packets transmission between the electronic buffers of the ingress and egress ports. The limited contention resolution capability of the optical packet switch is compensated by these electronic buffers and a retransmissions algorithm. We investigate the performance of the switch with 1024 in/out ports in terms of data loss, throughput and latency with a data center-like traffic model. The results show that increasing the electronic input buffer size allows lower packet loss at the expense of higher latency. A buffer size in the order of 20 times the average packet length proves to be adequate to obtain a packet loss lower than 10 - 5 and latency below 1 µs when managing a sustained normalized input load of 0. 3. This traffic intensity is more than triple the average utilization of current data centers aggregation switches. Packet loss lower than 10 - 4 can be achieved for input load up to 0. 4, keeping latency at 1. 4 µs...|$|R
40|$|In recent years, {{extensive}} research {{is in progress}} to enhance TCP performance for wireless networks. The assumptions made by TCP for wireline networks do not hold for wireless links. TCP uses <b>end-to-end</b> <b>flow</b> <b>control,</b> congestion control and error recovery to provide reliability in the wireline networks. Wireless communication has quite different characteristics such as high bit error rates, high latency, limited bandwidth, multi-path fading of the signals and handoffs due to mobility. These spurious characteristics degrade the performance of TCP in wireless networks. In this paper, we discuss the various circumstances under which TCP implementation results in degraded performance and various solutions proposed to overcome these problems...|$|E
40|$|We {{develop a}} {{mathematical}} model within a game theoretical framework for variable rate real time traffic at a bottleneck node. We address not only the flow control problem, but also pricing and allocation of a single resource among users. A distributed, <b>end-to-end</b> <b>flow</b> <b>control</b> is proposed by introducing a cost function, defined as the difference of pricing and utility functions. For two different utility functions, there exists a unique Nash equilibrium in the underlying game. The paper also introduces three distributed update algorithms, parallel, random and gradient update, which are globally stable under reasonable conditions. The convergence properties and robustness of each algorithm are studied through extensive simulations...|$|E
40|$|The {{traditional}} assumptions made by TCP {{about the}} operation of wired networks are often found to be invalid for wireless networks. Standard TCP semantics such as <b>end-to-end</b> <b>flow</b> <b>control,</b> congestion control mechanisms and error recovery provide reliability in wired networks. However, wireless communication systems have different characteristics when compared to wired networks that include higher bit error rates, higher latency, limited bandwidth, multipath fading of the signals and handoff. In this paper, we propose an enhancement to TCP that we shall call ETCP, which improves upon conventional TCP when it {{is applied to the}} wireless environment. Our simulation results show significant improvements to TCP performance with respect to packet loss detection...|$|E
40|$|In this chapterwe {{described}} the main principles {{in designing the}} networking and transport layers of NoCs. These layers include the specification of the following NoC characteristics: switching technique, topology, addressing and routing, and <b>end-to-end</b> congestion and <b>flow</b> <b>control</b> schemes. We presented this complex problem as a constrained optimization process. The NoC designer should minimize {{the cost of the}} NoC which is expressed in terms of VLSI area and power consumption added to his overall chip design. The constraints are the level of services (service classes) to be provided for the traffic patterns of the SoC under consideration. Since NoCs can be designed anew for each SoC implementation, this optimization process is expected to be repeated for each new SoC design, using NoC CAD tools. Following this definition, {{it is clear that the}} SoC traffic characteristics strongly impact the NoC characteristics. We therefore classified SoCs according to how much is known in advance about their functionality, and consequently about their expected module-to-module communication patterns (Fig. 5. 1). We reviewed topical state-of-the-art solutions for each of the important NoC characteristics: switching mechanisms, OoS implementations, topological design, routing mechanisms, congestion and <b>flow</b> <b>control</b> techniques. We showed how the NoC model impacts the choices available, for each of these, as weIl as the relationships and trade-offs between them...|$|R
3000|$|... is a {{continuously}} differentiable, increasing, and concave {{utility function}} of <b>end-to-end</b> <b>flow</b> rates, that is, the aggregated flow rate [...]...|$|R
3000|$|Assume {{that there}} is a set S of <b>end-to-end</b> <b>flows</b> in the WMN, where each flow s∈S is {{characterized}} with a source-destination pair s [...]...|$|R
30|$|In wired networks, router-assisted {{flow control}} {{mechanisms}} (e.g., [6]) {{have been proposed}} for use alongside end-host based congestion control protocols. Pure <b>end-to-end</b> <b>flow</b> <b>control</b> schemes cannot provide isolation between flows or ensure rate or delay guarantees; they instead depend on these router-assisted mechanisms for support. We are interested in evaluating the feasibility of establishing similar controls at gateway mesh routers in WMNs providing last mile access. Traffic flows in these networks are primarily directed towards or away from the gateway. This allows the gateway to develop a unified view of the end-to-end flow rates of flows through this gateway, making it a suitable choice for enforcing various resource allocation policy objectives. In particular, we wish to use gateway-enforced control to address flow rate unfairness in WMNs.|$|E
40|$|In recent years, many {{extensive}} {{studies have}} been performed that have attempted to improve the performance of TCP for wireless networks. The common assumptions made by TCP for wired networks definitely do not hold for wireless networks. TCP with its semantics such as <b>end-to-end</b> <b>flow</b> <b>control,</b> a congestion control mechanism and error recovery provide reliability in wired networks. Wireless communication has significantly different characteristics compared to wired networks such as higher bit error rates, higher latency, limited bandwidth, multi-path fading of the signals and handoff. In this paper, we propose an enhancement to TCP that will {{be referred to as}} E-TCP, which improves upon conventional TCP congestion and flow control in a wireless environment. Our simulation results show significant improvements to TCP performance can be achieved...|$|E
40|$|We have {{proposed}} the diffusion-type flow control mechanism {{as a solution}} of severely time-sensitive flow control required for high-speed networks. In this mechanism, each node in a network manages its local traffic flow {{on the basis of}} only the local information directly available to it, by using predetermined rules. In the current IP based networks, <b>end-to-end</b> <b>flow</b> <b>control</b> including TCP is widely used. However, end-to-end control cannot be applied to decision-making in a time-scale shorter than the round-trip delay, since end hosts provide the flow control. In this paper, we investigate the performance of diffusion-type flow control and TCP by using the simulation tool ns 2. Then, we show that diffusion-type flow control can coexist with TCP and can be complementary to each other...|$|E
40|$|Graduation date: 2012 Physical-Layer Network Coding (PNC) is a {{promising}} technique that has great potentials {{for improving the}} achievable data rates of <b>end-to-end</b> <b>flows</b> through higher packet transmission rates, thereby increasing the overall network throughput. In this thesis, we study {{the performance of the}} PNC transmission techniques for unidirectional <b>end-to-end</b> <b>flows</b> in multi-hop wireless networks, and compare it with that of the traditional transmission techniques. We first derive the bit-error rate (BER) that the PNC transmission technique achieves. Then, using the derived BER, we evaluate and quantify the achievable network throughput under both the PNC transmission technique and the traditional technique, where the network throughput is measured as the aggregate/sum of all end-to-end flows' achievable data rates in the wireless network. Using extensive simulations, we show that PNC increases the overall achievable <b>end-to-end</b> <b>flow</b> throughput in multi-hop wireless networks, especially under medium to high signal-to-noise ratios...|$|R
30|$|We repeat these {{experiments}} using FQ at the gateway router with a per-flow buffer size of 5 packets. Our prior work [36] {{shows that this}} buffer size maintains low queueing delays at the gateway with little loss in <b>end-to-end</b> <b>flow</b> rate.|$|R
40|$|In this paper, {{we present}} a {{distributed}} flow-based access scheme for slotted-time protocols, that providesproportional fairness in ad-hoc wireless networks under constraints on the buffer overflow probabilities ateach node. The proposed scheme requires local information exchange at the link-layer and end-to-endinformation exchange at the transport-layer, and is cast as a nonlinear program. A medium access controlprotocol {{is said to be}} proportionally fair with respect to individual <b>end-to-end</b> <b>flows</b> in a network, if theproduct of the <b>end-to-end</b> <b>flow</b> rates is maximized. A key contribution of this work lies in the construction ofa distributed dual approach that comes with low computational overhead. We discuss the convergenceproperties of the proposed scheme and present simulation results to support our conclusions...|$|R
