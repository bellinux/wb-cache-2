0|38|Public
5000|$|<b>Geographic</b> Data <b>Files</b> (GDF) — An {{interchange}} <b>file</b> {{format for}} <b>geographic</b> data ...|$|R
40|$|The aim of {{this article}} is to {{introduce}} a new stand-alone application—Geo-Segregation Analyzer— that is capable of calculating 43 residential segregation indices, regardless of the population groups or the metropolitan region under study. In practical terms, the user just needs to have a Shapefile <b>geographic</b> <b>file</b> containing counts of population groups that differ in ethnic origin, birth country, age, or income across a metropolitan area at a small area level (e. g., census tracts). Developed in Java using the GeoTools library, this free and open-source application is both multiplatform and multilanguage. The software functions on Windows, Mac OS X, and Linux operating systems and its user interface currently supports 10 languages (English, French, Spanish, Catalan, German, Italian, Portuguese, Creole, Vietnamese, and Chinese). The application permits users to display and manipulate several Shapefile <b>geographic</b> <b>files</b> and to calculate 19 one-group indices, 13 two-group indices, 8 multigroup indices, and 3 local measures that could be mapped (location quotient, entropy measure, and typology of the ethnic areas proposed by Poulsen, Johnson, and Forrest) ...|$|R
40|$|This polygon shapefile layer {{represents}} {{areas where}} zoning and discretionary tax incentives {{are available for}} the development, expansion and renovation of full line grocery stores and supermarkets. This is a <b>geographic</b> <b>file</b> created by the New York City Department of City Planning, showing eligible areas for zoning incentives and eligible areas for tax incentives through the NYC Industrial Development Agency. For {{more information on the}} FRESH program and other incentives targeting grocery stores, please see www. nyc. gov/FRESH, or download the report in the archival copy...|$|R
50|$|February 8, 2017, for {{boundary}} files (second edition), reference maps (second edition), attribute information products (GeoSuite and <b>geographic</b> attribute <b>file),</b> {{and reference}} guides and documents (second edition).|$|R
50|$|ArcSDE enables {{organizations}} {{to move from}} a traditional approach — managing separate collections of <b>geographic</b> data <b>files</b> — to an integrated environment in which one can manage spatial data as a continuous database: accessible to the entire organization simultaneously and easily publishable on the Web.|$|R
40|$|The series {{consists}} of: <b>geographic</b> <b>files,</b> subject {{files and}} international organizations <b>files.</b> The <b>geographic</b> <b>files</b> include materials on 40 countries in Europe, North Africa and the Middle East. The subject files cover the following topics: National AJC staff and lay committees in Germany; the national AJC Committee on Near Eastern Affairs; Augustin Cardinal Bea and the Pro Deo Project; AJC delegations to Europe, Israel, and North Africa; antisemitism, fascism, and neo-Nazism; Christian-Jewish relations and the Ecumenical Council; the Columbus Project (David Astor and psychopathology); denazification trials; the Eichmann case; freedom of information; the Gauting Conference; genocide; group libel; human rights; immigration; Jewish communal services conference; Jewish war orphans; racial discrimination; European restitution programs and operations; visas to enter the United States. The international organizations files consist of: correspondence, reports, and other papers involving relationships between the AJC Paris Office and various organizations and groups such as: American Jewish Joint Distribution Committee, 1947 - 1952; Centre d'Information Israelite, 1947; Conference on Jewish Material Claims Against Germany, 1952 - 1962; Consultative Council of Jewish Organizations, 1946 - 1963; Council of Europe, 1951 - 1953; emigre organizations, 1942 - 1959; International Center, St. Paul the Apostle (Rome), 1964 - 1966; International Council of Christians and Jews, 1947 - 1949; International League, 1963 - 1966; International Refugee Organization, 1946 - 1949; London Conference, 1945 - 1946; Memorial Foundation for Jewish Culture, 1965 - 1967; P. E. N. Club, 1953; United Jewish Educational and Cultural Organization, 1946 - 1951; United Nations, and its various bodies, 1947 - 1967; World Brotherhood Organization; World Council of Churches; and World Jewish Congress. Inventory: English, 28 pp., typedLabeledEstablished in 1947 as the regional office for Europe and North Africa...|$|R
5000|$|USGS Geographic Names Information System (GNIS) Feature Detail Report for: SpruceFeature ID: 856140Name: SpruceClass: Populated PlaceCitation: Collected during Phase I data {{compilation}} (1976-1981), primarily from U.S. Geological Survey 1:24,000-scale topographic maps (or 1:25K, Puerto Rico 1:20K), various edition dates, and from U.S. Board on <b>Geographic</b> Names <b>files</b> FID 856140.Entry Date: 12-Dec-1980Elevation(ft/m)*: 5604/1708 ...|$|R
50|$|<b>Geographic</b> Data <b>Files</b> (GDF) is an {{interchange}} <b>file</b> {{format for}} <b>geographic</b> data.In contrast with generic GIS formats, GDF provides detailed rules for data capture and representation, and an extensive catalog of standard features, attributes and relationships. The most recent extension expanded applicability further towards pedestrian navigation, 3-D map rendering, and advanced driver-assistance systems (ADAS).|$|R
40|$|A {{computer-based}} system to produce listings of topical sub;ect terms and geographically subdivided terms is described. The system files and their associated listings {{are called the}} Subject Authority File (SAF) and the <b>Geographic</b> Authority <b>File</b> (GAF). Conversion, operation, problems, and costs of the system are presented. Details of the optical scanning conversion, with illustrations, show the relative ease of the technique for simple upper case data files. Program and data characteristics are illustrated with record layouts and sample listings...|$|R
50|$|Dual Independent Map Encoding (DIME) is an {{encoding}} scheme {{developed by the}} US Bureau of the Census for efficiently storing geographical data. The committee behind the case study that eventually resulted in DIME was established in 1965, although the term DIME itself was first coined by George Farnsworth in August 1967. The file format developed for storing the DIME-encoded data was known as <b>Geographic</b> Base <b>Files</b> (GBF). The Census Bureau replaced the data format with Topologically Integrated Geographic Encoding and Referencing (TIGER) in 1990.|$|R
40|$|In {{this report}} the data survey is {{described}} {{and the initial}} analysis results are provided, concerning major arteries within built-up areas. With these arteries the major roads for through traffic within an urban area are indicated. The risk data are based on road data, traffic data and accident data. No representative files of road characteristics and traffic characteristics were available for the road categories investigated. For the accident data, the Netherlands Transport Research Centre, Department for Statistics and Data Management (AVV/BG) <b>files</b> (including the <b>geographic</b> <b>file</b> on which these data are recorded, the so-called VLN files) were used. The road characteristics were surveyed anew. The traffic characteristics were requested from the municipalities. Recent traffic data, however, was not always available. A number of sample survey areas were selected within which the information from all relevant roads was gathered. The structure and specific VLN properties and its accident files, and the consequences for managing and using the collected data are examined. For the main types of roads and intersections the core data and the computed risks are given. A first comparison is drawn using data collected approximately ten years ago. The involvement of slow traffic and heavy goods vehicles is analysed. See also C 7533, 7534, 7536 anf 7537...|$|R
5000|$|Map {{database}} formats {{are almost}} uniformly proprietary, with no industry standards for satellite navigation maps, although {{some companies are}} trying to address this with SDAL and Navigation Data Standard (NDS). Map data vendors such as Tele Atlas and Navteq create the base map in a GDF (<b>Geographic</b> Data <b>Files)</b> format, but each electronics manufacturer compiles it in an optimized, usually proprietary manner. GDF is not a CD standard for car navigation systems. GDF is used and converted onto the CD-ROM in the internal format of the navigation system. CDF (CARiN Database Format) is a proprietary navigation map format created by Philips.|$|R
50|$|A map {{database}} {{represents a}} road network along with associated features. Map providers can choose various models {{of a road}} network as a basis to formulate a database. Commonly, such a model comprises basic elements (nodes, links and areas) of the road network and properties of those elements (location coordinates, shape, addresses, road class, speed range, etc.). The basic elements {{are referred to as}} features and the properties as attributes. Other information associated with the road network is also included, including points of interest, building shapes, and political boundaries. This is shown schematically in the adjacent image. <b>Geographic</b> Data <b>Files</b> (GDF) is a standardized description of such a model.|$|R
40|$|The American Jewish Committee Records, Domestic and <b>Geographic</b> <b>Files</b> {{consists}} of materials created by executive offices, departments, local offices and {{chapters of the}} committee concerning a variety of matters, primarily Jewish civil and religious rights, integration, Jewish communal organizations and communal issues. However, materials found in this collection encompass other civil, racial, and religious minority groups as well. The records consist of briefs, conference proceedings, correspondence, legal documents, memoranda, minutes of meetings, printed materials, reports, resolutions, statements, studies, and surveys. The American Jewish Committee Records, Domestic and <b>Geographic</b> <b>Files</b> {{consists of}} materials created by executive offices, departments, local offices and chapters of the Committee concerning a variety of matters, primarily Jewish civil and religious rights, integration, Jewish communal organizations and communal issues. However, materials found in this collection encompass other civil, racial, and and religious minority groups as well. The records consist of briefs, conference proceedings, correspondence, legal documents, memoranda, minutes of meetings, printed materials, reports, resolutions, statements, studies, and surveys. The collection is arranged alphabetically by state with further subdivisions by counties and cities. The collection covers topics such as Jewish communal organizations that were affiliated with the American Jewish Committee, communal issues, fundraising, hate groups, the American Jewish Committee’s membership, and visits by the organization’s representatives to various areas of the United States. The American Jewish Committee deposited selected record series at the YIVO Archives in 1983. Several record series were transferred from AJC to the YIVO Archives prior to 1983. The American Jewish Committee (AJC) was founded in New York in 1906 to defend Jewish civil and religious rights throughout the world. Among the original founders of the AJC were Louis Marshall, Judge Mayer Sulzberger, Jacob Schiff, and Cyrus Adler. At the outset, the AJC consisted of a select group who interceded on behalf of Jews privately and behind-the-scenes, in the traditional style of personal diplomacy. Early AJC efforts included lobbying for a liberal American immigration policy and against the literacy test requirement for immigrants. It campaigned against violations of rights of Jews in Tsarist Russia and worked to secure minority rights for Jews in post-WWI Europe. In the 1930 s the AJC began to widen its membership, and by the 1940 s its structure and approach had undergone a fundamental change. The private diplomacy policies gave way to more broad and outspoken public relations and educational programs, including anti-German boycott campaigns and scholarly studies, surveys, and publications on anti-Semitism, Nazi influences in the US, civil and religious rights, and inter-religious and intercultural relations. During the rise of Nazism and Fascism and the years of World War II, the AJC intervened before the US and other Allied governments {{on behalf of the}} persecuted Jews of Europe. It campaigned against domestic indifference and pro-Nazi sympathies, and encouraged neutral states‘ representatives to allow Jewish immigration and to create safe heavens for Jewish refugees. After the war, the Committee continued its lobbying activities, public relations and educational programs, monitoring anti-Semitism, racism and bigotry, and promoting intergroup cooperation, cultural diversity, and intercultural education. The AJC supported legislation addressing racial and religious discrimination in employment, education, and housing. The Committee campaigned on behalf of Soviet Jews, as well as for Jewish groups in SFinding Aid available in Reading Room and on Internet...|$|R
50|$|The {{hierarchical}} {{data model}} lost traction as Codd's relational model became {{the de facto}} standard used by virtually all mainstream database management systems. A relational-database implementation of a hierarchical model was first discussed in published form in 1992 (see also nested set model). Hierarchical data organization schemes resurfaced {{with the advent of}} XML in the late 1990s (see also XML database). The hierarchical structure is used primarily today for storing <b>geographic</b> information and <b>file</b> systems.|$|R
30|$|The UPGMA tree {{revealed}} that rice varieties clustered into smaller sub-groups based on type, grain qualities or geographic origin. For example, boro, jum, glutinous, and agronomically improved varieties clustered together into smaller sub-groups within Group-I (indica) while the Group-II (japonica) formed two sub-groups corresponding the <b>geographic</b> locations (Additional <b>file</b> 3 : Figure S 1). A few sub-groups and varieties (marked with double asterisk), however, did not cluster with respective types or grain quality (Additional file 3 : Figure S 1).|$|R
40|$|This {{deliverable}} {{consists of}} three main parts. The first part is a comprehensive survey on standardisation efforts for geographic information. The second part contains {{a description of the}} <b>Geographic</b> Data <b>Files</b> (GDF) standard. This is an ISO specification of how to store geographic information for intelligent transport systems. The structures in GDF, although primarily developed for storing data, are already a sophisticated ontology for transport networks. They are, however, still described on paper, and not with a formal system for representing ontologies. Therefore we turned the more informal description of the GDF ontology in a formal OWL-based ontology. The result is OTN, an Ontology for Transportation Systems. OTN is very similar to GDF, with some extras. It is described informally in the third part of this deliverable. The precise technical details of OTN can be obtained online a...|$|R
40|$|Public health {{researchers}} {{have used a}} class of statistical methods to calculate prevalence estimates for small geographic areas with few direct observations. Many {{researchers have}} used Behavioral Risk Factor Surveillance System (BRFSS) data {{as a basis for}} their models. The aims of this study were to 1) describe a new BRFSS small area estimation (SAE) method and 2) investigate the internal and external validity of the BRFSS SAEs it produced. The BRFSS SAE method uses 4 data sets (the BRFSS, the American Community Survey Public Use Microdata Sample, Nielsen Claritas population totals, and the Missouri Census <b>Geographic</b> Equivalency <b>File)</b> to build a single weighted data set. Our findings indicate that internal and external validity tests were successful across many estimates. The BRFSS SAE method is one of several methods {{that can be used to}} produce reliable prevalence estimates in small geographic areas. 27418213 PMC 495108...|$|R
40|$|This {{assessment}} {{of the potential for}} disposal of CO 2 in geological settings considers use in enhanced oil recovery, disposal in saline aquifers, storage in caverns in salt, and reaction with igneous rocks rich in magnesium and iron. Factors that limit the potential for disposal in saline aquifers include thickness of alluvial cover; nearness to faults; mineral, geothermal, and water resources; urban areas; and restricted lands. <b>Geographic</b> information system <b>files</b> used in the analysis are included on a CD-ROM and are also available at www. nbmg. unr. edu/dox/r 51. zip. 200...|$|R
40|$|Many {{geographical}} databases {{have been}} developed by different programs and applications, but data acquisition and data sharing are still a big problem because no interoperability exists among these different databases. This study presents a GML (Geography Markup Language) approach to build a geographical database in order to enable interoperability. As an open, non-proprietary industry standard, GML overcomes the problems of current GIS software proprietary data models and database structures. Compared with other standards, such as <b>Geographic</b> Data <b>File</b> (GDF) and Spatial Data Transfer Standard (SDTS), GML approach {{has the advantage of}} enabling on-line data exchange. GML holds promise in providing a standard way to share and use the existing spatial data over the Web. A GML-based interoperable geographical database for the conservation of the Stone Forest Landscape is implemented as a case study. It shows that the public can access and use the GML-based spatial database through a user-friendly interface and that GML can deliver high quality vector data on the Web...|$|R
5000|$|SYMAP's {{ability to}} print cheap, albeit low quality, maps using readily {{available}} technology led to rapid adoption {{in the late}} 1960s. SYMVU software, developed in 1969 to illustrate surface displays, was another popular product. GRID, CALFORM, and POLYVRT products further explored the raster versus vector approach to mapping. The Laboratory gained a reputation for solid output leading to several commercially successful projects and significant budgetary independence for a research institute. Some struggles with restructuring <b>Geographic</b> Base <b>Files</b> - Dual Independent Map Encoding (GBF-DIME files, an early vector and polygonal data structure) for the Census Bureau's Urban Atlas in 1975 inspired the Laboratory to develop an integrated suite of programs beneath by a common user interface and common data manipulation software. [...] In 1978 this suite became the Odyssey project. [...] The Odyssey project's aim was to produce a vector GIS that provided spatial analysis of many different forms within a single system.|$|R
40|$|Bureau of the Census, Geography Division's ADDEDIT-L {{program is}} a {{computer}} address editing program system composed of two step programs, PRERANGE and RANGEDIT, for purpose of detecting errors in node chain, address range, and ZIP code aspects in GBF/DIME files. Issued January 1, 1975. Item 131 -E. At head of title: <b>Geographic</b> base (DIME) <b>file,</b> CUE, correction-update-extension. Bureau of the Census, Geography Division's ADDEDIT-L {{program is a}} computer address editing program system composed of two step programs, PRERANGE and RANGEDIT, for purpose of detecting errors in node chain, address range, and ZIP code aspects in GBF/DIME files. Mode of access: Internet...|$|R
40|$|Understanding the {{determinants}} of foreign direct investment (FDI) is important for analyzing capital flows and the industrial organization of multinational firms. Most empirical studies of FDI, however, have focused on case studies of nontax factors in overseas investment decisions or on discerning reduced-form relationships between some measure of FDI and variables relating to nontax and tax aspects of the investment decision. In this paper, we {{examine the effects of}} taxation on FDI using previously unexplored (for this purpose) panel data on FDI by subsidiaries of U. S. multinational firms collected by Compustat's <b>geographic</b> segment <b>file</b> project. These firm- level data contain information on new capital investment overseas which enable us to measure tax influences on FDI more precisely and allow us to focus on structural models of subsidiaries' investment decision. Our empirical results cast significant doubt on the simplest notion that 'taxes don't matter' for U. S. firms' FDI decisions. Tax parameters influence FDI in precisely the way indicated by neoclassical models. Our results also lend support to the application of the 'tax capitalization' model to the study of dividend repatriation and foreign direct investment decisions. ...|$|R
40|$|The orthorectification of {{satellite}} images is a foundational process in satellite applications. With {{the improvement of}} the satellite imaging technology and the orthorectification calculation models, the collection of Ground Control Point (GCP) is becoming the key factor restricting the efficiency and precision of orthorectification. At the same time, the services based on web in the <b>geographic</b> information <b>filed</b> have obtained substantial achievements, and the gradual maturity of GCP chips database construction technology, it is possible to provide remote sensing image ortho-rectification services via the internet based on the exiting GCP chips database. This paper proposed a framework design of Service Platform for satellite images automatic OrthoRectification(SPOR). Under B/S three tired (i. e. Data server, Web application server and Browser) system structure mode, this service platform translated noncorrected images form the user browser to the server side, corrected the images automatically under the assistance of GCPs image database and Digital Elevation Model(DEM), and sent the corrected images to users via the internet. The prototype test of the system shows that, the application of the SPOR can substantially improve the efficiency {{of satellite}} image orthorectification, save the labor of ortho-image demand users, and make the correction of the satellite images more professionally and automatically. 1...|$|R
40|$|This paper {{reviews the}} first {{international}} release of the <b>Geographic</b> Data <b>Files</b> (GDF) ISO standard for the ITS industry and the ongoing follow-up work. The standard, GDF 4. 0, has been created by ISO/TC 204 Working Group 3. GDF 4. 0 represents harmonized, application-independent global specifications for the modeling of geographic information for high-end map-dependent ITS applications and services, catering for map requirements of in-vehicle navigation, dynamic route guidance, location-based services (LBS), fleet management, public transport, road administration, etc. Through its vast dictionary of standardized semantic definitions, GDF 4. 0 forms a foundation for interoperability between map-based ITS applications and services. Given that map data requirements of modern ITS applications are ever growing, while the room to pay for data and data handling increases at a far less rapid pace, GDF will continue its role as vehicle to share map data costs and to minimize data handling costs by providing a uniform basis for map data processing. It plays this role in an ever changing environment which explains the continual need for evolution. Such further development is carried out by WG 3 under the project name X-GDF (eXtended GDF), addressing issues like convergence with other relevant standards (ISO/TC 211), new map content requirements (3 D mapping, temporality, multi-modality, Safety Applications), and alternative physical realizations in terms of XML, GML and SQL...|$|R
40|$|Integrating mobile devices into Grid {{technologies}} and server applications can give ability to command power of supercomputers with a mobile device {{on one hand}} and can allow big applications to reach important data anywhere, anytime, on the other. IMOGA is planned to be an example to gather and share data that can be collected by ubiqui-tous mobile devices which can employ different kind of sen-sors such as Global Positioning System (GPS), temperature, health monitoring and pollution. In this project location and speed information that is produced by GPS enabled mo-bile devices such as mobile phones, is used. The developed client application running on mobile devices located in ve-hicles, such as the mobile phone of the driver, sends loca-tion and speed information to the server application in short time intervals via GPRS in the forms of Extended Mark-up Language (XML) like messages. The developed server ap-plication, which is preloaded with the highway coordinates via <b>files</b> in <b>Geographic</b> Data <b>Files</b> (GDF) format, locates the street that the vehicle is moving along and the received speed information is recorded along with a timestamp. A display application has also been implemented to calculate average of speeds that any vehicle may have at that very moment and post it on the Internet and WAP. If there is no actual data, i. e. there is no vehicle moving on a specific street, statistical data is utilised to produce such informa-tion. 1...|$|R
40|$|This work is {{embedded}} in a project to support traffic planning with heterogeneous data. We will describe how we develop a common ontology of two existing databases which are used in this project. The two databases are ATKIS (Amtliches Topographisches Informationssystem) and GDF (<b>Geographic</b> Data <b>Files)</b> [1, 2]. For information sharing the involved databases must either share the same conceptualization or agree on adopting a common conceptualization which is {{the intersection of the}} two distinct original conceptualizations [3]. We will show how to describe parts of the concepts of the databases ATKIS and GDF and how to use this description to develop a common ontology to share information. An ontology can be, considered as a set of logical axioms designed to account for intended use of vocabulary[4]. Axioms can be written as executable code in functional programming languages [5]. This implies that functional languages are useful to describe ontologies. With functional languages like Haskell it is possible to built axioms for a clear description with no ambiguities of interpretation [6]. Also it is possible to test the results, which gives a better chance to identify mistakes in definitions. This represents a deceive advantage over first order logic descriptions which cannot be tested. Additional the way to program code like Java or C++ is short [7]. The paper will show the application of functional languages to the description of ontologies for road data...|$|R
40|$|Digital {{interpretation}} of imagery produces {{descriptions of the}} earth's surface, each description relying on the inherent resolution of the original image. Forest cover <b>geographic</b> information (GIS) <b>files</b> have been produced by {{interpretation of}} aerial photography. Common mapping scales in Canada for representing land information are 1 : 20, 000 and 1 : 250, 000. This paper discusses two methods to automatically generalize GIS from higher spatial resolution scales to lower scales. These two methods are a raster method (MapGen) for generalization developed by Pamap and the BC Ministry of Forests, and an object-oriented method (ObjectGen). The GIS data set consists of topographic data and forest cover files, both at 1 : 20, 000 scale and placed on the same datum. In this presentation we compare the results for generalizing forest objects by these different methods. This work leads to segmentations of remote sensing images, at corresponding resolutions to the GIS files, being used to constrain the ge [...] ...|$|R
40|$|Geographic {{information}} {{plays an}} important part in people’s life. Especially with the development of computer science and Internet. GIS also went into a new era, from paper works to digital formats. The digital <b>geographic</b> data <b>files</b> can be spread and shared fast and widely via Internet. However, establishing new geographic data is expensive, thus the data users are not always the data establisher. In the hight speed developing GI society, many private sectors have participated in geographic data production, and also many datasets are from unclear sources with unclear quality information. In addition, errors can be generated during the transform and transfer processes. Therefor proper geographic data quality control and management is in urgent demand. GML is an XML-formed document for geographic information. It is a young but fast developing geographic data format, with its natural advantages, it is now being considered as standard geographic data format world wide. This project is concerned with the data quality control for GML files. Data validation is one kind of data quality measurement method in the data quality control process. The thesis aims to build up a validation framework for GML files based on the Norwegian standard. In the report the geographic data modeling is first described, including the Norwegian road network production specification, simple feature specification, and the related GML knowledge. The data quality issues are introduced after the modeling, the data quality issues are elaborated from two levels: general inconsistency level and specific ISO data quality element level. Following is the introductions, discussions and comparisons to the existing relevant geographic data quality tools. And at the ene the final GML validation framework is determined...|$|R
40|$|The accuracy, quality, and on-time {{delivery}} of geographic, spatial, cartographic, and address data products are integral to accomplishing {{the mission of}} the U. S. Census Bureau. These products support current surveys, decennial censuses, estimates programs, partnership programs, and the public need for geospatial data. For the 2010 Census field operations, the US Census Bureau’s Geography Division (GEO) delivered over 17 million unique map sheets, 10 <b>Geographic</b> Reference <b>Files</b> (GRFs) containing 6. 7 million blocks, and eight full MAF Extracts of over 144 million addresses. These products are generated from the Master Address File/Topologically Integrated Geographic Encoding and Referencing (MAF/TIGER) Product Database (PDB) that is created from the current MAF/TIGER transaction database (MTDB) through a Benchmarking process. The MTDB was developed as part of the MAF/TIGER Redesign project, and was a major step forward for GEO’s management of spatial and address data. The system utilized Commercial Off-The-Shelf (COTS) software including Oracle Spatial and Topology Data Model. The design included persistent topology and a seamless national database that integrated the spatial and address data. It facilitated real time updates and maintenance of business rules. However, to effectively support continuous flow-based {{on-time delivery}} of data products, a multi-level geospatial database design approach was adopted. The design resulted in the implementation of a complimentary database to the current MTDB known as the MAF/TIGER Product Database (PDB). The PDB utilizes a denormalized database design approach where tables from the current MTDB are combined, derived fields are stored, and there is no explicit storage of topology. The PDB also provides a data structure that supports geospatial COTS application tools including ESRI’s Geodatabase for spatial data visualization, analysis, and research...|$|R
3000|$|In {{comparison}} to GEOMAGIA 50.v 1, which contained seven metadata tables (Figure one in K 08) and displayed 11 metadata fields within the magnetic data results table (called ‘Master Table’ in section 5.2. 1. of K 08), version 3 calls from 14 metadata tables and displays 30 metadata fields (Additional file 1 : Table S 1). The metadata tables shown in K 08 have been appended with new entries and fields. The ‘Country/Region’ metadata table (previously called SITES in Table two of K 08) now contains a field for continents. This allows ordering of countries/regions by continent in the dropdown menu in <b>geographic</b> constraints (Additional <b>file</b> 1 : Figure S 3). In addition, {{it has been}} appended with new countries/regions as data have been added in versions 2 and 3 of the database (and as data {{have been added to}} the sediment database (Brown et al. 2015), with which this metadata table is shared). Currently, their are 110 countries/regions. The most up-to-date country/region metadata table can be found at [URL] [...]...|$|R
30|$|The {{expansion}} of rice {{to a wide}} geographical area after its domestication generated enormous diversification due to the progressive breeding activity through the selection of plants that showed superior performance under the different local climate conditions leading to {{a broad range of}} novel phenotypes. Genetic diversity is a natural resource for rice breeding to meet current food demands. Understanding population structure and genome variations are crucial achievements to facilitate genome-wide association studies of complex traits and functional gene investigations. In this regard, our study provides a useful pool of SNP markers with deep coverage throughout the rice genome. We have characterized 1713 SNPs that were genotyped in 217 rice varieties. Cultivars were representative of all genetic groups found across geographical regions in temperate climate as revealed by our population structure analysis and in accordance with previous studies (Courtois et al. 2012). Our genomic diversity and structure analyses have included old and modern japonica cultivars attempting to uncover a maximum spectrum of variability. This allowed us to reconstruct the genetic relationships and genetic diversity among several temperate rice varieties from distant <b>geographic</b> origins (Additional <b>file</b> 1 : Table S 1) which possess an enormous variability in agro-morphological and physiological traits.|$|R
40|$|Manual by Andrew G. Dean and John F. Smith. Version 1 {{design by}} Jeffrey A. Dean, Anthony H. Burton, and Andrew G. Dean; Version 1 Programming by Jeffrey A. Dean and Karl A. Brendel; Version 2 design by Andrew G. Dean and John F. Smith; Version 2 Programming by John F. Smith and Thomas G. Arner. This program for IBM-compatible {{microcomputers}} was produced through collaboration between Division of Surveillance and Epidemiology, Epidemiology Program Office and Public Health Practices Program Office, Centers for Disease Control and Prevention, Atlanta, Georgia 30333 and The Surveillance, Forecasting, and Impact Assessment Unit, Office of Research, Global Programme on AIDS, World Health Organization, Geneva, Switzerland. Epi Map {{is a program}} for IBM-compatible microcomputers that produces and displays maps from <b>geographic</b> boundary <b>files</b> and data values entered from the keyboard or supplied in Epi Info or dBASE files. The data may be counts, rates, or other numeric values. In Color/Pattern maps, the values are represented as shading or color patterns for each geographic entity. In Dot Density maps, randomly placed dots proportional in number to the values are placed in each entity. Epi Map also produces Cartograms, in which the value for each geographic entity is allowed to control {{the size of the}} entity. Thus, a state or country will be small on the map if the value being represented (e. g., cases of AIDS) is small, but large if the number is large. Suggested citation: Dean JA, Dean AG, Smigh JF, Burton AH, Brendel KA, and Arner, TG. Epi Map 2 : a mapping program for IBM-compatible microcomputers. Centers for Disease Control and Prevention, Atlanta, Georgia, U. S. A., 1995. Introduction: What Is Epi Map 2 ? [...] Chapter. 1 Installation [...] 2. A Quick introduction to Epi Map [...] 3. Boundary files [...] 4. Data files [...] 5. Map files [...] 6. Map types [...] 7. Titles, legends, labels, and other annotations [...] 8. Simplifying, projecting, importing, exporting, and rotating boundary files [...] 9. Printing maps [...] 10. Producing slides and transparencies [...] 11. Multiple maps on one screen: the Map Manager [...] 12. Linking Epi Map to Epi Info databases [...] 13. Point-and-click information display [...] 14. Epi Map program (. EMP) files [...] 15. EPIMAP and EPIMAP 64 : using all of random access memory [...] Reference: Epi Map MAP file structure [...] Index. en...|$|R
40|$|While {{there is}} a general {{impression}} expressed by many in the media and among policy makers that the economy is becoming more globalized and internationally competitive, these claims are not agreed upon among economists. This dissertation attempts to clarify the validity of these crucial claims through empirical research. ^ This dissertation focusses on one aspect of economic internationalization and integration [...] the behavior of U. S. multinational manufacturing corporations and their foreign direct investment activities. The research presented here attempts to test two main hypotheses; first, that the extent of internationalization within U. S. manufacturing firms has grown in the recent past and, second, that production abroad by U. S. manufacturers substitutes for production in the domestic U. S. economy by these firms. ^ Using industry data from the Department of Commerce Surveys of U. S. Direct Investment Abroad, this dissertation supports the view of growing globalization by U. S. manufacturing multinational firms in the period from the late 1970 s through the 1980 s as measured by a range of measures. In particular, the data show that slow or non-existent domestic production growth combined with steady growth in foreign production to result in increased internationalization for these firms. The Department of Commerce data is also consistent with the claim that U. S. multinational manufacturing firms are increasingly substituting away from their domestic production base towards production in foreign countries in response to lower factor costs abroad. ^ Next, merging the Compustat Industrial File and the Compustat <b>Geographic</b> Segment <b>File</b> allowed the construction of a unique cross-section, time-series data set of 123 U. S. manufacturing multinational firms. Employing this firm level data, regression analysis is used to test if foreign production growth by U. S. manufacturing firms represents a substitution away from domestic production. Results of the analysis suggest that whether increased internationalization will displace domestic growth for a U. S. manufacturing firm is dependent on the degree of indebtedness of the firm and the concentration of its foreign operations in low wage areas of the world. For the high debt firms in the sample, the substitution effect of foreign growth on domestic growth outweighs the stimulating effect, while the opposite is true for less indebted firms. Regression analysis also shows a tendency for foreign affiliate growth to substitute for domestic growth when the firm 2 ̆ 7 s foreign operations are concentrated in developing countries, a result consistent with the analysis of the Department of Commerce data described above. ...|$|R
40|$|Epi Map is {{a program}} for IBM-compatible {{microcomputers}} that produces and displays maps from <b>geographic</b> boundary <b>files</b> and data values entered from the keyboard or supplied in Epi Info or dBASE files. The data may be counts, rates, or other numeric values. In Color/Pattern maps, the values are represented as shading or color patterns for each geographic entity. In Dot Density maps, randomly placed dots proportional in number to the values are placed in each entity. Epi Map also produces Cartograms, in which the value for each geographic entity is allowed to control {{the size of the}} entity. Thus, a state or country will be small on the map if the value being represented (e. g., cases of AIDS) is small, but large if the number is large. Introduction: What Is Epi Map 2 ? [...] Chapter. 1 Installation [...] 2. A Quick introduction to Epi Map [...] 3. Boundary files [...] 4. Data files [...] 5. Map files [...] 6. Map types [...] 7. Titles, legends, labels, and other annotations [...] 8. Simplifying, projecting, importing, exporting, and rotating boundary files [...] 9. Printing maps [...] 10. Producing slides and transparencies [...] 11. Multiple maps on one screen: the Map Manager [...] 12. Linking Epi Map to Epi Info databases [...] 13. Point-and-click information display [...] 14. Epi Map program (. EMP) files [...] 15. EPIMAP and EPIMAP 64 : using all of random access memory [...] Reference: Epi Map MAP file structure [...] Indexmanual by Andrew G. Dean and John F. Smith. "An Epi info- and dBASE-compatible mapping program" [...] coverManual by Andrew G. Dean and John F. Smith. Version 1 design by Jeffrey A. Dean, Anthony H. Burton, and Andrew G. Dean; Version 1 Programming by Jeffrey A. Dean and Karl A. Brendel; Version 2 design by Andrew G. Dean and John F. Smith; Version 2 Programming by John F. Smith and Thomas G. Arner. "This program for IBM-compatible microcomputers was produced through collaboration between Division of Surveillance and Epidemiology, Epidemiology Program Office and Public Health Practices Program Office, Centers for Disease Control and Prevention, Atlanta, Georgia 30333 and The Surveillance, Forecasting, and Impact Assessment Unit, Office of Research, Global Programme on AIDS, World Health Organization, Geneva, Switzerland. " - title page. "This manual and the programs are in the public domain and may be copied and distributed without restriction. " - title pageDean JA, Dean AG, Smigh JF, Burton AH, Brendel KA, and Arner, TG. Epi Map 2 : a mapping program for IBM-compatible microcomputers. Centers for Disease Control and Prevention, Atlanta, Georgia, U. S. A., 1995...|$|R
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. Background : The Crime Survey for England and Wales (CSEW), previously known as the British Crime Survey (BCS), has been in existence since 1981. The survey traditionally asks a sole randomly selected adult, in {{a random sample of}} households, details pertaining to any instances where they, or the household, has been a victim of a crime in the previous 12 months. These are recorded in the victim form data file (VF). A wide range of questions are then asked covering demographics and crime-related subjects such as attitudes to the police and the criminal justice system (CJS). Most of the questionnaire is completed in a face-to-face interview in the respondent's home; these variables are contained within the non-victim form (NVF) data file. Since 2009, the survey has been extended to children aged 10 - 15 years old; one resident of that age range has also been selected at random from the household and asked about incidents where they have been a victim of crime, and other related topics. The first set of children's data, covering January-December 2009, had experimental status, and is held separately under SN 6601. From 2009 - 2010, the children's data cover the same period as the adult data and are included with the main dataset. Further information may be found on the ONS Crime Survey for England and Wales webpage and for the previous BCS, from the GOV. UK BCS Methodology webpage. Self-completion data A series of questions on drinking behaviour, drug use and intimate personal violence (including stalking and sexual victimisation) are administered to adults via a self-completion module which the respondent completes on a laptop computer. Children aged 10 - 15 years also complete a separate self-completion questionnaire. The questions are contained within the main questionnaire documents, but the data are available only under Special Licence/Secure Access conditions from the UK Data Archive. Lower-level geographic variables are also available under Special Licence/Secure Access conditions to match to the survey. History : Up to 2001, the survey was conducted biennially. From April 2001, interviewing was carried out continually and reported on in financial year cycles and the crime reference period was altered to accommodate this change. The core sample size has increased from around 11, 000 in the earlier cycles to over 40, 000. Following the National Statistician's Review of Crime Statistics in June 2011 the collation and publication of Crime Statistics moved to the Office for National Statistics (ONS) from 1 st April 2012, and the survey changed its name to the Crime Survey for England and Wales (CSEW) accordingly. Scottish data : The 1982 and 1988 BCS waves were also conducted in Scotland. The England and Wales data for 1982 and 1988 are held at the UKDA under SNs 1869 and 2706, but the Scottish data for these studies are held separately under SNs 4368 and 4599. Since 1993, separate Scottish Crime and Justice Surveys have been conducted, and these are held under GN 33330. For the second edition (January 2016) data for 2013 - 2014 has been added, and previous data files enhanced. Main Topics : The Crime Survey for England and Wales, 2011 - 2014 : Secure Access, Low-Level <b>Geographic</b> Data <b>files</b> comprise the following variables: Super Output Areas (Lower Layer) Super Output Areas (Middle Layer) Community Safety Partnerships (not included in file for 2013 / 14) Basic Command Units (not included in file for 2012 / 13 or file for 2013 / 14) Prospective users should also order the main Crime Survey for England and Wales held under SNs 7252 and 7422 (End User Licence) or 7280 (Secure Access). Documentation Please see the documentation for the main CSEW survey, held under SNs 7252 and 7422 (End User Licence) or 7280 (Secure Access). <br...|$|R
