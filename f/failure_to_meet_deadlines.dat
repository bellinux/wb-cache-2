12|10000|Public
50|$|IDX Systems Corporation {{was removed}} from the Southern Cluster Fujitsu Alliance in August 2005 {{following}} repeated <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines.</b> They were replaced in September 2005 by Cerner Corporation.|$|E
50|$|In 2012, the FDA was sued by {{consumer}} groups the Center for Food Safety (CFS) and the Center for Environmental Health for its <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines.</b> In settling the litigation, the agency agreed to deadlines in 2015 and 2016 for certain rules.|$|E
50|$|In {{the first}} half of 1978, Gerber was fired from first the {{newspaper}} strip and then the comic-book series for a <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines.</b> On August 29, 1980, after learning of Marvel's efforts to license Howard for use in film and broadcast media, Gerber filed a copyright infringement lawsuit against Marvel corporate parent Cadence Industries and other parties, alleging that he was the sole owner of the character.|$|E
50|$|However, due <b>to</b> Cuprom's <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> {{regarding}} the financing, the Serbian government had cut {{the deal and}} the complex was put up for privatization once again.|$|R
500|$|In January 2010, {{work began}} on the C-111 canal, built in the 1960s to drain {{irrigated}} farmland, to reconstruct it to keep from diverting water from Everglades National Park. Two other projects focusing on restoration were also scheduled to start in 2010. Governor Crist announced the same month that $50 million would be earmarked for Everglades restoration. In April of the same year, a federal district court judge sharply criticized both state and federal <b>failures</b> <b>to</b> <b>meet</b> <b>deadlines,</b> describing the cleanup efforts as being slowed by [...] "glacial delay" [...] and government neglect of environmental law enforcement [...] "incomprehensible".|$|R
40|$|Photograph {{used for}} {{a story in the}} Daily Oklahoman newspaper. Caption: "A plan to study and {{coordinate}} law enforcement in Canadian County has been shelved temporarily because of some opposition and <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> for federal funds, an official of the Association of Central Oklahoma Governments said. ...|$|R
5000|$|Mike [...] "Fletch" [...] Fletcher is {{a general}} {{assignments}} reporter for the metro desk of the paper. He is a talented writer but sometimes struggles to submit his work in time for deadlines. Fletch has a relaxed approach to his work and a sometimes flippant attitude. While he is still young he is savvy {{enough to know that}} a victim's background is more important than good writing in getting a murder story on the front page. Fletch's <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> earns him a reproach from city desk editor Gus Haynes.|$|E
40|$|Failure of a safety-critical {{application}} on an {{embedded processor}} {{can lead to}} severe damage or even loss of life. Here we are concerned with two kinds of failure: stack overflow, which usually leads to run-time errors {{that are difficult to}} diagnose, and <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines,</b> which is catastrophic for systems with hard real-time characteristics. Classical validation methods like code review and testing with repeated measurements require a lot of effort, are expensive, and do not really help in proving the absence of such errors. AbsIntâ€™s tools StackAnalyzer and aiT (timing analyzer) provide a solution to this problem. They use abstract interpretation as a formal method that allows to obtain statements valid for all program runs with all inputs. ...|$|E
40|$|Reasoning {{about the}} timing {{properties}} of a program is indispensable {{in the development of}} time critical systems where <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> can result in loss of life or material. To this end having tools to calculate safe and tight Worst Case Execution Time (WCET) bounds can be very valuable. In most of the approaches to date a lot of pessimism is attributed to the fact that many paths that are infeasible are not excluded from the WCET computations. To remedy this, user annotations to the source code were proposed and used. Unfortunately, {{there is no guarantee that}} these annotations are always correct. This fact renders such a manual approach unacceptable in the case of R/T systems where safety is an absolute priority. In this paper another approach for the safe elimination of infeasible execution paths is presented. This method is based on the R/T programming language SIGNAL and its internal Dynamic Graph representation. 1 The problem and related work Reasoning {{about the timing}} [...] ...|$|E
40|$|The task of {{checking}} if {{a computer system}} satisfies its timing specifications is extremely important. These systems are often used in critical applications where <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> can have serious or even fatal consequences. This work describes Verus, an efficient tool for performing this verification task. Using our tool...|$|R
5000|$|In May 2009, N-Europe interviewed Adam Artur Antolski, an ex-Nibris {{employee}} and scriptwriter for Sadness, who {{revealed that the}} game's delays were caused by prolonged dispute over the game design, which led <b>to</b> constant <b>failures</b> <b>to</b> <b>meet</b> <b>deadlines.</b> Antolski asserted that because no consensus could be made among the staff and with Frontline, the only progress made {{during the first year}} was completion of the script, concept design, and [...] "only one 3D object - some minecart I believe." [...] When asked regarding the announcement that Nibris would be present at that year's Electronic Entertainment Expo, Antolski stated that [...] "Nibris always was better in promoting than making anything." [...] As such, Nibris did not appear at E3 2009, and the game silently missed the projected Autumn 2009 release date.|$|R
40|$|The Act {{removes a}} {{provision}} from existing law that automatically prohibited a municipality {{that failed to}} submit a schedule for eliminating its combined sewer overflows by a specified deadline from making any connections to the combined sewer system. <b>Failure</b> <b>to</b> <b>meet</b> the <b>deadline</b> can still result in penalties under the Georgia Water Pollution Control Act, including the sewer moratorium, but the penalty {{will be at the}} discretion of the Environmental Protection Division (EPD) ...|$|R
40|$|In {{this paper}} {{we present a}} simple model that {{combines}} the <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> with hardware/software failures in computing the reliability of a real-time system. We define the performability as the probability of meeting deadlines by real-time tasks {{in the presence of}} hardware and software failures. Deadline driven schedules rely on worst-case task execution time. This may be necessary for hard real-time systems where missed deadlines can be very costly. For soft real-time systems (where a missed deadline is not catastrophic), using worst case task execution times leads to very inefficient use of processing resources. This is particularly true when worst case execution occurs very infrequently. Our performability analysis permits task schedules to slide (that is, require more time than predicted). The amount of slack allowed by the task deadlines can be varied to achieve a desired performability. We are developing a tool that empirically calculates the performability for a task system with specified task profiles and reliability system components...|$|E
40|$|International audienceWe {{present a}} tool {{currently}} {{under construction in}} order to enhance the SIGNAL language environment with a facility that will allow the temporal validation of a system specification with respect to its R/T constraints while staying {{within the context of the}} SIGNAL language. By use of the so called temporal homomorphisms we express the temporal dimension of a functional specification as a SIGNAL program. This facility can be further extended to evaluate the temporal behavior of a system with respect to a chosen execution architecture, by modelling processor architectural features influencing execution time. Reasoning about the timing properties of a program is indispensable in the development of time critical systems where <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> can result in loss of life or material. There is much work done in the domain of functional specification where formal languages like SIGNAL, Esterel, Lustre can be successfully used. There seems to be an inadequacy as far as the validation of temporal properties is concerned and this is mainly due to the fact that many different factors influence the execution time of a program making this problem quite complicated when viewed from a high abstraction level...|$|E
40|$|The thesis {{discusses}} deadlines for decisions issuing in proceedings {{on international}} protection, especially within {{the frame of}} procedure for granting of international protection status. This analysis compares current legal situation with the situation before the amendment to the Asylum Act by the Act No. 314 / 2015 Coll., effective from December 18 th, 2015, which reflects jurisprudence, literature and administrative practice in the field. It further elaborates interpretation of certain vague legal concepts which manage the international protection of vital importance, such as "reasonable period", "without undue delay", "factual and legal complexity. " The study discusses -from the applicant's perspective - means of the protection against inactivity and compares their efficiency. The thesis aims to monitor and evaluate a common phenomenon of the administrative practice, the <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines,</b> altogether with extension of the deadline in the application proceedings due to the exceptional circumstances, which has become the standard procedure rather than an exception. My goal is also to raise a question whether the fundamental rights of the applicants for the international protection (who {{are considered to be}} vulnerable individuals in a difficult life situation), guaranteed by the Charter and [...] ...|$|E
50|$|The {{following}} year, {{the three}} teams would face-off in a rematch, with Gas Monkey Garage (featured on the Discovery Channel show Fast N' Loud) {{also in the}} competition. A major point of contention in this build-off was Jesse James' <b>failures</b> <b>to</b> <b>meet</b> the <b>deadlines</b> for completion, requiring extensions each time. Gas Monkey Garage was especially upset, eventually leading to heated confrontations with James at the live build-off results show on December 12.|$|R
2500|$|On January 8, 2008 the New York Times {{reported}} that North Korea had missed a deadline to submit {{an inventory of}} its nuclear arms programs and that Hill said that <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> should be confronted with patience and perseverance. [...] "They were prepared to give a declaration which wasnâ€™t going to be complete and correct and we {{felt that it was}} better for them to give us a complete one even if it's going to be a late one", said Hill.|$|R
40|$|Abstract The task of {{checking}} if {{a computer system}} satisfies its timing specifications is extremelyimportant. These systems are often used in critical applications where <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> can have serious or even fatal consequences. This work proposes an efficientmethod for performing this verification task. The method is based on temporal logic model checking, a technique for verifying concurrent reactive systems. In the proposedtechnique, a real-time system is modeled by a state-transition graph represented by binary decision diagrams. Efficient symbolic algorithms exhaustively explore the state space todetermine whether the system satisfies a given specification...|$|R
40|$|This thesis makes a {{contribution}} towards the certification of reconfigurable real-time mission critical software systems. In highly reconfigurable software systems {{it is possible}} for a situation to arise where the system expends most or all of its resources on reconfiguring, and thus cannot provide sufficient resources to conduct intended computing functions. This anomaly has been termed "configuration thrashing" by the author due to its loose analogy to memory thrashing. If configuration thrashing is not eliminated, or at least minimised, then {{it is possible for}} circumstance to occur where reconfigurable systems cannot be certified due to potential <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> caused by configuration thrashing. The elimination of reconfiguration thrashing is a step towards certifiable dynamic reconfigurable systems capable of enforcing deadlines. The elimination of reconfiguration thrashing is necessary, though not sufficient, for this goal. In order to restrict configuration thrashing it is necessary to understand the possibilities available within reconfigurable software. A VDM-SL model is presented to explore the options available for reconfigurable architectures, and has allowed many operators to be formally specified providing a much greater understanding of the tasks involved in reconfiguration. The thesis demonstrates how model checkers can be used to check software processes for configuration thrashing using predefined CSP models, thus allowing system programmers to engineer configuration thrashing out of systems. However, model checkers are susceptible to state space explosion, particularly if models are large and / or complex, which may make the use of the model checkers impractical or even impossible for some systems. The thesis therefore also explores potential run-time solutions to configuration thrashing. These solutions allow developers to include additional logic / processes within their systems in order to eliminate configuration thrashing (without the use of model checkers). Several options are explored in-depth, from providing mechanisms for developers to choose when reconfiguration can / cannot occur, to a rule based solution. The exploration of the rule based solution explores issues such as rule expression, rule predictability, as well as potential core rules. The two approaches taken within this thesis to eliminate, or at least restrict sufficiently, configuration thrashing form a basis which would allow for the certification of reconfigurable real-time mission critical software systems. EThOS - Electronic Theses Online ServiceBAE SystemsGBUnited Kingdo...|$|E
40|$|The ACP Council of Ministers {{have agreed}} to have a single overall {{spokesperson}} at the Cancun WTO Ministerial meeting. The Botswanan Minister of Trade and Industry, Jacob Nkate, will take on this role. With regard to agriculture the ACP Ministers expressed 'concern at the <b>failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> {{for the establishment of}} modalities for further commitments in agriculture' and the view that 'progress in this matter is essential for the successful conclusion of the Doha work programme'. ACP Ministers reiterated the need for improved 'market access for all agricultural products originating from ACP states, and the need for developed countries to eliminate export subsidies and to reduce trade-distorting support, especially when having a negative impact on ACP countries'. The Ministers also expressed regret at the WTO challenge to the EU sugar regime. More specifically the ACP called for: 'the Cancun Ministerial conference to take a decision on the rapid elimination of subsidies to cotton, and adopt measures so as to compensate those countries adversely affected by these practices'; 'developed countries to exercise restraint in applying TBT and SPS measures on products from ACP countries' provision to be made for special safeguard mechanisms, special treatment for 'special products' and for the special needs of net-food-importing developing countries to be addressed. Comment: Significantly improved market access for ACP agricultural exports can best be secured through modifying, on a case-by-case basis, the provisions of Declaration XXII of the Cotonou Agreement, since this restricts the benefits of any new EU liberalisation to ACP countries, while any multilateral commitments will benefit all WTO members, including the competitors of ACP countries. According to reports by Agence Europe the EU and the ACP {{have agreed to}} work together to ensure that the objectives of the Doha Development Round are respected by striking a balance between tighter global trade rules and market liberalisation on the one hand, and taking the particular situation facing ACP states, given their level of development, and the problems they encounter in meeting their WTO obligations on the other. The ACP Council of Ministers have agreed to have [...] ...|$|E
40|$|Real-time {{computing}} is {{not just}} fast computing but time-predictable computing. Many tasks in safety-critical embedded real-time systems have hard real-time characteristics. <b>Failure</b> <b>to</b> <b>meet</b> <b>deadlines</b> may result {{in the loss of}} life or in large damages. Known of Worst Case Execution Time (WCET) is important for reliability or correct functional behavior of the system. As multi-core processors are increasingly adopted in industry, it has become a great challenge to accurately bound the worst-case execution time (WCET) for real-time systems running on multi-core chips. This is particularly true because of the inter-thread interferences in accessing shared resources on multi-cores, such as shared L 2 caches, which can significantly affect the performance but are very difficult to be estimate statically. We propose an approach to analyzing Worst Case Execution Time (WCET) for multi-core processors with shared L 2 instruction caches by using a model checking based method. Our experiments indicate that compared to the static analysis technique based on extended ILP (Integer Linear Programming), our approach improves the tightness of WCET estimation more than 31. 1 % for the benchmarks we studied. However, due to the inherent complexity of multi-core timing analysis and the state explosion problem, the model checking based approach currently can only work with small real-time kernels for dual-core processors. At the same time, improving the average-case performance and energy efficiency has also been important for real-time systems. Recently, Hybrid SPM-Cache (HSC) architectures by combining caches and Scratch-Pad Memories (SPMs) have been increasingly used in commercial processors and research prototypes. Our research explores HSC architectures for real-time systems to reconcile time predictability, performance, and energy consumption. We study the energy dissipation of a number of hybrid on-chip memory architectures by combining both caches and Scratch-Pad Memories (SPM) without increasing the total on-chip memory size. Our experimental results indicate that with the equivalent total on-chip memory size, several hybrid SPM-Cache architectures are more energy-efficient than either pure software controlled SPMs or pure hardware-controlled caches. In particular, using the hybrid SPM-cache to store both instructions and data can achieve the best energy efficiency. However, the SPM allocation for the HSC architecture must be aware of the cache to harness the full potential of the HSC architecture. First, we propose and evaluate four SPM allocation strategies to reduce WCET for hybrid SPM-Caches with different complexities. These algorithms differ by whether or not they can cooperate with the cache or be aware of the WCET. Our evaluation shows that the cache aware and WCET-oriented SPM allocation can maximally reduce the WCET with minimum or even positive impact on the average-case execution time (ACET). Moreover, we explore four SPM allocation algorithms to maximize performance on the HSC architecture, including three heuristic-based algorithms, and an optimal algorithm based on model checking. Our experiments indicate that the Greedy Stack Distance based Allocation (GSDA) can run efficiently while achieving performance either the same as or close to the optimal results got by the Optimal Stack Distance based Allocation (OSDA). Last but not the least, we extend the two stack distance based allocation algorithms to GSDA-E and OSDA-E to minimize the energy consumption of the HSC architecture. Our experimental results show that the GSDA-E can also reduce the energy either the same as or close to the optimal results attained by the OSDA-E, while achieving performance close to the OSDA and GSDA...|$|E
50|$|In 2009, {{it became}} clear that the {{building}} of the second Danube Bridge could not be finished by the end of 2010, since it had not yet really begun. Due <b>to</b> the <b>failure</b> <b>to</b> <b>meet</b> the original <b>deadline,</b> Bulgaria almost lost the financing of the whole project, but they were granted more time to finish the bridge by the end of 2012,.|$|R
5000|$|CSC {{was one of}} the {{contractors}} hired by the Internal Revenue Service to modernize its tax-filing system. They told the IRS it would meet a January 2006 deadline, but failed to do so, leaving the IRS with no system capable of detecting fraud. Its <b>failure</b> <b>to</b> <b>meet</b> the delivery <b>deadline</b> for developing an automated refund fraud detection system cost the IRS between $200 million and $300 million.|$|R
50|$|On 19 April 2016, it was {{reported}} that Romania's participation in the Eurovision Song Contest 2016 was in danger owing to TVR's repeated non-payment to the EBU of debts totaling CHF 16 million and dating back to January 2007. The EBU had issued a deadline to the Romanian government requiring it to make satisfactory arrangements to repay the debt by 20 April, or else face exclusion from the contest. Two days later it announced that, following the government's <b>failure</b> <b>to</b> <b>meet</b> the <b>deadline,</b> the EBU had withdrawn all member services from TVR: these included - in addition to TVR's participation in the Song Contest - access to the Eurovision News and Sports News Exchanges, the right to broadcast specific sporting events, and entitlement to benefit from the EBU's legal, technical, research, expertise, and lobbying services.|$|R
40|$|Introduction The task of {{checking}} if {{a computer system}} satisfies its timing specifications is extremely important. These systems are often used in critical applications where <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> can have serious or even fatal consequences. This work discusses an efficient method for performing this verification task. The method is based on temporal logic model checking, a technique for verifying concurrent reactive systems. In the proposed technique, the system being verified is modeled by a state-transition graph represented by binary decision diagrams[1]. Efficient symbolic algorithms exhaustively explore the state space {{to determine whether the}} system satisfies a given specification. Two symbolic model checkers are used in this work, SMV[11] and Verus[2]. They allow the verification of untimed properties expressed in the temporal logic CTL [...] - Computation Tree Logic[11]. Time bounded properties can be verified using Real-Time CTL model checking[10]...|$|R
5000|$|The {{original}} {{commitment in}} Phase III required all countries to have 45 {{percent of the}} chemical stockpiles destroyed by April 2004. Anticipating the <b>failure</b> <b>to</b> <b>meet</b> this <b>deadline,</b> the Bush administration in September 2003 requested a new deadline of December 2007 for Phase III and announced a probable need for an extension until April 2012 for Phase IV, total destruction (requests for deadline extensions cannot formally be made until 12 months before the original deadline). This extension procedure {{spelled out in the}} treaty has been utilized by other countries, including Russia and the unnamed [...] "state party". Although April 2012 is the latest date allowed by the treaty, the U.S. also noted that this deadline may not be met due to environmental challenges and the U.S. decision to destroy leaking individual chemical shells before bulk storage chemical weapons.|$|R
40|$|Introduction The task of {{checking}} if {{a computer system}} satisfies its timing specifications is extremely important. These systems are often used in critical applications where <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> can have serious or even fatal consequences. This work describes Verus, an efficient tool for performing this verification task. Using our tool, the system being verified is specified in the Verus language and then compiled into a state-transition graph. A symbolic model checker allows the verification of untimed properties expressed in CTL [8]. Time bounded properties can be verified using RTCTL model checking [7]. Moreover, algorithms derived from symbolic model checking are used to compute quantitative information about the model [1]. The information produced allows the user to check the temporal correctness of the model: schedulability of the tasks of the system can be determined by computing their response time; reaction times to events and...|$|R
40|$|Chao-Lin Liu Artificial Intelligence Laboratory, University of Michigan 1101 Beal Avenue Ann Arbor, Michigan 48105 chaolin@umich. edu Many {{applications}} require computational {{systems to}} respond to queries by a particular <b>deadline.</b> <b>Failure</b> <b>to</b> <b>meet</b> the <b>deadlines</b> may render the returned solution useless. Moreover, the deadlines of such time-critical applications are often uncertain at system design time. Anytime algorithms have been suggested to cope with these challenges by trading {{the quality of the}} solutions for the reactiveness of the systems at run time [1]. We have introduced an anytime evaluation algorithm [2] for a formalism commonly used in uncertain reasoning: Bayesian networks. Empirical results indicate that approximations of good quality can be obtained within a much shorter time than would be required to directly evaluate the networks by exact algorithms. Also the quality of the approximation improves with the allocated computational time on average. Approximations o [...] ...|$|R
40|$|<b>Failure</b> <b>to</b> <b>meet</b> task <b>deadline</b> {{in safety}} {{critical}} real-time {{systems can be}} catastrophic. Moreover, fault tolerance is a crucial aspect of such systems if faults are likely. In this work, fault tolerance in real-time systems is proposed using time redundancy to mask at most F transient faults. Schedulability {{of a set of}} n preemptive real-time periodic tasks using Rate-Monotonic(RM) schedule in chip multiprocessor (CMP) is considered. Chip multiprocessor rather than uniprocessor is proposed to make more CPU time available before deadline of tasks. This paper addresses the issue of finding maximum number of tasks that can run in parallel at a particular time and also finds minimum number of processing cores required in a CMP, denoted by MinC, to make the real-time system task set schedulable. A real-time fault-tolerant algorithm FT-RT-CMP for scheduling tasks using MinC cores is also developed considering the worst case distribution of F transient faults...|$|R
40|$|The task of {{checking}} if {{a computer system}} satisfies its timing specifications is extremely important. These systems are often used in critical applications where <b>failure</b> <b>to</b> <b>meet</b> a <b>deadline</b> can have serious or even fatal consequences. This paper presents an efficient method for performing this verification task. In the proposed method a real-time system is modeled by a state-transition graph represented by binary decision diagrams. Efficient symbolic algorithms exhaustively explore the state space {{to determine whether the}} system satisfies a given specification. In addition, our approach computes quantitative timing information such as minimum and maximum time delays between given events. These results provide insight into the behavior of the system and assist in the determination of its temporal correctness. The technique evaluates how well the system works or how seriously it fails, as opposed to only whether it works or not. Based on these techniques a verification tool called Verus [...] ...|$|R
40|$|INTRODUCTION I N hard {{real-time}} systems, <b>failure</b> <b>to</b> <b>meet</b> the <b>deadline</b> of a task {{may result}} in catastrophic consequences. Each task must therefore be guaranteed a priori <b>to</b> <b>meet</b> its timing constraint, and hence, efficient techniques for preruntime scheduling or schedulability analysis are needed. Since periodic tasks are the base load of such systems, we shall focus on how to schedule them. Sporadic tasks may be considered periodic by using, for example, the sporadic server. For the algorithm to be of practical value, task precedence constraints and resource requirements {{need to be taken}} into account. Furthermore, the algorithm should find a feasible schedule (i. e., one that <b>meets</b> all <b>deadlines),</b> whenever such a schedule exists. One approach is to cast this problem into that of minimizing maximum task lateness. A feasible schedule would then correspond to a solution where maximum task lateness is nonpositive. If the optimal schedule has positive lateness, th...|$|R
40|$|INTRODUCTION Real-time {{systems are}} defined as those systems in which the {{correctness}} of the system depends {{not only on the}} logical result of computation, but also on the time at which the results are produced [9]. A real-time system is usually comprised of a set of cooperating tasks, which communicate by sharing resources or by message passing. A task typically senses the state of the system, performs certain computation, and if necessary sends commands to change the state of the system. Tasks in a real-time system are of two types, periodic tasks and aperiodic tasks [16]. Periodic tasks are invoked at regular intervals and their characteristics are known a priori. Whereas, aperiodic tasks are activated only when certain events occur and their characteristics are known only when they arrive. Each task has a deadline before which it should complete its execution. The problem of meeting task deadlines is of great importance in real-time systems, because <b>failure</b> <b>to</b> <b>meet</b> task <b>deadlines...</b>|$|R
5000|$|On 14 July 2008, {{facing the}} {{imminent}} <b>failure</b> <b>to</b> <b>meet</b> a self-imposed <b>deadline</b> <b>to</b> enact [...] "constitutional reform" [...] consisting of further devolution of powers to the nation's three linguistic communities, Leterme tendered his resignation to King Albert II. On 17 July, King Albert, after holding {{a flurry of}} consultations with leaders of political parties, labour unions, and the employers' association, rejected Leterme's resignation. Instead, the King appointed a three-person commission of representatives of the linguistic communities to investigate how to restart the reform process. The commission was {{to report to the}} King by 31 July 2008.|$|R
40|$|Jobs {{submitted}} into {{a cluster}} have varying requirements depending on user-specific needs and expectations. Therefore, in utility-driven cluster computing, cluster Resource Management Systems (RMSs) {{need to be}} aware of these requirements in order to allocate resources effectively. Service Level Agreements (SLAs) can be used to differentiate different value of jobs as they define service conditions that the cluster RMS agrees to provide for each different job. The SLA acts as a contract between a user and the cluster whereby the user is entitled to compensation whenever the cluster RMS fails to deliver the required service. In this paper, we present a proportional share allocation technique called LibraSLA that takes into account the utility of accepting new jobs into the cluster based on their SLA. We study how LibraSLA performs with respect to several SLA requirements that include: (i) deadline type whether the job can be delayed, (ii) deadline when the job needs to be finished, (iii) budget to be spent for finishing the job, and (iv) penalty rate for compensating the user for <b>failure</b> <b>to</b> <b>meet</b> the <b>deadline...</b>|$|R
40|$|This work {{addresses}} {{the problem of}} reducing context switch overhead on a processor which supports a large register file - a register file much like that {{which is part of}} the Berkeley RISC processors and several other emerging architectures (which are not necessarily reduced instruction set machines in the purest sense). Such a reduction in overhead is particularly desirable in a real-time embedded application, in which task-to-task context switch overhead may result in <b>failure</b> <b>to</b> <b>meet</b> crucial <b>deadlines.</b> A storage management technique by which a context switch may be implemented as cheaply as a procedure call is presented. The essence of this technique is the avoidance of the save/restore of registers on the context switch. This is achieved through analysis of the static source text of an Ada tasking program. Information gained during that analysis directs the optimized storage management strategy for that program at run time. A formal verification of the technique in terms of an operational control model and an evaluation of the technique's performance via simulations driven by synthetic Ada program traces are presented...|$|R
40|$|Testimony {{issued by}} the Government Accountability Office with an {{abstract}} that begins "In Berlin, Germany, the transition from analog to digital television (DTV), the DTV transition, culminated in the shutoff of analog television signals in August 2003. As GAO previously reported, the December 2006 deadline for {{the culmination of the}} DTV transition in the United States seems unlikely <b>to</b> be met. <b>Failure</b> <b>to</b> <b>meet</b> this <b>deadline</b> will delay the return of valuable spectrum for public safety and other commercial purposes. Thus, the rapid completion of the DTV transition in Berlin has sparked interest among policymakers and industry participants in the United States. At the request of the Subcommittee on Telecommunications and the Internet, House Committee on Energy and Commerce, GAO examined (1) the structure and regulation of the German television market, (2) how the Berlin DTV transition was achieved, and (3) whether there are critical components of how the DTV transition was achieved in Berlin and other areas of Germany that have relevance to the ongoing DTV transition in the United States. ...|$|R
