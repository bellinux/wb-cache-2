78|1896|Public
25|$|The {{antagonism}} of abjad versus alphabet, {{as it was}} {{formulated by}} Daniels, has been rejected by other scholars because abjad is also used as a term {{not only for the}} Arabic numeral system but, which is most important in terms of historical grammatology, also as term for the alphabetic device (i.e. letter order) of ancient Northwest Semitic scripts in opposition to the 'south Arabian' order. This caused fatal effects on terminology in general and especially in (ancient) Semitic philology. Also, it suggests that consonantal alphabets, in opposition to for instance the Greek alphabet, were not yet true alphabets and not yet entirely complete, lacking something important to be a fully working script system. It has also been objected that, as a set of letters, an alphabet is not the mirror of what should be there in a language from a phonemic or even phonological point of view, rather, it is the <b>data</b> <b>stock</b> of what provides maximum efficiency with least effort from a semantic point of view.|$|E
50|$|A Microsoft Excel add-in is {{used for}} {{communication}} between the Jedox OLAP database and the Excel front-end. Users can link any number of Excel workspaces on-line, all of which access one central <b>data</b> <b>stock</b> (single point of truth). The data entered in Microsoft Excel is written back and aggregated to the OLAP cube structure through the add-in. Due to the well-known Excel interface, specialists may use Jedox to create budgets, analyses, and reports without any specialist IT knowledge.|$|E
50|$|Arachne was {{developed}} in 1995 as a FileMaker-database and benefits since 2001 from {{the establishment of the}} Institute for Humanities Computing at the University of Cologne (Historisch-Kulturwissenschaftliche Informationsverarbeitung, HKI), whose students started to use arachne as a realistic test environment for serious programming projects. Thanks to the significant and continuous support by the German Research Foundation (DFG) since 2001 Arachne integrates also negative archives, which have significantly expanded the <b>data</b> <b>stock</b> of Arachne, hence the archives of the photographers Barbara Malter and Gisela Badura-Fittschen were digitized and documented. Since 2003 the negative archives of ancient sculpture of the German Archaeological Institute in Rome were added. All that totaled in 40.000 high quality scans of ancient sculptures, that are presented with a state-of-the-art scientific documentation.|$|E
30|$|In our {{analysis}} we used migration <b>stock</b> <b>data</b> rather than flow data of migration. Studies such as Ortega and Peri (2009), Brücker and Siliverstovs (2006), Grogger and Hanson (2011), Ramos and and Suriñach (2013) among others <b>data</b> have used <b>stock</b> <b>data.</b> Brücker and Siliverstovs (2006) {{argues that the}} analysis of stocks {{can be interpreted as}} a representation of a long-term equilibrium analysis. They argue that <b>stock</b> <b>data</b> are probably of higher quality than flow <b>data</b> because <b>stocks</b> <b>data</b> are based on national censuses, thus free from unambiguous net permanent moves and the undercounting of undocumented immigrants.|$|R
40|$|In this article, we {{describe}} two commands - fetchyahooquotes and fetchyahookeystats - that import historical financial data and key current finan- cial statistics from Yahoo! Finance. fetchyahooquotes, fetchyahookeystats, finance, financial <b>data,</b> <b>stocks,</b> exchange-traded funds, historical data, Yahoo! Finance...|$|R
3000|$|In fact, when {{we study}} the {{long-term}} effect {{of production and}} operation brought by OFDI, lagged <b>data</b> of OFDI <b>stock</b> <b>data</b> {{would be the most}} reasonable choice. For example, Zhou and Niu (2012), Chih-Fan and Dong (2013), Zhang and Huang (2013), Liu and Xie (2014), and Wang and Xiang (2014) used the current <b>stock</b> <b>data.</b> But since the current <b>stock</b> <b>data</b> is calculated based on current flow <b>data,</b> lagged <b>stock</b> <b>data</b> and investment profit. Since it includes information concerning the current flow data of OFDI, the problem of endogenous bias could not be avoided. In reality, no matter OFDI takes the form of merger and acquisition, the legal procedure, site construction, procurement and installation of production equipment, and recruitment and training of production personnel all need to consume a certain amount of time. Instead, lagged <b>data</b> of OFDI <b>stock</b> fully considered the required time lag that investment flow transformed into actual production capacity. Therefore, this paper selected the lagged terms of OFDI stock as the core explanatory variable in empirical analysis. 2 The paper also provides regression results using current flow <b>data</b> and <b>stock</b> <b>data</b> for comparison. They are based on the same set of sample so the differences between the conclusions are solely attributable to different selections of core explanatory variables. Regression results reveal that with the current flow and <b>stock</b> <b>data</b> as the explanatory variables, the estimated value and significance of promoting effect are overestimated while that of substitution effect are underestimated. The lag of <b>stock</b> <b>data</b> has no promoting effect on export. 3 [...]...|$|R
50|$|The {{antagonism}} of abjad versus alphabet, {{as it was}} {{formulated by}} Daniels, has been rejected by other scholars because abjad is also used as a term {{not only for the}} Arabic numeral system but, which is most important in terms of historical grammatology, also as term for the alphabetic device (i.e. letter order) of ancient Northwest Semitic scripts in opposition to the 'south Arabian' order. This caused fatal effects on terminology in general and especially in (ancient) Semitic philology. Also, it suggests that consonantal alphabets, in opposition to for instance the Greek alphabet, were not yet true alphabets and not yet entirely complete, lacking something important to be a fully working script system. It has also been objected that, as a set of letters, an alphabet is not the mirror of what should be there in a language from a phonemic or even phonological point of view, rather, it is the <b>data</b> <b>stock</b> of what provides maximum efficiency with least effort from a semantic point of view.|$|E
50|$|Since 2004 Arachne is {{operated}} by a consortium, consisting of the DAI and the CoDArchLab of the University of Cologne. In the same year Arachne has been reworked from the bottom structurally as well as editorially. The data of the FileMaker solution were exported, Arachne was rebuilt from scratch using an MAMP environment. Since 2006 {{as part of a}} multiphase-project (Emagines), funded by the DFG, the glass negatives of the German Archaeological Institute were digitized and the records were provided in the arachne database (finally 150,000 scans in 60,000 object records).As a result of the “Berlin Sculpture Network” another important <b>data</b> <b>stock</b> were added within the years 2009-2012: the Complete Catalog of Sculptures in the Antiquities Collection of the Berlin State Museums (Antikensammlung der Staatlichen Museen zu Berlin), which includes revised scientific catalog texts, images (colored) and archive material (“Archivalien”), altogether referring to 2,600 sculptures and are freely accessible in the Arachne since 2013. Furthermore, there are approximately 3,500 plaster casts of the Berlin Abgußsammlung, already provided in Arachne and associated with the datasets of the originals mentioned above.|$|E
40|$|FlyBase is a {{database}} of genetic and molecular data concerning Drosophila. FlyBase is maintained as a relational database (in Sybase) and {{is available from the}} ftp. bio. indiana. edu Gopher server. The scope of FlyBase includes: genes, alleles, aberrations, pointers to sequence <b>data,</b> <b>stock</b> lists, Drosophila workers and bibliographic references...|$|E
30|$|The company <b>stock</b> <b>data</b> and <b>stock</b> index <b>data</b> {{are from}} Datastream database. The firm {{financial}} data are from Worldscope database. The sample period is from 1993 to 2015.|$|R
40|$|Using certain {{artificial}} intelligence techniques, <b>stock</b> <b>data</b> mining has given encouraging results in both trend analysis and similarity search. However, representing <b>stock</b> <b>data</b> effectively {{is a key}} issue in ensuring {{the success of a}} data mining process. In this paper, we aim to compare the performance of numeric and symbolic data representation of a stock dataset in terms of similarity search. Given the properly normalized dataset, our empirical study suggests that the results produced by numeric <b>stock</b> <b>data</b> are more consistent as compared to symbolic <b>stock</b> <b>data.</b> ...|$|R
40|$|Abstract — This program {{begins with}} <b>stock</b> <b>data</b> {{retrieval}} using a syntax curl. <b>Stock</b> <b>data</b> {{will be taken}} based on the choice of date for the selected user. In the syntax of such a program will take the curl site <b>stock</b> <b>data</b> that will be targeted, finance. yahoo. com and select <b>stock</b> <b>data</b> companies what want is taken, this project takes data company Indosat Tbk. and then select the historical prices. There will appear the history <b>data's</b> <b>stocks</b> many years and updated automatically. After the site is loaded, and then take what is taken from page, this program takes the CSV API to put programming language. Prediction stock prices in this program using Least Square algorithm. Least Square algorithm is the algorithm {{that is used to}} predict future data came based on previous data. The more data that will be more predictable, then the results are more accurate. Beginning with the creation of tables analysis aims to conclude all of the <b>stock</b> <b>data</b> ad made into 1 <b>stock.</b> Taken <b>stock</b> <b>data</b> “high” only, as it would predict the highest stock price. After the analysis then the next entry to the Least Square formula. Least Square can only be to compute predictions 1 day ahead. The end result of the program {{is in the form of}} prediction results and graph. There are two predictions for the results, i. e. Results prediction 1 day ahead and prediction a few days ahead, and also added captions up or down in the price of the stock. And then visualized in the form of a graph line and bar chart. The graph of a line and bar chart for how to actually call him <b>stock</b> <b>data</b> is the same, but are distinguished by a type, line and columns. With the graphics users can find out next day stock price developments and up or down...|$|R
30|$|The {{required}} input includes historical mobility {{data from}} the <b>Data</b> <b>Stock,</b> predicted mobility (from the Passenger and Freight Demand modules), and user input changes to safety risk and safety risk causal factors. Risk {{is defined as the}} number of occurrences (fatalities, injuries) per unit of mobility (in vehicle-kilometer or number of trips).|$|E
40|$|A Capital Asset Pricing Model is {{estimated}} on French weekly <b>data,</b> <b>stock</b> returns heteroskedasticity being modelled using ARCH conditional variances. The main {{objective is to}} incorporate information generated by the risk premia variability in the underlying pricing model. Empirical results show that risk measures may well be specified as ARCH processes, whereas CAPM restrictions are rejected. ...|$|E
40|$|Every day, many {{customers}} buy {{many kinds of}} products like books, CD, and DVD etc, at online stores. Then, the companies often have giant <b>data</b> <b>stock</b> of the transactions. In academic viewpoint, the data {{is important because it}} is able to become a clue to understand the complexity of the market. The main issue is what kind of order i...|$|E
3000|$|... [...]) at time t+k. The {{approach}} is interesting {{in that it}} does not require other <b>data</b> than exports, <b>stock</b> changes, and prices. A drawback is that <b>stock</b> <b>data</b> are usually not available at the same time frequency as trade and price data: price and trade data are usually at monthly, weekly, and also daily frequency, whereas <b>stock</b> <b>data</b> are rarely available at such a high frequency.|$|R
5000|$|The Jedox OLAP {{database}} is a memory-based, multi-dimensional real-time OLAP server (MOLAP) that administers {{economic or}} statistical <b>data</b> <b>stocks</b> (multi-dimensional database). Apart from multi-dimensional queries, {{data can be}} written back and consolidated in real-time. The server keeps all data in the cache for fast data access. APIs in Java, PHP, C/C++, or [...]NET {{can be used to}} integrate the Jedox OLAP database in other software environments.|$|R
5000|$|... 2005: Trade Stocks & Commodities With The Insiders, on {{a way to}} use the <b>data</b> for <b>stock</b> index futures.|$|R
40|$|In this {{appendix}} {{we describe}} the data we use in the paper, their detrending and time aggregation and we provide the raw data as well as selected summary statistics. This appendix describes the data used in this paper. The …nancial <b>data</b> (<b>stock</b> returns, interest rate data) and the price index numbers from the CPI stem from Campbell (2003), and are available publicly a...|$|E
40|$|Production {{plans are}} often not {{applicable}} in practice {{due to the fact}} that the data base presupposed during the computation of the plan has changed during its realization. Therefore the current plan can become inecient or even infeasible. To cope with this often occurring problem this paper gives a brief description of a general adaptable control concept for arbitrary production and logistic systems. In this concept very ecient replanning instruments have to be designed which are able to nd new production plans in real-time simultaneously to the execution of the controlled processes. 1 Introduction A main problem arising during the realization of existing production plans concerns the often only short validity of the <b>data</b> <b>stock</b> presupposed during the computation of the current operative production plan. Therefore the current production plan can become inecient or even infeasible if this <b>data</b> <b>stock</b> changes during the execution of the production process. Today companies are often co [...] ...|$|E
40|$|The {{interconnection}} of heterogeneous and autonomous {{data sources}} for information sharing demands for exible and extensible integrative components. In this paper {{we present a}} universal architecture for building wrapper com-ponents to access various types of heterogeneous informa-tion sources. The wrapper comprises an event detection subsystem to detect and propagate modications of the <b>data</b> <b>stock.</b> The architecture proposed especially supports En-hanced Active Database Systems, which are able to actively notify their tightly-coupled wrapper components about data changes. ...|$|E
25|$|In the past, nations {{tended to}} keep more sizable food stockpiles, but more recently, {{due to a}} faster pace of food growth and ease of importation, less {{emphasis}} is placed on high stockpiles. For example, in February 2008 wheat stockpiles hit a 60-year low in the United States (see also Rice shortage). <b>Data</b> <b>stocks</b> are often calculated as a residual between Production and Consumption but it becomes difficult to discriminate between a de-stocking policy choices of individual countries and a deficit between production and consumption.|$|R
40|$|Abstract: During the {{analysis}} of knowledge processes in enterprises it often turns out that simple access to existing enterprise knowledge which is covered in documents is not possible. To enable access to a company’s document and <b>data</b> <b>stocks</b> Information Retrieval (IR) technologies play a central role. In the following we describe the underlying theory of the SemanticMiner system, including methods and technologies as well as continuing approaches to obtain Knowledge Retrieval (KR) by dint of semantic technologies. Key Words: information retrieval, knowledge management, knowledge representation, ontology, logi...|$|R
50|$|In the past, nations {{tended to}} keep more sizable food stockpiles, but more recently, {{due to a}} faster pace of food growth and ease of importation, less {{emphasis}} is placed on high stockpiles. For example, in February 2008 wheat stockpiles hit a 60-year low in the United States (see also Rice shortage). <b>Data</b> <b>stocks</b> are often calculated as a residual between Production and Consumption but it becomes difficult to discriminate between a de-stocking policy choices of individual countries and a deficit between production and consumption.|$|R
30|$|In {{comparison}} with the classical integer-order calculus, the fractional calculus has natural advantages in describing systems possessing memory and hereditary properties. In recent years, the classical mathematical modeling approaches coupled with the stochastic methods {{have been used to}} develop stochastic dynamic models for financial <b>data</b> (<b>stock</b> price). In order to extend this approach to more complex dynamic processes in sciences and engineering operating under internal structural and external environmental perturbations, we establish stochastic fractional differential equations by introducing the concept of dynamics processes operating under a set of linearly independent time-scales.|$|E
40|$|We {{investigate}} the behaviour of stock returns in Africa’s largest markets namely, Egypt, Kenya, Morocco, Nigeria, South Africa, Tunisia and Zimbabwe. The {{validity of the}} random walk hypothesis is examined and rejected by employing a battery of tests. Secondly we employ smooth transition and conditional volatility models to uncover {{the dynamics of the}} first two moments and examine weak from efficiency. The empirical stylized facts of volatility clustering, leptokurtosis and leverage effect are present in the African <b>data..</b> <b>Stock</b> Returns, Weak Form Efficiency, Asymmetric Volatility and African Stock Markets. ...|$|E
40|$|Abstract- Lognormal {{distribution}} has wide {{applications in}} the analysis of failure time <b>data,</b> <b>stock</b> prices and rainfall. In this paper we derive Bayes estimator and credible regions for the mean of the lognormal distribution. We compare the coverage probability and length of the Bayes credible interval with the confidence interval obtained from the maximum likelihood estimator of the log location and scale parameters. The procedure is illustrated using the failure time data of locomotive control and stock price. Keywords- Lognormal distribution, stock prices, Bayes estimator and credible regions, confidence interval, maximum likelihood estimator. I...|$|E
5000|$|Calculating {{market value}} and EPS impact of fossil fuel price changes uses {{publicly}} available <b>data</b> on <b>stock</b> returns, analyst earnings estimates, and fossil fuel producer prices. Steps are: ...|$|R
40|$|Innovation in {{the field}} of {{environmental}} surveillance is pushed by extended environmental legislation, by development of new sensors and by innovation of information and communication technology. In addition to air quality control and surface water quality control the protection of soils and ground water, the automation of analytical laboratory procedures and the development of environmental information systems will gain primary interest. Environmental information systems open the way from expanding environmental <b>data</b> <b>stocks</b> to the availability of appropriate information. This will be the most important contribution to environmental protection in the next years...|$|R
40|$|Abstract. To gain {{knowledge}} out of {{your data}}, your data has to be of high quality. Bad data quality {{becomes more and more}} the problem for companies, who start to exploit their <b>data</b> <b>stocks.</b> This article will show the main obstacles on the way to perfect data quality. It is based on our experience to improve data quality in large customer or business partner databases. The examples mentioned in this paper show data defects we have found during our daily work. There are also some notes how to improve data quality and avoid data defects. ...|$|R
40|$|Abstract — Massive {{datasets}} arise naturally as {{a result}} of automated monitoring and transaction archival. Military intelligence <b>data,</b> <b>stock</b> trades, retail purchases, medical and scientific observations, weather monitoring, spacecraft sensor data and censors data are all examples of data streams continuously logged and stored in extremely large volumes, which create the need for innovative data visualization solutions. Although, there are many on-going researches and developments on this field recently, there are only few solutions to visualize information for general public. In this paper, I explore different methods to use ManoStick chart to visualize information. Index Terms—data visualization, chart, graph, manostic...|$|E
40|$|We empirically {{analyze the}} return on {{investment}} of different casino resort amenities (e. g., casinos, hotels, restaurants, and other entertainment). We model casino corporation stock prices using regression analysis of cross-sectional time series <b>data.</b> <b>Stock</b> prices are explained by variables that represent firm-level investments in and revenues from different functional areas of the typical casino resort, and two macroeconomic control variables. Results {{are sensitive to the}} dependent return variable chosen; and revenue variable results differ from expenditure variable results. This suggests that subsequent research should focus on market-specific analyses, which may help to determine which amenities provide greatest returns in particular markets...|$|E
40|$|The article {{presents}} a study regarding {{the influence of}} international institutional investors on local equity prices. The study used the comprehensive company-level ownership data from the Pacific-Basin Capital Markets (PACAP) Research Center databases including the accounting <b>data,</b> <b>stock</b> prices, and return data for stocks traded in Tokyo Stock Exchange in Japan from 1975 to 2006. Results showed {{that there was a}} strong correlation between the equity size premium and the investment flows of international institutional investors. Moreover, equity size premium was reversed in mid- 1990 s when investment flows shifted into larger stocks. Hao Jiang, Takeshi Yamad...|$|E
50|$|Other uses of push-enabled web {{applications}} include market <b>data</b> distribution (<b>stock</b> tickers), online chat/messaging systems (webchat), auctions, online betting and gaming, sport results, monitoring consoles, and {{sensor network}} monitoring.|$|R
5000|$|... #Subtitle level 4: Internet-based <b>data</b> {{sources for}} <b>stock</b> market {{prediction}} ...|$|R
40|$|A web-based stock {{prediction}} {{system is}} developed {{based on a}} fuzzy neural network by using the past <b>stock</b> <b>data</b> to discover fuzzy rules and make future predictions. The learning algorithm is implemented. Input data to each network are the moving averages of the weekly <b>stock</b> <b>data,</b> which are obtained from [Online] Availabl...|$|R
