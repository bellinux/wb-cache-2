11|4|Public
50|$|In the Hilbert R-tree, {{there is}} no need to re-insert {{orphaned}} nodes whenever a <b>father</b> <b>node</b> underflows. Instead, keys can be borrowed from the siblings or the underflowing node is merged with its siblings. This is possible because the nodes have a clear ordering (according to Largest Hilbert Value, LHV); in contrast, in R-trees {{there is no}} such concept concerning sibling nodes. Notice that deletion operations require s cooperating siblings, while insertion operations require s - 1 siblings.|$|E
30|$|SAT [17] i.e., Secure Aggregation Tree is {{a method}} that detects and {{prevents}} cheating in the network. This method does not use any cryptographic operation; however, detection of cheating {{is based on the}} topological constraints in the aggregation tree. This method is different from other proposed methods as it is based on cheating detection instead of persistent data authentication. With topological constraints in SAT, each node can hear all messages sent to its <b>father</b> <b>node</b> and message sent by a <b>father</b> <b>node</b> to its grandfather node, that help to check whether <b>father</b> <b>node</b> performs the Data Aggregation correctly or not. If the <b>father</b> <b>node</b> sends aggregated value which is different from the correct aggregation value, then the node will raise an alert. On receiving the alert message by neighbouring nodes they all check whether the cheating node is its <b>father</b> <b>node</b> or not. If yes, then weighted confidence is evaluated. If the weighted confidence value is larger than a predefined threshold value, then the <b>father</b> <b>node</b> is assigned to be cheating node and a detection confirmation message is broadcasted within a given hop limit. After that, the node receiving the detection confirmation message will use recovery mechanism to avoid using the compromised node. During Data Aggregation, a metric to represent the degree of belief is generated for defining the uncertainty in the aggregated result. This framework effectively measures the uncertainty in both data and aggregation result.|$|E
3000|$|Each {{child must}} either be a leaf or {{the root of}} another tree, each node has a <b>father</b> <b>node</b> {{when it is not}} a root node; [...]...|$|E
50|$|Figure 1 {{highlights}} {{the problem of}} the lowx packed R-tree. Figure 1 Right shows the leaf nodes of the R-tree that the lowx packing method will create for the points of Figure 1 Left. The fact that the resulting <b>father</b> <b>nodes</b> cover little area explains why the lowx packed R-tree achieves excellent performance for point queries. However, the fact that the fathers have large perimeters explains the degradation of performance for region queries. This is consistent with the analytical formulas for R-tree performance. Intuitively, the packing algorithm should ideally assign nearby points to the same leaf node. Ignorance of the y coordinate by the lowx packed R-tree tends to violate this empirical rule.|$|R
40|$|Conditional Preference-nets (CP-nets for short) and {{possibilistic}} logic with symbolic weights are {{two different}} ways of expressing preferences, which leave room for incomparability in the underlying ordering between the different choices. Relations can be expressed between the two settings. A CP-net can be mapped to a weighted set of formulas, one per node of the CP-net, and appropriate constraints between symbolic weights of formula are defined according to the observed priority of <b>father</b> <b>nodes</b> over children nodes in the CP-net. Thus, each potential choice {{can be associated with}} a vector of symbolic weights which acknowledges the satisfaction, or not, of each node formula. However, this local priority between <b>father</b> and children <b>nodes</b> in the CP-net {{does not seem to be}} transitive. It may happen that the same pair of vectors in the possibilistic representations of two CP-nets correspond to decisions that are comparable in one CP-net structure and incomparable in the other. This troublesome situation points out the discrepancies between the two representation settings, the difficulties of an exact translation of one representation into the other, and questions the faithfulness of the preference representation in CP-nets from a user’s point of view. This note provides a preliminary discussion of these issues, using example...|$|R
30|$|Verb phrase (verb+{{noun phrase}}) (CBANP). In the parsing tree of a sentence, if a noun phrase node has an {{ancestor}} verb phrase node (VP), we say the noun phrase {{is dominated by}} the action in the VP. For instance, in “Register account”, the noun phrase node “account” has a <b>father</b> VP <b>node</b> of action “Register” as shown in Fig.  4 a, then the noun phrase {{is dominated by the}} action.|$|R
40|$|We {{consider}} multi-type Galton Watson trees, {{and find}} the distribution of these trees when conditioning on very general types of recursive events. It {{turns out that the}} conditioned tree is again a multi-type Galton Watson tree, possibly with more types and with offspring distributions, {{depending on the type of}} the <b>father</b> <b>node</b> and on the height of the <b>father</b> <b>node.</b> These distributions are given explicitly. We give some interesting examples for the kind of conditioning we can handle, showing that our methods have a wide range of applications. Comment: 17 pages, 3 figure...|$|E
30|$|The <b>father</b> <b>node</b> {{adds the}} new son node in its sons list. The {{surrounding}} nodes that heard the Father message add the new node to {{their list of}} neighbors.|$|E
40|$|Many complex {{networks}} have displayed the community structures, and {{the detection of}} community structure can give insights into the structural and functional information of these complex networks. In this paper, we proposed a neighbor similarity based new algorithm for community structure detection, in which we only consider the similarities between a node and its unclassified neighbors in the breadth-first traversal order, without considering other nodes’ influences; we take this node as a <b>father</b> <b>node</b> and its neighbors as the children nodes, to find out those children nodes which should belong in the same community with their <b>father</b> <b>node.</b> Then these children nodes are processed {{in the same way}} as their <b>father</b> <b>node</b> recursively, until the termination condition is reached. The most prominent property of our algorithm is that it has near liner time complexity, and furthermore it is a deterministic algorithm. We have tested our algorithm on several real networks, compared with some other algorithms, and the results have manifested that our algorithm outperforms the previous algorithms significantly.  </p...|$|E
40|$|Abstract. In this paper, we model {{learning}} to rank algorithms based on structural dependencies in hierarchical multi-label text categorization (TC). Our method uses the classification probability of the binary clas-sifiers {{of a standard}} top-down approach to generate k-best hypotheses. The latter are generated according to their global probability {{while at the same}} time satisfy the structural constraints between <b>father</b> and children <b>nodes.</b> The rank is then refined using Support Vector Machines and tree kernels applied to a structural representation of hypotheses, i. e., a hier-archy tree in which the outcome of binary one-vs-all classifiers is directly marked in its nodes. Our extensive experiments on the whole Reuters Corpus Volume 1 show that our models significantly improve over the state of the art in TC, thanks to the use of structural dependecies. ...|$|R
40|$|In {{this paper}} we {{introduce}} the triangular heap, a heap {{with the special}} property that for every <b>father</b> <b>node</b> its right child (if present) is smaller than its left child. We show how triangular heaps {{can be applied to}} the traditional problem of sorting an array in situ in ways quite similar to well-known methods using ordinary heaps. An average case analysis is presented for the construction and for the sorting process of both ordinary and triangular heaps. Keywords: data structures, analysis of algorithms, heaps, heapsort. 1 Introduction In this paper we propose the triangular heap, a heap with the special property that for every <b>father</b> <b>node</b> (the key of) its right child [...] -if present [...] - is smaller than (the key of) its left child. Whereas in a heap the largest node always takes the first position (i. e. the root), in a triangular heap both the largest and the second largest node can always be found in first and second position (i. e. in the root and in the left child of the root). The h [...] ...|$|E
30|$|There are two lists in this algorithm: the O-list and the C-list. The open list, {{known as}} the O-list, {{contains}} the nodes that are candidates for exploration. The closed list, {{known as the}} C-list, contains the nodes {{that have already been}} explored. The nodes from the C-list were previously on the O-list, but as they are explored they are moved to the C-list. The nodes on these lists store the <b>father</b> <b>node,</b> which is the node used to optimally reach them. This is the node that lies in the shortest path from the original to the current node. If the heuristic function is admissible, then the path cost of q_goal is guaranteed to be optimal.|$|E
3000|$|DBFS_n-A* {{selection}} {{a spectrum}} of selection strategies {{can be obtained by}} combining the one from A* and the one from MCTS by varying n= 0 to n=d, where d is the length of the path from the root to S_E hit by DBFS. As illustrated in Fig. 3 f, one end is DBFS_ 0 -A that hits S_E by MCTS without using A*. Generally, DBFS_n-A* conducts DBFS search to return back for n nodes along the path from S_E back to the root. For examples, DBFS_ 1 -A* returns back to its <b>father</b> <b>node,</b> while A* or precisely BFS selects the best among all the children (i.e. ones indicated by double circle [...]) as S_E; DBFS_ 2 -A* returns back for two nodes, while BFS selects the best among all its children and grandchildren (i.e. add in two double circled nodes) as S_E, so forth. The other end is DBFS_d-A that returns back to the root and becomes equivalent to A* that picks the best among OPEN.|$|E
40|$|Abstract: Traditional outlier mining methods {{identify}} outliers from {{a global}} point of view. These methods are inefficient to find locally-biased data points (outliers) in low dimensional subspaces. Constrained concept lattices {{can be used}} as an effective formal tool for data analysis because constrained concept lattices have the characteristics of high constructing efficiency, practicability, and pertinency,. In this paper，we propose an outlier mining algorithm that by treats the intent of any constrained concept lattice node as a subspace. We introduce sparsity and density coefficientsto measure outliers in low dimensional subspaces. The intent of any constrained concept lattice node is regarded as a subspace，and sparsity subspaces are searched by traversing the constrained concept lattice according to a sparsity coefficient threshold. If the intent of any <b>father</b> <b>node</b> of the sparsity subspace is a density subspace according to a density coefficient threshold, then objects contained in the extent of the sparsity subspace node are considered as bias data points or outliers. Our experimental results show that the proposed algorithm performs very well for high red-shift spectral data sets...|$|E
40|$|We {{introduce}} {{the concept of}} a "simple local property" of a binary (search) tree, as a property for which a "weight" can be attached to every node of the tree and this weight depends in a simple way on the weight of its <b>father</b> <b>node.</b> We give formulae to compute the average weight of any single node and the corresponding variance, with respect to all the trees with a predefined number of nodes. We show by examples that many useful properties of binary trees are simple local and therefore can be studied by means of our method. In particular, we give an exact formula for the sequential allocation of binary trees to secondary storage, as proposed by Muntz and Uzgalis. Finally, we propose an algorithm to improve the space-performance of the grouped allocation introduced by the same authors. This algorithm depends on the solution of what we call the "father problem" for a binary tree. This consists in finding the father of a node, when it has not been reached by the usual searching procedure for binary trees. We show that the father problem can be formulated as a property very similar to a simple local property and can be studied accordingly,. proving that the problem can be solved in a constant average number of accesses to nodes...|$|E

