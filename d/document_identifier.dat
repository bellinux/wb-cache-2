25|66|Public
5000|$|... {{a system}} of {{globally}} unique identifiers for resources on the Web and elsewhere, the universal <b>document</b> <b>identifier</b> (UDI), later known as uniform resource locator (URL) and uniform resource identifier (URI); ...|$|E
50|$|GeneRIFs {{are always}} {{associated}} with specific {{entries in the}} Entrez Gene database. Each GeneRIF has a pointer to the PubMed ID (a type of <b>document</b> <b>identifier)</b> of a scientific publication that provides evidence for the statement made by the GeneRIF. GeneRIFs are often extracted directly from the document that is identified by the PubMed ID, very frequently from its title or from its final sentence.|$|E
50|$|A Nature Precedings {{preprint}} {{is cited}} like a traditional journal article. However, the preprint's DOI {{is used as}} the <b>document</b> <b>identifier</b> instead of journal volume, issue, and page numbers. Scientists and journal publishers have expressed concerns regarding preprint submissions to Nature Precedings and whether these submissions would lead to violations of the Ingelfinger rule, a policy in which journals will not publish a manuscript if its findings have been reported elsewhere.|$|E
40|$|Ankara : The Department of Computer Engineering and the Institute of Engineering and Science of Bilkent University, 2008. Thesis (Master's) [...] Bilkent University, 2008. Includes bibliographical {{references}} leaves 43 - 46. Compression of inverted indexes received great {{attention in}} recent years. An inverted index consists of lists of <b>document</b> <b>identifiers,</b> also referred as posting lists, for each term. Compressing an inverted index reduces {{the size of}} the index, which also improves the query performance due to the reduction on disk access times. In recent studies, it is shown that reassigning <b>document</b> <b>identifiers</b> has great effect in compression of an inverted index. In this work, we propose a novel technique that reassigns both term and <b>document</b> <b>identifiers</b> of an inverted index by transforming the matrix representation of the index into a block-diagonal form, which improves the compression ratio dramatically. We adapted row-net hypergraph-partitioning model for the transformation into block-diagonal form, which improves the compression ratio by as much as 50...|$|R
50|$|Here {{are some}} GeneRIFs taken from Entrez Gene for GeneID 7157, the human gene TP53.The PubMed <b>document</b> <b>identifiers</b> have been {{omitted from the}} examples. Note the wide {{variability}} {{with respect to the}} presence or absence of punctuation and of sentence-initial capital letters.|$|R
40|$|Two {{new office}} {{document}} file formats (Office Open XML and OpenDocument Format) {{make it easier}} to glean time stamps and unique <b>document</b> <b>identifiers</b> while also improving opportunities for file carving and data recovery. This work was funded in part by the US Naval Postgraduate Schoolâ s Research Initiation Program...|$|R
40|$|Some {{issues have}} title: Defense Integrated Data System DIDS {{procedures}} manual. "DOD 4100. 39 -M" [...] Cover. Description based on: v. 5, July 1989 v. 1 General and administrative information [...] v. 2 Multiple applictaion procedures [...] v. 3 Development {{and maintenance of}} item logistics data tools [...] v. 4 Item identification [...] v. 5 Data bank interrogations/search [...] v. 6 Supply management [...] v. 7 Establish/maintenance of organizational entity and provisioning screening master address table [...] v. 8 <b>Document</b> <b>identifier</b> code input/output formats (fixed length) [...] v. 9 <b>Document</b> <b>identifier</b> code input/output formats (variable length) [...] v. 10 Multiple application references/instructions/tables and gridsUpdated by irregularly issued changes. Mode of access: Internet...|$|E
40|$|Human {{relevance}} {{judgments are}} a key component for measuring the effectiveness of information retrieval systems using test collections. Since relevance is not an absolute concept, human assessors can disagree on particular topic-document pairs {{for a variety of}} reasons. In this work we investigate the effect that document presentation order has on inter-rater agreement, comparing two presentation ordering approaches similar to those used in IR evaluation campaigns: decreasing relevance order and <b>document</b> <b>identifier</b> order. We make a further distinction between "easy" topics and "hard" topics in order to explore system effects on inter-rater agreement. The results of our pilot user study indicate that assessor agreement is higher when documents are judged in <b>document</b> <b>identifier</b> order. In addition, there is higher overall agreement on easy topics than on hard topics...|$|E
40|$|This {{procedure}} {{establishes a}} uniform numbering system (<b>document</b> <b>identifier)</b> for all Program and project technical, cost, and schedule baseline documents, and selected management and procurement documents developed for or {{controlled by the}} Office of Civilian Radioactive Waste Management (OCRWM) for the Civilian Radioactive Waste Management System (CRWMS). The <b>document</b> <b>identifier</b> defined in this procedure is structured {{to ensure that the}} relational integrity between configuration items (CIs) and their associated documentation and software is maintained, traceable, categorical, and retrievable {{for the life of the}} program. This revision reflects an update of the document type codes and originator codes, and includes a code for construction specifications. A draft of the revised procedure was circulated for review by all Program offices, and all comments that were received were satisfactorily resolved and incorporated...|$|E
40|$|Web {{search engines}} serve {{millions}} of query requests per day. Caching query results {{is one of}} the most crucial mechanisms to cope with such a demanding load. In this paper, we propose an efficient storage model to cache <b>document</b> <b>identifiers</b> of query results. Essentially, we first cluster queries that have common result documents. Next, for each cluster, we attempt to store those common <b>document</b> <b>identifiers</b> in a more compact manner. Experimental results reveal that the proposed storage model achieves space reduction of up to 4 %. The proposed model is envisioned to improve the cache hit rate and system throughput as it allows storing more query results within a particular cache space, in return to a negligible increase in the cost of preparing the final query result page. © 2008 IEEE...|$|R
5000|$|The {{start tag}} may also include {{attributes}} within the tag. These indicate other information, such as identifiers for sections within the <b>document,</b> <b>identifiers</b> used to bind style {{information to the}} presentation of the document, and for some tags such as the [...] used to embed images, the reference to the image resource.|$|R
40|$|Abstract Recent studies {{demonstrated}} {{that it is}} possible to reduce Inverted Files (IF) sizes by reassigning the <b>document</b> <b>identifiers</b> of the original collection, as this lowers the distance between the positions of documents related to a single term. Variable-bit encoding schemes can exploit the average gap reduction and decrease the total amount of bits per document pointer. This paper presents an efficient solution to the reassignment problem, which consists in reducing the input data dimensionality using a SVD transformation, as well as considering it a Travelling Salesman Problem (TSP). We also present some efficient solutions based on clustering. Finally, we combine both the TSP and the clustering strategies for reordering the <b>document</b> <b>identifiers.</b> We present experimental tests and performance results in two text TREC collections, obtaining good compression ratios with low running times, and advance the possibility of obtaining scalable solutions for web collections based on the techniques presented here...|$|R
40|$|Given a text {{collection}} ofN {{documents and}} T terms, an inverted file {{is a set}} of posting lists, storing information for everyti 2 T Each posting list follows the form ;dik <dij 8 k<j where fti stands for the frequency of the term ti (number of documents in which ti appears), and dik is the k-th <b>document</b> <b>identifier</b> for the termi...|$|E
40|$|ISBN Number: n/a n/a <b>Document</b> <b>Identifier</b> Edition Number: 1. 0 n/a Edition Date: 5 June 2009 On 30 December 2008, the European Community and the European Organisation for the Safety of Air Navigation (“EUROCONTROL”) {{concluded}} a cooperation agreement for {{the provision of}} support by EUROCONTROL to the European Commission for the inclusion of aviation in the scheme for greenhouse gas emission allowances trading within the Community (European Union Emissions Trading Scheme, EU ETS) ...|$|E
40|$|We {{present the}} {{foundations}} of DocTrack, a digital and paper document identification, distribution, augmentation and interaction system. Printed documents are tagged with an encoded <b>document</b> <b>identifier,</b> allowing the digital version of the document content to be remotely recalled from its paper counterpart using a webcam or mobile device with a camera. We present results regarding the available document space, discuss the relevance of this approach {{in the light of}} existing research and outline the proposed applications of the system and future work planned to enable this. 1...|$|E
40|$|We {{introduce}} a new representation of the inverted index that performs faster ranked unions and intersections while using less space. Our index {{is based on the}} treap data structure, which allows us to intersect/merge the <b>document</b> <b>identifiers</b> while simultaneously thresholding by frequency, instead of the costlier two-step classical processing methods. To achieve compression we represent the treap topology using compact data structures. Further, the treap invariants allow us to elegantly encode differentially both <b>document</b> <b>identifiers</b> and frequencies. Results show that the space consumption is below 10 % {{of the size of the}} corpus and the index performs queries up to twice as fast than previous compact representations, which in addition require more space. Modern two-stage (massive filtering / detailed ranking) information retrieval systems would benefit from this boosting of the filtration stage of the query resolution process, which would free more resources for the ranking stage, thus enabling more precise results within a given time budget. 1...|$|R
40|$|Granting {{efficient}} accesses to {{the index}} {{is a key}} issue for the performances of Web Search Engines (WSE). In order to enhance memory utilization and favor fast query resolution, WSEs use Inverted File (IF) indexes where the posting lists are stored as sequences of d gaps (i. e. differences among successive <b>document</b> <b>identifiers)</b> compressed using variable length encoding methods. This paper describes {{the use of a}} lightweight clustering algorithm aimed at assigning the <b>identifiers</b> to <b>documents</b> in a way that minimizes the average values of d gaps. The simulations performed on a real dataset, i. e. the Google contest collection, show that our approach allows to obtain an IF index which is, depending on the d gap encoding chosen, up to 23 % smaller than the one built over randomly assigned <b>document</b> <b>identifiers.</b> Moreover, we will show, both analytically and empirically, that the complexity of our algorithm is linear in space and time...|$|R
40|$|Index {{compression}} {{has been}} a major issue in the field of Information Retrieval Systems. In particular, due to the impressive figures involved with Web Search Engines (WSEs) the compression of the index is not an option anymore but it has become a must. The most important index compression methods are designed to work for Inverted File (IF) indexes. These methods are {{based on the assumption that}} the posting lists are stored as sequences of d gaps (i. e. differences among successive <b>document</b> <b>identifiers).</b> The compression is thus carried out by using variable length encoding methods which represents smaller number using a smaller number of bits. In this paper, instead of focusing on finding a novel encoding method, we propose an algorithm which allows the assignment of <b>identifiers</b> to <b>documents</b> in a way that minimizes the average values of d gaps. The simulations performed on a real dataset, i. e. the Google contest collection, show that our approach allows to obtain an IF index which is, depending on the d gap encoding chosen, up to 23 % smaller than the one built over randomly assigned <b>document</b> <b>identifiers.</b> Moreover, we will show, both analytically and empirically, that the complexity of our algorithm is linear in space and time...|$|R
40|$|<b>Document</b> <b>Identifier</b> Reference SRC DOC 6 srcdoc 06 _e 4. 0 _ri_web Edition Number 4. 0 Edition Date 29 - 06 - 2012 This {{document}} {{describes the}} review process {{used by the}} SRC {{for the development of}} a SRC Review Report on the safety of European ATM programmes. The process and its output is intended to facilitate, through an early coordination of views, the harmonisation of the approaches used by the relevant authorities (i. e. NAAs and progressively EASA) when they exercise their acceptance and oversight responsibilities with regard to the implementation of those programmes...|$|E
40|$|The RDF/XML {{serialization}} for OWL {{has proven}} quite successful as an interchange format, {{but it was}} never intended to be read or written by humans, nor to serve as an API for ontology manipulation—complex and verbose encodings make the encoding of even simple ontological structures quite arcane. In this deliverable we describe three different surface syntaxes which can be mapped to OWL: the Open Biological Ontologies format, a new Structured Ontology Format designed specifically to make working with OWL ontologies easier, and Object Role Modeling. <b>Document</b> <b>Identifier</b> KWEB/ 2007 /D 2. 5. 7 /v 1. 0 Projec...|$|E
40|$|Purpose – An {{issue which}} tends to be ignored in {{information}} retrieval {{is the issue of}} updating inverted files. This is largely because inverted files were devised to provide fast query service, and much work has been done with the emphasis strongly on queries. In this paper we study the effect of using parallel methods for the update of inverted files in order to reduce costs, by looking at two types of partitioning for inverted files: <b>document</b> <b>identifier</b> and term identifier. Design/methodology/approach – Raw update service and update with query service are studied with these partitioning schemes using an incremental update strategy. We use standard measures used in parallel computing such as speedup to examine the computing results and also the costs of reorganising indexes while servicing transactions. Findings – Empirical results show that for both transaction processing and index reorganisation the <b>document</b> <b>identifier</b> method is superior. However, there is evidence that the term identifier partitioning method could be useful in a concurrent transaction processing context. Practical implications – There is an increasing need to service updates which is now becoming a requirement of inverted files (for dynamic collections such as the Web), demonstrating that a shift in requirements of inverted file maintenance is needed from the past. Originality/value – The paper is of value to database administrators who manage large-scale and dynamic text collections, and who need to use parallel computing to implement their text retrieval services...|$|E
40|$|Granting {{efficient}} and fast accesses to the index {{is a key}} issuefor performances of Web Search Engines. In order to enhancememory utilization and favor fast query resolution, WSEs useInverted File (IF) indexes that consist of an array of theposting lists where each posting list {{is associated with a}} termand contains the term as well as the identifiers of the documentscontaining the term. Since the <b>document</b> <b>identifiers</b> are stored insorted order, they can be stored as the difference between thesuccessive documents so as {{to reduce the size of}} the index. Thispaper describes a clustering algorithm that aims atpartitioning the set of documents into ordered clusters so thatthe documents within the same cluster are similar and are beingassigned the closer <b>document</b> <b>identifiers.</b> Thus the averagevalue of the differences between the successive documents willbe minimized and hence storage space would be saved. Thepaper further presents the extension of this clustering algorithmto be applied for the hierarchical clustering in which similarclusters are clubbed to form a mega cluster and similar megaclusters are then combined to form super cluster. Thus thepaper describes the different levels of clustering whichoptimizes the search process by directing the searchto a specific path from higher levels of clustering to the lowerlevels i. e. from super clusters to mega clusters, then to clustersand finally to the individual documents so that the user gets thebest possible matching results in minimum possible time...|$|R
5000|$|The Global <b>Document</b> Type <b>Identifier</b> (GDTI) {{is part of}} the GS1 {{system of}} standards. It is a simple tool to {{identify}} a document by type and can identify documents uniquely where required.|$|R
40|$|We like {{to propose}} here a {{standard}} for text mining output. The output standard is a data object that captures the relationships found with text mining, the <b>document</b> <b>identifiers,</b> the sentences from where the results originate, the method used, and its metrics. Such an output standard would enable a user-oriented comparison of text mining results. Currently, text-mining results are mainly evaluated on their performance in finding relevant results. By enabling a text mining out standard, the results become available to the larger user community. The data is immediately accessible {{to a wide range}} of applications. If a text mining method supports our output standard, the pathway curation community can use it in Pathvisio through our plug-in...|$|R
40|$|Deliverable D 2. 3. 8 v 1 (WP 2. 3) proposes {{the dynamic}} {{ontology}} lifecycle schema and discusses its implementation. It provides concrete solutions to ontology development and evolution issues in highly dynamic and data-intensive environments. Particularly, {{it deals with}} proper placement of ontology learning, evaluation and negotiation methods and with integration of learned and collaborative ontologies in a novel way. The transfer possibilities of the framework are justified by elaborated application scenarios from the medicine domain. Keyword list: ontology, ontology lifecycle, ontology development, dynamic ontology evolution, ontology integration, meaning negotiation, ontology versioning Copyright c © 2007 The contributors <b>Document</b> <b>Identifier</b> KWEB/ 2007 /D 2. 3. 8 /v 1. ...|$|E
40|$|<b>Document</b> <b>Identifier</b> Edition Number: 2. 2 Edition Date: 07 / 04 / 2008 This {{document}} {{defines the}} ATM Surveillance Strategy for ECAC from today to 2020 +. The document identifies the operational drivers for change {{during that period}} and identifies the surveillance evolution necessary to enable the operational changes. In brief it foresees (for En-Route and TMA airspace) : The continuation of Primary Surveillance Radars where required. A migration to dependent cooperative surveillance (based on ADS-B) combined with Cooperative Independent Surveillance such as SSR Mode-S and/or Wide Area Multilateration. An increasing use of Aircraft Derived Data. An increasing use of surveillance data onboard the aircraft to support Airborne Separation Assistance System applications (Situational Awareness, Spacing, Separation) and later an increasing delegation of responsibility for Self-Separation to the aircraft...|$|E
40|$|Search {{on the web}} is a daily {{activity}} for many people throughout the world. Applications based on search are everywhere. We are in a data rich situation this becomes an obstacle for Information retrieval system. In this paper, we propose a pipelining architecture of indexing {{in order to enhance}} memory utilization and fast query optimization and also a soft clustering algorithm is applied to group documents into clusters hierarchically linked. Each cluster is labeled with is most relevant term known as <b>document</b> <b>identifier.</b> Such that documents within the same cluster are similar. In this way it will create hierarchy of index so that search will travel from lower level to higher level. The comparisons of the document against the user query will direct to specific clusters not the whole collection of clusters...|$|E
40|$|Web Search Engines {{provide a}} {{large-scale}} text document retrieval service by processing huge Inverted File indexes. Inverted File indexes allow fast query resolution and good memory utilization since their d-gaps representation can be {{effectively and efficiently}} compressed by using variable length encoding methods. This paper proposes and evaluates some algorithms aimed to find an assignment of the <b>document</b> <b>identifiers</b> which minimizes the average values of d-gaps, thus enhancing the effectiveness of traditional compression methods. We ran several tests over the Google contest collection in order to validate the techniques proposed. The experiments demonstrated the scalability and effectiveness of our algorithms. Using the proposed algorithms, {{we were able to}} sensibly improve (up to 20. 81 %) the compression ratios of several encoding schemes. Categories and Subject Descriptors H. 3. 4 [Information Storage and Retrieval]: System...|$|R
40|$|Measuring the {{information}} retrieval effectiveness of Web search engines {{can be expensive}} if human relevance judgments are required to evaluate search results. Using implicit user feedback for search engine evaluation provides a cost and time effective manner of addressing this problem. Web search engines can use human evaluation of search results without the expense of human evaluators. An additional advantage {{of this approach is}} the availability of real time data regarding system performance. We capture user relevance judgments actions such as print, save and bookmark, sending these actions and the corresponding <b>document</b> <b>identifiers</b> to a central server via a client application. We use this implicit feedback to calculate performance metrics, such as precision. We can calculate an overall system performance metric based on a collection of weighted metrics...|$|R
40|$|Graph {{reordering}} is {{a powerful}} technique to increase the locality of the representations of graphs, which {{can be helpful in}} several applications. We study how the technique can be used to improve compression of graphs and inverted indexes. We extend the recent theoretical model of Chierichetti et al. (KDD 2009) for graph compression, and show how it can be employed for compression-friendly reordering of social networks and web graphs and for assigning <b>document</b> <b>identifiers</b> in inverted indexes. We design and implement a novel theoretically sound reordering algorithm that is based on recursive graph bisection. Our experiments show a significant improvement of the compression rate of graph and indexes over existing heuristics. The new method is relatively simple and allows efficient parallel and distributed implementations, which is demonstrated on graphs with billions of vertices and hundreds of billions of edges...|$|R
40|$|<b>Document</b> <b>Identifier</b> Edition Number: 1. 0 ASA. 01. CORA. 2. DEL 04 -B. RS Edition Date: 14 / 03 / 02 This {{document}} {{reports a}} study investigating how controllers develop resolutions for aircraft conflict situations in en route air traffic management. Forty-five controllers in seven countries were interviewed individually and in groups, {{to determine their}} best resolutions {{for a series of}} statically presented conflict scenarios. Factors, rules and principles that they used to generate their resolutions, as well as actions they would not take (seen as poor practice) were elicited. The study showed sufficient agreement between controllers to suggest that an advisory system for controllers, such as is envisaged by the Conflict Resolution Assistant (CORA 2) system, is viable. The information collected in this study can therefore be used to inform the developing CORA 2 algorithm...|$|E
40|$|We {{propose a}} formal {{framework}} in which notification and recommendation services can be defined for a community of users sharing a collection of documents. We assume that the documents reside at the repositories of their providers and that a “mediator”, or digital library, provides the (virtual) integration of all repositories, by indexing the documents using a hierarchy of terms. A provider willing to share a document must register it at the library, providing a <b>document</b> <b>identifier</b> (e. g., a URI) and a document description. The description of a document {{is seen as a}} set of terms from the term hierarchy, and so is seen the profile of a user. Notification/recommendation of a document to a user is based upon matching the document description to the user profile. The the paper proposes an method for determining the set of users to be notified when a document is inserted, deleted or modified at the library. ...|$|E
40|$|Web {{search engines}} use the full-text {{inverted}} index data structure. Because query processing performance is {{impacted by the}} size of the inverted index, a plethora of research has focused on fast and effective techniques for compressing this structure. Recently, researchers have proposed techniques for improving index compression by optimizing the assignment of document identifiers in the collection, leading to significant reduction in overall index size. In this paper, we propose improved techniques for <b>document</b> <b>identifier</b> assignment. Previous work includes simple and fast heuristics such as sorting by URL, as well as more involved approaches based on the Traveling Salesman Problem or on graph partitioning. These techniques achieve good compression but do not scale to larger document collections. We propose a new framework based on performing a Traveling Salesman computation on a reduced sparse graph obtained through Locality Sensitive Hashing. This technique achieves improved compression while scaling to tens of millions of documents. Based on this framework, we describe new algorithms, and perform a detailed evaluation on three large data sets showing improvements in index size...|$|E
40|$|List {{intersection}} is {{a central}} operation, utilized excessively for query processing on text and databases. We present list intersection algorithms for an arbitrary number of sorted and unsorted lists tailored to the characteristics of modern hardware architectures. Two new list intersection algorithms are presented for sorted lists. The first algorithm, termed Dynamic Probes, dynamically decides the probing order on the lists exploiting information from previous probes at runtime. This information is utilized as a cache-resident microindex. The second algorithm, termed Quantile-based, deduces in advance a good probing order, thus avoiding the overhead of adaptivity {{and is based on}} detecting lists with non-uniform distribution of <b>document</b> <b>identifiers.</b> For unsorted lists, we present a novel hashbased algorithm that avoids the overhead of sorting. A detailed experimental evaluation is presented based on real and synthetic data using existing chip multiprocessor architectures with eight cores, validating the efficiency and efficacy of the proposed algorithms. 1...|$|R
40|$|We {{consider}} {{the problem of}} retrieving the k documents from a collection of strings where a given pattern P appears most often. We show that, by representing the collection using a Compressed Suffix Array CSA, a data structure using the asymptotically optimal |CSA|+o(n) bits can answer queries in the time needed by CSA to find the suffix array interval of the pattern plus O(k lg 2 k lg ɛ n) accesses to suffix array cells, for any constant ɛ> 0. This is lg n / lg k {{times faster than the}} only previous solution using optimal space, lg k times slower than the fastest structure that uses twice the space, and lg 2 k lg ɛ n times the lower-bound cost of obtaining k <b>document</b> <b>identifiers</b> from the CSA. To obtain the result we introduce a tool called the sampled document array, which can be of independent interest...|$|R
40|$|The World-Wide Web (W 3) {{initiative}} encourages physicists {{to share}} information using wide-area networks. The W 3 software provides easy hypertext navigation and information retrieval in a consistent manner to a vast store of existing data and future hypertext. The client-server architecture uses global conventions for <b>document</b> <b>identifiers,</b> a set of common access protocols, and an ever-widening set of transfer formats. The HTTP protocol is introduced which allows servers, sometimes simple shell scripts, to provide data {{and take advantage of}} a range of hypertext browsers on many platforms. Existing data may be put on the "web" by a gateway without affecting data management procedures. Internet archives, news, "WAIS" and "Gopher" systems are already included in the web. The future will see multiple data formats being handled by negotiation between client and server, and hypertext editors bringing collaborative authorship in the information universe. The need In few disciplines is th [...] ...|$|R
