12|10000|Public
50|$|The Musurgia Universalis (1650) {{sets out}} Kircher's views on music: he {{believed}} that the harmony of music reflected the proportions of the universe. The book includes plans for constructing water-powered automatic organs, notations of birdsong and diagrams of musical instruments. One illustration shows the <b>differences</b> <b>between</b> <b>the</b> <b>ears</b> of humans and other animals. In Phonurgia Nova (1673) Kircher considered the possibilities of transmitting music to remote places.|$|E
40|$|Auditory psychophysical {{testing was}} carried out on a patient with a central pontine lesion {{involving}} the trapezoid body, who presented with a deficit in sound localisation and sound movement detection. A deficit {{in the analysis of}} time and intensity <b>differences</b> <b>between</b> <b>the</b> <b>ears</b> was found, which would explain the deficit in detection of sound movement. The impaired detection of sound movement, due to a lesion interfering with convergence of auditory information at the superior olive, suggests this structure to be critical for human sound movement analysis...|$|E
40|$|Speech {{processing}} for {{cochlear implant}} users has now reached a level where some severely hearing-impaired hearing aid users {{may be better}} aided by a cochlear implant, or a hearing aid and implant together. This paper reviews studies comparing the loudness, pitch, and vowel perception in opposite ears of adults using cochlear implants and hearing aids. A study of nine subjects showed narrow dynamic ranges and steep loudness growth in both ears. Mismatches in aided thresholds and dynamic ranges at different frequencies resulted in highly variable loudness <b>differences</b> <b>between</b> <b>the</b> <b>ears</b> for some subjects. A comparison using pure tones showed that the electric pitch depended on both rate and electrode site. Pitch of electrodes was lower than expected from the characteristic frequency distribution in a normal cochlea. Synthetic vowels were used to show that signals presented via the implant and hearing aid {{may be perceived as}} different vowels in the two ears. Open Acces...|$|E
50|$|As the {{wavelength}} approaches {{twice the size}} of the head, phase relationships become ambiguous, since it is no longer clear whether <b>the</b> phase <b>difference</b> <b>between</b> <b>the</b> <b>ears</b> corresponds to one, two, or even more periods as the frequency goes up.Fortunately, the head will create a significant acoustic shadow in this range, which causes a slight <b>difference</b> in level <b>between</b> <b>the</b> <b>ears.</b> This is called the interaural level difference, or ILD (the same cone of confusion applies). Combined, these two mechanisms provide localisation over the entire hearing range.|$|R
5000|$|These criticisms were rebutted in two articles. Deutsch (2004a) used a new procedure, which {{provided}} more explicit {{documentation of the}} octave illusion; here musically trained subjects notated precisely what they heard. The experiment confirmed that subjects, on listening to the illusion, perceive an octave <b>difference</b> <b>between</b> <b>the</b> <b>ears.</b> This result cannot be explained by diplacusis, which refers to a difference of {{a fraction of a}} semitone <b>between</b> <b>the</b> <b>ears.</b> <b>The</b> article also documented that Chambers et al. used problematic procedures. In a further article, Deutsch (2004b) [...] showed that Chambers et al. made inappropriate comparisons with other phenomena of sound perception, and failed to consider several key findings that support Deutsch’s model. In addition, the octave illusion, in which an octave <b>difference</b> <b>between</b> <b>the</b> <b>ears</b> is perceived, has been replicated in several other laboratories. For example, Oehler and Reuter recently replicated the handedness correlate in a study of 174 subjects Lamminmaki and Hari (2000) and Lamminmaki et al. (2012) in MEG studies provide an explanation of the illusion at the neurophysiological level that is in accordance with Deutsch’s two-channel model.|$|R
50|$|While <b>the</b> <b>difference</b> <b>between</b> APR and <b>EAR</b> {{may seem}} trivial, {{because of the}} {{exponential}} nature of interest these small differences can have a large effect {{over the life of}} a loan. For example, consider a 30-year loan of $200,000 with a stated APR of 10.00%, i.e., 10.0049% APR or <b>the</b> <b>EAR</b> equivalent of 10.4767%. The monthly payments, using APR, would be $1755.87. However, using an <b>EAR</b> of 10.00% <b>the</b> monthly payment would be $1691.78. <b>The</b> <b>difference</b> <b>between</b> <b>the</b> <b>EAR</b> and APR amounts to a difference of $64.09 per month. Over the life of a 30-year loan, this amounts to $23,070.86, which is over 11% of the original loan amount.|$|R
40|$|Cetaceans (whales and dolphins) use {{acoustic}} cues {{to determine}} the locations and identities of environmental stimuli within their underwater habitats. Dolphins evolved unique auditory systems for spatially differentiating ultrasonic signals, whereas the larger baleen whales appear to have evolved different mechanisms for localizing lower frequency sound sources. Many of the cues that terrestrial mammals use to localize sounds in air are less well suited for localizing sounds underwater. Nevertheless, cetaceans can localize sounds as well as or better than most terrestrial mammals. Position dependent spectral filtering likely {{plays an important role}} in sound localization by toothed whales, whereas phase <b>differences</b> <b>between</b> <b>the</b> <b>ears</b> may be important for baleen whales. However, it is exceedingly difficult to determine how filtering and phase differences contribute to spatial hearing by whales and dolphins because, in contrast to terrestrial mammals, the structures through which cetaceans receive sounds are completely internalized (and thus invisible). Computational models of cetacean auditory processing provide one viable approach to generating testable predictions about the mechanisms cetaceans use to localize and identify sound sources...|$|E
40|$|The {{mammalian}} auditory {{system is}} the temporally most precise sensory modality: To localize low-frequency sounds in space, the binaural system can resolve time <b>differences</b> <b>between</b> <b>the</b> <b>ears</b> with microsecond precision. In contrast, the binaural system appears sluggish in tracking changing interaural time differences as they arise from a low-frequency sound source moving along the horizontal plane. For a combined psychophysical and electrophysiological approach, we created a binaural stimulus, called "Phasewarp," that can transmit rapid changes in interaural timing. Using this stimulus, the binaural performance in humans is significantly better than reported previously and comparable with the monaural performance revealed with amplitude-modulated stimuli. Parallel, electrophysiological recordings of binaural brainstem neurons in the gerbil show fast temporal processing of monaural and different types of binaural modulations. In a refined electrophysiological approach that was matched to the psychophysics, the seemingly faster binaural processing of the Phasewarp was confirmed. The current data provide both psychophysical and physiological evidence against a general, hard-wired binaural sluggishness and reconcile previous contradictions of electrophysiological and psychophysical estimates of temporal binaural performance. ...|$|E
40|$|Sound source {{localization}} {{is critical}} to animal survival and for identification of auditory objects. We investigated the acuity with which humans localize low frequency, pure tone sounds using timing <b>differences</b> <b>between</b> <b>the</b> <b>ears.</b> These small differences in time, known as interaural time differences or ITDs, are identified {{in a manner that}} allows localization acuity of around 1 ° at the midline. Acuity, a relative measure of localization ability, displays a non-linear variation as sound sources are positioned more laterally. All species studied localize sounds best at the midline and progressively worse as the sound is located out towards the side. To understand why sound localization displays this variation with azimuthal angle, we took a first-principles, systemic, analytical approach to model localization acuity. We calculated how ITDs vary with sound frequency, head size and sound source location for humans. This allowed us to model ITD variation for previously published experimental acuity data and determine the distribution of just-noticeable differences in ITD. Our results suggest that the best-fit model is one whereby just-noticeable differences in ITDs are identified with uniform or close to uniform sensitivity across the physiological range. We discuss how our results have several implications for neural ITD processing in different species as well as development of the auditory system...|$|E
50|$|Traditionally, nightjars {{have been}} {{divided into three}} subfamilies: the Caprimulginae, or typical nightjars with about 80 species, and the Chordeilinae, or nighthawks of the New World with about 19 species. The two groups are similar in most respects, but the typical nightjars have rictal bristles, longer bills, and softer plumage. In their {{pioneering}} DNA-DNA hybridisation work, Sibley and Ahlquist found that <b>the</b> genetic <b>difference</b> <b>between</b> <b>the</b> <b>eared</b> nightjars and <b>the</b> typical nightjars was, in fact, greater than that <b>between</b> <b>the</b> typical nightjars and the nighthawks of the New World. Accordingly, they placed the eared-nightjars in a separate family: Eurostopodidae, but the family {{has not yet been}} widely adopted.|$|R
2500|$|While <b>the</b> <b>difference</b> <b>between</b> APR and <b>EAR</b> {{may seem}} trivial, {{because of the}} {{exponential}} nature of interest these small differences can have a large effect {{over the life of}} a loan. [...] For example, consider a 30-year loan of $200,000 with a stated APR of 10.00%, i.e., 10.0049% APR or <b>the</b> <b>EAR</b> equivalent of 10.4767%. [...] The monthly payments, using APR, would be $1755.87. [...] However, using an <b>EAR</b> of 10.00% <b>the</b> monthly payment would be $1691.78. [...] <b>The</b> <b>difference</b> <b>between</b> <b>the</b> <b>EAR</b> and APR amounts to a difference of $64.09 per month. [...] Over the life of a 30-year loan, this amounts to $23,070.86, which is over 11% of the original loan amount.|$|R
50|$|At {{the most}} basic level, {{echolocation}} {{is based on the}} neural anatomy of auditory brain circuitry. In essence, ascending brain pathways in the brain stem allow the brain to calculate <b>the</b> <b>difference</b> <b>between</b> <b>the</b> two <b>ears</b> to very small fractions of a second.|$|R
40|$|Introduction: The {{resonant}} frequency is the probe frequency in which susceptance is 0 {{due to the}} neutralization of the forces of mass and stiffness components that control the middle ear. This frequency can be evaluated by multifrequency tympanometry, and the normality value for adults ranges 800 - 1, 200 Hz. Studies about {{resonant frequency}} in children are scarce. Aim: Identify the variation of the resonant frequency in infants between the first days after birth and the third month of life. Method: Prospective study. Thirty newborns were evaluated at 2 different times: at the neonatal phase up to 12 days of life, and between 72 and 84 days of life. In the first evaluation, we carried out otoacoustic emissions and identified the resonant frequency, and identified the resonant frequency again in the second evaluation. Results: In the first evaluation, we determined a mean resonance value of 250 Hz for both ears, while that in the second evaluation was 385 Hz. In both assessments, we found no significant <b>differences</b> <b>between</b> <b>the</b> <b>ears.</b> There {{was a significant difference}} between the first and second evaluation. Conclusion: The middle ear resonant frequency in infants is lower in the first days of life due to the influence of the mass component. The present study demonstrated that the resonance frequency increased in the first months of life...|$|E
40|$|Speaker {{localization}} is {{the study}} direction of sound detection. A listener can identify the location or origin of sound. Human auditory system mechanisms of speaker localization have been widely studied. To adapt {{the ability of the}} human auditory system, the researcher uses several methods such as time and level <b>differences</b> <b>between</b> <b>the</b> <b>ears,</b> spectral information, timing analysis, correlation analysis, and pattern matching. The application of the system is implemented to the robot as a model human auditory system. The robot now can interact naturally when human speak to them as it can determine the localization of the speaker. In this paper is to build speaker localization where to determine the sound source in front side of 180 degrees. The azimuth, distance, and also height will be fixed. The sensor is built from the three microphones to detect sound. The speaker source that came will be comparing its intensity at {{the right and the left}} side. So, if the source is from the right side, then the servo motor will rotate in the right until the different intensity of sound is same to the both sides. Therefore, the servo motor will stop here. Whereas, this will show the direction of the sound source. The result in the experiment shows that it’s quite satisfying with error accuracy as this technique need a more sensitive instrument to compare the sound source...|$|E
40|$|This study {{investigated}} the relationship between speech perception performance in spatially complex, lateralized listening scenarios and temporal fine-structure (TFS) coding at low frequencies. Young normal-hearing (NH) and two groups of elderly hearing-impaired (HI) listeners with mild or moderate hearing loss above 1. 5 [*]kHz participated in the study. Speech reception thresholds (SRTs) were estimated {{in the presence of}} either speech-shaped noise, two-, four-, or eight-talker babble played reversed, or a nonreversed two-talker masker. Target audibility was ensured by applying individualized linear gains to the stimuli, which were presented over headphones. The target and masker streams were lateralized to the same or to opposite sides of the head by introducing 0. 7 -ms interaural time <b>differences</b> <b>between</b> <b>the</b> <b>ears.</b> TFS coding was assessed by measuring frequency discrimination thresholds and interaural phase difference thresholds at 250 [*]Hz. NH listeners had clearly better SRTs than the HI listeners. However, when maskers were spatially separated from the target, the amount of SRT benefit due to binaural unmasking differed only slightly between the groups. Neither the frequency discrimination threshold nor the interaural phase difference threshold tasks showed a correlation with the SRTs or with the amount of masking release due to binaural unmasking, respectively. The results suggest that, although HI listeners with normal hearing thresholds below 1. 5 [*]kHz experienced difficulties with speech understanding in spatially complex environments, these limitations were unrelated to TFS coding abilities and were only weakly associated with a reduction in binaural-unmasking benefit for spatially separated competing sources...|$|E
50|$|For {{frequencies}} below 800 Hz, {{the dimensions}} of <b>the</b> head (<b>ear</b> distance 21.5 cm, corresponding to an interaural time delay of 625 µs) are smaller than the half wavelength of the sound waves. So the auditory system can determine phase delays between both ears without confusion. Interaural level differences are very low in this frequency range, especially below about 200 Hz, so a precise evaluation of the input direction is nearly impossible {{on the basis of}} level differences alone. As the frequency drops below 80 Hz it becomes difficult or impossible to use either time difference or level difference to determine a sound's lateral source, because <b>the</b> phase <b>difference</b> <b>between</b> <b>the</b> <b>ears</b> becomes too small for a directional evaluation.|$|R
50|$|At low frequencies, {{where the}} {{wavelength}} is large {{compared to the}} human head, an incoming sound diffracts around it, {{so that there is}} virtually no acoustic shadow and hence no level <b>difference</b> <b>between</b> <b>the</b> <b>ears.</b> In this range, the only available information is <b>the</b> phase relationship <b>between</b> <b>the</b> two <b>ear</b> signals, called interaural time difference, or ITD.Evaluating this time difference allows for precise localisation within a cone of confusion: the angle of incidence is unambiguous, but the ITD is the same for sounds from the front or from the back. As long as the sound is not totally unknown to the subject, the confusion can usually be resolved by perceiving the timbral front-back variations caused by <b>the</b> <b>ear</b> flaps (or pinnae).|$|R
50|$|Depending {{on where}} the source is located, our head acts {{as a barrier to}} change the timbre, intensity, and {{spectral}} qualities of the sound, helping the brain orient where the sound emanated from. These minute <b>differences</b> <b>between</b> <b>the</b> two <b>ears</b> are known as interaural cues.|$|R
40|$|BACKGROUND—Ear {{thermometers}} {{are becoming}} popular {{as a method}} for measuring deep body (core) temperature.  AIM—To determine the variability of a single user's tympanic membrane (ear) temperature measurements.  SUBJECTS—Forty two, afebrile, healthy children, and 20 febrile children with acute burns.  RESULTS—In afebrile children measurements made in both ears (and within {{just a few minutes}} of each other) differed by as much as 0. 6 °C. Operator measurement error, sw of three consecutive measurements, in the same ear, was 0. 13 °C. In the group of febrile, burned children, core temperature was measured hourly at a number of sites (ear, rectum, axilla, bladder). A peak in core temperature occurred approximately 10 - 12 hours after the burn. Measurement error was calculated in 14 febrile, burned children with a peak temperature in excess of 38 °C. For the left ear, measurement error was 0. 19 °C and for the right ear, 0. 11 °C. In the febrile children agreement between the ears was poor. The limits of agreement were 0. 4 °C to − 0. 8 °C. It was not possible to predict the occasions when the temperature <b>differences</b> <b>between</b> <b>the</b> <b>ears</b> would be large or small.  CONCLUSIONS—The measurement error of one recording from the next is probably acceptable at about 0. 1 to 0. 2 °C. To limit the variations in temperature of one ear to the other, measurements should be restricted to one of the ears whenever possible and the same ear used throughout the temperature monitoring period. Nurses and parents should take more than one temperature reading from the same ear whenever possible. ...|$|E
40|$|Mammals {{and birds}} appear to encode timing <b>differences</b> <b>between</b> <b>the</b> <b>ears,</b> a major cue for {{auditory}} localization, in fundamentally different ways. It now appears {{that results from}} different species can be accommodated within a single general framework. An ability to localize sounds both accurately and rapidly — particularly if they occur outside {{the field of view}} — is of obvious survival value. Because the afferent nerves from the cochlea do not convey spatial information directly, neural computations have to be performed within the brain {{in order to determine the}} direction of a sound source. This involves comparing the intensity and time of arrival of the sound at the two ears. Together with the spectral filtering imposed by the external ear, these binaural cues are responsible for auditory localization [1]. Psychophysical studies in humans have shown that the principal cue for sound localization in the horizontal plane, at least at low frequencies, is the interaural time difference (ITD) [2]. The maximum ITD encountered depends on the distance between the ears; in adult humans it is about 600 µs. Humans can discriminate ITDs as small as 10 – 20 µs [3] — an astonishing achievement given that the duration of an action potential is two orders of magnitude greater than this. Over the last few years, electrophysiological studies have indicated that the neural basis for ITD coding may vary among different species. Recent modelling data [4], however, suggest that the optimal coding strategy depends primarily on head size and the sound frequency range over which ITDs can be discriminated, rather than a more intrinsic difference between species...|$|E
40|$|Abstract Based on {{binaural}} signals, i. e. {{the signals}} observed {{at the two}} ears, a listener can localize and recognize different sound sources and then focus on one of these. For decades, researchers have tried to invent a machine that {{can do the same}} under similar conditions. Despite all the efforts, the human auditory system is, by far, superior to any machine that has been devised. The topic of this thesis is computational techniques for the localization and separation of sources in binaural signals. In order to give an overview of different areas of research that have considered the problems of source localization and separation, we start with a review of existing techniques. This provides the background for the techniques that we propose subsequently. Binaural Localization The most important cues for localization of sound sources in binaural signals are the level and time <b>differences</b> <b>between</b> <b>the</b> <b>ears.</b> We propose a technique for the joint evaluation of these cues where noisy level difference estimates are combined with less noisy but ambiguous time difference estimates in order to provide accurate azimuth estimates. The proposed technique enables the localization of sources and the tracking of these in dynamic scenes. Head model Based on a study of the level and time differences as function of azimuth angle for different heads, we propose a generic model that is parametrized by the distance between the ears only. This enables the use of the binaural localization technique mentioned above for a listener whose head related transfer functions have not been measured. Binaural separation For the separation of sources we propose a method based on spatial windowing in the azimuth parameter space. Separation of overlapping partials Finally, we propose a technique for the separation of overlapping partials in mixtures of harmonic instruments. The technique is based on the similarity of temporal envelopes between the different partials of a harmonic note...|$|E
50|$|The {{binaural}} squelch {{effect is}} a result of nuclei of the brainstem processing timing, amplitude, and spectral <b>differences</b> <b>between</b> <b>the</b> two <b>ears.</b> Sounds are integrated and then separated into auditory objects. For this effect to take place, neural integration from both sides is required.|$|R
50|$|The Mellerud rabbit {{is similar}} to the Gotland rabbit in terms of conformation. It is a {{medium-sized}} rabbit with an adult weight of 3-3.5 kg (6.6-7.7 lbs). The body of the doe is relatively elongated with a fine head while the buck is usually somewhat more compact with a rounder head and thicker muzzle. There is no weight <b>difference</b> <b>between</b> <b>the</b> genders. <b>The</b> <b>ears</b> are of medium length and relatively thin, pointed rather than rounded. The eyes are somewhat large with an alert expression. The eyes are brown, blue or a mixture of the two.|$|R
25|$|<b>The</b> {{pressure}} <b>difference</b> <b>between</b> <b>the</b> middle <b>ear</b> and <b>the</b> outside, if not released, {{can result}} in a burst eardrum. This damages hearing, and if this occurs underwater, cold water in <b>the</b> middle <b>ear</b> chills <b>the</b> inner <b>ear,</b> causing vertigo. <b>The</b> pressure difference can also cause damage to other body air spaces, such as the paranasal sinuses. This can also be caused by damaged sinus ducts.|$|R
25|$|Alternobaric vertigo {{is caused}} by a {{pressure}} <b>difference</b> <b>between</b> <b>the</b> middle <b>ear</b> cavities, usually due to blockage or partial blockage of one eustachian tube, usually when flying or diving underwater. It is most pronounced when the diver is in the vertical position; the spinning is towards <b>the</b> <b>ear</b> with <b>the</b> higher pressure and tends to develop when the pressures differ by 60cm of water or more.|$|R
50|$|<b>The</b> {{pressure}} <b>difference</b> <b>between</b> <b>the</b> middle <b>ear</b> and <b>the</b> outside, if not released, {{can result}} in a burst eardrum. This damages hearing, and if this occurs underwater, cold water in <b>the</b> middle <b>ear</b> chills <b>the</b> inner <b>ear,</b> causing vertigo. <b>The</b> pressure difference can also cause damage to other body air spaces, such as the paranasal sinuses. This can also be caused by damaged sinus ducts.|$|R
40|$|This paper {{focuses on}} how <b>the</b> {{acoustical}} <b>differences</b> <b>between</b> <b>the</b> <b>ear</b> canals of {{adults and children}} affect amplification requirements and describes efficient strategies to allow for these differences when prescribing and verifying amplification. We will first summarize the problem for hearing assessment and then describe how adult-equivalent hearing loss can be calculated to circumvent this problem. Example cases demonstrate manual calculation and automatic derivation by using the NAL-NL 1 software. The advantage of using real-ear aided gain prescriptions rather than real-ear insertion gain prescriptions for young children is explained. The practical benefit of deriving coupler gain targets to achieve the required real-ear aided gain by using individually measured real-ear-to-coupler differences is emphasized, together with a discussion on the practical issues relating to calibration and probe tube placement in measuring real-ear-to-coupler differences. Finally, an illustrative case exemplifies the deriva-tion of individualized coupler gain targets by using the NAL-NL 1 software system to achieve the required real-ear aided gain for a young child...|$|R
40|$|SummaryThe {{hormonal}} {{changes that}} occur {{in a short time}} span promote modifications all over the woman's body, with physical and emotional manifestations which are frequently observed. Aimto evaluate the activity of the external ciliated cells in women during their menstrual cycle, observing the effect of hormonal changes caused by the cycle in their 3 phases. Methodsthis is a longitudinal prospective study where 21 women between 20 and 35 years old who did not take any contraceptive medicine were assessed. Transient otoacoustic emissions were evaluated by distortion product during the 3 phases of the menstrual cycle (luteal, follicular and ovulatory phases). The SPSS 13. 0 software was used to analyze the data. Resultsthe phases of menstrual cycle do not alter the amplitude and reproducibility values of the transient otoacoustic emissions. We noticed a <b>difference</b> <b>between</b> <b>the</b> <b>ears</b> in <b>the</b> frequency of 1. 5 KHz in the amplitude of emissions by distortion product, and <b>the</b> right <b>ear</b> showed <b>the</b> highest values. ConclusionThere are no significant differences in transient otoacoustic emissions and distortion products in the phases of the menstrual cycle...|$|R
40|$|Anthropometric data {{is needed}} {{in the design of}} {{products}} as it varies between individuals and nations. These data for Nigerians is presently scant and this study is an attempt to provide data on hand, foot and <b>ear</b> for <b>the</b> improvements of hand gloves, handles, shoes, pedal dimensions, ear-phones and other related products. A random sample of 500 students was taken and their ages were between 18 and 29 years (mean of 21. 7 years). Two hundred and fifty of the samples were males and the same numbers were females. The dimensions measured were ▪ hand: length and breadth; ▪ foot: length, breadth and height; ▪ ear: height and breadth. The study presents the anthropometric data for the 5 th, 50 th and 95 th percentiles for the above-presented variables. The study established that foot breadths of the females were larger than those of the males while the males had larger foot lengths. There were no significant <b>differences</b> <b>between</b> <b>the</b> hand dimensions of the males and those of the females. Similarly, there were no significant <b>differences</b> <b>between</b> <b>the</b> <b>ear</b> dimensions of males and the female...|$|R
50|$|Despite {{having never}} been bred towards a written breed {{standard}} until recent times, most Gotland rabbits share a distinctive and recognizable type. The variety is of medium size {{with an adult}} weight of 3-4 kg (6.6-8.8 lb). The body of the doe is relatively elongated with a fine head while the buck is usually somewhat more compact with a rounder head and thicker muzzle. There is no weight <b>difference</b> <b>between</b> <b>the</b> genders. <b>The</b> <b>ears</b> are of medium length and relatively thin, pointed rather than rounded. The eyes are somewhat large with an alert expression. Any eye colour is allowed.The coat is short and fine, usually straight although a few rex coated Gotlands have been known. Any pattern and colour is allowed.|$|R
40|$|Studies on <b>the</b> elasmobranch inner <b>ear</b> {{have focused}} {{predominantly}} {{on a small}} group of sharks, particularly, carcharhinids. As a result, subsequent studies in other species have subdivided species into two main groups: those typical and those atypical of carcharhinid sharks. This study proposes a different set of inner-ear morphology groupings to those previously suggested. <b>The</b> inner <b>ears</b> from 17 species of elasmobranchs (representing both sharks and rays) are examined in this study and based on morphometric data some groups include both rays and sharks. Four groups are now proposed based predominantly on the shape and dimensions of the membranous otoconial organs, and characteristics of the semicircular canals. Evident morphological <b>differences</b> <b>between</b> <b>the</b> <b>ear</b> types belonging to the new groups include the membranes of the semicircular canals being bound to the otoconial organs in some species, while only being connected via the canal ducts in others, as well as clear variation present in saccular organ size. Previous studies examining variation in <b>the</b> inner <b>ear</b> have attributed differences to either phylogeny or functional significance. Results from this study suggest that neither phylogeny nor feeding strategy solely accounts for the morphological diversity present in the external morphology of <b>the</b> elasmobranch inner <b>ear.</b> J. Morphol., 2010. © 2010 Wiley-Liss, Inc...|$|R
40|$|Time <b>differences</b> <b>between</b> <b>the</b> two <b>ears</b> are an {{important}} cue for animals to azimuthally locate a sound source. The first binaural brainstem nucleus, in mammals the medial superior olive, is generally believed to perform the necessary computations. Its cells are sensitive to variations of interaural time differences of about 10 μs. The classical explanation of such a neuronal time-difference tuning {{is based on the}} physical concept of delay lines. Recent data, however, are inconsistent with a temporal delay and rather favor a phase delay. By means of a biophysical model we show how spike-timing-dependent synaptic learning explains precise interplay of excitation and inhibition and, hence, accounts for a physical realization of a phase delay. ...|$|R
40|$|Purposeto {{assess the}} {{occurrence}} of hearing loss in infants with corpus callosum agenesis comparing them to children without such malformation. Methoda cohort study in two parts: a retrospective from 2008 to 2011, and prospective from 2011 to 2012. The study group consisted of 12 infants diagnosed with agenesis of the corpus callosum and the control group of 12 infants, matched for sex and post conceptional age. All patients underwent otoacoustic emissions transient stimulus, Auditory Evoked Potential (analysis of the average latencies of waves I, III and V and interpeak I-III, III-V and IV 80 dBnNA) and behavioral auditory tests. Resultthe analysis of {{the occurrence of}} hearing impairment evaluationotoacoustic emissions transient stimulusand Auditory Evoked Potential showed differences in both groups, withhighest percentage of normal results in the control group. There was significant <b>difference</b> <b>between</b> <b>the</b> <b>ears,</b> <b>the</b> latencies of wave III and I-III interpeak interval, and lower right in the control group. In behavioral assessment, there was significant <b>difference</b> <b>between</b> <b>the</b> groups in relation to normal and abnormal results, with higher prevalence of central alteration in the study group. Also in this group, the second assessment showed a statistically significant higher rate of abnormal results {{when compared to the}} first assessment. Conclusionhearing disorders in infants with corpus callosum agenesis were not identified at birth, but within {{the first six months of}} life. Most of the changes occurred in the central auditory pathway in the brainstem. Purposeto assess the occurrence of hearing loss in infants with corpus callosum agenesis comparing them to children without such malformation. Methoda cohort study in two parts: a retrospective from 2008 to 2011, and prospective from 2011 to 2012. The study group consisted of 12 infants diagnosed with agenesis of the corpus callosum and the control group of 12 infants, matched for sex and post conceptional age. All patients underwent otoacoustic emissions transient stimulus, Auditory Evoked Potential (analysis of the average latencies of waves I, III and V and interpeak I-III, III-V and IV 80 dBnNA) and behavioral auditory tests. Resultthe analysis of the occurrence of hearing impairment evaluationotoacoustic emissions transient stimulusand Auditory Evoked Potential showed differences in both groups, withhighest percentage of normal results in the control group. There was significant <b>difference</b> <b>between</b> <b>the</b> <b>ears,</b> <b>the</b> latencies of wave III and I-III interpeak interval, and lower right in the control group. In behavioral assessment, there was significant <b>difference</b> <b>between</b> <b>the</b> groups in relation to normal and abnormal results, with higher prevalence of central alteration in the study group. Also in this group, the second assessment showed a statistically significant higher rate of abnormal results when compared to the first assessment. Conclusionhearing disorders in infants with corpus callosum agenesis were not identified at birth, but within the first six months of life. Most of the changes occurred in the central auditory pathway in the brainstem. Objetivoverificar a ocorrência de alterações auditivas em lactentes com alteração do corpo caloso, comparando-os a crianças sem tal malformação. Métodoestudo de coorte dividido em duas partes: retrospectivo de 2008 a 2011 e prospectivo de 2011 a 2012. O grupo estudo foi constituído por 12 lactentes com diagnóstico de agenesia de corpo caloso e o grupo controlepor 12 lactentes, pareados por idade pós concepcional e sexo. Todos realizaram Emissões Otoacústicas Evocadas por Estimulo Transiente, Potencial Evocado Auditivo de Tronco Encefálico (análise da média das latências das ondas I, III e V e interpicos I-III, III-V e I-V a 80 dBnNA) e Avaliação do Comportamento Auditivo. Resultadona análise da ocorrência de alteração auditiva na avaliação com Emissões Otoacústicas Transientes e Potencial Evocado Auditivo de Tronco Encefálico, houve diferença em ambos os grupos com maior percentual de resultados normais no grupo controle. Houve diferença significante entre as orelhas, nas latências da onda III e intervalo interpico I-III, menor à direita, nogrupo controle. Naavaliação comportamental, houve diferença significante entre os grupos em relação aos resultados normais e alterados, com maior ocorrência de alteração central no grupo estudo. Ainda neste grupo, a segunda avaliação mostrou maior índice de resultados alterados quando comparados à primeira avaliação, sendo estaticamente significante. Conclusãoas alterações auditivas nos lactentes com alteração do corpo caloso não foram identificadas ao nascimento, tendo sido apenas a partir de seis meses de vida. A maioria das alterações ocorreram na via auditiva central, no tronco encefálico. Departamento de Fonoaudiologia Departamento de FonoaudiologiaEscola Paulista de Medicina Escola Paulista de MedicinaUniversidade Federal de São Paulo (UNIFESP) Universidade Federal de São Paulo (UNIFESP) Clinica do Hospital São PauloUniversidade Federal de São Paulo (UNIFESP) Escola Paulista de MedicinaUNIFESP, EPM, Escola Paulista de MedicinaEPM (EPM), Clinica do Hospital São PauloEPM, Escola Paulista de MedicinaSciEL...|$|R
40|$|Objective: To {{determine}} whether choosing <b>the</b> “better” <b>ear</b> or <b>the</b> “worse” <b>ear</b> for co-chlear implantation impacts performance outcome. Study Design: Retrospective cohort study. Firstly two groups out of 139 cochlear implantees are selected {{on the basis}} of audiological and electrophysiological tests. Secondly two groups of cochlear implantees are selected and matched based on clinical parameters. Group 1 is implanted on <b>the</b> better <b>ear</b> and group 2 on <b>the</b> worse <b>ear.</b> Setting: Cochlear implant program of the university hospital RWTH Aachen. Patients: 139 cochlear implant patients operated between 1986 and 2001 with little difference in audiological an electrophysiological tests preoperatively between both ears. Interventions: audiometry, Freiburg speech test, promontorial test, BERA and electrocochleography. Results: One year after implantation the medium increase in Freiburg polysyllabic test (FP) in group 1 (implantation of better ears) with audiological tests is 18, 9 % versus 27, 9 % in group 2 (implantation of worse ears). After grouping with electrophysiological tests it is 38, 9 %% versus 59, 4 % and in matched-pair comparison it is 46, 7 % versus 51, 4 %. After one year medium increase in Freiburg monosyllabic test (FM) in group 1 with audiological grouping is 26, 9 % versus 30, 4 % in group 2. In electrophysiological grouping it is 26, 3 % versus 28, 6 % and in matched-pair comparison it is 31 % versus 23, 3 %. Statistically there is no performance <b>difference</b> <b>between</b> implanting <b>the</b> better and <b>the</b> worse <b>ear.</b> Conclusions: Choosing <b>the</b> “worse” or <b>the</b> “better” <b>ear</b> for cochlear implantation does not appear to have an impact on speech performance outcome on patients with small functional <b>difference</b> <b>between</b> <b>the</b> <b>ears</b> preoperatively...|$|R
50|$|Unless a {{sound is}} {{directly}} in front of or behind the individual, the sound stimuli will have a slightly different distance to travel to reach each ear. This difference in distance causes a slight delay in the time the signal is perceived by each <b>ear.</b> <b>The</b> magnitude of the interaural time difference is greater the more the signal comes {{from the side of the}} head. Thus, this time delay allows humans to accurately predict the location of incoming sound cues. Interaural level difference is caused by the difference in sound pressure level reaching <b>the</b> two <b>ears.</b> This is because the head blocks the sound waves for <b>the</b> further <b>ear,</b> causing less intense sound to reach it. This level <b>difference</b> <b>between</b> <b>the</b> two <b>ears</b> allows humans to accurately predict azimuth of an auditory signal. This effect only occurs at sounds that are high frequency.|$|R
30|$|These <b>differences</b> {{in sound}} <b>between</b> <b>the</b> <b>ears</b> {{give rise to}} {{binaural}} cues such as the interaural time difference (ITD) and interaural level difference (ILD). These cues depend {{on a variety of}} factors, notably the shape of the head, pinnae, and upper torso. All of these can be affected by the distance the sound travels to each ear, attenuation due to occlusion (the head shadow effect), and reflections (from the upper torso and the pinnae). In addition, the pinna creates direction-dependent spectral cues that can be used by the brain to infer source direction.|$|R
