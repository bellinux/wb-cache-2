456|2334|Public
5|$|At the time, {{the general}} method {{to compute the}} inverse square root was to {{calculate}} an approximation for , then revise that approximation via another method until it came within an acceptable <b>error</b> <b>range</b> of the actual result. Common software methods in the early 1990s drew approximations from a lookup table. The key of the fast inverse square root was to directly compute an approximation by utilizing the structure of floating-point numbers, proving faster than table lookups. The algorithm was approximately four times faster than computing the square root with another method and calculating the reciprocal via floating point division. The algorithm was designed with the IEEE 754-1985 32-bit floating point specification in mind, but investigation from Chris Lomont showed {{that it could be}} implemented in other floating point specifications.|$|E
5|$|However it was {{considered}} the low-level sight's chief advantages would be demonstrated under operational conditions. The sight {{was considered}} a great advancement on any previous method of low-level bombing, either by eye or with a bombsight. The best figures from No. 59 Squadron's trials were 6yd range error with release from 800ft, and 5yd error when approaching at 100ft, but releasing from 400ft with the aircraft's nose slightly up. Some academics in the ORS stated a 20yd <b>error</b> <b>range</b> existed but maintained the Mark III was promising. Some crews did not trust the device, which was the case when asked to use equipment of which they had little experience. Instead, many continued relying on their own trusted eyesight. A continued lack of resources meant there was no widespread use of the sights. In later months, the aircrew changed tactics and with new weapons, they decided {{that it would take}} too long to zero-in on a target using the device. Pilots and crew often opted to use their own judgement by direct sighting with considerable success.|$|E
5|$|The Kirtlandian faunal age {{was named}} by Lucas and Sullivan in 2003, and found by their {{original}} study to date from 74.9 to 72million years ago. In 2006, Sullivan and Lucas refined their estimate, {{stating that the}} Kirtlandian ranged from 75 to 72.8million years ago. Later that year, Sullivan changed the time range again, finding that the faunal age lasted only 2 million years, from 74.8 to 72.8million years ago. He said that the later part of the Kirtlandian, from the De-na-zin Member of the Kirtland Formation, dated to 73 million years ago, {{on the basis of}} ash layers dating to 73.04 and 73.37million years ago. This observation was based on findings by Sullivan and Lucas, who dated the two ash layers from 73.04 ± 0.25 and 73.37 ± 0.28million years ago. They also dated the earlier ashes from the Fruitland Formation, which dated to 75.56 ± 0.41, 74.55 ± 0.29, and 74.11 ± 0.62 million years ago. The first ash, called by them the Dog Eye Pond, was found slightly higher than the start of the Fruitland Formation, which meant that the start of the Fruitland Formation was older than 75.5 million years ago. More precise dating in 2010 by Longrich found that the second youngest ash can actually be dated more precisely than thought by Sullivan (2006), only having an <b>error</b> <b>range</b> of 0.18million years. Longrich also dated the two older ashes, finding a date {{the same as that of}} Sullivan in 2006. These ash datings are what Sullivan used to find the precise age of the Kirtlandian age.|$|E
50|$|LD50 (<b>error</b> <b>ranges</b> not shown): Mouse: 65 mg/kg, i.p.; 900 mg/kg, p.o.|$|R
5000|$|... #Caption: Data from Salt Farm Brochure. Envelopes (yellow) and <b>error</b> <b>ranges</b> (brown) {{have been}} introduced. The scatter is quite high.|$|R
40|$|This study {{describes}} typical <b>error</b> <b>ranges</b> of {{high resolution}} regional climate models operated over complex orography and investigates the scale-dependence of these <b>error</b> <b>ranges.</b> The results are valid {{primarily for the}} European Alpine region, but to some extent {{they can also be}} transferred to other orographically complex regions of the world. We investigate the model errors by evaluating a set of 62 one-year hindcast experiments for the year 1999 with four different regional climate models. The analysis is conducted for the parameters mean sea level pressure, air temperature (mean, minimum and maximum) and precipitation (mean, frequency and intensity), both as an area average over the whole modeled domain (the "Greater Alpine Region", GAR) and in six subregions. The subregional seasonal <b>error</b> <b>ranges,</b> defined as the interval between the 2. 5 th percentile and the 97. 5 th percentile, lie between - 3. 2 and + 2. 0 K for temperature and between - 2. 0 and + 3. 1 mm/day (- 45. 7 and + 94. 7 %) for precipitation, respectively. While the temperature <b>error</b> <b>ranges</b> are hardly broadened at smaller scales, the precipitation <b>error</b> <b>ranges</b> increase by 28 %. These results demonstrate that high resolution RCMs are applicable in relatively small scale climate impact studies with a comparable quality as on well investigated larger scales as far as temperature is concerned. For precipitation, which is a much more demanding parameter, the quality is moderately degraded on smaller scales...|$|R
2500|$|This {{estimate}} notes however that [...] "...other immigrants of Romanian {{national minority}} {{groups have been}} included such as: Armenians, Germans, Gypsies, Hungarians, Jews, and Ukrainians". It also includes an unspecified allowance for second- and third-generation Romanians, and an indeterminate number living in Canada. An <b>error</b> <b>range</b> for the estimate is not provided. For the United States 2000 Census figures, almost 20% {{of the total population}} did not classify or report an ancestry, and the census is also subject to undercounting, an incomplete (67%) response rate, and sampling error in general.|$|E
2500|$|Further {{limitations}} were {{a result}} of the aircraft itself. A lack of proper bombsight equipment and poor forward visibility meant the aircraft had to attack from low level. This meant an approach at just 45 metres at 290 kph (180mph) and then release of bombs at 240 metres (790ft) from the target. This was known as the [...] "Swedish turnip" [...] tactic by crews. This allowed for a high chance of a direct hit or damaging near miss. The Fw 200 carried four SC 250kg bombs, ensuring a hit potential. Merchant vessels lacked armour or damage-control systems at that time, so a hit or more would have a high chance of sinking a ship. This meant an average of one ship sunk for every attack made. At low level, it was not uncommon for German crews to achieve three out of four hits. However, many bombs failed to explode at low level, owing to improper fusing of the ordnance. Once the Lotfernrohr 7D bombsight was introduced – with a similar degree of accuracy to the top secret American Norden bombsight – more accurate bombing from 3,000 metres (9,840 feet) could take place with an <b>error</b> <b>range</b> of just 91 metres (300 feet). Later Fw 200s were fitted with heavier machine guns and cannon, so that strikes at low level could also damage the superstructure of ships.|$|E
60|$|I {{have in this}} {{declaration}} insensibly overstepped {{the limits}} which I had determined not to pass: let me be forgiven; for it is hope which hath carried me forward. In such a mixed assemblage as our age presents, with its genuine merit and its large overbalance of alloy, I may boldly ask into what errors, either with respect to person or thing, could a young man fall, who had sincerely entered upon the course of moral discipline which has been recommended, and to which the condition of youth, it has been proved, is favourable? His opinions could no where deceive him beyond the point up to which, after a season, he would find that it was salutary {{for him to have}} been deceived. For as that man cannot set a right value upon health who has never known sickness, nor feel the blessing of ease who has been through his life a stranger to pain, so can there be no confirmed and passionate love of truth for him who has not experienced the hollowness of <b>error.</b> <b>Range</b> against each other as advocates, oppose as combatants, two several intellects, each strenuously asserting doctrines which he sincerely believes; but the one contending for the worth and beauty of that garment which the other has outgrown and cast away. Mark the superiority, the ease, the dignity, {{on the side of the}} more advanced mind, how he overlooks his subject, commands it from centre to circumference, and hath the same thorough knowledge of the tenets which his adversary, with impetuous zeal, but in confusion also, and thrown off his guard at every turn of the argument, is labouring to maintain. If it be a question of the fine arts (poetry for instance) the riper mind not only sees that his opponent is deceived; but, what is of far more importance, sees how he is deceived. The imagination stands before him with all its imperfections laid open; as duped by shows, enslaved by words, corrupted by mistaken delicacy and false refinement, as not having even attended with care to the reports of the senses, and therefore deficient grossly in the rudiments of its own power. He has noted how, as a supposed necessary condition, the understanding sleeps in order that the fancy may dream. Studied in the history of society, and versed in the secret laws of thought, he can pass regularly through all the gradations, can pierce infallibly all the windings, which false taste through ages has pursued, from the very time when first, through inexperience, heedlessness, or affectation, the imagination took its departure from the side of truth, its original parent. Can a disputant thus accoutred be withstood?--one to whom, further, every movement in the thoughts of his antagonist is revealed by the light of his own experience; who, therefore, sympathizes with weakness gently, and wins his way by forbearance; and hath, when needful, an irresistible power of onset, arising from gratitude to the truth which he vindicates, not merely as a positive good for mankind, but as his own especial rescue and redemption.|$|E
30|$|The {{proposed}} algorithm should adequately {{cope with}} {{various kinds of}} map <b>errors</b> <b>ranging</b> from small ones, such as sensing errors, to large ones, such as the transformation of obstacles.|$|R
3000|$|... are the {{opposite}} sign, {{can be provided}} by an occultation observation of the AKR. It {{should be noted that}} these <b>error</b> <b>ranges</b> include the frequency dependence of the wave source.|$|R
3000|$|F 2 and M 3000 F 2, respectively. The model {{results have}} <b>errors</b> <b>ranging</b> from {{approximately}} 8 – 15 %, 9 – 17 %, and 3 – 5 %, respectively, for h [...]...|$|R
50|$|B4 = 0.87058 83800 ± 0.00000 00005, the <b>error</b> <b>range</b> {{having a}} 99% {{confidence}} level according to Nicely.|$|E
5000|$|Alkali <b>error</b> <b>range</b> - at low {{concentration}} of hydrogen ions (high values of pH) contributions of interfering alkali metals (like Li, Na, K) are comparable with the one of hydrogen ions. In this situation dependence of the potential on pH become non-linear.|$|E
5000|$|Acidic <b>error</b> <b>range</b> - at {{very high}} {{concentration}} of hydrogen ions (low values of pH) the dependence of the electrode on pH becomes non-linear {{and the influence of}} the anions in the solution also becomes noticeable. These effects usually become noticeable at pH < -1.|$|E
30|$|The polynomial-basis {{response}} surface approximation {{is different from}} the real function between cross-sectional area and nodal displacement, relative <b>error</b> <b>ranging</b> from 4.747 % to 23.56 % which does not meet the engineering requirement.|$|R
30|$|Observing Figure 2, one infers {{that the}} {{estimates}} {{are closely related}} and that the <b>errors</b> <b>range</b> well within EBs stretched by growing p. Inherently, the prediction error is reduced by increasing N {{that can be seen}} by comparing Figure 2 a,b.|$|R
30|$|Random <b>error</b> <b>ranged</b> from 0.11 to 0.41 mm for linear {{measurements}} and from 0.19 ° to 0.60 ° for angular measurements. The coefficient of reliability ranged from 0.90 to 0.99 for linear {{measurements and}} from 0.95 to 0.99 for angular measurements.|$|R
50|$|SLIM is Japan's {{first major}} lunar surface mission, and will {{demonstrate}} precise, pinpoint lunar landing. During its descent to the moon, the lander will recognizing lunar craters {{by applying the}} technology used in facial recognition systems, and decipher its current location from utilizing observation data collected by the SELENE (Kaguya) lunar orbiter mission. SLIM aims to soft land with an <b>error</b> <b>range</b> of 100 m. In comparison, the <b>error</b> <b>range</b> of the Apollo 11 Eagle lunar module was an elliptic which was 20 km wide in downrange and 5 km wide in crossrange. According to Yoshifumi Inatani, deputy {{director general of the}} JAXA Institute of Space and Astronautical Science (ISAS), by succeeding in this extremely precise landing, it will lead to enhancing the quality of space exploration.|$|E
5000|$|In their {{respective}} pages, the Planets are listed {{along with their}} basic properties such as the year of planet’s discovery, mass, radius, orbital period, semi-major axis, eccentricity, inclination, longitude of periastron, time of periastron, maximum time variation, and time of transit, including all <b>error</b> <b>range</b> values.|$|E
5000|$|The entire HARP {{algorithm}} {{takes only}} a few minutes to perform on a normal computer and the motion tracking result is accurate (with a typical <b>error</b> <b>range</b> of [...] pixel). As a result, it is now widely adopted by the medical image analysis community as a standard processing technique for tagged MRI.|$|E
50|$|Using {{an audit}} {{protocol}} tool, it was identified that human entry <b>errors</b> <b>range</b> from 0.01% when entering donors' clinical follow-up details, to 0.53% when entering pathological details, highlighting {{the importance of}} an audit protocol tool in a medical research database.|$|R
40|$|OBJECTIVEdTo examine state {{differences}} in the reporting of diabetes-related incorrect cause-of-death (COD) causal sequences on death certificates in the U. S. RESEARCH DESIGN AND METHODSdWe conducted a cross-sectional descriptive study to determine the prevalence of two types of incorrect COD causal sequences with data from the Multiple Cause Mortality File of the year 2004. RESULTSdAmong deaths in which diabetes was reported as the first diagnosis on line a, b, c, or d in Part I of the death certificate in the U. S., 21 % had below diabetes placement <b>error</b> (<b>ranged</b> from 30 % in Maryland to 7 % in Hawaii) and 11 % had above diabetes placement <b>error</b> (<b>ranged</b> from 18 % in Kentucky to 5 % in California). The net effects of {{the two types of}} <b>error</b> <b>ranged</b> from 20. 7 % in Nevada to 19. 6 % in the District of Columbia. CONCLUSIONSdBecause the rates of incorrect reporting of diabetes-related COD causal sequence varied across states, the comparability of the diabetes death rate between states may have been compromised. Diabetes Care 35 : 1572 – 1574, 2012 Mortality from diabetes is one of theimportant indicators in the statediabetes surveillance system initi...|$|R
40|$|We discuss two {{different}} integration methods for radar-based quantitative precipitation estimation (QPE) : the echo intensity integral {{and the rain}} intensity integral. Theoretical analyses and simulations were used to test differences between these two methods. Cumulative rainfall calculated by the echo intensity integral is usually greater than that from rain intensity integral. The difference of calculated precipitation using these two methods is generally smaller for stable precipitation systems and larger for unstable precipitation systems. If the echo intensity signal is sinusoidal, {{the discrepancy between the}} two methods is most significant. For stratiform and convective precipitation, the normalized <b>error</b> <b>ranges</b> from − 0. 138 to − 0. 15 and from − 0. 11 to − 0. 122, respectively. If the echo intensity signal is linear, the normalized <b>error</b> <b>ranges</b> from 0 to − 0. 13 and from 0 to − 0. 11, respectively. If the echo intensity signal is exponential, the normalized <b>error</b> <b>ranges</b> from 0 to − 0. 35 and from 0 to − 0. 30, respectively. When both the integration scheme and real radar data were used to estimate cumulative precipitation for one day, their spatial distributions were similar...|$|R
50|$|Although GA {{is often}} {{regarded}} as a lesser component of the aviation industry, this perception is incorrect. In the United States, GA accounts for 96% of aircraft, 60% of flight hours, and 94% of fatal aviation accidents. Airline and military aviation {{estimates of the number}} of accidents caused by pilot <b>error</b> <b>range</b> from 70-80%.|$|E
50|$|While using {{powers of}} 2 as counter values is memory efficient, {{arbitrary}} values tend {{to create a}} dynamic <b>error</b> <b>range,</b> and the smaller values will have a greater error ratio than bigger values. Other methods of selecting counter values consider parameters such as memory availability, desired error ratio, or counting range to provide an optimal set of values.|$|E
50|$|Finally, if {{the code}} had an {{asterisk}} next to it, a final FAC would {{be drawn to}} check for error. This was done by comparing the <b>error</b> <b>range</b> on the FAC to the error rating of the fielder. For example, if the fielder's error rating was E2 and the error rating on the FAC was F8 to F10, {{then there would be}} no error.|$|E
50|$|Due to {{volume and}} density ambiguities, a {{different}} approach involves volumetrically measuring the ingredients, then using scales or balances of appropriate accuracy and <b>error</b> <b>ranges</b> to weigh them, and recording the results. With this method, occasionally an error or outlier of some kind occurs.|$|R
30|$|Hafez et al. (2013 b) {{report an}} <b>error</b> <b>ranging</b> between − 30 and 180  s, and our <b>error</b> <b>ranges</b> between − 25 and 195  s. Their average and {{standard}} deviation of detection error were 35 and 44  s, respectively, very similar to our values of 17 and 53  s. In the algorithm of Hafez et al. (2013 b), detection takes 50 – 180  s with the hardware conditions described in section “Detection speed.” Our algorithm requires, on average, 160  s after storm onset before an SSC is detected, so it is comparable in terms of detection delay. As can be seen, both studies result in very similar levels of accuracy with different data sets and programming approaches, underlining the reliability of this method.|$|R
40|$|In team sport, {{classifying}} playing position {{based on}} a players' expressed skill sets can provide a guide to talent identification by enabling the recognition of performance attributes relative to playing position. Here, elite junior Australian football players were a priori classified into 1 of 4 common playing positions; forward, midfield, defence, and ruck. Three analysis approaches {{were used to assess}} the extent to which 12 in-game skill performance indicators could classify playing position. These were a linear discriminant analysis (LDA), random forest, and a PART decision list. The LDA produced classification accuracy of 56. 8 %, with class <b>errors</b> <b>ranging</b> from 19. 6 % (midfielders) to 75. 0 % (ruck). The random forest model performed at a slightly worse level (51. 62 %), with class <b>errors</b> <b>ranging</b> from 27. 8 % (midfielders) to 100 % (ruck). The decision list revealed 6 rules capable of classifying playing position at accuracy of 70. 1 %, with class <b>errors</b> <b>ranging</b> from 14. 4 % (midfielders) to 100 % (ruck). Although the PART decision list produced the greatest relative classification accuracy, the technical skill indicators reported were generally unable to accurately classify players according to their position using the 3 analysis approaches. This player homogeneity may complicate recruitment by constraining talent recruiter's ability to objectively recognise distinctive positional attributes...|$|R
50|$|Since {{this is a}} very long-period planet {{detected}} by the radial velocity method that this planet didn't complete the orbit during the continuous observations, the <b>error</b> <b>range</b> for orbital period is very large, at 4885 ± 1600 days or 13.37 ± 4.4 years. This puts it in the range of semimajor axes between 4.2 and 6.6 AU or between 630 and 990 Gm. So this planet will need couple more years of observations to better constrain the period and semimajor axis.|$|E
5000|$|This {{estimate}} notes however that [...] "...other immigrants of Romanian {{national minority}} {{groups have been}} included such as: Armenians, Germans, Gypsies, Hungarians, Jews, and Ukrainians". It also includes an unspecified allowance for second- and third-generation Romanians, and an indeterminate number living in Canada. An <b>error</b> <b>range</b> for the estimate is not provided. For the United States 2000 Census figures, almost 20% {{of the total population}} did not classify or report an ancestry, and the census is also subject to undercounting, an incomplete (67%) response rate, and sampling error in general.|$|E
5000|$|For each {{candidate}} cluster, a least-squares {{solution for the}} best estimated affine projection parameters relating the training image to the input image is obtained. If the projection of a keypoint through these parameters lies within half the <b>error</b> <b>range</b> that {{was used for the}} parameters in the Hough transform bins, the keypoint match is kept. If fewer than 3 points remain after discarding outliers for a bin, then the object match is rejected. The least-squares fitting is repeated until no more rejections take place. This works better for planar surface recognition than 3D object recognition since the affine model is no longer accurate for 3D objects.|$|E
30|$|The N, P, and K, {{content of}} BBRDM was 49, 440.64 ± 236.25 : 1, 628.75 ± 322.25 : 9, 367.94 ± 1, 132.06 mg/kg. The N/P/K ratio was {{approximately}} 30.36 : 1 : 5.75. <b>Error</b> <b>ranges</b> indicate {{one standard deviation}} from the mean (n = 6).|$|R
30|$|Alzaharni [8] {{implemented}} a nonlinear autoregressive exogenous (NARX) model with external inputs for forecasting the {{global solar radiation}} using meteorological parameters. The data from 1991 to 2005 for Vichy National Airport in Rolla was used. The model achieved a mean square <b>error</b> <b>ranging</b> from 5.7 % to 15.33 %.|$|R
40|$|A reliable, {{real-time}} simultaneous localization and mapping (SLAM) {{method is}} crucial for the navigation of actively controlled capsule endoscopy robots. These robots are an emerging, minimally invasive diagnostic and therapeutic technology {{for use in the}} gastrointestinal (GI) tract. In this study, we propose a dense, non-rigidly deformable, and real-time map fusion approach for actively controlled endoscopic capsule robot applications. The method combines magnetic and vision based localization, and makes use of frame-to-model fusion and model-to-model loop closure. The performance of the method is demonstrated using an ex-vivo porcine stomach model. Across four trajectories of varying speed and complexity, and across three cameras, the root mean square localization <b>errors</b> <b>range</b> from 0. 42 to 1. 92 cm, and the root mean square surface reconstruction <b>errors</b> <b>range</b> from 1. 23 to 2. 39 cm...|$|R
