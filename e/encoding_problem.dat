72|639|Public
25|$|Memory {{problems}} can occur, specifically in recalling learned information, with an important improvement with cues. Recognition is less impaired than free recall, pointing towards a retrieving {{more than to}} an <b>encoding</b> <b>problem.</b>|$|E
25|$|By {{the late}} 90s, the <b>encoding</b> <b>problem</b> {{had been almost}} {{completely}} resolved, due to increasing support from software manufacturers and Internet service providers. Volapuk still maintains a level of use for SMS text messages, because {{it is possible to}} fit more characters in a Latinized SMS message than a Unicode one. It is also used in computer games that do not allow Cyrillic text in chat, particularly Counter-Strike.|$|E
50|$|Memory problems; {{specifically}} in recalling learned information, with an important improvement with cues. Recognition is less impaired than free recall pointing towards a retrieving {{more than to}} an <b>encoding</b> <b>problem.</b>|$|E
2500|$|Autism {{spectrum}} disorders (ASD) are {{neurological development}} disorders characterized by repetitive behaviours and impaired social skills. [...] Patients with ASD are also characterized by over-selectivity, {{which is a}} tendency to attend to only a few stimuli. [...] Over-selectivity causes memory <b>encoding</b> <b>problems,</b> as relevant information is not attended to, and thus not stored in memory. [...] These <b>encoding</b> <b>problems</b> are associated with an impaired memory for faces, which is in turn associated with impairments in social functioning.|$|R
5000|$|... #Caption: Between 1855 and 1859, the {{way most}} people wrote the glyphs êëè and êëé changed, causing <b>encoding</b> <b>problems</b> when {{attempting}} to transcribe documents using the latter glyphs with Unicode.|$|R
40|$|The vertex-disjoint {{triangle}} packing {{problem is}} an NP-hard problem with applications in, among others, the matching of patient-donor pairs for kidney transplantation. This paper {{shows that this}} problem can in many cases be solved efficiently by translating the problem to SAT, and solving the <b>encoded</b> <b>problem</b> with a SAT solver...|$|R
50|$|Hawkins is an {{electrical}} engineer by training, and a neuroscientist by inclination. He used electrical engineering concepts {{as well as the}} studies of neuroscience to formulate his framework. In particular, Hawkins treats the propagation of nerve impulses in our nervous system as an <b>encoding</b> <b>problem,</b> specifically, a future predicting state machine, similar in principle to feed-forward error-correcting state machines.|$|E
50|$|By {{the late}} 90s, the <b>encoding</b> <b>problem</b> {{had been almost}} {{completely}} resolved, due to increasing support from software manufacturers and Internet service providers. Volapuk still maintains a level of use for SMS text messages, because {{it is possible to}} fit more characters in a Latinized SMS message than a Unicode one. It is also used in computer games that do not allow Cyrillic text in chat, particularly Counter-Strike.|$|E
50|$|The Korean Wikipedia {{initially}} used {{an older}} version of MediaWiki, the software had problems representing Hangul, which limited usage. In August 2002, the software was upgraded {{and started to}} support non-English scripts such as hangul. However, Internet Explorer continued to have an <b>encoding</b> <b>problem,</b> which kept contributions to the encyclopedia low. Nevertheless, from October 2002 to July 2003, the number of articles increased from 13 to 159, and in August 2003 it reached 348. Finally, in September 2003 the hangul problem was solved. From September 2003, with no accessing difficulty once the encoding error in IE was solved, the number of contributions and visits increased. Korean Wikipedia's prospects became even more optimistic following the momentum created by substantial coverage in the Korean media.|$|E
40|$|We {{present a}} tool for commonsense {{reasoning}} in the classical logic event calculus using satisfiability. We describe the tool, which takes event calculus reasoning <b>problems</b> as input, <b>encodes</b> the <b>problems</b> as propositional satisfiability problems, runs a satisfiability solver on the <b>encoded</b> <b>problems,</b> and produces solutions to the reasoning problems as output. We describe the encoding method and how various commonsense phenomena are expressed using the tool. We evaluate the tool on 14 benchmark commonsense reasoning problems for the event calculus, compare its performance with the causal calculator on eight zoo world test problems, and discuss two natural understanding applications built using the tool...|$|R
50|$|Significant {{developments}} {{in the most recent}} version of EXCLAIM include support for Mandarin Chinese. By developing support for this language, EXCLAIM has added solutions to segmentation and <b>encoding</b> <b>problems</b> which will allow the system to be extended to many other languages written with non-European orthographic conventions. This support is supplied through the Trimming And Reformatting Modular System (TARMS) toolkit.|$|R
50|$|The translit system arose when Russian {{speakers}} first {{needed to}} write their language on computers that {{did not support the}} Cyrillic script. There is evidence of past translit use in international telegraphic communications. Translit found its way into web forums, chats, messengers, emails, MMORPGs and other network games. Some Cyrillic web sites had a translit version for cases of <b>encoding</b> <b>problems.</b>|$|R
5000|$|Hawkins has {{extensive}} {{training as}} an electrical engineer. Another {{way to describe}} the theory (hinted at in his book) is as a learning hierarchy of feed forward stochastic state machines. In this view, the brain is analyzed as an <b>encoding</b> <b>problem,</b> not too dissimilar from future-predicting error-correction codes. The hierarchy is a hierarchy of abstraction, with the higher level machines' states representing more abstract conditions or events, and these states predisposing lower-level machines to perform certain transitions. The lower level machines model limited domains of experience, or control or interpret sensors or effectors. The whole system actually controls the organism's behavior. Since the state machine is [...] "feed forward", the organism responds to future events predicted from past data. Since it is hierarchical, the system exhibits behavioral flexibility, easily producing new sequences of behavior in response to new sensory data. Since the system learns, the new behavior adapts to changing conditions.|$|E
40|$|A new {{theoretical}} {{formulation of}} the input <b>encoding</b> <b>problem</b> is presented, based {{on the concept of}} compatibility of dichotomies. The input <b>encoding</b> <b>problem</b> is shown to be equivalent to a two-level logic minimization. Three possible techniques to solve the <b>encoding</b> <b>problem</b> are discussed, based on: 1) techniques borrowed from classical logic minimization (generation of prime dichotomies and solving the covering problem), 2) graph coloring applied to the graph of incompatibility of dichotomies, and 3) extraction of essential prime dichotomies followed by graph coloring. The extraction of essential prime dichotomies serves the same purpose as the extraction of essential prime implicants in logic minimization, {{in the sense that it}} reduces the size of the covering/graph coloring problem. The conditions of optimality of the solutions to the input <b>encoding</b> <b>problem</b> are discussed. For near-optimum results a powerful heuristic, based on iterative improvement technique, has been developed and imple [...] ...|$|E
40|$|Abstract So far, {{very little}} has been {{published}} in the literature on the <b>encoding</b> <b>problem</b> that occurs in functional (Curtis, Roth-Karp) decomposition. In particular, the encoding techniques used to optimize the decomposition of functions for this problem have tried to optimize only the predecessor or only the successor logic, but not both concurrently. This report presents several approaches to the input-output &quot;Symbol <b>Encoding</b> <b>Problem</b> &quot; that occurs in the decomposition of Boolean functions. We show new methods for encoding, that attempt to optimize concurrently both the predecessor logic and the successor logic...|$|E
25|$|XML {{has come}} into common use for the {{interchange}} of data over the Internet. IETF , now superseded by , gave rules {{for the construction of}} Internet Media Types for use when sending XML. It also defines the media types application/xml and text/xml, which say only that the data is in XML, and nothing about its semantics. The use of text/xml has been criticized as a potential source of <b>encoding</b> <b>problems</b> and {{it has been suggested that}} it should be deprecated.|$|R
40|$|Balanced {{incomplete}} block design generation {{is a standard}} combinatorial problem from design theory. Constraint programming has recently been applied to the problem using a mixture of binary and non-binary constraints, with special techniques for symmetry breaking. We describe a new binary constraint model and apply search algorithms indirectly via satis ability <b>encoding.</b> The <b>encoded</b> <b>problems</b> {{turn out to be}} hard for current algorithms, and symmetry breaking sometimes makes them harder, but the results suggest a promising direct approach...|$|R
50|$|XML {{has come}} into common use for the {{interchange}} of data over the Internet. IETF RFC 7303 gives rules {{for the construction of}} Internet Media Types for use when sending XML. It also defines the media types application/xml and text/xml, which say only that the data is in XML, and nothing about its semantics. The use of text/xml has been criticized as a potential source of <b>encoding</b> <b>problems</b> and {{it has been suggested that}} it should be deprecated.|$|R
40|$|This paper shows {{a method}} to {{represent}} a multipleoutput function: Encoded characteristic function for nonzero outputs (ECFN). The ECFN uses (n + u) binary variables to represent an n-input m-output function, where u = dlog 2 me. The size of the sum-of-products expressions (SOPs) depends on the encoding method of the outputs. For some class of functions, the optimal encoding produces SOPs with O(n) products, while the worst encoding produces SOPs with O(2 n) products. We formulate <b>encoding</b> <b>problem</b> and show a heuristic optimization method. Experimental results using standard benchmark functions show {{the usefulness of the}} method. Index term: Multiple-output function, <b>encoding</b> <b>problem,</b> multiple-valued logic, TDM, SOP, characteristic function. 1...|$|E
40|$|This paper aims {{to propose}} a new {{selection}} procedure for real value <b>encoding</b> <b>problem,</b> specifically for shrimp diet problem. This new selection is a hybrid between two well-known selection procedure; roulette wheel selection and binary tournament selection. Shrimp diet problem is investigated to understand the hard constraints and the soft constraints involved. The comparison between other existing selections is also described for evaluation purposes. The result shows that roulette-tournament selection is better in terms of number of feasible solutions achieved and thus suitable for real value <b>encoding</b> <b>problem.</b> However, the combination with other crossover or mutation might be investigated {{to find the most}} suited combination that can obtain better best so far solution...|$|E
40|$|This paper {{provides}} a new, generalized {{approach to the}} problem of encoding information as vectors of binary digits. We furnish a formal definition for the Boolean constrained <b>encoding</b> <b>problem,</b> and show that this definition encompasses many particular encoding problems found in VLSI design, at various description abstraction levels. Our approach can capture equivalence and/or compatibil-ity classes in the original symbol set to encode, by allowing symbols codes to be cubes of a Boolean space, instead of the usual minterms. Besides, we introduce a unified framework to represent encoding constraints which is more general than previous efforts. The frame-work is based upon a new definition of the pseudo-dichotomy con-cept, and is adequate to guide the solution of encoding problems through the satisfaction of constraints extracted from the original problem statement. An <b>encoding</b> <b>problem</b> case study is presented, the state assignment of synchronous finite state machines with the simultaneous consideration of state minimization. The practical comparison with well-established approaches to solve this problem in two separate steps, shows that our solution is competitive with other published results. However, the case study is primarily in-tended to show the feasibility of the Boolean constrained <b>encoding</b> <b>problem</b> formulation. ...|$|E
5000|$|Similar to the CD versus LP {{sound quality}} debates {{common in the}} audiophile community, some videophiles argue that LaserDisc {{maintains}} a [...] "smoother", more [...] "film-like", natural image while DVD still looks slightly more artificial. Early DVD demo discs often had compression or <b>encoding</b> <b>problems,</b> lending additional support to such claims at the time. However, the video signal-to-noise ratio and bandwidth of LaserDisc are substantially {{less than that of}} DVDs, making DVDs appear sharper and clearer to most viewers.|$|R
40|$|Currently, the {{back-propagation}} is {{the most}} widely applied neural network algorithm at present. However, its slow learning speed and local minima problem are often cited as the major weakness of the algorithm. In this paper, described are an adaptive training algorithm based on selective retraining of patterns through error analysis, and dynamic adaptation of learning rate and momentum through oscillation detection for improving the performance of back-propagation algorithm. The usefulness of proposed algorithms was demonstrated in experiments with the XOR and <b>Encode</b> <b>problems...</b>|$|R
3000|$|In this section, {{we first}} {{describe}} the <b>encoding</b> decision <b>problem</b> {{that aims to}} decide which native packets should be encoded at each time slot [...]...|$|R
40|$|Abstract ‚Äî This paper {{presents}} an automated method for {{the synthesis of}} multiple-input-change (MIC) asynchronous state machines. Asynchronous state machine design is subtle since, unlike synchronous synthesis, logic must be implemented without hazards, and state codes must be chosen carefully to avoid critical races. We formulate and solve an optimal hazard-free and critical race-free <b>encoding</b> <b>problem</b> for a class of MIC asynchronous state machines called burst-mode. Analogous to a paradigm successfully used for the optimal encoding of synchronous machines, the problem is formulated as an input <b>encoding</b> <b>problem.</b> Implementations are targeted to sum-of-product realizations. We {{believe this is the}} first general method for the optimal encoding of hazard-free MIC asynchronous state machines under a generalized fundamental mode of operation. Results indicate that improved solutions are produced, ranging up to 17 % improvement. ...|$|E
40|$|Low-density parity-check (LDPC) codes can be {{considered}} serious competitors to turbo codes in terms of performance and complexity and {{they are based on}} a similar philosophy: constrained random code ensembles and iterative decoding algorithms. In this paper, we consider the <b>encoding</b> <b>problem</b> for LDPC codes. More generally, we consider the <b>encoding</b> <b>problem</b> for codes specified by sparse parity-check matrices. We show how to exploit the sparseness of the parity-check matrix to obtain efficient encoders. For the @Q TA-regular LDPC code, for example, the complexity of encoding is essentially quadratic in the block length. However, we show that the associated coefficient can be made quite small, so that encoding codes even of length IHH HHH is still quite practical. More importantly, we will show that ‚Äúoptimized‚Äù codes actually admit linear time encoding...|$|E
40|$|The paper {{describes}} the algorithm, which is developed to solve scheduling tasks in Flexible Manufacturing Systems. The algorithm {{is a combination}} of Genetic Algorithm and Coloured Petri Nets. It is proposed to use Coloured Petri Nets to tackle the <b>encoding</b> <b>problem</b> in Genetic Algorithm. The objective is to minimize the total make-span subject to different constraints obtained in Flexible Manufacturing Systems...|$|E
5000|$|Given a G√∂del {{numbering}} [...] of the computable functions, the set [...] is recursively enumerable. This set <b>encodes</b> the <b>problem</b> {{of deciding}} a function value.|$|R
3000|$|... at {{the current}} time slot. In this paper, such an <b>encoding</b> {{decision}} <b>problem</b> using XORs coding {{is referred to as}} network coding based data dissemination (NCDD) problem.|$|R
40|$|TheBlackbox {{planning}} system unifies {{the planning}} as satisfiability framework (Kautz and Selman 1992, 1996) {{with the plan}} graph approach to STRIPS planning (Blum and Furst 1995). We show that STRIPS problems can be directly translated into SAT and efficiently solved using new randomized systematic solvers. For certain computationally challenging benchmark problems this unified approach outperforms both SATPLAN and Graphplan alone. We also demonstrate that polynomialtime SAT simplification algorithms applied to the <b>encoded</b> <b>problem</b> instances are a powerful complement to the ‚Äúmutex ‚Äù propagation algorithm that works directly on the plan graph. ...|$|R
40|$|We {{present a}} new output <b>encoding</b> <b>problem</b> as follows: Given a {{specification}} table, {{such as a}} truth table or a finite state machine state table, {{where some of the}} outputs are specified in terms of 1 's, 0 's and don't cares, and others are specified symbolically, and assuming that the minimum number of bits are used to encode the symbolic outputs (#log 2 n# bits for n symbolic outputs), determine a binary code for each symbol of the symbolically specified output column such that the total number of output functions to be implemented after encoding the symbolic outputs and compacting the columns is minimum. There are several applications of this output <b>encoding</b> <b>problem,</b> one of which is to reduce the area overhead while implementing scan or pseudo-random BIST in a circuit with one-hot signals. We develop an exact algorithm to solve the above problem and present experimental data to validate the claim that our encoding strategy helps to reduce the area of a synthesized circuit...|$|E
40|$|Frequently, {{the logic}} {{designer}} deals with functions with symbolic input variables. The binary encoding of such symbols should be chosen {{to optimize the}} final implementation. Conventionally, this input <b>encoding</b> <b>problem</b> has been solved in a two step process. First step generates constraints {{on the relationship between}} binary codes for different symbols, called group constraints. In a following step, symbols are encoded such that constraints are satisfied. Face generation has not received much attention contrary to the second step. In this paper we present a novel procedure for generating face constraint in the framework of the input <b>encoding</b> <b>problem</b> with a restriction on the length of the codes. It is {{based on the fact that}} as the solution to the symbolic minimization step, involved in the face constraint generation process, is not unique, different sets of face constraints can be used to guide the encoding step. Clearly the set selected can influence the cost of the final boolean cover obtained. Preliminary experiments show promising results...|$|E
40|$|AbstractWhen {{learning}} processes {{depend on}} samples {{but not on}} the order of the information in the sample, then the Bernoulli distribution is relevant and Bernstein polynomials enter into the analysis. We derive estimates of the approximation of the entropy function xlogx that are sharper than the bounds from Voronovskaja's theorem. In this way we get the correct asymptotics for the Kullback‚ÄìLeibler distance for an <b>encoding</b> <b>problem...</b>|$|E
40|$|Recently {{different}} design tasks {{have been}} formulated as <b>problems</b> of <b>encoding</b> of symbols but restricted {{to use a}} given number of binary variables (Partial <b>Encoding</b> <b>Problems).</b> Up to now specific approaches have been developed only for one type of partial encoding problem: the Partial Input <b>Encoding</b> (PIE) <b>problem</b> and {{have been shown to}} produce better results than accommodating standard encoding algorithms to that partial problem. Optimization steps, such as the state assignment, which are formulated as Partial Input-Output problems (PIOE) are solved using PIE algorithms or standard input-output algorithms because no specific one has been proposed. This paper presents an original column based approach for the PIE problem that unlike existing ones can be extended to the PIOE. A novel study of unfeasible constraint implementation has been developed too as it is a key factor of the new method. Our preliminary algorithm performs similar to the best previous algorithms while it is portable to the PIOE Problem...|$|R
5000|$|To <b>encode</b> this <b>problem</b> as a DCOP, {{for each}} [...] create one {{variable}} [...] with associated domain [...] Then for all possible context :where [...] {{is a function}} such that ...|$|R
40|$|International audienceRelational Concept Analysis (RCA) {{facilitates}} {{the discovery of}} new abstractions in data descriptions including relations. A model driven approach for RCA implementation makes possible to deal with most input data (models) simply by configuring the transformation for the chosen input data type (metamodel). Until now, we only applied this approach to one-level models (mainly class models). In this paper we study RCA applied to bi-levels models, which mix elements and meta-elements (class-instance models, e. g. OWL models). We propose a model hybridisation approach to tackle the <b>encoding</b> <b>problems</b> and we provide a case study showing {{the results obtained on}} OWL models...|$|R
