298|770|Public
25|$|Below, {{the voltage}} gain of the {{amplifier}} with feedback, the closed-loop gain AFB, is derived {{in terms of}} the gain of the amplifier without feedback, the open-loop gain AOL and the feedback factor β, which governs how much of the output signal is applied to the input (see Figure 1). The open-loop gain AOL in general may be a function of both frequency and voltage; the feedback parameter β is determined by the <b>feedback</b> <b>network</b> that is connected around the amplifier. For an operational amplifier, two resistors forming a voltage divider may be used for the <b>feedback</b> <b>network</b> to set β between 0 and 1. This network may be modified using reactive elements like capacitors or inductors to (a) give frequency-dependent closed-loop gain as in equalization/tone-control circuits or (b) construct oscillators. The gain of the amplifier with feedback is derived below {{in the case of a}} voltage amplifier with voltage feedback.|$|E
25|$|A {{precursor}} to this approach, {{and one of}} the first model types to account for the dimension of time in linguistic comprehension and production was Elman's simple recurrent network (SRN). By making use of a <b>feedback</b> <b>network</b> to represent the system's past states, SRNs were able in a word-prediction task to cluster input into self-organized grammatical categories based solely on statistical co-occurrence patterns.|$|E
25|$|The op-amp is {{one type}} of {{differential}} amplifier. Other types of differential amplifier include the fully differential amplifier (similar to the op-amp, but with two outputs), the instrumentation amplifier (usually built from three op-amps), the isolation amplifier (similar to the instrumentation amplifier, but with tolerance to common-mode voltages that would destroy an ordinary op-amp), and negative-feedback amplifier (usually built from one or more op-amps and a resistive <b>feedback</b> <b>network).</b>|$|E
40|$|This paper {{concerns}} {{the problem of}} stability for quantum <b>feedback</b> <b>networks.</b> We demonstrate {{in the context of}} quantum optics how stability of quantum <b>feedback</b> <b>networks</b> can be guaranteed using only simple gain inequalities for network components and algebraic relationships determined by the <b>network.</b> Quantum <b>feedback</b> <b>networks</b> are shown to be stable if the loop gain is less than one-this is an extension of the famous small gain theorem of classical control theory. We illustrate the simplicity and power of the small gain approach with applications to important problems of robust stability and robust stabilization. Comment: 16 page...|$|R
50|$|In <b>feedback</b> <b>networks</b> the Willshaw network {{as well as}} the Hopfield network {{are able}} to learn instantaneously.|$|R
5000|$|This {{model is}} useful because it {{completely}} characterizes feedback amplifiers, including loading effects and the bilateral properties of amplifiers and <b>feedback</b> <b>networks.</b>|$|R
25|$|One {{might say}} {{the second stage}} of the {{amplifier}} is just a voltage follower, transmitting the voltage at the collector of the input transistor to the top of R2. That is, the monitored output signal is really the voltage at the collector of the input transistor. That view is legitimate, but then the voltage follower stage becomes part of the <b>feedback</b> <b>network.</b> That makes analysis of feedback more complicated.|$|E
25|$|For example, for a current-{{feedback}} amplifier, current {{from the}} output is sampled for feedback and combined with current at the input. Therefore, the feedback ideally {{is performed using}} an (output) current-controlled current source (CCCS), and its imperfect realization using a two-port network also must incorporate a CCCS, that is, the appropriate choice for <b>feedback</b> <b>network</b> is a g-parameter two-port. Here the two-port method used in most textbooks is presented, using the circuit treated in the article on asymptotic gain model.|$|E
25|$|If AOL ≫ 1, then AFB ≈ 1 / β, and the {{effective}} amplification (or closed-loop gain) AFB is {{set by the}} feedback constant β, and hence set by the <b>feedback</b> <b>network,</b> usually a simple reproducible network, thus making linearizing and stabilizing the amplification characteristics straightforward. Note also that if there are conditions where β AOL = −1, the amplifier has infinite amplification – {{it has become an}} oscillator, and the system is unstable. The stability characteristics of the gain feedback product β AOL are often displayed and investigated on a Nyquist plot (a polar plot of the gain/phase shift as a parametric function of frequency). A simpler, but less general technique, uses Bode plots.|$|E
40|$|This is {{the author}} {{accepted}} manuscript. The final version is available from AIP Publishing via [URL] express the rules for forming quantum <b>feedback</b> <b>networks</b> using the Stratonovich form of quantum stochastic calculus rather than the Ito or SLH (J. E. Gough and M. R. James, ?Quantum feedback networks: Hamiltonian formulation,? Commun. Math. Phys. 287, 1109 (2009), J. E. Gough and M. R. James, ?The Series product and its application to quantum feedforward and <b>feedback</b> <b>networks,?</b> IEEE Trans. Autom. Control 54, 2530 (2009)) form. Remarkably the feedback reduction rule implies that we obtain the Schur complement of the matrix of Stratonovich coupling operators where we short out the internal input/output coefficientsauthorsversionPeer reviewe...|$|R
50|$|It is also {{assumed that}} the graph of gain vs. {{frequency}} crosses unity gain with a negative slope and does so only once. This consideration matters only with reactive and active <b>feedback</b> <b>networks,</b> as {{may be the case}} with active filters.|$|R
40|$|Gough, J. E., Gohm, R., Yanagisawa, M. (2008). Linear quantum <b>feedback</b> <b>networks.</b> Physical Review A, 78 (6), Article No: 062104. The {{mathematical}} {{theory of}} quantum <b>feedback</b> <b>networks</b> {{has recently been}} developed [J. Gough and M. R. James, e-print arXiv: 0804. 3442 v 2] for general open quantum dynamical systems interacting with bosonic input fields. In this article we show, for the special case of linear dynamical Markovian systems with instantaneous feedback connections, that the transfer functions can be deduced and agree with the algebraic rules obtained in the nonlinear case. Using these rules, we derive the transfer functions for linear quantum systems in series, in cascade, and in feedback arrangements mediated by beam splitter devices. Peer reviewe...|$|R
25|$|An {{alternative}} view is {{that the}} voltage at the top of R2 is set by the emitter current of the output transistor. That view leads to an entirely passive <b>feedback</b> <b>network</b> made up of R2 and Rf. The variable controlling the feedback is the emitter current, so the feedback is a current-controlled current source (CCCS). We search through the four available two-port networks and find the only one with a CCCS is the g-parameter two-port, shown in Figure 4. The next task is to select the g-parameters so that the two-port of Figure 4 is electrically equivalent to the L-section made up of R2 and Rf. That selection is an algebraic procedure made most simply by looking at two individual cases: the case with V1 = 0, which makes the VCVS {{on the right side of}} the two-port a short-circuit; and the case with I2 = 0. which makes the CCCS on the left side an open circuit. The algebra in these two cases is simple, much easier than solving for all variables at once. The choice of g-parameters that make the two-port and the L-section behave the same way are shown in the table below.|$|E
25|$|Is {{the main}} {{amplifier}} block also a two-port? The main amplifier {{is shown in}} the upper shaded box. The ground connections are labeled. Figure 7 shows the interesting fact that the main amplifier does not satisfy the port conditions at its input and output unless the ground connections are chosen to make that happen. For example, on the input side, the current entering the main amplifier is IS. This current is divided three ways: to the <b>feedback</b> <b>network,</b> to the bias resistor RB and to the base resistance of the input transistor rπ. To satisfy the port condition for the main amplifier, all three components must be returned to the input side of the main amplifier, which means all the ground leads labeled G1 must be connected, as well as emitter lead GE1. Likewise, on the output side, all ground connections G2 must be connected and also ground connection GE2. Then, {{at the bottom of the}} schematic, underneath the feedback two-port and outside the amplifier blocks, G1 is connected to G2. That forces the ground currents to divide between the input and output sides as planned. Notice that this connection arrangement splits the emitter of the input transistor into a base-side and a collector-side – a physically impossible thing to do, but electrically the circuit sees all the ground connections as one node, so this fiction is permitted.|$|E
2500|$|... have input {{impedance}} large {{with respect to}} values present in the <b>feedback</b> <b>network.</b>|$|E
40|$|The paper {{proposes a}} general {{framework}} which encompasses {{the training of}} neural networks and the adaptation of filters. We show that neural networks {{can be considered as}} general non-linear filters which can be trained adaptively, i. e. which can undergo continual training with a possibly infinite number of time-ordered examples. We introduce the canonical form of a neural network. This canonical form permits a unified presentation of network architectures and of gradient-based training algorithms for both feedforward networks (transversal filters) and <b>feedback</b> <b>networks</b> (recursive filters). We show that several algorithms used classically in linear adaptive filtering, and some algorithms suggested by other authors for training neural networks, are special cases in a general classification of training algorithms for <b>feedback</b> <b>networks...</b>|$|R
40|$|We {{present a}} {{mathematical}} model of interacting neuron-like units that we call Input <b>Feedback</b> <b>Networks</b> (IFN). Our model is motivated by {{a new approach to}} biological neural networks, which contrasts with current approaches (e. g. Layered Neural Networks, Perceptron, etc.). Classification and reasoning in IFN ar...|$|R
5000|$|Regulatory <b>feedback</b> <b>networks</b> {{started as}} a model to explain brain {{phenomena}} found during recognition including network-wide bursting and difficulty with similarity found universally in sensory recognition. [...] This approach can also perform mathematically equivalent classification as feedforward methods and {{is used as a}} tool to create and modify networks.|$|R
2500|$|The {{first step}} is {{replacement}} of the <b>feedback</b> <b>network</b> by a two-port. Just what components go into the two-port? ...|$|E
2500|$|... a <b>feedback</b> <b>network</b> β, which senses {{the output}} signal and {{possibly}} transforms {{it in some}} way (for example by attenuating or filtering it), ...|$|E
2500|$|This {{internal}} {{compensation is}} provided to achieve unconditional {{stability of the}} amplifier in negative feedback configurations where the <b>feedback</b> <b>network</b> is non-reactive and the closed loop gain is unity or higher.|$|E
40|$|Two {{standard}} {{operations of}} model reduction for quantum <b>feedback</b> <b>networks,</b> elimination of internal connections under the instantaneous feedback limit and adiabatic elimination of fast degrees of freedom, are cast as structure-preserving transformations of It? generator matrices. It is {{shown that the}} order in which they are applied is inconsequential. Peer reviewe...|$|R
40|$|Abstract: From the {{perspective}} of nonlinear science, {{it is argued that}} one may accept physicalism and reject substance dualism without being forced into reductionism. This permits a property dualism under which biological and men-tal phenomena may emerge from intricate positive <b>feedback</b> <b>networks,</b> involving many levels of both the biological and cognitive hierarchies...|$|R
40|$|This paper proposes an {{economic}} method for the nonlinear modeling of dynamic processes using <b>feedback</b> neural <b>networks,</b> by undersampling the training sequences. The undersampling (i) allows a better {{exploration of the}} operating range of the process for a given size of the training sequences, and (ii) it speeds up the training of the <b>feedback</b> <b>networks.</b> This method is successfully applied to the training of a neural model of the electromagnetic part of an induction machine, whose sampling period must be small enough to take fast variations of the input voltage into account, i. e. smaller than 1 µs. 1...|$|R
2500|$|... "In {{contrast}} to block diagram and two-port {{approaches to the}} <b>feedback</b> <b>network</b> analysis problem, signal flow methods mandate no a priori assumptions as to the unilateral or bilateral properties of the open loop and feedback subcircuits. Moreover, they are not predicated on mutually independent open loop and feedback subcircuit transfer functions, {{and they do not}} require that feedback be implemented only globally. Indeed signal flow techniques do not even require explicit identification of the open loop and feedback subcircuits. Signal flow thus removes the detriments pervasive of conventional <b>feedback</b> <b>network</b> analyses but additionally, it proves to be computationally efficient as well." ...|$|E
2500|$|... where {{division}} is used because the input connection is shunt: the feedback two-port is {{in parallel with}} the signal source at the input side of the amplifier. A reminder: AOL is the [...] loaded open loop gain found above, as modified by the resistors of the <b>feedback</b> <b>network.</b>|$|E
2500|$|These {{currents}} {{flow through}} the resistances connected to the inputs and produce small voltage drops across those resistances. Appropriate design of the <b>feedback</b> <b>network</b> can alleviate problems associated with input bias currents and common-mode gain, as explained below. The heuristic rule {{is to ensure that}} the impedance [...] "looking out" [...] of each input terminal is identical.|$|E
40|$|AbstractThe {{bacterial}} chemotaxis {{network features}} robust adaptation implemented by negative integral feedback. Here, {{we show that}} the adaptation module can be characterized by measurement of the response to simple step-addition and removal of a chemoattractant. The method does not rely on a particular form of the receptor module, and thus {{can be used to}} characterize other integral <b>feedback</b> <b>networks...</b>|$|R
40|$|This paper {{explains}} {{some fundamental}} ideas of feedback control of quantum systems through {{the study of}} a relatively simple two-level system coupled to optical field channels. The model for this system includes both continuous and impulsive dynamics. Topics covered in this paper include open and closed loop control, impulsive control, optimal control, quantum filtering, quantum <b>feedback</b> <b>networks,</b> and coherent <b>feedback</b> control...|$|R
5000|$|Regulatory <b>feedback</b> <b>{{networks}}</b> are {{neural networks}} that perform inference using Negative feedback. [...] The feedback {{is not used}} to find optimal learning or training weights but to find the optimal activation of nodes. In effect this approach is most similar to a non-parametric method but is different from K-nearest neighbors in {{that it can be}} shown to mathematically emulate feedforward neural networks.|$|R
2500|$|If {{predictable}} {{operation is}} desired, negative feedback is used, by applying {{a portion of}} the output voltage to the inverting input. The closed-loop feedback greatly reduces the gain of the circuit. [...] When negative feedback is used, the circuit's overall gain and response becomes determined mostly by the <b>feedback</b> <b>network,</b> rather than by the op-amp characteristics. If the <b>feedback</b> <b>network</b> is made of components with values small relative to the op amp's input impedance, the value of the op-amp's open-loop response AOL does not seriously affect the circuit's performance. The response of the op-amp circuit with its input, output, and feedback circuits to an input is characterized mathematically by a transfer function; designing an op-amp circuit to have a desired transfer function is in the realm of electrical engineering. [...] The transfer functions are important in most applications of op-amps, such as in analog computers. High input impedance at the input terminals and low output impedance at the output terminal(s) are particularly useful features of an op-amp.|$|E
2500|$|If {{instead we}} wanted to find the {{impedance}} presented at the emitter of the output transistor (instead of its collector), which is series connected to the <b>feedback</b> <b>network,</b> feedback would increase this resistance by the improvement factor ( [...] 1 + βFB AOL). = 0, inserting a test current in the emitter lead Ix, finding the voltage across the test source Vx, and finding Rout = Vx / Ix.|$|E
2500|$|On {{the other}} hand, {{for the current}} amplifier, the output current βIout of the <b>feedback</b> <b>network</b> is applied in {{parallel}} and with an opposite direction to the input current Ix. As a result, the total current flowing through the circuit input (not only through the input resistance Rin) increases and the voltage across it decreases so that the circuit input resistance decreases (Rin apparently decreases). Its new value can be calculated by applying the dual Miller theorem (for currents) or the basic Kirchhoff's laws: ...|$|E
5000|$|<b>Feedback</b> Delay <b>Networks</b> - Digital {{reverberation}} devices {{which use}} Hadamard matrices to blend sample values ...|$|R
40|$|We {{express the}} rules for forming quantum <b>feedback</b> <b>networks</b> using the Stratonovich form of quantum {{stochastic}} calculus rather than the Ito, or SLH form. Remarkably the feedback reduction rule implies that we obtain the Schur complement of the matrix of Stratonovich coupling operators where we short out the internal input/output coefficients. Comment: 14 pages, 6 figures (The Stratonovich form of the Series Product added in the revision. ...|$|R
40|$|Synaptic {{connections}} adjusted {{one at a}} time {{in small}} increments. Simplified gradient-descent learning scheme for electronic neural-network processor less efficient than better-known back-propagation scheme, but offers two advantages: easily implemented in circuitry because data-access circuitry separated from learning circuitry; and independence of data-access circuitry makes possible to implement feedforward as well as <b>feedback</b> <b>networks,</b> including those of multiple-attractor type. Important in such applications as recognition of patterns...|$|R
