22|100|Public
30|$|Figures  6 and 7 {{show the}} {{estimation}} {{accuracy of the}} proposed method. From these figures, {{we can see that}} the proposed method can show the unexpected large estimation errors that may occur. Usually, the <b>frame</b> <b>correlation</b> is high because of the same frame type and being adjacent to each other. However, during cases like scene change, the <b>frame</b> <b>correlation</b> becomes low. This is the case where there occur large estimation errors. In this case, complexity information for estimation for the next frame cannot be used, and we should update the complexity information. So, we use complexity profiling with max frequency of processor which is explained in Equation  7.|$|E
40|$|In {{this work}} we {{address the problem}} of {{designing}} an efficient algorithm that allows high quality real time video streaming, from the source coding and scheduling perspectives. We take into account some key quantities like <b>frame</b> <b>correlation,</b> channel constraints and QoS metrics such as distortion and PSNR. We first formalize the problem in a mathematical fashion and then propose a Markov-chain based solution that applies to quantized values of the metrics involved in the framewor...|$|E
3000|$|... [...]) {{into a new}} {{analytic}} method {{which is}} used to classify many Grassmannian frames in this setting. The method and associated algorithm decrease the maximum <b>frame</b> <b>correlation,</b> and hence give rise to the construction of specific examples of Grassmannian frames. Many of the results are known by other techniques, and even more generally, so that this paper can be viewed as tutorial. However, our analytic method is presented with the goal of developing it to address unresovled problems in [...]...|$|E
40|$|December 2016 feature release IMPROVED: umxRAM returns invisibly IMPROVED: umx_aggregate {{can return}} a {{formatted}} table (kable = TRUE) IMPROVED: umxAPA returns lower-triangle of data. <b>frame</b> <b>correlations</b> (by default) REMOVED: umxSE now included in OpenMx 2. 7. 0 ! FIXED: umx_set_plot_format uses silent = TRUE internally where neede...|$|R
40|$|Abstract—In this paper, {{we develop}} a novel video {{watermarking}} framework {{based on the}} collusion-resistant design rules formulated in a companion paper. We propose to employ a spatially-localized image dependent approach to create a watermark whose pairwise <b>frame</b> <b>correlations</b> approximate those of the host video. To characterize the spread of its spatially-localized energy distribution, {{the notion of a}} watermark footprint is introduced. Then we explain how a particular type of image dependent footprint structure, comprised of subframes centered around a set of visually significant anchor points, can lead to two advantageous results: pairwise watermark <b>frame</b> <b>correlations</b> that more closely match those of the host video for statistical invisibility, and the ability to apply image watermarks directly to a frame sequence without sacrificing collusion-resistance. In the ensuing overview of the proposed video watermark, two new ideas are put forward: synchronizing the subframe locations using visual content rather than structural markers and exploiting the inherent spatial diversity of the subframe-based watermark to improve detector performance. Simulation results are presented to show that the proposed scheme provides improved resistance to linear frame collusion, while still being embedded and extracted using relatively low complexity frame-based algorithms. Index Terms—Image feature extraction, linear collusion, robust digital video watermarking, statistical invisibility. I...|$|R
40|$|Abstract — This paper {{presents}} an algorithm {{to find out}} the path of an object which is moving in different frames. These objects are coming from different background. To detect a moving object from different <b>frames</b> <b>correlation</b> is useful but correlation process consumes huge time. So to reduce searching time here selective correlation is used. The proposed algorithm can significantly speed up the computation of the block matching because for many search position of the block, only 1 / 4 th size of that block needs to be calculated. This paper focuses to minimize the object detection time...|$|R
40|$|In this dissertation, we {{investigate}} methods of modifying a tight frame sequence on a finite {{subset of the}} frame so that {{the result is a}} tight frame with better properties. We call this a surgery on the frame. There are basically three types of surgeries: transplants, expansions, and contractions. In this dissertation, {{it will be necessary to}} consider surgeries on not-necessarily-tight frames because the subsets of frames that are excised and replaced are usually not themselves tight frames on their spans, even if the initial frame and the final frame are tight. This makes the theory necessarily complicated, and richer than one might expect. Chapter I is devoted to an introduction to frame theory. In Chapter II, {{we investigate}} conditions under which expansion, contraction, and transplant problems have a solution. In particular, we consider the equiangular replacement problem. We show that we can always replace a set of three unit vectors with a set of three complex unit equiangular vectors which has the same Bessel operator as the Bessel operator of the original set. We show that this can not always be done if we require the replacement vectors to be real, even if the original vectors are real. We also prove that the minimum angle between pairs of vectors in the replacement set becomes largest when the replacement set is equiangular. Iterating this procedure can yield a frame with smaller maximal <b>frame</b> <b>correlation</b> than the original. Frames with optimal maximal <b>frame</b> <b>correlation</b> are called Grassmannian frames and no general method is known at the present time for constructing them. Addressing this, in Chapter III we introduce a spreading algorithm for finite unit tight frames by replacing vectors three-at-a-time to produce a unit tight frame with better maximal <b>frame</b> <b>correlation</b> than the original frame. This algorithm also provides a ?good? orientation for the replacement sets. The orientation part ensures stability in the sense that if a selected set of three unit vectors happens to already be equiangular, then the algorithm gives back the same three vectors in the original order. In chapter IV and chapter V, we investigate two special classes of frames called push-out frames and group frames. Chapter VI is devoted to some mathematical problems related to the ?cocktail party problem ?...|$|E
40|$|The {{frame to}} <b>frame</b> <b>correlation</b> {{properties}} of the video process are utilized to reduce the mean squared error of the demodulated video where zero mean noise is a factor. An interpolative estimator is used for continuous estimation with the output process delayed in time by one frame. Theoretical development shows that for the model herein developed reduction of the mean squared error by 1. 0 to 4. 0 db possible for parameter ranges of interest. Interpolative estimation using inter-frame correlation properties of a video process is then applied to the Apollo 17 parameters to yield a model for application on that mission...|$|E
40|$|In {{this paper}} a novel {{scalable}} video coder, {{based on the}} principle of distributed source coding with side information is proposed. Coding scalability is achieved by means of bitplane coding in the wavelet domain. The distributed coding paradigm is applied to encode the wavelet coefficients of a given frame, by considering those of the previous frame as side information. LDPC syndrome encoding with proper context modeling of the <b>frame</b> <b>correlation</b> allowed us to significantly outperform intra coding obtained with JPEG 2000. Moreover, the proposed approach permits to perform motion compensation at the decoder side, thus opening a new perspective in the field of scalable video codin...|$|E
40|$|Two point space-time {{measurements}} of the axial component of fluctuating velocity were made using linearized hot-wire anemometry. Space scales, convected <b>frame</b> <b>correlations</b> and time scales, and convection velocities in the shear layer were evaluated. Both filtered narrow and broad band convected frame autocorrelations were determined. Differences between axial broad band convection velocities and both mean turbulence and mean entrained fluid velocities were observed. Scaled broad band convection velocities for the mixing layer and simple round jets were found to collapse to a common curve. Axial narrow band convection velocities showed strong frequency and transverse position dependence...|$|R
40|$|The {{relativistic}} {{version of}} the Greenberger-Horne-Zeilinger experiment with massive particles is proposed. We point out that, in the moving <b>frame,</b> GHZ <b>correlations</b> of spins in original directions transfer to different directions due to the Wigner rotation. Its effect {{on the degree of}} violation of Bell-type inequality is also discussed. Comment: 12 page...|$|R
40|$|We {{studied the}} subset of optical light curves of gamma-ray bursts with {{measured}} redshifts and well-sampled R band data that have clearly detected peaks. Among 43 such events, 11 are promptoptical peaks (P), coincident with gamma-ray activity, 22 are purely afterglows (A), and 10 more carrythe signatures of an underlying activity (A(U)). We studied pair correlations of their gamma-ray andoptical parameters, e. g. total energetics, peak optical luminosities, and durations. The main outcomeof our {{study is the}} detection of source <b>frame</b> <b>correlations</b> between both optical peak luminosity and total energy and the redshift for classes A and A(U), {{and the absence of}} such a correlation for class Pevents. This result seems to provide evidence of the cosmological evolution of a medium around the burst defining class A and A(U) energetics, and the absence of cosmological evolution of the internal properties of GRB engines. We also discuss some other prominent correlations...|$|R
40|$|An {{algorithm}} {{of detection}} and tracking of multiple small moving space junks under the complex star sequential images is proposed in this paper. Firstly we take image smoothing and adaptive threshold segment {{to improve the}} weight of junks. Furthermore, back neighborhood <b>frame</b> <b>correlation</b> (BNFC) is proposed to detect and locate the junk which is sheltered by bigger interfaced stars. Through cross projection method, we could extract the centroid of the moving junks. At last, the Kalman Filter is used to track and estimate the trajectory of moving junks. Experiments show that through this algorithm the multiple small space junks could be detected and tracked effectively and accurately under complex star background with good performance in low error rate and good real-time processing. © 2016 SPIE. </p...|$|E
40|$|Grassmannian {{frames are}} frames {{satisfying}} a minmax correlation criterion. We translate a geometrically intuitive approach {{for two and}} three dimensional Euclidean space (R 2 and R 3) into a new analytic method {{which is used to}} classify many Grassmannian frames in this setting. The method and associated algorithm decrease the maximum <b>frame</b> <b>correlation,</b> and hence give rise to the construction of specific examples of Grassmannian frames. Many of the results are known by other techniques, and even more generally, so that this paper can be viewed as tutorial. However, our analytic method is presented with the goal of developing it to address unresovled problems in d-dimensional Hilbert spaces which serve as a setting for sherical codes, erasure channel modeling, and other aspects of communications theory...|$|E
40|$|AbstractThis paper {{presents}} a novel error resilience scheme for wavelet scalable video coding. We use Wyner-Ziv codec to produce extra bits protecting the {{important parts of}} the embedded video streaming. At the same time these bits also as the second description of important parts are transmitted over auxiliary channel to the receiver for error resilience. The errors in the embedded video streaming can be corrected by Wyner-Ziv description which regards the decoded frame as side information. Moreover, Wyner-Ziv decoder utilizes a coarse estimated version of the corrupted parts exploiting <b>frame</b> <b>correlation</b> in wavelet video decoder to generate a refine version. Simulation results show that our proposed method can achieve much better performance compared with Forward Error Correction code. Meanwhile, this error resilient algorithm can achieve 2 - 3 dB PSNR gains over the motion compensation error concealment...|$|E
40|$|There {{has been}} a growing concern about the {{potential}} impact of long-term correlations (second-order statistic) in variable-bit-rate (VBR) video traffic on ATM buffer dimensioning. Previous studies have shown that video traffic exhibits long-range dependence (LRD) (Hurst parameter large than 0. 5). We investigate the practical implications of LRD in the context of realistic ATM traffic engineering by studying ATM multiplexers of VBR video sources over a range of desirable cell loss rates and buffer sizes (maximum delays). Using results based on large deviations theory, we introduce the notion of Critical Time Scale (CTS). For a given buffer size, link capacity, and the marginal distribution of frame size, the CTS of a VBR video source is defined as the number of <b>frame</b> <b>correlations</b> that contribute to the cell loss rate. In other words, second-order behavior at the time scale beyond the CTS does not significantly affect the network performance. We show that whether the video source model i [...] ...|$|R
40|$|The present paper {{provides}} a {{comprehensive study of}} de-noising properties of frames and, in particular, tight frames, which constitute {{one of the most}} popular tools in contemporary signal processing. The objective of the paper is to bridge the existing gap between mathematical and statistical theories on one hand and engineering practice on the other and explore how one can take advantage of a specific structure of a frame in contrast to an arbitrary collection of vectors or an orthonormal basis. For both the general and the tight frames, the paper presents a set of practically implementable de-noising techniques which take <b>frame</b> induced <b>correlation</b> structures into account. These results are supplemented by an examination of the case when the frame is constructed as a collection of orthonormal bases. In particular, recommendations are given for aggregation of the estimators at the stage of frame coefficients. The paper is concluded by a finite sample simulation study which confirms that taking frame structure and <b>frame</b> induced <b>correlations</b> into account indeed improves de-noising precision. Comment: 22 pages, 2 figure...|$|R
40|$|This paper {{presents}} a formant tracking linear prediction (LP) model for speech processing in noise. The {{main focus of}} this work is on the utilization of the correlation of the energy contours of speech, along the formant tracks, for improved formant and LP model estimation in noise. The approach proposed in this paper provides a systematic framework for modelling and utilization of the inter-frame correlation of speech parameters across successive speech frames; the within <b>frame</b> <b>correlations</b> are modelled by the LP parameters. The formant tracking LP model estimation is composed of three stages: (1) a pre-cleaning spectral amplitude estimation stage where an initial estimate of the LP model of speech for each frame is obtained, (2) a formant classification and estimation stage using probability models of formants and Viterbi-decoders and (3) an inter-frame formant de-noising and smoothing stage where Kalman filters are used to model the formant trajectories and reduce the effect of residue noise on formants. The adverse effects of car and train noise on estimates of formant tracks and LP models are investigated. The evaluation results for the estimation of the formant tracking LP model demonstrate that the proposed combination of the initial noise reduction stage with formant tracking and Kalman smoothing stages, results in {{a significant reduction in}} errors and distortions...|$|R
40|$|This paper investigates ways {{to explore}} the between <b>frame</b> <b>correlation</b> of shape {{information}} {{within the framework of}} an operationally rate-distortion (ORD) optimal coder. Contours are approximated both by connected second-order spline segments, each defined by three consecutive control points, and by segments of the motioncompensated reference contours. Consecutive control points are then encoded predictively using angle and run temporal contexts. We utilize a novel criterion for selecting global object motion vectors, which further improves efficiency. Formulating this problem as Lagrangian minimization, we employ an iterative technique to remove dependency on a particular VLC and jointly arrive at the ORD optimal solution and its underlying conditional parameter distribution. 1. INTRODUCTION In the process of evaluating competing techniques for the MPEG- 4 standard, several binary coders were considered. These coders, however, lack optimality in their both intra and inter modes of ope [...] ...|$|E
40|$|Spatial {{sampling}} is {{a necessary}} and important method for extracting geospatial data and its methodology directly affects the geo-analysis results. Counter to the deficiency of separate models of spatial, sampling, this article analyzes three crucial elements of spatial sampling (<b>frame,</b> <b>correlation</b> and decision diagram) and induces its general integrated model. The program of Spatial Sampling Integration (SSI) has been developed with Component Object Model (COM) to realize the general integrated model. In two practical applications, i. e. design of the monitoring network of natural disasters and sampling survey of the areas of non-cultivated land, SSI has produced accurate results at less cost, better realizing the cost-effective goal of sampling toward the geo-objects with spatial correlation. The two cases exemplify expanded application and convenient implementation of the general integrated model with inset components in an integrated environment, which can also be extended to other modeling of spatial analysis...|$|E
40|$|An {{effective}} method for dim and small multi-targets detection and tracking through successive CCD images in complex starry background is put forward in this paper. Optical starry background images contain {{a lot of}} interference noise besides the moving targets. Firstly, self-adaptive threshold segmentation {{can play an important}} role in eliminating noise and improving detection rate. Furthermore, back neighborhood <b>frame</b> <b>correlation</b> (BNFC) is proposed to detect and locate the target, which is sheltered by bigger interfered stars. After detection framework acquiring the location of moving targets, particle filter which has nonlinear filtering feature is applied to track the trajectories for multi-targets in real-time. Experimental results show that by using the adaptive target detection and improved particle filter, the trajectories could be achieved at a relative low signal to noise ratio (SNR ≥ 3. 5) in the case of multi-targets detection and tracking in real time. The method has good prospect for engineering application. </p...|$|E
40|$|Camera/photometer {{systems have}} been {{constructed}} for analyzing particulate contamination on STS- 2. The systems contained two 16 -mm photographic cameras to make stereoscopic observation of contaminant particles and the background. During the STS- 2 mission, 102 photographic exposures were obtained under conditions suitable for recording particulate contamination. Attention is given to a breakdown of STS- 2 camera/photometer data {{with the number of}} particles observed per <b>frame,</b> a <b>correlation</b> of observed contamination with mission elapsed time broken into 5 -hr segments, and a correlation of observed contamination with onboard spacecraft events...|$|R
40|$|We {{exhibit a}} purely quantum {{mechanical}} carrier of the imprints of gravitation by identifying for a relativistic system a property which (i) {{is independent of}} its mass and (ii) expresses the Poincare invariance of spacetime {{in the absence of}} gravitation. This carrier consists of the phase and amplitude correlations of waves in oppositely accelerating <b>frames.</b> These <b>correlations</b> are expressed as a Klein-Gordon-equation-determined vector field whose components are the ``Planckian power'' and the ``r. m. s. thermal fluctuation'' spectra. The imprints themselves are deviations away from this vector field. Comment: 8 pages, RevTex. Html version of this and related papers on accelerated frames available at [URL]...|$|R
40|$|Abstract: Most EIT image {{reconstruction}} algorithms do {{not account}} for temporal effects such as non-instantaneous acquisition of data <b>frames</b> and temporal <b>correlation</b> between successive EIT images. We have recently published a framework for assessing the performance of reconstruction algorithms accounting for temporal effects. Results of ap-plying this framework to five reconstruction algorithms and three types of EIT data frame will be presented. ...|$|R
40|$|Face Detection {{makes it}} {{possible}} to use the facial images of a person to authenticate him into secure system, for criminal identification, for passport verification etc. It is done by Principal Component Analysis (PCA). Face images are projected onto a face space that encodes best variation among known face images. The face space is collection of Eigen face. In the algorithm, initially video segmented using shot boundary detection techniques. Specifically, it can detect both the cut and gradual shot transitions in video. For detecting the shot boundary haar wavelet transform is used. In this method, each frame and its haar wavelet transform image is correlated for detection the shot. By setting the threshold of <b>frame</b> <b>correlation</b> shot boundaries can be detected. Video segmentation can be used in various application like video summarization, video search, and video annotation. General Terms For detecting face there are various algorithms including skin color based algorithms like Image acquisition, get video frame, run detector, bonding box around face etc...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimited. For an Autonomous Underwater Vehicle to complete many operational missions, {{it must have}} the ability to maintain its position relative to the ocean floor. Maintaining station requires that the AUV be able to determine the direction and the distance displaced during a small time interval. Knowing the direction and distance traveled in a measured amount of time, the magnitude and direction of the ocean current can be calculated. Once this ocean current information is known, the AUV speed and direction can be properly adjusted to directly offset the ocean current forces. This thesis will attempt to determine, by computer simulation, if the first problem of AUV station keeping, vehicle movement direction and distance detection can be performed using bottom-tracking sonar as the AUV's only sensor. Both the problems of performing and storing successive synthetic sonar images and of determining AUV motion using frame to <b>frame</b> <b>correlation</b> of these images are investigated. Naval Postgraduate School under the cognizance of the Naval Surface Weapons Center O & MN, Direct Funding[URL] Postgraduate School under the cognizance of the Naval Surface Weapons Center O & MN, Direct FundingLieutenant, United States Coast Guar...|$|E
40|$|In this {{dissertation}} {{we first}} consider {{a problem in}} analog to digital (A/D) conversion. We compute the power spectra of the error arising from an A/D conversion. We then design various higher dimensional analogs of A/D schemes, and compare these schemes to a standard error diffusion scheme in digital halftoning. Secondly, we study finite frames. We classify certain finite frames that are constructed as orbits of a group. These frames are seen to have subtle symmetry properties. We also study Grassmannian frames which are frames with minimal correlation. Grassmannian frames have an important intersection with spherical codes, erasure channel models, and communication theory. This is {{the main part of}} the dissertation, and we introduce new theory and algorithms to decrease the maximum <b>frame</b> <b>correlation</b> and hence construct specific examples of Grassmannian frames. A connection has been drawn between the two parts of this thesis, namely A/D conversion and finite frames. In particular, finite frames are used to expand vectors in ^d, and then different quantization schemes are applied to the coefficients of these expansions. The advantage is that all possible outcomes of quantization can be considered because of the finite dimensionality...|$|E
30|$|Recently, the {{construction}} of equiangular tight frames has gained {{the interest of the}} sparse modeling community, as ETFs are maximally incoherent. Thus, a category of algorithms that produce incoherent frames has been developed in the latest years [22 – 30]. Most of the existing algorithms are inspired by the work of [17] and are based on a “shrinkage” operation on the Gram matrix. For example, the algorithm proposed in [22] starts from an arbitrary m×N frame that has full rank, and sequentially “shrinks” the absolute values of the off-diagonal entries of the Gram matrix in order to reduce <b>frame’s</b> column <b>correlation.</b> Then, truncated SVD is used to obtain a frame with rank m.|$|R
40|$|International audienceThe {{application}} of distributed coding in many media applications, where low power and low-complexity encoder device is essential, {{is a new}} paradigm. In this paper, we propose a new pixel-domain Distributed Video Coding (DVC) scheme, in which both temporal and spatial correlations are exploited at the decoder. The Slepian-Wolf decoder is modified by introducing a source decoder to exploit Wyner-Ziv <b>frame's</b> spatial <b>correlation.</b> We assume the most significant bitplanes to be one-dimensional stationary markov process. The markov characteristic means that this source has a residual redundancy providing additional information for the receiver and can be exploited to correct some errors introduced by the virtual channel, through a joint source-channel decoding scheme...|$|R
3000|$|... (n) ≥ 0.5, {{then the}} context in the time domain is {{employed}} in the present adjacent subbands with the same bit allocation. By statistical analysis, {{we have found that}} the audio coding parameters for music signal have higher correlation than the speech signal in time domain. As to the quantized norms in G. 719, a large percentage, 98.9 %, of all the <b>frames</b> have the <b>correlation</b> (i.e., the correlation coefficient is higher than 0.5) between the adjacent frames which enables larger compression.|$|R
40|$|We {{consider}} a scenario with a mobile user who either upstreams a video clip to a portal in the Internet, where video consumers can watch it in real-time, or, conversely, downstreams a multi-view video from the Internet {{to be played}} on his/her mobile device. Thus, we design a delivery framework {{that takes into account}} the correlation of the video frames, due to the dynamics of the scene both in the temporal and spatial domains (multiviews), and the available time-varying wireless channel capacity, to predict the evolution {{of the structure of the}} video segment to be sent. We implement a Markov Decision Process (MDP) model to foresee the optimal video encoding and packet scheduling policies to be used at the video source to generate the video frames with the goal of minimizing the overall distortion of the video consumed at the end user side. By means of simulation, we discuss the insights gained into the impact of <b>frame</b> <b>correlation</b> and time-varying wireless channel on the video stream generation and transmission, and the possible benefits from extending the model to more complex video coding and scheduling mechanisms...|$|E
40|$|This paper {{presents}} a novel filtering technique based on sample adaptive offset (SAO) in H. 265 /high-efficiency video coding (HEVC) for {{reduction in the}} temporal flickering artifacts and improving the coding performance. SAO is a newly introduced technique for in-loop filtering in H. 265 /HEVC, which derives the offsets independently for each frame in the spatial domain without considering temporal <b>frame</b> <b>correlation.</b> As a result, the temporal distortion artifacts which will {{have a negative effect}} on the subjective quality, such as flickering artifacts, cannot be effectively addressed. In this paper, the rate-distortion optimization of the newly developed SAO method, referred to as Inter-SAO, is performed on the residual samples between adjacent frames. Inter-SAO and SAO in the reference software of H. 265 /HEVC (i. e., the test model HM) are then combined to form the novel in-loop filter-based method, denoted as 3 D-SAO filtering method, where both spatial information and temporal information are effectively utilized to reduce the overall distortion in reconstructed videos. Compared with the SAO in HM, 3 D-SAO has demonstrated its advanced performance for flickering artifacts suppression. Furthermore, 3 D-SAO improves the coding efficiency compared with the SAO in HM with a performance gain of up to 0. 91 dB in, 1. 74 dB in and 7. 33 % in BD-rate reduction...|$|E
40|$|This paper {{proposes a}} new speaker-dependent coding {{algorithm}} to efficiently compress a large speech database for corpus-based concatenative text-to-speech (TTS) engines while maintaining high fidelity. To achieve a high compression ratio {{and meet the}} fundamental requirements of concatenative TTS synthesizers, such as partial segment decoding and random access capability, we adopt a nonpredictive analysis-by-synthesis scheme for speaker-dependent parameter estimation and quantization. The spectral coefficients are quantized by using a memoryless split vector quantization (VQ) approach that does not use <b>frame</b> <b>correlation.</b> Considering that excitation signals of a specific speaker show low intra-variation especially in the voiced regions, the conventional adaptive codebook for pitch prediction {{is replaced by a}} speaker-dependent pitch-pulse codebook trained by a corpus of single-speaker speech signals. To further improve the coding efficiency, the proposed coder flexibly combines nonpredictive and predictive type method considering the structure of the TTS system. By applying the proposed algorithm to a Korean TTS system, we could obtain comparable quality to the G. 729 speech coder and satisfy all the requirements that TTS system needs. The results are verified by both objective and subjective quality measurements. In addition, the decoding complexity of the proposed coder is around 55 % lower than that of G. 729 annex A...|$|E
40|$|This paper {{describes}} the hardware {{design and implementation}} of the JAWS (Just Another Watermarking System) embedder and detector for watermarking of realtime uncompressed digital video. Our design employs a floating point datapath, maximizing dynamic range of the FFT, <b>frame</b> filtering, and <b>correlation</b> operations. The design, implemented in a 1. 8 V, 0. 18 μm CMOS process with a core area of 3. 53 mm 2, is capable of watermarking video streams at a peak rate of over 3 Mpixels/s. 1...|$|R
40|$|Bayesian maxent lets one {{integrate}} thermal {{physics and}} information theory {{points of view}} in the quantitative study of complex systems. Since net surprisal (a free energy analog for measuring "departures from expected") allows one to place second law constraints on mutual information (a multi-moment measure of correlations), it makes a quantitative case {{for the role of}} reversible thermalization in the natural history of invention, and suggests multiscale strategies to monitor standing crop as well. It prompts one to track evolved complexity starting from live astrophysically-observed processes, rather than only from evidence of past events. Various gradients and boundaries that play a role in availability flow, ranging from the edge of a wave-packet to the boundary between idea-pools, allow one to <b>frame</b> wide-ranging <b>correlations</b> (including that between a phenomenon and its explanation) as delocalized physical structures. Comment: 8 pages, 3 figures, 43 reference...|$|R
30|$|The {{presence}} of an irregular internal frame substantially increases building vulnerability to earthquake loads (estimated parameter: 0.604; Table  2). Our marginal effect analysis demonstrates that a one-unit increase in internal frame irregularity increases the earthquake load vulnerability of factory buildings by 0.047 (Table  2). This result {{is consistent with the}} findings of Yee et al. (2011) where the authors mentioned that a regular column grid is a pre-requisite for seismic resistance. An irregular internal <b>frame</b> has moderate <b>correlation</b> with earthquake load vulnerability (correlation value: 0.409; Table  4).|$|R
