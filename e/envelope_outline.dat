1|14|Public
40|$|The scale {{effects of}} Area-Specific {{sediment}} yield (Ys) are studied for Zhujiang basin and its four sub-basins. Considering the entire Zhujiang basin, {{there is no}} apparent relation between Ys and contributing area (A(d)) for stations when A(d) is less than 100, 000 km(2), while there is an upper <b>envelope</b> <b>outline</b> of Ys. For the stations with A(d) larger than 100, 000 km(2) mainly located on the middle and lower reaches, there is a negative relation of Ys to A(d). Considering the four sub-basins of Zhujiang basin, three kinds of relations between Ys and A(d) are established: (1) Ys increases with A(d) for the sub-basin of the upper reach; (2) Ys increases with A(d) then declines for the two sub-basins of the middle reaches; (3) Ys decreases with Ad for the sub-basin of the lower reaches. The Ys-A(d) relation is further investigated using the spatial variation of hill slopes, the Land Use and Land Cover (LULC), and the bed slopes. Finally, to remove the effect of A(d) and to make Ys comparable across scales, the scaled Ys calculation equations are given for both linear and non-linear relations between Ys and A(d) first. And then the Ys are scaled to the standard units of 1000 km(2) and 10, 000 km(2). Using Kriging method, the Ys maps are created under GIS platform where high Ys centers are outlined, and the spatial patterns of Ys are compared for the two standard unit Ys maps. (C) 2013 Elsevier Ltd and INQUA. All rights reserved...|$|E
40|$|Climate {{change is}} a {{worrying}} problem of unprecedented magnitude originated by greenhouse gas emissions. It encompasses increased mean temperature and heat waves {{that are responsible for}} aggravating Urban Heat Island (UHI) effects. This is not only responsible for an escalation of health problems and human deaths, but it also leads to an increase of building cooling needs. This chapter reviews aspects of climate change, including UHI. Attention is dedicated to adaptation and mitigation related issues, especially to the greening of the building <b>envelope.</b> An <b>outline</b> of the book is included...|$|R
40|$|A modular, {{maintainable}} and extensible {{particle beam}} simulation architecture is presented. Design considerations for single particle, multi particle, and rms envelope simulations (in {{two and three}} dimensions) are <b>outlined.</b> <b>Envelope</b> simulation results have been validated against Trace 3 D. Hybridization with a physics-centric contol-system abstraction provides a convenient environment for rapid deployment of applications employing model-reference control strategies. ...|$|R
40|$|AbstractThe paper {{describes}} {{an evaluation of}} thermal performance of residential building envelope. Basing on the visual-and-instrumental inspection the conclusion on the non-compliance of the stated object {{with the requirements of}} the design and normative documentation was drawn. The thermovision control allowed revealing latent defects of the buildings <b>envelopes</b> and <b>outlining</b> the ways of their elimination. The numerical modeling of heat transfer made it possible to reasonably develop suggestions aimed at enhancing the thermal performance of buildings envelope elements. The integrated application of these methods gave an opportunity to determine the thermotechnical state of the object in whole. The results of the study serve as a basis for the development of methodological foundations for design, construction, operation and reconstruction of energy-efficient building...|$|R
40|$|International audienceThe {{amplitude}} modulations {{of musical}} instrument sounds and speech are important perceptual cues. Accurate {{estimation of the}} amplitude, or equivalently energy, envelope of a time-domain signal (waveform) is not a trivial task, though. Ideally, the amplitude <b>envelope</b> should <b>outline</b> the waveform connecting the main peaks and avoiding over fitting. In this work we propose a method to obtain a smooth function that approximately matches the main peaks of the waveform using true envelope estimation, dubbed true amplitude envelope. True envelope is a cepstral smoothing technique that {{has been shown to}} outperform traditional envelope estimation techniques both in accuracy of estimation and ease of order selection. True amplitude envelope gives a reliable estimation that follows closely sudden variations in amplitude and avoids ripples in more stable regions with near optimal order selection depending on the fundamental frequency of the signal...|$|R
40|$|Emission and {{absorption}} line observations of molecules in late-type stars are a vital component {{in our understanding}} of stellar evolution, dust formation and mass loss in these objects. The molecular composition of the gas in the circumstellar envelopes of AGB stars reflects chemical processes in gas whose properties are strong functions of radius with density and temperature varying by more than ten and two orders of magnitude, respectively. In addition, the interstellar UV field plays a critical role in determining not only molecular abundances but also their radial distributions. In this article, I shall briefly review some recent successful approaches to describing chemistry in both the inner and outer <b>envelopes</b> and <b>outline</b> areas of challenge for the future. Comment: To appear in the refereed proceedings of the 11 th Pacific Rim Conference on Stellar Astrophysics held in Hong Kong, Dec. 14 - 17, 2015, Sun Kwok (editor). 10 pages, 2 figure...|$|R
40|$|The thesis {{deals with}} the {{assessment}} of the current proposal for pension envelopes along with proposing alternative plans with emphasis on reducing heating costs. The first section describes the types of buildings according to heating demand and output energy performance of buildings. Work also deals with a list of different variants of thermal insulation materials and design options outer insulation of the building <b>envelope.</b> It <b>outlines</b> fire characteristics of building materials and options of construction budget. The second part is devoted to a specific pension house in the Old Rejviz for which there are designed in three variants of insulation. These variants are then reviewed in terms of thermal insulation. Through research will bedetermined price of implementation of proposed insulation options together with the costs of operation of the pension. The conclusion is to evaluate each proposed version of insulation of the building envelope associated with the economic return on investment...|$|R
40|$|Outer {{envelopes}} of {{neutron stars}} consist mostly of fully ionized, strongly coupled Coulomb plasmas characterized by typical densities 10 4 { 10 11 g cm 3 and temperatures T 10 4 { 10 9 K. Many neutron stars possess magnetic elds B 10 11 { 10 14 G. Recent theoretical advances allow one to calculate thermodynamic functions and electron transport coecients for such plasmas with an accuracy required for theoretical interpretation of observations. 1 Overview Envelopes of neutron stars (NSs) are divided {{in the inner}} and outer envelopes. Properties of the inner <b>envelopes</b> are <b>outlined</b> in a companion paper [1]. Here we focus on the outer ones, at typical densities 10 4 10 11 g cm 3 and temperatures T 10 4 10 9 K. These envelopes are relatively thin, but they aect signicantly NS evolution. In particular, they provide thermal insulation of stellar interiors. Bulk properties of the NS envelopes (pressure P, internal energy U) are determined mainly by dege [...] ...|$|R
40|$|Recent {{observational}} {{studies of}} intermediate- and high-mass star-forming regions at submillimeter and infrared wavelengths are reviewed, and chemical diagnostics {{of the different}} physical components associated with young stellar objects are summarized. Procedures for determining the temperature, density and abundance profiles in the <b>envelopes</b> are <b>outlined.</b> A detailed study {{of a set of}} infrared-bright massive young stars reveals systematic increases in the gas/solid ratios, the abundances of evaporated molecules, and the fraction of heated ices with increasing temperature. Since these diverse phenomena involve a range of temperatures from < 100 K to 1000 K, the enhanced temperatures must be communicated to both the inner and outer parts of the envelopes. This `global heating' plausibly results from the gradual dispersion of the envelopes with time. Similarities and differences with low-mass YSOs are discussed. The availability of accurate physical models will allow chemical models of ice evaporation followed by `hot core' chemistry to be tested in detail. Comment: 16 pages, 6 figures, to be published in IAU Symposium 197, Astrochemistry: from Molecular Clouds to Planetary Systems, eds. Y. C. Minh and E. F. van Dishoeck, ASP (uses newpasp. sty...|$|R
40|$|Recent {{observational}} {{studies of}} high- and low-mass YSOs at (sub) millimeter and infrared wavelengths are reviewed, and chemical diagnostics {{of the different}} physical components are summarized. Methods for determining the temperature, density and abundance profiles in the <b>envelopes</b> are <b>outlined,</b> and are illustrated for one high-mass and one low-mass YSO. The combination of (sub) millimeter and infrared data gives a nearly complete chemical inventory of the gas and solid state material. In both high- and low-mass YSOs, the chemical characteristics are dominated by freeze-out in the cold outer part of the envelope and evaporation of ices in the warm inner part. Abundance jumps of factors of ~ 100 in selected molecules {{are found in the}} warm gas for both types of objects. Potential differences include (i) the complex hot core chemistry, which has been observed so far only for high-mass YSOs; (ii) the high level of deuterium fractionation seen only in low-mass YSOs; (iii) the effects of internal or external UV and X-rays; (iv) the relative importance of shocks versus thermal heating of the envelope; and (v) the importance of geometrical effects. Comment: 13 pages, 9 figures; review for Univ. of Waterloo conference August 2002; needs sfchem. cls. To appear in: Chemistry as a Diagnostic of Star Formation, eds. C. L. Curry & M. Fich, NRC pres...|$|R
40|$|We {{discuss the}} various phases {{encountered}} during common-envelope (CE) evolution, {{starting with the}} criterion for dynamical mass transfer and the onset of a common-envelope phase, the main spiralin phase and ending with the final merging of the binary components (in cases where the envelope is not ejected earlier). We emphasize the different physical processes and uncertainties in these different phases and try to clarify the main issues involved in modeling these. Results of a systematic study of the quasi-static response of a common envelope to a spiralling-in binary {{shed some light on}} the various phases and the conditions under which CE ejection may be expected. It suggests that, when the CE is ejected, the process tends to be very efficient. However, a simple energy criterion for the ejection is generally not sufficient since in many cases the spiral-in process can be self-regulating and non-dynamic. The physics of the spiral-in is fundamentally different if the initial mass donor is a radiative star. In this case, it is possible that a CE system (contact system) may become semi-detached again without experiencing significant spiral-in, and the mass loss from the contact configuration is best described by a frictionally driven stellar wind. If the spiralling-in star is compact, CE ejection may also occur when it penetrates below the convective <b>envelope.</b> Finally we <b>outline</b> a scheme, combining both quasi-static and hydrodynamical approaches, by which it can be hoped that a detailed, semi-quantitative understanding of CE evolution may be achieved in the foreseeable future...|$|R
40|$|The U. S. Department of Energy (DOE) {{outlined}} {{a path to}} advance high-performance and zero-energy homes in its Building America research program (DOE 2008). That program - and other efforts in the Unites States {{over the last few}} years to tighten energy codes - follow closely the evolution of energy standard developments in Europe. That is, developmentsmoved fromconventional buildings to low-energy buildings, then to passive buildings, net zero, and recently even plus energy. The common denominator is low-load homes that require less energy fromthe start. Designing these homes requires specialized design tools to achieve targeted performance and quality assurance. The tools must enable the designer to meet the energy performance of the envelope and the minimizedmechanical system and - critically - to achieve proper hygrothermal design of building skins before the detailed construction documents phase. The hygrothermal component reduces the risk of potentially catastrophic design flaws, thereby reducing risk for designers, builders, and homeowners. The passive design approach offers a solid baseline for all low-load homes. The simplified static balance-based method has provided early adopters a useful tool. But it lacks the capacity to assess certain dynamic factors of the energy balance, such as transient effects that occur under real conditions - for example, thermal lag time and related overheating in summer or the hygrothermal performance of the building <b>envelope.</b> This paper <b>outlines</b> the incorporation of the balance-based method currently employed to design passive buildings into hygrothermal whole-building simulation software. A case study illustrates both methods as they are applied to an actual building. Additional results and insights from the dynamic building simulation are highlighted...|$|R
40|$|Fast {{reconnection}} {{of magnetic}} field in turbulent fluids allows magnetic field {{to change its}} topology and connections. As a result, the traditional concept of magnetic fields being frozen into the plasma is no longer applicable. The diffusion of plasmas and magnetic field is enabled by reconnection and therefore is termed "reconnection diffusion". We explore the consequences of reconnection diffusion for star formation. In the paper we explain the physics of reconnection diffusion both from macroscopic and microscopic points of view. We quantify the reconnection diffusion rate both for weak and strong MHD turbulence and {{address the problem of}} reconnection diffusion acting together with ambipolar diffusion. In addition, we provide a criterion for correctly representing the magnetic diffusivity in simulations of star formation. We show that the role of the plasma effects is limited to "breaking up lines" on small scales and does not affect the rate of reconnection diffusion. We address the existing observational results and demonstrate how reconnection diffusion can explain the puzzles presented by observations, in particular, the observed higher magnetization of cloud cores in comparison with the magnetization of <b>envelopes.</b> We also <b>outline</b> a possible set of observational tests of the reconnection diffusion concept and discuss how the application of the new concept changes our understanding of star formation and its numerical modeling. Finally, we outline the differences of the process of reconnection diffusion and the process of accumulation of matter along magnetic field lines that is frequently invoked to explain the results of numerical simulationsComment: 35 pages, 15 figures, extended after comments by the referee (submitted to Nonlin. Processes Geophys...|$|R
40|$|Optimal {{climate control}} for {{building}} systems is facilitated by linear, low-order {{models of the}} building and of its heat, ventilation and air conditioning systems (HVAC). The difficulty of obtaining such linear models greatly hampers the commercial implementation of these optimal controllers. This work focuses on obtaining a linear controller model of the building envelope, consisting of the walls, windows, floors, etc. but also the air present in the building. We present a work-intensive method on how to obtain the best possible linear model and we quantify its Np-steps ahead prediction performance. The obtained models can be used as benchmark for linear models obtained by for example system identification or for investigating the influence of the prediction performance on a model based controller. Furthermore, the method greatly automates the setting up of a model-based control method in a Modelica© simulation environment. The following paragraphs briefly pinpoint the non-linearities presents in the building <b>envelope</b> and <b>outline</b> the proposed method. The non-linearities in a building envelope are mainly due to the Stefan-Boltzmann law for long- and short-wave radiation where the radiative heat transfer of a body is proportional to its absolute temperature to the fourth power. Other non-linearities are the absorption and transmission of radiation through glazing and the convective heat transfer which is a non-linear function of the temperature. Finally, the partial differential equation of heat transport in a solid is three-dimensional and time dependent and its boundary conditions are non-linear. In this work, we built a detailed building envelope model in Modelica© using the IDEAS-library taking these non-linearities into account except for the heat transfer equation (a partial differential equation) which is simplified to ordinary differential equations with a finite number of parameters representing only one-dimensional heat transport. The model is based on the dimensions and the physical properties of a real building. The obtained model is then linearized around a chosen operating point using its equations implemented in Modelica© directly, resulting into a state-space model of hundreds of states, their initial value and their initial derivative. Its inputs are the convective, conductive and radiant heat supply by the HVAC system and its outputs can be any states of the original model. Finally, we apply a model reduction technique {{to reduce the number of}} states to 30 and we compute the Np-steps ahead prediction performance of the reduced-order model. Since prediction performance requires an observer for state estimation, state-estimators (Kalman Filter or Luenberger observer) are designed based on the reduced-order model obtained from the large-scale linear model. The obtained model is the best linear approximation of the non-linear model around the chosen working point as it is uniquely derived from the original equations. The model can be used to benchmark controller models obtained by system identification on the original model or it can be used directly into a model-based controller implementation. status: publishe...|$|R
40|$|Exposure assessment, {{which is}} an {{investigation}} of the extent of human exposure to a specific contaminant, must include estimates of the duration and frequency of exposure. For a groundwater system, the duration of exposure is controlled largely by the arrival time of the contaminant of concern at a drinking water well. This arrival time, which is normally estimated by using groundwater flow and transport models, can have a range of possible values due to the uncertainties that are typically present in real problems. Earlier arrival times generally represent low likelihood events, but {{play a crucial role in}} the decision-making process that must be conservative and precautionary, especially when evaluating the potential for adverse health impacts. Therefore, an emphasis must be placed on the accuracy of the leading tail region in the likelihood distribution of possible arrival times. To demonstrate an approach to quantify the uncertainty of arrival times, a real contaminant transport problem which involves TCE contamination due to releases from the Lockformer Company Facility in Lisle, Illinois is used. The approach used in this research consists of two major components: inverse modelling or parameter estimation, and uncertainty analysis. The parameter estimation process for this case study was selected based on insufficiencies in the model and observational data due to errors, biases, and limitations. A consideration of its purpose, which is to aid in characterising uncertainty, was also made in the process by including many possible variations in attempts to minimize assumptions. A preliminary investigation was conducted using a well-accepted parameter estimation method, PEST, and the corresponding findings were used to define characteristics of the parameter estimation process applied to this case study. Numerous objective functions, which include the well-known L 2 -estimator, robust estimators (L 1 -estimators and M-estimators), penalty functions, and deadzones, were incorporated in the parameter estimation process to treat specific insufficiencies. The concept of equifinality was adopted and multiple maximum likelihood parameter sets were accepted if pre-defined physical criteria were met. For each objective function, three procedures were implemented as a part of the parameter estimation approach for the given case study: a multistart procedure, a stochastic search using the Dynamically-Dimensioned Search (DDS), and a test for acceptance based on predefined physical criteria. The best performance in terms of the ability of parameter sets to satisfy the physical criteria was achieved using a Cauchy’s M-estimator that was modified for this study and designated as the LRS 1 M-estimator. Due to uncertainties, multiple parameter sets obtained with the LRS 1 M-estimator, the L 1 -estimator, and the L 2 -estimator are recommended for use in uncertainty analysis. Penalty functions had to be incorporated into the objective function definitions to generate a sufficient number of acceptable parameter sets; in contrast, deadzones proved to produce negligible benefits. The characteristics for parameter sets were examined in terms of frequency histograms and plots of parameter value versus objective function value to infer the nature of the likelihood distributions of parameters. The correlation structure was estimated using Pearson’s product-moment correlation coefficient. The parameters are generally distributed uniformly or appear to follow a random nature with few correlations in the parameter space that results after the implementation of the multistart procedure. The execution of the search procedure results in the introduction of many correlations and in parameter distributions that appear to follow lognormal, normal, or uniform distributions. The application of the physical criteria refines the parameter characteristics in the parameter space resulting from the search procedure by reducing anomalies. The combined effect of optimization and the application of the physical criteria performs the function of behavioural thresholds by removing parameter sets with high objective function values. Uncertainty analysis is performed with parameter sets obtained through two different sampling methodologies: the Monte Carlo sampling methodology, which randomly and independently samples from user-defined distributions, and the physically-based DDS-AU (P-DDS-AU) sampling methodology, which is developed based on the multiple parameter sets acquired during the parameter estimation process. Monte Carlo samples are found to be inadequate for uncertainty analysis of this case study due to its inability to find parameter sets that meet the predefined physical criteria. Successful results are achieved using the P-DDS-AU sampling methodology that inherently accounts for parameter correlations and does not require assumptions regarding parameter distributions. For the P-DDS-AU samples, uncertainty representation is performed using four definitions based on pseudo-likelihoods: two based on the Nash and Sutcliffe efficiency criterion, and two based on inverse error or residual variance. The definitions consist of shaping factors that strongly affect the resulting likelihood distribution. In addition, some definitions are affected by the objective function definition. Therefore, all variations are considered in the development of likelihood distribution envelopes, which are designed to maximize the amount of information available to decision-makers. The considerations that are important to the creation of an uncertainty <b>envelope</b> are <b>outlined</b> in this thesis. In general, greater uncertainty appears to be present at the tails of the distribution. For a refinement of the uncertainty envelopes, the application of additional physical criteria is recommended. The selection of likelihood and objective function definitions and their properties are made based on the needs of the problem; therefore, preliminary investigations should always be conducted to provide a basis for selecting appropriate methods and definitions. It is imperative to remember that the communication of assumptions and definitions used in both parameter estimation and uncertainty analysis is crucial in decision-making scenarios...|$|R

