423|19|Public
5000|$|Eye {{tracking}} experiments {{demonstrate that}} a large prevalence effect can occur across a group of participants with targets of similar appearance. In the experiment, participants had to discriminate the letter T from several similar-looking Ls. With a low prevalence, participants missed about 40 percent of the rare targets and responded more rapidly to target-absent trails {{than they did in}} high-prevalence conditions. (Previous work generally used simple stimuli.) Researchers discovered that when a target is rare, participants spend less time searching before concluding that it is absent (regardless of stimuli complexity). <b>Eye-tracking</b> <b>data</b> suggests that many errors at low prevalence were attributable to participants terminating the search without finding the target. Although cues suggested a higher target probability, searchers took longer to respond [...] "no" [...] (suggesting that the prevalence effect is ingrained).|$|E
40|$|Based on 2 ̆ 2 {{ground truth}} 2 ̆ 2 <b>eye-tracking</b> <b>data,</b> earlier {{research}} [1] shows that adding natural scene saliency (NSS) can improve an objective metric's performance in predicting perceived image quality. To include NSS in a real-world implementation of an objective metric, a computational model instead of <b>eye-tracking</b> <b>data</b> is needed. Existing models of visual saliency are generally {{designed for a}} specific domain, and so, not applicable to image quality prediction. In this paper, we propose {{an efficient model for}} NSS, inspired by findings from our eye-tracking studies. Experimental results show that the proposed model sufficiently captures the saliency of the <b>eye-tracking</b> <b>data,</b> and applying the model to objective image quality metrics enhances their performance {{in the same manner as}} when including <b>eye-tracking</b> <b>data.</b> © 2012 IEEE...|$|E
40|$|This data deposit {{contains}} {{data from}} the project “Loneliness and Hypervigilance to Social Cues in Females: An Eye-Tracking Study” The dataset contains the following data: -	File 0 :	Questionnaire data. Contains the questionnaires loneliness (UCLA), social anxiety (SPIN) and depression (CES-D), and information on {{who is in the}} lonely and nonlonely group (lonely_group). -	File 1 : <b>Eye-tracking</b> <b>data</b> from the first task -	File 2 : <b>Eye-tracking</b> <b>data</b> from the second task -	File 3 : <b>Eye-tracking</b> <b>data</b> from the third task -	File 4 : <b>Eye-tracking</b> <b>data</b> from the fourth task All eye-tracking files contain all fixations that were measured during the eye-tracking task. The process for aggregating these data is described in the paper “Loneliness and Hypervigilance to Social Cues in Females: An Eye-Tracking Study”. The syntaxes for creating these data can be obtained by contacting the first author of the study (Gerine Lodder) ...|$|E
30|$|One popular {{physiological}} {{method to}} assess <b>data</b> instrumentally is <b>eye-tracking.</b> Recorded <b>data</b> {{can be used}} to monitor and record user behaviour. The exact purpose of using eye-tracking should be noted: As a method of usability testing, information can be obtained about which items of a GUI are salient or not. However, often used “heat-maps” can be very misleading due to the aggregation of data.|$|R
40|$|This paper reports an {{exploratory}} {{study of the}} impact of post-editing and translation task execution in the Portuguese-Chinese language pair as performed by professional translators. <b>Eye-tracking</b> and key-logging <b>data</b> were used to assess temporal, technical and cognitive measures related to the understanding of two Portuguese source texts and the production of two Chinese target texts. The results point to no impact of task type on overall temporal effort, but indicate an impact on the cognitive effort related to source-text [...] ...|$|R
40|$|<b>Eye-tracking</b> video <b>data</b> {{that had}} been {{collected}} for a previous driving study was re-examined to analyze other aspects of driver eye movement. Drivers in the original study navigated a pre-set route at night while their eye movements were recorded using a head-mounted eye-tracking system. For the new analysis, eye movements from eleven of the previous study’s drivers were observed as they drove on selected segments of public roads. Four driving environments were examined: 1) a segment of highway without street lighting, 2) a segment of highway with street lighting, 3) the approach to a stop-sign controlled intersection without street lighting, and 4) the approach to signalized intersection with street lighting. Researchers evaluated the probabilities of drivers looking at specific areas of the road scene using binary logistic regression modeling. In the original study, drivers had been instructed to watch for specific signs {{on the right-hand side}} of the roadway, which likely affected their eye movement patterns. Despite this probable bias, drivers exhibited different eye movement patterns in the four driving environments examined. The probabilities of drivers looking at locations off the eye...|$|R
40|$|Unseen is Unsold: Assessing Visual Equity with Commercial <b>Eye-Tracking</b> <b>Data</b> In today’s {{cluttered}} retail environments, creating consumer {{pull through}} memory-based brand equity is not enough; marketers must also create “visual equity ” for their brands (i. e., incremental sales triggered by in-store visual attention). In this paper, {{we show that}} commercial <b>eye-tracking</b> <b>data,</b> analyzed using a simple decision-path model of visual attention and brand consideration, can separately measure memory-based and visual equity of brands displayed on a supermarket shelf. In the two product categories studied, juices and detergents, we find that in-store visual attention doubles on average the memory-based probability of consideration. Additionally, our empirical applications and normative analyses show how separating memory-based and visual equity can help improve managerial decisions about which brands to select for enhanced point-of-purchase marketing activities. Keywords: Point-of-purchase marketing, <b>eye-tracking</b> <b>data,</b> probability model, retailing, bran...|$|E
30|$|In the {{following}} paragraphs, {{we will go}} into detail for two major categories of dependent variables, questionnaires and indirect measures (<b>eye-tracking</b> <b>data</b> and interaction parameters).|$|E
40|$|Image quality {{assessment}} potentially {{benefits from the}} addition of visual attention. However, incorporating aspects of visual attention in image quality models {{by means of a}} perceptually optimized strategy is largely unexplored. Fundamental challenges, such as how visual attention is affected by the concurrence of visual signals and their distortions; whether visual attention affected by distortion or that driven by the original scene only should be included in an image quality model; and how to select visual attention models for the image quality application context, remain. To shed light on the above unsolved issues, designing and performing eye-tracking experiments are essential. Collecting <b>eye-tracking</b> <b>data</b> for the purpose of image quality study is so far confronted with a bias due to the involvement of stimulus repetition. In this paper, we propose a new experimental methodology to eliminate such inherent bias. This allows obtaining reliable <b>eye-tracking</b> <b>data</b> with a large degree of stimulus variability. In fact, we first conducted 5760 eye movement trials that included 160 human observers freely viewing 288 images of varying quality. We then made use of the resulting <b>eye-tracking</b> <b>data</b> to provide insights into the optimal use of visual attention in image quality research. The new <b>eye-tracking</b> <b>data</b> are made publicly available to the research community...|$|E
40|$|Mutual gaze is an {{important}} aspect of face-to-face communication that arises from the interaction of the gaze behavior of two individuals. In this dual <b>eye-tracking</b> study, gaze <b>data</b> was collected from human conversational pairs with the goal of gaining insight into what characteristics of the conversation partners influence this behavior. We investigate the link between personality, familiarity and mutual gaze. The results found indicate that mutual gaze behavior depends on the characteristics of both partners rather than on either individual considered in isolation. We discuss the implications of these findings for the design of socially appropriate gaze controllers for robots that interact with people. ?? 2012 IEEE...|$|R
40|$|Program {{comprehension}} is a {{very important}} activity during the development and the maintenance of programs. This activity has been actively studied in the past decades to present software engineers with the most accurate and—hopefully—most useful pieces of information on the organisation, algorithms, executions, evolution, and documentation of a program. Yet, only few work tried to understand concretely how software engineers obtain and use this information. Software engineers mainly use sight to obtain information about a program, usually from source code or class diagrams. Therefore, we use <b>eye-tracking</b> to collect <b>data</b> about the use of class diagrams by software engineers during program comprehension. We introduce a new visualisation technique to aggregate and to present the collected data. We also report the results and surprising insights gained from two case studies. ...|$|R
40|$|Eye-tracking {{systems have}} been widely used as a data {{collection}} method in the human–computer interaction research field. Eyetracking has typically been applied in stationary environments to evaluate the usability of desktop applications. In the mobile context, user studies with eye-tracking are far more infrequent. In this paper, we report our findings from user tests performed with an eye-tracking system in a forest environment. We present some of the most relevant issues that should be considered when planning a mobile study in the wild using <b>eye-tracking</b> as a <b>data</b> collection method. One of the most challenging finding was the difficulty in identifying where the user actually looked in the three-dimensional environment from the two-dimensional scene video. In a concrete matter that means it is difficult to assure whether the gaze is directed to an object short of the user or to a distant object that is partly occluded by the closer one...|$|R
40|$|In this paper, we {{describe}} how <b>eye-tracking</b> <b>data</b> {{can be used}} to predict students ’ learning scores. In a previous study, the first author collected <b>eye-tracking</b> <b>data</b> such as gaze position and pupil size while subjects either collaborated or worked independently on a problem. In this paper, we seek patterns in the <b>eye-tracking</b> <b>data</b> gathered during this experiment to accurately predict students ’ learning outcomes. We iteratively tried various machine-learning algorithms and found that a Support Vector Machine (SVM) with a quadratic kernel was able to correctly classify 93. 18 % of our test data using only aggregated eyetracking counts. We then repeated this approach under a generalized setting where we extracted features after applying k-means clustering to the gaze data. The accuracy improved to 97. 56 %. These results show how machine-learning techniques can be applied to make qualitative sense of educational datasets. 1...|$|E
40|$|Abstract. Two {{sources of}} weak {{biometric}} data are investigated {{for the development}} of user identification models. A probabilistic neural network model is created from keystroke digraph features extracted from raw typing data. A second model is developed from scan-path features extracted from raw <b>eye-tracking</b> <b>data.</b> A third model is created from a combination of features from the two biometric sources. Experimental results show that models based on keystroke biometric data perform very well, whereas the models involving the <b>eye-tracking</b> <b>data</b> are not as successful but encourage further study...|$|E
40|$|This work {{presents}} a semantic level no-reference image sharpness/blurriness metric {{under the guidance}} of top-down & bottom-up saliency map, which is learned based on <b>eye-tracking</b> <b>data</b> by SVM. Unlike existing metrics focused on measuring the blurriness in vision level, our metric more concerns about the image content and human's intention. We integrate visual features, center priority, and semantic meaning from tag information to learn a top-down & bottom-up saliency model based on the <b>eye-tracking</b> <b>data.</b> Empirical validations on standard dataset demonstrate the effectiveness of the proposed model and metric. Department of ComputingRefereed conference pape...|$|E
40|$|Prediction error ("surprise") {{affects the}} rate of learning: We learn more rapidly about cues for which we {{initially}} make incorrect predictions than Cues for Which our initial predictions are correct. The current studies employ electrophysiological measures to reveal early attentional differentiation of events that differ in their previous involvement in errors of predictive judgment. Error-related events attract more attention, as evidenced by features of event-related scalp potentials previously implicated in selective visual attention (selection negativity, augmented anterior N 1). The earliest differences detected occurred around [20 msec after stimulus onset, and distributed source localization (LORETA) indicated that the interior temporal regions were one source of the earliest differences. In addition, stimuli associated with the production of prediction errors show higher dwell times in an <b>eye-tracking</b> procedure. Our <b>data</b> {{support the view that}} early attentional processes play a role in human associative learning. This research was supported by a BBSRC grant 9 /S 17109, and EC Framework 6 project grant 516542 (NEST) to the first author...|$|R
40|$|The {{manner in}} which choice is framed {{influences}} individualsâ decision-making. This research examines the impact of different decision constructs on decision-making {{by focusing on the}} more problematic decision constructs: the un-selected and pre-selected optout. The study employs eye-tracking with cued retrospective think-aloud (RTA) to combine quantitative and qualitative <b>data.</b> <b>Eye-tracking</b> will determine how long a user focuses on a decision construct before taking action. Cued RTA where the user will be shown a playback of their interaction will be used to explore their attitudes towards a decision construct and identify problematic designs. This pilot begins the second of a three phase study, which ultimately aims to develop a research model containing the theoretical constructs along with hypothesized causal associations between the constructs to reveal the impact of measures such as decision construct type, default value type and question framing have on the perceived value of the website and loyalty intentions. Keywords: Framing of choice, decision constructs, consumer involvement, elaboration likelihood model, optionality presentation, opt-out, must-opt, eye-tracking...|$|R
40|$|The audience’s {{reluctance}} {{to wait for}} the international release of audiovisual products, coupled with the easy access to audiovisual material and subtitling tools on the Internet, has triggered an increase in the production and use of non-professional subtitling. However, up to now, we know little of how people receive the subtitles and how much they understand when watching products with non-professional subtitles. This paper presents the results of a study that explores the audience reception of subtitled TV series using professional and non-professional subtitling. Fifty-two participants were shown three excerpts from The Big Bang Theory with three subtitle versions: the professional version extracted from the Spanish DVD and two non-professional versions produced by two different non-professional subtitling communities. Data were collected through questionnaires, eye-tracking and interviews. The results show that non-professional subtitles do not necessarily affect the audience reception negatively. Further, both <b>eye-tracking</b> and self-reported <b>data</b> yielded interesting insights into audience’s reception. Based on the findings, it is possible {{to say that there are}} non-professional translations that are as good as their professional counterparts...|$|R
30|$|Participants searched through 22 (1 practice, 21 experimental) chest CT scans for nodules {{using the}} same {{procedure}} described for Experiment 1. No <b>eye-tracking</b> <b>data</b> were recorded in Experiment 2.|$|E
40|$|<b>Eye-tracking</b> <b>data</b> was {{gathered}} {{as part of}} a user and functional evaluation of the Europeana v 1. 0 prototype, to determine which areas of the interface screen are most heavily used and which areas attract users’ attention but are not effectively used in search. Outputs from <b>eye-tracking</b> <b>data</b> can offer insight into how advanced search functions can be made more intuitive for end users with differing interests and abilities, and can be used to inform continued interface development as digital libraries look to the future. Results led to recommendations for the future development of the Europeana digital library...|$|E
40|$|This paper {{outlines}} a {{new method}} for estimating the visual saliency different areas {{displayed on a}} web page. Latent Semantic Analysis {{is used to calculate}} Semantic Fields values for any (x, y) coordinate point on a web page based on the structure of that web page. These Semantic Field values were then used to predict <b>eye-tracking</b> <b>data</b> that was collected from 49 participants ’ goal-orient search tasks on a total of 1842 web pages. Semantic Field values were found to predict the participants ’ <b>eye-tracking</b> <b>data.</b> Keywords: LSA; Semantic Fields; LSA-SF; web pages; eyetracking; visual saliency...|$|E
40|$|Sudden {{temporal}} depth changes, such as {{cuts that}} are introduced by video edits, can significantly degrade {{the quality of}} stereoscopic content. Since usually not encountered in the real world, they are very challenging for the audience. This is because the eye vergence has to constantly adapt to new disparities in spite of conflicting accommodation requirements. Such rapid disparity changes may lead to confusion, reduced understanding of the scene, and overall attractiveness of the content. In most cases the problem cannot be solved by simply matching the depth around the transition, as this would require flattening the scene completely. To better understand this limitation of the human visual system, we {{conducted a series of}} <b>eye-tracking</b> experiments. The <b>data</b> obtained allowed us to derive and evaluate a model describing adaptation of vergence to disparity changes on a stereoscopic display. Besides computing user-specific models, we also estimated parameters of an average observer model. This enables a range of strategies for minimizing the adaptation time in the audience. National Science Foundation (U. S.) (IIS- 1111415) National Science Foundation (U. S.) (IIS- 1116296...|$|R
40|$|The {{purpose of}} this report is to propose {{business}} solutions for a start-up firm called Realeyes that provides eye-tracking services in UK, Europe and United States. This report makes use of the research and interview findings from the group project that involved developing an international marketing plan for Realeyes to launch in Australia. However, the recommendations in this report have been made keeping in mind Realeyes’ global operations. After having laid the foundation with the literature review, the section after that provides {{a detailed description of}} Realeyes’ present service model consisting of mainly four stages: designing an <b>eye-tracking</b> study, <b>data</b> collection, data analysis and lastly, delivering results to clients. This is followed by the business solutions section. In {{the first half of this}} section, the report explains why increasingly firms are looking to become solution providers. It then explains how Realeyes can look to add value to the businesses of its clients by becoming solution providers. This section also provides recommendations for improving customer service processes and grooming the organisation for providing solutions. The section on customisation comes after business solutions. It starts off by explaining the importance of mass customisation and its benefits. The report then discusses segment-based mass customisation. Subsequently, the shift from mass customisation to customerisation is discussed. After this, there is an in-depth analysis of the need for Realeyes to customerise its services. This is followed by recommendations for Realeyes to customerise its services by providing its clients a wide array of selection parameters to design their study. The next section focuses on business integration. It not only explains the need for born global firms like Realeyes to look at business integration for sustained growth but also provides recommendations for Realeyes to integrate its business processes. Lastly, the key findings and recommendations of the report are summarised in the conclusion...|$|R
40|$|This {{exploratory}} {{case study}} aimed at investigating learner profiles when participants are studying, self-reporting, restudying content and answering {{questions related to}} the division theorem in mathematics. It includes surveys aiming to measure participants’ epistemological beliefs, metacognitive strategies and the levels of mathematics anxiety; behavioral data including audio-visuals and screen capture embedded with <b>eye-tracking,</b> and physiological <b>data</b> including heart, respiration and eye blink rates. It uses ‘learner profiling framework’ built on previous literature and defined with a new perspective. The data are analyzed using mixed research methodology cross validating self-report, behavioral and physiological data. The results from four participants provide contributions to the literature in four aspects. First, learner profiling framework offers a new methodology to educational research with numerous benefits. Second, CUR (Calculation-Understanding-Reasoning) framework offers {{a new way of}} categorizing mathematical cognition and corresponding content. Third, qualitative approach in investigating learner motivations indicates motivational constructs are much more nuanced than previously thought. Fourth, single case approach for studying learner behavior and physiology provides successful links to underlying cognitive and affective processes. The investigations are followed by learner profiles that involve assessments from teacher’s perspective and recommendations for future work...|$|R
40|$|In this research, we outline a user {{modeling}} framework that uses both unsupervised and {{supervised machine learning}} {{in order to reduce}} development costs of building user models, and facilitate transferability. We apply the framework to model student learning during interaction with the Adaptive Coach for Exploration (ACE) learning environment (using both interface and <b>eye-tracking</b> <b>data).</b> In addition to demonstrating framework effectiveness, we also compare results from previous research on applying the framework to a different learning environment and data type. Our results also confirm previous research on the value of using <b>eye-tracking</b> <b>data</b> to assess student learning. ACM Classification: I 5. 5 [Pattern Recognition]: Implementation. -Interactive systems...|$|E
40|$|Understanding {{bottom-up}} and top-down visual attention mechanisms {{related to}} visual quality perception can be greatly beneficial {{for the design}} of effective objective quality metrics. Subjective studies based on eye-movement tracking have been recently published that try to get more insight in these interactions. However, it is still not easy to find coherence across their results, also due to the different methodologies adopted to analyze <b>eye-tracking</b> <b>data.</b> In this paper we propose a robust methodology to measure differences between <b>eye-tracking</b> <b>data</b> collected under different experimental conditions. The proposed method takes into account inter-observer variability and content effects, producing results that give an accurate insight in attention variations...|$|E
40|$|We present research-in-progress on an {{attentive}} in-store mobile {{recommender system}} that is integrated into the userâs glasses and worn during purchase decisions. The system makes use of the Attentive Mobile Interactive Cognitive Assistant (AMICA) platform prototype designed as a ubiquitous technology that supports people in their everyday-life. This paper gives a short overview of the technology and presents results from a pre-study in which we collected real-life <b>eye-tracking</b> <b>data</b> during decision processes in a supermarket. The data helps us to characterize and identify the different decision contexts based on differences in the observed attentional processes. AMICA provides <b>eye-tracking</b> <b>data</b> {{that can be used}} to classify decision-making behavior in real-time to make a recommendation process context-aware. ...|$|E
40|$|Visual {{problem solving}} with {{multiple}} representations {{is a critical}} component of chemistry learning and communication. Understanding how students comprehend and utilize visual representations is key to improving chemistry education, and a multimodal approach to understanding how students tackle visual stoichiometry problems offers insight into misconceptions and difficulties that they face. A mixed methods approach was used, employing multimodal <b>data</b> (<b>eye-tracking,</b> drawings, oral responses, and visual problem solving scores) to study participant interaction with representations and develop a framework for understanding college general chemistry students' metavisualization skills. Student performance during a PhET interactive simulation chemistry game was investigated using eye-tracking and qualitative analyses of a talk aloud protocol to isolate key mental blocks contributing to the participants' misconceptions. Cluster analysis and principal component analysis of gaze patterns revealed that participants follow coherent patterns when solving visual problems with multiple representations with respect to the equation, submicroscopic representations, and numbers provided in the question. Participants were divided into high and low score groups based on quantitative analysis of responses to key questions associated with the conservation of mass in stoichiometric analysis and the groups were further investigated using the of multimodal responses from individuals within each group. Eye-tracking and cluster analysis were found to be valuable tools for framing how students solve chemistry problems with multiple representations...|$|R
40|$|Air {{travel is}} {{expected}} to grow around 5 percent per year over the next 20 years, resulting in an estimated {{increase in the number of}} airplanes in service to around 35. 000 in 2032. Therefore, aviation stakeholders, through programs like SESAR in Europe and NextGen in the US are developing ways to create additional airspace capacity and decrease delays both on the ground and in the air. One way to reduce runway occupancy time could be to allow simultaneous independent departures from parallel runways under instrument flight rules in instrument weather conditions. Within the scope of ACROSS, a project co-funded by the European Commission, DLR is working on additional head-up-display symbology to support the pilot during take-off by increasing situation awareness and reducing workload, while at the same time enhancing safety and performance. In addition to the standard symbology, the new layout includes information about traffic in the vicinity, a no-transgression zone, obstacles and runway limits. Human Factors principles were the main driver of all evaluations performed so far. The display was assessed using performance, <b>eye-tracking</b> and subjective <b>data</b> in the form of questionnaires. The evaluations were successful. Pilots performed the low visibility take-off without major problems. The pilots were in general very supportive and provided important feedback. This will be used to further improve the display to support the pilots managing workload during take-off...|$|R
40|$|Eye-tracking {{was used}} to examine how younger and older adults use {{syntactic}} and semantic information to disambiguate noun/verb (NV) homographs (e. g., park). We find that young adults exhibit inflated first fixations to NV-homographs when only syntactic cues are available for disambiguation (i. e., in syntactic prose). This effect is eliminated with the addition of disambiguating semantic information. Older adults (60 +) as a group fail to show the first fixation effect in syntactic prose; they instead reread NV homographs longer. This pattern mirrors that in prior event-related potential work (Lee & Federmeier, 2009, 2011), which reported a sustained frontal negativity to NV-homographs in syntactic prose for young adults, which was eliminated by semantic constraints. The frontal negativity was not observed in older adults as a group, although older adults with high verbal fluency showed the young-like pattern. Analyses of individual differences in eye-tracking patterns revealed a similar effect of verbal fluency in both young and older adults: high verbal fluency groups of both ages show larger first fixation effects, while low verbal fluency groups show larger downstream costs (rereading and/or refixating NV homographs). Jointly, the <b>eye-tracking</b> and ERP <b>data</b> suggest that effortful meaning selection recruits frontal brain areas important for suppressing contextually inappropriate meanings, which also slows eye movements. Efficacy of fronto-temporal circuitry, as captured by verbal fluency, predicts the success of engaging these mechanisms in both young and older adults. Failure to recruit these processes requires compensatory rereading or leads to comprehension failures (Lee & Federmeier, in press) ...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis supports the Army's mission {{to establish a}} measure for cognitive agility in soldiers. It examines attention-allocation patterns as quantified by <b>eye-tracking</b> <b>data</b> collected while subjects played a military-relevant cognitive agility computer game (Make Goal), to determine whether certain patterns are associated with effective performance. It also investigates the effects of stress on cognitive agility as measured by attention allocation. Methods: Forty military officers {{were randomly assigned to}} a stress or control group. Stress level was manipulated by timed turns and experimenter behavior. Results: <b>Eye-tracking</b> <b>data</b> was analyzed in terms of regions of interest on which subjects focused their cognitive workload. Results were analyzed by stress and control group and top and bottom ten performers. The stress and control groups showed similar attention-allocation patterns. The high performers attended more to the important information and made more optimal selections than poor performers. Discussion: Results are discussed {{in the context of the}} Yerkes-Dodson stress model. <b>Eye-tracking</b> <b>data</b> revealed attention-allocation patterns associated with higher performance. In order to better detect the impact of stress on Cognitive Agility, an experiment that includes a wider range of stress levels is needed. Lieutenant, United States Nav...|$|E
40|$|Analysis of eye {{movements}} {{recorded with}} a mobile eye-tracker is difficult since the <b>eye-tracking</b> <b>data</b> are severely affected by simultaneous head and body movements. Automatic analysis methods developed for remote-, and tower-mounted eye-trackers {{do not take}} this into account and are therefore not suitable to use for data where also head- and body movements are present. As a result, data recorded with a mobile eye-tracker are often analyzed manually. In this work, we investigate how simultaneous recordings of eye- and head movements can be employed to isolate {{the motion of the}} eye in the <b>eye-tracking</b> <b>data.</b> We recorded eye-in-head movements with a mobile eye-tracker and head movements with an Inertial Measurement Unit (IMU). Preliminary results show that by compensating the <b>eye-tracking</b> <b>data</b> with the estimated head orientation, the standard deviation of the data during vestibular-ocular reflex (VOR) eye movements, was reduced from 8. 0 to 0. 9 in the vertical direction and from 12. 9 to 0. 6 in the horizontal direction. This suggests that a head compensation algorithm based on IMU data can be used to isolate the movements of the eye and therefore simplify the analysis of data recorded using a mobile eye-tracker...|$|E
40|$|This {{doctoral}} dissertation applies user experience and complex systems theory, combining <b>eye-tracking</b> <b>data</b> with verbal and observational data from user test instances, {{to study the}} effectiveness of metadata records that accompany digital primary source objects available on The Portal to Texas History...|$|E
3000|$|In short, a {{large amount}} of {{research}} works have studied the human behavior while driving, using different tools to capture and extract the <b>data</b> (<b>eye-tracking</b> systems, camera with videos processing and machine learning tools, etc.); these data were processed to extract various features such as PERCLOS (Bergasa and Nuevo 2006; Ji et al. 2004; Jin et al. 2013; Kong et al. 2015; Friedrichs and Yang 2010; Darshana et al. 2015; Sun et al. 2017) and blink frequency (Bergasa and Nuevo 2006; Jin et al. 2013; Friedrichs and Yang 2010; Sun et al. 2017, 2015). (More details are giving in [...] "Driver's behavior features extraction" [...] section). Finally, regarding the driver-state identification, three main approaches have been adopted: threshold and probabilistic (Ji et al. 2004), expert system (Azim et al. 2014; Bergasa and Nuevo 2006), and classification (Ji et al. 2004; Jin et al. 2013; Kong et al. 2015; Friedrichs and Yang 2010; Miyaji and Kawanaka 2010; Zhao et al. 2018). In this work, a literature study revealed that works use different features, chosen randomly or according to an unjustified cause. In addition, these works give different definitions to the same feature, for example, Kong et al. (2015) defines the PERCLOS as being percentage of times in 30 s, when the eye is closed at 30 %; while others define it as the proportion of time in 3 min, when the eyes are at least 80 % closed. Thus, we gather a list of all features related to fatigue, this list included the most used features in the literature and which are sorted by FS methods, according to their order of importance (relevance and non-redundant). It is validated on a set of 66 senior drivers and the database was collected by the eye-tracking system ‘seeing machines’ FaceLAB, while above research works used small databases composed of at least 30 real drivers.|$|R
40|$|In my {{doctoral}} research I studied {{how different}} types of second language grammar input are processed by learners and how their working memory capacity influences input processing. There were four different input conditions: two explicit and two implicit and 100 second language learners of English in Sri Lanka participated in this study. The study used a pre/post test design, four working memory tests and <b>eye-tracking</b> to collect <b>data</b> on how learners {{pay attention to the}} target construction. The findings highlighted that explicit input techniques are more beneficial than the implicit input techniques when acquiring novel grammatical constructions. Moreover, the results indicated that working memory capacity was very strongly related to how language learners process second language input as learners with high working memory had clear advantages in any instructional condition. These findings are directly relevant in teaching a second language to learners with dyslexia, who tend to have shorter working memory capacity and process novel language input in different ways. In this talk, I will discuss these current research findings related to dyslexia and language learning and inclusive practices that different countries have implemented to facilitate such learners in the language classroom. Further to this, I will present a teacher training project that has been designed to train English language teacher trainers in Sri Lanka on identification and inclusive practices of dyslexic learners in English classroom. The project will fund to train ca. 100 English language teacher trainers all over the country. They will be exposed to free professional development programmes and free resources as well. The project will also attempt to raise awareness among policy planners and language testing body in Sri Lanka of the importance of incorporating inclusive practices in policy/curriculum design and high-stakes exams...|$|R
40|$|The aim of {{this study}} was to shed light on the consumers’ {{decision}} making processes in an online environment. The vast amount of information found online and the presence of online peer recommendations has shaped the purchase decision making environment – making it more simple in some situations, more complex in others. This study answers to the need for more research on consumers’ cognitive processes when making purchase decisions, the influence of website design factors towards consumer decision making as well as the social presence of others in online environments. Previously little research has been done on the effects of product ratings toward consumer attention through eye-tracking methodology. Eye-tracking methodology was chosen to overcome the limitations created by using solely self-report methods and projective techniques, such as surveys and interviews, in order to better understand the mental constructs and the behavior of a consumer. A 2 (decision complexity) X 2 (quality of product rating) between-subjects experiment design was employed for this study to assess whether consumers would try to ease cognitively demanding purchase decision making tasks through the use of social heuristics. The data (N= 25) was collected through assessing the eye movements of multiple subjects. From the <b>data</b> <b>eye-tracking</b> parameters such as fixation duration, dwell time and the time to first fixation were analyzed through statistical tests. Supporting data was collected through asking the subjects for a brief verbalization of their thought process during the experiment. The results show a significant combined effect of task complexity and product ratings towards the decision making time. No significant combined effect of task complexity and product ratings was found for fixation duration, dwell time and the time to first fixation on the area of interest. A significant main effect was discovered between task complexity and dwell time percentage. Good product ratings were perceived faster than bad product ratings, which as a finding is in line with earlier research. Consumers also seem to be prone to using social heuristics, such as peer-made product ratings, to conform with others during the purchase decision making process, even if the purchase decision is seemingly simple...|$|R
