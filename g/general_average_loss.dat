1|4247|Public
40|$|Nonasymptotic risk bounds are {{provided}} for maximum likelihood-type isotonic estimators {{of an unknown}} nondecreasing regression function, with <b>general</b> <b>average</b> <b>loss</b> at design points. These bounds are optimal up to scale constants, and they imply uniform n − 1 / 3 -consistency of the ℓp risk for unknown regression functions of uniformly bounded variation, under mild assumptions on the joint probability distribution of the data, with possibly dependent observations...|$|E
40|$|Abstract. We {{consider}} {{a model of}} correlated defaults in which the default times of multiple entities depend not only on a common and specific factors, {{but also on the}} extent of past defaults in the market, via the <b>average</b> <b>loss</b> process, including the average number of defaults as a special case. The paper characterizes the <b>average</b> <b>loss</b> process when the number of entities becomes large, showing that under some monotonicity conditions the limiting <b>average</b> <b>loss</b> process can be determined by a fixed point problem. We also show that the Law of Large Numbers holds under certain compatibility conditions...|$|R
5000|$|Despite {{advances}} in maritime transport technology, <b>general</b> <b>average</b> continues {{to come into}} play. The M/V MSC Sabrina declared <b>general</b> <b>average</b> in effect after grounding in the Saint Lawrence river on [...] The owners of the Hanjin Osaka declared <b>general</b> <b>average</b> following {{an explosion in the}} ship's engine room on [...]|$|R
5000|$|The <b>average</b> <b>loss</b> of life-expectancy, LLE, in the {{population}} is defined by: ...|$|R
5000|$|Thus, the ETL can be {{interpreted}} as the <b>average</b> <b>loss</b> beyond VaR: ...|$|R
50|$|The overall <b>average</b> <b>loss</b> of {{the gears}} is about 1&thinsp;%-5&thinsp;%, {{comparable}} to a derailleur.|$|R
50|$|One study {{commissioned}} in the UK {{estimated the}} <b>average</b> <b>loss</b> rate of libraries to theft at 5.3%.|$|R
5000|$|Expectancy = (Trading system Winning {{probability}} * Average Win) - (Trading system losing probability * <b>Average</b> <b>Loss)</b> ...|$|R
5000|$|The first {{codification}} of <b>general</b> <b>average</b> was the York Antwerp Rules of 1890. American companies {{accepted it}} in 1949. <b>General</b> <b>average</b> requires three elements which are clearly stated by Justice Grier in Barnard v. Adams: ...|$|R
50|$|In January, 6 U-boats were {{destroyed}} in the theatre; this also became the <b>average</b> <b>loss</b> for the year.|$|R
5000|$|Choose the {{decision}} rule {{with the lowest}} <b>average</b> <b>loss</b> (i.e. minimize the expected value of the loss function): ...|$|R
50|$|<b>General</b> <b>average</b> not {{lower than}} 85%.|$|R
50|$|The GA {{indicates}} the <b>General</b> <b>Average.</b>|$|R
5000|$|<b>Average</b> <b>loss</b> {{of energy}} of an atom moving through a dense medium gives idea on {{stopping}} cross section and capability of depth perception.|$|R
50|$|Voluntary sacrifices and {{extraordinary}} expenses incurred {{for the common}} safety are called <b>general</b> <b>average</b> sacrifices and expenses. These are made good to the party who has made the sacrifice or incurred the expense by a <b>general</b> <b>average</b> contribution, which is recoverable from {{the owners of the}} property saved in proportion to its value. In other words, each contributes according to the benefit received. The law that regulates the rights of the parties in regard to such contribution is called the law of <b>general</b> <b>average.</b>|$|R
40|$|The {{selection}} of controlled variables (CVs) from available measurements through exhaustive search is computationally forbidding for large-scale processes. We have recently proposed novel bidirectional {{branch and bound}} (B- 3) approaches for CV selection using the minimum singular value (MSV) rule and the local worst- case loss criterion {{in the framework of}} self-optimizing control. However, the MSV rule is approximate and worst-case scenario may not occur frequently in practice. Thus, CV selection by minimizing local <b>average</b> <b>loss</b> can be deemed as most reliable. In this work, the B- 3 approach is extended to CV selection based on local <b>average</b> <b>loss</b> metric. Lower bounds on local <b>average</b> <b>loss</b> and, fast pruning and branching algorithms are derived for the efficient B- 3 algorithm. Random matrices and binary distillation column case study are used to demonstrate the computational efficiency of the proposed method...|$|R
30|$|Thirdly, even {{profitable}} {{strategies such as}} MACD and STOCH-D {{could not}} reliably predict subsequent market directions as their profitable trades are usually less than fifty percent of total number of trades. They make money from having a higher average profit from profitable trades than an <b>average</b> <b>loss</b> from unprofitable ones. Interestingly, optimized parameters do not improve the odds of profitable trades. Our results {{support the idea that}} profitable strategies make money not from outguessing market directions, but from maximizing average profits and minimizing <b>average</b> <b>losses.</b>|$|R
40|$|This paper {{presents}} a comparative analysis of various interior permanent magnet (IPM) machines and a surface permanent magnet (SPM) machine {{designed for a}} commuter train. The different IPM machines are characterized by a different rotor geometry and volume of permanent magnets. The traction requirements fix the maximum machine volume and the back electromotive force at uncontrolled generator operations. The comparison is extended considering the drive performance. Therefore, considering a standard load cycle the different machines and drives are compared in terms of torque capability at reduced voltage, machine <b>average</b> <b>losses</b> and power converter <b>average</b> <b>losses...</b>|$|R
40|$|This paper {{discusses}} {{the problem of}} designing a new variable sampling plan. Suppose that the lot quality characteristic obeys an exponential distribution. Adopting Taguchi's loss function, {{the objective is to}} design a plan under which the producer's risk of rejecting a lot that has a specified <b>average</b> <b>loss</b> per item is no greater than alpha, and the consumer's risk of accepting a lot that has a specified <b>average</b> <b>loss</b> per item is no greater than beta. The method of designing this plan is an extension of the method used by Derman and Ross. ...|$|R
40|$|Appendices, p. [419]- 853) [...] A-B, AA-BB. Laws of <b>general</b> <b>average</b> {{in force}} in the various countries. [...] CC. The International <b>general</b> <b>average</b> congresses and York-Antwerp rules. [...] DD. Draft {{international}} code relating to <b>general</b> <b>average.</b> [...] EE. Rules of practice adopted by the Association of average adjusters up to 1922. [...] FF. Warehousing clauses of the Merchant shipping act, 1894, and Mersey docks consolidation act, 1858. [...] GG. Lloyd's average bond. [...] HH. Rules of practice of the Association of average adjusters of the United States. (Effective on July 6 th, 1922) Mode of access: Internet...|$|R
50|$|The <b>General</b> <b>Average</b> was of 37 points, being {{satisfactory}} for the schedule.|$|R
30|$|Ireland {{is one of}} the {{countries}} most severely affected by the Great Recession. National income fell by more than 10 per cent between 2007 and 2012, {{as a result of the}} bursting of a remarkable property bubble, an exceptionally severe banking crisis, and deep fiscal adjustment. This paper examines the income distribution consequences of the recession, and identifies the impact of a broad range of austerity policies on the income distribution. The overall fall in income was just under 8 per cent between 2008 and 2011, but the greatest losses were strongly concentrated on the bottom and top deciles. Tax, welfare and public sector pay changes over the 2008 to 2011 period gave rise to lower than <b>average</b> <b>losses</b> for the bottom decile. Thus, the larger than <b>average</b> <b>losses</b> observed overall are not due to these policy changes; instead, the main driving factors are the direct effects of the recession itself. Policy changes do contribute to the larger than <b>average</b> <b>losses</b> at high income levels.|$|R
40|$|This paper {{reports the}} results of {{experiments}} carried out to establish losses that occur at the different stages in the processing of cassava into gari at both local and improved technology centres. An <b>average</b> <b>loss</b> of 6. 1 % occurred during cassava processing into gari at the peeling stage for local and 4. 7 % at improved technology centres. The grating process recorded <b>average</b> <b>losses</b> of 5. 9 % at both local and improved technology centers. The losses at the dewatering stage ranges from 3. 0 % for local and 5. 6 % for improved technology centres. The sifting process recorded losses of 4. 3 and 5. 4 % for local and improved technology centres respectively. The total <b>average</b> <b>loss</b> in cassava processing into gari for local centres was 19. 3 % while that for improved technology centres 21. 5 %. A garification rate of 0. 32 and 0. 33 was established for local and improved technology centres respectively...|$|R
5000|$|Marine {{damage is}} either {{particular}} average, which is borne {{only by the}} owner of the damaged property, or <b>general</b> <b>average,</b> where the owner can claim a proportional contribution from all the parties to the marine venture. The type of calculations used in adjusting <b>general</b> <b>average</b> gave rise to the use of [...] "average" [...] to mean [...] "arithmetic mean".|$|R
30|$|<b>Average</b> packet <b>loss</b> ratio. The <b>average</b> packet <b>loss</b> {{ratio is}} the number of packets {{received}} unsuccessfully by all receivers versus the total number of packets sent out by all senders.|$|R
5000|$|... $500.00 for the [...] "best <b>general</b> <b>average</b> in {{landing at}} a given point." ...|$|R
5000|$|... $7,500.00 for [...] "the machine {{making the}} best <b>general</b> <b>average</b> in all events." ...|$|R
50|$|In the 1997-1998 National Secondary Assessment Test, QCA carded a <b>general</b> <b>average</b> of 98.9%.|$|R
50|$|According to the National Fire Protection Association (NFPA), {{fires in}} hotels with {{sprinklers}} averaged 78% less damage than fires in hotels without them (1983-1987). The NFPA says the <b>average</b> <b>loss</b> per fire in buildings with sprinklers was $2,300, {{compared to an}} <b>average</b> <b>loss</b> of $10,300 in unsprinklered buildings. The NFPA adds {{that there is no}} record of a fatality in a fully sprinklered building outside the point of fire origin. However, in a purely economic comparison, this is not a complete picture; the total costs of fitting, and the costs arising from non-fire triggered release must be factored.|$|R
3000|$|..., can be obtained. This <b>average</b> path <b>loss</b> {{reflects}} {{the distance between}} the FBS and the MUE. The <b>average</b> DL path <b>loss,</b> PL [...]...|$|R
40|$|This paper {{focuses on}} a version of {{sequential}} mastery testing (i. e., classifying students as a master/nonmaster or continuing testing and administering another item or testlet) in which response behavior is modeled by a multidimensional item response theory (IRT) model. First, a general theoretical framework is outlined {{that is based on}} a combination of Bayesian sequential decision theory and multidimensional IRT. Then how multidimensional IRT-based sequential master testing can be generalized to adaptive item- and testlet-selection rules is discussed for the case where the choice of the next item or testlet to be administered is optimized using the information from previous responses. Both compensatory and conjunctive loss structures are considered. Simulation studies are used to evaluate: (1) the performance, in terms of <b>average</b> <b>loss,</b> of multidimensional IRT-based sequential mastery testing {{as a function of the}} number of items administered per testing stage; (2) the effects on <b>average</b> <b>loss</b> when turning the sequential procedure into an adaptive sequential procedure; and (3) the impact on <b>average</b> <b>loss</b> when the multidimensional structure is ignored and a unidimensional IRT model is used in the decision procedure...|$|R
5000|$|Must have a <b>general</b> <b>average</b> of not below 78% {{to be able}} to {{take the}} Diagnostic Test.|$|R
40|$|This paper {{presents}} QoS control enhanced architecture for VoIP networks. In this architecture we {{use both}} the probe flow delay and <b>average</b> <b>loss</b> rate measurement systems. First we apply the probability-based EMBAC scheme on our delay system. Then we propose a new probability-based EMBAC {{with a severe}} congestion consideration scheme to improve the admission control scheme in both measurement systems. We compare {{the performance of the}} enhanced systems in terms of blocking probability under the same condition of achieving <b>average</b> packet <b>loss</b> rate no greater than the certain target by setting an appropriate admission threshold in each system under each scenario. In this study, it is shown through simulations that the enhanced systems proposed in this paper can be a powerful and reliable EMBAC tool for VoIP networks with minimum blocking probability and minimum <b>average</b> <b>loss</b> rates. I...|$|R
50|$|Example 1. If {{we believe}} our <b>average</b> <b>loss</b> on the worst 5% of the {{possible}} outcomes for our portfolio is EUR 1000, then we could say our expected shortfall is EUR 1000 for the 5% tail.|$|R
5000|$|The eight bar {{subjects}} are separately graded. Each subject {{contributes to the}} <b>general</b> <b>average</b> in the following proportion: ...|$|R
30|$|This {{number is}} {{the ratio of}} an average profit from {{profitable}} trades over an <b>average</b> <b>loss</b> from unprofitable ones. A good trading system would let the profit run while cutting losses quickly, resulting in a high ratio.|$|R
