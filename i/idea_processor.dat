3|15|Public
40|$|We have {{developed}} a new <b>idea</b> <b>processor,</b> called modified Mandel-Art, in which a user can communicate with the system by using eye movement, finger and hand motion and voice. By using this cognitive <b>idea</b> <b>processor,</b> human associative thinking and especially, problem solving, is accelerated. This type of <b>idea</b> <b>processor</b> may lead to innovating the educational style via the computer...|$|E
40|$|Idea {{processors}} are {{computer programs}} that can aid the user in creating outlines {{by allowing the}} user to move, reorder, renumber, expand upon, or delete entries with a push of a button. The question is whether these programs are useful and should be offered to students. Theoretically, an <b>idea</b> <b>processor</b> prioritizes ideas by placing them in a hierarchy. Unf'rtunately, the <b>idea</b> <b>processor</b> does not really set priorities; it attaches labels indicating priorities that the writer has set. The confusion is between labels or symbols (which are on paper or in the computer) and ideas (which are in the head). The basic limitations of the <b>idea</b> <b>processor</b> are that (1) the meaning of an item on a list is not stable, and (2) the appropriate symbol for the meaning must change when {{any of the things}} the item depends on change. Three things need to be adjusted when a program command is used: the idea of what the item means, the idea of wha...|$|E
40|$|The {{purpose of}} the project is to show the {{susceptibility}} of students and staff of Hwa Chong Junior College to contracting SARS in the school compound. This is done by simulating the spreading of infection in the school compound using a computer programme called Axon <b>Idea</b> <b>Processor.</b> The simulation is loosely based on existing infection models, but the results are different in that they show how the extent of infection {{is affected by the}} frequency of temperature checks (speediness of detection) and the degree and duration of contact between people in the school. In conclusion, the simulation results are useful for the planning and designing of schools in future, such that minimal spreading of viruses occur...|$|E
5000|$|Companies that {{pioneered the}} <b>idea</b> of media <b>processors</b> (and created the {{marketing}} term of media processor) included: ...|$|R
40|$|Noting {{that recent}} {{developments}} in computer technology facilitate the integration of media in literacy development, this paper reviews 18 items of courseware designed to promote literacy development within a whole language framework. The reviews are divided into four sections dealing with the following topics: (1) <b>idea</b> <b>processors</b> and the contributions of graphic organizers to information processing in the content areas; (2) media integration systems and the capacity to-ynthesize interdisciplinary content; (3) desktop publishing as a veh. s. cle for producing sophisticated report formats; and (4) courseware in reading and literature designed to promote integrated literacy development. The paper concludes that these programs are useful both across the curriculum to facilitate information processing and in conjunction with thematic, literature-based, or content area units of study t...|$|R
40|$|We {{propose a}} “layered {{structured}} network diagram,” {{which consists of}} layers of time differences. We have implemented a tool called “NeL 2 ” for handling layered structured network diagrams. Layered structured network diagrams have multiple accumulated layers and are not single diagrams. Using this layered structure, time differences can be included in one diagram. In addition, various type of information, such as the overall tendency in a diagram during a specific period of time, can be visualized. We used layered structured network diagrams to show the co-authorship network of academic literature. Changes in the co-authorship network become visible using the layered structured network diagram. We can read various information such as changes of active research communities and other phenomena. In addition to co-authorship networks, the layered structured network diagram {{can be applied to}} the visualization of various data, such as <b>idea</b> <b>processors,</b> changes of Web sites, and others...|$|R
40|$|Processor designs {{specialized}} for functional languages received {{very little}} {{attention in the}} past 20 years. The potential for exploiting more parallelism and the developments in hardware technology, ask for renewed investigation of this topic. In this paper, we use <b>ideas</b> from modern <b>processor</b> architectures {{and the state of}} the art in compilation,to guide the design of our processor, the PilGRIM. We define a high-level instruction set for lazy functional languages and show the processor architecture, that can efficiently execute these instructions...|$|R
40|$|This {{material}} {{is presented to}} ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected {{to adhere to the}} terms and constraints invoked by each author's copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. [...] Copyright IEEE. Personal use of this {{material is}} permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. During the last decade RISC <b>ideas</b> on <b>processor</b> architecture have become widely accepted. RISC architectures achieve significant performance advantages over CISC architectures by striving to execute one instruction per cycle. However, a traditional RISC architemre can never execute more than one instruction per cycle. Achieving further performance improvements beyond RISC depends on developing processors which fetch and execute more than one operation in each processor cycle...|$|R
50|$|The philosophy, interests, and methodologies of CNN {{researchers}} are varied. Due {{to the potential}} of the CNN architecture, this platform has attracted people from a variety of backgrounds and disciplines. Some are exploring practical implementations of CNN processors, others are using CNN processors to model physical phenomena, and there are even researchers exploring theoretical mathematical, computational, and philosophical <b>ideas</b> through CNN <b>processors.</b> Some applications are engineering related, where some known, understood behavior of CNN processors is exploited to perform a specific task, and some are scientific, where CNN processors are used to explore new and different phenomenon. CNN processors are versatile platforms that are being used for a variety of applications.|$|R
40|$|Abstract. This paper {{explores the}} <b>idea</b> of the <b>processor</b> as an {{asynchronous}} network, called the micronet, of functional units which compute concurrently and communicate asynchronously. A micronet-based asynchronous processor exposes spatial {{as well as}} temporal concurrency. We analyse {{the performance of the}} ‘processor-as-a-network’ by comparing three scheduling algorithms for exploiting Instruction Level Parallelism (ILP). Schedulers for synchronous architectures have relied on deterministic instruction execution times. In contrast, ILP scheduling in micronet-based architectures is a challenge as it is less certain in advance when instructions start execution and when results become available. Performance results comparing the three schedulers are presented for SPEC 95 benchmarks executing on a cycle-accurate model of the micronet architecture. ...|$|R
40|$|Noise self-generated by {{a surface}} ship towing an array {{in search of}} a weak target {{presents}} a major problem for the signal processing especially if broadband techniques are being employed. In this paper we discuss the development and application of an adaptive noise canceling processor capable of extracting the weak far-field acoustic target in a noisy ocean acoustic environment. The fundamental <b>idea</b> for this <b>processor</b> is to use a model-based approach incorporating both target and ship noise. Here we briefly describe the underlying theory and then demonstrate through simulation how effective the canceller and target enhancer perform. The adaptivity of the processor not only enables the ''tracking'' of the canceller coefficients, but also the estimation of target parameters for localization. This approach which is termed ''joint'' cancellation and enhancement produces the optimal estimate of both in a minimum (error) variance sense...|$|R
40|$|Charm++, a {{parallel}} object language {{based on the}} <b>idea</b> of virtual <b>processors,</b> has attained significant success in efficient parallelization of applications. Requiring the user to only decompose the computation into {{a large number of}} objects (“virtual processors ” or VPs), Charm++ empowers its intelligent adaptive runtime system to assign and reassign the objects to processors at runtime. This facility is used to optimize execution, including via dynamic load balancing. Having multiple sets of VPs for distinct parts of a simulation leads to improved modularity and performance. However, it also tends to obscure the global flow of control: One must look at the code of multiple objects to discern how the sets of objects are orchestrated in a given application. In this paper, we present an orchestration notation that allows expression of Charm++ functionality without its fragmented flow of control. 1...|$|R
30|$|According {{to several}} observers, {{vertically}} coordinated supply chain relationships of agri-food markets prevail nowadays as dominant strategies (Vetter and Karantininis 2002; Ménard 2004; Mènard and Valceschini 2005; MacDonald and Korb 2008; Jang and Olson 2010; Cembalo et al. 2014 a). Quality, healthiness, and nutritional values of meals {{are some of}} the determinants of food demand (Jang and Olson 2010). Thereby, several scholars support the <b>idea</b> that both <b>processors</b> and retailers need detailed information about the use of raw materials and the compliance to specific production norms, to certify the quality of their products (Reardon et al. 2003; Mac Donald et al. 2004; Mènard 2004; Bertazzoli et al. 2011). Since smooth and transparent supply chain relationships are one of the pre-condition for market competitiveness and farms profitability (Jang and Olson 2010; Jarzebowski et al. 2013; Morales et al. 2013), contract farming represents an effective tool to trace and promote high-quality productions in food sector (Cembalo et al. 2014 b; Carillo 2016).|$|R
5000|$|The <b>idea</b> of CNN <b>processors</b> was {{introduced}} by Leon Chua and Lin Yang’s two-part, 1988 article, [...] "Cellular Neural Networks: Theory" [...] and [...] "Cellular Neural Networks: Applications" [...] in IEEE Transactions on Circuits and Systems. In these articles, Chua and Yang outline the underlying mathematics behind CNN processors. They use this mathematical model to demonstrate, for a specific CNN implementation, that if the inputs are static, the processing units will converge, {{and can be used}} to perform useful calculations. They then suggest one of the first applications of CNN processors: image processing and pattern recognition (which is still the largest application to date). Leon Chua is still active in CNN research and publishes many of his articles in the International Journal of Bifurcation and Chaos, of which he is an editor. Both IEEE Transactions on Circuits and Systems and the International Journal of Bifurcation also contain a variety of useful articles on CNN processors authored by other knowledgeable researchers. The former tends to focus on new CNN architectures and the latter more on the dynamical aspects of CNN processors.|$|R
40|$|Bearing in {{mind that}} Isteshab {{principle}} is ranked as established principles and in proportion to other threesome principles, it locates at the top; therefore obviously in lieu of other operation principles,  it acts like an indication and it has priority in opposition with acquittal principle, caution and authority with all kinds and fundamentalists have consensus in this case, but whatever in this problem makes difference and contention is the primacy quality of  Isteshab principle which is perceptible in principle sources of some theories. Some fundamentalists considered primacy from respect of entrance; some from respect of government and some by separation of intellectual and quoted principles believing in government and entrance {{and some of them}} believing in to allocation. Therefore our try in this article is the examination of the primacy quality of Isteshab principle from fundamentalists’ viewpoint and adaption with sufficiency <b>processor</b> <b>idea</b> and sharehin. The result of essay is that apparently primacy aspect of Isteshab in proportion to other practical principles whether intellectual or religiously correct is simply from respect of entrance; because by Isteshab principle, threesome principles subject deliberately is no longer contemplated.  </p...|$|R
40|$|Computers {{have found}} their way into {{language}} classrooms. It seems machines are slowly taking over from teachers all tedious working which must be done with error in language classes, all the repetitive and time-consuming jobs that make machines of teachers (Kenning, 1990). One of the ways of using computers in language classrooms is word processors to help students in writing mechanics and grammar. This study was done {{to see if there is}} any significant difference in the Iranian EFL learners’ writing when they use a word processor. For this purpose, a number of 60 sophomore EFL students at Shiraz Islamic Azad University were chosen. Two topics were assigned to write two paragraphs about. It was considered as the pretest. Then, participants were divided into two groups. For treatment, the subjects practiced paragraph writing. In the first group, the teacher corrected the papers, and in the second, the students used the word processor for making corrections. Finally, another paragraph writing test was given to them. The comparison between the students’ scores showed that there was a significant difference in the final performance of the two groups. Therefore, this study supports the <b>idea</b> that word <b>processors</b> improve the EFL learners’ writing mechanics...|$|R
40|$|Abstract — We {{introduce}} a wait-and-chase scheme that models the contact times between moving agents within a connectionist construct. The <b>idea</b> that elementary <b>processors</b> move within a network {{to get a}} proper position is borne out both by biological neurons in the brain morphogenesis and by agents within social networks. From the former, we take inspiration to devise a medium-term project for new artificial neural network training procedures where mobile neurons exchange data only when they are close {{to one another in}} a proper space (are in contact). From the latter, we accumulate mobility tracks experience. We focus on the preliminary step of characterizing the elapsed time between neuron contacts, which results from a spatial process fitting in the family of random processes with memory, where chasing neurons are stochastically driven by the goal of hitting target neurons. Thus, we add an unprecedented mobility model to the literature in the field, introducing a distribution law of the intercontact times that merges features of both negative exponential and Pareto distribution laws. We give a constructive description and implementation of our model, as well as a short analytical form whose parameters are suitably estimated in terms of confidence intervals from experimental data. Numerical experiments show the model and related inference tools to be sufficiently robust to cope with two main requisites for its exploitation in a neural network: the nonindependence of the observed intercontact times and the feasibility of the model inversion problem to infer suitable mobility parameters. Index Terms — Algorithmic inference, brain morphogenesis, complex networks, mobile neurons, mobility models, Paret...|$|R
40|$|This article reviews Overseers of the Poor: Surveillance, Resistance and the Limits of Privacy John Gilliom (2001). In 1964, as {{the welfare}} state emerged in full force in the United States, Charles Reich {{published}} The New Property, {{one of the most}} influential articles ever to appear in a law review. Reich argued that in order to protect individual autonomy in an 2 ̆ 2 age of governmental largess, 2 ̆ 2 a new property right in governmental benefits had to be recognized. He called this form of property the 2 ̆ 2 new property. 2 ̆ 2 In retrospect, Reich, rather than anticipating trends, was swimming against the tide of history. In the past forty years, formal claims to government benefits have become more tenuous rather than more secure. Overseers of the Poor: Surveillance, Resistance and the Limits of Privacy, by John Gilliom, an associate professor of political science at Ohio State University, demonstrates both the tenuousness of welfare rights today and the costs that this system imposes on individual autonomy. In Overseers of the Poor, Gilliom uses his case study of welfare recipients as the occasion for an attack on classic notions of privacy rights. Gilliom finds that welfare clients do not engage in 2 ̆ 2 privacy talk 2 ̆ 2 - indeed, he finds the concept to be devoid of value for the welfare recipients. Here, another comparison can be made with Reich 2 ̆ 7 s new property. Reich explicitly tied his idea of a property right in government entitlements to privacy. He felt that the new property was needed to protect privacy and, in particular, individual autonomy. Reich 2 ̆ 7 s notion of privacy reaches back to a classic concept of privacy, one that we term the 2 ̆ 2 old privacy. 2 ̆ 2 It is precisely this classic idea that Gilliom finds welfare recipients to have rejected. Theoretical work inside and outside of the legal academy has pointed, however, to a 2 ̆ 2 new privacy. 2 ̆ 2 The new privacy is centered around Fair Information Practices (2 ̆ 2 FIPs 2 ̆ 2) and is intended to prevent threats to autonomy. The idea of privacy centered on FIPs is based not on a property interest in one 2 ̆ 7 s information, but the <b>idea</b> that <b>processors</b> of personal data should be obliged to follow certain standards. If, as we will see, classic notions of privacy are not of much use in {{the welfare state}}, the new privacy may be. This review begins by examining Gilliam 2 ̆ 7 s methodology and findings. It credits the insights of his look at the inner world of welfare recipients, but finds that he appears to ignore the need for income limits on aid recipients and the concomitant need for at least some personal information to enforce these limits. It also criticizes his failure to explore an interaction of an 2 ̆ 2 ethics of care 2 ̆ 2 among welfare recipients with possible use of retooled privacy rights or interests. In the second part of this review, The authors consider the extent to which theoretical work inside and outside of the legal academy points to a new privacy and discuss how Gilliam 2 ̆ 7 s empirical research provides support for that scholarship. They also evaluate the extent to which the new privacy, centered on PIPs, can prevent the threats to personal autonomy so poignantly identified by Gilliom...|$|R

