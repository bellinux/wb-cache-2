241|1152|Public
5000|$|... #Caption: A typical scoring results screen from X-Rite's 100 Hues test <b>evaluation</b> <b>software.</b>|$|E
5000|$|SPECapc for 3ds Max™ 2011, {{performance}} <b>evaluation</b> <b>software</b> for systems running Autodesk 3ds Max 2011.|$|E
5000|$|SPECapcSM for Lightwave 3D 9.6, {{performance}} <b>evaluation</b> <b>software</b> for systems running NewTek LightWave 3D v9.6 software.|$|E
5000|$|C V Ramamoorthy. Evolution and <b>Evaluation</b> of <b>Software</b> Quality Models. ICTAI, page 543, 2002.|$|R
5000|$|... 1900.3 Working Group on Recommended Practice for Conformance <b>Evaluation</b> of <b>Software</b> Defined Radio (SDR) Software Modules ...|$|R
40|$|<b>Software</b> <b>evaluation</b> is {{the problem}} of {{determining}} {{the extent to which a}} software product satisfies a set of requirements. We create quantitative models for <b>software</b> <b>evaluation</b> using a general system evaluation method called LSP (Logic Scoring of Preference). In this paper we define and classify <b>software</b> <b>evaluation</b> problems, overview the LSP method, and present design concepts, implementation, and use of a new LSP-based tool for <b>software</b> <b>evaluation.</b> Our tool is called the Integrated System Evaluation Environment (ISEE). ISEE is suitable for rapid development of software models and their use for evaluation, comparison, and selection of complex software systems...|$|R
5000|$|Software - the specification, design, development, test, and {{implementation}} of computer software for aerospace applications, including flight software, ground control software, test & <b>evaluation</b> <b>software,</b> etc.|$|E
5000|$|There are six {{working groups}} that are common across the three {{universities}} included in the original Moore/Sloan grant. The working groups are intended to [...] "address the major challenges facing advances in data-intensive research" [...] and include Career Paths and Alternative Metrics, Reproducibility and Open Science, Education and Training, Ethnography and <b>Evaluation,</b> <b>Software</b> Tools and Environments, and Working Spaces and Culture. and while all three are separate aspects of one division, they were awarded different grant money.|$|E
50|$|Dr. Robert Lowe was {{previously}} the founding Director of Enterprise Creation at Carnegie Mellon University, a position created to provide management advice and {{assistance to the}} university's many start-up companies. He was a professor of entrepreneurship at Carnegie Mellon University and has authored over a dozen academic papers on technology commercialization and start-ups. Mr Lowe started work full-time at Wellspring Worldwide in Summer 2007.Prior to his academic career, Dr. Lowe worked for the Boston Consulting Group where he advised clients in pharmaceuticals, consumer products, and industrial automation. He also worked as an intern in the University of California's Office of the President to develop metrics, performance <b>evaluation</b> <b>software,</b> and policy analysis related to the University of California's start-up companies.|$|E
40|$|The USL NASA PC <b>software</b> <b>evaluation</b> {{project is}} {{intended}} to provide a structured framework for facilitating the development of quality NASA PC software products. The project will assist NASA PC development staff to understand the characteristics and functions of NASA PC software products. Based {{on the results of}} the project teams' evaluations and recommendations, users can judge the reliability, usability, acceptability, maintainability and customizability of all the PC software products. The objective here is to provide initial, high-level specifications and guidelines for NASA PC <b>software</b> <b>evaluation.</b> The primary tasks to be addressed in this project are as follows: to gain a strong understanding of what <b>software</b> <b>evaluation</b> entails and how to organize a structured <b>software</b> <b>evaluation</b> process; to define a structured methodology for conducting the <b>software</b> <b>evaluation</b> process; to develop a set of PC <b>software</b> <b>evaluation</b> criteria and evaluation rating scales; and to conduct PC <b>software</b> <b>evaluations</b> in accordance with the identified methodology. Communication Packages, Network System Software, Graphics Support Software, Environment Management Software, General Utilities. This report represents one of the 72 attachment reports to the University of Southwestern Louisiana's Final Report on NASA Grant NGT- 19 - 010 - 900. Accordingly, appropriate care should be taken in using this report out of context of the full Final Report...|$|R
40|$|Evaluating and {{selecting}} {{software packages}} that meet an organization's requirements {{is a difficult}} software engineering process. Selection of a wrong software package can {{turn out to be}} costly and adversely affect business processes. The aim {{of this paper is to}} provide a basis to improve the process of evaluation and selection of the software packages. This paper reports a systematic review of papers published in journals and conference proceedings. The review investigates methodologies for selecting <b>software</b> packages, <b>software</b> <b>evaluation</b> techniques, <b>software</b> <b>evaluation</b> criteria, and systems that support decision makers in evaluating software packages. The key findings of the review are: (1) analytic hierarchy process has been widely used for <b>evaluation</b> of the <b>software</b> packages, (2) there is lack of a common list of generic <b>software</b> <b>evaluation</b> criteria and its meaning, and (3) there is need to develop a framework comprising of <b>software</b> selection methodology, <b>evaluation</b> technique, evaluation criteria, and system to assist decision makers in software selection. (C) 200...|$|R
40|$|Selecting Commercial-Off-The-Shelf (COTS) {{software}} components to fit requirements {{is still a}} problem because of the "black box" nature of COTS components and the rapid changes in marketplace. This paper describes the problems of COTS <b>software</b> <b>evaluation</b> and reviews existing frameworks to support COTS <b>software</b> <b>evaluation</b> and selection. Although a number of initiatives have been proposed {{to deal with the}} COTS <b>software</b> <b>evaluation</b> problems, they do not adequately address the non-technical issues. The paper presents a method of applying social-technical approach for COTS software selection and recommends customer participation in the COTS <b>software</b> <b>evaluation</b> and use of a social-technical evaluation criteria. Keywords: COTS <b>software</b> <b>evaluation,</b> social-technical evaluation criteria, customer participation 1 INTRODUCTION COTS software component selection is a process of determining "fitness for use" of previously-developed components that are being applied in a new system context (Haines, 1 [...] ...|$|R
50|$|In 2009, seven {{schools in}} the Central Dauphin School District {{received}} funding through Highmark Healthy High 5 grants. Central Dauphin High School received $9,499 which was used to purchase equipment for an interactive DDR program. Central Dauphin East received a $10,000 grant which was used to purchase fitness and <b>evaluation</b> <b>software</b> and tools to implement Fit for Life program. Fitnessgram will be utilized to create a comprehensive fitness unit for 9-12-grade students. Central Dauphin East Middle School received $9,999 which was used to implement the East Middle School Video Dance program. Linglestown Elementary received a $3000 grant which it used to implement the Game On Ultimate Wellness Challenge) program. Mountain View Elementary received $9,000 which was used to purchase equipment for the modified PE program. Rutherford Elementary School and Lawnton Elementary School each received $1,865 grant to purchase materials to enhance their bullying prevention programs. Beginning in 2006, Highmark Foundation engaged in a 5-year, $100 million program to promote lifelong healthy behaviors {{in children and adolescents}} through local nonprofits and schools.|$|E
40|$|ABSTACT NURDIANSAH. 2011. Development of <b>Evaluation</b> <b>Software</b> on Information Technology and Communication at SMKN 1 in Bulukumba (supervised by Sidin Ali ali and Mansyur). 	The {{curriculum}} of SMK which initially was school based and subject matter curriculum, adjusted to competence curriculum which stressed on {{the competence of}} students according to the demand of business world {{and the development of}} science and technology which referred to the applicable provisions. 	This study aimed at examining the development of <b>evaluation</b> <b>software</b> on Information Technology and Communication (TIK) with the subject of installation of network operation system which was based on Graphical User Interface (GUI) and examining the validity and the effectiveness of the <b>evaluation</b> <b>software</b> of learning result of TIK the subject of Installation of network operation system which was based. On GUI whether it fulfilled the criteria of valid and effective. The validity was obtained based on the examiners’ evaluation toward the learning result from the <b>evaluation</b> <b>software.</b> The effectiveness included the arhievement of classical minimal mastery criterion and the response toward <b>evaluation</b> <b>software.</b> 	The result revealed that the learning result toward <b>evaluation</b> <b>software</b> bhad fulfilled valid criteria based on the examiners’ evaluation and the <b>evaluation</b> <b>software</b> had fulfilled effective criterion based on the archivement of classical mastery thatall students had mastered from the determined KKM score, and students’ response had fulfilled positive response...|$|E
40|$|The US Department of Energy is {{estimating}} the undeveloped hydropower {{potential in the}} US. The Hydropower <b>Evaluation</b> <b>software</b> is a computer model that {{was developed by the}} Idaho National Engineering Laboratory for this purpose. The Hydropower <b>Evaluation</b> <b>Software</b> estimates the undeveloped hydropower resources available in the US, using uniform criteria for measurement. The software was developed and tested using hydropower information and data provided by the Southwestern Power Administration. It is a menu-driven software application. Hydropower <b>Evaluation</b> <b>Software</b> allows the personal computer user to assign environmental attributes to potential hydropower sites, calculate development suitability factors for each site based on the environmental attributes present, and generate reports based on these suitability factors. This status report describes Hydropower Evaluation Software`s development, its data requirements, and its application to the 20 states assessed to date. This report does not discuss or present the various user-friendly menus of the Hydropower <b>Evaluation</b> <b>Software.</b> The reader is referred to the User`s Manual for specifics. This report focuses on data derivation, summarization of the 20 states (Arkansas, Missouri, Montana, New Hampshire, North Dakota, Oklahoma, Rhode Island, South Dakota, Texas, Utah, Vermont, and Wyoming) assessed to date, and plans for future assessments...|$|E
40|$|Abstract: The <b>evaluation</b> of <b>software</b> {{architectures}} {{is crucial}} {{to ensure that the}} de-sign of software systems meets the requirements. We present a generic methodical framework that enables the <b>evaluation</b> of component-based <b>software</b> architectures. It allows to determine system characteristics {{on the basis of the}} characteristics of its con-stituent components. Basic prerequisites are discussed and an overview of different architectural views is given, which can be utilised for the evaluation process. On this basis, we outline the general process of evaluating software architectures and provide a taxonomy of existing evaluation methods. To illustrate the <b>evaluation</b> of <b>software</b> architectures in practice, we present some of the methods in detail. ...|$|R
40|$|The {{application}} of <b>software</b> <b>evaluation</b> technologies in different research fields to verify and validate research {{is a key}} factor in the progressive evolution of those fields. Nowadays, however, to have a clear picture of the maturity of the technologies used in evaluations or to know which steps to follow in order to improve the maturity of such technologies is not easy. This paper describes a <b>Software</b> <b>Evaluation</b> Technology Maturity Model {{that can be used to}} assess <b>software</b> <b>evaluation</b> technologies in a research field. To illustrate the use of this model, we have employed it for assessing the maturity of <b>software</b> <b>evaluation</b> technologies in some evaluation initiatives within the semantic research field...|$|R
40|$|The <b>evaluation</b> of <b>software</b> {{architectures}} {{is crucial}} {{to ensure that the}} design of software systems meets the requirements. We present a generic methodical framework that enables the <b>evaluation</b> of component-based <b>software</b> architectures. It allows to determine system characteristics {{on the basis of the}} characteristics of its constituent components. Basic prerequisites are discussed and an overview of different architectural views is given, which can be utilised for the evaluation process. On this basis, we outline the general process of evaluating software architectures and provide a taxonomy of existing evaluation methods. To illustrate the <b>evaluation</b> of <b>software</b> architectures in practice, we present some of the methods in detail...|$|R
40|$|A long-time {{experience}} in emittance measurements and result evaluation at GSI were {{transformed into a}} set of numerical instruments to perform basic and advanced data analysis for data obtained in various emittance measurement systems. The common problems and differences between slit-grid-, pepper-pot- and longitudinal emittance data analysis are discussed. Some aspects of non-linear algorithms particularly for the case of non-zero slit width and pepper-pot holes diameter are presented. TOOLBOX APPLICATIONS Historically the emittance <b>evaluation</b> <b>software</b> development has been started {{as a part of}} control and <b>evaluation</b> <b>software</b> developed for a new pepper-po...|$|E
40|$|Form {{evaluation}} algorithms that characterise geometric {{dimensions and}} verify the conformance {{to a given}} tolerance from the 3 D measurement data {{play a significant role}} in 3 D coordinate metrology. This paper reviews the research on form <b>evaluation</b> <b>software,</b> including the approaches to development, testing and selection of appropriate algorithms for form evaluation. By investigating the issues raised in form <b>evaluation</b> <b>software,</b> a methodology for testing of spherical form evaluation algorithms has been proposed and presented, including drawing up the criteria for algorithms testing, and designing approaches to testing procedures. Based on testing and analysing, conclusions have been drawn for properly applying form evaluation algorithm...|$|E
30|$|Drs. Salluh, Soares and Reis are founders {{and equity}} holders at Epimed Solutions, the {{provider}} of a cloud-based healthcare analytics and performance <b>evaluation</b> <b>software.</b> Prof Chiche received honorarium from GE Healthcare for lectures at various medical congresses.|$|E
40|$|This paper {{proposes a}} {{framework}} for educational <b>software</b> <b>evaluation</b> based on the Multiple Criteria Decision Aid methodology. Evaluating educational software products is a twofold process: both the educational and the technical aspect of the evaluated products have to be considered. As far as the product educational effectiveness is concerned, we propose a set of attributes covering both the general educational features {{and the content of}} the product. From the technical point of view, a software attribute set based on the ISO/IEC 9126 standard has been chosen together with the accompanying measurement guidelines. Finally, an evaluation example involving three commercial educational software packages for mechanics is presented. <b>Software</b> <b>Evaluation,</b> Educational <b>Software,</b> MCD...|$|R
5000|$|Hans van Vliet, Hans de Bruin. [...] "Scenario-based {{generation}} and <b>evaluation</b> of <b>software</b> architectures." [...] in: Generative and Component-Based Software Engineering. Springer Berlin Heidelberg, 2001. p. 128-139 ...|$|R
40|$|AbstractCore {{banking system}} is the most {{important}} software system for commercial banks. The complexities of the core banking system projects lead to that the financial software testing is very complex and difficult. This paper analyzes the traditional <b>software</b> testing management <b>evaluation</b> criteria, and proposes a new evaluation model. By removing the correlation between traditional evaluation criteria, the model can obtain a set of uncorrelated evaluation factors, and these factors can be used for the <b>evaluation</b> of <b>software</b> testing management. Experiments have proved that this model can be more scientific and objective for the <b>evaluation</b> of <b>software</b> testing management in core banking systems programme...|$|R
40|$|Uncertainty <b>evaluation</b> <b>software</b> {{based on}} Monte Carlo {{simulations}} is very useful for coordinate measurement machines (CMMs). These Monte Carlo methods use so-called virtual CMMs to simulate CMM measurement errors. Based on the simulated errors measurement uncertainties can be determined. This paper shows how CMM hardware errors can be modelled {{in a simple}} and straightforward way. It considers CMM geometric errors as well as probe and articulating probe head errors. A key element of the presented method is the selection of representative virtual CMMs based on a virtual ISO 10360 - 2 acceptance test. The method has been implemented in own developed uncertainty <b>evaluation</b> <b>software</b> but {{can also be used}} in other software. Results show that very reliable uncertainty statements are obtained with this method. status: submitte...|$|E
40|$|The {{purpose of}} our study {{was to develop a}} simple and {{reproducible}} method for calculating post-operative acetabular cup position based upon computed tomographic images. Next, we sought to examine the reliability, objectivity and accuracy of this method. We developed a 3 D CT <b>evaluation</b> <b>software</b> based upon Amira(R) (data visualisation, analysis and modelling software) to calculate the abduction and anteversion of the acetabular cup relative to the APP (anterior pelvic plane). To test the accuracy of the method, we constructed a special phantom pelvic model as the gold standard, in which the acetabulum was mounted at various abduction and anteversion angles that had previously been measured digitally. This phantom was then CT scanned in 12 different cup positions (30 degrees to 50 degrees abduction, 0 degrees to 30 degrees anteversion) and then evaluated using the 3 D CT <b>evaluation</b> <b>software.</b> In addition, we also examined the reliability and objectivity of this method in 10 patients following implantation of a hip prosthesis, as a clinical trial. We observed an average accuracy of the 3 D CT <b>evaluation</b> <b>software</b> of - 0. 3 degrees (range - 1. 4 degrees to 1. 3 degrees; SD 0. 6 degrees) for abduction and 0. 2 degrees (range - 1. 4 degrees to 1. 4 degrees; SD 0. 6 degrees) for anteversion compared with the gold standard. Moreover, a high intra -and interindividual agreement in the resulting ICC well above 0. 8 for abduction and abduction values in the phantom study and the clinical trial were observed. This study found that the 3 D CT <b>evaluation</b> <b>software</b> provides high reliability, objectivity and accuracy. Thus, the 3 D CT software is a method that permits very precise evaluation of the post-operative cup position independent of patient positioning or pelvic til...|$|E
40|$|International audienceThis paper {{introduces}} {{a new concept}} of thermal transient measurement of IC packages without a tester. The thermal transient test kit described here consists of a test chip, dedicated software running on a PC and a special cable connecting the PC to the IC package which encapsulates the test chip. The functionality of the thermal transient test equipment is realized by the test chip itself and the measurement software. The software performs both {{the control of the}} measurement and the results evaluation. The final output of the <b>evaluation</b> <b>software</b> is a compact model network and the structure function, describing the properties of the heat conduction path realised by the IC package under test. The use of the test kit and the capabilities of its <b>evaluation</b> <b>software</b> are demonstrated by a few examples...|$|E
40|$|In {{simulation}} software selection problems, packages are evaluated either {{on their own}} merits or in comparison with other packages. In either method, a list of criteria for <b>evaluation</b> of simulation <b>software</b> is essential for proper selection. Although various simulation <b>software</b> <b>evaluation</b> checklists do exist, {{there are differences in}} the lists provided and the terminologies used. This paper presents a comprehensive list of criteria structured in a hierarchical framework for simulation <b>software</b> <b>evaluation</b> consisting of seven main groups and several subgroups. An explanation for each criterion is provided and an analysis of the usability of the proposed framework is further discussed...|$|R
40|$|The <b>evaluation</b> of <b>software</b> {{technologies}} suffers {{because of}} the lack of quantitative assessment of their effect on software development and modification. A seven-step data collection and analysis methodology couples <b>software</b> technology <b>evaluation</b> with <b>software</b> measurement. Four in-depth applications of the methodology are presented. The four studies represent each of the general categories of analyses on the software product and development process: blocked subject-project studies, replicated project studies, multi-project variation studies, and single project strategies. The four applications are in the areas of, respectively, software testing, cleanroom software development, characteristic software metric sets, and software error analysis...|$|R
40|$|The Connecticut Special Education Network for <b>Software</b> <b>Evaluation</b> is {{intended}} to help special educators learn about effective software. The network has developed a <b>software</b> <b>evaluation</b> model and instrument which solicits both descriptive and evaluative information on special education courseware. A needs assessment performed {{in the state in}} 1983 revealed patterns of access to computers and a need for high quality courseware for students with learning disabilities. Twenty-eight teachers have been trained in <b>software</b> <b>evaluation.</b> Evaluation results will be disseminated via a newsletter. (CL) Reproductions supplied by EDRS are the best that can be made from the original document...|$|R
40|$|International audienceThis paper {{presents}} {{a new concept}} for the thermal transient measurement of IC packages. The TTMK thermal transient test kit described here consists of a test chip, a dedicated software running on a PC and a special cable connecting the PC to the IC package which encapsulates the test chip. The function of the thermal transient test equipement is realized partly by the test chip itself and partly by the measuring software. The software performs both {{the control of the}} measurement and the evaluation of the results. The output of the <b>evaluation</b> <b>software</b> may be a compact model network or the structure function describing the properties of the heat conduction path. The use of TTMK kit and the capabilities of the <b>evaluation</b> <b>software</b> are presented in the paper...|$|E
40|$|Contents: New CSAS Web Page Field Day On Specialty Crops Windbreak <b>Evaluation</b> <b>Software</b> Integrated Farm Update: Cover Crop Research Teaching Sustainability at a Distance President 2 ̆ 7 s Task Force Says U. S. Ag Must Be Sustainable Exchange Program for Organic Farmers Agroforestry for Farms, Ranches, and Communities Windbreaks for Corn...|$|E
40|$|Full-featured {{evaluation}} {{board for}} the AD 9910 PC <b>evaluation</b> <b>software</b> for control and measurement of the AD 9910 USB interface Graphic user interface (GUI) software with frequency sweep capability for board control and data analysis Factory tested and ready to use PACKAGE CONTENTS AD 9910 evaluation board AD 9910 /PCBZ installation software CD USB cabl...|$|E
40|$|Sorry, {{the full}} text of this article is not {{available}} in Huskie Commons. Please click on the alternative location to access it. 189 p. In a wave of reform movements, our schools need to respond to the increasing use of technology in order to prepare learners to become productive members of society. The use of technology has entered schools slowly and recently skyrocketed with more microcomputers and software being purchased every year by schools. For the microcomputer to become an effective classroom aid, the software implemented must be dynamic. This has not been the case. Software has been poor in relation to technical capabilities, matching curricular objectives for the classroom, and instructional capabilities. There exists a definite need to have a <b>software</b> <b>evaluation</b> model reliable in assessing the technical capabilities, meeting of curricular objectives, and instructional capabilities of microcomputer software. This study analyzed the instructional component of the <b>software</b> <b>evaluation</b> model by examining models of instruction based on teacher effectiveness research of Barak Rosenshine, Madeline Hunter, David Ausubel, and Robert Gagne as well as instructional criteria with low-inferential implications from extant <b>software</b> <b>evaluations</b> to develop a microcomputer <b>software</b> <b>evaluation</b> instrument. The microcomputer <b>software</b> <b>evaluation</b> instrument based on models of instruction was field-tested and found reliable for evaluating high school mathematics software (KR- 20 =. 8884), science software (KR- 20 =. 8989), and mathematics and science software combined (KR- 20 =. 8924). Based on the study's findings, it was concluded that the microcomputer <b>software</b> <b>evaluation</b> instrument developed for this study was a valid and reliable tool for assessing the instructional qualities of high school mathematics and science software. Implications of the microcomputer <b>software</b> <b>evaluation</b> instrument included recommendations for educational software writers to acquire an educational background and utilize the microcomputer <b>software</b> <b>evaluation</b> instrument to provide instructional guidance in developing software. In addition, it was recommended that the instrument become entirely computerized so that the practitioner can easily and reliably assess high school mathematics and science software by the total utilization of the microcomputer...|$|R
40|$|In {{order to}} ensure that {{technology}} supports business needs and that IT investments deliver the desired value, it is fundamental to define an Information System Architecture (ISA) and measure its accurateness to the business model and existing technologies. Thus, in this paper we are concern on evaluating ISA by measuring its qualities (relevant at enterprise level). Since software architecture (SA) is part of the information system architecture and the evaluation topic is a quite mature issue on the software engineering domain, we enumerate and classify several <b>software</b> <b>evaluation</b> approaches in order to consider its applicability to ISA evaluation. Therefore, in this paper, we present and classify the most significant <b>software</b> <b>evaluation</b> issues, namely: <b>software</b> qualities, <b>software</b> <b>evaluation</b> approaches, and <b>software</b> metrics. Our preliminary findings indicate that: the quality attributes relevant for SA evaluation are generally applicable for ISA evaluation, the SA evaluation approaches are also useful for ISA evaluation, and the SA metrics are not applicable to ISA evaluation. In this paper we propose a set of metrics for ISA evaluation, considering the most experienced and tested software engineering metrics. We apply the ISA evaluation approach, qualities and metrics to a health-care project case study...|$|R
40|$|The Computer Safety and Reliability Group at Lawrence Livermore National Laboratory (LLNL) is {{researching the}} <b>evaluation</b> of <b>software</b> used in safety-critical applications. This paper {{describes}} one, {{of the research}} and development efforts currently underway to model the <b>software</b> <b>evaluation</b> process and to develop a <b>software</b> <b>evaluation</b> tool. One of the primary techniques available for determining the safety of software proposed for use in safety-critical applications is to evaluate the software development process and the resulting products. This model of the evaluation process was influenced by several factors the underlying motivation was to identify, control and reduce the risk inherent in building safety-critical software systems. This prototype tool, the <b>Software</b> <b>Evaluation</b> Assistant (SEA), assists and guides evaluators as they analyze safety-critical software. SEA describes specific evaluation goals, provides a brief overview of the specific evaluation process, identifies potential, risks of not performing the evaluation, identifies the skills required to carry out the evaluation of a particular topic, identifies the material that should typically be available for the evaluation, and poses questions used to examine and rate the software item...|$|R
