0|10000|Public
40|$|Good {{visual quality}} and precise {{accommodation}} {{are required to}} be able <b>to</b> <b>focus</b> <b>objects</b> at <b>distance</b> and near, and are essential {{in order to be}} able to perform most tasks in life. Most eyes are not ideal eyes, i. e., they have different refractive errors which distort the produced image. The well-known refractive errors (lower order aberrations), myopia, hyperopia and astigmatism, have long been correctable. In addition to these common errors, irregularities in the refractive media create higher order aberrations, which are described by the Zernike polynomials. To achieve a higher level of visual quality, it is important to correct aberrations. Spherical aberration and chromatic aberration, present in polychromatic light, serve as cues for accurate accommodation in order to provide a clear image of the object. It is of interest to know how a reduction or increase of certain aberrations might affect visual quality and accommodation. The aim of this project was to develop techniques to measure the changes in optical aberrations and accommodation in subjects while wearing standard contact lenses, and lenses with aberration control and to find new strategies to enhance the fitting of these lenses in order to achieve a higher level of visual quality. Using an aberrometer, residual spherical aberration was evaluated with a standard contact lens and with a lens with spherical aberration control. Visual quality (i. e. visual acuity and contrast sensitivity) was also evaluated with the different contact lenses. Aberration and accommodation were measured with and without accommodative cues present. Accommodation was evaluated with a multifocal contact lens with a near reading addition. The results show that it is possible to evaluate residual spherical aberration with contact lenses on the eye, but the change in aberration gave no difference in visual acuity or contrast sensitivity at distance or near with the methods used. Spherical aberration and chromatic aberration were shown not to be strong directional cues for accommodation, indicating that there are other cues more important for directional information. Since the multifocal contact lens, a centre distance design with reading addition + 1. 00, was not able to relax the accommodation for the subjects, it is therefore unlikely that subjects with reduced accommodative ability can effectively be treated with such a lens. In conclusion, a wavefront measurement should be performed both with and without contact lenses, in order to know the amount of aberration in the eye and to note any change from a contact lens. The relatively small change in spherical aberration that non-customised lenses induce does not affect visual acuity, contrast sensitivity or accommodation. These lenses may then be fitted without worrying about affecting accommodation and they do not seem suitable to be fitted on young subjects with the ability to accommodate with the purpose of reducing their accommodative load. There is still reason to believe that there are subgroups of patients who can achieve better visual quality, but more sensitive clinical methods have to be developed...|$|R
2500|$|The image {{distance}} [...] is related <b>to</b> an <b>object</b> <b>distance</b> [...] by the thin lens equation ...|$|R
40|$|Abstract. In this paper, we {{introduce}} a millimeter wave imaging modality with extended depthof-field that provides diffraction limited images with reduced spatial sampling. The technique uses a cubic phase {{element in the}} pupil {{of the system and}} a nonlinear recovery algorithm to produce images that are insensitive <b>to</b> <b>object</b> <b>distance.</b> We present experimental results that validate system performance and demonstrate a greater than four-fold increase in depth-of-field with a reduction in sampling requirements by a factor of at least two. c ○ 2012 Society of Photo-Optical Instrumentation Engineers. DOI: 10. 0000 /XXXX Subject terms: Computational imaging, millimeter wave imaging, extended depth-of-field, imag...|$|R
40|$|Coral {{substrate}} {{spatial information}} from video image mosaicing is potential {{to use on}} Quickbird image validation. The dimension of image mosaicing may estimated from lens calibration parameter values. On this study, these values was result from 108 pictures of A 0 size chessboard patern taken from three different orientation at 2, 5, 4, 5 and 7, 5 meter respectively, within two conditions: fix and unfix lens focusing. This study shows that the image dimension produce by test video camera has polynomial function <b>to</b> <b>object</b> <b>distance.</b> The video mosaic image capable to inform coral life form level hence more detail than Quickbird imag...|$|R
40|$|In this paper, we {{introduce}} a new millimeter wave imaging modality with extended depth-of-field that provides diffraction limited images based on {{a significant reduction in}} scan-time. The technique uses a cubic phase element in the pupil of the system and a nonlinear recovery algorithm to produce images that are insensitive <b>to</b> <b>object</b> <b>distance.</b> We present experimental results that validate system performance and demonstrate a greater than four-fold increase in depth-of-field with a reduction in scan-time by a factor of at least two. Index Terms — Computational imaging, millimeter wave imaging, extended depth-of-field, image reconstruction, sparsity. 1...|$|R
40|$|Two {{procedures}} {{dealing with}} distance estimation in space are analyxed. In one, formulae relating angular subtense to target distance are derived for spherical and disk objects. A {{design for a}} simple reticle {{to be used in}} distance estimation is described. In the other procedure, the utili 2 ation of illuminance f rom spherical and disk-shaped satellites for the purpose of relating it <b>to</b> <b>object</b> <b>distance</b> is examined. Formulae describing the relationsh@s for certain cases are developed. The appearance of spherical satellites when illuminated by sources of both small and large angular szlbtense is dealt with in some detail...|$|R
50|$|The sensors emit {{acoustic}} pulses, with {{a control}} unit measuring the return interval of each reflected signal and calculating <b>object</b> <b>distances.</b> The system in turns warns the driver with acoustic tones, the frequency indicating <b>object</b> <b>distance,</b> with faster tones indicating closer proximity and a continuous tone indicating a minimal pre-defined distance. Systems may also include visual aids, such as LED or LCD readouts <b>to</b> indicate <b>object</b> <b>distance.</b> A vehicle may include a vehicle pictogram on the car's infotainment screen, with {{a representation of the}} nearby objects as coloured blocks.|$|R
40|$|Reliable object {{detection}} and segmentation {{is crucial for}} active safety driver assistance applications. In urban areas where the object density is high, a segmentation based on a spatial criterion often fails due <b>to</b> small <b>object</b> <b>distances.</b> Therefore, optical flow estimates are combined with distance measurements of a Laserscanner in order <b>to</b> separate <b>objects</b> with different motions even if their distance is vanishing. Results are presented on real measurements taken in potentially harmful traffic scenarios...|$|R
50|$|In about 10% of Hendry’s cases {{caused by}} {{celestial}} bodies, witnesses greatly underestimated <b>distances</b> <b>to</b> the <b>objects,</b> giving <b>distance</b> estimates ranging from 200 feet to 125 miles (60 m to 200 km).|$|R
50|$|When the {{inability}} <b>to</b> <b>focus</b> <b>objects</b> from varying <b>distances</b> is presented. Headaches, blurred vision and general vision discomfort {{are presented in}} subjects who have this condition and are exposed to 3D effects.|$|R
50|$|Overhead {{projectors}} normally {{include a}} manual focusing mechanism which raises and lowers {{the position of}} the focusing lens (including the folding mirror) in order <b>to</b> adjust the <b>object</b> <b>distance</b> (optical distance between the slide and the lens) <b>to</b> <b>focus</b> at the chosen image distance (distance to the projection screen) given the fixed focal length of the focusing lens. This permits a range of projection distances.|$|R
2500|$|Very Long Baseline Interferometry which finds precise {{directions}} to quasars in distant galaxies, and allows {{determination of the}} Earth's orientation with respect <b>to</b> these <b>objects</b> whose <b>distance</b> is so great they can be considered to show minimal space motion [...]|$|R
40|$|Several {{non-invasive}} {{methods are}} in use for recording mechanocardiograms. In this paper a new laser technique {{will be presented}} to measure heart motion, chest wall displacement and other displacement curves of cardiovascular structures. Principles of the laser displacement technique are described. The measurement range within which displacement is sensed, is 32 mm with a detector <b>to</b> <b>object</b> <b>distance</b> of 25 cm and a resolution of 8 micron (digital output) or 16 micron (analogue output). The specific surface of which motion is sensed is 1 mm 2. The sensitivity of the system is 156 mV/mm at a frequency bandwidth of 0 - 2 kHz. Assessment of the laser displacement technique was carried out during 6 dog experiments on the closed chest, on the exposed heart, on blood vessels and also on the chest wall of 5 normal subjects. Displacement of the chest wall at the apical site ranges between 0. 3 - 0. 8 mm and of the exposed heart between 3 - 10 mm. status: publishe...|$|R
3000|$|... [*]=[*] 13.3204 mm, and S D D[*]=[*] 717.5830 mm. The <b>object</b> <b>to</b> {{detector}} <b>distance</b> ODD≈ 25 mm; it is however {{not required}} by the algorithm and therefore only manually approximated.|$|R
5000|$|GRB 101225A, {{also known}} as the [...] "Christmas burst", was a cosmic {{explosion}} first detected by NASA's Swift observatory on Christmas Day 2010. The gamma-ray emission lasted at least 28 minutes, which is unusually long. Follow-up observations of the burst's afterglow by the Hubble Space Telescope and ground-based observatories were unable <b>to</b> determine the <b>object's</b> <b>distance</b> using spectroscopic methods.|$|R
5000|$|Very Long Baseline Interferometry which finds precise {{directions}} to quasars in distant galaxies, and allows {{determination of the}} Earth's orientation with respect <b>to</b> these <b>objects</b> whose <b>distance</b> is so great they can be considered to show minimal space motion (McCarthy & Seidelmann, 2009, p. 265) ...|$|R
40|$|Abstract. The {{desire to}} ensure safety of the {{infrastructure}} such as bridge, dam, and tunnel while reducing maintenance time and costs in the civil engineering applications emerged. Image processing techniques may well represent a {{next step in the}} development of smart monitoring of crack. In this paper, a method to inspect the surface crack in a concrete structure using 2 D image has been proposed. The standardized crack specimen which has different crack widths was manufactured and the crack images were taken at the <b>object</b> <b>distance</b> from 5 <b>to</b> 60 m with 5 m step. The characteristics of the several edge operators such as Sobel, Prewitt, Robert, Canny and LoG to recognize the crack were analyzed according <b>to</b> the <b>object</b> <b>distance...</b>|$|R
40|$|With {{the rise}} of virtual reality (VR) technology, {{panoramic}} images are used more widely, which obtained by multi-camera stitching {{and take advantage of}} homography matrix and image transformation, however, this method will destroy the collinear condition, make it's difficult to 3 D reconstruction and other work. This paper proposes a new method for cylindrical panoramic image mosaic, which set the number of mosaic camera, imaging focal length, imaging position and imaging attitude, simulate the mapping process of multi-camera and construct cylindrical imaging equation from 3 D points to 2 D image based on photogrammetric collinearity equations. This cylindrical imaging equation can not only be used for panoramic stitching, but also be used for precision analysis, test results show: ①this method can be used for panoramic stitching under the condition of multi-camera and incline imaging; ②the accuracy of panoramic stitching is affected by 3 kinds of parameter errors including focus, displacement and rotation angle, in which focus error can be corrected by image resampling, displacement error is closely related <b>to</b> <b>object</b> <b>distance</b> and rotation angle error is affected mainly by the number of cameras...|$|R
40|$|DE 10037771 A UPAB: 20020528 NOVELTY - The laser {{scanners}} (3 a, 3 b) arranged at {{a defined}} spacing are moved, until the scanning beams (4 a, 4 b) converge at a measurement point (6) on an object (2). The object image {{is picked up}} using a video camera (7) and the image is processed to set scanners movement for beam convergence and <b>to</b> determine <b>object</b> <b>distance</b> by triangulation principle using scanners position and converging point. DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for <b>object</b> <b>distance</b> measurement device. USE - For detecting <b>object</b> <b>distance,</b> 3 D profile of an area or objects for precision control of insertion of endoscope, and controlling tools and robots in industrial automation. ADVANTAGE - The measurement is independent of the spatial resolution of the optical detectors and only dependent on the mechanical guides used for moving the scanners, hence precision and reliability are high...|$|R
40|$|The {{team was}} tasked with the {{creation}} of an autonomous cyber-physical system that could be continually developed as a post-capstone class by future STEM students and as a means to teach future engineering students. The strict definition of a cyber-physical system is a computation machine that networks with an embedded computer that performs a physical function. The autonomous aspect was achieved through two sonic sensors <b>to</b> monitor <b>object</b> <b>distances</b> in order <b>to</b> avoid walls and obstacles. The integrated system was based on the Intel Edison computation module. A primary goal for future addition is automation capabilities and machine learning applications...|$|R
40|$|Optical signal {{processor}} produces two-dimensional cross correlation of images from steroscopic video camera in real time. Cross correlation used <b>to</b> identify <b>object,</b> determines <b>distance,</b> or measures movement. Left and right cameras modulate beams from light source for correlation in video detector. Switch in position 1 produces information about range of object viewed by cameras. Position 2 gives information about movement. Position 3 helps <b>to</b> identify <b>object...</b>|$|R
40|$|Abstract- We {{present a}} method for {{securing}} guided robot motions in terms of human/robot cooperation. For this, we limit the maximum allowable velocity of the robot based on {{the distance to the}} human or to the next obstacle and generate the effective velocity using guidance informations provided by the interacting human. Therefore, we fuse the two heterogenous data types of a camera and a force torque sensor. The cameras are used to monitor the robot's workspace applying a difference image method. Given this obstacle information, distances are calculated between the robot and humans or objects in the environment respectively. The distance within each image is determined via an extended difference image method. The distances acquired from each camera are fused to approximate the real robot <b>to</b> <b>object</b> <b>distance</b> within the workspace. This distance regulates the maximum allowable velocity of the robot. The force/torque sensor provides the guidance information, i. e. amount, direction of the force and moment. This information is used to generate the robot's movement taking the maximum allowable velocity into consideration. Index Terms – human/robot cooperation, industrial robot, workspace supervision, difference image method, heterogeonous multisensor fusion, vision, force torque sensor I...|$|R
40|$|Detection of {{very fine}} defects in the width {{range of a}} few microns is very {{difficult}} by using conventional radiographic equipment, due to three limiting factors- contrast, definition and image graininess. Variables, such as X-ray energy, scattered radiation, type of film, processing parameters, film density, focal spot size, source <b>to</b> <b>object</b> <b>distance</b> etc, if controlled properly, can lead to radiographic image with improved quality and better flaw detection sensitivity. Image quality can be enhanced further by using microfocus X-ray tube having focal spot size from 1 to 50 micron. Microfocus X-ray machine when employed with projection radiography and real time radiography can result in ease of viewing a magnified image instantaneously. It becomes a very powerful tool for detecting microvoids and fine cracks in different materials and components having simple as well as complex geometry. However, due to high capital cost and requirement of dynamic vacuum for X-ray tube, microfocus equipments are used only in R&D sector and are rather less popular among common users. Considering {{the basic principles of}} image quality enhancement, potential of conventional X-ray machine was explored to detect the air gap of 30 to 50 micron width in...|$|R
40|$|In this paper, we {{demonstrate}} light field triangulation {{to determine}} depth distances and baselines in a plenoptic camera. Advances in micro lenses and image sensors have enabled plenoptic cameras {{to capture a}} scene from different viewpoints with sufficient spatial resolution. While <b>object</b> <b>distances</b> can be inferred from disparities in a stereo viewpoint pair using triangulation, this concept remains ambiguous when applied {{in the case of}} plenoptic cameras. We present a geometrical light field model allowing the triangulation to be applied to a plenoptic camera in order <b>to</b> predict <b>object</b> <b>distances</b> or specify baselines as desired. It is shown that distance estimates from our novel method match those of real objects placed in front of the camera. Additional benchmark tests with an optical design software further validate the model’s accuracy with deviations of less than ± 0. 33...|$|R
50|$|The lens is {{flexible}} and its curvature {{is controlled by}} ciliary muscles through the zonules. By changing the curvature of the lens, one can focus the eye on <b>objects</b> at different <b>distances</b> from it. This process is called accommodation. At short focal distance the ciliary muscle contracts, zonule fibers loosen, and the lens thickens, resulting in a rounder shape and thus high refractive power. Changing <b>focus</b> <b>to</b> an <b>object</b> at a greater distance requires the relaxation of the lens and thus increasing the focal distance.|$|R
60|$|The {{house of}} the forest of Lebanon had many windows in it; 'And there were windows in three rows, and light was against light in three ranks' (1 Kings 7:4). Windows are to let the light in at, and the eye out at, <b>to</b> <b>objects</b> at a <b>distance</b> from the house, and from those that are therein.|$|R
40|$|Abstract. The {{use of a}} novel {{motorized}} lens {{to perform}} segmentation of image sequences is presented in this paper. The lens {{has the effect of}} introducing small, repeating movements of the camera center so that <b>objects</b> appear <b>to</b> translate in the image by an amount that depends on the distance from the plane of focus. For a stationary scene, optical flow magnitudes are therefore directly related <b>to</b> three-dimensional <b>object</b> <b>distance</b> from the observer. We describe a segmentation procedure that exploits these controlled observer movements and present experimental results that demonstrate the successful extraction of objects at different depths. Potential applications of our approach include image compositing, teleconferencing, and range estimation...|$|R
40|$|AbstractThe {{idea that}} extra-retinal {{information}} about {{the orientation of the}} eyes could be used <b>to</b> judge an <b>object’s</b> <b>distance</b> has a long history, and has been the issue of considerable debate throughout this century. We here show that the poor performance in comparison with judgements of direction has geometrical rather than physiological reasons, and discuss why previous studies have misled us into believing that information about distance is even poorer than the geometry predicts...|$|R
40|$|Accommodation is {{the process}} by which the human eye changes its <b>focus</b> <b>to</b> see <b>objects</b> at varying <b>distances</b> from the eye. For nearly 300 years, {{scientists}} have investigated and presented various views on the mechanism of accommodation. The purpose of this review is to present both the historical and contemporary theories that underpin the process of accommodation. Keywords such as ocular accommodation, mechanism of accommodation and accommodative mechanism were used to retrieve published material on the subject. Classical propositions by Thomas Young and Hermann von Helmholtz, amongst others, are presented...|$|R
50|$|When {{a camera}} lens is <b>focused</b> <b>to</b> project an <b>object</b> some <b>distance</b> away onto the film or detector, the {{objects that are}} closer in distance, {{relative}} <b>to</b> the distant <b>object,</b> are also approximately in focus. The range of distances that are nearly in focus is called the depth of field. Depth of field generally increases with decreasing aperture diameter (increasing f-number). The unfocused blur outside the depth of field is sometimes used for artistic effect in photography. The subjective appearance of this blur is known as bokeh.|$|R
40|$|Both {{judgment}} {{studies and}} studies of feedforward reaching {{have shown that}} the visual perception of <b>object</b> <b>distance,</b> size, and shape are inaccurate. However, feedback has been shown to calibrate feedfoward reaches-to-grasp to make them accurate with respect <b>to</b> <b>object</b> <b>distance</b> and size. We now investigate whether shape perception (in particular, the aspect ratio of <b>object</b> depth <b>to</b> width) can be calibrated in the context of reaches-to-grasp. We used cylindrical objects with elliptical cross-sections of varying eccentricity. Our participants reached to grasp the width or the depth of these objects with the index finger and thumb. The maximum grasp aperture and the terminal grasp aperture were used to evaluate perception. Both occur before the hand has contacted an object. In Experiments 1 and 2, we investigated whether perceived shape is recalibrated by distorted haptic feedback. Although somewhat equivocal, the results suggest that it is not. In Experiment 3, we tested the accuracy of feedforward grasping with respect to shape with haptic feedback to allow calibration. Grasping was inaccurate in ways comparable to findings in shape perception judgment studies. In Experiment 4, we hypothesized that online guidance is needed for accurate grasping. Participants reached to grasp either with or without vision of the hand. The result was that the former was accurate, whereas the latter was not. We conclude that shape perception is not calibrated by feedback from reaches-to-grasp and that online visual guidance is required for accurate grasping because shape perception is poor. Copyright 2008 Psychonomic Society, Inc. link_to_subscribed_fulltex...|$|R
50|$|Visually {{impaired}} {{people may}} use monoculars <b>to</b> see <b>objects</b> at <b>distances</b> at which people with normal vision {{do not have}} difficulty, e.g., to read text on a chalkboard or projection screen. Applications for viewing more distant objects include natural history, hunting, marine and military. Compact monoculars are also used in art galleries and museums to obtain a closer view of exhibits.|$|R
5000|$|Reflecting telescopes, {{just like}} any other optical system, do not produce [...] "perfect" [...] images. The need <b>to</b> image <b>objects</b> at <b>distances</b> up <b>to</b> infinity, view them at {{different}} wavelengths of light, along with the requirement to have some way to view the image the primary mirror produces, means there is always some compromise in a reflecting telescope's optical design.|$|R
40|$|The {{idea that}} extra-retinal {{information}} about {{the orientation of the}} eyes could be used <b>to</b> judge an <b>object's</b> <b>distance</b> has a long history, and has been the issue of considerable debate throughout this century. We here show that the poor performance in comparison with judgements of direction has geometrical rather than physiological reasons, and discuss why previous studies have misled us into believing that information about distance is even poorer than the geometry predicts. (C) 2000 Elsevier Science Ltd...|$|R
40|$|Abstract—Time-of-Flight (ToF) cameras gain depth {{information}} by emitting amplitude-modulated near-infrared light and measuring the phase shift between the emitted and the reflected signal. The phase shift is proportional <b>to</b> the <b>object’s</b> <b>distance</b> modulo the wavelength of the modulation frequency. This {{results in a}} distance ambiguity. Distances larger than the wavelength are wrapped into the sensor’s non-ambiguity range and cause spurious distance measurements. We apply Phase Unwrapping to reconstruct these wrapped measurements. Our approach {{is based on a}} probabilistic graphical model. We use loopy belief propagation to detect and infer the position of wrapped measurements. Besides depth discontinuities, our method utilizes multiple modulation frequencies to identify wrapped measurements. In experiments, we show that wrapped measurements are identified and corrected, eve...|$|R
40|$|Abstract—Due to the {{inaccuracy}} and noisy, {{uncertainty is}} inherent in time series streams, and increases the complexity of streams clustering. For the continuous arriving and massive data size, efficient data storage is a crucial task for clustering uncertain data streams. With hash-compressed structure, an extended uncertain sketch and update strategy are proposed to store uncertain data streams. And based on divergence and sketch metric, a sketch based similarity is given <b>to</b> measure <b>objects</b> <b>distances.</b> Then with core-sets and the max-min cluster distance measure, an initial cluster centers selection algorithm is proposed {{to improve the quality}} of clustering uncertain time series streams. Finally, the effectiveness of the proposed clustering algorithm is illustrated through the experimental results...|$|R
