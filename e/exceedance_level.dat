19|72|Public
30|$|Both the NAAQS and the MAAQS for PM 10 are 150  µg/m 3. As {{shown in}} Fig.  3 e, the <b>exceedance</b> <b>level</b> of PM 10 {{can be seen}} for almost every year except in 2007 and 2010 for all stations. The highest <b>exceedance</b> <b>level</b> {{recorded}} for PM 10 was in mid- 2005 and mid- 2013 (less than 700  µg/m 3) at S 1. In addition to that, there were episodes where PM 10 levels were high for several days to weeks, for example, in 2005, 2006, 2008, 2009, 2012, 2014 and 2015. A study by Rahman et al. (2015) stated that S 1 had {{the highest number of}} exceedance events compared to S 2, S 3 and S 4, and these were related to severe haze episodes that transported suspended particulates from Sumatra to the west coast of Peninsular Malaysia.|$|E
40|$|International audienceWe {{develop new}} {{algorithms}} for spatial field re- construction, <b>exceedance</b> <b>level</b> estimation and classification in heterogeneous (mixed analog & digital sensors) Wireless Sensor Networks (WSNs). We consider spatial physical phenomena which are observed by a heterogeneous WSN, {{meaning that it}} consists partially of sparsely deployed high-quality sensors and partially of low-quality sensors. The high-quality sensors transmit their (continuous) noisy observations to the Fusion Centre (FC), while the low-quality sensors first perform a simple thresholding operation and then transmit their binary values over imperfect wireless channels to the FC. The resulting observations are mixed continuous and discrete (1 -bit decisions) observations, and are combined in the FC to solve the inference problems. We first formulate the problem of spatial field reconstruction, <b>exceedance</b> <b>level</b> estimation and classification in such heterogeneous networks. We show that the resulting posterior predictive distribution, which is key in fusing such disparate observations, involves intractable integrals. To overcome this problem, we develop an algorithm {{that is based on}} a multivariate series expansion approach resulting in a Saddle-point type approximation. We then present comprehensive study of the performance gain that can be obtained by augmenting the high-quality sensors with low-quality sensors using real data of insurance storm surge database known as the Extreme Wind Storms Catalogue...|$|E
3000|$|Daily maximum {{concentration}} of pollutants with respect to averaging hour of the Malaysian Ambient Air Quality Standard (MAAQS) and the National Ambient Air Quality Standard (NAAQS) of the United States Environmental Protection Agency (USEPA) were calculated and plotted to study the <b>exceedance</b> <b>level</b> of pollutants during the study period. Running average data for O 3 were 8  h and PM 10 were 24  h while CO, NO 2 and SO 2 were 1  h. The running times for different air pollutants were based on averaging times suggested by MAAQS and NAAQS of USEPA. In addition, wind speed, wind direction and air pollutant data were computed and analysed using statistical software Openair, R package version 3.3. 1 (Carslaw 2015) which can be downloaded free from the website [URL] [...]...|$|E
50|$|The use of {{a robust}} {{monitoring}} tool in providing accurate and timely information was an important aspect to the project. SRA Information Technology provided its EnviroSys software as the tool whereby turbidity monitoring and vessel tracking could occur in real time. Early warning alerts could be generated by the monitoring tool to inform when predefined <b>exceedance</b> <b>levels</b> had been triggered.|$|R
40|$|AbstractIn {{this paper}} we {{consider}} stationary sequences with extremal index θ, 0 <θ⪕ 1, and verifying {{an extension of}} Leadbetter's D(un) condition. For these sequences we prove that the limit law for high <b>level</b> <b>exceedances</b> is of the Compound Poisson Type and specify the parameters. We also give the joint limit law for <b>exceedances</b> of multiple <b>levels</b> and consequently, for any r upper order statistics...|$|R
30|$|This study aims to {{determine}} the long-term variation in concentrations of major air pollutants along with corresponding seasonal variation at selected air-quality monitoring stations in an urban environment in Malaysia. The analysed pollutants were CO, O 3, nitrogen dioxide (NO 2), SO 2 and PM 10, using data from an 11 -year period to assess the pollutant trends, seasonal effects and <b>exceedance</b> <b>levels</b> at each site. The statistical software Openair R version 3.3. 1 (Carslaw and Ropkins 2012) was used to conduct a supplementary analysis to assess concentration distributions in relation to meteorological factors. The results from the analysis are then further discussed {{in relation to the}} contribution of local sources to the atmospheric pollutant levels at all study sites.|$|R
40|$|Abstract: It {{has been}} known that the “background ozone ” level in urban cities is {{changing}} over the years. What is the background ozone and why this is changing is not entirely clear. This paper looks at one definition of background ozone level and using this definition to derive the background level of ozone using ambient quality data measured at the monitoring stations. From the derived background ozone level, {{it is possible to}} determine the change of background level from the early 1990 to the present day. The change or trend in background level at different monitoring stations will be accessed using the Long Range Dependent method and the results are shown to be not the same at different stations. This shows that the local conditions at each station are important in determining whether a quality management plan to reduce ozone below <b>exceedance</b> <b>level</b> is effective (or achievable) or not...|$|E
40|$|The {{rain rate}} {{distribution}} is the input data used in models predicting the rain attenuation distribution on microwave links. Some methods partially mitigating the rain attenuation {{are used in}} practice. The well known "site diversity" method is described in this contribution. The attenuation is obtained from the rain rates which are converted into the attenuation using the Assis-Einloft model. The rain rates are measured on 4 sites in the Czech Republic at distances from 8 to 150 km. It is shown that the site diversity gain is big (about 10 dB at 0. 01 % <b>exceedance</b> <b>level</b> at 12 GHz). The gain is increasing with the increasing distance (as expected) and is also {{a function of the}} azimuth of 2 sites. The north-south sites position has lower gain in comparison with the west-east position: it is due to the prevailing frontal motion from west to east in our country...|$|E
30|$|The <b>exceedance</b> <b>level</b> {{recorded}} for O 3 (Fig.  3 b) was quite high in number {{for all four}} stations in every year, especially {{during the first quarter}} of the year. The concentrations of O 3 for the 8  h average exceeded both the NAAQS (70  ppb) and the MAAQS (60  ppb). The number of O 3 exceedance events around Klang Valley can be seen from a study by Ahamad et al. (2014), where it was concluded that O 3 exceedance patterns were greatly influenced by localised pollutant emissions. According to a study by Latif et al. (2012), S 1 located near the sea and the shipping port may be influenced by sea breezes causing the dispersion of pollutants. In addition to that, S 3 and S 4 had high O 3 concentrations due to local conditions while S 2 had the lowest exceedance due to the titration process of O 3 by NO.|$|E
40|$|Noise {{events are}} well {{established}} in the measurement and management of aircraft noise. While there have been attempts to apply similar noise-event concepts to road and rail traffic noise signals for many decades, the idea has remained largely peripheral to the current paradigm of surface traffic noise measurement, assessment and management. The latter is based, almost exclusively, on metrics that utilize integrated energy of the traffic noise signal, or <b>exceedance</b> <b>levels.</b> This paper, as an introduction to a session that focuses on noise events from transportation noise, {{provides an overview of}} concepts and past findings on human responses of annoyance and interference with human activities, including sleep disturbance, that have been related to noise events and other pattern measures of the noise from surface traffic flows. Griffith Sciences, Griffith School of EnvironmentFull Tex...|$|R
40|$|Statistical {{inference}} for extremes {{has been}} a subject of intensive research during {{the past couple of}} decades. One approach is based on modeling exceedances of a random variable over a high threshold with the Generalized Pareto (GP) distribution. This has shown to be an important way to apply extreme value theory in practice and is widely used. In this paper we introduce a multivariate analogue of the GP distribution and show that it is characterized by each of following two properties: (i) exceedances asymptotically have a multivariate GP distribution if and only if maxima asymptotically are Extreme Value (EV) distributed, and (ii) the multivariate GP distribution is the only one which is preserved under change of <b>exceedance</b> <b>levels.</b> We also give a number of examples and discuss lowerdimensional marginal distribution...|$|R
40|$|Concentrations of {{tropospheric ozone}} (O 3) and <b>exceedance</b> of {{critical}} <b>levels</b> to vegetation {{have been investigated}} and mapped for Ireland. Hourly ozone concentration data (1995 – 1997) at 7 seven monitoring stations and the CORINE landcover database, supported by a Geographical Information System, were used. AOT 40 (Accumulated exposure Over a Threshold of 40 ppb) was calculated for daylight hours for each station, and mapped using surface interpolation. Average O 3 concentrations vary from year to year, and were estimated to be 28 ppb, 26 ppb and 24 ppb for 1995, 1996 and 1997 respectively. Ozone concentrations show a large diurnal variation, with a maximum {{in the afternoon and}} a minimum at night-time. The critical level for crops and (semi-) natural vegetation was exceeded in all years examined. The highest exceedance occurred in 1995, where the critical level was exceeded for almost 35 % of the mapped area. Approximately 15 % and 1 % of the mapped area was exposed to <b>exceedance</b> <b>levels</b> during 1996 and 1997 respectively. The maximum cumulative exposures (AOT 40) were approximately 5000, 3890 and 3230 ppbh in 1995, 1996 and 1997 respectively. The critical level for forests was not exceeded during the period of investigatio...|$|R
40|$|AbstractMore than 30, 000 {{steel strip}} {{reinforced}} soil walls {{have been built}} in Japan since their introduction in the early 1970 s. The current Japanese method of computing tensile loads in the reinforcement strips {{is based on the}} Coherent Gravity Method first developed in France more than three decades ago. At that time, the method was calibrated against measured loads from seven instrumented structures based on soil friction angles in the range of 35 – 46 °. In Japan, however, there are many reinforced soil walls that have been built successfully using cohesive-frictional soils with fines contents as high as 35 % and lower friction angles. The present paper uses the results of load measurements from 18 instrumented wall sections, reported previously in the literature, and nine instrumented Japanese walls to examine the prediction accuracy of the Coherent Gravity Method described in the Public Works Research Center (2003) guidelines. The current design chart for the coefficients of earth pressure, used to compute tensile reinforcement loads, is empirically adjusted for soil backfills falling into three different friction angle ranges. The new design chart is calibrated to satisfy an average load <b>exceedance</b> <b>level</b> that matches the value adopted when the Coherent Gravity Method was first calibrated...|$|E
40|$|Analysis of {{two years}} of {{measurements}} from a three-site satellite beacon diversity experiment in Norway is presented. The operating frequency was 19. 68 GHz, elevation angles were between 21. 7 ° and 22 °, and site separations 23, 29. 7 and 50. 1 km. Due to spatial decorrelation of rain, combined attenuation at these sites occurs much less frequently than at a single site. All three two-site combinations and a three-site combination were investigated. Measured values for diversity gain at 0. 01 % <b>exceedance</b> <b>level</b> were 8. 8, 10. 7 and 12. 1 dB for the two-site pairs and 12. 5 dB for three-sites, given a single site attenuation level between 13 and 16 dB. Comparison of the measured data showed excellent agreement with current ITU-R models. Fade duration statistics for single-site and for the combinations are analyzed and it is shown that the statistics for the diversity combinations can be modelled using a double-lognormal function {{as is the case}} for single-site statistics. Analysis of the effects of a non-ideal switch-over scheme showed that using moderate switch-over threshold levels and time delays, the number of switch-overs can be significantly reduced while most of the diversity gain and reduction in number of fades is retained...|$|E
40|$|A {{methodology}} concerning how {{to determine}} the correlation factors between individual long-term dynamic load components for the prediction of the combined total stress is presented. The combined stress in short-term sea states can be expressed by the square root of sum of squares of the load components with corresponding stress factors and relevant correlation factors. One of advantages for this formulation is that the correlation factors do {{not depend on the}} relative magnitudes of the individual stress components. The long-term stress is expressed by an equation similar in format to one derived for the shortterm sea states. The weighted average values of the correlation factors over wave scatter diagram entry and wave headings are defined as the long-term load combination factors. For illustration, the direct calculations of the load combination factors are performed for end longitudinal connections in the midship tank of a modern crude oil tanker. The calculation results show that the load combination factors for short-term sea states strongly depend on wave heading and average zero-up crossing wave period. For long-term multiple sea states, it is shown that the load combination factors are not sensitive to the selected probability of <b>exceedance</b> <b>level.</b> It is found, however, that the long-term load combination factors can be noticeably different depending on the cargo loading and environmental wave conditions. KEY WORDS: load combination factor; phase correlation; long-term load; fatigue assessmen...|$|E
40|$|A route {{optimization}} methodology in {{the frame}} of an onboard decision support/guidance system for the ship's master has been developed and is presented in this paper. The method aims at the minimization of the fuel voyage cost and the risks related to the ship's seakeeping performance expected to be within acceptable limits of voyage duration. Parts of this methodology were implemented by interfacing alternative probability assessment methods, such as Monte Carlo, first order reliability method (FORM) and second order reliability method (SORM), and a 3 -D seakeeping code, including a software tool for the calculation of the added resistance in waves of NTUA-SDL. The entire system was integrated within the probabilistic analysis software PROBAN. Two of the main modules for the calculation of added resistance and the probabilistic assessment for the considered seakeeping hazards with respect to <b>exceedance</b> <b>levels</b> of predefined threshold values are herein elaborated and validation studies proved their efficiency in view of their implementation into an on-board optimization system. © 2012 Harbin Engineering University and Springer-Verlag Berlin Heidelberg...|$|R
40|$|The December 2004 Sumatra-Andaman {{earthquake}} {{emphasized the}} need for a consistent and comprehensive assessment of tsunami hazard. We have developed a method for Probabilistic Tsunami Hazard Analysis (PTHA) based on the traditional Probabilistic Seismic Hazard Analysis (PSHA) and therefore completely consistent with standard seismic practice. In lieu of attenuation relations, it uses the summation of finitedifference Green’s functions that have been pre-computed for individual subfaults, which enables us to rapidly construct scenario tsunami waveforms from an aggregate of subfaults that comprise a single large event. For every fault system, it is then possible to integrate over sets of thousands of events within a certain magnitude range that represents a fully probabilistic distribution. Because of the enclosed nature of ports and harbors, effects of resonance need to be addressed as well, which is why we have extended this method to not only analyze <b>exceedance</b> <b>levels</b> of maximum wave height, but also of spectral amplitudes. As in PSHA, these spectral amplitudes can be matched with the spectral response of harbors, and thus allow a comprehensive probabilistic analysis of tsunami hazard in ports and harbors. ...|$|R
40|$|Abstract- The {{occurrence}} of dangerously {{high or low}} water levels at coastal locations is an important public concern and is {{a significant factor in}} coastal hazard assessment, navigational safety, and ecosystem management. The monthly highest and lowest water levels at 117 NOAA/National Ocean Service water level stations show a clear response to local mean sea level trends. The extreme levels reached by hurricanes and extra-tropical storms of the past can be adjusted for sea level trend, so that unbiased comparisons can be made. A data set of the annual highest and lowest water levels is derived from the monthly data and used to determine the expected frequency of future storm tides rising above or falling below any given level. The same analysis is also applied to the data for each individual month in order to estimate the varying likelihood of extreme high or low levels by season. The results are a set of annual and monthly <b>exceedance</b> probability <b>levels</b> relative to the tidal datums for each station. This information should prove useful for identifying, in real time, when a rare event threshold has been crossed. The <b>exceedance</b> probability <b>levels</b> can be adjusted in the future to reflect newly-updated tidal datums...|$|R
40|$|Fifty-four {{sediment}} {{samples of}} the five Northern Egyptian lakes, (Mariout, Edku, El-Burullus, El-Manzallah, and El-Bardaweel) were analyzed to investigate the pollution status of mercury (Hg). The total mercury (T-Hg) content in sediment samples ranged from 15. 33 to 171. 29 ng·g – 1 dry wt). The results showed that T-Hg were lower than the back ground values reported and also lower than the ranges of uncontaminated sediments. Moreover, the T-Hg concentrations in all sediments were under the upper chemical <b>Exceedance</b> <b>level</b> (1 µg·g – 1). The concentrations of Methyl mercury (MeHg) in surface sediments of the Northern lakes ranged from 0. 002 - 0. 023 ng·g – 1 dry wt. The contribution of MeHg was less than 0. 1 % of total mercury concentration with index values from 0. 08 - 1. 37 ng·g – 1; dry wt). MeHg showed insignificant correlation with T-Hg. This suggested that MeHg contents were not controlled by the T-Hg in sediments. The T-Hg and MeHg concentrations were insignificantly correlated with TOC content which indicates that the concentration of T-Hg and MeHg in sediments of Northern lakes were not influence by TOC. The average T-Hg concentration {{was found in the}} following order; Mariout > El-Manzallah > El-Burullus > Edku > El-Bardaweel. While the MeHg was found in the order; El-Bardaweel > El-Burullus ≥ El-Manzallah > Mariout > Edku...|$|E
40|$|In {{this paper}} the TNO gust {{analysis}} method {{and the resulting}} TNO gust model are described. The method {{has been applied to}} a set of 700 hours of stationary wind speed time series measured at the meteorological mast at Cabauw, The Netherlands. The results are discussed in this paper. The TNO gust model has been developed for the calculation of wind turbine loads, especially fatigue loads. To model gusts an analysis method has been developed to statistically analyze full-scale wind speed data and translate these to discrete gusts. The main result of the TNO gust model is that finally, all gust amplitudes are described by one single expression being a function of the height, the mean wind speed, the turbulence intensity, the gust duration and the probability <b>exceedance</b> <b>level</b> within an error band of less than 5 %. The model also gives a relation between the gust duration and the frequency of occurence of the gusts. The TNO gust model has been incorporated in the Dutch Handbook 'Wind Data for Wind Turbine Design'. Verification of this handbook has been performed by comparing the flap and lag loads on the blade root of three different wind turbines by means of the Handbook with the loads measured. The comparison showed very good agreement especially in the range 10 2 to 10 8 load fluctuations per year. © 1992...|$|E
40|$|In Utah {{during the}} 1960 s, {{the cost of}} {{producing}} electrical energy was as much, {{or in some cases}} more, by hydroelectric generation than by plants using steam from coal fired boilers. The relatively high hydropower cost was generally attributed to maintenance and replacement costs associated with plants that had been build in the 1920 s. Utah Power 2 ̆ 6 Light Company during the 1960 period decided not to renew power licenses and to abandon many small hdyroplants. Since 1973, rising coal and related fossil fuel costs have caused steam generation costs to accelerate and have made hydroelectric generation relatively more attractive. However, the capital cost of replacing deteriorated pipelines and restoring plants to production capability is high, and the prospect of large capital investment during periods of high interest rates creates a hesitancy to renovate existing or to construct new small hydro units. The cost analysis to replace abandoned plants or to construct new plants has been generally based on restoring an existing configuration or building to design standards in use {{at the time of the}} original structure. The traditional design method was to design a pipeline on a flat slope with a relatively large pipe diameter. This method maximized head, but minimized the flow. The resultant energy was therefore less than the potential, but constant. This method also confined the variations in flow to a range that could be handled by a single, or the most two, variable geometry turbines. The flow point on the typical flow duration curve for western mountain streams where the ratio of maximum to minimum flow variation is 4 to 1 or less is at is at or near the 25 percent <b>exceedance</b> <b>level.</b> It is shown in this report that the same diameter pipeline as used in traditional design can by sloped to maximize the power output of the plant (powermax slope) and thus increase the annual energy production by 149 to 186 percent, the difference being dependent upon the amount of energy recovered by the static regain in pressure pipelines when flows are reduced below the maximum. This optimized flow and head without changing the cost of the pipeline. The effect is to reduce the unit cost of energy produced. The higher flow at the powermax slope has a greater variability and will therefore require turbines with greater variability. It is demonstrated that multiple fixed geometry turbines sized in binary steps can effectively span flow variability ratios from 10 to 1 or greater and be installed at less cost than custom designed variable geometry units. Thus, designing at the points on the flow duration curve corresponding to the 10 percent or lower <b>exceedance</b> <b>level</b> is economically feasible. Combining the powermax concept for pipelines with the concept of using binary sized turbines and a pressure system to use the static regain concept can result in hydro plant designs that utilize a greater portion of the potential energy at a given site and reduce the unit cost of energy...|$|E
40|$|The {{author has}} {{identified}} the following significant results. The Skylab S- 193 radiometer/scatterometer collected thousands of measurements of scattering coefficient and brightness temperature over {{various parts of}} the United States during the summer of 1973 at angles of incidence between vertical and about 45 deg. These measurements have been combined to produce histograms of the response at each of several angles within this range, and to establish average scattering coefficient vs angle curves with 10 % and 90 % <b>exceedance</b> <b>levels</b> as well. The variation of the radiometeric measurements is primarily in the region from 255 K to 285 K, with very few measurements giving values down to and even below 200 K. The scattering coefficient varies, for the mean, from about 0 db at 1 deg off vertical to a low in the neighborhood of - 10 db at 45 deg. The variability of the scattering coefficient measurements with this coarse resolution sensor is surprisingly small. The number of distinguishable levels is slightly more for the scatterometer than for the radiometer, but the amount of variation in brightness temperature caused by the physical temperature of the ground is enough so that the scatterometer can be used to distinguish significantly more meaningful levels than the radiometer...|$|R
40|$|Noise {{processing}} {{experiments with}} ELF (3 to 300 Hz) atmospheric noise and signals in the 40 to 80 Hz range are described. The {{primary purpose of}} the experiments was to record and analyze wideband ELF noise in order to design the noise processing portion of a receiver which minimizes the required transmitter power. The application of appropriate theory and extensive simulations led to a noise processor which consists of the following functions: (1) a compensating (or whitening) filter, (2) a prenotch filter clipper, (3) notch filters at frequencies of manmade interference (e. g., power lines), (4) a post-notch filter clipper, and (5) a phase-coherent linear matched filter. The nonlinear processing provides considerable gain relative to a linear receiver (i. e., a receiver consisting only of a matched filter and appropriate whitening filters). It is convenient to measure sys tem performance in terms of an "effective noise level" which is equal to twice the received signal energy divided by the signal to noise ratio at the matched filter output. For example, the highest effective noise levels observed at 45 Hz with the nonlinear processor were about - 134, - 131 and - 137 dB wrt 1 amp/m [Hz] using Saipan, Malta and Norway data, respectively, compared to 1 percent <b>exceedance</b> <b>levels</b> of effective noise for the linear receiver of about - 115, 115 and - 130 dB wrt 1 amp/m [Hz] respectively...|$|R
40|$|For a {{sequence}} of independent, identically distributed random variables any limiting point process for the time normalized <b>exceedances</b> of high <b>levels</b> is a Poisson process. However, for stationary dependent sequences, under general local and asymptotic dependence restrictions, any limiting point process for the time normalized <b>exceedances</b> of high <b>levels</b> is a compound Poisson process, i. e., there is a clustering of high exceedances, where the underlying Poisson points represent cluster positions, and the multiplicities correspond to the cluster sizes. For such classes of stationary sequences there exists the extremal index theta, 0 0 for "almost all" cases of interest. The estimation of the extremal index {{through the use of}} the Generalized Jackknife methodology, possibly together with the use of subsampling techniques, is performed. Case studies in the fields of environment and finance will illustrate the performance of the new extremal index estimator comparatively to the classical one. (C) 2007 Elsevier B. V. All rights reserved...|$|R
40|$|Abstract. —The {{relationship}} between the movement of small (, 150 -mm) Dolly Varden Salvelinus malma and cutthroat trout Oncorhynchus clarkii and stream discharge is not well known in streams of southeast Alaska. We measured movement in a small headwater stream using passive integrated transponder (PIT) tags and stationary antennas to record time and date of movement. Fish with PIT tags were detected by transceivers and stationary antennas in the stream. The date and time of detection at an antenna were matched with stream discharge (m 3 /s) at the same date and time. Most Dolly Varden moved upstream during late summer and early fall. Most cutthroat trout movement was in May, and movement declined through the summer. Few fish moved during the winter. Most fish moved within a narrow discharge range, with a few moving at higher discharges. More than 97 % of fish from both species were detected as moving upstream at discharges below the 5 % <b>exceedance</b> <b>level</b> during the 4 -year period of discharge measurements. Dolly Varden and cutthroat trout moved throughout {{the entire length of}} usable habitat in the stream. Connectivity throughout watersheds even within headwater streams is important and can be maintained for these species by use of road crossings that ensure passage over a range of flow conditions such as those described here. Recent studies in southeast Alaska have demonstrat-ed that both resident and anadromous salmonids ar...|$|E
40|$|Tunnels, culverts, and subway {{stations}} {{are the main}} parts of an integrated infrastructure system. Most of them are constructed by the cut-and-cover method at shallow depths (mainly lower than 30 m) of soil deposits, where large-scale seismic ground deformation can occur with lower stiffness and strength of the soil. Therefore, the transverse racking deformation (one of the major seismic ground deformation) due to soil shear deformations {{should be included in}} the seismic design of underground structures using cost- and time-efficient methods that can achieve robustness of design and are easily understood by engineers. This paper aims to develop a simplified but comprehensive approach relating to vulnerability assessment in the form of fragility curves on a shallow two-story reinforced concrete underground box structure constructed in a highly-weathered soil. In addition, a comparison of the results of earthquakes per peak ground acceleration (PGA) is conducted to determine the effective and appropriate number for cost- and time-benefit analysis. The ground response acceleration method for buried structures (GRAMBS) is used to analyze the behavior of the structure subjected to transverse seismic loading under quasi-static conditions. Furthermore, the damage states that indicate the <b>exceedance</b> <b>level</b> of the structural strength capacity are described by the results of nonlinear static analyses (or so-called pushover analyses). The Latin hypercube sampling technique is employed to consider the uncertainties associated with the material properties and concrete cover owing to the variation in construction conditions. Finally, a large number of artificial ground shakings satisfying the design spectrum are generated in order to develop the seismic fragility curves based on the defined damage states. It is worth noting that the number of ground motions per PGA, which is equal to or larger than 20, is a reasonable value to perform a structural analysis that produces satisfactory fragility curves...|$|E
40|$|The paper {{deals with}} {{some aspects of}} {{modelling}} catastrophic risk and with its application to non- -life insurance claims. First, we formulate the problem of generalization of classical Cramér-Lundberg collective risk model. Then using some well-known extreme value results we study two methods for extremal claims registration. Finally, we apply the theoretical results for real insurance data. As suitable mathematical models for large insurance claims are used heavy-tailed distributions (subexponential, stable and max-stable distributions). The main reason why {{we are interested in}} stable distributions is, that for the extreme value distributions the classical central limit theorem (CLT) condition (finite mean and variance) doesn‘t hold. Instead of CLT we use the Fisher-Tippett theorem which specifies the limit laws for maximum of independent identically distributed (iid) random variables as Generalised Extreme Value (GEV) distribution. For recording extreme insurance claims we use two approaches. The first one is based on modelling maximum of the sample and called method of block-maxima. This method is based just on the Fisher-Tippett theorem and in non-life insurance we can use it for non-proportional Largest Claim Reinsurance (LCR). The second approach is based on modelling excess values over the chosen threshold. This approach is called Peaks Over Threshold method and is based on the Picands theorem which specifies the limit law for the exceedances as Generalised Pareto Distri- bution (GPD). This method is used in non-proportional Excess-of-Loss Reinsurance (XL). In the end, we apply these methods for modelling real fire insurance claims. We find an optimal <b>exceedance</b> <b>level</b> for reinsurance and identify lognormal distribution for all data and Pareto distri- bution for the tail. The empirical data are compared with considered theoretical distribution using chi-squared and Kolmogorov-Smirnov goodness-of-fit tests. For detailed statistical analysis of data we use STATGRAPHICS and its procedure Distribution fitting...|$|E
30|$|The {{results show}} that a change in epsilon-based record {{selection}} decreases the probability of <b>exceedance</b> expected performance <b>levels</b> by less than 10 %, 15 %, and 18 % for 72 -, 475 -, and 2, 475 -year return periods, respectively. It seems that the regarded typical building (steel frame with concrete shear walls) in high hazard levels is safe for collapse in the site.|$|R
30|$|Throughout this paper, let {ξ_i, i≥ 1 } be a {{standardized}} strongly dependent stationary normal sequence with correlation coefficients r_ij=Cov(ξ_i,ξ_j). C {{stands for a}} constant which may vary from line to line and ‘→’ for the convergence as n→∞. The remainder of the paper is organized as follows. In Section  2, we define an in plane Cox process and prove that the time-normalized point process N_n of <b>exceedances</b> of <b>levels</b> u^(1)_n, u^(2)_n,..., u^(r)_n by {ξ_i, 1 ≤ i≤ n} converges in distribution to the in plane Cox process. In Section  3, as the applications of our main result, the asymptotic results of the probabilities P(a_n(M_n^(2)-b_n)≤ x, L_n^(2)/n≤ t), and P(a_n(M_n^(1)-b_n)≤ x_ 1, a_n(M_n^(2)-b_n)≤ x_ 2) are established.|$|R
40|$|Sediment acid {{volatile}} sulﬁde (AVS) {{concentrations were}} measured in wadeable streams {{of a wide}} variety of ecoregions of western Europe (84 sites in 10 countries and nine ecoregions) to better understand spatial distribution and ecoregion relationships. Acid volatile sulﬁde has been shown to be a major factor controlling the bioavailability and toxicity of many common trace metals, such as Cd, Cu, Ni, Pb, and Zn. Sediment characteristics varied widely. The ratio of the sum of the simultaneously extracted metals (SEM) to AVS ranged from 0. 03 to 486. 59. The SEM-AVS ranged from 40. 02 to 17. 71 mol/g. On a regional scale, sediment characteristics such as dominant parent soil material showed signiﬁcant trends in AVS distribution and variation by ecoregion. Total Fe and Mn were correlated weakly with SEM concentrations. Three AVS model approaches (i. e., the SEM:AVS ratio, SEM-AVS difference, and carbon normalization) were compared at threshold <b>exceedance</b> <b>levels</b> of SEM/AVS 9, SEM-AVS 2, and SEMAVS/fOC 150 mol/g organic carbon (OC). Only 4. 76 % of the sediments exceeded all three AVS thresholds; 22. 6 % of the sediments exceeded two models; and 13 % of the sediments exceeded one model only. Using the SEM:AVS, SEM-AVS, and fraction of organic carbon models, and including site-speciﬁc data and regional soil characteristics, ecoregions 1 (Portugal), 3 (Italy), 4 (Switzerland), and 9 (Belgium/Germany) had the highest potential metals toxicity; ecoregions 13 and 8 (Belgium/France) showed the lowest potential toxicity. However, because AVS can vary widely spatially and temporally, these data should not be considered as representative of the sampled ecoregions. The general relationship between AVS levels and sediment characteristics provides some predictive capability for wadeable streams in the European ecoregions...|$|R
40|$|AbstractCurrent {{practice}} for yield prognosis of {{solar thermal power}} plants simulates the average annual performance by using a typical meteorological year data set (TMY). This represents the long-term average or a 50  % probability of exceedance(P 50) ofdirect normal irradiance (DNI) at the project's location. For more conservative risk evaluation it is common practice to calculate the 90  % yield <b>exceedance</b> <b>level</b> (P 90) by estimating {{the uncertainty of the}} long-term DNI which depends on data set uncertainty and inter-annual variability. A simple approach to calculate the P 90 yieldis to assume a normal distribution for this uncertaintyand a direct 1 : 1 relation of DNI averages to the yields. However, since the relation of DNI to energy yield is actually not linear it becomes more and more popular to calculate it from annual meteorological data sets (MY 90), which are representing P 90 DNI averages at a realistic distribution of actual values in the same time resolution as the P 50 TMY. Applying such MY 90 data sets still has the shortcoming that they are synthetic, whilereal years of data should lead to more realistic yields. Thus, this paper proposes the use of multiple years of weather inputto realistically include the annual variability of DNI. To also represent the effect of the data set uncertainty,thetime-series are modifiedin such away that the annual DNI values follow a normal distribution with a 1 -sigma width equivalent to the diagnosed data set uncertainty. The impact of this probabilistic approach on the energy yield of a CSP project is shown for thesite Bom Jesus da Lapa in Brazil. Since the estimation of a realistic uncertainty of the long-term DNI at this location was challenging, several uncertainties between 3 - 9  % were assumed that could possibly be inherent in such a data set. Using theseassumed data set uncertainties and theinter-annual variability of the data set, the deviations to the long-term meanof energy yield are shown for the current practice approaches and the new method. Hence for a data set uncertainty of 5  %the very basic risk analysis results in a single-year P 90 yield 11. 1  % below P 50,while using a MY 90 single year data set is resulting in a P 90 yield 9. 7  % below P 50. The probabilistic approach introduced here is leading to P 90 yields 8. 5  % below P 50...|$|E
40|$|Deep Bay {{is located}} in the northwestern coast of Hong Kong (HK), where {{brackish}} water from the Pearl River Estuary meets and interacts with fresh water from Shenzhen River and Yuen Long Creek. A review of published material in this study indicates rapid economic and industrial developments can be found in Hong Kong and Pearl River Delta (PRD) region in the last 60 years, which would have contaminated the sediment in Deep Bay with heavy metals. To examine the nature of metal contamination history, two 2 m-long sediment cores are collected from the mud flat of Deep Bay, and the chemical and physical properties of the sediment sequence analyzed. Small disturbance of sediment profile is observed by the fluctuation of 210 Pb signal, and constant rate of supply (CRS) model is applied for the calculation of sedimentation rate which is estimated to be 1. 82 cm/year. 137 Cs dating resolves two peaks for the radionuclide at 28 cm and 109 cm, as well as the onset of excessive 137 Cs activity at 135 cm, which are connected to the Chernobyl accident in 1986 and the banning and beginning of atmospheric testing of nuclear weapons in 1963 and 1950 respectively. Particle size analysis shows the core sediments are predominantly silt (4 - 64 μm) and clay(< 4 μm). Enrichment factor of metal concentration displays that Cd, Cr, Cu and Zn has been significantly enriched since the 1950 s, and hence 3 phases of metal enrichment could be identified: 1) insignificant anthropogenic input in preindustrial period before 1950, 2) significant enrichment of metal from anthropogenic sources during industrial stage in HK from 1950 to 1980, and 3) a further increase of metal enrichment after the introduction of new town development in northwestern part of HK and Chinese economic reform since 1980. Among the metals in the sediments at depth over 70 cm, Cu and Zn are found to be exceeded the Lower Chemical <b>Exceedance</b> <b>Level</b> of the sediment quality criteria given by the Hong Kong Environmental Protection Department; hence, the metals would impose threats to the natural environment once they are released back to water column by changes to physical conditions. To evaluate the extent of environmental threats, future studies could focus on the bioavailability of the metals and the interaction of metals in sediments and water with organisms in the ecosystem of Deep Bay. published_or_final_versionEarth SciencesMasterMaster of Philosoph...|$|E
40|$|The Deep Bay Catchment is a transboundary {{region of}} two Chinese {{metropolitan}} cities -Hong Kong and Shenzhen. The Shenzhen River {{serves as a}} natural border between these two cities with distinctive political, economic and social backgrounds. The wetland located at the river mouth has been recognized as an internationally important wetland under the Ramsar Convention since 1995. Nevertheless, the landscape in this border region has been transformed drastically due to rapid urbanization since {{the establishment of the}} Shenzhen Special Economic Zone in 1979. This study attempted to investigate habitat change in this transboundary region {{in the past two decades}} and its implications for spatial integration and nature conservation. Firstly, habitat and land cover change in the Deep Bay Catchment was quantified with the aid of remote sensing technology and GIS. Results demonstrated a pronounced contrast of landscape on the south and north side of the catchment. The north side of the catchment (Shenzhen) was highly urbanized with 248 km 2 of urban area, compared with the relatively rural Hong Kong side with 89 km 2 of urban area in 2013. Besides, the ecological value of habitats in Hong Kong was considerably higher than its Shenzhen counterpart. Overall, a degradation of the ecological value of the landscape was found between 1993 and 2013, as a consequence of the loss in agricultural area and fishponds. It is asserted that political and economic factors were primary drivers of the dissimilarity in land use. The establishment of China’s first Special Economic Zone in Shenzhen and the designation of a Frontier Closed Area by the British colonial government contributed substantially in shaping the land use. Secondly, data on rivers, marine water and sediment quality within the Deep Bay Catchment were explored. Results of statistical tests indicated that water quality of rivers on the Hong Kong side had been improving in the past two decades, albeit under conditions of considerable urban sprawl. Marine water quality in the Deep Bay has remained unacceptable and frequently failed the Marine Water Quality Objectives. Besides, some records of heavy metals including Cu, Cr, Ni, Pb and Zn exceeded the Hong Kong Lower Chemical <b>Exceedance</b> <b>Level,</b> suggesting that Deep Bay has been contaminated with heavy metals. 16 PAHs in marine sediment have been explored and the Mann-Kendall Trend test identified an increasing trend of pyrene at a monitoring station in Deep Bay. Analysis of the nesting population of egretries in the Deep Bay Catchment showed that the overall population has been stable, yet a decrease in species diversity from five to three species was found. Habitat change within two kilometers of egretries was analyzed with results suggesting that the loss of foraging habitat played a crucial role in reducing the nesting population. This study is the first comprehensive research on changes inland use, water quality and egretries in this border region from catchment and transboundary perspectives. Several policy recommendations including the adoption of Integrated Coastal Zone Management and Strategic Environmental Assessment are proposed for improving the sustainability of this ecologically sensitive catchment. published_or_final_versionGeographyDoctoralDoctor of Philosoph...|$|E
40|$|The {{association}} can {{be useful}} to model the approximate independence in the extreme value theory. The present paper proposes to study the limiting compound Poisson process for <b>exceedances</b> of high <b>levels</b> by associated variables. We give a sufficient condition to get this limit based on the bivariate dependence structure of an associated sequence. The application of the dependence condition introduced is illustrated with auto-regressive sequences. Extreme values Association Point processes...|$|R
40|$|Abstract The {{objective}} {{of this study is}} to provide a perspective on the extremes of sea-level variability and predictability for the U. S. -Affiliated Pacific Islands (USAPI) on seasonal time-scales. Based on the Generalized Extreme Value (GEV) model, the L-moments method has been used to estimate the model parameters. The bootstrap method has been used to define the <b>exceedance</b> probability <b>level</b> of upper and lower bounds of the return periods at the 90 % confidence interval. On the basis of these return calculations and expected extremes of high sea level, the seasonal maxima of sea level and the varying likelihood of extreme events have been estimated. For analyzing the predictability of the extremes of sea-level, a canonical correlation analysis (CCA) statistical model has been developed. Findings reveal that there is seasonal climatol...|$|R
40|$|AbstractConsider a {{stationary}} sequence Xj=supiciZj−i,j∈I, where {ci} is {{a sequence of}} con {Zi} a sequence of i. i. d. random variables with regularly varying tail probabilities. For suitable normalizing functions υ 1, υ 2,…, the limit form of the two dimensional point process with points (jn,υ− 1 n(Xj)),j∈I, is derived. The implications of the convergence are briefly discussed, while {{the distribution of the}} joint <b>exceedances</b> of high <b>levels</b> by {Xj} is explicitly obtained as a corollary...|$|R
