4|42|Public
40|$|The {{primary purpose}} of this report is to assess the spatial {{variability}} and uncertainty of bulk thermal conductivity in the host horizon for the repository at Yucca Mountain. More specifically, the lithostratigraphic units studied are located within the Topopah Spring Tuff (Tpt) and consist of the upper lithophysal zone (Tptpul), the middle nonlithophysal zone (Tptpmn), the lower lithophysal zone (Tptpll), and the lower nonlithophysal zone (Tptpln). Design plans indicate that approximately 81 percent of the repository will be excavated in the Tptpll, approximately 12 percent in the Tptpmn, and the remainder in the Tptul and Tptpln (BSC 2004 [DIRS 168370]). This report provides three-dimensional <b>geostatistical</b> <b>estimates</b> of the bulk thermal conductivity for the four stratigraphic layers of the repository horizon. The three-dimensional <b>geostatistical</b> <b>estimates</b> of matrix and lithophysal porosity, dry bulk density, and matrix thermal conductivity are also provided. This report provides input to various models and calculations that simulate heat transport through the rock mass. These models include the ''Drift Degradation Analysis, Multiscale Thermohydrologic Model, Ventilation Model and Analysis Report, Igneous Intrusion Impacts on Waste Packages and Waste Forms, Drift-Scale Coupled Processes (DST and TH Seepage) Models'', and ''Drift Scale THM Model''. These models directly or indirectly provide input to the total system performance assessment (TSPA). The main distinguishing characteristic among the lithophysal and nonlithophysal units is the percentage of large-scale (centimeters-meters) voids within the rock. The Tptpul and Tptpll, as their names suggest, have {{a higher percentage of}} lithophysae than the Tptpmn and the Tptpln. Understanding the influence of the lithophysae is of great importance to understanding bulk thermal conductivity...|$|E
40|$|This is a {{case study}} {{illustrating}} the application of geostatistics to a vein-type nickel deposit. Data are defined {{in relation to the}} structural aspects of the geology of the deposit and variograms are calculated for thickness and nickel accumulation. Variogram models are validated by the back estimation technique. A shape preserving spline surface is fitted to the mid-points of drill hole intersections with the orebody and this surface is used to control subsequent estimation. Various drilling densities are evaluated, global reserves are calculated and orebody shape and location are estimated on various horizontal planes. <b>Geostatistical</b> <b>estimates</b> of reserves and orebody shape are compared with the known orebody in a mined area. P. A. Dowd and D. W. Milto...|$|E
40|$|<b>Geostatistical</b> <b>estimates</b> of a soil {{property}} by kriging are {{equivalent to}} the best linear unbiased predictions (BLUPs). Universal kriging is BLUP with a fixed-effect model that is some linear function of spatial coordinates, or more generally a linear function of some other secondary predictor variable when it is called kriging with external drift. A problem in universal kriging {{is to find a}} spatial variance model for the random variation, since empirical variograms estimated from the data by method-of-moments will be affected by both the random variation and that variation represented by the fixed effects. The geostatistical model of spatial variation is a special case of the linear mixed model where our data are modelled as the additive combination of fixed effects (e. g. the unknown mean, coefficients of a trend model), random effects (the spatially dependent random variation in the geostatistical context) and independent random error (nugget variation in geostatistics). Statisticians use residual maximum likelihood (REML) to estimate variance parameters, i. e. to obtain the variogram in a geostatistical context. REML estimates are consistent (they converge in probability to the parameters that are estimated) with less bias than both maximum likelihood estimates and method-of-moment estimates obtained from residuals of a fitted trend. If the estimate of the random effects variance model is inserted into the BLUP we have the empirical BLUP or E-BLUP. Despite representing {{the state of the art}} for prediction from a linear mixed model in statistics, the REML-E-BLUP has not been widely used in soil science, and in most studies reported in the soils literature the variogram is estimated with methods that are seriously biased if the fixed-effect structure is more complex than just an unknown constant mean (ordinary kriging). In this paper we describe the REML-E-BLUP and illustrate the method with some data on soil water content that exhibit a pronounced spatial trend...|$|E
30|$|The Case HE 2 (Figs.  8 c, d) can be {{compared}} to the results obtained in Case 3 (true source location in Fig.  7) of Butera et al. (2013). The <b>geostatistical</b> approach <b>estimates</b> a large confidence interval at the head and at the tail of the estimated release function; while MRE at the same times estimates non zero concentration values but it presents a narrow confidence interval.|$|R
40|$|The {{modifiable}} areal unit problem (MAUP) is {{a problem}} by which aggregated units of data influence the results of spatial data analysis. Standard GWR, which ignores aggregation mechanisms, cannot be considered {{to serve as an}} efficient countermeasure of MAUP. Accordingly, this study proposes a type of GWR with aggregation mechanisms, termed area-to-point (ATP) GWR herein. ATP GWR, which is closely related to <b>geostatistical</b> approaches, <b>estimates</b> the disaggregate-level local trend parameters by using aggregated variables. We examine the effectiveness of ATP GWR for mitigating MAUP through a simulation study and an empirical study. The simulation study indicates that the method proposed herein is robust to the MAUP when the spatial scales of aggregation are not too global compared with the scale of the underlying spatial variations. The empirical studies demonstrate that the method provides intuitively consistent estimates...|$|R
40|$|Spatial {{heterogeneity}} is {{a striking}} feature of the blue crab life history and fisheries in Chesapeake Bay. However, a quantitative assessment of their spatial distribution and the factors controlling it has been lacking. Based on 13 years of data from a baywide winter dredge survey, geostatistical and two-stage generalized additive models (GAMs) are used to characterize blue crab distributions and investigate environmental factors responsible for the distribution of mature females, respectively. A landscape-based distance metric, the "Lowest-Cost Path" (LCP) distance, is developed {{as an alternative to}} Euclidean distance for kriging in estuaries. Estimates of variogram parameters differed significantly between the two metrics but kriging accuracy did not. <b>Geostatistical</b> abundance <b>estimates</b> show significant declines from 1990 to 2002. The observed relationship between changes in distribution and changes in abundance is suggestive of density-dependent habitat selection. Depth and distance from the Bay mouth were the most important predictors of mature female abundance...|$|R
40|$|A {{statistical}} model {{for assessing the}} risk of subsidence in abandoned mines is presented. The model {{is based on the}} relationship that exists between the frequency and location of subsidence events and the physical conditions of the ground. These conditions are described by geological, mining, and physical variables. The model suggests the existence of regions in the multi-dimensional space of variables which can be associated with increases, or decreases, in the frequency of subsidence events. Regions associated with an increase in the frequency of subsidence events correspond to regions of higher risks, and vice versa. Risk is assessed by expressing the limits of these high and low risk regions in the space of variables, and by expressing the degree of membership of blocks of land within any of these regions. The theoretical framework for the model is extracted from discriminant analysis. The high and low risk regions are associated with two populations: (1) blocks which according to their ground properties are not likely to develop subsidence, and (2) blocks which are likely to develop subsidence. Risk is quantified by the probabilities of membership of blocks of land into any of these two populations. These membership probabilities are computed using discriminant functions which use <b>geostatistical</b> <b>estimates</b> of the ground's properties and the number of subsidence events registered in each of the blocks. Risk maps are produced by displaying membership probabilities contoured in appropriate levels. The model was applied in two urban areas: Penn Hills, near Pittsburgh, and Scranton/Wilkes-Barre in northeastern Pennsylvania. At Penn Hills, the risk maps generated were sensitive to the equal-covariance and multi-normality assumptions of the model. The risk map generated under a non-parametric approach resulted in closer agreement and comparable to an independently generated risk map. Both maps succeed in locating recent subsidence events inside medium and high risk zones in seven out of eight cases. In the Scranton/Wilkes-Barre area, the risk maps generated under the equal-covariance and the multi-normality assumptions, as well as that generated under the non-parametric approach, reproduce well the present degree of subsidence in the area...|$|E
40|$|Over 270 single-hole (Guzman et al., 1996) and 44 cross-hole {{pneumatic}} injection tests (Illman et al., 1998; Illman, 1999) {{have been}} conducted at the Apache Leap Research Site (ALRS) near Superior, Arizona. They {{have shown that the}} pneumatic pressure behavior of fractured tuff at the site is amenable to analysis by methods which treat the rock as a continuum on scales ranging from meters to tens of meters, and that this continuum is representative primarily of interconnected fractures. Both the single-hole and cross-hole test results are free of skin effect. Single-hole tests have yielded estimates of air permeability at various locations throughout the tested rock volume, on a nominal support scale of about 1 m. The corresponding log permeability data exhibit spatial behavior characteristic of a random fractal and yield a kriged estimate of how these 1 -m scale log permeabilities vary in three-dimensional space (Chen et al., 2000). Cross-hole tests have been analyzed by means of a three-dimensional inverse model (Vesselinov et al., 2000) in two ways: (a) by interpreting pressure records from individual borehole monitoring intervals, one at a time, while treating the rock as if it was spatially uniform; and (b) by using the inverse model to interpret pressure records from multiple tests and borehole monitoring intervals simultaneously, while treating the rock as a random fractal characterized by a power variogram. The first approach has yielded equivalent air permeabilities and air-filled porosities for a rock volume characterized by a length-scale of several tens of meters. Comparable results have been obtained by means of type-curves (Illman and Neuman, 2001). The second approach amounts to three-dimensional pneumatic tomography, or stochastic imaging, of the rock. It has yielded a high-resolution <b>geostatistical</b> <b>estimate</b> of how air permeability and air-filled porosity, defined over grid blocks having a length-scale of 1 m, vary throughout the modeled rock volume. These tomographic images are comparable to those obtained by the kriging of 1 -m scale log permeability data from single-hole tests. The results reveal a highly pronounced scale effect in permeability and porosity at the ALRS. We analyze the scaling of permeability at the site {{on the basis of a}} recent theory, which is consistent with our representation of the rock as a random fractal...|$|R
40|$|The {{problem of}} {{estimating}} areal averages from point measurement {{has been extensively}} studied by mining engineers and hydrologists. Its application to satellite measurements has recently been introduced. The semivariaogram {{has been used in}} many <b>geostatistical</b> applications to <b>estimate</b> spatial structures of observed properties, such as mineral distributions. An examination is made of snow variations in Colorado from daily snow data collected in 11 SNOTEL stations. The associated semivariogram is estimated. The objective is to estimate the spatial structure of the snow field so that the point data can be used for comparison with, and validation for, satellite measurements...|$|R
40|$|Standard echo {{integration}} methodology {{has been}} applied to the stock of Norwegian spring spawning herring (Clupea harengus) wintering in the Ofotfjord-Tysfjord-Vestfjord system during late autumn 1995 and early winter 1996. The primary instruments of acoustic data collection and processing were the SIMRAD EK 500 / 38 -kHz echo sounder and the Bergen Echo Integrator. Biological sampling was effected by means of a so-called MultiSampler pelagic trawl in addition to standard pelagic trawls. Compensation was made during postprocessing for the effect of acoustic extinction. The major complication of the survey and challenge of the analysis has been stratification. This is discussed in the context of (1) mixing of immature and mature year classes, each with its own behavioural characteristics apropos of diurnal vertical migration and outwards spawning migration, (2) degree of achieved survey coverage, depending on fjord geometry, navigational hazards, available time, and fish distribution, and (3) ongoing spawning migration. Because of various uncertainties, a series of abundance estimates is presented. These are accompanied by fitted variogram models and <b>geostatistical</b> variance <b>estimates...</b>|$|R
40|$|This report {{provides}} the main {{results of the}} 2015 underwater television survey on the ‘Labadie, Jones and Cockburn Banks’ ICES assessment area; Functional Unit 20 - 21. This was the second survey to achieve full coverage of the full area. The 2015 survey was multidisciplinary in nature collecting UWTV, CTD and other ecosystem data. A total of 96 UWTV stations were completed at 6 nmi intervals over a randomised isometric grid design. The mean burrow density was 0. 20 burrows/m 2 compared with 0. 19 burrows/m 2 in 2014. The 2015 <b>geostatistical</b> abundance <b>estimate</b> was 2. 0 ± 0. 02 billion a 2 % decrease on the abundance for 2014 with a CV of 3 % which is well below the upper limit of 20 % recommended by SGNEPS 2012. Highest densities were general observed towards the north and southwest of the ground, and there were also high densities observed close to boundaries. Using the 2015 abundance estimate and updated stock data implies catch of 3045 tonnes and landings of 2225 tonnes. Only one species of sea pen Virgilaria mirabilis was recorded as present at the stations surveyed. Trawl marks were observed at 30 % of the stations surveyed...|$|R
40|$|This report {{provides}} the main {{results of the}} 2014 underwater television survey on the ‘Labadie, Jones and Cockburn Banks’ ICES assessment area; Functional Unit 20 - 21. Some exploratory UWTV stations were carried out in 2006 and 2012. In 2013 ~ 60 % of the ground was surveyed. This was the first survey to achieve full coverage of the newly defined area. The 2014 survey was multi-disciplinary in nature collecting UWTV, CTD and other ecosystem data. A randomised isometric grid design was employed with 98 UWTV stations at 6. 0 nmi intervals. The mean burrow density was 0. 19 burrows/m 2 compared with 0. 16 burrows/m 2 in 2013. The 2014 <b>geostatistical</b> abundance <b>estimate</b> was 2. 1 ± 0. 1 billion a 26 % increase on the extrapolated abundance for 2013. Highest densities were general observed towards {{the middle of the}} ground, but there were also high densities observed close to boundaries. Using the 2014 abundance and recent fisheries data it is possible to estimate harvest ratios consistent with various landings options. These can be used by ICES to provide catch options for 2015. The occurrence of sea-pens and trawl marks on the UWTV footage and processed CTD is also presented...|$|R
40|$|Background: Current {{understanding}} of the spatial epidemiology and geographical distribution of Plasmodium vivax is far less developed than that for P. falciparum, representing a barrier to rational strategies for control and elimination. Here we present the first systematic effort to map the global endemicity of this hitherto neglected parasite. Methodology and Findings: We first updated to the year 2010 our earlier estimate of the geographical limits of P. vivax transmission. Within areas of stable transmission, an assembly of 9, 970 geopositioned P. vivax parasite rate (PvPR) surveys collected from 1985 to 2010 were used with a spatiotemporal Bayesian model-based <b>geostatistical</b> approach to <b>estimate</b> endemicity age-standardised to the 1 – 99 year age range (PvPR 1 – 99) within every 565 km resolution grid square. The model incorporated data on Duffy negative phenotype frequency to suppress endemicity predictions, particularly in Africa...|$|R
40|$|Aerodynamic {{analysis}} in motorsport is conducted using three methods, computational, scaled experimental and full-scale operational. However, the varying fidelity, different sampling resolutions and unavoidable errors of each technique make valid comparisons between datasets from each method difficult and time consuming. Kriging is a <b>geostatistical</b> method to <b>estimate</b> values within a data field by examining and applying the trends of the dataset. This research examines how such techniques {{can be used}} to aid comparison between aerodynamic measurements of a race car. It examines how kriging {{can be used to}} transform discrete measurements, of varying fidelity and sampling resolution, into semi-continuous measurements, thus allowing computational results to be compared across a wider range of conditions than initially tested. This work explores how kriging can allow the trends from highly sampled data, such as track running, to be applied to less sampled data, such as CFD to improve computational and overall aerodynamic analysis...|$|R
40|$|Spatial {{distributions}} of Cu, Pb, Cd, Ni and Zn concentrations in brown shrimps Crangon crangon (Linnaeus, 1758) collected {{on a cruise}} of FRV Walther Herwig III to the southern North Sea in January 2004, were investigated {{on a scale of}} 18 x 18 km to evaluate the range of spatial autocorrelations for the different variables under study. Semivariogram models obtained by geostatistical procedures indicated a distinct increase in variability for most variables with sampling distance. Only if samples are taken at distances above the estimated values for the practical range of the semivariogram can stochastic independence of the data be assumed. These are 6. 6 km for Cd, 3. 0 km for Ni and 5. 2 km for Pb. Contour plots revealed a clear coincidence of high values for Cd, Ni and Pb with low shrimp mean body wet weight. Nevertheless, spatial autocorrelations were rather weak, since classical and <b>geostatistical</b> population <b>estimates</b> for the means and the 95 % confidence intervals were in good agreement. The low detected concentrations of Pb in C. crangon were in good agreement with reported data for decapod crustaceans from other regions. For Zn reported values were distinctly below our 95 % confidence intervals, while for Cu they were slightly above and for Cd distinctly above concentrations in C. crangon from this study. For Ni no comparative values exist. We conclude that with this integrated biomonitoring approach metal concentrations could be assessed more precisely and relations between biotic and abiotic variables could be evaluated...|$|R
40|$|Abstract. —Spatial {{heterogeneity}} is {{a striking}} life history feature of the blue crab Callinectes sapidus in the Chesapeake Bay. Spatial patterns of sex- and age-specific habitat use have been well documented and affect the fisheries in the bay. However, a quantitative assessment of the spatial distribution of blue crabs during winter, when they are generally buried in the sediments, has been lacking. We applied geostatistical techniques (variogram modeling and kriging) to 13 years of winter dredge survey (WDS) data to map patterns of blue crab winter abundance. These maps were then quantified to derive a time series of baywide abundance and to examine changing patterns of habitat use and aggregation. <b>Geostatistical</b> abundance <b>estimates</b> were generally similar to those calculated from design-based methods but were more highly correlated with fishery catch per unit of effort. Both abundance time series showed a large and significant decline from 1990 to 2002. Changes in spatial distribution were evaluated using trend maps and a density-weighted centroid. Interannual variation in the latitude of the weighted centroid {{was positively correlated with}} baywide abundance, suggesting possible density-dependent changes in distribution. The south-ward shift in winter distribution at low stock size may increase the vulnerability of blue crabs to exploitation in a winter dredge fishery that occurs only in the southern portion of the bay. Such quantitative and spatially explicit information provides a potentially useful base for constructing population models and evaluating alternative management options. There is increasing recognition of the impor-tance of space and the need for spatially explicit information for understanding the ecology, pop-ulation dynamics, and management of marine re-sources (Nishida and Booth 2001). This is not only because of a growing awareness of the risks of not accounting for the spatial distribution of exploite...|$|R
40|$|A {{growing area}} of {{application}} for geostatistical conditional simulation is {{as a tool for}} risk analysis in mineral resource and environmental projects. In these applications accurate field measurement of a variable at a specific location is difficult and measurement of variables at all locations is impossible. Conditional simulation provides a means of generating stochastic realizations of spatial (essentially geological and/or geotechnical) variables at unsampled locations thereby quantifying the uncertainty associated with limited sampling and providing stochastic models for 'downstream' applications such as risk assessment. However, because the number of experimental data in practical applications is limited, the <b>estimated</b> <b>geostatistical</b> parameters used in the simulation are themselves uncertain. The inference of these parameters by maximum likelihood provides a means of assessing this estimation uncertainty which, in turn, can be included in the conditional simulation procedure. A case study based on transmissivity data is presented to show the methodology whereby both model selection and parameter inference are solved by maximum likelihood. The authors give an overview of their previously published work on maximum likelihood estimation of geostatistical parameters with particular reference to uncertainty analysis and its incorporation into geostatistical simulation...|$|R
40|$|We {{propose a}} {{modification}} to the Levenberg-Marquardt minimization algorithm {{for a more}} robust and more efficient calibration of highly parameterized, strongly nonlinear models of multiphase flow through porous media. The new method combines the advantages of truncated singular value decomposition {{with those of the}} classical Levenberg-Marquardt algorithm, thus enabling a more robust solution of underdetermined inverse problems with complex relations between the parameters to be estimated and the observable state variables used for calibration. The truncation limit separating the solution space from the calibration null space is re-evaluated during the iterative calibration process. In between these re-evaluations, fewer forward simulations are required, compared to the standard approach, to calculate the approximate sensitivity matrix. Truncated singular values are used to calculate the Levenberg-Marquardt parameter updates, ensuring that safe small steps along the steepest-descent direction are taken for highly correlated parameters of low sensitivity, whereas efficient quasi-Gauss-Newton steps are taken for independent parameters with high impact. The performance of the proposed scheme is demonstrated for a synthetic data set representing infiltration into a partially saturated, heterogeneous soil, where hydrogeological, petrophysical, and <b>geostatistical</b> parameters are <b>estimated</b> based on the joint inversion of hydrological and geophysical data...|$|R
40|$|Póster presentado en el XXIV Congreso de la Asociación de Geógrafos Españoles, celebrado en Zaragoza del 18 al 21 de octubre de 2015. Between {{marshes and}} stabilised sands, {{there are the}} most biodiverse areas of Doñana National Park, an ecotone where the water table is {{relatively}} {{close to the surface}} and causes the existence of important plant communities that are concentrated in the wetter areas. In the study area, the phreatic groundwater piezometers are irregularly distributed and it is inadequate to characterise different microenvironments spatially, mainly in areas of ecotone and faraway, where there are not piezometers installed near. In this paper, we compare interpolators and <b>geostatistical</b> methods for <b>estimating</b> the water table with piezometric data and topographic covariates. The results show that the covariates, when they are well correlated and better sampled than primary variables, can improve precision and reduce errors of prediction. In this cases, we recommend Co-Kriging over Kriging and IDW. Este trabajo ha sido posible gracias a una Beca Jae-Predoc (CSIC), cuyo beneficiario es Oliver Gutiérrez Hernández. Los trabajos han contado con la financiación de los proyectos DECALDO (OAPN, 091 / 2009) y BIOGEOBIRD (P 09 -RMN- 4987). Peer reviewe...|$|R
40|$|Calibration and {{prediction}} in conceptual rainfall-runoff (CRR) modelling {{is affected}} by the sampling and measurement uncertainty in the observed input/output data and by the structural error of the model conceptualisation. The Bayesian Total Error Analysis methodology (BATEA) provides the opportunity to directly and comprehensively address these sources of uncertainty. BATEA is based on Bayesian hierarchical methods and uses explicit error models for input/output data and structural errors. Previous studies demonstrated that simultaneous inference on forcing (e. g. rainfall) and structural errors requires strong prior knowledge of the error mechanisms (e. g., statistical properties of rainfall errors). This paper investigates a <b>geostatistical</b> approach to <b>estimate</b> the sampling error made in approximating the areal rainfall by averaging point-values from a raingauge network. The geostatistical model generates an ensemble of rainfall fields conditioned on gauged values. This ensemble is treated as a distribution of the “true” areal rainfall over the catchment and used as a prior in the BATEA framework. A case study shows that the inclusion of such prior knowledge allows simultaneous estimation of input and structural errors, whereas in the absence of such information the inference is ill-posed...|$|R
40|$|Basic {{univariate}} {{statistics and}} key <b>geostatistical</b> parameters of <b>estimates</b> of hydraulic conductivity obtained at the decimeter scale by two different methods are presented and compared. The two estimates {{are based on}} (1) the empirical Kozeny-Carman formulation, and (2) impeller flowmeter tests. The former provides values of conductivity, KGS, based on particle size distributions. Impeller flowmeter techniques allow inferring conductivities, KFM, from measurements of vertical flows within a borehole. Data obtained during an extensive monitoring campaign at an experimental site located {{near the city of}} Tübingen, Germany, are considered. Statistics of the natural logarithm of KGS and KFM at the site are similar in terms of mean values (with averages of ln KGS being slightly smaller than those of ln KFM) and differ in terms of variogram ranges and sample variances. The correlation between the two sets of estimates is virtually absent. Additional data from two different sites already presented in the literature allow comparing conductivity estimates from flowmeter and grain-size distributions (or permeameter measurements) taken at adjacent wells and support the finding that KGS and KFM lack correlation. The analysis highlights the difficulty in obtaining meaningful quantitatively comparable hydraulic conductivity data at the decimetric scale. Peer ReviewedPostprint (published version...|$|R
40|$|<b>Geostatistical</b> {{methods of}} <b>estimating</b> ore {{reserves}} and other spatial phenomena {{are becoming increasingly}} wide spread in their use. Properly applied, Geostatistical estimation falls into two stages [...] the "modelling " of the spatial variability within the study area; {{and the use of}} this spatial model to provide an appropriate estimation technique. The first stage usually consists of construction and interpretation of semi-variogram graphs, and the second is the development of the corresponding Kriging method. Because of the apparent subjectivity inherent to the first stage of a geostatistical analysis, {{attempts have been made to}} provide methods of "testing " whether a particular semi-variogram model (say) adequately represents the study area. Increasingly, the choice of model is being justified by a process known as "Cross Validation". With this approach, the analyst uses a partial data set to estimate values at actual sampled positions. "Real " and "estimated " values are then compared in such a way that the model can be accepted or rejected. This paper discusses the process of cross validation in some detail, using case studies as examples. Some problems with the technique are illustrated and discussed...|$|R
40|$|We clarify {{relationships}} between conditional (CAR) and simultaneous (SAR) autoregressive models. We review {{the literature on}} this topic and find that it is mostly incomplete. Our main result is that a SAR model can be written as a unique CAR model, and while a CAR model can be written as a SAR model, it is not unique. In fact, we show how any multivariate Gaussian distribution on a finite set of points with a positive-definite covariance matrix can be written as either a CAR or a SAR model. We illustrate how to obtain any number of SAR covariance matrices from a single CAR covariance matrix by using Givens rotation matrices on a simulated example. We also discuss sparseness in the original CAR construction, and for the resulting SAR weights matrix. For a real example, we use crime data in 49 neighborhoods from Columbus, Ohio, and show that a geostatistical model optimizes the likelihood much better than typical first-order CAR models. We then use the implied weights from the <b>geostatistical</b> model to <b>estimate</b> CAR model parameters that provides the best overall optimization. Comment: 18 pages, 4 figure...|$|R
40|$|Invalid ISBN as {{published}} on the item: 97808258259461 Calibration and prediction in conceptual rainfall-runoff (CRR) modelling {{is affected by the}} sampling and measurement uncertainty in the observed input/output data and by the structural error of the model conceptualisation. The Bayesian Total Error Analysis methodology (BATEA) provides the opportunity to directly and comprehensively address these sources of uncertainty. BATEA is based on Bayesian hierarchical methods and uses explicit error models for input/output data and structural errors. Previous studies demonstrated that simultaneous inference on forcing (e. g. rainfall) and structural errors requires strong prior knowledge of the error mechanisms (e. g., statistical properties of rainfall errors). This paper investigates a <b>geostatistical</b> approach to <b>estimate</b> the sampling error made in approximating the areal rainfall by averaging point-values from a raingauge network. The geostatistical model generates an ensemble of rainfall fields conditioned on gauged values. This ensemble is treated as a distribution of the “true” areal rainfall over the catchment and used as a prior in the BATEA framework. A case study shows that the inclusion of such prior knowledge allows simultaneous estimation of input and structural errors, whereas in the absence of such information the inference is ill-posed. B. Renard, E. Leblois, G. Kuczera, D. Kavetski, M. Thyer and S. Frank...|$|R
40|$|Assimilation of {{satellite}} soil moisture and streamflow data into a distributed hydrologic model has received increasing attention {{over the past}} few years. This study provides a detailed analysis of the joint and separate assimilation of streamflow and Advanced Scatterometer (ASCAT) surface soil moisture into a distributed Sacramento Soil Moisture Accounting (SAC-SMA) model, with the use of recently developed particle filter-Markov chain Monte Carlo (PF-MCMC) method. Performance is assessed over the Salt River Watershed in Arizona, {{which is one of the}} watersheds without anthropogenic effects in Model Parameter Estimation Experiment (MOPEX). A total of five data assimilation (DA) scenarios are designed and the effects of the locations of streamflow gauges and the ASCAT soil moisture on the predictions of soil moisture and streamflow are assessed. In addition, a geostatistical model is introduced to overcome the significantly biased satellite soil moisture and also discontinuity issue. The results indicate that: (1) solely assimilating outlet streamflow can lead to biased soil moisture estimation; (2) when the study area can only be partially covered by the satellite data, the <b>geostatistical</b> approach can <b>estimate</b> the soil moisture for those uncovered grid cells; (3) joint assimilation of streamflow and soil moisture from geostatistical modeling can further improve the surface soil moisture prediction. This study recommends that the geostatistical model is a helpful tool to aid the remote sensing technique and the hydrologic DA study...|$|R
40|$|ABSTRACT The spatial {{distribution}} of forest biomass in the Amazon is heterogeneous with a temporal and spatial variation, especially {{in relation to the}} different vegetation types of this biome. Biomass estimated in this region varies significantly depending on the applied approach and the data set used for modeling it. In this context, this study aimed to evaluate three different <b>geostatistical</b> techniques to <b>estimate</b> the {{spatial distribution}} of aboveground biomass (AGB). The selected techniques were: 1) ordinary least-squares regression (OLS), 2) geographically weighted regression (GWR) and, 3) geographically weighted regression - kriging (GWR-K). These techniques were applied to the same field dataset, using the same environmental variables derived from cartographic information and high-resolution remote sensing data (RapidEye). This study was developed in the Amazon rainforest from Sucumbíos - Ecuador. The results of this study showed that the GWR-K, a hybrid technique, provided statistically satisfactory estimates with the lowest prediction error compared to the other two techniques. Furthermore, we observed that 75 % of the AGB was explained by the combination of remote sensing data and environmental variables, where the forest types are the most important variable for estimating AGB. It should be noted that while the use of high-resolution images significantly improves the estimation of the {{spatial distribution of}} AGB, the processing of this information requires high computational demand...|$|R
40|$|Automatically {{generating}} maps of {{a measured}} variable of interest can be problematic. In this work {{we focus on}} the monitoring network context where observations are collected and reported by a network of sensors, and are then transformed into interpolated maps for use in decision making. Using traditional <b>geostatistical</b> methods, <b>estimating</b> the covariance structure of data collected in an emergency situation can be difficult. Variogram determination, whether by method-of-moment estimators or by maximum likelihood, is very sensitive to extreme values. Even when a monitoring network is in a routine mode of operation, sensors can sporadically malfunction and report extreme values. If this extreme data destabilises the model, causing the covariance structure of the observed data to be incorrectly estimated, the generated maps will be of little value, and the uncertainty estimates in particular will be misleading. Marchant and Lark [2007] propose a REML estimator for the covariance, which is shown to work on small data sets with a manual selection of the damping parameter in the robust likelihood. We show how this can be extended to allow treatment of large data sets together with an automated approach to all parameter estimation. The projected process kriging framework of Ingram et al. [2007] is extended to allow the use of robust likelihood functions, including the two component Gaussian and the Huber function. We show how our algorithm is further refined to reduce the computational complexity {{while at the same time}} minimising any loss of information. To show the benefits of this method, we use data collected from radiation monitoring networks across Europe. We compare our results to those obtained from traditional kriging methodologies and include comparisons with Box-Cox transformations of the data. We discuss the issue of whether to treat or ignore extreme values, making the distinction between the robust methods which ignore outliers and transformation methods which treat them as part of the (transformed) process. Using a case study, based on an extreme radiological events over a large area, we show how radiation data collected from monitoring networks can be analysed automatically and then used to generate reliable maps to inform decision making. We show the limitations of the methods and discuss potential extensions to remedy these...|$|R
40|$|Insect {{population}}s {{tend to be}} patchy in distribution. Even {{when the}} mean population density is low, there may be local patches with high densities. As a result, estimates of mean populations may provide little information about the size or intensity of local patches within the sampled area. We compared the following 3 methods of estimating local population densities of insects: (1) with moving averages, a local mean population density is estimated as the mean of samples taken within a given radius of a central point, (2) with inverse distances, local means are estimated as weighted averages of samples; each sample is given a weight proportional to a power of the reciprocal of its distance {{from the center of}} the region for which the mean is to be estimated, (3) kriging is a <b>geostatistical</b> algorithm for <b>estimating</b> local means as weighted averages of samples. Weighting is based on the spatial covariance of the samples, or the degree to which samples that are near to each other are related. The first 2 methods are relatively easy to calculate but were unreliable when used with standard parameters to estimate local Japanese beetle grub densities. When an optimum radius was used with moving averages and an optimum exponent was used with inverse distances, the advantage of ease of calculation was lost, yet both methods were still inferior to kriging in providing accurate estimates of local mean...|$|R
40|$|Estimation {{of noise}} {{contained}} within a {{remote sensing image}} is often a prerequisite {{to dealing with the}} deleterious effects of noise on the signal. Image based methods to estimate noise are attractive to researchers for a range of applications because they are in many cases automatic and do not depend on external data or laboratory measurement. In this paper, the <b>geostatistical</b> method for <b>estimating</b> image noise was applied to Compact Airborne Spectrographic Imager (CASI) imagery. Three CASI wavebands (0. 46 – 0. 49 mm (blue), 0. 63 – 0. 64 mm (red), 0. 70 – 0. 71 mm (nearinfrared)) and four land covers (coniferous woodland, grassland, heathland and deciduous woodland) were selected for analysis. Five sub-images were identified per land cover resulting in 20 example cases per waveband. As in previous studies, the analysis showed that noise was related to land cover type. However, the noise estimates were not related to the mean of the signal in any waveband. Rather, the noise estimates were related to the square root of the semivariogram sill, which represents the variability in the underlying signal. These results suggest that the noise estimates produced using the geostatistical method may be inflated where the variance in the image is large. Regression of the noise estimates on the square root of the sill may lead to a stable noise estimate (i. e. the regression intercept), which is not affected by the variability in the image. This provides a refined geostatistical (GS) method that avoids the problems outlined above...|$|R
40|$|This study {{evaluated}} the associations between biological markers in the nitrate-nitrite-NO pathway and four environmental exposures among subjects {{examined in the}} second survey (2003 - 2007) of the French Epidemiological study on Genetics and Environment of Asthma (EGEA). Total nitrite and nitrate (NO(2) (-) /NO(3) (-)) levels were measured both in plasma and in exhaled breath condensate (EBC) in 949 adults. Smoking, diet and exposure to chlorine products were assessed using standardized questionnaires. Exposure to air pollutants was <b>estimated</b> by using <b>geostatistical</b> models. All <b>estimates</b> were obtained with generalized estimating equations for linear regression models. Median levels of NO(2) (-) /NO(3) (-) were 36. 3 muM (1 st- 3 rd quartile: 25. 7, 51. 1) in plasma and 2. 0 mumol/mg proteins (1 st- 3 rd quartile 0. 9, 3. 9) in EBC. After adjustment for asthma, age, sex and menopausal status, plasma NO(2) (-) /NO(3) (-) level increased with leafy vegetable consumption (above versus below median= 0. 04 (95 %CI: 0. 001, 0. 07)) and decreased in smokers (versus non/ex-smokers=- 0. 08 (95 %CI: - 0. 11, - 0. 04). EBC NO(2) (-) /NO(3) (-) level decreased in smokers (- 0. 08 (95 %CI: - 0. 16, - 0. 001)) and with exposure to ambient O(3) concentration (above versus below median=- 0. 10 (95 %CI: - 0. 17, - 0. 03)). Cured meat, chlorine products, PM(10) and NO(2) concentrations were not associated with NO(2) (-) /NO(3) (-) levels. Results suggest that potential modifiable environmental and behavioral risk factors may modify NO(2) (-) /NO(3) (-) levels in plasma and EBC according to the route of exposur...|$|R
40|$|Particulate matter (PM 10 and PM 2. 5) is a {{criteria}} {{air pollutant}} providing a useful indicator {{to assess the}} impact of the WTC disaster on air quality. The objective of this initial analysis is to use a <b>geostatistical</b> approach to <b>estimate</b> particulate matter over space and time in the surroundings of the WTC site in order to assess the ability of available monitoring data to reconstruct the plume of air toxics released by the collapse of the towers and the ensuing fires. In this analysis we use the Bayesian Maximum Entropy (BME) method of modern Geostatistics, which performs a composite space/time analysis and provides the capability to account for measurement errors when that information will be available. The implementation of the BME method for the WTC situation resulted in the development of the BME-WTC model presented herein. Using this model we analyzed monitoring data from the US-EPA AIRS database, which contains monitoring data for the federal criteria air pollutants measured at a fixed network in the US, as well as from monitoring stations that were deployed after the 9 / 11 disaster to specifically monitor the air toxics coming from the WTC site. Our initial results show that the BME-WTC model provides a useful framework for the spatiotemporal exposure mapping in the WTC situation, however the data used so far in our analysis is not sufficient to reconstruct the space/time plume. Future work is focused on getting a more complete database of the monitoring data in order to obtain a better reconstruction of the plume, and combining this reconstruction of the plume with predictions from physical air transport simulations...|$|R
40|$|The {{sampling}} frequency {{in space and}} time is often inadequate to estimate the accuracy and precision of aeolian sediment transport. The problem stems from a lack of knowledge about the spatial and temporal scale of variation in aeolian transport and is compounded by a shortage of resources (aeolian sediment traps and labour). This study developed a <b>geostatistical</b> methodology for <b>estimating</b> sediment transport at unsampled locations and tested {{the extent to which it}} was dependent on sampling networks (nested, grid and random) and frameworks (mobile or static sampling framework between wind erosion events). Aeolian transport data were collected in an area of Australia influenced by wind erosion (Diamantina Lakes National Park, southwestern Queensland) to evaluate the combination of events used for mapping transport. Insufficient wind erosion events occurred to test sediment sampling strategies and hence simulated sampling was conducted using maps of sediment transport produced with existing models of aeolian sediment transport in the same study area. Independent validation data were used to test the estimation performance. The results suggested that sampling networks that did not include information on the spatial scale of variation (i. e. grid and random sampling) did not represent adequately the sediment transport population. In contrast, a bespoke nested sampling network performed consistently better than the other networks. Overall the static framework with a nested network was recommended for estimation and mapping of sediment transport with few resources and was likely to be especially important for use over large areas. This approach has the advantage of requiring only a single pooled within-event variogram for sediment transport to be used to derive the model parameters for kriging or stochastic simulation for each event. No Full Tex...|$|R
40|$|Temperature {{changes are}} known to have {{significant}} impacts on human health. Accurate estimates of population-weighted average monthly air temperature for US counties are needed to evaluate temperature's association with health behaviours and disease, which are sampled or reported at the county level and measured on a monthly-or 30 -day-basis. Most reported temperature estimates were calculated using ArcGIS, relatively few used SAS. We compared the performance of <b>geostatistical</b> models to <b>estimate</b> population-weighted average temperature in each month for counties in 48 states using ArcGIS v 9. 3 and SAS v 9. 2 on a CITGO platform. Monthly average temperature for Jan-Dec 2007 and elevation from 5435 weather stations were used to estimate the temperature at county population centroids. County estimates were produced with elevation as a covariate. Performance of models was assessed by comparing adjusted R (2), mean squared error, root mean squared error, and processing time. Prediction accuracy for split validation was above 90 % for 11 months in ArcGIS and all 12 months in SAS. Cokriging in SAS achieved higher prediction accuracy and lower estimation bias as compared to cokriging in ArcGIS. County-level estimates produced by both packages were positively correlated (adjusted R (2) range= 0. 95 to 0. 99); accuracy and precision improved with elevation as a covariate. Both methods from ArcGIS and SAS are reliable for U. S. county-level temperature estimates; However, ArcGIS's merits in spatial data pre-processing and processing time may be important considerations for software selection, especially for multi-year or multi-state projects. LUB 2 /Intramural CDC HHS/United States 2015 - 07 - 09 T 00 : 00 : 00 Z 26167169 PMC 449795...|$|R
40|$|Background: current {{understanding}} of the spatial epidemiology and geographical distribution of Plasmodium vivax is far less developed than that for P. falciparum, representing a barrier to rational strategies for control and elimination. Here we present the first systematic effort to map the global endemicity of this hitherto neglected parasite. Methodology and findings: we first updated to the year 2010 our earlier estimate of the geographical limits of P. vivax transmission. Within areas of stable transmission, an assembly of 9, 970 geopositioned P. vivax parasite rate (PvPR) surveys collected from 1985 to 2010 were used with a spatiotemporal Bayesian model-based <b>geostatistical</b> approach to <b>estimate</b> endemicity age-standardised to the 1 – 99 year age range (PvPR 1 – 99) within every 5 × 5 km resolution grid square. The model incorporated data on Duffy negative phenotype frequency to suppress endemicity predictions, particularly in Africa. Endemicity was predicted within a relatively narrow range throughout the endemic world, with the point estimate rarely exceeding 7 % PvPR 1 – 99. The Americas contributed 22 % of the global area at risk of P. vivax transmission, but high endemic areas were generally sparsely populated and the region contributed only 6 % of the 2. 5 billion people at risk (PAR) globally. In Africa, Duffy negativity meant stable transmission was constrained to Madagascar {{and parts of the}} Horn, contributing 3. 5 % of global PAR. Central Asia was home to 82 % of global PAR with important high endemic areas coinciding with dense populations particularly in India and Myanmar. South East Asia contained areas of the highest endemicity in Indonesia and Papua New Guinea and contributed 9 % of global PAR. Conclusions and significance: this detailed depiction of spatially varying endemicity is intended to contribute to a much-needed paradigm shift towards geographically stratified and evidence-based planning for P. vivax control and eliminatio...|$|R
40|$|Current {{understanding}} of the spatial epidemiology and geographical distribution of Plasmodium vivax is far less developed than that for P. falciparum, representing a barrier to rational strategies for control and elimination. Here we present the first systematic effort to map the global endemicity of this hitherto neglected parasite. We first updated to the year 2010 our earlier estimate of the geographical limits of P. vivax transmission. Within areas of stable transmission, an assembly of 9, 970 geopositioned P. vivax parasite rate (PvPR) surveys collected from 1985 to 2010 were used with a spatiotemporal Bayesian model-based <b>geostatistical</b> approach to <b>estimate</b> endemicity age-standardised to the 1 - 99 year age range (PvPR(1 - 99)) within every 5 × 5 km resolution grid square. The model incorporated data on Duffy negative phenotype frequency to suppress endemicity predictions, particularly in Africa. Endemicity was predicted within a relatively narrow range throughout the endemic world, with the point estimate rarely exceeding 7 % PvPR(1 - 99). The Americas contributed 22 % of the global area at risk of P. vivax transmission, but high endemic areas were generally sparsely populated and the region contributed only 6 % of the 2. 5 billion people at risk (PAR) globally. In Africa, Duffy negativity meant stable transmission was constrained to Madagascar {{and parts of the}} Horn, contributing 3. 5 % of global PAR. Central Asia was home to 82 % of global PAR with important high endemic areas coinciding with dense populations particularly in India and Myanmar. South East Asia contained areas of the highest endemicity in Indonesia and Papua New Guinea and contributed 9 % of global PAR. This detailed depiction of spatially varying endemicity is intended to contribute to a much-needed paradigm shift towards geographically stratified and evidence-based planning for P. vivax control and elimination...|$|R
40|$|The {{uniaxial}} {{compressive strength}} (UCS) of intact rocks {{is an important}} geotechnical parameter required for designing geotechnical and mining engineering projects. Obtaining accurate estimates of the rock mass UCS parameter throughout a 3 D geological model of the deposit is vital for determining optimum rock slope stability, designing new exploratory and blast boreholes, mine planning, optimizing the production schedule and even designing the crusher’s feed size. The main objective {{of this paper is}} to select the preferred estimator of the UCS parameter based on accuracy performance using all the available geological-geotechnical data at the Sarcheshmeh copper deposit, located 160 km southwest of Kerman City, in south-eastern Iran. In this paper, an attempt is made to estimate the spatial distribution of the UCS parameter using commonly-used statistical-structural and geostatistical methods. In order to achieve the aim of the current study, the UCS parameter was measured along with other qualitative geological properties, including the rock type, weathering, alteration type and intensity of core samples taken from 647 boreholes. The 3 D distribution of the UCS parameter is obtained using different algorithms including statistical-structural (the nearest-neighbour technique), linear (ordinary Kriging) and nonlinear (indicator Kriging) <b>geostatistical</b> methods. After <b>estimating</b> the UCS parameter at block centres using the above-mentioned methods, the performance of each method is compared and validated through 21 set aside borehole data. The assessment of selecting best estimator of UCS parameter is based on scatter plots of the observed versus estimated data plus the root mean square error (RMSE) statistics of the differences between observed and estimated values for 21 set aside borehole data. Finally, due to the special characteristics of the UCS spatial variability, it is concluded that the nearest-neighbour method is the most appropriate method for estimating the UCS parameter in porphyry copper deposits...|$|R
