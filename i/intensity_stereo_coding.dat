10|167|Public
50|$|This form {{of joint}} stereo uses a {{technique}} known as joint frequency encoding, which functions {{on the principle of}} sound localization. Human hearing is predominantly less acute at perceiving the direction of certain audio frequencies. By exploiting this characteristic, <b>intensity</b> <b>stereo</b> <b>coding</b> can reduce the data rate of an audio stream with little or no perceived change in apparent quality.|$|E
50|$|More specifically, the {{dominance}} of inter-aural time differences (ITD) for sound localization by humans is only present for lower frequencies. That leaves inter-aural amplitude differences (IAD) as the dominant location indicator for higher frequencies. The idea of <b>intensity</b> <b>stereo</b> <b>coding</b> is to merge the lower spectrum into just one channel (thus reducing overall differences between channels) and to transmit a little side information about how to pan certain frequency regions to recover the IAD cues.|$|E
50|$|The idea is {{to merge}} a given {{frequency}} range of multiple sound channels together so that the resulting encoding will preserve the sound information of that range not as a bundle of separate channels but as one homogeneous data stream. This will destroy the original channel separation permanently, as the information cannot be accurately reconstructed, but will greatly lessen the amount of required storage space. Only some forms of joint stereo use the joint frequency encoding technique, such as <b>intensity</b> <b>stereo</b> <b>coding.</b>|$|E
30|$|Since most audio {{material}} {{is produced in}} <b>stereo,</b> an efficient <b>coding</b> tool should also exploit the redundancies and irrelevancies of both channels simultaneously. Since it is not straightforward to use standard <b>stereo</b> <b>coding</b> tools like mid/side <b>stereo</b> [51] and <b>intensity</b> <b>stereo</b> [52] in conjunction with parametric coding, and since the aim also {{was to develop a}} general <b>stereo</b> <b>coding</b> tool for low bit rates, the novel Parametric Stereo (PS) tool was developed where the <b>stereo</b> image is <b>coded</b> on the basis of spatial cues. The PS tool as standardized in MPEG was developed in 2003 and primarily aimed to enhance the performance of SSC and HE-AAC at low bit rates.|$|R
50|$|The bitrate of the {{standard}} SP mode is 292 kbit/s, and it uses separate <b>stereo</b> <b>coding</b> with discrete left and right channels. LP2 mode uses a bitrate of 132 kbit/s and also uses separate <b>stereo</b> <b>coding.</b> The last mode, LP4, has a bitrate of 66 kbit/s and uses joint <b>stereo</b> <b>coding.</b> The sound quality is noticeably poorer than the first two modes, but is sufficient for many uses.|$|R
40|$|Applying joint <b>stereo</b> <b>coding</b> {{techniques}} {{for the low}} bitrate coding of audio signals can lead to significant improvements in the perceived sound quality. Nevertheless, some pitfalls {{for the use of}} these techniques should be taken into account in order to avoid coding artifacts. The combined (MS/Intensity) joint <b>stereo</b> <b>coding</b> techniques implemented in Layer III of the ISO/MPEG/Audio coder will be described...|$|R
5000|$|M/S stereo coding {{transforms}} {{the left and}} right channels into a mid channel and a side channel. The mid channel is the sum of {{the left and right}} channels, or [...] The side channel is the difference of the left and right channels, or [...] Unlike <b>intensity</b> <b>stereo</b> <b>coding,</b> M/S coding is a special case of transform coding, and retains the audio perfectly without introducing artifacts. Lossless codecs such as FLAC or Monkey's Audio use M/S stereo coding because of this characteristic.|$|E
5000|$|Layer II {{can also}} {{optionally}} use <b>intensity</b> <b>stereo</b> <b>coding,</b> {{a form of}} joint stereo. This means that the frequencies above 6 kHz of both channels are combined/down-mixed into one single (mono) channel, but the [...] "side channel" [...] information on the relative intensity (volume, amplitude) of each channel is preserved and encoded into the bitstream separately. On playback, the single channel is played through left and right speakers, with the intensity information applied to each channel to give the illusion of stereo sound. This perceptual trick is known as stereo irrelevancy. This can allow further reduction of the audio bitrate without much perceivable loss of fidelity, but is generally not used with higher bitrates as it does not provide very high quality (transparent) audio.|$|E
40|$|The coding {{method has}} the stereo audio {{spectral}} values grouped into scale factor bands (28), with formation of sections each containing {{at least one}} scale factor band. The audio spectral values are coded within each section using a coding table selected {{from a number of}} coding tables. Each coding table is identified by a coding table number transmitted alongside the coded stereo audio spectral values. An additional coding table number is transmitted for an <b>intensity</b> <b>stereo</b> <b>coding</b> method, or an adaptive Huffman coding method for the stereo audio spectral values. ADVANTAGE - Provides compression of audio digital signals without quality degradation...|$|E
50|$|As with MP3, Ogg Vorbis stereo files can employ either L/R stereo or joint stereo. When using joint stereo, both M/S <b>stereo</b> and <b>intensity</b> <b>stereo</b> methods may be used. As {{opposed to}} MP3 where M/S stereo (when used) is applied before quantization, an Ogg Vorbis encoder applies M/S stereo to samples in the {{frequency}} domain after quantization, making application of M/S stereo a lossless step. After this step, any frequency area {{can be converted to}} <b>intensity</b> <b>stereo</b> by removing the corresponding part of the M/S signal's side channel. Ogg Vorbis' floor function will take care of the required left-right panning.|$|R
50|$|Note: {{although}} possible, {{the resulting}} quality is {{much worse than}} typicalfor this bitrate. So for normal 64 kbit/s AAC LC a bandwidth of 14-16 kHz isachieved by using <b>intensity</b> <b>stereo</b> and reduced NMRs. This degrades audible qualityless than transmitting 6 kHz bandwidth with perfect quality.|$|R
30|$|Since 1990, joint <b>stereo</b> <b>coding</b> {{algorithm}} {{has been}} widely used in the two-channel audio coding. Various techniques {{have been developed for}} compressing stereo or multichannel audio signals. Recently, the ISO/MPEG standardization group has published a new audio standard, that is, MPEG Surround, which is a feature-rich open standard compression technique for multichannel audio signals [1]. MPEG Surround coding can be regarded as an enhancement of the joint <b>stereo</b> <b>coding</b> and an extension of BCC [[2, 5]]. BCC exploits binaural cue parameters for capturing the spatial image of multichannel audio and enables low-bit-rate transmission by transmitting mono signals plus side information in relation to binaural perception.|$|R
40|$|The same program {{heard on}} DAB at 128 kbit/s and 192 kbit/s has been {{compared}} with a high quality FM stereo signal. The result from informal listening tests {{is that there are}} audible impairments in the stereo imaging of high-frequency instruments, and in particular hi-hats at 128 kbit/s. Some examples of songs where this effect can be heard are given. The effect can be explained by spectral analysis of the output of a DAB radio which shows that at 128 kbit/s, 3 kHz is used as the switch frequency for the <b>intensity</b> <b>stereo</b> <b>coding</b> of the MPEG-I layer 2 encoder, effectively removing most signal differences above this frequency. This degradation cannot be heard in a good quality FM stereo signal...|$|E
40|$|When coding several signals {{which are}} not {{dependent}} on each other, selection of the suitable coding type {{is dependent on the}} degree of similarity. According to one aspect of the invention, the degree of similarity is determined by coding one of the signals first using the intensity stereo process and then decoding it {{in order to create a}} signal containing a coding error, whereupon the latter and the related non-coded signal are transformed into the frequency range. Within the frequency range, the actually audible spectral component, the signal bearing the coding error and the related signal not containing any coding error are selected or evaluated using a masking threshold which is determined by a psycho-acoustic calculation. If the degree of similarity is high, an <b>intensity</b> <b>stereo</b> <b>coding</b> is performed, whereas in the opposite case, the channels are coded separately...|$|E
40|$|The ISO/MPEG phases 1 and 2 audio {{compression}} is receiving {{a wide range}} of applications. In the encoding process of MPEG, the psychoacoustic model exploits audio irrelevancy which is the key role to achieve high compression ratio without losing audio quality. However, the Fourier transform (FT) which has been used by the two psychoacoustic models suggested in standard draft requires high computational complexity which leads to high hardware and software cost for real-time applications. This paper presents a new design named the hybrid filter bank to replace the FT. The hybrid filter bank can be integrated with the psychoacoustic models and provides a much lower complexity than the FT. Also, this paper shows that the hybrid filter is more suitable for the stereo coding and hence can provide a better quality for the <b>intensity</b> <b>stereo</b> <b>coding,</b> which is the key technology for the MPEG 1 to achieve near transparent quality lower than 96 x 2 Kbits for two stereo channels...|$|E
50|$|In {{addition}} to Layer II's <b>intensity</b> encoded joint <b>stereo,</b> MP3 can use middle/side (mid/side, m/s, MS, matrixed) joint stereo. With mid/side stereo, certain frequency ranges of both channels are merged {{into a single}} (middle, mid, L+R) mono channel, while the sound difference between {{the left and right}} channels is stored as a separate (side, L-R) channel. Unlike <b>intensity</b> <b>stereo,</b> this process does not discard any audio information. When combined with quantization, however, it can exaggerate artifacts.|$|R
50|$|HE-AAC profile {{was first}} {{standardized}} in ISO/IEC 14496-3:2001/Amd 1:2003. HE-AAC v2 profile (HE-AAC with Parametric Stereo) was first specified in ISO/IEC 14496-3:2005/Amd 2:2006. The Parametric <b>Stereo</b> <b>coding</b> tool used by HE-AAC v2 was standardized in 2004 and published as ISO/IEC 14496-3:2001/Amd 2:2004.|$|R
50|$|This {{reduces the}} data rate to 66 kbit/s (half that of LP2), partly by using joint <b>stereo</b> <b>coding</b> and a lowpass filter around 13.5 kHz. It allows 324 minutes to be {{recorded}} on an 80-minute MiniDisc, with the same padding required as LP2.|$|R
30|$|MPEG- 1 audio coding [1, 2] (including {{the popular}} Layer III {{also known as}} MP 3 audio coding), MPEG- 2 AAC (advanced audio coding) [3 – 5], and Dolby AC- 3 [6, 7] are some {{well-known}} audio coding methods for stereo and multichannel audio content. These methods mainly exploit the masking property of the human auditory system for shaping the quantization noise {{so that it will}} be inaudible. In addition to reducing the intrachannel redundancies and irrelevancies, these methods also include algorithms for exploring the interchannel redundancies, irrelevancies, more specifically mid/side coding [8], for frequencies below 2 [*]kHz, and <b>intensity</b> <b>stereo</b> <b>coding</b> [9] above 2 [*]kHz. M/S codes the sum and difference signals instead of the actual channels, operating in an approximate Karhunen-Loeve (K-L transform) manner. Intensity stereo is based on coding only the sum signal of the channels, as well as the time envelopes for each channel as side information, given that these envelopes are adequate for synthesizing the spatial image at the decoder. A useful introduction to several technologies for the more general area of audio compression can be found in [10]. More recently, exact KLT methods have been derived (e.g., [11]), while intensity stereo has been generalized for the entire frequency spectrum by MPEG Surround [12].|$|E
50|$|AAC-LD {{can also}} process stereo signals {{by using the}} {{advanced}} <b>stereo</b> <b>coding</b> tools of AAC. Thus {{it is possible to}} transmit a stereo signal with a bandwidth of 7 kHz via one ISDN line or with a bandwidth of 15 kHz via two ISDN lines.|$|R
40|$|The method {{involves}} {{grouping of}} the stereo audio spectral values in scale factor bands, before coding via an intensity-stereo method, {{so that one}} channel carries the intensity-stereo <b>coded</b> <b>stereo</b> audio spectral values and the other channel carries stereo audio spectral values equal to zero. The intensity-stereo <b>coded</b> <b>stereo</b> audio <b>coded</b> values are decoded for each scale factor band and a prediction method is used to provide the <b>coded</b> <b>stereo</b> audio spectral values for the other channel. ADVANTAGE - Reduced bit rate for increased data transmission rate without impaired quality...|$|R
40|$|Significant perceptual {{improvements}} can {{be gained}} in the coding of stereoscopic videos, as is illustrated here by modifying the adaptive quantization of an MPEG- 2 codec. Applying human visual properties to MPEG- 2 's temporal scalability framework, a perceptual adaptive quantization approach to stereoscopic video coding is presented. To optimize the perceived picture {{quality of the}} reconstructed stereo images, binocular visibility of <b>stereo</b> <b>coding</b> artifacts is investigated, including image fusion and visual masking. Four normalized indicators are introduced to account for 3 D visual artifacts, and are incorporated to determine the quantization parameters. They are (1) prediction accuracy, (2) prediction correlation, (3) fusion indicator, and (4) texture intensity. Simulations indicate the importance of perceptual <b>stereo</b> <b>coding,</b> with improvements in overall stereo quality and reductions in binocular artifacts. 1. INTRODUCTION Motivated {{by the idea of}} a combination 3 D system and HDTV, we [...] ...|$|R
40|$|Abstract — Wyner-Ziv coding, {{also known}} as {{distributed}} video coding, is currently a very hot research topic in video coding due to the new opportunities it opens. This paper applies the distributed video <b>coding</b> principles to <b>stereo</b> video <b>coding,</b> to propose a practical solution for Wyner-Ziv <b>stereo</b> <b>coding</b> based on mask-based fusion of temporal and spatial side informations. The architecture includes a low-complexity encoder and avoids any communication between the cameras/encoders. While the rate-distortion (RD) performance strongly depends on the motion-based frame interpolation (MBFI) and disparity-based frame estimation (DBFE) solutions, first {{results show that the}} proposed approach is promising and there are still issues to address. ...|$|R
50|$|HE-AAC version 1 was {{standardized}} as {{a profile}} of MPEG-4 Audio in 2003 by MPEG and published as part of MPEG-4 in document ISO/IEC 14496-3:2001/Amd 1:2003. The HE-AAC version 2 profile was standardized in 2006 as ISO/IEC 14496-3:2005/Amd 2:2006.A parametric <b>stereo</b> <b>coding</b> tool used in HE-AAC v2 was standardized in 2004 by MPEG and published in document ISO/IEC 14496-3:2001/Amd 2:2004.|$|R
40|$|Almost all voice {{communications}} {{are based}} on monophonic narrowband speech. Wideband stereophonic communications provide a more natural sounding environment. This holds especially true for teleconferencing applications, where the localization information in the stereo signal adds {{a new dimension to}} the communication. As of today, there is no standardized speech codec with full stereo support. Statistical analysis shows that there exists correlation between left and right channels of a stereo speech signal. Instead of coding both channels independently (2 x mono bitrate) stereo parameters are extracted which, combined with the mono signal, allows for low bit rate stereo reproduction. This thesis report describes a parametric <b>stereo</b> <b>coding</b> algorithm. The algorithm, which is targeted at conversational applications such as teleconferencing, reproduces the stereo signal from a down-mixed mono signal and additional stereo parameters. During the thesis work, different <b>stereo</b> <b>coding</b> methods have been studied and evaluated. Given design constraints such as low complexity, low delay and low bit rate...|$|R
50|$|An AAC HE v2 {{bitstream}} {{is obtained}} by downmixing the stereo audio to mono at the encoder along with 2-3 kbit/s of side info (the Parametric Stereo information) {{in order to}} describe the spatial <b>intensity</b> <b>stereo</b> generation and ambience regeneration at the decoder. By having the Parametric Stereo side info along with the mono audio stream, the decoder (player) can regenerate a faithful spatial approximation of the original stereo panorama at very low bitrates.|$|R
50|$|For {{the channel}} {{coupling}} CELT may use M/S <b>stereo</b> or <b>intensity</b> <b>stereo.</b> Blocks {{can be described}} independent from adjacent frames (Intra-frame); for example to enable a decoder to jump into a running stream. With transform codecs so-called pre-echo artifacts can get audible, because the quantisation error of sharp, energy-heavy sounds (transients) can spread over the entire DCT block and the transient doesn't mask them backward in {{time as well as}} forward. With CELT each block can be further divided to thwart such artifacts.|$|R
40|$|This thesis {{presents}} a <b>stereo</b> <b>coding</b> architecture for the ITU-T G. 719 fullband mono codec. G. 719 {{is suitable for}} teleconferencing applications with a competitive audio quality for speech and audio signals that are encoded at 32, 48 and 64 kbps. The proposed stereo architecture comprises parametric <b>stereo</b> <b>coding</b> where the spatial properties of the stereo channels are modeled {{with the use of}} parameters, which are encoded and transmitted to the decoder together with an encoded downmix of the stereo channels. The stereo architecture has been implemented in MATLAB with an external mono coding using a floating point ANSI-C implementation of the ITU-T G. 719 codec. Two parametric stereo models have been implemented in a framework operating in the complex-valued Modified Discrete Fourier Transform (MDFT) domain. The first model is based on the inter-channel cues that represent level differences, time differences and coherences between the stereo channels. The cues approximate the corresponding interaural cues that characterize our localization of sound in space. The second model is based on the Karhunen-Loève Transform (KLT) with the associated rotation angles, the inter-channel time differences and the residual scaling parameters. An improved MDFT domain extraction of the inter-channel time difference between the stereo channels has been used for both stereo models. The extracted stereo parameters have been non-uniformly quantized based on the spatial accuracy and the frequency dependency of the human auditory system. The data rate of the stereo parameters has been estimated for each model to around 4 kbps. As a result G. 719 {{has been used as a}} core codec at 44 and 60 kbps in order to subjectively evaluate the performance of the fullband stereo codec at 48 and 64 kbps. In the comparison with G. 719 dual mono coding, i. e. independent mono <b>coding</b> of the <b>stereo</b> channels, the evaluation showed a higher performance of the proposed stereo models for complex clean and reverberant speech signals. However, no consistent gain of the parametric <b>stereo</b> <b>coding</b> was revealed for noisy speech, mixed content and music signals. In addition, the first stereo model showed consistently a slightly higher performance than the second model in the subjective evaluation but with no significant difference. The results revealed a high potential for parametric <b>stereo</b> <b>coding</b> using the ITU-T G. 719 codec. In comparison to the existing stereo codecs 3 GPP AMR-WB+ and 3 GPP eAAC+ the average performance was better at the equal bitrate of 48 kbps...|$|R
25|$|A {{working group}} {{consisting}} of van de Kerkhof, Stoll, Italian Leonardo Chiariglione (CSELT VP for Media), Frenchman Yves-François Dehery, German Karlheinz Brandenburg, and American James D. Johnston (United States) took ideas from ASPEC, integrated the filter bank from Layer II, added {{some of their}} own ideas such as the joint <b>stereo</b> <b>coding</b> of MUSICAM and created the MP3 format, which was designed to achieve the same quality at 128kbit/s as MP2 at 192kbit/s.|$|R
30|$|In general, stereo video {{sequences}} {{are composed}} of left and right images acquired from two slightly different viewpoints, thus making them similar and containing a lot of redundant information. Fractal compression is an effective method to remove the redundancy. But traditional (2 D) fractal coding makes the depth perception defective. In this article, we proposed disparity compensated prediction (DCP) and motion compensated prediction (MCP) which are used in fractal <b>stereo</b> <b>coding</b> to conquer these problems.|$|R
50|$|A {{working group}} {{consisting}} of van de Kerkhof, Stoll, Italian Leonardo Chiariglione (CSELT VP for Media), Frenchman Yves-François Dehery, German Karlheinz Brandenburg, and American James D. Johnston (United States) took ideas from ASPEC, integrated the filter bank from Layer II, added {{some of their}} own ideas such as the joint <b>stereo</b> <b>coding</b> of MUSICAM and created the MP3 format, which was designed to achieve the same quality at 128 kbit/s as MP2 at 192 kbit/s.|$|R
50|$|Because {{only one}} audio channel is transmitted, {{along with the}} {{parametric}} side info, a 24 kbit/s coded audio signal with Parametric Stereo will be substantially improved in quality, compared to a discretely <b>stereo</b> <b>coded</b> audio signal coded with conventional means. Thus, the additional bitrate spent on the single mono channel (combined with some PS side info) will improve the perceived quality substantially of the audio compared to a standard stereo stream at similar bitrate.|$|R
40|$|A {{scheme for}} <b>stereo</b> audio <b>coding</b> is {{proposed}} {{consisting of a}} 2 -channel linear prediction stage in combination with a single rotator. It is argued that it combines different attractive features of existing <b>stereo</b> <b>coding</b> mechanisms. It is experimentally shown that for unequal orders of auto- and cross-predictors, {{the stability of the}} synthesis system cannot always be guaranteed. For equal orders, the Block-Levinson algorithm is applicable, which is the basis for the proof of the stability of the synthesis filter. It is shown that the forward and the backward error signal vectors appearing in a 2 -channel lattice filter implementation are coupled via a 2 -channel allpass filter. This latter finding can be used as the basis for an alternative proof of the stability of the synthesis system...|$|R
40|$|For {{real-time}} {{as well as}} off-line {{transmission of}} high quality audio signals over the Internet, the best quality at very low bit-rate is desired. MPEG- 2 Layer 3 audio supports close to FM stereo quality (11 kHz bandwidth, 24 kHz sampling frequency) at 64 kbit/s total bit rate using advanced <b>stereo</b> <b>coding</b> techniques. The decoder supports real-time decoding on workstations or fast PCs. Different implementations of the encoder and the decoder and their use for Internet transmission of high quality audio are described...|$|R
40|$|Vision {{researchers}} have advocated {{the integration of}} vision modules. However, generic system integration issues for recovering 3 D information have not been adequately addressed in the literature. We propose a unified Bayesian integration framework for interactions among the vision modules to obtain a complete 3 D reconstruction {{from a pair of}} <b>intensity</b> (<b>stereo)</b> images. We integrate perceptual grouping, stereo, shape from shading, and shape from texture modules under the proposed framework and demonstrate that the integrated system recovers the depth and surface orientation information more reliably than the individual modules for different synthetic and real images...|$|R
50|$|Currently, the {{majority}} of digital TV broadcasts use <b>stereo</b> audio <b>coding.</b> MPEG Surround {{could be used to}} extend these established services to surround sound, as with DAB.|$|R
