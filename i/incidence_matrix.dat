749|242|Public
25|$|The <b>incidence</b> <b>matrix</b> of a quasisymmetric 2-(v,k,λ) {{design with}} k ≡ x ≡ y (mod 2) generates a binary self-orthogonal code (when bordered if k is odd).|$|E
25|$|This {{construction}} is reversible, and the <b>incidence</b> <b>matrix</b> of a symmetric 2-design with these parameters {{can be used}} to form an Hadamard matrix of size 4a.|$|E
25|$|Given an Hadamard {{matrix of}} order 4a in {{standardized}} form, remove {{the first row}} and first column and convert every −1 to a 0. The resulting 0–1 matrix M is the <b>incidence</b> <b>matrix</b> of a symmetric 2nbsp&−nbsp&(4anbsp&−nbsp&1, 2anbsp&−nbsp&1, anbsp&−nbsp&1) design called an Hadamard 2-design. This construction is reversible, and the <b>incidence</b> <b>matrix</b> of a symmetric 2-design with these parameters {{can be used to}} form an Hadamard matrix of order 4a. When anbsp&=nbsp&2 we obtain the, by now familiar, Fano plane as an Hadamard 2-design.|$|E
40|$|In this work, we {{have made}} some {{modifications}} on {{the definition of the}} <b>incidence</b> <b>matrices</b> of a directed graph, to let the <b>incidence</b> <b>matrices</b> to be   more  confident for X – Labeled graphs.   The new <b>incidence</b> <b>matrices</b> are called  the <b>incidence</b> <b>matrices</b> of  X – Labeled graphs, and  we used the new definition to give a computer program for Nickolas`s Algorithm...|$|R
50|$|In mathematics, the Parry-Sullivan {{invariant}} (or Parry-Sullivan number) is {{a numerical}} quantity {{of interest in}} the study of <b>incidence</b> <b>matrices</b> in graph theory, and of certain one-dimensional dynamical systems. It provides a partial classification of non-trivial irreducible <b>incidence</b> <b>matrices.</b>|$|R
30|$|HPN [8] are an {{extension}} of standard PN. They model the coexistence of discrete and continuous variables. HPN have two groups of places and transitions: discrete and continuous. Thus, there are three kinds of directed arcs here: (i) between discrete places and discrete transitions (described by the <b>incidence</b> <b>matrices</b> Pre_dd and Post_dd); (ii) between continuous places and continuous transitions (described by the <b>incidence</b> <b>matrices</b> Pre_cc and Post_cc); (iii) between discrete places and continuous transitions (described by the <b>incidence</b> <b>matrices</b> Pre_dc and Post_dc) {{as well as between}} the continuous places and discrete transitions (described by the <b>incidence</b> <b>matrices</b> Pre_cd and Post_cd). The discrete places and transitions handle discrete tokens, while the continuous places and transitions handle continuous variables.|$|R
25|$|The <b>incidence</b> <b>matrix</b> of block designs {{provide a}} natural source of {{interesting}} block codes {{that are used}} as error correcting codes. The rows of their incidence matrices are also used as the symbols in a form of pulse-position modulation.|$|E
25|$|The <b>incidence</b> <b>matrix</b> of a BTD (where {{the entries}} are the multiplicities of the {{elements}} in the blocks) {{can be used to}} form a ternary error-correcting code analogous to the way binary codes are formed from the incidence matrices of BIBDs.|$|E
25|$|The {{rigidity}} matroids {{describe the}} {{degrees of freedom}} of mechanical linkages formed by rigid bars connected at their ends by flexible hinges. A linkage of this type may {{be described as a}} graph, with an edge for each bar and a vertex for each hinge, and for one-dimensional linkages the rigidity matroids are exactly the graphic matroids. Higher-dimensional rigidity matroids may be defined using matrices of real numbers with a structure {{similar to that of the}} <b>incidence</b> <b>matrix</b> of the underlying graph, and hence are -linear.|$|E
50|$|<b>Incidence</b> <b>matrices</b> {{are mostly}} used in graph theory.|$|R
40|$|AbstractWe {{examine the}} p-ary codes, for any prime p, {{that can be}} {{obtained}} from <b>incidence</b> <b>matrices</b> and line graphs of the Hamming graphs, H(n,m), obtaining the main parameters of these codes. We show that the codes from the <b>incidence</b> <b>matrices</b> of H(n,m) can be used for full permutation decoding for all m,n≥ 3...|$|R
40|$|We define <b>incidence</b> <b>{{matrices}}</b> to be zero-one matrices with no zero rows or columns. A {{classification of}} <b>incidence</b> <b>matrices</b> is considered for which conditions of symmetry by transposition, having no repeated rows/columns, or identification by permutation of rows/columns are imposed. We find asymptotics and relationships {{for the number}} of matrices with n ones in these classes as n → ∞...|$|R
25|$|Matrix {{structures}} {{include the}} <b>incidence</b> <b>matrix,</b> {{a matrix of}} 0's and 1's whose rows represent vertices and whose columns represent edges, and the adjacency matrix, in which both the rows and columns are indexed by vertices. In both cases a 1 indicates two adjacent objects and a 0 indicates two non-adjacent objects. The Laplacian matrix is a modified form of the adjacency matrix that incorporates information about the degrees of the vertices, and is useful in some calculations such as Kirchhoff's theorem {{on the number of}} spanning trees of a graph.|$|E
25|$|A {{framework}} is an undirected graph, embedded into d-dimensional Euclidean space {{by providing a}} d-tuple of Cartesian coordinates for each vertex of the graph. From a framework with n vertices and m edges, one can define a matrix with m rows and nd columns, an expanded version of the <b>incidence</b> <b>matrix</b> of the graph called the rigidity matrix. In this matrix, the entry in row e and column (v,i) is zero if v is not an endpoint of edge e. If, on the other hand, edge e has vertices u and v as endpoints, then {{the value of the}} entry is the difference between the ith coordinates of v and u.|$|E
500|$|Hypergraphs can be characterised {{by their}} {{incidence}} matrices. [...] A regular graph containing only two-terminal components will have exactly two non-zero entries in each row. [...] Any <b>incidence</b> <b>matrix</b> {{with more than}} two non-zero entries in any row is a representation of a hypergraph. [...] The number of non-zero entries in a row is the rank of the corresponding branch, and the highest branch rank is the rank of the <b>incidence</b> <b>matrix.</b>|$|E
40|$|Abstract. We {{discuss the}} problem of {{counting}} <b>incidence</b> <b>matrices,</b> i. e. zero-one matrices with no zero rows or columns. Using different approaches we give three different proofs for the leading asymptotics {{for the number of}} matrices with n ones as n → ∞. We also give refined results for the asymptotic number of i × j <b>incidence</b> <b>matrices</b> with n ones. 1...|$|R
25|$|Whitehead, J.H.C., On <b>incidence</b> <b>matrices,</b> nuclei and {{homotopy}} types, Annals of Math. 42 (1941), 1197–1239.|$|R
40|$|We {{identify}} {{a relationship between}} a random walk on a certain Eu-clidean lattice and <b>incidence</b> <b>matrices</b> of balanced incomplete block de-signs. We then compute the return probability of the random walk {{and use it to}} obtain the asymptotic number of BIBD <b>incidence</b> <b>matrices</b> (as the number of columns increases). Our strategy is similar in spirit to the one used by de Launey and Levin to count partial Hadamard matrices. ...|$|R
500|$|Incidence {{is one of}} {{the basic}} {{properties}} of a graph. [...] An edge that is connected to a vertex is said to be incident on that vertex. [...] The incidence of a graph can be captured in matrix format with a matrix called an <b>incidence</b> <b>matrix.</b> [...] In fact, the <b>incidence</b> <b>matrix</b> is an alternative mathematical representation of the graph which dispenses with the need for any kind of drawing. [...] Matrix rows correspond to nodes and matrix columns correspond to branches. [...] The elements of the matrix are either zero, for no incidence, or one, for incidence between the node and branch. [...] Direction in directed graphs is indicated by the sign of the element.|$|E
500|$|Graph {{theory has}} been used in the network {{analysis}} of linear, passive networks almost from the moment that Kirchhoff's laws were formulated. [...] Gustav Kirchhoff himself, in 1847, used graphs as an abstract representation of a network in his loop analysis of resistive circuits. [...] This approach was later generalised to RLC circuits, replacing resistances with impedances. [...] In 1873 James Clerk Maxwell provided the dual of this analysis with node analysis. [...] Maxwell is also responsible for the topological theorem that the determinant of the node-admittance matrix is equal to the sum of all the tree admittance products. [...] In 1900 Henri Poincaré introduced the idea of representing a graph by its <b>incidence</b> <b>matrix,</b> hence founding the field of algebraic topology. [...] In 1916 Oswald Veblen applied the algebraic topology of Poincaré to Kirchhoff's analysis. [...] Veblen is also responsible for the introduction of the spanning tree to aid choosing a compatible set of network variables.|$|E
2500|$|A {{corresponding}} <b>incidence</b> <b>matrix</b> is {{specified in}} the following table: ...|$|E
5000|$|J. H. C. Whitehead, On <b>incidence</b> <b>matrices,</b> nuclei and {{homotopy}} types, Ann. of Math. (2) 42 (1941), 1197 - 1239.|$|R
5000|$|On {{the use of}} <b>incidence</b> <b>matrices</b> of {{designs in}} {{sampling}} from finite populations, MC Chakrabarti - Journal of Indian Statistical Association, 1963 ...|$|R
40|$|We obtain {{explicit}} formulae for {{the values}} of the v - j minors, j = 0, 1, 2 of (1, - 1) <b>incidence</b> <b>matrices</b> of SBIBD(v, k, λ). This allows us to obtain explicit information on the growth problem for families of matrices with moderate growth. An open problem remains to establish whether the (1, - 1) CP <b>incidence</b> <b>matrices</b> of SBIBD(v, k, λ), can have growth greater than v for families other than Hadamard families...|$|R
2500|$|Given an Hadamard {{matrix of}} size 4a in {{standardized}} form, remove {{the first row}} and first column and convert every −1 to a 0. The resulting 0–1 matrix M is the <b>incidence</b> <b>matrix</b> of a symmetric 2-(4a1, 2a1, a1) design called an Hadamard 2-design.|$|E
2500|$|All {{eigenvalues}} of the {{adjacency matrix}} [...] {{of a line}} graph are at least 2. The {{reason for this is}} that [...] can be written as , where [...] is the signless <b>incidence</b> <b>matrix</b> of the pre-line graph and [...] is the identity. In particular, [...] is the Gramian matrix of a system of vectors: all graphs with this property have been called generalized line graphs.|$|E
2500|$|Take an {{oriented}} diagram [...] of {{the knot}} with n crossings; there are n+2 {{regions of the}} knot diagram. To work out the Alexander polynomial, first one must create an <b>incidence</b> <b>matrix</b> of size (n, n+2). [...] The n rows correspond to the n crossings, and the n+2 columns to the regions. The values for the matrix entries are either 0, 1, −1, t, −t.|$|E
50|$|It can {{be shown}} that, for nontrivial {{irreducible}} <b>incidence</b> <b>matrices,</b> flow equivalence is completely determined by the Parry-Sullivan number and the Bowen-Franks group.|$|R
40|$|We {{consider}} {{a series of}} configurations defined by fibers of a given base configuration. We prove that Markov degree of the configurations is bounded from above by the Markov complexity of the base configuration. As important examples of base configurations we consider <b>incidence</b> <b>matrices</b> of graphs and study the maximum Markov degree of configurations defined by fibers of the <b>incidence</b> <b>matrices.</b> In particular we give a proof that the Markov degree for two-way transportation polytopes is three. Comment: 28 page...|$|R
3000|$|From {{the data}} {{structure}} representing a cellular mesh, {{that is a}} regular cell complex, we can deduce the <b>incidence</b> <b>matrices</b> representing the boundary operators. The [...]...|$|R
2500|$|The graphic matroid of a graph [...] can {{be defined}} as the column matroid of any {{oriented}} <b>incidence</b> <b>matrix</b> of [...] Such a matrix has one row for each vertex, and one column for each edge. The column for edge [...] has [...] in the row for one endpoint, [...] in the row for the other endpoint, and [...] elsewhere; the choice of which endpoint to give which sign is arbitrary. The column matroid of this matrix has as its independent sets the linearly independent subsets of columns.|$|E
50|$|It was {{realized}} {{later that}} these conditions define an <b>incidence</b> <b>matrix</b> {{of a balanced}} signed graph; thus, this example says that the <b>incidence</b> <b>matrix</b> of a signed graph is totally unimodular if the signed graph is balanced. The converse is valid for signed graphs without half edges (this generalizes {{the property of the}} unoriented <b>incidence</b> <b>matrix</b> of a graph).|$|E
5000|$|If an {{incidence}} structure [...] has an <b>incidence</b> <b>matrix</b> , {{then the}} dual structure [...] has the transpose matrix T as its <b>incidence</b> <b>matrix</b> (and {{is defined by}} that matrix).|$|E
40|$|We {{discuss the}} problem of {{counting}} <b>incidence</b> <b>matrices,</b> i. e. zero-one matrices with no zero rows or columns. Using different approaches we give three different proofs for the leading asymptotics {{for the number of}} matrices with n ones as n→∞. We also give refined results for the asymptotic number of i× j <b>incidence</b> <b>matrices</b> with n ones. Comment: jpconf style files. Presented at the conference "Counting Complexity: An international workshop on statistical mechanics and combinatorics. " In celebration of Prof. Tony Guttmann's 60 th birthda...|$|R
40|$|The paper {{presents}} a construction of very high-rate low-density parity-check (LDPC) codes based on <b>incidence</b> <b>matrices</b> of unital designs. Like the projective geometry and oval designs, unital designs exist with <b>incidence</b> <b>matrices</b> which are significantly rank deficient. Thus high-rate LDPC codes {{with a large}} number of linearly dependent parity-check equations can be constructed. The LDPC codes from unitals have Tanner graphs free of 4 -cycles and perform well with iterative decoding, offering new LDPC codes at rates and lengths not available with existing algebraic LDPC codes...|$|R
40|$|Looking at <b>incidence</b> <b>{{matrices}}</b> of t-(v,k,λ) designs as v × b matrices with 2 possible entries, each {{of which}} indicates incidences of a t-design, we introduce {{the notion of a}} c-mosaic of designs, having the same number of points and blocks, as a matrix with c different entries, such that each entry defines incidences of a design. In fact, a v × b matrix is decomposed in c <b>incidence</b> <b>matrices</b> of designs, each denoted by a different colour, hence this decomposition might be seen as a tiling of a <b>matrix</b> with <b>incidence</b> <b>matrices</b> of designs as well. These mosaics have applications in experiment design when considering a simultaneous run of several different experiments. We have constructed infinite series of examples of mosaics and state some probably non-trivial open problems. Furthermore we extend our definition to the case of q-analogues of designs in a meaningful way...|$|R
