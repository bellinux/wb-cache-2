9|21|Public
5000|$|The Terak 8510/a of 1976 or 1977 was {{the first}} {{graphics}} desktop personal computer. It was a desktop workstation with an LSI-11 compatible processor, a <b>graphical</b> <b>frame</b> buffer, and a text mode with downloadable fonts. Despite {{the lack of a}} MMU, it was capable of running a stripped version of UNIX version 6. It {{was the first}} personal machine on which the UCSD p-System was widely used. Various universities in the USA used it in the late 1970s and early 1980s to teach Pascal programming. It provided immediate graphic feedback from simple programs encouraging students to learn.|$|E
40|$|Abstract-WWW {{is a vast}} {{source of}} {{information}} and search engines are the meshwork to navigate the web for several purposes. It is problematic to identify and ping with <b>graphical</b> <b>frame</b> of mind for the desired information amongst the large set of web pages resulted by the search engine. With further increase {{in the size of}} the Internet, the problem grows exponentially. This paper is an endeavor to develop and implement an efficient framework with multi search agents to make search engines inapt to chaffing using curl features of the programming, called CurlCrawler. This work is an implementation experience for use of graphical perception to upright search on the web. Main features of this framework are curl programming, personalization of information, caching and graphical perception. about basic modules of search engine functioning and these essential modules are (see Fig. 1) [9, 10]...|$|E
40|$|Current {{views in}} the {{teaching}} and learning of data handling suggest that learners should create graphs of data they collect themselves and not just use textbook data. It is presumed real-world data creates an ideal environment for learners to tap from their pool of stored knowledge and demonstrate their meta-representational competences. Although prior knowledge is acknowledged as a critical resource out of which expertise is constructed, empirical evidence shows that new levels of mathematical thinking do not always build logically and consistently on previous experience. This suggests that researchers should analyse this resource in more detail in order to understand where prior knowledge could be supportive and where it could be problematic in the process of learning. This article analyses Grade 11 learners’meta-representational competences when constructing bar graphs. The basic premise was that by examining the process of graph construction and how learners respond to a variety of stages thereof, it was possible to create a description of a <b>graphical</b> <b>frame</b> or a knowledge representation structure that was stored in the learner’s memory. Errors could then be described and explained in terms of the inadequacies of the frame, that is: ‘Is the learner making good use of the stored prior knowledge?’ A total of 43 learners were observed over a week in a classroom environment whilst they attempted to draw graphs for data they had collected for a mathematics project. Four units of analysis are used to focus on how learners created a frequency table, axes, bars and the overall representativeness of the graph vis-à-vis the data. Results show that learners had an inadequate <b>graphical</b> <b>frame</b> as they drew a graph that had elements of a value bar graph, distribution bar graph and a histogram all representing the same data set. This inability to distinguish between these graphs and the types of data they represent implies that learners were likely to face difficulties with measures of centre and variability which are interpreted differently across these three graphs but are foundational in all statistical thinking...|$|E
5000|$|Begin {{a render}} loop that {{produces}} <b>graphical</b> <b>frames</b> to be {{displayed on the}} VR device.|$|R
40|$|Text-to-scene {{conversion}} requires {{knowledge about}} how actions and locations {{are expressed in}} language and realized in the world. To provide this knowlege, we are creating a lexical resource (VigNet) that extends FrameNet by creating a set of intermediate frames (vignettes) that bridge between the high-level semantics of FrameNet frames and {{a new set of}} low-level primitive <b>graphical</b> <b>frames.</b> Vignettes {{can be thought of as}} a link between function and form – between what a scene means and what it looks like. In this paper, we describe the set of primitive <b>graphical</b> <b>frames</b> and the functional properties of 3 D objects (affordances) we use in this decomposition. We examine the methods and tools we have developed to populate VigNet with a large number of action and location vignettes...|$|R
5000|$|In Europe before 1900, {{the science}} of <b>graphical</b> {{perspective}} <b>framed</b> geometrical exercises. For example, in 1719 Brook Taylor wrote in New Principles of Linear Perspective ...|$|R
40|$|The {{paper is}} to define {{interface}} design principles for web site design through user experiences in net art {{that will allow the}} designer to achieve truly user-centred design (UCD). Net art enables the designers {{to bridge the gap between}} traditional graphic design and interactive user experience in that it has empowered the users to be an interactive artist. Analysis of the characteristics of net art indicates that understanding of online users from generic approach to visual design could confine UCD into a merely visible <b>graphical</b> <b>frame.</b> Furthermore, it implies that the interactivity will degenerate into one-way communication so long as designers define the Internet user as a user which is the opposite concept to a producer. The paper presents the four principles extracted from net art for interactive experience design - invisible design elements, collaborative participation, Anarchic structure and non-linear communication. Note: This paper is the extension of 'Interactive design principles: online communities and the user experience' (Park 2007) published in Journal of Digital Design (vol. 14) and the both studies were intended to provide the theoretical foundation for developing a conceptual framework of interactive user experience design. ...|$|E
40|$|Figure 1 : Simulation of a {{peach tree}} with anatomically {{realistic}} geometry (Prunus Persica), with fracture. Peaches {{fall from the}} tree swaying in the space-time Perlin wind. 299, 707 triangles, 237 branches, 3, 556 twigs, 18, 536 leaves, 330 fruits, 2, 950 reduced DOFs, 7 hierarchy levels, 5 msec of simulation per <b>graphical</b> <b>frame.</b> Physically based simulation can produce quality motion of plants, but requires an authoring stage to convert plant “polygon soup” triangle meshes to a format suitable for physically based simula-tion. We give a system that can author complex simulation-ready plants {{in a manner of}} minutes. Our system decomposes the plant geometry, establishes a hierarchy, builds and connects simulation meshes, and detects instances. It scales to anatomically realistic geometry of adult plants, is robust to non-manifold input geometry, gaps between branches or leaves, free-flying leaves not connected to any branch, spurious geometry, and plant self-collisions in the in-put configuration. We demonstrate the results using a FEM model reduction simulator that can compute large-deformation dynamics of complex plants at interactive rates, subject to user forces, grav-ity or randomized wind. We also provide plant fracture (with pre-specified patterns), inverse kinematics to easily pose plants, as well as interactive design of plant material properties. We authored and simulated over 100 plants from diverse climates and geographic re-gions, including broadleaf (deciduous) trees and conifers, bushes and flowers. Our largest simulations involve anatomically realistic adult trees with hundreds of branches and over 100, 000 leaves...|$|E
40|$|Information is a {{vital role}} playing {{versatile}} thing from availability at church level to web through trends of books. WWW is now the exposed and up-to-date huge repository of information available to everyone, everywhere and every time [1]. It is the thrust arena of engineering endeavor and is evolving without a grand design blueprint. Finally, an age has come, where information has become an instrument, a tool {{that can be used}} to solve many problems. The biggest challenge being posed by the Internet is its ever-growing size with the availability of endless pool of information hosted on the World Wide Web (WWW). It is problematic to identify and ping with <b>graphical</b> <b>frame</b> of mind for the desired information amongst the large set of web pages resulted by the search engine with reduced chaffing and cross features of the framework. With further increase in the size of the Internet, the problem grows exponentially. Crawlers can retrieve data much quicker and in greater depth than human searchers, so they can have a crippling impact on the performance of a site [7, 17]. Needless to say that building an effective web crawler to solve your purpose is not a difficult task, but choosing the right strategies and building an effective architecture will lead to implementation of multi-agent framework to outcome highly featured web crawler application [2, 3]. This paper is an experimental strives to develop and implement an extended framework with extended architecture to make search engines more efficient using local resource utilization features of the programming. This work is an implementation experience for use of focused and path oriented approach to provide a cross featured framework for search engines with human powered approach. In addition to curl programming, personalization of information, caching and graphical perception, main features of this framework are cross platform, cross architecture, focused, path oriented and human powered...|$|E
40|$|Living Color Frame Maker (LCFM) {{computer}} program generates computer-graphics <b>frames.</b> <b>Graphical</b> <b>frames</b> saved as text files, in readable and disclosed format, easily retrieved and manipulated by user programs for {{wide range of}} real-time visual information applications. LCFM implemented in frame-based expert system for visual aids in management of systems. Monitoring, diagnosis, and/or control, diagrams of circuits or systems brought to "life" by use of designated video colors and intensities to symbolize status of hardware components (via real-time feedback from sensors). Status of systems can be displayed. Written in C++ using Borland C++ 2. 0 compiler for IBM PC-series computers and compatible computers running MS-DOS...|$|R
5000|$|... #Caption: Composite of Early BioBIKE Lisp-Listener Style Interaction {{depicting}} {{knowledge base}} <b>frames,</b> <b>graphical</b> I/O, and through-the-web Lisp programmability.|$|R
30|$|All {{surgical}} interventions {{were recorded}} and the available vascular obturator variations were {{registered in the}} course of operation. The records were reviewed later, appropriate images were processed and by using a <b>graphical</b> editor, <b>frames</b> of the basic types of obturator vascular variations were selected. Standard statistical methods were used for data description.|$|R
40|$|The {{goal with}} the project {{was to make the}} graphic for Djungeltrumman. se´s {{upcoming}} webb-TV. Djungeltrumman. se is a clubguide on the internet and as a magazine. Their target group is people in the age between 18 - 34 with an interest for culture and nightlife that lives in a city where Djungeltrumman. se is active. The purpose of the project was to make a <b>graphical</b> <b>frame</b> that had the feelling of Djungeltrumman. se. The feeling should capture the interest of the target group and make them care more for Djungeltrumman. se. The graphics will contain an intro, information frames and presentations for the different parts in the program. In this project I focused on making the intro for the program. The other graphical content will later on be based on the intro. How can I make an intro that captures the interest of the targetgroup, again and again without them getting tired of it? With what and how do you present Djungeltrumman. se best in motion graphic? A television intro? What does the history tell about it? The making of the intro was focused on the three keywords, the city, energy and guidance. And from those words I made a colour pallet. The biggest decision was to build a real model of a city. With that I got a depth in the footage that never could be made in 3 d. Every little part of the model had something to tell. Ruff edges and windows that were cut by hand gave a charming look. The result of my project was an intro that communicated the feeling of Djungeltrumman. se with my keyword the city, energy and guidance. It captures the interest of the viewer that wants to see it again and again...|$|E
40|$|With {{the advent}} of 4 G and other {{long-term}} evolution (LTE) wireless networks, the traditional boundaries of patient record propagation are diminishing as networking technologies extend the reach of hospital infrastructure and provide on-demand mobile access to medical multimedia data. However, due to legacy and proprietary software, storage and decommissioning costs, {{and the price of}} centralization and redevelopment, it remains complex, expensive, and often unfeasible for hospitals to deploy their infrastructure for online and mobile use. This paper proposes the SparkMed data integration framework for mobile healthcare (m-Health), which significantly benefits from the enhanced network capabilities of LTE wireless technologies, by enabling a wide range of heterogeneous medical software and database systems (such as the picture archiving and communication systems, hospital information system, and reporting systems) to be dynamically integrated into a cloud-like peer-to-peer multimedia data store. Our framework allows medical data applications to share data with mobile hosts over a wireless network (such as WiFi and 3 G), by binding to existing software systems and deploying them as m-Health applications. SparkMed integrates techniques from multimedia streaming, rich Internet applications (RIA), and remote procedure call (RPC) frameworks to construct a Self-managing, Pervasive Automated netwoRK for Medical Enterprise Data (SparkMed). Further, it is resilient to failure, and able to use mobile and handheld devices to maintain its network, {{even in the absence of}} dedicated server devices. We have developed a prototype of the SparkMed framework for evaluation on a radiological workflow simulation, which uses SparkMed to deploy a radiological image viewer as an m-Health application for telemedical use by radiologists and stake-holders. We have evaluated our prototype using ten devices over WiFi and 3 G, verifying that our framework meets its two main objectives: 1) interactive delivery of medical multimedia data to mobile devices; and 2) attaching to non-networked medical software processes without significantly impacting their performance. Consistent response times of under 500 ms and <b>graphical</b> <b>frame</b> rates of over 5 frames per second were observed under intended usage conditions. Further, overhead measurements displayed linear scalability and low resource requirements. Department of Electronic and Information Engineerin...|$|E
40|$|A {{prototype}} of a haptic and virtual reality simulator {{has been developed}} for simulation of the bone milling and material removal process occurring in several operations, e. g. temporal bone surgery or dental milling. The milling phase of an operation is difficult, safety critical and very time consuming. Reduction of operation time by only a few percent would {{in the long run}} save society large expenses. In order to reduce operation time and to provide surgeons with an invaluable practicing environment, this licentiate thesis discusses the introduction of a simulator system to be used in both surgeon curriculum and in close connection to the actual operations. The virtual reality and haptic feedback topics still constitute a young and unexplored area. It has only been active for about 10 - 15 years for medical applications. High risk training on real patients and the change from open surgery to endoscopic procedures have enforced the introduction of haptic and virtual reality simulators for training of surgeons. Increased computer power and the similarity to the successful aviation simulators also motivate to start using simulators for training of surgical skills. The research focus has been twofold: 1) To develop a well working VR-system for realistic graphical representation of the skull itself including the changes resulting from milling, and 2) to find an efficient algorithm for haptic feedback to mimic the milling procedure using the volumetric Computer Tomography (CT) data of the skull. The developed haptic algorithm has been verified and tested in the simulator. The visualization of the milling process is rendered at a <b>graphical</b> <b>frame</b> rate of 30 Hz and the haptic rendering loop is updated at 1000 Hz. Test results show that the real-time demands are fulfilled. The visual and haptic implementations have been the two major steps to reach the over all goal with this research project. A survey study is also included where the use of VR and haptic simulators in the surgical curriculum is investigated. The study starts with a historical perspective of the VR and haptic topics and is built up by answering different questions related to this topic and the implementation of simulators at the medical centres. The questions are of general concern for those developing surgical VR and haptic simulators. Suggested future work includes modelling, development and validation of the haptic forces occurring in the milling process and, based on this, implementation in the simulator system. Also, further development of the simulator should be done in close cooperation with surgeons in order to get appropriate feedback for further improvements of the functionality and performance of the simulator. QC 2010111...|$|E
40|$|Graphical {{representations}} of political issues and economic trends are an increasingly popular means of conveying {{information to the}} public. However, graphs {{have the potential to}} shape public opinion by visually emphasizing or downplaying the information they convey. I randomly assign subjects to view graphs that represent the same underlying information but that differ in relative emphasis: one is consistent with a textual account of rising inequality, while the other de-emphasizes the same information by increasing the scale of the Y-axis. My results indicate that <b>graphical</b> <b>frames</b> provide powerful contextual cues: for Republicans and conservatives, exposure to the de-emphasizing graph results in a 40 % decrease in expressed support for intervention against inequality relative to Republicans and conservatives in the control condition, despite the fact that both groups read the same textual information. My findings reveal how an increasingly important and unexamined form of political communication affects public opinion, also suggesting promising avenues for future research...|$|R
40|$|Interactive {{entertainment}} {{has long}} {{been one of the}} driving factors behind architectural innovation, pushing the boundaries of computing to achieve ever more realistic virtual experiences. Future entertainment applications will feature robust physics modeling to enable on-the-fly content creation. However, application designers must provide at least 30 <b>graphical</b> <b>frames</b> per second to provide the illusion of visual continuity. This constraint directly impacts the physics engine, which must deliver the results of physical interactions in the virtual world at a fraction of this frame rate. With more sophisticated applications combining massive numbers of complex entities, the cost of robust physics simulation will easily exceed the capability of today’s most power machines. This work explores the characteristics of real-time physics simulation, and proposes a suite of future-thinking benchmarks stressing different situations that represent the demands of future interactive entertainment. With this suite, we then explore techniques to help meet these demands, including parallel execution, a fast estimation approach that self-regulates error, and a value prediction technique that is allowed to get “close enough ” to the real value. We demonstrate that parallel execution together with the proposed fast estimation approach can satisfy the demands of nearly all of the PhysicsBench suite...|$|R
40|$|The Generic Frame Protocol (GFP) is an {{application}} program interface for accessing knowledge bases stored in frame knowledge representation systems (FRSs). GFP provides a uniform model of FRSs based on a common conceptualization of frames, slots, facets, and inheritance. GFP consists {{of a set of}} Common Lisp functions that provide a generic interface to underlying FRSs. This interface isolates {{an application}} from many of the idiosyncrasies of specific FRS software and enables the development of generic tools (e. g., <b>graphical</b> browsers, <b>frame</b> editors) that operate on many FRSs. To date, GFP has been used as an interface to LOOM, Ontolingua, THEO, and SIPE- 2. ...|$|R
40|$|The ADAMS {{computer}} program for automated analysis of mechanisms and machines is described. The program automatically formulates mathematical models for prototype or existing mechanisms with the minimum necessary physical and geometric data. The model {{can then be}} analyzed in various modes of analysis. The outputs (displacements, velocities, acceleration and forces) can be produced in tabular and <b>graphical</b> (plots, wire <b>frame</b> graphics) form. The application of this {{computer program}} to simulating satellite docking maneuvers is illustrated...|$|R
40|$|Computer {{graphics}} {{are often}} applied for better understanding {{and interpretation of}} data under observation. These graphics become more complicated when animation is required during "run-time", as found in many typical modern artificial intelligence and expert systems. Living Color Frame Maker is a solution to many of these real-time graphics problems. Living Color Frame Maker (LCFM) is a graphics generation and management tool for IBM or IBM compatible personal computers. To eliminate graphics programming, the graphic designer can use LCFM to generate computer graphics <b>frames.</b> The <b>graphical</b> <b>frames</b> are then saved as text files, in a readable and disclosed format, which can be easily accessed and manipulated by user programs {{for a wide range}} of "real-time" visual information applications. For example, LCFM can be implemented in a frame-based expert system for visual aids in management of systems. For monitoring, diagnosis, and/or controlling purposes, circuit or systems diagrams can be brought to "life" by using designated video colors and intensities to symbolize the status of hardware components (via real-time feedback from sensors). Thus status of the system itself can be displayed. The Living Color Frame Maker is user friendly with graphical interfaces, and provides on-line help instructions. All options are executed using mouse commands and are displayed on a single menu for fast and easy operation. LCFM is written in C++ using the Borland C++ 2. 0 compiler for IBM PC series computers and compatible computers running MS-DOS. The program requires a mouse and an EGA/VGA display. A minimum of 77 K of RAM is also required for execution. The documentation is provided in electronic form on the distribution medium in WordPerfect format. A sample MS-DOS executable is provided on the distribution medium. The standard distribution medium for this program is one 5. 25 inch 360 K MS-DOS format diskette. The contents of the diskette are compressed using the PKWARE archiving tools. The utility to unarchive the files, PKUNZIP. EXE, is included. The Living Color Frame Maker tool was developed in 1992...|$|R
40|$|This paper {{examines}} {{the importance of}} the context in which a medical alternative is presented to individuals. It raises a number of questions about the presentation of risk information in a healthcare leaflet. In line with prior research, risk format may influence healthcare decisions (Stone et al., 1997; Feldman-Stewart, 2000; Schapira, et al., 2001). The main aim of this research was to the impacts of attribute framing, statistical format of risk information and visual representation effect from graphical display on the persuasiveness of a health communication, by measuring the likelihood of adopting the doctor’s recommendation. Attribute <b>framing,</b> <b>graphical</b> display and statistical formats of risk probabilistic information were examined to explain the conditions under which messages would be more effective in a health communication. Study 1 demonstrated the interaction between <b>framing</b> and <b>graphical</b> display: in the conditions with <b>graphical</b> display, positive <b>frames</b> were more effective than negative frames, whereas in the conditions without graphical display, positive and negative frames were equally persuasive. Study 2 extended the idea of frequency representation to investigate how people respond to messages based on different but equivalent forms of relative frequency information, and found that the enhancing effect of visual representation from graphical display disappeared when the messages were presented in a large rote of frequency...|$|R
40|$|This paper {{presents}} {{a framework for}} understanding Problem Frames that locates them within the Requirements Engineering model of Zave and Jackson, and its subsequent formalization in the Reference Model of Gunter et al. It distinguishes between problem frames, context diagrams and problem diagrams, and allows us to formally define the relationship between them as assumed in the Problem Frames framework. The semantics of a problem diagram is given in terms of `challenges', a notion that we also introduce. The notion of a challenge is interesting {{in its own right}} for two reasons: its proof theoretic derivation leads us to consider a challenge calculus that might underpin the Problem Frame operations of decomposition and recomposition; and it promises to extend the notion of formal refinement from software development to requirements engineering. In addition, the semantics supports a textual representation of the diagrams in which Problem Frames capture problems and their relationship to solutions. This could open the way for <b>graphical</b> Problem <b>Frames</b> tools. ...|$|R
40|$|Retrospective {{reports in}} survey {{interviews}} and questionnaires {{are subject to}} many types of recall error, which affect completeness, consistency, and dating accuracy. Concerns about this problem {{have led to the}} development of so-called calendar instruments, or timeline techniques. These aided recall procedures have been designed to help respondents gain better access to long-term memory by providing a <b>graphical</b> time <b>frame</b> in which life history information can be represented. In order to obtain more insights into the potential benefits of calendar methodology, this paper presents a review of the application of calendar instruments, their design characteristics and effects on data quality. Calendar techniques are currently used in a variety of fields, including life course research, epidemiology and family planning studies. Despite the growing interest in these new methods, their application often lacks sufficient theoretical foundation and little attention has been paid to their effectiveness. Several recent studies however, have demonstrated that in comparison to more traditional survey methods, calendar techniques can improve some aspects of data quality. While calendar instruments have been shown to be potentially beneficial to retrospective data quality, there is an apparent need for methodological research that generates more systematic knowledge about their application in social surveys...|$|R
5|$|Although the {{original}} PC version of Elite Force gained critical acclaim, the 2001 PlayStation 2 port received a more negative reception. Majesco's port {{of the game}} garnered mediocre reviews, holding scores of 54 percent and 52 percent on Game Rankings and Metacritic respectively. While the level design, story and atmosphere were praised, critics were negative towards what was seen to be a poorly performed port, with complaints focused on difficult controls, <b>graphical</b> problems and <b>frame</b> rate issues. In addition, the artificial intelligence was deemed to be significantly worse than the earlier PC incarnation of the game. Several reviews suggested that Majesco had simply not put effort into the port, resulting in a level of quality behind that which was expected of PlayStation 2 games at the time.|$|R
50|$|On July 24, 2007, Sega {{released}} a Nintendo DS {{version of the}} game in Japan to commemorate the five year anniversary of the franchise. The DS version comes with a scanner that players can use on their existing cards from the arcade game or cards exclusive to the DS game. The game comes with a starter deck that includes 7 cards, three of which give a random beetle in a specialized section every time they are used(rock, paper, and scissors). The game supports all of the arcade modes and includes a Wi-Fi mode to play against unseen players across Japan. Due to a significant difference in power between the Nintendo DS and the arcade machines, there is a noticeable difference in <b>graphical</b> quality and <b>frame</b> rate.|$|R
40|$|Many {{clustering}} {{problems can}} be reduced to the task of partitioning a weighted graph into highly-connected components. The weighted edges indicate pairwise similarity between two nodes and can often be estimated from training data. However, in many domains, there exist higherorder dependencies not captured by pairwise metrics. For example, there may exist soft constraints on aggregate features of an entire cluster, such as its size, mean or mode. We propose clusterwise similarity metrics to directly measure the cohesion of an entire cluster of points. We describe ways to learn a clusterwise metric from labeled data, using weighted, first-order features over clusters. Extending recent work equating graph partitioning with inference in <b>graphical</b> models, we <b>frame</b> this approach within a discriminatively-trained Markov network. The advantages of our approach are demonstrated on the task of coreference resolution. 1 Clusterwise Similarit...|$|R
40|$|Probabilistic {{graphical}} {{models are}} one of the most influential and widely used techniques in machine learning. Powered by exponential gains in processor technology, graphical models have been successfully applied to a wide range of increasingly large and complex real-world problems. However, recent developments in computer architecture, large-scale computing, and data-storage have shifted the focus away from sequential performance scaling and towards parallelism and large-scale distributed systems. Therefore, in order for graphical models to continue to benefit from developments in computer architecture and remain a viable option in the clouds and beyond, we must discover and exploit the parallelism of learning and inference in probabilistic graphical models. In this thesis we explore how to design efficient parallel algorithms for probabilistic <b>graphical</b> models by <b>framing</b> learning and inference as iterative adaptive asynchronous computation. We first present our work on efficient parallel algorithms for loopy belief propagation and Gibbs sampling. We then describe GraphLab, a new parallel abstraction for designing and implementing iterative adaptive asynchronous computation. Finally, we conclude wit...|$|R
40|$|The {{plethora of}} {{available}} Web design guidelines induces a credibility problem for designers: since most guidelines come from sources having various confidences, {{to what extent}} does applying these guidelines {{lead to a more}} usable web site that will be better accepted by users? A corpus of tested web design guidelines is therefore expected to answer that question. To reach such a corpus, five steps were performed: firstly, guidelines sources were categorized according to a source model; secondly, the most representative and interesting guidelines sources were selected according to certain criteria; thirdly, the selected guidelines were then categorized according to a general purpose model and subsequently gathered into an initial corpus; fourthly, particular guidelines subject to a user survey were identified; fifthly, these guidelines have been tested to see if users perceive any benefit in applying them. A first corpus of such guidelines was consequently composed into three parts: text-only sites, <b>graphical</b> sites, and <b>framed</b> sites. The contents of this corpus were used to develop an on-line version by a bootstrapping approach...|$|R
5000|$|Slide to Play's Andrew Podolsky was of {{a similar}} mind to IGN, feeling the series itself has become {{stagnant}} and scoring the game 3 out of 4 (the same score he had awarded Asphalt 5); [...] "Gameloft's got us {{in a bit of}} a bind. Their games consistently push the technical limits of the iPhone, with each new iteration in a long-running series like Asphalt looking and sounding better than the one before. But without a bit more creativity, the Asphalt series is starting to feel like it's stuck in second gear. The sixth Asphalt game (and the third on the iPhone) is another brilliant technical achievement. The environments are each detailed, colorful, and distinctive, and we detected almost no <b>graphical</b> pop-in or <b>frame</b> rate slowdown when we played on a 4th generation iPod Touch. At the same time, it's not the huge leap we saw from Asphalt 4 to Asphalt 5 ... What's really missing from Asphalt 6: Adrenaline is not the graphical flair or well-balanced gameplay progression. Gameloft has found a way to churn out iPhone games that can look as good and feel as viscerally exciting as Hollywood blockbusters. But like those blockbusters, we are sometimes left looking at a product that lacks basic creativity. With basically the same events as the last game, there's very little incentive to buy this year's Asphalt." ...|$|R

