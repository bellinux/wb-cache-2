9|13|Public
40|$|Abstract. We review {{several aspects}} of {{building}} real-time streaming data Grid applications. Building on general purpose messaging system software (NaradaBrokering) and generalized collaboration services (GlobalMMCS), we are developing a diverse set of <b>interoperable</b> <b>capabilities.</b> These include dynamic information systems for managing short-lived collaborative service collections (“gaggles”), stream filters to support the integration of Geographical Information Systems services with data analysis applications, streaming video to support collaborative geospatial maps with time-dependent data, and video stream playback and annotation services to enable scientific collaboration...|$|E
40|$|Interoperability has {{traditionally}} been considered a property of operational systems, where systems are able to exchange information in some agreed-upon fashion. However, other aspects of interoperability are often overlooked. This report introduces one of those aspects—the concept of programmatic interoperability, which is the application of principles of interoperability to the acquisition management of systems. It shows how programmatic interoperability contributes to fielding <b>interoperable</b> <b>capabilities</b> and relates this aspect to current trends such as network-centric operations. The report also discusses the orchestration of decisions and activities that are applicable to acquisition in a system-of-systems environment. Finally, the report suggests several research topics...|$|E
40|$|Canada {{is facing}} a force {{structuring}} dilemma. In spite of Ottawa's desire to promote international peace and stability alongside the United States and the United Nations, Canada's minimalist approaches to defence spending and capital expenditures are undermining the long-term viability of the Canadian Forces' (CF) expeditionary and <b>interoperable</b> <b>capabilities.</b> Two solutions to this dilemma present themselves: increased defence spending or greater force structure specialization. Since Ottawa is unlikely to increase defence spending, specialization provides the only practical solution to the CF's capabilities predicament. Although it would {{limit the number of}} tasks that the CF could perform overseas, specialization would maximize the output of current capital expenditures and preserve the CF's interoperability with the US military in an age of defence transformation. This paper thus argues that the economics of Canadian defence necessitate a more specialized CF force structure. Canadian defence, Force structure, Specialization, Interoperability, Capital expenditure,...|$|E
50|$|The NATO Consultation, Command and Control Organization (NC3O) {{was formed}} in 1996. Its main {{objective}} {{is to provide a}} coherent, secure and <b>interoperable</b> C3 <b>capability</b> to the NATO.|$|R
40|$|The Open Geospatial Consortium (OGC) [1] {{defines a}} number of standards, both for data models and for online services, that has been widely adopted in the Geographical Information System (GIS) community. This has lead to {{a number of}} {{software}} development efforts, online data archives, and application communities. The emergence of Web Service technique overcomes the shortcoming of traditional Distributed Object technique and provides the <b>interoperable</b> <b>capability</b> of cross-platform and cross-language in distributed net environment. GIS services will be implemented more extensively by using Web Service approach. A spatial data infrastructure lets many GIS vendors share data stores and applications in a distributed environment. GIS basically involves the integration of data and services from multiple sources from different vendors. The Web services architecture establishes a standard interconnection rules between services and information clients that nicely support the dynamic integration of data, which is the key to creating a spatial data infrastructure. By introducing Web Services, distributed GIS services from different vendors can be dynamically integrated into the GIS applications using the interoperable standard communication protocols of the Web Services. To be able to benefit from the Web Services in the GIS applications, all the service providers should provide their services as Web Services. General acceptance from the vendors increases the interoperability and enhances the GIS applications. We find that the OGC standards are very compatible with Web Services standards, although they are not technically implemented this way. To be able to benefit from Web Services technologies we have built a common architecture to convert any OGC GIS services to Web Services an...|$|R
40|$|There is {{no doubt}} that today {{manufacturing}} is more competitive and challenging than ever before in trying to respond to "production on demand". Companies from east and west and all over the world have changing rules of business and need to collaborate beyond geographic boundaries {{with the support of the}} rapid advancement of information technology associated with manufacturing technology. To satisfy customers' demands for product variety and the industrial need for high precision, numerically controlled machining with multiple axes and sophisticated machine tools are required. Due to the complexity of programming there is a need to model their process capability to improve the <b>interoperable</b> manufacturing <b>capability</b> of machines such as turning centres. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Testimony {{issued by}} the Government Accountability Office with an {{abstract}} that begins "For over a decade, the Department of Veterans Affairs (VA) and the Department of Defense (DOD) {{have been working on}} initiatives to share electronic health information. To expedite their efforts, Congress mandated in the National Defense Authorization Act for Fiscal Year 2008 that VA and DOD establish a joint interagency program office to act as a single point of accountability in the development of electronic health records systems or capabilities that allow for full interoperability (generally, the ability of systems to exchange data) by September 30, 2009. In this statement, GAO summarizes findings from its upcoming report, focusing on progress in setting up the interagency program office and the departments' actions to achieve fully <b>interoperable</b> <b>capabilities</b> by September 30, 2009. To do so, GAO analyzed agency documentation on project status and conducted interviews with agency officials. ...|$|E
40|$|Proceedings Paper (for Acquisition Research Program) During {{this past}} year, Congress passed the Weapons Systems Acquisition Reform Act, which made several changes to DoD {{acquisition}} organizations and processes. More recently, Congress passed, and the President signed, the National Defense Authorization Act for FY 2010, becoming Public Law 111 - 84, directing changes in DoD {{acquisition of information}} technologies (IT). The law requires the DoD to base the new acquisition process on recommendations in the March 2009 Report of the Defense Science Board Task Force on Department of Defense Policies and Procedures for the Acquisition of Information Technology (hereafter DSB-IT). The report recommends an agile model for acquiring information technologies (IT) similar to successful commercial practices (see [URL] A second DSB report, also issued in March 2009, the Report of the Defense Science Board Task Force on Achieving Interoperability in a Net Centric Environment (DSB-NC), made recommendations to ensure that IT acquisition delivers information-assured, <b>interoperable</b> <b>capabilities</b> essential to modern warfighting. Together, the reports provide a foundation {{on which to build}} the new model for acquisition and testing of IT; this paper attempts to connect them and fill the remaining gaps necessary to truly transform to agile processes that foster rapid acquisition of enhanced IT capabilities for the warfighter. Acquisition Research Progra...|$|E
40|$|The Joint Interoperable Operator Network (JION) will be {{a subset}} of the global signals {{intelligence}} (SIGINT) enterprise. It will concurrently serve warfighters, intelligence producers, and decision-makers at various echelons and locations. The goal of JION is to create a global airborne SIGINT network that includes all new generation and existing airborne SIGINT systems. It will enable connectivity and interoperability among all components of the airborne SIGINT reconnaissance system, and will exchange services with other tactical and national SIGINT networks, IMINT networks, and MASINT systems. The JION effort was initiated in response to the Defense Airborne Reconnaissance Steering Committee (DARSC) direction to the Services to modernize all airborne SIGINT systems, including ground stations and airborne operator positions, to make them compatible with the Joint Airborne SIGINT Architecture (JASA) and interoperable. JION will gradually replace legacy stand-alone capabilities with connected and <b>interoperable</b> <b>capabilities.</b> JION will network a mix of airborne reconnaissance SIGINT sensors, ground/surface stations, and associated collection communications to link local and distant SIGINT assets into a distributed SIGINT infrastructure. This enterprise will facilitat the system functions of collection tasking, collection m agement, collection, processing, exploitation, and timely SIGINT results dissemination. JION will provide compatible SIGINT inputs to the Distributed Common Ground System (DCGS) for multi-intelligence (Multi-INT) production, and be able to receive cueing and tip-offs from IMINT and MASINT activities. JION will contribute to the fundamental foundation that enables the four key thrusts of Joint Visio...|$|E
50|$|The {{military}} has limited tactical <b>capabilities,</b> <b>interoperable</b> with NATO. A 12-day major exercise in Greece, Trial Spartan Hammer (TSH) ‘06, involved 2,000 personnel from 14 NATO countries and 15 NATO agencies, including the SIGINT & ESM working group (SEWG) under the NATO Joint Intelligence, Surveillance, and Reconnaissance Capability Group. It {{was the second}} NATO joint Signal Intelligence/Electronic Warfare (SIGINT/EW) demonstration. Canadian Forces involved included the Electronic Warfare Centre (CFEWC), HMCS Iroquois, 772 EW Squadron, the Joint Intelligence Fusion Capability and the Directorate of Space Development.|$|R
40|$|This conference {{paper was}} {{presented}} at the 22 nd International Manufacturing Conference, IMC 22, Institute of Technology, Tallaght, Dublin, Ireland. This paper reports ongoing research on the application of new standards for CNC machining to enable quality assured customised part manufacture by implementing the new standard, ISO 14649 otherwise known as STEP-NC. The paper focuses on the use of this new standard, to address the process planning and machining of turn/mill discrete components. Today complex turn/mill components can be produced {{on a wide range of}} turning centre configurations with multi axes, twin spindles and dual turrets. Due to the complexity of programming there is a need to model their process capability to improve the <b>interoperable</b> manufacturing <b>capability</b> on machines such as turning centres. This paper proposes a STEP Compliant NC structure for generation of ISO 14646 code which can be used for turn/mill component manufacture...|$|R
50|$|The Army {{leadership}} {{adopted a}} more Systems of Systems Engineering (SOSE) approach toward Battle Command development and have formulated {{a concept of}} Unified Battle Command (UBC). The goal for UBC is to achieve an affordable, <b>interoperable</b> battle command <b>capability</b> across all of the Army's formations—maneuver, functional, and multi-functional brigades. For platforms and soldiers, UBC will consist {{of a combination of}} Future Combat Systems (FCS) Battle Command (BC) and JBC-P computers, software and a new hybrid network of the Warfighter Information Network-Tactical (WIN-T), Joint Tactical Radio Systems (JTRS) and BFT 2. As the Army develops JBC-P, it will do so with an eye toward achieving UBC capabilities.|$|R
40|$|Scientific {{problems}} {{that depend on}} processing large amounts of data require overcoming challenges in multiple areas: managing large-scale data distribution, controlling co-placement and scheduling of data with compute resources, and storing, transferring, and managing large volumes of data. Although there exist multiple approaches to addressing each of these challenges and the complexity of distributed environments, an integrative approach is missing; furthermore, extending existing functionality or enabling <b>interoperable</b> <b>capabilities</b> remains difficult at best. We propose the concept of Pilot-Data to address the fundamental challenges of co-placement and scheduling of data and compute in heterogeneous and distributed environments with interoperability and extensibility as first-order concerns. Pilot-Data {{is an extension of}} the Pilot-Job abstraction for supporting the management of data in conjunction with compute tasks. Pilot-Data separates logical data units from physical storage, thereby providing the basis for efficient compute/data placement and scheduling. In this paper, we discuss the design and implementation of the Pilot-Data prototype, demonstrate its use by data-intensive applications on multiple production distributed cyberinfrastructure and illustrate the advantages arising from flexible execution modes enabled by Pilot-Data. Our experiments utilize an implementation of Pilot-Data in conjunction with a scalable Pilot-Job (BigJob) to establish the application performance that can be enabled by the use of Pilot-Data. We demonstrate how the concept of Pilot-Data also provides the basis upon which to build tools and support capabilities like affinity which in turn can be used for advanced data-compute co-placement and scheduling. 1...|$|E
40|$|Wireless sensor {{networks}} {{represent an}} important component of distributed pervasive computing infrastructure supporting a range of applications including health,military, environmental monitoring, civil structure monitoring, smart homes, etc. The primary factor driving such pervasive real-world applications is availability of data from sensors distributed in the environment. Traditional way of collecting data is to transmit the data from sensors to a collection point using wireless radio communications. However, the traditional approach is expensive and not always efficient. This thesis addresses a major challenge of cost-efficient collection of data from wireless sensor networks. Our data collection philosophy is to use mobile devices as sensor data collectors. The use of mobile devices as mobile data mules facilitates the formation of a mobile access network that can be used by sensors to connect to the external world. We propose, investigate, develop and validate a sensor data collection framework called sGaRuDa which enables <b>interoperable</b> <b>capabilities</b> and takes advantage of existing communication and hardware capabilities of the mobile data mule platforms enabling them to collect sensor data on-the-run. The sGaRuDa framework incorporates intelligent mobile data mule allowing them to dynamically make data collection and delivery decisions. The sGaRuDa framework and the corresponding data collection algorithms are targeted at sensor networks that use short range radio communication technologies like Bluetooth. We have also proposed, implemented and validated a novel three dimensional k-Nearest Neighbour query-based sensor data collection approach called 3 D-KNN to address broadcast-based sensor network communication architectures. The 3 D-KNN facilitates multi-hop data collection from infrastructure-less wireless sensor networks (e. g. Zigbee). We propose, develop, implement and validate a dynamic smart spaces modelling approach called Ranked-Context Spaces (R-CS). Our smart spaces modelling approach is driven by the notion of situation modelling and reasoning about context. Ranked-Context Spaces is capable of computing situation-based smart spaces model taking into account changing contextual information. R-CS is proposed as an extension to Context Spaces theory. The thesis presents implementation and evaluation details of the proposed sGaRuDa framework and the 3 D-KNN algorithm. We have demonstrated the feasibility and cost-efficiency of the sGaRuDa system framework in real-world environments by implementing a proof-of-concept prototype on a range of mobile device platforms, namely, Personal Digital Assistants and mobile robot. Extensive evaluation and experimentation have been performed to prove the extent of energy conservation using the proposed data collection framework and the 3 D-KNN algorithm. Finally, we have implemented the R-CS system to demonstrate its reasoning ability under uncertainty. Experiments based on synthetic sensor data streams have been performed to evaluate the proposed Context Spaces extensions incorporated into R-CS. During the course of the thesis work, 7 peer-refereed international conference papers, 1 peer-refereed workshop paper and 1 journal paper have been produced. One of the conference papers was awarded a BEST PAPER AWARD...|$|E
40|$|In the {{construction}} sector, capturing the building product {{in a single}} information model with good <b>interoperable</b> <b>capabilities</b> {{has been the subject}} of much research efforts in at least the last three decades. Contemporary advancements in Information Technology and the efforts from various research initiatives in the AEC industry are showing evidence of progress with the advent of building information modelling (BIM). BIM presents the opportunity of electronically modelling and managing the vast amount of information embedded in a building project, from its conception to end-of-life. Researchers have been looking at extensions to expand its scope. Sustainability is one such modelling extension that is in need of development. This is becoming pertinent for the structural engineer as recent design criteria have put great emphasis on the sustainability credentials in addition to the traditional criteria of structural integrity, constructability and cost. Considering the complexity of nowadays designs, there is a need to provide decision support tools to aid the assessment of sustainability credentials. Such tools would be most beneficial at the conceptual design stage so that sustainability is built into the design solution starting from its inception. This research work therefore investigates how contemporary process and data modelling techniques can be used to map and model sustainability related information to inform the structural engineer’s building design decisions at an early stage. The research reviews current design decisions support systems on sustainability and highlights existing deficiencies. It examines the role of contemporary information modelling techniques in the building design process and employs this to tackle identified gaps. The sustainability of buildings is related to life cycle and is measured using indicator-terms such as life cycle costing, ecological footprint and carbon footprint. This work takes advantage of current modelling techniques to explore how these three indicators can be combined to provide sustainability assessment of alternative design solutions. It identifies the requirements for sustainability appraisal and information modelling to develop a requisite decision-support framework vis-à-vis issues on risk, sensitivity and what-if scenarios for implementation. The implementation employed object-oriented programming and feature modelling techniques to develop a sustainability decision-support prototype. The prototype system was tested in a typical design activity and evaluated to have achieved desired implementation requirements. The research concludes that the utilized current process and data modelling techniques can be employed to model sustainability related information to inform decisions at the early stages of structural design. As demonstrated in this work, design decision support systems can be optimized to include sustainability credentials through the use of object-based process and data modelling techniques. This thesis presents a sustainability appraisal framework, associated implementation algorithms and related object mappings and representations systems that could be used to achieve such decision support optimization...|$|E
5000|$|... “The Distributed Common Ground System-Army (DCGS-A) is the Army's premier intelligence, surveillance, and {{reconnaissance}} (ISR) enterprise for the tasking of sensors, {{analysis and}} processing of data, exploitation of data, {{and dissemination of}} intelligence (TPED) across all echelons. It is the Army component of the larger Defense Intelligence Information Enterprise (DI2E) and interoperable with other Service DCGS programs. Under the DI2E framework, USD (I) hopes to provide COCOM Joint Intelligence Operations Centers (JIOCs) <b>capabilities</b> <b>interoperable</b> with DCGS-A through a Cloud/widget approach.DCGS-A connects tactical, operational, and theater-level commanders to hundreds of intelligence and intelligence-related data sources at all classification levels and allows them to focus efforts of the entire ISR community on their information requirements.|$|R
40|$|Various Department of Defense (DoD) {{organizations}} have recognized shortfalls in training opportunities and assets to meet operational demand. The complexity {{of current and}} future weapons systems demand concurrency training in an environment representative of realistic battlefield conditions, yet the DoD can ill afford to provide this level of training at the desired frequency. Aviation fuel price escalation and range space limitations are exacerbating the training dilemma. Traditional training applications include the following discrete categories: Live, training on actual platform hardware; Virtual, training on manned simulations; and Constructive, training with computer generated simulations of battlefield conditions. With the advent of <b>interoperable</b> training <b>capability,</b> such as the Air Force's Distributed Mission Operations (DMO), the ability exists to link local or remote training systems over a local or wide area network {{for the purpose of}} training in a team environment. The DMO network has the capability to greatly enhance the live training domain by supplying a vast operational environment composed of virtual and constructive red/blue forces. The integration of live platforms onto the DMO network, however, has unforeseen training challenges that need to be addressed. This paper discusses the research performed and the challenges encountered when an integrated LV...|$|R
40|$|There is {{no doubt}} that today {{manufacturing}} is more competitive and challenging than ever before in trying to respond to “production on demand”. Due to the complexity of programming {{there is a need to}} model process capability to improve the <b>interoperable</b> manufacturing <b>capability</b> of machines such as turning centres. This chapter focuses on the use of the new standard; ISO 14649 (STEP-NC), to address the process planning and machining of discrete turned components. It explores how ISO 14649 can be used to combine turning and milling operations to support interoperable CNC manufacturing of rotational asymmetric components at a single turning centre. This chapter focuses on the creation of a computational environment for a STEP-NC compliant system for turning operations namely SCSTO. SCSTO is the experimental part of the research, supported by specification of information models and constructed using a structured methodology and object-oriented methods. SCSTO was developed to generate a Part 21 file based on machining features to support the interactive generation of process plans utilising feature extraction. An important aspect was the need to overcome the complexities of component geometry including milling features so as to have the ability to manufacture turn/mill components...|$|R
40|$|The {{changing}} {{economic climate}} has made global manufacturing a growing reality {{over the last}} decade, forcing companies from east and west {{and all over the}} world to collaborate beyond geographic boundaries in the design, manufacture and assemble of products. The ISO 10303 and ISO 14649 Standards (STEP and STEP-NC) have been developed to introduce interoperability into manufacturing enterprises so as to meet the challenge of responding to production on demand. The paper focuses on the use of this new standard to address the process planning and machining of turn/mill discrete components. Due to the complexity of programming these machines there is a need to model their process capability to improve the <b>interoperable</b> manufacturing <b>capability</b> in places such as turning centres. Finally a proposed computational environment for a STEP-NC compliant system for turning operations (SCSTO) is described. And supported by the specification of information models and constructed using a structured methodology and object-oriented methods. SCSTO was developed to generate a Part 21 file based on machining features to support the interactive generation of process plans utilizing feature extraction. A case study component has been developed to prove the concept for using the milling and turning parts of ISO 14649 to provide a turn-mill CAD/CAPP/CAM environment. </p...|$|R
40|$|Large, {{complex systems}} {{development}} {{has always been}} challenging, even when the 2 ̆ 2 only 2 ̆ 2 things a program manager {{had to worry about}} were cost, schedule, and performance within a single program. The emergence of operational concepts such as network-centric operations, greatly expanded use of joint and combined operations, and rampant growth in system complexity has led to the prevalence of interoperable systems of systems as the preferred solution to providing operational capability. This report explores how systems-of-systems realities necessitate changes in the processes used to acquire, develop, field, and sustain operational <b>capability.</b> <b>Interoperable</b> acquisition is defined, and key concepts are explored through an analysis of some {{of the ways in which}} traditional (i. e., system-centric) acquisition approaches can result in problems when applied to a system-of-systems context...|$|R
40|$|The paper {{entitled}} “A Protocol Design for Mobility Assisted Delay / Disruption Tolerant Network Nodes” mainly intends {{in designing}} a disruption tolerant network useful for challenged internet areas lacking “always-on” setup, fewer expectations of end-to-end connection and node resources. Disruption Tolerant Networking (DTN) is a networking area which addresses challenges in disconnected, disrupted networks without end-to-end connection. Today’s internet operated using highly successful architecture and supporting protocols (protocols in TCP/IP model) performs poorly in environments characterized by very long delay paths and frequent network partitions. These problems make end nodes having severe power or memory constraints perform poor. Many DTN networks {{use their own}} specialized protocols like Licklider Transmission Protocol (LTP), Bundle Protocol (BP) etc. In order to achieve interoperability between such networks, an overlay architecture is designed above the transport layers of the networks it interconnects provides important services such as in-network data storage and retransmission <b>capability,</b> <b>interoperable</b> naming, coarse-grained class of services and authenticated forwarding. A network with three node test setup is created which will demonstrate the working of delay/disruption tolerant network for asymmetric data rates, high error rates, long and variable delays and intermittent connectivity...|$|R
40|$|The U. S {{government}} has created and been executing an Identity and Management (IdM) vision {{to support a}} global, robust, trusted and <b>interoperable</b> identity management <b>capability</b> that provides the ability to correctly identify individuals and non-person entities in support of DoD mission operations. Many Directives and Instructions have been issued to standardize the process to design, re-designed new and old systems with latest available technologies to meet the visions requirements. In this thesis we introduce a cloud-based architecture for the Defense Biometric Identification System (DBIDS), along {{with a set of}} DBIDS Cloud Services that supports the proposed architecture. This cloud-based architecture will move DBIDS in the right direction to meet Dod IdM visions and goals by decoupling current DBIDS functions into DBIDS core services to create interoperability and flexibility to expand future DBIDS with new requirements. The thesis will show its readers how DBIDS Cloud Services will help Defense Manpower Data Center (DMDC) easily expanding DBIDS functionalities such as connecting to other DMDC services or federated services for vetting purposes. This thesis will also serve as a recommendation of a blue-print for DBIDS architecture to support new generation of DBIDS application. This is a step closer in moving DMDC Identity Enterprise Solution toward DoD IdM realizing vision and goals. The thesis also includes a discussion of how to utilize virtualized DBIDS workstations to address software-deployment and maintenance issues to resolve configuration and deployment issues which have been costly problems for DMDC over the years. Civilian, Department of Defens...|$|R

