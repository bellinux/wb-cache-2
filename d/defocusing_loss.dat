5|9|Public
30|$|Once the <b>defocusing</b> <b>loss</b> is {{estimated}} {{as a function}} of time from trajectory information and the relationship between α and a from the Doppler measurements, one may calculate the total atmospheric absorption from the time series of the received signal power. This time series is converted to a height profile of the absorptivity with the aid of ray tracing on the assumption of a spherically symmetric atmosphere (Jenkins and Steffes, 1991; Jenkins et al., 1994). The absorption due to CO 2,N 2 and SO 2 is removed from the absorptivity profile based on its dependence on the ambient pressure and temperature. The remaining absorption will be principally due to H 2 SO 4 vapor.|$|E
30|$|The height {{range of}} the Venus’ neutral {{atmosphere}} accessible by radio occultation is approximately 32 – 90 km. Below 40 km the <b>defocusing</b> <b>loss</b> and the attenuation by the atmosphere limits {{the quality of the}} observation, and 32 km is the lowest accessible altitude, below which the radius of curvature of the ray path becomes smaller than the distance to the planet center (Fjeldbo et al., 1971; Häusler et al., 2006). The atmosphere above 100 km is too thin to be detected. The broad height coverage of radio occultation is a great advantage in the investigation of the vertical coupling among different atmospheric layers; no other technique can cover this altitude range at the same time.|$|E
40|$|The poor low-frequency {{performance}} of geometrically designed beam-waveguide (BWG) antennas {{is shown to}} be caused by the diffraction phase centers being far from the geometrical optics mirror focus, resulting in substantial spillover and <b>defocusing</b> <b>loss.</b> Two novel solutions are proposed: (1) reposition the mirrors to focus low frequencies and redesign the high frequencies to utilize the new mirror positions, and (2) redesign the input feed system to provide an optimum solution for the low frequency. A novel use of the conjugate phase-matching technique is utilized to design the optimum low-frequency feed system, and the new feed system has been implemented in the JPL research and development BWG as part of a dual S-/X-band (2. 3 GHz/ 8. 45 GHz) feed system. The new S-band feed system is shown to perform significantly better than the original geometrically designed system...|$|E
40|$|Paper {{addresses}} defocusing and diffraction effects {{important in}} design of beam waveguide. Phase center of beam waveguide at lower frequency differs from {{focal point of}} geometric optics. If antenna system optimized for higher frequency, shift in phase center causes <b>defocusing,</b> with <b>loss</b> of signal at lower frequency. Defocusing caused by diffraction at lower frequencies reduced by shaping input pattern...|$|R
40|$|We present Simulated Annealing fiber-to-target {{allocation}} simulations for {{the proposed}} DESI and 4 MOST massively multiplexed spectroscopic surveys, and for both Poisson and realistically clustered mock target samples. We simulate both Echidna and theta-phi actuator designs, including the restrictions caused by the physical actuator characteristics during repositioning. For DESI, with theta-phi actuators, used in 5 passes over the sky for a mock ELG/LRG/QSO sample, with matched fiber and target densities, a total target allocation yield of 89. 3 % was achieved, but only 83. 7 % for the high-priority Ly-alpha QSOs. If Echidna actuators are used with the same pitch and number of passes, the yield increases by 5. 7 % and 16 % respectively. Echidna also allows a factor-of-two {{increase in the number}} of close Ly-alpha QSO pairs that can be observed. Echidna spine tilt causes a variable loss of throughput, with average loss being the same as the loss at the rms tilt. With a natural tilt minimization scheme, we find an rms tilt always close to 0. 58 x maximum. There is an additional but much smaller <b>defocus</b> <b>loss,</b> equivalent to an average defocus of 30 microns. These tilt losses offset the gains in yield for Echidna, but because the survey strategy is driven by the higher priority targets, a clear survey speed advantage remains. For 4 MOST, high and low latitude sample mock catalogs were supplied by the 4 MOST team, and allocations were carried out with the proposed Echidna-based positioner geometry. At high latitudes, the resulting target completeness was 85. 3 % for LR targets and 78. 9 % for HR targets. At low latitude, the target completeness was 93. 9 % for LR targets and 71. 2 % for HR targets. Comment: 10 pages, SPIE 2014 9150 - 7...|$|R
40|$|A stable {{resonator}} {{incorporating a}} suitably adjusted telescope gives reliable operation of an Nd:YAG laser with a large-volume TEMoo mode. The telescope adjustment is chosen {{to minimize the}} effect of focal length variations in the laser rod {{and at the same}} time ensures the optimum mode-selection properties of a confocal resonator. Simple approximations applied to the ray transfer matrices allow a detailed analysis of the resonator to be performed. This analysis yields simple design equations relating the mode spot sizes, resonator length, telescope magnification and <b>defocusing,</b> and diffraction <b>losses.</b> Experimental results show excellent agreement with the results of this analysis...|$|R
30|$|Radio {{occultation}} {{has played}} a crucial role in determining the structures of the planetary atmospheres (e.g., Eshleman 1973; Tyler 1987; Pätzold et al. 2007; Imamura et al. 2012). In a radio occultation experiment conducted with a spacecraft equipped with a stable frequency source, the spacecraft transmits radio waves toward the Earth, while it goes behind the planet and reemerges as seen from the Earth. During such occultation events, the planetary atmosphere causes bending and attenuation of the radio waves. Assuming a local spherical symmetry, the analysis of the frequency and the signal intensity time series obtained at the tracking station yields vertical profiles of the refractive index and the absorption coefficient. Temperature profiles are obtained from the refractive index profiles assuming hydrostatic balance. The advantages of this technique over other remote sensing techniques are its high vertical resolution (typically <  1  km) and high temperature resolution (typically <  1  K) (Hinson and Jenkins 1995; Tellmann et al. 2009). Radio occultation can cover altitudes from the sub-cloud region (<  50  km) to the upper atmosphere (~  90  km). The quality of the measurement declines below 40  km due to <b>defocusing</b> <b>loss</b> and absorption, and no information is obtained below ~  32  km since the curvature of the ray path exceeds that of the planetary surface (Fjeldbo et al. 1971; Häusler et al. 2006).|$|E
40|$|We {{recommend}} {{using the}} dayside Martian ionosphere as a reflector for global communication, {{because it has}} a stable density peak and usable critical frequency. This is very crucial for the future Mars ground to ground communication. The dayside ionosphere has been well modeled as a Chapman layer. We suggest performing the Martian nightside ionosphere modeling study. Because the nightside ionosphere has very little measurements available, we propose to drop a digital ionosound instrument into the Mars surface for data collection. Even though the Martian tropospheric radio refractivity had a small value, it still can cause ray bending and multipath effects. We recommend performing an accurate calculation on excess phase and group delays (range and time delays). Other effects, such as range rate errors, appearance angle deviation, <b>defocusing</b> <b>loss</b> on Mars, etc. should be estimated. Ice depolarization effects due to Martian clouds on radio waves are unknown yet, but they are expected to be small, because of lower optical depth and the thinner layer of cloud. Total Martian atmospheric gaseous attenuation is expected to be less than 1 dB on microwaves and, because the Martian atmosphere had very low concentration in uncondensed H 2 O and O 2. An accurate calculation for zenith opacity requires the information about scale heights of H 2 O and O 2 distribution. An accurate water vapor altitude profile at Mars is not available et. Under the normal condition, CO 2 and N 2 gases ddo not have electric or magnetic dipoles and do not absorb electromagnetic energy from the waves. However, they may generate the dipoles through a collision and interact with waves under a high density condition and absorb electromagnetic waves in the infrared and visible band. Dust storm is the most dominant factor on the radio wave attenuation. Large Martian dust storms can cause at least 3 dB or higher loss to Ka band wave. For a normal dust storm, the attenuation is about 1 dB. The attenuation much depends on dust mass loading, dust size distribution, etc. Most large dust storms occur in the southern hemisphere during later spring and early summer when the southern hemisphere becomes suddenly hot...|$|E
40|$|We study {{effects of}} tight harmonic-oscillator {{confinement}} on the electromagnetic field in a laser cavity by solving the two-dimensional Lugiato-Lefever (2 D LL) equation, {{taking into account}} self- focusing or <b>defocusing</b> nonlinearity, <b>losses,</b> pump, and the trapping potential. Tightly confined (quasi-zero-dimensional) optical modes (pixels), produced by this model, are analyzed {{by means of the}} variational approximation, which provides a qualitative picture of the ensuing phenomena. This is followed by systematic simulations of the time-dependent 2 D LL equation, which reveal the shape, stability, and dynamical behavior of the resulting localized patterns. In this way, we produce stability diagrams for the expected pixels. Then, we consider the LL model with the vortical pump, showing that it can produce stable pixels with embedded vorticity (vortex solitons) in remarkably broad sta- bility areas. Alongside confined vortices with the simple single-ring structure, in the latter case the LL model gives rise to stable multi-ring states, with a spiral phase field. In addition to the numeri- cal results, a qualitatively correct description of the vortex solitons is provided by the Thomas-Fermi approximation. Comment: 11 pages, 15 figures, Eur. Phys. Journal D, in press (Topical Issue "Theory and Applications of the Lugiato-Lefever Equation"...|$|R
40|$|A {{conventional}} camera has {{a limited}} {{depth of field}} (DOF), which often results in <b>defocus</b> blur and <b>loss</b> of image detail. The technique of image refocusing allows a user to interactively change the plane of focus and DOF of an image after it is captured. One way to achieve refocusing is to capture the entire light field. But this requires a significant compromise of spatial resolution. This {{is because of the}} dimensionality gap - the captured information (a light field) is 4 -D, while the information required for refocusing (a focal stack) is only 3 -D. In this paper, we present an imaging system that directly captures a focal stack by physically sweeping the focal plane. We first describe how to sweep the focal plane so that the aggregate DOF of the focal stack covers the entire desired depth range without gaps or overlaps. Since the focal stack is captured in a duration of time when scene objects can move, we refer to the captured focal stack as a duration focal stack. We then propose an algorithm for computing a space-time in-focus index map from the focal stack, which represents the time at which each pixel is best focused. The algorithm is designed to enable a seamless refocusing experience, even for textureless regions and at depth discontinuities. We have implemented two prototype focal-sweep cameras and captured several duration focal stacks. Results obtained using our method can be viewed at www. focalsweep. com...|$|R
40|$|Abstract—For a given camera setting, scene {{points that}} lie outside of {{depth of field}} (DOF) will appear defocused (or blurred). <b>Defocus</b> causes a <b>loss</b> in image details. To recover details from a defocused region, {{deblurring}} techniques must be employed. It {{is well known that}} deblurring quality is closely related to the defocus kernel or point-spread-function (PSF), whose shape is largely determined by the aperture pattern of the camera. In this paper, we propose a comprehensive framework of aperture evaluation for the purpose of defocus deblurring, which takes the effects of image noise, deblurring algorithm, and the structure of natural images into account. By using the derived evaluation criterion, we are able to find the optimal coded aperture patterns. Extensive simulations and experiments are then conducted to compare the optimized coded apertures with previously proposed ones. The proposed framework for aperture evaluation is further extended to evaluate and optimize extended depth of field (EDOF) cameras. EDOF cameras (e. g., focal sweep and wavefront coding camera) are designed to produce PSFs that are less sensitive to depth variation, so that a single PSF can be used to deblur captured images without knowledge of scene depth. The deblurring quality for EDOF cameras depends on the parameters of the camera and the PSF used for deconvolution. We show that our evaluation criterion can be used to find both optimal values for the camera parameters and an optimal PSF for deblurring...|$|R
40|$|Abstract A {{conventional}} camera has {{a limited}} {{depth of field}} (DOF), which often results in <b>defocus</b> blur and <b>loss</b> of im-age detail. The technique of image refocusing allows a user to interactively change the plane of focus and DOF of an im-age after it is captured. One way to achieve refocusing is to capture the entire light field. But this requires a significant compromise of spatial resolution. This {{is because of the}} di-mensionality gap- the captured information (a light field) is 4 -D, while the information required for refocusing (a focal stack) is only 3 -D. In this paper, we present an imaging system that directly captures a focal stack by physically sweeping the focal plane. We first describe how to sweep the focal plane so that the aggregate DOF of the focal stack covers the entire desired depth range without gaps or overlaps. Since the focal stack is captured in a duration of time when scene objects can move, we refer to the captured focal stack as a duration focal stack. We then propose an algorithm for computing a space-time in-focus index map from the focal stack, which represents the time at which each pixel is best focused. The algorithm is designed to enable a seamless refocusing experience, even for textureless regions and at depth discontinuities. We have implemented two prototype focal-sweep cam-eras and captured several duration focal stacks. Results ob...|$|R
40|$|For a given camera setting, scene {{points that}} lie outside of {{depth of field}} (DOF) will appear defocused (or blurred). <b>Defocus</b> causes the <b>loss</b> of image details. To recover scene details from a defocused region, {{deblurring}} techniques must be employed. It {{is well known that}} the deblurring quality is closely related to the defocus kernel or point-spread-function (PSF), whose shape is largely determined by the aperture pattern of the camera. In this paper, we propose a comprehensive framework of aperture evaluation for the purpose of defocus deblurring, which takes the effects of image noise, deblurring algorithm, and the structure of natural images into account. By using the derived evaluation criterion, we are able to solve for the optimal coded aperture patterns. Extensive simulations and experiments are then conducted to compare the optimized coded apertures with previously proposed ones. The proposed framework of aperture evaluation is further extended to evaluate and optimize extended depth of field (EDOF) cameras. EDOF cameras (e. g., focal sweep and wavefront coding camera) are designed to produce PSFs which are less sensitive to depth variation, so that people can deconvolve the whole image using a single PSF without knowing scene depth. Different choices of camera parameters or the PSF to deconvolve with lead to different deblurring qualities. With the derived evaluation criterion, we are able to derive the optimal PSF to deconvolve with in a closed-form and optimize camera parameters for the best deblurring results...|$|R
40|$|High Harmonic Generation (HHG) is a {{fascinating}} phenomenon from both fundamental and technological point of view. It enables the generation of attosecond pulses and can have applications in EUV lithography and bio-microscopy. HHG can be described by the Three Step Model (TSM), due to the three stages of the process: ionization, propagation and recombination. However, HHG suffers from low efficiencies and a study, which shows the efficiency scaling with laser and material parameters is essential. For a long time experimentalists were using only 800 nm driver pulses from Ti:sapphire lasers. With the advent of new light sources like optical parametric amplifiers, different driving wavelengths became available and thus the scaling of the single atom response versus drive wavelength has attracted a lot of attention. A detailed analysis shows that the efficiency scales with w 50 at the cutoff and w 60 at the plateau region for a fixed EUV frequency, where w 0 is the carrier frequency of the driver pulse. To understand the limitations of such a light source, we have developed a semi-analytic model for the computation of the conversion efficiency into a single harmonic for the plateau and cutoff regions. This model is one-dimensional, uses the TSM for the calculation of the single atom response and takes laser, material parameters and macroscopic effects into account. Closed form expressions for the plateau and cutoff regions are derived and used to calculate efficiencies for 400 and 800 nm driver pulses. The results are compared with experimental ones showing very good agreement. In order to investigate long-wavelength driven HHG efficiency, the 1 -D model is extended to three dimensions taking into account spatiotemporal propagation effects, such as plasma <b>defocusing</b> and <b>losses</b> due to electron-neutral inverse bremsstrahlung. These phenomena change the phase matching along propagation, resulting in non-coherent harmonic generation and consequently poor efficiencies. We further study ways {{to mitigate the effect}} of plasma defocusing like the use of Supergaussian pulses and the use of Gaussian pulses with larger beam waists. The work presented can help us develop tools for an optimization study of HHG efficiency, in order to make useful EUV sources. by Vasileios-Marios Gkortsas. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2013. Cataloged from PDF version of thesis. Includes bibliographical references (pages 157 - 164) ...|$|R

