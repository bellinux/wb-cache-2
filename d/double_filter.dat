33|223|Public
50|$|The contourlet {{transform}} uses a <b>double</b> <b>filter</b> bank {{structure to}} get the smooth contours of images. In this <b>double</b> <b>filter</b> bank, the Laplacian pyramid (LP) is first used to capture the point discontinuities, and then a directional filter bank (DFB) is used to form those point discontinuities into linear structures.|$|E
5000|$|Single and <b>Double</b> <b>filter</b> wheel {{systems for}} {{detecting}} and characterizing fluorescence emission ...|$|E
50|$|It used a <b>double</b> <b>filter</b> {{system and}} {{delivered}} water to {{external and internal}} wash basins, as well a drinking troughs for animals.|$|E
40|$|Abstract Background Many {{researchers}} use the <b>double</b> <b>filtering</b> {{procedure with}} fold change and t test to identify differentially expressed genes, {{in the hope}} that the <b>double</b> <b>filtering</b> will provide extra confidence in the results. Due to its simplicity, the <b>double</b> <b>filtering</b> procedure has been popular with applied researchers despite the development of more sophisticated methods. Results This paper, for the first time to our knowledge, provides theoretical insight on the drawback of the <b>double</b> <b>filtering</b> procedure. We show that fold change assumes all genes to have a common variance while t statistic assumes gene-specific variances. The two statistics are based on contradicting assumptions. Under the assumption that gene variances arise from a mixture of a common variance and gene-specific variances, we develop the theoretically most powerful likelihood ratio test statistic. We further demonstrate that the posterior inference based on a Bayesian mixture model and the widely used significance analysis of microarrays (SAM) statistic are better approximations to the likelihood ratio test than the <b>double</b> <b>filtering</b> procedure. Conclusion We demonstrate through hypothesis testing theory, simulation studies and real data examples, that well constructed shrinkage testing methods, which can be united under the mixture gene variance assumption, can considerably outperform the <b>double</b> <b>filtering</b> procedure. </p...|$|R
40|$|Abstract- The ac/dc {{filters are}} always needed in HVDC {{converter}} stations to suppress harmonic currents/voltages. The ac side filters are also employed to compensate network requested reactive power. Among {{different types of}} <b>filters,</b> <b>double</b> tuned passive <b>filters</b> have been widely utilized in HVDC stations, yet these filters are still not considered well developed. This paper presents an algorithm for design of the conventional and damped-type <b>double</b> tuned <b>filters</b> to reduce harmonic distortion and improve power factor in electrical systems. Firstly, the conventional <b>double</b> tuned <b>filters</b> are comprehensively studied, and an algorithm for precisely determining the parameters {{of this type of}} filters is presented. Next, the proposed design algorithm is developed for damped-typed <b>double</b> tuned <b>filters.</b> Using this method, the parameters of damped-type <b>double</b> tuned <b>filters</b> are calculated based on the tuned frequencies, the parallel resonance frequency, and the reactive power compensation capacity etc. Finally, the performance of the design algorithm is tested for a 6 -pulse HVDC converter simulated on the MATLAB. The results clearly show the effectiveness of proposed design method in harmonics elimination and power factor correction. Keywords- HVDC converters, harmonics, <b>filter</b> design, damped-type <b>double</b> tuned <b>filters.</b> I...|$|R
50|$|Derivative filters {{based on}} {{arbitrary}} cubic splines was presented by Hast. He showed how {{first and second}} order derivatives can be computed correctly using cubic or trigonometric splines by a <b>double</b> <b>filtering</b> approach giving filters of length 7.|$|R
50|$|The Laplacian pyramid (LP) {{decomposition}} only produce one bandpass {{image in}} a multidimensional signal processing, that can avoid frequency scrambling. And directional filter bank (DFB) is only fit for high frequency since it will leak the low frequency of signals in its directional subbands. This {{is the reason}} to combine DFB with LP, which is multiscale decomposition and remove the low frequency. Therefore, image signals pass through LP subbands to get bandpass signals and pass those signals through DFB to capture the directional information of image. This <b>double</b> <b>filter</b> bank structure of combination of LP and DFB is also called as pyramid directional filter bank (PDFB), and this transform is approximate the original image by using basic contour, so it is also called discrete contourlet transform.|$|E
50|$|Although the wavelet {{transform}} is not optimal in capturing the 2-D singularities of images, {{it can take}} the place of LP decomposition in the <b>double</b> <b>filter</b> bank structure to make the contourlet transform a non-redundant image transform. The wavelet-based contourlet transform is similar to the original contourlet transform, and it also consists of two filter bank stages. In the first stage, the {{wavelet transform}} is used to do the sub-band decomposition instead of the Laplacian pyramid (LP) in the contourlet transform. And the second stage of the wavelet-based contourlet transform is still a directional filter bank (DFB) to provide the link of singular points. One of the advantages to the wavelet-based contourlet transform is that the wavelet-based contourlet packets are similar to the wavelet packets which allows quad-tree decomposition of both low-pass and high-pass channels and then apply the DFB on each sub-band.|$|E
40|$|Abstract. In this paper, the <b>double</b> <b>filter</b> {{cylinder}} of {{the compact}} containment sump strainer in {{nuclear power station}} was adopted as the research object. The impact and transmission mechanical experiments were carried out to investigate the material and structural properties {{in the event of}} earthquake and LOCA (Loss-of-Coolant Accident). Furthermore, the modal analysis and the stress calculations were conducted in LOCA condition to test the validity of the filter cylinder. The research results could provide the basis for designing the <b>double</b> <b>filter</b> cylinder of the compact containment sump strainers...|$|E
40|$|International audienceIn this paper, {{we report}} the {{realization}} of a double Bragg gratings (BG) structure based on titanium-diffused optical waveguides in lithium niobate Ti:LiNbO 3 by using Focused Ion Beam (FIB) technique. A <b>double</b> <b>filtering</b> function in wavelengths around the bands 1200 nm and 1550 nm has thereby been achieve...|$|R
40|$|A video {{presentation}} {{on how to}} build detailed automatic identification models from LOKI zooplankton imagery and how to validate {{them as well as}} an introduction to the <b>double</b> <b>filtering</b> algorithm that was developed in our lab. Concluding with some ecological data. This presentation was recorded for the 5 ème Rencontre des Technologies Marines. [URL]...|$|R
40|$|We {{have been}} {{developing}} Drabkin energy filters for pulse shaping and energy analysis at the J-PARC spallation neutron source. By installing two Drabkin energy filters in sequence (a <b>double</b> Drabkin <b>filter),</b> subsidiary {{peaks of the}} resonant spin-flip are suppressed and pulse shaping could be performed more effectively. In this contribution, simulation results of pulse shaping by a <b>double</b> Drabkin <b>filter</b> for the J-PARC moderators are presented...|$|R
40|$|A <b>double</b> <b>filter</b> module having {{integrated}} filtration and refiltration steps was developed, and its streaming conditions, pressure drop, {{and separation}} ability was calculated. The pressure drop {{can now be}} predicted by simple calculations based on the modelling of the complete system and on the specific membrane. Filter combinations can be optimised before carrying out the experiment. The fractionation ability and efficiency of different filter combinations was determined, and a <b>double</b> <b>filter</b> module for medical applications was developed. (orig.) SIGLEAvailable from TIB Hannover: RA 3251 (99 /E/ 17) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|E
40|$|The {{purpose of}} this study was to {{investigate}} the clinical outcome, inflammatory response and myocardial function in high-risk patients undergoing three different leukocyte depletion strategies. Over a four-month period, forty patients (EuroSCORE 6 +) undergoing coronary revascularization were prospectively randomized to one of the four perfusion protocols: Group 1 (N= 10) : Conventional circuits (ECC) + two leukocyte filters (LG 6 B, Pall, USA) with the method of two-phase (continuous + strategic) leukofiltration; Group 2 (N= 10) : ECC + single leukocyte filter with the method of continuous leukofiltration; Group 3 (N= 10) : ECC + single leukocyte filter with the method of strategic leukofiltration; Group 4 (N= 10) Control: ECC without leukocyte filtration. Blood samples were collected at T 1 : Baseline, T 2 : On CPB, T 3 : X-Clamp, T 4 : Off CPB, T 5 : ICU 24 and T 6 : ICU 48. Perioperative follow-up was thoroughly monitored. Leukocyte counts in <b>double</b> <b>filter</b> and strategic filtration groups demonstrated significant differences at T 4 (p <. 05 vs. control). TNFalpha levels were significantly lower in Group 1 at T 4 and procalcitonin levels at T 5 and T 6 (p <. 05 vs. control). CKMB levels demonstrated well preserved myocardium in <b>double</b> <b>filter</b> group (p <. 05 vs. control). Brain natriuretic peptide levels in <b>double</b> <b>filter</b> group were significantly lower at T 5 and T 6 with respect to Group 2 (p <. 05) and control (p <. 001). Matrixmetallopeptidase 9 and D-Dimer levels in <b>double</b> <b>filter</b> group were significantly lower at T 5 and T 6 (p <. 05 vs. control). Two-phase leukofiltration is associated with some compound benefit over continuous deployment in high-risk patients. A larger more powerful study than this pilot one is warranted for further evaluation...|$|E
40|$|Abstract. In this paper, the conflux {{channel of}} the {{containment}} sump strainer in {{nuclear power station}} was adopted as the research object. The modal analysis and the stress calculations were conducted in LOCA (Loss-of-Coolant Accident) condition to test {{the validity of the}} conflux channel. The research results could provide the basis for designing the <b>double</b> <b>filter</b> cylinder of the compact containment sump strainers...|$|E
3000|$|... {{plays an}} {{important}} role in signal theory as a <b>double</b> digital <b>filter</b> [14] and theory of machines in mechanical engineering [14].|$|R
40|$|Na- 23 {{double and}} triple quantum {{filtered}} NMR spectra of intact dog and human {{red blood cells}} were measured with the pulse sequence 90 degrees-tau/ 2 - 180 degrees-tau/ 2 -theta degrees-t 1 -theta degrees-t 2 (Acq). For theta = 90 degrees the triple quantum filtered spectra exhibited the typical multiple quantum filtered lineshape, characteristic of isotropic media, while the <b>double</b> quantum <b>filtered</b> ones presented a superposition of two signals, whose proportion depended on the creation time tau. This effect {{is due to the}} formation of both second and third rank tensors. The formation of the second rank tensor, T 21 results from non-zero residual quadrupolar interaction and is related to the anisotropic motion of sodium ions. Measurements of the <b>double</b> quantum <b>filtered</b> spectra with theta = 54. 7 degrees enabled the detection of the contribution of T 21 exclusively. No residual quadrupolar interaction was detected for sodium in the cytoplasm, while unsealed ghosts displayed the <b>double</b> quantum <b>filtered</b> spectral pattern, similar to that of intact cells. The anisotropy of motion of the sodium at the plasma membrane of mammalian erythrocytes depended on the integrity of the cytoskeleton network. Theoretical analysis of the <b>double</b> quantum <b>filtered</b> spectra gave a value of residual quadrupolar splitting of approximately 20 Hz for intact unsealed ghosts. The data presented prove that <b>double</b> quantum <b>filtering</b> is a sensitive technique for detection of motional anisotropies in biological systems...|$|R
3000|$|... used in {{this paper}} plays an {{important}} role in signal theory as a <b>double</b> digital <b>filter</b> and the theory of machines in mechanical engineering.|$|R
40|$|A {{direct method}} for robust design of <b>double</b> <b>filter</b> IMC {{controllers}} is presented. With {{respect to the}} general scheme, already proposed to control ill-conditioned plants, this method {{is based on a}} simple filter structure depending on fewer parameters. Guidelines for their selection are indicated; in many cases performance is mostly affected by a single parameter, thus making the controller tuning a much easier task to perform...|$|E
40|$|The VESUVIO {{spectrometer}} at the ISIS pulsed {{neutron source}} performs inelastic neutron scattering at high-energy and wave vector transfers, employing gold and uranium resonant foils. A factor of two {{improvement in the}} instrumental resolution has been achieved by making use of the <b>double</b> <b>filter</b> difference method. Experimental results are presented for measurements on polycrystalline Pb, which indicate that accurate measurements of single-particle momentum distribution n(p) in quantum fluids are now possible at eV energy transfers...|$|E
40|$|Active region 10961 was {{observed}} over a five day period (2007 July 2 - 6) by instrumentation on-board STEREO, Hinode, TRACE and SOHO. As it progressed from Sun centre to the solar limb a comprehensive {{analysis of the}} EUV, X-ray and magnetic field data reveals clearly observable changes in the global nature of the region. Temperature analyses undertaken using STEREO EUVI <b>double</b> <b>filter</b> ratios and XRT single and combined filter ratios demonstrate an overall cooling of the region from between 1. 6 - 3. 0 MK to 1. 0 - 2. 0 MK over the five days. Similarly, Hinode EIS density measurements show a corresponding increase in density of 27...|$|E
30|$|Note 2.3 The product {{transform}} {{plays an}} important role in signal theory as a <b>double</b> digital <b>filter</b> [7] and the theory of machines in mechanical engineering.|$|R
40|$|A new {{prototype}} pore-water sampler {{is proposed}} which allows temporal sampling of pore-water from intertidal sediments. The system {{consists of a}} nylon device provided with regularly spaced chambers, <b>double</b> <b>filtering</b> ports and pipes for in-situ sample recovering. The field use of this apparatus for determining sulfur species in pore-waters is described; a satisfactory agreement between data obtained by using the proposed in-situ sampler and by core-squeezing in proper experimental conditions is found. Finally, advantages and differences with respect to other in-situ samplers are critically evaluated...|$|R
30|$|The <b>filtering</b> system {{includes}} <b>double</b> bag <b>filter</b> (F- 101 A/B), poor liquid {{buffer tank}} (V- 102) and pneumatic diaphragm additive pump (P- 104). The elemental sulfur is separated and the liquid is recycled after the rich liquid sulfur {{getting through the}} <b>double</b> bag <b>filter.</b> The filtrate will enter the poor liquid buffer tank. The mixed liquor containing soluble catalyst is replenished by pneumatic diaphragm additive pump. The filter liquor after sulfuric acid catalyst top-up will re-enter the desulfurizing reaction tower by using the sulfur-poor liquid pump and re-used in a closed loop.|$|R
40|$|We {{studied the}} {{interaction}} between a synthetic peptide (sequence Ac-GXGGFGGXGGFXGGXGG-NH 2, where X = arginine, Nω,Nω-dimethylarginine, DMA, or lysine) corresponding to residues 676 – 692 of human nucleolin and several DNA and RNA substrates using <b>double</b> <b>filter</b> binding, melting curve analysis and circular dichroism spectroscopy. We found that despite the reduced capability of DMA in forming hydrogen bonds, Nω,Nω-dimethylation {{does not affect the}} strength of the binding to nucleic acids nor does it have any effect on stabilization of a double-stranded DNA substrate. However, circular dichroism studies show that unmethylated peptide can perturb the helical structure, especially in RNA, to a much larger extent than the DMA peptide...|$|E
40|$|In {{this text}} {{we will attempt}} {{to bring out the}} way in which Bühler’s {{conception}} of metaphor, based on the famous « model of the <b>double</b> <b>filter</b> », is consistent with his general theory of signs, whose fundamental axis is constituted, as is well known, by the Organon Modell. The latter affords clarification of the specificity of metaphor in its relation to the concepts of « field » and « functions » to which the « production » of signs is articulated. This specificity in turn clarifies the « creativity » proper to metaphor, which renders it irreducible to other instruments of sign production, thus providing it with a fullness which is as rich as it is irreplaceable...|$|E
40|$|The {{result of}} the {{extraction}} of the edge and contour information of the multifunctional digital ship image directly affects the evaluation and recognition of the subsequent image quality. At present, the common method used to extract the edge contour information {{is based on the}} Canny operator, and there is a problem that the edge is not clear. In order to obtain more accurate edge information, a method of extracting edge and contour information of multimedia digital image based on multi-scale morphology is proposed. Firstly, the digital ship image is made <b>double</b> <b>filter</b> and the fuzzy threshold segmentation, and then the edge and contour information is extracted by multi-scale morphology. Experiments show that the proposed method can obtain more accurate edge information compared with the other methods...|$|E
40|$|This paper proposes double-talk {{resistant}} {{echo canceller}} with <b>double</b> <b>filters,</b> one for echo-path estimation {{and one for}} echo cancellation. An adaptive step-size algorithm based on the cross-correlation between the echo replica and the near-end speech {{is used for the}} echo-path identification. The filter co-efficients are copied from the estimation filter to the cancel-lation filter only when the cross-correlation is small enough. Computer simulation results show that the proposed algo-rithm successfully reduces echoes in a double-talk period. The tracking capability of the proposed algorithm for echo path changes is almost comparable to that of a previously proposed double-filter algorithm with fast transversal filter. 1...|$|R
40|$|Time-Of-Flight Diffraction (or TOFD, as it {{is widely}} known) has been {{developed}} {{for a number of}} years; however, there is still potential for improvement, from reducing dead zones to characterizing defects to more accurate sizing. This presentation will describe the TOFD technique as currently known, plus the subsequent developments available (lateral wave straightening, lateral wave removal, synthetic aperture focusing). Then, a new, improved sizing approach will be described, which uses a <b>double</b> <b>filtering</b> technique adapted from geophysics. This involves Weiner filtering to tidy up the signal, followed by autoregressive spectral extrapolation. Some preliminary TOFD results will be shown on a standard cracked block...|$|R
40|$|In {{terahertz}} pulsed imaging (TPI), a deconvolution {{process is}} usually applied as an inverse operation {{to extract the}} sample impulse function for further imaging or spectroscopic analysis. Often, such deconvolution is achieved by direct inverse filtering (IF) or IF with a coupled low-pass or <b>double</b> Gaussian <b>filter.</b> However, the low-pass or <b>double</b> Gaussian <b>filter</b> cannot cope well with both suppressing noise and retrieving localized terahertz pulses and they often result in over-smoothing. Here, we apply the iterative total variation method to the deconvolution process in TPI {{with a view to}} enhance the sample impulse function and generate better terahertz images. Experiments with both simulated and raw data validate a better performance for the proposed approach...|$|R
40|$|Abstract—The <b>double</b> <b>filter</b> {{method has}} been widely used for {{measuring}} the concentration of radon or thoron in air. The method consists of letting the filtered air into a cylindrical tube and collecting the decay products formed inside the tube on a filter paper at the exit. A sig-nificant portion of the decay products deposit on the wall. In the present modification, aerosol particles are let into the tube near the periphery. These scavenge and bring-the decay products on to the end filter thus preventing their deposition on the wall. The modified method improves the sensitivity, allows low flow rate sampling and {{can be considered as}} absolute, since nearly 95 % of all the decay products formed inside the decay tube are collected on the end filter. This method has a potential for the measurement of the low levels of radon found in the environment...|$|E
40|$|Abstract. This chapter {{focuses on}} the {{development}} of a new “true ” twodimensional representation for images that can capture the intrinsic geometrical structure of pictorial information. Our emphasis is on the discrete framework that can lead to algorithmic implementations. We propose a <b>double</b> <b>filter</b> bank structure, named the pyramidal directional filter bank, by combining the Laplacian pyramid with a directional filter bank. The result is called the contourlet transform, which provides a flexible multiresolution, local and directional expansion for images. The contourlet transform can be designed to satisfy the anisotropy scaling relation for curves, and thus offers a fast and structured curvelet-like decomposition sampled signals. As a result, the proposed transform provides a sparse representation for two-dimensional piecewise smooth signals that resemble images. The link between the developed filter banks and the continuous-space constructions is set up precisely in a newly defined directional multiresolution analysis. Finally, we show some numerical experiments demonstrating the potential of the new transform in several image processing tasks. 1...|$|E
40|$|Core {{electron}} temperature measurements {{have been performed}} in the large, high-current RFX reversed field pinch experiment (a = 0. 46 m, R = 2 m, target plasma current = 2 MA) with the <b>double</b> <b>filter</b> technique. With this technique the soft x-ray emission is measured by two Si detectors, covered by different Be-filters, and viewing the same region of the plasma. By choosing the filters {{in such a way}} that only the emission from the continuum part of the spectrum is measured, the ratio of the two signals is a function of the highest {{electron temperature}} along the line of sight of the detectors. With this diagnostic, the electron temperature has been measured in RFX with a bandwidth of approximately 2 kHz. This allows the direct measurement, for the first time in a RFP on a single shot basis, of coherent oscillations, associated with relaxation events and showing under some conditions a sawtooth-like character. The measurements of electron temperature obtained with this method are in good agreement with those performed with other diagnostics...|$|E
40|$|We {{present the}} notion of a {{filtered}} bundle as a generalisation of a graded bundle. In particular, we weaken the necessity of the transformation laws for local coordinates to exactly respect the weight of the coordinates by allowing more general polynomial transformation laws. The key examples of such bundles include affine bundles and various jet bundles, both of which play fundamental roles in geometric mechanics and classical field theory. We also present {{the notion of}} <b>double</b> <b>filtered</b> bundles which provide natural generalisations of double vector bundles and double affine bundles. Furthermore, we show that the linearisation of a filtered bundle - which {{can be seen as a}} partial polarisation of the admissible changes of local coordinates - is well defined. Comment: 23 page...|$|R
5000|$|Derivative filters {{based on}} {{arbitrary}} cubic splines was presented by Hast. He showed how both {{first and second}} order derivatives can be computed more correctly using cubic or trigonometric splines. Efficient derivative filters need to be of odd length so that the derivative is computed for the central pixel. However, any cubic filter is fitted over 4 sample points, giving a centre that falls between pixels. This is solved by a <b>double</b> <b>filtering</b> approach giving filters of size 7 x 7. The idea is to first filter by interpolation so that the interpolated value between pixels are obtained, whereafter the procedure is repeated using a derivative filters, where the centre value now falls on pixel centres. This can easily be proved by the associative law for convolution ...|$|R
40|$|We {{examine the}} in- and out-of-sample {{behavior}} of two popular trading systems, Alexander and <b>Double</b> MA <b>filters,</b> for 14 developed-country currencies using daily data with bid-ask spreads. We find significant in-sample returns {{in the early}} periods. But out-of-sample returns are lower and only occasionally significant. We show that a currency risk factor proposed in the literature is systematically related to these returns. We find no support for the hypotheses that falling transactions costs are responsible for declining trading profits or for the Adaptive Market hypothesis. Importantly, we show that algorithms that simulate out-of-sample returns have serious instability difficulties. Technical rules Alexander <b>filter</b> <b>Double</b> Moving Average Foreign exchange market...|$|R
