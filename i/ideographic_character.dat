8|35|Public
2500|$|... is a Japanese reading aid, {{consisting}} of smaller kana, or syllabic characters, printed {{next to a}} kanji (<b>ideographic</b> <b>character)</b> or other character to indicate its pronunciation. It is one type of ruby text. Furigana {{is also known as}} [...] or [...] in Japanese. In modern Japanese, it is mostly used to gloss rare kanji, to clarify rare, nonstandard or ambiguous kanji readings, or in children's or learners' materials. Before the post-World War II script reforms, it was more widespread.|$|E
50|$|Coded <b>Ideographic</b> <b>character</b> set {{specified}} collections such as: GB 2312, GBK, JIS 0208.|$|E
5000|$|Ideographic {{repertoire}} ( [...] , literally [...] "Chinese character repertoire" [...] or [...] "Hanzi repertoire"), in {{the field}} of Chinese information processing, refer to using coded <b>Ideographic</b> <b>character</b> set or category specifies Chinese characters set.|$|E
2500|$|<b>Ideographic</b> <b>characters</b> {{assigned}} by Unicode {{appear in the}} following blocks: ...|$|R
25|$|However, the {{boundary}} between the classes was not precise, as some <b>ideographic</b> <b>characters</b> were also used for their phonetic value as parts of other words.|$|R
50|$|Linear B Ideograms is a Unicode block {{containing}} <b>ideographic</b> <b>characters</b> {{for writing}} Mycenaean Greek. Several Linear B ideographs double as syllabic letters, and are encoded in the Linear B Syllabary block.|$|R
5000|$|... 1946: Chinese {{character}} typewriterIBM introduces {{an electric}} Chinese <b>ideographic</b> <b>character</b> typewriter, which allowed an experienced user to type {{at a rate}} of 40 to 45 Chinese words a minute. The machine utilizes a cylinder on which 5,400 ideographic type faces are engraved.|$|E
5000|$|... 1979: Overcoming {{barriers}} to technology useSince 1946, with its announcement of Chinese and Arabic <b>ideographic</b> <b>character</b> typewriters, IBM {{has worked to}} overcome cultural and physical {{barriers to}} the use of technology. As part of these ongoing efforts, IBM introduces the 3270 Kanji Display Terminal; the System/34 Kanji System with an ideographic feature, which processes more than 11,000 Japanese and Chinese characters; and the Audio Typing Unit for sight-impaired typists.|$|E
5000|$|Furigana (...) is a Japanese reading aid, {{consisting}} of smaller kana, or syllabic characters, printed {{next to a}} kanji (<b>ideographic</b> <b>character)</b> or other character to indicate its pronunciation. It is one type of ruby text. Furigana {{is also known as}} yomigana (...) or rubi (...) in Japanese. In modern Japanese, it is mostly used to gloss rare kanji, to clarify rare, nonstandard or ambiguous kanji readings, or in children's or learners' materials. Before the post-World War II script reforms, it was more widespread.|$|E
2500|$|Compound ideographs (會意 huì yì, [...] "joined meaning"), {{also called}} {{associative}} compounds or logical aggregates, are compounds {{of two or}} more pictographic or <b>ideographic</b> <b>characters</b> to suggest {{the meaning of the word}} to be represented.|$|R
50|$|It {{does not}} cover the {{combining}} diacritics used by Vietnamese-related code page 1258, the Thai letters used in code page 874, Hebrew and Arabic letters covered by code pages 1255 and 1256, or the <b>ideographic</b> <b>characters</b> used by code pages 932, 936, 949 and 950.|$|R
5000|$|Compound ideographs (會意 huì yì, [...] "joined meaning"), {{also called}} {{associative}} compounds or logical aggregates, are compounds {{of two or}} more pictographic or <b>ideographic</b> <b>characters</b> to suggest {{the meaning of the word}} to be represented.In the postface to the Shuowen Jiezi, Xu Shen gave two examples: ...|$|R
40|$|The current {{document}} is an extract of nine pages from my 2003 PhD Dissertation. These pages {{are intended to}} introduce some aspects of Wenlin Institute's CDL, a system which holds much promise for management of CJK Unified <b>Ideographic</b> <b>character</b> data. This document augments part three of L 2 / 03 - 286 (Cook & Bishop). Additional documents in this series will follow, including {{a draft of the}} full XML CDL specification...|$|E
40|$|The {{identification}} of {{any form of}} social learning, imitation, copying or mimicry presupposes a notion of correspondence between two autonomous agents. Judging whether a behavior has been transmitted socially requires the observer to identify a mapping between the demonstrator and the imitator. If the demonstrator and imitator have similar bodies, e. g. are animals of the same species, of similar age, and of the same gender, then to a human observer an obvious correspondence is to map the corresponding body parts: left arm of demonstrator maps to left arm of imitator, right eye of demonstrator maps to right eye of imitator, tail of demonstrator maps to tail of imitator. There is also an obvious correspondence of actions: raising the left arm by the model corresponds to raising the left arm by the imitator, production of vocal signals by the model corresponds {{to the production of}} acoustically similar ones by the imitator, picking up a fruit by the demonstrator corresponds to picking up a fruit of the same type by the imitator. Furthermore, there is a correspondence in sensory experience: audible sounds, a touch, visible objects and colors, and so on evidently seem to be detected and experienced in similar ways. What to take as the correspondence seems relatively clear in this case. As humans, we are good at imitating and at recognizing such correspondences. It is also clear that most other animals, robots, and software programs may in fact generally fail to recognize any such correspondences. To judge a produced behavior to be a copy of an observed one, we require at least that it respects some such correspondence. The faithfulness or precision of the behavioral match can obviously vary, and no absolute cutoff or threshold exists defining success as opposed to failure of behavioral matching. But one can study the degree of success using various metrics and measures of correspondence (Nehaniv & Dautenhahn, 2001; also see below). Moreover, {{it turns out that the}} 9 ̆ 3 obvious 9 ̆ 4 correspondences between similar bodies mentioned above are not the only ones possible. Consider a human imitating another one that is facing her: if the demonstrator raises her left arm, should the imitator raise her own left arm? Or should she raise her right, to make a "mirror image" of the demonstrator's actions? If the demonstrator picks up a brush, should an imitator pick up the same brush? Or just another brush of the same type? If the demonstrator opens a container to get at chocolate inside, should the imitator open a similar container in the same way 9 ̆ 6 e. g. by unwrapping but not tearing the surrounding paper?, or is it enough just to open the container somehow? The different possible answers to these questions presuppose different correspondences. If a child watches a teacher solving subtraction problems in arithmetic, and then solves for the first time similar but not identical problems on its own, social learning has occurred. But what type of correspondence is at work here? In China and Japan, the <b>ideographic</b> <b>character</b> for 9 ̆ 3 to imitate 9 ̆ 4 also means 9 ̆ 3 to learn 9 ̆ 4 or 9 ̆ 3 to study 9 ̆ 4. By going through the motions of an algorithm for solving sample problems, students everywhere are able to learn how to solve similar ones, of course without necessarily gaining understanding of why the procedures they have learned work. In this chapter, for lack of a better term, we shall use the word 9 ̆ 3 imitator 9 ̆ 4 to refer to any autonomous agent performing a candidate behavioral match. The use of this word here does not entail any particular mechanism of matching or any particular type of social learning. In what follows, we shall describe how different matching phenomena arise depending on the criteria employed in generating the behavior of the imitator. For example, goal emulation, stimulus enhancement, mimicry, and so on, will all be cast as solutions to correspondence problems with different particular selection criteria...|$|E
5000|$|In September 2002, the U.S. District Court for Northern California awarded Tegic, {{owned by}} AOL TimeWarner, [...] {{million in damages}} for Zi's {{infringement}} of two Tegic patents. Zi's claim that the two Tegic patents were based on existing methods of inputting Chinese <b>ideographic</b> <b>characters</b> were rejected.|$|R
2500|$|Also {{translated}} as logical aggregates or associative compounds, these characters have been interpreted as combining {{two or more}} pictographic or <b>ideographic</b> <b>characters</b> to suggest a third meaning. [...] Commonly cited examples include [...] "rest" [...] (composed of the pictograms [...] "person" [...] and [...] "tree") and [...] "good" [...] (composed of [...] "woman" [...] and [...] "child").|$|R
40|$|It is {{desirable}} to store text {{data in a}} database so that the basic functions are provided by the underlying database management system (DBMS). However, most DBMSs use English-like semantics as the query language for data manipulation. Although they can be localized to users' preferred languages, text processing under database systems are still far short of support for handling <b>ideographic</b> <b>characters,</b> such as Chinese, Japanese, and Korean [2]. Usually, sorting and indexing in a database system use the internal code sequence defined in the given codeset. For alphabet-based languages, such as English and French, sorting and indexing is quite straight forward because the internal code sequence naturally reflects the alphabetic order. But, sorting and indexing <b>ideographic</b> <b>characters</b> such as Chinese based on internal code sequence does not reveal relationships among data. Therefore, browsing data indexed based on internal code sequence cannot reveal the relationships among the neighbouring d [...] ...|$|R
5000|$|The {{following}} Unicode-related documents {{record the}} purpose and process of defining specific <b>characters</b> in the <b>Ideographic</b> Description <b>Characters</b> block: ...|$|R
5000|$|The <b>Ideographic</b> Myth: Chinese <b>characters</b> {{represent}} ideas {{instead of}} sounds.|$|R
40|$|AbstractThe {{present study}} {{investigated}} the role of interword spacing in a naturally unspaced language, Japanese. Eye movements were registered of native Japanese readers reading pure Hiragana (syllabic) and mixed Kanji–Hiragana (ideographic and syllabic) text in spaced and unspaced conditions. Interword spacing facilitated both word identification and eye guidance when reading syllabic script, but not when the script contained <b>ideographic</b> <b>characters.</b> We conclude that in reading Hiragana interword spacing serves as an effective segmentation cue. In contrast, spacing information in mixed Kanji–Hiragana text is redundant, since the visually salient Kanji characters serve as effective segmentation cues by themselves...|$|R
40|$|Abstract — Optical Character Recognition (OCR) in Japanese, both {{handwritten}} and printed, {{is difficult}} to perform, owing to several reasons. Firstly, the Japanese language is comprised of over 3000 characters which can be classified as syllabic characters, or Kana, and <b>ideographic</b> <b>characters,</b> called Kanji. Secondly, Japanese text does not have delimiters like spaces, separating different words. Thirdly, several characters in the Japanese alphabet could be homo-morphic, i. e. have similar shape definition which could add {{to the complexity of}} the recognition process. In this paper, we present a survey that has been conducted of some of the approaches that have attempted to address these issues and implement schemes for Japanese character recognition in texts...|$|R
50|$|<b>Ideographic</b> Description <b>Characters</b> is a Unicode block {{containing}} graphic characters {{used for}} describing CJK ideographs. They {{are not intended}} to provide a mechanism for the composition of complex characters, whether already encoded or not, but are used within Ideographic Description Sequences (IDS) for that purpose.|$|R
50|$|This one was {{the root}} of the {{so-called}} Oiban kanri for series production management, of the Seiban kanri for discontinuous productions and of the Setsuban Kanri for make-to-order productions. The study and formalization of this threefold approach were run later on by JMA - the Japan Management Association, who could base their work on the most significant industrial experiences to date (such as the application of the oiban kanri at Kawasaki Heavy Industries). Besides, they could enrich and tune the methodological contents with specific implementation tools and gave meaningful contributions to the definition of the methodology itself, which was named Setsuban Kanri from the reading of the <b>ideographic</b> <b>characters</b> 節 (setsu = period/temporal unit) and 番 (ban = ordinal number) + 管理 (kanri = management, control).|$|R
5000|$|A set of {{radicals}} {{was provided}} in Unicode 3.0 (CJK radicals between U+2E80 and U+2EFF, KangXi radicals in U+2F00 to U+2FDF, and <b>ideographic</b> description <b>characters</b> from U+2FF0 to U+2FFB), but the Unicode standard (ch. 12.2 of Unicode 5.2) warns against using ideographic description sequences as an alternate representation for previously encoded characters: ...|$|R
40|$|This paper {{presents}} QuickStroke: {{a system}} for the incremental recognition of handwritten Chinese characters. Only a few strokes of an ideogram need to be entered {{in order for a}} character to be successfully recognized. Incremental recognition is a new approach for on-line recognition of <b>ideographic</b> <b>characters.</b> It allows a user to enter characters a factor of 2 times faster than systems that require entry of full characters. Incremental recognition is performed by a two-stage system which utilizes 68 neural networks with more than 5 million free parameters. To enable incremental recognition, we use specialized time-delay neural networks (TDNNs) that are trained to recognize partial characters. To boost the recognition accuracy of complete characters, we also use standard fully-connected neural networks. Quickstroke is 97. 3 % accurate for the incremental writer-independent recognition of 4400 simplified GB Chinese ideograms...|$|R
500|$|Young did so, {{with two}} results that {{together}} {{paved the way}} for the final decipherment. In the hieroglyphic text, he discovered the phonetic characters [...] "p t o l m e s" [...] (in today's transliteration [...] "p t w l m y s") that were used to write the Greek name [...] "Ptolemaios". He also noticed that these characters resembled the equivalent ones in the Demotic script, and went on to note as many as 80 similarities between the hieroglyphic and Demotic texts on the stone, an important discovery because the two scripts were previously thought to be entirely different from one another. This led him to deduce correctly that the Demotic script was only partly phonetic, also consisting of <b>ideographic</b> <b>characters</b> imitated from hieroglyphs. Young's new insights were prominent in the long article [...] "Egypt" [...] that he contributed to the Encyclopædia Britannica in 1819. He could make no further progress, however.|$|R
40|$|The most {{commonly}} used Japanese alphabets are Kanji, Hiragana and Katakana. The Kanji alphabet includes pictographs or <b>ideographic</b> <b>characters</b> that were adopted from the Chinese alphabet. Hiragana is used to spell words of Japanese origin, while Katakana is used to spell words of western or other foreign origin. Two methods are commonly used to input Japanese to the computer. One, the 'kana input method' that uses a keyboard having 46 Japanese iroha (or kana) letter keys. The other method is 'Roma-ji input method', where the Japanese letters are composed of English input from a standard QWERTY keyboard. Both the methods have their advantages and disadvantages. This article analyses two inventions on inputting Japanese language through a computer keyboard. One invention uses a standard English keyboard to input Japanese characters, the other invention uses a standard mobile phone key board to input the Japanese characters. Comment: Published in TRIZsite Journal, April 2005, also available at [URL]...|$|R
5000|$|Young did so, {{with two}} results that {{together}} {{paved the way}} for the final decipherment. In the hieroglyphic text, he discovered the phonetic characters [...] "p t o l m e s" [...] (in today's transliteration [...] "p t w l m y s") that were used to write the Greek name [...] "Ptolemaios". He also noticed that these characters resembled the equivalent ones in the Demotic script, and went on to note as many as 80 similarities between the hieroglyphic and Demotic texts on the stone, an important discovery because the two scripts were previously thought to be entirely different from one another. This led him to deduce correctly that the Demotic script was only partly phonetic, also consisting of <b>ideographic</b> <b>characters</b> imitated from hieroglyphs. Young's new insights were prominent in the long article [...] "Egypt" [...] that he contributed to the Encyclopædia Britannica in 1819. He could make no further progress, however.|$|R
40|$|The {{recognition}} of Chinese characters {{has been an}} area of great interest for many years, {{and a large number}} of research papers and reports have already been published in this area. There are several major problems with Chinese character recognition: Chinese characters are distinct and <b>ideographic,</b> the <b>character</b> size is very large and many structurally similar characters exist in the character set. Thus, classification criteria are difficult to generate...|$|R
40|$|Abstract. This paper {{discusses}} online {{handwriting recognition}} of Japanese characters, {{a mixture of}} <b>ideographic</b> <b>characters</b> (Kanji) of Chinese ori-gin, and the phonetic characters made from them. Most Kanji character patterns are composed of multiple subpatterns, called radicals, which are shared among many (sometimes hundreds of) Kanji character patterns. This is common in Oriental languages of Chinese origin, i. e., Chinese, Ko-rean and Japanese. It is also common that each language has thousands of characters. Given these characteristics, structured character pattern representation (SCPR) composed of subpatterns is effective {{in terms of the}} size reduction of a prototype dictionary (a set of prototype patterns) and the robustness to deformation of common subpatterns. In this pa-per, we show a prototype learning algorithm and HMM-based recognition for SCPR. Then, we combine the SCPR-based online recognizer with a compact offline recognizer employing quadratic discriminant functions. Moreover, we also discuss online handwritten Japanese text recognition and propose character orientation-free and line direction-free handwrit-ten text recognition and segmentation. Finally, as applications of online handwritten Japanese text recognition, we show segmentation of mixed objects of text, formulas, tables and line-drawings, and handwritten text search. ...|$|R
40|$|Abstract Among the {{language}} texts in natural language, Chinese texts {{are written in}} a continuous way with <b>ideographic</b> <b>characters.</b> Unlike other western language texts such as English, Portuguese, etc., delimiters are used to specify the word boundaries. Hence, for any Chinese information processing system such as automatic question and answering, web information retrieval, text to speech conversion, machine translation, etc., {{the first and most}} important step is the word segmentation or word boundaries detection. In this paper, we present a Chinese word segmenter which is based on the maximum entropy model. The word segmentation algorithm is based on the idea so-called treat Chinese word segmentation as tagging. Maximum entropy model is a kind of feature-based model which is flexible to include arbitrary features for determining the boundaries of word and it gives a good criterion to evaluate the results of word segmentation. Besides the rule-based model like maximum matching, statistics-based model like N-gram model and the N-shortest-paths method, maximum entropy model is an alternative approach that is applied to the task of word segmentation. An important property of maximum entropy model is the selection of features to set up the model for a specific task. In our research, we have performed experiments based on the three corpora from the First International Chinese Word Segmentation Bakeoff, namely the corpora from Academia Sinica (AS), Cit...|$|R
5000|$|Lastly, Lin Yutang's {{dictionary}} {{has some}} minor mistakes (Ching 1975: 524). One example of translation error is found under {{the very first}} entry, tsair 才; tsairmauh 才貌 [...] "personal appearance as reflecting ability" [...] is translationally incompatible with larng-tsair-nyuumauh 郎才女貌 [...] "the boy has talent and the girl has looks" [...] (under 郎) and tsair-mauh-shuang-chyuarn 才貌雙全 [...] "to have both talent and looks" [...] (under 全). Another example of carelessness is seen under the sequential entries shyu 戍 [...] "Garrison; frontier guard" [...] and shuh 戌 [...] "No. 11 in the duodecimal cycle", where Lin warns students to distinguish the characters from each other. Yet, the chiaan 遣 entry writes the example word chiaanshuh 遣戌 [...] "send to exile" [...] twice as [...] "遣戍"; an error that the revised 1987 edition corrected. Admittedly, these two <b>ideographic</b> <b>characters</b> are easily confused, xū 戌 (戊 [...] "a weapon" [...] and a horizontal stroke 一 signifying [...] "to wound") [...] "destroy; 11th" [...] and shù 戍 (戊 [...] "a weapon" [...] and a dot 丶 simplified from the original 人 [...] "person" [...] signifying [...] "person with a weapon") [...] "frontier guard" [...] (Bernard Karlgren, Wenlin 2016). Eugene Ching concludes that, [...] "Since his profound knowledge of both Chinese and English makes Lin {{one of the most}} qualified persons to work on a bilingual dictionary, it is impossible that he is ignorant of the correct translation and the correct grammar of the above examples. These mistakes can only suggest Lin's failure to proofread carefully the work of his assistants." ...|$|R
40|$|THE {{proposed}} {{procedure for}} automatic translation of a Japanese linear text into English {{can be divided}} into four stages: 1) automatic input editing, 2) automatic segmentation with morphological analysis, 3) syn-tactical analysis, and 4) transformation with output editing, including semantic transfer. 2. FORMS OF INPUT TEXTS It is apparent that input texts which are in accord with a commonly accepted writing system are better {{in the sense that they}} need less pre-editing before they are fed into a machine. Because the standard vernac-ular writing system of Japanese makes no use of spaces between words and because kanas (syllable Japanese <b>characters)</b> and kanjis (<b>ideographic</b> Chinese <b>characters)</b> are used instead of roman letters, it is necessary to devise a method of automatically cutting into its components the unseg-mented sentence, written in kanas and kanjis, In the standard writing system, 71 kanas and 1850 kanjis are used...|$|R
40|$|Recognition of Chinese {{characters}} {{has been}} an area of major for many years, {{and a large number}} of research papers and reports have already been published in this area. There are several major problems with Chinese character recognition: Chinese characters are distinct and <b>ideographic,</b> the <b>character</b> size is very large and a lot of structurally similar characters exist in the character set. Thus, classification criteria are difficult to generate. This paper presents a new technique for the recognition of hand-printed Chinese characters using statistical pattern classification. Conventional methods have relied on hand-constructed dictionaries which are tedious to construct and difficult to make tolerant to variation in writing styles. The paper discusses Chinese character recognition using dominant point feature extraction and statistical pattern classification. The system was tested with 500 characters (each character has 40 samples) and the rate of recognition obtained was 84. 45 %. This [...] ...|$|R
40|$|A Doctoral Thesis. Submitted in partial {{fulfilment}} of {{the requirements}} for the award of Doctor of Philosophy of Loughborough University. Automatic indexing is the automatic creation of a text surrogate, normally keywords or phrases, to represent the original text. In the current English text retrieval systems, this process of content representation is accomplished by extracting words using spaces and punctuations as word delimiters. The same technique cannot easily be applied to Chinese texts which contain no obvious word boundaries; {{they appear to be}} a linear sequence of non-spaced or equally spaced <b>ideographic</b> <b>characters</b> and thenumber of characters in words varies. The solution to the problem lies in morphological and syntactic analyses of Chinese morphemes, words and phrases. The idea is inspired by the experiments on English computational morphology and its application to English text retrieval, mainly automatic compound and phrase indexing. These areas are particularly germane to Chinese because typographically there are no morph and phrase boundaries in either Chinese or English texts. The experiment is based on the hypothesis that words and phrases exceeding two Chinese characters can be characterised by a grammar that describes the concatenation behaviour of morphological and syntactic categories. This is examined using the following three procedures: (1) text segmentation - texts are divided into one and two character segments by searching a dictionary containing over 17000 morphemes and words, which are tagged with 'morphological and syntactic categories. (2) category disambiguation - for the resulting morphemes and words tagged with more than one category, the correct one is selected based on context (3) parsing - the segments are analysed using the grammar, which combines them into compound and complex words and phrases for indexing and retrieval. The utilities employed in the experiment include CCOOS, an extended version of MSOOS providing for Chinese I/O system,Chinese Wordstar for text input and Chinese dBASEIII for dictionary construction. Source codes are written in Turbo BASIC including its database toolbox. Thiny texts are drawn randomly from newspapers to form thcsample for the experiment. The results prove that the partial syntactic analysis-based approach can extract keywords with a good degree of accuracy...|$|R
40|$|Ideograph {{characters}} are often formed by some smaller functional units, {{which we call}} character components. These character components can be ideograph radicals, ideographs proper, or some pure components which must be used with others to form characters. Decomposition of ideographs {{can be used in}} many applications. It is particularly important in the study of Chinese character formation, phonetics and semantics. However, the way a character is decomposed depends on the definition of components as well as the decomposition rules. The 12 <b>Ideographic</b> Description <b>Characters</b> (IDCs) introduced in ISO 10646 are designed to describe characters using components. The Hong Kong SAR Government recently published two sets of glyph standards for ISO 10646 characters. The standards, being the first of its kind, make use of character decomposition to specify a character glyph using its components. In this paper, we will first introduce the IDCs and how they can be used with components to describe two dimensional ideograph characters in a linear fashion. Next we will briefly discuss the basic references and character decomposition rules. We will then describe the data structure and algorithms to decompose Chinese characters into components and, vice versa. We have also implemented our database and algorithms as an internet application, called the Chinese Character Search System, available at websit...|$|R
