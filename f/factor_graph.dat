736|485|Public
25|$|Bipartite graphs are {{extensively}} used {{in modern}} coding theory, especially to decode codewords {{received from the}} channel. Factor graphs and Tanner graphs are examples of this. A Tanner graph is a bipartite graph in which the vertices {{on one side of}} the bipartition represent digits of a codeword, and the vertices on the other side represent combinations of digits that are expected to sum to zero in a codeword without errors. A <b>factor</b> <b>graph</b> is a closely related belief network used for probabilistic decoding of LDPC and turbo codes.|$|E
5000|$|... with a {{corresponding}} <b>factor</b> <b>graph</b> {{shown on the}} right. Observe that the <b>factor</b> <b>graph</b> has a cycle. If we merge [...] into a single factor, the resulting <b>factor</b> <b>graph</b> will be a tree. This is an important distinction, as message passing algorithms are usually exact for trees, but only approximate for graphs with cycles.|$|E
5000|$|OpenGM Library for {{discrete}} <b>factor</b> <b>graph</b> {{models and}} distributive operations on these models (C++) ...|$|E
40|$|Abstract—We {{introduce}} {{the concept of}} convolutional <b>factor</b> <b>graphs,</b> which represent convolutional factorizations of multivariate functions, just as conventional (multiplicative) <b>factor</b> <b>graphs</b> represent multiplicative factorizations. Convolutional and multiplicative <b>factor</b> <b>graphs</b> arise as natural Fourier transform duals. In coding theory applications, algebraic duality of group codes is essentially an instance of Fourier transform duality. Convolutional <b>factor</b> <b>graphs</b> arise when a code is represented as a sum of subcodes, just as conventional multiplicative <b>factor</b> <b>graphs</b> arise when a code is represented as an intersection of supercodes. With auxiliary variables, convolutional <b>factor</b> <b>graphs</b> give rise to “syndrome realizations ” of codes, just as multiplicative <b>factor</b> <b>graphs</b> with auxiliary variables give rise to “state realizations. ” We introduce normal and co-normal extensions of a multivariate function, which essentially allow a given function to be represented with either a multiplicative or a convolutional factorization, as is convenient. We use these function extensions to derive a number of duality relationships among the corresponding <b>factor</b> <b>graphs,</b> and use these relationships to obtain the duality properties of Forney graphs as a special case. Index Terms—Duality, <b>factor</b> <b>graphs,</b> Forney graphs, Fourier transform, graphical models, normal realizations, state realizations, syndrome realizations, Tanner graphs. I...|$|R
5000|$|... #Subtitle level 2: Generalized {{compressibility}} <b>factor</b> <b>graphs</b> {{for pure}} gases ...|$|R
40|$|Several {{problems}} in robotics {{can be solved}} using constrained optimization. For example, solutions in areas like control and planning frequently use it. Meanwhile, the Georgia Tech Smoothing and Mapping (GTSAM) toolbox provides a straight forward way to represent sparse least-square optimization problems as <b>factor</b> <b>graphs.</b> <b>Factor</b> <b>graphs,</b> are a popular graphical model to represent a factorization of a probability distribution allowing for efficient computations. This paper demonstrates {{the use of the}} GTSAM and <b>factor</b> <b>graphs</b> to solve linear and quadratic constrained optimization programs using the active set method. It also includes an implementation of a line search method for sequential quadratic programming that can solve nonlinear equality constrained problems. The result is a constrained optimization framework that allows the user to think of optimization problems as solving a series of <b>factor</b> <b>graphs</b> and is open-source. Undergraduat...|$|R
5000|$|Variants of {{the belief}} {{propagation}} algorithm exist for several types of graphical models (Bayesian networks and Markov random fields, in particular). We describe here the variant that operates on a <b>factor</b> <b>graph.</b> A <b>factor</b> <b>graph</b> is a bipartite graph containing nodes corresponding to variables V and factors F, with edges between variables and the factors in which they appear. We can write the joint mass function: ...|$|E
50|$|When such a {{factorization}} does exist, it {{is possible}} to construct a <b>factor</b> <b>graph</b> for the network.|$|E
5000|$|A <b>factor</b> <b>graph</b> is a {{bipartite graph}} {{representing}} the factorization of a function. Given a factorization of a function , ...|$|E
40|$|<b>Factor</b> <b>graphs</b> are {{important}} models for succinctly representing probability distributions in machine learning, coding theory, and statistical physics. Several computational problems, such as computing marginals and partition functions, arise naturally {{when working with}} <b>factor</b> <b>graphs.</b> Belief propagation is a widely deployed iterative method for solving these problems. However, despite its significant empirical success, not much {{is known about the}} correctness and efficiency of belief propagation. Bethe approximation is an optimization-based framework for approximating partition functions. While it is known that the stationary points of the Bethe approximation coincide with the fixed points of belief propagation, in general, the relation between the Bethe approximation and the partition function is not well understood. It has been observed that for a few classes of <b>factor</b> <b>graphs,</b> the Bethe approximation always gives a lower bound to the partition function, which distinguishes them from the general case, where neither a lower bound, nor an upper bound holds universally. This has been rigorously proved for permanents and for attractive graphical models. Here we consider bipartite normal <b>factor</b> <b>graphs</b> and show that if the local constraints satisfy a certain analytic property, the Bethe approximation is a lower bound to the partition function. We arrive at this result by viewing <b>factor</b> <b>graphs</b> through the lens of polynomials. In this process, we reformulate the Bethe approximation as a polynomial optimization problem. Our sufficient condition for the lower bound property to hold is inspired by recent developments in the theory of real stable polynomials. We believe that this way of viewing <b>factor</b> <b>graphs</b> and its connection to real stability might lead {{to a better understanding of}} belief propagation and <b>factor</b> <b>graphs</b> in general. Comment: Invited to Allerton 201...|$|R
40|$|Inference on <b>factor</b> <b>graphs</b> with loops {{with the}} {{standard}} forwardbackward algorithm, can give unpredictible results as messages can travel indefinitely in the system with no guarantee on convergence. We apply the exact method of cutset conditioning to <b>Factor</b> <b>Graphs</b> with loops starting from a fully developed three-variable example and providing comments and suggestions for distributed implementations...|$|R
30|$|To avoid {{computational}} complications, it {{is important}} to express the formulas for the product of F-sum of graphs in terms of their <b>factor</b> <b>graphs.</b> So, we presented bounds for the first Zagreb index, the ABC-index, the third Zagreb index, the augmented Zagreb index, the F-index, the first multiple Zagreb index and the GA-index for the Cartesian product of F-sum of graphs in form of its <b>factor</b> <b>graphs.</b>|$|R
5000|$|... (as per the <b>factor</b> <b>graph</b> representation) can {{be viewed}} as a measure of the {{internal}} energy present in a system, computed as ...|$|E
50|$|For every integer ,the free <b>factor</b> <b>graph</b> , {{equipped}} with the simplicial metric (where every edge has length 1), is a connected graph of infinite diameter.|$|E
5000|$|... where xa is {{the vector}} of {{neighboring}} variable nodes to the factor node a. Any Bayesian network or Markov random field {{can be represented}} as a <b>factor</b> <b>graph.</b>|$|E
40|$|Gates {{are a new}} {{notation}} for representing mixture {{models and}} context-sensitive independence in <b>factor</b> <b>graphs.</b> <b>Factor</b> <b>graphs</b> provide a natural representation for message-passing algorithms, such as expectation propagation. However, message passing in mixture models is not well captured by <b>factor</b> <b>graphs</b> unless the entire mixture is represented by one factor, because the message equations have a containment structure. Gates capture this containment structure graphically, allowing both the independences and the message-passing equations for a model to be readily visualized. Different variational approximations for mixture models {{can be understood as}} different ways of drawing the gates in a model. We present general equations for expectation propagation and variational message passing in the presence of gates. ...|$|R
40|$|Abstract. We {{introduce}} a new framework for feature grouping based on <b>factor</b> <b>graphs,</b> which are graphical models that encode interactions among arbitrary numbers of random variables. The ability of <b>factor</b> <b>graphs</b> to express interactions higher than pairwise order (the highest order encountered in most graphical models used in computer vision) is useful for modeling a variety of pattern recognition problems. In particular, we show how this property makes <b>factor</b> <b>graphs</b> a natural framework for performing grouping and segmentation, which we apply {{to the problem of}} finding text in natural scenes. We demonstrate an implementation of our factor graph-based algorithm for finding text on a Nokia camera phone, which is intended for eventual use in a camera phone system that finds and reads text (such as street signs) in natural environments for blind users. ...|$|R
50|$|<b>Factor</b> <b>graphs</b> can be {{combined}} with message passing algorithms to efficiently compute certain characteristics of the function , such as the marginal distributions.|$|R
5000|$|For every integer ,the free <b>factor</b> <b>graph</b> , {{equipped}} with the simplicial metric, is Gromov-hyperbolic. This result was originally established by Bestvina and Feighn; see also [...] for subsequent alternative proofs.|$|E
5000|$|The {{hyperbolic}} boundary [...] of {{the free}} <b>factor</b> <b>graph</b> can be identified with the set of equivalence classes of ``arational" [...] -trees in the boundary [...] of the Outer space [...]|$|E
5000|$|A <b>factor</b> <b>graph</b> is an undirected {{bipartite graph}} {{connecting}} variables and factors. Each factor represents a function over the variables it is connected to. This is a helpful representation for understanding and implementing belief propagation.|$|E
40|$|Many {{applications}} that involve inference {{and learning in}} signal processing, communication and artificial intelligence can be cast into a <b>graph</b> framework. <b>Factor</b> <b>graphs</b> are a type of network that can be studied and solved by propagating belief messages with the sum/product algorithm. In this paper we provide explicit matrix formulas for inference and learning in finite alphabet Forney-style <b>factor</b> <b>graphs,</b> with the precise intent of allowing rapid prototyping of arbitrary topologies in standard software like MATLAB...|$|R
30|$|Of course, the {{proposed}} framework is not unique, so we also refer {{the reader to}} an alternative version based on <b>factor</b> <b>graphs</b> [23].|$|R
40|$|We offer a {{solution}} to the problem of efficiently translating algorithms between different types of discrete statistical model. We investigate the expressive power of three classes of model—those with binary variables, with pairwise factors, and with planar topology—as well as their four in-tersections. We formalize a notion of “simple reduction ” for the problem of inferring marginal probabilities and consider whether it is possible to “simply reduce ” marginal inference from general discrete <b>factor</b> <b>graphs</b> to <b>factor</b> <b>graphs</b> in each of these seven subclasses. We characterize the reducibility of each class, showing in particular that the class of binary pairwise <b>factor</b> <b>graphs</b> is able to simply reduce only positive models. We also exhibit a continuous “spectral reduction ” based on polynomial interpolation, which overcomes this limitation. Experiments assess the performance of standard approximate inference algorithms on the out-puts of our reductions. ...|$|R
50|$|In {{the case}} where the <b>factor</b> <b>graph</b> is acyclic (i.e. is a tree or a forest), these {{estimated}} marginal actually converge to the true marginals in {{a finite number of}} iterations. This can be shown by mathematical induction.|$|E
50|$|Below is a graph {{fragment}} of an example LDPC code using Forney's <b>factor</b> <b>graph</b> notation. In this graph, n variable nodes {{in the top}} of the graph are connected to (n&minus;k) constraint nodes in the bottom of the graph.|$|E
5000|$|In {{the case}} when the <b>factor</b> <b>graph</b> is a tree, the belief {{propagation}} algorithm will compute the exact marginals. Furthermore, with proper scheduling of the message updates, it will terminate after 2 steps. This optimal scheduling {{can be described as}} follows: ...|$|E
40|$|The Dynamic Tree [1] (DT) Bayesian Network is a {{powerful}} analytical tool for image segmentation and object segmentation tasks. Its hierarchical nature {{makes it possible to}} analyze and incorporate information from different scales, which is desirable in many applications. Having a flexible structure enables model selection, concurrent with parameter inference. In this paper, we propose a novel framework, dynamic <b>factor</b> <b>graphs</b> (DFG), where data segmentation and fusion tasks are combined in the same framework. <b>Factor</b> <b>graphs</b> (FGs) enable us to have a broader range of modeling applications than Bayesian networks (BNs) since FGs include both directed acyclic and undirected graphs in the same setting. The example in this paper will focus on segmentation and fusion of 2 D image features with a linear Gaussian model assumption. Index Terms — dynamic <b>factor</b> <b>graphs,</b> sum-product algorithm, linear Gaussian models, data fusion, data segmentatio...|$|R
40|$|Expectation {{propagation}} is {{an important}} variational inference algorithm for graphical models, especially {{if some of the}} variables are continuous. This tutorial presents two views EP: as repeatedly projecting into an approximating family, and as a message-passing algorithm. We present EP in terms of <b>factor</b> <b>graphs,</b> which simplifies some of the presentation and provides concreteness, while remaining completely general. We give special emphasis to explaining why belief propagation is a special case of EP, and how EP can be used to approximate a <b>factor</b> <b>graph’s</b> partition function. ...|$|R
30|$|We {{consider}} factor-graph-based soft self-iterative equalization in wireless multipath channels. Since <b>factor</b> <b>graphs</b> {{are able}} to characterize multipath channels to per-path level, the corresponding soft self-iterative equalizer possesses reduced computational complexity in sparse multipath channels. The performance of the considered self-iterative equalizer is analyzed in both single-antenna and multiple-antenna multipath channels. When <b>factor</b> <b>graphs</b> of multipath channels have no cycles or mild cycle conditions, the considered self-iterative equalizer can converge to optimum performance after a few iterations; but it may suffer local convergence in channels with severe cycle conditions.|$|R
50|$|In {{constraint}} satisfaction research of artificial intelligence and operations research, constraint graphs and hypergraphs {{are used to}} represent relations among constraints in a {{constraint satisfaction}} problem. A constraint graph is a special case of a <b>factor</b> <b>graph,</b> which allows {{for the existence of}} free variables.|$|E
5000|$|For turbo codes, an {{interleaver}} is {{an integral}} component and its proper design is crucial for good performance. [...] The iterative decoding algorithm works best when there are not short cycles in the <b>factor</b> <b>graph</b> that represents the decoder; the interleaver is chosen to avoid short cycles.|$|E
5000|$|... where , the {{corresponding}} <b>factor</b> <b>graph</b> [...] consists of variable vertices, factor vertices , and edges [...] The edges {{depend on the}} factorization as follows: there is an undirected edge between factor vertex [...] and variable vertex [...] iff [...] The function is tacitly assumed to be real-valued: [...]|$|E
3000|$|... can be {{efficiently}} capitalized by (1) {{describing the}} joint probability distribution {{of all the}} variables involved in the system by means of <b>factor</b> <b>graphs</b> and (2) marginalizing for [...]...|$|R
30|$|We {{determine}} the lower and upper bounds for the F-index and the Narumi-Katayama {{index of the}} Cartesian product of F-sum of graphs {{in terms of their}} <b>factor</b> <b>graphs</b> for F=R.|$|R
5000|$|<b>Factor</b> <b>graphs</b> {{are used}} to [...] "pack up" [...] each team into [...] pairs on which the update {{formulas}} are run; the skill updates are then correctly distributed to each player.|$|R
