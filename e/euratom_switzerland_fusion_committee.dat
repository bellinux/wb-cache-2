0|48|Public
5000|$|Member, <b>Fusion</b> Visiting <b>Committee,</b> Argonne, National Laboratory ...|$|R
5000|$|Chair, <b>Fusion</b> Advisory <b>Committee,</b> Oak Ridge National Laboratory ...|$|R
5000|$|Member, Inertial <b>Fusion</b> Review <b>Committee,</b> Lawrence Livermore Lab ...|$|R
5000|$|Member, Light Ion <b>Fusion</b> Review <b>Committee,</b> Sandia National Laboratories ...|$|R
50|$|The DFL {{was created}} on April 15, 1944, with {{the merger of}} the Minnesota Democratic Party and the Farmer-Labor Party. Leading the merger effort were Elmer Kelm, {{the head of the}} Minnesota Democratic Party and {{founding}} chairman of the DFL; Elmer Benson, effectively the head of the Farmer-Labor Party by virtue of his leadership of its dominant left-wing faction; and rising star Hubert H. Humphrey, who chaired the <b>Fusion</b> <b>Committee</b> that accomplished the union and then went on to chair its first state convention.|$|R
5000|$|... 1991-1994 Member, USDOE <b>Fusion</b> Energy Advisory <b>Committee</b> (FEAC) ...|$|R
5000|$|... 1911-1944 Joseph M. Price — key {{organizer}} of the <b>Fusion</b> Executive <b>Committee,</b> which in 1913 succeeded in electing John Purroy Mitchel mayor of New York, defeating the Tammany Hall candidate ...|$|R
40|$|This paper {{contains}} {{a method to}} bound the test errors of voting committees with members chosen {{from a pool of}} trained classifiers. There are so many prospective committees that validating them directly does not achieve useful error bounds. Because there are fewer classifiers than prospective committees, it is better to validate the classifiers individually, then use linear programming to infer committee error bounds. We test the method using credit card data. Also, we extend the method to infer bounds for classifiers in general. Key words machine learning, learning theory, <b>fusion,</b> <b>committees,</b> voting, Vapnik-Chervonenkis, linear programming. Computer Science Department, California Institute of Technology 256 - 80, Pasadena, California, 91125 (eric@cs. caltech. edu). 2 1 Introduction Consider the following machine learning problem. There is an unknown booleanvalued target function, and there is a distribution over the input space of the function. For example, the input distribution cou [...] ...|$|R
40|$|In fusion, a {{hypothesis}} function is formed {{by using a}} mixing function to combine the outputs {{of a collection of}} basis functions. We develop a method to bound the out-of-sample error of the hypothesis function. First, uniform error bounds are calculated for the basis functions. Then a linear program is used to infer a bound for the hypothesis function from the basis function bounds. The resulting hypothesis function bound is not based {{on the size of the}} class of prospective hypothesis functions. Instead, the bound is based on the number of basis functions and on similarities between the basis functions and the hypothesis function. Hence, the linear program produces a stronger bound than direct validation when the number of basis functions is small, when the class of prospective hypothesis functions is complex, and when the hypothesis function is similar to the basis functions. Key words machine learning, learning theory, <b>fusion,</b> <b>committees,</b> VapnikChervonenkis, linear programming. Mat [...] ...|$|R
25|$|Meanwhile, the {{moderate}} syndicalist CORA grew in size {{as a result}} of its pragmatic approach, which included participating in negotiations with employers in place of direct action as advocated by the anarchists. Striving for labor unity, the CORA set up a <b>fusion</b> <b>committee</b> with some non-affiliated unions to push for a merger with the FORA. The majority of the FORA agreed, calling for the CORA to abolish itself and enter the FORA. At the April 1915 FORA congress, its ninth, a resolution which reversed its commitment to anarchist communism was passed, paving the way for the CORA unions to join. Only a minority in the FORA rejected this move. After the congress, this minority started a breakaway federation under the name FORA V, referring to the fifth congress, which the resolution for anarcho-communism was passed at. While the FORA IX had somewhere between 100,000 and 120,000 members, the anarchist FORA V had 10,000 at the most, though both figures are considered unreliable. The FORA V was strongest in the interior of the country, where most of the workers were native Argentines.|$|R
40|$|International audienceThe 2007 Data Fusion Contest {{that was}} {{organized}} by the IEEE Geoscience and Remote Sensing Data <b>Fusion</b> Technical <b>Committee</b> was dealing with the extraction of a land use/land cover maps in and around an urban area, exploiting multitemporal and multisource coarse-resolution data sets. In particular, synthetic aperture radar and optical data from satellite sensors were considered. Excellent indicators for mapping accuracy were obtained by the top teams. The best algorithm {{is based on a}} neural classification enhanced by preprocessing and postprocessing steps...|$|R
40|$|The IEEE Data <b>Fusion</b> Technical <b>Committee</b> is {{organizing}} a “Data Fusion Contest” {{in conjunction with}} the IGARS Symposium. For the first issue of the contest, the fusion of multispectral and panchromatic images for optical very high resolution images is considered. A comparative study of the results provided by the participants on common data sets is presented during the conference in the “Data Fusion” session and the “winning” team(s) is (are) granted an IEEE award during the IEEE GRS-S Technical Committee and Chapter Dinner...|$|R
50|$|He {{has been}} a Fellow at the American Physical Society since 2001. In 2010, he was {{appointed}} to the Board of Physics and Astronomy of the National Academy of Sciences. He was Vice Chair of the <b>Fusion</b> Energy Science <b>Committee</b> of the Department of Energy.|$|R
40|$|International audienceThe IEEE Data <b>Fusion</b> Technical <b>Committee</b> is {{organizing}} a “Data Fusion Contest” {{in conjunction with}} the IGARS Symposium. For the first issue of the contest, the fusion of multispectral and panchromatic images for optical very high resolution images is considered. A comparative study of the results provided by the participants on common data sets is presented during the conference in the “Data Fusion” session and the “winning” team(s) is (are) granted an IEEE award during the IEEE GRS-S Technical Committee and Chapter Dinner...|$|R
40|$|International audienceThe 2016 Data Fusion Contest, {{organized}} by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> (IADF TC) of the IEEE Geoscience and Remote Sensing Society (GRSS), aims at providing a challenging image analysis opportunity including multitemporal, multiresolution, and multisensor fusion. The 2016 contest involves two data modalities acquired over the city of Vancouver, Canada (49 ? 15 ?N 123 ? 6 ?W) : a very high-resolution multitemporal sequence and an ultrahigh definition (UHD) video from space acquired from the International Space Station (ISS). The data were acquired and provided by Deimos Imaging and UrtheCast (Figure 1) ...|$|R
40|$|International audienceIn January 2006, the Data <b>Fusion</b> <b>Committee</b> of the IEEE Geoscience and Remote Sensing Society {{launched}} a public contest for pansharpening algorithms, which aimed {{to identify the}} ones that perform best. Seven research groups worldwide participated in the contest, testing eight algorithms following different philosophies [component substitution, multiresolution analysis (MRA), detail injection, etc. ]. Several complete data sets from two different sensors, namely, QuickBird and simulated Pléiades, were delivered to all participants. The fusion results were collected and evaluated, both visually and objectively. Quantitative results of pansharpening were possible owing to the availability of reference originals obtained either by simulating the data collected from the satellite sensor by means of higher resolution data from an airborne platform, {{in the case of}} the Pléiades data, or by first degrading all the available data to a coarser resolution and saving the original as the reference, {{in the case of the}} QuickBird data. The evaluation results were presented during the special session on Data Fusion at the 2006 International Geoscience and Remote Sensing Symposium in Denver, and these are discussed in further detail in this paper. Two algorithms outperform all the others, the visual analysis being confirmed by the quantitative evaluation. These two methods share the same philosophy: they basically rely on MRA and employ adaptive models for the injection of high-pass details...|$|R
40|$|An {{assessment}} of the Office of Fusion Energy Sciences (OFES) program with guidance for future program strategy. The overall objective {{of this study is}} to prepare an independent {{assessment of}} the scientific quality of the Office of Fusion Energy Sciences program at the Department of Energy. The <b>Fusion</b> Science Assessment <b>Committee</b> (FuSAC) has been appointed to conduct this study...|$|R
5000|$|As {{the mayoral}} {{election}} approached in 1913, the Citizens Municipal Committee of 107 {{set out to}} find a candidate that would give New York [...] "a non-partisan, efficient and progressive government." [...] They were assisted in this endeavor by the <b>Fusion</b> Executive <b>Committee,</b> led by Joseph M. Price of the City Club of New York. After nine ballots, Mitchel was nominated as a candidate for mayor. During his campaign, Mitchel focused on making City Hall a place of decency and honesty. He also focused on business as he promised New Yorkers that he would modernize the administrative and financial machinery and the processes of city government.|$|R
40|$|International audienceDATA fusion {{emerged as}} a new topic in the late 1980 s, {{but it was only}} by {{the first half of the}} {{following}} decade that the availability of remotely sensed data in digital form by different sources allowed the consideration of remote-sensing data fusion. At that point, the Data <b>Fusion</b> Technical <b>Committee</b> (DFTC) of the IEEE Geoscience and Remote Sensing Society recognized the need for a Special Issue on the IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING about "data fusion," which was published in May 1999. That pioneering issue brought to the attention of many researchers the need for an increased effort toward the joint exploitation of multiple data or information sources...|$|R
40|$|The 2008 Data Fusion Contest {{organized}} by the IEEE Geoscience and Remote Sensing Data <b>Fusion</b> Technical <b>Committee</b> deals with the classification of high-resolution hyperspectral data from an urban area. Unlike in the previous issues of the contest, the goal was not only to identify the best algorithm but also to provide a collaborative effort: The decision fusion of the best individual algorithms was aiming at further improving the classification performances, and the best algorithms were ranked according to their relative contribution to the decision fusion. This paper presents the five awarded algorithms and the conclusions of the contest, stressing the importance of decision fusion, dimension reduction, and supervised classification methods, such as neural networks and support vector machines...|$|R
40|$|<b>Fusion</b> Technical <b>Committee</b> (DFTC) of the IEEE Geoscience and Remote Sensing Society {{aimed at}} {{investigating}} the synergistic use of hyperspectral andLightDetectionAndRanging (LiDAR) data. The data sets {{distributed to the}} participants during the Contest, a hyperspectral imagery and the corresponding LiDAR-derived dig-ital surfacemodel (DSM), were acquired by the NSF-funded Center for Airborne Laser Mapping over the University of Houston cam-pus and its neighboring area {{in the summer of}} 2012. This paper highlights the two awarded research contributions, which investi-gated different approaches for the fusion of hyperspectral and LiDAR data, including a combined unsupervised and supervised classification scheme, and a graph-based method for the fusion of spectral, spatial, and elevation information. Index Terms—Data fusion, hyperspectral, Light Detection And Ranging (LiDAR), multi-modal, urban, VHR imagery...|$|R
40|$|The 2017 Data Fusion Contest, {{organized}} by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> (IADF TC) of the IEEE Geoscience and Remote Sensing Society (GRSS), aims at providing a challenging image analysis opportunity, including multiresolution and multimodal fusion. The 2017 contest focuses on the classification of local climate zones (LCZs) [1] in various urban environments. LCZs are a generic, climate-based typology of urban and natural landscapes that deliver information on basic physical properties of an area {{that can be used}} by land-use planners or climate modelers [2]. They are used as first-order discretization of urban areas by the World Urban Database and Access Portal Tools (WUDAPT) initiative, which aims to collect, store, and disseminate data on the form and function of cities around the world [3]...|$|R
50|$|Robert Aymar {{has served}} on many Councils and Committees at {{national}} and international level, for example, the Institut Laue Langevin (ILL), the European Synchrotron Research Facility (ESRF), and the Joint European Torus (JET). He also acted {{as chairman of the}} European <b>Fusion</b> Technology Steering <b>Committee,</b> and {{as a member of the}} ITER (International Thermonuclear Experimental Reactor) Technical Advisory Committee. He was appointed ITER Director in 1994 and International Team Leader in 2001.|$|R
40|$|International audienceThe 2009 - 2010 Data Fusion Contest {{organized}} by the Data <b>Fusion</b> Technical <b>Committee</b> of the IEEE Geoscience and Remote Sensing Society {{was focused on the}} detection of ﬂooded areas using multi-temporal and multi-modal images. Both high spatial resolution optical and synthetic aperture radar data were provided. The goal was not only to identify the best algorithms (in terms of accuracy), but also to investigate the further improvement derived from decision fusion. This paper presents the four awarded algorithms and the conclusions of the contest, investigating both supervised and unsupervised methods and the use of multi-modal data for ﬂood detection. Interestingly, a simple unsupervised change detection method provided similar accuracy as supervised approaches, and a digital elevation model-based predictive method yielded a comparable projected change detection map without using post-event data...|$|R
40|$|This paper {{reports the}} {{outcomes}} of the 2014 Data Fusion Contest organized by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> (IADF TC) of the IEEE Geoscience and Remote Sensing Society (IEEE GRSS). As for previous years, the IADF TC organized a data fusion contest aiming at fostering new ideas and solutions for multisource remote sensing studies. In the 2014 edition, participants considered multiresolution and multisensor fusion between optical data acquired at 20 -cm resolution and long-wave (thermal) infrared hyperspectral data at 1 -m resolution. The Contest was proposed as a double-track competition: one aiming at accurate landcover classification and the other seeking innovation in the fusion of thermal hyperspectral and color data. In this paper, the results obtained by the winners of both tracks are presented and discussed...|$|R
40|$|The 2009 - 2010 Data Fusion Contest {{organized}} by the Data <b>Fusion</b> Technical <b>Committee</b> of the IEEE Geoscience and Remote Sensing Society {{was focused on the}} detection of flooded areas using multi-temporal and multi-modal images. Both high spatial resolution optical and synthetic aperture radar data were provided. The goal was not only to identify the best algorithms (in terms of accuracy), but also to investigate the further improvement derived from decision fusion. This paper presents the four awarded algorithms and the conclusions of the contest, investigating both supervised and unsupervised methods and the use of multi-modal data for flood detection. Interestingly, a simple unsupervised change detection method provided similar accuracy as supervised approaches, and a digital elevation model-based predictive method yielded a comparable projected change detection map without using post-event data...|$|R
25|$|In 1980, Conn left Wisconsin to {{join the}} University of California, Los Angeles (UCLA), where he {{continued}} research in plasma physics and nuclear fusion, {{as well as in}} materials science and energy policy. While at UCLA Conn led the establishment in 1986 of the Institute of Plasma and Fusion Research, and served as its founding director. It was during this time that Conn began more extensively to advise the federal government on fusion energy, specifically for the United States House Committee on Science, Space and Technology and the Department of Energy’s Magnetic <b>Fusion</b> Advisory <b>Committee,</b> among other governmental bodies. At UCLA Conn and his colleague, Farrokh Najmabadi, directed a national U.S. Department of Energy program known as ARIES, which prepared conceptual designs of possible fusion energy power plants. Conn also {{played a key role in}} the creation of PISCES, a laboratory research facility located first at UCLA and today at UC San Diego. The lab studies what happens when very high temperature plasma comes into contact with the material world, such as plasma chamber walls, as would occur inside a magnetic fusion reactor. Conn further led the formation of a multi-lateral experiment program, the Advanced Limiter Test or ALT program, that studied plasma as it interacts with components inside a tokamak fusion experiment, in this case the former TEXTOR tokamak machine at Germany’s largest national laboratory, the Forschungszentrum Jülich. The countries participating included Germany, Japan, Belgium, and the United States. In 1991, Conn became chair of the newly formed <b>Fusion</b> Energy Advisory <b>Committee</b> (FEAC) at the U.S. Department of Energy.|$|R
40|$|International audiencePansharpening may be deﬁned as {{the process}} of synthesizing {{multispectral}} images at a higher spatial resolution. A wide range of pansharpening methods are available, each producing images with different characteristics. To compare the performances and characteristics of different methods, a contest was held in 2006 by the IEEE Data <b>Fusion</b> Technical <b>Committee.</b> In this contest, À trous wavelet transform-based pansharpening (AWLP) and Laplacian pyramid-based context adaptive (CBD) pansharpening methods were declared as joint winners. While assessing the quantitative quality of the pansharpened images, we observed that the two methods outperform each other depending upon the local content of the scene. Hence, {{it is interesting to}} design a method taking advantage of both methods by locally selecting the best one. This adaptive decision fusion is performed based on the local scale of the structure. The interest of the proposed method is veriﬁed using both visual and quantitative analyses for different Pléiades data sets...|$|R
40|$|Abstract—Pansharpening may {{be defined}} as the process of synthesizing {{multispectral}} images at a higher spatial resolution. A wide range of pansharpening methods are available, each producing images with different characteristics. To compare the performances and characteristics of different methods, a contest was held in 2006 by the IEEE Data <b>Fusion</b> Technical <b>Committee.</b> In this contest, À trous wavelet transform-based pansharpening (AWLP) and Laplacian pyramid-based context adaptive (CBD) pansharpening methods were declared as joint winners. While assessing the quantitative quality of the pansharpened images, we observed that the two methods outperform each other depending upon the local content of the scene. Hence, it is interesting to design a method taking advantage of both methods by locally selecting the best one. This adaptive decision fusion is performed based on the local scale of the structure. The interest of the proposed method is verified using both visual and quantitative analyses for different Pléiades data sets. Index Terms—Image fusion, remote sensing. I...|$|R
40|$|In this paper, {{we report}} the {{outcomes}} of the 2015 data fusion contest organized by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> (IADF TC) of the IEEE Geoscience and Remote Sensing Society. As for previous years, the IADF TC organized a data fusion contest aiming at fostering new ideas and solutions for multisource studies. The 2015 edition of the contest proposed a multiresolution and multisensorial challenge involving extremely high resolution RGB images (with a ground sample distance of 5  cm) and a 3 -D {{light detection and ranging}} point cloud (with a point cloud density of approximately 65 pts/m 2). The competition was framed in two parallel tracks, considering 2 -D and 3 -D products, respectively. In this Part B, we report the results obtained by the winners of the 3 -D contest, which explored challenging tasks of road extraction and ISO containers identification, respectively. The 2 -D part of the contest and a detailed presentation of the dataset are discussed in Part A...|$|R
40|$|The 2012 Data Fusion Contest {{organized}} by the Data <b>Fusion</b> Technical <b>Committee</b> (DFTC) of the IEEE Geoscience and Remote Sensing Society (GRSS) aimed at investigating the potential use of very high spatial resolution (VHR) multi-modal/multi-temporal image fusion. Three different types of data sets, including spaceborne multi-spectral, spaceborne synthetic aperture radar (SAR), and airborne {{light detection and ranging}} (LiDAR) data collected over the downtown San Francisco area were distributed during the Contest. This paper highlights the three awarded research contributions which investigate (i) a new metric to assess urban density (UD) from multi-spectral and LiDAR data, (ii) simulation-based techniques to jointly use SAR and LiDAR data for image interpretation and change detection, and (iii) radiosity methods to improve surface reflectance retrievals of optical data in complex illumination environments. In particular, they demonstrate the usefulness of LiDAR data when fused with optical or SAR data. We believe these interesting investigations will stimulate further research in the related areas...|$|R
40|$|International audienceIn this paper, the {{scientific}} {{outcomes of the}} 2016 Data Fusion Contest organized by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> of the IEEE Geoscience and Remote Sensing Society are discussed. The 2016 Contest was an open topic competition based on a multitemporal and multimodal dataset, which included a temporal pair of very high resolution panchromatic and multispectral Deimos- 2 images and a video captured by the Iris camera on-board the International Space Station. The problems addressed and the techniques proposed by the participants to the Contest spanned across a rather broad range of topics, and mixed ideas and methodologies from the remote sensing, video processing, and computer vision. In particular, the winning team developed a deep learning method to jointly address spatial scene labeling and temporal activity modeling using the available image and video data. The second place team proposed a random field model to simultaneously perform coregistration of multitemporal data, semantic segmentation, and change detection. The methodological key ideas of both these approaches and the main results of the corresponding experimental validation are discussed in this paper...|$|R
40|$|International audienceIn this paper, {{we discuss}} the {{scientific}} outcomes of the 2015 data fusion contest organized by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> (IADF TC) of the IEEE Geoscience and Remote Sensing Society (IEEE GRSS). As for previous years, the IADF TC organized a data fusion contest aiming at fostering new ideas and solutions for multisource studies. The 2015 edition of the contest proposed a multiresolution and multisensorial challenge involving extremely high-resolution RGB images and a three-dimensional (3 -D) LiDAR point cloud. The competition was framed in two parallel tracks, considering 2 -D and 3 -D products, respectively. In this paper, {{we discuss the}} scientific results obtained by {{the winners of the}} 2 -D contest, which studied either the complementarity of RGB and LiDAR with deep neural networks (winning team) or provided a comprehensive benchmarking evaluation of new classification strategies for extremely high-resolution multimodal data (runner-up team). The data and the previously undisclosed ground truth will remain available for the community and can be obtained at [URL] The 3 -D part of the contest is discussed in the Part-B paper [1]...|$|R
40|$|In this paper, the {{scientific}} {{outcomes of the}} 2016 Data Fusion Contest organized by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> of the IEEE Geoscience and Remote Sensing Society are discussed. The 2016 Contest was an open topic competition based on a multitemporal and multimodal dataset, which included a temporal pair of very high resolution panchromatic and multispectral Deimos- 2 images and a video captured by the Iris camera on-board the International Space Station. The problems addressed and the techniques proposed by the participants to the Contest spanned across a rather broad range of topics, and mixed ideas and methodologies from the remote sensing, video processing, and computer vision. In particular, the winning team developed a deep learning method to jointly address spatial scene labeling and temporal activity modeling using the available image and video data. The second place team proposed a random field model to simultaneously perform coregistration of multitemporal data, semantic segmentation, and change detection. The methodological key ideas of both these approaches and the main results of the corresponding experimental validation are discussed in this paper...|$|R
40|$|In this paper, {{we discuss}} the {{scientific}} outcomes of the 2015 data fusion contest organized by the Image Analysis and Data <b>Fusion</b> Technical <b>Committee</b> (IADF TC) of the IEEE Geoscience and Remote Sensing Society (IEEE GRSS). As for previous years, the IADF TC organized a data fusion contest aiming at fostering new ideas and solutions for multisource studies. The 2015 edition of the contest proposed a multiresolution and multisensorial challenge involving extremely high-resolution RGB images and a three-dimensional (3 -D) LiDAR point cloud. The competition was framed in two parallel tracks, considering 2 -D and 3 -D products, respectively. In this paper, {{we discuss the}} scientific results obtained by {{the winners of the}} 2 -D contest, which studied either the complementarity of RGB and LiDAR with deep neural networks (winning team) or provided a comprehensive benchmarking evaluation of new classification strategies for extremely high-resolution multimodal data (runner-up team). The data and the previously undisclosed ground truth will remain available for the community and can be obtained at [URL] The 3 -D part of the contest is discussed in the Part-B paper [1]...|$|R
40|$|We {{examined}} the dependency of the pixel reflectance of hyperspectral imaging spectrometer data (HISD) on a normalized total insolation index (NTII). The NTII was estimated using a {{light detection and ranging}} (LiDAR) -derived digital surface model (DSM). The NTII and the pixel reflectance were dependent, to various degrees, on the band considered, {{and on the}} properties of the objects. The findings could be used to improve land cover (LC) /land use (LU) classification, using indices constructed from the spectral bands of imaging spectrometer data (ISD). To study this possibility, we investigated the normalized difference vegetation index (NDVI) at various NTII levels. The results also suggest that the dependency of the pixel reflectance and NTII could be used to mitigate the shadows in ISD. This project was carried out using data provided by the Hyperspectral Image Analysis Group and the NSF-funded Centre for Airborne Laser Mapping (NCALM), University of Houston, for the purpose of organizing the 2013 Data Fusion Contest (IEEE 2014). This contest was organized by the IEEE GRSS Data <b>Fusion</b> Technical <b>Committee...</b>|$|R
