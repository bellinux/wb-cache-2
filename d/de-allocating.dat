10|37|Public
5000|$|Easy scaling management. Scaling out is just {{a matter}} of {{deploying}} new servers and then propagating a new configuration to all of the nodes. The data will automatically and optimally be moved to accommodate the new resources. <b>De-allocating</b> resources is basically the same process in reverse. Simply deploy the new configuration and the data will be moved off the old resources automatically.After the data has been moved, simply take the old resources off line.|$|E
5000|$|SWT widgets, unlike {{almost any}} other Java toolkit, {{requires}} manual object deallocation, {{in contrast to the}} standard Java practice of automatic garbage collection. SWT objects must be explicitly deallocated using the [...] method, which is analogous to the C language's [...] [...] If this is not done, memory leaks or other unintended behavior may result. On this matter, some have commented that [...] "explicitly <b>de-allocating</b> the resources could be a step back in development time (and costs) at least for the average Java developer" [...] and that [...] "this is a mixed blessing. It means more control (and more complexity) for the SWT developer instead of more automation (and slowness) when using Swing." [...] The need for manual object deallocation when using SWT is largely due to SWT's use of native objects. These objects are not tracked by the Java JVM, so it cannot track whether or not such objects are in use, and thus cannot garbage collect them at a suitable time.|$|E
40|$|Abstract {{data types}} {{developed}} for computational {{science and engineering}} are frequently modeled after physical objects whose state variables must satisfy governing differential equations. Generalizing the associated algebraic and differential operators to operate on the abstract data types facilitates high-level program constructs that mimic standard mathematical notation. For non-trivial expressions, multiple object instantiations must occur to hold intermediate results during the expression's evaluation. When the dimension of each object's state space is not specified at compile-time, the programmer becomes responsible for dynamically allocating and <b>de-allocating</b> memory for each instantiation. With the advent of allocatable components in Fortran 2003 derived types, the potential exists for these intermediate results to occupy a substantial fraction of a program's footprint in memory. This issue becomes particularly acute {{at the highest levels}} of abstraction where coarse-grained data structures predominate. This paper proposes a set of rules for <b>de-allocating</b> memory that has been dynamically allocated for intermediate results in derived type calculus, while distinguishing that memory from more persistent objects. The new rules are applied to the design of a polymorphic time integrator for integrating evolution equations governing dynamical systems. Associated issues of efficiency and design robustness are discussed...|$|E
50|$|A {{multiprogramming}} or multitasking OS is {{a system}} executing many processes concurrently. Multiprogramming requires that the processor be allocated to each process {{for a period of}} time and <b>de-allocated</b> at an appropriate moment. If the processor is <b>de-allocated</b> during the execution of a process, it must be done in such a way that it can be restarted later as easily as possible.|$|R
50|$|Out of {{the above}} 216 blocks, 24 blocks were <b>de-allocated</b> (three blocks in 2003, two blocks in 2006, one block in 2008, one block in 2009, three blocks in 2010, and 14 blocks in 2011) for {{non-performance}} of production by the allocatees, and two <b>de-allocated</b> blocks were subsequently reallocated (2003 and 2005) to others. Hence, 194 coal blocks, with aggregates geological reserves of 44.44 billion metric tons, stood allocated as at 31 March 2011.Source: Draft CAG Report, Table 5.1.|$|R
50|$|Cloud BUR enables {{flexible}} {{allocation of}} storage capacity to customers without limit. Storage is allocated on demand and also <b>de-allocated</b> as customers delete backup sets as they age.|$|R
40|$|Identity {{management}} {{is the concept}} of centralizing the control of resource provisioning and system access. Leveraging human resources software, corporate directories, and centralized servers, it provides large enterprises with Key the means fingerprint to initiate = AF 19 workflow FA 27 2 F 94 for 998 D automatically FDB 5 DE 3 D allocating F 8 B 5 06 E 4 and A 169 <b>de-allocating</b> 4 E 46 physical and computing resources to users. Poor or no identity management can open many security holes and this class of software, combined with effective policy, promises to counter these vulnerabilities. Some software solutions cover all areas of identity management while others only address a specific concern. This document aims to provide a guide to the various ways it can be implemented and show how identity management can lead to improved security...|$|E
40|$|Since the {{introduction}} of memory management technique in contemporary operating system, much advancement {{has been made in}} terms of application development. As good as these advancements may sound, many drawbacks soon follows. Many contemporary operating systems offers the flexibility of explicitly allocating and <b>de-allocating</b> memory on the heap using user-level functions such as malloc, calloc and free. Creating objects on the heap is easy, getting rid of them is hard. Explicit reclamation of heap allocated objects imposes a serious burden on the programmer and eventually leads to memory leaks and dangling references. Here we will {{take a look at a}} mechanism employed by most modern programming language to automate the reclamation of these heap allocated objects. We will mainly talk about two distinct technique; reference counting and mark and sweep. One is not better that the other, but simply a necessity in order for garbage collection to work...|$|E
40|$|Abstract. Constructing a Master Air Attack plan {{requires}} the negotiations of many constraints. Typical of these constraints are {{limitations on the}} munitions that can be delivered to each target, limitations on the platforms that can carry the munitions, as well as limitations {{on the availability of}} the platforms from a specified unit. A schedule needs to be constructed that respects the unit contracts, the planner enforced attack waves, and the packaging preferences. In the process, we seek to maximize the targets that can be attained with available resources subject to the priorities of the targets. The initialization of the genetic algorithm is accomplished by randomized greedy operations that quickly find local minima in the solution space. These greedy algorithms are implemented as genetic operators and are used not only to initialize the chromosomes with valid solutions but also to “finish off ” the good solutions that result from the genetic algorithm to ensure that any remaining resources are used and that the solution can only be improved by <b>de-allocating</b> some subset of the existing solution...|$|E
50|$|Meanwhile, Jindal Steel and Power Ltd (JSPL) {{intends to}} appeal in court against the {{government}} decision to <b>de-allocate</b> the coal block allocated to it, a company source said.|$|R
5000|$|Each Oracle {{instance}} allocates {{itself an}} SGA {{when it starts}} and <b>de-allocates</b> it at shut-down time. The information in the SGA consists of the following elements, {{each of which has}} a fixed size, established at instance startup: ...|$|R
3000|$|... in Step 1.1 {{satisfy the}} {{targeted}} data rates and G 2, {{the set of}} users for who the solutions does not provide the data rate. Thus, some resource blocks are <b>de-allocated</b> from users in G 1 and allocated to G 2.|$|R
40|$|Mobile e-health {{applications}} provide {{users and}} healthcare practitioners with an insightful way to check users/patients’ status and monitor their daily calorie intake. Mobile e-health applications provide users and healthcare practitioners with an insightful way to check users/patients’ status and monitor their daily activities. This paper proposes a cloud-based mobile e-health calorie {{system that can}} classify food objects in the plate and further compute the overall calorie of each food object with high accuracy. The novelty in our system {{is that we are}} not only offloading heavy computational functions of the system to the cloud, but also employing an intelligent cloud-broker mechanism to strategically and efficiently utilize cloud instances to provide accurate and improved time response results. The broker system uses a dynamic cloud allocation mechanism that takes decisions on allocating and <b>de-allocating</b> cloud instances in real-time for ensuring the average response time stays within a predefined threshold. In this paper, we further demonstrate various scenarios to explain the workflow of the cloud components including: segmentation, deep learning, indexing food images, decision making algorithms, calorie computation, scheduling management as part of the proposed cloud broker model. The implementation results of our system showed that the proposed cloud broker results in a 45 % gain in the overall time taken to process the images in the cloud. With the use of dynamic cloud allocation mechanism, we were able to reduce the average time consumption by 77. 21 % when 60 images were processed in parallel...|$|E
40|$|In {{real-time}} systems it is {{of paramount}} importance that time constraints of tasks are enforced. A tremendous amount of research has been carried out on scheduling problems associated with such systems, primarily focusing on priority assignment policies in non-overloaded systems. While static real-time systems, by definition, do not suffer from overloads, they offer limited or no flexibility and ability to adapt to new situations, often making them a poor choice for complex real-time applications. While dynamic real-time systems often meet these demands, they are prone to transient overloads. In this paper we introduce a novel scheduling architecture with a new algorithm for dynamically resolving transient overloads, that is executed when a new transaction cannot be admitted to the system due to scarce resources. The resolver algorithm generates a cost effective overload resolution plan which, in order to admit the new transaction, finds the required time by <b>de-allocating</b> time among the previously admitted but not yet completed transactions. Considering the cost efficiency of executing the plan and the importance of the new transaction, a decision is made whether to execute the plan and admit the new transaction, or to reject it. the new transaction. We consider a multi-class transaction workload consisting of hard critical and firm transactions, where critical transactions have contingency transactions that can be invoked during overloads. We present a thorough performance analysis showing to what degree the overload resolver enforces predictability and ensures the timeliness of critical transactions when handling extreme overload scenarios in real-time database systems...|$|E
40|$|Caching {{is one of}} the {{important}} concept used for optimizing the performance gap across data hierarchies; in particular, disk storage systems. Cloud applications are generally resource hungry and may consist of high frequency of occasional resource consumption, which are common in the cloud; do benefit the most from caching. There are many levels of cache but the using local memory as cache might be a good alternative, this memory can be taken from main memory of the system or secondary storage with many well-known restrictions and effective use. There are many technical as well as business challenges such as meeting the service offering and billing accurately. Here it presents the cache as a service (CaaS) system as an additional service by cloud infrastructure service providers as one of their service to their existing consumers. CaaS alone may not be possible to avail as the consumer needs to have a Virtual machine or physical machine with the provider. The cloud infrastructure provider creates a cluster of memory resources {{in such a way that}} these collective resources can be divided on demand to the right consumer and can be offered on demand to them. This disk cache system need to have security while allocating memory blocks as well as while <b>de-allocating</b> them. CaaS model is proposed to leverage existing resources which can be idle or kept as redundancy and offer them as a service to the consumer with small overhead yet high performance improvement. This will not only increase the performance of the client but will also help service provider to use his idle capacity and offer better utilization...|$|E
5000|$|TScript {{uses the}} {{standard}} C++ class encapsulation to allocate and <b>de-allocate</b> memory resources. This {{means that all}} allocated memory is released when the variable containing it is destroyed and operated differently from the Garbage Collection model of Java or the reference counting model of [...]NET languages.|$|R
5000|$|Azure Data Lake Analytics is a {{parallel}} on-demand job service. The parallel processing system {{is based on}} the Microsoft Dryad solution. [...] Dryad can represent arbitrary Directed Acyclic Graphs (DAGs) of computation. [...] Data Lake Analytics provides a distributed infrastructure that can dynamically allocate or <b>de-allocate</b> resources so customers pay for only the services they use.|$|R
3000|$|... [*]Improved Focus on Core Business:[*]The {{outsourcing}} {{of certain}} systems according to SaaS (or SECaaS) <b>de-allocates</b> internal resources [11, 25]. These resources can be (re-)allocated to an organization’s core business, which might increase overall performance [15, 25] - assuming that IT security {{is not the}} core competency. Hence, this {{is also one of}} the major drivers for IT security outsourcing in general [38].|$|R
40|$|In {{this paper}} {{we present a}} new {{parallel}} multi-frontal direct solver, dedicated for hp Finite Element Method (hp-FEM). The self-adaptive hp FEM generates in a fully automatic mode a sequence of hp meshes delivering exponential convergence of the error {{with respect to the}} number of degrees of freedom (d. o. f.) as well as the CPU time, by performing a sequence of hp refinements starting from an arbitrary initial mesh. The solver constructs initial elimination tree for an arbitrary initial mesh, and expands the elimination tree each time the mesh is refined. This allows {{to keep track of the}} order of elimination for the solver. The solver also minimizes the memory usage, by <b>de-allocating</b> partial LU factorizations computed during the elimination stage of the solver, and recomputes them for the backward substitution stage, by utilizing only about 10 % of the computational time necessary for the original computations. The solver has been tested on 3 D Direct Current (DC) borehole resistivity measurement simulations problems. We measure the execution time and memory usage of the solver over large regular mesh with 1. 5 million degrees of freedom as well as on the highly non-regular mesh, generated by the self-adaptive hp-FEM, with finite elements of various size and polynomial orders of approxi-mation varying from p = 1 to p = 9. From the presented experiments it follows that the parallel solver scales well up to the maximum number of utilized processors. The limit for the solver scalability is the maximum sequential part of the algorithm: the computations of the partial LU factorizatons over the longest path, comming from the root of the elimination tree down to the deepest leaf...|$|E
40|$|General Packet Radio Service (GPRS) [1], {{initiated}} in 1994, is an ETSI standard for packet data transmission using the core GSM (Global System for Mobile Communications) radio access network. GPRS shares the GSM frequency bands with telephone and circuit-switched data traffic, and {{makes use of}} many properties of the physical layer of the original GSM system. Since radio resources of a cell are shared by both the GPRS and GSM voice services, how to efficiently allocate radio resources between these two services {{and at the same}} time not degrading the QOS of voice service is an important issue. Guard channels can be temporarily allocated to GPRS connections to improve channel utilization. As voice traffic load increases, the channels of some ongoing GPRS connections are <b>de-allocated</b> to arriving voice calls. The de-allocation must still maintain the minimum required QOS of the <b>de-allocated</b> connections. Simulation results show that at low voice traffic load, there is no need to apply admission control to GPRS connections. At high voice traffic load, the call admission control guarantees the blocking probability of new and handoff calls to be below certain value. But this will result in high GPRS rejection and low channel utilization. To guarantee the QOS of voice service not to be affected by the introduction of GPRS...|$|R
5000|$|The coal {{ministry}} on Thursday {{decided to}} <b>de-allocate</b> 11 captive coal blocks including three mines of Jindal Steel and Power, besides forfeiting the bank guarantees of six firms and asking five to expressly furnish bank guarantees. The ministry has been facing intense flak over alleged irregularities in allocation of coal blocks since 1993 and the Central Bureau of Investigation (CBI) is currently investigating the abnormalities and criminal conspiracy in their allotment. The agency has filed 14 FIRs and two preliminary enquiries {{so far in}} this connection. In this backdrop, an inter-ministerial group (IMG) of the coal ministry met on 24 October to consider the fate of 30 coal blocks, including those being investigated by the CBI. Of the mines recommended for de-allocation, two blocks - Amarkonda Murgadangal and Ramchandi Promotional (coal-to-liquid mine) belongs to Naveen Jindal-promoted JSPL and the Urtan North block also allocated to JSPL along with Monnet Ispat & Energy [...] All allottees had been issued show-cause notices {{and were asked to}} furnish their views to the IMG. The decisions have been taken after careful consideration, a top coal ministry official told The Indian Express. Coal minister Sriprakash Jaiswal is learnt to have approved the recommendations of the IMG. Another coal-to-liquid block - North of Akrapal allocated to the Strategic Energy tech System Limited, which is a joint venture between the Tata group and South African firm Sasol has also been <b>de-allocated.</b> The Radhikapur (West) block allocated jointly to Rungta Mines, OCL India and Ocean Ispat, Bikram mine allotted to Birla Corporation, Khappa and Extension block allocated to Sunflag Iron and Steel and Dalmia Cement have been cancelled. The ministry has decided to <b>de-allocate</b> the Rajgamar Dipside (South of Pulakdih Nala) coal block jointly allotted to Monnet Ispat and Energy Ltd among others. With the fresh round of de-allocation, the total number of blocks cancelled stands at 51 as the government had earlier <b>de-allocated</b> 40 blocks. The ministry is preparing to inform the companies impacted by the decision. As per the IMG's recommendations steel maker SAIL is among the five companies to lose bank guarantees for delay in developing allotted blocks. Other firms include Abhijeet Infrastructure, Andhra Pradesh Mineral Development Corporation, Tenughat Vidyut Nigam and Chaman Metaliks. DE-ALLOCATED BLOCKS - COMPANIES COAL BLOCKS STATE Jindal Steel and Power Amarkonda Murgadangal Jharkhand, Jindal Steel and Power Ramchandi Promotional Block(CTL) Orissa [...]Jindal Steel and Power & Urtan North Madhya Pradesh, Monnet Ispat and Energy [...]Rungta Mines, OCL India Radhikapur (West) Orissa and Ocean Ispat, Strategic Energy tech System North of Akrapal (CTL) Orissa Ltd (A Tata-Sasol JV company), Birla Corporation Bikram Madhya Pradesh [...]Sunflag Iron and Steel Khappa & Extension Maharashtra & Dalmia Cement Monnet Ispat and Energy Rajagamar Dipside Chhattisgarh & Shri Virangana Steels Ltd, Rathi Udyog Limited Kesla North Chhattisgarh, Castron Brahmdiha Jharkhand, Maharashtra State Mining Corp Warora Maharashtra [...]|$|R
25|$|Vdevs can be {{manipulated}} while in active use. A single disk can have additional devices added to create a mirrored vdev, and a mirrored vdev can have physical devices added or removed to leave a larger or smaller number of mirrored devices, or a single device. A RaidZ vdev cannot be converted to or from a mirror, although additional vdevs can always be added to expand storage capacity (which can be any kind including RaidZ). A device in any vdev can be marked for removal, and ZFS will <b>de-allocate</b> data from it {{to allow it to}} be removed or replaced.|$|R
40|$|We {{present a}} {{translation}} scheme for the polymorphically typed call-by-value -calculus. All runtime values, including function closures, {{are put into}} regions. The store consists of a stack of regions. Region inference and effect inference are used to infer where regions can be allocated and <b>de-allocated.</b> Recursive functions are handled using a limited form of polymorphic recursion. The translation is proved correct {{with respect to a}} store semantics, which models a regionbased run-time system. Experimental results suggest that regions tend to be small, that region allocation is frequent and that overall memory demands are usually modest, even without garbage collection...|$|R
50|$|Vdevs can be {{manipulated}} while in active use. A single disk can have additional devices added to create a mirrored vdev, and a mirrored vdev can have physical devices added or removed to leave a larger or smaller number of mirrored devices, or a single device. A RaidZ vdev cannot be converted to or from a mirror, although additional vdevs can always be added to expand storage capacity (which can be any kind including RaidZ). A device in any vdev can be marked for removal, and ZFS will <b>de-allocate</b> data from it {{to allow it to}} be removed or replaced.|$|R
5000|$|In general terms, the {{operation}} of the system as it appears to the client application is very similar to working with a normal monolithic kernel. Although the results passed back might come from a third party handler, this was essentially invisible to the client. Servers handling these requests operated in a similar fashion to the clients, opening connections with the kernel to pass data. However, servers generally spawned new threads as required to handle longer-lasting requests. When these were handled and the responses posted, the thread could be <b>de-allocated</b> and the servers could go into a [...] "receive mode" [...] awaiting further requests.|$|R
5000|$|For most file systems, {{a program}} terminates {{access to a}} file in a {{filesystem}} using the close system call. This flushes buffers, updates file metadata (which may include and end of file indicator in the data), <b>de-allocates</b> resources associated with the file (including the file descriptor) and updates the system wide table of files in use. Some languages maintain a structure of files opened by its run-time library and may close when the program terminates. Some operating systems will invoke the close if the program terminates. Some operating systems will invoke the close {{as part of an}} operating system recovery {{as a result of a}} system failure.|$|R
40|$|Abstract—In this letter, we {{analyzed}} and compared {{the performance of}} dynamic resource allocation with/without channel de-allocation in GSM/GPRS networks. It is quite known that dynamic resource allocation allows communication systems to utilize their resources more efficiently than the traditional fixed allocation schemes. In GPRS, multiple channels may be allocated to a user to increase the transmission rate. In the case {{when there are no}} free channels in the system, some of these channels may be <b>de-allocated</b> to serve higher priority calls. The results show that with channel de-allocation mechanism, the voice blocking probability can be greatly reduced, especially at high GPRS traffic load. Besides, the scheme with channel de-allocation mechanism can achieve higher channel utilization. Index Terms—Channel de-allocation, dynamic resource allocation, GPRS...|$|R
40|$|Systems (CAPS) at Florida State University. CAPS is {{attempting}} reconfigure the shipboard power system without human intervention and without centralized scheduling and planning. CAPS has had success with radial plants. The CAPS {{solution is to}} use an agent to represent and exert high-level control on each critical system component. By summarizing the power budget and cost, the resource can be reserved, <b>de-allocated</b> and redistributed without the scheduling of a central entity. The agent in the system only communicates with its immediate neighbor, reducing the dependency between the reconfiguration algorithm and system topology. The behaviors for this agent network are described in detail. The deadlock avoidance and adequacy of the solution are also discussed. Key-words – Intelligent agents, multi-agent system, electric ship, shipboard power system. 1...|$|R
40|$|Region {{inference}} is {{a program}} analysis which statically determines regions of memory in which values are stored. Regions are allocated and <b>de-allocated</b> according to a stack discipline. Region inference is an attractive alternative to dynamic memory management via garbage collection {{for the implementation of}} mission-critical applications, of inter-operating system components, of certiable software. In the aim of putting region-based memory management to work for the design and implementation of real-time system software, the goal of the present article is to consolidate present knowledge on region-based memory management by giving a simplied account of region inference. We achieve this goal by giving an inductive proof of correctness for region inference w. r. t. a small step operational semantics and by dening a sound, fixed-point iterative, inference algorithm...|$|R
30|$|The biggest {{downside}} of variable pricing models is unpredictability. If the price spikes {{at some time}} in the future, the allocation may have to drop even though the demand is the same to avoid breaking the budget. Exactly how much budget to allocate to resources depends on the predictability of the prices, i.e. the demand. If the demand is flat over time, very little excess budget has to be put aside to cope with situations where resources are critically needed and demand and prices are high. On the other hand, if some application is not elastic enough to handle resource variation, e.g. nodes being <b>de-allocated</b> because the price is too high, a higher budget may need to be allocated to make sure the application runs at some minimal level of allocation.|$|R
40|$|Inclusive last-level caches (LLCs) waste {{precious}} silicon estate due to cross-level {{replication of}} cache blocks. As the industry moves toward cache hierarchies with larger inner levels, this wasted cache space leads to bigger performance losses compared to exclusive LLCs. However, exclusive LLCs make {{the design of}} replacement policies more challenging. While in an inclusive LLC a block can gather a filtered access history, this is not possible in an exclusive design because the block is <b>de-allocated</b> from the LLC on a hit. As a result, the popular least-recently-used replacement policy and its approximations are rendered ineffective and proper choice of insertion ages of cache blocks becomes even more important in exclusive designs. On the other hand, {{it is not necessary to}} fill every block into an exclusive LLC. This is known a...|$|R
40|$|This thesis {{presents}} {{a framework for}} using explicit memory management to improve the communication performance of Java TM cluster applications. The framework allows programmers to explicitly manage Java communication buffers, called jbufs, which are directly accessed by the DMA engines of high-performance network interfaces and by Java programs as primitive-typed ar-rays. The central idea is to remove the hard separation between Java’s gar-bage-collected heap and the non-collected memory region in which DMA buffers must normally be allocated. The programmer controls when a jbuf {{is part of the}} garbage-collected heap so that the garbage collector can ensure it is safely re-used or <b>de-allocated,</b> and when it is not so it can be used for DMA transfers. Unlike other techniques, jbufs preserve Java’s storage- and type-safety and do not depend on a particular garbage collection scheme. The safety, efficiency, and programmability of jbufs are demonstrated throughout this thesis with implementations of an interface to the Virtual In...|$|R
40|$|International audienceWe {{show that}} the typed region {{calculus}} of Tofte and Talpin can be encoded in a typed π-calculus equipped with name groups and a novel effect analysis. In the region calculus, each boxed value has a statically determined region {{in which it is}} stored. Regions are allocated and <b>de-allocated</b> according to a stack discipline, thus improving memory management. The idea of name groups arose in the typed ambient calculus of Cardelli, Ghelli, and Gordon. There, and in our π-calculus, each name has a statically determined group to which it belongs. Groups allow for type-checking of certain mobility properties, as well as effect analyses. Our encoding makes precise the intuitive correspondence between regions and groups. We propose a new formulation of the type preservation property of the region calculus, which avoids Tofte and Talpin’s rather elaborate co-inductive formulation. We prove the encoding preserves the static and dynamic semantics of the region calculus. Our proof of the correctness of region de-allocation shows it to be a specific instance of a general garbage collection principle for the π-calculus with effects...|$|R
40|$|For garbage-collected applications, dynamically-allocated {{objects are}} {{contained}} in a heap. Programmer productivity improves significantly {{if there is a}} garbage collector to automatically <b>de-allocate</b> objects that are no longer needed by the applications. However, there is a run-time performance overhead in garbage collection, and this cost is sensitive to heap size H: a smaller H will trigger more collection, but a large H can cause page faults, as when H exceeds the size M of main memory allocated to the application. This paper presents a Heap Sizing Rule for how H should vary with M. The Rule can help an application trade less page faults for more garbage collection, thus reducing execution time. It is based on a heap-aware Page Fault Equation that models how the number of page faults depends on H and M. Experiments show that this rule outperforms the default policy used by JikesRVM’s heap size manager. Specifically, the number of faults and the execution time are reduced for both static and dynamically changing M. 1...|$|R
5000|$|Sources in the Coal Ministry {{said the}} IMG {{has sent a}} note to the Ministry recommending de-allocation of 11 coal blocks of {{companies}} including JSPL, Monnet Ispat and Energy Ltd and either imposition or deduction of bank guarantee in another 19 cases. A large of allottees of these blocks were issued show cause notices by the IMG to show why they had failed to take the required action to develop these blocks and why action {{should not be taken}} against them. Following this, the Coal Ministry had asked the owners of these blocks to make a presentation before the IMG on achievement of milestones and reasons for delays. Those who were asked to make a presentation before the IMG included state-owned Steel Authority of India (SAIL), NTPC Ltd, JSPL, Abhijeet Infrastructure, Birla Corp and Rathi Udyog, Tata Power and Monnet Ispat and Energy Ltd. JSPL was specifically asked to make a presentation with regard to delay in production from its four coal blocks - Amarkunda Murgadangal in Jharkhand, Utkal B1 and Ramchandi in Odisha and Urtan North in Madhya Pradesh. Similarly, SAIL was asked to make presentation for Sitanala mine in Jharkhand and NTPC for Parki Barwadih mine in Jharkhand and Talaipalli mine in Chhattisgarh. During the presentation, a number of companies pointed to the continued unending delays in land acquisition, getting environmental clearances and regulatory hurdles for delays in development of the mines. The government had formed the IMG last year to review the progress of coal blocks allocated to firms for captive use and recommend action, including de-allocation. The panel has members from other Ministries including Steel and Power. The Supreme Court is monitoring the Coalgate scam probe into coal block allocations since 1993 being conducted by CBI following three public interest litigation petitions alleging that rules were flouted in giving away the natural resources and favouring certain companies at a huge loss of crores to the national exchequer. Slamming the decision to <b>de-allocate</b> their coal blocks, Jindal Steel and Power and Monnet Ispat and Energy have blamed lack of government approvals and external factors like Naxal activities for not making enough progress in their mines. The two companies, whose 4 blocks figure in the list of 11 to be <b>de-allocated,</b> said that they are being punished for no fault of theirs. The de-allocation is seen as a major setback to both as the blocks were supposed to be the captive raw material source for their upcoming/existing steel and power plants. Jindal's Rs. 80,000-crore mega venture of Coal-to-Liquid project is likely to be hit. The two companies have together invested over 110 billion so far on development of their end-use plants. At the outset, we are shocked and surprised to hear the recommendation made by IMG (Inter-ministerial group), it seems that everybody in the policy making/monitoring wants to avoid a pragmatic decision in view of the media hype," [...] Monnet Ispat spokesperson said in a statement. The JSPL spokesperson said the company's coal blocks are being <b>de-allocated</b> [...] "despite best efforts made by the company and no fault on part of the company." [...] Last week, the Coal Ministry decided to <b>de-allocate</b> 11 captive coal blocks to various companies. JSPL's three - Ramchandi promotional block, Amarkonda Murgadangal and Urtan North (jointly with Monnet) — figure in the list. Monnet's one more block, Rajagamar Dipside (South of Pulakdih Nala) coal block jointly allotted to Monnet Ispat and Energy Ltd among others, is also part of the list. The Monnet spokesperson further said 450 hectares of the block, out of total 650 hectares, is over-lapping with a block of the South Eastern Coalfields Ltd (SECL) and SECL needs to surrender title of the land and transfer it to Monnet. He also accused the Coal Ministry of violating its own conditions (clause 17 of General Condition of Allocation), saying that the caluse [...] "clearly stipulates that any delay in transferring the land by a government company to the coal block allocatee can be claimed as grace period." [...] “If IMG has recommended for de-allocation, then they are violating the published guidelines of MoC," [...] the spokesperson said, adding that Monnet can start development of the block immediately as it needs [...] "to acquire only 5 acre of land for making an entry." [...] According to the JSPL spokesperson, the company has made 4 attempts for carrying out exploration at Amarkonda Murgadangal block since April, 2009 but could not do it due to [...] "large amount of extremist/Naxal activities" [...] and [...] "illegal mining" [...] supported by extremists/anti-social elements. [...] "State government had further agreed to extend the validity of PL (prospective licence) by 2 years 4 months and 8 days under force majeure conditions on 5 June 2013 and {{we are in the process}} of starting our fifth attempt to carry out drilling operations in this block," [...] he said. The spokesperson of Jindal Steel and Power (JSPL) said its employees, officials and contractors were assaulted or made hostage many times at the site and equipment were damaged. He added that many complaints and FIRs have been filed on these issues and state and central governments have been informed about it. Talking about the to be <b>de-allocated</b> Ramchandi promotional block, he said JSPL's application for prospecting licence is pending with Odisha government for more than three years and the state government has not yet [...] "executed PL on one pretext or the other in spite of a number of reminders." [...] “In the circumstances, company could not start exploration activities for no fault of the company," [...] he said, while noting that the company has already completed various initial work, including detailed feasibility study, for the project and has invested Rs. 740 million on it. The Ramchandi block, which has estimated 1.5 billion tonnes of coal reserves, was allocated for ambitious Coal-to-Liquid project in February, 2009 and JSPL had already announced investment Rs. 800 billion on the venture. On Urtan North block, the third to be <b>de-allocated</b> block (jointly allocated with Monnet), JSPL spokesperson said that its Mine Plan is pending for final approval from Coal Ministry for more than six months now. The delay in Coal Ministry's approval has led to further delay in securing Environment Clearance (EC) as well. [...] "Expert Appraisal Committee (EAC) of MoEF, GoI has already considered grant of EC and is mainly pending for submission of Mine Plan approval letter. The Mine Plan approval letter is pending for issuance with Ministry of Coal for more than six months," [...] the company said. Monnet, which is also a partner in the block, also echoed the same. It the spokesperson said that grant of EC is in the [...] "final stage" [...] and the company is hopeful that it will be cleared by EAC in their [...] "forthcoming meeting" [...] to be held later this month. For Monnet, Urtan North and Rajagamar Dipside blocks are supposed to be the captive raw material source for its over a million tonne steel plant in Chhattisgarh's Raigarh, which is now in final stages of commissioning. The company said it has invested over Rs. 60 billion to develop the end-use plant. The Urtan North block is also critical to JSPL's plans as it was supposed to meet 10-12 per cent of the coking coal needs of its already operational Raigarh steel plant in Chhattisgarh. The company said has invested Rs. 34.16 billion on its development.|$|R
40|$|We {{show that}} the typed region {{calculus}} of Tofte and Talpin can be encoded in a typed -calculus equipped with name groups and a novel effect analysis. In the region calculus, each boxed value has a statically determined region {{in which it is}} stored. Regions are allocated and <b>de-allocated</b> according to a stack discipline, thus improving memory management. The idea of name groups arose in the typed ambient calculus of Cardelli, Ghelli, and Gordon. There, and in our -calculus, each name has a statically determined group to which it belongs. Groups allow for type-checking of certain mobility properties, as well as effect analyses. Our encoding makes precise the intuitive correspondence between regions and groups. We propose a new formulation of the type preservation property of the region calculus, which avoids Tofte and Talpin’s rather elaborate co-inductive formulation. We prove the encoding preserves the static and dynamic semantics of the region calculus. Our proof of the correctness of region de-allocation shows it to be a specific instance of a general garbage collection principle for the -calculus with effects. We propose new equational laws for letregion, analogous to scope mobility laws in the -calculus, and show them sound in our semantics...|$|R
