75|368|Public
2500|$|The 2011 CBA instituted {{major changes}} to the luxury tax regime. The {{previous}} CBA had a dollar-for-dollar tax provision system, which remained in effect through the 2012–13 season. Teams exceeding the tax level were punished by being forced to pay one dollar to the league for each dollar by which their payroll exceeded the tax level. Starting in 2013–14, the tax changed to an <b>incremental</b> <b>system.</b> Under the current system, tax is assessed at different levels based on the amount that a team is over the luxury tax threshold. The scheme is not cumulative—each level of tax applies only to amounts over that level's threshold. For example, {{a team that is}} $8 million over the tax threshold will pay $1.50 for each of its first $5 million over the tax threshold, and $1.75 per dollar for the remaining $3 million. Starting in 2014–15, [...] "repeat offenders", subject to additional penalties, are defined as teams that paid tax in previous seasons. In the first season, repeat offenders from in all previous three seasons will pay a stiffer tax rate; from 2015–16 thereafter, teams paying taxes in three out of four years will be subject to the higher repeater rate. As in the previous CBA, the tax revenue is divided among teams with lower payrolls. However, under the new scheme, no more than 50% of the total tax revenue can go exclusively to teams that did not go over the cap. Initial reports did not specify the use of the remaining 50% under the 2011 CBA, but it was later confirmed that this amount would be used to fund revenue sharing for the season during which tax was paid.|$|E
50|$|COBWEB is an <b>incremental</b> <b>system</b> for {{hierarchical}} conceptual clustering. COBWEB {{was invented}} by Professor Douglas H. Fisher, currently at Vanderbilt University.|$|E
50|$|In Windows Vista, a Complete PC Backup {{could not}} be {{performed}} to a network location. Windows 7 allows performing a full system image backup to a network location. However, subsequent <b>incremental</b> <b>system</b> image backups cannot be performed to a network; all image-based backups to the network must be full backups. Full system image backups to local or removable storage can be incremental.|$|E
50|$|The Potassco project {{acts as an}} {{umbrella}} {{for many of the}} systems below, including clasp, grounding <b>systems</b> (gringo), <b>incremental</b> <b>systems</b> (iclingo), constraint solvers (clingcon), action language to ASP compilers (coala), distributed MPI implementations (claspar), and many others.|$|R
5000|$|US patent 3,732,557 (1973) <b>Incremental</b> Position-Indicating <b>System</b> ...|$|R
40|$|Abstract. Text {{search engines}} have {{historically}} been designed for unchanging collections of documents. While this is fine for many applications, {{a growing number of}} important applications in news, finance, law and desktop search require indexes that can be efficiently updated. Previous research into supporting dynamic collections revolves around <b>incremental</b> methods. <b>Incremental</b> <b>systems</b> are optimized for adding large batches of documents to an existing index. These systems do not generally allow for queries to run while an incremental update is taking place. This work presents recent changes to the Indri search engine to support dynamic collections. Unlike previous <b>incremental</b> <b>systems,</b> Indri does not require large batch sizes to achieve efficient indexing performance. Indri is also designed to be as concurrent as possible, allowing queries to run while documents are added to the system. 1...|$|R
50|$|The National Grid {{sustained}} heavy damage {{during the}} event, as crashing cables short-circuited, {{which in some}} cases overheated the main system. Its headquarters faced the choice of keeping the Grid online to help London as the storm approached but risk an <b>incremental</b> <b>system</b> breakdown, failure and burnout, or to shut down most of South East England including London and avert that risk. The headquarters made the decision, the first one like it since before World War II: {{to shut down the}} South East power systems to maintain the network as soon as signs of overheating began.|$|E
5000|$|Substantial {{changes were}} made to the luxury tax regime. The dollar-for-dollar tax {{provisions}} of the previous CBA remained in effect through the 2012-13 season. Starting in 2013-14, the tax changed to an <b>incremental</b> <b>system.</b> Tax is now assessed at different levels based on the amount that a team is over the tax threshold, which remains at a level above the actual cap. The scheme is not cumulative—each level of tax applies only to amounts over that level's threshold. For example, a team that is $8 million over the tax threshold pays $1.50 for each of its first $5 million over the tax threshold, and $1.75 per dollar for the remaining $3 million. In addition, [...] "repeat offenders", subject to additional tax penalties, are defined as teams that paid tax in four of the five previous seasons. As in the previous CBA, the tax revenue is divided among teams with lower payrolls. However, under the new scheme, no more than 50% of the total tax revenue can go exclusively to teams that did not go over the cap; the use of the remaining 50% was not specified in the new agreement.|$|E
5000|$|The 2011 CBA instituted {{major changes}} to the luxury tax regime. The {{previous}} CBA had a dollar-for-dollar tax provision system, which remained in effect through the 2012-13 season. Teams exceeding the tax level were punished by being forced to pay one dollar to the league for each dollar by which their payroll exceeded the tax level. Starting in 2013-14, the tax changed to an <b>incremental</b> <b>system.</b> Under the current system, tax is assessed at different levels based on the amount that a team is over the luxury tax threshold. The scheme is not cumulative—each level of tax applies only to amounts over that level's threshold. For example, {{a team that is}} $8 million over the tax threshold will pay $1.50 for each of its first $5 million over the tax threshold, and $1.75 per dollar for the remaining $3 million. Starting in 2014-15, [...] "repeat offenders", subject to additional penalties, are defined as teams that paid tax in previous seasons. In the first season, repeat offenders from in all previous three seasons will pay a stiffer tax rate; from 2015-16 thereafter, teams paying taxes in three out of four years will be subject to the higher repeater rate. As in the previous CBA, the tax revenue is divided among teams with lower payrolls. However, under the new scheme, no more than 50% of the total tax revenue can go exclusively to teams that did not go over the cap. Initial reports did not specify the use of the remaining 50% under the 2011 CBA, but it was later confirmed that this amount would be used to fund revenue sharing for the season during which tax was paid.|$|E
5000|$|Dump (program) - UNIX utility for {{multilevel}} <b>incremental</b> file <b>system</b> backups.|$|R
50|$|Modern servomotors use rotary encoders, either {{absolute}} or incremental. Absolute encoders {{can determine}} their position at power-on, but are {{more complicated and}} expensive. Incremental encoders are simpler, cheaper and work at faster speeds. <b>Incremental</b> <b>systems,</b> like stepper motors, often combine their inherent ability to measure intervals of rotation with a simple zero-position sensor to set their position at start-up.|$|R
40|$|The Parlance {{system for}} {{interactive}} search processes dialogue at a microturn level, displaying dialogue phenomena that {{play a vital}} role in human spoken conversation. These dialogue phenomena include more natural turn-taking through rapid system responses, generation of backchannels, and user barge-ins. The Parlance demonstration system differentiates from other <b>incremental</b> <b>systems</b> in that it is data-driven with an infrastructure that scales well. ...|$|R
50|$|He was {{involved}} in the assessment of the oral contraceptive but in 1962 turned down an offer by Dr Geoffrey Pincus, its originator, to work with him. Instead he went to help set up the Endocrine Clinic at the Royal Women's Hospital in Melbourne, Australia, as a safe and highly effective method achieving pregnancy in anovulatory women and developed the Threshold Hypothesis of gonadothrophin action. In 1962 James Brown joined the Department of Obstetrics and Gynaecology, University of Melbourne. With colleagues, he developed methods for the safe use of human gonadotrophin with the minimum of multiple pregnancies, and for a time produced all the gonadotrophin for clinical use in Australia, New Zealand, Singapore and parts of Canada. It was from these clinical results that he developed the <b>incremental</b> <b>system</b> of gonadotrophin therapy and propounded the threshold hypothesis of gonadotrophin action on the ovary. The threshold hypothesis explained, for the first time, how only one follicle is usually selected for ovulation in the human, but it took 20 years for the explanation to be universally accepted. The pregnancy rate achieved with gonadotrophin therapy has not been bettered. The key to this success was in mimicking the hormone patterns of the natural cycle as closely as possible, a point which is still not fully appreciated today. He continually improved the sensitivity, speed and convenience of the methods for measuring oestrogen and progesterone metabolites in urine, so that the lowest concentrations found in the human could be measured. In the early 1970s, {{the rest of the world}} changed to blood assays for monitoring ovarian and pituitary activity. The validation of these blood assays depended on demonstrating that the hormone patterns obtained were the same as those obtained by the urinary assays.|$|E
40|$|Several {{technology}} and fuel options {{could be used}} to lower the strong oil dependence of the transportation sector. To formulate policies and to cost-effectively meet oil reduction objectives, assessments and comparisons of the long-term economic performances of different technology trajectories are essential. In this work, the energy and technology costs associated with reducing oil consumption in passenger cars in Sweden are calculated for a number of possible future transport fuel pathways and for different energy prices and climate policies. An optimisation model is applied in a simulatory multiple-run approach for this purpose. The model encompasses the transportation sector, as well as the stationary energy system. In terms of results, a methanol-based pathway gives <b>incremental</b> <b>system</b> costs in the range of − 0. 9 – 3 billion EUR for a complete phase-out of passenger car oil up to 2030. As compared to the methanol pathway, other biomass gasification-based fuel pathways involve additional <b>incremental</b> <b>system</b> costs in the region of 3 billion EUR, whereas ethanol- and electricity-based pathways give additional <b>incremental</b> <b>system</b> costs of 4 – 5 billion EUR. At lower oil reduction levels, the cost differences between the pathways are smaller and the electricity-based pathway is significantly more cost-competitive...|$|E
30|$|The {{following}} {{result is}} proven from Theorem 2.1, by {{taking into account}} the above asymptotic stability conditions for the linearized <b>incremental</b> <b>system</b> about the disease-free equilibrium point, which imply that of the nonlinear one (1.1)–(1.5) about the equilibrium point, and the related former discussion.|$|E
5000|$|GIPSY: a {{geographic}} <b>incremental</b> plotting <b>system</b> by Mark Stephen Monmonier, (University Park, Pennsylvania: Dept. of Geography, Pennsylvania State University, 1969.) ...|$|R
40|$|This paper {{presents}} Jindigo – a Java-based {{open source}} framework for implementing and experimenting with <b>incremental</b> dialogue <b>systems.</b> The framework {{is based on}} a general, abstract model of incremental processing. The paper describes how the framework supports revisions, incremental feedback, incremental reference resolution and incremental production of spoken utterances. Index Terms: dialogue <b>systems,</b> <b>incremental</b> processing 1...|$|R
40|$|We {{present a}} general model and {{conceptual}} framework for specifying architectures for incremental processing in dialogue systems, in particular {{with respect to the}} topology of the network of modules that make up the system, the way information flows through this network, how information increments are ‘packaged’, and how these increments are processed by the modules. This model enables the precise specification of <b>incremental</b> <b>systems</b> and hence facilitates detailed comparisons between systems, as well as giving guidance on designing new systems. ...|$|R
40|$|The {{problem of}} {{evaluating}} machine translation (MT) systems is more challenging than it may first appear, as diverse translations {{can often be}} considered equally correct. The task is even more difficult when practical circumstances require that evaluation be done automatically over short texts, for instance, during <b>incremental</b> <b>system</b> development and error analysis. While severa...|$|E
40|$|This paper {{describes}} a Dedicated Short Range Communications (DSRC) software-defined radio (SDR) which demonstrates {{the use of}} an integrated modeling and hardware design environment. Reconfigurable hardware {{in the form of a}} Field Programmable Gate Array (FPGA) serves as the hardware platform for the design. Intuitive interfaces between the simulation and hardware design models allow <b>incremental</b> <b>system</b> development with fine granularity...|$|E
40|$|In many {{disciplines}} {{of the social}} and natural sciences dynamic systems are encountered that are made up {{of a large number of}} separate but interacting units. Due to complexity, inherent random effects or incompleteness of information about the dynamic structure, a stochastic model is often appropriate for many of these systems. In this work we introduce a general two-stage procedure for modelling such systems that is able to handle both deterministic and stochastic influences on local system evolution. Its essential element is a hierarchy of two connected stochastic processes: At the marcrolevel the main determinants of <b>incremental</b> <b>system</b> evolution are captured in a parametric stochastic process structure. At the microlevel the remaining influences on <b>incremental</b> <b>system</b> evolution are then cumulatively used to locally and individually fine-tune the coarse-grained dynamics through stochastic parameter processes. The procedure is discussed in the context of concrete examples. (orig.) Available from TIB Hannover: RR 6943 (97 - 24) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|This paper {{addresses}} {{methods of}} specialising first-order theories {{within the context}} of <b>incremental</b> learning <b>systems.</b> We demonstrate the shortcomings of existing first-order <b>incremental</b> learning <b>systems</b> with regard to their specialisation mechanisms. We prove that these shortcomings are fundamental to the use of classical logic. In particular, minimal "correcting " specialisations are not always obtainable within this framework. We propose instead the adoption of a specialisation scheme based on an existing non-monotonic logic formalism. This approach overcomes the problems that arise with <b>incremental</b> learning <b>systems</b> which employ classical logic. As a side-effect of the formal proofs developed for this paper we define a function called "deriv" which turns out to be an improvement on an existing explanation-based-generalisation (EBG) algorithm. Prolog code and a description of the relationship between "deriv" and the previous EBG algorithm are described in an appendix. 1 Introduction [...] ...|$|R
40|$|Abstract. To {{adapt to}} the {{changing}} requirement of task data interface under the situation of far distance, multiple segment, multiple circle, multiple satellite and multi-station visibility for satellite misson in transfer orbit segment, the web <b>incremental</b> maintenance <b>system</b> based on materialized view was achieved through applying incremental maintenance principle, database technology, synchronization mechanism and maintenance proxy, and realizing the synchronization and consistency of data interface about the distributed experiment information surveillance software system. The result shows that web <b>incremental</b> maintenance <b>system</b> can ensure the real-time and consistency of data processing and transmission...|$|R
40|$|The paper {{reports on}} the {{methodology}} and preliminary results of {{a case study in}} automatically extracting ontological knowledge from Italian legislative texts. We use a fully-implemented ontology learning system (T 2 K) that includes a battery of tools for Natural Language Processing (NLP), statistical text analysis and machine language learning. Tools are dynamically integrated to provide an incremental representation of the content of vast repositories of unstructured documents. Evaluated results, however preliminary, show the great potential of NLP-powered <b>incremental</b> <b>systems</b> like T 2 K for accurate large-scale semi-automatic extraction of legal ontologies...|$|R
40|$|The goal of cross-show diarization is {{to index}} speech {{segments}} of speakers from {{a set of}} shows, with the particular challenge that reappearing speakers across shows have to be labeled with the same speaker identity. In this paper, we introduce three cross-show diarization systems namely Global-BIC-Seg, Global-BIC-Cluster, and Incremental. We compared the three systems {{on a set of}} 46 English scientific podcast shows. Among the three systems, the Global-BIC-Cluster achieves the best performance with 15. 53 % and 13. 21 % cross-show diarization error rate (DER) on the dev and test set, respectively. However, an incremental approach is more practical since data and shows are typically collected over time. By applying T-Norm on our <b>incremental</b> <b>system,</b> we obtain 13. 18 % and 10. 97 % relative improvements in terms of cross-show DER on dev and test set. We also investigate the impact of the show processing order on cross-show diarization for the <b>incremental</b> <b>system.</b> Index Terms: speaker diarization, cross-show diarization, conversational podcast show...|$|E
40|$|Heterogeneous {{data models}} and coding schemes for {{electronic}} health records present challenges for automated search across distributed data sources. This paper describes a loosely coupled software framework {{based on the}} terminology controlled approach to enable the interoperation between the search interface and heterogeneous data sources. Software components interoperate via common terminology service and abstract criteria model so as to promote component reuse and <b>incremental</b> <b>system</b> evolutio...|$|E
40|$|A {{step towards}} {{incremental}} generation of logical forms This paper presents AsdeCopas, an incremental module designed to interface syntax and semantics. In {{order to be}} an <b>incremental</b> <b>system,</b> AsdeCopas is based on self-contained, hierarchically organised semantic rules, that output formulas in a flat language. In this paper, we show how this system {{can be used in}} the following applications: a) semantic disambiguation; b) logical formulas construction (in Minimal Recursion Semantics); c) question interpretation...|$|E
40|$|This paper {{presents}} the on-going {{development of a}} model of incremental semantics driven natural language generation (NLG) for <b>incremental</b> dialogue <b>systems.</b> The approach is novel in its tight integration of incremental goal-driven semantics and syntactic construction, utilizing Type Theory with Records (TTR) record types for goal concepts as its input and the grammar formalism Dynamic Syntax (DS) for a wordby-word tactical generation procedure. The characterization of generation in terms of semantic input and word output graphs allows an integration into the <b>incremental</b> dialogue <b>system</b> Jindigo and facilitates the generation of human-like self-repairs in a semantically and syntactically motivated way. ...|$|R
5000|$|<b>Incremental</b> sensors. This <b>system</b> uses {{vehicle speed}} data {{supplied}} by a Fleet Management System.|$|R
5000|$|Since Diablo (Maemo 4.1), Maemo {{supports}} [...] "Seamless Software Update" [...] (SSU), {{which allows}} <b>incremental</b> operating <b>system</b> upgrades [...] "over the air" [...] using the Advanced Packaging Tool, {{without the need}} for a full flash with every update.|$|R
40|$|This paper {{presents}} an eficient hardware prototyping methodologies of digital systems. It {{is based on}} a low-cost and flexible prototyping system which consists of a general-purpose CPU and a FPGA-based custom board. Using our prototyping methodologies such as <b>incremental</b> <b>system</b> design and module-by-module verification, we can map partial system specification into hardware prototype, which is implemented by programming FPGAs on custom board. This allows flexible and efficient system verification as well as reduction in cost and time of prototype buildzng. I...|$|E
40|$|A Doctoral Thesis. Submitted in partial {{fulfilment}} of {{the requirements}} for the award of Doctor of Philosophy at Loughborough University. It has become evident {{in recent years that}} due to the complexity and diversity of computer applications in manufacturing environments, not only will previously established 'islands of automation' continue to exist, but new islands will emerge as a result of system expansion and technical renovation. Therefore, it is vitally important that systems integration methods are capable of supporting pre-existing manufacturing application systems as well as <b>incremental</b> <b>system</b> growth. [Continues. ...|$|E
40|$|When {{dialogue}} systems, {{through the}} use of incremental processing, are not bounded anymore by strict, nonoverlapping turn-taking, a whole range of additional interactional devices becomes available. We explore the use of one such device, trial intonation. We elaborate our approach to dialogue management in incremental systems, based on the Information-State-Update approach, and discuss an implementation in a microdomain that lends itself to the use of immediate feedback, trial intonations and expansions. In an overhearer evaluation, the <b>incremental</b> <b>system</b> was judged as significantly more human-like and reactive than a non-incremental version. ...|$|E
50|$|Partial-order {{plans are}} known to easily and optimally solve the Sussman Anomaly. Using this type of <b>incremental</b> {{planning}} <b>system</b> solves this problem quickly and efficiently. This {{was a result of}} partial-order planning that solidified its place as an efficient planning system.|$|R
40|$|What is Universal Access-NY? Universal Access-NY is a {{complete}} online planning toolkit, www. UniversalAccessNY. org, where a One-Stop Delivery System can assess its practices, and develop work plans to improve physical and programmatic accessibility for all One-Stop customers. This web site and manual was developed by Cornell University’s Employment and Disability Institute, through the support and guidance of the New York State Department of Labor, with funding from two U. S. Department of Labor Work Incentive Grants (WIG 1 and 2). This web site was designed {{for use in a}} collaborative manner, bringing together One-Stop personnel, agency partners, business leaders and customers with disabilities. Universal Access-NY supports continuous improvement, with features that encourage multiple uses and <b>incremental</b> <b>systems</b> change...|$|R
40|$|The paper {{reports on}} {{methodology}} and preliminary {{results of a}} case study in automatically extracting ontological knowledge from Italian legislative texts in the environmental domain. We use a fully-implemented ontology learning system (T 2 K) that includes a battery of tools for Natural Language Processing (NLP), statistical text analysis and machine language learn-ing. Tools are dynamically integrated to provide an incremen-tal representation of the content of vast repositories of unstruc-tured documents. Evaluated results, however preliminary, are very encouraging, showing the great potential of NLP-powered <b>incremental</b> <b>systems</b> like T 2 K for accurate large-scale semi– automatic extraction of legal ontologies. Index Terms: ontology learning, document management, knowledge extraction from texts, Natural Language Processin...|$|R
