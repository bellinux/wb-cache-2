70|363|Public
50|$|Tree {{clustering}} or join-tree clustering {{is based}} on merging constraints {{in such a way}} the resulting problem has a <b>join</b> <b>tree,</b> this <b>join</b> <b>tree</b> {{is the result of the}} decomposition.|$|E
50|$|Not all {{constraint}} satisfaction problems have a <b>join</b> <b>tree.</b> However, {{problems can be}} modified to acquire a <b>join</b> <b>tree.</b> Join-tree clustering is a specific method to modify problems {{in such a way}} they acquire a joint tree. This is done by merging constraints, which typically increases the size of the problem; however, solving the resulting problem is easy, as it is for all problems that have a <b>join</b> <b>tree.</b>|$|E
50|$|Decomposition methods generalize join-tree {{clustering}} by grouping {{variables in}} such a way the resulting problem has a <b>join</b> <b>tree.</b> Decomposition methods directly associate a tree with problems; the nodes of this tree are associated variables and/or constraints of the original problem. By merging constraints based on this tree, one can produce a problem that has a <b>join</b> <b>tree,</b> and this <b>join</b> <b>tree</b> can be easily derived from the decomposition tree. Alternatively, one can build a binary acyclic problem directly from the decomposition tree.|$|E
50|$|The {{neighbor}} <b>joining</b> <b>tree</b> is now complete, {{as shown}} in the figure.|$|R
40|$|The {{main goal}} {{of this paper is}} to {{describe}} a data structure called binary <b>join</b> <b>trees</b> that are useful in computing multiple marginals efficiently using the Shenoy-Shafer architecture. We define binary <b>join</b> <b>trees,</b> describe their utility, and sketch a procedure for constructing them. Comment: Appears in Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence (UAI 1996...|$|R
5000|$|The joining of the {{elements}} and the branch length calculation help drawing the neighbor <b>joining</b> <b>tree</b> {{as shown in the}} figure.|$|R
5000|$|Finding a <b>join</b> <b>tree,</b> if any, {{can be done}} {{exploiting}} the following property: if a dual graph has a <b>join</b> <b>tree,</b> then the maximal-weight spanning trees of the graph are all join trees, if edges are weighted {{by the number of}} variables the corresponding constraints enforce to be equal. An algorithm for finding a <b>join</b> <b>tree,</b> if any, proceeds as follows. In the first step, edges are assigned weights: if two nodes represent constraints that share [...] variables, the edge joining them is assigned weight [...] In the second step, a maximal-weight spanning tree is searched for. Once one is found, it is checked whether it enforces the required equality of variables. If this is the case, this spanning tree is a <b>join</b> <b>tree.</b>|$|E
50|$|Not all {{constraint}} satisfaction problems have a <b>join</b> <b>tree.</b> However, {{problems can be}} modified to acquire a <b>join</b> <b>tree</b> by merging constraints. Tree clustering {{is based on the}} fact that a problem has a <b>join</b> <b>tree</b> if and only if its primal graph is chordal and conformant with the problem, the latter meaning that the variables of every maximal clique of the primal graph are the scope of a constraint and vice versa. Tree clustering modify an arbitrary problem in such a way these two conditions are met. Chordality is enforced by adding new binary constraints. Conformality is obtained by merging constraints.|$|E
5000|$|Another {{method for}} finding out whether a {{constraint}} satisfaction problem has a <b>join</b> <b>tree</b> uses the primal graph of the problem, {{rather than the}} dual graph. The primal graph of a constraint satisfaction problem is a graph whose nodes are problem variables and whose edges represent the presence of two variables in the same constraint. A <b>join</b> <b>tree</b> for the problem exists if: ...|$|E
3000|$|..., in its {{neighboring}} hood {{to allow}} other nodes to <b>join</b> the <b>tree</b> {{and so on}} until all the nodes <b>join</b> the <b>tree.</b>|$|R
50|$|Cloud <b>joined</b> <b>Tree</b> of Knowledge, as {{a speaker}} in 2007. He {{left the company}} in 2013 to {{concentrate}} on developing a TV and stage career.|$|R
40|$|In recent years, the {{computation}} of marginals {{out of a}} factorization of val-uations {{has been}} studied in detail. There are several algorithms solving this task such that the domains of the intermediate results remain small. These methods are essentially based on message passing schemes on <b>join</b> <b>trees.</b> Every node’s label equals the domain of a factor or {{the domain of the}} combination of several factors. However, we are usually forced to use covering <b>join</b> <b>trees</b> where the domains of the factors are only supposed to be contained in the labels of the nodes. A major drawback of the use of covering <b>join</b> <b>trees</b> {{is that we have to}} ensure that all marginals to be computed are well defined. Until yet, this problem was simplified by filling the nodes with neutral elements bearing the desired, bigger domain. Although mathematical correct, this is not feasible for practical purposes, since neutral elements tend to contain infinite elements. We will see that such unfavorable extensions are not needed. Of particular interest in this paper are the collect algorithm, the Shenoy-Shafer (Shenoy & Shafer...|$|R
5000|$|The {{problem that}} results from this process has a <b>join</b> <b>tree,</b> and such a <b>join</b> <b>tree</b> can be {{obtained}} by using the same ordering of variables again. Proceeding from the last node to the first, every constraint is connected with the preceding constraint that shares more variables with it. Join-tree clustering {{can be seen as a}} decomposition method in which: ...|$|E
50|$|A <b>join</b> <b>tree</b> of a {{constraint}} satisfaction {{problem is a}} tree in which each node is associated a constraints (and vice versa) and such that the subtree of nodes whose constraint contains a variable is connected. As a result, producing a <b>join</b> <b>tree</b> {{can be viewed as}} a particular form of decomposition, where each node of the tree is associated the scope of a constraint.|$|E
50|$|In turn, chordality can {{be checked}} using a max-cardinality {{ordering}} of the variables. Such an ordering {{can also be}} used, if the two conditions above are met, for finding a <b>join</b> <b>tree</b> of the problem. Ordering constraints by their highest variable according to the ordering, an algorithm for producing a <b>join</b> <b>tree</b> proceeds from the last to the first constraint; at each step, a constraint {{is connected to the}} constraint that shares a maximal number of variables with it among the constraints that precede it in the ordering.|$|E
25|$|It {{can also}} be viewed, in terms {{familiar}} in computer science, as the magma of binary trees with leaves labelled by elements of X. The operation is that of <b>joining</b> <b>trees</b> at the root. It therefore has a foundational role in syntax.|$|R
50|$|Agglomerative Hierarchical {{clustering}} of nodes on {{the basis}} of the similarity of their profiles of ties to other nodes provides a <b>joining</b> <b>tree</b> or Dendrogram that visualizes the degree of similarity among cases - and can be used to find approximate equivalence classes.|$|R
50|$|It {{can also}} be viewed, in terms {{familiar}} in computer science, as the magma of binary trees with leaves labelled by elements of X. The operation is that of <b>joining</b> <b>trees</b> at the root. It therefore has a foundational role in syntax.|$|R
50|$|A graph {{obtained}} from the dual graph by removing some redundant edges is called a join graph. If it is a tree, it is called a <b>join</b> <b>tree.</b> The dual problem can be solved from a join graph since all removed edges are redundant. In turn, the problem can be solved efficiently if that join graph is a tree, using algorithms tailored for acyclic constraint satisfaction problems.|$|E
5000|$|A tree-structured graph, {{where each}} node is {{a subset of}} variables, each pair of neighbors has {{non-empty}} intersection, and the intersection of two distinct nodes is contained in every node on the path connecting the two distinct nodes. Such a graph is also sometimes called a <b>join</b> <b>tree.</b> In mathematical notations, a Markov tree is a graph [...] that satisfies the following: (1) [...] is a hypergraph; (2) if , then and (3) if [...] and [...] are distinct vertices of , and , then [...] is in every vertex on the path from [...] to [...]|$|E
40|$|State-of-the-art exact {{algorithms}} {{for solving}} the MAP problem in Bayesian networks use depthfirst branch-and-bound search with bounds computed by evaluating a <b>join</b> <b>tree.</b> Although {{this approach is}} effective, it can fail if the <b>join</b> <b>tree</b> is too large to fit in RAM. We describe an externalmemory MAP search algorithm that stores much of the <b>join</b> <b>tree</b> on disk, keeping {{the parts of the}} <b>join</b> <b>tree</b> in RAM that are needed to compute bounds for the current search nodes, and using heuristics to decide which parts of the <b>join</b> <b>tree</b> to write to disk when RAM is full. Preliminary results show that this approach improves the scalability of exact MAP search algorithms. ...|$|E
50|$|In 2002 he <b>joined</b> Porcupine <b>Tree.</b>|$|R
40|$|FIGURE 3. Neighbor <b>joining</b> <b>tree</b> for {{all species}} of Charissa, {{subgenus}} Pterygnophos, {{on the basis}} of DNA barcoding (pairwise distances model for COI- 5 P marker) with Gnophos furvata ([Denis & Schiffermüller], 1775) as outgroup. Terminal branches provided with species name, barcode id., barcode length, origin, and BIN number from BOLD...|$|R
40|$|FIGURE 58. Neighbor <b>Joining</b> <b>tree</b> (Kimura 2 parameter, {{built with}} MEGA 5; cf. Tamura et al. 2011), only {{sequences}} (> 600 bp) considered. Width of triangles represent sample size, depth the genetic variation within the cluster. Source: DNA Barcode data from BOLD (Barcode of Life Database, cf. Ratnasingham & Hebert 2007) ...|$|R
40|$|In this paper, we {{put forth}} the first <b>join</b> <b>tree</b> {{propagation}} algorithm that selectively applies either arc reversal (AR) or variable elimination (VE) {{to build the}} propagated messages. Our approach utilizes a recent method for identifying the propagated <b>join</b> <b>tree</b> messages à priori. When it is determined that precisely one message is to be constructed at a <b>join</b> <b>tree</b> node, VE is utilized to build this distribution; otherwise, AR is applied as it is better suited to construct multiple distributions passed between neighboring <b>join</b> <b>tree</b> nodes. Experimental results, involving evidence processing in seven real-world and one benchmark Bayesian network, empirically demonstrate that selectively applying VE and AR is faster than applying one of these methods exclusively on the entire network...|$|E
40|$|AbstractIn this paper, we {{put forth}} the first <b>join</b> <b>tree</b> {{propagation}} algorithm that selectively applies either arc reversal (AR) or variable elimination (VE) {{to build the}} propagated messages. Our approach utilizes a recent method for identifying the propagated <b>join</b> <b>tree</b> messages à priori. When it is determined that a <b>join</b> <b>tree</b> node will construct a single distribution {{to be sent to}} a neighbouring node, VE is utilized as it builds a single distribution in the most direct fashion; otherwise, AR is applied as it maintains a factorization of distributions allowing for barren variables to be exploited during propagation later on in the <b>join</b> <b>tree.</b> Experimental results, involving evidence processing in four benchmark Bayesian networks, empirically demonstrate that selectively applying VE and AR is faster than applying one of these methods exclusively on the entire network...|$|E
40|$|Data Stream Management Systems (DSMS) have {{recently}} {{received a lot}} of attention from the database research community. DSMS handles a particular type of applications that involve multiple continuous data streams with inputs arriving at highly variable and unpredictable rates. Since data rate fluctuates over time in this type of applications the appropriate <b>join</b> <b>tree</b> is crucial for maintaining high system throughput. DSMS must also be able to adaptively change the <b>join</b> <b>tree</b> according to the environment. We consider the problem of finding optimal <b>join</b> <b>tree</b> for performing count based sliding window multi-joins over continuous streams. We use a unit-time based cost model to evaluate the expected performance for a given <b>join</b> <b>tree.</b> We materialize all intermediate results assuming there is enough main memory to store all partial results and window buffers. We give a polynomial time algorithm that finds the optimal <b>join</b> <b>tree</b> under our cost model for a given non-commuting order of streams. This algorithm can be used in conjunction with any linear order producing heuristic to give the optimal tree for that order. Our algorithm is implemented in the JESS rule engine and an extensive experimental evaluation is provided. 1...|$|E
30|$|The {{result of}} model based {{analysis}} is {{in accordance with}} the clustering pattern of Neighbour <b>joining</b> <b>tree</b> and Principal Coordinate Analysis. The first two principal coordinates explained 12.6 and 4.8  % of the molecular variance. Similar pattern of molecular variance explanation was observed by Zhang et al. (2011) for two population subgroups.|$|R
40|$|FIGURE 6. Neighbor <b>joining</b> <b>tree</b> for all {{analyzed}} {{species of}} Gnophopsodos {{on the basis}} of DNA barcoding (Kimura 2 - parameter distance model for COI- 5 P marker) with Gnophos furvata ([Denis & Schiffermüller], 1775) as outgroup. Terminal branches provided with species name, barcode id., barcode length, origin, and BIN number from BOLD...|$|R
40|$|FIGURE 23. Phylogenetic tree of Capniidae {{based on}} 594 bp of 28 S. Neighbour <b>joining</b> <b>tree</b> based on {{absolute}} distances. Support values: *, ** indicate Bayesian posterior probability> 0. 95 and> 0. 99 respectively; MP and NJ bootstrap percentages {{are shown in}} this order separated by a slash. Bootstrap values < 50 not shown...|$|R
40|$|Current <b>join</b> <b>tree</b> {{propagation}} algorithms {{treat all}} propagated messages as being of equal importance. On the contrary, {{it is often}} the case in real-world Bayesian networks that only some of the messages propagated from one <b>join</b> <b>tree</b> node to another are relevant to subsequent message construction at the receiving node. In this article, we propose the first <b>join</b> <b>tree</b> propagation algorithm that identifies and constructs the relevant messages first. Our approach assigns lower priority to the irrelevant messages as they only need to be constructed so that posterior probabilities can be computed when propagation terminates. Experimental results, involving the processing of evidence in four real-world Bayesian networks, empirically demonstrate an improvement over the state-of-the-art method for exact inference in discrete Bayesia...|$|E
40|$|This paper {{presents}} {{a comparison of}} two architectures for belief propaga-tion in evidential networks, namely the binary <b>join</b> <b>tree</b> using joint be-lief functions [9] and the modified binary <b>join</b> <b>tree</b> using conditional belief functions [2]. This com-parison is done from the perspec-tive of graphical structure, message-passing scheme, computational effi-ciency, storage efficiency, and com-plexity analysis. As a main result, we show that the implication of the conditional relations between vari-ables in evidential networks reduces the computational complexity of the inference process...|$|E
40|$|The {{notions of}} γ and β-acyclicity are two classic generalizations of the acyclicity of graphs to hypergraphs. They satisfy the {{property}} that, if a hypergraph is γ-acyclic {{then it is}} β-acyclic, and the reverse is false. We give some new properties concerning these notions. First we show that we can strictly insert another notion of acyclicity between them, namely the fact of having a <b>join</b> <b>tree</b> with disjoint branches. And if we add a condition {{on the existence of}} such a <b>join</b> <b>tree,</b> we obtain a notion equivalent to γ-acyclicity. Then we present two characterizations, consisting in applying successively a small set of rules, deciding γ and β-acyclicity respectively. ...|$|E
40|$|FIGURE 5. Neighbor <b>joining</b> <b>tree</b> for {{all species}} of the Charissa mutilata - group {{on the basis of}} DNA barcoding (pairwise {{distances}} model for COI- 5 P marker) with Gnophos furvata ([Denis & Schiffermüller], 1775) as outgroup. Terminal branches provided with species name, barcode sample ID, barcode length (bp), origin, and BIN number from BOLD...|$|R
5000|$|<b>Join</b> two <b>trees</b> {{together}} by making one tree {{a child of}} the other.|$|R
50|$|Operation (2) {{it is also}} efficient. It is easy to <b>join</b> two <b>trees</b> together.|$|R
