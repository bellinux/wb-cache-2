1447|365|Public
25|$|Polikar, R., Udpa, L., Udpa, S., and Honavar, V. (2001). Learn++: An <b>Incremental</b> <b>Learning</b> Algorithm for Multi-Layer Perceptron Networks. IEEE Transactions on Systems, Man, and Cybernetics. Vol. 31, No. 4. pp.497–508.|$|E
25|$|Polikar, R., Udpa, L., Udpa, S., and Honavar, V. (2000). Learn++: An <b>Incremental</b> <b>Learning</b> Algorithm for Multilayer Perceptron Networks. In: Proceedings of the IEEE Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2000. Istanbul, Turkey.|$|E
25|$|R. Polikar, L. Udpa, S. Udpa, and V. Honavar (2004). An <b>Incremental</b> <b>Learning</b> Algorithm with Confidence Estimation for Automated Identification of NDE Signals. IEEE Transactions of Ultrasonics, Ferroelectrics, and Frequency Control. Vol. 51. pp.990–1001, 2004.|$|E
40|$|The {{objective}} of pool-based <b>incremental</b> active <b>learning</b> {{is to choose}} a sample to label {{from a pool of}} unlabeled samples in an incremental manner so that the generalization error is minimized. In this scenario, the generalization error often hits a minimum {{in the middle of the}} <b>incremental</b> active <b>learning</b> procedure and then it starts to increase. In this paper, we address the problem of early labeling stopping in probabilistic classification for minimizing the generalization error and the labeling cost. Among several possible strategies, we propose to stop labeling when the empirical classposterior approximation error is maximized. Experiments on benchmark datasets demonstrate the usefulness of the proposed strategy. Keywords pool-based <b>incremental</b> active <b>learning,</b> early stopping, least-squares probabilisti...|$|R
40|$|<b>Incremental</b> class <b>learning</b> {{involves}} sequentially learning {{classes in}} bursts of {{examples from the}} same class. This violates the assumptions that underlie methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting. Arguably, the best method for <b>incremental</b> class <b>learning</b> is iCaRL, but it requires storing training examples for each class, making it challenging to scale. Here, we propose FearNet for <b>incremental</b> class <b>learning.</b> FearNet is a generative model that does not store previous examples, making it memory efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall. FearNet achieves state-of-the-art performance at <b>incremental</b> class <b>learning</b> on image (CIFAR- 100, CUB- 200) and audio classification (AudioSet) benchmarks. Comment: Under review as a conference paper at ICLR 201...|$|R
5000|$|Feature extraction: Mini-batch {{dictionary}} <b>learning,</b> <b>Incremental</b> PCA.|$|R
25|$|The third type of knowledge, {{innovative}} knowledge, is {{the labor}} of genius, such {{as the work of}} Leonardo da Vinci—who, in the late 15th century, conceptualized cutting-edge ideas like the aeroplane, the parachute, cranes, submarines, tanks, water pumps, canals, and drills. Innovative knowledge encompasses the type of learning that leapfrogs the other types, and—in da Vinci's case—was so advanced that it had to wait hundreds of years for <b>incremental</b> <b>learning</b> to catch up.|$|E
25|$|The {{learning}} curve for cued recall increases systematically {{with the number}} of trials completed. This result has caused a debate about whether or not learning is all-or-none. One theory is that learning is incremental and that the recall of each word pair is strengthened with repetition. Another theory suggests that learning is all-or-none, that is one learns the word pair in a single trial and memory performance is due to the average learned pairs, some of which are learned on earlier trials and some on later trials. To examine the validity of these theories researchers have performed memory experiments. In one experiment published in 1959, experimental psychologist Irvin Rock and colleague Walter Heimer of the University of Illinois had both a control group and an experimental group learn pairs of words. The control group studied word pairs that were repeated until the participants learned all the word pairs. In the experimental group, the learned pairs remained in the list while unlearned pairs were substituted with recombinations of previous words. Rock believed that associations between two items would be strengthened if learning were incremental even when pairs are not correctly recalled. His hypothesis was that the control group would have a higher correct recall probability than the experimental group. He thought that repetition would increase the strength of the word pair until the strength reaches a threshold needed to produce an overt response. If learning were all or none, then the control group and the experimental group should learn the word pairs at the same rate. Rock found experimentally there was little difference in learning rates between the two groups. However, Rock's work did not settle the controversy because in his experiment he rearranged replaced word pairs that could be either easier or harder to learn than the original words in the word- digit pair. In further experiments that addressed the question, there were mixed results. The <b>incremental</b> <b>learning</b> hypothesis is supported by the notion that awhile after Ai-Bi pairs are learned, the recall time to recall Bi decreases with continued learning trails.|$|E
5000|$|<b>Incremental</b> <b>learning</b> {{does not}} {{negatively}} affect the ROC {{curve of the}} classifier; in fact, <b>incremental</b> <b>learning</b> yielded an improvement ...|$|E
40|$|We {{present a}} {{concrete}} design for Solomonoff's <b>incremental</b> machine <b>learning</b> system suitable for desktop computers. We use R 5 RS Scheme and its standard library {{with a few}} omissions as the reference machine. We introduce a Levin Search variant based on a stochastic Context Free Grammar together with new update algorithms that use the same grammar as a guiding probability distribution for <b>incremental</b> machine <b>learning.</b> The updates include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. The issues of extending the a priori probability distribution and bootstrapping are discussed. We have implemented {{a good portion of}} the proposed algorithms. Experiments with toy problems show that the update algorithms work as expected. Comment: This is the original submission for my AGI- 2010 paper titled Stochastic Grammar Based <b>Incremental</b> Machine <b>Learning</b> Using Scheme which may be found on [URL] and presented a partial but general solution to the transfer learning problem in AI. arXiv admin note: substantial text overlap with arXiv: 1103. 100...|$|R
40|$|Abstract: One of the {{essences}} of {{supervised learning}} in neural network is generalization capability. It is {{an ability to}} give an accurate result for data that are not learned in learning process. One of supervised learning method that theoretically guarantees the optimal generalization capability is projection learning. The method was formulated as inverse problem from functional analytic {{point of view in}} reproducing kernel Hilbert space. This paper will describe a computational study to the <b>incremental</b> projection <b>learning</b> in neural networks, called incremental projection generalizing neural networks, for solving function approximation problem. The study is done based on computer simulations of a mathematics function as test problem. Aspects of study focus on model selection, generalization capability and number of neurons in hidden layer. Key Words: supervised <b>learning,</b> <b>incremental</b> projection <b>learning,</b> generalization capability, artificial neural networks, function approximation proble...|$|R
40|$|The {{problem of}} {{designing}} input signals for optimal generalization is called active learning. In this paper, we give a two-stage sampling scheme for reducing both the bias and variance, {{and based on}} this scheme, we propose two active learning methods. One is the multi-point-search method applicable to arbitrary models. The e#ectiveness of this method is shown through computer simulations. The other is the optimal sampling method in trigonometric polynomial models. This method precisely specifies the optimal sampling locations. Keywords Active learning, generalization capability, projection <b>learning,</b> <b>incremental</b> projection <b>learning,</b> trigonometric polynomial space. <b>Incremental</b> Active <b>Learning</b> for Optimal Generalization 2 1 Introduction Supervised learning is obtaining an underlying rule from sampled information. Depending {{on the type of}} sampling, supervised learning can be classified into two di#erent categories. One is the case where information is given unilaterally from the environ [...] ...|$|R
5000|$|... #Subtitle level 3: Population-based <b>incremental</b> <b>learning</b> (PBIL) ...|$|E
5000|$|<b>Incremental</b> <b>learning</b> allows OPTIMOL {{to collect}} a better dataset ...|$|E
5000|$|<b>Incremental</b> <b>learning</b> allows OPTIMOL {{to learn}} faster (by {{discarding}} irrelevant images) ...|$|E
40|$|Abstract. <b>Incremental</b> on-line <b>learning</b> is a {{research}} topic gaining increasing interest in the machine learning community. Such learning methods are highly adaptive, not restricted to distinct training and ap-plication phases, and applicable to large volumes of data. In this pa-per, we present a novel classifier based on the unsupervised topology-learning TopoART neural network. We demonstrate that this classi-fier is capable of fast <b>incremental</b> on-line <b>learning</b> and achieves excel-lent results on standard datasets. We further show that it can success-fully process imbalanced, incomplete, and noisy data. Due to these properties, we consider it a promising component for constructing artificial agents operating in real-world environments. ...|$|R
50|$|Vijayakumar's {{articles}} on <b>Incremental</b> online <b>learning</b> in high dimensions, and Natural actor-critic, {{have been cited}} over 450 times each in academic papers and he won the IEEE Robotics King-Sun Fu Memorial Best Paper Award 2013.|$|R
30|$|In our {{experimental}} results, {{we consider}} sets of training data associated with fully sampled time series {{from the first}} days of each experiment for generating the dictionaries. The subspace identified by the fully sampled data is used for the subsequent recovery of past measurements and prediction of future ones. Alternatively, the dictionary could be updated {{during the course of the}} SS-MC application via an <b>incremental</b> subspace <b>learning</b> method [53, 54]. We opted out from an <b>incremental</b> subspace <b>learning</b> since although it can potentially lead to better estimation, it is also associated with increased computational load and the higher probability of estimation drift and lower performance.|$|R
5000|$|... <b>incremental</b> <b>{{learning}},</b> {{a learning}} {{model for the}} incremental extension of knowledge ...|$|E
5000|$|STAGGER, J.C.Schlimmer, R.H.Granger, <b>Incremental</b> <b>Learning</b> from Noisy Data, Mach. Learn., vol.1, no.3, 1986.|$|E
50|$|In {{computer}} science, <b>incremental</b> <b>learning</b> is {{a method}} of machine learning, in which input data is continuously used to extend the existing model's knowledge i.e. to further train the model. It represents a dynamic technique of supervised learning and unsupervised learning {{that can be applied}} when training data becomes available gradually over time or its size is out of system memory limits. Algorithms that can facilitate <b>incremental</b> <b>learning</b> are known as incremental machine learning algorithms.|$|E
40|$|In {{this paper}} we present the Semantic Turkey Ontology Learner (ST-OL), an <b>incremental</b> {{ontology}} <b>learning</b> system, that follows two main ideas: (1) putting final {{users in the}} learning loop; (2) using a probabilistic ontology learning model that exploits transitive relations for inducing better extraction models...|$|R
40|$|A {{number of}} soft {{computing}} approaches, such as neural networks, evolutionary algorithms, and fuzzy logic, {{have been widely}} used for classifier agents to adaptively evolve solutions on classification problems. However, most work in the literature focuses on the learning ability of individual classifier agent. This paper explores <b>incremental,</b> collaborative <b>learning</b> in a multi-agent environment. We use genetic algorithm (GA) and incremental genetic algorithm (IGA) as the main techniques to evolve the rule set for classification, and employ new class acquisition as a typical example to illustrate the <b>incremental,</b> collaborative <b>learning</b> capability of classifier agents. Benchmark data sets are used to evaluate proposed approaches. The results show that GA and IGA can be successfully used for collaborative learning among classifier agents...|$|R
40|$|Incremental Support Vector Machines (SVM) are {{instrumental}} in practical applications of online learning. This work {{focuses on the}} design and analysis of efficient <b>incremental</b> SVM <b>learning,</b> {{with the aim of}} providing a fast, numerically stable and robust implementation. A detailed analysis of convergence and of algorithmic complexity of <b>incremental</b> SVM <b>learning</b> is carried out. Based on this analysis, a new design of storage and numerical operations is proposed, which speeds up the training of an incremental SVM by a factor of 5 to 20. The performance of the new algorithm is demonstrated in two scenarios: learning with limited resources and active learning. Various applications of the algorithm, such as in drug discovery, online monitoring of industrial devices and and surveillance of network traffic, can be foreseen...|$|R
50|$|Both methods {{could be}} combined: {{the system could}} start with initial {{standard}} values of these parameters issued from a generic database, then some <b>incremental</b> <b>learning</b> customizes the classifier to each individual user.|$|E
5000|$|Polikar, R., Udpa, L., Udpa, S., and Honavar, V. (2001). Learn++: An <b>Incremental</b> <b>Learning</b> Algorithm for Multi-Layer Perceptron Networks. IEEE Transactions on Systems, Man, and Cybernetics. Vol. 31, No. 4. pp. 497-508.|$|E
5000|$|Polikar, R., Udpa, L., Udpa, S., and Honavar, V. (2000). Learn++: An <b>Incremental</b> <b>Learning</b> Algorithm for Multilayer Perceptron Networks. In: Proceedings of the IEEE Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2000. Istanbul, Turkey.|$|E
40|$|We {{describe}} an online approach to learn non-linear motion patterns and robust appearance models for multi-target tracking in a tracklet association framework. Unlike most previous approaches that use linear motion methods only, we online build a non-linear motion map to better explain direction changes and produce more robust motion affinities between tracklets. Moreover, {{based on the}} <b>incremental</b> <b>learned</b> entry/exit map, a multiple instance learning method is devised to produce strong appearance models for tracking; positive sample pairs are collected from different tracklets so that training samples have high diversity. Finally, using online learned moving groups, a tracklet completion process is introduced to deal with tracklets not reaching entry/exit points. We evaluate our approach on three public data sets, and show significant improvements compared with state-of-art methods. 1...|$|R
40|$|A {{neural network}} {{formulation}} {{of a leader}} independent, nonparametric, Bayes' risk consistent algorithm [8] for <b>incremental</b> machine <b>learning</b> is presented. Implementation of the computing algorithm on a medical data base is compared with some recently reported ANN algorithms for classification/clustering. Importance of the approach is highlighted...|$|R
40|$|Abstract. In {{this paper}} we present the Semantic Turkey Ontology Learner (ST-OL), an <b>incremental</b> {{ontology}} <b>learning</b> system, that follows two main ideas: (1) putting final {{users in the}} learning loop; (2) using a probabilistic ontology learning model that exploits transitive relations for inducing better extraction models. ...|$|R
5000|$|... 15 Misra, A., Sowmya, A., and Compton, P. <b>Incremental</b> <b>Learning</b> of Control Knowledge for Lung Boundary Extraction. in Proceedings of the Pacific Knowledge Acquisition Workshop 2004. Auckland: University of Tasmania Eprints repository, p. 211-225, 2004.|$|E
5000|$|R. Polikar, L. Udpa, S. Udpa, and V. Honavar (2004). An <b>Incremental</b> <b>Learning</b> Algorithm with Confidence Estimation for Automated Identification of NDE Signals. IEEE Transactions of Ultrasonics, Ferroelectrics, and Frequency Control. Vol. 51. pp. 990-1001, 2004.|$|E
50|$|Many {{traditional}} {{machine learning}} algorithms inherently support <b>incremental</b> <b>learning,</b> other algorithms {{can be adapted to}} facilitate this. Examples of incremental algorithms include decisions trees (IDE4, ID5R), decision rules, artificial neural networks (RBF networks, Learn++, Fuzzy ARTMAP, TopoART, and IGNG) or the incremental SVM.|$|E
50|$|OPTIMOL (automatic Online Picture {{collection}} via <b>Incremental</b> MOdel <b>Learning)</b> {{approaches the}} problem of learning object categories from online image searches by addressing model learning and searching simultaneously. OPTIMOL is an iterative model that updates its model of the target object category while concurrently retrieving more relevant images.|$|R
30|$|Zhou et al. [49] {{describe}} how a Deep Learning algorithm {{can be used}} for <b>incremental</b> feature <b>learning</b> on very large datasets, employing denoising autoencoders [50]. Denoising autoencoders are a variant of autoencoders which extract features from corrupted input, where the extracted features are robust to noisy data and good for classification purposes. Deep Learning algorithms in general use hidden layers to contribute towards the extraction of features or data representations. In a denoising autoencoder, there is one hidden layer which extracts features, with the number of nodes in this hidden layer initially being the same as the number of features that would be extracted. Incrementally, the samples that do not conform to the given objective function (for example, their classification error is more than a threshold, or their reconstruction error is high) are collected and are used for adding new nodes to the hidden layer, with these new nodes being initialized based on those samples. Subsequently, incoming new data samples are used to jointly retrain all the features. This <b>incremental</b> feature <b>learning</b> and mapping can improve the discriminative or generative objective function; however, monotonically adding features can lead to having a lot of redundant features and overfitting of data. Consequently, similar features are merged to produce a more compact set of features. Zhou et al. [49] demonstrate that the <b>incremental</b> feature <b>learning</b> method quickly converges to the optimal number of features in a large-scale online setting. This kind of incremental feature extraction is useful in applications where the distribution of data changes with respect to time in massive online data streams. <b>Incremental</b> feature <b>learning</b> and extraction can be generalized for other Deep Learning algorithms, such as RBM [7], and makes it possible to adapt to new incoming stream of an online large-scale data. Moreover, it avoids expensive cross-validation analysis in selecting the number of features in large-scale datasets.|$|R
50|$|These {{properties}} are desirable, since a learning rule satisfying them is more biologically plausible. For example, since {{the human brain}} is always learning new concepts, one can reason that human <b>learning</b> is <b>incremental.</b> A <b>learning</b> system that were not incremental would generally be trained only once, with a huge batch of training data.|$|R
