11|10000|Public
50|$|The <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> it is {{extremely}} difficult to determine where, on the continuum of first order processes, type identity ends and merely token identities begin. Take Quine's example of English country gardens. In such gardens, the tops of hedges are cut into various shapes, for example the shape of an elf. We can make generalizations over the type elf-shaped hedge only if we abstract away from the concrete details of the individual twigs and branches of each hedge. So, whether we say that two things are of the same type or are tokens of the same type because of subtle differences {{is just a matter of}} descriptive abstraction. The type-token distinction is not all or nothing.|$|E
5000|$|Robert Holden and Tom Turner, in {{a review}} of the Olympic Park's {{landscape}} architecture [...] state that 'Our <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> [...] "the landscape planning is much better than the landscape design". The landscape planning includes the opening up of the River Lea in the northern section of the park, the habitat-creation strategy and the park's excellent links with its hinterland. The landscape design is dominated by vast pedestrian concourses which will be busy during events but will resemble unused airport runways on every other occasion. There is some good garden-type planting but it has not been used to make [...] "gardens": it is used more like strips of planting beside highways'.|$|E
5000|$|In 2008, Mosley won a {{court case}} (Mosley v News Group Newspapers) against the News of the World {{newspaper}} which had reported his involvement in a sex act involving five women {{on the grounds that}} it had breached his privacy. Justice Eady ruled that despite one of the attendees wearing a military uniform there were no Nazi connotations to the orgy. As a result, in 2009 Mosley brought a case (Mosley v United Kingdom) against the UK's privacy laws in the European Court of Human Rights, in a bid to force newspapers to warn people before exposing their private lives so they could have the opportunity to seek a court injunction. The case was rejected by the court on 10 May 2011 as they argued that a [...] "pre-notification requirement would inevitably affect political reporting and serious journalism." [...] In July 2011, The Daily Telegraph reported that Mosley was financially guaranteeing the court costs of claimants who may have been subjected to phone hacking by the News of the World. Mosley refused to comment at the time, but he later gave a TV interview to the BBC and telephone interview to Reuters where he confirmed the story. Mosley launched legal action against Google, in an attempt to stop searches from returning web pages which use the photographs from the video used for the News of the World story. On 6 November 2013 in Mosley v SARL Google a French court sided with Mosley and ordered Google to prevent its search engine from providing links to images of Mosley engaging in sexual activities from the video. The Register suggested the ruling would lead to a Streisand effect, increasing interest in the images, which are still findable through other search engines. At the Leveson Enquiry, Mosley stated his reasons for pursuing Google: [...] "the <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> Google could stop this material appearing but they don't, or they won't as a matter of principle. My position is that if the search engines - if somebody were to stop the search engines producing the material, the actual sites don't really matter because without a search engine, nobody will find it, it would just be a few friends of the person who posts it. The really dangerous things are the search engines." [...] Mosley launched similar legal action against Google in Germany. In January 2014, the German court also ruled against the American company. In giving its verdict, the court stated, [...] "that the banned pictures of the plaintiff severely violate his private sphere." ...|$|E
5000|$|Sullivan also {{asserts that}} Freire is: [...] "Uncompromisingly {{on the side}} of oppressed peoples everywhere, Freire {{promotes}} his philosophically dense ideas with the fervor of a revolutionary.” [...] Additionally, Collins makes a point to acknowledge that Freire [...] "makes profound apologies for apparent sexism in his earlier writings". [...] Shelli B. Fowler contends that Freire promoted teaching as acts of creativity--acts <b>that</b> should always <b>be</b> critical and never be mechanical. She also asserts that one of Freire's most <b>fundamental</b> <b>points</b> <b>was</b> <b>that</b> teachers need to teach students how to teach themselves.|$|R
5000|$|By late November 2007, with {{still more}} {{evidence}} that the surge and other tactics and developments had led to a significant lessening of the civil violence in Iraq, Clinton acknowledged the successes but said that the underlying equation had not changed: [...] "Our troops are {{the best in the}} world; if you increase their numbers they are going to make a difference. The <b>fundamental</b> <b>point</b> here <b>is</b> <b>that</b> the purpose of the surge was to create space for political reconciliation and that has not happened, and there <b>is</b> no indication <b>that</b> it <b>is</b> going to happen, or that the Iraqis will meet the political benchmarks. We need to stop refereeing their civil war and start getting out of it." ...|$|R
40|$|The {{thesis of}} this paper <b>is</b> <b>that</b> {{morphological}} templates {{have access to a}} richer variety of categories than the CV tier. Although foot and syllable reduplication had been suggested previously, here I have shown the need for templates—conditions on the form of words of particular morphological types—that refer to syllables in modern Hebrew and to feet in Cupeño. In the course of the analyses I have suggested a number of technical proposals: a specific version of the prosodic hierarchy, a procedure for expansion of morphological templates containing higher-level prosodic units, and another procedure for selecting the appropriate structure in case of ambiguity. Furthermore, morphological systems have emerged as a new source of evidence for the nature of prosodic categories, confirming in this case the need for syllables and feet as well as some details of their construction. The <b>fundamental</b> <b>point,</b> however, <b>is</b> <b>that</b> phonological theory and morphological theory must manipulate essentially the same units embedded in the same representational system...|$|R
40|$|If data {{availability}} were a simple problem, it would {{already have been}} resolved. In this paper, I argue that by viewing {{data availability}} as a public good, {{it is possible to}} both understand the complexities with which it is fraught and identify a path to a solution. 1 Data Availability as a Public Good Those who view data availability as a black-and-white issue—the purist view, as in the left-hand panel in Figure 1, are ignoring or attenuating not only reality, but also fundamental principles of economics and human behavior. Instead, data availability is composed of infinitely many shades of gray, as in the right-hand panel in Figure 1 —the realist view. My <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> data availability is a public good (Varian, 1992). As are other public goods, it is extremely complex. Strikingly, however, much of the current conversation about data availability ignores, in many cases willfully, this complexity. To purists who disagree, I submit that the empirical evidence is overwhelming. If data availability were a simple problem, it would have been resolved long ago. Solutions imposed by fiat are inefficient at best, and generally ineffective. Many proposals overlook the multiplicity of stakeholders (§ 3), as well as the complex, competing incentives to which they are subject...|$|E
40|$|This note {{describes}} {{my analysis}} of the measurement of the electron energy distribution function in a DC glow discharge reported by T. Kimura, K. Akatsuka, and K. Ohe, in `Experimental and theoretical investigations of DC glow discharges in argon-nitrogen mixtures,`J. Phys. D: Appl. Phys. 27 (1994) 1664 - 1671. T. Kimura of the Department of Systems Engineering at the Nagoya Institute of Technology sent me this paper in 1994, as well as `Electron Energy Distribution Function in Neon-Nitrogen Mixture Positive Column,` T. Kimura, and K. Ohe, Jpn. J. Appl. Phys. Vol. 3 1, Part 1, No. 12 A, December 1992, pp. 4051 - 4052. I base my analysis on the data for a pure N{sub 2 } discharge at p= 1 torr in the 1994 paper. Figures 2 and 3 in that paper show a discrepancy between f({epsilon}) as measured by Langmuir probing and f({epsilon}) as calculated from E/N {{based on the measured}} axial field. Kimura et. al. explain their observation of hotter than expected electrons on superelastic collisions with vibrationally excited nitrogen. My <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> the radial field generated by ambipolar diffusion significantly augments E/N above the contribution from the axial field in this experiment, and creates a higher than expected radially averaged electron energy...|$|E
40|$|A rather {{elementary}} {{family of}} local Hamiltonians H◦,ℓ,ℓ = 1, 2, 3, [...] ., is described for a 2 −dimensional quantum mechanical system of spin = 1 2 particles. On the torus, the ground state space G◦,ℓ is essentially infinite dimensional but may collapse under “perturbation ” to an anyonic {{system with a}} complete mathematical description: the quantum double of the SO(3) −Chern-Simons modular functor at q = e 2 πi/ℓ+ 2 which we call DEℓ. The Hamiltonian H◦,ℓ defines a quantum loop gas. We argue that for ℓ = 1 and 2, G◦,ℓ is unstable and the collapse to Gǫ,ℓ ∼ = DEℓ can occur truly by perturbation. For ℓ ≥ 3 G◦,ℓ is stable {{and in this case}} finding Gǫ,ℓ ∼ = DEℓ must require either ǫ> ǫℓ> 0, help from finite system size, surface roughening (see section 3), or some other trick, hence the initial use of quotes “ ”. A hypothetical phase diagram is included in the introduction. The effect of perturbation is studied algebraically: the ground state G◦,ℓ of H◦,ℓ is described as a surface algebra and our ansatz is that perturbation should respect this structure yielding a perturbed ground state Gǫ,ℓ described by a quotient algebra. By classification, this implies Gǫ,ℓ ∼ = DEℓ. The <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> nonlinear structure...|$|E
40|$|Abstract: Camera {{is widely}} used for 3 D-Reconstruction and Recognition where a <b>fundamental</b> task <b>is</b> <b>point</b> {{correspondence}} <b>that</b> finds the corresponding points captured by different cameras from the same 3 D-point. The approaches based on epipolar constraint are very effective for the task. However, they set the threshold of epipolar constraint by empirical method, and their complexity and computational cost will quickly increase with {{increasing the number of}} cameras. This paper proposes a novel two-step strategy using epipolar constraint regardless of the number of cameras in a uniform way. The strategy uses a statistic method to set the threshold, and decomposes the task of point correspondence in a multi-ocular system into the task of point correspondence in several binocular systems by transitivit...|$|R
40|$|This {{paper is}} a part of a series of works where we in detail examine the concept of Transverse Momentum Dependent (TMD), or k_T, factorization, which is {{frequently}} encountered in the literature and is widely used in the phenomenological applications of QCD at very high energies. We address the question of what exactly factorization is, as it is meant in different contexts and formalisms, and we compare the formalisms to each other. We clarify some basic concepts regarding factorization and how it exactly is applied in high energy QCD, and we make important notes on some key and <b>fundamental</b> <b>points</b> <b>that</b> <b>are</b> often overlooked. We offer an extensive analysis of single inclusive particle production, and we analyze the TMD gluon distribution that plays a pivotal role in high energy QCD. Comment: 80 pages v 2 : Few typos corrected, and references adde...|$|R
40|$|Interpretative {{research}} has many faces and can develop along many lines (Denzin, 1989 : 22), but a <b>fundamental</b> starting <b>point</b> <b>is</b> <b>that</b> the researcher should approach social reality with as few a priori's as possible. He has {{to discover the}} problems as they are experienced by the participants of the social scene. This principle creates a particular problem if the researcher has to give answers on questions as they are seen by the sponsor of the project. This {{was the case with}} our project. The project was proposed by the project leaders and accepted by the Minister of Education (National Foundation of Scientific Research) to be financed after screening of the proposal by a board of academics and senior civil servants. To understand the methodology of the project {{it is important to know}} the circumstances influencing the options of the project leaders. First, there was the research experience in relation to educational planned change. Since 1969 a national program to make secondary schools comprehensive, was set up. Later the innovation of elementary schools was started as well as the experimental introduction of health education in primary and secondary schools. These experiences and the vast literature about a school approach of educational and management problems had convinced the researchers that school administration should be studied on the level of the school. Moreover it <b>was</b> clear <b>that</b> the survey approach could not give the answers on problems of school administration because of the importance of the context in which school administration is happening. To get an illuminating picture of this context techniques of qualitative research are more fruitful than others. status: publishe...|$|R
40|$|This paper {{addresses}} {{the issue of}} whether establishing consensus standards for the treatment of particular medical conditions increases a physician's exposure to legal liability. The conclusion reached is that the legal effects of standard setting, rather than representing a significant threat of liability, should be seen as beneficial to the medical profession. A <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> the legal test for liability is entirely dependent on the medical profession's definition of what constitutes adequate care. The law incorporates the standard of care defined by the medical profession and does not impose an external norm. In the absence of formally stated standards, the process of defining relevant medical criteria will involve a great deal of uncertainty. Outcomes of legal contests will be affected by such extraneous factors as the relative experience of the lawyers involved, their access to knowledgeable expert witnesses, and their strategic decisions made with respect to tactics and procedures. Establishment of formal standards has the salutory effect of limiting the influence of these factors and thus reducing the randomness of the results reached. Formal standards also have the advantage of being easily replicated in unrelated proceedings and thereby {{contribute to the development of}} a consistent, evenly applied rule of liability. Finally, even if formal standards are either more, or less, progressive than the actual state of medical practice, there is relatively little risk that they will produce untoward results...|$|E
40|$|Various {{aspects of}} the {{experimental}} design and com-putational methods used in plant growth analysis were investigated. This was done either analytically, or by repeatedly simulating harvests from theoretical populations upon which were imposed the underlying growth curves {{as well as the}} variability in plant material. In the first part the consequences of neglecting an In-transformation of the primary weight data were con-sidered. T-tests are affected {{in such a way that}} signi-ficant differences between treatments show up less readily than in transformed data. A more <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> most hypotheses on plant weight concern proportional effects rather than absolute ones. In these cases, an In-transformation prior to a statistical test is required anyway. Secondly, the accuracy of average RGR estimates was evaluated. Variability in RGR estimation increases linearly with variability in the plant material. It is also strongly dependent on the time interval between harvests and the number of replicates per harvest. Even with conservative values for plant weight variability, the chances of arriving at aberrant RGR estimates are rather high. Therefore, it is suggested that the variability in the population is decreased deliberately, unless variability within the population is itself of biological interest. Thirdly, three computational methods to fit dry weight progressions and describe time trends in RGR and related growth parameters were evaluated. Although complicated to calculate, the Richards function was superior to poly-nomials fitted through either the weight data ('poly-nomial ' approach), or the classically derived RGR values ('combined ' approach). Key words: Plant growth analysis, experimental design, computational methods, relative growth rate, net assimila-tion rate...|$|E
40|$|Abstract. I revisit a known {{solution}} of the Einstein field equations {{to show that it}} describes the formation of non-spherical black holes by the collapse of pure electromagnetic monochromatic radiation. Both positive and negative masses are feasible without ever violating the dominant energy condition. The solution {{can also be used to}} model the destruction of naked singularities and the evaporation of white holes by emission or reception of light. PACS numbers: 04. 70. Bw, 04. 40. Nr, 04. 20. Jb Today there are many models describing the formation, or the evaporation, of black holes in General Relativity, some of them deal with the collapse of matter or fluids, others with out- or in-coming “incoherent radiation”. However, there is no identified case of the formation/evaporation of a black hole by means of electromagnetic radiation solely. The purpose of this sort Note is to call attention to a family of solutions which describe the formation/destruction of black holes (also naked singularities) by reception or emission of pure monochromatic light. Actually, the solution is known since long ago, and has been used to describe the collapse of null dust to non-spherical black holes with negative cosmological constant [13, 14], and to analyze the first example of a dynamical horizon with toroidal topology [5]. However, the <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> the radiation can be properly identified as monochromatic light —it should not be treated as “incoherent radiation”. The line-element of the solution was first presented —among many other exact solutions — by Robinson and Trautman in their celebrated paper [22], and is given in local coordinates {u, r, x, y} by (see also [24], p. 430) ds 2 = r 2 (dx 2 + dy 2) + 2 dvdr...|$|E
40|$|The {{purpose of}} this paper is to {{describe}} a better way to go about the enterprise of altering the behavior of drivers, where far less progress has been made than in the engineering of safer roads and vehicles. In thinking about doing so, the concept “traffic-safety culture ” is quite appropriate. In a sense, this paper presents the argument that a traffic-safety culture should involve a reordered set of values, different beliefs from those <b>that</b> <b>are</b> now common, and, as a consequence, altered norms for appropriate behavior of its members. This applies whether the notion of a traffic-safety culture is narrowly constrained to professionals working in the traffic-safety domain or is more broadly defined to incorporate much of the population of a nation. The <b>fundamental</b> <b>point</b> presented here <b>is</b> <b>that</b> to reduce traffic-related deaths and injuries, we must take a far more enlightened approach to developing and implementing programs and policies than is presently the case. To achieve meaningful declines will require taking advantage of the vast stores of scientific understanding <b>that</b> <b>are</b> currently overlooked. The following paper includes a brief description of how we presently operate, why the current approach works poorly, why it occasionally succeeds, a listing of several pertinent well-established fundamental principles of human behavior, and a suggestion for how we can do better in the future...|$|R
40|$|Collapse therapy, as a term, embraces {{a variety}} of {{procedures}} and has developed rapidly in recent years. The literally enormous number of publications upon the subject testifies to the interest in it. The naturally radical see in it the greatest therapeutic advance of the century, while even the most conservative concede it a great step in advance. No one dealing with pulmonary tuberculosis can ignore it. Controversy still reigns on some points; is silenced on others. How {{the various forms of}} collapse therapy work their effect physiologically, whether through an influence on the pulmonary lymphatics or circulation, is not settled. On the mechanical side, however, there is considerable agreement. The diseased lung is subject to tension and trauma owing to its enforced apposition to the moving chest wall. Cavities are held open, fibrous scar tissue cannot contract beyond a limited degree. Both stretch and contract with respiration. Collapse procedures change the condition from tension to relaxation, permit the retraction of scar tissue and the closure of cavities, lessen respiratory trauma, and thereby greatly aid nature in the healing process. None of these surgical measures heals in itself, although with their help nature can and does heal more quickly and more effectively. A patient may, with a successful pneumothorax, lose his symptoms, close a cavity, and be outwardly well in a few weeks, but the healing process is only begun. The <b>fundamental</b> <b>point</b> must <b>be</b> stressed <b>that</b> all collapse or compression methods are merely adjuvants to the old, time-tried therapy of rest. They are designed to increase the lung rest and render it more effective. They do not replace other forms of lung rest. Speaking in a very general way, one may say that pulmonary tuberculosis assumes two forms: the exudative form in which the pathology is more pneumonic in character, and the productive for...|$|R
40|$|The present {{recommendation}} summons up {{matter from}} {{a project in}} progress, concerning the possibilities and conditions of founding a Social Geographical Information System (GIS) in the Municipality of Rhodes. It <b>is</b> argued <b>that,</b> {{on the level of}} local societies and their self-administration, the importance of GIS can prove decisive for the rational management of resources and mainly for a better service of the citizens. Local governments, being that very institution at the closest possible relationship and contact with the resident-citizen, are called to cope with a constantly expanding spectrum of functions and services, often with insufficient infrastructures and limited resources. Today’s stage of the applied development of the GIS technology permits an overall arrangement and regulation of a series of functions <b>that</b> <b>are</b> important elements of everyday life in a city. In this sense, the use of GIS, although in the beginning seems as an â€œunnecessary luxuryâ€ for Greek administrational matters, can contribute in a creative way to the realization of the institutional role of local government organizations, to the accomplishment of the declared goals of each municipal authority but also to the saving of time and expenses. However, beyond the applications of GIS related to the improvement of a city’s functions, and which are the most frequent, there is a whole constellation of additional uses <b>that</b> <b>are</b> often downgraded or ignored. It is about those dimensions and applications, during which the GIS are utilized as an implement of social studies and search, as a mechanism of tendency diagnosis, {{as a starting point for}} awareness on the problems of urban areas and of their residents. It is the perspective and necessity of such applications <b>that</b> we <b>are</b> trying not to downgrade in the present, initial stage of development of a â€œSocial GIS for the Municipality of Rhodesâ€. Our <b>fundamental</b> <b>point</b> of view <b>is</b> <b>that</b> no modern â€œleading-edgeâ€ technology, no advanced implement is by itself a panacea. It can simply assist the development procedures, when it is in the right hands and with the appropriate staff, information and infrastructure. Procedures that have finally reference to the level of central or local political choices but also to the disposition, dynamic or not dynamic, of the body politic for interference and action. ...|$|R
40|$|Solar systems, {{stars and}} planets form from an initial cloud of dust and gas. But the gas {{is not in a}} neutral inert state. It is {{partially}} ionized. Some atoms, due to cosmic rays, radiation and other processes have been separated into free electrons and free nuclei. The interaction of the dust with such an environment {{is one of the most}} important aspects in the formation of {{stars and planets}} and on their properties. As the electrons move faster than the nuclei (by virtue of their much lighter mass), more electrons reach the dust than nuclei. Thereby the dust charges negatively. Seemingly this would prevent the dust from attracting (by gravity) and disrupting further congragation. However, under special conditions the process can be eliminated and the attraction of dust can be re-enabled. But where and in what conditions? Where does the dust congregate? Examples are of course terrestrial planets (that unlike gaseous giants are formed ultimately from dust) and cometary clouds (a misnomer that ought not to be mistaken for comets as they are instead hugely larger and the nursery for new solar systems with the famous Hubble picture of the Eagle nebula showing such "lumps") A <b>fundamental</b> <b>point</b> <b>is</b> <b>that</b> the charging of the dust and the ionization of the gas depend crucially on the ultraviolet radiation emitted by other young forming stars. So depending on the specifics of the mechanisms the dust can accrete more rapidly. We will focus especially on the recent discovery [1] of a new attraction mechanism among dust particles in presence of light-stimulated emission (photo-emission). This mechanism can promote gravitational collapse [2]. The presentation will investigate the role of the dust in the formation of solar systems, exploring both the formation of stars and planets and focusing on the mechanisms for dust interaction. status: publishe...|$|E
40|$|This {{dissertation}} examines E. E. Cummings's writings in the sonnet genre and {{in those}} genres to which the sonnet is related in various ways. Its <b>fundamental</b> <b>point</b> <b>is</b> <b>that,</b> despite the surface impression of poetic iconoclasm for which Cummings has a popular reputation, in choosing to write sonnets he engages in a traditional literary practice. He does this because his purpose is always to be an artist, {{as defined by the}} Aesthetic movement which influenced him. In order to argue his embracing of a traditional artistic role, the theory of genres espoused by Alastair Fowler in his book, Kinds of Literature, is used. Chapter 1 of the thesis comprises general introductory material, both to the range of Aesthetic ideas to which Cummings subscribed, and to Fowler's theory of genres. Several key generic kinds are also described. The second chapter makes use of two of these generic models, the sonnet sequence and the silva, as a way of examining Cummings's deployment of the sonnet within the larger context of his poetry collections. It is a survey {{of the structure of the}} anthologies he compiled from Tulips & Chimneys (1922) to 95 Poems (1958). The third chapter explores the three sonnet modes which Cummings first identifies and names when compiling the manuscript of Tulips & Chimneys, and continues to use in his collections up to and including is 5 (1926). Chapter 4 shows how certain themes and concerns from these early sonnets are altered and synthesised as Cummings matures from an aesthete to a Romantic poet. Sonnets from his later books are taken to be representative of three central kinds in all of his work after is 5. Chapters 3 and 4 proceed by means of relatively close readings of individual sonnets. This practice fulfils a double role: it penetrates the apparent obscurity of the more difficult poems, and it attempts to preserve the integrity of individual poems which exemplify different generic tendencies in Cummings's work. One of Cummings's reasons for writing sonnets is that the form favours the achievement of what Wordsworth calls "a feeling of intense unity". In undertaking close readings of a few sonnets I have attempted to preserve that feeling. ...|$|E
50|$|Genjōkōan (現成公按) {{sometimes}} {{translated as}} Actualizing the <b>Fundamental</b> <b>Point</b> <b>is</b> an influential essay written by Dōgen, {{the founder of}} Zen Buddhism's Sōtō school in Japan. It {{is considered one of}} the most popular essays in Shōbōgenzō.|$|R
50|$|Handicap go is the {{traditional}} form of teaching given to go players. Fixed handicap placements are in effect a form of graded tutorials: if you cannot beat your teacher with a nine-stone handicap, some <b>fundamental</b> <b>points</b> <b>are</b> still to be learned.|$|R
50|$|Also, precise azimuths {{to one or}} two network <b>points</b> <b>are</b> observed, and {{are taken}} over as orientated {{directions}} of these network lines. By these procedure, the polar axis of the reference ellipsoid becomes parallel to the Earth rotation axis, and therefore the vertical deflection of the <b>fundamental</b> <b>point</b> <b>is</b> zero.|$|R
40|$|This paper {{describes}} the activities {{carried out in}} order to estimate the distance traveled by the neutrinos beam between CERN and LNGS with an accuracy better than 1 meter. In particular, the distance between two <b>fundamental</b> <b>points</b> has <b>been</b> estimated: the start point at CERN (de ned as T- 40 -S-CERN) and the OPERA detector point (de ned as A 1 - 9999). The measurements campaings, at CERN and at LNGS, were performed using both terrestrial and Global Positioning System (GPS) based geodetic techniques. The positions of the two <b>fundamental</b> <b>points</b> <b>were</b> estimated in a common reference frame through the processing of the collected observations. The resulting distance (730534. 610 m) was estimated with an accuracy {{at the level of}} 20 cm, remarkably better than the stated limit...|$|R
50|$|In Dzogchen, a <b>fundamental</b> <b>point</b> of {{practice}} <b>is</b> to distinguish rigpa from sems (mind).|$|R
50|$|Eggen has {{mentioned}} {{the inspiration of}} Dutch total football and Rinus Michels for his own work. A <b>fundamental</b> <b>point</b> <b>was</b> the subordination of individuals (the parts) to the whole, so that the whole could outperform the sum of talents of all its players. Often he has used {{the metaphor of the}} Rosenborg rhythm to get his message across. He has had a focus on quick and massive counter-attacks and the building of an offensive attitude in the team. The 4-3-3 system played vital parts in Eggen's philosophy as a coach.|$|R
50|$|If f:X&rarr;Y is a birational {{transformation}} of projective varieties with Y normal, then the total transform of a <b>fundamental</b> <b>point</b> of f <b>is</b> connected and of dimension at least 1.|$|R
5000|$|The pedagogic {{value of}} fixed {{handicap}}s {{is an old}} debate for Western players. The [...] "theory" [...] of handicap go shares {{with much of the}} rest of the Japanese pedagogic go literature a less explicit approach, based on perception as much as analysis. Whether fixed handicap placement makes it easier or more difficult for the weaker player to learn these <b>fundamental</b> <b>points</b> <b>is</b> moot. The nature of these [...] "tutorial" [...] steps may certainly be misunderstood and contested by Western players new to the game. Handicaps are also unpopular with Chinese players, who have more of a tradition of equality at the board rather than deference to a teacher.|$|R
5000|$|It <b>was</b> {{later found}} <b>that</b> the actual island of El Hierro itself {{is in fact}} 20° 23 9" [...] west of Paris, but the Ferro {{meridian}} was still defined as 20 degrees west of Paris.According to the European longitude adjustment of Carl Theodor Albrecht (ca. 1890) the Ferro meridian is 17° 39 46.02" [...] west of the Greenwich meridian. But for the geodetic networks of Austria, Germany and Czechoslovakia, the value 17° 40 00" [...] was adopted in the 1920s, not only for practical reasons but also as it <b>was</b> discovered <b>that</b> the longitude of the Berlin (Rauenberg) <b>fundamental</b> <b>point</b> <b>was</b> miscalculated by 13.39". For the geodetic networks of Hungary and Yugoslavia, the value of Albrecht was used prior to the switch to the Greenwich prime meridian.|$|R
40|$|This study {{aimed to}} {{describe}} the shape of local government actions in tackling illegal fishing in Aceh, the handling of illegal fishing destructive fishery resources. The <b>fundamental</b> <b>point</b> <b>is</b> Law No. 45 Year 2009 concerning fisheries. This spesification of this research descriptive analysis, used both normative juridical approach and empirical. The {{results showed that the}} local government has made an effort preventive and repressive in the case of illegal fishing. To coordinate with relevant agencies and empower the role of traditional institutions of the sea to assist the role of government and law enforcement. Local governments should improve the coordination and supervision of the marine area, to monitor and evaluate the performance of local authorities in applying the law against this illegal fishing case...|$|R
40|$|In the {{intervention}} at the Environment Commission of the Senate {{on the problems}} of the sustainable development, following the recent World Summit in Johannesburg, some <b>fundamental</b> <b>points</b> <b>are</b> underpinned: the question is summed up and an exam is made about the results of the Summit and on the meaning of the commitments taken for the future. Indeed, it <b>is</b> universally accepted <b>that,</b> to <b>be</b> considered sustainable, the development must reach a compromise between economical, social and environmental goals, to maximize the present well-being, without challenging the right of future generations to satisfy their own needs. It <b>is</b> also accepted <b>that</b> this cannot <b>be</b> realised without defence for our eco-system and without a simultaneous and well coordinated intervention of all Countries and the participation of all productive and social categories; probably, this should be the true finality of the so much acclaimed “globalisation”...|$|R
3000|$|... (j) on {{the same}} factors. The <b>fundamental</b> <b>point</b> <b>that</b> we <b>are</b> making here relates to the {{distinction}} between individual and group risks; {{for a discussion of}} this and how it applies to epidemiology and genetics (including a discussion of cancer), see [7].|$|R
2500|$|The left-of-center/liberal-leaning Urban Institute (UI) largely {{agreed with}} Moore {{regarding}} {{the need for}} a universal health care system and failure of the current system. Urban Institute economist Linda Blumberg stated that Moore correctly provides evidence that the current system fails and a universal system <b>is</b> needed, adding <b>that</b> any system will face budget constraints. Overall, Blumberg stated that [...] "Americans as a whole have yet to buy the philosophy <b>that</b> health care <b>is</b> a right and not a privilege" [...] and if Moore succeeded in popularizing the idea, he [...] "will have done the country a tremendous service." [...] Bradford Gary agrees with the main points made by Moore but criticizes the film for making various omissions and lacking attention to detail, stating that [...] "though Moore is not interested in the details behind the outrages he has assembled, many of his <b>fundamental</b> <b>points</b> <b>are</b> nevertheless accurate." ...|$|R
40|$|In {{complexity}} theory, {{there exists}} a famous unsolved problem whether NP can be P or not. In this paper, we discuss this aspect in SAT (satisfiability) problem, and it <b>is</b> shown <b>that</b> the SAT can be solved in plynomial time by means of quantum algorithm. 1 Introduction Although the ability of computer is highly progressed, there are several problems {{which may not be}} solved effectively, namely, in polynomial time. Among such problems, NP problem and NP complete problem are fundamental. It <b>is</b> known[5] <b>that</b> all NP complete problems are equivalent and an essential question is whether {{there exists a}}n algorithm to solve a NP complete problem in polynomial time. After pioneering works of Feymann[4] and Deutsch[1], several important works have been done on quantum algorithms by Deutsch and Jozsa[2], Shor[7], Ekert and Jozsa[3] and many others[6]. The computation in quantum computer is performed on a tensor product Hilbert space, and its <b>fundamental</b> <b>point</b> <b>is</b> to use quantum coherence of states. A [...] ...|$|R
40|$|Regional {{development}} policy perspectives have changed considerably {{in the past}} 25 years. One can distinguish three generations of theories informing policy practices. The first generation of regional policy emerged in the 50 s and 60 s. A <b>fundamental</b> <b>point</b> of departure <b>was</b> the fact <b>that</b> economic growth did not occur simultaneously throughout a territory but tha...|$|R
5000|$|Hamza Yusuf said, [...] "In the Christian {{narrative}} {{the most}} central and <b>fundamental</b> <b>point</b> of Christianity <b>is</b> {{the death and}} resurrection of Jesus Christ but Islam basically denies that. The Quran states <b>that</b> it <b>was</b> made to appear <b>that</b> Jesus <b>was</b> crucified as when the Romans captured Jesus God organised a rescue operation." ...|$|R
