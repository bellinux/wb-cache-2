5576|10000|Public
5|$|A {{weather map}} {{displays}} various meteorological features across {{a particular area}} at a particular point in time and has various symbols which all have specific meanings. Such maps have been in use since the mid-19th century and are used for research and weather forecasting purposes. Maps using isotherms show temperature gradients, which can help locate weather fronts. Isotach maps, analyzing lines of equal wind speed, on a constant pressure surface of 300 or 250hPa show where the jet stream is located. Use of constant pressure charts at the 700 and 500hPa level can indicate tropical cyclone motion. Two-dimensional streamlines based on wind speeds at various levels show areas of convergence and divergence in the wind field, which are helpful in determining the location of features within the wind pattern. A popular type of surface weather map is the surface weather analysis, which plots isobars to depict areas of high pressure and low pressure. Cloud codes are translated into symbols and plotted on these maps along with other meteorological <b>data</b> <b>that</b> <b>are</b> included in synoptic reports sent by professionally trained observers.|$|E
25|$|It aims {{at using}} input <b>data</b> <b>that</b> <b>are</b> {{generally}} available, or {{that can be}} estimated with reasonable accuracy, or that can be measured with relative ease. Although the calculations are done numerically {{and have to be}} repeated many times, the final results can be checked by hand using the formulas in the manual.|$|E
25|$|These {{applications}} demonstrate {{delving into}} {{aspects of the}} <b>data</b> <b>that</b> <b>are</b> hidden from shallow learning networks and the human senses, {{such as in the}} cases of predicting onset of sleep apnea events, of an electrocardiogram of a fetus as recorded from skin-surface electrodes placed on the mother's abdomen early in pregnancy, of financial prediction or in blind filtering of noisy speech.|$|E
50|$|<b>Data</b> <b>that</b> <b>is</b> closed (only {{accessible}} by its subject, owner or holder); <b>data</b> <b>that</b> <b>is</b> shared (with named access - <b>data</b> <b>that</b> <b>is</b> shared only with named people or organisations,group-based access - <b>data</b> <b>that</b> <b>is</b> available to specific groups who meet certain criteria, and public access - <b>data</b> <b>that</b> <b>is</b> {{available to anyone}} under terms and conditions <b>that</b> <b>are</b> not ‘open’); and <b>data</b> <b>that</b> <b>is</b> open (<b>data</b> <b>that</b> anyone can access, use and share).|$|R
50|$|In cryptography, {{a secure}} channel {{is a way}} of {{transferring}} <b>data</b> <b>that</b> <b>is</b> resistant to overhearing and tampering. A confidential channel {{is a way of}} transferring <b>data</b> <b>that</b> <b>is</b> resistant to overhearing (i.e., reading the content), but not necessarily resistant to tampering. An authentic channel is a way of transferring <b>data</b> <b>that</b> <b>is</b> resistant to tampering but not necessarily resistant to overhearing.|$|R
5000|$|Data Use Analyser. This {{separates}} the variables and parameters {{used by the}} program into distinct classes depending upon their use. (i.e. <b>Data</b> <b>that</b> <b>is</b> read before being written, <b>Data</b> <b>that</b> <b>is</b> written without being read or <b>Data</b> <b>that</b> <b>is</b> written twice without an intervening read). The report can identify errors such as uninitialised data and function outputs not written on all paths.|$|R
25|$|There {{are five}} main types of {{experimental}} <b>data</b> <b>that</b> <b>are</b> {{used for the}} determination of solution equilibrium constants. Potentiometric data obtained with a glass electrode are {{the most widely used}} with aqueous solutions. The others are Spectrophotometric, Fluorescence (luminescence) measurements and NMR chemical shift measurements; simultaneous measurement of K and ΔH for 1:1 adducts in biological systems is routinely carried out using Isothermal Titration Calorimetry.|$|E
25|$|Many {{graphics}} programs (such as Apple's Preview software) save PNGs {{with large}} amounts of metadata and color-correction <b>data</b> <b>that</b> <b>are</b> generally unnecessary for Web viewing. Unoptimized PNG files from Adobe Fireworks are also notorious for this since they contain options to make the image editable in supported editors. Also CorelDRAW (at least version 11) sometimes produces PNGs which cannot be opened by Internet Explorer (versions 6–8).|$|E
25|$|Not every {{successful}} {{reading of}} a tag (an observation) {{is useful for}} business purposes. A large amount of data may be generated that is not useful for managing inventory or other applications. For example, a customer moving a product from one shelf to another, or a pallet load of articles that passes several readers while being moved in a warehouse, are events that do not produce <b>data</b> <b>that</b> <b>are</b> meaningful to an inventory control system.|$|E
5000|$|Auditing, then, {{would involve}} <b>data</b> <b>that</b> <b>is</b> not {{immediately}} discardable. In other words: <b>data</b> <b>that</b> <b>is</b> {{assembled in the}} auditing process, is stored persistently, is protected by authorization schemes and is, always, connected to some end-user functional requirement.|$|R
40|$|Data {{warehouses}} using {{a multidimensional}} view of data {{have become very}} popular in both business and science in recent years. Data warehouses for scientific purposes such as medicine and bio-chemistry pose several great challenges to existing data warehouse technology. Data warehouses usually use pre-aggregated data to ensure fast query response. However, pre-aggregation cannot be used in practice if the dimension structures or the relationships between facts and dimensions are irregular. A technique for overcoming this limitation and some experimental results are presented. Queries over scientific data warehouses often need to reference <b>data</b> <b>that</b> <b>is</b> external to the data warehouse, e. g., <b>data</b> <b>that</b> <b>is</b> too complex to be handled by current data warehouse technology, <b>data</b> <b>that</b> <b>is</b> "owned" by other organizations, or <b>data</b> <b>that</b> <b>is</b> updated frequently. An exampl...|$|R
50|$|Telecom data {{intelligence}} (TDI), is {{the ability}} of a telco (mobile operator and/or fixed line carrier), to extract detailed customer-profiling data from the <b>data</b> <b>that</b> <b>is</b> generated in the network combined with the <b>data</b> <b>that</b> <b>is</b> collected directly from the customers, by engaging customers online through an enhanced VAS customer experience.|$|R
25|$|Twin studies {{reveal the}} {{importance}} of environmental and genetic influences for traits, phenotypes, and disorders. Twin research is considered a key tool in behavioral genetics and in content fields, from biology to psychology. Twin studies {{are part of the}} broader methodology used in behavior genetics, which uses all <b>data</b> <b>that</b> <b>are</b> genetically informative – siblings studies, adoption studies, pedigree, etc. These studies have been used to track traits ranging from personal behavior to the presentation of severe mental illnesses such as schizophrenia.|$|E
25|$|Two main {{statistical}} methods {{are used in}} data analysis: descriptive statistics, which summarize data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draw conclusions from <b>data</b> <b>that</b> <b>are</b> subject to random variation (e.g., observational errors, sampling variation). Descriptive statistics are most often concerned with two sets of properties of a distribution (sample or population): central tendency (or location) seeks to characterize the distribution's central or typical value, while dispersion (or variability) characterizes {{the extent to which}} members of the distribution depart from its center and each other. Inferences on mathematical statistics are made under the framework of probability theory, which deals with the analysis of random phenomena.|$|E
25|$|Neuroimaging is {{controversial}} in whether it provides specific patterns unique to neuroborreliosis, but may aid in differential diagnosis and {{in understanding the}} pathophysiology of the disease. Though controversial, some evidence shows certain neuroimaging tests can provide <b>data</b> <b>that</b> <b>are</b> helpful in the diagnosis of a patient. Magnetic resonance imaging (MRI) and single-photon emission computed tomography (SPECT) {{are two of the}} tests that can identify abnormalities in the brain of a patient affected with this disease. Neuroimaging findings in an MRI include lesions in the periventricular white matter, as well as enlarged ventricles and cortical atrophy. The findings are considered somewhat unexceptional because the lesions {{have been found to be}} reversible following antibiotic treatment. Images produced using SPECT show numerous areas where an insufficient amount of blood is being delivered the cortex and subcortical white matter. However, SPECT images are known to be nonspecific because they show a heterogeneous pattern in the imaging. The abnormalities seen in the SPECT images are very similar to those seen in people with cerebral vacuities and Creutzfeldt–Jakob disease, which makes them questionable.|$|E
50|$|Secondary data {{refers to}} <b>data</b> <b>that</b> <b>was</b> {{collected}} by {{someone other than}} the user. Common sources of secondary data for social science include censuses, information collected by government departments, organisational records and <b>data</b> <b>that</b> <b>was</b> originally collected for other research purposes. Primary data, by contrast, are collected by the investigator conducting the research.|$|R
5000|$|Data classification: {{discussions in}} the {{communities}} can set out how different types of data can be used - for example a traffic light system can define ‘red’ <b>data</b> <b>that</b> <b>is</b> confidential to the community, ‘amber’ data which should be discussed prior to any use, and ‘green’ <b>data</b> <b>that</b> <b>is</b> approved for release.|$|R
50|$|Dynamic XML means dynamic <b>data</b> <b>that</b> <b>is</b> in an XML format.|$|R
25|$|In {{response}} to aforementioned shortcoming in the tsunami warning system, JMA have started investigation in year 2011 and updated their system in 2013. In the updated system, for powerful earthquake with possibility {{to cause the}} JMA magnitude scale to saturate, no quantitative prediction will be released in the initial warning, and instead there will be words that describe the situation's emergency. It have been planned to install new teleseismometers with ability to measure larger earthquake to prevent the inability to calculate moment magnitude scale in timely manner. A simpler empirical method to integrate data from GPS tidal meter as well as undersea water pressure meter into tsunami warning have been deployed, {{and there are also}} plan to install more of these meters and develop further technology to utilize data observed from them. To prevent under-reporting tsunami height, early quantitative observation <b>data</b> <b>that</b> <b>are</b> smaller than expected amplitude will be overridden and public will instead get told the situation is under observation.An additional report on possibility of tsunami about 90 seconds after earthquakes will also be included into observation report in order to warn people before JMA magnitude can be calculated.|$|E
25|$|Standard {{tools to}} {{simulate}} sequence evolution along trees such as INDELible or PhyloSim {{can be adapted}} to simulate HGT. HGT events cause the relevant gene trees to conflict with the species tree. Such HGT events can be simulated through subtree pruning and regrafting rearrangements of the species tree. However, it is important to simulate <b>data</b> <b>that</b> <b>are</b> realistic enough to be representative of the challenge provided by real datasets, and simulation under complex models are thus preferable. A model was developed to simulate gene trees with heterogeneous substitution processes in addition to the occurrence of transfer, and accounting for the fact that transfer can come from now extinct donor lineages. Alternatively, the genome evolution simulator ALF directly generates gene families subject to HGT, by accounting for a whole range of evolutionary forces at the base level, but {{in the context of a}} complete genome. Given simulated sequences which have HGT, analysis of those sequences using the methods of interest and comparison of their results with the known truth permits study of their performance. Similarly, testing the methods on sequence known not to have HGT enables the study of false positive rates.|$|E
2500|$|... where x and y are the {{positions}} on the x-xaxis of two bands in the original <b>data</b> <b>that</b> <b>are</b> subject to intensity changes.|$|E
5000|$|Find any {{associated}} <b>data</b> <b>that</b> <b>is</b> {{needed to}} process the instruction ...|$|R
5000|$|Collecting {{relevant}} <b>data</b> <b>that</b> <b>is</b> {{useful for}} the organization as knowledge ...|$|R
50|$|The {{level of}} {{measurement}} {{is the type}} of <b>data</b> <b>that</b> <b>is</b> measured.|$|R
2500|$|Clustering – is {{the task}} of {{discovering}} groups and structures in the <b>data</b> <b>that</b> <b>are</b> {{in some way or}} another [...] "similar", without using known structures in the data.|$|E
2500|$|Attributes are {{entities}} of <b>data</b> <b>that</b> <b>are</b> {{stored as}} metadata in the compiled assembly. An attribute {{can be added}} to types and members like properties and methods. Attributes [...] better maintenance of preprocessor directives.|$|E
2500|$|According to the Encyclopedia of Islam, the [...] "Qur'an {{responds}} {{constantly and}} often candidly to Muhammad's changing historical circumstances and contains {{a wealth of}} hidden <b>data</b> <b>that</b> <b>are</b> relevant {{to the task of}} the quest for the historical Muhammad." [...] In contrast, Solomon A. Nigosian writes that the Quran tells us very little about the life of Muhammad.|$|E
5000|$|Drop any <b>data</b> <b>that</b> <b>is</b> {{within one}} {{standard}} deviation ± average band ...|$|R
5000|$|Among the <b>data</b> <b>that</b> <b>is</b> {{required}} to file an EEI includes the following: ...|$|R
5000|$|Centering {{the data}} entails demeaning each {{component}} of the input <b>data</b> , <b>that</b> <b>is,</b> ...|$|R
2500|$|The Soviet Union {{was also}} {{interested}} in the Arctic and established a significant presence there by continuing the North-Pole drifting stations. [...] This program operated continuously, with 30 stations in the Arctic from 1950 to 1991. [...] These stations collected <b>data</b> <b>that</b> <b>are</b> valuable to this day for understanding the climate of the Arctic Basin. [...] shows the location of Arctic research facilities during the mid-1970s and the tracks of drifting stations between 1958 and 1975.|$|E
2500|$|There is {{a general}} {{perception}} that statistical knowledge is all-too-frequently intentionally misused by finding ways to interpret only the <b>data</b> <b>that</b> <b>are</b> favorable to the presenter. A [...] mistrust and misunderstanding of statistics {{is associated with the}} quotation, [...] "". Misuse of statistics can be both inadvertent and intentional, and the book How to Lie with Statistics outlines a range of considerations. In an attempt to shed light on the use and misuse of statistics, reviews of statistical techniques used in particular fields are conducted (e.g. Warne, Lazo, Ramos, and Ritter (2012)).|$|E
2500|$|A {{study by}} the Potomac Institute concluded; [...] "Based on the {{available}} evidence, and on accepted criteria for defining product risk vs. efficacy, we believe that when stun technology is appropriately applied, it is relatively safe and clearly effective. The only known field <b>data</b> <b>that</b> <b>are</b> available suggest that the odds are, at worst, one in one thousand that a stun device would contribute to (and this does not imply “cause”) death. This figure is likely not different than the odds of death when stun devices are not used, but when other multiple force measures are. A more defensible figure is one in one hundred thousand." ...|$|E
5000|$|Least-squares {{spectral}} analysis, for computing periodograms in <b>data</b> <b>that</b> <b>is</b> not {{equally spaced}} ...|$|R
5000|$|Online {{datastore}} - Use the SaaS {{platform to}} store <b>data</b> <b>that</b> <b>is</b> extracted ...|$|R
40|$|A {{system was}} {{developed}} to provide a new mechanism {{for members of the}} mission community to create and contribute new science data {{to the rest of the}} community. Mission tools have allowed members of the mission community to share first order <b>data</b> (<b>data</b> <b>that</b> <b>is</b> created by the mission s process in command and control of the spacecraft or the <b>data</b> <b>that</b> <b>is</b> captured by the craft itself, like images, science results, etc.). However, second and higher order <b>data</b> (<b>data</b> <b>that</b> <b>is</b> created after the fact by scientists and other members of the mission) was previously not widely disseminated, nor did it make its way into the mission planning process...|$|R
