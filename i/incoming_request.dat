97|543|Public
50|$|An <b>incoming</b> <b>request</b> for a client-client {{connection}} {{cannot be}} linked with an actual connection.|$|E
50|$|An <b>incoming</b> <b>request</b> for a client-client {{connection}} {{is linked to}} an actual connection, {{with the use of}} a token.|$|E
50|$|The kube-proxy is an {{implementation}} of a network proxy and a load balancer, and it supports the service abstraction along with other networking operation. It is responsible for routing traffic to the appropriate container based on IP and port number of the <b>incoming</b> <b>request.</b>|$|E
5000|$|HandlerAdapter: {{execution}} {{of objects that}} handle <b>incoming</b> <b>requests</b> ...|$|R
5000|$|MultipartResolver: {{facilitate}} {{working with}} file uploads by wrapping <b>incoming</b> <b>requests</b> ...|$|R
30|$|Bin packing [11] (BP), where hosting {{and network}} {{requirements}} are mapped using a Bin per type of media cloud resource. The Bin packing in [11] introduces {{a method for}} forming and classifying Bins based on the resources available. Using the information of Bin classification, the <b>incoming</b> <b>requests</b> are mapped accordingly. The pseudo code for mapping of <b>incoming</b> <b>requests</b> using Bin packing is shown in Algorithm 1.|$|R
5000|$|A reverse proxy can {{distribute}} the load from incoming requests to several servers, with each server serving its own application area. In {{the case of}} reverse proxying {{in the neighborhood of}} web servers, the reverse proxy may have to rewrite the URL in each <b>incoming</b> <b>request</b> in order to match the relevant internal location of the requested resource.|$|E
5000|$|Reverse proxies {{can operate}} {{wherever}} multiple web-servers must be accessible via a single public IP address. The web servers listen on different ports {{in the same}} machine, with the same local IP address or, possibly, on different machines and different local IP addresses altogether. The reverse proxy analyzes each <b>incoming</b> <b>request</b> and delivers it to the right server within the local area network.|$|E
50|$|Traditional model-view-controller (MVC) {{frameworks}} work {{in terms}} of whole requests and whole pages. In each request cycle, the <b>incoming</b> <b>request</b> is mapped to a method on a controller object, which then generates the outgoing response in its entirety, usually by pulling data out of a model to populate a view written in specialized template markup. This keeps the application's flow-of-control simple and clear, but can make code reuse in the controller difficult.|$|E
30|$|Our {{approach}} {{assumes that}} the resources supporting each component are enough to handle <b>incoming</b> <b>requests.</b> If this condition cannot be guaranteed, we recommend using an elastic queue to control <b>incoming</b> <b>requests.</b> Another approach could be to implement some form of admission control mechanism, for example, {{limiting the number of}} requests that are handled concurrently by each component, to avoid overloads or any degradation in the component’s performance.|$|R
50|$|Node.js is a Javascript runtime {{environment}} that processes <b>incoming</b> <b>requests</b> in a loop, called the event loop.|$|R
30|$|To {{complete}} the cycle, the GM updates its table for accepting further <b>incoming</b> <b>requests</b> to establish game connections.|$|R
50|$|To service an <b>incoming</b> <b>request,</b> the {{web server}} sends {{environment}} {{information and the}} page request itself to a FastCGI process over either a Unix domain socket, a named pipe or a TCP connection. Responses are returned from the process to the web server over the same connection, and the web server subsequently delivers that response to the end-user. The connection may be closed {{at the end of}} a response, but both the web server and the FastCGI service processes persist.|$|E
5000|$|... struct ireq { /* Structure of <b>incoming</b> <b>request</b> */ short ir_fc; /* Function code */ short ir_rn; /* Request number */ long ir_opid; /* Owner ID {{that you}} gave on open or mount */ long ir_bc; /* Byte count */ long ir_upar; /* User {{parameter}} */ long ir_rad; /* Random address */ ushort ir_uid; /* User ID */ ushort ir_gid; /* User group */ time_t ir_time; /* Request time */ ulong ir_nph; ulong ir_npl; /* Node and process ID */}; ...|$|E
5000|$|... the WBEM server will decode the <b>incoming</b> <b>request,</b> {{perform the}} {{necessary}} authentication and authorization checks and then consult the previously defined {{model of the}} managed device to see {{how to handle the}} request. This model provides the power of the architecture: it represents the pivot point of the transaction, with the client simply interacting with the model and the model interacting with the real hardware or software. The model uses the Common Information Model standard; the DMTF has published many models for commonly managed devices and services: IP routers, storage servers, desktop computers, etc.|$|E
50|$|Unikernels {{have been}} {{regularly}} shown to boot extremely quickly, {{in time to}} respond to <b>incoming</b> <b>requests</b> before the requests time-out.|$|R
5000|$|HandlerInterceptor: {{interception}} of <b>incoming</b> <b>requests</b> comparable, but {{not equal}} to Servlet filters (use is optional and not controlled by DispatcherServlet).|$|R
5000|$|HandlerMapping: {{selecting}} {{objects that}} handle <b>incoming</b> <b>requests</b> (handlers) based on any attribute or condition {{internal or external}} to those requests ...|$|R
50|$|When an {{operating}} system is booted, typically several processes are created. Some {{of these are}} foreground processes, that interacts with a (human) user and perform work for them. Other are background processes, which are not associated with particular users, but instead have some specific function. For example, one background process may be designed to accept incoming e-mails, sleeping {{most of the day}} but suddenly springing to life when an incoming e-mail arrives. Another background process may be designed to accept an <b>incoming</b> <b>request</b> for web pages hosted on the machine, waking up when a request arrives to service that request.|$|E
5000|$|By {{including}} Application {{streaming in}} the design of an application server capable of hosting a Virtual Application, no application specific code need reside on the server at all. Packages of code reside on the server, but the details on how they are to be invoked in order to create the functionality that adds up to the application, gets passed to the server as and when needed. In effect the application does not exist on the server at all. Though clients can still invoke it almost as if it did. The difference being that the <b>incoming</b> <b>request</b> must either include application logic ( [...] exploiting the code packages on the server), or information on where to locate such logic in a repository.|$|E
30|$|Upon request arrival, {{the hybrid}} {{algorithm}} determines whether the <b>incoming</b> <b>request</b> {{is to be}} accepted (determined by MMS) and if accepted, whether.|$|E
50|$|Many Career Retention Specialists are {{required}} at Headquarters, U.S. Marine Corps in Quantico, VA who process <b>incoming</b> <b>requests</b> on the Total Force Retention System.|$|R
50|$|Setting Priorities Based on Materiality and Contribution Potential: The PBO {{maintains}} an independent research plan, while simultaneously responding to <b>incoming</b> <b>requests</b> from parliamentarians and committees.|$|R
50|$|A load-balancing router sits at {{the front}} of Cloud Foundry to route <b>incoming</b> <b>requests</b> to the correct {{application}} - essentially to one of the containers where the application is running.|$|R
30|$|Feasibility delay: This is {{the delay}} of backoff and denial caused {{due to lack}} of {{feasible}} solutions at a given time for the <b>incoming</b> <b>request.</b>|$|E
30|$|Off-line clustering: is used {{to create}} a set of {{clusters}} for different types of VMs and users using long term historical data. The centres of these clusters used to classify <b>incoming</b> <b>request</b> during a specific time frame.|$|E
30|$|The Secondary server(s) {{processes}} the <b>incoming</b> <b>request</b> (s) {{and sends}} {{the response to}} the dispatcher. Then the dispatcher sends the response back to the client. The algorithm in Figure  5 shows how the dispatcher works. Also, the sequence diagram in Figure  6 summarizes the main dispatcher functionalities.|$|E
3000|$|... (iii) the {{resources}} supporting each component {{are enough to}} handle the magnitude of new <b>incoming</b> <b>requests</b> as the workload changes. This ensures {{that there is no}} overload when all components are functional.|$|R
5000|$|Controller: comes between Model and View {{to manage}} <b>incoming</b> <b>requests</b> and {{redirect}} to proper response. It {{acts as a}} gate that directs the incoming information. It switches between going into model or view.|$|R
40|$|Mutual {{exclusion}} {{among the}} nodes waiting for critical resources is {{considered as one}} of the major area of research in MANET. Mutual Exclusion allows mobile nodes to share resources among them. Formation of quorum is required for delivery of data with common intermediate node in between them. While communication, data transmission between quorums, is carried out using an arbitrator that is common to both regions. The main function of arbitrator is to grant the permission to <b>incoming</b> <b>requests</b> so as to enter the CS, by forwarding <b>incoming</b> <b>requests</b> to node, that is having the the primary token, which in turn will reduce the response time, synchronization delay and message complexity...|$|R
30|$|Learning {{from the}} idea of distributing data by a label in MPLS [3] and {{resource}} reservation in RSVP [4], taking advantage of TOS service type field is not commonly used in IP packets. The SDN controller may reserve resources for the <b>incoming</b> <b>request</b> according to the data flow characteristics of different application types after negotiating with the application server.|$|E
40|$|Server {{switches}} distribute <b>incoming</b> <b>request</b> traffic {{across the}} nodes of Internet server clusters and Web proxy cache arrays. These switches are a standard building block for large-scale Internet services, with many commercial {{products on the}} market. As Internet applications and service architectures continue to evolve, the role of server switches and the demands on their request routing policies will also change. This paper explore...|$|E
40|$|In this paper, {{security}} {{attacks in}} ARP are classified and logically organized/represented {{in a more}} lucid manner. ARP provides no authentication mechanism to the <b>incoming</b> <b>request</b> packets {{this is the reason}} that any client can forge an ARP message contains malicious information to poison the  ARP cache of target host. There are many possible attacks on ARP which can make the communication unsecure such as man-in-the-middle (MITM), Denial of service (DOS) and cloning attack...|$|E
50|$|Heroku’s HTTP routers {{distribute}} <b>incoming</b> <b>requests</b> for {{the application}} across the running web dynos. A random selection algorithm is used for HTTP/HTTPS request load balancing across web dynos. It also supports multiple simultaneous connections, as well as timeout handling.|$|R
5000|$|Advanced {{vertical}} scaling for {{application server}} by featuring a unique control region (integrated control area) server region (where workloads are completed) separation which enables the control region {{to open and}} close server regions as needed by the volume of <b>incoming</b> <b>requests</b> ...|$|R
5000|$|Network Dispatcher: Used {{to direct}} <b>incoming</b> <b>requests</b> to an {{appropriate}} server {{based on a}} set of rules which may include load balancing requests across several servers and content-based routing (i.e. redirecting a request based on the content of that request) ...|$|R
