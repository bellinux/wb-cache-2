1635|3|Public
5000|$|It occurs {{frequently}} in the elderly irrespective of them being hypertensive, and has moderate to modest <b>intraobserver</b> and interobserver agreement. It {{is also known as}} [...] "Osler's maneuver".|$|E
50|$|Another {{criticism}} {{is the fact}} that many of the measurements that are essential to this program are subject to both interobserver error and <b>intraobserver</b> error. Measurements between researchers can vary substantially in size and that this degree of variation in measurements can have a striking effect on the results of CranID. Due to this potential error, the results of CranID should be taken into account when assessing how accurate any findings formed by CranID are.|$|E
50|$|The {{utilities}} of STE {{are increasingly}} recognized. Strain results derived from STE have been validated using sonomicrometry and tagged MRI and results correlate significantly with Tissue Doppler-derived measurements. Tissue Doppler technology, the alternative method for strain rate imaging to speckle tracking technology, requires achieving sufficient parallel orientation between {{the direction of}} motion and the ultrasound beam. Its use has remained limited due to angle dependency, substantial <b>intraobserver</b> and interobserver variability and noise interference. Speckle tracking technology has {{to a certain degree}} overcome these limitations.|$|E
50|$|THI {{involves}} the use of harmonic frequencies that originate within the tissue as a result of nonlinear wave front propagation and are not present in the incident beam. These harmonic signals may arise differently at anatomic sites with similar impedances and thus lead to higher contrast resolution.” Along with higher contrast resolution it has an elevated signal-to-noise ratio and significantly reduced inter- and <b>intraobserver</b> variability compared with conventional US. Additionally it is possible to nearly eliminate ordinary US artifacts, i.e. side-lobe, near-field artifacts, reverberation artifacts. As aforementioned THI has already led to enhanced abdominal, breast, vascular and cardiac sonography.|$|E
5000|$|Unique hue is a {{term used}} in certain {{theories}} of color vision, which implies that human perception distinguishes between [...] "unique" [...] (psychologically primary) and composite (mixed) hues. A unique hue {{is defined as a}} color which an observer perceives as a pure, without any admixture of the other colors. There {{is a great deal of}} variability when defining unique hues experimentally. Often the results show a great deal of interobserver and <b>intraobserver</b> variability leading to much debate on the number of unique hues. Another source of variability is environmental factors in color naming. Despite the inconsistencies, often four color perceptions are associated as unique; [...] "red", [...] "green", [...] "blue", and [...] "yellow".|$|E
40|$|Objectives. The {{measurement}} of mucociliary transport velocity by rhinoscintigraphy with Tc- 99 m-macroaggregated albumin (99 mTc-MAA) is reliable measure of mucociliary clearance. The {{aim of this}} study is to assess the intratest, interobserver, and <b>intraobserver</b> reproducibility of nasal mucociliary transport rate (NMTR) measurement. Materials and Methods. Twenty-two subjects were evaluated to determine intratest reproducibility and a group of 35 subjects was examined to determine inter- and <b>intraobserver</b> reproducibility. Rhinoscintigraphy with 99 mTc-MAA was used to measure NMTR in all study subjects. Paired NMTR measurements were compared using a range of statistical methodologies. Intraclass correlation coefficients (ICC) and repeatability coefficients and Bland-Altman plots were applied to assess the degree of intratest, interobserver, and <b>intraobserver</b> variation. Results. Statistical analysis of test and retest experiments demonstrated the statistical equivalence of intratest NMTR measurements, interobserver NMTR measurements, and <b>intraobserver</b> NMTR measurements. The intratest ICC, interobserver ICC, and <b>intraobserver</b> ICC were 0. 96, 0. 83, and 0. 91, respectively, indicating that intratest and <b>intraobserver</b> reproducibility are excellent and interobserver reproducibility is good. Conclusions. Rhinoscintigraphy using 99 mTc-MAA results in highly reproducible {{measurement of}} NMTR. The use of radionuclide imaging in measuring NMTR results in excellent intratest and <b>intraobserver</b> reproducibility and good interobserver reliability...|$|E
30|$|Several studies {{concerning}} the <b>intraobserver</b> and interobserver agreements {{of the methods}} were published, {{and most of them}} were focused on the Graf method. The reported <b>intraobserver</b> and interobserver reliability {{concerning the}} hip typing in the Graf method ranged from moderate to substantial and from fair to substantial, respectively [21, 22, 23, 24, 25, 26]. Besides, the reported <b>intraobserver</b> and interobserver measurement variability of the α angle ranged from 4 ° to 11 ° and from 3 ° to 13 °, respectively [21, 23, 24, 26, 27]. The reported <b>intraobserver</b> and interobserver measurement variability of the β angle was between 6 ° and 14 ° and between 6 ° and 19 °, respectively [23, 24, 26, 27].|$|E
40|$|Context: Few {{studies of}} inter- or <b>intraobserver</b> {{reliability}} {{have focused on}} evaluations of cranial strain patterns. Objective: To determine whether substantial <b>intraobserver</b> reli-ability {{can be achieved by}} osteopathic physicians (DOs) using common palpatory tests to diagnose cranial dysfunction. Methods: Forty-eight subjects were divided into three diag-nostic groups, categorized as those with asthma, headaches, or neither asthma nor headaches (ie, healthy control group). Two blinded DO examiners separately evaluated approxi-mately 8 subjects from each group (4 subjects per session), con-ducting diagnostic tests for cranial rhythmic impulse (CRI) rate, cranial strain patterns, and quadrants of restriction. Results: Overall, among the three diagnostic procedures, cra-nial strain patterns showed the highest <b>intraobserver</b> relia-bility (= 0. 67). The highest <b>intraobserver</b> reliability wa...|$|E
30|$|The intraclass {{correlation}} coefficient (ICC) {{was used to}} measure the <b>intraobserver</b> and interobserver reliabilities, with 1.0 being perfect agreement and 0 indicating agreement by chance alone. Excellent reliability was defined as an ICC > 0.9, good 0.8 – 0.9 and fair 0.7 – 0.8. The <b>intraobserver</b> reliability was calculated for each variable (AP, axial, oblique plane) and the same images were re-examined by the same observers in order to calculate the <b>intraobserver</b> reliability for the oblique plane calculation between the first reading and the second reading.|$|E
40|$|Copyright © 2014 Zeki Dostbil et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Objectives. The measurement of mucociliary transport velocity by rhinoscintigraphy with Tc- 99 m-macroaggregated albumin (99 mTc-MAA) is reliable measure of mucociliary clearance. The {{aim of this study}} is to assess the intratest, interobserver, and <b>intraobserver</b> reproducibility of nasal mucociliary transport rate (NMTR) measurement. Materials and Methods. Twenty-two subjects were evaluated to determine intratest reproducibility and a group of 35 subjects was examined to determine inter-and <b>intraobserver</b> reproducibility. Rhinoscintigraphy with 99 mTc-MAA was used to measure NMTR in all study subjects. Paired NMTR measurements were compared using a range of statistical methodologies. Intraclass correlation coefficients (ICC) and repeatability coefficients and Bland-Altman plots were applied to assess the degree of intratest, interobserver, and <b>intraobserver</b> variation. Results. Statistical analysis of test and retest experiments demonstrated the statistical equivalence of intratest NMTR measurements, interobserver NMTR measurements, and <b>intraobserver</b> NMTR measurements. The intratest ICC, interobserver ICC, and <b>intraobserver</b> ICC were 0. 96, 0. 83, and 0. 91, respectively, indicating that intratest and <b>intraobserver</b> reproducibility are excellent and interobserver reproducibility is good. Conclusions. Rhinoscintigraphy using 99 mTc-MAAresults in highly reproducibl...|$|E
40|$|Objectives: The {{purpose of}} this study was to measure the <b>intraobserver</b> and {{interobserver}} reliability of magnetic resonance detection of cervical spondylotic myelopathy with and without operational guidelines. Methods: Seven radiologists examined images from 10 patients with cord signal abnormalities and clinical signs of myelopathy. Radiologist examined films twice, with and without operational guidelines designed to define stenotic changes, while blinded to the clinical findings of the patients. Analyses included a Fleiss kappa assessment of <b>intraobserver</b> and interobserver reliability. Results: Results demonstrated high percentage of agreement and strong <b>intraobserver</b> reliability and variable Fleiss kappa, values for interobserver assessment. Operational guidelines did not improve the <b>intraobserver</b> or interobserver agreement. Conclusion: Although the percentage of agreement was high in some cases, the kappa agreement was low-most likely a result of the base rate problem of a kappa analysis. Sample bias toward severe degenerative changes resulted in highly prevalent selections and kappa adjusted values. Nonetheless, the results do suggest that substantial <b>intraobserver</b> kappa agreement and a wide range of interobserver kappa agreement exists among trained radiologists during detection of stenotic changes associated with cervical spondylotic myelopathy...|$|E
40|$|Inhalation {{medication}} {{is essential in}} the treatment of asthma and chronic obstructive pulmonary disease (COPD) patients. Incorrect inhalation technique reduces the effects of medication and has been reported to range from 22 % to 95 % from optimal. The objective {{of this study was to}} determine inter- and <b>intraobserver</b> reliability in inhalation technique assessment. For interobserver reliability three observers scored after three times viewing a total of 49 video recorded inhalation demonstrations using device-specific checklists and mutually agreed scoring rules. <b>Intraobserver</b> reliability was assessed for two observers after 8 months by scoring inhalation demonstrations a second time. Both inter- and <b>intraobserver</b> reliability were expressed by mean percent agreement and mean Kappa scores. All inhaler devices revealed a high mean percent agreement and a substantial or almost perfect Kappa scoring for both inter- and <b>intraobserver</b> reliability. Only one item, "exhale to residual volume," showed poor <b>intraobserver</b> reliability. Assessment of video recorded inhalation technique using device-specific checklists, triple viewing, and mutual agreed scoring rules is reliable. This method enables blind observation of inhalation techniqu...|$|E
40|$|OBJECTIVES: To {{evaluate}} {{the reliability of}} semiquantitative Vertebral Fracture Assessment (VFA) on chest Computed Tomography (CT). METHODS: Four observers performed VFA twice upon sagittal reconstructions of 50 routine clinical chest CTs. Intra- and interobserver agreement (absolute agreement or 95 % Limits of Agreement) and reliability (Cohen's kappa or intraclass correlation coefficient(ICC)) were calculated for the visual VFA measures (fracture present, worst fracture grade, cumulative fracture grade on patient level) and for percentage height loss of each fractured vertebra compared to the adjacent vertebrae. RESULTS: Observers classified 24 - 38 % patients as having at least one vertebral fracture, giving rise to kappa's of 0. 73 - 0. 84 (<b>intraobserver)</b> and 0. 56 - 0. 81 (interobserver). For worst fracture grade we found good <b>intraobserver</b> (76 - 88 %) and interobserver (74 - 88 %) agreement, and excellent reliability with square-weighted kappa's of 0. 84 - 0. 90 (<b>intraobserver)</b> and 0. 84 - 0. 94 (interobserver). For cumulative fracture grade the 95 % Limits of Agreement were maximally ± 1, 99 (<b>intraobserver)</b> and ± 2, 69 (interobserver) and the reliability (ICC) varied from 0. 84 - 0. 94 (<b>intraobserver)</b> and 0. 74 - 0. 94 (interobserver). For percentage height-loss on a vertebral level the 95 % Limits of Agreement were maximally ± 11, 75 % (<b>intraobserver)</b> and ± 12, 53 % (interobserver). The ICC was 0. 59 - 0. 90 (<b>intraobserver)</b> and 0. 53 - 0 - 82 (interobserver). Further investigation is needed to {{evaluate the}} prognostic value of this approach. CONCLUSION: In conclusion, these results demonstrate acceptable reproducibility of VFA on CT...|$|E
40|$|AbstractObjectiveTo {{assess the}} inter- and <b>intraobserver</b> {{reproducibility}} {{of the original}} version and different descriptions of the Kellgren and Lawrence classification used in epidemiological studies for osteoarthritis of the knee. MethodsThe study included 72 patients with osteoarthritis of the knee. Three medical members of the Brazilian Society of Knee Surgery were invited to evaluate the images. An intra- and interobserver analysis was conducted, with an interval of one month. The <b>intraobserver</b> agreement was analyzed using the weighted Cohen's Kappa coefficient. The interobserver agreement was analyzed using the Krippendorff alpha coefficient (α). ResultsThe <b>intraobserver</b> assessment indicated conflicting results. In the interobserver analysis, the level of agreement was superficial. ConclusionsThe classification of Kellgren and Lawrence and its variants generated a low reproducibility between observers. The <b>intraobserver</b> analysis showed a lack of uniformity {{in the use of}} this classification and its variants, even among experienced observers...|$|E
40|$|We {{determine}} {{the reliability and}} reproducibility of retinal thickness measurements with a custom-built OCT retinal image analysis software (OCTRIMA). Ten eyes of five healthy subjects undergo repeated standard macular thickness map scan sessions by two experienced examiners using a Stratus OCT device. Automatic∕semi automatic thickness quantification of the macula and intraretinal layers is performed using OCTRIMA software. <b>Intraobserver,</b> interobserver, and intervisit repeatability and reproducibility coefficients, and intraclass correlation coefficients (ICCs) per scan are calculated. <b>Intraobserver,</b> interobserver, and intervisit variability combined account for less than 5 % of total variability for the total retinal thickness measurements and less than 7 % for the intraretinal layers except the outer segment∕ retinal pigment epithelium (RPE) junction. There is {{no significant difference between}} scans acquired by different observers or during different visits. The ICCs obtained for the <b>intraobserver</b> and intervisit variability tests are greater than 0. 75 for the total retina and all intraretinal layers, except the inner nuclear layer <b>intraobserver</b> and interobserver test and the outer plexiform layer, <b>intraobserver,</b> interobserver, and intervisit test. Our results indicate that thickness measurements for the total retina and all intraretinal layers (except the outer segment∕RPE junction) performed using OCTRIMA are highly repeatable and reproducible...|$|E
40|$|The Fuhrman nuclear {{grade is}} {{the most widely used}} grading system for renal cell carcinoma. The aim {{of this study was to}} {{evaluate}} the <b>intraobserver</b> and interobserver variability of the Fuhrman and modified Fuhrman grading systems for conventional renal cell carcinoma. In this study, five pathologists independently classified 110 cases of conventional renal cell carcinoma according to the Fuhrman and modified (three- and two-tiered) Fuhrman grading systems. The <b>intraobserver</b> and interobserver variability of these systems were assessed using κ statistics. The associations between the Fuhrman and modified Fuhrman grades, pathologic stage and tumor size were determined by correlation analysis. The <b>intraobserver</b> and interobserver combined mean κ values for four-tiered Fuhrman grading were 0. 48 and 0. 41, respectively. The highest agreement was detected in two-tiered modification (including grades 1 + 2 and 3 + 4); the <b>intraobserver</b> and inter-observer combined mean κ values were 0. 67 and 0. 62, respectively. Correlations between pathologic stage and tumor size with two-tiered modification (including grades 1 + 2 and 3 + 4) were greater than those in three- and four-tiered Fuhrman grading. Collapsing the Fuhrman grading into a two-tiered scheme improved the <b>intraobserver</b> and interobserver reproducibility...|$|E
40|$|Seven experts {{drew the}} rectal axes of 18 {{representative}} proctographic images on two occasions, with a 1 -year interval, {{in order to}} assess <b>intraobserver</b> variation in the determination of the anorectal angle (ARA). <b>Intraobserver</b> variation (6 %) and interobserver variation (17 %) were smallest when the central rectal axis was used to determine the ARA. A strong relation was found between inter- and <b>intraobserver</b> variation (r = 0. 77). <b>Intraobserver</b> variation tended to be rather small for pictures made during straining, but a relation with the magnitude of the ARA was not found. Although none of the seven experts could reproduce the rectal axes with {{less than or equal to}} 10 % variation in all 18 pictures, redrawing of the central rectal axis delivered less than or equal to 10 % variation in 86 % of determinations. It is concluded that <b>intraobserver</b> variation is influenced by the expertise of the investigator, the method of analysis, and the anorectal configuration to be analyzed. Radiologic assessment of the ARA may yield reliable data on the dynamics of the anorectum if performed by a single investigator on x-ray films that allow confident analysis. status: publishe...|$|E
40|$|ABSTRACT OBJECTIVE: To {{assess the}} inter- and <b>intraobserver</b> {{reproducibility}} {{of the original}} version and different descriptions of the Kellgren and Lawrence classification used in epidemiological studies for osteoarthritis of the knee. METHODS: The study included 72 patients with osteoarthritis of the knee. Three medical members of the Brazilian Society of Knee Surgery were invited to evaluate the images. An intra- and interobserver analysis was conducted, with an interval of one month. The <b>intraobserver</b> agreement was analyzed using the weighted Cohen's Kappa coefficient. The interobserver agreement was analyzed using the Krippendorff alpha coefficient (a). RESULTS: The <b>intraobserver</b> assessment indicated conflicting results. In the interobserver analysis, the level of agreement was superficial. CONCLUSIONS: The classification of Kellgren and Lawrence and its variants generated a low reproducibility between observers. The <b>intraobserver</b> analysis showed a lack of uniformity {{in the use of}} this classification and its variants, even among experienced observers...|$|E
40|$|Abstract Objective: To {{evaluate}} radiologist {{agreement on}} the quantification of bronchiectasis by high-resolution computed tomography (HRCT). Materials and Methods: The HRCT scans of 43 patients with bronchiectasis were analyzed by two radiologists, who used a scoring system to grade the findings. Kappa (&# 954;) values and overall agreement were calculated. Results: For the measurement and appearance of bronchiectasis, the interobserver agreement was moderate (&# 954; = 0. 45 and &# 954; = 0. 43, respectively), as was the <b>intraobserver</b> agreement (&# 954; = 0. 54 and &# 954; = 0. 47, respectively). Agreement {{on the presence of}} mucous plugging was fair, for central distribution (overall interobserver agreement of 68. 3 % and &# 954; = 0. 39 for <b>intraobserver</b> agreement) and for peripheral distribution (&# 954; = 0. 34 and &# 954; = 0. 35 for interobserver and <b>intraobserver</b> agreement, respectively). The agreement was also fair for peribronchial thickening (&# 954; = 0. 21 and &# 954; = 0. 30 for interobserver and <b>intraobserver</b> agreement, respectively). There was fair interobserver and <b>intraobserver</b> {{agreement on the}} detection of opacities (&# 954; = 0. 39 and 71. 9 %, respectively), ground-glass attenuation (64. 3 % and &# 954; = 0. 24, respectively), and cysts/bullae (&# 954; = 0. 47 and &# 954; = 0. 44, respectively). Qualitative analysis of the HRCT findings of bronchiectasis and the resulting individual patient scores showed that there was an excellent correlation between the observers (intraclass correlation coefficient of 0. 85 and 0. 81 for interobserver and <b>intraobserver</b> agreement, respectively). Conclusion: In the interpretation of HRCT findings of bronchiectasis, radiologist agreement appears to be fair. In our final analysis of the findings using the proposed score, we observed excellent interobserver and <b>intraobserver</b> agreement...|$|E
40|$|The Healthy Lifestyle in Europe by Nutrition in Adolescence Study aims to {{describe}} total {{body fat percentage}} and anthropometric indices of body fat distribution in European adolescents. Objective: To describe the standardization process and reliability of anthropometric and bioelectrical impedance analysis (BIA) measurements. We examined both intra- and interobserver errors for skinfolds, circumferences and BIA. Methods: For the <b>intraobserver</b> error assessment, first of all, 202 adolescents in the pilot study (110 boys, 92 girls, aged 13. 64 ± 0. 78 years) were assessed. For the second <b>intraobserver</b> and interobserver assessments, 10 adolescents were studied (5 boys and 5 girls). Results: The pilot study’s <b>intraobserver</b> technical errors of measurement (TEMs) were between 0. 12 and 2. 9 mm for skinfold thicknesses, and between 0. 13 and 1. 75 cm for circumferences. <b>Intraobserver</b> reliability for skinfold thicknesses was greater than 69. 44 % and beyond 78. 43 % for circumferences. The final workshop’s <b>intraobserver</b> TEMs for skinfold thicknesses and circumferences were smaller than 1; for BIA resistance TEMs were smaller than 0. 1 O and for reactance they were smaller than 0. 2 O. <b>Intraobserver</b> reliability values were greater than 95, 97, 99 and 97 % for skinfold thicknesses, circumferences, BIA resistance and reactance, respectively. Interobserver TEMs for skinfold thicknesses and circumferences ranged from 1 to 2 mm; for BIA they were 1. 16 and 1. 26 O for resistance and reactance, respectively. Interobserver reliability for skinfold thicknesses and circumferences were greater than 90 %, and for BIA resistance and reactance they were greater than 90 %. Conclusions: After {{the results of the}} pilot study, it was necessary to optimize the quality of the anthropometric measurements before the final survey. Significant improvements were observed in the <b>intraobserver</b> reliabilities for all measurements, with interobserver reliabilities being higher than 90 % for most of the measurements...|$|E
40|$|OBJECTIVE: Although {{the need}} for {{accurate}} anthropometric measurement has been repeatedly stressed, reports on growth and physical measurements in human populations rarely include estimates of measurement error. We describe the standardization process and reliability of anthropometric measurements carried out in a pilot study. METHODS: For the <b>intraobserver</b> assessment of anthropometric measurements, we studied 101 adolescents (58 boys and 43 girls) from five cities. For interobserver assessment, we studied 10 adolescents from the same class in Zaragoza and different {{from those in the}} <b>intraobserver</b> sample. RESULTS: For skinfold thickness, <b>intraobserver</b> technical errors of measurement (TEMs) in general were smaller than 1 mm; for circumferences, TEMs in general were smaller than 1 cm. <b>Intraobserver</b> reliability for skinfold thickness was greater than 95 % for almost all cases; for circumferences, <b>intraobserver</b> reliability generally was greater than 95 %. Interobserver TEMs ranged from 1 to 2 mm for the six skinfold thicknesses measured; for circumferences, TEMs were smaller than 1 cm for the arm, biceps, and waist and between 1 and 2 cm for the hip and thigh. Interobserver reliabilities for skinfold thickness and circumference were always greater than 90 %, except for biceps skinfold. CONCLUSIONS: Our results are in agreement with those recommended in the literature. Therefore, thes...|$|E
40|$|OBJECTIVE: To {{investigate}} the interobserver and <b>intraobserver</b> agreements for the semiquantitative assessment of markers of subclinical cardiovascular disease as identified by routine care, diagnostic computed tomography (CT) of the chest, {{to improve the}} quality of reporting of these incidental findings. METHODS: Two observers independently evaluated 109 consecutive chest CT scans in routine care, clinical patients from one tertiary referral center. All nongated, contrast-enhanced scans were acquired on a 16 -slice CT scanner. Images were scored for the presence of aortic wall abnormalities and calcifications of the coronary artery, the heart valves, the thoracic aorta, and the proximal supraaortic arteries. Furthermore, the presence of left ventricular scarring and elongation of the aorta were recorded. All markers were scored on a semiquantitative scale. Interobserver and <b>intraobserver</b> agreements are presented as weighted kappa and intraclass correlation coefficients. RESULTS: Interobserver and <b>intraobserver</b> agreements for individual markers were good to excellent, with weighted kappa coefficients of 0. 54 to 0. 89 for interobserver agreement and 0. 55 to 0. 96 for <b>intraobserver</b> agreement. CONCLUSIONS: Semiquantitative assessment of subclinical cardiovascular disease markers in routine care, diagnostic chest CT scans is possible with good to excellent interobserver and <b>intraobserver</b> agreements. Use of these definitions in clinical practice will enable a more standardized assessment and reporting of incidental findings in diagnostic chest CT...|$|E
40|$|AbstractObjectives: {{to assess}} intra- and {{interobserver}} {{variability in the}} measurement of aortic and common iliac artery diameter by means of computed tomography (CT). Design: reproducibility study. Material and Methods: three radiologists performed measurements of aortic diameter at five different levels and of both common iliac arteries with CT. Fifty-nine subjects were examined, 29 with and 30 without abdominal aortic aneurysms (AAA) as assessed by ultrasound. Results: <b>intraobserver</b> variability varied between radiologists, measurement plane (anterior-posterior vs transverse) and measurement level. The interobserver variability was markedly higher at the bifurcation than at the suprarenal level and higher than <b>intraobserver</b> variability for measurements at all levels. Both <b>intraobserver</b> and interobserver variability increased with increasing vessel diameter and were largest in patients with AAA. The absolute <b>intraobserver</b> difference of the maximal infrarenal aortic diameter was 2 mm or less in 94 % of <b>intraobserver</b> pairs. The corresponding interobserver difference was 82 %. Conclusions: interobserver variability of CT measurements of aortic and common iliac artery diameter is not negligible and {{should be taken into}} account when making clinical decisions. When assessing change in aortic diameter, previous CT-scans should be reviewed simultaneously as a routine to exclude interobserver variability. Eur J Vasc Endovasc Surg 25, 399 - 407 (2003...|$|E
40|$|Measurement {{of brown}} adipose tissue (BAT) {{activity}} {{is the focus}} of intensive research, among others as a potential target for weight-lowering strategies. In this, BAT activity is visualized and quantified using F-fluorodeoxyglucose (F-FDG) PET-CT. The aim {{of this study was to}} determine the interobserver and <b>intraobserver</b> variability for detecting and quantifying BAT on F-FDG PET-CTs. Three observers retrospectively independently assessed 55 F-FDG PET-CTs (performed between April 2013 and January 2014) for BAT activity parameters: BAT volume, the maximal and mean standardized uptake value (SUVmax and SUVmean) obtained in healthy male controls. One observer reassessed the scans after 2 months for the <b>intraobserver</b> variability. Interobserver and <b>intraobserver</b> variability were expressed using Lin's concordance coefficient (LCC) and Bland-Altman plots. Correlations between the three parameters were assessed using Spearman's correlation. The LCCs for the interobserver and <b>intraobserver</b> concordance for SUVmax were the highest (LCC SUVmax varied between 0. 998 and 0. 999, for SUVmean between 0. 989 and 0. 991 and for volume between 0. 947 and 0. 972). The Bland-Altman analysis showed a small absolute mean difference between all observers for both SUVmax and SUVmean, but the differences for volume were markedly higher. All parameters correlated statistically strongly and positively. The SUVmax showed the lowest interobserver and <b>intraobserver</b> variation. Although SUVmean and BAT volume had a higher interobserver and <b>intraobserver</b> variation, the variation is still within acceptable limits. Therefore, all parameters can be used to describe BAT activity. However, for an adequate comparison between studies, we recommend the use of SUVma...|$|E
30|$|The mapping was compared. There {{was high}} inter and <b>intraobserver</b> validity.The {{results will be}} presented.|$|E
40|$|The {{purpose of}} this work was to compare inter- and <b>intraobserver</b> {{agreement}} {{in the analysis of}} CAWT by using MDCTA. The CAWT in 35 patients was quantified by 4 observers. Bland-Altman statistics were used to measure the agreement between observers. The results of our study demonstrated that the CAWT measured by using MDCTA shows a good reproducibility between observers by considering inter- and <b>intraobserver</b> agreement...|$|E
40|$|AbstractObjectiveto {{determine}} whether 3 D reconstruction images from computed tomography (CT) increase the inter and <b>intraobserver</b> {{agreement of the}} Neer and Arbeitsgemeinschaft für Osteosynthesefragen (AO) classification systems. Methodsradiographic images and tomographic images with 3 D reconstruction were obtained in three shoulder positions and were analyzed on two occasions by four independent observers. Resultsthe radiographic evaluation demonstrated that using CT improved the inter and <b>intraobserver</b> agreement of the Neer classification. This was not seen with the AO classification, in which CT was only shown to increase the interobserver agreement. Conclusionuse of 3 D CT allows better evaluation of fractures {{with regard to their}} component parts and their displacements, but nevertheless the <b>intraobserver</b> agreement presented is less than ideal...|$|E
40|$|Objective: Purpose of {{this study}} is to {{determine}} the interobserver and <b>intraobserver</b> variability of 3 D GIS in the assessment of intrauterine abnormalities. Study design: Forty five 3 D volumes were randomly selected from a larger prospective cohort study that studied the diagnostic accuracy of 3 D GIS in addition to 2 D GIS. To study interobserver agreement volumes were reviewed by two independent examiners. One examiner reviewed these samples twice with an interval of 1 month in a random order. Interobserver and <b>intraobserver</b> agreement were tested with Cohen's kappa coefficient and shown in Bland and Altman plots. Quality of the 3 D volumes was evaluated. Results: Cohen's kappa for interobserver variability for type of abnormalities (none, polyp, fibroid, other) was 0. 64 and for presence of a fibroid (fibroid yes/no) 0. 77. Agreement on type of fibroid was 0. 59. <b>Intraobserver</b> agreement was almost perfect for type of abnormality (Cohen's kappa of 1. 0) and good for fibroid diameter. Quality of the 3 D volumes was poor in 11 out of 45 cases. Reproducibility increased when poor quality images were excluded. Conclusion: Substantial interobserver and <b>intraobserver</b> agreement for 3 D GIS in the diagnoses of intrauterine abnormalities was found. 3 D GIS interobserver and <b>intraobserver</b> agreement are good for fibroid diameter and moderate for volume and protrusion. © 2014 Elsevier Ireland Ltd. All rights reserved...|$|E
40|$|Purpose. It was to {{quantify}} the <b>intraobserver</b> and interobserver variability of the sonographic measurements of renal pelvis and classify hydronephrosis severity. Methods. Two ultrasonographers evaluated 17 fetuses from 23 to 39 weeks of gestation. Renal pelvis APD were taken in 50 renal units. For <b>intraobserver</b> error, one of them performed three sequential measurements. The {{mean and standard deviation}} from the absolute and percentage differences between measurements were calculated. Bland-Altman plots were used to visually assess the relationship between the precision of repeated measurements. Hydronephrosis was classified as mild (5. 0 to 9. 9 [*]mm), moderate (10. 0 to 14. 9 [*]mm), or severe (≥ 15. 0 [*]mm). Interrater agreement were obtained using the Kappa index. Results. Absolute <b>intraobserver</b> variation in APD measurements was 5. 2 ± 3. 5 %. Interobserver variation of ultrasonographers was 9. 3 ± 9. 7 %. Neither <b>intraobserver</b> or interobserver error increased with increasing APD size. The overall percentage of agreement with the antenatal hydronephrosis diagnosis was 64 %. Cohen's Kappa to hydronephrosis severity was 0. 51 (95 % CI, 0. 33 to 0. 69). Conclusion. Inter and <b>intraobserver</b> APD measurement errors were low in these group, but the agreement to hydronephrosis diagnosis and classification was fair. We suggest that standard and serial APD measurement can better define and evaluate fetal hydronephrosis...|$|E
40|$|Background: Sagittal ratio values (SRVs) of {{cervical}} vertebrae {{are used}} for ante-mortem diagnosis of cervical vertebral stenotic myelopathy, but <b>intraobserver</b> and interobserver variability in measurement may influence radiographic interpretation of vertebral stenosis in horses with neurological disease. Objectives: To determine <b>intraobserver</b> repeatability in SRVs, intra- and interobserver agreement in SRVs {{and whether or not}} agreement was influenced by animal age. Animals: Forty-two horses (&# 62; 1  year old) with neurological disease from which laterolateral computed radiographic images of C 2 –C 7 were obtained. Methods: Four observers made measurements from C 2 to C 7 for each horse and interobserver agreement for intra- and intervertebral SRVs was determined using Bland–Altman analysis (acceptable agreement: limits of agreement [LOA] &# 8804;  0. 05) on all horses and those &# 8804; 3 (n =  25) and &# 62; 3 (n =  17) years old. Each observer also made repeated measurements for 10 horses and <b>intraobserver</b> repeatability and agreement were determined. Results: Adequate <b>intraobserver</b> repeatability was achieved for 6 sites. Within observers, paired measurements had a median difference &# 8804; 5. 7...|$|E
40|$|Background:With {{increasing}} knowledge concerning fractures of {{the distal}} radius,different classifications have been proposed. Reliability {{of most of}} these classifications has been assessed. The Fernandez classification has never been assessed for <b>intraobserver</b> and interobserver reliability, although this classification is commonly used. Methods: Five observers including one attending orthopaedic hand surgeon,one hand surgery fellow, two attending orthopaedic surgeons and one senior resident of orthopaedic surgery classified 42 standard anteroposterior and lateral radiographs of prereduction distal radius fractures. Four weeks later the radiographs were renumbered differently and reviewed and classified by the same observers. Reliability of classification was assessed by Kappa value.  Results: The mean <b>intraobserver</b> Kappa value was 0. 64 (0. 53 - 0. 73), indicating good or substantial reliability, while the mean interobserver reliability was 0. 45 (0. 30 - 0. 71) representing moderate reliability.  Conclusion: In contrast to previous classifications of distal radius fracture, which their <b>intraobserver</b> and interobserver reliabilities were poor or moderate in most studies, the Fernandez classification has good <b>intraobserver</b> reliability and moderate interobserver reliability, {{so it can be}} used by orthopaedic surgeons with more confidence...|$|E
40|$|OBJECTIVE: to {{determine}} whether 3 D reconstruction images from computed tomography (CT) increase the inter and <b>intraobserver</b> agreement of the Neer and Arbeitsgemeinschaft für Osteosynthesefragen (AO) classification systems. METHODS: radiographic images and tomographic images with 3 D reconstruction were obtained in three shoulder positions and were analyzed on two occasions by four independent observers. RESULTS: the radiographic evaluation demonstrated that using CT improved the inter and <b>intraobserver</b> agreement of the Neer classification. This was not seen with the AO classification, in which CT was only shown to increase the interobserver agreement. CONCLUSION: use of 3 D CT allows better evaluation of fractures {{with regard to their}} component parts and their displacements, but nevertheless the <b>intraobserver</b> agreement presented is less than ideal...|$|E
30|$|Interobserver and <b>intraobserver</b> {{agreement}} {{concerning the}} streak artifact were poor or fair. This {{may be due}} to the difficulty in distinguishing streak artifact from image noise, particularly when there is prominent image noise. <b>Intraobserver</b> agreement for diagnostic acceptability was poor for one of the readers. Since diagnostic acceptability is a more notional evaluation term, evaluation basis could have changed during evaluation of 279 images, and reflect the reader becoming accustomed to the images.|$|E
40|$|A {{study was}} carried out to {{determine}} whether the diagnosis of non-specific urethritis was affected by differences in the microscopical interpretation of urethral smears between individual observers (interobserver variation) and the same observer on separate occasions (<b>intraobserver</b> variation). A marked degree of both <b>intraobserver</b> and interobserver variation was found which [...] depending on the diagnostic criteria adopted [...] could affect both the diagnosis and treatment of many patients attending a clinic of genitourinary medicine...|$|E
40|$|Magnetic {{resonance}} imaging (MRI) is increasingly {{applied in the}} evaluation of uterine fibroids. However, {{little is known about the}} reproducibility of MRI in the assessment of uterine fibroids. This study evaluates the inter- and <b>intraobserver</b> variation in the assessment of the uterine fibroids and concomitant adenomyosis in women scheduled for uterine artery embolization (UAE). Forty patients (mean age: 44. 5 years) with symptomatic uterine fibroids who were scheduled for UAE underwent T(1) - and T(2) -weighted MRI. To study inter- and <b>intraobserver</b> agreement 40 MR images were evaluated independently by two observers and reevaluated by both observers 4 months later. Inter- and <b>intraobserver</b> agreement was calculated using Cohen's kappa statistic and intraclass correlation coefficient for categorical and continuous variables, respectively. Inter-observer agreement for uterine volumes (kappa = 0. 99, p < 0. 0001), dominant fibroid volumes (kappa = 0. 98, p <or= 0. 0001), and number of fibroids (kappa = 0. 88; CI, 0. 77 - 0. 93; p < 0. 0001) was excellent. For the T(1) - and T(2) -weighted signal intensity of the dominant fibroid there was good agreement between the observers (87 %; 95 % CI, 71. 9 %- 95. 6 %) and the <b>intraobserver</b> agreement was good for observer A (95 %; 95 % CI, 83. 1 %- 99. 4 %) and moderate for observer B (kappa = 0. 47). The interobserver agreement with respect to the presence of adenomyosis was good (kappa = 0. 73, p < 0. 0001), while both <b>intraobserver</b> agreements were fair to moderate (observer A, kappa = 0. 55, p = 0. 0003; and observer B, kappa = 0. 66, p < 0. 0001). In conclusion, MRI criteria used for the selection of suitable UAE patients show good inter- and <b>intraobserver</b> reproducibilit...|$|E
40|$|The goal of {{this work}} was to {{validate}} the Radiation Therapy Oncology Group (RTOG) -endorsed guidelines for brachial plexus (BP) contouring by determining the intra- and interobserver agreement. Accuracy of the delineation process was determined using anatomically validated imaging datasets as a gold standard. Five observers delineated the right BP on three cadaver computed tomography (CT) datasets. To assess <b>intraobserver</b> variation, every observer repeated each delineation three times with a time interval of 2 weeks. The BP contours were divided into four regions for detailed analysis. Inter- and <b>intraobserver</b> variation was verified using the Computerized Environment for Radiation Research (CERR) software. Accuracy was measured using anatomically validated fused CT-magnetic resonance imaging (MRI) datasets by measuring the BP inclusion of the delineations. The overall kappa (kappa) values were rather low (mean interobserver overall kappa: 0. 29, mean <b>intraobserver</b> overall kappa: 0. 45), indicating poor inter- and <b>intraobserver</b> reliability. In general, the kappa coefficient decreased gradually from the medial to lateral BP regions. The total agreement volume (TAV) was {{much smaller than the}} union volume (UV) for all delineations, resulting in a low Jaccard index (JI; interobserver agreement 0 - 0. 124; <b>intraobserver</b> agreement 0. 004 - 0. 636). The overall accuracy was poor, with an average total BP inclusion of 38 %. Inclusions were insufficient for the most lateral regions (region 3 : 21. 5 %; region 4 : 12. 6 %). The inter- and <b>intraobserver</b> reliability of the RTOG-endorsed BP contouring guidelines was poor. BP inclusion worsened from the medial to lateral regions. Accuracy assessment of the contours showed an average BP inclusion of 38 %. For the first time, this was assessed using the original anatomically validated BP volume. The RTOG-endorsed BP guidelines have insufficient accuracy and reliability, especially for the lateral head-and-neck regions...|$|E
