23|69|Public
5000|$|... #Caption: Exponential <b>failure</b> <b>density</b> functions. Each {{of these}} has a (different) {{constant}} hazard function (see text).|$|E
5000|$|... where [...] is {{the time}} to (first) failure {{distribution}} (i.e. the <b>failure</b> <b>density</b> function) and [...]|$|E
5000|$|... where [...] is {{the failure}} time.The failure {{distribution}} function is the integral of the <b>failure</b> <b>density</b> function, f(t), ...|$|E
40|$|In future {{nanotechnologies}} <b>failure</b> <b>densities</b> are {{predicted to}} be several {{orders of magnitude}} higher than in current CMOS technologies. For such <b>failure</b> <b>densities</b> existing fault tolerance implementations are inadequate. This work presents several principles of building multiple-fault tolerant memory cells and logic gates for circuits affected by high defect densities {{as well as a}} first evaluation of the area cost and performance...|$|R
40|$|ISBN 978 - 3 - 540 - 73006 - 4 International audienceIn future {{nanotechnologies}} <b>failure</b> <b>densities</b> are {{predicted to}} be several {{orders of magnitude}} higher than in current CMOS technologies. For such <b>failure</b> <b>densities</b> existing fault tolerance implementations are inadequate. This work presents several principles of building multiple-fault tolerant memory cells and logic gates for circuits affected by high defect densities {{as well as a}} first evaluation of the area cost and performance...|$|R
30|$|Slope <b>failure</b> <b>densities</b> were minimal within {{areas of}} pasture (< 0.03  ha− 1) and mature exotic forest (0.02  ha− 1) (Table  2).|$|R
5000|$|The [...] {{function}} is a CONDITIONAL probability of the <b>failure</b> <b>DENSITY</b> function. The condition {{is that the}} failure has not occurred at time [...]|$|E
40|$|In {{the contest}} of {{environmental}} management, {{the problem of}} minimizing the expected cost due to random checking processes and a possible failure is here addressed. Non-homogeneous Poisson checking processes with continuous non-decreasing intensity are considered, leading to the explicit detection of the sub-optimal solution for exponential or uniform <b>failure</b> <b>density</b> functions. The dynamic of the optimal solution is then analized using the phase-diagram tool. Environmental management; audit scheme; random inspections; non-homogeneous Poisson checking process; optimal control; exponential <b>failure</b> <b>density</b> function; uniform <b>failure</b> <b>density</b> function. ...|$|E
40|$|Both solid {{business}} ventures and those not on as firm a footing can fail {{because they do}} not manage risk properly. This study shows that start-ups with a positive NPV project can fail because of inadequate cash reserves. We apply the first-hitting time model to analyze the effect of a cash reserve on the business <b>failure</b> <b>density</b> function and the cumulative failure probability for a specific business venture. The analysis of this model shows that {{business ventures}} have a much higher survival probability when they reduce their future cash-flow volatility. It is also shown that when risks cannot be controlled or are too expensive to be controlled, then business ventures need to have adequate cash reserves if they are to reduce <b>failure</b> <b>density</b> and cumulative failure probability...|$|E
30|$|The {{progress}} on novel interconnects for carbon nanotube (CNT)-based electronic circuit {{is by far}} behind the remarkable development of CNT-field effect transistors. The Cu interconnect material used in current integrated circuits seems not applicable for the novel interconnects, as it requires electrochemical deposition followed by chemical-mechanical polishing. We report our experimental results on the <b>failure</b> current <b>density,</b> resistivity, electromigration effect and failure mechanism of patterned stripes of Pd, Sc and Y thin-films, regarding them as the potential novel interconnects. The Pd stripes have a <b>failure</b> current <b>density</b> of (8 ∼ 10)× 106 A/cm 2 (MA/cm 2), and they are stable when the working current density is as much as 90 % of the <b>failure</b> current <b>density.</b> However, they show a resistivity around 210 μΩ·cm, which is 20 times of the bulk value and leaving room for improvement. Compared to Pd, the Sc stripes have a similar resistivity but smaller <b>failure</b> current <b>density</b> of 4 ∼ 5 MA/cm 2. Y stripes seem not suitable for interconnects by showing even lower <b>failure</b> current <b>density</b> than that of Sc and evidence of oxidation. For comparison, Au stripes of the same dimensions show a <b>failure</b> current <b>density</b> of 30 MA/cm 2 and a resistivity around 4 μΩ·cm, making them also a good material as novel interconnects.|$|R
5000|$|... are {{the failure}} stress, <b>failure</b> strain, <b>density</b> and elastic modulus of the yarn ...|$|R
5000|$|... where [...] is the <b>failure</b> {{probability}} <b>density</b> {{function and}} [...] is {{the length of}} the period of time (which is assumed to start from time zero).|$|R
40|$|AbstractThe {{method of}} projection, {{proposed}} in Part I, {{is applied to}} derive sharp moment bounds for the expectations of order statistics based onindependentsamples from restricted families of distributions. Three families are considered: life distributions with decreasing <b>failure</b> <b>density,</b> decreasing failure rate, and symmetric unimodal ones. The respective bounds are also numerically compared with those for general populations in both the dependent and independent cases...|$|E
40|$|The {{description}} of degree model of {{reliability of the}} heat power equipment in which as a factor of loading the working temperature of the equipment is used is provided, interval estimates of constant values of model are given. For a row of elements of constructions of boilers dependences of the relative increase in <b>failure</b> <b>density</b> are given by operation in {{the conditions of the}} increased temperatures for a long time...|$|E
40|$|Latent Dirichlet Allocation (LDA) is a {{statistical}} topic model {{that has been}} widely used to abstract semantic information from software source code. Failure refers to an observable error in the program behavior. This work investigates whether semantic information and failures recorded in the history {{can be used to}} predict component failures. We use LDA to abstract topics from source code and a new metric (topic <b>failure</b> <b>density)</b> is proposed by mapping failures to these topics. Exploring the basic information of topics from neighboring versions of a system, we obtain a similarity matrix. Multiply the Topic <b>Failure</b> <b>Density</b> (TFD) by the similarity matrix to get the TFD of the next version. The prediction results achieve an average 77. 8 % agreement with the real failures by considering the top 3 and last 3 components descending ordered by the number of failures. We use the Spearman coefficient to measure the statistical correlation between the actual and estimated failure rate. The validation results range from 0. 5342 to 0. 8337 which beats the similar method. It suggests that our predictor based on similarity of topics does a fine job of component failure prediction...|$|E
40|$|We {{consider}} a competing risks model, in which system failures {{are due to}} one out of two mutually exclusive causes, formulated {{within the framework of}} shock models driven by bivariate Poisson process. We obtain the <b>failure</b> <b>densities</b> and the survival functions as well as other related quantities under three different schemes. Namely, system failures are assumed to occur at the first instant in which a random constant threshold is reached by (a) the sum of received shocks, (b) the minimum of shocks, (c) the maximum of shocks. ...|$|R
40|$|International audienceTransient and {{permanent}} fault densities are increasing in future submicron technologies. Thus more advanced solutions {{may be required}} to produce memories in the upcoming nanometric CMOS process generations. Moreover, this problem will be exacerbated with nanotechnologies, where future densities are predicted to be several order of magnitude higher than in current CMOS technologies. For such <b>failure</b> <b>densities,</b> nowadays memory architectures and repair techniques are not adequate. This work presents several memory cells architectures and methods addressing memories affected by high defect densities as well as evaluation of the area cost and performances...|$|R
40|$|In {{this paper}} we {{investigate}} the monotonicity of the <b>density,</b> <b>failure</b> rate and mean residual life {{functions of the}} log-exponential inverse Gaussian distribution. It turns out that, in this case, the monotonicity of the <b>density,</b> <b>failure</b> rate and mean residual life functions take different forms depending on {{the range of the}} parameters. Maximum likelihood estimators of the critical points of the <b>density,</b> <b>failure</b> rate and mean residual life functions of the model are evaluated using Monte Carlo simulations. An example of a published data set is used to illustrate the estimation of the critical points...|$|R
40|$|The {{method of}} projection, {{proposed}} in Part I, {{is applied to}} derive sharp moment bounds for the expectations of order statistics based onindependentsamples from restricted families of distributions. Three families are considered: life distributions with decreasing <b>failure</b> <b>density,</b> decreasing failure rate, and symmetric unimodal ones. The respective bounds are also numerically compared with those for general populations in both the dependent and independent cases. independent identically distributed random variables, decreasing failure rates, symmetric unimodal distribution, convex cone, Bernstein polynomial, variation diminishing property...|$|E
40|$|Values {{of system}} {{availability}} are computed {{for a system}} whose <b>failure</b> <b>density</b> is exponential (A) and whose repair density is special Erlang (y,a). The system is modeled as an alternating renewal process. The Laplace transform of the availability function is developed and inverted (by using a numerical procedure) to obtain {{the values of the}} system availability. Corresponding values of the long-run average system availability and the average availability over the first mission time are also computed. Comparisons are made which establish that using the long-run average value to approximate the true availability over the first mission time is a conservative practice. [URL] United States Arm...|$|E
40|$|Oxytocin, {{which is}} {{produced}} in the supraoptic (SON) and paraventricular (PVN) nuclei of the hypothalamus, is released in to circulation from magnocellular neurons which extend down to the posterior pituitary. In addition, oxytocin is produced and released from parvocellular neurons in the PVN, which project to many areas within the brain such as {{other parts of the}} hypothalamus, the amygdala, the striatum, the raphenuclei, the LC, the vagal motor and sensory nuclei, the dorsal horn of the spinal cord as well as the preganglionic sympathetic neurons of the intermediolateral column of the spinal cord. The structure of the nonapeptide oxytocin differs by only two amino acids from that of vasopressin, which {{is produced in}} separate neurons of the PVN and SON. Only one oxytocin receptor, i. e. the uterine type of receptor, has been identified. This type of receptor also has been demonstrated in the central nervous system. Oxytocin release into the nervous system during the early postpartum period may strengthen the expression of maternal behaviors and prolong breastfeeding. Comparisons between woman following vaginal delivery (VD) versus caesarean section (CS) suggest that exposure to oxytocin during labor and in the postpartal period can influence the subsequent function of oxytocin-producing neurons during the lactation period. In the Mathematical model, both the cases are compared by finding the Renewal density and <b>Failure</b> <b>Density</b> functions. Renewal density is higher if we compare the caesarean case with vaginal delivery during the labor and in the early post partum period. In a similar manner, we obtain the bounds of the <b>failure</b> <b>density</b> functions in both the cases. MATHEMATICAL SUBJECT CLASSIFICATION: 60 GXX, 60 E 05...|$|E
50|$|The biogeographical {{history of}} non-avian Tetanurae spans over 110 million years and all continents. The {{presence}} of major lineages {{prior to the}} breakup of Pangaea implies wide dispersal of these clades, with later absences indicating regional extinctions or dispersal <b>failure.</b> The <b>density</b> of sampling is currently insufficient to provide {{a detailed analysis of}} biogeographical evolution for the Tetanurae.|$|R
40|$|AbstractA {{model for}} the {{dynamics}} {{of a system of}} particles undergoing simultaneously coalescence and breakup is considered, each particle being assumed to be fully identified by its size. Existence of solutions to the corresponding evolution integral partial differential equation is shown for product-type coagulation kernels with a weak fragmentation. The <b>failure</b> of <b>density</b> conservation (or gelation) is also investigated in some particular cases...|$|R
40|$|A {{yield model}} was {{developed}} allowing {{the calculation of}} yield using defect density data of manufacturing equipment. The approach allows studying impact of semiconductor manufacturing equipment on yield, to calculate and monitor yield during semiconductor manufacturing and predicting yield based on real time input of semiconductor manufacturing equipment regarding <b>failures,</b> defect <b>density</b> etc. The yield model bases on generic flows of manufacturing processes. The model assigns each functional layer a yield loss during the sequence of manufacturing steps. The yield model was implemented in a software code. The software was used to study yield impact of specific equipment for different technologies and products...|$|R
40|$|The new {{approach}} {{was developed to}} analyze the failure causes in operation of linear facilities independent power supply sources (mini-CHP-plants) of gas-transmission system in Eastern part of Russia. Triggering conditions of ceiling operation substance temperature at condenser output were determined with mathematical simulation use of unsteady heat and mass transfer processes in condenser of mini-CHP-plants. Under these conditions the failure probability in operation of independent power supply sources is increased. Influence of environmental factors (in particular, ambient temperature) as well as output electric capability values of power plant on mini-CHP-plant operation reliability was analyzed. Values of {{mean time to failure}} and power plant <b>failure</b> <b>density</b> during operation in different regions of Eastern Siberia and Far East of Russia were received with use of numerical simulation results of heat and mass transfer processes at operation substance condensation...|$|E
40|$|In {{order to}} study the problem of {{detecting}} an optimal sequence of random audits, this paper is devoted to determine a checking schedule minimizing the expected total cost resulting from the inspections and the possible first failure. This problem is considered in the general {{case in which the}} number of checks during an interval is described by a Poisson checking process: in the framework of the Optimal Control Theory, the analytical solution of a new problem which is related to that of detecting the optimal random audit scheme is characterized. This is achievable because in this case the control function is associated to the rate of growth of the checking intensity. In particular, the proposed representation leads to the explicit detection of the (sub-) optimal solution for exponential or uniform <b>failure</b> <b>density</b> functions and it ensures the analysis of the optimal solution dynamic in the phase-diagram framework...|$|E
40|$|International audienceLow voltage {{operation}} and small device sizes reduce the critical charge {{stored in a}} SRAM cell making caches more susceptible to soft errors. To counter the problem, a plethora of protection schemes are being proposed to reduce the power and area overheads of cache protection. Accurate methods to measure and compare the effectiveness of such schemes are sorely needed. This paper introduces a unified reliability benchmarking framework with PARMA (Precise Analytical Reliability Model for Architecture). PARMA is a rigorous analytical framework to measure the failure rate {{in the presence of}} soft errors under any protection scheme. PARMA continuously and accurately accounts for the increase of <b>failure</b> <b>density</b> due to soft errors affecting program behavior during an execution. We have implemented the PARMA framework on top of a cycle-accurate simulator to benchmark Level- 2 cache failure rates for a set of CPU 2000 benchmarks. Three protection schemes are compared: parity, word-level 1 -bit ECC and block-level 1 -bit ECC...|$|E
40|$|Electrostatic {{discharge}} (ESD) investigations on the multiwalled carbon nanotubes (MWCNTs) {{are performed}} {{for the first}} time. A novel ESD failure mechanism of subsequent shell burning has been discovered. By using nanosecond pulse measurements, a new insight into metal-to-carbon nanotube (CNT) contact behavior could be achieved. Clear signature of two very different conduction mechanisms and related failure types at high current injection has been found. By determining the time to failure, an Arrhenius-like relation was extracted, which was explained by the oxidation of CNT shells. Finally, an extraordinary ESD <b>failure</b> current <b>density</b> of MWCNT of 1. 2 x 10 (9) A/cm(2) could be shown...|$|R
40|$|This paper {{presents}} Markov reliability {{model of}} Photovoltaic module encapsulation. The model includes {{all the possible}} failures associated with the operation of PV module. The same procedure of modeling can be extended {{to other parts of}} Photovoltaic systems. Firstly, failure causes are identified in details to develop the model, and then all the possible states of the encapsulation during the service are considered. Finally a complete Markov process is attained to assess the probability of each state and estimate the encapsulation mean time to <b>failure,</b> probability <b>density</b> function of the time to encapsulation failure, hazard and survival functions of PV module encapsulation...|$|R
40|$|In this paper, an {{iterative}} {{estimate of}} the multivariate density is proposed when the variables are binary in nature. Some properties of this estimate are also discussed. Finally, applications of this estimate {{are discussed in the}} areas of pattern recognition and reliability. Binary data character recognition estimation of <b>density</b> <b>failure</b> modes medical diagnosis pattern recognition and reliability...|$|R
40|$|AbstractThis paper {{presents}} {{reliability evaluation}} of residual magnetism in rotor {{core of the}} induction motor operated as SEIG using probability distribution approach and Monte Carlo simulation for unregulated renewable energy applications in remote areas. Parallel capacitors with calculated minimum capacitive value across the terminals of the induction motor operated as SEIG with unregulated shaft speed are connected during the experimental study. A three phase, 4 poles, 50 Hz, 5. 5 hp, 12. 3 A, 230 V induction motor coupled with DC Shunt Motor is tested in the electrical machine laboratory with variable reactive loads. Using this experimental study, {{it is possible to}} choose a reliable induction machines operated as SEIG for unregulated renewable energy application. <b>Failure</b> <b>density</b> function, cumulative failure distribution function, survivor function, hazard model, probability of success and probability of failure for reliability evaluation of the three phase induction motor operating as a SEIG have been presented graphically in this paper...|$|E
40|$|The United States Coast Guard has {{recently}} investigated new strategies to maintain cutter propulsion diesel engines. Reliability centered maintenance with statistical methods may allow {{the time between}} costly scheduled overhauls to be increased. One indicator of engine aging {{is the number of}} failures experienced with increasing operating hours. The {{purpose of this paper is}} to investigate the failure-time relationship of the ALCO 251 marine diesel propulsion engine operated on Reliance class cutters. This analysis used exponential, Weibull, and three-part composite Weibull <b>failure</b> <b>density</b> functions to model engine casualty data dating back to 1978. The data does not indicate the source of the engine failure, but every failure had a significant operational impact. Results indicate an increasing failure rate as the engine ages to the 24, 000 hour overhaul time. The evidence indicates a constant failure useful life region, but the increasing failure rate from the Weibull models suggests that the periodic over-hauls do not prevent wearout failures. As a result, the Coast Guard should consider refining diesel engine overhaul policy in order to prevent increasing age-related failures...|$|E
40|$|Resilience is an {{important}} challenge for extreme-scale supercomputers. Failures in current supercomputers {{are assumed to be}} uniformly distributed in time. However, recent studies show that failures in high-performance computing systems are partially correlated in time, generating periods of higher <b>failure</b> <b>density.</b> The detection of those periods is important in order to adjust the system to new conditions. In this paper we present a monitoring system that listens to hardware events across computing nodes and forwards important events to the fault tolerance runtime so it can react to those regime changes. Our evaluation at scale shows several aspects of this dynamic checkpointing scheme, critical to understanding its applicability on production systems, as well as to identifying possible avenues for future improvements. In particular, we evaluate the ability of our system to monitor as many types of events as possible, measure their importance, and forward them to the resilience runtime. Results presented in this paper were obtained using the Chameleon testbed supported by the National Science Foundation. This material was based upon work supported by the U. S. Department of Energy, Office of Science, Advanced Scientific Computer Research, under Contract DEAC 02 - 06 CH 11357. This research has also received funding from the European Community’s Seventh Framework Programme [FP 7 / 2007 - 2013] under the Mont-Blanc 2 Project (www. montblancproject. eu), grant agreement No 610402 and it has been supported in part by the European Union (FEDER funds) under contract TTIN 2015 - 65316 -P. Peer ReviewedPostprint (author's final draft...|$|E
40|$|Effects of {{corrosive}} {{solution temperature}} on the failure time in {{stress corrosion cracking}} of Cu- 30 wt%Zn alloy have been investigateted by the Weibull distribution method. All test pieces were full annealed and their average grain sizes were controlled in 20 μm. The test pieces have been stress corrosion tested at various solution temperatures of 14, 19, 24, 29, 34 and 39 ℃ under the constant applied stress 80 % of the yield stress in Mattsson's solution of pH 7. 5. The failure time(tf), crack initiation time(ti) and crack propagation period(tc) obey the single Weibull distributions with high values of shape parameter(m) that are from 9. 3 to 13. 3 in tf, from 4. 8 to 10. 1 in ti and from 3. 8 to 10. 7 in tc. The Weibull distributions with estimated location parameters (γ) of failure times have been confirmed to be right by comparison with histograms of actual failure times and the cumulative failure distribution function vs time curves or plots of calculated <b>failure</b> probability <b>densities.</b> By illustrating the cumulative failure distribution function F(t), the <b>failure</b> probability <b>density</b> function f(t) and the failure rate　λ(t) vs time curves at every temperature, {{it is found that}} solution temperature dependence on failure time is very remarkable. Apparent activation energies evaluated from Arrhenius plots of reciprocals of median values(M) are 16. 1 kcal/mol in tf, 14. 1 kcal/mol in ti and 18. 1 kcal/mol in tc...|$|R
40|$|It is {{well-known}} that SiC wafer quality deficiencies are delaying {{the realization of}} outstandingly superior 4 H-SiC power electronics. While efforts to date have centered on eradicating micropipes (i. e., hollow core super-screw dislocations with Burgers vectors> 2 c), 4 H-SiC wafers and epilayers also contain elementary screw dislocations (i. e., Burgers vector = 1 c with no hollow core) in densities {{on the order of}} thousands per cm 2, nearly 100 -fold micropipe densities. While not nearly as detrimental to SiC device performance as micropipes, it has been previously shown that diodes containing elementary screw dislocations exhibit a 5 % to 35 % reduction in breakdown voltage, higher pre-breakdown reverse leakage current, softer reverse breakdown I-V knee, and concentrated microplasmic breakdown current filaments when measured under DC testing conditions. This paper details the impact of elementary screw dislocations on the experimentally observed reverse-breakdown pulse-failure characteristics of low-voltage (< 250 V) small-area (< 5 x 10 - 4 cm 2) 4 H-SiC p+n diodes. The presence of elementary screw dislocations did not significantly affect the failure properties of these diodes when subjected to non-adiabatic breakdown-bias pulsewidths ranging from 0. 1 m s to 20 m s in duration. Diodes with and without elementary screw dislocations exhibited positive temperature coefficient of breakdown voltage and high junction <b>failure</b> power <b>densities</b> well above the <b>failure</b> power <b>densities</b> exhibited by highly reliable silicon power rectifiers. This preliminary result, based on measurements from one wafer of SiC diodes, suggests that highly reliable low-voltage SiC rectifiers may be attainable despite the presence of elementary screw dislocations...|$|R
40|$|Abstract. Residual {{strength}} degradation of 35 CrMo alloy steel is investigated experimentally and theoretically in this paper. The experimental results {{were obtained by}} high-frequency fatigue testing machine and electro-hydraulic servo testing machine at room temperature. The experimental results showed the true tensile strength under static load and the residual strength under different cycle ratio, respectively. An exponential degradation model was proposed relating the initial strength, residual strength to the applied fatigue cycles and the constant amplitude stress. The residual strength distribution was described using three-parameter Weibull probability density function. The mathematical software MatLab was used for parameter estimation. Finally, the distribution function and <b>failure</b> probability <b>density</b> function of the residual strength was received, which was significant in fatigue reliability...|$|R
