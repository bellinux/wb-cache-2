40|184|Public
50|$|Output Spooling - Output {{spooling}} is {{the process}} of queueing files for printing. Files are scheduled for printing based on <b>job</b> <b>priority</b> and availability of the printing device(s). You can specify special printing forms and formats.|$|E
50|$|In {{computer}} science, rate-monotonic scheduling (RMS) is {{a priority}} assignment algorithm used in real-time operating systems (RTOS) with a static-priority scheduling class. The static priorities are assigned according to the cycle duration of the job, so a shorter cycle duration results in a higher <b>job</b> <b>priority.</b>|$|E
50|$|According to {{a recent}} article the {{following}} tasks met as the highest <b>job</b> <b>priority</b> for healthcare technicians: Blood draws, arterial gases, venous access through IV insertion, central line dressing changes, electrocardiograms, patient monitoring, oxygen requirements, breathing exercises, and vital signs. HCT's are {{at the forefront of}} healthcare and can assist in the addressing issues or concerns within the healthcare structure. They can be utilized to mention gaps or strengths when addressing chronic pain patients within the healthcare system. The empathetic approach that HCT's use while on the job can assist medical teams better care for patients facing chronic health illnesses.|$|E
40|$|Abstract. Backfill is a {{technique}} in which lower <b>priority</b> <b>jobs</b> requiring fewer resources are initiated before one or more currently waiting higher <b>priority</b> <b>jobs</b> requiring as yet unavailable resources. Processors are frequently the resource involved {{and the purpose of}} backfilling is to increase system utilization and reduce average wait time. Generally, a scheduler backfills when the user-specified run times indicate that executing the lower <b>priority</b> <b>jobs</b> will not delay the anticipated initiation of the higher <b>priority</b> <b>jobs.</b> This paper explores the possibility of using a relaxed backfill strategy in which the lower <b>priority</b> <b>jobs</b> are initiated {{as long as they do}} not delay the highest <b>priority</b> <b>job</b> too much. A simulator was developed to model this approach; it uses a parameter ω to control the length of the acceptable delay as a factor times the wait time of the highest <b>priority</b> <b>job.</b> Experiments were performed for a range of ω values with both user-estimated run times and actual run times using workload data from two parallel systems, a Cray T 3 E and an SGI Origin 3800. Fo...|$|R
40|$|Information {{flows in}} a service {{organisation}} allow business units to co-ordinate {{their response to}} changes in the operating environment. Processes and interactions can be designed so that the right information flows to the right people, at the right time to make effective decisions regarding <b>job</b> <b>priorities</b> and allocation of limited resource. This paper develops an analysis framework an...|$|R
40|$|In this paper, {{we address}} the {{scheduling}} problem of multi-mode real-time systems upon uniform multiprocessor platforms. We propose two transition protocols, specified {{together with their}} schedula-bility test, and provide the reader with two distinct upper bounds {{for the length of}} the transient phases during mode transitions, respectively for the cases where <b>jobs</b> <b>priorities</b> are known and unknown be-forehand. ...|$|R
40|$|In this study, {{based on}} the {{consideration}} of energy consumption, we take to improve the strategy of the MapReduce job scheduling algorithm, {{in order to reduce}} the average response time for task scheduling of interactive jobs in the network. In accordance with the <b>job</b> <b>priority</b> grouping to adjust the scheduling task response time which can reduce the impact of network congestion, with good results that increase the throughput of the system transferring data and computing power...|$|E
30|$|A year after, Ghanbari et al., in [15] {{introduced}} a scheduling algorithm based on <b>job</b> <b>priority</b> named (PJSC) where each job is assigned resources {{based on its}} priority, in other words higher priority jobs gain access to resources first. Simulation results as clarified by the authors indicated that PJSC has reasonable complexity but sufferer from increasing makespan. In addition to that PJSC may cause Job starvation as the jobs with less priority may never {{gain access to the}} resources they need.|$|E
40|$|A {{job shop}} was {{simulated}} {{in order to}} determine the effect of different <b>job</b> <b>priority</b> rules involving setup times on shop performance. The seven priority rules tested were chosen on the basis that they could be implemented by job shop foremen. Assumptions in the simulation model were based on experience with an electronics company and published literature. The study indicates that, for a fully loaded shop, giving priority to be the job with the shortest actual setup time, regardless of its run time, gives the best overall performance result. ...|$|E
40|$|We ask the question, "for {{minimizing}} mean {{response time}} (sojourn time), which is preferable: one fast server of speed 1, or k slow servers each of speed 1 /k?" Our setting is the M/PH/k system with two priority classes of customers, high priority and low priority, where PH is a phase-type distribution. We find that multiple slow servers are often preferable, and we demonstrate {{exactly how many}} servers are preferable {{as a function of}} the load and service time distribution. In addition, we find that the optimal number of servers with respect to the high <b>priority</b> <b>jobs</b> may be very di#erent from that preferred by low <b>priority</b> <b>jobs,</b> and we characterize these preferences. We also study the optimal number of servers with respect to overall mean response time, averaged over high and low <b>priority</b> <b>jobs.</b> Lastly, we ascertain the e#ect of the service demand variability of high <b>priority</b> <b>jobs</b> on low <b>priority</b> <b>jobs...</b>|$|R
40|$|We {{present an}} online {{adjustment}} method {{to discover the}} latest defer time for each <b>job</b> using Fixed <b>Priority</b> scheduling algorithm. By deferring the preemption of lower <b>priority</b> <b>jobs</b> by higher <b>priority</b> <b>jobs</b> until the latest defer time, we reduce the overhead caused by preemptions while still ensuring every job meets its deadline. We present our ongoing work which modifies dual priority of Fixed-Priority scheduling using the worst case response time. Thus we find each task’s latest defer time by subtracting its deadline from its worst case response time offline. Then for each job’s release time, we adjust the latest defer time online. In this manner, we can then reduce certain amount of preemptions hence reduce the overhead. 1...|$|R
40|$|The {{integration}} of fuzzy set theory and fuzzy logic into scheduling {{is a rather}} new aspect with growing importance for manufacturing applications, resulting in various unsolved aspects. In the current paper, we investigate an improved local search technique for fuzzy scheduling problems with fitness plateaus, using a multi criteria formulation of the problem. We especially {{address the problem of}} changing <b>job</b> <b>priorities</b> over time as studied at the Sherwood Press Ltd, a Nottingham based printing company, who is a collaborator on the project...|$|R
40|$|In {{this paper}} we {{consider}} a k-out-of-N system with identical, repairable components under a condition-based maintenance policy. Maintenance consists of replacing all failed and/or aged components. Next, the replaced components {{have to be}} repaired. The system availability can be controlled by the maintenance policy, the spare part inventory level, the repair capacity and repair <b>job</b> <b>priority</b> setting. We present two approximate methods to analyse the relation between these control variables and the system availability. Comparison with simulation results shows that we can generate accurate approximations using one of these models, depending on the system size. © 2005 Elsevier B. V. All rights reserved...|$|E
40|$|Abstract — The Flexible Manufacturing Systems (FMS) {{basically}} {{belongs to}} a category of productive systems in which the main characteristic is the simultaneous execution of several processes and sharing a finite set of resource. Analysis and modeling of flexible manufacturing system (FMS) includes priority analysis of machining jobs and machining routing for efficient profit and production. Flexible manufacturing system (FMS) <b>job</b> <b>Priority</b> calculation becomes exceptionally complex {{when it comes to}} contain frequent variations in the part designs of incoming jobs. This paper focuses on priority analysis of variety of incoming jobs into the system efficiently and maximizing system utilization and throughput of system where machines are equipped with different tools and tool magazines but multiple machines can be assigned to single operation. For the complete analysis of the proposed work, a cloud of four incoming jobs have been considered. The Jobs have been assigned the priority according to Slack per Remaining Operations. Usually the probability of incoming <b>job</b> <b>priority</b> is calculated based on three parameters based strategy. In this work an adaptive Neuro fuzzy inference system (ANFIS) is developed to calculate the priority of incoming jobs based on Slack per Remaining Operations (S/RO) parameter. Four horizontal CNC lathe machines have been utilized for this work. Therefore, in this paper, an ANFIS system is developed to generate best priority of incoming jobs. The results obtained clearly indicate the higher efficiency of the proposed work to decide the priority of the incoming jobs...|$|E
40|$|Abstract—Using the {{advances}} {{of the modern}} microelectronics technology, the safety-critical systems, such as avionics, can reduce their costs by integrating multiple tasks on one device. This makes such systems essentially mixed-critical, as this brings together different tasks whose safety assurance requirements may differ significantly. In the context of mixed-critical scheduling theory, we studied the dual criticality problem of scheduling a finite set of hard real-time jobs. In this work we propose an algorithm which is proved to dominate OCBP, a state-of-the-art algorithm for this problem that is optimal over fixed <b>job</b> <b>priority</b> algorithms. We show through empirical studies that our algorithm can reduce the set of non-schedulable instances {{by a factor of}} two or, under certain assumptions, by a factor of four, when compared to OCBP. I...|$|E
40|$|Because job {{deadlines}} are {{not used}} directly to determine <b>job</b> <b>priorities</b> under G-FL (unlike under G-EDF), the computations for tardiness bounds are more complex for G-FL than the computations described in Sec. 3. 1. Here we summarize the analysis from [1] as applied to split tasks. We first assume the absence of critical sections and then describe how our analysis is modified to account for critical sections. Each task is given a relative priority point Y split i = T split i S spli...|$|R
40|$|Backfill is a {{technique}} in which lower <b>priority</b> <b>jobs</b> requiring fewer resources are initiated before one or more currently waiting higher <b>priority</b> <b>jobs</b> requiring as yet unavailable resources. Processors are frequently the resource involved {{and the purpose of}} backfilling is to increase system utilization and reduce average wait time. Generally, a scheduler backfills when the user-specified runtimes indicate that executing the lower <b>priority</b> <b>jobs</b> will not delay the anticipated initiation of the higher <b>priority</b> <b>jobs.</b> This paper explores the possibility of using a relaxed backfill strategy in which the lower <b>priority</b> <b>jobs</b> are initiated {{as long as they do}} not delay the highest <b>priority</b> <b>job</b> too much. A simulator was developed to model this approach; it uses a parameter omega to control the length of the acceptable delay as a factor of the user-estimated run time. Experiments were performed for omega = 0, 1, 2, 3, and 1 with both user-estimated run time and actual run time using workload data from two parallel systems, a Cray T 3 E and an SGI Origin 3800. For these workloads, queue wait time is typically shortest for omega = 1 and the effect of poor user run time estimates is relatively small. More experiments must be performed to determine the generality of these results...|$|R
50|$|The {{response}} time is further affected when a <b>priority</b> <b>job</b> arrives. Whenever a <b>priority</b> <b>job</b> {{arrives at the}} system, that job will be given priority with respect to all other jobs, even over the one which are currently being executed on the processors. In case, when <b>priority</b> <b>job</b> arrives, the sub-gang which is currently executing on the system will be stopped and all the progress {{that has been made}} will be lost and has to be redone. This interruption of the job will further delay the total {{response time}} of the BoG.|$|R
40|$|In {{order to}} offer on-demand {{computing}} services {{as well as}} improve overall job throughput, the San Diego Supercomputer Center has implemented preemption on its production supercomputers. Preemption allows time critical applications to run as needed and also allows more jobs to be processed through the queue since the jobs can backfill in several smaller discrete blocks of time rather than in one contiguous block. With our local home grown scheduler, Catalina[4], we implemented preemp-tion to enable these new usage scenarios. We explore {{the impact of the}} job expansion factor and utilization when preemption and <b>job</b> <b>priority</b> are taken into account on both long-running and large-scale jobs. We simulated real production log using a simulator to investigate preemption impact to scheduling metrics. 1...|$|E
40|$|This {{paper is}} {{concerned}} with scheduling in flexible manufacturing systems (FMSs) using a fuzzy logic (FL) approach. Four fuzzy input variables: machine allocated processing time, machine priority, due date priority and setup time priority are defined. The <b>job</b> <b>priority</b> is the output fuzzy variable, showing the priority status of a job to be selected for next operation on a machine. The model will first select the machines and then assign operations based on a multi-criteria scheduling scheme. The performance of the approach is compared against established methods reported in the literature. The performance measures considered average machine utilisation, meeting due dates, setup times, work in process and mean flow times. The test results demonstrate {{the superiority of the}} fuzzy logic approach in most performance measures...|$|E
40|$|International audienceUsing the {{advances}} {{of the modern}} microelectronics technology, the safety-critical systems, such as avionics, can reduce their costs by integrating multiple tasks on one device. This makes such systems essentially mixed-critical, as this brings together different tasks whose safety assurance requirements may differ significantly. In the context of mixed-critical scheduling theory, we studied the dual criticality problem of scheduling a finite set of hard real-time jobs. In this work we propose an algorithm which is proved to dominate OCBP, a state-of-the art algorithm for this problem that is optimal over fixed <b>job</b> <b>priority</b> algorithms. We show through empirical studies that our algorithm can reduce the set of non-schedulable instances {{by a factor of}} two or, under certain assumptions, by a factor of four, when compared to OCBP...|$|E
5000|$|Performance {{management}} can {{be defined}} as 'an ongoing and continuous process of communicating and clarifying <b>job</b> responsibilities, <b>priorities,</b> and performance expectations in order to ensure understanding between supervisor and employee.' ...|$|R
40|$|We {{consider}} {{the issue of}} deadline tardiness under global multiprocessor scheduling algorithms. We present a general tardiness-bound derivation that is applicable {{to a wide variety}} of such algorithms (including some whose tardiness behavior has not been analyzed before). Our derivation is very general: <b>job</b> <b>priorities</b> may change rather arbitrarily at runtime, arbitrary non-preemptive regions are allowed, and capacity restrictions may exist on certain processors. Our results show that, with the exception of static-priority algorithms, most global algorithms considered previously have bounded tardiness. In addition, our results provide a simple means for checking whether tardiness is bounded under newly-developed algorithms. ...|$|R
40|$|Dynamic {{priority}} dispatching {{rules in}} job shops require the computation of all <b>job</b> <b>priorities</b> {{in a work}} center queue every time a machine in the work center becomes idle. This is extremely costly. Alternative priority update procedures are studied and comparative results in terms of performance measures and costs are reported. Ease of implementation of the various procedures in a real world job shop environment is discussed. A second problem related to an anomaly in ratio type dynamic priority rules is also studied; a simple modification to remove the anomaly is suggested and the performances of the "old" and "modified" procedures are compared. simulation: applications, production/scheduling: job shop, deterministic, queues: priority...|$|R
40|$|Discriminatory Processor Sharing policy {{introduced}} by Kleinrock is {{of a great}} interest in many application areas, including telecommunications, web applications and TCP flow modelling. Under the DPS policy the <b>job</b> <b>priority</b> is controlled by the vector of weights. Verifying the vector of weights it is possible to modify the service rates of the jobs and optimize system characteristics. In the present paper we present the results concerning the comparison of two DPS policies with different weight vectors. We show the monotonicity of the expected sojourn time of the system depending on the weight vector under certain condition on the system. Namely, the system has to consist of classes with means which are quite different from each other. The classes with similar means can be organized together and considered as one class, so the given restriction can be overcame...|$|E
40|$|Scale of data {{generated}} {{and processed}} is exponential {{growth in the}} Big Data ear. It poses a challenge that is far beyond {{the goal of a}} single computing system. Processing such vast amount of data on a single machine is impracticable in term of time or cost. Hence, distributed systems, which can harness very large clusters of commodity computers and processing data within restrictive time deadlines, are imperative. In this thesis, we target two aspects of distributed systems: application profiling and resource management. We study a MapReduce system in detail, which is a programming paradigm for large scale distributed computing, and presents solutions to tackle three key problems. Firstly, this thesis analyzes the characteristics of jobs running on the MapReduce system to reveal the problem—the Application scope of MapReduce has been extended beyond the original design goal that was large-scale data processing. This problem enables us to present a Workload Characteristic Oriented Scheduler (WCO), which strives for co-locating tasks of possibly different MapReduce jobs with complementing resource usage characteristics. Secondly, this thesis studies the current <b>job</b> <b>priority</b> mechanism focusing on resource management. In the MapReduce system, <b>job</b> <b>priority</b> only exists at scheduling level. High priority jobs are placed {{at the front of the}} scheduling queue and dispatched first. Resource, however, is fairly shared among jobs running at the same worker node without any consideration for their priorities. In order to resolve this, this thesis presents a non-intrusive slot layering solution, which dynamically allocates resource between running jobs based on their priority and efficiently reduces the execution time of high priority jobs while improves overall throughput. Last, based on the fact of underutilization of resource at each individual worker node, this thesis propose a new way, Local Resource Shaper (LRS), to smooth resource consumption of each individual job by automatically tuning the execution of concurrent jobs to maximize resource utilization while minimizing resource contention...|$|E
40|$|Abstract — We {{introduce}} a formal scheduling methodology for batch processes based on fuzzy logic theory. In particular, we present this methodology {{in the manufacturing}} context. Our approach takes into account most, if not all, relevant factors in this scheduling problem and models them as fuzzy sets. In the model developed for factory batch process scheduling, the inputs include the “literal ” <b>job</b> <b>priority,</b> job’s critical ratio, the length of each queue, job’s current relative position in its process flow, etc. The model outputs the effective priority value for each queue, based upon which scheduling decisions are made. On numerical examples, we illustrate the use of our model and show the correctness and effectiveness of our model. More importantly, {{we were able to}} show that the batch processors ’ utilization could be increased and jobs’ average lateness (with respect to the internal deadline) reduced significantly by applying our methodology. I...|$|E
40|$|Abstract: 2 ̆ 2 We ask the question, 2 ̆ 7 for {{minimizing}} mean response time, {{which is}} preferable: one fast server of speed 1, or k slow servers each of speed 1 /k? 2 ̆ 7 Our setting is the M/GI/k system with two priority classes of customers, high priority and low priority, where G is a phase-type distribution. We find that multiple slow servers are often preferable [...] and we demonstrate {{exactly how many}} servers are preferable {{as a function of}} load and G. In addition, we find that the optimal number of servers with respect to the high <b>priority</b> <b>jobs</b> may be very different from that preferred by low <b>priority</b> <b>jobs,</b> and we characterize these preferences. We also evaluate the optimal number of servers with respect to overall mean response time, averaged over high and low <b>priority</b> <b>jobs.</b> Lastly, we ascertain the effect of the variability of high <b>priority</b> <b>jobs</b> on low <b>priority</b> <b>jobs.</b> This paper is the first to analyze an M/GI/k system with two priority classes and a general phase-type distribution. Prior analyses of the M/GI/k with two priority classes either require that G be exponential, or are approximations that work well when G is exponential, but are less reliable for more variable G. Our analytical method {{is very different from the}} prior literature: it combines the technique of dimensionality reduction (see [9]) with Neuts 2 ̆ 7 technique for determining busy periods in multiserver systems [22]. Our analysis is approximate, but can be made as accurate as desired, and is verified via simulation. 2 ̆...|$|R
40|$|In Fall 2008, the Communications Network {{surveyed}} professionals {{working in}} communications at private and community foundations {{to learn about}} <b>job</b> satisfaction, <b>priorities,</b> relationships with other departments, changing {{nature of the work}} they do, among other things. This report summarizes those findings...|$|R
40|$|Abstract — This paper {{considers}} the modelling and designing of a production-flow scheduler based on fuzzy interval system. Particularly, the supervisory control is built {{according to the}} satisfaction degree of conflicting objectives which are quantified by fuzzy intervals. The control system aims at adjusting the machine’s production rates {{in such a way}} that satisfies the demand while maintaining the overall performances within acceptable limits. At the shop-floor level, the actual dispatching times are determined from the continuous production rates through a sampling procedure. A decision for the actual part to be processed is taken using some criterions which represent a measure of the <b>job’s</b> <b>priority.</b> A case study demonstrates the efficiency of the proposed control approach T I...|$|R
40|$|We {{describe}} a new, non-FCFS policy to schedule parallel jobs on systems {{that may be}} part of a computational grid. Our algorithm continuously monitors the system (i. e., intensity of incoming jobs and variability of their resource demands) and continuously adapts its scheduling parameters to sudden workload fluctuations. The proposed policy is based on backfilling which permits job rearrangement in the waiting queue. By exploiting otherwise idle processors, this rearrangement reduces fragmentation of system resources, thereby providing higher system utilization. We propose to maintain multiple job queues that effectively separate jobs according to their projected execution time. Our policy supports different <b>job</b> <b>priority</b> classes as well as job reservations, making it appropriate for scheduling jobs on parallel systems that are part of a computational grid. Detailed performance comparisons via simulation using traces from the Parallel Workload Archive indicate that the proposed policy consistently outperforms traditional scheduling approaches...|$|E
40|$|This paper {{describes}} {{the design and}} implementation of a neural network-based <b>job</b> <b>priority</b> assigner system for a job scheduling environment. Scheduling deals with the allocation of resources over time to perform a collection of tasks. Scheduling problems arise in domains as diverse as manufacturing, computer processing, transportation, health care, space exploration, and education. In {{the case of a}} neural network (NN) based scheduler, once the job attributes are properly trained for a specified schedule, it will never miss that related scheduling pattern for that particular job. An NN based scheduling procedure can successfully overcome the local minima of its error surface. This paper reports on research which established that a back propagation neural network-based priority procedure would recognize jobs from a job queue by estimating each job’s priority. Once the priorities are assigned, {{it is not possible to}} alter the priorities under any circumstances...|$|E
40|$|A {{conservative}} synchronization protocol {{is described}} for the parallel simulation of queueing networks having C <b>job</b> <b>priority</b> classes, where a job's class is fixed. This problem has long vexed designers of conservative synchronization protocols {{because of its}} seemingly poor ability to compute lookahead: {{the time of the}} next departure. For, a job in service having low priority can be preempted at any time by an arrival having higher priority and an arbitrarily small service time. The solution is to skew the event generation activity so that the events for higher priority jobs are generated farther ahead in simulated time than lower priority jobs. Thus, when a lower priority job enters service for the first time, all the higher priority jobs that may preempt it are already known and the job's departure time can be exactly predicted. Finally, the protocol was analyzed and it was demonstrated that good performance can be expected on the simulation of large queueing networks...|$|E
40|$|In {{real world}} {{scheduling}} problems, <b>priorities</b> of <b>jobs</b> may change over time. A less important job today {{may be of}} high importance tomorrow and vice versa. Another important aspect of decision making in manufacturing environments is often the impreciseness of the problem definition, comprising both the available data and the knowledge about the preference structure of the decision maker. The paper presents a study of neighbourhood search heuristics for fuzzy scheduling. We especially {{address the problem of}} changing <b>job</b> <b>priorities</b> over time as studied at the Sherwood Press Corporation, a Nottingham based printing company. It can be shown, that the use of multiple criteria within the search process may improve the effectiveness of local search operators...|$|R
40|$|This paper {{presents}} Natjam, {{a system}} that supports arbitrary <b>job</b> <b>priorities,</b> hard real-time scheduling, and efficient preemption for Mapreduce clusters that are resource-constrained. Our contributions include: i) exploration and evaluation of smart eviction policies for jobs and for tasks, based on resource usage, task runtime, and job deadlines; and ii) a work-conserving task preemption mechanism for Mapreduce. We incorporated Natjam into the Hadoop YARN scheduler framework (in Hadoop 0. 23). We present experiments from deployments on a test cluster, Emulab and a Yahoo! commercial cluster, using both synthetic workloads as well as Hadoop cluster traces from Yahoo!. Our results reveal that Natjam incurs overheads as low as 7 %, and is preferable to existing approaches...|$|R
40|$|This article {{models and}} evaluates the common {{practice}} {{found in many}} job shops of revising <b>job</b> <b>priorities</b> {{at the end of}} accounting periods to achieve specified goals, e. g. monthly dollars shipped. Fourth-week rules are modelled which utilize time priorities the first three weeks and value (cost/profit) priorities the last week for jobs near completion. The performance of these rules is compared to that of rules which use value information throughout the month for both randomly routed and flow routed job shops. These value-based rules are shown to out perform the fourth-week rules at several utilization levels of the shop. In addition, these value-based rules eliminate the shop disruption which often results when fourth week rules are used. ...|$|R
