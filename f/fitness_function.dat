3800|1076|Public
5|$|Optimality: {{the genetic}} code {{continued}} to evolve after its initial creation, so that the current code maximizes some <b>fitness</b> <b>function,</b> usually some kind of error minimization.|$|E
25|$|The {{concept of}} a scalar valued <b>fitness</b> <b>function</b> f(s) also {{corresponds}} to the {{concept of a}} potential or energy function in physics. The two concepts only differ in that physicists traditionally think in terms of minimizing the potential function, while biologists prefer the notion that fitness is being maximized. Therefore, taking the inverse of a potential function turns it into a <b>fitness</b> <b>function,</b> and vice versa.|$|E
25|$|In {{evolutionary}} optimization problems, fitness landscapes are {{evaluations of}} a <b>fitness</b> <b>function</b> for all candidate solutions (see below).|$|E
3000|$|Utility theory-based <b>fitness</b> <b>functions</b> (UTB-FFs) are <b>fitness</b> <b>functions</b> {{based on}} UTB-REFs. We {{analyzed}} eight UTB-FFs (F 3 to F 10) defined as follows: [...]...|$|R
30|$|We propose aggregative {{context-aware}} <b>fitness</b> <b>functions</b> {{based on}} feature selection for evolutionary learning of characteristic graph patterns. The proposed <b>fitness</b> <b>functions</b> estimate the <b>fitness</b> {{of a set}} of correlated individuals rather than the sum of fitness of the individuals, and specify the fitness of an individual as its contribution degree {{in the context of the}} set. We apply the proposed <b>fitness</b> <b>functions</b> to our evolutionary learning, based on Genetic Programming, for obtaining characteristic block-preserving outerplanar graph patterns and characteristic TTSP graph patterns from positive and negative graph data. We report some experimental results on our evolutionary learning of characteristic graph patterns, using the context-aware <b>fitness</b> <b>functions.</b>|$|R
40|$|Credit card fraud {{detection}} {{based on}} machine learning has recently attracted considerable interest {{from the research}} community. One {{of the most important}} tasks in this area is the ability of classifiers to handle the imbalance in credit card data. In this scenario, classifiers tend to yield poor accuracy on the fraud class (minority class) despite realizing high overall accuracy. This is due to the influence of the majority class on traditional training criteria. In this paper, we aim to apply genetic programming to address this issue by adapting existing <b>fitness</b> <b>functions.</b> We examine two <b>fitness</b> <b>functions</b> from previous studies and develop two new <b>fitness</b> <b>functions</b> to evolve GP classifier with superior accuracy on the minority class and overall. Two UCI credit card datasets are used {{to evaluate the effectiveness of}} the proposed <b>fitness</b> <b>functions.</b> The results demonstrate that the proposed <b>fitness</b> <b>functions</b> augment GP classifiers, encouraging fitter solutions on both the minority and the majority classes...|$|R
25|$|In {{order to}} use {{evolutionary}} optimization, {{one has to}} define for every possible solution s {{to the problem of}} interest (i.e., every possible route {{in the case of the}} delivery truck) how 'good' it is. This is done by introducing a scalar-valued function f(s) (scalar valued means that f(s) is a simple number, such as 0.3, while s can be a more complicated object, for example a list of destination addresses in the case of the delivery truck), which is called the <b>fitness</b> <b>function.</b>|$|E
25|$|The {{second is}} {{evolutionary}} robots. This is a methodology that uses evolutionary computation to help design robots, especially the body form, or motion and behavior controllers. In {{a similar way}} to natural evolution, a large population of robots is allowed to compete in some way, or their ability to perform a task is measured using a <b>fitness</b> <b>function.</b> Those that perform worst are removed from the population and replaced by a new set, which have new behaviors based on those of the winners. Over time the population improves, and eventually a satisfactory robot may appear. This happens without any direct programming of the robots by the researchers. Researchers use this method both to create better robots, and to explore the nature of evolution. Because the process often requires many generations of robots to be simulated, this technique may be run entirely or mostly in simulation, then tested on real robots once the evolved algorithms are good enough. Currently, there are about 10 million industrial robots toiling around the world, and Japan is the top country having high density of utilizing robots in its manufacturing industry.|$|E
500|$|The {{principles}} {{of natural selection}} have inspired a variety of computational techniques, such as [...] "soft" [...] artificial life, that simulate selective processes and can be highly efficient in 'adapting' entities to an environment defined by a specified <b>fitness</b> <b>function.</b> For example, a class of heuristic optimisation algorithms known as genetic algorithms, pioneered by John Henry Holland in the 1970s and expanded upon by David E. Goldberg, identify optimal solutions by simulated reproduction and mutation of a population of solutions defined by an initial probability distribution. Such algorithms are particularly useful when applied to problems whose energy landscape is very rough or has many local minima.|$|E
40|$|Abstract—Genetic {{algorithms}} {{have been}} successfully used for searching for quasigroups with good properties. In this study we extend previous work done on evolutionary search for quasigroups by defining new <b>fitness</b> <b>functions</b> based on selected algebraical properties of the quasigroups. Introduced <b>fitness</b> <b>functions</b> make use of heterogeneous sequences generated during the exponentiation of quasigroups elements. Effects of the artificial evolution utilizing proposed <b>fitness</b> <b>functions</b> are illustrated on quasigroups of the order 8, 10, and 12. Keywords-genetic algorithms, quasigroups, optimization, fitness I...|$|R
40|$|Attribute {{reduction}} {{is one of}} the most important topics in rough set theory. Heuristic attribute reduction algorithms have been presented to solve the attribute reduction problem. It is generally known that <b>fitness</b> <b>functions</b> play a key role in developing heuristic attribute reduction algorithms. The monotonicity of <b>fitness</b> <b>functions</b> can guarantee the validity of heuristic attribute reduction algorithms. In probabilistic rough set model, distribution reducts can ensure the decision rules derived from the reducts are compatible with those derived from the original decision table. However, there are few studies on developing heuristic attribute reduction algorithms for finding distribution reducts. This is partly due to the fact that there are no monotonic <b>fitness</b> <b>functions</b> that are used to design heuristic attribute reduction algorithms in probabilistic rough set model. The main objective of this paper is to develop heuristic attribute reduction algorithms for finding distribution reducts in probabilistic rough set model. For one thing, two monotonic <b>fitness</b> <b>functions</b> are constructed, from which equivalence definitions of distribution reducts can be obtained. For another, two modified monotonic <b>fitness</b> <b>functions</b> are proposed to evaluate the significance of attributes more effectively. On this basis, two heuristic attribute reduction algorithms for finding distribution reducts are developed based on addition-deletion method and deletion method. In particular, the monotonicity of <b>fitness</b> <b>functions</b> guarantees the rationality of the proposed heuristic attribute reduction algorithms. Results of experimental analysis are included to quantify the effectiveness of the proposed <b>fitness</b> <b>functions</b> and distribution reducts. Comment: 44 pages, 24 figure...|$|R
40|$|<b>Fitness</b> <b>functions</b> are the {{evaluation}} measures driving evolutionary processes towards solutions. In this paper, three <b>fitness</b> <b>functions</b> are proposed for solving the unbalanced dataset problem in Haptic-based handwritten signatures using genetic programming (GP). The {{use of these}} specifically designed <b>fitness</b> <b>functions</b> produced simpler analytical expressions than those obtained with currently available fitness measures, while keeping comparable classification accuracy. The functions introduced in this paper capture explicitly the nature of unbalanced data, exhibit better dimensionality reduction and have better False Rejection Rate. Peer reviewed: YesNRC publication: Ye...|$|R
2500|$|... genetic {{algorithms}} to [...] "evolve" [...] new low energy conformations {{and where the}} score of each pose acts as the <b>fitness</b> <b>function</b> used to select individuals for the next iteration.|$|E
2500|$|Hence, the <b>fitness</b> <b>function</b> [...] is {{a mapping}} between strings of length K+1 and scalars, which Weinberger's later work calls [...] "fitness {{contributions}}". Such fitness contributions are often chosen randomly from some specified probability distribution.|$|E
2500|$|The {{function}} f is called, variously, {{an objective}} function, a loss function or cost function (minimization), [...] a utility function or <b>fitness</b> <b>function</b> (maximization), or, in certain fields, an energy function or energy functional. A feasible solution that minimizes (or maximizes, {{if that is}} the goal) the objective function is called an optimal solution.|$|E
40|$|Abstract. A {{new kind}} of <b>fitness</b> <b>functions</b> for {{controller}} optimization is presented. This new <b>fitness</b> <b>functions</b> are postulated to be strong causal. Thus a better behaviour during the optimization process can be achieved. The design of dynamical systems for industrial applications can be divided in to two parts...|$|R
5000|$|... #Subtitle level 3: <b>Fitness</b> <b>functions</b> and the {{selection}} environment ...|$|R
5000|$|... #Subtitle level 5: <b>Fitness</b> <b>functions</b> for {{classification}} and {{logistic regression}} ...|$|R
2500|$|Evolutionary {{robotics}} (ER) is {{a methodology}} that uses evolutionary computation to develop controllers for autonomous robots. Algorithms in ER frequently operate on populations of candidate controllers, initially selected from some distribution. [...] This population is then repeatedly modified {{according to a}} <b>fitness</b> <b>function.</b> [...] In the case of genetic algorithms (or [...] "GAs"), a common method in evolutionary computation, the population of candidate controllers is repeatedly grown according to crossover, mutation and other GA operators ...|$|E
2500|$|For simplicity, we {{will work}} with binary strings. Consider an NK model with N = 5, K = 1. Here, the fitness of a string is given by the sum of {{individual}} fitness contributions from each of 5 loci. Each fitness contribution depends on the local locus value and one other. We will employ the convention that , so that each locus is affected by its neighbour, and [...] for cyclicity. If we choose, for example, the <b>fitness</b> <b>function</b> f(0, 0) = 0; f(0, 1) = 1; f(1, 0) = 2; f(1, 1) = 0, the fitness values of two example strings are: ...|$|E
2500|$|... {{and then}} culled {{according}} to the <b>fitness</b> <b>function.</b> The candidate controllers used in ER applications may be drawn from some subset of the set of artificial neural networks, although some applications (including SAMUEL, developed at the Naval Center for Applied Research in Artificial Intelligence) use collections of [...] "IF THEN ELSE" [...] rules as the constituent parts of an individual controller. [...] It is theoretically possible to use any set of symbolic formulations of a control law (sometimes called a policy in the machine learning community) as the space of possible candidate controllers. Artificial neural networks {{can also be used}} for robot learning outside the context of evolutionary robotics. [...] In particular, other forms of reinforcement learning can be used for learning robot controllers.|$|E
30|$|We propose new {{context-aware}} <b>fitness</b> <b>functions</b> {{and give}} GP-based learning methods incorporating the proposed functions for acquiring characteristic bpo-graph patterns and TTSP graph patterns. The proposed context-aware <b>fitness</b> <b>functions</b> employ super-CWC [19] (CWC, for short), {{which is a}} state-of-the-art feature selection algorithm. Context-aware <b>fitness</b> <b>functions</b> evaluate each individual based on its importance in a group, while conventional <b>fitness</b> <b>functions</b> evaluate each individual independently in population. Since the fitness of an individual is evaluated within a group (i.e. context), if the group including the individual is changed, the fitness of this individual may be also changed. This aspect {{is very important to}} find a general pattern to cover the whole set of positive examples because even if each selected pattern has relatively high coverage of positive examples, each coverage does not necessarily imply the high coverage of the whole positive examples by the selected individuals.|$|R
30|$|In this paper, <b>fitness</b> <b>functions</b> {{aware of}} context are {{considered}} {{in the sense that}} the fitness of an individual depends on a set of individuals relevant to it, instead of the individual only. Three new aggregative context-aware <b>fitness</b> <b>functions</b> based on a feature selection method [19] are proposed for evolutionary learning of characteristic graph patterns. Using the proposed <b>fitness</b> <b>functions,</b> we estimate the fitness of a set of correlated individuals rather than the sum of fitness of the individuals, and define the fitness of an individual as its contribution degree in the context of the set of correlated individuals.|$|R
40|$|This paper {{introduces}} a Minimum Description Length (MDL) principle to define <b>fitness</b> <b>functions</b> in Genetic Programming (GP). In traditional (Koza-style) GP, {{the size of}} trees was usually controlled by user-defined parameters, such as {{the maximum number of}} nodes and maximum tree depth. Large tree sizes meant that the time necessary to measure their fitnesses often dominated total processing time. To overcome this difficulty, we introduce a method for controlling tree growth, which uses an MDL principle. Initially we choose a "decision tree" representation for the GP chromosomes, and then show how an MDL principle can be used to define GP <b>fitness</b> <b>functions.</b> Thereafter we apply the MDL-based <b>fitness</b> <b>functions</b> to some practical problems. Using our implemented system "STROGANOFF", we show how MDL-based <b>fitness</b> <b>functions</b> can be applied successfully to problems of pattern recognitions. The results demonstrate that our approach is superior to usual neural networks in terms of general [...] ...|$|R
2500|$|In other words, with a {{probability}} [...] the particle [...] evolves {{to a new}} state [...] randomly chosen with the probability distribution otherwise, [...] jumps to a new location [...] randomly chosen with {{a probability}} proportional to [...] and evolves to a new state [...] randomly chosen with the probability distribution [...] If [...] is the unit function and , {{the interaction between the}} particle vanishes and the particle model reduces to a sequence of independent copies of the Markov chain [...] When [...] the mean field particle model described above reduces to a simple mutation-selection genetic algorithm with <b>fitness</b> <b>function</b> G and mutation transition M. These nonlinear Markov chain models and their mean field particle interpretation can be extended to [...] time non homogeneous models on general measurable state spaces (including transition states, path spaces and random excursion spaces) and continuous time models.|$|E
2500|$|Many of the {{commonly}} used {{machine learning algorithms}} require a set of training examples consisting of both a hypothetical input and a desired answer. [...] In many robot learning applications the desired answer is an action for the robot to take. These actions are usually not known explicitly a priori, instead the robot can, at best, receive a value indicating {{the success or failure}} of a given action taken. [...] Evolutionary algorithms are natural solutions to this sort of problem framework, as the <b>fitness</b> <b>function</b> need only encode {{the success or failure of}} a given controller, rather than the precise actions the controller should have taken. [...] An alternative to the use of evolutionary computation in robot learning is the use of other forms of reinforcement learning, such as q-learning, to learn the fitness of any particular action, and then use predicted fitness values indirectly to create a controller.|$|E
2500|$|In {{computational}} physics {{and more specifically}} in quantum mechanics, the ground state energies of quantum systems {{is associated with the}} top of the spectrum of Schrödinger's operators. The Schrödinger equation is the quantum mechanics version of the Newton's second law of motion of classical mechanics (the mass times the acceleration is the sum of the forces). This equation represents the wave function (a.k.a. the quantum state) evolution of some physical system, including molecular, atomic of subatomic systems, as well as macroscopic systems like the universe. The solution of the imaginary time Schrödinger equation (a.k.a. the heat equation) is given by a Feynman-Kac distribution associated with a free evolution [...] Markov process (often represented by Brownian motions) in the set of electronic or macromolecular configurations and some potential energy function. The long time behavior of these nonlinear semigroups is related to top eigenvalues and ground state energies of [...] Schrödinger's operators. [...] The genetic type mean field interpretation of these Feynman-Kac models are termed Resample Monte Carlo, or Diffusion Monte Carlo methods. These branching type evolutionary algorithms are based on mutation and selection transitions. During the mutation transition, the walkers evolve randomly and independently in a potential energy landscape on particle configurations. [...] The mean field selection process (a.k.a. quantum teleportation, population reconfiguration, resampled transition) is associated with a <b>fitness</b> <b>function</b> that [...] reflects the particle absorption in an energy well. Configurations with low relative energy are more likely to duplicate. In molecular chemistry, and statistical physics Mean field particle methods are also used to sample Boltzmann-Gibbs measures associated with some cooling schedule, and to compute their normalizing constants (a.k.a. free energies, or partition functions).|$|E
40|$|A {{deterministic}} mutation-selection {{model in}} the sequence space approach is investigated. Genotypes are identified with two-letter sequences. Mutation is modelled as a Markov process, <b>fitness</b> <b>functions</b> are of Hopfield type, where the fitness of a sequence {{is determined by the}} Hamming distances to a number of predefined patterns. Using a maximum principle for the population mean fitness in equilibrium, the error threshold phenomenon is studied for quadratic Hopfield-type <b>fitness</b> <b>functions</b> with small numbers of patterns. Different from previous investigations of the Hopfield model, the system shows error threshold behaviour not for all <b>fitness</b> <b>functions,</b> but only for certain parameter values. Comment: 36 pages, 9 figure...|$|R
40|$|Abstract. This paper {{deals with}} an {{automatic}} design of image filters at hardware level in dynamic environment. The environment is modeled using eight different <b>fitness</b> <b>functions</b> representing eight types of noise. Various properties of adaptation process have been measured when these <b>fitness</b> <b>functions</b> were applied for a constant time. The resulting filters operate in average {{much better than the}} conventional solution...|$|R
40|$|Alternative {{reproductive}} phenotypes (ARPs) occur {{across a}} wide range of taxa. Most ARPs are conditionally expressed in response to a cue, for example body size, that reliably correlates with the status of the environment: individuals below the (body size) threshold then develop into one morph, and individuals above the threshold develop into the alternative morph. The environmental threshold model provides a theoretical framework to understand the evolution and maintenance of such ARPs, yet no study has examined the underlying <b>fitness</b> <b>functions</b> that are necessary to realize this. Here, we empirically examined <b>fitness</b> <b>functions</b> for the two male morphs of the bulb mite (Rhizoglyphus robini). <b>Fitness</b> <b>functions</b> were derived in relation to male size for solitary males and in relation to female size under competition. In both cases, the <b>fitness</b> <b>functions</b> of the two morphs intersected, and the resulting fitness trade-offs {{may play a role in}} the maintenance of this male dimorphism. We furthermore found that competition was strongest between males of the same morph, suggesting that fitness trade-off in relation to male size may persist under competition. Our results are a first step towards unravelling <b>fitness</b> <b>functions</b> of ARPs that are environmentally cued threshold traits, which is essential for understanding their maintenance and in explaining the response to selection against alternative morphs...|$|R
50|$|The {{stopping}} criterion is {{evaluated by}} the <b>fitness</b> <b>function</b> as it gets the reciprocal of the mean-squared-error from each network during training. Therefore, {{the goal of the}} genetic algorithm is to maximize the <b>fitness</b> <b>function,</b> reducing the mean-squared-error.|$|E
50|$|Two main {{classes of}} fitness {{functions}} exist: {{one where the}} <b>fitness</b> <b>function</b> does not change, as in optimizing a fixed function or testing with a fixed set of test cases; and one where the <b>fitness</b> <b>function</b> is mutable, as in niche differentiation or co-evolving the set of test cases.|$|E
5000|$|Definition of the <b>fitness</b> <b>function</b> is not {{straightforward}} in {{many cases}} and often is performed iteratively if the fittest solutions produced by GA are not what is desired. In some cases, {{it is very hard}} or impossible to come up even with a guess of what <b>fitness</b> <b>function</b> definition might be. Interactive genetic algorithms address this difficulty by outsourcing evaluation to external agents (normally humans).|$|E
30|$|Accordingly, <b>fitness</b> <b>functions</b> O_R are {{developed}} {{for all three}} cases of scenarios 2 – 5.|$|R
40|$|Abstract. We {{explore the}} {{advantages}} of DNA-like genomes for evolutionary computation in silico. Coupled with simulations of chemical reactions, these genomes offer greater efficiency, reliability, scalability, new computationally feasible <b>fitness</b> <b>functions,</b> and more dynamic evolutionary algorithms. The prototype application is the decision problem of HPP (the Hamiltonian Path Problem.) Other applications include pre-processing of protocols for biomolecular computing and novel <b>fitness</b> <b>functions</b> for evolution in silico. ...|$|R
50|$|So by {{counting}} the TP, TN, FP, and FN and further assigning different weights to these {{four types of}} classifications, {{it is possible to}} create smoother and therefore more efficient <b>fitness</b> <b>functions.</b> Some popular <b>fitness</b> <b>functions</b> based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient, and cost/gain matrix which combines the costs and gains assigned to the 4 different types of classifications.|$|R
