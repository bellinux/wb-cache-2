4|128|Public
40|$|The {{structure}} of X 6000 DC source system is introduced. A temperature monitor device for its storage pile based on 1 -wire bus is designed. Its {{central processing unit}} is single chip microcomputer 80296 SA in the monitor unit of this DC source. The DS 1822 chip, a kind of digital thermometer chip based on 1 -wire bus, is {{used to measure the}} temperature of the X 6000 DC source system storage pile. The hardware, interface and software are designed and the condition description of the <b>interface</b> <b>routine</b> and realization are given. The system possesses of many advantages, including its novel structure, simple circuit and expedient control. <br /...|$|E
30|$|FLO- 2 D {{is used in}} {{this study}} as the flood {{inundation}} model. It is based on the full 2 D shallow water equations (also called dynamic wave momentum equation) (FLO- 2 D Software, 2012). In the FLO- 2 D modeling system, channel flow is 1 D with the channel geometry represented by either rectangular or trapezoidal cross sections; meanwhile, the overland flow is modelled 2 D as either sheet flow or flow in multiple channels (FLO- 2 D Software, 2012). Overbank flow in the channel is computed when the channel capacity is exceeded. Besides, an <b>interface</b> <b>routine</b> calculates the channel to floodplain flow exchange including return flow to the channel. More technical details of FLO- 2 D can be referred to Obrien et al. (1993), O'Brien et al. (1999), and D'Agostino and Tecca (2006).|$|E
40|$|The present note {{provides}} {{a brief description}} of a collection of functions {{that can be used for}} accurate estimation of position and orientation of a camera relative to a guide mark. The software is intended to be incorporated in the navigation system on an autonomous guided vehicle. The software represents a C-implementation of the procedure outlined in the Master's thesis [Ols 97]. All functions are written in ANSI-C and assumes no hardware support for image processing. It is necessary for the user to write a few lines of code to interface to the software. How this <b>interface</b> <b>routine</b> is written depends of course on the available image processing hardware. The software has been tested on a PC supplied with a Meteor II frame grabber board from Matrox, Inc. The MIL Light library was available for communication with the frame grabber board. The software has also been tested under MATLAB where it was called as a so-called MEX-function. This made it easy to compare the [...] ...|$|E
50|$|IO.SYS is an {{essential}} part of MS-DOS and Windows 9x. It contains the default MS-DOS device drivers (hardware <b>interfacing</b> <b>routines)</b> and the DOS initialization program.|$|R
5000|$|Foreign Language Interface (FFI) for <b>interfacing</b> with <b>routines</b> {{written in}} C ...|$|R
50|$|The line {{discipline}} glues {{the low level}} device driver code with the high level generic <b>interface</b> <b>routines</b> (such as read(2), write(2) and ioctl(2)), and is responsible for implementing the semantics associated with the device. The policy is separated from the device driver so that the same serial hardware driver {{can be used by}} devices that require different data handling.|$|R
40|$|A feature {{recently}} developed for MCNPX [1] {{is the ability}} to perform transmutation calculations. Although this capability has been available to users via various post-processing utilities, such as Monteburns [2], {{it would be the first}} time this process is entirely automated within MCNPX. Such an enhancement provides many benefits to the user by eliminating the need to learn other post-processing codes, reducing errors in normalizations and auxiliary input, and eliminating file manipulation and tracking issues. This transmutation option is implemented with a batching scheme that updates material properties at various user-specified time steps. The number of particle histories sampled per batch is also specified by the user. Within each time step, MCNPX tallies a 63 -group neutron flux averaged over each material within the geometry. At the end of the time step, the neutron flux data and various 1 -group cross sections, along with related isotopic atom densities, are passed through an <b>interface</b> <b>routine</b> to CINDER 90 [3]. In its usual fashion, CINDER 90 uses the neutron fluxes to perform activation, depletion, and decay. It then updates the isotopic inventory, which then is returned to MCNPX for use during transport of the next time step. As usual, users can perform various time-dependent tallie...|$|E
40|$|We {{describe}} {{several new}} tools for modeling MPEC {{problems that are}} built around the introduction of an MPEC model type into the GAMS language. We develop subroutines that allow such models to be communicated directly to MPEC solvers. This library of <b>interface</b> <b>routines,</b> written in the C language, provides algorithmic developers with access to relevant problem data, including for example, function and Jacobian evaluations. A MATLAB interface to the GAMS MPEC model type has been designed using the <b>interface</b> <b>routines.</b> Existing MPEC models from the literature have been written in GAMS, and computational results are given that were obtained using all the tools described. Keywords Complementarity, Algorithm, MPEC, Modeling 1 Introduction The Mathematical Program with Equilibrium Constraints (MPEC) arises when one seeks to optimize an objective function subject to equilibrium contraints. These equilibrium constraints may {{take the form of}} a variational inequality or complementarity problem, o [...] ...|$|R
40|$|In {{its current}} state the basic purpose of {{annotate}} is to supply <b>interface</b> <b>routines</b> that support user actions {{that rely on}} the different meta-data packages provided through the Bioconductor Project. There are currently four basic categories of functions that are contained in annotate. � Interface functions for getting data out of specific meta-data libraries. � Functions that support querying the different web services provided b...|$|R
40|$|Abstract-During {{the past}} decade a number of multiimage picture {{processing}} software packages have been put together. However, {{only a few of}} the references to picture processing systems discuss image data structure or input/output routines. This correspondence is a first step in a direction toward getting a communication process started by suggesting some specifications for a multiimage data format and standard input/output <b>interface</b> <b>routines</b> to access the image data. Index Terms-Digital image processing, image processing, software. I...|$|R
40|$|This report {{describes}} the program description of an interactive graphics package interfacing the Vector General Graphics Display Unit and a Digital Equipment Corporation PDP- 11 / 50 computer. The program {{was written in}} the C-programming language and designed {{to be used in the}} multiprogramming environment of the UNIX Timesharing operating system. Included is a description of the Vector General, operating system modifications, device driver, and <b>interface</b> <b>routines.</b> (Author) Prepared for: Naval Electronics Systems Command (ELEX 320) Washington, D. C. [URL] 59051 N...|$|R
50|$|In the 1980s {{and early}} 1990s, desktop PCs were only running {{at a few}} MHz and {{assembly}} language routines were commonly used to speed up programs written in C, Fortran, Pascal and others. These languages, at the time, used different calling conventions. Macros {{could be used to}} <b>interface</b> <b>routines</b> written in assembly language to the front end of applications written in almost any language. Again, the basic assembly language code remained the same, only the macro libraries needed to be written for each target language.|$|R
5000|$|<b>Interfaces</b> between <b>routines</b> {{are some}} of the most {{error-prone}} areas of a program. One study showed that 39 percent of all errors were errors in communication between routines.|$|R
25|$|A set of interrupt-driven user <b>interface</b> <b>routines</b> called Pinball {{provided}} {{keyboard and}} display {{services for the}} jobs and tasks running on the AGC. A rich set of user-accessible routines were provided to let the operator (astronaut) display the contents of various memory locations in octal or decimal in groups of 1, 2, or 3 registers at a time. Monitor routines were provided so the operator could initiate a task to periodically redisplay the contents of certain memory locations. Jobs could be initiated. The Pinball routines performed the (very rough) equivalent of the UNIX shell.|$|R
40|$|This {{report is}} the {{description}} of a users manual for an interactive graphics package designed to allow programmatic control of the Vector General Graphics Display Unit from a Digital Equipment Corporation PDP- 11 / 50 computer. The manual requires {{a knowledge of the}} C-programming language and a general familiarity with graphics terminology. Included is {{a brief description of the}} Vector General Graphics Display Unit, a description of the <b>interface</b> <b>routines,</b> and a description of the Vector General graphics display instructions. (Author) Prepared for: Naval Electronics Systems Command (ELEX 320), Washington, D. C. [URL]...|$|R
40|$|With the {{development}} of high-level languages for new computer architectures comes the need for appropriate debugging tools as well. One method for meeting this need would be to develop, from scratch, a symbolic debugger {{with the introduction of}} each new language implementation for any given architecture. This, however, seems to require unnecessary duplication of effort among developers. Compilation technology has alleviated some duplication of effort in {{the development}} of compilers. Can similar ideas aid in the efficient development of symbolic debuggers as well? Maygen explores the possibility of making debugger development efficient by influencing the language and architecture development processes. Maygen is a "debugger generation system," built upon the idea that symbolic debuggers can be divided into three components: a set of source language <b>interface</b> <b>routines,</b> a set of machine architecture <b>interface</b> <b>routines,</b> and a language-independent and architecture-independent debugger skeleton. Maygen then exploits this modularity: First, Maygen precisely defines as well as houses the languageindependent and architecture-independent debugger skeleton. Second, Maygen defines the protocol for interface interaction among source language developers, machine architecture developers, and the general-purpose debugger skeleton. Finally, Maygen provides a framework in which the resident debugger skeleton is automatically developed into a stand-alone symbolic debugger; the resulting debugger is tailored to the specific provisions of a particular language group and a particular architecture group...|$|R
50|$|The {{programming}} <b>interface</b> macros and <b>routines</b> are collectively called DAM: {{direct access}} methods.|$|R
40|$|The ANSYS {{environment}} {{allows for}} implementing user elements in Fortran subroutines, compiling a new executable file; however, this requires the user to: a) understand the <b>interfacing</b> <b>routines</b> {{provided with the}} ANSYS code; b) to correctly guess how the <b>interfacing</b> <b>routines</b> will be actually called by the ANSYS environment. This burden can be avoided by exploiting the APDL (ANSYS Parametric Design Language) command, which allows to call an external executable program from within the main ANSYS analysis procedure, or from within an APDL subroutine. The main idea is to pass quantities of interest (e. g. nodal displacements, velocities, etc.) to the external executable program via an intermediate data file written by standard APDL commands. The external executable replies with some computed quantities (e. g. nodal forces) in a second data file that will be read, processed and applied to the structure by APDL statements. It is worth underline that this implies a decoupling between the process of achieving a structural equilibrium configuration {{and that of the}} state determination of the external element. The usefulness and the limits inherently with this strategy will be shown with reference to the implementation of a new external non-linear element devoted to modelling passive (Bouc-Wen) and semi-active (Skyhook) control devices; these will be used in companion papers for the control of a bridge structure under seismic and wind loading. The external user element is finally evaluated by a comparison with a proven implementation inside the MATLAB environment, which explicitly considers the coupling between the structural state determination and that of the external element, with reference to seismic excitatio...|$|R
40|$|NASA's Goddard Space Flight Center (GSFC) has {{developed}} a Transportable Applications Executive (TAE) for use in implementing portable applications software that can be shared by different research projects. Since many of the supported disciplines require the interactive display and manipulation of remotely sensed images, a device independent Display Management Subsystem (DMS) was written as a TAE extension. The DMS attempts to abstract and standardize the device dependent functions {{that are used in}} the display and manipulation of image data on image analysis terminals. This paper explores the concept of DMS and the <b>interface</b> <b>routines</b> that are available to the applications programmer for use in developing a set of portable image display utility programs...|$|R
5000|$|Hamilton {{then joined}} the Charles Stark Draper Laboratory at MIT, {{which at the}} time was working on the Apollo space mission. She {{eventually}} led a team credited with developing the software for Apollo and Skylab. Hamilton's team was responsible for developing in-flight software, which included algorithms designed by various senior scientists for the Apollo command module, lunar lander, and the subsequent Skylab. Another part of her team designed and developed the systems software [...] which included the error detection and recovery software such as restarts and the Display <b>Interface</b> <b>Routines</b> (AKA the Priority Displays) which Hamilton designed and developed. She worked to gain hands-on experience during a time when computer science courses were uncommon and software engineering courses did not exist.|$|R
40|$|A RHIC Accelerator Device Object is an {{abstraction}} {{which provides a}} software view {{of a collection of}} collider control points known as parameters. A grammar has been defined which allows these parameters, along with code describing methods for acquiring and modifying them, to be specified efficiently in compact definition files. These definition files are processed to produce C++ source code. This source code is compiled to produce an object file which can be loaded into a front end computer. Each loaded object serves as an Accelerator Device Object class definition. The collider will be controlled by applications which set and get the parameters in instances of these classes using a suite of <b>interface</b> <b>routines.</b> Significant features of the grammar are described with details about the generated C++ code. I...|$|R
50|$|One of {{the more}} subtle {{features}} of the SYM-1 {{was the use of}} a look up table in the low memory of the 6502. This provided a vectoring function in its operating system to redirect subroutine calls to various input and output drivers, including interrupt servicing. Users were able to develop their own <b>interface</b> <b>routines,</b> and substitute new vectors for the original vectors in the startup UV-EPROM. This seamlessly maintained the normal operation of the board's monitor and languages such as Synertek Systems BASIC. One of the later home/education computers that used this concept extensively was the BBC Micro produced by Acorn Computers in the UK. Some of the other computer designers of this era failed to grasp the significance of this elegant use of vectors to the software mapping of new developments in hardware.|$|R
5000|$|MS-DOS itself did {{not provide}} any way to {{position}} the text cursor other than to advance it after displaying each letter (teletype mode). While the BIOS video <b>interface</b> <b>routines</b> were adequate for rudimentary output, they were necessarily less efficient than direct hardware addressing, as they added extra processing; {{they did not have}} [...] "string" [...] output, but only character-by-character teletype output, and they inserted delays to prevent CGA hardware [...] "snow" [...] (a display artifact of CGA cards produced when writing directly to screen memory)——an especially bad artifact since they were called by IRQs, thus making multitasking very difficult. A program that wrote directly to video memory could achieve output rates 5 to 20 times faster than making system calls. Turbo Pascal used this technique from its earliest versions.|$|R
40|$|Instructions {{are given}} {{for using the}} Winterkill {{indicator}} model CCAD data base interface driver. The purpose {{of the system is}} to interface the Winterkill Indicator Model with the CCAD operational data base. The <b>interface</b> driver <b>routine</b> decides what meteorological stations should be processed and calls the proper subroutines to process the stations...|$|R
40|$|The Parallel Virtual Machine #PVM#, an {{integrated}} framework for heterogeneous network computing, lets scientists exploit collections of networked machines when carrying out complex scienti#c computations. Under PVM, a user-de#ned grouping of serial, parallel, and vector computers appears as one large distributed-memory machine. Con#guring a personal parallel virtual computer involves simply listing {{the names of}} the machines in a #le that is read when PVM is started. Applications can be written in Fortran 77 or C and parallelized by use of message-passing constructs common to most distributed-memory computers. With the use of messages sentover the network, multiple tasks of an application can cooperate to solve a problem in parallel. This article discusses components of PVM, including the programs and library of <b>interface</b> <b>routines.</b> It summarizes the characteristics of appropriate applications and discusses the current status and availability of PVM. In addition, the articl [...] ...|$|R
40|$|The Swarm {{storage system}} uses log-based {{striping}} to achieve high performance. Clients collect application writes in a log and stripe the log across multiple storage servers to aggregate server bandwidth. The Swarm storage server {{has been designed}} to meet various requirements of the Swarm storage system. These include high performance for data-intensive operations, rapid crash recovery, security support and atomic <b>interface</b> <b>routines.</b> The design of the Swarm storage server is simple enough to allow its implementation as a network appliance. Department of Computer Science The University of Arizona Tucson, AZ 1 Introduction Today's network file systems suffer from performance problems that limit their scalability. File servers often become a performance bottleneck when a system has to scale beyond a few dozens of nodes. Network file systems like NFS [Sandberg 85] try to deal with scalability by having multiple servers handling different parts of the directory hierarchy. This mapping of f [...] ...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimited. The Joint Army/Navy Rotorcraft Analysis and Design (JANRAD) computer program {{was developed to}} aid in the analysis of helicopter rotor performance, stability and control, and rotor dynamics. JANRAD is an interactive, user friendly program, capable of accurately and quickly solving helicopter design problems at the preliminary design level. The program was written as a collection of MATLAB script and function files (M-files) using the 386 -MATLAB version 3. 5 programming language. The M-file janrad. in invokes the user <b>interface</b> <b>routines</b> and calls various analysis modules (M-files) which contain the appropriate analysis and output routines. Each of these modules use a common routine, trim. m, which employs blade element theory and a harmonic balance method for rotor trim. The program is limited to conditions of steady flight with no winds and is accurate at a hover and for forward airspeeds {{greater than or equal to}} 50 knots. Major, United States Arm...|$|R
40|$|This code is {{designed}} to solve conic programming problems whose constraint cone {{is a product of}} semidefinite cones, second-order cones, nonnegative orthants and Euclidean spaces. It employs a primaldual predictor-corrector path-following method, with either the HKM or the NT search direction. The basic code is written in Matlab, but key subroutines in Fortran and C are incorporated via a Mex <b>interface.</b> <b>Routines</b> are provided to read in problems in either SDPA or SeDuMi format. Sparsity and block diagonal structure are exploited, but the latter needs to be given explicitly or detected via a subroutine that is provided. Various techniques to improve the efficiency and stablility of the algorithm are incorporated. For example, step-lengths associated with semidefinite cones are calculated via the Lanczos method. Numerical experiments show that this general purpose code can solve 80 % of a total of about 300 problems to an accuracy of at least 10 − 6 in relative duality gap and infeasibilities. ...|$|R
40|$|The Parallel Virtual Machine (PVM), an {{integrated}} framework for heterogeneous network computing, lets scientists exploit collections of networked machines when carrying out complex scientic computa-tions. Under PVM, a user-dened grouping of serial, parallel, and vector computers appears as one large distributed-memory machine. Con guring a personal parallel virtual computer involves simply listing {{the names of}} the machines in a le that is read when PVM is started. Applications can be written in Fortran 77 or C and parallelized by use of message-passing constructs common to most distributed-memory computers. With the use of messages sent over the network, multiple tasks of an application can cooperate to solve a problem in parallel. This article discusses components of PVM, including the programs and library of <b>interface</b> <b>routines.</b> It summarizes the characteristics of appropriate applications and discusses the current status and availabil-ity of PVM. In addition, the article introduces a recent extension to PVM known as the Heterogeneous Network Computing Environment (HeNCE). ...|$|R
40|$|The {{implementation}} of an inference engine for embedded diagnostic systems is described. The system {{consists of two}} distinct parts. The first is an off-line compiler which accepts a propositional logical statement {{of the relationship between}} facts and conclusions and produces data structures required by the on-line inference engine. The second part consists of the inference engine and <b>interface</b> <b>routines</b> which accept assertions of fact and return the conclusions which necessarily follow. Given a set of assertions, it will generate exactly the conclusions which logically follow. At the same time, it will detect any inconsistencies which may propagate from an inconsistent set of assertions or a poorly formulated set of rules. The memory requirements are fixed and the worst case execution times are bounded at compile time. The data structures and inference algorithms are very simple and well understood. The data structures and algorithms are described in detail. The system has been implemented on Lisp, Pascal, and Modula- 2...|$|R
40|$|A branch-and-cut mixed integer {{programming}} system, called bc - opt, is described, incorporating {{most of the}} valid inequalities {{that have been used}} or suggested for such systems, namely lifted 0 - 1 knapsack inequalities, 0 - 1 gub knapsack and integer knapsack inequalities, flow-cover and continuous knapsack inequalities, path inequalities for fixed charge network flow structure and Gomory mixed integer cuts. The principal development is a set of <b>interface</b> <b>routines</b> allowing these cut routines to generate cuts for new subsets or aggregations of constraints. The system is built using the XPRESS Optimisation Subroutine Library (XOSL) which includes a cut manager that handles the tree and cut management, so that the user only essentially needs to develop the cut separation routines. Results for the MIPLIB 3. 0 library are presented - 37 of the instances are solved very easily, optimal or near optimal solution are produced for 18 other instances, and of the 4 remaining instances, 3 have 0, + 1, - 1 matrices for which bc - opt contains no special features...|$|R
40|$|This report {{contains}} {{a description of}} the flow solver for hybrid three dimensional grids, consisting of prismatic and tetrahedral (or hexahedral) cells. The following topics are described: 1. Edge Based Data Structure 2. Determination of the Auxiliary Grid 3. Basic Flow Solver 4. Boundary Conditions From the initial grid an auxiliarygrid of control volumes is determined. The governing equations are solved on the auxiliary grid and fluxes over the boundaries of the control volumes are computed. From the fluxes the new flow conditions in grid points are computed. This iterative process is executed until a certain number of time steps has been performed. A separate chapter deals with the parallelisation of the code based on domain decomposition. The decomposition is performed for the auxiliary grid. For the communication to be performed <b>interface</b> <b>routines</b> are used. Furthermore the report {{contains a}} description of the adaptation module for local refinement of hybrid three dimensional grids, consisting of prismatic and tetrahedral cells. The main topics are: 1. Grid-Adaptation Indicator 2. Grid-Adaptation Algorith...|$|R
40|$|The paper {{presents}} the toolbox NLPLIB TB 1. 0 (NonLinear Programming LIBrary) � {{a set of}} Matlab solvers, test problems, graphical and computational utilities for unconstrained and constrained optimization, quadratic programming, unconstrained and constrained nonlinear least squares, box-bounded global optimization, global mixed-integer nonlinear programming, and exponential sum model tting. NLPLIB TB, like the toolbox OPERA TB for linear and discrete optimization, {{is a part of}} TOMLAB � an environment in Matlab for research and teaching in optimization. TOMLAB currently solves small and medium size dense problems. Presently, NLPLIB TB implements more than 25 solver algorithms, and it is possible to call solvers in the Matlab Optimization Toolbox. MEX- le interfaces are prepared for seven Fortran and C solvers, and others are easily added using the same type of <b>interface</b> <b>routines.</b> Currently, MEX- le interfaces have beendeveloped for MINOS, NPSOL, NPOPT, NLSSOL, LPOPT, QPOPT and LSSOL. There are four ways to solve a problem: by a direct call to the solver routine or a call to amulti-solver driver routine, or interactively, using the Graphica...|$|R
40|$|POTLIB 2001 is a {{computer}} program library of global chemical potential energy surface (PES) functions (91 functions in version 1. 0) along with test data, a suite of utility programs, and a convenient user interface. The PES programs are written in ANSI standard FORTRAN 77 {{and can be used}} to determine the Born–Oppenheimer potential energy of chemical systems {{as a function of the}} internal coordinates. The accompanying test data allow users to verify local implementations of this library. Finally, the utility programs permit use of this library in conjunction with a variety of chemical dynamics and chemical kinetics computer codes. <b>Interface</b> <b>routines</b> are provided for the POLYRATE and ABCRATE program packages of Truhlar and co-workers, the VENUS 96 program package of Hase and co-workers, and the VARIFLEX program package of Klippenstein and co-workers; the routines in this library can also be used in conjunction with the DYNASOL program package of Zhang and co-workers. This article describes the library and the utility programs and outlines the systematic conventions used for interfaces in the computer programs contained in the library. Adherence to these conventions will allow future PESs to be compatible with this library...|$|R
40|$|HyperCLIPS {{combines}} the intuitive, interactive user interface of the Apple Macintosh(TM) with the powerful symbolic computation {{of an expert}} system interpreter. HyperCard(TM) is an excellent environment for quickly developing {{the front end of}} an application with buttons, dialogs, and pictures, while the CLIPS interpreter provides a powerful inference engine for complex problem solving and analysis. By integrating HyperCard and CLIPS the advantages and uses of both packages are made available {{for a wide range of}} uses: rapid prototyping of knowledge-based expert systems, interactive simulations of physical systems, and intelligent control of hypertext processes, to name a few. Interfacing HyperCard and CLIPS is natural. HyperCard was designed to be extended through the use of external commands (XCMDs), and CLIPS was designed to be embedded through the use of the I/O router facilities and callable <b>interface</b> <b>routines.</b> With the exception of some technical difficulties which will be discussed later, HyperCLIPS implements this interface in a straight forward manner, using the facilities provided. An XCMD called 'ClipsX' was added to HyperCard to give access to the CLIPS routines: clear, load, reset, and run. And an I/O router was added to CLIPS to handle the communication of data between CLIPS and HyperCard...|$|R
40|$|The code we {{describe}} (FLY) is a newly written code (using the tree N-body method), for three-dimensional self-gravitating collisionless systems evolution. FLY is a fully parallel code {{based on the}} tree Barnes-Hut algorithm and periodical boundary conditions are implemented {{by means of the}} Ewald summation technique. FLY is based on the one-side communication paradigm to share data among the processors, that access to remote private data avoiding any kind of synchronism. The code was originally developed on CRAY T 3 E system using the logically SHared MEMory access routines (SHMEM) but it runs also on SGI ORIGIN systems and on IBM SP by using the Low-Level Application Programming <b>Interface</b> <b>routines</b> (LAPI). This new code reaches good performance in all systems where it has been well-tested. This performance allows us today to consider the code FLY among the most powerful parallel codes for tree N-body simulations. The FLY version 1. 1 is freely available on [URL] and it will be maintained and upgraded with new releases. Comment: 17 pages, 8 figures; Comp. Phys. Comm. in press, [URL] to download a free copy of FLY packag...|$|R
