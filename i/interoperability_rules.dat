9|13|Public
40|$|International audienceA {{company manager}} wanting to choose {{relevant}} partners {{in order to}} respond rapidly and efficiently to a business opportunity must be confident first on the partners' ability and adequacy, second on their organizational interoperability allowing then to collaborate profitably all along the affair. The aim {{of this paper is}} to present an approach allowing this manager to identify potential interoperability problems between partners. This approach is based on the specification of <b>interoperability</b> <b>rules</b> and on the analysis of these rules on enterprise models by using two complementary formal checking techniques...|$|E
40|$|A Spatial Data Infrastructure (SDI) is a {{computer}} system integrated {{by a group of}} resources (catalogues, servers, programs, data, applications, web pages …) for managing Geographic Information, i. e. maps, ortophotos, satellite images, geographical names. It’s available in Internet and complies with <b>interoperability</b> <b>rules,</b> allowing the user free access to information provided by different organisms and, also, the overlapping of this data. The Spatial Data Infrastructure of Spain (IDEE for Infraestructura de Datos Espaciales de España) is an initiative integrating data, metadata and geographical information produced in Spain by a wide set of data producers, which enables data discovering, viewing, and sometimes analyzing and downloading...|$|E
40|$|International audiencePartners {{involved}} into a collaborative process must satisfy interoperability requirements {{in order to}} fulfil adequately their mission all along the process. Indeed, interoperability is now considered as a key factor of success when sharing data, services, knowledge, skills, and resources. However, although the main desired effects (to respect a cost, to produce n products, to respect a quality ratio [...] .) of this process are generally reached, some others effects (unpredictable, undesirable [...] .) may be also induced and can lead in some cases, to a worsening of these desired effects that process has to perform. This paper presents and illustrates an Anticipative Effects-Driven Approach to check <b>interoperability</b> <b>rules</b> into a considered collaborative process...|$|E
50|$|COM (<b>Interoperability)</b> - <b>rules</b> that detect COM Interop issues.|$|R
40|$|As {{part of the}} Service Oriented Computing (SOC), Service Oriented Architecture (SOA) is a {{technology}} that has been developing {{for almost a decade}} and during this time there have been published many studies, papers and surveys that are referring to the advantages of projects using it. In this article we discuss some ways of using SOA in the business environment, {{as a result of the}} need to reengineer the internal business processes with the scope of moving forward towards providing and using standardized services and achieving enterprise <b>interoperability.</b> Business <b>Rules,</b> Business Processes, SOA, BPM, BRM, Semantic Web, Semantic Interoperability...|$|R
40|$|Promotor: Grzegorz J. Nalepa. Recenzent: Marcin Szpyrka, Ngoc Thanh Nguyen. Niepublikowana praca doktorska. Tyt. z ekranu tyt. Praca doktorska. AGH University of Science and Technology in Kraków. Faculty of Electrical Engineering, Automatics, Computer Science and Biomedical Engineering, 2015. Zawiera bibliogr. Dostępna również w wersji drukowanej. Tryb dostępu: Internet. State {{of the art}} in rule representation, {{knowledge}} representation with rules, selected {{knowledge representation}} methods, expert systems, production systems Shells, business rules approach, rules on semantic web, rules in software engineering, formalization of rules, propositional logic, First-Order Predicate Calculus, common logic, description logics, attributive logic, F-LOGIC, modal logics, knowledge engineering processes, problem identification, knowledge acquisition, knowledge modeling, inference process, knowledge verification and validation, knowledge <b>interoperability,</b> <b>rule</b> <b>interoperability</b> methods, knowledge interchange framework, rule interchange framework, production rule representation, rule markup language, REWERSE rule markup language, languages for production rules, important features of rule languages, Polish Liability Insurance Use Case Example, CLIPS, Jess, DROOLS, XTT 2, comparison of rule languages, CLIPS versus JESS, CLIPS versus DROOLS, JESS versus DROOLS, all versus XTT 2, existing approaches to translation of the selected rule languages, model of production rule representation, multilevel approach to <b>rule</b> <b>interoperability,</b> definition of the formalized model, data types and objects, facts, system state and trajectory, variables, taxonomy of formulae and operators, semantics of formulae and operators, rules, modules, knowledge base, model-based knowledge translation, identification of semantically equivalent features, translation of rule base structure, modules, rule level features, submodules, evaluation of the approach, evaluation procedure, definition and translation of the formal model of the PLI use case, definitions of types, initial state, definitions of rules, modules definitions, implementation of translation tool, identified challenges, syntax of rule languages, XML schema of the Model Concrete Synatx, CLIPS Syntax in BNF, data types, variables and expressions, Constructs, deffacts Construct, deftemplate Construct, fact specification, defrule Construct, defglobal Construct, deffunction Construct, defgeneric Construct, defmethod Construct, defclass Construct, defmessage-handler Construct, definstances Construct, defmodule Construct, Constraint Attributes, JESS Syntax, deffacts Construct, deffunction Construct, defglobal Construct, defmodule Construct, defquery Construct, defrule Construct, deftemplate Construct, Complete Models of the Selected Use Cases, Model of PLI Use Case, Formal Model of System, Model in CLIPS, Model in JESS, Model in DROOLS, Model in XTT 2, Model of UserV Use Case, Formal Model of Syste...|$|R
40|$|Kennedy has {{recently}} {{argued that the}} designers of C ♯ should try to informally verify that their compilation from C ♯ source to Microsoft Common Language Runtime (CLR) bytecode is “fully abstract ” {{in the sense that}} any two code fragments that C ♯ programs cannot distinguish must compile into CLR code fragments that CLR programs also cannot distinguish. In this paper we treat that property as a criterion for what constitutes a well-designed interoperability system and refine it using the techniques of Matthews-Findler-style multilanguage systems. We begin by giving our own variation on Kennedy’s criterion that does not directly involve a notion of compilation. Then we argue that our criterion is useful and workable by using it to guide our development of a multilanguage system that combines call-by-name and call-by-value lambda calculi. We begin with a straightforward system that we show does not meet our criterion. Then we refine that system’s <b>interoperability</b> <b>rules</b> and show that the result does meet our criterion. We conclude by sketching how our criterion would apply to multilanguage systems whos...|$|E
40|$|Native {{multicast}} {{routing protocols}} {{have been built}} and deployed using two basic types of trees: singlesource, shortest-path trees and shared, core-based trees. Core-based multicast trees use less routing state compared to shortest-path trees, but generally have higher end-to-end delay and poor fault tolerance. In this paper we consider {{a new type of}} shared multicast structure that uses multiple, independent, simultaneously-active cores. Our design provides for low end-to-end delay, improved fault tolerance, and low source discovery delay, while balancing bandwidth cost and routing state. These results indicate that shared trees with multiple active cores are a viable alternative to shortest-path trees. The Internet’s multicast routing structure is still evolving [1]. Since its inception in 1992, the Multicast Backbone [7] — the multicast-capable subset of the Internet — has primarily consisted of DVMRP [9, 26], PIM [10], and MOSPF [21] routers, tied together with a complex set of <b>interoperability</b> <b>rules</b> and utilizing a flat routing topology. In recent years, network operators have introduced native multicast support, policy, and a hierarchical structure. The current near-term solution consists of domains running PIM-SM [13] internally, connected by MSDP [15] for interdomain reachability. Eventually, MSDP will be replaced by BGMP [20], although some engineers advocate using the single-source architecture proposed by Express [8]...|$|E
40|$|In an {{increasingly}} diverse and splintered world, <b>interoperability</b> <b>rules.</b> The ability to leverage code written for another platform means {{more time and}} re-sources for doing new and exciting research instead of reinventing the wheel. Interoperability requires standards, and as the saying goes, {{the best part of}} standards is that everyone can have their own. How-ever, in the userspace file system world, the Linux-originated FUSE is the clear yardstick. In this paper we present ReFUSE, a userspace implementation of the FUSE interface on top of the NetBSD native puffs (Pass-to-Userspace Framework File System) userspace file systems framework. We argue that an additional layer of indirection is the right solution here, as it allows for a more natural export of the kernel file system interface instead of emulating a foreign interface in the kernel. Doing so also reaps other minor benefits such as clarifying the license as the whole chain from the kernel to the file system is BSD-licensed. Another obvious bene-fit is having a fully performant native userspace file system interface available. We summarize the puffs and FUSE interfaces and explain how the mapping between the two was done, including experiences from the implementation. After this we show by example that FUSE file systems work with ReFUSE as expected, present a virtual direc-tory extension for the FUSE interface and conclude by outlining future work in the area. 1...|$|E
40|$|International audienceThe {{interaction}} between business communities becomes a crucial requirement {{due to the}} need of exchanging and sharing resources and services. In general, each system defines its own security policy to manage access control to its resources. In this case, we may have security interoperability problems due to the variety and complexity of secured systems implementations. In this paper, we provide a formal approach for interoperability testing of security rules. First we propose a method to integrate <b>interoperability</b> security <b>rules</b> in a functional model represented by an extended finite automata. Then, test cases are generated from the obtained secured functional model by using an automatic test generation tool, Test Gen-IF. As an application, we provide {{a case study of}} security interoperability between two hospitals that share some resource...|$|R
50|$|In a 2017 {{lawsuit against}} a retailer, a Canadian court ruled {{in favour of}} Nintendo under anti-circumvention {{provisions}} in Canadian copyright law, which prohibit any breaching of technical protection measures. The court ruled {{that even though the}} retailer claimed the products could be used for homebrew, thus asserting exemptions for maintaining <b>interoperability,</b> the court <b>ruled</b> that because Nintendo offers development kits for its platforms, interoperability could be achieved without breaching TPMs, and thus the defence is invalid.|$|R
40|$|Abstract. This paper {{presents}} a JSON based rule language and its JavaScript-based rule engine towards providing Web 2. 0 applications with rule-based inference capabilities. For <b>interoperability</b> purposes the <b>Rule</b> Interchange Format is used. While the rule engine is enough general, its main {{purpose is to}} execute production rules and Event-Condition-Action rules related to the web page DOM processing. This way the user’s browsing experience will be enriched {{with the ability to}} modify on the fly the DOM of the current document as well as the browser user interface (Firefox). ...|$|R
40|$|DEVELOPMENT ASSOCIATIONThis {{standard}} {{makes no}} warranty, express or implied, {{with respect to}} the use of any intellectual property, such as patents, copyrights and trademarks, belonging to any corporation or individual. Nor does this standard make any warranty regarding system reliability or product liability. Windows ™ is a registered trademark of Microsoft Corporation in the United States and elsewhere. Revision History This "Digital Still Camera Image File Format Standard " is issued as a standard for the image file format (Exif: Exchangeable image file format) used in digital still cameras and related systems. It was first published in October 1996 as Version 1. 0 i. Then in May 1997, Version 1. 1 ii was issued, adding specifications for optional attribute information as well as stipulations relating to format implementation, in addition to the mandatory specifications of Version 1. 0. The desire for a uniform file format standard for the image data stored by digital still cameras has increased as these cameras have grown in popularity. At the same time, with the broadening application of this technology, a similar desire has arisen for uniformity of the attribute information that can be recorded in a file. The Version 2. 0 iii makes improvements to the Exif format for greater ease of use, while allowing for backward compatibility with products of manufacturers currently implementing Exif Version 1. x or considering its future implementation. The present Version 2. 1 contains Recommended Exif <b>Interoperability</b> <b>Rules.</b> The following additions and changes are made from Version 1. 1 to Version 2. 1...|$|E
40|$|JEIDA) This {{standard}} {{makes no}} warranty, express or implied, {{with respect to}} the use of any intellectual property, such as patents, copyrights and trademarks, belonging to any corporation or individual. Nor does this standard make any warranty regarding system reliability or product liability. Windows ™ is a registered trademark of Microsoft Corporation in the United States and elsewhere. FlashPix ™ is a registered trademark of Eastman Kodak Company. Revision History This "Digital Still Camera Image File Format Standard " is issued as a standard for the image file format (Exif: Exchangeable image file format) used in digital still cameras and related systems. It was first published in October 1996 as Version 1. 0 i. Then in May 1997, Version 1. 1 ii was issued, adding specifications for optional attribute information as well as stipulations relating to format implementation, in addition to the mandatory specifications of Version 1. 0. The desire for a uniform file format standard for the image data stored by digital still cameras has increased as these cameras have grown in popularity. At the same time, with the broadening application of this technology, a similar desire has arisen for uniformity of the attribute information that can be recorded in a file. The Version 2. 0 iii makes improvements to the Exif format for greater ease of use, while allowing for backward compatibility with products of manufacturers currently implementing Exif Version 1. x or considering its future implementation. The present Version 2. 1 contains Recommended Exif <b>Interoperability</b> <b>Rules.</b> The following additions and changes are made from Version 1. 1 to Version 2. 1...|$|E
40|$|A {{road from}} paper-based-administration of the 80 -ties to Smart Cities of today is being showed in this paper. Shift from paper do digital {{environment}} started with regaining of Polish independence in 1989, 26 years ago. The first e-mail from Poland was sent in 1990 year, 19 {{years after the}} first e-mail on the world of Ray Tomlinson (1971). Transfter of legal responsibilities, legal power, competences and finance from the top to local levels resulted in revolution in IT sector, which was the first commercial sector running in apost comunist country, in the 80 -ties and the beginning of 90 ties. Pressure for changes was visible exspecially in the biggest cities, and were initially connected with process of “mucicipalization” – i. e. – transfering of ownership of land from the state level to the level of municipalities. Signum Tempori of this time, was a process of transfer of state owned land to the city property of the City of Gdansk, where more than 30000 real estates of of the market value of 750 million US dollars were transferred and became municipal between 1992 and 1994 years. More and more LIS (Land Information Systems) and GIS (Geographic Information Systems) were implemented, without <b>interoperability</b> <b>rules</b> and standards. Lack of ability to adapt centrain common standards between State Surveying and the biggest cities resulted in appearance of more than 20 graphical applications and more then 20 textual databases applications which required later substantial efforts and costs to overcome information chaos. 10 biggest metropolitan Polish Cities spend more then 3 times than the General Office of Geodesy and Cadasrte of Poland, between 1991 and 1994. Gradual implementaion of INSPIRE Directive and the Law of National Infrastrructure of Spatial Information created unprecedented shitf from paper maps and paper records to almost all digital Poland. Expenditures of c. a. 650 million PLN were assigned to creation of digital representaion of all 34 data layers of INSPIRE Directive for the impelmentaion period of 2010 to 2019. Nevertheless, this amount has been almost doubled in the first 3 years, taking into acccount expenditures of only regional and local GIS/SDI Projects. Polish spatial and economic conditions created spatio-economic background, within which more than 65...|$|E
40|$|International audienceTesting {{is one of}} {{the most}} widely used {{techniques}} to increase the quality and reliability of complex software systems. In this paper we present the notion of testing <b>interoperability</b> security <b>rules</b> in virtual organizations. In particular, we incorporate mechanisms to test those interactions among the organizations of the business communities when the resources are shared. In order to apply our technique to increase the confidence on the correctness of these systems, we need to obtain a set of tests compiling the relevant properties of the interoperability security policies. We present a model based testing approach for checking the correctness of these policies in this environment. In addition to provide the theoretical framework, we show how this formalism, based on extended finite automata, has been used to test a hospital scenario. This exercise convinced us that a formal approach to test systems can facilitate some of the development phases. In particular, how to choose which tests to apply, is simplified since tests are automatically extracted from the specification...|$|R
40|$|Part 6 : Interoperability for Specific Application TypesInternational audienceInteroperability research, to date, {{primarily}} {{focuses on}} data, processes {{and technology and}} not explicitly on business rules. The core problem of interoperability from an organisation’s perspective is the added value generated from collaborating with other parties. The added value from a data, process and technology perspective has been widely researched. Therefore it is {{the aim of this}} study to provide insights into the added value for organisations to collaborate when executing business rules management solutions. Explanations of possibilities, opportunities and challenges can help to increase the understanding of business <b>rules</b> <b>interoperability</b> value creation. Presented results provide a grounded basis from which empirical and practical investigation can be further explored...|$|R
40|$|This paper aims at {{presenting}} {{the foundation of}} an Anticipative Effects Driven Approach to validate a collaborative process taking into account <b>interoperability</b> constraints and <b>rules.</b> The objective {{of this approach is}} to allow managers in charge of this collaborative process to detect and characterize the possible effects {{due to a lack of}} organizational interoperability between partners involved into the collaborative process. This approach is based on several concepts, model and reasoning mechanisms presented and illustrated in this paper. It is applied here to a case of a crisis management process involving several partners. This research is issued from a previous approach coming from a French research project dealing with the interoperability of systems in crisis situation: ISYCRI (Interoperability of SYstems in situation of CRIsis, ANR- 06 -CSOSG) ...|$|R
40|$|The rule of origin, {{globally}} {{applied to}} determine the eligibility for trade preference, is a vital instrument for an international trade, as it defines the country origin of products. The unified rule of origin ontology and knowledge representations is a vital key to promote <b>interoperability</b> and effective <b>rule</b> of origin verification services that could bring about trust amongst stakeholders and trading partners. This paper aims to lay down a rule of origin knowledge representations model using the composite act frame technique extended from the frame-based ontology of law proposed by van Kralingen and Visser. To prove the generic and extendibility aspect of the model, an assessment test with different criteria {{for the rule of}} origin is conducted. The implementation of the rule of origin knowledge representations to support the web-based e-government services is accomplished through the system called “Rule of Origin VERification Systems: ROVERs”. The rule of origin knowledg...|$|R
40|$|With deeper {{levels of}} {{external}} process integration {{and a growing}} number of electronic business relationships, enterprises strive for becoming more interoperable with their business partners. Although B 2 B standards are supposed to ensure scalable B 2 B integration and m:n connectivity, enterprises face the challenge of ambiguous interpretations of standards when it comes to their implementation. This paper develops a conceptual model for service-based B 2 B interoperability which leverages web service technologies for implementing industry standards. The authors instantiate the conceptual model in a concrete B 2 B scenario in the automotive industry where a consortium of automotive manufacturers and suppliers are currently redesigning their inter-organizational Engineering change Management (ECM) processes. From the evaluation, they conclude that it is not sufficient to specify that standards are used related to pragmatics, semantics and syntax. In order to ensure <b>interoperability,</b> additional design <b>rules</b> are needed which define how industry standards are mapped to a web service design...|$|R
40|$|International audienceIn {{a climate}} change context, the {{availability}} of real time and forecast piezometric data is essential information for decision makers. Indeed, associated with threshold values (groundwater levels corresponding to different alert discharges values) those data can indicate if a crisis situation is expected, either drought or flooding episodes. To meet societal expectations, BRGM (French geological survey) currently works on improving its national piezometric data network. Raw data from sensors are exposed in interoperable formats and services in accordance with international open standards for sensorWeb <b>interoperability</b> and European <b>rules</b> (INSPIRE directive guidance {{on the use of}} Observations & Measurements and OGC SWE-Sensor Web Enablement Framework). The objective of the " MétéEau des Nappes " project is to deploy an interoperable communication tool unable to cross data from different networks (meteorology, river flow, piezometric) in order to characterize in almost real-time groundwater quantitative state. A prototype of this tool was deployed on a few selected French regions with different hydrogeological characteristics and various issues (drought or flooding). Preliminary steps were to define case studies (watersheds) to select the representative piezometers and the corresponding measured stations and, eventually to calibrate models that provide piezometric level forecasts. At the present stage, the tool shows maps giving the location of measured stations and charts drawing the real time evolution of data compared to thresholds and model predictions. It also provides the model predictions as a Sensor Observation Service in addition to the raw data flows. BRGM also contributes to the achievement of the national hydrological situation report (monthly evolution of water resource) on behalf of the French ministry of Environment. Then the final step of the project is to integrate into the tool a map showing specified indicators of the groundwater state and trends. Perspectives of the project are the implementation of data assimilation and automatic forecasting processes into the models. Among the French stakeholders interested in the tool, we can indicate: Water agencies, decentralized services of ministries, Regions and Departments, Association of Municipalities, Industrial water producers...|$|R
40|$|If heath {{policy makers}} 2 ̆ 7 wishes come true, {{by the end}} of the current decade the paper charts in which most of our medical {{information}} is currently recorded will be replaced by networked electronic health records (2 ̆ 2 EHRs 2 ̆ 2). [ [...] . ] Like all computerized records, networked EHRs are difficult to secure, and the information in EHRs is both particularly sensitive and particularly valuable for commercial purposes. Sadly, the existing federal statute meant to address this problem, the Health Insurance Portability and Accountability Act of 1996 (2 ̆ 2 HIPAA 2 ̆ 2), is probably inadequate to the task. [ [...] . ] Health law, privacy, and intellectual property scholars have all suggested that the river of information created by integrated, networked EHRs and other data systems must somehow be controlled, and many of these scholars have considered whether 2 ̆ 2 property 2 ̆ 2 might provide such control. [ [...] . ] The Article 2 ̆ 7 s principal thesis is that arguments over the control of rights in personal information test contemporary understandings of what property is and reveal fault lines in modern property theory. If property rights exist at all in 2 ̆ 2 dephysicalized, 2 ̆ 2 digitized information, those rights are unlikely to be consolidated in a single person, to operate in rem, to grant owners significant powers to exclude, or to be standardized [...] qualities that, in the eyes of some, are required of true 2 ̆ 2 property 2 ̆ 2 interests. Claims of ownership to personal information also raise questions about whether property is the right rhetorical frame in which to consider the problem of information that is deeply connected to people 2 ̆ 7 s selves. Finally, propertization claims assume a closer connection between property and control than is either realistic or desirable in an interconnected world. It is likely that, at the end of the day, individuals will as a matter of policy be granted some rights to control some of their personal information, but those rights will not follow from anything in property 2 ̆ 7 s 2 ̆ 2 nature. 2 ̆ 2 Part I introduces the control issues raised by EHRs specifically and by the collection of personal information more generally, and then examines the arguments for using property as a device to control information. [ [...] . ] Part II explores the connection between the loss of control over information and concerns about the 2 ̆ 2 self. 2 ̆ 2 It questions whether property is the best frame in which to talk about medical and other personal information, i. e., whether, rhetorically, we should treat information about the self as a commodity. It questions also whether we can avoid a property frame. [ [...] . ] Part III returns to the specific policy problems presented by EHRs and by personal information. A workable EHR policy will take account of a wide variety of values, issues, and interests. Incentives must be created to facilitate EHR adoption, standards must be set to insure <b>interoperability,</b> malpractice <b>rules</b> must be adjusted to accommodate new practices (not to mention new mistakes), and procedures must be developed to enable use of EHR data for public health purposes. [ [...] . ] A workable policy for EHRs and for personal information will no doubt provide individuals some control rights. These rights might look, in the eyes of some, like property rights. But if control rights are granted, it will not be because 2 ̆ 2 property 2 ̆ 2 demands them, but because other considerations of health and public policy do. All this raises the question of when and whether property might ever provide the control that advocates of information-as-property desire. In a world of de-physicalization and digitization, ownership may not provide the kind of power that old-fashioned property rhetoric invokes. This state of affairs is not necessarily one to be lamented. The question of how power and control over information will be apportioned involves hard choices. But because property theory is itself deeply divided over the extent to which property provides control, 2 ̆ 2 property 2 ̆ 2 itself cannot determine how these choices should be made. 2 ̆ 2 Property 2 ̆ 2 may never have actually given owners as much control as the new adherents of property in information envision. Even if it did, in a world of increasing interconnection, it may be good to be reminded that power and control are themselves always shared...|$|R

