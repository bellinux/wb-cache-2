111|341|Public
2500|$|According to Carnap, {{many words}} of metaphysics do not fulfill these {{requirements}} and thus they are meaningless. As an example, Carnap considers the word 'principle'. This word has a definite meaning, if the sentence [...] "x {{is the principle}} of y" [...] {{is supposed to be}} equivalent to the sentence [...] "y exists by virtue of x" [...] or [...] "y arises out of x". The latter sentence is perfectly clear: y arises out of x when x is invariably followed by y, and the invariable association between x and y is empirically verifiable. But—says Carnap—metaphysicians are not satisfied with this interpretation of the meaning of 'principle'. They assert that no empirical relation between x and y can completely explain the meaning of [...] "x is the principle of y", because there is something that cannot be grasped by means of the experience, something for which no <b>empirical</b> <b>criterion</b> can be specified. It is the lacking of any empirical criterion—says Carnap—that deprives of meaning the word 'principle' when it occurs in metaphysics. Therefore, metaphysical pseudo-statements such as [...] "water is the principle of the world" [...] or [...] "the spirit is the principle of the world" [...] are void of meaning because a meaningless word occurs in them.|$|E
5000|$|The [...] "Ramsey test" [...] for {{evaluating}} probability distributions is implementable in theory, and has kept experimental psychologists occupied {{for a half}} century.This work demonstrates that Bayesian-probability propositions can be falsified, and so meet an <b>empirical</b> <b>criterion</b> of Charles S. Peirce, whose work inspired Ramsey. (This falsifiability-criterion was popularized by Karl Popper.) ...|$|E
50|$|An <b>empirical</b> <b>criterion</b> for tornado {{formation}} {{has been}} developed by Dan Sowa from Northwest Orient Airlines as follows: the cumulonimbus overshooting top must enter into the stratosphere by at least 10000 feet. This criterion is, however, incorrect and the Sonnac tornado is a counter-example. It reached level EF2 while being generated by a small cumulonimbus that did not attain 9000 m.|$|E
40|$|Abstract- In {{recent decades}} several <b>empirical</b> <b>criteria</b> have been presented, {{in order to}} {{simulate}} the triaxial behavior of rock samples. These factors have mostly been associated with some limitations, because of the natural complexity in rock sample’s behavior in deformation and physical form. Some of these parameters are appropriate for {{a specific type of}} rock or special condition in laboratory. By comparison with other parameters, although Bieniawski, Ramamurthy and Hoek criteria show minimal limitations, but according to this paper, they are not accurate enough in correlation with the results of the tests. In this paper a new <b>empirical</b> <b>criteria</b> is introduced and compared to the three mentioned criteria and as a result, the advantages of this newly introduced parameter in correlation with the test results are interpreted...|$|R
50|$|A 2010 study {{identified}} 62 regularly published heterodox {{journals and}} used various <b>empirical</b> <b>criteria</b> to compare {{several aspects of}} their research quality. The Quarterly Journals Bibliographic Ranking was ranked 33rd out of the 62 heterodox economics journals surveyed; its reputation among peers (both mainstream and heterodox) was ranked 57th.|$|R
40|$|In the past, the {{performance}} of a condenser has been judged by <b>empirical</b> <b>criteria</b> such as cleanliness factor, terminal temperature difference and/or cooling water pressure drop. However, these criteria vary with load, cooling water inlet temperature and cooling water flow rate. Thus, to base maintenance or operating decisions on deviations in the <b>empirical</b> <b>criteria</b> requires that these other factors be taken into account. One way to avoid this is to develop a benchmark or reference condenser duty. A source for this reference {{can be found in the}} analysis of turbine thermal kit data to create a design model of the turbine LP stage. Provided that the turbogenerator is operating with the equipment configuration on which the thermal kit data was based; and that the boiler operating conditions are close to design for a given load; then the exhaust enthalpy an...|$|R
50|$|Although {{bacteria}} are traditionally {{divided into two}} main groups, gram-positive and gram-negative, based on their Gram stain retention property, this classification system is ambiguous as it refers to three distinct aspects (staining result, envelope organization, taxonomic group), which do not necessarily coalesce for some bacterial species. The gram-positive and gram-negative staining response is also not a reliable characteristic as these two kinds of bacteria do not form phylogenetic coherent groups. However, although Gram staining response is an <b>empirical</b> <b>criterion,</b> its basis lies in the marked differences in the ultrastructure and chemical composition of the bacterial cell wall, marked by the absence or presence of an outer lipid membrane.|$|E
50|$|Although the {{bacteria}} are conventionally {{divided into two}} main groups — gram-positive and gram-negative, based upon their Gram-stain retention property — this classification system is ambiguous as it can refer to three distinct aspects (staining result, cell-envelope organization, taxonomic group), which do not necessarily coalesce for some bacterial species. However, although Gram-staining response of bacteria is an <b>empirical</b> <b>criterion,</b> its basis lies in the marked differences in the ultrastructure and chemical composition of the two main kinds of bacteria. These bacteria are distinguished from each other based on {{the presence or absence}} of an outer lipid membrane, which is a more reliable and fundamental characteristic of {{the bacteria}}l cells.|$|E
5000|$|The {{original}} MMPI {{was developed}} on a scale-by-scale {{basis in the}} late 1930s and early 1940s. Hathaway and McKinley used an <b>empirical</b> <b>criterion</b> keying approach, with clinical scales derived by selecting items that were endorsed by patients {{known to have been}} diagnosed with certain pathologies. The difference between this approach and other test development strategies used around that time was that it was atheoretical (not based on any particular theory) and thus the initial test was not aligned with the prevailing psychodynamic theories. The atheoretical approach to MMPI development ostensibly enabled the test to capture aspects of human psychopathology that were recognizable and meaningful, despite changes in clinical theories.However, the MMPI had flaws of validity that were soon apparent and could not be overlooked indefinitely. The control group for its original testing consisted of {{a very small number of}} individuals, mostly young, white, and married people from rural Midwestern geographic areas. The MMPI also faced problems with its terminology not being relevant to the population it was supposed to measure, and it became necessary for the MMPI to measure a more diverse number of potential mental health problems, such as [...] "suicidal tendencies, drug abuse, and treatment-related behaviors." ...|$|E
40|$|From {{geotechnical}} {{and engineering}} geology {{points of view}} collapsible soils are classified as problematic soils. The existence of collapsible soils {{has been reported in}} all of the world continents. In Iran they are located in central and eastern desert. One of the most important problems concerning collapsible soils is instability and considerable settlement due to minor changes in the water content which can cause remarkable damages to overlying structures. Therefore, evaluation of collapsibility potential through defining many <b>empirical</b> <b>criteria</b> is especially important. In this study some of <b>empirical</b> <b>criteria</b> were classified and implemented to evaluate Semnan central desert collapsibility. As a case study, Semnan Railway station was considered because of considerable risk of failure due to collapsibility phenomena. After site investigation and performing many laboratory, tests the soil collapsibility potential was confirmed through comparison of selected criteria...|$|R
40|$|Nonparametric density estimation, kernel estimator, <b>empirical</b> error <b>criterion,</b> {{stochastic}} {{measures of}} For {{the purpose of}} comparing different nonparametric density estimators, Wegman (1972) introduced an <b>empirical</b> error <b>criterion.</b> In a recent paper by Hall (1982) it is shown that this <b>empirical</b> error <b>criterion</b> converges to the mean integrated square error. Here, {{in the case of}} kernel estimation, the results of Hall are improved in several ways, most notably multivariate densities are treated and the range of allowable bandwidths is extended. The techniques used here are quite different from those of Hall, which demonstrates that the elegant Brownian Bridge approximation of Komlos, Major an...|$|R
40|$|A vast {{literature}} (Cattell, Horn, Velicer) {{has been}} devoted to the assessment of the proper number of eigenvalues that have to be retained in Principal Components Analysis. Most of the publications are based on either (non-realistic) distributional assumptions for the underlying populations or on <b>empirical</b> <b>criteria.</b> Techniques that are based on bootstrap or cross-validation hav...|$|R
5000|$|According to Carnap, {{many words}} of metaphysics do not fulfill these {{requirements}} and thus they are meaningless. As an example, Carnap considers the word 'principle'. This word has a definite meaning, if the sentence [...] "x {{is the principle}} of y" [...] {{is supposed to be}} equivalent to the sentence [...] "y exists by virtue of x" [...] or [...] "y arises out of x". The latter sentence is perfectly clear: y arises out of x when x is invariably followed by y, and the invariable association between x and y is empirically verifiable. But—says Carnap—metaphysicians are not satisfied with this interpretation of the meaning of 'principle'. They assert that no empirical relation between x and y can completely explain the meaning of [...] "x is the principle of y", because there is something that cannot be grasped by means of the experience, something for which no <b>empirical</b> <b>criterion</b> can be specified. It is the lacking of any empirical criterion—says Carnap—that deprives of meaning the word 'principle' when it occurs in metaphysics. Therefore, metaphysical pseudo-statements such as [...] "water is the principle of the world" [...] or [...] "the spirit is the principle of the world" [...] are void of meaning because a meaningless word occurs in them.|$|E
3000|$|As known, {{according}} to Merzhanov's <b>empirical</b> <b>criterion,</b> for {{the reaction to}} be self-sustaining {{in the absence of}} preheat, the adiabatic temperature (T [...]...|$|E
40|$|An <b>empirical</b> <b>criterion</b> for {{assessing}} the significance of individual terms of regression models of wind tunnel strain gage balance outputs is evaluated. The criterion {{is based on the}} percent contribution of a regression model term. It considers a term to be significant if its percent contribution exceeds the empirical threshold of 0. 05 %. The criterion has the advantage that it can easily be computed using the regression coefficients of the gage outputs and the load capacities of the balance. First, a definition of the <b>empirical</b> <b>criterion</b> is provided. Then, it is compared with an alternate statistical criterion that is widely used in regression analysis. Finally, calibration data sets from a variety of balances are used to illustrate the connection between the empirical and the statistical criterion. A review of these results indicated that the <b>empirical</b> <b>criterion</b> seems to be suitable for a crude assessment of the significance of a regression model term as the boundary between a significant and an insignificant term cannot be defined very well. Therefore, regression model term reduction should only be performed by using the more universally applicable statistical criterion...|$|E
40|$|The lack of pharmacopoeial methodologies for {{the quality}} control of plants used for {{therapeutic}} purposes is a huge problem that impacts directly upon public health. In the case of saponins, their great structural complexity, weak glycoside bonds and high polarity hinder their identification by conventional techniques. To apply high-performance liquid chromatography-electrospray tandem mass spectrometry (HPLC-ESI/MS(n)) to identify the O-glycoside sequence of saponins from the roots of Phytolacca bogotensis. Saponins were isolated by preparative HPLC and characterised by NMR spectroscopic experiments. Collision-induced dissociation (CID) of isolated saponins was performed producing typical degradation reactions that {{can be associated with}} several glycosidic bonds as <b>empirical</b> <b>criteria.</b> A method using solid-phase extraction (SPE) and HPLC/ESI-MS(n) for the characterisation of saponins and identification of novel molecules is described. Three saponins reported {{for the first time in}} P. bogotensis were isolated and characterised by NMR spectroscopy. Characteristic cross ring cleavage reactions have been used as <b>empirical</b> <b>criteria</b> for the characterisation of the glycosidic bonds most frequently reported for Phytolacca saponins. One new saponin was proposed on the basis of <b>empirical</b> <b>criteria,</b> and other five saponins were identified for the first time for P. bogotensis using HPLC-ESI/MS(n). Electrospray ionisation in combination with tandem mass spectrometry has been established as a powerful tool for the profiling of saponins from roots of P. bogotensis. CID proved to be a useful tool for the characterisation and identification of known and novel saponins from the plant family Phytolaccaceae and can be used for quality control purposes of crude plant extracts...|$|R
5000|$|... the Hankinson <b>criterion,</b> an <b>empirical</b> failure <b>criterion</b> that is {{used for}} {{orthotropic}} materials such as wood.|$|R
40|$|Usability-evaluation of user {{interfaces}} {{can be done}} by <b>empirical,</b> <b>criteria</b> oriented and model based methods (e. g., interview study, checklist, and cognitive model). Model based methods enable more detailed predictions of quantitative parameters, for example error rates, times and sequences of actions compared to <b>empirical</b> and <b>criteria</b> based methods – even without an existing prototype. This allows applying model based methods in early phases of system-development processes, to detect usability-problems and to change the examined user interface. Integrating these aspects, cognitive models additionally take into account the cognitive abilities and characteristics of humans (Newell, 1990). Complex paradigms (e. g., dual-tasking, decisionmaking, and time-estimation) that are important in present user scenarios are hardly to observe with classical usabilitymethod...|$|R
40|$|An {{approximate}} <b>empirical</b> <b>criterion,</b> {{based on}} the projected side area and the mass distribution of the airplane, was formulated. The British results were analyzed and applied to American designs. A simpler design criterion, {{based solely on the}} type and the dimensions of the tail, was developed; it is useful in a rapid estimation of whether a new design is likely to comply with the minimum requirements for safety in spinning...|$|E
40|$|We {{provide new}} methods for {{estimation}} of the one-point specification probabilities in general discrete random fields. Our procedures are based on model selection by minimization of a penalized <b>empirical</b> <b>criterion.</b> The selected estimators satisfy sharp oracle inequalities without any assumption on the random field for both L 2 -risk and Küllback loss. We also prove the validity of slope heuristic for the specification probabilities estimation problem. We finally show in simulation studies the practical performances of our methods. ...|$|E
40|$|This paper {{deals with}} the question: What are the {{criteria}} that an adequate theory of computation has to meet? (1) Smith 2 ̆ 7 s answer: it has to meet the <b>empirical</b> <b>criterion</b> (i. e. doing justice to computational practice), the conceptual criterion (i. e. explaining all the underlying concepts) and the cognitive criterion (i. e. providing solid grounds for computationalism). (2) Piccinini 2 ̆ 7 s answer: it has to meet the objectivity criterion (i. e. identifying computation {{as a matter of}} fact), the explanation criterion (i. e. explaining the computer 2 ̆ 7 s behaviour), the right things compute criterion, the miscomputation criterion (i. e. accounting for malfunctions), the taxonomy criterion (i. e. distinguishing between different classes of computers) and the <b>empirical</b> <b>criterion.</b> (3) Von Neumann 2 ̆ 7 s answer: it has to meet the precision and reliability of computers criterion, the single error criterion (i. e. addressing the impacts of errors) and the distinction between analogue and digital computers criterion. (4) 2 ̆ 2 Everything 2 ̆ 2 computes answer: it has to meet the implementation theory criterion by properly explaining the notion of implementation...|$|E
40|$|In {{exploratory}} factor analysis (EFA), most popular methods for dimensionality assessment such as the screeplot, the Kaiser criterion, or—the current gold standard—parallel analysis, are based on eigenvalues of the correlation matrix. To further understanding and development of factor retention methods, results on population and sample eigenvalue distributions are introduced based on random matrix theory and Monte Carlo simulations. These results are used {{to develop a new}} factor retention method, the <b>Empirical</b> Kaiser <b>Criterion.</b> The performance of the <b>Empirical</b> Kaiser <b>Criterion</b> and parallel analysis is examined in typical research settings, with multiple scales that are desired to be relatively short, but still reliable. Theoretical and simulation results illustrate that the new <b>Empirical</b> Kaiser <b>Criterion</b> performs as well as parallel analysis in typical research settings with uncorrelated scales, but much better when scales are both correlated and short. We conclude that the <b>Empirical</b> Kaiser <b>Criterion</b> is a powerful and promising factor retention method, because it is based on distribution theory of eigenvalues, shows good performance, is easily visualized and computed, and is useful for power analysis and sample size planning for EF...|$|R
40|$|For {{the purpose}} of {{comparing}} different nonparametric density estimators, Wegman (J. Statist. Comput. Simulation 1 225 - 245) introduced an <b>empirical</b> error <b>criterion.</b> In a recent paper by Hall (Stochastic Process. Appl. 13 11 - 25) it is shown that this <b>empirical</b> error <b>criterion</b> converges to the mean integrated square error. Here, {{in the case of}} kernel estimation, the results of Hall are improved in several ways, most notably multivariate densities are treated and the range of allowable bandwidths is extended. The techniques used here are quite different from those of Hall, which demonstrates that the elegant Brownian Bridge approximation of Komlós, Major, and Tusnády (Z. Warsch. Verw. Gebrete 32 111 - 131) does not always give the strongest results possible. Nonparametric density estimation kernel estimator <b>empirical</b> error <b>criterion</b> stochastic measures of accuracy...|$|R
30|$|This way of {{handling}} the models aims to reduce the distinction between a confirmatory approach (only one model tested) and exploratory approach. Comparing several models and/or the existence of equivalent models improves the fit of the structural model to empirical data or to the theory that underlies it. Indexes exist to identify variables that are worth the effort of re-specification. Indeed, {{it is possible to}} add or withdraw paths based on <b>empirical</b> <b>criteria</b> (de Marco et al. 2009).|$|R
40|$|Abstract: Based on the {{research}} of rock burst in underground engineering at home and abroad, definition, type, intensity grading, influencing factors, the failure mechanism, the <b>empirical</b> <b>criterion</b> and on-site forecasting and control methods of rock burst are summarized systematically. The current main problems in rock burst research are pointed out {{and the idea of}} rock burst comprehensive prediction are put forward. We recommend that the rock burst prediction should be divided into three steps, i. e. tendentiousness prediction, trend prediction and field prediction and forecasting...|$|E
40|$|This is Turing's {{classical}} {{paper with}} every passage quote/commented to highlight what Turing said, might have meant, {{or should have}} meant. The paper was equivocal about whether the full robotic test was intended, or only the email/penpal test, whether all candidates are eligible, or only computers, and whether the criterion for passing is really total, liefelong equavalence and indistinguishability or merely fooling enough people enough of the time. Once these uncertainties are resolved, Turing's Test remains cognitive science's rightful (and sole) <b>empirical</b> <b>criterion</b> today...|$|E
40|$|The {{behaviour}} {{of novel}} metal matrix composites {{and their respective}} matrix alloys is studied in the present work from the fracture mechanics point of view. A series of experiments were executed in single edge notched specimens with various initial crack inclinations and the crack opening displacement was recorded versus externally applied load. An <b>empirical</b> <b>criterion</b> was established permitting easy, in-situ inspection of the safety and further loading capacity of cracked structural members, already in function. © 1996 Kluwer Academic Publishers. Printed in the Netherlands...|$|E
40|$|Abstract. Learning {{models are}} widely {{implemented}} for prediction of system behaviour and forecasting future trends. A comparison of different learning models used in Data Mining and a practical guideline how {{to select the}} most suited algorithm for a specific medical application is presented and some <b>empirical</b> <b>criteria</b> for describing and evaluating learning methods are given. Three case studies for medical data sets are presented and potential benefits of the proposed methodology for diagnosis learning are suggested...|$|R
40|$|This letter {{addresses}} the security {{issues of the}} multimedia encryption schemes using multiple Huffman table (MHT). A known-plaintext attack is presented {{to show that the}} MHTs used for encryption should be carefully selected to avoid the weak keys problem. We then propose chosen-plaintext attacks on the basic MHT algorithm as well as the enhanced scheme with random bit insertion. In addition, we suggest two <b>empirical</b> <b>criteria</b> for Huffman table selection, based on which we can simplify the stream cipher integrated scheme, while ensuring a high level of security...|$|R
40|$|The <b>empirical</b> rock failure <b>criteria</b> play an {{important}} role in predicting the mechanical behavior of rocks, since affecting parameters on the behavioral properties of rocks are complex and numerous. Usually the <b>empirical</b> failure <b>criteria</b> are obtained by statistical methods, namely by means of fitting the mathematical function onto the experimental data. For evaluation and verification of the results, however, the quality and accuracy of the fit must be considered. This paper studies the efficiency and accuracy of conventional <b>empirical</b> rock failure <b>criteria</b> using a new approach, which is based on the analysis of uncertainty amplitude on the constant parameters of each criterion. The approach adopted here, is based on the combination of some parameters such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), type of function, degree of freedom and the confidence level of constants. Correlation coefficient (R 2) is then a comprehensive test and can be used effectively for comparison and accuracy of <b>empirical</b> rock failure <b>criteria...</b>|$|R
40|$|We have {{compiled}} {{and studied}} photometric and spectroscopic data {{published in the}} literature of several star forming regions and young open clusters (Orion, Taurus, IC 348, Sco-Cen Complex, Chamaeleon I, TW Hya association, sigma Orionis cluster, IC 2391, alpha Per cluster and the Pleiades). Our goal was to seek the definition of a simple <b>empirical</b> <b>criterion</b> to classify stars or brown dwarfs which are accreting matter from a disk on the sole basis of low-resolution optical spectroscopic data. We show that using Halpha equivalent widths and spectral types we can statistically classify very young stars and brown dwarfs as classical T Tauri stars and substellar analogs. As a boundary between accreting and non accreting objects, we use the saturation limit of chromospheric activity at Log L(Halpha) /L(bol) =- 3. 3 (determined in the open clusters). We discuss the uncertainties in the classification scheme due to the occurrence of flares. We have used this spectroscopic <b>empirical</b> <b>criterion</b> to classify objects found in the literature, and we compute the fraction of accreting objects in several star forming regions. The fraction of accreting objects appears to decrease from about 50 % to about 5 % from 1 Myr to 10 Myr for both stars and brown dwarfs. Comment: Astronomical Journal, accepte...|$|E
40|$|We {{present a}} sample of 8498 quasars with both SDSS ugriz optical and UKIDSS YJHK near-IR {{photometric}} data. With this sample, we obtain the median colour-z relations based on 7400 quasars with magnitude uncertainties less than 0. 1 mag in all bands. By analyzing the quasar colours, we propose an <b>empirical</b> <b>criterion</b> in the Y-K vs. g-z colour-colour diagram to separate stars and quasars with redshift z< 4, and two other criteria for selecting high-z quasars. Using the SDSS-UKIDSS colour-z relations, we estimate the photometric redshifts of 8498 SDSS-UKIDSS quasars, and find that 85. 0...|$|E
40|$|This study {{presents}} a new <b>empirical</b> <b>criterion</b> {{for assessing the}} potential of internal erosion and suffusion of granular soils. This method considers the bimodal structure of a soil having a primary coarse fabric and loose finer particles based on the porosities influenced by the particle size distribution {{and the degree of}} compaction. By comparing the representative particle size of a loose finer fraction with the controlling constriction size of a primary coarse fabric, a distinct boundary between internally stable and unstable soils with respect to internal erosion may be found...|$|E
40|$|Decisional {{processes}} {{underlying the}} determination of a suicide in the largest injury surveillance system currently available in South Africa are assessed through face-to-face semi-structured interviews with 32 medical practitioners involved in the system. Focus is placed on their current work circumstances and practices, and views of operational and <b>empirical</b> <b>criteria</b> proposed by US experts. Common themes and discrepancies in opinions emerged regarding {{the quality of the}} data currently available for suicide determinations, and regarding the importance and difficulty in assessing the US-developed criteria in South Africa. A truly standard approach is unlikely without considerable changes to the medico-legal system...|$|R
40|$|The Moral Judgment Test (MJT) {{has been}} {{developed}} 30 years ago to assess simultaneously moral attitudes and moral judgment competence in a cross-cultural study. Rigorous validation procedures were implemented {{to make sure that}} the MJT has the same (semantic and pragmatic) meaning for the participants in these countries and that, therefore, we can draw safe conclusions from compari-sons of the data. The validity of the MJT was tested not only by checking its semantic equivalence by careful translations but also analyzing its semiotic equivalence using three <b>empirical</b> <b>criteria</b> derived from theory and research: a) Preference Hierarchy (Jim Rest), b) Affective-cognitive Paral...|$|R
30|$|In the past, many {{fracture}} criteria {{have been}} developed to predict the fracture limit. Lee and Kuhn (1973) developed a mathematical model based on total strain at failure to evaluate the effect of material characteristics and process parameters on the initiation of ductile fracture. Zhang et al. (2000 a) and Down and Kuhn (1975) investigated the fracture loci (tensile strain/compressive strain) for porous materials under various processing conditions. In addition, several authors (Vujovic and Shabaik 1986; Clift et al. 1990; Ko et al. 1996) developed models for predicting ductile fracture initiation during bulk metal forming. These criteria can be categorized as <b>empirical</b> and semi-empirical <b>criteria.</b> The <b>empirical</b> <b>criteria</b> are either strain based at fracture locus or stress based defined in terms of stress formability index (Xue-min et al. 2009). Criteria based on cumulative plastic energy and void coalescence can be considered as semi-empirical criteria.|$|R
