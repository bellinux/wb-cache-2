3|15|Public
40|$|Abstract [...] In this paper, a new spiking {{neural network}} {{architecture}} based Ellias <b>Grossberg</b> <b>model</b> is proposed and different connection schemes that investigate the synchronization performance is provided. The synchronization {{time and the}} network neurons correlation are used {{as a measure of}} the network performance. An example of a pattern recognition problem is used to illustrate the proposed connection schemes. Results on the English character recognition are presented. Any of the proposed connection schemes may be used to design artificial neural networks for scene segmentation, figure ground segregation and object recognition. 1...|$|E
40|$|In {{this paper}} we develop the gamma neural model, a new neural net {{architecture}} for processing of temporal patterns. Time varying patterns are normally segmented into {{a sequence of}} static patterns that are successively presented to a neural net. In the approach presented here segmentation is avoided. Only current signal values are presented to the neural net, that adapts its own internal memory to store the past. Thus, in the gamma neural net, an adaptive short term mechanism obviates a priori signal segmentation. We evaluate {{the relation between the}} gamma net and competing dynamic neural models. Interestingly, the gamma model brings many popular dynamic net architectures, such as the time-delay-neural-net and the concentration-intime -neural-net, into a unifying framework. In fact, the gamma memory structure appears as general as a temporal convolution memory structure with arbitrary time varying weight kernel w(t). Yet, the gamma model remains mathematically equivalent to the additive (<b>Grossberg)</b> <b>model</b> with constant weights. We present a backpropagation procedure to adapt the weights in a particular feedforward structure, the focused gamma net. ...|$|E
40|$|The {{dynamics}} of complex neural networks modelling the self [...] organization process in cortical maps must include {{the aspects of}} long and short [...] term memory. The behaviour of the network is such characterized by an equation of neural activity as a fast phenomenon and an equation of synaptic modification as a slow part of the neural system. We present new methods of analyzing the {{dynamics of}} a competitive neural system with different time scales: The K [...] monotone system theory developped by Kamke in 1932 Hir 85 as a global analysis techniques and the theory of singular perturbations Vid 93 as a local analysis method. We also show {{the consequences of the}} stability analysis on the neural net parameters. Keywords: Cohen [...] <b>Grossberg</b> <b>model,</b> Theory of K [...] monotone systems, Theory of singular perturbations, Learning rule 1 INTRODUCTION The dynamics of complex neural networks must include the aspects of long and short [...] term memory. The behaviour of the network is thus characterized by an equation [...] ...|$|E
40|$|Sequential {{viewing of}} two orthogonally related {{patterns}} produces an afterimage {{of the first}} pattern. We report an experiment that quantifies some properties {{of this type of}} afterimage. It is shown that {{it is important for the}} two patterns to have orthogonal orientations and that the appearance of the afterimage does not depend on the spatial frequency of the second pattern. We then show that <b>Grossberg’s</b> <b>model</b> of interacting boundary and feature contour systems can account for the observed properties of these afterimages. Interactions of afterimages...|$|R
5000|$|Shunting {{model is}} one of the <b>Grossberg's</b> neural network <b>model</b> based on Leaky integrator, given by the expression: ...|$|R
2500|$|LAMINART {{and similar}} neural {{networks}} researched by Stephen <b>Grossberg</b> attempt to <b>model</b> both {{the infrastructure of}} the cortex and the behavior of neurons in a temporal framework to explain neurophysiological and psychophysical data. [...] However, these networks are, at present, too complex for realistic application.|$|R
40|$|In this paper, we {{investigate}} {{the use of}} adaptive extended Luenberger state estimators for general nonlinear and possibly time-varying systems. We identify {{the connection between the}} extended Luenberger observer and <b>Grossberg’s</b> additive <b>model</b> for dynamic neural networks. The association between dynamic neural networks and the Luenberger observer leads to an obvious modification on the proposed observer scheme that would allow handling state estimation for those systems whose dynamic equations are partially known or not known at all. The performance of the adaptive observer is demonstrated on a number of systems including an LTI system, the Van der Pol oscillator, the Lorenz attractor and a realistic partial gasoline engine model. 1...|$|R
40|$|A {{computer}} simulation was conducted of an agent attempting to sur-vive in a 2 D environment, given existence of food, water and shock ob-jects. The {{behavior of the}} agent was governed by <b>Grossberg’s</b> [3] neural <b>model</b> of instrumental and classical conditioning that captures the con-cepts of Hull’s drive theory [4]. The drives of pain, hunger and thirst were simulated, and acted as reinforcement signals to successfully learn approach-avoidance behavior. ...|$|R
50|$|According to Pinna and <b>Grossberg,</b> the FAÇADE <b>model</b> better models {{the brain}} {{activity}} {{that occurs when}} the watercolor illusion is viewed. The FAÇADE model illustrates that the boundary contour system (BCS) and feature contour system (FCS) in parallel. The BCS does boundary grouping and the FCS does the surface filling in. These two processes occur within the regions V1 (primary visual cortex) through V4 (V2 through V4 are three extrastriate visual cortical areas). The FAÇADE model is weakened when the edges are low contrast to each other.|$|R
40|$|Abstract. This paper {{presents}} a neural design which {{is able to}} pro-vide the necessary reactive navigation and attention skills for 3 D em-bodied agents (virtual humanoids or characters). Based on <b>Grossberg’s</b> neural <b>model</b> of conditioning [6], as recently implemented by Chang and Gaudiando [7], {{and according to the}} Adaptative Resonance The-ory (ART) and the neuroscientific concepts associated, the neural design introduced has been divided in two main phases. Firstly, an environment-categorization phase, where an on-line pattern recognition and catego-rization of the current agent sensory input data is carried out by a self organizing neural network, which will finally provide the agent’s short term memory layer(STM). Secondly, and based on the classical condi-tioning paradigm, the model will associate the interesting STM states, from the navigation or attention points of view, to finally simulate these necessary skills for 3 D characters or humanoids. Finally, we will show some experimental navigational results, through the integration of the model presented in 3 D virtual environments. ...|$|R
40|$|The laminar {{structure}} of cortex was first described by Ramón y Cajal (1899). It consists of six different layers, each containing a characteristic distribution of neurons and cell types connecting with other cortical and sub-cortical regions. These extensive connections form microcircuits that group into functionally distinct columns (e. g. Mountcastle, 1997). To {{account for the}} Venetian Blind Effect, Cao and <b>Grossberg</b> propose a <b>model</b> which exploits the functional organization of visual cortex, in particular the selective firing activities of visual cortical neurons responding to the orientation and/or the luminance contrast of surface boundaries, demonstrated first by Hubel & Wiesel (1959 and 1962) ...|$|R
40|$|This paper {{presents}} a neural design which {{is able to}} provide the necessary reactive navigation and attention skills for 3 D embodied agents (virtual humanoids or characters). Based on <b>Grossberg’s</b> neural <b>model</b> of conditioning [6], as recently implemented by Chang and Gaudiando [7], {{and according to the}} Adaptative Resonance Theory (ART) and the neuroscientific concepts associated, the neural design introduced has been divided in two main phases. Firstly, an environmentcategorization phase, where an on-line pattern recognition and categorization of the current agent sensory input data is carried out by a self organizing neural network, which will finally provide the agent’s short term memory layer(STM). Secondly, and based on the classical conditioning paradigm, the model will associate the interesting STM states, from the navigation or attention points of view, to finally simulate these necessary skills for 3 D characters or humanoids. Finally, we will show some experimental navigational results, through the integration of the model presented in 3 D virtual environments. Partially supported by the GVA-project CTIDIB- 2002 - 182 (Spain) ...|$|R
40|$|AbstractThis paper {{deals with}} {{modeling}} and simulation of neural oscillators introduced by Ellias and <b>Grossberg.</b> The proposed <b>model</b> incorporates all-important physiological characteristics. The model uses reliable, compact, and inexpensive components for simulation and several such models can be interconnected together to study complex dynamic behavior of central nervous system such as the human gait transitions. The model has been successfully tested for different phenomena and behavior of neuronal systems. A chain of the proposed electronic model tested for phase locking produced good results similar to those obtained from software simulation. This model is also {{a step in the}} direction of development of artificial intelligent systems...|$|R
40|$|Introduction Non-linear {{diffusion}} or Variable Conductance Diffusion (VCD) processes {{can be used}} as {{to filter}} away noise while preserving boundary information. However, adjustment of the control parameters is not well understood. By approaching the control of VCD systems through a multiscale statistical analysis, information about the image is revealed regarding the strength of boundaries and their influence with regard to the local geometry of the object. This information can then be used to monitor and guide the diffusion process. Background Several approachs to computer vision begin with a set of governing constraints and equations, and construct the mathematics and superstructure for vision based upon these axiomatic principles. One such approach toward vision is based upon diffusion as a plausible <b>model</b> of vision. <b>Grossberg</b> describes a <b>model</b> that includes a boundary detection system and a system by which feature values undergo a process of "filling-in" [Gro...|$|R
40|$|D. M. Jacobs and C. F. Michaels (2006) {{concluded}} that aspects of hand movements in lateral catching were {{predicted by the}} ratio of lateral optical velocity to expansion velocity. Their conclusions were based partly on {{a modified version of}} the required velocity model of catching (C. E. Peper, R. J. Bootsma, D. R. Mestre, & F. C. Bakker, 1994). The present article considers this optical ratio in detail and asks whether it, together with a control law, predicts the (often curious) hand trajectories observed in lateral interception. The optical ratio was used to create a succession of target-position inputs for the vector integration to endpoint model of hand movements (D. Bullock & S. <b>Grossberg,</b> 1988). The <b>model</b> used this succession, initial hand position, and model parameters (fit to 60 trials) to predict hand trajectories on each trial. Predicted trajectories were then compared with observed hand trajectories. Hand movements were predicted accurately, especially in the binocular condition, and were superior to predictions based on lateral ball position, the input variable of the required velocity model. The authors concluded, as did C. E. Peper et al. (1994), that perceivers continuously couple movements to optics. Copyright 2006 by the American Psychological Association...|$|R
40|$|To {{analyze the}} impact of outline shape on visual word recognition, the visual pattern of the stimuli can be {{distorted}} by size alternation. Contrary to the predictions of models that rely on outline shape (Allen et al., 1995), the effect of size alternation was greater for lowfrequency words than for high-frequency words in a lexical decision task (Experiment 1). In Experiment 2, the effect of case type (lowercase vs. UPPERCASE) occurred for lowfrequency words, but not for high-frequency words. The effect of neighborhood size was remarkably similar in the two experiments. The results can be readily explained {{in the framework of}} a resonance <b>model</b> (<b>Grossberg</b> & Stone, 1986), in which a mismatch between the original sensory pattern and the abstract orthographic code slows down the formation of a stable percept. 3 An important (and recurrent) issue in visual word recognition in alphabetic languages is whether words can be formed uniquely on the basis of abstract letter units or, instead, they can also be formed on the basis of other sources (e. g., via word global shape). Undoubtedly, this is clearly an issue that has implications for the teaching of both reading and spelling (Besner, 1983). Although early research suggested that words could be identified by the use of word shape (see Cattell, 1886), most theorists currently support the idea that words are initially formed from component letters ("analytical" models; e. g., search model, Forster, 1976; multiple read-out model, Grainger & Jacobs, 1996; interactive-activation model, McClelland & Rumelhart, 1981; activation-verification model, Paap, Newsome, McDonald, & Schvaneveldt, 1982). In these models, information about visual form is probably lost early in the process of word recognition, so that the particular visual form t [...] ...|$|R

