124|442|Public
5000|$|... Touch-Sensitive Display Screen With Absolute And Relative <b>Input</b> <b>Modes</b> ...|$|E
50|$|For <b>input</b> <b>modes,</b> it {{supports}} RPN, Chain and Algebraic input.|$|E
5000|$|The three <b>input</b> <b>modes</b> for {{terminals}} in Seventh Edition Unix were: ...|$|E
50|$|Note that Envy24HT-S {{supports}} 24-bit / 192 kHz mode only in 4 channel output (4 channel <b>input)</b> <b>mode,</b> {{while in}} 8 channel output (2 channel <b>input)</b> <b>mode</b> it {{is limited to}} 20-bit / 48 kHz.|$|R
5000|$|Does the {{interface}} utilize different <b>inputs</b> <b>modes</b> such as touching, spoken, gestures, or orientation? ...|$|R
5000|$|GNU Emacs allows {{mnemonics}} entry {{by switching}} to rfc1345 <b>input</b> <b>mode</b> (by default [...] ).|$|R
5000|$|OPERATING MODES OF 8279:1)Input ModesThe basic <b>input</b> <b>modes</b> are1)Scanned keyboard2)Scanned sensor matrix3)Strobed input2)Display ModesThe {{two basic}} output modes are1)Left Entry ( [...] Typewriter type)2)Right Entry ( [...] Calculator type) ...|$|E
50|$|This version, {{finalized}} 27 February 2007, {{expands the}} capabilities of XHTML MP 1.1 with full support for the Forms Module and OMA Text <b>Input</b> <b>Modes.</b> XHTML MP 1.2 is part of v2.3 of the OMA Browsing Specification (13 March 2007).|$|E
5000|$|The data {{structure}} used {{by all of}} the terminal library calls is the [...] structure, whose C and C++ programming language definition is as follows:struct termios { tcflag_t c_iflag // <b>Input</b> <b>modes</b> tcflag_t c_oflag // Output modes tcflag_t c_cflag // Control modes tcflag_t c_lflag // Local modes cc_t c_ccNCCS // Control characters} ...|$|E
5000|$|Arrow keys work in <b>input</b> <b>mode.</b> In fact, if you {{invoke the}} editor via the name [...] "input", {{then it will}} start editing in <b>input</b> <b>mode.</b> You can make your changes, and then exit by hitting Control-Z twice, and NEVER go into visual command mode. In other words, elvis can act pretty much like a normal editor -- {{something}} that the real vi certainly can't do.|$|R
5000|$|Direct input {{is almost}} {{necessarily}} absolute, but indirect input may be either absolute or relative. For example, digitizing graphics tablets {{that do not}} have an embedded screen involve indirect input and sense absolute positions and are often run in an absolute <b>input</b> <b>mode,</b> but they may also be set up to simulate a relative <b>input</b> <b>mode</b> like that of a touchpad, where the stylus or puck can be lifted and repositioned.|$|R
40|$|In 2 experiments, {{investigated}} the automaticity of attribute memory; Ss were {{a total of}} 78 {{high school and college}} students. Results show that when instructed to attend to the case and color in which words were presented, Ss 2 ̆ 7 retention <b>input</b> <b>mode</b> improved, but their recognition performance was depressed. Allocating attention to <b>input</b> <b>mode</b> thus appears to result in diminished attention to semantic aspects of words. When case and color were uncorrelated with taxonomic category, memory for <b>mode</b> of <b>input</b> dropped to chance levels. When case and color were redundant with taxonomic category, memory for <b>mode</b> of <b>input</b> was better than chance. Findings suggest, however, that this result was due to rule learning rather than to memory for <b>input</b> <b>mode</b> for individual items...|$|R
50|$|Two {{major groups}} of {{multimodal}} interfaces have merged, one concerned in alternate input methods {{and the other}} in combined input/output. The first group of interfaces combined various user <b>input</b> <b>modes</b> beyond the traditional keyboard and mouse input/output, such as speech, pen, touch, manual gestures, gaze and head and body movements. The most common such interface combines a visual modality (e.g. a display, keyboard, and mouse) with a voice modality (speech recognition for input, speech synthesis and recorded audio for output). However other modalities, such as pen-based input or haptic input/output may be used. Multimodal user interfaces are a research area in human-computer interaction (HCI).|$|E
5000|$|From a {{programming}} {{point of}} view, a terminal device had transmit and receive baud rates, [...] "erase" [...] and [...] "kill" [...] characters (that performed line editing, as explained), [...] "interrupt" [...] and [...] "quit" [...] characters (generating signals {{to all of}} the processes for which the terminal was a controlling terminal), [...] "start" [...] and [...] "stop" [...] characters (used for software flow control), an [...] "end of file" [...] character (acting like a carriage return except discarded from the buffer by the [...] system call and therefore potentially causing a zero-length result to be returned) and various mode flags determining whether local echo was emulated by the kernel's terminal driver, whether modem flow control was enabled, the lengths of various output delays, mapping for the carriage return character, and the three <b>input</b> <b>modes.</b>|$|E
50|$|Strictly speaking, in Unices a {{terminal}} device comprises the underlying tty device driver, {{responsible for the}} physical control of the device hardware via I/O instructions and handling device interrupt requests for character input and output, and the line discipline. A line discipline is independent of the actual device hardware, and the same line discipline {{can be used for}} {{a terminal}} concentrator device responsible for multiple controlling terminals as for a pseudoterminal. In fact, the line discipline (or, in the case of BSD, AIX, and other systems, line disciplines) are the same across all terminal devices. It is the line discipline that is responsible for local echo, line editing, processing of <b>input</b> <b>modes,</b> processing of output modes, and character mapping. All these things are independent of the actual hardware, dealing as they do in the simple abstractions provided by tty device drivers: transmit a character, receive a character, set various hardware states.|$|E
50|$|Kate {{can be used}} as a modal {{text editor}} through its vi <b>input</b> <b>mode</b> which emulates a Unix text editor with the same name.|$|R
50|$|In the <b>input</b> <b>mode,</b> the 8255 gets {{data from}} the {{external}} peripheral ports and the CPU reads the received data via its data bus.|$|R
2500|$|For {{entering}} Japanese, {{the most}} common method is entering text phonetically, as romanized (transliterated) kana, which are then converted to kanji as appropriate by an input method editor. It is also possible to type kana directly, depending on the mode used. For example, to type , [...] "Takahashi", a Japanese name, one could type either [...] in Romanized (Rōmaji) <b>input</b> <b>mode,</b> or [...] in kana <b>input</b> <b>mode.</b> Then the user can proceed to the conversion step to convert the input into the appropriate kanji.|$|R
40|$|In {{this paper}} we discuss our use of {{multi-modal}} input to improve human computer interaction. Specifically {{we look at the}} methods used in the Intelligent Classroom to combine multiple <b>input</b> <b>modes,</b> and examine in particular the visual <b>input</b> <b>modes.</b> The Classroom provides context that improves the functioning of the visual <b>input</b> <b>modes.</b> It also determines which visual <b>input</b> <b>modes</b> are needed when. We examine a number of visual <b>input</b> <b>modes</b> to see how they fit into the general scheme, and look at how the Classroom controls their operation...|$|E
40|$|We {{propose a}} scheme for continuous-variable quantum cloning of {{coherent}} states with phase-conjugate <b>input</b> <b>modes</b> using linear optics. The quantum cloning machine yields $M$ identical optimal clones from $N$ replicas {{of a coherent}} state and $N$ its replicas of phase conjugate. This scheme can be straightforwardly implemented with the setup accessible at present since its optical implementation only employs simple linear optical elements and homodyne detection. Compared with the original scheme for continuous variables quantum cloning with phase-conjugate <b>input</b> <b>modes</b> proposed by Cerf and Iblisdir [Phys. Rev. Lett. 87, 247903 (2001) ], which utilized a nondegenerate optical parametric amplifier, our scheme loses the output of phase-conjugate clones and is regarded as irreversible quantum cloning. Comment: 6 pages, 3 figures. appear in Phys. Rev. ...|$|E
40|$|Multimodal {{interfaces}} require effective parsing {{and understanding}} of utterances whose content is distributed across multiple <b>input</b> <b>modes.</b> Johnston 1998 presents an approach in which strategies for multimodal integration are stated declaratively using a unification-based grammar {{that is used by}} a multidimensional chart parser to compose inputs. This approach is highly expressive and supports a broad class of interfaces, but offers only limited potential for mutual compensation among the <b>input</b> <b>modes,</b> is subject to significant concerns in terms of computational complexity, and complicates selection among alternative multimodal interpretations of the input. In this paper, we present an alternative approach in which multimodal parsing and understanding are achieved using a weighted finite-state device which takes speech and gesture streams as inputs and outputs their joint interpretation. This approach is significantly more efficient, enables tight-coupling of multimodal understanding with [...] ...|$|E
5000|$|... <b>input</b> <b>mode</b> flags for {{controlling}} input parity, input newline translation, modem flow control, 8-bit cleanliness, {{and response to}} a (serial port's) [...] "break" [...] condition ...|$|R
5000|$|For {{entering}} Japanese, {{the most}} common method is entering text phonetically, as romanized (transliterated) kana, which are then converted to kanji as appropriate by an input method editor. It is also possible to type kana directly, depending on the mode used. For example, to type たかはし, [...] "Takahashi", a Japanese name, one could type either [...] in Romanized (Rōmaji) <b>input</b> <b>mode,</b> or [...] in kana <b>input</b> <b>mode.</b> Then the user can proceed to the conversion step to convert the input into the appropriate kanji.|$|R
50|$|The {{keyboard}} {{does not}} have hangul symbols. Instead diacritic marks are used. The <b>input</b> <b>mode</b> key in this version {{does not have}} an LED and is lettered 'CODE'.|$|R
40|$|In this paper, ongoing {{research}} {{pursuing the}} distinction of online handwriting into textual and different drawing classes is described. In the context of natural pen-based interactions, users will seamlessly switch between such different <b>input</b> <b>modes.</b> Therefore, it is vital for pen input recognition systems {{to be able to}} distinguish between these cases, preferably in an early stage of processing. The method described in this paper is tested on data acquired in a multi-modal task setting where users are requested to specify shape and dimensions of bathrooms, using pen and speech. Mode detection in this context yields comparable outcomes to recent findings from the literature. The results presented here elaborate on these findings by examining the possibility to perform early recognition of <b>input</b> <b>modes,</b> socalled incremental recognition. To this end, PENDOWN as well as PENUP trajectories are being explored. 1...|$|E
40|$|The {{system is}} modular and is {{designed}} for use on a small to medium sized computer. Each module of the programming package is a functional entity, linked to other modules by an overlay technique. In the paper, {{the construction of the}} programming system and its modules, the different <b>input</b> <b>modes</b> and the various hidden-line detection procedures are described...|$|E
3000|$|... [...]), the {{input-output}} {{relation of}} the parametric amplifier in Eq. (15 b) has the minimal form of a scattering mode amplifier [19]. The amplification process reaches the vacuum limit {{as long as the}} <b>input</b> <b>modes</b> are cooled into the vacuum. In practice, however, the device may have finite loss γ which increases the effectively added noise by a factor of [...]...|$|E
50|$|The {{keyboard}} contains {{symbols of}} Hangul {{and a special}} key (with the label «Hangul» in hangul), which switches <b>input</b> <b>mode</b> between English and hangul. This key has a LED indicator (similar to the CAPS LOCK key).|$|R
50|$|These {{informal}} {{bodies are}} created by municipal councils. Their mode of operation varies by commune, the age (9 to 25) and the <b>input</b> <b>mode</b> (election town hall, schools, designation within representative associations, volunteering, etc. mixed system).|$|R
50|$|Typical Caps Lock {{behaviour}} is that {{pressing the}} key sets an <b>input</b> <b>mode</b> {{in which all}} typed letters are uppercase by default (i.e. in All caps). The keyboard remains in Caps Lock mode until the key is pressed again.|$|R
40|$|A {{keystroke}} {{biometric system}} for long-text input {{was developed and}} evaluated for identification and authentication applications. The system consists of a Java applet to collect raw keystroke data over the Internet, a feature extractor, and pattern classifiers to make identification or authentication decisions. Experiments on over 100 subjects investigated two <b>input</b> <b>modes</b> – copy and free-text input – and two keyboard types – desktop and laptop keyboards. The system can accurately identify or authenticate individuals if sufficient enrollment samples are available and if {{the same type of}} keyboard is used to produce the enrollment and questioned input samples. Identification and authentication performance decreased significantly when subjects used different <b>input</b> <b>modes</b> or different keyboard types for enrollment and testing. Longitudinal experiments quantified performance degradation over intervals of several weeks and over an interval of two years. Additional experiments investigated the system’s hierarchical model, parameter settings, assumptions, and sufficiency of enrollment samples and input-text length...|$|E
40|$|Abstract: Many {{organizations}} had employed {{interactive media}} systems to facilitate ecology education in natural science museum or through websites based on touch screen technologies. Since the mapping issue between <b>input</b> <b>modes</b> and digital contents is very important, {{the objective of}} this research is to study the effects of touch <b>input</b> <b>modes</b> and navigation bar styles on the usability of an ecology education system. In this research, three types of navigation menu, i. e., global fisheye menu, local fisheye menu, and tabbed menu were constructed for comparison. In addition, two touch modes for the backward shortcut button from the detailed page to the main menu were constructed. In the experiment, participants carried out typical tasks to locate assigned pages for searching information. Video recording were employed {{to keep track of the}} behaviors. After that, the participant was asked to complete system component usability and overall workload questionnaire. The result revealed that tabbed menu with long touch was superior in usability...|$|E
3000|$|In {{telecommunications}} applications, {{the output}} modes {{will be called}} diversity modes because they correspond to time, space, and frequency diversities, whereas the <b>input</b> <b>modes</b> are associated with resources like transmit antennas, codes, and data streams. For these applications, the matrices Φ(n) are formed with 0 ’s and 1 ’s, {{and they can be}} interpreted as allocation matrices used for allocating some resources r [...]...|$|E
50|$|In the POSIX {{terminal}} interface, these modes {{have been}} superseded {{by a system}} of just two input modes: canonical and non-canonical. The handling of signal-generating special characters in the POSIX terminal interface is independent of <b>input</b> <b>mode,</b> and is separately controllable.|$|R
50|$|Boshiamy {{provides}} a special <b>input</b> <b>mode</b> for users to master these short codes. In this mode, users can only input a character by its shortest code, otherwise {{it does not}} output the character, but instead shows users the character alongside its shortest code.|$|R
50|$|Different {{computer}} {{operating systems}} require {{different degrees of}} mode support when terminals are used as computer terminals. The POSIX terminal interface, as provided by Unix and POSIX-compliant operating systems, does not accommodate block-mode terminals at all, and only rarely requires the terminal itself to be in line-at-a-time mode, since the operating system is required to provide canonical <b>input</b> <b>mode,</b> where the terminal device driver in the operating system emulates local echo in the terminal, and performs line editing functions at the host end. Most usually, and especially so that the host system can support non-canonical <b>input</b> <b>mode,</b> terminals for POSIX-compliant systems are always in character-at-a-time mode. In contrast, IBM 3270 terminals connected to MVS systems are always required to be in block mode.|$|R
