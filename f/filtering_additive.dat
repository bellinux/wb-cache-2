12|114|Public
30|$|In this study, a new semi-fragile {{digital speech}} {{watermarking}} technique was implemented by application of DWPT and angle quantization. This watermarking technique is fragile against various attacks, including <b>filtering,</b> <b>additive</b> noise, cut sampling, and compression attacks. The degradation {{effect on the}} recognition performance of this watermarking technique is negligible. In addition, any intentional or unintentional tampering with the watermarked speech signal can easily be detected via a tampering threshold because the watermark {{is embedded in the}} least speaker-specific of the speech sub-bands.|$|E
40|$|A novel speckle {{reduction}} technique {{based on}} soft thresholding of wavelet coefficients using interval type II fuzzy system {{was developed for}} reducing speckle noise in Optical Coherence Tomography images. The proposed algorithm {{is an extension of}} a recently published method for <b>filtering</b> <b>additive</b> noise by use of type I fuzzy system. Unlike type I, interval type II fuzzy based thresholding filter considers the uncertainty in the calculated threshold and the wavelet coefficient is adjusted based on this uncertainty. Application of this novel algorithm to optical coherence tomography images of a finger tip show reduction in speckle with little edge blurring...|$|E
40|$|AbstractThis paper {{presents}} a new blind digital speech watermarking technique based on Eigen-value quantization in Discrete Wavelet Transform. Initially, each {{frame of the}} digital speech was transformed into the wavelet domain by applying Discrete Wavelet Transform. Then, the Eigen-value of Approximation Coefficients was computed by using Singular Value Decomposition. Finally, the watermark bits were embedded by quantization of the Eigen-value. The experimental results show that this watermarking technique is robust against different attacks such as <b>filtering,</b> <b>additive</b> noise, resampling, and cropping. Applying new robust transforms, adaptive quantization steps and synchronization techniques can be the future trends in this field...|$|E
3000|$|... {{refers to}} a complex Gaussian random vector (or variable) with mean vector m and {{covariance}} matrix Σ. Also, n 0,i(t) is the <b>filtered</b> <b>additive</b> white Gaussian noise process.|$|R
40|$|Cigarette {{smoke is}} an aerosol {{containing}} {{a large number of}} chemicals, including toxicants. In recent years, a number of cigarette <b>filter</b> <b>additives</b> have been evaluated for their toxicant filtration properties. Screening is a useful tool to accelerate the testing and development of new <b>filter</b> <b>additives</b> and filtration mechanisms. The evaluation of a filter material screening technique based on the so-called InfraSORP technology is described. By comparing InfraSORP measurements with reference cigarette smoke experiments of potential cigarette filter materials like activated carbons and ion-exchange resin, an excellent correlation is demonstrated. This technique allows for a rapid screening of potential filter materials prior to testing any final candidates in cigarettes...|$|R
50|$|Analog signal {{processing}} is for signals {{that have not}} been digitized, as in legacy radio, telephone, radar, and television systems. This involves linear electronic circuits as well as non-linear ones. The former are, for instance, passive <b>filters,</b> active <b>filters,</b> <b>additive</b> mixers, integrators and delay lines. Non-linear circuits include compandors, multiplicators (frequency mixers and voltage-controlled amplifiers), voltage-controlled filters, voltage-controlled oscillators and phase-locked loops.|$|R
40|$|A Real-Time audio {{watermarking}} {{scheme is}} proposed, where {{the strength of}} audio signal modifications {{is limited by the}} requirement of producing an output audio signal that is perceptually equal to the original one. The watermark embedding stage, based on a spread spectrum algorithm operating in the Modulated Complex Lapped Transform (MCLT) domain, inserts a watermark that is generated using a private key which modeled according to the Human Auditory System (HAS). The proposed blind detection approach is based on the Additive White Gaussian Noise (AWGN) channel theory; and to achieve this goal several whitening methods in the receptor side were evaluated. Evaluation results show that the proposed watermarking embedding scheme is robust to common attacks such like, D/A and A/D conversion, <b>filtering,</b> <b>additive</b> noise and high quality MPEG audio coding...|$|E
40|$|<b>Filtering</b> <b>additive</b> white Gaussian {{noise in}} images using the best linear {{unbiased}} estimator (BLUE) is technically sound {{in a sense}} that it is an optimal average filter derived from the statistical estimation theory. The BLUE filter mask has the theoretical advantage in that its shape and its size are formulated in terms of the image signals and associated noise components. However, like many other noise filtering problems, prior knowledge about the additive noise needs to be available, which is often obtained using training data. This paper presents the sequential Gaussian simulation in geostatistics for measuring signal and noise variances in images without the need of training data for the BLUE filter implementation. The simulated signal variance and the BLUE average can be further used as parameters of the adaptive Wiener filter for image restoration...|$|E
40|$|Reordering by {{the rule}} of {{decreased}} absolute amplitudes, the discrete cosine transformation (DCT) coefficients of an image are approximately modeled as dichotomous noise. Based on this assumption, {{it is interesting to}} note that the classical multiplicative embedding method can be transformed into an additive embedding rule, which accords with the signal processing problem of detecting a known weak signal in additive non-Gaussian noise. Then, following the generalized Neyman-Pearson lemma, a locally optimum detector, named the sign detector, is introduced to distinguish the correct watermark from the wrong ones. The statistical characteristics of this nonlinear sign detector are analytically investigated in detail. Extensive experimental results demonstrate the robustness of watermark against some common attacks, e. g., JPEG compression, cropping, <b>filtering,</b> <b>additive</b> Gaussian noise, dithering, and also verify the robust performance of the nonlinear sign detector for watermark detection. Fabing Duan, Derek Abbott, François Chapeau-Blondea...|$|E
25|$|Pet stores market zeolites {{for use as}} <b>filter</b> <b>additives</b> in aquaria. In aquaria, zeolites {{can be used to}} adsorb ammonia {{and other}} {{nitrogenous}} compounds. However, due to the high affinity of some zeolites for calcium, they may be less effective in hard water and may deplete calcium. Zeolite filtration is used in some marine aquaria to keep nutrient concentrations low for the benefit of corals adapted to nutrient-depleted waters.|$|R
40|$|Abstract—In this paper, an {{innovative}} watermarking scheme for audio signal based on genetic algorithms (GA) in the discrete wavelet transforms is proposed. It is robust against watermarking attacks, which are commonly employed in literature. In addition, the watermarked image quality is also considered. We employ GA for the optimal localization {{and intensity of}} watermark. The watermark detection process can be performed without using the original audio signal. The experimental results demonstrate that watermark is inaudible and robust to many digital signal processing, such as cropping, low pass <b>filter,</b> <b>additive</b> noise. Keywords—Intelligent Audio Watermarking, Genetic Algorithm, Discrete wavelet transform...|$|R
40|$|Cigarette smoke {{can cause}} {{cellular}} oxidative stress {{that contributes to}} various adverse health effects associated with smoke exposure, partially due to reactive oxygen species (ROS) present in cigarette smoke. Reduction of abundant ROS in the cigarette mainstream smoke (MSS) is of importance for human health. In this work, a simple, rapid, and reliable fluorescence evaluation of scavenging efficiency of antioxidants as potential <b>filter</b> <b>additives</b> against ROS in cigarette smoke is reported. This method {{was based on the}} combination of model glass reactor and a fluorescence assay of ROS in cigarette smoke using dihydrorhodamine 6 G (DHR- 6 G). The antioxidant was added into a glass reactor attached to cigarette filter, which simplified the preparation of combined <b>filter</b> containing <b>additives.</b> The ROS scavenging efficiency of antioxidants was then determined using spectrofluorimetry by the change in fluorescence intensity of whole smoke-bubbled solutions before and after addition of antioxidants into the glass reactor. The proposed method was successfully applied to the determination of ROS scavenging efficiency of several potential additives, such as tert-butylhydroquinone (TBHQ), vitamin C, -carotene, grape seed extract, and Ginkgo biloba extract. Moreover, the relationship between MSS ROS scavenging efficiency and antioxidant activities (DPPH radicals scavenging efficiency and Fe 2 + reducing power) of these compounds was also investigated...|$|R
40|$|Orthogonal Frequency Division Multiple xer (OFDM) {{technology}} is a key technique for achieving the high dat a rate and spectral efficiency requirements for wireless communicati on systems of the near future. This paper presents a modeling and simulati on of OFDM by MATLAB& Simulink. Different modulation schemes hav e been used, such as BPSK, QPSK, DBPSK, DQPSK, 8 PSK and 16 PSK. The paper concentrated on Differential Quadrature Phase Shift Keying (DQPSK) as a modulation scheme since it achieved high data rate and very good per formance. As part of this, an investigation of detrimental effe cts of wireless transmission system drawbacks on OFDM is presented, showing the effect of band pass <b>filtering,</b> <b>Additive</b> White Gaussian Noise (AWGN) on modulation Bit Error Rate (BER). The paper also presents how OFDM deal with other transmission drawbacks such as attenuation, multipath, delay spread and Doppler shif...|$|E
30|$|In {{digital image}} watermarking, an image is {{embedded}} into a picture {{for a variety}} of purposes such as captioning and copyright protection. In this paper, a robust private watermarking scheme for embedding a gray-scale watermark is proposed. In the proposed method, the watermark and original image are processed by applying blockwise DCT. Also, a Dynamic Fuzzy Inference System (DFIS) is used to identify the best place for watermark insertion by approximating the relationship established between the properties of HVS model. In the insertion phase, the DC coefficients of the original image are modified according to DC value of watermark and output of Fuzzy System. In the experiment phase, the CheckMark (StirMark MATLAB) software was used to verify the method robustness by applying several conventional attacks on the watermarked image. The results showed that the proposed scheme provided high image quality while it was robust against various attacks, such as Compression, <b>Filtering,</b> <b>additive</b> Noise, Cropping, Scaling, Changing aspect ratio, Copy attack, and Composite attack in comparison with related methods.|$|E
40|$|Introduction. Digital watermarks (DWM) {{refer to}} {{embedding}} additional information directly into audio signal for digital right management and automatic identification of radiotelephone transmissions in aeronautical, maritime and military VHF communication. The main part. The designed embedding algorithm {{is based on}} evaluation of sliding frame to embed information or no regarding to distortions introduced by DWM. Watermark location is grounded calculation of distances norm between received and maximum likelihood estimated signal vectors {{in the domain of}} Discreet Fourier Transform and doesn?t need for any marking and synchronizing measures. Robustness of DWM against quantization, <b>filtering,</b> <b>additive</b> Gaussian noise, digital format conversion is provided by multichannel narrowband DWM transmission and application of BCH (63, 30, 6) error-correction code. The proposed algorithm demonstrates watermark inaudibility because of preserving signal power before and after data embedding and searching the most suitable frames for DWM positioning. Conclusion. The proposed algorithms provide advanced compromising solution of audio watermarking process: data payload ? inaudibility ? robustness. The designed algorithms are applicable both in analog and digital channels for transmission monitoring and digital right management. ??????????? ????????? ??????????? ? ??????????? ???????? ??????? ?????? ? ???????? ??????? ?? ?????? ??????? ??????????? ?????? ? ????????? ???????. ????????? ???????????? ??????????? ????????? ???????, ??????????? ? ????????????? ??? ? ??????????? ?????? ??? ????????????? ?????-???? ???????? ? ??????????????. ??? ??????????? ?????????????????? ??? ????????? ???????????? ?????????????? ???????? ? ???????????????? ???????????...|$|E
30|$|The second {{component}} constituting our SE front-end is an MVDR beamformer. This {{component is}} designed to <b>filter</b> out <b>additive</b> noise that remains in the dereverberated signals. In this work, the MVDR beamformer was implemented by using the scheme proposed in [20] by using noise covariance matrices estimated from the initial and final 10 frames of each utterance.|$|R
40|$|This master’s thesis {{deals with}} issues, which are {{suitable}} to solve by {{the method of}} adaptive <b>filtering</b> of <b>additive</b> noise in image processing. It deduces an algorithm of the adaptive filtering method. Then it studies properties of this filter. In the end it applies deduced algorithm on a particular picture and compares the results with linear filtering...|$|R
40|$|ABSTRACT Speech {{recognition}} systems perform {{poorly on}} speech degradedby even simple effects such as linear <b>filtering</b> and <b>additive</b> noise. One {{solution to this}} problem is to modify the probability densityfunction (PDF) of clean speech to account for the effects of the degradation. However, even for the case of linear filtering andadditive noise, it is extremely difficult to do this analytically. Previously-attempted analytical solutions for the problem ofnoisy speech recognition have either used an overly-simplified mathematical description of the effects of noise on the statisticsof speech, or they have relied on the availability of large environment-specific adaptation sets. In this paper we present the Vector Polynomial approximationS(VPS) method to compensate for the effects of linear <b>filtering</b> and <b>additive</b> noise on the PDF of clean speech. VPS alsoestimates the parameters of the environment, namely the noise and the channel, by using statistically linearized approximationsof these effects...|$|R
40|$|In {{digital image}} watermarking, an image is {{embedded}} into a picture {{for a variety}} of purposes such as captioning and copyright protection. In this paper, a robust private watermarking scheme for embedding a gray-scale watermark is proposed. In the proposed method, the watermark and original image are processed by applying blockwise DCT. Also, a Dynamic Fuzzy Inference System (DFIS) is used to identify the best place for watermark insertion by approximating the relationship established between the properties of HVS model. In the insertion phase, the DC coefficients of the original image are modified according to DC value of watermark and output of Fuzzy System. In the experiment phase, the CheckMark (StirMark MATLAB) software was used to verify the method robustness by applying several conventional attacks on the watermarked image. The results showed that the proposed scheme provided high image quality while it was robust against various attacks, such as Compression, <b>Filtering,</b> <b>additive</b> Noise, Cropping, Scaling, Changing aspect ratio, Copy attack, and Composite attack in comparison with related methods. </p...|$|E
40|$|Copyright © 2010 Hossein Rahmani et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. In digital image watermarking, an image is embedded into a picture {{for a variety of}} purposes such as captioning and copyright protection. In this paper, a robust private watermarking scheme for embedding a gray-scale watermark is proposed. In the proposed method, the watermark and original image are processed by applying blockwise DCT. Also, a Dynamic Fuzzy Inference System (DFIS) is used to identify the best place for watermark insertion by approximating the relationship established between the properties of HVS model. In the insertion phase, the DC coefficients of the original image are modified according to DC value of watermark and output of Fuzzy System. In the experiment phase, the CheckMark (StirMark MATLAB) software was used to verify the method robustness by applying several conventional attacks on the watermarked image. The results showed that the proposed scheme provided high image quality while it was robust against various attacks, such as Compression, <b>Filtering,</b> <b>additive</b> Noise, Cropping, Scaling, Changing aspect ratio, Copy attack, and Composite attack in comparison with related methods. 1...|$|E
40|$|Speech {{recognition}} systems perform {{poorly on}} speech degraded by even simple effects such as linear <b>filtering</b> and <b>additive</b> noise. One possible {{solution to this}} problem is to modify the probability density function (PDF) of clean speech to account for the effects of the degradation. However, even for the case of linear <b>filtering</b> and <b>additive</b> noise, it is extremely difficult to do this analytically. Previously attempted analytical solutions to the problem of noisy speech recognition have either used an overly-simplified mathematical description of the effects of noise on the statistics of speech, or they have relied on the availability of large environmentspecific adaptation sets. Some of the previous methods required the use of adaptation data that consists of simultaneously-recorded or "stereo" recordings of clean and degraded speech. In this paper we introduce an approximation-based method to compute the effects of the environment on the parameters of the PDF of clean speech...|$|R
40|$|Abstract—In {{this paper}} a simple {{watermarking}} method for color images is proposed. The proposed method {{is based on}} watermark embedding for the histograms of the HSV planes using visual cryptography watermarking. The method has been proved to be robust for various image processing operations such as <b>filtering,</b> compression, <b>additive</b> noise, and various geometrical attacks such as rotation, scaling, cropping, flipping, and shearing...|$|R
40|$|This paper {{develops}} an optimization {{methodology for}} designing and embedding synchronization patterns in images, for watermarking applications {{in which the}} host image is not available the decoder. Optimality is {{in the sense of}} a certain Fisher information game between the embedder and the attacker. Analytical solutions are derived for problems involving translation, rotation, linear <b>filtering,</b> and <b>additive</b> Gaussian noise attacks...|$|R
40|$|Recently it {{was shown}} that, in some situations, blind {{watermarking}} can perform as well as watermarking schemes with the host signal available to the decoder. In this paper, blind watermarking of colored Gaussian host signals {{in the presence of}} <b>filtering</b> and <b>additive</b> Gaussian noise attacks is discussed. Three suboptimal but practical schemes are compared with a scheme where the host signal is available at the decoder. The performance is analyzed theoretically and experimentally for image watermarking...|$|R
40|$|AbstractTobacco {{smoke from}} a {{combustible}} cigarette {{contains more than}} 6000 constituents; approximately 150 of these are identified as toxicants. Technologies that modify the tobacco blend to reduce toxicant emissions have been developed. These include tobacco sheet substitute to dilute toxicants in smoke and blend treated tobacco to reduce the levels of nitrogenous precursors and some polyphenols. <b>Filter</b> <b>additives</b> to reduce gas (vapour) phase constituents have also been developed. In this study, both tobacco blend and filter technologies were combined into an experimental cigarette and smoked to International Organisation on Standardisation and Health Canada puffing parameters. The resulting particulate matter was subjected to a battery of in vitro genotoxicity and cytotoxicity assays – the Ames test, mouse lymphoma assay, the in vitro micronucleus test and the Neutral Red Uptake assay. The results indicate that cigarettes containing toxicant reducing technologies may be developed without observing new additional genotoxic hazards as assessed by the assays specified. In addition, reductions in bacterial mutagenicity and mammalian genotoxicity of the experimental cigarette were observed relative to the control cigarettes. There {{were no significant differences}} in cytotoxicity relative to the control cigarettes...|$|R
40|$|This paper {{discusses}} {{the problem of}} restoring a digital input signal which has been degraded by an unknown FIR <b>filter</b> in <b>additive</b> Gaussian noise. A Bayesian approach is taken to recover the signal, implemented by the Gibbs sampler, a Markov Chain Monte Carlo method. A method for drawing {{a random sample of}} a sequence of bits is presented: this is shown to have faster convergence and better performance than a scheme by Chen and Li [2] which draws bits independently. 1 PROBLEM FORMULATION Most digital communications systems transmit a signal fx t g where the value of each of the x t are taken from a finite alphabet of p symbols. This is transmitted over a channel which may introduce distortion and noise. The channel model used here is an FIR <b>filter</b> with <b>additive</b> Gaussian noise: y t = nΓ 1 X i= 0 x tΘ h i + v t (1) x t 2 fS 0; : : :; S pΓ 1 g v t i:i:d: ¸ N(0; oe 2 v) (2) where fy t g is the observed signal, fx t g is the transmitted signal, S i a symbol fr [...] ...|$|R
40|$|This {{paper is}} {{a review of}} some of the {{techniques}} {{that can be used to}} improve the performance of spoken dialogue systems in noisy environments. We will look at methods to improve the quality of the input signal by <b>filtering</b> out <b>additive</b> noise in different ways. We will also look at methods to improve a dialogue system’s capability of choosing the correct recognition hypothesis and how to identify recognition errors by prosodic as well as NLU (Natural Language Understanding) features. ...|$|R
40|$|In remote sensing, {{image fusion}} {{technique}} {{is a useful}} tool used to fuse high spatial resolution panchromatic images (PAN) with lower spatial resolution multispectral images (MS) to create a high spatial resolution multispectral of image fusion (F) while preserving the spectral information in the multispectral image (MS). There are many PAN sharpening techniques or Pixel-Based image fusion techniques {{that have been developed}} to try to enhance the spatial resolution and the spectral property preservation of the MS. This paper attempts to undertake the study of image fusion, by using two types of pixel -based image fusion techniques i. e. Arithmetic Combination and Frequency Filtering Methods of Pixel-Based Image Fusion Techniques. The first type includes Brovey Transform (BT), Color Normalized Transformation (CN) and Multiplicative Method (MLT). The second type include High-Pass <b>Filter</b> <b>Additive</b> Method (HPFA), High -Frequency- Addition Method (HFA) High Frequency Modulation Method (HFM) and The Wavelet transform-based fusion method (WT). This paper also devotes to concentrate on the analytical techniques for evaluating the quality of image fusion (F) by using various methods including Standard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to estimate the quality and degree of information improvement of a fused image quantitatively...|$|R
40|$|There is an {{increased}} need for high quality transmission of video over wireless networks for rapidly growing {{applications such as}} telehealth. In this paper, we propose a method for achieving high quality within a diagnostically important Region-of-Interest (ROI) using mathematically lossless (M-lossless) video coding of the ROI and Motion Compensated Temporal Filtering (MCTF) of the video. The remaining region (non-ROI) is coded in a lossy manner. MCTF as a prefilter addresses the issue of noise in video. With the correct values of filter parameters, it results in very good denoising for noisy video and improved quality for even near noiseless video. The key motivation to use MCTF in our application is that in both cases it results in significant reduction of the required total bitrate. This is crucial on data rate constrained wireless networks. We also show how MCTF is particularly advantageous for the ROI. We study the advantages of MCTF in terms of (i) quality improvement, and (ii) bitrate reduction. We apply a mean MCTF to <b>filter</b> <b>Additive</b> White Gaussian Noise (AWGN), and propose a new median MCTF to filter impulse noise. The {{results show that the}} applied techniques result in substantial improvement in quality and significant total bitrate reduction...|$|R
40|$|We study local filters for two {{properties}} of functions f: { 0, 1 } d → R: the Lipschitz property and monotonicity. A local <b>filter</b> with <b>additive</b> error a is a randomized algorithm that is given black-box {{access to a}} function f and a query point x {{in the domain of}} f. Its output is a value F (x), such that (i) the reconstructed function F (x) satisfies the property (in our case, is Lipschitz or monotone) and (ii) if the input function f satisfies the property then for every point x in the domain, with high constant probability the reconstructed value F (x) differs from f(x) by at most a. Local filters were introduced by Saks and Seshadhri (SICOMP 2010). The relaxed definition we study is due to Bhattacharyya et al. (RANDOM 2010), except that we further relax it by allowing <b>additive</b> error. Local <b>filters</b> for Lipschitz and monotone functions have applications to areas such as data privacy. We show that every local filter for Lipschitz (resp., monotone) functions runs in time exponential in the dimension d in the worst case. This holds even for <b>filters</b> with significant <b>additive</b> error, as well as for both previously studied definitions. Prior lower bounds (for local <b>filters</b> with no <b>additive</b> error, i. e., with a = 0) applied only to more restrictive notions of filters, e. g., nonadaptive filters that are required to specify all their lookups in advance, before obtaining values of f on any points. To prove our lowe...|$|R
40|$|Efficient {{numerical}} {{schemes for}} nonlinear diffusion <b>filtering</b> based on <b>additive</b> operator splitting (AOS) {{were introduced in}} [15]. AOS schemes are efficient and unconditionally stable, yet their accuracy is limited. Future applications of nonlinear diffusion filtering may require better accuracy {{at the expense of}} a relatively modest cost in computations and complexity...|$|R
40|$|Different {{approaches}} to real-time estimation {{will be discussed}} (scalar, wave algorithms) and their applications to INS/GPS integration will be analyzed when cycle slips and losses of lock occur. In this case, the predicted position errors of the investigated algorithms do not exceed 10 cm during a time period of 0. 6 - 0. 8 min. This precision could not be achieved by traditional means in real-time, such as Kalman <b>filtering</b> with <b>additive</b> bias parameters. Test results from both, synthetic and field data, will be presented. (orig.) Available from TIB Hannover: RO 7297 (20) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|Knowledge of {{the state}} of balance of the moving human is {{essential}} for the design of fall detection algorithms and wearable robotic controllers for balance assistance. Still, there is no known general method to make an online estimation {{of the state}} of balance of the walking human, with the limited and local sensor measurements that are usually available. Previous work has failed to address such an estimation for human walking rather than standing or biped walking, with only an upper body Inertial Measurement Unit (IMU), and by incorporating the major human balance strategies, to adequately predict the interaction between the human and the robot. In this study, a state estimation technique is introduced: the applied observer is an <b>Additive</b> Unscented Kalman <b>Filter</b> (<b>Additive</b> UKF), and the model consists of a spring-loaded inverted pendulum and articulated upper body, with virtual pivot point (VPP) control and foot placement based on the extrapolated center of mass (XCoM); the Virtual Pendulum Model. The following is described: the dynamic model and observer design, a sensitivity analysis with simulation data, and observer performance with data from a human walking experiment on a treadmill. Proper tuning and limited errors in model parameters, particularly foot contact detection, resulted in promising estimates. With further research toward improved parameter estimation and higher efficiency for online implementation, this method could be useful for the prediction of human movement. Mechanical, Maritime and Materials EngineeringBioMechanical Engineerin...|$|R
40|$|The {{occurrence}} of falls is an urgent challenge in our aging society. For wearable devices that actively prevent falls or mitigate their consequences, a critical prerequisite is knowledge on the user’s {{current state of}} balance. To keep such wearable systems practical and to achieve high acceptance, only very limited sensor instrumentation is possible, often restricted to inertial measurement units at waist level. We propose to augment this limited sensor information by combining it with additional knowledge on human gait, {{in the form of}} an observer concept. The observer contains a combination of validated concepts to model human gait: a spring-loaded inverted pendulum model with articulated upper body, where foot placement and stance leg are controlled via the extrapolated center of mass (XCoM) and the virtual pivot point (VPP), respectively. State estimation is performed via an <b>Additive</b> Unscented Kalman <b>Filter</b> (<b>Additive</b> UKF). We investigated sensitivity of the proposed concept to model uncertainties, and we evaluated observer performance with real data from human subjects walking on a treadmill. Data were collected from an Inertial Measurement Unit (IMU) placed near the subject’s center of mass (CoM), and observer estimates were compared to the ground truth as obtained via infrared motion capture. We found that the root mean squared deviation did not exceed 13 cm on position, 22 cm/s on velocity (0. 56 – 1. 35 m/s), 1. 2 ° on orientation, and 17 °/s on angular velocity. Biomechatronics & Human-Machine ControlBiorobotic...|$|R
40|$|This paper {{included}} the derivation of basic performance bounds and {{the analysis of}} the feedforward NLF STR structure as a sub [...] optimal ML implementation. This was accompanied by texts by Stiffler [15], Lindsey and Simon [16] and others which presented detailed descriptions and analysis of the MLE and MAP methods. Analysis was confined to baseband digital transmission signals such as Non Return to Zero (NRZ) data and, to some extent, signals with optimum filtering such as those with Nyquist channel filtering (for example raised cosine <b>filters)</b> and <b>additive</b> white Gaussian noise. Such models are still common today due to their mathematical tractability. 8 Chapter 1 : Introductio...|$|R
40|$|This {{paper is}} {{concerned}} with non-fragile H∞ filtering for linear systems in network environments. The filtering error system is modeled as a linear system with an interval time-varying delay. Then a delay-decomposition approach is employed to derive a sufficient condition such that the filtering error system is asymptotically stable with a prescribed H∞ disturbance attenuation level, where the non-fragility of filters, network-induced delays and data packet dropouts {{are taken into account}} simultaneously. Based on this condition, a networked non-fragile H ∞ <b>filter</b> with <b>additive</b> uncertainties can be designed by solving a set of linear matrix inequalities. A numerical example is given to demonstrate the effectiveness of the proposed design method...|$|R
