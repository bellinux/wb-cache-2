13|10000|Public
40|$|Just-in-Time {{manufacturing}} (<b>J.</b> <b>I.</b> <b>T.),</b> {{an essential}} component of the Japanese manufacturing model, is increasingly emulated by western corporations. While <b>J.</b> <b>I.</b> <b>T.</b> has received considerable conceptual and empirical attention, suitable management control systems, which are essential to successful implementation, have been sorely neglected. This study provides large-scale empirical evidence comparing management control systems as they relate to <b>J.</b> <b>I.</b> <b>T.</b> in the U. S. and Japan. © 1991 JIBS. Journal of International Business Studies (1991) 22, 603 – 617...|$|E
40|$|Contents: E-{{business}} conference opens {{minds and}} business avenues; CIRAS manual helps boost food processing industry in Iowa; CIRAS to manage Iowa 2 ̆ 7 s 2 ̆ 7 Industries of the Future 2 ̆ 7 program; Are <b>J.</b> <b>I.</b> <b>T.</b> order quanitties always your bust buy?; Engineering distance education gets new director; IPOC proactive effort targets small businesses[URL]...|$|E
40|$|Algebras that {{represent}} a generalization of both quantum groups, quantum supergroups and braided groups is defined. They are {{given by a}} pair of solutions of the Yang [...] Baxter equation that satisfy some additional conditions. Several examples are presented. PACS numbers: 02. 10. Tq, 02. 20 Hj Postal address: Brehov'a 7, 115 19 Prague 1, Czech Republic. E-mail: hlavaty@br. fjfi. cvut. cz 1 Quantized braided groups 2 1 Introduction [...] quantum groups and braided groups Matrix groups like GL(n); SO(n) e. t. c. were generalized in two ways recently. Both are based on deformation of the algebra of functions on the groups generated by coordinate functions T j i that commute T <b>j</b> <b>i</b> <b>T</b> l k = T l k T <b>j</b> <b>i,</b> <b>T</b> 1 T 2 = T 2 T 1 (1) In the quantum groups [1, 2] these commutation relations are modified by a matrix R = fR kl ij g so that the functions do not commute but satisfy the relations R 12 T 1 T 2 = T 2 T 1 R 12 (2) In this relation the elements of matrix R are numbers but the matrix T = fT j i [...] ...|$|E
5000|$|<b>J.</b> <b>I.</b> Packer, N. <b>T.</b> Wright, Anglican Evangelical Identity: Yesterday and Today (Latimer Trust, 2008) ...|$|R
5000|$|Schultz, <b>J.</b> C., Baldwin, <b>I.</b> <b>T.</b> (1982): Oak leaf quality {{declines in}} {{response}} to defoliation by Gypsy moth larvae. Science, 217, 149-151.|$|R
5000|$|R <b>J</b> Stephens, <b>I</b> <b>J</b> Beebe, <b>T</b> C Poulter Innervation of the vibrissae of the California sea lion, Zalophus californianus Anat Rec. 1973 Aug176 (4):421-41 4723405 ...|$|R
30|$|In {{order to}} {{tolerate}} the previously described attack, we define two threshold values: the M a x D e l a y T h r e s h o l d[*]and the M a x <b>J</b> <b>i</b> <b>t</b> t e r T h r e s o l d. When the RS- 3 TCAC (n) computes the jitter or the delay on the link between itself and its subordinate, it compares the obtained values to the threshold ones. If the obtained values are larger than the thresholds, we propose that RS- 3 TCAC (n) renews its entity and then increments the p r o b a b l y-m a l i c i o u s-R S[*]variable for it and its subordinate. When the[*]p r o b a b l y-m a l i c i o u s-R S[*]variable reaches a pre-configured threshold, the concerned 3 TCAC sends a p r o b a b l y-m a l i c i o u s-R S-A l e r t[*]signaling message which will be forwarded till the MR-BS. The values of M a x D e l a y T h r e s h o l d[*]and[*]M a x <b>J</b> <b>i</b> <b>t</b> t e r T h r e s o l d may be dynamically updated according to numerous {{factors such as the}} history of the feasible QoS on the links, the load conditions, etc.|$|E
40|$|This paper {{describes}} a generalization of the inverse of a non-singular matrix, as the unique solution {{of a certain}} set of equations. This generalized inverse exists for any (possibly rectangular) matrix whatsoever with complex elements <b>J.</b> <b>I</b> <b>t</b> is used here for solving linear matrix equations, and among other applications for finding an expression for the principal idempotent elements of a matrix. Also {{a new type of}} spectral decom-position is given. In another paper its application to substitutional equations and the value of hermitian idempotents will be discussed. Notation. Capital letters always denote matrices (not necessarily square) with com-plex elements. The conjugate transpose of the matrix A is written A*. Small letters are used for column vectors (with an asterisk for row vectors) and small Greek letters for complex numbers. The following properties of the conjugate transpose will be used: A* * = A, (A+B) * = A * + B*...|$|E
40|$|Given {{pairwise}} dissimilarities between N = |P | pixels in an image, and {{an integer}} p ≤ N, we compute the p-dimensional feature space as an Euclidean embedding of the input dissimilarities. Let D be the input N × N dissimilarity matrix, such that Dij = d (i, <b>j,</b> <b>I,</b> <b>T),</b> (A. 1) and F be the N × p output configuration matrix. A p-dimensional Euclidean embedding of between N points in an unknown input space, is a canonical configuration of N points in R p {{such that the}} Euclidean distance matrix of the points ideally equals D. Algorithms to discover such embeddings formulate the problem as optimizations and typically produce approximately Euclidean embeddings. Classical Multidimensional Scaling (cMDS) cMDS [5] is an algebraic approach to solving the embedding problem. cMDS implicitly minimizes the Frobenius norm ‖Kref − K‖F, where K = FFT is the kernel (Gram) matrix of the reported (approximate) configuration, and Kref is the Gram matrix of the ideal (exact) Euclidean embedding, when it exists. For approximate, p-dimensional embeddings, p < N...|$|E
30|$|When R (<b>i,</b> <b>j)</b> = <b>T,</b> {{it is easy}} {{to verify}} R*(i, j) = 0. So, the new {{function}} is continues at T.|$|R
40|$|C. Baikousssis, D. E. Blair[1] made a {{study of}} Legendre curves in contact metric manifolds. <b>J.</b> <b>I.</b> Inoguchi, <b>T.</b> Kumamoto, N. Ohsugi, and Y. Suyama[2] studied {{fundamental}} properties of Heisenberg 3 -spaces. M. Belkhelfa, I. E. Hirica, R. Rosca, L. Verstlraelen[3] obtained a com-plete characterization of surfaces with paralel second fundamental form in 3 -dimensional Bianchi-Cartan-Vranceanu spaces(BCV). In this paper, making use of method in paper of C. Baikousssis...|$|R
3000|$|... where <b>i,</b> <b>j,</b> and <b>t</b> index individuals, regions, and years, respectively, y is {{the labor}} market outcome of interest, X is a vector of individual-level characteristics, Z [...]...|$|R
40|$|Consider a Markov process X with finite lifetime. In this paper, we derive {{sufficient}} {{conditions for}} the existence of a Yaglom limit, or limiting conditional distribution for X. 1. Introduction The problem of Yaglom limits for Markov processes can be described as follows. Let X be a Markov process with locally compact metric state space E, X 0, and suppose that the lifetime i = inffs ? 0 : X s = 2 Eg is a. s. finite. We assume that X s+t = 2 E, t 0, which is a minimality requirement on X. Does there exist a probability measure on E such that lim t! 1 E (f(X t) <b>j</b> <b>i</b> ? <b>t)</b> = Z fd; f bounded. (1) Such a measure, if it exists, is variously known as a quasistationary distribution or limiting conditional distribution. In this paper, we use the same terminology as in (Kesten, 1995), and refer to as a Yaglom limit, in honour of A. M. Yaglom, who first showed the existence of such measures for branching processes (Yaglom, 1947). A first generalization of his results was achieved by [...] ...|$|E
40|$|BedRock Mining Support (Pty) Ltd is a fully {{integrated}} timber-based mine support company that supplies timber {{support to the}} gold and platinum mines. BedRock runs a <b>J.</b> <b>I.</b> <b>T</b> process and therefore has a challenge to consistently produce and provide quality products to the platinum mines. This {{is due to the}} fact that timber has a limited shelf life and timber extraction from plantations is rendered during the wet months. Currently a buffer has been implemented, but can only serve mines within its region, therefore mines that fall outside this region will struggle obtain timber during the wet months. A proposed centralised site located back in the chain is seen to be a solution to the current concerns and the bigger picture. A facilities plan needs to be generated for management purposes of understanding the size of the depot that is required and layout to use as a benchmark when a physical site is determined. Research was done to determine the best methodology to apply to the project problem. Systematic planning procedures became the viable option and were then used to develop a design. The design involved defining the project environment, using quantitative and qualitative measurements to determine the degree of closeness for each department relative to each other. These measurements were then used to produce various charts and diagrams that assisted in the development of alternative facility layouts known as block layouts. These block layouts were then evaluated by means of three integrated techniques to finally reveal the most feasible layout design that BedRock would use in their New Centralised Depot. The size of the depot was calculated to be 20262 square meters and block layout 2 was deemed the most feasible layout design. Thesis (B Eng. (Industrial and Systems Engineering)) [...] University of Pretoria, 2012...|$|E
40|$|Industrial {{technology}} has excelled profoundly {{in the past}} few decades, helping organisations throughout the world to be more efficient in all processes and keeping costs down. However, despite the abundance of several IT solutions, there exist many problems where more than one decision has to be made. Among the techniques supporting a multi-decisional context, simulations can undoubtedly play an important role as they provide what-if analysis and hence help to evaluate quantitative benefits. This thesis develops a simulation model for breakdown in an industrial machine, the main crusher in a cement factory. It also examines three important parameters (Drill Head, Dusting and Lubrication) of the crusher machine with the use of Bayesian network modelling which allows determination of suitable influencing factors in a precise and dynamic manner. The model also supports integration with management systems such as <b>J.</b> <b>I.</b> <b>T,</b> and MRPII. Witness simulation software has been used in this work to model the breakdown frequency of the Crusher machine and the associated parameters. The Bayesian Network Modelling is used to consider historical data and expert opinions; the Bayes’ approach takes into consideration off all existing parameters that affect the machine breakdown directly or indirectly. This tool is capable of establishing a probability based on the information gathered about the parameters. The simulation model is developed further to enable the Bayesian Network Modelling to be applied via the Chain Rule to calculate the probability of failure. The findings of this research show the approach developed in this work, where the Bayesian probability development process is integrated into the simulation model. This provides a unique and dynamic tool to aid decision making in understanding machine breakdowns. The resulting simulator is a decision making tool capable of analysing the status of the machine and the associated influencing factors. This uses an approach based on multiple performance measures and a user-defined set of inputs based on historical and expert opinion. This work provides a methodology to study the importance of key parameters of the crusher machine. This in effect highlights the correlation between the governing parameters and the occurrence of breakdown. ...|$|E
50|$|A {{model is}} time {{reversible}} if {{and only if}} it satisfies the property (the notation is explained below)or, equivalently, the detailed balance property,for every <b>i,</b> <b>j,</b> and <b>t.</b>|$|R
5000|$|Founded by Jerome I. Case in 1842 as the <b>J.</b> <b>I.</b> Case Threshing Machine Company, {{the company}} {{operated}} under that name {{for most of}} a century, until 1928. In some of its advertisements the name was styled <b>J.</b> <b>I.</b> Case <b>T.</b> M. Co. for short. Another business founded by Jerome <b>I.</b> Case, the <b>J.</b> <b>I.</b> Case Plow Works, was an independent business. When the Plow Works was bought by Massey-Harris in 1928, the latter sold the name rights to the <b>J.</b> <b>I.</b> Case Threshing Machine Company, which reincorporated as the <b>J.</b> <b>I.</b> Case Company. That company, which became majority-owned by Tenneco in 1967 and a wholly owned subsidiary in 1970, was often called by the simple brand name Case.|$|R
40|$|I n {{this paper}} the {{application}} of observers to monitoring, failure detection and fault diagnosis in aircraji <b>j</b> <b>i</b> gh <b>t</b> control systems is discussed in detail. New results concerning the design of parameter-insensitive observers are presented. The feasibility of real-time implementation of a monitoring and failure detection and diagnosis scheme on multiple transputers is investigated and it is shown that the real-time performance specijications can be met and that the method {{could be used in}} practice. ...|$|R
40|$|This paper {{estimates}} adult equivalence scalcs in {{the context}} of a nonlinear demand system using cross-section individual household data. It then evaluates the treatment of children under the tax allowance and child benefit systems on the basis of the estimated equivalence scales. The results suggest that a child benefit system allowing for economies of scale in the family is consistent with the cost of children implied by the notion of adult equivalence scale. For any tax and benefit system to be considered equitable it must allow for dissimilar treatment of unequals or similar treatment of equals. Households are unequal not only in terms of their income level, but also in terms of their size and composition. For example, families with children that have the same income as childless families are likely to have lower standards of living because of the financial burden of raising children. Therefore, an equitable tax and benefit system should equivalize the well-being of families with alternative size and composition in the assessment of net income taxes. Most countries attempt to equivalize the well-being of families with different size and composition through child welfare programs. Such programs usually provide assistance to families with children either in the form of a tax allowance, a reduction in the tax liability of the household, or a child b ~ w <b>j</b> <b>i</b> <b>t,</b> a payment to the person who looks after the child. The child welfare programs in developed countries are often based on a child benefit and payments may vary with the number and age of children. In the U. K., for example, the child welfare system was originally based on tax allowance, but since 1977 has changed to one based on child benefit. This cha~lge was implemented mainly because the tax allowance system is regressive since households benefit in proportion to their marginal income tax rate. Under the tax allowance system, families with low income will not receive any financial assistance for their children because they pay no taxes. The cost of children can be measured with the concept of (udult) rquivulrnce scale, generally defined as the cost of reaching a given level of utility under differen...|$|E
40|$|Antigen {{presentation}} by host dendritic cells (DC) {{is critical for}} the initiation of adaptive immune responses. We have previously demonstrated in immunogenic murine tumor models that bone marrow (BM) - derived DC pulsed ex vivo with synthetic tumor-associated peptides, naturally expressed by tumor cells, serve as effective antitumor vaccines, protecting animals against an otherwise lethal tumor challenge (Mayordomo, <b>J.</b> <b>I.,</b> <b>T.</b> Zorina, W. J. Storkus, C. Celluzzi, L. D. Falo, C. J. Melief, T. Ildstad, W. M. Kast, A. B. DeLeo, and M. T. Lotze. 1995. Nature Med. 1 : 1297 - 1302). However, T cell-defined epitopes have not been identified for most human cancers. To explore the utility of this approach {{in the treatment of}} tumors expressing as yet uncharacterized epitopes, syngeneic granulocyte/macrophage colony- stimulating factor-stimulated and BM-derived DC, pulsed with unfractionated acid-eluted tumor peptides (Storkus, W. J., H. J. Zeh III, R. D. Salter, and M. T. Lotze. 1993. J. Immunother. 14 : 94 - 103) were used to treat mice bearing spontaneous, established tumors. The adoptive transfer of 5 x 10 (5) tumor peptide-pulsed DC dramatically suppressed the growth of weakly immunogenic tumors in day 4 to day 8 established MCA 205 (H- 2 b) and TS/A (H- 2 d) tumor models, when applied in three biweekly intravenous injections. Using the immunogenic C 3 (H- 2 b) tumor model in B 6 mice, tumor peptide-pulsed DC therapy resulted in the erradication of established d 14 tumors and long-term survival in 100 % of treated animals. The DC-driven antitumor immune response was primarily cell mediated since the transfer of spleen cells, but not sera, from immunized mice efficiently protected sublethally irradiated naive mice against a subsequent tumor challenge. Furthermore, depletion of either CD 4 + or CD 8 + T cells from tumor-bearing mice before therapy totally suppressed the therapeutic efficacy of DC pulsed with tumor- derived peptides. Costimulation of the host cell-mediated antitumor immunity was critical since inoculation of the chimeric fusion protein CTLA 4 -Ig virtually abrogated the therapeutic effects of peptide-pulsed DC in vivo. The analysis of the cytokine pattern in the draining lymph nodes and spleens of tumor-bearing mice immunized with DC pulsed with tumor-eluted peptides revealed a marked upregulation of interleukin (IL) 4 and interferon (IFN) gamma production, as compared with mice immunized with DC alone or DC pulsed with irrelevant peptides. DC- induced antitumor effects were completely blocked by coadministration of neutralizing monoclonal antibody directed against T helper cell 1 - associated cytokines (such as IL- 12, tumor necrosis factor alpha, IFN- gamma), and eventually, but not initially, blocked by anti-mIL- 4 mAb. Based on these results, we believe that DC pulsed with acid-eluted peptides derived from autologous tumors represents a novel approach to the treatment of established, weakly immunogenic tumors, and serves as a basis for designing clinical trials in cancer patients...|$|E
40|$|Deposited with {{permission}} of the author. © 2002 Heng, <b>J.</b> <b>I.</b> <b>T.</b> The mammalian cerebral cortex is a remarkable product of brain evolution, and is the structure that most distinctively delineates the human species from others (Northcutt and Kaas, 1995; Rakic, 1988). Neurons in the adult brain are organised into cytoarchitectonic areas, defined by distinct biochemical, morphological and physiological characteristics (Rakic 1988). Remarkably, this complex structure is generated from a simple neuroepithelium. What are the signalling mechanisms that direct neuron formation and subsequent functional-parcellation of the cerebral cortex? Key {{to the study of}} this process is an understanding of neuronal fate determination. Available evidence demonstrates an intrinsic programming potential by neuronal progenitors within subdomains of the developing cerebral cortex that is instructive for proper corticogenesis. These regional domains are demarcated by expression of certain transcription factors, including members of the Helix-Loop-Helix (HLH) family of proteins. The HLH family of transcription factors are key contributors to a wide array of developmental processes, including neurogenesis and haematopoiesis. These factors are thought to exert their regulatory influences by binding to cognate promoter-DNA sequences as dimers. While studies in mice have convincingly demonstrated that neurogenic HLH proteins such as NeuroD (Lee et al., 1995; Miyata et al., 1999; Liu et al., 2000) and Mash 1 (Casarosa et al., 1999) are intimately involved in neuronal fate determination and terminal differentiation, the role of the ubiquitously expressed HLH protein, E 12, in mammalian neurogenesis remains ambiguous. Originally discovered as an important regulator of lymphopoiesis, expression studies revealed its widespread expression in proliferative zones of multiple nascent organs of the embryo, including the developing cerebral cortex; implying a role for E 12 in development of the nervous system. Since the function of E 12 is, in part, coded by its capacity for protein dimerisation, a search was undertaken for binding partners in developing mouse brain, and using a yeast 2 -hybrid assay. Yeast 2 -hybrid prey libraries were constructed using complementary DNA (cDNA) isolated from embryonic mouse forebrain tissue at early (embryonic day e 11. 5) and peak (e 15. 5) stages of neurogenesis. Screening of these libraries for binding partners to an E 12 bait resulted in cloning of HLH factors, such as Mash 1, NSCL and Id 2. Importantly, a novel binding partner, named GRIPE, was cloned as a novel GAP Related Interacting Protein to E 12. GRIPE binds to the HLH region of E 12, and may require E 12 for nuclear import. Furthermore, GRIPE may negatively regulate E 12 -dependent target gene transcription. High levels of GRIPE and E 12 mRNA were coincidently detected during embryogenesis, but only GRIPE mRNA levels remained high in adult brain, particularly in neurons of the cortex and hippocampus. These observations were reconfirmed through an in vitro model of neurogenesis. Taken together, these results indicate that GRIPE is a novel protein whose dimerisation with E 12 has important consequences for cells undergoing neuronal differentiation. A model is proposed to suggest how neurogenic HLH proteins that dimerise to E 12 may promote signalling cascades driving early neuroblast differentiation. Open Acces...|$|E
5000|$|Carlsson J, von Wagenheim B, Linder R, Anwari TM, Qvist <b>J,</b> Petersson <b>I,</b> Magounakis <b>T,</b> Lagerqvist B. <b>Is</b> late stent {{thrombosis}} in {{drug-eluting stents}} a real clinical issue? : A single-center experience and {{review of the}} literature.Clin Res Cardiol 2007 Feb; 96(2):86-93.|$|R
5000|$|Industrial {{monitoring}} of hydrocyclone operation using electrical resistance tomography, R.A. Williams, X. Jia, R.M. West, M. Wang, J.C. Cullivan, <b>J.</b> Bond, <b>I.</b> Faulks, <b>T.</b> Dyakowski, S.J. Wang, N. Climpson, J.A. Kostuch and D. Payton, Minerals Engineering, 12, 10 (1999), pp. 1245-1252, [...]|$|R
3000|$|... 1. Demoule A, Carreira S, Lavault S, Pallanca O, Morawiec E, Mayaux <b>J,</b> Arnulf <b>I,</b> Similowski <b>T</b> (2016) Impact of earplugs and eye mask on {{sleep in}} {{critically}} ill patients: a prospective randomized polysomnographic study. Annals of Intensive Care 6 (Suppl 1): S 9 [...]...|$|R
40|$|This thesis looks {{directly}} into the controversial subject of the microwave field effect by {{the production of a}} versatile prototype isothermal microwave reactor for the investigation of enzymatic and microbiological reactions. The observed results from the prototype reactor and experiments conducted conclude that there is a nonthermal, nonlinear response between the exposure microwave power and rate and yield of cellulose saccharification. The nature of the nonthermal response is controversial and may be dependent on the definition of "nonthermal,' leading to ambiguity of exact mechanism. Enzymatic and microbial conversion of cellulosic material to ethanol is a highly desirable industrial process. Whether the demand is for the mitigation of climate change, political obligations or energy independence, the use of arable land for energy crops limits the available glucose carbon sources for conversion to bioproducts. To prevent this limitation, cellulose (~-l, 4 -linked glucose polymers) are touted as the "silver bullet" to prevent carbon exhaustion or impinging on food crops. The technical constraint for the industrialization of cellulose based processing is the rate limitation in the cellulase enzymatic action on cellulose. The enzyme rate is limited by feedback cycles and limited mechanical freedom, therefore a relatively high enzyme concentration is required to speed up the process. To date, the associated enzyme production costs and infrastructure prevents bulk volume exploitation. Biomolecular advances (amino acid substitutions, recombination of expression vectors etc) have gone some way to increase either enzymatic rate or enzyme concentration. The work presented in this thesis differs by increasing the rate of the enzyme without molecular modification. Using a microwave field, the work presented shows that by separating the system into its base units, irradiation of the enzyme/substrate complex in an aqueous environment can increase both the initial enzyme rate and the saccharification yield without alteration of the temperature set point. This study shows that the rate increase is not proportional to the microwave field power. An optimal power in each study is either found or suggested. The results cited show that in the three systems (Endoglucanase and cellobiohydrolase with cellulose, endoglucanase and cellobiohydrolase and ~- glucosidase with cellulose, and ~-glucosidase with cellobiose) the initial rates can be increased by 201 %, 65. 5 % and 69 % respectively. In the total hydrolytic process (endoglucanase and cellobiohydrolase and ~-glucosidase on a cellulose substrate) the final glucose yield was increased by 43 % in comparison to the conventional thermal control reaction. This is shown in Figure 1. 10. 000 1 9. 000 1 8. 000 j 7. 000 6. 000 o 20 40 60 80 100 120 140 160 180 I I 1 I U 5. 000 r:: o u 4. 000 3. 000 2. 000 <b>j</b> <b>i</b> <b>t</b> t, f 1. 000 0. 000 Time (hours) =->=OOOW Glucose' ? 012 W Glucose ?p 025 W Glucose ~ 050 W Glucose ? 075 W Glucose Figure 1. Microwave irradiated "cellulase" enzymes with cellulose substrate I For development into an industrial system and looking towards simultaneous saccharification and fermentation (SSF), the yeast Saccharomyces cerevisiae was subjected to irradiated microwave fermentations on a glucose substrate. Although inconclusive in terms of rate increase, cell density 1 was comparable across the power range showing that the irradiation does not have a derogatory effect. ! The natural evolution of the conclusions drawn would be development of the system into a SSF or SSCF configuration for bio-product formation is possible with irradiation up to SOW. ii The novelty of the experiments conducted is twofold. Firstly, the reactor has been designed to ensure that the microwave irradiation is independent of the bulk temperature therefore allowing the exploration of the microwave field effect independently to the thermal effect. Secondly, the microwave source is a continuous microwave irradiation (none pulse irradiation) ensuring that the reaction is subjected to the microwave field for the entire reaction...|$|E
30|$|Baelani I, Jochberger S, Laimer T, Otieno D, Kabutu <b>J,</b> Wilson <b>I,</b> Baker <b>T,</b> Dünser MW. Availability of {{critical}} care resources to treat patients with severe sepsis or septic shock in Africa: a self-reported, continent-wide survey of anaesthesia providers. Crit Care. 2011; 15 (1):R 10.|$|R
25|$|Evangelical {{scholars}} and various public figures critical of inclusive-language translations include John F. MacArthur, <b>J.</b> <b>I.</b> Packer, Jack <b>T.</b> Chick, Gail Riplinger, James Dobson, Jerry Falwell, Texe Marrs, Wayne Grudem, Peter Ruckman, D. James Kennedy, Josh McDowell, R. Albert Mohler, Jr., John Piper, Pat Robertson, R.C. Sproul, and Joni Eareckson Tada.|$|R
40|$|We {{study the}} {{situation}} where a set of n jobs with release dates and equal processing times have to be scheduled on m identical parallel machines. We show that, if the objective function can be expressed as the sum of n functions f i of the completion time C i of each job <b>J</b> <b>i,</b> the problem can be solved in polynomial time for any xed value of m. The only restriction is that functions f {{i have to be}} non-decreasing and that for any pair of jobs (J i; J j), the function f <b>i</b> f <b>j</b> has to be monotonous. This assumption holds for several standard scheduling objectives, such as the weighted sum of completion times or the total tardiness. Hence, the problems (Pmjp i = p; r <b>i</b> <b>j</b> P w <b>i</b> C i) and (Pmjp i = p; r <b>i</b> <b>j</b> P <b>T</b> <b>i)</b> are polynomially solvable...|$|R
40|$|We {{will give}} a short {{introduction}} to foreground/background estimation and Hidden Markov for tracking. More information about the topics {{can be found in}} the papers listed at the end. 1 Foreground estimation The objective is to extract the foreground and consequently also the background from a sequence of images. Problems facing us includes for example • long execution time, • slowly varying lighting conditions, • rapidly varying lighting conditions, and • what should be considered background. The image sequence may come from a video camera with 352 × 288 resolution color images running 20 frames per second. Let It: R 2 → R 3, t = 0, [...] . n− 1 be a sequence of n color images. We use the notation It = (<b>I</b> 1 <b>t,</b> <b>I</b> 2 <b>t,</b> <b>I</b> 3 <b>t)</b> to denote the different color channels when needed. In order to compute a feature at each location we can use convolution f j t (x, y) = Ij t ∗ h(x, y) = <b>I</b> <b>j</b> <b>t</b> (x − a, y − b) h(a, b) dadb, where h: R 2 → R is the filter mask. This gives a filter response at every point (x, y) ∈ R 2 and the statistical properties of these can be used to classify background and foreground. 1. 1 Pixel based foreground estimation The Stauffer–Grimson [15] estimator is obtained by letting h = δ 0, 0 be the Dirac measure at the origin in which case <b>I</b> <b>j</b> <b>t</b> ∗ δ 0, 0 = <b>I</b> <b>j</b> <b>t,</b> <b>i.</b> e. that is the estimator is based on the individual pixel data. A simple solution would be to define a probability function at each point (x, y) ∈ R. Note that for digital images there are only a finite set of points in the definition set giving a finite set of probability functions. Thus, for a gray level image we will need to define probability functions px,y(a) like for example px,y(a) = 1 √...|$|R
40|$|The f-cost {{of a tree}} {{decomposition}} (fX <b>i</b> <b>j</b> <b>i</b> 2 Ig; <b>T</b> = (I; F)) for {{a function}} f : N ! R is defined as f(jX <b>i</b> <b>j).</b> This measure associates with the running time or memory use of some algorithms that use the tree decomposition. In this paper we investigate the problem to find tree decompositions of minimum f-cost. A functio...|$|R
50|$|Glasgow Caledonians: R Shepherd; A Bulloch, <b>J</b> Stewart, <b>I</b> Jardine, <b>T</b> Hayes; B Irving, F Stott; D Hilton, G Bulloch, G McIlwham, S Campbell, D Burns, J White, M Waite, G Simpson. Subs: G Scott for Waite 34mins, G Beveridge for Stott 66, A Watt for Hilton, 72.|$|R
40|$|For an [n, k, d] 3 code C with gcd(d, 3) = 1, {{we define}} a map wG from Σ = PG(k − 1, 3) {{to the set}} of weights of codewords of C through a {{generator}} matrix G. A t-flat Π in Σ is called an (<b>i,</b> <b>j)</b> <b>t</b> flat if (<b>i,</b> <b>j)</b> = (|Π ∩ F 0 |, |Π ∩ F 1 |), where F 0 = {P ∈ Σ | wG(P) ≡ 0 (mod 3) }, F 1 = {P ∈ Σ | wG(P) ̸ ≡ 0, d (mod 3) }. We give geometric characterizations of (<b>i,</b> <b>j)</b> <b>t</b> flats, which involve quadrics. As an application to the optimal linear codes problem, we prove the non-existence of a [305, 6, 202] 3 code, which is a new result. ...|$|R
40|$|C. Baikousssis, D. E. Blair[1] made a {{study of}} Legendre curves in contact metric manifolds. <b>J.</b> <b>I.</b> Inoguchi, <b>T.</b> Kumamoto, N. Ohsugi, and Y. Suyama[2] studied {{fundamental}} properties of Heisenberg 3 -spaces. M. Belkhelfa, I. E. Hirica, R. Rosca, L. Verstlraelen[6] obtained a complete characterization of surfaces with paralel second fundamental form in 3 -dimensional Bianchi-Cartan-Vranceanu spaces(BCV). In this study, we define the canal surface around Legendre curve with Frenet frame in BCV spaces. Afterwards we investigate tubular surface around Legendre curve curve with Frenet frame. Finally we give some characterizations about special curves lying on tubular surface around Legendre curve...|$|R
40|$|De Buck S., Van Cleynenbreugel <b>J.,</b> Geys <b>I.,</b> Koninckx <b>T.,</b> Koninck P. R., Suetens P., ''A {{system to}} support laparoscopic surgery by {{augmented}} reality visualization'', Lecture notes in computer science, vol. 2208, pp. 691 - 698, 2001 (Proceedings 4 th {{international conference on}} medical image computing and computer-assisted intervention - MICCAI 2001, October 14 - 17, 2001, Utrecht, The Netherlands). status: publishe...|$|R
40|$|Statement of {{responsibility}} on title-page reads: editor: M. J. Driscoll; contributors: D. C. Aldrich, M. J. Driscoll, O. K. Kadiroglu, S. Keyvan, H. U. R. Khan, D. D. Lanning, R. Morton, J. Pasztor, T. J. Reckart, A. A. Salehi, <b>J.</b> <b>I.</b> Shin, A. <b>T.</b> Supple, D. J. Wargo, and S. S. WuIncludes bibliographical referencesProgress report; September 30, 1976 U. S. Atomic Energy Commission contracts: E(11 - 1) 225...|$|R
40|$|FIGURES 6 A – F. Comparison of male genitalia, left palp. G – J. Comparison of male RTA. A – C, G, H. Tengella perfuga; D – F, <b>I,</b> <b>J.</b> <b>T.</b> radiata; A, D. Prolateral view; B, E, G, I. Ventral view; C, F, H, J. Retrolateral view. Con—conductor, Em—embolus, MA—median apophysis, RTA—retrolateral tibial apophysis, Sp—spines and spine attachments...|$|R
