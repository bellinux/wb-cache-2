20|335|Public
40|$|We {{describe}} a general technique to construct data structures for similarity search in semialgebraic pattern spaces. These spaces capture most known combinations of geometric patterns (e. g., point sets, polygons, polygonal curves) and geometric distance measures for them (e. g. Hausdorff-distance, area of overlap, Fréchet-distance) {{together with their}} quotients under various transformation classes (e. <b>g.,</b> <b>translations,</b> rigid motions) and they provide the first non-trivial exact search structures in these settings...|$|E
40|$|Dedicated to {{the memory}} of H. H. Schaefer Abstract. We {{investigate}} R-bounded representations Ψ: L 1 (G) →L(X), where X is a Banach space and G is a lca group. Observing that Ψ induces a (strongly continuous) group homomorphism U: G →L(X), we are then able to analyze certain classical homomorphisms U (e. <b>g.</b> <b>translations</b> in L p (G)) from the viewpoint of R-boundedness and the theory of scalar-type spectral operators...|$|E
40|$|We are all {{familiar}} with frameworks of rods attached at joints. A rod and joint framework {{gives rise to}} a simple mathematical model consisting of line segments in Euclidean 3 -space with common endpoints. A deformation is a continuous one-parameter family of such frameworks. If a framework has only trivial deformations, e. <b>g.</b> <b>translations</b> and rotations, then it is said to be rigid. Before giving a more precise mathematical formulation, we can use simple geometry to explore these ideas...|$|E
40|$|This study {{focuses on}} {{strategies}} and statistical considerations for assessment of translation in language (e. <b>g.</b> <b>translation</b> of case report forms in multinational clinical trials), information (e. <b>g.</b> <b>translation</b> of basic discoveries to the clinic) and technology (e. <b>g.</b> <b>translation</b> of Chinese diagnostic techniques to well-established clinical study endpoints) in pharmaceutical/clinical research and development. However, {{most of our}} efforts will be directed to statistical considerations for translation in information. Translational medicine {{has been defined as}} bench-to-bedside research, where a basic laboratory discovery becomes applicable to the diagnosis, treatment or prevention of a specific disease, and is brought forth by either a physician—scientist who works at the interface between the research laboratory and patient care, or by a team of basic and clinical science investigators. Statistics {{plays an important role in}} translational medicine to ensure that the translational process is accurate and reliable with certain statistical assurance. Statistical inference for the applicability of an animal model to a human model is also discussed. Strategies for selection of clinical study endpoints (e. g. absolute changes, relative changes, or responder-defined, based on either absolute or relative change) are reviewed...|$|R
25|$|H. <b>G.</b> Evelyn-White's <b>translation,</b> {{published}} 1914, {{is used on}} the Perseus Project.|$|R
50|$|Figure 2 {{illustrates}} the aligned result using PairWise. Using the same DNA and protein sequence, {{and with the}} penalties modified as below. The arrow is pointing to the position where frameshifting took place. At that nucleotide (<b>G),</b> <b>translation</b> frame was shifted from frame one to frame two (dotted line). This change resulted a much better alignment which has a score of 9.|$|R
40|$|We {{present in}} this paper an {{algorithm}} inspired by the human visual system to reconstruct images from irregularly placed samples. This algorithm is based on linear spline approximations with control points on a hexagonal grid. Several spline approximations are computed for different transformations of the control point grid (e. <b>g.</b> <b>translations</b> and rotations). These approximations are then merged together after compensation of the transformations, yielding a high-quality invariant image reconstruction. Evaluations show {{that the use of}} hexagonal grids and of the “invariance by integration ” principle improves reconstruction quality. ...|$|E
40|$|International audienceThe Text Alignment Network (TAN) is a {{suite of}} XML {{encoding}} formats intended to serve anyone who wishes to encode, exchange, and study multiple versions of texts (e. <b>g.,</b> <b>translations,</b> paraphrases), and annotations on those texts (e. g., quotations, word-for-word correspondences). This article focuses on TAN’s innovative intertextual pointers, which, I argue, provide an unprecedented level of readability, interoperability, and semantic context. Because TAN is a new, experimental format, this article provides a brief introduction to the format and concludes with comments on progress and future prospects...|$|E
40|$|A popular {{framework}} for the interpretation of image sequences is the layers or sprite model of e. g. Wang and Adelson (1994), Irani et al. (1994). Jojic and Frey (2001) provide a generative probabilistic model {{framework for}} this task, but their algorithm is slow as it needs to search over discretized transformations (e. <b>g.</b> <b>translations,</b> or affines) for each layer. In this paper we show that by using invariant features (e. g. Lowe’s SIFT features) and clustering their motions we can reduce or eliminate the search and thus learn the sprites much faster. We demonstrate our algorithm on two image sequences. ...|$|E
2500|$|A {{complete}} English {{translation of}} the work, free for non-commercial use, Edward <b>G.</b> Seidensticker's <b>translation.</b>|$|R
5000|$|... 2003. Trimble, Robert <b>G.</b> A <b>Translation</b> of José Zorrilla’s Don Juan Tenorio. Lewiston, NY: Edwin Mellen Press.|$|R
3000|$|From now on, we {{suppose that}} f is {{translation}} compact. Together {{with the fact}} that <b>g</b> is <b>translation</b> compact in [...]...|$|R
40|$|Automatically {{produced}} texts (e. <b>g.</b> <b>translations</b> or summaries) {{are usually}} evaluated with n-gram based {{measures such as}} BLEU or ROUGE, while the wide set of more sophisticated measures that have been proposed {{in the last years}} remains largely ignored for practical purposes. In this paper we first present an indepth analysis {{of the state of the}} art in order to clarify this issue. After this, we formalize and verify empirically a set of properties that every text evaluation measure based on similarity to human-produced references satisfies. These properties imply that corroborating system improvements with additional measures always increases the overall reliability of the evaluation process. In addition, the greater the heterogeneity of the measures (which is measurable) the higher their combined reliability. These results support the use of heterogeneous measures in order to consolidate text evaluation results. ...|$|E
40|$|Abstract. We {{describe}} {{design and}} implementation of the linguistic query language DDDquery. This language aims at querying a large linguistic database storing a corpus of richly annotated historic German texts. We use a graph-based data model that supports multiple independent annotation layers on a shared text layer as well as alignments of text layers representing the same text or related texts (e. <b>g.,</b> <b>translations).</b> The corpus is stored in an object-relational database system with a text retrieval extension. DDDquery is based on XPath to leverage the familiarity of many users with this language. It is translated to SQL in a two phase compilation with first order logic as an intermediate language. This approach effectively decouples the query language from the schema of the underlying corpus. We provide an overview of DDDquery, the underlying ODAG data model, its implementation as relational schema, the predicates of the intermediate language, and describe both phases of the translation process. ...|$|E
40|$|Abstract. A popular {{framework}} for the interpretation of image sequences is the layers or sprite model, see e. g. [1], [2]. Jojic and Frey [3] provide a generative probabilistic model {{framework for}} this task, but their algorithm is slow as it needs to search over discretized transformations (e. <b>g.</b> <b>translations,</b> or affines) for each layer simultaneously. Exact computation with this model scales exponentially {{with the number of}} objects, so Jojic and Frey used an approximate variational algorithm to speed up inference. Williams and Titsias [4] proposed an alternative sequential algorithm for the extraction of objects one at a time using a robust statistical method, thus avoiding the combinatorial explosion. In this chapter we elaborate on our sequential algorithm in the following ways: Firstly, we describe a method to speed up the computation of the transformations based on approximate tracking of the multiple objects in the scene. Secondly, for sequences where the motion of an object is large so that different views (or aspects) of the object are visible at different times in the sequence, we learn appearance models of the different aspects. We demonstrate our method on four video sequences, including a sequence where we learn articulated parts of a human body. ...|$|E
5000|$|Russian: <b>G.</b> Sablukov, <b>Translation</b> of 15 Theodore Abu Qurrah's Greek Works about islam, Missioner 6 (1879), and Dialogue with a Muslim ...|$|R
2500|$|... {{bound with}} W. <b>G.</b> Waddell's <b>translation</b> of Manetho's History of Egypt (1940). Cambridge, Mass.: Harvard University Press; London: W. Heinemann. Internet Archive, {{retrieved}} 16 November 2011.|$|R
40|$|The book {{is one of}} the Routledge Applied Linguistics Series {{which are}} {{designed}} to guide a number of key areas (e. <b>g.</b> <b>translation,</b> second language acquisition and intercultural communication) in the field of applied linguistics. In keeping with other books in this (c) series, John this book Benjamins follows the ‘introduction-extensionexploration’ template, Delivered which explains key by terms Ingenta and concepts (‘introduction’), introduces and on: comments Wed, on 27 selected Dec core 2006 readings 07 : 55 : 52 (‘extension’), and puts theory into practice in student-oriented to: Guest cas...|$|R
40|$|We {{propose a}} novel method to {{accurately}} reconstruct {{a set of}} images representing a single scene from few linear multi-view measurements. Each observed image is modeled as the sum of a background image and a foreground one. The background image is common to all observed images but undergoes geometric transformations, as the scene is observed from different viewpoints. In this paper, we assume that these geometric transformations are represented by a few parameters, e. <b>g.,</b> <b>translations,</b> rotations, affine transformations, etc [...] The foreground images differ from one observed image to another, and are used to model possible occlusions of the scene. The proposed reconstruction algorithm estimates jointly the images and the transformation parameters from the available multi-view measurements. The ideal solution of this multi-view imaging problem minimizes a non-convex functional, and the reconstruction technique is an alternating descent method built to minimize this functional. The convergence of the proposed algorithm is studied, and conditions under which the sequence of estimated images and parameters converges to a critical point of the non-convex functional are provided. Finally, {{the efficiency of the}} algorithm is demonstrated using numerical simulations for applications such as compressed sensing or super-resolution. Comment: Accepted in SIAM Journal on Imaging Science...|$|E
40|$|Institute for Adaptive and Neural ComputationThis thesis {{explores the}} use of {{invariant}} features for learning sprites from image sequences, and for recognising object categories in images. A popular framework for the interpretation of image sequences is the layers or sprite model of e. g. Wang and Adelson (1994), Irani et al. (1994). Jojic and Frey (2001) provide a generative probabilistic model framework for this task, but their algorithm is slow as it needs to search over discretised transformations (e. <b>g.</b> <b>translations,</b> or affines) for each layer. We show that by using invariant features (e. g. Lowe’s SIFT features) and clustering their motions we can reduce or eliminate the search and thus learn the sprites much faster. The algorithm is demonstrated on example image sequences. We introduce the Generative Template of Features (GTF), a parts-based model for visual object category detection. The GTF consists {{of a number of}} parts, and for each part there is a corresponding spatial location distribution and a distribution over ‘visual words’ (clusters of invariant features). We evaluate the performance of the GTF model for object localisation as compared to other techniques, and show that such a relatively simple model can give state-of- the-art performance. We also discuss the connection of the GTF to Hough-transform-like methods for object localisation...|$|E
40|$|Names are {{studied in}} {{different}} ﬁelds, and, among the issues they present,name variations (e. <b>g.,</b> <b>translations,</b> misspellings, etc [...] .) and name variants (e. g., pseudonyms) pose {{a challenge to}} name matching, i. e., discovering instances that diﬀer typographically but represent the same entity. Our scenario for name matching is a P 2 P, entity-based network of users divided in local level (the users), community level (groups of users), and global level(all the entities). Entities at local level are a partial view of the real word entity, represented at the global level. In this framework, name variations and name variants change the orthography of names because of linguistic and social factors, and their presence depends on the scenario level considered. Thus, they are hard to tackle by an automatic approach such as name matching. Our proposed solutions {{is to use a}} taxonomy we created to understand and predict the variations and variants of different entity names, and divide the entity name in different entries to accommodate the original name plus variations and variants. Our approach is novel because we take advantage of a multidisciplinary method, drawing from various ﬁelds (i. e., philosophy, sociology and geography) importing terms and views not found in computer science. We also draw from areas close to name matching, building from their ﬁndings and expanding them...|$|E
2500|$|Ian <b>G.</b> Kidd, The <b>Translation</b> of the Fragments, vol. III, 1999.|$|R
30|$|Without loss of generality, we {{may assume}} that <b>G</b> {{contains}} no <b>translations.</b>|$|R
40|$|Interimage {{matching}} is {{the process}} of determining the geometric transformation required to conform spatially one image to another. In principle, the parameters of that transformation are varied until some measure of some difference between the two images is minimized or some measure of sameness (e. g., cross-correlation) is maximized. The number of such parameters to vary is faily large (six for merely an affine transformation), and it is customary to attempt an a priori transformation reducing the complexity of the residual transformation or subdivide the image into small enough match zones (control points or patches) that a simple transformation (e. <b>g.,</b> pure <b>translation)</b> is applicable, yet large enough to facilitate matching. In the latter case, a complex mapping function is fit to the results (e. <b>g.,</b> <b>translation</b> offsets) in all the patches. The methods reviewed have all chosen {{one or both of the}} above options, ranging from a priori along-line correction for line-dependent effects (the high-frequency correction) to a full sensor-to-geobase transformation with subsequent subdivision into a grid of match points...|$|R
40|$|Shoeprints are {{routinely}} left at crime scenes and {{are reported to}} be present more frequently than fingerprints. It {{has been reported that}} 35 percent of crime scenes present shoe marks that can be recovered and used as forensic evidence. During investigations, a scene of crime shoeprint can be matched against a database of known shoeprints in order to identify the brand and the model of the corresponding shoe. TIlls is known as shoeprint classification and is, currently, performed manually or using some semi-automatic systems. These current approaches are time consuming and are not very reliable. Thus, the development of automatic shoeprint classification methods would offer valuable assistance to forensic scientists. TIlls thesis addresses the task of automatic shoeprint classification and its related challenges. This includes the problem of classifying partial, noisy and/or blurred shoeprint images. The issues of invariance to geometric distortions, e. <b>g.</b> <b>translations</b> and rotations, as well as rapid classification are also considered. The thesis proposes a number of different ideas and methods for the automatic classification of distorted shoeprint images including the use of Fourier-Mellin transform, modified phase-only correlation and two-dimensional advanced correlation filters. It also investigates the use of multiple one-dimensional correlation filters and classifier combination techniques, such as algebraic rules, Decision Templates and Support Vector Machine based combiners. The experimental results suggest that the investigated correlation-based methods can offer high accuracies when classifying low quality shoeprint images while providing tolerance to geometric distortions. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|Guiding visions' play an {{important}} role in the transition management approach as a central means of mobilizing social actors and the co-ordination of dispersed agency. 'Energy regions' in Austria are an interesting example for the strategic promotion of such guiding visions in the context of regional development. We describe the case of Murau, an alpine district in which a strong actor network has been built around a vision of systematically exploiting renewable energy sources and at the same time saving the region from economic decay. The vision gained much authority and has been institutionalised at various levels of regional governance. It furthermore was supported by and played {{an important}} role for regime level attempts to influence socio-technical change. Development and social propagation of such visions are inherently political and contested processes involving much strategizing and anticipation of conflict. We describe particular discursive strategies applied in niches - such as the combination and translation of sentiments into localised visions and demonstrations of feasibility. These strategies can be understood as systematic attempts to support discursive shifts at regime level by means of local activities, and aim to modify rather durable power structures. We suggest ways to analyse such discursive practices in order to orient strategic action in the course of such processes: analysing 'guiding visions' and their interference with other emerging trends; extending analyses across spatial scales (e. <b>g.</b> <b>translations)</b> and across thematic fields (e. g. convergence of agendas); and focusing on processes of stabilisation, institutionalisation and mutually reinforcing developments. Guiding visions Transition management Multi-level framework Regional governance Energy systems...|$|E
40|$|Question-Answering (QA) is an {{important}} research area, which is concerned with developing an automated process that answers questions posed by humans in a natural language. QA is a shared task for the Information Retrieval (IR), Information Extraction (IE), and Natural Language Processing communities (NLP). A technical review of different QA system models and methodologies reveals that a typical QA system consists of different components to accept a natural language question from a user and deliver its answer(s) back to the user. Existing systems have been usually aimed at structured/ unstructured data collected from everyday English text, i. e. text collected from television programmes, news wires, conversations, novels and other similar genres. Despite all up-to-date research in the subject area, a notable fact {{is that none of}} the existing QA Systems has been tested on a Parallel Corpus of religious text with the aim of question answering. Religious text has peculiar characteristics and features which make it more challenging for traditional QA methods than other kinds of text. This thesis proposes PARMS (Parallel Corpus Multi Stream) Methodology; a novel method applying existing advanced IR (Information Retrieval) techniques, and combining them with NLP (Natural Language Processing) methods and additional semantic knowledge to implement QA (Question Answering) for a parallel corpus. A parallel Corpus involves use of multiple forms of the same corpus where each form differs from others in a certain aspect, e. <b>g.</b> <b>translations</b> of a scripture from one language to another by different translators. Additional semantic knowledge can be referred as a stream of information related to a corpus. PARMS uses Multiple Streams of semantic knowledge including a general ontology (WordNet) and domain-specific ontologies (QurTerms, QurAna, QurSim). This additional knowledge has been used in embedded form for Query Expansion, Corpus Enrichment and Answer Ranking. The PARMS Methodology has wider applications. This thesis applies it to the Quran – the core text of Islam; as a first case study. The PARMS Method uses parallel corpus comprising ten different English translations of the Quran. An individual Quranic verse is treated as an answer to questions asked in a natural language, English. This thesis also implements PARMS QA Application as a proof of concept for the PARMS methodology. The PARMS Methodology aims to evaluate the range of semantic knowledge streams separately and in combination; and also to evaluate alternative subsets of the DATA source: QA from one stream vs. parallel corpus. Results show that use of Parallel Corpus and Multiple Streams of semantic knowledge have obvious advantages. To the best of my knowledge, this method is developed {{for the first time and}} it is expected to be a benchmark for further research area...|$|E
40|$|We {{present an}} autoencoder that leverages learned {{representations}} to better measure similarities in data space. By combining a variational autoencoder with a {{generative adversarial network}} we can use learned feature representations in the GAN discriminator as basis for the VAE reconstruction objective. Thereby, we replace element-wise errors with feature-wise errors to better capture the data distribution while offering invariance towards e. <b>g.</b> <b>translation.</b> We apply our method to images of faces and show that it outperforms VAEs with element-wise similarity measures in terms of visual fidelity. Moreover, we show that the method learns an embedding in which high-level abstract visual features (e. g. wearing glasses) can be modified using simple arithmetic...|$|R
40|$|Psychophysical {{experiments}} {{show that}} humans are better at perceiving rotation and expansion than translation [5][9]. These findings are inconsistent with standard models of motion integration which predict best performance for translation. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we first perform model selection between the competing models (e. <b>g.</b> <b>translation,</b> rotation, and expansion) and then estimate the velocity using the selected model. We define novel prior models for smooth rotation and expansion using techniques {{similar to those in}} the slow-and-smooth model [23] (e. g. Green functions of differential operators). The theory gives good agreement with the trends observed in four human experiments...|$|R
40|$|This paper {{describes}} the strategic vision {{for a new}} translation management workflow for the US Government’s National Virtual Transla-tion Center (NVTC). The paper also describes past, current, and planned experiments vali-dating the vision, along with experiment re-sults to-date. The most salient features of the new workflow include the embedding of translation technology at {{the front end of}} the workflow (e. <b>g.,</b> <b>translation</b> memory technol-ogy, specialized lexicons, and machine trans-lation), technology-generated “seed translation”, a new human work role called “paralinguist ” to assess the “seed translation” and assign an appropriate translator/post-editor, and new human translation strategies including federated search of online dictionar-ies and collaborative translation. ...|$|R
40|$|The {{advances}} made in {{the last}} two decades have allowed robotic platforms, and in particular mobile robots, to successfully address a large variety of tasks, albeit mainly repetitive and simple ones. However, real-world applications typically involve complex decision making processes and non structured environments thus requiring a level of perception/world awareness and cognitive capabilities that cannot yet be provided by a robot. For this reason it is convenient, if not mandatory, to have a human supervising the execution. The robot shared control framework (see, e. g., [1], [2]) represents a promising step in this direction, since it allows to merge robots (limited) autonomy and humans cognitive capabilities. Previous studies have applied this idea to mobile robots navigating in cluttered environments, with an emphasis on bilateral shared control architectures with haptic feedback for the human operator. Typically, the operator commands a motion (desired position, reference velocity) to the robot via a haptic device. The robot executes the command while retaining some autonomy in order to, e. g., avoid obstacles or other dangers. Finally, the loop is closed by rendering on the haptic feedback a force that is proportional to the mismatch between commanded and executed motion in order to increase the operator’s situational awareness. Despite being an effective approach, commanding direct motion inputs requires a high commitment of the human, especially when the task is very complex or the environment is highly cluttered. Therefore, we propose an extension to the shared control in which an operator acts at the planning level, in order to modify some characteristics of the task but without the burden of directly driving the robot [3]. We assume that a task scheduler generates an initial trajectory based only on prior information. The trajectory is described as i) a geometric path controls to the set of parameters x, allowing the user to command some global behavior, e. <b>g.</b> <b>translations</b> or rotations of the curve. At the same time, the robot must track the generated trajectory and, whenever needed, modify it in real time in order to avoid collisions or to reach a nearby target. In particular, the robot performs both a reactive deformation of the reference trajectory and a planning of alternative paths. Finally, the bilateral component of the human-robot interaction is realized by feeding back to the operator a force cue informative of the global deformation acting on the desired path rather than on a local mismatch between commanded and executed position/velocity. Summarizing, the novel elements of this approach are: i) broadening the classical shared control approach by endowing the mobile robot with a higher planning autonomy, ii) allowing a human operator to act at the planning level rather than at the motion control level, iii) generating a force cue informative of the global deformation of the desired path rather than of the mismatch between direct motion commands and their execution. The proposed method has been extensively tested with human/hardware in-the-loop simulations, featuring a physically simulated quadrotor aerial vehicle and a haptic device (see Fig. 1) ...|$|E
40|$|The {{appearance}} {{of objects in}} an image can change dramatically depending on their pose, distance, and illumination. Learning representations that are invariant against such appearance changes {{can be viewed as}} an important preprocessing step which removes distracting variance from a data set, so that downstream classifiers or regression estimators perform better. Complex cells in primary visual cortex are commonly seen as building blocks for such invariant image representations (e. g. Riesenhuber Poggio 2000). While complex cells, like simple cells, respond to edges of particular orientation they are less sensitive to the precise location of the edge. A variety of neural algorithms have been proposed that aim at explaining the response properties of complex cells as components of an invariant representation that is optimized for the spatio-temporal statistics of the visual input. For certain classes of transformations (e. <b>g.</b> <b>translations,</b> scalings, and rotations), it is possible to analytically derive features that are invariant under these transformations, and the design of such invariant features has been studied extensively in computer vision. The range of naturally occurring transformations, however, is much more variable and not precisely known. Thus, an analytical design of invariant features does not seem feasible. Instead one can seek to find features that may not be perfectly invariant anymore but which on average change as slowly as possible under the transformations occurring in the data (Földiák 1991). The best known instantiation of this approach is slow feature analysis (SFA) which has been proposed to underlie the formation of complex cell receptive fields (Berkes Wiskott 2005). From a machine learning perspective, SFA {{can be seen as a}} special case of oriented principal component analysis that greedily searches for filters that maximize the signal-to-noise ratio if the variations generated by the transformational changes are considered noise. For the learning of complex cells the algorithm has been applied in the quadratic feature space. Here we present a new algorithm called slow subspace analysis (SSA). SSA combines the slowness objective of SFA with the energy model known from steerable filter theory such that it yields perfectly invariant steerable filters in the ideal analytically tractable cases. There are two important differences between SFA and SSA: First, while SSA uses the same slowness criterion as SFA for each individual feature, it replaces the greedy search strategy by optimizing all filters simultaneously for the best average slowness, and second, the optimization in SSA is done only over the (n 2 + n) / 2 dimensional parameter space of orthogonal transforms on the original n-dimensional signal space while for complex cell learning with SFA the optimization is carried out over the entire quadratic feature space for which the number of parameters is much larger, i. e. (n 4 + 2 n 3 −n 2 − 2 n) / 8. These differences make SSA an interesting alternative to SFA. In particular, the theoretical grounding of SSA in steerable filter theory is attractive as it allows one to carry out meaningful model comparisons between different algorithms. Accordingly, we show that our new algorithm exhibits larger slowness than SFA for various important examples such as translations, rotations and scalings as well as natural movies...|$|E
40|$|Vision {{deals with}} the problem of {{deriving}} information about the world from the light reflected from it. Although the active and task-oriented nature of vision is only implicit in this formulation, this view captures several of the essential aspects of vision. As Marr (1982) phrased it in his book Vision, vision is an information processing task, in which an internal representation of information is of utmost importance. Only by representation information can be captured and made available to decision processes. The purpose of a representation is to make certain aspects of the information content explicit, that is, immediately accessible without any need for additional processing. This introductory chapter deals with a fundamental aspect of early image representation [...] -the notion of scale. As Koenderink (1984) emphasizes, the problem of scale must be faced in any imaging situation. An inherent property of objects in the world and details in images is that they only exist as meaningful entities over certain ranges of scale. A simple example of this is the concept of a branch of a tree, which makes sense only at a scale from, say, a few centimeters to at most a few meters. It is meaningless to discuss the tree concept at the nanometer or the kilometer level. At those scales it is more relevant to talk about the molecules that form the leaves of the tree, or the forest in which the tree grows. Consequently, a multi-scale representation is of crucial importance if one aims at describing the structure of the world, or more specifically the structure of projections of the three-dimensional world onto two-dimensional images. The need for multi-scale representation is well understood, for example, in cartography; maps are produced at different degrees of abstraction. A map of the world contains the largest countries and islands, and possibly, some of the major cities, whereas towns and smaller islands appear at first in a map of a country. In a city guide, the level of abstraction is changed considerably to include streets and buildings etc. In other words, maps constitute symbolic multi-scale representations of the world around us, although constructed manually and with very specific purposes in mind. To compute any type of representation from image data, it is necessary to extract information, and hence interact with the data using certain operators. Some of the most fundamental problems in low-level vision and image analysis concern: what operators to use, where to apply them, and how large they should be. If these problems are not appropriately addressed, the task of interpreting the output results can be very hard. Ultimately, the task of extracting information from real image data is severely influenced by the inherent measurement problem that real-world structures, in contrast to certain ideal mathematical entities, such as ``points'' or ``lines'', appear in different ways depending upon the scale of observation. Phrasing the problem in this way shows the intimate relation to physics. Any physical observation by necessity has to be done through some finite aperture, and the result will, in general, depend on the aperture of observation. This holds for any device that registers physical entities from the real world including a vision system based on brightness data. Whereas constant size aperture functions may be sufficient in many (controlled) physical applications, e. g., fixed measurement devices, and also the aperture functions of the basic sensors in a camera (or retina) may have to determined a priori because of practical design constraints, it is far from clear that registering data at a fixed level of resolution is sufficient. A vision system for handling objects of different sizes and at difference distances needs a way to control the scale(s) at which the world is observed. The goal of this chapter is to review some fundamental results concerning a framework known as scale-space that has been developed by the computer vision community for controlling the scale of observation and representing the multi-scale nature of image data. Starting from a set of basic constraints (axioms) on the first stages of visual processing it will be shown that under reasonable conditions it is possible to substantially restrict the class of possible operations and to derive a (unique) set of weighting profiles for the aperture functions. In fact, the operators that are obtained bear qualitative similarities to receptive fields at the very earliest stages of (human) visual processing (Koenderink 1992). We shall mainly be concerned with the operations that are performed directly on raw image data by the processing modules are collectively termed the visual front-end. The purpose of this processing is to register the information on the retina, and to make important aspects of it explicit that are to be used in later stage processes. If the operations are to be local, they have to preserve the topology at the retina; for this reason the processing can be termed retinotopic processing. Early visual operationsAn obvious problem concerns what information should be extracted and what computations should be performed at these levels. Is any type of operation feasible? An axiomatic approach that has been adopted in order to restrict the space of possibilities is to assume that the very first stages of visual processing should be able to function without any direct knowledge about what can be expected to be in the scene. As a consequence, the first stages of visual processing should be as uncommitted and make as few irreversible decisions or choices as possible. The Euclidean nature of the world around us and the perspective mapping onto images impose natural constraints on a visual system. Objects move rigidly, the illumination varies, the size of objects at the retina changes with the depth from the eye, view directions may change etc. Hence, it is natural to require early visual operations to be unaffected by certain primitive transformations (e. <b>g.</b> <b>translations,</b> rotations, and grey-scale transformations). In other words, the visual system should extract properties that are invariant with respect to these transformations. As we shall see below, these constraints leads to operations that correspond to spatio-temporal derivatives which are then used for computing (differential)  geometric descriptions of the incoming data flow. Based on the output of these operations, in turn, a large number of feature detectors can be expressed as well as modules for computing surface shape. The subject of this chapter is to present a tutorial overview on the historical and current insights of linear scale-space theories as a paradigm for describing the structure of scalar images and as a basis for early vision. For other introductory texts on scale-space; see the monographs by Lindeberg (1991, 1994) and Florack (1993) as well as the overview articles by ter Haar Romeny and Florack (1993) and Lindeberg (1994). QC 20110914 </p...|$|E
50|$|Complexity and Information, Cambridge University Press, 1998 (with A. <b>G.</b> Werschulz); Japanese <b>translation,</b> 2000.|$|R
50|$|In 1964, Ramily Bin Thakir {{translated}} the Kural text in verse. In 1967, Hussein Ismail {{translated the}} {{work under the}} title Thirukural Sastera Kalasik Tamil Yang. <b>G.</b> Soosai’s <b>translation</b> appeared under the title Thirukkural dalam bahasa Melayu.|$|R
30|$|By Proposition  17 we {{may reduce}} {{ourselves}} to the case where <b>G</b> contains no <b>translations.</b>|$|R
