27|63|Public
5000|$|... {{specific}} API’s {{can be used}} to dynamically evolve {{the database}} schema. This is an advanced topic, involving what's called Versant runtime classes. Basically, you can create completely <b>dynamic</b> <b>schema</b> structure for the database so that new classes and attributes can be created on the fly.|$|E
40|$|The schema of {{a system}} {{consists}} of the constructs that model its entities. Schema evolution is the timely change {{and management of the}} schema. <b>Dynamic</b> <b>schema</b> evolution is the management of schema changes while the system is in operation. We propose a sound and complete axiomatic model for <b>dynamic</b> <b>schema</b> evolution in objectbase management systems (OBMSs) that support subtyping and property inheritance. The model is formal, which distinguishes it from the traditional approach of informally defining a number of invariants and rules to enforce them. By reducing systems to the axiomatic model, their functionality with respect to <b>dynamic</b> <b>schema</b> evolution can be compared within a common framework. 1 Introduction Object-oriented computing is emerging as the predominant technology for providing database services in advanced application domains such as engineering design, CAD/CAM systems, multimedia, medical imaging, and geo-information systems, to name a few. An important characteristic of t [...] ...|$|E
40|$|Although {{database}} {{technologies have}} been used widely, they still carl not be simply used to construct such complicated database like classical literature database or archaeological relics ' database. This is because these kinds ofdata are semi-structured data {{that do not have}} regular structures, so that their database schema can't be defined before storing data. We have proposed DREAM model for semi-structured databases. In this model, a database consists of five elements and its operations are similar to that of set theory. And furthennore we have introduced <b>dynamic</b> <b>schema</b> &quot;shape &quot; showing structure of each element. Based on this model, we have realized a protofype of database management system, called DREAM DBMS, including the function of constructing shapes, called shape-function. However, shape is insufficient to describe database structures because it can't explain nested structures ofelements. In this paper, we refine the concept &quot;shape&quot; by introducing a new concept &quot;shape-graph&quot; that is also a <b>dynamic</b> <b>schema</b> showing database structures more exactly. Then we describe the implementation of DREAM DBMS. Finally. we evaluate the performance of constructing shape and shape-graph in order to reveal the efficiency of DREAM DBMS. Keywords: Database management system, Semi-structured data, <b>Dynamic</b> <b>schema,</b> Data model...|$|E
5000|$|... #Subtitle level 3: Modeling {{numerous}} {{classes with}} very few instances per class: highly <b>dynamic</b> <b>schemas</b> ...|$|R
50|$|MongoDB is {{a widely}} used {{open-source}} NoSQL database that eschews the traditional table-based relational database structure in favor of JSON-like documents with <b>dynamic</b> <b>schemas</b> (calling the format BSON), making the integration of data in certain types of applications easier and faster.|$|R
40|$|Next-generation {{problem solving}} environments (PSEs) promise {{significant}} advances over those now available. They will span scientific disciplines and incorporate collaboration capabilities. They will host featuredetection and other agents, allow data mining and pedigree tracking, and provide access {{from a wide}} range of devices. Fundamental changes in PSE architecture are required to realize these and other PSE goals. This paper focuses specifically on issues related to data management and recommends an approach based on open, metadatadriven repositories with loosely defined, <b>dynamic</b> <b>schemas.</b> Benefits of this approach are discussed and the redesign of the Extensible Computational Chemistry Environment's (Ecce) data storage architecture to use such a repository is described, based on the distributed authoring and versioning (DAV) standard. The suitability of DAV for scientific data, the mapping of the Ecce schema to DAV, and promising initial results are presented. Index Terms—metadata, problem solving environments, scientific data management, self-describing <b>dynamic</b> <b>schemas,</b> WebDAV protocol, XML. 1...|$|R
40|$|This paper extends {{relational}} {{processing and}} optimization to the FISQL/FIRA languages for <b>dynamic</b> <b>schema</b> queries over multidatabases. <b>Dynamic</b> <b>schema</b> queries involve {{the creation and}} restructuring of metadata at run time. We present a full implementation of a FISQL/FIRA engine based on our work, which includes subqueries and all transformational capabilities of FISQL/FIRA on distributed, multidatabase platforms. An important application {{of the system is}} to enhance traditional information architectures by enabling the creation and maintenance of dynamic wrappers and mapping queries at source databases within GAV, LAV, GLAV, peer-to-peer, or other integration frameworks. In addition to fully supporting FISQL/FIRA on multidatabases, our implementation introduces a bi-level optimization paradigm where purely relational sub-fragments of queries are pushed into source engines. This paradigm shares features of canonical distributed database processing, but has a new dimension through the extension of the relational model to dynamic schemas. We present empirical results showing the feasibility of optimization in this context, and discuss tradeoffs involved. Our system is the first to extend relational databases with these capabilities on this scale. 1...|$|E
40|$|A {{database}} {{system for}} storing and querying data of a <b>dynamic</b> <b>schema</b> {{has been developed}} based on the kdb+ database management system and the q programming language {{for use in a}} financial setting of order and execution services. Some basic assumptions of mandatory fields of the data to be stored are made including that the data are time-series based. A <b>dynamic</b> <b>schema</b> enables an Order-Management System (OMS) to store information not suitable or usable when stored in log files or traditional databases. Log files are linear, cannot be queried effectively and are not suitable for the volumes produced by modern OMSs. Traditional databases are typically row-oriented which does not suit time-series based data and rely on the relational model which uses statically typed sets to store relations. The created system includes software that is capable of mining the actual schema stored in the database and visualize it. This enables ease of exploratory querying and production of applications which use the database. A feedhandler has been created optimized for handling high volumes of data. Volumes in finance are steadily growing as the industry continues to adopt computer automation of tasks. Feedhandler performance is important to reduc...|$|E
40|$|This paper {{focuses on}} an aspect that is widely {{neglected}} in native XML database management systems: support for concurrent transactional access. We analyze the isolation {{requirements of the}} XQuery Update language and disclose typical sources of anomalies of various query processing strategies. We also present extensions to our proven XML lock protocol, which allow us to exploit <b>dynamic</b> <b>schema</b> information for query processing and protects us against XML-specific “schema phantoms”. All concepts shown were implemented in our research prototype resulting in a scalable framework for serializable XQuery. 1...|$|E
50|$|RethinkDB is a {{free and}} open-source, NoSQL, {{distributed}} document-oriented database originally created by {{the company of the}} same name. The database stores JSON documents with <b>dynamic</b> <b>schemas,</b> and is designed to facilitate pushing real-time updates for query results to applications. Initially seed funded by Y Combinator in June 2009, the company announced in October 2016 that it had been unable to build a sustainable business and its products would in future be entirely open-sourced without commercial support.|$|R
50|$|Johnson {{indicates}} that {{his analysis of}} out drew upon a 1981 doctoral dissertation by Susan Lindner in linguistics at UCSD under Ronald Langacker, and more generally by the theory of cognitive grammar put forth by him. For the force group of image schemas Johnson also drew on {{an early version of}} the force <b>dynamic</b> <b>schemas</b> put forth by Len Talmy, as used by linguists such as Eve Sweetser. Other influences include Wertheimer's gestalt structure theory and Kant's account of schemas in categorization, as well as studies in experimental psychology on the mental rotation of images.|$|R
40|$|Interpretations of Emerson 2 ̆ 7 s {{theme of}} {{self-reliance}} which generate {{charges that he}} understood neither evil nor virtue are inappropriate. A fairer reading {{should keep in mind}} the Neo-Platonism of Plotinus, which gave to Transcendentalism a <b>dynamic</b> emanation/return <b>schema</b> and to mankind a place of privilege in knowing and valuing Nature...|$|R
40|$|The Data Meta Structure {{employs a}} {{database}} to persist agent and tag information. The tables and fields contain {{are known as}} the database schema. The attributes present in these tables are the basis of queries from the users. Hence, there may arise, a need for adding new fields to existing tables or adding new tables to support new functionalities iqueries. These additions to the database are known as a schema update. This paper describes logic that enables dynamic update of the schema through the <b>Dynamic</b> <b>Schema</b> Binding in the Data Meta Structures...|$|E
40|$|In {{this paper}} {{we present a}} uniform {{approach}} to dynamic relationships in object oriented databases. We present our relationship categorisation based on dividing the object database into three virtual spaces each hosting entities of a particular type and show how relationships from the modelling domain map onto relationships in our categorisation. We present a relationship model and the semantics of relationships. The relationship model is complemented with a metamodel for implementing dynamic relationships in an object oriented database. The applicability of the dynamic relationships approach is explored by employing it to implement the database model for a system {{in order to achieve}} <b>dynamic</b> <b>schema</b> modification capabilities...|$|E
40|$|Optimizing queries over XML streams {{has been}} an {{important}} and non-trivial issue with the emergence of complex XML stream applications such as monitoring sensor networks and online transaction processing. Our system, R-SOX, provides a platform for runtime query optimization based on <b>dynamic</b> <b>schema</b> knowledge embedded in the XML streams. Such information provides refined runtime schema knowledge thus dramatically enlarged the opportunity for schema-based query optimizations. In this demonstration, we focus on the following three aspects: (1) annotation of runtime schema knowledge; (2) incremental maintenance of runtime schema knowledge; (3) dynamic semantic query optimization techniques. The overall framework for runtime semantic query optimization, including several classes of dynamic optimization techniques, will be shown in this demonstration. 1...|$|E
40|$|In semistructured {{databases}} {{there is}} no schema fixed in advance. To provide {{the benefits of a}} schema in such environments, we introduce DataGuides: concise and accurate structural summaries of semistructured databases. DataGuides serve as <b>dynamic</b> <b>schemas,</b> generated from the database; they are useful for browsing database structure, formulating queries, storing information such as statistics and sample values, and enabling query optimization. This paper presents the theoretical foundations of DataGuides along with algorithms for their creation and incremental maintenance. We provide performance results based on our implementation of DataGuides in the Lore DBMS for semistructured data. We also describe the use of DataGuides in Lore, both in the user interface to enable structure browsing and query formulation, and as a means of guiding the query processor and optimizing query execution. 1. Introduction Traditional relational and object-oriented database systems force all data to adhere [...] ...|$|R
40|$|While underlining the {{importance}} of the visual approach in the artefacts design a hypothesis is made that computer graphics can he a method that allows to pass from abstract architectural and urban data graphic representation to figurative one. The “Vision” of a three components matrices and the <b>dynamic</b> computer <b>schema</b> {{can be seen as a}} possible interface toward the architectural schema...|$|R
40|$|Abstract. Formal {{models of}} {{geographic}} space should support reasoning about its static and dynamic properties, its objects, their behaviors, and the relation-ships between them. Image schemas, used to embody spatiotemporal experien-tial abstractions, capture high-level perceptual concepts {{but do not}} have generally accepted formalizations. This paper provides a method for formally representing topological and physical image schemas using Milner’s bigraphi-cal models. Bigraphs, capable of independently representing mobile locality and connectivity, provide formal algebraic specifications of geographic environ-ments enhanced by intuitive visual representations. Using examples from a built environment, we define topological schemas CONTAINER and LINK as static bigraph components, <b>dynamic</b> <b>schemas</b> INTO and LINKTO as rule-based changes in static components, and more complex schemas RE MOVAL_OF_RESTRAINT and BLOCKAGE with sequences of rules. Finally, we demonstrate that bigraphs {{can be used to}} describe scenes with incomplete information, and that we can adjust the granularity of scenes by using bigraph composition to provide additional context...|$|R
40|$|Abstract — Efficient {{packaging}} and communication of metadata are critical in multimedia communications to achieve seamless mobility. The XML schema compression proposed here comprises {{a method for}} decomposing an XML schema into a sequence of atomic elements. This representation reorganizes the given XML schema with the threefold purpose of facilitating <b>dynamic</b> <b>schema</b> switching and reconfiguration of metadata decoders, increasing the efficiency of binary metadata decoding, and storing XML schemas in binary format. As a result, schemas can be efficiently transmitted over congested networks and stored in devices with limited resources. Since each schema may represent the metadata structure for {{a different type of}} media format, this allows a system to support different profiles (schemas) and media formats, enabling dynamically reconfigurable metadata encoders and decoders...|$|E
40|$|Abstract: For a long time, {{data has}} been {{typically}} stored in tabular form {{so as to}} increase the indexing and readability. Nowadays, the trends are changing as Graph databases are quickly gaining popularity. In fact, {{it would not be}} wrong to call them "the future of DBMS". The representation of data {{in the form of a}} graph lends itself well to structured data with a <b>dynamic</b> <b>schema.</b> This paper goes over current applications and implementations of graph databases, giving an overview of the different types available and their application. Due wide spread of graph algorithms and models, no standard system or query language has been denied for graph databases. Research and industry adoption will determine the future direction of graph databases...|$|E
40|$|This paper	explores	the	societal	underpinnings	of	child	abuse	and	neglect. It looks	at	child	abuse	and	neglect	as	systemic	violence	against	children, and argues	the	importance	of	recognising	its	occurrence	as	the	collateral damage of	social	strategy	and	not	just	individual	happenstance. Thus,	 {{in order}} to	address	 the	problem	of	 child	abuse	and	neglect	 effectively,	 we need to	understand	the	normative	biases	in	its	favour,	 its	structural	causes, <b>dynamic</b> <b>schema,</b>	 costs,	 fallout	 and	 payoff. In	 other	words,	 we	 need	 to know why,	 how,	 in	which	ways	and	for	whose	benefit	societies	operate	as though (and	people	seem	to	think) 	 violence	against	children	is	ok	 –	 even {{necessary}} –	 and,	 so,	 perpetuated. The	paper	particularly	 focuses	on	 the evidence of	indigenous	children...|$|E
40|$|In this paper, {{we propose}} a generic method for elaborating the {{behavioural}} specification dictionary of applications. It could apply {{in the context}} of various conceptual modelling approaches and take advantage of functionalities provided by associated CASE tools. The method is based on a meta-schema abstracting the behavioural concepts by using the structural abstractions of the chosen modelling approach. Once storage structures are generated from this meta-schema, they can be populated in an automated way by examining <b>dynamic</b> <b>schemas</b> specified by designers. The method is intended for dealing with particular applications in which behaviour must be preserved. 1 Motivations There are some kinds of applications in which behaviour must be represented not to be simulated or enhanced (through some executive programs or even active rules [Ha 90, LNR 87, TPC 94 b]) but to be preserved. Reasons behind "storing behaviour" are various. First of all, by keeping the whole trace of the applica [...] ...|$|R
5000|$|It is programmer-intensive. XML schemas are {{notoriously}} tricky to write by hand, a recommended {{approach is to}} create them by defining relational tables, generating XML-schema code, and then dropping these tables. This is problematic in many production operations involving <b>dynamic</b> <b>schemas,</b> where new attributes are required to be defined by power-users who understand a specific application domain (e.g. inventory management or biomedicine) but are not necessarily programmers. By contrast, in production systems that use EAV, such users define new attributes (and the data-type and validation checks associated with each) through a GUI application. Because the validation-associated metadata is required to be stored in multiple relational tables in a normalized design, a GUI application that ties these tables together and enforces the appropriate metadata-consistency checks is the only practical way to allow entry of attribute information, even for advanced developers - even if the end-result uses XML or JSON instead of separate relational tables.|$|R
40|$|M. A. This {{study is}} based on the {{principles}} of the subjectivist approach of Cognitive Linguistics, as opposed to the more traditional objectivist view, specifically those principles applicable to the acquisition of mental contact between conceptualizers in a given communication situation. One of the most fundamental points of departure of Cognitive Linguistics is the opinion that abstractions (even linguistic abstractions) are modelled on man's bodily experience of his surrounding reality. These embodied experiences constitute a network of preconceptual and non-propositional image schemas, categorized as space <b>schemas,</b> force <b>dynamic</b> <b>schemas,</b> schemas based on sensation and basic-level objects. Several mapping processes, including metaphor and metonymy, transpose these image schemas from a preconceptual, prelinguistic level to a conceptual and linguistic niveau. A prerequisite for conceptualization through linguistic communication is to constitute mental contact between the speaker and hearer as the conceptualizers. Linguistic communication presupposes the transfer of meaning, which {{is based on}} certain cognitive variables determining mental spaces and conceptual blends. Against the preceding background, the newspaper headline, as cognitive entity, constitutes the research domain by means of which the nature of the potential mental contact between the headline writer (as speaker) and the headline reader (as hearer) in a specific communication situation is analysed and evaluated. A seemingly useful and potent cognitive measuring instrument regarding presupposed and actualised mental contact, by means of which any written or spoken communication can be analysed and evaluated, is the outcome of this study. A set of examples of headlines was collected from the Afrikaans daily newspaper, Beeld, and the Afrikaans Sunday paper, Rapport, from February 1996 until September 1998, serving as research material...|$|R
40|$|The {{objective}} of this dissertation {{is to create a}} theoretical framework and mechanisms for automating <b>dynamic</b> <b>schema</b> evolution in a heterogeneous database environment. The structure or schema of databases changes over time. Accommodating changes to the schema without loss of existing data and without significantly affecting the day to day operation of the database is the management of <b>dynamic</b> <b>schema</b> evolution. To address the problem of schema evolution in a heterogeneous database environment, we first propose a comprehensive taxonomy of schema changes and examine their implications. We then propose a formal methodology for managing schema evolution using graph theory with a well-defined set of operators and graph-based algorithms for tracking and propagating schema changes. We show that these operators and algorithms preserve the consistency and correctness of the schema following the changes. The complete framework is embedded in prototype software system called SEMAD (Schema Evolution Management ADvisor). We evaluate the system for its usefulness by conducting exploratory case studies using two different heterogeneous database domains, viz., a University database environment and a scientific database environment that is used by atmospheric scientists and hydrologists. The results of the exploratory case studies supported the hypothesis that SEMAD does help database administrators in their tasks. The results indicate that SEMAD helps the administrators identify and incorporate changes better than performing these tasks manually. An important overhead cost in SEMAD is the creation of the semantic data model, capturing the meta data associated with the model, and defining the mapping information that relates the model and the set of underlying databases. This task is a one-time effort that is performed at the beginning. The subsequent changes are incrementally captured by SEMAD. However, the benefits of using SEMAD in dynamically managing schema evolution appear to offset this overhead cost...|$|E
40|$|Abstract—The {{growth of}} the use of {{wireless}} and internet technologies in transport systems, enables the provision of new information services based on vehicle-to-ground communications. There are many broadband management systems, but most of them come from non-mobile environments. This results in a poor performance when deployed to environments where senders and receivers are moving. Such problems appear because transportation systems environments present specific requirements related to coverage, bandwidth and also a mix of communications networks. In order to tackle these challenges, this paper presents the work in progress of a vehicle-to-ground communication middleware that aims to manage communication requests using a <b>dynamic</b> <b>schema.</b> The core of this new communications manager is an adaptive algorithm that selects the most favorable network link taking into account several actual and past aspects of the communications requests...|$|E
40|$|Object-oriented {{computing}} is influencing {{many areas}} of computer science, including database systems. Despite many advances, object-oriented computing {{is still in its}} infancy and a universally accepted definition of an object-oriented model is virtually nonexistent. In this thesis, the object model, meta-model, query model, <b>dynamic</b> <b>schema</b> evolution policies, and version control of the TIGUKAT objectbase management system are presented. An identifying characteristic of this system is that all components are uniformly modeled as objects with well-defined behavior. This is an important achievement towards advancing database technology because it unifies the components of a database within a single, clean, underlying semantics that can be easily extended to support other database services. The TIGUKAT object model is purely behavioral, supports full encapsulation of objects, defines a clear separation between primitive components, and incorporates a uniform semantics over objects. A behavi [...] ...|$|E
50|$|CookXml is {{a unique}} XML data binding engine in Java. It is capable of mapping XML {{documents}} of desired format directly onto the corresponding object-oriented classes, essentially treating XML as a programming language rather than merely a data storage format. Therefore, it is ideal to use CookXml to write any programs that interpret XML. The tag library of CookXml is constructed dynamically at run time, and thus allows <b>dynamic</b> XML <b>schema.</b> The current implementation has unmarshalling part done.|$|R
40|$|Emergence of XML as {{a popular}} dataexchange {{standard}} � Group-by queries {{are one of the}} most common class of practical queries � BUT – XQuery � Has no explicit group-by operator � And requires simulation of group-by operations by nesting � Hence focus on efficient processing of a group-by operator (additionally with aggregation etc.) Related Work � Beyer et al [1] and Borkar and Carey [2] propose syntactic extensions to XQuery FLOWR expressions to support explicit for group-by. � But none discuss algorithms to directly support group-by. � Another approach: Detect grouping in nested queries and rewrite with explicit grouping operations. Related Work (contd.) � Most popular approach: Shred the XML data to tables in Relational database and execute equivalent SQL query [3] � Works for fixed schemas. Need to re-shred frequently for <b>dynamic</b> <b>schemas</b> – inefficient � Conversion of XQuery to SQL – not automatic � Loss of expressive power of XML (hierarchy etc.) � Performance issues in nested/hierarchical queries More on this later. Our Contributions � Framework for expressing complex group-by queries on XML with a variety of aggregation, nesting, having clause etc. � A disk-based algorithm for efficient processing of the above queries � Stringent experimental performance analysi...|$|R
40|$|Abstract- Knowledge Management {{system is}} a system that will allow {{employees}} or users to get the required information they need and at the required time, anytime and anywhere as far as there is a network coverage in that area, this will make them perform their duties well. This system is made up of a program runner which is the PC, this is called the Server, the GSM modem that aids the user's phone to communicate with the Server even when connected, MongoDB is a database System that stores data as JSON-like documents with <b>dynamic</b> <b>schemas,</b> Chrome browser, a software application used to locate, retrieve and also display content on the World Wide Web. AT Command that establishes communication between the Modem and the Server. JavaScript and HTML, Protocol Distribution Unit that also helped in the processes of this Project. The project is suitable for broad range of applications as it can be applied in various areas of human life. It can be customized to fit in any organization. Corporate bodies like Communication Companies, Oil firms, Banks can use a Knowledge Management System to get useful information from experts to keep their jobs moving effectively and also to attend to, and satisfy their customers by providing prompt answers to their queries. Generally, it is a means the organisational intellectual resources and information are within the business environment...|$|R
40|$|Abstract Process-based {{composition}} of Web services has recently gained signifi-cant momentum {{for the implementation}} of inter-organizational business collabora-tions. In this approach, individual Web services are choreographed into composite Web services whose integration logics are expressed as composition schema. In this paper, we present a goal-directed composition framework to support on-demand busi-ness processes. Composition schemas are generated incrementally by a rule inference mechanism based on a set of domain-specific business rules enriched with contextual information. In situations where multiple composition schemas can achieve the same goal, we must first select the best composition schema, wherein the best schema is selected based on the combination of its estimated execution quality and schema qual-ity. By coupling the <b>dynamic</b> <b>schema</b> creation and quality-driven selection strategy in one single framework, we ensure that the generated composite service comply with business rules when being adapted and optimized...|$|E
40|$|Workflow {{management}} is a ubiquitous task faced by many organizations, and entails {{the coordination of}} various activities. This coordination is increasingly carried out by software systems called workflow management systems (WFMS). An important component of many WFMSs is a DBMS for keeping track of workflow activity. This DBMS maintains an audit trail, or event history, that records the results of each activity. Like other data, the event history can be indexed and queried, and views can be defined on top of it. In addition, a WFMS must accommodate frequent workflow changes, which result from a rapidly evolving business environment. Since the database schema depends on the workflow, the DBMS must also support <b>dynamic</b> <b>schema</b> evolution. These requirements are especially challenging in high-throughput WFMSs [...] -i:e:, systems for managing high-volume, mission-critical workflows. Unfortunately, existing database benchmarks do not capture the combination of flexibility and perfo [...] ...|$|E
40|$|Materialization is a {{powerful}} and ubiquitous abstraction pattern for conceptual modeling that relates a class of categories (e. g., models of cars) and a class of more concrete objects (e. g., individual cars). This paper presents materialization as a generic relationship between two classes of objects and describes an abstract implementation of it. The presentation is abstract {{in that it is}} not targeted at a specific object system. The target system is supposed to provide: 1) basic object-modeling facilities, supplemented with an explicit metaclass concept and 2) operations for <b>dynamic</b> <b>schema</b> evolution like creation or deletion of a subclass of a given class and modification of the type of an attribute of a class. The presentation is generic in that the semantics of materialization is implemented in a metaclass, which is a template to be instantiated in applications. Application classes are created as instances of the metaclass and they are thereby endowed with structure and behavior consistent with the generic semantics of materialization...|$|E
40|$|Discovering {{optimized}} {{intervals of}} numeric attributes in association rule mining {{has been recognized}} as an influential research problem over the last decade. There have been several stochastic optimization approaches such as evolutionary and swarm methods which try to find good intervals. One drawback of these approaches is sequential nature which requires multiple runs to find all rules. This paper presents multi agent architecture to find optimized rules simultaneously using a <b>dynamic</b> priority <b>schema.</b> The Practical Swarm Optimization (PSO) Variant is modeled and implemented in JADE framework and tested with synthetic datasets. The results confirm finding the same sequential results in parallel...|$|R
40|$|In last {{decades of}} years {{the field of}} {{databases}} has emerged. The organizations are migrating towards Non-Relational databases from Relational Databases due to the current trend of Big Data, Big Users and Cloud Computing. Business data processing is the main market of Relational Databases. It {{turns out to be}} harder to managing Big Clients and Big information on a cloud domain. To modeling the data these databases uses a rigid and schema based approach and are designed to run on a single machine and NoSQL (Not Only SQL) database provides, flexible data model, <b>dynamic</b> <b>schemas,</b> efficient big data storage, scale-out architecture and access requirement hence these are considering as new Era of database [11][12]. We have taken Redis as a new NoSQL database in this work. Redis in its least difficult structure is a key value pair based information framework. It bolsters all the information structures like arrays, variables, strings and linked list. In SQL database like SQL Server, MySQL and Oracle the data in Redis is structured data unlike the other databases where the data is relational data [6]. However Redis provides minimum to virtually no security for the data. As all the information is put away in key value pair, anyone can get the value if the key is known. Accordingly such a database is not suitable for big enterprise and most useful application information. So in this work we add security to a Redis framewor...|$|R
40|$|In this article, {{we develop}} a {{relational}} algebra for metadata integration, Federated Interoperable Relational Algebra (FIRA). FIRA has many desirable properties such as compositionality, closure, a deterministic semantics, a modest complexity, support for nested queries, a subalgebra equivalent to canonical Relational Algebra (RA), and robustness under certain classes of schema evolution. Beyond this, FIRA queries {{are capable of}} producing fully <b>dynamic</b> output <b>schemas,</b> where the number of relations and/or the number of columns in relations of the output varies dynamically with the input instance. Among existing query languages for relational metadata integration, only FIRA provides generalized <b>dynamic</b> output <b>schemas,</b> where the values in any (fixed) number of input columns can determine output schemas. Further contributions of this article include development of an extended relational model for metadata integration, the Federated Relational Data Model, which is strictly downward compatible with the relational model. Additionally, we define the notion of Transformational Completeness for relational query languages and postulate FIRA as a canonical transformationally complete language. We also give a declarative, SQL-like query language that is equivalent to FIRA, called Federated Interoperable Structured Query Language (FISQL). While our main contributions are conceptual, the federated model, FISQL/FIRA, {{and the notion of}} transformational completeness nevertheless have important applications to data integration and OLAP. In addition to summarizing these applications, we illustrate the use of FIRA to optimize FISQL queries using rule-based transformations that directly parallel their canonical relational counterparts. We conclude the article with an extended discussion of related work as well as an indication of current and future work on FISQL/FIRA...|$|R
