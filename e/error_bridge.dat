1|24|Public
40|$|The Federal Highway Administration {{requires}} State Transportation Agencies to have {{a formal}} method to estimate contract time for highway construction projects. To meet this requirement many states use an integrated scheduling system to estimate project durations based on assumed productivity rates and generic job logic. The current work investigated the accuracy of two of these systems found that both systems accuracy in predicting the duration of Kentucky Transportation Cabinet projects was greater than + 200 %. In response to this poor accuracy, a parametric project duration estimating tool was developed based on a multivariate regression analysis of bid item quantities and engineering and construction estimate. Five regression models were develop to estimate contract time for large projects (great than $ 1, 000, 000) based on key bid item quantities; limited access (+ 22 % median error), open access (+ 35 % median error), new route (+ 55 % median <b>error),</b> <b>bridge</b> rehabilitation (+ 77 % median error), and bridge replacement(+ 17 % median error). It {{was not possible to}} develop a parametric estimating tool for predicting the duratio...|$|E
40|$|Figure 1 : An {{example of}} input mesh, minimum <b>error</b> <b>bridges,</b> and final stencil image. Creating {{physical}} stencils from 3 D meshes {{is a unique}} rendering challenge {{that has not been}} previously addressed. The task is a problem of two competing goals: forming a single, well-connected and stable stencil sheet, while simultaneously limiting the error introduced by pieces of bridging material. Under these conflicting goals, it can often be difficult to create visually pleasing stencils from complicated imagery by hand. Even for well-behaved images, expressive stencils can be time-consuming to craft manually. We present a method for generating expressive stencils from polygonal meshes or images. In our system, users provide input geometry and can adjust desired view, lighting conditions, line thickness, and bridge preferences to achieve their final desired stencil. The stencil creation algorithm makes use of multiple metrics to measure the appropriateness of connections between unstable stencil regions. These metrics describe local features to help minimize the distortion of the abstracted image caused by stabilizing bridges. The algorithm also uses local statistics to choose a best fit connection that maintains both structural integrity and local shape information. We demonstrate our algorithm on physical media including construction paper and sheet metal...|$|R
40|$|This paper {{proposes a}} new CLB {{architecture}} for FPGAs and an associated testing technique that detects routing errors caused by SEUs in the SRAM configuration {{memory of the}} FPGA. The proposed testing technique detects all possible routing <b>errors</b> including <b>bridging</b> faults, and requires a single configuration of only the LUTs of the FPGA. Any routing error that affects {{the logic of the}} circuit is detected by the proposed technique in a maximum of 8 clock cycles. It is noteworthy that the time required for error detection is independent of both the number of switch matrices and the number of logic blocks in the FPGA...|$|R
40|$|We obtain, by {{extensive}} direct numerical simulations, time-dependent and equal-time structure {{functions for}} the vorticity, in both quasi-Lagrangian and Eulerian frames, for the direct-cascade regime in two-dimensional fluid turbulence with air-drag-induced friction. We show that differ- ent ways of extracting time scales from these time-dependent structure functions lead to different dynamic-multiscaling exponents, which {{are related to}} equal-time multiscaling exponents by different classes of bridge relations; for a representative value of the friction we verify that, given our <b>error</b> bars, these <b>bridge</b> relations hold. Comment: Published in Phys. Rev. Lett, Supplemental materials added as appendi...|$|R
5000|$|Kernot wrote {{many papers}} for {{technical}} journals; an important work was On Some Common <b>Errors</b> in Iron <b>Bridge</b> Design, {{which appeared in}} 1898, an enlarged second edition was published in 1906. A younger brother, Wilfred Noyce Kernot, born in 1868, was for many years a lecturer at the University of Melbourne, and from 1932 to 1936 was professor of engineering. Kernot {{was president of the}} Wallaby Club in 1901. [...] He was also interested in astronomy, member of the British Astronomical Association from 1897 May 26 until his death. (Journal British Astronomical Association, vol. 7).|$|R
40|$|Recent {{research}} has shown that tests generated without taking process variation into account may lead to loss of test quality. At present there is no efficient device-level modeling technique that models the effect of process variation on resistive bridge defects. This paper presents a fast and accurate technique to achieve this, including modeling the effect of voltage and temperature variation using BSIM 4 transistor model. To speedup the computation time and without compromising simulation accuracy (achieved through BSIM 4) two efficient voltage approximation algorithms are proposed for calculating logic threshold of driven gates and voltages on bridged lines of a fault-site to calculate bridge critical resistance. Experiments are conducted on a 65 -nm gate library (for illustration purposes), and results show that on average the proposed modeling technique is more than 53 times faster and in the worst case, <b>error</b> in <b>bridge</b> critical resistance is 2. 64 % when compared with HSPICE...|$|R
40|$|Recent {{research}} has shown that tests generated without taking process variation into account may lead to loss of test quality. At present there is no efficient device-level modeling technique that models the effect of process variation on resistive bridges. This paper presents a fast and accurate technique to model the effect of process variation on resistive bridge defects. The proposed model is implemented in two stages: firstly, it employs an accurate transistor model (BSIM 4) to calculate the critical resistance of a bridge; secondly, the effect of process variation is incorporated in this model by using three transistor parameters: gate length (L), threshold voltage (V) and effective mobility (ueff) where each follow Gaussian distribution. Experiments are conducted on a 65 -nm gate library (for illustration purposes), and results show that on average the proposed modeling technique is more than 7 times faster and in the worst case, <b>error</b> in <b>bridge</b> critical resistance is 0. 8 % when compared with HSPICE...|$|R
40|$|A hidden Markov {{process is}} a well known concept in {{information}} theory and is used for a vast range of applications such as speech recognition and <b>error</b> correction. We <b>bridge</b> between two disciplines, experimental physics and advanced algorithms, and propose to use a physically oriented hidden Markov process as a new tool for analyzing experimental data. This tool enables one to extract valuable information on physical parameters of complex systems. We demonstrate the usefulness of this technique on low dimensional electronic systems which exhibit time dependent resistance noise. This method is expected to become a standard technique in experimental physics. Comment: 4 pages, 4 figure...|$|R
25|$|The {{music was}} {{performed}} by a choir of 430, a 65 piece orchestra and 10 State Trumpeters. At the 1838 coronation, the organist had attempted to play the instrument and conduct at the same time, {{with the result that}} neither function was satisfactory. Bridge not only delegated the organ to Walter Alcock, but also used two sub-conductors, and furthermore alternated with Parratt in conducting {{from the top of the}} organ screen. The only real musical <b>error</b> was that <b>Bridge</b> misjudged the timing of I Was Glad and had finished the anthem before the King had arrived, having to repeat it when the right moment came. Bridge was saved by the organist, who improvised in the interim.|$|R
500|$|The river's {{catchment}} area of approximately [...] {{is the largest}} of any waterway within the Adelaide region. The upper reaches are {{used to create a}} potable water supply for metropolitan Adelaide with the river supplying three of Adelaide's eight reservoirs. The upper catchment has an average annual rainfall of between [...] at its eastern end to [...] near Uraidla. The Torrens has a very variable flow leaving early settlers to use trial and <b>error</b> in determining <b>bridge</b> heights, with many bridges consequently being washed away. Due to the variability of Adelaide's climate, flow rates can change from a trickle to flood conditions quickly. On 5 June 1889, prior to major flooding, the flow rate before it entered the suburbs was , rising to , eight days later.|$|R
40|$|A single-parameter text-line {{extraction}} {{algorithm is}} described {{along with an}} efficient technique for estimating the optimal value for the parameter for individual images without need for ground truth. The algorithm is based on three simple tree operations, cut, glue and flip. An XY-tree representing the segmentation is incrementally transformed to reflect {{a change in the}} parameter while intrinsic measures {{of the cost of the}} transformation are used to detect when specific tree operations would cause an error if they were performed, allowing these errors to be avoided. The algorithm correctly identified 98. 8 % of the area of the ground truth bounding boxes and committed no column <b>bridging</b> <b>errors</b> on a set of 97 test images selected from a variety of technical journals...|$|R
40|$|Background and Aim: Dentists {{can reduce}} <b>errors</b> of <b>bridge's</b> {{framework}} through controlling and reducing errors during impression. Open tray splitting impression {{is a method}} that it's precision is questionable. The {{aim of this study}} was evaluation of framework's marginal gap produced in direct impression with and without splinting. Materials and Methods: This experimental in vitro study was done on two parallel implants (regular Neck ITI), that inserted on left premolar and molar region mandibular model. Ten final impressions by open tray and ten final impressions with splinted technique were made. Marginal gap was measured with direct view method. We used SPSS 18 and T-Test for analysis. Results: mean gap in splint and conventional methods were (43. 87 ± 11. 35) µ and (87. 30 ± 34. 50) µ, respectively. There was a significant difference between two methods (P< 0. 001). Also the marginal gap in distal and mesial retainer with splint method were significantly lower than conventional method (P< 0. 05). Conclusion: Marginal gap in splint method was lower. Because marginal integrity level of splint method was high, for final impression of implant supported bridge suggestion, however clinical procedure of this method is difficult. Key words: Implant supported dental prosthesis; Adaptation; Dental marginal; Dental impression technic...|$|R
50|$|The river's {{catchment}} area of approximately 500 km2 {{is the largest}} of any waterway within the Adelaide region. The upper reaches are {{used to create a}} potable water supply for metropolitan Adelaide with the river supplying three of Adelaide's eight reservoirs. The upper catchment has an average annual rainfall of between 575 mm at its eastern end to 1025 mm near Uraidla. The Torrens has a very variable flow leaving early settlers to use trial and <b>error</b> in determining <b>bridge</b> heights, with many bridges consequently being washed away. Due to the variability of Adelaide's climate, flow rates can change from a trickle to flood conditions quickly. On 5 June 1889, prior to major flooding, the flow rate before it entered the suburbs was , rising to , eight days later.|$|R
40|$|Interactive {{development}} environments (IDEs) increase programmer productivity, {{but unfortunately}} also {{the burden on}} language implementors since sophisticated tool support is expected even for small domain-specific languages. Our goal is to alleviate that burden, by generating IDEs from high-level language specifications using the JastAdd meta-compiler system. This puts increased tension on scope recovery in parsers, since at least a partial AST is required by the system to perform static analysis, such as name completion and context sensitive search. In this paper we present a novel recovery algorithm called bridge parsing, which provides a light-weight recovery mechanism that complements existing parsing recovery techniques. An initial phase recovers nesting structure in source files making them easier to process by existing parsers. This enables batch parser generators with existing grammars {{to be used in}} an interactive setting with minor or no modifications. We have implemented bridge parsing in a generic extensible IDE for JastAdd based compilers. It is independent of parsing technology, which we validate by showing how it improves recovery in a set of typical interactive editing scenarios for three parser generators: ANTLR (LL(variable lookahead) parsers), LPG (LALR(k) parsers), and Beaver (LALR(1) parsers). ANTLR and LPG both contain sophisticated support for error recovery, while Beaver requires manual <b>error</b> productions. <b>Bridge</b> parsing complements these techniques and yields better recovery for all these tools with only minimal changes to existing grammars...|$|R
40|$|Thesis (MTech (Information Technology)) [...] Cape Peninsula University of Technology, 2016. Access to {{healthcare}} {{is regarded}} as a basic and essential human right. It is widely known that ICT solutions have potential to improve access to healthcare, reduce healthcare cost, reduce medical <b>errors,</b> and <b>bridge</b> the digital divide between rural and urban healthcare centres. The access to personal healthcare records is, however, an astounding challenge for both patients and healthcare professionals alike, particularly within resource-restricted environments (such as rural communities). Most rural healthcare institutions have limited or non-existent access to electronic patient healthcare records. This study explored the accessibility of personal healthcare records by patients and healthcare professionals within a rural community hospital in the Eastern Cape Province of South Africa. The case study was conducted at the St. Barnabas Hospital with the support and permission from the Faculty of Informatics and Design, Cape Peninsula University of Technology and the Eastern Cape Department of Health. Semi-structured interviews, observations, and interactive co-design sessions and focus groups served as the main data collection methods used to determine the accessibility of personal healthcare records by the relevant stakeholders. The data was qualitatively interpreted using thematic analysis. The study highlighted the various challenges experienced by healthcare professionals and patients, including time-consuming manual processes, lack of infrastructure, illegible hand-written records, missing records and illiteracy. A number of recommendations for improved access to personal healthcare records are discussed. The significance of the study articulates the imperative need for seamless and secure access to personal healthcare records, not only within rural areas but within all communities...|$|R
40|$|In 1996, the {{expected}} field {{errors in the}} dipoles and quadrupoles yielded a long-term dynamic aperture of some 8 sigma at injection. The target was set to 12 sigma {{to account for the}} limitations of our model (imperfections and dynamics). From scaling laws and tracking, a specification for the field imperfections yielding the target dynamic aperture was deduced. The gap between specification and expected <b>errors</b> is being <b>bridged</b> by i) an improvement of the dipole field quality, ii) a balance between geometric and persistent current errors, iii) additional correction circuits (a 3,b 4). With the goal in view, the emphasis has now turned to the sensitivity of the dynamic aperture to the optical parameters. The distortion of the dynamics at the lower amplitudes effectively reached by the particles is minimized by optimizing the distribution of the betatron phase advance. At collision energy, the dynamic aperture is limited by the field imperfections of the low-beta triplets, enhanced by the crossing angle. With correction of the most important aberrations, the dynamic aperture reaches the target set to 10 sigma...|$|R
40|$|The {{increasing}} {{demands on}} information processing require novel computational concepts and true parallelism. Nevertheless, hardware realizations of unconventional computing approaches never exceeded a marginal existence. While {{the application of}} optics in super-computing receives reawakened interest, new concepts, partly neuro-inspired, are being considered and developed. Here we experimentally demonstrate the potential of a simple photonic architecture to process information at unprecedented data rates, implementing a learning-based approach. A semiconductor laser subject to delayed self-feedback and optical data injection is employed to solve computationally hard tasks. We demonstrate simultaneous spoken digit and speaker recognition and chaotic time-series prediction at data rates beyond 1 Gbyte/s. We identify all digits with very low classification errors and perform chaotic time-series prediction with 10 % <b>error.</b> Our approach <b>bridges</b> the areas of photonic information processing, cognitive and information science. © 2013 Macmillan Publishers Limited. All rights reserved. This work was supported by MICINN (Spain), Comunitat Autònoma de les Illes Balears, FEDER, and the European Commission under Projects TEC 2009 - 14101 (DeCoDicA), Grups Competitius and EC FP 7 Projects PHOCUS (Grant No. 240763) and NOVALIS (Grant no. 275840). Peer Reviewe...|$|R
40|$|Sampling {{is one of}} {{the most}} {{commonly}} used techniques in Approx-imate Query Processing (AQP) —an area of research that is now made more critical by the need for timely and cost-effective ana-lytics over “Big Data”. Assessing the quality (i. e., estimating the error) of approximate answers is essential for meaningful AQP, and the two main approaches used in the past to address this problem are based on either (i) analytic error quantification or (ii) the boot-strap method. The first approach is extremely efficient but lacks generality, whereas the second is quite general but suffers from its high computational overhead. In this paper, we introduce a prob-abilistic relational model for the bootstrap process, along with rig-orous semantics and a unified <b>error</b> model, which <b>bridges</b> the gap between these two traditional approaches. Based on our proba-bilistic framework, we develop efficient algorithms to predict the distribution of the approximation results. These enable the com-putation of any bootstrap-based quality measure for a large class of SQL queries via a single-round evaluation of a slightly modi-fied query. Extensive experiments on both synthetic and real-world datasets show that our method has superior prediction accuracy for bootstrap-based quality measures, and is several orders of magni-tude faster than bootstrap...|$|R
40|$|We {{investigated}} possible {{interaction between}} an arbovirus infection and the ME 7 induced mice prion disease. C 57 BL/ 6, females, 6 -week-old, were {{submitted to a}} bilateral intrahippocampal injection of ME 7 prion strain (ME 7) or normal brain homogenate (NBH). After injections, animals were organized into two groups: NBH (n= 26) and ME 7 (n= 29). At 15 th week after injections (wpi), animals were challenged intranasally with a suspension of Piry arbovirus 0. 001 % or with NBH. Behavioral changes in ME 7 animals appeared in burrowing activity at 14 [*]wpi. Hyperactivity on open field test, <b>errors</b> on rod <b>bridge,</b> and time reduction in inverted screen were detected at 15 th, 19 th, and 20 th wpi respectively. Burrowing was more sensitive to earlier hippocampus dysfunction. However, Piry-infection did not significantly affect the already ongoing burrowing decline in the ME 7 -treated mice. After behavioral tests, brains were processed for IBA 1, protease-resistant form of PrP, and Piry virus antigens. Although virus infection in isolation did not change the number of microglia in CA 1, virus infection in prion diseased mice (at 17 th wpi) induced changes in number and morphology of microglia in a laminar-dependent way. We suggest that virus infection exacerbates microglial inflammatory response {{to a greater degree}} in prion-infected mice, and this is not necessarily correlated with hippocampal-dependent behavioral deficits...|$|R
40|$|Bridge {{sampling}} is {{an effective}} Monte Carlo method for estimating the ratio of normalizing constants of two probability densities, a routine computational problem in statistics, physics, chemistry, etc. The Monte Carlo <b>error</b> of the <b>bridge</b> sampling estimator {{is determined by the}} amount of overlap between the two densities. Complementing and generalizing the Warp-I, II, and III transformations (Meng and Schilling, 2002), which are most effective for increasing the overlap between two uni-modal densities, we introduce Warp-U transformations that aim to transform multi-modal densities into uni-modal ones but without altering their normalizing constants. The construction of Warp-U transformation starts with a Gaussian (or other convenient) mixture distribution that has a reasonable overlap with a target density p underlying the unknown normalizing constant. The stochastic transformation that maps the Gaussian mixture distribution back to its generating distribution N(0, 1) is then applied to p, resulting in its Warp-U transformation. The overlap between the Warp-U transformation density and N (0, 1) is theoretically guaranteed to be no less than the overlap between p and the Gaussian mixture, as measured by any f-divergence, leading to statistically more efficient bridge sampling estimators. We propose a computationally efficient method to find an appropriate the Gaussian mixture, and use simulations to explore various estimation strategies and the choices of tuning parameters, with the aim to achieve statistical efficiency without unduly losing computational efficiency. We illustrate our findings using 10 - 50 dimensional highly irregular multi-modal densities. We also propose a strategy for using Warp-U transformations to improve MCMC algorithms, especially for sampling from multi-modal distributions...|$|R
40|$|Coal seam gas (CSG) {{is gaining}} global {{interests}} {{due to its}} natural abundance and environmental benefits in comparison to more traditional energy sources. To efficiently recover this clean and abundant energy, a detailed understanding of the fundamental properties of coal is required, which makes the coal characterisation be of paramount importance. However, coal is highly heterogeneous at multiscales, such that the characterisation of coal lags behind that of conventional reservoir rocks. X-ray microcomputed tomography (micro-CT) has been widely applied to obtain the 3 D digital representation of the coal samples. However, micro-CT images always suffer from a trade-off between the sample size to be scanned and the obtained resolution, and commonly pose a major challenge for direct numerical simulations due to the simulation instabilities. This thesis designs a complete and comprehensive coal characterisation framework, and demonstrates the capability of a digital model, named “Digital Coal”, {{can be used to}} characterise the multiscale structure of coal as well as petrophysical properties. The “Digital Coal” model developed in this thesis can preserve multiscale features of real coal samples, including the coal lithotype distribution on centimetre-length scale, cleat network and mineralisation on millimetre- to centimetre-length scale as well as cleat rough surface structure on micrometre-length scale. Our developed “Digital Coal” integrates multiscale geostatistics that are obtained from micro-CT data of different resolutions. Hence, it is not restricted by imaging resolution and can be constructed with extended domain size. Therefore, “Digital Coal” can act {{as an alternative to the}} segmented micro-CT images, such that we can avoid the challenges that are inherent to micro-CT images, such as the resolution limitation and segmentation <b>errors.</b> This study <b>bridges</b> coal properties at multiple scales, which can be potentially applied for the prediction of CSG and water production on reservoir scales by populating the model into reservoir simulators...|$|R
40|$|In this study, we analyse the 410 -km and 660 -km upper-mantle {{transition}} zone discontinuitiesas seen from seismic P-to-s wave conversions beneath the Eurasian-African Plate boundaryat south Spain and north Morocco. For this purpose we use teleseismic events recorded at 43 broad-band seismic stations deployed mainly by the TopoIberia project. The conversionsfrom the upper-mantle discontinuities {{arrive in the}} P-wave coda together with other signalsand are usually identified on stacked receiver functions. We build a new processing approachwhich is leaned on receiver functions and {{which is based on}} cross-correlation and stackingtechniques to efficiently detect and extract signals by means of their coherence, slowness, traveltime and polarity. In order to add consistency and robustness to the detections, our finalresults are based on a joint analysis of two different cross-correlation functionals and receiverfunctions. This permits to assess <b>errors</b> and to <b>bridge</b> observation gaps due to the breakdownof any of the techniques inherent to signal and noise characteristics. Finally, discontinuitydepths are determined using time corrections obtained from a 3 -D velocity model. We presenttopography maps for the 410 -km and 660 -km discontinuities which show a thickening of the{{transition zone}} beneath the plate boundary towards Morocco. The transition zone thickness isabout global average beneath south Spain (240 - 250 km) and is thicker beneath east Morocco(250 - 275 km). This is mainly due to a deeper 660 -km discontinuity, while the topography ofthe 410 -km discontinuity is smaller. In the Alboran Sea we find an up to 25 km deflection ofthe 660 -km discontinuity which suggests that the Alboran Sea heterogeneity or slab is stillsufficiently cold to depress the post-spinel phase transition. We finally discuss the results inorder to add new constraints on temperature and composition to seismic velocity anomaliesobserved in the transition zone beneath south Spain and north Morocco. © The Authors 2013. This is a contribution of the projects Consolider-Ingenio 2010 TOPOIBERIA [CSD 2006 - 00041], TOPOMED CGL 2008 - 03474 -E/BTE], Rifsis [CGL 2009 - 09727], CGL 2012 - 31472 and P 09 -RNM- 5100. L. Bonatto benefits from a Ph. D. JaePredoc (CSIC) grant. Peer Reviewe...|$|R
40|$|Inland {{shipping}} is {{an important}} pillar of the European transport system; however the challenges of inland navigation due to dense traffic, increasing ship dimension, reduced maneuver space and visibility are multifaceted and increasing. About 20 to 30 collisions per year, partially caused by carelessness, demonstrate the necessity of driving assistance systems for inland waterway applications. The project LAESSI (Guiding and assistance systems to improve safety of navigation on inland waterways) is developing efficient navigation assistance functions for inland waterway transport which aim the reduction of risk of collisions by supporting the skipper in its task. Therefore, nautical information like position, height, velocity and heading has to be determined. One focus in this contribution is a bridge collision warning system, which provides a timely alert to the skipper, whenever the vessel, particularly the wheelhouse or radar mast, will not safely pass the bridge. A feasibility study has identified Global Navigation Satellite System (GNSS) technologies as basis for the reliable height determination for such a bridge collision warning system. This approach requires information about the vertical clearance of the bridge superstructure as well as precise height information in the same height reference system at least 300 m before the vessel will pass the bridge. The high accuracy level of less than 10 cm in the vertical position necessitates the Real Time Kinematic (RTK) as suitable GNSS processing method. RTK is a phase-based differential GNSS technique and uses additional observations from permanent reference stations to mitigate or eliminate effects like tropospheric and ionospheric delays or satellite clocks and orbit <b>errors.</b> As <b>bridge</b> collision warning system is a safely critical application, this means that beside the provision of accurate height information also an integrity monitoring for the complete RTK procedure has to be introduced. The shore-based architecture is designed {{in such a way}} that correction data, based on a permanent GNSS reference station network, will be checked for their integrity before they are broadcasted (Pre-Broadcast Monitoring) to the processing computer on the vessel. Furthermore, several station dependent effects like signal interferences, signal losses or multipath effects, caused due to obstacles near the inland waterways, impact the GNSS signals, which hamper or falsify the ambiguity fixing and finally the position results. To prevent the provision of faulty results a further integrity monitoring for the shipborne architecture has to be applied. This shipborne integrity monitoring utilizes on the one hand a number of internal statistical parameters from the RTK algorithm like the conventional used fixed ratio value and on the other hand additional information from other sensors or observations. The contribution will present the derived requirements for accuracy, integrity and time to alert for different inland waterway assistance functions. Furthermore an overview about the system architecture and a communication concept based on VHF Data Exchange System (VDES) communication channels will be given. The main focus, however, is an RTK-algorithm which not only estimates position, velocity and heading, but also provides integrity information. This concept considers in a first realization internal statistical parameters from the RTK adjustment, other observations (e. g. Doppler shift) and physical information (e. g. baseline length of two GNSS antennas). A first measurement campaign was done in July 2016 in Koblenz/Germany on the river Moselle. This test area is characterized by three bridges in a relatively short distance of only 300 m which make the provision of reliable and precise RTK position data rather challenging. The preliminary analyses based on three hours GPS and GLONASS observations showed a high rate (> 85...|$|R
40|$|Many {{structures}} are built throughout {{various stages of}} construction. Typically, the process of control of the construction is undertaken by measuring the variations of its geometry at different points of the structure during the construction period. The differences between the values observed during this process of control and the theoretical values computed {{by means of a}} structural model, can mainly be explained due to the existing differences between the preconceived material properties and the real ones. Concrete bridge built by cantilevering represents a frequent example in which the control of the deviations from the forecast geometry is very important from the aesthetic and the functional point of view. These deviations can be very large at a certain stage of construction due to the cumulative effects of the deviations of previous stages and also due to the high dispersion of properties that concrete presents in comparison with other materials such as steel. Moreover, these deviations must be corrected during the cantilevenng procedure since it is normally required that, during the construction phase in which the two cantilevers are joined {{at the center of the}} span, these do not present apparent geometrical differences. This paper sets forth a procedure of control which may predict the final bridge geometry at each construction stage. For this prediction, it is necessary to take into account the material properties worked out from the measurements taken during the process of control carried out up to the current construction stage, instead of using the values stated by the initial project. Following this procedure, it is possible to introduce punctual modifications of the geometry so that the final bridge profile can be adapted to the initially assumed in the design. This control technique demands to solve successively a problem called Structural Identification. This problem consists in finding the set of characteristic parameters of a structural model that predict the geometry that best fit with the measurements of the different control stages. Normally, the Structural model itself cannot represent the exact behaviour of the real construction, therefore the best adjustment would represent the best approximation i. e. some filling differences would persist. This paper presents a sensitivity analysis of the identification procedure applied to a cantilever bridge construction with regard to the set of usual imperfections. The imperfections considered here are the following: Non homogeneity of the concrete material characteristic among different parts of the <b>bridge.</b> Measurements <b>errors</b> along the <b>bridge</b> construction control. Effects of other actions not explicitly considered in the identification anal ysis. Finally, a construction control procedure, based on identification techniques and alternative to the standardized ones, is proposed...|$|R

