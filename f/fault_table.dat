17|46|Public
40|$|Abstract-The problem {{considered}} {{in this paper}} is that of gen- 1) Reducing the cost of applying the SDT which is erating sequential decision trees (SDT's) for fault diagnosis in proportional to {{the average number of}} tests applied. digital combinational networks. Since in most applications of the decision tree the final conclusion will be that the network is fail- 2) Reducing the computation time needed for gener-ure-free, we are interested mainly in decision trees containing ating the SDT. minimal fault detection paths. Such a procedure will reduce the In most applications of the SDT the final conclusion will cost of verifying the proper operation of the network. be that the network is failure-free. Therefore we have to The faults under consideration are assumed to be single, per- minimize the number of tests in the detection path in order manent, stuck-at type faults. A priori probabilities are assigned to the nonequivalent faults and the generated decision tree is based to achieve the first objective. The second objective is upon these probabilities. It is suggested in this paper that the a achieved by generating the required tests rather than se-priori probability Pi assigned to the fault fh should be proportional lecting them from a given <b>fault</b> <b>table.</b> to the number of faults in the equivalence class of fi. The <b>fault</b> <b>table</b> is used in most existing methods for se-A procedure for generating the required decision tree for fan- lecting locating tests. From the <b>fault</b> <b>table</b> a minimal or out-free networks is presented. The procedure generates the test...|$|E
40|$|There is {{recently}} {{an interest in}} test generation for reversible circuits, but nothing has been published about fault localization in such circuits. This paper deals with fault localization for binary reversible (permutative) circuits. We concentrate on functional test based fault localization, to detect and locate “stuck-at ” faults in a reversible circuit by creating an adaptive tree. A striking property of reversible circuits is that they exhibit “symmetric ” adaptive trees. This helps considerably {{by being able to}} generate only half of the tree, and the other half is created as the mirror image of the first half. Because each test covers half faults [1] and the <b>fault</b> <b>table</b> has a high density of ones, it is relatively easy to generate the tree. The problem of fault localization of reversible circuits is therefore easier than the same problem for standard irreversible circuits. We present some preliminary results from an approach using traditional adaptive tree methods. We propose also a new efficient algorithm that eliminates the <b>fault</b> <b>table</b> generation and dynamically creates the adaptive fault tree...|$|E
40|$|Electric {{vehicle drive}} {{system is a}} multi-variable function, running {{environment}} complexed and changeable system, so it’s failure form is complicated. In this paper, according to the fault happens in different position, establish vehicle <b>fault</b> <b>table,</b> analyze the consequences of failure may cause and the causes of failure. Combined with hardware limitations, and the maximum guarantee system performance requirements, passive software redundancy fault-tolerant strategy is put forward, give an example to analysis {{the pros and cons}} of this method...|$|E
40|$|The {{critical}} issues of testing field programmable gate arrays (FPGA) {{with a view}} to diagnosing faults are an important step that ensures the reliability of FPGA designs. Correct diagnosis of faulty logic blocks of FPGAs guarantees restoration of functionality through replacement of faulty block with replacement units. This process can be done autonomously or without the intervention of an engineer depending on application area. This paper considers two methods for analysing test results of FPGA logic blocks with the purpose of localising and distinguishing faults. The algebraic logic and vector-logical methods are proposed for diagnosing faulty logic blocks in FPGA fabric. It is found that the algebraic logic method is more useful for processing of sparse <b>faults</b> <b>tables</b> when the number of coordinates with 1 s values with respect to zero values ​​is not more than 20 %, whereas the vector-logical method facilitates the analysis of <b>faults</b> <b>table</b> with predominance of 1 s values...|$|R
5000|$|... clarity - Information {{tables are}} {{ubiquitous}} and mostly inherently understood {{even by the}} general public (especially <b>fault</b> diagnostic <b>tables</b> in product guides) ...|$|R
40|$|A new {{approach}} to detecting and localizing single gate design errors in combinational circuits is proposed. The method is based on using <b>fault</b> <b>tables</b> for stuck-at <b>fault</b> diagnosis with subsequent translation of the result into the design error area. This allows to exploit standard gate-level ATPGs also for diagnosis of design errors. A powerful hierarchical approach is proposed based on using structurally synthesized BDDs, where combining the error detection and diagnosis phases into a single whole allows to drastically {{reduce the amount of}} work for error site localization...|$|R
40|$|The {{problem of}} quantum test is {{formally}} addressed {{for the first}} time. An algorithm is presented making fault detection feasible both {{now and in the}} foreseeable future for actual quantum circuits. The presented method attempts the quantum role of classical test generation and test set reduction methods known from standard binary and analog circuits. QuFault, the authors software package generates test plans for arbitrary quantum circuits using the very efficient simulator QuIDDPro[1]. The quantum <b>fault</b> <b>table</b> is introduced and mathematically formalized, and the test generation method explained...|$|E
40|$|Abstract This work justifies several quantum gate level fault {{models and}} {{discusses}} the causal error mechanisms thwarting correct function. A quantum {{adaptation of the}} classical test set generation technique known as constructing a <b>fault</b> <b>table</b> is given. This classical technique optimizes test plans to detect all the most common error types. This work therefore considers the set of predominate errors modeled by unwanted qubit rotations. In classical test, a <b>fault</b> <b>table</b> is constructed allowing the comparison between a circuit’s nominal response and a response perturbed by each separately considered error. It was found that isolating a correct circuit from a circuit containing any of the Pauli Fault rotations, requires applications of just two independent test vectors. This {{is related to the}} proven fact that a reversible system preserves the probability that additional information may be present. Thus, the probability of detection for an observable fault is related only to the probability of presence. A theorem that better connects classical ideas to quantum test set generation is presented. This leads directly to a relationship between the deterministic presence of a fault in the state vector observed with some probability and the probabilistic presence of a fault observed deterministically (Relating Time and Space Error Models). ...|$|E
40|$|It is {{believed}} that quantum computing will begin to have a practical impact in industry around year 2010. We propose an approach to test generation and fault localization for a wide category of fault models. While in general we follow the methods used in test of standard circuits, there are two significant differences: (2) we use both deterministic and probabilistic tests to detect faults, (2) we use special measurement gates to determine the internal states. A <b>Fault</b> <b>Table</b> is created that includes probabilistic information. “Probabilistic set covering” and “probabilistic adaptive trees ” that generalize those known in standard circuits, are next used. 1...|$|E
40|$|In this paper, a {{functional}} fault model for analog circuit diagnosis is proposed. A faulty circuit is modeled as a fault-free module in serial or {{in parallel with}} a fault module. To extract the faults, we adopt an iterative deconvolution technique to deconvolute the impulse response of the fault module from the faulty response. Such impulse response fault modeling makes the faults independent of input signals and system function. As the test results show, the input independent property significantly improves the diagnostic resolution, and the system function independent property allows single-module <b>fault</b> <b>tables</b> {{to be applied to}} multi-module diagnosis...|$|R
5000|$|Seismic {{refraction}} (surface)- mapping top of bedrock, <b>faults,</b> {{and water}} <b>table</b> ...|$|R
40|$|We {{propose a}} method for fault {{isolation}} in discrete event systems such as object oriented control systems, where the observations are the logged error messages. The method is based on automatic abstraction that preserves only the behavior relevant to fault isolation. In this way we avoid the state space explosion, and a model checker {{can be used to}} reason about the temporal properties of the system. The result is a <b>fault</b> isolation <b>table</b> that maps possible error logs to isolated faults, and fault isolation thus reduces to <b>table</b> lookup. The <b>fault</b> isolation <b>table</b> can also be used as an analysis tool at the design level to find both faults that cannot be isolated as well as redundant error messages...|$|R
40|$|This paper {{presents}} a hybrid BIST solution for testing systems-on-chip which combines pseudorandom test patterns with stored precomputed deterministic test patterns. A procedure is proposed for fast {{calculation of the}} cost of hybrid BIST at different lengths of pseudorandom test to find an optimal balance between test sets, and to perform core test with minimum cost of both, time and memory, and without losing in test quality. Compared to the previous approach, based on iterative use of deterministic ATPG for evaluating the cost of stored patterns, in this paper a new, extremely fast procedure is proposed, which calculates costs on a basis of <b>fault</b> <b>table</b> manipulations. Experiments on the ISCAS benchmark circuits show that the new procedure is about two orders of magnitude faster than the previous one...|$|E
40|$|This paper {{introduces}} {{the problem of}} test generation and test minimization for quantum circuits using a discrete fault model. QuFault, our software package generates test sequences for arbitrary quantum circuits using the very efficient simulator QuIDDPro [1]. The quantum <b>fault</b> <b>table</b> and the test set minimization algorithm is presented, along with some tricks to make quantum testing as deterministic as possible. As our fault model we use the single qubit rotation operators about the x, y and z axis. The angle of the rotation {{is based on the}} expected accuracy of the mechanism performing the unitary operations, or the largest impact of expected noise from the environment. We consider superposition inputs as well as interference in order to detect phase faults, such as possible errors traveling backwards through controlled gates...|$|E
40|$|An on-line {{algorithm}} is {{developed for the}} location of single cross point faults in a PLA (FPLA). The main feature of the {{algorithm is}} the determination of a fault set corresponding to the response obtained for a failed test. For the apparently small number of faults in this set, all other tests are generated and a <b>fault</b> <b>table</b> is formed. Subsequently, an adaptive procedure is used to diagnose the fault. Functional equivalence test is carried out to determine the actual fault class if the adaptive testing results {{in a set of}} faults with identical tests. The large amount of computation time and storage required in the determination, a priori, of all the fault equivalence classes or in the construction of a fault dictionary are not needed here. A brief study of functional equivalence among the cross point faults is also made...|$|E
2500|$|... 1. List of <b>faults</b> from UCERF-2, <b>Table</b> 13. [...] Unless {{otherwise}} noted other details are from Appendix A, Table 1.|$|R
5000|$|... #Caption: Location of main <b>faults</b> in {{following}} <b>table,</b> with segments color-coded to show slip-rate (up to 40 mm per year).|$|R
30|$|The Smoothing F Model is also {{successful}} {{although the}} ΔAIC {{for the entire}} historical dataset is {{not as high as}} those for the Fault and Smoothing F Models. Frankel (1995) proposed using fault data and other data for a source model of large events with magnitude > 7.0 and to use the spatial smoothing technique for smaller events. As such, it is acceptable to test the Smoothing F Model against the historical dataset of events unrelated to late Quaternary <b>faults</b> (<b>Table</b> 2). We find that the best model of distributed sources is the Smoothing F Model. The weighting factors used for combining different models seem to have an unpredictable mystic effect because the δAIC of the F Model is larger than the sum of those of S and M models (Table 1).|$|R
40|$|It is {{believed}} that quantum computing will begin {{to have an impact}} around year 2010. Much work is done on physical realization and synthesis of quantum circuits, but nothing so far on the problem of generating tests and localization of faults for such circuits. Even fault models for quantum circuits have been not formulated yet. We propose an approach to test generation for a wide category of fault models of single and multiple faults. It uses deterministic and probabilistic tests to detect faults. A <b>Fault</b> <b>Table</b> is created that includes probabilistic information. If possible, deterministic tests are first selected, while covering faults with tests, in order to shorten the total length of the test sequence. The method is applicable to both binary and ternary quantum circuits. The system generates test sequences and adaptive trees for fault localization for small binary and ternary quantum circuits...|$|E
40|$|V. CONCLUSIONS {{transition}} from qiE Q to qjE Q when the input x is applied. First- and second-order resolution {{are related to}} simple F is the output function F: Q-+ Y. cover algebra concepts that are in turn used to develop We can extend the function M to X*, the set of all input procedures for finding the resolutions from the generalized sequences of finite length, by defining M(A) =I 4 and <b>fault</b> <b>table.</b> The procedures given here are improvements M(XiX 2. = M(XI) M(X 2). M(.) (1) [...] Xk) over those in [1] for resolutions over domain DA. However, there are applications in which domains other than DA are where A is the input sequence of length zero and In is the useful. In these cases, the second-order resolution procedure identity matrix of size n. Then the ij entry of M(u) is the in [1] is still of value in a modified form. probability of a {{transition from}} qi to qj when the input se-quence u is applied...|$|E
40|$|We {{address the}} problem of quantum test set {{generation}} using measurement from a single basis and the single fault model. Experimental physicists currently test quantum circuits exhaustively, meaning that each n-bit permutative circuit requires ζ x 2 n tests to assure functionality, and for an m stage permutative circuit proven not to function properly the current method requires ζ x 2 n x m tests as the upper bound for fault localization, where zeta varies with physical implementation. Indeed, the exhaustive methods complexity grows exponentially with the number of qubits, proportionally to the number of stages in a quantum circuit and directly with zeta. This testability bound grows still exponentially with the attempted verification of quantum effects, such as the emission of a quantum source. The exhaustive method will soon not be feasible for practical application provided the number of qubits increases even a small number from {{the current state of the}} art. An algorithm is presented making fault detection feasible both now and in the foreseeable future for quantum circuits. The presented method attempts the quantum role of classical test generation and test set reduction methods known from standard binary and analog circuits. The quantum <b>fault</b> <b>table</b> is introduced, and the test generation method explained, we show that all faults can be detected that impact calculations from the computational basis. It is believed that this fundamental research will lead to the simplification of testing for commercial quantum computers...|$|E
30|$|It {{is to be}} {{expected}} that the Fault Model successfully reproduces historical seismicity (Table 1). However, it also successfully reproduces the data of earthquakes uncorrelated with late Quaternary <b>faults</b> (<b>Table</b> 2). This latter result is rather surprising since recent large shallow crustal earthquakes tend to occur in areas where no late Quaternary fault have been mapped and the importance of a “blind fault” is emphasized (e.g., Toda and Awata, 2008). However, the Fault Model is constructed by the spatial smoothing of synthetic events based on the late Quaternary fault data. In comparison with the correlation distance of 75 km used for the smoothing, those events took place not far from the nearest mapped fault and, therefore, high occurrence probabilities are estimated in areas of blind faulting. The Fault Model also shows robustness for the different time-period data (Table 3).|$|R
30|$|The Zoning P Model {{employs the}} {{original}} a- and b-values in each zone {{proposed by the}} Property and Casualty Insurance Rating Organization of Japan (2000). Tables 1, 2, and 3 show that the δAIC of this model is negative in all cases. Since the zoning method was used for distributed sources, it is logical to test the Zoning P Model against the historical data of events uncorrelated with late Quaternary <b>faults</b> (<b>Table</b> 2). However, δAIC is nearly zero and, consequently, the model does not provide much information on the spatial distribution of large events. Since the Zoning S Model is successful (Table 2), the zoning itself should not be blamed. Property and Casualty Insurance Rating Organization of Japan (2000) obtained the a- and b-values from seismicity data for 1885 to 1995. It {{is likely that the}} migration of large earthquakes over time is one cause of the poor result.|$|R
40|$|Since a smart {{distribution}} grid has {{a diversity of}} components and complicated topology; {{it is very hard}} to achieve fault early warning for each part. A fault early warning model for smart {{distribution grid}} combining a back propagation (BP) neural network with a gene sequence alignment algorithm is proposed. Firstly; the operational state of smart distribution grid is divided into four states; and a BP neural network is adopted to explore the operational state from the historical fault data of the smart distribution grid. This obtains the relationship between each state transition time sequence and corresponding fault, and is used to construct the <b>fault</b> gene <b>table.</b> Then; a state transition time sequence is obtained online periodically, which is matched with each gene in <b>fault</b> gene <b>table</b> by an improved Smith–Waterman algorithm. If the maximum match score exceeds the given threshold, the relevant fault will be detected early. Finally, plenty of time domain simulation is performed on the proposed fault early warning model to IEEE- 14 bus. The simulation results show that the proposed model can achieve efficient early fault warning of smart distribution grids...|$|R
40|$|This {{thesis is}} {{concerned}} with the detection of non-transient faults in digital networks. A procedure for detection of faults in a simple controllable Linear Sequential Circuit (LSC) over GF(2) is developed. The following is assumed: 1) The faults are those which cause the LSC to behave as if some of its primary (external) or secondary (internal) terminals were permanently stuck at zero, or permanently stuck at one; 2) That all testing must be performed on the external terminals of the LSC. The characterizing matrix B, s vectors of the form AnBdv (v=l, 2, [...] .,s), s unit input vectors and the zero input vector are used instead of the <b>fault</b> <b>table.</b> (s is the number of primary input terminals, n is the dimension of LSC, A is its characteristic matrix and Sv is the unit input vector having 1 on the position v.) It is shown that the set of s+ 1 tests is sufficient to detect the existence of any fault that belongs to the set of defined faults. The test is defined here as a procedure consisting of: (a) Application of the unit input vector (or zero input vector) followed by 2 n zero input vectors, (b) Comparison of the resulting output vectors with the vectors AnBdv. There are no faults in the LSC if and only if these vectors agree. It is further shown that for an arbitrary LSC over GF(2) realized in pseudo-canonical realization of m simple controllable LSCs, the set of (s+l). m tests is sufficient (m is the number of primary output terminals) ...|$|E
40|$|With the {{advances}} in very large scale integration (VLSI) technology, hardware is going parallel. Software, which was traditionally designed to execute on single core microprocessors, now faces the tough challenge of {{taking advantage of}} this parallelism, made available by the scaling of hardware. The work presented in this dissertation studies the acceleration of electronic design automation (EDA) software on several hardware platforms such as custom integrated circuits (ICs), field programmable gate arrays (FPGAs) and graphics processors. This dissertation concentrates on a subset of EDA algorithms which are heavily used in the VLSI design flow, and also have varying degrees of inherent parallelism in them. In particular, Boolean satisfiability, Monte Carlo based statistical static timing analysis, circuit simulation, fault simulation and <b>fault</b> <b>table</b> generation are explored. The architectural and performance tradeoffs of implementing the above applications on these alternative platforms (in comparison to their implementation on a single core microprocessor) are studied. In addition, this dissertation also presents an automated approach to accelerate uniprocessor code using a graphics processing unit (GPU). The key idea is to partition the software application into kernels in an automated fashion, such that multiple instances of these kernels, when executed in parallel on the GPU, can maximally benefit from the GPU?s hardware resources. The work presented in this dissertation demonstrates that several EDA algorithms can be successfully rearchitected to maximally harness their performance on alternative platforms such as custom designed ICs, FPGAs and graphic processors, and obtain speedups upto 800 X. The approaches in this dissertation collectively aim to contribute towards enabling the computer aided design (CAD) community to accelerate EDA algorithms on arbitrary hardware platforms...|$|E
40|$|In {{classical}} {{test and}} verification one develops a test set separating a correct circuit from a circuit containing any considered fault. Classical faults are modelled at the logical level by fault models that act on classical states. The stuck fault model, {{thought of as}} a lead connected to a power rail or to a ground, is most typically considered. A classical test set complete for the stuck fault model propagates both binary basis states, 0 and 1, through all nodes in a network and is known to detect many physical faults. A classical test set complete for the stuck fault model allows all circuit nodes to be completely tested and verifies the function of many gates. It is natural to ask if one may adapt any of the known classical methods to test quantum circuits. Of course, classical fault models do not capture all the logical failures found in quantum circuits. The first obstacle faced when using methods from classical test is developing a set of realistic quantum-logical fault models (a question which we address, but will likely remain largely open until the advent of the first quan- tum computer). Developing fault models to abstract the test problem away from the device level motivated our study. Several results are established. First, we describe typical modes of failure present in the physical design of quantum circuits. From this we develop fault models for quantum binary quantum circuits that enable testing at the logical level. The application of these fault models is shown by adapting the classical test set generation technique known as constructing a <b>fault</b> <b>table</b> to gener- ate quantum test sets. A test set developed using this method will detect each of the considered faults...|$|E
2500|$|Of the {{hundreds}} of seismogenic (earthquake causing) geologic faults in California, UCERF classifies only six faults as Type A sources, meaning there is sufficient information to both estimate and model {{the probability of a}} Magnitude (M) 6.7 or greater earthquake within 30 years. These six <b>faults</b> (summarized in <b>Table</b> A, below) are the: (1) San Andreas (split into northern and southern sections, (2) San Jacinto, (3) Elsinore, (4) Garlock, (5) Calaveras, and (6) Hayward-Rodgers Creek. [...] Faults which are known to be slipping (and therefore seismogenic) but lack sufficient information to fully model how close they might be to rupture are classified as Type B. [...] About twenty of these <b>faults</b> (see <b>Table</b> B) are estimated to have a 5% or greater chance of an M ≥ 6.7 earthquake within 30 years. An additional six areas where strain is accumulating but where knowledge is insufficient to apportion slip onto specific faults are classified as Type C sources.|$|R
30|$|Table 1 {{shows the}} seeded faults {{and number of}} data sets {{recorded}} for each fault type. The details of each fault are described in [4, 20, 21]. There are total 248 labeled data sets that are recorded for each sensor position. In testing of this technique, the last three <b>faults</b> from <b>Table</b> 1 were used {{as part of the}} unlabeled data set and the rest were part of labeled data set. For testing, the labeled data set for each position of the sensor is divided into different ratios of training and testing data set, as shown in Table 2.|$|R
40|$|AbstractFor {{diagnosing}} {{failure and}} sick rectifying elements, a fault detection and prediction method of rectifier {{was presented in}} this paper. The output voltage of rectifier was contrasted with normal simulation signal in phase to obtain the difference signal. After it was processed according to the set threshold, the coding of the difference signal was achieved. The signal coding was adopted to diagnose failure elements or sick elements. In simulation test, the <b>fault</b> code <b>tables</b> of rectifier with different control angle were given. The simulation results show {{the validity of the}} fault detection method presented in this paper...|$|R
40|$|ABSTRACT: – Algebra-logical model, {{method and}} {{algorithm}} of fault embedded diagnosis in functional blocks of SoC are proposed. The reduced SoC Functional Intellectual Property Infrastructure that {{is characterized by}} minimal set of the embedded diagnosis processes in real time and enables to realize the services: testing of the nominal functions on basis of generable input patterns and analysis of output reactions; fault diagnosis with given resolution of fault location by means of utilization of the IEEE 1500 multiprobe; fault simulation to pro-vide of realization {{of the first two}} procedures on basis of the <b>fault</b> detection <b>table</b> is presented...|$|R
5000|$|Notes for Table B. 1. List of <b>faults</b> from UCERF-2, <b>Table</b> 13. Unless {{otherwise}} noted other details are from Appendix A, <b>Table</b> 1. 2. <b>Fault</b> numbers and maps from USGS Quaternary Fault and Fold Database. Some faults lack a QFFDB entry. [...] 5. Estimated {{probability of a}} M≥6.7 event in 30 years. From UCERF-2 Table 13.|$|R
40|$|This paper {{extends the}} CMOS {{standard}} cells characterization methodology for defect based testing. The proposed methodology allows {{to find the}} types of faults which may occur in a real IC, to determine their probabilities, and to find the input test vectors which detect these faults. For shorts at the inputs two types of cell simulation conditions – “Wired-AND ” and “Wired-OR ” – are used. Examples of industrial standard cells characterization indicate that a single logic <b>fault</b> probability <b>table</b> is not sufficient. Separate tables for “Wired-AND ” and “Wired-OR ” conditions at the inputs are needed for full characterization and hierarchical test generation. 1...|$|R
40|$|New {{testing methods}} are {{required}} as {{the complexity of}} Field Programmable Gate Array (FPGA) designs grow rapidly and time-to-market demands shorten. In this {{paper we propose a}} new, physical fault injection method for the test of a system’s self-stabilizing property, that is its intrinsic ability to recover from transient faults. Therefore we inject transient <b>faults</b> in Look-Up <b>Table</b> (LUT) -based FPGA designs by dynamical, partial reconfiguration. 1...|$|R
40|$|Abstract—Many STUMPS {{architectures}} {{found in}} current chip designs allow disabling of individual scan chains for debug and diagnosis. In a recent paper {{it has been}} shown that this feature can be used for reducing the power consumption during test. Here, we present an efficient algorithm for the automated generation of a test plan that keeps fault coverage as well as test time, while significantly reducing the amount of wasted energy. A <b>fault</b> isolation <b>table,</b> which is usually used for diagnosis and debug, is employed to accurately determine scan chains that can be disabled. The algorithm was successfully applied to large industrial circuits and identifies a very large amount of excess pattern shift activity. Categories and Subject Descriptors—B. 8. 1 [Hardware]...|$|R
40|$|This article {{describes}} technology for diagnosing SoC HDL-models, based on transactional graph. Diagnosis method is focused to considerable decrease {{the time of}} fault detection and memory for storage of diagnosis matrix by means of forming ternary relations {{in the form of}} test, monitor, and functional component. The following problems are solved: creation of digital system model in the form of transaction graph and multi-tree of <b>fault</b> detection <b>tables,</b> as well as ternary matrices for activating functional components in tests, relative to the selected set of monitors; development of a method for analyzing the activation matrix to detect the faults with given depth and synthesizing logic functions for subsequent embedded hardware fault diagnosing. Comment: 7 pages; International Conference on VLSI, MEMS and NEMS, VMN- 2012, 24 th - 25 th January 2012, Noidar, Uttar, Paradesh, Indi...|$|R
