61|7|Public
25|$|By early 1992, {{the search}} was on for a good byte stream {{encoding}} of multi-byte character sets. The draft ISO 10646 standard contained a non-required annex called UTF-1 that provided a byte stream encoding of its 32-bit code points. This encoding was not satisfactory on performance grounds, among other problems, and the biggest problem was probably {{that it did not}} have a clear separation between ASCII and non-ASCII: new UTF-1 tools would be backward compatible with ASCII-encoded text, but UTF-1-encoded text could confuse existing code expecting ASCII (or <b>extended</b> <b>ASCII),</b> because it could contain continuation bytes in the range 0x21–0x7E that meant something else in ASCII, e.g., 0x2F for '/', the Unix path directory separator, and this example is reflected in the name and introductory text of its replacement. The table below was derived from a textual description in the annex.|$|E
2500|$|Fallback and auto-detection: [...] UTF-8 {{provided}} {{backwards compatibility}} for 7-bit ASCII, but much software and data uses 8-bit <b>extended</b> <b>ASCII</b> encodings designed {{prior to the}} adoption of Unicode to represent the character sets of European languages. [...] Part of the popularity of UTF-8 {{is due to the fact}} that it provides a form of backward compatibility for these as well. [...] A UTF-8 processor which erroneously receives an <b>extended</b> <b>ASCII</b> file as input can [...] "fall back" [...] or replace 8-bit bytes using the appropriate code-point in the Unicode Latin-1 Supplement block, when the 8-bit byte appears outside a valid multi-byte sequence. Though it does happen, the 8-bit characters in <b>extended</b> <b>ASCII</b> encodings do not usually have the correct form for UTF-8 multi-byte sequences. This is because the 8-bit bytes which introduce multi-byte sequences in UTF-8 are primarily accented letters (mostly vowels) in the common <b>extended</b> <b>ASCII</b> encodings, and the UTF-8 continuation bytes are punctuation and symbol characters. [...] To appear as a valid UTF-8 multi-byte sequence, a series of 2 to 4 <b>extended</b> <b>ASCII</b> 8-bit characters would have to be an unusual combination of symbols and accented letters. In short, <b>extended</b> <b>ASCII</b> character sequences which look like valid UTF-8 multi-byte sequences are unlikely. Fallback errors will be false negatives, and these will be rare. Moreover, in many applications, such as text display, the consequence of incorrect fallback is usually slight. Only legibility is affected, and not significantly. [...] These two things make fallback feasible, if somewhat imperfect. Indeed, as discussed further below, the HTML5 standard requires that erroneous bytes in supposed UTF-8 data be replaced upon display on the assumption that they are Windows-1252 characters. [...] The presence of invalid 8-bit characters outside valid multi-byte sequences can also be used to [...] "auto-detect" [...] that an encoding is actually an <b>extended</b> <b>ASCII</b> encoding rather than UTF-8, and decode it accordingly. A UTF-8 stream may simply contain errors, resulting in the auto-detection scheme producing false positives; but auto-detection is successful in the majority of cases, especially with longer texts, and is widely used.|$|E
2500|$|The {{most popular}} form of online {{graphics}} was ANSI art, which combined the IBM <b>Extended</b> <b>ASCII</b> character set's blocks and symbols with ANSI escape sequences to allow changing colors on demand, provide cursor control and screen formatting, and even basic musical tones. During the late 1980s and early 1990s, most BBSes used ANSI to make elaborate welcome screens, and colorized menus, and thus, ANSI support was a sought-after feature in terminal client programs. The development of ANSI art became {{so popular that}} it spawned an entire BBS [...] "artscene" [...] subculture devoted to it.|$|E
50|$|ISO/IEC 4873 {{introduced}} 32 additional control codes {{defined in}} the 80-9F hexadecimal range, as part of <b>extending</b> the 7-bit <b>ASCII</b> encoding to become an 8-bit system.|$|R
25|$|BBSes were {{generally}} text-based, rather than GUI-based, and early BBSes conversed using the simple ASCII character set. However, some home computer manufacturers <b>extended</b> the <b>ASCII</b> character set {{to take advantage}} of the advanced color and graphics capabilities of their systems. BBS software authors included these extended character sets in their software, and terminal program authors included the ability to display them when a compatible system was called. Atari's native character set was known as ATASCII, while most Commodore BBSes supported PETSCII. PETSCII was also supported by the nationwide online service Quantum Link.|$|R
50|$|Later, {{computer}} manufacturers {{began to}} make use of the spare bit to <b>extend</b> the <b>ASCII</b> character set beyond its limited set of English alphabet characters. 8-bit extensions such as IBM code page 37, PETSCII and ISO 8859 became commonplace, offering terminal support for Greek, Cyrillic, and many others. However, such extensions were still limited in that they were region specific and often could not be used in tandem. Special conversion routines had to be used to convert from one character set to another, often resulting in destructive translation when no equivalent character existed in the target set.|$|R
2500|$|The {{character}} set was originally introduced by Hewlett-Packard as <b>extended</b> <b>ASCII</b> 7-bit codepage named HP Roman Extension (also known as RE, code page 1050, CP1050 or ibm-1050), which existed {{at least since}} 1978. On some systems it was also accessible as 8-bit codepage. Before the name [...] "Roman-8" [...] was established for the 8-bit variant in 1983, this was sometimes called [...] "8-bit mode", [...] "8-bit Roman Extension" [...] or [...] "HP Roman-8 Extension". Over the years both variants were revised to include more characters. The final 1985 revision of the {{character set}} was also standardized as codepage 1050 by IBM in 1989.|$|E
50|$|UTF-8 is true <b>extended</b> <b>ASCII,</b> as {{are some}} Extended Unix Code encodings.|$|E
5000|$|... {{at the end}} of the {{alphabet}} (as in Swedish or in <b>extended</b> <b>ASCII).</b>|$|E
40|$|The {{date range}} is 1761 - 90. About 300, 000 words have been {{transcribed}} and corrected. The corpus {{is currently in}} two forms: plain text with COCOA-style annotations, like the Helsinki corpus and HTML. The files are <b>extended</b> (8 -bit) <b>Ascii</b> (ANSI/Windows default coding), and the text is coded {{as far as possible}} according to the conventions used in the Helsinki Corpus, that is, with COCOA-style brackets giving information on writer, date, page breaks, etc, enclosed within carets...|$|R
40|$|Security and secrecy {{are some}} of the {{significant}} concerns in the communications world. In the last years, several encryption techniques had been proposed to improve the secrecy of the information transition. Chaos-based encryption techniques are being exceedingly studied as part of the because of the random-look nature and very unpredictable of the chaotic signals. In this study, a digital-based mobile communication system was proposed that uses chaotic encryption code, Arduino platforms was utilized for this work because it possess an open-source prototyping platform, software and hardware very accessible and extremely flexible to be customized and <b>extended.</b> The <b>ASCII</b> code of input message signal was encrypted using a Chaotic Random Number Generator it will send to the receiver side through mobile GSM system. In the receiver side, the ASCII coded message was decrypted using the same Chaotic Random Number Generator code for decryption. The target of this system is to make a more security based on the mobile communication system, the obtained results of this study confirm a secure system for sending and receiving SMS-based on the mobile communication system...|$|R
40|$|The {{problem of}} {{automatic}} insertion of diacritics into an electronic text is well justified for several languages. Even if the diacritical characters concerned {{are present in}} the <b>extended</b> 8 -bit <b>ASCII</b> charset (as the case is with French) any 7 -bit filtering transmission of such a text will corrupt it. The situation is even worse when the diacritic characters are not in the 8 -bit ASCII charset. To find a way to automating the diacritics insertion is worthy not only for old valuable texts stored in electronic form, but also for contemporary electronic texts as they continue to be produced in non-diacritical form. The reasons for this could be many, including the lack of localised and standardised keyboards. Ergonomic factors can also be mentioned (if someone is supposed to press more than two keys to get a diacritical character, then, mainly in informal communication (e. g. e-mail), he/she will probably take the easiest one-stroke solution). In Romanian, every second word might contain at least one diacritical character and for large texts that lack diacritics, to insert them manually is highly time-consuming, boring and errorprone. Unfortunately, the automatic recovery of diacritics is non deterministic whatever the language which uses them. Various approaches can be envisaged to solve this problem but, when speed is of the utmost importance, then the approaches to be made are few. We present such an approach for Romanian language based on our recent results i...|$|R
5000|$|... all ASCII bytes (0x00 to 0x7F) {{have the}} same meaning in all {{variants}} of <b>extended</b> <b>ASCII,</b> ...|$|E
50|$|Apple Computer {{introduced}} {{their own}} eight-bit <b>extended</b> <b>ASCII</b> codes in Mac OS, such as Mac OS Roman.|$|E
5000|$|Fallback and auto-detection: UTF-8 {{provided}} {{backwards compatibility}} for 7-bit ASCII, but much software and data uses 8-bit <b>extended</b> <b>ASCII</b> encodings designed {{prior to the}} adoption of Unicode to represent the character sets of European languages. Part of the popularity of UTF-8 {{is due to the fact}} that it provides a form of backward compatibility for these as well. A UTF-8 processor which erroneously receives an <b>extended</b> <b>ASCII</b> file as input can [...] "fall back" [...] or replace 8-bit bytes using the appropriate code-point in the Unicode Latin-1 Supplement block, when the 8-bit byte appears outside a valid multi-byte sequence. Though it does happen, the 8-bit characters in <b>extended</b> <b>ASCII</b> encodings do not usually have the correct form for UTF-8 multi-byte sequences. This is because the 8-bit bytes which introduce multi-byte sequences in UTF-8 are primarily accented letters (mostly vowels) in the common <b>extended</b> <b>ASCII</b> encodings, and the UTF-8 continuation bytes are punctuation and symbol characters. To appear as a valid UTF-8 multi-byte sequence, a series of 2 to 4 <b>extended</b> <b>ASCII</b> 8-bit characters would have to be an unusual combination of symbols and accented letters. In short, <b>extended</b> <b>ASCII</b> character sequences which look like valid UTF-8 multi-byte sequences are unlikely. Fallback errors will be false negatives, and these will be rare. Moreover, in many applications, such as text display, the consequence of incorrect fallback is usually slight. Only legibility is affected, and not significantly. These two things make fallback feasible, if somewhat imperfect. Indeed, as discussed further below, the HTML5 standard requires that erroneous bytes in supposed UTF-8 data be replaced upon display on the assumption that they are Windows-1252 characters. The presence of invalid 8-bit characters outside valid multi-byte sequences can also be used to [...] "auto-detect" [...] that an encoding is actually an <b>extended</b> <b>ASCII</b> encoding rather than UTF-8, and decode it accordingly. A UTF-8 stream may simply contain errors, resulting in the auto-detection scheme producing false positives; but auto-detection is successful in the majority of cases, especially with longer texts, and is widely used.|$|E
50|$|There are {{two groups}} of code pages in Windows systems: OEM and ANSI code pages. Code pages {{in both of these}} groups are <b>extended</b> <b>ASCII</b> code pages.|$|E
50|$|Stanford <b>Extended</b> <b>ASCII</b> (SEASCII) is a {{derivation}} of the 7-bit ASCII {{character set}} {{developed at the}} Stanford Artificial Intelligence Laboratory (SAIL/SU-AI) in the early 1970s. Not all symbols match ASCII.|$|E
50|$|The popular game {{creation}} system (GCS) ZZT used ANSI graphics exclusively. A later GCS {{based on}} the same concept, MegaZeux, allowed users to modify the <b>extended</b> <b>ASCII</b> character set as well.|$|E
5000|$|There {{are many}} <b>extended</b> <b>ASCII</b> {{encodings}} (more than 220 DOS and Windows codepages). EBCDIC ("the other" [...] major 8-bit character code) likewise developed many extended variants (more than 186 EBCDIC codepages) over the decades.|$|E
5000|$|A {{traditional}} <b>extended</b> <b>ASCII</b> {{character set}} adds up-to 128 characters to the ASCII set. Vietnamese requires 134 additional letter-diacritic combinations, which is six too many. There are essentially three {{different ways to}} handle this problem: ...|$|E
50|$|Hack {{implements}} a graphical {{user interface}} using arrangements of ASCII or <b>Extended</b> <b>ASCII</b> glyphs to represent game elements. Some later ports of Hack, on AmigaOS for example, use graphical tiles in place of these letters and symbols.|$|E
50|$|ISO/IEC 6937 is not <b>extended</b> <b>ASCII</b> {{because its}} code point 0x24 {{corresponds}} to the general currency sign (¤) {{rather than to the}} dollar sign ($), but it is an extended version of the International Reference Version of ISO 646.|$|E
5000|$|Sequences of {{the form}} , where [...] "0x" [...] is literal, and [...] "FF" [...] {{represents}} any two-digit hexadecimal number, are replaced with the corresponding single-byte value. This {{can be used to}} embed non-printing ASCII characters, or <b>extended</b> <b>ASCII</b> characters.|$|E
50|$|Shift JIS is {{not true}} <b>extended</b> <b>ASCII,</b> because {{although}} ASCII characters are encoded {{the same as in}} ASCII (except for the backslash; its position is used for the yen character), multi-byte characters can also include ASCII bytes (0x00-0x7F). Shift JIS can directly be used in programming languages and languages such as HTML (if accepting that backslash looks like ¥), because the bytes used for free text delimiters are not used as part of non-ASCII characters. UTF-16 is even less <b>extended</b> <b>ASCII</b> because ASCII characters are stored as two bytes with one byte equal to 0x00. Porting an existing system to support character sets as Shift JIS or UTF-16 is complicated and bug prone.|$|E
50|$|Some multi-byte {{character}} encodings (character encodings {{that can}} handle more than 256 different characters) are also true <b>extended</b> <b>ASCII.</b> That means all ASCII characters are encoded with a single byte with the value that is used in ASCII to encode that character. They {{can be used in}} file formats where only ASCII bytes are used for keywords and file format syntax, while bytes 0x80-0xFF might be used for free text, including most programming languages, where language keywords, variable names, and function names must be in ASCII, but string constants and comments can use non-ASCII characters. This makes it much easier to introduce a multi-byte character set into existing systems that use <b>extended</b> <b>ASCII.</b>|$|E
5000|$|DOS did {{not support}} Chinese characters, which are not in <b>Extended</b> <b>ASCII.</b> Many {{companies}} in Taiwan developed their own IBM PC compatible traditional Chinese operating system running on DOS, which were mutually incompatible between the OS, such as Kuo Chia (國喬) and Acer.|$|E
50|$|For {{programming}} {{languages and}} document languages such as C and HTML, {{the principle of}} <b>Extended</b> <b>ASCII</b> is important, since it enables many different encodings and therefore many human languages to be supported with little extra programming effort in the software that interprets the computer-readable language files.|$|E
50|$|Various {{techniques}} were devised to send files over Usenet, such as uuencoding and Base64. Later Usenet software allowed 8 bit <b>Extended</b> <b>ASCII,</b> which permitted new techniques like yEnc. Large files were broken up {{to reduce the}} effect of a corrupted download, but the unreliable nature of Usenet remained.|$|E
50|$|UTF-8 (originally {{developed}} for Plan 9) {{has become the}} main storage encoding on most Unix-like operating systems (though others are also used by some libraries) {{because it is a}} relatively easy replacement for traditional <b>extended</b> <b>ASCII</b> character sets. UTF-8 is also the most common Unicode encoding used in HTML documents on the World Wide Web.|$|E
50|$|Apogee {{started in}} 1987 {{with the release}} of Scott Miller's Kingdom of Kroz, which used crude <b>extended</b> <b>ASCII</b> {{characters}} as graphics. Nevertheless, the game sold quite well and Apogee was born. In 1991, George Broussard joined the company as co-owner, bringing with him several games of his that were previously released under the name Micro F/X.|$|E
50|$|The {{representation}} of a character within the computer memory, in storage, and in data transmission, is dependent on a particular character encoding scheme. For example, an ASCII (or <b>extended</b> <b>ASCII)</b> scheme will use a single byte of computer memory, while a UTF-8 scheme will use 1 or more bytes, depending on the particular character being encoded.|$|E
5000|$|Visual Basic 1.0 for DOS was {{released}} in September 1992. The language itself was not quite compatible with Visual Basic for Windows, as it was actually the next version of Microsoft's DOS-based BASIC compilers, QuickBASIC and BASIC Professional Development System. The interface used a text user interface, using <b>extended</b> <b>ASCII</b> characters to simulate {{the appearance of a}} GUI.|$|E
50|$|Many {{languages}} {{or language}} families {{not based on}} the Latin alphabet such as Greek, Cyrillic, Arabic, or Hebrew have historically been represented on computers with different 8-bit <b>extended</b> <b>ASCII</b> encodings. Written East Asian languages, specifically Chinese, Japanese, and Korean, use far more characters than can be represented in an 8-bit computer byte and were first represented on computers with language-specific double byte encodings.|$|E
50|$|The {{parallel}} port interface was originally {{known as the}} Parallel Printer Adapter on IBM PC-compatible computers. It was primarily designed to operate printers that used IBM's 8-bit <b>extended</b> <b>ASCII</b> character set to print text, but {{could also be used}} to adapt other peripherals. Graphical printers, along with a host of other devices, have been designed to communicate with the system.|$|E
50|$|TIS-620 is a {{conventionally}} structured <b>Extended</b> <b>ASCII</b> {{national character}} set that retains full compatibility with 7-bit ASCII {{and uses the}} 8-bit range hex A1 to FB for encoding the Thai alphabet. Due to the complex combining nature of Thai vowels and diacritics, TIS-620 is intended for information interchange only, and an additional display engine is required to compose characters correctly.|$|E
50|$|The {{meaning of}} each {{extended}} code point can {{be different in}} every encoding. In order to correctly interpret and display text data (sequences of characters) that includes extended codes, hardware and software that reads or receives the text must use the specific <b>extended</b> <b>ASCII</b> encoding that applies to it. Applying the wrong encoding causes irrational substitution of many or all extended characters in the text.|$|E
