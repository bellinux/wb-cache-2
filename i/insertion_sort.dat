281|30|Public
25|$|List <b>insertion</b> <b>sort</b> is {{a variant}} of <b>insertion</b> <b>sort.</b> It reduces the number of movements.|$|E
25|$|Bubble sort is {{asymptotically}} {{equivalent in}} running time to <b>insertion</b> <b>sort</b> {{in the worst}} case, but the two algorithms differ greatly {{in the number of}} swaps necessary. Experimental results such as those of Astrachan have also shown that <b>insertion</b> <b>sort</b> performs considerably better even on random lists. For these reasons many modern algorithm textbooks avoid using the bubble sort algorithm in favor of <b>insertion</b> <b>sort.</b>|$|E
25|$|The average case is also quadratic, {{which makes}} <b>insertion</b> <b>sort</b> {{impractical}} for sorting large arrays. However, <b>insertion</b> <b>sort</b> {{is one of}} the fastest algorithms for sorting very small arrays, even faster than quicksort; indeed, good quicksort implementations use <b>insertion</b> <b>sort</b> for arrays smaller than a certain threshold, also when arising as subproblems; the exact threshold must be determined experimentally and depends on the machine, but is commonly around ten.|$|E
5000|$|Disperse: Read over A, {{dropping}} each {{key into}} its bucket in A2; <b>insertion</b> <b>sorting</b> as needed.|$|R
5000|$|... #Caption: Unlike bucket sorting which sorts {{after all}} the buckets are filled, the {{elements}} are <b>insertion</b> <b>sorted</b> as they are inserted ...|$|R
40|$|Description This package {{proposes a}} model-based {{clustering}} algorithm for ranking data. Multivariate rankings {{as well as}} partial rankings are taken into account. This algorithm {{is based on an}} extension of the <b>Insertion</b> <b>Sorting</b> Rank (ISR) model for ranking data, which is a meaningful and effective model parametrized by a position parameter (the modal ranking,quoted by mu) and a dispersion parameter (quoted by pi). The heterogeneity of the rank population is modelled by a mixture of ISR, whereas conditional independence assumption is considered for multivariate rankings...|$|R
25|$|A variant named binary {{merge sort}} uses a binary <b>insertion</b> <b>sort</b> to sort groups of 32 elements, {{followed}} by a final sort using merge sort. It combines the speed of <b>insertion</b> <b>sort</b> on small data sets {{with the speed of}} merge sort on large data sets.|$|E
25|$|<b>Insertion</b> <b>sort</b> iterates, {{consuming}} one input element each repetition, {{and growing}} a sorted output list. At each iteration, <b>insertion</b> <b>sort</b> removes one element from the input data, finds the location it belongs within the sorted list, and inserts it there. It repeats until no input elements remain.|$|E
25|$|Bubble sort also interacts poorly {{with modern}} CPU hardware. It {{produces}} {{at least twice}} as many writes as <b>insertion</b> <b>sort,</b> twice as many cache misses, and asymptotically more branch mispredictions. Experiments by Astrachan sorting strings in Java show bubble sort to be roughly one-fifth as fast as an <b>insertion</b> <b>sort</b> and 70% as fast as a selection sort.|$|E
40|$|Abstract. A {{variant of}} the Ford-Johnson or merge <b>insertion</b> <b>sorting</b> {{algorithm}} that we called four Ford-Johnson (4 FJ, for short) is presented and proved to execute exactly {{the same number of}} comparisons than the Ford-Johnson algorithm. The main advantage of our algorithm is that, instead of recursively working over lists of size the half of the input, as the Ford-Johnson algorithm does, 4 FJ recursively works over lists of size the quarter of the input. This allows for implementations of data structures for coordinating the recursive calls of size only 33 % of the ones needed for the Ford-Johnson algorithm...|$|R
40|$|We {{consider}} {{the problem of}} sorting on a one-dimensional sub-bus array of processors. The sub-bus broadcast operation makes possible {{a new class of}} parallel sorting algorithms whose complexity we analyze with the parallel <b>insertion</b> model. A <b>sorting</b> method, or sorting strategy, in the parallel insertion model, uses a sequence of left and right insertion steps, of which we give two types: greedy insertion steps and simple insertion steps. For two restricted classes of parallel <b>insertion</b> <b>sorting,</b> the one-way and the alternating sorting strategies, we give lower bounds and optimal sorting strategies that exactly match the lower bounds. Optimal alternating sorting strategies are demonstrated to use a factor of two fewer insertion steps on average than oddeven transposition sort and any optimal one-way sorting strategy. For general sorting strategies, we give a weak lower bound and consider a sorting strategy that uses the fewest greedy insertion steps. Finally, we discuss the issues involve [...] ...|$|R
40|$|International audienceRankcluster is {{the first}} R package {{dedicated}} to ranking data. This package proposes modelling and clustering tools for ranking data, potentially multivariate and partial. Ranking data are modelled by the <b>Insertion</b> <b>Sorting</b> Rank (isr) model, which is a meaningful model parametrized by a central ranking and a dispersion parameter. A conditional independence assumption allows {{to take into account}} multivariate rankings, and clustering is performed by the mean of mixtures of multivariate isr model. The clusters parameters (central rankings and dispersion parameters) help the practitioners in the interpretation of the clustering. Moreover, the Rankcluster package provides an estimation of the missing ranking positions when rankings are partial. After an overview of the mixture of multivariate isr model, the Rankcluster package is described and its use is illustrated through two real datasets analysis...|$|R
25|$|Two of the {{simplest}} sorts are <b>insertion</b> <b>sort</b> and selection sort, {{both of which are}} efficient on small data, due to low overhead, but not efficient on large data. <b>Insertion</b> <b>sort</b> is generally faster than selection sort in practice, due to fewer comparisons and good performance on almost-sorted data, and thus is preferred in practice, but selection sort uses fewer writes, and thus is used when write performance is a limiting factor.|$|E
25|$|When people {{manually}} sort {{cards in}} a bridge hand, most use {{a method that}} is similar to <b>insertion</b> <b>sort.</b>|$|E
25|$|<b>Insertion</b> <b>sort</b> is {{very similar}} to {{selection}} sort. As in selection sort, after k passes through the array, the first k elements are in sorted order. For selection sort these are the k smallest elements, while in <b>insertion</b> <b>sort</b> they are whatever the first k elements were in the unsorted array. Insertion sort's advantage is that it only scans as many elements as needed to determine the correct location of the k+1st element, while selection sort must scan all remaining elements to find the absolute smallest element.|$|E
40|$|Sorting {{algorithms}} are {{an intrinsic}} part of functional programming folklore as they exemplify algorithm design using folds and unfolds. This {{has given rise}} to an informal notion of duality among <b>sorting</b> algorithms: <b>insertion</b> <b>sorts</b> are dual to selection sorts. Using bialgebras and distributive laws, we formalise this notion within a categorical setting. We use types as a guiding force in exposing the recursive structure of bubble, insertion, selection, quick, tree, and heap sorts. Moreover, we show how to distill the computational essence of these algorithms down to one-step operations that are expressed as natural transformations. From this vantage point, the duality is clear, and one side of the algorithmic coin will neatly lead us to the other `for free'. As an optimisation, the approach is also extended to paramorphisms and apomorphisms, which allow for more efficient implementations of these algorithms than the corresponding folds and unfolds...|$|R
25|$|The {{algorithm}} below uses a trailing pointer for the <b>insertion</b> {{into the}} <b>sorted</b> list. A simpler recursive method rebuilds the list each time (rather than splicing) and can use O(n) stack space.|$|R
40|$|Abstract: This paper proposes {{the first}} model-based {{clustering}} algorithm dedicated to multivariate partial ranking data. This {{is an extension}} of the <b>Insertion</b> <b>Sorting</b> Rank (isr) model for ranking data, which is a meaningful and effective model obtained by modelling the ranking generating process assumed to be a sorting algorithm. The heterogeneity of the rank population is modelled by a mixture of isr, whereas conditional independence assumption allows the extension to multivariate ranking. Maximum likelihood estimation is performed through a SEM-Gibbs algorithm, and partial rankings are considered as missing data, what allows to simulate them during the estimation process. After having validated the estimation algorithm on simulations, three real datasets are studied: the 1980 American Psychological Association (APA) presidential election votes, the results of French students to a general knowledge test and the votes of the European countries to the Eurovision song contest. For each application, the proposed model shows relevant adequacy and leads to significant interpretation. In particular, regional alliances between European countries are exhibited in the Eurovision contest, which are often suspected but never proved...|$|R
25|$|<b>Insertion</b> <b>sort</b> is {{a simple}} sorting {{algorithm}} that is relatively efficient for small lists and mostly sorted lists, and is often used as part of more sophisticated algorithms. It works by taking elements from the list {{one by one and}} inserting them in their correct position into a new sorted list. In arrays, the new list and the remaining elements can share the array's space, but insertion is expensive, requiring shifting all following elements over by one. Shellsort (see below) is a variant of <b>insertion</b> <b>sort</b> that is more efficient for larger lists.|$|E
25|$|The only {{significant}} advantage that bubble sort has over most other implementations, even quicksort, but not <b>insertion</b> <b>sort,</b> {{is that the}} ability to detect that the list is sorted efficiently is built into the algorithm. When the list is already sorted (best-case), the complexity of bubble sort is only O(n). By contrast, most other algorithms, even those with better average-case complexity, perform their entire sorting process on the set and thus are more complex. However, not only does <b>insertion</b> <b>sort</b> have this mechanism too, but it also performs better on a list that is substantially sorted (having a small number of inversions).|$|E
25|$|If {{the cost}} of {{comparisons}} exceeds {{the cost of}} swaps, {{as is the case}} for example with string keys stored by reference or with human interaction (such as choosing one of a pair displayed side-by-side), then using binary <b>insertion</b> <b>sort</b> may yield better performance. Binary <b>insertion</b> <b>sort</b> employs a binary search to determine the correct location to insert new elements, and therefore performs ⌈log2(n)⌉ comparisons in the worst case, which is O(n log n). The algorithm as a whole still has a running time of O(n2) on average because of the series of swaps required for each insertion.|$|E
40|$|Binary Trees are {{examined}} comb ina tori ally {{with the view}} of providing information useful in analyzing algorithms based on this widely used storage structure. Exact and asymptotic results are given for equally likely trees and those grown by binary <b>insertion</b> tree <b>sorts</b> applied to random strings of key symbols. An appendix is provided with tabulations of results. supported by the Foundation Research Program with funds provided by the Chief of Naval Research, Arlington, Virginia, during FY 76 [URL]...|$|R
40|$|Automatic text summarisation is the {{technique}} where {{a computer program}} summarises a text. One summarisation technique is to, on linguistical and statistical grounds, extract sentences that {{are central to the}} text and use them to form a shorter text, the summary. In this case, automatically summarised text can sometimes result in dangling anaphors (i. e. broken anaphoric references). This {{is due to the fact}} that the sentences are extracted without making any deeper linguistic analysis of the text. We will in this thesis show a novel method to resolve some types of pronouns and to summarise the text such that coherence and important information is preserved. The method is implemented as a text pre-processor, called PRM (Pronoun Resolution Module) written in Perl. PRM uses lists of likely focuses (Sidner 1984), here called focus applicants. These lists are by order of <b>insertion</b> <b>sorted</b> in order of likelihood. Choice of applicant for an anaphor is based upon salience (represented by the antecedents position in a list) and semantic likelihood (based on what list the antecedent is to be found in). The latter is determined by using semantic information in a noun lexicon. This method enables us to resolve anaphors non-linearly. The domain is Swedish HTML-tagged newspape...|$|R
40|$|Magister Scientiae - MScOur {{main results}} are that splay trees are faster for <b>sorted</b> <b>insertion,</b> where AVL trees are faster for random insertion. For searching, skip lists are faster than single class {{top-down}} splay trees, but two-class and multi-class top-down splay trees can behave better than skip lists. South Afric...|$|R
25|$|For example, simple, comparison-based sorting {{algorithms}} are quadratic (e.g. <b>insertion</b> <b>sort),</b> {{but more}} advanced algorithms {{can be found}} that are subquadratic (e.g. Shell sort). No general-purpose sorts run in linear time, but the change from quadratic to sub-quadratic is of great practical importance.|$|E
25|$|Selection sort is an in-place {{comparison}} sort. It has O(n2) complexity, {{making it}} inefficient on large lists, and generally performs {{worse than the}} similar <b>insertion</b> <b>sort.</b> Selection sort is noted for its simplicity, and also has performance advantages over more complicated algorithms in certain situations.|$|E
25|$|Shellsort {{was invented}} by Donald Shell in 1959. It {{improves}} upon bubble sort and <b>insertion</b> <b>sort</b> by moving out of order elements more than one position at a time. The concept behind Shellsort is that both of these algorithms perform in O(kn) time, where k is the greatest distance between two out-of-place elements. This means that generally, they perform in O(n2), but for data that is mostly sorted, {{with only a few}} elements out of place, they perform faster. So, by first sorting elements far away, and progressively shrinking the gap between the elements to sort, the final sort computes much faster. One implementation can be described as arranging the data sequence in a two-dimensional array and then sorting the columns of the array using <b>insertion</b> <b>sort.</b>|$|E
3000|$|... 2) to sort m servers [31]. However, {{the power}} profile for cloud-computing data center servers are available. The energy profile sorting {{can be done}} prior to the server’s {{activation}} for function. Therefore, {{the complexity of the}} MESF task scheduling scheme is reduced to <b>insertion</b> of a <b>sorted</b> list, which has a time complexity of O(m [...]...|$|R
40|$|The {{continuous}} {{growth in}} international container traffic volumes makes it ever {{more important for}} carriers to optimize their service network. In this thesis, we present a multi-start local search algorithm for solving the routing and scheduling problem in liner shipping. The objective {{is to find a}} service network of routes, given the demand between ports, that maximizes profit. The algorithm consists of a randomized initialization phase that generates initial net-works, and a local search phase that tries to improve the solution using local search oper-ators. For each phase we present different implementations, such that several algorithm configurations are obtained, representing different multi-start local search heuristics. For the first phase, we propose the quantity <b>sort</b> <b>insertion</b> heuristic, and the profit-driven <b>sort</b> <b>insertion</b> heuristic. For the second phase, we propose three local search operators. The route-length operator removes ports from round trips that incur more costs than revenue, and tries to allocate unassigned cargoes by adding ports to round trips. The port-exchange operator relocates ports within a route or between routes in an attemp...|$|R
40|$|Given {{an array}} with n elements, {{we want to}} {{rearrange}} them in ascending order. Sorting algorithms such as the Bubble, <b>Insertion</b> and Selection <b>Sort</b> all have a quadratic time complexity that limits their use {{when the number of}} elements is very big. In this paper, we introduce Merge Sort, a divide-and overcome algorithm to sort an N element array. We evaluate the O(NlogN) time complexity of merge sort theoretically and empirically. Our results show a large improvement in efficiency over other algorithms...|$|R
25|$|When {{the number}} of {{elements}} is below some threshold (perhaps ten elements), switch to a non-recursive sorting algorithm such as <b>insertion</b> <b>sort</b> that performs fewer swaps, comparisons or other operations on such small arrays. The ideal 'threshold' will vary based {{on the details of}} the specific implementation.|$|E
25|$|The {{best case}} input is an array {{that is already}} sorted. In this case <b>insertion</b> <b>sort</b> has a linear running time (i.e., O(n)). During each iteration, the first {{remaining}} element of the input is only compared with the right-most element of the sorted subsection of the array.|$|E
25|$|Although {{bubble sort}} {{is one of}} the {{simplest}} sorting algorithms to understand and implement, its O(n2) complexity means that its efficiency decreases dramatically on lists of more than a small number of elements. Even among simple O(n2) sorting algorithms, algorithms like <b>insertion</b> <b>sort</b> are usually considerably more efficient.|$|E
40|$|One of the {{fundamental}} issues in Computer Science is the ordering of a list of items- known as sorting. Sorting algorithms such as the Bubble, <b>Insertion</b> and Selection <b>Sort,</b> all have a quadratic time complexity O(N 2) that limits their use {{when the number of}} elements is very large. This paper presents Use-Me sort. It sorts a list by making the use of already sorted elements present in the list. Moreover, it provides a trade-off between Space and Time Complexity with better performance than the existing sorting algorithms of the O (N 2) class...|$|R
40|$|In {{this work}} we study two {{variants}} of a bucketing game. This game {{is used for}} the lower bound proof of time complexity of item <b>insertion</b> into a <b>sorted</b> array, a data structure for the order maintenance problem. We show that these two variants of the bucketing game have the same time complexity up to a constant factor. Then we show that sorted arrays can use cache efficiently for certain operations. Finally, we present one implementation of the order maintenance data structure using the array of size n 1 +e...|$|R
40|$|We {{show the}} {{importance}} of sequential sorting {{in the context of}} in memory parallel sorting of large data sets of 64 bit keys. First, we analyze several sequential strategies like Straight <b>Insertion,</b> Quick <b>sort,</b> Radix sort and CC-Radix sort. As a consequence of the analysis, we propose a new algorithm that we call Sequential Counting Split Radix sort, SCS-Radix sort. SCS-Radix sort is a combination of some of the algorithms analyzed and other new ideas. There are three important contributions in SCS-Radix sort. First, the work saved by detecting data skew dynamically. Second, the exploitation of the memory hierarchy done by the algorithm. Third, the execution time stability of SCS-Radix when sorting data sets with different characteristics. We evaluate the use of SCS-Radix sort {{in the context of a}} parallel sorting algorithm on an SGI Origin 2000. The parallel algorithm is from 1 : 2 to 45 times faster using SCS-Radix sort than using Radix sort or Quick sort. ...|$|R
