40|261|Public
5000|$|There are {{models for}} which it is either very {{difficult}} or even impossible to derive analytical expressions for the elements of the Jacobian. Then, the numerical approximationis obtained by calculation of [...] for [...] and [...] The <b>increment,,</b> <b>size</b> should be chosen so the numerical derivative is not subject to approximation error by being too large, or round-off error by being too small.|$|E
50|$|Kit-of-parts {{architecture}} involves {{organizing the}} individual parts and raw material {{in a building}} into assemblies of standard easy-to-manufacture components, sized for convenient handling or according to shipping constraints. The construction of the building is carried out on the assembly level {{as opposed to the}} raw material level. The architect defines a parts library describing every major assembly in the building. The assemblies are conceived in a systematic way, based on certain rules such as <b>increment,</b> <b>size,</b> or by shape grammar. Standard, simple connections between the assemblies are carefully defined, so the number of possible shapes and appearance the parts can take is limitless.|$|E
30|$|According to {{different}} sampling frequency, {{the time period}} and time <b>increment</b> <b>size</b> of the environmental vibration problem are studied in many Literatures (Ma et al. 2016; Lai et al. 2016 a, b, c). The research results show that when the minimal time period of the model is 50 {{times as much as}} the time <b>increment</b> <b>size,</b> the error of the calculation results can not be considered. The ground time-period of the Bell Tower is 0.29 – 0.4  s, so when the time <b>increment</b> <b>size</b> is 0.005  s, the computational accuracy meets the requirements.|$|E
30|$|For {{experimental}} evaluation, we {{have used}} the same synthetic dataset T 10 I 4, {{that was used in}} the previous experiment. We fixed the size of the initial database to 10, 000 rows. To test the performance of the rare pattern mining techniques on incremental databases, we kept adding different increments and the experiments were performed on varying <b>increment</b> <b>sizes.</b> The <b>increment</b> <b>sizes</b> were varied from 500 transactions, that constitutes 5 % of the original database to 5000 transactions, constituting 50 % of the original database. The Minsup value has been set to 5 %.|$|R
40|$|Abstract-Although ScaScraIH [1] {{is able to}} scalably {{scramble}} image/video {{and offer}} scalable carrier capacity for reversible data embedding [2], the product of ScaScraIH suffers from bitstream <b>size</b> <b>increment</b> of rv 9. 17 % on average. The main cause of bitstream <b>size</b> <b>increment</b> in ScaScraIH is storing the number of nonzero coefficients in each 8 x 8 block which is utilized during the descrambling process. This paper proposes two techniques in suppressing bitstream <b>size</b> <b>increment</b> for ScaScraIH. The first technique exploits the distribution of nonzero nCT coefficients in the image to construct a scanning order, aiming to shorten the distance between nonzero coefficients in a block. For the second technique, combination of predictive and entropy coding is used to encode the number of nonzero coefficients. Experiments are conducted by using standard test images to verify the effectiveness of both techniques in suppressing bitstream <b>size</b> <b>increment.</b> On average, bitstream <b>size</b> <b>increment</b> is significantly suppressed to rv 0. 91 %, {{with some of the}} processed images assuming smaller bitstream size than its original counter part. I...|$|R
5000|$|Injection (suspicious {{because of}} the content-unrelated file <b>size</b> <b>increment)</b> ...|$|R
30|$|The {{algorithmic}} parameters are: {{the loading}} u̅_l=lΔ u with l∈ [1, 110) and the <b>increment</b> <b>size</b> Δ u:= 0.06 · 10 ^- 3 mm, the tolerance magnitudes are TOL_NR:= 10 ^- 8, TOL_Stag:= 10 ^- 5, and TOL_GL:= 10 ^- 6.|$|E
40|$|We study random walks whose {{increments}} are -stable distributions with {{shape parameter}} 1 < < 2. Specically, assuming a mean <b>increment</b> <b>size</b> which is negative, we provide series expansions {{in terms of}} the mean <b>increment</b> <b>size</b> for the probability that the all-time maximum of an -stable random walk is equal to zero and, in the totally skewed to the left case of = 1, for the expected value of the all-time maximum of an -stable random walk. Our proofs also cover the Gaussian case of = 2 and = 0 for which previous results have already been obtained in the literature using different techniques. Key ingredients in our proofs are Spitzer's identity for random walks and Zolotarev's integral representation for the CDF of an -stable random variable. We also discuss an application of our results to a problem arising in queueing theory. ...|$|E
40|$|Monkeys {{were trained}} to detect 100 -msec {{increments}} in the intensity of continuous white noise. A response on one of two bars was reinforced with some probability if it conformed to {{the presence or absence}} of the increment on that trial. Stimulus parameters of background intensity, <b>increment</b> <b>size,</b> and probability of increment presentation were varied, and response probabilities and latencies were recorded. The task was analogous to the “yes-no” task used in human psychophysics. Data analysis within the context of signal-detection theory revealed response biasing toward one bar or the other to be related to the probability of increment presentation, whereas sensitivity depended on the combination of <b>increment</b> <b>size</b> and background noise intensity. Weber's law was found to hold for a large range of background intensities in that the sensitivity to relative intensity increments varied little. Performance was compared to that of an ideal observer that uses samples of the envelope of the noise waveform on which to base its responses...|$|E
30|$|Starting {{from the}} lower bounds, first, an {{exhaustive}} batch simulation was carried out using the following parameter increment sizes: P 1 _increment_size = P 2 _increment_size = P 3 _increment_size = 0.03 m, α _F_increment_size = 3.0 ° to obtain an initial point for the SQP optimization phase. These relatively large <b>increment</b> <b>sizes</b> help to reduce the time taken for this batch simulation. The initial point for the SQP optimization {{turned out to be}} P 1 = 0.2675 m, P 2 = 0.21 m, P 3 = 0.4396 m, and α _F = 16.75 ° with the energy consumption of 18.658 J.|$|R
40|$|Introduction Let X; X 1; X 2; : : : be a {{sequence}} of independent and identically distributed (i. i. d.) random variables with common nondegenerate distribution function F. For each integer j 1, let S j = X 1 + : : : + X j and set S 0 = 0 : We {{are interested in the}} limiting behavior of the minimum of the maximal increments of partial sums, where we consider different <b>increment</b> <b>sizes.</b> To be more specific, we shall study the asymptotic behavior of (1 : 1) m n (k n) = min 0 in n max 0 jkn j S i+j Γ S<F 10. 9...|$|R
40|$|Abstract-A {{method was}} {{developed}} for obtaining a mathematical function for the probability density of particle size when the measured distributions are in terms of <b>size</b> <b>increments.</b> The method is particularly applicable when a measured size distribution does not correspond to the normal, log-normal or Weibull distributions {{but it can also}} be applied to these distribu-tions over the limits of the experimental data. An iterative least squares technique is used to fit a partial probability density function over the size range of the experimental data. Particle 'size data are represented which were initially grouped into seven <b>size</b> <b>increments,</b> but the method is applicable to any number of <b>size</b> <b>increments...</b>|$|R
40|$|The {{main focus}} of this degree {{dissertation}} was to improve the finite element (FE) tool ABAQUS/Standard (ABAQUS) by writing user subroutines to simulate the degradation of an adhesive between a skin and stringer in a composite panel. In this work simple stress based failure criteria were implemented to predict failure. Preliminary investigations were made on a simple shear plate model, which represented the basic solution for the adhesive modelling of the panel Design 1 (D 1) of the COCOMAT project (www. cocomat. com). Based on these experiences, the D 1 panel was analysed using the FE software ABAQUS. In {{the main part of}} this work three subroutines were developed, the USDFLD, UMAT explicit and UMAT implicit. These user subroutines were used to investigate the shear plate and D 1 panel, where the subroutines were used to simulate the degradation of the adhesive layer. From these calculations it was determined that the axial stiffness of both models was reduced significantly and the failure propagation within the adhesive layer was successfully performed through the entire analysis. The USDFLD and UMAT explicit subroutines both gave good results with short analysis times, though both were heavily <b>increment</b> <b>size</b> dependent. The UMAT implicit subroutine gave more accurate results as it used the stresses of the current increment, and was independent of <b>increment</b> <b>size</b> as it applied user-defined criteria to control the <b>increment</b> <b>size,</b> though both of these aspects increased the analysis time considerably. The different user subroutines were then discussed across a range of aspects including accuracy, time consumption, failure stresses and usability, and recommendations were made for the setup, application and improvement of the subroutines...|$|E
40|$|An {{integral}} equation representation is given for parabolic partial differential equations. When the equations are defined in unbounded domains, {{as in the}} initial value (Cauchy) problem, {{the solution of the}} {{integral equation}} by the method of successive approximation has inherent advantages over other methods. Error bounds for the method are of order h 3 / 2 and h 7 / 2 (h is the <b>increment</b> <b>size)</b> depending on the finite difference approximations involved...|$|E
40|$|A {{computer}} simulation study {{was carried out}} to evaluate various methods for determining threshold stimulus levels for impact sensitivity tests. In addition, {{the influence of a}} number of variables (initial stimulus level, particular stimulus response curve, and <b>increment</b> <b>size)</b> on the apparent threshold values and on the corresponding population response levels was determined. Finally, a critical review of previous assumptions regarding the stimulus response curve for impact testing is presented {{in the light of the}} simulation results...|$|E
40|$|Latent {{semantic}} analysis suers from {{a relatively high}} sensitivity to both task domain and composition style. Because the traditional -in " process simply pop-ulates the existing semantic vector space with current data, performance degrades when training and operat-ing conditions dier. On the other hand, recomputing the semantic space from scratch typically precludes real-time operation. An adaptation strategy therefore makes sense as a potential compromise. This paper investigates {{the use of a}} linear transformation to suitably update the semantic space as new data becomes available. This transformation takes into account the compound eects of adding both new words and new documents. Experi-ments with dierent <b>increment</b> <b>sizes</b> are conducted, and the paper discusses the comparative merits of this ap-proach under several scenarios. 1...|$|R
40|$|The {{behavior}} of {{finite element models}} employing different constitutive relations to describe the stress-strain {{behavior of}} soils is investigated. Three models, which assume small strain theory is applicable, include a nondilatant, a dilatant and a strain hardening constitutive relation. Two models are formulated using large strain theory and include a hyperbolic and a Tresca elastic perfectly plastic constitutive relation. These finite element models are used to analyze retaining walls and footings. Methods of improving the finite element solutions are investigated. For nonlinear problems better solutions {{can be obtained by}} using smaller load <b>increment</b> <b>sizes</b> and more iterations per load increment than by increasing the number of elements. Suitable methods of treating tension stresses and stresses which exceed the yield criteria are discussed...|$|R
40|$|To {{elucidate}} the attention switching {{function of a}} memory-comparison-based change detection system in the visual modality, the effects of task-irrelevant infrequent stimulus-size decrements that engaged memory-comparison-based change detection as well as stimulus-size increments that engaged memory-comparison-based change detection and refractoriness-based rareness detection on behavioral and event-related brain potential (ERP) measures were assessed using the distraction paradigm. Both <b>size</b> <b>increments</b> and <b>size</b> decrements caused distraction in forced-choice task performance, which was mirrored by a posterior negativity (peaking at around 240 - 260 ms, posterior N 2) and a broad positivity (420 - 460 ms, P 3 a) that reflected attentional capture. Preceding these effects, <b>size</b> <b>increments</b> elicited a posterior negativity (120 - 140 ms, change-related negativity), while size decrements elicited a posterior positivity (140 - 160 ms, change-related positivity) and an anterior positivity (160 - 180 ms, frontal positivity). Taken together, these results indicate an attention switching function of a memory-comparison-based change detection system in the visual modality, which is most probably indexed by change-related positivity...|$|R
40|$|Mackerel larvae {{have been}} sampled during two cruises south of lrland, in May and June 1989 and {{preserved}} in ethanol. The microstructure of the otoliths (sagittae) from the mackerel larvae have been examined. There is a linear relationship between length (3. 6 - 11. 6 mm) of the larvae and the {{radius of the}} otolith {{and there is an}} exponential relationship between the dry weight of the same larvae and the radius of the otolith. Although the mackerel larvae initially have a high specific growth rate (~ 12 % d^- 1), the corresponding otolith <b>increment</b> <b>size</b> is rather small (< 1 µm). From an estimated age of 20 days till an age of 35 days the specific growth rate increased three times (~ 30 % d^- 1), while the <b>increment</b> <b>size</b> doubled (~ 1. 5 µm). The average hatching date for the sampled mackerel larvae in May were estimated to 16. April 1989, and the average spawning date was calculated to 10. April 1989. For the larvae sampled in June the average hatching date were estimated to 21. May 1989, and the average spawning date was calculated to 16. May 1989...|$|E
30|$|Direct-integration dynamic {{procedure}} in ABAQUS/Standard is provided using the implicit Hilber–Hughes–Taylor (HHT) operator for {{integration of the}} equations of motion. In an implicit dynamic analysis, a set of nonlinear equilibrium equations must be solved at each time increment followed by the integration operator matrix must be inverted. The implicit operator can be unconditionally stable and thus, there is no limit {{on the size of}} the time increment that can be used for most analyses. In fact, the time <b>increment</b> <b>size</b> is controlled only by solution accuracy.|$|E
40|$|Abstract- The {{need for}} {{content-based}} image retrieval has increased with <b>increment</b> <b>size</b> and volume of digital images. This paper introduces the graph-based approach {{in order to}} retrieve the content-based image. In the proposed method, an image presents {{by a set of}} regions, while comparison of images are posing, each image represents by a graph, hence the estimation of the region correspondence transform into an graph matching problem. In addition, by using and image distance criteria, the difference between images obtained. Experimental results show that the proposed graph-theoretic image matching performance is acceptable...|$|E
50|$|Each <b>increment</b> of <b>size</b> enabled destroyers {{to carry}} {{more of the}} {{personnel}} and equipment previously found on the tender. Destroyers reached the size of cruisers during the cold war, and with that size acquired a cruiser's capability for independent action. Surviving tenders became functionally indistinguishable from repair ships.|$|R
30|$|The {{execution}} {{times of}} the algorithms on the original database and different <b>increment</b> <b>sizes</b> are depicted in Fig. 10 a, b, respectively. Figure 10 c on the other hand, illustrates the runtime invested by the algorithms on updated database {{with respect to the}} original database. From the figures, we can observe that the performance of the algorithms degrade upon addition of the increments. The execution time spent on the updated database is quite higher than the original database and it kept on increasing with smaller increments to very large increments. This is quite obvious since the algorithms run from scratch when new transactions are added to the original data. This clearly establishes the inefficiency of the rare pattern mining techniques in handling incremental data and the need of competent techniques for handling the same with greater adaptability.|$|R
40|$|International audienceOne of {{the major}} issues {{experienced}} by the IEEE 802. 11 standard is the fair sharing of the channel between unicast and multicast flows. This problem is obviously caused {{by the use of}} the smallest Contention Window size to transmit the multicast packets compared to an exponentially <b>incremented</b> <b>size</b> for every unicast packet transmission retry. This pattern is due mainly to the reliability degree difference between the unicast and the multicast traffic. Currently, the unicast uses feedbacks to provide reliability, whereas the multicast does not rely on such a mechanism and is therefore considered as unreliable. In this paper we propose a reliable Multicast flow transport proposal called the Reliable PLCP-based Multicast Protocol (RPMP) and we study its impact on the fair channel sharing with unicast flows in high-load conditions. We show that RPMP solves the issues of the legacy multicast...|$|R
40|$|A new 3 D {{finite element}} {{concrete}} model is described. The model brings together two recently developed sub-models for simulating cracking and crack contact behaviour, {{both of which}} use smoothed evolution functions, with a triaxial plasticity model component. A number of examples are presented that validate the model using a range of plain and reinforced concrete test data. These examples demonstrate that the model is numerically robust, has good equilibrium convergence performance and is objective with respect to mesh grading and <b>increment</b> <b>size.</b> The examples also illustrate the model’s ability to predict peak loads, failure modes and post-peak responses...|$|E
40|$|Investment is {{a central}} theme in economics, finance, and {{operational}} research. Traditionally, the focus of analysis has been either on assessing the value of flexibility (investment under uncertainty) or on describing commitment effects in competitive settings (industrial organization). Research contributions addressing the intersection of investment under uncertainty and industrial organization have become numerous in recent years. In this paper, we provide an overview aimed at categorizing and relating these research streams. We highlight managerial insights concerning the nature of competitive advantage (first- versus second-mover advantage), {{the manner in which}} information is revealed, firm heterogeneity, capital <b>increment</b> <b>size,</b> and the number of competing firms. Finance Investment analysis Real options Strategic investment Option games...|$|E
40|$|Superimposed {{electrical}} stimulation techniques {{can be used}} to detect central activation failure (CAF), that is, incomplete central nervous system recruitment or suboptimal activation of motor units. The {{purpose of this study was}} to evaluate the effects of two stimulation parameters on perceived discomfort and torque <b>increment</b> <b>size</b> and variability. Discomfort was evaluated using a visual analog scale (0 - 100 mm) for pain. The rectus femoris muscle of the dominant leg of 24 young healthy men was stimulated during submaximal (80 % maximal) voluntary contractions. The size and variability of torque increments and perceived discomfort were assessed following stimulation with: (1) pulse trains (100 HZ, 150 V, 0. 2 -ms pulse duration) of different lengths (50 ms and 100 ms); and (2) pulse trains (100 HZ, 100 ms, 150 V) with different pulse durations (0. 2 ms and 0. 1 ms). Pulse trains of 100 ms generated larger torque increments and produced less variability, but caused more discomfort than pulse trains of 50 ms. Average discomfort ratings for pulse trains of 100 ms were 43. 1 mm, and of 50 ms were 53. 2 mm. There was no difference in torque <b>increment</b> <b>size</b> or in variability between pulse trains with pulse durations of 0. 1 ms and 0. 2 ms, whereas discomfort was less for the shorter pulse durations; average discomfort ratings were 53. 1 mm and 58. 1 mm for pulse durations of 0. 1 ms and 0. 2 ms, respectively. Thus, the appropriate selection of stimulation parameters can reduce discomfort but maintain the ability to detect CAF. Muscle Nerve 27 : 90 - 98, 200...|$|E
3000|$|... [...]. We {{can form}} 45 {{combinations}} of two constraint Equation  2 and n observation Equation  1 {{which are then}} used to estimate 45 sets of fitting coefficients (a 0,[*]a 1,[*]…,[*]a 9). In step IV, we <b>increment</b> the <b>size</b> of constraint equations by 1 until the size increases to 10. The total number of the fitting coefficients sets is [...]...|$|R
2500|$|The {{standard}} door sizes in the US {{run along}} 2" [...] <b>increments.</b> Customary <b>sizes</b> have {{a height of}} 78" [...] (1981mm) or 80" [...] (2032mm) and a width of 18" [...] (472mm), 24" [...] (610mm), 26" [...] (660mm), 28" [...] (711mm), 30" [...] (762mm) or 36" [...] (914mm). Most residential passage (room to room) doors are 30" [...] x 80" [...] (762mm x 2032mm).|$|R
5000|$|Sizing systems {{also differ}} in what units of {{measurement}} they use. This also results in different <b>increments</b> between shoe <b>sizes,</b> because usually only [...] "full" [...] or [...] "half" [...] sizes are made.|$|R
40|$|In {{the finite}} element {{analysis}} of reinforced concrete structures which feature cracking, yielding and crushing, the selection of load <b>increment</b> <b>size</b> is generally regarded {{as a matter of}} experience and judgement. It has been shown, however, that the prediction of structural response can be sensitive to this choice. A better approach to load step selection would involve consideration of the physical condition of the structure at any stage of loading. This paper describes, with examples, an automatic load increment selection scheme which removes the need for guesswork. The scheme employs a simple algorithm which takes account of previous and projected damage at integration points and selects an appropriate load increment. The load-damage history of the structure is efficiently followed and convergence problems associated with overly large increments of load are avoided...|$|E
40|$|This paper {{describes}} the numerical formulation of a force-resultant model describing the elasto-plastic load-displacement behaviour of a spudcan foundation in clay. The formulation uses an implicit integration scheme, {{which has the}} advantages of numerical efficiency and insensitivity to <b>increment</b> <b>size.</b> Importantly to the user, step-size does not require determination before investigating "unknown" problems. Implementation of the model as a user element subroutine for the commercially available finite element program ABAQUS is described. The formulation presented ensures optimum compatibility with the incremental-iterative solution scheme employed by ABAQUS itself, and therefore allows efficient integration with the range of structural elements available in ABAQUS. The implementation is verified against established analysis problems, including the pushover of a jack-up structure. Copyright © 2008 by The International Society of Offshore and Polar Engineers (ISOPE) ...|$|E
40|$|ABSTRACT. Advanced life {{predictions}} in {{cyclically loaded}} components consider both crack initiation and crack propagation phase with its quite different damage mechanisms. In components under internal cyclic pressure loading the notches {{are located in}} the pressurized inside, so that crack initiation and crack propagation cannot be observed directly. Usually only the total life up to the leakage of the component can be determined. Due to the lack of experimental data for crack initiation and crack growth phases the corresponding life predictions cannot be validated separately. A method for automatic crack growth calculation with FE is presented. For the numerical crack growth simulation the crack <b>increment</b> <b>size</b> influences directly the crack shape development. Too large increments cause numerical instability. To reach the numerical stability model extensions are presented and explained. The comparisons of the calculated cycles to experimental results show a good agreement...|$|E
40|$|Incremental mining {{algorithms}} {{that can}} efficiently derive the current mining output by utilizing previous mining results are attractive to business organizations since data mining is typically a resource-intensive recurring activity. In this paper, we present the DELTA algorithm for the robust and efficient incremental mining of association rules on large market basket databases. DELTA guarantees efficiency by ensuring that, for any dataset, at most three passes over the increment and one {{pass over the}} previous database are required to generate the desired rules. Further, it handles "multi-support" environments where the support requirements for the current mining differ from those used in the previous mining, a feature {{in tune with the}} exploratory nature of the mining process. We present a performance evaluation of DELTA on large databases over a range of <b>increment</b> <b>sizes</b> and data distributions, as well as change in support requirements. The experimental results show that DELTA can provide significant improvements in execution times over previously proposed incremental algorithms in all these environments. In fact, for many workloads, its performance is close to that achieved by an optimal, but practically infeasible, algorithm...|$|R
5000|$|The {{standard}} door sizes in the US {{run along}} 2" [...] <b>increments.</b> Customary <b>sizes</b> have {{a height of}} 78" [...] (1981 mm) or 80" [...] (2032 mm) and a width of 18" [...] (472 mm), 24" [...] (610 mm), 26" [...] (660 mm), 28" [...] (711 mm), 30" [...] (762 mm) or 36" [...] (914 mm). Most residential passage (room to room) doors are 30" [...] x 80" [...] (762 mm x 2032 mm).|$|R
5000|$|The Paris point equates to [...] {{centimetre}} (about 6.7 mm or 0.26 in). That is the <b>increment</b> between whole <b>sizes,</b> {{and about}} 3.3 mm or 0.13 in between half sizes. This unit {{is commonly used}} in Continental Europe.|$|R
