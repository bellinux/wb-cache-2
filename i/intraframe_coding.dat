37|20|Public
40|$|A wavelet-based video coder {{built on}} the {{principles}} of distributed source coding is described. The encoder employs a syndrome-based encoding strategy for intercoded coefcients while other co-efcients are intracoded using an embedded wavelet-based coder designed for the coding of arbitrarily shaped image objects. The de-coder uses a reference frame in the domain of a redundant wavelet transform to search for blocks matching the syndrome received from the encoder in order to decode intercoded coefcients. Ex-perimental results indicate that, due to improved <b>intraframe</b> <b>coding,</b> the proposed wavelet-based algorithm signicantly outperforms a similar technique constructed with JPEG-like <b>intraframe</b> <b>coding.</b> 1...|$|E
40|$|While {{directional}} adaption {{is introduced}} into traditional transforms, different orders of two 1 -D transforms {{will result in}} different results of one 2 -D transform. Based upon an anisotropic image model, this paper analyzes the effect of transform orders in terms of theoretical coding gain. Our results reveal that the transform orders have {{little effect on the}} coding gain with full decomposition, good directional modes and good interpolation. However, in practical compression schemes, since high-pass bands are not decomposed fully because of the consideration on complexity, different transform orders have different coding performances, which can be solved by an adaptive transform order. Motivated by our analyzed results, a directional filtering transform (dFT, in order to distinguish from the common usage on DFT) is proposed in this paper to better exploit correlations among samples in H. 264 <b>intraframe</b> <b>coding.</b> It provides an evenly distributed set of prediction modes with an adaptive transform order. Both interblock and intrablock correlations are exploited in this scheme. Experimental results in H. 264 <b>intraframe</b> <b>coding</b> demonstrate its superiority both objectively and subjectively...|$|E
40|$|This paper {{concerns}} the <b>intraframe</b> <b>coding</b> of pictures. Conventionally the predictive coding methods use a two dimensional linear predictor {{which is based}} on the autoregressive model of the picture. This paper proposes two versions of a twodimensional lattice algorithm for linear prediction. This algorithm is arrived at by representing the forward prediction error as a function of a lower order predictor. This method is computationally efficient and possesses all the advantages of the lattice algorithm I...|$|E
40|$|An MPEG-encoded {{video signal}} {{includes}} groups of pictures (GOPs), each GOP having an <b>intraframe</b> <b>coded</b> (I) picture {{and a series}} of predictively encoded (P) pictures and bi-directionally predictively (B) pictures. Usually, the GOP structure IBBPBBP... is used. However, in order to embed a watermark in the MPEG-encoded video signal, the MPEG encoder is forced to produce a GOP structure which does not normally occur, e. g., a GOP including a BPP sequence. Different symbol values can be assigned to different positions of the BPP sequence in the GOP...|$|R
40|$|In {{this paper}} {{we present a}} new coding and packetization {{approach}} for <b>intraframe</b> <b>coded</b> video transmission, based on space-frequency dispersion. Subband-decomposed video data is packetized so that data appearing in any one packet is highly dispersed in both space and frequency. Each packet is {{a description of the}} frame at various points in space and frequency. Any errors arising from packet loss are spread across the frame and this allows easy error concealment. We compare our method to the more conventional block-based packetization scheme and illustrate its advantages in both PSNR and subjective visual quality...|$|R
40|$|AbstractGeoscience {{applications}} often produce sizable datasets {{which are}} vector-valued and increasingly {{in need of}} compression algorithms to reduce storage and transmission burdens, particularly when the data is time-varying. In this paper, several advanced interframe-compression tech-niques are extended from the traditional realm of natural video to the cod-ing of time-varying vector elds. Although similar to natural video in some respects, time-varying vector-eld sequences often possess complex temporal evolution of vector-valued features {{that are important to}} the an-alytic quality of the data yet defy the simple motion models widely em-ployed for natural video. To improve coding performance, motion com-pensation with reduced resolution is proposed such that motion compensa-tion is applied only at low spatial resolution while high-resolution informa-tion, for which the motion model fails, is <b>intraframe</b> <b>coded</b> with no tempo-ral decorrelation. In empirical results on datasets of ocean-surface winds, this reduced-resolution motion-compensation technique results in signi-cant performance improvement and greater feature preservation...|$|R
3000|$|Despite PRISM, {{most of the}} {{distributed}} video coding {{schemes that}} focus on error resilience try to increase the robustness of standard encoded video by adding redundant information encoded according to distributed video coding principles. One of the first works along this direction is presented in [49], where auxiliary data is encoded only for some frames, denoted as [...] "peg" [...] frames, {{in order to stop}} drift propagation at the decoder. The idea is to achieve the robustness of intrarefresh frames, without the rate overhead due to <b>intraframe</b> <b>coding.</b>|$|E
40|$|The {{first goal}} of diploma thesis is {{to study the}} basic {{principles}} of video signal compression. Introduction to techniques used to reduce irrelevancy and redundancy in the video signal. The second goal is, on the basis of information about compression tools, implement the individual compression tools in the programming environment of Matlab and assemble simple model of the video codec. Diploma thesis contains a description of the three basic blocks, namely - interframe coding, <b>intraframe</b> <b>coding</b> and coding with variable length word - according the standard MPEG- 2...|$|E
40|$|A {{simple and}} {{computationally}} lightweight video coder employing shape-adaptive, embedded <b>intraframe</b> <b>coding</b> and wavelet-domain conditional replenishment is proposed. Robustness to packet losses arises from packetization of the embedded bitstream with {{unequal error protection}} which is assigned to the packets with a fast, locally optimal procedure. Experimental results reveal that, when compared to H. 264 /AVC configured for low-complexity, error-resilient operation, {{not only does the}} proposed coder usually produce substantially superior rate-distortion performance as packet losses increase, it also achieves a significantly faster encoding speed. Index Terms â€” Conditional replenishment, robust video coding, shape-adaptive wavelet transform 1...|$|E
40|$|<b>Intraframe</b> {{transform}} <b>coding</b> {{of pictures}} {{for the case}} of a nonseparable covariance model is considered. Performances of the Walsh-Hadamard, discrete-cosine, and Karhunen-Loeve transforms are compared based on the compaction of signal energy in the transform components and the degree of decorrelation of the data. The results demonstrate that the performances of the discrete-cosine and Karhunen-Loeve transforms compare closely, {{as is the case with}} a separable covariance model. The corresponding performance of the Walsh-Hadamard transform is inferior...|$|R
40|$|In {{this paper}} the authors {{introduce}} a block-classified bidirectional motion compensation scheme for the previously developed wavelet-based video codec, where multiresolution motion estimation is {{performed in the}} wavelet domain. The frame classification structure described in this paper {{is similar to that}} used in the MPEG standard. Specifically, the I-frames are <b>intraframe</b> <b>coded,</b> the P-frames are interpolated from a previous I- or a P-frame, and the B-frames are bidirectional interpolated frames. They apply this frame classification structure to the wavelet domain with variable block sizes and multiresolution representation. They use a symmetric bidirectional scheme for the B-frames and classify the motion blocks as intraframe, compensated either from the preceding or the following frame, or bidirectional (i. e., compensated based on which type yields the minimum energy). They also introduce the concept of F-frames, which are analogous to P-frames but are predicted from the following frame only. This improves the overall quality of the reconstruction in a group of pictures (GOP) but at the expense of extra buffering. They also study the effect of quantization of the I-frames on the reconstruction of a GOP, and they provide intuitive explanation for the results. In addition, the authors study a variety of wavelet filter-banks to be used in a multiresolution motion-compensated hierarchical video codec...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Issued also on microfiche from Lange Micrographics. A software based, three resolution video encoder is developed for use in real time, desktop, packet switched videoconferencing over the Internet. The encoder is capable of encoding simultaneously, three streams for three- 80 x 60, 160 x 120 and 320 x 240 -video resolutions. One stream is for the medium, 160 x 120, resolution video and consists of <b>intraframe</b> <b>coded</b> conditional replenishment blocks. It has an average bit rate of 44 kbits/s at two frames/s. The compression algorithm that is used is taken from the popular CU-SeeMe videoconferencing tool. Another stream is for the low, 80 x 60, resolution video and is produced by decimating the medium resolution conditional replenishment blocks. It has an average bit rate of 17 kbits/S at two frames/s. The third stream is a pyramidal difference layer that is used to reconstruct the full, 320 x 240, resolution video. A "lossy pyramidal coding" method is used to code the pyramidal difference stream and the average rate varies from over 140 kbits/s to less than 10 kbits/s at two frames/s, depending on the desired quality...|$|R
40|$|ABSTRACT: The shape {{adaptive}} DCT is {{a widely}} used tool for coding of arbitrarily shaped image segments due to its rather low complexity. However, having been primarily designed for <b>intraframe</b> <b>coding,</b> we will show in this paper that the transform is clearly suboptimal when applied to interframe coding. Using a suitable covariance model we show that a rescaled, orthonormalized transform much closer approximates the optimal shape adaptive eigentransform of motion compensated difference images. Rate distortion curves verify that orthonormalization improves the coding efficiency in interframe coding by up to 2 dB while not adding to complexity. ...|$|E
40|$|Downsampling {{technique}} for <b>intraframe</b> <b>coding</b> {{is a new}} scenario for low bit rate coding. In the existing methods of downsampling technique, the alternate entire row or column of pixels are downsampling, Which leads to more loss image quality during interpolation. Checkerboard pattern technique is proposed in downsampling process. Here we remove alternate pixel value same as chess board. Interpolation {{is a process of}} generating a value of a pixel based on its neighbors. We use adaptive weighted interpolation technique. JPEG-LS technique is to provide effective lossless and near lossless compression in upsampling and downsampling process. LOCO-I algorithm is used in JPEG-LS. By using this technique, the image quality is improved...|$|E
40|$|High {{data rate}} video is an {{integral}} part of high-quality multimedia for broadband networks. Owing to the high rate, compression of video information is required for an efficient use of network bandwidth. A hierarchical DCT-based video codec is examined that prioritizes and compresses high data rate video for transmission over ATM networks. The video codec utilizes <b>intraframe</b> <b>coding</b> by independently processing each frame of the video sequence. The lossless compression part consists of run length coding to exploit zero values in the high frequency DCT coefficients and variable length coding (VLC) to further reduce the bit rate. Three compression schemes are examined: adaptive Huffman, arithmetic coding, and Lempel-Ziv-Welch coding. For the model-based compression algorithms, we study several models to characterize the input bit stream to the VLC: memoryless, and Markov with either fixed orders or orders determined by an order estimator. For the three VLCs in the codec, the best performance was obtained from a combination of a memoryless Huffman codec and two first-order Huffman codecs. Many of the models incorporating memory, performed poorly due to the small size of the input files. Due to the VLC, the output rate of the system is variable; however, since <b>intraframe</b> <b>coding</b> is utilized, rate variations are small. In order to fully utilize available bandwidth, we examine the rate control problem of converting the codec from a variable rate system to a fixed rate system. The rate control problem is formulated as one of constrained minimization, and analyzed for optimal solutions. Algorithms are presented for optimal rate control...|$|E
40|$|This thesis {{addresses}} {{the problem of}} developing and implementing in software a variable block size (quadtree splitting) disparity estimation algorithm that is optimized for use in compression of stereo image pairs and studying its performance over a range of rate/distortion values {{for a variety of}} images. First the constrained optimization problem is converted to an unconstrained one using the Lagrange multiplier approach. Then by solving the optimization problem using dynamic programming, the optimal variables representing the optimal quadtree structure and the quantizer for each node are determined. The experimental results show the improvements of this method over simple <b>intraframe</b> JPEG <b>coding</b> and over fixed block-size disparity estimation...|$|R
40|$|Spatial {{transform}} coding {{has been widely}} applied for image compression because of its high coding efficiency. However, in many intraframe systems, in which every TV frame is independently processed, coding of moving objects {{in the case of}} interlaced input signals is not addressed. In this paper, we extend <b>intraframe</b> transform <b>coding</b> techniques for interlaced video signals with limited additional complexity. After discussing key aspects of an interlaced video signal, we present a simple motion-detection scheme which is suitable for an a priori block-coding decision, thereby saving hardware complexity. The transformer is modified to obtain either intraframe or intrafield transformed blocks by performing partially different fast cosine computation algorithms. As a result, the subjective image quality of the motion-adaptive coding technique is considerably improved as compared with the nonadaptive system...|$|R
40|$|Abstract â€“ Video {{transcoding}} is assuming {{an important}} role in modern video communication systems in order to allow interoperability between different equipment and standards. So far most effort has been spent in transcoding from older standards to the most recent ones. However, as new standards reach higher levels of compression efficiency, the diversity of bitstream formats also increases. In this paper we propose a new transcoding architecture for H. 264 /AVC (Advanced Video Coding) to MPEG- 2 Video. Since both standards are based on the same coding paradigms, interframe block based motion estimation and <b>intraframe</b> transform <b>coding,</b> the proposed architecture explores their similarities in order to achieve an efficient format conversion. The proposed transcoder significantly reduces the computational complexity of the MPEG- 2 Video motion estimation based on the information included in the H. 264 /AVC bitstream. The presented results from our architecture show a significant computation reduction, as much as 30 %, with a small objective quality reduction. I...|$|R
30|$|The {{evaluation}} {{assumed the}} same rate and quality for the odd frames of all the schemes, and therefore the rate-distortion performances of odd frames {{were not included in}} the plots. It is evident from Fig.Â  11 that when highly reliable side information (MC-I) is used, the TDWZ codec is 7 â€“ 8 Â dB better than the PDWZ codec. On the other hand, using less reliable side information (MC-E), the TDWZ codec yields a PSNR gain of 1 â€“ 3 Â dB against DCT-based <b>intraframe</b> <b>coding.</b> It is also observed that compression efficiency loss is approximately 5 Â dB higher since the motion and occlusions in the foreman sequence make it more difficult to extrapolate the succeeding frames.|$|E
40|$|We {{introduce}} a formula to compute an optimum 2 -D shape-adaptive Karhunen-Loeve transform (KLT) suitable for coding pels in arbitrarily-shaped image segments. The {{efficiency of the}} KLT on a 2 -D AR(1) process is used to benchmark two other shape-adaptive transforms described in literature. It is shown that the optimum KLT significantly outperforms the well known shape-adaptive DCT method introduced by Gilge et al. (1989) for coding Segments of arbitrary shape in <b>intraframe</b> <b>coding</b> mode. A statistical transform gain close to the Gilge-method can be achieved with a shape-adaptive DCT algorithm introduced by Sikora and Makai (see Proc. Workshop Image Anal. Image Coding, Berlin, FRG, Nov. 1993) which is implemented with much lower complexity...|$|E
40|$|This paper {{presents}} a simple, fast coding technique for lossless compression of mosaic video data. The {{design of a}} video codec needs {{to strike a balance}} between the compression performance and the codec throughput. Aiming to make the encoding throughput high enough for real-time lossless video compression, we propose a hybrid scheme of inter and <b>intraframe</b> <b>coding.</b> Interframe predictive coding is invoked only when the motion between adjacent frames is modest and a simple motion compensation operation can significantly improve the compression performance. Otherwise, still frame compression is performed to keep the complexity low. Experimental results show that the proposed scheme achieves higher lossless video compression ratio than existing methods such a...|$|E
40|$|A VLSI {{architecture}} for a low complexity <b>intraframe</b> subband image <b>coding</b> for HDTV signals is presented. The Generalized Quadrature Mirror Filters (GQMFs), {{which have}} smaller overall delay, are optimized {{in order to}} achieve high coding efficiency. The filter design exploits a symmetry property among different filter coefficients which, in turn, reduces the hardware complexity of the architecture substantially. The architecture is designed with 1 Î¼m CMOS technology using the scalable design rules of MOS Integrated Services Inc. (MOSIS). The VLSI architecture contains approximately 200, 000 transistors and it is capable of operating at a speed of 34 MHz...|$|R
40|$|Most low {{bit rate}} speech coders employ linear {{predictive}} coding (LPC) which models the short-term spectral information within each speech frame as an all-pole lter. In this thesis, we examine various methods that can e ciently encode spectral parameters for every 20 ms frame interval. Line spectral frequencies (LSF) {{are found to be}} the most e ective parametric representation for spectral coding. Product code vector quantization (VQ) techniques such as split VQ (SVQ) and multi-stage VQ (MSVQ) are employed in <b>intraframe</b> spectral <b>coding,</b> where each frame vector is encoded independently from other frames. Depending on the product code structure, coding " quality isachieved for SVQ at 2628 bits/frame and for MSVQ at 2527 bits/frame. Because speech is quasi-stationary, interframe coding methods such as predictive SVQ (PSVQ) can exploit the correlation between adjacent LSF vectors. Nonlinear PSVQ (NPSVQ) is introduced in which a nonparametric and nonlinear predictor replaces the linear predictor used in PSVQ. Regardless of predictor type, PSVQ garners a performance gain of 57 bits/frame over SVQ. By interleaving intraframe SVQ wit...|$|R
40|$|The Letter {{describes}} a low complexity <b>intraframe</b> sub-band image <b>coding</b> algorithm suitable for video coding applications. A {{new class of}} quadrature mirror filter (QMF), called the generalized quadrature mirror filter (GQMF), with smaller overall delay, is introduced. In this approach, the spectra of the HDTV signals are first decomposed into smaller frequency bands where the baseband is DPCM encoded and the high bands are PCM encoded. For optimum performance, an efficient entropy coder is designed that significantly reduces the overall bit rate. It is shown that high quality HDTV images can be obtained at bit rates as low as 34 Mbit/s with a considerable reduction in complexity...|$|R
40|$|In current {{interframe}} {{video compression}} systems, the encoder performs predictive coding {{to exploit the}} similarities of successive frames. The Wyner-Ziv Theorem on source coding with side information available only at the decoder suggests that an asymmetric video codec, where individual frames are encoded separately, but decoded conditionally (given temporally adjacent frames) could achieve similar e#ciency. We propose a transformdomain Wyner-Ziv coding scheme for motion video that uses intraframe encoding, but interframe decoding. In this system, the transform coe#cients of a Wyner-Ziv frame are encoded independently using a scalar quantizer and turbo coder. The decoder uses previously reconstructed frames to generate side information to conditionally decode the Wyner-Ziv frames. Simulation results show significant gains above DCT-based <b>intraframe</b> <b>coding</b> and improvements over the pixel-domain Wyner-Ziv video coder...|$|E
40|$|The paper {{describes}} video codecs {{that provide}} the functionality of spatio-temporal scalability that enables construction of highly scalable video codecs. The coder exploits wavelet decomposition for <b>intraframe</b> <b>coding</b> and combined temporal prediction and spatial interpolation for P- and B-frames. In a two-layer system, the bitrate overhead measured relative to the single layer MPEG- 2 bitstream varies about 10 % for progressive television test sequences. The base layer bitstream constitutes about 40 % of the overall bitstream. In multilayer systems, the bitrate ratio of consecutive layers is about 1 : 2. 5. The base layer encoder is fully compatible with the MPEG- 2 video coding standard. The paper comprises experimental results obtained for a two-layer system for progressive video sequence compression...|$|E
40|$|Abstract â€” In {{the past}} decades, video coding {{technologies}} have greatly promoted {{the development of}} digital multimedia contents related industry. To satisfy the rapid increasing demand for high-definition (HD) and ultra-HD (UHD) video contents, a higher requirement for more efficient video coding has been brought forward. In this {{paper we propose a}} new approach for efficient video compression. We mainly focus on <b>intraframe</b> <b>coding</b> that performs compression techniques on any one of the frames in video sequence. A single pixel based lossless prediction (SPLP) along with downsampling and interpolation is used to achieve a better compression ratio compared to existing system. SPLP is an enhancement of H. 264 /MPEG- 4 standard, which employs pulse code modulation for better prediction. Along with SPLP, a checker board pattern downsampling and adaptive weighted interpolation techniques are used to improve the performance...|$|E
40|$|Envisioned {{advanced}} multimedia video services include arbitrarily-shaped (AS) image segments as well {{as regular}} rectangular images. Images segments of the TV weather reporter produced by the chromo-key technique [1] and image segments produced by video analysis and image segmentation[2, 3, 4] are typical examples of AS image segments. This paper explores efficient <b>intraframe</b> transform <b>coding</b> techniques for general two-dimensional (2 D) AS image segments, treating the traditional rectangular images as a special case. In particular, we focus on transform coding of the partially-defined image blocks along the boundary of the AS image segments. We recognize two different approaches â€” the brute-force transform coding approach and the shape-adaptive transform coding approach. The former fills up the uncovered area with the optimal redundant data such that the resulting transform spectrum is compact. A simple but efficient mirror-image extension technique is proposed. Once augmented into full image blocks, these boundary blocks can be processed by traditional block-based transform techniques like the popular Discrete Cosine Transform (DCT). In the second approach, we change either the transform basis or the coefficient calculation process adaptively based on {{the shape of the}} A...|$|R
40|$|A {{procedure}} {{to evaluate the}} coding gain for 2 -D subband systems is explicitly presented, The technique operates in the signal domain and requires {{the knowledge of the}} input process auto-correlation function, Both the case of uniform subband and pyramid decomposition are considered. In the case of a separable input process spectrum, the evaluation can be performed by considering appropriately defined 1 -D systems, thus, making the procedure very convenient in terms of computational complexity, Using a model that has been recently derived for difference images in motion-compensated image sequence coders, we compare the performance of several filter banks and transform coders in terms of coding gain and asymptotic rate-distortion figures, The results for <b>intraframe</b> and interframe <b>coding</b> show that uniform subband coders can have a performance superior to that of transform coders, Pyramidal schemes appear to have a slightly worse performance...|$|R
40|$|Special purpose {{hardware}} {{has been}} traditionally {{viewed as the}} only practical solution for high speed Video Signal Processing (VSP). However, new parallel computing technologies may provide a much more flexible alternative. In this paper we discuss techniques for implementing VSP algorithms on data-parallel computers, including data distribution and the tradeoffs between memory usage, communication, and computation. We provide theoretical analyses and illustrate them with examples of implementations written for the MasPar data-parallel computers. The algorithms studied here are a selection of classical algorithms that includes block-DCT coding, subband coding and block-matching motion estimation. Additionally, two new algorithms of the authors are also presented, on <b>intraframe</b> nonorthogonal subband <b>coding</b> and on motion compensated 3 -D subband coding. 1 Introduction The concurrent progress in digital video signal processing (VSP) technologies and digital video transmission on the one h [...] ...|$|R
40|$|Abstract â€” In this paper, a {{new method}} for low bit-rate content-adaptive mesh-based video coding is proposed. <b>Intraframe</b> <b>coding</b> {{of this method}} employs feature map {{extraction}} for node distribution at specific threshold levels to achieve higher density placement of initial nodes for regions that contain high frequency features and conversely sparse placement of initial nodes for smooth regions. Insignificant nodes are largely removed using a subsequent node elimination scheme. The Hilbert scan is then applied before quantization and entropy coding to reduce amount of transmitted information. For moving images, both node position and color parameters of only a subset of nodes may change from frame to frame. It is sufficient to transmit only these changed parameters. The proposed method is wellsuited for video coding at very low bit rates, as processing results demonstrate that it provides good subjective and objective image quality at a lower number of required bits 1...|$|E
40|$|This paper {{presents}} a new lossless interframe coding scheme for Magnetic Resonance (MR) images. The existing schemes, like block matching method and uniform meshbased scheme, are inadeqaute {{to model the}} motion field of MR sequence. The above schemes use uniform mesh elements which may comprise multiple motions. We propose a scheme consisting of (a) content-based mesh generation (b) forward motion tracking (c) motion compensation using affine transformation and (d) context-based modeling. By using context-based modeling, intraframe correlation is also exploited in addition to interframe correlation. The obtained average compression ratio of 4. 3 : 1 {{is better than the}} values of 4 : 1, achieved by CALIC, {{the state of the art}} lossless <b>intraframe</b> <b>coding</b> scheme and 3 : 1, by the existing uniform mesh-based interframe coding scheme for MR images. The performance of the existing uniform mesh-based scheme can also be improved by employing context-based modeling...|$|E
40|$|This paper {{proposes a}} new {{approach}} to distributed video coding. Distributed video coding is based on the concept of decoding with side information at the decoder. Such a coding scheme employs a low-complexity encoder and the load of computational complexity is shifted to the decoder side. This property makes it well suited for low-power devices such as mobile video cameras. The uniqueness of our approach lies in the combined use of discrete wavelet transform (DWT) and the concept of sampling of signals with nite rate of innovation (FRI) [1], which allow us to shift the task of motion estimation to the decoder side. Unlike the currently existing practical coders, we do not employ any traditional channel coding technique. Our preliminary results show that, for a simple video sequence with a uniform background, the proposed coding scheme can achieve a better PSNR than JPEG 2000 <b>intraframe</b> <b>coding</b> at low bit rates...|$|E
40|$|We {{present a}} {{detailed}} {{statistical analysis of}} a 2 -hour long empirical sample of VBR video. The sample was obtained by applying a simple <b>intraframe</b> video compression <b>code</b> to an action movie. The main findings of our analysis are (1) the tail behavior of the marginal bandwidth distribution can be accurately described using "heavy-tailed" distributions (e. g., Pareto); (2) the autocorrelation of the VBR video sequence decays hyperbolically (equivalent to long-range dependence) and can be modeled using self-similar processes. We combine our findings in a new (non-Markovian) source model for VBR video and present an algorithm for generating synthetic traffic. Trace-driven simulations show that statistical multiplexing results in significant bandwidth efficiency even when long-range dependence is present. Simulations of our source model show long-range dependence and heavy-tailed marginals to be important components which are not accounted for in currently used VBR video traff [...] ...|$|R
40|$|In this paper, {{we present}} a fast mode {{decision}} method for H. 263 to H. 264 /AVC intraframe transcoding. The proposed algorithm {{is based on the}} observation that features of DCT coefficients extracted from H. 263 <b>coded</b> <b>intraframe</b> strongly relates to the optimal mode in H. 264 /AVC intra mode decision. Specifically, the total number of non-zero AC coefficients of four 8 x 8 DCT blocks in H. 263 is taken as a measurement in the intra block size decision. The objective is to reject improbable block types in earlier stages in order to achieve computation saving. In addition, a transform domain edge direction estimation is also adopted into our scheme to further speed up the intra mode prediction. Simulation results show that the proposed approach can reduce the computational complexity of intraframe transcoding by up to 65 % while maintaining the rate-distortion (R-D) performance. Department of Electronic and Information EngineeringRefereed conference pape...|$|R
40|$|Most low {{bit rate}} speech coders employ linear {{predictive}} coding (LPC) which models the short-term spectral information within each speech frame as an all-pole filter. In this thesis, we examine various methods that can efficiently encode spectral parameters for every 20 ms frame interval. Line spectral frequencies (LSF) {{are found to be}} the most effective parametric representation for spectral coding. Product code vector quantization (VQ) techniques such as split VQ (SVQ) and multi-stage VQ (MSVQ) are employed in <b>intraframe</b> spectral <b>coding,</b> where each frame vector is encoded independently from other frames. Depending on the product code structure, "transparent coding" quality is achieved for SVQ at 26 - 28 bits/frame and for MSVQ at 25 - 27 bits/frame. Because speech is quasi-stationary, interframe coding methods such as predictive SVQ (PSVQ) can exploit the correlation between adjacent LSF vectors. Nonlinear PSVQ (NPSVQ) is introduced in which a nonparametric and nonlinear predictor replaces the linear predictor used in PSVQ. Regardless of predictor type, PSVQ garners a performance gain of 5 - 7 bits/frame over SVQ. By interleaving intraframe SVQ with PSVQ, error propagation is limited to at most one adjacent frame. At an overall bit rate of about 21 bits/frame, NPSVQ can provide similar <b>coding</b> quality as <b>intraframe</b> SVQ at 24 bits/frame (an average gain of 3 bits/frame). The particular form of nonlinear prediction we use incurs virtually no additional encoding computational complexity. Voicing classification is used in classified NPSVQ (CNPSVQ) to obtain an additional average gain of 1 bit/frame for unvoiced frames. Furthermore, switched-adaptive predictive SVQ (SA-PSVQ) provides an improvement of 1 bit/frame over PSVQ, or 6 - 8 bits/frame over SVQ, but error propagation increases to 3 - 7 frames. We have verified our comparative performance results using subjective listening tests...|$|R
