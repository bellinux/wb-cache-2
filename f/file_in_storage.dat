0|10000|Public
50|$|After {{four days}} of searching through <b>files</b> <b>in</b> <b>storage,</b> the <b>files</b> were found <b>in</b> an unmarked box along with the files of the Mary Helen Williams murder case. However, much {{evidence}} was missing, including Brenda Sue's dress, underwear, shoes, her powder-puff compact, the rock {{that was used to}} kill her, two vials of blood, fingernail scrapings, branches, and a hair sample.|$|R
50|$|Note: {{this only}} applies to <b>file</b> systems used <b>in</b> <b>storage</b> devices.|$|R
5000|$|Sync <b>files</b> stored <b>in</b> {{corporate}} <b>storage</b> to user desktops {{and devices}} ...|$|R
50|$|Editing a saved game {{offers an}} {{indirect}} way to modify game data. By modifying a <b>file</b> <b>in</b> persistent <b>storage,</b> {{it is possible}} to effectively modify the run time game data that will be restored when the game attempts to load the save game.|$|R
5000|$|Ikonboard 3.0 {{represented}} a [...] "total rewrite" [...] for Ikonboard. The board was still coded entirely in Perl; however, Mecham adopted an object-oriented style of coding, and {{did away with}} flat <b>files</b> <b>in</b> favor of <b>storage</b> abstraction, allowing data <b>storage</b> <b>in</b> a relational database such as MySQL or Oracle.|$|R
50|$|Extent-based file {{systems can}} also {{eliminate}} {{most of the}} metadata overhead of large files that would traditionally be {{taken up by the}} block-allocation tree. Because the savings are small compared to the amount of stored data (for all <b>file</b> sizes <b>in</b> general) but make up {{a large portion of the}} metadata (for large <b>files),</b> the benefits <b>in</b> <b>storage</b> efficiency and performance are slight.|$|R
40|$|Cloud {{storage is}} a model of {{networked}} online storage based on cloud computing, and provides users with immediate access to a broad range of resources and applications. Although a lot of cloud storage providers adopt encryption to protect costumer data, but users still suspect the security and privacy of their data. The paper analyzed Information dispersal algorithms (IDAs), and proved that it can better address the issues of confidentiality, integrity and availability of data. On this basis, the paper presented a cloud storage system adopting IDAs, and illustrated its key component and the process of writing <b>file</b> <b>in</b> cloud <b>storage...</b>|$|R
25|$|OS/360 also {{pioneered the}} concept that the {{operating}} system keeps track {{of all of the}} system resources that are used, including program and data space allocation in main memory and <b>file</b> space <b>in</b> secondary <b>storage,</b> and <b>file</b> locking during update. When the process is terminated for any reason, all of these resources are re-claimed by the operating system.|$|R
40|$|Many storage systems rely on {{replication}} {{to increase}} the availability and durability of data on untrusted stor-age systems. At present, such storage systems provide no strong evidence that multiple copies of the data are actu-ally stored. Storage servers can collude {{to make it look}} like they are storing many copies of the data, whereas in reality they only store a single copy. We address this short-coming through multiple-replica provable data possession (MR-PDP) : A provably-secure scheme that allows a client that stores t replicas of a <b>file</b> <b>in</b> a <b>storage</b> system to verify through a challenge-response protocol that (1) each unique replica can be produced at the time of the challenge and that (2) the storage system uses t times the storage required to store a single replica. MR-PDP extends previous work on data possession proofs for a single copy of a <b>file</b> <b>in</b> a client/server <b>storage</b> system [4]. Using MR-PDP to store t replicas is computationally much more efficient than using a single-replica PDP scheme to store t separate, unrelated files (e. g., by encrypting each file separately prior to storing it). Another advantage of MR-PDP is that it can generate further replicas on demand, at little expense, when some of the existing replicas fail. ...|$|R
50|$|Virtuoso {{provides}} an extended object-relational model, which combines {{the flexibility of}} relational access with inheritance, run time data typing, late binding, and identity-based access. Virtuoso Universal Server database includes physical <b>file</b> and <b>in</b> memory <b>storage</b> and operating system processes that interact with the storage. There is one main process, which has listeners on a specified port for HTTP, SOAP, and other protocols.|$|R
40|$|P-GRADE portal is a multi-grid portal {{that can}} support GT 2, LCG and gLite based Grid systems. In order to enable MPI {{execution}} in a transparent way {{in any of}} these grids we have developed a generic MPI execution mechanism that can tolerate the lack of shared working directory and is able to work with local job managers unable to support MPI jobs. The solution can support both direct job submission to selected grid sites as well as broker-based job submission. In case of using the EGEE broker the developed method enables the access of remote <b>files</b> stored <b>in</b> <b>storage</b> elements even if the executable code can access only local files...|$|R
40|$|The EXT 3 NS is a {{scalable}} {{file system}} designed to handle video streaming workload in large-scale on-demand streaming services. It {{is based on a}} special H/W device, called Network-Storage card (NS card), which aims at accelerating streaming operation by shortening the data path from storage device to network interface. The design objective of EXT 3 NS is to minimize the delay and the delay variance of I/O request in the sequential workload on NS card. Metadata structure, file organization, metadata structure, unit of storage, etc. are elaborately tailored to achieve this objective. Further, EXT 3 NS provides the standard API’s to read and write <b>files</b> <b>in</b> <b>storage</b> unit of NS card. The streaming server utilizes it to gain high disk I/O bandwidth, to avoid unnecessary memory copies on the data path from disk to network, and to alleviates CPU’s burden by offloading parts of network protocol processing, The EXT 3 NS is a full functional file system based on the popular EXT 3. The performance measurements on our prototype video server show obvious performance improvements. Specifically, we obtain better results from file system benchmark program, and obtain performance improvements in disk read and network transmission, which leads to overall streaming performance increase. Especially, the streaming server shows much less server’s CPU utilization and less fluctuation of client bit rate, hence more reliable streaming service is possible...|$|R
50|$|Likewise {{developed}} a CIFS/SMB implementation (versions 1.0, 2.0, 2.1 and NFS 3.0) back in 2009 {{that provided a}} multiprotocol, identity-aware platform for network access to <b>files</b> used <b>in</b> OEM <b>storage</b> products built on Linux/Unix based devices. The platform {{could be used for}} traditional NAS, Cloud Gateway, and Cloud Caching devices for providing secure access to files across a network. Likewise was purchased by EMC Isilon in 2012.|$|R
40|$|Abstract. ARM is {{the newest}} 32 -bite RISC microprocessor. Its high performance, low power {{consumption}} and flexible extension make ARM particularly suitable for designing embedded system. Therefore, {{the realization of the}} FAT 16 file system with ARM can satisfy the demand of <b>file</b> <b>storage</b> <b>in</b> embedded system. This article descripts the simple realization of FAT 16 file system with ARM 7...|$|R
40|$|Abstract — The aim of {{this paper}} is to {{introduce}} a new algorithm for QOS based resource scheduling. Cloud is a type of parallel and distributed system consisting of a collection of inter-connected and virtualized computers that are dynamically provisioned and presented as one or more unified computing resources based on service-level agreements established through negotiation between the service provider and consumers. Resource scheduling, which is a part of resource management is an important process that takes place <b>in</b> <b>storage</b> cloud which falls under IaaS cloud, so that the available resources may be properly allocated to the requesting tasks in a best fit manner so that no resources are wasted. In this paper a new algorithm is designed for task scheduling to minimize memory wastage since our task is to store some <b>files</b> <b>in</b> the <b>storage</b> cloud, task completion time and task response time. The task manager checks all the virtual machine and assigns the task to proper virtual machine which will have least memory wastage...|$|R
40|$|Abstract—Researches on {{technologies}} about testing {{aggregate bandwidth}} of <b>file</b> systems <b>in</b> cloud <b>storage</b> systems. Through the memory file system, network file system, parallel file system theory analysis, {{according to the}} cloud storage system polymerization bandwidth and concept, developed to cloud storage environment file system polymerization bandwidth test software called FSPoly. In this paper, use FSpoly to luster file system testing, find reasonable test methods, and then evaluations latest development <b>in</b> cloud <b>storage</b> system <b>file</b> system performance by using FSPoly. Keywords-cloud storage, aggregate bandwidth, file system, performance evaluation I...|$|R
40|$|Cloud storage {{has become}} an {{important}} part of a cloud system nowadays. Most current cloud storage systems perform well for large files but they cannot manage small file storage appropriately. With the development of cloud services, more and more small files are emerging. Therefore, we propose an optimized data replication approach for small <b>files</b> <b>in</b> cloud <b>storage</b> systems. A small file merging algorithm and a block replica placement algorithm are involved in this approach. Small files are classified into four types according to their access frequencies. A number of small files will be merged into the same block based on which type they belong to. And the replica placement algorithm helps to improve the access efficiencies of small <b>files</b> <b>in</b> a cloud system. Related experiment results demonstrate that our proposed approach can effectively shorten the time spent reading and writing small files, and it performs better than the other two already known data replication algorithms: HAR and SequenceFile...|$|R
5000|$|Whenever a Search Folder is accessed, it returns {{results that}} are {{relevant}} to a saved search query; results manifest themselves as actual <b>files</b> and folders <b>in</b> <b>storage.</b> Search queries can be defined based on a number of parameters and properties, including all or part of a filename, specific dates, the content of the files themselves, associated metadata, specific file types, where files are located, and various other attributes. A feature called Query Composition allows searches to be based on other Search Folders to further refine results.|$|R
40|$|DE 102005008342 A 1 UPAB: 20061005 NOVELTY - A {{device for}} {{controlling}} audio data storage for an audio-piece <b>in</b> a <b>storage</b> device (1) {{and in which}} a scene description is carried out for each scene, A device (4) is provided for examining the scene description and for ascertaining a first scene which demands a higher processing capacity of the wave-field synthesis system (3) than a second scene. A control device (5) controls the write device (2) so that audio data files are identified by the scene description of the first scene and are written on the storage device (1). DETAILED DESCRIPTION - INDPENDENT CLAIMS are included for; (1) (A) A method for storage of audio data <b>files</b> <b>in</b> a <b>storage</b> device and (2) (B) A computer program product with program code USE - For wave-field synthesis concept and especially {{in connection with a}} multi-rendering system. ADVANTAGE - Facilitates storage of audio data of higher quality and provides easily implemented wave-field synthesis...|$|R
40|$|Phone book {{application}} {{is a program}} for storing names and family relationships. In this program can save, edit, delete and search for family names and relations that have been stored <b>in</b> text <b>files</b> for <b>storage.</b> <b>In</b> the <b>storage</b> process will use the edit distance algorithm {{to determine whether the}} data to be stored already exists or not. Algorithm leveinstein edit distance or distance is an algorithm that compares the words with the words and find the distance difference between the two words are compared...|$|R
40|$|As {{more mobile}} storage devices {{are used in}} {{consumer}} electronics, possibility of user confidential data leakage increases. To make things worse, data of deleted <b>file</b> <b>in</b> mobile <b>storage</b> such as USB drives can be easily recovered and, thus, can be vulnerable to data leakage. To prevent this type of data leakage, efficient secure deletion techniques are required and we present two secure deletion techniques, namely block cleaning and zero overwriting, for Flash memory storage. Also, we propose cost and benefit models of both techniques. The models imply an existence of an efficient adaptive hybrid secure deletion scheme that applies one of the techniques based on their costs and benefits at given data arrangements. Experimental results measured on an Embedded board show that the adaptive hybrid scheme deletes data securely and efficiently for various data patterns on Flash memory storage. clos...|$|R
40|$|The Data Migration Application Programming Interface (DMAPI) has the {{potential}} to allow developers of open systems Hierarchical Storage Management (HSM) products to virtualize native file systems without the requirement to make changes to the underlying operating system. This paper describes advantages of virtualizing native <b>file</b> systems <b>in</b> hierarchical <b>storage</b> management systems, the DMAPI at a high level, what the goals are for the interface, and the integration of the Convex UniTree+HSM with DMAPI along with some of the benefits derived in the resulting product...|$|R
40|$|Storage {{management}} {{is one of}} the most important enabling technologies for large-scale scientific investigations. Having to deal with multiple heterogeneous storage and file systems {{is one of the}} major bottlenecks in managing, replicating, and accessing <b>files</b> <b>in</b> distributed environments. <b>Storage</b> Resource Managers (SRMs), named after their web services control protocol, provide the technology needed to manage the rapidly growing distributed data volumes, as a result of faster and larger computational facilities. SRMs are Grid storage services providing interfaces to storage resources, as well as advanced functionality such as dynamic space allocation and file management on shared storage systems. They call on transpor...|$|R
40|$|With cloud {{computing}} growing in IT Enterprise. {{the importance of}} storing and searching files on the cloud increase. cloud storage {{is defined as a}} set of scalable data servers or chunk servers that provide computing and storage services to clients. Our research concern with searching <b>in</b> the <b>file</b> content throw cloud storage system Our research using ontology approach that can be store and retrieve <b>files</b> <b>in</b> the cloud based on its content to resolves the weaknesses that existed <b>in</b> Google <b>File</b> System that depends on metadata and searching only using file name Our new architecture was tested on Cloud Storage Simulator and the result shows that the new architecture has better scalability, fault tolerance and performance for searching for <b>file</b> content <b>in</b> cloud <b>storage</b> system...|$|R
40|$|To bring {{deduplication}} {{storage of}} VM images, this paper uses LiveDFS as the <b>file</b> system <b>in</b> image <b>storage</b> backend. And <b>in</b> order to offer stable persistent volumes to VM instances, this paper develops a distributed block-level storage system called ORTHRUS which is integrated into this IaaS system. Additionally, this paper deploys Ganglia monitoring {{system in the}} IaaS system to monitor all the physical nodes VM instances. At last, this paper designs and implements a high-performance service, a net disk service and an education management service on this IaaS system...|$|R
40|$|Background/Objective: Brest {{cancer is}} the second reason of {{mortality}} due to cancer in women and according to its high prevalence and psychosociophysical complications, immediate diagnosis is always under consideration. In most cases diagnosis of breast cancer in young women in reproductive ages is difficult. The objective {{of this study was}} report mammographic findings of breast cancer in women under 35 years old. "nPatients and Methods: In this study the present <b>files</b> <b>in</b> <b>storage</b> room of radiology ward of Imam Reza, Qaem, and Omid Hospitals (1995 - 2004). In Mashad university of Medical sciences related to women under 35 years with breast cancer were assessed. Specific goals in this study were specification the clinical signs, mammographic findings, the pathology of breast cancer and also family history. "nResults: A total of 2570 patients with breast cancer during 10 years period refered to these centers that 231 patients (9 %) were &le; 35 years. Sixty two patients (51. 3 %) had positive family history. The most common cancer according to the history was breast cancer in 30 cases (48. 4 %). The most common chief complain in these patients was a mass in 74 cases (80. 4 %). The most common mammographic pattern was mass with microcalcification in 37 cases (33. 9 %). Identifying a mass alone in mammography was seen in 17 cases (15. 6 %). The tumors were in the left breast in 114 cases (49 %), and the most common site was supralateral quadrant (50. 8 %). The most common pathology was ductal carcinoma invasive in 200 cases (86. 6 %). "nConclusion: Breast cancer in young women have poor prognosis. It may be difficult to detect breast cancer in mammography and the other modalities are usually helpful. Masses which discovered by patients themselves must be considered strictly and diagnostic procedures must be performed due to that, immediate treatment would be effective...|$|R
40|$|Errors <b>in</b> <b>files</b> {{detected}} and corrected during operation. Permanent File Validation (PFVAL) utility {{computer program}} provides CDC CYBER NOS sites with mechanism to verify integrity of permanent file base. Locates and identifies permanent <b>file</b> errors <b>in</b> Mass <b>Storage</b> Table (MST) and Track Reservation Table (TRT), <b>in</b> permanent <b>file</b> catalog entries (PFC's) in permit sectors, and in disk sector linkage. All detected errors written to listing file and system and job day files. Program operates by reading system tables, catalog track, permit sectors, and disk linkage bytes to vaidate expected and actual file linkages. Used extensively {{to identify and}} locate errors <b>in</b> permanent <b>files</b> and enable online correction, reducing computer-system downtime...|$|R
40|$|A {{file system}} is {{designed}} to store the data into the storage device efficiently and without any data loss. Every data stored on the storage device is used by some or the other application. When an application is opened, 90 % probability is that the user will open a file which is supported by that application. But the <b>files</b> <b>in</b> the <b>storage</b> devices are not stored in a sorted manner. They are generally stored on the first come first serve basis. We have paid special attention and made efforts to design a file system which stores the data in a sorted manner so that while accessing the data <b>in</b> the <b>file</b> system, the disk header has to make least possible movement thus reducing the seek time and giving an optimal response time. Software is responsible to make the hardware perform its work efficiently. This has influenced the design of ABFS which stands for Application Based File System...|$|R
40|$|High Energy Physics {{experiments}} {{are known for}} their production of large amounts of data. Even small projects may have to manage several Giga Byte of event information. One possible solution for the management of this data is to use today`s technology to archive the raw data <b>files</b> <b>in</b> tertiary <b>storage</b> and build on-line catalogs which reference interesting data. This approach has been taken by the Gammas, Electrons and Muons (GEM) Collaboration for their evaluation of muon chamber technologies at the Superconducting Super Collider Laboratory (SSCL). Several technologies were installed and tested during a 6 month period. Events produced were first recorded in the UNIX filesystem of the data acquisition system and then migrated to the Physics Detector Simulation Facility (PDSF) for long term storage. The software system makes use of a commercial relational database management system (SYBASE) and the Data Management System (DMS), a tape archival system developed at the SSCL. The components are distributed among several machines inside and outside PDSF. A Motif-based graphical user interface (GUI) enables physicists to retrieve interesting runs from the archive using the on-line database catalog...|$|R
40|$|As {{promising}} as {{cloud computing}} is, this paradigm brings forth new security and privacy challenges when {{operating in the}} untrusted cloud scenarios. In this paper, we propose a new cryptographic primitive Proxy Reencryption with Private Searching (PRPS for short). The PRPS scheme enables the data users and owners efficiently query and access <b>files</b> <b>storaged</b> <b>in</b> untrusted cloud, while keeping query privacy and data privacy from the cloud providers. The concrete construction is based on proxy re-encryption, public key encryption with keyword search and the dual receiver cryptosystem. The scheme is semantically secure under the BDH assumption...|$|R
40|$|Abstract. Proofs of Retrievability (POR) is a {{cryptographic}} method for remotely auditing {{the integrity of}} <b>files</b> stored <b>in</b> the cloud, without keeping {{a copy of the}} original <b>files</b> <b>in</b> local <b>storage.</b> <b>In</b> a POR scheme, a user Alice backups her data file together with some authentication data to a potentially dishonest cloud storage server Bob. Later, Alice can periodically and remotely verify the integrity of her data stored with Bob using the authentication data, without retrieving back the data file during a verification. Besides security, performances <b>in</b> communication, <b>storage</b> overhead and computaton are major considerations. Shacham and Waters [1] gave a fast scheme with O(s) communication bits and a factor of 1 /s file size expansion. Although Ateniese et al. [2] achieves constant communication requirement with the same 1 /s storage overhead, it requires intensive computation in the setup and verification. In this paper, we incorporate a recent construction of constant size polynomial commitment scheme into Shacham and Waters [1] scheme. The resulting scheme requires constant communication bits (particularly, 720 bits if elliptic curve is used or 3312 bits if a modulo group is used) per verification and a factor of 1 /s file size expansion, and its computation in the setup and verification is significantly reduced compared to Ateniese et al. [2]. Essentially, Ateniese et al. [2] requires one group multiplication per each bit of the data <b>file</b> <b>in</b> the setup, while the proposed scheme requires one group multiplication per each chunk of data bits (160 bits per chunk if elliptic curve is used or 1024 bits per chunk if modulo group is used). The experiment results show that our proposed scheme is indeed efficient and practical. Our security proof is based on Strong Diffie-Hellman Assumption...|$|R
40|$|Protecting {{confidential}} information {{is a major}} concern for organizations and individuals alike, who stand to suffer huge losses if private data falls into the wrong hands. One of the primary threats to confidentiality is malicious software on personal computers, which is estimated to already reside on 100 to 150 million machines. Current security controls, such as firewalls, anti-virus software, and intrusion detection systems, are inadequate at preventing malware infection. This paper introduces Storages Capsules, a new approach for protecting confidential files on a personal computer. Storage Capsules are encrypted file containers that allow a compromised machine to securely view and edit sensitive files without malware being able to steal confidential data. The system achieves this goal by taking a checkpoint of the current system state and disabling device output before allowing access a Storage Capsule. Writes to the Storage Capsule are then sent to a trusted module. When the user is done editing <b>files</b> <b>in</b> the <b>Storage</b> Capsule, the system is restored to its original state and device output resumes normally. Finally, the trusted module declassifies the Storage Capsule by re-encrypting its contents, and exports it for <b>storage</b> <b>in</b> a low-integrity environment. This work presents the design, implementation, and evaluation of Storage Capsules, with a focus on exploring covert channels...|$|R
40|$|Abstract—Cloud {{computing}} {{has emerged}} as a popular comput-ing paradigm in recent years. However, today’s cloud computing architectures often lack support for computer forensic investiga-tions. A key task of digital forensics is to prove the presence of a particular <b>file</b> <b>in</b> a given <b>storage</b> system. Unfortunately, {{it is very hard to}} do so in a cloud given the black-box nature of clouds and the multi-tenant cloud models. In clouds, analyzing the data from a virtual machine instance or data stored <b>in</b> a cloud <b>storage</b> only allows us to investigate the current content of the cloud storage, but not the previous contents. In this paper, we introduce the idea of building proofs of past data possession in the context of a cloud storage service. We present a scheme for creating such proofs and evaluate its performance in a real cloud provider. We also discuss how this proof of past data possession can be used effectively in cloud forensics. I...|$|R
40|$|The {{concept of}} {{providing}} transparent {{access to a}} collection of <b>files</b> <b>in</b> a mass <b>storage</b> system is a familiar one. The goal of this project {{was to investigate the}} feasibility of providing similar access to a collection of persistent, complex objects. We describe an architecture for interfacing a persistent store of complex objects to a hierarchical storage system. Persistent object stores support the uniform creation, storage, and access of complex objects, regardless of their lifetimes. In other words, a mechanism is provided so that persistent objects outlive the processes which create them and can be accessed in a uniform manner by other processes. We validated this architecture by implementing a proof-of-concept system and testing the system on two stores of data. These tests indicate that this architecture supports the creation, storage, and access of very large persistent object stores...|$|R
40|$|The {{work of the}} Department of Natural Resources impacts {{the lives}} of all Iowans. Iowans deserve a clean {{environment}} and quality natural areas for public use and enjoyment. This report reflects the progress made during fiscal year 2013 (FY 13) toward our goals and provides information regarding the condition of our state’s natural resources and the effectiveness of our programs. In FY 13, we continued to improve collaboration with other executive branch agencies. The DNR and DOT work very closely on the issuance of permits needed for road and bridge constructions, but recently we have also been working together to meet the administrative needs of the agencies. The DNR is working closely with the DOT to adopt an Electronic Records Management System used by the DOT. This system will improve accessibility to public documents and reduce the amount of paper <b>files</b> retained <b>in</b> <b>storage.</b> The DNR also continues to improve collaboration with other agencies, such as the Iowa Economic Development Authority as we work closely with them on business development in the state. The DNR strives to continually improve our customer service and how we can meet Iowan’s needs. As an example, the online reservation system for campground reservations has grown over the past eight years so that now 88...|$|R
40|$|Abstract. Large-scale storage systems {{used for}} {{scientific}} applications can store petabytes {{of data and}} billions of files, making the organization and management of data in these systems a difficult, time-consuming task. The ability to search <b>file</b> metadata <b>in</b> a <b>storage</b> system can address this problem by allowing scientists to quickly navigate experiment data and code while allowing storage administrators to gather {{the information they need}} to properly manage the system. In this paper, we present Spyglass, a file metadata search system that achieves scalability by exploiting storage system properties, providing the scalability that existing file metadata search tools lack. In doing so, Spyglass can achieve search performance up to several thousand times faster than existing database solutions. We show that Spyglass enables important functionality that can aid data management for scientists and storage administrators. 1...|$|R
