27|7|Public
5000|$|A <b>densifier</b> can {{be applied}} once the {{concrete}} is opened up and in a condition to readily accept the chemical. The step at which the <b>densifier</b> is applied is determined by hydration of the slab. There are many types of densifiers including, sodium, potassium, lithium, magnesium fluorosilicate and colloidal.|$|E
5000|$|The <b>densifier</b> {{is allowed}} to dry and cure until proper {{hardness}} has been achieved, followed {{by one or more}} abrasive cuts, which will refine the floor to the desired level of reflectivity.|$|E
50|$|A Powder Deaerator (also powder {{compactor}} or powder <b>densifier)</b> is {{a working}} apparatus for deaerating and compacting / densifying of dry, fine-grained powders. The machine removes excess air and open {{spaces in the}} powder, leaving it a more solid, compact, material.|$|E
50|$|Colloidal silica {{is used in}} {{concrete}} <b>densifiers</b> and polished concrete.|$|R
5000|$|Consolideck - A {{flooring}} system consisting of concrete <b>densifiers,</b> dyes and cleaners.|$|R
50|$|<b>Densifiers</b> may use various {{carrying}} {{agents to}} accomplish the hardening process, potassium, sodium, lithium, or other agents.|$|R
5000|$|A {{concrete}} <b>densifier</b> is {{a chemical}} {{applied to a}} concrete surface in order to fill pores, increasing surface density. Chemical densifiers are used on polished and non-polished concrete to reduce dusting and wear; on polished concrete surfaces densifiers help concrete take a better polish and make the surface less permeable to liquids so the slab does not require sealing.|$|E
5000|$|<b>Densifier</b> - This item {{can alter}} {{the body of a}} person by {{adjusting}} it to allow the body pass through any attack, walls and objective. It can also make the user body too heavy or can be use to weaken a monsters power. It's also has to ability to make the user look like a Dark Phantom.|$|E
50|$|Excess {{water in}} newly placed {{concrete}} {{rises to the}} surface. This bleed water carries with it the finest aggregate and laitance, making it much softer than the slab's core. It also increases the water to cement ratio, which further weakens the surface. Densifiers address this problem by binding to available lime in a pozzolanic fashion, creating additional cementitious material and strengthening the surface. It {{is important to note}} that <b>densifier</b> cannot improve weak/sub-standard concrete to satisfactory levels.|$|E
5000|$|Concrete {{polishing}} uses <b>densifiers</b> {{to achieve}} a better shine. Polishing works by smoothing out peaks and valleys in the surface; if the concrete is not strong enough, this abrasion will remove micro-chunks that decrease the surface uniformity and quality of shine. Concrete surfaces face two major obstacles to polishing: bleed water and pores.|$|R
50|$|Over {{the last}} decade, garage {{flooring}} products {{have become more}} readily available to the general public. In fact, the volume of garage flooring {{on the market today}} can serve as a source of frustration and confusion for homeowners. Generally speaking, these products can be broken into the following categories: garage floor mats, garage floor tiles, coatings (including epoxy, urethanes and hybrids), sealers and <b>densifiers</b> as well as garage floor containment systems.|$|R
50|$|The {{medium in}} the primary DMS circuit {{consists}} of a mixture of milled ferrosilicon and magnetite, with the exact mix regulated to maintain appropriate medium stability. The secondary and scavenger DMS correct mediums consist purely of atomised ferrosilicon. All correct mediums are kept at the correct density using a set of <b>densifiers,</b> supplemented by low intensity wet magnetic separators (LIMS) removing ferrosilicon from the dilute medium. The non-magnetic proportion of the LIMS feed reports to the same effluent tank that also contains the <0.5 mm proportion of the feed removed by the prep screen. The DMS effluent is dewatered using a set of cyclones, with the underflow reporting to the fines storage tank feeding the gravity circuit.|$|R
50|$|Concrete is {{by nature}} a porous material, with pores formed by water {{evaporation}} during curing. These pores interfere with surface uniformity, {{and make the}} slab more susceptible to staining from spilled liquids. The additional cementitious material formed by the <b>densifier</b> and lime tightens these pores for better surface hardness and durability. Most densifiers can react within 1-2 hours with concrete surface, however the chemical reaction with the calcium and free lime in the concrete will continue for up to 2 months after the application {{of it to the}} surface of the concrete.|$|E
5000|$|A diamond {{polished}} {{concrete floor}} is very time-consuming if done correctly, {{this is due}} to the fact that there are at least 6 to 12 steps of actual grinding involved. The general rule is to start the initial grinding with a coarse 30- 60-grit diamond and finish with a 800, 1500- or 3000-grit diamond, depending on the exposure level of aggregate and gloss level required. These diamonds are impregnated inside a metal- or resin-bonded segment. Typically the diamonds' grit size will double once the first grind has been carried out. The use of 30-grit size diamonds, then use 60/80-grit diamonds followed by the 120-grit metal bond segments. The polishing process begins with a 50-grit diamond resin pad instead of a metal segment. When using the resin pads the steps may be 100, then 200, 400, 800, 1500 and finally 3000 grit. Throughout the process a <b>densifier</b> is used to harden the concrete surface, which allows the concrete to be polished. A number of densifiers can be used; these consist of a lithium, potassium or sodium silicates. In some cases A grouting chemical is also used to fill in any holes, cracks or imperfections that were exposed from the initial coarse grinding step. The concrete can be also finished with a natural-look impregnating Polish-Guard; this [...] "Guard" [...] penetrates 2-5 mm inside the pores of the concrete preventing any deep staining from oils and spills. But, is also breathable and not a sealer (as a sealer actually seals the concrete 100% and does not allow vapor transmission).|$|E
40|$|At Dome F, one of {{the summits}} of the East Antarctic Ice Sheet, a very deep ice-coring {{operation}} is {{to be carried out}} by the Japanese Antarctic Research Expedition from 1995. Since it will take two years to complete the coring up to about 3000 m depth, the borehole should be filled with proper drilling fluid to prevent borehole closure during the operation. This paper is a report on our investigations for searching for the proper drilling fluid which can be used in the very cold environment at Dome F. Although the investigations are still in progress, three kinds of fluid were chosen as drilling fluid candidates. They are : 1) n-butyl acetate, 2) "IP-solvent" with <b>densifier</b> and 3) Silicone Oil. Their properties were investigated and compared in terms of density and viscosity, which are essential requirements for a drilling fluid. As a result, it was shown that n-butyl acetate and IP-solvent with <b>densifier</b> can be used as the drilling fluid. However, the use of n-butyl acetate is impossible without sufficient ventilation at the coring site or other action to dispose of its vapor. When the use of IP-solvent with <b>densifier</b> is considered, the choice of proper <b>densifier</b> is also a problem...|$|E
40|$|This paper {{reviews the}} design {{approach}} for material recovery systems, which, through balancing a combina tion of manual and mechanical sorting techniques, {{is able to}} automatically sort up to 75 % of incoming mate rial and process to market specifications while also achieving a percentage of residue less than 5 %. The system is designed utilizing a two-stream ap proach of processing paper and commingled containers separately to maximize material recovery utilizing engi neering expertise which integrates state-of-the-art tech nology to separate and process recyclable material. The technologies applied include the customized use of various material handling conveyors, electromag nets, eddy current separators, air classifiers, vibratory screens and feeders, mechanical sorting tables, crush ers, <b>densifiers,</b> balers, trommel screens, and dust collec tion equipment...|$|R
40|$|This paper {{describes}} in-detail a {{test program}} that was initiated at the Glenn Research Center (GRC) involving the cryogenic densification of liquid oxygen (LO 2). A large scale LO 2 propellant densification system rated for 200 gpm and sized for the X- 33 LO 2 propellant tank, was designed, fabricated and tested at the GRC. Multiple objectives of the test program included validation of LO 2 production unit hardware and characterization of <b>densifier</b> performance at design and transient conditions. First, performance data is presented for an initial series of LO 2 <b>densifier</b> screening and check-out tests using densified liquid nitrogen. The second series of tests show performance data collected during LO 2 <b>densifier</b> test operations with liquid oxygen as the densified product fluid. An overview of LO 2 X- 33 tanking operations and load tests with the 20, 000 gallon Structural Test Article (STA) are described. Tank loading testing and the thermal stratification that occurs inside of a flight-weight launch vehicle propellant tank were investigated. These operations involved a closed-loop recirculation process of LO 2 flow through the <b>densifier</b> and then back into the STA. Finally, in excess of 200, 000 gallons of densified LO 2 at 120 oR was produced with the propellant densification unit during the demonstration program, an achievement that s {{never been done before}} in the realm of large-scale cryogenic tests...|$|E
40|$|Embeddings are generic {{representations}} that {{are useful for}} many NLP tasks. In this paper, we introduce <b>DENSIFIER,</b> a method that learns an orthogonal transformation of the embedding space that focuses the information relevant for a task in an ultradense subspace of a dimensionality that is smaller {{by a factor of}} 100 than the original space. We show that ultradense embeddings generated by <b>DENSIFIER</b> reach state of the art on a lexicon creation task in which words are annotated with three types of lexical information - sentiment, concreteness and frequency. On the SemEval 2015 10 B sentiment analysis task we show that no information is lost when the ultradense subspace is used, but training is an order of magnitude more efficient due to the compactness of the ultradense space...|$|E
40|$|International audienceWe {{present a}} test bench {{designed}} {{to study the}} performances of interferometric recombination systems, mainly for direct imaging applications (hypertelescope principle). It aims at comparing the aperture synthesis, Fizeau and densified pupils beam combination schemes. It allows identification of the technical requirements like photometry and cophasing correction of the future imaging recombiners for large arrays. A densified assembly has been designed in the visible wavelengths, using a multi-apertures mask associated with a wavefront sensor. It allows pupil rearrangement and spatial filtering by using single mode fibers. The technical specifications and the conception of the fiber <b>densifier</b> are described here, with a {{particular attention to the}} correction of the differential chromatic dispersion...|$|E
40|$|We {{initiate}} {{the study of}} inverse problems in approximate uniform generation, focusing on uniform generation of satisfying assignments of various types of Boolean functions. In such an inverse problem, the algorithm is given uniform random satisfying assignments of an unknown function f belonging to a class of Boolean functions, and {{the goal is to}} output a probability distribution D which is ϵ-close, in total variation distance, to the uniform distribution over f^- 1 (1). Positive results: We prove a general positive result establishing sufficient conditions for efficient inverse approximate uniform generation for a class. We define a new type of algorithm called a <b>densifier</b> for, and show (roughly speaking) how to combine (i) a <b>densifier,</b> (ii) an approximate counting / uniform generation algorithm, and (iii) a Statistical Query learning algorithm, to obtain an inverse approximate uniform generation algorithm. We apply this general result to obtain a poly(n, 1 /) -time algorithm for the class of halfspaces; and a quasipoly(n, 1 /) -time algorithm for the class of (n) -size DNF formulas. Negative results: We prove a general negative result establishing that the existence of certain types of signature schemes in cryptography implies the hardness of certain inverse approximate uniform generation problems. This implies that there are no subexponential-time inverse approximate uniform generation algorithms for 3 -CNF formulas; for intersections of two halfspaces; for degree- 2 polynomial threshold functions; and for monotone 2 -CNF formulas. Finally, we show that there is no general relationship between the complexity of the "forward" approximate uniform generation problem and the complexity of the inverse problem for a class [...] it is possible for either one to be easy while the other is hard...|$|E
40|$|A {{method is}} {{provided}} for closing out {{the edges of}} a flexible ceramic insulation member including inner and outer mold line covering layers. A rigid, segmented, ceramic frame is placed round {{the edges of the}} insulation member and exposed edges of the inner and outer mold line covering layers are affixed to the ceramic frame. In one embodiment wherein the covering layers comprise fabrics, the outer fabric is bonded to the top surface and to grooved portion of the side surface of the frame. In another embodiment wherein the outer cover layer comprises a metallic foil, clips on the edges of the frame are used to engage foil extensions. The ceramic frame is coated with a high emittance <b>densifier</b> coating...|$|E
40|$|The GISP deep drill became {{stuck in}} 1981, but was free the {{following}} year. The NGRIP/EPICA deep drill {{has suffered from}} two big setbacks : The drill is stuck both at NGRIP in Greenland and at Dome C in Antarctica. Both events occurred in a period with routine drilling and high productivity. The reasons for the two events {{are believed to be}} different, but the chosen bore-hole liquid seems to be problematic. The <b>densifier</b> can adhere {{to the surface of the}} ice cuttings, making fine ice cuttings to sink in the liquid, in spite of a liquid density of 935 kg/m^ 3. In spite of changed procedures and modified constructions, the drill became stuck again at NGRIP. It was freed using glycol, making use of both the temperature and temperature gradient in the hole...|$|E
40|$|In this paper, {{the results}} of an {{experimentation}} on the production of granules suitable to be used as aggregates in cementitious or asphalt mixes are presented and discussed. The granules were obtained by granulating the non-metallic fraction of automotive shredder residues. In a preliminary separation step the fluff fraction containing mainly inert and non-metallic materials was sieved and analyzed for the metal content. In the following granulation step, the sieved fraction was mixed with binding materials, fly ash and a <b>densifier</b> agent, to produce granules of 5 - 30 mm of diameter and up to 1400 kg/m(3) of specific weight. The granulation was carried out at room temperature in a rotating tank. Concrete samples prepared using as aggregates the produced granules showed a specific weight up to 1800 kg/m(3) and a compressive strength up to about 55 % of reference samples prepared using a calcareous aggregate, depending on the fluff content of the mixes, and {{on the nature of the}} binder and of the other components used. (c) 2006 Elsevier B. V. All rights reserved...|$|E
40|$|A {{concept for}} {{improving}} the performance of propulsion systems in expendable and single-stage-to-orbit (SSTO) launch vehicles much like the X 33 /RLV has been identified. The approach is to utilize densified cryogenic liquid hydrogen (LH 2) and liquid oxygen (LOX) propellants to fuel the propulsion stage. The primary benefit for using this relatively high specific impulse densified propellant mixture is the subsequent reduction of the launch vehicle gross lift-off weight. Production of densified propellants however requires specialized equipment to actively subcool both the liquid oxygen and liquid hydrogen to temperatures below their normal boiling point. A propellant densification unit based on an external thermodynamic vent principle which operates at subatmospheric pressure and supercold temperatures provides a means for the LH 2 and LOX densification process to occur. To demonstrate the production concept for the densification of the liquid hydrogen propellant, a system comprised of a multistage gaseous hydrogen compressor, LH 2 recirculation pumps and a cryogenic LH 2 heat exchanger was designed, built and tested at the NASA Lewis Research Center (LeRC). This paper presents the design configuration of the LH 2 propellant densification production hardware, analytical details and results of performance testing conducted with the hydrogen <b>densifier</b> Ground Support Equipment (GSE) ...|$|E
40|$|In {{this paper}} {{the results of}} an {{experimentation}} on the granulation of non metallic automotive shredder residues to produce aggregates for cementitious or asphalt mixes are presented and discussed. In a preliminary separation step a fraction containing mainly inert and non metallic materials was sieved to obtain the required grading and analyzed for the metal content. In the following granulation step, performed in a pilot scale granulator, the sieved fraction was mixed with binding materials, fly ash and a <b>densifier</b> agent, to produce granules of up to 2000 kg/m 3 of specific weight. The size of the produced granules, between 2 and 40 mm, proved to be a function of water content: increasing the ratio between water and solids the diameter of the particles also increased. The diameter of the produced granules were in the range. The granules were then used to produce artificial lightweight aggregate for concrete mixes. Concrete samples showed a specific weight up to about 2000 kg/m 3 and a compressive strength up to about 30 MPa, depending on the fluff content of the mixes, and {{on the nature of the}} binder and of the other components used. Leaching tests performed on the concrete samples showed that a good immobilization of metals and ions was achieved...|$|E
40|$|Issue: Wood waste {{supplies}} are diverse, ranging from sawdust or shavings to large stumps, containers or portions of structural framing. In some situations, the larger {{pieces of wood}} waste are difficult to load into the primary size reduction equipment. On occasion, the material is simply too large {{to fit into the}} equipment throat. As a result, reducing bulk before conveying to the primary size-reduction equipment presents some advantages. Best Practice: This Best Practice recommends the use of bulk reduction equipment to prepare large wood waste material for feeding into size reduction equipment. The appropriate type of bulk reduction equipment depends on the characteristics of the incoming raw material and downstream equipment. These equipment are discussed below: Mobile Bulk Reduction Attachments: Rolling stock equipment can be fitted with various attachments for reducing the bulk of large wood waste materials. The types of attachments available for front-end loaders and excavators include shears, pulverizers, <b>densifier</b> grapples, and stump splitters. These attachments can be customized to reduce raw materials ranging from pallets and structural framing to stumps. Rolling Stock Compaction: This method of bulk reduction is accomplished by driving the rolling stock over large wood waste before loading it into the processing system. This type of compaction may create to...|$|E
40|$|This {{purpose of}} this paper is to review several {{historical}} cryogenic test programs that were conducted at the NASA Glenn Research Center (GRC), Cleveland, Ohio over the past fifty years. More recently these technology programs were intended to study new and improved denser forms of liquid hydrogen (LH 2) and liquid oxygen (LO 2) cryogenic rocket fuels. Of particular interest are subcooled cryogenic propellants. This is due to the fact that they have a significantly higher density (eg. triple-point hydrogen, slush etc.), a lower vapor pressure and improved cooling capacity over the normal boiling point cryogen. This paper, which is intended to be a historical technology overview, will trace the past and recent development and testing of small and large-scale propellant densification production systems. <b>Densifier</b> units in the current GRC fuels program, were designed and are capable of processing subcooled LH 2 and L 02 propellant at the X 33 Reusable Launch Vehicle (RLV) scale. One final objective of this technical briefing is to discuss some of the potential benefits and application which propellant densification technology may offer the industrial cryogenics production and end-user community. Density enhancements to cryogenic propellants (LH 2, LO 2, CH 4) in rocket propulsion and aerospace application have provided the opportunity to either increase performance of existing launch vehicles or to reduce the overall size, mass and cost of a new vehicle system...|$|E
40|$|A deep {{bore-hole}} 5 G at Vostok Station (East Antarctica) {{from the}} depth of 2755 m was drilled by electromechanical drill KEMS- 132. During wintering of the 40 th (1995) Russian Antarctic Expedition and summer seasons of the 41 st (1995 / 1996), 42 nd (1996 / 1997) and 43 rd (1997 / 1998) RAE the bore-hole was deepened from 2755 to 3623 m. At present the bore-hole 5 G has a complicated stepwise structure. The casing with an inner diameter of 165 mm insulates the upper 120 m of the hole from permeable firn. From 120 m to 2200 m {{the diameter of the}} hole is 153 mm. In the deeper sections of the hole its diameter decreases to 139 mm (between 2200 and 3095 m). 138. 4 mm (3095 - 3321 m), 137. 9 mm (3321 - 3500 m) - 136. 2 mm (3500 - 3570 m), and 135 mm (3570 - 3623 m). The drilling fluid, a mixture of kerosene and Forane F- 141 b as <b>densifier,</b> has an average density of 928 kg/m^ 3. Its level in the hole is maintained at a depth of 95 m. The difference between the overburden pressure of ice and the hydrostatic pressure of the fluid {{at the bottom of the}} hole is estimated to be about 0. 1 MPa. Accordingly, the rate of bore-hole closure at the bottom is calculated to be less than 0. 1 mm/year. Data regarding the technology of drilling by electromechanical drill KEMS- 132 (description of drilling complex, electromechanical drill, casing, stability of the bore-hole) are given...|$|E
40|$|We {{initiate}} a principled study of graph densification. Given a graph G {{the goal of}} graph densification is {{to come up with}} another graph H that has significantly more edges than G but nevertheless approximates G well with respect to some set of test functions. In this paper we focus on the case of cut and spectral approximations. As it turns out graph densification exhibits rich connections to a set of interesting and sometimes seemingly unrelated questions in graph theory and metric embeddings. In particular we show the following results: • A graph G has a multiplicative cut approximation with an asymptotically increased density if and only if it does not embed into ℓ 1 under a weak notion of embeddability. We demonstrate that all planar graphs as well as random geometric graphs possess such embeddings and thus do not have densifiers. On the other hand, expanders do have densifiers (namely, the complete graph) and as a result do not embed into ℓ 1 even under our weak notion of embedding. • An analogous characterization is true for multiplicative spectral approximations where the embedding is into ℓ 2 2. Using this characterization we expose a surprisingly close connection between multiplicative spectral and multiplicative cut densifiers. • We also consider additive cut and spectral approximations. We exhibit graphs that do not possess non-trivial additive densifiers. Our results are mainly based on linear and semidefinite programs (and their duals) for computing the maximum weight <b>densifier</b> of a given graph. This also leads to efficient algorithms in the case of spectral densifiers and additive cut densifiers...|$|E
40|$|High angular {{resolution}} images obtained with a hypertelescope can strongly constrain the radiative-hydrodynamics simulations of red supergiant (RSG) stars, {{in terms of}} intensity contrast, granulation size and temporal variations of the convective motions that are visible on their surface. The characterization of the convective pattern in RSGs is crucial to solve the mass-loss mechanism which contributes heavily to the chemical enrichment of the Galaxy. We show here how the astrophysical objectives and the array configuration are highly dependent to design a hypertelescope. For a given field of view and a given resolution, there is a trade-off between the array geometry {{and the number of}} required telescopes to optimize either the (u,v) coverage (to recover the intensity distribution) or the dynamic range (to recover the intensity contrast). To obtain direct snapshot images of Betelgeuse with a hypertelescope, a regular and uniform layout of telescopes is the best array configuration to recover the intensity contrast and the distribution of both large and small granulation cells, but it requires a huge number of telescopes (several hundreds or thousands). An annular configuration allows a reasonable number of telescopes (lower than one hundred) to recover the spatial structures but it provides a low-contrast image. Concerning the design of a pupil <b>densifier</b> to combine all the beams, the photometric fluctuations are not critical Delta photometry < 50 %) contrary to the residual piston requirements (OPD <lambda/ 8) which requires the development of an efficient cophasing system to fully exploit the imaging capability of a hypertelecope...|$|E
40|$|This {{paper is}} based on the data {{published}} in research report of P. G. Talalay and N. S. Gundestrup; Hole fluids for deep ice core drilling : A review. Copenhagen University, Copenhagen, 1999, 120 p. In the practice of deep ice core drilling only three types of bore-hole fluids have been used : 1) petroleum oil products (fuels or solvents) containing <b>densifier,</b> 2) aqueous ethylene glycol or ethanol solutions, 3) n-butyl acetate. The main parameters of drilling fluids are 1) density and fluid top; 2) viscosity; 3) frost-resistance; 4) stability; 5) compatibility with polymers and metals; 6) volatility; 7) flammability; 8) ice and water solubility; 9) toxicological and environmental characteristics; 10) cost. The main properties of bore-hole fluids which have been used in practice for deep ice drilling as well as potential bore-hole fluids are described. The analyzing of the property 2 ̆ 7 s data showed that there are no ideal drilling fluids. All types of used and potential drilling fluids have their own advantages and disadvantages. Probably {{one of the most promising}} types of drilling fluid is low-temperature silicone oil. It is non-aggressive, inert, and non-toxic. The main problem of silicone oil use is the relatively high viscosity at negative temperatures that have influence on the travel time of the drill string and finally on the total time drilling. The final choice of the drilling fluid depends on the possibilities and the ways of solving of indicating problems and depends on the rational correlation between the cost of drilling fluid and other properties of the fluid...|$|E
40|$|The NASA Glenn Research Center at Lewis Field {{has taken}} the lead in the {{development}} of practical densified cryogenic propellants for launch vehicle applications. The technology of subcooling cryogenic propellants below their normal boiling point to produce a denser fluid {{is one of the key}} process technologies necessary to meet the challenge of single-stage-to-orbit and reusable launch vehicles. Densified propellants are critical to lowering launch costs because they enable more propellant to be packed into a given unit volume, thus improving the performance by reducing the overall size and weight of the launch vehicle. This two-pronged research and test program has evolved into (1) conducting tank loading tests using densified liquid hydrogen and (2) developing two large-scale propellant densification systems that will be performance tested next year at Glenn. The propellant-loading test program was undertaken at Glenn in coordination with Lockheed Martin Michoud Space Systems. In this testing, the liquid hydrogen recirculation and densification process was simulated, and the thermal stratification of the densified propellant was recorded throughout the tank. The test article was a flight-weight tank constructed from composite materials similar to those to be used on the X- 33 launch vehicle. The tank geometry as designed by Lockheed Martin had two cylindrical lobes with a center septum. Liquid hydrogen flow rate, pressure data, and temperature data plotted over time were collected while the subscale tank was filled with 27 R (15 K) densified liquid hydrogen propellant. This testing has validated mathematical models and demonstrated the readiness of densified propellant technology for near-term use. It marks the first time that such a process has been carried out with a multiple-lobe, flight-similar tank. Glenn researchers have also been working on providing a process and critical test data for the continuous production of densified liquid hydrogen (LH 2) and densified liquid oxygen (LO 2). Each densification production process uses a high-efficiency, subatmospheric boiling bath heat exchanger to cool the working fluid. A near triple-point hydrogen boiling bath is used to condition and subcool hydrogen to 27 R (15 K), and a nitrogen boiling bath is used to cool the liquid oxygen to 120 R (66. 7 K). Multistage centrifugal compressors operating at cryogenic inlet conditions maintain the heat exchanger bath vapor pressure below 1 atm. The LO 2 propellant densification unit shown in the photograph has a 30 lb/sec capacity, whereas the LH 2 unit was designed to process 8 lb/sec of propellant. Each densification unit will be transported to Glenn's South Forty area after all fabrication work is completed sometime late next year. There the LO 2 and LH 2 <b>densifier</b> performance tests will be conducted with another larger Lockheed Martin tank designated the Structural Test Article (STA). This liquid oxygen tank is a full-scale, flight-weight, prototype aluminum tank designed for the X- 33. It has a capacity of 20, 000 gallons of LO 2. The tank loading and recirculation testing planned for next year with STA will provide the data necessary for full-scale development of propellant densification technology...|$|E
40|$|Luciola {{is a large}} (one kilometer) "multi-aperture densified-pupil imaging interferometer", or "hypertelescope" {{employing}} {{many small}} apertures, rather than a few large ones, for obtaining direct snapshot images with a high information content. A diluted collector mirror, deployed in space as a flotilla of small mirrors, focuses a sky image which is exploited by several beam-combiner spaceships. Each contains a pupil <b>densifier</b> micro-lens array to avoid the diffractive spread and image attenuation caused by the small sub-apertures. The elucidation of hypertelescope imaging properties {{during the last decade}} has shown that many small apertures tend to be far more efficient, regarding the science yield, than a few large ones providing a comparable collecting area. For similar underlying physical reasons, radio-astronomy has also evolved in the direction of many-antenna systems such as the proposed Low Frequency Array having hundreds of thousands of individual receivers. With its high limiting magnitude, reaching the mv= 30 limit of HST when 100 collectors of 25 cm will match its collecting area, high-resolution direct imaging in multiple channels, broad spectral coverage from the 1200 Angstrom ultra-violet to the 20 micron infra-red, apodization, coronagraphic and spectroscopic capabilities, the proposed hypertelescope observatory addresses very broad and innovative science covering different areas of ESA s Cosmic Vision program. In the initial phase, a focal spacecraft covering the UV to near IR spectral range of EMCCD photon-counting cameras (currently 200 to 1000 nm), will image details on the surface of many stars, as well as their environment, including multiple stars and clusters. Spectra will be obtained for each resel. It will also image neutron star, black-hole and micro-quasar candidates, as well as active galactic nuclei, quasars, gravitational lenses, and other Cosmic Vision targets observable with the initial modest crowding limit. With subsequent upgrade missions, the spectral coverage can be extended from 120 nm to 20 microns, using four detectors carried by two to four focal spacecraft. The number of collector mirrors in the flotilla can also be increased from 12 to 100 and possibly 1, 000. The imaging and spectroscopy of habitable exoplanets in the mid infra-red then becomes feasible once the collecting area reaches 6 m 2, using a specialized mid infra-red focal spacecraft. Calculations (Boccaletti et al., 2000) have shown that hypertelescope coronagraphy has unequalled sensitivity for detecting, at mid infra-red wavelengths, faint exoplanets within the exo-zodiacal glare. Later upgrades will enable the more difficult imaging and spectroscopy of these faint objects at visible wavelengths, using refined techniques of adaptive coronagraphy (Labeyrie. & Le Coroller, 2004). Together, the infra-red and visible spectral data carry rich information on the possible presence of life. The close environment of the central black-hole in the Milky Way will be imageable with unprecedented detail in the near infra-red. Cosmological imaging of remote galaxies at the limit of the known universe is also expected, from the ultra-violet to the near infra-red, following the first upgrade, and with greatly increasing sensitivity through successive upgrades. These areas will indeed greatly benefit from the upgrades, in terms of dynamic range, limiting complexity of the objects to be imaged, size of the elementary Direct Imaging Field, and limiting magnitude, approaching that of an 8 -meter space telescope when 1000 apertures of 25 cm are installed. Similar gains will occur for addressing fundamental problems in physics and cosmology, particularly when observing neutron stars and black holes, single or binary, including the giant black holes, with accretion disks and jets, in active galactic nuclei beyond the Milky Way. Gravitational lensing and micro-lensing patterns, including time-variable patterns and perhaps millisecond lensing flasheshich may be beamed by diffraction from sub-stellar masses at sub-parsec distances (Labeyrie, 1994), will also be observable initially in the favourable cases, and upgrades will greatly improve the number of observable objects. The observability of gravitational waves emitted by binary lensing masses, in the form of modulated lensing patterns, is a debated issue (Ragazzoni et al., 2003) but will also become addressable observationally. The technology readiness of Luciola approaches levels where low-orbit testing and stepwise implementation will become feasible in the 2015 - 2025 time frame. For the following decades beyond 2020, once accurate formation flying techniques will be mastered, much larger hypertelescopes such as the proposed 100 km Exo-Earth Imager and the 100, 000 km Neutron Star Imager should also become feasible. Luciola is therefore also seen as a precursor toward such very powerful instruments...|$|E
40|$|With the SKYLINE (ANR) {{research}} programme, I led a {{group of}} researchers in exploring the landscape issues at stake in connection with towers, focusing attention on a particular dimension of the city landscape: the skyline. Because of their architectural characteristics and their prominence, towers {{become part of the}} material landscape at all levels. On the other hand, only they can be read and {{have an impact on the}} wider landscape in its volume. Sometimes, they act as symbols of a dynamic economy and/or urban renewal and translate into a political project (McNeill 2005; Appert 2008, 2011, 2012). As they are highly visible from far and near, they are among the most widely contested buildings at a time when the landscape is being remobilised both as a living environment, and to win over local populations when it comes to urban projects. In European cities, opposition to towers has become more organised and more widespread: London (Appert and Drozdz 2010), Paris (d’Aboville 2015), but also Seville, Vienna, Barcelona, Geneva and even Saint-Petersburg are affected (Dixon 2009). The first part of Volume 3 describes the resurgence of towers in Europe and elucidates the motivations behind this. The post-war boom years and adherence to urban and architectural modernism precipitated the first construction phase of skyscrapers, both in Eastern and Western Europe. Verticalization of the cities of the continent was brought about by the combined effect of real estate developers and large-scale planning projects by public authorities. The repeated economic crises in the 1970 s and 1980 s and the rise of heritage preservation aspirations diminished the desire for towers, which were rejected both by a sector of the population and city councils. The 1980 ’s and 1990 ’s saw an all-time low, with just a few exceptions. After this “fallow” period during which very few towers were built, European cities saw a renewed enthusiasm for this architectural and urban form. While the resurgence of skyscrapers has, to date, been somewhat timid in France, it has reached unprecedented proportions in a significant number of other European countries, reflecting a complete change in economic and political contexts. The need to densify cities to meet the demands of sustainable development has broad political consensus. This need is met by a public-private partnership in which city councils become entrepreneurial and adopt an agenda of growth, which usually takes the form of policies that aim to make urban districts more attractive. In this context, towers are once again justified. They are synonymous with maximising land use for residential and commercial functions and – when they are located close to public transport hubs – with signs of network centrality and urban renewal. Economic logic will prevail in what is offered; the choice of towers does not emanate from the people and not necessarily from city councils either. Real estate promoters are henceforth the key players in verticalization. Elected representatives, such as Gérard Colomb in Lyon, or indeed Ken Livingstone and Boris Johnson in London, won over by the symbolism of the towers, mastermind projects to promote their areas. Negotiated urbanism, particularly in the case of London, aims first to accommodate urban growth to the detriment of heritage protection or housing supply. The image of towers will often remain complex and polarised. French players questioned for this part of the study confirmed the hypothesis of the shock factor of modernist architecture of large housing developments among professionals, elected representatives and a section of the population. Taking cognizance of this negative mindset, promoters are not reckoning on a “spontaneous” resurgence of towers (Fincher,  2007; Mollé, 2016). Rather they are tending towards remobilising the mindsets of elevation, domination and distinction to reformulate their vertical housing and office offers as commercial products that combine accommodation, views and lifestyles. The second part of volume 3 revisits the landscape issues at stakes with the return of towers in Europe. Scientific research that has sustainability in its sights, had for a long time failed to recognise the impact the towers had on the landscape. Promoting a sustainable city should not be limited to identifying and creating conditions for lower energy consumption. We should also consider the potential change in the relationship between urban societies and their landscape in the context of verticalization. Projecting urban activities, standards and regulations, the urban landscape is also a territorial marker, a sign of living together and a social and economic resource. The return of towers is mobilising several landscape dimensions. In most cases the skyline - even if it is not always named - is at the core of conflicts between economic players, professionals, elected representatives and associations in terms of material existence and representation of a large part of the urban area read vertically. The second part of the Volume is devoted to this idea. Having recorded and analysed the conflicts in relation to the skyline (Appert, 2008, 2011; Appert and Montès, 2015), I now propose to decrypt the skyline, to stabilise its content and contours, and to discuss its physical and mental representations in order to feed the public debate. The reflection is also intended for a host of players, city councils and associations who are confronted with increasing pressure in favour of verticalization. The proposal I have devised to define the skyline is based on three assumptions. First, the skyline covers a material dimension: it corresponds with an entire combination of views and viewpoints which lead the eye to observe large portions of the urban territory engaging its verticality against the sky. Then, the skyline has a social and cultural dimension: it projects human activities, cultural, social and regulatory norms. In return, through the representation of players, it carries economic values and contributes to lifestyle and well-being. Finally, the skyline is political: as projector and landmark of a pluralist urban society, it is the subject of debates and regulations. The term skyline thus becomes a scientific object that the geographer may engage with, both in a heuristic perspective and in the purpose of decision-making (Chapter 3). Defining the skyline constitutes a first phase in which to discuss three dimensions of the notion, with as many different methodological approaches: the material presence of the vistas and visibility, especially through modelling (Chapter 4), the significance and aesthetic aspects of the skyline, mobilising more sensitive and cultural approaches (Chapter 5) and their reception by experts and lay people gathered by means of surveys (Chapter 6). The last part of Volume 3 constitutes a programme of future research to be carried out in an extension of the ANR SKYLINE programme. This future research will deal with the vertical city, which I continue to feed through two distinct lines of research: dwelling practices in the towers, and the definition and assessment of the urban canopy. The first line, one of the 4 of the industrial chair HEVD (Université de Lyon, labex IMU) is examining dwelling practice in the towers through the production of a vertical home, its representations and the lifestyles therein in France and the United Kingdom. The first observation is the exclusion of the choice of towers in urban renewal schemes in France, even though the other European countries have cumulatively approved more than 350 projects (Appert, 2015). After characterisation of the projects approved in the United Kingdom, it will be a question of examining the exclusion of this architectural choice in France through the recension and analysis of the strategies employed by the players in the real estate industry, as well as the representations with respect to residential towers in France, whether by professionals, players in the real estate industry or people living in towers. Then I will do a more specific study on lifestyles and habits (domestic, mobility, sociability and use of spaces) in private and social housing in residential towers using several case studies. Finally, I will analyse the regulatory constraints and the technical and economical contexts associated with the construction of vertical accommodation in order to understand their repercussions for, on the one hand, the strategies of the players in the real estate industry and on the other, the conditions of occupation and use by the residents. The planned case studies will be about contemporary works involving the partner GFC/Bouygues in London and Lyon, as well as two case studies on social housing, the Montée de l’Observance towers in Lyon and a housing scheme in East London. The second line of research is based on developing the research project for submission of an application to the ANR which I will lead during the next “Villes et bâtiments durables”* call for projects (AAP) in 2016. The project brings together researchers and professionals from various disciplines (geography, information technology, urbanism, architecture, law and sociology) to study the capacity, visibility, potential and possible uses of the urban canopy. Facing the pressures of environmental sustainability and steady urbanisation, roofs (built element of the urban canopy) could contribute additional capacity, constitute spaces for living, leisure and even production, agriculture and electricity, etc. The project envisages: 1 / cross-disciplinary reflection on the delineation of the urban canopy; 2 / an analysis of experience in using rooftops and developing rooftop spaces; 3 / an assessment of the capacity and visibility of the urban canopy and 4 / the development and testing of scenarios for reuse of roofs (in cooperation with the post-doctoral researcher in information technology). Avec le programme de recherche SKYLINE (ANR), j’ai emmené un collectif de chercheurs dans l’exploration des enjeux paysagers des tours en focalisant l’attention sur une dimension particulière du paysage de la ville : le skyline. Du fait de leurs caractéristiques architecturales et de leur proéminence, les tours s’inscrivent dans le paysage matériel à toutes les échelles. En revanche, elles seules sont lisibles et impactent le grand paysage lu dans son volume. Elles y jouent parfois le rôle d’emblèmes de dynamisme économique et/ou de renouvellement urbain et traduisent un projet politique (McNeill 2005  ; Appert 2008, 2011, 2012). Par leur visibilité, de près comme de loin, elles font partie des édifices les plus contestés, ce au moment où le paysage est remobilisé à la fois comme cadre de vie et pour faire adhérer les populations aux projets urbains. Dans les villes européennes, la contestation des tours s’organise et s’amplifie : Londres (Appert et Drozdz 2010), Paris (d’Aboville 2015), mais aussi Séville, Vienne, Barcelone, Genève et même Saint-Pétersbourg sont concernées (Dixon 2009). La première partie du volume 3 consiste à caractériser le retour des tours en Europe et à en expliciter les ressorts. Les crises économiques qui se succèdent dans les années 1970 et 1980 et la montée des aspirations à la patrimonialisation réduisent l’appétence pour les tours nées du modernisme et de la phase de verticalisation des Trente Glorieuses. Elles sont rejetées à la fois par une partie de la population et les municipalités. Les décennies 1980 et 1990 sont celles d’un étiage marqué, à quelques exceptions prés. Après cette période d’étiage durant laquelle très peu de tours ont été construites, les villes européennes connaissent un regain d’intérêt pour cette forme architecturale et urbaine. Si le retour des tours est encore modeste en France, il atteint une ampleur sans précédent dans bon nombre de pays européens, témoignant tout d’un changement de contexte économique et politique. La nécessité de <b>densifier</b> les villes pour en réponse aux injonctions du développement durable fait quasi-consensus politique. Elle s’arrime sur une gouvernance publique-privée dans laquelle les municipalités devenues entrepreneuriales adoptent un agenda de croissance qui passe le plus souvent par des politiques visant à rendre plus attractifs les territoires urbains. Dans ce contexte, les tours se trouvent de nouveau légitimées. Elles sont synonymes de maximisation de l’usage du sol pour des fonctions résidentielles et commerciales et, lorsqu’elles sont localisées à proximité des nœuds de transport collectif, des signaux de centralité de réseau et de régénération urbaine. C’est une logique économique de l’offre qui prévaudrait : le choix des tours n’émane pas des populations et pas non plus nécessairement des municipalités. La promotion immobilière est désormais le principal acteur de la verticalisation. Les élus, tels que Gérard Colomb à Lyon, ou encore Ken Livingstone et Boris Johnson à Londres, conquis par la symbolique des tours, instrumentalisent les projets pour commercialiser leurs territoires. Les représentations des tours resteraient souvent complexes et polarisées. Les acteurs français interrogés dans cette partie ont confirmé l’hypothèse d’un traumatisme de l’architecture moderniste, des grands ensembles, parmi les praticiens, les élus et une partie de la population. Prenant acte de cette imaginaire négatif, les promoteurs ne tableraient donc pas sur un retour « spontané » vers les tours (Fincher,  2007; Mollé, 2016). Ils tendraient plutôt à remobiliser les imaginaires de l’élévation, de la domination et de la distinction, pour reformuler leur offre de logements et de bureaux verticaux dans des produits commerciaux qui associent habitat, vue et lifestyles. La deuxième partie du volume 3 revient sur les conflits paysagers suscités par le retour des tours en Europe. Les recherches scientifiques qui ont pour horizon la durabilité, ont longtemps laissé de côté l’impact paysager des tours. Promouvoir une ville durable ne se limite pas à identifier et mettre en œuvre les conditions d’une ville moins énergivore, il s’agit aussi de considérer l’altération potentielle des rapports des sociétés urbaines à leur paysage dans le contexte de verticalisation. Projection des activités, des normes et des règlements urbains, le paysage urbain est aussi un marqueur territorial, une signalétique du vivre ensemble et une ressource économique et sociale. Le retour des tours mobilise plusieurs dimensions du paysage. Dans la majorité des cas, le skyline - même s’il n’est pas toujours nommé - en tant que matérialité et représentation d’une vaste portion du territoire urbain lue dans sa verticalité, est au cœur de conflits entre acteurs économiques, praticiens, élus et associations. La deuxième partie du volume lui est consacré. Ayant acté et analysé les conflits associés au skyline (Appert, 2008, 2011; Appert et Montès, 2015), J’ai proposé de le décrypter, d’en stabiliser le contenu et les contours, et d’en discuter les représentations matérielles et mentales pour alimenter le débat public. L’horizon de la réflexion est aussi celui d’un appareillage des acteurs, municipalités et associations, confrontés à une accentuation de la pression à la verticalisation. La dernière partie du volume 3 constitue une programmation des recherches à venir dans le prolongement du programme ANR SKYLINE. Ces recherches futures s’inscrivent dans le champ de la ville verticale, que je continue à alimenter à travers deux axes distincts : l’habiter dans les tours (chaire industrielle HEVD Université de Lyon, labex IMU) et la formalisation et la mesure de la canopée urbaine (ANR CANOPY) ...|$|E

