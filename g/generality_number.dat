3|18|Public
40|$|Viable {{cryptosystem}} designs {{must address}} power analysis attacks, and masking is a commonly proposed technique for defending against these side-channel attacks. It {{is possible to}} overcome simple masking by using higher-order techniques, but apparently only at some cost in terms of <b>generality,</b> <b>number</b> of required samples from the device being attacked, and computational complexity. We make progress towards ascertaining {{the significance of these}} costs by exploring a couple of attacks that attempt to efficiently employ second-order techniques to overcome masking. In particular, we consider two variants of second-order differential power analysis: Zero-Offset 2 DPA and FFT 2 DPA...|$|E
40|$|This paper {{asks the}} question: Can we see {{evidence}} of General Purpose Technologies in patent data? Using data on three million US patents granted between 1967 and 1999, and their citations received between 1975 and 2002, we construct {{a number of}} measures of GPTs, including <b>generality,</b> <b>number</b> of citations, and patent class growth, for patents themselves and for the patents that cite the patents. A selection of the top twenty patents in the tails {{of the distribution of}} several of these measures yields a set of mostly ICT technologies, of which the most important are those underlying transactions on the internet and object-oriented software. We conclude with a brief discussion of the problems we encountered in developing our measures and suggestions for future work in this area. ...|$|E
30|$|In this section, several {{numerical}} {{examples are}} performed {{to demonstrate the}} efficiency of the proposed scheme. A single-group multicasting system with two users is employed and without loss of <b>generality,</b> the <b>number</b> of receive antennas for each user is set equal to each other, i.e., N 1 = N 2 = N. Transmit symbols are commonly chosen from quadrature phase shift keying (QPSK) constellation throughout this paper.|$|R
30|$|In what follows, {{and without}} loss of generality, we {{normalize}} t =  1 {{and all other}} parameters are just “normalized by t”. This normalization is completely general. We also assume (without loss of <b>generality)</b> that the <b>number</b> of workers is n =  1.|$|R
30|$|From Corollary  3.9 we {{know that}} for self-adjointness of K and A(U) the {{condition}} β_j∈R for all j∈Θ_ 1 is necessary. Hence we require without loss of <b>generality</b> that the <b>numbers</b> ε_s for s∈Θ_ 1 are chosen as in Proposition  3.8, conditions 2 and 3.|$|R
3000|$|... ◇. That {{indicates}} x^∈S^. Therefore, we {{have that}} p^S⊂S^. Conversely, we can show that S^⊂p^S by reverting above steps. Hence, p^S = S^. Without loss of <b>generality,</b> the positive <b>number</b> p is always assumed to be 1 in the rest part of the paper.|$|R
50|$|Kermack and McKendrick {{were able}} to show that it admits an {{stationary}} solution where disease is endemic, as long as the supply of susceptible individuals is sufficiently large. This model is difficult to analyze in its full <b>generality,</b> and a <b>number</b> of open questions remain regarding its dynamics.|$|R
30|$|In {{the case}} of {{multiple}} VNs mapping, the number of VNs simultaneously arriving is random in real applications. In our simulations, without the loss of <b>generality,</b> the <b>number</b> of arriving VNs is randomly distributed from 1 to 4, and each VN randomly consists of 3 or 4 nodes. The resource demand of each node is a variable that is randomly generated between 20 and 30, and its geographic coordinate is also generated randomly with the longitude and latitude whose values fall into a specific range. The possibility that there exists a virtual link between two virtual nodes is 50 %. The bandwidth demand of the virtual link is randomly generated between 50 and 80.|$|R
40|$|Distance-based {{methods are}} popular for reconstructing {{evolutionary}} trees of protein sequences, {{mainly because of}} their speed and <b>generality.</b> A <b>number</b> of variants of the classical neighbor-joining algorithm have been proposed, {{as well as a}} number of methods to estimate protein distances. We here present a large-scale assessment of performance in reconstructing the correct tree topology for the most popular algorithms. The programs BIONJ, FastME, Weighbor, and standard neighbor-joining were run using 12 distance estimators, producing 48 tree building / distance estimation method-combinations. These were evaluated on a test set based on real trees taken from 100 Pfam families. Each tree was used to generate multiple sequence alignments with the ROSE program using three evolutionary models. The accuracy of each method was analyzed as a function of both sequence divergence and location in the tree. We found that BIONJ produced the overall best results, although the average accuracy differed little between the tree building methods (normally less than a percent). A noticeable trend was that FastME performed poorer than the rest on long branches. Weighbor wa...|$|R
40|$|This {{study used}} bibliometric methods to analyze subject {{disciplines}} of knowledge originality and knowledge generality for Library and Information Science (LIS) by using citing and cited documents from 1997 to 2006. We {{found that the}} major subject disciplines of knowledge originality and generality are still LIS, and computer science and LIS interact and influence each other closely. It is evident that number of subject disciplines of knowledge originality is {{higher than that of}} knowledge generality. The interdisciplinary characteristics of LIS are illustrated by variety areas of knowledge originality and knowledge <b>generality.</b> Because the <b>number</b> of received subject disciplines is higher than that of given subject disciplines, it suggests that LIS is an application-oriented research area. [Article content in Chinese...|$|R
40|$|Abstract We {{consider}} the GI/D/n + GI many-server queue, with renewal arrival process (the first GI), deterministic (D) service times, {{a large number}} n of servers and customer abandonment, with i. i. d. abandonment times having a general distribution (the +GI), when the arrival rate exceeds the maximum total service rate. The customer abandonment keeps the model stable: In great <b>generality,</b> the <b>number</b> of customers in the system converges to a unique stationary distribution. However, when n is large, if the system does not start with that steady state distribution, e. g., if it starts empty, then the time-dependent performance tends to rapidly become periodic with a period equal to the service time. This anomalous behavior is explained through a many-server heavy-traffic fluid limit in which n → ∞. The limiting deterministic fluid model also has a unique stationary point, but that stationary point is not approached from any other initial state. Instead, the fluid model performance approaches one of its uncountably many periodic steady states. Keywords many-server queues · deterministic fluid model · customer abandonment · deterministic service times · periodic steady state · transient behavior · multiple equilibria · nearly deterministic queues · asymptotic stabilit...|$|R
5000|$|As {{the laws}} of {{rational}} trigonometry give algebraic (and not transcendental) relations, they apply in <b>generality</b> to algebraic <b>number</b> fields beyond the rational numbers. Specifically, any finite field which does not have characteristic 2 reproduces a form of these laws, and thus a finite field geometry. The 'plane' formed by a finite field [...] is the cartesian product [...] of all ordered pairs of field elements, with opposite edges identified forming {{the surface of a}} discrete torus. Individual elements correspond to standard 'points' whereas 'lines' are sets of no more than [...] points related by incidence (an initial point) plus direction or slope given in lowest terms (say all points '2 over and 1 up') that 'wrap' the plane before repeating.|$|R
40|$|To {{characterize}} {{the influence of}} decision makers’ psychological factors on the group decisionprocess, this paper develops {{a new class of}} aggregation operators based on reference-dependentutility functions (RUs) in multi-attribute group decision analysis. We consider two types of RUs:S-shaped, representing decision makers who are risk-seeking for relative losses, and non-S-shaped,representing those that are risk-averse for relative losses. Based on these RUs, we establish twonew classes of reference-dependent aggregation operators; we study their properties and showthat their <b>generality</b> covers a <b>number</b> of existing aggregation operators. To determine the optimalweights for these aggregation operators, we construct an attribute deviation weight model and adecision maker (DM) deviation weight model. Furthermore, we develop a new multi-attribute groupdecision-making (MAGDM) approach based on these RU aggregation operators and weight models. Finally, numerical examples are given to illustrate the application of the approach...|$|R
60|$|But to take Things as they are, {{and only}} talk {{by way of}} natural Consequence, for to argue from Nature is {{certainly}} the best Way {{to find out the}} Devil's Story; if there are good and evil Spirits attending us, that is to say, a good Angel and a Devil, then 'tis no unjust Reproach upon any Body to say, when they follow the Dictates of the latter, the Devil is in them; or they are Devils; nay, I must carry it farther still, namely, that as the <b>Generality</b> and greatest <b>Number</b> of People do follow and obey the evil Spirit and not the good, and that the predominate Power is allowed to be the nominating Power; you must then allow, that in short, the greater Part of Mankind has the Devil in them, and so I come to my Text.|$|R
40|$|For an L ^ 2 -bounded Calderon-Zygmund Operator T, and {{a weight}} w ∈ A_ 2, {{the norm of}} T on L ^ 2 (w) is {{dominated}} by A_ 2 characteristic of the weight. The recent theorem completes a line of investigation initiated by Hunt-Muckenhoupt-Wheeden in 1973, {{has been established in}} different levels of <b>generality</b> by a <b>number</b> of authors over the last few years. It has a subtle proof, whose full implications will unfold over the next few years. This sharp estimate requires that the A_ 2 character of the weight can be exactly once in the proof. Accordingly, {{a large part of the}} proof uses two-weight techniques, is based on novel decomposition methods for operators and weights, and yields new insights into the Calderón-Zygmund theory. We survey the proof of this Theorem in this paper. Comment: 19 pages. Submitted to the proceedings of the Jozef Marcinkiewicz Centenary Conferenc...|$|R
30|$|Note {{that there}} is a {{trade-off}} between the H constraint and number of queries required to breach the constraint. For example, if the DO is comfortable in revealing data to a granularity of H= 2 ^ 24, then considering n = 32 results in u = 8 and l = 24. Thus, 2 ^ 8 = 256 queries are sufficient to breach this interval constraint. On the other hand, if H was 2 ^ 20, then 2 ^ 12 = 1024 queries would be needed to breach the constraint. In the coming sections, we will assume, without loss of <b>generality,</b> that the <b>number</b> of bits in the RS partition is equal to the number of bits in the BS partition, i.e., the PT is divided into two equal halves (u = l = n/ 2). This leads to a balance between the RPS constraint and the number of queries needed to breach the constraint.|$|R
40|$|The present work {{describes}} the design, implementation {{and evaluation of}} a system for automatic audio signal classification. The signals are classified according to audio type, such as speech, background noise and several musical genres. The classification process is organized hierarchically, that is, as a succession of type decisions. At {{the highest level of}} the hierarchy, signals are recognized as speech, music or background noise. Speech signals are further divided into male speech, female speech and speech with background music or noise. Special focus is given to the distinction between music genres, where a total of 13 classical and non-classical genres have been considered. Also, an effort was made in selecting the music genres, aiming at simplicity and <b>generality.</b> A large <b>number</b> of audio features are evaluated for their suitability in such a classification task, including well-known physical and perceptual features, audio descriptors defined in the MPEG- 7 standard, as well as new features proposed in this work. They are selected with regard to their robustness to noise an...|$|R
40|$|Abstract Background Distance-based {{methods are}} popular for reconstructing {{evolutionary}} trees {{thanks to their}} speed and <b>generality.</b> A <b>number</b> of methods exist for estimating distances from sequence alignments, which often involves some sort of correction for multiple substitutions. The problem is to accurately estimate the number of true substitutions given an observed alignment. So far, the most accurate protein distance estimators have looked for the optimal matrix {{in a series of}} transition probability matrices, e. g. the Dayhoff series. The evolutionary distance between two aligned sequences is here estimated as the evolutionary distance of the optimal matrix. The optimal matrix can be found either by an iterative search for the Maximum Likelihood matrix, or by integration to find the Expected Distance. As a consequence, these methods are more complex to implement and computationally heavier than correction-based methods. Another problem is that the result may vary substantially depending on the evolutionary model used for the matrices. An ideal distance estimator should produce consistent and accurate distances independent of the evolutionary model used. Results We propose a correction-based protein sequence estimator called Scoredist. It uses a logarithmic correction of observed divergence based on the alignment score according to the BLOSUM 62 score matrix. We evaluated Scoredist and a number of optimal matrix methods using three evolutionary models for both training and testing Dayhoff, Jones-Taylor-Thornton, and Müller-Vingron, as well as Whelan and Goldman solely for testing. Test alignments with known distances between 0. 01 and 2 substitutions per position (1 – 200 PAM) were simulated using ROSE. Scoredist proved as accurate as the optimal matrix methods, yet substantially more robust. When trained on one model but tested on another one, Scoredist was nearly always more accurate. The Jukes-Cantor and Kimura correction methods were also tested, but were substantially less accurate. Conclusion The Scoredist distance estimator is fast to implement and run, and combines robustness with accuracy. Scoredist has been incorporated into the Belvu alignment viewer, which is available at ftp://ftp. cgb. ki. se/pub/prog/belvu/. </p...|$|R
60|$|The {{adherence}} to abstractions, {{or to the}} personification of abstractions, is closely allied in Young to the want of genuine emotion. He sees virtue sitting on a mount serene, far above the mists and storms of earth; he sees Religion {{coming down from the}} skies, with this world in her left hand and the other world in her right; but we never find him dwelling on virtue or religion as it really exists—in the emotions of a man dressed in an ordinary coat, and seated by his fireside of an evening, with his hand resting on the head of his little daughter, in courageous effort for unselfish ends, in the internal triumph of justice and pity over personal resentment, in all the sublime self-renunciation and sweet charities which are found in the details of ordinary life. Now, emotion links itself with particulars, and only in a faint and secondary manner with abstractions. An orator may discourse very eloquently on injustice in general, and leave his audience cold; but let him state a special case of oppression, and every heart will throb. The most untheoretic persons are aware of this relation between true emotion and particular facts, as opposed to general terms, and implicitly recognize it in the repulsion they feel toward any one who professes strong feeling about abstractions—in the interjectional “Humbug!” which immediately rises to their lips. Wherever abstractions appear to excite strong emotion, this occurs in men of active intellect and imagination, in whom the abstract term rapidly and vividly calls up the particulars it represents, these particulars being the true source of the emotion; and such men, if they wished to express their feeling, would be infallibly prompted to the presentation of details. Strong emotion can no more be directed to generalities apart from particulars, than skill in figures can be directed to arithmetic apart from <b>numbers.</b> <b>Generalities</b> are the refuge at once of deficient intellectual activity and deficient feeling.|$|R
40|$|The {{determination}} of the energy levels and the probabilities of transition between them, by the formal analysis of observed electronic, vibrational, and rotational band structures, forms the direct goal of all investigations of molecular spectra, but the significance of such data lies {{in the possibility of}} relating them theoretically to more concrete properties of molecules and the radiation field. From the well developed electronic spectra of diatomic molecules, it has been possible, with the aid of the non-relativistic quantum mechanics, to obtain accurate moments of inertia, molecular potential functions, electronic structures, and detailed information concerning the coupling of spin and orbital angular monenta with the angular momentum of nuclear rotation. The silicon fluori 1 e molecule has been investigated in this laboratory, and is found to emit bands whose vibrational and rotational structures can be analyzed in this detailed fashion. Like silicon fluoride, however, the great majority of diatomic molecules are formed only under the unusual conditions of electrical discharge, or in high temperature furnaces, so that although their spectra are of great theoretical interest, the chemist is eager to proceed to a study of polyatomic molecules, in the hope that their more practically interesting structures might also be determined with the accuracy and assurance which characterize the spectroscopic determinations of the constants of diatomic molecules. Some {{progress has been made in}} the {{determination of}} molecule potential functions from the vibrational term values deduced from Raman and infrared spectra, but in no case can the calculations be carried out with great <b>generality,</b> since the <b>number</b> of known term values is always small compared with the total number of potential constants in even so restricted a potential function as the simple quadratic type. For the determination of nuclear configurations and bond distances, however, a knowledge of the rotational terms is required. The spectra of about twelve of the simpler polyatomic molecules have been subjected to rotational analyses, and a number of bond distances are known with considerable accuracy, yet the number of molecules whose rotational fine structure has been resolved even with the most powerful instruments is small. Consequently, it was felt desirable to investigate the spectra of a number of other promising polyatomic molecules, with the purpose of carrying out complete rotational analyses of all resolvable bands, and ascertaining the value of the unresolved band envelopes in determining the structures of such molecules, in the cases in which resolution is no longer possible. Although many of the compounds investigated absorbed too feebly to be photographed under high dispersion with the present infrared sensitizations, the location and relative intensities of their bands, determined by low dispersion measurements, will be reported in the hope that these compounds may be reinvestigated in the future with improved techniques. ...|$|R

