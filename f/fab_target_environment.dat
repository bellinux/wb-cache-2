0|1792|Public
40|$|Telepresent walking {{creates the}} {{sensation}} of walking through a <b>target</b> <b>environment,</b> which is not directly accessible to a human, e. g. because it is remote, hazardous, or of inappropriate scale. A mobile teleoperator replicates user motion and collects visual and auditory information from the <b>target</b> <b>environment,</b> which is then sent and displayed to the user. While walking freely about the user environment, the user perceives the <b>target</b> <b>environment</b> with the sensors of the teleoperator and feels as if walking through the <b>target</b> <b>environment.</b> Without additional processing of the user’s motion data, {{the size of the}} <b>target</b> <b>environment</b> to be explored is limited {{to the size of the}} user environment. Motion compression extends telepresent walking to arbitrarily large <b>target</b> <b>environments</b> without making use of scaling or walking-in-place metaphors. Both travel distances and turning angles are mapped with ratio 1 : 1...|$|R
30|$|They {{maintain}} long-term {{access to}} the <b>target</b> <b>environment.</b>|$|R
40|$|Use of {{appropriate}} nursery environments will maximize gain from selection for yield of wheat (Triticum aestivum L.) in the <b>target</b> population of <b>environments</b> of a breeding program. The {{objective of this}} study was to investigate how well-irrigated (low-stress) nursery environments predict yield of lines in <b>target</b> <b>environments</b> that varied in degree of water limitation. Fifteen lines were sampled from the preliminary yield evaluation stage of the Queensland wheat breeding program and tested in 26 trials under on-farm conditions (<b>Target</b> <b>Environments)</b> across nine years (1985 to 1993) and also in 27 trials conducted at three research stations (Nursery Environments) in three years (1987 to 1989). The nursery environments were structured to impose different levels of water and nitrogen (N) limitation, whereas the <b>target</b> <b>environments</b> represented a random sample of on-farm conditions from the <b>target</b> population of <b>environments.</b> Indirect selection and pattern analysis methods were used to investigate selection for yield in the nursery environments and gain from selection in the <b>target</b> <b>environments.</b> Yield under low-stress nursery conditions was an effective predictor of yield under similar low-stress <b>target</b> <b>environments</b> (r = 0. 89, P 0. 05; severe stress r = - 0. 08, P > 0. 05). Yield in the stress nurseries was a poor predictor of yield in the <b>target</b> <b>environments.</b> Until there is a clear understanding of the physiological-genetic basis of variation for adaptation of wheat to the water-limited environments in Queensland, yield improvement can best be achieved by selection for a combination of yield potential in an irrigated low-stress nursery and yield in on-farm trials that sample the range of water-limited <b>environments</b> of the <b>target</b> population of <b>environments...</b>|$|R
40|$|Drought {{frequently}} limits crop production. A modelling {{approach was}} used to characterise the water deficit that wheat plants experience over the cropping season in <b>targeted</b> <b>environments.</b> Using this insight, the StressMaster application assists in decision-making in managed environment trials to increase the probability of attaining a seasonal drought pattern that represents the <b>targeted</b> <b>environments...</b>|$|R
5000|$|Java Platform, Micro Edition (Java ME) - <b>targeting</b> <b>environments</b> {{with limited}} resources.|$|R
40|$|Abstract — This paper {{presents}} a mechanism which enables verification of algorithmic-level SoC model against actual <b>target</b> <b>environment.</b> By dividing algorithmic SoC model into functional sub-model and interface sub-model and {{to model the}} behavior of the latter with FPGA-based in-circuit emulator, we can verify {{the behavior of the}} former against actual <b>target</b> <b>environment.</b> The proposed mechanism also include a debugging environment for both functional sub-model and interface sub-model, which enables simultaneous debugging of both hardware and software components of the target SoC model. We implemented H. 264 video encoder and decoder model with the proposed method and verified it against actual <b>target</b> <b>environment.</b> I...|$|R
40|$|International audienceIn {{order to}} model {{telecommunications}} services as mobile agent system, we are defining a methodology {{based on the}} RM-ODP standards. Our approach makes {{the distinction between the}} service behavior specification, that is independent of the support environment, and the complete service specification that must take into account the <b>target</b> <b>environment.</b> To obtain this specification, the designer must be able to model the <b>target</b> <b>environment</b> according to the concepts used in the methodology, i. e., the RM-ODP concepts. We describe in this paper such a modeling activity. The <b>target</b> <b>environment</b> that we consider is an OMG-MASIF compliant mobile agent platform. We model it by using the RM-ODP engineering language...|$|R
5000|$|Acquisition {{requirements}}, like System {{requirements and}} technical constraints such as <b>target</b> <b>environment,</b> are defined.|$|R
40|$|Purpose of {{investigation}} was to group test environments in les number of <b>target</b> <b>environments</b> {{on the basis of}} specific interactions of genotypes. Fifteen commercial maize hybrids were investigated. Trials were conducted in six locations during two years. Two hybrids were detected as carriers of maximal grain yield in <b>target</b> <b>environments.</b> By use of information from GxE interaction, narrow adaptability for maize was utilized...|$|R
5000|$|A signal handler can be {{specified}} for all but two signals (SIGKILL and SIGSTOP {{cannot be}} caught, blocked or ignored). A signal handler is a function which is called by the <b>target</b> <b>environment</b> when the corresponding signal occurs. The <b>target</b> <b>environment</b> suspends execution of the program until the signal handler returns or calls [...] For maximum portability, an asynchronous signal handler should only: ...|$|R
40|$|A process-time diagram {{showing the}} {{execution}} history of individual processes and {{the interactions between}} processes {{can be a very}} useful tool in understanding the behavior of a distributed or concurrent application. Managing the size of these visualizations via suitable abstraction facilities is essential for longrunning and complex applications. This paper describes Poet, a tool that collects and visualizes event traces from applications running in several different <b>target</b> <b>environments,</b> such as OSF DCE, ABC++, SR, and PVM. To manage the complexity of the resulting visualizations for non-trivial executions, Poet supports abstraction facilities in both the process and time dimensions. These abstraction facilities enable Poet to visualize distributed executions on a number of abstraction levels. To achieve target-system independence, Poet makes as few assumptions as possible about characteristics that must be possessed by all <b>target</b> <b>environments.</b> Information describing each <b>target</b> <b>environment</b> is placed in configuration files, allowing a single set of Poet executables to be used for all <b>target</b> <b>environments...</b>|$|R
50|$|A {{common cause}} of {{software}} failure (real or perceived) {{is a lack of}} its compatibility with other application software, operating systems (or operating system versions, old or new), or <b>target</b> <b>environments</b> that differ greatly from the original (such as a terminal or GUI application intended to be run on the desktop now being required to become a web application, which must render in a web browser). For example, {{in the case of a}} lack of backward compatibility, this can occur because the programmers develop and test software only on the latest version of the <b>target</b> <b>environment,</b> which not all users may be running. This results in the unintended consequence that the latest work may not function on earlier versions of the <b>target</b> <b>environment,</b> or on older hardware that earlier versions of the <b>target</b> <b>environment</b> was capable of using. Sometimes such issues can be fixed by proactively abstracting operating system functionality into a separate program module or library.|$|R
40|$|The main <b>target</b> <b>environments</b> for {{pearl millet}} {{breeding}} programmes within the Indian arid zone, and male-sterile (A) lines {{for the development}} of suitable landrace-based topcross hybrids (TCHs) and conventional hybrids for the <b>target</b> <b>environments</b> were identified. The <b>target</b> <b>environments</b> were defined as extreme stress, moderate stress and favourable environments based on the available environmental resources for crop production in each target zone. TCHs based on 39 A-lines were classified into five clusters for grain, stover and biomass yields, yield stability, responsiveness to environment, downy mildew [Sclerospora graminicola] and drought resistance, and other variables. The suitability of individual A-lines for different <b>target</b> <b>environments</b> was evaluated based on their ability to produce TCHs with the adaptive traits considered as most important for each <b>target</b> <b>environment.</b> None of the A-lines produced hybrids that were equally well-adapted to all the three types of environments; most of the A-lines produced hybrids that showed a contrasting adaptation pattern to the different <b>target</b> <b>environments.</b> The A-lines ICMA 93111, ICMA 94555, ICMA 95111, HMS 9 A and CZMS 44 A produced highly stable dual purpose hybrids, whereas 842 A, ICMA 95444, ICMA 97111, ICMA 97444 and 843 A produced grain hybrids that were suitable for extreme stress environments. Hybrids developed with ICMA 97333, ICMA 93111, ICMA 95555, ICMA 96333, 842 A, ICMA 91444 and ICMA 92666 were suitable for moderate stress environments since these hybrids were high-yielding, moderately stable and responsive hybrids to better environments. Hybrids based on 5054 A, ICMA 88006, ICMA 95222, ICMA 92333, ICMA 92444, ICMA 94555, ICMA 97333, ICMA 96222, ICMA 97111, ICMA 91444 and ICMA 95444 were the most desirable for favourable environments...|$|R
40|$|Abstract: Telepresence gives a user the {{impression}} of actually being present in a distant environment. A mobile teleoperator acts as a proxy in this <b>target</b> <b>environment,</b> replicates the user’s motion, and records sensory information, which is transferred to the user and displayed in real-time. As a result the user is immersed in the <b>target</b> <b>environment.</b> The user can then control the teleoperator by walking naturally. Motion Compression, a nonlinear mapping between the user’s and the robot’s motion, allows exploration of large <b>target</b> <b>environments</b> even from small user environments. For manipulation tasks haptic feedback is important. However, current haptic displays do not allow wide-area motion. In this work we present our design of a novel haptic display for simultaneous wide area motion and haptic interaction. ...|$|R
40|$|In {{order to}} model {{telecommunications}} services as mobile agent system, we are defining a methodology {{based on the}} RM-ODP standards. Our approach makes {{the distinction between the}} service behavior specification, that is independent of the support environment, and the complete service specification that must take into account the <b>target</b> <b>environment.</b> To obtain this specification, the designer must be able to model the <b>target</b> <b>environment</b> according to the concepts used in the methodology, i. e., the RM-ODP concepts. We describe in this paper such a modeling activity. The <b>target</b> <b>environment</b> that we consider is an OMG-MASIF compliant mobile agent platform. We model it by using the RM-ODP engineering language. Keywords: methodology for agent-based services development, mobile agent architecture, RM-ODP, OMG MASIF standard 1...|$|R
40|$|Telepresence gives a user the {{impression}} of actually being present in a distant environment. A mobile teleoperator acts as a proxy in this <b>target</b> <b>environment,</b> replicates the user’s motion, and records sensory information, which is transferred to the user and displayed in real-time. As a result the user is immersed in the <b>target</b> <b>environment.</b> The user can then control the teleoperator by walking naturally. Motion Compression, a nonlinear mapping between the user’s and the robot’s motion, allows exploration of large <b>target</b> <b>environments</b> even from small user environments. For manipulation tasks haptic feedback is important. However, current haptic displays do not allow wide-area motion. In this work we present our design of a novel haptic display for simultaneous wide area motion and haptic interaction...|$|R
50|$|Identify new {{and useful}} genetic {{variation}} from related species {{and sources of}} wheat germplasm not adapted to <b>target</b> <b>environments.</b>|$|R
30|$|Achieve {{sufficient}} {{area coverage}} (in {{the order of}} hectares) to collect data that {{is representative of the}} <b>targeted</b> <b>environment.</b>|$|R
5000|$|Release related {{activities}} include schedule, orchestration, provisioning and deploying software into production and <b>targeted</b> <b>environment.</b> The specific Release {{activities include}}: ...|$|R
2500|$|In {{explaining}} why the culling {{had missed the}} <b>target,</b> <b>Environment</b> Secretary Owen Paterson famously commented that [...] "the badgers moved the goalposts." ...|$|R
40|$|Due to {{simulation}} overhead, {{validation of}} proposed microarchitecture enhancements {{may be limited}} to simple test scenarios, which focus on the known architectural deficiencies. These test scenarios often avoid a complete simulation of the eventual <b>target</b> <b>environment</b> in which the enhancements will be employed. A case study is presented, comparing and contrasting the performance of previous Thread-Level Speculation (TLS) proposals {{with that of a}} new, context-preserving proposal. Validation is performed within the constraints of a simulated <b>target</b> <b>environment...</b>|$|R
5000|$|The {{fundamental}} {{use of a}} {{cross compiler}} is to separate the build <b>environment</b> from <b>target</b> <b>environment.</b> This is useful {{in a number of}} situations: ...|$|R
40|$|Abstract: The agile {{methods were}} {{investigated}} {{to determine the}} factors making up their <b>target</b> <b>environment.</b> A theoretical model of the <b>target</b> <b>environment</b> for agile methods was developed and then tested using a multi-case study. Data from nine software development projects, both agile and non-agile, was gathered from project leaders. Then a cross-case analysis of each factor in the theoretical model explored the relationship between each of the environmental factors {{and the extent of}} agile method usage. This led to a refined model of the <b>target</b> <b>environment.</b> The empirical data showed that specific environmental factors correlate with effective use of an agile method. We also report that methods are tailored for use, and that, although agile methods are distinct from ad hoc development, the extent of agile method use must be measured before conclusions from agile method studies can be considered valid. ...|$|R
50|$|The default MANA {{configuration}} {{should work}} as-is. However, users {{can change the}} settings to match their <b>target</b> <b>environment</b> such as the SSID, channel number, etc.|$|R
40|$|Terminal {{recommendations}} and rules from most standards generally include references to various interaction objects belonging to different <b>target</b> <b>environments.</b> Since these references {{are not made}} explicit, the standard user is responsible to make a pattern matching between rules contents and physical interaction objects. To avoid problems that such a translation induces, a common view on standardised interaction objects is suggested {{through the use of}} abstract interaction objects. By this way, {{recommendations and}} rules can be expressed independently of <b>target</b> <b>environments</b> without relying on various particularisms...|$|R
40|$|Approaches using breeding, {{physiology}} and modelling for evaluating adaptation of plant genotypes to <b>target</b> <b>environments</b> are discussed {{and methods of}} characterizing the <b>target</b> <b>environments</b> outlined. Traditional approaches, and their limitations, to evaluation of genotypic adaptation using statistical and classificatory techniques with a phenotypic model are discussed. It is suggested that a simple biological model is the most appropriate framework in which to integrate {{physiology and}} modelling with plant breeding. Methods by which physiology and modelling may contribute to assessment of adaptive traits and to selection for adaptation in a breeding programme are considered...|$|R
40|$|The {{relative}} {{performance of}} genotypes for yield and agronomic traits {{is measured in}} multi-environment trials (METs) in order to predict their performance in a <b>target</b> population of <b>environments</b> (TPE). It is shown {{that it is the}} correlation of genotype performance between environments that allows such a prediction. Thus, efficiency of selection and size of realised genetic advance in the TPE depend on the genetic correlation between the test and <b>target</b> <b>environments,</b> the heritability in the test and <b>target</b> <b>environments</b> and the phenotypic variance in the <b>target</b> <b>environments.</b> The phenotypic correlation between genotype performance in test and <b>target</b> <b>environments</b> estimates the combined effects of the genetic correlation and heritability parameters. These relationships from correlated genetic advance theory can be applied to various forms of retrospective analysis (cumulative analysis over years, sequential analysis by adding one year’s data at a time, and status analysis by embedding this year’s data in a long term discrimination space) used to analyse MET data. The best estimate of genotype performance to use in these analyses is obtained using the approach of Gilmour, Cullis and Verbyla (JABES 2 : 269 - 293, 1997). One should fit a model combining design information and spatial adjustment within the trials, either in a one-stage analysis or, if that is not possible, a two-stage analysis where each individual trial is weighted according to the inverse of its estimated error variance and number of replicates...|$|R
40|$|This paper {{proposes a}} novel {{optimization}} technology called deployment time optimization and presents several examples where the proposed technology {{can improve the}} performance of distributed applications. Using the configuration information collected from the <b>target</b> operation <b>environment</b> of an application, the proposed optimization approach tries to deploy only necessary components and best alternatives for the <b>target</b> <b>environment.</b> Since deployment time optimization works at module level, we may call this approach a macro level compilation. To enable deployment time optimization, we have designed a novel framework called Blue Pencil. The Blue Pencil framework consists of policy module for storing rules for optimization, programming environment to support generating glues between distributed modules, configuration discovery module that can collect information about a <b>target</b> <b>environment,</b> and code transformer that can customize an application for a <b>target</b> operation <b>environment.</b> We conclude this paper by presenting a simple example on how to select appropriate bindings between distributed objects as a proof of concept. 1...|$|R
40|$|The {{problem of}} {{learning}} decision rules for sequential tasks is addressed, {{focusing on the}} problem of learning tactical plans from a simple flight simulator where a plane must avoid a missile. The learning method relies on the notion of competition and employs genetic algorithms to search the space of decision policies. Experiments are presented that address issues arising from differences between the simulation model on which learning occurs and the <b>target</b> <b>environment</b> on which the decision rules are ultimately tested. Specifically, either the model or the <b>target</b> <b>environment</b> may contain noise. These experiments examine the effect of learning tactical plans without noise and then testing the plans in a noisy environment, and the effect of learning plans in a noisy simulator and then testing the plans in a noise-free environment. Empirical results show that, while best result are obtained when the training model closely matches the <b>target</b> <b>environment,</b> using a training environment that is [...] ...|$|R
40|$|Designing and {{implementing}} a visual debugger for distributed programs {{is a significant}} challenge. Distributed applications are often large and frequently exhibit {{a high degree of}} complexity. Consequently, a debugger must address problems of complexity and scale in at least two ways. First, appropriate user interfaces should allow a user to manage the vast amount of information typically obtained from distributed executions. Second, the tool itself, in handling this information, should be implemented efficiently, providing a user with reasonable response times for interactive use. Our research efforts, concentrating on these problems, have {{led to the development of}} Poet, a tool for the collection and presentation of event-based traces of distributed executions. Poet makes as few assumptions as possible about characteristics that must be possessed by all <b>target</b> <b>environments.</b> Information describing each <b>target</b> <b>environment</b> is placed in configuration files, allowing a single set of Poet executables to be used for all <b>target</b> <b>environments.</b> Comparing Poet's performance to XPVM, the standard visualization tool for PVM executions, reveals that this target-system independence does not impose a performance penalty...|$|R
40|$|The adequacies of the simulation-based {{assessment}} of speech recognition systems under noisy conditions are investigated and discussed. To evaluate the speech recognition systems in various environments, {{it is desirable}} to collect the test data uttered in the corresponding environments {{but it is not}} realistic since enormous works are required. To conduct evaluations of the speech recognition systems properly, it is promising to simulate evaluation experiments in the <b>target</b> <b>environments</b> as described below: comparatively small test data are collected, and test data of the <b>target</b> <b>environment</b> are generated by computing convolution of the impulse response of the <b>target</b> <b>environment</b> with the collected data. However, {{it is well known that}} changes of the acoustic characteristics are caused by Lombard effect, and so it is not necessarily obvious whether the simulation can precisely approximate the experiment in actual environment. This paper clarifies the condition to perform effective simulations of the noisy speech recognition, focusing on the influence of impulse response accuracies and Lombard effects on the speech recognition performance. Index Terms- Noisy speech recognition, assessment, simulation, impulse response, Lombard effect 1...|$|R
5000|$|Once the {{developer}} {{thinks it is}} ready, the product is copied to a Test environment, to verify it works as expected. This test environment is supposedly standardized and in close alignment with the <b>target</b> <b>environment.</b>|$|R
25|$|The seeding organisms need {{to survive}} and {{multiply}} in the <b>target</b> <b>environments</b> and establish a viable biosphere. Some of the new branches of life may develop intelligent beings who will further expand life in the galaxy.|$|R
40|$|International audienceIn this paper, {{we present}} a domain-specific Interface Definition Language (IDL) and its compiler, {{dedicated}} {{to the development of}} pervasive computing applications. Our IDL provides declarative support for concisely characterizing a pervasive computing environment. This description is (1) to be used by programmers as a high-level reference to develop applications that coordinate entities of the <b>target</b> <b>environment</b> and (2) to be passed to a compiler that generates a programming framework dedicated to the <b>target</b> <b>environment.</b> This process enables veriﬁcations to be performed prior to runtime on both the declared environment and a given application. Furthermore, customized operations are automatically generated to support the development of pervasive computing activities, such as service discovery and session negotiation for stream-oriented devices...|$|R
40|$|A {{combined}} gas chromatography/fast-atom bombardment {{mass spectrometry}} (GC/FABMS) method {{specific to the}} analysis of carboxylic acids is reported. The method is demonstrated in the analysis of organic acids in Freon extracts from oil well production water. The samples are run directly as the extracts. A direct measure of the isomer and molecular weight distribution of the acids is obtained using either FAB-positive or FAB-negative ion detection methods. The FAB-positive method detects the carboxylic acid-Ca-triethanolamine complexes that are formed on-line in the selvedge region of the <b>FAB</b> <b>target,</b> Ca-triethanolamine, matrix. The FAB-negative method detects the carboxylic acid anions that are formed in the selvedge region of a clean, stainless steel target plate. Both approaches are carboxylic acid-specific and require minimum preparation prior to analysis. Other components, such as hydrocarbons, also present in oil well water extracts are invisible to the method. This is the first report of the combination of GC and FABMS...|$|R
40|$|AbstractStudies of fast-atom {{bombardment}} (FAB) -induced condensation between trimethyltetradecylammonium cations and glycerol {{have been}} extended to consider spectral time dependence. To enhance reproducibility of time dependence, a modified <b>FAB</b> <b>target</b> was used. <b>FAB</b> mass spectrometry of deuterium-labeled surfactants and FAB/collision-induced dissociation (CID) of nonlabeled material demonstrate that products of condensation at the surfactant “head group” predominate early in the analysis, while tail adducts become prominent later. This time dependence correlates with the expected surface activity of the products. It is incompatible with gas-phase reaction, but consistent with reaction in the condensed phase. Subtle variations in the surface activities of various condensation products (derived from changes {{in the number of}} hydroxyls from the reactive glycerol radical or in the position of attack along the surfactant chain) are reflected in the time dependence of FAB and CID spectra. CID spectra of deuterium-labeled cations provide evidence for intramolecular hydrogen transfer from the surfactant tail to the head within a surfactant radical. This transfer shows no significant kinetic isotope effect...|$|R
