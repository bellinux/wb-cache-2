0|18|Public
40|$|A {{search for}} counterexamples of Randić 2 ̆ 7 s prime {{molecular}} ID-numbers for alkane-trees {{with up to}} 20 carbon atoms produced only one pair of non-isomorphic trees with the same prime ID- number. Thus, it is shown that the prime ID-number, although a highly <b>discriminating</b> molecular <b>descriptor,</b> is not unique...|$|R
40|$|Previously, we {{proposed}} {{the concept of}} connectivity to obtain <b>discriminating</b> shape <b>descriptors.</b> In this paper, we use connectivity to obtain superior distance histograms for multi-scale images. Experiments {{are performed to evaluate}} distance histograms, based on connectivity, for shape-based retrieval of multi-scale images. Item S 8 within the MPEG- 7 Still Images Content Set is used for performing experiments. Experimental results show that the proposed method enhances retrieval performance significantly. 1...|$|R
40|$|We {{propose a}} method for {{enhancing}} the accuracy of shape descriptors. The concept of connectivity to obtain <b>discriminating</b> shape <b>descriptors,</b> is introduced. We show how connectivity is applied to two popular shape descriptors. Experiments are performed to test the effect of using connectivity with generic Fourier descriptors and distance histograms. Item S 8 within the MPEG- 7 still images content set is used for performing experiments. This dataset consists of 3621 still images. The experimental results show that connectivity enhances {{the performance of the}} methods significantly. <br /...|$|R
40|$|In this paper, we have {{proposed}} a method for enhancing the accuracy of shape descriptors. The concept of connectivity, to obtain <b>discriminating</b> shape <b>descriptors,</b> has been introduced. We have shown how connectivity {{can be applied to}} two popular shape descriptors. Experiments were performed to test the effect of using connectivity with Generic Fourier Descriptors and distance histograms. Item S 8 within the MPEG- 7 Still Images Content Set [5] was used for performing experiments. This dataset consists of 3621 still images. The experimental results show that connectivity enhances the performance of the methods significantly...|$|R
40|$|This paper {{considers}} {{the problem of}} shape-based recognition and pose estimation of 3 -D free-form objects in scenes that contain occlusion and clutter. Our approach {{is based on a}} novel set of <b>discriminating</b> <b>descriptors</b> called spherical spin images, which encode the shape information conveyed by classes of distributions of surface points constructed with respect to reference points on the surface of an object. The key to this approach is the relationship that exists between the l 2 metric, which compares n-dimensional signatures in Euclidean space, and the metric of the compact space on which the class representatives (spherical spin images) are defined. The connection allows us to efficiently utilize the linear correlation coefficient to discriminate scene points which have spherical spin images that are similar to the spherical spin images of points on the object being sought. The paper also addresses the problem of a compressed spherical-spin-image representation by means of a random projection of the original descriptors that reduces the dimensionality without a significant loss of recognition/localization performance. Finally, the efficacy of the proposed representation is validated in a comparative study of the two algorithms introduced here that use uncompressed and compressed spherical spin images versus two previous spin image algorithms reported recently in the literature. The results of 2012 experiments suggest that the performance of our proposed algorithms is significantly better with respect to accuracy and speed than the performance of the other algorithms tested...|$|R
40|$|UMR AGAP - équipe AFEF - Architecture et fonctionnement des espèces fruitièresThis study {{aimed to}} assess the centennial olive trees growing across Lebanon, with theperspective of {{conservation}} of the ancient germplasm. The survey indicated the existenceof numerous centennial olive trees distributed in different agro-climatic areas, from 80 to 1350 meters altitude across the country. Centennial olives were found in large sizeorchards and scattered {{as well as in}} young orchards, road hedges and gardens forornamental purposes. Yet, no reliable information is available regarding the age of thecentennials, but they can considered as 500 to 1000 years old. Among these, only sixcentennials located in Bcheale village in the north of the country at 1000 meters altitudeare considered as “millenials” or “monumentals” by the Ministry of Tourism, while theremaining ones widespread across the countries are still ignored. As a preliminarymorphological characterization of the trees conducted on 292 centennials spread in 48 orchards, a large variability was recorded for foot, trunk and central cavity sizes. Principalcomponent analysis showed that foot and trunk circumferences as well as central cavitydiameter were the most <b>discriminating</b> <b>descriptors.</b> Most of the 48 orchards were clusteredtogether in one pool sharing similar traits. The most outstanding orchards were located in 10 locations distributed across Lebanon. At the tree level, six single trees located in Northand Mount Lebanon were well differentiated by their large sized foot, trunk and centralcavity diameter. These centennials should be further characterized using morphologicaland agronomical descriptors in order to understand their performance through time and tovalorize them in selection programs...|$|R
40|$|This study {{aimed to}} assess the centennial olive trees growing across Lebanon, with the {{perspective}} of conservation of the ancient germplasm. The survey indicated the existence of numerous centennial olive trees distributed in different agro-climatic areas, from 80 to 1350 meters altitude across the country. Centennial olives were found in large size orchards and scattered {{as well as in}} young orchards, road hedges and gardens for ornamental purposes. Yet, no reliable information is available regarding the age of the centennials, but they can considered as 500 to 1000 years old. Among these, only six centennials located in Bcheale village in the north of the country at 1000 meters altitude are considered as “millenials” or “monumentals” by the Ministry of Tourism, while the remaining ones widespread across the countries are still ignored. As a preliminary morphological characterization of the trees conducted on 292 centennials spread in 48 orchards, a large variability was recorded for foot, trunk and central cavity sizes. Principal component analysis showed that foot and trunk circumferences as well as central cavity diameter were the most <b>discriminating</b> <b>descriptors.</b> Most of the 48 orchards were clustered together in one pool sharing similar traits. The most outstanding orchards were located in 10 locations distributed across Lebanon. At the tree level, six single trees located in North and Mount Lebanon were well differentiated by their large sized foot, trunk and central cavity diameter. These centennials should be further characterized using morphological and agronomical descriptors in order to understand their performance through time and to valorize them in selection programs...|$|R
40|$|Descriptors for quinoa (Chenopodium quinoa Willd.) and its wild relatives, is a {{revision}} of the original IBPGR (now Bioversity International) publication titled ‘Descriptores de quinua’ (AGP:IBPGR/ 81 / 104). This revision, expanded to accommodate wild relatives, {{is the result of}} a joint collaboration effort involving Bioversity International, FAO, PROINPA, INIAF and IFAD. During the review process, more than 50 quinoa scientists from 11 countries and different organizations provided their expert advice. The updating process of the descriptors for quinoa has been funded by the Proyecto Semillas Andinas de la FAO (GCP/RLA/ 183 /SPA) that runs with funds from the Cooperación Española. This work aims to enhance the use and conservation of plant genetic resources and is expected will contribute to studies focusing on the analysis of genetic diversity, germplasm management, definition of new varieties and useful traits for crop improvement. The scientific overview of this document was provided by Wilfredo Rojas (Fundación PROINPA) and Stefano Padulosi (Bioversity International). The technical advice and coordination of the whole development process by A. Alercia (Bioversity International). This descriptor list is intended to be comprehensive for the descriptors it contains. This approach assists with the standardization of descriptor definitions. Bioversity does not, however, assume that curators will characterize accessions of their collection using all descriptors given. Descriptors should be used when they are useful to curators for the management and maintenance of the collection or to the users of plant genetic resources, or both. To this end, highly <b>discriminating</b> <b>descriptors</b> are listed at the beginning of the Characterization section and are highlighted in the text to facilitate selection of descriptors In Annex I, the reader will find a ‘Collecting form for quinoa’ that will facilitate data collection...|$|R
30|$|The all-facet ruler map {{is useful}} for eyeballing initial {{problems}} with facets on the logit scale. The first column (labeled “Measurement”) is the logit scale, an arbitrary measurement scale centered on 0, running from - 2 up to + 3 logits. The second column (labeled “Item”) contains 39 descriptors, each marked with an ID number, its CEFR level, and its intended CSE level (e.g., V 35 -C 1 -CSE 8). The descriptors were calibrated in rank order on the logit scale. The third column (labeled “Rater”) - with each participant having been assigned an ID number (e.g., T 1 for Teacher 1) - shows each participant’s ability in <b>discriminating</b> between <b>descriptor</b> levels. The use of levels is demonstrated in the last 21 columns, where S. 1 stands {{for the use of}} the scales by T 1, S. 2 for T 2, etc.|$|R
40|$|The optical Fourier {{transformation}} {{was used}} to analyse the chromatin/interchromatin pattern of lymphocytes of healthy subjects and lymphoid cells of patients with chronic lymphocytic leukaemia (CLL, type B, stage O). Peripheral blood smears were prepared routinely, fixed, and stained by the Feulgen method, and the photographic images of the nuclei were quantitatively analysed. From the radial distribution of light intensity of diffractograms, several Feulgen chromatin (F-chromatin/interchromatin) descriptors were evaluated. Four showed the strongest discriminant power and these <b>descriptors</b> <b>discriminated</b> well between lymphocytes of healthy donors and lymphoid cells of CLL patients, although F-chromatin/interchromatin components of the same sizes were found in lymphocytes and lymphoid cells...|$|R
40|$|The general {{distance}} matrix D {{was modified}} to distinguish cis / trans isomers of cycloalkanes. A new topological index, VDI (± 1), {{was derived from}} the modified distance matrix (D mod) according to the calculation of VDI proposed in a previous paper. This new structural <b>descriptor</b> <b>discriminates</b> all compounds studied in this paper. The regression analysis against the boiling temperatures (t b) for 53 cis / trans isomers of cycloalkanes with VDI (± 1) and other topological indices gives a high correlation coefficient (r = 0. 9961) and low standard deviation (s = 3. 31 °C), which is much better than that obtained with VDI (0) ...|$|R
40|$|Descriptors for durian (Durio zibethinus Murr.) were {{developed}} by Drs Songpol Somsri, Alfredo T. Corpuz, Salma Idris and Bhag Mal. Dr Bhag Mal coordinated {{the development of this}} descriptor list. A draft version prepared in the internationally accepted Bioversity format for descriptor lists was subsequently sent to a number of international experts for their comments and amendments. A full list of the names and addresses of those involved is given in 'Contributors'. Bioversity encourages the collection of data for all five types of descriptors (see Definitions and Use of Descriptors), whereby data from the first four categories - Passport, Management, Environment and Site and Characterization - should be available for any accession. The number of descriptors selected in each of the categories will depend on the crop and the importance of the crop's description. Descriptors listed under Evaluation allow for a more extensive description of accession, but generally require replicated trials over a period of time. Although the suggested coding should not be regarded as the definitive scheme, this format represents an important tool for a standardized characterization system and it is promoted by Bioversity throughout the world. This descriptor list provides an international format and thereby produces a universally understood 'language' for plant genetic resources data. The adoption of this scheme for data encoding, or at least the production of a transformation method to convert other schemes to the Bioversity format, will produce a rapid, reliable and efficient means for information storage, retrieval and communication, and will assist with the utilization of germplasm. It is recommended, therefore, that information should be produced by closely following the descriptor list with regard to ordering and numbering descriptors, using the descriptors specified, and using the descriptor states recommended. This descriptor list is intended to be comprehensive for the descriptors that it contains. This approach assists with the standardization of descriptor definitions. Bioversity does not, however, assumes that each curator will characterize accessions of their collection utilizing all descriptors given. Descriptors should be used when they are useful to the curator for the management and maintenance of the collection and/or to the users of the plant genetic resources. However, highly <b>discriminating</b> <b>descriptors</b> are highlighted in the text to facilitate selection of descriptors. Multicrop passport descriptors {{were developed}} jointly by Bioversity (ex IPGRI) and FAO, to provide consistent coding schemes for common passport descriptors across crops. They are marked in the text as [MCPD]. Please note that owing to the generic nature of the multicrop passport descriptors, not all descriptor states for a particular descriptor will be relevant to a specific crop. In Annex I, the reader will find a collecting form for durian that will facilitate data collecting. Any suggestions for improvement on the Descriptors for Durian will be highly appreciated by Bioversity. Peer Revie...|$|R
40|$|International audiencePERSEUS project aims to {{identify}} the most relevant pressures exerted on the ecosystems of the Southern European Seas (SES), highlighting knowledge and data gaps that endanger the achievement of SES Good Environmental Status (GES) as mandated by the Marine Strategy Framework Directive (MSFD). A complementary approach has been adopted, by a meta-analysis of existing literature on pressure/impact/knowledge gaps summarized in tables related to the MSFD <b>descriptors,</b> <b>discriminating</b> open waters from coastal areas. A comparative assessment of the Initial Assessments (IAs) for five SES countries has been also independently performed. The comparison between meta-analysis results and IAs shows similarities for coastal areas only. Major knowledge gaps have been detected for the biodiversity, marine food web, marine litter and underwater noise descriptors. The meta-analysis also allowed the identification of additional research themes targeting research topics that are requested to the achievement of GES...|$|R
40|$|Phenolic Schiff bases {{are known}} as {{powerful}} antioxidants. To select the electronic, 2 D and 3 D descriptors responsible for the free radical scavenging ability {{of a series of}} 30 phenolic Schiff bases, a set of molecular descriptors were calculated by using B 3 P 86 (Becke’s three parameter hybrid functional with Perdew 86 correlation functional) combined with 6 - 31 + G(d,p) basis set (i. e., at the B 3 P 86 / 6 - 31 + G(d,p) level of theory). The chemometric methods, simple and multiple linear regressions (SLR and MLR), principal component analysis (PCA) and hierarchical cluster analysis (HCA) were employed to reduce the dimensionality and to investigate the relationship between the calculated descriptors and the antioxidant activity. The results showed that the antioxidant activity mainly depends on the first and second bond dissociation enthalpies of phenolic hydroxyl groups, the dipole moment and the hydrophobicity descriptors. The antioxidant activity is inversely proportional to the main descriptors. The selected <b>descriptors</b> <b>discriminate</b> the Schiff bases into active and inactive antioxidants...|$|R
40|$|Crise, A. [...] . et. al. [...] 12 pages, 1 figure, 5 tablesPERSEUS project aims to {{identify}} the most relevant pressures exerted on the ecosystems of the Southern European Seas (SES), highlighting knowledge and data gaps that endanger the achievement of SES Good Environmental Status (GES) as mandated by the Marine Strategy Framework Directive (MSFD). A complementary approach has been adopted, by a meta-analysis of existing literature on pressure/impact/knowledge gaps summarized in tables related to the MSFD <b>descriptors,</b> <b>discriminating</b> open waters from coastal areas. A comparative assessment of the Initial Assessments (IAs) for five SES countries has been also independently performed. The comparison between meta-analysis results and IAs shows similarities for coastal areas only. Major knowledge gaps have been detected for the biodiversity, marine food web, marine litter and underwater noise descriptors. The meta-analysis also allowed the identification of additional research themes targeting research topics that are requested to the achievement of GES. © 2015 The AuthorsThis work has been partially funded by the EC FP 7 PERSEUS Project (Grant. Agr. 287600) Peer Reviewe...|$|R
40|$|Statistical {{techniques}} for screening experimental or literature chemical databases for compounds exhibiting potential environmental activity {{are becoming increasingly}} utilized in environmental analysis as pragmatic and economical complementary tools to enhance or augment costly traditional analytical procedures. Utilizing the predictive modeling approach, it is often argued, implicitly permits an unlimited number of chemicals to be screened for specific behavioral or physicochemical characteristics {{in a variety of}} environmental and biological matrices, consequentially conserving the financial resources for exhaustive testing, yet providing a methodology that helps to insure that questionable compounds are more thoroughly tested. Moreover, such techniques provide a database of exhaustive test results from which investigators and regulators can extract relevant information for further research or decision-making. To assess the efficiency of statistical modeling methods for predicting chemical processes in the environment, a one-year exploratory study utilizing Quantitative Structure-Activity Relationship (QSAR) methodology to obtain linear model equations for estimating the rates of chemical hydrolysis of several organophosphorus (OP) pesticides in natural river waters has been conducted. This modeling effort specifically considers the effects of chemical structure on reactivity and utilizes connectivity parameters from graph theory as quantitative structural descriptors. Derived model equations were examined to establish whether quantitative correlations between fundamental molecular characteristics and observed hydrolytic properties were possible. Inconclusive results for a training set of six OP pesticides indicate that there are inherent weaknesses in molecular connectivity theory when applied to complex reaction parameters that require further exploration. The inherent complexity of most chemical reaction mechanisms and the indistinct influence of both adjoining and distant atoms in the molecular environment makes it difficult for a single descriptor, even one as widely successful as connectivity indices, to adequately account for definitive structural characteristics of molecules. It is apparent from results of this study that molecular connectivity indices alone are often not <b>discriminating</b> enough <b>descriptors</b> for procuring comprehensive structure-property relationships beyond a rather restricted range of structural variation, at least when characterizing chemical reaction parameters...|$|R
40|$|Durch die steigende Anzahl verfügbarer Daten in unterschiedlichsten Anwendungsgebieten nimmt der Aufwand vieler Data-Mining Applikationen signifikant zu. Speziell hochdimensionierte Daten (Daten die über viele verschiedene Attribute beschrieben werden) können ein großes Problem für viele Data-Mining Anwendungen darstellen. Neben höheren Laufzeiten können dadurch sowohl für überwachte (supervised), als auch nicht überwachte (unsupervised) Klassifikationsalgorithmen weitere Komplikationen entstehen (z. B. ungenaue Klassifikationsgenauigkeit, schlechte Clustering-Eigenschaften, …). Dies führt zu einem Bedarf an effektiven und effizienten Methoden zur Dimensionsreduzierung. Feature Selection (die Auswahl eines Subsets von Originalattributen) und Dimensionality Reduction (Transformation von Originalattribute in (Linear) -Kombinationen der Originalattribute) sind zwei wichtige Methoden um die Dimension von Daten zu reduzieren. Obwohl sich in den letzten Jahren vielen Studien mit diesen Methoden beschäftigt haben, gibt es immer noch viele offene Fragestellungen in diesem Forschungsgebiet. Darüber hinaus ergeben sich in vielen Anwendungsbereichen durch die immer weiter steigende Anzahl an verfügbaren und {{verwendet}}en Attributen und Features laufend neue Probleme. Das Ziel dieser Dissertation ist es, verschiedene Fragenstellungen in diesem Bereich genau zu analysieren und Verbesserungsmöglichkeiten zu entwickeln. Grundsätzlich, werden folgende Ansprüche an Methoden zur Feature Selection und Dimensionality Reduction gestellt: Die Methoden sollten effizient (bezüglich ihres Rechenaufwandes) sein und die resultierenden Feature-Sets sollten die Originaldaten möglichst kompakt repräsentieren können. Darüber hinaus ist es in vielen Anwendungsgebieten wichtig, die Interpretierbarkeit der Originaldaten beizubehalten. Letztendlich sollte der Prozess der Dimensionsreduzierung keinen negativen Effekt auf die Klassifikationsgenauigkeit haben - sondern idealerweise, diese noch verbessern. Offene Problemstellungen in diesem Bereich betreffen unter anderem den Zusammenhang zwischen Methoden zur Dimensionsreduzierung und der resultierenden Klassifikationsgenauigkeit, wobei sowohl eine möglichst kompakte Repräsentation der Daten, als auch eine hohe Klassifikationsgenauigkeit erzielt werden sollen. Wie bereits erwähnt, ergibt sich durch die große Anzahl an Daten auch ein erhöhter Rechenaufwand, weshalb schnelle und effektive Methoden zur Dimensionsreduzierung entwickelt werden müssen, bzw. existierende Methoden verbessert werden müssen. Darüber hinaus sollte natürlich auch der Rechenaufwand der verwendeten Klassifikationsmethoden möglichst gering sein. Des Weiteren ist die Interpretierbarkeit von Feature Sets zwar möglich, wenn Feature Selection Methoden für die Dimensionsreduzierung verwendet werden, im Fall von Dimensionality Reduction sind die resultierenden Feature Sets jedoch meist Linearkombinationen der Originalfeatures. Daher ist es schwierig zu überprüfen, wie viel Information einzelne Originalfeatures beitragen. Im Rahmen dieser Dissertation konnten wichtige Beiträge zu den oben genannten Problemstellungen präsentiert werden: Es wurden neue, effiziente Initialisierungsvarianten für die Dimensionality Reduction Methode Nonnegative Matrix Factorization (NMF) entwickelt, welche im Vergleich zu randomisierter Initialisierung und im Vergleich zu State-of-the-Art Initialisierungsmethoden zu einer schnelleren Reduktion des Approximationsfehlers führen. Diese Initialisierungsvarianten können darüber hinaus mit neu entwickelten und sehr effektiven Klassifikationsalgorithmen basierend auf NMF kombiniert werden. Um die Laufzeit von NMF weiter zu steigern wurden unterschiedliche Varianten von NMF Algorithmen auf Multi-Prozessor Systemen vorgestellt, welche sowohl Task- als auch Datenparallelismus unterstützen und zu einer erheblichen Reduktion der Laufzeit für NMF führen. Außerdem wurde eine effektive Verbesserung der Matlab Implementierung des ALS Algorithmus vorgestellt. Darüber hinaus wurde eine Technik aus dem Bereich des Information Retrieval [...] Latent Semantic Indexing [...] erfolgreich als Klassifikationsalgorithmus für Email Daten angewendet. Schließlich wurde eine ausführliche empirische Studie über den Zusammenhang verschiedener Feature Reduction Methoden (Feature Selection und Dimensionality Reduction) und der resultierenden Klassifikationsgenauigkeit unterschiedlicher Lernalgorithmen präsentiert. Der starke Einfluss unterschiedlicher Methoden zur Dimensionsreduzierung auf die resultierende Klassifikationsgenauigkeit unterstreicht dass noch weitere Untersuchungen notwendig sind um das komplexe Zusammenspiel von Dimensionsreduzierung und Klassifikation genau analysieren zu können. {{sheer volume}} of data today and its expected growth over the next years {{are some of the}} key challenges in data mining and knowledge discovery applications. Besides the huge number of data samples that are collected and processed, the high dimensional nature of data arising in many applications causes the need to develop effective and efficient techniques that are able to deal with this massive amount of data. In addition to the significant increase in the demand of computational resources, those large datasets might also influence the quality of several data mining applications (especially if the number of features is very high compared to the number of samples). As the dimensionality of data increases, many types of data analysis and classification problems become significantly harder. This can lead to problems for both supervised and unsupervised learning. Dimensionality reduction and feature (subset) selection methods are two types of techniques for reducing the attribute space. While in feature selection a subset of the original attributes is extracted, dimensionality reduction in general produces linear combinations of the original attribute set. In both approaches, the goal is to select a low dimensional subset of the attribute space that covers most of the information of the original data. During the last years, feature selection and dimensionality reduction techniques have become a real prerequisite for data mining applications. There are several open questions in this research field, and due to the often increasing number of candidate features for various application areas (e. g., email filtering or drug classification/molecular modeling) new questions arise. In this thesis, we focus on some open research questions in this context, such as the relationship between feature reduction techniques and the resulting classification accuracy and the relationship between the variability captured in the linear combinations of dimensionality reduction techniques (e. g., PCA, SVD) and the accuracy of machine learning algorithms operating on them. Another important goal is to better understand new techniques for dimensionality reduction, such as nonnegative matrix factorization (NMF), which can be applied for finding parts-based, linear representations of nonnegative data. This "sum-of-parts" representation is especially useful if the interpretability of the original data should be retained. Moreover, performance aspects of feature reduction algorithms are investigated. As data grow, implementations of feature selection and dimensionality reduction techniques for high-performance parallel and distributed computing environments become more and more important. In this thesis, we focus on two types of open research questions: methodological advances without any specific application context, and application-driven advances for a specific application context. Summarizing, new methodological contributions are the following: The utilization of nonnegative matrix factorization in the context of classification methods is investigated. In particular, it is of interest how the improved interpretability of NMF factors due to the non-negativity constraints (which is of central importance in various problem settings) can be exploited. Motivated by this problem context two new fast initialization techniques for NMF based on feature selection are introduced. It is shown how approximation accuracy can be increased and/or how computational effort can be reduced compared to standard randomized seeding of the NMF and to state-of-the-art initialization strategies suggested earlier. For example, for a given number of iterations and a required approximation error a speedup of 3. 6 compared to standard initialization, and a speedup of 3. 4 compared to state-of-the-art initialization strategies could be achieved. Beyond that, novel classification methods based on the NMF are proposed and investigated. We can show that they are not only competitive in terms of classification accuracy with state-of-the-art classifiers, but also provide important advantages in terms of computational effort (especially for low-rank approximations). Moreover, parallelization and distributed execution of NMF is investigated. Several algorithmic variants for efficiently computing NMF on multi-core systems are studied and compared to each other. In particular, several approaches for exploiting task and/or data-parallelism in NMF are studied. We show that for some scenarios new algorithmic variants clearly outperform existing implementations. Last, but not least, a computationally very efficient adaptation of the implementation of the ALS algorithm in Matlab 2009 a is investigated. This variant reduces the runtime significantly (in some settings by a factor of 8) and also provides several possibilities to be executed concurrently. In addition to purely methodological questions, we also address questions arising in the adaptation of feature selection and classification methods to two specific application problems: email classification and in silico screening for drug discovery. Different research challenges arise in the contexts of these different application areas, such as the dynamic nature of data for email classification problems, or the imbalance in the number of available samples of different classes for drug discovery problems. Application-driven advances of this thesis comprise the adaptation and application of latent semantic indexing (LSI) to the task of email filtering. Experimental results show that LSI achieves significantly better classification results than the widespread de-facto standard method for this special application context. In the context of drug discovery problems, several groups of well <b>discriminating</b> <b>descriptors</b> could be identified by utilizing the "sum-of-parts" representation of NMF. The number of important descriptors could be further increased when applying sparseness constraints on the NMF factors...|$|R

