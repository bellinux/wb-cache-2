10000|939|Public
25|$|Classification {{refinement}} {{for increased}} data <b>granularity.</b>|$|E
25|$|A {{deep level}} of <b>granularity</b> is {{expected}} in the plan.|$|E
25|$|Architectures {{that can}} only support these with region <b>granularity</b> are: i386 (without PAE), other powerpc (such as macppc).|$|E
40|$|Temporal {{constraints}} {{are part}} of the specification of many complex application frameworks including planning, scheduling, real-time systems, workflow and cooperative systems. This paper investigates the problem of converting among quantitative temporal constraints expressed in terms of different time <b>granularities.</b> An expressive formal model for time <b>granularities</b> is assumed including common <b>granularities</b> like hours and days as well as user-defined <b>granularities</b> like business-days and academic semesters...|$|R
40|$|This paper reports recent {{results on}} {{deriving}} mathematical (periodical) representations of time <b>granularities</b> from more user friendly algebraic expressions. The practical {{application of these}} results {{can be found in}} using systems for solving multi-granularity temporal constraint satisfaction problems. Indeed, while these systems in principle allow users to specify distance constraints in terms of arbitrary <b>granularities,</b> they require <b>granularities</b> to be expressed as sets of sets of periodic integers. Our goal is to allow users of these systems to specify the <b>granularities</b> used in their constraints with symbolic algebraic expressions. ...|$|R
30|$|Group {{these basic}} <b>granularities</b> into a cluster if necessary. Based {{on the nature}} of these <b>granularities,</b> some spatial-clustering algorithms, such as DBSCAN (Density-Based Spatial Clustering of Application with Noise) [[28]], can be used.|$|R
25|$|Architectures {{that have}} per-page <b>granularity</b> consist of: alpha, amd64, hppa, i386 (with PAE), powerpc (ibm4xx), sh5, sparc (sun4m, sun4d), sparc64.|$|E
25|$|Timestamp: (32 bits) Used {{to enable}} the {{receiver}} to play back the received samples at appropriate intervals. When several media streams are present, the timestamps are independent in each stream, {{and may not be}} relied upon for media synchronization. The <b>granularity</b> of the timing is application specific. For example, an audio application that samples data once every 125µs (8kHz, a common sample rate in digital telephony) would use that value as its clock resolution. The clock <b>granularity</b> is one of the details that is specified in the RTP profile for an application.|$|E
25|$|Multi-piece {{rectangular}} sand cloth, bonding {{around the}} metal handle. <b>Granularity</b> is generally in the 60 # -320 #, for {{the diameter of}} the inner wall of the polishing.|$|E
40|$|Time can be {{expressed}} and aggregated into concepts called <b>granularities.</b> <b>Granularities</b> are defined in a structure with their rules of conversion that may {{take the form of}} trees or graphs, thus it’s possible to design tools that dynamically explore different <b>granularities</b> that might reveal patterns hidden in other levels. We described an intial investigation of the use of interactive visualization techniques for that purpose and define future work to be done...|$|R
40|$|Introduction. Determining the {{sufficient}} number of frequencies for biological object impedance measuring is being researched. The presence {{of one or two}} object <b>granularities</b> is considered. Formulation of the problem. Often impedance measuring is conducted in a real time conditions. The number of frequencies directly influences measuring time. Existing studies of frequencies quantity were based on a coarse Krike and Morse impedance model. Research methods and the results analysis. This work offers method for calculating the {{sufficient number}} of impedance measuring freqencies for biological object, which contains one or two <b>granularities.</b> Conclusions. Sufficient number of frequencies for the object containing one or two <b>granularities</b> was evaluated. Also path for discovering the case three and more <b>granularities</b> was prompted. </p...|$|R
40|$|String-based metrics of {{automatic}} machine translation (MT) evaluation are widely applied in MT research. Meanwhile, some linguistic motivated metrics {{have been suggested}} to improve the string-based metrics in sentencelevel evaluation. In this work, we attempt to change their original calculation units (<b>granularities)</b> of string-based metrics to generate new features. We then propose a powerful string-based automatic MT evaluation metric, combining all the features with various <b>granularities</b> based on SVM rank and regression models. The experimental results show that i) the new features with various <b>granularities</b> {{can contribute to the}} automatic evaluation of translation quality; ii) our proposed string-based metrics with multiple <b>granularities</b> based on SVM regression model can achieve higher correlations with human assessments than the stateof-art automatic metrics. ...|$|R
25|$|Changes {{that can}} be seen in chronic {{ulcerative}} colitis include <b>granularity,</b> loss of the vascular pattern of the mucosa, loss of haustra, effacement of the ileocecal valve, mucosal bridging, strictures and pseudopolyps.|$|E
25|$|An ASIC based IPS may {{detect and}} block denial-of-service attacks {{because they have}} the {{processing}} power and the <b>granularity</b> to analyze the attacks and act like a circuit breaker in an automated way.|$|E
25|$|The {{results are}} limited to whole numbers for a {{specific}} driving interval, but with very low blow counts, the <b>granularity</b> of the results, {{and the possibility of}} a zero result, makes handling the data cumbersome.|$|E
40|$|AbstractTo {{study the}} impact of {{different}} <b>granularities</b> on the gas adsorption of coal, the experimental system {{has been designed to}} apply dynamic constant pressure and the coal sample which is made from the same quality coal. The experimental data of the gas adsorption and desorption capacity with four different <b>granularities</b> coal sample under different initial pressure are obtained. Relative analysis to the different data shows the mathematical equation relationship among the capacity, rate and time of gas adsorption. The fitted curves of gas adsorption capacity with time in different <b>granularities</b> coal indicated how the size of <b>granularities</b> influences the time to reach the equilibrium of adsorption and desorption, the rate of gas adsorption. And the fitted curve showed the initial pressure had no influence on the rate of gas adsorption too. The smaller of the <b>granularities,</b> the faster of the adsorption rate, the shorter the time spent to adsorption equilibrium; the bigger of the <b>granularities,</b> the slower of the adsorption rate, the longer the time spent to adsorption equilibrium. It can be concluded that the rate of gas adsorption and desorption has scale effect...|$|R
40|$|An {{important}} presupposition for HW/SW partitioning are sophisticated estimation algorithms at a {{high level}} of abstraction that obtain high quality results. Therefore the <b>granularities</b> of estimation and partitioning have to be adapted adequately. In this paper we discuss the effects that arise when the <b>granularities</b> of partitioning and estimation are not adapted in a necessary way. Furthermore we present our solution that allows to choose different levels of <b>granularities</b> adapted to the estimation and partitioning phase. The experiments show that this refinement in estimation {{at a high}} level of abstraction leads to an inprovement (in terms of run-time and chip area) of the whole mixed HW/SW system...|$|R
40|$|Recently, {{association}} {{rules have}} been used to generate pro les of " behavior for anomaly detection. However, the time factor (especially in terms of multiple time <b>granularities)</b> has not been studied extensively in generation of these pro les. In reality, user behavior during di erent time periods (in terms of time <b>granularities)</b> may bevery di erent. For example, the " number and duration of FTP connections may vary from working hour to midnight, from business day toweekend or holiday. Furthermore, these variations may depend {{on the day of the}} month or the week. This paper proposes to build pro les using temporal association rules in terms of multiple time <b>granularities,</b> and describes algorithms to discover these pro les. Because multiple time <b>granularities</b> are used for the pro le generation, the proposed method is more exible and precise than previous methods that use xed division of time periods. Finally, the paper describes an experiment and its analysis on real TCP-dump data. ...|$|R
25|$|Another popular {{theory is}} Loop quantum gravity (LQG), a theory first {{proposed}} by Carlo Rovelli {{that describes the}} quantum properties of gravity. It is also a theory of quantum space and quantum time, because in general relativity the geometry of spacetime is a manifestation of gravity. LQG {{is an attempt to}} merge and adapt standard quantum mechanics and standard general relativity. The main output of the theory is a physical picture of space where space is granular. The <b>granularity</b> is a direct consequence of the quantization. It has the same nature of the <b>granularity</b> of the photons in the quantum theory of electromagnetism or the discrete levels of the energy of the atoms. But here it is space itself which is discrete.|$|E
25|$|The <b>granularity</b> of {{pools of}} securitized assets can {{mitigate}} the credit risk of individual borrowers. Unlike general corporate debt, the credit quality of securitized debt is non-stationary due {{to changes in}} volatility that are time- and structure-dependent. If the transaction is properly structured and the pool performs as expected, the credit risk of all tranches of structured debt improves; if improperly structured, the affected tranches may experience dramatic credit deterioration and loss.|$|E
25|$|Digital {{watermarking}} for relational databases {{has emerged}} as a candidate solution to provide copyright protection, tamper detection, traitor tracing, and maintaining integrity of relational data. Many watermarking techniques have been proposed in the literature to address these purposes. A survey of the current state-of-the-art and a classification of the different techniques according to their intent, the way they express the watermark, the cover type, <b>granularity</b> level, and verifiability was published in 2010 by Halder et al. in the Journal of Universal Computer Science.|$|E
40|$|Modelling, {{reasoning}} {{about and}} integrating knowledge based on multiple time <b>granularities</b> in knowledge-based systems is important, especially {{when talking about}} events {{that take place in}} the real world. Formal approaches based on temporal logics have been successfully applied in many application domains of knowledge-based systems where the notion of dynamic change (that is, evolution of a system through time) is central. This paper presents a methodology based on temporal logic to deal with knowledge based on multiple time <b>granularities</b> in knowledge-based systems. The methodology includes an approach to the representation of timing systems, a method used for representing facts and rules in a knowledge-based system that involve multiple time <b>granularities,</b> and several deductive reasoning techniques. 6 page(s...|$|R
40|$|In this paper, an {{experimental}} {{analysis of the}} gating characteristics of the TOAD for different <b>granularities</b> (tributary bitrates) of an OTDM stream is presented. This study {{is based on the}} evaluation of the time-domain response (i. e. the switching window) and Contrast Ratio (CR) measurements of the dropped tributary and the residual (through) signal. The minimum obtainable switch window is approximately 6 ps for the TOAD under investigation and allows deployment in a 160 Gbit/s environment. Applying a TOAD in an OTDM add/drop node is possible with optical <b>granularities</b> up to 2. 5 Gbit/s. Application as an OTDM demultiplexer is possible at higher <b>granularities</b> (10 Gbit/s) at the expense of reduced CR of the dropped tributary...|$|R
40|$|Most work on {{temporal}} constraints {{has ignored}} the subtleties involved {{in dealing with}} multiple time <b>granularities.</b> This paper considers a constraint satisfaction problem (CSP) where binary quantitative constraints in terms of different time <b>granularities</b> can be specified {{on a set of}} variables, and unary constraints are allowed to limit the domain of variables. Such a CSP cannot be trivially reduced to one of the known CSP problems. The main result of the paper is a complete algorithm for checking consistency and finding a solution. The complexity of the algorithm is studied in the paper under di#erent assumptions about the <b>granularities</b> involved in the CSP, and a second algorithm is proposed to improve the efficiency of the backtracking process needed to obtain all the solutions of the CSP...|$|R
25|$|For {{simulating}} {{molecules in}} a solvent, a choice {{should be made}} between explicit and implicit solvent. Explicit solvent particles (such as the TIP3P, SPC/E and SPC-f water models) must be calculated expensively by the force field, while implicit solvents use a mean-field approach. Using an explicit solvent is computationally expensive, requiring inclusion of roughly ten times more particles in the simulation. But the <b>granularity</b> and viscosity of explicit solvent is essential to reproduce certain properties of the solute molecules. This is especially important to reproduce chemical kinetics.|$|E
25|$|Constant {{false alarm}} rate, {{a form of}} {{automatic}} gain control (AGC), is a method that relies on clutter returns far outnumbering echoes from targets of interest. The receiver's gain is automatically adjusted to maintain a constant level of overall visible clutter. While this does not help detect targets masked by stronger surrounding clutter, it does help to distinguish strong target sources. In the past, radar AGC was electronically controlled and affected the gain of the entire radar receiver. As radars evolved, AGC became computer-software controlled and affected the gain with greater <b>granularity</b> in specific detection cells.|$|E
25|$|Locks can {{be applied}} on {{different}} levels of granularity—on entire tables, pages, or even on a per-row basis on tables. For indexes, it can either be on the entire index or on index leaves. The level of <b>granularity</b> to be used is defined on a per-database basis by the database administrator. While a fine-grained locking system allows more users to use the table or index simultaneously, it requires more resources, so it does not automatically yield higher performance. SQL Server also includes two more lightweight mutual exclusion solutions—latches and spinlocks—which are less robust than locks but are less resource intensive. SQL Server uses them for DMVs and other resources that are usually not busy. SQL Server also monitors all worker threads that acquire locks {{to ensure that they}} do not end up in deadlocks—in case they do, SQL Server takes remedial measures, which in many cases are to kill one of the threads entangled in a deadlock and roll back the transaction it started. To implement locking, SQL Server contains the Lock Manager. The Lock Manager maintains an in-memory table that manages the database objects and locks, if any, on them along with other metadata about the lock. Access to any shared object is mediated by the lock manager, which either grants access to the resource or blocks it.|$|E
40|$|Representation, {{reasoning}} {{about and}} integrating knowledge based on multiple time <b>granularities</b> in knowledge-based systems is important, especially {{when talking about}} events {{that take place in}} the real world. Formal approaches based on temporal logics have been successfully applied in many application domains of knowledge-based systems where the evolution of a system and its environment through time is central. This paper presents a methodology based on temporal logic to deal with knowledge based on multiple time <b>granularities</b> in knowledge-based systems. The temporal logic we consider is especially suitable for modelling events with different rates and/or scales of progress. The methodology includes an approach to the representation of timing systems, a method used for representing facts and rules in a knowledge-based system that involve multiple time <b>granularities</b> using temporal logic, and several deductive reasoning techniques. 21 page(s...|$|R
40|$|Multiple <b>granularities</b> are {{essential}} to extract significant knowledge from spatiotemporal datasets {{at different levels of}} detail. They enable to zoom-in and zoom-out spatio-temporal datasets, thus enhancing the data modelling flexibility and improving the analysis of information. In this paper we discuss effective solutions to implementation issues arising when a data model and a query language are enriched with spatio-temporal multigranularity. We propose appropriate representations for space and time dimensions, <b>granularities,</b> granules, and multi-granular values. In particular the design of <b>granularities</b> and their relationships is illustrated with respect to the application of multigranular conversions for data access. Finally, we describe how multigranular spatio-temporal conversions affect data usability and how such important property may be guaranteed. In our discussion, we refer to an existing multigranular spatio-temporal model, whose design was previously proposed as extension of the ODMG data model...|$|R
30|$|To {{enhance the}} {{efficiency}} while analyzing a large multidimensional dataset, we adopt the OLAP (online analytical processing) [21] approach to execute analytical queries. OLAP’s slicing operation enables {{the user to}} take out one specific part of data. SemanticPrism [23] pre-computed the aggregation values along necessary dimensions and storing them into several database tables. The dimension hierarchy is essential for these computations. Pre-computing all possible aggregations on all different <b>granularities,</b> however, will use too many resources. We selected several dimensions to compute in certain <b>granularities.</b>|$|R
500|$|Because {{flash memory}} must be erased {{before it can}} be rewritten, with much coarser <b>granularity</b> of the erase {{operation}} when compared to the write operation, the process to perform these operations results in moving (or rewriting) user data and metadata more than once. [...] Thus, rewriting some data requires an already used portion of flash to be read, updated and written to a new location, together with initially erasing the new location if it was previously used at some point in time; due to the way flash works, much larger portions of flash must be erased and rewritten than actually required by the amount of new data. [...] This multiplying effect increases the number of writes required {{over the life of the}} SSD which shortens the time it can reliably operate. The increased writes also consume bandwidth to the flash memory which mainly reduces random write performance to the SSD. Many factors will affect the write amplification of an SSD; some can be controlled by the user and some are a direct result of the data written to and usage of the SSD.|$|E
2500|$|In {{order to}} do this, in LQG theory space and time are quantized, analogously to the way {{quantities}} like energy and momentum are quantized in quantum mechanics. [...] The theory gives a physical picture of spacetime where space and time are [...] "granular". The <b>granularity</b> is {{a direct consequence of}} the quantization. It has the same nature as the <b>granularity</b> of the photons in the quantum theory of electromagnetism and the discrete energy levels of atoms. Here, it is space itself that is discrete. In other words, there is a minimum distance possible to travel through it.|$|E
2500|$|Sherbet {{can be sold}} {{by itself}} or used as a {{decorative}} agent on other sweets. The measured qualities of sherbet include <b>granularity,</b> colour, [...] "zing" [...] (acidity) and flavouring (normally a citrus fruit).|$|E
40|$|Abstract. Multiple {{spatial and}} {{temporal}} <b>granularities</b> are essential to extract significant knowledge from datasets {{at different levels of}} detail: they enable to zoom-in and zoom-out a dataset, enhancing the data modelling flexibility and being instrumental to boost the analysis of information. Implementing <b>granularities</b> poses several interesting problems. Specifically, in this paper we analyse the issues involved by enhancing a data model and a query language with spatio-temporal multi-granularity, and we figure out efficacious solutions to address all of them. In our exposition, we investigate proper representa-tions for the spatial and the temporal domains; then we conceive an appropriate design for granules and <b>granularities,</b> and for multi-granular values. In particular, mutual relationships among granular-ities and how they affect <b>granularities</b> design is discussed according to their influence on data access and considering the application of multi-granular conversions. Afterward, we dedicated to the design of multi-granular spatio-temporal conversions, discussing the multiple ways in which they affect data usability and envisaging how the design of a multi-granular model and query language may guarantee such an fundamental property, reducing uncertainty on the represented values, combining concepts like topologically consistent transformation, probability distributions, invertibility and quasi-invertibility properties. In our discussion, we are influenced on our previous work on multi-granularity. Especially...|$|R
40|$|In {{this paper}} we {{investigate}} some issues {{arising from the}} introduction of multiple temporal <b>granularities</b> in an objectoriented data model. Although issues concerning temporal <b>granularities</b> have been investigated {{in the context of}} temporal relational database systems, no comparable amount of work has been done in the context of object-oriented models. Moreover, the main drawback of the existing proposals is the lack of a formal basis [...] which we believe is essential to manage the inherent complexity of the object-oriented data model. In this paper, we provide a complete temporal object-oriented type system supporting multiple temporal <b>granularities</b> and we formally define the set of legal values for our type system. We then address issues related to inheritance, type refinement and substitutability. 1. Introduction Conventional database systems do not offer the possibility of dealing with time-varying data. The content of a database represents a snapshot of the reality in that only the [...] ...|$|R
40|$|In {{this work}} {{we present a}} uniform {{behavioral}} temporal object model which includes a rich and extensible set of types and behaviors to support various notions of time. Our temporal model supports the continuous and discrete domains of time. It also supports various specifications of time namely, time instants, time intervals, and time spans. Two issues which deal with temporal information that frequently arise in real-world applications are the need to consistently store and operate on temporal information that is comprised of different <b>granularities,</b> {{and the ability to}} represent indeterminate temporal information. Temporal indeterminacy arises when we know for certain that an event did occur, but exactly when it occured is unknown. Our model provides a uniform framework that supports different <b>granularities</b> of time and temporal indeterminacy. We show how different <b>granularities</b> can be converted to each other, and how this leads to temporal indeterminacy. We further show how continuous [...] ...|$|R
