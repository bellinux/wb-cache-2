2|140|Public
40|$|Abstract. In this paper, a {{prototype}} of an Online Public Access Catalog (OPAC) is presented. This new OPAC features new functionalities and utilizes web 2. 0 technologies in order to deliver improved search and retrieval services. Some of these new services include social tag annotations, user opinions and ranks and tag-based similarity searches. The prototype is evaluated by a user group through questionnaires, interviews and with the system's <b>integrated</b> <b>logging</b> mechanism. The results are encouraging enough and show that Library 2. 0 technologies seem to be acceptable {{by the majority of}} the users. Key-words: Web 2. 0, social tagging, subject representation, OPAC, evaluation...|$|E
40|$|<b>Integrated</b> <b>logging</b> {{immediately}} before a large storm in February 1992 caused extensive erosion of a feeder road in compartment 588 / 2 of Yambulla State Forest that allegedly supplied {{large amounts of}} sand and fine gravel to the downstream river channel where pools were supposedly infilled. However, most sediment eroded on the feeder road was actually stored on slopes and in filter strips before reaching channels. Subsequent soil conservation works rehabilitated the worst-eroded areas {{and they are still}} functioning effectively today. There is no direct connection of sand and fine gravel between the general harvest area and downstream channels because of many intervening sediment discontinuities, such as ponds, drainage lines, filter strips and floodouts. The catastrophic flood of February 1971 was the largest for at least the last 50 y in the Towamba catchment and caused substantial widening of lower Letts Creek and Wog Wog River. It also reorganised channel-spanning boulder steps on upper Letts Creek and a tributary in and immediately downstream of compartment 588 / 2, and may have caused gully erosion on the tributary of Letts Creek. Bank erosion supplied the sand and fine gravel in the river bed of these headwater channels. A cluster of large floods between 1988 and 1992 exacerbated bank erosion in the two channels draining the logged compartment and infilled pools...|$|E
30|$|We {{propose a}} novel anti-malware {{system based on}} {{behavior}} profiling called Andro-profiler. We classify malware by exploiting the behavior profiling extracted from <b>integrated</b> system <b>logs.</b> Our method captures the behavior profiling by converting <b>integrated</b> system <b>logs</b> into human-readable contexts, which helps analysts analyze malware intuitively.|$|R
5000|$|TGT Oil and Gas Services specialises in <b>integrated</b> well <b>logging</b> and {{provides}} the following solutions: ...|$|R
5000|$|... {{organizations}} <b>integrate</b> the <b>logs</b> {{of various}} business-applications into an enterprise log manager for better value proposition.|$|R
50|$|OP5 Monitor is a {{software}} product for server, Network {{monitoring and management}} based on the Open Source project Nagios, is further developed and supported by OP5 AB. OP5 Monitor displays the status, health and performance of the IT network being monitored and has an <b>integrated</b> <b>log</b> server, OP5 Logger. The company sells downloadable software that monitor, visualize and troubleshoot IT environments and collect information both from hardware, software, virtual and/or cloud based services.|$|R
5000|$|JSNLog - A {{port for}} JavaScript. Automatically places {{messages}} from JavaScript loggers in server side logs using a [...]NET server side component that interfaces with Log4Net, NLog, Elmah or Common.Logging. This {{to provide an}} <b>integrated</b> <b>log</b> for client and server side events. Request ids correlate events related to a specific user. Configuration is via a server side web.config file. Supports exception logging including stack traces. In July 2014 the latest version was 2.7.1 and updates were made regularly.|$|R
40|$|Mass-market mobile {{security}} threats have increased recently {{due to the}} growth of mobile technologies and the popularity of mobile devices. Accordingly, techniques have been introduced for identifying, classifying, and defending against mobile threats utilizing static, dynamic, on-device, off-device, and hybrid approaches. In this paper, we contribute to the {{mobile security}} defense posture by introducing Andro-profiler, a hybrid behavior based analysis and classification system for mobile malware. Andro-profiler classifies malware by exploiting the behavior profiling extracted from the <b>integrated</b> system <b>logs</b> including system calls, which are implicitly equivalent to distinct behavior characteristics. Andro-profiler executes a malicious application on an emulator in order to generate the <b>integrated</b> system <b>logs,</b> and creates human-readable behavior profiles by analyzing the <b>integrated</b> system <b>logs.</b> By comparing the behavior profile of malicious application with representative behavior profile for each malware family, Andro-profiler detects and classifies it into malware families. The experiment results demonstrate that Andro-profiler is scalable, performs well in detecting and classifying malware with accuracy greater than 98 %, outperforms the existing state-of-the-art work, and is capable of identifying zero-day mobile malware samples. Comment: 13 page...|$|R
3000|$|... {{recently}} due to {{the growth}} of mobile technologies and the popularity of mobile devices. Accordingly, techniques have been introduced for identifying, classifying, and defending against mobile threats utilizing static, dynamic, on-device, and off-device techniques. Static techniques are easy to evade, while dynamic techniques are expensive. On-device techniques are evasion, while off-device techniques need being always online. To address some of those shortcomings, we introduce Andro-profiler, a hybrid behavior based analysis and classification system for mobile malware. Andro-profiler main goals are efficiency, scalability, and accuracy. For that, Andro-profiler classifies malware by exploiting the behavior profiling extracted from the <b>integrated</b> system <b>logs</b> including system calls. Andro-profiler executes a malicious application on an emulator in order to generate the <b>integrated</b> system <b>logs,</b> and creates human-readable behavior profiles by analyzing the <b>integrated</b> system <b>logs.</b> By comparing the behavior profile of malicious application with representative behavior profile for each malware family using a weighted similarity matching technique, Andro-profiler detects and classifies it into malware families. The experiment results demonstrate that Andro-profiler is scalable, performs well in detecting and classifying malware with accuracy greater than 98  %, outperforms the existing state-of-the-art work, and is capable of identifying 0 -day mobile malware samples.|$|R
40|$|In {{this paper}} it is shown how a {{real-world}} electronic dictionary can be simultaneously compiled {{and its use}} studied. While {{the results of the}} dictionary use study may be successfully fed back into the compilation, the semi-automatic analysis of the use itself for the first time reveals how electronic dictionaries are really used. In order to achieve this, an intricate and multifaceted <b>integrated</b> <b>log</b> file tracks every single action of every single user – date and time stamping each lookup, ordering founds and not-founds, monitoring long-term vocabulary retention, etc. – with a multitude of summaries being presented to the lexicographers. The ultimate goal is that with such data the parameters of various user profiles could be pinpointed, with which self-tailoring electronic dictionaries could be built...|$|R
30|$|To {{overcome}} the drawbacks in previous methods, we propose a feature-rich anti-malware {{system based on}} behavior profiling called Andro-profiler. Our proposed behavior profiling system comprises mobile devices and a remote server to facilitate profiling, and adopts profiling method in the malware analysis domain. We exploit system calls, including their arguments provided by Loadable Kernel Module (LKM) and system logs (e.g., SMS, call, and network I/O) provided by Droidbox (2011) as feature vectors for malware characterization. We define system calls and system <b>logs</b> as <b>integrated</b> system <b>logs</b> from which we directly infer behavior patterns representation using the concept of behavior profiling of Bayer et al. (2009). We assume that: (a) malware samples have unique malicious behavior patterns, (b) malicious behavior is determined by system calls, and (c) such system call set has influence {{on the behavior of}} the program (malware). We prepare representative behavior profile for each malware family represented by <b>integrated</b> system <b>logs</b> including system calls, their arguments, and system logs of Droidbox—an analysis system we utilize in this work. We construct the behavior profile of each malware sample through its <b>integrated</b> system <b>logs</b> by executing it on an emulator. Then, by comparing the behavior profiles across samples, we can detect and classify malware samples into related families.|$|R
40|$|This paper reports an {{approach}} to linking data on European emitters to data on their innovation practices. We illustrate a straightforward approach to record linkage between the European Union Community <b>Integrated</b> Transaction <b>Log</b> (CITL) and the PATSTAT international patent database. We show how that record linkage can be maintained with relatively minimal human input...|$|R
40|$|Graduation date: 1997 The timber {{shortage}} in the Pacific Northwest {{is forcing}} sawmill owners {{to improve the}} competitiveness of their harvesting and processing operations. A computer simulation and financial statement analysis were {{used to compare the}} processing efficiency and profitability of three bucking strategies: log cost minimization (traditional 40 -foot preferred-length logs); hauling length maximization (55 -foot preferred-length logs); and the <b>Integrated</b> <b>Log</b> Manufacturing system (ILM), a proposed computer-based strategy that acts as a harvest-site merchandiser and integrates harvest-site tree bucking and lumber manufacturing. Five days of sawmill operations were simulated for each strategy; the same second-growth Douglas-fir trees were processed each day to fill identical lumber orders. The sawmill produced 0. 4 percent and 1. 9 percent more cubic feet of targeted lumber with the 55 -foot preferred-length strategy and ILM respectively, than with the 40 -foot preferred-length strategy. Compared with the 40 -foot preferred-length strategy, sawmill profits rose 2, 262 (23...|$|R
30|$|This {{research}} work, <b>integrate</b> wireline <b>logs,</b> 3 D seismic data volumes, and seismic attributes volumes {{to characterize}} the reservoir {{in the field of}} study (Fig.  1). Several different techniques, namely, multilayer perceptron neural networks, and technique which incorporates seismic inversion and multiattribute transforms together were used towards the achievement of the aim of the work in the field of study, Pennay field, offshore Niger Delta.|$|R
30|$|The BP module parsed <b>integrated</b> system <b>logs</b> to {{make the}} {{behavior}} profile of each malware, and stored the behavior profile as a dictionary structure of the Python language for efficient membership test. The parsing rule listed in Table  4 consists of system call and its arguments—only arguments provided by LKM, and information provided by Droidbox. The parsed behavior profile is encoded in a base- 64 format and stored in database.|$|R
40|$|A new semiparametric {{proportional}} {{hazard rate}} model is proposed which extends standard models {{to include a}} dynamic specication. Two main prob-lems are resolved {{in the course of}} this paper. First, the partial likelihood ap-proach to estimate the components of a standard proportional hazard model is not available in a dynamic model involving lags of the <b>log</b> <b>integrated</b> baseline hazard. We use a discretisation approach to obtain a semiparametric estimate of the baseline hazard. Second, the <b>log</b> <b>integrated</b> baseline hazard is not ob-served directly, but only through a threshold function. We employ a special type of observation driven dynamic which allows for a computationally simple maximum likelihood estimation. This specications approximates a standard ARMA model in the <b>log</b> <b>integrated</b> baseline hazard and is identical if the baseline hazard is known. It is shown that this estimator is quite exible and easily extended to in-clude unobserved heterogeneity, censoring and state dependent hazard rates. A Monte Carlo study on the approximation quality of the model and an em-pirical study on BUND future trading at the former DTB complement the paper...|$|R
40|$|This report {{contains}} {{results from}} {{the third year of}} the Full Waveform Acoustic Logging Consortium and rock physics studies at M. J. T. This year marks the completion of {{the first phase of the}} project which has been directed primarily to the understanding of the basic theoretical aspects of acoustic waves in a borehole. With such a background we are ready to emphasize applications as well as to undertake special problems which require new and different theoretical approaches. As examples of the latter, we can mention uncentered tools, vertical fractures around boreholes, thinly bedded formations and anisotropy. The third year studies fall into four general areas: theoretical aspects of wave propagation in the borehole, applications to the characterization of formations, <b>integrated</b> <b>log</b> analysis and physical properties of sedimentary rocks relevant to logging. There are fifteen papers in this report which discuss individual topics in detail. In this introduction we summarize the major points and also list the potential applications of full waveform acoustic logs and future directions of our research...|$|R
30|$|The BI module is {{implemented}} as python script coupled with Droidbox. The emulator is {{run on the}} Android 2.3. 4 (level 10). In order to capture the malicious behavior, the BI module executed each application for 60  s after the installation process is completed. After capturing <b>integrated</b> system <b>logs</b> of malicious application, the BI module passed those logs to the BP module and restored the emulator to the initial state only for capturing malicious behavior.|$|R
30|$|In this paper, we have {{presented}} Andro-profiler, an anti-malware {{system based on}} behavior profiling. Using Andro-profiler, we classified malware by exploiting the behavior profiling extracted from <b>integrated</b> system <b>logs,</b> which are implicitly equivalent to distinct behavior characteristics. Our behavior profiling is simple and relatively easy to understand, whereas Andro-profiler is capable of distinguishing benign and malicious applications, and malicious applications into families. Furthermore, Andro-profiler is capable of detecting 0 -day threats, which are missed by antivirus scanners.|$|R
3000|$|... ({{behavior}} profiling) A behavior profiling P {{is defined}} by four tuples as P = (O, OP, Γ, Δ [...]), where O is the set of all objects and OP is the set of all operations, which is represented in nested dictionary form as name : target : attribute. Γ⊆ (O × OP) is a relation assigning more than one operation to each other, and Δ⊆ ((O × OP), (O × OP)) represents the sequence-unrelated set, which is equivalent to <b>integrated</b> system <b>logs.</b>|$|R
40|$|Low-porosity highly {{fractured}} carbonate {{rocks in}} the deep Ordovician Formation in the Langgu depression of China remain active exploration targets. However, the seismic characterization of fractured reservoirs has been a challenging problem for decades. By <b>integrating</b> <b>logs</b> with seismic data acquired from the Huabei Oilfield in the Langgu depression, we improved a rock-physics-based method of estimating fractured zones using post-stack seismic data combined with stress field analysis. Using an FMI image log, porosity, density as well as sonic logs, fractured zones and heterogeneous rock types are classified. Two reservoir types are identified as having different elastic properties: the high-porosity zone (?> 6. 5 %) and the fractured zone (?< 6. 5 %). Further, by using a pore structure parameter ? from a rock physics model, {{it has been found}} that acoustic impedance correlates well with both porosity and this pore structure parameter, for the oil reservoir of the ultra-deep carbonate buried-hill of the Ordovician Age. Fractured zones in the studied reservoirs have a signature of acoustic impedance lower than 16500 (g/cc*m/s) and a pore structure parameter higher than 14. Quantitative geological interpretation further indicates that fractured zones are mostly located along the faults whereas high-porosity zones are distributed along the unconformity surface formed by dominating diagenetic processes...|$|R
40|$|Graduation date: 1984 Presentation date: 1983 - 06 - 30 Strip {{thinning}} {{is recognized}} {{as a way of}} commercial thinning young-growth stands. strip thinning has been used worldwide. The {{purpose of this study was}} to explicitly evaluate the costs and benefits associated with skyline strip thinning in young Douglas-fir (Pseudotuqo menzesii Franco) stands in the Pacific Northwest and to compare the results with the conventional method of cable thinning. A computer simulation model was developed to <b>integrate</b> <b>logging</b> technology, silvicultural treatment, and economic concerns. The computer model was validated using DFSIM. Simulation runs were conducted using data from previous O. S. U. field studies. The integrated results were expressed in present net worth yields over the rotation for specific treatments. The results suggest that in economic terms, strip thinning is always inferior to the conventional method of low thinning. This is due primarily to the reduced growth and yield experienced from strip thinning when compared to the conventional method. It is unlikely, under any foreseeable situation, that enough Abstract approved: Eldon D. Olsen logging cost reductions can be realized for the first entry to make the strip thinning alternative competitive. Sensitivity analysis of dID ratio suggests that strip thinning would be the best alternative only at d/D ratios of 1. 15 and greater...|$|R
40|$|The U. S. Geological Survey in {{cooperation}} with the Central Platte Natural Resources District is investigating the hydrostratigraphic framework of the High Plains aquifer in the Central Platte River basin. As part of this investigation, a comprehensive set of geophysical logs was collected from six test holes at three sites and analyzed to delineate the penetrated stratigraphic units and characterize their lithology and physical properties. Flow and fluid-property logs were collected from two wells at one of the sites and analyzed along with the other geophysical logs to determine the relative transmissivity of the High Plains aquifer units. The <b>integrated</b> <b>log</b> analysis indicated that the coarse-grained deposits of the alluvium and {{the upper part of the}} Ogallala Formation contributed more than 70 percent of the total transmissivity at this site. The lower part of the Ogallala with its moderately permeable sands and silts contributed some measureable transmissivity, as did the fine-grained sandstone of the underlying Arikaree Group, likely as a result of fractures and bedding-plane partings. Neither the lower nor the upper part of the siltstone- and claystone-dominated White River Group exhibited measurable transmissivity. The integrated analysis of the geophysical logs illustrated the utility of these methods in the detailed characterization of the hydrostratigraphy of the High Plains aquifer...|$|R
30|$|The model {{effectively}} <b>integrated</b> core, <b>logging,</b> seismic, {{and dynamic}} data {{to establish a}} three-dimensional structural model of low permeability reservoirs. Seismic impedance effectively predicts the distribution of inter-well sandbody. Ant body and water drive front data effectively predict fracture distribution. The established model can more effectively match the prior geological understanding of subsurface reservoirs {{and can be used}} to calculate the reserves and guide oil injection development. The reserves calculated by the model (718.82 [*]×[*] 104  t) were highly consistent with the actual reserves (724.1 [*]×[*] 104  t) with an error of approximately 7.4 %.|$|R
30|$|Andro-profiler conducts malware {{characterization}} {{based on}} dynamic behavior analysis. Our system extended Droidbox to embed the Loadable Kernel Module (LKM) for hijacking system calls including their arguments. More specifically, the Behavior Identification (BI) module {{in our system}} executes malware on an emulator and monitors malicious behavior in an isolated environment. Whenever malware is executed on the emulator, the BI fetches the integrated system logger. The integrated system logger parses system calls including their arguments provided by LKM and system logs provided by Droidbox; Droidbox monitors SMS, call, and network I/O. The parsed <b>integrated</b> system <b>logs</b> are then passed to the decision process.|$|R
30|$|Based on {{accurate}} horizon calibration {{and structural}} interpretation, it {{is a key}} procedure to build a low-frequency model for pre-stack inversion because it can greatly influence the inversion result. The structure {{in this area is}} simple, and it is easy to build a structural framework. <b>Integrated</b> with <b>logging</b> data and the geology framework, low-frequency models are built to include the P-impedance (Ip), S-impedance (Is) and density (ρ) models. We conducted the three previous inversion tests for each type of regularization. Further, the pseudo-P-impedance (PIp) model is constructed to aid and constrain the density solution as described previously.|$|R
30|$|The {{integration}} of several subsurface information to evaluate reservoir qualities of Eni field, offshore Niger Delta in southern Nigeria has proved successful {{in identifying the}} likely reasons for production challenges presented as decrease in oil production with increasing water output. This study has analysed and <b>integrated</b> well <b>logs,</b> 3 D seismic volume, core data, PVT and production data to generate information that would assist better management of the delineated reservoir compartments {{that make up the}} Eni field. The distribution of some reservoir properties as presented by the reservoir property maps could also guide the placement of both production and injection wells for optimum recovery.|$|R
40|$|The <b>Integrated</b> Health <b>Log</b> {{demonstrator}} {{shows how}} multimedia {{can be used}} in collaborative settings in healthcare. Patient data can be shared annotated discussed and processed by medics involved with a patient. Special emphasis is put on protecting the privacy of patients and allowing medics to keep responsibility for their patient data. In particular, grid technology is used to decouple services and service providers so that services can be executed {{under the control of the}} data owner. The system will be piloted in a gait analysis laboratory and in a network of physiotherapists involved in treating children with movement disorders...|$|R
5000|$|Samuel Morse {{independently}} {{developed a}} version of the electrical telegraph that he unsuccessfully demonstrated on 2 September 1837. Soon after he was joined by Alfred Vail who developed the register [...] - [...] a telegraph terminal that <b>integrated</b> a <b>logging</b> device for recording messages to paper tape. This was demonstrated successfully over three miles (five kilometres) on 6 January 1838 and eventually over forty miles (sixty-four kilometres) between Washington, D.C. and Baltimore on 24 May 1844. The patented invention proved lucrative and by 1851 telegraph lines in the United States spanned over 20,000 miles (32,000 kilometres).|$|R
40|$|In a {{large-scale}} IT infrastructure {{such as the}} LHCb Online system many applications are running on thousands of machines producing many GBs of logs every day. Although most of the logs are just routine logs, {{some of them may}} indicate an attack, a malfunction or provide vital debugging information. Due to their volume only automatisation of the analysis of the logs can provide us with an efficient way to handle all of these logs, ensuring that even the most rare logs will be processed. We present a centralized logging system which allow us to do in-depth analysis of every log. The description of the architecture includes information from how we <b>integrate</b> <b>logging</b> from many devices to a centralized server using syslog and in particular how a correlation can indicate an attack. Special emphasis is given both to security monitoring {{as well as to the}} logs that indicate developing malfunctions. To secure our network we have deployed the most known of HIDS, NIDS, LIDS (Host, Network, Log intrusion detection). Each one of them was configured both to cover our needs and communicate with other tools. In some cases, in addition to f configuring the tools, modification to their source code was needed. These modifications are described. Finally we evaluate our work on the performance on live data from our system and show how the predefined requirements are met. We present performance figures, resources needed for the tools and include a comparative study of various tools...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references: p. 95 - 97. Issued also on microfiche from Lange Micrographics. A major problem when analyzing open hole well logging data in large fields {{is the fact that the}} logs were run using different logging service companies, using different logging tools over a long time span. To obtain correct log interpretations, the logging data must be depth shifted, borehole corrected, then normalized. The normalized data can then be analyzed using modem interpretation methods to obtain consistent results from well to well. Well logs provide the data that allow geologists and engineers to characterize layered reservoirs. To <b>integrate</b> <b>log</b> analysis with core, well test and production data, the logging data must be consistent. To correct calibration errors and develop consistent data, the logging data must be normalized. Significant improvements in well log analysis methods, improved stratigraphic interpretation and reservoir delineation are possible when consistent logging data are available to the analysts and geologists. Practice in using well log analysis as part of integrated reservoir studies has shown that a process called multiwell normalization is necessary to ensure that results are accurate, consistent and comparative well-to-well. The objectives of this research were to explain the need for correcting and normalizing log data, illustrate how log normalization should be accomplished, and illustrate the use of log normalization using a field case history...|$|R
30|$|In {{order to}} further reduce the user {{efforts in the}} {{relevance}} feedback sessions, some approaches have been proposed for exploiting the feedback of various users in conjunction. In recent years, there is an emerging interest to analyze and exploit the historic data from different user interactions for improving the effectiveness of retrieval results considering multi-user collaborative environments [28]. This paradigm, {{commonly referred to as}} Collaborative Image Retrieval (CIR), has attracted a lot of attention [29 – 31]. In [30], a semi-supervised distance metric learning technique <b>integrates</b> both <b>log</b> data and unlabeled data information, using a graph approach. An approach for collaborative image retrieval using multi-class relevance feedback and Particle Swarm Optimization classifier is proposed in [31].|$|R
30|$|Meanwhile, {{carbonate}} reservoirs hold {{a larger}} percentage of the world’s proven reserves (Awolayo et al. 2015); their characterization will continue to remain enormously difficult due to LRP among other concerns. With this background knowledge in mind, this paper proposes a novel workflow to evaluate LRP reservoirs and develop a robust model to unveil the reservoir potential. The developed workflow is aimed to be the best practice to define hydrocarbon saturation through an interdisciplinary study by <b>integrating</b> conventional <b>logs,</b> core analysis (porosity, permeability, Dean–Stark, MICP, porous plate, and centrifuge capillary pressures), wireline formation tester (WFT), and drill stem test (DST) results. Lastly, we present the validation of the new model with data acquired from a new well drilled to the newly identified free water level (FWL).|$|R
40|$|Mississippian {{carbonate}} reservoirs {{have produced}} {{in excess of}} 1 billion barrels of oil in Kansas accounting for over 16 % of the state's production. With declining production from other age reservoirs, the contribution of Mississippian reservoirs to Kansas's oil production has risen to 43 % as of 2004. However, solution-enhanced features such as vertical shale intervals extending from the karst erosional surface at the top introduce complexities/compartmentalizations in Mississippian carbonate reservoirs. Coupled with this, strong water drives charge many of these reservoirs resulting in limited drainage from vertical wells due to high water cuts after an initial period of low water production. Moreover, most of these fields are operated by small independent operators without access to the knowledge bank of modern research in field characterization and exploitation/development practices. Thus, despite increasing importance of Mississippian fields to Kansas production, these fields are beset with low recovery factors and high abandonment rates leaving significant resources in the ground. Worldwide, horizontal infill wells {{have been successful in}} draining compartmentalized reservoirs with limited pressure depletion. The intent of this project was to demonstrate the application of horizontal wells to successfully exploit the remaining potential in mature Mississippian fields of the mid-continent. However, it is of critical importance that for horizontal wells to be economically successful, they must be selectively targeted. This project demonstrated the application of initial and secondary screening methods, based on publicly available data, to quickly shortlist fields in a target area for detailed studies to evaluate their potential to infill horizontal well applications. Advanced decline curve analyses were used to estimate missing well-level production data and to verify if the well produced under unchanging bottom-hole conditions [...] two commonly occurring data constraints afflicting mature Mississippian fields. A publicly accessible databank of representative petrophysical properties and relationships was developed to overcome the paucity of such data that is critical to modeling the storage and flow in these reservoirs. Studies in 3 Mississippian fields demonstrated that traditional reservoir models built by <b>integrating</b> <b>log,</b> core, DST, and production data from existing wells on 40 -acre spacings are unable to delineate karst-induced compartments, thus making 3 D-seismic data critical to characterize these fields. Special attribute analyses on 3 D data were shown to delineate reservoir compartments and predict those with pay porosities. Further testing of these techniques is required to validate their applicability in other Mississippian reservoirs. This study shows that detailed reservoir characterization and simulation on geomodels developed by <b>integrating</b> wireline <b>log,</b> core, petrophysical, production and pressure, and 3 D-seismic data enables better evaluation of a candidate field for horizontal infill applications. In addition to reservoir compartmentalization, two factors were found to control the economic viability of a horizontal infill well in a mature Mississippian field: (a) adequate reservoir pressure support, and (b) an average well spacing greater than 40 -acres...|$|R
40|$|Obtaining an {{accurate}} velocity model {{is fundamental to}} successfully imaging complex salt bodies in the deep Gulf of Mexico. With the introduction of faster, full volume wavefield solutions that output finely-sampled angle gathers, velocity models can be constructed allowing the full potential of the wavefield method {{to be applied to}} our most complex subsurface problems. We present a case history of building a high-resolution velocity model in the Gulf of Mexico, using multiple iterations of wave-equation migration and angle common image gathers (ACIG). We show how in certain instances picking in depth slices can build more detail in the velocity model, and how we <b>integrated</b> well <b>log</b> information and other stratigraphic geological information into the velocity model in collaboration with the interpreter team, to produce an optimal depth migrated image...|$|R
30|$|Prediction of {{permeability}} accurately {{enough from}} core and well logs {{have been achieved}} by several authors (Tiab 1993; Amaefule et al. 1993; Elkewidy 1996; Shedid Elgaghah 1997). They proposed methods for <b>integrating</b> core and <b>log</b> data for formation evaluation in term of flow units. To have a better reservoir description, we should consider the vertical variation of hydraulic properties. Osisanya et al. (1998) developed new permeability porosity correlations but without consideration of anisotropic conditions of the reservoirs.|$|R
