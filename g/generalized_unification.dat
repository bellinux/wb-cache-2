5|20|Public
40|$|There {{are four}} {{fundamental}} forces; gravitational force, electromagnetic force, strong force and weak force, {{in the well}} known physics. The unified field theory considers the constructive relations among these forces or fields. In the present work the fundamental relations have been studied and trial {{has been made to}} derive more significant relations among the known fields. This gives out a <b>generalized</b> <b>unification...</b>|$|E
40|$|We {{report on}} a method of {{automated}} hypothesis generation, called f-resolution, which is derived from deductive resolution techniques. The method is inductive in character, {{in the sense that}} given input statement E, it generates hypotheses H, such that E is a deductive consequence of E. The method is extended by a <b>generalized</b> <b>unification</b> algorithm which introduces appropriate identity assumptions needed to unify a pair of literals. The f-resolution technique is shown to embody a version of Ockham's raror as a pruning heuristic. Some promising experimental results are also presented. In [5] we discussed a general method fo...|$|E
40|$|AbstractIncorporating {{equality}} {{into the}} unification process has added great power to automated theorem provers. We see a similar trend in logic programming where {{a number of}} languages are proposed with specialized or extended unification algorithms. There {{is a need to}} give a logical basis to these languages. We present here a general framework for logic programming with definite clauses, equality theories, and <b>generalized</b> <b>unification.</b> The classic results for definite clause logic programs are extended in a simple and natural manner. The extension of the soundness and completeness of the negation-as-failure rule for complete logic programs is conceptually more delicate and represents the main result of this paper...|$|E
40|$|Abstract. Sequence {{variables}} play {{an interesting}} role in unification and matching {{when dealing with}} terms in an unranked signature. Sequence <b>Unification</b> <b>generalizes</b> Word <b>Unification</b> {{and seems to be}} appealing for information extraction in XML documents, program transformation, and rule-based programming. In this work we study a relation between Sequence Unification and another generalization of Word Unification: Context Unification. We introduce a variant of Context Unification, called Left-Hole Context Unificatio...|$|R
40|$|We extend {{previous}} work on difference identification and reduction as a technique for automated reasoning. We <b>generalize</b> <b>unification</b> so that terms are made equal {{not only by}} finding substitutions for variables but also by hiding term structure. This annotation of structural differences serves to direct rippling, a kind of rewriting designed to remove structural differences in a controlled way. On the technical side, we give a rule-based algorithm for diffeerence unification, and analyze its correctness, completeness, and complexitiy. On the practical side, we present a novel search strategy (called left-first search) for applying these rules in an efficient way. Finally, we show how this algorithm {{can be used in}} new ways to direct rippling and how it can {{play an important role in}} theorem proving and other kinds of automated reasoning. (orig.) SIGLEAvailable from TIB Hannover: RR 1912 (92 - 247) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Forschung und Technologie (BMFT), Bonn (Germany) DEGerman...|$|R
50|$|Many {{applications}} require one {{to consider}} the unification of typed lambda-terms instead of first-order terms. Such unification is often called higher-order unification. A well studied branch of higher-order unification {{is the problem of}} unifying simply typed lambda terms modulo the equality determined by αβη conversions. Such unification problems do not have most general unifiers. While higher-order unification is undecidable, Gérard Huet gave a semi-decidable (pre-)unification algorithm that allows a systematic search of the space of unifiers (<b>generalizing</b> the <b>unification</b> algorithm of Martelli-Montanari with rules for terms containing higher-order variables) that seems to work sufficiently well in practice. Huet and Gilles Dowek have written articles surveying this topic.|$|R
40|$|Understanding {{the nature}} of time remains a key unsolved problem in science. Newton in the Principia {{asserted}} an absolute universal time that `flows equably'. Hamilton then proposed a mathematical unification {{of space and time}} {{within the framework of the}} quaternions that ultimately lead to the famous Minkowski formulation in 1908 using four-vectors. The Minkowski framework is found to provide a versatile formalism for describing the relationship between space and time in accordance with relativistic principles, but nevertheless fails to provide deeper insights into the physical origin of time and its properties. In this paper we begin with a recognition of the fundamental role played by three-dimensional space in physics that we model using the Clifford algebra multivector. From this geometrical foundation we are then able to identify a plausible origin for our concept of time. This geometrical perspective also allows us to make a key topological distinction between time and space, with time being a point-like quantity. The multivector then allows a <b>generalized</b> <b>unification</b> of time and space within a Minkowski-like description. Comment: 17 pages, 0 figure...|$|E
40|$|Gated {{attribute}} grammars and error-tolerant unification expand {{upon the}} usual views of attribute grammars and unification. Normally, attribute grammars are constrained to be noncircular; gated attribute grammars allow fairly general circularities. Most unification algorithms do not behave well when given inconsistent input; the new unification paradigm proposed here not only tolerates inconsistencies but extracts information from them. The expanded views {{prove to be}} useful in interactive language-based programming environments. <b>Generalized</b> <b>unification</b> allows the environment to help the user find the sources of type errors in a program, while gated attribute grammars allow the environment to provide an interpreter for incremental reevaluation of programs after small changes to the code. The defining feature of gated attribute grammars is {{the appearance of a}} gate attribute (indicating where cycle evaluation should begin and end) within every cycle. Attributes are ordered by collapsing strongly connected components in the dependency graph and topologically sorting the result. The smaller dependency graph for each component (ignoring edges leading to the gate) can be recursively collapsed to provide further ordering. use of the evaluation order defined in this manner allows gated attribute grammars to do without the restrictions on functions within a component needed by the other varieties of circular attribute grammars. Initial and incremental evaluation algorithms are given, as well as a sample grammar allowing an editor for a small language to become an incremental interpreter. Counting unification defines unique solutions to sets of input equations that contain conflicting type information. These solutions are derived from the potential variable constraints implied by the input equations. For each type variable, each branch (a portion of a constraint) is assigned a weight indicating the number of times the input set implied such a constraint. When the input equations are derived from the static analysis of a program, the relative branch weights for a conflicting variable give the overall pattern of uses of that variable and can direct attention to parts of the program that disagree with the majority of uses. A number of error-tolerant unification algorithms are presented...|$|E
40|$|Abstract. We extend first-order order-sorted {{unification}} by permitting {{regular expression}} sorts for variables {{and in the}} domains of function symbols. The set of basic sorts is finite. The obtained signature corresponds to a finite bottom-up hedge automaton. The unification problem in such a theory <b>generalizes</b> some known <b>unification</b> problems. Its unification type is infinitary. We give a complete unification procedure and prove decidability...|$|R
40|$|Unification is a {{fundamental}} operation in various areas of computer science, in particular in automated theorem proving and logic programming. In this paper we establish a relation between unification theory and classical model theory. We show how model‐theoretic methods {{can be used to}} investigate a <b>generalized</b> form of <b>unification,</b> namely the problem whether, given an equational theory E and a system of equations S, there is an extension of the free algebra in E in which S is solvable...|$|R
40|$|Finding, {{transforming}} or integrating {{information on}} the Web and Semantic Web often involves matching a structured query with semi-structured data. In logic programming languages, this notion of matching is formalized by unification. With the plethora of different data formats available on the Web, {{there is no single}} sensible notion of matching or unifying queries with data. We introduce the notion of rich <b>unification,</b> which <b>generalizes</b> standard <b>unification</b> in logic programming, matching SPARQL query patterns with RDF graphs, evaluation of XPath or XQuery expressions on XML documents, and simulation of Xcerpt terms with RDF or XML data. On top of rich unification, we introduce a rule language Xcerpts with recursion and negation as failure which is a variant of Xcerpt. We present an evaluation algorithm, called Subsumption-Based Resolution for rule languages with rich unification (SBR) resolving a query w. r. t. a locally stratified program with the bounded-term-size property. With the help of numerous Xcerpts resolution examples we explain the main features of the algorithm and its differences to some other evaluation strategies such as SLD-, OLDT- an...|$|R
40|$|International audienceThe graph {{rewriting}} calculus is {{an extension}} of the ρ-calculus, handling graph like structures rather than simple terms. The calculus over terms is naturally <b>generalized</b> by using <b>unification</b> constraints in addition to the standard rho-calculus matching constraints. The transformations are performed by explicit application of rewrite rules as first class entities. The possibility of expressing sharing and cycles allows one to represent and compute over regular infinite entities. We propose in this paper a reduction strategy for the graph rewriting calculus which aims at maintaining the sharing information as long as possible in the terms. The corresponding reduction relation is shown to be confluent and complete with regards to the small-step semantics of the graph rewriting calculus...|$|R
40|$|Generating {{timetables}} is a cumbersome {{and time}} consuming task, but programs developed {{to solve them}} are usually meant for a particular organisation {{and can not be}} easily adapted. Constraint Logic Programming, the result of <b>generalizing</b> Logic Programming <b>unification</b> to constraint solving over a computation domain, aim at expressing constrained decision problems declaratively, and still solve them efficiently. DOMLOG is a CLP(FD) system, that extends CHIP with features such as user-defined heuristics, and more flexible lookahead constraint solving. The adequacy of integrating heuristics and lookahead was discussed in previous work for a simplified timetabling problem. This paper presents the main features of an expert system developed with DOMLOG to solve the timetabling problem for the Computer Science Department of the FCT/UNL...|$|R
40|$|Restricted Access. Quantum {{mechanics}} and gravitation are two pillars of modern physics. Despite {{their success in}} describing the physical world around us, {{they seem to be}} incompatible theories. There are suggestions that one of these theories must be <b>generalized</b> to achieve <b>unification.</b> For example, Born’s rule—one of the axioms of quantum mechanics—could be violated. Born’s rule predicts that quantum interference, as shown by a double-slit diffraction experiment, occurs from pairs of paths. A generalized version of quantum mechanics might allow multipath (i. e., higher-order) interference, thus leading to a deviation from the theory. We performed a three-slit experiment with photons and bounded the magnitude of three-path interference to less than 10 − 2 of the expected two-path interference, thus ruling out third- and higher-order interference and providing a bound on the accuracy of Born’s rule. Our experiment is consistent with the postulate both in semiclassical and quantum regimes...|$|R
40|$|Introduced {{at the end}} of the nineties, the Rewriting Calculus (rho-{{calculus}}, for short) is {{a simple}} calculus that uniformly integrates term-rewriting and lambda-calculus. The Rhog has been recently introduced as an extension of the rho-calculus, handling structures with cycles and sharing. The calculus over terms is naturally <b>generalized</b> by using <b>unification</b> constraints in addition to the standard rho-calculus matching constraints. This leads to a term-graph representation in an equational style where terms consist of unordered lists of equations. In this paper we show that the (linear) Rhog is confluent. The proof of this result is quite elaborated, due to the non-termination of the system and to the fact that we work on equivalence classes of terms. We also show that the Rhog can be seen as a generalization of first-order term-graph rewriting, in the sense that for any term-graph rewrite step a corresponding sequence of rewritings can be found in the Rhog...|$|R
40|$|Introduced {{at the end}} of the nineties, the Rewriting Calculus (ρ-{{calculus}}, for short) is {{a simple}} calculus that fully integrates term-rewriting and λ-calculus. The rewrite rules, acting as elaborated abstractions, their application and the obtained structured results are first class objects of the calculus. The evaluation mechanism, generalizing beta-reduction, strongly relies on term matching in various theories. In this paper we propose an extension of the ρ-calculus, handling graph like structures rather than simple terms. The transformations are performed by explicit application of rewrite rules as first class entities. The possibility of expressing sharing and cycles allows one to represent and compute over regular infinite entities. The calculus over terms is naturally <b>generalized</b> by using <b>unification</b> constraints in addition to the standard ρ-calculus matching constraints. This therefore provides us with the basics for a natural extension of an explicit substitution calculus to term graphs. Several examples illustrating the introduced concepts are given...|$|R
40|$|Abstract. Introduced {{at the end}} of the nineties, the Rewriting Calculus (ρ-{{calculus}}, for short) is {{a simple}} calculus that uniformly integrates termrewriting and λ-calculus. The ρg-calculus has been recently introduced as an extension of the ρ-calculus, handling structures with cycles and sharing. The calculus over terms is naturally <b>generalized</b> by using <b>unification</b> constraints in addition to the standard ρ-calculus matching constraints. This leads to a term-graph representation in an equational style where terms consist of unordered lists of equations. In this paper we show that the (linear) ρg-calculus is confluent. The proof of this result is quite elaborated, due to the non-termination of the system and to the fact that we work on equivalence classes of terms. We also show that the ρg-calculus can be seen as a generalization of first-order term-graph rewriting, in the sense that for any term-graph rewrite step a corresponding sequence of rewritings can be found in the ρg-calculus. ...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceIntroduced {{at the end}} of the nineties, the Rewriting Calculus (rho-{{calculus}}, for short) is {{a simple}} calculus that fully integrates term-rewriting and lambda-calculus. The rewrite rules, acting as elaborated abstractions, their application and the obtained structured results are first class objects of the calculus. The evaluation mechanism, generalizing beta-reduction, strongly relies on term matching in various theories. In this paper we propose an extension of the rho-calculus, handling graph like structures rather than simple terms. The transformations are performed by explicit application of rewrite rules as first class entities. The possibility of expressing sharing and cycles allows one to represent and compute over regular infinite entities. The calculus over terms is naturally <b>generalized</b> by using <b>unification</b> constraints in addition to the standard rho-calculus matching constraints. This therefore provides us with the basics for a natural extension of an explicit substitution calculus to term graphs. Several examples illustrating the introduced concepts are given...|$|R
40|$|Quantum {{mechanics}} and gravitation are two pillars of modern physics. Despite {{their success in}} describing the physical world around us, {{they seem to be}} incompatible theories. There are suggestions that one of these theories must be <b>generalized</b> to achieve <b>unification.</b> For example, Born's rule, one of the axioms of quantum mechanics could be violated. Born's rule predicts that quantum interference, as shown by a double slit diffraction experiment, occurs from pairs of paths. A generalized version of quantum mechanics might allow multi-path, i. e. higher order interferences thus leading to a deviation from the theory. We performed a three slit experiment with photons and bounded the magnitude of three path interference to less than 10 - 2 of the expected two-path interference, thus ruling out third and higher order interference and providing a bound on the accuracy of Born's rule. Our experiment is consistent with the postulate both in semi-classical and quantum regimes...|$|R
40|$|Both Sequence and Context <b>Unification</b> <b>generalize</b> {{the same}} problem: Word Unification. Besides that, Sequence Unification solves {{equations}} between unranked terms involving sequence variables, {{and seems to}} be appealing for information extraction in XML documents, program transformation, knowledge representation, and rule-based programming. It is decidable. Context Unification deals with the same problem for ranked terms involving context variables, and has applications in computational linguistics and program transformation. Its decidability is a long-standing open question. In this work we study a relation between these two problems. We introduce a variant (restriction) of Context Unification, called Left-Hole Context Unification (LHCU), to which Sequence Unification is P-reduced: We define a partial currying procedure to translate sequence unification problems into left-hole context unification problems, and prove soundness of the translation. Furthermore, a precise characterization of the shape of the unifiers allows us to easily reduce Left-Hole Context Unification to (the decidable problem of) Word Unification with Regular Constraints, obtaining then a new decidability proof for Sequence Unification. Finally, we define an extension of Sequence Unification (ESU) and, closing the circle, prove the inter P-reducibility of LHCU and ESU...|$|R

