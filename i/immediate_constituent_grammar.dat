1|111|Public
40|$|The paper {{presents}} {{an example of}} a representation of parse tree forests advocated by the author. Although motivated by the need to analyse the forests generated by Świdziński's grammar, the representation can be used for any grammar handled by Woliński's Birnam parser, and the basic ideas can be applied to any <b>Immediate</b> <b>Constituent</b> <b>grammar.</b> Syntactic spreadsheets can serve several purposes. They can be simply included in printed publications or dynamically displayed by an appropriate viewer. Unfortunately the implementation of the idea is not easy and therefore it is still in progress...|$|E
40|$|This diploma thesis "Adverbials in German and Czech" is {{exploring}} adverbials in Czech and German grammars and further more it explores their presentation in German textbooks. First part deals with German grammars - {{what is their}} conception of syntax, how do they determine constituent of a sentence and how they then classify adverbials. Comparison is made on basis of traditional grammar, interest is given to dependency <b>grammar</b> and <b>immediate</b> <b>constituent</b> analysis. Czech <b>grammar</b> is explained shortly in second part, followed by description of adverbials found in Czech language. Semantics play major when classifying adverbials. Third part of thesis {{is dealing with the}} textbooks which are available in Czech Republic and which could be used for teaching of German language. There are not many textbooks edited in Czech Republic which would be considering adverbials in German language. The division of Ergänzung and Angabe could be found in textbooks edited in Germany. This division is important when considering word order...|$|R
5000|$|Given {{a phrase}} {{structure}} grammar (= constituency grammar), IC-analysis divides up a sentence into major parts or <b>immediate</b> <b>constituents,</b> and these constituents are in turn divided into further <b>immediate</b> <b>constituents.</b> The process continues until irreducible constituents are reached, i.e., until each constituent consists {{of only a}} word or a meaningful part of a word. The end result of IC-analysis is often presented in a visual diagrammatic form that reveals the hierarchical <b>immediate</b> <b>constituent</b> structure of the sentence at hand. These diagrams are usually trees. For example: ...|$|R
50|$|This tree {{illustrates}} {{the manner in}} which the entire sentence is divided first into the two <b>immediate</b> <b>constituents</b> this tree and illustrates IC-analysis according to the constituency relation; these two constituents are further divided into the <b>immediate</b> <b>constituents</b> this and tree, and illustrates IC-analysis and according to the constituency relation; and so on.|$|R
40|$|Origins {{of phrase}} {{structure}} analysis To understand {{the properties of}} modern phrase structure grammars, {{it is useful to}} place their development in a wider formal and historical context. Phrase structure grammars and associated notions of phrase structure analysis have their proximate origins in models of <b>Immediate</b> <b>Constituent</b> (IC) analysis. Although inspired by the programmatic syntactic remarks in Bloomfield (����), these models were principally developed by Bloomfield’s successors, most actively in the decade between the publication of Wells (����) and the advent of transformational analyses in Harris (����) and Chomsky (����). The central intuition underlying models of IC analysis was that the structure of an expression could be exhibited by dividing the expression into parts (its <b>immediate</b> <b>constituents),</b> further subdividing these parts, and continuing until syntactically indivisible units were obtained. This style of analysis was motivated in part by a belief in the ������� � of syntactic relations, in particular the view that the most important relations held between <b>immediate</b> <b>constituents.</b> The process of analyzing syntax is largely one of finding successive layer...|$|R
40|$|ESP. ?? ????????-?????????? ??????????? ??????? ???, ? ????? ????????????, ??????????? ? ??????????????. ????????????? ??????? ??????????? ? ?????????? ??????? ???????-????????? ??????????. Foundations of the {{technical}} translation as <b>immediate</b> <b>constituents</b> of ESP are considered in this article. They are: lexical and grammar particulars of {{the technical}} texts, linguistic and stylistic as well. The question concerns abstract and annotated translation. ? ?????? ??????????????? ?????? ??????-???????????? ???????? ??? ???????????? ????? ESP. ??? ???????-?????????????? ??????????? ??????? ???, ? ????? ???????????????, ?????????????? ? ?????????????????. ????????????? ?????? ????????????? ? ????????????? ??????? ??????-??????????? ??????????...|$|R
40|$|Drawing on methods from {{quantitative}} linguistics, {{this paper}} tests {{the hypothesis that}} the intonation unit is a valid language construct whose <b>immediate</b> <b>constituent</b> is the foot (and whose own <b>immediate</b> <b>constituent</b> is the syllable). If the hypothesis is true, then the lengths of intonation units, measured in feet, should abide by a regular and parsimonious discrete probability distribution, and the immediate constituency relationship between feet and intonation units should be further demonstrable by successfully fitting the Menzerath-Altmann equation with a negative exponent. However, out of sixteen texts from the Aix-MARSEC database, only six share a common probability distribution and only eight exhibit a tolerable fit of the Menzerath-Altmann equation. A failure rate of ≥ 50 % in both cases casts doubt on the validity of the hypothesis...|$|R
40|$|Exocentric (aredundant) constructions {{to which}} belong e. g. prepositional phrases periphrastic forms within the verb phrase, phraseologisms, idiomatic expressions, {{are the result}} of {{analysis}} of syntactic constructions according to the method of <b>immediate</b> <b>constituents.</b> The article contains their survey together with the examples of derivation in Polish and German...|$|R
40|$|The aim of {{this paper}} is to {{describe}} the internal syntax of Hungarian noun phrases in terms of their <b>immediate</b> <b>constituent</b> structure. The external syntax of NPs, i. e. their distribution in larger phrases and sentences will be mentioned only in passing – for a more detailed discussion, see Kenesei (1985). Section 1 deals wit...|$|R
50|$|A {{constituent}} is {{any word}} or combination {{of words that}} is dominated by a single node. Thus each individual word is a constituent. Further, the subject NP Colorless green ideas, the minor NP green ideas, and the VP sleep furiously are constituents. Phrase structure rules and the tree structures {{that are associated with}} them are a form of <b>immediate</b> <b>constituent</b> analysis.|$|R
40|$|One {{strategy}} in trading competition is by using advertising {{but to make}} a good advertisement an advertiser should pay attention on several key elements. Most of those key elements are in form of a written language such as headline, illustration, subhead, and slogan. Advertisement language is usually arranged in interesting design and exciting language. To understand the language of advertisement can be done by understanding the constituents of the language. The goal of this research is to find out the constituents and to describe the construction of the advertisement language of Dunkin’ Donuts advertisement in Dunkin’ Donuts calendar 2001. This research is a descriptive qualitative research that describes the construction of a structure and find out the constituents that form the structure. This research is concentrate on structural <b>grammar</b> with applying <b>immediate</b> <b>constituents</b> analysis by using Chinese box. The results of this research are: (1) kinds of constituents that form the construction are <b>immediate</b> <b>constituent</b> and ultimate <b>constituent,</b> (2) in <b>Immediate</b> <b>Constituents</b> analysis there are four kinds of syntactic structures that used to show the relation between constituents. Those syntactic structures are Syntactic Structure of Modification (SSoM), Syntactic Structure of Predication (SSoP), Syntactic Structure of Complementation (SSoC), Syntactic Structure of Coordination (SSoCo), (3) a sentence is, at list, built up by Syntactic Structure of Predication (SSoP) except imperative sentence that built up by Syntactic Structure of Complementation (SSoC). Syntactic Structure of Modification (SSoM) builds a phrase construction Syntactic Structure of Coordination (SSoCo) is used to show the relation of two equivalent constituents...|$|R
40|$|A simple {{sentence}} {{consists of}} a single independent clause. A multiple sentence contains one or more clauses as its <b>immediate</b> <b>constituents.</b> Multiple sentences are either compound or complex. In a compound sentence the <b>immediate</b> <b>constituents</b> are two or more coordinate clause. In a complex sentence {{one or more of}} its elements, such as direct object or adverbial, are realized by a subordinate. [1] Simple sentence may be divided into four major syntactic classes, whose use correlates with different communicative functions;[2] we have in Albanian and English same structure of forms e. g. 	The sentence that has the subject and is always present and usually precedes the verb and it is positive sentence: The teacher will speak to the dean today. Mësuesi do të flet me dekanin sot. 	The question sentence forms have three or more models of making and noun is the kernel e. g. Will teacher speak to the dean today? [1] Randolph Quirk (…). (1985). A comprehensive grammar of the English language. London, p. 719. [2] Randalph Quirk. (1973). A university grammar of English. London, p. 191...|$|R
40|$|In {{this paper}} we analyze the perfor-mance of {{different}} composition models {{on a large}} dataset of German compound nouns. Given a vector space model for the German language, we try to reconstruct the observed representation (the corpus-estimated vector) of a compound by com-posing the observed representations of its two <b>immediate</b> <b>constituents.</b> We explore the composition models proposed in the literature and also present a new, simple model that achieves the best performance on our dataset. ...|$|R
40|$|Words, phrases or {{sentences}} are ambiguous if {{they express}} {{more than one}} meaning. Ambiguity {{is a very complex}} problem, and one of the suggestions how to solve the problem is either to use the method of <b>immediate</b> <b>constituents</b> analysis or apply transformational generative approach to language analyses. There are other contemporary approaches that treat the problem of ambiguity, {{and one of them is}} the phrase structure grammar. In comprehending ambiguous sentences and phrases, syntax and semantics have an equal status...|$|R
5000|$|The {{structural}} analysis of subject-auxiliary inversion, and of inversion in general, challenges many theories of sentence structure, in particular, those theories based on phrase structure. The challenge {{stems from the}} fact that these theories posit the existence of a finite verb phrase constituent. The standard declarative sentence is divided into two <b>immediate</b> <b>constituents,</b> a subject NP and a predicate VP. When subject-auxiliary inversion occurs, it appears to violate the integrity of the predicate. The canonical predicate is underlined in the following sentences: ...|$|R
50|$|The {{remnants}} {{in these}} examples are <b>constituents</b> in constituency <b>grammars</b> (= phrase structure grammars), since every individual word {{is by definition}} a <b>constituent</b> in constituency <b>grammars.</b> These words are not, however, <b>constituents</b> in dependency <b>grammars,</b> since they dominate other (elided) material. The constituency vs. dependency distinction is therefore one avenue that one might pursue to locate an explanation of such cases. If one chooses a constituency-based grammar, however, then the explanation might {{draw attention to the}} distinction between projection levels (see X-bar theory): the remnant must qualify as a maximal projection (as opposed to an intermediate or minimal projection).|$|R
40|$|International audienceThis paper {{investigates the}} seminal texts on <b>Immediate</b> <b>Constituent</b> Analysis and the {{associated}} diagrams. We show that {{the relations between the}} whole and its parts, that are typical of current phrase structure trees, were less prominent in the early di-agramming efforts than the relationships between units of the same level. This can be observed until the beginning of the 1960 's, including in Chomsky's Syntactic Structures (1957). We discuss whether such analyses could be said " dependency-based ", according to an attempt to define this term...|$|R
40|$|In {{this article}} I {{am trying to}} find some analogies between {{linguistic}} and archaeological units. Once these analogies have been stated, we may apply some linguistic concepts to archaeology, especially when building typologies. In the same way I describe the analogies, I must say that in some cases these analogies are not valid. Basically, the linguistic concepts that may be applied to archaeology are: 1) the <b>immediate</b> <b>constituents,</b> and 2) the fact that both disciplines can be seen as structures with significant forms, arrangements and functions...|$|R
40|$|A {{procedure}} {{based on}} the frequency and redundancy of sequences of syntactic word-classes was devised to identify behavioural word groups, or phrases. A small sample of these phrases, derived from processing a short corpus of running text, w a s compared with phrases produced by <b>immediate</b> <b>constituent</b> analysis of the same text. Over 50 % agreement between the two procedures was found, with {{a majority of the}} disagreements being attributable to the disparity in descriptive power between the two analytic procedures rather than 10 a conceptual dzerence in the types of word-group defined...|$|R
40|$|International audienceWe {{show that}} the class of string-meaning {{relations}} definable by the following two types of grammars coincides: (i) Lambek grammars where each lexical item is assigned a (suitably typed) lambda term as a representation of its meaning, {{and the meaning of}} a sentence is computed according to the lambda- term corresponding to its derivation; and (ii) cycle-free context-free grammars that do not generate the empty string where each rule is associated with a (suitably typed) lambda term that specifies how the meaning of a phrase is determined by the meanings of its <b>immediate</b> <b>constituents...</b>|$|R
40|$|This paper {{investigates the}} seminal texts on <b>Immediate</b> <b>Constituent</b> Analysis and the {{associated}} diagrams. We show that {{the relations between the}} whole and its parts, that are typical of current phrase structure trees, were less prominent in the early diagramming efforts than the relationships between units of the same level. This can be observed until the beginning of the 1960 ’s, including in Chomsky’s Syntactic Structures (1957). We discuss whether such analyses could be said “dependency-based”, according to an attempt to define this term. this term. Peer reviewe...|$|R
50|$|He was {{saddled with}} the more {{challenging}} task of nurturing the Demobilisation, Rehabilitating and Re-integration of ex-combatants back into society. His <b>immediate</b> <b>constituents</b> were 20,192 warring youth who accepted the Amnesty Proclamation in 2009. He took the challenge with the zeal of priesthood. Although he held the office for about a year, he {{put in place a}} five-year framework for the efficient implementation of the Demobilisation, Demobilisation and Reintegration Program. Today, as the Federal Government reflects on some of the initial successes of this program, Timi Alaibe stands tall as the midwife of that process.|$|R
40|$|Unrestricted text {{analysis}} requires an accurate syntactic analysis but structural ambiguity {{is one of}} the most difficult problems to resolve. Researchers have tried different approaches to obtain the correct syntactic structure from analyzed sentences but not successful results have been obtained. Two different approaches have traditionally applied to syntactic analysis: <b>constituent</b> <b>grammars</b> and dependency grammars. We propose a model for syntactic analysis and disambiguation combining lexical dependencies and semantic proximity. Lexical dependencies are applied by means of a government pattern dictionary following the dependency approach. The semantic proximity is introduced by means of semantic closeness among constituents. Examples are given to illustrate method’s contributions...|$|R
40|$|The article aims {{to examine}} the {{similarities}} and differences between Minangkabau languages in the origin regions 50 Kota and Pasaman West Sumatra compared to rantau areas Kampar and Rokan Hulu Riau. The study is done by dialectology approach which focuses on affixes. The data are collected by using conversational observation method along with the interview and record techniques. The data are analyzed by using identity method along with <b>immediate</b> <b>constituent</b> analysis and advanced techniques, comparative and contrastive techniques. The result shows there similarities and differences of Minangkabau affixes between both areas. Keyword: Affix, dialectological, Minangkabau, origin, ranta...|$|R
40|$|A new {{approach}} to bottom. up parsing that extends Augmented Context-Free Grammar to a Process Grammar is formally presented. A Process Grammar (PG) defines {{a set of rules}} suited for bottom-up parsing and conceived as pracesses that are apPlied by a PG Processor. The matching phase is a crucial step for process application, and a parsin 8 structure for efficient matching is also presented. The PG Processor is composed of a process scheduler that allows <b>immediate</b> <b>constituent</b> analysis of structures, and behaves in a non-deterministic fashion. On the other side, the PG offers means for implementing specOc parsing strategies improving the lack of determinism innate in the processor...|$|R
40|$|This study {{addresses}} {{the possibility that}} interfixes in multiconstituent nominal compounds in German and Dutch are functional as markers of <b>immediate</b> <b>constituent</b> structure. We report a lexical statistical survey of interfixation in the lexicons of German and Dutch which shows that all interfixes of German and one interfix of Dutch are {{significantly more likely to}} appear at the major constituent boundary than expected under chance conditions. A series of experiments provides evidence that speakers of German and Dutch are sensitive to the probabilistic cues to constituent structure provided by the interfixes. Thus, our data provide evidence that probability {{is part and parcel of}} grammatical competence...|$|R
50|$|In linguistics, <b>immediate</b> <b>constituent</b> {{analysis}} or IC {{analysis is}} a method of sentence analysis that was first mentioned by Leonard Bloomfield and developed further by Rulon Wells. The process reached a full-blown strategy for analyzing sentence structure in the early works of Noam Chomsky. The practice is now widespread. Most tree structures employed to represent the syntactic structure of sentences are products of some form of IC-analysis. The process and result of IC-analysis can, however, vary greatly based upon whether one chooses the constituency relation of phrase structure grammars (= constituency grammars) or the dependency relation of dependency grammars as the underlying principle that organizes constituents into hierarchical structures.|$|R
40|$|This Research Paper aims at knowing (1) What are the <b>immediate</b> <b>constituents</b> in phrasal verb, and (2) What are {{the types}} of meaning of phrasal verb. In this research, the writer conducts a {{qualitative}} research, it develops theories and proposition from the data they collect as the research develops. Then it attempts to describe as fully as possible what is being observed. The object {{of the study is}} English phrasal verb, that is verb made up of verb and preposition or an adverb. The writer collects the data from documentary sources, namely Hot Chord magazine. Then the steps in collecting data are: reading the text of the song in magazine, and selecting the phrasal verb in a song to support the analysis process. In analyzing the data, the writer applies a descriptive method. After the data are collected, the writer analyzes it by using structural analysis in Chinese box, then she describes it as fully as possible. To analyze the type of meaning, the writer uses Leech’s theory about seven types of meaning. After the writer analyzes the phrasal verb by using structural analysis, she comes to the conclusion that: (a) The <b>immediate</b> <b>constituents</b> in phrasal verb are: verb + preposition + object,it forms transitive phrasal verb; verb + adverb; verb + pronoun object + adverb, those form intransitive phrasal verb and (b) Based on Seven Types of Meaning by Leech, Phrasal verb has five types of meaning, those are: Denotative Meaning, Connotative Meaning, Social Meaning, Reflective Meaning,,and Affective Meaning...|$|R
40|$|The study {{describes}} subordinators indicating temporal {{relations of}} equivalence and sequence {{in which their}} existence in compound-complex sentences are obligatory. The distribution method and its five techniques (<b>Immediate</b> <b>Constituent,</b> deletion, permutation, substitution, and expansion) are used to identify the types and distribution of the subordinators within the Indonesian sentences. The result shows that subordinators indicating equivalence of temporal relations are saat, ketika, waktu, sewaktu, kala, tatkala, selama, and selagi. Meanwhile, subordinators indicating sequence of temporal relations are begitu, usai, sesuai, sesudah, selepas, and sehabis. The distribution of the two kinds of subordinators in the cimpound-complex sentences vary; they can be placed initially, medially after the main clause, and after subject of the main clause...|$|R
40|$|The author {{establishes}} {{all kinds}} of segment units on the plane of constituents (infrastructure, size level) and representation (infrastructure) which are compatible with the taxonomic model of language and grammar as that of German. On the latter plane there occurs a differentiation of system units ("emic" according to Pike) and their variants (units of an allo or "etic" type) and the author pays {{particular attention to the}} proper identification of free (facultative) variants. The author keeps himself away from establishing variants resulting not from the representation of <b>immediate</b> <b>constituents</b> of units, but from the projection of indirect constituents. The notion of variation is finally extended onto the language as a whole, including in to it considerations on the subject of so called diacodes and language varieties...|$|R
5000|$|Most {{if not all}} {{theories}} of syntax acknowledge verb phrases (VPs), but they can diverge greatly {{in the types of}} verb phrases that they posit. Phrase structure grammars acknowledge both finite verb phrases and non-finite verb phrases as <b>constituents.</b> Dependency <b>grammars,</b> in contrast, acknowledge just non-finite verb phrases as constituents. The distinction is illustrated with the following examples: ...|$|R
40|$|An {{important}} assumption in Optimality Theory is parallelism, and {{a proper}} analysis of cyclic effects is crucial. I examine a typical case of cyclicity, namely, stress in Shanghai compounds, where {{the layers of}} embedding are in principle unlimited. I show that alignment constraints are inadequate. Instead, identity constraints are needed, in particular Stress-ID which requires that stress locations in the <b>immediate</b> <b>constituents</b> of a compound {{be the same as}} when the constituents occur alone. In addition, Stress-ID (and other constraints) must be checked recursively, namely, at every layer of syntactic bracketing. This analysis incorporates the essential properties of the cycle and can therefore handle all cyclic cases. Finally, I discuss the compatibility of recursive constraint evaluation with parallelism, and the remaining differences between a cyclic analysis and recursive constraint evaluation...|$|R
40|$|In {{order to}} be able to {{systematically}} link compounds in GermaNet to their constituent parts, compound splitting needs to be applied recursively and has to identify the <b>immediate</b> <b>constituents</b> at each level of analysis. Existing tools for compound splitting for German only offer an analysis of all component parts of a compound at once without any grouping of subconstituents. Thus, existing tools for splitting compounds were adapted to overcome this issue. Algorithms combining three heterogeneous kinds of compound splitters are developed to achieve better results. The best overall result with an accuracy of 92. 42 % is achieved by a hybrid combined compound splitter that takes into account all knowledge provided by the individual compound splitters, and in addition some domain knowledge about German derivation morphology and compounding. ...|$|R
50|$|An {{important}} aspect of phrase structure rules is that they view sentence structure from the top down. The category on {{the left of the}} arrow is a greater <b>constituent</b> and the <b>immediate</b> <b>constituents</b> {{to the right of the}} arrow are lesser constituents. Constituents are successively broken down into their parts as one moves down a list of phrase structure rules for a given sentence. This top-down view of sentence structure stands in contrast to much work done in modern theoretical syntax. In Minimalism for instance, sentence structure is generated from the bottom up. The operation Merge merges smaller constituents to create greater constituents until the greatest constituent (i.e. the sentence) is reached. In this regard, theoretical syntax abandoned phrase structure rules long ago, although their importance for computational linguistics seems to remain intact.|$|R
2500|$|In {{syntactic}} analysis, {{a constituent}} {{is a word}} {{or a group of}} words that function(s) as a single unit within a hierarchical structure. [...] The analysis of constituent structure is associated mainly with phrase structure grammars, although dependency grammars also allow sentence structure to be broken down into constituent parts. The constituent structure of sentences is identified using constituency tests. These tests manipulate some portion of a sentence and based on the result, clues are delivered about the <b>immediate</b> <b>constituent</b> structure of the sentence. Many constituents are phrases. A phrase is a sequence of one or more words (in some theories two or more) built around a head lexical item and working as a unit within a sentence. A word sequence is shown to be a phrase/constituent if it exhibits {{one or more of the}} behaviors discussed below.|$|R
40|$|This paper {{defends the}} view that the Faculty of Language is compositional, i. e., that it computes the meaning of complex {{expressions}} from the meanings of their <b>immediate</b> <b>constituents</b> and their structure. I fargue that compositionality and other competing constraints on {{the way in which the}} Faculty of Language computes the meanings of complex expressions should be understood as hypotheses about innate constraints of the Faculty of Language. I then argue that, unlike compositionality, most of the currently available non-compositional constraints predict incorrect patterns of early linguistic development. This supports {{the view that}} the Faculty of Language is com- positional. More generally, this paper presents a way of framing the compositionality debate (by focusing on its implications for language acquisition) that can lead to its even- tual resolution, so it will hopefully also interest theorists who disagree with its main conclusion...|$|R
