120|45|Public
50|$|Since {{the optical}} {{centers of the}} cameras lenses are distinct, each center {{projects}} onto a distinct point into the other camera's image plane. These two image points are denoted by eL and eR are called <b>epipoles</b> or epipolar points. Both <b>epipoles</b> eL and eR in their respective image planes and both optical centers OL and OR lie on a single 3D line.|$|E
5000|$|... #Caption: Example of epipolar geometry. This {{paragraph}} needs clarification as {{the content}} is not clear: {{if the two}} camera plane coincide then the two <b>epipoles</b> are undetermined as intersection of one optical center of one camera with the other camera plane is not a point but a line. Two cameras, with their respective centers of projection points OL and OR, observe a point P. The projection of P onto each of the image planes is denoted pL and pR. Points EL and ER are the <b>epipoles.</b>|$|E
50|$|Finally, we scale both {{images to}} the same {{approximate}} resolution and align the now horizontal <b>epipoles</b> for easier horizontal scanning for correspondences (row 4 of 2D image set).|$|E
40|$|Abstract. The {{position}} of the <b>epipole</b> (or focus of expansion), when a camera moves under pure translation, provides useful information {{in a range of}} computer vision applications. Here we present a robust method to estimate the <b>epipole,</b> which is based on the relation between the <b>epipole</b> and the fundamental matrix and which uses both a binning technique and random sample consensus (RANSAC). The required input data is only two uncalibrated images. No prior knowledge of either the parameters of the camera, or camera motion is required. Firstly, we use a linear method to get an initial estimate of the <b>epipole.</b> This is then used to initialise a non-linear optimization method, based on the minimization of the epipolar distance, in order to refine this estimate and yield a highly accurate <b>epipole.</b> Simultaneously, the method computes a highly accurate fundamental matrix. Extensive experimental results on real images and simulated data illustrate that the new method, which leads to an enormous improvement on the accuracy of the <b>epipole,</b> performs very well in terms of robustness to outliers and noises. ...|$|R
50|$|The {{fundamental}} matrix is of rank 2. Its kernel {{defines the}} <b>epipole.</b>|$|R
40|$|This paper {{presents}} a novel method {{for determining the}} location of the instantaneous <b>epipole</b> in a sequence of images acquired by an uncalibrated camera and containing a single, rigid motion (e. g., the camera moves in a static environment). The method uses the full perspective camera model and requires the estimation of the optical flow at a minimum of six image locations. The key observation is that the optical flow equations can be written in terms of the instantaneous <b>epipole</b> in a strikingly simple form if the translational and rotational flow components are not separated as done usually. The <b>epipole</b> location can then be obtained as the minimum of a least-square residual function associated to the computed optical flow. We report and discuss initial experiments on both synthetic and real data indicating the reliability of the method. 1 Introduction Finding the <b>epipole</b> is a useful starting point for uncalibrated reconstruction of motion and structure [2, 8, 9, 3]. In this paper we pr [...] ...|$|R
5000|$|... #Caption: Example of epipolar geometry. Two cameras, {{with their}} {{respective}} centers of projection points OL and OR, observe a point P. The projection of P onto {{each of the}} image planes is denoted pL and pR. Points EL and ER are the <b>epipoles.</b>|$|E
5000|$|Note {{that it is}} {{possible}} to perform this and similar algorithms without having the camera parameter matrices M and M' [...] All that is required is a set of seven or more image to image correspondences to compute the fundamental matrices and <b>epipoles.</b>|$|E
5000|$|In {{order to}} {{transform}} the original image pair into a rectified image pair, {{it is necessary to}} find a projective transformation H. Constraints are placed on H to satisfy the two properties above. For example, constraining the epipolar lines to be parallel with the horizontal axis means that <b>epipoles</b> must be mapped to the infinite point 1,0,0T in homogeneous coordinates. Even with these constraints, H still has four degrees of freedom. It is also necessary to find a matching H' [...] to rectify the second image of an image pair. Poor choices of H and H' [...] can result in rectified images that are dramatically changed in scale or severely distorted.|$|E
40|$|We present {{algorithms}} for {{estimating the}} <b>epipole</b> or direction of translation of a moving camera. We use constraints arising from two points that are antipodal {{on the image}} sphere in order to decouple rotation from translation. One pair of antipodal points constrains the <b>epipole</b> to lie on a plane, and two such pairs will correspondingly give two planes. The intersection of these two planes is {{an estimate of the}} <b>epipole.</b> This means we require image motion measurements at two pairs of antipodal points to obtain an estimate. Two classes of algorithms are possible and we present two simple yet extremely robust algorithms representative of each class. These are shown to have comparable accuracy with {{the state of the art}} when teste...|$|R
40|$|This paper {{presents}} {{a novel approach}} to uncalibrated view synthesis that overcomes the sensitivity to the <b>epipole</b> of existing methods. The approach follows a interpolate- then-derectify scheme, {{as opposed to the}} previous derectify- then-interpolate strategy. Both approaches generate a tra- jectory in an uncalibrated framework that is related to a specific Euclidean counterpart, but our method yields a warping map that is more resilient to errors in the estimate of the <b>epipole,</b> as it is confirmed by synthetic experiments...|$|R
40|$|This paper {{develops}} an algorithm for {{estimating the}} <b>epipole</b> or direction of translation of a moving monocular observer. To this end, we use constraints arising from two points that are antipodal {{on the image}} sphere. The antipodal point condition is necessary for decoupling rotation from translation. One such pair of points constrains the <b>epipole</b> to lie on a plane, and using two pairs of points, we have two such planes. The intersection of these two planes gives {{an estimate of the}} <b>epipole.</b> This means we require image motion measurements at two pairs of antipodal points to obtain an estimate. Repeating this will yield a set of possible solutions and a variety of methods could be applied to obtain a robust and refined estimate from this set. One robust and simple method is chosen for illustrative purposes and results on real images are shown. With real sequences, results of below 2 ◦ error in the estimate of the <b>epipole</b> can be obtained. Since antipodal points on an image sphere are required, this algorithm must use some kind of omnidirectional or large field-of-view (FOV) sensor. 1...|$|R
40|$|Abstract — A new {{image-based}} visual servoing, {{based on}} the epipolar geometry, is presented. The estimation of the <b>epipoles</b> position, obtained by points correspondences extracted from two different images, allows to control the hand-eye robotic system. The camera-robot motion is achieved from the observation of the <b>epipoles</b> coordinates. Experimental results are presented. I...|$|E
40|$|This paper {{presents}} an epipolar based visual servoing for mobile robots {{equipped with a}} panoramic camera. The proposed visual servoing {{is based on the}} epipolar geometry and exploits the auto-epipolar property, a special configuration for the <b>epipoles</b> which occurs when the desired and the current views undergo a pure translation. This occurrence is detectable observing when the bi-osculating mirror conics co-intersect at the two <b>epipoles.</b> The auto epipolar condition enables our controller to retrieve the equal orientation between target and current camera. Translation is performed by exploiting the <b>epipoles.</b> Simulated experiments and Lyapunov-based stability analysis demonstrate the parametric robustness of the proposed method...|$|E
40|$|We {{present a}} {{geometric}} approach {{for the analysis}} of dynamic scenes containing multiple rigidly moving objects seen in two perspective views. Our approach exploits the algebraic and geometric properties of the so-called multibody epipolar constraint and its associated multibody fundamental matrix, which are natural generalizations of the epipolar constraint and of the fundamental matrix to multiple moving objects. We derive a rank constraint on the image points from which one can estimate the number of independent motions and linearly solve for the multibody fundamental matrix. We prove that the <b>epipoles</b> of each independent motion lie exactly in the intersection of the left null space of the multibody fundamental matrix with the so-called Veronese surface. We then show that individual <b>epipoles</b> and epipolar lines can be uniformly and efficiently computed by using a novel polynomial factorization technique. Given the <b>epipoles</b> and epipolar lines, the estimation of individual fundamental matrices becomes a linear problem. Then, motion and feature point segmentation is automatically obtained from either the <b>epipoles</b> and epipolar lines or the individual fundamental matrices. We test the proposed approach by segmenting a real sequence...|$|E
50|$|In Greek mythology, <b>Epipole</b> was a {{daughter}} of Trachion, of Carystus in Euboea. In the disguise of a man she went with the Greeks against Troy. But when Palamedes discovered her sex, she was stoned to death by the Greek army.|$|R
50|$|As an {{alternative}} visualization, consider the points X, OL & OR that form a plane called the epipolar plane. The epipolar plane intersects each camera's image plane where it forms lines—the epipolar lines. All epipolar planes and epipolar lines intersect the <b>epipole</b> {{regardless of where}} X is located.|$|R
2500|$|... 13th century BC – Estimated {{time period}} of the Trojan War. According to ancient sources, several women {{participate}} in battle. See [...] for more information. The Trojan war {{is one of the}} first alleged instances of women cross-dressing as men to fight, as is in the case of <b>Epipole</b> of Carystus.|$|R
40|$|In this paper, {{we propose}} a new {{approach}} to camera calibration from silhouettes under circular motion with minimal data. We exploit the mirror symmetry property and derive a common homography that relates silhouettes with <b>epipoles</b> under circular motion. With the <b>epipoles</b> determined, the homography can be computed from the frontier points induced by epipolar tangencies. On the other hand, given the homography, the <b>epipoles</b> can be located directly from the bi-tangent lines of silhouettes. With the homography recovered, the image invariants under circular motion and camera parameters can be determined. If the <b>epipoles</b> are not available, camera parameters can be determined by a low-dimensional search of the optimal homography in a bounded region. In the degenerate case, when the camera optical axes intersect at one point, we derive a closed-form solution for the focal length to solve the problem. By using the proposed algorithm, we can achieve camera calibration simply from silhouettes of three images captured under circular motion. Experimental results on synthetic and real images are presented to show its performance. 1...|$|E
40|$|In {{this paper}} {{we present a}} unified {{approach}} of decomposing the fundamental and the essential matrix using information about <b>epipoles.</b> In contrast to other methods our approach is based on Householder transformations and can deal with finite and infinite <b>epipoles.</b> Our decomposition is able to yield a minimal parametrization of the fundamental and the essential matrix and retains their characteristic properties. We give a geometrical interpretation and relate our approach to the singular value decomposition and to the epipolar line homography. Experiments show that our parametrization {{can be used as}} an alternative to existing ones in terms of speed and accuracy. Moreover, if <b>epipoles</b> are known a priori, our approach reduces the number of remaining parameters for determining the epipolar geometry of two images. ...|$|E
40|$|This paper {{proposes a}} new {{reactive}} method of avoiding dynamic obstacles by real-time optimization. A mobile robot {{is equipped with}} a monocular camera and dynamic obstacles are identified in the image sequence by clustering the optical flow. The respective <b>epipoles</b> of the clusters are determined and afterwards the relative epipole positions are evaluated to identify colliding and dangerous objects. In this work the correlation between the vehicle's velocities and the cluster <b>epipoles</b> is derived and utilized in the proposed cost function for shifting the <b>epipoles.</b> By optimizing this cost function the vehicle is able to avoid collisions, which means that the 3 D motion is deduced from purely 2 D image data. Finally, the validity of the concept is confirmed by hardware-in-the-loop simulations...|$|E
40|$|This paper {{reports a}} closed-form {{solution}} for reconstructing a scene {{up to an}} affine transformation from a single image {{in the presence of}} a symmetry plane. Unlike scene reconstruction in stereo vision, the affine reconstruction process discussed in this paper does not require any knowledge about camera parameters or camera orientation relative to the scene, so camera self-calibration is totally eliminated. By setting in the scene a plane mirror which creates lateral symmetric world points for an uncalibrated, perspective camera to capture, the linear equations involved in the reconstruction process can be derived from two sets of similar triangles. The affine reconstruction is relative to an arbitrary affine coordinated frame implicitly defined on the mirror plane. Also involved in the process are the estimation of the <b>epipole</b> and recovery of the image-to-mirror plane homography. Implementation on estimating the <b>epipole</b> is detailed. A real experiment is presented to demonstrate the reconstruction...|$|R
40|$|An {{accurate}} {{estimate of}} the <b>epipole</b> (direction of camera translation) is necessary if image motion is to be decomposed into rotational and translational components, which give the camera rotation and feature depths respectively. In this paper we introduce the Linearised Subspace Method to find direct constraints on the <b>epipole</b> which are independent of camera rotation and scene structure. We present methods to compute reliable constraints and their uncertainties from image motion. We show how erroneous constraints due to errors in tracking can be rejected and how the valid constraints should be combined to form accurate estimates of the direction of translation. Experimental results show these methods lead to improvements in the recovery of camera motion and that the uncertainty estimates are accurate and useful in detecting degenerate scene structure or camera motions. 1 Introduction In the structure from motion problem image motion is used to recover unknown camera motion and scene [...] ...|$|R
40|$|Initial {{attempts}} to grow skin and its cellular components {{centered on the}} use of organ cultures and explants cultures, where whole pieces of skin were kept alive and growth was confined to the <b>epipole</b> around the piece or onto the plastic around the explants. These cultures have a short life span and limited applications, as mixed cultures of keratinocytes, melanocytes, Langerhans cells, fibroblasts, Merkel’s cells...|$|R
40|$|This paper {{proposes a}} visual servoing {{algorithm}} for hand-eye robotic {{system based on}} epipolar geometry. The control law {{is based on the}} estimation of the <b>epipoles</b> position obtained by points correspondences extracted from the current and target images. The camera-robot motion is computed from the observation of the <b>epipoles</b> coordinates. Only the principal camera point is assumed to be known but not the other intrinsic parameters. Experimental results are reported to validate the visual servoing algorithm proposed...|$|E
40|$|Finding <b>epipoles</b> of a {{sequence}} of images {{has been an important}} topic of considerable research in the field of computer vision. Epipole is the main feature in epipolar geometry which has enormous demand in computer vision. In most of the cases epipole is estimated from two images and the images are taken by two stationary cameras or by one stationary camera from two different locations. But if the images are taken from a moving camera, the constraints of images are changed and finding <b>epipoles</b> becomes very difficult. A better performance can be achieved by capturing {{a sequence}} of images for a small translation of the camera in pure forward direction then the epipole can be found for each image. The implementation of our technique deals with the estimation of <b>epipoles</b> for {{a sequence of}} images for the pure forward moving camera...|$|E
40|$|The three {{best known}} {{criteria}} in two-view motion analysis ' are based, respectively, on the distances between points' and their corresponding epipolar lines, on the gradientweighted epipolar errors', {{and on the}} distances between points' and the reprojections of their reconstructed points'. The last one has a better statistical interpretation, but is', however, much slower than the first two. In this paper, we show that the last two criteria are equivalent when the <b>epipoles</b> are at infinity, and differ from each other only a little even when the <b>epipoles</b> are in the image. The first two criteria are equivalent only when the <b>epipoles</b> are at infinity and when the observed object has the same scale in the two images. This suggests' that the second criterion is sufficient in practice because of its' computational efficiency. The result is valid for both calibrated and uncalibrated images...|$|E
40|$|A {{higher order}} scheme is {{presented}} for the optimal correction method of Kanatani [5] for triangulation from two views and is {{compared with the}} method of Hartley and Sturm [3]. It is {{pointed out that the}} <b>epipole</b> is a singularity of the Hartley-Sturm method, while the proposed method has no singularity. Numerical simulation confirms that both compute identical solutions at other points. However, the proposed method is significantly faster. ...|$|R
40|$|Abstract. A {{higher order}} scheme is {{presented}} for the optimal correction method previously {{proposed by the}} authors for computing the 3 -D position of corresponding points in a stereo image pair, and this method is compared with the Hartley-Sturm method. It is {{pointed out that the}} <b>epipole</b> is a singularity of the Harley-Sturm method, while the our method has no singularity. It is confirmed by numerical simulation that both compute identical solutions at other points. It can be shown, however, that our method is significantly faster. 1...|$|R
40|$|We {{present a}} purely {{rotational}} visual servoing algorithm which aligns the orientation between two cameras at different locations in space. Specifically, our kinematic controller steers {{a set of}} so-called bi-tangent lines to intersect at the <b>epipole</b> using a purely image-based bi-tangent line Jacobian. Bi-tangent lines, i. e. lines joining corresponding features on the superposition of two views of a scene, can be defined for both points and contours, so we apply our controller to both feature types. Simulated experiments demonstrate the parametric robustness of the proposed method...|$|R
40|$|Abstract. In {{this paper}} we present an {{algorithm}} that estimates dense planar-parallax motion from multiple uncalibrated {{views of a}} 3 D scene. This generalizes the + parallax &quot; recovery methods to more than two frames. The parallax motion of pixels across multiple frames (relative to a planar surface) {{is related to the}} 3 D scene structure and the camera <b>epipoles.</b> The parallax eld, the <b>epipoles,</b> and the 3 D scene structure are estimated directly from image brightness variations across multiple frames, without pre-computing correspondences. ...|$|E
40|$|Abstract—In this paper, {{we present}} an {{algorithm}} that estimates dense planarparallax motion from multiple uncalibrated {{views of a}} 3 D scene. This generalizes the “plane+parallax ” recovery methods to more than two frames. The parallax motion of pixels across multiple frames (relative to a planar surface) {{is related to the}} 3 D scene structure and the camera <b>epipoles.</b> The parallax field, the <b>epipoles,</b> and the 3 D scene structure are estimated directly from image brightness variations across multiple frames, without precomputing correspondences. Index Terms—Plane+parallax, direct (gradient-based) methods, multiframe analysis, correspondence estimation, structure from motion. ...|$|E
40|$|This paper {{addresses}} {{the problem of}} motion recovery from image profiles, in the important case of turntable sequences. No correspondences between points or lines are used. Symmetry properties of surfaces of revolution are exploited to obtain, in a robust and simple way, {{the image of the}} rotation axis of the sequence and the homography relating epipolar lines. These, together with geometric constraints for images of rotating objects, are used to obtain <b>epipoles</b> and, consequently, the full epipolar geometry of the camera system. This sequential approach (image of rotation axis [...] - homography [...] - <b>epipoles)</b> avoids many of the problems usually found in other algorithms for motion recovery from profiles. In particular, the search for the <b>epipoles,</b> by far the most critical step for the estimation of the epipolar geometry, is carried out as a one-dimensional optimization problem, with a smooth unimodal cost function. The initialization of the parameters is trivial in all three stages of the [...] ...|$|E
40|$|Abstract. Suppose {{that two}} {{perspective}} views of four world points are given, that the intrinsic parameters are known, but the camera poses {{and the world}} point positions are not. We prove that the <b>epipole</b> in each view is then constrained to lie on a curve of degree ten. We give the equation for the curve and establish many of the curve’s properties. For example, we show that the curve has four branches through each of the image points {{and that it has}} four additional points on each conic of the pencil of conics through the four image points. We show how to compute the four curve points on each conic in closed form. We show that orientation constraints allow only parts of the curve and find that there are impossible configurations of four corresponding point pairs. We give a novel algorithm that solves for the essential matrix given three corresponding points and one <b>epipole.</b> We then use the theory to describe a solution, using a 1 -parameter search, to the notoriously difficult problem of solving for the pose of three views given four corresponding points. ⋆ ⋆ Prepared through collaborative participation in the Robotics Consortium sponsored by the U. S. Army Research Laborator...|$|R
40|$|This demo {{addresses}} {{the following two}} problems: (i) self-calibration of a moving camera observing a 3 D scene composed by planar structures; (ii) the scene segmentation and reconstruction. For tackling them, we propose an iterative linear algorithm exploiting the constraints induced by planarity in the scene. Instead of solving a non-linear or a complex multi-linear problem, we solve iteratively several linear problems: coplanar features segmentation, planar projective transferring, <b>epipole</b> computation, all plane intersections and calibration. Linear methods allow our approach to be suitable for real-time localization and 3 D reconstruction. 1. Overview In this demo, we propose an iterative algorithm exploiting projective constraints induced by planarity in the scene. Our approach allows us to deal with calibration, localization and reconstruction problems using only linear systems of equations, instead of solving non-linear problems with the corresponding dependency on the initial parameters guess. All the homographies are rewritten on a multi-linear form using a reference homography, the first <b>epipole</b> and the vectors that describe the intersections (at the key frame) between the reference plane and any other plane, a similar idea as in [1] but avoiding instability due to the explicit epipolar geometry computation. Consequently, three linear systems are presented in order to recover those parameters and to improve them iteratively. This stage {{is at the core}} of our method and assures projective coherence between all the homographies...|$|R
40|$|International audienceA {{new method}} is {{developed}} to estimate fundamental matrix (F matrix). We first find two parameters in the 8 -parameter F model {{by the new}} constraint developed in this paper, the two parameters are the affine coordinates of an <b>epipole.</b> Then we obtain the rest 6 parameters by solving a set of linear equations. Finally, our method is tested with many real images and compared with the 8 -point method and some iterative algorithms, {{the results show that}} our method has many advantages, such as the obvious geometrical meaning, the fewer matching pairs needed for calculation and high accuracy F matrice...|$|R
