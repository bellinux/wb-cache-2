0|4725|Public
50|$|The <b>Sense</b> <b>Apparatus</b> is {{the first}} album by Frantic Bleep.|$|R
5000|$|Electronic {{components:}} relays, switches, connectors, micro sensing devices, MEMS sensors, <b>image</b> <b>sensing</b> technologies ...|$|R
40|$|A {{system for}} {{measuring}} momentum flux in a turbulently flowing fluid includes: a <b>sensing</b> <b>apparatus</b> for dynamically <b>sensing</b> the mainstream and the cross velocity {{components of the}} fluid, a transducer operative to provide two electrical output signals representative of the velocity components in the mainstream and in the cross direction, and signal processors to derive the Reynolds stress wave and the Reynolds stress...|$|R
40|$|A {{chemical}} <b>sensing</b> <b>apparatus</b> {{and method}} {{for the detection}} of sub parts-per-trillion concentrations of molecules in a sample by optimizing electron utilization in the formation of negative ions is provided. A variety of media may be sampled including air, seawater, dry sediment, or undersea sediment. An electrostatic mirror is used to reduce the kinetic energy of an electron beam to zero or near-zero kinetic energy...|$|R
40|$|Pictorial {{communication}} systems use synthesized pictures, rather than text, {{to communicate with}} users. Because such systems depend on images to convey meanings, {{it is critical to}} understand how a human user perceives the <b>image</b> meaning (<b>sense).</b> This paper offers an empirical and theoretical study of how humans perceive <b>image</b> <b>senses.</b> We conduct a user study with 113 users to elicit their perceived <b>senses</b> on 400 <b>image</b> sets, from which we discover widespread <b>image</b> <b>sense</b> ambiguities. We examine how the number of images shown relates to sense ambiguity and discover several significant patterns. We then propose a Bayesian model to explain human image perception behaviors, based on a novel random walk process on a WordNet-like sense hierarchy. Our model makes qualitative and quantitative predictions that largely agree with our observations of human perception. It can explain the ?basic level? phenomenon known in psychology, and suggests a method for <b>image</b> <b>sense</b> disambiguation in pictorial {{communication systems}}...|$|R
40|$|Verification of {{computer}} vision theories is {{facilitated by the}} development and implementation {{of computer}} simulation systems. Computer simulation avoids the necessity of building actual systems; they are fast, flexible, and can be easily duplicated for use by others. Development and implementation of computational models in computer vision are both interesting and challenging. It involves research in diverse areas and requires integration of both science and technology. This dissertation addresses the computer modeling and simulation techniques for two computer vision problems: object recognition and <b>image</b> <b>sensing</b> process. <b>Image</b> <b>sensing</b> process investigates how an <b>image</b> is <b>sensed</b> by specifying the input characteristics of the object and the imaging devices, [...] ...|$|R
40|$|A {{system is}} {{described}} for measuring fluid velocity in a turbulently flowing fluid including a <b>sensing</b> <b>apparatus</b> for dynamically <b>sensing</b> the mainstream and two orthogonal cross velocity {{components of the}} fluid. A transducer operative is included to provide three electrical output signals representative of the velocity components in the mainstream, and in the cross directions. Signal processors can be utilized to derive the Reynolds stress wave and the Reynolds stress...|$|R
40|$|We {{describe}} an unusual data set {{of thousands of}} annotated <b>images</b> with interesting <b>sense</b> phenomena. Natural language <b>image</b> <b>sense</b> annotation involves increased semantic complexities compared to disambiguating word senses when annotating text. These issues are discussed and illustrated, including the distinction between word senses and iconographic senses. ...|$|R
40|$|We discuss <b>Image</b> <b>Sense</b> Discrimination (ISD), {{and apply}} a method based on {{spectral}} clustering, using multimodal features from {{the image and}} text of the embedding web page. We evaluate our method on a new data set of annotated web images, retrieved with ambiguous query terms. Experiments investigate different levels of sense granularity, {{as well as the}} impact of text and image features, and global versus local text features. 1 Introduction and problem clarification Semantics extends beyond words. We focus on <b>image</b> <b>sense</b> discrimination (ISD) 1 for web image...|$|R
5000|$|In 2013, {{he won the}} ACM Mobile Systems, Applications and Services (MobiSys) Best Paper Award for {{his paper}} “Energy Characterization and Optimization of <b>Image</b> <b>Sensing</b> Toward Continuous Mobile Vision” ...|$|R
40|$|NOVELTY - The {{apparatus}} has {{a temperature}} sensor fixed with a photovoltaic (PV) cell. A controller is {{coupled with the}} PV cell. The temperature sensor determines PV current, PV voltage and temperature of the PV cell. The temperature sensor detects presence of irradiance at the PV cell based on PV current and PV voltage. The controller comprises a neural network algorithm. A voltage determination circuit is coupled between the PV cell and the controller. The voltage determination circuit {{is equipped with a}} test resistor. The test resistor is coupled with output terminals of the PV cell [...] . USE - Solar irradiance <b>sensing</b> <b>apparatus</b> for a PV array system and a PV power plant [...] . ADVANTAGE - The apparatus improves efficiency of a PV power plant. The apparatus has simple structure, better sensing accuracy and low manufacturing cost. The apparatus effectively avoids need of a solar irradiance equipment [...] . DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a PV array maximum power point tracking (MPPT) method [...] . DESCRIPTION OF DRAWING(S) - The drawing shows a graphical view illustrating relationship between current and voltage of a solar irradiance <b>sensing</b> <b>apparatus</b> [...] ...|$|R
5000|$|Remotely <b>sensed</b> <b>image</b> analysis: Object {{detection}} from remotely <b>sensed</b> <b>images</b> ...|$|R
40|$|<b>Image</b> <b>sensing</b> at a {{small scale}} is {{essentially}} important in many fields, including microsample observation, defect inspection, material characterization and so on. However, nowadays, multi-directional micro object imaging is still very challenging due to the limited field of view (FOV) of microscopes. This paper reports a novel approach for multi-directional <b>image</b> <b>sensing</b> in microscopes by developing a rotatable robot. First, a robot with endless rotation ability is designed and integrated with the microscope. Then, the micro object is aligned to the rotation axis of the robot automatically based on the proposed forward-backward alignment strategy. After that, multi-directional images of the sample {{can be obtained by}} rotating the robot within one revolution under the microscope. To demonstrate the versatility of this approach, we view various types of micro samples from multiple directions in both optical microscopy and scanning electron microscopy, and panoramic images of the samples are processed as well. The proposed method paves a new way for the microscopy <b>image</b> <b>sensing,</b> and we believe it could have significant impact in many fields, especially for sample detection, manipulation and characterization {{at a small}} scale...|$|R
50|$|Humans {{perceive}} {{a lot of}} information about the three-dimensional structure in their environment by moving through it. When the observer moves and the objects around the observer move, information is obtained from <b>images</b> <b>sensed</b> over time.|$|R
40|$|Two-dimensional passive {{photodiode}} matrices {{are hardly}} useful for <b>image</b> <b>sensing</b> {{due to the}} crosstalk between pixels. This crosstalk {{makes it difficult to}} recover information from individual pixels. A switching unit attached to each sensing unit has been the common solution in image sensors (such as in CMOS sensors and in TFT-PiN a-Si photosensors). A novel organic photodiode with voltage-switchable photosensitivity was developed recently. Passive photodiode matrices made with such organic photodiodes can be used for <b>image</b> <b>sensing</b> applications. This circuit simulation study demonstrates an effective scheme to extract images from passive photodiode matrices, concluding that individual photodiode parameters determine the contrast and resolution of N by M image sensors...|$|R
40|$|We {{consider}} a general <b>image</b> <b>sensing</b> framework that includes many quantum sensing problems by an appropriate choice of image set, prior probabilities, and cost function. For any such problem, {{in the presence}} of loss and a signal energy constraint, we show that a pure input state of light with the signal modes in a mixture of number states minimizes the cost among all ancilla-assisted parallel strategies. Lossy binary phase discrimination with a peak photon number constraint and general lossless <b>image</b> <b>sensing</b> are considered as examples. Comment: 6 pages, 3 figures. The supplementary material is provided as an appendix. The content {{is the same as the}} published versio...|$|R
40|$|In {{this work}} a {{wearable}} gesture sensing device {{consisting of a}} textile strain sensor, using elastic conductive webbing, was designed for monitoring the flexion angle of elbow and knee movements. The elastic conductive webbing shows a linear response {{of resistance to the}} flexion angle. The wearable gesture sensing device was calibrated and then the flexion angle-resistance equation was established using an assembled gesture <b>sensing</b> <b>apparatus</b> with a variable resistor and a protractor. The proposed device successfully monitored the flexion angle during elbow and knee movements...|$|R
40|$|Inspired {{by recent}} {{development}} of artificial satellite, remote <b>sensing</b> <b>images</b> have attracted extensive attention. Recently, noticeable {{progress has been}} made in scene classification and target detection. However, it is still not clear how to describe the remote <b>sensing</b> <b>image</b> content with accurate and concise sentences. In this paper, we investigate to describe the remote <b>sensing</b> <b>images</b> with accurate and flexible sentences. First, some annotated instructions are presented to better describe the remote <b>sensing</b> <b>images</b> considering the special characteristics of remote <b>sensing</b> <b>images.</b> Second, in order to exhaustively exploit the contents of remote <b>sensing</b> <b>images,</b> a large-scale aerial image data set is constructed for remote <b>sensing</b> <b>image</b> caption. Finally, a comprehensive review is presented on the proposed data set to fully advance the task of remote sensing caption. Extensive experiments on the proposed data set demonstrate that the content of the remote <b>sensing</b> <b>image</b> can be completely described by generating language descriptions. The data set is available at [URL] 14 pages, 8 figure...|$|R
40|$|A high {{temperature}} pressure transducer and <b>sensing</b> <b>apparatus</b> {{to determine the}} deflection of the transducer diaphragm is disclosed. The pressure transducer utilizes a fused silica diaphragm (12) which is illuminated at selected locations by a coherent laser source (52) via optical fibers (38, 46). The light reflected by the diaphragm (12) forms interference fringe patterns which are focused by gradient index rod lenses (36) {{on the ends of}} optical fibers (40, 48) for transmission to a fringe counting circuit (54). By digital techniques, the fringe count is converted into a determination of diaphragm deflection...|$|R
40|$|Abstract: Aiming at the correctness, {{quality and}} {{efficiency}} of remotely <b>sensed</b> <b>image</b> processing service composition for geospatial applications, a remotely <b>sensed</b> <b>image</b> processing service composition approach is proposed. It includes three main algorithm: (1) remotely <b>sensed</b> <b>image</b> processing service chaining based on heuristic search to composite services into a meaningful order; (2) knowledge navigated remotely <b>sensed</b> <b>image</b> processing service classification and selection, which using data mining to select an appropriate service for specific user requirement; (3) remotely <b>sensed</b> <b>image</b> processing service selection with response time to meet the response time requirement from user. ...|$|R
40|$|Based on the {{principle}} of remote <b>sensing</b> <b>image</b> classification, the paper roundly discusses most popular conservative methods of supervised classification and unsupervised classification of remote <b>sensing</b> <b>image,</b> and simply appraises their advantages, disadvantages, and suitable occasions. The newest methods of computerized remote <b>sensing</b> <b>image</b> classification are discussed with the attempt to bring out the trend of remote <b>sensing</b> <b>image</b> classification. In the end, this paper proposes a new classification method based on the multi-resolution hierarchy in order to have new breakthrough for the research of the classification method of remote <b>sensing</b> <b>image.</b> 1...|$|R
40|$|RedactorPublisherYokohamaThe ResearchA {{desire to}} develop a "quick-witted" {{artificial}} intelligence system based on <b>image</b> <b>sensing</b> technology Recognizing and understanding individuals under various situations by detecting and tracking their behavior Aiming to put the technologies into practical use in entertainment, fashion and medical field...|$|R
40|$|Because {{any trace}} on water {{seems to be}} {{immediately}} dissolved by currents, the seas have long been associated with a permanent present that resists any writing of history. The infinite liquid expanse has equally represented a challenge for governance: the impossibility of drawing stable boundaries in ever changing waters has led to consider the seas as a space of absolute freedom and flow – the “free seas”. In this article, we demonstrate that on the contrary, the seas are increasingly documented and divided, and inextricably so. A complex <b>sensing</b> <b>apparatus</b> is fundamental {{to a form of}} governance that combines the division of maritime spaces and the control of movement, and that instrumentalises the partial, overlapping, and “elastic” nature of maritime jurisdictions and international law. It is in these conditions that the EU imposed migration regime operates, selectively expanding sovereign rights through patrols in the high seas but also retracting from responsibility, as in the many instances of non-assistance to migrants at sea. Through the policies and the conditions of maritime governance organized by the EU the sea is turned into a deadly liquid – the direct cause of over 13. 000 documented deaths over the last fifteen years. However, by using the Mediterranean’s remote <b>sensing</b> <b>apparatus</b> against the grain and spatialising violations of migrants’ rights at sea, it is possible to re-inscribe responsibility into a sea of impunity...|$|R
40|$|One {{approach}} {{to gauge the}} complexity of the computational problem underlying haptic perception is to determine the number of dimensions needed to describe it. In vision, the number of dimensions can be estimated to be seven. This observation raises the question of what is the number of dimensions needed to describe touch. Only with certain simplified representations of mechanical interactions can this number be estimated, because it is in general infinite. Organisms must be sensitive to considerably reduced subsets of all possible measurements. These reductions are discussed by considering the <b>sensing</b> <b>apparatuses</b> of some animals and the underlying mechanisms of two haptic illusions...|$|R
5000|$|One type of {{granulation}} is the quantization of variables. It is {{very common}} that in data mining or machine-learning applications the resolution of variables needs to be decreased in order to extract meaningful regularities. An example {{of this would be}} a variable such as [...] "outside temperature" [...] (...) , which in a given application might be recorded to several decimal places of precision (depending on the <b>sensing</b> <b>apparatus).</b> However, for purposes of extracting relationships between [...] "outside temperature" [...] and, say, [...] "number of health-club applications" [...] (...) , it will generally be advantageous to quantize [...] "outside temperature" [...] into a smaller number of intervals.|$|R
50|$|A Micro DVR {{is a small}} {{form factor}} digital video {{recorder}} (DVR) such as a spy cam, lipstick cam, or helmet cam. It includes both <b>image</b> <b>sensing</b> and recording functions, and also includes either a USB port, a receptacle for a removable storage device, or both.|$|R
5000|$|The company {{launched}} publicly at PC Forum in 2002, announcing its CMOS-based single chip 3D <b>image</b> <b>sensing</b> technology {{using the}} Time of flight principle. Described as “electronic perception technology”, the company promotes its technology as enabling everyday machines and digital devices {{with the ability}} to “see.” ...|$|R
40|$|The {{bidirectional}} microdisplay approach combines organic {{light-emitting diode}} (OLED) image display and silicon complementary metal-oxide-semiconductor <b>image</b> <b>sensing</b> {{in a single}} chip. Its application in smart glasses might enable gaze-controlled interaction. This is to present a new bidirectional OLED microdisplay featuring super video graphics array resolution for both image display and acquisition...|$|R
40|$|As {{an attempt}} to {{introduce}} Interactive, Content Dependent Adaptive (ICDA) image processing a simple but powerful active <b>image</b> <b>sensing</b> and two image-enhancement methods are introduced via adaptive CNN-UM sensorcomputers. Thus the method ICDA {{can be used for}} adaptive control of <b>image</b> <b>sensing</b> and for subsequent on-line or offline image enhancement as well. The algorithms use both intensity and contrast content. The <b>image</b> <b>sensing</b> technology can be realized with the current CNN-UM chip [1],[2]. Our first image enhancement method is also executable on this chip, but it is more suitable for the Adaptive Cellular Neural Network Universal Machine (ACNN-UM) architecture [3]. Some results of simulator and chip experiments and an adaptive extended cell is presented. Our second, dynamical image enhancement method is planned to be executable on a multi-layer, complex cell CNN architecture [3]. In [15] a 3 -layer architecture is described which is capable to realize {{the main part of the}} second enhancement method. The main issues of our paper are as follows: the novel outlook of the ICDA framework, 3 new methods for two key application-area of CNN-UM, the notion of “regional ” adaptive computing, the novelty of application of equilibriumcomputing in the third method. However, the key novelty of our work is not just a new method and a new realization: by combining sensing and computing, dynamically and pixelwise, a new quality becomes practical. 1...|$|R
50|$|A {{vision chip}} is an {{integrated}} circuit having both <b>image</b> <b>sensing</b> circuitry and <b>image</b> processing circuitry {{on the same}} die. The <b>image</b> <b>sensing</b> circuitry may be implemented using charge-coupled devices, active pixel sensor circuits, or any other light <b>sensing</b> mechanism. The <b>image</b> processing circuitry may be implemented using analog, digital, or mixed signal (analog and digital) circuitry. One area of research {{is the use of}} neuromorphic engineering techniques to implement processing circuits inspired by biological neural systems. The output of a vision chip is generally a partially processed image or a high level information signal revealing something about the observed scene. Although there is no standard definition of a vision chip, the processing performed may comprise anything from processing individual pixel values to performing complex image processing functions and outputting a single value or yes/no signal based on the scene.|$|R
50|$|The Xperia XZ Premium is also {{backed up}} by Sonys Triple <b>Image</b> <b>Sensing</b> {{technology}} first introduced in the Xperia XZ, comprised by the <b>Image</b> <b>sensing</b> (CMOS sensor with PDAF), Distance sensing (Laser AF sensor) and Color sensing (RGBC-IR sensor) systems. It features a hybrid autofocus that utilizes Phase Detection (PDAF) to lock focus on a subject within 0.03 seconds, and also includes phase and contrast detection along with predictive motion tracking. Like the previous flagship, it has a laser autofocus sensor for tracking and locking focus on an object faster than regular autofocus modes alongside the RGBC-IR (RedGreenBlueClear-InfraRed) color sensor that assists the white balance function of the camera by providing additional data about the light conditions of the surrounding environment. It also has SteadyShot with Intelligent Auto {{in addition to the}} five-axis sensor-shift image stabilization first seen in the Xperia XZ.|$|R
5000|$|The {{rear camera}} of the Xperia XZ {{features}} a new multi-aspect 24.8MP Sony Exmor RS image sensor, officially named as Sony IMX300. Similar to the Xperia Z5 series, the Xperia X and Xperia X Performance, it has 23 megapixels with a sensor size of 1/2.3 {{inch and a}} f/2.0 aperture. Sony introduces the Triple <b>Image</b> <b>Sensing</b> technology with the Xperia XZ, comprised by the <b>Image</b> <b>sensing</b> (CMOS sensor with PDAF), Distance sensing (Laser AF sensor) and Color sensing (RGBC-IR sensor) systems. It features a hybrid autofocus that utilizes phase detection to lock focus on a subject within 0.03 seconds, also same with the Xperia Z5. It also includes phase and contrast detection along with predictive motion tracking, both working together to adjust {{the right amount of}} contrast accurately and significantly reduce blur and image shift caused by shaky hands.|$|R
5000|$|The Xperia XZs is also {{backed up}} by Sonys Triple <b>Image</b> <b>Sensing</b> {{technology}} first introduced in the Xperia XZ, comprised by the <b>Image</b> <b>sensing</b> (CMOS sensor with PDAF), Distance sensing (Laser AF sensor) and Color sensing (RGBC-IR sensor) systems. It features a hybrid autofocus that utilizes Phase Detection (PDAF) to lock focus on a subject within 0.03 seconds, and also includes phase and contrast detection along with predictive motion tracking. Like the previous flagship, it has a laser autofocus sensor for tracking and locking focus on an object faster than regular autofocus modes alongside the RGBC-IR (RedGreenBlueClear-InfraRed) color sensor that assists the white balance function of the camera by providing additional data about the light conditions of the surrounding environment. It also has SteadyShot with Intelligent Auto {{in addition to the}} five-axis sensor-shift image stabilization first seen in the Xperia XZ.|$|R
40|$|Land cover {{classification}} {{for high}} spatial resolution remote <b>sensing</b> <b>images</b> becomes a challenging work. The high spatial resolution remote <b>sensing</b> <b>images</b> have more spatial information. The low or medium resolution remote <b>sensing</b> <b>images</b> have more spectral information. In {{order to improve}} the accuracy of high spatial resolution remote <b>sensing</b> <b>image</b> classification, additional information should {{be incorporated into the}} classification process of high spatial resolution remote <b>sensing</b> <b>image.</b> This paper proposed a method of object-based land cover classification for high spatial resolution ALOS images combining the spectral information of TM images. First, the high spatial resolution ALOS panchromatic image was segmented by multi-resolution segmentation method. Second, the spectral features of segmented regions were extracted from multi-spectral ALOS image and TM image by spatial mapping mechanism. Third, the regions were classified by SVM classifier. Experimental results show that the classification method for high spatial resolution remote <b>sensing</b> <b>images</b> combining the TM spectral information based on the spatial mapping mechanism can make use of the spectral information both in high and low spatial resolution remote <b>sensing</b> <b>images</b> and improve classification accuracy...|$|R
40|$|The {{current and}} near-future {{state-of-the-art}} in visual simulation equipment technology {{is related to}} the requirements of the space shuttle visual system. <b>Image</b> source, <b>image</b> <b>sensing,</b> and displays are analyzed on a subsystem basis, and the principal conclusions are used in the formulation of a recommended baseline visual system. Perceptibility and visibility are also analyzed...|$|R
40|$|The {{data from}} remote <b>sensing</b> <b>images</b> {{are widely used}} for characterizing land use and land cover at present. With the {{increasing}} availability of very high resolution (VHR) remote <b>sensing</b> <b>images,</b> the remote <b>sensing</b> <b>image</b> classification {{becomes more and more}} important for information extraction. The VHR remote <b>sensing</b> <b>images</b> are rich in details, but high within-class variance as well as low between-class variance make the classification of ground cover a difficult task. What’s more, some related studies show that the quality of VHR remote <b>sensing</b> <b>images</b> also has a great influence on the ability of the automatic image classification. Therefore, the research that how to select the appropriate VHR remote <b>sensing</b> <b>images</b> to meet the application of classification is of great significance. In this context, the factors of VHR remote <b>sensing</b> <b>image</b> classification ability are discussed and some indices are selected for describing the image quality and the image classification ability objectively. Then, we explore the relationship of the indices of image quality and image classification ability under a specific classification framework. The results of the experiments show that these image quality indices are not effective for indicating the image classification ability directly. However, according to the image quality metrics, we can still propose some suggestion for the application of classification...|$|R
