28|10000|Public
5000|$|... 1. <b>Definition</b> <b>of</b> <b>default</b> in the {{original}} prospectus for Argentina’s 2005 debt exchange: ...|$|E
50|$|Since Java 8, Java has {{a similar}} feature called default methods, which are methods with a body {{declared}} on interfaces. As opposed to C# extension methods, Java default methods are instance methods on the interface that declare them. <b>Definition</b> <b>of</b> <b>default</b> methods in classes that implement the interface is optional: If the class does not define the method, the default definition is used instead.|$|E
40|$|A {{retail bank}} {{consumer}} loan dataset {{is used to}} develop logistic regression based scoring functions with different definitions of default from a very broad to a narrow or hard. The performance of the scoring functions is compared {{with respect to the}} hard <b>definition</b> <b>of</b> <b>default</b> which indicates real losses suffered by the bank. The results confirm the hypothesis that the scoring functions developed on softer definitions of default perform worse than those developed on harder definitions of default. The conclusion is put into contrast with the observation that the Basel II regulation gives an incentive to use a rather soft <b>definition</b> <b>of</b> <b>default</b> in the rating and scoring process. credit risk, regulatory capital, default, scoring...|$|E
30|$|See Grunert and Volk (2008) {{regarding}} the influence <b>of</b> the <b>definition</b> <b>of</b> a <b>default</b> event when determining the recovery rate.|$|R
40|$|We study {{probabilistically}} informative (weak) {{versions of}} transitivity by using suitable <b>definitions</b> <b>of</b> <b>defaults</b> and negated defaults {{in the setting}} of coherence and imprecise probabilities. We represent p-consistent sequences <b>of</b> <b>defaults</b> and/or negated defaults by g-coherent imprecise probability assessments on the respective sequences of conditional events. Moreover, we prove the coherent probability propagation rules for Weak Transitivity and the validity of selected inference patterns by proving p-entailment of the associated knowledge bases. Finally, we apply our results to study selected probabilistic versions of classical categorical syllogisms and construct {{a new version of the}} square of opposition in terms <b>of</b> <b>defaults</b> and negated defaults...|$|R
40|$|AbstractThe paper {{examines}} the <b>definitions</b> <b>of</b> open <b>default</b> theories {{known from the}} literature. First it is shown {{that none of them}} is satisfactory either for formal or for intuitive reasons. Next a new approach is considered. It is free from the obvious deficiencies <b>of</b> the known <b>definitions,</b> but possesses their positive properties...|$|R
40|$|The "recursive" <b>definition</b> <b>of</b> <b>Default</b> Logic {{is shown}} to be representable in a {{monotonic}} Modal Quantificational Logic whose modal laws are stronger than S 5. Specifically, it is proven that a set of sentences of First Order Logic is a fixed-point of the "recursive" fixed-point equation of Default Logic with an initial set of axioms and defaults {{if and only if}} the meaning of the fixed-point is logically equivalent to a particular modal functor of the meanings of that initial set of sentences and of the sentences in those defaults. This is important because the modal representation allows the use of powerful automatic deduction systems for Modal Logic and because unlike the original "recursive" <b>definition</b> <b>of</b> <b>Default</b> Logic, it is easily generalized to the case where quantified variables may be shared across the scope of the components of the defaults...|$|E
40|$|Reiter’s {{original}} <b>definition</b> <b>of</b> <b>default</b> logic {{allows for}} the application of a default that contradicts a previously applied one. We call failure this condition. The possibility of generating failures {{has been in the past}} considered as a semantical problem, and variants have been proposed to solve it. We show that it is instead a computationa...|$|E
40|$|Abstract: The "recursive " <b>definition</b> <b>of</b> <b>Default</b> Logic {{is shown}} to be representable in a {{monotonic}} Modal Quantificational Logic whose modal laws are stronger than S 5. Specifically, it is proven that a set of sentences of First Order Logic is a fixed-point of the "recursive " fixed-point equation of Default Logic with an initial set of axioms and defaults {{if and only if}} the meaning of the fixed-point is logically equivalent to a particular modal functor of the meanings of that initial set of sentences and of the sentences in those defaults. This is important because the modal representation allows the use of powerful automatic deduction systems for Modal Logic and because unlike the original "recursive " <b>definition</b> <b>of</b> <b>Default</b> Logic, it is easily generalized to the case where quantified variables may be shared across the scope of the components of the defaults...|$|E
40|$|There {{is a vast}} {{literature}} on default rules in the law of contract and commercial relations. The question explored here is whether “default rule thinking” can enlighten the theory or practice of constitutional law. The first part expresses skepticism. The very notion that public officials may change or override certain constitutional protections may seem simply incoherent as a view of constitutional law. The second part argues that despite reasons for skepticism, the idea must be pursued, because default rules are pervasive in constitutional law. This part provides a typology <b>of</b> constitutional <b>default</b> rules employed in judicial decisions, tracking roughly the categories and <b>definitions</b> <b>of</b> <b>defaults</b> commonly identified in the contracts literature. The final part provides a tangible example of how rigorous application <b>of</b> <b>default</b> rule thinking in the constitutional area can have normative payoff. Applying positive theory, the article explains how default rule thinking {{can be used to}} enhance the democratic pedigree of constitutional decisions...|$|R
40|$|One {{important}} defect <b>of</b> Reiter’s <b>default</b> {{logic is}} inability to reason by cases. To overcome the defect <b>definition</b> <b>of</b> Reiter’s extension. Roos presents a modified <b>definition</b> <b>of</b> a <b>default</b> extension that solves the problem. In this paper, {{we will discuss}} the properties of Roos-extension that similar to Reiter-extension, and will find some properties of Reiter-extension cannot still correct to Roos-extension. We point out the difference of them, and Roos-extension offers a new idea for inference of artificial intelligent, it can achieve a method to classify the information...|$|R
40|$|This paper {{examines}} the factors driving the equity-owner’s decision to terminate lending relationships with debt-holders through either prepaying or defaulting on their underlying debt obligations. Using loan level data, we estimate prepayment and default functions in a competing risks proportional hazard model which {{allows us to}} account for unobserved heterogeneity. Under a strict <b>definition</b> <b>of</b> mortgage <b>default</b> we do not find {{evidence to support the}} existence of unobserved heterogeneity. However, when the <b>definition</b> <b>of</b> mortgage <b>default</b> is relaxed, we do find weak evidence of two distinctive borrower groups. Our results suggest that the values of implicit put and call options drive default and prepayment actions in a non-linear and interactive fashion. Prepayment and default risks are found to be convex in the intrinsic value of call and put options, respectively. Consistent with the jointness of the two underlying options, high value of the put / call option is found to significantly reduce the call / put risk since the borrower forfeit...|$|R
40|$|Reiter's {{original}} <b>definition</b> <b>of</b> <b>default</b> logic {{allows for}} the application of a default that contradicts a previously applied one. We call failure this condition. The possibility of generating failures {{has been in the past}} considered as a semantical problem, and variants have been proposed to solve it. We show that it is instead a computational feature that is needed to encode some domains into default logic...|$|E
40|$|AbstractWhen {{building}} large specifications from requirements, {{the structure}} of the specification becomes a central problem: the specification language should allow a decomposition that closely reflects {{the structure of}} requirements. In this paper, we propose a decomposition into defaults (general rules) and exceptions to these general rules that fits the requirements found in some application domains. It is complementary, and builds upon, the modular decomposition proposed by the algebraic specification school. Its definition is based on abstract model theory, leading to the <b>definition</b> <b>of</b> <b>default</b> institutions...|$|E
30|$|A {{configuration}} file is handled {{with the aid}} of the libconfig++ library, where i. a. the default graphical extent of each Modelica component can be adjusted. It also allows the <b>definition</b> <b>of</b> <b>default</b> CIM datatype multipliers (e. g. M for MW in case of IEC 61970 ::Base::Domain::ActivePower) which are not defined in some CIM RDF/XML documents such as the ones from NEPLAN based on the ENTSO-E profile, specified by (ENTSO-E 2018). After these implementation details, in following subsections the main aspects of the overall implementation are presented.|$|E
3000|$|For the analysis, {{we first}} {{determine}} the recovery rate (RR j [...]) for every debtor j ∈(1, 2,..., 499). In our data set, the proceeds include the {{returns from the}} liquidation of any possible collateral {{as well as the}} payments made by the debtor. Costs include all external costs (e.g., costs for arbitration measures, the real estate agent’s commission fees, etc.). 9 Determining the EAD appears to be critical, since the exact time <b>of</b> the <b>default</b> event as well as the criteria for the default are not known. 10 Therefore, we use the <b>definition</b> <b>of</b> a <b>default</b> event specified under the Basel Accord. Following Basel Committee on Banking Supervision (2006), a loan is considered to be in default if the bank is selling the loan obligation and thereby accepting an economic loss. Due to the reduction in the selling price, selling a receivable to BAG always satisfies this definition. 11 Hence, we take the debtor’s existing liabilities at the time of transfer to BAG as the exposure at default (EAD). Using this <b>definition,</b> the difficulty <b>of</b> employing inconsistent <b>definitions</b> <b>of</b> a <b>default</b> event among the 123 included banks can be avoided.|$|R
40|$|The goal of our {{research}} is to highlight the connection between modal provability theory and default logic. Our work continues the research tradition in which <b>definitions</b> <b>of</b> extensions in <b>default</b> logic are related to modal systems. The main innovation {{is to try to}} get the most out of reflection results due to G 6 del and developed by Boolos, Smorynski, Bernardi, and Solovay...|$|R
40|$|We {{present a}} {{development}} of the theory <b>of</b> <b>default</b> information structures, combining ideas from domain theory with ideas from non-monotonic logic. Conceptually, our treatment ii distinguished from standard default logic in that we view default structures as generating models rather than theories. Reiter's default rules are viewed as non-deterministic algorithms for generating preferred partial models. Using domain-theoretical notions, we suggest a robust alternative to the standard <b>definition</b> <b>of</b> extensions in <b>default</b> logic, by introducing the notion of dilation. We prove {{the existence of such}} dilations for a new class <b>of</b> <b>default</b> information structures, called the class of rational structures, which properly includes the class of semi-normal structures. Keywordr. Default reasoning, domain theory, non-monotonicity. ...|$|R
40|$|AbstractThe McCain-Turner {{semantics}} of causal {{rules is}} based on a fixpoint construction similar to the one found in the <b>definition</b> <b>of</b> <b>default</b> logic. In the special case when the heads of the rules are literals, it can be equivalently expressed by a translation from sets of rules into sets of propositional formulas. We define a translation from causal logic into classical logic that characterizes the semantics of arbitrary causal rules, without any restrictions on their syntactic form. This translation suggests a way to extend the McCain-Turner logic to nonpropositional causal theories...|$|E
40|$|The aim of {{this work}} {{is to develop a}} {{suitable}} model that estimates a probability of default of client's loan. As estimation method was used a logistic regression and a probit regression and two definitions of default, 60 and 90 days overdue. The work describes the method of construction, estimation and testing of scoring models and a structure of dataset, which was used in the practical part. Firstly, it was created a theoretical model that was later confronted with estimates. Estimated models were compared by described statistics as McFadden R^ 2, the ability to diversify was investigated by the Lorenz curve and by the Gini coefficient. It was found that the logistic and the probit regressions have almost the same results, and that 90 days is preferable <b>definition</b> <b>of</b> <b>default</b> than 60 days...|$|E
40|$|We {{examine the}} effects of owner {{liability}} and non-accounting and financial accounting information on the probability of default as defined in Basel II in bank loan contracted by non listed firms. We model default as a function of owner liability and accounting and non-accounting information of non-listed firms, drawing on 43, 117 annual accounts of 16, 029 firms over a 7 -year period. Our estimations based on mixed logistic regressions with random parameters show that the predicted default probability of full-liability firms is 0. 72 times that of limited liability firms. The likelihood ratio test for omitted variables confirms the additional predictive ability of liability status over and above other non-accounting and financial accounting information. A Heckman self-selection model does not indicate sampling bias. The particular <b>definition</b> <b>of</b> <b>default</b> used in the study enables the findings to be generalizable across other institutional contexts...|$|E
50|$|The US Pension Protection Act of 2006 {{included}} a provision which changed the <b>definition</b> <b>of</b> Qualified <b>Default</b> Investments (QDI) for retirement plans from stable value investments, money market funds, and cash investments to investments which expose {{an individual to}} appropriate levels of stock and bond risk based on the years left to retirement. The Act required that Plan Sponsors move the assets of individuals who had never actively elected their investments and had their contributions in the default investment option. This meant that individuals who had defaulted into a cash fund with little fluctuation or growth would soon have their account balances moved to much more aggressive investments.|$|R
40|$|In a {{traditional}} structural model <b>of</b> <b>default</b> it is implicitly {{assumed that the}} information used to calibrate and run the model is publicly available. In reality, model inputs and parameters are unobservable. In this article we analyze the role of information in structural models, which we specify through a model <b>definition</b> <b>of</b> the <b>default</b> time and a model filtration. The model <b>definition</b> relates the <b>default</b> <b>of</b> a firm to its assets and liabilities. The model filtration describes the information of investors relative to the model definition. It parameterizes a family <b>of</b> <b>default</b> models for a given default time. An important situation is when the default is not observable {{with respect to the}} model filtration. Examples include models with incomplete information about firm assets and models with incomplete information about the liabilitydependent barrier that triggers default. Here the default time is typically totally inaccessible, as in the intensity-based, reduced-form models <b>of</b> <b>default.</b> In this case the model admits generalized reduced-form security pricing formulae in terms of the trend, which is the cumulative intensity. The trend can be explicitly characterized through the conditional default probability given the model filtration. If the trend is absolutely continuous with respect to the Lebesgue measure, then its density is the intensity and our formulae simplify to the classica...|$|R
40|$|This thesis {{explores the}} {{modelling}} for Internal Rating Based (IRB) of Credit Risk for Small and Medium Enterprises (SMEs) as required for implementation of Basel II Accord. There {{has been limited}} previous research for this important sector of the economy. There are two major approaches: Accounting Based and Merton Type, and these are compared. To make the comparison initially a small sample is considered and simulation is used to explore {{the use of the}} two approaches. The study indicates some of the limitation of analysis for both Accounting Based and Merton Type approaches, for example the issue of colinearity for the Accounting Based approach and lack of trading of SMEs’ equity affecting the Merton Type approach. A large sample is then investigated using standard Credit Scoring approaches for the Accounting Based modelling. Different <b>definitions</b> <b>of</b> <b>default</b> and distress are considered to overcome the problem of low number <b>of</b> <b>defaults.</b> These approaches are found to be viable. Merton Type model is then compared to benchmark models from the Accounting Based approach. The predictions are compared over differing time horizons. It is found that Merton Type models perform well within a limited period compared to the Accounting Base approach. Overall, credit scoring models demonstrated better performance when the sample group included a considerable number of ‘Bad’ firms or cutoff point was selected so that an acceptance rate was relatively low, otherwise model’s predictive accuracy would decline. Merton model presented better predictive accuracy with higher acceptance rates. Credit scoring models was able to give early signs <b>of</b> <b>default</b> year. In addition, one may take into consideration that if the company is going to decline credit quality or raise default probability this year, Merton type models can be helpful in adjusting credit rating. When considering a loan to a company, a bank wants to know the likelihood <b>default</b> for duration <b>of</b> loan. In this sense Merton models is only useful for a relatively short loan terms. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|The aim of {{the paper}} is to {{critically}} evaluate the regulatory principles of Basel II, based on credit risk modelling. The paper {{is based on the}} definition of credit risk, default and necessary literature research dealing with the topic. The Internal Rating-Based (IRB) approach for calculating the capital requirement to cover losses from credit risk is evaluated. Within this calculation it deals with the right choice of parameters of probability of default and loss given default for the calculation of risk-weighted assets and following setting of the capital requirement to cover credit risk. The <b>definition</b> <b>of</b> <b>default</b> was, in the calculation based on the model data, gradually tightening so that even claims whose loss given default equal to 0 % was identified as the default. It is evident from the calculations that the bank can control (to some degree), by using an appropriate choice of the <b>definition</b> <b>of</b> <b>default,</b> the amount of risk weight and the subsequent amount of capital requirement. The paper further analyses the key role of correlation in credit risk modelling. The calculations indicate in this case that the value of correlation may significantly affect the amount of capital required to cover the risk, i. e. the capital requirement. The IRB approach may not be the right measure for the allocation of capital in banks, because IRB outputs cannot be considered as an estimate of the actual economic capital. Finally the paper points to the pro-cyclical character of Basel II, because the risk parameters fluctuate in time with the economic cycle, as well as the actual capital requirements for credit risk. Cílem tohoto článku je kriticky zhodnotit regulační principy Basel II na základě modelování úvěrového rizika. Práce je založena na definici úvěrového rizika a potřebné rešerše zabývající se daným tématem. Na závěr práce poukazuje na pro-cyklický charakter Basel II, protože rizikové parametry kolísají v čase v závislosti na hospodářském cyklu, stejně jako na skutečných kapitálových požadavcích k úvěrovému riziku...|$|E
30|$|The {{deduction}} of n-PEC ini needs {{the information on}} experimental physico-chemical characteristics as well as preliminary data on environmental behaviour of the ENMs, i.e. information on the agglomeration behaviour, stability of the coating, and alteration of the ENMs, e.g. by oxidation or dissolution. For information {{on some of these}} endpoints, modified or even newly developed test guidelines and guidances, e.g. on agglomeration behaviour or dissolution rate, will be necessary. The {{deduction of}} n-PECini also needs information on the production volume {{as well as on the}} amount of the ENMs released in every life-cycle stage. Furthermore, it requires a specification of the volume of the initial compartment, e.g. the definition of a local or regional scenario. Finally, the <b>definition</b> <b>of</b> <b>default</b> models which is already applied for the exposure assessment of conventional chemicals, plant protection products and biocides is also considered for the derivation of n-PECini.|$|E
40|$|In {{this paper}} {{we present a}} terminological {{language}} which includes defaults, and a <b>definition</b> <b>of</b> <b>default</b> subsumption based {{on the notion of}} skeptical inheritance in default reasoning. Except for the inclusion of defaults the language is limited when compared to most terminological logics. However defaults are a necessary construct in many applications and we suggest that the language presented here is a useful tradeoff between different types of expressivity We present an algorithm for classifying new concepts into the default hierarchy representing the taxonomy, and in addition an algorithm for what we call default classification, suitable for interactive reasoning about individuals. We describe a diagnosis application which has been implemented using this language and reasoning mechanisms. We present an evaluation of the diagnosis application on the basis of comparison with 63 patient protocols. We conclude that the language presented is in fact adequate for the application presented here and hypothesize that it i. s interesting for a significant group of applications. ...|$|E
40|$|The {{study of}} {{different}} variants <b>of</b> <b>default</b> logic reveales not only differences but also properties they share. For example, {{there seems to}} be a close relationship between semi [...] monotonicity and the guaranteed existence of extensions. Likewise, formula [...] manipulating default logics tend to violate the property of cumulativity. The problem is that currently such properties must be established separately for each approach. This paper describes some steps towards the study of properties <b>of</b> classes <b>of</b> <b>default</b> logics by giving a rather general <b>definition</b> <b>of</b> what a <b>default</b> logic is. Essentially our approach is operational and restricts attention to purely formula [...] manipulating logics. We motivate our definition and demonstrate that it includes a variety of well [...] known default logics. Furthermore, we derive general results regarding the concepts of semi [...] monotonicity and cumulativity. As a benefit of the discussion we uncover that some design decisions <b>of</b> concrete <b>default</b> logics were not acc [...] ...|$|R
40|$|The Basel II Advanced Internal Ratings (AIRB) {{approach}} {{is compared to}} capital requirements set using an equilibrium structural credit risk model. Analysis shows the AIRB approach undercapitalizes credit risk relative to regulatory targets and allows wide variation in capital requirements for a given exposure owing to ambiguity in the <b>definitions</b> <b>of</b> loss given <b>default</b> and exposure at default. In contrast, the Foundation Internal Ratings Based (FIRB) approach may over-capitalize credit risk relative to supervisory objectives. It is unclear how Basel II will buttress financial sector stability as it specifies the weakest risk regulatory capital standard for large complex AIRB banks. ...|$|R
50|$|The {{return on}} {{domestically}} held short-dated government bonds is normally {{perceived as a}} good proxy for the risk free rate. In Business valuation the long-term yield on the US Treasury coupon bonds is generally accepted as the risk free rate of return. However, theoretically this is only correct {{if there is no}} perceived risk <b>of</b> <b>default</b> associated with the bond. Government bonds are conventionally considered to be relatively risk-free to a domestic holder of a government bond, because there is by <b>definition</b> no risk <b>of</b> <b>default</b> - the bond is a form of government obligation which is being discharged through the payment of another form of government obligation (i.e. the domestic currency). <b>Of</b> course, <b>default</b> on government debt does happen, so if in theory this is impossible, then this points out a deficiency of the theory. Another issue with this approach is that with coupon-bearing bonds, the investor does not know ex-ante what his return will be on the reinvested coupons (and hence the return cannot really be considered risk free).|$|R
40|$|In Reiter's default logic, the {{parameters}} of a default are treated as metavariables for ground terms. We propose an alternative definition of an extension for a default theory, which handles parameters as genuine object variables. The new form of default logic may be preferable when the domain closure assumption is not postulated. It stands in a particularly simple relation to circumscription. Like circumscription, it {{can be viewed as}} a syntactic transformation of formulas of higher order logic. 1 Introduction Default logic [Reiter, 1980] is one of the most expressive and most widely used nonmonotonic formalisms. In one respect, however, the main <b>definition</b> <b>of</b> <b>default</b> logic, that of an extension, is not entirely satisfactory. Recall that a default ff : fi 1; : : :; fi m =fl (1) is open if it contains free variables, and closed otherwise. The concept of an extension is defined in two steps: It is first introduced, by means of a fixpoint construction, for default theories without op [...] ...|$|E
40|$|The {{statistical}} techniques which {{cover the}} process of modeling and evaluating consumer credit risk have become widely accepted instruments in risk management. In contrast, we find only few and vague statements on how to define the default event, i. e. on the concrete circumstances {{that lead to the}} decision of identifying a certain credit as defaulted. Based on a large data set of individual payment histories this paper investigates a possible solution to this problem in the area of installment purchase. The proposed <b>definition</b> <b>of</b> <b>default</b> is based on the time due amounts are outstanding and the resulting profitability of the receivables portfolio. Furthermore, to assess the individual payment performance during the credit period, indicators for monitoring and forecasting default events are derived. The empirical results show that these indicators generate valuable information which can be used by the creditor to improve his credit and collection policy and hence, to improve cash flows and reduce bad debt loss...|$|E
40|$|The {{goal of the}} Basel II {{regulatory}} {{formula is}} to model the unexpected loss on a loan portfolio. The regulatory formula {{is based on an}} asymptotic portfolio unexpected default rate estimation that is multiplied by an estimate of the loss given default parameter. This simplification leads to a surprising phenomenon where the resulting regulatory capital depends on a <b>definition</b> <b>of</b> <b>default</b> that plays the role of a frontier between the unexpected default rate estimate and the LGD parameter, whose unexpected development is not modeled at all or is modeled only partially. We study the phenomenon in the context of single-factor models where default and loss given default are driven by one systematic factor and by one or more idiosyncratic factors. In this theoretical framework we propose and analyze a relatively simple remedy of the problem requiring that the LGD parameter be estimated as an appropriate quantile on the required probability level. credit risk, correlation, recovery rate, regulatory capital...|$|E
40|$|The Basel Committee's Revised Framework for Capital Measurement and Capital {{internal}} models to estimate probability <b>of</b> <b>default</b> (PD) when calculating the minimum capital requirement using the internal ratings-based approaches. Valid {{estimates of the}} PDs require a considerable amount <b>of</b> data and <b>default</b> observations. Basel II allows for banks to pool their data to overcome their data shortcomings {{and a number of}} international data pooling projects have emerged. Thus even international banks need more data to fulfil the requirements of Basel II. To the best of our knowledge, so far no study has compared the banks' capital requirements calculated on the basis of PDs estimated from single-country creditscoring models and multi-country credit-scoring models and accordingly no study has discussed the incentive structure this might create for banks pooling data. The {{purpose of this paper is}} to illustrate the consequences on the calculated capital requirements of pooling data for estimation of PD from several countries. We construct a hypothetical portfolio of loans to small and medium sized enterprises for a hypothetical bank operating in France, Italy and Spain. For this purpose we use real world data extracted from the pan-European Amadeus database provided by Bureau van Dijk. Using this data, the PDs are estimated on the basis of single-country creditscoring models and on the basis of multi-country credit-scoring models with pooled data from the three countries. The estimated PDs are then used to calculate the minimum capital requirements. The result shows that there might be incentives for cherry-picking, i. e. that banks are motivated to choose a certain method because it results in a lower capital requirement. The calculated capital requirements vary with up to 18 percent depending on the choice of method for the hypothetical bank. Calculated for the individual countries it varies up to 47 percent. The results are of particular interest for banks operating in several countries, which plan to pool data from the various countries in order to estimate PDs, maybe due to lack of a sufficient single-country database. They are equally interesting for banks planning to pool data with banks from other countries to make up for an insufficient database. Though our default definition is the same for the three countries and we have controlled for variables such as age, size, legal form and sector of each firm, we find quite large differences in terms of the resulting minimum capital requirements for the portfolio in each of the three countries, when the PDs are estimated using a singlecountry credit-scoring model compared to using multi-country credit-scoring models. We show that it is not enough for banks to apply similar <b>definitions</b> <b>of</b> <b>default</b> and similar accounting regimes in the countries. Banks and regulators should also have a careful look into the models, especially the factors that drive financial distress, when banks pool data...|$|R
40|$|It {{has been}} {{reported}} that many women referred to outpatient colposcopy clinics fail to attend for their appointments. The aim {{of this paper is to}} search the literature to assess the extent <b>of</b> <b>default</b> from colposcopy and to identify interventions, suitable for implementation within primary care, to reduce the proportion <b>of</b> women <b>defaulting.</b> Searches were performed on MEDLINE, PsychLIT, Bids and Cancerlit from 1986 to September 1997 using the terms colposcopy or cervical/Pap smear in association with default, non-attendance, adherence, patient compliance, treatment refusal, patient dropouts, attendance, barriers or intervention. The inclusion criteria for primary papers were that they contained data that enables the calculation <b>of</b> <b>default</b> rates for colposcopy or the results of interventions aimed at improving the default rates. Thirteen publications describing default rates and four describing interventions were included as primary papers. Combining the data from these studies suggests <b>default</b> rates <b>of</b> 3 %, 11 %, and 12 % for assessment/treatment visits, first review, and second review respectively. The intervention studies suggested a need to tailor the intervention to the population and the type of information to suit the individual. Varying <b>definitions</b> make comparison <b>of</b> <b>default</b> rates difficult, and the use of a crude non-attendance rate may result in an overestimate <b>of</b> <b>default</b> rates. The vast majority of women invited to colposcopy eventually attend. It is questionable if there is a need for interventions to increase compliance. Where necessary, greater cooperation across the primary/secondary care interface and use of the extended primary care team may be a more cost-effective means of increasing compliance...|$|R
40|$|In {{this article}} we discuss {{fundamentals}} of the debt securities pricing. We begin with a generalization of the present value concept. Though the present value is the base valuation method in the modern finance we will illustrate that this concept does not sufficiently accurate in producing instrument pricing. The incompleteness of the unique present value approach stems from variability of the interest rates. Admitting variability of the interest rates we define two present values one for buyer other for seller. Therefore future buyer and seller cash payments can be described by the correspondent present values. Usually used assumption that future interest on investment over a specified time period {{would be the same}} as before specified period is a theoretical simplification that might be admitted or not. Admitting such assumption leads to eliminating {{an important component of the}} market risk. Recall that the assumption that a future payment can be invested with the same constant interest rate equal to the one used in the past is a component of the group conditions that specify frictionless of the market. We use this new concept that splits present value within two counterparties to outline details of the new valuation method of the fixed income securities. The primary goal of this paper is a credit derivative pricing method of the risky debt instruments. First we introduce a formal <b>definition</b> <b>of</b> the <b>default.</b> It somewhat close but does not coincide with the reduced form <b>of</b> the <b>default</b> setting. ...|$|R
