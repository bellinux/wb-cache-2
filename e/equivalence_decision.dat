6|16|Public
40|$|The use of {{signatures}} {{as efficient}} filters in boolean matching {{is a crucial}} step in technology mapping and/or formal verification. In this work we combine well known representations of boolean functions, the binary decision diagrams, {{with those in the}} spectral domain, the functional decision diagrams and the <b>equivalence</b> <b>decision</b> diagrams. We obtain signatures of Boolean functions and their variables, which are easy to compute but can reduce the problem of aliases though...|$|E
40|$|AbstractThe {{non-singular}} deterministic pushdown automata {{were first}} defined by Valiant {{as an example}} of a class of machines with a decidable equivalence problem [3]. No algorithm currently exist for deciding whether or not a deterministic pushdown automation is non-singular, so the applicability of Valiant's <b>equivalence</b> <b>decision</b> procedure cannot be readily (if ever) determined. In this paper, it is shown that the equivalence problem for non-singular automata is reducible to the problem of deciding whether or not a deterministic pushdown automaton is non-singular...|$|E
40|$|We {{introduce}} {{the class of}} nested polynomially recurrent sequences which includes {{a large number of}} sequences that are of combinatorial interest. We present an algorithm for deciding zero equivalence of these sequences, thereby providing a new algorithm for proving identities among combinatorial sequences: in order to prove an identity, decide by the algorithm whether the difference of left hand side and right hand side is identically zero. This algorithm is able to treat mathematical objects which are not covered by any other known symbolic method for proving combinatorial identities. Despite its theoretical flavor and its high complexity, an implementation of the algorithm can be successfully applied to nontrivial examples. Key words: symbolic computation, combinatorial sequences, nested polynomially recurrent sequences, zero <b>equivalence,</b> <b>decision</b> procedure...|$|E
40|$|In {{this paper}} it is {{explained}} how {{the techniques of}} fuzzy decision tables can used for business site selection. It is outlined how this technique fits in the spectrum of techniques which can be adopted for business site selection. Furthermore, it is described how decision tables can be modelled based on functional <b>equivalence.</b> The <b>decision</b> tables are modelled with a tool called Prologa. This tool supports the interactive construction, optimization and consultation of knowledge structuring formalisms such as decision tables, decision rules and decision trees. 1...|$|R
40|$|The {{method of}} quality multi {{criterion}} for nonlinear robust control synthesis by the dynamic systems with analytical nonlinearity is developed. It is shown an <b>equivalence</b> of task <b>decision</b> of nonlinear robust control synthesis basis of functional multiple state vector conception {{to the decision}} of the Hamilton-Yacobi-Bellman-Isaacs equation. The example of dynamic characteristics for synthesis system is given. Key words - quality multi criterion, nonlinear robust control...|$|R
40|$|International audienceReasoning {{about the}} {{knowledge}} of an attacker is a necessary step in many formal analyses of security protocols. In {{the framework of the}} applied pi calculus, as in similar languages based on equational logics, knowledge is typically expressed by two relations: deducibility and static <b>equivalence.</b> Several <b>decision</b> procedures have been proposed for these relations under a variety of equational theories. However, each theory has its particular algorithm, and none has been implemented so far. We provide a generic procedure for deducibility and static equivalence that takes as input any convergent rewrite system. We show that our algorithm covers all the existing decision procedures for convergent theories. We also provide an efficient implementation, and compare it briefly with the more general tool ProVerif...|$|R
40|$|Singleton kinds {{provide an}} elegant device for expressing type {{equality}} information resulting from modern module languages, {{but they can}} complicate the metatheory of languages in which they appear. I present a translation from a language with singleton kinds to one without, and prove that translation to be sound and complete. This translation is useful for type-preserving compilers generating typed target languages. The proof of soundness and completeness is done by normalizing type equivalence derivations using Stone and Harper's type <b>equivalence</b> <b>decision</b> procedure. 1 Introduction Type-preserving compilation, compilation using statically typed intermediate languages, offers many compelling advantages over conventional untyped compilation. A typed compiler can utilize type information to enable optimizations {{that would otherwise be}} prohibitively difficult or impossible. Internal type checking can be used to help debug a compiler by catching errors introduced into programs in optimizati [...] ...|$|E
30|$|As {{shown in}} Figure  3, when {{the image is}} scanned, the label in the {{previous}} row is stored in last _label and <b>equivalence</b> <b>decision</b> is performed. When P(y,x) {{is the beginning of}} the run or inside a run, the connectivity is detected by judging info(x).g. If the connectivity is detected (overlapped = 1), the translated label (the label which corresponds to pfl 1 in the current row (i.e., MAP(pfl 1)) when MAP(pfl 1) ≠ 0, or new _cnt when MAP(pfl 1) = 0) is stored in line _new _cnt, and it is used to assign provisional label for the run when the first pixel behind the tail of the run is encountered, the line _new _cnt is also used for updating of the multi-layer-index structure. The overlapping mode (overlapping _mode) and run end mode (run _end _mode) are also recorded for the updating of the multi-layer-index structure. In the scanning, updating of info(x).g and info(x).run _start is performed at each pixel, and assignment of info(x).label is performed at the tail of the run.|$|E
40|$|ABSTRACT The {{evaluation}} of drug permeation/penetration of semisolid formulations into animal skin {{can be useful}} to supplement the pharmaceutical equivalence. This paper describes the in vitro assessment of acyclovir (ACV) into porcine skin from commercial formulations with etermination of drug concentration in different layers of cutaneous tissue to correlate with effective antiviral concentration {{in order to improve}} the <b>equivalence</b> <b>decision.</b> Studies were conducted using Franz cells and porcine skin. Selected pharmaceutical creams containing ACV had identical (reference and generic) and different (similar) excipients. A software program was employed for the simulation of antiviral effectiveness in the skin. Regarding ACV skin penetration, the first batch of the generic product showed a significant difference from reference and similar products, while in the second batch all products demonstrated equivalent drug penetration in the skin. Simulation studies suggest that formulations analysed exhibit a pharmacological effect even when in contact with Herpes simplex strains of high IC 50 (inhibitory concentration required to reduce viral replication by 50 %). According to results, it can be assumed that the in vitro cutaneous permeation/penetration study does not supply sensitivity information regarding small alterations of ACV semisolid formulations due to the variability inherent to the method, although it can be relevant to pharmaceutical equivalence studies in the development of semisolid products...|$|E
40|$|We {{identify}} the complete class of transfer rules that guarantee strategyproofness of any non-increasing in completion time allocation rule for the sequencing problem. We then characterize {{the class of}} mechanisms satisfying efficiency of decision (or aggregate cost minimization), egalitarian equivalence and strategyproofness. There is no mechanism in this class that satisfies either feasibility or weak group strategyproofness. Finally we {{identify the}} restrictions under which egalitarian <b>equivalence,</b> efficiency of <b>decision,</b> identical preference lower bound and strategyproofness are compatible. ...|$|R
40|$|Process algebras are a {{convenient}} tool for describing and reasoning about the behaviour of concurrent systems. A variety of equivalence relations {{are used to}} study the relationship between di erent systems or between di erent levels of abstractions of the system. This paper reports on an implementation of a testing <b>equivalence</b> with binary <b>decision</b> diagrams (BDDs). It is de ned in terms of observations that process may or must satisfy. As the testing equivalence is shown to be an instance of a bisimulation equivalence, efcient algorithms for computing bisimulations using BDDs could be employed for its implementation. ...|$|R
40|$|We study {{a general}} {{adaptive}} ranking problem where an algorithm needs {{to perform a}} sequence of actions on a random user, drawn from a known distribution, so as to "satisfy" the user as early as possible. The satisfaction of each user is captured by an individual submodular function, where the user {{is said to be}} satisfied when the function value goes above some threshold. We obtain a logarithmic factor approximation algorithm for this adaptive ranking problem, which is the best possible. The adaptive ranking problem has many applications in active learning and ranking: it significantly generalizes previously-studied problems such as optimal <b>decision</b> trees, <b>equivalence</b> class determination, <b>decision</b> region determination and submodular cover. We also present some preliminary experimental results based on our algorithm...|$|R
40|$|The {{object of}} this paper is to show that, given any total {{recursive}} function g, one can effectively construct a Thue system T such that the decision problem for the range of g and the word problem for T are of the same many-one degree. It follows immediately that any many-one degree containing a recursively enumerable (r. e.) set can be represented by the word problem of some Thue system. The properties of Thue systems were investigated by Post ([4]), who was able to show that the general word problem is undecidable. Later Boone ([1]) was able to establish Turing equivalence between the word problem of Thue systems and the word problem for groups. Shepherdson ([5]) gave a simplified construction showing the Turing <b>equivalence</b> of the <b>decision</b> problem for r. e. sets, the decision problems (halting, derivability, and confluence) for Turing machines, and the word problem for Thue systems. As a refinement of a section of Shepherdson's investigation, Overbeek ([3]) established the many-one <b>equivalence</b> of the <b>decision</b> problem for r. e. sets and the decision problems for Turing machines. This paper is a logical extension of that work, carrying many-one equivalence into the general word problem for Thue systems. Singletary ([2]) has shown that these are the best possible results in the sense that not all r. e. one-one degrees can be represented by the word problem for Thue systems. There will be three major steps in the construction of T. (1) Given a total recursive function g, a Turing machine M * is defined such that the confluence problem for M * restricted to a recursive set of configurations is many-one equivalent to the decision problem for the range of g. (2) A Thue system T * is constructed and a recursive set of words P is defined such that the word problem of T * over P and the restricted confluence problem for M * are of the same many-one degree...|$|R
40|$|Given a logic {{presented}} in a sequent calculus, a natural question is that of equivalence of proofs: to determine whether two given proofs are equated by any denotational semantics, ie any categorical interpretation of the logic compatible with its cut-elimination procedure. This notion can usually be captured syntactically {{by a set of}} rule permutations. Very generally, proofnets can be defined as combinatorial objects which provide canonical representatives of equivalence classes of proofs. In particular, the existence of proof nets for a logic provides a solution to the equivalence problem of this logic. In certain fragments of linear logic, it is possible to give a notion of proofnet with good computational properties, making it a suitable representation of proofs for studying the cut-elimination procedure, among other things. It has recently been proved that there cannot be such a notion of proofnets for the multiplicative (with units) fragment of linear logic, due to the equivalence problem for this logic being Pspace-complete. We investigate the multiplicative-additive (without unit) fragment of linear logic and show it is closely related to binary decision trees: we build a representation of proofs based on binary decision trees, reducing proof <b>equivalence</b> to <b>decision</b> tree <b>equivalence,</b> and give a converse encoding of binary decision trees as proofs. We get as our main result that the complexity of the proof equivalence problem of the studied fragment is Logspace-complete. Comment: arXiv admin note: text overlap with arXiv: 1502. 0199...|$|R
40|$|AbstractThis paper {{outlines}} the inspiration {{received by the}} author from the Zadeh–MacFarlane–Jamshidi trio in his pursuit concerning the theory and Application of fuzzy logic. Beginning with Zadeh’s pioneering work, a hierarchical control system was developed, in collaboration with MacFarlane, for application in robotic manipulators. Subsequently, the work was extended to an analytical basis for controller tuning using fuzzy decision making. On the prompting of Jamshidi {{to address the issue}} of knowledge-base simplification, theorems were developed related to decoupling a fuzzy rule base. These developments provided a theoretical basis for applying single-context decision making to a problem governed by the knowledge base of coupled fuzzy rules. The developed theorems establish an analytical <b>equivalence</b> between the <b>decisions</b> made from a coupled set of fuzzy rules and an uncoupled set of fuzzy rules concerning the same problem domain. These developments have been applied to supervisory control of an industrial fish cutting machine. The paper presents the pertinent theory and illustrative examples...|$|R
40|$|For two {{disjoint}} sets of variables, X and Y, and a {{class of}} functions C, we define DT (X; Y; C) to be the class of all decision trees over X whose leaves are functions from C over Y. We study the learnability of DT (X; Y; C) using membership and <b>equivalence</b> queries. Boolean <b>decision</b> trees, DT (X;;; f 0; 1 g), were shown to be exactly learnable by Bshouty but does this imply the learnability of decision trees that have non-boolean leaves? A simple encoding of all possible leaf values will work provided {{that the size of}} C is reasonable. Our investigation involves several cases where simple encoding is not feasible, i. e., when jCj is large. We show how to learn decision trees whose leaves are learnable concepts belonging to a class C, DT (X; Y; C), when the separation between the variables X and Y is known. A simple algorithm for decision trees whose leaves are constants, DT (X;;; C), is also presented. Each case above requires at least s separate executions of the algorithm d [...] ...|$|R
40|$|Considering {{an economy}} with two goods {a private good and a {{household}} good with a variable degree of publicness {and identical individuals, the paper investigates {{the implications for}} economies of size of two extreme households' decision rules: (i) the cooperative model, where households maximize the welfare of their members, and (ii) the non-cooperative model, where each household's member maximizes her own utility. Under the cooperative rule, publicness of the household good is necessary and sufficient for positive economies of size and for these to increase with family size. This no longer holds true under the non-cooperative rule where negative economies of size may appear even in the case where the household consumption good is purely public. The results {{suggest that it is}} the inefficiency of the non-cooperative rule that is at the origin of the problem. Furthermore comparison of the scale factors' values indicates that the cooperative rule leads to less generous scales than the non-cooperative one. <b>Equivalence</b> scales, Household <b>decision</b> rule, Welfare maximization, Non-cooperative behaviour, Returns to size. ...|$|R
40|$|Abstract—We {{study the}} problem of {{determining}} approximate <b>equivalences</b> in Markov <b>Decision</b> Proceses with rewards using bisimulation metrics. We provide {{an extension of the}} framework previously introduced in Ferns et al. (2004), which computes iteratively improving approximations to bisimulation metrics using exhaustive pairwise state comparisons. The similarity between states is determined using the Earth Mover’s Distance, as extensively studied in optimization and machine learning. We address two computational limitations of the above framework: first, all pairs of states have to be compared at every iteration, and second, convergence is proven only under exact computations. We extend their work to incorporate “on-the-fly ” methods, which allow computational effort to focus first on pairs of states where the impact is expected to be greater. We prove that a method similar to asynchronous dynamic programming converges to the correct value of the bisimulation metric. The second relaxation is based on applying heuristics to obtain approximate state comparisons, building on recent work on improved algorithms for computing Earth Mover’s Distance. Finally, we show how this approach can be used to generate new algorithmic strategies, based on existing prioritized sweeping algorithms used for prediction and control in MDPs. I...|$|R
40|$|Proof {{equivalence}} in a {{logic is}} the problem of deciding whether two proofs are equivalent modulo a set of permutation of rules that reflects the commutative conversions of its cut-elimination procedure. As such, it is related to the question of proofnets: finding canonical representatives of equivalence classes of proofs that have good computational properties. It can also be seen as the word problem for the notion of free category corresponding to the logic. It has been recently shown that proof equivalence in MLL (the multiplicative with units fragment of linear logic) is PSPACE-complete, which rules out any low-complexity notion of proofnet for this particular logic. Since it is another fragment of linear logic for which attempts to define a fully satisfactory low-complexity notion of proofnet have not been successful so far, we study proof equivalence in MALL- (multiplicative-additive without units fragment of linear logic) and discover a situation that is totally different from the MLL case. Indeed, we show that proof equivalence in MALL- corresponds (under AC 0 reductions) to <b>equivalence</b> of binary <b>decision</b> diagrams, a data structure widely used to represent and analyze Boolean functions efficiently. We show these two equivalent problems to be LOGSPACE-complete. If this technically leaves open the possibility for a complete solution to the question of proofnets for MALL-, the established relation with binary decision diagrams actually suggests a negative solution to this problem. Comment: in TLCA 201...|$|R
40|$|Programmed {{cell death}} is an {{evolutionarily}} conserved process that plays critical roles in normal animal development {{and has been}} extensively studied in C. elegans. During programmed cell death, caspases are activated in the dying cell. The cell corpse is engulfed by a neighboring cell and degraded. Almost all cell deaths in C. elegans are "suicides"-they are caspase-dependent and apparently cell-autonomous, and do not require engulfment. During development of the C. elegans male, the cells B. alapaav and B. arapaav are generated during the late third-larval stage. During the early fourth-larval stage one of these cells undergoes programmed cell death, and the other survives. These two cells form an <b>equivalence</b> group; the <b>decision</b> of which cell dies and which survives is stochastic. The cell that dies is engulfed by the neighboring cell P 12. pa and was speculated to be an engulfment-dependent cell "murder" or an "induced suicide. " I have discovered that B. al/rapaav instead represents an "assisted suicide" that requires both the core apoptosis pathway and the engulfment pathway. egl- 1 and ced- 3 are expressed in the dying or undead cell in wild-type and engulfment-defective animals, and these genes are required for the B. al/rapaav cell death. In engulfment mutants the B. al/rapaav death process fails at a point after caspase activation, suggesting that the core cell-death pathway is necessary but not sufficient for this cell death. Previous genetic screens have not been designed to systematically identify essential genes with a role in cell death. Most somatic cell deaths in C. elegans occur during early development, but several male-specific cell deaths occur during the fourth larval stage. These late cell deaths {{provide an opportunity to}} examine essential genes for a role in programmed cell death, as RNAi treatment after hatching can eliminate gene function before these deaths occur but after embryogenesis. I performed an RNAi screen for 1, 132 essential genes and assayed the effect on Rn. aap cell survival. I analyzed candidate genes for non-specific effects, such as affecting the Rn cell lineage rather than cell death processes, to find twenty-five essential genes that might have a role in the Rn. aap cell death. by Holly L. Johnsen. Thesis: Ph. D., Massachusetts Institute of Technology, Department of Biology, 2016. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Cataloged from student-submitted PDF version of thesis. Includes bibliographical references...|$|R
40|$|The {{conceptualization}} of the term 2 ̆ 2 system 2 ̆ 2 has become highly dependent on the application domain. What a physicist means by the term system might be different than what a sociologist means by the same term. In 1956, Bertalanffy [1] defined a system as 2 ̆ 2 a set of units with relationships among them 2 ̆ 2. This and many other definitions of system share {{the idea of a}} system as a black box that has parts or elements interacting between each other. This means that at some level of abstraction all systems are similar, what eventually differentiates one system from another is the set of underlining equations which describe how these parts interact within the system. ^ In this dissertation we develop a framework that allows us to characterize systems from an interaction level, i. e., a framework that gives us the capability to capture how/when the elements of the system interact. This framework is a process algebra called Calculus for Decision Systems (CDS). This calculus provides means to create mathematical expressions that capture how the systems interact and react to different stimuli. It also provides the ability to formulate procedures to analyze these interactions and to further derive other interesting insights of the system. ^ After defining the syntax and reduction rules of the CDS, we develop a notion of behavioral <b>equivalence</b> for <b>decision</b> systems. This <b>equivalence,</b> called bisimulation, allows us to compare decision systems from the behavioral standpoint. We apply our results to games in extensive form, some physical systems, and cyber-physical systems. ^ Using the CDS for the study of games in extensive form we were able to define the concept of subgame perfect equilibrium for a two-person game with perfect information. Then, we investigate the behavior of two games played in parallel by one of the players. We also explore different couplings between games, and compare - using bisimulation - the behavior of two games that are the result of two different couplings. The results showed that, with some probability, the behavior of playing a game as first player, or second player, could be irrelevant. ^ Decision systems can be comprised by multiple decision makers. We show that in the case where two decision makers interact, we can use extensive games to represent the conflict resolution. For the case where there are more than two decision makers, we presented how to characterize the interactions between elements within an organizational structure. Organizational structures can be perceived as multiple players interacting in a game. In the context of organizational structures, we use the CDS as an information sharing mechanism to transfer the inputs and outputs from one extensive game to another. We show the suitability of our calculus for the analysis of organizational structures, and point out some potential research extensions for the analysis of organizational structures. ^ The other general area we investigate using the CDS is cyber-physical systems. Cyber-physical systems or CPS is a class of systems that are characterized by a tight relationship between systems (or processes) in the areas of computing, communication and physics. We use the CDS to describe the interaction between elements in some simple mechanical system, as well as a particular case of the generalized railroad crossing (GRC) problem, which is a typical case of CPS. We show two approaches to the solution of the GRC problem. ^ This dissertation does not intend to develop new methods to solve game theoretical problems or equations of motion of a physical system, it aims to be a seminal work towards the creation of a general framework to study systems and equivalence of systems from a formal standpoint, and to increase the applications of formal methods to real-world problems. ...|$|R

