15|15|Public
50|$|Each glyph design can {{be drawn}} or traced by a stylus on a <b>digitizing</b> <b>board,</b> or {{modified}} from a scanned drawing, or composed entirely within the program itself. Each glyph is then in a digital form, either in a bitmap (pixel-based) or vector (scalable outline) format. A given digitization of a typeface can easily be modified by another type designer; such a modified font is usually considered a derivative work, and is covered by the copyright of the original font software.|$|E
40|$|The {{invention}} {{provides a}} method and apparatus for remote sensing of livestock, using a thermographic image sensing system, {{in order to}} determine {{one or more of the}} number, weight, location, temperature, carcass pH, etc., of animals in a surveillance area. A thermographic image comprising pixels of the area is sent to a <b>digitizing</b> <b>board</b> in a microcomputer, where the image is converted into a number array. The numbers are then interpreted by software to provide the desired information in a decipherable form...|$|E
40|$|An inexpensive, {{high-speed}} densitometer {{made from}} an Apple II computer, a black-and-white video camera, and an image <b>digitizing</b> <b>board</b> is described. By supplementing the {{computer with a}} very fast coprocessor, one can obtain a measurement of a typical thin-layer spot in 30 - 40 s. Only minimal electronic expertise is required for assembling the system from the commercially available components. Coefficients of variation for multiple readings of a single 500 -ng spot of charred lipid were about 0. 5 %. For lipid spots weighing 250 to 2000 ng, a second-order relationship between weight and density reading was obtained with a correlation coefficient of 0. 998...|$|E
50|$|In the CODA system, each chassis {{contains}} a board {{that is an}} intelligent controller {{for the rest of}} the chassis. This board, called a ReadOut Controller (ROC), configures each of the <b>digitizing</b> <b>boards</b> upon first receiving data, reads the data from the digitizers, and formats the data for later analysis.|$|R
50|$|Most {{airports}} and airlines have automatic readers that will verify {{the validity of}} the boarding pass at the jetway door or boarding gate. This also automatically updates the airline's database that shows the passenger has boarded and the seat is used, and that the checked baggage for that passenger may stay aboard. This speeds up the paperwork process at the gate, but requires passengers with paper tickets to check in, surrender the ticket and receive the <b>digitized</b> <b>boarding</b> pass.|$|R
40|$|Laser anemometry {{was used}} to make two {{independent}} measurements of the flow velocity by capturing individual Doppler signals with high-speed <b>digitizing</b> <b>boards.</b> The two independent measurements were cross-correlated to reduce the contribution of photo detector shot noise on the frequency determination and subsequently on the turbulence estimate. In addition, criteria were developed to eliminate "bad" Doppler bursts from the data set, which then allowed reasonable low turbulence estimates to be made. The laser anemometer measurements were obtained at the inlet of an annular cascade and at the exit of a flow calibration nozzle and were compared with hot-wire data...|$|R
40|$|Abstract—The {{objective}} of this paper, is to apply support vector machine (SVM) approach for the classification of cancerous and normal regions of prostate images. Three kinds of textural features are extracted and used for the analysis: parameters of the Gauss-Markov random field (GMRF), correlation function and relative entropy. Prostate images are acquired by the system consisting of a microscope, video camera and a <b>digitizing</b> <b>board.</b> Cross-validated classification over a database of 46 images is implemented to evaluate the performance. In SVM classification, sensitivity and specificity of 96. 2 % and 97. 0 % are achieved for the 32 x 32 pixel block sized data, respectively, with an overall accuracy of 96. 6 %. Classification performance is compared with artificial neural network and k-nearest neighbor classifiers. Experimental results demonstrate that the SVM approach gives the best performance. Keywords—Computer-aided diagnosis, support vector machines, Gauss-Markov random fields, texture classification. I...|$|E
40|$|Previous {{studies have}} {{demonstrated}} that methapyrilene hydro-chloride (MP) is a rat-specific nongenotoxic carcinogen which in-duces liver tumors in a dose-dependent manner following chronic exposure in the diet. This study was conducted to determine the dose response of MP in the medium-term bioassay and to compare the response to tumor incidence. Two weeks following a single initiating dose of diethylnitrosamine (DEN), male F 344 rats were administered MP at doses of 0, 62. 5, 125, 250, or 1000 ppm in the diet for 6 weeks. A f partial hepatectomy was performed 3 weeks post-DEN. At termination, sections from the remaining three lobes were stained with GST-P antibody. Number and size of foci were measured using an image analysis system with a <b>digitizing</b> <b>board.</b> MP induced a dose-dependent {{increase in the number of}} GST-P+ foci/cm 2 (0 ppm= 0. 85 foci/cm 2; 62. 5 ppm= 1. 29 foci/cm 2; 125 ppm= 1. 59 foci/cm 2; 250 ppm= 6. 55 foci/cm 2; 100...|$|E
40|$|Does {{a drawing}} embody {{the form and}} focus of what the artist {{actually}} sees, or instead, is it only after seeing the finished drawing that the artist knows {{the true meaning of}} his or her visual experience? It is the knowledge of the visual experience that drives the representation of it. Knowledge of the visual experience is present in varying degrees, contains the defining characteristics and distinctive features of what is seen, but may not be readily accessible in its entirety at all times. To study this concept, the perceptual and cognitive activities of two children were recorded as they made drawings on paper attached to a computer <b>digitizing</b> <b>board.</b> Analysis of verbal and visual protocols synchronized in real time allowed inferences to be made about the artists ' judgments as they drew. It was found that the most powerful force guiding the evolution of a drawing is not the concept of the representation of what is seen, but rather the sense of organization and balance of that representation on the picture surface which inspires the artist to give form to meaning. (DGM) Reproductions supplied by EDRS are the best that can be mad...|$|E
50|$|All {{the camera}} {{connections}} {{coming into the}} video village go into the video trolley. These come in several shapes and sizes and are often hand-built by the operator based on his/her own preferences {{and the needs of}} the show. On the cart are the video recorders, the most important equipment of a VA op. The cart usually holds a video matrix, for making quick interconnections, several small operator's monitors, a video printer, all the wireless receivers, speakers, computers, laptops, <b>digitizing</b> <b>boards,</b> UPSes, and a bunch of small tools. The camera images are then fed to the larger monitors for the director, and sometimes for a second array of monitors for the producers, clients, etc. More often than not the Director and DP request a smaller, more private monitor set, and then the second array can be watched by everyone else. Video is often fed to make-up trucks, production trailers, or separate monitors around set for cuing stunts, special effects or puppeteers. A complex video assist can have up to 20 monitors depending on the number of cameras used. Wireless handheld monitors are often used so the director can be close to the actors. On-board monitors, mounted directly on the camera, helps the focus puller to follow the shot.|$|R
40|$|Background. Dysrhythmia {{is one of}} the {{features}} frequently associated with the motor disturbance in Parkinson’s disease (PD). The mechanism responsible for this phenomenon is not known. Objectives. To assess the rhythmic movements of the hand in PD patients in general and in parkinsonian subtypes. Methods. Fifty-one PD patients (32 males) with mean age 66. 3 ^ 9. 1 years (6. 6 years of symptoms) and 36 healthy controls (age 64. 9 ^ 13. 2, range 40 – 85) were studied. Subjects were asked to tap with their dominant or less affected arm on a <b>digitized</b> switch <b>board</b> at their most comfortable pace (16 s), fastest tapping speed (12 s), and at different frequencies provided by a metronome. The mean rhythm and the tap-to-tap variation were compared. Performance of the PD patients and control subjects were compared, as there were different subtype...|$|R
40|$|Abstract—A {{non-contact}} capacitive biopotential electrode with a common-mode {{noise suppression}} circuit is presented. The sensor network utilizes a single conductive sheet {{to establish a}} common body wide reference line, {{eliminating the need for}} an explicit signal ground connection. Each electrode senses the local biopotential with a differential gain of 46 dB over a 1 - 100 Hz bandwidth. Signals are <b>digitized</b> directly on <b>board</b> with a 16 -bit ADC. The coin sized electrode consumes 285 µA from a single 3. 3 V supply, and interfaces with a serial data bus for daisychain integration in body area sensor networks. Keywords-ECG, EEG, Body Sensor, Capacitive Sensing I...|$|R
40|$|The {{cerebrovascular}} accident {{often results in}} motor impairment {{of one of the}} upper limbs, hence, compromising {{the quality of life of}} stroke survivors. Rehabilitation aims to restore the movement abilities of the paralyzed/paretic upper limb. An important element in rehabilitation is to apply a quantified measure of the quality of movement, in order to follow the recovery and select the most appropriate therapeutic modality. We developed a method that uses data recorded during planar movements and outputs an objective measure that relates to the smoothness, velocity and precision of the movement. This method is universal, in a sense that hand position can be recorded by any available means (e. g., robot assistant, <b>digitizing</b> <b>board,</b> motion tracking systems, etc). The method follows the Drawing Test, but generates results that show the ability of the patient to make point to point movements and track the presented trajectory. The method is based on measurements of hand position during movement along a target path in form of a 2 cm wide rectangle. The patient’s task is to move the hand along the target path as quickly as possible, with as few contacts (collisions) with the sides of the path. This paper addresses the aspects of automatic detection of parameters that quantify the quality of movement (speed, smoothness and precision). The use of this method is presented with 10 patients. [Projekat Ministarstva nauke Republike Srbije, br. 175016...|$|E
40|$|Masteroppgave i idrettsvitenskap- Universitetet i Agder 2012 Purpose: This study {{examined}} the effect of an eight week Sling Exercise Therapy (SET) training programme in children and the response to their gross and fine motor coordination skills. Methods: The study was a non-controlled experimental design. An intervention group consisting of 13 boys aged 8 to 12 years identified with motor coordination difficulties trained in an eight week long SET programme designed to strengthen their proximal stabilizing musculature. Pre and post testing were performed using the Movement Assessment Battery for Children (M-ABC- 2) and a self developed Grapho-motor Function Test for Children (GFTC) to quantify any changes in motor coordination and drawing skills. The GFTC comprised three different figures of varying complexity for retracing/drawing on a <b>digitizing</b> <b>board.</b> A specially designed computer programme calculated accuracy through to unique variables; mean error and error standard deviation. These were combined with time to give a score on precision. On the M-ABC- 2 the 25 th percentile were used as a cutoff for entry into the project. Qualitative observations and unsolicited feedback regarding the children's improvements were noted during the period. Results: Significant changes were observed on the M-ABC- 2 total score after the training intervention, from 64. 9 on the pre test to 74. 1 on the post test (p 0. 05). For the group below the 16 th percentile on the M-ABC- 2 there was a marginally significant improvement on the GFTC from a precision score of 68. 3 to 47. 6 (p< 0. 05). Qualitative feedback included functional improvements in everyday activities. Conclusion: Training the proximal stabilizing musculature of children with motor coordination problems seems to yield considerable improvements in their motor control skills. Findings suggest that this may also apply to grapho-motor function. Due to limitations in this study further research is required to properly document these effects...|$|E
40|$|Purpose: This study {{examined}} the effect of an eight week Sling Exercise Therapy (SET) training programme in children and the response to their gross and fine motor coordination skills. Methods: The study was a non-controlled experimental design. An intervention group consisting of 13 boys aged 8 to 12 years identified with motor coordination difficulties trained in an eight week long SET programme designed to strengthen their proximal stabilizing musculature. Pre and post testing were performed using the Movement Assessment Battery for Children (M-ABC- 2) and a self developed Grapho-motor Function Test for Children (GFTC) to quantify any changes in motor coordination and drawing skills. The GFTC comprised three different figures of varying complexity for retracing/drawing on a <b>digitizing</b> <b>board.</b> A specially designed computer programme calculated accuracy through to unique variables; mean error and error standard deviation. These were combined with time to give a score on precision. On the M-ABC- 2 the 25 th percentile were used as a cutoff for entry into the project. Qualitative observations and unsolicited feedback regarding the children's improvements were noted during the period. Results: Significant changes were observed on the M-ABC- 2 total score after the training intervention, from 64. 9 on the pre test to 74. 1 on the post test (p 0. 05). For the group below the 16 th percentile on the M-ABC- 2 there was a marginally significant improvement on the GFTC from a precision score of 68. 3 to 47. 6 (p< 0. 05). Qualitative feedback included functional improvements in everyday activities. Conclusion: Training the proximal stabilizing musculature of children with motor coordination problems seems to yield considerable improvements in their motor control skills. Findings suggest that this may also apply to grapho-motor function. Due to limitations in this study further research is required to properly document these effects...|$|E
40|$|International audienceA {{low-cost}} high-quality {{system for}} the processing of satellite data received in the WEFAX analogue format is presented. It is composed of a receiver with its antenna connected to a personal computer with <b>digitizing</b> and graphic <b>boards.</b> The software automatically performs the storage of data onto the hard disk, contrast enhancement and false colour display, accurate navigation and animation loops. Interactive features are also available. Such a system is of great use in meteorological education, in weather forecasting and in environmental research. Taking into account the peculiarities of the WEFAX format, some algorithms have been devised lo correct for atmospheric depletion. Ground albedo can therefore be evaluated accurately on a pixel basis as well as global irradiation, cloud coverage and atmospheric global transmission...|$|R
40|$|Abstract. Color {{variability}} of paper birch (Betula papyrifera Marsh.) wood {{at the tree}} level was examined in this article. Tree age, dimension, and vigor were expected to influence the proportion of discolored wood in paper birch boards; older, larger, and less vigorous trees were assumed to produce boards with higher proportions of discolored wood. The color analysis was performed on approximately 2250 boards produced from 168 paper birch trees harvested in two different stands from which only logs of sawing quality were used. An industrial scanner was used to <b>digitize</b> the <b>boards</b> and obtain colorimet-ric information. Results show that tree diameter and vigor significantly influenced the proportion of discolored wood in boards, whereas the effect of tree age {{did not have a}} significant influence in the model. An average area of 32. 4 % of discolored wood was obtained when considering all boards. Less vigorous trees showed a mean area of 45. 32 %, whereas middle-vigor and most-vigorous trees had mean areas of 30. 78 and 15. 47 %, respectively. The colorimetric values were mainly affected by tree age and diameter, but these effects were variable for every colorimetric parameter. The analysis of the random effects demonstrated that most of the total random variance of the dependent factors came from the between-board, between-tree, and, to a lesser extent, between-log variation. These findings suggest tha...|$|R
40|$|A drastic {{increase}} in storage density of magnetic media {{had a strong}} impact {{on the development of}} new sensor concepts for the measurement of weak magnetic fields. Two prerequisites were the miniaturization and the efficiency of the used effect. A number of magnetic field sensors based on various mechanisms have been developed and found their applications in information data-storage technology, mechanical engineering, and automative industry. The use of such sensors is quite attractive for special nondestructive testing (NDT) applications, e. g. eddy current testing with high penetration and online monitoring capabilities. Compared to most conventional sensors, the sensitivity of giant magneto-resistance (GMR) based sensors is higher; therefore, weaker magnetic fields can be detected. Based on a commercial GMR chip, we have designed an array with 16 gradiometer sensors arranged in a line with a pitch of 4 mm. A preamplifier and a multiplexer are integrated into the sensor array. A PC data acquisition <b>board</b> <b>digitizes</b> the output signals from the array. The sensor array has been tested on surface and sub-surface defects. This paper presents an overview of the equipment design, including Sensor-On-Chip (SOC) technologies especially suitable for industrial application...|$|R
40|$|We have {{developed}} a multi-user 4 th Dimension ™ Macintosh ™ database program that logs procedures, keeps inventory and generates reports and referral letters. In addition to the text output, quick and simple methodologies allow cine images to be captured in the cath lab, and automatically incorporated into the reports and referral letters. The images are digitized using standard Macintosh computers with a high quality gray scale <b>digitizing</b> <b>board.</b> The software utilized is the public domain NIH Image software package. Macros have been written to make the image acquisition and storage process very simple requiring only a few keystrokes. If desired, quantitation of diameter stenosis, vessel size, ejection fraction or valve area calculations can also be easily performed. Included images {{are not limited to}} those acquired in the cath lab. Scanned hemodynamic tracings, EKGs or any other image data can be easily incorporated into the patient's database record off line. Images are stored directly in the database and along with the report can be retrieved at anytime. To conserve space and minimize network traffic, the images are compressed approximately 10 to 1 using standard Macintosh Quicktime ™ routines. Alternatively, the images can be stored external to the data base so that other applications can have access to them as well. The entire process of generating a report, complete with images can be accomplished in less than 3 minutes and requires minimal training. The reports and letters are printed on standard laser printers and the image quality is excellent. As the image to the left shows, a picture is truly worth a thousand words. This user friendly system allows the clinicians to better care for their patients by giving them easy access not only to the written reports, but also to high quality angiographic images...|$|E
40|$|Ouantitative {{angiography}} {{is considered}} the ″gold standard″ {{for the assessment of}} coronary arterial dimensions. The presence in the actual systems of one or more disadvantages such as high cost, difficulty in usage and poor portability, have prevented the wide utilization of this method. To implement a similar system, the acquisition of the computer, software, <b>digitizing</b> <b>board</b> and cineprojector with CCD camera is usually required. We developed a system running on every Macintosh computer with only one special requirement, that of a commercially available slide scanner. A public domain software, NIH Image (written by Wayne Rasband) was modified and expanded to perform the following tasks: acquisition and storage of the digitized angiographic frames, automatic edge detection and measurements, and saving of the results in a text format file, readable from every database, spreadsheet or statistical package. Films (courtesy of Dr. Patrick W. Serruys, Rotterdam) of coronary phantoms with known size (0. 5, 0. 7, 1. 0, 1. 4, 1. 9 mm) implanted in pigs, were used for system validation. The angiographic frames (24 × 18 mm) were digitized with a spatial resolution of 1850 pixels/inch (slide scanners with higher resolution are also available) and 256 gray levels. Using isocenter calibration, the measurements resulted in a correlation coefficient of 0. 96 (y= 0. 86 ×+ 0. 12), accuracy of – 0. 03 mm and precision of 0. 15 mm. A correlation coefficient of 0. 92 (y= 0. 67 x+ 0. 33), an accuracy of – 0. 03 mm and a precision of 0. 23 mm were found using catheter calibration. With the same phantoms, the mean reproducibility was 0. 08 mm for the interpolated reference diameter (RD), 0. 03 mm for the minimal luminal diameter (MLD), 1. 4 % for the diameter stenosis (DS) and 0. 6 mm for the lesion length. The variability of coronary measurements was also assessed in 23 patients who had 2 angiograms, a median of 21 days apart. The mean (±SD) of the difference between the 2 measurements was 0. 09 ± 0. 28 mm for RD, 0. 06 ± 0. 30 mm for MLD, 1. 5 ± 9. 1 % for DS, and 0. 32 ± 1. 7 mm for lesion length. Less than 1 hour of training was needed for learning how to use this system efficiently...|$|E
40|$|Measurement {{of coral}} {{extension}} rate is facilitated by x-radiography of medial slabs of coral skeletons which contain annual density banding. Densitometer analysis of film optic density with calibration to skeletal density {{can also provide}} calcification rate and density, but is time consuming and restricted to thin transects equal in width to the densitometer beam. Coral density and calcification data are useful because they provide skeletal growth information additional to extension rate. A microcomputer system has been assembled and a BASIC program has been written to rapidly and accurately obtain extension, density, and calcification measurements from x-radiograph revealed coral skeletal growth bands. The hardware consists of: an IBM-PC microcomputer, internal <b>digitizing</b> <b>board</b> providing resolution of 256 x 256 picture elements (pixels) by 256 grey levels, closed circuit TV camera, and an evenly distributed back-light source. The software (BASIC program) is written to incorporate actual scale of the x-radiograph. Initially, film optic density is calibrated to skeletal density by digitizing {{the image of an}} aluminum wedge included in the x-radiograph. Appropriate formulas (Buddemeier, 1974) and mass absorption coefficients are utilized. Next, the coral x-radiograph is digitized and a transect perpendicular to growth band boundaries is defined. The transect dimensions are selectable by the operator. Pixel values of optic density within the transect are converted to skeletal density through the wedge calibration. These values are averaged parallel to band boundaries and graphed to produce a chart of peaks and valleys representing high and low density portions within each band. The program finds midpoints of each peak and valley along the graph. Linear distance between these points for each couplet gives annual extension rate. Density is found by integration of the area under peaks and valleys. Mass or calcification rate is calculated by the product of extension and density. Extension, density, and mass are also available for subannual band portions. Depending upon skeletal growth rate, the program can analyze up to 12 years on a single digitization. The image (and transect) can also be printed on a dot matrix printer making it possible to overlap and continue transects along the entire portion of the coral desired. Conventional image analysis systems cost in the $ 40, 000 price range. The microcomputer system described here can be implemented for less than $ 5, 000. The method provides relatively rapid, accurate, and objective measurements of the three skeletal growth parameters: extension, density, and calcification (mass). Investigations continue into the precision and reproducibility of the technique as well as for hardware to obtain greater resolution...|$|E
40|$|Abstract—The KAOS {{spectrometer}} {{is maintained}} by the A 1 collaboration at the Mainz Microtron MAMI {{with a focus on}} the study of (e, e′K+) coincidence reactions. For its electron-arm two vertical planes of fiber arrays, each comprising approximately 10 000 fibers, are operated close to zero degree scattering angle and in close proximity to the electron beam. A nearly dead-time free DAQ system to acquire timing and tracking information has been installed for this spectrometer arm. The signals of 144 multi-anode photomultipliers are collected by 96 -channel front-end <b>boards,</b> <b>digitized</b> by double-threshold discriminators and the signal time is picked up by state-of-the-art F 1 time-to-digital converter chips. In order to minimize background rates a sophisticated trigger logic was implemented in newly developed VUPROM modules. The trigger performs noise suppression, signal cluster finding, particle tracking, and coincidence timing, and can be expanded for kinematical matching (e′K+) coincidences. The full system was designed to process more than 4 000 read-out channels and to cope with the high electron flux in the spectrometer and the high count rate requirement of the detectors. It was successfully in-beam tested at MAMI in 2009. I...|$|R
40|$|An FPGA based {{digital signal}} {{processing}} (DSP) system for biasing and reading out multiplexed bolometric detectors for mm-wavelength telescopes is presented. This readout system is being deployed for balloon-borne and ground based cosmology experiments with {{the primary goal of}} measuring the signature of inflation with the Cosmic Microwave Background Radiation. The system consists of analog superconducting electronics running at 250 mK and 4 K, coupled to digital room temperature backend electronics described here. The digital electronics perform the real time functionality with DSP algorithms implemented in firmware. A soft embedded processor provides all of the slow housekeeping control and communications. Each board in the system synthesizes multi-frequency combs of 8 to 32 carriers in the MHz band to bias the detectors. After the carriers have been modulated with the sky-signal by the detectors, the same <b>boards</b> <b>digitize</b> the comb directly. The carriers are mixed down to base-band and low pass filtered. The signal bandwidth of 0. 050 Hz - 100 Hz places extreme requirements on stability and requires powerful filtering techniques to recover the sky-signal from the MHz carriers. Comment: 6 pages, 6 figures, Submitted May 2007 to IEEE Transactions on Nuclear Science (TNS...|$|R
40|$|The Kaos {{spectrometer}} {{is maintained}} by the A 1 collaboration at the Mainz Microtron MAMI {{with a focus on}} the study of (e,e'K^+) coincidence reactions. For its electron-arm two vertical planes of fiber arrays, each comprising approximately 10 000 fibers, are operated close to zero degree scattering angle and in close proximity to the electron beam. A nearly dead-time free DAQ system to acquire timing and tracking information has been installed for this spectrometer arm. The signals of 144 multi-anode photomultipliers are collected by 96 -channel front-end <b>boards,</b> <b>digitized</b> by double-threshold discriminators and the signal time is picked up by state-of-the-art F 1 time-to-digital converter chips. In order to minimize background rates a sophisticated trigger logic was implemented in newly developed Vuprom modules. The trigger performs noise suppression, signal cluster finding, particle tracking, and coincidence timing, and can be expanded for kinematical matching (e'K^+) coincidences. The full system was designed to process more than 4 000 read-out channels and to cope with the high electron flux in the spectrometer and the high count rate requirement of the detectors. It was successfully in-beam tested at MAMI in 2009. Comment: Contributed to 17 th IEEE Real Time Conference (RT 10), Lisbon, 24 - 28 May 201...|$|R
40|$|In {{order to}} {{identify}} and quantify sources of digitizing error, and to understand how error is carried through a map overlay, three experiments were performed. First, four operators repeatedly digitized eight randomly distributed points eight times. Data were analyzed using parametric statistics and by an error models so that average point digitizing error, the operator error (random error and bias), and the machine error (random error) were estimated; the operators 2 ̆ 7 digitizing characteristics were statistically analyzed. In the second experiment I designed and created a standard coverage with the ARC/INFO GENERATE command. The coverage consists {{of a set of}} special geometric entities: a series of differently sized circles, differently shaped triangles and rectangles drawn by PC ARCPLOT. These figures were designed to test the effect of the original map polygons 2 ̆ 7 characteristics on both machine error and operator error, such as area and perimeter, figure shape and geometric entities combination, line curvature, number of vertices selected for representing a line, position of a geometric entity on <b>digitizing</b> <b>board.</b> Several operators repeatedly digitized the coverage six or more times. The operator error (area error and perimeter error) were obtained by subtracting the standard coverage from a digitized coverage. The machine error (area error and perimeter error) were obtained by subtracting the theoretical true coverage from the standard coverage. The results were analyzed statistically. The causation of errors and the operators 2 ̆ 7 digitizing characteristics were further discussed. The third experiment addressed how digitizing errors are propagated through map overlay. In this experiment the digitized coverages created in the second experiment by each operator were overlaid with the ARC/INFO UNION command. Area error, perimeter error, and the numbers of the spurious polygons were collected. The means, sums, maximum, minimum, and standard deviation of area error and perimeter error were obtained. The relationship between area error, perimeter error, and number of spurious polygons of the overlaid coverage were analyzed. ^ This study: (1) focuses on position, as opposed to attribute, error; (2) examines errors in vector-based, not raster-based, GIS; and (3) examines errors caused during the digitizing process, and their propagation through map overlay. The digitizing method is point mode, not stream mode. ^ Results were applied to error management and error reduction to: (1) create a theoretical model which can be used to check quality of the vector source coverages, and to lead users to correctly utilize the GIS data, to prevent them from making unnecessary mistakes; (2) identify some rules to properly use the ARC/INFO ELIMINATE command, and to set MMU (minimum mapping unit) for a particular project. ...|$|E
40|$|INTRODUCTION An {{algorithm}} {{to study}} hand movements {{in patients with}} Parkinson's disease (PD) who experience temporary, involuntary inability to move a hand have been developed. In literature, this rather enigmatic phenomenon has been described in gait, speech, handwriting and tapping, and noted as motor blocks (MB) or freezing episodes. Freezing refers to transient periods in which the voluntary motor activity being attempted by an individual is paused. It is a sudden, unplanned state of immobility that appears to arise from deficits in initiating or simultaneously and sequentially executing movements, in correcting inappropriate movements or in planning movements. The clinical evaluation of motor blocks is difficult because of a variability both within and between individuals and relationship of blocks to time of drug ingestion. In literature the terms freezing, motor block or motor freezing are used in parallel. AIM In clinical settings classical manifestations of Parkinson's Disease (akinesia bradykinesia, rigidity, tremor, axial motor performance and postural instability) are typically evaluated. Recently, in literature, new computerized methods are suggested for their objective assessment. We propose monitoring of motor blocks during hand movements to be integrated. For this purpose we have developed a simple method that comprises PC computer, <b>digitizing</b> <b>board</b> and custom made software. Movement analysis is "off line", {{and the result is}} the data that describe the number, duration and onset of motor blocks. METHOD Hand trajectories are assessed during simple volitional self paced point-to-point planar hand movement by cordless magnetic mouse on a <b>digitizing</b> <b>board</b> (Drawing board III, 305 x 457 mm, GTCO Cal Comp Inc), Fig. 1. Testing included 8 Parkinsonian patients and 8 normal healthy controls, age matched, with unknown neurologic motor or sensory disorders, Table 1. Three kinematic indicators of motor blocks: 1) duration (MBTJ; 2) onset (t%); and 3) number (N) of MB episodes, allow identification and quantification of motor blocks. Duration of motor blocks (MVT) is defined as the time sequence when (x,y) coordinates do not change their values and is expressed in percentage from the whole movement duration MBT% = MBT/T (%). If during some movements more than one motor block occurs (N > 1) then this movement is decomposed. The whole movement motor block (mbt) is the sum of all motor blocks MVT,; during the same movement and expressed in percentage from the whole movement duration mbt%= tYJa (%). The onset of motor block (t) is determined with the beginning of motor block and expressed in percentage from the whole move- ment duration: t% = t/T (%). After the determination of kinematic indicators of motor blocks (MVT, N, t) for healthy controls, their mean values are calculated. Statistical package ANOVA is applied to determine statistical significance of the difference between PD patients and mean values from age matched control healthy group. PD patients are then classified into two groups: one group consisting of PD patients with motor blocks and the other without motor blocks, similar to healthy controls. RESULTS Acquired movements are processed and analyzed. Fig. 2 is an example of hand trajectories. Time course of (x, y) coordinates indicates motor block appearance, Fig. 3. Detailed presentation of kinematic indicators of motor block (MVT, N, t) is in Fig. 4. Intra-subject variability of these parameters is presented in Figs 5, 6 and 7 for patient # 3. The results for N show that 45 % of all patients # 3 movements had none motor blocks (N = 0); 20 % had N = 1; 15 % had N = 2; 11. 5 % had N = 3; 5. 7 % had N = 4; 0. 3 % had N = 5; 0. 7 % had N = 6; 0. 3 % had N = 7 and 1 % had N = 8 motor blocks. The results for t% show that 3 % of all patients' # 3 blocks started at first quarter, 17 % started in the second, 36 % in the third, and 44 % {{in the last quarter of}} movement. The results for MBT% show that 14. 5 % of all movements had MBT% in the range 0 - 5 %; 56 % had MBT% 5 - 10 %; 22 % had MBT% 10 - 15 %; 5. 5 % had MBT% 15 - 20 °% and 2 % had MBT% 20 - 25 %. No block lasted more than 25 % from the whole movement duration. Table 2 is the summary of mean variability for kinematic indicators of motor block (N, mbt%, t%) and for the movement duration T during a 7 day-testing of patients # 3. The analysis of calculated data for eight tested PD patients revealed a significant difference (p < 0. 01) between healthy controls and three PD patients; data on five PD patients were not significantly different (ns). This method clustered 3 PD patients in the group that experience motor blocks, while the rest were in the group without their significant occurrence. DISCUSSION This algorithm is an additional instrument in classical evaluation of PD patients during their clinical evaluation and treatment. It provides to clinician a rapid feedback on the changes of voluntary hand movements in everyday progress of illness. Furthermore, this method could be of assistance for developing strategies to overcome motor blocks in arm movements at their beginning, as well as for the feedback of the success of drug therapy...|$|E
40|$|In {{clinical}} setting, {{the symptoms}} of the impaired motor behavior in patients with different neurological diseases are identified by classical tests incorporated in clinical neurological examination. New computerized methods for objective motor assessment have been recently suggested in the literature. We developed computerized method for assessment and evaluation of arm movement in patients with Parkinson's disease (PD) in early phase and in patients with cerebellar syndrome. Method is based on automatic acquisition of hand coordinates during drawing of line and circle, and offline analysis of kinematic parameters (time duration, path length, mean and maximal velocity, velocity profile, and precision). Clinical application is in recognition and follow-up of the impaired kinematic parameters, specific for these two groups of patients. AIM We propose computerized method that consists of two motor tasks: Task 1 - drawing a line defined with end points; and Task 2 - drawing a circle defined by referential model. The first task was rather simple with defined direction, and the second included continuous change of the direction that required permanent adjustment. The aim was to detect which kinematic parameters were particularly different in PD and in patients with cerebellar syndrome in relation to healthy controls, and then to apply this method as an additional instrument in clinical evaluation. METHODS Hand trajectories were assessed during simple self-paced 1) point-to-point movement-Task 1; and 2) circle-Task 2, by cordless magnetic mouse in a hand on <b>digitizing</b> <b>board</b> (Drawing board III, 305 x 457 mm, GTCO Cal Comp Inc). The subjects were seated in a relaxed manner on the chair adjusted to the table height, and instructed not to correct drawn line during performance of a task. The first session was for practicing the tests only, {{and in the next}} session, the subjects repeated 5 times each task. All sessions were videotaped with CCD camera. Testing included three groups: 10 Parkinsonian patients, 8 patients with cerebellar syndrome and 10 healthy controls, age matched, with not known neurologic motor or sensory disorders. Data were obtained using custom-made software written in C++, and stored in computer for further analysis. Data were analyzed using the Excel (ver. 9. 0) and MatLab (ver. 6. 0). The following kinematic parameters were calculated: time duration, path length, mean and maximal velocity, velocity profile and precision, and then statistically processed. Generalized linear model was formed in SPSS 10. 0. RESULTS The data from all subjects and from all trials for two tasks were first visually inspected. In the first task, PD patients significantly differed in relation to controls in the following parameters: mean and maximal velocity, while in the second task, time duration and mean velocity were significantly different. For patients with cerebellar syndrome in relation to controls, mean and maximal velocity, and path length were significantly different for the first task, while in the second task, path length. For the task to draw a line, both groups of patients had statistically smaller mean and maximal velocities in respect to controls, and for the drawing of a circle, none parameter was at the same time statistically different for both groups in regard to controls. Between the two groups of patients, the only statistically different kinematic parameter was the length of drawn line. The velocity profile for the same task was shown as characteristic for the three groups. CONCLUSION Identifying the abnormal kinetic parameters of hand movement as well as their correlation with classical clinical signs could be highly important in the process of patient's motor control status evaluation, and could enable better understanding of the course and prognosis of specific pathological entity...|$|E
40|$|The {{dramatic}} increase in storage density in magnetic media had a strong impact {{on the development of}} new sensor concepts for measurement of weak magnetic fields. Two prerequisites were miniaturization and the efficiency of the effect used. A number of magnetic field sensors based on various mechanisms has been developed and found applications in information storage technology, mechanical engineering and automotive industry. It is attractive to use such sensors for special applications in nondestructive testing (NDT) i. e. eddy-current testing with high penetration and on-line monitoring. Compared to the most conventional sensors the sensitivity of such sensors based on giant magneto-resistance (GMR) effect is higher, so smaller pre-magnetization fields are necessary. Based on a commercial GMR chip, we have built up an array with 16 gradiometer sensors arranged in a line with a pitch of 4 mm. A pre-magnetization device and multiplexer is integrated in a sensor head. A PC data acquisition <b>board</b> <b>digitizes</b> the output signals of the array. For spatial filtering a wavelet transformation algorithm based on Doubechies wavelet is used. The sensor array was tested on samples in different forms with artificial surface and sub-surface defects in various depths and widths as well as for natural defects. An outlook on the design of equipment including special sensor-on-chip technologies fit for industrial application is presented...|$|R
40|$|In 2011 the University of Iowa Libraries began {{crowdsourcing}} {{the digital}} transcription of its manuscript archives. Four years and over 50, 000 transcribed pages later, that project, known as DIY History, has garnered considerable internet attention via Buzzfeed, Twitter, Tumblr, and the NBC News blog. At the same time, {{it has been}} threaded into undergraduate classrooms at Iowa {{as a means of}} introducing students to primary source research, information literacy, and multimodal design. Matt Gilchrist and Tom Keegan will discuss how faculty members and librarians collaborated on an assignment that emphasizes course objectives while strengthening student connections to the UI Libraries. That assignment, Archives Alive!, resulted from a partnership between DIY History and Iowa Digital Engagement and Learning (IDEAL). Students are asked to transcribe a document, compose a brief rhetorical analysis and historical contextualization of it, and create screencasts of their work. By making use of narrative primary source material like letters and diary entries, Archives Alive! helps students see themselves in research material. Building an assignment around the crowdsourcing model provides students with two attitudes important to project success: a sense of ownership (through crowdsourced participation) and a sense of purpose (through a dynamic assignment with a real audience). The success of the project rests upon a flexible, design-centered approach to program structure that fosters an audience for library collections while asking students to create work with the public in mind. Paul Soderdahl will discuss the administrative considerations and costs in moving digital library operations from project to program. The UI Libraries have made deliberate efforts {{over the past several years}} to achieve this transition – in particular a reorganization of Digital Library Services into Digital Research and Publishing. He will also discuss the relative leap of faith and return on investment associated with large-scale digitization projects and audience engagement. The James Merrill Digital Archive (JMDA) is comprised of <b>digitized</b> Ouija <b>board</b> session transcripts, poem drafts, and other materials toward Merrill’s epic narrative poem, “The Book of Ephraim,” part of the Pulitzer Prize-winning book, Divine Comedies. The JMDA is the result of expertise and input of many collaborators across the Washington University campus. Shannon Davis and Joel Minor will speak on various aspects of the ongoing project, including successful cross-campus collaboration, employing student workers to perform high-level encoding and exhibit curation, and how Omeka was used to develop the digital archive...|$|R
40|$|Graduation date: 2003 The {{purpose of}} the thesis is to design and develop a network of automated, distributed, living {{cell-based}} sensors, called CytoSensors. Their main role is to detect a variety of biological and chemical toxins. The system {{is designed to help}} researchers to carry out multitude of experiments, in order to build a practical knowledge base in toxin detection. The network is developed in accordance with industry standards, to be used and deployed for prevention in inhospitable environments such as battlefields, toxic urban locations or polluted agricultural regions. The sensor is composed of a processing unit (processor and memory), an archiving unit (permanent data storage), a communication unit, input devices attached to a data acquisition unit, and control devices. The CytoSensor is specifically designed to acquire and analyze visual information about the living cells: hence cameras are used as input devices and frame grabbers are used as the digitizers. The control devices are additional external devices developed to help control and automate the process of data acquisition: they comprise light intensity control USB boards to provide the correct amount of light to view the cells, touch panels for user-instrument interaction, and bar code readers to identify vials and experiments. The software, on the other hand, is a complex mosaic of different elements, each of which has a specific task to accomplish. These building blocks include the real-time acquisition, archiving, networking, processing, modelling, sensor output presentation and user interfaces. Our goal is to develop, integrate and optimize all these components to produce a viable and working device. The prototypes evolved from an offline, portable sensor equipped with a single high-resolution CCD camera and high-quality optics, to distributed online sensors with multiplexed CCD cameras and affordable optics. The acquisition <b>board</b> <b>digitizes</b> in real time the images from one to twelve multiplexed high resolution cameras. Several operational requirements must be met. First, a fault-tolerant and stable control over the input devices and control devices must be provided. Secondly, acquisition timing errors should be minimized as a trade-off between performance and the use of a low-cost, general-purpose, industry-standard operating system such as Microsoft Windows NT. Finally, in order to reduce development time and increase code reusability, a common abstraction layer is designed to provide for flexible use with various types of digitizers and cameras. As part of a distributed detection network, each sensor is able to exchange data with other "trusted" sensors and users, and to allow remote control of certain tasks. The sensor may be seen as a node capable of transmitting and receiving acquired or processed data to a distant device (another sensor, a workstation or a PDA) for visualization, inspection and decision-making by a front-end user. Each node on the network provides a set of complementary services including data acquisition, data processing, communication and system. The mandatory system service monitors the local system performance and manages data archiving. The communication service connects the various services on the network by enabling message-passing, file transfer and caching. The sensor network integrates a lightweight, interoperable and flexible RPC (Remote Procedure Call) protocol to achieve real-time control and monitoring of these distributed resources. A reliable embedded database system is used to store metadata bound to acquired and processed images. This database is also used to maintain information on neighbor nodes, and to check access credentials of available local services. Finally, by adding store-and-forward messaging capabilities, the application can be extended to work in wireless and mobile networks...|$|R

