91|5091|Public
5000|$|Supply <b>item</b> <b>data</b> {{needed for}} {{top-level}} logistics and engineering analysis ...|$|E
5000|$|Improve {{access to}} {{historical}} <b>item</b> <b>data</b> across {{the life cycle}} from system design to disposal ...|$|E
5000|$|This {{data type}} has the {{advantage}} over arrays that it is infinitely expandable. Data are extracted using the operations first, butfirst, last, butlast, butmember, member and <b>item.</b> <b>Data</b> elements are added using sentence fput and lput.|$|E
40|$|To improve data {{accessibility}} in ad hoc networks, {{in our previous}} work we proposed three methods of replicating <b>data</b> <b>items</b> by considering the data access frequencies from mobile nodes to each <b>data</b> <b>item</b> and the network topology. In this paper, we extend our previously proposed methods to consider the correlation among <b>data</b> <b>items.</b> Under these extended methods, the data priority of each <b>data</b> <b>item</b> is defined based on the correlation among <b>data</b> <b>items,</b> and <b>data</b> <b>items</b> are replicated at mobile nodes with the data priority. We employ simulations {{to show that the}} extended methods are more efficient than the original ones. ...|$|R
5000|$|Each Wave {{consists}} {{of a number of}} individual display places which are used to hold <b>Data</b> <b>Items.</b> Each <b>Data</b> <b>Item</b> on the Wave is then represented by an [...] "Icon".|$|R
40|$|A {{method of}} {{representing}} {{a group of}} <b>data</b> <b>items</b> comprises, for each of a plurality of <b>data</b> <b>items</b> in the group, determining the similarity between said <b>data</b> <b>item</b> and each of a plurality of other <b>data</b> <b>items</b> in the group, assigning a rank to each pair {{on the basis of}} similarity, wherein the ranked similarity values for each of said plurality of <b>data</b> <b>items</b> are associated to reflect the overall relative similarities of <b>data</b> <b>items</b> in the group...|$|R
50|$|Interior tree nodes {{are simply}} flat lists of key-pointer pairs, where the pointer is the logical block number {{of a child}} node. Leaf nodes contain item keys packed into {{the front of the}} node and <b>item</b> <b>data</b> packed into the end, with the two growing toward each other as the leaf fills up.|$|E
50|$|In {{the absence}} of such a system-based {{internal}} control, the item creation process must include a suitable administrative control through the detailed checking, by a responsible officer, of all fields entered for the new item, by comparing a print-out taken from the system with the <b>item</b> <b>data</b> entry sheet, and ensuring that any corrections in the item description (and other similar fields where no system control is possible) are promptly carried out.|$|E
50|$|BAI, or the BAI {{file format}}, is a file format for {{performing}} electronic cash management balance reporting. The BAI format {{was developed and}} previously maintained by the Bank Administration Institute (BAI). One common application of the BAI format is for use by banks to transmit returned <b>item</b> <b>data</b> to customers (for example, checks which have been marked insufficient funds (NSF)). The current release is Cash Management Balance Reporting Specifications Version 2, typically referred to as BAI2.|$|E
50|$|In a list, {{the order}} of <b>data</b> <b>items</b> is significant. Duplicate <b>data</b> <b>items</b> are permitted. Examples of {{operations}} on lists are searching for a <b>data</b> <b>item</b> in the list and determining its location (if it is present), removing a <b>data</b> <b>item</b> from the list, adding a <b>data</b> <b>item</b> to the list at a specific location, etc. If the principal operations on the list are to be the addition of <b>data</b> <b>items</b> {{at one end and}} the removal of <b>data</b> <b>items</b> at the other, it will generally be called a queue or FIFO. If the principal operations are the addition and removal of <b>data</b> <b>items</b> at just one end, it will be called a stack or LIFO. In both cases, <b>data</b> <b>items</b> are maintained within the collection in the same order (unless they are removed and re-inserted somewhere else) and so these are special cases of the list collection. Other specialized operations on lists include sorting, where, again, {{the order of}} <b>data</b> <b>items</b> is of great importance.|$|R
50|$|In COBOL, union <b>data</b> <b>items</b> {{are defined}} in two ways. The first uses the RENAMES (66 level) keyword, which {{effectively}} maps a second alphanumeric <b>data</b> <b>item</b> {{on top of}} the same memory location as a preceding <b>data</b> <b>item.</b> In the example code below, <b>data</b> <b>item</b> PERSON-REC is defined as a group containing another group and a numeric <b>data</b> <b>item.</b> PERSON-DATA is defined as an alphanumeric <b>data</b> <b>item</b> that renames PERSON-REC, treating the data bytes continued within it as character data.|$|R
5000|$|Other {{operations}} perform {{more sophisticated}} tasks, such as [...] which rearranges n <b>items</b> of <b>data</b> {{such that the}} nth node gets the nth <b>item</b> of <b>data</b> from each.|$|R
50|$|There is one {{checksum}} item per contiguous run of allocated blocks, with per-block checksums packed end-to-end {{into the}} <b>item</b> <b>data.</b> If {{there are more}} checksums than can fit, they spill rightwards over into another checksum item in a new leaf. If the file system detects a checksum mismatch while reading a block, it first tries to obtain (or create) a good copy of this block from another device if internal mirroring or RAID techniques are in use.|$|E
50|$|One {{of the key}} {{organizations}} driving wider {{implementation of}} two-dimensional barcodes is GS1 http://www.gs1.org/ GS1's main activity {{is the development of}} the GS1 System, a series of standards designed to improve supply chain management. The GS1 System is composed of four key product areas: Barcodes (used to automatically identify things), eCom (electronic business messaging allowing automatic electronic transmission of data), GDSN (Global Data Synchronisation Network which allows partners to have consistent <b>item</b> <b>data</b> in their systems at the same time) and EPCglobal (which uses RFID technology to immediately track an item).|$|E
50|$|The {{post-test}} {{open ended}} items would ask interns to respond to: 1) To what degree {{and for what}} reason(s) their science course encouraged them to seriously consider teaching upper level/middle level science; and 2) to what degree and for what reason(s) their science course encouraged them to teach science in an inquiry-based manner. The sample includes all the teacher education interns who expressed interest in teaching upper elementary/middle level science and who are enrolled in the designated transformative science content course at both UM and BSU during Project Year 2 (28). The Likert <b>item</b> <b>data</b> has been quantitatively analyzed to report means by item and to look for statistically significant changes between the pre-and post-administrations of the survey. The open-ended items were analyzed using the qualitative technique of open coding to look for trends and patterns. Data was disaggregated to highlight minority students’ responses.|$|E
50|$|In a tree, {{which is}} {{a special kind of}} graph, a root <b>data</b> <b>item</b> has {{associated}} with it some number of <b>data</b> <b>items</b> which in turn have associated with them some number of other <b>data</b> <b>items</b> in what is frequently viewed as a parent-child relationship. Every <b>data</b> <b>item</b> (other than the root) has a single parent (the root has no parent) and some number of children, possibly zero. Examples of operations on trees are the addition of <b>data</b> <b>items</b> so as to maintain a specific property of the tree to perform sorting, etc. and traversals to visit <b>data</b> <b>items</b> in a specific sequence.|$|R
30|$|Data {{entry and}} {{analysis}} were done using SPSS and STATA respectively. Before the analysis data editing {{was done to}} get rid of non response <b>items.</b> <b>Data</b> analysis was done using tobit regression model.|$|R
40|$|The <b>item</b> {{response}} <b>data</b> is the nm-dimensional data {{based on}} the responses made by m examinees to the questionnaire consisting of n items. It is used to estimate the ability of examinees and item parameters in educational evaluation. For estimates to be valid, the simulation input data must reflect reality. This paper presents the effective combination of the genetic algorithm (GA) and Monte Carlo methods for the generation of <b>item</b> response <b>data</b> as simulation input data similar to real data. To this end, we generated four types of <b>item</b> response <b>data</b> using Monte Carlo and the GA and evaluated how similarly the generated <b>item</b> response <b>data</b> represents the real <b>item</b> response <b>data</b> with the <b>item</b> parameters (item difficulty and discrimination). We adopt two types of measurement, which are {{root mean square error}} and Kullback-Leibler divergence, for comparison of item parameters between real data and four types of generated data. The results show that applying the GA to initial population generated by Monte Carlo is the most effective in generating <b>item</b> response <b>data</b> that is most similar to real <b>item</b> response <b>data.</b> This study is meaningful in that we found that the GA contributes to the generation of more realistic simulation input data...|$|R
50|$|A pre-test, {{post-test}} mixed methodology {{study of}} the Project NEXUS cohort’s beliefs and teaching practices was conducted, disaggregating data to highlight {{the responses of the}} minority interns. The existing valid and reliable instrument developed earlier by McGinnis et al. was used (“Attitudes and Beliefs About the Nature of and the Teaching of Mathematics and Science”) to measure the variables. In addition, add the following open-ended items were added to the pre-test: 1) What grade levels do you want to teach science? 2) How do you intend to teach science? The following open-ended items were added to the post-test: 1) What grade levels do you want to teach science? 2) How do you intend to teach science?, and 3) and 2) to what degree and for what reason(s) did their science methods course and their field based PDS placement encourage them to teach science in an inquiry-based manner that included a focus on data management and statistical analysis? The Likert <b>item</b> <b>data</b> was quantitatively analyzed to report means by item and to look for statistically significant changes between the pre-and post-administrations of the survey. The open-ended items were analyzed using the qualitative technique of open coding to look for trends and patterns. Data were disaggregated to highlight minority students’ responses. In addition, a number of qualitative case studies (n= 10) were conducted of UM and BSU interns as they experienced in their senior year the semester long transformative science methods course and their yearlong PDS urban field placements. At least 6 of the participants were minority teacher candidates, representing both BSU and UM (3 from each institution). Data consisted of ongoing audiotaped and transcribed interviews with the participating interns, weekly intern email journal reflections on their experiences, the science instructors’ observations and reflections on the interns’ participation in the science methods course, and researcher field notes. Open coding, analytic induction and constant comparison were used to analyze the data. Also, during their science methods course, a field- tested HOSO calendar product was used as a research data collection instrument regarding the interns’ understanding of data management and statistical analysis as well as the role of informal science in promoting Standards-based science teaching and learning.|$|E
30|$|<b>Item</b> <b>data</b> {{storage is}} {{flexible}} {{not only with}} respect to storing domain-specific details required for presentation and answer evaluation, but also with respect to storing item parameters required for different IRT-algorithms. The {{same is true for}} parameters required to correctly evaluate polytomous items.|$|E
40|$|Computer systems program {{specifications}} {{are presented}} for the modular space station information management system. These are {{the computer program}} contract end <b>item,</b> <b>data</b> bus system, data bus breadboard, and display interface adapter specifications. The performance, design, tests, and qualification requirements are established {{for the implementation of}} the information management system. For Vol. 1, see N 72 - 19972...|$|E
50|$|A <b>data</b> <b>item</b> {{describes}} an atomic state {{of a particular}} object concerning a specific property {{at a certain time}} point. A collection of <b>data</b> <b>items</b> for the same object at the same time forms an object instance (or table row). Any type of complex information can be broken down to elementary <b>data</b> <b>items</b> (atomic state). <b>Data</b> <b>items</b> are identified by object (o), property (p) and time (t), while the value (v) is a function of o, p and t: v = F(o,p,t).|$|R
5000|$|... server actions - {{such as a}} {{notification}} - {{triggered by}} an update to a <b>data</b> <b>item</b> or <b>data</b> source included into a data supply chain ...|$|R
40|$|Abstract. 4 -ary vector {{expression}} {{was defined by}} 3 -ary vector to describe subject and <b>data</b> <b>item</b> in dataspace. Association method between subject and <b>data</b> <b>item</b> was represented. Correlation of <b>data</b> <b>item</b> was defined by 4 -ary vector. Correlation and association way between <b>data</b> <b>items</b> were represented by 4 -ary vector. The validity of these methods was verified in technical document library...|$|R
30|$|In {{the former}} section, we have {{introduced}} our architecture and a prototypical implementation with a test engine using catR. We {{were able to}} show that the CAT-oriented requirements R 1 –R 3 could be met by our architecture. The technical feasibility of integrating the platform with other systems on presentation or data layer (R 4) has been shown in principle by adopting the Vaadin framework for displaying information and XML as one potential form of <b>item</b> <b>data</b> representation.|$|E
30|$|The <b>Item</b> <b>Data</b> Handling {{component}} {{is used to}} load and manage the items {{that are to be}} used in a test. The test engine accesses this component when retrieving data necessary for the selection of a next item. As a test not necessarily only comprises items of a single type, the ways to address items and evaluate answers given by examinees need to be generic. This component thus consists of a set of interfaces that need to be implemented for domain-specific item types.|$|E
40|$|By {{means of}} simple {{numerical}} examples it is demonstrated how {{the value of}} coefficient alpha {{is determined by the}} size and sign of the item intercorrelations, the dimensionality of the items, and the number of items. Relatively high alphas may be obtained for multidimensional <b>item</b> <b>data</b> (as obtained under a violation of essential tau-equivalence). Dimensionality analyses should therefore precede internal-consistency analyses if unidimensional tests are required. Such analyses also may alert one to the possibility of negative alpha values. Alternative coefficients are mentioned for situations when essential tau-equivalence is in doubt...|$|E
5000|$|... {{assigned}} by a data creator or generator to a <b>data</b> <b>item</b> or a <b>data</b> source ...|$|R
5000|$|The [...] "Point" [...] message defines two {{mandatory}} <b>data</b> <b>items,</b> x and y. The <b>data</b> <b>item</b> {{label is}} optional. Each <b>data</b> <b>item</b> has a tag. The tag is defined after the equal sign. For example, x has the tag 1.|$|R
50|$|In a multiset (or bag), {{like in a}} set, {{the order}} of <b>data</b> <b>items</b> does not matter, {{but in this case}} {{duplicate}} <b>data</b> <b>items</b> are permitted. Examples of operations on multisets are the addition and removal of <b>data</b> <b>items</b> and determining how many duplicates of a particular <b>data</b> <b>item</b> are present in the multiset. Multisets can be transformed into lists by the action of sorting.|$|R
40|$|Analyzing {{extended}} twin-family {{data with}} off-the-shelf Bayesian software, such as JAGS, requires the genetic model to be specifed as a directed acyclic graph. This article presents {{a method that}} makes the respecification of a genetic model including phenotypic assortment and cultural transmission feasible. The developed method entails a Cholesky factorization of the expected covariance matrix. In this way, the genetic model can be easily extended with an item response measurement model to analyze raw <b>item</b> <b>data</b> for more accurate parameter estimates. Simulation studies show that this method is able to recover the simulated parameter values...|$|E
40|$|The {{development}} of approaches which offer an integral view of packaging {{and the natural}} environment is outlined. The difference between the Environmental Impact Assessment of an industrial plant and the analysis of industrial product is pointed out. It is shown how characteristics of the environmental impact being relevant to a package should be chosen. A model for calculating the environmental impact within {{the history of a}} package is presented. The model offers advantages in clarity and calculation effort as well as sensitivity statements of the resulting environmental impact to <b>item</b> <b>data</b> are facilitated...|$|E
40|$|Preliminary {{studies on}} data mining focus on finding {{association}} rules from transaction databases containing items without relationships among them. However, relationships among items often exist in real applications. Most {{of the previous}} works only concern about Is-A hierarchy. In this paper, hierarchical relationships include a Has-A hierarchy and multiple Is-A hierarchies are discussed. The proposed method first reduces a Has-A & Is-A hierarchy into an extended Has-A hierarchy using the IsA-Reduce algorithm. The quantitative data is transformed into fuzzy items. The RPFApriori algorithm is then applied to find fuzzy association rules from the fuzzy <b>item</b> <b>data</b> and the extended Has-A hierarchy...|$|E
500|$|An 88 level-number {{declares}} a [...] (a so-called 88-level) {{which is}} true when its parent <b>data</b> <b>item</b> contains one of the values specified in its [...] clause. For example, the following code defines two 88-level condition-name items that are true or false depending on the current character data value of the [...] <b>data</b> <b>item.</b> When the <b>data</b> <b>item</b> contains a value of , the condition-name [...] is true, whereas when it contains a value of [...] or , the condition-name [...] is true. If the <b>data</b> <b>item</b> contains some other value, both of the condition-names are false.|$|R
30|$|We {{found that}} the {{proposed}} algorithm is presently in the broadcast structure. The wireless broadcast scheduling has been considered the <b>data</b> <b>item</b> frequency of the fixed and it has an unreasonable supposition. The <b>data</b> <b>item</b> frequency would be {{the request of the}} client for a change under the factual dynamic environments. Each of the <b>data</b> <b>item</b> has a frequency value itself and the each frequency of <b>data</b> <b>item</b> should been computed for its weight value and adjusted for dynamic broadcast adaptive so the frequency of <b>data</b> <b>item</b> has no fixed probability value.|$|R
5000|$|An 88 level-number {{declares}} a [...] (a so-called 88-level) {{which is}} true when its parent <b>data</b> <b>item</b> contains one of the values specified in its [...] clause. For example, the following code defines two 88-level condition-name items that are true or false depending on the current character data value of the [...] <b>data</b> <b>item.</b> When the <b>data</b> <b>item</b> contains a value of , the condition-name [...] is true, whereas when it contains a value of [...] or , the condition-name [...] is true. If the <b>data</b> <b>item</b> contains some other value, both of the condition-names are false.|$|R
