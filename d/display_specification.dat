5|56|Public
50|$|Miracast {{support is}} built into Android 4.2 or later and {{starting}} with Android 4.4, devices can be certified to the Wi-Fi Alliance <b>Display</b> <b>Specification</b> as Miracast compatible.|$|E
5000|$|Web browsers {{follow the}} HTML <b>display</b> <b>specification</b> and for programmers' {{convenience}} ignore runs of white space when displaying them. This convention originally {{comes from the}} underlying SGML standard, which collapses multiple spaces because of the clear division between content and layout information. [...] In order to force a web browser to display multiple spaces, a special character sequence must be used (such as [...] "" [...] for an en-space followed by a thin space, [...] "" [...] for an em-space, or [...] "" [...] for two successive full spaces). However, using a non-breaking space can lead to uneven justified text and additional unwanted spaces or line breaks in the text in certain programs. [...] Alternatively, sentence spacing can be controlled in HTML by separating every sentence into a separate element (e.g., a span), and using CSS to finely control sentence spacing. [...] This is seldom done in practice.|$|E
40|$|Componentisation of {{software}} promises to deliver cost efficiency {{that has not}} been achieved through object orientation [19]. PAC [5] is a popular conceptual architecture for structuring user interface software in an object oriented fashion. This paper reports our experience of adapting and refining PAC as a component architecture in the context of consumer electronics, and On-screen Displays in particular. The paper describes a structured scheme for the specification of user interface software components, distinguishing `look' and `feel' specific components, and fostering their modular development and reuse. Keywords. PAC, user interface, software architecture, on-screen <b>display,</b> <b>specification.</b> 1 Introduction This paper discusses a component architecture and a specification scheme for OnScreen Displays (OSD), i. e. graphical user interfaces for consumer electronics devices. The OSD may be supported, e. g., by a `Set-Top Box' which is a device that displays, on an analogue te [...] ...|$|E
40|$|Luminance, {{contrast}} ratio and amplitude resolution are rapidly growing <b>display</b> <b>specifications.</b> Through {{a series of}} human factor studies we have developed simple guidelines for these specifications including viewer preference for luminance, optimal {{contrast ratio}} and amplitude resolution under realistic conditions. 1...|$|R
40|$|The rapid {{development}} of graphics technology allows for greater flexibility in aircraft displays, but display evaluation techniques have not kept pace. Historically, display evaluation {{has been based}} on subjective opinion and not on the actual aircraft/pilot performance. Existing electronic <b>display</b> <b>specifications</b> and evaluation techniques are reviewed. A display rating technique analogous to handling qualities ratings was developed and is recommended for future evaluations. The choice of evaluation pilots is also discussed and the use of a limited number of trained evaluators is recommended over the use {{of a large number of}} operational pilots...|$|R
50|$|Most Universe toys lacked {{technical}} specifications on their boxes, {{but many of}} the toys <b>displayed</b> technical <b>specifications</b> that appeared on the Transformers' official website or in the short lived Transformers: Universe and Wreckers comic books.|$|R
40|$|In {{this paper}} we discuss some design {{principles}} that will aid in the design and querying of multi-media databases. We use an object-relational data model and argue that multi-media objects should normally have a special attribute called `core' which stores the real object itself in contrast to the abstraction which is reflected {{in the rest of the}} attributes. We present an extension to the ER Diagram that takes advantage of the `core' notion to facilitate design of multi-media databases. We discuss some desirable features in a query language for multimedia databases: simplifications like the use of path expressions and implicit use of functions (methods) as attributes, and explicit specification of the display layout and format either at the data definition level or query specification level. To materialize this last feature, we propose a <b>display</b> <b>specification</b> extension to SQL (SQL+D) that we have implemented. 1 Introduction A Multi-media database (MMDB) 1 differs from a conventiona [...] ...|$|E
40|$|Remote-sensing {{systems that}} map {{aircraft}} icing {{conditions in the}} flight path from airports or aircraft would allow icing to be avoided and exited. Icing remote-sensing system development requires consideration of the operational environment, the meteorological environment, and the technology available. Operationally, pilots need unambiguous cockpit icing displays for risk management decision-making. Human factors, aircraft integration, integration of remotely sensed icing information into the weather system infrastructures, and avoid-and-exit issues need resolution. Cost, maintenance, power, weight, and space concern manufacturers, operators, and regulators. An icing remote-sensing system detects cloud and precipitation liquid water, drop size, and temperature. An algorithm is needed to convert these conditions into icing potential estimates for cockpit <b>display.</b> <b>Specification</b> development requires that magnitudes of cloud microphysical conditions and their spatial and temporal variability be understood at multiple scales. The core of an icing remote-sensing system is the technology that senses icing microphysical conditions. Radar and microwave radiometers penetrate clouds and can estimate liquid water and drop size. Retrieval development is needed; differential attenuation and neural network assessment of multiple-band radar returns are most promising to date. Airport-based radar or radiometers are the most viable near-term technologies. A radiometer that profiles cloud liquid water, and experimental techniques to use radiometers horizontally, are promising. The most critical operational research needs are to assess cockpit and aircraft system integration, develop avoid-and-exit protocols, assess human factors, and integrate remote-sensing information into weather and air traffic control infrastructures. Improved spatial characterization of cloud and precipitation liquid-water content, drop-size spectra, and temperature are needed, {{as well as an}} algorithm to convert sensed conditions into a measure of icing potential. Technology development also requires refinement of inversion techniques. These goals can be accomplished with collaboration among federal agencies including NASA, the FAA, the National Center for Atmospheric Research, NOAA, and the Department of Defense. This report reviews operational, meteorological, and technological considerations in developing the capability to remotely map in-flight icing conditions from the ground and from the air...|$|E
50|$|GPU-Z is a {{lightweight}} utility {{designed to provide}} information about video cards and GPUs. The program <b>displays</b> the <b>specifications</b> of the GPU and its memory, and displays temperature, core frequency, memory frequency, GPU load and fan speeds.|$|R
5000|$|Unscaled bitmap fonts {{always give}} {{exactly the same}} output when {{displayed}} on the same <b>specification</b> <b>display</b> ...|$|R
50|$|MCCS {{requires}} a bidirectional communication protocol like Display Data Channel between host and <b>display,</b> although the <b>specification</b> does not favour any particular protocol.|$|R
5000|$|The {{flexible}} {{electronic paper}} display technology co-developed by Arizona State University and HP employs a manufacturing process developed by HP Labs called Self-Aligned Imprint Lithography (SAIL). The screens are made by layering stacks of semi-conductor materials and metals between pliable plastic sheets. The stacks need to be perfectly aligned and stay that way. Alignment proves difficult during manufacturing when heat during manufacturing can deform the materials and when the resulting screen also needs to remain flexible. The SAIL process gets around this by ‘printing’ the semiconductor pattern on a fully composed substrate, so that the layers always remain in perfect alignment. The limitation of the material the screen is based on allows only a finite amount of full rolls, hence limiting its commercial application as a flexible <b>display.</b> <b>Specifications</b> provided regarding the prototype display are as follows: ...|$|R
40|$|Abstract- In this paper,we {{describe}} an investigation exploring user experiences of accessing streamed multimedia content, when that content is tailored according to perceptual, device and location characteristics. To this end, {{we have created}} pre-defined transmission profiles and stream perceptually tailored multimedia content to three different locations, each characterised by different infotainment requirements. In the light of our results, we propose that multimedia transmission to mobile and wireless devices should be made based on pre-defined profiles, which contains a combination of static (perceptual, device type, CPU speed, and <b>display</b> <b>specifications)</b> and dynamic information (streamed content type location of the device/user, context of the device/user). The evaluation of such a system showed that the users and service providers can gain from such an approach considerably, as user perceptions of quality were not detrimentally affected by QoS degradations. Consequently, service providers can utilise this information to effectively manage local network traffic and bandwidth. I...|$|R
40|$|We propose here a loosely-bound SQL {{extension}} {{that will}} allow users to include high-level <b>display</b> <b>specifications</b> with an SQL query, particularly when dealing with multimedia databases. This way, the user can specify both the data {{that needs to be}} extracted and how it should be displayed. We also describe an architecture {{that will allow}} a relatively simple implementation of dynamic query browsers using the proposed query language on stand-alone applications or Web pages. We have implemented a major subset of our proposed extension and are working on a complete prototype. 1 Introduction At the time when the concept of a "database" came into being, nobody imagined the extent and variety of data that will eventually be stored in such structures. To display data as columns and rows of text is no longer sufficient these days. Multimedia databases, with their rich content of images, audio, video and animations, demand much more. Multimedia information is not necessarily stored using a differ [...] ...|$|R
40|$|In {{this paper}} we {{investigate}} human binocular depth perception on 3 D electronic display technologies. Our study {{is motivated by}} {{the increasing use of}} 3 D displays in applications, including geo-science and medicine, where critical decisions are made using fine binocular depth judgements. We predict subject performance for a depth judgement task using published specifications for seven different 3 D displays. A repeated measures, within subjects experimental design is used to determine the effect that display and binocular disparity have on subject scores in the task. We find that there is reliable variation in participant performance with display and disparity, however this variation is not always consistent with our predictions from the <b>display</b> <b>specifications.</b> We also present subjective results that suggest user preference for a 3 D display is not always a reliable guide to their ability to perform the task. We conclude that care must be taken in selecting 3 D display systems for tasks that critically rely on human depth judgement...|$|R
40|$|In a fast-paced {{clinical}} trials computing environment, programmers often {{need to create}} tables, listings, and figures within a limited time span. In these cases, available working data sets are paramount to insure quality deliveries. The SAS ® system offers many tools for simulating data which allow users to pilot their display programs prior to receiving real working data sets. This article explores the use of SAS ® functions and macro processing to generate artificial data using gamma and binomial random variates. The SAS ® macro {{presented in this article}} uses these functions to simulate patient-level and adverse event (AE) data sets. The results of these simulations are then used to populate abbreviated tables and listings. By having artificial data similar in structure to what <b>display</b> <b>specifications</b> provide, statistical programmers can verify the accuracy of their code prior to receiving real data. While this article targets a clinical computing audience, the techniques are applicable to a broad range of computing scenarios...|$|R
50|$|The two manual organ {{was built}} in 1937 by Henry Willis II of Henry Willis & Sons. The pipes are {{positioned}} in an elevated case on the north wall of the chancel, exploiting the building's excellent acoustic. The case was designed by Dykes Bower, with the 16 ft Open Diapason pipes on <b>display.</b> Its <b>specification</b> {{can be found on}} the church's official website (see external links).|$|R
40|$|Marine Information Objects (MIOs) {{consist of}} chart- and navigation-related {{information}} that supplement the minimum information required by ECDIS {{to ensure safety}} of navigation at sea. As related {{to the use of}} Electronic Navigational Chart (ENC) data, MIOs are additional, non-mandatory information not already covered by existing IMO, IHO, or IEC standards. Such information includes ice coverage, tide/water level, current flow, meteorological, oceanographic, and marine habitats. A Harmonization Group on MIOs (HGMIO) has been established between IHO and IEC to recommend additional data and <b>display</b> <b>specifications</b> that may be incorporated into future editions of IHO and IEC standards. This paper discusses the scope of MIO activities, particularly {{as it relates to the}} challenges of converting a wide variety of MIO-related information into suitable data formats for use with a type-approved ECDIS. This includes information that will be provided via shipboard Automated Identification Systems (AIS) and Vessel Traffic Service (VTS) centers. In particular, there are significant challenges related to developing data formats that deal with time-varying information (i. e., X, Y, Z and time), simultaneous display of MIOs with other chart and navigation-related information, and the means/process to disseminate in a timely manner...|$|R
40|$|Viewing {{document}} {{images on}} small devices is a challenge. When showing {{a region of}} a page for reading on a small display a page overview is generally lost. If a page overview is desired, typically a low resolution version of the image fitting a small array of pixels- a thumbnail- is provided. Whereas the readability of text in thumbnails is often lost, document layout information {{may or may not}} be preserved. Preserving document layout information in thumbnails is the goal of this paper. We derive models for controlling the preservation of document layout information in thumbnails by determining the size of a thumbnail depending on the layout content of the document. The downsampling factor for a document image will depend on its layout information, such that layout units will be visually separate after scaling. The link between scaling factors and document layout information is created through novel models, White Space Graphs and White Space Trees. These models enable control over enhancement and suppression of document layout structures during scaling. Minimal scaling factors can be derived that assure visual separability of a controlled set of layout units after scaling. Those scaling factors depends on the document content as well as user and <b>display</b> <b>specifications.</b> Keywords: Thumbnail, document layout, Voronoi diagram, White Space Graph. 1...|$|R
50|$|The {{idea for}} Line Describing a Cone came to McCall on his voyage from London to New York, where he {{produced}} {{the film in}} 1973. Though he had already created {{a number of other}} 16mm films, Line allowed him to actualize his ideas on the relationship between viewer and film and the medium of film itself. The thirty-minute film begins with a single white dot projected onto a black surface. As time progresses, the dot begins to form a curved line, tracing the circumference of a circle {{until the end of the}} line reaches its starting point. Meanwhile, particles in the air reveal the path of light in the space between the projector and the wall, making visible a cone of light. If the artist's <b>display</b> <b>specifications</b> are met, this beam of light projects between thirty and fifty feet. The circle that is projected onto the surface sits approximately twelve inches above the ground, and its diameter spans seven to nine feet. The exhibition space lacks seating, inviting the viewer to interact with the ray of light beaming from the projector to the screen. When multiple spectators view the piece together, these encounters with the light, at once an interruption and component of the piece, become an interaction with other audience members.|$|R
40|$|Video {{transmission}} over wireless links is {{an emerging}} application which involves a time varying channel. In this paper, we introduce a scalable video compression system using wavelets {{in which the}} encoder is to operate independently of decoder and transmission bandwidth limitations. Motion estimation is done in a multiresolution framework using the spatial and temporal correlation of the motion vectors to reduce the computations in a significant way. To remove the discontinuities contained in the displaced frame difference signal produced by the conventional motion compensation, raised cosine overlapped block motion compensation (OBMC) is used. The wavelet coeffi- cients corresponding to a spatial location are framed into a block and the block is adaptively quantized. The quantized coefficients of a block are represented with zerotree encoding and modified scanning methods. The symbols and quantized coefficients or run lengths and quantized coefficients are losslessly encoded using Huffman codes, which are developed. It is shown that modified scanning outperforms zerotree encoding. With scalable algorithms, only one original compressed video stream is generated. Different subsets of the bit stream can be selected at the de- coder to support a multitude of <b>display</b> <b>specifications</b> such as bit rate, spatial resolution, quality level, and decoding hardware complexity. This type of scheme is very useful for both constant and variable bit rate transmission over mobile communication channels as well as video distribution over heterogeneous multi cast networks...|$|R
50|$|The Samsung Galaxy Pocket Duos is an Android {{smartphone}} {{manufactured by}} Samsung that {{was released in}} September 2012. The handset is budget-oriented, sporting a relatively small 2.8-inch LCD <b>display.</b> Its <b>specifications</b> are {{similar to that of}} the original Samsung Galaxy Pocket, only that it is dual sim capable. The Pocket Duos is powered by an 832 MHz processor and offers a set of connectivity options including 3G, Wi-Fi and Bluetooth 3.0. Internally, it comes with 3 GB of storage which can be further expanded to up to 32 GB using a microSD card, and with 1200 mAh Li-ion battery.|$|R
40|$|Computer systems program {{specifications}} {{are presented}} for the modular space station information management system. These are {{the computer program}} contract end item, data bus system, data bus breadboard, and <b>display</b> interface adapter <b>specifications.</b> The performance, design, tests, and qualification requirements are established {{for the implementation of}} the information management system. For Vol. 1, see N 72 - 19972...|$|R
5000|$|GSMArena {{gave the}} Lumia 950 XL a very {{favorable}} review, praising the <b>specifications,</b> <b>display</b> and camera, and commending Microsoft's unification of the UI and app stores of Windows 10 on mobile and desktop devices. The polycarbonate design {{was seen to}} be somewhat lacking given the price, with the reviewer saying that the phone [...] "performs like a flagship champ, it's priced like a flagship champ, but it doesn't look the part".|$|R
40|$|The user {{interface}} is the {{component of a}} software system that connects two very complex system: humans and computers. Each of these two systems impose certain requirements on the final product. The user is the judge of the usability and utility of the system; the computer software and hardware are the tools with which the interface is constructed. Mistakes are sometimes made in designing and developing {{user interface}}s because the designers and developers have limited knowledge about human performance (e. g., problem solving, decision making, planning, and reasoning). Even those trained in user interface design make mistakes because {{they are unable to}} address all of the known requirements and constraints on design. Evaluation of the user inter-face is therefore a critical phase of the user interface development process. Evaluation should not be considered the final phase of design; but it should be part of an iterative design cycle with the output of evaluation being feed back into design. The goal of this research was to develop a set of computer-based tools for objectively evaluating graphical user interfaces. The research was organized into three phases. The first phase resulted in the development of an embedded evaluation tool which evaluates the usability of a graphical user interface based on a user's performance. An expert system to assist in the design and evaluation of user interfaces based upon rules and guidelines was developed during the second phase. During the final phase of the research an automatic layout tool {{to be used in the}} initial design of graphical inter- faces was developed. The research was coordinated with NASA Marshall Space Flight Center's Mission Operations Laboratory's efforts in developing onboard payload <b>display</b> <b>specifications</b> for the Space Station...|$|R
40|$|The {{development}} of mathematical {{models for the}} analysis of physiological data can be a difficult and time consuming procedure, especially when limited by software. This paper describes a minicomputer software system called BLD which facilitates data input, <b>display,</b> and model <b>specification</b> and generalized linear and non-linear regression. The package also includes an APL-like interpreter which allows convenient array-oriented data manipulation. BLD {{has proven to be a}} flexible, user-oriented tool, convenient for both interactive and batch operation modes...|$|R
40|$|The study {{described}} in this paper originally aimed at studying the human factors problems of airborne separation in a Free Flight environment. However, to define the Free Flight environment with sufficient detail, an overall concept was also designed at NLR. This concept includes rules-of-the-sky, conflict detection, a conflict resolution algorithm, cockpit <b>displays,</b> system <b>specification</b> {{as well as an}} assessment of operational implications. The feasibility of the concept has been evaluated in three sub-studies: (i) off-line traffic simulations with very high traffic densities and a total of up to 300 aircraft in the incinity, (ii) a safety analysis comparing the resolution method with current day ATC and (iii) a man-in-the-loop simulator experiment with line pilots in traffic densities up to three times the average West-European traffic density in the particular airspace. None of these studies could refute the feasibility of the achieved Free Flight conceptual design. - 4 NLR -TP- 9825 [...] ...|$|R
40|$|Permission to {{copy and}} <b>display</b> the WS-Addressing <b>Specification,</b> in any medium without fee or royalty is hereby granted, {{provided}} that you {{include the following}} on ALL copies of the WS-Addressing Specification, or portions thereof, that you make: 1. A link or URL to the WS-Addressing Specification at this location 2. The copyright notice {{as shown in the}} WS-Addressing Specification. BEA Systems, IBM and Microsoft (collectively, the “Authors”) each agree to grant you a royalty-free license, under commercially reasonable terms and conditions, to their respective patents that they deem necessary to implement the WS-Addressin...|$|R
5000|$|GSMArena {{rated the}} Lumia 950 very highly, {{saying that the}} phone [...] "lives up to the hype and {{delivers}} on all advertised promises". The review highlighted the <b>specifications,</b> <b>display</b> and camera as being [...] "top-notch" [...] and found both Windows Hello and Continuum to be working [...] "as advertised". While some faults were found with the design, battery life and price, the review concluded with: [...] "Microsoft has done an amazing job with the Lumia 950... It's an eagerly anticipated phone and ... it deserves every bit of praise it gets." ...|$|R
40|$|Hardware Ltd. ProofPower is only {{available}} on Sun 4 machines running Sunview. A version running under Solaris with Motif is currently under development. 4. 1 Editing and <b>Displaying</b> the <b>Specification</b> ProofPower Z specifications are edited using the standard Sunview text editor, using a special Sunview font for HOL and Z developed by ICL. Fixity and syntactic category (ie infix relation, function or generic) of operators is declared {{at top level}} {{and there is a}} special function Π to coerce a schema expression to be interpreted as a predicate; this is not required inside specifications, but only when quoting Z out of context. There are facilities for projecting the prepared specification into a L A T E X source file for typesetting or a Standard ML source file for entry into the ProofPower theorem proving tool. The specifications are referred to as `literate scripts' but this only means that they contain interleaved documentation and formal text; they don't provide the sort of cross-re [...] ...|$|R
30|$|Regardless of {{the basis}} for these {{different}} after-effects, we have shown that they are manifest in predictable ways in the medical images that radiologists are routinely exposed to. Whether they are also manifest {{within the context of}} an actual clinical session or in trained radiologists remains to be tested. However, our work again suggests that adaptation is in principle an important factor in understanding how medical images – or indeed any images – are perceived and could potentially impact decisions based on these perceptions. While there are numerous guidelines for lighting and <b>display</b> <b>specifications</b> in radiological reading rooms (Chawla & Samei, 2007; Harisinghani et al., 2004; Siddiqui, Chia, Knight, & Siegel, 2006), we have noted previously (Kompaniez et al., 2013) that there are few guidelines for specifying how images should be sampled or inspected during a radiological reading. Inspection protocols that control for differential adaptation, such as order effects or exposure history, may aid the visual judgments of the radiologist. Similarly, image processing algorithms that simulate the consequences of adaptation (Webster, 2014), may facilitate medical image perception by pre-adapting and thus optimizing the image for the observer. Finally, how spatial sensitivity is adapted and optimized in the observer may also play a role in understanding the perceptual implications of different imaging modalities, including the differences between projection imaging (e.g. the mammogram images used here) and volumetric imaging such as computed tomography (CT). Radiology has seen a substantial shift towards volumetric imaging over the last 20 – 30 years, with CT and magnetic resonance imaging replacing projection radiography. Metheany, Abbey, Packard, and Boone (2008) showed that anatomy in breast CT images has an amplitude spectrum that is much closer to a spectral slope of[*]−[*] 1. Chen et al. (2015) compared radiologists’ lesion-detection performance in “thin” slice images compared to “thick” projections of the volumetric data. In addition to overall improved performance for slice images compared to projections, they found that humans had higher efficiency relative to a prewhitened matched filter for the task, suggesting that humans are better at reading the images with a spectral slope close to[*]−[*] 1.|$|R
40|$|This {{dissertation}} {{will present}} the full syntax, semantics, and architecture of an extension to the query language SQL. The extended language, SQL+D, allows users to include high-level <b>display</b> <b>specifications</b> within an SQL query, particularly when dealing with multimedia databases. That is, using SQL+D, the user can specify in a query both the data {{that needs to be}} extracted and how it should be displayed, without having to write a program to construct the display. For example, say the user is querying a database that contains information about CS professors, like biographical information and a picture of the professor, plus the research documents authored by him or her, and a video where the professor talks about his or her interests. Using SQL+D, the user is able to specify that he/she wants the name of the professor centered on top, with the picture on the upper left comer, the biographical data below the picture, and a list of his/her research papers on the right. The user can also specify that if the user were to click on a particular research paper, that document would be displayed in full, or that upon clicking on a button, the video is displayed. All of these specifications can be done within the query, with simple commands, without writing a single fine of code. ^ In addition to the capabilities just described, SQL+D allows the specification of temporal presentations with the data extracted from the database. It also allows data to be visualized using charts or graphs, and even as 3 -dimensional virtual worlds where the user can navigate through the data. ^ We also present a semantic model of the most important features of SQL+D. The model is based on a non-Markovian temporal action language called ALAN. We present the full syntax and semantics of ALAN, to provide a means of expressing the behavior of complex, dynamic multimedia displays, modeling both user-initiated actions and system actions as well as temporal presentations, triggers, and data elements that span over time such as video and audio. To the best of our knowledge, ALAN is the first non-Markovian action language presented. ...|$|R
30|$|Column 4 <b>displays</b> an {{alternative}} <b>specification</b> including also {{a full set}} of country effects, on top of year effects, which imply the dropping of time-invariant variables. All coefficients (except that of parliamentary seats held by the government) remain very close to the ones estimated without country effects, but the precision of the estimation decreases in light of reduced degrees of freedom. All in all, we interpret the results of this alternative specification as support for the robustness of our results and proceed by estimating the rest of the results in specifications including year effects but not country effects.|$|R
40|$|The Incubator <b>Display</b> Software Requirements <b>Specification</b> was {{initially}} developed by Intrinsyx Technologies Corporation (Intrinsyx) under subcontract to Lockheed Martin, Contract Number NAS 2 - 02090, for the National Aeronautics and Space Administration (NASA) Ames Research Center (ARC) Space Station Biological Research Project (SSBRP). The Incubator Display is a User Payload Application (UPA) {{used to control}} an Incubator subrack payload for the SSBRP. The Incubator Display functions on-orbit {{as part of the}} subrack payload laptop, on the ground as part of the Communication and Data System (CDS) ground control system, and also as part of the crew training environment...|$|R
40|$|Abstract. General {{standards}} are proposed for specifying fulldome <b>displays.</b> Proposed <b>specifications</b> include brightness, brightness uniformity, color uniformity, contrast, resolution and update rate. A methodology for measuring edge-blend uniformity is proposed, and suggestions {{are made for}} approaching more difficult parameters such as color gamut. In today’s marketplace {{there are a variety}} of fulldome display technologies, each with their own unique visual and functional properties. Display technologies currently in use include cathode ray tube (CRT), digital light processor (DLP), liquid crystal on silicon (LCoS) and laser-based displays including 2 -dimensional scanning (Zeiss) and the new grating light valve (GLV from E&S). The technical trade-offs involved in selecting an appropriate technology are enough to boggle a display engineer, much less an aspiring fulldome theater owner. While there is no substitute for actually seeing the various technologies in action, a common technical language is required if we are to make display technology selection comprehensible to all interested parties. This paper proposes that the industry voluntarily adopts standard language for expressing basic display system characteristics, and standard methods for measuring thes...|$|R
50|$|Chunks {{providing}} {{content information}} include the file origin chunk, which identifies the application that generated the UEF file. Inlay scan chunks, {{intended as a}} file preview, hold a raw bitmap of the cover art although anything beyond a thumbnail can take up more data than a typical game. The UEF author can also provide the text of an instruction booklet or a URL for more information, a short title for <b>display,</b> minimum machine <b>specification</b> and keyboard mapping for the enclosed software; and where a game does not use the whole screen, the coordinates of the visible area can be given. A minority of UEF files available online contain anything in this class but an origin chunk.|$|R
