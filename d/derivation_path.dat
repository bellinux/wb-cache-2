7|59|Public
40|$|This paper {{presents}} {{a new form}} of abduction called global abduction. Usual abduction in logic programming is used to complement unknown information and used in one <b>derivation</b> <b>path</b> in a search tree. We call this kind of abduction local abduction. In this paper, we propose another abduction which is used over paths in a search tree for search control. As far as we know, this is the first attempt to formalize a search control in a logical way. We discuss applications of global abduction by using examples; a formalization of don't-care nondeterminism and a formalization of reuse of the previously obtained result in a di#erent search path...|$|E
40|$|The dynamic {{semantics}} of LOTOS {{are defined}} in terms of axioms and inference rules which generate, from a given behaviour expression, the next possible actions and their resulting behaviour expressions. In this paper, we present a new type of inference rules, which are capable of generating traces of actions leading to a pre-selected action in the specification. These inference rules are guided by the static <b>derivation</b> <b>path</b> of the pre-selected action, which locates the action in the abstract syntactic tree of the current behaviour statically. This allows a considerable reduction of the search space. Such a technique often permits the analysis of divergent specifications that are generally beyond the capabilities of verification tools based on traces...|$|E
40|$|Like {{experiments}} {{performed at}} a laboratory bench, the data {{associated with an}} e-Science experiment are of reduced value if other scientists {{are not able to}} identify the origin, or provenance, of those data. Provenance information is essential if experiments are to be validated and verified by others, or even by those who originally performed them. In this article, we give an overview of our initial work on the provenance of bioinformatics e-Science experiments within myGrid. We use two kinds of provenance: the <b>derivation</b> <b>path</b> of information and annotation. We show how this kind of provenance can be delivered within the myGrid demonstrator WorkBench and we explore how the resulting Webs of experimental data holdings can be mined for useful information and presentations for the e-Scientist...|$|E
5000|$|... #Subtitle level 2: <b>Derivation</b> in the <b>path</b> {{integral}} formulation ...|$|R
40|$|The dynamic {{behaviour}} of a LOTOS specification {{can be described}} as a tree, called behaviour tree, where the nodes represent the states of the behaviour, and the branches represent the possible next actions. Unfortunately, the behaviour tree for a realistic size LOTOS specification can be very large and often has no finite representation. This is the major limitation for the existing LOTOS verification techniques. The main goal of this thesis is to provide a new behaviour tree exploration technique, called Goal-Oriented Execution, {{that can be used to}} check properties of LOTOS specifications by narrowing exploration to a meaningfully selected subset of the tree. In this execution technique, the system derives traces (i. e paths in the behaviour tree) satisfying certain assertions that express temporal ordering of actions and data values properties. Goal-Oriented Execution is a combination of three techniques. The first technique is an automatically generated ADT evaluator/narrower engine. It is capable of evaluating an expression based on a rewriting rule approach, borrowed from functional programming, and deriving solutions to a set of constraints using a narrowing technique, borrowed from logic programming. The second technique is a static analyzer that determines where the given assertions are likely to hold, producing static information called static <b>derivation</b> <b>paths.</b> The third technique, called guided-inference system, involves a new type of inference rules that derive traces using static <b>derivation</b> <b>paths</b> to resolve most non-determinism. Implementation issues of this technique are also discussed, and examples of its usage are provided. The technique is now included in ELUDO, the University of Ottawa LOTOS interpreter...|$|R
50|$|Requirements {{traceability}} is a sub-discipline of requirements management within {{software development}} and systems engineering. Traceability {{as a general}} term {{is defined by the}} IEEE Systems and Software Engineering Vocabulary as (1) {{the degree to which a}} relationship can be established between two or more products of the development process, especially products having a predecessor-successor or master-subordinate relationship to one another; (2) the identification and documentation of <b>derivation</b> <b>paths</b> (upward) and allocation or flowdown paths (downward) of work products in the work product hierarchy; (3) the degree to which each element in a software development product establishes its reason for existing; and (4) discernable association among two or more logical entities, such as requirements, system elements, verifications, or tasks.|$|R
40|$|In {{this paper}} a new {{assertion}} constraint model is proposed and implemented. The model {{is designed to}} enforce and maintain the integrity constraints in mobile database and object data model environments. It has an object assertion model for integrity constraints which {{it is used to}} create classes and collect attributes and their constraints that are derived from multiple composition or inheritance hierarchies. Also it has a compile-time model which keeps the <b>derivation</b> <b>path</b> along with the attributes' relationships. Furthermore, the run-time model enforces integrity constraints, enforcing the logical integrity constraints during the run-time. And a new technique is designed to check the object metadata to detect the object violation before it occurs. However, the model is implemented and tested over set of definitions that check attribute values validity and objects for object-oriented and mobile databases...|$|E
40|$|The {{subject of}} this thesis is {{collection}} and storage of the provenance data in a Grid system. Provenance is defined as <b>derivation</b> <b>path</b> {{of a piece of}} data. Nowadays Grid systems are equipped with tools and components forming collaborative space for science, called virtual laboratories. These modern scientific environments allows for executing in silico experiments in such disciplines as biochemistry, astronomy or quantum physics. In each of those cases, scientists are highly interested in resem-blances between experiments and results, tracing data entities or attaching metadata to obtained results. All these requirements can be fulfilled by tracing, storing and querying provenance in the system. This thesis presents PROToS- provenance tracking system designed to meet specific requirements of the ViroLab virtual laboratory. It is based around semantic modelling of provenance and system’s data and motivated by the Semantic Grid vision. Apart from design and implementation of the PROToS, also integration in challenging envi-ronment of the ViroLab is presented...|$|E
40|$|Managing {{semantic}} heterogeneity is {{a complex}} task. One solution involves matching like terms to each other. We view Match as an operator that takes two graph-like structures (e. g., concept hierarchies or ontologies) and returns a mapping between the nodes of the graphs that correspond semantically to each other. State of the art matching systems (e. g., Cupid) perform well for many real world applications. However, matching systems may produce mappings {{that may not be}} intuitively obvious to human users. In order for users to trust the mappings (and thus use them), they need information about them. Users need access to the sources that were used to determine semantic correspondences between terms and potentially they need to understand how deductions are performed. In this paper we describe how matching systems can explain their answers using the Inference Web (IW) infrastructure. There, S-Match, asemantic matching system, produces proofs for mappings it has discovered. Using the IW browser, users may visualize different explanations including provenance information, the <b>derivation</b> <b>path</b> of the mappings, etc. Thus users can make informed decisions about them. ...|$|E
40|$|When we have noncommutativity among {{coordinates}} (or conjugate momenta), {{we consider}} Wigner's formulation of quantum mechanics, {{including a new}} <b>derivation</b> of <b>path</b> integral formula. We also propose the Moyal star product based on the Dirac bracket in constrained systems. Comment: 10 pages, No figures, Late...|$|R
40|$|Two main {{aspects of}} Partial Evaluation for Prolog {{programs}} are considered: treatment of cuts {{and control of}} recursion. The analysis about cut is exhaustive: we consider occurrences of cut within both conjunctions and disjunctions. We show which restrictions are necessary to safely deal with cut in Partial Evaluation and which transformations are allowed. We define a set of conditions for compile-time execution and remotion of cuts. The safety of these conditions is formally proved. Some interesting results {{about the impact of}} mode inference techniques within this framework are finally drawn. As for control issues, we address a new approach to the problem of detecting infinite <b>derivation</b> <b>paths.</b> It is based on a theoretical characterization of non-termination and provides a general technique whose effectiveness does not depend on the structure of program domains. ...|$|R
40|$|In {{contrast}} to most traditional information systems {{which are based}} on a static, consistent view of transactional data, a data warehouse comprises several stages of data integration and data aggregation. Hence, the conceptual design of data ware-houses addresses not only data structures, but also <b>derivation</b> <b>paths.</b> Integration and aggregation paths result in highly complex schemas and consistent time references must be introduced. Moreover, available meta data often cannot be reused for data warehouse design because warehouse development tools focus on physical data load instead of conceptual integra-tion. In this paper we enrich the Structured Entity-Relationship Model with appropriate extensions for data warehousing design (e. g. derivation rules and schema aggregation) and adapt a commercial CASE toolset to support such extended conceptual modeling. By that means warehouse schemas can be specified efficiently and meta data of existing information systems can be reused. ...|$|R
40|$|Recent {{approaches}} for protecting information in data outsourcing scenarios exploit the combined use of access control and cryptography. In this context, {{the number of}} keys to be distributed and managed by users can be maintained limited by using a public catalog of tokens that allow key derivation along a hierarchy. However, the public token catalog, by expressing the key derivation relationships, may leak information on the security policies (authorizations) enforced by the system, which the data owner may instead wish to maintain confidential. In this paper, we present an approach to protect {{the privacy of the}} tokens published in the public catalog. Consistently with the data outsourcing scenario, our solution exploits the use of cryptography, by adding an encryption layer to the catalog. A complicating issue in this respect is that this new encryption layer should follow a <b>derivation</b> <b>path</b> that is "reversed" with respect to the key derivation. Our approach solves this problem by combining cryptography and transitive closure information. The result is an efficient solution allowing token release and traversal of the key derivation structure only to those users authorized to access the underlying resources. We also present experimental results that illustrate the behavior of our technique in large settings...|$|E
40|$|This is {{a note on}} the <b>derivation</b> of <b>path</b> {{integral}} formulism for $Z_{ 2 }$ slave-spin {{representation of}} Hubbard model and may be helpful for further study in related works. We are rather happy to receive any comments and other discussions are welcome. Comment: 3 pages, a research note may be useful for students or experts in related issue...|$|R
40|$|Copyright Idea Group Inc. In {{contrast}} to most traditional information systems {{which are based}} on a static, consistent view of transactional data, a data warehouse comprises several stages of data integration and data aggregation. Hence, the conceptual design of data warehouses addresses not only data structures, but also <b>derivation</b> <b>paths.</b> Integration and aggregation paths result in highly complex schemas and consistent time references must be introduced. Moreover, available meta data often cannot be reused for data warehouse design because warehouse development tools focus on physical data load instead of conceptual integration. In this paper we enrich the Structured Entity-Relationship Model with appropriate extensions for data warehousing design (e. g. derivation rules and schema aggregation) and adapt a commercial CASE toolset to support such extended conceptual modeling. By that means warehouse schemas can be specified efficiently and meta data of existing information systems can be reused. ...|$|R
40|$|We {{present a}} {{methodology}} based on Abstract Parallel Machines (APMs) for deriving an executable parallel program from a high-level specification. The specification is given initially in mathematical notation and then {{transformed into a}} functional specification which is not explicitly parallel. This is refined through a sequence of intermediate executable programs in the functional language using equational reasoning. At many of the steps in this process there are decisions which {{need to be made}} producing a variety of possible <b>derivation</b> <b>paths,</b> leading to a range of possible implementations. Hence the final implementation can be in a variety of languages and for a variety of programming models and architectures. We illustrate the method with a simple case study: the summation of the columns of a triangular matrix using load balancing to improve performance. We use Haskell in the derivation and C+MPI as the target language, and show the intermediate steps in the derivation and the transfo [...] ...|$|R
40|$|Abstract. my Grid is an e-Science project {{assisting}} life {{scientists to}} build workflows that gather and co-ordinate data from distributed, autonomous, replicated and heterogeneous resources. The provenance logs of workflow executions are recorded as RDF graphs. The log of one workflow run {{is used to}} trace the history of its execution process; however, by aggregating provenance logs of workflow reruns, or runs of different workflows, we can gather the provenance of a common data product shared in multiple <b>derivation</b> <b>paths.</b> This aggregation relies on accurate and universal identification of each data product. The nature of bioinformatics data and services, however, makes this difficult. We describe the identity problem in bioinformatics data, and present a protocol for managing identity coreferences and allocating identity to collected and computed data products. The ability to overcome this problem means that the provenance of workflows in bioinformatics and other domains can be themselves exploited to enhance the practice of e-Science. ...|$|R
40|$|Seismic {{interferometry}} (SI) is {{the process}} of generating new seismic traces from the cross-correlation of existing traces. One of the starting assumptions for deriving the SI representation equations is that of a lossless medium. In practice, this condition is not always met. Here, we show what the effect is of intrinsic losses on the SI result {{with the help of a}} laboratory experiment in a homogeneous sand chamber. Using numerical modelling results, we further show that, in the case of a dissipative inhomogeneous medium with internal multiple scattering, ghost reflections will appear in the cross-correlation results. In its most general definition, Seismic Interferometry (SI) {{is the process}} of generating new seismic traces from the cross-correlation of existing (measured or modelled) traces. SI representation equations can be obtained following different <b>derivation</b> <b>paths.</b> An overview of these paths can be found in the special issue of Geophysics on SI, July-August 2006. All the path...|$|R
40|$|This paper {{addresses}} the <b>derivation</b> of <b>path</b> loss models and model parameters based on measurement data, {{in particular with}} a view to current modeling work for 5 G millimeter-wave systems. In order to ensure accurate and comparable results, which are independent from the measurement hardware, it is of utmost importance to incorporate a sufficiently large data set and use a coherent data processing including spatial averaging...|$|R
40|$|Pepl, {{parameter}} estimation in Prolog, is an {{implementation of the}} failure adjusted maximisation algorithm (FAM) [4] for Stochastic Logic Programs (Slps) [6, 7]. SLPs extend logic programming by arithmetic labels on clausal definitions. They have well characterised log linear semantics and backtracking strategies [5, 3]. The FAM algorithm was introduced as an extension to the Expectation-Maximization (EM) algorithm and account for failed <b>derivation</b> <b>paths</b> in SLPs [4]. It provides a closed-form for computing the parameter weights within EM’s iterative maximization approach. The algorithm {{has been shown to}} work for normalised SLPs, [4], and is in practice applicable to a wide class of programs. The failure adjusted aspect of the algorithm has also been incorporated in the PRISM system [8]. Pepl is implemented in Prolog and is available as open source. Stochastic clauses are term expanded to standard Prolog ones. Unique identifiers and a path argument are added to the transformation of stochastic clauses. These are used to identify the <b>path</b> of each <b>derivation.</b> In addition failure paths ar...|$|R
40|$|The (parallel) linear {{transports}} along {{paths in}} vector bundles are axiomatically described. Their general form and certain properties are found. It is shown that these transports are locally (i. e. along every fixed path) always Euclidean ones in a senses that there exist frames {{in which their}} matrices are unit. The investigated transports along paths are {{described in terms of}} their local coefficients, as well as in terms of <b>derivations</b> along <b>paths.</b> Comment: 14 LaTeX pages. For related papers, visit the "publication" pages at [URL]...|$|R
5000|$|A <b>derivation</b> of the <b>path</b> {{integral}} {{is possible}} {{in the same way}} as in quantum mechanics, simply because the Fokker-Planck equation is formally equivalent to the Schrödinger equation. Here are the steps for a Fokker-Planck equation with one variable x. Write the FP equation in the form ...|$|R
40|$|This paper {{presents}} {{a method for}} deriving metonymic coercions from the knowledge available in WordNet. Two different classes of metonymies are inferred by using (1) lexico-semantic connections between concepts or (2) morphological cues and logical formulae defining lexical concepts. In both cases the <b>derivation</b> of metonymic <b>paths</b> is based on approx- imations of sortal constraints retrieved from Word- Net...|$|R
40|$|The numerals {{that exist}} in natural {{languages}} {{can be divided into}} different classes of numerals, of which the most common are cardinals, ordinals, fractionals, multiplicatives, approximatives, collectives and distributives. Often in studies on numerals, it is (implicitly) assumed that the numeral classes, if morphologically derived, are universally derived from cardinals, and the exceptions to this are overlooked or ignored. In this thesis the numeral classes are morphologically analysed in a sample of five structurally and genetically unrelated languages: Dutch, Bulgarian, Hungarian, Japanese and Adyghe. What patterns of derivation can be observed? And what can these patterns tell us about the morphology and meaning of numerals of different classes? The results do not support the ‘naive’ picture. Ten non-typical <b>derivation</b> <b>paths</b> were attested. Four of them connect the fractional denominator and the ordinal numerals. Four others connect the multiplicative to cardinals, ordinals, approximatives and distributives respectively. Two of them connect the multiplicative and the fractional denominator. Cognitively, the numerals below 4 are processed by the Object Tracking System (OTS), and the numerals 5 and higher are processed by the Approximate Number System (ANS), according to Spelke (2011). Ordinal and fractional constructions in my sample seem to reflect this distinction: only the forms involving lower numerals have suppletive forms. It is also reflected in the numeric scope of the derivational rules for multiplicatives and collectives. My sample does not exhaust all derivational possibilities. Future research may discover more ‘exotic’ derivations...|$|R
40|$|We discuss Laughlin 2 ̆ 7 s {{ground state}} and its <b>derivation</b> in the <b>path</b> {{integral}} approach. When the external magnetic field is very strong, we regard all electron-electron interactions such as the Coulomb term as weak perturbations. It seems that from the non-trivial topology of the configuration space alone, {{it is possible to}} arrive at a Hamiltonian for which Laughlin wavefunctions are exact ground states...|$|R
40|$|Consolution and its Relation with Resolution* In {{this paper}} {{the method of}} consolution for clause form theorem proving is introduced. Consolution {{is based on the}} {{connection}} method. This means that in a consolution <b>derivation</b> the <b>paths</b> through the input formula are checked for complementarity. In contrast to resolution this checking can be done in a systematic way as in any connection calculus. It is proved that the consolution calculus presented here is sound and complete and that it can simulate resolution step by step and is a generalization of resolution. It combines the advantages of the connection method such as the directedness of search with the advantages of resolution such as the possibility of the use of lemmata. ...|$|R
40|$|In this note, we give a {{description}} of the graded Lie algebra of double <b>derivations</b> of a <b>path</b> algebra as a graded version of the necklace Lie algebra equipped with the Kontsevich bracket. Furthermore, we formally introduce the notion of double Poisson-Lichnerowicz cohomology for double Poisson algebras, and give some elementary properties. We use the description of the graded necklace Lie algebra to compute an example of double Poisson-Lichnerowicz cohomology. ...|$|R
40|$|This article {{studies the}} Lie algebra Diff(KΓ) of <b>derivations</b> on the <b>path</b> algebra KΓ of a quiver Γ and the Lie algebra {{on the first}} Hochschild cohomology group H^ 1 (KΓ). We relate these Lie algebras to the {{algebraic}} and combinatorial properties of the path algebra. Characterizations of <b>derivations</b> on a <b>path</b> algebra are obtained, leading to a canonical basis of Diff(KΓ) and its Lie algebra properties. Special derivations are associated to the vertices, arrows and faces of a quiver, and the concepts of a connected matrix and boundary matrix are introduced to study the relations among these derivations, concluding that the space of edge derivations is the direct sum of the spaces of the vertex derivations and the face derivations, while {{the dimensions of the}} latter spaces are the largest possible. By taking dimensions, this relation among spaces of derivations recovers Euler's polyhedron formula. This relation also leads a combinatorial construction of a canonical basis of the Lie algebra H^ 1 (KΓ), together with a semidirect sum decomposition of H^ 1 (KΓ). Comment: 28 page...|$|R
40|$|We {{suggest a}} simple <b>derivation</b> of the <b>path</b> {{integral}} representation for the Wilson loop in SU(N) gauge theory and 4 -dimensional Euclidean space-time. We {{show that the}} path integral representation derived by Diakonov and Petrov (Phys. Lett. B 224 (1989) 131) is erroneous. We argue that no new non-Abelian Stokes theorem can exist within any path integral representation for the Wilson loop except the old-fashioned one derived {{by means of the}} path-ordering procedure...|$|R
40|$|The <b>derivation</b> of <b>path</b> {{integrals}} is reconsidered. It {{is shown}} that the expression for the discretized action is not unique, and the path integration domain can be deformed so that at least Gaussian path integrals become probabillistic. This leads to a practical algorithm of sign-problem-free Monte Carlo sampling from the Gaussian path integrals. Moreover, the dynamical influence of Gaussian quantum system (the bath) on any other quantum system can be exactly represented as interaction with classical non-Markovian noise. We discuss the relation of these findings to the Bell's theorem and the Feynman's conjecture on the exponential complexity of the classical simulation of quantum systems. In Feynman's path integral we have quasiprobability distributions for trajectories, and in analitycally continued path integrals we have probability distributions for quasitrajectories. Comment: 7 pages, 3 postscript figure...|$|R
40|$|We {{suggest a}} simple <b>derivation</b> of the <b>path</b> {{integral}} representation for the Wilson loop in SU(N) gauge theory and 4 –dimensional Euclidean space–time. We {{show that the}} path integral representation derived in Ref. [3] is erroneous. We argue that no new non–Abelian Stokes theorem can exist within any path integral representation for the Wilson loop except the old–fashioned one derived {{by means of the}} path–ordering procedure. PACS: 11. 10. –z, 11. 15. –q, 12. 38. –t, 12. 38. Aw, 12. 90. +...|$|R
5000|$|The {{explicit}} formula for the eigenenergies of the Schrödinger equation with double-well potential {{has been given}} by Müller-Kirsten with derivation by both a perturbation method (plus boundary conditions) applied to the Schrödinger equation, and explicit <b>derivation</b> from the <b>path</b> integral (and WKB). The result is the following. Defining parameters of the Schrödinger equation and the potential by the equationsandthe eigenvalues for [...] are found to be:Clearly these eigenvalues are asymptotically (...) degenerate as expected {{as a consequence of}} the harmonic part of the potential.|$|R
40|$|The L ATEX 2 ε source file of {{this paper}} was {{produced}} by converting a ChiWriter 3. 16 source file into ChiWriter 4. 0 file and then converting the latter file into a L ATEX 2. 09 source file, which was manually edited for correcting numerous errors and for improving the appearance of the text. As a result of this procedure, some errors in the text may exist. The (parallel) linear transports along paths in vector bundles are axiomatically described. Their general form and certain properties are found. It is shown that these transports are locally (i. e. along every fixed path) always Euclidean ones in a senses that there exist frames in which their matrices are unit. The investigated transports along paths are described in terms of their local coefficients, as well as in terms of <b>derivations</b> along <b>paths.</b> 1...|$|R
40|$|This paper {{intends to}} fill that gap. Notwithstanding that C-logit and PSL are related concepts, the PSL {{approach}} is assumed as a departure point because of its more convincing logic (3). This paper proposes the derivation of a new path size expression different from the classic formulation, the significant extension of the theoretical derivation given for the classic formulation, and the clear identification of the assumptions needed for its derivation. The new and the classic expres-sions are compared by estimating route choice models for two real-world networks and by calculating predicted choice probabilities for a synthetic network. Although the measures are mathematically different, the differ-ences in estimation and prediction outcomes are small. Therefore, the real contribution is the sound <b>path</b> size <b>derivation</b> and the clarity about the assumptions made in including a path size measure in the utility function. The paper is organized as follows. The next section discusses the correlation among alternative routes. The third section shows the <b>derivation</b> of the <b>path</b> size measure. The fourth section introduces the new <b>derivation</b> of the <b>path</b> size correction factor, and the fifth sec-tion presents an interpretation of this correction factor. The last sec-tion presents model estimation results for two real-world networks and compares predictions by using a synthetic route data set...|$|R
40|$|The {{theory of}} linear {{transports}} along paths in vector bundles, generalizing the parallel transports generated by linear connections, is developed. The normal frames for them {{are defined as}} ones in which their coefficients vanish. A number of results, including theorems of existence and uniqueness, concerning normal frames are derived. Special attention is paid on the important case when the bundle's base is a manifold. The normal frames are defined and investigated also for <b>derivations</b> along <b>paths</b> and along tangent vector fields in the last case. It is proved that normal frames always exist at a single point or along a given (smooth) path (with separable points of self-intersections, if any). On other subsets normal frames exist only as an exception if (and only if) certain additional conditions, derived here, are satisfied. The gravity physics is pointed out as a possible field for application of the results obtained...|$|R
40|$|This {{second volume}} {{of a set}} of six volumes of the text on hydrologic optics deals with foundations: radiometric and {{photometric}} concepts and the interaction principle. Detailed treatment is given on: radiant flux; the meaning and fundamental geometric properties of radiant flux; irradiance and radiant emittance; radiance; an invariance property of radiance; scalar irradiance, radiant energy, and related concepts; vector irradiance; radiant intensity; polarized radiance; transition from radiometry to photometry; generalized photometries; the interaction principle; reflectance and transmittance operators for surfaces; applications to plane surfaces; applications to curved surfaces; reflectance and transmittance operators for plane-parallel media; applications to plane-parallel media; interaction operators for general spaces; applications to general spaces; derivation of the beam transmittance function; derivation of the volume attenuation function; <b>derivation</b> of <b>path</b> radiance and <b>path</b> function; <b>derivation</b> of apparent-radiance equation; derivation of volume scattering function; equation of transfer for radiance; integral structure of the interaction operators and summary of the interaction method. (OEIS...|$|R
