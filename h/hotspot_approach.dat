10|37|Public
50|$|Those {{in favor}} of the <b>hotspot</b> <b>approach</b> point out that species are irreplaceable {{components}} of the global ecosystem, they are concentrated in places that are most threatened, and should therefore receive maximal strategic protections. The IUCN Red List categories, which appear on Wikipedia species articles, {{is an example of the}} hotspot conservation approach in action; species that are not rare or endemic are listed the least concern and their Wikipedia articles tend to be ranked low on the importance scale. This is a <b>hotspot</b> <b>approach</b> because the priority is set to target species level concerns over population level or biomass. Species richness and genetic biodiversity contributes to and engenders ecosystem stability, ecosystem processes, evolutionary adaptability, and biomass. Both sides agree, however, that conserving biodiversity is necessary to reduce the extinction rate and identify an inherent value in nature; the debate hinges on how to prioritize limited conservation resources in the most cost-effective way.|$|E
40|$|This study, {{commissioned}} by the European Parliament’s Policy Department for Citizens' Rights and Constitutional Affairs {{at the request of}} the LIBE Committee, examines the EU’s mechanism of relocation of asylum seekers from Greece and Italy to other Member States. It examines the scheme in the context of the Dublin System, the <b>hotspot</b> <b>approach,</b> and the EU-Turkey Statement, recommending that asylum seekers’ interests, and rights be duly taken into account, as it is only through their full engagement that relocation will be successful. Relocation can become a system that provides flexibility for Member States and local host communities, as well as accommodating the agency and dignity of asylum seekers. This requires greater cooperation from receiving States, and a clearer role for a single EU legal and institutional framework to organise preference matching and rationalise efforts and resources overall...|$|E
40|$|The {{reality of}} global climate change demands novel {{approaches}} to science that are reflective of the scales at which changes are likely to occur, and of the new forms of knowledge required to positively influence policy to support vulnerable populations. We examine some of the opportunities and challenges presented by a collaborative, transdisciplinary research project on climate change adaptation in Africa and Asia that utilised a <b>hotspot</b> <b>approach.</b> A large scale effort to develop appropriate baselines was a key challenge {{at the outset of the}} program, as was the need to develop innovative methodologies to enable researchers to work at appropriate spatial scales. Efforts to match research to the biophysical scales at which change occurs need to be aware of the mismatch that can develop between these regional scales and the governance scales at which decisions are made...|$|E
5000|$|The {{high profile}} of the {{biodiversity}} <b>hotspots</b> <b>approach</b> has resulted in some criticism. Papers such as Kareiva & Marvier (2003) {{have argued that the}} biodiversity hotspots: ...|$|R
40|$|Given the {{alarming}} loss of biodiversity and {{considering that the}} location and threats to this biodiversity are distributed unevenly across the globe, a systematic strategy of international conservation planning must complement national conservation actions by directing inadequate flexible funding to places where the greatest biological distinctiveness coincides with the greatest threat, thus safeguarding {{the protection of the}} most species for the money invested. One such approach is Conservation Internationalʼs Biodiversity Hotspots, regions where extraordinary biological diversity coincides with exceptional threat. Drawing from discussions in the scientific literature, conservation planning theory and ecological theory, this study is an attempt to evaluate the <b>hotspots</b> <b>approach</b> as a tool for global conservation planning. Based on an assessment of the strategyʼs objectives and methods, its congruence with other approaches and the theoretical, financial and practical impact it has had so far, the biodiversity hotspots are found to be of great utility in identifying and targeting global conservation priorities until more sufficient data regarding species knowledge and threat make the use of surrogates such as endemism or habitat loss futile...|$|R
40|$|In an era {{of global}} habitat loss and species extinction, {{conservation}} biology is increasingly becoming a science of triage. A key approach has been the designation of global biodiversity hotspots – areas of high species richness and endemism – prioritizing regions that are disproportionately valuable. However, traditional <b>hotspot</b> <b>approaches</b> leave absent information on species evolutionary histories. We argue that prioritizing the preservation of evolutionary diversity {{is one way to}} maximize genotypic and functional diversity, providing ecosystems with the greatest number of options for dealing with an uncertain future. Global. We review methods for encapsulating phylogenetic diversity and distinctiveness and provide an illustration of how phylogenetic metrics can be extended to include data on geographical rarity and inform conservation prioritization at biogeographic scales. Abundance-weighted metrics of evolutionary diversity can be used to simultaneously prioritize populations, species, habitats and biogeographical regions. Policy makers need to know where scarce conservation funds should be focused to maximize gains and minimize the loss of biological diversity. By incorporating these evolutionary diversity metrics into prioritization schemes, managers can better quantify the valuation of different regions based on evolutionary information...|$|R
40|$|A global {{survey of}} a well-studied order of {{tropical}} mammals, primates, {{is used to}} explore the use of diversity hotspots in con-servation. The results at this shallow taxonomic level match those for most cross-phylum analyses. Overlap of hotspots for species, genera, trait-complexes, families, and threatened species varies with the continent, and the comparison. Overlap is best in Africa and Madagascar, and poorest in Asia, but reasons for the dierences need exploring. A complete mismatch of taxonomic and threatened species hotspots in South America, resulting from the mismatch of the hotspots of diversity and human destruction, suggests that conservation biologist’s <b>hotspot</b> <b>approach</b> could benefit from adding hotspots of human threat {{to the analysis of}} diversity hotspots. Conservationists ’ use of hotspot analysis seems to have been largely empirical. If analysis of single orders can contribute to conservation, application of biogeographic theory to our knowledge of the distribution of the order, primates, is th...|$|E
40|$|A {{range of}} {{different}} biodiversity-based selection methods for nature reserves {{has been tested}} for terrestrial environments, including those based on diversity hot spots, endemicity hotspots and complementarity. In this study, we investigate the utility of these approaches for a coral reef embayment. We compare coral and fish species richness in a random accumulation of reserve sites with (a) hotspots analysis, (b) stratified selection of hotspots, and (c) complementarity. Cumulative species-site curves indicated that complementarity maximized the rate of accumulation of species of both corals and fishes in reserves, while the <b>hotspot</b> <b>approach</b> performed moderately well. An equivalent number of reserve sites supported {{a greater proportion of}} the coral biodiversity when compared to fishes, reflecting the broader distribution of corals. Our results indicate that when choosing an indicator group as a proxy for representing overall diversity in a reserve network, the group with the greatest heterogeneity will provide the best results. Our findings also show that although a modest number of protected sites (20 %) will incorporate much of the local diversity (> 75 %), species-specific approaches must be incorporated to target rare species...|$|E
40|$|Comprehensive {{studies of}} coral reef {{biodiversity}} suggest that diversity patterns {{may be more}} congruent with geotectonic events than with the reigning paradigms of dispersal, center of origin, and vicariance. Geotectonic processes slowly accumulate taxa in areas exemplified {{by the presence of}} composite or lineage-based evolutionary diversity. This process-pattern model can suggest additional areas where similar patterns are likely to occur. Information on types and levels of diversity should be a primary concern in emerging conservation efforts for deepwater coral ecosystems. Current marine conservation efforts in shallow reef systems rely primarily on identifying “hotspots” that reflect measures of species richness and endemicity rather than intrinsic evolutionary relationships. Recent phylogenetic and molecular research from shallow reef systems questions the validity of the <b>hotspot</b> <b>approach.</b> Biodiversity assembly rules for both deep-sea and shallow coral assemblages are likely congruent and thus should exhibit similar diversity patterns. Given logistic and expense concerns in studying deep coral systems, a predictive and testable biodiversity model that suggests areas where composite, lineage-based diversity may be located would help focus and allocate scarce resources...|$|E
40|$|Western Australia has an {{extensive}} coastline {{ranging from the}} tropical north to the temperate south, with a high diversity of neritic marine fishes. Distribution data of 1855 neritic fish species were used to compare a range of methods for identifying priority areas for their conservation. Species richness and endemism richness hotspots, biogeographic zoning and complementarity analysis were tested for their efficiency at representing the total suite of species. The <b>hotspot</b> <b>approaches</b> demonstrated low efficiency, as the sections of coastline selected were grouped together in isolated geographic locations and relatively few of the total suite of neritic fish species were represented. Biogeographic zoning divided the coast of Western Australia into six regions, and as such, priority areas were selected around the entire coastline, which resulted in fairly high levels of efficiency. However, the complementarity analysis {{proved to be the}} most efficient method, as > 95 % of all neritic fish species could be represented in six, appropriately located, 100 km long sections of coastline. Complementarity analysis indicated a total of 26 priority areas for neritic fish conservation, which were spread around the entire coast of Western Australia. However, as current marine conservation measures in Western Australia are focused on the west and northwest coasts, this study highlighted the need for marine conservation efforts to be extended to cover the north and south coasts...|$|R
50|$|Rachel Slocum's {{beautiful}} coffee-colored Morgan mare, {{whom she}} bought solely because the horse's coloring matched her hair. Ryan rides {{her on the}} last leg of his quest to recapture Apache Hotspot, taking Sam's advice to ride a less dominant horse than Sky Ranger. After Ryan takes off for home on <b>Hotspot,</b> Sam <b>approaches</b> Mocha and rides her back to Gold Dust Ranch. She would have ridden Ace, but he ran off without her after she made a failed attempt to slide from his back to the Phantom's. Mocha is wary of new riders, but Sterling Stables taught her exceptionally well and Sam rides her with no problems. She is trained under both English and Western saddles.|$|R
40|$|Network {{screening}} {{techniques are}} widely used by state agencies to identify locations with high collision concentration, {{also referred to as}} hotspots. However, most of the research in this regard has focused on identifying highway segments that are of concern to automobile collisions. A major difference between pedestrian and automobile hotspots is that pedestrian-based conflicts are more likely to arise in localized regions, such as near intersections, mid-blocks, and/or other crossings, as opposed to along long stretches of roadway. Hence, in order to address this issue, a dynamic programming-based <b>hotspot</b> identification <b>approach</b> is proposed which provides efficient hotspot definitions for pedestrian crashes. The proposed approach is compared with the sliding window method and the results reveal that the dynamic programming method generates more hotspots with a higher number of crashes, while covering fewer miles...|$|R
40|$|The {{province}} of groningen {{wants to get}} a sense of the direction of adaptation measures and strategies for the future. Therefore the <b>hotspot</b> <b>approach</b> has been applied. Several relevant themes (agriculture, nature and water, the coast, energy and fresh water supply) were put on maps separately. Every map showing the ultimate adapted future for that theme for the relatively short term (20 - 30 years). Combined these maps show an integrated adaptation map of the {{province of}} groningen (see figure 1). to get a feeling of possible long term futures (100 year or more), three separate backtracking scenarios have been developed. They show the broad bandwidth of, sometimes unimaginable, futures. these scenarios are used as the background against which adaptation measures and strategies can be judged on robustness and usefulness in specific areas. The combination of the integrated adaptation map and the long-term scenarios show the areas where adaptation measures and strategies are robust and other areas (so-called windows), where they form a dilemma, where further in-depth study is needed. In combination with the integrated adaptation map and the backtracking scenarios, the solutions for these windows can be used to develop long-term climate proof scenarios under extreme conditions. For the province of Groningen these scenarios are named 'sustain' or 'give-up'. These scenarios and the robust measures define a short-term adaptation agenda, because the measures and strategies, which are useful in even a every unlikely future, can be implemented at present...|$|E
40|$|Reserve {{networks}} {{are a major}} tool of ecological management aiming at biodiversity conservation. Maximizing {{the number of species}} conserved with the minimum land sacrifice is a primary requirement in reserve design. In this study, we examine the efficiency of five different scenarios to conserve: (i) the biodiversity of one target group and (ii) the overall biodiversity of an area. The study was conducted in Dadia Reserve, in northern Greece. Six groups of species were selected to represent its biodiversity: woody plants, orchids, Orthoptera, aquatic and terrestrial herpetofauna, and small terrestrial birds. The scenarios examined represent different conservation approaches to select network sites. For each approach, the starting point was one of the above six groups of species, considered as the target group. In scenario A, which reflects the <b>hotspot</b> <b>approach,</b> the sites richest in species are selected. Scenario B selects the sites most complementary in terms of species richness. The next two scenarios use the principle of environmental representativeness, expressed in terms of habitat (scenario C) or vegetation (scenario D). Under scenario E, sites forming the network are selected at random. The rank of scenarios in terms of preserving the species of the target group was always B > A > C > D > E, irrespective of the group considered as target group. Their rank, when preservation of the total biodiversity was the issue, was B, A > C, D > E. (C) 2004 Elsevier Ltd. All rights reserved...|$|E
40|$|Volume XXV of the Italian Yearbook of International Law {{opens with}} pieces {{dedicated}} {{to the memory of}} Professor Conforti and Professor Ferrari Bravo, two founding members of the Board of Editors of the IYIL who passed away in early 2016. There follows a Focus section devoted to a number of international and European legal issues raised by the ongoing migratory crisis. It discusses inter alia the fight against migrant smuggling under UN Security Council resolution 2240 (2015), amendment proposals to the 1951 Refugees Convention, the implications for international responsibility of the EU’s <b>hotspot</b> <b>approach</b> to managing migration, and the protection of EU citizens victims of human trafficking in Europe. The section on Notes and Comments contains a variety of timely contributions, including on the regime governing wrecks of State-owned ships, on the legal framework to counter foreign terrorist fighters, and on the 2015 Paris Agreement on Climate Change. The section on Practice of International Courts and Tribunals offers an analytical overview of the 2015 activities of the ICJ, the ITLOS and other law of the sea jurisdictions, international and mixed criminal courts and tribunals, the WTO, and ICSID. The following part of the Volume continues the tradition of the Italian Yearbook of providing reports on the contemporary Italian practice of international law, including judicial practice, diplomatic and parliamentary practice, treaty practice, and legislation. The remaining part of the Volume contains a bibliographical index of Italian contributions to international law scholarship published in 2015, a book review section, and an analytical index for easy consultation and reference to materials cited in the Yearbook...|$|E
40|$|In {{the past}} 5 years {{there has been}} a {{proliferation}} of efforts to map climate change “hotspots” — regions that are particularly vulnerable to current or future climate impacts, and where human security may be at risk. While some are academic exercises, many are produced with the goal of drawing policy maker attention to regions that are particularly susceptible to climate impacts, either to mitigate the risk of humanitarian crises or conflicts or to target adaptation assistance. Hotspots mapping efforts address a range of issues and sectors such as vulnerable populations, humanitarian crises, conflict, agriculture and food security, and water resources. This paper offers a timely assessment of {{the strengths and weaknesses of}} current <b>hotspots</b> mapping <b>approaches</b> with the goal of improving future efforts. It also highlights regions that are anticipated, based on combinations of high exposure, high sensitivity and low adaptive capacity, to suffer significant impacts from climate change...|$|R
40|$|The Wachusett Reservoir is {{a primary}} {{drinking}} water resource for the greater Boston, Massachusetts, area. With a drainage area of 280 km 2, the watershed has been gradually urbanized with increased residential, commercial, industrial, and transportation land uses. Increased impervious surface area {{as a result of}} urbanization results in increased runoff volume and pollutant loads to the reservoir. This study estimated annual stormwater pollutant mass loads in the watershed to prioritize sub-basins and to identify areas susceptible to stormwater pollution. Catchment Prioritization Index (CPI) was calculated using annual stormwater pollutant mass loads, which were further used to identify clustered hotspots through application of the Getis&# 8208;Ord Gi* statistic. Validation with observed data showed higher levels of fecal coliform bacteria loading from identified <b>hotspots.</b> This <b>approach</b> will be useful to prioritize sub-basins for future (1) development of stormwater monitoring strategies and (2) best management practices (BMPs) in the watershed. clos...|$|R
40|$|Among the {{satellite}} techniques developed to study active volcanoes, a multi-temporal approach named RST (Robust Satellite Technique) has shown high performances in detecting and monitoring <b>hotspots.</b> This <b>approach</b> has been recently implemented on MSG-SEVIRI data that, providing {{information on the}} same areas every 15 minutes in the MIR spectral region (the most suitable to identify high temperature surfaces), offers {{a unique opportunity to}} monitor volcanoes in real time. In this paper, RST performances in promptly identifying hotspots by means of SEVIRI data have been analyzed, comparing the results obtained during the Mount Etna eruption of May 2008 with the ones automatically provided by {{the satellite}} monitoring system operational at IMAA (Institute of Methodologies for Environmental Analysis), which use both AVHRR and MODIS data. The RST potential in monitoring hotspots in real time, in view of the development of an efficient early warning system devoted to volcanic hazard mitigation, will also be analyzed...|$|R
40|$|This report makes {{recommendations}} {{for the development of}} programmatic HIV/AIDS prevention work with males who have sex with males (MSM) in Lao PDR and Thailand. The recommendations made derive from a consultation process commissioned by Pact, and undertaken by an external consultant, Paul Boyce, working for the Naz Foundation International (NFI), conducting the assessment in Thailand, along with Shivananda Khan of NFI, conducting the Lao PDR review. The objective {{of the study was to}} provide evidence-based knowledge towards developing a comprehensive client-friendly outreach and peer-education focused interventions for MSM in both Lao PDR and Thailand. This involved identifying key services in target areas and the gaps that existed, along with key individuals and organisations working with MSM, as well as potential organisations that can be sub-grantees, while recommending a programmatic strategy form increasing coverage of key services. Further key capacity building needs of nascent organisations were also to be identified. A three-week field visit to Thailand was carried out in February and March 2005, focusing on three regional sites identified by Pact and USAID as hotspots, 1 and most appropriate for the initial phase of programmatic development – Bangkok, Chiang Mai and Pattaya. In Lao PDR, a one-week study visit between 16 th – 26 th March, 2005 focused on Luang Prabang, Savannakhet, and Vietianne, identified in a USAID conducted workshop on 17 th March 2005 as current hotspots in this country. (See the annexure for a caveat to the <b>hotspot</b> <b>approach.)</b> In Thailand, field research explored existing HIV/AIDS interventions among males who have sex with males, assessing the best strategies to augment current community-based interventions and expand coverage of their HIV/AIDS prevention work. In Lao PDR, where HIV/AIDS interventions are implemented by international non-government agencies (INGOs), and in one specific case by the government sponsored Lao Buddhist Association, and where no community-based organising exists, 2 field research focused on those who were developing responses to the needs of males who have sex with males, and/or who wished to. Due to a lack of knowledge by those accessed by the review, and time constraints, actual costings have not been done on the recommended interventions. Further work will need to be done to assist potential implementers to develop appropriate budgets...|$|E
40|$|QTL hotspots, {{groups of}} traits co-mapping {{to the same}} genomic location, are a common feature of genetical {{genomics}} studies. Genomic locations associated with many traits are biologically interesting since they may harbor influential regulators. Nonetheless, non-genetic mechanisms, uncontrolled environmental factors and unmeasured variables are capable of inducing a strong correlation structure among clusters of transcripts, and as a consequence, whenever a transcript shows a spurious linkage, many correlated transcripts will likely map to the same locus, creating a spurious QTL <b>hotspot.</b> Permutation <b>approaches</b> that do {{not take into account}} the phenotypic correlation tend to underestimate the size of the hotspots that might appear by change in these situations (Breitling et al. 2008). This issue motivated the development of permutation tests that preserve the correlation structure of the phenotypes in order to determine the significance of QTL hotspots (Breitling et al. 2008, Chaibub Neto et al. 2012). In this tutorial we present software tools implementing the NL-method (Chaibub Neto et al. 2012), the N-method (Breitling et al. 2008), and th...|$|R
30|$|As an example, let us {{assume a}} {{scenario}} where a crowd is moving towards a stadium, requesting a real-time augmented reality service, i.e., low bandwidth and strict delay requirements. In this case, the stadium hotspot {{is surrounded by}} macro cells generating high-bandwidth background traffic, which therefore generates larger resource requests to the coordinator. A content-unaware CoMP would base its decisions on traffic volumes only, thus penalizing the <b>hotspot.</b> A CoCo <b>approach</b> instead can be configured to boost the requests from the hotspot, thus protecting its performance. Using this approach, the interference among eNBs will be managed effectively, and a low-delay content access will be guaranteed to users under the hotspot at the same time.|$|R
50|$|Those {{arguing in}} favor of setting {{priorities}} for coldspots {{point out that there}} are other measures to consider beyond biodiversity. They point out that emphasizing hotspots downplays the importance of the social and ecological connections to vast areas of the Earth's ecosystems where biomass, not biodiversity, reigns supreme. It is estimated that 36% of the Earth's surface, encompassing 38.9% of the worlds vertebrates, lacks the endemic species to qualify as biodiversity hotspot. Moreover, measures show that maximizing protections for biodiversity does not capture ecosystem services any better than targeting randomly chosen regions. Population level biodiversity (i.e. coldspots) are disappearing at a rate that is ten times that at the species level. The level of importance in addressing biomass versus endemism as a concern for conservation biology is highlighted in literature measuring the level of threat to global ecosystem carbon stocks that do not necessarily reside in areas of endemism. A <b>hotspot</b> priority <b>approach</b> would not invest so heavily in places such as steppes, the Serengeti, the Arctic, or taiga. These areas contribute a great abundance of population (not species) level biodiversity and ecosystem services, including cultural value and planetary nutrient cycling.|$|R
40|$|This paper {{presents}} an approach of compact thermal modeling — HotSpot, which is parameterized according to design geometrical dimensions and material physical properties. While most existing compact thermal modeling methods facilitate thermal analysis of existing package designs, the HotSpot modeling method is {{more suitable for}} the exploration of new designs at both the die level and the package level due to its physically-based parametrization characteristics. Although {{it may not be}} as “compact ” as other modeling <b>approaches,</b> <b>HotSpot</b> provides much more thermal information of the design, especially at the die level, with negligible computational overhead. We also show that the HotSpot achieves reasonable boundary condition independence (BCI) by comparing it with a DELPHI compact thermal model for a benchmark BGA chip under the same set of boundary conditions. 1...|$|R
40|$|Soil erosion {{is a very}} {{critical}} form of land degradation resulting {{in the loss of}} soil nutrients and downstream sedimentation of water storages in the highlands of Ethiopia. As it is technically and financially impossible to conserve all landscapes affected by erosion, identification of priority areas of intervention is necessary. Spatially distributed erosion models can help map landscape susceptibility to erosion and identify high erosion risk areas. Integration of erosion models with geographic information systems (GIS) enables assessing evaluate the spatial variability of soil erosion and plan implementing conservation measures at landscape levels. In this study, the Revised Universal Soil Loss Equation adjusted for sediment delivery ratio was used in a GIS system to assess landscape sensitivity to erosion and identify <b>hotspots.</b> The <b>approach</b> was applied in three catchments with size being 10 – 20  km 2 and results were compared against quantitative and semi-quantitative data. The model estimated mean soil loss rates of about 45  t ha− 1  y− 1 with an average variability of 30 % between catchments. The estimated soil loss rate is above the tolerable limit of 10  t ha− 1  y− 1. The model predicted high soil loss rates at steep slopes and shoulder positions as well as along gullies. The results of the study demonstrate that knowledge of spatial patterns of high soil loss risk areas can help deploy site-specific conservation measures...|$|R
40|$|Regardless of its {{intent and}} purposes, {{the first decade}} of the Local Air Quality Management (LAQM) {{framework}} had little or no effect in reducing traffic-related air pollution in the UK. Apart from the impact of increased traffic volumes, the major factor attributed to this failure is that of policy disconnect between the process of diagnosing air pollution and its management thereby limiting the capability of local authorities to control traffic-related sources of air pollution. Integrating air quality management into the Local Transport Plan (LTP) process therefore presents opportunities for enabling political will, funding and joined-up policy approach to reduce this limitation. However, despite the increased access to resources for air quality measures within the LTP process, this paper highlights local institutional, political and funding constraints which reduce the impact of these policy interventions on air quality management. The results of this study illustrate the policy implementation gaps between central government policy intentions and the local government process by providing evidence of the deprioritisation of air quality management compared to the other shared priorities in the LTP process. The paper draws conclusions on the policy and practice of integrating air quality management into transport planning. It argues the need for a policy shift from a solely localised <b>hotspot</b> management <b>approach,</b> in which the LAQM framework operates, to a more holistic management of vehicular emissions within wider spatial administrative areas...|$|R
40|$|We {{present a}} 200 ks Chandra ACIS-I image of Cygnus A, and discuss a long linear feature seen in its counterlobe. This feature has a non-thermal {{spectrum}} and {{lies on the}} line connecting the brighter <b>hotspot</b> on the <b>approaching</b> side and the nucleus. We therefore conclude that this feature is (or was) a jet. However, the outer part of this X-ray jet does not trace the current counterjet observed in radio. No X-ray counterpart is observed on the jet side. Using light-travel time effects we conclude that this X-ray 50 kpc linear feature is a relic jet that contains enough low-energy plasma (gamma ~ 10 ^ 3) to inverse-Compton scatter cosmic microwave background photons, producing emission in the X-rays. Comment: 4 pages. Proceedings of "High Energy Phenomena in Relativistic Outflows", held in Dublin, Ireland, September 24 - 28, 200...|$|R
40|$|A way {{is needed}} to parametrically assess fatigue life. Fatigue is a {{function}} of many variables ranging from design and fabrication to operational issues and little work has been done to quantify the relative effects. This work focuses on a narrow problem: fatigue life of bulk carrier side shell frame lower bracket toes. The frame was reduced to a simple two dimensional beam, subject to heave induced inertial and buoyant loads. The ship was assumed to be operating in an ITTC wave spectrum. It was assumed that the speed of advance is zero; the ship was flexible and the seas were from ahead. Boundary conditions were modeled using spring supports and fixity parameters. Fatigue analysis was performed using a <b>hotspot</b> SN <b>approach</b> and Miner's Rule. Results show a rapid decrease in fatigue life for ships greater than 100 m. [...] A loading parameter was defined to model the difference between homogeneous and alternate hold loading. Results indicate homogeneous hold loading is preferable for ships less than approximately 290 m in length and alternate hold loading is preferable for ships greater than 290 m in length. This is thought to be because the heave natural frequency tends to be higher than the wave spectrum peak for small ships. Increasing length and unit loading causes a lowering of the heave natural frquency to a value closer to the forcing frequency of the waves for larger ships...|$|R
40|$|Thesis (M. Eng.) [...] Memorial University of Newfoundland, 2000. Engineering and Applied ScienceBibliography: leaves 107 - 109 A way {{is needed}} to parametrically assess fatigue life. Fatigue is a {{function}} of many variables ranging from design and fabrication to operational issues and little work has been done to quantify the relative effects. This work focuses on a narrow problem: fatigue life of bulk carrier side shell frame lower bracket toes. The frame was reduced to a simple two dimensional beam, subject to heave induced inertial and buoyant loads. The ship was assumed to be operating in an ITTC wave spectrum. It was assumed that the speed of advance is zero; the ship was flexible and the seas were from ahead. Boundary conditions were modeled using spring supports and fixity parameters. Fatigue analysis was performed using a <b>hotspot</b> SN <b>approach</b> and Miner's Rule. Results show a rapid decrease in fatigue life for ships greater than 100 m. [...] A loading parameter was defined to model the difference between homogeneous and alternate hold loading. Results indicate homogeneous hold loading is preferable for ships less than approximately 290 m in length and alternate hold loading is preferable for ships greater than 290 m in length. This is thought to be because the heave natural frequency tends to be higher than the wave spectrum peak for small ships. Increasing length and unit loading causes a lowering of the heave natural frquency to a value closer to the forcing frequency of the waves for larger ships...|$|R
40|$|This report {{discusses}} the methodology, formulas, and inputs {{needed to make}} characterization and clearance decisions for Bacillus anthracis-contaminated and uncontaminated (or decontaminated) areas using a statistical sampling approach. Specifically, the report includes the methods and formulas for calculating the • number of samples required to achieve a specified confidence in characterization and clearance decisions • confidence in making characterization and clearance decisions for a specified number of samples for two common statistically based environmental sampling approaches. In particular, the report addresses an issue raised by the Government Accountability Office by providing methods and formulas to calculate the confidence that a decision area is uncontaminated (or successfully decontaminated) if all samples collected according to a statistical sampling approach have negative results. Key to addressing this topic is the probability that an individual sample result is a false negative, which is {{commonly referred to as}} the false negative rate (FNR). The two statistical sampling approaches currently discussed in this report are 1) hotspot sampling to detect small isolated contaminated locations during the characterization phase, and 2) combined judgment and random (CJR) sampling during the clearance phase. Typically if contamination is widely distributed in a decision area, it will be detectable via judgment sampling during the characterization phrase. Hotspot sampling is appropriate for characterization situations where contamination is not widely distributed and may not be detected by judgment sampling. CJR sampling is appropriate during the clearance phase when it is desired to augment judgment samples with statistical (random) samples. The hotspot and CJR statistical sampling approaches are discussed in the report for four situations: 1. qualitative data (detect and non-detect) when the FNR = 0 or when using statistical sampling methods that account for FNR > 0 2. qualitative data when the FNR > 0 but statistical sampling methods are used that assume the FNR = 0 3. quantitative data (e. g., contaminant concentrations expressed as CFU/cm 2) when the FNR = 0 or when using statistical sampling methods that account for FNR > 0 4. quantitative data when the FNR > 0 but statistical sampling methods are used that assume the FNR = 0. For Situation 2, the <b>hotspot</b> sampling <b>approach</b> provides for stating with Z% confidence that a hotspot of specified shape and size with detectable contamination will be found. Also for Situation 2, the CJR approach provides for stating with X% confidence that at least Y% of the decision area does not contain detectable contamination. Forms of these statements for the other three situations are discussed in Section 2. 2. Statistical methods that account for FNR > 0 currently only exist for the <b>hotspot</b> sampling <b>approach</b> with qualitative data (or quantitative data converted to qualitative data). This report documents the current status of methods and formulas for the hotspot and CJR sampling approaches. Limitations of these methods are identified. Extensions of the methods that are applicable when FNR = 0 to account for FNR > 0, or to address other limitations, will be documented in future revisions of this report if future funding supports the development of such extensions. For quantitative data, this report also presents statistical methods and formulas for 1. quantifying the uncertainty in measured sample results 2. estimating the true surface concentration corresponding to a surface sample 3. quantifying the uncertainty of the estimate of the true surface concentration. All of the methods and formulas discussed in the report were applied to example situations to illustrate application of the methods and interpretation of the results...|$|R
40|$|Traffic {{accidents}} {{are very serious}} problems for human life and the environment. In road safety, {{it is crucial to}} identify the high risk locations to apply proper counter measures. This paper aims at introducing outcomes of a pilot project whose main goal is to develop a GIS based crash analysis system integrated with the quantitative methods for identification of high risk locations on road networks in Turkey. In this concept, traditional hotspot detection methods used in Turkey(crash frequency, rate, and severity) are compared with the spatial statistical methods including Moran's I, GetisOrd G and planar and network kernel density estimation in terms of their sensitivity to spatial characteristics of crash clusters. Many countries use traditional <b>hotspot</b> detection <b>approaches</b> such as crash frequency, crash rate, and crash severity as well as Turkey. In this project, we aimed at obtaining a model including different hotspot identification methods for the safety program of Turkey. In order to obtain the model, many hotspot detection methods will be used and compare stage by stage. In the first stage, the seven methods mentioned above are used and examined. Although some of these methods are compared in couple, there is no study using all these methods together extensively in the literature. Methods validated with a different spatial vantage points. Repetitiveness of hotspots in a seven years period are used to compare the methods. Meanwhile advantages and disadvantages of the methods according to location of hotspots are examined additionally. Results show that using planar KDE with Gi in the junction locations and using planar KDE with Moran's I in the straight road locations could improve the model while determining hotspots...|$|R
40|$|A {{variety of}} reasons, {{specifically}} contact issues, irregular loads, cracks in insulation, defective relays, terminal junctions {{and other similar}} issues, increase the internal temperature of electrical instruments. This results in unexpected disturbances and potential damage to power equipment. Therefore, the initial prevention measures of thermal anomalies in electrical tools are essential to prevent power-equipment failure. In this article, we address this initial prevention mechanism for power substations using a computer-vision approach {{by taking advantage of}} infrared thermal images. The thermal images are taken through infrared cameras without disturbing the working operations of power substations. Thus, this article augments the non-destructive approach to defect analysis in electrical power equipment using computer vision and machine learning. We use a total of 150 thermal pictures of different electrical equipment in 10 different substations in operating conditions, using 300 different <b>hotspots.</b> Our <b>approach</b> uses multi-layered perceptron (MLP) to classify the thermal conditions of components of power substations into “defect” and “non-defect” classes. A total of eleven features, which are first-order and second-order statistical features, are calculated from the thermal sample images. The performance of MLP shows initial accuracy of 79. 78 %. We further augment the MLP with graph cut to increase accuracy to 84 %. We argue that with the successful development and deployment of this new system, the Technology Department of Chongqing can arrange the recommended actions and thus save cost in repair and outages. This can {{play an important role in}} the quick and reliable inspection to potentially prevent power substation equipment from failure, which will save the whole system from breakdown. The increased 84 % accuracy with the integration of the graph cut shows the efficacy of the proposed defect analysis approach...|$|R
40|$|Background: An {{atmosphere}} of ineffectiveness regarding {{the ability of}} police to address crime problems in general and street-level drug problems in particular prevailed in the 1980 s. Law enforcement tactics in the 1980 s were typically reactive, unfocused and generally failed to disrupt street-level drug market activity. Development of focused proactive policing strategies during the 1990 s, such as problem-oriented policing and partnerships with third parties, led to a renewed faith in {{the capacity of the}} police to efficaciously deal with street-level drug problems. Objectives: To utilize meta-analytic procedures to assess the relative effectiveness of police-led drug law enforcement interventions. Specifically, we examined the relative effectiveness of a number of policing approaches, including problem-oriented policing, community-wide policing, and hotspots policing compared to the standard, reactive mode of drug law enforcement that dominated police practice until the 1990 s. Search Strategy: We identified relevant studies using a guided, iterative search process utilizing appropriate keyword searches of major databases from various disciplines. In addition, we hand searched key journals in the law enforcement literature, trawled discipline relevant websites, consulted key researchers, postgraduate students, and criminal justice librarians, and cross-checked the reference list of each identified study. Selection Criteria: We restricted our meta-analysis to interventions initiated, managed and/or implemented by the police to reduce or prevent illicit drug use, drug dealing and associated problems at drug dealing places. We investigated the impact of these interventions on a number of outcome variables, including drug outcomes using drug-related calls for service and reported offenses, as well as reported offenses and calls for service outcomes for non-drug specific outcomes such as property crime, violent offences, and disorder. The review imposed no time restrictions (i. e. publication year) and we included unpublished literature (i. e. dissertations, reports, etc) and non-English language studies. Included studies all needed, at a minimum, a pre-test/post-test, comparison group design. Our review included quasi-experimental designs given the lack of methodologically sound evaluations in this area. Data Collection & Analysis: We used meta-analytic techniques to investigate the effectiveness of various drug law enforcement approaches on the outcome variables of interest. Specifically, we used the odds ratio to assess pre-test to post-test intervention effects, using a random effects model. We analysed separately the effect of drug law enforcement on each of the outcomes of interest. Main Results: Our results show that problem-oriented and community-wide policing approaches are more effective at reducing drug calls for service and drug incidents than law enforcement approaches that target drug hotspots. We also find that problem-oriented policing is more effective than community-wide policing in dealing with both drug-related and total calls for service. But the simple tactic of geographically focusing law enforcement resources on drug hotspots is a marked improvement over the deployment of “standard” law enforcement tactics (such as preventive patrols) that are geographically unfocused. In regards to non-drug outcomes, community-wide policing approaches tend to reduce disorder-related activity more than law enforcement-only activities that target drug <b>hotspots.</b> <b>Hotspots</b> <b>approaches</b> aimed at disrupting street-level drug market have a more desirable impact on person (e. g. street assaults) and property crime (motor vehicle theft) outcomes than problem-oriented or community-wide policing approaches. Reviewer’s Conclusions: Our results reveal that geographically targeted problem-oriented policing interventions, involving cooperative partnerships between police and third parties, tend to be more effective at disrupting street-level drug markets than policing efforts that involve partnerships but are spread across a community. Yet our results suggest that both problem-oriented policing and community-wide partnerships are more effective at disrupting street level drug markets than traditional, law enforcement-only interventions, whether they are focused on hotspots or not. Our results suggest that rather than simply increasing police presence or intervention (e. g. arrests) at drug hotspots, street-level drug law enforcement should (1) focus on forging productive partnerships with third parties, (2) target drug hotspots rather than spreading intervention efforts across neighborhoods, and (3) make efforts to alter the underlying criminogenic conditions that exist in places with street-level drug market problems...|$|R
40|$|We {{present a}} novel {{efficient}} adaptive sensing and monitoring solution {{for a system}} of mobile sensing devices that support traffic monitoring applications. We make a key observation {{that much of the}} variance in commute times arises at a few congestion hotspots, and a reliable estimate of congestion can be obtained by selectively monitoring congestion just at these hotspots. We design a smartphone application and a backend system that automatically identifies and monitors congestion hotspots. The solution has low resource footprint in terms of both battery usage on the sensing devices and the network bytes used for uploading data. When a user is not inside any hotspot zone, adaptive sampling conserves battery power and reduces network usage, while ensuring that any new hotspots can be effectively identified. Our results show that our application consumes 40 - 80 % less energy than a periodic sampling system for different routes in our experiments, with similar accuracy of congestion information. The system can be used for a variety of applications such as automatic congestion alerts to users <b>approaching</b> <b>hotspots,</b> reliable end-to-end commute time estimates and effective alternate route suggestions. Comment: 11 pages, Tech rep of the paper accepted at COMSNETS 201...|$|R
40|$|Abstract The {{regulatory}} mechanism of recombination {{is a fundamental}} problem in genomics, with wide applications in genome-wide association studies, birth-defect diseases, molecular evolution, cancer research, etc. In mammalian genomes, recombination events cluster into short genomic regions called "recombination hotspots". Recently, a 13 -mer motif enriched in hotspots is identified as a candidate cis-regulatory element of human recombination hotspots; moreover, a zinc finger protein, PRDM 9, binds to this motif and is associated with variation of recombination phenotype in human and mouse genomes, thus is a trans-acting regulator of recombination hotspots. However, this pair of cis and trans-regulators covers {{only a fraction of}} hotspots, thus other regulators of recombination hotspots remain to be discovered. In this paper, we propose an approach to predicting additional trans-regulators from DNA-binding proteins by comparing their enrichment of binding sites in <b>hotspots.</b> Applying this <b>approach</b> on newly mapped mouse hotspots genome-wide, we confirmed that PRDM 9 is a major trans-regulator of hotspots. In addition, a list of top candidate trans-regulators of mouse hotspots is reported. Using GO analysis we observed that the top genes are enriched with function of histone modification, highlighting the epigenetic {{regulatory mechanism}}s of recombination hotspots. </p...|$|R
40|$|During {{a typical}} {{measurement}} campaign, lots of {{temporal and spatial}} data can be gathered regarding {{the condition of the}} rail. This paper proposes two approaches that make use of data analytics techniques to find causes of rolling contact fatigue (RCF) damages. The first approach, named ‘bottom-up approach’, determines the influencing factors regarding RCF based on the worst affected areas (<b>hotspots).</b> The second <b>approach,</b> called ‘top-down approach’, determines the influencing factors based on the condition of the whole track. The approaches use correlation analysis, clustering and similarity of parameters. To show the advantage of the approaches, they have been used {{for the study of the}} Dutch High Speed Line (HSL). The results indicates that severe RCF defects occurred only under two very specific conditions. First, in specific curves where one type of train was driving under high tractive efforts and large cant excess through curves. Second, at the entry zones of the HSL where voltage locks are present, the same type of trains’ low driving speeds result in driving without cant excess/deficiency (theoretical cant). The conditions suggest that structurally driving below design speed on a high-speed track can be a cause of rail damages. Railway EngineeringIntegral Design and ManagementMaterials and Environmen...|$|R
40|$|ABSTRACT. Determining the {{original}} tectonic setting of volcanic rocks via their geochemical signature {{has been a}} long-standing goal for petrologists. However, current visually based methods for geochemical discrimination afford only limited success. We develop a probabilistic method for geochemical discrimination based upon statistics generated from geochemical databases and Bayesian analysis. This method incorporates elemental covariance, accounts for data measurement and theoretical uncertainty, and is not restricted in dimensionality of analysis, which is inherent in visual systems of discrimination. Furthermore, the method provides a direct way to discern statistical outliers whose inclusion would otherwise lead to lower discrimination accuracy. Tests of the approach yielded successful classification rates for single analyses of over 90 percent for volcanic arc basalts, mid-ocean ridge basalts, and ocean island basalts. introduction Fully understanding the geologic history of complex areas such as active margins often requires determining {{the original}} tectonic setting of volcanic rocks. However, these rocks are often set in an ambiguous context due to subsequent rearrangement by tectonic processes and, in most cases, geological inference alone is insufficient to discriminate between possible plate-tectonic settings. Therefore, we must rely on an examination of a sample’s intrinsic properties, such as its major and trace element abundances. Geochemical discrimination techniques {{have been used for}} decades to distinguish between the original plate-tectonic setting of volcanic rocks, such as those from island arcs, mid-ocean ridges, and ocean-island <b>hotspots.</b> One standard <b>approach</b> is to us...|$|R
