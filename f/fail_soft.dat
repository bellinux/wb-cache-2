3|23|Public
5000|$|A {{system that}} is {{designed}} to experience graceful degradation, or to <b>fail</b> <b>soft</b> (used in computing, similar to [...] "fail safe") operates at a reduced level of performance after some component failures. For example, a building may operate lighting at reduced levels and elevators at reduced speeds if grid power fails, rather than either trapping people in the dark completely or continuing to operate at full power. In computing an example of graceful degradation is that if insufficient network bandwidth is available to stream an online video, a lower-resolution version might be streamed in place of the high-resolution version. Progressive enhancement is an example in computing, where web pages are available in a basic functional format for older, small-screen, or limited-capability web browsers, but in an enhanced version for browsers capable of handling additional technologies or that have a larger display available.|$|E
40|$|A seventy hour {{flight test}} program was {{performed}} to determine the suitability and accuracy of a low cost Omega navigation receiver in a general aviation aircraft. An analysis was made of signal availability in two widely separated geographic areas. Comparison is made {{of the results of}} these flights with other navigation systems. Conclusions drawn from the test experience indicate that developmental system improvement is necessary before a competent fail safe or <b>fail</b> <b>soft</b> area navigation system is offered to general aviation...|$|E
40|$|A seventy hour {{flight test}} program was {{accomplished}} {{to determine the}} suitability and accuracy of a low cost Omega navigation receiver in a general aviation aircraft. An analysis was made of signal availability in two widely separated geographic areas. Comparison {{was made of the}} results of these flights with previous work focused on VOR/ DME. Conclusions are drawn from the test experience that indicate developmental system improvement is necessary before a competent fail safe or <b>fail</b> <b>soft</b> area navigation system is offered to general aviation. Cover titleOriginally presented as the author's thesis (E. A. A.), M. I. T. Dept. of Aeronautics and Astronautics, 1975 NASA CR- 132677 " [...] stamped on cover. [...] "R 75 - 5 " [...] handwritten on coverIncludes bibliographical references (p. 263 - 266) Prepared by Massachusetts Institute of Technology for National Aeronautics and Space Administratio...|$|E
30|$|The multi-axial {{correction}} (MAC) system (Biomet, Parsippany, NJ) is {{an external}} fixator capable of gradual or acute correction, {{as well as}} tri-planar angulation, translational, rotational, and length deformity correction that overcomes {{many of the issues}} faced by the traditional Ilizarov technique; this approach is particularly suited for angularity and length correction in early adolescents with previous <b>failed</b> <b>soft</b> tissue procedures. In this report, we describe a series of three cases (previously presented at the 2007 Pediatric Orthopaedic Society of North America [POSNA] Conference) of severe radial club hand in which the MAC fixation system was used to achieve successful deformity resolution and ulnar lengthening.|$|R
30|$|Clinically, the radial club hand {{spectrum}} is classifiable by severity {{into one of}} four types based {{on the degree of}} radius present (as described by Bayne and Klug [5]) or by a modified scheme that grades thumb, carpal, and radius deficiencies in summation [2, 5]. The treatment of radial club hand varies considerably with the extent of the deformity and the age of the patient. Mild cases of Bayne type I may be sufficiently treated by stretching and splinting. More severe cases may require preliminary soft tissue distraction and tendon transfer to rebalance the wrist [6, 7, 8, 9, 10], followed by surgical centralization of the wrist on the ulna and tendon transfer to rebalance the wrist [11, 12, 13]. Subsequent ulnar lengthening and angular correction may be performed, particularly in the case of <b>failed</b> <b>soft</b> tissue surgery, progressive angular deformity, or inadequate functional length; these procedures are preferable at early adolescence, where an external fixator can be tolerated and treatment does not interfere with psychosocial development [14, 15, 16, 17, 18, 19, 20].|$|R
40|$|Abstract Background A {{retrospective}} study concerning patients presenting with patella instability, treated using a Roux-Elmslie-Trillat reconstruction operation and followed up for 10 years following surgery, is presented. Methods Pre-operative and follow-up radiographic evaluation included the weight-bearing anteroposterior and merchant views. Evaluation {{was carried out}} using the Insall-Salvati index, sulcus and congruence angle. The Roux-Elmslie-Trillat reconstruction operation was performed on 18 patients. The clinical evaluation at follow-up was performed using the Knee-Society-Score (KSS) and Tegner-Score. Results Subjective results of the operation were classed as excellent or good in 16 of the 18 patients ten years after surgery; persistent instability of the patella was recorded in {{only one of the}} 18 patients. The majority of patients returned to the same level of sporting activity after surgery as they had participated in before injury. Conclusions The Roux-Elmslie-Trillat procedure could be recommended in cases presenting with an increased q-angle, trochlea dysplasia or <b>failed</b> <b>soft</b> tissue surgery. In the present study the majority of patients report a return to previous sporting activity ten years after surgery. </p...|$|R
6000|$|... "If {{you knew}} what I have suffered," [...] he said; [...] "if you had gone through what I have been {{compelled}} to endure--" [...] His voice <b>failed</b> him; his <b>soft</b> brown eyes moistened; his head drooped. He said no more.|$|R
40|$|Background: Outcomes in {{management}} of compound tibial fractures are {{measured by the}} rate of infection and non-union. These are a function of many variables that interact in complex ways. Our aims are to describe changes in these injuries over the past decade, to determine which variables predict a poor outcome and to compare reconstructive options controlling for these variables. Methods: All compound tibial fractures reconstructed at the Princess Alexandra Hospital from 1999 to early 2009 were reviewed retrospectively. The remainder of 2009 and 2010 were reviewed prospectively. Data were collected from departmental audits, medical records and imaging. Results: 251 flaps were performed in 235 patients. Reconstructions within one week declined after 2000, which correlated with increasing Negative Pressure Dressings use (R = 0. 77). Free flap use increased though the incidence of distal fractures did not (R = 0. 29). Muscle flaps were consistently preferred. Injuries with a poor outcome had a greater delay or <b>failed</b> <b>soft</b> tissue reconstruction. A poor outcome was more likely in patients with a contaminated distal fracture (p = 0. 0038). Outcomes in muscle and fasciocutaneous flaps were not significantly different. Conclusions: Compound tibial fracture management has evolved to temporary followed by definitive fixation. Free flap use has increased, particularly in diaphyseal injuries. Delays in reconstruction should prompt aggressive surgical management. Injuries at risk of a poor outcome can be further characterised as being distal and contaminated. Reconstructive surgeons should not be discouraged from using muscle flaps. A management algorithm {{based on the evidence}} provided is presented. Level of Evidence: Therapeutic III...|$|R
5000|$|The Peaveys' machine had {{two pairs}} of {{cylinders}} with an articulation between the pairs to effect steering. At least two prototype vehicles were constructed: one was steam powered the other used a gasoline engine. The prototypes worked well on hard packed snow but <b>failed</b> in <b>soft</b> powder because the flanges had nothing to grip into. The machine was designed to haul logs, but its length and rigid construction meant that it had difficulty with the uneven winter roads {{for which it was}} intended. Peavey's invention could not compete with the Lombard Steam Log Hauler built by Alvin Lombard and it was not produced commercially. (The Lombard vehicle was an early example of a half-track vehicle, it resembled a railway locomotive with a sled or wheels in front for steering and caterpillar tracks for traction.) ...|$|R
30|$|The {{pendulum}} for clubfoot {{treatment has}} swung substantially from operative to non-operative techniques {{over the past}} few decades [8]. In the present climate, the use of revision posteromedial release with calcaneocuboid fusions in this age group (4 – 8  years) may be unusual. However, the idea of limited fusions has been tested before as one possible solution for the difficult situation of a relapsed clubfoot [1, 9]. In 1999, our institution published on a series of 20 patients (27 feet) treated with the Dillwyn Evans procedure as a salvage procedure after <b>failed</b> initial <b>soft</b> tissue clubfoot releases [7]. At the time of final follow-up, most patients were not yet skeletally mature. The purposes of the present study were to determine: (1) functional level at 17 -year follow-up compared to 5 -year follow-up; (2) patients’ current functional level, satisfaction, and pain; and (3) current arthropometric measurements.|$|R
5000|$|While most {{algorithms}} achieve {{good results}} with hard cuts, many <b>fail</b> with recognizing <b>soft</b> cuts. Hard cuts usually go together with sudden and extensive {{changes in the}} visual content while soft cuts feature slow and gradual changes. A human being can compensate this lack of visual diversity with understanding {{the meaning of a}} scene. While a computer assumes a black line wiping a shot away to be [...] "just another regular object moving slowly through the on-going scene", a person understands that the scene ends and is replaced by a black screen.|$|R
40|$|A moment {{resisting}} {{frame is}} one of the most commonly used lateral load resisting system in modem structures because it is suitable for low and medium rise buildings and industrial structures. It can be designed to behave in a ductile manner under seismic loads. Masonry infills have traditionally been used in buildings as partitions and for architectural or aesthetic reasons. They are normally considered as non-structural elements, and their effect on the structural system has been ignored in the design. However, even though they are considered non-structural elements, there is mounting evidence that they interact with the frame when the structures are subjected to lateral loads Infill walls have been identified as a contributing factor to catastrophic structural failures during earthquakes. Frame-infill interaction can induce brittle shear failures of reinforced concrete columns by creating a short column. Furthermore, infills can over-strengthen the upper stories of a structure and when they <b>fail</b> a <b>soft</b> first storey is created, which is highly undesirable from the earthquake resistance standpoint. There is a need for an efficient and accurate computational model to simulate the nonlinea...|$|R
40|$|Young's law <b>fails</b> on <b>soft</b> {{solid and}} liquid {{substrates}} where there are substantial deformations near the contact line. On liquid substrates, this is captured by Neumann's classic analysis, which provides a geometrical construction for minimising the interfacial free energy. On soft solids, the total free energy includes an additional contribution from elasticity. A linear-elastic model incorporating an out-of-plane restoring force due to solid surface tension was recently shown to accurately predict the equilibrium shape of a thin elastic film due to a large sessile droplet. Here, we extend this model to find substrate deformations due to droplets of arbitrary size. While the macroscopic contact angle matches Young's law for large droplets, it matches Neumann's prediction for small droplets. The cross-over droplet size is roughly given by {{the ratio of the}} solid's surface tension and elastic modulus. At this cross-over, the macroscopic contact angle increases, indicating that the substrate is effectively less wetting. For droplets of all sizes, the microscopic behaviour near the contact line follows the Neumann construction giving local force balance. Comment: 5 figure...|$|R
40|$|Risk-based {{inspection}} methods enable {{estimation of}} the probability of failure on demand for spring-operated pressure relief valves at the United States Department of Energy&#x 27;s Savannah River Site in Aiken, South Carolina. This paper presents a statistical performance evaluation of soft seat spring operated pressure relief valves. These pressure relief valves are typically smaller and of lower cost than hard seat (metal to metal) pressure relief valves and can provide substantial cost savings in fluid service applications (air, gas, liquid, and steam) providing that probability of failure on demand (the probability that the pressure relief valve fails to perform its intended safety function during a potentially dangerous over pressurization) {{is at least as}} good as that for hard seat valves. The research in this paper shows that the proportion of soft seat spring operated pressure relief valves failing is the same or less than that of hard seat valves, and that for <b>failed</b> valves, <b>soft</b> seat valves typically have failure ratios of proof test pressure to set pressure less than that of hard seat valves...|$|R
40|$|This paper {{describes}} {{a strategy for}} a robotic hand to pick up deformable 3 D objects from a table. Inspired by the human hand behavior, the robotic hand employs two rigid fingers to first squeeze a soft object until it “feels ” the object to be liftable. Such “feeling ” is provided by a (virtual) liftability test that is repeatedly conducted during the squeeze. Passing of the test then triggers a lifting action. Throughout the manipulation the object’s deformation and its state of contact with the fingers and the table are being tracked based on contact events. Deformable modeling uses the finite element method (FEM) while slip computation employs the homotopy continuation method, based on the contact displacements induced by finger movements. Experiment was conducted over daily items ranging from vegetables to a toy. A simulation-based comparison between deformable grasping and rigid body grasping reveals why soft objects are easier to pick up than hard ones, and demonstrates how a grasping strategy for rigid objects could <b>fail</b> on <b>soft</b> objects in certain situations. KEY WORDS — Deformable grasping, gravity, liftability test, contact modes, finite element method. ...|$|R
40|$|We outline a {{proof of}} {{factorization}} in exclusive processes, {{taking into account}} the presence of soft and collinear modes of arbitrarily low energy, which arise when the external lines of the process are taken on shell. Specifically, we examine the process of e^+e^- annihilation through a virtual photon into two light mesons. In an intermediate step, we establish a factorized form that contains a soft function that is free of collinear divergences. In contrast, in soft-collinear effective theory, the low-energy collinear modes factor most straightforwardly into the soft function. We point out that the cancellation of the soft function, which relies on the color-singlet nature of the external hadrons, <b>fails</b> when the <b>soft</b> function contains low-energy collinear modes. Comment: 18 pages, 10 figures, 2 tables, version published in Physical Review...|$|R
40|$|Most of the peers {{accessing}} the services {{are under the}} assumption that the service accessed in a P 2 P network is utmost secured. By means of prevailing hard security mechanisms, security goals like authentication, authorization, privacy, non repudiation of services and other hard security issues are resolved. But these mechanisms <b>fail</b> to provide <b>soft</b> security. An exhaustive survey of existing trust and reputation models in P 2 P network regarding service provisioning is presented and challenges are listed. p 2 p Trust issues like trust bootstrapping, trust evidence procurement, trust assessment, trust interaction outcome evaluation and other trust based classification of peers behaviour into trusted, inconsistent, un trusted, malicious, betraying, redemptive are discussed. Comment: 12 pages, 4 figures, 1 table, International Journal on Web Service Computing (IJWSC), Vol. 5, No. 3, September 201...|$|R
40|$|Parking {{space for}} {{residential}} apartments in populated cities {{is a matter}} of major concern. Hence the trend has been to utilize the ground storey of the building itself for parking. “Open Ground Storey” (OGS) buildings are those types of buildings in which the ground storey is free of any infill masonry walls. These types of buildings are very common in India for parking provisions. The strength and stiffness of infill walls in infilled frame buildings are ignored in the structural modelling in conventional design practice. The design in such cases will generally be conservative in the case of fully infilled framed building. But the behaviour is different in the case of OGS framed building. OGS framed building is slightly stiffer than the bare frame, has larger drift (especially in the ground storey), and <b>fails</b> due to <b>soft</b> storey-mechanism at the ground floor...|$|R
50|$|In {{previous}} Ys titles, {{players had}} to switch between elemental weapons to damage monsters and bosses. In this game, weapon types {{are used to}} determine whether damage is enhanced or minimized. Slashing weapons deal enhanced damage to <b>soft</b> enemies but <b>fail</b> against hard enemies. Striking weapons deal enhanced damage to hard and armored enemies but <b>fail</b> against <b>soft</b> enemies. Piercing weapons deal enhanced damage to flying enemies and other agile enemies but fail against armored enemies. A party can have up to three characters in it with the player controlling one of them. The two other members are controlled by the AI while in combat {{and it is possible}} to set how they attack. All playable characters except for Adol are able to use weapons that fit a damage type assigned to that character, while Adol uses swords that can be classified to any damage type. For example, Dogi can only use punching weapons which all deal striking damage. Hitting enemies with charged attacks fills a skill point meter that allows characters to perform skills. Skills are taught by using different weapons. Once a character uses a skill enough, he or she can use the skill with any weapon. Further use of a skill allows the user to enhance the skill. There is also an extra meter that when filled, allows the character the player controls to perform a super attack. Using skills is needed to fill the extra meter.|$|R
40|$|A deep {{exposure}} of the bright star Arcturus (Alpha Bootis: K 1 III) with the Roentgensatellit (Rosat) <b>failed</b> to detect <b>soft</b> X-ray emission from the archetype 'noncoronal' red giant. The 3 -sigma upper limit in the energy band 0. 1 - 2. 4 keV corresponds to an X-ray luminosity of less than 3 x 10 to the 25 th erg/s, equivalent to a coronal surface flux density of less than 0. 0001 solar. The nondetection safely eliminates coronal irradiation as a possible mechanism to produce the highly variable He I 10830 feature and emphasizes the sharp decline in solarlike coronal activity that accompanies the evolution of low-mass single stars away from the main sequence. While the most conspicuous object in the Rosat field of view was not visible in X-rays, at least one fainter star is among the about 60 sources recorded: the Sigma Sct variable CN Boo, an A 8 giant in the UMa Stream...|$|R
40|$|Particle Accelerators require {{high voltage}} and often high power. Typically the high voltage/power {{generation}} utilizes a topology {{with an extra}} energy store and a switching means to extract that stored energy. The switches may be active or passive devices. Active switches are hard or soft vacuum tubes, or semiconductors. When required voltages exceed tens of kilovolts, numerous semiconductors are stacked to withstand that potential. Such topologies can use large numbers of critical parts that, when in series, compromise the system reliability and performance. This paper describes a modular, linear, solid state amplifier which uses a parallel array of semiconductors, coupled with transmission line transformers. Such a design can provide output signals with voltages exceeding 10 kV (into 50 -ohms), and with rise and fall times (10 - 90 % amplitude) that are less than 1 [...] ns. This compact solid state amplifier is modular, and has both hot-swap and <b>soft</b> <b>fail</b> capabilities...|$|R
40|$|Subterminal {{polygalacturonase}} from Aspergillus, which <b>fails</b> to macerate <b>soft</b> {{plant tissue}} {{in spite of}} a rapid action on pectate in vitro, was examined for its action at pH 3. 5 on substrate (degree of polymerization 9 - 50) altered by the reduction of the reducing end to 3 H labeled l-galactonic acid, and the introduction of unsaturation in a portion of the nonreducing end groups. Endo-polygalacturonase from Saccharomyces fragilis was used as a control. The hydrolysis products were separated by gel filtration chromatography and the sugar residues, the tritium label, and the ultraviolet absorption (of the unsaturated groups) were measured. Endo-polygalacturonase gave equal production of the two end-labeled oligomers. Subterminal polygalacturonase rapidly produced a mixture of tritiated oligomers (mainly trimer, dimer, and tetramer), 2. 5 times faster than it liberated unsaturated oligomers, and 3 times faster than it liberated unlabeled oligomers, showing that its action begins at the reducing end. The unsaturated pentamer and hexamer, which accumulated during the rapid phase of enzyme action, were subsequently hydrolyzed to the unsaturated tetramer, in accord with action from the reducing end...|$|R
40|$|ABSTRACT. The {{drive to}} reduce vehicle weight and improve crash {{performance}} has led automotive manufacturers to in-troduce higher-strength grades of ad-vanced high-strength steels (AHSS). For these materials {{to be used}} effectively, the influence of material and process condi-tions on gas metal arc (GMA) weld prop-erties must be understood. The objective of this work was to characterize the effects of material prestrain, cooling rate condi-tions (welding heat input and fixture heat sink), filler metal selection, dilution, and postbaking on the microstructure and me-chanical properties of GMA welds on coated dual-phase (DP) and transforma-tion-induced plasticity (TRIP) steels. The primary materials studied were DP 780 and TRIP 780; for comparison purposes {{a limited amount of}} work was conducted with DP 980. The DP steels showed vary-ing degrees of heat-affected zone (HAZ) hardening and softening depending on the material grade, prestrain, and cooling rate condition. The relatively high aluminum content of the TRIP 780 allowed retained ferrite to be present in all regions of the HAZ, along with a continuous region of coarse ferrite along the weld interface. This resulted in the TRIP 780 having lower peak HAZ hardness than the DP 780. Fusion zone microstructure and hard-ness were found to be affected by the base metal chemistry, the cooling rate condi-tion, and the filler metal composition. Filler metal strength did not affect the sta-tic or dynamic tensile properties of either the TRIP 780 lap or butt joint welds, or the DP 780 butt joint welds. All of the TRIP 780 and DP 780 butt joints <b>failed</b> in the <b>soft</b> HAZ. The results of the lap joint tests showed a greater variation in strength that is attributed to porosity {{at the root of the}} weld...|$|R
40|$|As we move {{deep into}} {{nanometer}} regime of CMOS VLSI (45 nm node and below), the device noise margin gets sharply eroded because of continuous lowering of device threshold voltage together with ever increasing rate of signal transitions {{driven by the}} consistent demand for higher performance. Sharp erosion of device noise margin vastly {{increases the likelihood of}} intermittent failures (also known as parametric failures) during device operation as opposed to permanent failures caused by physical defects introduced during manufacturing process. The major sources of intermittent failures are capacitive crosstalk between neighbor interconnects, abnormal drop in power supply voltage (also known as droop), localized thermal gradient, and soft errors caused by impact of high energy particles on semiconductor surface. In nanometer technology, these intermittent failures largely outnumber the permanent failures caused by physical defects. Therefore, it is of paramount importance to come up with efficient test generation and test application methods to accurately detect and characterize these classes of failures. ^ Soft error rate (SER) is an important design metric used in semiconductor industry and represented by number of such errors encountered per Billion hours of device operation, known as Failure-In-Time (FIT) rate. Soft errors are rare events. Traditional techniques for SER characterization involve testing multiple devices in parallel, or testing the device while keeping it in a high energy neutron bombardment chamber to artificially accelerate the occurrence of single events. Motivated by the fact that measurement of SER incurs high time and cost overhead, in this thesis, we propose a two step approach: 〈i〉 a new filtering technique based on amplitude of the noise pulse, which significantly reduces the set of soft error susceptible nodes to be considered for a given design; followed by 〈ii〉 an Integer Linear Program (ILP) -based pattern generation technique that accelerates the SER characterization process by 1 - 2 orders of magnitude compared to the current state-of-the-art. ^ During test application, it is important to distinguish between an intermittent failure and a permanent failure. Motivated by {{the fact that most of}} the intermittent failures are temporally sparse in nature, we present a novel design-for-testability (DFT) architecture which facilitates application of the same test vector twice in a row. The underlying assumption here is that a <b>soft</b> <b>fail</b> will not manifest its effect in two consecutive test cycles whereas the error caused by a physical defect will produce an identically corrupt output signature in both test cycles. Therefore, comparing the output signature for two consecutive applications of the same test vector will accurately distinguish between a <b>soft</b> <b>fail</b> and a hard fail. We show application of this DFT technique in measuring soft error rate as well as other circuit marginality related parametric failures, such as thermal hot-spot induced delay failures. ^ A major contribution of this thesis lies on investigating the effect of multiple sources of noise acting together in exacerbating the noise effect even further. The existing literature on signal integrity verification and test falls short of taking the combined noise effects into account. We particularly focus on capacitive crosstalk on long signal nets. A typical long net is capacitively coupled with multiple aggressors and also tend to have multiple fanout gates. Gate leakage current that originates in fanout receivers, flows backward and terminates in the driver causing a shift in driver output voltage. This effect becomes more prominent as gate oxide is scaled more aggressively. In this thesis, we first present a dynamic simulation-based study to establish the significance of the problem, followed by proposing an automatic test pattern generation (ATPG) solution which uses 0 - 1 Integer Linear Program (ILP) to maximize the cumulative voltage noise at a given victim net due to crosstalk and gate leakage loading in conjunction with propagating the fault effect to an observation point. Pattern pairs generated by this technique are useful for both manufacturing test application as well as signal integrity verification for nanometer designs. This research opens up a new direction for studying nanometer noise effects and motivates us to extend the study to other noise sources in tandem including voltage drop and temperature effects. ...|$|R
40|$|Fiber {{laser welding}} (FLW) {{was used to}} join {{advanced}} high strength steel (AHSS) and high strength steel (HSS); specifically two dual-phase (DP) steels, with ultimate tensile strengths above 980 MPa and with different chemistries (DP 980 Rich and DP 980 Lean), and a {{high strength low alloy}} (HSLA) steel, with an ultimate tensile strength of 450 MPa (HSLA 450). The welding speed and power were varied to develop a process envelope for minimizing weld concavity. In order to attain welds free of weld concavity a balance of speed and power was required; weld concavity could be reduced by lowering power and increasing speed. Welds with amounts of concavity ranging from 15 % to 35 % were characterized with respect to hardness, tensile and fatigue testing. Tensile results revealed that DP steel was sensitive to weld concavity while HSLA 450 was not. At stress amplitudes enduring beyond 1000 cycles, welded specimens exhibited lower fatigue resistance compared to the base metal. Concavity reduced the fatigue life of DP 980 steels, where increasing the amount of concavity further reduced the fatigue resistance, while the fatigue resistance of HSLA steel welds was not sensitive to weld concavity. Hardness profiling of the welds revealed that HAZ softening was present in the DP 980 steel welds. The amount of HAZ softening was normalized; allowing for comparison of different steels. Welds made by FLW demonstrated reduced softening compared other laser welding types because FLW was capable of welding with lower heat input. A difference in the FZ hardness was observed between the DP 980 steels because of the difference in carbon content of the steels; where higher carbon content resulted in higher FZ hardness. Additionally the high cooling rate in FLW created higher fusion zone hardness than the values predicted by Yurioka’s model based on arc welding. Examination of the microstructure revealed that the soft zone of DP 980 Lean steel possessed severely tempered martensite and untransformed ferrite while DP 980 Rich generated a structure with a mixture of tempered martensite, untransformed ferrite and a small fraction of non-tempered martensite. This difference in HAZ softening was attributed to the alloying content of the DP 980 Rich steel the higher alloying content of DP 980 Rich steel formed a stable austenite that could exist near the Ac 1 temperature and enabled the formation of new martensite in the soft zone. The effects of HAZ softening were apparent in tensile testing where the DP 980 Lean steel, which exhibited higher softening, demonstrated by a severe reduction in elongation while the DP 980 Rich steel, which had higher resistance to softening, attained elongation comparable to its base metal. HSLA 450 exhibited a slight reduction in elongation due to the hardening of the fusion zone. The welded DP 980 Rich and HSLA 450 steels consistently failed within the base metal, while the DP 980 Lean steel <b>failed</b> in the <b>soft</b> zone. The welded DP 980 Rich steel also demonstrated limiting dome heights comparable to the base metal while the severe softening in the DP 980 Lean led to premature fracture in the soft zone, yielding a larger reduction in the limiting dome height...|$|R
40|$|By today disciplines, both hard {{sciences}} and softer areas that often {{fight for the}} ‘scientific’ status, grew so large that they became impossible to master. This statement perhaps re-quires some explanation. By hard sciences we mean disciplines, such as physics or biology, that are {{around for a long}} time, focus on discovering universally and infinitely (both in time and space) valid laws of nature and are in a position where the ‘truth’ of their statements can be demonstrated, enabling prediction and control. In turn, soft disciplines, including not only arts but also any knowledge domains that aim at understanding human and social phe-nomena, are in comparison limited. This means, that the laws of nature in these areas {{do not seem to be}} universally and infinitely valid (there are variations both in time and space), ‘truth’ allows for multiple interpretations, and prediction and control, if attempted, usually <b>fail.</b> These <b>soft</b> knowledge domains thus cannot meet the requirements of hard scientific disciplines. There are three ways to battle this situation: (1) giving up the claim of the scien-tific status, (2) redefine what science means in such knowledge domains, and (3) trying to squeeze the discipline into the traditional ‘science’ box. Most researchers in the human-social arena are unhappy with (1), cannot make (2) happen and thus attempt (3). We be-lieve that this is not only dangerous but outright harmful. When squeezing the human-social disciplines into the ‘science’ box, the discipline is truncated. Instead of becoming scientific they become ‘scientistic’ (Dörfler & Eden, 2014). We do not attempt to resolve this problem in this paper but we wanted to clarify our departure point in order to outline the playing field. What is common for both hard and soft disciplines is that there is such amount of knowledge accumulated in each of them that it is impossible to master any of them completely. This means that nobody today knows physics or biology – and, equally, nobody knows psychology or economics. However, it is possible to get a taster from the various disciplines at every level of education. Education starts with a liberal arts phase. Elementary school pupils learn reading, calculating, somersaulting, painting and singing. In higher school years they may learn solving integrals, burning sulphur, the directions and timing of Napoleon’s quests or that the antagonist is a necessary component of a story. Here pupils start to specialise, shift-ing more towards hard or soft. At university level students of engineering become familiar with the deep secrets of the Carnot-cycle and the Nash equilibrium but are not longer able to understand anything a sociology professors says, and vice versa. The outcome of the uni-versity is then a semi-specialised cultivated mind. By semi-specialised we mean that it is not a balanced knowledge any more, such as it was in the liberal arts phase, but engineers can still read, know some history, and some of them will appreciate paintings, others music. Some are more narrowly focused than others, but all of them will have knowledge limited to the part of their respective disciplines that can be taught and learned. This part is easy to accept. However we also want to make an assertion that is somewhat more difficult to ac-cept: the knowledge acquired in formal education is both necessary and useless. The semi-specialised cultivated mind is familiar with the main concepts of the discipline(s) they specialised in. In the formal education these concepts are developed from scratch, which is a time-consuming process, and they are validated in an intellectual context, through thinking. This means that the cultivated mind sees the world through the lens of their re-spective disciplines and can think about it using the disciplinary context. Then, however, the cultivated mind leaves the school and finds itself in the context of praxis. To their horror the school-leavers find themselves in a place that seems familiar, i. e. they recognise the con-cepts – but these concepts seem to make a completely different sense than what they ‘sup-pose’ to mean. The knowledge of the textbooks is useless. At this point it does not help if further and further disciplinary concepts are added to the cultivated mind. Instead, in the context of praxis the same disciplinary concepts are re-developed, they gradually acquire a new meaning validated through application. However, it would not be possible to re-develop the concepts, if the school-leaver did not have them in the first place. Therefore the formal education is also indispensable. From time to time the practitioner may go back to the for-mal education for knowledge refreshment, acquire new concepts of the discipline, and then bring these back to praxis. Thus going back and forth between the formal education and the praxis competence emerges. We expect the competent practitioner to be able to solve the problems of praxis. However, as they are becoming competent, the practitioners quickly discover that the real world of praxis does not fit within the boundaries of any discipline. In order to solve any real-life problem in praxis, we need to borrow tools, models, insights sometimes from one other times from another discipline. This will partly lead to the competent practitioners expanding their horizons, and partly to working together with other competent practitioners (semi) specialised in different disciplines. These processes of problem solving we call trans-disciplinary. Without attempting detailed delineation from inter-, cross- and multidiscipli-nary, we conceptualise the transdisciplinary problem solving process as one in which we bor-row what and when needed from various disciplines in order to solve the problem at hand. In a sense it can be regarded as a superior stage of interdisciplinarity, “which will not be limited to recognize the interactions and/or reciprocities between the specialized research-es, but which will locate these links inside a total system without stable boundaries between the disciplines” (Piaget, 1972). Together with Nicolescu (2010) we argue that such transdis-ciplinarity must not be reduced to the ‘hard sciences’. In our presentation we will address the possibility of supporting transdisciplinary problem solving process through a particular form of coaching called knowledge engineering and knowledge based expert system...|$|R

