20|30|Public
25|$|Digest access {{authentication}} {{is one of}} the agreed-upon methods a {{web server}} can use to negotiate credentials, such as username or password, with a user's web browser. This can be used to confirm the identity of a user before sending sensitive information, such as online banking transaction history. It applies a hash function to the username and password before sending them over the network. In contrast, basic access authentication uses the easily reversible Base64 encoding instead of <b>hash</b> <b>digest,</b> making it non-secure unless used in conjunction with TLS.|$|E
50|$|Spectral hash is insecure; {{a method}} exists to {{generate}} arbitrary collisions in the hash state, and therefore {{in the final}} <b>hash</b> <b>digest.</b>|$|E
50|$|The {{vulnerable}} hashing functions work {{by taking}} the input message, and using it to transform an internal state. After all of the input has been processed, the <b>hash</b> <b>digest</b> is generated by outputting the internal state of the function. It is possible to reconstruct the internal state from the <b>hash</b> <b>digest,</b> which can then be used to process the new data. In this way one may extend the message and compute the hash that is a valid signature for the new message.|$|E
5000|$|For this reason, most digital {{signature}} algorithms only confirm {{the authenticity of}} a <b>hashed</b> <b>digest</b> of the message to be [...] "signed". Verifying the authenticity of a <b>hashed</b> <b>digest</b> of the message is considered proof that the message itself is authentic.|$|R
50|$|SHA-2 {{includes}} {{significant changes}} from its predecessor, SHA-1. The SHA-2 family consists of six <b>hash</b> functions with <b>digests</b> (<b>hash</b> values) that are 224, 256, 384 or 512 bits: SHA-224, SHA-256, SHA-384, SHA-512, SHA-512/224, SHA-512/256.|$|R
50|$|There {{are several}} reasons to sign such a <b>hash</b> (or message <b>digest)</b> instead of the whole document.|$|R
50|$|A desired {{characteristic}} of a cryptographic hash algorithm is that (for all practical purposes) the hash result (referred to as a <b>hash</b> <b>digest</b> or a hash) of any two modules will produce the same hash value only if the modules are identical.|$|E
5000|$|Nilsimsa is an {{anti-spam}} focused locality-sensitive hashing algorithm. The goal of Nilsimsa is {{to generate}} a <b>hash</b> <b>digest</b> of an email message such that the digests of two similar messages are similar to each other. The paper suggests that the Nilsimsa satisfies three requirements: ...|$|E
50|$|TLSH is locality-sensitive hashing {{algorithm}} {{designed for a}} range of security and digital forensic applications. The goal of TLSH is to generate a <b>hash</b> <b>digest</b> of document such that if two digests have a low distance between them, then {{it is likely that the}} messages are similar to each other.|$|E
40|$|This paper {{presents}} {{applications of}} the trope of the locked and sealed piggy-bank into which the secret can be easily inserted but from which it cannot be withdrawn without opening the box. We present a basic two-pass cryptographic scheme that can serve as template {{for a variety of}} implementations. Together with the sealed piggy-bank is sent a coded letter that lists and certifies the contents of the box. We show how this idea can help increase the security of cryptographic protocols for classical systems as well as those based on "single-state" systems. More specifically, we propose the use of a <b>hashing</b> <b>digest</b> (instead of the coded letter) to detect loss of key bits to the eavesdropper and use in communication systems where error correction is an important issue. Comment: 7 pages, 6 figure...|$|R
50|$|Ensuring {{the message}} as {{sent by the}} {{application}} is immutable allows for end-to-end message signing and/or encryption and ensures that any integrity checks (e.g. <b>hashes</b> or <b>digests)</b> remain valid. The message can be annotated by intermediaries during transit, but any such annotations are kept distinct from the immutable bare message. Annotations may be added {{before or after the}} bare message.|$|R
40|$|Image perceptual hashing is {{a notable}} concept {{in the field}} of image processing. Its {{application}} ranges from image retrieval, image authentication, image recognition, to content-based image management. In this paper a novel image hashing algorithm based on SURF and KPCA, which extracts speed-up robust feature as the perceptual feature, is proposed. SURF retains the robust properties of SIFT, and it is 3 to 10 times faster than SIFT. Then, the Kernel PCA is used to decompose key points&# 39; descriptors and get compact expressions with well-preserved feature information. To improve the precision of digest matching, a binary image template of input image is generated which contains information of salient region to ensure the key points in it have greater weight during matching. After that, the <b>hashing</b> <b>digest</b> for image retrieval and image recognition is constructed. Experiments indicated that compared to SIFT and PCA based perceptual hashing, the proposed method could increase the precision of recognition, enhance robustness, and effectively reduce process time. © 2016 SPIE. </p...|$|R
50|$|First {{layer of}} the encryption: The {{ciphertext}} of the original readable message is hashed, and subsequently the symmetric keys are encrypted via the asymmetric key - e.g. deploying the algorithm RSA.In an intermediate step the ciphertext, and the <b>hash</b> <b>digest</b> of the ciphertext are combined into a capsule, and packed together.It follows the approach: Encrypt-then-MAC. In order for the receiver to verify that the ciphertext has not been tampered with, the digest is computed before the ciphertext is decrypted.|$|E
5000|$|Where [...] "data" [...] is the {{encrypted}} data that immediately follows the Interlock Protocol exchange (it could be anything), encoded using an all-or-nothing transform to prevent in-transit {{modification of the}} message. Ma<1> could contain an encrypted request {{and a copy of}} Ka. Ma<2> could contain the decryption key for Ma<1>. Mb<1> could contain an encrypted copy of Kb, and Mb<2> could contain the decryption key for Mb<1> and the response, such as OK, or NOT FOUND, and the <b>hash</b> <b>digest</b> of the data.|$|E
5000|$|Nilsimsa is an {{anti-spam}} focused locality-sensitive {{hashing algorithm}} originally proposed the cmeclax remailer operator in 2001 and then reviewed by Ernesto Damiani et al. in their 2004 paper titled, [...] "An Open Digest-based Technique for Spam Detection". The goal of Nilsimsa is {{to generate a}} <b>hash</b> <b>digest</b> of an email message such that the digests of two similar messages are similar to each other. In comparison with cryptographic hash functions such as SHA-1 or MD5, making a small modification to a document does not substantially change the resulting hash of the document. The paper suggests that the Nilsimsa satisfies three requirements: ...|$|E
5000|$|A <b>digest</b> (<b>hash)</b> of {{the user}} entered {{password}} in UTF-8 encoding is created and passed to the package component. ODF versions 1.0 and 1.1 only mandate support for the SHA-1 digest here, while version 1.2 recommends SHA-256.|$|R
30|$|Repudiation. Even if an {{attacker}} A {{creates a}} modified file F′ by inserting an extra 1 byte near {{the start of}} an original file F to bypass sector hashing, LogDrive preserves both the original file F and the modified file F′. In this case, similarity <b>digest</b> <b>hash</b> algorithms, such as sdhash [54], are needed to find F′ using the original file F.|$|R
40|$|Abstract. We re-examine {{the needs}} of {{computer}} security in pervasive computing from first principles, specifically the problem of bootstrap-ping secure networks. We {{consider the case of}} systems that may have no shared secret information, and where there is no structure such as a PKI available. We propose several protocols which achieve a high degree of security based on a combination of human-mediated communication and an ordinary Dolev-Yao communication medium. In particular they resist combinatorial attacks on the <b>hash</b> or <b>digest</b> values that have to be compared by human users, seemingly optimising the amount of secu-rity they can achieve for a given amount of human effort. We compare our protocols with recent pairwise protocols proposed by, for example, Hoepman and Vaudenay. ...|$|R
5000|$|This message {{includes}} {{all of the}} padding that was appended to the original message inside of the hash function before his payload (in this case, a 0x80 followed {{by a number of}} 0x00s and a message length, 0x228 = 552 = (14+55)*8, which is the length of the key plus the original message, appended at the end). The attacker knows that the state behind the hashed key/message pair for the original message is identical to that of new message up to the final [...] "&." [...] The attacker also knows the <b>hash</b> <b>digest</b> at this point, which means they know the internal state of the hashing function at that point. It is then trivial to initialize a hashing algorithm at that point, input the last few characters, and generate a new digest which can sign his new message without the original key.|$|E
50|$|A related {{application}} is password verification (first invented by Roger Needham). Storing all user passwords as cleartext {{can result in}} a massive security breach if the password file is compromised. One way to reduce this danger is to only store the <b>hash</b> <b>digest</b> of each password. To authenticate a user, the password presented by the user is hashed and compared with the stored hash. (Note that this approach prevents the original passwords from being retrieved if forgotten or lost, {{and they have to be}} replaced with new ones.) The password is often concatenated with a random, non-secret salt value before the hash function is applied. The salt is stored with the password hash. Because users will typically have different salts, it is not feasible to store tables of precomputed hash values for common passwords when salt is employed. On the other hand, standard cryptographic hash functions are designed to be computed quickly, and, as a result, it is possible to try guessed passwords at high rates. Common graphics processing units can try billions of possible passwords each second. Key stretching functions, such as PBKDF2, Bcrypt or Scrypt, typically use repeated invocations of a cryptographic hash to increase the time, and in some cases computer memory, required to perform brute force attacks on stored password digests.|$|E
3000|$|... [...]. Using {{the ideal}} {{theoretical}} {{value of the}} <b>hash</b> <b>digest</b> H, we can calculate the ideal theoretical absolute difference of the two hash digests. With {{the assumption that the}} two hash digests H and H [...]...|$|E
40|$|Digest Values for DOM (DOMHASH) Status of this Memo This memo {{provides}} {{information for the}} Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2000). All Rights Reserved. This memo defines a clear and unambiguous definition of <b>digest</b> (<b>hash)</b> values of the XML objects regardless of the surface string variation of XML. This definition {{can be used for}} XML digital signature as wel...|$|R
50|$|A hash {{function}} is any function {{that can be}} used to map data of arbitrary size to data of fixed size. The values returned by a {{hash function}} are called hash values, <b>hash</b> codes, <b>digests,</b> or simply <b>hashes.</b> One use is a data structure called a hash table, widely used in computer software for rapid data lookup. Hash functions accelerate table or database lookup by detecting duplicated records in a large file. An example is finding similar stretches in DNA sequences. They are also useful in cryptography. A cryptographic hash function allows one to easily verify that some input data maps to a given hash value, but if the input data is unknown, it is deliberately difficult to reconstruct it (or equivalent alternatives) by knowing the stored hash value. This is used for assuring integrity of transmitted data, and is the building block for HMACs, which provide message authentication.|$|R
40|$|Recent {{work has}} {{proposed}} the Lempel-Ziv Jaccard Distance (LZJD) {{as a method}} to measure the similarity between binary byte sequences for malware classification. We propose and test LZJD's effectiveness as a similarity <b>digest</b> <b>hash</b> for digital forensics. To do so we develop a high performance Java implementation with the same command-line arguments as sdhash, {{making it easy to}} integrate into existing work-flows. Our testing shows that LZJD is effective for this task, and significantly outperforms sdhash and ssdeep in its ability to match related file fragments and is faster at comparison time...|$|R
3000|$|... of {{the mean}} value of a uniform {{distribution}} [47]. As the mean value of a uniform distribution with {{the characteristics of a}} <b>hash</b> <b>digest</b> with the size of 128 bits is equal to 2, 040, therefore, the ideal mean value of the absolute difference for H and H [...]...|$|E
40|$|Cryptographic hash {{function}} {{has been used}} extensively in many cryptographic protocols. Many of the {{hash function}}s generate the message digest thru a randomizing process of the original message. Subsequently a chaos system also generates random behavior, {{but at the same}} time a chaos system is completely deterministic. In this paper, we propose a new hash function (CHA- 1) based on chaos, which produces 160 -bit <b>hash</b> <b>digest,</b> accepts message length less than 280 bits, and has a security factor 280 of brute-force attack...|$|E
40|$|ISSN (online) : 2231 - 8852 Stenography {{is the art}} {{of hiding}} secret message into a cover media. Some of the usage for this {{algorithm}} is to protect the digital Holly Quran. This paper presents a novel stenographic algorithm based on the spatial domain. THE NEW ALGORITHM refers to a combined stenographic techniques; mainly Huffman algorithm and SLSB algorithm. The new method will both provide a less distortion images and increase the security. THE NEW ALGORITHM will use the <b>hash</b> <b>digest</b> from the Gear hash function as a secret message...|$|E
30|$|Hash table {{has been}} widely used in {{computer}} science as well, mainly for quick search of things in each of different value, {{and is able to}} identify certain location[10, 11]. Another popular use of <b>hash</b> is message <b>digest</b> or fingerprint such as MD 5 [12] to ensure integrity in a large amount of data (such as files or records) by either identifying or verifying using a small amount of information. Hash is also used in several major applications for identifying the changed part within large datasets such as remote file synchronization tool[13, 14] and squid proxy server[15].|$|R
50|$|Another avatar-based {{system is}} one wherein an image is {{automatically}} generated {{based on the}} identity of the poster. Identicons are formed as visually distinct geometric images derived from a <b>digest</b> <b>hash</b> of the poster's IP address. In this way, a particular anonymous user can be uniquely identified from session to session without the need for registration or authentication. In the cases where registration has occurred, the identicon serves as a means to associate a particular user with a particular geometric representation. If an account is compromised, a dissimilar identicon will be formed as the attacker is posting from an unfamiliar IP address.|$|R
40|$|Abstract—This paper {{presents}} {{the design and}} analysis of an area efficient implementation of the SHA- 3 candidate Blue Midnight Wish (BMW- 256) <b>hash</b> function with <b>digest</b> size of 256 bits on an FPGA platform. Our architecture {{is based on a}} 32 bit data-path. The core functionality with finalization implementation without padding stage of BMW on Xilinx Virtex- 5 FPGA requires 84 slices and two blocks of memory: one memory block to store the intermediate values and hash constants and the other memory block to store the instruction controls. The proposed implementation achieves a throughput of 56 Mpbs. Keywords-SHA- 3; Blue Midnight Wish; NIST...|$|R
40|$|Abstract: This paper {{presents}} a HMAC based Temper Evident Encryption (HTEE) technique for providing confidentiality {{and integrity of}} numeric data in a database environment through an encryption scheme based on the keyed Hash Message Authentication Code (HMAC) function. The encryption scheme implemented in this project extends and improves an existing HMAC based encryption scheme. The result is a symmetric encryption process which detects unauthorized updates to ciphertext data, verifies integrity and provides confidentiality. This encryption scheme provides an alternative to standard approaches that offer confidentiality and integrity of data such as combining the Advanced Encryption Standard (AES) algorithm with a <b>hash</b> <b>digest.</b> The purpose of the scheme {{is to provide a}} straightforward and efficient encryption that supports data integrity, to investigate the use of HMAC for reversible encryption and key transformation, and to improve upon an existing method. ...|$|E
40|$|Authentication is {{a process}} by which the sender and the {{receiver}} identify the legal communicating partners prior to commencement of message transactions. Authentication is a part of security which is ascertained at the time of initiation of the communication between the two communicating entities like client and server. Network communications are found to be vulnerable due to the increase in number of threats from unknown intruders. Session Initiation Protocol (SIP) is used for initializing the session between two communicating devices or entities. This protocol is widely used in multimedia communications. SIP is a powerful signaling protocol which initializes, establishes, maintains, and terminates the session between the communicating devices. Many authentication schemes were proposed for SIP from time to time. Here, we propose a new authentication scheme based on Multifactor <b>Hash</b> <b>Digest</b> Challenge-Response Sequence Count method for SIP. This method enhances the SIP authentication and overcomes vulnerability attacks like Password guessing...|$|E
40|$|Abstract. Data fusion in sensor {{networks}} {{involves the}} processing of data from multiple sources. For distributed settings, the fusion operation has to be executed at individual nodes, which makes data synchronization among nodes a crucial task to ensure consistency. If the sensor nodes are mobile, the communication channel between them can sometimes be broken. When communication is re-established, the snapshots of the nodes {{may no longer be}} consistent. The challenge is further made more difficult given limited communication bandwidth. In this paper, we propose two algorithms for data synchronization in distributed and constrained mobile sensor networks. The first one uses timestamps to locate data records to be transferred between nodes. The second one employs <b>hash</b> <b>digest</b> and index tree to locate the discrepancy set between two sensor nodes. For the hash-based algorithm, we further investigate the cases for complete and rounded data. The evaluation results show that the timestamp-based algorithm is better if complete data are required for fusion, while the hash-based algorithm can outperform the timestamp-based one if the fusion algorithm can tolerate errors within some given threshold. ...|$|E
40|$|Datacenters {{have become}} a {{fundamental}} infrastructure for modern cloud services. The traffic pattern of DataCenter Network (DCN) however has dramatic difference compared to conventional Internet traffic. In particular, momentary bursts have been widely observed which significantly impacts the utilization, packet latency and packet loss of the links. We have also found from real traces that the datacenter traffic has much shorter packet arrival interval and more short-lived bursts. The packet loss and reordering within one router or through multi-path routing of modern DCN further aggravate the problem. In this paper, we propose SaHaD (Sampling, <b>Hash</b> and <b>Digest),</b> a passive fine-grained in-network latency measurement mechanism for DCN. We define a multiple slot structure and leverage hash function to reduce the influence of packet loss and reordering. We present an adaptive packet sampling algorithm for latency measurement. A segmented digest is further developed to derive packet loss and reordering level with minimized overhead. Our trace-driven experiment suggests that SaHaD achieves high efficiency and accuracy for highly bursty and short-lived DCN traffic, and yet with acceptable deployment and maintenance cost...|$|R
50|$|Some hash functions, such as Skein, Keccak, and RadioGatún output an {{arbitrarily}} long {{stream and}} {{can be used as a}} stream cipher, and stream ciphers can also be built from fixed-length <b>digest</b> <b>hash</b> functions. Often this is done by first building a cryptographically secure pseudorandom number generator and then using its stream of random bytes as keystream. SEAL is a stream cipher that uses SHA-1 to generate internal tables, which are then used in a keystream generator more or less unrelated to the hash algorithm. SEAL is not guaranteed to be as strong (or weak) as SHA-1. Similarly, the key expansion of the HC-128 and HC-256 stream ciphers makes heavy use of the SHA256 hash function.|$|R
40|$|This paper {{forms the}} sixth chapter of my thesis, and reports my recent {{research}} result towards the first goal of my proposal: “Efficient and secure digest functions”. This paper {{has also been}} submitted to AFRICACRYPT 2010 in January 2010. This paper introduces two related methods of generating a new cryptographic primitive termed digest which has similarities to ɛ-balanced and almost universal <b>hash</b> functions. <b>Digest</b> functions, however, typically have a very short output, e. g. 16 - 64 bits, and hence they {{are not required to}} resist collision and inversion attacks. They also have the potential to be very fast to compute relative to long-output hash functions. The first construction uses Toeplitz matrix multiplication, which is similar to a Toeplitz based universal hashing algorithm of Krawczyk, whose security requirements can be reduced to the underlying ɛ-biased sequences of random variables. The second is based on integer multiplications which have, perhaps surprisingly, a similar structure to Toeplitz matrix multiplication. However, due to the complication of carry bits, a rigorous mathematical proof of the second construction cannot be provided. We instead exploit the short output of digest functions to carry out statistical analysis, including chi-square tests, quantilequantile plots and maximum median calculation, of digest collision and distribution test results to argue for the security of the second construction. ...|$|R
