13|305|Public
50|$|In photography, <b>filter</b> <b>factor</b> {{refers to}} the multiplicative amount of light a filter blocks.|$|E
50|$|The table below {{illustrates}} {{the relationship between}} <b>filter</b> <b>factor,</b> the amount of light that is allowed through the filter, {{and the number of}} stops this corresponds to.|$|E
30|$|We {{can clearly}} {{see that the}} error of {{estimated}} radius {{is proportional to the}} height of such imperfection if it is not filtered out (the <b>filter</b> <b>factor</b> is too large). However, the form is fitted correctly for lower filter factors (such as 10 σ in this case). Nevertheless, the <b>filter</b> <b>factor</b> cannot be too small because too many points will be excluded from calculations. Thus some compromise must be made and the corresponding <b>filter</b> <b>factor</b> value is different for different aspheric surfaces and for different imperfections. In the case of min-max algorithm (e.g. in [8]) the form error is large if 0 % of points is excluded. However, it can be significantly smaller if some points are excluded (e.g. about 5 %). The parameters obtained from such fitting with a reasonable <b>filter</b> <b>factor</b> can be used to display surface deviations for all points and the standardized form error can be evaluated from these residuals.|$|E
50|$|The table below gives {{approximate}} <b>filter</b> <b>factors</b> for {{a variety}} of common photographic filters. It {{is important to note that}} <b>filter</b> <b>factors</b> are highly dependent on the spectral response curve of the film being used. Thus, <b>filter</b> <b>factors</b> provided by the film manufacturer should be preferred over the ones documented below. Furthermore, note well that these factors are for daylight color temperature (5600K); when shooting under a different color temperature of ambient light, these values will most likely be incorrect.|$|R
5000|$|... #Subtitle level 2: Converting between <b>filter</b> <b>factors</b> {{and stops}} ...|$|R
30|$|Here α is the <b>filtering</b> <b>factor.</b> Further on, the {{monitored}} KPI {{will also}} {{be referred to as}} the LTE or WLAN cell load.|$|R
40|$|Transport of Escherichia coli ATCC 11105 through porous {{media was}} {{investigated}} in this study using two sets of column experiments to quantify the attachment-related parameters (sticking efficiency, attachment rate coefficient and <b>filter</b> <b>factor).</b> The first set of experiments was performed in quartz sand under different ionic strength conditions (1, 20, 100, 200 mM) while the second experiments were carried out in quartz sand mixed with metal oxyhydroxide-coated sand (0, 5, 10, 25 %). The breakthrough curves of bacteria were obtained by monitoring effluent, and then bacterial mass recovery and attachment-related parameters were quantified from these curves. The first experiments showed that the mass recoveries were {{in the range of}} 13. 3 to 64. 7 %, decreasing with increasing ionic strength. In the second experiments, the mass recoveries were in the range of 15. 0 to 43. 4 %, decreasing with increasing coated sand content. The analysis indicated that the sticking efficiency, attachment rate coefficient and <b>filter</b> <b>factor</b> increased with increasing ionic strength and coated sand content. The value of <b>filter</b> <b>factor</b> in the first experiments ranged from 1. 45 e- 2 to 6. 72 e- 2 1 /cm while in the second experiments it ranged from 2. 78 e- 2 to 6. 32 e- 2 1 /cm. Our <b>filter</b> <b>factor</b> values are one order of magnitude lower than those from other studies. This discrepancy {{can be attributed to the}} size of sand used in the experiment. The analysis demonstrated that the travel distance of bacteria estimated using the <b>filter</b> <b>factor</b> can be varied greatly depending on the solution chemistry and charge heterogeneity of porous media...|$|E
40|$|Abstract—A new {{approach}} to analog-to-digital conversion is proposed which combines unstable analog filters with digital Kalman filtering. The proposed approach subsumes sigma-delta converters, on which it offers a new perspective. Index Terms—Analog-to-digital conversion, Kalman <b>filter,</b> <b>factor</b> graphs, Gaussian message passing...|$|E
40|$|Abstract—A hybrid silicon {{photonic}} integrated filter {{is proposed}} and demonstrated {{with a novel}} structure. This filter incorporates a ring resonator in one arm of a Mach–Zehnder interferometer {{making it possible to}} obtain a programmable filter response. The optical filter consists of a 5 -mm-long delay loop made of low-loss silicon waveguides with integrated thermal modulators resulting in a 0. 164 -nm free spectral range with absolute phase tunability and gain elements that allow for the tuning of the <b>filter</b> <b>factor.</b> The microwave response of this integrated filter is measured and display tunability of 20 GHz. Index Terms—Hybrid integrated circuits, microwave filters, op-tical waveguide components, photonic integrated circuits (PICs). I...|$|E
50|$|The normal {{exposure}} will be increased by three stops with this filter. As {{a consequence of}} this relationship, <b>filter</b> <b>factors</b> should be multiplied together when such filters are stacked, as opposed to stop adjustments, which should be added together.|$|R
40|$|Application of the {{exposure}} value system {{requires that the}} system be extended to high brightness level and expanded to include <b>filter</b> <b>factors.</b> A minimum of four photographic factors {{are involved in the}} evaluation of an exposure which, when determined from tables of 1 -stop interval, could introduce noticeable error...|$|R
30|$|The common {{attribute}} {{of the two}} methods {{is the use of}} context as the decision <b>filtering</b> <b>factor</b> but with different context elements in each case. Context Awareness in Recommendation Systems involves the use of data that characterizes an entity to be used as contextual information for the computation of recommendations, wherever this is needed.|$|R
40|$|To {{the case}} k = 3 of the Berman`s {{approximation}} algorithm, the improved {{algorithm is proposed}} in this study. It constructs a Voronoi region to get the cost of triple subtree {{on the basis of}} using Fibonacci heap to count the shortest distance of each pair of points in the corresponding set. Then, to decrease useless triples by the topology analysis of Steinertree, it simplifies the topology and reduces the time complexity. In the experiment results, the <b>filter</b> <b>factor</b> � is above 0. 9 for each example, some even up to 0. 999. It shows that many useless triples have been filtered before the beginning of the evaluation phase and the construction phase...|$|E
40|$|Linear discrimination, {{from the}} point of view of {{numerical}} linear algebra, can be treated as solving an ill-posed system of linear equations. In order to generate a solution that is robust in the presence of noise, these problems require regularization. Here, we examine the ill-posedness involved in the linear discrimination of cancer gene expression data with respect to outcome and tumor subclasses. We show that a <b>filter</b> <b>factor</b> representation, based upon Singular Value Decomposition, yields insight into the numerical ill-posedness of the hyperplane-based separation when applied to gene expression data. We also show that this representation yields useful diagnostic tools for guiding the selection of classifier parameters, thus leading to improved performance. Comment: 22 pages, 3 figures; uses journal's ws-jbcb. cls; submitted to Journal of Bioinformatics and Computational Biolog...|$|E
40|$|Nonstationary {{iterated}} Tikhonov is an iterative regularization {{method that}} requires a strategy for defining the Tikhonov regularization parameter at each iteration and an early termination of the iterative process. A classical choice for the regularization parameters is a decreasing geometric sequence {{which leads to a}} linear convergence rate. The early iterations compute quickly a good approximation of the true solution, but the main drawback of this choice is a rapid growth of the error for later iterations. This implies that a stopping criteria, e. g. the discrepancy principle, could fail in computing a good approximation. In this paper we show by a <b>filter</b> <b>factor</b> analysis that a nondecreasing sequence of regularization parameters can provide a rapid and stable convergence. Hence, a reliable stopping criteria is no longer necessary. A geometric nondecreasing sequence of the Tikhonov regularization parameters into a fixed interval is proposed and numerically validated for deblurring problems...|$|E
40|$|Polarization {{measurements}} {{were carried out}} in orange light for Phobos and Deimos on the Mariner 9 A-camera system at large phase angles. The presence of regoliths on the satellites is indicated by {{a comparison of the}} measurement data with the results of laboratory measurements on powdered rock samples. Four different sets of assumptions concerning the <b>filter</b> <b>factors</b> were taken into account in the data reduction process...|$|R
40|$|This {{research}} {{is presented in}} short presentation format for a research effort based on previous studies on Halal standards. In this study, researcher tried to modify previous study published by Medwell Journals. Researchers applied Multi Criteria Decision Making (MCDM) tool to <b>filter</b> <b>factors</b> of non-compliance of Halal standard among restaurant operations in Kuala Lumpur in cause and effect groups. In this study, researcher failed to prove his hypnotized conceptual model...|$|R
40|$|A {{convolutional}} factor-analysis {{model is}} developed, {{with the number}} of <b>filters</b> (<b>factors)</b> inferred via the beta process (BP) and hierarchical BP, for single-task and multi-task learning, respectively. The computation of the model parameters is implemented within a Bayesian setting, employing Gibbs sampling; we explicitly exploit the convolutional nature of the expansion to accelerate computations. The model is used in a multi-level (“deep”) analysis of general data, with specific results presented for image-processing data sets, e. g., classification. 1...|$|R
40|$|A robust Kalman filter {{improved}} with IGG (Institute of Geodesy and Geophysics) scheme is proposed {{and used to}} resist the harmful effect of gross error from GPS observation in PPP/INS (precise point positioning/inertial navigation system) tightly coupled positioning. A new robust <b>filter</b> <b>factor</b> is constructed as a three-section function to increase the computational efficiency based on the IGG principle. The results of simulation analysis show that the robust Kalman filter with IGG scheme is able to reduce the filter iteration number and increase efficiency. The effectiveness of new robust filter is demonstrated by a real experiment. The results support our conclusion that the improved robust Kalman filter with IGG scheme used in PPP/INS tightly coupled positioning is able to remove the ill effect of gross error in GPS pseudorange observation. It clearly illustrates that the improved robust Kalman filter is very effective, and all simulated gross errors added to GPS pseudorange observation are successfully detected and modified...|$|E
40|$|Abstract—In {{this paper}} we {{describe}} a simplified way to implement performance control in a multi-tier computing system designed for e-commerce applications. We {{show that the}} simpler SISO (Single Input Single Output) controller, rather than a more complex distributed or centralized MIMO (Multiple Input Multiple Output) controller, works well, regardless {{of the presence of}} multiple cluster nodes and multiple execution time deadlines. Our feedback control loop acts on the speed of all server nodes capable of dynamic voltage scaling (DVS), with QoS (Quality of Service) being the reference setpoint. By changing the speed, we change the position of the p-quantile of the tardiness probability distribution, a variable that enables to measure QoS indirectly. Then, the control variable will be the average tardiness, and the setpoint the tardiness value that will position this p-quantile at 1. 0, value at which a request finishes exactly at the deadline. Doing so will guarantee that the QoS will be statistically p. We test this new Tardiness Quantile Metric (TQM) in a SISO PIDF control loop implemented in a multi-tier cluster. We use open software, commodity hardware, and a standardized e-commerce application to generate a workload close to the real world. The main contribution {{of this paper is to}} empirically show the robustness of the SISO controller, presenting a sensibility analysis of the four controller parameters: damping factor zeta, derivative <b>filter</b> <b>factor</b> beta, integral gain ki, and zero time constant tau. I...|$|E
40|$|The photoactivity of carbon-incorporated {{titanium}} dioxide (TiO 2) {{has been widely}} reported. This study involves a novel approach to the incorporation of carbon into TiO 2 {{through the use of}} microwave plasma processing. The process involved thermally treating printed TiO 2 nanoparticle coatings in a microwave-induced argon-oxygen plasma containing low concentrations of methane. The resulting deposited carbon layer was characterized using XRD, XPS, Raman, UV–vis, ellipsometry, and optical profilometry. It was found that the methane gas was dissociated in the microwave plasma into its carbon species, which were then deposited as a nm-thick layer onto the TiO 2 coatings, most likely in the form of graphite. The photovoltaic performances of both the TiO 2 and the carbon-incorporated TiO 2 were assessed through J-V and IPCE measurements of the N 719 -sensitized solar cells using the titania as their photoanodes. Up to a 72 % improvement in the maximum power density (Pd-max) was observed for the carbon-incorporated TiO 2 samples as compared to the TiO 2, onto which no carbon was added. This improvement was found to be mainly associated with an increase in the short-circuit current density (Jsc), but independent from the open-circuit voltage (Voc), the <b>filter</b> <b>factor</b> (FF), and the level of dye adsorption. Possible contributory factors to the improved performance of the carbon-incorporated TiO 2 were the enhanced electron conductivity and electron lifetime, both of which were elucidated through electrochemical impedance spectroscopy (EIS). When the surface layer was examined using XPS, the optimal carbon content on the TiO 2 coating surface was found to be 8. 4 %, beyond which there was a reduction in the DSSC efficiency...|$|E
40|$|Specular {{reflections}} from environments cause uncertainties to {{ultrasonic sensor}} range data. In this paper, {{we examine the}} application of evidential method for data integration using the specially designed sensor model to overcome the problem. Dempster’s rule of combination is used to fuse the sensor data to obtain the map defined on a 2 D evidence grid. The sensor model tries to reduce the uncertainties caused by specular reflections with a <b>filtering</b> <b>factor.</b> Experimental results have shown the usefulness of this method...|$|R
40|$|A {{computer}} {{program for the}} design and analysis of linear phase FIR raised cosine filters is described. It allows the design of traditional and equiripple FIR <b>filters</b> with roll-off <b>factors</b> between 0 and 1. In addition the program is capable of computing coefficients for the recently introduced raised cosine <b>filters</b> with <b>factor</b> > 1. The design algorithms are solved using linear programming. A number of filter examples are included...|$|R
30|$|Consequently, these <b>factors</b> <b>filter</b> out {{solution}} components {{pertaining to}} small singular values.|$|R
40|$|PID {{control has}} been the most widely spread form of {{feedback}} in industry for at least five or six decades. It has very old roots, but prior to the 1930 s the development was driven by instrument companies, plant designers and plant operators. Today the interest among academics is large and increasing. When new controller types and new tuning rules are presented, they have to show their superiority over already accepted types and rules in one respect or another. A correct comparison requires an evaluation method that can guarantee that an improvement of one property has not been paid by a too bad deterioration of another. Such a method is presented in this thesis. It is based on four well defined criteria, related to vital performance and robustness system characteristics. According to the proposed evaluation method optimal PI and PID controllers have been investigated for a large number of plant models. Common features have been observed, resulting in almost optimal tuning rules for stable plants, including those with an oscillating mode, and for plants with integral action. Derivative action in the controller is recommended, since in most cases a PID controller increases the output performance significantly compared to a PI controller. This improvement is reached, with moderate enlargement of the control activity and the sensor noise sensitivity and without deterioration of the stability margin, only by including the low-pass filter on the derivative part in the design. An alternative to the traditional parameterization of the PID controller is introduced, which makes the same parameters well suited for formulation of all kinds of low order controllers. Furthermore, almost optimal zeros for the PID controller (specified by two of the new parameters) can well be found by help of a simple step response. The two remaining PID parameters, the high-frequency gain (or alternatively the <b>filter</b> <b>factor)</b> related to control activity and the integral gain related to performance, can then be manipulated sequentially by the user to tune the important trade-off between output performance, stability margins and sensitivity to sensor noise as well as high-frequency robustness. To further improve the high-frequency properties it is also shown how additional low-pass filtering can easily be added to the classical PID controller...|$|E
40|$|Abstract—A 2 -D {{electrical}} filter is introduced that {{is compatible with}} today’s conventional integrated circuit processes. The rich 2 -D propagation properties of the medium are used to introduce a novel high quality <b>factor</b> <b>filter</b> called an electrical prism. The pro-posed filter shows a quality factor {{much larger than the}} quality factor of the individual components at high millimeter-wave and terahertz frequencies. This structure also provides a negative ef-fective index in a low-pass lattice. Based on this idea, we show <b>filters</b> with quality <b>factors</b> of 130 at 230 GHz and 420 at 460 GHz consisting of elements with the quality factor of 10 and 20, respec-tively. The effect of component loss on the <b>filter</b> quality <b>factor</b> is discussed in this paper. The negative effective index and the filter behavior of the lattice is verified by measuring a prototype on a CMOS process at 32 – 40 GHz. There is good agreement among the theory, simulation, and experimental results. Index Terms—CMOS, dispersion, electrical prism, high quality <b>factor</b> <b>filter,</b> negative effective index, spatial filtering, terahertz, 2 -D electrical lattice. I...|$|R
5000|$|This is {{also the}} {{bandwidth}} of the <b>filter.</b> The damping <b>factor</b> is given by ...|$|R
40|$|We {{introduce}} a new filtering method for approximate string matching called the suffix filter. It has some similarity with well-known filtration algorithms, which we call <b>factor</b> <b>filters,</b> and which {{are among the best}} practical algorithms for approximate string matching using a text index. Suffix filters are stronger, i. e., produce fewer false matches than <b>factor</b> <b>filters.</b> We demonstrate experimentally that suffix filters are faster in practice, too. ...|$|R
30|$|We {{adopt the}} notion of distance-based {{outliers}} proposed by Knorr and Ng [27] for data-mining applications: “An object in a dataset is an outlier if at least {{a fraction of the}} objects in this dataset lies in a larger distance from this object.” Our approach {{is based on the assumption}} that points belonging to building wall structures have normal distribution. Thus, we apply a double-threshold scheme: firstly, we reduce the impact of infrequent points in the model, the relative distances from which to the other points in the model are comparatively large. After eliminating such points, we estimate the second <b>filtering</b> <b>factor</b> based on the global mean over mean distances of each point’s neighborhood.|$|R
30|$|Other {{researchers}} implemented adaptive FIR {{digital filter}} using least mean square (LMS) evaluation criterion {{to realize the}} filter performances to eliminate random noise frequencies and reconstruct mud pulse signals. This technique was adopted to reduce mud pump noise and improve surface received telemetry signal detection and reliability. However, the quality of reconstructed signal depends on the signal distortion factor, which relates to the <b>filter</b> step-size <b>factor.</b> Reasonably, chosen <b>filter</b> step-size <b>factor</b> reduces the signal distortion quality. Li and Reckmann (2009) research used the reference signal fundamental frequencies and simulated mud pump harmonic frequencies passed through the LMS filter design to adaptively track pump noises. This method reduced the pump noise signals by subtracting the pump noise approximation from the received telemetry signal. Shen et al. (2013 a) studied the impacts of filter step-size on signal-to-noise ratio (SNR) distortions. The study used the LMS control algorithm to adjust the adaptive filter weight coefficients on mud pulse signal modulated by differential phase shift keying (DPSK). In this technique, the same <b>filter</b> step-size <b>factor</b> numerical calculations showed that the distortion factor of reconstructed mud pressure QPSK signal is smaller {{than that of the}} mud pressure DPSK signal.|$|R
50|$|Frequently used {{methods for}} {{description}} <b>filtering</b> include <b>factor</b> analysis (e.g. by PCA), singular value decomposition (e.g. as latent semantic indexing in text retrieval) and the extraction {{and testing of}} statistical moments. Advanced concepts such as the Kalman filter are used for merging of descriptions.|$|R
40|$|Stochastic {{filtering}} {{concerns the}} estimation {{of the state of}} a randomly evolving system that is only indirectly observed and the observations are, furthermore, affected by noise. The primary examples in finance concern factor models, where some factors are not directly observable. We review stochastic filtering in discrete and continuous time in linear and nonlinear models and describe some applications to pricing and portfolio management. Key words: Incomplete information, stochastic filtering, Bayesian estimation, analytic filter solutions, particle <b>filters,</b> <b>factor</b> models, pricing, portfolio management. The filtering problem Consider a randomly evolving system, the state of which is denoted by xt and this state may not be directly observable. Denote by yt the observation at time t ∈ [0, T] (xt and yt may be vectorvalued) ...|$|R
40|$|In {{research}} with carbon arc-jets, a need arose to transpose the experimentally determined correct exposure settings for {{one set of}} conditions to others with the same exceedingly high light levels of the jet. It appeared that the transpositions could be accomplished more rapidly and accurately if the EV system could be expanded both in extent and detail. How this was accomplished is explained. The exposure value system or additive value system has been expanded to include <b>filter</b> <b>factors</b> and transmittance. In addition, the equations for photoflash and electronic flash photography are converted into a form compatible with the EV system. The photographic factors are presented in tabular form together with their corresponding values in the additive value system in 25 % steps or quarter stops to permit an ac-ceptable solution to be obtained more readily...|$|R
3000|$|... [*]kHz {{due to the}} use of a pulse shaping <b>filter</b> with {{roll-off}} <b>factor</b> 0.4. In HB transmission, {{the carrier}} frequency was [...]...|$|R
40|$|Maintenance {{has had a}} {{tremendous}} impact on company’s proficiency to optimize its production system in order to meet its long term objectives. Generally, a production system in which maintenance is not given attention may easily lead to the system producing defective product as a result of machine defect. The purpose of this thesis is to utilized tools and methods to analyze the impact of maintenance implementation in a production system. The analytical Hierarchy process was utilized to <b>filter</b> the defining <b>factors</b> and sub-factors considered {{to be related to the}} life length and performance of production equipment in the research which was carried out at SCA Packaging Sweden AB. Various cost associated with these factors were analyzed using the cost breakdown structure, an element of life cycle cost analysis. Finally, economic evaluation of the <b>filtered</b> <b>factors</b> was performed to show the benefits associated with implementing maintenance. The result shows that while investment on maintenance implementation might be a cost at the earlier stage of implementation because it is hard to measure and follow up its impact on company’s business. Nevertheless, its role in improving company productivity profitability is indispensable. Thus, maintenance is a profit centre rather than a cost centre...|$|R
40|$|A typical way {{to compute}} a {{meaningful}} solution of a linear {{least squares problem}} involves {{the introduction of a}} <b>filter</b> <b>factors</b> array, whose aim is to avoid noise amplification due to the presence of small singular values. Beyond the classical direct regularization approaches, iterative gradient methods can be thought as filtering methods, due to their typical capability to recover the desired components of the true solution at the first iterations. For an iterative method, regularization is achieved by stopping the procedure before the noise introduces artifacts, making the iteration number playing the role of the regularization parameter. In this paper we want to investigate the filtering and regularizing effects of some first-order algorithms, showing in particular which benefits can be gained in recovering the filters of the true solution by means of a suitable scaling matrix...|$|R
