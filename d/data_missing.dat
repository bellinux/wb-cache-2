359|10000|Public
5000|$|... 2013: Hans van Houwelingen ring design Truike Verdegaal {{sculpture}} (<b>data</b> <b>missing)</b> ...|$|E
5000|$|There are <b>data</b> <b>missing</b> {{for this}} tournament, updates will {{follow in the}} due course.|$|E
5000|$|There are <b>data</b> <b>missing</b> {{for this}} tournament {{which will be}} added in the due course.|$|E
40|$|Introduction. <b>Missing</b> <b>data</b> is {{a common}} problem in {{research}} and can produce severely misleading analyses, including biased estimates of statistical parameters, and erroneous conclusions. In its 1999 report, the APA Task Force on Statistical Inference encouraged authors to report complications such as <b>missing</b> <b>data</b> and discouraged the use of traditional <b>missing</b> <b>data</b> methods, such as listwise and pairwise deletion. While many advances in the statistical treatment of <b>missing</b> <b>data</b> have been made, {{it remains to be}} seen whether these procedures are applied in practice. In their study examining <b>missing</b> <b>data</b> reporting practices of studies published in 1999 and 2003, Peugh and Enders found that <b>missing</b> <b>data</b> was rarely acknowledged and, when it was addressed, out-of-date statistical methods were used in response. ^ Purpose. The purpose of this dissertation is to (a) provide an overview of the causes, assumptions, misconceptions, and statistical remedies regarding <b>missing</b> <b>data</b> in applied research; (b) replicate partially, extend, and expand the Peugh and Enders findings; (c) identify the ways in which <b>missing</b> <b>data</b> are addressed; and (d) assess current reporting practices. ^ Sample. Data from 1, 106 studies were collected from the 24 educational and applied psychological journals published in 2007. ^ Methods. Data were collected on a number of points including the amount of <b>missing</b> <b>data,</b> the <b>missing</b> <b>data</b> method used, the study design, the cause of <b>missing</b> <b>data,</b> the type of <b>missing</b> <b>data,</b> the underlying nature of the <b>missing</b> <b>data,</b> the <b>missing</b> <b>data</b> mechanism, and whether or not a power analysis was performed. ^ Findings. Compared to the Peugh and Enders findings, the current sample of studies published in 2007 showed improvements in the assessment and treatment of <b>missing</b> <b>data.</b> More studies explicitly acknowledged <b>missing</b> <b>data,</b> modern <b>missing</b> <b>data</b> methods were employed more often, more studies discussed <b>missing</b> <b>data</b> in detail, and the underlying nature of the <b>missing</b> <b>data</b> was examined more often. However, the way in which many studies reported the amount, type, and cause of <b>missing</b> <b>data</b> was often inaccurate and/or unclear. This dissertation gives a statistical and narrative description of results and provides recommendations for improvement. ...|$|R
5000|$|In statistics, ignorability is {{a feature}} of an {{experiment}} design whereby the {{method of data collection}} (and the nature of <b>missing</b> <b>data)</b> do not depend on the <b>missing</b> <b>data.</b> A <b>missing</b> <b>data</b> mechanism such as a treatment assignment or survey sampling strategy is [...] "ignorable" [...] if the <b>missing</b> <b>data</b> matrix, which indicates which variables are observed or missing, is independent of the <b>missing</b> <b>data</b> conditional on the observed data.|$|R
5000|$|Accommodates <b>missing</b> <b>data</b> (i.e. <b>missing</b> feature {{values in}} {{training}} instances) ...|$|R
5000|$|... ? = Sources incongruent or explicit/implicit {{numerical}} <b>data</b> <b>missing</b> or {{inclusion of}} nuclear isomers in figures unclear.|$|E
5000|$|<b>Data</b> <b>missing</b> from few of Cup seasons, {{thus the}} correct total figures in bold differ {{from some of}} added sums on the table above.|$|E
50|$|Lossy data correction, or prediction, is used {{to recover}} <b>data</b> <b>missing</b> from some {{dimensions}}. It is done by finding the nearest group with the data dimensions available, then predicting the result based on the values for the missing dimensions, assuming {{that they will have}} the same value as the group's centroid.|$|E
40|$|This paper {{outlines}} an algorithm {{to improve}} the robustness of <b>missing</b> <b>data</b> treatment to pathological motion (PM). PM can cause misdiagnosis of clean image <b>data</b> as <b>missing</b> <b>data.</b> The proposed algorithm uses a probabilistic framework to jointly detect PM and <b>missing</b> <b>data</b> by exploiting more temporal information than is typically used for <b>missing</b> <b>data</b> detection and by exploiting the local smoothness assumption of motion fields. The results of the framework are compared to an equivalent <b>missing</b> <b>data</b> detector without PM detection and the framework is shown to prevent the misdiagnosis of <b>missing</b> <b>data</b> due to P...|$|R
3000|$|... {{represent}} <b>missing</b> <b>data.</b> Finally, let ϕ be the scalar or vector‐valued parameter {{describing the}} process that generates the <b>missing</b> <b>data.</b> The underlying mechanism that generates <b>missing</b> <b>data</b> can be considered either ignorable or non‐ignorable. An ignorable <b>missing</b> <b>data</b> mechanism {{is one in which}} inferences are not affected by {{the process that}} generated the <b>missing</b> <b>data.</b>|$|R
40|$|This {{paper is}} {{concerned}} with the inference of incomplete <b>data</b> when the <b>missing</b> <b>data</b> process is non-ignorable in the sense of Rubin (Biometrica 38 (1982) 963 - 974). With the random effects model and the proposed <b>missing</b> <b>data</b> process, the conditions missing at random (MAR) and distinct parameters (DP) are discussed. The impact of the <b>missing</b> <b>data</b> is illustrated by the asymptotic bias of the sample mean based on only the observed data and ignoring the <b>missing</b> <b>data</b> process. Maximum likelihood and moment estimators of the marginal mean are obtained. Missing values random effects model non-ignorable <b>missing</b> <b>data</b> process <b>missing</b> at random distinct parameters EM algorithm ECM algorithm...|$|R
50|$|Election watchdogs were {{generally}} {{satisfied with the}} conduct of the election. In a statement, the Legal Network for Truthful Elections (LENTE) said that The canvassing went very well. It took ten hours. Delay was due to a lot of petitions for exclusion by the lawyers of the two main candidates in the recall. Petitions were primarily based on missing inner paper seal, missing statistical <b>data,</b> <b>missing</b> thumbmarks and allegations of fraud, tampering of the ERs (election returns).|$|E
50|$|In 1999 Whigham and Potthast {{returned}} to the fray. Their new paper contained two strands. First, they argued that John Hoyt Williams’ population estimate based on the 1846 census needed to be raised; {{he was working with}} incomplete <b>data</b> (<b>missing</b> parishes, and undercounting of some ethnic groups and children). Furthermore, 1846 was only two years after a smallpox epidemic which must have reduced the population anyway. Accordingly: we feel safe in arguing that Paraguay had a population somewhere between 420,000 and 450,000 {{at the beginning of the}} war.|$|E
50|$|Prior to his auditor's position, Kyle, both a PhD and a C.P.A., taught {{governmental}} accounting and auditing from 1968-1989 at Louisiana State University in Baton Rouge. In 2000, Kyle uncovered {{serious problems with}} an audit of historically black Grambling State University in Grambling in Lincoln Parish. A 1998 audit of the same institution uncovered no problems, but two years later, the auditor received inaccurate and incomplete information from the university administration. Grambling had four months of <b>data</b> <b>missing,</b> which rendered it impossible to conduct the required two-year audit.|$|E
40|$|The $k$-means {{algorithm}} {{is often used}} in clustering applications but its usage requires a complete <b>data</b> matrix. <b>Missing</b> <b>data,</b> however, is common in many applications. Mainstream approaches to clustering <b>missing</b> <b>data</b> reduce the <b>missing</b> <b>data</b> problem to a complete data formulation through either deletion or imputation but these solutions may incur significant costs. Our $k$-POD method presents a simple extension of $k$-means clustering for <b>missing</b> <b>data</b> that works even when the missingness mechanism is unknown, when external information is unavailable, and when there is significant missingness in the data. Comment: 26 pages, 7 table...|$|R
5000|$|... 3. MLM can Handle <b>Missing</b> Data: <b>Missing</b> <b>data</b> is {{permitted}} in MLM without causing additional complications. With RM-ANOVA, subject’s data must be excluded {{if they are}} <b>missing</b> a single <b>data</b> point. <b>Missing</b> <b>data</b> and attempts to resolve <b>missing</b> <b>data</b> (i.e. using the subject’s mean for non-missing data) can raise additional problems in RM-ANOVA.|$|R
30|$|Comparisons of CBT and PPT {{administered}} assessments {{may also}} be impacted by <b>missing</b> <b>data.</b> Our use of Hierarchical Multiple Imputations (HMI) mitigates the impacts of <b>missing</b> <b>data,</b> but studies that use listwise deletion to address <b>missing</b> <b>data</b> may have different results. The skewing of participation rates by student course grade demonstrates that the <b>data</b> are not <b>missing</b> completely at random and that <b>missing</b> <b>data</b> are therefore non-ignorable.|$|R
5000|$|Synthetic Aperture Personality Assessment (SAPA) is {{a method}} used for telemetric {{assessment}} of individual differences, primarily {{in the context of}} online surveys. The SAPA method uses data collected from the administration of large inventories of personality assessment items to large pools of participants, though it differs from traditional data collection methods in that each participant responds to only a small subset of all available items. In other words, each participant receives a random (or partially random) subset of the items under study. As long as some of the items are overlapping between pairs of participants, the smaller subset is more palatable for individual participants yet can be combined to synthesize large covariance matrices (with considerable <b>data</b> <b>missing</b> at random). In this way, the SAPA methodology is well-suited for assessing personality and individual differences across multiple domains. [...] It is also a highly efficient means for new item prototyping and scale construction.|$|E
50|$|After demodulating, a CIRC error {{corrector}} takes each {{audio data}} frame, stores it in a SRAM memory and verifies {{that it has}} been read correctly, if it is not, it takes the parity and correction bits and fixes the data, then it moves it out to a DAC to be converted to an analog audio signal. If the <b>data</b> <b>missing</b> is enough to make recovery impossible, the correction is made by interpolating the data from subsequent frames so the missing part is not noticed. Each player has a different interpolation ability so if enough data frames are missing or unrecoverable, it may be impossible to fix by interpolation so an audio mute flag is raised to mute the DAC to avoid invalid data to be played back.The Redbook standard dictates that, if there is invalid, erroneous or missing audio data, it cannot be output to the speakers as digital noise, it has to be muted.|$|E
50|$|Predicting {{weather change}} {{requires}} accurate data that is collected over many years, {{and the application}} of models. GEWEX was conceived to respond to the need for observations of the Earth's radiation budget and clouds. Many preexisting techniques were limited to observations taken from land and populated areas. This ignored the large amount of weather that occurs over the oceans and unpopulated regions, with key <b>data</b> <b>missing</b> from these areas. Since satellites orbiting the earth cover large areas in small time frames, they can better estimate climate where measurements are infrequently taken. GEWEX was initiated by World Climate Research Programme (WCRP) to take advantage of environmental satellites such as TRMM, but now uses information from newer satellites as well as collections land based instruments, such as BSRN. These land based instruments can be used to verify information interpreted from satellite. GEWEX studies the long-term and regional changes in climate with a goal of predicting important seasonal weather patterns and climate changes that occurs over a few years.|$|E
50|$|A cache miss is {{a failed}} attempt to read or write a piece of data in the cache, which results in a main memory access with much longer latency. There are three kinds of cache misses: {{instruction}} read <b>miss,</b> <b>data</b> read <b>miss,</b> and <b>data</b> write <b>miss.</b>|$|R
30|$|All the {{aforementioned}} methods for air quality <b>missing</b> <b>data</b> imputation {{have been well}} documented. However, all these methods are not sufficiently accurate when longer segments of <b>data</b> are <b>missing</b> or {{in the event that}} the relationship between the data segments is not linear. Spectral methods consider the entire signal in their evaluation of <b>missing</b> <b>data,</b> which in return present better results when large chucks of <b>data</b> are <b>missing.</b>|$|R
40|$|Analysis of Covariance (ANCOVA) {{is mostly}} {{used in the}} {{analysis}} of research or experimental design. ANCOVA is the combination between regression analysis and Analysis of Variance (ANOVA). ANCOVA were used because there are some concomitant variable, which is variable that difficult to control by the researchers but an impact on observed the response variable. The purpose from concomitant variable is reduces variability in the experiment. If there is <b>missing</b> <b>data</b> on Randomized Complete Block Design (RCBD) the first must be done estimating the <b>missing</b> <b>data</b> before ANCOVA done. ANCOVA on RCBD with complete <b>data</b> or <b>missing</b> <b>data</b> isn 2 ̆ 7 t much different, if there are <b>missing</b> <b>data,</b> the degrees of freedom is reduced by the total amount of <b>missing</b> <b>data</b> and the sum of square treatment reduced by the value of the bias. Application of tensile strength of the glue experiment to the case ANCOVA on RCBD with one <b>missing</b> <b>data</b> show no effect of treatment and group by the tensile strength of the glue. For Fe toxicity experiment with two <b>missing</b> <b>data</b> are found only treatment effect to Fe texicity. Based on value from the coefficient of variance for one <b>missing</b> <b>data</b> and two <b>missing</b> <b>data</b> showed that ANCOVA is more appropriately used than ANOVA...|$|R
30|$|However, during data collection, data {{errors and}} <b>data</b> <b>missing</b> would occur {{occasionally}} because the wireless transmission network {{is affected by}} the external environment during data transmission. Therefore, the original data need to be processed before being used in experiments. Deletion and interpolation processing are adopted to deal with data errors and <b>data</b> <b>missing,</b> respectively.|$|E
30|$|Lithium, carbamazepine, valproate, {{lamotrigine}} or an antipsychotic as maintenance medication {{was used}} by 804 (96.1 %) respondents. Of the remaining 32 (3.9 %) who currently did not use any pharmacotherapy, 15 had BD I, 13 BD II, three BD NOS, and one SZA; all reported at least two previous mood episodes (<b>data</b> <b>missing</b> in one), and eight had been admitted at least once (<b>data</b> <b>missing</b> in two).|$|E
3000|$|Based on this model, we {{considered}} {{the following three}} <b>data</b> <b>missing</b> mechanisms of the response, respectively: [...]...|$|E
40|$|Methods {{proposed}} {{to solve the}} <b>missing</b> <b>data</b> problem in estimation procedures should consider the type of <b>missing</b> <b>data,</b> the <b>missing</b> <b>data</b> mechanism, the sampling design {{and the availability of}} auxiliary variables correlated with the process of interest. This article explores the use of geostatistical models with multiple imputation to deal with <b>missing</b> <b>data</b> in environmental surveys. The method is applied to the analysis of data generated from a probability survey to estimate Coho salmon abundance in streams located in western Oregon watersheds...|$|R
40|$|This session, {{consisting}} of two 80 minute presentations, will discuss {{the issues raised by}} <b>missing</b> <b>data</b> and how these can be addressed using multiple imputation. The aim is that at the end participants will have the confidence necessary to apply multiple imputation in their own work. Although we will touch on randomised clinical trials (where <b>missing</b> <b>data</b> occur mostly in the response), our main focus will be on observational <b>data</b> (where <b>missing</b> <b>data</b> occur in both response and covariates). Specifically, we will cover the following topics: 1 Issues raised by <b>missing</b> <b>data</b> We will begin by discussing the impact of non-trivial fractions of <b>missing</b> <b>data,</b> and specifically the additional ambiguity they cause in an analysis (Carpenter and Kenward, 2008, ch. 1). This arises because the reasons for the <b>missing</b> <b>data</b> cannot in general be known. Any analysis, and resulting inference, therefore rests on an ultimately untestable assumptions about these reasons. Therefore, sensitivity analysis, where we explore the robustness of our conclusions to different, yet plausible, assumptions about the reasons for <b>missing</b> <b>data,</b> is important. We will illustrate the above by discussing the implications for analyses restricted to records with no <b>missing</b> <b>data</b> (so called complete cases), and highlight the importance of careful exploratory analyses. Then, we will review the practical implications of three key classes of assumptions about the <b>missing</b> <b>data</b> mechanism: <b>Missing</b> Completely At Random (MCAR), Missing At Random (MAR...|$|R
50|$|In statistics, <b>missing</b> <b>data,</b> or <b>missing</b> values, {{occur when}} no data value is stored for the {{variable}} in an observation. <b>Missing</b> <b>data</b> {{are a common}} occurrence and can {{have a significant effect}} on the conclusions that can be drawn from the data.|$|R
3000|$|One {{important}} {{advantage of}} the GEE approach is a substantial reduction {{in the amount of}} missing <b>data.</b> <b>Missing</b> values for which Y [...]...|$|E
30|$|The {{socioeconomic}} {{statistics in}} WIOD lack several data for some economies, {{for the years}} 2010 and 2011, so we use the 2009 coefficients whenever there was <b>data</b> <b>missing.</b>|$|E
40|$|This article {{describes}} {{the results of a}} simulation study to investigate the impact of missing data on the detection of differential item functioning (DIF). Specifically, it investigates how four methods for dealing with missing data (listwise deletion, zero imputation, two-way imputation, response function imputation) interact with two methods of DIF detection (Mantel-Haenszel statistic, logistic regression analysis) under three mechanisms of missingness (<b>data</b> <b>missing</b> completely at random, <b>data</b> <b>missing</b> at random, and <b>data</b> <b>missing</b> not at random) to produce over- or underesti-mates of the DIF effect sizes and detection rates. Results show that the interaction effects between missingness mechanism, treatment, and rate are most influential for explaining variation in bias, root mean square errors, and rejection rates. An incorrect treatment of missing data can thus lead to severe increases of Type I and Type II error rates. However, the choice between the two DIF detection methods investigated in this study is not important...|$|E
40|$|Abstract. The Naive Bayesian {{classifier}} is {{the least}} sensitive to <b>missing</b> <b>data</b> in the methods of <b>data</b> mining. However, <b>missing</b> <b>data</b> still affects {{the accuracy of the}} classifiers before the dataset which contains <b>missing</b> <b>data</b> used to train in the classifier. We can fill up the <b>missing</b> <b>data</b> to gain a full dataset. This paper introduces a random patch algorithm based on Markov Transition probability. This algorithm can fill up the dataset which contains <b>missing</b> <b>data</b> to a full one. Using the full dataset to classification can increase the accuracy of the classifier. We perform experiments to prove the algorithm effectiveness...|$|R
40|$|Purpose - Data {{preparation}} {{plays an}} important role in data mining as most real life <b>data</b> sets contained <b>missing</b> <b>data.</b> This paper aims to investigate different treatment methods for <b>missing</b> <b>data.</b> Design/methodology/approach - This paper introduces, analyses and compares well-established treatment methods for <b>missing</b> <b>data</b> and proposes new methods based on naÃ¯ve Bayesian classifier. These methods have been implemented and compared using a real life geriatric hospital dataset. Findings - In the case where a large proportion of the <b>data</b> is <b>missing</b> and many attributes have <b>missing</b> <b>data,</b> treatment methods based on naive Bayesian classifier perform very well. Originality/value - This paper proposes an effective <b>missing</b> <b>data</b> treatment method and offers a viable approach to predict inpatient length of stay from a data set with many missing values. ...|$|R
50|$|According to All American League <b>data,</b> <b>Miss</b> Gregory {{played in}} the league in its 1946 season. Nevertheless, {{additional}} information is incomplete because there are no records available {{at the time of the}} request.|$|R
