27|10000|Public
5|$|At Imageworks, as per Leon, he {{was asked}} to develop an {{improved}} digital film review software as an alternative to a then existing software. Leon released the initial version within two months of having been assigned the job; after receiving positive feedback from the artists using the software, Leon kept updating various <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> over the years. This digital 3D film review software, itView, led Leon to get an Academy Award in 2016. Leon mentions working alone on the project for many years, and that he was over time given a team when the project achieved significant growth. In a 2016 media interview, Leon says that he worked on the itView technology for eight years as the chief contributor.|$|E
5000|$|They {{specify the}} {{requirements}} and <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> of Catalan Name and Title Authority List.|$|E
50|$|At Imageworks, as per Leon, he {{was asked}} to develop an {{improved}} digital film review software as an alternative to a then existing software. Leon released the initial version within two months of having been assigned the job; after receiving positive feedback from the artists using the software, Leon kept updating various <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> over the years. This digital 3D film review software, itView, led Leon to get an Academy Award in 2016. Leon mentions working alone on the project for many years, and that he was over time given a team when the project achieved significant growth. In a 2016 media interview, Leon says that he worked on the itView technology for eight years as the chief contributor.|$|E
50|$|<b>The</b> main <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> is <b>the</b> {{automatic}} creation <b>of</b> music notation {{directly from}} music performance or recordings.|$|R
50|$|PSpice Lite version, {{which can}} be used by {{students}} comes with full <b>functionality</b> <b>of</b> <b>the</b> <b>software,</b> limited only by size and complexity.|$|R
50|$|Act! has {{hundreds}} of active certified consultants globally.A number of third-party companies develop add-on products using Act!'s {{software development kit}} that expands <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software.</b>|$|R
40|$|International audienceThe {{reduction}} of embedded electronic systems susceptibility to electromagnetic fields is often obtained by hardware devices whose cost must {{be added to}} each product. On the contrary, we consider the use of conventional hardware systems (COTS) handling their misfunctioning by software techniques. This paper introduces software detection mechanisms whose development cost is low as the mechanisms are generic, that is, independent on the specific <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> applications processed by the electronic systems...|$|E
40|$|This paper 1 {{describes}} {{the progress of}} our work presented at m-ICTE 2006 (Boguslavsky et al., 2006; Diachenko, 2006). The general purpose {{of the work is}} to develop a software system which promotes the mastery of the combinatorial potential of natural language words by language learners. It lists some basic concepts of Lexical function theory and {{describes the}} architecture and <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> system developed. We describe the idea and the results of training experiment...|$|E
40|$|Actor of its {{presentation}} and actor of its online representation, the diarist draws his diegetic existence {{by setting up}} a strategy of automediation. The Self-representation is a personal creation determined by the interface and the <b>functionalities</b> <b>of</b> <b>the</b> <b>software.</b> A pragmatic approach of the Self-representation in the Livejournal Blog and the Touchgraph Livejournal browser provides a way to observe the play between intimacy and intersubjectivity. The software leads the user from the lonely space of writing to the community space of publication. Comment: in French, [URL]...|$|E
5000|$|An initial {{specification}} <b>of</b> <b>the</b> intended <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> is developed. <b>The</b> specification should unambiguously define: functions, data formats (which include comparison vectors, c-vectors, {{and comparison}} status indicators, cs-indicators), cross-check points (cc-points), comparison algorithm, {{and responses to}} the comparison algorithm.|$|R
50|$|On November 24, 2010, Research In Motion (RIM) removed Kik Messenger from BlackBerry App World {{and limited}} <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> for its users. RIM also sued Kik Interactive for patent {{infringement}} and misuse of trademarks. In October 2013, the companies settled the lawsuit, with the terms undisclosed.|$|R
40|$|In this paper, a {{software}} application that features <b>the</b> visualization <b>of</b> commonly used data structures and their associated insertion and deletion operations is introduced. In addition, this software {{can be used}} to animate user-defined algorithms. Examples illustrating <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> as a supplemental teaching tool are discussed. [URL]...|$|R
40|$|A recent paper [1] {{proposed}} a new technique, termed the channel reactivity-based method (CRB), for characterizing EEG alpha rhythms using individual (IAFs) and channel (CAFs) alpha frequencies. These frequencies {{were obtained by}} identifying the frequencies at which {{the power of the}} alpha rhythms decreases. In the present study, we present a graphical interactive toolbox that can be plugged into the popular open source environment EEGLAB, making it easy to use CRB. In particular, we illustrate the major <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> and discuss the advantages of this toolbox for common EEG investigations. The CRB analysis plugin, along with extended documentation and the sample dataset utilized in this study, is freely available on the web at [URL]...|$|E
40|$|Abstract. Recently, {{the open}} source process has sparked {{interest}} of {{researchers in the}} universities and in the software industry. So, our ob-jective is to investigate if the open source process works effectively when developers do not have good knowledge about the <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> that will be developed. Thus, two studies have been performed; one to compare the “traditional ” process and the open source process aiming to observe if analysis and design models {{are relevant to the}} soft-ware development; and other, to observe if a requirements specification gives benefits to the open source processes when developing a software with unknown or unclear functionalities. Both studies were formulated and documented according to experimentation process; and, the lessons learned can be considered as the first step to adjusting, establishing and transferring the best practices of the OS process to the software industry. ...|$|E
40|$|Abstract. This paper {{describes}} the steps taken to transform a semi-structured collection of documents containing bibliographic references of {{researchers from the}} Serbian province of Vojvodina into an information retrieval service which permits explicit visualization of publication coauthorhips. The process of information extraction consisting of reference recognition and coauthorship detection is presented first, together with an experimental evaluation on a representative subset of the data which demonstrates good values of precision and recall of extraction. Then, an overview of a program is given, which provides services for search and visualization of bibliographic data collected from the semi-structured source. Examples of program usage demonstrate how collaboration of researchers and organizations may be analyzed using the visualization <b>functionalities</b> <b>of</b> <b>the</b> <b>software.</b> Besides (co) authorships, the data collection contains other interesting information which may be utilized for social network analysis of Vojvodinian researchers and organizations in future work. ...|$|E
25|$|Several MediaWiki {{extensions}} {{are installed}} to extend <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> MediaWiki <b>software.</b>|$|R
40|$|Research resume Numerical {{analysis}} and scientific computing. I {{have developed a}} novel spectral method for linear ordinary and partial differential equations, fast Gauss quadrature routines, a new continuous linear algebra for functions, a high degree bivariate polynomial rootfinder, and a fast Chebyshev–Legendre transform. I also developed <b>the</b> two-dimensional <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> package Chebfun...|$|R
30|$|<b>The</b> basic <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> {{has been}} fully tested on an ideal {{synthetic}} vector data set, where {{the noise and}} external fields were ignored and an ideal distribution <b>of</b> data on <b>the</b> sphere was assumed. <b>The</b> performances <b>of</b> <b>the</b> algorithm were extensively tested on the data sets defined below. Results are given in the next section.|$|R
40|$|In {{neuroscience}} research, fMRI {{image analysis}} {{is a major}} approach to identify the relationships between brain region and behavior. fMRI provides delayed real time brain activity signals non-invasively. Spatial preprocessing and statistical analysis needs to be performed to find the brain region that is responsive to certain tasks or stimulations. This project introduce an implementation of a tailored fMRI image processing pipeline, FIONA (Functional Imaging Overlay for NAvigated TMS), based on Insight Toolkit (ITK). The major <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> include preprocessing (realignment, co- registration, spatial smoothing), GLM analysis, hypothesis testing and multiple comparison correction (mainly FDR). FIONA is designed for usual clinical users or fMRI analyst {{who may not be}} an expert in neuroscience. It is designed for navigated TMS as its intended use. We also did benchmarking on different ITK optimizers comparing their performance in realignment section, to select an overall best optimizer. We test our whole implementation on different level noisy fMRI datasets. Electrical Engineering, Mathematics and Computer ScienceIntelligent SystemsEIT Digital (Digital Media Technology...|$|E
40|$|The {{following}} research examines a specific issue Cornrn 5 Web Systems is facing regarding overall customer satisfaction {{and extent of}} utilization among its product, beneJitsCONNECTSm. An electronic survey entitled, Client Utilization Survey, was developed to address client opinions on very useful features and less useful features and functionality within the system. It was also developed to assess why certain client groups do not use the software package {{even though they have}} obtained a license and continue to pay for its services on a monthly basis or yearly contract. The Client Utilization Survey was electronically sent to 643 system users of the beneJitsCONNECTSm system. This group is primarily compromised of insurance brokers nationwide. A total of 69 surveys were returned and analyzed. The objective of the research was to identify important and highly used features and <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> system, while alsoconsidering those undesired fimctionalities. This would provide great insight as to what Cornm 5 Web System's various departments should expend energy on (i. e. improvements, enhancements, and upgrades). Determining reasons why users d...|$|E
40|$|In this paper, {{we propose}} an aspect-oriented language, called SHL (Security Hardening Language), for specifying {{systematically}} the security hardening solutions. This language constitutes our new achievement towards developing our security hardening framework. SHL allows the description and specification of security hardening plans and patterns {{that are used}} to harden systematically security into the code. It is a minimalist language built on top of the current aspect-oriented technologies that are based on advice-poincut model and can also be used in conjunction with them. The primary contribution of this approach is providing the security architects with the capabilities to perform security hardening of software by applying well-defined solution and without the need to have expertise in the security solution domain. At the same time, the security hardening is applied in an organized and systematic way in order not to alter the original <b>functionalities</b> <b>of</b> <b>the</b> <b>software.</b> We explore the viability and relevance of our proposition by applying it into a case study and presenting the experimental results of securing the connections of open source software. N/...|$|E
50|$|Where most methodologies tend to {{concentrate}} on bringing rigour and structure to a software project's functional aspects, MASCOT's primary purpose is to emphasise <b>the</b> architectural aspects <b>of</b> a project. Its creators purposely avoided saying anything about <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> being developed, and concentrated on the real-time control and interface definitions between concurrently running processes.|$|R
50|$|Regression {{testing is}} {{performed}} when changes {{are made to}} <b>the</b> existing <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> or {{if there is a}} bug fix in <b>the</b> <b>software.</b> Regression testing can be achieved through multiple approaches, if a test all approach is followed it provides certainty that the changes made to <b>the</b> <b>software</b> have not affected the existing functionalities, which are unaltered, in any way.|$|R
40|$|This paper {{describes}} <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> elements, {{provides an}} overview <b>of</b> <b>the</b> system models developed for this task, and discusses <b>the</b> demonstrated capabilities <b>of</b> <b>the</b> integrated system. <b>The</b> goal <b>of</b> {{this paper is to}} provide an example of how state-of-the-art modelbased autonomy technology is integrated with a complex aerospace system, and to highlight the lessons learned from the integration proces...|$|R
30|$|Vulnerabilities are {{subset of}} {{software}} defects; they allow violation of constraints {{that can lead}} to malicious use of the software. The information, tools, and expertise that help to analyze faults (functionalities errors) apply with limited efficacy to analyze vulnerabilities. Zimmermann et al. [5] reported, for example, that the number of vulnerabilities is highly correlated with code dependencies, while the metrics that are correlated with faults such as size of changed code have only small effect. In addition, detecting faults requires exercising the specified <b>functionalities</b> <b>of</b> <b>the</b> <b>software,</b> while vulnerabilities analysis requires the software developers to have the knowledge and expertise to think like attackers [6]. Moreover, vulnerabilities detection tools do not provide often sufficient information to locate the issue easily, besides that they report high number of false positive. Thus, it is believed that “finding vulnerabilities is akin to finding a needle in a haystack” [6]. Also vulnerabilities issues occur much less frequently then faults. Thus, models derived from data related to faults and vulnerabilities issues have to deal with unbalanced datasets, c.f., [7]. Therefore, better prediction models of issue fix time should use only security issues data and consider the characteristics of issues.|$|E
40|$|In this paper, {{we present}} an aspect-oriented {{approach}} and propose a high-level language called SHL (Security Hardening Language) for the systematic security hardening of software. The primary contribution of this proposition is providing the software architects with the capabilities to perform security hardening by applying well-defined solutions {{and without the}} need to have expertise in the security solution domain. At the same time, the security hardening is applied in an organized and systematic way in order not to alter the original <b>functionalities</b> <b>of</b> <b>the</b> <b>software.</b> This is done by providing an abstraction over the actions required to improve the security of a program and adopting aspect-oriented programming to build and develop the solutions. SHL allows the developers to describe and specify the security hardening plans and patterns needed to harden systematically security into open source software. It is a minimalist language built on top of the current aspect-oriented technologies that are based on advice-poincut model and can also be used in conjunction with them. We explore the viability and relevance of our proposition by applying it into several security hardening case studies and presenting their experimental results. PublishedN/...|$|E
40|$|Abstract. Issues {{related to}} 3 d turtle’s {{navigation}} and geometrical figures ’ manipulation in the simulated 3 d {{space of a}} newly developed computational environment, MaLT, are reported and discussed here. The joint use of meaningful formalism and the dynamic manipulation of graphically represented 3 d figures seem to offer new resources and to pose new challenges as far as geometrical activities and construction of meanings are concerned, which are strongly related to the representational infrastructure of MaLT. Abilities such as spatial orientation and spatial visualisation come into play and are interwoven with the software’s functionalities and semantics. Although the body-syntonic metaphor remains critical while navigating the turtle in the 3 d simulated space, it seems {{that it has to}} be co-ordinated with other – often conflicting one another – frames of reference. The strong link between spatial graphical and geometrical aspects, that was accentuated by the dragging <b>functionalities</b> <b>of</b> <b>the</b> <b>software,</b> helped students go beyond an immediate perceptual approach, relating geometrical figures with real 3 d objects and the change of planes in 3 d space with physical angle situations. In this framework the concept of angle as turn and measure with emphasis on directionality but also as a relationship between the planes defined by 2 d figures has arisen as central...|$|E
40|$|Abstract- <b>The</b> <b>Software</b> testing phase <b>of</b> <b>the</b> {{development}} {{life cycle}} model of software plays {{a very important}} role in deciding <b>the</b> quality and <b>functionality</b> <b>of</b> <b>the</b> <b>software.</b> <b>The</b> Testing <b>of</b> <b>the</b> <b>software</b> is done to detect the fault in its functionality and on <b>the</b> basis <b>of</b> its performance further quality of software is improved. In <b>the</b> <b>software</b> testing phase there is a task involved which is prioritization of Test cases. In this paper we have discussed about test case prioritization, what is <b>the</b> need <b>of</b> test cases prioritization? And the various techniques proposed by researchers for performing the test case prioritization...|$|R
40|$|When {{developing}} complex embedded applications, <b>the</b> <b>software</b> {{is often}} built in <b>the</b> form <b>of</b> subsystems or components, which are later integrated and assembled {{to a full}} system. Throughout all stages of development and assembly, software testing is performed. On unit- or componentlevel, the structure and run-time properties <b>of</b> <b>the</b> <b>software</b> can fairly easily be predicted. This enables a thorough testing based on <b>the</b> structure <b>of</b> <b>the</b> <b>software</b> (as well as testing based on <b>the</b> intended <b>functionality</b> <b>of</b> <b>the</b> <b>software).</b> However, in <b>the</b> later stages <b>of</b> <b>the</b> assembly process, <b>the</b> structure <b>of</b> <b>the</b> <b>software</b> becomes more complex and less obvious. Hence, the developers are forced to base their testing solely on <b>the</b> intended <b>functionality</b> <b>of</b> <b>the</b> <b>software,</b> leading to a reduced testing-induced quality assurance. At the same time, bugs found in <b>the</b> later stages <b>of</b> testing (i. e., integration- and system-level testing) are significantly more costly to correct. Using dynamic and static information <b>of</b> <b>the</b> <b>software,</b> this situation can be significantly improved. This paper outlines a framework for more efficient system-level testing of real-time software for embedded applications. ...|$|R
40|$|<b>The</b> goal <b>of</b> this {{document}} {{is to present}} the development process and <b>the</b> function <b>of</b> <b>the</b> SUM radiometer system control and processing software, in order to fulfil the requirements expressed in the scenario and operational requirements and in section 7. 3. 2 <b>of</b> <b>the</b> Technical Requirement Document. This document contains the description and flowcharts <b>of</b> <b>the</b> control and processing <b>software</b> and describes <b>the</b> <b>software</b> implementation and <b>the</b> graphical user interface. First imaging results <b>of</b> <b>the</b> SUM Imaging Radiometer (SUMIRAD) show <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software.</b> <b>The</b> present document is the third and last output <b>of</b> <b>the</b> work package WP 3. 2...|$|R
40|$|This paper {{describes}} {{the progress of}} our work presented at m-ICTE 2006 [1, 2]. The general purpose {{of the work is}} to develop a software system which promotes the mastery of the combinatorial potential of natural language words by language learners. It lists some basic concepts of Lexical function theory and {{describes the}} architecture and <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> system developed. We describe the idea and the results of training experiment. Keywords lexical functions; idioms; collocations 1. General concept Good command of idioms and collocations is an important ability of any natural language speaker. This ability needs to be developed not only in foreign language learners but also in people wishing to enhance their linguistic competence in the native language. Since systematic description of idiomaticity is still a very difficult issue and linguistic resources focused on idioms and collocations are scarce, tools intended for boosting up this ability are poorly represented in modern language learning techniques. We developed a software system which can be used to improve human knowledge of the combinatorial potential of words. The idea of a software system which should facilitate the mastering of LF was first put forward by Juri Apresjan in early 1990 s, who compiled a prototype dictionary for English and Russian underlying such a system, to be followed in a mid- 1990 s INTAS-funded project, CALLEX (Computer-Aided Learning of Lexica...|$|E
40|$|The Visual_HEA {{software}} tool {{was created in}} 2006 to facilitate the assessment of losses and gains in ecosystem services related to compensatory mitigation under the United States National Resource Damage Assessment Act (NRDA). Habitat Equivalency Analysis (HEA) is an ecological equivalence assessment method under NRDA that can be performed using the Visual_HEA software and {{for which it was}} named. The newers version – 2. 6 – was recently enhanced and tested over several years to be adapted to the European context and to facilitate adherence to the Environmental Liability Directive (2004 / 35 /EC) to compensate for environmental damages. Herein, enhancements, limitations, and a turnkey method of calculating variable gain and loss rates over space and time using the 2. 6 version of the software are discussed. Major functionality enhancements include a quarterly discount calculation, increased decimal precision, gain calculations that extend into perpetuity, and the elimination of many small software “bugs”. A case study about the accidental pollution of the Mimizan River from a sodium hypochlorite spill at a paper mill illustrates the new <b>functionalities</b> <b>of</b> <b>the</b> <b>software.</b> The use of the HEA method to assess ecosystem services related to biodiversity offset has been widespread thanks to the development of this user-friendly software package. Furthermore, the HEA method implemented in Visual HEA_ 2. 6 is recommended by the European Commission to enforce its Environmental Liability Directive and to size mitigations after accidental environmental damages...|$|E
40|$|The master thesis {{deals with}} the {{principles}} of design easily extensible and easily manageable applications, and has as a main objective to give directions for changing the existing and generally accepted ways of software development by using modern object-oriented software architectures that can meet the challenges of development software solutions that rise up {{in the beginning of the}} second decade of the twenty-first century. The analysis of current conditions and principles for developing software that are in common use, shows that there are problems that extensively contribute to lowered productivity in the process of software development. The main problem is the lack of standardized and functional methods for unlimited usage of functional components that have already been developed and generally because the functional components are tightly coupled with other functional components within the application. Additionally, documentation of the <b>functionalities</b> <b>of</b> <b>the</b> <b>software</b> applications is difficult due to the lack of independence of the functional components as well as their too vide range. Consequently due to this the maintenance and upgrading of the software applications in the future becomes inflexible. The modern object-oriented software architecture that is elaborated in the thesis directly targets the discovered weaknesses and problems that affect productivity in the development process of software applications by using a combination of several known principles and guidelines tries to resolve them. It is aimed to increase the productivity and in foster the cooperation between developers of software solutions. ...|$|E
40|$|This {{high level}} control <b>software</b> used in <b>the</b> tests <b>of</b> TT 40 and TI 8 in 2003 and 2004 was {{developed}} by the LSA project team. This note describes the tools used, <b>the</b> architecture <b>of</b> <b>the</b> system and <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> provided. <b>The</b> architecture chosen and validated by the tests will be used for the LHC {{high level control}} software. Future developments are discussed...|$|R
5000|$|Modules, which extend <b>the</b> <b>functionality</b> <b>of</b> <b>the</b> <b>software</b> program itself. These modules act as plugins to the AveDesk program itself, {{and are not}} desklets or widgets. Modules provide {{additional}} functionality {{such as the ability}} to show or hide [...] "PidlShortcut" [...] desklets that point to specific disk drives as they are mounted or dismounted, or to automatically hide all normal desktop icons when the program is started.|$|R
5000|$|... the [...] "phylogenetic motif model" [...] {{scanning}} <b>functionality</b> <b>of</b> <b>the</b> MONKEY <b>software</b> that models evolutionary {{relationships among}} aligned sequences, ...|$|R
