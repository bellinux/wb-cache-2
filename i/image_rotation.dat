292|438|Public
25|$|Dynamic color {{convergence}} and purity {{are one of}} {{the main}} reasons why until late in their history, CRTs were long-necked (deep) and had biaxially curved faces; these geometric design characteristics are necessary for intrinsic passive dynamic color convergence and purity. Only starting around the 1990s did sophisticated active dynamic convergence compensation circuits become available that made short-necked and flat-faced CRTs workable. These active compensation circuits use the deflection yoke to finely adjust beam deflection according to the beam target location. The same techniques (and major circuit components) also make possible the adjustment of display <b>image</b> <b>rotation,</b> skew, and other complex raster geometry parameters through electronics under user control.|$|E
5000|$|Lens {{distortion}} correction {{as well as}} <b>image</b> <b>rotation</b> ("Straighten") via playback ("Retouch") menu ...|$|E
5000|$|Vignetting ("Vignette control") correction, {{as well as}} <b>image</b> <b>rotation</b> ("Straighten") via {{playback}} ("Retouch") menu ...|$|E
5000|$|Telemedicine {{allows a}} remote {{retrieval}} of three-dimensional CT scans, <b>images</b> <b>rotation</b> and zooming {{in real time}} through an operator interface to hospital server and medical equips in speakerphone.|$|R
5000|$|For scale {{changes in}} the range 2-2.5 and <b>image</b> <b>rotations</b> in the range 30 to 45 degrees, SIFT and SIFT-based {{descriptors}} again outperform other contemporary local descriptors with both textured and structured scene content.|$|R
40|$|Non-search {{algorithm}} {{of image}} angle estimation is presented. This algorithm improves precision of image angle estimation {{by means of}} estimation of particular angles, which are less than real angle. Analysis of algorithm includes investigation of test and real <b>images</b> <b>rotation.</b> ???????????? ???????????? ???????? ??????????? ???? ???????? ???????????, ?????????????? ????????? ???????? ?????????? ?? ???? ???????? ? ??????????? ??????? ????? ???????? ???????????, ??????? ??????? ?????????? ????????. ?????? ????????? ???????? ?? ???????? ? ???????? ????????????????? ????????????...|$|R
50|$|Other basic two {{dimensional}} techniques include operations such as <b>image</b> <b>rotation,</b> warping, color balancing etc.|$|E
50|$|Other {{methods can}} handle {{problems}} such as translation, scale, <b>image</b> <b>rotation</b> and even all affine transformations.|$|E
5000|$|Auto lens {{distortion}} ("Distortion") correction and Perspective Control {{as well as}} <b>image</b> <b>rotation</b> ("Straighten") via playback ("Retouch") menu ...|$|E
30|$|Robust guidance, navigation, {{and control}} systems for MAVs[1] {{depend on the}} input {{information}} obtained from on-board sensors as cameras. Undesired movements are usually generated during the fly {{as a result of}} complex aerodynamic characteristics of the UAV. Unnecessary <b>image</b> <b>rotations</b> and translations appear in the video sequence, increasing the difficulty to control the vehicle.|$|R
30|$|In {{addition}} to its high accuracy, the suggested system has two other advantages as well. First, it is computationally inexpensive so it is very favorable for using in real-time systems. Also the proposed algorithm is resistant to <b>rotation</b> of the <b>images.</b> <b>Rotation</b> invariance {{is very important for}} retina-based identification systems because people may turn their head slightly during scanning time. In the proposed algorithm, a suitable resistance to the rotation has been formed using 1 D Fourier transform.|$|R
3000|$|In {{terms of}} {{performance}} accuracy, SIFT and SURF provide highest precision although the recalls are low. Harris detector performs well when used together with SIFT or SURF descriptor, generating better balance between recall and precision. The DWT-based corner detector does not {{perform as well}} as the Harris detector when used with SIFT or SURF descriptor. This is because the DWT-based detector is more sensitive to discretization noise caused by <b>image</b> <b>rotations</b> which happen to be very common in the Oxford dataset ([...] [...]...|$|R
50|$|The {{auxiliary}} telescopes {{can only}} be used for imaging on static optical tables and do not provide <b>image</b> <b>rotation</b> correction.|$|E
50|$|A delta prism is {{a compact}} folded {{version of the}} {{traditional}} Dove prism. It is used for <b>image</b> <b>rotation</b> and derotation. Only the base is silvered, and the prism is made of high-index glass.|$|E
50|$|<b>Image</b> <b>rotation</b> {{is a very}} {{important}} feature for websites giving users basic image editing abilities. Images are either automatically rotated (based on Exif data) or the user is allowed to manually rotate the image.|$|E
40|$|The method {{itself can}} be {{classified}} as relational matching, bases on point features. For robust extraction and filtration of features the special procedure, based on dynamic resampling technique, was elaborated. Further the rotation invariant relations among the features are used to confirm or reject initial hypothesis. All calculation procedures are time effective and invariant to <b>images</b> <b>rotation.</b> Finally, the approach given is applied to two different tasks: automatic mosaic creation from video camera sequence frames and automatic relative orientation of photographic camera images. 1...|$|R
40|$|This paper {{addresses}} {{the problem of}} structure and motion from silhouettes for turntable sequences. Previous works have exploited corresponding points induced by epipolar tangencies to estimate the image invariants under turntable motion and recover the epipolar geometry. In these approaches, however, camera intrinsics are {{needed in order to}} obtain Euclidean motion and reconstruction. This paper proposes a novel approach to precisely estimate the image invariants and the rotation angles {{in the absence of the}} camera intrinsics, and to perform auto-calibration. By exploiting a special parameterization of the epipoles, it is shown that the imaged circular points can be formulated in terms of the image invariants. A fixed scalar κ, introduced to account for the different scales in the homogeneous representations of the image invariants used in the parameterizations, is found crucial in both calibration and motion estimation. Given the image invariants, namely the horizon, the <b>imaged</b> <b>rotation</b> axis and its orthogonal vanishing point, this scalar can be determined from the epipoles in an image triplet. A robust method for estimating κ is proposed and the rotation angles can be recovered using this estimated value of κ. All the estimated variables are then refined using bundle-adjustment and auto-calibration is performed using the imaged circular points, the <b>imaged</b> <b>rotation</b> axis and the associated vanishing point. This allows the recovery of the full camera positions and orientations, and hence Euclidean reconstruction. Experimental results demonstrate the simplicity of this novel approach and the high precision in the estimated motion and reconstruction. ...|$|R
30|$|Image size: 320 × 240  pixels (visible and thermal), Total 4228 {{pairs of}} thermal and visible images with 176 – 250 images/person, 11 <b>images</b> per <b>rotation</b> (poses for each {{expression}} and each illumination) 30 persons - Expression, pose, and illumination.|$|R
50|$|As of January 2009, {{almost all}} new mobile phones and digital cameras contain {{at least a}} tilt sensor and {{sometimes}} an accelerometer {{for the purpose of}} auto <b>image</b> <b>rotation,</b> motion-sensitive mini-games, and to correct shake when taking photographs.|$|E
50|$|KolourPaint is a free, raster {{graphics}} editor by KDE. It {{is similar to}} Microsoft's Paint application before the version shipped with Windows 7, but has some additional features such as support for transparency, color balance and <b>image</b> <b>rotation.</b>|$|E
50|$|However, Johnson and Bouchard {{found that}} “isolation {{of the tests}} {{involved}} resulted in identification of an additional third-stratum factor for <b>image</b> <b>rotation,</b> which also eliminated the contradictory cross-loadings.” Therefore, finally, the new model was named as verbal-perceptual-rotation (VPR) model.|$|E
40|$|Invariant {{features}} are image characteristics which remain unchanged under {{the action of}} a transformation group. We consider in this paper <b>image</b> <b>rotations</b> and translations and present algorithms for constructing invariant features. After briefly sketching the theoretical background we develop algorithms for recognizing several objects in a single scene without the necessity to segment the image beforehand. The objects can be rotated and translated independently. Moderate occlusions are tolerable. Furthermore we show {{how to use these}} techniques for the recognition of articulated objects. The methods work directly with the gray values and do not rely on the extraction of geometric primitives like and tested both on synthetic and real image data. We present some illustrative experimental results...|$|R
40|$|International audienceIn this paper, {{we address}} the problem of {{estimating}} and removing non-uniform motion blur from a single blurry image. We propose a deep learning approach to predicting the probabilistic distribution of motion blur at the patch level using a convolutional neural network (CNN). We further extend the candidate set of motion kernels predicted by the CNN using carefully designed <b>image</b> <b>rotations.</b> A Markov random field model is then used to infer a dense non-uniform motion blur field enforcing motion smoothness. Finally, motion blur is removed by a non-uniform de-blurring model using patch-level image prior. Experimental evaluations show that our approach can effectively estimate and remove complex non-uniform motion blur that is not handled well by previous approaches...|$|R
40|$|International audienceWe {{claim and}} present {{arguments}} {{to the effect}} that a large class of manifold learning algorithms that are essentially local and can be framed as kernel learning algorithms will suffer from the curse of dimensionality, at the dimension of the true underlying manifold. This observation suggests to explore non-local manifold learning algorithms which attempt to discover shared structure in the tangent planes at different positions. A criterion for such an algorithm is proposed and experiments estimating a tangent plane prediction function are presented, showing its advantages with respect to local manifold learning algorithms: it is able to generalize very far from training data (on learning handwritten character <b>image</b> <b>rotations),</b> where a local non-parametric method fails...|$|R
50|$|In this step, each keypoint is {{assigned}} {{one or more}} orientations based on local image gradient directions. This is the key step in achieving invariance to rotation as the keypoint descriptor can be represented relative to this orientation and therefore achieve invariance to <b>image</b> <b>rotation.</b>|$|E
50|$|It {{otherwise}} offers {{nearly all}} {{the features of the}} D3S, including robust weather-sealed alloy-body construction and a built-in vertical grip. Its Nikon EXPEED image processor features automatic correction of lateral chromatic aberration, and vignetting ("vignette control") and lens distortion ("distortion"), as well as <b>image</b> <b>rotation</b> ("straighten") via playback ("retouch") menu and in camera 5:4 aspect ratio cropping.|$|E
5000|$|SURF {{was first}} {{presented}} by Herbert Bay, et al., at the 2006 European Conference on Computer Vision. An {{application of the}} algorithm is patented in the United States. An [...] "upright" [...] version of SURF (called U-SURF) is not invariant to <b>image</b> <b>rotation</b> and therefore faster to compute and better suited for application where the camera remains more or less horizontal.|$|E
40|$|In a {{previous}} report ([5]: Davidoff J & Warrington EK. The bare bones of object recognition: implications from {{a case of}} object recognition impairment. Neuropsychologia 1999; 37 : 279 - 92) the inability to differentiate between mirror images was recorded in a patient with excellent canonical view recognition. We now extend our investigation to a patient (JBA) with probable Alzheimer's disease in whom canonical view recognition was compromised. The reciprocal inhibition of two aspects of object processing are demonstrated in JBA. The patient's ability to detect mirror <b>image</b> <b>rotations</b> was dependent on her inability to identify the object. Paradoxically, her performance was more impaired for those stimuli {{that she was able}} to identify than those she was not...|$|R
40|$|We {{claim and}} present {{arguments}} {{to the effect}} that a large class of man-ifold learning algorithms that are essentially local and can be framed as kernel learning algorithms will suffer from the curse of dimensionality, at 1 the dimension of the true underlying manifold. This observation suggests to explore non-local manifold learning algorithms which attempt to discover shared structure in the tangent planes at different positions. A criterion for such an algorithm is proposed and experiments estimating a tangent plane prediction function are presented, showing its advantages with respect to local manifold learning algorithms: it is able to generalize very far from training data (on learning handwritten character <b>image</b> <b>rotations),</b> where a local non-parametric method fails. ...|$|R
40|$|International audienceThis work puts forth a {{probabilistic}} graphical {{framework to}} track unoccluded objects undergoing large out of <b>image</b> plane <b>rotations</b> and/or presenting large scale variations in video sequences. The proposed scheme incorporates measurements from an ensemble of local patch trackers and inter-patch geometric layout {{to arrive at}} a sample based approximation of the state posterior. Following this, the geometric layout is updated online using the Iterative Conditional Estimation technique. These steps are iterated until convergence to arrive at the final state posterior. In contrast to offline training based schemes the proposed framework imposes no prior on the geometric layout and instead relies on online update of the geometric layout, thus broadening the scope of usage. Amongst other advantages, the scheme implicitly estimates the scale of the target and also adapts to varying target appearances to enable tracking under a fair degree of out of the <b>image</b> plane <b>rotations.</b> The tracking abilities of this scheme is put to test on several challenging videos with scale changes, out of the <b>image</b> plane <b>rotations,</b> illumination changes and motion jerks. Whereever possible qualitative comparisons are facilitated using videos from standard databases...|$|R
50|$|With the {{exception}} of Cork, the company (like NTL Ireland) carries the basic channel pack on all analogue cable links unencrypted, to save on decoder equipment. Premium channels - some of Sky Sports and Sky Movies are always available, with more movies and the Fantasy Channel in some areas - use a simple <b>image</b> <b>rotation</b> system {{that is similar to}} 1980s satellite TV systems.|$|E
5000|$|Fingerprint-matching {{algorithms}} {{vary greatly}} {{in terms of}} Type I (false positive) and Type II (false negative) error rates. They also vary in terms of features such as <b>image</b> <b>rotation</b> invariance and independence from a reference point (usually, the [...] "core", or center of the fingerprint pattern). The accuracy of the algorithm, print matching speed, robustness to poor image quality, and the characteristics noted above are critical elements of system performance.|$|E
50|$|Un{{compressed}} {{video is}} digital video that either {{has never been}} compressed or was generated by decompressing previously compressed digital video. It is commonly used by video cameras, video monitors, video recording devices (including general purpose computers), and in video processors that perform functions such as image resizing, <b>image</b> <b>rotation,</b> deinterlacing, and text and graphics overlay. It is conveyed over various types of baseband digital video interfaces, such as HDMI, DVI, DisplayPort and SDI.|$|E
5000|$|... #Caption: Earth's <b>rotation</b> <b>imaged</b> by DSCOVR EPIC on 29 May 2016, a {{few weeks}} before the {{solstice}} ...|$|R
30|$|This {{leads to}} the {{importance}} of a given rotation matrix and translation matrix to rectify an <b>image.</b> The <b>rotation</b> and translation matrices are taken from the essential matrix, i.e., decomposing the essential matrix allows the rotation and translation matrices to be calculated.|$|R
50|$|In mathematics, {{a figure}} is chiral (and {{said to have}} chirality) if it cannot be mapped to its mirror <b>image</b> by <b>rotations</b> and {{translations}} alone. For example, a right shoe is different from a left shoe, and clockwise is different from anticlockwise.|$|R
