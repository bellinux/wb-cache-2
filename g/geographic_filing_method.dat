0|567|Public
5000|$|<b>Geographic</b> Data <b>Files</b> (GDF) — An {{interchange}} <b>file</b> {{format for}} <b>geographic</b> data ...|$|R
40|$|The aim of {{this article}} is to {{introduce}} a new stand-alone application—Geo-Segregation Analyzer— that is capable of calculating 43 residential segregation indices, regardless of the population groups or the metropolitan region under study. In practical terms, the user just needs to have a Shapefile <b>geographic</b> <b>file</b> containing counts of population groups that differ in ethnic origin, birth country, age, or income across a metropolitan area at a small area level (e. g., census tracts). Developed in Java using the GeoTools library, this free and open-source application is both multiplatform and multilanguage. The software functions on Windows, Mac OS X, and Linux operating systems and its user interface currently supports 10 languages (English, French, Spanish, Catalan, German, Italian, Portuguese, Creole, Vietnamese, and Chinese). The application permits users to display and manipulate several Shapefile <b>geographic</b> <b>files</b> and to calculate 19 one-group indices, 13 two-group indices, 8 multigroup indices, and 3 local measures that could be mapped (location quotient, entropy measure, and typology of the ethnic areas proposed by Poulsen, Johnson, and Forrest) ...|$|R
5000|$|The {{extraction}} to temporary <b>file</b> <b>method</b> {{has several}} disadvantages: ...|$|R
5000|$|Receive {{and record}} the incoming/outgoing mail and {{organize}} the GSDP's archive according to advanced <b>filing</b> <b>methods.</b>|$|R
5000|$|Google Contacts can be {{utilized}} {{by the user}} specifically, using any of three CSV (Comma-separated values) <b>file</b> <b>methods</b> listed below: ...|$|R
40|$|This polygon shapefile layer {{represents}} {{areas where}} zoning and discretionary tax incentives {{are available for}} the development, expansion and renovation of full line grocery stores and supermarkets. This is a <b>geographic</b> <b>file</b> created by the New York City Department of City Planning, showing eligible areas for zoning incentives and eligible areas for tax incentives through the NYC Industrial Development Agency. For {{more information on the}} FRESH program and other incentives targeting grocery stores, please see www. nyc. gov/FRESH, or download the report in the archival copy...|$|R
50|$|February 8, 2017, for {{boundary}} files (second edition), reference maps (second edition), attribute information products (GeoSuite and <b>geographic</b> attribute <b>file),</b> {{and reference}} guides and documents (second edition).|$|R
30|$|Anesthesia, {{surgical}} procedure, {{protocol and}} physiologic measurements {{have been described}} in a previous publication [5], and a full account is provided in the supplementary <b>files</b> (<b>Methods</b> Supplement).|$|R
30|$|All {{resulting}} permutations {{were classified}} {{into the following}} categories: monaural versus stereo, same stereo versus same stereo <b>file,</b> <b>method</b> A versus method B, method A versus nonexpert mix, method B versus nonexpert mix, method A versus expert mix, and method B versus expert mix.|$|R
40|$|Signature {{files and}} {{inverted}} files are well-known index structures. In this paper we undertake a direct {{comparison of the}} two for searching for partially-specified queries in a large lexicon stored in main memory. Using n-grams to index lexicon terms, a bit-sliced signature file can be compressed to a smaller size than an inverted file if each n-gram sets only one bit in the term signature. With a signature width {{less than half the}} number of unique n-grams in the lexicon, the signature <b>file</b> <b>method</b> is about as fast as the inverted <b>file</b> <b>method,</b> and significantly smaller. Greater flexibility in memory usage and faster index generation time make signature files appropriate for searching large lexicons or other collections in an environment where memory is at a premium...|$|R
50|$|ArcSDE enables {{organizations}} {{to move from}} a traditional approach — managing separate collections of <b>geographic</b> data <b>files</b> — to an integrated environment in which one can manage spatial data as a continuous database: accessible to the entire organization simultaneously and easily publishable on the Web.|$|R
40|$|A new {{signature}} <b>file</b> <b>method</b> for accessing {{information from}} large data files containing both formatted and free text data is presented. The new method, called the multi-organizational scheme is proposed for indexing very large data files containing {{hundreds of thousands}} or possibly mil-lions of records. 1...|$|R
5000|$|The {{interface}} only declares {{the class}} interface {{and not the}} methods themselves: the actual code is written in the implementation <b>file.</b> Implementation (<b>method)</b> <b>files</b> normally have the file extension , which originally signified [...] "messages".|$|R
40|$|Abstract. Many {{works on}} the {{signature}} <b>file</b> <b>methods</b> {{have been made in}} the past, but they are mainly for static environments. However, many re-cent applications in practice require a dynamic information storage struc-ture that effectively supports insertions, deletions and updates. Though there are a few signature file techiniqucs for dynamic: environments, they suffer from serious performance degradation when query signature weights are light. In this paper, we propose a new dynamic signature file organization, called the hierarchical signature(llS) file, that solves the problem of light query signature weights. We perform simulation ex-periments by using wide range of parameter values. We show through performance comparison based on experiments that the HS file improves performance significantly in both the retrieval time and the storage over-head over the other dynamic signature <b>file</b> <b>methods</b> proposed earlier...|$|R
40|$|The series {{consists}} of: <b>geographic</b> <b>files,</b> subject {{files and}} international organizations <b>files.</b> The <b>geographic</b> <b>files</b> include materials on 40 countries in Europe, North Africa and the Middle East. The subject files cover the following topics: National AJC staff and lay committees in Germany; the national AJC Committee on Near Eastern Affairs; Augustin Cardinal Bea and the Pro Deo Project; AJC delegations to Europe, Israel, and North Africa; antisemitism, fascism, and neo-Nazism; Christian-Jewish relations and the Ecumenical Council; the Columbus Project (David Astor and psychopathology); denazification trials; the Eichmann case; freedom of information; the Gauting Conference; genocide; group libel; human rights; immigration; Jewish communal services conference; Jewish war orphans; racial discrimination; European restitution programs and operations; visas to enter the United States. The international organizations files consist of: correspondence, reports, and other papers involving relationships between the AJC Paris Office and various organizations and groups such as: American Jewish Joint Distribution Committee, 1947 - 1952; Centre d'Information Israelite, 1947; Conference on Jewish Material Claims Against Germany, 1952 - 1962; Consultative Council of Jewish Organizations, 1946 - 1963; Council of Europe, 1951 - 1953; emigre organizations, 1942 - 1959; International Center, St. Paul the Apostle (Rome), 1964 - 1966; International Council of Christians and Jews, 1947 - 1949; International League, 1963 - 1966; International Refugee Organization, 1946 - 1949; London Conference, 1945 - 1946; Memorial Foundation for Jewish Culture, 1965 - 1967; P. E. N. Club, 1953; United Jewish Educational and Cultural Organization, 1946 - 1951; United Nations, and its various bodies, 1947 - 1967; World Brotherhood Organization; World Council of Churches; and World Jewish Congress. Inventory: English, 28 pp., typedLabeledEstablished in 1947 as the regional office for Europe and North Africa...|$|R
40|$|Abstract In this paper, a {{signature}} <b>file</b> <b>method</b> for indexing document database systems is presented. For this purpose, {{the concept of}} presentative word hierarchy is introduced, based on which signature file hierarchies can be established. Together {{with the concept of}} query signature hierarchy, it improves significantly the retrieval efficiency of documents stored structurally in object oriented databases. ...|$|R
50|$|Paper filing is the universally {{accepted}} <b>filing</b> <b>method.</b> Form 1040, {{along with its}} variants, schedules, and instructions, can be downloaded as PDFs from the Internal Revenue Service website. Finalized versions of the forms for the tax year (which in the US {{is the same as}} the calendar year) are released near the end of January of the following year.|$|R
5000|$|USGS Geographic Names Information System (GNIS) Feature Detail Report for: SpruceFeature ID: 856140Name: SpruceClass: Populated PlaceCitation: Collected during Phase I data {{compilation}} (1976-1981), primarily from U.S. Geological Survey 1:24,000-scale topographic maps (or 1:25K, Puerto Rico 1:20K), various edition dates, and from U.S. Board on <b>Geographic</b> Names <b>files</b> FID 856140.Entry Date: 12-Dec-1980Elevation(ft/m)*: 5604/1708 ...|$|R
50|$|<b>Geographic</b> Data <b>Files</b> (GDF) is an {{interchange}} <b>file</b> {{format for}} <b>geographic</b> data.In contrast with generic GIS formats, GDF provides detailed rules for data capture and representation, and an extensive catalog of standard features, attributes and relationships. The most recent extension expanded applicability further towards pedestrian navigation, 3-D map rendering, and advanced driver-assistance systems (ADAS).|$|R
50|$|Also many {{independent}} artists {{choose a}} peer-to-peer <b>file</b> sharing <b>method</b> named BitTorrent Bundle for distribution.|$|R
5000|$|Project and Code Navigation: {{specialized}} project views, file structure {{views and}} quick jumping between <b>files,</b> classes, <b>methods</b> and usages ...|$|R
40|$|We outline {{a scheme}} to perform static {{watermarking}} on an entire Java class <b>file,</b> <b>method</b> by method. We show that our scheme offers a structural approach towards increased resistance against tampering attacks. We demonstrate how the watermark {{can be used to}} determine in what way the class file has been modified, if tampering has happened. We compare against other previously known watermarking schemes and show that our scheme provides watermarking with increased robustness and decreased visibility...|$|R
40|$|Two {{laboratories}} performed this testing during 2001 - 2002. In {{order to}} maintain confidentiality of the participants the quality control summary statistics and graphs were combined to mask the individual analysis dates from the two laboratories. Methods for both labs are included in this release. Most methods for Lab 18 analytes are in one combined <b>file.</b> <b>Methods</b> Lab 40 are described in a separate file for each analyte tested. A list of the released analytes follows...|$|R
40|$|A new {{signature}} <b>file</b> <b>method,</b> Multi-Frame Signature <b>File</b> (MFSF), {{is introduced}} by extending the bit-sliced signature <b>file</b> <b>method.</b> In MFSF, a signature file {{is divided into}} variable sized vertical frames with different on-bit densities to optimize the response time using a partial query evaluation methodology. In query evaluation the on-bits of the lower on-bit density frames are used first. As the number of query terms increases, the number of query signature on-bits in the lower on-bit density frames increases and the query stopping condition is reached in fewer evaluation steps. Therefore, in MFSF, the query evaluation time decreases for increasing numbers of query terms. Under the sequentiality assumption of disk blocks, in a PC environment with 30 ms average disk seek time, MFSF provides a projected worst-case response time of 3. 54 seconds for a database size of one million records in a uniform distribution multi-term query environment with 1 - 5 terms per query. Due to partial evaluation, this desired response time is guaranteed for queries with several terms. The comparison of MFSF with the inverted file approach shows that MFSF provides promising research opportunities. © 1997 Elsevier Science Ltd...|$|R
40|$|Cataloged from PDF {{version of}} article. A new {{signature}} <b>file</b> <b>method,</b> Multi-Frame Signature <b>File</b> (MFSF), is introduced by extending the bit-sliced signature <b>file</b> <b>method.</b> In MFSF a signature file {{is divided into}} variable sized vertical frames with different on-bit densities to optimize the response time using a partial query evaluation methodology. In query evaluation the on-bits of the lower on-bit density frames are used first. As the number of query terms increases, the number of query signature on-bits in the lower on-bit density frames increases and the query stopping condition is reached in fewer evaluation steps. Therefore, in MFSF, the query evaluation time decreases for increasing numbers of query terms. Under the sequentiality assumption of disk blocks, in a PC environment with 30 ms average disk seek time, MFSF provides a projected worst-case response time of 3. 54 seconds for a database size of one million records in a uniform distribution multi-term query environment with 1 - 5 terms per query. Due to partial evaluation, this desired response time is guaranteed for queries with several terms. The comparison of MFSF with the inverted file approach shows that MFSF provides promising research opportunities. (C) 1997 Elsevier Science Ltd...|$|R
50|$|XDCC (Xabi DCC or eXtended DCC) is a {{computer}} <b>file</b> sharing <b>method</b> which uses the Internet Relay Chat (IRC) network as a host service.|$|R
40|$|The {{signature}} <b>file</b> <b>method</b> is {{a popular}} indexing technique used in information retrieval and databases. It excels in efficient index maintenance and lower space overhead. However, it suffers from inefficiency in query processing {{due to the fact}} that for each query processed the entire signature file needs to be scanned. In this paper, we introduce a tree structure, called a signature tree, established over a signature file, which can be used to expedite the signature file scanning by one order of magnitude o...|$|R
40|$|For {{processing}} {{a signature}} file in parallel, an effective signature <b>file</b> declustering <b>method</b> is needed. The Linear Code Decomposition Method(LCDM) {{used for the}} Hamming Filter may give a good performance in some cases, but due to its static property, it fails to evenly decluster a signature file when signatures are skewed. In addition, it has other problems such as limited scalability and non-determinism. In this {{paper we propose a}} new signature <b>file</b> declustering <b>method,</b> called the Inner-product method, which overcomes those problems in the LCDM. The Inner-product method declusters a signature file dynamically based on the signature difference which is computed by using signature inner product. We show through the various experiments that the Inner-product method outperforms the LCDM under various data workloads. Jae � Chung � Jae��Byoung � A Dynamic Signature <b>File</b> Declustering <b>Method</b> based on the Signature Differenc...|$|R
40|$|Several <b>file</b> {{retention}} policy <b>methods</b> propose that a file {{retention policy}} {{should be based on}} file value. Though such a retention policy might increase the value of accessible <b>files,</b> the <b>method</b> to arrive at such a policy is underresearched. This article discusses how one can arrive at a <b>method</b> for developing <b>file</b> retention policies based on the use values of <b>files.</b> The <b>method’s</b> applicability is initially assessed through a case study at Capgemini, Netherlands. In the case study, we hypothesize that one can develop a file retention policy by testing causal relations between file attributes (as used by <b>file</b> retention <b>methods)</b> and the use value of files. Unfortunately, most file attributes used by <b>file</b> retention <b>methods</b> have a weak correlation with file value, resulting in the conclusion that these methods do not well select out high- and low-value files. This would imply the ineffectiveness of the used attributes in our study or errors in our conceptualization of file value. We continue with the last possibility and develop indicators for file utility (with low utility being waste). With this approach we were able to detect waste files, in a sample of files, with an accuracy of 80 %. We therefore not only suggest further research in information waste detection as part of a file retention policy, but also to further explore other file attributes that could better predict file value and file utility...|$|R
5000|$|Automatic data wiper: Allows you {{to clear}} usage data, {{temporary}} internet files, cookies, and more whenever NetCaptor is closed. Supports several different <b>file</b> wiping <b>methods.</b>|$|R
50|$|Twister is a Twitter-like microblogging {{platform}} that utilizes the same blockchain technology as Bitcoin, and the <b>file</b> exchange <b>method</b> from BitTorrent, both based on P2P technologies.|$|R
5000|$|Project and code navigation: special project views, file {{structure}} views, {{and quick}} jumping between <b>files,</b> classes, <b>methods</b> and usages, navigation through class hierarchy, and usages search.|$|R
40|$|The {{problem of}} using {{redundancy}} for constructing algorithmic properties of nonpositional numerical repersentations is solved; theoretical bases of constructing different classes of redundancy of numerical representations, theoretical bases of constructing basis representations and minibasis modeling are developed. Methods and algorithms of supporting data safety when operating distributed ACS, methods of unified through control of pseudobinary and pseudononpositional <b>files,</b> <b>methods</b> of formal decomposition are processing of dependent files on components of distributed ACS are developedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|A grinding-free {{method to}} extract DNA from teeth via a direct minimal-invasive {{retrograde}} {{approach to the}} pulp cavity and dentine was compared to a standard grinding/pulverisation method. This alternate method uses endodontic dental files to access the root canals and pulp cavity for tissue and dentine harvest via the apical end of the roots and avoids mechanical damage to the crown and root morphology. In contrast, other methods require pulverisation of the whole root or tooth, transection or destruction of the occlusal surface {{to gain access to}} the DNA in the root canals and pulp chamber. This study compared two methods for preparing dentine powder from the roots of environmentally challenged teeth for forensic DNA analysis. We found that although the <b>filing</b> <b>method</b> was more laborious, and produced less dentine powder, the amount of amplifiable DNA per milligram of powder was substantially higher with the <b>filing</b> <b>method</b> compared to grinding the entire root. In addition, the number of short tandem repeat (STR) alleles detected and the peak height ratios of the STR profiles were notably higher. Although several other methods of extracting DNA-rich tissue from the pulp chamber of teeth have previously been reported, the method presented in this study is minimally invasive, thereby allowing the preservation of tooth and crown morphology...|$|R
40|$|Exchanging CAD model data among {{heterogeneous}} CAD {{systems is}} indispensable for collaborative product development. Currently, the industry mainly uses the standardized neutral <b>files</b> based <b>methods</b> to implement such exchange. While {{at the same}} time, the application of Web Ontology Language (OWL) file and underlying Semantic Web technologies in CAD model data exchange is gaining importance and popularity within the academia. The coexistence {{of different types of}} methods has generated a series of controversies and questions within the industry and the academia. Yet, can the neutral <b>files</b> based exchange <b>methods</b> completely implement model data exchange among heterogeneous CAD systems? What challenges have been addressed to date by the developed CAD model data exchange standards? Why OWL has been introduced to CAD model data exchange? Does CAD model data exchange really need OWL? Are there any issues in existing neutral <b>files</b> based exchange <b>methods</b> and OWL <b>file</b> based exchange <b>methods</b> need to be addressed in future studies? This paper proposes to conduct a study of the standardized neutral <b>files</b> based exchange <b>methods</b> and OWL <b>file</b> based exchange <b>methods.</b> An in-depth analysis of the widely used STandard for the Exchange of Product model data (STEP) method and the newly emerging OWL methods is firstly provided. Then the paper makes a detailed comparison between these two types of methods based on this analysis. Finally, some issues in the two types of methods {{that need to be addressed}} in the future are discusse...|$|R
40|$|A {{computer-based}} system to produce listings of topical sub;ect terms and geographically subdivided terms is described. The system files and their associated listings {{are called the}} Subject Authority File (SAF) and the <b>Geographic</b> Authority <b>File</b> (GAF). Conversion, operation, problems, and costs of the system are presented. Details of the optical scanning conversion, with illustrations, show the relative ease of the technique for simple upper case data files. Program and data characteristics are illustrated with record layouts and sample listings...|$|R
