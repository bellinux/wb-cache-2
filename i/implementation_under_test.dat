130|10000|Public
5000|$|To {{ensure that}} actual {{implementations}} of such standardised features are interoperable, the standardisation bodies also create so called test specifications. These document detail exact procedures {{on how to}} test that an <b>implementation</b> <b>under</b> <b>test</b> acts according to conformance requirements. Important test specifications for the (U)SIM interface are: ...|$|E
50|$|KeY is usable as a model-based {{testing tool}} that can {{generate}} unit tests for Java programs. The model from which test {{data and the}} test case are derived consists of a formal specification (provided in JML) and a symbolic execution tree of the <b>implementation</b> <b>under</b> <b>test</b> which is computed by the KeY system.|$|E
5000|$|Based on {{the amount}} of test cases {{required}} to construct a complete test suite in each context (i.e. a test suite such that, if it is applied to the <b>implementation</b> <b>under</b> <b>test,</b> then we collect enough information to precisely determine whether the system is correct or incorrect according to some specification), a testability hierarchy with the following testability classes has been proposed: ...|$|E
40|$|Abstract: Generally, {{test cases}} {{derived from a}} formal model can not be {{directly}} fed into <b>implementations</b> <b>under</b> <b>test</b> (IUT), because model based test generation techniques produce abstract test cases. In order to run an abstract test case against an IUT the ab-stract test case either has to be transformed to a concrete test case or an execution of the abstract test case is needed. In this {{paper we propose a}} rule based test execution frame-work, which allows the execution of abstract test cases. Furthermore, we present first results from testing a so called SIP Registrar by executing abstract test cases derived with the TGV tool from a formal specification. ...|$|R
40|$|AbstractWe {{consider}} the specification {{and testing of}} systems where probabilistic information is not given by means of fixed values but as intervals of probabilities. We will use {{an extension of the}} finite state machines model where choices among transitions labelled by the same input action are probabilistically resolved. We will introduce our notion of test and we will define how tests are applied to <b>implementations</b> <b>under</b> <b>test.</b> We will also present implementation relations to assess the conformance, up to a level of confidence, of an implementation to a specification. In order to define these relations we will take finite samples of executions of the implementation and compare them with the probabilistic constraints imposed by the specification. Finally, we will give an algorithm for deriving sound and complete test suites...|$|R
40|$|Abstract—TinyAID is a {{tool that}} {{supports}} automated instru-mentation and evaluation of TinyOS-based distributed applica-tions. Two types of instrumentations are provided: logging of call chains and message flows within the network. TinyAID assists the debugging process by post evaluation of the logged data. A main benefit is the visualization component for representing traces in their spatial and temporal order. The instrumentation and evaluation concepts are evaluated in two case studies: the SelfWISE framework and a selection of routing algorithms. Due to the automated process of TinyAID the evaluation could be performed without a deeper knowledge of the <b>implementations</b> <b>under</b> <b>test.</b> In the first case TinyAID revealed a weakness in the TOSSIM random number generator. The second case demonstrates the power of TinyAID to visualize the quality of protocols in a unified manner, without any manual changes to the specific source code. I...|$|R
50|$|Snapshot Semantics is a {{technique}} in TTCN3 (also in TTCN2), which deals with the message passed during communication by system to system or <b>implementation</b> <b>under</b> <b>test.</b> When a series of responses are received by system under test, then snapshot is taken and they are evaluated in order of their arrival. So, each time around a set of attributes, a snapshot is taken and only those events are evaluated which are present in snapshot.|$|E
50|$|It {{has been}} proved that each class is {{strictly}} included into the next. For instance, testing when {{we assume that the}} behavior of the <b>implementation</b> <b>under</b> <b>test</b> can be denoted by a deterministic finite-state machine for some known finite sets of inputs and outputs and with some known number of states belongs to Class I (and all subsequent classes). However, if the number of states is not known, then it only belongs to all classes from Class II on. If the <b>implementation</b> <b>under</b> <b>test</b> must be a deterministic finite-state machine failing the specification for a single trace (and its continuations), and its number of states is unknown, then it only belongs to classes from Class III on. Testing temporal machines where transitions are triggered if inputs are produced within some real-bounded interval only belongs to classes from Class IV on, whereas testing many non-deterministic systems only belongs to Class V (but not all, and some even belong to Class I). The inclusion into Class I does not require the simplicity of the assumed computation model, as some testing cases involving implementations written in any programming language, and testing implementations defined as machines depending on continuous magnitudes, have been proved to be in Class I. Other elaborated cases, such as the testing framework by Matthew Hennessy under must semantics, and temporal machines with rational timeouts, belong to Class II.|$|E
40|$|This paper {{presents}} a methodology to perform passive testing based on invariants for systems that present temporal restrictions. Invariants represent {{the most relevant}} expected properties of the <b>implementation</b> <b>under</b> <b>test.</b> Intuitively, an invariant expresses the fact that each time the <b>implementation</b> <b>under</b> <b>test</b> performs a given sequence of actions, then it must exhibit a behavior in a lapse of time reflected in the invariant. In particular, the algorithm {{presented in this paper}} are fully implemente...|$|E
40|$|We {{describe}} a centralized approach to testing that distributed fault-tolerant protocols satisfy their safety and timeliness specifications {{in the presence}} of the very failures they are designed to tolerate. Cesium is a testing environment based on the centralized simulation of distributed executions and failures. Processes are run in a single address space while providing the appearance of a truly distributed execution. The human tester can force the occurrence of arbitrary failures and security attacks. The <b>implementations</b> <b>under</b> <b>test</b> are not instrumented for testing purposes, and their source codes need not be available. We prove that Cesium can execute exactly the set of runs feasible in the real distributed system being simulated. We also show that there are safety and timeliness properties in the specifications of many existing distributed protocols that cannot be tested in practical distributed systems. All of these properties can, however, be accurately tested by Cesium without [...] ...|$|R
40|$|While today’s {{communications}} {{are essential}} {{and a huge}} set of services is available online, computer networks continue to grow and novel communication protocols are continu-ously being defined and developed. De facto, protocol standards are required to allow different systems to interwork. Though these standards can be formally verified, the de-velopers may produce some errors leading to faulty implementations. That {{is the reason why}} their implementations must be strictly tested. However, most current testing approaches require a stimulation of the <b>implementation</b> <b>under</b> <b>tests</b> (IUT). If the system cannot be accessed or interrupted, the IUT {{will not be able to}} be tested. Besides, most of the existing works are based on formal models and quite few works study formalizing performance requirements. To solve these issues, we proposed a novel logic-based testing approach to test the protocol conformance and performance passively. In our approach, conformance and performance requirements can be accurately formal-ized using the Horn-Logic based syntax and semantics. These formalized requirements are also tested through millions of messages collected from real communicating environ...|$|R
40|$|Cesium is an {{object-oriented}} {{environment for}} testing that implementations of real-time, fault-tolerant protocols satisfy {{the safety and}} timeliness properties prescribed by their specifications. Protocol <b>implementations</b> are <b>tested</b> <b>under</b> configurable workloads and failure scenarios. A centralized simulator executes all tasks in a single address space while providing the appearance of truly distributed execution. Experiments can be exactly reproduced any number of times; Cesium provides an unprecedented degree of monitoring and control over them. It {{is not necessary to}} instrument (or even to have access to) the source code of the protocols <b>under</b> <b>test.</b> The observed behaviors correspond exactly to executions in the real system being simulated, as Cesium does not change the time of occurrence of any event. Besides from providing a testing and performance evaluation environment superior to real distributed systems, Cesium can test properties of existing protocols that can not be tested in an [...] ...|$|R
40|$|In {{this paper}} we extend our {{previous}} work on passive testing of timed systems {{to establish a}} formal criterion to determine correctness of an <b>implementation</b> <b>under</b> <b>test.</b> In our framework, an invariant expresses {{the fact that if}} the <b>implementation</b> <b>under</b> <b>test</b> performs a given sequence of actions, then it must exhibit a behavior in a lapse of time reflected in the invariant. In a previous paper we gave an algorithm to establish the correctness of an invariant with respect to a specification. In this paper we continue the work by providing an algorithm to check the correctness of a log, recorded form the <b>implementation</b> <b>under</b> <b>test,</b> with respect to an invariant. We show the soundness of our method by relating it to an implementation relation. In addition to the theoretical framework we have developed a tool, called PASTE, that facilitates the automation of our passive testing approach...|$|E
40|$|This paper {{presents}} a methodology to perform passive testing of timed systems. In passive testing, the tester does not {{interact with the}} <b>implementation</b> <b>under</b> <b>test.</b> On the contrary, execution traces are observed without interfering with the behaviour of the system. Invariants are used to represent the most relevant expected properties of the <b>implementation</b> <b>under</b> <b>test.</b> Intuitively, an invariant expresses the fact that each time the <b>implementation</b> <b>under</b> <b>test</b> performs a given sequence of actions, it must exhibit a behaviour in a lapse of time reflected in the invariant. There {{are two types of}} invariants: consequent and observational. The paper gives two algorithms to decide the correctness of proposed invariants with respect to a given specification and algorithms to check the correctness of a log, recorded from the <b>implementation</b> <b>under</b> <b>test,</b> with respect to an invariant. The soundness of this methodology is shown by relating it to an implementation relation. In addition to the theoretical framework, a tool called PASTE has been developed. This tool helps in the automation of the passive testing approach because it implements all the algorithms presented in this paper. PASTE takes advantage of mutation testing techniques in order to evaluate the goodness of an invariant according to its capability to detect errors in logs generated from mutants. An empirical study where PASTE was used to analyse a non-trivial system is also reported...|$|E
40|$|Online {{testing is}} a {{technique}} in which test derivation from a model program and test execution are combined into a single algorithm. We describe a practical online testing algorithm that is implemented in the model-based testing tool developed at Microsoft Research called Spec Explorer. Spec Explorer is being used daily by several Microsoft product groups. Model programs in Spec Explorer are written in the high level specification languages AsmL or Spec#. We view model programs as implicit definitions of interface automata. The conformance relation between a model and an <b>implementation</b> <b>under</b> <b>test</b> is formalized in terms of refinement between interface automata. Testing then amounts to a game between the test tool and the <b>implementation</b> <b>under</b> <b>test.</b> 1...|$|E
40|$|The Integrated Tokamak Modelling (ITM) Task Force aims at {{providing}} {{a suite of}} codes for preparing and analyzing future ITER discharges. In {{the framework of the}} ITM, the universal access layer (UAL) provides the capability of storing and retrieving data involved in simulation. The underlying data structure is hierarchical and the granularity in data access is given by the definition of a set of consistent physical objects (CPOs). To describe the data structure of the overall ITM database, the XML schema description (XSD) has been used. Originally intended to describe the structure of XML documents, XSD is used here to provide an unambiguous way of describing how data are structured, regardless of the actual implementation of the underlying database. The MDSplus-based UAL <b>implementation</b> is currently <b>under</b> <b>test</b> and other prototypes for investigating alternative data storage systems are foreseen...|$|R
40|$|The {{topic of}} this thesis is {{automated}} test generation for control software represented {{in a specific}} standard, the IEC 61499. This standard, which is largely based {{on the concept of}} function block, establishes a way to design distributed control systems in a visually clear way. The goal of the thesis was to design a test generation approach or a number of such approaches that would produce input test data with high coverage of the <b>implementation</b> of systems <b>under</b> <b>test.</b> Coverage is a measure which expresses the fraction of the system that was exercised at least ones when all tests in a test suite were run on this system. To reach the stated goal, evolutionary computation, a general optimization methodology, was employed. In this methodology, possible solutions of the problem (in our case, test suites) are developed during a simulated evolution process which involves mutating solutions (that is, altering them insignificantly) and combining them into new ones. Two methods of test suite generation were designed based on the mentioned approaches. The experimental evaluation showed that one of them produces test suites with high coverage but is time consuming, and another one is more flexible and fast, but produces test suites with lower coverage. It was also shown that the proposed methods are capable of identifying faults in control software <b>under</b> <b>test,</b> which are mainly connected with unreachable system segments...|$|R
5000|$|UBASIC {{provides}} an <b>implementation</b> <b>under</b> the name APRT-CLE (APR Test CL extended) ...|$|R
40|$|International audienceTesting {{techniques}} {{are used to}} check if a given system implementation satisfies its specification or some predefined properties. These testing techniques can be active, based on the execution of specific test sequences against the <b>implementation</b> <b>under</b> <b>test,</b> or passive, based on the observation of the exchange of messages (input and output events) of the <b>implementation</b> <b>under</b> <b>test</b> during run-time. In the last years an important research activity has been taken place on the definition of monitoring techniques based on passive testing and verification techniques. In this talk, we will present the main characteristics of monitoring techniques, their advantages and limitations. We will also present the monitoring in practice; in particular, we will present the Montimage Monitoring Tool, an industrial prototype developed by the SME Montimag...|$|E
40|$|There are {{two aspects}} to testing: (1) the {{selection}} of appropriate test inputs and (2) {{the analysis of the}} observed interactions of the <b>implementation</b> <b>under</b> <b>test</b> (IUT) in order to determine whether they conform to the IUT's specification. The paper considers the second aspect with particular attention to the testing o...|$|E
40|$|Scenarios {{are vital}} for the {{specification}} of software systems. We are developing an open {{framework for the}} specification, execution, and conformance evaluation of scenarios. The scenarios define a contract which is bound to an <b>implementation</b> <b>under</b> <b>test.</b> The scenarios are executed by our framework to ensure conformance against the contract...|$|E
5000|$|The Legion of the Bouncy Castle {{provides}} Java and C# <b>implementations</b> <b>under</b> the MIT License.|$|R
5000|$|OpenRISC: an {{open-source}} microprocessor family, with architecture specification licensed under GNU GPL and <b>implementation</b> <b>under</b> LGPL.|$|R
5000|$|OP-TEE, an {{open source}} <b>implementation</b> <b>under</b> BSD license, {{originally}} from STMicroelectronics, now owned and maintained by Linaro.|$|R
40|$|Abstract. On-the-fly {{testing is}} a {{technique}} in which test derivation from a model program and test execution are combined into a single algorithm. It can also be called online testing using a model program, to distinguish it from offline test generation as a separate process. We describe a practical on-the-fly testing algorithm that is implemented in the model-based testing tool developed at Microsoft Research called Spec Explorer. Spec Explorer is being used daily by several Microsoft product groups. Model programs in Spec Explorer are written in a high level specification language AsmL or Spec#. We view model programs as implicit definitions of interface automata. The conformance relation between a model and an <b>implementation</b> <b>under</b> <b>test</b> is formalized in terms of refinement between interface automata, and testing amounts to a game between the test tool and the <b>implementation</b> <b>under</b> <b>test.</b> ...|$|E
40|$|International audienceIn {{this paper}} we expand our {{work in our}} {{specification}} formalism UIOLTSs. We present three implementation relations and provide alternative characterizations of these relations {{in terms of the}} tests that the <b>implementation</b> <b>under</b> <b>test</b> successfully passes. In addition, we present the main ideas to obtain an algorithm to derive complete test suites from specifications...|$|E
40|$|We present several theorems {{and their}} proofs which enable using {{synchronous}} testing {{techniques such as}} input output conformance testing (ioco) {{in order to test}} implementations only accessible through asynchronous communication channels. These theorems define when the synchronous test-cases are sufficient for checking all aspects of conformance that are observable by asynchronous interaction with the <b>implementation</b> <b>under</b> <b>test...</b>|$|E
40|$|In {{a process}} and a device for the {{acoustic}} testing {{of a unit}} <b>under</b> <b>test,</b> the unit <b>under</b> <b>test</b> is subjected to sound excitement and the sound generated {{in the region of}} the unit <b>under</b> <b>test</b> is recorded and evaluated. In order to perform a test on such units <b>under</b> <b>test</b> which do not resonate and have no intrinsic sounds, the sound generated in the region of the test is recorded and evaluated while the unit <b>under</b> <b>test</b> is being excited by sound...|$|R
5000|$|To make {{recommendations}} {{on the new}} safety standards of various components for notification and <b>implementation</b> <b>under</b> Central Motor Vehicles Rules.|$|R
50|$|Boediono. 2002. The IMF support {{program in}} Indonesia: {{comparing}} its <b>implementation</b> <b>under</b> three presidents, Bulletin of Indonesian Economic Studies, 38 (3).|$|R
40|$|The {{objective}} of protocol testing is {{to confirm that}} a protocol <b>implementation</b> <b>under</b> <b>test</b> conforms to its specification. However, in protocol test architectures that utilize multiple remote testers in a distributed environment, this objective can be {{complicated by the fact}} that testers may encounter problems relating to controllability and observability during the application of a test sequence. Solutions in literature to these problems usually involve first generating a test sequence from the specification of an <b>implementation</b> <b>under</b> <b>test,</b> then inserting coordination messages or appending selected test subsequences that will allow the testers to solve the controllability and observability problems. This thesis proposes a method that uses a set of transformation rules to construct a directed graph from a given specification. A transition tour of this directed graph based on a rural Chinese postman tour will result in a test sequence with no potential for controllability or observability problems, and where the use of coordination messages is either minimized or, if possible, avoided altogether...|$|E
40|$|International audienceThis paper {{presents}} {{an extension of}} the methodology to perform passive testing based on invariants for systems that present temporal restrictions. Invariants represent the most relevant expected properties of the <b>implementation</b> <b>under</b> <b>test.</b> Intuitively, an invariant expresses the fact that each time the <b>implementation</b> <b>under</b> <b>test</b> performs a given sequence of actions, then it must exhibit a behavior in a lapse of time reflected in the invariant. When a trace is checked against an invariant, for each input/output action that appears in the trace then the complete set of invariants is checked. That is, it is assumed that invariants must hold at any point of the trace, and the cost of checking this process depends on the length of the trace and the number of invariants. In this paper a novel approach that allows us to "activate" and "deactivate" some invariants during the testing task is presented. Within this approach automatically the number of invariants that must be checked can be decreased at runtime, which causes a reduction in the cost of the testing task without loosing any power of error detection...|$|E
40|$|We {{present and}} compare {{different}} notions of conformance testing based on labeled transition systems. We formulate and prove several theorems which enable using synchronous conformance testing {{techniques such as}} input–output conformance testing (ioco) {{in order to test}} implementations only accessible through asynchronous communication channels. These theorems define when the synchronous test cases are sufficient for checking all aspects of conformance that are observable by asynchronous interaction with the <b>implementation</b> <b>under</b> <b>test.</b> © 2015, Springer-Verlag Berlin Heidelberg...|$|E
50|$|JSSCxml a Web browser <b>implementation</b> <b>under</b> active development. Highly conformant, {{with good}} support for DOM Events. Only {{supports}} the ECMAScript datamodel.|$|R
40|$|An error {{response}} {{test system}} and method with increased functionality and improved performance is provided. The error response test system provides {{the ability to}} inject errors into the application <b>under</b> <b>test</b> to test the error response of the application <b>under</b> <b>test</b> in an automated and efficient manner. The error response system injects errors into the application through a test mask variable. The test mask variable {{is added to the}} application <b>under</b> <b>test.</b> During normal operation, the test mask variable is set to allow the application <b>under</b> <b>test</b> to operate normally. During testing, the error response test system can change the test mask variable to introduce an error into the application <b>under</b> <b>test.</b> The error response system can then monitor the application <b>under</b> <b>test</b> to determine whether the application has the correct response to the error...|$|R
40|$|WO 200123877 A UPAB: 20010607 NOVELTY - Non-destructive {{material}} characterization {{and internal}} stress measurement of a ferromagnetic part <b>under</b> <b>test</b> comprises determining electrical potential of part by {{direct or indirect}} electrical tapping. DETAILED DESCRIPTION - Non-destructive material characterization and internal stress measurement of a ferromagnetic part <b>under</b> <b>test</b> comprises measuring a high frequency electrical signal caused by an excitation current flowing through the part <b>under</b> <b>test</b> and/or by mechanical deformation of the part <b>under</b> <b>test.</b> The electrical potential of the part <b>under</b> <b>test</b> is determined by a direct or indirect electrical tapping on the part <b>under</b> <b>test.</b> A high frequency potential component caused by magnetic reversal processes is determined from the electrical potential of the part <b>under</b> <b>test</b> and {{is used as a}} high frequency noise signal for determining test quantities. USE - For monitoring thermo-chemical heat treatment of materials, and plastic deformation, tear initiation and advancement in materials (claimed). ADVANTAGE - The process is reliable...|$|R
