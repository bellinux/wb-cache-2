8|10000|Public
30|$|Since {{the focus}} of the multi-DOA {{estimation}} system is to estimate the <b>direction</b> <b>of</b> <b>speech</b> sources, a general infinite impulse response band-pass filter is used {{at the beginning of the}} process to remove general ambient noise that is outside the human speech frequency bands (between 1 and 4 kHz). Thus, sound sources that are outside of this frequency range are rejected. This filter was designed using a single Butterworth-based second-order solution.|$|E
40|$|The {{spectral}} subtraction {{method is}} a classical approach for enhancement of speech degraded by additive background noise. The basic principle {{of this method}} is to estimate the short-time spectral magnitude of speech by subtracting estimated noise spectrum from the noisy speech spectrum. This is also achieved by multiplying the noisy speech spectrum with a gain function and later combining it with the phase of the noisy speech. Besides reducing the background noise, this method introduces an annoying perceptible tonal characteristic in the enhanced speech and affects the human listening, known as remnant musical noise. Several variations and implementations of this method have been adopted in past decades to address the limitations of spectral subtraction method. These variations constitute a family of subtractive-type algorithms and operate in frequency domain. The objective {{of this paper is}} to provide an extensive overview of spectral subtractive-type algorithms for enhancement of noisy speech. After the review, this paper is concluded by mentioning a future <b>direction</b> <b>of</b> <b>speech</b> enhancement research from spectral subtraction perspective...|$|E
40|$|AbstractCommonly {{displayed}} functional asymmetries such as hand {{dominance and}} hemispheric speech lateralisation are well researched in adults. However there is debate about when such functions become lateralised in the typically developing brain. This study examined whether patterns of speech laterality and hand dominance were related {{and whether they}} varied with age in typically developing children. 148 children aged 3 – 10 years performed an electronic pegboard task to determine hand dominance; a subset of 38 of these children also underwent functional Transcranial Doppler (fTCD) imaging to derive a lateralisation index (LI) for hemispheric activation during speech production using an animation description paradigm. There was no main effect {{of age in the}} speech laterality scores, however, younger children showed a greater difference in performance between their hands on the motor task. Furthermore, this between-hand performance difference significantly interacted with <b>direction</b> <b>of</b> <b>speech</b> laterality, with a smaller between-hand difference relating to increased left hemisphere activation. This data shows that both handedness and speech lateralisation appear relatively determined by age 3, but that atypical cerebral lateralisation is linked to greater performance differences in hand skill, irrespective of age. Results are discussed in terms of the common neural systems underpinning handedness and speech lateralisation...|$|E
40|$|In modern {{computer}} systems, {{more attention}} {{is given to}} building natural interface information; <b>directions</b> <b>of</b> <b>speech</b> are the dialogue, which contains automatic speech recognition and synthesis. The system included many different applications, for example voice control, voice access to information resources, language training programming, incapable, accessing through voice verification/identification. Study a starting point on the speech recognition trouble used hidden Markov model, wavelets and neural network could be involved for making more precise prediction are implemented in as a library of Computer Simulation for use with digital signal processors tms 320 vc- 5505 of Texas Instruments Brand. On this library there was created a test speaker dependent system of specific terms recognition with {{the small size of}} the dictionary...|$|R
40|$|The study {{investigated}} the L 2 <b>speech</b> rhythm <b>of</b> Chinese English speakers (L 1 = Mandarin) using the metrics of ΔV, ΔC, %V, VarcoV, VarcoC, rPVI-C and nPVI-V. Five native speakers of American English and Mandarin were recruited to record five sentences in English. In addition, the Chinese speakers also recorded five Mandarin sentences. One-way ANOVAs were conducted to see if significant differences exist {{on each of the}} metrics among L 1 English, L 2 English and L 1 Mandarin. Results show that the two L 1 ’s are categorically distinct on all metrics, conforming to the perceptually distinct rhythmicities of English and Mandarin. However, {{no significant differences were found}} between L 1 and L 2 English (which have different intuitive rhythmicities) on almost all the metrics, suggesting that the metrics are inadequate to capture the suprasegmental details that give the final make-up <b>of</b> <b>speech</b> rhythm. Finally, new <b>directions</b> <b>of</b> <b>speech</b> rhythm research and new applications of the rhythm metrics are sketched...|$|R
40|$|In this paper, we {{describe}} a system developed for hands free audio analysis {{for a living}} room environment. It comprises detection and localisation of the verbal and paralinguistic events, which can augment the behaviour of virtual director and improve the overall experience of interactions between spatially separated families and friends. The results show good performance in reverberant environments and fulfil real-time requirements. Index Terms: real-time audio processing, <b>direction</b> <b>of</b> arrival, <b>speech</b> meta-dat...|$|R
40|$|In sociolinguistic terms, {{certain aspects}} of {{academician}} Grot’s activity {{can be seen as}} language policy. Therefore a discussion of the new conflictological direction of sociolinguistics (along with status and corpus directions) is of current importance. Its object is delinquent communicative situations: 1) speech crimes against non-proprietary rights of people and organizations (deffamation and libel), against societal and governmental rights to normal functioning (speech extremism); 2) discussions of mass media deontology violations. Its objectives are identification and resolution of conflicts in communication, as well as punishment and prevention of speech crimes. Within its framework, the decision of a court or a deontological authority is a direct act of language policy, whereas a linguistic expertise is its consecutive act and simultaneously its tool. A linguistic expertise as a procedure of search for an evidential base of a speech crime is performed in governmental and independent centers. This correlates with a governmental and public <b>direction</b> <b>of</b> <b>speech</b> policy, revealing their inherent contradictions. As an illustration the author uses a lawsuit on protection of honor and dignity of a «United Russia» party member V. Svirid versus a well-known political figure of the opposition field, A. Navalny, in which the court verdict didn't take into consideration the professional opinions of linguistical experts from a regional university...|$|E
40|$|International audienceVocal pitch {{has been}} found to {{influence}} judgments of perceived trustworthiness and dominance from a novel voice. However, the majority of findings arise from using only male voices and in context-specific scenarios. In two experiments, we first explore the influence of average vocal pitch on first-impression judgments of perceived trustworthiness and dominance, before establishing the existence of an overall preference for high or low pitch across genders. In Experiment 1, pairs of high- and low-pitched temporally reversed recordings of male and female vocal utterances were presented in a two-alternative forced-choice task. Results revealed a tendency to select the low-pitched voice over the high-pitched voice as more trustworthy, for both genders, and more dominant, for male voices only. Experiment 2 tested an overall preference for low-pitched voices, and whether judgments were modulated by speech content, using forward and reversed speech to manipulate context. Results revealed an overall preference for low pitch, irrespective of <b>direction</b> <b>of</b> <b>speech,</b> in male voices only. No such overall preference was found for female voices. We propose that an overall preference for low pitch is a default prior in male voices irrespective of context, whereas pitch preferences in female voices are more context- and situation-dependent. The present study confirms the important role of vocal pitch in the formation of first-impression personality judgments and advances understanding of the impact of context on pitch preferences across genders...|$|E
40|$|ABSTRACT The article {{presents}} theoretical principles of study the verbal oral speaking {{of children of}} a preschool age {{on the basis of}} the analysis of studies by T. V. Akhutina, D. B. Elkonin, Z. M. Istomina, K. V. Zasipkina, L. O. Kalmykova, M. M. Koltsova, N. I. Lepskaya, A. O. Lublinskaya, I. G. Ovchinnikova, A. O. Romanova, S. L. Rubinstein, N. M. Yurieva and others; the definition of the phenomenon “narration” is clarified, its characteristics are generalized; the criteria and indicators of study the peculiarities of the development of verbal spoken language of children of a preschool age are distinguished and substantiated with such indicators as: sustainability of motives, independence of motives, cognitive orientation, social <b>direction</b> <b>of</b> <b>speech</b> motives; internal-language criterion, represented by indicators, namely: semantic syntax and the choice of meanings in internal speech in time sequence, semantic syntax and the choice of verbal meanings of words; lexical-grammatical criterion presented by a complex indicator of formal grammatical structuring and the choice of words in form (lexeme) with the establishment of: the types of sentences, types of phrases, the presence of morphological classes of the words, the presence of lexical-semantic group of words, the number of words in sentences, the formal grammatical coherence; context criterion, correlated with the following indicators: the sequence in the story presentation, the logical presentation of the story, connectivity, integrity; structural criterion, which provides such indicators as: the presence of compositional parts, the order of words in the sentence; intonation criterion, the essence of which is revealed through such indicators: melodic, tempo, phrasal and logical accents, intonation of the ending. The chosen criteria are based on the analysis of speech generation mechanism, which is represented by the operations on motive emergence, the formation of thought, the construction of the internal semantic program, the semantic structure of sentence, the lexico-grammatical structure of sentence and motor program of a syntagma, which allows to study the peculiarities of development in children of the internal and external operations of logical and sequential creation of the story with taking into account its essential features, in particular, context, intonation, etc...|$|E
40|$|Theories {{suggesting}} common processing mechanisms link praxis {{and speech}} {{are supported by}} evidence that both functions share neural architecture. A new fTCD paradigm is presented exploring the hypothesis that only motor tasks dependent on left hemispheric specialisation for sequential processing will accurately predict <b>direction</b> and strength <b>of</b> <b>speech</b> lateralisation (Methodology...|$|R
25|$|In contrast, the Beat poets, who {{included}} such figures as Jack Kerouac (1922–1969), Allen Ginsberg (1926–1997), Gregory Corso (1930–2001), Joanne Kyger (born 1934), Gary Snyder (born 1930), Diane Di Prima (born 1934), Amiri Baraka (born 1934) and Lawrence Ferlinghetti (born 1919), were distinctly raw. Reflecting, sometimes in an extreme form, the more open, relaxed and searching {{society of the}} 1950s and 1960s, the Beats pushed {{the boundaries of the}} American idiom in the <b>direction</b> <b>of</b> demotic <b>speech</b> perhaps further than any other group.|$|R
40|$|In {{this paper}} the {{localization}} cue preservation of a noise reduction algorithm for binaural hearing aids is analyzed. In a binaural noise reduction procedure based on Multi-channel Wiener Filtering (MWF), the basic cost function is extended with terms {{related to the}} Interaural Transfer Functions (ITF) <b>of</b> a <b>speech</b> and noise source. To make the algorithm computationally feasible, these cost terms are simplified to quadratic terms. First it is shown that this approach cannot preserve the ITF <b>of</b> the <b>speech</b> and noise component simultaneously. However, the obtained output ITF {{is related to the}} output SNR. This will lead to a perceptually advantageous effect: a noisy output signal (low SNR) will be perceived in the <b>direction</b> <b>of</b> the noise source, while a clean output signal (high SNR) will be perceived in the <b>direction</b> <b>of</b> the <b>speech</b> source. status: publishe...|$|R
40|$|This thesis {{presents}} work {{in three}} main <b>directions</b> <b>of</b> the automatic <b>speech</b> recognition field. The work within {{two of these}} [...] dynamic decoding and hybrid HMM/ANN speech recognition [...] {{has resulted in a}} real-time speech recognition system, currently in use in the human/machine dialogue demonstration system WAXHOLM, developed at the department. The third direction is fast unsupervised speaker adaptation, where "fast" refers to adaptation with a small amount <b>of</b> adaptation <b>speech.</b> The work i...|$|R
40|$|An {{adaptive}} beamformer for behind-the-ear dual-microphone {{hearing aids}} has been optimized for speech intelligibility enhancement {{in the presence}} of disturbing sounds or noise. The noise reduction approach is based on the scheme presented by Vanden Berghe and Wouters (1998). A real-time implementation of the signal processing is realized in Audallion, a wearable, small digital signal processing (DSP) platform. After physical evaluation, speech-in-noise intelligibility tests have been carried out on three normally-hearing and two hearing-impaired subjects. A significant speech reception threshold improvement of 11. 3 dB was obtained in a moderately reverberant environment for one jammer sound source (steady speech-weighted noise or multi-talker babble) in a <b>direction</b> <b>of</b> 90 degrees relative to the <b>direction</b> <b>of</b> the <b>speech.</b> status: publishe...|$|R
40|$|Humans, both {{consciously}} and unconsciously, use subtle expressions to indirectly {{communicate their}} emotions and intentions through variations <b>of</b> the gaze <b>direction,</b> pitch <b>of</b> <b>speech</b> and gesture speed. Humans also perceive {{changes in the}} internal states of others from subtle changes in their expressivities while interacting with them. Subtle expressivity plays the supporting part to the leading role of explicit expressivity, such as contents <b>of</b> <b>speech</b> or category <b>of</b> facial expressions. However, subtle expressivity {{plays an important role}} to gently regulate the relationship among the participants of an continuous interaction. These subtle expressivities are little focused on in the design of interactive media in the context of software products and computers. Only in the area of computer games in which pre-designed animated characters are used...|$|R
50|$|KSDB {{began as}} an {{experiment}} {{on the third floor}} of Nichols Gymnasium in 1949. The first broadcasts began in earnest in March, but KSDB was a commercial station by June. KSDB's commercial status allowed it to be self-supporting. Instead of a tower, the station broadcast over the campus power system. Broadcasting as a wired-wireless (or carrier current) station meant the signals never went more than a few hundred feet from power lines. This was within the maximum distance allowed by the Federal Communications Commission (FCC). At this time, the station was a member of the Intercollegiate Broadcasting System and under the <b>direction</b> <b>of</b> the <b>Speech</b> Department and Prof. George L. Arms.|$|R
40|$|Speech {{intelligibility}} {{is substantially}} improved when speech and interfering noise are spatially separated. This spatial unmasking is mostly {{caused by a}} combination of head shadow and binaural auditory processing. Binauralspeech reception thresholds (SRTs) in such spatial conditions can be predicted very accurately using a combination of an Equalization-and-Cancellation (EC) model and the Speech-Intelligibility-Index (SII). This binauralspeech intelligibilitymodel predicts effects including levels, frequency spectra, and <b>directions</b> <b>of</b> the <b>speech</b> and noise signals as well as listeners' hearing loss, early reflections and reverberant parts of the noise signals. Earlier versions of the model were only able to predict the intelligibility <b>of</b> near-field <b>speech.</b> Recent extensions can also predict the intelligibility <b>of</b> far-field <b>speech</b> by taking early reflections and reverberant parts <b>of</b> the <b>speech</b> signal into account. However, some interactions between the <b>direction</b> <b>of</b> the noise source and early speech reflections cannot be predicted yet. The overall high prediction accuracy of the model (more than 90 % of the data's variance can be explained) indicates that the model is applicable in real rooms and may serve as a tool in room acoustical design. This work was supported by the Deutsche Forschungsgemeinschaft (SFB TRR 31) ...|$|R
2500|$|Adaptive {{directional}} microphones automatically {{vary the}} <b>direction</b> <b>of</b> maximum amplification or rejection (to reduce an interfering directional sound source). The <b>direction</b> <b>of</b> amplification or rejection is varied by {{the hearing aid}} processor. The processor attempts to provide maximum amplification in the <b>direction</b> <b>of</b> the desired <b>speech</b> signal source or rejection in the <b>direction</b> <b>of</b> the interfering signal source. Unless the user manually temporarily switches to a [...] "restaurant program, forward only mode" [...] adaptive directional microphones frequently amplify the <b>speech</b> <b>of</b> other talkers in a cocktail party type environments, such as restaurants or coffee shops. The presence <b>of</b> multiple <b>speech</b> signals {{makes it difficult for}} the processor to correctly select the desired speech signal. Another disadvantage is that some noises often contain characteristics similar to speech, making it difficult for the hearing aid processor to distinguish the speech from the noise. Despite the disadvantages, adaptive directional microphones can provide improved speech recognition in noise ...|$|R
40|$|Humans, both {{consciously}} and unconsciously, use subtle expressions to indirectly {{communicate their}} emotions and intentions through variations <b>of</b> the gaze <b>direction,</b> pitch <b>of</b> <b>speech</b> and gesture speed. Humans also perceive {{changes in the}} internal states of others from subtle changes in their expressivities while interacting with them. Subtle expressivity plays the supporting part to the leading role of explicit expressivity, such as contents <b>of</b> <b>speech</b> or category <b>of</b> facial expressions. However, subtle expressivity {{plays an important role}} to gently regulate the relationship among the participants of an continuous interaction. The design and evaluation of subtle expressivity are challenges for designers and researchers of embodied characters. How do the subtle variations in expressioninfluence the interaction? What types of subtle expressions are most important for the design of interactive media? How can the effect of the expressions be reliably measured? To address these questions, we gathered related studies for this workshop. We hope that this workshop will serve as a forum for vivid discussions and hence point out future research directions...|$|R
40|$|The {{research}} {{objective is to}} disclose the subject matter of speech therapy work focused on fluidity <b>speech</b> formation <b>of</b> preschool age children, suffering stutter. Stutter is a difficult disorder of articulation organs such that the tempo-rhythmical organisation of statements is distressed that leads to defects and failures of dialogue system, negatively influences on individual development of the child; more specifically it generates the mental stratifications, specific features of emotional-volitional sphere, and causes undesirable qualities of character such as shyness, indecision, isolation, negativism. The author notes that the problem of early stutter correction among junior preschool-aged children considered as topical and immediate issue.  Methods. Concerning the clinical, physiological, psychological and psychologic-pedagogical positions, the author summarizes theoretical framework; an experimentally-practical approbation of an author's method <b>of</b> <b>speech</b> fluidity and stutter abolition of preschool children is described. Stage-by-stage process of correction, spontaneous and non-convulsive speech formation: 1. restraint mode application in order to decrease incorrect verbal output; 2. training exercises to long phonatory and speech expiration; 3. development of coordination and movements rhythm helping to pronounce words and phrases; 4. formation <b>of</b> situational <b>speech,</b> at first consisted of short sentences, then passing to long ones; 5. training to coherent text statements. The research demonstrates data analyses of postexperimental diagnostic examination of stuttering preschool children, proving {{the efficiency of the}} author’s applied method. Scientific novelty. The research findings demonstrate a specific approach to correction and stutter abolition of preschool children. Proposed author’s approach consists of complementary to each other <b>directions</b> <b>of</b> <b>speech</b> therapy work which are combines in the following way: coherent speech formation corresponding to age norms; the assistance in development of lexical and grammatical means of language; development of communicative skills. Practical significance. The identified methodological recommendations while correction-pedagogical process can be used for formation of communicative children readiness to school training and gaining experience of positive interaction with people around them. Timely measures aimed at <b>speech</b> acquisition <b>of</b> stuttering preschool children can warn possible deviations in mental development and prevent many difficulties due to their social adaptation. It is especially underlined that the guarantee <b>of</b> successful <b>speech</b> therapy work on stutter correction should be aimed at active interaction of experts with teachers of preschool educational institutions and parents. </p...|$|R
40|$|Abstract—Speech source {{localization}} in reverberant environments {{has proved}} difficult for automated microphone array systems. Because of its nonstationary nature, certain features observable in the reverberant speech signal, such as sudden increases in audio energy, provide cues to indicate time–frequency regions that are particularly useful for audio localization. We exploit these cues by learning a mapping from reverberated signal spectrograms to localization precision using ridge regression. Using the learned mappings in the generalized cross-correlation framework, we demonstrate improved localization performance. Additionally, the resulting mappings exhibit behavior {{consistent with the}} well-known precedence effect from psychoacoustic studies. Index Terms—Acoustic arrays, array signal processing, delay estimation, <b>direction</b> <b>of</b> arrival estimation, <b>speech</b> processing. I...|$|R
40|$|OBJECTIVE: In {{this study}} the {{performance}} of a noise reduction strategy applied to cochlear implants is evaluated. The noise reduction strategy is based on a 2 -channel adaptive filtering strategy using two microphones in a single behind-the-ear hearing aid. DESIGN: Four adult LAURA cochlear implant users (Peeters et al., 1993) took part in the experiments. The tests included identification of monosyllabic CVC (consonant-vowel-consonant) words and measurements <b>of</b> the <b>speech</b> reception threshold (SRT) of lists of numbers, in background noise presented at 90 degrees relative to the 0 degrees frontal <b>direction</b> <b>of</b> the <b>speech.</b> Percent correct phoneme scores for the CVC words at signal to noise ratios (SNRs) of - 5, 0, and + 5 dB in steady speech-weighted noise at 60 dB SPL and SRTs for numbers in speech-weighted steady and nonsteady ICRA noise were both obtained in conditions with and without the noise reduction pre-processing. Physical SNR improvements of the noise reduction system are evaluated as well, as a function <b>of</b> the <b>direction</b> <b>of</b> the noise source. RESULTS: Highly significant improvements in speech understanding, corresponding on average to an SNR improvement of about 10 dB, were observed with this 2 -channel adaptive filtering noise reduction strategy using both types of speech-noise test materials. These perceptual evaluations agree with physical evaluations and simulations of this noise reduction strategy. Taken together, these data demonstrate that cochlear implantees may increase their speech intelligibility in noisy environments with the use of multimicrophone noise reduction systems. status: publishe...|$|R
40|$|This article {{examines}} the changing relation between speech and writing in contemporary communications. Firstly, it considers the development, during the 20 th century, of new kinds of audio and audio-visual communication media [as at 1983]; such media, it argues, shifted the long-standing cultural pre-eminence of printed forms in the <b>direction</b> <b>of</b> recorded <b>speech.</b> Secondly, the article discusses academic conceptualisation of changes brought about by new communication technologies as a stage in social evolution that is likely, over time, to remodel literacy concerns as challenges presented by ‘secondary orality’ (Ong, 1982). The author argues that the mass speech community brought into being by contemporary ‘speech media’ needs to {{be understood in terms}} of specific discourse forms and related notions of cultural value, rather than by means of general observations about speech and writing. Educational priorities in relation to such new media, it is suggested, cut across the two most influential ways of describing their capabilities: insights offered by discourse analysis as regards differences between what is spoken and what is written, and general propositions based on anthropological and sociological studies of orality and literacy...|$|R
40|$|Two {{experiments}} {{investigated the}} effects of conflicting interaural time and level differences on the masked threshold <b>of</b> <b>speech.</b> Target sentences were prepared using manipulated HRTFs for azimuths of 0 ° and 60 °. Speech reception thresholds (SRTs) were measured against a masker with a 0 ° simulated azimuth, consisting of either Brown noise (− 6 dB/oct. spectral roll-off) or speech. Experiment 1 compared the advantage of spatial separation produced by differences between target and interferer in cues to their azimuth. The introduction of an interaural time delay (ITD) or interaural level difference (ILD) reduced SRTs by 3 – 4 dB, but their combined effect was about 6 dB. Experiment 2 compared the advantage of spatial separation produced by combined cues that indicated either the same or opposing hemi-fields for the target speech. The combined effects of these two cues were indistinguishable, even when they conflicted with each other regarding the <b>direction</b> <b>of</b> the target <b>speech.</b> These {{results suggest that the}} improvements in audibility gained from exploiting ILD and ITD are not constrained by a need to focus attention on a particular direction...|$|R
40|$|In this study, {{two types}} of hearing aids were used. Both aids had the same {{frequency}} characteristics for frontal sound, but one employed an omnidirectional microphone {{and the other a}} directional microphone. The frequency characteristics of both hearing aids were measured for five azimuths on KEMAR and in situ in 12 normal-hearing subjects. For these subjects we also determined the speech reception threshold (SRT) with background noise in two rooms with different reverberation times. The <b>direction</b> <b>of</b> the <b>speech</b> stimuli was always frontal; the <b>direction</b> <b>of</b> the noise was varied. Additionally, directional hearing was measured with short noise bursts from eight loudspeakers surrounding the subject. In the less reverberant room, sounds coming from behind were less amplified by the hearing aid with the directional microphone than by the one with the omnidirectional microphone. In this room the monaural SRT values were largely determined by the level of the background noise. For the directional hearing aids there was an extra binaural advantage which depended on the <b>direction</b> <b>of</b> the background noise. Only for low-frequency noise bursts was directional hearing better with directional hearing aids. In the more reverberant room, no distinct differences between the frequency characteristics of the two hearing aid types were measured. However, a systematic difference between monaural SRT values measured through the two hearing aids was found. This difference was independent of noise azimuth. In conclusion, hearing aid(s) with a directional microphone showed no disadvantages and clear advantages under specific condition...|$|R
40|$|A two {{microphone}} <b>direction</b> <b>of</b> arrival (DOA) {{estimation technique}} for multiple speech sources is developed which exploits speech specific properties, namely sparsity in time-frequency (spectrum) domain. For robustness, we exploit the sparsity {{in the frequency}} domain {{by focusing on the}} spectral content concentrated in sinusoidal tracks obtained through sinusoidal modeling. When multiple speeches are mixed in the two microphone system, the inter-channel phase differences (IPD) between the dual channels on those sinusoidal tracks will be dominated by the spatial information of the most powerful source at that specific time-frequency point because of the spectrum sparsity and masking effects. Thereby, the source localization problem is turned into a clustering problem on the IPD versus frequency plot, and the generalized mixture decomposition algorithm (GMDA) is used to cluster the groups of points corresponding to multiple sources. The DOA of each source is derived from the parameters of each cluster. Experimental results conducted show the scheme to be very effective. Index Terms — Two microphone system, <b>direction</b> <b>of</b> arrival estimation, <b>speech,</b> sparsity, sinusoidal modeling, generalized mixture decomposition algorithm 1...|$|R
40|$|This article {{discusses}} {{some aspects}} <b>of</b> the <b>speech</b> therapist in modern conditions, {{in accordance with}} the GEF. This issue is currently poorly understood and requires more complete and comprehensive analysis. We have attempted to highlight the main <b>directions</b> <b>of</b> the teacher-speech therapist, his professional competence and organization of subject-spatial environment <b>of</b> <b>speech</b> therapy cabinet...|$|R
40|$|The present work is {{an attempt}} in the <b>direction</b> <b>of</b> writing of {{computer}} programs for defining texts {{in the form of}} vector algebra and their basis so that pattern of occurrence <b>of</b> parts <b>of</b> <b>speech</b> could be modeled in the form of Markov Chain. Logic, flow and description of various important algorithms / functions used in the program and related snapshots for Modeling <b>of</b> Parts <b>of</b> <b>Speech</b> Patterns an...|$|R
40|$|The {{problem of}} reading and writing {{disorders}} in children with speech underdevelopment with dizartricheskim component. The methodology <b>of</b> the survey <b>speech</b> capabilities for this category <b>of</b> children. The <b>directions</b> <b>of</b> correctional and developmental work on the formation of intonational party <b>of</b> <b>speech</b> {{in order to prevent}} violations {{of reading and}} writing...|$|R
30|$|The output signals x(t) are the {{convolutions}} of 40 pairs <b>of</b> <b>speech</b> sources (male {{and female}} speaking French and English) {{by two of}} the impulse responses {h (l)} 0 ≤l≤Lmeasured for the <b>direction</b> <b>of</b> arrivals presented in Figure 11.|$|R
40|$|In his Assembly speech "On Organization", Demosthenes {{uses the}} Siphnians and Cythnians – {{inhabitants}} of small Cycladic island states – {{as a negative}} double example to impress upon his Athenian listeners the importance of sustaining their traditional spirit of geopolitical enterprise. The example has frequently been assimilated to the rhetoric of Athenian disdain for small or weak states, but this paper reassesses it in its speech context, suggesting that Demosthenes is instead specifically using the Siphnians and Cythnians as examples of states which once had the resources to become a presence {{on the international stage}} but had no drive {{to make the most of}} them; Athens – which does traditionally possess such a drive – must therefore change her priorities so as not to lose it. Furthermore, the example can be seen as responding and contributing to the thematic <b>directions</b> <b>of</b> the whole <b>speech,</b> and not only the immediate argument...|$|R
40|$|This paper {{describes}} {{principles for}} the design of interactive pronunciation exercises using the EC-ISLE system with highly accentuated learner speech. The paper “Pronunciation Teaching: Requirements and Solutions ” outlined the exercise-types specified as desirable in previous userstudies. This paper is primarily concerned with measuring which of these exercise-types are really viable given the state-of-the art in recognition. Conclusions are drawn from a series of recognition experiments using a non-native corpus of Italian and German learners of English and Entropic’s HMM-based speech API (HAPI 2. 0). The factors examined include 1. Recognition task perplexity and its effect on recognition accuracy. 2. The effect of mother tongue and proficiency on recognition accuracy. 3. The effect of a mismatch in acoustic modelling between the target British English HMMs and highly accentuated incoming speech. 4. The effect of speaker adaptation techniques to transform the native acoustic models in the <b>direction</b> <b>of</b> the accented <b>speech.</b> This report is for public distribution. The target reader is anyone interested in using automati...|$|R
5000|$|... the Liberals were {{traditionally}} the party <b>of</b> freedom <b>of</b> <b>speech,</b> conscience and trade. They were against jingoism, heavy armaments and compulsion....Liberals were neither wholehearted nor unanimous about conscription, censorship, the Defence of the Realm Act, severity toward aliens and pacifists, <b>direction</b> <b>of</b> labour and industry. The Conservatives... {{had no such}} misgivings.|$|R
40|$|Wherever {{there exists}} {{a high degree of}} civilisation,with its {{complexity}} of social and political organisations and its necessary concomitant, freedom <b>of</b> <b>speech,</b> we find the literature developing in the <b>direction</b> <b>of</b> satire, and the literature of satire occupies a very interesting chapter in the intellectual and literary history of every nation. [ [...] . ...|$|R
500|$|... the Liberals were {{traditionally}} the party <b>of</b> freedom <b>of</b> <b>speech,</b> conscience and trade. [...] They were against jingoism, heavy armaments and compulsion....Liberals were neither wholehearted nor unanimous about conscription, censorship, [...] the Defence of the Realm Act, severity toward aliens and pacifists, <b>direction</b> <b>of</b> labour and industry. [...] The Conservatives... {{had no such}} misgivings.|$|R
40|$|The list <b>of</b> <b>speeches,</b> {{articles}} and reports (p. 5 - 13) is reprinted from "List of references {{on the popular}} election of senators, with appendix [...] . compiled under the <b>direction</b> <b>of</b> A. P. C. Griffin, chief bibliographer [Library of Congress]," Washington, Govt. Print. Off., 1904. Submitted by Mr. Borah. Ordered printed Jan. 11, 1911. Mode of access: Internet...|$|R
