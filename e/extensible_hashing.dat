10|3|Public
50|$|November 2014: OrangeFS 2.9.0 {{released}} adding {{support for}} distributed metadata for directory entries using an <b>extensible</b> <b>hashing</b> algorithm modeled after giga+, posix backward compatible capability base security supporting multiple modes.|$|E
5000|$|Each edition has {{separate}} database libraries, {{despite the}} common branding. The {{first is the}} traditional Berkeley DB, written in C. It contains several database implementations, including a B-tree and one built around <b>extensible</b> <b>hashing.</b> It supports multiple language bindings, including C/C++, Java (via JNI), C# [...]NET, Perl and Python.|$|E
40|$|The {{problem of}} {{efficient}} data structures for IP lookups {{has been well}} studied in literature. Techniques such as LC tries and <b>Extensible</b> <b>Hashing</b> are commonly used. In this paper, we {{address the problem of}} generalizing LC tries and <b>Extensible</b> <b>Hashing,</b> based on traces of past lookups, to provide performance guarantees for memory sub-optimal structures. As a specific example, if a memory-optimal (LC) trie takes 6 MB and the total memory at the router is 8 MB, how should the trie be modified to make best use of the 2 MB of excess memory? We present a greedy algorithm for this problem and prove that, if for the optimal data structure there are b fewer memory accesses on average for each lookup compared with the original trie, the solution produced by the greedy algorithm will have 22 fewer memory accesses on average (compared to the original trie). An efficient implementation of this algorithm presents significant additional challenges. We describe an implementation with a time complexity of O(#(d) n log n) and a space complexity of O(n), where n is the number of nodes of the trie and d its depth. The depth of a trie is fixed for a given version of the Internet protocol and is typically O(log n). Inthiscase,#(d) =O(log n). We demonstrate experimentally the performance and scalability of the algorithm on actual routing data. We also show that our algorithm significantly outperforms <b>Extensible</b> <b>Hashing</b> for the same amount of memory...|$|E
40|$|We {{present the}} first lock-free {{implementation}} of an <b>extensible</b> <b>hash</b> table running on current architectures. Our algorithm provides concurrent insert, delete, and search operations with an expected O(1) cost. It consists of very simple code, easily implementable using only load, store, and compare-and-swap operations. The new mathematical structure {{at the core}} of our algorithm is recursive split-ordering, a way of ordering elements in a linked list {{so that they can be}} repeatedly “split ” using a single compare-and-swap operation. Though lock-free algorithms are expected to work best in multiprogrammed environments, empirical tests we conducted on a large shared memory multiprocessor show that even in non-multiprogrammed environments, the new algorithm performs as well as the most efficient known lock-based resizable hash-table algorithm, and in high load cases it significantly outperforms it...|$|R
40|$|Abstract. We {{present the}} first lock-free {{implementation}} of an <b>extensible</b> <b>hash</b> table running on current architectures. Our algorithm provides concurrent insert, delete, and find operations with an expected O(1) cost. It consists of very simple code, easily implementable using only load, store, and compareand-swap operations. The new mathematical structure {{at the core}} of our algorithm is recursive splitordering, a way of ordering elements in a linked list {{so that they can be}} repeatedly “split ” using a single compare-and-swap operation. Metaphorically speaking, our algorithm differs from prior known algorithms in that extensibility is derived by “moving the buckets among the items ” rather than “the items among the buckets. ” Though lock-free algorithms are expected to work best in multiprogrammed environments, empirical tests we conducted on a large shared memory multiprocessor show that even in non-multiprogrammed environments, the new algorithm performs as well as the most efficient known lock-based resizable hash-table algorithm, and in high load cases it significantly outperforms it...|$|R
40|$|This paper {{describes}} a generic algorithm for concurrent resizing and on-demand per-bucket rehashing for an <b>extensible</b> <b>hash</b> table. In contrast to known lock-based hash table algorithms, the proposed algorithm separates the resizing and rehashing stages {{so that they}} neither invalidate existing buckets nor block any concurrent operations. Instead, the rehashing work is deferred and split across subsequent operations with the table. The rehashing operation uses bucket-level synchronization only and therefore allows a race condition between lookup and moving operations running in different threads. Instead of using explicit synchronization, the algorithm detects the race condition and restarts the lookup operation. In comparison with other lock-based algorithms, the proposed algorithm reduces high-level synchronization on the hot path, improving performance, concurrency, and scalability of the table. The response time of the operations is also more predictable. The algorithm is compatible with cache friendly data layouts for buckets and {{does not depend on}} any memory reclamation techniques thus potentially achieving additional performance gain with corresponding implementations. Comment: The author is one of core developers of Intel Threading Building Blocks (TBB) and the algorithm discussed in the paper is implemented as tbb::concurrent_hash_map since TBB version 2. 2. The paper compares it with tbb::concurrent_hash_map implementation available in TBB 2. 1. This paper was written in 2011 for the last of 3 attempts to be accepted for a conference (PPoPP 10, PPoPP 11, and SPAA 11...|$|R
40|$|Abstract — The {{problem of}} {{efficient}} data structures for IP lookups {{has been well}} studied in literature. Techniques such as LC tries and <b>Extensible</b> <b>Hashing</b> are commonly used. In this paper, we {{address the problem of}} generalizing LC tries and <b>Extensible</b> <b>Hashing,</b> based on traces of past lookups, to provide performance guarantees for memory sub-optimal structures. As a specific example, if a memory-optimal (LC) trie takes 6 MB and the total memory at the router is 8 MB, how should the trie be modified to make best use of the 2 MB of excess memory? We present a greedy algorithm for this problem and prove that, if for the optimal data structure ¢ there are fewer memory accesses on average for each lookup compared with the original trie, the solution produced by the greedy algorithm £¥¤§ ¦ ¨© ¨ will have fewer memory accesses on average (compared to the original trie). An efficient implementation of this algorithm presents significant additional challenges. We describe an implementation with a time �����§������������������ � complexity of and a space ������ � complexity of, where is the number of nodes of the trie � and its depth. The depth of a trie is fixed for a given version of the ¨ Internet protocol and ������������ � is typically. In �§���������������� � �� � this case,. We demonstrate experimentally the performance and scalability of the algorithm on actual routing data. We also show that our algorithm significantly outperforms <b>Extensible</b> <b>Hashing</b> for the same amount of memory. I...|$|E
40|$|Recently, {{the issues}} of how to define {{functional}} dependencies (XFDs) and multivalued dependencies (XMVDs) in XML have been investigated. In this paper we consider the problem of checking the satisfaction {{of a set of}} XMVDs in an XML document. We present an algorithm using <b>extensible</b> <b>hashing</b> to check whether an XML document satisfies a given set of XMVDs. The performance of the algorithm is shown to be linear in relation to the "tuple size" of the XML document, a measure which is related to, but not the same as, the size of the XML document. We then propose a method to estimate the "tuple size" of an XML document. We als...|$|E
40|$|This paper {{describes}} RIME (Replicated IMage dEtector), {{an alternative}} approach to watermarking for detecting unauthorized image copying on the Internet. RIME profiles internet images and stores the feature vectors of the images and their URLs in its repository. When a copy detection request is received, RIME matches the requested image's feature vector with the vectors stored in the repository and returns a list of suspect URLs. RIME characterizes each image using Daubechies' wavelets. The wavelet coefficients are stored as the feature vector. RIME uses a multidimensional <b>extensible</b> <b>hashing</b> scheme to index these high-dimensional feature vectors. Our preliminary result shows that it can detect image copies effectively: It can find the top suspects and copes well with image format conversion, resampling, and requantization. Keywords: copy detection, wavelets, multidimensional indexes 1. INTRODUCTION Advancement in the internet and world-wide web technology {{has led to the}} growth of inf [...] ...|$|E
40|$|Abstract — Linear Hashing is {{a widely}} used and {{efficient}} version of <b>extensible</b> <b>hashing.</b> A distributed version of Linear Hashing is LH ∗ that stores key-indexed records on up {{to hundreds of thousands}} of sites in a distributed system. LH∗ implements the dictionary data structure efficiently since it does not use a central component for the key-based operations of insertion, deletion, actualization, and retrieval and for the scan operation. LH ∗ allows a client or a server to commit an addressing error by sending a request to the wrong server. In this case, the server forwards to the correct server directly or in one more forward operation. We discuss here methods to avoid the double forward, which is rare but might breach quality of service guarantees. We compare our methods with LH ∗ P 2 P that pushes information about changes in the file structure to clients, whether they are active or not...|$|E
40|$|The dbm {{database}} library [1] introduced disk-based <b>extensible</b> <b>hashing</b> to UNIX. The library {{consists of}} functions {{to use a}} simple database consisting of key/value pairs. A number of work-alikes have been developed, offering additional features [5] and free source code [14, 25]. Recently, a new package was developed that also offers improved performance [19]. None of these implementations, however, provide fault-tolerant behaviour. In many applications, a single high-level operation may cause many database items to be updated, created, or deleted. If the application crashes while processing the operation, the database could be left in an inconsistent state. Current versions of dbm do not handle this problem. Existing dbm implementations do not support concurrent access, even though the use of lightweight processes in a UNIX environment is growing. To address these deficiencies, tdbm was developed. Tdbm is a transaction processing database with a dbmlike interface. It provides nested atomic transactions, volatile and persistent databases, and support for very large objects and distributed operation. This paper describes the design and implementation of tdbm and examines its performance. 1...|$|E
40|$|This paper {{presents}} {{the design of}} a non-hierarchical network architecture, an alternative Internet structure to suit the upcoming trends of the Internet use. Such trends include the booming of mobile and wireless devices, the diversification of their functions, the customization of the Internet domain names, and the long-needed consistency of the global Internet management. To satisfy these needs, the non-hierarchical network design leverages on (i) location transparency, to free devices from their location affiliation and constraints, (ii) structure simplicity, to reduce the network hierarchy to the core components, and (iii) direct routing, to streamline the data traffic for the mobile and wireless devices. The primary phase of the network design implements a centralized server to handle all the Internet domain name queries, and the secondary phase applies the distributed system based on the central server scheme, making the design more practical and feasible. Some detailed implementations of the non-hierarchical structure, including the use of <b>extensible</b> <b>hashing</b> in the centralized domain name system and the installation of a network topology to the local data server, are discussed in details. Two examples, ping and electronic mail, following the design issues, are given to illustrate the mechanism of the non-hierarchical architecture. 1...|$|E
40|$|Databases as a Service (DaaS) are {{recently}} in the spotlight as {{an essential component of}} the cloud computing framework. We can more easily develop applications to facilitate users ' collaboration than without DaaS. Unfortunately, DaaS brings a new risk of data compromise because most data are currently stored and managed by the service provider. Securing users ' information, the data are generally encrypted at a trusted client. Although encryption ensures that no one can sneak a look at the data, malicious users still have opportunities to take users ' relational information. The relational information, which we name social information as opposed to personal information, has not been adequately examined, but it is becoming important because of improvement of social analysis. As described herein, we rst introduce an attack model of obtaining social information from analyses of query logs in DaaS; then we provide a solution to the problem. Our method converts some di erent queries in the same query, so that malicious attackers cannnot analyze the query logs. We also de ne an overhead cost of the translation and propose a method that can optimize the conversion using <b>extensible</b> <b>hashing.</b> 1...|$|E

