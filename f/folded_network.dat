1|161|Public
40|$|Hierarchical {{interconnection}} networks provide {{high performance}} at low cost by exploring the locality {{that exists in}} the communication patterns of massively parallel computers. A Symmetric Tori connected Torus Network (STTN) is a 2 D-torus network of multiple basic modules, in which the basic modules are 2 D-torus networks that are hierarchically interconnected for higher-level networks. We also fold the STTN to minimize the length of the longest wire of STTN. The <b>folded</b> <b>network</b> is called Folded Tori connected Torus Network (FTTN). In this paper, we present the architecture of the STTN and FTTN, addressing of node, routing of message, and evaluate the static network performance of STTN, FTTN, TTN, TESH, mesh, and torus networks. It is shown that both the STTN and FTTN possess several attractive features, including constant node degree, small diameter, low cost, small average distance, moderate bisection width, and high fault tolerant performance than that of other conventional and hierarchical interconnection networks. We further evaluate the longest wire length of FTTN and compare it with other networks. We found that the longest wire length of the FTTN is far lower than that of other networks considered in this paper while keeping good static network performance. It is just about (1 / 2 m th) of its rival STTN. </p...|$|E
40|$|The {{information}} theoretical learnability of <b>folding</b> <b>networks,</b> a {{very successful}} approach capable of dealing with tree structured inputs, is examined. We find bounds on the VC, pseudo-, and fat shattering dimension of <b>folding</b> <b>networks</b> with various activation functions. As a consequence, valid generalization of <b>folding</b> <b>networks</b> can be guaranteed. However, distribution independent bounds on the generalization error cannot exist in principle. We propose two approaches which take the specific distribution into account and allow us to derive explicit bounds on the deviation of the empirical error from the real error of a learning algorithm: The first approach requires the probability of large trees to be limited a priori, the second approach deals with situations where the maximum input height in a concrete learning example is restricted...|$|R
30|$|While weak {{ties and}} closure are {{building}} blocks of small world structures, forbidden triads are {{building blocks of}} <b>fold</b> <b>networks.</b> <b>Fold</b> <b>networks</b> {{have been identified as}} predictors of the generation of novelty, where overlapping cohesive communities contribute to both the recognition of a novel possibility, and the realization of the novel idea as a product (de Vaan et al., 2015). It was also demonstrated {{that it is not the}} agency at the overlap of communities that matters, but the successful mobilization of the non-intersecting unique part of overlapping communities, and overlapping communities have also been shown to be more unstable than non-overlapping communities (Vedres and Stark 2010). <b>Fold</b> <b>networks</b> operate by a generative tension: They provoke the generation of novelty, but also contribute to coordination and loyalty conflicts.|$|R
40|$|Protein folding is {{a complex}} multidimensional process that is {{difficult}} to illustrate by the traditional analyses based on one- or two-dimensional profiles. Analyses based on transition networks have become an alternative approach that has the potential to reveal detailed features of protein folding dynamics. However, {{due to the lack of}} successful reversible folding of proteins from conventional molecular-dynamics simulations, this approach has rarely been utilized. Here, we analyzed the <b>folding</b> <b>network</b> from several 10 μs conventional molecular-dynamics reversible folding trajectories of villin headpiece subdomain (HP 35). The <b>folding</b> <b>network</b> revealed more complexity than the traditional two-dimensional map and demonstrated a variety of conformations in the unfolded state, intermediate states, and the native state. Of note, deep enthalpic traps at the unfolded state were observed on the folding landscape. Furthermore, in contrast to the clear separation of the native state and the primary intermediate state shown on the two-dimensional map, the two states were mingled on the <b>folding</b> <b>network,</b> and prevalent interstate transitions were observed between these two states. A more complete picture of the folding mechanism of HP 35 emerged when the traditional and network analyses were considered together...|$|R
40|$|This thesis {{examines}} so-called <b>folding</b> neural <b>networks</b> as {{a mechanism}} for machine learning. <b>Folding</b> <b>networks</b> form a generalization of partial recurrent neural networks such {{that they are able}} to deal with tree structured inputs instead of simple linear lists. In particular, they can handle classical formulas [...] they were proposed originally for this purpose. After a short explanation of the neural architecture we show that <b>folding</b> <b>networks</b> are well suited as a learning mechanism in principle. This includes three parts: the proof of their universal approximation ability, the aspect of information theoretical learnability, and the examination of the complexity of training. Approximation ability: It is shown that any measurable function can be approximated in probability. Explicit bounds on the number of neurons result if only a finite number of points is dealt with. These bounds are new results in the case of simple recurrent networks, too. Several restrictions occur if a function is [...] ...|$|R
40|$|We {{establish}} some general results concerning PAC learning: We find a {{characterization of the}} property, that any consistent algorithm is PAC. It is shown that the shrinking width property is equivalent to PUAC learnability. By counterexample PAC and PUAC learning are shown to be different concepts. We find conditions ensuring that any nearly consistent algorithm is PAC resp. PUAC. The VC dimension of recurrent neural <b>networks</b> and <b>folding</b> <b>networks</b> is infinite. For restricted inputs, bounds exist. The upper bound {{in the case of}} recurrent perceptron networks is improved and the upper and lower bounds for restricted inputs are transferred to <b>folding</b> <b>networks.</b> We find conditions on the probability of the input space ensuring polynomial learnability: The probability of sequences resp. trees have to converge with increasing length resp. height to 0 sufficiently fast. Finally, we find an example for a concept class that requires exponentially growing sample size for accurate generalization...|$|R
40|$|The folding energy {{landscape}} of proteins {{has been suggested}} to be funnel-like {{with some degree of}} ruggedness on the slope. How complex the landscape, however, is still rather unclear. Many experiments for globular proteins suggested relative simplicity, whereas molecular simulations of shorter peptides implied more complexity. Here, by using complete conformational sampling of 2 globular proteins, protein G and src SH 3 domain and 2 related random peptides, we investigated their energy landscapes, topological properties of <b>folding</b> <b>networks,</b> and <b>folding</b> dynamics. The projected energy surfaces of globular proteins were funneled {{in the vicinity of the}} native but also have other quite deep, accessible minima, whereas the randomized peptides have many local basins, including some leading to seriously misfolded forms. Dynamics in the denatured part of the network exhibited basin-hopping itinerancy among many conformations, whereas the protein reached relatively well-defined final stages that led to their native states. We also found that the <b>folding</b> <b>network</b> has the hierarchic nature characterized by the scale-free and the small-world properties...|$|R
40|$|Let G be {{a simple}} graph with n {{vertices}} and let λ 1,λ 2,…,λn be the eigenvalues of its adjacency matrix; the Estrada index EEG of the graph G {{is defined as the}} sum of the terms eλi,[*][*]i= 1, 2,…,n. The n-dimensional <b>folded</b> hypercube <b>networks</b> FQn are an important and attractive variant of the n-dimensional hypercube networks Qn, which are obtained from Qn by adding an edge between any pair of vertices complementary edges. In this paper, we establish the explicit formulae for calculating the Estrada index of the <b>folded</b> hypercubes <b>networks</b> FQn by deducing the characteristic polynomial of the adjacency matrix in spectral graph theory. Moreover, some lower and upper bounds for the Estrada index of the <b>folded</b> hypercubes <b>networks</b> FQn are proposed...|$|R
40|$|<b>Network</b> <b>folding</b> is a {{technique}} for realizing permutations on N elements using interconnection networks with M input (and output) terminals, where M<N. A major motivation for <b>network</b> <b>folding</b> is the severely limited number of I/O pins in microelectronic packages such as VLSI chips or multichip module (MCM) packages. Cost overhead and performance degradationdue to off chip communication as well as long on chip wires may render implementing otherwise good designs infeasible or inefficient and systematic methodology is proposed for designing <b>folded</b> permutation <b>networks</b> that can be route the class of bit-permute-complement (BPC) permutations. In particulaer, is is shown that any <b>folded</b> BPC permutation <b>network</b> can be contructed using only two stages of uniform-size transpose networks. This results in highly modular structures for bpc networks. The methodology trades off speed (time), with I/O and chip area...|$|R
40|$|Abstract. In {{this paper}} we show several {{approximation}} results for <b>folding</b> <b>networks</b> { a generalization of partial recurrent neural networks such {{that not only}} time sequences but arbitrary trees can serve as input: Any measurable function can be approximated in probability. Any continuous function can be approximated in the maximum norm on inputs with restricted height, but the resources necessarily increase at least exponentially in the input height. In general, approximation on arbitrary inputs is not possible in the maximum norm. 1...|$|R
40|$|During {{the last}} years, <b>folding</b> {{architecture}} <b>networks</b> and the closely related concept of recursive neural networks {{have been developed}} for solving supervised learning tasks on data structures. In this paper we address the fundamental problem of finding fixedlength vector representations for structures in an unsupervised way. A solution based on ideas from feature extraction and <b>folding</b> architecture <b>networks</b> is proposed. Furthermore, a new method for supervised learning for data structures which combines ideas from learning vector quantization and <b>folding</b> architecture <b>networks</b> is suggested. 1 Introduction In almost all fields of scientific and technical reasoning, people and systems assisting them have to deal with structured objects. Examples are chemical structures, algebraic (mathematical) expressions and formulas, software source code, and conceptual and taxonomic graphs. With structured objects we mean objects which are composed of `smaller' objects, which may be structured too. T [...] ...|$|R
30|$|While the {{overlapping}} of communities provides a clear mechanism for realizable novelty, the empirical operationalization of <b>fold</b> <b>networks</b> {{has so far}} been cumbersome. One needs to identify communities first, and especially communities that overlap to measure <b>network</b> <b>folding.</b> Previous studies have used the number of community memberships of a given node (Vedres and Stark 2010), or the number of subgroup overlaps within a larger collective (De Vaan et al. 2015). But community detection is far from being a universal and simple process: The large number of community detection algorithms is a symptom of the complex nature of mapping the community concept (especially with overlaps allowed) onto sets of nodes in a network (Granell et al. 2015; Xie et al., 2013).|$|R
30|$|Instrumental {{innovation}} is another possible alternative explanation: the session is successful {{not because of}} a <b>fold</b> <b>network</b> dynamic, but because forbidden triads are a proxy for experimenting with a new instrument combination: Bringing in a new musician is really about bringing in a new instrument. Thus I entered distinctiveness: the average cosine distance of the instrument combination vector of the session (in {{the space of the}} top 200 most frequent instruments) to all other sessions over the preceding 5 years (t- 1 to t- 5).|$|R
40|$|The {{ambiguous}} restraint for iterative assignment (ARIA) {{approach for}} NMR structure calculation is evaluated for symmetric homodimeric proteins by assessing {{the effect of}} several data analysis and assignment methods on the structure quality. In particular, we {{study the effects of}} network anchoring and spin-diffusion correction. The spin-diffusion correction improves the protein structure quality systematically, whereas network anchoring enhances the assignment efficiency by speeding up the convergence and coping with highly ambiguous data. For some homodimeric <b>folds,</b> <b>network</b> anchoring has been proved essential for unraveling both chain and proton assignment ambiguities...|$|R
40|$|One of {{the major}} {{problems}} in theorem proving is control of the proof search. A promising approach is the application of machine learning techniques for the acquisition of search control knowledge by learning from successful proof searches. In this paper we briefly discuss this idea and existing machine learning techniques for this task. We suggest neural <b>folding</b> architecture <b>networks</b> together with supervised training algorithms as a very promising candidate for learning search control knowledge. This suggestion is based on two sets of experiments in which we applied <b>folding</b> architecture <b>networks</b> to term ordering problems and clause classification tasks resulting from the proof search of the equational theorem prover DISCOUNT...|$|R
40|$|We {{employed}} the single replica multiple state transition interface sampling (MSTIS) approach {{to sample the}} kinetic (un) <b>folding</b> <b>network</b> of Trp-cage mini-protein in explicit water. Cluster analysis yielded 14 important metastable states in the network. The MSTIS simulation thus resulted in a full 14 x 14 rate matrix. Analysis of the kinetic rate matrix indicates {{the presence of a}} near native intermediate state characterized by a fully formed alpha helix, a slightly disordered proline tail, a broken salt-bridge, and a rotated arginine residue. This intermediate was also found in recent IR experiments. Moreover, the predicted rate constants and timescales are in agreement with previous experiments and simulations...|$|R
50|$|On May 7, 2001, {{the station}} {{formed the basis}} for CHUM's {{short-lived}} national sports radio network The Team, which adopted the Ottawa station's brand identity. The station retained its format and brand when CHUM subsequently <b>folded</b> the <b>network.</b>|$|R
40|$|Many {{research}} on the <b>folded</b> Petersen cube <b>networks</b> have been published {{during the past several}} years due to its favorite properties. In this paper, we consider the ring and path embedding in faulty <b>folded</b> Petersen cube <b>networks.</b> We use FPQn,k to denote the <b>folded</b> Petersen cube <b>networks</b> of parameters n and k. In this paper, we show that FPQn,k − F remains hamiltonian for any F ⊆ V (FPQn,k) ∪ E(FPQn,k) with |F | ≤ n + 3 k − 2 and FPQn,k − F remains hamiltonian connected for any F ⊆ V (FPQn,k) ∪ E(FPQn,k) with |F |≤n+ 3 k− 3 if (n, k) / ∈ {(0, 1) }∪{(n, 0) | n is a positive integer}. Moreover, this result is optimal...|$|R
40|$|This paper {{deals with}} the {{connection}} of symbolic and subsymbolic systems. It focuses on connectionistic systems processing symbolic data. We examine the capability of learning symbolic data with various neural architectures which constitute partially dynamic approaches: discrete time partially recurrent neural networks as a simple and well established model for processing sequences, and advanced generalizations like holographic reduced representation, recursive autoassociative memory, and <b>folding</b> <b>networks</b> for processing tree structured data. The methods share the basic dynamics, but they differ in the specific training methods. We consider the following questions: Which are the representational capabilities of the architectures from an algorithmic point of view? Which are the representational capabilities from a statistical point of view? Are the architectures learnable in an appropriate sense? Are they efficiently learnable...|$|R
40|$|We {{consider}} recurrent {{neural networks}} which deal with symbolic formulas, terms, or, generally speaking, tree-structured data. Approaches like the recursive autoassociative memory, discrete-time recurrent <b>networks,</b> <b>folding</b> <b>networks,</b> tensor construction, holographic reduced representations, and recursive reduced descriptions {{fall into this}} category. They share the basic dynamics of how structured data are processed: the approaches recursively encode symbolic data into a connectionistic representation or decode symbolic data from a connectionistic representation {{by means of a}} simple neural function. In this paper, we give an overview of the ability of neural networks with these dynamics to encode and decode tree-structured symbolic data. The correlated tasks, approximating and learning mappings where the input domain or the output domain may consist of structured symbolic data, are examined as well...|$|R
50|$|Beginning in 2007, Pancrase: Legends of Mixed Martial Arts aired weekly on ImaginAsian TV. The <b>network</b> <b>folded</b> in 2011.|$|R
30|$|I am {{interested}} in relating the presence of three kinds of triads to levels of success. The first kind of triad is a building block of <b>fold</b> <b>networks,</b> the forbidden triad: a triad with two strong ties, and one absent tie. The second kind of triad is an open triad: two weak ties and one absent tie. The third kind of triad is closure: all three ties are present (of any strength). To measure {{the presence of these}} triad types I categorically delimit forbidden triads from open triads by a threshold tie strength value, and then count the number of three mutually exclusive triad types (forbidden triads, open triads, and closed triads). I then normalize the number of triads by the number of connected triads (with at least two ties present).|$|R
40|$|In {{the modern}} {{technology}} of communication architecture, network on chip {{is widely used}} as communication architecture. Network on chip topologies are becoming a backbone of communication architectures. Network on chip provides a good integration of huge amount of storage on chip blocks as well as computational also. Network on chip handled the unfavorable conditions and it provides the scalability to the architecture. Mesh and folded torus architectures are most commonly used architecture for network on chip communication. Here, we compare the performance of Mesh and <b>Folded</b> torus <b>network</b> architecture on chip, {{on the basis of}} different parameters under broadcasting with the help of distance vector routing algorithm. To evaluate the performance of Mesh and <b>folded</b> torus <b>network</b> on chip in the simulation environment, we use the network simulator (NS- 2) in the Linux platform...|$|R
50|$|Before the United <b>Network</b> <b>folded,</b> 23 {{episodes of}} The Las Vegas Show had aired. Two {{additional}} episodes remained unaired when network operations shut down.|$|R
5000|$|The {{station was}} {{originally}} {{an affiliate of}} LAT TV, a Houston-based Spanish-language television network that launched in May 2006; however, the <b>network</b> <b>folded</b> 2 years later.|$|R
5000|$|The {{company went}} public in 1996and soon {{afterwards}} attempted to acquire PGP Inc.; it was instead acquired in 1998 by Network Associates (NAI), which later became McAfee, who had already bought PGP Inc. in 1997. The security research organization became NAI Labs and the Gauntlet engineering and development organization was <b>folded</b> into <b>Network</b> Associates' engineering and development.|$|R
40|$|Molecular chaperones of the Hsp 70 family form an {{important}} hub in the cellular protein <b>folding</b> <b>networks</b> in bacteria and eukaryotes, connecting translation with the downstream machineries of protein folding and degradation. The Hsp 70 folding cycle {{is driven by}} two types of cochaperones: J-domain proteins stimulate ATP hydrolysis by Hsp 70, while nucleotide exchange factors (NEFs) promote replacement of Hsp 70 -bound ADP with ATP. Bacteria and organelles of bacterial origin have only one known NEF type for Hsp 70, GrpE. In contrast, a large diversity of Hsp 70 NEFs has been discovered in the eukaryotic cell. These NEFs belong to the Hsp 110 /Grp 170, HspBP 1 /Sil 1 and BAG domain protein families. In this short review we compare the structures and molecular mechanisms of nucleotide exchange factors for Hsp 70 and discuss how these cochaperones contribute to protein folding and quality control in the cell...|$|R
40|$|One of {{the major}} {{problems}} in theorem proving is the control of proof search. A promising approach is the application of machine learning techniques for the acquisition of search control knowledge by learning from successful proof searches. In this paper we shortly discuss this idea and existing machine learning techniques for this task. We then suggest <b>folding</b> architecture <b>networks</b> trained with the back-propagation through structure algorithm as a very promising candidate. This suggestion {{is based on a}} couple of experiments in which we applied <b>folding</b> architecture <b>networks</b> to term ordering problems and clause classification tasks resulting from the proof search of the equational theorem prover DISCOUNT. 1 Introduction Currently, automated theorem provers (ATP systems) and similar deductive systems are being introduced into more and more application areas, like e. g. deductive databases, verification problems, or truth maintenance systems. However, the power of current systems is often [...] ...|$|R
50|$|The Overmyer Network debuted as the United Network on May 1, 1967. Unfortunately, the <b>network</b> <b>folded</b> {{one month}} later and Treyz's {{chance to make a}} {{comeback}} also failed.|$|R
40|$|Recent {{experiments}} {{uncovered a}} mutational pathway between two proteins, along which a single mutation causes a switch in fold. Searching for such paths between real proteins remains, despite this achievement, a true challenge. Here, we analyze fold switching in the minimalistic hydrophobic/polar model on a square lattice. For this analysis, we generate a comprehensive sequence-structure database for chains of length ≤ 30, which exceeds previous work by five units. Single-mutation-induced fold switching {{turns out to}} be quite common in the model. The switches define a <b>fold</b> <b>network,</b> whose topology is roughly similar to what one would expect for a set of randomly connected nodes. In the combinatorially challenging search for fold switches between two proteins, a tempting strategy is to only consider paths containing the minimum number of mutations. Such a restricted search fails to correctly identify 40 % of the single-mutation-linked fold pairs that we observe. The thermodynamic stability is correlated with mutational stability and is, on average, markedly reduced at the observed fold switches...|$|R
40|$|SummaryThe {{mammalian}} {{endoplasmic reticulum}} (ER) contains a diverse oxidative protein <b>folding</b> <b>network</b> in which ERp 46, {{a member of}} the protein disulfide isomerase (PDI) family, serves as an efficient disulfide bond introducer together with Peroxiredoxin- 4 (Prx 4). We revealed a radically different molecular architecture of ERp 46, in which the N-terminal two thioredoxin (Trx) domains with positively charged patches near their peptide-binding site and the C-terminal Trx are linked by unusually long loops and arranged extendedly, forming an opened V-shape. Whereas PDI catalyzes native disulfide bond formation by the cooperative action of two mutually facing redox-active sites on folding intermediates bound to the central cleft, ERp 46 Trx domains are separated, act independently, and engage in rapid but promiscuous disulfide bond formation during early oxidative protein folding. Thus, multiple PDI family members likely contribute to different stages of oxidative folding and work cooperatively to ensure the efficient production of multi-disulfide proteins in the ER...|$|R
40|$|By {{constructing}} the <b>fold</b> similarity <b>network</b> (FSN), we present {{an alternative approach}} to the characteristic and architecture of protein fold space. The degree distribution P(k) of FSN differs far {{from that of the}} random network with the same number of nodes and connections. The investigation shows that FSN possesses small-world property and broad-scale feature. In order to access to the assumption of the dynamics behavior for FSN, we design a simple evolutionary dynamics model based on the duplication and variation fashions of protein <b>folds.</b> The simulation <b>network</b> generated by this model is a small-world one and reproduces the broad-scale degree distribution consistent with that of FSN. It seems that this model can be used to depict the divergent evolution and expanding progress of protein fold space. Copyright EDP Sciences/Società Italiana di Fisica/Springer-Verlag 2006...|$|R
50|$|From June 2007 to May 2008, {{this station}} {{affiliated}} with LAT TV, a Spanish-language network. Since that <b>network</b> <b>folded</b> and until its affiliation with SBN, {{it is unknown}} what programming that station offered.|$|R
5000|$|Two hundred {{stations}} were {{needed for the}} network to break even. However, only [...] "about 100 stations" [...] joined, and the <b>network</b> <b>folded</b> {{at the end of}} its schedule on January 31, 1951.|$|R
40|$|The {{classical}} {{approach to}} protein folding inspired by statistical mechanics avoids the high dimensional {{structure of the}} conformation space by using effective coordinates. Here we introduce a network approach to capture the statistical properties {{of the structure of}} conformation spaces. Conformations are represented as nodes of the network, while links are transitions via elementary rotations around a chemical bond. Self-avoidance of a polypeptide chain introduces degree correlations in the conformation network, which in turn lead to energy landscape correlations. Folding can be interpreted as a biased random walk on the conformation network. We show that the folding pathways along energy gradients organize themselves into scale free networks, thus explaining previous observations made via molecular dynamics simulations. We also show that these energy landscape correlations are essential for recovering the observed connectivity exponent, which belongs to a different universality class than that of random energy models. In addition, we predict that the exponent and therefore the structure of the <b>folding</b> <b>network</b> fundamentally changes at high temperatures, as verified by our simulations on the AK peptide. 1...|$|R
40|$|The {{hypothesis}} that folding robustness {{is the primary}} determinant of the evolution rate of proteins is explored using a coarse-grained off-lattice model. The simplicity of the model allows rapid computation of the folding probability of a sequence to any folded conformation. For each robust folder, the network of sequences that share its native structure is identified. The fitness of a sequence is postulated to be a simple function {{of the number of}} misfolded molecules that have to be produced to reach a characteristic protein abundance. After fixation probabilities of mutants are computed under a simple population dynamics model, a Markov chain on the <b>fold</b> <b>network</b> is constructed, and the fold-averaged evolution rate is computed. The distribution of the logarithm of the evolution rates across distinct networks exhibits a peak with a long tail on the low rate side and resembles the universal empirical distribution of the evolutionary rates more closely than either distribution resembles the log-normal distribution. The results suggest that the universal distribution of the evolutionary rates of protein-coding genes is a direct consequence of the basic physics of protein folding...|$|R
