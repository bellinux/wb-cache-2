0|10000|Public
3000|$|In a {{previous}} study [18], we showed that <b>the</b> <b>NMF</b> components promise a higher representation and localization property {{compared to the other}} MD techniques. Therefore, <b>the</b> features extracted <b>from</b> <b>the</b> <b>NMF</b> component represent <b>the</b> TFM with a high-time and-frequency localization.|$|R
30|$|Pre-processing. All sound {{files are}} re-sampled to 16 kHz and treated as mono signal. The signals are {{analyzed}} by STFT with a Hann window, and a window size of 1024, leading to 513 frequency bins ranging from 0 – 8 kHz. The constant coefficient is removed <b>from</b> <b>the</b> <b>NMF</b> analysis and added for reconstruction in post-processing.|$|R
40|$|In this letter, {{we propose}} a new {{identification}} criterion that guarantees {{the recovery of}} the low-rank latent factors in the nonnegative matrix factorization (NMF) model, under mild conditions. Specifically, using the proposed criterion, it suffices to identify the latent factors if the rows of one factor are sufficiently scattered over the nonnegative orthant, while no structural assumption is imposed on the other factor except being full-rank. This is by far the mildest condition under which the latent factors are provably identifiable <b>from</b> <b>the</b> <b>NMF</b> model...|$|R
40|$|In this paper, a novel {{method for}} facial {{representation}} called Spatially Confined Non-Negative Matrix Factorization (SFNMF) is presented. SFNMF aims to extract more spatially confined, parts-based representation <b>from</b> <b>the</b> <b>NMF</b> based representation by merely removing non-prominent region, and focalize on the salient feature. SFNMF derived a significant set of basis which allows a non-subtractive representation {{of images and}} these bases manifest localized features. Experimental results are presented to compare SFNMF with NMF and Local NMF. Advantageous of SFNMF is demonstrated when SFNMF achieves highest verification rate among the other...|$|R
40|$|We {{introduce}} {{a novel approach}} for noise-robust feature extraction in speech recognition, based on non-negative matrix factorization (NMF). While NMF has previously been used for speech denoising and speaker separation, we directly extract time-varying features <b>from</b> <b>the</b> <b>NMF</b> output. To this end we extend basic unsupervised NMF to a hybrid supervised/unsupervised algorithm. We present a Dynamic Bayesian Network (DBN) architecture that can exploit these features in a Tandem manner together with the maximum likelihood phoneme estimate of a bidirectional long short-term memory (BLSTM) recurrent neural network. We show that addition of NMF features to spelling recognition systems can increase word accuracy by up to 7 % absolute in a noisy car environment...|$|R
40|$|In this paper, we {{test the}} use of Nonnegative Matrix Fac-torization (NMF) for feature {{extraction}} {{in the context of}} audio classification. NMF calculates a decomposition of the spectrogram into nonnegative factors and has been successfully applied to audio source separation. Thus, {{it has the potential to}} be robust to noise disturbances when used for feature calculation. We then introduce two fea-ture sets directly derived <b>from</b> <b>the</b> <b>NMF</b> decomposition. Experiments performed on an 8 -class speaker recognition task with Support Vector Machines show that the pro-posed representations convey complementary information to the baseline MFCC features. Indeed, {{the use of}} only the NMF-based descriptors lead to similar results as the refer-ence features, and the combination of these representations yields a significant improvement of the obtained accuracy. ...|$|R
40|$|This paper {{presents}} an {{improvement of the}} classical Non-negative Matrix Factorization (NMF) approach, for dealing with local representations of image objects. NMF, when applied to global data representations such as faces presents a high ability to represent local features of the original data in an unsupervised way. However, when applied to local representations NMF generates redundant basis. This work implements an improvement on <b>the</b> original <b>NMF</b> approach by incorporating prior knowledge {{in the form of}} a weight matrix extracted <b>from</b> <b>the</b> training data. A detailed mathematical description of the inclusion of this weight matrix is provided, and results demonstrating its advantages are included. Furthermore, <b>the</b> original <b>NMF</b> approach lacks a hierarchy of the elements of the estimated basis. A technique to determine an ordered set of discriminant basis is also presented. Finally, the effectiveness of the weighted approach with respect to the classical one is experimentally compared. This is done by implementing a clustering algorithm that automatically extracts object parts <b>from</b> <b>the</b> <b>NMF</b> representation of an image database corresponding to newspapers. 1...|$|R
3000|$|... [...]. The regularization terms due to two gamma bases are {{additionally}} considered. Different <b>from</b> <b>the</b> Bayesian <b>NMF</b> (BNMF) [15], BGS-NMF conducts group sparse learning {{which does}} not only characterize the within-segment harmonic information but also represent the across-segment rhythmic regularity. Sparse sets of basis vectors are further determined for sparse representation. Basically, BGS-NMF follows a general objective function. By applying different hyperparameter values [...]...|$|R
40|$|Abstract. Separating {{multiple}} music {{sources from}} a single channel mix-ture is a challenging problem. We present {{a new approach to}} this problem based on non-negative matrix factorization (NMF) and note classifica-tion, assuming that the instruments used to play the sound signals are known a priori. The spectrogram of the mixture signal is first decomposed into building components (musical notes) using an <b>NMF</b> algorithm. <b>The</b> Mel frequency cepstrum coefficients (MFCCs) of both the decomposed components and the signals in the training dataset are extracted. The mean squared errors (MSEs) between the MFCC feature space of the decomposed music component and those of the training signals are used as the similarity measures for the decomposed music notes. The notes are then labelled to the corresponding type of instruments by the K nearest neighbors (K-NN) classification algorithm based on the MSEs. Finally, the source signals are reconstructed <b>from</b> <b>the</b> classified notes and the weighting matrices obtained <b>from</b> <b>the</b> <b>NMF</b> algorithm. Simulations are provided to show the performance of the proposed system...|$|R
30|$|We can {{see from}} this figure that as the block size increases, {{the ratio of the}} public pixels increases. When the block size is 100 × 100, the {{algorithm}} with the new blocking strategy obtains the best robustness performance (the ratio of the public pixels is over 89 %). It is worth noting that the robustness performance in the block size of 40 × 40 is better than that of 60 × 60, which can be explained as follows. Though the larger block size can increase the ratio of public pixels for the rotational robustness improvement, in the testing we have applied the same rank for NMF decomposition {{in such a way that}} the bigger the block size is, the more feature information extracted <b>from</b> <b>the</b> <b>NMF</b> processing operation will be lost. As a result, the uniqueness will be reduced. Therefore, a rational block size is a trade-off between the robustness and uniqueness. For NMF-based hashing algorithm, we propose to apply the blocks of size 100 × 100 for hashing.|$|R
40|$|Variations of the ionospheric Total Electron Content (TEC) over China are {{investigated}} {{using the}} TEC {{data obtained from}} China Crustal Movement Observation Network in the year 2004. The results show a single-peak occurred in post-noon for the diurnal variation and two peaks exit around two equinox points, respectively, for the seasonal variation. Overall, the values of TEC increased <b>from</b> <b>the</b> north {{to the south of}} China. There were small but clear longitudinal differences in both sides of the longitudes with zero magnetic declination. The intensity of the day-to-day variation of TEC was not a monotonic change along the latitudes. It was usually weaker in the middle of China than that in the north or south. Comparing with the maximum F-layer electron density (<b>NmF</b> 2) derived <b>from</b> <b>the</b> ionosonde stations in China, it is found that the day-to-day variation of TEC was less significant than that of NmF 2, and that the northern crest of the equatorial anomaly identified <b>from</b> <b>the</b> <b>NmF</b> 2 data can reach Guangzhou-region. While, the TEC crest was hardly observed in the same location. This is probably caused by the tilt of topside ionosphere near the northern anomaly crest region at lower latitudes...|$|R
40|$|Nonnegative Matrix Factorization (NMF) {{has been}} proven to be {{effective}} in text mining. However, since NMF is a well-known unsupervised components analysis tech-nique, <b>the</b> existing <b>NMF</b> method can not deal with prior constraints, which are beneficial to clustering or classifi-cation tasks. In this paper, we address the text clustering problem via a novel strategy, called Pairwise Constraints-guided Non-negative Matrix Factorization (PCNMF for short). Differing <b>from</b> <b>the</b> traditional <b>NMF</b> method, <b>the</b> pro-posed method can capture the available abundance prior constraints in original space, which result in more effec-tive for clustering or information retrieval. Therefore, PC-NMF enforces the discriminative capability in the reduced space. Utilizing the appropriate transformation, PCNMF represents as a new optimization problem, which can be ef-ficiently solved by an iterative approach. The cluster mem-bership of each document can be easily determined as <b>the</b> standard <b>NMF.</b> Empirical studies based on Benchmark doc-ument corpus demonstrate appealing results. ...|$|R
40|$|Non-negative matrix {{factorization}} (NMF) {{has been}} widely used for challenging single-channel audio source separation tasks. However, inference in NMF-based models relies on iterative inference methods, typically formulated as multiplicative updates. We propose ”deep NMF”, a novel non-negative deep network architecture which results <b>from</b> unfolding <b>the</b> <b>NMF</b> it-erations and untying its parameters. This architecture can be discriminatively trained for optimal separation performance. To optimize its non-negative parameters, we show how {{a new form of}} back-propagation, based on multiplicative updates, can be used to preserve non-negativity, without the need for constrained optimization. We show on a challenging speech separation task that deep NMF improves in terms of accuracy upon NMF and is competitive with conventional sigmoid deep neural networks, while requiring a tenth of the number of parameters...|$|R
40|$|Nonnegative matrix {{factorization}} (NMF), {{which aims}} at obtaining the nonnegative low-dimensional representation of data, has received wide attention. To obtain more effective nonnegative discriminant bases <b>from</b> <b>the</b> original <b>NMF,</b> in this paper, a novel method called nonnegative discriminant matrix factorization (NDMF) is proposed for image classification. NDMF integrates the nonnegative constraint, orthogonality, and discriminant {{information in the}} objective function. NDMF considers the incoherent information of both factors in standard NMF and is proposed to enhance the discriminant ability of the learned base matrix. NDMF projects the low-dimensional representation of the subspace of the base matrix to regularize <b>the</b> <b>NMF</b> for discriminant subspace learning. Based on the Euclidean distance metric and the generalized Kullback-Leibler (KL) divergence, two kinds of iterative algorithms are presented to solve the optimization problem. The between-and within-class scatter matrices are divided into positive and negative parts for the update rules and the proofs of the convergence are also presented. Extensive experimental results demonstrate {{the effectiveness of the}} proposed method in comparison with <b>the</b> state-of-the-art discriminant <b>NMF</b> algorithms. </p...|$|R
40|$|NMF and PLSI are two {{state-of-the-art}} {{unsupervised learning}} models in data mining, {{and both are}} widely used in many applications. References have shown <b>the</b> equivalence between <b>NMF</b> and PLSI under some conditions. However, a new issue arises here: why can they result in different solutions since they are equivalent? or in other words, their algorithm differences are not studied intensively yet. In this note, we explicitly give the algorithm differences between PLSI and NMF. Importantly, we find that even if starting <b>from</b> <b>the</b> same initializations, <b>NMF</b> and PLSI may converge to different local solutions, and the differences between them are born in the additional constraints in PLSI though NMF and PLSI optimize the same objective function...|$|R
40|$|Nonnegative matrix {{factorization}} (NMF) is {{a useful}} dimension reduction method that has been investigated and applied in various areas. NMF is considered for high-dimensional data in which each element has a nonnegative value, and it provides a low-rank approximation formed by factors whose elements are also nonnegative. The nonnegativity constraints imposed on the low-rank factors not only enable natural interpretation but also reveal the hidden structure of data. Extending <b>the</b> benefits of <b>NMF</b> to multidimensional arrays, nonnegative tensor factorization (NTF) {{has been shown to}} be successful in analyzing complicated data sets. Despite <b>the</b> success, <b>NMF</b> and NTF have been actively developed only in the recent decade, and algorithmic strategies for computing NMF and NTF have not been fully studied. In this thesis, computational challenges regarding NMF, NTF, and related least squares problems are addressed. First, efficient algorithms of NMF and NTF are investigated based on a connection <b>from</b> <b>the</b> <b>NMF</b> and <b>the</b> NTF problems to the nonnegativity-constrained least squares (NLS) problems. A key strategy is to observe typical structure of the NLS problems arising in <b>the</b> <b>NMF</b> and <b>the</b> NTF computation and design a fast algorithm utilizing the structure. We propose an accelerated block principal pivoting method to solve the NLS problems, thereby significantly speeding up <b>the</b> <b>NMF</b> and NTF computation. Implementation results with synthetic and real-world data sets validate the efficiency of the proposed method. In addition, a theoretical result on the classical active-set method for rank-deficient NLS problems is presented. Although the block principal pivoting method appears generally more efficient than the active-set method for the NLS problems, it is not applicable for rank-deficient cases. We show that the active-set method with a proper starting vector can actually solve the rank-deficient NLS problems without ever running into rank-deficient least squares problems during iterations. Going beyond the NLS problems, it is presented that a block principal pivoting strategy can also be applied to the l 1 -regularized linear regression. The l 1 -regularized linear regression, also known as the Lasso, has been very popular due to its ability to promote sparse solutions. Solving this problem is difficult because the l 1 -regularization term is not differentiable. A block principal pivoting method and its variant, which overcome a limitation of previous active-set methods, are proposed for this problem with successful experimental results. Finally, a group-sparsity regularization method for NMF is presented. A recent challenge in data analysis for science and engineering is that data are often represented in a structured way. In particular, many data mining tasks have to deal with group-structured prior information, where features or data items are organized into groups. Motivated by an observation that features or data items that belong to a group are expected to share the same sparsity pattern in their latent factor representations, We propose mixed-norm regularization to promote group-level sparsity. Efficient convex optimization methods for dealing with the regularization terms are presented along with computational comparisons between them. Application examples of the proposed method in factor recovery, semi-supervised clustering, and multilingual text analysis are presented. PhDCommittee Chair: Park, Haesun; Committee Member: Gray, Alexander; Committee Member: Lebanon, Guy; Committee Member: Monteiro, Renato; Committee Member: Zha, Hongyua...|$|R
40|$|We {{investigate}} a semi-automated identification of technical problems occurred by armed forces weapon systems during mission of war. The proposed methodology {{is based on}} a semantic analysis of textual information in reports from soldiers (war logs). Latent semantic indexing (LSI) with non-negative matrix factorization (NMF) as technique from multivariate analysis and linear algebra is used to extract hidden semantic textual patterns <b>from</b> <b>the</b> reports. <b>NMF</b> factorizes <b>the</b> term-by-war log matrix - that consists of weighted term frequencies – into two non-negative matrices. This enables natural parts-based representation of the report information and it leads to an easy evaluation by human experts because human brain also uses parts-based representation. For an improved research and technology planning, the identified technical problems are a valuable source of information. A case study extracts technical problems from military logs of the Afghanistan war. Results are compared to a manual analysis written by journalists of "Der Spiegel"...|$|R
40|$|Nonnegative matrix {{factorization}} (NMF) is {{a popular}} tool for analyzing the latent structure of nonnegative data. For a positive pairwise similarity matrix, symmetric NMF (SNMF) and weighted NMF (WNMF) {{can be used to}} cluster the data. However, both of them are not very efficient for the ill-structured pairwise similarity matrix. In this paper, a novel model, called relationship matrix nonnegative decomposition (RMND), is proposed to discover the latent clustering structure <b>from</b> <b>the</b> pairwise similarity matrix. The RMND model is derived <b>from</b> <b>the</b> nonlinear <b>NMF</b> algorithm. RMND decomposes a pairwise similarity matrix into a product of three low rank nonnegative matrices. The pairwise similarity matrix is represented as a transformation of a positive semidefinite matrix which pops out the latent clustering structure. We develop a learning procedure based on multiplicative update rules and steepest descent method to calculate the nonnegative solution of RMND. Experimental results in four different databases show that the proposed RMND approach achieves higher clustering accuracy...|$|R
30|$|Minimum average RSSI threshold: this {{information}} is gathered by <b>the</b> <b>NMF.</b> By using <b>the</b> <b>NMF,</b> we automatically include RSSI information from duplicate packets received from this neighbour.|$|R
40|$|In this paper, a novel graph-preserving sparse non-negative matrix {{factorization}} (GSNMF) {{algorithm is}} proposed for facial expression recognition. The GSNMF algorithm is derived <b>from</b> <b>the</b> original <b>NMF</b> algorithm by exploiting both sparse and graph-preserving properties. The latter may contain the class information of the samples. Therefore, GSNMF can be conducted as an unsupervised or a supervised dimension reduction method. A sparse representation of the facial images is obtained by minimizing the l 1 -norm of the basis images. Furthermore, according to graph embedding theory, the neighborhood of the samples is preserved by retaining the graph structure in the mapped space. The GSNMF decomposition transforms the high-dimensional facial expression images into a locality-preserving subspace with sparse representation. To guarantee convergence, we use the projected gradient method to calculate the non-negative solution of GSNMF. Experiments are conducted on the JAFFE database and the Cohn-Kanade database with not-occluded and partially occluded facial images. The {{results show that the}} GSNMF algorithm provides better facial representations and achieves higher recognition rates than NMF. Moreover, GSNMF is also more robust to partial occlusions than other tested methods...|$|R
3000|$|For <b>the</b> <b>NMF</b> window length, {{we chose}} T= 10 frames, which offered a good balance between {{dictionary}} complexity and ASR performance. The length of <b>the</b> <b>NMF</b> R matrix initialization filter that functions as an {{upper bound on}} the reverberation time the update algorithm can handle was set to T [...]...|$|R
30|$|<b>From</b> <b>the</b> above {{experimental}} analysis, we can {{see that}} <b>the</b> <b>NMF</b> hashing algorithm with the restricted blocking strategy can provide stronger performance than <b>the</b> recently reported <b>NMF</b> hashing algorithm [20] in the presence of rotation with the loose and crop modes while keeping the robustness to other attacks.|$|R
40|$|We {{propose a}} new method to {{incorporate}} rich statistical priors, modeling temporal gain sequences in the solutions of nonnegative matrix factorization (<b>NMF).</b> <b>The</b> proposed method {{can be used}} for single-channel source separation (SCSS) applications. In NMF based SCSS, NMF is used to decompose the spectra of the observed mixed signal as a weighted linear combination of a set of trained basis vectors. In this work, <b>the</b> <b>NMF</b> decomposition weights are enforced to consider statistical and temporal prior information on the weight combination patterns that the trained basis vectors can jointly receive for each source in the observed mixed signal. The Hidden Markov Model (HMM) is used as a log-normalized gains (weights) prior model for <b>the</b> <b>NMF</b> solution. <b>The</b> normalization makes the prior models energy independent. HMM is used as a rich model that characterizes the statistics of sequential data. <b>The</b> <b>NMF</b> solutions for <b>the</b> weights are encouraged to increase the log-likelihood with the trained gain prior HMMs while reducing <b>the</b> <b>NMF</b> reconstruction error at the same time...|$|R
40|$|This {{vignette}} {{describes how}} to produce different informative heatmaps from NMF objects, such as returned by <b>the</b> function <b>nmf</b> in <b>the</b> <b>NMF</b> package 1 (Gaujoux et al. 2010). The main drawing engine is {{implemented by the}} function aheatmap, which is a highly enhanced modi-fication of <b>the</b> function pheatmap <b>from</b> <b>the</b> pheatmap package 2, and provides convenient and quick ways of producing high quality and customizable annotated heatmaps. Currently this function is part of <b>the</b> package <b>NMF,</b> but may eventually compose a separate package on its own...|$|R
40|$|Abstract — In {{this paper}} {{we present a}} {{methodology}} for document clustering based on Non-negative Matrix Factorization (NMF) and ensemble clustering. Thanks to the ensemble clustering the algorithm is less prone {{to get into a}} local minimum caused by the initialization of <b>the</b> <b>NMF.</b> Despite <b>the</b> ensemble clustering, the algorithm keeps the semantic interpretability of <b>the</b> <b>NMF</b> and constructs a coocurrence matrix that allows the projection of the documents onto a two-dimensional space suitable for visualization. The algorithm is freely available for the information retrieval community <b>from</b> <b>the</b> Bioengineering Laboratory web page. I...|$|R
50|$|Methods {{differ on}} the {{priority}} {{and meaning of}} opener's response to <b>the</b> <b>NMF</b> asking bid.|$|R
30|$|For the {{comparison}} between observation and the model, both the URSI and CCIR options of the IRI- 2007 model are used to predict <b>the</b> <b>NmF</b> 2 values, which can be downloaded <b>from</b> <b>the</b> site: [URL] iri_vitmo.php.|$|R
30|$|Considering the {{initialization}} step in <b>the</b> <b>NMF</b> algorithm on <b>the</b> {{most complex}} LDA+MLLT+SAT+f-bMMI and LDA+MLLT+SAT+DNN back-ends, {{the results indicate}} that it is beneficial to apply dereverberation during initialization. However, on the less complex LDA+MLLT+SAT back-end, the benefit is negligible and on the least complex LDA+MLLT back-end, the initialization step is detrimental as <b>the</b> <b>NMF</b> alone provides <b>the</b> lowest average WERs on both SimData and RealData.|$|R
40|$|We {{propose a}} new method to enforce priors on the {{solution}} of the nonnegative matrix factorization (<b>NMF).</b> <b>The</b> proposed algorithm can be used for denoising or single-channel source separation (SCSS) applications. <b>The</b> <b>NMF</b> solution is guided to follow the Minimum Mean Square Error (MMSE) estimates under Gaussian mixture prior models (GMM) for the source signal. In SCSS applications, the spectra of the observed mixed signal are decomposed as a weighted linear combination of trained basis vectors for each source using NMF. In this work, <b>the</b> <b>NMF</b> decomposition weight matrices are treated as a distorted image by a distortion operator, which is learned directly <b>from</b> <b>the</b> observed signals. The MMSE estimate of the weights matrix under GMM prior and log-normal distribution for the distortion is then found to improve <b>the</b> <b>NMF</b> decomposition results. <b>The</b> MMSE estimate is embedded within the optimization objective to form a novel regularized <b>NMF</b> cost function. <b>The</b> corresponding update rules for the new objectives are derived in this paper. Experimental results show that, <b>the</b> proposed regularized <b>NMF</b> algorithm improves <b>the</b> source separation performance compared with using NMF without prior or with other prior models...|$|R
30|$|The basic {{steps of}} <b>the</b> <b>NMF</b> method {{presented}} in this section are summarized as the following algorithm.|$|R
30|$|In {{equinoctial}} months (April, October), <b>the</b> noon time <b>NmF</b> 2 {{values are}} in the range of 3 – 28 × 105 electron/cm 3, increasing with F 10.7 in the quiet and moderate geomagnetic activity condition, and NmF 2 at midnight is less than 13 × 105 electron/cm 3. The difference of <b>the</b> <b>NmF</b> 2 between noon and midnight is getting higher with increasing solar activity. The patterns of <b>the</b> <b>NmF</b> 2 variation for each geomagnetic activity conditions are very similar in winter month (January) and equinoctial months (April, October), except that <b>the</b> <b>NmF</b> 2 difference between noon and midnight is higher in winter than in other seasons, probably due to recombination during longer time after sunset. On the other hand, <b>the</b> pattern of <b>NmF</b> 2 in summer (July) is quite different from other seasons. Most NmF 2 values in July are less than 10 × 105 el/cm 3 even in high solar activity and <b>the</b> response of <b>NmF</b> 2 is very similar at noon and at midnight, resulting in only small NmF 2 difference between noon and midnight even in high solar activity. <b>The</b> <b>NmF</b> 2 responses with F 10.7 in January, and in July are consistent with those reported by Bremer (1998). Correlation coefficients at noontime for low geomagnetic activity condition are more than 0.86 for all months except summer months, when the data are scattered severely for Kp < 2. We will discuss causes of <b>the</b> scattered <b>NmF</b> 2 values during summer in later sections. Overall, Fig. 1 shows that <b>the</b> Anyang <b>NmF</b> 2 data are consistent with the IRI- 2007 values for all seasons and solar activities.|$|R
40|$|We {{propose a}} new method to {{incorporate}} priors on {{the solution of}} nonnegative matrix factorization (<b>NMF).</b> <b>The</b> <b>NMF</b> solution is guided to follow the {{minimum mean square error}} (MMSE) estimates of the weight combinations under a Gaussian mixture model (GMM) prior. The proposed algorithm can be used for denoising or single-channel source separation (SCSS) applications. NMF is used in SCSS in two main stages, the training stage and the separation stage. In <b>the</b> training stage, <b>NMF</b> is used to decompose the training data spectrogram for each source into a multiplication of a trained basis and gains matrices. In the separation stage, the mixed signal spectrogram is decomposed as a weighted linear combination of the trained basis matrices for the source signals. In this work, to improve the separation performance of <b>NMF,</b> <b>the</b> trained gains matrices are used to guide the solution of <b>the</b> <b>NMF</b> weights during <b>the</b> separation stage. The trained gains matrix is used to train a prior GMM that captures the statistics of the valid weight combinations that the columns of the basis matrix can receive for a given source signal. In the separation stage, the prior GMMs are used to guide <b>the</b> <b>NMF</b> solution of <b>the</b> gains/weights matrices using MMSE estimation. <b>The</b> <b>NMF</b> decomposition weights matrix is treated as a distorted image by a distortion operator, which is learned directly <b>from</b> <b>the</b> observed signals. The MMSE estimate of the weights matrix under the trained GMM prior and log-normal distribution for the distortion is then found to improve <b>the</b> <b>NMF</b> decomposition results. <b>The</b> MMSE estimate is embedded within the optimization objective to form a novel regularized <b>NMF</b> cost function. <b>The</b> corresponding update rules for the new objectives are derived in this paper. The proposed MMSE estimates based regularization avoids the problem of computing the hyper-parameters and the regularization parameters. MMSE also provides a better estimate for the valid gains matrix. Experimental results show that <b>the</b> proposed regularized <b>NMF</b> algorithm improves <b>the</b> source separation performance compared with using NMF without a prior or with other prior models. © 2014 Elsevier Inc...|$|R
40|$|The diurnal {{variation}} of peak electron density, NmF 2, of five stations for different seasons, solar maximum conditions and quiet magnetic activity (Kp ≤ 3) is analyzed {{in terms of}} the ExB drift velocity at the equator. The stations analyzed are Kodaikanal at the magnetic equator, Tucuman and Okinawa at the crests of the equatorial ionization anomaly (EIA), and Yamagawa and Kokobunji at the outer sides of the EIA crests. The drift velocity was taken from an empirical model based on AE-E satellite measurements, and the meridional thermospheric wind <b>from</b> <b>the</b> HWM 93 model. <b>The</b> departure of <b>NmF</b> 2 from simple zenith angle dependence is qualitatively explained for stations at the magnetic equator and at the EIA crests based on the contribution of electrons coming <b>from</b> <b>the</b> equator. In the case of stations away <b>from</b> <b>the</b> EIA crests, <b>NmF</b> 2 behavior follows mainly a zenith angle dependence, which is compared to the meridional wind pattern. In all cases there are features not explainable {{in terms of the}} ExB drift or the meridional neutral wind...|$|R
30|$|<b>The</b> <b>NMF</b> {{algorithm}} with combined constraints (F 35 -NMF) performs {{better than}} the algorithm with one constraint (F 3 -NMF).|$|R
30|$|In this section, {{we first}} present <b>the</b> <b>NMF</b> problem {{and then the}} {{optimization}} algorithm used to solve it in this article.|$|R
30|$|We {{perform a}} lot of testing to measure the hashing {{algorithm}} (with the restricted blocking method) against <b>the</b> previous <b>NMF</b> hashing algorithm [20]. Experimental {{results show that the}} use of the restricted blocking strategy can effectively improve the performance of <b>the</b> <b>NMF</b> hashing algorithm for the rotation operations.|$|R
