112|7|Public
25|$|A {{return to}} {{extended}} generations of single exposure patterning {{would be possible}} with higher numerical aperture (NA) tools. An NA of 0.45 using 13.5nm wavelength could require retuning of a few percent. Increasing <b>demagnification</b> could avoid this retuning, but the reduced field size severely affects large patterns (one die per 26mm × 33mm field) such as the many-core multi-billion transistor 14nm Xeon chips. by requiring field stitching.|$|E
25|$|Higher <b>demagnification</b> will {{increase}} the mask size or {{reduce the size of}} the printed field. Reduced field size would divide full-size chip patterns (normally taking up 26mm × 33mm) among two or more conventional 6-inch EUV masks. Large (approaching or exceeding 500mm2) chips, typically used for GPUs or servers, would have to be stitched together from two or more sub-patterns from different masks. Without field stitching, die size would be limited. With field stitching, features that cross field boundaries would have alignment errors, and the extra time required to change masks would reduce the throughput of the EUV system.|$|E
25|$|In some contexts, {{especially}} in photography and astronomy, aperture {{refers to the}} diameter of the aperture stop rather than the physical stop or the opening itself. For example, in a telescope, the aperture stop is typically the edges of the objective lens or mirror (or of the mount that holds it). One then speaks of a telescope as having, for example, a 100-centimeter aperture. Note that the aperture stop is not necessarily the smallest stop in the system. Magnification and <b>demagnification</b> by lenses and other elements can cause a relatively large stop to be the aperture stop for the system. In astrophotography, the aperture may be given as a linear measure (for example in inches or mm) or as the dimensionless ratio between that measure and the focal length. In other photography, it is usually given as a ratio.|$|E
40|$|The {{design of}} Final Focus systems for linear {{colliders}} is challenging {{because of the}} large <b>demagnifications</b> needed to produce nanometer-sized beams at the interaction point. Simple first- and second-order matrix matching have proven insufficient for this task, and minimization of third- and higher-order aberrations is essential. An appropriate strategy is required for the latter to be successful. A recipe for Final Focus design, and a set of computational tools used to implement this approach, are described herein. An example of the use of this procedure is given...|$|R
40|$|This {{research}} {{demonstrates the}} feasibility of a full-field photographic method for remotely measuring the movement of large deforming objects. 'Large objects' could include civil engineering structures such as dam walls, buildings and bridges, and geological phenomena such as glaciers. Such structures must be examined in situ and preferably by a non contacting method. The objective is to measure motion from time lapsed photographs of the moving object. The method is based on speckle photography which is a well developed optical metrology technique for deformation measurement of engineering structures in laboratory conditions. Its application to large scale structures illuminated in sunlight at high imaging <b>demagnifications</b> has demanded some significant extensions and modifications to the technique. Imaging these large objects offers {{a unique set of}} challenges which include the establishment of rigid tripods from which to take the time lapsed photographs in rugged glacial terrain, the variation of illumination in terms of both quality and angle of incidence, imaging through several kilometres of turbulent atmosphere and recording the signature texture of the object surface onto film at high imaging <b>demagnifications.</b> The effects of these factors are considered both conceptually and experimentally, providing fundamental understanding of the problem. Displacement analysis is performed primarily by interrogation of time lapsed negative pairs using an unexpanded laser beam, as is generally the case in speckle photography. An automated system is developed to make practical the analysis of multiple points in the field of view. In parallel, a new digital technique is introduced where displacement results are obtained by pattern matching in digital versions of the speckle images. This analysis method is shown to be highly suitable for the application to glacier flow. Registration of the pair of time lapsed images is performed by calculating the affine transform describing the image misalignment (introduced at either the recording or analysis stage) within the non-deforming areas of the field of view. Use of this novel technique allows pairs of single exposures, rather than double exposures, to be examined, and it also increases the sensitivity of measurement. Two dimensional motion fields representing glacier flow are presented, leading {{to the conclusion that the}} technique is feasible in sunlight illumination, for a variety of glacial surface types and at high imaging <b>demagnifications...</b>|$|R
40|$|Due to the {{deflection}} {{of light}} by density fluctuations {{along the line}} of sight, weak lensing is an unavoidable systematic uncertainty in the use of type Ia supernovae (SNe Ia) as cosmological distance indicators. We derive the expected weak lensing signatures of SNe Ia by convolving the intrinsic distribution in SN Ia peak luminosity with magnification distributions of point sources. We find that current SN Ia data at high $z$ show both the presence of a non-Gaussian tail at the bright end (possibly due to high magnifications), and a faint-ward shift of the peak of the distribution (possibly due to <b>demagnifications).</b> Weak lensing effect may have begun to set in as a non-negligible systematic uncertainty in the use of SNe Ia as a cosmological probe, and should be minimized by flux-averaging...|$|R
2500|$|Preparation of an {{anamorphic}} lens with an NA between 0.5 and 0.6 is underway as of 2016. The <b>demagnification</b> will be 8X in one dimension and 4X in the other, and {{the angle of}} reflection will increase.|$|E
2500|$|In 2015, ASML {{disclosed}} {{details of}} its anamorphic next-generation EUV (13.5nm wavelength) scanner, with an NA of 0.55. The <b>demagnification</b> is increased from 4x to 8x only {{in one direction}} (in the plane of incidence). [...] However, the 0.55 NA has a much smaller depth of focus than immersion lithography. Also, an anamorphic 0.52 NA tool {{has been found to}} exhibit too much CD and placement variability for 5nm node single exposure and multi-patterning cutting.|$|E
5000|$|... #Caption: Reduction {{of field}} size by <b>demagnification.</b> Increasing the <b>demagnification</b> from 4X to 8X in one {{dimension}} would split the original full imaging field {{into two parts}} to preserve the same die area (26 mm × 33 mm).|$|E
40|$|The Final Focus Test Beam (FFTB) {{project at}} SLAC is a {{demonstration}} of the feasibility of making the extremely small spot sizes needed for future e + e - linear colliders. Fermilab joined the FFTB collaboration in late 1993. This paper describes the Fermilab contributions to FFTB, emphasizing the work on lattice diagnostics. I. Introduction There has been an ongoing involvement by Fermilab in work on high energy e + e - linear colliders [1]. In 1993 Fermilab joined the Final Focus Test Beam Collaboration. The FFTB [2] is an experiment to demonstrate the feasibility of making the small beam spot sizes that are required for the success any future linear collider project. The experiment has already yielded impressive results [3] and has shown that the <b>demagnifications</b> needed for the NLC design are feasible. Fermilab joined the collaboration after almost all of the hardware was already installed. However an earlier engineering run indicated the need for an additional x - y halo collima [...] ...|$|R
40|$|Parabolic {{compound}} refractive lenses (PCRLs) {{are high}} quality imaging optics for hard x-rays [1]. They {{can be used}} for the production of intensive hard x-ray microbeams for microanalytical applications [2], and are particularly well suited for full field imaging applications, such as full field microscopy and x-ray lithography with a PCRL as reduction lens. For hard x-ray microscopy a PCRL can be used as an objective lens to enlarge the projection image of a sample. This way, x-ray micrographs with resolutions down to 300 nm have been achieved so far using Al as a lens material. Using more transparent lens materials such as beryllium, resolutions down to 50 nm are expected. A detailed numerical model of the contrast formation including coherent phenomena is given. Due to the inherently small numerical aperture of PCRLs, the depth of field is large, and images of sufficiently thin samples (~ 1 mm thickness) are sharp projections. This allows to combine microscopic imaging with tomography. First experimental results on this method are given. Similarly, a PCRL can be used to project the reduced image of an x-ray lithography mask onto a resist. In a first experiment, <b>demagnifications</b> between 3 and 6 were obtained at an x-ray energy of 20 to 25 keV using aluminium lenses. Future beryllium reduction lenses will work optimally aroun...|$|R
40|$|Due to the {{deflection}} {{of light}} by density fluctuations {{along the line}} of sight, weak lensing is an unavoidable systematic uncertainty in the use of type Ia supernovae (SNe Ia) as cosmological distance indicators. We derive the expected weak lensing signatures of SNe Ia by convolving the intrinsic distribution in SN Ia peak luminosity with magnification distributions of point sources. We find that current SN Ia data at high z show both the presence of a non-Gaussian tail at the bright end (possibly due to high magnifications), and a faint-ward shift of the peak of the distribution (possibly due to <b>demagnifications).</b> Weak lensing effect may have begun to set in as a non-negligible systematic uncertainty in the use of SNe Ia as a cosmological probe, and should be minimized by flux-averaging. Subject headings: cosmology: observations—cosmology: theory—gravitational lensing 1. introduction The use of type Ia supernovae (SNe Ia) as cosmological distance indicators has become fundamental in observational cosmology (Garnavich et al. 1998; Riess et al. 1998; Perlmutter et al. 1999; Knop et al. 2003; Tonry et al. 2003; Riess et al. 2004). Although SNe Ia can be calibrated to be good standard candles (Phillips 1993; Riess, Press, & Kirshner 1995), they can be affected by systematic uncertainties. These include possible evolution in the intrinsic SN Ia peak brightness with time (Drell, Loredo, & Wasserman 2000), weak lensing of SNe Ia (Kantowski, Vaughan...|$|R
5000|$|Preparation of an {{anamorphic}} lens with an NA between 0.5 and 0.6 is underway as of 2016. The <b>demagnification</b> will be 8X in one dimension and 4X in the other, and {{the angle of}} reflection will increase.|$|E
50|$|A {{return to}} {{extended}} generations of single exposure patterning {{would be possible}} with higher numerical aperture (NA) tools. An NA of 0.45 using 13.5 nm wavelength could require retuning of a few percent. Increasing <b>demagnification</b> could avoid this retuning, but the reduced field size severely affects large patterns (one die per 26 mm × 33 mm field) such as the many-core multi-billion transistor 14 nm Xeon chips. by requiring field stitching.|$|E
5000|$|In 2015, ASML {{disclosed}} {{details of}} its anamorphic next-generation EUV (13.5 nm wavelength) scanner, with an NA of 0.55. The <b>demagnification</b> is increased from 4x to 8x only {{in one direction}} (in the plane of incidence). [...] However, the 0.55 NA has a much smaller depth of focus than immersion lithography. Also, an anamorphic 0.52 NA tool {{has been found to}} exhibit too much CD and placement variability for 5 nm node single exposure and multi-patterning cutting.|$|E
40|$|The flux {{anomalies}} in four-image gravitational lenses can {{be interpreted}} as evidence for the dark matter substructure predicted by cold dark matter (CDM) halo models. In principle, these flux anomalies could arise from alternate sources such as absorption, scattering or scintillation by the interstellar medium (ISM) of the lens galaxy, problems in the ellipsoidal macro models used to fit lens systems, or stellar microlensing. We apply several tests to the data that appear to rule out these alternate explanations. First, the radio flux anomalies show no significant dependence on wavelength, as would be expected for almost any propagation effect in the ISM or microlensing by the stars. Second, the flux anomaly distributions show the characteristic <b>demagnifications</b> of the brightest saddle point relative to the other images expected for low optical depth substructure, which cannot be mimicked by either the ISM or problems in the macro models. Microlensing by stars also cannot reproduce the suppression of the bright saddle points if the radio source sizes are consistent with the Compton limit for their angular sizes. Third, while it is possible to change the smooth lens models to fit the flux anomalies in some systems, we can rule out the necessary changes in all systems where we have additional lens constraints to check the models. Moreover, the parameters of these models are inconsistent with our present observations and expectations for the structure of galaxies. We conclude that low-mass halos remain the best explanation of the phenomenon. Comment: Submitted to Ap...|$|R
5000|$|Most X-ray {{lithography}} demonstrations {{have been}} performed by copying with image fidelity (without magnification) on the line of fuzzy contrast as illustrated in the figure. However, with the increasing need for high resolution, X-ray lithography is now performed on {{what is called the}} [...] "sweet spot", using local [...] "demagnification by bias". Dense structures are developed by multiple exposures with translation. The advantages of using 3x <b>demagnification</b> include, the mask is more easily fabricated, the mask to wafer gap is increased, and the contrast is higher. The technique is extensible to dense 15 nm prints.|$|E
50|$|Higher <b>demagnification</b> will {{increase}} the mask size or {{reduce the size of}} the printed field. Reduced field size would divide full-size chip patterns (normally taking up 26 mm × 33 mm) among two or more conventional 6-inch EUV masks. Large (approaching or exceeding 500 mm2) chips, typically used for GPUs or servers, would have to be stitched together from two or more sub-patterns from different masks. Without field stitching, die size would be limited. With field stitching, features that cross field boundaries would have alignment errors, and the extra time required to change masks would reduce the throughput of the EUV system.|$|E
50|$|In some contexts, {{especially}} in photography and astronomy, aperture {{refers to the}} diameter of the aperture stop rather than the physical stop or the opening itself. For example, in a telescope, the aperture stop is typically the edges of the objective lens or mirror (or of the mount that holds it). One then speaks of a telescope as having, for example, a 100-centimeter aperture. Note that the aperture stop is not necessarily the smallest stop in the system. Magnification and <b>demagnification</b> by lenses and other elements can cause a relatively large stop to be the aperture stop for the system. In astrophotography, the aperture may be given as a linear measure (for example in inches or mm) or as the dimensionless ratio between that measure and the focal length. In other photography, it is usually given as a ratio.|$|E
50|$|In {{order to}} obtain spectromicroscopy data the {{following}} operating procedure is followed. The desired monochromator grating is selected along with photon energy {{in the middle of}} NEXAFS range. Refocus mirrors are adjusted to put the beam into the microscope and steered to maximize the flux passing through the zone plate. A pinhole is placed in the photon beam upstream in a transverse position to maximize transmission. Pinhole size is determined by <b>demagnification</b> {{to the size of the}} diffraction limit of the zone plate lens. An undersized pinhole is often used to reduce intensity which controls radiation damage. The order sorting aperture is positioned to eliminate transmission of unfocused zero order light, which would blur the image. Then an x/y line scan is defined across an intensity variation in the image. The x/y line scans are repeated with varying focus conditions. Adsorption spectra can also be obtained with a stationary photon spot.|$|E
50|$|The {{basic idea}} is that the {{illumination}} pattern is imaged onto a geometrically congruent cutoff pattern (essentially a multiplicity of knife edges) with focusing optics, while density gradients lying between the illumination pattern and the cutoff pattern are imaged, typically by a camera system. As in classical schlieren, the distortions produce regions of brightening or darkening corresponding to the position and direction of the distortion, because they redirect rays either away from or onto the opaque part of the cutoff pattern. While in classical schlieren, distortions over the whole beam path are visualized equally, in focusing schlieren, only distortions in the object field of the camera are clearly imaged. Distortions away from the object field become blurred, so this technique allows some degree of depth selection. It also has the advantage that a wide variety of illuminated backgrounds can be used, since collimation is not required. This allows construction of projection-based focusing schlieren systems which are much easier to build and align than classical schlieren systems. The requirement of collimated light in classical schlieren is often a substantial practical barrier for constructing large systems due to the need for the collimating optic to be {{the same size as the}} field of view. Focusing schlieren systems can use compact optics with a large background illumination pattern, which is particularly easy to produce with a projection system. For systems with large <b>demagnification,</b> the illumination pattern needs to be around twice the size of the field of view to allow for defocusing of the background pattern.|$|E
40|$|The project {{presents}} {{analysis and}} implementation of several image magnification (interpolation) and <b>demagnification</b> (decimation) techniques for non-integer magnification/demagnification factors. Fast algorithms for image magnification and <b>demagnification</b> {{which are based on}} fast snic interpolation algorithm [1, 2, 3] are described. These algorithms exhibit higher performance than the traditional methods. Implementation and performance issues are discussed. Experimental evidence to support the claims are provided. 1. Block diagram of fast sinc interpolation algorithm for odd N The fast sinc-interpoation algorithm for odd N (N is the number of coefficients used in fast Fourier transform) is presented in fig. 1 : µr = exp(i 2 πpr/N...|$|E
40|$|This paper follows {{previous}} {{demonstrations of}} <b>demagnification</b> by bias in ultra-high resolution proximity x-ray lithography. The <b>demagnification,</b> × 1 –× 6, is achieved without lenses or mirrors. Two-dimensional proximity corrections, applied to rectangular mask shapes, are simulated. A V-shaped inrigger, {{cut into the}} mask, is particularly effective. When a typical range of broadband illumination wavelengths is used, several beneficial effects are observed when the gap is held at the ‘critical condition’. Maintaining fine resolution, oscillations—due to Fresnel diffraction parallel to the longer dimension of a rectangle—are virtually eliminated, and the image intensity is made uniform by the elimination of bright spots near the ends of a rectangle. 1...|$|E
40|$|Vacuum-type neutron image {{intensifier}} tube improves image detection in thermal neutron radiographic inspection. This system converts images to an electron image, and with electron acceleration and <b>demagnification</b> between the input target and output screen, produces a bright image viewed through a closed circuit television system...|$|E
40|$|Ion {{projection}} facilitates {{a direct}} structuring, which Is an attractive potential manufacturing process for patterned storage media. An advantage to {{this method is}} that the media roughness remaines unchanged. The feasibility of ion projection direct structuring for processing full disk surfaces was investigated using a next generation lithography projector. Co-Pt multilayer films with strong perpendicular anisotropy were deposited on 1 -in glass disks as used in the IBM microdrive and on Si substrates. Concentric tracks including data, as well as head positioning servo structures, were patterned in a single exposure step with 45 keV He+ at a 4 x <b>demagnification.</b> In a second experiment, sub- 100 -nm magnetic islands were produced using projection at 8. 7 x <b>demagnification</b> and visualized by magnetic force microscopy...|$|E
40|$|We {{examine a}} {{gravitational}} lens model inspired by modified gravity theories and exotic matter and energy. We study an asymptotically flat, static, and spherically symmetric spacetime that is modified {{in such a}} way that the spacetime metric depends on the inverse distance to the power of positive n in the weak-field approximation. It is shown analytically and numerically that there is a lower limit on the source angular displacement from the lens object to get <b>demagnification.</b> Demagnifying gravitational lenses could appear, provided the source position β and the power n satisfy β > 2 /(n+ 1) in the units of the Einstein ring radius under a large-n approximation. Unusually, the total amplification of the lensed images, though they are caused by the gravitational pull, could be less than unity. Therefore, time-symmetric <b>demagnification</b> parts in numerical light curves by gravitational microlensing (F. Abe, Astrophys. J. 725, 787, 2010) may be evidence of an Ellis wormhole (being an example of traversable wormholes), but they do not always prove it. Such a gravitational <b>demagnification</b> of the light might be used for hunting a clue of exotic matter and energy that are described by an equation of state more general than the Ellis wormhole case. Numerical calculations for the n= 3 and 10 cases show maximally ∼ 10 and ∼ 60 percent depletion of the light, when the source position is β∼ 1. 1 and β∼ 0. 7, respectively. Comment: 10 pages, 2 figures, surface mass density discussed; accepted by PR...|$|E
40|$|Feasibility of ion {{projection}} printing for full disk surface processing was investigated. The influence of different ion species and ion energies on the Co/Pt interfaces was evaluated by Monte Carlo simulations. In a single exposure step several tracks within an exposure field of 17. 5 mm in diameter were magnetically structured by projecting 45 keV He+ at a 4 -fold <b>demagnification...</b>|$|E
40|$|INTRODUCTION In {{order to}} achieve {{luminosity}} {{in the range of}} 10 34 cm - 2 sec - 1, a TeV-scale linear collider will need {{to reduce the size of}} electron and positron bunches at collision to sizes on the order of several nanometers. This vertical size mandates a <b>demagnification</b> from the linac to the IP of a factor of 400. Such a severe <b>demagnification</b> places unprecedented tolerances on many optical aberrations of the final focus system, most of which cannot be met ab initio, but only as a result of beam-based tuning of the final focus. Any linear collider must have an algorithm and diagnostics which will allow such tuning to converge in a finite time. The Final Focus Test Beam (FFTB) is a prototype linear collider final focus, designed to reduce the 46. 6 GeV SLAC beam to a size of 2 microns by 60 nanometers. The FFTB has the horizontal and vertical demagnifications required by a future linear collider, and thus addresses all the same optical aberrations. We...|$|E
40|$|With high NA (> 0. 33), and the {{associated}} higher angles of incidence on the reflective EUV mask, mask induced effects will significantly impact the overall scanner-performance. We discuss the expected effects in detail, in particular {{paying attention to the}} interaction between reflective coating and absorber on the mask, and show that there is a trade-off between image quality and mask efficiency. We show that by adjusting the <b>demagnification</b> of the lithography system one can recover both image quality and mask efficiency...|$|E
40|$|The {{performance}} of prototype Hybrid Photo-Diodes (HPDs) with 80 mm diameter is evaluated, anticipating their usage in the RICH detectors of the LHCb experiment at CERN. Data from LED scan {{are used to}} estimate the magnitude of <b>demagnification</b> from cross- focusing. The photoelectron yields and Cherenkov angle resolutions obtained from these HPDs when used {{as part of a}} RICH detector installed in a test beam have been measured. The results agree with the expectations from simulations. The response of these tubes to charged particles is also reported...|$|E
30|$|Similarly, {{a variety}} of imaging {{strategies}} can be employed to minimize the electron dose, chief among which is reducing the beam current. Using more source <b>demagnification</b> can improve spatial resolution, but the lower signal level may degrade the signal-to-noise ratio. Other possibilities include control of the beam dose via ‘blanking’, adjusting operating parameters (such as focus and astigmatism) on an area slightly away from the area of interest, using repeated fast scans [13], or making more efficient use of the available signals [14]. The recent development of sparse sampling methods {{also appears to be}} extremely promising [15].|$|E
40|$|We {{report on}} an {{approach}} to ultraviolet (UV) photolithography and direct writing where both the exposure pattern and dose are determined by a {{complementary metal oxide semiconductor}} (CMOS) controlled micro-pixellated light emitting diode array. The 370 nm UV light from a demonstrator 8 x 8 gallium nitride micro-pixel LED is projected onto photoresist covered substrates using two back-to-back microscope objectives, allowing controlled <b>demagnification.</b> In the present setup, the system is capable of delivering up to 8. 8 W/cm 2 per imaged pixel in circular spots of diameter approximately 8 microm. We show example structures written in positive as well as in negative photoresist...|$|E
40|$|We {{have used}} the Final Focus Test Beam beamline and {{associated}} instrumentation to reduce the 46. 6 GeV SLAC electron beam to a vertical size of 70 nm. This represents a reduction from the linac beam size {{by a factor of}} 320, comparable to the <b>demagnification</b> required by a TeV-scale linear collider, and addresses the same aberrations predicted in such an environment. The beam dimensions were measured by two novel beam size monitors at the focal point. Details of the optical and hardware design of the beam line, necessary tuning operations, beam size monitor principles, and future plans are discussed. 1...|$|E
40|$|The Compact Linear Collider (CLIC) {{study at}} CERN proposes a linear {{collider}} with nanometer-size colliding beams at an energy of 3 TeV c. m. ("colliding high energy nanobeams"). The transport, <b>demagnification</b> and collision of these nanobeams imposes magnet vibration tolerances {{that range from}} 0. 2 nm to a few nanometers. This is well below the floor vibration usually observed. A test stand for magnet stability was set-up at CERN in the immediate neighborhood of roads, operating accelerators, workshops, and regular office space. It was equipped with modern stabilization equipment. The experimental setup and first preliminary results are presented. (10 refs) ...|$|E
40|$|This thesis {{investigates the}} design of {{quadrupole}} probe forming lens systems with resolution in the nanometre range. To achieve sub-micron resolution, big improvements must be made in focusing, lens aberration, and reduction of scattering processes. This thesis {{presents the results of}} a theoretical investigation into the performance of two-stage magnetic quadrupole lens systems with an intermediate focus. Such systems are capable of far greater <b>demagnification</b> than single-stage systems, but the challenge is to find a two-stage system with an acceptable ratio between <b>demagnification</b> and aberration. The results of a systematic survey of two-stage lens systems using the numerical raytracing technique to accurately calculate the lens aberrations of each system are presented. This thesis also investigates the use of pre-lens electrostatic scanning with magnetic quadrupole lenses. It is shown that in spite of the large thirdorder aberration of quadrupole systems, the use of dog-leg deflection systems in which the beam always crosses the optical axis at the entrance principal plane of the lens, can minimize distortion due to off-axis aberration. An evaluation of the lens aberrations in microbeam and nanobeam systems caused by stray DC magnetic fields is also presented. The relative thickness of the beamline optical elements compared to the curvature of the beam in stray magnetic fields causes aberration where the beam axis differs from the optical axis of the lens system. Numerical raytracing is used to study the influence of stray DC magnetic fields on beam resolution at the sub-micron level...|$|E
40|$|A novel {{scheme for}} the {{focusing}} of high-energy leptons in future linear colliders was proposed in 2001 [P. Raimondi and A. Seryi Phys. Rev. Lett. 86 3779 (2001) ]. This scheme has many advantageous properties over previously studied focusing schemes, including being significantly shorter {{for a given}} energy and having a significantly better energy bandwidth. Experimental results from the ATF 2 accelerator at KEK are presented that validate the operating principle of such a scheme by demonstrating the <b>demagnification</b> of a 1. 3 GeV electron beam down to below 65 nm in height using an energy-scaled version of the compact focusing optics designed for the ILC collider...|$|E
