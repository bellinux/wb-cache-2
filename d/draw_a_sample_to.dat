0|10000|Public
40|$|Second edition. Introduction the {{compelling}} case for data literacy [...] Speaking the language correctly [...] Creating {{a snapshot of}} data with a picture [...] Presenting a mountain of data with one number [...] Understanding why the range in your data is important [...] <b>Drawing</b> <b>a</b> <b>sample</b> <b>to</b> represent the whole group [...] Putting your ideas and assumptions to the test [...] T-tests : examining differences between two groups [...] ANOVA : what if {{there are more than}} two groups? [...] Chi-square: examining distributions for differences [...] Correlations : detecting relationships [...] Reporting your data clearly and strategically...|$|R
50|$|Unbeknownst to Molly Director Sparks is {{planning}} to covertly bring her in for further study with a medical team. Her doctor Dr. Barton, arrives that night <b>to</b> <b>draw</b> <b>a</b> blood <b>sample</b> <b>to</b> determine the DNA of Molly's unborn fetus. Later, Molly reveals to John she is pregnant and that she is afraid he wouldn't believe her.|$|R
3000|$|... -test. We {{afterwards}} randomly <b>draw</b> <b>a</b> {{number of}} <b>samples</b> <b>to</b> {{be used as}} the training set and employed the rest as a testing set. The number of training points are chosen to be small to keep the small <b>sample</b> setting, and <b>to</b> have a large enough testing set. This was repeated [...]...|$|R
40|$|Efficient {{management}} of school lunch programs involves {{the operation of}} the food service to provide attractive, palatable and nutritionally adequate meals and the realization of the educational potentialities of such programs. These are recognized as important management aspects of feeding children at school. This bulletin reports results of a survey of management aspects of school lunch programs in 25 Iowa schools which were <b>drawn</b> as <b>a</b> <b>sample</b> <b>to</b> represent the 622 Iowa schools in which full meals were served during the 1948 - 49 school year. The survey was made in connection with a regional study of the nutritional status of school children and the influence of the school lunch upon it...|$|R
50|$|In {{fields such}} as epidemiology, social sciences, {{psychology}} and statistics, <b>an</b> observational study <b>draws</b> inferences from <b>a</b> <b>sample</b> <b>to</b> <b>a</b> population where the independent variable is not {{under the control of}} the researcher because of ethical concerns or logistical constraints. One common observational study is about the possible effect of a treatment on subjects, where the assignment of subjects into a treated group versus a control group is outside the control of the investigator. This is in contrast with experiments, such as randomized controlled trials, where each subject is randomly assigned to a treated group or a control group.|$|R
40|$|Abstract: Generalized random {{tessellation}} stratified (GRTS) samples are useful spatial <b>sampling</b> designs for <b>a</b> number of reasons. But, actually <b>drawing</b> <b>a</b> GRTS <b>sample</b> {{can be so}} complicated that some practitioners opt for a simpler design. In this paper, I describe a computer program designed <b>to</b> draw GRTS <b>samples</b> of discrete sample units that are located in either 1 -dimension or 2 -dimension. This program, S-Draw, is a Fortran-based application that will run on any computer running a Windows operating system. The GRTS <b>sampling</b> program reads <b>a</b> <b>sample</b> frame from <b>a</b> standard ASCII file, and writes the sample in another ASCII file. While {{the existence of this}} program will not illuminate the theoretical details and justification of GRTS samples, it will, I hope, make <b>drawing</b> <b>a</b> GRTS <b>sample</b> accessible <b>to</b> non-statistically inclined researchers...|$|R
40|$|This paper {{describes}} the “Bounded Memory, Inertia, Sampling and Weighting” (BI-SAW) model, {{which won the}} [URL] Entry Prediction Competition in 2010. The BI-SAW model refines the I-SAW Model (Erev et al. [1]) by adding the assumption of limited memory span. In particular, we assume when players <b>draw</b> <b>a</b> small <b>sample</b> <b>to</b> weight against the average payoff of all past experience, they can only recall 6 trials of past experience. On the other hand, we keep all other key features of the I-SAW model: (1) Reliance on <b>a</b> small <b>sample</b> of past experiences, (2) Strong inertia and recency effects, and (3) Surprise triggers change. We estimate this model using {{the first set of}} experimental results run by the competition organizers, and use it to predict results of a second set of similar experiments later ran by the organizers. We find significant improvement in out-of-sample predictability (against the I-SAW model) in terms of smaller mean normalized MSD, and such result is robust to resampling the predicted game set and reversing the role of the sets of experimental results. Our model’s performance is the best among all the participants. learning; market entry game; prediction competition...|$|R
40|$|This paper {{describes}} the 'Bounded Memory, Inertia, Sampling and Weighting' (BI-SAW) model, {{which won the}} [URL] Entry Prediction Competition in 2010. The BI-SAW model refines the I-SAW Model (Erev et al. [1]) by adding the assumption of limited memory span. In particular, we assume when players <b>draw</b> <b>a</b> small <b>sample</b> <b>to</b> weight against the average payoff of all past experience, they can only recall 6 trials of past experience. On the other hand, we keep all other key features of the I-SAW model: (1) Reliance on <b>a</b> small <b>sample</b> of past experiences, (2) Strong inertia and recency effects, and (3) Surprise triggers change. We estimate this model using {{the first set of}} experimental results run by the competition organizers, and use it to predict results of a second set of similar experiments later ran by the organizers. We find significant improvement in out-of-sample predictability (against the I-SAW model) in terms of smaller mean normalized MSD, and such result is robust to resampling the predicted game set and reversing the role of the sets of experimental results. Our model's performance is the best among all the participants...|$|R
40|$|In {{order to}} make {{statistical}} inference, that is <b>drawing</b> conclusions from <b>a</b> <b>sample</b> <b>to</b> describe <b>a</b> population, {{it is crucial to}} know the correct distribution of the data. This paper focused on censored data from the normal distribution. The purpose of this paper was to answer whether we can test if data comes from a censored normal distribution. This by using normality tests and tests designed for censored data and investigate if we got correct size of these tests. This has been carried out with simulations in the program R for left censored data. The results indicated that with increasing censoring normality tests failed to accept normality in <b>a</b> <b>sample.</b> On the other hand the censoring tests met the requirements with increasing censoring level, which was the most important conclusion in this paper. ...|$|R
40|$|When {{exploring}} a game {{over a large}} strategy space, {{it may not be}} feasible or cost-effective to evaluate the payoff of every relevant strategy profile. For example, determining a profile payoff for a procedurally defined game may require Monte Carlo simulation or other costly computation. Analyzing such games poses a search problem, with the goal of identifying equilibrium profiles by evaluating payoffs of candidate solutions and potential deviations from those candidates. We propose two algorithms, applicable to distinct models of the search process. In the revealed-payoff model, each search step determines the exact payoff for a designated purestrategy profile. In the noisy-payoff model, <b>a</b> step <b>draws</b> <b>a</b> stochastic <b>sample</b> corresponding <b>to</b> such <b>a</b> payoff. We compare our algorithms to previous proposals from the literature for these two models, and demonstrate performance advantages. 1...|$|R
40|$|We {{develop an}} {{algorithm}} for simulating "perfect" random {{samples from the}} invariant measure of a Harris recurrent Markov chain. The method uses backward coupling of embedded regeneration times, and works most effectively for finite chains and for stochastically monotone chains even on continuous spaces, where paths may be sandwiched below "upper" and "lower" processes. Examples show that more naive approaches to constructing such bounding processes may be considerably biased, but that the algorithm can be simplified in certain cases {{to make it easier}} to run. We give explicit analytic bounds on the backward coupling times in the stochastically monotone case. An application of the simpler algorithm to storage models is given. 1 Introduction There has been considerable recent work on the development and application of algorithms that will enable the simulation of the invariant measure ß of a Markov chain, either exactly (that is, by <b>drawing</b> <b>a</b> random <b>sample</b> known <b>to</b> be from ß) or approximat [...] ...|$|R
40|$|The {{determination}} of <b>sample</b> size is <b>a</b> common task for many organizational researchers. Inappropriate, inadequate, or excessive <b>sample</b> sizes continue <b>to</b> influence {{the quality and}} accuracy of research. This manuscript describes the procedures for determining sample size for continuous and categorical variables using Cochran’s (1977) formulas. A discussion and illustration of sample size formulas, including the formula for adjusting the sample size for smaller populations, is included. A table is provided {{that can be used}} <b>to</b> select the <b>sample</b> size for <b>a</b> research problem based on three alpha levels and a set error rate. Procedures for determining the appropriate sample size for multiple regression and factor analysis, and common issues in sample size determination are examined. Non-respondent sampling issues are addressed. I n troduct ion A common goal of survey research is to collect data representative of a population. The researcher uses information gathered from the survey to generalize findings from <b>a</b> <b>drawn</b> <b>sample</b> back <b>to</b> <b>a</b> population...|$|R
40|$|YouGov {{constructed}} the CCES survey <b>sample</b> by first <b>drawing</b> <b>a</b> target <b>sample</b> designed <b>to</b> {{be representative of}} the American adult population. This <b>sample</b> was <b>drawn</b> with <b>a</b> <b>sampling</b> frame of U. S. citizens from the American Community Survey, which was matched with additional data from the Current Population Survey Supplement and the Pew Religious Landscape Survey. The target sample was thus representative of the population on demographic characteristics (gender, age, race, marital status, education, income, region and urbanicity of residence), political covariates (party identification, ideology, voter registration status, and interest in politics), and religion (affiliation and attendance of religious services). For each member of the target sample, proximity matching techniques were then used to identify survey respondents who were as similar as possible <b>to</b> target <b>sample</b> members. Finally, weights were calculated so that the final sample would be similar to the adult population on these characteristics. For more details on this process, see Vavreck and Rivers 2008. When compared with actual election results, estimates from CCES 2010 state-level <b>samples</b> were found <b>to</b> exhibit error rates similar to that expected from random sampling (Ansolabehere 2012). Since the launch of the CCES in 2005, data from the study have been used in more than 50 studies published in peer-reviewed journals (CCES 2013) ...|$|R
40|$|Over the years, breath {{testing has}} become a widely used method for {{quantitative}} determination {{of the level of}} intoxication of individuals suspected of driving while under the influence of alcohol. After recognition of the need for quantitative assessment of intoxication, blood alcohol concentration was considered as the single most important variable. However concern about the invasiveness requirements of <b>drawing</b> <b>a</b> blood <b>sample</b> led <b>to</b> the development of the breath test as a non-invasive means of assessing level of intoxication. The breath test is an indirect test, but has been considered to be a good estimate of the blood alcohol concentration because of the assumption that <b>an</b> end-exhaled breath <b>sample</b> accurately reflects the alveolar (or deep-lung) air which is in equilibrium with the blood. In spite of the great deal of effort that has gone into the studies attempting to validate the breath test, forensic scientists and toxicologists still have a very limited understanding of the breath alcohol test and its limitations. 2 ANATOMY OF THE LUNGS The lungs are located within the chest. This organ allows inspired air to come into close proximity with the blood so gases (such as oxygen and carbon dioxide) ca...|$|R
40|$|Over the years, breath {{testing has}} become a widely used method for {{quantitative}} determination {{of the level of}} intoxication of individuals suspected of driving while under the influence of alcohol. After recognition of the need for quantitative assessment of intoxication, blood alcohol concentration was considered as the single most important variable. However concern about the invasiveness requirements of <b>drawing</b> <b>a</b> blood <b>sample</b> led <b>to</b> the development of the breath test as a non-invasive means of assessing level of intoxication. PHYSIOLOGY OF THE LUNGS The lungs are located within the chest. The organ allows inspired air to come into close proximity with the blood so gases (such as oxygen and carbon dioxide) can exchange between the air and the blood. The lung is made up of over 300 million small air sacs called alveoli. Outside air comes to the alveoli from the mouth or nose via the airways. The major airway leading to the lungs from the throat is the trachea. The trachea divides into the left and right "mainstem bronchi " (going to the left and right lungs) which divide further into the "lobar bronchi". This division goes on about 23 time...|$|R
40|$|The {{paradox of}} enjoying {{listening}} to music that evokes sadness {{is yet to be}} fully understood. Unlike prior studies that have explored potential explanations related to lyrics, memories, and mood regulation, we investigated the types of emotions induced by unfamiliar, instrumental sad music, and whether these responses are consistently associated with certain individual difference variables. One hundred and two participants were <b>drawn</b> from <b>a</b> representative <b>sample</b> <b>to</b> minimise self-selection bias. The results suggest that the emotional responses induced by unfamiliar sad music could be characterized in terms of three underlying factors: Relaxing sadness, Moving sadness, and Nervous sadness. Relaxing sadness was characterized by felt and perceived peacefulness and positive valence. Moving sadness captured an intense experience that involved feelings of sadness and being moved. Nervous sadness was associated with felt anxiety, perceived scariness and negative valence. These interpretations were supported by indirect measures of felt emotion. Experiences of Moving sadness were strongly associated with high trait empathy and emotional contagion, but not with other previously suggested traits such as absorption or nostalgia-proneness. Relaxing sadness and Nervous sadness were not significantly predicted by any of the individual difference variables. The findings are interpreted within a theoretical framework of embodied emotions...|$|R
40|$|There is no {{recognised}} {{legal structure}} for social enterprises operating in South Africa {{and as a}} result many are running two or more legal entities. This has created confusion and skepticism in the market place, specifically when it comes to funding these enterprises. By using both qualitative and quantitative methods, this research study <b>draws</b> from <b>a</b> small <b>sample</b> <b>to</b> create <b>an</b> understanding of the dynamics that social entrepreneurs are faced with when choosing an appropriate structure. It then <b>draws</b> <b>a</b> correlation between South African social enterprises and those internationally in order to compare the revenue generated from earned income and grant funding. Furthermore, the research compares and discusses the correlations between the forprofit and non-profit social enterprises and how these compare with regards to generating revenue and sustaining their activities. It outlines some important principles of social enterprises which include that they: (1) are mission focused, (2) can access funding in order to scale, (3) earn sufficient income to sustain their operations and (4) provide a social return on investment. The research highlights both similarities and differences between the various entities and suggests an optimal framework for the South African context that guides social entrepreneurs, investors and funders of social enterprises. CopyrightDissertation (MBA) [...] University of Pretoria, 2012. Gordon Institute of Business Science (GIBS) unrestricte...|$|R
5000|$|Mathematically, <b>a</b> <b>sampling</b> {{design is}} denoted by the {{function}} [...] {{which gives the}} probability of <b>drawing</b> <b>a</b> <b>sample</b> ...|$|R
3000|$|... is {{a mixture}} of Gaussian {{distribution}}s. <b>Sampling</b> from this, <b>a</b> distribution is very simple. First, <b>draw</b> <b>a</b> <b>sample</b> [...]...|$|R
30|$|Given {{the index}} j∗, <b>draw</b> <b>a</b> <b>sample</b> x′ in the {{interval}} i̇I_j^* with pdf i̇ϕ _j^*(x), i.e., i̇x' ∼ϕ _j^*(x).|$|R
2500|$|Suppose one {{randomly}} <b>draws</b> <b>a</b> <b>sample</b> of two observations X1 and X2 from {{a population}} in which values {{are assumed to}} have a continuous probability distribution ...|$|R
3000|$|Step two is a Monte-Carlo {{simulation}} {{to approximate}} P(w⃗^BR_i) for every business resource BR_i∈B⃗R⃗. We <b>draw</b> <b>a</b> <b>sample</b> from w⃗ {{and from all}} dependencies in the mission dependency model. We check for every BR [...]...|$|R
50|$|To fulfill OECD requirements, {{each country}} must <b>draw</b> <b>a</b> <b>sample</b> {{of at least}} 5,000 students. In small {{countries}} like Iceland and Luxembourg, where there are fewer than 5,000 students per year, an entire age cohort is tested. Some countries used much larger <b>samples</b> than required <b>to</b> allow comparisons between regions.|$|R
50|$|There are 20 balls—either {{black or}} white—in an urn. To {{estimate}} their respective numbers, you <b>draw</b> <b>a</b> <b>sample</b> of four balls {{and find that}} three are black and one is white. A good inductive generalization would be that there are 15 black and five white balls in the urn.|$|R
40|$|ABSTRACT The {{study was}} {{conducted}} in Palampur, Himachal Pradesh. Multi-stage stratified random <b>sampling</b> was used <b>to</b> <b>draw</b> <b>a</b> <b>sample</b> of 108 respondents. Based on sample survey, the study reveals that the garbage disposal outside the house was a major problem. Polythene was burnt along with other waste in both the communities. Waste recycling awareness was found to be higher in teaching community as compared to non-teaching community...|$|R
2500|$|Let A1 denote a set {{obtained}} by <b>drawing</b> <b>a</b> random <b>sample</b> of six measurements: ...|$|R
5000|$|Derivative-free {{optimization}} is {{a subject}} of mathematical optimization. This method is applied to a certain optimization problem when its derivatives are unavailable or unreliable. Derivate-free method establishes model based on sample function values or directly <b>draw</b> <b>a</b> <b>sample</b> set of function values without exploiting detailed model. Since it needs no derivatives, it cannot be compared to derivative-based methods.|$|R
40|$|In a multidatabase system (MDBS), some query {{optimization}} {{information related}} to local database systems may not be available {{at the global level}} because of local autonomy. To perform global query optimization, a method is required to derive the necessary local information. This paper presents a new method that employs <b>a</b> query <b>sampling</b> technique <b>to</b> estimate the cost parameters of an autonomous local database system. We introduce a classification for grouping local queries and suggest a cost estimation formula for the queries in each class. We present <b>a</b> procedure <b>to</b> <b>draw</b> <b>a</b> <b>sample</b> of queries from each class and use the observed costs of <b>sample</b> queries <b>to</b> determine the cost parameters by multiple regression. Experimental results indicate that the method is quite promising for estimating the cost of local queries in an MDBS...|$|R
3000|$|... <b>a</b> Rather than <b>drawing</b> <b>a</b> <b>sample</b> of {{targeted}} students and teachers, Iceland surveyed the entire population, which for PISA included all 15 year old students and and for TALIS included all teachers who teach ISCED level 2 students (usually aged between 11 and 16). Our study includes schools where these two populations overlapped, that is schools serving PISA students taught by TALIS teachers.|$|R
30|$|Needless <b>to</b> say, <b>sampling</b> {{frames are}} much more easily derived from {{centralized}} registers. If registers are available only at the local level, one has <b>to</b> <b>draw</b> <b>a</b> <b>sample</b> of localities and then, from those localities, draw samples from local registers. 8 These multi-stage cluster samples are (in statistical terms) less efficient than simple random samples and moreover, need more resources for their implementation.|$|R
3000|$|<b>A</b> simple random <b>sample</b> of the {{training}} data is <b>drawn</b> with <b>a</b> <b>sample</b> size about half the sample size of {{the training}} data.n [...]...|$|R
5000|$|Then, {{each step}} in the {{algorithm}} consists of first <b>drawing</b> <b>a</b> <b>sample</b> of the particle index [...] which will be propagated from [...] into the new step [...] These indexes are auxiliary variables only used as an intermediary step, hence {{the name of the}} algorithm. The indexes are drawn according to the likelihood of some reference point [...] which in some way is related to the transition model [...] (for example, the mean, <b>a</b> <b>sample,</b> etc.): ...|$|R
30|$|Random {{sampling}} is {{the simplest}} and widely used sampling technique. In random sampling, each item or element {{of the population has}} an equal chance of being selected at each <b>draw.</b> <b>A</b> <b>sample</b> is random if the method for obtaining the sample meets the criterion of randomness (each element having an equal chance at each draw). The actual composition of the sample itself does not determine {{whether or not it was}} <b>a</b> random <b>sample.</b>|$|R
40|$|The paper {{introduces}} the general design features and particularities {{of a new}} largescale panel study for research on recipients of benefits for the long-term unemployed (the so called Unemployment Benefit II) in Germany that combines <b>a</b> <b>sample</b> of 6000 recipient households with <b>an</b> equally large <b>sample</b> of the general population. Particular {{focus is on the}} sampling procedure for the general population, where a commercial database was used <b>to</b> <b>draw</b> <b>a</b> <b>sample</b> stratified by status. " (Author's abstract, IAB-Doku) ((en)) IAB-Haushaltspanel - Konzeption, empirische Sozialforschung, Erhebungsmethode, Stichprobe, Langzeitarbeitslosigkeit...|$|R
5000|$|Opinium {{surveys are}} {{conducted}} online via web interviewing, <b>drawing</b> <b>a</b> <b>sample</b> of {{responses from the}} company's panel of around 30,000 people. This sample {{is representative of the}} adult population of Great Britain in the areas of age, gender, regional location, working status and social grade, as according to the latest Office for National Statistics data. Responses from different demographic groups are handled appropriately to compensate for differential response rates in these different groups.|$|R
40|$|<b>Drawing</b> <b>a</b> <b>sample</b> of {{data that}} {{adequately}} represents the population from which it was <b>drawn</b> can be <b>a</b> difficult task. Biases are often introduced in this initial phase of statistical analyses. The paper addresses the sampling problem in relation to traditional author co-citation analysis. It identifies common biases (misrepresentation of different theoretical orientations within the domain of study, national differences, misrepresentation of document types, ISI data) and discusses possible alternatives (“authoritative ” lists of authors, PFNETs, domain analysis). It concludes that conducting a proper domain analysis before starting the <b>sampling</b> procedure seems <b>to</b> be the only good answer <b>to</b> the <b>sampling</b> problem...|$|R
