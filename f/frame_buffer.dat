431|167|Public
25|$|With severe {{resource}} limitations {{including a}} mere 128 bytes of RAM and no video <b>frame</b> <b>buffer,</b> the 2600 {{is considered to}} be a difficult machine to program. However, tools such as emulators, the batari Basic language, and a wealth of documentation, exist to assist the homebrewer.|$|E
25|$|The BBC B+ and {{the later}} Master {{provided}} 'shadow modes', where the 1–20KB <b>frame</b> <b>buffer</b> was stored in an alternative RAM bank, freeing the main memory for user programs. This feature was requested by setting bit 7 of the mode variable, i.e. by requesting modes 128–135.|$|E
25|$|The 68000 {{and video}} {{controller}} took turns accessing DRAM every four CPU cycles during {{display of the}} <b>frame</b> <b>buffer,</b> while the 68000 had unrestricted access to DRAM during vertical and horizontal blanking intervals. Such an arrangement reduced the overall performance of the CPU as much as 35% for most code as the display logic often blocked the CPU's access to RAM. This made the machine run more slowly than several of its competitors, despite the nominally high clock rate.|$|E
5000|$|RAM {{configured}} into 4 Megabytes for <b>frame</b> <b>buffer(s)</b> and Z-buffer and 4 or 8 Megabytes texture memory.|$|R
5000|$|VRAM (Video {{random access}} memory) An older type of {{dual-ported}} memory once {{used for the}} <b>frame</b> <b>buffers</b> of video adapters (video cards).|$|R
40|$|Algorithms for {{approximately}} optimal quantization of color images are discussed. The distortion measure used is the distance in RGB space. These algorithms {{are used to}} compute the color map for low-depth <b>frame</b> <b>buffers</b> {{in order to allow}} high-quality static images to be displayed. It is demonstrated that most color images can be very well displayed using only 256 or 512 colors. Thus <b>frame</b> <b>buffers</b> of only 8 or 9 bits can display images that normally require 15 bits or more per pixel...|$|R
25|$|The Atari 2600 is {{generally}} considered to be a very demanding programming environment, with a mere 128 bytes of RAM available without additional hardware, and no video <b>frame</b> <b>buffer</b> at all. The programmer must prepare each line of video output one at a time as it is being sent to the television. The only sprite capabilities the 2600 offers are one-dimensional 1-bit and 8-bit patterns; creating a two-dimensional object requires changing the pattern between each line of video.|$|E
2500|$|OpenGL 3.0 - GLSL 1.3, Texture Arrays, Conditional rendering, <b>Frame</b> <b>Buffer</b> Object (FBO) ...|$|E
2500|$|Jim Kajiya – {{computer}} scientist; {{developed the}} <b>frame</b> <b>buffer</b> concept for storing and displaying single-raster images and the rendering equation ...|$|E
5000|$|Joel McCormack. Writing Fast X Servers for Dumb Color <b>Frame</b> <b>Buffers,</b> Research Report 91/1, Digital Equipment Corporation, Western Research Laboratory, February 1991. of the Software: Practice and Experience paper listed {{immediately}} below.|$|R
50|$|The quad-buffered mode allows {{developers}} {{to control the}} rendering, avoiding the automatic mode of the driver and just presenting the rendered stereo picture to left and right <b>frame</b> <b>buffers</b> with associated back buffers.|$|R
50|$|Arcade system boards {{have been}} using {{specialized}} graphics chips since the 1970s. In early video game hardware, the RAM for <b>frame</b> <b>buffers</b> was expensive, so video chips composited data together as the display was being scanned out on the monitor.|$|R
2500|$|It {{includes}} enhancements to Direct2D, DirectWrite, Direct3D, Windows Imaging Component (WIC), Windows Advanced Rasterization Platform (WARP), Windows Animation Manager (WAM), XPS Document API, H.264 Video Decoder and JPEG XR decoder. However {{support for}} Direct3D 11.1 is limited as the update {{does not include}} DXGI/WDDM 1.2 from Windows 8, making unavailable many related [...] APIs and significant features such as stereoscopic <b>frame</b> <b>buffer,</b> feature level 11_1 and optional features for levels 10_0, 10_1 and 11_0.|$|E
2500|$|Memory {{managers}} on 386-based systems (such as QEMM or MEMMAX (+V) in DR-DOS) {{could achieve}} the same effect, adding conventional memory at 640 KB and moving the barrier to 704 KB (up to segment B000, the start of MDA/HGC) or 736 KB (up to segment B800, {{the start of the}} CGA). [...] Only CGA could be used in this situation, because Enhanced Graphics Adapter (EGA) video memory was immediately adjacent to the conventional memory area below the 640 KB line; the same memory area could not be used both for the <b>frame</b> <b>buffer</b> of the video card and for transient programs.|$|E
50|$|Graphics {{capability}} {{was provided}} by two <b>frame</b> <b>buffer</b> modules, the monochrome and color <b>frame</b> <b>buffer.</b> The monochrome <b>frame</b> <b>buffer</b> supports 1-bit color and a resolution of 1024 × 864 pixels, while the color <b>frame</b> <b>buffer</b> supports 8-bit color and the same resolution as the monochrome <b>frame</b> <b>buffer.</b> Both frame buffers use the Brooktree Bt478 RAMDAC with three 256-entry, 8-bit color maps. The hardware cursor is generated by DC503 PCC (Programmable Cursor Chip), which can provide a 16 × 16 pixel, 2-bit color cursor. The color <b>frame</b> <b>buffer</b> has an 8-bit write mask, used to select which pixel(s) are to be updated. None of the framebuffers use all the memory provided by the <b>frame</b> <b>buffer</b> module, the color frame buffer's VRAM is organized as 2048 × 1024 pixels and the monochrome <b>frame</b> <b>buffer,</b> 1024 × 1024, but only the leftmost pixels are displayed in the color <b>frame</b> <b>buffer</b> and the topmost pixels in the monochrome <b>frame</b> <b>buffer.</b> Unused areas of the VRAM {{may be used to}} store graphical structures such as fonts. The frame buffers are not parity-protected, unlike the rest of the system memory. A DB15 male connector is used for video. The connector uses RS343A/RS170 compatible signals.|$|E
50|$|They are {{distinct}} from GPUs, which contain specialised hardware for rasterization and texture mapping (for 3D graphics), and whose memory architecture is optimised for manipulating bitmap images in off-chip memory (reading textures, and modifying <b>frame</b> <b>buffers,</b> with random access patterns).|$|R
30|$|The color {{quantization}} of {{an image}} {{is a process that}} uses a limited number of colors to represent an image; it is widely used in image segmentation, image retrieval, and image compression [17]. The objective is to approximate as closely as possible the original full-color images. This technique is necessary for systems that can display only a few colors. For example, systems with 8  bits/pixel <b>frame</b> <b>buffers</b> can display only 256 colors. Although various modern systems have 24  bits/pixel <b>frame</b> <b>buffers</b> and can display 224 [*]=[*] 16, 777, 216 colors, color quantization is still practical for system running animations and those used for advanced graphics applications. It reduces storage requirements and saves image transmission time over networks [17].|$|R
5000|$|Joel McCormack. Writing Fast X Servers for Dumb Color <b>Frame</b> <b>Buffers,</b> Software - Practice and Experience, Vol 20(S2), John Wiley & Sons, Ltd., West Sussex, England, October 1990, pp. 83-108. and {{reprinted in}} the Japanese edition of UNIX Magazine, ASCII Corp., October 1991, pp. 76-96.|$|R
50|$|The Personal DECstation {{features}} an integrated 8-bit color <b>frame</b> <b>buffer</b> {{capable of a}} resolution of 1024 × 768 at a refresh rate of 72 Hz. The <b>frame</b> <b>buffer</b> consists of 1 MB of VRAM organized as 262,144 32-bit words, with each 32-bit word containing four 8-bit pixels. The <b>frame</b> <b>buffer</b> uses an INMOS IMS G332 RAMDAC with a 256-entry 24-bit color look up table, which selects 256 colors for display out of a palette of 16,777,216. The <b>frame</b> <b>buffer</b> is treated {{as part of the}} memory subsystem.|$|E
5000|$|... x11vnc keeps {{a copy of}} the X server's <b>frame</b> <b>buffer</b> in RAM. The X11 {{programming}} interface XShmGetImage is used {{to retrieve}} the <b>frame</b> <b>buffer</b> pixel data. x11vnc compares the X server's <b>frame</b> <b>buffer</b> against its copy to see which pixel regions have changed (and hence need to be sent to the VNC viewers.) Reading pixel data from the physical <b>frame</b> <b>buffer</b> can be much slower than writing to it (because graphics devices are not optimized for reading) and so a sequential pixel by pixel check would often be too slow.|$|E
50|$|The {{conventional}} way to {{draw the}} playfield {{is to use a}} bitmap held in a <b>frame</b> <b>buffer,</b> in which each memory location in the <b>frame</b> <b>buffer</b> represents one or more locations on the screen. In the case of the 2600, which normally used a resolution of 160x192 pixels, a <b>frame</b> <b>buffer</b> would need to have at least 160x192/8 = 3840 bytes of memory. Built in an era where RAM was very expensive, the TIA could not afford this solution.|$|E
25|$|In 1994, DEC {{launched}} a new range of AlphaStation and AlphaServer systems. These used 21064 or 21164 processors and introduced the PCI bus, VGA-compatible <b>frame</b> <b>buffers</b> and PS/2-style keyboards and mice. The AlphaServer 8000 series superseded the DEC 7000/10000 AXP and also employed XMI and FutureBus+ buses.|$|R
40|$|RS-PC) decoder for DVD {{applications}} is presented. It mainly con-tains two frame-buffer controllers, a (182, 172) row RS decoder, and a (208, 192) column RS decoder. The RS decoder {{features an}} area-efficient key equation solver using a novel modified decomposed inversionless Berlekamp–Massey algorithm. The proposed RS-PC decoder solution was implemented using 0. 6 - m CMOS single-poly double-metal (SPDM) standard cells. The chip size is 4 22 3 64 mm 2 with a core area of 2 90 2 88 mm 2, where the total gate count is about 26 K. Test {{results show that}} the proposed RS-PC decoder chip can support 4 DVD speed with off-chip <b>frame</b> <b>buffers</b> or 8 DVD speed with embedded <b>frame</b> <b>buffers</b> operating at 3 V. Index Terms—Reed–Solomon Product-Code decoder, DVD, de-composed inversionless Berlekamp–Massey algorithm...|$|R
40|$|For {{the last}} decade, the {{research}} in CSCW (Computer Supported Cooperative Work) has been focusing on synchronous collaboration, which requires the participants involved in common tasks to remotely share computer display workspaces simultaneously without leaving their workplaces. However, to support truly global cooperative work, asynchronous collaboration is equally prominent, {{in order to accommodate}} the participants who may not be available for the synchronous CSCW session. These participating individuals, whether working synchronously or asynchronously, may be mobile and may have to connect to and disconnect from the session repeatedly with ubiquitous systems. In this research paper, we describe a framework for asynchronous as well as synchronous collaboration. The framework provides facilities to transfer the screen images or <b>frame</b> <b>buffers</b> of the ongoing CSCW session to remote users, allowing the available participants to share the view and the control of the session simultaneously, and to record the screen images or <b>frame</b> <b>buffers</b> for the absent participants to retrieve and playback the session at a later stage, with VCR-like control (i. e. fast forward, rewind, play and stop). The <b>frame</b> <b>buffers</b> are transferred and recorded in units of rectangles containing pixel values of the screen images. These rectangles are platform independent and can be dynamically directed to and displayed by heterogeneous systems such as X Windows or Windows NT, or by Web browser such as Netscape...|$|R
50|$|The 29116 {{microprocessor}} periodically checked a work queue {{set up in}} {{the memory}} using DMA and executed commands from that queue. The commands performed BitBlt operations within the <b>frame</b> <b>buffer,</b> between the system memory and <b>frame</b> <b>buffer</b> and were also used to paint characters from the font cache.|$|E
5000|$|Side-port {{memory as}} local <b>frame</b> <b>buffer,</b> {{supporting}} DDR2 and GDDR3 ...|$|E
50|$|Side-port {{memory as}} local <b>frame</b> <b>buffer,</b> {{supporting}} DDR2 and GDDR3 chips.|$|E
50|$|The TGA {{file format}} was {{originally}} defined and specified by AT&T EPICenter with feedback from Island Graphics Inc in 1984. AT&T EPICenter was an internal spin-off of AT&T created to market new technologies AT&T had developed for color <b>frame</b> <b>buffers.</b> What later became Truevision {{was the result}} of a leveraged employee buyout from AT&T in 1987.|$|R
40|$|High-speed {{evaluation}} {{of a large number}} of polynomial expressions has potential applications in the modeling and real-time display of objects in computer graphics. Using VLSI techniques, chips called pixel planes have been built by Fuchs and his group to evaluate linear expressions on <b>frame</b> <b>buffers.</b> Extending the linear evaluation to quadratic evaluation, however, has resulted in the loss of regularity of interconnection among the cells. In this paper, we present two types of organizations for <b>frame</b> <b>buffers</b> of m × m pixels: one, a single wavefront complex cell array requiring O(m^ 2 n) space and the other a simple cell multiple wavefront array with O(m^ 2) area and O(n^ 2) wavefronts. Both these organizations have two main advantages over the earlier proposed method. The cells and the interconnection among them are regular and hence are suitable for efficient VLSI implementation. The organization also permits {{evaluation of}} higher order polynomials...|$|R
40|$|Described is a {{hardware}} architecture for combining the outputs {{of a number}} of zbuffer rendering engines to achieve higher performance than is possible with a single renderer. It allows a combination of renderers to achieve the same price/performance ratio as the individual renderers that compose it, and can be extended to create systems with arbitrarily high performance. The described architecture is based on a fusion of scan-line rendering and the conventional z-buffer algorithm. The <b>frame</b> <b>buffers</b> of several z-buffer engines are modified to scan out z-values as well as color values. Multiplexing devices combine the z/color streams from each pair of frame-buffers. These z/color streams are then combined by further multiplexers, creating a binary tree that funnels the z/color information from the many conventional <b>frame</b> <b>buffers</b> into a single z/color stream. The color stream is then used to drive a standard display device. The proposed architecture allows rendering rates of [...] ...|$|R
5000|$|Seamless {{support for}} framebuffer objects, pbuffers and <b>frame</b> <b>buffer</b> render-to-texture effects ...|$|E
5000|$|Side-port {{memory as}} local <b>frame</b> <b>buffer,</b> {{supporting}} DDR2 and GDDR3 chips (780G only) ...|$|E
5000|$|OpenGL 3.0 - GLSL 1.3, Texture Arrays, Conditional rendering, <b>Frame</b> <b>Buffer</b> Object (FBO) ...|$|E
40|$|Abstmct-High-speed {{evaluation}} {{of a large number}} of poly-nomial expressions has potential applications in the modeling and real-time display of objects in computer graphics. Using VLSI techniques, chips called pixel planes have been built by Fuchs and his group to evaluate linear expressions on <b>frame</b> <b>buffers.</b> Extending the linear evaluation to quadratic evaluation, however, has resulted in the loss of regularity of interconnec-tion among the cells. In this paper, we present two types of organizations for <b>frame</b> <b>buffers</b> of m xm pixels: one, a single wavefront complex cell array requiring O(m 2 n) space and the other a simple cell multiple wavefront array with O(m 2) area and O(n 2) wavefronts. Both these organizations have two main advantages over the earlier proposed method. The cells and the interconnection among them are regular and hence are suitable for efficient VLSI implementation. The organization also per-mits {{evaluation of}} higher order polynomials. Index Terms- Computer graphics, polygon scan conversion, polynomial expression evaluation, systolic arrays, VLSI...|$|R
40|$|This paper {{describes}} a visualization architecture for scalable computer systems. The architecture {{is currently being}} prototyped for use in Beowulf-class clustered systems. A set of OpenGL <b>frame</b> <b>buffers</b> are driven in parallel {{by a set of}} CPUs. The visualization architecture merges the contents of these <b>frame</b> <b>buffers</b> by userprogrammable associative and commutative combining operations. The system hardware is built from off-the-shelf components including OpenGL accelerators, Field Programmable Gate Arrays (FPGAs), and gigabit network interfaces and switches. A secondgeneration prototype supports 60 Hz operation at 1024 # 1024 pixel resolution with interactive latency up to 1000 nodes. CR Categories: B. 7. 1 [Integrated circuits]: Types and design styles [...] -Gate arrays; C. 2. 5 [Computer-communication networks]: Local and wide-area networks [...] -High-speed; D. 1. 3 [Programming techniques]: Concurrent programming [...] -Parallel programming; I. 3. 1 [Computer graphics]: Hardware architecture [...] -Parallel processing; I. 3. 2 [Computer graphics]: Graphics systems [...] - Distributed/network graphics Keywords: FPGA, OpenGL, visualization, cluster, Beowulf, gigabit, fat-tree...|$|R
40|$|In {{this paper}} a multiresolution {{architecture}} {{to expand the}} dynamic range of low dynamic range (LDR) images to 32 -bit high dynamic range (HDR) counterpart is presented. The processor is capable to provide on-the-fly calculation of the edge-preserving bilateral filtering and luminance average, to images images up to full-HD images (1920 × 1080 pixels) using 25 × 9 filtering and up to 4 K UHDTV images (3840 × 2160 pixels) using 25 × 5 filtering without <b>frame</b> <b>buffers.</b> To this end, a "hardware friendly" algorithm has been derived from the most effective methods presented in the literature. Additionally, the proposed design is capable of processing the input pixel in streaming order, as they come from input devices by avoiding <b>frame</b> <b>buffers</b> and eliminating external DRAM. The processor complexity can be configured with different area/speed ratios {{in order to meet}} the requirements of different FPGA platforms. Implemented on a high-end FPGA the processor achieves state-of-the art performances...|$|R
