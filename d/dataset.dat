10000|10000|Public
5|$|In {{addition}} to the four storms in the <b>dataset,</b> according to the Joint Typhoon Warning Center and Japan Meteorological Agency, on October22 Tropical Storm Alice crossed the International Dateline, entering into CPHC's area of responsibility. The storm eventually became extratropical on October23 over open waters.|$|E
25|$|Suppose the {{original}} <b>dataset</b> D contains the n spectra in rows. The signals of {{the original}} <b>dataset</b> are generally preprocessed. The original spectra are compared to a reference spectrum. By subtracting a reference spectrum, often the average spectrum of the <b>dataset,</b> so called dynamic spectra are calculated which form the corresponding dynamic <b>dataset</b> E. The presence and interpretation may be dependent on the choice of reference spectrum. The equations below are valid for equally spaced measurements of the perturbation.|$|E
25|$|Google Earth, {{satellite}} and aerial photos <b>dataset</b> (including commercial DigitalGlobe images) with international road <b>dataset,</b> the first popular virtual globe along with NASA World Wind.|$|E
30|$|We study all 22 {{heuristics}} {{covering a}} large range of datasets: 4 real <b>datasets,</b> 20 <b>datasets</b> from TSPLIB benchmark [30], 2 existing synthetic <b>datasets</b> [21] and new synthetic <b>datasets.</b>|$|R
40|$|Modern {{technologies}} {{have resulted in}} the production of numerous high-throughput biological <b>datasets.</b> However, the pace of development of capable computational methods does not cope with the pace of generation of new high-throughput <b>datasets.</b> Amongst the most popular biological high-throughput <b>datasets</b> are gene expression <b>datasets</b> (e. g. microarray <b>datasets).</b> This work targets this aspect by proposing a suite of computational methods which can analyse multiple gene expression <b>datasets</b> collectively. The focal method in this suite is the unification of clustering results from multiple <b>datasets</b> using external specifications (UNCLES). This method applies clustering to multiple heterogeneous <b>datasets</b> which measure the expression of the same set of genes separately and then combines the resulting partitions in accordance to one of two types of external specifications; type A identifies the subsets of genes that are consistently co-expressed in all of the given <b>datasets</b> while type B identifies the subsets of genes that are consistently co-expressed in a subset of <b>datasets</b> while being poorly co-expressed in another subset of <b>datasets.</b> This contributes to the types of questions which can addressed by computationa...|$|R
40|$|Marine {{protected}} areas (MPAs) {{can be an}} effective tool for marine biodiversity conservation, yet decision-makers usually have limited and biased <b>datasets</b> with which to make decisions about where to locate MPAs. Using commonly available abiotic and biotic <b>datasets,</b> I asked how many <b>datasets</b> are necessary to achieve robust patterns of conservation importance. I applied a decision support tool for marine protected area design in two regions of British Columbia, Canada, and sequentially excluded the <b>datasets</b> with the most limited geographic distribution. I found that the reserve selection method was robust to some missing <b>datasets.</b> The removal of up to 15 of the most geographically limited <b>datasets</b> did not significantly change the geographic patterns of the importance of areas for conservation. Indeed, including abiotic <b>datasets</b> plus at least 12 biotic <b>datasets</b> resulted in a spatial pattern similar to including all available biotic <b>datasets.</b> It was best to combine abiotic and biotic <b>datasets</b> in order to ensure habitats and species were represented. Patterns of clustering differed according to whether I used one set alone or both combined. Biotic <b>datasets</b> served as better surrogates for abiotic <b>datasets</b> than vice versa, and both represented more biodiversity features than randomly selected reserves. These results should provide encouragement to decision-makers engaged in MPA planning with limited spatial data...|$|R
25|$|YF-17 {{aircraft}} Plot: The featured image displays {{plots of}} a CGNS <b>dataset</b> representing a YF-17 jet aircraft. The <b>dataset</b> {{consists of an}} unstructured grid with solution. The image was created by using a pseudocolor plot of the dataset's Mach variable, a Mesh plot of the grid, and Vector plot of a slice through the Velocity field.|$|E
25|$|The UK Biobank <b>dataset</b> {{was opened}} to {{applications}} from researchers in March 2012.|$|E
25|$|The National Public Transport Gazetteer {{is closely}} {{associated}} with the NaPTAN <b>dataset</b> and contains details of every City, Town, Village, suburb in Great Britain (i.e., UK but not including Northern Ireland). This <b>dataset</b> is based on usage of names, rather than legal definitions and so includes local informal names for places as well as their official names.|$|E
40|$|Abstract. Linked Open Data (LOD) Cloud is a mesh of open <b>datasets</b> {{coming from}} {{different}} domains. Among these <b>datasets,</b> a notable amount of <b>datasets</b> {{belong to the}} life sciences domain linked together forming an interlinked “Life Sciences Linked Open Data (LSLOD) Cloud”. One of the key challenges for data publishers is to identify and establish links between newly generated domain specific <b>datasets</b> and LSLOD Cloud. While a number of publishing tools exist for creating links from new to existing <b>datasets,</b> tools to detect domain-specific relevant <b>datasets</b> for linking purposes are missing. In this paper, we propose an extended technique for automatically identifying relevant <b>datasets</b> in LSLOD Cloud for inner-ear anatomical and clinical terminologies. We validate the proposed technique with experiments over the publicly accessible LSLOD Cloud using real-world terminologies and <b>datasets</b> provided by clinical organizations. ...|$|R
50|$|On May 28, 2013, the Province of Alberta {{launched}} the Alberta Open Data Portal with approximately 244 <b>datasets.</b> As of September 2015, there are 1929 <b>datasets</b> {{available to the}} public, including <b>datasets</b> connected to GeoDiscover Alberta. In August 2015 a new portal open.alberta.ca was released to the public, adding further content to the <b>datasets</b> including Government of Alberta publications, a blog, descriptions of how both <b>datasets</b> and publications are chosen and published on the portal.|$|R
40|$|This study informs {{efforts to}} improve the {{discoverability}} of and access to biomedical <b>datasets</b> by providing a preliminary estimate of the number and type of <b>datasets</b> generated annually by research funded by the U. S. National Institutes of Health (NIH). It focuses on those <b>datasets</b> that are "invisible" or not deposited in a known repository. We analyzed NIH-funded journal articles that were published in 2011, cited in PubMed and deposited in PubMed Central (PMC) to identify those that indicate data were submitted to a known repository. After excluding those articles, we analyzed a random sample of the remaining articles to estimate how many and what types of invisible <b>datasets</b> were used in each article. About 12 % of the articles explicitly mention deposition of <b>datasets</b> in recognized repositories, leaving 88 % that are invisible <b>datasets.</b> Among articles with invisible <b>datasets,</b> we found an average of 2. 9 to 3. 4 <b>datasets,</b> suggesting there were approximately 200, 000 to 235, 000 invisible <b>datasets</b> generated from NIH-funded research published in 2011. Approximately 87 % of the invisible <b>datasets</b> consist of data newly collected for the research reported; 13 % reflect reuse of existing data. More than 50 % of the <b>datasets</b> were derived from live human or non-human animal subjects. In addition to providing a rough estimate {{of the total number of}} <b>datasets</b> produced per year by NIH-funded researchers, this study identifies additional issues that must be addressed to improve the discoverability of and access to biomedical research data: the definition of a "dataset," determination of which (if any) data are valuable for archiving and preservation, and better methods for estimating the number of <b>datasets</b> of interest. Lack of consensus amongst annotators about the number of <b>datasets</b> in a given article reinforces the need for a principled way of thinking about how to identify and characterize biomedical <b>datasets...</b>|$|R
25|$|In the {{training}} phase, evaluation task {{participants were asked}} to use a training <b>dataset</b> to induce the sense inventories for a set of polysemous words. The training <b>dataset</b> consisting of a set of polysemous nouns/verbs and the sentence instances that they occurred in. No other resources were allowed other than morphological and syntactic Natural Language Processing components, such as morpohological analyzers, Part-Of-Speech taggers and syntactic parsers.|$|E
25|$|Image-guided {{radiation}} therapy (IGRT) {{is the process}} of frequent two and three-dimensional imaging, during a course of radiation treatment, used to direct {{radiation therapy}} utilizing the imaging coordinates of the actual radiation treatment plan. The patient is localized in the treatment room in the same position as planned from the reference imaging <b>dataset.</b> An example of IGRT would include localization of a cone beam computed tomography (CBCT) <b>dataset</b> with the planning computed tomography (CT) <b>dataset</b> from planning. IGRT would also include matching planar kilovoltage (kV) radiographs or megavoltage (MV) images with digital reconstructed radiographs (DRRs) from the planning CT. These two methods comprise the bulk of IGRT strategies currently employed circa 2013.|$|E
25|$|Linking {{data from}} NHS {{hospital}} outpatient records and GP {{to the main}} <b>dataset</b> were being investigated in 2017.|$|E
50|$|Since the LINQ to SQL {{provider}} (above) {{works only}} with Microsoft SQL Server databases, {{in order to}} support any generic database, LINQ also includes the LINQ to <b>DataSets.</b> It uses ADO.NET to handle the communication with the database. Once the data is in ADO.NET <b>Datasets,</b> LINQ to <b>DataSets</b> execute queries against these <b>datasets.</b>|$|R
50|$|Common and Fundamental Operational <b>Datasets</b> (CODs) are {{critical}} <b>datasets</b> {{that are used}} to support the work of humanitarian actors across multiple sectors. They are considered a de facto standard for the humanitarian community and should represent the best-available <b>datasets</b> for each theme. The Fundamental Operational <b>Datasets</b> (FODs) are <b>datasets</b> that are relevant to a humanitarian operation, but are more specific to a particular sector or otherwise do not fit into one of the seven COD themes.|$|R
40|$|In various {{research}} areas, {{the availability}} of open <b>datasets</b> is considered as key for research and application purposes. These <b>datasets</b> are used as benchmarks to develop new algorithms and to compare them to other algorithms in given settings. Finding such available <b>datasets</b> for experimentation can be a challenging task in technology enhanced learning, as there are various sources of data {{that have not been}} identified and documented exhaustively. In this paper, we provide such an analysis of <b>datasets</b> {{that can be used for}} research on learning and knowledge analytics. First, we present a framework for the analysis of educational <b>datasets.</b> Then, we analyze existing <b>datasets</b> along the dimensions of this framework and outline future challenges for the collection and sharing of educational <b>datasets.</b> status: publishe...|$|R
25|$|More {{recently}} the Berkeley Earth Surface Temperature <b>dataset.</b> These datasets are updated frequently, and are generally in close agreement.|$|E
25|$|Release Small {{population}} <b>Dataset</b> SP1 (18 December 2014) – specific {{ethnic group}} or {{country of birth}} population by sex and age.|$|E
25|$|Data from NHS {{hospital}} inpatient records (England from 1996, Scotland from 1997 and Wales from 1998) {{were linked to}} the main <b>dataset</b> on an ongoing basis.|$|E
50|$|Disk-resident <b>datasets</b> {{used by a}} {{user program}} were 'local' to the {{individual}} job. Once a job completed, its local <b>datasets</b> would be released and space reclaimed. In order to retain the data between jobs, <b>datasets</b> had to be explicitly made 'permanent'. Magnetic tape <b>datasets</b> were also supported on Cray systems which were equipped with an I/O Subsystem.|$|R
40|$|One {{significant}} {{challenge to}} scaling entity resolution algorithms to massive <b>datasets</b> is understanding how performance changes after moving {{beyond the realm}} of small, manually labeled reference <b>datasets.</b> Unlike traditional machine learning tasks, when an entity resolution algorithm performs well on small hold-out <b>datasets,</b> there is no guarantee this performance holds on larger hold-out <b>datasets.</b> We prove simple bounding properties between the performance of a match function on a small validation set and the performance of a pairwise entity resolution algorithm on arbitrarily sized <b>datasets.</b> Thus, our approach enables optimization of pairwise entity resolution algorithms for large <b>datasets,</b> using a small set of labeled data...|$|R
40|$|D. Tech. Engineering Electrical. Developes {{and compare}} {{algorithms}} to restore sequences degraded by {{the effects of}} atmospheric turbulence with the focus placed on the removal of heat scintillation. Results in the dissertation were obtained using <b>datasets</b> divided into two categories: real <b>datasets</b> and simulated <b>datasets.</b> The real <b>datasets</b> consist of sequences obtained {{in the presence of}} real atmospheric turbulence. These <b>datasets</b> were obtained from the CSIR (Council for Scientific and Industrial Research) using their Cyclone camera and vary in range from 5 km- 15 km. The simulated sequences were generated using ground truth images/sequences. Both <b>datasets</b> can be further divided into sequences with real-motion and sequences without real motion...|$|R
25|$|A 2D {{synchronous}} spectrum {{expresses the}} similarity between spectral of the data in the original <b>dataset.</b> In generalized 2D correlation spectroscopy this is mathematically expressed as covariance (or correlation).|$|E
25|$|A third study (Yang, 2002) {{used the}} same <b>dataset</b> that Chen and Li used but {{estimated}} the ancestral effective population of 'only' ~12,000 to 21,000, using a different statistical method.|$|E
25|$|Based on the NOAA <b>dataset,</b> the {{following}} table lists the global combined land and ocean annually averaged temperature rank and anomaly {{for each of the}} 12 warmest years on record.|$|E
40|$|Several {{countries}} {{are planning a}} data-archive facility for historical <b>datasets.</b> In the archives the data will be extensively documented. A standardized way of describing the machine readable <b>datasets</b> will facilitate the exchange of information. The Standard Study Description Scheme used at the long existing social science data-archives is - in unaltered form - not applicable to historical <b>datasets.</b> There are many similarities between social scientific <b>datasets</b> and historical <b>datasets.</b> It is useful for historians to use a documentation standard that can be exchanged with the standards in use at social science data-archives. At {{the same time the}} specific demands of the historical <b>datasets</b> should be taken into consideration...|$|R
30|$|These {{acquired}} vibration {{signals are}} {{used to test the}} DBN-based fault diagnosis system. These vibration signals are divided into training <b>datasets</b> and testing <b>datasets</b> separately, and both <b>datasets</b> are randomized before being used in the DBN model.|$|R
40|$|<b>Datasets</b> {{comprising}} Poll Tax {{data for}} the parishes of All Hallows Honey Lane, St Martin Ironmonger Lane, St Mary Colechurch, St Mary le Bow and St Pancras Soper Lane, 1678 - 1694. These <b>datasets</b> have been drawn up to indicate property and household divisions more clearly than in the 'raw' <b>datasets</b> {{that can be found}} under the Source Specific <b>Datasets</b> collection...|$|R
25|$|Information from UK {{registries}} {{of death}} (from 2006) and cancer (Scotland from 1957, England and Wales from 1995) {{were linked to}} the main Biobank <b>dataset</b> on an ongoing basis.|$|E
25|$|Release Small {{population}} <b>Dataset</b> SP2 (18 December 2014) – separate ethnic group, {{religion or}} national identity by sex, age, economic activity, qualifications, provision of unpaid care and disability.|$|E
25|$|Zipf's law {{might be}} able to be used to {{indicate}} if a given <b>dataset</b> of animal communication indicate an intelligent natural language. Some researchers have used this algorithm to study bottlenose dolphin language.|$|E
40|$|Clustering {{has been}} widely used in {{different}} fields of science, technology, social science, and so forth. In real world, numeric as well as categorical features are usually {{used to describe the}} data objects. Accordingly, many clustering methods can process <b>datasets</b> that are either numeric or categorical. Recently, algorithms that can handle the mixed data clustering problems have been developed. Affinity propagation (AP) algorithm is an exemplar-based clustering method which has demonstrated good performance {{on a wide variety of}} <b>datasets.</b> However, it has limitations on processing mixed <b>datasets.</b> In this paper, we propose a novel similarity measure for mixed type <b>datasets</b> and an adaptive AP clustering algorithm is proposed to cluster the mixed <b>datasets.</b> Several real world <b>datasets</b> are studied to evaluate the performance of the proposed algorithm. Comparisons with other clustering algorithms demonstrate that the proposed method works well not only on mixed <b>datasets</b> but also on pure numeric and categorical <b>datasets...</b>|$|R
40|$|An {{increasing}} number of thematic <b>datasets</b> are published as RDF graphs and linked to other <b>datasets</b> by identifying equivalent resources in other relevant <b>datasets.</b> Among the set of properties usually used as data linking criteria, geolocation (addresses, locations, coordinates) {{remains one of the}} most commonly used. However, resources that actually refer to complex topographic features are generally described by very simple geolocation properties, such as a position defined by coordinates (long, lat). On the other hand, geographic reference <b>datasets</b> provide more precise geometric information about geographic features. Interlinking thematic linked open <b>datasets</b> with geographic reference <b>datasets</b> would enable us to take advantage of both information sources to link independent thematic <b>datasets</b> and create rich cartographic applications for data visualization. This data linking task is generally performed by comparing properties values of each resource of a given data set, with homologous properties of the resources described in other <b>datasets</b> [3]. In the field of geographic databases, data matchin...|$|R
40|$|In this paper, we {{investigate}} {{the possibility of}} using EGADP for protecting data in horizontallydistributed <b>datasets.</b> EGADP [10] is a new advanced data perturbation method that masks confidential numeric attributes in original <b>datasets</b> while reproducing all linear relationships in masked <b>datasets.</b> It is developed for centralized <b>datasets</b> that are owned by one owner, and no study (to the best of our knowledge) suggests and investigates empirically the possibilities of using it to protect distributed confidential <b>datasets.</b> This study is intended to fill this gap. 1...|$|R
