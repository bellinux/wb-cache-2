1513|10000|Public
5|$|Phantasmagoria {{quickly became}} the best-selling game in the United States, and was Sierra's best-selling {{computer}} game to date. It grossed $12 million and sold 300,000 units during its first weekend of release, debuting at number four in PC <b>Datas</b> August 1995 list of top-selling computer games for MS-DOS and Windows. It followed , Microsoft Flight Simulator and Myst. By September it had reached {{number one on the}} list among computer games and ranked third among all computer software, following Windows 95 and Microsoft Plus! InterAction, a magazine published by Sierra On-Line, wrote that no other Sierra game topped game charts as quickly as Phantasmagoria did. By the end of December, it remained at number three among overall software, and number one among computer games, and by January it was estimated as many as 500,000 copies had been sold.|$|E
500|$|Robert Legato and Rick Berman spent {{forty minutes}} on the {{telephone}} with Shearer during the strike. While she refused to write the lines during the strike, Berman suggested dialogue and Shearer would give opinions with Legato taking down handwritten notes. Legato decided on the directing notes himself, and used a whip pan shot instead of an effects shot to film the three <b>Datas</b> as director Robert Becker had never used effects shots previously. Shearer wasn't happy with the final result, saying [...] "we were writing the most romantic episode in the world" [...] but that [...] "it was toned down 75%".|$|E
5000|$|After {{combining}} with the Mystic Brothers, <b>Datas</b> Hyper becomes Mystic <b>Datas</b> Hyper (Misutikku Dētasu Haipā). The {{two halves of}} the Egg Headder cover <b>Datas</b> Hyper's hands and allow him to shoot out blasts of energy, while the Mystic Runner attaches {{to the top of}} <b>Datas</b> Hyper to enable helicopter-style flight.|$|E
50|$|A <b>data</b> {{architecture}} {{should set}} <b>data</b> standards {{for all its}} <b>data</b> systems as a vision or {{a model of the}} eventual interactions between those <b>data</b> systems. <b>Data</b> integration, for example, should be dependent upon <b>data</b> architecture standards since <b>data</b> integration requires <b>data</b> interactions between two or more <b>data</b> systems. A <b>data</b> architecture, in part, describes the <b>data</b> structures used by a business and its computer applications software. <b>Data</b> architectures address <b>data</b> in storage and <b>data</b> in motion; descriptions of <b>data</b> stores, <b>data</b> groups and <b>data</b> items; and mappings of those <b>data</b> artifacts to <b>data</b> qualities, applications, locations etc.|$|R
5000|$|The tools include <b>data</b> networks, file systems, a <b>data</b> warehouse, <b>data</b> marts, an {{operational}} <b>data</b> store, <b>data</b> mining, <b>data</b> analysis, <b>data</b> visualization, <b>data</b> federation and <b>data</b> virtualization. One {{of the newest}} tools, virtual master <b>data</b> management utilizes <b>data</b> virtualization and a persistent metadata server to implement a multi-level automated master <b>data</b> management hierarchy[...].|$|R
40|$|In <b>data</b> compression, {{one wishes}} to give a compact {{representation}} of <b>data</b> generated by a <b>data</b> source. Depending upon {{the source of the}} <b>data,</b> the <b>data</b> could be of various types, such as text <b>data,</b> image <b>data,</b> speech <b>data,</b> audio <b>data,</b> video <b>data,</b> etc. <b>Data</b> compression is performed in order to more easily store the <b>data</b> or to more easily transmit the <b>data.</b> It is the job of the <b>data</b> compression practitioner to design a dat...|$|R
50|$|By {{combining}} with the Hyper Change Headder, <b>Datas</b> {{turns into a}} giant robot called <b>Datas</b> Hyper (Dētasu Haipā) where he can perform attacks such as the <b>Datas</b> Punch (Dētasu Panchi) and the Hyper Upper (Haipā Appā). His finishing move is the <b>Datas</b> Dynamic Crash (Dētasu Dainamikku Kurasshu), which fires several powerful lasers and cards to destroy the enemy.|$|E
5000|$|Hyper Change Headder (Haipā Chenji Heddā): The Hyper Change Headder {{resembles a}} bullet and allows <b>Datas</b> to {{transform}} into <b>Datas</b> Hyper.|$|E
5000|$|<b>Datas</b> (Dētasu) is a robot that is sent by Master Head to Earth, {{prior to}} Heaven's Tower being {{destroyed}} as both an emergency system and means for {{communication between the}} Gosei World and Earth. Tending to end his sentences with [...] "desu", and usually sleeping when not needed, <b>Datas</b> also can pinpoint the likely location of villain activity. His form resembles the Super Sentai Battle: Dice-O arcade machine. <b>Datas</b> did not reappear in the Legend War because he was beaten and badly damaged by Zangyack.|$|E
40|$|Abstract—In {{wireless}} sensor networks, compromised sensor nodes can inject false <b>data</b> {{during both}} <b>data</b> aggregation and <b>data</b> forwarding. The existing false <b>data</b> detection techniques consider false <b>data</b> injections during <b>data</b> forwarding only {{and do not}} allow any change on the <b>data</b> by <b>data</b> aggregation. However, this paper presents a <b>data</b> aggregation and authentication protocol, called DAA, to integrate false <b>data</b> detection with <b>data</b> aggregation and confidentiality. To support <b>data</b> aggregation along with false <b>data</b> detection, the monitoring nodes of every <b>data</b> aggregator also conduct <b>data</b> aggregation and compute the corresponding small-size message authentication codes for <b>data</b> verification at their pairmates. To support confidential <b>data</b> transmission, the sensor nodes between two consecutive <b>data</b> aggregators verify the <b>data</b> integrity on the encrypted <b>data</b> rather than the plain <b>data.</b> Performance analysis shows that DAA detects any false <b>data</b> injected by up to compromised nodes, and that the detected false <b>data</b> are not forwarded beyond the next <b>data</b> aggregator on the path. Despite that false <b>data</b> detection and <b>data</b> confidentiality increase the communication overhead, simulation results show that DAA can still {{reduce the amount of}} transmitted <b>data</b> by up to 60 % with the help of <b>data</b> aggregation and early detection of false <b>data.</b> Index Terms—Data aggregation, <b>data</b> integrity, network-level se-curity, sensor networks. I...|$|R
5000|$|There {{are some}} key words {{related to this}} norm: Securities, Messages, Dictionaries, Databases, <b>Data</b> layout, <b>Data</b> organization, <b>Data</b> processing, banking documents, finance, {{electronic}} <b>data</b> interchange, Electronic messaging, Syntax, Character sets, Control characters, Information separators, Sets of <b>data,</b> <b>Data</b> blocks, Codes, Numerical designations, Tags (<b>data</b> processing), <b>Data,</b> <b>Data</b> elements, Coding (<b>data</b> conversion), Access, EDIFACT, <b>Data</b> transmission ...|$|R
5000|$|<b>Data</b> architecture: The <b>data</b> {{structures}} used by {{a business}} and/or its applications. Descriptions of <b>data</b> in storage and <b>data</b> in motion. Descriptions of <b>data</b> stores, <b>data</b> groups and <b>data</b> items. Mappings of those <b>data</b> artifacts to <b>data</b> qualities, applications, locations etc.|$|R
50|$|The file {{contained}} {{different types}} of <b>datas.</b>|$|E
50|$|<b>Datas</b> is {{voiced by}} Kōki Miyata (Miyata Kōki).|$|E
5000|$|Tensou Sentai Goseiger vs. Shinkenger: Epic on Ginmaku as <b>Datas</b> ...|$|E
5000|$|<b>Data</b> Preparation is a necessary, {{but often}} tedious, {{activity}} that is a critical first step in <b>data</b> analytics projects for <b>Data</b> wrangling. <b>Data</b> Preparation can include many discrete tasks such as loading <b>data</b> or <b>data</b> ingestion, <b>data</b> fusion, <b>data</b> cleansing, <b>data</b> augmentation and <b>data</b> delivery (writing out the prepared <b>data</b> to databases, file systems or applications).|$|R
40|$|Title: <b>Data</b> Profiling Author: Radka Hladíková Department: Department of Software Engineering Supervisor: Ing. Vladimír Kyjonka Supervisor's e-mail address: Vladimir. Kyjonka@cze. sas. com Abstract: This thesis puts mind on {{problems}} with <b>data</b> quality and <b>data</b> profiling. This Work analyses and summarizes problems of <b>data</b> quality, <b>data</b> defects, process of <b>data</b> quality, <b>data</b> quality assessment and <b>data</b> profiling. The main topic is <b>data</b> profiling {{as a process}} of researching <b>data</b> available in existing <b>data</b> sources and creating of statistics and information about these <b>data.</b> There is a projected system for evaluating <b>data</b> status in term of its quality. Work is focused on measuring of general characteristic of <b>data,</b> following <b>data</b> defects and its analyses. With the help of <b>data</b> quality SW there is a projected and realized system for evaluation of <b>data</b> quality for real <b>data.</b> Keywords: <b>data</b> quality, <b>data</b> profiling, <b>data</b> quality metric, DataFlu...|$|R
50|$|Processes {{commonly}} seen in master <b>data</b> management include source identification, <b>data</b> collection, <b>data</b> transformation, normalization, rule administration, {{error detection}} and correction, <b>data</b> consolidation, <b>data</b> storage, <b>data</b> distribution, <b>data</b> classification, taxonomy services, item master creation, schema mapping, product codification, <b>data</b> enrichment and <b>data</b> governance.|$|R
5000|$|... #Caption: Location of <b>Datas</b> in {{the state}} of Minas Gerais, Brazil ...|$|E
50|$|Brevis responsio ad solutiones ad solutiones <b>datas</b> ad Adversariis ad argumenta Maccovii. Franeker, 1642.|$|E
50|$|Nord-1 was Norsk <b>Datas</b> first {{minicomputer}} and {{the first}} commercially available computer made in Norway.|$|E
5000|$|On {{receipt of}} <b>data,</b> <b>data</b> links {{evaluate}} their state, given the <b>data</b> input (simple <b>data</b> links), or pass the <b>data</b> value {{to a special}} <b>data</b> link that performs some transformation of input <b>data</b> (calculated <b>data</b> link).|$|R
30|$|Big <b>Data</b> Analytics faces {{a number}} of {{challenges}} beyond those implied by the four Vs. While {{not meant to be}} an exhaustive list, some key problem areas include: <b>data</b> quality and validation, <b>data</b> cleansing, feature engineering, high-dimensionality and <b>data</b> reduction, <b>data</b> representations and distributed <b>data</b> sources, <b>data</b> sampling, scalability of algorithms, <b>data</b> visualization, parallel and distributed <b>data</b> processing, real-time analysis and decision making, crowdsourcing and semantic input for improved <b>data</b> analysis, tracing and analyzing <b>data</b> provenance, <b>data</b> discovery and integration, parallel and distributed computing, exploratory <b>data</b> analysis and interpretation, integrating heterogenous <b>data,</b> and developing new models for massive <b>data</b> computation.|$|R
40|$|This {{presentation}} {{deals with}} the potential role of the information professional in research <b>data</b> management. It touches on the reason for <b>data</b> management, general tasks, designing of <b>data</b> management plans, <b>data</b> capture, <b>data</b> storage and back-ups, metadata creation, types of metadata, <b>data</b> interpretation and analysis, <b>data</b> visualisation, <b>data</b> cleansing, <b>data</b> verification, <b>data</b> validation, <b>data</b> publishing, linking <b>data</b> to research outputs, <b>data</b> preservation, <b>data</b> citation, skills that will be needed, and helpful tools. This presentation was delivered at the NeDICC Workshop on 'The role of the information professional in relation to research <b>data</b> management', CSIR, Pretoria, South Africa, 10 June 201...|$|R
5000|$|... de Oliveira, José Teixeira and Affonso d'Escragnolle Taunay. Dicionário brasileiro de <b>datas</b> históricas. Editora Vozes, 2002[...]|$|E
50|$|Biologists conduct {{research}} {{based on the}} scientific method, to test the validity of a theory, with hypothesis formation, experimentation and documentation of protocols and <b>datas.</b>|$|E
5000|$|Y = full {{metering}}Y+ = full metering + {{focal length}} <b>dataS</b> = stop down meteringS! = stop down metering, possible damage to camera contactsX = will not fit ...|$|E
40|$|Nowadays, many {{business}} intelligence or master <b>data</b> management initiatives {{are based on}} regular <b>data</b> integration, since <b>data</b> integration intends to extract and combine a variety of <b>data</b> sources, it is thus considered as a prerequisite for <b>data</b> analytics and management. More recently, TPC-DI is proposed as an industry benchmark for <b>data</b> integration. It is designed to benchmark the <b>data</b> integration {{and serve as a}} standardisation to evaluate the ETL performance. There are a variety of <b>data</b> quality problems such as multi-meaning attributes and inconsistent <b>data</b> schemas in source <b>data,</b> which will not only cause problems for the <b>data</b> integration process but also affect further <b>data</b> mining or <b>data</b> analytics. This paper has summarised typical <b>data</b> quality problems in the <b>data</b> integration and adapted the traditional <b>data</b> quality dimensions to classify those <b>data</b> quality problems. We found that <b>data</b> completeness, timeliness and consistency are critical for <b>data</b> quality management in <b>data</b> integration, and <b>data</b> consistency should be further defined in the pragmatic level. In order to prevent typical <b>data</b> quality problems and proactively manage <b>data</b> quality in ETL, we proposed a set of practical guidelines for researchers and practitioners to conduct <b>data</b> quality management in <b>data</b> integration...|$|R
50|$|A <b>data</b> {{architecture}} {{describes the}} <b>data</b> structures {{used by a}} business and/or its applications. There are descriptions of <b>data</b> in storage and <b>data</b> in motion; descriptions of <b>data</b> stores, <b>data</b> groups and <b>data</b> items; and mappings of those <b>data</b> artifacts to <b>data</b> qualities, applications, locations etc.|$|R
50|$|Warranty <b>data</b> {{consists}} of claims <b>data</b> and supplementary <b>data.</b> Claims <b>data</b> are the <b>data</b> {{collected during the}} servicing of claims under warranty and supplementary <b>data</b> are additional <b>data</b> such as production and marketing <b>data.</b> This <b>data</b> can help determine product reliability and plan for future modifications.|$|R
50|$|The {{telemetry}} {{system is}} usually integrated {{in the radio}} transmitter that store the <b>datas</b> in a file. After that a computer analysis is possible by use some telemetry software.|$|E
50|$|The movie {{pamphlet}} for Gokaiger Goseiger Super Sentai 199 Hero Great Battle {{reveals how}} Ninjaman (who appears {{later in the}} television series), Gunmazin, and <b>Datas</b> do not have Ranger Keys. As Ninjaman explains in episode 45, the Three God Generals {{put him in a}} jar for ten years as punishment for going overboard while trying to rescue a little girl from rampaging zoo animals, and thus was unable to participate in the Legend War. <b>Datas</b> fought along with the other giant robots to fight the first Zangyack fleet as <b>Datas</b> Hyper and ended up unable to fight along with the Super Sentai. Gunmazin may have also fought as a giant, however {{due to the fact that}} he has to serve whoever holds his key (good, neutral, or evil), he may not have participated in the war at all. Zubaan was able to survive the giant battle and went on to participate in the war in normal size, thus having his own Ranger Key.|$|E
5000|$|The {{distance}} to Diamantina is 54 km; and the {{distance to}} Belo Horizonte is 298 km. Neighboring municipalities are: <b>Datas,</b> Santo Antônio do Itambé, Conceição do Mato Dentro and Gouveia.|$|E
40|$|<b>Data</b> mining is {{a process}} of extracting hidden, unknown, but {{potentially}} useful information from massive <b>data.</b> Big <b>Data</b> has great impacts on scientific discoveries and value creation. This paper introduces methods in <b>data</b> mining and technologies in Big <b>Data.</b> Challenges of <b>data</b> mining and <b>data</b> mining with big <b>data</b> are discussed. Some technology progress of <b>data</b> mining and <b>data</b> mining with big <b>data</b> are also presented...|$|R
30|$|Mining and extracting {{meaningful}} patterns from massive input <b>data</b> for decision-making, prediction, {{and other}} inferencing {{is at the}} core of Big <b>Data</b> Analytics. In addition to analyzing massive volumes of <b>data,</b> Big <b>Data</b> Analytics poses other unique challenges for machine learning and <b>data</b> analysis, including format variation of the raw <b>data,</b> fast-moving streaming <b>data,</b> trustworthiness of the <b>data</b> analysis, highly distributed input sources, noisy and poor quality <b>data,</b> high dimensionality, scalability of algorithms, imbalanced input <b>data,</b> unsupervised and un-categorized <b>data,</b> limited supervised/labeled <b>data,</b> etc. Adequate <b>data</b> storage, <b>data</b> indexing/tagging, and fast information retrieval are other key problems in Big <b>Data</b> Analytics. Consequently, innovative <b>data</b> analysis and <b>data</b> management solutions are warranted when working with Big <b>Data.</b> For example, in a recent work we examined the high-dimensionality of bioinformatics domain <b>data</b> and investigated feature selection techniques to address the problem [23]. A more detailed overview of Big <b>Data</b> Analytics is presented in Section “Big <b>data</b> analytics”.|$|R
50|$|<b>Data</b> {{provenance}} {{covers the}} provenance of computerized <b>data.</b> There {{are two main}} aspects of <b>data</b> provenance: ownership of the <b>data</b> and <b>data</b> usage. Ownership will tell the user {{who is responsible for}} the source of the <b>data,</b> ideally including information on the originator of the <b>data.</b> <b>Data</b> usage gives details regarding how the <b>data</b> has been used and modified and often includes information on how to cite the <b>data</b> source or sources. <b>Data</b> provenance is of particular concern with electronic <b>data,</b> as <b>data</b> sets are often modified and copied without proper citation or acknowledgement of the originating <b>data</b> set. Databases make it easy to select specific information from <b>data</b> sets and merge this <b>data</b> with other <b>data</b> sources without any documentation of how the <b>data</b> was obtained or how it was modified from the original <b>data</b> set or sets.|$|R
