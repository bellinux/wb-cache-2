632|609|Public
25|$|Texas <b>Educational</b> <b>Assessment</b> of Minimum Skills - {{the second}} {{standardized}} test used by Texas from 1984 until 1990.|$|E
25|$|The Australian Schools Science Competition – International Competitions and Assessments for Schools (ICAS) is {{conducted}} by <b>Educational</b> <b>Assessment</b> Australia, UNSW Global Pty Limited. UNSW Global is a not-for-profit provider of education, training and consulting services and a wholly owned enterprise of the University of New South Wales. It provides exams {{for students in}} Australia, New Zealand, Singapore, Brunei, Malaysia, South Africa, Indonesia, Hong Kong, India and the Pacific region. It caters to students from year 3 (Australia) through year 12, examining skills in English, mathematics, science, computers, writing and spelling.|$|E
2500|$|To keep {{providing}} {{qualitative and}} reliable <b>educational</b> <b>assessment</b> ...|$|E
5000|$|Educational {{measurement}} {{refers to}} the use of <b>educational</b> <b>assessments</b> and the analysis of data such as scores obtained from <b>educational</b> <b>assessments</b> to infer the abilities and proficiencies of students. The approaches overlap with those in psychometrics.Educational measurement is the assigning of numerals to traits such as achievement, interest, attitudes, aptitudes, intelligence and performance.|$|R
30|$|This paper reviews recent {{research}} on causal inference with large-scale assessments in education from a Bayesian perspective. I begin by adopting the potential outcomes model of Rubin (J Educ Psychol 66 : 688 - 701, 1974) {{as a framework}} for causal inference that I argue is appropriate with large-scale <b>educational</b> <b>assessments.</b> I then discuss the elements of Bayesian inference arguing that methods and models of causal inference can benefit from the Bayesian approach to quantifying uncertainty. Next I outline one method of causal inference that I believe is fruitful for addressing causal questions with large-scale <b>educational</b> <b>assessments</b> within the potential outcomes framework—namely, propensity score analysis. I then discuss the quantification of uncertainty in propensity score analysis through a Bayesian approach. Next, I discuss a series of necessary conditions for addressing causal questions with large-scale <b>educational</b> <b>assessments.</b> The paper closes with a discussion of the implications for the design of large-scale <b>educational</b> <b>assessments</b> when the goal is in asking causal questions and warranting causal claims.|$|R
50|$|Technology-Based Assessment {{project was}} {{designed}} to explore the use of technology, especially {{the use of the}} computer as a tool to enhance the quality and efficiency of <b>educational</b> <b>assessments.</b>|$|R
2500|$|John Ewing, {{writing in}} the Notices of the American Mathematical Society criticized the use of {{value-added}} models in <b>educational</b> <b>assessment</b> {{as a form of}} [...] "mathematical intimidation" [...] and a [...] "rhetorical weapon." [...] Ewing cited problems with input data and the influence of factors not included in the model.|$|E
2500|$|The American Statistical Association {{issued an}} April 8, 2014 {{statement}} criticizing {{the use of}} value-added models in <b>educational</b> <b>assessment,</b> without ruling out the usefulness of such models. [...] The ASA cited limitations of input data, the influence of factors {{not included in the}} models, and large standard errors resulting in unstable year-to-year rankings.|$|E
2500|$|Psychometrics {{is applied}} widely in <b>educational</b> <b>assessment</b> to measure {{abilities}} in domains such as reading, writing, and mathematics. [...] The main approaches in applying tests in these domains have been classical test {{theory and the}} more recent Item Response Theory and Rasch measurement models. [...] These latter approaches permit joint scaling of persons and assessment items, which provides a basis for mapping of developmental continua by allowing descriptions of the skills displayed at various points along a continuum.|$|E
50|$|Assessment users, {{including}} {{teachers and}} other educational stakeholders, are increasingly demanding relevant results from <b>educational</b> <b>assessments.</b> This requires assessments to be aligned with classroom practice to be of maximum instructional value.|$|R
40|$|<b>Educational</b> <b>assessments</b> {{define what}} aspects of {{learning}} will formally be given credit and therefore {{have a huge}} impact upon teaching and learning. Although the impact of high-stakes national and international assessments on teaching and learning is considered in the literature, remarkably, there is little research on the connection between theories of learning and <b>educational</b> <b>assessments.</b> Given the voluminous assessment that takes place annually in systematic ways in most many nations, {{it is surprising that}} more has not been gained from these assessments in the development of theories of learning and vice versa. In this article we consider both theories of learning and assessment and draw the main message of the article, that if assessments are to serve the goals of education, then theories of learning and assessment should be developing more closely with each other. We consider fundamental aspects of assessment theory, such as constructs, unidimensionality, invariance and quantifiability, and in doing so, we distinguish between <b>educational</b> and psychological <b>assessment.</b> Second, we show how less traditionally considered cases of a) international assessments and b) Assessment for Learning affect student learning. Through these cases we illustrate the otherwise somewhat theoretical discussion in the article. We argue that if assessment is to serve the learning goals of education, then this discussion on the relationship between assessment and learning should be developed further and be at the forefront of high-stakes, large-scale <b>educational</b> <b>assessments...</b>|$|R
40|$|Research on teachers’ {{judgments}} of student performance {{has demonstrated that}} <b>educational</b> <b>assessments</b> may be biased or may more correctly take the achievements of students into account depending on teachers’ motivations while making the judgment. Building on research on social judgment formation the present investigation examined whether the accountability of teachers {{has an influence on}} judgment formation. We predicted that unaccountable teachers would activate social categories and use them for the assessment, whereas accountable teachers’ attention would be directed to individual attributes of students. Using secondary school teachers as participants, three studies investigating teachers’ assessments, inferences and memory for students’ attributes supported these hypotheses. Thus, accountability appears to be a moderator of social information processing and judgment formation in the domain of <b>educational</b> <b>assessments...</b>|$|R
50|$|During the 2012-13 school year, East Feliciana Public Schools {{ranked second}} {{in the state in}} {{proficiency}} growth on the 3rd-8th grade Louisiana <b>Educational</b> <b>Assessment</b> Program (LEAP) and integrated Louisiana <b>Educational</b> <b>Assessment</b> Program (iLEAP) spring assessments.|$|E
5000|$|To keep {{providing}} {{qualitative and}} reliable <b>educational</b> <b>assessment</b> ...|$|E
50|$|President of the International Association for <b>Educational</b> <b>Assessment,</b> IAEA.|$|E
5000|$|... #Caption: [...] Ukrainian Center for <b>Educational</b> Quality <b>Assessment</b> ...|$|R
50|$|Over time, the O-Grade was {{gradually}} phased out {{and replaced by}} other <b>educational</b> <b>assessments.</b> Its replacement, the Standard Grade, focused more closely on coursework {{and the application of}} knowledge. The Standard Grade has eventually been replaced by the National 4/5 qualifications, as part of the introduction of the Curriculum for Excellence.|$|R
50|$|In {{terms of}} the broad body of purely {{mathematical}} theory drawn on, there is substantial overlap between educational measurement and psychometrics. However, certain approaches {{considered to be a}} part of psychometrics, including Classical test theory, Item Response Theory and the Rasch model, were originally developed more specifically for the analysis of data from <b>educational</b> <b>assessments.</b>|$|R
5000|$|A Cognitive and <b>Educational</b> <b>assessment</b> by an Educational Psychologist ...|$|E
50|$|<b>Educational</b> <b>Assessment</b> Australia (EAA) is a not-for-profit {{organisation}} {{owned by}} the University of New South Wales. It is a national and international <b>educational</b> <b>assessment</b> organisation specialising in large-scale assessment programs including the International Competitions and Assessments for Schools (ICAS) in Australia, New Zealand, Asia, India, South Africa and the Pacific region.|$|E
5000|$|... “Rethinking <b>Educational</b> <b>Assessment</b> Using Crowd Sourcing”, Stanford Media X Seminar ...|$|E
40|$|Aims and {{objectives}} To evaluate the usability of the <b>educational</b> needs <b>assessment</b> tool in clinical practice, from a practitioner and patient perspective {{and to establish}} whether patients perceive that they are getting an equally good or equally inadequate education service for their needs. Background The <b>educational</b> needs <b>assessment</b> tool was developed to enable patients with Rheumatoid Arthritis to assess their education needs prior to a consultation with a health professional. The <b>educational</b> needs <b>assessment</b> tool has been translated into nine languages and measurement properties have been established, however, its usability in clinical practice has not been studied. Design A qualitative study embedded into a multicentre RCT in which patients had been randomised into either <b>educational</b> needs <b>assessment</b> tool-focused education (Experimental Group) or usual care (control group). Methods Both groups were seen by a clinical nurse specialist. Sixteen patients and four clinical nurse specialists were recruited from the Rheumatology Outpatient Departments of three Acute Hospitals within the U K. Data were collected by interviews with patients and clinical nurse specialist. Analysis followed the Framework approach. Results Patients and clinical nurse specialist found completion of the <b>educational</b> needs <b>assessment</b> tool straightforward, comprehensive and easy to use. Completing the <b>educational</b> needs <b>assessment</b> tool helped patients {{to focus on what}} they needed to know from the clinical nurse specialist. Patients in both the control group and the experimental group felt supported and reassured by their clinical nurse specialist and perceived that they received a good and adequate education provision. Conclusion This study provides useful insights into the ability of the <b>educational</b> needs <b>assessment</b> tool to assess the educational needs of patients with rheumatoid arthritis in routine clinical practice. Relevance to clinical practice The <b>educational</b> needs <b>assessment</b> tool would be useful as a structured guide for nurses when assessing and meeting individual patient educational needs. This has the potential to improve patient-centred care, involve patients more actively in their care and enhance the long-term effects of patient education provision...|$|R
40|$|<b>Educational</b> <b>assessments</b> are {{conducted}} {{in a variety of}} ways and their outcomes can be used for a variety of purposes. There are differences in who decides what is to be assessed, who carries out the assessment, where the assessment takes place, how the resulting responses made by students are scored and interpreted, and what happens as...|$|R
40|$|Background: The {{educational}} needs of people with undifferentiated spondyloarthritis (USpA) have not been well studied. The <b>educational</b> needs <b>assessment</b> tool (ENAT) has been translated into Swedish and validated in other rheumatic diseases but not USpA. 1 Objectives: validate the <b>educational</b> needs <b>assessment</b> tool (ENAT) in people with USpA {{and use it to}} study their {{educational needs}}. Download the structured abstract to read more...|$|R
5000|$|... #Subtitle level 2: Contributions to Developmental Screening and <b>Educational</b> <b>Assessment</b> ...|$|E
5000|$|... #Subtitle level 3: 2006 Michigan <b>Educational</b> <b>Assessment</b> Program (MEAP) Results ...|$|E
50|$|Vice {{president}} of the Association for <b>Educational</b> <b>Assessment</b> in Africa, AEAA.|$|E
50|$|The AHM is a {{promising}} method for cognitive diagnostic assessment. Using a principled test design approach, integrating cognition into test development, can promote stronger inferences about how students actually think and solve problems. With this knowledge, {{students can be}} provided with additional information that can guide their learning, leading to improved performance on future <b>educational</b> <b>assessments</b> and problem solving tasks.|$|R
50|$|Begins its {{activity}} Ukrainian Center for <b>Educational</b> Quality <b>Assessment.</b> Created 8 regional centers otsnyuvannya quality education.|$|R
50|$|The aim {{of theory}} and {{practice}} in educational measurement is typically to measure abilities and levels of attainment by students {{in areas such as}} reading, writing, mathematics, science and so forth. Traditionally, attention focuses on whether assessments are reliable and valid. In practice, educational measurement is largely concerned with the analysis of data from <b>educational</b> <b>assessments</b> or tests. Typically, this means using total scores on assessments, whether they are multiple choice or open-ended and marked using marking rubrics or guides.|$|R
5000|$|To {{developing}} {{means of}} <b>educational</b> <b>assessment</b> for {{all levels of}} education.|$|E
50|$|Measured Progress : a not-for-profit {{corporation}} {{recognized as}} a national leader in <b>educational</b> <b>assessment.</b>|$|E
5000|$|APPD LEARN - Association of Pediatric Program Directors Longitudinal <b>Educational</b> <b>Assessment</b> Research Network Virginia ...|$|E
50|$|The Johnson Center for Child Health and Development (formerly {{known as}} Thoughtful House Center for Children or simply Thoughtful House) is a {{non-profit}} organization working to advance the understanding of childhood development through clinical care, research, and education. Located in Austin, Texas, the Johnson Center offers diagnostic services, healthcare services, behavioral therapy, <b>educational</b> <b>assessments,</b> community outreach and education. The center continues to have a diverse research program, including clinical research studies and biological research {{under the direction of}} Laura Hewitson.|$|R
50|$|CEMO’s mission is, firstly, to {{move the}} field of {{educational}} measurement forward. This includes an orientation towards action such as the development of instruments that balance educational quality, equity, and effectiveness, but also towards reaction such as addressing concerns about unintended consequences and side-effects of assessments by examining these in-depth. A special objective of CEMO is to contextualize <b>educational</b> <b>assessments</b> in the societal and cultural characteristics of the five Nordic countries (Denmark, Finland, Iceland, Norway and Sweden), with the intention to “unpack” the Nordic model.|$|R
30|$|Over {{the last}} two decades, an {{increasing}} number of education systems (hereafter countries) have found their participation in large-scale cross-national <b>educational</b> <b>assessments</b> a more and more relevant part of quality evaluation of their school systems. Examples of these studies are the Programme for International Student Assessment (PISA), conducted by the Organisation for Economic Co-operation and Development (OECD), and the Trends in International Mathematics and Science Study (TIMSS), conducted by the International Association for the Evaluation of Educational Achievement (IEA). Germany is one of the countries that regularly takes part in these comparative studies.|$|R
