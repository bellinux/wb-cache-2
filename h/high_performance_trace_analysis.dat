1|10000|Public
40|$|Nuclear {{activities}} unavoidably leave fingerprints in the environment. Such fingerprints may {{consist of}} characteristic building structures, of typical supply lines or of minute releases of process material. In particular, {{the release of}} micron-sized aerosol particles to the immediate environment {{is very difficult to}} avoid to the complete extent, especially when nuclear materials are processed in larger quantities. These micro-particles contain the isotopic signature of the handled nuclear materials. This allows nuclear safeguards authorities with specialised sampling techniques and analytical laboratories to verify the completeness of a state's declaration and to check the consistency of measured material properties (i. e. isotopic composition) with declared operations at nuclear facilities. This methodology has been in particular applied to uranium enrichment facilities. The European Commission (EC) Joint Research Centre (JRC), the Institute of Transuranium Elements (ITU) has performed uranium particle analysis for nuclear safeguards purposes on environmental samples since the late 90 's with the EC Directorate General Energy (DG-ENER) as its main user. In recent years, significant efforts have been made to enhance the used analytical techniques. The enhancements have been achieved in collaboration with leading manufactures of analytical equipment that has implemented new purpose built systems for particle analysis in the field of Secondary Ion mass Spectrometry (SIMS). This paper describes the purpose and outlines the performance of a new analytical Large Geometry – Secondary Ion Mass Spectrometry (LG-SIMS) laboratory that has been established at ITU, jointly funded by the JRC and DG-ENER. The laboratory will mainly be used for analysing uranium bearing aerosol particles collected on cotton swipes from nuclear safeguards inspections but it will also be used for other safeguards related applications and nuclear forensics. This paper will give an overview of the capabilities and enhancements that can be expected from this new laboratory and it will also describe the use and importance of environmental sampling that are followed by <b>high</b> <b>performance</b> <b>trace</b> <b>analysis</b> of particles, in the context of European nuclear safeguards. JRC. E. 7 -Nuclear Safeguards and Forensic...|$|E
40|$|AbstractIn {{this paper}} we {{describe}} an approach {{used to study}} the functional aspects and estimate the performance of large (read “ten times more cores than currently available”) cluster computing system configurations running MPI applications. A combination of a functional simulation, <b>performance</b> models, <b>traces</b> <b>analysis</b> and real-world measurements is used to achieve these goals. We also present the first results of applying this methodology to actual applications of interest...|$|R
40|$|Our {{procedure}} of direct splitless injection on capillary columns {{is based on}} the choice of column temperature for injection. Under appropriate conditions a marked concentration effect is observed, i. e. the eluted band is more concentrated than the injected one. The dependence of this effect on column temperature, injection time, sample size, and other variables has been studied experimentally. A solvent bypassing technique has been developed which allows the <b>performance</b> of <b>trace</b> <b>analysis</b> on capillary column...|$|R
40|$|Some {{limitations}} of tunable diode laser spectroscopy caused by laser noise, drifts and general interferometric effects are discussed together with novel signal processing strategies {{to cope with}} stability problems. The importance of fast switching between ambient and background measurements is emphasized {{and the application of}} additional sample modulation is proposed to improve system <b>performance</b> for <b>trace</b> gas <b>analysis...</b>|$|R
40|$|<b>Tracing</b> and <b>performance</b> <b>analysis</b> {{tools are}} an {{important}} component {{in the development of}} <b>high</b> <b>performance</b> applications. <b>Tracing</b> parallel programs with current tracing tools, however, easily leads to large trace files with hundreds of Megabytes. The storage, visualization, and <b>analysis</b> of such <b>trace</b> files is often difficult. We propose a trace-scaling agent for tracing parallel applications, which learns the application behavior in runtime and achieves a small, easy to handle trace. The agent dynamically identifies the amount of information needed to capture the application behavior. This knowledge acquired at runtime allows recording only the non-iterative trace information, which drastically reduces the size of the trace file. Peer Reviewe...|$|R
40|$|Abstract {{requirement}} for trace files. We {{show that the}} agent can obtain such an understanding automatically at runtime without programmer intervention or support. The remainder of the paper is structured as follows: In section 2 we describe scalability problems of tracing mechanisms. Section 3 shows {{the implementation of the}} trace-scaling agent. Section 4 describes some applications and results of scaled tracing. Section 5 contains further disussion of our approach. In section 6 we conclude the paper. <b>Tracing</b> and <b>performance</b> <b>analysis</b> tools are an important component in the development of <b>high</b> <b>performance</b> applications. <b>Tracing</b> paral'el prqgrams with current tracing tools. however. easily leads to large trace files with hundreds of lUegabytes. The s~orage...|$|R
40|$|We {{present a}} {{performance}} comparison of bounding volume hier-archies and kd-trees for ray tracing on many-core architectures (GPUs). The comparison is focused on rendering times and traver-sal characteristics on the GPU using data structures that were opti-mized for maximum <b>performance</b> of <b>tracing</b> rays irrespective of the time needed for their build. We show that for a contemporary GPU architecture (NVIDIA Kepler) bounding volume hierarchies have <b>higher</b> ray <b>tracing</b> <b>performance</b> than kd-trees for simple and mod-erately complex scenes. Kd-trees, on the other hand, have <b>higher</b> <b>performance</b> for complex scenes, in particular for those with occlu-sion...|$|R
40|$|TaintTrace is a <b>high</b> <b>performance</b> flow <b>tracing</b> {{tool that}} protects systems against {{security}} exploits. It {{is based on}} dynamic execution binary rewriting empowering our tool with fine-grained monitoring of system activities such as the tracking of the usage and propagation of data origi-nated from the network. The challenge lies in minimizing the run-time overhead of the tool. TaintTrace uses a number of techniques such as direct memory mapping to optimize performance. In this paper, we demonstrate that TaintTrace is effective in protecting against various attacks while main-taining a modest slowdown of 5. 5 times, offering significant improvements over similar tools. ...|$|R
40|$|I/O traces contain {{valuable}} {{information about the}} workloads encountered in production environments. By studying a trace one can optimize a system for {{the specifics of the}} workload and as a result attain <b>higher</b> <b>performance</b> levels. <b>Traces</b> are also useful for the proper performance evaluation of the existing systems. Out of 68 storage and file system papers published in 2010 in major system conferences (FAST, OSDI, HotStorage, MSST, and ATC), 35 used standard or custom <b>traces</b> for their <b>performance</b> evaluation. It is therefore not surprising that SNIA’s trace repository grows rapidly and contains at the moment more than 20 traces collected by different organizations [5]. Although traces are indispensable for proper performance evaluation in some projects, they are cumbersom...|$|R
40|$|As the {{technology}} of the intelligent tracing vehicles is developing, demands on <b>high</b> <b>performance</b> intelligent <b>tracing</b> vehicles are increasing. Using proper control methods can significantly {{improve the quality of}} intelligent tracing vehicles. By studying the working principles of tracing vehicles, relationships among their speeds, angular speeds and driving motor speeds are derived. Also, front, medially and back symmetrical tracing sensor arrays are also designed. Meanwhile, a fuzzy control algorithm is proposed to recognize the motion paths. The proposed fuzzy control method can achieve the tracing purposes of the tracing vehicles. It is verified by experiments. The tracing vehicles can travel along the lines with small radians and can even fulfill right-angle turnings in addition to walking on straight lines and the lines with large radians...|$|R
40|$|One of the {{important}} phases of parallel programming is <b>performance</b> <b>analysis.</b> <b>Trace</b> data provides information about where time is spent in programs. Since this data is huge, a tool for analyzing and visualizing the trace data is convenient and necessary for performance analysis of parallel programs. Environments which provide such a faclility are many and varied. In this report, we discuss our work on the enhancement of one such environment for accessibility over more platforms and better visualization capabilities. The environment is Pablo...|$|R
40|$|Reflector attack [9] {{belongs to}} one of the most serious types of Denial-of-Service (DoS) attacks, which can hardly be traced by {{contemporary}} traceback techniques, since the marked information written by any routers between the attacker and the reflectors will be lost in the replied packets from the reflectors. We propose in this paper a reflective algebraic marking scheme for tracing DoS and DDoS attacks, as well as reflector attacks. The proposed marking scheme contains three algorithms, namely the marking, reflection and reconstruction algorithms, which have been well tested through extensive simulation experiments. The results show that the marking scheme can achieve a <b>high</b> <b>performance</b> in <b>tracing</b> the sources of the potential attack packets. In addition, it produces negligible false positives; whereas other current methods usually produce a certain amount of false positives. 1...|$|R
40|$|The AR 350 is a {{ray tracing}} {{processor}} developed by Advanced Rendering Technologies. By using AR 350 processors arrays, the PURE and RenderDrive products achieve <b>high</b> <b>performances</b> in Ray <b>Tracing</b> based rendering. In this paper we present {{an extension of}} their capabilities to global illumination computation by implementing Path Tracing based methods. Because the core program of these rendering appliances is not modifiable but driven by a Render-Man compliant interface, we achieve this goal by writing dedicated shaders. We obtain better indirect illumination than {{with the use of}} standard shaders and keep <b>high</b> <b>performances</b> by the exclusive use of the AR 350 processors array for all intersection tests...|$|R
50|$|Several {{methods can}} be used for <b>trace</b> <b>analysis</b> of TATP, {{including}} gas chromatography/mass spectrometry (GC/MS) <b>high</b> <b>performance</b> liquid chromatography/mass spectrometry (HPLC/MS), and HPLC with post-column derivitization.|$|R
40|$|Abstract [...] The {{thorough}} {{analysis of}} network performance often requires understanding {{the details of}} activity occurring in several dimensions. First, there is the {{information that can be}} observed by active or passive measurements of network traffic on a link. This in itself is a multilayer problem in that activity at one layer, say loss at the ATM transport layer, can impact another, for example, IP layer performance. A second dimension concerns topological relationships, both physical and logical, that interconnect network elements and higher level service points. In this dimension we find the physical connections, MPLS pathways, routing tables, etc., that bridge a network together. Finally, we add the configuration details that define service characteristics or link behavior. Here we include transmission MTUs, leaky bucket parameters and high-level policies on traffic such as admission control. We need to visualize all of these interrelationships in order to understand subtle details that affect user-perceived performance. Using examples drawn from detailed, packet-by-packet analyses taken over the years, we demonstrate how understanding the complete nature of network performance requires reconstructing much of the basic network structure – across multiple layers and in consideration of physical and logical topological relations. At times it is necessary to shift between analysis techniques that average away details, such as histograms, and instead examine long sequences of individual packet delays to uncover the cause of network degradation. We conclude with a description of work in progress to use data modeling techniques to represent these multilayer and topological considerations so that we can automate some of the processes involved in the determination of the root causes of performance problems. Index Terms [...] data modeling, network <b>performance</b> <b>analysis,</b> <b>trace</b> <b>analysis.</b> I...|$|R
40|$|In this contribution, we give an {{overview}} {{on the military}} multi-agent simulation environment ITSimBw, which is developed at Fraunhofer IAIS/ART under contract for the department A 5 of the IT office of the German Armed Forces (ITAmtBw), where the project is overseen by Captain Thomas Doll. Due to the growing importance of network centric capabilities in military operations, {{one of the main}} focus points for the development of ITSimBw is the faithful modelling of IT and communication aspects. This goal is achieved essentially by two means: 1. A message format for simulated communication acts between agents is provided which allows the detailed specification of communication channel, medium, and range. 2. A voxel-space representation is used to model the extension of all objects belonging to the simulated environment. This allows for the application of <b>high</b> <b>performance</b> ray <b>tracing</b> algorithms to precisely determine the impact of effects like radio-pockets (e. g. caused by mountains) as well as jamming by opposing forces. These two features in conjunction allow for a detailed and realistic modeling of communication chains for reporting and command both inside and across different echelons. Clearly, the modelling of communication aspects can only reasonably be carried out in an environmen...|$|R
40|$|This <b>performance</b> <b>analysis</b> <b>traces</b> the {{emergence}} of masculinity in the open-ended narratives of 14 men who self identify as “physically disabled. ” The participants range in physical ability, age, relationship status, build, and socioeconomic status. They also range in their responses to the interaction of their ability and gender: mourning, resisting, accepting, and/or embracing their daily performances of physically disabled masculinity. Through bodies defined as the negation of ‘normal,’ they attend to and expose the nuances of the interacting cultural components of hegemonic masculinity that all human beings negotiate, interpret, create and re-create through our interactions. Their stories and insights offer opportunities for us to understand the impossibilities of ideal gender performance all humans co-imagine, reiterate, and pursue but can never realize.   Keywords: Performance Analysis, Masculinity, Physical Disability, Personal Narrativ...|$|R
40|$|Abstract: In a {{previous}} work, {{we proposed a}} framework for the o-line simulation of MPI applications. Its main originality {{with regard to the}} literature is to rely on time-independent execution traces. Time-independent traces are an original way to estimate the performance of parallel applications. To acquire time-independent traces of the execution of MPI applications, we have to instrument them to log the necessary information. There exist many pro ling tools which can instrument an application. In this report we propose a scoring system that corresponds to our framework speci c requirements and evaluate the most well-known and open source pro ling tools according to it. Furthermore we introduce an original tool called Minimal Instrumentation that was designed to ful ll the requirements of our framework. Key-words: MPI, Pro ling tools, <b>Traces,</b> <b>Performance</b> <b>Analysis,</b> o-line simulatio...|$|R
40|$|Deep {{learning}} {{applications are}} computation-intensive and often employ GPU as the underlying computing devices. Deep learning frameworks provide powerful programming interfaces, but {{the gap between}} source codes and practical GPU operations {{make it difficult to}} analyze the performance of deep learning applications. In this paper, through examing the features of GPU traces and deep learning applications, we use the suffix tree structure to extract the repeated patten in GPU <b>traces.</b> <b>Performance</b> <b>analysis</b> graphs can be generated from the preprocessed GPU traces. We further present DeepProf, a novel tool to automatically process GPU <b>traces</b> and generate <b>performance</b> <b>analysis</b> reports for deep learning applications. Empirical study verifies the effectiveness of DeepProf in performance analysis and diagnosis. We also find out some interesting properties of Tensorflow, which can be used to guide the deep learning system setup...|$|R
40|$|Scalability of {{parallel}} applications run on clusters and multi-clusters is often limited by communication <b>performance.</b> Message <b>tracing</b> can provide data for understanding bottlenecks, and for performance tuning. However, it requires collecting, storing, analyzing, and transferring potentially gigabytes of data. We have designed the EventSpace system for low overhead and <b>high</b> <b>performance</b> runtime collective communication <b>trace</b> <b>analysis.</b> EventSpace separates the perturbation and performance requirements of data collection, analysis, gathering and visualization. Data collection overhead is low since the {{minimum amount of}} data is recorded and stored temporarily in main memory. The recorded data is either discarded or analyzed on demand using available cluster resources. Analysis is distributed for <b>high</b> <b>performance,</b> and coscheduled with the computation and communication system threads for low perturbation. Gathering of analyzed data is done using extensible collective communication operations, which can be tuned to trade off between performance and monitoring overhead. EventSpace was used to do run-time monitoring and analysis of collective communication micro-benchmarks run on clusters, multi-clusters, and multi-clusters with emulated WAN links. Performance data was collected, analyzed and gathered with 0 – 3 % monitoring overhead. ...|$|R
40|$|In this paper, gait {{recognition}} using Gait Energy Image (GEl) {{and pattern}} trace transform, is presented for human identification. The first step, gait recognition using GEl and pattern trace transform, used silhouette input. The gait period could be estimated by computing the median of the walkingstep {{width of the}} three consecutive maxima. Subsequently, we calculated the Gait Energy Images from the silhouettes. GEl was transformed to a trace transform image. The pattern trace transform images were calculated using a threshold from the trace transform image to develop the pattern trace transform, which was a significant difference. Finally, we used template matching for identification. The results of gait recognition using GEl and pattern trace transform show that the proposed technique is quite effective and can be developed for <b>higher</b> <b>performance.</b> Index Terms- <b>trace</b> transform; gait recognition; Gait Energy Image, GE...|$|R
40|$|In the past, {{ray tracing}} {{has been used}} widely in offline {{rendering}} applications since it provided the ability to better capture high quality secondary effects such as reflection, refraction and shadows. Such effects are difficult to produce in a robust, high quality fashion with traditional, real-time rasterization algorithms. Motivated to bring the advantages to ray tracing to real-time applications, researchers have developed better and more efficient algorithms that leverage {{the current generation of}} fast, parallel CPU hardware within the past few years. This thesis provides the implementation and design details of a <b>high</b> <b>performance</b> ray <b>tracing</b> solution called ``RTTest'' for standard, desktop CPUs. Background information on various algorithms and acceleration structures are first discussed followed by an introduction to novel techniques used to better accelerate current, core ray tracing techniques. Techniques such as Omni-Directional Packets, Cone Proxy Traversal and Multiple Frustum Traversal are proposed and benchmarked using standard ray tracing scenes. Also, a novel soft shadowing algorithm called Edge Width Soft Shadows is proposed which achieves performance comparable to a single sampled hard shadow approach targeted at real time applications such as games. Finally, additional information on the memory layout, rendering pipeline, shader system and code level optimizations of RTTest are also discussed...|$|R
40|$|Ray tracing is {{a method}} of {{rendering}} high-quality images and video by calculating what happens to virtual light rays in a 3 -dimensional scene. It is capable of creating far more realism than traditional Z-buffering methods. This paper describes {{the design of a}} hardware ray tracing system implemented on a multi-FPGA Xilinx Virtex-E prototyping system. The result is a hardware ray tracer that is capable of out-performing a 2. 4 GHz Pentium 4, running a well-known <b>high</b> <b>performance</b> software ray <b>tracing</b> algorithm, by up to a factor of thirty. When these results are projected forward into a next generation FPGA system, consisting of a single large Virtex 2 Pro FPGA, it is found that the system should be able to out perform the same Pentium 4 by up to two orders of magnitude, and the fastest known hardware implementation, the AR 350, by up to a factor of three. 1...|$|R
40|$|Abstract. The {{graphics}} processors (GPUs) {{have recently}} {{emerged as a}} low-cost alternative for parallel programming. Since modern GPUs have great computa-tional power as well as high memory bandwidth, running ray tracing on them has been an active field of research in computer graphics in recent years. Fur-thermore, the introduction of CUDA, a novel GPGPU architecture, has removed several limitations that the traditional GPU-based ray tracing suffered. In this paper, an implementation of <b>high</b> <b>performance</b> CUDA ray <b>tracing</b> is dem-onstrated. We focus on the performance and show how our design choices in various optimization lead to an implementation that outperforms the previous works. For reasonably complex scenes with simple shading, our implementation achieves the performance of 30 to 43 million traced rays per second. Our implementation also includes the effects of recursive specular reflection and re-fraction, which were less discussed in previous GPU-based ray tracing works...|$|R
40|$|I hereby {{declare that}} I am the sole {{author of this}} thesis. This is a true copy of the thesis, {{including}} any required final revisions, as accepted by my examiners. I understand that my thesis may be made electronically available to the public. ii A wide range of libraries are available for a developer to choose from when building a software system, but once the library is chosen, the developer must determine which version of the library to use. Is there some characteristic that can identify the optimal version of a library to use? Even if a library compiles correctly, {{there could be a}} better version of that library that will provide better error handling, or improved security. In particular, the developer would prefer to avoid poor configurations: that is, sets of libraries that perform poorly, or not at all. This paper describes a method by which a sub performing version of a library can be identified from the behavior observed from different configurations of the library. Each library is measured by <b>performance</b> and <b>trace</b> <b>analysis.</b> During the course of these runs, different configurations of the library are substituted in and the results are collected to be analyzed. The results of this analysis shows that there is no quick way to identify a sub performing library. However such a library can be determined through concentrated efforts to collect and analyze time-based data. iii Acknowledgements I would like to thank my mom and dad, my two brothers, my grandmother, my cousins, my aunts and uncles, my friends and my supervisors. i...|$|R
40|$|This work {{demonstrates}} {{the development of}} highly sensitive and selective analytical methods, which {{make use of the}} hyphenation of <b>high</b> <b>performance</b> ion chromatography (HPIC) to inductively coupled plasma sector field mass spectrometry (ICP-SFMS). On-line coupling a chromatographic separation method with an elemental detection method provides two advantages: (1) the components of a possibly interfering matrix can be separated allowing accurate and precise ultra <b>trace</b> <b>analysis</b> of the element of interest and (2) elemental species of an element can be separated and quantified. In this work, matrix separation methods for interference free determination of 232 Th, 234 U, 235 U and 238 U in geological matrices were developed and employed. Furthermore HPIC-ICP-SFMS was applied for ultra <b>trace</b> <b>analysis</b> of Pd in environmental and geological matrices. The usefulness of HPIC-ICP-SFMS for speciation studies was demonstrated by investigating the interaction of an anti-cancer drug (cisplatin) with guanosine monophosphates...|$|R
40|$|We {{present an}} {{algorithm}} for determining if a ray intersects a triangle interior; and computing intersection point parameters {{as well as}} distance of intersection {{in response to the}} ray intersecting a triangle interior. Particularly a variation of a hybrid test having all benefits of Plücker and projected barycentric tests is proposed. The test is also vectorized using SIMD instructions for efficient handling ray packets. It is essential for achieving <b>high</b> ray <b>tracing</b> <b>performance</b> on modern CPUs. Our implementation also detects axis-orthogonal triangles and processing them separately. For maximum performance we also introduce a method for triangle representation, using only necessary pre-computed values. We also present inherently thread-safe and memory efficient alternative of mailboxing to avoid unnecessary intersection tests for ray packet in case when many leaves share the same triangle...|$|R
40|$|International audienceCareful {{data layout}} design {{is crucial for}} {{achieving}} <b>high</b> <b>performance.</b> However exploring data layouts is time-consuming and error-prone, and assessing {{the impact of a}} layout transformation on performance is difficult without performing it. We propose to guide application programmers through data layout restructuring by providing a comprehensive multidimensional description of the initial layout, built from <b>trace</b> <b>analysis,</b> and then by giving a performance evaluation of the transformations tested and an expression of each transformed layout. The programmer can limit the exploration to layouts matching some patterns. We apply this method to two multithreaded applications. The performance prediction of multiple transformations matches within 5 % the performance of hand-transformed layout code...|$|R
40|$|<b>Trace</b> <b>Analysis</b> of Semiconductor Materials is a guidebook {{concerned}} with procedures of ultra-trace analysis. This book discusses six distinct techniques of <b>trace</b> <b>analysis.</b> These techniques {{are the most}} common and can be applied to various problems compared to other methods. Each of the four chapters basically includes an introduction to the principles and general statements. The theoretical basis for the technique involved is then briefly discussed. Practical applications of the techniques and the different instrumentations are explained. Then, the applications to <b>trace</b> <b>analysis</b> as pertainin...|$|R
40|$|Abstract. This paper {{describes}} a new meta-tool named EARL {{which consists of}} a new highlevel <b>trace</b> <b>analysis</b> language and its interpreter which allows to easily construct new <b>trace</b> <b>analysis</b> tools. Because of its programmability and flexibility, EARL {{can be used for}} a wide range of event <b>trace</b> <b>analysis</b> tasks. It is especially well-suited for automatic and for view on an event trace the EARL interpreter provides to the user, and give an overview about the EARL language. Finally, a set of EARL script examples are used to demonstrate the features of EARL. ...|$|R
40|$|We {{present in}} this paper some new and {{efficient}} algorithms for segmentation, recognition and <b>tracing</b> <b>analysis</b> of cell phases for high-content screening. The conceptual frameworks {{are based on the}} morphological structures of cells where a series of morphological structural points are established. Furthermore, we address the issue of touching cells and then propose morphological techniques for cell separation, reconstruction and <b>tracing</b> <b>analysis.</b> The new segmentation method can resolve the question of over-segmentation. The <b>tracing</b> <b>analysis</b> of cell phases is based on cell shape, geometrical features and difference information of corresponding neighbor frames. Experiment results test the efficiency of the new metho...|$|R
40|$|International audienceProper {{testing of}} {{applications}} over embedded {{systems such as}} set-top boxes requires endurance tests, i. e. running applications for extended periods of times, typically several days. In order to understand bugs or poor <b>performances,</b> execution <b>traces</b> have to be analyzed, however current <b>trace</b> <b>analysis</b> methods are not designed to handle several days of execution traces due to the huge quantity of data generated. Our proposal, designed for regular applications such as multimedia decoding/encoding, is to monitor execution by analyzing trace on the fly in order to record trace only in time periods where a suspicious activity is detected. Our experiments show {{a significant reduction in}} the trace size compared to recording the whole trace...|$|R
30|$|We further {{show that}} the data {{integrity}} checking that DTrace provides can prevent the attacker from making security-sensitive operations. As we discussed earlier, any data corruption attack on specified security sensitive data can be revealed from the <b>trace</b> <b>analysis.</b> DTrace conducts such analysis before security-sensitive system calls. As the data corruption event can be discovered in the <b>trace</b> <b>analysis,</b> the process will fail in the <b>trace</b> <b>analysis</b> part and cannot step into the system call handling. Even though the <b>trace</b> <b>analysis</b> may happen long after the data corruption event takes place, DTrace ensures the corruption cannot be finally exploited and affect any security-sensitive operations. For example, in the example of corrupting the uid in the sudo case, even if the attacker is able to send a crafted uid to trick the kernel, DTrace will abort any security-sensitive system call as it discovers the corruption event from the trace.|$|R
50|$|It {{should be}} {{applicable}} for <b>trace</b> <b>analysis</b> {{as well as}} for undiluted samples.|$|R
40|$|Abstract—I/O {{workload}} is {{a critical}} and important factor to analyze I/O pattern and file system <b>performance.</b> However <b>tracing</b> I/O operations on the fly distributed parallel file system is non-trivial due to collection overhead and a large volume of data. In this paper, we design and implement a parallel file system logging method for <b>high</b> <b>performance</b> computing using shared memory-based multi-layer scheme. It minimizes the overhead with reduced logging operation response time and provides efficient post-processing scheme through shared memory. Separated logging server can collect sequential logs from multiple clients in a cluster through packet communication. Implementation and evaluation result shows low overhead and high scalability of this architecture for <b>high</b> <b>performance</b> parallel logging analysis. O Keywords—I/O workload, PVFS, I/O Trace...|$|R
40|$|AspectJ is a {{language}} implementing aspect oriented programming {{on top of}} Java. Usually aspect application influences not only observable behavior but changes program flow internally. To test if an aspect works as intended, we suggest <b>trace</b> <b>analysis</b> to capture these internal changes. We demonstrate how <b>trace</b> <b>analysis</b> {{can be used for}} impact analysis. It {{can also be used to}} validate that refactorings which replaced scattered code by an aspect did not change system behavior...|$|R
