3|12|Public
5000|$|ARQ-M was {{standardised}} by the Comité consultatif international pour la radio. The XII Plenary {{session in}} New Delhi in 1970 approved recommendation 342-2 Automatic <b>error-correcting</b> <b>system</b> for telegraph signals transmitted over radio circuits. [...] The CCITT produced recommendation S.13 [...] Use on radio circuits of 7-unit synchronous systems giving error correction by automatic repetition.|$|E
40|$|Rumelhart & Zipser's (1986) {{competitive}} learning algorithm is {{an account of}} unsupcrvised learning and, as such, might be considered a potential model of free classification behavior in humans. However, selective learning effects (e. g. Dickinson, Shanks & Evenden, 1984) suggest that human learning, ai least under conditions of feedback, may be better characterized by an <b>error-correcting</b> <b>system.</b> An experiment is reported that provides preliminary evidence {{for the existence of}} a selective learning effect in free classification. Simulations indicate that Rumelhart & Zipser's algorithm does not provide an adequate account of the behavior observed, whilst an error-correcting variant of {{competitive learning}} does...|$|E
40|$|Powerful error-correcting codes {{have enabled}} a {{dramatic}} increase in the bit density on the recording medium of hard-disk drives (HDDs). Error-correcting codes in magnetic recording require a low-complexity decoder and a code design that delivers a target error-rate performance. This dissertation proposes an <b>error-correcting</b> <b>system</b> based on polar codes incorporating a fast, low-complexity, soft-output decoder and a design that is optimized for error-rate performance in the magnetic recording channel. LDPC codes are the state-of-the-art in HDDs, providing the required error-rate performance on high densities at the cost of increased computational complexity of the decoder. Substantial research in LDPC codes has focused on reducing decoder complexity and has resulted in many variants such as quasi-cyclic and convolutional LDPC codes. Polar codes are a recent and important breakthrough in coding theory, as they achieve capacity on a wide spectrum of channels using a low-complexity successive cancellation decoder. Polar codes make a strong case for magnetic recording, because they have low complexity decoders and adequate finite-length error-rate performance. In their current form, polar codes are not feasible for magnetic recording for two reasons. Firstly, there is no low-complexity soft-output decoder available for polar codes that is required for turbo-based equalization of the magnetic recording channel. The only soft-output decoder available to date is a message passing based belief propagation decoder that has very high computational complexity and is not suitable for practical implementations. Secondly, current polar codes are optimized for the AWGN channel only, and may not perform well under turbo-based detector for ISI channels. This thesis delivers a powerful low-complexity <b>error-correcting</b> <b>system</b> based on polar codes for ISI channels. Specifically, we propose a low-complexity soft-output decoder for polar codes that achieves better error-rate performance than the belief propagation decoder for polar codes while drastically reducing the complexity. We further propose a technique for polar code design over ISI channels that outperform codes for the AWGN channel in terms of error rate under the proposed soft-output decoder. Ph. D...|$|E
50|$|EOS memory (for ECC on SIMMs) is an <b>error-correcting</b> memory <b>system</b> {{built into}} SIMMs, used to upgrade server-class {{computers}} without built-in ECC memory support. The EOS SIMM itself does the error checking, with {{no need for}} ECC memory modules and support. The technology was introduced by IBM in the mid-1990s.|$|R
40|$|The {{influence}} of envelope source and loadterminations on theRF performance of high power GaN amplifiers is investigated. An <b>error-corrected</b> two-tonemeasurement <b>system</b> {{has been developed}} enabling load- and source pull measurements in the envelope frequencybandwidth. Measured results on a 0. 5 µm-HEMT with a gatewidth of 8 x 125 µmshow a variation of 1 dB output powerand 8 % PAE...|$|R
40|$|DNA {{self-assembly}} {{has emerged}} as a rich and promising primitive for nano-technology. Experimental and analytical evidence indicates that such systems are prone to errors, and accordingly, several error-correction mechanisms have been proposed for the tile model of selfassembly. These error-correction mechanisms suffer either from high resolution loss or a large {{increase in the number of}} tile-types. In this paper, we propose dimension augmented proof-reading, a technique that uses the third dimension to do error-correction in two dimensional self-assembling systems. This involves no resolution loss in the two dimensions of interest, results in a smaller increase in the number of tile-types than previous techniques, and appears to have the same errorcorrection properties. <b>Error-correcting</b> <b>systems</b> need to be analyzed in the kinetic Tile Assembly Model; such analysis involves complicated Markov Chains and is cumbersome. In this paper, we also present a set of completely combinatorial criteria that can be used to prove properties of errorcorrecting self-assembling systems. We illustrate these criteria by applying them to two known proof-reading systems, one of which was not previously known to work. We then use these criteria to prove the correctness of dimension augmented proof-reading applied to a selfassembling system that computes the parity of a string. ...|$|R
40|$|Shift {{register}} time-shared in proposed error-correcting {{code for}} tape-storage <b>systems.</b> <b>Error-correcting</b> code logic for blocks of 256 -bit data words implemented by 14 -stage-time-shared shift register, two 4, 096 bit RAM's and logic gates. Encoding and decoding logic implement generator polynomial that defines error-correcting code, and error correction based on algorithm also implemented by logic...|$|R
40|$|Secret sharing is an {{interesting}} subject of cryptography, and has wide applications in real <b>systems.</b> <b>Error-correcting</b> codes {{have been used to}} construct secret sharing schemes. However, it is hard to determine the access structure of them. In this paper, we use certain two-weight codes to construct secret sharing schemes, and analyze their access structure. The secret sharing schemes described in this paper have interesting access structures. © 2005 Elsevier Ltd. All rights reserved...|$|R
40|$|The Consultative Committee for Space Data Standards (CCSDS) {{recommends}} that space communication links employ a concatenated, <b>error-correcting,</b> channel-coding <b>system</b> {{in which the}} inner code is a convolutional (7, 1 / 2) code and the outer code is a (255, 223) Reed-Solomon code. The traditional implementation is to perform the node synchronization for the Viterbi decoder and the frame synchronization for the Reed-Solomon decoder as separate, sequential operations. This article discusses a unified synchronization technique that is required for deep space missions that have data rates and signal-to-noise ratios (SNR's) that are extremely low. This technique combines frame synchronization in the bit and symbol domains and traditional accumulated-metric growth techniques to establish a joint frame and node synchronization. A variation on this technique {{is used for the}} Galileo spacecraft on its Jupiter-bound mission...|$|R
40|$|International audienceThis paper {{presents}} a new automated and vector <b>error-corrected</b> active load-pull <b>system</b> allowing {{the characterization of}} microwave power transistors under coherent pulsed RF and pulsed DC operating conditions. In this paper, {{the use of this}} system is focused on the characterization of a 240 -μm 2 GaInP-GaAs heterojunction bipolar transistor (HBT) (Thomson CSP-LCR, Orsay, France). On one hand, source and load-pull measurements of such a transistor are reported for different pulsewidths. On the other hand, nonlinear simulations based on an electrothermal model of an HBT have been performed and are compared with experiments. Power variations and RF carrier phase shift within the pulse versus input power and junction temperature of the transistor are show...|$|R
40|$|Traditionally, {{fault-tolerance}} {{has been}} the domain of expensive, hard real-time critical systems. However, the rates of transient faults occurring in semiconductor devices will increase significantly due to shrinking structure sizes and reduced operating voltages. Thus, even consumer-grade embedded applications with soft real-time requirements, like audio and video players, will require error detection and correction methods to ensure reliable everyday operation. Cost, timing and energy considerations, however, prevent the embedded system developer from correcting every single error. In many situations, however, {{it will not be}} required to create a totally error-free system. In such a system, only perceptible errors will have to be corrected. To distinguish between perceptible and non-perceptible errors, a classification of errors according to their relevance to the application is required. When real-time conditions have to be observed, the current timing properties of the system will provide additional contextual information. In this paper, we present a structure for an <b>error-correcting</b> embedded <b>system</b> based on a real-time aware classification. Using a cross-layer approach utilizing application annotations of error classifications as well as information available inside the operating system, the error correction overhead can be significantly reduced. This is shown in a first evaluation by analyzing the achievable improvements in an H. 264 video decoder under error injection and simulated error correction. I...|$|R
40|$|Abstract. In CP {{literature}} combinatorial design {{problems such}} as sport scheduling, Steiner <b>systems,</b> <b>error-correcting</b> codes and more, are typically solved using Finite Domain (FD) models despite often being more naturally expressed as Finite Set (FS) models. Existing FS solvers have difficulty with such problems as they do not make strong use of the ubiquitous set cardinality information. We investigate {{a new approach to}} strengthen the propagation of FS constraints in a tractable way: extending the domain representation to more closely approximate the true domain of a set variable. We show how this approach allows us to reach a stronger level of consistency, compared to standard FS solvers, for arbitrary constraints as well as providing a mechanism for implementing certain symmetry breaking constraints. By experiments on Steiner Systems and error correcting codes, we demonstrate that our approach is not only an improvement over standard FS solvers but also an improvement on recently published results using FD 0 / 1 matrix models as well. ...|$|R
40|$|We {{put forward}} {{a new type of}} computationally-sound proof systems, called universal-arguments, which are related but {{different}} from both CS-proofs (as defined by Micali) and arguments (as defined by Brassard, Chaum and Crepeau). In particular, we adopt the instance-based proverefficiency paradigm of CS-proofs, but follow the computational-soundness condition of argument systems (i. e., we consider only cheating strategies that are implementable by polynomial-size circuits). We show that universal-arguments can be constructed based on standard intractability assumptions that refer to polynomial-size circuits (rather than assumptions referring to subexponentialsize circuits as used in the construction of CS-proofs). As an application of universal-arguments, we weaken the intractability assumptions used in the recent non-black-box zero-knowledge arguments of Barak. Specifically, we only utilize intractability assumptions that refer to polynomialsize circuits (rather than assumptions referring to circuits of some "nice" super-polynomial size). Keywords: Probabilistic proof systems, computationally-sound proof systems, zero-knowledge proof systems, proofs of knowledge, probabilistic checkable proofs (PCP), collision-free hashing, witness indistinguishable proof <b>systems,</b> <b>error-correcting</b> codes, Supported by a MINERVA Foundation, Germany. 0...|$|R
40|$|We are {{undergoing}} {{a revolution in}} data. The ever-growing amount of information in our world has created an unprecedented demand for ultra-reliable, affordable, and resource-efficient data storage <b>systems.</b> <b>Error-correcting</b> codes, as {{a critical component of}} any memory device, will {{play a crucial role in}} the future of data storage. One particular class of error-correcting codes, known as graph-based codes, has drawn significant attention in both academia and in industry. Graph-based codes offer superior performance compared to traditional algebraic codes. Recently, it has been shown that non-binary graph-based codes, which operate over finite fields rather than binary alphabets, outperform their binary counterparts and exhibit outstanding overall performance. For this reason, these codes are particularly suitable for emerging data storage systems. In this dissertation, we present a comprehensive combinatorial analysis of non-binary graph-based codes. We perform both finite-length and asymptotic analyses for these codes, providing a systematic framework to evaluate and optimize various families of non-binary graph-based codes. In the finite-length case, we provide a mathematical characterization of the error floor problem, including a general definition of absorbing sets over non-binary alphabets. We consider several structured low-density parity-check (LDPC) codes, including quasi-cyclic and spatially-coupled codes, as well as unstructured LDPC codes. We offer design guidelines for non-binary LDPC codes with outstanding performance in extremely low error-rate regimes; making them excellent candidates for data storage applications. In the asymptotic case, we provide a novel toolbox for the evaluation of families of non-binary graph-based codes. By utilizing insights from graph theory and combinatorics, we establish enumerators for a general family of graph-based codes which are constructed based on protographs. We provide asymptotic distributions of codewords and trapping sets for the family of protograph-based codes. Furthermore, we present an asymptotic enumeration of binary and non-binary elementary absorbing sets for regular code ensembles. The contributions of this dissertation can potentially impact a broad range of data storage and communication technologies that require excellent performance in high-reliability regimes...|$|R
40|$|The {{paper is}} devoted to the class {{construction}} of the most non-linear Boolean bent-functions of any length  N  = 2 k  (k  = 2, 4, 6 …), {{on the basis of their}} spectral representation – Agievich bent squares. These perfect algebraic constructions are used as a basis to build many new cryptographic primitives, such as generators of pseudo-random key sequences, crypto graphic  S -boxes, etc. Bent-functions also find their application in the construction of  C -codes in the systems with code division multiple access (CDMA) to provide the lowest possible value of Peak-to-Average Power Ratio (PAPR)   k  = 1, as well as for the construction of <b>error-correcting</b> codes and <b>systems</b> of orthogonal biphasic signals. All the numerous applications of bent-functions relate to the theory of their synthesis. However, regular methods for complete class synthesis of bent-functions of any length   N   = 2 k   are currently unknown. The paper proposes a regular synthesis method for the basic Agievich bent squares of any order   n, based on a regular operator of dyadic shift. Classification for a complete set of spectral vectors of lengths (l   = 8, 16, …) based on a criterion of the maximum absolute value and set of absolute values of spectral components has been carried out in the paper. It has been shown that any spectral vector can be a basis for building bent squares. Results of the synthesis for the Agievich bent squares of order   n   = 8 have been generalized and it has been revealed that there are only 3 basic bent squares for this order, while the other 5 can be obtained with help the operation of step-cyclic shift. All the basic bent squares of order   n   = 16 have been synthesized that allows to construct the bent-functions of length   N   = 256. The obtained basic bent squares can be used either for direct synthesis of bent-functions and their practical application or for further research in order to synthesize new structures of bent squares of orders   n   = 16, 32, 64, … </p...|$|R

