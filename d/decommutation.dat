66|0|Public
5000|$|<b>Decommutation</b> of {{parameter}} values, and {{association of}} these values with mnemonics ...|$|E
50|$|The frame {{synchronizer}} immediately follows the bit synchronizer in most telemetry applications. Without frame synchronization, <b>decommutation</b> is impossible.|$|E
50|$|Commutation {{is named}} by analogy with {{electric}} commutators, which engage multiple electrical contacts in sequence as they rotate; similarly, telemetry commutation involves sampling {{a sequence of}} data points in turn, {{before returning to the}} first data point. Hardware or software which performs commutation is referred to as a commutator; its opposite at the receiving end is a decommutator. Dedicated hardware generally supports faster commutation and <b>decommutation</b> than software on a general purpose architecture.|$|E
50|$|The frame {{synchronization}} pattern is a known binary pattern which repeats at a regular interval within the PCM stream. The frame synchronizer recognizes this pattern and aligns the data into minor frames or sub-frames. Typically the frame sync pattern {{is followed by}} a counter (sub-frame ID) which dictates which minor or sub-frame in the series is being transmitted. This becomes increasingly important in the <b>decommutation</b> stage where all data is deciphered as to what attribute was sampled. Different commutations require a constant awareness of which section of the major frame is being decoded.|$|E
40|$|A generic <b>decommutation</b> {{capability}} {{has been}} created {{as part of the}} Space Flight Operation Center's goal of developing a multimission telemetry system. Generic <b>decommutation</b> involves separating the algorithmic description for extracting data from the actual implementation of <b>decommutation.</b> This was done by creating a <b>decommutation</b> map language, which allows mission designers to describe <b>decommutation</b> algorithms without the restrictions imposed by a standard programming language. A <b>decommutation</b> map compiler converts this description into C code, which is then linked with a <b>decommutation</b> library to provide an executable <b>decommutation</b> program. So far, this approach has been used successfully to decommutate several different types of data...|$|E
40|$|International Telemetering Conference Proceedings / October 17 - 20, 1988 / Riviera Hotel, Las Vegas, NevadaA generic <b>decommutation</b> {{capability}} {{has been}} created {{as part of the}} Space Flight Operation Center's goal of developing a multi-mission telemetry system. Generic <b>decommutation</b> involves separating the algorithmic description for extracting data from the actual implementation of <b>decommutation.</b> This was done by creating a <b>Decommutation</b> Map Language, which allows mission designers to describe <b>decommutation</b> algorithms without the restrictions imposed by a standard programming language. A <b>Decommutation</b> Map Compiler converts this description into C code, which is then linked with a <b>decommutation</b> library to provide an executable <b>decommutation</b> program. So far, this approach has been used successfully to decommutate several different types of data...|$|E
40|$|ITC/USA 2012 Conference Proceedings / The Forty-Eighth Annual International Telemetering Conference and Technical Exhibition / October 22 - 25, 2012 / Town and Country Resort & Convention Center, San Diego, CaliforniaThe Test and Training Enabling Architecture (TENA) is {{implemented}} within the TENA Software <b>Decommutation</b> System (TSDS) {{in order to}} bring TENA {{as close as possible to}} the sensor interface. Key attributes of TSDS include: • TSDS is a software-based approach to telemetry stream <b>decommutation</b> implemented within Java. This offers technical advantages such as platform independence and portability. • TSDS uses auto code generation technologies to further reduce the effort associated with updating <b>decommutation</b> systems to support new telemetry stream definitions. Users of TSDS within the range are not required to have detailed knowledge of proprietary protocols, nor are they required to have an understanding of how to implement <b>decommutation</b> within software. The use of code generation in software <b>decommutation</b> offers potential cost savings throughout the entire T&E community. • TSDA offers a native TENA interface so that telemetry data can be published directly into TENA object models...|$|E
40|$|The {{requirements}} are defined {{for developing a}} <b>decommutation</b> and a data reformat program to process test data obtained by the balloon-borne ultraviolet stellar spectrometer used in a joint experiment with the Space Research Laboratory in the Netherlands. Background information and objectives are discussed...|$|E
40|$|ITC/USA 2009 Conference Proceedings / The Forty-Fifth Annual International Telemetering Conference and Technical Exhibition / October 26 - 29, 2009 / Riviera Hotel & Convention Center, Las Vegas, NevadaIt is {{well known}} that current PCM {{telemetry}} formats are outstripping the capability of commercial off-the-shelf (COTS) Telemetry Systems to implement the corresponding data conversions required to process them. Two complementary approaches are needed for solving this problem: one is to put end users into direct touch with the information stored in telemetry streams; and the other is to convert telemetry applications into this new way of doing things. It is less known that a single technology, software <b>decommutation,</b> provides a practical foundation for both approaches. This document explains why this is so. While developing this software <b>decommutation</b> theme, a very sharp line must be drawn between a software <b>decommutation</b> approach and the COTS telemetry systems solution so that the label "software decommutation" will not be used in misleading ways. The key to drawing this line is SDM's (Software <b>Decommutation</b> Model) ability to: * Extract bits from the raw telemetry stream into 64 -bit parameter "containers" in a platform independent ("big endian" or "little endian") manner. * Process algorithms in an algorithm chain on telemetry parameter data to support the desired formatting (i. e. engineering unit conversion). * Easily integrate "special" processing of non-IRIG 106 telemetry data as required (i. e. multiple embedded streams, mode changes, embedded packetized data, etc.). * Independently interface to user-developed data displays locally or via a network connection. *Note: The SDM cannot process a PCM stream directly; to do its job, a databridge is required that provides telemetry data as frame aligned IP packets via a network port...|$|E
40|$|The {{results of}} an {{analysis}} of the Spacelab (SL) data uplink/downlink structure and those data system elements associated with the support of this data flow are presented. Specific objectives of this report are to present the results of the following analyses: (1) operations of the SL high rate multiplexer, including format structure, data rates, format combinations, format switching, etc.; (2) operations of SL data recorders to include the definition of modes, data rates and forms; (3) operations of the high rate demultiplexer as described above; (4) potential experiment data formats defining formatting parameters to be considered in <b>decommutation</b> analysis; (5) SL computer input/output (I/O) <b>decommutation</b> channels, including the definition of structure, quantity and use of this I/O data; (6) detailed requirements of the data quality monitoring philosophy for this function...|$|E
40|$|International Telemetering Conference Proceedings / October 26 - 29, 1987 / Town and Country Hotel, San Diego, CaliforniaThis paper {{presents}} a non-standard digitization scheme which samples the data asymmetrically {{in order to}} maximize data bandwidth. Two frame sychronization words are utilized in a separated manner to permit their replacement with the average value of adjacent data words during the <b>decommutation</b> process...|$|E
40|$|International Telemetering Conference Proceedings / September 28 - 30, 1982 / Sheraton Harbor Island Hotel and Convention Center, San Diego, CaliforniaEvolving {{growth in}} Navy ship-to-air missile design has {{resulted}} in a need for larger quantities of telemetry information with increasing emphasis on digital telemetry. This has inherently led to the requirement for telemetry processing equipment that is adaptable to these changing missile telemetry data formats. The design for the Telemetry Recording and Reduction Equipment (TRRE), that incorporates today’s technology into a compact, realtime analysis tool for shipboard use, is presented in this paper. The TRRE was designed to process both the Pulse Amplitude Modulation (PAM) telemetry data formats of existing missile designs and the Pulse Code Modulation (PCM) data formats of evolving missile designs. The TRRE design minimizes the required operator interace through preprogrammed telemeter formats and programmable <b>decommutation</b> tables. A microprocessor is utilized in the design to program the <b>decommutation</b> hardware configuration...|$|E
40|$|Two {{different}} {{system architectures}} are presented. The two architectures {{are derived from}} two different data flows within the Spacelab Output Processing System. The major differences between these system architectures are {{in the position of}} the <b>decommutation</b> function (the first architecture performs <b>decommutation</b> {{in the latter half of}} the system and the second architecture performs that function in the front end of the system). In order to be examined, the system was divided into five stand-alone subsystems; Work Assembler, Mass Storage System, Output Processor, Peripheral Pool, and Resource Monitor. The work load of each subsystem was estimated independent of the specific devices to be used. The candidate devices were surveyed from a wide sampling of off-the-shelf devices. Analytical expressions were developed to quantify the projected workload in conjunction with typical devices which would adequately handle the subsystem tasks. All of the study efforts were then directed toward preparing performance and cost curves for each architecture subsystem...|$|E
40|$|A {{programmable}} telemetry processor {{was designed}} for the NASA Goddard Space Flight Center {{in support of the}} Systems Utilization Enhancement (SUE) upgrade of the NASA tracking stations at Merritt Island, FL, and Bermuda. The processor is an integrated hardware and software system that performs the front-end telemetry synchronization and <b>decommutation</b> functions and provides for application-specific data processing. This paper presents the design, architecture, and features of the microprocessor controlled unit...|$|E
40|$|The {{basic design}} is {{described}} of the Atmosphere Explorer Control System (AECS) software {{used in the}} testing, integration, and flight contol of the AE spacecraft and experiments. The software performs several vital functions, such as issuing commands to the spacecraft and experiments, receiving and processing telemetry data, and allowing for extensive data processing by experiment analysis programs. The major processing sections are: executive control section, telemetry <b>decommutation</b> section, command generation section, and utility section...|$|E
40|$|The NASA Johnson Space Center's new Multiprogram Control Center (MPCC) {{addresses}} the control requirements of complex STS payloads {{as well as}} unmanned vehicles. An account is given {{of the relationship of}} the MPCC to the STS Mission Control Center, with a view to significant difficulties that may be encountered and solutions thus far devised for generic problems. Examples of MPCC workstation applications encompass telemetry <b>decommutation,</b> engineering unit conversion, data-base management, trajectory processing, and flight design...|$|E
40|$|International Telemetering Conference Proceedings / October 18 - 21, 2004 / Town & Country Resort, San Diego, CaliforniaThe use of {{traditional}} telemetry <b>decommutation</b> equipment {{can be easily}} expanded to create a real-time pulse code modulation (PCM) telemetry data recorder. However, there are two areas that create unique demands where architectural investment is required: the PCM output stage and the storage stage. This paper details the efforts to define the requirements and limits of a traditional telemetry system when used as a real-time, multistream PCM data recorder with time tagging...|$|E
40|$|The use of low-power, high-rate {{pulse code}} {{modulation}} (PCM) in a helicopter instrumentation system is examined. A Helicopter Instrumentation and Recording System (HIARS) was developed to obtain main rotor blade measurements and fuselage performance measurements. The HIARS consists of a low-power PCM telemeter, a digital PCM system, an optical rotor position sensor, and a PCM <b>decommutation</b> unit; the components and functions of these subsystems are described. Flight tests were conducted to evaluate {{the ability of the}} HIARS to measure aircraft parameters. The test data reveal that the PCM telemetry is applicable to helicopter instrumentation systems...|$|E
40|$|The {{processing}} stage {{in which the}} restored values of the physical parameters are received is described. The following main steps are discussed: estimation {{of the state of}} the telemetry data, processing of the calibration data, and determination of the errors in the data; data <b>decommutation</b> and analysis of the structure of measurement cycles for each instrument; decoding, estimates of the reliability of the restored data, and their agreement with the models adopted for the measurement process; and analysis of errors due to deterministic and random factors. A block diagram of the method is presented...|$|E
40|$|The {{preparation}} of remotely sensed data sets {{into a form}} useful to the analyst is a significant computational task, involving the processing of spacecraft data (e. g., orbit, attitude, temperatures, etc.), <b>decommutation</b> of the video telemetry stream, radiometric correction and geometric correction. Many of these processes are extremely well suited for implementation on attached array processors. Currently, at Goddard Space Flight Center a number of computer systems provide such capability for earth observations or are under development as test beds for future ground segment support. Six such systems will be discussed...|$|E
40|$|ITC/USA 2005 Conference Proceedings / The Forty-First Annual International Telemetering Conference and Technical Exhibition / October 24 - 27, 2005 / Riviera Hotel & Convention Center, Las Vegas, NevadaThe Telemetry Data Center (TDC) at White Sands Missile Range (WSMR), New Mexico {{recently}} targeted analog {{best source}} selectors for replacement {{along with their}} associated signal handling equipments. The commercial selectors available offered no better performance, so TDC engineers circulated a "White Paper" on real time correlation based compositing. Within two years a Correlating Source Selector (CSS) was fielded successfully. The CSS’s bridging feature unexpectedly {{opened the door to}} a ubiqituous software decommutator (decom) that has catalyzed a complete “make-over” of the entire TDC architecture. Hardware and software interaction in a decom is different with the CSS. While performing its correlation tasks the CSS is able to provide raw data over TCP/IP directly to the end application. The CSS places the data in computer friendly frame aligned form and the <b>decommutation</b> may be performed in software. The converse is similarly simple, a data file maybe transferred to the CSS for commutation into PCM. This white paper describes the morphing of software <b>decommutation</b> into a commodity, integrated into each end device, be it graphics display, Disk or Chart recorder. The result is an interesting consolidation that spawns a new functionally integrated Telemetry Data Center (iTDC). This integrated Display Decom (iDD) concept has been demonstrated on Apple G 5 RISC computers...|$|E
40|$|TDPlus {{computer}} program software system for <b>decommutation</b> of pulse-code-modulation (PCM) telemetry signals. Provides synchronization, conversion into engineering units, and display of serial bit streams. Transforms IBM PC-compatible computer into PCM-telemetry-decommutation system. Synchronizes telemetric signals data and enables conversion back into such meaningful forms as voltage, current, pressure, and the like. Also controls operation of digital-to-analog converters to ship data to paper strip charts or to parallel digital ports for offloading to other computers. Software used to process actual data only when telemetry-data-processing computer modified {{in accordance with}} specifications contained in "TDPlus TM Data Processor" (GSC- 13291). Written in Turbo C and 8088 Assembly language...|$|E
40|$|International Telemetering Conference Proceedings / October 13 - 15, 1970 / International Hotel, Los Angeles, CaliforniaThe type of {{functions}} required to optimally process PCM plus noise {{are the same}} at low and high bit rates. At high bit rates there are severe constraints in synthesizing these functions due to limitations of present day devices and logic; and due to extrinsic effects of networks over broad baseband bandwidths. Techniques developed for signal conditioning, bit synchronization, group synchronization, and <b>decommutation</b> of NRZ PCM from 10 Mb/sec to 200 Mb/sec are presented. Multiple techniques were investigated in each area over the complete bit rate range of interest to ascertain performance versus complexity and cost effectiveness among different techniques at different bit rates...|$|E
40|$|International Telemetering Conference Proceedings / October 13 - 16, 1986 / Riviera Hotel, Las Vegas, NevadaThis paper {{describes}} an on-board PCM data acquisition and processing system using standard PCM units and commercial micro-computer equipments. A special interface, which {{was developed in}} order to allow a direct connection to PCM encoders, is also presented. It performs data buffering and <b>decommutation</b> prior to the data acquisition process. This approach facilitated the independent conduction of flight tests away from the users’ ground stations using a minimal investment. It helped to provide test results in flight or immediately after flights, thus shortening the flight test processing turn around time and contributing to expedite the overall flight test program...|$|E
40|$|Relikt- 2 is {{a russian}} astronomical satellite. Its main task is {{measuring}} of the anisotropy {{of the cosmic}} background radiation. 1999 / 2000 it will be launched into a halo orbit around the Lagrange point. Beside it's main task, plasma devices on board should allow basic research investigations of the physics of hot plasma under {{the conditions of the}} far tail. Interactions of the particles with plasma fluctuations instead of Coulomb forces characterize the transport properties, reconnection, heating, and acceleration. The fluctuation sensor IFP-R {{as a part of the}} plasma and magnetic field analyser APW-R is specially designed to investigate these processes. Its hardware is improved compared to the precursor model IFPE (INTERBALL- 1). Due to the limited payload, ion sensors will be used only. The development of the hardware has been advanced to ordering the production of the electronic box. The concept of IFP-R was reworked with the experiences with IFPE on INTERBALL- 1. Due to the fact that the launch didn't take place up to now, beside the hardware production, mainly methodical and preparatory work has been done mainly. A contract about the development and delivery of <b>decommutation</b> software was signed with the IKI Moscow. Newly developed processing software and russian <b>decommutation</b> programs were tested with INTERBALL- 1 and PROGNOZ- 8 data. Model calculations were carried out for optimization of device parameters. Measuring ranges were estimated by kinetic and MHD simulations. (orig.) SIGLEAvailable from TIB Hannover: DtF QN 1 (64, 5) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Bildung, Wissenschaft, Forschung und Technologie, Bonn (Germany); Deutsche Agentur fuer Raumfahrtangelegenheiten (DARA) GmbH, Bonn (Germany) DEGerman...|$|E
40|$|International Telemetering Conference Proceedings / October 25 - 28, 1999 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe {{trend of}} current data {{acquisition}} and recording systems is to capture multiple streams of Pulse Code Modulation (PCM) {{data on a}} single media. The MARS II data recording system manufactured by Datatape, the Asynchronous Realtime Multiplexer and Output Reconstructor (ARMOR) systems manufactured by Calculex, Inc., and other systems {{on the market today}} are examples of this technology. The quantity of data recorded by these systems can be impressive, and can cause difficulties in post-test data processing in terms of data storage and turn around time to the analyst. This paper describes the system currently in use at the Strategic Systems Combined Test Force B- 1 B division to simultaneously post-flight process up to twelve independent PCM streams at twice real-time speeds. This system is entirely personal computer (PC) based running the Window NT 4. 0 operating system with an internal ISA bus PCM <b>decommutation</b> card. Each PC is capable of receiving and processing one stream at a time. Therefore, the core of the system is twelve PCs each with <b>decommutation</b> capability. All PCs are connected via a fast ethernet network hub. The data processed by this system is IRIG 106 Chapter 8 converted MIL-STD- 1553 B bus data and Chapter 4 Class I and II PCM data. All system operator inputs are via Distributed Component Object Modeling (DCOM) provided by Microsoft Developers Studio, Versions 5. 0 and 6. 0, which allows control and status of multiple data processing PCs from one workstation. All data processing software is written in-house using Visual C++ and Visual Basic...|$|E
40|$|The {{modifications}} made to {{both the}} AVIRIS instrument and the data processing facility since the instrument made its initial flight {{in the summer of}} 1987 are described. Historical development of the data system is discussed and attention is given to enhancements to instrument stability and noise performance. AVIRIS data facility objectives include rapid and automated <b>decommutation</b> and archiving of data, the ability to assess the quality of the data and health of the instrument, and the provision of an automated procedure for applying radiometric corrections to the data and providing responsive processing of data requests from investigators. The modifications described have resulted in an overall radiometric stability of better than 10 percent, with stability of only a few percent during a single flight...|$|E
40|$|International Telemetering Conference Proceedings / October 13 - 16, 1986 / Riviera Hotel, Las Vegas, NevadaThis paper {{presents}} a method developed to automate the data base entry and setup of the ADS 100 <b>Decommutation</b> System. Automation {{was accomplished by}} interfacing an existing RS- 232 C port with a VAX computer. Other available interface options are considered. The automated system provides a method for rapid data entry while minimizing errors. Automation also eliminates the continuing requirement for a skilled ADS 100 programmer. Additional topics reviewed are the various problems encountered while developing the interface. Also discussed is the development and interface of host computer software, including the predefined ADS 100 record structures. The final result is a complete and accurate digital data base setup in the ADS 100 system...|$|E
40|$|A Generic Mission Operations System using Expert System {{technology}} {{to demonstrate the}} potential of Artificial Intelligence (AI) automated monitor and control functions in a Mission Operations and Satellite Test environment will be developed at the National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL). Expert system techniques in a real time operation environment are being studied and applied to science and engineering data processing. Advanced <b>decommutation</b> schemes and intelligent display technology will be examined to develop imaginative improvements in rapid interpretation and distribution of information. The Generic Payload Operations Control Center (GPOCC) will demonstrate improved data handling accuracy, flexibility, and responsiveness in a complex mission environment. The {{ultimate goal is to}} automate repetitious mission operations, instrument, and satellite test functions by the applications of expert system technology and artificial intelligence resources and to enhance the level of man-machine sophistication...|$|E
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1995 / Riviera Hotel, Las Vegas, NevadaThe Consultative Committee on Space Data Systems (CCSDS) did {{not create}} a {{specification}} like the IRIG 106, but rather a recommendation [1 - 4]. That means that each country, community, and application is free to select subsets, adapt techniques, and even alter the structure to suit particular needs. This variability places new demands on a <b>decommutation</b> system. The implementation of the CCSDS Recommendation in the Loral 550 accommodates this "variability within a structure" by using a modular and adaptable collection of structured components. The result covers the two most popular versions of CCSDS: Conventional/Telecommand and the Advanced Orbital Systems (AOS) in both operational and test modes, and couples the CCSDS inputs and outputs {{to a host of}} other data format and processing options...|$|E
40|$|ITC/USA 2012 Conference Proceedings / The Forty-Eighth Annual International Telemetering Conference and Technical Exhibition / October 22 - 25, 2012 / Town and Country Resort & Convention Center, San Diego, CaliforniaThis paper {{discusses}} the current development of all-in-one telemetry displays. This system provides a self-configuring environment utilizing common telemetry display objects that setup and deploy. Often range display systems require frequent revision {{to reason with}} changing requirements. The display is rendered accordingly as a strip-chart equivalent or other element, per requirements from a flight safety officer for example. Our reusable code system approach {{is based on a}} novel abstraction of the display elements. The approach may be deployed beyond the <b>decommutation</b> stage as is typically done or interface directly to a plug in software decommutator. This system's plug-and-play functionality facilitates rapid deployment of interoperable Department of Defense (DOD) range displays and recorders...|$|E
40|$|International Telemetering Conference Proceedings / November 04 - 07, 1991 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe Telemetry Test Station {{has been}} {{developed}} at the Digital Systems Division, ISRO Satellite Centre, to test the housekeeping telemetry packages which will be flown onboard satellites. The heart of the test procedure is the <b>decommutation,</b> display and processing of the telemetry output format. The <b>decommutation</b> has been achieved by designing a simple plug in card to an IBM PC/XT compatible computer and writing the related assembly language software. The card and the software have been extensively tested and found to work satisfactorily upto 60 Kbps PCM data rate. To make the hardware and software flexible and truly general purpose, the acquisition should be independent of the modes of operation and data formats. All the parameters which define acquisition display and processing are therefore programmable and can be changed at any time. The parameters which influence acquisition are bit rate, word rate, frame rate, length of word, length of frame and frame synchronous code. The bit rate is transparent, i. e., need not be set by the user. The word length {{is assumed to be}} 8 bits or multiples of 8 bits. The other parameters are programmable {{at any time during the}} test session. Similarly, the parameters which affect display are the display rate, and positioning of the format including highlighting, alarm signals, related information etc. This gives a user the facility to tailor the display to his liking. The storage is also flexible and independent of display. All these modes are in real time and have therefore been coded in assembly. It has been found that a large part of the software is needed for user interface alone and user requirement is far more changeable than expected. The software is therefore designed for change. The problems and solutions in achieving these features are discussed in this paper...|$|E
40|$|International Telemetering Conference Proceedings / October 13 - 15, 1970 / International Hotel, Los Angeles, CaliforniaThis paper {{discusses}} the Manned Space Flight Network (MSFN) Telemetry System {{as it has}} been developed through the Mercury, Gemini, and Apollo programs and is now being modified to meet Skylab, Earth Resources Technology Satellite (ERTS), and Apollo "J" mission (Apollo 16 and subsequent lunar missions) requirements. The existing telemetry system must be modified to meet the requirements of these future programs. This modification will consist of the implementation of automated configuration switching, centralized control of telemetry subsystems, tunable FM and PSK modulators/ demodulators, high frequency PCM signal conditioners, and the upgrading of both the wide band instrumentation magnetic tape recorders and the PCM <b>decommutation</b> capability. The resulting telemetry system, which will be capable of supporting various manned and unmanned space missions, is described here. Data flow diagrams are delineated and equipment electrical characteristics are discussed...|$|E
40|$|International Telemetering Conference Proceedings / October 24 - 27, 1983 / Sheraton-Harbor Island Hotel and Convention Center, San Diego, CaliforniaThe Setup Bus Expansion Interface, a {{software}} selectable, 8 channel, digital demultiplexor {{was designed as}} an augmentation to the Telemetry Controller System (TMCS) at White Sands Missile Range (WSMR), New Mexico. The TMCS performs ‘front end’ synchronization and <b>decommutation</b> duties for the Telemetry Data Center at WSMR, utilizing EMR 700 series equipment hosted by a DEC PDP 11 / 44 computer/processor. The Setup Bus Expansion Interface has increased the capability of this system by transforming the single setup output bus of the host computer to a selectable 8 bus structure, allowing output of variable parameters to the 700 series equipment entirely from the host computer. The interface also offers dual selectable input on one channel {{to provide for the}} future implementation of a multiplex processor into the TMCS...|$|E
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1989 / Town & Country Hotel & Convention Center, San Diego, CaliforniaThe Naval Ocean Research and Development Activity (NORDA) has {{adapted the}} Loral Instrumentation Advanced <b>Decommutation</b> system (ADS 100) as a {{portable}} maintenance system {{for one of}} its remotely deployable buoy systems. This particular buoy system sends up to 128 channels of amplified sensor data to a centralized A/D for formatting and storage on a high density digital recorder. The resulting tapes contain serial PCM data in a format consistent with IRIG Standard 106 - 87. Predictable and correctable perturbations exist within the data due to the quadrature multiplexed telemetry system. The ADS 100 corrects for the perturbations of the telemetry system and provides the user with diagnostic tools to examine the stored data stream and determine the operational status of the buoy system prior to deployment...|$|E
40|$|International Telemetering Conference Proceedings / October 02 - 04, 1967 / Marriott Motor Hotel, Washington, D. C. The {{trend toward}} more {{automated}} PCM <b>decommutation</b> systems demands less operator intervention in their operation. A weak link in this progression {{has been in}} the implementation of group synchronizer strategy. A new synchronizer has been developed based on the optimum properties of sequential probability ratio testing which requires only one program based on required worst case decision error probabilities and which is independent of the PCM format being synchronized. A mathematical model is formulated which accurately describes the operating characteristics of this technique. These operating characteristics are then compared to conventional synchronizer characteristics which demonstrate the superiority of this approach. The decision process described inherently adapts to signal conditions by making decisions faster and with less chance of error as bit error rate decreases. Only the Check Mode is discussed, but the same techniques apply to the Lock Mode...|$|E
