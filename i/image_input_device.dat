5|10000|Public
40|$|In this paper, a {{high-performance}} face recognition terminal for access control systems is described. The terminal is specially designed to acquire stable face patterns for reliable recognition. To determine design of an <b>image</b> <b>input</b> <b>device,</b> we evaluate similarity values and their changes for {{three types of}} lighting apparatuses. Our basic experiment indicates {{that a combination of}} the upper-right lamp and the lower lanip accomplishes the best performance. Though an experiment using 100 individuals, we explain that the face recognition terminal achieves a competitive performance compared with other biometrics devices and offers better user-interfaces such as contact-less verification and remote monitoring. ...|$|E
40|$|Some of the {{information}} that as used in arriving at a design for a high quality <b>image</b> <b>input</b> <b>device</b> is documented. The device uses a PIN photo-diode directly coupled to an FET-input op-amp as the sensor and two moving-iron galvanometer-driven mirrors as the deflection system. The disadvantages of a system like this are its long random access time (about 4 milli-seconds) and the long settling time of the diode-amplifier system (about 1 milli-seconds). In almost all other respects such a sensor is superior to other known image sensors. Pictures taken with this device have shown that some of the difficulties experienced in image analysis can be directly traced to the low quality of images read in through vidicons and image dissectors. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the laboratory's artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N 00014 - 70 -A- 0362 - 0005. MIT Artificial Intelligence Laborator...|$|E
40|$|Abstract — In these days, {{there are}} many vessel traffics to trade with foreign nations and travel abroad. Near coast or in harbor, the more traffics of transportation, the more {{possibility}} of accidents tends to occur. Thus, to reduce ships collision, vessel traffic services (VTS) centers have installed lots of equipment to {{keep a close eye}} on ships sailing in sea port, such as night observation device, telescope, and CCTV. To improve efficiently existing tracking system and overcome flaw of noises in the process of pursuit in maritime environment, considering bad weather and waves, this paper presents vessel tracking system using an <b>image</b> <b>input</b> <b>device.</b> The tracking system uses a fusion of Bayesian classifier to distinguish some images at initial stage, Kalman filter algorithm for keeping tracking the watercraft when it cannot be detected from the obtained image because some noises or inappropriate parameters used in the library functions may prevent detection from successive pictures, and the adaptive tracking algorithm for not only whether Kalman filtering is used as adaptive way to reduce a computational time but also disregarding the noise interference. The experimental results are included to prove the validity of the proposed method...|$|E
40|$|This chapter {{presents}} the requirements {{and recommendations for}} display monitors, DVD playback, and video <b>input</b> and capture <b>devices</b> under the Microsoft Windows family of operating systems. Requirements for graphics adapters and TV output capabilities are defined in the “Graphics Adapters ” chapter in Part 4 of this guide. For requirements related to digital cameras and other digital <b>image</b> <b>input</b> <b>devices,</b> see the “Scanners an...|$|R
50|$|Macaw (metadata software) is an {{open-source}} metadata collection tool {{written by}} J. Richard, Digital Services Division. Macaw accomplishes 3 tasks in the scanning workflow:(1) import and manage <b>images</b> from <b>input</b> <b>device</b> (scanner or camera); (2) collect page-level metadata about physical aspects of scanned page; (3) post-processing and exporting digital book to other systems.|$|R
50|$|The {{virtual machine}} can {{interface}} with {{many types of}} physical host hardware. These include: hard disks, CD-ROM drives, network cards, audio interfaces, and USB devices. USB devices can be completely emulated (mass storage from <b>image</b> files, <b>input</b> <b>devices),</b> or the host's USB devices can be used (however, this requires administrator privileges and does not work with all devices).|$|R
40|$|The {{progress}} {{and technology in}} development of transportation is increasing. However, this is also accompanied {{by the emergence of}} some undesirable negative effects such as increased number of traffic accidents. The increase in number of accidents is usually caused by various factors including human factors, vehicle factors, and environmental factors. The human factor {{is one of the most}} frequent factors causing traffic accidents. This system is designed as the manufacture of detection software for detect the condition of eyestrain in the driver of the vehicle using a camera connected to the computer as an <b>image</b> <b>input</b> <b>device</b> and measured performance of system develeopment. The method used in this system is to detect faces with segmentation RGB color to YCBCR color, eye detect with Roberts edge and the last method of simple logic as a classification of eye conditions. The system shows the results of classification with the highest accuracy is on video 1 of 85. 40 % and the lowest accuracy in video 7 is 13. 67 % whereas, the highest accuracy warning results on video 5 with 94. 4 % and the least accurate accuracy of warning with 25. 26 %...|$|E
40|$|The {{main purpose}} of this {{research}} is to construct a highly efficient low cost image-calculation system. In this system the distance between the user and the targeted object can be calculated by a light signal (Super LED) received from a <b>image</b> <b>input</b> <b>device</b> (CCD). We are trying to accomplish two things: an image measurement in conjunction with an image depth and a fast measurement of the image`s distance. Of course, it is difficult to measure the distance between an object and an image using a simple eye lens (CCD). The hardware platform of a system is composed of a light source, a Web cam and a convex lens constitute. According to the principle of parallel optical axis, the distance can be obtained by conveying the image to the system via USB communication interface, applying a characteristic (a straight line between the light source and the object), utilizing the dimension data and using a variety of light from the light source. Consequently, the experimental results reveal that the distance between the object and the image lens can be acquired by utilizing a system where the image calculation in conjunction with a vision algorithm is used. </p...|$|E
40|$|In this paper, {{methods for}} the {{colorimetric}} characterisation of colour scanners are proposed and evaluated. These methods apply equally to other colour <b>image</b> <b>input</b> <b>devices</b> such as digital cameras. The goal of our characterisation {{is to establish}} {{the relationship between the}} device-dependent colour space of the scanner and the device-independent CIELAB colour space. The scanner characterisation is based on polynomial regression techniques. Several regression schemes have been tested. The retained method consists in applying a non-linear correction to the scanner RGB values followed by a 3 rd order 3 D polynomial regression function directly to CIELAB space. This method gives very good results in terms of residual colour differences. This is partly {{due to the fact that}} the RMS error that is minimised in the regression corresponds to ΔE*ab which is well correlated to visual colour differences...|$|R
40|$|This report {{describes}} {{a personal computer}} based system for automatic and semiautomatic tracking of objects on film or video tape, developed {{to meet the needs}} of the Microgravity Combustion and Fluids Science Research Programs at the NASA Lewis Research Center. The system consists of individual hardware components working under computer control to achieve a high degree of automation. The most important hardware components include 16 -mm and 35 -mm film transports, a high resolution digital camera mounted on a x-y-z micro-positioning stage, an S-VHS tapedeck, an Hi 8 tapedeck, video laserdisk, and a framegrabber. All of the <b>image</b> <b>input</b> <b>devices</b> are remotely controlled by a computer. Software was developed to integrate the overall operation of the system including device frame incrementation, grabbing of image frames, image processing of the object's neighborhood, locating the position of the object being tracked, and storing the coordinates in a file. This process is performed repeatedly until the last frame is reached. Several different tracking methods are supported. To illustrate the process, two representative applications of the system are described. These applications represent typical uses of the system and include tracking the propagation of a flame front and tracking the movement of a liquid-gas interface with extremely poor visibility...|$|R
40|$|As the {{applications}} of the OCR are widely expanding recently, computers have to extract character patterns from various types of images such as scanned document images, scene images and video frames. Many methods for character pattern extraction have been proposed so far. They were designed and tuned for a special type of image and for a certain <b>input</b> <b>device.</b> However, we have many images which cannot be processed by the conventional framework. It is necessary for us to develop an allpurpose, unified processing which can extract character patterns from various types of <b>images</b> using various <b>input</b> <b>devices.</b> To realize the unified processing, we previously developed a character pattern extraction method based on the local multilevel processing and the region growing. The performance of the method was evaluated using scanned document images, however, no detailed evaluation has been performed for scene images. By the new experiments using scene images, we have verified that the method works well even for scene images. The rate of text line extraction is 75 %, which is almost {{same as that of}} a conventional method. Although the rate is not very high, the remarkable property of our method is that it is applicable to various types of images. ...|$|R
40|$|In this paper, online {{handwritten}} Devnagari word recognition {{system is}} proposed and discussed. The increase in usage of handheld devices which accept handwritten data as input created {{a demand for}} application which analyze and recognize data efficiently. Due to the popularity of digital device, we use Smartphone as <b>input</b> <b>device.</b> <b>Input</b> <b>image</b> is drawn on Smartphone. Feature extraction of <b>input</b> <b>image</b> is done by android technology. Using that features HMM recognizes the word. Experimental results show advantages of this method {{in the field of}} handwriting recognition...|$|R
40|$|This paper {{presents}} {{our approach}} {{for exploring the}} design space of <b>input</b> <b>devices</b> for three-dimensional graphics applications. We use an extended <b>input</b> <b>device</b> taxonomy as an inspiring source for generating permutations of sensors to suggest sensor configurations for new <b>input</b> <b>devices.</b> The taxonomy uses the integrated and separated degrees of freedom of an <b>input</b> <b>device</b> as a major classification criterion. We suggest and discuss <b>input</b> <b>devices</b> with six and twelve degrees of freedom, which are inspired by our taxonomy. By examining the properties of various devices and the different phases of a docking task, the idea for an <b>input</b> <b>device</b> with redundant degrees of freedom is derived. ...|$|R
5000|$|ZigBee <b>input</b> <b>device</b> - ZigBee (RF4CE) {{supports}} HID devices {{through the}} ZigBee <b>input</b> <b>device</b> profile.|$|R
40|$|Abstract: Experimental {{studies of}} spatial <b>input</b> <b>devices</b> {{have focused on}} demonstrating either the superiority of 3 D <b>input</b> <b>devices</b> over 2 D <b>input</b> <b>devices,</b> or the superiority of bimanual {{interaction}} over unimanual interaction. In this paper, we argue that hybrid interfaces that combine a 3 D <b>input</b> <b>device</b> with a 2 D <b>input</b> <b>device</b> have received little attention up to now and are potentially very useful. We demonstrate {{by means of an}} experimental evaluation that working with hybrid interfaces can indeed provide superior performance compared to strictly 3 D and 2 D interfaces...|$|R
40|$|The ToolStone is a cordless, {{multiple}} degree-of-freedom (MDOF) <b>input</b> <b>device</b> that senses {{physical manipulation}} of itself, such as rotating, flipping, or tilting. As an <b>input</b> <b>device</b> for the non-dominant hand when a bimanual interface is used, the ToolStone provides several interaction techniques including a toolpalette selector, and MDOF interactors such as zooming, 3 D rotation, and virtual camera control. In this paper, {{we discuss the}} design principles of <b>input</b> <b>devices</b> that effectively use a human's physical manipulation skills, and describe the system architecture and applications of the ToolStone <b>input</b> <b>device.</b> KEYWORDS: Interaction techniques, <b>input</b> <b>devices,</b> physical user interfaces, multiple function inputs, multiple-degreeof -freedom input, two-handed input INTRODUCTION Although the mouse is the most successful <b>input</b> <b>device</b> {{in the history of}} computer interfaces, its limits are becoming frustrating as the complexity of software increases. The mouse is a generic <b>input</b> <b>device,</b> so a [...] ...|$|R
40|$|Keyboards {{have been}} used on {{typewriters}} and as <b>input</b> <b>devices</b> to computers and many keyboards have been proposed {{in order to improve}} their performance. Some glove-based <b>input</b> <b>devices</b> to computers have been also proposed for compactness and flexibility. In this paper, an <b>input</b> <b>device</b> to computers consisting of a pair of gloves is proposed. The keys of the proposed gloves are mounted on the fingers of gloves and their chording methods resemble those of a Braille keyboard. Since the Braille representation for numbers and characters is efficient and has been well established for every language, the proposed <b>input</b> <b>device</b> may be one of good <b>input</b> <b>devices</b> to computers. Furthermore, since the Braille has been used for visually impaired people, the proposed one can be easily used as an <b>input</b> <b>device</b> to computers for them. Index Terms – keyboard, chord keyboard, chord glove, <b>input</b> <b>device,</b> Braille 1...|$|R
40|$|This' paper proposes virtual <b>input</b> <b>devices</b> {{based on}} {{collision}} detection for easy construc#on of interactive 3 D graphics applications, which use a motion capture {{system as a}} real-#me <b>input</b> <b>device.</b> Each virtual <b>input</b> <b>device</b> is' composed jm several collision sensor objects and an actuator object. These objects are software components' represented as a visible object which users can manipulate on a computer screen. Each virtual <b>input</b> <b>device</b> has a certain metaphor associated with its' role that is' determined by location and composition structure of its' components: Therefore, it is' possible to define various virtual <b>input</b> <b>devices</b> eas'ily only by combining several sensor objects and an actuator object through direct manipulations on a computer screen. This' paper presents' a realization mechanism and actual examples' of virtual <b>input</b> <b>devices...</b>|$|R
5000|$|When {{unprocessed}} data {{is sent to}} {{the computer}} with the help of <b>input</b> <b>devices,</b> the data is processed and sent to output <b>devices.</b> The <b>input</b> <b>devices</b> may be hand-operated or automated. The act of processing is mainly regulated by the CPU. Some examples of hand-operated <b>input</b> <b>devices</b> are: ...|$|R
50|$|Audio <b>input</b> <b>devices</b> {{are used}} to capture sound. In some cases, an audio output device {{can be used as}} an <b>input</b> <b>device,</b> in order to capture {{produced}} sound.Audio <b>input</b> <b>devices</b> allow a user to send audio signals to a computer for processing, recording, or carrying out commands. Devices such as microphones allow users to speak to the computer in order to record a voice message or navigate software.Aside from recording, audio <b>input</b> <b>devices</b> are also used with speech recognition software.|$|R
40|$|An {{overview}} of methods, devices, and research] Color image generation and processing {{has been growing}} at an unprecedented rate {{over the last two}} decades, and its effects are being felt throughout our everyday lives. Today, scanners, digital cameras, displays, and printers are available at relatively inexpensive prices for commercial and consumer applications. With the overwhelming number of <b>image</b> <b>input</b> and output <b>devices,</b> it is critical for the imaging engineer to understand the underlying transformations, from physical properties to digital representation, that take place in the recording hardware. It is equally important to comprehend the transformations that will occur when a digital image is sent to the output hardware for display or printing. Generally speaking, recording and display devices are limited in terms of noise, dynamic range, metamerism, spatial resolution, gamut, and spectral response. To fully comprehend the meaning of the recorded digital data and the displayed image, it is necessary to know the limits of the recording system and display hardware in these terms. This knowledge enables the optimization of processing methods from a system viewpoint [32] yielding better results with reduced resources. The goal {{of this article is to}} provide an {{overview of}} the transformations and limitations that occur in color imaging <b>input</b> and output <b>devices.</b> It is beyond the scope of the article to do an exhaustive survey of all devices. Instead, we will concentrate on two common recording devices and three common output devices. First we provide an overview of digital scanners and cameras, and then we discuss inkjet and laser printers. Finally, liquid crystal display (LCD) devices are presented...|$|R
50|$|<b>Input</b> <b>devices</b> are {{instruments}} used {{to manipulate}} objects, and send control {{instructions to the}} computer system. They vary in terms of degrees of freedom available to them and can be classified into standard <b>input</b> <b>devices,</b> trackers, control devices, navigation equipment, and gesture interfaces. Standard <b>input</b> <b>devices</b> include keyboards, tablets and stylus, joysticks, mice, touch screens, knobs, and trackballs.|$|R
40|$|DE 19846762 A UPAB: 20000613 NOVELTY - An <b>input</b> <b>device</b> (1) {{creates an}} input signal. A display {{appliance}} has a display surface (3) fitted with an identifying mechanism for identifying an input signal. On its bottom side the <b>input</b> <b>device</b> forms an even surface (10) containing three trackballs (11) in a triangle. The <b>input</b> <b>device</b> slides {{on the display}} surface of a display appliance. USE - For multiple user applications, such as team work on factory planning projects. ADVANTAGE - The <b>input</b> <b>device</b> allows for the input {{of two or more}} signals...|$|R
50|$|Gauntlet is a {{wireless}} glove {{that can be}} used as a computer keyboard <b>input</b> <b>device.</b> The glove was invented under a project called G.A.U.N.T.L.E.T. (Generally Accessible Universal Nomadic Tactile Low-power Electronic Typist), and it is still in the beta phase. In addition to being a computer <b>input</b> <b>device,</b> Gauntlet can also be used as an <b>input</b> <b>device</b> for smartphones and other portable devices.|$|R
40|$|Concepts such as {{the logical}} device, taxonomies, and other {{descriptive}} frameworks have improved understanding of <b>input</b> <b>devices</b> but ignored or else treated informally their pragmatic qualities, which are fundamental to selection of <b>input</b> <b>devices</b> for tasks. We seek the greater leverage of a predictive theoretical framework by basing our investigation of three-dimensional vs. two-dimensional <b>input</b> <b>devices</b> on Garner’s theory of processing of perceptual structure in multidimensional space. We hy~othesize that perceptual structure ~rovides a key to understanding performance of multidimensional <b>input</b> <b>devices</b> on multidimensional tasks, Two three-dimensional tasks may seem equivalent, but if they involve different types of perceptua...|$|R
40|$|The paper {{describes}} two <b>input</b> <b>devices</b> and {{a software}} interface that allow severely impaired people to easily interact {{with a personal}} computer. The first <b>input</b> <b>device</b> does not require residual movement but makes use of skin electrical signals and applies Artificial Neural Networks to decode the mind-driven commands. The second <b>input</b> <b>device</b> is an evolution of a proximity sensor that can be activated using minimal residual movements, therefore it is suitable for {{the main part of}} motor disabilities. The software interface can be adapted to any kind of <b>input</b> <b>device</b> and makes it possible to access any standard software installed on a PC...|$|R
40|$|Persons {{suffering}} from intractable disease like ALS (Amyotrophic Lateral Sclerosis) and {{spinal cord injury}} often show deterioration in muscular function. Some of these patients are obliged to use artificial respirators and cannot have verbal communication with others. In order to support their communication, there exist various <b>input</b> <b>devices</b> like touch sensor <b>input</b> <b>devices,</b> capacitance sensor <b>input</b> <b>devices</b> and also vision <b>input</b> <b>devices.</b> In addition, computer controlled environment is helpful for such patients. By developing proper computer controlled environment which {{is controlled by the}} proper <b>input</b> <b>device,</b> even the patient with serious disability can live sound life. Due to the infrared network system, the computer controlled environment could be well organized. 9 th IEEE International Conference on Mobile Ad-Hoc and Sensor Networks, MSN 2013; Dalian; China; 11 December 2013 through 13 December 201...|$|R
50|$|An absolute-movement <b>input</b> <b>device</b> (e.g., stylus, {{finger on}} touch screen) {{provides}} a consistent mapping between {{a point in}} the input space (location/state of the <b>input</b> <b>device)</b> and {{a point in the}} output space (position of pointer on screen). A relative-movement <b>input</b> <b>device</b> (e.g., mouse, joystick) maps displacement in the input space to displacement in the output state. It therefore controls the relative position of the cursor compared to its initial position.|$|R
40|$|SummaryObjectiveTo {{study the}} effect of new {{interactive}} computer <b>input</b> <b>devices</b> on cartilage segmentation in terms of time, consistency between <b>input</b> <b>devices,</b> and precision in quantitative magnetic resonance imaging (qMRI). DesignWe compared two new <b>input</b> <b>devices,</b> an interactive digitizing tablet and an interactive touch-sensitive screen, to a traditional mouse. Medial tibial and patellar cartilage of six healthy and six osteoarthritic knees were segmented using each <b>input</b> <b>device.</b> Cartilage volume, surface area and mean thickness were assessed using a validated algorithm and used to determine consistency and precision. Segmentation time was also measured. ResultsSegmenting with an interactive touch-sensitive screen reduced segmentation time by 15 % {{when compared to the}} traditional mouse but we found no significant difference in segmentation time between the interactive digitizing tablet and the traditional mouse. We found no difference in consistency or precision of cartilage volume, mean thickness or surface area between the three <b>input</b> <b>devices</b> tested. ConclusionsWe conclude that measurements of cartilage made using articular cartilage segmentation from MR images are independent of the <b>input</b> <b>device</b> chosen for user interaction...|$|R
25|$|X is an architecture-independent {{system for}} remote {{graphical}} user interfaces and <b>input</b> <b>device</b> capabilities. Each person using a networked terminal {{has the ability to}} interact with the display with any type of user <b>input</b> <b>device.</b>|$|R
40|$|We {{present a}} new {{approach}} to the integration of <b>input</b> <b>devices</b> into virtual environment software systems. Our approach employs a so-called Mapper module as an intermediate between <b>input</b> <b>device</b> drivers and virtual environment application. Major advantages of our approach are full device-independence, including the easy integration of new <b>input</b> <b>devices</b> and emulation of missing device capabilities, interactive reconfiguration, sharing of <b>input</b> <b>devices</b> among multiple applications, automatic selection of devices and interaction appropriate for the task, and high-level support for a large variety of navigation styles in virtual environments. 1. Introduction Successful human-computer interaction requires efficient transfer of information from humans to computers. Such communication is mediated via <b>input</b> <b>devices,</b> which have become more diverse with the introduction of virtual reality systems that frequently use 6 degree of freedom (DOF) trackers and other devices that cannot really be consi [...] ...|$|R
5000|$|We {{categorize}} computer <b>devices</b> as <b>input</b> <b>devices</b> {{because we}} use these devices to send {{instructions to the}} computer, we are sending our [...] "Input" [...] to the computer, some common examples of computer <b>input</b> <b>devices</b> are: ...|$|R
40|$|ICon is {{an editor}} {{designed}} to select a set of <b>input</b> <b>devices</b> and connect them to actions into a graphical interactive application. ICon allows physically challenged users to connect alternative <b>input</b> <b>devices</b> and/or configure their interaction techniques according to their needs. It allows skilled users [...] graphic designers or musicians for example [...] to configure any ICon aware application to use their favorite <b>input</b> <b>devices</b> and interaction techniques (bimanual, voice enabled, etc.) ...|$|R
40|$|The present {{invention}} is in {{the technical}} field of computer <b>input</b> <b>devices.</b> More particularly, the present invention {{is in the}} technical field of computer keyboards. More particularly, a computer keyboard comprising capacitive multi-touch technology. Conventional computer <b>input</b> <b>devices</b> consist of a keyboard and a pointing device. These devices are often separated spatially thus decreasing the efficiency of user input due to time spent moving hands and fingers between the different <b>input</b> <b>devices...</b>|$|R
5000|$|Head-mounted {{displays}} are {{not designed}} to be workstations, and traditional <b>input</b> <b>devices</b> such as keyboards {{do not support the}} concept of smart glasses. <b>Input</b> <b>devices</b> that lend themselves to mobility and/or hands-free use are good candidates, for example: ...|$|R
40|$|Current <b>input</b> <b>device</b> {{taxonomies}} {{and other}} frameworks typically emphasize the mechanical structure of <b>input</b> <b>devices.</b> We suggest that selecting an appropriate <b>input</b> <b>device</b> for an interactive task requires looking beyond the physical structure of devices to the deeper perceptual {{structure of the}} task, the device, and the interrelationship between the perceptual structure of the task and the control properties of the device. We affirm that perception is key to understanding performance of multidimensional <b>input</b> <b>devices</b> on multidimensional tasks. We have therefore extended the theory of processing of perceptual structure to graphical interactive tasks and to the control structure of <b>input</b> <b>devices.</b> This allows us to predict task and device combinations that lead to better performance and hypothesize that performance is improved when the perceptual structure of the task matches the control structure of the device. We conducted an experiment in which subjects performed two tasks wi [...] ...|$|R
