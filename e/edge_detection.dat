5187|248|Public
5|$|In {{computer}} vision, {{the active}} contour model for <b>edge</b> <b>detection</b> and image segmentation {{is based on}} curve shortening, and evolves curves based {{on a combination of}} their curvature and the features of an image.|$|E
5|$|Disruptive {{patterns}} use strongly contrasting, non-repeating markings such as spots or stripes {{to break}} up the outlines of an animal or military vehicle, or to conceal telltale features, especially the eyes, as in the common frog. Disruptive patterns may use more than one method to defeat visual systems such as <b>edge</b> <b>detection.</b> Predators like the leopard use disruptive camouflage to help them approach prey, while potential prey like the Egyptian nightjar use it to avoid detection by predators. Disruptive patterning is common in military usage, both for uniforms and for military vehicles. Disruptive patterning, however, does not always achieve crypsis on its own, as an animal or a military target may be given away by factors like shape, shine, and shadow.|$|E
25|$|The ACO {{algorithm}} {{is used in}} image processing for image <b>edge</b> <b>detection</b> and edge linking.|$|E
30|$|The {{algorithm}} uses Sobel’s {{filter to}} perform <b>edges</b> <b>detection</b> on an input image. Since TI provides {{it as part}} of the board’s SDK, this use-case should be easily reproducible.|$|R
40|$|Abstract. Road image <b>edge</b> <b>detections</b> are {{sensitive}} response to light intensity, the whole mean gray value of road image changed significantly under different illumination. Using one algorithm {{can not be}} effectively detected to road edge line. From the analysis of characteristic situation of different light road image, we put forward a algorithm of road <b>edge</b> line <b>detection</b> under different illumination. The example studied showed that this algorithm could obtain more ideal image edge from the road gray image, and certain anti-noise performance could be generated...|$|R
40|$|Three {{configurations}} of block <b>edge</b> <b>detections</b> {{based on the}} third level of the conjugate classification for binary images of the hexagonal grid, are investigated in this paper. Constructing an operation of three configurations, {{it is necessary to}} collect a state set contained 48, 66 and 90 states as the structuring patterns respectively. To represent the selected state set in equivalent detecting functions, cellular logic and conjugate computations are illustrated and compared. Because a conjugate expression uses a class representation for structuring patterns, its real implementation is very efficient. For three {{configurations of}} 0 (or 1) block <b>edge</b> <b>detections,</b> a speed-up ratio 6 - 15 compared with the same activity performed by a standard implementation in a cellular logic expression, can be measured. Sample processed pictures and their timing measurements are illustrated and analyzed...|$|R
25|$|Gaussian {{smoothing}} {{is commonly}} used with <b>edge</b> <b>detection.</b> Most edge-detection algorithms are sensitive to noise; the 2-D Laplacian filter, built from a discretization of the Laplace operator, is highly sensitive to noisy environments. Using a Gaussian Blur filter before <b>edge</b> <b>detection</b> aims to reduce the level of noise in the image, which improves {{the result of the}} following edge-detection algorithm. This approach is commonly referred to as Laplacian of Gaussian, or LoG filtering.|$|E
25|$|These {{artifacts}} can {{be reduced}} by choosing {{a lower level of}} compression; they may be completely avoided by saving an image using a lossless file format, though this will result in a larger file size. The images created with ray-tracing programs have noticeable blocky shapes on the terrain. Certain low-intensity compression artifacts might be acceptable when simply viewing the images, but can be emphasized if the image is subsequently processed, usually resulting in unacceptable quality. Consider the example below, demonstrating the effect of lossy compression on an <b>edge</b> <b>detection</b> processing step.|$|E
25|$|For {{the most}} part, {{computer}} vision algorithms used on color images are straightforward extensions to algorithms designed for grayscale images, for instance k-means or fuzzy clustering of pixel colors, or canny <b>edge</b> <b>detection.</b> At the simplest, each color component is separately {{passed through the}} same algorithm. It is important, therefore, that the features of interest can be distinguished in the color dimensions used. Because the R, G, and B components of an object’s color in a digital image are all correlated {{with the amount of}} light hitting the object, and therefore with each other, image descriptions in terms of those components make object discrimination difficult. Descriptions in terms of hue/lightness/chroma or hue/lightness/saturation are often more relevant.|$|E
40|$|A {{method was}} {{developed}} for segmenting images of space scenes into manmade and natural components, using fractal dimensions and lacunarities. Calculations of these parameters are presented. Results are presented {{for a variety of}} aerospace images, showing {{that it is possible to}} perform <b>edge</b> <b>detections</b> of manmade objects against natural background such as those seen in an aerospace environment...|$|R
30|$|Although {{analyses}} {{using the}} gravity gradient tensor have yielded excellent results in subsurface structure estimations and <b>edge</b> <b>detections,</b> gravity gradiometry surveys {{have been conducted}} {{in only a few}} areas, limiting the tensor data available. If we were to carry out these analyses in areas where gravity gradiometry surveys have not been conducted yet, we would have to use the tensor estimated from existing gravity anomaly data.|$|R
40|$|Abstract — <b>Edges</b> <b>detection</b> {{in digital}} images {{is a problem}} that has been solved by means of the {{application}} of different techniques from digital signal processing, also the combination of some of these techniques with Fuzzy Inference System (FIS) has been experienced. In this work a new FIS Type- 2 method is implemented for the <b>detection</b> of <b>edges</b> and the results of three different techniques for the same intention are compared...|$|R
25|$|A simple example {{would be}} a GPU program that {{collects}} data about average lighting values as it renders some view from either a camera or a computer graphics program {{back to the main}} program on the CPU, so that the CPU can then make adjustments to the overall screen view. A more advanced example might use <b>edge</b> <b>detection</b> to return both numerical information and a processed image representing outlines to a computer vision program controlling, say, a mobile robot. Because the GPU has fast and local hardware access to every pixel or other picture element in an image, it can analyze and average it (for the first example) or apply a Sobel edge filter or other convolution filter (for the second) with much greater speed than a CPU, which typically must access slower random-access memory copies of the graphic in question.|$|E
25|$|Pre-processing helped {{enhancing}} {{the quality of}} an image by filtering and removing unnecessary noises. The minutiae based algorithm only worked effectively in 8-bit gray scale fingerprint image. A reason was that an 8-bit gray fingerprint image was a fundamental base to convert the image to 1-bit image with value 0 for ridges and value 1 for furrows. As a result, the ridges were highlighted with black color while the furrows were highlighted with white color. This process partly removed some noises in an image and helped enhance the <b>edge</b> <b>detection.</b> Furthermore, there are two more steps to improve the best quality for the input image: minutiae extraction and false minutiae removal. The minutiae extraction {{was carried out by}} applying ridge thinning algorithm which was to remove redundant pixels of ridges. As a result, the thinned ridges of the fingerprint image are marked with a unique ID so that further operation can be conducted. After the minutiae extraction step, the false minutiae removal was also necessary. The lack of the amount of ink and the cross link among the ridges could cause false minutiae that led to inaccuracy in fingerprint recognition process.|$|E
2500|$|The {{following}} are the steps involved in <b>edge</b> <b>detection</b> using ACO: ...|$|E
40|$|A normalized, power-weighted {{averaging}} filter (NPF) {{is a very}} good approximation to the well-know local maximum and minimum filters along the object edges and offers noise reduction in foreground and background regions. This favorable combination turns out to be very effective in image smoothing, <b>edges</b> <b>detection</b> and image sharpening. It offers a clear improvement over the existing operators based on true max-min filtering. Our filter can be implemented very efficiently by a table lookup (for the power) and two (separable) convolutions. 1...|$|R
3000|$|However, {{these data}} require {{specific}} statistical methods {{to assess the}} accuracy of the resulted edge images-accuracy here being the extent to which detected edges agree with true edges. Correspondence values ranging from 0 to N produce N + 1 thresholds which correspond to <b>edge</b> <b>detections</b> with different combinations of true-positive and false-positive rates. The threshold that corresponds to correspondence value 0 is ignored. Hence, the main goal of the method is to estimate the correspondence threshold CT (from the set CT [...]...|$|R
40|$|A {{statistical}} {{approach to}} distributed <b>edge</b> sensor <b>detection</b> is proposed for wireless sensor networks. <b>Edge</b> sensor <b>detection</b> {{is a technique}} to decide whether a target sensor is an edge sensor {{based on data from}} its neighboring sensors. It is desirable that the computational complexity be low and the amount of data transferred among sensors be small. With some reasonable assumptions and the maximal likelihood technique, we propose both one-level and two-level decision methods to fulfill the above two constraints. 1...|$|R
2500|$|The game engine {{features}} hand-painted textures stylized with <b>edge</b> <b>detection</b> outlining. The game world is developed continuously, through {{the release of}} important updates (referred to as [...] "Generations" [...] and [...] "Seasons") that introduce new areas, additional features such as pets and new skills, and advancement of the storyline. The user interface is simple and designed in the likeness of Microsoft Windows' task bar.|$|E
2500|$|IGN's Chris Roper was {{impressed}} with New York City, praising [...] "how well your general duties as a cop are tied into the game, working very well alongside your own personal investigations," [...] and finding the gameplay and game mechanics superior to Streets of LA. Eurogamer's Jim Rossignol was critical of the AI; [...] "the perps you take down never suggest that they are anything other than mindless automata ready to be slain, and exhibit an artificiality that could never be described as 'intelligence'." [...] GameSpy's Sterling McGarvey wrote [...] "Luxoflux have turned a slightly above-par GTA clone into a sub-par franchise." [...] Of the graphics, he wrote, [...] "the frame rate {{has a knack for}} chugging. Considering it's a console and not a five year-old PC running this game, it's unacceptable. Out of nowhere, the frame rate will completely bottom out while Marcus patrols the streets." [...] He called the game [...] "unfinished." [...] GameSpot's Greg Mueller accused the game of being [...] "so riddled with problems that it feels like it was rushed to make it to store shelves in time for the holidays. He cited [...] "collision detection issues and <b>edge</b> <b>detection</b> problems that cause you to get stuck {{on the edge of a}} platform. [...] the game will actually freeze up entirely from time to time [...] There are also some pretty ugly clipping issues here too." [...] He concluded [...] "the technical problems far outweigh any faint hope this game ever had of being enjoyable. If you're curious about what a video game looks like before it goes through adequate testing and quality assurance, then by all means give this one a try." ...|$|E
2500|$|GameSpot's Greg Mueller was {{extremely}} unimpressed, scoring the GameCube and PlayStation 2 versions 4.6 out of 10, and the Xbox version 4.3 out of 10. He accused {{the game of}} being [...] "so riddled with problems that {{it feels like it}} was rushed to make it to store shelves in time for the holidays." [...] He cited [...] "bugs that will make you randomly fall through the ground into a bunch of nothingness, bugs that make textures change when you {{get in and out of}} a car, bugs that cause you to inadvertently break a scripted sequence, thus making it impossible to complete a mission. There are also collision detection issues and <b>edge</b> <b>detection</b> problems that cause you to get stuck on the edge of a platform. That's not all--the game will actually freeze up entirely from time to time [...] There are also some pretty ugly clipping issues here too." [...] He concluded [...] "True Crime: New York City should be avoided regardless of whether or not you enjoyed the first True Crime. The gameplay has a few almost-decent spots, but the technical problems far outweigh any faint hope this game ever had of being enjoyable. If you're curious about what a video game looks like before it goes through adequate testing and quality assurance, then by all means give this one a try." [...] He scored the PC version 5.2 out of 10, writing, [...] "while it manages to address some of the more egregious glitches that appeared in the console versions of the game, it still doesn't feel like a finished product." ...|$|E
40|$|A new {{algorithm}} {{to preserve}} edges in image magnification is proposed. The algorithm {{is based on}} an inpainting technique: Blurry edges in the initially magnified image are erased using automatic <b>edge</b> <b>detections,</b> then the erased regions are filled with the filling priority guided by the watershed concept. The algorithm results in sharp patterns along the edges of the initial image, and the discontinuity across the edges is guaranteed. Experiments demonstrate that the algorithm is superior to some popular methods such as edge-directed interpolations and anisotropic diffusions. 1...|$|R
40|$|Noninvasive optical {{measurement}} {{and evaluation of}} the pulse wave velocity of a self-oscillating elastic tube was done. A latex tube was loaded by self-excited internal pulsatile flow as a simple model of human big arteries. The method is based on evaluation of high speed camera recordings and <b>edges</b> <b>detection</b> algorithm. Displacements of the tube edge were evaluated by a given scale factor from a standard gauge inserted to the recorded scene. Our goal is to recognize the pulse wave and measure its velocity along the tube...|$|R
40|$|Image {{processing}} can be {{used for}} digital restoration of ancient papyri, that is, for a restoration performed on their digital images. The digital manipulation allows reducing the background signals and enhancing the readability of texts. In the case of very old and damaged documents, this is fundamental for identification of the patterns of letters. Some examples of restoration, obtained with an image processing which uses <b>edges</b> <b>detection</b> and Fourier filtering, are shown. One of them concerns 7 Q 5 fragment of the Dead Sea Scrolls...|$|R
50|$|Among the <b>edge</b> <b>detection</b> methods {{developed}} so far, Canny <b>edge</b> <b>detection</b> {{algorithm is}} one of the most strictly defined methods that provides good and reliable detection. Owing to its optimality to meet with the three criteria for <b>edge</b> <b>detection</b> and the simplicity of process for implementation, it became one of the most popular algorithms for <b>edge</b> <b>detection.</b>|$|E
5000|$|Canny <b>edge</b> <b>detection</b> is a {{technique}} to extract useful structural information from different vision objects and dramatically {{reduce the amount of}} data to be processed. It has been widely applied in various computer vision systems. Canny has found that the requirements for the application of <b>edge</b> <b>detection</b> on diverse vision systems are relatively similar. Thus, an <b>edge</b> <b>detection</b> solution to address these requirements can be implemented {{in a wide range of}} situations. The general criteria for <b>edge</b> <b>detection</b> includes: ...|$|E
5000|$|While {{traditional}} canny <b>edge</b> <b>detection</b> provides {{relatively simple}} but precise methodology for <b>edge</b> <b>detection</b> problem, {{with the more}} demanding requirements on the accuracy and robustness on the detection, the traditional algorithm can no longer handle the challenging <b>edge</b> <b>detection</b> task. The main defects of the traditional algorithm can be summarized as following:8 ...|$|E
40|$|Abstract. A road <b>edges</b> <b>detection</b> {{method of}} a novel {{electronic}} travel aid for the blind was proposed. Road edges extraction was realized by Canny filter and Hough line transfer. Multiple lines detected by Hough transfer were processed into one edge line. Road deviation judgment method was proposed {{to determine if the}} user has deviated from the road by judging the position and angle of the edge lines. Experiments showed that the correct extraction rate of road edges was 93 %, and the road deviation judgment method was effective and fast. Experiments were done using the consecutive stereo image sequences captured on road...|$|R
40|$|This paper {{presents}} a technique, which determines whether an edge is visible {{for a human}} eye or not. First, a threshold function is built according to the optical characteristics of the sensor and a contrast sensitivity function (CSF). Then, the DCT coefficients of each 8 × 8 block are computed. For each one, the computed spectrum is compared with the previous threshold function, which enables to conclude {{about the presence of}} visible picture elements. Finally, this information is applied to <b>edges</b> <b>detection</b> using a binarization technique. Results are given on images grabbed onboard a moving vehicle. 1...|$|R
30|$|Approximating the {{contours}} point lists describing the piece under evaluation using fitting results, assuming further {{that the various}} errors, specifically those related to image processing, are independent and identically distributed, we have estimated error bounds for the <b>edges</b> <b>detection</b> process. These errors are defined as being equal to the orthogonal distances of the contour pixels to the geometric feature described by the corresponding fitting parameters. These data are computed for each geometric feature {{being part of the}} object of interest. Using a dedicated error propagation scheme, the estimates have also been propagated through the whole processing chain setup for analyzing the images acquired with our stereovision system.|$|R
5000|$|Deriche edge {{detector}} is an <b>edge</b> <b>detection</b> operator developed by Rachid Deriche in 1987. It's a multistep algorithm {{used to obtain}} an optimal result of <b>edge</b> <b>detection</b> in a discrete two-dimensional image. This algorithm is based on John F. Canny's work related to the <b>edge</b> <b>detection</b> (Canny's {{edge detector}}) and his criteria for optimal edge detection: ...|$|E
50|$|A {{survey of}} a number of {{different}} <b>edge</b> <b>detection</b> methods can be found in (Ziou and Tabbone 1998); see also the encyclopedia articles on <b>edge</b> <b>detection</b> in Encyclopedia of Mathematics and Encyclopedia of Computer Science and Engineering.|$|E
50|$|The Canny edge {{detector}} is an <b>edge</b> <b>detection</b> operator {{that uses a}} multi-stage algorithm to detect {{a wide range of}} edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of <b>edge</b> <b>detection</b> explaining why the technique works.|$|E
40|$|Digital {{images are}} {{generally}} created as discrete measurements of light, as performed by dedicated sensors. Consequently, each pixel contains a discrete approximation {{of the light}} inciding in a sensor element. The nature of this measurement implies certain uncertainty due to discretization matters. In this work we propose to model such uncertainty using intervals, further leading to the generation of so-called interval-valued images. Then, we study the partial differentiation of such images, putting a spotlight on antisymmetric convolution operators for such task. Finally, we illustrate {{the utility of the}} interval-valued images by studying the behaviour of an extended version of the well-known Canny <b>edges</b> <b>detection</b> method...|$|R
40|$|This {{bachelor}} thesis {{deals with}} the options of using the development environment of LabVIEW in specific processes such as an analyzing and biomedical image data processing. This bachelor thesis sets its goal as projecting and developing a computer program, which could process image data collected from microscopic devices. Image data from computer or external devices could be loaded into the program. It includes such functions as calculation of picture histogram, preprocessing by luminance or geometric transformations, preprocessing by smoothing filtration and <b>edges</b> <b>detection</b> and processing by segmentation. Function {{of the program was}} tested by tester images, microscopic images and also by images taken with camera straight into the program...|$|R
40|$|Abstract — A {{statistical}} {{approach to}} distributed <b>edge</b> sensor <b>detection</b> with {{wireless sensor networks}} is proposed in this research. The objective is {{to determine whether a}} target sensor is located in the edge area of a certain phenomenon or not based on data from its neighboring sensors. Due to the nature of wireless sensor networks, it is desirable to have a distributed algorithm that has a low computational complexity and a low data communication cost among sensors. With some reasonable assumptions and the aid of composite hypothesis testing, we propose data fusion as well as decision fusion methods for <b>edge</b> sensor <b>detection</b> to fulfill the aforementioned constraints. Numerical experiments are used to demonstrate the efficiency of the proposed algorithm...|$|R
