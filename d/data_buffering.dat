121|82|Public
5000|$|... fs_plugin_cache: {{increases}} {{performance of}} FFS2 by introducing a new method of <b>data</b> <b>buffering.</b>|$|E
5000|$|Hardware {{support for}} packet handling, <b>data</b> <b>buffering,</b> burst transmissions, data encryption, data authentication, clear channel assessment, link quality {{indication}} and packet timing information ...|$|E
50|$|On 12 March 2014 {{the launch}} was rescheduled to 30 March or 2 April 2014, {{for a variety}} of reasons {{including}} <b>data</b> <b>buffering</b> issues, working some issues with the range, some operational issues with the new Dragon design, and some contamination of the impact shielding blanket. SpaceX ultimately decided to move forward and use the shielding blanket with the minor contamination problems, believing it would not impact the optical payloads being carried in the Dragon trunk.|$|E
50|$|Flow Control - <b>Buffering</b> <b>data</b> {{transmissions}} {{to ensure}} that a fast sender does not overwhelm a slower receiver.|$|R
50|$|Even {{preserving}} the USB model typical error rates in wireless media require modifications in the mechanisms used to achieve said model: among others, <b>data</b> handshakes and <b>buffering.</b>|$|R
50|$|A {{circular}} buffer, circular queue, cyclic buffer or {{ring buffer}} is a data structure {{that uses a}} single, fixed-size buffer {{as if it were}} connected end-to-end.This structure lends itself easily to <b>buffering</b> <b>data</b> streams.|$|R
30|$|The low power, IEEE 802.15. 4 [40] and ZigBee compatible, RF chip CC 2420 [41] {{is used as}} a {{wireless}} transceiver. The chip provides features such as error detection and <b>data</b> <b>buffering</b> for the packets that need to be transmitted and received.|$|E
30|$|However, {{as can be}} seen in the {{architecture}} of Fig. 20, there is no inherent support for memory <b>data</b> <b>buffering</b> organization beyond relying on HLS or custom RTL development. As this article has shown, this organization and control of DRAM data onto on-chip buffers can significantly affect the application level performance.|$|E
40|$|This {{research}} {{describes a}} parallel implementation of Liang-Barsky clipping algorithm on a pipeline network configuration. The implemented configuration uses pipeline of four transputers and programmed under Occam 2 language. In {{order to achieve}} the concurrency, to improve the performance and to cut down the hold-ups caused by the calculation of intersection, <b>data</b> <b>buffering</b> is used...|$|E
30|$|Strategies E 1 to E 7 are {{differentiated}} {{according to}} the different mechanisms used to mitigate the adverse effects of secondary call interruptions {{as well as to}} provide QoS in CRNs (i.e., spectrum handoff, <b>data</b> call <b>buffering,</b> spectrum adaptation, double preemptive priority, channel reservation, and selective interruption mechanisms). The study carried out in this work allows us to investigate the performance improvement due to the use of these resource management mechanisms commonly separately employed in the literature. All of the strategies studied in this work consider the use of spectrum handoff.|$|R
40|$|The {{timing and}} flow of {{detector}} and ancillary data for the Airborne Visible/Infrared imaging spectrometer (AVIRIS) are controlled within the instrument by its digital electronics assembly. In addition to providing detector and signal chain timing, the digital electronics receives, formats, and rate-buffers digitized science data; collects and formats ancillary (calibration and engineering) data; and merges both into a single tape record. Overall AVIRIS data handling is effected {{by a combination of}} dedicated digital electronics to control instrument timing, image data flow, and <b>data</b> rate <b>buffering</b> and a microcomputer programmed to handle real-time control of instrument mechanisms and the coordinated preparation of ancillary data...|$|R
40|$|The use {{of small}} {{computers}} in on-line experiments in high-energy physics is briefly indicated. The requirement for an above-average performance (data-handling rates up to 1. 5 Mbit/sec) is described, emphasizing {{the problem of}} data acquisition; <b>data</b> rates and <b>buffering,</b> <b>data</b> storage, {{and the importance of}} flexibility are dealt with. The discussion of hardware solutions to the special problems posed by on- line experiments includes the use of CAMAC interfaces, systems of linked computers, and the use of special processors which perform the first steps of data analysis very rapidly. A section on the software solution to data acquisition problems treats the requirements for flexibility and ease of use, giving as an example a comparison of a manufacturer-supplied Editor and CERN's ORION Editor, and concludes with an outline of the need for direct access to more powerful computers, giving as an illustration the FOCUS and Omega/SFM networks. (0 refs) ...|$|R
40|$|Abstract. Many {{large-scale}} production parallel programs often {{run for a}} very long time and require data checkpoint periodically to save the state of the computation for program restart and/or tracing the progress. Such a write-only pattern has become a dominant part of an applicationâ€™s I/O workload and implies the importance of its optimization. Existing approaches for write-behind <b>data</b> <b>buffering</b> at both file system and MPI I/O levels have been proposed, but challenges still exist for efficient design to maintain data consistency among distributed buffers. To address this problem, we propose a buffering scheme that coordinates the compute processes to achieve the consistency control. Different from other earlier work, our design can be applied to files opened in read-write mode and handle the patterns with mixed MPI collective and independent I/O calls. Performance evaluation using BTIO and FLASH IO benchmarks is presented, which shows a significant improvement over the method without buffering. Keywords: Write behind, MPI I/O, file consistency, <b>data</b> <b>buffering,</b> I/O thread...|$|E
40|$|This thesis {{examines}} the architectural {{issues in the}} design of a video capture board intended for use in multimedia videoconferencing. The major issues examined are: Control of reception and transmission of multimedia video streams, (i) Quality of service and service provision (ii) Compression requirements and solutions (iii) <b>Data</b> <b>buffering</b> and card connection strategies (iv) Handling multiple video streams Results of measurements for prototype boards designed and constructed at Penn are also given...|$|E
40|$|A broad {{variety of}} {{implementation}} considerations become important when implementing software for embedded signal processing applications. These include complex trade-offs {{such as those}} involving code size, <b>data</b> <b>buffering</b> requirements, performance, and power consumption. This presentation motivates the use of high-level, dataflow-based programming models for automated synthesis of DSP software; presents an overview of optimization issues and trade-offs that arise in uniprocessor software synthesis from dataflow specifications; describes useful techniques {{that have been developed}} to address some of these trade-offs; and motivates important problems in this area for further investigation. 1...|$|E
40|$|We {{present a}} {{buffering}} streaming engine for processing top-down XSLT transformations. It {{consists of an}} analyzer and a transformer. The analyzer examines given top-down XSLT and XSD, and gen-erates fragments which identify parts of XSD need to be buffered when XSLT is applied. The fragments are passed to the transformer which processes XSLT on an input XML document conforming to XSD. It uses auxiliary memory buffers to store temporary <b>data</b> and <b>buffering</b> is controlled according to the fragments. We describe implementation of the engine within the Xord framework and pro-vide evaluation tests which show that the new engine is much more memory-efficient comparing to the common XSLT processors. 1...|$|R
40|$|Proposed {{scheme for}} <b>buffering</b> <b>data</b> on intensities of picture {{elements}} (pixels) of image increases rate or processing beyond that attainable when data read, one pixel at time, from main image memory. Scheme applied in design of specialized image-processing circuitry. Intended to optimize performance of processor in which electronic equivalent of address-lookup table used {{to address those}} pixels in main image memory required for processing...|$|R
40|$|A {{geometric}} programming {{framework is}} proposed {{in this paper}} to automate exploration of the design space consisting of <b>data</b> reuse (<b>buffering)</b> exploitation and loop-level parallelization, {{in the context of}} FPGA-targeted hardware compilation. We expose the dependence between data reuse and data-level parallelization and explore both problems under the on-chip memory constraint for performance-optimal designs within a single optimization step. Results from applying this framework to several real benchmarks demonstrate that given different constraints on on-chip memory utilization, the corresponding performance-optimal designs are automatically determined by the framework, and performance improvements up to 4. 7 times have been achieved compared with the method that first explores data reuse and then performs parallelization. 1...|$|R
30|$|<b>Data</b> <b>buffering</b> in CRN: The {{possibility}} of delay in data transmission has seldom been factored into the RA problems of CRN. Almost all works reviewed have equally neglected this concept in their problem definition. In reality, for heterogeneous CRN particularly, delay tolerance of different users might differ significantly, and {{there might be}} need for queue considerations. To analyse RA models that capture such possibilities, the use of queueing theory could help in addressing the delay issues. Hence, RA problems in CRN that factor this into their designs, especially when heterogeneous considerations are also involved, {{would be a good}} research focus.|$|E
40|$|Phase Changing Memory (PCM), {{as one of}} {{the most}} {{promising}} next-generation memory technologies, offers various attractive properties such as non-volatility, bit-alterability, and low idle energy consumption. In this paper, we present PCMLogging, a novel logging scheme that exploits PCM devices for both <b>data</b> <b>buffering</b> and transaction logging in disk-based databases. Different from the traditional approach where buffered updates and transaction logs are completely separated, they are integrated in the new logging scheme. Our preliminary experiments show an up to 40 % improvement of PCMLogging in disk I/O performance in comparison with a basic buffering and logging scheme...|$|E
40|$|Advanced Metering Infrastructure (AMI) have rapidly {{become a}} topic of {{international}} interest as governments have sponsored their deployment {{for the purposes of}} utility service reliability and efficiency, e. g., water and electricity conservation. Two problems plague such deployments. First is the protection of consumer privacy. Second is the problem of huge amounts of data from such deployments. A new architecture is proposed to address these problems through the use of Aggregators, which incorporate temporary <b>data</b> <b>buffering</b> and the modularization of utility grid analysis. These Aggregators are used to deliver anonymized summary data to the central utility while preserving billing and automated connection services...|$|E
40|$|This paper {{examines}} the requirements {{and functions of}} the telemetry-data recording and storage systems, and the data-storage-system technology projected for the Space Station, with particular attention given to the Space Optical Disk Recorder, an on-board storage subsystem based on 160 gigabit erasable optical disk units each capable of operating at 300 M bits per second. Consideration is also given to storage systems for ground transport recording, which include systems for <b>data</b> capture, <b>buffering,</b> processing, and delivery on the ground. These can be categorized as the first in-first out storage, the fast random-access storage, and the slow access with staging. Based on projected mission manifests and data rates, the worst case requirements were developed for these three storage architecture functions. The results of the analysis are presented...|$|R
40|$|A new and {{powerful}} approach to threading is proposed, {{that is designed}} to improve the responsiveness of concurrent logic programs for distributed, real-time AI applications. The technique builds on previously proposed scheduling techniques to improve responsiveness by synchronously passing control and data directly from a producer to a consumer. Furthermore, synchronous transfer of <b>data</b> requires less <b>buffering</b> and so less garbage is produced. Arguments are also passed in registers, further reducing overheads...|$|R
50|$|In 1981 {{support for}} {{separate}} instruction and data space for users with Unibus machines (PDP-11/44, PDP-11/45, PDP-11/55 and PDP-11/70) provided an extension {{to the memory}} constraints of an individual program. Compiling programs to use separate instruction and data space would soon give a program up to 64 kB for instructions, and up to 64 kB for <b>buffering</b> <b>data.</b> The DCL RTS is included as well as support for the newer revision of DECnet III.|$|R
40|$|Although {{the nascent}} state of {{parallel}} systems makes empirical performance measurement, analysis and tuning critical, rapid technological evolution, coupled with short product life cycles, has often {{made it difficult}} to isolate fundamental experimental principles from implementation artifacts. By definition, the apparatus for experimental performance analysis (i. e., instrumentation specification, <b>data</b> <b>buffering,</b> timestamp generation, and data extraction) is shaped by the intended experiment and the object of study. In some environments, certain experiments are not feasible. Balancing the volume of captured performance data against its accuracy and timeliness requires both appropriate tools and an understanding of instrumentation costs, implementation alternatives, and support infrastructure...|$|E
40|$|ATLAS Muon TDC test-element group chip (AMT-TEG) was {{developed}} and tested to confirm the performance of critical circuits of the TDC and measure radiation tolerance of the process. The chip was fabricated in a 0. 3 m m CMOS Gate-Array technology. Measurements of critical elements of the chip such as the PLL, and <b>data</b> <b>buffering</b> circuits demonstrated adequate performance. The effect of gamma-ray irradiation, using a Co 60 source, and neutron irradiation, using PROSPERO reactor in France, were also examined. The test results revealed radiation tolerance adequate for {{the operation of the}} circuits in the environment of the ATLAS MDT. 1...|$|E
40|$|Concurrent {{processes}} can be {{used both}} for programming computation and for programming storage. Previous implementations of Flat GHC, however, have been tuned for computation-intensive programs, and perform poorly for storage-intensive programs (such as programs implementing reconfigurable data structures using processes and streams) and demand-driven programs. This paper proposes an optimization technique for programs in which processes are almost always suspended. The technique compiles unification for data transfer into message passing. Instead of {{reducing the number of}} process switching operations, the technique optimizes the cost of each process switching operation and reduces the number of cons operations for <b>data</b> <b>buffering...</b>|$|E
50|$|NMODEM is a file {{transfer}} protocol developed by L.B. Neal in 1990. NMODEM is essentially a version of XMODEM-CRC using larger 2048 byte blocks, as opposed to XMODEM's 128 byte blocks. NMODEM was implemented as a separate program, written in Turbo Pascal 5.0 for the IBM PC compatible family of computers. The block size was chosen to match the common cluster size of the MS-DOS FAT file system on contemporary hard drives, making <b>buffering</b> <b>data</b> for writing simpler.|$|R
40|$|The architecture, components, and {{technical}} approach for a Space Station era mass storage system prototype are described. The primary data storage needs call for such functions as line outage recording, rate <b>buffering,</b> <b>data</b> archiving, and level zero type processing. The prototype mass storage system hardware will be configurable to support three {{modes of operation}} at up to 300 Mbps. The system architecture consists of two distinct components: a configurable high-level mass storage control system and a basic storage kernal...|$|R
40|$|The IMB experiment, a large water Cherenkov {{detector}} {{which began}} data collection in September 1982, has undergone several upgrades to improve light collection, on-line processing power, <b>data</b> throughput and <b>buffering,</b> calibration, and operating efficiency. The current device, known as IMB- 3, enjoys {{a factor of}} four light collection advantage over its precursor. Since May 1986, {{it has been used}} to search for such diverse phenomena as nucleon decay, dark matter, neutrino oscillation, and magnetic monopoles, an...|$|R
40|$|Temperature {{changing}} {{has affected}} to the electrical load consumption. It has {{considered in the}} calculation of short-term load forecasting. In this study, ANFIS method was used to forecast short-term load using historical data of electrical load and temperature. From the testing process, the MAPE value has obtained during the procces for daily bunch from Monday to Sunday and Public Holiday is included, i. e. 8. 567 %; 5. 013 %; 5. 341 %; 4. 214 %; 7. 741 %; 6. 635 %; 6. 875 % and 0. 022689 %, respectively. The addicting of temperature <b>data</b> <b>buffering</b> has proven that forecasting accuracy is increased...|$|E
40|$|Packet Queue {{is ideal}} for a system that needs to buffer packet data from {{multiple}} channels and aggregate the packet data into a single output interface. This type of <b>data</b> <b>buffering</b> and aggregation is common in many applications, including networking, data communications, telecommunications, and digital signal processing. Packet Queue also enables packet-level flow-control by supporting the ability to drop packets on the write interface and retransmit packets on the read interface. A typical Ethernet over SONET application is shown in Figure 1 with Packet Queue used to buffer data received by four 1 -Gigabit Ethernet links and transmit them to a SONET framer over a SPI- 4. 2 interface...|$|E
40|$|Automated {{prototyping}} tool-kit (APT) is {{an integrated}} set of software tools that generate source programs directly from real-time requirements. The APT system uses a fifth-generation prototyping language {{to model the}} communication structure, timing constraints, 1 / 0 control, and <b>data</b> <b>buffering</b> that comprise the requirements for an embedded software system. The language supports the specification of hard real-time systems with reusable components from domain specific component libraries. APT has been used successfully as a research tool in prototyping large war-fighter control systems (e. g. the command-and-control station, cruise missile flight control system, patriot missile defense systems) and demonstrated its capability to support the development of large complex embedded software...|$|E
40|$|Mobile IP {{has several}} inefficiencies, {{and was not}} {{originally}} designed for situations where both peers are highly mobile. We present a mobility management solution that retains compatibility with existing Internet protocols, whilst increasing the efficiency of communications between two GPRS mobile hosts. Our proposal eradicates triangle routing and minimizes handoff latency. We show by numerical analysis that the routing optimization improves the performance of TCP controlled <b>data</b> flows, reducing <b>buffering</b> requirements and minimizing the recovery time after a handoff occurs...|$|R
40|$|I l 1 Il l IlIH l 1 l 11 1 Stored-program {{computers}} {{have not yet}} been used in small scientific spacecraft. The evolution of spacecraft data systems indicates that inclusion of a computer is a logical next step. The computer would be used for four types of computation: <b>buffering</b> <b>data,</b> formatting data, re-dundancy removal, and parameter extraction. The most important advantage of using a computer is the flexibility obtained from using a stored program rather than a wired one. i...|$|R
40|$|Visual {{applications}} need to represent, manipulate, store, {{and retrieve}} both raw and processed visual data. Existing relational and object-oriented database systems fail to offer satisfactory visual data management support {{because they lack}} the kinds of representations, storage structures, indices, access methods, and query mechanisms needed for visual data. We argue that extensible visual object stores offer feasible and effective means to address the data management needs of visual applications. ISR 4 is such a visual object store under development at the University of Massachusetts {{for the management of}} persistent visual information. ISR 4 is designed to offer extensive storage and retrieval support for complex and large visual <b>data,</b> customizable <b>buffering</b> and clustering, and spatial and temporal indexing, along with a variety of multi-dimensional access methods and query languages. Index Terms: visual information management, persistent object store, extensible visual object stor...|$|R
