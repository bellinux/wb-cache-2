0|13|Public
40|$|This article {{analyses}} {{the magnitude}} of the possible regional economic impacts that might stem from the proposed De Beers Pass Route (DBPR) project in South Africa. The regional income multiplier and income accelerator analysis are used to estimate the gross and net once-off increase in regional income during construction, and the recurring increases in regional income during road use. The difference between a cost–benefit analysis and a regional economic income analysis is indicated. To end, <b>guiding</b> <b>pointers</b> are supplied on the appropriate use of independent variables when applying the regional income multiplier-accelerator model...|$|R
50|$|The basic {{equipment}} is inexpensive, however, {{and for those}} with access to a squash court it can easily be enjoyed for its recreational and exercise value. Dick Squires published {{a guide to the}} sport in 1968. The booklet was not copyrighted, and is available online at Project Gutenberg. The <b>guide</b> includes <b>pointers</b> on how to play the game, history, rules, and a list of all national champions.|$|R
40|$|This {{document}} provides {{instructions on}} setting up, starting up, and building DICE and its key companion packages, dicemin and dicelang. This installation process {{is based on}} a general set of conventions, which we refer to as the DICE organizational conventions, for software packages. The DICE organizational conventions are specied in this report. These conventions are applied in DICE, dicemin, and dicelang, and also to other software packages that are developed in the Maryland DSPCAD Research Group [1]. This user's guide is supplemented by an overview of DICE and some of its core features [2], online docu-mentation available in DICE, and various tutorial materials that are available electronically from the DICE User's <b>Guide.</b> <b>Pointers</b> to these resources are available in the Online Supplement [3]. 1 What is DICE? DICE (the DSPCAD Integrative Command Line Environment) is a package of utilities that facilitates e-cient management of software projects. Key areas of emphasis in DICE are cross-platform operation, support for projects that integrate heterogeneous programming languages, and support for applying and integrating dierent kinds of design and testing methodologies. The package is being developed at the University of Maryland to facilitate the research and teaching of methods for implementation, testing, evolution, and revi-sion of engineering software. The package is also being developed as a foundation for developing experimenta...|$|R
5000|$|Herman Hollerith's first {{device for}} {{punching}} cards from the 1890s was ...any ordinary ticket punch, cutting a round hole 3/16 {{of an inch}} in diameter. Use of such a punch was facilitated by placing the holes to be used near {{the edges of the}} card. Hollerith soon developed a more accurate and simpler to use Keyboard Punch, using a pantograph to link a punch mechanism to a <b>guide</b> <b>pointer</b> that an operator would place over the appropriate mark in a 12 by 20 matrix to line up a manual punch over the correct hole in one of 20 columns. [...] In 1901 Hollerith patented a mechanism where an operator pressed one of 12 keys to punch a hole, with the card automatically advancing to the next column. This first-generation Type 001 keypunch used 45 columns and round holes. In 1923 The Tabulating Machine Company introduced the first electric keypunch, the Type 011 Electric Keypunch, a similar looking device where each key closed an electrical contact that activated a solenoid which punched the hole. The 80 column punched card format was introduced in 1928; existing keypunches and other products could be modified for this new format while keeping the same model numbers. [...] Later Hollerith keypunches included the Type 016 Motor-Driven Electric Duplicating Keypunch (1929), the Type 31 Alphabetical Duplicating Punch (1933), and the Type 32 Alphabetical Printing Punch (1933).|$|R
30|$|Links: in {{the form}} of mash-ups and <b>pointers,</b> <b>guide</b> to what is {{important}} and provide structure to online content by providing interconnections between content. Dense link structures (continuously updated and reflecting the opinions of many participants) lead to better search output and help in getting more value from the content (McAfee [2006]; Frappaolo et al. [2008]).|$|R
40|$|The {{clinical}} interview {{is an essential}} component of neuropsychological assessment and assumes even greater importance in situations where standardized tests are lacking. In such situations, qualitative assessment strategies may be necessary. This chapter will summarize some cultural and social factors that may influence client presentation and collection of collateral information, and strategies for interviewing and qualitative assessment with Asians and Asian Americans. A pan-Asian perspective is adopted heuristically to provide an introductory <b>guide</b> with <b>pointers</b> in working with Asians and Asian Americans. Clinical neuropsychologists are encouraged to consult the literature on individual Asian cultures for more in-depth information according to the specific needs of their setting...|$|R
40|$|Abstract—Today’s mobile {{computing}} devices provide a convenient means {{to search for}} points-of-interest (POIs) such as restaurants and accommodation. These devices however, have several design constraints including limited screen space and hardware capabilities. Adaptive User Interfaces (AUIs) have been proposed {{to address these issues}} but have not been extensively applied to mobile tourist guides. A recent field study was conducted {{in order to determine the}} adaptation requirements for an existing mobile tourist <b>guide</b> called <b>POInter.</b> This paper discusses the analysis of the field study results and details a list of user requirements for an adaptive mobile tourist. A model-based design approach for an adaptive mobile tourist guide is discussed together with appropriate algorithms to achieve the adaptation required...|$|R
40|$|This {{guide is}} {{primarily}} for evaluators {{working in the}} international development sector. It is also useful for commissioner of evaluations, evaluation managers and M&E officers. The guide explains how to make evaluations more useful. It helps to better understand conceptual issues and appreciate how evaluations can contribute to changing mindsets and empowering stakeholders. On a practical level, the guide presents core <b>guiding</b> principles and <b>pointers</b> on how to design and facilitate evaluations that matter. Furthermore, it shows how to get primary intended users and other key stakeholders to contribute effectively to the evaluation proces...|$|R
40|$|Recent {{advances}} in multi-core and many-core processors requires programmers to exploit an increasing amount of parallelism from their applications. Data parallel languages such as CUDA and OpenCL {{make it possible}} to take advantage of such processors, but still require a large amount of effort from programmers. To address the challenge of parallel programming, we introduce Bones. Bones is a source-to-source compiler based on algorithmic skeletons and a new algorithm classification. The compiler takes C-code annotated with class information as input and generates parallelized target code. Targets include NVIDIA GPUs (through CUDA), AMD GPUs (through OpenCL) and x 86 CPUs (through OpenCL and OpenMP). Bones is open-source, written in the Ruby programming language, and is available through our website. The compiler is based on the C-parser CAST, which is used to parse the input code into an abstract syntax tree (AST) and to generate the target code from a transformed AST. This document is meant as a manual for users of Bones. It includes usage instructions, an installation <b>guide</b> and <b>pointers</b> to further documentation. It furthermore contains an overview of the tool itself and the skeletons, a mandatory read for users that plan on modifying or extending the skeletons and/o...|$|R
40|$|Retrieving the stylus of a pen-based device {{takes time}} and {{requires}} a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are {{the occlusion of the}} target by the user’s finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users <b>guide</b> the <b>pointer</b> into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary—over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets. Author Keywords mobile devices, touch-screens, interaction techniques, occlusion...|$|R
40|$|This {{guide is}} {{primarily}} for evaluators {{working in the}} international development sector. However, {{if you are a}} commissioner of an evaluation, an evaluation manager or a monitoring and evaluation (M&E) officer, you too will find it useful. Too often evaluations are shelved, with very little being done to bring about change within organisations that requested the evaluation in the first place. This guide will explain how you can make your evaluations more useful. It will help you to better understand some conceptual issues and appreciate how evaluations can contribute to changing mindsets and empowering stakeholders. On a practical level, the guide presents core <b>guiding</b> principles and <b>pointers</b> on how to design and facilitate evaluations that matter. Furthermore, it shows you how you can get your primary intended users and other key stakeholders to contribute effectively to the evaluation process...|$|R
40|$|An {{earthquake}} is {{a natural}} disaster caused by {{the movement of the}} earth plates or from below the Earth surface. The impact of the earthquake could lead casualties and other losses whether material or immaterial. The evacuation process of the victims must immediately proceed. The SAR (Search and Rescue) team has a duty to rescue victims who trapped in the rubble of the building. But information about the position of the victims could not be known precisely, and the environment around the location of the disaster is still very dangerous that might endanger the safety of SAR Team. In this research, a robot path pointer was designed to help SAR team in locating the victims. The method used in this research is the robot wirelessly controlled by SAR team at SAR team’s post with remote control. The robot searches in the rubble of the building and sends the victim’s location information to SAR team. This robot pointer research aims to find safe routes for SAR team of the victim’s location to reduce the risks that may harm the SAR team. The robot will give the main results of the pointer in the form of location coordinates and routes of the victim so that the SAR team only have to follow the route. Robot <b>pointer</b> <b>guides</b> the SAR team to the location of the earthquake in a short and less risky path for victim evacuation...|$|R
40|$|XII, 118 p. : ill. Libro ElectrónicoThis {{guide is}} {{primarily}} for evaluators {{working in the}} international development sector. It is also useful for commissioner of evaluations, evaluation managers and M&E officers. The guide explains how to make evaluations more useful. It helps to better understand conceptual issues and appreciate how evaluations can contribute to changing mindsets and empowering stakeholders. On a practical level, the guide presents core <b>guiding</b> principles and <b>pointers</b> on how to design and facilitate evaluations that matter. Furthermore, it shows how to get primary intended users and other key stakeholders to contribute effectively to the evaluation process. Table of contents A letter to the reader	 ix Introduction	xi 1 	 Core principles for guiding evaluations that matter	 1 : 13 1. 1 	 Utilization-focused, influence- and consequence-aware. 1 : 14 1. 2 	 Stakes, stakeholder engagement and learning 1 : 19 1. 3 	 Situational responsiveness. 1 : 19 1. 4 	 Multiple evaluator and evaluation roles 1 : 21 1. 5 	 Some key points on core principles for guiding evaluations that matter. 1 : 22 2 	 Suggested steps for designing and facilitating evaluations that matter 	 2 : 23 2. 1 	 Establish ability and readiness for evaluation. 2 : 26 2. 2 	 Focus the evaluation. 2 : 30 2. 3 	 Implement the evaluation. 2 : 45 2. 4 	 Evaluate the evaluation 2 : 59 2. 5 	 Some key points on suggested steps for designing and facilitating evaluations that matter 2 : 60 3 	 Getting stakeholders to contribute successfully	 3 : 61 3. 1 	 Who the stakeholders are. 3 : 61 3. 2 	 What are the stakes and who has these stakes? 3 : 62 3. 3 	 Why encourage stakeholder engagement?. 3 : 63 3. 4 	 How much engagement? 3 : 63 3. 5 	 Who to engage {{and what are the}} consequences of these choices?. 3 : 66 3. 6 	 Evaluation roles needed in balancing content and people processes 3 : 70 3. 7 	 Engaging stakeholders effectively. 3 : 76 3. 8 	 Strategies for addressing group issues 3 : 77 3. 9 	 Some key points on getting stakeholders to contribute successfully. 3 : 78 4 	 Turning evaluation into a learning process	 4 : 79 4. 1 	 Learning in evaluative practice 4 : 80 4. 2 	 Experiential learning cycle 4 : 81 4. 3 	 Single, double and triple loop learning. 4 : 83 4. 4 	 Key learning moments during the evaluation process 4 : 85 4. 5 	 Enhancing learning. 4 : 87 v 4. 6 	 Dealing with diversity in learning processes. 4 : 88 4. 7 	 Some key points on turning evaluation into a learning process 4 : 89 5 	 Thinking through the possible influences and consequences of evaluation on change processes	 5 : 91 5. 1 	 How change happens 5 : 93 5. 2 	 Some key points on thinking through the possible influences and consequences of evaluation on the change process 5 : 96 Conclusion: Evaluations matter	 97 Annex A: 	 xamples of (Learning) Purposes, Assessment Questions, Users and Uses E of an Evaluation for a Food Security Initiative 99 Annex B:	Contrasts between Traditional Evaluation and Complexity-Sensitive Developmental Evaluation 101 References 105 Glossary	. 111 Acronyms and abbreviations. 114 Index	. 115 List of figures Figure 2. 1 	 Flow Chart – Evaluation Design and Facilitation. 2 : 24 Figure 2. 2 A Theory of Change for Agri-ProFocus (APF) 2 : 38 Figure 3. 1 Influence Matrix of Stakeholders on an Evaluation. 3 : 69 Figure 3. 2 Life-Cycle: Stages of Group Formation 3 : 76 Figure 4. 1 Stages of the Experiential Learning Cycle. 4 : 81 Figure 4. 2 Single, Double and Triple Loop Learning 4 : 84 Figure 5. 1 Matrix Showing Factors Promoting Transformation at the Individual, Relationship, Cultural and Systems Levels 5 : 94 List of tables Table 1. 1 	 Consequences of Evaluation Use 1 : 18 Table 2. 1 	 Criteria for Assessing Ability and Readiness for Evaluation. 2 : 27 Table 2. 2 Example of Stakeholder Participation in Evaluation 2 : 43 Table 2. 3 	 Example of an Evaluation Matrix for an Agricultural Development Initiative for Improved Livelihoods. 2 : 49 vi Table 3. 1 Examples of Situational Factors in Evaluation that Can Affect Stakeholders’ Participation and Use 3 : 66 Table 3. 2 Examples of Situations that Pose Special Challenges to Evaluation Use and the Evaluator’s Role 3 : 73 Table 3. 3 	 Stages of Group Formation, Group Characteristics and Expectations, and Role of the Evaluator/Manager. 3 : 77 List of boxes Box 1. 1 	 Threats to Utility. 1 : 15 Box 1. 2 	 Being Clear about Your Own Principles for Evaluation 1 : 16 Box 2. 1 	 Readiness for Evaluation. Readiness for Change?. 2 : 28 Box 2. 2 	 Adding Rigour to the Evaluation Process 2 : 28 Box 2. 3 	 Standards for Evaluation. 2 : 33 Box 2. 4 	 Definition of Key Evaluation Areas 2 : 40 Box 2. 5 	 Evaluation / Performance / Learning Questions 2 : 41 Box 2. 6 	 Examples of Evaluation Questions in Relation to Key Evaluation Areas 2 : 41 Box 2. 7 	 Suggested Outline for a Work Plan for an Evaluation. 2 : 47 Box 2. 8 	 Sample Format for Terms of Reference. 2 : 47 Box 2. 9 	 Measuring Change with an Open Mind - Most Significant Change (MSC) Technique and Participatory Video in Zanzibar 2 : 51 Box 2. 10 	 Poor Feedback with Serious Consequences 2 : 57 Box 2. 11 	 Ten Guidelines for Useful and Practical Recommendations 2 : 58 Box 3. 1 	 Multiple Stakes in a Street Kids’ Programme. 3 : 63 Box 3. 2 	 Empowering Stakeholders through Evaluation 3 : 64 Box 3. 3 	 Integrating Self-assessment in Evaluation: A Story from the Centre for Development Innovation. 3 : 65 Box 3. 4 	 Stakeholder Participation in Data Collection and Analysis – Mixed Feelings About Consequences. 3 : 70 Box 3. 5 	 Essential Competencies for Programme Evaluators. 3 : 72 Box 3. 6 	 Changing the Focus of an Evaluation Half-Way through the Process 3 : 74 Box 4. 1 	 An Example of the Experiential Learning Cycle Applied to an Evaluation 4 : 82 Box 4. 2 	 Selected Barriers to Learning. 4 : 85 Box 4. 3 	 Critical Reflection Questions 4 : 86 Box 4. 4 	 Factors Affecting Learning from an Evaluation 4 : 88 Box 5. 1 	 An Evaluation Process that Influenced Change Processes. 5 : 92 Box 5. 2 	 Possible Reactions of Stakeholders to Change. 5 : 93 Box 5. 3 	 Learning-Based Change and the Learning Organisation’s Characteristics 5 : 9...|$|R

