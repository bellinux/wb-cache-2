0|10000|Public
40|$|The {{complexity}} of university activities {{does not allow}} reducing the multidimensional space of those activities and their outcomes into one dimension of linear ranking. The <b>difficulty</b> <b>of</b> <b>quantification</b> {{as well as the}} all too frequently experienced arbitrariness in defining composite indicators often results in inadequate representation and irreproducibility and hence in clear conflicts with the Berlin Principles on Ranking of HEIs. Even focussing on one single, however important aspect, such as the assessment of research performance, remains a multifaceted endeavour. Using the example of bibliometrics, we point to caveats and pitfalls in the challenge of comparative research assessment of colleges and universities. status: publishe...|$|R
40|$|Agriculture {{contributes}} {{to climate change}} {{and at the same}} time has a huge climate change mitigation potential – this lies mainly in increased soil carbon sequestration. This article discusses the mitigation potential of soil carbon sequestration, the underlying processes and main challenges for its utilization. There are <b>difficulties</b> <b>of</b> reliable <b>quantification,</b> aspects <b>of</b> leakage and system boundaries. Utilization of this mitigation potential is currently mainly via offset mechanisms. Due to the named challenges, offset mechanisms are not adequate for this and more aggregate approaches should be employed...|$|R
40|$|For {{many reasons}} writing {{is one of}} the {{foundational}} skills of educated persons. Tests of writing skills are therefore needed. The intent {{of this paper is to}} discuss and explore traditional essay techniques and suggests both objective and subjective scoring methods. It is recognized that the problem of quantifying essay tasks is a crucial difficulty in school applications. A method of interpreting learner protocols with a view toward helping learners to overcome language difficulties is focused. Though essay testing may require more work of the teacher and of the students than many other testing procedures, it is considered to be a profitable assessment technique. Certainly it affords a rich yield of diagnostic information concerning the learner’s developing expectancy grammar. One of the most often used and perhaps least understood methods of testing language skills is the traditional essay or composition. The freedom allowed by essay tasks may both their greatest strength and weakness- a strength because they require a lot of the examinee, and a weakness because of the judgement required of the examiner. Except for the greater accessibility of the written protocols of learners, the evaluation of writing performances is similar to the evaluation of spoken protocols. The fundamental problem in using essay tasks as tests is the <b>difficulty</b> <b>of</b> <b>quantification</b> - converting performances in scores...|$|R
40|$|The <b>difficulty</b> <b>of</b> the <b>quantification</b> <b>of</b> the {{irregular}} occupations leads {{the search of}} new procedures to indicate its perimeters and to distinguish the property. Normally this quantification is carried through directly in field, however the displacement inside of these areas is difficult because the community does not see with good eyes the circulation of strangers in its space. One in the ways to decide this problem is the air photograph job and the respective carried through three-dimensional interpretation {{from the use of}} estereoscópicos pairs. The conventional process suggests the use of estereoscopios of reflection. This article describes and analyzes procedures for detention and <b>quantification</b> <b>of</b> habitations in area of risk with the estereoscópica vision. Using vertical aerial photographs, normal color, of small format (negative: 2, 4 cm x 3, 6 cm), had been elaborated anaglyph aiming at to detect an area of irregular nesting and to classify the existing habitations in the place. The anaglyph allow a general visualization of the area in 3 D. Pages: 3899 - 390...|$|R
40|$|This paper calls {{attention}} to a methodological problem of acquisition experiments. It shows that {{the economy of the}} stimulus employed in child language experiments may lend an increased ostensive effect to the message communicated to the child. Thus, when the visual stimulus in a sentence-picture matching task is a minimal model abstracting away from the details of the situation, children often regard all the elements of the stimulus as ostensive clues to be represented in the corresponding sentence. The use of such minimal stimuli is mistaken when the experiment aims to test whether or not a certain element of the stimulus is relevant for the linguistic representation or interpretation. The paper illustrates this point by an experiment involving quantifier spreading. It is claimed that children find a universally quantified sentence like 'Every girl is riding a bicycle 'to be a false description of a picture showing three girls riding bicycles and a solo bicycle because they are misled to believe that all the elements in the visual stimulus are relevant, hence all of them are to be represented by the corresponding linguistic description. When the iconic drawings were replaced by photos taken in a natural environment rich in accidental details, the occurrence of quantifier spreading was radically reduced. It is shown that an extra object in the visual stimulus can lead to the rejection of the sentence also in the case of sentences involving no quantification, which gives further support to the claim that the source of the problem is not (or not only) the grammatical or cognitive <b>difficulty</b> <b>of</b> <b>quantification</b> but the unintended ostensive effect of the extra object.   This article is part of the special collection: Acquisition of Quantification</a...|$|R
40|$|Viruses {{may play}} a {{critical}} role in the microbial dynamics of activated sludge systems; however the <b>difficulty</b> <b>of</b> their <b>quantification</b> makes long term and large scale studies costly, timely and challenging. Thus a flow cytometric protocol was optimised and employed to determine virus abundance in activated sludge samples. The best flow cytometry signature and highest virus count was obtained by separating the indigenous floc-associated viruses using Tween 80 and sodium pyrophosphate, diluting the sample with Tris–EDTA and staining with SYBR Green II. Using the optimised protocol viral concentrations from 25 activated sludge plants were determined, with average concentrations of 2. 35 × 109 mL− 1 observed. Direct counts by transmission electron microscopy were highly correlated with flow cytometric counts (p = < 0. 05 and r 2 = 0. 77), with concentrations from both quantification methods comparable at the order of magnitude level. The high counting efficiency, ease of preparation and rapidity and reproducibility of analysis makes flow cytometric <b>quantification</b> <b>of</b> viruses in activated sludge ideal for routine investigation and thus invaluable in unravelling the complexity of phage host interactions in such systems...|$|R
40|$|The results {{presented}} in this thesis provide powerful conclusions regarding animal-fluid interactions in their natural environment. However, as with most original works, many questions remain. We have shown that measurements of in situ flows are necessarily assumed to be two dimensional due to the inherent <b>difficulties</b> <b>of</b> three-dimensional <b>quantification</b> <b>of</b> flows. Since this assumption cannot always be made, especially of turbulent background flows in the ocean, a technique that measures three-dimensional flows {{in the field is}} necessary. We have also showed striking images of animal-induced fluid transport in situ that are described by the drift mechanism and compared these measurements with simulations of moving, passive particles. However, the interaction of unsteady animal motion and wake generation with the drift volume needs to be investigated. Depending on the animal’s morphology or swimming mode, there may be a limiting characteristic that selects drift as a dominant mechanism of mixing over wake mixing and vice versa. Finally, multiple-animal interactions and its inherent effect on fluid transport needs to be extended to global scale ocean mixing, and its subsequent impact on climate needs to be addressed...|$|R
40|$|Base {{roughness}} {{plays an}} important role in the dynamics of granular flows but is still poorly understood due to the <b>difficulty</b> <b>of</b> its <b>quantification.</b> For a bumpy base made of spheres, at least two factors should be considered in order to characterize its geometric roughness, namely, the size ratio of flow to base particles and the packing arrangement of base particles. In this paper, we propose an alternative definition of base roughness, Ra, as a function of both the size ratio and the distribution of base particles. This definition is generalized for random and regular packings of multilayered spheres. The range of possible values of Ra is presented, and optimal arrangements for maximizing base roughness are studied. Our definition is applied to granular chute flows in both two- and three-dimensional configurations, and is shown to successfully predict whether slip occurs at the base. A transition is observed from slip to nonslip conditions as Ra increases. Critical values of Ra are identified for the construction of a nonslip base at various angles of inclination. Department of Civil and Environmental Engineerin...|$|R
40|$|The {{article is}} devoted to the {{investigation}} of current approaches to identification of factors of economic growth in the regions. The theory of new economic geography based on works and studies of P. Krugman has been considered. There highlighted the key issues of regional economic growth requiring an in-depth studying and consideration in the elaboration of strategies for sustainable development of the regions. The views of leading domestic and foreign scholars as well as the OECD experts, the World Bank, the National Statistics Service of the United Kingdom and others on the main drivers of economic growth have been analyzed. On the basis of the study the factors of regional economic growth most commonly encountered in theory and practice have been generalized. It is proved that scientists and analysts most often classify as the factors of regional economic growth the following ones: those characterizing human potential, scientific-technical and innovative activity, management and institutional capacity. The factors less frequently correlated by specialists and scientists with the regional economic growth include: those characterizing the environment, business and sociopolitical factors, which is associated with <b>difficulty</b> <b>of</b> their <b>quantification,</b> but in any case does not diminish their importance...|$|R
40|$|This {{report has}} been {{prepared}} {{in response to}} a brief from Queensland Transport (Integrated Transport Planning Division). The main objective of the work is to produce a summary of available evidence on how to capture economic impacts of public transport projects within the context of multi-modal transport evaluation. The assessment of Public Transport (PT) is essentially the trading-off of conflicting objectives, laden with technical, socio-economic, environmental and political value judgements. This may apply to PT initiatives related individual projects, as well as strategies, policies and plans either at the local, corridor or regional levels. When undertaking an economic assessment of PT initiatives it would appear sensible to follow the same economic principles which underpin all other transport economic evaluations, namely the welfare economic theory and practice used in cost-benefit analysis work. The perceived rigour in the evaluation of road network based passenger and freight related transport projects stems from: • the use of well established transport modelling techniques to estimate impacts • the use of cost-benefit analysis (CBA) when carrying out evaluations. The same level of rigour can be applied to PT initiatives given the availability of the same techniques and the applicability of the same underlying principles. The same approach can be adopted whether the PT initiatives relate to individual capital projects or to a set of policies or strategies. The difference between the economic evaluation of road projects and that of PT initiatives {{has to do with the}} degree <b>of</b> <b>difficulty</b> in <b>quantification</b> <b>of</b> impacts...|$|R
40|$|The paper {{refers to}} the {{modeling}} of the plasma plume influence on {{the shape of the}} crater obtained by means of nanosecond pulsed laser milling. A transient model of the physical state of the plasma plume is developed according to the laser parameters. Two empirical coefficients are proposed in the model in order to evaluate the plasma plume self-emission energy lost towards the environment and the energy spread from the plasma towards the target surface. These two coefficients, directly correlated to the depth and to the width of the crater, can be experimentally determined, due to the <b>difficulty</b> <b>of</b> their analytical <b>quantification,</b> and they can be used for tuning a complete plasma plume software package for laser milling simulation named LAS (Laser Ablation Simulator) already developed by the authors. In this paper their influence on the crater shape will be proved by means of several simulation runs...|$|R
40|$|Base {{roughness}} {{plays an}} important role to the dynamics of granular flows but is yet poorly understood due to the <b>difficulty</b> <b>of</b> its <b>quantification.</b> For a bumpy base made by spheres, at least two factors should be considered to characterize its geometric roughness, namely the size ratio of base- to flow-particles and the packing of base particles. In this paper, we propose a definition of base roughness, Ra, which is a function of both the size ratio and the packing arrangement of base particles. The function is generalized for random and regular packing of multi-layered spheres, where the range of possible values of Ra is studied, along with the optimal values to create maximum base roughness. The new definition is applied to granular flows down chute in both two- and three-dimensional configurations. It is proven to be a good indicator of slip condi- tion, and a transition occurs from slip to non-slip condition as Ra increases. Critical values of Ra are identified {{for the construction of a}} non-slip base. The effects of contact parameters on base velocity are studied, and it is shown that while the coefficient of friction is less influential, normal damping has more profound effect on base velocity at lower values of Ra. The application of present definition to other base geometries is also discussed. Comment: 18 figure...|$|R
40|$|This paper {{discusses}} a best-practice {{representation of}} uncertainty in satellite remote sensing data. An estimate of uncertainty {{is necessary to}} make appropriate use of the information conveyed by a measurement. Traditional error propagation quantifies the uncertainty in a measurement due to well-understood perturbations in a measurement and in auxiliary data - known, quantified "unknowns". The under-constrained nature of most satellite remote sensing observations {{requires the use of}} various approximations and assumptions that produce non-linear systematic errors that are not readily assessed - known, unquantifiable "unknowns". Additional errors result from the inability to resolve all scales of variation in the measured quantity - unknown "unknowns". The latter two categories of error are dominant in under-constrained remote sensing retrievals, and the <b>difficulty</b> <b>of</b> their <b>quantification</b> limits the utility of existing uncertainty estimates, degrading confidence in such data. This paper proposes the use of ensemble techniques to present multiple self-consistent realisations of a data set as a means of depicting unquantified uncertainties. These are generated using various systems (different algorithms or forward models) believed to be appropriate to the conditions observed. Benefiting from the experience of the climate modelling community, an ensemble provides a user with a more complete representation of the uncertainty as understood by the data producer and greater freedom to consider different realisations of the data...|$|R
40|$|Due to {{rainfall}} {{variation and}} poor land cover, water erosion in the loess hilly area is severe and experiences high temporal fluctuations, which increase the <b>difficulties</b> <b>of</b> erosion <b>quantification,</b> prediction and control. In this study, 15 runoff plots were implemented in Dingxi, a typical loess hilly area of Gansu Province since 1986. Three typical years representing WY (wet year), NY (normal year) and DY (drought year) were firstly filtered {{based on the}} consecutive rainfall-erosion data and an aridity index. Then, water erosion dynamics involving five land uses (cropland, alfalfa, scrubland, woodland and grassland) in the three typical years were analyzed. The following results were found. Firstly, the most severe annual erosion rates did not appear in WY, but in DY. Moreover, the rates in DY were far higher than those in NY and WY. Secondly, although total rain depth and number of events {{were in the order}} of WY>NY>DY, mean maximal intensity of erosive rainfall however, was in the order of DY>NY>WY. This finding is important for erosion control. Namely, we cannot judge water erosion degree just from annual rainfall. More attention should be paid to the specific rainfall variables and distributions. Thirdly, different land uses played an important role with sea buckthorn reducing water erosion in contrast to spring wheat cultivated on steep slopes. Lastly, regardless of different drought-level years, only a few number of events with high intensities were responsible for the majority of annual soil and water loss. (C) 2010 Elsevier B. V. All rights reserved...|$|R
40|$|The {{presence}} {{and role of}} melatonin in plants are still under debate owing to <b>difficulties</b> <b>of</b> identification and <b>quantification.</b> Accordingly, {{although it has been}} frequently proposed that melatonin acts as an antioxidant in phototrophic organisms, experimental data on its physiological role are scarce. This study describes the use of a rapid and simple new method for <b>quantification</b> <b>of</b> melatonin in the marine macroalga Ulva sp., organisms routinely exposed to tide-related environmental stresses and known for their high tolerance to abiotic conditions. The method was used here to show that exposure to oxidative stress-inducing environmental conditions (elevated temperature and heavy metals) induced a rise in melatonin level in the algae. Addition of exogenous melatonin alleviated the algae from cadmium-induced stress. Interestingly, although the algae were taken from a culture growing free floating and kept under constant photoperiod and water level, they exhibited a semi-lunar rhythm of melatonin levels that correlated with predicted spring tides. The correlation can probably be interpreted as reflecting preparation for predicted low tides, when the algae are exposed to increasing temperature, desiccation, and salinity, all known to induce oxidative stress. Given the simplicity of the described method it can easily be adapted for the study of melatonin in many other phototrophic organisms. These results provide, for the first time, experimental data that support both an antioxidant role for melatonin and its semi-lunar rhythm in macroalgae...|$|R
40|$|An {{estimate}} of uncertainty {{is necessary to}} make appropriate use of the information conveyed by a measurement. Traditional error propagation quantifies the uncertainty in a measurement due to well-understood perturbations in a measurement and auxiliary data – known, quantified `unknowns'. The underconstrained nature of most satellite remote sensing observations {{requires the use of}} approximations and assumptions that produce non-linear systematic errors that are not readily assessed – known, unquantifiable `unknowns'. Additional errors result from the inability of a measurement to resolve all scales and aspects of variation in a system – unknown `unknowns'. The latter two categories of error are dominant in satellite remote sensing and the <b>difficulty</b> <b>of</b> their <b>quantification</b> limits the utility of existing uncertainty estimates, degrading confidence in such data. Ensemble techniques present multiple self-consistent realisations of a data set as a means of depicting unquantified uncertainties, generated using various algorithms or forward models believed to be appropriate to the conditions observed. Benefiting from the experience of the climate modelling community, an ensemble provides a user with a more accurate representation of the uncertainty as understood by the data producer and greater freedom to exploit {{the advantages and disadvantages of}} different manners of describing a physical system. The technique will be demonstrated with retrievals of aerosol, cloud, and surface properties, for which many sources of error cannot currently be quantified (such as the assumed aerosol microphysical properties). The Optimal Retrieval of Aerosol and Cloud (ORAC) can produce an ensemble by evaluating data with a succession of microphysical models (e. g. liquid cloud, urban aerosol, etc.). A further ensemble can be formed from products produced by various European institutions. These will be used to demonstrate uncertainties in such observations that are poorly characterised in current products...|$|R
5000|$|Some {{versions}} of the notation explicitly mention the range <b>of</b> <b>quantification.</b> The range <b>of</b> <b>quantification</b> must always be specified; for a given mathematical theory, {{this can be done}} in several ways: ...|$|R
5000|$|Every {{quantification}} involves {{one specific}} variable and a domain of discourse or range <b>of</b> <b>quantification</b> <b>of</b> that variable. The range <b>of</b> <b>quantification</b> specifies {{the set of}} values that the variable takes. In the examples above, the range <b>of</b> <b>quantification</b> is the set of natural numbers. Specification of the range <b>of</b> <b>quantification</b> allows us to express the difference between, asserting that a predicate holds for some natural number or for some real number. Expository conventions often reserve some variable names such as [...] "n" [...] for natural numbers and [...] "x" [...] for real numbers, although relying exclusively on naming conventions cannot work in general since ranges of variables can change {{in the course of}} a mathematical argument.|$|R
40|$|The {{introductory}} {{article to}} this HSR Special Issue presents the emerging field <b>of</b> sociology <b>of</b> <b>quantification,</b> {{which can be}} regarded as a transdisciplinary approach to the analysis <b>of</b> processes <b>of</b> <b>quantification.</b> Processes <b>of</b> categorization and classification are included because they can result in processes of generating figures and numbers also. The contribution sketches the science-historical development of this field. It is argued that processes <b>of</b> <b>quantification</b> are related in many ways with other social and socio-economic processes. Therefore, one can speak of a comprehensive political economy <b>of</b> statistics, <b>quantification</b> and categorization. Especially the works of the French statistician and sociologist Alain Desrosières are an innovative and far-reaching groundwork for the analysis <b>of</b> statistics, <b>quantification</b> and categorization. Also, Desrosières has pointed to the fundamental role of conventions for processes <b>of</b> <b>quantification</b> (as for processes of categorization) and he has published important contributions to the French science movement of economics of convention (économie des conventions). At the end of the article, a set of positions for a sociology <b>of</b> <b>quantification</b> are presented...|$|R
30|$|The {{multi-task}} incentive {{is mainly}} {{determined by the}} degree <b>of</b> <b>quantification</b> <b>of</b> reward and punishment.|$|R
40|$|Scientific realism {{holds that}} the terms in our {{scientific}} theories refer {{and that we should}} believe in their existence. This presupposes a certain understanding <b>of</b> <b>quantification,</b> namely that it is ontologically committing, which I challenge in this paper. I argue that the ontological loading of the quantifiers is smuggled in through restricting the domains <b>of</b> <b>quantification,</b> without which it is clear to see that quantifiers are ontologically neutral. Once we remove domain restrictions, domains <b>of</b> <b>quantification</b> can include non-existent things, as they do in scientific theorizing. Scientific realism would therefore require redefining without presupposing a view <b>of</b> ontologically committing <b>quantification...</b>|$|R
30|$|One {{important}} step towards the use <b>of</b> <b>quantification</b> {{in a clinical}} setting is to know {{the accuracy of the}} method used. The aim {{of this study was to}} investigate the differences in image quality and to investigate the accuracy <b>of</b> <b>quantification</b> <b>of</b> 68 Ga-PET and 111 In-SPECT images. This was performed by phantom measurements, and different methods for segmentation and quantification were evaluated.|$|R
5000|$|... (i) Conventional (i.e. what Brouwer calls ‘classical’ [...] ) {{logic is}} {{the logic of}} finite domains. In {{particular}} the mathematical laws <b>of</b> <b>quantification</b> apply only when the domains <b>of</b> <b>quantification</b> are finite. here is being used in Mayberry’s sense of “definite” or “delimited” - the defining characteristic of arithmoi.|$|R
40|$|The theory <b>of</b> <b>quantification</b> is {{a method}} of {{statistical}} data analysis of categorical data. In other words, {{this is a kind}} of data theory and is closely related to optimum scaling method. This method has been mainly developed by Guttman in Israel and Hayashi in Japan. The multidimensional scaling method, which has been recently developed, is considered to be a continuation of the theory <b>of</b> <b>quantification.</b> Tanaka discussed mathematically some of Hayashi's methods <b>of</b> <b>quantification.</b> The present paper, gives an overview of the methods developed by him and other closely related methods and gives the orientation of those methods introduced by Tanaka. Then, as an illustration of exploratory categorical data analysis, the experimental data of Grizzle are analyzed by using the second method <b>of</b> <b>quantification.</b> The data structure is shown heuristically as a spatial configuration of factors in two-dimensional Euclidean space. Tanaka discussed my early methods <b>of</b> <b>quantification</b> from the stand point of mathematical statistics and added his newly developed method in the case of ordered categories with some asymptotic theories (1). The terminology and notations in his paper ar...|$|R
50|$|See the {{articles}} on aperture and f-number for the photographic effect and system <b>of</b> <b>quantification</b> <b>of</b> varying {{the opening in}} the diaphragm.|$|R
50|$|This meaning <b>of</b> <b>quantification</b> {{comes under}} the heading of pragmatics.|$|R
40|$|Recent {{years have}} seen a number of severe {{droughts}} in different regions around the world, causing agricultural and economic losses, famines and migration. Despite their devastating consequences, the Standardised Precipitation Index (SPI) of these events lies within the general range of observation-based SPI time series and simulations from the 5 th phase of the Coupled Model Intercomparison Project (CMIP 5). In terms of magnitude, regional trends of SPI over the last decades remain mostly inconclusive in observation-based datasets and CMIP 5 simulations, but Soil Moisture Anomalies (SMAs) in CMIP 5 simulations hint at increased drought in a few regions (e. g., the Mediterranean, Central America/Mexico, the Amazon, North-East Brazil and South Africa). Also for the future, projections {{of changes in the}} magnitude of meteorological (SPI) and soil moisture (SMA) drought in CMIP 5 display large spreads over all time frames, generally impeding trend detection. However, projections of changes in the frequencies of future drought events display more robust signal-to-noise ratios, with detectable trends towards more frequent drought {{before the end of the}} 21 st century in the Mediterranean, South Africa and Central America/Mexico. Other present-day hot spots are projected to become less drought-prone, or display non-significant changes in drought occurrence. A separation of different sources of uncertainty in projections of meteorological and soil moisture drought reveals that for the near term, internal climate variability is the dominant source, while the formulation of Global Climate Models (GCMs) generally becomes the dominant source of spread by the end of the 21 st century, especially for soil moisture drought. In comparison, the uncertainty from Green-House Gas (GHG) concentrations scenarios is negligible for most regions. These findings stand in contrast to respective analyses for a heat wave index, for which GHG concentrations scenarios constitute the main source of uncertainty. Our results highlight the inherent <b>difficulty</b> <b>of</b> drought <b>quantification</b> and the considerable likelihood range of drought projections, but also indicate regions where drought is consistently found to increase. In other regions, wide likelihood range should not be equated with low drought risk, since potential scenarios include large drought increases in key agricultural and ecosystem regions...|$|R
40|$|In the {{literature}} is largely addressed the problem <b>of</b> <b>quantification</b> <b>of</b> qualitative variables, and different proposals, ranging from a simple re-up to a transformation of the full scale of measurement of variables. In this work we discuss some techniques <b>of</b> <b>quantification,</b> used in the Structural Equations (SEM). The SEM allow simultaneous estimation of several causal links between different variables, in particular, we treat the problem of referring to the Partial Least Squares Path Modeling (PLS-PM) for which we present some proposals made in Litterature, based on algorithms <b>of</b> optimal <b>quantification...</b>|$|R
30|$|The {{incentive}} {{intensity of}} multiple tasks depends {{primarily on the}} authority status of affiliated principal, followed by the degree <b>of</b> <b>quantification</b> <b>of</b> reward and punishment.|$|R
40|$|This paper {{concentrates}} on peculiar behaviors of an English word, else, among various lexical items which {{have to do}} with the exceptive constructions. Reviewing its intriguing properties, it is argued that a simple way of reducing an "exception " from the domain <b>of</b> <b>quantification</b> and a more enriched domain <b>of</b> <b>quantification,</b> containing at least pairs of individuals, are preferable. ...|$|R
5000|$|... 1973: [...] "The Proper Treatment <b>of</b> <b>Quantification</b> in Ordinary English" [...] (= PTQ) ...|$|R
5000|$|All known human {{languages}} {{make use}} <b>of</b> <b>quantification</b> (Wiese 2004). For example, in English: ...|$|R
5000|$|Increased {{accuracy}} <b>of</b> <b>quantification</b> by {{the elimination}} of errors resulting from calibrations and standards ...|$|R
40|$|Analyzing social {{processes}} <b>of</b> <b>quantification</b> has {{close relationship with}} the origins, core and potentialities of the economics <b>of</b> convention. <b>Quantification</b> and its social organization and goals are now impacted by the turn toward the market for organizing all human activities. Research should focus on the relationship between generalizing the market, transforming the state and changing the rote and status <b>of</b> <b>quantification.</b> Retracing the main outcomes of the seminal works on quantification, this paper highlights the contributions that EC could provide in that field. " (author's abstract...|$|R
5000|$|It {{seems to}} be held as universally true that [...] "the {{foundation}} <b>of</b> <b>quantification</b> is measurement." ...|$|R
3000|$|The {{limit of}} {{detection}} (LOD) and limit <b>of</b> <b>quantification</b> (LOQ) were calculated using the following equation: [...]...|$|R
