10000|8237|Public
5|$|In January 2011, the closely {{orbiting}} planet Kepler-10b {{was confirmed}} in {{the orbit of}} the star Kepler-10 after measurements of its transiting behavior (where it crosses in front of Kepler-10, periodically dimming it) and a radial velocity effect detected in Kepler-10's spectrum provided the information needed {{to prove that it}} was indeed a planet. An additional, longer-period dimming was detected in Kepler-10's spectrum, suggesting that a second planet existed in the system; however, there remained the possibility that this signal could have some other cause, and that the transit event was a <b>false</b> <b>positive.</b> Attempts to measure the radial velocity effects of this object, now named KOI 072.02, were fruitless; therefore, to rule out <b>false</b> <b>positive</b> scenarios, the Kepler team used a technique called Blender.|$|E
5|$|HAT-P-33b was {{difficult}} to confirm because its star experiences high jitter, which disrupted the ability to obtain accurate measurements. As such, {{a greater number of}} radial velocity observations were collected to make the confirmation, although it was later determined that HAT-P-33b could not be determined using the radial velocity method. The planet's confirmation came about after the planet's light curve was collected, and the Blendanal process ruled out most <b>false</b> <b>positive</b> scenarios.|$|E
5|$|After {{the stellar}} {{parameters}} were established, the Kepler science team ran models and fits {{to ensure that}} Kepler-5's transit event was not a <b>false</b> <b>positive,</b> such as an eclipsing binary star. Once the planetary nature of Kepler-5b was established, the Kepler team searched for the planet's occultation behind its star, hoping to find the temperature on its day side. They found both, {{and were able to}} set the equilibrium temperature of the planet. The use of speckle imaging using adaptive optics at the WIYN Observatory in Arizona and the Palomar Observatory in California isolated the starlight of Kepler-5 from background stars.|$|E
30|$|Errors of S 3 {{come from}} <b>false</b> <b>positives</b> and <b>false</b> negatives. S 3 seeks to achieve higher {{performance}} than prior work by reducing <b>false</b> <b>positives</b> and <b>false</b> negatives. However, {{to choose the}} optimal threshold in the trade-off of <b>false</b> <b>positives</b> and <b>false</b> negatives, we seek less false negatives than <b>false</b> <b>positives.</b> This is because <b>false</b> <b>positives</b> identify normal data as sensitive, and thus cause over protection, while false negatives leave sensitive data unprotected, and cause more serious consequences, e.g., data exposed to attackers. In statistics, Recall can reflect the measure of false negatives and Precision reflects <b>false</b> <b>positives.</b> Therefore we seek higher recall value than precision value in this paper.|$|R
3000|$|Mutual {{membership}} checks provide {{detection of}} <b>false</b> <b>positives</b> in the bloom filters of DIAS. Only if multiple <b>false</b> <b>positives</b> occur between [...]...|$|R
40|$|The {{present study}} compares eight models for {{analyzing}} count data: {{ordinary least squares}} (OLS), OLS with a transformed dependent variable, Tobit, Poisson, overdispersed Poisson, negative binomial, ordinal logistic, and ordinal probit regressions. Simulation reveals the extent that each model produces <b>false</b> <b>positives.</b> Results suggest that, despite methodological expectations, OLS regression does not produce more <b>false</b> <b>positives</b> than expected by chance. The Tobit and Poisson models yield too many <b>false</b> <b>positives.</b> The negative binomial models produce fewer than expected <b>false</b> <b>positives...</b>|$|R
5|$|Later, Millennium Group {{offender}} profilers Frank Black (Lance Henriksen) and Peter Watts (Terry O'Quinn) {{investigate the}} disappearance of a bus full of schoolchildren. They believe the driver was also a victim, and not responsible; they meet with the local sheriff, John Cayce (Steven Rankin), who has dredged the bus from a lake. It is empty, but inside, Black experiences the same vision as Prine. He also finds paint transfer on the exterior, indicating the perpetrator was driving a white van. A <b>false</b> <b>positive</b> results as police apprehend storm chasers in a different van, who warn that a violent tornado is approaching.|$|E
5|$|Normal {{blood flow}} is {{anterograde}} (going to the heart), and from superficial to deep veins via perforator veins. However, {{there are two}} exceptions: firstly, the great saphenous vein (GSV) collaterals, (the veins that run parallel), drain the abdominal wall and have a flow {{from top to bottom}} so that when an examiner tests the sapheno-femoral junction, a <b>false</b> <b>positive</b> diagnosis might be made; secondly, in the flow from the sole of the foot venous network around 10% drains to the dorsal venous arch of the foot, going therefore against the norm, from deep to superficial veins.|$|E
5|$|Using {{a program}} called Blendanal, similar to the Blender {{technique}} used to verify the planets discovered by Kepler, the astronomers observing HAT-P-33 hoped to rule out <b>false</b> <b>positive</b> alternatives that could explain the planet-like signal seen in HAT-P-33's light curve and radial velocity. The use of Blendanal ruled out the possibilities that the signal was caused by that of a hierarchical triple star or a mixture between a bright star and a binary star in the background. The possibility that HAT-P-33 is actually a binary star whose secondary companion is too dim to be distinguishable from the brighter star could not be ruled out. However, the data indicated that the planet HAT-P-33b did indeed exist.|$|E
30|$|Experimental {{evaluation}} {{illustrates the}} high accuracy and matching achieved {{even in the}} case of <b>false</b> <b>positives</b> in bloom filters. Tolerance to <b>false</b> <b>positives</b> provides large data space savings. Accuracy is maintained even if the size of bloom filters decreases significantly, resulting in a high number of detected <b>false</b> <b>positives.</b> A future extension is the dynamic and automated allocation of larger space in the bloom filters based on accuracy requirements under <b>false</b> <b>positives.</b> Alternative approaches to bloom filters are also considered in future work, e.g., hash compaction (Dillinger and Manolios 2004).|$|R
30|$|During the {{retrospective}} visual {{investigation of the}} <b>false</b> <b>positives,</b> the appearance of unilateral and bilateral <b>false</b> <b>positives</b> in the CNN outputs (Table  2, Figs.  2 and 3) was linked with the age-related periventricular white matter hypoattenuation (see Fig.  3 b, c). Cortical <b>false</b> <b>positives</b> {{were related to the}} widening of the cortical sulci due to cortical atrophy (see Fig.  3 d). As a consequence, most of the <b>false</b> <b>positives</b> were located in the periventricular white matter and near to cortical cerebrospinal fluid spaces, {{to be associated with the}} normal aging effects on the brain.|$|R
30|$|Agglomerations help {{developers}} to avoid <b>false</b> <b>positives.</b> In general, developers identified less <b>false</b> <b>positives</b> {{when they used}} agglomerations (9 FP design problems) than when they used the list of code smells (21 FP design problems). As presented in our qualitative analysis (“How to improve design problem identification?” section), {{with the exception of}} participant 11, who analyzed several irrelevant agglomerations—i.e., agglomerations that do not reveal any design problem—all others identified either less or equal number of <b>false</b> <b>positives</b> when they were in the agglomeration group than when they were in the control group. When we analyze the control group, we can notice {{that more than half of}} the identified design problems are <b>false</b> <b>positives</b> (61.76 %) while the agglomeration group identified only 36 % of <b>false</b> <b>positives.</b>|$|R
5|$|Amphetamine is {{frequently}} measured in urine or blood {{as part of}} a drug test for sports, employment, poisoning diagnostics, and forensics. Techniques such as immunoassay, which is {{the most common form of}} amphetamine test, may cross-react with a number of sympathomimetic drugs. Chromatographic methods specific for amphetamine are employed to prevent <b>false</b> <b>positive</b> results. Chiral separation techniques may be employed to help distinguish the source of the drug, whether prescription amphetamine, prescription amphetamine prodrugs, (e.g., selegiline), over-the-counter drug products that contain levomethamphetamine, or illicitly obtained substituted amphetamines. Several prescription drugs produce amphetamine as a metabolite, including benzphetamine, clobenzorex, famprofazone, fenproporex, lisdexamfetamine, mesocarb, methamphetamine, prenylamine, and selegiline, among others. These compounds may produce positive results for amphetamine on drug tests. Amphetamine is generally only detectable by a standard drug test for approximately 24hours, although a high dose may be detectable for days.|$|E
5|$|The Kepler team's {{scientists}} conducted follow-up {{observations to}} confirm or reject the planetary nature of the detected object. To do so, they used the Keck 1 telescope at the W.M. Keck Observatory in Hawaii; the Shane and Hale telescopes in California; telescopes at the WIYN (including MMT) and Whipple observatories in Arizona; Nordic Optical Telescope in the Canary Islands; the Hobby-Eberly and Harlan J. Smith telescopes in Texas; and NASA's Spitzer Space Telescope. Because Kepler-11g orbits its star at a far greater distance than the inner five planets, fewer transits were observed, and radial velocity (the observation of a Doppler effect) interactions could not be easily discerned. As {{with the discovery of}} Kepler-9d, the Kepler team ran the information through numerous models to see if Kepler-11g's light curve could fit the profile of some other object, including an eclipsing binary star in the background that may have contaminated the data. The probability that Kepler-11g is not a planet but instead a <b>false</b> <b>positive</b> was determined to be 0.18%, effectively confirming its existence.|$|E
5|$|These {{laboratory}} tests are only of diagnostic value during the acute {{phase of the}} illness {{with the exception of}} serology. Tests for dengue virus-specific antibodies, types IgG and IgM, can be useful in confirming a diagnosis in the later stages of the infection. Both IgG and IgM are produced after 5–7 days. The highest levels (titres) of IgM are detected following a primary infection, but IgM is also produced in reinfection. IgM becomes undetectable 30–90 days after a primary infection, but earlier following re-infections. IgG, by contrast, remains detectable for over 60 years and, in the absence of symptoms, is a useful indicator of past infection. After a primary infection, IgG reaches peak levels in the blood after 14–21 days. In subsequent re-infections, levels peak earlier and the titres are usually higher. Both IgG and IgM provide protective immunity to the infecting serotype of the virus. In testing for IgG and IgM antibodies there may be cross-reactivity with other flaviviruses which may result in a <b>false</b> <b>positive</b> after recent infections or vaccinations with yellow fever virus or Japanese encephalitis. The detection of IgG alone is not considered diagnostic unless blood samples are collected 14 days apart and a greater than fourfold increase in levels of specific IgG is detected. In a person with symptoms, the detection of IgM is considered diagnostic.|$|E
50|$|<b>False</b> <b>positives</b> {{occur when}} the {{wireless}} intrusion prevention system detects an access point not actually connected to the secure network as wired rogue. Frequent <b>false</b> <b>positives</b> result in wastage of administrative bandwidth spent in chasing them. Possibility of <b>false</b> <b>positives</b> also creates hindrance to enabling automated blocking of wired rogues due to the fear of blocking friendly neighborhood access point.|$|R
3000|$|Finally, if {{more than}} one {{positive}} mutual membership is detected (o> 1 in lines 16 - 18), multiple <b>false</b> <b>positives</b> occur that cannot be identified. These <b>false</b> <b>positives</b> concern [...]...|$|R
40|$|The main {{disadvantage}} of static code analysis tools {{is the high}} rates of <b>false</b> <b>positives</b> they produce. Users may need to manually analyze {{a large number of}} warnings, to determine if these are false or legitimate warnings, reducing the benefits of automatic static analysis. Our long term goal is to significantly reduce the number of <b>false</b> <b>positives</b> that these tools report. A learning system could classify the warnings into true <b>positives</b> and <b>false</b> <b>positives</b> by means of features extracted from the program source code. This work implements and evaluates a technique to reduce the source code producing <b>false</b> <b>positives</b> into code snippets that are simpler to analyze. Results indicate that the method considerably reduces the source code size and it is feasible to use it to characterize <b>false</b> <b>positives...</b>|$|R
25|$|Perhaps {{the most}} widely {{discussed}} false positives in medical screening come from the breast cancer screening procedure mammography. The US rate of <b>false</b> <b>positive</b> mammograms is up to 15%, the highest in world. One consequence of the high <b>false</b> <b>positive</b> rate in the US is that, in any 10-year period, half of the American women screened receive a <b>false</b> <b>positive</b> mammogram. <b>False</b> <b>positive</b> mammograms are costly, with over $100million spent annually in the U.S. on follow-up testing and treatment. They also cause women unneeded anxiety. As {{a result of the}} high <b>false</b> <b>positive</b> rate in the US, as many as 90–95% of women who get a positive mammogram do not have the condition. The lowest rate in the world is in the Netherlands, 1%. The lowest rates are generally in Northern Europe where mammography films are read twice and a high threshold for additional testing is set (the high threshold decreases the power of the test).|$|E
25|$|Subsequent work by John Ioannidis {{and others}} {{has shown that}} for {{treatments}} with no prior plausibility, {{the chances of a}} positive result being a <b>false</b> <b>positive</b> are much higher, and that any result not consistent with the null hypothesis should be assumed to be a <b>false</b> <b>positive.</b>|$|E
25|$|As {{poppy seeds}} cause <b>false</b> <b>positive</b> results in drug tests, it is advised in {{airports}} in India not to carry such items to other countries, where this {{can result in}} punishments based on <b>false</b> <b>positive</b> results. Travelers to the United Arab Emirates are especially prone to difficulties and severe punishments.|$|E
30|$|The recall is {{sensitive}} to false negatives, {{and on the other}} hand, precision {{is sensitive}} to <b>false</b> <b>positives.</b> If the levenshtein values are higher, then <b>false</b> <b>positives</b> increase, and if the levenshtein values are lower, then false negatives increase.|$|R
40|$|Abstract—Transactional Memory (TM) has {{attracted}} considerable attention because {{it promises to}} increase programmer productivity by {{making it easier to}} write correct parallel programs. To maintain correctness in the face of concurrency, detecting conflicts among simultaneously running transactions is an essential element. Hardware signatures have been proposed as an area-efficient mechanism for conflict detection. A signature can summarize an unbounded amount of addresses and misses no conflicts, but could falsely declare conflicts even when no true conflict exists (<b>false</b> <b>positives)</b> due to aliasing and occupancy. Previous signature designs assume that <b>false</b> <b>positives</b> are destructive to performance and attempt to reduce the total number of <b>false</b> <b>positives.</b> In this paper, we show that some <b>false</b> <b>positives</b> can be helpful to performance by triggering the early abortion of a transaction which would encounter a true conflict later anyway. Based on this observation, we propose an adaptive grain signature to improve performance by dynamically changing the range of address keys based on the history. With the use of adaptive grain signatures, we can increase the number of performance-friendly <b>false</b> <b>positives</b> as well as decrease the number of performance-destructive <b>false</b> <b>positives...</b>|$|R
5000|$|... where , , [...] and [...] are {{the number}} of true <b>positives,</b> <b>false</b> negatives, <b>false</b> <b>positives</b> and true negatives respectively.|$|R
25|$|Thus, c = 10 {{yields a}} much greater {{probability}} of <b>false</b> <b>positive.</b>|$|E
25|$|The main {{criticism}} {{applied to}} the yeast two-hybrid screen of protein–protein interactions are {{the possibility of a}} high number of <b>false</b> <b>positive</b> (and false negative) identifications. The exact rate of <b>false</b> <b>positive</b> results is not known, but earlier estimates were as high as 70%. This also, partly, explains the often found very small overlap in results when using a (high throughput) two-hybrid screening, especially when using different experimental systems.|$|E
25|$|Expanded newborn {{screening}} is also opposed by among some health care providers, {{who are concerned}} that effective follow-up and treatment may not be available, that <b>false</b> <b>positive</b> screening tests may cause harm, and issues of informed consent. A recent study by Genetic Alliance and partners suggests that communication between health care providers and parents may be key in minimizing the potential harm when a <b>false</b> <b>positive</b> test occurs. The {{results from this study}} also reveal that parents found {{newborn screening}} to be a beneficial and necessary tool to prevent treatable diseases. To address the <b>false</b> <b>positive</b> issue, researchers from the University of Maryland, Baltimore and Genetic Alliance established a check-list to assist health care providers communicate with parents about a screen-positive result.|$|E
3000|$|... verifies the {{probability}} of <b>false</b> <b>positives.</b> For n= 1500, {{the probability}} of <b>false</b> <b>positives</b> in the first scheme is 0.76 ∗ 10 − 9, whereas, for the other two schemes is 0.005. The second scheme introduces higher randomness compared to the third one due to the higher number of hash functions. However, the second scheme causes a higher number of bit changes during insertions. This results in a higher number of potential collisions (Dillinger and Manolios 2004) that cause a higher number of <b>false</b> <b>positives.</b>|$|R
40|$|The authors {{assessed}} {{the extent to}} which multielement designs produced <b>false</b> <b>positives</b> using continuous duration recording (CDR) and interval recording with 10 -s and 1 -min interval sizes. Specifically, they created 6, 000 graphs with multielement designs that varied in the number of data paths, and the number of data points per data path, using a random number generator. In Experiment 1, the authors visually analyzed the graphs for the occurrence of <b>false</b> <b>positives.</b> Results indicated that graphs depicting only two sessions for each condition (e. g., a control condition plotted with multiple test conditions) produced the highest percentage of <b>false</b> <b>positives</b> for CDR and interval re-cording with 10 -s and 1 -min intervals. Conversely, graphs with four or five sessions for each condition produced the lowest percentage of <b>false</b> <b>positives</b> for each method. In Experiment 2, they applied two new rules, which were intended to decrease <b>false</b> <b>positives,</b> to each graph that depicted a false posi-tive in Experiment 1. Results showed that application of new rules decreased <b>false</b> <b>positives</b> to less than 5 % for all of the graphs except for those with two data paths and two data points per data path. Implications for brief assess-ments are discussed. at PENNSYLVANIA STATE UNIV on May 16, 2016 bmo. sagepub. comDownloaded fro...|$|R
5000|$|... cpplint.py {{suffers from}} both <b>false</b> <b>positives</b> and <b>false</b> negatives.False <b>positives</b> can be {{eliminated}} by tagging lines with [...] (or [...] to suppress only the incriminated [...] category).|$|R
25|$|There {{have been}} <b>false</b> <b>positive</b> {{phencyclidine}} (PCP) results caused by larger doses of venlafaxine, with certain on-site routine urine-based drug tests.|$|E
25|$|False positives {{can also}} produce serious and counter-intuitive {{problems}} when the condition being searched for is rare, as in screening. If a test has a <b>false</b> <b>positive</b> {{rate of one}} in ten thousand, but only {{one in a million}} samples (or people) is a true positive, most of the positives detected by that test will be false. The probability that an observed positive result is a <b>false</b> <b>positive</b> may be calculated using Bayes' theorem.|$|E
25|$|Reasons for <b>false</b> <b>positive</b> {{elevated}} serum amylase include {{salivary gland}} disease (elevated salivary amylase), bowel obstruction, infarction, cholecystitis, and a perforated ulcer.|$|E
30|$|Having such a {{human-in-the-loop}} {{makes it}} possible to tolerate a higher number of <b>false</b> <b>positives</b> than would be acceptable in a fully automated system. Since there is a trade-off between <b>false</b> <b>positives</b> and <b>false</b> negatives, the increase of <b>false</b> <b>positives</b> should decrease the number of false negatives (i.e., classifying weak signals from potential terrorists as non-interesting). Hence, the suggested method should {{be thought of as a}} help for the analyst to filter out a smaller set of data to look at, rather than a method to be fully automated.|$|R
40|$|Laboratory {{identification}} of radionuclides at environmental concentrations {{can easily be}} mistaken, because many energy interferences (coincident or overlapping spectral peaks) are possible. Conventional laboratory quality control measurements are typically not designed to test interferences found in real samples. In order to evaluate the occurrence of radiological <b>false</b> <b>positives</b> in environmental soil and groundwater samples collected at the Savannah River Site, instrument printouts, calibration records, and procedure manuals were examined between 1997 and 2001 at five commercial radiological laboratories. <b>False</b> <b>positives</b> of many radionuclides {{were found to be}} routinely reported at all five laboratories; causes vary. Magnitudes were generally between 0. 1 and 3 pCi/g in soils, and between 2 and 40 pCi/L in groundwater, within the range of possible concern to regulators. The frequency of <b>false</b> <b>positives</b> varied, but for several nuclides listed below, nearly every detection reported in SRS environmental samples during the study period was judged to be false. Gamma spectroscopy: Low-level <b>false</b> <b>positives</b> of Mn- 54, Zr- 95, Eu- 155, and Np- 239 were reported in many soil samples from four laboratories, due to interference from naturally occurring Tl- 208, Pb- 212, and Ac- 228. There were two causes. First, laboratories did not include low abundance (less than 2 per cent) peaks of Tl- 208, Pb- 212, and Ac- 228 in the libraries used by instrument software for interference correction. Second, even when instrument software rejected the identifications, incorrectly identified nuclides were still often reported as detected, because some labs' data management systems were not able to distinguish between software-accepted nuclides and software-rejected nuclides. Magnitudes of these <b>false</b> <b>positives</b> are usually below 1 pCi/g. Alpha spectroscopy: Incomplete chemical separation and breakthrough of natural radionuclides and/or daughters of laboratory tracers generate <b>false</b> <b>positives</b> in soils up to about 5 pCi/g. Examples include natural Th- 228 causing <b>false</b> <b>positives</b> of Am- 241 and Pu- 238; natural U- 234 being mistaken for Np- 237; and natural Ra- 224 generating <b>false</b> <b>positives</b> of Cm- 243 / 244. Peak taildown of tracers or other nuclides into neighboring peak windows can also generate <b>false</b> <b>positives</b> in both soils and groundwater. Examples include taildown of Th- 229 tracer into the Th- 230 spectral window, and U- 234 taildown causing <b>false</b> <b>positives</b> of U- 235. Liquid Scintillation: Incomplete chemical separation may generate <b>false</b> <b>positives</b> of virtually any Liquid Scintillation nuclide. High tritium content in Savannah River Site groundwater causes <b>false</b> <b>positives</b> of C- 14. Actinides produce <b>false</b> <b>positives</b> of Pm- 147. Most <b>false</b> <b>positives</b> in alpha spectroscopy and liquid scintillation counting at commercial labs are due to incomplete separation of the target nuclide from interferors. However, quality control measurements such as matrix spikes and chemical yield are of ten unable to identify cases where interfering nuclides break through into the final preparation. In addition, laboratory personnel often fail to manually interpret sample spectra, and thus do not notice peak interference when it occurs. In fact, some laboratories are unable to produce energy spectra for liquid scintillation or alpha spectroscopy, making recognition of peak interference virtually impossible. Gamma spectroscopy of environmental samples usually does not involve chemical separation, so peak interference may occur in every sample. Interference correction software appears to be ineffective at the concentrations seen in environmental samples. At all labs, careful manual review of printouts appeared to be lacking when the study was performed. Some labs have improved their data review processes since then...|$|R
40|$|Purpose: A {{large number}} of <b>false</b> <b>positives</b> (FPs) {{generated}} by computer-aided detection (CAD) schemes is likely to distract radiologists’ attention and decrease their interpretation efficiency. This study aims to develop projection-based features which characterize true and <b>false</b> <b>positives</b> to increase the specificity while maintaining high sensitivity in detecting colonic polyps...|$|R
