0|10000|Public
50|$|Gray {{codes are}} also used in {{labelling}} the axes of Karnaugh maps {{as well as in}} Händler circle <b>graphs,</b> <b>both</b> graphical methods <b>for</b> logic circuit minimization.|$|R
5000|$|One of the {{advantages}} of using Uniform Resource Identifier (URIs) is that they can be dereferenced using the HTTP protocol. According to the so-called Linked Open Data principles, such a dereferenced URI should result in a document that offers further data about the given URI. In this example, all URIs, <b>both</b> <b>for</b> <b>edges</b> and nodes (e.g. , , [...] ) can be dereferenced and will result in further RDF graphs, describing the URI, e.g. that Dresden is a city in Germany, or that a person, in the sense of that URI, can be fictional.|$|R
40|$|In {{this article}} we provide a formal {{framework}} for reidentification in general. We define n-confusion as a concept for modelling the anonymity of a database table and we prove that n-confusion is a generalization of k- anonymity. After a short survey on the different available definitions of k- anonymity for graphs we provide a new definition for k-anonymous graph, which we {{consider to be the}} correct definition. We provide a description of the k-anonymous <b>graphs,</b> <b>both</b> <b>for</b> the regular and the non-regular case. We also introduce the more flexible concept of (k,l) -anonymous graph. Our definition of (k,l) -anonymous graph is meant to replace a previous definition of (k, l) -anonymous graph, which we here prove to have severe weaknesses. Finally we provide a set of algorithms for k-anonymization of graphs...|$|R
40|$|The surface plasmon polaritons (SPP) of {{graphene}} {{reflect the}} microscopic spatial variations of underlying electronic structure and dynamics. Access to this information requires probing the full SPP response function. We image the graphene SPP phase and amplitude by combining scanning probe tip coupled surface plasmon interferometry with phase resolved near-field signal detection. We {{show that a}} simple analytical cavity model can self-consistently describe the phase and amplitude response <b>both</b> <b>for</b> <b>edge,</b> grain boundary, and defect SPP reflection and scattering. The derived complex SPP wavevector, damping, and carrier mobility agree with the results from more complex models. This phase information opens a new degree of freedom for spatial and spectral graphene SPP tuning and modulation for opto-electronics applications. Comment: 5 pages, 6 figure...|$|R
40|$|CDMA is {{technology}} for digital transmission of radio signal in telecommunication systems. In this technology, multiple users can transmit the data simultaneously in a channel using same frequency. Each user is assigned a distinguished code for transmission. There are different codes {{are used for}} this purpose. Here, PN sequence, Gold sequence and Walsh code are generated using Matlab Programming. Using Walsh code, the data was transmitted to receiver in AWGN and Fading channels. Here, transmitted data is generated randomly using matlab function. During transmission, SNR values of signal changes to calculate BER value to plot BER vs. SNR <b>graph</b> <b>for</b> <b>both</b> <b>for</b> single user and multi users in AWGN and Fading channel...|$|R
5000|$|According to 1881 census data, the {{majority}} of occupations within the parish were agricultural. The different occupations {{can be seen in}} the <b>graph</b> below <b>for</b> <b>both</b> females and males. Many female roles were classed as 'unspecified'.|$|R
5000|$|Chaitin's {{algorithm}} is a bottom-up, graph coloring register allocation algorithm that uses cost/degree as its spill metric. It {{is named after}} its designer, Gregory Chaitin. Chaitin's algorithm was the first register allocation algorithm that made use of coloring of the interference <b>graph</b> <b>for</b> <b>both</b> register allocations and spilling.|$|R
30|$|By {{performing}} the segment reallocation and intra-segment transformation, {{we get the}} the transformed histograms <b>for</b> <b>both</b> <b>edge</b> and non-edge images. The desired histogram is obtained by combining these two histograms {{which is used to}} perform histogram specification.|$|R
40|$|The {{serum protein}} {{electrophoresis}} in the cat: reference intervals and clinical interpretation*§ The zonal serum-electrophoresis (SPE) is a laboratory technique, used to separate with a specific support the serum proteins according to their size and electric net charge. In literature there are reduced information about feline reference intervals (RIs), <b>both</b> <b>for</b> agarose gel (AGE) or cellulose acetate (ACE). In this study 515 SPEs carried on serum sample of European common cats were evaluated, 291 carried out on ACE and 224 on AGE. Among all SPE carried out 179 (ACE, 105; AGE, 74) were selected based on the following criteria to establish the healthy group: Total Protein, Albumin and Globulin values in the normal RIs, regular aspect of their SPE run and densitometric <b>graph.</b> <b>Both</b> <b>for</b> ACE and AGE the following protein fractions were observed: Albumin, α 1, α 2, β 1, β 2 and γ globulins. Some sub-fractions were observed too such as α 2 A, α 2 B, γ 1 and γ 2 mostly in ACE. New RIs were calculated <b>both</b> <b>for</b> ACE and AGE and they were compared each other. For all protein fractions (except for Albumin and γ-globulins) statistically significant differences were observed between ACE and AGE (p< 0. 05). The AGE shows a better electrophoretic resolution. In 28 runs with hyper-γ-globulinemia (performed on AGE) several modifications were observed mostly polyclonal gammopathies. The SPE is a semi-quantitative technique to assess the different serum protein fractions and is useful to develop a proper diagnostic orientation...|$|R
40|$|Part 1 : Track A: Algorithms, Complexity and Models of ComputationInternational audienceIn {{this work}} we address a game theoretic {{variant of the}} {{shortest}} path problem, in which two decision makers (agents/players) move together {{along the edges of}} a graph from a given starting vertex to a given destination. The two players take turns in deciding in each vertex which edge to traverse next. The decider in each vertex also has to pay the cost of the chosen edge. We want to determine the path where each player minimizes its costs taking into account that also the other player acts in a selfish and rational way. Such a solution is a subgame perfect equilibrium and can be determined by backward induction in the game tree of the associated finite game in extensive form. We show that finding such a path is PSPACE-complete even <b>for</b> bipartite <b>graphs</b> <b>both</b> <b>for</b> the directed and the undirected version of the game. On the other hand, we can give polynomial time algorithms for directed acyclic graphs and for cactus graphs in the undirected case. The latter is based on a decomposition of the graph into components and their resolution by a number of fairly involved dynamic programming arrays...|$|R
40|$|In {{this article}} we provide a formal {{framework}} for reidentification in general. We define n-confusion as a concept for modeling the anonymity of a database table and we prove that n-confusion is a generalization of k-anonymity. After a short survey on the different available definitions of k-anonymity for graphs we provide a new definition for k-anonymous graph, which we {{consider to be the}} correct definition. We provide a description of the k-anonymous <b>graphs,</b> <b>both</b> <b>for</b> the regular and the non-regular case. We also introduce the more flexible concept of (k, l) -anonymous graph. Our definition of (k, l) -anonymous graph is meant to replace a previous definition of (k, l) -anonymous graph, which we here prove to have severe weaknesses. Finally, we provide a set of algorithms for k-anonymization of graphs. © 2012 Springer-Verlag. Partial support by the Spanish MEC projects ARES (CONSOLIDER INGENIO 2010 CSD 2007 - 00004), eAEGIS (TSI 2007 - 65406 -C 03 - 02), COPRIVACY (TIN 2011 - 27076 -C 03 - 03), and RIPUP (TIN 2009 - 11689) is acknowledged. One author is partially supported by the FPU grant (BOEs 17 / 11 / 2009 and 11 / 10 / 2010) and by the Government of Catalonia under grant 2009 SGR 1135 Peer Reviewe...|$|R
50|$|In {{computer}} science, {{control flow}} analysis (CFA) is a static code analysis technique {{for determining the}} control flow of a program. The control flow is expressed as a control flow <b>graph</b> (CFG). <b>For</b> <b>both</b> functional programming languages and object-oriented programming languages, the term CFA, and elaborations such as k-CFA, refer to specific algorithms that compute control flow.|$|R
40|$|In {{this work}} we address a game theoretic {{variant of the}} {{shortest}} path problem, in which two decision makers (players) move together {{along the edges of}} a graph from a given starting vertex to a given destination. The two players take turns in deciding in each vertex which edge to traverse next. The decider in each vertex also has to pay the cost of the chosen edge. We want to determine the path where each player minimizes its costs taking into account that also the other player acts in a selfish and rational way. Such a solution is a subgame perfect equilibrium and can be determined by backward induction in the game tree of the associated finite game in extensive form. We show that the decision problem associated with such a path is PSPACE-complete even <b>for</b> bipartite <b>graphs</b> <b>both</b> <b>for</b> the directed and the undirected version. The latter result is a surprising deviation from the complexity status of the closely related game Geography. On the other hand, we can give polynomial time algorithms for directed acyclic graphs and for cactus graphs even in the undirected case. The latter is based on a decomposition of the graph into components and their resolution by a number of fairly involved dynamic programming arrays. Finally, we give some arguments about closing the gap of the complexity status for graphs of bounded treewidth. Comment: Extended version contains the full description of the dynamic programming arrays in Section...|$|R
40|$|This book {{gives an}} {{elementary}} {{treatment of the}} basic material about <b>graph</b> spectra, <b>both</b> <b>for</b> ordinary, and Laplace and Seidel spectra. The text progresses systematically, by covering standard topics before presenting some new material on trees, strongly regular graphs, two-graphs, association schemes, p-ranks of configurations and similar topics. Exercises {{at the end of}} each chapter provide practice and vary from easy yet interesting applications of the treated theory, to little excursions into related topics. Tables, references at the end of the book, an author and subject index enrich the text. Spectra of Graphs is written for researchers, teachers and graduate students interested in graph spectra. The reader is assumed to be familiar with basic linear algebra and eigenvalues, although some more advanced topics in linear algebra, like the Perron-Frobenius theorem and eigenvalue interlacing are included...|$|R
40|$|Purpose – Usually {{the impact}} of {{research}} and researchers is quantified by using citation data: either by journal-centered citation data {{as in the case}} of the journal impact factor (JIF) or by author-centered citation data {{as in the case of}} the Hirsch- or h-index. This paper aims to discuss a range of impact measures, especially usage-based metrics, and to report the results of two surveys. Design/methodology/approach – The first part of the article analyzes both citation-based and usage-based metrics. The second part is based on the findings of the surveys: one in the form of a brainstorming session with information professionals and scientists at the OAI 6 conference in Geneva, the second in the form of expert interviews, mainly with scientists. Findings – The results of the surveys indicate an interest in the social aspects of science, like visualizations of social <b>graphs</b> <b>both</b> <b>for</b> persons and their publications. Furthermore, usage data are considered an appropriate measure to describe quality and coverage of scientific documents; admittedly, the consistence of usage information among repositories has to be kept in mind. The scientists who took part in the survey also asked for community services, assuming these might help to identify relevant scientific information more easily. Some of the other topics of interest were personalization or easy submission procedures. Originality/value – This paper delineates current discussions about citation-based and usage-based metrics. Based on the results of the surveys, it depicts which functionalities could enhance repositories, what features are required by scientists and information professionals, and whether usage-based services are considered valuable. These results also outline some elements of future repository research...|$|R
40|$|For the Erdos-Rényi random graph Gn,p, we {{consider}} {{the order of a}} largest vertex subset that induces a subgraph with average degree at most t. For the case when both p and t are fixed, this value is asymptotically almost surely concentrated on at most two explicitly given points. This generalises a result on the independence number of random <b>graphs.</b> <b>For</b> <b>both</b> the upper and lower bounds, we rely on large deviations inequalities for the binomial distribution. © 2011 Elsevier B. V...|$|R
40|$|In recent years, {{the field}} of Machine Learning is showing great {{interest}} towards the processing of structured data, such as sequences, trees and graphs. In this paper an unsupervised recursive learning schema for structured data clustering is introduced. The schema allows to process data organized in <b>graphs</b> <b>for</b> <b>both</b> graph-focused and node-focused applications. The approach uses the Fuzzy C-Means algorithm as building block. Some experiments are proposed to show its performances and to compare it with another approach known in literature...|$|R
5000|$|In the {{directed}} case, {{the greedy}} tour is at most (n − 1)-times longer than an optimal tour. This matches the lower bound of n − 1. An analogous competitive lower bound of Ω(n) also holds for randomized algorithms that know the coordinates of each node in a geometric embedding. If instead of visiting all nodes {{just a single}} [...] "treasure" [...] node has to be found, the competitive bounds are Θ(n²) on unit weight directed <b>graphs,</b> <b>for</b> <b>both</b> deterministic and randomized algorithms.|$|R
40|$|Testing a graph on 2 -vertex- and 2 -edge-connectivity are two {{fundamental}} algorithmic <b>graph</b> problems. <b>For</b> <b>both</b> problems, different linear-time algorithms with simple implementations are known. Here, an even simpler linear-time algorithm is presented that computes a structure from which both the 2 -vertex- and 2 -edge-connectivity of a graph {{can be easily}} "read off". The algorithm computes all bridges and cut vertices of the input graph in the same time...|$|R
30|$|Analysis of Granovetter’s Example A (Fig.  7) {{reveals that}} the local bridges (A,B) and (E,I) of Example A rank highest <b>for</b> <b>both</b> <b>edge</b> betweenness and Edge Gravity metrics, {{although}} the order is reversed (see Fig.  9). This illustrates that the structural importance derived from inclusion in shortest paths can {{be consistent with the}} structural importance derived from inclusion in all paths quantified by Edge Gravity.|$|R
40|$|AbstractThe {{problem of}} {{computing}} minimum distortion embeddings {{of a given}} graph into a line (path) was introduced in 2004 and has quickly attracted significant attention with subsequent results appearing at recent stoc and soda conferences. So far, all such results concern approximation algorithms or exponential-time exact algorithms. We give the first polynomial-time algorithms for computing minimum distortion embeddings of graphs into a path when the input graphs belong to specific graph classes. In particular, we solve this problem in polynomial time for bipartite permutation graphs and threshold <b>graphs.</b> <b>For</b> <b>both</b> <b>graph</b> classes, the distortion can be arbitrarily large. The graphs that we consider are unweighted...|$|R
40|$|Thomson Scattering (TS) is a {{powerful}} technique capable to measure electron temperature and electron density. For TS on the COMPASS tokamak, several possible systems were considered and relevant parameters were calculated <b>for</b> <b>both</b> <b>edge</b> and core plasma studies. To attain the expected values of electron density and temperature, two possibilities were chosen {{to be the most}} suitable: (i) Nd-YAG laser at the second harmonic frequency with Littrow spectrometers with ICCD cameras (<b>for</b> <b>both</b> core and <b>edge</b> systems), and (ii) Nd-YAG laser at the first harmonic frequency with Littrow spectrometer with CMOS camera (for the core) and spectral filters with APDs (<b>for</b> the <b>edge)</b> ...|$|R
40|$|Cycle bases {{belong to}} a k-connected simple <b>graph</b> used <b>both</b> <b>for</b> listing and {{enumerating}} Hamiltonian cycles contained in a planar graph. Planar cycle bases have a weighted induced graph whose weight values limited to 1. Hence making it was possible used in the Hamiltonian cycle enumeration procedures efficiently. In this paper a Hamiltonian cycle enumeration scheme is obtained through two stages. First, i cycles out of m bases cycles are determined using an appropriate constructed constraint. Secondly, to search all Hamiltonian cycles which are formed by the combination of i bases cycles obtained {{in the first stage}} efficiently. This efficiency achieved through a generation a class of objects as the representation of i cycle combinations among m bases cycles. The experiment conducted based on the proposed algorithm successfully generated and enumerated all the Hamiltonian cycles contained in a well-known example of planar graph...|$|R
40|$|We {{study the}} related questions: (i) when Feynman amplitudes in massless ϕ^ 4 theory {{evaluate}} to multiple zeta values, and (ii) when their underlying motives are mixed Tate. More generally, by considering configurations of singular hypersurfaces which fiber linearly over each other, we deduce sufficient geometric and combinatorial criteria on Feynman <b>graphs</b> <b>for</b> <b>both</b> (i) and (ii) to hold. These criteria hold for some infinite classes of graphs which essentially contain all cases previously known to physicists. Calabi-Yau varieties {{appear at the}} point where these criteria fail...|$|R
40|$|Purpose Usually {{impact of}} {{research}} and researchers is tried to be quantified by using citation data: Either by journal-centered citation data {{as in the case}} of the journal impact factor JIF or by author-centered citation data {{as in the case of}} the Hirsch- or h-index. The paper discusses a range of impact measures, especially usage based metrics. Furthermore the authors report the results of two surveys. The surveys focused on innovative features for open access repositories — with an emphasis on functionalities based on usage information. Design/methodology/approach The first part of the article analyzes both citation-based and usage-based metrics. The second part is based on the findings of the surveys: One in form of a brainstorming session with information professionals and scientists at the OAI 6 conference in Geneva, the second in form of expert interviews mainly with scientists. Findings The results of the surveys indicate an interest in the social aspects of science like visualizations of social <b>graphs</b> <b>both</b> <b>for</b> persons and their publications. Furthermore usage data is considered an appropriate measure to describe quality and coverage of scientific documents, admittedly the consistence of usage information among repository has to be kept in mind. The scientist that took part in the survey also asked for community services, assuming these might help to identify relevant scientific information more easily. Some of the other topics of interest were personalization or easy submission procedures. Originality/value This paper delineates current discussions about citation-based and usage-based metrics. Based on the results of the surveys it depicts which functionalities could enhance repositories, what features are required by scientists and information professionals and whether usage-based services are considered valuable. These results also outline some elements of future repository research...|$|R
40|$|The {{similarity}} {{solution of}} unsteady, incompressible MHD thermal boundary layer flow in natural convection {{has been investigated}} using group-theoretic transformations. Two parameter group transformations is applied for simultaneous elimination {{of more than one}} independent variable. Consequently the system of governing highly non-linear partial differential equations with auxiliary conditions reduces to a non-linear ordinary differential equation with appropriate auxiliary conditions. Effects of all emerging physical parameters are demonstrated with the help of <b>graphs</b> <b>for</b> <b>both</b> velocity and temperature distribution. The numerical solution is derived systematically in dimensionless form as a...|$|R
30|$|Here, C (e_ij^k) {{denotes the}} set of all copies of e_ij^k (cf. Item 8), P_i,j is {{the set of}} all {{parallel}} edges directed from vertex i to vertex j, and x_ij^k is the decision variable corresponding to edge e_ij^k. Note that constraints (2 c) and (2 d) arise directly from {{the description of the}} AG (cf. Items 8, and 10). Item 11 is accounted for by constraints (2 e) and (2 f), which <b>both</b> account <b>for</b> parallel <b>edges.</b>|$|R
40|$|The {{branch-and-bound}} {{algorithm is}} stated in generality, {{and illustrated by}} two applications, unidirectional graph search, and reducing a sparse matrix to its minimal band form. The algorithm is then generalised to multiple partitions, applied to bidirectional <b>graph</b> searching <b>for</b> <b>both</b> heuristic and non-heuristic searches, and further extended to graph searches and problem solving with subgoals. 1. 0 Introduction and Summary The branch-and-bound algorithm is a simple technique for the optimisation search for the minimum (or maximum) o...|$|R
40|$|Proceedings of Graph Theory@Georgia Tech, {{a conference}} honoring the 50 th Birthday of Robin Thomas, May 7 - 11, 2012 in the Clough Undergraduate Learning Commons. We {{determine}} the asymptotics logorithmic density of subgraphs of large geometric graphs and of some large sparse graphs (from a nowhere dense class). This also {{leads to a}} unified approach to <b>graph</b> limits <b>for</b> <b>both</b> sparse and dense classes. Joint work with Patrice Ossona de Mendez, Paris. NSF, NSA, ONR, IMA, Colleges of Sciences, Computing and Engineerin...|$|R
40|$|Let G be {{a simple}} graph and L = L(G) the Laplacian matrix of G. G is called L-integral if all its Laplacian {{eigenvalues}} are integer numbers. It is known that every cograph, a graph free of P 4, is L-integral. The class of P 4 -sparse graphs and the class of P 4 -extendible graphs contain the cographs. It seems natural to investigate if the graphs in these classes are still L-integral. In this paper we characterized the L-integral <b>graphs</b> <b>for</b> <b>both</b> cases, P 4 -sparse graphs and P 4 -extendible graphs. Comment: 10 pages, 6 figure...|$|R
40|$|AbstractFor the Erdős–Rényi random graph Gn,p, we give {{a precise}} {{asymptotic}} formula {{for the size}} αˆt(Gn,p) of a largest vertex subset in Gn,p that induces a subgraph with average degree at most t, provided that p=p(n) is not too small and t=t(n) is not too large. In the case of fixed t and p, we find that this value is asymptotically almost surely concentrated on at most two explicitly given points. This generalises a result on the independence number of random <b>graphs.</b> <b>For</b> <b>both</b> {{the upper and lower}} bounds, we rely on large deviations inequalities for the binomial distribution...|$|R
40|$|The first R {{package to}} work with GEXF graph files (used in Gephi and others). Using XML li-brary, it allows the user to easily build/read graph files {{including}} attributes, GEXF viz at-tributes (such as colour, size, and position), network dynamics (<b>for</b> <b>both</b> <b>edges</b> and nodes, includ-ing spells) and edges weighting. Users can build/handle graphs element-by-element or mas-sively through data-frames, visualize the graph on a web browser through sigmajs javascript li-brary and interact with the igraph package...|$|R
40|$|We study {{a series}} of topics {{involving}} approximation algorithms {{and the presence of}} uncertain data in optimization. On the first theme of approximation, we derive performance bounds for rollout algorithms. Interpreted as an approximate dynamic programming algorithm, a rollout algorithm estimates the value-to-go at each decision stage by simulating future events while following a heuristic policy, referred to as the base policy. We provide a probabilistic analysis of knapsack problems, proving that rollout algorithms perform significantly better than their base policies. Next, we study the average performance of greedy algorithms for online matching on random graphs. In online matching problems, vertices arrive sequentially and reveal their neighboring edges. Vertices may be matched upon arrival and matches are irrevocable. We determine asymptotic matching sizes obtained by a variety of greedy algorithms on random <b>graphs,</b> <b>both</b> <b>for</b> bipartite and non-bipartite graphs. Moving to the second theme of uncertainty, we analyze losses resulting from uncertain transition probabilities in Markov decision processes. We assume that policies are computed using exact dynamic programming with estimated transition probabilities, but the system evolves according to dierent, true transition probabilities. Given a bound on the total variation error of estimated transition probability distributions, we derive a general tight upper bound on the loss of expected total reward. Finally, we consider a randomized model for minmax regret in combinatorial optimization under cost uncertainty. This problem {{can be viewed as a}} zero-sum game played between an optimizing player and an adversary, where the optimizing player selects a solution and the adversary selects costs with the intention of maximizing the regret of the player. We analyze a model where the optimizing player selects a probability distribution over solutions and the adversary selects costs with knowledge of the player's distribution. We show that under this randomized model, the minmax regret version of any polynomial solvable combinatorial problem is polynomial solvable, <b>both</b> <b>for</b> interval and discrete scenario representations of uncertainty. by Dana Andrew Mastin. Thesis: Ph. D., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2015. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Cataloged from student-submitted PDF version of thesis. Includes bibliographical references (pages 249 - 260) ...|$|R
40|$|A finite {{abstract}} {{simplicial complex}} G defines two finite simple graphs: the Barycentric refinement G 1, connecting two simplices {{if one is}} {{a subset of the}} other and the connection graph G', connecting two simplices if they intersect. We prove that the Poincare-Hopf value i(x) = 1 -X(S(x)), where X is Euler characteristics and S(x) is the unit sphere of a vertex x in G 1, agrees with the Green function value g(x,x),the diagonal element of the inverse of (1 +A'), where A' is the adjacency matrix of G'. By unimodularity, det(1 +A') is the product of parities (- 1) ^dim(x) of simplices in G, the Fredholm matrix 1 +A' is in GL(n,Z), where n is the number of simplices in G. We show that the set of possible unit sphere topologies in G 1 is a combinatorial invariant of the complex G. So, also the Green function range of G is a combinatorial invariant. To prove the invariance of the unit sphere topology we use that all unit spheres in G 1 decompose as a join of a stable and unstable part. The join operation + renders the category X of simplicial complexes into a monoid, where the empty complex is the 0 element and the cone construction adds 1. The augmented Grothendieck group (X,+, 0) contains the graph and sphere monoids (Graphs, +, 0) and (Spheres,+, 0). The Poincare-Hopf functionals i(G) as well as the volume are multiplicative functions on (X,+). For the sphere group, both i(G) as well as Fredholm characteristic are characters. The join + can be augmented with a product * so that we have a commutative ring (X,+, 0,*, 1) for which there are both additive and multiplicative primes and which contains as a subring of signed complete complexes isomorphic to the integers (Z,+, 0,*, 1). We also look at the spectrum of the Laplacian of the join of two <b>graphs.</b> <b>Both</b> <b>for</b> addition + and multiplication *, one can ask whether unique prime factorization holds. Comment: 39 pages, 10 figure...|$|R
40|$|A cycle {{cover of}} a graph {{is a set of}} cycles such that every vertex is part of exactly one cycle. An L-cycle cover is a cycle cover in which the length of every cycle is in the set L ⊆ N. For most sets L, the problem of {{computing}} L-cycle covers of maximum weight is NP-hard and APX-hard. We devise polynomial-time approximation algorithms for L-cycle covers. More precisely, we present a factor 2 approximation algorithm for computing L-cycle covers of maximum weight in undirected graphs and a factor 20 / 7 approximation algorithm for the same problem in directed <b>graphs.</b> <b>Both</b> algorithms work <b>for</b> arbitrary sets L. To do this, we develop a general decomposition technique for cycle covers. Finally, we show tight lower bounds for the approximation ratios achievable by algorithms based on such decomposition techniques...|$|R
40|$|An {{analytical}} {{closed-form solution}} to the transformed equation that must be solved for the thickness problem in thin-airfoil theory is obtained by expanding the airfoil thickness function in a trigonometric series. Contrary to implications of previous studies, it is shown that the thickness function will contain cosine terms whenever a sharp edge is present and sine terms whenever a rounded edge is involved. Conditions that the constants An and Bm must satisfy the following conditions. For airfoils closed at <b>both</b> ends, <b>for</b> rounded <b>edges,</b> and <b>for</b> sharp <b>edges.</b> Expressions <b>for</b> the thickness functions, thickness/chord ratios, and leading-edge radii of elliptic, Joukowski, and biconvex airfoils are tabulated. The biconvex airfoil {{is found to be}} represented by cosine term...|$|R
