1988|74|Public
5|$|The composited camera {{negative}} of Citizen Kane {{was destroyed}} in a New Jersey film laboratory fire in the 1970s. Subsequent prints were derived from a master positive (a <b>fine-grain</b> preservation element) made in the 1940s and originally intended for use in overseas distribution. Modern techniques were used to produce a pristine print for a 50th Anniversary theatrical reissue in 1991 which Paramount released for then-owner Turner Broadcasting System, which earned $1.6 million in North America.|$|E
5|$|The Texas Chain Saw Massacre {{was mainly}} shot using an Eclair NPR 16mm camera with <b>fine-grain,</b> {{low-speed}} film that required {{four times more}} light than modern digital cameras. Most of the filming {{took place in the}} farmhouse, which was filled with furniture constructed from animal bones and a latex material used as upholstery to give the appearance of human skin. The house was not cooled, and there was little ventilation. The crew covered its walls with drops of animal blood obtained from a local slaughterhouse. Art director Robert A. Burns drove around the countryside and collected the remains of cattle and other animals in various stages of decomposition, with which he littered the floors of the house.|$|E
5|$|In 2013, {{the video}} {{distribution}} company The Criterion Collection, {{in collaboration with}} the Academy of Motion Picture Arts and Sciences’ Film Archive, began the restoration of the original negatives of the Apu trilogy, including Pather Panchali. These negatives had been severely damaged by a fire in London in 1993, and all film cans and fragments belonging to the Ray films were sent to the Motion Picture Academy for storage, where they lay unseen for two decades. It was discovered upon reexamination that, although many parts of the films were indeed destroyed by fire or the effects of age, other parts were salvageable. The materials were shipped to a restoration laboratory in Bologna, Italy: L’Immagine Ritrovata. Over a thousand hours of labor by hand were expended in restoring and scanning the negatives and, in the end, about 40 percent of the Pather Panchali negative was restored. (For those parts of the negative that were missing or unusable, duplicate negatives and <b>fine-grain</b> masters from various commercial or archival sources were used.) The Criterion Collection’s own lab then spent six months creating the digital version of all three films, at times choosing to preserve the distinctive look of the films even at the cost of retaining some imperfections.|$|E
40|$|Benchmarks, {{input data}} and {{compiler}} source code {{to implement the}} Lynx queue from the paper 'Lynx: Using OS and Hardware Support for Fast <b>Fine-Grained</b> Inter-Core Communication'This research data supports “Lynx: Using OS and Hardware Support for Fast <b>Fine-Grained</b> Inter-Core Communication” which {{will be published in}} “International Conference on Supercomputing”. This work was supported by the EPSRC [grant number EP/K 026399 / 1]...|$|R
40|$|A new {{complexity}} measure {{named as}} Lattice Complexity is presented for finite symbolic sequences. This measure {{is based on}} the symbolic dynamics of one-dimensional iterative maps and Lempel-Ziv Complexity. To make Lattice Complexity distinguishable from Lempel-Ziv Complexity, an approach called <b>fine-graining</b> process is also proposed. When the control parameter <b>fine-graining</b> order is small enough, the two measures are almost equal. While the order increases, {{the difference between the two}} measures becomes more and more significant. Applying Lattice Complexity to logistic map with a proper order, we find that the sequences that are regarded as complex are roughly at the edges of chaotic regions. Further derived properties of the two measures concerning the <b>fine-graining</b> process are also discussed. Comment: 16 page, 8 figures,a revised English version of a article published in Chines...|$|R
3000|$|<b>Fine-Grained</b> Access Control The {{data owner}} is {{permitted}} to impose an access policy on each file to be uploaded that precisely entitles the set of data users allowed to access. The public cloud is also prohibited from learning the plaintexts of data files.|$|R
25|$|The {{balls are}} then hard ground. They are {{ground in the}} same type of machine as used before, but either an {{abrasive}} is introduced into coolant or the rotating plate is replaced with a very hard <b>fine-grain</b> grinding wheel. This step can get the balls within ±. If the balls need more precision then they are lapped, again in {{the same type of}} machine. However, this time the rill plates are made of a softer material, usually cast iron, less pressure is applied, the plate is rotated slowly. This step is what gives bearing balls their shiny appearance and can bring the balls between grades 10 and 48.|$|E
2500|$|Neuroinformatics is a {{research}} field concerned with the organization of neuroscience data by the application of computational models and analytical tools. These areas of research are important for the integration and analysis of increasingly large-volume, high-dimensional, and <b>fine-grain</b> experimental data. [...] Neuroinformaticians provide computational tools, mathematical models, and create interoperable databases for clinicians and research scientists. Neuroscience is a heterogeneous field, consisting of many and various sub-disciplines (e.g., cognitive psychology, behavioral neuroscience, and behavioral genetics). In order for {{our understanding of the}} brain to continue to deepen, it is necessary that these sub-disciplines are able to share data and findings in a meaningful way; Neuroinformaticians facilitate this.|$|E
2500|$|Fires on the Plain was {{released}} November 3, 1959 in Japan. It was later released on June 6, 2000 by [...] Homevision. Then it {{was released}} {{as part of the}} Criterion Collection on March 13, 2007. The disc includes a video interview with Kon Ichikawa and Mickey Curtis. Also included is a video introduction with Japanese film scholar Donald Richie and a booklet with an essay on Fires on the Plain by Chuck Stephens. The film was digitally restored from a Spirit DataCine 35mm composite <b>fine-grain</b> master positive print. The sound was restored from a 35mm optical soundtrack. It was co-released by the Criterion Collection with another Ichikawa film, The Burmese Harp.|$|E
50|$|Of Cretaceous age, Aquia Creek {{sandstone}} {{is composed}} of rounded, coarse- to <b>fine-grains</b> of quartz, cemented with silica and containing scattered pellets of clay as large as an inch in diameter. This sandstone is typically gray or tan, sometimes with streaks or shades of red, yellow or buff, giving the stone a warm effect.|$|R
30|$|In {{subgroup}} B 1, amphibole lamella type garnet, monomineralic prisms and tablets of amphibole {{occur as}} coarse-grains (80 [*]×[*] 20  μm on average) and <b>fine-grains</b> (20 [*]×[*] 10  μm on average), respectively. Long and short multiphase needles/blades (ca. 350 [*]×[*] 15 and 25 [*]×[*] 10  μm, respectively) {{are composed of}} amphibole with rutile, ilmenite, srilankite, and apatite.|$|R
40|$|The sum of entropic {{uncertainties}} for {{the measurement}} of two non-commuting observables is not always reduced {{by the amount of}} entanglement (quantum memory) between two parties, and in certain cases may be impacted by quantum correlations beyond entanglement (discord). An optimal lower bound of entropic uncertainty in the presence of any correlations may be determined by <b>fine-graining.</b> Here we express the uncertainty relation in a new form where the maximum possible reduction of uncertainty is shown to be given by the extractable classical information. We show that the lower bound of uncertainty matches with that using <b>fine-graining</b> for several examples of two-qubit pure and mixed entangled states, and also separable states with non-vanishing discord. Using our uncertainty relation we further show that {{even in the absence of}} any quantum correlations between the two parties, the sum of uncertainties may be reduced with the help of classical correlations. Comment: 12 pages, 2 figures, accepted for publication in Quantum Information Processin...|$|R
5000|$|... {{enhanced}} {{support for}} synchronization for <b>fine-grain</b> control over program execution.|$|E
50|$|Active {{collection}} systems capture entire {{lineage of}} the data flow at run time. The kind of lineage they capture may be coarse-grain or <b>fine-grain,</b> but they donot require any further computations on the data flow after its execution. Active <b>fine-grain</b> lineage collection systems incur higher capture overheads than lazy collection systems. However, they enable sophisticated replay and debugging.|$|E
5000|$|University of British Columbia (MPICH2/SCTP, and <b>Fine-Grain</b> MPI (FG-MPI) {{which adds}} support for coroutines) ...|$|E
40|$|The {{objective}} {{for this}} portion of the research involved conducting field studies and laboratory investigations to develop and refine models for mud-rich submarine fan architectures used by seismic analysis and reservoir engineers. These research aspects have been presented in two papers as follows: (1) Bouma, A. H., {open_quotes}Review of <b>Fine-Grained</b> Submarine Fans and Turbidite Systems{close_quotes}; (2) Kirkova, J. T. and Lorenzo, J. M., {open_quotes}Synthetic Seismic Modeling of Measured Submarine Fans Sections, Case Study of the Tanqua Complex, Karoo, South Africa{close_quotes} The {open_quotes}Review of <b>Fine-Grained</b> Submarine Fans and Turbidite Systems{close_quotes} by Arnold Bouma discusses research targeted toward stimulating an increase in oil and gas recovery by developing new and improved geological understanding. The {open_quotes}Synthetic Seismic Modeling of Measured Submarine Fan Sections, Case Study of the Tanqua Complex, Karoo, South Africa{close_quotes} by J. T. Kirkova and J. M. Lorenso discusses the limitations of verticle resolution and how this affects the interpretation and characterization of submarine fan complexes...|$|R
40|$|Is the {{dynamical}} {{evolution of}} physical systems objectively {{a manifestation of}} information processing by the universe? We find that an affirmative answer has important consequences for the measurement problem. In particular, we calculate the amount of quantum information processing involved {{in the evolution of}} physical systems, assuming a finite degree of <b>fine-graining</b> of Hilbert space. This assumption is shown to imply that there is a finite capacity to sustain the immense entanglement that measurement entails. When this capacity is overwhelmed, the system's unitary evolution becomes computationally unstable and the system suffers an information transition (`collapse'). Classical behaviour arises from the rapid cycles of unitary evolution and information transitions. Thus, the <b>fine-graining</b> of Hilbert space determines the location of the `Heisenberg cut', the mesoscopic threshold separating the microscopic, quantum system from the macroscopic, classical environment. The model {{can be viewed as a}} probablistic complement to decoherence, that completes the measurement process by turning decohered improper mixtures of states into proper mixtures. It is shown to provide a natural resolution to the measurement problem and the basis problem. Comment: 24 pages; REVTeX 4; published versio...|$|R
40|$|Restricted Access. Is the {{dynamical}} {{evolution of}} physical systems objectively {{a manifestation of}} information processing by the universe? We find that an affirmative answer has important consequences for the measurement problem. In particular, we calculate the amount of quantum information processing involved {{in the evolution of}} physical systems, assuming a finite degree of <b>fine-graining</b> of Hilbert space. This assumption is shown to imply that there is a finite capacity to sustain the immense entanglement that measurement entails. When this capacity is overwhelmed, the system's unitary evolution becomes computationally unstable and the system suffers an information transition (ldquocollapserdquo). Classical behavior arises from the rapid cycles of unitary evolution and information transition. Thus, the <b>fine-graining</b> of Hilbert space determines the location of the ldquoHeisenberg cutrdquo, the mesoscopic threshold separating the microscopic, quantum system from the macroscopic, classical environment. The model {{can be viewed as a}} probablistic complement to decoherence, that completes the measurement process by turning decohered improper mixtures of states into proper mixtures. It is shown to provide a natural resolution to the measurement problem and the basis problem...|$|R
50|$|The {{requirements}} for a <b>fine-grain</b> parallelism language are better {{met with a}} dataflow language than a systems language.|$|E
50|$|Lazy lineage {{collection}} typically captures only coarse-grain lineage at run time. These systems incur low capture overheads due to {{the small}} amount of lineage they capture. However, to answer <b>fine-grain</b> tracing queries, they must replay the data flow on all (or a large part) of its input and collect <b>fine-grain</b> lineage during the replay. This approach is suitable for forensic systems, where a user wants to debug an observed bad output.|$|E
5000|$|Google Summer of Code'2009 {{extensions}} {{to enable}} <b>fine-grain</b> program optimizations including polyhedral transformations, function level run-time adaptation and collective optimization ...|$|E
40|$|<b>Fine-Grained</b> Visual Categorization (FGVC) has {{achieved}} significant progress recently. However, {{the number of}} fine-grained species could be huge and dynamically increasing in real scenarios, {{making it difficult to}} recognize unseen objects under the current FGVC framework. This raises an open issue to perform large-scale fine-grained identification without a complete training set. Aiming to conquer this issue, we propose a retrieval task named One-Shot <b>Fine-Grained</b> Instance Retrieval (OSFGIR). "One-Shot" denotes the ability of identifying unseen objects through a fine-grained retrieval task assisted with an incomplete auxiliary training set. This paper first presents the detailed description to OSFGIR task and our collected OSFGIR- 378 K dataset. Next, we propose the Convolutional and Normalization Networks (CN-Nets) learned on the auxiliary dataset to generate a concise and discriminative representation. Finally, we present a coarse-to-fine retrieval framework consisting of three components, i. e., coarse retrieval, fine-grained retrieval, and query expansion, respectively. The framework progressively retrieves images with similar semantics, and performs fine-grained identification. Experiments show our OSFGIR framework achieves significantly better accuracy and efficiency than existing FGVC and image retrieval methods, thus could be a better solution for large-scale fine-grained object identification. Comment: Accepted by MM 2017, 9 pages, 7 figure...|$|R
40|$|Graduation date: 2015 The {{communication}} in MLS cross-domain environments faces many challenges. The {{three most important}} challenges are efficient key management, privacy preserving and covert channel. We propose an Efficient, Secure and Covert Channel Capacity Bounded Protocol which has three algorithms that addresses these challenges: The Efficient Attribute-based <b>Fine-Grained</b> Authentication (EAFA) algorithm, Anonymous Authentication (A 2) algorithm and Limiting Covert Channel Capacity (LC 3) algorithm. We implemented a prototype of the ESC 3 B protocol and measured the performance and efficiency of the system...|$|R
5000|$|Mesos {{was first}} {{presented}} in 2009 (while still named Nexus) by Andy Konwinski at HotCloud '09 in a talk accompanying the first paper published about the project. Later in 2011 it {{was presented in}} a more mature state in a talk by Zaharia at the Usenix Symposium on Networked Systems Design and Implementation conference about the paper [...] "Mesos: A Platform for <b>Fine-Grained</b> Resource Sharing in the Data Center" [...] by Benjamin Hindman, Andy Konwinski, Zaharia, Ali Ghodsi, Anthony D. Joseph, Randy Katz, Scott Shenker, Ion Stoica.|$|R
50|$|Connection Machine (CM-2) and J-Machine are {{examples}} of <b>fine-grain</b> parallel computers that have grain size {{in the range of}} 4-5 μs.|$|E
50|$|Substituting orzo, rice, Israeli {{couscous}} or barley for <b>fine-grain</b> couscous is not acceptable. In some regions, a medium-grain couscous {{is seldom}} used.|$|E
50|$|Phonolite is an {{uncommon}} volcanic rock, of intermediate chemical composition between felsic and mafic, with texture ranging from aphanitic (<b>fine-grain)</b> to porphyritic (mixed fine- and coarse-grain).|$|E
40|$|Due to {{oxidizability}} {{of copper}} coating on carbon nanotubes, the interfacial bond strength between copper coating and its matrix is weak, {{which leads to}} the reduction of the macroscopic properties of copper matrix composite. The electroless coating technics was applied to prepare nickel-copper bilayers coated on single-walled carbon nanotubes. The coated single-walled carbon nanotubes were characterized through transmission electron microscope spectroscopy, field-emission electron microscope spectroscopy, X-ray diffractometry, and thermogravimetric analysis. The results demonstrated that the nickel-copper bilayers coated on single-walled carbon nanotubes possessed higher purity of unoxidized copper <b>fine-grains</b> than copper monolayers...|$|R
40|$|In this paper, {{we propose}} a multi-agent {{approach}} for solving {{a class of}} optimization problems involving expensive resources, where monolithic local search schemes perform miserably. More specifically, we study the class of bin-packing problems. Under our proposed <b>Fine-Grained</b> Agent System scheme, rational agents work both collaboratively and selfishly based on local search and mimic physics-motivated systems. We apply our approach to a generalization of bin-packing - the Inventory Routing Problem with Time Windows - which is an important logistics problem, and demonstrate the efficiency and effectiveness of our approach...|$|R
40|$|Abstract – Robust {{streaming}} {{of video}} over the IEEE 802. 11 Wireless LANs (WLANs) poses many challenges, including coping with bandwidth variations and data losses. To address these challenges, we evaluate and compare various error control strategies in this paper, namely, Medium Access Control (MAC) layer Forward Error Correction (FEC), MAC retransmission, and application-layer FEC, combined with FGS {{scalable video coding}} to achieve reliable communication over the IEEE 802. 11 WLANs. Moreover, we assess the performance of <b>Fine-Grained</b> Loss Protection (FGLP) for different multipath channel conditions. Furthermore, the performance of cross-layer strategies such as application-layer FEC with MAC retransmissions are also determined. 1...|$|R
50|$|SISAL saw a brief {{resurgence}} in 2010 {{when a group}} of undergraduates at Worcester Polytechnic Institute investigated implementing a <b>fine-grain</b> parallelism backend for the SISAL language.|$|E
50|$|An {{additional}} dedicated 20 GB/s {{bus that}} bypasses L1 and L2 GPU cache for direct system memory access, reducing synchronisation challenges when performing <b>fine-grain</b> GPGPU compute tasks.|$|E
50|$|Rodinal {{is not a}} <b>fine-grain</b> developer, and is best {{used with}} film of low and medium sensitivity, with {{inherently}} finer grain than high-speed films, or with larger film sizes.|$|E
40|$|Zagami {{contains}} lithologic heterogeneity {{suggesting that}} it did not form in a homogeneous, thick lava flow [1]. We have previously investigated the Sr and Nd isotopic systematics of Coarse-Grained (CG) and <b>Fine-Grained</b> (FG) lithologies described by [2]. Both appear to belong to Normal Zagami (NZ) [1, 3], but their initial Sr-isotopic compositions differ [4, 5]. Here we report new analyses of the Dark Mottled Lithology (DML, [3]) that show its age and initial Sr and Nd isotopic compositions to be identical within error limits with those of CG, but Sr initial isotopic compositions differ from those of FG...|$|R
40|$|We {{determine}} which translationally invariant matrix product {{states have a}} continuum limit, that is, which {{can be considered as}} discretized versions of states defined in the continuum. To do this, we analyse a <b>fine-graining</b> renormalization procedure in real space, characterise the set of limiting states of its flow, and find that it strictly contains the set of continuous matrix product states. We also analyse which states have a continuum limit after a finite number of a coarse-graining renormalization steps. We give several examples of states with and without the different kinds of continuum limits. Comment: 6 pages, 2 figure...|$|R
40|$|For a toy {{version of}} a quantum system with a {{conscious}} observer, it is demonstrated that the many-worlds problem is solved by retreating into the conscious subspace of an entire observer history. In every step of a discretised time, the observer tries to "see" records of his past and present in a coherent temporal sequence, by scanning through a temporal <b>fine-graining</b> cascade. The extreme most likely occurs {{at the end of}} some branch, thus determining observer's world line. The relevant neurons, each with two dimensions, are power-law distributed in number, so order statistics implies that conscious dimension is located almost entirely in the extremal branch. Comment: 22 pages, no figure...|$|R
