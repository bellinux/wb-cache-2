0|1323|Public
40|$|It is {{the aim of}} the CULTOS {{project to}} provide {{researchers}} in intertextual studies with a collaborative multimedia platform for the authoring, management, search, exchange, and presentation of Intertextual Threads (ITTs), knowledge structures that interrelate and compare cultural artefacts. By means of the CULTOS platform, researchers will be able to create a world-wide collection of multimedia-enhanced ITTs comparing cultural artefacts from different personal and cultural backgrounds. This constitutes a valuable contribution for comparative studies and cultural heritage. In this paper, we propose and formally define Enhanced Multimedia Meta Objects (Emmos) as a new means for representing multimedia content. Emmos are unique in that they combine three different aspects of multimedia content: the <b>individual</b> <b>media</b> <b>objects</b> making up the content, semantic relationships between those <b>media</b> <b>objects,</b> and functionality on the content. With Emmos, we obtain an adequate means for the representation of multimedia-enriched ITTs as the foundation for the worldwide distributed collection of ITTs envisioned by CULTOS. 1...|$|R
40|$|There is an {{increasing}} demand for high-quality interactive applications which combine complex application logic with a sophisticated user interface, making use of <b>individual</b> <b>media</b> <b>objects</b> like graphics, animations, 3 D graphics, audio or video. Their development is still challenging as it requires the integration of software design, user interface design, and media design. This chapter presents a model-driven development approach which integrates these aspects. Its basis is the Multimedia Modeling Language (MML), which integrates existing modeling concepts for interactive applications and adds support for multimedia. As we show, advanced multimedia integration requires new modeling concepts not supported by existing languages yet. MML models can be transformed into code skeletons for multiple target platforms. Moreover, we support the integration of existing professional multimedia authoring tools into the development process by generating code skeletons which can be directly processed in authoring tools. In this way the advantages of both – systematic model-driven development and support for creative visual design – are combined...|$|R
50|$|The Board became {{involved}} in the Oliver Finegold affair when the Mayor of London, Ken Livingstone made comments to a Jewish reporter, Oliver Finegold, comparing him or the newspaper he worked for, to a concentration camp guard. Many <b>individuals</b> and <b>media</b> commentators <b>objected</b> to the remark. Along with the Commission for Racial Equality, the Board filed a complaint to the Standards Board for England, calling for the Mayor to apologise to the reporter. The Mayor made a statement condemning the Holocaust, but stood by his remarks to the journalist, mentioning in passing his belief that the Board of Jewish Deputies only represents a small section of the Jewish community.|$|R
40|$|This {{dissertation}} examines {{new media}} by taking as its starting point the definition offered by Lev Manovich, "the shift of all culture to computer culture" [...] new media are new {{not so much}} because they have not existed before but because they must adhere to the conventions of a computer. Media, according to Manovich, become programmable, and in their new programmability, along with a host of other implications and repercussions of that programmability, we human beings experience something new. Articulating that something remains no easy chore, and Manovich continually makes his case that "the language of new media" much resembles the language of that older medium, cinema. However, to nod in agreement with Manovich is not the present task; instead, I take Manovich and place his notion of new media in direct dialogue with rhetorical theorists Aristotle, Plato, Kenneth Burke, Barry Brummett, Jeffery Walker, Michel Foucault, and other writers and thinkers in order to pursue a portion of that "shift of all culture": I ask, "If new media has a language, what is the poetics of that language?" In order to pursue an answer to this question, I take <b>individual</b> new <b>media</b> <b>objects</b> [...] the film Saving Private Ryan; the video game Medal of Honor: Frontline; the computer worm MyDoom; the media coverage of the 1996 presidential campaign trail, including the "Dean Scream"; the SanDisk's cooperation with the Alzheimer's Association's "Take Action against Alzheimer's" campaign; the film The Manchurian Candidate; and the modern database [...] and analyze how they make meaning. In order to do this, I frequently reach back into antiquity, specifically into the early and predisciplinary areas of philosophy, rhetoric, and poetics...|$|R
40|$|We {{develop a}} theory of <b>media</b> <b>objects,</b> and present optimal {{algorithms}} for collaborative object synthesis for constructing multimedia documents by composing together a given set of <b>media</b> <b>objects.</b> We then extend the algorithms to incorporate quality constraints (such as image size) as well as distribution across multiple nodes. The theoretical model is validated by an experimental implementation that supports the theoretical results. 1 Introduction Collaborative multimedia systems consist of collaborators constructing and manipulating various kinds of <b>media</b> <b>objects,</b> such as video-clips, pictures, text files, or perhaps some complex entity constructed out of these simpler entities. In this paper, we develop {{a theory of}} <b>media</b> <b>objects,</b> and present optimal algorithms for collaborative <b>object</b> synthesis. 2 <b>Media</b> <b>Objects</b> We classify all media-objects into three types: 1. Static: Intuitively, a static <b>media</b> <b>object</b> is an object that does not change when it is presented. Examples of static media- [...] ...|$|R
40|$|Abstract. This paper {{proposes a}} novel {{business}} model to support media content personalisation: an agent-based business-to-business (B 2 B) brokerage platform for media content producer and distributor businesses. Distributors aim to pro-vide viewers with a personalised content experience and producers wish to en-sure that their <b>media</b> <b>objects</b> are watched {{by as many}} targeted viewers as possi-ble. In this scenario viewers and <b>media</b> <b>objects</b> (main programmes and candi-date objects for insertion) have profiles and, {{in the case of}} main programme ob-jects, are annotated with placeholders representing personalisation opportuni-ties, i. e., locations for insertion of personalised <b>media</b> <b>objects.</b> The MultiMedia Brokerage (MMB) platform is a multiagent multilayered brokerage composed by agents that act as sellers and buyers of viewer stream timeslots and/or <b>media</b> <b>objects</b> on behalf of the registered businesses. These agents engage in negotia-tions to select the <b>media</b> <b>objects</b> that best match the current programme and viewer profiles...|$|R
40|$|In this paper, we {{consider}} the problem of multimedia document (MMD) semantics understanding and content-based cross-media retrieval. An MMD {{is a set of}} <b>media</b> <b>objects</b> of different modalities but carrying the same semantics and the content-based cross-media retrieval is a new kind of retrieval method by which the query examples and search results can be of different modalities. Two levels of manifolds are learned to explore the relationships among all the data in the level of MMD and in the level of <b>media</b> <b>object</b> respectively. We first construct a Laplacian <b>media</b> <b>object</b> space for <b>media</b> <b>object</b> representation of each modality and an MMD semantic graph to learn the MMD semantic correlations. The characteristics of <b>media</b> <b>objects</b> propagate along the MMD semantic graph and an MMD semantic space is constructed to perform cross-media retrieval. Different methods are proposed to utilize relevance feedback and experiment shows that the proposed approaches are effective...|$|R
40|$|This paper {{proposes a}} novel {{business}} model to support media content personalisation: an agent-based business-to-business (B 2 B) brokerage platform for media content producer and distributor businesses. Distributors aim to provide viewers with a personalised content experience and producers wish to en-sure that their <b>media</b> <b>objects</b> are watched {{by as many}} targeted viewers as possible. In this scenario viewers and <b>media</b> <b>objects</b> (main programmes and candidate objects for insertion) have profiles and, {{in the case of}} main programme objects, are annotated with placeholders representing personalisation opportunities, i. e., locations for insertion of personalised <b>media</b> <b>objects.</b> The MultiMedia Brokerage (MMB) platform is a multiagent multilayered brokerage composed by agents that act as sellers and buyers of viewer stream timeslots and/or <b>media</b> <b>objects</b> on behalf of the registered businesses. These agents engage in negotiations to select the <b>media</b> <b>objects</b> that best match the current programme and viewer profiles...|$|R
40|$|The DEMOM (Description based <b>Media</b> <b>Object</b> data Model) <b>media</b> <b>object</b> {{data model}} aims at {{providing}} a uniform framework for managing {{different types of}} media data, i. e., images, text, sound or graphics. According to DEMOM <b>media</b> <b>objects</b> are defined as a class hierarchy of objects, i. e., images, text, sound, and graphics being subtypes of the general type <b>media</b> <b>object.</b> Representation specific objects are regarded as subordinate types of the corresponding subtype, e. g. a SUN raster image in pixrect format is an instance of the subtype pixrect which is in turn a subtype of image. Using images as an example we discuss the <b>media</b> <b>object</b> hierarchy, the corresponding access operations and implementation issues. Content oriented search of media data {{on the basis of}} predicate calculus is considered as an essential part of DEMOM and hence discussed as wellNaval Ocean Systems Center[URL] Direct FundingN...|$|R
5000|$|PBCore extends Dublin Core {{by adding}} a number of {{elements}} specific to audiovisual (AV) assets. These AV assets can be physical analog media items, or digital <b>media</b> <b>objects.</b> PBCore provides a standard for cataloging and describing <b>media</b> <b>objects</b> in three general ways: ...|$|R
40|$|Distributed {{multimedia}} presentation, involving different <b>media</b> <b>objects</b> {{on different}} servers, must strictly follow its defined temporal scenario. Out of synchronization {{is a fundamental}} problem in case of distributed multimedia. In this paper, we introduce a distributed QoS handler, whose aim is to distribute the QoS adaptation tasks among all the servers holding the <b>media</b> <b>object.</b> In this case, the client is considerably freed from the QoS-related tasks and it focuses only on playing the received, adapted <b>media</b> <b>objects</b> and notifying {{the end of their}} presentation to the concerned servers. This will lead to a better load balance for playing a distributed multimedia application, where the tasks of applying QoS rules and playing the objects are better distributed among the playing client and the <b>media</b> <b>object</b> servers...|$|R
40|$|This paper {{describes}} how the handling of visual <b>media</b> <b>objects</b> is implemented in the visual information retrieval project VizIR. Essentially, four areas are concerned: media access, media representation in user interfaces, visualisation of media-related data and media transport over the network. The paper offers detailed technical descriptions of the solutions developed in VizIR for these areas. Unified media access for images and video is implemented through class MediaContent. This class contains methods to access the view on a <b>media</b> <b>object</b> {{at any point in}} time as well as methods to change the colour model and read/write format parameters (size, length, frame-rate). Based on this low-level-API class VisualCube allows accessing spatio-temporal areas in temporal media randomly. Transformer-classes allow to modify visual objects in a very simple but effective way. Visualisation of <b>media</b> <b>object</b> is implemented in class MediaRenderer. Each MediaRenderer represents one <b>media</b> <b>object</b> and is responsible for any aspect of its visualisation. In the paper examples for reasonable implementations of MediaRenderer-classes are presented. Visualisation of mediarelated data is strongly connected to MediaRenderer. MediaRenderer is to a large extent responsible for displaying visual panels created by other framework components. Finally, <b>media</b> <b>object</b> transport in VizIR is based on the Realtime Transfer Protocol (for <b>media</b> <b>objects)</b> and XML-messaging (for XML-data) ...|$|R
5000|$|Formal {{semantics}} for spatio-temporal relations across <b>media</b> <b>objects</b> and events.|$|R
40|$|A web media {{agent is}} presented, {{which can make}} a user's web surfing {{experience}} more productive. Once the user visits a web page, semantic descriptions of the <b>media</b> <b>objects</b> on the page are automatically collected and used as their semantic indexes, which can help the user quickly find relevant <b>media</b> <b>objects</b> later...|$|R
40|$|In {{previous}} work we have described a multimedia system, MAVIS 2, supporting content and concept based retrieval and navigation. A central {{component of the}} system is a multimedia thesaurus in which media content is associated with appropriate concepts in a semantic layer. A major challenge is identifying and constructing these associations in a particular application without requiring a huge amount of manual effort. In this paper we propose a two phase approach to the problem. In the first phase, latent semantic analysis is used to associate metadata available for some <b>media</b> <b>objects</b> with concept class descriptions. This facilitates automatic associations to be made with the concept layer for those <b>media</b> <b>objects.</b> In the second phase, media content matching is used to classify <b>media</b> <b>objects</b> without metadata through their similarity to <b>media</b> <b>objects</b> classified in phase 1...|$|R
40|$|In {{multi-user}} multimedia {{information systems}} (e. g., movie-on-demand, digital-editing), scheduling the retrievals of continuous <b>media</b> <b>objects</b> becomes a challenging task. This {{is because of}} both intra and inter object time dependencies. Intra-object time dependency refers to the real-time display requirement of a continuous <b>media</b> <b>object.</b> Inter-object time dependency is the temporal relationships defined among multiple continuous <b>media</b> <b>objects.</b> In order to compose tailored multimedia presentations, a user might define complex time dependencies among multiple continuous <b>media</b> <b>objects</b> having various length and display bandwidth requirement. Scheduling the retrieval tasks corresponding to the components of such a presentation in order to respect both inter and intra task time dependencies {{is the focus of}} this study. To tackle this task scheduling problem (CRS), we start with a simpler scheduling problem (ARS) where there is no inter task time dependency (e. g., movie-on-demand). With ARS, th [...] ...|$|R
40|$|Structuring <b>media</b> <b>objects</b> such as text, {{graphics}} etc. {{by means}} of XML is a broadly discussed issue in hypermedia modeling. Thereby, an entire hypermedia document is not only arranged {{in such a way}} different developers may interchange data and have easy access to the inner structure of <b>media</b> <b>objects</b> {{by means of}} powerful tools available in the XML scene. Moreover, utilizing a given document structure to find new possibilities of linking documents is a major concern. Formal approaches, however, rarely appear in this context. In this paper, we contribute to formally structuring <b>media</b> <b>objects</b> and their linkage, thereby aiming at analyzing hyperlink structures. That is, properties of hyperlinks between <b>media</b> <b>objects</b> underlie a mathematical verification in advance of encoding the concrete hyperdocument. Algebraic specifications serve as a formal model allowing to obtain algebras reflecting hyperlink structures open to analysis...|$|R
40|$|Recommending <b>media</b> <b>objects</b> {{to users}} {{typically}} requires users to rate existing <b>media</b> <b>objects</b> {{so as to}} understand their preferences. The number of ratings required to produce good suggestions can be reduced through collaborative filtering. Collaborative filtering is more difficult when prior users have not rated {{the same set of}} <b>media</b> <b>objects</b> as the current user or each other. In this work, we describe an approach to applying prior user data {{in a way that does}} not require users to rate the same <b>media</b> <b>objects</b> and that does not require imputation (estimation) of prior user ratings of objects they have not rated. This approach is applied to the problem of finding good equalizer settings for music audio and is shown to greatly reduce the number of ratings the current user must make to find a good equalization setting...|$|R
40|$|Structuring <b>media</b> <b>objects</b> such as text, {{graphics}} etc. {{by means}} of XML is a broadly discussed issue in hypermedia modeling. Thereby, an entire hypermedia document is not only arranged {{in such a way}} different developers may interchange data and have easy access to the inner structure of <b>media</b> <b>objects</b> {{by means of}} powerful tools available in the XML scene...|$|R
40|$|By {{introducing}} rebuilding {{and repair}} as critical {{practice in the}} media studies classroom, students can examine effects as they are triggered by direct engagement with the materiality or media. Encountering material <b>media</b> <b>objects</b> challenges how the media studies student acquires a canonical understanding of media studies and opens new venues for insight. The act of engaging with the material media object–allows students to engage more fully with questions involving the infrastructures that go into the production of <b>media</b> <b>objects,</b> the paradigms for media innovation, and the assumptions that students might bring {{to bear on the}} material make up of the <b>media</b> <b>object</b> itself. Peer reviewe...|$|R
40|$|We study caching {{strategies}} for proxies that cache VBR encoded continuous <b>media</b> <b>objects</b> for highly interactive streaming applications. First, we develop {{a model for}} streaming VBR encoded continuous <b>media</b> <b>objects.</b> This model forms {{the basis for a}} stream admission control criterion and our study of caching strategies. We find that unlike conventional web caches, proxy caches for continuous <b>media</b> <b>objects</b> need to replicate or stripe objects to achieve high hit rates. We develop novel caching strategies that either implicitly or explicitly track the request pattern and cache (and replicate) objects accordingly. Our numerical results indicate that our caching strategies achieve significantly higher hit rates than caching without object replication...|$|R
40|$|Introduction The Web {{continues}} to grow rapidly delivering text oriented data, such as news and stock quotes, along with a scattering of multimedia objects, such as audio/video clips and images. Commercial developers and multimedia standard bodies are trying to extend the current Web technology so that Web <b>media</b> <b>objects</b> can be temporally and spatially synchronized to create richer TV-like multimedia content. A number of well thought solutions have been proposed, which can be grouped into the following categories: (1) media structure [...] using new application structure to perform <b>media</b> <b>object</b> synchronization, e. g. applications such as Macromedia's Shockwave [10] and MHEG- 5 [11]; (2) media creation [...] using new media format to form synchronized <b>media</b> <b>objects,</b> e. g. <b>media</b> formats such as MPEG- 4 [3] and VRML [15]; (3) media content [...] using existing Web technologies such HTML and Cascading Style Sheets (CSS) with JavaScript to synchronize <b>media</b> <b>objects,</b> e. g. Dynamic HTML. The a...|$|R
50|$|OMA DRM version 1.0 {{was first}} drafted in November 2002, and {{approved}} in June 2004. It provides basic Digital Rights Management, without strong protection. The standard specifies three main methods: Forward Lock, Combined Delivery (combined rights <b>object</b> / <b>media</b> <b>object),</b> and Separate Delivery (separated rights <b>object</b> + encrypted <b>media</b> <b>object).</b> Forward Lock prevents the user from forwarding content such as ringtones and wallpapers on their phone.|$|R
40|$|Nowadays, {{the idea}} of media {{contents}} streaming through the Internet has become a very important issue. On the other hand, full caching for <b>media</b> <b>objects</b> is not a practical solution and leads to consume the cache storage in keeping few <b>media</b> <b>objects</b> because of its limited capacity. Furthermore, repeated traffic which is being sent to clients wastes the network bandwidth. Thus, utilizing the bandwidth of the network is considered as an important objective for network administrators. <b>Media</b> <b>objects</b> have some characteristics {{that have to be}} considered when a caching algorithm is going to be performed. In this paper, recent approaches that have been proposed for media streams caching in peer-to-peer systems are reviewed...|$|R
5000|$|WinPlus {{was also}} {{licensed}} by Oracle {{as the basis}} for Oracle Card, later known as Oracle <b>Media</b> <b>Objects</b> when the [...] "card" [...] terminology was frowned upon. It was first introduced in 1991 as part of [...] "Oracle for Windows", which included a full suite of client/server software and a variety of their existing database client-side interface programs (text based). Version 1.1 followed at the Oracle Developers and Integrators conference in 1992, followed shortly thereafter by the Mac version. The system was later re-purposed as the front-end for a database-hosted media system for interactive TV, changing the name to Oracle <b>Media</b> <b>Objects.</b> This project went nowhere, and <b>Media</b> <b>Objects</b> disappeared in the late 1990s.|$|R
40|$|An {{important}} {{trend in}} web information processing is {{the support of}} content- based multimedia retrieval (CBMR). However, the most prevailing paradigm of CBMR, such as content-based image retrieval, content-based audio retrieval, etc, is rather conservative. It can only retrieve <b>media</b> <b>objects</b> of single modality. With the rapid development of Internet, {{there is a great}} deal of <b>media</b> <b>objects</b> of different modalities in the multimedia documents such as webpages, which exhibit latent semantic correlation. Cross-media retrieval, as a new multi- media retrieval method, is to retrieve all the related <b>media</b> <b>objects</b> with multi- modalities via submitting a query <b>media</b> <b>object.</b> To the best of our knowledge, this is the first study on how to speed up the cross-media retrieval via indexes. In this paper, based on a Cross-Reference-Graph(CRG) -based similarity retrieval method, we propose a novel unified high-dimensional indexing scheme called CIndex, which is specifically designed to effectively speedup the retrieval performance of the large crossmedia databases. In addition, we have conducted comprehensive experiments to testify the effectiveness and efficiency of our proposed method...|$|R
40|$|Although {{multimedia}} {{objects such}} as images, audios and texts are of different modalities, {{there are a great}} amount of semantic correlations among them. In this paper, we propose a method of transductive learning to mine the semantic correlations among <b>media</b> <b>objects</b> of different modalities so that to achieve the cross-media retrieval. Cross-media retrieval is a new kind of searching technology by which the query examples and the returned results can be of different modalities, e. g., to query images by an example of audio. First, according to the <b>media</b> <b>objects</b> features and their co-existence information, we construct a uniform cross-media correlation graph, in which <b>media</b> <b>objects</b> of different modalities are represented uniformly. To perform the cross-media retrieval, a positive score is assigned to the query example; the score spreads along the graph and <b>media</b> <b>objects</b> of target modality or MMDs with the highest scores are returned. To boost the retrieval performance, we also propose different approaches of long-term and short-term relevance feedback to mine the information contained in the positive and negative examples...|$|R
40|$|Rapid {{growth of}} {{competition}} on the electronic market place calls for innovative communication modes with web users. Considering {{the emergence of}} dynamic <b>media</b> <b>objects</b> containing temporal infromation such as animated character agents, web page scripts nowadays cannot satisfy users' increasing requirements well. We will develop a Dynamic Web Markup Language (DWML) as a software platform for authoring animated web pages with character agents. We assume that both primary <b>media</b> <b>objects</b> (text, image, etc.) and animated characters can be dynamic objects carrying time-based information, and that a character agent is a special dynamic medium {{as part of a}} multimedia interface. DWML, having a distributed structure and timeline flow, is used to generate both dynamic and static <b>media</b> <b>objects,</b> as well as characters' verbal and non-verbal behaviors...|$|R
40|$|In this article, {{we present}} the basic {{architecture}} of the Network Environment for Multimedia Objects (NEMO). NEMO is a smart media environment for contextualized, personalized, and device-specific interaction with multimedia objects. It provides its users access to interactive multimedia objects {{across a variety of}} computing platforms and devices, such as mobile phones, multi-touch tables, desktop computers and interactive white-boards. NEMO Multimedia Objects are containers for metadata and <b>media</b> <b>objects.</b> Such <b>media</b> <b>objects</b> can be, for example, images, texts, animations, videos, audio files. Dedicated NEMO clients do not only offer means for presentation of <b>media</b> <b>objects</b> but also a runtime environment for applications on such objects. The system is suitable for application domains ranging from work environments to educational use and recreational activities...|$|R
5000|$|Profile 3 is for {{embedding}} PRISM metadata in <b>media</b> <b>objects</b> such as {{digital images}} or PDFs using XMP technology.|$|R
30|$|Child {{objects of}} {{templates}} can be <b>media</b> <b>objects</b> (any object whose content {{is to be}} processed for exhibition) or other nested compositions. An interface can define part {{of the content of}} a <b>media</b> <b>object,</b> or can define a child object property, like its positioning on the screen, etc. Child composite objects and the template itself may also have interfaces that externalize interfaces of their internal child objects. Note that in defining the vocabulary we are also defining the hierarchy imputed to the child objects, given by the composition nesting.|$|R
5000|$|Numerical Representation: {{essentially}} {{means that}} [...] "all new <b>media</b> <b>objects</b> {{can be described}} mathematically and can be manipulated via algorithms." ...|$|R
5000|$|They {{should have}} the ability to {{retrieve}} <b>media</b> <b>objects</b> from a local storage device in a good manner. (Storage support) ...|$|R
5000|$|Automation: [...] "Automation {{is seen in}} {{computer}} programs that allow users to create or modify <b>media</b> <b>objects</b> using templates or algorithms".|$|R
5000|$|PlusTalk (?) - of Spinnaker Plus (originally by the German Format Verlag), {{which was}} used as the basis for Oracle <b>Media</b> <b>Objects.</b>|$|R
40|$|<b>Media</b> <b>objects</b> of {{different}} modalities always exist jointly {{and they are}} naturally complementary of each other, either {{in the view of}} semantics or in the view of modality. In this paper, we propose a manifold learning based cross-media retrieval approach that gives solutions to the two intrinsically basic but crucial questions of <b>media</b> <b>objects</b> semantics understanding and cross-media retrieval. First, considering the semantic complementary, how can we represent the concurrent <b>media</b> <b>objects</b> and fuse the complementary information they carry to understand the integrated semantics precisely. Second, considering the modality complementary, how can we accomplish the modality bridge to establish the cross-index and facilitate the cross-media retrieval? To solve the two problems, we first construct a Multimedia Document (MMD) Semi-Semantic Graph (MMDSSG) and then adopt Multidimensional Scaling to create an MMD Semantic Space (MMDSS). Both long-term and short-term feedbacks are proposed to boost the system performance. The first one is used to refine the MMDSSG and the second one is adopted to introduce new items that are not in the training set into the MMDSS. Since all of the MMDs and their component <b>media</b> <b>objects</b> {{of different}} modalities lie in the MMDSS and they are indexed uniformly by their coordinates in the MMDSS regardless of their modalities, the semantic subspace is actually a bridge of <b>media</b> <b>objects</b> which are of different modalities and the crossmedia retrieval can be easily achieved. Experiment results are encouraging and indicate that the proposed approach is effective...|$|R
