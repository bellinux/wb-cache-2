10000|10000|Public
5|$|Although {{distinctly}} {{different from each}} other, DNA damage and mutation are related because DNA damage often causes <b>errors</b> of DNA synthesis during replication or repair; these <b>errors</b> are {{a major source of}} mutation.|$|E
5|$|<b>Errors</b> as to {{precedent}} facts, {{sometimes called}} jurisdictional facts, in Singapore administrative law are <b>errors</b> committed by public authorities concerning facts that must objectively exist or not exist before the authorities {{have the power}} to take actions or make decisions under legislation. If an error concerning a precedent fact is made, the statutory power has not been exercised lawfully and may be quashed by the High Court if judicial review is applied for by an aggrieved person. The willingness of the Court to review such <b>errors</b> of fact is an exception to the general rule that the Court only reviews <b>errors</b> of law.|$|E
5|$|CSS parsing: A {{number of}} illegal CSS {{statements}} {{are present in}} Acid2 to test error handling. Standards-compliant browsers are expected to handle these <b>errors</b> as the CSS specification directs. This helps ensure cross-browser compatibility by making all browsers treat CSS with {{the same level of}} strictness, so that what works in one browser should not cause <b>errors</b> in another.|$|E
5000|$|<b>Error</b> {{management}} including <b>error</b> prevention, <b>error</b> correction, {{user support}} for <b>error</b> management, and <b>error</b> messages.|$|R
40|$|Conventional <b>error</b> {{diffusion}} half toning uses {{a causal}} <b>error</b> filter. We propose the iterative <b>error</b> diffusion algorithm by extending the <b>error</b> diffusion to accommodate noncausal <b>error</b> filters. We realize {{the importance of}} the phase response of the <b>error</b> filter in the <b>error</b> diffusion halftoning method, and demonstrate it using examples. Iterative <b>error</b> diffusion is able to realize a zero phase <b>error</b> filter. We also trace a drawback of <b>error</b> diffusion to the shape of the <b>error</b> filter, and provide a remedy. The results obtained using zero phase <b>error</b> filter in the iterative <b>error</b> diffusion algorithm are, in our opinion, superior to the <b>error</b> diffusion halftones...|$|R
40|$|Abstract. According to definitions, {{geometric}} characteristics and corresponding <b>error</b> evaluation functions of straightness <b>error,</b> flatness <b>error,</b> roundness <b>error,</b> cylindricity <b>error</b> and sphericity <b>error,</b> {{the concept of}} evaluation reference of form <b>error</b> is put forward by analyzing the minimum zone evaluation method of form <b>error.</b> The evaluation reference corresponding to form <b>error</b> is obtained by studying the function {{of all kinds of}} form <b>error.</b> The relationship between the evaluation references and the all kinds of form <b>error</b> are studied. The unified formula of the form <b>error</b> is gained and the unification of the form <b>error</b> is realized by summing up the relationships. The foundation of researching the unified shape <b>error</b> evaluation algorithm is laid by unified mathematical description...|$|R
5|$|<b>Errors</b> in {{procedure}} {{can also}} lead to <b>errors</b> in the results. If 1% of the benzene in a modern reference sample accidentally evaporates, scintillation counting will give a radiocarbon age that is too young by about 80 years.|$|E
5|$|If a {{defendant}} is convicted, the usual remedy for {{a violation of}} one of these provisions is reversal of the conviction or modification of the defendant's sentence. With the exception of structural <b>errors</b> (such as the total denial of counsel), constitutional <b>errors</b> are subject to harmless error analysis, although they must be harmless beyond a reasonable doubt. With the exception of a Double Jeopardy or Speedy Trial violation, the government will usually be permitted to retry the defendant. Pursuant to the Antiterrorism and Effective Death Penalty Act of 1996 (AEDPA), these provisions are the source of nearly all reviewable <b>errors</b> in federal habeas review of state convictions.|$|E
5|$|It {{has been}} {{suggested}} that a question of fact involves a matter concerning primary facts such as a new witness or what people saw or heard, while a question of law involves an application of a statutory word or phase to such facts. However, this distinction is debatable, and the view has been taken that courts sometimes simply regard a matter as one involving an error of law if they wish to adopt an interventionist approach, and seek to allow judicial review to take place. In any case, it is said that the courts generally treat <b>errors</b> of fact committed by public authorities differently from <b>errors</b> of law. While <b>errors</b> of law are regarded by the courts as within their jurisdiction and thus subject to judicial review, they show more reluctance to intervene when <b>errors</b> of fact are alleged.|$|E
40|$|Data <b>error</b> is an {{obstacle}} to effective application, integration, and sharing of data. <b>Error</b> reduction, although desirable, is not always necessary or feasible. <b>Error</b> measurement is a natural alternative. In this paper, we outline an <b>error</b> propagation calculus which models the propagation of an <b>error</b> representation through queries. A closed set of three <b>error</b> types is defined: attribute value inaccuracy (and nulls), object mismembership in a class, and class incompleteness. <b>Error</b> measures are probability distributions over these <b>error</b> types. Given measures of <b>error</b> in query inputs, the calculus both computes and &quot;explains &quot; <b>error</b> in query outputs, so that users and administrators better understand data <b>error.</b> <b>Error</b> propagation is non-trivial as <b>error</b> may be amplified or diminished through query partitions and aggregations. As a theoretical foundation, this work suggests managing <b>error</b> in practice by instituting measurement of persistent tables and extending database output to include a quantitative <b>error</b> term, akin to the confidence interval of a statistical estimate. Two theorems assert the completeness of our <b>error</b> representation...|$|R
50|$|Forecast <b>error</b> {{can be a}} {{calendar}} forecast <b>error</b> or a cross-sectional forecast <b>error,</b> when we want to summarize the forecast <b>error</b> over a group of units. If we observe the average forecast <b>error</b> for a time-series of forecasts for the same product or phenomenon, then we call this {{a calendar}} forecast <b>error</b> or time-series forecast <b>error.</b> If we observe this for multiple products for the same period, then this is a cross-sectional performance <b>error.</b> Reference class forecasting has been developed to reduce forecast <b>error.</b> Combining forecasts {{has also been shown}} to reduce forecast <b>error.</b>|$|R
50|$|There {{are several}} basic fitness {{functions}} for evaluating model performance, {{with the most}} common being based on the <b>error</b> or residual between the model output and the actual value. Such functions include the mean squared <b>error,</b> root mean squared <b>error,</b> mean absolute <b>error,</b> relative squared <b>error,</b> root relative squared <b>error,</b> relative absolute <b>error,</b> and others.|$|R
5|$|Nicholas Pocock found <b>errors</b> in Tregelles' edition, but William Hatch {{thought it}} satisfactory. J. Harold Greenlee {{corrected}} Tregelles' <b>errors</b> and edited {{the list of}} corrections in 1957, which was examined by William Hatch. In 1959 Greenlee published a commentary. The codex probably needs another examination with modern technology.|$|E
5|$|Standard <b>errors</b> of prediction, {{also known}} as {{accuracy}} or possible change value {{in the context of}} EBV and EPD predictions, are dependent on the quality of information used to predict an animal's EBV or EPD for a given trait. <b>Errors</b> in estimating genetic merit are being addressed in research programmes that aim to supplement phenotypic data extensively used in current BLUP predictions with genotypic data.|$|E
5|$|There {{are many}} <b>errors</b> by homoioteleuton (Mark 2:18; 4:24; 12:26; 14:70; 15:14; Luke 12:22.47; 13:28.29; John 4:14).|$|E
40|$|Abstract. A {{new type}} of a 2 -PRS/ 2 -UPS 4 -DOF {{parallel}} platform was introduced. The <b>error</b> model of the parallel worktable was established through the vector method. The effect of structural <b>error,</b> driving <b>error,</b> position <b>error</b> and clearance <b>error</b> of the joint point to the pose <b>error</b> of the moving platform can be analyzed. <b>Error</b> modeling provides theoretical foundation for design and <b>error</b> compensation of the parallel mechanism...|$|R
50|$|In {{standard}} ARQ {{a transmission}} {{must be received}} <b>error</b> free on any given transmission for the <b>error</b> detection to pass. In Type II Hybrid ARQ, the first transmission contains only data and <b>error</b> detection (no different from standard ARQ). If received <b>error</b> free, it's done. If data is received in <b>error,</b> the second transmission will contain FEC parities and <b>error</b> detection. If received <b>error</b> free, it's done. If received in <b>error,</b> <b>error</b> correction can be attempted by combining the information received from both transmissions.|$|R
40|$|Contents [...] <b>Error!</b> Bookmark not defined. Background [...] <b>Error!</b> Bookmark not defined. Water, {{sanitation}} {{and health}} [...] <b>Error!</b> Bookmark not defined. Why is sanitation {{such a problem}} ? [...] . <b>Error!</b> Bookmark not defined. National policy for sanitation [...] <b>Error!</b> Bookmark not defined. Institutional frameworks [...] <b>Error!</b> Bookmark not defined. Programmes and impact [...] <b>Error!</b> Bookmark not defined. Role {{of the private sector}} [...] <b>Error!</b> Bookmark not defined. Role of NGOs and CBOs [...] . ...|$|R
25|$|All {{single bit}} <b>errors</b> within the bitfilter period {{mentioned}} above (for even {{terms in the}} generator polynomial) can be identified uniquely by their residual. So CRC method {{can be used to}} correct single-bit <b>errors</b> as well (within those limits, e.g. 32767 bits with optimal generator polynomials of degree 16). Since all odd <b>errors</b> leave an odd residual, all even an even residual, 1-bit <b>errors</b> and 2-bit <b>errors</b> can be distinguished. However, like other SECDED techniques, CRCs cannot always distinguish between 1-bit <b>errors</b> and 3-bit <b>errors.</b> When 3 or more bit <b>errors</b> occur in a block, CRC bit error correction will be erroneous itself and produce more <b>errors.</b>|$|E
25|$|Apart from {{internet}} slang, grammatical <b>errors</b> and typographical <b>errors</b> are {{features of}} {{writing on the}} Internet and other CMC channels. As users of the Internet gets accustomed to these <b>errors,</b> it progressively infiltrates into everyday language use, in both written and spoken forms. It is also common to witness such <b>errors</b> in mass media works, from typographical <b>errors</b> in news articles to grammatical <b>errors</b> in advertisements and even internet slang in drama dialogues.|$|E
25|$|The {{theory of}} <b>errors</b> may {{be traced back}} to Roger Cotes's Opera Miscellanea (posthumous, 1722), but a memoir {{prepared}} by Thomas Simpson in 1755 (printed 1756) first applied the theory to the discussion of <b>errors</b> of observation. The reprint (1757) of this memoir lays down the axioms that positive and negative <b>errors</b> are equally probable, and that certain assignable limits define the range of all <b>errors.</b> Simpson also discusses continuous <b>errors</b> and describes a probability curve.|$|E
40|$|Abstract: <b>Error</b> sources which {{influence}} the end-executor’s accuracy are summarized. Based on {{an analysis of}} influence caused by the structural <b>error</b> and transmission <b>error,</b> we build a pose <b>error</b> model of industrial robots with screw theory. If regarding the inertia force of the robot system as the external force, the robot system will become a static system. The rigidity can be analyzed using the screw theory, then we establish the dynamic <b>error</b> modle which {{is caused by the}} inertia force and gravity. After the <b>error</b> parameters which {{influence the}} static <b>error</b> of Selective Compliance Assembly Robot Arm (SCARA) robot are expressed by two-dimensional discrete variable, <b>error</b> space of the end-executor’s track of robot are made. Position <b>error</b> which influenced by the <b>error</b> sources are analysed by comparision of difference. Total accuracy can be improved through controlling the <b>error</b> direction of the static <b>error</b> to counteract the dynamic <b>error's</b> influence. The <b>error</b> model provides an effective theoretical support for the design of industrial robots with different accuracy requirements...|$|R
30|$|We can {{see that}} the <b>error</b> is smaller for smaller θ, smaller Δ t_soft, or larger r_cut. Roughly speaking, the <b>error</b> depends on two terms, Δ t_soft/r_cutσ and θ. If Δ t_soft/r_cutσ is large, it determines the <b>error.</b> In this regime, the <b>error</b> is {{dominated}} by the truncation <b>error</b> of the leapfrog integrator. If it is small enough, θ determines the <b>error,</b> in other words, the tree force <b>error</b> dominates the total <b>error.</b> Even for a very small value of θ like 0.2, the tree force <b>error</b> dominates if Δ t_soft/r_cutσ≲ 0.05.|$|R
50|$|The <b>Error</b> Event schema holds {{records of}} all <b>error</b> events thrown {{by the quality}} screens. It {{consists}} of an <b>Error</b> Event Fact table with foreign keys to three dimension tables that represent date (when), batch job (where) and screen (who produced <b>error).</b> It also holds information about exactly when the <b>error</b> occurred and {{the severity of the}} <b>error.</b> In addition there is an <b>Error</b> Event Detail Fact table with a foreign key to the main table that contains detailed information about in which table, record and field the <b>error</b> occurred and the <b>error</b> condition.|$|R
25|$|The worst type of <b>errors</b> {{are silent}} data corruptions which are <b>errors</b> undetected by the disk {{firmware}} or the host operating system; {{some of these}} <b>errors</b> {{may be caused by}} hard disk drive malfunctions.|$|E
25|$|Since protein {{structures}} are experimental models that can contain <b>errors,</b> {{it is very}} important to be able to detect these <b>errors.</b> The process aimed at the detection of <b>errors</b> is known as validation.|$|E
25|$|Traditionally, <b>errors</b> are {{attributed}} to mistakes made by individuals who may be penalized for these mistakes. The usual approach to correct the <b>errors</b> is to create new rules with additional checking steps in the system, aiming to prevent further <b>errors.</b> As an example, an error of free flow IV administration of heparin is approached by teaching staff {{how to use the}} IV systems and to use special care in setting the IV pump. While overall <b>errors</b> become less likely, the checks add to workload and may in themselves be a cause of additional <b>errors.</b>|$|E
40|$|Abstract. The {{straightness}} <b>error</b> {{was measured}} {{from a certain}} part surface by CMM. The paper expounded the principle of <b>error</b> separation technique, and separated the straightness <b>error</b> into deterministic <b>error</b> and random <b>error.</b> It proved strictly an opinion that random <b>error</b> is obedient to normal distribution. Extraction point of random <b>error</b> far outweighs the extraction point which is obtained from deterministic <b>error.</b> Based {{on the principle of}} sampling signal, a conclusion can be pointed out that utilizing the characteristic of random <b>error</b> to recover the signal of straightness <b>error</b> without distortion is feasible and normal distribution model can be used in the computer simulation to study the problem of extraction point...|$|R
40|$|Generating <b>error</b> {{messages}} for LR parsers {{is currently a}} difficult and <b>error</b> laden process �Adding <b>error</b> productions to the grammar makes the grammar difficult to read, and can hinder <b>error</b> recovery �Manually adding <b>error</b> messages based on parse state is <b>error</b> prone, {{and needs to be}} updated after every grammatical chang...|$|R
40|$|Abstract. This paper derives {{the exact}} {{functional}} {{form of an}} <b>error</b> contaminated regression function when the <b>error</b> free regression is a polynomial function of <b>error</b> free covariates (discrete or continuous) which are contaminated by normally distributed measurement <b>error,</b> with coe¢cients which may be arbitrary functions of <b>error</b> free covariates. The form of higher order central moment <b>error</b> contaminated regressions is examined and by way of example the form of normal measurement <b>error</b> induced heteroskedasticity when the <b>error</b> free regression is linear and homoskedastic is derived. The results of this paper may provide at least a partial explanation of mild non-linearity and heteroskedasticity found in applied econometric work with survey data when <b>error</b> contamination, e. g. of income and expenditure data, is likely. The <b>error</b> contaminated regression function is completely determined by the coe¢cients in the <b>error</b> free regression, the measurement <b>error</b> variance and {{the density of the}} observed covariates. This density can be estimated, opening the way to estimation of <b>error</b> free regression functions using only data on the response and the <b>error</b> contaminated covariate, to investigation of the potential impact of measurement <b>error</b> on structural <b>error</b> free regressions and to the development of speci…cation tests sensitive to unmodelled measurement <b>error...</b>|$|R
25|$|The United States Pharmacopeia (USP) sets {{official}} {{standards for}} all prescription and over-the-counter medicines, dietary supplements, and other healthcare products manufactured {{and sold in}} the United States, but USP standards are also recognized and used in more than 130 other countries. USP operates two programs to promote patient safety. The Medication <b>Errors</b> Reporting Program enables healthcare professionals to report medication <b>errors</b> directly to USP. MEDMARX, an internet-based error and drug reaction reporting program, is designed for use in hospitals. The USP analyzes the data it receives through its reporting programs, develops professional education programs and disseminates alerts related to medication <b>errors.</b> The MEDMARX report released in 2007 analyzed 11,000 medication <b>errors</b> during surgery in 500 hospitals between 1998 and 2005. The analysis showed that medication <b>errors</b> that happen {{in the operating room}} or recovery areas are {{three times more likely to}} harm a patient than <b>errors</b> occurring in other types of hospital care. , this was the largest known analysis of medical <b>errors</b> related to surgery.|$|E
25|$|The {{central issue}} in {{behavioral}} finance is explaining why market participants make irrational systematic <b>errors</b> contrary to assumption of rational market participants. Such <b>errors</b> affect prices and returns, creating market inefficiencies. The study of behavioral finance also investigates how other participants take advantage (arbitrage) of such <b>errors</b> and market inefficiencies.|$|E
25|$|In {{the same}} paperp.190 they call these two sources of error, <b>errors</b> of typeI and <b>errors</b> of typeII respectively.|$|E
40|$|We {{present a}} novel method of {{judgment}} analysis called <b>Error</b> Parsing, based upon an alternative method of implementing Social Judgment Theory (SJT). SJT and <b>Error</b> Parsing both posit {{the same three}} components of <b>error</b> in human judgment: <b>error</b> due to noise, <b>error</b> due to cue weighting, and <b>error</b> due to inconsistency. In that sense, the broad theory and framework are the same. However, SJT and <b>Error</b> Parsing were developed to answer different questions, and thus use different methodological approaches {{in the analysis of}} <b>error.</b> While SJT makes use of correlational methods, <b>Error</b> Parsing uses absolute differences. We discuss the similarities and differences between the methodologies and provide empirical evidence for the utility of the <b>Error</b> Parsing technique. Keywords: Social Judgment Theory, judgment, <b>error...</b>|$|R
30|$|Equation 27 {{shows that}} the {{relative}} and absolute time synchronization <b>error</b> all affect the estimation <b>error.</b> As {{the magnitude of the}} relative synchronization <b>error</b> doubles the magnitude of the absolute <b>error,</b> mitigating the relative <b>error</b> is more important.|$|R
5000|$|In {{communication}} systems with very low uncorrected bit <b>error</b> rates, such as modern fiber optic transmission systems, or systems with higher low-level <b>error</b> rates that are corrected using {{large amounts of}} forward <b>error</b> correction, <b>errored</b> seconds are often a better measure of the effective user-visible <b>error</b> rate than the raw bit <b>error</b> rate.|$|R
