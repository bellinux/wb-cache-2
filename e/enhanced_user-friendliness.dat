6|19|Public
40|$|We live in {{a society}} in which {{information}} and communications technologies (ICT) are becoming a driving force for its development. E-learning is obviously a part of this. e basic thought for creation of an adaptive e-learning environment is respecting and supporting di ering learning styles of students, by which it is then possible to prepare a learning environment that is more e ective, with <b>enhanced</b> <b>user-friendliness</b> and quality. is paper describes a dra adaptive education model and the results of the rst part of the solution – de nition of learning styles, pilot testing on students and an outline of further {{research in the area of}} teaching styles of teachers...|$|E
40|$|International audienceThe 2 D-Video-Distrometer (2 DVD) is a {{ground-based}} point-monitoring precipitation gauge. From each particle reaching the measuring area front and side contours {{as well as}} fall velocity and precise time stamp are recorded. In 1991 the 2 DVD development has been started to clarify discrepancies found when comparing weather radar data analyses with literature models. Then being manufactured in a small scale series the first 2 DVD delivery took place in 1996, 10 years back from now. An overview on present 2 DVD features is given, and it is presented how the instrument was continuously improved {{in the past ten}} years. Scientific merits of 2 DVD measurements are explained, including drop size readings without upper limit, drop shape and orientation angle information, contours of solid and melting particles, and an independent measurement of particles' fall velocity also in mixed phase events. Plans for a next generation instrument are described, by <b>enhanced</b> <b>user-friendliness</b> the unique data type shall be opened to a wider user community...|$|E
40|$|BACKGROUND: Spiromax® {{is a novel}} dry-powder inhaler {{containing}} {{formulations of}} budesonide plus formoterol (BF). The device is intended to provide dose equivalence with <b>enhanced</b> <b>user-friendliness</b> compared to BF Turbuhaler® in asthma and {{chronic obstructive pulmonary disease}} (COPD). The present study was performed to compare inhalation parameters with empty versions of the two devices, and to investigate the effects of enhanced training designed to encourage faster inhalation. METHODS: This randomised, open-label, cross-over study included children with asthma (n[*]=[*] 23), adolescents with asthma (n[*]=[*] 27), adults with asthma (n[*]=[*] 50), adults with COPD (n[*]=[*] 50) and healthy adult volunteers (n[*]=[*] 50). Inhalation manoeuvres were recorded with each device after training with the patient information leaflet (PIL) and after enhanced training using an In-Check Dial device. RESULTS: After PIL training, peak inspiratory flow (PIF), maximum change in pressure (∆P) and the inhalation volume (IV) were significantly higher with Spiromax than with the Turbuhaler device (p values were at least < 0. 05 in all patient groups). After enhanced training, numerically or significantly higher values for PIF, ∆P, IV and acceleration remained with Spiromax versus Turbuhaler, except for ∆P in COPD patients. After PIL training, one adult asthma patient and one COPD patient inhaled < 30 L/min through the Spiromax compared to one adult asthma patient and five COPD patients with the Turbuhaler. All patients achieved PIF values of at least 30 L/min after enhanced training. CONCLUSIONS: The two inhalers have similar resistance so inhalation flows and pressure changes would be expected to be similar. The higher flow-related values noted for Spiromax versus Turbuhaler after PIL training suggest that Spiromax might have human factor advantages in real-world use. After enhanced training, the flow-related differences between devices persisted; increased flow rates were achieved with both devices, and all patients achieved the minimal flow required for adequate drug delivery. Enhanced training could be useful, especially in COPD patients...|$|E
40|$|Abstract. Communication channel {{established}} from {{a display}} to a device’s camera {{is known as}} visual channel, and it is helpful in securing key exchange protocol [18]. In this paper, we study how visual channel can be exploited by a network terminal and mobile device to jointly verify information in an interactive session, and how such information can be jointly presented in a user-friendly manner, {{taking into account that}} the mobile device can only capture and display a small region, and the user may only want to authenticate selective regions-of-interests. Motivated by applications in Kiosk computing and multi-factor authentication, we consider three security mod-els: (1) the mobile device is trusted, (2) at most one of the terminal or the mobile device is dishonest, and (3) both the terminal and device are dishonest but they do not collude or communicate. We give two protocols and investigate them under the abovementioned models. We point out a form of replay attack that renders some other straightforward implementations cumbersome to use. To <b>enhance</b> <b>user-friendliness,</b> we propose a solution using visual cues embedded into the 2 D barcodes and incorporate the framework of “augmented reality ” for easy verifications through visual inspec-tion. We give a proof-of-concept implementation to show that our scheme is feasible in practice...|$|R
40|$|A {{steady-state}} {{simulation of}} a cooling system is described. The simulation {{has been carried}} out using an algorithm, implemented in Turbo Pascal, which allows the system parameters to be changed, or the output to be modified easily. A computer program, called CCSim, has been developed and is currently being extended to cover other systems likely to be encountered in practice. Turbo Vision, the screen-menu design routine of Turbo Pascal, has been employed to <b>enhance</b> its <b>user-friendliness.</b> A case study, whose output has been checked using IMSL-FORTRAN routines, is presented. ...|$|R
40|$|AbstractThis paper {{presents}} the modular design {{and control of}} a novel variable impedance compact compliant wearable ankle robot (powered Ankle-Foot Orthosis, AFO) for overground gait rehabilitation and assistance mainly for stroke patients. Design of AFO, its construction, kinematics, working principle, actuation, control etc. are described. A novel variable impedance compact compliant series elastic actuator (SEA) is designed to actuate the AFO with variable impedance and compliance. The actuator design consists of a servomotor, a ball screw, a torsional spring connecting the motor and the ball screw via a pair of spur gear, {{and a set of}} translational springs connecting the ball screw nut to the output link. Two types of springs of the actuator with different stiffness provide variable impedance and compliance to the AFO based on the range of operational force. The translational springs with low stiffness are used to handle the low force operation that reduces friction, impedance and impact. The torsional spring, being in the high speed range, has high effective stiffness and improves bandwidth in large force operation when the translational springs are fully compressed. Application of the variable impedance compact compliant actuator makes the AFO compact, and it may <b>enhance</b> <b>user-friendliness.</b> Simulation results confirm the effectiveness of the AFO design. Competitive advantages of AFO over its existing counterparts are described and its future extensions are discussed...|$|R
40|$|The {{introduction}} of the functional safety standard ISO 26262 was motivated by an increasing demand to ensure reliability and correctness of safety-critical systems in the automotive industry. However, the adoption of this standard in the automotive industry is hindered {{by a number of}} obstacles. Scania is an industrial partner in the VeriSpec project which studies these obstacles and proposes relevant tools and methods compliant with academic and industrial needs. This thesis is within the scope of the VeriSpec project, and aims to address one of the project’s goals, which is to provide tool support for a pattern-based requirement formalization process. The Specification Property System (SPS) proposed by Konrad and Cheng is a patterning method that provides automatic translation of system properties into temporal logics. The SPS also helps in restricting the {{introduction of}} ambiguities and inconsistencies in system specification properties. However, the adoption of the SPS in the industry is hindered due to some issues. These issues are, a long learning curve, Constrained Natural Language (CNL) ambiguities, and the lack of tool-support for real-time SPS patterns. In this thesis, a qualitative research study with a literature survey has been performed to find and select state-of-the-art supportive methods to provide feedback on the formalized requirements’ semantics. The Scania Specifier tool has been extended and modified to support a requirement formalization process using the SPS qualitative and real-time patterns. In addition, three supportive methods that resulted from the research study have been integrated into the Specifier tool to provide different feedback options for the users. Finally, the performance of the Specifier tool and the feedback of the supportive methods have been evaluated. The outcome of the study shows that the feedback of the supportive methods helped in guaranteeing the intended behavior of the requirement developers. In addition supportive methods’ feedback <b>enhanced</b> <b>user-friendliness,</b> and aided the users in shortening the SPS learning curve. Finally, an additional outcome of the study {{is in the form of}} a number of suggestions and emerged patterns with regard to the SPS usage and supportive methods’ feedback. ...|$|E
30|$|The approach, using {{a single}} set-up {{and only one}} {{illumination}} source, represents a significant simplification over most current methodologies which rely on the separate application of two techniques (VIL and UVL), each requiring a different illumination source. The case studies discussed in this investigation have shown that that the combined VIL/VIVL method proposed is able to efficiently detect and map both of these pigments with analogous results to those obtained by more established methodologies. In addition, the use of LED sources provide a more targeted excitation for the pigments of interest, reducing risk to both user and objects, and avoiding spurious signals from excited species produced by less specific forms of irradiation. The simplified set-up also promotes better data reproducibility and facilitates post-processing, <b>enhancing</b> the <b>user-friendliness</b> of the approach.|$|R
40|$|This working {{document}} illustrates {{the findings of}} an extensive comparative review of commonalities and differences between commercially available malaria rapid diagnostic tests with regard to for harmonization and end-user friendliness. 1 This review was commissioned by the Roll Back Malaria partnership in July 2012. The document contains a set of criteria for consideration by the participants to the Stakeholder Consultation meeting on 3 – 5 December in Antwerp, Belgium. It serves {{as a starting point}} to guide discussions on relevant and feasible opportunities to <b>enhance</b> harmonization and <b>user-friendliness</b> of malaria rapid diagnostic tests...|$|R
40|$|AbstractReasoning {{by analogy}} refers to {{recognizing}} certain similarities between a source situation/object and a target situation/object and deriving some {{properties of the}} target {{on the basis of}} observed similarities with the source. Analogy is an important inference tool in human cognition and is a powerful computational tool for general inference. Null queries are queries that elicit a null answer from the database system, often because of the incompleteness of information in the database, for example, the absence of certain attribute values for some objects. Analogy is useful for obtaining an approximate answer to a null query. In this paper, we develop the theoretical basis for the application of analogical reasoning to obtain approximate answers for null queries {{in the context of a}} fuzzy relational data model. The incorporation of analogical reasoning in data models <b>enhances</b> their <b>user-friendliness.</b> Our proposed model of analogy incorporates fuzzy logic and is a natural generalization of models of analogy researched in the domain of artificial intelligence...|$|R
40|$|The {{favorable}} self-adhesiveness of resin-modified glass ionomers (RMGIs) {{might be}} even further improved if the time-consuming and technically sensitive etch-and-rinse pre-treatment step with polyalkenoic acids could be avoided. We undertook {{this study to}} assess the effectiveness of an experimental self-etch adhesive for RMGIs that {{does not need to}} be rinsed off. Ultrastructural analysis and micro-tensile bond strength testing to enamel and dentin of a RMGI restorative material and a RMGI adhesive were performed after 4 different surface pre-treatments: no conditioning; 25 % polyalkenoic acid; an experimental self-etch adhesive; and 37. 5 % phosphoric acid followed by the experimental self-etch adhesive. The use of an experimental self-etch adhesive increased the bond strength of RMGIs, especially after an additional conditioning step. Interfacial analysis showed the formation of a thin hydroxyapatite-containing hybrid layer. The self-etch technique <b>enhances</b> the <b>user-friendliness</b> of RMGIs and lowers their technique-sensitivity, while maintaining desirable characteristics of the conventional etch-and-rinse approach with polyalkenoic acids. status: publishe...|$|R
40|$|The {{purpose of}} this project is to {{innovate}} a low-cost table tennis robot with unique control system. Currently, the available table tennis robots are very expensive, {{and almost all of}} them are with wired controller where the player himself cannot control the machine when training sessions. A new design and concept are developed in order to solve these problems. This innovation called automated table tennis launcher, a self-table tennis training kit prototype which is integrated with a microcontroller better known as Arduino. This machine is controlled by the use of Android smart phones to <b>enhance</b> the <b>user-friendliness</b> and the use of wooden support and PVC pipes to fabricate greatly reduces the manufacturing cost. A 3 D virtual prototype is developed by using SolidWorks software before the fabrication process and tested for function ability. This fabricated prototype can shoot the ball in three different directions and with adjustable spinning direction, which helps the user to practice almost all types of strokes in this sport. The machine is being tested and analyzed in terms of ball speed, ball shooting coverage, feeding rate and shooting distance. The results show reliable data where this machine could develop a player’s ability to return the ball with proper strokes as well as improve the player’s reaction. Furthermore, this machine is considerably very cheap for its function compared to the currently marketed products. As a conclusion, this automated table tennis launcher able to function as expected and can perform better when fabricated into the real products by using the customized size for every part...|$|R
40|$|A {{portable}} colorimetric {{device is}} presented for arsenic ion detection in drinking water. The {{main purpose of}} this device – which was developed to complement a commercial water dearsenating station demanding regular (weekly to monthly) regeneration runs depending on its saturation – is to provide regular field measurements and easy, semi-automatic operation designed specifically for untrained, typically illiterate users e. g. the population of developing countries. The device exploits a commercially available, well established reagent kit, which is widely used in arsenic field-testing in many developing countries. The hereby presented custom-designed microfluidic system <b>enhances</b> the <b>user-friendliness,</b> the functionality and reliability of the test-strip based kit. The response for total inorganic arsenic ion concentrations (As(III) and As(V)) is linear in the 5 - 20 μg/l (ppb) range with a sensitivity of 1 μg/l, thus the device is capable to distinguish drinkable water based on the World Health Organization (WHO) guidelines of 10 μg/l. The average relative standard deviation of the measurements is 8 % in the linear range and it is below 2 % for higher arsenic concentrations (above 20 μg/l). The hardware construction of the device and the custom microfluidic system is presented in detail. The effect of elevated water sample temperature on the kinetics and performance of the device was also investigated {{in order to reduce}} the required time for the measurements. Stable and reliable arsenic concentration values were obtained after 60 min at 22 oC (ambient temperature) and after only 25 min at 50 oC water sample temperature, but at a cost of an increased relative standard deviation to 16 %, in the linear range...|$|R
40|$|The {{discovery}} and commercialization {{of a new}} drug is a long and expensive process. Such process is divided into different phases during which the phisico-chemical and therapeutic properties of the compounds are determined. In particular, {{the aim of the}} first phase is to verify whether the compound recognises and interacts efficiently with the target protein. In the last decade, several computational tools have been developed and used to support experimentalists. For this purpose, the scientist have to deal with high complex systems that are difficult to study in whole; thus, the methods and algorithms developers have to strongly simplify the system treatment. Moreover, the time required to obtain the results depends on the computational resources (hardware) available. Fortunately, the technological progress have increased the computing power at low cost, resulting in new and more complex techniques development. During this Ph. D. project we were focused on the development and even the improvement of in silico methods, which allowed to answer certain questions by saving time and money. Furthermore, these methods were implemented in software presenting a Graphical Unit Interface (GUI) with the aim to <b>enhance</b> the <b>user-friendliness.</b> The computational techniques often require a high understanding of the methodology theoretical aspects and also a good informatics proficiency, like different type files handling and hardware management. For this reason, our developed software were organized as pipelines to automatize the entire process and to make this tools useful also for non-expert users. Finally, these methodologies were applied in several research projects demonstrating their usefulness by elucidating, for the first time, interesting aspects of the ligand-protein recognition pathway...|$|R
40|$|Background: The Analytic Hierarchy Process (AHP) is {{increasingly}} {{used to measure}} patient priorities. Studies have shown that there are several different approaches to data acquisition and data aggregation. The {{aim of this study}} was to measure the information needs of patients having a rare disease and to analyze the effects of these different AHP approaches. The ranking of information needs is then used to display information categories on a web-based information portal about rare diseases according to the patient's priorities. Methods: The information needs of patients suffering from rare diseases were identified by an Internet research study and a preliminary qualitative study. Hence, we designed a three-level hierarchy containing 13 criteria. For data acquisition, the differences in outcomes were investigated using individual versus group judgements separately. Furthermore, we analyzed the different effects when using the median and arithmetic and geometric means for data aggregation. A consistency ratio ≤ 0. 2 was determined to represent an acceptable consistency level. Results: Forty individual and three group judgements were collected from patients suffering from a rare disease and their close relatives. The consistency ratio of 31 individual and three group judgements was acceptable and thus these judgements were included in the study. To a large extent, the local ranks for individual and group judgements were similar. Interestingly, group judgements were in a significantly smaller range than individual judgements. According to our data, the ranks of the criteria differed slightly according to the data aggregation method used. Conclusions: It is important to explain and justify the choice of an appropriate method for data acquisition because response behaviors differ according to the method. We conclude that researchers should select a suitable method based on the thematic perspective or investigated topics in the study. Because the arithmetic mean is very vulnerable to outliers, the geometric mean and the median seem to be acceptable alternatives for data aggregation. Overall, using the AHP to identify patient priorities and <b>enhance</b> the <b>user-friendliness</b> of information websites offers an important contribution to medical informatics. BMB...|$|R
40|$|As {{the world}} {{population}} rises, {{there is an}} increase in agricultural production, which has compromised safe water consumption for many demographics. Phosphate, a compound commonly used in agriculture fertilizers, leaks into local water sources contaminating the resource for its consumers 1. Since high levels of phosphate lead to osteoporosis, kidney damage and digestive issues in humans as well as eutrophication and destruction of natural ecosystems, the Environmental Protection Agency in the United States has limited phosphate levels to 25 parts per billion in lakes and reservoirs 2, 3. To combat the issue of phosphate contamination, widespread testing is necessary in affected areas, however current testing methods are expensive, off-site and time consuming. Since affected areas mainly comprise of developing nations, {{there is a need for}} an affordable and user-friendly phosphate testing platform. With our research, we present an affordable, rapid, user-friendly, and sensitive electrochemical phosphate sensor that has the ability to test water samples and provide immediate nutrient diagnosis. The electrochemical sensor is composed of a three-electrode system and utilizes voltammetry for the detection of phosphate. The working, counter and reference electrodes are printed in carbon, platinum, and silver ink respectively onto a glass substrate. The sensor is then connected to an electrochemical analyzer which will apply voltammetry with a voltage range from 0. 6 V to - 0. 3 V and a voltage scan rate of 1 V/s. Current peaks are then analyzed and correspond to the concentration of phosphate in the tested solution. From test experiments with our sensor, phosphate concentrations as low as 10 parts per billion are detectable. The sensor will combine with a hand-held portable potentiostat and a mobile application to <b>enhance</b> the <b>user-friendliness,</b> speed, and affordability of phosphate detection in water. Our device has the ability to accurately test phosphate concentration in water samples and effectively communicate the results to its users. This rapid detection system contributes to improved water sanitation and global health...|$|R
40|$|This thesis {{details the}} design and {{development}} of an intelligent prosthetic hand based on hybrid DC and Shape Memory Alloy (SMA) actuation and controlled by only two myoelectric sensors. A prosthesis as a tool makes no pretence of trying to replace the lost limb physiologically but it works {{as an aid to}} help provide some of the lost functions and is an interchangeable device worn and used as needed. Much research has been carried out to develop artificial prosthetic hands with capabilities similar to the human hand. The human hand is a very complex grasping tool, that can handle objects of different size, weight and shape; however, they are far from providing its manipulation capabilities. This is for many different reasons, such as active bending is limited to two or three joints and user-unfriendliness. These limitations are present in commercial prosthetic hands, together with others always complained about by patients and amputees, such as inability to provide enough grasping functionality and heavy weight. Several robotic and anthropomorphic hands may have sufficient active degrees of freedom to allow dexterity comparable to that of the human hand. Unfortunately, they cannot be used as prostheses due to their physical characteristic that poses several serious limitations on human-hand interaction. Hence, the motivation for this research is to investigate the use of a hybrid actuation mechanism in {{the design and}} development of an intelligent prosthetic hand. This work highlights user-friendliness and involves a proper mechanical design with more active degrees of freedom and incorporating an intelligent control system. A system with a finger prototype is considered. Testing through simulation and physical models reveals a number of limitations. A hybrid actuation system, to increase the finger active degrees of freedom is therefore developed, with a mechanism consisting of DC and SMA actuators. Besides, only two myoelectrodes channels (<b>enhancing</b> the <b>user-friendliness</b> of the device) are used for the system control input signal. Two novel features are developed in the new prosthetic hand. Firstly, its hybrid actuation mechanism has the advantage of increasing the active degrees of freedom; secondly, using only two myoelectric sensors has potential for controlling more than three patterns of fingers movements. By using artificial neural network patterns classification technique, three and five patterns of wrist joint movement corresponding to finger movement can be recognised as more than 85 % correct and furthermore, seven as 70 % correct. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Despite {{the strong}} {{emphasis}} on large N designs in most statistical and methodological courses and handbooks, single-case designs are gaining popularity. They can provide a viable alternative or supplement to group studies to investigate causal research questions. This could be the case when it is unnecessary to collect data from {{a large group of}} subjects (e. g., generating pilot data) or when this is impossible (e. g., studying rare conditions). Although several data-analytic techniques have been suggested for the analysis of single-case experiments, visual analysis still remains the predominant method. An important reason is the absence of these techniques in popular statistical packages. The focus of this doctoral research project is on providing user-friendly tools for analyzing single-case data. As a statistical technique, randomization tests were selected, because they are promising for analyzing the specific data resulting from single-case experiments. For the software development, the statistical programming language R was chosen. To <b>enhance</b> the <b>user-friendliness,</b> an implementation in the window-based graphical user interface, the R commander, was also created. The developed software is presented in six separate manuscripts and contains functions for three important steps in analyzing single-case data: visual exploration, statistical significance testing, and effect size calculation. Manuscript 1 presents the SCVA package, which helps researchers in making graphical representations of single-case data and to transform graphical displays back to raw data. Manuscript 2 introduces the SCRT package for designing single-case phase and alternation experiments, as well as for conducting randomization tests on data resulting from these experiments. In manuscript 3, a systematic review on the use of multiple baseline designs is provided. Since it was found that most multiple baseline studies in the sample data relied solely on visual analysis of the data, in manuscript 4 an extension of the SCRT package is presented for use with multiple baseline data. Manuscript 5 explains the use of the SCMA package, with functions for probability combining and effect size calculation. In manuscript 6, all functionalities are combined in the RcmdrPlugin. SCDA package: a window-based graphical user interface, which overcomes the difficulties of the command line interface of R. By making these data-analytic tools available and assemble them in one overarching user-friendly system, we wish to contribute to their familiarity with applied researchers, and hence their increased use in empirical studies. The scripts could also be used in stochastic simulation studies, and in this way add to the knowledge on the statistical properties of effect size measures and statistical techniques for single-case data. status: publishe...|$|R
40|$|Oxidoreductases {{are found}} in all living organisms and play {{essential}} roles in housekeeping, perception of environmental stress, plant-pathogen interactions, defense reactions, and pathogenicity. In particular, laccase, peroxidases and NADPH oxidase, have been implicated in virulence of phytopathogenic fungi in pathogenicity. Despite its relevance towards plant microbe interaction, the identification and comparative analysis of fungal peroxidase-encoding genes at the genomic level have been limited {{by the lack of}} a bioinformatics platform as well as paucity of information on transcript profiling of potential candidate oxidoreductase genes. In this project, one of the primary tasks addressed was the construction and development of a new fungal peroxidase database (fPoxDB). The availability of fPoxDB platform facilitated comparative and evolutionary studies of fungal peroxidases at the genomic level. The database contains 6, 113 peroxidase genes of 25 gene families from 331 genomes. The archived genes were subjected to pre-computational analyses using eight different bioinformatic tools: SignalP 3. 0, SecretomeP 1. 0 f, TargetP 1. 1 b, predictNLS, ChloroP 1. 1, TMHMM 2. 0 c, PSortII, and InterPro Scan. Similarity search tools including HMMER, ClustalW, Blast, and BlastMatrix are provided on the platform. A web interface enables researchers to browse the database via either species or class. Graphics support the work and <b>enhance</b> <b>user-friendliness.</b> Retrieved data can be exported to other family web-systems including the comparative fungal genomics platform (CFGP). In parallel to the above study, the second project was focused on in silico comparative analysis fungal NADPH oxidase (Nox) genes sequences. Nox proteins are transmembrane enzymes found in most eukaryotic organisms and influence many biological processes by generating reactive oxygen species (ROS). In fungi, Nox enzymes play roles in pathogenicity, such as the weakening of plant cell walls by ROS. The enzymes exhibit high sequence similarities to the ferric-reductases (Fre) and ferric-chelate reductases (FRO) proteins, which are involved in reduction of Fe 3 + to Fe 2 + for iron uptake. A total of 34 eukaryotic genomes, covering 28 fungal, one Oomycota, three animal and two plant species, were subjected to bioinformatic analysis. The results indicate that the properties of fungal Nox genes differ from those of the human and plants, providing novel insights that will enable more accurate identification and characterization of the fungal genes. In the third project, as not much is known is about precise role of oxidoreductase encoding genes in pathogenesis, we explored expression profiling of a typical oxidoreductase gene, laccase, in Heterobasidion conifer pathosystem. Laccases are multi-copper oxidoreductases catalyzing the oxidation of phenolic substrates, and they play diverse roles in plants and fungi. In fungi, laccase {{have been shown to be}} involved in pathogenicity, as well as in lignin degradation. To understand the potential roles of laccases of the forest pathogen Heterobasidion annosum, a total of 18 laccase genes was identified in this fungus and phylogenetically analyzed. The expression levels of the genes, and laccase activities, during growth of H. annosum on its host in the presence or absence of additional carbon source, such as glucose and sucrose, were investigated. Based on increased transcript expression levels eight laccases were considered to be potentially involved in H. annosum virulence. In summary, we provide the research community with a database dedicated to fungal peroxidases, and our in silico analysis affords new insights in the structure of fungal NADPH oxidases. Lastly, we present experimental evidence that some H. annosum laccases might be involved in virulence during infection of non-suberized Scots pine seedlings. Oksidoreduktaasit ovat kaikkien eliöiden aineenvaihdunnalle tärkeitä entsyymeitä. Niiden toiminta liittyy ympäristön aiheuttaman stressin sietokykyyn, kasvien ja taudinaiheuttajien väliseen vuorovaikutukseen, puolustautumiseen ja taudinaiheuttamiskykyyn. Taudinaiheuttajille erityisen tärkeitä ovat lakkaasit, peroksidaasit ja NADPH-oksidaasit. Sienten peroksidaasigeenien tunnistaminen ja vertailu ei ole kuitenkaan ollut mahdollista siihen sopivien bioinformatiikkasovellusten puuttuessa, ja myös oksidoredukstaasigeenien transkrtiptio on tunnettu huonosti. Tutkimuksessa kehitettiin uusi sienten peroksidaasitietokanta (fPoxDB), joka sisältää 6 113 peroksidaasigeeniä ja 25 geeniperhettä yhteensä 331 sienen genomista. Tietokannan geenit analysoitiin kahdeksalla eri bioinformatiikkatyökalulla (SignalP 3. 0, SecretomeP 1. 0 f, TargetP 1. 1 b, predictNLS, ChloroP 1. 1, TMHMM 2. 0 c, PSortII, ja InterPro Scan). Tietokantasovellus sisältää HMMER, ClustalW, Blast, and BlastMatrix vertailualgoritmit ja se mahdollistaa genomitason vertailun ja evolutiiviset tutkimukset. Käyttäjät voivat tehdä graafisesti tuettuja tietokantahakuja sienilajien tai geeniluokkien perusteella. Haettu data voidaan viedä verkossa toimiviin analyysipalveluihin, kuten Comparative Fungal Genomics Platform (CFGP). Tutkimuksessa vertailtiin NADPH oxidaasigeenien (Nox) sekvenssejä. Nox proteiinit ovat useimmista aitotumallisista eliöistä löytyviä solukalvon entsyymeitä, jotka osallistuvat useisiin biologisiin prosesseihin tuottamalla reaktiivisia happiyhdisteitä (ROS). Sienten Nox entsyymit liittyvät patogeenisuuteen, kuten kasvin soluseinän heikentämiseen. Tulokset osoittavat, että entsyymejä koodaavat sekvenssit olivat hyvin samankaltaisia kuin raudan (Fre) ja rautakelaatin reduktaasiproteiinit (FRO), jotka liittyvät raudan pelkistymiseen solujen aineenvaihdunnassa. Yhteensä 34 aitotumallisen genomin (28 sientä, yksi munasieni, kolme eläinä ja kaksi kasvia) Nox geenien sekvenssejä vertailtiin. Tulosten mukaan sienten Nox geenit ovat hyvin erilaisia verrattuna ihmisen ja kasvien geeneihin. Tutkimus avasi myös uusia näkökulmia sienten geenien tunnistamiseen ja karakterisointiin. Oksidoreduktaasien toimintaa selvitettiin juurikäävän ja männyn vuorovaikutuksessa. Lakkaasit ovat oksidoreduktaaseja, jotka hapettavat fenoliyhdisteitä, ja niillä on useita rooleja kasvien ja sienten aineenvaihdunnassa. Sienillä lakkaasit liittyvät patogeenisuuteen ja ligniinin hajottamiseen. 18 juurikäävän lakkaasigeeniä tunnistettiin ja analysoitiin. Geenien ilmenemistä seurattiin juurikäävän kasvaessa isäntäkasvillaan ja lisäksi tutkittiin geenien ilmenemisen muutoksia glukoosin ja sakkaroosin vaikutuksesta. Yhteensä kahdeksan lakkaasi-entsyymin pääteltiin liittyvän sienen virulenssiin...|$|R
40|$|The {{ultimate}} goal of contemporary restorative dentistry is to partially or completely replace compromised or lost tooth tissue using a minimally invasive treatment strategy. In both cases, a complex biomechanical entity is formed at the interface between biomaterials and mineralized hard tissues, which ultimately controls the premature failure of tooth restorations and dental implants. The overall {{aim of this study}} was to characterize the micro-pathogenesis of interface failure with mineralized hard tissues, by performing a comprehensive characterization of interaction mechanisms and optimization strategies for clinically relevant and challenging interfaces. Moreover, we have also developed and applied advanced characterization techniques based on recently developed ion-beam sample preparation techniques and quantitative 3 D electron microscopy analysis of hard tissue-biomaterial interfaces. The first part of this thesis focused on tooth-glass ionomer interfaces, which, despite their excellent bonding retention in clinical trials, are a challenge to mechanical testing and structural characterization due to their inherent brittleness, reactivity and solubility. Our aim was thus to develop and test new restorative strategies with glass ionomers that were free from their current limitations (papers 2 & 3), based on a better understanding of the chemical interaction at these interfaces (paper 1). We have found through high-resolution microscopy and chemical surface analysis that the self-adhesiveness of RMGIs should be attributed to ionic bonding to hydroxyapatite that remained attached to the partially exposed collagen fibrils, as well as to micro-mechanical interlocking for those RMGIs that additionally hybridize dentin. Moreover, a distinct polycarboxylate gel resulted from an ion-exchange process between the RMGI and dentin as a particular morphologic interfacial feature, the gel-phase. Subsequently, we have determined that the self-etch technique showed very promising in vitro results when applied to glass ionomer-tooth interfaces, since it further <b>enhanced</b> the <b>user-friendliness</b> of RMGIs and lowered their technique-sensitivity, while maintaining desirable characteristics of the conventional etch-and-rinse approach with polyalkenoic acids. Finally, the investigated nano-filled RMGI exhibited adequate bond strength to dentin and enamel, at the same magnitude as other glass ionomers, on the condition that the surface was beforehand treated with the proprietary primer, thus confirming that the non-rinsing approach and specific delivery device favored the ease of use and might reduce the technique sensitivity. The second part of this thesis focused on overcoming the many limitations experienced in our previous studies with the glass ionomer-tooth interface, such as the difficult and labor-intensive sample preparation for conventional high-resolution analysis and the possible interpretation artifacts in such analysis due to reduced sampling, operator bias and/or 2 D projection of 3 D features. It was also clear that such problems were equally present in other promising, but challenging hard tissues-biomaterial interfaces, which have been studied by separate groups up to the moment, but could benefit from a more unified approach. Consequently, we have chosen to customize and apply newly-developed techniques on such interfaces. We concentrated in particular on sample preparation for high-resolution analysis (paper 4) and exploration of intensively discussed topics in the literature using multi-scale 3 D analysis, such as nanoleakage in tooth-biomaterial interfaces (paper 5) and histomorphometric analysis of bone-implant interfaces (paper 6). The FIB/BIB techniques demonstrated to be suitable preparation methodologies of toothbiomaterial interfaces for TEM and nicely complemented information obtained from ultramicrotomy-based techniques. They excelled particularly for more advanced TEM analysis, but not without compromises. Fortunately, most of them could be controlled through judicious preparation and analysis. Subsequently, we have shown that conventional nanoleakage evaluation was heavily influenced by direction, position, and inclination of field-of-view. We have also demonstrated two novel techniques to evaluate nanoleakage quantitatively in 3 D and at high resolution, and in a way that was not affected by possible artifacts with conventional techniques. Finally, we have clearly demonstrated that qualitative and quantitative 2 D-analysis of bone-implant interfaces may contain severe under- or over-estimation of bone trabeculae, both at meso- and micro-scale. As the heterogeneity of bone-distribution parameters cannot be inferred from single histologic slices of the interface, future studies should either perform a controlled confirmation of their findings using 3 D-based techniques, or at least analyze multiple slices produced from the same specimens. 1. 	Introduction and Aims	 1 1. 1. 	Failure at tooth-biomaterial interfaces	 1 1. 2. 	Failure at bone-implant interfaces	 5 1. 3. 	Aims	 7 2. 	Glass ionomers: Bonding Mechanisms and New Technologies	 9 2. 1. 	Gel-phase formation at resin-modified glass ionomer/tooth interfaces	 11 2. 2. 	Development of a self-etch adhesive for resin-modified glass ionomers	 17 2. 3. 	Bonding effectiveness and interfacial characterization of a nano-filled resin-modified glass ionomer	 22 3. 	Advanced Characterization of Hard Tissue-Biomaterial Interfaces	 33 3. 1. 	Ultrastructural characterization of tooth–biomaterial interfaces prepared with broad and focused ion beams	 35 3. 2. 	Nanoleakage distribution at adhesive-dentin interfaces in 3 D	 48 3. 3. 	Comparative multi-scale 3 D versus 2 D analysis of bone-implant interfaces	 55 4. 	Discussion	 75 4. 1. 	On the evidence for a gel-phase at the glass ionomer interface	 80 4. 2. 	Artifacts on nanoleakage and water-tree assessment	 83 4. 3. 	Problems and solutions on 3 D data collection & analysis	 87 5. 	Conclusions	 95 nrpages: 117 status: publishe...|$|R
40|$|The {{objective}} of this thesis {{is to develop a}} functional-based approach for a relevance analysis of nanotechnology in the product planning process. This objective comprises four goals: 1. the relevance of nanotechnology for products shall be analysed and assessed by linking product-related problems (so called "problem ideas") with solution approaches of nanotechnology ("solution idea"). Thereby, new product ideas based on nanotechnology and thus new innovation potential ideas shall be identified. 2. Therefore, a formalised description of nanotechnology as an operable access is to be set up as a based on functions of nanotechnology. 3. A set of analysis and assessment methods is to be developed with a special focus on the integration of implicit knowledge. 4. The approach for product design with nanotechnology shall be integrated in the product planning process as published in VDI 2220 as part of the corporate innovation process. The possibility of nanotechnology by creating new functionalities of materials and structures through targeted and specific design in the nanometre range offers a great innovation potential. The universality and possible combinations of functional nanomaterials opens up various applications for nearly every industry. Improved product properties, a better cost-performance ratio, higher quality or novel functions for products provide an increased customer benefit. However, a significant gap can be seen between the technological 'bank' of nanotechnologies and (pro-spective) application 'banks' in practice. Solution approaches by nanotechnology are still almost unknown on the application side. Due to the dynamic technology development, nanotechnology is not yet a differentiated technology field with established application areas and structured access. Therefore, enterprises have to be systematically introduced to nanotechnology. Solution approaches by nanotechnology have {{to be taken into account}} already during the ideas generation phase in the product planning process and have to be assessed with respect to their innovation potential. However, in the early phase of idea generation, product planning view and technology view are not yet linked in order to consider novel solution approaches in the product design process. Therefore, both domains have to be brought together. In this context, suitable methods to identify problems, to analyse new technologies and to integrate specific knowledge are lacking. Ex-isting approaches show a poor suitability in practical applications and complex and unspecific methodological procedures. With the developed approach, a procedure is presented which can support enterprises in analysing the functional-based relevance of nanotechnology focused on nanomaterials and their properties. The procedure is positioned in product design within the product planning process. Relevant enterprise-specific applications fields in products ("problem ideas") are identified and selected as well as correspondent solution approaches ("solution ideas") by nanotechnology are analysed and assessed. The procedure is built on a successive, systematic discursive approach. Nanotechnology experts are involved in the analysing and assessing process as a source of implicit knowledge. A terminology based on approaches from design is developed in order to operationalise the access to nanotechnology. At the same time, an understanding about the impact manner and the recognisable connections of nanotechnology is built up. Methodical approaches like decomposition, House of Technology or portfolio analysis are adjusted. The focal point of the approach is the function as an abstraction of consumer requirements and potential solutions by nanotechnology as well as relevance criteria: so called purpose functions and system functions are combined as means-purpose-combinations. Thus, new product ideas can be obtained and assessed. Working principles of nanotechnology provide the basis to identify problem ideas as a demand for application of nanotechnology. Problem ideas represent problems, required optimisations of product specifications or the substitution of a product function. In a first assessment step, basic solution concepts represented by a system function and a nanomaterial, e. g. photocatalytic by TiO 2 nanoparticles, are searched and compared to problem ideas. The relevance is assessed based on a qualitative consideration regarding benefit (attractiveness for customers, level of innovation, market size or volume of the new product, portability of the problem to other products/ product groups/ components and consistency with strategic measures) and fulfillment of the solution. In a second assessment step, relevant solution concepts are detailed as solution ideas, e. g. regarding the corresponding substrate, technical specifications or manufacturing technology. Problem and solution idea constitute an innovation potential, e. g. the prevention of bacteria growth by photocatalytic TiO 2. Thus the developed approach focuses not only on the analysis of nanotechnology. Preceding the search for solutions, the approach contributes to the identification of specific problems as possible applications for which nanotechnology offers a principle solution. Using the proposed procedure, enterprises can obtain a starting point for innovations by nanotechnology, which can be induced by completely new means or can be radical innovations. The objective is amongst others to increase added value, optimise <b>user-friendliness,</b> <b>enhance</b> resource efficiency or realise a competitive advantage by offering a new solution principle or state of the art. The relevance analysis was applied with two producing companies, one from the capital-intensive goods and the other one from consumer goods industry. The practical application showed that the approach is well suited to identify novel and very specific applications for nanotechnology in the company's product range. Both companies received an application-specific access to nanotechnology with less expense. Nanomaterials and nanostructures with their functionality were compared to the functional requirement of potential applications. Relevant applications were chosen from a multitude of combinations of applications-sited problem ideas and nanotechnological solution concepts and thus the product ideas narrowed as problem and solution ideas. Their innovation potentials were assessed regarding the fulfilment of the benefit and the contribution of the solution. Measures were derived and defined for further monitoring or implementation. Simple methods for analysing and assessing the potential provided a transparent procedure and adaptability of the applied methods. Implicit expert knowledge was involved to search for solution concepts...|$|R
40|$|Die Nanotechnologie bietet ein großes Innovationspotenzial durch die Schaffung neuer Funktionalitäten von Materialien und Strukturen durch deren gezielte und spezifische Gestaltung im nm-Bereich. Aufgrund der Universalität und Kombinationsmöglichkeit der funktionalen Nanomaterialien eröffnen sich vielfältige Anwendungsmöglichkeiten. In der Praxis kann jedoch eine Lücke zwischen Nanotechnologie und den möglichen Anwendung identifiziert werden. Nanotechnologische Lösungsansätze sind auf Anwendungsseite nahezu unbekannt. Unternehmen müssen deshalb systematisch an die Nanotechnologie herangeführt werden. Bereits bei der Ideenfindung in der Produktplanung müssen Lösungsansätze der Nanotechnologie berücksichtigt und deren Innovationspotenzial bewertet werden. Allerdings sind in diesen frühen Phasen der Ideenfindung die Produktplanungs- und Technologiesicht noch nicht gekoppelt, um neueste technologische Lösungsansätze in die Produktfindung einfließen lassen zu können. Beide Domänen müssen hierfür zusammengeführt werden. Mit dem entwickelten Ansatz wird ein Verfahren vorgestellt, das Unternehmen bei der funktionsbasierten Analyse der Relevanz der Nanotechnologie im Rahmen der Produktfindung in der Produktplanung unterstützt. Der Schwerpunkt in der Nanotechnologie wird auf Nanomaterialien und funktionalisierte Oberflächen gelegt. Es werden {{relevante}} unternehmens-spezifische Anwendungsfelder in Produkten identifiziert und ausgewählt sowie korrespondierende Lösungsansätze der Nanotechnologie analysiert und bewertet. Das Verfahren baut auf einer Terminologie, basierend auf den Ansätzen der Konstruktion auf, um den Zugang zur Nanotechnologie zu operationalisieren. Methodische Ansätze wie De-komposition, House of Technology oder Portfolioanalyse werden angepasst. Im Zentrum des Verfahrens steht die Funktion als Abstraktion zwischen Nutzeranforderungen und den Lösungspotenzialen der Nanotechnologie sowie als Relevanzkriterium. Wirkprinzipen der Nanotechnologie liegen der Identifikation von Problemideen als Bedarf für den Einsatz der Nanotechnologie zugrunde. Die Relevanz wird in Bezug auf Nutzen und Lösungserfüllung qualitativ bewertet und es werden Maßnahmen abgeleitet. Das Unternehmen erhält so Ansatzpunkte für Innovationen durch die Nanotechnologie. Das Ziel ist es, u. a. den Mehrwert zu erhöhen, die Nutzerfreundlichkeit zu verbessern, die Ressourceneffizienz zu optimieren oder einen Wettbewerbsvorteil zu erzielen, indem ein neues Lösungsprinzip angewandt wird. Die Umsetzung des Verfahrens und seine Eignung wird am Beispiel von zwei Unternehmen der Investitions- und Gebrauchsgüterindustrie gezeigt. Es handelt sich um einen Hersteller von Füll- und Verpackungsmaschinen und einen Hersteller von Sanitärarmaturen. Aus einer Vielzahl an Kombinationen von anwendungsseitigen Problemen und nanotechnologischen Lösungskonzepten wurden dort sukzessiv relevante Anwendungen ausgewählt und somit Produktideen eingegrenzt. Deren Innovationspotenzial wurde hinsichtlich der Nutzenerfüllung und dem Lösungsbeitrag bewertet und Maßnahmen für die Umsetzung oder die weitere Verfolgung der Produktideen definiert. Einfache Analyse- und Bewertungsme-thoden sorgten für ein transparentes Vorgehen und die Anpassbarkeit des Methodeneinsatzes. Für die Recherche von Lösungsansätzen der Nanotechnologie wurde implizites Fachwissen genutzt. The {{objective of}} this thesis {{is to develop a}} functional-based approach for a relevance analysis of nanotechnology in the product planning process. This objective comprises four goals: 1. 	the relevance of nanotechnology for products shall be analysed and assessed by linking product-related problems (so called “problem ideas”) with solution approaches of nanotechnology (“solution idea”). Thereby, new product ideas based on nanotechnology and thus new innovation potential ideas shall be identified. 2. 	Therefore, a formalised description of nanotechnology as an operable access is to be set up as a based on functions of nanotechnology. 3. 	A set of analysis and assessment methods is to be developed with a special focus on the integration of implicit knowledge. 4. 	The approach for product design with nanotechnology shall be integrated in the product planning process as published in VDI 2220 as part of the corporate innovation process. The possibility of nanotechnology by creating new functionalities of materials and structures through targeted and specific design in the nanometre range offers a great innovation potential. The universality and possible combinations of functional nanomaterials opens up various applications for nearly every industry. Improved product properties, a better cost-performance ratio, higher quality or novel functions for products provide an increased customer benefit. However, a significant gap can be seen between the technological ‘bank’ of nanotechnologies and (pro-spective) application ’banks’ in practice. Solution approaches by nanotechnology are still almost unknown on the application side. Due to the dynamic technology development, nanotechnology is not yet a differentiated technology field with established application areas and structured access. Therefore, enterprises have to be systematically introduced to nanotechnology. Solution approaches by nanotechnology have {{to be taken into account}} already during the ideas generation phase in the product planning process and have to be assessed with respect to their innovation potential. However, in the early phase of idea generation, product planning view and technology view are not yet linked in order to consider novel solution approaches in the product design process. Therefore, both domains have to be brought together. In this context, suitable methods to identify problems, to analyse new technologies and to integrate specific knowledge are lacking. Ex-isting approaches show a poor suitability in practical applications and complex and unspecific methodological procedures. With the developed approach, a procedure is presented which can support enterprises in analysing the functional-based relevance of nanotechnology focused on nanomaterials and their properties. The procedure is positioned in product design within the product planning process. Relevant enterprise-specific applications fields in products (“problem ideas”) are identified and selected as well as correspondent solution approaches (“solution ideas”) by nanotechnology are analysed and assessed. The procedure is built on a successive, systematic discursive approach. Nanotechnology experts are involved in the analysing and assessing process as a source of implicit knowledge. A terminology based on approaches from design is developed in order to operationalise the access to nanotechnology. At the same time, an understanding about the impact manner and the recognisable connections of nanotechnology is built up. Methodical approaches like decomposition, House of Technology or portfolio analysis are adjusted. The focal point of the approach is the function as an abstraction of consumer requirements and potential solutions by nanotechnology as well as relevance criteria: so called purpose functions and system functions are combined as means-purpose-combinations. Thus, new product ideas can be obtained and assessed. Working principles of nanotechnology provide the basis to identify problem ideas as a demand for application of nanotechnology. Problem ideas represent problems, required optimisations of product specifications or the substitution of a product function. In a first assessment step, basic solution concepts represented by a system function and a nanomaterial, e. g. photocatalytic by TiO 2 nanoparticles, are searched and compared to problem ideas. The relevance is assessed based on a qualitative consideration regarding benefit (attractiveness for customers, level of innovation, market size or volume of the new product, portability of the problem to other products/ product groups/ components and consistency with strategic measures) and fulfillment of the solution. In a second assessment step, relevant solution concepts are detailed as solution ideas, e. g. regarding the corresponding substrate, technical specifications or manufacturing technology. Problem and solution idea constitute an innovation potential, e. g. the prevention of bacteria growth by photocatalytic TiO 2. Thus the developed approach focuses not only on the analysis of nanotechnology. Preceding the search for solutions, the approach contributes to the identification of specific problems as possible applications for which nanotechnology offers a principle solution. Using the proposed procedure, enterprises can obtain a starting point for innovations by nanotechnology, which can be induced by completely new means or can be radical innovations. The objective is amongst others to increase added value, optimise <b>user-friendliness,</b> <b>enhance</b> resource efficiency or realise a competitive advantage by offering a new solution principle or state of the art. The relevance analysis was applied with two producing companies, one from the capital-intensive goods and the other one from consumer goods industry. The practical application showed that the approach is well suited to identify novel and very specific applications for nanotechnology in the company’s product range. Both companies received an application-specific access to nanotechnology with less expense. Nanomaterials and nanostructures with their functionality were compared to the functional requirement of potential applications. Relevant applications were chosen from a multitude of combinations of applications-sited problem ideas and nanotechnological solution concepts and thus the product ideas narrowed as problem and solution ideas. Their innovation potentials were assessed regarding the fulfilment of the benefit and the contribution of the solution. Measures were derived and defined for further monitoring or implementation. Simple methods for analysing and assessing the potential provided a transparent procedure and adaptability of the applied methods. Implicit expert knowledge was involved to search for solution concepts...|$|R

