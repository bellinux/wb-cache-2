116|167|Public
40|$|Abstract — In this paper, {{we propose}} {{a simple but}} {{effective}} shadow removal method using a single input image. We first derive a 2 -D <b>intrinsic</b> <b>image</b> from a single RGB camera image based solely on colors, particularly chromaticity. We next present a method to recover a 3 -D <b>intrinsic</b> <b>image</b> based on bilateral filtering and the 2 -D <b>intrinsic</b> <b>image.</b> The luminance contrast in regions with similar surface reflectance due to geometry and illumination variances is effectively reduced in the derived 3 -D <b>intrinsic</b> <b>image,</b> while the contrast in regions with different surface reflectance is preserved. However, the <b>intrinsic</b> <b>image</b> contains incorrect luminance values. To obtain the correct luminance, we decompose the input RGB image and the <b>intrinsic</b> <b>image.</b> Each image is decomposed into a base layer and a detail layer. We obtain a shadow-free image by combining the base layer from the input RGB image and the detail layer from the <b>intrinsic</b> <b>image</b> such that {{the details of the}} <b>intrinsic</b> <b>image</b> are transferred to the input RGB image from which the correct luminance values can be obtained. Unlike previous methods, the presented technique is fully automatic and does not require shadow detection. Index Terms — Bilateral filter, chromaticity, <b>intrinsic</b> <b>image.</b> I...|$|E
40|$|We {{present a}} method for decomposing a single face {{photograph}} into its <b>intrinsic</b> <b>image</b> components. <b>Intrinsic</b> <b>image</b> decomposition has commonly been used to facilitate image editing operations such as relighting and re-texturing. Although current single-image <b>intrinsic</b> <b>image</b> methods are able to obtain an approximate decomposition, image operations involving the human face require greater accuracy since slight errors can lead to visually disturbing results. To improve decomposition for faces, we propose to utilize human face priors as constraints for <b>intrinsic</b> <b>image</b> estimation. These priors include statistics on skin reflectance and facial geometry. We also make use of a physically-based model of skin translucency to heighten accuracy, {{as well as to}} further decompose the reflectance image into a diffuse and a specular component. With the use of priors and a skin reflectance model for human faces, our method is able to achieve appreciable improvements in <b>intrinsic</b> <b>image</b> decomposition over more generic techniques. Skin Reflectance Model [3] • Outgoing radiance can be separated into a specular reflectance com-ponent and a diffuse subsurface scattering component. • Specular reflectance is the integration of BRDF fs over all incoming illumination directions ωi. • Diffuse subsurface scattering is the integration of BSSRDF Bd over incoming illumination and local subsurface scattering...|$|E
40|$|In this paper, {{we present}} a novel <b>intrinsic</b> <b>image</b> {{recovery}} approach using optimization. Our approach {{is based on the}} assumption of in a local window in natural images. Our method adopts a premise that neighboring pixels in a local window of a single image having similar intensity values should have similar reflectance values. Thus the <b>intrinsic</b> <b>image</b> decomposition is formulated by optimizing an energy function with adding a weighting constraint to the local image properties. In order to improve the <b>intrinsic</b> <b>image</b> extraction results, we specify local constrain cues by integrating the user strokes in our energy formulation, including constant-reflectance, constant-illumination and fixed-illumination brushes. Our experimental results demonstrate that our approach achieves a better recovery of intrinsic reflectance and illumination components than by previous approaches...|$|E
40|$|<b>Intrinsic</b> <b>images,</b> {{including}} reflectance and illumination images, are {{desirable to}} many vision applications. An improved method for extracting <b>intrinsic</b> <b>images</b> {{from a single}} color image with integrated measures is presented. To start with, the input image convolves with a predefined set of derivative filters. The pixels of filtered images are then classified into reflectance-related or illumination-related using a criterion measure comprising three measures of filtered pixels calculated from the input image. The three measures are denoted as chromatic measure, blur measure, and intensity measure. Finally, the <b>intrinsic</b> <b>images</b> of the input image can be computed from the classification results of the filtered images. Both synthetic and real images have been utilized in our experiments. The results demonstrated that the proposed technique can effectively extract the <b>intrinsic</b> <b>images</b> from a single <b>image.</b> KEY WORDS <b>Intrinsic</b> <b>images,</b> reflectance, chromatic measure, blur measure, intensity measure 1...|$|R
40|$|In {{this paper}} {{a method for}} the {{extraction}} of shading and reflectance <b>intrinsic</b> <b>images</b> from a single uncalibrated image is presented. It {{is based on the}} classification of the image derivatives as either caused by shading or reflectance effects, using an illumination-invariant image to guide this classification. Our approach avoids the learning process – which requires ground truth <b>intrinsic</b> <b>images</b> – and obtain results comparable with the state of the art. Index Terms — Reflectance Recovery, <b>Intrinsic</b> <b>Images</b> 1...|$|R
40|$|A {{technique}} for extracting <b>intrinsic</b> <b>images,</b> including the reflectance and illumination images, {{from a single}} color image is presented. The technique first convolves the input image with a prescribed set of derivative filters. The pixels of filtered images are then classified into reflectance-related or illumination-related based {{on a set of}} chromatic characteristics of pixels calculated from the input image. Chromatic characteristics of pixels are defined by a photometric reflectance model based on the Kubelka-Munk color theory. From the classification results of the filtered <b>images,</b> the <b>intrinsic</b> <b>images</b> of the input image can be computed. Real images have been utilized in our experiments. The results have indicated that the proposed technique can effectively extract the <b>intrinsic</b> <b>images</b> from a single image. 1...|$|R
40|$|In this paper, {{we present}} a novel {{high-quality}} <b>intrinsic</b> <b>image</b> recovery approach using optimization and user scribbles. Our approach {{is based on the}} assumption of color characteristics in a local window in natural images. Our method adopts a premise that neighboring pixels in a local window having similar intensity values should have similar reflectance values. Thus, the <b>intrinsic</b> <b>image</b> decomposition is formulated by minimizing an energy function with the addition of a weighting constraint to the local image properties. In order to improve the <b>intrinsic</b> <b>image</b> decomposition results, we further specify local constraint cues by integrating the user strokes in our energy formulation, including constant-reflectance, constant-illumination, and fixed-illumination brushes. Our experimental results demonstrate that the proposed approach achieves a better recovery result of intrinsic reflectance and illumination components than the previous approaches...|$|E
40|$|IEEE Computer Society and U. Colorado at Colorado Springs     In this paper, {{we present}} a novel <b>intrinsic</b> <b>image</b> {{recovery}} approach using optimization. Our approach {{is based on the}} assumption of color characteristics in a local window in natural images. Our method adopts a premise that neighboring pixels in a local window of a single image having similar intensity values should have similar reflectance values. Thus the <b>intrinsic</b> <b>image</b> decomposition is formulated by optimizing an energy function with adding a weighting constraint to the local image properties. In order to improve the <b>intrinsic</b> <b>image</b> extraction results, we specify local constrain cues by integrating the user strokes in our energy formulation, including constant-reflectance, constantillumination and fixed-illumination brushes. Our experimental results demonstrate that our approach achieves a better recovery of intrinsic reflectance and illumination components than by previous approaches. </p...|$|E
40|$|The <b>intrinsic</b> <b>image</b> {{decomposition}} aims {{to retrieve}} “intrinsic” properties of an image, such as shading and reflectance. To {{make it possible}} to quantitatively compare different approaches to this problem in realistic settings, we present a ground-truth dataset of <b>intrinsic</b> <b>image</b> decompositions for a variety of real-world objects. For each object, we separate an image of it into three components: Lambertian shading, reflectance, and specularities. We use our dataset to quantitatively compare several existing algorithms; we hope that this dataset will serve as a means for evaluating future work on intrinsic images. 1...|$|E
40|$|The {{first step}} is the {{analysis}} of oriented texture consists of the extraction of an orientation field. The orientation field is comprised of the angle and coherence images, which describe at each point the dominant local orientation and degree of anisotropy, respectively. A new algorithm for computing the orientation field for a flow-like texture is presented. The basic idea behind the algorithm is to use an oriented filter, namely the gradient of Gaussian, and perform manipulations on the resulting gradient vector field. The {{most important aspect of}} the new algorithm is that it is provably optimal in estimating the local orientation of an oriented texture. An added strength of the algorithm is that it is simpler and has a better signal-to-noise ratio than previous approaches, because it employs fewer derivative operations. We also propose a new measure of coherence, which works better than previous measures. The estimates for orientation and coherence are related to measures in the statistical theory of directional data. We advocate the use of the angle and coherence <b>images</b> as <b>intrinsic</b> <b>images.</b> An analysis of oriented textures will require the computation of these <b>intrinsic</b> <b>images</b> as a first step. In this sense, the computation of the orientation field, resulting in the <b>intrinsic</b> <b>images,</b> is indispensible in the analysis of oriented textures. We provide results from several experiments to indicate the usefulness of the angle and coherence <b>intrinsic</b> <b>images.</b> These results show that the notion of scale {{plays an important role in}} the interpretation of textures. Further, measures defined on these <b>intrinsic</b> <b>images</b> are useful for the inspection of surfaces...|$|R
40|$|Abstract Shading and {{reflectance}} images, {{which are}} commonly called <b>intrinsic</b> <b>images,</b> {{are useful in}} many computer vision applications. A number of methods have been proposed to extract those images. Unfortunately, all of these methods assume diffuse only reflections and deem highlights to be outliers. To overcome the presence of highlights, usually reflection compo-nents separation is applied before attempting to recover <b>intrinsic</b> <b>images.</b> However, {{it is well known}} that reflection components separation itself is an intractable task that could pose additional problems. In this paper, we present a method that not only extracts the <b>intrinsic</b> <b>images</b> from an image with highlights but also decomposes the image reflection components in a single integrated framework. By considering reflection components as part of <b>image</b> <b>intrinsic</b> properties, and then using our method, we can extract four type properties: shading image, reflectance image, diffuse reflection component and specular reflection component. The method requires only a single image, without knowledge of the 3 D geometrical data of the objects. The method is based on the specular-free image, a diffuse component pseudo image that has a geometrical profile exactly identi-cal to the diffuse component of the input image, and can be generated using a local (pixel-based) operation. The method is effective even if the input image has textured surfaces. Key words <b>Intrinsic</b> <b>images,</b> reflection components separation, specular reflections, diffuse reflections, shading and re-flectance images. 1...|$|R
40|$|Densely-sampled image {{representations}} such as {{the light}} eld or Lumigraph have been effective in enabling pho-torealistic image synthesis. Unfortunately, lighting inter-polation with such representations has not {{been shown to be}} possible without the use of accurate 3 D geometry and surface reectance properties. In this paper, we propose an approach to image-based lighting interpolation that is based on estimates of geometry and shading from relatively few images. We decompose captured light elds at different lighting conditions into <b>intrinsic</b> <b>images</b> (reectance and il-lumination images), and estimate view-dependent scene ge-ometries using multi-view stereo. We call the resulting rep-resentation an Intrinsic Lumigraph. In {{the same way that the}} Lumigraph uses geometry to permit more accurate view interpolation, the Intrinsic Lumigraph uses both geometry and <b>intrinsic</b> <b>images</b> to allow high-quality interpolation at different views and lighting conditions. Joint use of geom-etry and <b>intrinsic</b> <b>images</b> is effective in the computation of shadow masks for shadow prediction at new lighting condi-tions. We illustrate our approach with images of real scenes. ...|$|R
40|$|Intrinsic {{decomposition}} from {{a single}} image is a highly challenging task, due to its inherent ambiguity and the scarcity of training data. In contrast to traditional fully supervised learning approaches, {{in this paper we}} propose learning <b>intrinsic</b> <b>image</b> decomposition by explaining the input image. Our model, the Rendered Intrinsics Network (RIN), joins together an image decomposition pipeline, which predicts reflectance, shape, and lighting conditions given a single image, with a recombination function, a learned shading model used to recompose the original input based off of <b>intrinsic</b> <b>image</b> predictions. Our network can then use unsupervised reconstruction error as an additional signal to improve its intermediate representations. This allows large-scale unlabeled data to be useful during training, and also enables transferring learned knowledge to images of unseen object categories, lighting conditions, and shapes. Extensive experiments demonstrate that our method performs well on both <b>intrinsic</b> <b>image</b> decomposition and knowledge transfer. Comment: NIPS 2017, project page: [URL]...|$|E
40|$|We {{introduce}} {{a new approach to}} <b>intrinsic</b> <b>image</b> decomposition, the task of decomposing a single image into albedo and shading components. Our strategy, which we term direct intrinsics, is to learn a convolutional neural network (CNN) that directly predicts output albedo and shading channels from an input RGB image patch. Direct intrinsics is a departure from classical techniques for <b>intrinsic</b> <b>image</b> decomposition, which typically rely on physically-motivated priors and graph-based inference algorithms. The large-scale synthetic ground-truth of the MPI Sintel dataset {{plays a key role in}} training direct intrinsics. We demonstrate results on both the synthetic images of Sintel and the real images of the classic MIT <b>intrinsic</b> <b>image</b> dataset. On Sintel, direct intrinsics, using only RGB input, outperforms all prior work, including methods that rely on RGB+Depth input. Direct intrinsics also generalizes across modalities; it produces quite reasonable decompositions on the real images of the MIT dataset. Our results indicate that the marriage of CNNs with synthetic training data may be a powerful new technique for tackling classic problems in computer vision. Comment: International Conference on Computer Vision (ICCV), 201...|$|E
40|$|While {{invaluable}} {{for many}} computer vision applications, decomposing a natural image into intrinsic reflectance and shading layers represents a challenging, underdetermined inverse problem. As opposed to strict reliance on conventional optimization or filtering solutions with strong prior assumptions, deep learning-based approaches {{have also been}} proposed to compute <b>intrinsic</b> <b>image</b> decompositions when granted access to sufficient labeled training data. The downside is that current data sources are quite limited, and broadly speaking {{fall into one of}} two categories: either dense fully-labeled images in synthetic/narrow settings, or weakly-labeled data from relatively diverse natural scenes. In contrast to many previous learning-based approaches, which are often tailored to the structure of a particular dataset (and may not work well on others), we adopt core network structures that universally reflect loose prior knowledge regarding the <b>intrinsic</b> <b>image</b> formation process and can be largely shared across datasets. We then apply flexibly supervised loss layers that are customized for each source of ground truth labels. The resulting deep architecture achieves state-of-the-art results on all of the major <b>intrinsic</b> <b>image</b> benchmarks, and runs considerably faster than most at test time...|$|E
40|$|Abstract. Intrinsicimagesrepresenttheunderlyingpropertiesofascene such as {{illumination}} (shading) {{and surface}} reflectance. Extracting <b>intrinsic</b> <b>images</b> is a challenging, ill-posed problem. Human performance on {{tasks such as}} shadow detection and shape-from-shading is improved by adding colour and texture to surfaces. In particular, when a surface is painted with a textured pattern, correlations between local mean luminance and local luminance amplitude promote the interpretation of luminance variations as illumination changes. Based on this finding, we propose a novel feature, local luminance amplitude, to separate illumination and reflectance, and a framework to integrate this cue with hue and texture to extract <b>intrinsic</b> <b>images.</b> The algorithm uses steerable filters to separate images into frequency and orientation components and constructs shading and reflectance images from weighted combinations of these components. Weights are determined by correlations between correspondingvariations inlocal luminance, local amplitude,colour andtexture. The <b>intrinsic</b> <b>images</b> are further refined by ensuring the consistency of local texture elements. We test this method on surfaces photographed under different lighting conditions. The effectiveness of the algorithm is demonstrated bythecorrelation between ourintrinsic images andground truth shading and reflectance data. Luminance amplitude {{was found to be}} a useful cue. Results are also presented for natural images. ...|$|R
40|$|Recovering <b>intrinsic</b> <b>images</b> {{from natural}} photos {{is one of}} the {{foundational}} problems in computer vision. This mission always falls into an ill-posed problem. In order to attain reasonable estimations, one strategy is to use multiple images of the scene under various lightings so as to narrow the solution space, whereas another is to utilize priori knowledge as constraints. In this paper, we present an approach to deriving <b>intrinsic</b> <b>images</b> (including illumination images and reflectance images) that employs both strategies. Specifically, the Total Variation (TV) constraint is imposed because of its excellent edge preservation ability and simple parameter settings. To solve this objective function efficiently, we propose using the Alternating Direction Method of Multipliers (AD-MM) to build an iterative numerical scheme. Experimental results illustrate the effectiveness of the proposed model and the numerical scheme...|$|R
40|$|Stereo {{correspondence}} is {{a central}} issue in computer vision. The traditional approach involves extracting image features, establishing correspondences based on photometric and geometric criteria and nally, determine a dense disparity eld by interpolation. In this context, occlusions are considered as undesirable artifacts and often ignored. The challenging problems addressed in this paper are a) nding an image representation that facilitates (or even trivializes) the matching procedure and, b) detecting and including occlusion points in such representation. We propose a new <b>image</b> representation called <b>Intrinsic</b> <b>Images</b> {{that can be used}} to solve correspondence problems within a natural and intuitive framework. <b>Intrinsic</b> <b>images</b> combine photometric and geometric descriptors of a stereo image pair. We extend this framework to deal with occlusions and brightness changes between two views. We show that this new representation greatly simplies the computation of dense dispa [...] ...|$|R
40|$|Intrinsic {{characterization}} of scenes {{is often the}} best way to overcome the illumination variability artifacts that com-plicate most computer vision problems, from 3 D reconstruc-tion to object or material recognition. This paper examines the deficiency of existing <b>intrinsic</b> <b>image</b> models to accu-rately account for the effects of illuminant color and sen-sor characteristics in the estimation of intrinsic images and presents a generic framework which incorporates insights from color constancy research to the <b>intrinsic</b> <b>image</b> decom-position problem. The proposed mathematical formulation includes information about the color of the illuminant and the effects of the camera sensors, both of which modify the observed color of the reflectance of the objects in the scene during the acquisition process. By modeling these effects...|$|E
40|$|Scene {{decomposition}} {{into its}} illuminant, shading, and re-flectance intrinsic images {{is an essential}} step for scene un-derstanding. Collecting <b>intrinsic</b> <b>image</b> groundtruth data is a laborious task. The assumptions on which the ground-truth procedures are based limit their application to simple scenes with a single object taken {{in the absence of}} indirect light-ing and interreflections. We investigate synthetic data for in-trinsic image research since the extraction of ground truth is straightforward, and it allows for scenes in more realistic sit-uations (e. g, multiple illuminants and interreflections). With this dataset we aim to motivate researchers to further explore <b>intrinsic</b> <b>image</b> decomposition in complex scenes. Index Terms — intrinsic images, synthetic data, re-flectance modeling, illuminant estimation 1...|$|E
40|$|Copyright © 2013 Qiang He, Chee-Hung Henry Chu. This is an {{open access}} article {{distributed}} under the Creative Commons Attribu-tion License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Shadow and variable illumination considerably influence the results of image understanding such as image segmenta-tion, object tracking, and object recognition. The <b>intrinsic</b> <b>image</b> decomposition is to separate the reflectance and the illumination image from an observed image. The <b>intrinsic</b> <b>image</b> decomposition is very useful to remove shadows and then improve the performance of image understanding. In this paper, we present a new shadow removal method based on <b>intrinsic</b> <b>image</b> decomposition on a single color image using the Fisher Linear Discriminant (FLD). Under the as-sumptions-Lambertian surfaces, approximately Planckian lighting, and narrowband camera sensors, there exist an in-variant image, which is 1 -dimensional greyscale and independent of illuminant color and intensity. The Fisher Linear Discriminant is applied to create the invariant image. And further the shadows can be removed through the difference between invariant image and original color image. The experimental results on real data show good performance of this algorithm...|$|E
40|$|Abstract—We {{present a}} method for {{computing}} ambient occlusion (AO) for a stack of images of a Lambertian scene from a fixed viewpoint. Ambient occlusion, a concept common in computer graphics, characterizes the local visibility at a point: it approximates how much light can reach that point from different directions without getting blocked by other geometry. While AO has received surprisingly little attention in vision, we show {{that it can be}} approximated using simple, per-pixel statistics over image stacks, based on a simplified image formation model. We use our derived AO measure to compute reflectance and illumination for objects without relying on additional smoothness priors, and demonstrate state-of-the art performance on the MIT <b>Intrinsic</b> <b>Images</b> benchmark. We also demonstrate our method on several synthetic and real scenes, including 3 D printed objects with known ground truth geometry. Index Terms—Ambient occlusion, <b>intrinsic</b> <b>images,</b> image stacks, pixel statistics F...|$|R
40|$|Deriving <b>intrinsic</b> <b>images</b> from <b>image</b> {{sequences}} <b>Intrinsic</b> <b>images</b> are {{a useful}} midlevel description of scenes proposed by Barrow and Tenenbaum [1]. An image is decomposed into two images: a reflectance image and an illumination image. Finding such a decomposition remains a difficult problem in computer vision. Here {{we focus on}} a slightly easier problem: given a sequence of Ì images where the reflectance is constant and the illumination changes, can we recover Ì illumination images and a single reflectance image? We show that this problem is still illposed and suggest approaching it as a maximum-likelihood estimation problem. Following recent work on the statistics of natural images, we use a prior that assumes that illumination images will give rise to sparse filter outputs. We show that {{this leads to a}} simple, novel algorithm for recovering reflectance images. We illustrate the algorithm’s performance on real and synthetic image sequences. ...|$|R
30|$|The {{singular}} value (SV) of the SVD {{represents the}} <b>intrinsic</b> algebraic <b>image</b> properties.|$|R
40|$|We {{propose a}} {{data-driven}} approach for <b>intrinsic</b> <b>image</b> decomposition, {{which is the}} process of inferring the confounding factors of reflectance and shading in an image. We pose this as a two-stage learning problem. First, we train a model to predict relative reflectance ordering between image patches (`brighter', `darker', `same') from large-scale human annotations, producing a data-driven reflectance prior. Second, we show how to naturally integrate this learned prior into existing energy minimization frameworks for <b>intrinsic</b> <b>image</b> decomposition. We compare our method to the state-of-the-art approach of Bell et al. on both decomposition and image relighting tasks, demonstrating the benefits of the simple relative reflectance prior, especially for scenes under challenging lighting conditions. Comment: International Conference on Computer Vision (ICCV) 201...|$|E
40|$|Mathematical {{morphology}} is {{a powerful}} tool for image analysis; however, classical morphological operators suffer from lacks of robustness against noise, and also <b>intrinsic</b> <b>image</b> features are not accounted at all in the process. We propose in this work a new and different way to overcome such limits, by introducing both robustness and locally adaptability in morphological operators, which are now defined in a manner such that <b>intrinsic</b> <b>image</b> features are accounted. Dealing with partial differential equations (PDEs) for generalized Cauchy problems, we show that proposed PDEs are equivalent to impose robustness and adaptability of corresponding sup-inf operators, to structuring functions. Accurate numerical schemes are also provided to solve proposed PDEs, and experiments conducted for both synthetic and real images, show the efficiency and robustness of our approach...|$|E
40|$|We {{report an}} <b>intrinsic</b> <b>image</b> {{distortion}} in microwave-induced thermoacoustic tomography. The distortion, due to microwave diffraction in the object to be imaged, leads to nonuniform excitation of acoustic pressure during microwave illumination. Both numerical simulations and phantom experiments demonstrate this phenomenon. A method of partial correction is also provided...|$|E
40|$|This paper {{introduces}} mesostructure roughness as {{an effective}} cue in image segmentation. Mesostructure roughness corresponds to small-scale bumps on the macrostructure (i. e., geometry) of objects. Specifically, {{the focus is on}} the texture that is created by the projection of the mesostructure roughness on the camera plane. Three <b>intrinsic</b> <b>images</b> are derived: reflectance, smooth-surface shading and mesostructure roughness shading (meta-texture images). A constructive approach is proposed for computing a metatexture image by preserving, equalizing and enhancing the underlying surface-roughness across color, brightness and illumination variations. We evaluate the performance on sample images and illustrate quantitatively that different patches of the same material, in an image, are normalized in their statistics despite variations in color, brightness and illumination. We develop an algorithm for segmentation of an image into patches that share salient mesostructure roughness. Finally, segmentation by line-based boundary-detection is proposed and results are provided and compared to known algorithms. Key words: Texture analysis, <b>image</b> segmentation, <b>intrinsic</b> <b>images.</b> ...|$|R
40|$|Computer vision systems are, on most counts, poor performers, when {{compared}} to their biological counterparts. The reason for this may be that computer vision is handicapped by an unreasonable assumption regarding {{what it means to}} see, which became prevalent as the notions of <b>intrinsic</b> <b>images</b> and of representation by reconstruction took over the field in the late 1970 ’s. Learning from biological vision may help us to overcome this handicap. 1...|$|R
40|$|Cast shadows produce {{troublesome}} {{effects for}} video surveillance systems, typically for object tracking from a fixed viewpoint, since it yields appearance variations of objects {{depending on whether}} they are inside or outside the shadow. To robustly eliminate these shadows from image sequences as a preprocessing stage for robust video surveillance, we propose a framework {{based on the idea}} of <b>intrinsic</b> <b>images.</b> Unlike previous methods for deriving <b>intrinsic</b> <b>images,</b> we derive time-varying reflectance images and corresponding illumination images from a sequence of images. Using obtained illumination images, we normalize the input image sequence in terms of incident lighting distribution to eliminate shadow effects. We also propose an illumination normalization scheme which can potentially run in real time, utilizing the illumination eigenspace, which captures the illumination variation due to weather, time of day etc., and a shadow interpolation method based on shadow hulls. This paper describes the theory of the framework with simulation results, and shows its effectiveness with object tracking results on real scene data sets for traffic monitoring. ...|$|R
40|$|The {{output from}} a color imaging sensor, or appar-ent color, can change {{considerably}} due to illumination conditions and scene geometry changes. In this work we {{take into account}} the dependence of apparent color with illumination an attempt to find appropriate color mod-els for the typical conditions found in outdoor settings. We evaluate three color based trackers, one based on hue, another based on an <b>intrinsic</b> <b>image</b> representation and the last one based on a proposed combination of a chromaticity model with a physically reasoned adap-tation of the target model. The evaluation is done on outdoor sequences with challenging illumination con-ditions, and shows that the proposed method improves the average track completeness by over 22 % over the hue-based tracker and the closeness of track by over 7 % over the tracker based on the <b>intrinsic</b> <b>image</b> repre-sentation. 1...|$|E
40|$|Blind motion {{deblurring}} from {{a single}} image is a highly under-constrained problem with many degenerate solutions. A good approximation of the <b>intrinsic</b> <b>image</b> can therefore only be obtained {{with the help of}} prior information in the form of (often non-convex) regularization terms for both the <b>intrinsic</b> <b>image</b> and the kernel. While the best choice of image priors is still a topic of ongoing investigation, this research is made more {{complicated by the fact that}} historically each new prior requires the development of a custom optimization method. In this paper, we develop a stochastic optimization method for blind deconvolution. Since this stochastic solver does not require the explicit computation of the gradient of the objective function and uses only efficient local evaluation of the objective, new priors can be implemented and tested very quickly. We demonstrate that this framework, in combination with different image priors produces results with PSNR values that match or exceed the results obtained by much more complex state-of-the-art blind motion deblurring algorithms...|$|E
40|$|Shape {{information}} has been recognised as {{playing a role in}} <b>intrinsic</b> <b>image</b> estimation since its inception. However, it is only in recent years that hints of the importance of geometry have been found in decomposing surface appearance into albedo and shading estimates. This thesis establishes the central importance of shape in intrinsic surface property estimation for static and dynamic scenes, and introduces methods for the use of approximate shape {{in a wide range of}} related problems to provide high-level constraints on shading. A key contribution is intrinsic texture estimation. This is a generalisation of <b>intrinsic</b> <b>image</b> estimation, in which appearance is processed as a function of surface position rather than pixel position. This approach has numerous advantages, in that the shape can be used to resolve occlusion, inter-reflection and attached shading as a natural part of the method. Unlike previous bidirectional texture function estimation approaches, high-quality albedo and shading textures are produced without prior knowledge of materials or lighting. Many of the concepts in intrinsic texture estimation can be extended to single-viewpoint capture for which depth information is available. Depth information greatly reduces the ambiguity of the shading estimation problem, allowing online intrinsic video to be developed for the first time. The availability of a lighting function also allows high-level temporal constraints on shading to be applied over video sequences, which previously required per-pixel correspondence between frames to be established. A number of applications of intrinsic video are investigated, including augmented reality, video stylisation and relighting, all of which run at interactive framerates. The albedo distribution of the input video is preserved, even in the case of natural scenes with complex appearance, and a globally-consistent shading estimate is obtained which remains robust over dynamic sequences. Finally, an integrated framework bridging the gaps between <b>intrinsic</b> <b>image,</b> video and texture estimation is presented for the first time. Approximate scene geometry provides a convenient means of achieving this, and is used in establishing pixel constraints between adjacent cameras, reconstructing scene lighting, and removing cast shadows and inter-reflections. This introduces a unified geometry-based approach to <b>intrinsic</b> <b>image</b> estimation and related fields, which achieves high-quality results for complex natural scenes for a wide range of capture modalities...|$|E
40|$|We {{present an}} {{algorithm}} that uses multiple cues to recover shading and reflectance <b>intrinsic</b> <b>images</b> {{from a single}} image. Using both color information and a classifier trained to recognize gray-scale patterns, each image derivative is classified as being caused by shading or {{a change in the}} surface's reflectance. Generalized Belief Propagation is then used to propagate information from areas where the correct classification is clear to areas where it is ambiguous. We also show results on real images...|$|R
40|$|In this paper, {{we present}} anapproach to colorimage understandingthat accountsforcolorvariationsdue to {{highlights}} and shading. We {{demonstrate that the}} reflected light from every point on a dielectric object. such as plastic, can be described asa linearcombination of the object color and the highlight color. The colors of all light rays reflected from one object then form a planar cluster in the color space. The shapeof this cluster {{is determined by the}} object and highlight colors and by the object shape and illumination geometry. We present a method that exploits the difference between object color and highlight color to separate the color of every pixel into a matte component and a highlight component. This generates two <b>intrinsic</b> <b>images,</b> one showing the scene without highlights, and the other one showing only the highlights. The <b>intrinsic</b> <b>images</b> may be a useful tool for a variety of algorithms in computer vision. such as stereo vision, motion analysis, shape from shading,and shapefrom highlights. Ourmethod combines the analysis of matte and highlight reflection with a sensor model that accounts for camera limitations. This enables us to successfully run our algorithm on real images taken in a laboratory setting. We show and discuss the results...|$|R
40|$|Figure 1 : Our {{algorithm}} decomposes {{an input}} <b>image</b> into its <b>intrinsic</b> <b>images</b> without user interaction. (a) Input image and scatter plot of pixel {{data in the}} (a,b) plane (Lab color space). (b) k-means segmentation according to (a,b) pixel coordinates. (c) Final clustering yielded by our method, taking into account spatial information (both (b) and (c) are depicted in false color). (d) The resulting shading and reflectance <b>intrinsic</b> <b>images.</b> The whole image is shown in Figure 5. Decomposing an input <b>image</b> into its <b>intrinsic</b> shading and reflectance components is a long-standing ill-posed problem. We present a novel algorithm that requires no user strokes and works on a single image. Based on simple assumptions about its reflectance and luminance, we first find clusters of similar reflectance in the image, and build a linear system describing the connections and relations between them. Our assumptions are less restrictive than widely-adopted Retinex-based approaches, and can be further relaxed in conflicting situations. The resulting system is robust even {{in the presence of}} areas where our assumptions do not hold. We show a wide variety of re-sults, including natural images, objects from the MIT dataset and texture images, along with several applications, proving the versatility of our method...|$|R
