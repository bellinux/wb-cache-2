7|6121|Public
5000|$|Ramtek 8210/UET <b>interactive</b> <b>data</b> <b>entry</b> {{terminal}} - {{compatible with}} UNIVAC computers ...|$|E
5000|$|GCOS 6 Mod 200 was {{an entry}} {{version of the}} system {{oriented}} toward <b>interactive</b> <b>data</b> <b>entry.</b>|$|E
40|$|The Oklahoma Geographic Information Retrieval System (OGIRS) is {{a highly}} <b>interactive</b> <b>data</b> <b>entry,</b> storage, manipulation, and display {{software}} system for use with geographically referenced data. Although originally developed for a project concerned with coal strip mine reclamation, OGIRS is capable of handling any geographically referenced data {{for a variety of}} natural resource management applications. A special effort has been made to integrate remotely sensed data into the information system. The timeliness and synoptic coverage of satellite data are particularly useful attributes for inclusion into the geographic information system...|$|E
5000|$|The term {{interactive}} editing {{is commonly used}} for modern computer-assisted manual editing. Most <b>interactive</b> <b>data</b> editing tools applied at National Statistical Institutes (NSIs) allow one to check the specified edits during or after <b>data</b> <b>entry,</b> and if necessary to correct erroneous data immediately. Several approaches can be followed to correct erroneous data: ...|$|R
5000|$|<b>Data</b> <b>entry</b> and {{conversion}} services include: academic <b>data</b> <b>entry,</b> database {{content and}} support, survey digitization, and direct marketing support.|$|R
40|$|Routine {{capture of}} patient data for a {{computer-based}} patient record system remains {{a subject of}} study. Time constraints that require fast <b>data</b> <b>entry</b> and maximal expression power {{are in favor of}} free text <b>data</b> <b>entry.</b> However, using patient data directly for decision support systems, for quality assessment, etc. requires structured <b>data</b> <b>entry,</b> which appears to be more tedious and time consuming. In this paper, a prototype clinical <b>data</b> <b>entry</b> application is described that combines free text and structured <b>data</b> <b>entry</b> in one single application and allows clinicians to smoothly switch between these two different input styles. A knowledge base involving a semantic network of clinical <b>data</b> <b>entry</b> terms and their properties and relationships is used by this application to support structured <b>data</b> <b>entry.</b> From structured <b>data,</b> sentences are generated and shown in a text processor together with the free text. This presentation metaphor allows for easy integrated presentation of structured data and free text...|$|R
40|$|Personal Electronic Health Records (EHR) have {{recently}} been published as one means to support patient empowerment and patient control over their personal health record. The functionality of such an EHR may vary from a simple web-based interface for <b>interactive</b> <b>data</b> <b>entry</b> and data review up to a much more powerful system additionally supporting electronic data/document communication between clinical information systems of primary care practitioners or hospitals and even reminder based support for the empowered citizen, to actively {{take care of his}} health, based on relevant disease management programs. Since storage and communication of data in an EHR comprises sensible personal health data, each of those functions need specific security and access management requirements to be considered and implemented. In this article the most critical requirements for these aspects will be classified and respective mechanisms to provide secure data storage and communication as well as flexible access management functions will be presented...|$|E
40|$|Includes bibliographical {{references}} (pages 109 - 110) The Los Angeles Community College District (LACCD) Data Dictionary System {{provides information}} about the data used by LACCD data processing programs. The Data Dictionary System serves as an online reference for data item, program, procedure, job, and data base definitions. It gives district administrators, systems analysts, applications maintenance programmers, and data base support personnel a mechanism for evaluating the impact of changes and additions to data definitions on application programs. The Dictionary is embedded in a transaction oriented teleprocessing system that offers users immediate access to individual data units, generates batch requests for printed reports, and allows <b>interactive</b> <b>data</b> <b>entry</b> and updating through formatted screens. The Dictionary has a menu that accesses available functions, help screens that explain each function, and messages that suggest positive actions to correct observed errors. It {{is designed to be}} user friendly and readily utilized by clerical staff as well as data processors...|$|E
40|$|Managing and facilitating data {{integrity}} {{is a critical}} element when collecting information. Many dollars are spent to actively obtain data, making it imperative to ensure the data is of the highest quality. Even with <b>interactive</b> <b>data</b> <b>entry</b> and other checks performed at time of data entry, it will often fall on the SAS programmer to find the remaining problems {{and bring them to}} light. The SAS system allows you to find, organize, and report data errors simply and effectively. This paper, written from a clinical research perspective, presents a strategy for performing and facilitating {{data integrity}} checks using SAS, including how to communicate and resolve errors with study team members. The examples shown use Base SAS ® and work for versions 6 and above. The programming presented is at a beginner’s level, but the strategy for managing data integrity applies to a broader audience. TERMS Data error – An incorrect variable value in a data set, which may include missing values. Data check – Logic placed on a variable or variables to identify data errors. Data cleaning – The process of finding data errors and fixing them. Study team – A group of people responsible for conducting a research study. Members specialize in designing and conducting the study, collecting, entering, and analyzing data, and writing publications...|$|E
50|$|While {{this method}} of quality control clearly is not proof against {{systematic}} errors or operator misread entries from a source document, it is very useful in catching and correcting random miskeyed strokes which occur even with experienced <b>data</b> <b>entry</b> operators. However, {{it proved to be}} a fatally tragic flaw in the Therac 25 incident. This method has survived the keypunch and is available in some currently available <b>data</b> <b>entry</b> programs (e.g. PSPP/SPSS <b>Data</b> <b>Entry).</b> At least one study suggests that single-pass <b>data</b> <b>entry</b> with range checks and skip rules approaches the reliability of two-pass data entry; however, it is desirable to implement both systems in a <b>data</b> <b>entry</b> application.|$|R
50|$|Founded in 1968, <b>Interactive</b> <b>Data</b> is a {{supplier}} of financial market data and related offerings. Acquisitions {{have contributed to}} <b>Interactive</b> <b>Data’s</b> growth, enabling the company to deliver an increasing range of services, while expanding into adjacent markets and extending its reach geographically.|$|R
40|$|Abstract. While many {{data mining}} models {{concentrate}} on automation and efficiency, <b>interactive</b> <b>data</b> mining models {{should focus on}} adaptive and effective communications between human users and computer systems. The crucial point is not how intelligent users are, or how efficient systems are, but how well these two parts can be connected, adapted, understood and trusted. Some fundamental issues including processes and forms of <b>interactive</b> <b>data</b> mining, roles, requirements, as well as complexities of <b>interactive</b> <b>data</b> mining systems are discussed in this paper. ...|$|R
40|$|This thesis {{describes}} {{a new technique}} for studying the non-linear behaviour of reinforced concrete frames with flexible joints. The method {{is based on the}} concept of establishing an equilibrium deflected shape of a structure. The computations involve two basic levels of iteration. First, starting with an assumed nodal deformation, equilibrium deflected shapes and end forces of individual members in a structure are calculated using moment-thrust-curvature relations. The out of balance forces are computed by considering equilibrium of member forces at nodal points. In the second level of iteration based on a numerically computed nonlinear stiffness matrix, the nodal deformation are updated until the out of balance forces are negligible. The interaction of torsion with flexure has been assumed to be independent and further, the members are assumed to behave linearly in torsion. The influence of floors and cladding is ignored and only the skeleton frame is considered in the analysis. The associated computer program SWANSA based on the above method {{can be used as a}} design tool for sway and nonsway concrete frames with or without flexible joints. An <b>interactive</b> <b>data</b> <b>entry</b> facility allows the user to enter data by answering simple questions or by returning default values. Full scale experiments were carried out on eight column beam subframes to validate the computer program. Each subframe consisted of a two storey column with a short length of a typical mid-storey beam. Four types of connection commonly used in precast construction were selected to connect the beam to the column at mid height. Two sets of subframes were made for each connection, one each of a pair of subframes was tested for upward and downward rotations. The numerical technique is further validated with results published in literature, including experiments and the finite element method. All the comparisons show that the analysis developed in this thesis can be used to predict the behaviour of precast and other reinforced concrete frames for deflections, strains and for the ultimate loads. Finally, it is shown how a computer program based on the new numerical method can be used as an alternative method of designing rigid jointed or semi-rigid jointed precast concrete 3 -dimensional frames, taking into account material and geometrical nonlinearities...|$|E
5000|$|IBM 3740 <b>Data</b> <b>Entry</b> System was a <b>data</b> <b>entry</b> {{system that}} was {{announced}} by IBM in 1973. It recorded data on a Diskette, a new recording medium from IBM, for fast, flexible, efficient <b>data</b> <b>entry</b> to either high-production, centralized operations or to decentralized, remote operations. The [...] "Diskette" [...] was more commonly known as an 8-inch floppy disk, ...|$|R
40|$|Self-service {{technologies}} have been gaining increasing importance {{in public and}} private organizations over recent years. One of the predominant responsibilities of the customers in the context of self-service is to enter their data on their own. Self-service for <b>data</b> <b>entry</b> can help organizations to further enhance the efficiency of their processes and to make customer experience smoother. However, as self-service for <b>data</b> <b>entry</b> is intended to be handled without intensive employee assistance, inexp erienced <b>data</b> <b>entry</b> can lead to data quality problems. Although academic research has explored several effects of self-service technologies, there is still a lack of research investigating the effect of self-service <b>data</b> <b>entry</b> on <b>data</b> quality. Thus, in an in-depth case study in cooperation with the German Federal Employment Agency we analyzed how customer self-service for <b>data</b> <b>entry</b> affects <b>data</b> quality and found that assisted self-service <b>data</b> <b>entry</b> leads to highest data qualit...|$|R
5000|$|<b>Data</b> <b>entry</b> by geologists in {{the field}} may take less total time than {{subsequent}} <b>data</b> <b>entry</b> in the office, potentially reducing the overall time needed to complete a project.|$|R
40|$|This thesis {{describes}} {{the development of}} an <b>interactive</b> <b>data</b> en try system for the University of Nortb carolina at Chapel Hill Automated Payroll/Personnel System. It includes the analysis of the data processing needs and the existing batch-oriented <b>data</b> <b>entry</b> system as well as the design of the new system. Major emphasis in the design criteria was placed upon pro vidin 9 the Payroll Department with complete control over its data in familiar form. This goal was accomplished througn tvo main techniques. First, the computer terminals were placed in the Payroll offices, for direct use by th~; staff. l!oreover, th~; information displayed upon the screen is formatted to resemble the original paper documents as closely as possible. The system was implemented and is in use by the Payroll Department. A brief evaluation of its performance and eff~;ctiveness is included in the thesis. A ~ IN 1 EPACTIVE PPYFOLL/PERSONNEL DATA ENThY SYSTEM b...|$|R
5000|$|Gnuplot, a {{command-line}} driven <b>interactive</b> <b>data</b> {{and function}} plotting utility ...|$|R
5000|$|Support for <b>interactive</b> <b>data</b> {{visualization}} {{and use of}} GUI toolkits.|$|R
5000|$|May 2010: U Potter’s Wheel: An <b>Interactive</b> <b>Data</b> Cleaning System ...|$|R
5000|$|SuperMICAR automates the MICAR <b>data</b> <b>entry</b> process. This {{program is}} {{designed}} as an enhancement of the earlier PC-MICAR <b>Data</b> <b>Entry</b> program. Super-MICAR is designed to automatically encode cause-of-death data into numeric entity reference numbers.|$|R
40|$|The {{objective}} {{was to determine the}} conditions under which Automatic Speech Recognition (ASR) is an efficient choice for <b>data</b> <b>entry.</b> In particular the focus was on <b>data</b> <b>entry</b> tasks that are part of constructing military messages. The ADF Formatted Messaging System utilises a structured formatting system to constrain the semantics of a message but also includes a field for unlimited and unstructured text. Hence the <b>data</b> <b>entry</b> tasks involved range from form-filling to free dictation of short phrases. In the experiments, ASR and manual input modes are compared for three <b>data</b> <b>entry</b> tasks: textual phrase entry, selection from a list, and numerical <b>data</b> <b>entry.</b> To effect fair comparisons, the tasks minimised the transaction cycle for each input mode and data type and the main comparisons use only times from correct <b>data</b> <b>entry.</b> The results indicate that for inputting short phrases ASR only competes if the typist's speed is below 45 wpm. For selecting an item from a list, ASR offered an advantage only if the list length was greater than 15 items. For entering numerical data, ASR offered no advantage over keypad or mouse. The general conclusion for formatted <b>data</b> <b>entry</b> is that a keyboard/mouse interface designed to match the data to be entered will be more time efficient than any equivalent ASR interface...|$|R
40|$|<b>Interactive</b> <b>Data</b> Exploration Using Semantic Windows[1] {{offers a}} {{solution}} to finding interesting patterns and objects from a big set of data where the users {{do not need to}} wait for the whole query to finish and have the ability to see intermediate results or receive progress updates. This project includes the visualization component of <b>Interactive</b> <b>Data</b> Exploration Using Semantic Windows. Since the <b>Interactive</b> <b>Data</b> Exploration Using Semantic Windows requires that the database should be able to execute range queries efficiently, another aspect of this project is its integration to SciDB[2] which is especially optimized for the management of big data. ...|$|R
40|$|Abstract Clustering {{is one of}} {{the major}} data mining applications. An obvious {{characteristic}} of data mining distinguished from traditional data processing is that the conclusion of data mining cannot be predicted. Data mining is a multi-step process, and user must be allowed to be the front and the center in this process, especially clustering mining method. In this paper, the necessity of <b>interactive</b> <b>data</b> mining is illustrated. A framework of high performance <b>interactive</b> <b>data</b> mining on PC-cluster is proposed, and an interactive clustering algorithm for multi-dimensional data on the framework is presented. Keywords <b>interactive</b> <b>data</b> mining, multi-dimension data mining, clustering algorith...|$|R
5000|$|GGobi {{is a free}} {{software}} for <b>interactive</b> <b>data</b> visualization data visualization ...|$|R
5000|$|Immediate {{uploading}} of {{data into}} LAPOP’s free <b>interactive</b> <b>data</b> analysis program ...|$|R
40|$|Introduction: Use of {{electronic}} health record (EHR) systems can place a considerable <b>data</b> <b>entry</b> burden upon {{the emergency department}} (ED) physician. Voice recognition <b>data</b> <b>entry</b> has been proposed as one mechanism to mitigate some of this burden; however, no reports are available specifically comparing emergency physician (EP) time use or number of interruptions between typed and voice recognition data entry-based EHRs. We designed this study to compare physician time use and interruptions between an EHR system using typed <b>data</b> <b>entry</b> versus an EHR with voice recognition. Methods: We collected prospective observational data at 2 academic teaching hospital EDs, one using an EHR with typed <b>data</b> <b>entry</b> {{and the other with}} voice recognition capabilities. Independent raters observed EP activities during regular shifts. Tasks each physician performed were noted and logged in 30 second intervals. We compared time allocated to charting, direct patient care, and change in tasks leading to interruptions between sites. Results: We logged 4, 140 minutes of observation for this study. We detected no statistically significant differences in the time spent by EPs charting (29. 4 % typed; 27. 5 % voice) or the time allocated to direct patient care (30. 7 %; 30. 8 %). Significantly more interruptions per hour were seen with typed <b>data</b> <b>entry</b> versus voice recognition <b>data</b> <b>entry</b> (5. 33 vs. 3. 47; p= 0. 0165). Conclusion: The use of a voice recognition <b>data</b> <b>entry</b> system versus typed <b>data</b> <b>entry</b> did not appear to alter the amount of time physicians spend charting or performing direct patient care in an ED setting. However, we did observe a lower number of workflow interruptions with the voice recognition <b>data</b> <b>entry</b> EHR. Additional research is needed to further evaluate the <b>data</b> <b>entry</b> burden in the ED and examine alternative mechanisms for chart entry as EHR systems continue to evolve. [West J Emerg Med. 2014; 15 (4) : 541 - 547. ]...|$|R
5000|$|Jeffrey Michael Heer (born [...] ) is an American {{computer}} scientist {{best known for}} his work on information visualization and <b>interactive</b> <b>data</b> analysis. He {{is an associate professor of}} Computer Science & Engineering at the University of Washington, where he directs the UW <b>Interactive</b> <b>Data</b> Lab. He co-founded Trifacta with Joe Hellerstein and Sean Kandel in 2012.|$|R
30|$|<b>Interactive</b> <b>data</b> visualisation, {{exploration}} and reporting, {{as well as}} export of analysis results.|$|R
5000|$|Fawlty Language - Fawlty Language is an IDL8 (<b>Interactive</b> <b>Data</b> Language) {{compatible}} compiler.|$|R
3000|$|<b>Data</b> <b>Entry</b> Methods: The input methods {{available}} for mobile devices {{are different from}} those for desktop computers and require a certain level of proficiency. This problem increases the likelihood of erroneous input and decreases the rate of <b>data</b> <b>entry.</b>|$|R
40|$|The {{results of}} an {{experimental}} study of retail investors 2 ̆ 7 use of eXtensible Business Reporting Language tagged (<b>interactive)</b> <b>data</b> and PDF format for making investment decisions are reported. The main finding is that data format made no difference to participants 2 ̆ 7 ability to locate and integrate information from statement footnotes to improve investment decisions. <b>Interactive</b> <b>data</b> were perceived by participants as quick and ‘accurate’, but it failed to facilitate {{the identification of the}} adjustment needed to make the ratios accurate for comparison. An important implication is that regulators and software designers should work to reduce user reliance on the comparability of ratios generated automatically using <b>interactive</b> <b>data...</b>|$|R
3000|$|... [*]“… In {{case of a}} <b>data</b> <b>entry</b> zone, a Web page could {{contain more}} than one <b>data</b> <b>entry</b> zone with {{different}} purposes. The technique could allow the verification of all these repeated zones in a particular way.” - Inspector 4.|$|R
40|$|Capturing {{clinical}} data is a multi-faceted problem. This paper discusses clinical <b>data</b> <b>entry</b> problems encountered {{during the}} development of an intelligent clinical <b>data</b> <b>entry</b> system. Based on a review of the problems, recommendations are made for an approach to the design of clinical <b>data</b> <b>entry</b> programs. These recommendations include a discussion of key components in the design process as illustrated by the development of MedIO, a C++ computer program for the entry of history and physical exam information...|$|R
40|$|Work-related {{musculoskeletal}} disorders (WMSDs) negatively impact worker’s health, ability to work, and {{their quality of}} life. Non-invasive methods for assessing the physiological responses to workload may provide information on physiological markers leading to increased risk of WMSDs. The following study aimed to evaluate the feasibility of using thermography to quantify differences in thermal readings of participants during and following a <b>data</b> <b>entry</b> task and assess the repeatability of thermal readings. Skin surface temperature measurements of the dorsal forearm were obtained from 12 participants (6 females, 6 males) during a <b>data</b> <b>entry</b> task (35 minutes) and a 30 -minute post-task period. Participants also reported their perceived forearm discomfort during <b>data</b> <b>entry</b> and recovery. Three forearm analysis regions were analyzed based on statistical findings; Upper Left, Lower Left and Right regions. Temperature trends were found to increase during <b>data</b> <b>entry</b> and decrease during recovery. The Upper Left region was warmer during both <b>data</b> <b>entry</b> and recovery phases {{in comparison to the}} other regions. Repeatability of surface temperatures, based on intraclass correlations (ICCs), was found to be fair for magnitudes and trends during <b>data</b> <b>entry,</b> and poor for magnitudes and trend...|$|R
40|$|The before/after {{study of}} {{physiological}} and biochemical parameters {{was used to}} delineate the effects of VDT <b>data</b> <b>entry</b> work on operators. Twenty-nine healthy Chinese students were chosen and divided at random into the simple and the complicated <b>data</b> <b>entry</b> group. The subjects were instructed to work as quickly and correctly as possible according to the 'Data Entry Work Programme’ for 150 min. Work performance (correct entry) was automatically recorded once every lOmin. The before/after parameters were tested respectively. The results showed that performance fluctuated over time. It decreased obviously after 50 – 60 min of work, followed by a rebound, {{and there was a}} terminal motivation phenomenon {{at the end of the}} test, which was associated with the auto-arousal and cerebral compensatory effort. Changes in physiological parameters revealed that operators were fatigued after <b>data</b> <b>entry</b> work. The adrenaline excretion in urine showed a tendency to increase after simple <b>data</b> <b>entry</b> work. The noradrenaline excretion showed a tendency to decrease after complicated <b>data</b> <b>entry</b> work. The differences in performance, diastolic blood pressure in a standing position and neurobehaviour between two groups indicated that much stress was experienced when performing complicated <b>data</b> <b>entry</b> work...|$|R
