230|118|Public
50|$|There are {{two main}} {{variants}} of inverted indexes: A record-level inverted index (or <b>inverted</b> <b>file</b> index or just <b>inverted</b> <b>file)</b> contains a list of references to documents for each word. A word-level inverted index (or full inverted index or inverted list) additionally contains the positions of each word within a document. The latter form offers more functionality (like phrase searches), but needs more processing power and space to be created.|$|E
50|$|In an <b>{{inverted}}</b> <b>file</b> or inverted index, {{the contents}} of the data are used as keys in a lookup table, and the values in the table are pointers to the location of each instance of a given content item. This is also the logical structure of contemporary database indexes, which might only use the contents from a particular columns in the lookup table. The <b>inverted</b> <b>file</b> data model can put indexes in a second set of files next to existing flat database files, in order to efficiently directly access needed records in these files.|$|E
50|$|In {{computer}} science, {{an inverted}} index (also {{referred to as}} postings file or <b>inverted</b> <b>file)</b> is an index data structure storing a mapping from content, such as words or numbers, to its locations in a database file, or in a document or a set of documents (named {{in contrast to a}} Forward Index, which maps from documents to content). The purpose of an inverted index is to allow fast full text searches, at a cost of increased processing when a document is added to the database. The <b>inverted</b> <b>file</b> may be the database file itself, rather than its index. It is the most popular data structure used in document retrieval systems, used on a large scale for example in search engines. Additionally, several significant general-purpose mainframe-based database management systems have used inverted list architectures, including ADABAS, DATACOM/DB, and Model 204.|$|E
40|$|Two {{well-known}} indexing {{methods are}} <b>inverted</b> <b>files</b> and signature files. We have undertaken a detailed comparison {{of these two}} approaches {{in the context of}} text indexing, paying particular attention to query evaluation speed and space requirements. We have examined their relative performance using both experimentation and a refined approach to modeling of signature files, and demonstrate that <b>inverted</b> <b>files</b> are distinctly superior to signature files. Not only can <b>inverted</b> <b>files</b> be used to evaluate typical queries in less time than can signature <b>files,</b> but <b>inverted</b> <b>files</b> require less space and provide greater functionality. Our results also show that a synthetic text database can provide a realistic indication of the behavior of an actual text database. The tools used to generate the synthetic database have been made publicly available...|$|R
40|$|We examine index {{compression}} {{techniques for}} schemaindependent <b>inverted</b> <b>files</b> used in text retrieval systems. Schema-independent <b>inverted</b> <b>files</b> contain full positional information for all index terms {{and allow the}} structural unit of retrieval to be specified dynamically at query time, rather than statically during index construction. Schemaindependent indices have different characteristics than document-oriented indices, and this difference can affect the effectiveness of index compression algorithms greatly. Our experimenta...|$|R
40|$|Providing {{efficient}} query processing in database sys-tems is {{one step}} in gaining acceptance of such systems by end users. We propose several techniques for index-ing fuzzy sets in databases {{to improve the}} query evalu-ation performance. Three of the presented access meth-ods are based on superimposed coding, while the fourth relies on <b>inverted</b> <b>files.</b> The efficiency of these tech-niques was evaluated experimentally. We present results from these experiments, which clearly show the superi-ority of the <b>inverted</b> <b>files.</b> ...|$|R
50|$|From a pure formal {{mathematical}} {{point of}} view, the BIR is straightforward. From a practical point of view, however, several further problems should be solved {{that relate to}} algorithms and data structures, such as, for example, the choice of terms (manual or automatic selection or both), stemming, hash tables, <b>inverted</b> <b>file</b> structure, and so on.|$|E
50|$|In the 1960s, SDC {{developed}} the timesharing {{system for the}} AN/FSQ-32 mainframe computer for Defense Advanced Research Projects Agency (DARPA). The Q-32 {{was one of the}} first systems to support both multiple users and inter-computer communications. Experiments with a dedicated modem connection to the TX-2 at the Massachusetts Institute of Technology led to computer communication applications such as e-mail. In the 1960s, SDC also {{developed the}} JOVIAL programming language and the Time-Shared Data Management System (TDMS), an <b>Inverted</b> <b>File</b> Database System. Both were commonly used in real-time military systems.|$|E
40|$|The <b>inverted</b> <b>file</b> is {{the most}} popular {{indexing}} mechanism used for document search in an information retrieval system (IRS). However, the disk I/O for accessing the <b>inverted</b> <b>file</b> becomes a bottleneck in an IRS. To avoid using the disk I/O, we propose a caching mechanism for accessing the <b>inverted</b> <b>file,</b> called the <b>inverted</b> <b>file</b> cache (IF cache). In this cache, a proposed hashing scheme using a linked list structure to handle collisions in the hash table speeds up entry indexing. Furthermore, the replacement and storage mechanisms of this cache are designed specifically for the <b>inverted</b> <b>file</b> structure. We experimentally verify our design, based on documents collected from the TREC (Text REtrieval Conference) and search requests generated by the Zipf-like distribution. Simulation results show that the IF cache can improve the performance of a test IRS by about 60 % in terms of the average searching response time...|$|E
40|$|Vector {{of locally}} {{aggregated}} descriptors (VLAD) is a promising approach {{for addressing the}} problem of image search on a very large scale. This representation is proposed to overcome the quantization error problem faced in Bag-of-Words (BoW) representation. In this paper, we propose to enable <b>inverted</b> <b>files</b> of standard text search engines to exploit VLAD representation to deal with large-scale image search scenarios. We show {{that the use of}} <b>inverted</b> <b>files</b> with VLAD significantly outperforms BoW in terms of efficiency and effectiveness on the same hardware and software infrastructure...|$|R
40|$|Information {{retrieval}} {{systems are}} currently being developed to represent and manipulate complex multimedia objects. Such objects contain two types of components, i. e. structured components (e. g. of the type integer, real, fixed-length string, etc.), and unstructured components (e. g. text, images, sounds). Relational database systems (RDBS) are often used to store structured data and retrieve it via exact matching, while unstructured data is organized into <b>inverted</b> <b>files,</b> and accessed by Information storage and Retrieval Systems (IRS), utilizing indeterminate matching. The difficulty is how {{to fill the gap}} between the RDBs and <b>inverted</b> <b>files,</b> as well as the gap between the RDBMSs and IRSs based on <b>inverted</b> <b>files.</b> We describe an approach to integrating the two types of systems and the two different types of data. 1 Introduction A decade ago, a clear distinction between database (DB) systems and information retrieval (IR) systems could be based on the kinds of data stored in the systems [...] ...|$|R
40|$|Few if any Information Retrieval (IR) {{systems have}} {{had to deal with}} Concurrency Control (CC) on <b>inverted</b> <b>files.</b> In order to examine the issues {{involved}} in CC on <b>inverted</b> <b>files,</b> the effects of various operations (e. g. Boolean) on the effectiveness of the IR system are examined using the example of interleaved transactions. Solutions to the problems identified are examined by discussing the three main CC mechanisms; Locking, Optimistic CC and Timestamp Ordering. The effect of delays and document availability are examined. The problem of stored sets is identified. The need for further work in the area is identified. 1 Introduction To date Information Retrieval (IR) systems with <b>inverted</b> <b>files</b> have not had to deal with Concurrency Control (CC), since searching has taken priority over update. Insertions are usually done off-line and en-masse when no one is using the system e. g. overnight. Such methods are not suitable for systems where information is received at more frequent intervals an [...] ...|$|R
40|$|We {{propose a}} unique cluster-based {{retrieval}} (CBR) strategy {{using a new}} cluster-skipping <b>inverted</b> <b>file</b> for improving query processing efficiency. The new <b>inverted</b> <b>file</b> incorporates cluster membership and centroid information along with the usual document information into a single structure. In our incremental-CBR strategy, during query evaluation both best(-matching) clusters and best(-matching) documents of such clusters are computed together with a single posting list access per query term. As we switch from term to term, best clusters are recomputed and can dynamically change. During query-document matching, only relevant portions of the posting lists corresponding to the best clusters are considered {{and the rest is}} skipped. The proposed approach is essentially tailored for environments where inverted files are compressed, and provides substantial efficiency improvements while yielding comparable or sometimes better effectiveness figures. Our experiments with various collections show that, the incremental-CBR strategy using compressed cluster-skipping <b>inverted</b> <b>file</b> significantly improves CPU time efficiency regardless of the query length. The new compressed <b>inverted</b> <b>file</b> imposes an acceptable storage overhead in comparison to a typical <b>inverted</b> <b>file.</b> We also show that our approach scales well with the collection size...|$|E
40|$|Abstract. In {{order to}} further improve the overall {{efficiency}} of retrieval system, it proposes {{a method of}} inverted index based on block organizing technology. The specific studying process is as follows. Firstly, retrieval performance model of inverted index is generated based on data statistics, and then analyze the organizational strategy of <b>inverted</b> <b>file</b> block index, finally, retrieval performance model is verified through simulation experiment. The result shows that the method of <b>inverted</b> <b>file</b> block organization can get higher algorithm efficiency under the condition of less cycle numbers in the search algorithm, and also reduce the execution time of search algorithm significantly, which can verify the feasibility of <b>inverted</b> <b>file</b> block index method...|$|E
40|$|Recent {{advances}} in the asymptotic resource costs of pattern matching with compressed suffix arrays are attractive, but a key rival structure, the compressed <b>inverted</b> <b>file,</b> has been dismissed or ignored in papers presenting the new structures. In this paper we examine the resource requirements of compressed suffix array algorithms against compressed <b>inverted</b> <b>file</b> data structures for general pattern matching in genomic and English texts. In both cases, the <b>inverted</b> <b>file</b> indexes q-grams, thus allowing full pattern matching capabilities, rather than simple word based search, making their functionality equivalent to the compressed suffix array structures. When using equivalent memory for the two structures, inverted files are faster at reporting the location of patterns {{when the number of}} occurrences of the patterns is high...|$|E
40|$|We {{consider}} {{in this paper}} the information retrieval problem over a collection of time-evolving documents such that the search has {{to be carried out}} based on a query text and a temporal specification. A solution to this problem is critical for a number of emerging large scale applications involving archived collections of web contents, social network interactions, blog traffic, and information feeds. Given a collection of time-evolving documents, we develop an effective strategy to create <b>inverted</b> <b>files</b> and indexing structures such that a temporally anchored query can be processed fast using similar strategies as in the non-temporal case. The <b>inverted</b> <b>files</b> generated have exactly the same structure as those generated for the classical (non-temporal) case, {{and the size of the}} additional indexing structures is shown to be small. Well-known previous algorithms for constructing <b>inverted</b> <b>files</b> or for computing relevance can be extended to handle the temporal case. Moreover, we present high throughput, scalable parallel algorithms to build the <b>inverted</b> <b>files</b> with the additional indexing structures on multicore processors and clusters of multicore processors. We illustrate the effectiveness of our approach through experimental tests on a number of web archives, and include a comparison of space used by the indexing structures and postings lists and search time between our approach and the traditional approach that ignores the temporal information...|$|R
40|$|Abstract. The {{state-of-the-art}} algorithms {{for large}} visual content recognition and content based similarity search today use the “Bag of Features” (BoF) or “Bag of Words ” (BoW) approach. The idea, borrowed from text retrieval, enables {{the use of}} <b>inverted</b> <b>files.</b> A very well known issue with the BoF approach is that the query images, as well as the stored data, are described with thousands of words. This poses obvious efficiency problems when using <b>inverted</b> <b>files</b> to perform efficient image matching. In this paper, we propose and compare various techniques {{to reduce the number of}} words describing an image to improve efficiency...|$|R
50|$|A {{signature}} file {{is a technique}} that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to <b>inverted</b> <b>files</b> in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the <b>inverted</b> <b>files</b> in certain environments.|$|R
40|$|Abstract. This paper proposes and {{presents}} {{a comparison of}} scheduling algorithms applied to the context of load balancing the query traffic on distributed inverted files. We put emphasis on queries requiring intersection of posting lists, {{which is a very}} demanding case for the term partitioned <b>inverted</b> <b>file</b> and a case in which the document partitioned <b>inverted</b> <b>file</b> used by current search engines can perform very efficiently. We show that with proper scheduling of queries the term partitioned approach can outperform the document partitioned approach. ...|$|E
40|$|There is {{more and}} more {{commercial}} and research interest in location-based web search, i. e. finding web content whose topic is related to a particular place or region. In this type of search, location information should be indexed as well as text information. However, the index of conventional text search engine is set-oriented, while location information is two-dimensional and in Euclidean space. This brings new research problems on how to efficiently represent the location attributes of web pages and how to combine two types of indexes. In this paper, we propose to use a hybrid index structure, which integrates inverted files and R*-trees, to handle both textual and location aware queries. Three different combining schemes are studied: (1) <b>inverted</b> <b>file</b> and R*-tree double index, (2) first <b>inverted</b> <b>file</b> then R*-tree, (3) first R*-tree then <b>inverted</b> <b>file.</b> To validate the performance of proposed index structures, we design and implemen...|$|E
40|$|The rapid {{development}} {{of information systems}} generates new needs for indexing and retrieval of various kinds of media. The need for documents {{in the form of}} multimedia is increasing currently. Thus, the need to store or retrieve now becomes a primary problem. The multimedia type commonly used is text types, as widely seen as the main option in the search engines like Yahoo, Google or others. Essentially, search does not just want to get results, but also a more efficient process. For the purposes of indexing and retrieval, <b>inverted</b> <b>file</b> is used to provide faster results. However, there will be a problem if the making of an <b>inverted</b> <b>file</b> is related to a large amount of data. This study describes an algorithm called Fast Inversion as the development of base <b>inverted</b> <b>file</b> making method to address the needs related to the amount of data. </p...|$|E
40|$|This paper {{describes}} {{the application of}} techniques derived from text retrieval research to the content-based querying of image databases. Specifically, the use of <b>inverted</b> <b>files,</b> frequency-based weights and relevance feedback are investigated. The use of <b>inverted</b> <b>files</b> allows very large numbers (≥O(104)) of possible features to be used. since search {{is limited to the}} subspace spanned by the features present in the query image(s). A variety of weighting schemes used in text retrieval are employed, yielding different results. We suggest possibles modifications for their use with image databases. The use of relevance feedback was shown to improve the query results significantly, as measured by precision and recall, for all users...|$|R
50|$|The phrase full-text {{index is}} also {{often used for}} an index of all substrings of a text. But is ambiguous, as it is also used for regular word indexes such as <b>inverted</b> <b>files</b> and {{document}} retrieval. See full text search.|$|R
5000|$|A grid file began {{being used}} because [...] "traditional file {{structures}} that provide multikey access to records, for example, <b>inverted</b> <b>files,</b> are extensions of file structures originally designed for single-key access. They manifest various deficiencies in particular for multikey access to highly dynamic files." ...|$|R
40|$|Multiple-disk I/O systems (Disk Arrays) {{have been}} an {{attractive}} approach to meet high performance I/O demands in data intensive applications such as information retrieval systems. When we partition and distribute files across multiple disks to exploit the potential for I/O parallelism, a balanced I/O workload distribution becomes important for good performance. Naturally, {{the performance of a}} parallel information retrieval system using an <b>inverted</b> <b>file</b> structure is affected by the partitioning scheme of the <b>inverted</b> <b>file.</b> In this paper, we propose two different partitioning schemes for an <b>inverted</b> <b>file</b> system for a shared-everything multiprocessor machine with multiple disks. We study the performance of these schemes by simulation under a number of workloads where the term frequencies in the documents are varied, the term frequencies in the queries are varied, the number of disks are varied and the multiprogramming level is varied. 1 Introduction Applying multiprocessor machines to th [...] ...|$|E
30|$|Not {{categorised}} addresses were labelled ‘NC’; so the <b>inverted</b> <b>file</b> {{also contained}} NC-WEST AFRICA, NC-FOREIGN for the West African database and NC-KOREA, NC-FOREIGN for the Korean database.|$|E
40|$|Query {{languages}} {{that take}} advantage of the XML document structure already exist. However, the systems that have been developed to query XML data explore the XML sources from a database perspective. This paper examines an XML collection from the viewpoint of Information Retrieval (IR). As such, we view the XML documents as a collection of text documents with additional tags and we attempt to adapt existing IR techniques to achieve more sophisticated search on XML documents. We employ a class of queries that support path expressions and suggest an e#cient index, which extends the <b>inverted</b> <b>file</b> structure to search XML documents. This is accomplished by integrating the XML structure in the <b>inverted</b> <b>file</b> by combining the <b>inverted</b> <b>file</b> with a path index. The proposed structure is a lexicographical index, which may be used for the evaluation of queries that involve path expressions. Moreover, this paper discusses a ranking scheme based on both the term distribution and document structure. Some performance remarks are also presented...|$|E
40|$|The {{amount of}} {{documents}} increases so fast. Those documents exist {{not only in}} a paper based but also in an electronic based. It {{can be seen from}} the data sample taken by the SpringerLink publisher in 2010, which showed an increase in the number of digital document collections from 2003 to mid of 2010. Then, how to manage them well becomes an important need. This paper describes a new method in managing documents called as <b>inverted</b> <b>files</b> system. Related with the electronic based document, the <b>inverted</b> <b>files</b> system will closely used in term of its usage to document so that it can be searched over the Internet using the Search Engine. It can improve document search mechanism and document save mechanism...|$|R
40|$|International audienceThis paper {{introduces}} YAEL, {{a library}} implementing computationally intensive functions used in large scale image retrieval, such as neighbor search, clustering and <b>inverted</b> <b>files.</b> The library offers interfaces for C, Python and Matlab. Along {{with a brief}} tutorial, we analyze and discuss some implementation choices {{and their impact on}} efficiency...|$|R
40|$|Abstract — <b>Inverted</b> <b>files</b> {{have been}} very {{successful}} for document retrieval, but sponsored search is different. <b>Inverted</b> <b>files</b> are designed to find documents that match the query (all the terms in the query {{need to be in}} the document, but not vice versa). For sponsored search, ads are associated with bids. When a user issues a search query, bids are typically matched to the query using broad-match semantics: all the terms in the bid need to be in the query (but not vice versa). This means that the roles of the query and the bid/document are reversed in sponsored search, in turn making standard retrieval techniques based on inverted indexes ill-suited for sponsored search. This paper proposes novel index structures and query processing algorithms for sponsored search. We evaluate these structures using a real corpus of 180 million advertisements. I...|$|R
40|$|The {{increasing}} {{amount of}} textual {{information on the}} Internet {{is a good example}} of information explosion. Previous research on information retrieval mostly focused on improving the retrieval effectiveness of the system. As the amount of online information and the number of users accessing these information resources continue to grow at an exponential rate, system efficiency becomes an important concern of information retrieval systems since users demand better results to be found in a shorter period of time. Our research focuses on improving the efficiency of information retrieval systems. Several aspects concerning the efficiency of an information retrieval system are first discussed. A new index structure, called the Weight-Partitioned <b>Inverted</b> <b>File,</b> is proposed. Experiments are carried out on a subset of the TREC collection to obtain the tradeoff between retrieval effectiveness and efficiency. It is found that the Weight-Partitioned <b>Inverted</b> <b>File</b> is able to improve efficiency noticeably while maintaining the effectiveness at about the same level as a regular <b>inverted</b> <b>file</b> implementation...|$|E
40|$|A {{variety of}} data {{structures}} such as <b>inverted</b> <b>file,</b> multi-lists, quad tree, k-d tree, range tree, polygon tree, quintary tree, multidimensional tries, segment tree, doubly chained tree, the grid file, d-fold tree. super B-tree, Multiple Attribute Tree (MAT), etc. have been studied for multidimensional searching and related problems. Physical data base organization, which is an important application of multidimensional searching, is traditionally and mostly handled by employing <b>inverted</b> <b>file.</b> This study proposes MAT data structure for bibliographic file systems, by illustrating the superiority of MAT data structure over <b>inverted</b> <b>file.</b> Both the methods are compared in terms of preprocessing, storage and query costs. Worst-case complexity analysis of both the methods, for a partial match query, is carried out in two cases: (a) when directory resides in main memory, (b) when directory resides in secondary memory. In both cases, MAT data structure is shown to be more efficient than the <b>inverted</b> <b>file</b> method. Arguments are given to illustrate the superiority of MAT data structure in an average case also. An efficient adaptation of MAT data structure, that exploits the special features of MAT structure and bibliographic files, is proposed for bibliographic file systems. In this adaptation, suitable techniques for fixing and ranking of the attributes for MAT data structure are proposed. Conclusions and proposals for future research are presented...|$|E
30|$|As a database, a {{word bank}} is {{content-addressable}} {{because it does}} not use an index (<b>inverted</b> <b>file),</b> in contrast to the widely used coordinate-addressable databases (RDBMS). See Chisvin and Duckworth (1992) for an overview.|$|E
40|$|A network {{organization}} for implementing a document retrieval system is proposed. This organization has significant advantages {{in terms of}} the range of searches that can be used when compared to either <b>inverted</b> or clustered <b>file</b> organizations. Algorithms for generating and maintaining the network are described together with experiments designed to test their efficiency and effectiveness. I. Introduction physically grouping documents that are likely to The main types of file organlzd~ 1 on tha ~ b ~ retrieved by the same queries. nave been proposed for the implementation of In this paper, we investigate a network document retrleval systems rare <b>inverted</b> <b>files</b> organizatlon which combines Lll ~ advantages of and c±ustered files [SALT 82 J. Although other <b>inverted</b> and clustered <b>files.</b> This organizatio...|$|R
40|$|We {{present an}} {{algorithm}} for efficient processing of set-containment joins in main memory. Our algorithm uses an index structure based on <b>inverted</b> <b>files.</b> We focus on improving {{performance of the}} algorithm in a main-memory environment by utilizing the L 2 CPU cache more efficiently. To achieve this, we employ some optimizations including partitioning the inverted lists and compressing the intermediate results. ...|$|R
40|$|A {{new class}} of {{applications}} based on visual search engines are emerging, especially on smart-phones that have evolved into powerful tools for processing images and videos. The state-of-the-art algorithms for large visual content recognition and content based similarity search today use the "Bag of Features" (BoF) or "Bag of Words" (BoW) approach. The idea, borrowed from text retrieval, {{enables the use of}} <b>inverted</b> <b>files.</b> A very well known issue with this approach is that the query images, as well as the stored data, are described with thousands of words. This poses obvious efficiency problems when using <b>inverted</b> <b>files</b> to perform efficient image matching. In this paper, we propose and compare various techniques {{to reduce the number of}} words describing an image to improve efficiency and we study the effects of this reduction on effectiveness in landmark recognition and retrieval scenarios. We show that very relevant improvement in performance are achievable still preserving the advantages of the BoF base approach...|$|R
