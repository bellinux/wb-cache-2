1987|5510|Public
25|$|Costs {{proportional}} to change size, not to <b>data</b> <b>size.</b>|$|E
25|$|E-mail tax is a {{specific}} type of bit-tax, which would tax based on volume of email sent or received, quantified either by number of messages or <b>data</b> <b>size</b> of the messages.|$|E
25|$|DNS {{primarily}} {{uses the}} User Datagram Protocol (UDP) on port number 53 to serve requests. DNS queries {{consist of a}} single UDP request from the client followed by a single UDP reply from the server. The Transmission Control Protocol (TCP) is used when the response <b>data</b> <b>size</b> exceeds 512 bytes, or for tasks such as zone transfers. Some resolver implementations use TCP for all queries.|$|E
50|$|Intel i860 {{instructions}} {{acted on}} <b>data</b> <b>sizes</b> from 8-bit through 128-bit.|$|R
5000|$|Examples {{of the use}} of {{terabyte}} {{to describe}} <b>data</b> <b>sizes</b> in different fields are: ...|$|R
30|$|Using {{the cost}} model {{requires}} estimates of <b>data</b> <b>sizes</b> and cpu costs. This is realistic for many workflows, and producing these estimates is made easier if performance and capacity are logged for each run, so allowing statistical analysis to generate predictions. This is, for example, {{done by the}} e-Science Central cloud platform[6] which logs data on all <b>data</b> <b>sizes,</b> and service execution times.|$|R
25|$|NAND flash {{architecture}} {{was introduced}} by Toshiba in 1989. These memories are accessed much like block devices, such as hard disks. Each block consists {{of a number of}} pages. The pages are typically 512 or 2,048 or 4,096 bytes in size. Associated with each page are a few bytes (typically 1/32 of the <b>data</b> <b>size)</b> {{that can be used for}} storage of an error correcting code (ECC) checksum.|$|E
25|$|Many forums allow {{users to}} give {{themselves}} an avatar. An avatar {{is an image}} that appears beside all of a user's posts, {{in order to make}} the user more recognizable. The user may upload the image to the forum database, or may provide a link to an image on a separate website. Each forum has limits on the height, width, and <b>data</b> <b>size</b> of avatars that may be used; if the user tries to use an avatar that is too big, it may be scaled down or rejected.|$|E
2500|$|A fast Fourier {{transform}} (FFT) algorithm computes the discrete Fourier transform (DFT) of a sequence, or its inverse (IFFT). Fourier analysis converts {{a signal}} from its original domain (often time or space) to a representation in the frequency domain and vice versa. An FFT rapidly computes such transformations by factorizing the DFT matrix into a product of sparse (mostly zero) factors. As a result, it manages to reduce the complexity of computing the DFT from , which arises if one simply applies the definition of DFT, to , where [...] is the <b>data</b> <b>size.</b>|$|E
5000|$|Examples {{of the use}} of the {{petabyte}} {{to describe}} <b>data</b> <b>sizes</b> in different fields are: ...|$|R
5000|$|Numerics by Stata, {{supports}} {{any of the}} <b>data</b> <b>sizes</b> {{listed above}} in an embedded environment ...|$|R
5000|$|Tiling or {{blocking}} - reorganizes a loop {{to iterate}} over blocks of <b>data</b> <b>sized</b> {{to fit in}} the cache.|$|R
50|$|Information about <b>data</b> <b>size</b> limits.|$|E
5000|$|General {{data set}} {{properties}} (owner, creation <b>data,</b> <b>size,</b> format); ...|$|E
5000|$|Fully {{automated}} continuous scaling with {{no limit}} on <b>data</b> <b>size</b> or throughput.|$|E
5000|$|The minimum Ethernet {{frame size}} is 64 bytes, while typical {{industrial}} communication <b>data</b> <b>sizes</b> can {{be closer to}} 1-8 bytes. This protocol overhead affects data transmission efficiency.|$|R
40|$|Abstract – Efficient {{implementations}} of the Discrete Fourier Transform (DFT) for GPUs {{provide good}} performance with large <b>data</b> <b>sizes,</b> {{but are not}} competitive with CPU code for small <b>data</b> <b>sizes.</b> On the other hand, several applications perform multiple DFTs on small <b>data</b> <b>sizes.</b> In fact, even algorithms for large <b>data</b> <b>sizes</b> use a divide-andconquer approach, where eventually small DFTs need to be performed. We discuss our DFT implementation, which is efficient for multiple small DFTs. One feature of our implementation {{is the use of}} the asymptotically slow matrix multiplication approach for small <b>data</b> <b>sizes,</b> which improves performance on the GPU due to its regular memory access and computational patterns. We combine this algorithm with the mixed radix algorithm for 1 -D, 2 -D, and 3 -D complex DFTs. We also demonstrate the effect of different optimization techniques. When GPUs are used to accelerate a component of an application running on the host, it is important that decisions taken to optimize the GPU performance not affect the performance {{of the rest of the}} application on the host. One feature of our implementation is that we use a data layout that is not optimal for the GPU so that the overall effect on the application is better. Our implementation performs up to two orders of magnitude faster than cuFFT on an NVIDIA GeForce 9800 GTX GPU and up to one to two orders of magnitude faster than FFTW on a CPU for multiple small DFTs. Furthermore, we show that our implementation can accelerate the performance of a Quantum Monte Carlo application for which cuFFT is not effective. The primary contributions of this work lie in demonstrating the utility of the matrix multiplication approach and also in providing an implementation that is efficient for small DFTs when a GPU is used to accelerate an application running on the host. I...|$|R
40|$|We {{develop an}} {{analytic}} model, {{and a set}} of microbenchmark programs for the measurement of the structural parameters of data cache memories and data TLBs. Running under Linux, our microbenchmarks accurately measure data cache capacity, <b>data</b> cache line <b>size,</b> <b>data</b> cache associativity, effective cache latency, effective data path parallelism, <b>data</b> TLB <b>size,</b> <b>data</b> TLB associativity, and TLB latency. We present experimental results from running our microbenchmarks on Pentium II and Pentium III workstations...|$|R
5000|$|... ensures {{a minimum}} <b>data</b> <b>size</b> or {{representation}} required {{by at least}} one of the communicating processes involved in a transfer.|$|E
5000|$|TCP should {{determine}} the Maximum Segment <b>Data</b> <b>Size</b> (MSDS) {{from either the}} default or the received value of the MSS option.|$|E
50|$|Storage {{was through}} a {{cassette}} tape interface at 1500 baud. Files were compiled user application (fast loading) and Memory Raw <b>Data</b> (<b>size</b> dependent).|$|E
50|$|The {{data format}} {{consists}} of a header, followed by the compressed data. The header contains an identifier and house keeping information, such as compressed and decompressed <b>data</b> <b>sizes</b> and a 32-bit checksum (a variant of the Fletcher checksum).|$|R
30|$|Test Results (2) Test case (2) {{was carried}} out by {{increasing}} <b>data</b> event <b>size</b> and by adding one access control policy to the broker; results are shown in Fig.  9 a, b, and the horizontal axis is logarithmic (base 10). We make a performance comparison between the pub-to-sub latency with plain and with access control, as well as the broker latency with plain and with access control. For small <b>data</b> event <b>sizes,</b> the pub-to-sub latency and broker latency are low, such as for the 1 KB <b>data</b> event <b>size,</b> and the whole latency event messaging latency takes less than 20  ms (Fig.  9 a); the policy matching latency taken on the broker takes 5  ms (Fig.  9 b). As the <b>data</b> event <b>size</b> becomes larger, the latency is continuous curve. PS-ACF shows the same behaviour as the baseline. As with the pub-to-sub latency and the broker latency, the <b>data</b> event <b>size</b> is one of factors in the overhead.|$|R
30|$|Each of the {{primitive}} accepts two parameters. The first parameter is {{the address of}} the security-sensitive variable, which helps the Trace Analyzer distinguishes different recorded variables. The second parameter is the value of the variable. The primitives vary on supported <b>data</b> <b>sizes</b> and load/store events.|$|R
5000|$|... s, if set, {{indicates}} that the <b>data</b> <b>size</b> is specified in n (if e is set) or in the data part of the message ...|$|E
50|$|We can use {{the last}} offset and last <b>data</b> <b>size</b> to {{calculate}} the total data size: 495*8 + 540 = 3960 + 540 = 4500.|$|E
5000|$|The TCP {{should ask}} the IP for the Maximum Datagram <b>Data</b> <b>Size</b> (MDDS). This is the MTU minus the IP header length (MDDS = MTU - IPHdrLen).|$|E
40|$|Abstract—We {{consider}} {{the problem of}} preserving data in intermittently connected sensor networks wherein sensor nodes do not always have connected paths to the base stations. The generated data is first stored inside the network before being uploaded to the base station when uploading opportunities arise. Each node has both limited energy level and limited storage space, and {{is associated with a}} probability of failure. To guarantee that at any moment, each generated data item is available for being uploaded in the presence of node failure, we propose to replicate K copies of each data item in the network, where K depends upon the node failure probability. We refer to the problem as Data K-Availability Problem (DKAP). DKAP is naturally divided into two phases:K-Availability creation and K-Availability maintenance. For K-Availability creation, we show that the problem is NP-hard for arbitrary <b>data</b> <b>sizes,</b> and that it is equivalent to minimum cost flow problem for unit <b>data</b> <b>sizes.</b> For K-Availability maintenance, we show that it is NP-hard even for unit <b>data</b> <b>sizes</b> and design a centralized greedy heuristic. We further design an efficient and low-overhead distributed algorithm, which is applicable to both phases, and show using extensive simulations that it performs close to the heuristic...|$|R
40|$|Multimedia data {{security}} {{is important for}} multimedia commerce. Previous cryptography {{studies have focused on}} text data. The encryption algorithms developed to secure text data may not be suitable to multimedia applications because of large <b>data</b> <b>sizes</b> and real time constraint. For multimedia applications, light weight encryption algorithms are attractive...|$|R
5000|$|... #Subtitle level 3: Encoding and <b>data</b> {{structures}} (<b>size</b> overhead) ...|$|R
5000|$|... no pre-allocated structures: {{all data}} used by Proteus are {{dynamically}} allocated at execution time; {{there are no}} limits on: recursion, maximum <b>data</b> <b>size,</b> number of variables, etc.; ...|$|E
50|$|Since {{digital signals}} that are {{broadcast}} {{over the air}} are compressed (packed smaller), once they are received by the ATSC tuner, these compressed packets of digital data are then decompressed (unpacked to their original size). The ATSC system uses lossy compression, so while the decompressed <b>data</b> <b>size</b> {{is the same as}} the original compressed <b>data</b> <b>size,</b> the data produced is not exactly the same as the original data fed into the system at the transmitting site, but it is close enough that most people don't notice the difference.|$|E
5000|$|... slimRAW (April 2015): slimRAW {{lossless}} compressor for CinemaDNG raw video released. It converts uncompressed CinemaDNG to losslessly compressed CinemaDNG [...] "for {{a substantial}} <b>data</b> <b>size</b> reduction with no image quality loss".|$|E
40|$|Abstract —	   Information Visualisation {{techniques}} are one method {{that may be}} used to combat the growing complexity and <b>data</b> <b>sizes</b> associated with digital forensic investigations. This work outlines the processes, challenges, trials and tribulations of developing proof-of-concept forensic software designed to create interactive Information Visualisations from digital evidence sources...|$|R
50|$|Memory {{bandwidth}} is {{the rate}} at which data can be read from or stored into a semiconductor memory by a processor. Memory bandwidth is usually expressed in units of bytes/second, though this can vary for systems with natural <b>data</b> <b>sizes</b> that are not a multiple of the commonly used 8-bit bytes.|$|R
40|$|Click on the DOI link {{to access}} this conference paper (may not be free) We {{consider}} {{the problem of}} preserving data in intermittently connected sensor networks wherein sensor nodes do not always have connected paths to the base stations. The generated data is first stored inside the network before being uploaded to the base station when uploading opportunities arise. Each node has both limited energy level and limited storage space, and {{is associated with a}} probability of failure. To guarantee that at any moment, each generated data item is available for being uploaded in the presence of node failure, we propose to replicate K copies of each data item in the network, where K depends upon the node failure probability. We refer to the problem as Data K-Availability Problem (DKAP). DKAP is naturally divided into two phases: K-Availability creation and K-Availability maintenance. For K-Availability creation, we show that the problem is NP-hard for arbitrary <b>data</b> <b>sizes,</b> and that it is equivalent to minimum cost flow problem for unit <b>data</b> <b>sizes.</b> For K-Availability maintenance, we show that it is NP-hard even for unit <b>data</b> <b>sizes</b> and design a centralized greedy heuristic. We further design an efficient and low-overhead distributed algorithm, which is applicable to both phases, and show using extensive simulations that it performs close to the heuristic...|$|R
