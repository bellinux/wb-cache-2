2|3144|Public
40|$|Object-oriented {{programming}} {{languages are}} being widely adopted {{as one of}} the most powerful languages due their flexibility and reusability. However, these languages suffer from memory mismanagement that could be critical especially in real-time and embedded systems. Automatic memory management through garbage collector handles this problem. Concurrent garbage collection based on sporadic or deferrable server is considered the most famous collectors in this area. In such algorithms, the garbage collection task is assumed to be the single aperiodic task in the system. When there are other different types of traffic, with short deadlines and long deadlines, the single server provides poor performance. The garbage collection task may have to wait till a less urgent or a higher deadline request finishes its execution that leads to an increase in the system memory requirement and perhaps a deadline miss of the <b>garbage</b> <b>collection</b> <b>thread.</b> This paper concentrates on minimizing the system memory requirement when there are multiple sources of events by introducing a new concurrent garbage collector. I...|$|E
40|$|Shingled {{magnetic}} recording (SMR) increases {{the capacity of}} magnetic hard drives, but it requires that each zone of a disk be written sequentially and erased in bulk. This makes SMR {{a good fit for}} workloads dominated by large data objects with limited churn. To explore this possibility, we have developed SMORE, an object storage system designed to reliably and efficiently store large, seldom-changing data objects on an array of host-managed or host-aware SMR disks. SMORE uses a log-structured approach to accommodate the constraint that all writes to an SMR drive must be sequential within large shingled zones. It stripes data across zones on separate disks, using erasure coding to protect against drive failure. A separate <b>garbage</b> <b>collection</b> <b>thread</b> reclaims space by migrating live data out of the emptiest zones {{so that they can be}} trimmed and reused. An index stored on flash and backed up to the SMR drives maps object identifiers to on-disk locations. SMORE interleaves log records with object data within SMR zones to enable index recovery after a system crash (or failure of the flash device) without any additional logging mechanism. SMORE achieves full disk bandwidth when ingesting data [...] -with a variety of object sizes [...] -and when reading large objects. Read performance declines for smaller object sizes where inter- object seek time dominates. With a worst-case pattern of random deletions, SMORE has a write amplification (not counting RAID parity) of less than 2. 0 at 80 % occupancy. By taking an index snapshot every two hours, SMORE recovers from crashes in less than a minute. More frequent snapshots allow faster recovery. Comment: 13 pages, 8 figures, full version of 6 page paper published at MSST 201...|$|E
5000|$|Bartok is an {{optimizing}} compiler {{and managed}} runtime system for Common Intermediate Language (which [...]NET languages compile to), {{being developed by}} Microsoft Research. It aims to be efficient enough to be usable for writing operating systems. It provides services such as automatic memory management and <b>garbage</b> <b>collection,</b> <b>threading,</b> and marshalling data to and from native code, as well as verification of CIL code. Bartok is written in C#, including the garbage collector. Bartok is being used by Microsoft Research {{for the implementation of}} Singularity, a highly-dependable operating system written almost entirely in managed code.|$|R
40|$|Cache-coherent non uniform {{memory access}} (ccNUMA) {{architecture}} {{is a standard}} design pattern for contemporary multicore processors, and future generations of architectures {{are likely to be}} NUMA. NUMA architectures create new challenges for managed runtime systems. Memory-intensive applications use the system’s distributed memory banks to allocate data, and the automatic memory manager collects garbage left in these memory banks. The garbage collector may need to access remote memory banks, which entails access latency overhead and potential bandwidth saturation for the interconnection between memory banks. This dissertation makes ﬁve signiﬁcant contributions to <b>garbage</b> <b>collection</b> on NUMA systems, with a case study implementation using the Hotspot Java Virtual Machine. It empirically studies data locality for a Stop-The-World garbage collector when tracing connected objects in NUMA heaps. First, it identiﬁes a locality richness which exists naturally in connected objects that contain a root object and its reachable set— ‘rooted sub-graphs’. Second, this dissertation leverages the locality characteristic of rooted sub-graphs to develop a new NUMA-aware <b>garbage</b> <b>collection</b> mechanism. A <b>garbage</b> collector thread processes a local root and its reachable set, which is likely to have a large number of objects in the same NUMA node. Third, a garbage collector thread steals references from sibling threads that run on the same NUMA node to improve data locality. This research evaluates the new NUMA-aware garbage collector using seven benchmarks of an established real-world DaCapo benchmark suite. In addition, evaluation involves a widely used SPECjbb benchmark and Neo 4 J graph database Java benchmark, as well as an artiﬁcial benchmark. The results of the NUMA-aware garbage collector on a multi-hop NUMA architecture show an average of 15 % performance improvement. Furthermore, this performance gain is shown to be {{as a result of an}} improved NUMA memory access in a ccNUMA system. Fourth, the existing Hotspot JVM adaptive policy for conﬁguring the number of <b>garbage</b> <b>collection</b> <b>threads</b> is shown to be suboptimal for current NUMA machines. The policy uses outdated assumptions and it generates a constant thread count. In fact, the Hotspot JVM still uses this policy in the production version. This research shows that the optimal number of <b>garbage</b> <b>collection</b> <b>threads</b> is application-speciﬁc and conﬁguring the optimal number of <b>garbage</b> <b>collection</b> <b>threads</b> yields better <b>collection</b> throughput than the default policy. Fifth, this dissertation designs and implements a runtime technique, which involves heuristics from dynamic collection behavior to calculate an optimal number of garbage collector <b>threads</b> for each <b>collection</b> cycle. The results show an average of 21 % improvements to the <b>garbage</b> <b>collection</b> performance for DaCapo benchmarks...|$|R
50|$|The RTSJ {{addressed}} the critical issues by mandating a minimum specification for the threading model (and allowing other models to be {{plugged into the}} VM) and by providing for areas of memory that {{are not subject to}} <b>garbage</b> <b>collection,</b> along with <b>threads</b> that are not preemptable by the garbage collector. These areas are instead managed using region-based memory management. The latest specification, 2.0, supports direct device access and deterministic <b>garbage</b> <b>collection</b> as well.|$|R
40|$|Abstract — This paper {{presents}} a novel implementation of an embedded Java microarchitecture for secure, realtime, and multi-threaded applications. Together {{with the support}} of modern features of object-oriented languages, such as exception handling, automatic <b>garbage</b> <b>collection</b> and interface types, a general-purpose platform is established which also fits for the agent concept. Especially, considering real-time issues, new techniques have been implemented in our Java microarchitecture, such as an integrated stack and thread management for fast context switching, concurrent <b>garbage</b> <b>collection</b> for real-time <b>threads</b> and autonomous control flows through preemptive round-robin scheduling. I...|$|R
40|$|Clustering (and caching) is a {{crosscutting}} infrastructure {{service that}} {{has historically been}} implemented with API-based solutions. As a result, it has suffered from the same code scattering and tangling problems as other crosscutting concerns. In this paper we will show how Aspect-Oriented Programming (AOP) can help to modularize clustering {{and turn it into}} a runtime infrastructure Quality of Service. We will show how AOP can be used to plug in directly into the Java Memory Model, which allows us to maintain the key Java semantics of pass-byreference, <b>garbage</b> <b>collection</b> and <b>thread</b> coordination across the cluster, e. g. essentially cluster the Java Virtual Machine underneath the user application instead of the user application directl...|$|R
5000|$|The Common Language Runtime (CLR), {{the virtual}} machine {{component}} of Microsoft's [...]NET framework, manages {{the execution of}} [...]NET programs. A process known as just-in-time compilation converts compiled code into machine instructions which the computer's CPU then executes. The CLR provides additional services including memory management, type safety, exception handling, <b>garbage</b> <b>collection,</b> security and <b>thread</b> management. All programs written for the [...]NET framework, regardless of programming language, are executed by the CLR. All versions of the [...]NET framework include CLR.|$|R
40|$|Part of the new. NET {{platform}} from Microsoft {{is the new}} {{programming language}} C # which was first presented in 1999. In many articles, C # was compared with Java and C++, and its new and novel features were presented and discussed. In this article {{we do not want}} to elaborate these language extensions (as e. g. properties, events, attributes, operator overloading, etc.) but rather concentrate on some subtle and almost imperceptible language changes in which C # differs from Java. These language refinements enable the compiler to mark potential problems which are otherwise only found by static analyzer tools (as e. g. lint). Programmers can no longer fall into prominent language trap doors and thus save development and debugging time. We hope, that some of these language enhancements find their way back to the Java language. 1 C # AND ITS ANCESTORS Microsoft. NET is a platform for software components and web services. The kernel of the. NET framework is the Common Language Runtime (CLR) which can load and execute components and which provides some basic infrastructure as e. g. <b>garbage</b> <b>collection,</b> <b>threading</b> and security support. The components can be implemented in a variety of. NET compliant programming languages and are compiled into the Microsoft Intermediate Language (MSIL), a byte code comparable to Java byte code. The predestinate language to program on the. NET platform is C #, a modern, object-oriented and type safe language which (according to Microsoft evangelists) combines the power and efficiency of C++ with the simplicity of Visual Basic. C # was designed by Anders Hejlsberg [Hejlsberg 00], author of Object Pascal and Delphi (for an introduction to C # see e. g. [Wiltamuth 00]). Although Microsoft always declared C # as a direct successor of C++, the language has inherited almost all features of Java: <b>garbage</b> <b>collection,</b> byte code, meta information and reflection, single superclassing, interfaces, exceptions, etc. Many authors therefore compared C # with its sibling Java and discussed the new an...|$|R
40|$|We {{report on}} our {{experiences}} with the Spy project, including implementation details and benchmark results. Spy is a re-implementation of the Squeak (i. e., Smalltalk- 80) VM using the PyPy toolchain. The PyPy project allows code written in RPython, a subset of Python, to be translated to a multitude of different backends and architectures. During the translation, {{many aspects of the}} implementation can be independently tuned, such as the <b>garbage</b> <b>collection</b> algorithm or <b>threading</b> implementation. In this way, a whole host of interpreters can be derived from one abstract interpreter definition. Spy aims to bring these benefits to Squeak, allowing for greater portability and, eventually, improved performance. The current Spy codebase is able to run a small set of benchmarks that demonstrate performance superior to many similar Smalltalk VMs, but which still run slower than in Squeak itself. Spy was built from scratch {{over the course of a}} week during a joint Squeak-PyPy Sprint in Bern last autumn...|$|R
40|$|This paper {{outlines}} {{the design and}} implementation of the PEVM, a new scalable, high-performance implementation of orthogonal persistence for the Java platform (OPJ). The PEVM is based on the Sun Microsystems Laboratories Virtual Machine for Research, which features an optimizing Just-In-Time compiler, exact generational <b>garbage</b> <b>collection,</b> and fast <b>thread</b> synchronization. The PEVM also uses a new, scalable persistent object store designed to manage 80 GB of objects. It is approximately ten times faster than previous OPJ implementations and can run signi cantly larger programs. Despite its greater speed and scalability, the PEVM's implementation is much simpler (e. g., just 43 % of the VM source patches needed by our previous OPJ implementation). This is largely due to the pointer swizzling strategy we chose, the ResearchVM's exact memory management, and simple but e ective mechanisms. For example, we implement some key data structures in the Java programming language since this automatically makes them persistent...|$|R
40|$|This paper {{describes}} {{the design and}} implementation of the PEVM, a new scalable, high-performance implementation of orthogonal persistence for the Java™ platform (OPJ). The PEVM is based on the Sun Microsystems Laboratories Virtual Machine for Research (ResearchVM), which features an optimizing Just-In-Time compiler, exact generational <b>garbage</b> <b>collection,</b> and fast <b>thread</b> synchronization. It also uses a new, scalable persistent object store designed to manage more than 80 GB of objects. The PEVM is approximately ten times faster than previous OPJ implementations and can run significantly larger programs. It is faster than or comparable in performance to several commercial persistence solutions for the Java platform. Despite the PEVM’s speed and scalability, its implementation is simpler than our previous OPJ implementation (e. g., just 43 % of the VM source patches needed by our previous OPJ implementation). Its speed and simplicity are largely due to our pointer swizzling strategy, the ResearchVM’s exact memory management, and a few simple but effective mechanisms. For example, we implement some key data structures in the Java ™ programming language since this automatically makes them persistent...|$|R
40|$|Automatic storage {{management}} such as <b>garbage</b> <b>collection</b> {{is essential to}} list processing systems. Unfortunately, many reclamation algorithms cause long pauses of execution. The pause time is getting shorter in modern <b>garbage</b> <b>collection</b> algorithms, however can not be eliminated perfectly. Parallel <b>garbage</b> <b>collection</b> {{is one of the}} efficient <b>garbage</b> <b>collection</b> scheme. It provides high performance list processing and is a key approach to the real time system. No practical parallel <b>garbage</b> <b>collections</b> have been implemented yet. Real time <b>garbage</b> <b>collection</b> can be considered in the same category of parallel <b>garbage</b> <b>collection.</b> There are two disadvantages common to parallel <b>garbage</b> <b>collection</b> and real time <b>garbage</b> <b>collection.</b> One is that collection efficiency becomes 1 / 2 compared with traditional sequential <b>garbage</b> <b>collection,</b> and the other is List processor's overhead when programs that do not consume many cells. We present solutions for these disadvantages, Partial Marking GC and Conditional [...] ...|$|R
40|$|Mobile {{networks}} pose {{new issues}} {{in the field of}} distributed <b>garbage</b> <b>collection.</b> <b>Garbage</b> <b>collection</b> must deal with volatile connections that may break remote object references unexpectedly for an unpredictable amount of time. As a result, no automatic distributed <b>garbage</b> <b>collection</b> satisfies the new hardware phenomena. A semantic-based approach called semi-automatic <b>garbage</b> <b>collection</b> is proposed as a new strategy for distributed <b>garbage</b> <b>collection</b> where the collector will be steered by the developer to decide whether remote objects can be reclaimed. We investigate how to transmit the needs of the application to the <b>garbage</b> <b>collection</b> process. 1...|$|R
40|$|Comprehensive <b>garbage</b> <b>collection</b> is {{employed}} {{on a variety}} of com-puting devices, including intelligent cell phones. <b>Garbage</b> <b>collection</b> can cause prolonged user-interface pauses. In order to evaluate and compare the disruptiveness of various <b>garbage</b> <b>collection</b> strategies, it is necessary to gauge disruptions caused by <b>garbage</b> <b>collection.</b> In this paper, we de-scribe efficient algorithms for computing metrics useful for this purpose. 1 Formulation of the Problem Practical problem: need to minimize disruptions caused by <b>garbage</b> <b>collection.</b> In many computer-based systems – including mobile devices – it is necessary to periodically perform <b>garbage</b> <b>collection.</b> This computation can interfere with the progress of interactive programs. <b>Garbage</b> <b>collection</b> can cause intermittent prolonged pauses in gesture-driven user interfaces that can severely reduce their usability; see, e. g., [1, 2, 4]. Need to gauge the quality of different <b>garbage</b> <b>collection</b> strategies. T...|$|R
40|$|Providing hints for <b>garbage</b> <b>collection</b> Abstract—This paper {{presents}} a mechanism that uses off-line profile information to examine when garbage is best collected. This information is {{then used to}} guide the <b>garbage</b> <b>collection</b> frequency {{in order to reduce}} the <b>garbage</b> <b>collection</b> time and total execution time. Keywords—Java, <b>garbage</b> <b>collection,</b> scheduling I...|$|R
40|$|Hardware-assisted <b>garbage</b> <b>collection</b> {{makes use}} of {{dedicated}} circuits located within a special expansion memory module to enhance the response time and throughput of <b>garbage</b> <b>collection</b> operations. This paper provides detailed descriptions of the memory cycles required to implement each of the primitive <b>garbage</b> <b>collection</b> operations provided by the hardware-assisted <b>garbage</b> <b>collection</b> module...|$|R
40|$|Comprehensive <b>garbage</b> <b>collection</b> is {{employed}} {{on a variety}} of computing devices, including intelligent cell phones. <b>Garbage</b> <b>collection</b> can cause prolonged user-interface pauses. In order to evaluate and compare the disruptiveness of various <b>garbage</b> <b>collection</b> strategies, it is necessary to gauge disruptions caused by <b>garbage</b> <b>collection.</b> In this paper, we describe efficient algorithms for computing metrics useful for this purpose...|$|R
50|$|Lisp {{introduced}} {{the concept of}} automatic <b>garbage</b> <b>collection,</b> in which the system walks the heap looking for unused memory. Progress in modern sophisticated <b>garbage</b> <b>collection</b> algorithms such as generational <b>garbage</b> <b>collection</b> was stimulated by its use in Lisp.|$|R
40|$|In {{this project}} we present an {{improved}} <b>garbage</b> <b>collection</b> scheme for YAFFS 2 (Yet Another Flash File System). Our {{objective was to}} reduce the number of Aggressive <b>Garbage</b> <b>Collections</b> in <b>Garbage</b> <b>Collection</b> module of YAFFS 2. We explore the various values of beta (ratio of number of erased chunks to number of free chunks) experimentally and try to find the optimal value of beta for which number of Aggressive <b>Garbage</b> <b>Collections</b> (<b>Garbage</b> <b>Collection)</b> is the least. Extensive tests were conducted by varying the value of beta (0 < beta< 1). A total of three tests were used to determine the number of <b>Garbage</b> <b>Collections</b> in different scenarios: a write test (clean write as well as overwrites), an erase test and a post erase test <b>Garbage</b> <b>Collection</b> monitoring test. A generic write test and an erase test were provided with YAFFS 2 source code, which needed little modifications. The last test was developed by us as the situation demanded. Reduction in the number of Aggressive <b>Garbage</b> <b>Collections</b> reduces computational load on the processor, which in turn saves power, especially in battery powered devices...|$|R
40|$|Languages {{featuring}} automatic {{memory management}} (<b>garbage</b> <b>collection)</b> are increasingly {{used to write}} all kinds of applications because they provide clear software engineering and security advantages. Unfortunately, <b>garbage</b> <b>collection</b> imposes a toll on performance and introduces pause times, making such languages less attractive for high-performance or real-time applications. Much {{progress has been made}} over the last five decades to reduce the overhead of <b>garbage</b> <b>collection,</b> but it remains significant. We propose a cooperative hardware-software technique to reduce the performance overhead of <b>garbage</b> <b>collection.</b> The key idea is to reduce the frequency of <b>garbage</b> <b>collection</b> by efficiently detecting and reusing dead memory space in hardware via hardwareimplemented reference counting. Thus, even though software <b>garbage</b> <b>collections</b> are still eventually needed, they become much less frequent and have less impact on overall performance. Our technique is compatible with a variety of software <b>garbage</b> <b>collection</b> algorithms, does not break compatibility with existing software, and reduces <b>garbage</b> <b>collection</b> time by 31 % on average on the Java Da-Capo benchmarks running on the production build of the Jikes RVM, which uses a state-of-the-art generational garbage collector...|$|R
40|$|The {{costs of}} {{executing}} traditional <b>garbage</b> <b>collection</b> algorithms most generally {{include not only}} the costs of allocating and reclaiming memory, but also the overhead costs imposed by the <b>garbage</b> <b>collection</b> system on standard memory modification and lookup operations. This paper outlines {{the design of a}} general purpose <b>garbage</b> <b>collection</b> system that uses specialized hardware to allow standard memory access and modification operations to perform nearly as well as traditional memory. Allocation and <b>garbage</b> <b>collection</b> are as efficient as more traditional stop-and-wait <b>garbage</b> <b>collection</b> systems. The cost of the specialized hardware is relatively small in comparison to the cost of the memory it manages. Introduction Recent research has made possible full-fledged <b>garbage</b> <b>collection</b> of memory associated with realtime systems [1 - 4]. The <b>garbage</b> <b>collection</b> algorithm is real time {{in the sense that the}} time required to read and write each word of memory is bounded by a small constant. T [...] ...|$|R
40|$|Abstract—This paper {{presents}} a mechanism that uses off-line profile information to examine when garbage is best collected. This information is {{then used to}} guide the <b>garbage</b> <b>collection</b> frequency {{in order to reduce}} the <b>garbage</b> <b>collection</b> time and total execution time. Keywords—Java, <b>garbage</b> <b>collection,</b> scheduling I...|$|R
50|$|While the Objective-C {{traditionally}} had no <b>garbage</b> <b>collection,</b> {{with the}} release of OS X 10.5 in 2007 Apple introduced <b>garbage</b> <b>collection</b> for Objective-C 2.0, using an in-house developed runtime collector.However, with the 2012 release of OS X 10.8, <b>garbage</b> <b>collection</b> was deprecated in favor of LLVM's automatic reference counter (ARC) that was introduced with OS X 10.7. Furthermore, since May 2015 Apple even forbids the usage of <b>garbage</b> <b>collection</b> for new OS X applications in the App Store. For iOS, <b>garbage</b> <b>collection</b> has never been introduced due to problems in application responsivity and performance; instead, iOS uses ARC.|$|R
40|$|Programmers {{are writing}} {{a rapidly growing}} number of {{programs}} in object-oriented languages, such as Java and C#, that require <b>garbage</b> <b>collection.</b> <b>Garbage</b> <b>collection</b> traces and simulation speed up research by enabling deeper understandings of object lifetime behavior and quick exploration and design of new <b>garbage</b> <b>collection</b> algorithms. When generating perfect traces, the brute-force method of computing object lifetimes requires a whole-heap <b>garbage</b> <b>collection</b> at every potential collection point in the program. Because this process is prohibitively expensive, researchers often use granulated traces by collecting only periodically, for example, every 32 KB of allocation. We extend {{the state of the}} art for simulating <b>garbage</b> <b>collection</b> algorithms in two ways. First, we develop a systematic methodology for simulation studies of copying <b>garbage</b> <b>collection</b> and present results showing the effects of trace granularity on these simulations. We show that trace granularity often distorts simulated <b>garbage</b> <b>collection</b> results compared with perfect traces. Second, we present and measure the performance of a new algorithm called Merlin for computing object lifetimes...|$|R
50|$|Henry Lieberman and Carl Hewitt 1983 {{developed}} a real time <b>garbage</b> <b>collection</b> {{based on the}} lifetimes of Actors (Objects). The fundamental idea was to allocate Actors (objects) in generations so that only the latest generations {{would have to be}} examined during a <b>garbage</b> <b>collection.</b> See generational <b>garbage</b> <b>collection.</b>|$|R
5000|$|Java offers {{automatic}} <b>garbage</b> <b>collection,</b> {{which may}} be bypassed in specific circumstances via the Real time Java specification. Memory management in C++ is usually done via constructors, destructors, and smart pointers. The C++ standard permits <b>garbage</b> <b>collection,</b> but does not require it. <b>Garbage</b> <b>collection</b> is rarely used in practice.|$|R
5000|$|Genera {{supports}} {{several different}} types of garbage collection: full <b>Garbage</b> <b>Collection,</b> in-place <b>Garbage</b> <b>Collection,</b> Incremental <b>Garbage</b> <b>Collection</b> and Ephemeral <b>Garbage</b> <b>Collection.</b> The Ephemeral <b>Garbage</b> Collector only uses physical memory and uses the memory management unit to get information about changed pages in physical memory. The garbage collector uses generations and the virtual memory is divided into areas. Areas can contain objects of certain types (strings, bitmaps, pathnames, ...) and each area can use different memory management mechanisms.|$|R
50|$|Distributed <b>garbage</b> <b>collection</b> (DGC) in {{computing}} is {{a particular}} case of <b>garbage</b> <b>collection</b> where a remote client can hold references to an object.|$|R
40|$|<b>Garbage</b> <b>collection</b> {{has been}} a {{necessary}} evil of computer languages that employ dynamic data structures. The 1990 's has seen some significant technology shifts that present new challenges for automatic <b>garbage</b> <b>collection.</b> In particular, distributed systems are providing an economical approach to parallel processing. Many distributed <b>garbage</b> <b>collection</b> algorithms have been proposed but few have been analysed or evaluated. To take advantage of distributed systems, precise evaluation of new distributed <b>garbage</b> <b>collection</b> algorithms is prudent. This thesis presents an empirical evaluation of the several important distributed <b>garbage</b> <b>collection</b> algorithms. All proposals for distributed garbage collectors stem from uniprocessor collectors. For this reason, uniprocessor garbage collectors are first surveyed and classified. Then we give a survey of distributed <b>garbage</b> <b>collection</b> schemes and develop a taxonomy {{in terms of the}} issues of distribution. In the light of the surveys, we describe the g [...] ...|$|R
40|$|Abstract — In the past, <b>garbage</b> <b>collection</b> {{was often}} {{dismissed}} for performance critical applications {{as not being}} able to provide adequate performance, especially for real-time applications. But incremental <b>garbage</b> <b>collection</b> algorithms are quite capable of providing real time performance at acceptable latencies. There is also the possibility of providing hardware support to further reduce latency. There are also approaches for using <b>garbage</b> <b>collection</b> on embedded systems, where {{it is important not to}} waste too much memory on fragmentation. This paper is the second part of a three paper series intending to give an introduction to different approaches to real-time memory management through incremental <b>garbage</b> <b>collection</b> algorithms. Building on the basic algorithms presented in the first part of this series, this paper introduces some advanced algorithms to improve the performance, make the algorithms more appropriate for uncooperative environments and reduce memory usage, making real-time <b>garbage</b> <b>collection</b> feasible for embedded systems. There is also a short chapter about hardware supported <b>garbage</b> <b>collection.</b> Index Terms — <b>Garbage</b> <b>collection,</b> real-time, embedded systems, Treadmill, operating system...|$|R
40|$|Replication-based {{incremental}} <b>garbage</b> <b>collection</b> [5, 4] {{is one of}} {{the more}} appealing concurrent <b>garbage</b> <b>collection</b> algorithms known today. It allows continuous operation of the application (the mutator) with very short pauses for <b>garbage</b> <b>collection.</b> There is a growing need for such garbage collectors suitable for a multithreaded environments such as the Java Virtual Machine...|$|R
40|$|RESEARCH ACTIVITIES My {{research}} {{focuses on}} choosing appropriate memory management schemes for real-time applications written in programming languages like Java. Two major schemes have been presented in the literature: the use of real-time <b>garbage</b> <b>collection</b> {{and the use of}} memory models that do not involve <b>garbage</b> <b>collection.</b> One of my research directions includes analyzing the cost associated with memory models that do not involve <b>garbage</b> <b>collection.</b> Since real-time <b>garbage</b> <b>collection</b> is presented as a viable option for managing memory for real-time application written in Java, another facet of my research concerns the optimization of novel approaches to <b>garbage</b> <b>collection</b> on multi-processor systems. I am also interested in developing a taxonomy that unifies the theory of garbag...|$|R
50|$|If user-specified finalizers are allowed, it is {{possible}} for finalization to cause object resurrection, as the finalizers can run arbitrary code, which may create references from live objects to objects being destroyed. For languages without <b>garbage</b> <b>collection,</b> this is a severe bug, and causes dangling references and memory safety violations; for languages with <b>garbage</b> <b>collection,</b> this is prevented by the garbage collector, most commonly by adding another step to <b>garbage</b> <b>collection</b> (after running all user-specified finalizers, check for resurrection), which complicates and slows down <b>garbage</b> <b>collection.</b>|$|R
40|$|Hardware-Assisted <b>garbage</b> <b>collection</b> for Icon {{guarantees}} real-time {{response and}} consistent performance. This report describes the changes made to Icon 2 ̆ 7 s run-time system in porting Icon to the hardware-assisted <b>garbage</b> <b>collection</b> environment and compares {{the performance of}} fifty Icon programs using the traditional and hardware-assisted <b>garbage</b> <b>collection</b> implementations. Throughput for the hardware-assisted system ranges from 45...|$|R
40|$|This paper {{describes}} a memory discipline that combines region-based memory management and copying <b>garbage</b> <b>collection</b> by extending Cheney's copying <b>garbage</b> <b>collection</b> algorithm {{to work with}} regions. The paper presents empirical evidence that region inference very significantly reduces the number of garbage collections; and evidence that the fastest execution is obtained by using regions alone, without <b>garbage</b> <b>collection...</b>|$|R
