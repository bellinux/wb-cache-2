13|17|Public
2500|$|The then UMNO Youth Leader Anwar Ibrahim {{also said}} {{use of the}} term [...] "barbaric" [...] was regrettable. He said [...] "It is a <b>generative</b> <b>word</b> that passes {{judgement}} on our society—something we cannot accept and did not expect from such a friendly country." [...] He argued that the consequences of drug trafficking were well known in Malaysia, and the need for strong deterrents to eliminate the activity was accepted internationally.|$|E
5000|$|The then UMNO Youth Leader Anwar Ibrahim {{also said}} {{use of the}} term [...] "barbaric" [...] was regrettable. He said [...] "It is a <b>generative</b> <b>word</b> that passes {{judgement}} on our society—something we cannot accept and did not expect from such a friendly country." [...] He argued that the consequences of drug trafficking were well known in Malaysia, and the need for strong deterrents to eliminate the activity was accepted internationally.The conference of State Legislative Assembly speakers in Shah Alam also rejected Hawke's comment. They said it gave the impression Australia belittled Malaysian law and [...] "considers the capital punishment meted out to the two as uncivilised and unsuitable for this day and age." [...] The speakers at the conference unanimously passed an emergency resolution expressing their [...] "grave view" [...] of the statement. The conference felt that such comments should not have come from a national leader who upheld the law and that the statement had touched on the sovereignty of Malaysia's laws and the legal system.|$|E
40|$|Word {{alignment}} is {{a fundamental}} component for all SMT systems • Word-based SMT • Phrase-based SMT (PB-SMT) : conditional v. s. joint model • Formal syntax-based SMT: hiero-style v. s. ITG • Syntax-based SMT: Tree-to-String, String-to-Tree, Tree-to-Tree Approaches to word alignment • <b>Generative</b> <b>word</b> alignment • Discriminative word alignment • Heuristics-based word alignment • A mixture of above mentioned approache...|$|E
50|$|Merge merges two {{constituents}} in such {{a manner}} that these constituents become sister constituents and are daughters of the newly created mother constituent. This understanding of how structure is generated is constituency-based (as opposed to dependency-based). Dependency grammars (e.g. Meaning-Text Theory, Functional <b>Generative</b> Description, <b>Word</b> grammar) disagree with this aspect of Merge, since they take syntactic structure to be dependency-based.|$|R
5000|$|Furthermore, In Empowering Education, Ira Shor delineates a {{pedagogy}} {{in which}} the teacher facilitates discussion of generative themes produced by the students, and provides the example of his basic writing course with working-class students at [...] "a low-budget college in New York City" [...] several decades ago (10). The Freirean approach for teaching literacy and writing that Shor reviews in Empowering Education demonstrates how the <b>generative</b> <b>words</b> manifested themselves [...] "through researching local issues and language in the students' communities. From the many linguistic and sociological items…the educators selected some key concerns—generative themes expressed through generative words" [...] (55). In this framework, teachers and students research these items collaboratively, and once students have presented their research on problems in their community, they may begin to decide how they might analyze and upend power structures or rhetorical situations that contribute to and exacerbate such issues. For Shor's classroom, [...] "the generative themes have emerged…from student culture have most often related to sex, abortion, drugs, family, education, careers, work, and the economic crisis" [...] (56). Shor believes {{it is important to}} allow students to build a basis for problem-posing upon their prior knowledge and experiences to make it multicultural.|$|R
40|$|In this paper, I {{explore the}} {{semantic}} interpretation of sortally ambiguous nominalizations in syntactic ap-proaches to word formation {{in which there}} is no <b>generative</b> lexicon but <b>word</b> formation is entirely syntactic (i. e. in the tradition of Halle and Marantz [1993], Hale and Keyser [1993], Marantz [1997], Alexiadou [2001], Borer [2005]) ...|$|R
40|$|We {{present a}} general {{framework}} to incorporate prior knowledge such as heuristics or linguistic features in statistical <b>generative</b> <b>word</b> alignment models. Prior knowledge {{plays a role}} of probabilistic soft constraints between bilingual word pairs that shall be used to guide word alignment model training. We investigate knowledge that can be derived automatically from entropy principle and bilingual latent semantic analysis and show {{how they can be}} applied to improve translation performance. ...|$|E
40|$|Word {{alignment}} is {{the problem}} of annotating parallel text with translational correspondence. Previous <b>generative</b> <b>word</b> alignment models have made structural assumptions such as the 1 -to- 1, 1 -to-N, or phrase-based consecutive word assumptions, while previous discriminative models have either made such an assumption directly or used features derived from a generative model making one of these assumptions. We present a new generative alignment model which avoids these structural limitations, and show that it is effective when trained using both unsupervised and semi-supervised training methods. ...|$|E
40|$|Abstract—Many {{document}} {{collections of}} historical interest are handwritten and lack transcripts. Scholars need tools for high-quality information retrieval in such environments, preferably without {{the burden of}} extensive system training. This paper presents a novel approach to word spotting designed for manuscripts or degraded print that requires minimal initial training. It can infer a <b>generative</b> <b>word</b> appearance model from a single instance, and then use the model to retrieve similar words from arbitrary documents. An approximation to the retrieval statistic runs efficiently on graphics processing hardware. Tested on two standard data sets, the method compares favorably with prior results. I...|$|E
40|$|In {{this paper}} we sketch {{a model of}} grammar that is {{developed}} in detail in Ackema & Neeleman (to appear). We focus on the relation between syntax and morphology, and more specifically on the question {{whether there is a}} <b>generative</b> system for <b>word</b> formation separate from syntax. This is quite often denied: various authors argue that wor...|$|R
40|$|We {{present a}} novel {{framework}} for word alignment that incorporates synonym knowledge collected from monolingual linguistic resources in a bilingual probabilistic model. Synonym information is helpful for word alignment {{because we can}} expect a synonym to correspond to the same word in a different language. We design a <b>generative</b> model for <b>word</b> alignment that uses synonym information as a regularization term. The experimental results show that our proposed method significantly improves word alignment quality. ...|$|R
40|$|This paper {{presents}} the results of an evaluation of the Kenya Functional Literacy Programme, conducted on an experimental basis in six divisions (counties) {{in different parts of the}} country as part of the Special Rural Development Programme. The main problem with the literacy programme may be that it is too ambitious. Through the same set of texts it attempts to achieve three goals: first, the attainment of literacy, second, knowledge of the Swahili language, and third, knowledge of practical facts about agriculture, health and household management. By not establishing a priority order among these objectives, the programme risks failing to attain any of them. Little advantage is taken of the fact that Swahili, unlike English, is a phonetic language in which sounds are connected to written symbols in a rational and consistent manner. Students are not systematically taught the sound-values for each symbol, so they acquire only slowly the knowledge and skill needed to tackle the reading of new words for themselves. Instead, throughout the course each new word is learned first as a whole, by rote-memorisation. The period in which students remain intellectually dependent on their teachers is thus prolonged. An alternative teaching method based on the rapid breaking down of a few well-known and meaningful <b>generative</b> <b>words</b> into their simplest components is suggested. Virtually no account is taken of the fact that for most learners Swahili is a little-known second language. The order in which new words are introduced bears little relationship to their linguistic or phonetic difficulty. Forgetting of new words thus tends to be rapid. The information and advice given in the booklets about farming is sometimes inconsistent with existing knowledge, and often fails to take into account the constraints under which low-income families in Kenya live. If the new information to which learners are exposed is not both accurate and relevant, very little of what is taught will lead to permanent behaviour changes...|$|R
40|$|We {{introduce}} a syntactically enhanced word alignment model {{that is more}} flexible than state-of-the-art <b>generative</b> <b>word</b> alignment models and can be tuned according to different end tasks. First of all, this model takes the advantages of both unsupervised and supervised word alignment approaches by obtaining anchor alignments from unsupervised generative models and seeding the anchor alignments into a supervised discriminative model. Second, this model offers the flexibility of tuning the alignment according to different optimisation criteria. Our experiments show that using our word alignment in a Phrase-Based Statistical Machine Translation system yields a 5. 38 % relative increase on IWSLT 2007 task in terms of BLEU score. ...|$|E
40|$|<b>Generative</b> <b>word</b> {{alignment}} models, such as IBM Models, {{are restricted}} to one-to-many alignment, and cannot explicitly represent many-to-many relationships in a bilingual text. The problem is par-tially solved either by introducing heuris-tics or by agreement constraints such that two directional word alignments agree with each other. In this paper, we fo-cus on the posterior regularization frame-work (Ganchev et al., 2010) that can force two directional word alignment models to agree with each other during train-ing, and propose new constraints that can {{take into account the}} difference between function words and content words. Ex-perimental results on French-to-English and Japanese-to-English alignment tasks show statistically significant gains over the previous posterior regularization baseline. We also observed gains in Japanese-to-English translation tasks, which prove the effectiveness of our methods under gram-matically different language pairs. ...|$|E
40|$|We {{describe}} {{a method to}} align ASL video subtitles with a closed-caption transcript. Our alignments are partial, based on spotting words within the video sequence, which consists of joined (rather than isolated) signs with unknown word boundaries. We start with windows known to contain {{an example of a}} word, but not limited to it. We estimate the start and end of the word in these examples using a voting method. This provides a small number of training examples (typically three per word). Since there is no shared struc-ture, we use a discriminative rather than a <b>generative</b> <b>word</b> model. While our word spotters are not perfect, they are suffi-cient to establish an alignment. We demonstrate that quite small numbers of good word spotters results in an alignment good enough to produce simple English-ASL translations, both by phrase matching and using word substitution. Key...|$|E
40|$|This thesis {{seeks to}} engage {{with the city of}} Johannesburg on terms that break decisively with the linear-historical methods that have been used to both {{catalogue}} and decipher the city up to the present. The city is, itself, in its second incarnation - that of the post-apartheid, post-gold mining metropolis - and the fact of this historic overturning demands reappraisal of what Johannesburg is, and more importantly, what it can become. Its complexities stand in stark opposition to an apparent banality that arises from the ease with which it is visually apprehended. Words form a core of this thesis, used not only in their capacity to reveal through what they say, but through the possibilities created in the spaces between unrelated and related texts (what they do not say). The thesis has thus been concerned with the juxtaposition of words - fiction and non· fiction - as well as their mapping and diagramming, in order to foster new conceptualizations of a city whose blatancy is simultaneously its lifeblood and its problem. The <b>generative</b> <b>words</b> in this context have been those of the thirteen fictions written specifically for the thesis. These stand as a representation of the creative act that is here seen as being fundamental to the re-imagining of Johannesburg; to get beyond the image/face of the city in order to view the human substrata. Additionally, two architectural "provocations" are offered as vehicles for ways in which the city can begin to be re ·imagined. Both of these projects engage with the idea of "absorption" (removal from contingency, to focus on transcendental endeavors), and the notion of the architectural project as a generator, not specifically for what it is, but for what it represents. These architectural projects are, within the context of t he thesis, Brecht's "fragile instruments". by Paul Harry Schlapobersky. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Architecture, 2002. Includes bibliographical references (p. 91 - 92) ...|$|R
40|$|This paper {{considers}} extractive summarization of Chinese spoken documents. In {{contrast to}} conventional approaches, {{we attempt to}} deal with the extractive summarization problem under a probabilistic <b>generative</b> framework. A <b>word</b> topical mixture model (w-TMM) was proposed to explore the co-occurrence relationship between words of the language. Each sentence of the spoken document to be summarized was treated as a composite word TMM model for generating the document, and sentences were ranked and selected according to their likelihoods. Various kinds of modeling structures and learning approaches were extensively investigated. In addition, the summarization capabilities were verified by comparison with the other conventional summarization approaches. The experiments were performed on the Chinese broadcast news collected in Taiwan. Noticeable performance gains were obtained. The proposed summarization technique has also been properly integrated into our prototype system for voice retrieval of broadcast news via mobile devices. 1...|$|R
40|$|Words are everywhere. Ubiquitous, pervasive. Yet our {{relations}} with words are narrowly defined. How does the sound, feel, touch, taste, place, position, speed, and direction of words come to matter in their uses? Word begins from the premise that, if we consider words {{only in terms of}} language and as images, we overlook a range of bodily, sensory, affective and non-conscious relations with words. We overlook, too, their epistemological, methodological, experiential and political implications. This book seeks to redress this neglect by exploring words themselves in histories of language and contemporary theory, in print and typography, and through a series of empirical examples which include religion, embodiment, photography and performance. Word is a reminder that words live richly in the world. It is an invitation to recognise those non-linguistic word-relations that are already existing, and to bring new and <b>generative</b> encounters with <b>words</b> into being...|$|R
40|$|We {{introduce}} a word alignment framework that facilitates {{the incorporation of}} syntax encoded in bilingual dependency tree pairs. Our model consists of two sub-models: an anchor word alignment model which aims to find a set of high-precision anchor links and a syntaxenhanced word alignment model which focuses on aligning the remaining words relying on dependency information invoked by the acquired anchor links. We show that our syntaxenhanced word alignment approach leads to a 10. 32 % and 5. 57 % relative decrease in alignment error rate compared to a <b>generative</b> <b>word</b> alignment model and a syntax-proof discriminative word alignment model respectively. Furthermore, our approach is evaluated extrinsically using a phrase-based statistical machine translation system. The results show that SMT systems based on our word alignment approach tend to generate shorter outputs. Without length penalty, using our word alignments yields statistically significant improvement in Chinese–English machine translation {{in comparison with the}} baseline word alignment. ...|$|E
40|$|Most {{existing}} {{word embedding}} methods {{can be categorized}} into Neural Embedding Models and Matrix Factorization (MF) -based methods. However some mod-els are opaque to probabilistic interpre-tation, and MF-based methods, typically solved using Singular Value Decomposi-tion (SVD), may incur loss of corpus in-formation. In addition, it is desirable to incorporate global latent factors, such as topics, sentiments or writing styles, into the word embedding model. Since gen-erative models provide a principled way to incorporate latent factors, we propose a <b>generative</b> <b>word</b> embedding model, which is easy to interpret, and {{can serve as a}} basis of more sophisticated latent factor models. The model inference reduces to a low rank weighted positive semidefinite approximation problem. Its optimization is approached by eigendecomposition on a submatrix, followed by online blockwise regression, which is scalable and avoids the information loss in SVD. In experi-ments on 7 common benchmark datasets, our vectors are competitive to word 2 vec, and better than other MF-based methods. ...|$|E
40|$|Aligning ASL for {{statistical}} translation using a discriminative word model We describe {{a method to}} align ASL video subtitles with a closed-caption transcript. Our alignments are partial, based on spotting words within the video sequence, which consists of joined (rather than isolated) signs with unknown word boundaries. We start with windows known to contain {{an example of a}} word, but not limited to it. We estimate the start and end of the word in these examples using a voting method. This provides a small number of training examples (typically three per word). Since there is no shared structure, we use a discriminative rather than a <b>generative</b> <b>word</b> model. While our word spotters are not perfect, they are sufficient to establish an alignment. We demonstrate that quite small numbers of good word spotters results in an alignment good enough to produce simple English-ASL translations, both by phrase matching and using word substitution. Keywords...|$|E
40|$|Many natural {{language}} generation tasks, such as abstractive summarization and text simplification, are paraphrase-orientated. In these tasks, copying and rewriting are two main writing modes. Most previous sequence-to-sequence (Seq 2 Seq) models use a single decoder and neglect this fact. In this paper, we develop a novel Seq 2 Seq model to fuse a copying decoder and a restricted generative decoder. The copying decoder finds the position to be copied based on a typical attention model. The <b>generative</b> decoder produces <b>words</b> limited in the source-specific vocabulary. To combine the two decoders and determine the final output, we develop a predictor to predict the mode of copying or rewriting. This predictor can be guided by the actual writing mode in the training data. We conduct extensive experiments on two different paraphrase datasets. The result shows that our model outperforms the state-of-the-art approaches {{in terms of both}} informativeness and language quality. Comment: 7 pages, 1 figure, AAAI- 1...|$|R
40|$|This {{studies or}} {{the aim of}} the {{research}} is to deals the <b>generative</b> “morphems, <b>words</b> or “simple or compound[1]” sentence. The full congrast of Albanian and English language in this phenomena of generative is in morphology and in syntactic structure. This accepts of studies will comparted, contrasted and generated between two languages. This studies deals with noun (noun phrase), verb (verb phrase) of syntactic structure between Albanian and English language. In both of languages, most linguists (or scholars) are agree because has the contrast between Alb. – Eng. The following classes words: noun, verb, adjective, preposition, adverb, determinative and conjunction can generate. Each of these words classes is illustrated in the sentence below. The function of noun (or noun phrase) in the sentence can have the meaning of subject[2], direct object[3], indirect object[4] and “predicate” (…). The function of verb or verb phase in the sentence can have the predicate ( [...] .). [1] Shkelqim Millaku, THE CONTRAST OF THE COMPOUND WORDS BETWEEN ENGLISH AND ALBANIAN LANGUAGE, European Journal of Foreign Language Teaching ISSN: 2537 - 1754 ISSN-L: 2537 - 1754 Available on-line at: [URL] [URL] [2] Shkelqim Millaku, THE FUNCTION OF ALBANIAN AND ENGLISH SENTENCE, European Journal of English Language Teaching ISSN: 2501 - 7136 ISSN-L: 2501 - 7136 Available on-line at: [URL] [3] Shkelqim Millaku, The direct object, ANGLISTICUM. Journal of the Association for Anglo-American Studies, Volume 4, issue 1, 2015, e-ISSN: 1857 - 8187 p-ISSN: 1857 - 8179, [URL] [4] Shkelqim Millaku, THE INDIRECT OBJECT (IO) – ALBANIAN AND ENGLISH, European Journal of Foreign Language Teaching ISSN: 2537 - 1754 ISSN-L: 2537 – 1754, [URL]...|$|R
40|$|Abstract. Twitter {{has brought}} much {{attention}} {{recently as a}} hot research topic {{in the domain of}} sentiment analysis. Training sentiment classifiers from tweets data often faces the data sparsity problem partly due to the large variety of short forms introduced to tweets because of the 140 -character limit. In this work we propose using semantic smoothing to alleviate the data sparseness problem. Our approach extracts semantically hidden concepts from the training documents and then incorporates these concepts as additional features for classifier training. We tested our approach using two different methods. One is shallow semantic smoothing where words are replaced with their corresponding semantic concepts; another is to interpolate the original unigram language model in the Naive Bayes (NB) classifier with the <b>generative</b> model of <b>words</b> given semantic concepts. Preliminary results show that with shallow semantic smoothing the vocabulary size has been reduced by 20 %. Moreover, the interpolation method improves upon shallow semantic smoothing by over 5 % in sentiment classification and slightly outperforms NB trained on unigrams only without semantic smoothing. ...|$|R
40|$|Word {{alignment}} is {{a fundamental}} and crucial component in Statistical Machine Translation (SMT) systems. Despite the enormous progress {{made in the past}} two decades, this task remains an active research topic simply because the quality of word alignment is still far from optimal. Most state-of-the-art word alignment models are grounded on statistical learning theory treating word alignment as a general sequence alignment problem, where many linguistically motivated insights are not incorporated. In this thesis, we propose new word alignment models with linguistically motivated constraints in a bid {{to improve the quality of}} word alignment for Phrase-Based SMT systems (PB-SMT). We start the exploration with an investigation into segmentation constraints for word alignment by proposing a novel algorithm, namely word packing, which is motivated by the fact that one concept expressed by one word in one language can frequently surface as a compound or collocation in another language. Our algorithm takes advantage of the interaction between segmentation and alignment, starting with some segmentation for both the source and target language and updating the segmentation with respect to the word alignment results using state-of-the-art word alignment models; thereafter a refined word alignment can be obtained based on the updated segmentation. In this process, the updated segmentation acts as a hard constraint on the word alignment models and reduces the complexity of the alignment models by generating more 1 -to- 1 correspondences through word packing. Experimental results show that this algorithm can lead to statistically significant improvements over the state-of-the-art word alignment models. Given that word packing imposes "hard" segmentation constraints on the word aligner, which is prone to introducing noise, we propose two new word alignment models using syntactic dependencies as soft constraints. The first model is a syntactically enhanced discriminative word alignment model, where we use a set of feature functions to express the syntactic dependency information encoded in both source and target languages. One the one hand, this model enjoys great flexibility in its capacity to incorporate multiple features; on the other hand, this model is designed to facilitate model tuning for different objective functions. Experimental results show that using syntactic constraints can improve the performance of the discriminative word alignment model, which also leads to better PB-SMT performance compared to using state-of-the-art word alignment models. The second model is a syntactically constrained <b>generative</b> <b>word</b> alignment model, where we add in a syntactic coherence model over the target phrases in the context of HMM word-to-phrase alignment. The advantages of our model are that (i) the addition of the syntactic coherence model preserves the efficient parameter estimation procedures; and (ii) the flexibility of the model can be increased so that it can be tuned according to different objective functions. Experimental results show that tuning this model properly leads to a significant gain in MT performance over the state-of-the-art...|$|E
40|$|In {{comparison}} with the fields of phonology, syntax, and semantics, there is a distinct lack of a comprehensive and critical study of morphological theory, particularly modern trends in this sub-branch of linguistic theory. There is also a marked {{lack of interest in}} the underlying methodological and epistemological foundations of morphological theory, though this situation also holds for the three other areas of core-linguistics mentioned above. The present thesis has a modest aim: it is to give a critical and fairly comprehensive study of five modern morphological approaches, with particular reference, whenever possible, to their underlying methodological and epistemological principles. This thesis contains six chapters and a short Introduction. The Introduction deals with the place and state of morphological studies in modern linguistic theory. It also sets out the 'reasons' behind the restriction of the scope of the thesis to the following five approaches: (1) stratificational grammar, (2) transformational <b>generative</b> grammar, (3) <b>word</b> and paradigm I (Robins), (4) word and paradigm II (Matthews), and (5) axiomatic functionalism. A brief explanation of the format of the approach adopted in studying these different trends is also given here. [Only transcribed in part due to abstract length]...|$|R
40|$|GenJam, {{short for}} Genetic Jammer, is an {{evolutionary}} computation (EC) based software agent that models a jazz improviser. Recently GenJam has evolved {{away from its}} roots as an interactive genetic algorithm toward its current state as an autonomous generative system. GenJam has retained its chromosome-based representations and mappings, its intelligent selection, crossover and mutation operators, and its real-time interactive performance capabilities. However, it no longer needs any explicit representation of fitness, which arguably makes it no longer an EC system. This paper considers GenJam as a generative art system. Generative art produces “unique and non-repeatable events ” that express a designer’s generating idea. The designer’s generating idea defines a species of events, represented in a genetic code. In music, these events could be individual notes, melodic phrases, even entire pieces. In GenJam the events are four-measure phrases, or “licks ” in the jazz vernacular. The format for the genetic code, then, defines a species space from which unique individual events can be generated. Uniqueness is important in jazz because improvisation must be spontaneous and “new. ” Hence, improvisation is tailor-made for the generative art paradigm, and in fact, {{one could argue that}} improvisation is, by definition, the purest example of generative art applied to music. In other <b>words,</b> <b>generative</b> music is improvisation, and GenJam is the Generative Jammer...|$|R
40|$|Twenty {{years ago}} {{morphological}} analysis of natural language {{was a challenge}} to computational linguists. Simple cut-and-paste programs could be and were written to analyze strings in particular languages, {{but there was no}} general language-independent method available. Furthermore, cut-and-paste programs for analysis were not reversible, they could not be used to generate <b>words.</b> <b>Generative</b> phonologists of that time described morphological alternations by means of ordered rewrite rules, but it was not understood how such rules could be used for analysis. This was the situation in the spring of 1981 when Kimmo Koskenniemi came to a conference on parsing that Lauri Karttunen had organized at the University of Texas at Austin. Also at the same conference were two Xerox researchers from Palo Alto, Ronald M. Kaplan and Martin Kay. The four Ks discovered that all of them were interested and had been working on the problem of morphological analysis. Koskenniemi went on to Palo Alto to visit Kay and Kaplan at PARC. This was the beginning of Two-Level Morphology, the first general model in the history of computational linguistics for the analysis and generation of morphologically complex languages. The language-specific components, the lexicon and the rules, were combined with a runtime engine applicable to all languages. In this article we trace the development of the finite-state technology that Two-Level Morphology is based on. 1 The Origins Traditional phonological grammars, formalized in the 1960 s by Noam Chomsky and Morris Halle (Chomsky and Halle, 1968), consisted of an ordered sequence of rewrite rules that converted abstract phonological representations into surface forms through a series of intermediate representations. Such rules have the general form x-> y / z w where x, y, z, and w can be arbitrarily complex strings or feature-matrices. In mathematical linguistics (Partee et al., 1993), such rules are called CONTEXT-SENSITIVE REWRITE RULES, and they are more powerful than regular expressions or context-free rewrite rules...|$|R
40|$|In the 1950 s Brazil {{experienced}} transformative changes {{including the}} nascent emergence of democratic elections after 15 years of repressive dictatorship, {{the suicide of}} its President {{and the construction of}} a new federal capital city in Brasília. Optimism and a forward-looking spirit, summarized in the 1956 Presidential motto, " 50 years of progress in 5," suffused all spheres of the national experience. The modernization of Brazil would translate into the end of underdevelopment and a structure of dependency put in place with colonialism. My dissertation explores this historical moment through the Rio de Janeiro-based geometric abstract art movement, Neoconcretism. I study how this group of artists intersected with and contributed to the growing network of modernizing institutions that held the promise of a Brazil finally "catching up. " Influenced by early twentieth century European avant-garde art styles, Neoconcrete art brought together an art practice and theory based in expressiveness, intersubjectivity and sensorial experience, which continues to influence contemporary Latin American art production today. In this project I argue that Neoconcretism was a transformative cultural force that shaped Brazilian modernism and national culture. Neoconcrete artists and aesthetic ideals contributed to many areas of national production including literature, the newspaper industry, education, and architecture and urbanism. Departing from scholarship that examines Neoconcretism within the internationalization of Latin American art, I am especially attentive to the influence of local discourses on its stylistic and intellectual formation. Given the group's collaborative nature, I use an interdisciplinary and cultural studies methodology to examine the artworks and writings of the group members in relationship to the national project of modernization and nation-building developed by the governmental sectors, private institutions and the intellectual and cultural classes. My dissertation underscores the way culture operated as an essential political tool, distinct from traditional genres such as propaganda, in the production of the "national". The collaborative and interdisciplinary nature of the Neoconcretists structures the organization of the dissertation and each chapter is conceived as a dialogical relationship between members of the group and Brazilian society. Chapter one establishes the broader Brazilian concrete project, and positions the emergence of abstract art in São Paulo and Rio de Janeiro as directly tied to the developing political and social climate proposing the construction of a "new" Brazil. In chapter two I argue for the equally <b>generative</b> roles of <b>word</b> and image in the production of meaning in Neoconcretism through an analysis of Neoconcrete poetry and the two main theoretical texts that defined Neoconcretism. I demonstrate how the movement was marked by positions of anti-progress and anti-rationalism that challenged the dominant political ideology. Chapter three turns to the Brazilian newspaper, Jornal do Brasil, which served as a place of employment for Neoconcrete artists, as well as a place of publication and circulation of Neoconcrete artworks and writings. I argue for the paper's generative role as a site of publicity for the group and its significance as a place of translation between high art and popular culture. Chapter four puts Neoconcretism and the construction of Brasília into direct engagement to argue for the influence of the national architectural boom on the artistic production of the Neoconcrete artists, but also to demonstrate how their works performed a critique of the state-sponsored project of modernization. In the dissertation I argue that the study of Neoconcretism unsettles any single narrative of Brazilian modernism and provides a lens to re-evaluate Brazil's "Years of Confidence" and the making of the nation through industrializatio...|$|R

