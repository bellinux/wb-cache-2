15|4985|Public
5000|$|SuperMICAR automates the MICAR {{data entry}} process. This program is {{designed}} as an enhancement of the earlier PC-MICAR <b>Data</b> <b>Entry</b> <b>program.</b> Super-MICAR is designed to automatically encode cause-of-death data into numeric entity reference numbers.|$|E
50|$|The MICS package also {{includes}} <b>data</b> <b>entry</b> <b>program</b> (in CSPro) catering for paper-based or tablet-based data collection, standard tabulation plan (in Excel) and syntax (in SPSS), workshop training programmes, in-country capacity building and technical assistance, data dissemination templates, {{as well as}} various online resources, such as a survey data compiler (MICS Compiler).|$|E
40|$|The Yale {{database}} contains sequence {{changes in}} mutations induced {{in a number}} of bacterial, mammalian and yeast genes. It contains data in electronic form on more than 17, 000 mutations (July, 1994), is periodically updated, and is available without cost on Internet and on diskettes. Researchers are invited to contribute additional results; a <b>data</b> <b>entry</b> <b>program,</b> MUSTIN, is provided to facilitate adding new data and to minimize errors...|$|E
40|$|Capturing {{clinical}} data is a multi-faceted problem. This paper discusses clinical <b>data</b> <b>entry</b> problems encountered {{during the}} development of an intelligent clinical <b>data</b> <b>entry</b> system. Based on a review of the problems, recommendations are made for an approach to the design of clinical <b>data</b> <b>entry</b> <b>programs.</b> These recommendations include a discussion of key components in the design process as illustrated by the development of MedIO, a C++ computer <b>program</b> for the <b>entry</b> of history and physical exam information...|$|R
40|$|The {{acceptance}} of {{data processing systems}} in a hospital environment is mainly based on the ease of use and flexibility of <b>data</b> <b>entry</b> <b>programs.</b> Physicians' demands on clinical information systems focus on humanlike interactive features which can enhance their patient management capabilities and do not force them {{to adapt to a}} computer system. This paper presents a concept which goes beyond the limits of freetext <b>data</b> <b>entry</b> systems or menu-based systems. We present strategies, but also problems arising with the implementation of intelligent data acquisition modules in clinical order <b>entry</b> <b>programs...</b>|$|R
50|$|While {{this method}} of quality control clearly is not proof against {{systematic}} errors or operator misread entries from a source document, it is very useful in catching and correcting random miskeyed strokes which occur even with experienced <b>data</b> <b>entry</b> operators. However, {{it proved to be}} a fatally tragic flaw in the Therac 25 incident. This method has survived the keypunch and is available in some currently available <b>data</b> <b>entry</b> <b>programs</b> (e.g. PSPP/SPSS <b>Data</b> <b>Entry).</b> At least one study suggests that single-pass <b>data</b> <b>entry</b> with range checks and skip rules approaches the reliability of two-pass data entry; however, it is desirable to implement both systems in a <b>data</b> <b>entry</b> application.|$|R
40|$|This {{electronic}} database is {{a collection}} of 225 sets of data on mutations in more than twenty-three thousand mutants (October, 1995) in eleven bacterial genes, five mammalian genes and one gene in yeast cells. Each dataset consists of the changes in DNA sequence in the mutants, typically tens to hundreds, induced by mutagenesis of a particular cell line under specific conditions. The database is available on the Internet and on diskettes, and is periodically updated. Researchers are invited to submit additional data. A <b>data</b> <b>entry</b> <b>program,</b> MUTSIN, is available that diagrams each mutation on the computer screen as entered and alerts the user to any inconsistency between the entry and the wild type gene sequence...|$|E
40|$|The set of {{computer}} programs described allows for data definition, data input, and data transfer between the LSI- 11 microcomputers and the VAX- 11 / 780 minicomputer. Program VAXCOM {{allows for a}} simple method of textual file transfer from the LSI to the VAX. Program LSICOM allows for easy file transfer from the VAX to the LSI. Program TTY changes the LSI- 11 operators console to the LSI's printing device. Program DICTIN provides a means for defining a data set for input to either computer. Program DATAIN is a simple to operate <b>data</b> <b>entry</b> <b>program</b> which is capable of building data files on either machine. Program LEDITV is an extremely powerful, easy to use, line oriented text editor. Program COPYSBF is designed to print out textual files on the line printer without character loss from FORTRAN carriage control or wide record transfer...|$|E
40|$|Each {{mutation}} spectrum in this database is a dataset {{of changes}} in DNA base sequence in mutations induced in a gene by a particular mutagen (including spontaneous processes) under defined conditions. There are 240 datasets with 24 500 mutants in nine bacterial genes, two phage genes, five mammalian genes and one yeast gene. The database {{is available on the}} Web at [URL]. The data tables can be viewed on the Web and downloaded in text form for local use. The data are also available in dBASE III, a format which can be utilized by essentially any desktop computer database program or spreadsheet, and makes feasible analyses {{of a large number of}} mutants. Researchers are invited to submit additional data. A <b>data</b> <b>entry</b> <b>program,</b> MUTSIN, diagrams each mutation on the computer screen as the data are entered and alerts the user to any discrepancies between the entry and the gene sequence...|$|E
50|$|This was an RPG-like {{language}} that {{ran on the}} S/34. It was focused on <b>data</b> <b>entry</b> type <b>programs.</b> WSU was free, but it wasn't particularly well-received {{because it was so}} limited.|$|R
40|$|This chapter {{describes}} {{the role of}} data management {{in the design and}} implementation of national household surveys. It starts by discussing the relationship between data management and questionnaire design. It then explores the past, present and future options for survey <b>data</b> <b>entry</b> and <b>data</b> editing, and their implications for survey management in general. The next sections provide guidelines for the definition of quality control criteria and the development of <b>data</b> <b>entry</b> <b>programs</b> for complex national household surveys, up to and including the dissemination of the survey datasets. A final section discusses the role of data management as a support for the implementation of the survey sample design...|$|R
5000|$|Data-processing error: A {{category}} of administrative error {{that occurs in}} data processing because of incorrect <b>data</b> <b>entry,</b> incorrect computer <b>programming</b> or other error during data analysis.|$|R
40|$|Includes bibliographical {{references}} (page 49) Pattern classification {{and recognition}} {{have been applied}} to solve {{a broad spectrum of}} problems in the field of engineering and science. The main concern in this project is the design and implementation of a particular kind of pattern classifier: N-class Bayes classifier. The necessary background in statistics and the detailed formulation of the Bayes rules are presented. Performance evaluation on the N-class Bayes classifier is accomplished by using the Nearest Neighbor methods to estimate the error bound of the Bayes rules. Several computer programs are developed to implement the N-class Bayes classifier. The <b>data</b> <b>entry</b> <b>program</b> in Appendix A is written for the purpose of storing sample data in a file rather than entering data interactively. The linear quadratic discriminant program in Appendix B performs Bayes classification on input data of n-dimensions, and the nearest neighbor classification program in Appendix C gives an indication of estimated performance of the Bayes classifier by calculating the misclassification error bounds...|$|E
40|$|This {{database}} {{consists of}} over 24 000 mutations in 18 viral, bacterial, yeast or mammalian genes. The data are grouped as sets of DNA base sequence changes or spectra {{caused by a}} particular mutagen under defined conditions. The spectra {{are available on the}} World Wide Web at [URL] in two formats; in text format that can be browsed on-line or downloaded for use with a text editor and in dBASEIII format for use, after downloading, by relational database programs or by spreadsheets. Researchers are encouraged to submit DNA sequence changes to a suitable mutation database such as ours. A <b>data</b> <b>entry</b> <b>program,</b> MUTSIN, can be retrieved from this site. MUTSIN diagrams each mutation on the computer screen and alerts the user to any discrepancies. INTRODUCTION This database consists of sets of mutation data, each set being a spectrum of the changes in DNA base sequence in a gene caused by a particular mutagen under defined conditions. Included are over 24 000 mutations [...] ...|$|E
40|$|The aim of {{this study}} was to develop a {{national}} database on the prevalence, severity of malocclusion and orthodontic treatment needs among Yemeni adolescents. Other variables included were geographical zones, gender and urban-rural locations. A multi-stage stratified random sample of 2400 subjects from 60 schools with equal proportion of male and female were selected from nine governorates covering the whole topography of Yemen (coastal, plateau, mountains, desert and islands). Measuring instruments were the conventional FDI/WHO method of occlusal traits (Baume et al., 1973; Berzoukov et al., 1979) and the Index of Orthodontic Treatment Needs (IOTN), (Brooke and Shaw, 1989; Richmond et al., 1995). Other occlusal traits included based on clinical oral examination were canine relationship and bimaxillary protrusion. Data collection was carried out by one examiner assisted by a recorder, using mouth mirror and the orthodontic ruler, with patient seating on a portable dental chair or classroom chair and natural light. Prior to the oral examination, the examiner was calibrated against a gold standard on children of the same age in Malaysia. A pilot study was again conducted on Yemeni children in Thamar a week before data collection began. All information gathered was checked for completeness and data was transferred into a laptop using the SPSS software <b>data</b> <b>entry</b> <b>program.</b> Analysis was carried out using the SPSS version 15 program. Measurement of occlusal traits based on FDI/WHO objective method showed that dental discrepancies was observed in 14. 6...|$|E
50|$|In the <b>data</b> <b>entry</b> {{and update}} <b>program,</b> each data field is {{displayed}} separately {{on the screen}} with a descriptive label. Fields may be skipped during entry or duplicated from the previous record.|$|R
40|$|Many {{argue that}} {{monitoring}} conducted exclusively by scientists {{is insufficient to}} address ongoing environmental challenges. One solution entails the use of mobile digital devices in participatory monitoring (PM) programs. But how digital <b>data</b> <b>entry</b> affects <b>programs</b> with varying levels of stakeholder participation, from nonscientists collecting field data to nonscientists administering every step of a monitoring program, remains unclear. We reviewed the successes, in terms of management interventions and sustainability, of 107 monitoring programs described in the literature (hereafter programs) and compared these with case studies from our PM experiences in Australia, Canada, Ethiopia, Ghana, Greenland, and Vietnam (hereafter cases). Our literature review showed that participatory programs {{were less likely to}} use digital devices, and 2 of our 3 more participatory cases were also slow to adopt digital <b>data</b> <b>entry.</b> <b>Programs</b> that were participatory and used digital devices {{were more likely to report}} management actions, which was consistent with cases in Ethiopia, Greenland, and Australia. Programs engaging volunteers were more frequently reported as ongoing, but those involving digital <b>data</b> <b>entry</b> were less often sustained when data collectors were volunteers. For the Vietnamese and Canadian cases, sustainability was undermined by a mismatch in stakeholder objectives. In the Ghanaian case, complex field protocols diminished monitoring sustainability. Innovative technologies attract interest, but the foundation of effective participatory adaptive monitoring depends more on collaboratively defined questions, objectives, conceptual models, and monitoring approaches. When this foundation is built through effective partnerships, digital <b>data</b> <b>entry</b> can enable the collection of more data of higher quality. Without this foundation, or when implemented ineffectively or unnecessarily, digital <b>data</b> <b>entry</b> can be an additional expense that distracts from core monitoring objectives and undermines project sustainability. The appropriate role of digital <b>data</b> <b>entry</b> in PM likely depends more on the context in which it is used and less on the technology itself. </p...|$|R
50|$|During the 1960s, the {{punched card}} was {{gradually}} replaced {{as the primary}} means for data storage by magnetic tape, as better, more capable computers became available. Mohawk Data Sciences introduced a magnetic tape encoder in 1965, a system marketed as a keypunch replacement which was somewhat successful, but punched cards were still commonly used for <b>data</b> <b>entry</b> and <b>programming</b> until the mid-1980s when the combination of lower cost magnetic disk storage, and affordable interactive terminals on less expensive minicomputers made punched cards obsolete for this role as well. However, their influence lives on through many standard conventions and file formats.|$|R
40|$|Background: The {{clinical}} and scientific usage of patient-reported outcome measures is increasing {{in the health}} services. Often paper forms are used. Manual double entry of data {{is defined as the}} definitive gold standard for transferring data to an electronic format, but the process is laborious. Automated forms processing may be an alternative, but further validation is warranted. Methods: 200 patients were randomly selected from a cohort of 5777 patients who had previously answered two different questionnaires. The questionnaires were scanned using an automated forms processing technique, as well as processed by single and double manual data entry, using the EpiData Entry <b>data</b> <b>entry</b> <b>program.</b> The main outcome measure was the proportion of correctly entered numbers at question, form and study level. Results: Manual double-key data entry (error proportion per 1000 fields = 0. 046 (95 % CI: 0. 001 – 0. 258)) performed better than single-key data entry (error proportion per 1000 fields = 0. 370 (95 % CI: 0. 160 – 0. 729), (p = 0. 020)). There was no statistical difference between Optical Mark Recognition (error proportion per 1000 fields = 0. 046 (95 % CI: 0. 001 – 0. 258)) and double-key data entry (p = 1. 000). With the Intelligent Character Recognition method, there was no statistical difference compared to single-key data entry (error proportion per 1000 fields = 6. 734 (95 % CI: 0. 817 – 24. 113), (p = 0. 656)), as well as double-key data entry (error proportion per 1000 fields = 3. 367 (95 % CI: 0. 085 – 18. 616)), (p = 0. 319)) ...|$|E
40|$|Parallel {{processing}} {{over the}} Internet is now becoming a realistic possibility. There are numerous of-the-shelf-high-performance computing (HPC) platforms available with Internet access, {{on which to}} implement computationally intensive algorithms. HPC can be applied {{in the field of}} computational electromagnetics, to investigate problems that were so computationally expensive that they were practically "unsolvable. " The networking capabilities of the Internet now allow these computing resources {{to be used as a}} remote service. Additionally, the pragmatics of their utilization can be abstracted by adopting a World Wide Web (WWW) interface. A Web-based environment can provide the supportive tools for <b>data</b> <b>entry,</b> <b>program</b> initiation, result visualization, and even interactive modifications of the geometry and/or the electromagnetic (EM) properties of the problem being examined. For realistic interaction, the emerging question is which algorithm to use that supports the exploitation of parallelism. The rapid porting and evolution of algorithms originally designed for sequential machines to current HPC platforms, is now beginning to reach the limit of performance, as predicted and defined by Amdhl's law. The available HPC-platform performance now vastly exceeds the expectations imposed by these algorithms. In order to exploit and utilize all the available performance of current and predicted HPC platforms, inherently-parallel-based algorithms have to be devised. One such algorithm is the Parallel Method of Moments/Method of Auxiliary Sources, P(MoM/MAS), introduced in this paper. The resulting algorithm parallelization enables the MoM/MAS method to be applied to solving electrically-large-in-size and complex EM structures on various computational platforms. This paper concentrates on the parallel-processing issues, and on the importance of adopting suitable algorithms, such as the MoM/MAS technique. However, the authors would still like to draw the readers' attention to the potential possibilities of using the WWW as the interface environment, not only for connectivity, but also for three-dimensional and even four-dimensional visualizations. These can be presented through a standard WWW browser, independently of the underlying architecture...|$|E
40|$|Background: Bipolar {{disorder}} {{is a relatively}} common disorder and is characterized by "unpredictable swings in mood from mania to depression". Mania is a disease state which induces difficulties in work performance and psychosocial functioning requiring rapid and effective treatment {{in order to allow}} the patients to return to nonnal function. It is a very serious illness characterized by a high rate of recurrence and a deteriorating course. The treatment of acute mania should not only be effective and well tolerated but also anticipate and modify the future course of illness. Lithium, anticonvulsants, antipsychotics and EeT are recognized treatments for acute marna. Although lithium is considered by most as the treatment of choice, the position of anticonvulsants and EeT is currently gaining ground. Objectives: This study is aimed at determining which treatment is most adequate for acute mania. [...] . Each treatment modality will be discussed separately before comparing the three strategies for efficacy, safety and time taken to achieve the goals set. Methods and data analysis: All patients diagnosed with acute mama will be considered for this study. A non-randomized, open-label, comparative study will be conducted in a single center where patients will be assigned into three groups: the ones receiving lithium, the ones on anticonvulsants(carbamazepine or valproate) and fmally patients receiving EeT. Treatments are given depending on the patients' physician. All information concerning patients will be available through their files or medical records. The study data will be entered into a patient information database, using the SPSS <b>Data</b> <b>Entry</b> <b>Program.</b> Significance: Different studies have been conducted lately comparing various treatments of mania. Most of these have come out with contradicting results. So the question remains open as to which strategy should the first line treatment for acute mama. And because mania is such a severe disease with many complications, {{it would be interesting to}} find the answer. 1 bound copy: xvii, 29, [5] l. available at RNL...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedIn this thesis {{the development of}} a controls system analysis package is discussed. It is an interactive computer aid for the design and analysis of linear, single input / single output feedback control systems. The program is user friendly; it uses menus for option selections and prompts for <b>data</b> <b>entry.</b> The <b>program</b> will manipulate the transfer functions of multi-loop systems to produce the open and closed loop transfer functions required for a variety of analysis techniques. The output from any analysis may be either a tabulation of data points or a high resolution plot. [URL] United States Nav...|$|R
40|$|AbstractThis Data in Brief article {{contains}} individual level data of a randomized trial {{in a primary}} care setting. This trial offered mobile reminder to follow up for definitive tests during opportunistic screening of diabetes mellitus in Puducherry, India (2014). (“Effect of mobile reminders on screening yield during opportunistic screening for type 2 diabetes mellitus in a primary health care setting: a randomized trial” (Kumar et al., 2015) [1]) Variables collected included the baseline characteristics of study participants (n= 390) and information on initial screening and eligibility for definitive test, study group (intervention/control), follow up for definitive test and definitive test results. The data was double entered with adequate checks and validated in EpiData. Final data after correcting the <b>data</b> <b>entry</b> errors has been shared here. In addition, we have shared <b>data</b> <b>entry</b> plan, EpiData triplet files for <b>data</b> <b>entry</b> and <b>program</b> file for data analysis. They may be used by other researchers who intend to replicate this research in their setting...|$|R
50|$|The {{front panel}} has a volume knob, a master tuning knob, a <b>data</b> <b>entry</b> knob for <b>programming</b> patches, {{modulation}} and pitch wheels with knobs for {{the depth of}} the effect, and various buttons to switch on and off modulation destinations, enable chord memory, transpose the keyboard, or infinitely sustain notes. The case is black metal with fluorescent displays to indicate the status of different synthesis parameters (see Figure 1), and black rubberized end pieces. Other version, possible earlier may have gloss painted wood ends.|$|R
40|$|Objectives: To {{determine}} whether adults who witnessed intimate partner violence (IPV) as {{children would have}} an increased rate of being victims of ongoing IPV, {{as measured by the}} Ongoing Violence Assessment Tool (OVAT), compared with adult controls who did not witness IPV as children. The authors also sought to {{determine whether}} there were differences in demographics in these two groups. Methods: This was a cross sectional cohort study of patients presenting to a high-volume academic emergency department. Emergency department patients presenting from November 16, 2005, to January 5, 2006, during 46 randomized four-hour shifts were included. A confidential computer touch-screen <b>data</b> <b>entry</b> <b>program</b> was used for collecting demographic data, including witnessing IPV as a child and the OVAT. Main outcome measures were witnessing IPV as a child, ongoing IPV, and associated demographics. Assuming a prevalence of IPV of 20 % and a clinically significant difference of 20 % between adults who witnessed IPV as children and adult controls who did not witness IPV as children, the study was powered at 80 %, with 215 subjects included. Results: A total of 280 subjects were entered; 256 had complete data sets. Forty-nine percent of subjects were male, 45 % were Hispanic, 72 (28 %) were adults who witnessed IPV as children, and 184 (72 %) were adult controls who did not witness IPV as children. Sixty-three (23. 5 %) were positive for ongoing IPV. There was no correlation of adults who witnessed IPV as children with the presence of ongoing IPV, as determined by univariate and bivariate analysis. Twenty-three of 72 (32 %) of the adults who witnessed IPV as children, and 39 of 184 (21 %) of the adult controls who did not witness IPV as children, were positive for IPV (difference, 11 %; 95 % confidence interval [CI] = 2 % to 23 %). Significant correlations with having witnessed IPV as a child included age younger than 40 years (odds ratio [OR], 4. 2; 95 % CI = 1. 7 to 9. 1), income less than $ 20, 000 /year (OR, 5. 1; 95 % CI = 1. 6 to 12. 5), and abuse as a child (OR, 9. 1; 95 % CI = 4. 2 to 19. 6). Other demographics were not significantly correlated with having witnessed IPV as a child. Conclusions: Adults who witnessed IPV as children {{were more likely to have}} a lower income, be younger, and have been abused as a child, but not more likely to be positive for ongoing IPV, when compared with patients who had not witnessed IPV...|$|E
40|$|Background: The {{association}} of perpetrators of intimate partner violence (IPV) with {{drug and alcohol}} use, abuse as a child, age, socioeconomics and race has been established. The relation between IPV perpetrators and being an adult who witnessed IPV as a child (ACW) is not fully established, although in a previous study no association was found between IPV victims and ACWs. Objective: The objective {{of the present study}} was to determine whether perpetrators of IPV could be identified in a busy emergency department (ED) and were more likely than non-perpetrators to be ACWs. The hypothesis {{of the present study was}} that perpetrators differed significantly from non-perpetrators in being ACWs, in being victims of IPV, and in demographics, drug and alcohol use, and history of child abuse. Methods: The design was a cross-sectional cohort of patients presenting to a high volume academic emergency department (ED) during 46 randomized 4 -hour shifts determined via random numbers table 11 / 09 / 06 - 1 / 8 / 07. A choice of confidential computer touch screen <b>data</b> <b>entry</b> <b>program</b> or paper format was offered for collecting data. Data collected included demographics as well as scales to determine whether subjects were a perpetrator, victim, and/or ACW of IPV. Specific scales included a validated scale for perpetrators of IPV (PAPs), a single question for determining witnessing abuse as a child (ACW), and a validated scale, the ongoing violence assessment tool (OVAT) for ongoing victimization of IPV. Two other scales, the AWA and the WOVAT were used to confirm the construct validity of the scales used for perpetrators and ACWs. Predictor variables were ACW, ongoing IPV (OVAT) and demographics. Main Outcome Measures; Statistical analysis: Demographics and prevalence were reported as percentages. Relationships between perpetrators, ACWs, and victims were described using 2 way contingency tables. Predictors of perpetrators were analyzed using multivariable logistic regression. Odds ratios (OR) and 95 % Confidence intervals were reported where indicated. Results: 236 subjects were entered, 207 had complete data sets. Forty-four (19 %) were perpetrators. By univariate analysis there was a significant correlation of perpetrators and ACW (p= 0. 001 by single question) and between perpetrators and being IPV victims (p= 0. 001). There was no significant correlation of perpetrators with race, education, gender, insurance, children in the home, marital status, or abuse as a child. Perpetrators reported they and their spouses were more likely to use alcohol in excess and admitted to spouses’ abuse of drugs, but not their own. By regression analysis significant predictors of perpetrators included ACW (OR 2. 7; 95 % CI 1. 8, 11. 3), and spouse drug abuse (OR 7. 7; 95 % CI 1. 7, 34). Conclusion: Perpetrators were identified in a busy ED setting. Perpetrators were significantly more likely than non perpetrators to be ACWs but not more likely to be IPV victims. Spouse drug abuse and ACW were the 2 significant predictors of perpetrators...|$|E
40|$|This is a {{prospective}} {{study of a}} cohort sample of injured Kuwaiti First Gulf War survivors designed to investigate the prevalence of psychiatric morbidity due to combat and exposures to traumatic events. The study included two main phases. The first phase conducted in 1998, and in 2003 the second phase was executed. This {{study was designed to}} investigate the contribution of combat physical injury to the neurobiology of posttraumatic stress disorder (PTSD), prevalence rates of PTSD, depression, anxiety and other psychological morbidity, and predictors of chronic PTSD. The first assessment was in 1998 and the second assessment in 2003 that involved biological investigations. Beside the clinical interview and the physical examination of the site of injury, multiple psychological scales and questionnaires were used. Based on DSM-IV criteria of PTSD, after the second assessment the population of this study were classified to: Chronic PTSD(have PTSD at both assessments), Delayed PTSD (have PTSD only on the second assessment), Recovered (have PTSD only in the first assessment), and Never PTSD (have no PTSD in both assessments). The biological assessment include: blood investigations, BMI, and visual analogue. The data of the study were analyzed based on the four PTSD subgroups. In the first chapter an introduction to the First Gulf War was presented followed by the second chapter that discussed literature review. The third chapter tackled the methods used in this study. The fourth to the sixth chapters discussed {{the results of this study}} regarding prevalence of Chronic PTSD, Cortisol and PTSD and Thyroid hormones and PTSD respectively. The last chapter presented the limitations and strengths of the study. There were three main hypotheses. First: combat injured survivors with chronic PTSD have cluster of symptoms severity similar to delayed PTSD after 13 years of the trauma and the prevalence of chronic PTSD is constant over time. Second: low cortisol levels observed in chronic PTSD are constant with chronicity, normalize with recovery, unrelated to degree of disability, and are influenced by comorbid disorders. Third: there is minor role for thyroid hormones in chronic PTSD. All of registered Kuwaiti combat injured survivors at the Social Development Office in Kuwait, were approached to voluntary participate in this study. Of 234 individuals 212 participate in the first stage, and out of these 123 participate in the second stage with the addition of 33 new cases that were not examined in 1998 but were registered in SDO after 1998. An informed consent was taken from the participants at both phases. The participants were assessed using General Health Questionnaire, Trauma Questionnaire, Clinician Administered PTSD Scale, Eysenck Personality Questionnaire, Symptom Checklist- 90 Revised, and Life Event Scale. Questionnaires and scales applied in the first stage were applied in the second stage with the addition of Impact of Event Scale, Composite International Diagnostic Interview and Scale of Gulf War Syndrome. Biochemical assessment comprised cortisol level, thyroxine (fT 4), free triiodothyronine (fT 3) and thyroid stimulating hormone (TSH). The blood samples were taken before starting the interview. Physical assessment involved measurements of: pulse rate, systolic and diastolic blood pressure, waist-hip circumference, body mass index and visual analogue before and after the interview. <b>Data</b> <b>entry</b> <b>program</b> using Statistical Package for Social Scientists was used to enter data and analysis. The prevalence rate of delayed onset PTSD (14. 6 %), chronic PTSD (15. 4) recovered from PTSD (22. 8 %) and never had PTSD (47. 2 %). With chronic PTSD there are higher cluster of PTSD symptoms severity, not related to severity of physical injury, has more prevalence of PTSD associated symptoms, higher comorbid psychiatric disorders. Intrusions, avoidance and arousal are PTSD cluster of symptoms more predictive of future development of PTSD after the injury. There was a low baseline cortisol level with chronic PTSD, and it was significantly lower in participants with delayed PTSD. Furthermore trauma itself rather than PTSD diagnosis may have an impact on cortisol level. Other psychiatric comorbidity has an enhancing effect on cortisol level. The levels of thyroid hormones were within the normal range. The trend of thyroid function in delayed and chronic PTSD is lower fT 3, and TSH and higher fT 4 levels, with higher fT 3 levels in delayed PTSD compared to chronic PTSD. It was found that the higher severity of trauma score with PTSD the higher fT 3 mean values. Thesis (Ph. D.) - University of Adelaide, School of Medicine, 200...|$|E
5000|$|At {{the time}} that people began using SLOC as a metric, the most {{commonly}} used languages, such as FORTRAN and assembly language, were line-oriented languages. These languages were developed at the time when punched cards were the main form of <b>data</b> <b>entry</b> for <b>programming.</b> One punched card usually represented one line of code. It was one discrete object that was easily counted. It was the visible output of the programmer so it made sense to managers to count lines of code as a measurement of a programmer's productivity, even referring to such as [...] "card images". Today, {{the most commonly used}} computer languages allow a lot more leeway for formatting. Text lines are no longer limited to 80 or 96 columns, and one line of text no longer necessarily corresponds to one line of code.|$|R
5000|$|The {{front panel}} has two volume knobs (one for each {{available}} sound), a master tuning knob, a <b>data</b> <b>entry</b> knob for <b>programming</b> patches, modulation and pitch wheels, various buttons for mode (layer, or [...] "double", split) and program selection, and a four by eight grid for programming (with all parameters labelled on the grid; see Figure 1). Some other functions are also {{listed on the}} panel {{as a reminder of}} which buttons to press. The case is metal with light blue graphics and lettering, red LED indicators, and black painted wooden end pieces.|$|R
500|$|Billings {{chose the}} Bismarcks last battle {{because he felt}} {{it would be easier}} to develop than other war games. Computer Bismarck was written in BASIC and {{compiled}} to increase its processing speed. In August 1979, Billings provided Lyons with access to a computer to write the program. Lyons began programming a simplified version similar to a fox and hounds game—he had [...] "hounds" [...] search a playing field for a [...] "fox". At the time, the two were working full-time and programmed at Billings' apartment during the night. Lyons did the bulk of the programming, while Billings focused on design and assisted with <b>data</b> <b>entry</b> and minor <b>programming</b> tasks.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedIn this thesis {{the development of}} the Digital and Analog Control System Analysis Program (DACSAP) is discussed. DACSAP is an interactive computer aid for the design and analysis of linear, single input/output feedback control systems. DACSAP is user friendly; it uses menus for option selection and prompted <b>data</b> <b>entry.</b> The <b>program</b> will analyze systems which are described by transfer functions written in the s, z, w, or w' domains. The program will manipulate the transfer functions of multi-loop systems to produce the open and closed loop transfer functions required fir a variety of analysis techniques. The analysis techniques included is DACSAP are root locus, open and closed loop Bode frequency response, Nyquist frequency response, Nichols frequency response and closed loop time response. The output of any of these analysis techniques may be either a tabulation of data points or a high resolution plot. [URL] United States Nav...|$|R
40|$|Bifocal VDT (Visual Display Terminal) {{operators}} (50) {{were studied}} from different fields (<b>data</b> <b>entry,</b> conversational task, <b>programming,</b> CAD/CAM etc.) through user-product-environment system. Users profile includes experiments pertaining to users reactions, while products profile covers designs, manufacturing {{and marketing of}} existing computer furniture in the market. Existing VDT workstations were observed inappropriate for bifocal people facing vision problem, which was analysed thoroughly in simulated laboratory conditions by preparing a test fig with adjustable monitor angle from horizontal. Work posture of VDT operators was assessed with EMG, Photogram Metric Technique, and Centre of Gravity in four stages of test rig. An ergonomics criterion for redesigning VDT workstation was developed. It is appropriate and natural for the man-machine-environment system and also allows comfortable posture and greater efficiency of bifocal and normal VDT operators...|$|R
40|$|The Montana Behavioral Initiative (MBI) was {{developed}} in 1995 in response to increased incidents of student behavior problems. The intent of MBI is to improve educational environments {{to meet the needs}} of all students, including those with behavioral challenges. Each participating school conducts needs assessments and develops site-specific goals and strategies. Support is provided by an annual summer institute for staff development, MBI facilitators and consultants, an MBI council, and a state coordinator. A program evaluation conducted structured interviews and focus groups at five MBI schools at three levels of program adoption: established, emerging, and new. Recommendations include clearly distinguishing the MBI philosophy and process; tailoring future summer-institute content to areas of need identified from experienced sites; developing assessment practices that identify easily-tracked behavioral and academic measures; identifying computerized <b>data</b> <b>entry</b> and analysis <b>programs</b> that support MBI indicator...|$|R
40|$|The aims of this {{research}} is to evaluate and measured the finance performance used an Economic Value Added (EVA) method and market based finance performance which use a market ratio indicators, such as Annual Stock Return (ASR), Earning Per Share (EPS), Devidend Per Share (DPS), and Devidend Yield. Hypothesis testing done by Economic Value Added (EVA), market ratio, and SPSS. SPSS used to examined how significant the correlation between Economic Value Added (EVA) with the market based finanace performance, the result of Economic Value Added and market based financial performance used for <b>data</b> <b>entry</b> on SPSS <b>program.</b> The result of {{this research}} is Economic Value Added (EVA) does not have a correlation with the market based finance performance because all of the variabel indicators that used in this research having a weak correlation with Economic Value Added (EVA...|$|R
40|$|OVERVIEW: The Veterans Administration (VA) Computerized Patient Record System (CPRS) is {{a nationally}} {{deployed}} software product that integrates provider order entry, progress notes, vitals, consults, discharge summaries, problem lists, medications, labs, radiology, transcribed documents, study reports, and clinical reminders. Users rapidly adopted the {{graphical user interface}} for data retrieval, but demanded options to typing for <b>data</b> <b>entry.</b> We <b>programmed</b> "point and click" forms that integrate with CPRS individually, but were soon overwhelmed by requests. Subsequently, we developed the Progress Note Construction Set (PNCS); a tool suite that permits subject matter experts without programming skills to create reusable "point and click" forms. In this study, we evaluate the usability of these user-constructed forms. METHODS: An untrained, non-VA subject matter expert used the PNCS to create a graphical form for "skin tear" documentation. Ten VA nurses used the skin tear form to document findings for 7 standardized clinical scenarios. Following each scenario the subjects answered usability questions about the form. RESULTS: The subject matter expert created the skin tear form in 78 minutes. Users found the form to facilitate their <b>data</b> <b>entry</b> (p 0. 0265), and {{to be at least}} as fast (p 0. 0029) and as easy to use as expected (p 0. 0166). Average note entry time was 3. 4 minutes. CONCLUSION: The PNCS allowed a non-programmer to quickly create a usable, CPRS-integrated point and click form. Users found the subject matter expert s form fast and easy to use. The tool suite is a more scaleable form creation method because capacity is no longer limited by programmer availability...|$|R
50|$|Keypunches {{and punched}} cards were still {{commonly}} used for both <b>data</b> and <b>program</b> <b>entry</b> through the 1970s but were rapidly made obsolete {{by changes in}} the entry paradigm and by the availability of inexpensive CRT computer terminals. Eliminating the step of transferring punched cards to tape or disk (with {{the added benefit of}} saving the cost of the cards themselves) allowed for improved checking and correction during the entry process. The development of video display terminals, interactive timeshared systems and, later, personal computers allowed those who originated the data or program to enter it directly instead of writing it on forms to be entered by keypunch operators.|$|R
