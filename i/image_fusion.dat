2122|573|Public
25|$|In some centers, {{the nuclear}} {{medicine}} scans can be superimposed, using software or hybrid cameras, on images from modalities such as CT or MRI {{to highlight the}} part of the body in which the radiopharmaceutical is concentrated. This practice {{is often referred to as}} <b>image</b> <b>fusion</b> or co-registration, for example SPECT/CT and PET/CT. The fusion imaging technique in nuclear medicine provides information about the anatomy and function, which would otherwise be unavailable or would require a more invasive procedure or surgery.|$|E
2500|$|One {{of the key}} {{principles}} of dictionary learning is that the dictionary has to be inferred from the input data. The emergence of sparse dictionary learning methods was stimulated {{by the fact that}} in signal processing one typically wants to represent the input data using as few components as possible. Before this approach the general practice was to use predefined dictionaries (such as fourier or wavelet transforms). However, in certain cases a dictionary that is trained to fit the input data can significantly improve the sparsity, which has applications in data decomposition, compression and analysis and has been used in the fields of image denoising and classification, video and audio processing. Sparsity and overcomplete dictionaries have immense applications in image compression, <b>image</b> <b>fusion</b> and inpainting.|$|E
5000|$|The images used in <b>image</b> <b>fusion</b> should {{already be}} registered. Misregistration {{is a major}} source of error in <b>image</b> <b>fusion.</b> Some {{well-known}} <b>image</b> <b>fusion</b> methods are: ...|$|E
40|$|We {{propose a}} novel super-resolution multisource <b>images</b> <b>fusion</b> scheme via {{compressive}} sensing and dictionary learning theory. Under the sparsity prior of images patches and {{the framework of}} the compressive sensing theory, the multisource <b>images</b> <b>fusion</b> is reduced to a signal recovery problem from the compressive measurements. Then, a set of multiscale dictionaries are learned from several groups of high-resolution sample image’s patches via a nonlinear optimization algorithm. Moreover, a new linear weights fusion rule is proposed to obtain the high-resolution image. Some experiments are taken to investigate the performance of our proposed method, and the results prove its superiority to its counterparts...|$|R
40|$|This paper {{presents}} {{an overview of}} a satellite <b>images</b> <b>fusion</b> system for mapping applications. The main goal of this system is to dilate the map’s feature extraction bottleneck by semi-automating this process. This study deals with the linear planimetric features (LPF) extraction for the 1 : 50 000 topographical map creation. These features include roads, railroads, energy transmission lines and some types of rivers. Actually, the only data source used for their extraction is aerial black and white photographs. The objective here is to fusion multi-sources and multi-types information. This information ranges from satellite images (visible and radar) to domain based models and of expert’s modeled knowledge, strategies and rules. The whole system includes an operator who will give inputs and validates the results along the whole task. Key Words: remote-sensing, satellite <b>images</b> <b>fusion,</b> semi-automatic mapping systems, expert system...|$|R
40|$|Abstract: CFNN {{hybrid system}} in Multi-sensor data fusion {{introduced}} fuzzy logic reasoning and neural network adaptive, self-learning ability, and using fuzzy neurons, so networking skills appropriate {{to adjust the}} input and output fuzzy membership function, and can dynamically optimize fuzzy reasoning in global by means of compensated logic algorithm, to make the network more fault tolerance, stability and speed up training. This paper introduces a mathematical model of the <b>image</b> data <b>fusion,</b> and elaborates CFNN <b>image</b> data <b>fusion</b> algorithms, simulation results show that this method can significantly {{improve the quality of}} the <b>image</b> data <b>fusion,</b> data fusion with other existing algorithms have a very significant effect...|$|R
50|$|Comparative {{analysis}} of <b>image</b> <b>fusion</b> methods demonstrates that different metrics support different user needs, sensitive to different <b>image</b> <b>fusion</b> methods, {{and need to}} be tailored to the application. Categories of <b>image</b> <b>fusion</b> metrics are based on information theory, features, structural similarity, or human perception.|$|E
5000|$|The {{standard}} merging {{methods of}} <b>image</b> <b>fusion</b> {{are based on}} Red-Green-Blue (RGB) to Intensity-Hue-Saturation (IHS) transformation. The usual steps involved in satellite <b>image</b> <b>fusion</b> are as follows: ...|$|E
5000|$|<b>Image</b> <b>fusion</b> {{in remote}} sensing has several {{application}} domains. An important domain is the multi-resolution <b>image</b> <b>fusion</b> (commonly referred to pan-sharpening). In satellite imagery {{we can have}} two types of images ...|$|E
30|$|The surgeon can {{identify}} the narrowest face of the root if they view the MR/CT <b>fusion</b> <b>image</b> from the posterolateral-inferior direction. Surgeons use MR/CT <b>fusion</b> <b>images</b> as a pre-operative map and for intraoperative navigation. The MR/CT <b>fusion</b> <b>images</b> {{can also be used}} as educational materials for all hospital staff and for patients and patients’ families who provide informed consent for treatments.|$|R
40|$|BACKGROUND AND PURPOSE: The distal dural ring (DDR) {{represents}} the anatomic {{border between the}} extradural and intradural internal carotid arteries (ICAs). The {{purpose of this study}} was to examine whether 3 D-MR cisternography and MR angiography (MRA) <b>fusion</b> <b>images</b> can identify the boundary between the CSF and the cavernous sinus, which might represent the DDR. MATERIALS AND METHODS: Thirty-six consecutive patients with 39 ICA aneurysms were examined with use of MR <b>fusion</b> <b>images</b> with 3 D-cisternography and MRA on a 1. 5 T unit. Two neuroradiologists evaluated the configuration of the carotid cave and the location of the aneurysms on <b>fusion</b> <b>images</b> and classified them as intradural, transdural, and extradural aneurysms. RESULTS: The borderline between the CSF and the cavernous sinus was visualized on <b>fusion</b> <b>images</b> in all patients. The carotid cave configuration in 72 ICAs was classified as having no dent (n 31), a shallow dent (n 27), and a deep dent (n 14). The MR <b>fusion</b> <b>images</b> led to the classification of 39 ICA aneurysms as 21 intradural, 6 transdural, and 12 extradural. The interobserver agreement of MR <b>fusion</b> <b>images</b> was excellent (0. 80). CONCLUSIONS: <b>Fusion</b> <b>images</b> with 3 D-cisternography and MRA yielded clear visualization of the boundary between the suprasellar cistern and cavernous sinus indicating the DDR. This imagin...|$|R
5000|$|... #Caption: Conidial {{anastomosis}} tubes {{as found}} in C. lindemuthianum. <b>Image</b> (f): <b>fusion</b> point, (b) birth scar, (c) conidia, (a) CATs ...|$|R
50|$|In {{remote sensing}} applications,the {{increasing}} availability of space borne sensors gives a motivation for different <b>image</b> <b>fusion</b> algorithms.Several situations in image processing require high spatial and high spectral resolution {{in a single}} image. Most of the available equipment is not capable of providing such data convincingly. <b>Image</b> <b>fusion</b> techniques allow the integration of different information sources. The fused image can have complementary spatial and spectral resolution characteristics. However, the standard <b>image</b> <b>fusion</b> techniques can distort the spectral information of the multispectral data while merging.|$|E
5000|$|... #Caption: Manual <b>image</b> <b>fusion</b> of x-rayed and {{rectilinear}} scanned chest ...|$|E
50|$|<b>Image</b> <b>fusion</b> {{methods can}} be broadly {{classified}} {{into two groups}} - spatial domain fusion and transform domain fusion.|$|E
30|$|On the {{two-dimensional}} images {{created from}} the 3 D MR/CT <b>fusion</b> <b>image,</b> the flattened {{portion of the}} root appeared wide from some directions and narrow from other directions. During posterior decompression surgery performed under microscopy, the surgeon might meet the wide face of the affected root, but not the narrow face. The surgeon can identify the narrowest face of the root if they view the MR/CT <b>fusion</b> <b>image</b> from the posterolateral-inferior direction. Surgeons use MR/CT <b>fusion</b> <b>images</b> as a pre-operative map and for intraoperative navigation. The MR/CT <b>fusion</b> <b>images</b> {{can also be used}} as educational materials for all hospital staff and for patients and patients’ families who provide informed consent for treatments.|$|R
40|$|Abstract: There is {{significant}} difference in the imaging features of infrared image and color <b>image,</b> but their <b>fusion</b> <b>images</b> also have very good complementary information. In this paper, based on the characteristics of infrared image and color image, first of all, wavelet transform is applied to the luminance component of the infrared image and color image. In multi resolution the relevant regional variance is regarded as the activity measure, relevant regional variance ratio as the matching measure, and the <b>fusion</b> <b>image</b> is enhanced in the process of integration, thus getting the fused images by final synthesis module and multi-resolution inverse transform. The experimental results show that the <b>fusion</b> <b>image</b> obtained by the method proposed in this paper is better than the other methods in keeping the useful information of the original infrared image and the color information of the original color image. In addition, the <b>fusion</b> <b>image</b> has stronger adaptability and better visual effect. Copyright © 2014 IFSA Publishing, S. L...|$|R
40|$|There is {{significant}} difference in the imaging features of infrared image and color <b>image,</b> but their <b>fusion</b> <b>images</b> also have very good complementary information. In this paper, based on the characteristics of infrared image and color image, first of all, wavelet transform is applied to the luminance component of the infrared image and color image. In multi resolution the relevant regional variance is regarded as the activity measure, relevant regional variance ratio as the matching measure, and the <b>fusion</b> <b>image</b> is enhanced in the process of integration, thus getting the fused images by final synthesis module and multi-resolution inverse transform. The experimental results show that the <b>fusion</b> <b>image</b> obtained by the method proposed in this paper is better than the other methods in keeping the useful information of the original infrared image and the color information of the original color image. In addition, the <b>fusion</b> <b>image</b> has stronger adaptability and better visual effect...|$|R
50|$|Many methods {{exist to}} perform <b>image</b> <b>fusion.</b> The very basic {{one is the}} high pass {{filtering}} technique. Later techniques are based on Discrete Wavelet Transform, uniform rational filter bank, and Laplacian pyramid.|$|E
50|$|In {{computer}} vision, Multisensor <b>Image</b> <b>fusion</b> is {{the process}} of combining relevant information from two or more images into a single image. The resulting image will be more informative than any of the input images.|$|E
50|$|The SPOT PAN {{satellite}} provides {{high resolution}} (10m pixel) panchromatic data. While the LANDSAT TM satellite provides low resolution (30m pixel) multispectral images. <b>Image</b> <b>fusion</b> attempts to merge these images {{and produce a}} single high resolution multispectral image.|$|E
40|$|We {{propose a}} wavelet-domain Hidden Markov Tree (HMT) model-based multi-spectral and {{panchromatic}} <b>images</b> <b>fusion</b> algorithm in this study. Our algorithm exploits the wavelet-domain HMT model learnt from the high-resolution panchromatic image to perform super-resolution operation to the low-resolution multispectral image. In this way, the desired high-resolution multispectral image is obtained. The experimental {{results showed that}} the proposed algorithm can produce sharper images as well as retaining good color. Moreover, {{as a result of the}} insensitivity of the wavelet coefficients statistical information to the noises, our algorithm exhibits stronger robustness to the noises...|$|R
40|$|Abstract: In this paper, a new {{adaptive}} <b>images</b> <b>fusion</b> {{algorithm is}} presented for CT and MRI based on DT-CWT. For fusion, all the source images are decomposed into {{low and high}} frequency sub-bands, and then the fusion of low frequency is done by means of Principal Component Analysis (PCA) while for high frequency regional energy algorithm is used. Experiment are carried out {{on a number of}} CT and MRT images, results show that the DT-CWT method is better than that of DWT method in terms of quality measures PSNR, NCC and image visual quality. 1...|$|R
40|$|This {{contribution}} {{refers to}} the fusion of 2 D multi-spectral images. Short review of the currently used methods is given and an algorithm using the wavelet representation of vectorvalued is discussed. The pyramidal dyadic wavelet transform is modified according {{to the definition of}} maximal length of the multi-valued gradient and a solution of problems with orientation of the computed orthogonalized gradient is given. Several applications of the method including multimodal ophtalmic <b>images</b> <b>fusion</b> and multi-focused color photographs creation are presented and the suitability of the fusion for subsequent processing is discussed. ...|$|R
50|$|Outside of academia, Brady {{has been}} {{involved}} with numerous start-up companies in the field of medical imaging including Matakina and ScreenPoint (mammographic image analysis), Mirada Medical (medical <b>image</b> <b>fusion)</b> and Perspectum Diagnostics (magnetic resonance imaging of the liver).|$|E
50|$|Image processing: Hariharan et al. 2006 applied EMD to <b>image</b> <b>fusion</b> and enhancement. Chang et al. 2009 applied an {{improved}} EMD to iris recognition, which reported a 100% faster in computational speed without losing accuracy {{than the original}} EMD.|$|E
5000|$|Raster {{and remote}} sensing: statistics, filters, histogram, scale range, enhance, save to raster file, vectorization, Region of Interest (ROI) definition, general components, georeferencing, geolocation, {{supervised}} classification, band algebra, image profiles, decision tree, main components, tasseled cap, <b>image</b> <b>fusion,</b> scatter diagram, mosaics.|$|E
40|$|The aim of {{this paper}} is to {{evaluate}} two different <b>images</b> <b>fusion</b> methods - IHS (cylindrical and hexacon) and PANSHARPENING - applied to CBERS 2 B images. In order to accomplish this task, CBERS 2 B (CCD and HRC) satellite images were used, with 20 m and 2. 5 m of spatial resolution, respectively. A QUICKBIRD satellite <b>image</b> in <b>fusion</b> mode with spatial resolution of 0. 60 m was also used for orthorectifying the CBERS 2 B images, due the unavailability of control points in the field. Based on the GCP in the QUICKBIRD image and a DEM generated from contour lines, it was possible to execute the images orthorectification, which is an important prerequisite to the good quality of the fusion process. Qualitative (visual appraisal) as well as quantitative (statistical index) methods were employed to evaluate the fused images quality. The results show a good quality of the CBERS 2 B fused images, which may foster new applications possibilities in remote sensing. Pages: 6951 - 695...|$|R
30|$|In our work, CT to PET and MRI to PET <b>image</b> <b>fusions</b> were {{provided}} by a co-registration process in which small alignment errors may occur. Therefore, manual adjustment and qualitative judgment by expert clinicians were often required. This could possibly decrease the efficiency of a study design in terms of timing; however, the misalignment problem can be solved by hybrid imaging techniques. For instance, recently developed MRI-PET scanners are starting {{to be used in}} small-animal models [24], where no co-registration process is required since MR and PET images are obtained simultaneously with this new hybrid imaging technology.|$|R
40|$|This paper {{deals with}} fuzzy {{statistical}} image segmentation. We {{introduce a new}} hierarchical Markovian fuzzy hidden field model, which extends to the fuzzy case the classical Prez and Heitz hard model. Two fuzzy statistical segmentation methods related with the model proposed are defined in this paper and we show via simulations that they are competitive with, in some cases than, the classical Maximum Posterior Mode (MPM) based methods. Furthermore, they are faster, which will should facilitate extensions to more than two hard classes in future work. In addition, the model proposed is applicable to the multiscale segmentation and multiresolution <b>images</b> <b>fusion</b> problems...|$|R
5000|$|The {{images for}} {{polarized}} glasses {{have to share}} the screen simultaneously in which full, native resolution is downgraded, compromising picture quality of {{both sides of the}} image delivered to each eye simultaneously. A full 1080p picture results from <b>image</b> <b>fusion.</b> This disadvantage does not occur on projections where each pixel can contain information for both eyes.|$|E
50|$|Mutual {{information}} {{is also used}} {{in the area of}} signal processing as a measure of similarity between two signals. For example, FMI metric is an <b>image</b> <b>fusion</b> performance measure that makes use of mutual information in order to measure the amount of information that the fused image contains about the source images. The Matlab code for this metric can be found at.|$|E
50|$|In some centers, {{the nuclear}} {{medicine}} scans can be superimposed, using software or hybrid cameras, on images from modalities such as CT or MRI {{to highlight the}} part of the body in which the radiopharmaceutical is concentrated. This practice {{is often referred to as}} <b>image</b> <b>fusion</b> or co-registration, for example SPECT/CT and PET/CT. The fusion imaging technique in nuclear medicine provides information about the anatomy and function, which would otherwise be unavailable or would require a more invasive procedure or surgery.|$|E
40|$|Precise {{localization}} of the foci of 131 I uptake {{for management}} {{of patients with}} differentiated thyroid carcinoma can be difficult {{because of a lack}} of anatomic landmarks. The objective of the present study was to demonstrate the clinical usefulness of 131 I SPECT/CT <b>fusion</b> <b>images</b> in patients with differentiated thyroid carcinoma. Methods: CT and SPECT were performed 7 d after administration of a therapeutic dose of 131 I to 17 patients with differentiated thyroid carcinoma. External markers were placed at 3 locations on the skin of the patient to adjust the sections of CT and SPECT in the same geometric plane. <b>Fusion</b> <b>images</b> were constructed by combining the digital CT and SPECT im-ages on a computer workstation. The data from both planar and SPECT 131 I images and CT images were first separately as-sessed by 2 nuclear medicine physicians. 131 I SPECT/CT <b>fusion</b> <b>images</b> were then interpreted. <b>Fusion</b> <b>images</b> were considere...|$|R
40|$|The {{defection}} {{of single}} data source {{can be solved}} with fusion between TM and SAR images. It provides a better solution for land surface monitoring in the mining areas. Results of experiment showed that the <b>fusion</b> <b>images</b> can be integrated the advantages of each one, enhanced the recognition ability of features, improved land use/land cover classification accuracy. Further discussed the method of microwave remote sensing for ecological environment monitoring in mining areas, it is {{pointed out that the}} SAR images can be quantitative analysis of hydrogeological environment, the growth of crops and vegetation, land cover and soil resources, the INSAR images can be extracted collapse and change information. Research shows that the use of multi-source and multi-temporal <b>images,</b> <b>fusion</b> technology of TM and SAR images, could be favorable of dynamic monitoring for the ecological environment in mining areas, and provided basic data for exploitation of mining resources. *Corresponding author...|$|R
40|$|Abstract — In this work, an {{algorithm}} for {{the detection}} of the left ventricular border in two-dimensional long axis echocardiographic images is presented. In its preprocessing stage, <b>images</b> <b>fusion</b> was applied to a sequence of images composed of three cardiac cycles. This method exploits the similarity of corresponding frames from different cycles and produces contrast enhancement in the left ventricular boundary. This result improves the performance of the segmentation stage which is based on watershed transformation. The obtained left ventricle border is quantitatively and qualitatively compared with contours manually segmented by a cardiologist, and with results obtained using seven different techniques from the literature. I...|$|R
