10|26|Public
5|$|Following the Smithsonian Agreement, {{member states}} of the European Economic Community adopted a {{narrower}} currency band of 1.125% for exchange rates among their own currencies, creating a smaller scale fixed exchange rate system known as the snake in the tunnel. The snake proved unsustainable as it did not compel EEC countries to coordinate macroeconomic policies. In 1979, the European Monetary System (EMS) phased out the currency snake. The EMS featured two key components: the European Currency Unit (ECU), an artificial weighted average market basket of European Union members' currencies, and the Exchange Rate Mechanism (ERM), a procedure for managing exchange rate fluctuations in keeping with a calculated parity grid of currencies' par values. The parity grid was derived from parities each participating country established for its currency with all other currencies in the system, denominated in terms of ECUs. The weights within the ECU changed in response to variances in the values of each currency in its basket. Under the ERM, if an exchange rate reached its upper or lower limit (within a 2.25% band), both nations in that currency pair were obligated to intervene collectively in the foreign exchange market and buy or sell the under- or overvalued currency as necessary to return the exchange rate to its par value according to the parity matrix. The requirement of cooperative market intervention marked a key difference from the Bretton Woods system. Similarly to Bretton Woods however, EMS members could impose capital controls and other monetary policy shifts on countries responsible for exchange rates approaching their bounds, as identified by a <b>divergence</b> <b>indicator</b> which measured deviations from the ECU's value. The central exchange rates of the parity grid could be adjusted in exceptional circumstances, and were modified every eight months on average during the systems' initial four years of operation. During its twenty-year lifespan, these central rates were adjusted over 50 times.|$|E
40|$|Fixed or semi-fixed {{exchange}} rate regimes have volatility paths {{that are in}} general less smooth than their free floating counterpart. Moreover, there {{tends to be a}} correlation between the lack of smoothness and the weakness of the currency. In this article, the effects of divergence from central parity on the smoothness of the volatility are discussed within the framework of a TGARCH model. It is shown that, for various EMS rates, the <b>divergence</b> <b>indicator</b> has a statistically significant effect on the smoothness of the volatility path. status: publishe...|$|E
40|$|We {{investigate}} a general class of divergence measures among distributions for model selection. As alternative to theclassical test of model choice, we introduce kernel type estimators of α-divergence for continuous distributionsbased on model selection criteria in general non parametric case. We introduce the <b>Divergence</b> <b>Indicator</b> DI method by proposing {{a test for}} choosing between a random walk and aregression one, using a unified divergence measure. Under the assumptions of standard type about model densities, theasymptotic properties estimator of the expected divergence between the true unknown model and the candidate modelare established. From {{the point of the}} resulting statistics divergence estimator, the performance of the discrepancycriteria is discussed and illustrated in various settings in model selection test...|$|E
40|$|This paper {{considers}} how {{a regional}} currency basket {{and the associated}} <b>divergence</b> <b>indicators</b> {{could be used in}} official surveillance. Recently, proponents of Asian currency baskets have referred to the role the ECU played in constructing exchange rate <b>divergence</b> <b>indicators</b> in Europe as evidence of the intrinsic usefulness of currency baskets for exchange rate monitoring. We show in this paper a number of problems with the use of regional currency-basket based <b>divergence</b> <b>indicators.</b> First, at a technical level, such indicators involve tracking regional exchange rates against a moving currency basket and can obscure underlying movements in bilateral exchange rates. Second, currency baskets generally treat currencies asymmetrically leading to difficulties interpreting the derived measures of divergence. Third, intra-regional exchange rate monitoring can lead to potentially serious N- 1 or anchor problems. Some of thes...|$|R
40|$|This paper {{considers}} {{whether an}} intra-regional currency basket {{and the associated}} <b>divergence</b> <b>indicators</b> could play a useful role in official exchange rate surveillance. Recently, proponents of an Asian currency basket have referred to the role the European Currency Unit played in constructing exchange rate <b>divergence</b> <b>indicators</b> {{as evidence of the}} usefulness of intra-regional currency baskets for exchange rate monitoring. The paper shows that such indicators have a number of features that can lead to them obscuring underlying changes in exchange rates and that the signals they emit will often be difficult to interpret. In addition, the use of regional currency baskets for surveillance can lead to potentially serious N- 1 problems in circumstances when there is not agreement about which regional currencies will be the anchor currencies. An intra regional currency basket and the associated <b>divergence</b> <b>indicators</b> will be a rudderless beacon for surveillance unless there is agreement about anchors...|$|R
40|$|The {{system of}} {{so-called}} <b>Divergence</b> <b>Indicators</b> in the European Monetary System {{puts pressure on}} the monetary authorities to consult before the intervention points are reached in the foreign exchange markets. Under integration aspects this arrangement marks an advance, but it also carries risks and dangers with it...|$|R
40|$|This paper {{estimates}} {{the value of}} the RCU as a weighted average of East Asian currencies following the method used to calculate the ECU. The weight of component currencies is determined on the basis of each country's economic importance and contribution to regional cooperation such as the nominal GDP, GDP measured at purchasing power parity (PPP), intra-regional trade, and bilateral swap arrangement under the CMI. Two features are noteworthy. One is that the RCU value based on nominal GDP varies the most and the value based on PPP-GDP fluctuates the least. The other feature is that the trends of the RCU look very different according to the choice of the benchmark year. The RCU thus calculated {{can be used as a}} <b>divergence</b> <b>indicator</b> to monitor the exchange rate movement of East Asian currencies. This paper explores diverse ways to extend the use of RCU and to foster monetary integration in East Asia as well...|$|E
40|$|In {{this work}} we are proposing a trading system where fuzzy logic is applied {{not only for}} {{defining}} the trading rules, but also for managing the capital to invest. In fact, two fuzzy decision support systems are developed. The first one uses fuzzy logic to design the trading rules and to apply the stock market technical indicators. The second one enhances this fuzzy trading system adding a fuzzy strategy to manage the capital to trade. Additionally, a new technical market indicator that produces short and long entry signals is introduced. It {{is based on the}} MACD (Moving Average Convergence <b>Divergence)</b> <b>indicator.</b> Its parameters have been optimized by genetic algorithms. The proposals are compared to a classical non-fuzzy version of the pro-posed trading systems and to the Buy-and-Hold strategy. Results favor our fuzzy trading system in the two markets considered, NASDAQ 100 and EUROSTOXX. Conclusions suggest that the use of fuzzy logic for capital management is promising and deserves further exploratio...|$|E
40|$|This paper {{studies the}} semi-analytic {{solution}} (SAS) {{of a power}} system's differential-algebraic equation. A SAS is a closed-form function of symbolic variables including time, the initial state and the parameters on system operating conditions, and hence able to directly give trajectories on system state variables, which are accurate {{for at least a}} certain time window. A two-stage SAS-based approach for fast transient stability simulation is proposed, which offline derives the SAS by the Adomian Decomposition Method and online evaluates the SAS for each of sequential time windows until making up a desired simulation period. When applied to fault simulation, the new approach employs numerical integration only for the fault-on period to determine the post-disturbance initial state of the SAS. The paper further analyzes the maximum length of a time window for a SAS to keep its accuracy, and accordingly, introduces a <b>divergence</b> <b>indicator</b> for adaptive time windows. The proposed SAS-based new approach is validated on the IEEE 10 -machine, 39 -bus system. Comment: An extension of this work has been published as:Nan Duan, Kai Sun, "Power System Simulation Using the Multi-stage Adomian Decomposition Method, IEEE Transactions on Power Systems," vol. 32, no. 1, pp. 430 - 441, January 201...|$|E
50|$|The <b>divergence</b> of the <b>{{indicator}}</b> and the Laplacian of {{the indicator}} (or of the characteristic function, as the indicator is also known) {{have been used}} as the sample information from which surfaces can be reconstructed.|$|R
40|$|Proxy {{indicators}} of sea surface temperature and equatorial divergence based on radiolarian assemblage data, and of trade wind intensity based on eolian grain size data show similar aspects of variability {{during the late}} Pleistocene: All indicators fluctuate at higher frequencies than the 100, 000 -year glacial-interglacial cycle, display reduced amplitude variations since 300, 000 years ago, exhibit {{a change in the}} record character at about 300, 000 years ago (the mid-Brunhes climatic event), and have higher amplitude variations in sediments 300, 000 - 850, 000 years old. Time series analyses were conducted to determine the spectral character of each record (delta 18 O of planktonic foraminifer, sea surface temperature values, equatorial <b>divergence</b> <b>indicators,</b> and wind intensity indicators) and to quantify interrecord coherence and phase relationships. The record was divided at the 300, 000 -year clear change in climatic variability (nonstationarity). The delta 18 O-based time scale is better lower in the core so our spectral analyses concentrated on the interval from 402, 000 - 774, 000 years. The delta 18 O spectra show 100, 000 - and 41, 000 -year power in the younger portion, 0 - 300, 000 years, and 100, 000 -, 41, 000 - and 23, 000 -year power in the older interval, all highly coherent and in phase with the SPECMAP average stacked isotope record. Unlike the isotope record the dominant period in both the eolian grain size and equatorial <b>divergence</b> <b>indicators</b> is 31, 000 years. This period is also important in the sea surface temperature signal where the dominant spectral peak is 100, 000 years. The 31, 000 -year spectral component is coherent and in phase between the eolian and divergence records, confirming the link between atmospheric and ocean surface circulation {{for the first time in}} the paleoclimate record. Since the 31, 000 -year power appears in independent data sets within this core and also appears in other equatorial records [J. Imbrie personal communication, 1987], we assume it to be real and representative of both a nonlinear response to orbital forcing, possibly a combination of orbital tilt and eccentricity, and some resonance phenomenon required to amplify the response at this period so that it appears as a dominant frequency component. The mid-Brunhes climatic event is an important aspect of these records, but its cause remains unknown...|$|R
40|$|In {{smoothed}} particle hydrodynamics (SPH), artificial viscosity {{is necessary}} for the correct treatment of shocks, but often generates unwanted dissipation away from shocks. We present a novel method of controlling the amount of artificial viscosity, which uses the total time derivative of the velocity <b>divergence</b> as shock <b>indicator</b> and aims at completely eliminating viscosity away from shocks. We subject the new scheme to numerous tests and find that the method works at least as well as any previous technique in the strong-shock regime, but becomes virtually inviscid away from shocks, while still maintaining particle order. In particular sound waves or oscillations of gas spheres are hardly damped over many periods. Peer-reviewedPublisher Version 4413...|$|R
40|$|This paper {{examines}} different {{properties of}} the regional currency unit (RCU) in Asia and estimates {{the value of the}} RCU as a weighted average of East Asian currencies according to the method used to calculate the ECU under the EMS. The basket feature of the RCU yields benefits and costs. First, the use of the RCU central rate can make the intervention burden of a central bank less onerous than the use of a bilateral exchange rate. Also, for any given band of margins, a basket unit offers more flexibility than a bilateral exchange rate. Another advantage of using the RCU is that the variance of RCU exchange rates is smaller than the variance of exchange rates of component countries. However, the usefulness of the RCU as a unit of account for domestic transactions and contracts will be very limited because of information costs and uncertainty about the value of the RCU. Also, theintroduction of the RCU raises the important problem of asymmetry for foreign exchange market intervention. Once such a problem is solved, the RCU can be then used as a <b>divergence</b> <b>indicator</b> to monitor the exchange rates of Asian currencies between themselves and against the US dollar or the euro. The creation of the RCU {{is a good way to}} coordinate policies and assure exchange stability between Asian countries. Regional Currency Unit, ECU, parallel currency, Asian monetary integration...|$|E
40|$|In {{this paper}} we report the European {{experience}} with a basket currency, the ECU. The ECU was initially introduced as a reference unit and later became the anchor of the European Monetary System. Public policy was complemented by private sector initiatives {{and use of the}} ECU for denomination of financial instruments. In practice, it turned out that a basket currency entails considerable unexpected technical complexities. The technical particularities of a basket currency are discussed before we turn to the criteria for determining the shares of participating currencies. We show that there are no iron-clad economic principles and therefore there is some room for political considerations. In Europe three criteria were used for determining the weights: GDP shares, international trade shares, and financial market indicators. In addition, weights will change with exchange rate movements. Appreciating currencies will experience increasing weights and depreciating currencies decreasing weights. This may require a correction mechanism for political acceptability. In Europe, weights were rescaled by political authorities every five years. From an economic viewpoint, weights depend critically on the purpose of the basket currency: is it a reference indicator, is it a currency for international transactions, or is it a parallel currency? Thus, before weights are to be discussed a clear vision {{of the role of the}} basket currency would be desirable. The vastly different growth performance among Asian economies also suggests a preference to forward rather than backward-looking measures. Turning then to the different functions of a basket currency, we examine the use of basket currencies as a <b>divergence</b> <b>indicator,</b> or as a financial instrument in regional fina...|$|E
40|$|This paper {{reports the}} European {{experience}} with a basket currency, the ECU. The ECU was initially introduced as a reference unit and later became the anchor of the European Monetary System. Public policy was complemented by private sector initiatives {{and use of the}} ECU for denomination of financial instruments. In practice, it turned out that a basket currency entails considerable unexpected technical complexities. There are no iron-clad economic principles and therefore there is some room for political considerations. In Europe three criteria were used for determining the weights: GDP shares, international trade shares, and financial market indicators. In addition, weights will change with exchange rate movements. Appreciating currencies will experience increasing weights and depreciating currencies decreasing weights. This may require a correction mechanism for political acceptability. In Europe, weights were rescaled by political authorities every five years. From an economic view point, weights depend critically on the purpose of the basket currency: is it a reference indicator, is it a currency for international transactions, or is it a parallel currency? Thus, before weights are to be discussed a clear vision {{of the role of the}} basket currency would be desirable. The vastly different growth performance among Asian economies also suggests a preference to forward rather than backward-looking measure. Turning then to the different functions of a basket currency, the use of basket currencies as a <b>divergence</b> <b>indicator,</b> or as a financial instrument in regional financial markets before elaborating a road map for the development of a basket currency in Asia is examined. [DP 116]Currency; Fixed Currency Unit; Monetary Unit; Basket Currency; Fixed Exchange Rate; Asian Currency Unit; European Currency Unit; Parallel Currency; Hard Currency Unit; Divergence Indicator; Short Maturities; Long Maturities; Cost-Benefit Analysis; Zero-Sum Game...|$|E
40|$|Prior to Mexico’s {{entry to}} NAFTA {{predictions}} of the consequent {{impact on the environment}} in that country ranged from the dire to the very optimistic. This paper investigates NAFTA’s outcomes in terms of energy use and the emission of atmospheric pollutants. Specifically, has entry into NAFTA led to a convergence or <b>divergence</b> in <b>indicators</b> of emissions, environmental efficiency, and emissions specific technology in Mexico, the United States, and Canada? Four emissions variables are considered: energy, carbon, sulfur, and NOx. Three different indicators of emissions and environmental efficiency are computed and tested for both convergence and the presence of a structural break associated with the introduction of NAFTA: energy or emissions per capita; energy or emissions intensity of GDP; and the state of technology in sulfur abatement and energy efficiency derived from a production frontier model estimated using the Kalman filter. Three convergence tests test for β−convergence, σ−convergence and cointegration of the trends and the effect of NAFTA on these measures. I also test whether NAFTA induced a structural break in the trend of the various indicators. The results show that the extreme {{predictions of the}} outcomes of NAFTA have not materialized. Rather, trends that were alread...|$|R
40|$|AbstractThe use of {{technical}} analysis indicators for trading is widely known and discussed. Quite {{a large number}} of indicators and the long time period of their usage provide opportunities for creating profitable and successful trading strategies. On the other side technical analysis indicators were constructed for the stock market and therefore to traders on the Forex market it places the question. Can be a strategy based purely on technical analysis indicators profitable on the market with high volatility? Do we use the old, proven indicators, or use the newer ones? Will indicators generate good trading entries in time of crisis? The paper tries to find answers to some of these questions. On the basis of Moving Average Convergence <b>Divergence</b> (MACD) <b>indicator,</b> the trading strategies have been developed and back-tested at the Forex market with different timeframes. An important element of the research is to distinguish the time period of the crisis and beyond the crisis period and tested success of created strategies at the major, most traded currency pair. At the end of the paper the performance and profitability of the created strategies are discussed...|$|R
40|$|Ordered {{weighted}} averaging (OWA) {{operators and}} their extensions are powerful tools used in numerous decision-making problems. This class of operator {{belongs to a}} more general family of aggregation operators, understood as discrete Choquet integrals. Aggregation operators are usually characterized by indicators. In this article four indicators usually associated with the OWA operator are extended to discrete Choquet integrals: namely, the degree of balance, the <b>divergence,</b> the variance <b>indicator</b> and Renyi entropies. All of these indicators are considered from a local and a global perspective. Linearity of indicators for linear combinations of capacities is investigated and, to illustrate the application of results, indicators of the probabilistic ordered weighted averaging -POWA- operator are derived. Finally, an example is provided to show the application to a specific context...|$|R
40|$|In smooth-particle hydrodynamics (SPH), {{artificial}} viscosity {{is necessary}} for the correct treatment of shocks, but often generates unwanted dissipation away from shocks. We present a novel method of controlling the amount of artificial viscosity, which uses the total time derivative of the velocity <b>divergence</b> as shock <b>indicator</b> and aims at completely eliminating viscosity away from shocks. We subject the new scheme to numerous tests and find that the method works at least as well as any previous technique in the strong-shock regime, but becomes virtually inviscid away from shocks, while still maintaining particle order. In particular sound waves or oscillations of gas spheres are hardly damped over many periods. Comment: 14 pages (15 in arXiv), 15 figures, accepted for publication in MNRA...|$|R
40|$|The {{research}} {{aimed to}} measure the accuracy and combination of Classic and Modern Technical Analysis. PT Wijaya Karya Tbk (WIKA) ’s stock in two periods is the sample of research. Technical {{analysis was used to}} predict stock prices by observing changes in historical share price. Practically, technical analysis is divided into Classic Technical and Modern. Research was conducted by library study and using a computer software. Microsft Excel was used for the simulation and Chart Nexus for analyzing Modern Technical Analysis. The research period started in January 1, 2013 until December 31, 2013 and January 1, 2014 until December 31, 2014. The Classic Technical Analysis used Support, Resistance, Trendline, and Flag Patern. Meanwhile for Modern Technical Analysis used Moving Average, Stochastic, Moving Average Convergence <b>Divergence</b> (MACD) <b>indicator.</b> The Classical Technical Analysis gave less result than Modern Technical Analysis. The classical give 14 investment decisions in two periods. The average return of Classical Technical is 15, 50 %. Meanwhile the Modern Technical Analysis gave 18 investment decisions in two periods. The average return of Modern Technical is 18, 14 %. Combining Classic Technical Analysis and Modern Technical Analysis gave 20 investment decisions with the average rate of return 20, 41 %...|$|R
40|$|This study {{proposes a}} {{multiple}} kernel learning (MKL) -based regression model for crude oil spot price forecasting and trading. We used a well-known trend-following technical analysis indicator, the moving average convergence and <b>divergence</b> (MACD) <b>indicator,</b> for extracting features from original spot prices. Additionally, we factored {{in the possibility}} that movements of target crude oil prices {{may be related to}} other important crude oil markets besides the target market for the prediction time horizon since traders may find price movement information within other relevant crude oil markets useful. We also considered multiple timeframes in this study since trends may differ across different timeframes and, in fact, traders may use their own timeframes. Therefore, for forecasting target crude oil prices, this study emphasizes on features pertaining to other important crude oil markets and different timeframes in addition to features of the target crude oil market and target timeframe. Moreover, the MKL framework has been used to fuse information extracted from different sources and timeframes of the same data source. Experimental results show that out-of-sample forecasting using the MKL method is superior to benchmark methods in terms of root mean square error (RMSE) and average percentage profit (APP). They also show that the information from multiple timeframes is useful for prediction, but that from another crude oil market is not...|$|R
40|$|The current {{ability to}} produce massive amounts of data and the impossibility in storing it {{motivated}} the development of data stream mining strategies. Despite the proposal of many techniques, this research area still lacks in approaches to mine data streams composed of multiple time series, which has applications in finance, medicine and science. Most of the current techniques for clustering streaming time series have a serious limitation in their similarity measure, {{which are based on}} the Pearson correlation. In this paper, we show the Pearson correlation is not capable of detecting similarities even for classic time series models, such as those by Box and Jenkins. This limitation motivated our proposal to cluster streaming time series based on their generating functions, which is achieved by considering features obtained using descriptive measures, such as Auto Mutual Information, the Hurst Exponent and several others. We present a new tree-based clustering algorithm, entitled TS-Stream, which uses the extracted features to produce partitions in better accordance to the time series generating functions. Experiments with synthetic data sets confirm TS-Stream outperforms ODAC, currently the most popular technique, in terms of clustering quality. Using real financial time series from the NYSE and NASDAQ, we conducted stock trading simulations employing TS-Stream to support the creation of diversified investment portfolios. Results confirmed TS-Stream increased the monetary returns in several orders of magnitude when compared to trading strategies simply based on the Moving Average Convergence <b>Divergence</b> financial <b>indicator.</b> FAPESP (Fundação de Amparo à Pesquisa do Estado de São Paulo) —Brazil (grant # 2010 / 05062 - 6...|$|R
40|$|Despite the {{enormous}} theoretical {{attention given to}} the evolutionary consequences of sexual reproduction, {{the validity of the}} key assumptions on which the theory depends rarely has been evaluated. It is often argued that a reduced ability to purge deleterious mutations condemns asexual lineages to an early extinction. However, most well characterized asexual lineages fail to exhibit the high levels of neutral allelic divergence expected in the absence of recombination. With purely descriptive data, it is difficult to evaluate whether this pattern is a consequence of the rapid demise of asexual lineages, an unusual degree of mutational stability, or recombination. Here, we show in mutation-accumulation lines of asexual Daphnia that the rate of loss of nucleotide heterozygosity by ameiotic recombination is substantially greater than the rate of introduction of new variation by mutation. This suggests that the evolutionary potential of asexual diploid species is not only a matter of mutation accumulation and reduced efficiency of selection, but it underscores the limited utility of using neutral allelic <b>divergence</b> as an <b>indicator</b> of ancient asexuality...|$|R
40|$|In this paper, it {{is shown}} that two popular conceptions about the {{behavior}} of negative power law (neg-p) noise—that is, noise with a PSD Lp(f) |f| p for p< 0 —are based on myth and that the reality is quite different. The first myth is that one can “fix ” a neg-p divergence problem in a variance like a standard or N-sample variance simply by replacing it with an Allan or Hadamard variance without further action. The paper will show that each type of variance has a different interpretation as an error measure and that such arbitrary swapping merely masks the true problem. In the process, we will show that such variance <b>divergences</b> are true <b>indicators</b> of severe system or modeling problems that must be physically addressed, not ignored. The second myth is that one can use ensemble-based statistical estimation techniques like least squares and Kalman filters to properly estimate polynomial deterministic behavior in data containing non-highpass filtered neg-p noise. It is demonstrated that such noise can generate highly anomalous fitting results because non-highpass-filtered neg-p noise is both infinitely correlated and non-ergodic. Thus, non-p noise is shown to act more like systematic error than conventional noise in such cases...|$|R
40|$|The <b>divergence</b> and {{alignment}} <b>indicator</b> (DAI) is {{an extension}} of the ASTM E 803 L/D thermal neutron radiography L/D device that allows the user to determine both the beam centerline and the beam divergence. The DAI was made using aluminium plate and rods, and incorporated cadmium wire for contrast. Circular symmetry was utilized to simplify manufacture. The DAI was placed with the five posts against the film cassette or radioscopic imaging device in the physical center of the beam, The DAI was perpendicular to the selected beam radius when the front and back center Cd wire images overlap. The degree of misalignment was indicated by their image positions. After the DA 1 was aligned, analysis of the cadmium wire &quot;+ &quot; image spacing yielded the beam divergence. The DAI was tested in a neutron beam which has an L/D of 30 but a small degree of divergence. The DAI was also imaged using an X-ray source. The point source predictions of Cd wire image locations showed good agreement with those measured from the X-ray radiograph. The neutron radiographic locations could be predicted using the point source equations, even though the neutron beam was a complex distributed source...|$|R
40|$|Shifts in {{microbial}} community function and structure can be indicators of environmental stress and ecosystem change in wetland soils. This study evaluated {{the effects of}} increased salinity, increased inundation, and their combination, on soil microbial function (enzyme activity) and structure (phospholipid fatty acid (PLFA) signatures and terminal restriction fragment length polymorphisms (T-RFLP) profiles) in a brackish mangrove peat soil using tidal mesocosms (Everglades, Florida, USA). Increased tidal inundation resulted in reduced soil enzyme activity, especially alkaline phosphatase, {{an increase in the}} abundance and diversity of prokaryotes, and a decline in number of eukaryotes. The community composition of less abundant bacteria (T-RFLPs comprising 0. 3 – 1 % of total fluorescence) also shifted as a result of increased inundation under ambient salinity. Several key biogeochemical indicators (oxidation-reduction potential, CO 2 flux, porewater NH 4 +, and dissolved organic carbon) correlated with measured microbial parameters and differed with inundation level. This study indicates microbial function and composition in brackish soil is more strongly impacted by increased inundation than increased salinity. The observed <b>divergence</b> of microbial <b>indicators</b> within a short time span (10 -weeks) demonstrates their usefulness as an early warning signal for shifts in coastal wetland ecosystems due to sea level rise stressors...|$|R
40|$|Informal {{economy is}} rather {{difficult}} to define and demarcate in the methodological context. International Conference of Labour Statisticians in 2003 adopted a set of guidelines regarding definition of statistical categories of informal employment. These include for example employed unregistered own-account workers, contributing family workers, persons who work based on oral agreement, etc. Informal economy is a contentious topic {{in many developing countries}} as it brings about many elements that from several aspects adversely affect the development. The most commonly stressed are the fiscal implications (associated with tax revenue loss) and some social concerns. However, {{in some parts of the}} world informal sector went from being considered as a negative occurrence to be tolerated as a partial solution to some of the challenges that hinder development of rural regions and communities. The aim of the paper is to determine the relationship between informal economy and level of development and quality of life in Ukrainian regions. The paper examines the role of informal economy in regional structure of Ukraine, while confronting the findings with regional <b>divergence</b> in relevant <b>indicators</b> of development and quality of life. There are statistically significant differences in the size of the informal employment among different types of Ukrainian regions (by rural-urban typology). With increasing share of informal employment in the regions, the income level of households decreases significantly even when we take into consideration the level of unemployment...|$|R
40|$|It is {{now widely}} known that most {{economic}} time series of nominal and real exchange rates, money supplies, nominal and real interest rates, price levels and annual rates of inflation possess {{the property of}} unit root non-stationarity (stochastic trends). The objective {{of this paper is}} to consider whether the establishment of the Exchange Rate Mechanism (ERM) of the European Monetary System (EMS) in March 1979 contributed to greater stability in member countries' exchange rates in the 1980 s, and led to convergence to lower inflation rates. The analysis of time-series data in a multivariate framework suggests the existence of at least one stable relationship, and possibly two such relationships, in the goods, money and foreign exchange markets. The larger the number of cointegrated vectors for a particular set of variables, the more stable the system and the greater the reduction in the <b>divergence</b> of various <b>indicators</b> from their equilibrium values. We actually find fewer cointegrating vectors in total for the post- 1979 period than for the earlier period, though the volatility of both nominal and real exchange rates are lower in the later period. It is, however, likely that the supply side shocks which Europe and the rest of the world experienced during the period 1973 - 79 could also have increased the relative volatility in indicators in the pre-EMS period as compared to the post-EMS period...|$|R
40|$|Prior to Mexico's {{entry to}} NAFTA {{predictions}} of the consequent {{impact on the environment}} in that country ranged from the dire to the very optimistic. This paper investigates NAFTA's outcomes in terms of energy use and the emission of atmospheric pollutants. Specifically, has entry into NAFTA led to a convergence or <b>divergence</b> in <b>indicators</b> of emissions, environmental efficiency, and emissions specific technology in Mexico, the United States, and Canada? Four emissions variables are considered: energy, carbon, sulfur, and NOx. Three different indicators of emissions and environmental efficiency are computed and tested for both convergence and the presence of a structural break associated with the introduction of NAFTA: energy or emissions per capita; energy or emissions intensity of GDP; and the state of technology in sulfur abatement and energy efficiency derived from a production frontier model estimated using the Kalman filter. Three convergence tests test for beta-convergence, sigma-convergence, and cointegration of the trends and the effect of NAFTA on these measures. I also test whether NAFTA induced a structural break in the trend of the various indicators. The results show that the extreme {{predictions of the}} outcomes of NAFTA have not materialized. Rather, trends that were already present before the introduction of NAFTA continue and in some cases improve post-NAFTA, but not yet in a dramatic way. There is strong evidence of convergence for all four intensity indicators across the three countries towards a lower intensity level. Though intensity is rising initially in some cases in Mexico, it eventually begins to fall post-NAFTA. Per capita measures for the two criteria pollutants also show convergence, {{but this is not the}} case for energy and carbon and the latter variables also drift moderately upwards. The state of technology in energy efficiency and sulfur abatement is improving in all countries, though there is little if any sign of convergence and NAFTA has no effect on the rate of technology diffusion. However, total energy use and carbon emissions increase both pre- and post- NAFTA and total NOx emissions increase in Mexico. Only total sulfur emissions are stable and falling in all three NAFTA partners. ...|$|R
40|$|This paper {{provides}} {{evidence on}} whether {{the creation of the}} euro has changed the way global turbulences affect euro area and other economies. Specifically, it considers the impact of global shocks on the competitiveness of individual euro area countries and assesses whether their responses to such shocks have converged, as well as to what pattern. Technically, the paper applies a newly developed methodology based on infinite VAR theory featuring a dominant unit to a large set of over 60 countries' real effective exchange rates, including those of the individual euro area economies, and compares impulse response functions to the estimated systems before and after EMU with respect to three types of shocks: a global US dollar shock, generalised impulse response function shocks and a global shock to risk aversion. Our results show that the way euro area countries' real effective exchange rates adjust to these shocks has converged indeed, albeit to a pattern that depends crucially {{on the nature of the}} shock. This result is noteworthy given the apparent <b>divergence</b> in competitiveness <b>indicators</b> of these countries in the first ten years of EMU, which suggests that this diverging pattern is unlikely to be due to global external shocks with asymmetric effects but rather to other factors, such as country-specific domestic shocks. JEL Classification: C 21, C 23 euro, High-Dimensional VAR, Identification of Shocks, Real Effective Exchange Rates, Weak and Strong Cross Sectional Dependence...|$|R
40|$|This article aims to {{determine}} the convergence of the 27 EU Member States {{in the field of}} excise duties in the period 2000 – 2015. However, more recent complete data for all states are not available yet. The development trend towards convergence or <b>divergence</b> of monitored <b>indicators</b> is detected by indicators that represent excise taxes in the tax systems of the Member States of the European Union from the Eurostat database. Excise taxes are collected as whole. The article should answer two questions that are derived from generally preferred trends in the EU in a given period, ie. the trend growth of the tax burden to consumption and a trend approximation (harmonization) taxing consumption due to the functioning of internal market in the EU. The question is whether Member states and candidate countries are similar {{to each other in the}} field of excise duties and any similarity to the changes between the years 2000 and 2015. The second question is whether the differences are caused by tax policy states, ie. Changes in rates or absolute consumption. The indicators of individual member states are subjected to cluster analysis, and subsequently evaluated by means of selected factors that relate to tax policy and national economic aggregates, especially the consumption of taxed products. Results show growing differences (divergence) between most countries of the original EU‑ 15 group and the group of countries which joined the European Union in 2004 and 2007...|$|R
40|$|The Moving Average Convergence <b>Divergence</b> (MACD) trading <b>indicator</b> {{is simple}} and has been widely used in {{financial}} markets to provide trading signals. The MACD-Histogram (MACDH) {{can be derived from}} MACD as a second-order trading signal of price actions. To reduce the lagging effects in MACD&MACDH, forecasted values are introduced in a hybrid trading signal, termed as the forecasted MACDH. A detailed trading simulation is performed for a single stock/commodity under a single long-short-MACD parameter of different timeframes of charts is taken into consideration to explain the experimental design. In the Stock Market, Commodity Market, Forex Market all over the World this concept of Histograms can be applied. MACD Histogram is actually a value that can be positive or negative according that value a bar is plotted on the MACD Technical Indicator. This MACD Histogram gives the answer to what will be the movement of the market in future and according to that the investor or trader can take decision on Buy/Sell or Long/Short. The Concept Data Mining is used to retrieve the data and values of previous and current Histograms. Data mining is a process used by companies to turn raw data into useful information. By using software to look for patterns in large batches of data, businesses can learn more about their customers and develop more effective marketing strategies as well as increase sales and decrease costs. Data mining depends on effective data collectio...|$|R
40|$|Accurate {{measurement}} of bank risk {{is a matter}} of considerable importance for bank regulation and supervision. Current practices in most countries emphasize reliance on financial statement data for assessing banks 2 ̆ 019 risk. However, the possibility of increased reliance on market-based risk indicators has been a topic for academic and regulatory debate for a long time. Market monitoring of bank risk has typically been tested by regressing market-based risk indicators on various benchmark indicators (such as accounting ratios and credit ratings) to detect whether the market tracks bank risk. This approach overlooks the methodological 2 ̆ 018 unobservability 2 ̆ 019 problem that testing one imperfect proxy indicator against another, when the true value (in this case, a bank 2 ̆ 019 s 2 ̆ 018 true 2 ̆ 019 risk) is unknown, must yield limited conclusions as to the appropriateness of either indicator 2 ̆ 013 particularly in the event of failure to establish a significant association. This paper assesses the relative information content of different risk indicators indirectly by associating the <b>divergence</b> between these <b>indicators</b> with the institutional setting. Empirical results for a large panel of banks worldwide suggest that market-based indicators are often more accurate than accounting indicators for high levels of institutional quality. In particular, spreads on subordinated debt may be more informative than either equity-based or accounting-based measures if the institutional conditions for market discipline to function are favourable. In addition, a combination measure incorporating both accounting and market data has superior accuracy regardless of the level of institutional quality, indicating that market data may contain complementary information on risk. These results cast doubt on the validity of the conclusions drawn in several previous studies that reject market discipline based on the finding that market-based risk indicators do not correspond well with various standard non-market indicators...|$|R
40|$|Esta pesquisa tem o objetivo de avaliar o grau de convergência entre as normas contábeis emitidas pela China e as normas internacionais do IASB (International Accounting Standard Board). Para que fosse concebida, foi necessário identificar e descrever as divisões importantes no processo de reforma econômica da República Popular da China; analisar o ambiente legal e regulamentar, bem como a evolução da educação e da profissão contábil e sua influência na edição de normas contábeis; identificar os principais órgãos normatizadores da contabilidade e suas principais funções exercidas e comparar os padrões locais e os internacionais, com a finalidade de verificar a harmonia dos resultados sob as normas contábeis da China e as internacionais editadas pelo IASB. Para efetuar a comparação, foram utilizadas as reconciliações do lucro líquido divulgado pelas empresas que tem ações do tipo B negociadas na Bolsa de Valores de Shenzhen, sendo obtidas as reconciliações em conformidade com os padrões internacionais de contabilidade editados pelo IASB. Assim, utilizou-se um indicador de conservadorismo” que serviu de parâmetro para comparabilidade dos resultados obtidos pelos padrões locais e internacionais. Conforme verificado na comparação de padrões, as normas chinesas apresentam divergências quando comparadas aos padrões do IASB. Entretanto, para confirmar estas divergências, o indicador de “conservadorismo” ratificou ou não a aderência da convergência às normas internacionais. Este indicador mostrou que a amostra das empresas pesquisadas, quando utilizam as normas chinesas, resulta em um lucro mais conservador em relação ao resultado reconciliado com os padrões internacionais editados pelo IASB. ___________________________________________________________________________________________ ABSTRACTThis {{research}} has as objective to evaluate degree of convergence between the accounting standards emitted by China and the International IASB's standards International Standard Accounting Board). For {{this to be}} conceived, {{it was necessary to}} identify and to describe the striking divisions that were important in the process of economic reform of Popular Republic of China; it was also necessary to analyze the legal and regular atmosphere, as well as the evolution of education and of the accounting profession and its influence in the edition of accounting standards; besides, it was necessary to identify the main normative accounting bodies and its main exercised functions; and was necessary to compare the local and international patterns with the purpose of verifying the harmony of the results under the China's accounting standards and the international ones published by IASB. The reconciliations of the net profit disclosed by companies that have type B stocks traded in the Shenzhen's stock exchange were used to make the comparison. The reconciliations in conformity with the international standards of accounting published by IASB were then obtained. Thus, it was used an indicator of "conservatism" that served as parameter for the comparability of the results obtained by the local and international patterns. As verified in the comparison of standards, the Chinese one present divergences when compared with IASB's patterns. However, to confirm these <b>divergences,</b> the <b>indicator</b> of "conservatism" ratified, or not, the adherence of the convergence to the international standards. This indicator showed that the sample of the researched companies, when adopted the Chinese norms, result in a more conservative profit in relation to the result reconciled with the international standards published by IASB...|$|R
40|$|Evolutionary {{algorithms}} {{consist of}} several heuristics {{able to solve}} optimization tasks by imitating some aspects of natural evolution. In the ﬁeld of computational ﬁnance, this type of procedures, combined with neural networks, swarm intelligence, fuzzy systems and machine learning has been successfully applied {{to a variety of}} problems, such as the prediction of stock price movements and the optimal allocation of funds in a portfolio. Nowadays, there is an increasing interest among computer scientists to solve these issues concurrently by deﬁning automatic trading strategies based on artiﬁcial expert systems, technical analysis and fundamental and economic information. The objective is to develop procedures able, from one hand, to mimic the practitioners behavior and, from the other, to beat the market. In this sense, Fernandez-Rodríguez et al. (2005) investigate the proﬁtability of the generalized moving average trading rule for the General Index of Madrid Stock Market by optimizing parameter values with a genetic algorithm. They conclude that the optimized trading rules are superior to a risk-adjusted buy-and-hold strategy if the transaction costs are reasonable. Similarly, Papadamou & Stephanides (2007) present the GATradeTool, a parameter optimization tool based on genetic algorithms for technical trading rules. In the description of this software, they compare it with other commonly used, non-adaptive tools in terms of stability of the returns and computational costs. Results of the tests on the historical data of a UBS fund show that GATradeTool outperforms the other tools. Fernández-Blanco et al. (2008) propose to use the moving average convergence <b>divergence</b> technical <b>indicator</b> to predict stock indices by optimizing its parameters with a genetic algorithm. Experimental results for the Dow Jones Industrial Average index conﬁrm the capability of evolutionary algorithms to improve technical indicators with respect to the classical conﬁgurations adopted by practitioners. An alternative approach to generate technical trading systems for stock timing that combines machine learning paradigms and a variable length string multi-objective genetic algorithm is proposed in Kaucic (2010). The most informative technical indicators are selected by the genetic algorithm and combined into a unique trading signal by a learning method. A static single-position automated day trading strategy between the S&P 500 Composite Index and the 3 -months Treasury Bill is analyzed in three market phases, up-trend, down-trend and sideways-movements, covering the period 2000 - 2006. The results indicate that the near-optimal set of rules varies among market phases but presents stable results and is able to reduce or eliminate losses in down-trend periods. As a natural consequence of these studies, evolutionary algorithms may constitute a promising tool also for portfolio strategies involving more than two stocks. In the ﬁeld of portfolio selection, Markowitz and Sharpe models are frequently used as a task for genetic algorithm optimization. For instance, the problem of ﬁnding the efﬁcient frontier associated with the standard mean-variance portfolio is tackled by Chang et al. (2000). They extend the standard model to include cardinality and composition constraints by applying three heuristic algorithms based upon genetic algorithms, tabu search and simulated annealing. Computational results are presented for ﬁve data sets involving up to 225 assets. Wilding (2003) proposes a hybrid procedure for portfolio management based on factor models, allowing constraints on the number of trades and securities. A genetic algorithm is responsible for selecting the best subset of securities that appears in the ﬁnal solution, while a quadratic programming routine determines the utility value for that subset. Experiments show the ability of this approach to generate portfolios highly able to track an index. The β − G genetic portfolio algorithm proposed by Oh et al. (2006) selects stocks based on their market capitalization and optimizes their weights in terms of portfolio β’s standard deviation. The performance of this procedure depends on market volatility and tends to register outstanding performance for short-term applications. The approach I consider for portfolio management {{is quite different from the}} previous models and is based on technical analysis. In general, portfolio optimizations using technical analysis are modular procedures where a module employs a set of rules based on technical indicators in order to classify the assets in the market, while another module concentrates on generating and managing portfolio over time (for a detailed presentation of the subject, the interested reader may refer to Jasemi et al. (2011)). An interesting application in this context is the approach developed by Korczak & Lipinski (2003) that leads to the optimization of portfolio structures by making use of artiﬁcial trading experts, previously discovered by a genetic algorithm (see Korczak & Roger (2002)), and evolutionary strategies. The approach has been tested using data from the Paris Stock Exchange. The proﬁts obtained by this algorithm are higher than those of the buy-and-hold strategy. Recently, Ghandar et al. (2009) describe a two-modules interacting procedure where a genetic algorithm optimizes a set of fuzzy technical trading rules according to market conditions and interacts with a portfolio strategy based on stock ranking and cardinality constraints. They introduce several performance metrics to compare their portfolios with the Australian Stock Exchange index, showing greater returns and lower volatility. An alternative multi-modular approach has been developed by Gorgulho et al. (2011) that aims to manage a ﬁnancial portfolio by using technical analysis indicators optimized by a genetic algorithm. In order to validate the solutions, authors compare the designed strategy against the market itself, the buy-and-hold and a purely random strategy, under distinct market conditions. The results are promising since the approach outperforms the competitors. As the previous examples demonstrate, the technical module occupies, in general, a subordinate position relative to the management component. Since transaction costs, cardinality and composition constraints are of primary importance for the rebalancing purpose, the effective impact of technical signals in the development of optimal portfolios is not clear. To highlight the beneﬁts of using technical analysis in portfolio management, I propose an alternative genetic optimization heuristic, based on an equally weighted zero investment strategy, where funds are equally divided among the stocks of a long portfolio and the stocks of a short one. Doing so, the trading signals directly inﬂuence the portfolio construction. Moreover, I implement three types of portfolio generation models according to the risk-adjusted measure considered as the objective, in order to study the relation between portfolio risk and market condition changes. The remainder of the chapter is organized as follows. Section 2 explains in detail the proposed method, focusing on the investment strategy, the deﬁnitions of the technical indicators and the evolutionary learning algorithm adopted. Section 3 presents the experimental results and discussions. Finally, Section 4 concludes the chapter with some remarks and ideas for future improvements...|$|R

