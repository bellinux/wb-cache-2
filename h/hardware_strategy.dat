9|108|Public
25|$|In June 1991, Wang started {{reselling}} IBM computers, {{in exchange}} for IBM investing in Wang stock. Wang <b>hardware</b> <b>strategy</b> to re-sell IBM RS/6000s also included further pursuit of UNIX software.|$|E
50|$|NCSA {{provides}} leading-edge computing, data storage, and visualization resources. NCSA computational {{and data}} environment implements a multi-architecture <b>hardware</b> <b>strategy,</b> deploying both clusters and shared memory systems to support high-end users and communities on the architectures best-suited to their requirements. Nearly 1,360 scientists, engineers and students used the computing and data systems at NCSA to support research {{in more than}} 830 projects.|$|E
40|$|An {{embedded}} system is an application specific electronic subsystem {{used in a}} larger system such as an appliance, an instrument or a vehicle. An {{embedded system}} is generally made of software (called embedded software) and a hardware platform. The evolution of technologies is enabling to the integration of complex platforms in a single chip (called system-on-chip, SoC) including one or several CPU subsystems to execute software and sophisticated interconnect in addition to specific hardware subsystems. Mastering the design of these embedded systems is a challenge for both system and semiconductor houses that used to apply only software strategy or only <b>hardware</b> <b>strategy.</b> This paper analyzes this evolution and defines long term roadmaps for embedded system design...|$|E
40|$|Dynamic {{software}} {{cache coherence}} strategies use information about program sharing behaviour to manage caches at run-time {{and at a}} granularity defined by the application. The program-level information is obtained through annotations placed into the application by the user or the compiler. The coherence protocols may range from simple static algorithms to dynamic algorithms that use run-time data structures similar to the directories used in <b>hardware</b> <b>strategies.</b> In this paper, we present an analytic study of five dynamic software cache coherence algorithms and compare these to a representative <b>hardware</b> coherence <b>strategy.</b> The analytic model is constructed using four input parameters [...] write probability, locality, granularity, and system size [...] and solved by analysis of a Markov chain. We show that the fundamental tradeoffs between the different <b>hardware</b> and software <b>strategies</b> are captured in this model. The {{results of the study}} show that hardware schemes perform better for fine-graine [...] ...|$|R
40|$|The {{objective}} of this Phase I research was to establish the required software and <b>hardware</b> <b>strategies</b> to achieve large scale parallelism in solving PCM problems. To meet this objective, several investigations were conducted. First, we identified the multiple levels of parallelism in PCM and the computational strategies to exploit these parallelisms. Next, several software and hardware efficiency investigations were conducted. These involved the use of three different parallel programming paradigms and solution of two example problems on both a shared-memory multiprocessor and a distributed-memory network of workstations...|$|R
40|$|Abstract: This paper focusses on Matrix Converter (MC) {{protection}} strategies. In {{order to}} improve its ride-through capability, MC faults are classified and some software and <b>hardware</b> <b>strategies</b> are proposed. The influence of the clamp circuit in MC switches is analyzed, while a special emphasis {{is given to the}} blocking voltage of different MC topologies. Besides, the MC and doubly fed asynchronous induction machine (DFIM) interaction is theoretically studied in terms of the protection circuit and, finally, all the design parameters relating to a practical clamp circuit are defined in order to ensure its commercial use in full-scale applications. Key–Words: Matrix converter, clamp design, doubly fed asynchronous induction machine, DFIM, overvoltag...|$|R
40|$|In this paper, we {{investigate}} {{a class of}} cache coherence strategies in which an abstraction for shared data at the program-level, referred to as Shared Regions (SR), is used to manage caches dynamically through software. The practical value of these strategies is measured by their performance relative to existing hardware coherence protocols, and {{the complexity of the}} SR programming interface. We present detailed quantitative results highlighting the performance of a wide array of SR coherence algorithms, including some novel algorithms introduced in this paper that use direct cache-to-cache data transfers via software to improve performance. These algorithms are studied using execution-driven simulation and compared to a representative <b>hardware</b> <b>strategy</b> for a suite of parallel applications. We study the issue of programming complexity by analyzing the process of inserting Shared Regions program annotations into these applications. The experimental results show that the best SR coheren [...] ...|$|E
40|$|ISBN: 83 - 919289 - 9 - 3 An {{embedded}} system is an application specific electronic subsystem {{used in a}} larger entity such as an appliance, an instrument or a vehicle. The {{embedded system}} may embody the complete system functionality in several different ways [...] -using software running on CPUs or in specialized hardware accelerators. The evolution of technologies is enabling the integration of complex platforms in a single chip; called System-on-Chip, SoC. Modern SoC may include one or several CPU subsystems to execute software and sophisticated interconnect in addition to specific hardware subsystems. Mastering the design of these embedded systems is a challenge for both system and semiconductor houses that used to apply only software strategy or only <b>hardware</b> <b>strategy.</b> In addition to classic software and hardware that can be designed by software and hardware engineers, SoC design requires the design of hardware-dependent software and software-dependent hardware. In order to meet performances requirements, these two parts need to be jointly designed. This requires {{a new kind of}} engineers that need knowledge in both hardware and hardware design to codesign these HW-SW interfaces. This paper analyzes this evolution and defines long term roadmaps for embedded system design...|$|E
40|$|International audienceAn {{embedded}} system is an application specific electronic subsystem {{used in a}} larger entity such as an appliance, an instrument or a vehicle. The {{embedded system}} may embody the complete system functionality in several different ways [...] -using software running on CPUs or in specialized hardware accelerators. The evolution of technologies is enabling the integration of complex platforms in a single chip; called System-on-Chip, SoC. Modern SoC may include one or several CPU subsystems to execute software and sophisticated interconnect in addition to specific hardware subsystems. Mastering the design of these embedded systems is a challenge for both system and semiconductor houses that used to apply only software strategy or only <b>hardware</b> <b>strategy.</b> In addition to classic software and hardware that can be designed by software and hardware engineers, SoC design requires the design of hardware- dependent software and software-dependent hardware. In order to meet performances requirements, these two parts need to be jointly designed. This requires {{a new kind of}} engineers that need knowledge in both hardware and hardware design to codesign these HW-SW interfaces. This paper analyzes this evolution and defines long term roadmaps for embedded system design...|$|E
50|$|MccGwire {{developed}} 'objectives analysis' {{to track}} changes in military <b>hardware</b> and <b>strategy,</b> based on painstaking analysis of personnel, equipment and geopolitical intentions. Despite this, the British and USA military never fully accepted the 'MccGwire thesis' {{as it became}} known.|$|R
30|$|We now {{describe}} the <b>hardware</b> parts selection <b>strategy</b> and {{perform an analysis}} of the clock and timing requirements for the proposed solution.|$|R
40|$|VirtuaLinux is a Linux meta-distribution {{that allows}} the creation, {{deployment}} and administration of both physical and virtualized clusters with no single point of failure. They are avoided {{by means of a}} combination of architectural, software and <b>hardware</b> <b>strategies,</b> including the transparent support for disk-less and master-less cluster configuration. VirtuaLinux support the creation and management of virtual clusters in seamless way: VirtuaLinux Virtual Cluster Manager enables the system administrator to create, save, restore Xen-based virtual clusters, and to map and dynamically re-map them onto the nodes of the physical cluster. Master-less, disk-less and virtual clustering relies on the novel VirtuaLinux disk abstraction layer, which enables the fast (almost constant time), space-efficient, dynamic creation of virtual clusters composed of fully independent complete virtual machines. VirtuaLinux has been jointly designed and developed by the Computer Science Dept. (HPC lab.) o...|$|R
40|$|The International Space Station (ISS) crew {{complement}} {{has increased in}} size from 3 to 6 crew members. In order to support this increase in crew on ISS, the United States on-orbit Segment (USOS) has been outfitted with a suite of regenerative Environmental Control and Life Support (ECLS) hardware including an Oxygen Generation System (OGS), Waste and Hygiene Compartment (WHC), and a Water Recovery System (WRS). The WRS includes the Urine Processor Assembly (UPA) and the Water Processor Assembly (WPA). With this additional life support hardware, the ISS has achieved full redundancy in its on-orbit life support system between the t OS and Russian Segment (RS). The additional redundancy created by the Regenerative ECLS hardware creates the opportunity for independent support capabilities between segments, {{and for the first}} time since the start of ISS, the necessity to revise Life Support strategy agreements. Independent operating strategies coupled with the loss of the Space Shuttle supply and return capabilities in 2010 offer new and unique challenges. This paper will discuss the evolution of the ISS Life Support <b>hardware</b> <b>strategy</b> in support of 6 -Crew on ISS, as well as the continued work that is necessary to ensure the support of crew and ISS Program objectives through the life of statio...|$|E
40|$|Internet web {{browsing}} {{has reached}} a critical tipping point. Increasingly, users rely more on mobile web browsers to ac-cess the Internet than desktop browsers. Meanwhile, webpages {{over the past decade}} have grown in complexity by more than tenfold. The fast penetration of mobile browsing and ever-richer webpages implies a growing need for high-performance mobile devices in the future to ensure continued end-user browsing experience. Failing to deliver webpages meeting hard cut-off constraints could directly translate to webpage abandonment or, for e-commerce websites, great revenue loss. However, mobile devices ’ limited battery capacity limits the degree of performance that mobile web browsing can achieve. In this paper, we demonstrate the benefits of heterogeneous systems with big/little cores each with different frequencies to achieve the ideal trade-off between high performance and en-ergy efficiency. Through detailed characterizations of different webpage primitives based on the hottest 5, 000 webpages, we build statistical inference models that estimate webpage load time and energy consumption. We show that leveraging such predictive models lets us identify and schedule webpages us-ing the ideal core and frequency configuration that minimizes energy consumption while still meeting stringent cut-off con-straints. Real hardware and software evaluations show that our scheduling scheme achieves 83. 0 % energy savings, while only violating the cut-off latency for 4. 1 % more webpages as compared with a performance-oriented <b>hardware</b> <b>strategy.</b> Against a more intelligent, OS-driven, dynamic voltage and frequency scaling scheme, it achieves 8. 6 % energy savings and 4. 0 % performance improvement simultaneously. 1...|$|E
40|$|Systems {{with large}} amounts of {{computing}} power and storage are required to simulate very large neural networks capable of tackling complex control problems and real-time emulation of the human sensory, language and reasoning systems. General-purpose parallel computers do not have communications, processor and memory architectures optimized for neural computation and so can not perform such simulations at reasonable cost. This thesis analyses several software and <b>hardware</b> <b>strategies</b> to make feasible the simulation of large, brain-like neural networks in real-time, and presents a particular multicomputer design able to implement these strategies. An important design goal is that the system must not sacrifice computational flexibility for speed, as new information about {{the workings of the}} brain and new artificial neural network architectures and learning algorithms are continually emerging. The main contributions of the thesis are: [...] - an analysis of the important features of biological n [...] ...|$|R
40|$|This paper {{describes}} a measurement {{study of the}} effects of thread placement on memory access times on the Kendall Square KSR 1 multiprocessor. The KSR 1 uses a conventional shared memory programming model in a distributed memory architecture based on a ring of rings of 64 -bit superscalar microprocessors. Memory consists of local cache memories attached to each processor and is managed in a CacheOnly Memory Architecture (COMA) fashion. Experiments run on the KSR 1 across a variety of thread configurations show that shared memory access is accelerated through strategic placement of threads which share data. The experiments "stress test" the automatic prefetching feature of the <b>hardware.</b> <b>Strategies</b> to keep the KSR 1 memory access times nearly constant even when the number of participating threads increases are proposed. 1 Introduction Typically, as the number of processors increases in a shared memory multiprocessor, memory access times also increase due to contention on a common communicati [...] ...|$|R
40|$|This report {{presents}} ten {{strategies for}} improving freeway performance {{that have become}} feasible {{with the advent of}} new software and hardware technologies for traffic control. Most of the strategies can be applied with advanced implementations of existing <b>hardware.</b> The <b>strategies</b> have in common that they can be rigorously tested. heir measures of performance can be reliably obtained and do not depend on the accuracy of data- hungry, large-scale models. ...|$|R
40|$|This paper {{discusses}} {{the benefits and}} challenges of video {{as a tool for}} supporting and enhancing peer feedback and reflection. The analysis draws on key arguments from relevant literature in combination with the author&#x 0027;s own experiences of producing and using video recordings of peer feedback sessions, presentations and personal reflections, and on learners&#x 2019; experiences of the same, gathered through feedback interviews. A number of potential benefits are presented, including the exposure of additional and alternative perspectives, the assistance of focus and recall, increased impact and greater flexibility of learning. Several challenges are also explored, such as privacy of and access to recordings, participant anxiety, technical challenges and access to <b>hardware.</b> <b>Strategies</b> are offered for capitalising on the benefits while addressing the challenges. It is concluded that thoughtful use of video in the curriculum can augment the existing multiple benefits of reflection, enquiry and/or evaluation. In the specific context of teacher education, it is argued that the embedded use of technologies such as video in professional development courses can help to develop the digital literacy of teaching staff...|$|R
40|$|Tank {{irrigation}} systems of India are century old. Most of the tanks have, over time, degraded into open access resources due to weak property relations. Encroachment, privatization and government {{appropriation of the}} tanks have been the main outcomes {{of the failure of}} local authority system to enforce the institutional arrangements under common property resources management regime. About 2 % of the tanks in the tank less intensive region and 67 % of the tanks in the intensive region have become defunct. Wells that are supposed to be a security against late season tank water scarcity, have, of late become a major threat to the very survival of the tanks. Also taxes from the multiple uses of the tanks if collected by a single agency are sufficient to meet the operation and maintenance expenditure of the tanks both in the short run and in the long run. The modernization options derived from the simulation model indicate that software strategies such as sluice management will have higher pay-off than the <b>hardware</b> <b>strategies</b> such as canal lining and additional wells. Policy interventions include physical investments, management and legal aspects...|$|R
40|$|Artificial neural {{networks}} (ANN) offer tremendous promise in classifying electrocardiogram (ECG) for detection and diagnosis of cardiovascular diseases. In this thesis, we propose a reusable neuron architecture (RNA) to enable an efficient and cost-effective ANN-based ECG processing by multiplexing the same physical neurons for both feed-forward and back-propagation stages. RNA further conserves {{the area and}} resources of the chip and reduces power dissipation by coalescing different layers of the neural network into a single layer. Moreover, the microarchitecture of each RNA neuron has been optimized to maximize the degree of hardware reusability by fusing multiple two-input multipliers and a multi-input adder into one two-input multiplier and one two-input adder. With RNA, we demonstrated a hardware implementation of a three-layer 51 - 30 - 12 artificial neural network using only thirty physical RNA neurons. A quantitative design space exploration in area, power dissipation, and speed between the proposed RNA and three other implementations representative of different reusable <b>hardware</b> <b>strategies</b> is presented and discussed. An RNA ASIC was implemented using 45 nm CMOS technology and verified on a Xilinx Virtex- 5 FPGA board. Compared with an equivalent software implementation in C executed on a mainstream embedded microprocessor, the RNA ASIC improves both the training speed and the energy efficiency by three orders of magnitude, respectively. The real-time and functional correctness of RNA was verified using real ECG signals from the MIT-BIH arrhythmia database...|$|R
40|$|The robot-soccer {{system used}} in our {{experiments}} {{is divided into three}} sub-systems [...] vision system, <b>hardware</b> and <b>strategy.</b> The MediaCamp 7 vision system which can run at a full frame rate of 30 Hz is used. The same is trained on six colors (two for team colors, one for the ball, and three more for individual home robots). Communication is done through radio-frequency signals, sending three bytes of information(left velocity, right velocity and commands) to each robot. A centralised system is followed for controlling the robots. All calculations are done on the host computer and, commands are sent to robots...|$|R
40|$|We {{describe}} {{a framework for}} capturing firewall requirements as high-level descriptions based on the policy specification language Ponder. The framework provides abstraction from hardware implementation while allowing performance control through constraints. Our <b>hardware</b> compilation <b>strategy</b> for such descriptions involves a rule reduction step to produce a hardware firewall rule representation. Three main methods have also been developed for resource optimisation: partitioning, elimination, and sharing. A case study involving five sets of filter rules indicates {{that it is possible}} to reduce 67 - 80 % of hardware resources over techniques based on regular contentaddressable memory, and 24 - 63 % over methods based on irregular content-addressable memory. ...|$|R
40|$|Abstract—A multi-board {{run-time}} reconfigurable (MRTR) {{system for}} evolvable hardware (EHW) is introduced {{with the aim}} to implement on hardware the bidirectional incremental evolution (BIE) method. The main features of this digital intrinsic EHW solution rely on the multi-board approach, the variable chromosome length management and the partial configuration of the reconfigurable circuit. These three features provide a high scalability to the solution. The design has been written in VHDL with the concern of not being platform dependant {{in order to keep}} a flexibility factor as high as possible. This solution helps tackling the problem of evolving complex task on digital configurable support. Keywords—Evolvable <b>Hardware,</b> Evolutionary <b>Strategy,</b> multiboard FPGA system...|$|R
5000|$|In {{the summer}} of 1970, the CP/CMS team had begun work on a System/370 version of CP/CMS; this would become VM/370. CP-370 proved vital to the S/370 project, by {{providing}} a usable simulation of a S/370 on S/360-67 hardware [...] - [...] a reprise of CSC's earlier <b>hardware</b> simulation <b>strategies.</b> This approach enabled S/370 development and testing before S/370 hardware was available. A shortage of prototype S/370s was causing critical delays for the MVS project, in particular. This remarkable technical feat transformed MVS development, won an award for the CP-370 developers, and probably rescued the CP project from extinction, despite aggressive efforts to cancel the project.|$|R
40|$|The {{motivation}} {{for the construction of}} CERN Linac 4 is to improve the performance of the PSB by raising the injection energy and implementing a new H- charge exchange multiturn injection scheme. Lattice perturbations introduced by the new injection <b>hardware</b> are described. <b>Strategies</b> to mitigate the consequences, first by minimizing the additional focusing introduced and, by compensating the residual perturbation, are reported...|$|R
30|$|In our experiments, two {{use cases}} were addressed: the {{calculation}} of instant energy consumption in a region and {{the calculation of}} consumers’ monthly bill. The aggregation strategy with Intel SGX proved {{to be much more}} efficient than homomorphic encryption. However, since homomorphic encryption does not have specific <b>hardware</b> requirements, this <b>strategy</b> may be feasible for applications where the focus is not on the volume of data.|$|R
30|$|In {{contrast}} to its software strategies, Apple pursues open innovation strategies for outsourcing {{almost all of}} its hardware (display, processor, camera module, and communication module) and assembly. Apple outsources almost all its hardware needs to companies that have the best technology and patent holdings in the world (Samsung for its processor, LG for its display, and the camera module from a Japanese firm) and has its assembly done by firms in Taiwan and China. Apple retained major product concepts, core design patents, and system patents related to smartphone hardware. Apple, with its OI-type <b>hardware</b> expansion <b>strategy,</b> has supply cycles of at least 1  year, which is relatively long in this market. Consequently, Apple’s smartphone hardware is not particularly diverse.|$|R
40|$|FPGA Co-simulation of an IP core is an {{important}} design flow step in IP and System Development. In this paper we discuss how, with Xilinx's System Generator for DSP 3. 1 (XSG), {{it is possible for}} multiple-users to hardware cosimulate IP cores over any distance via TCP/IP, sharing only one FPGA board resource. The <b>hardware</b> co-simulation <b>strategy</b> is mutually exclusive in that only one user at any one time can hardware co-simulate on the FPGA board. We demonstrate this with the use of two encryption cores, Camellia and AES- 128 (Advanced Encryption Standard), which have both been generated using the block-based tool. The sharing of the FPGA board is handled with a set of Matlab function commands...|$|R
40|$|Thesis (M. S.) University of Alaska Fairbanks, 2002 This thesis {{describes}} {{the design and}} implementation of an embedded controller that {{is used for the}} Vehicle Navigation Unit (VNU) prototypes that are being developed at the University of Alaska Fairbanks (UAF). The goal of the VNU project is to develop a system that will measure relative position and provide wireless communication between four identical vehicles without the use of GPS signals. Each VNU consists of an antenna and phase detector array, embedded controller, radio modem magnetometer, and a diagnostic computer. The main focus of this thesis is the design and implementation of the embedded controller hardware and software that integrates all the VNU components into an operational system. The embedded controller utilizes the Motorola MC 68 HC 711 E 9 microcontroller and the Zilog Z 85230 Serial Communication Controller that receives and transmits the data serially. The relative distance and bearing between VNUs is estimated by measuring the angle of arrival and received signal strength of the radio frequency packets transmitted by each VNU. The magnetometer is used to monitor the horizontal orientation of the VNU and to serve as a fixed referencefor comparing the relative bearing between vehicles. These raw measurements are archived into a diagnostic computer, which estimates the relative position between the VNUs and provides a graphical representation. These VNU prototypes are designed for ideal environments and are intended to provide a test bed for evaluating signal processing and <b>hardware</b> <b>strategies</b> for mitigating multipath effects. The complete VNU design is presented, started with a functional block diagram of the hardware and software, and concluding with operational tests that demonstrate the performance of the fully integrated prototype...|$|R
40|$|Music {{perception}} of cochlear implant users: A questionnaire, {{and its implications}} for a music training program Technological advances in cochlear implant (CI) <b>hardware</b> and speech-processing <b>strategies</b> have resulted in the majority of post-lingually deafened adult CI recipients achieving excellent open-set speech discrimination in quiet. However, speech perception in noise, the {{perception of}} tonal languages, and music perception remains a challenge for many CI recipients (Gfeller et al, 1998...|$|R
40|$|We {{present a}} new hardware-software co-simulation {{framework}} enabling fast prototyping in system-on-chip de-signs. On the software side, the machine description language LISA allows {{the generation of}} bit-true models of programmable architectures on various levels – from instruction-set to phase accuracy. Based on these models, a complete tool-suite consisting of fast compiled processor simulator, assembler, linker, HLL-compiler as well as co-simulation interface can be generated automatically. On the hardware side, the SystemC simulation class library is employed and enhanced with our generic co-simulation in-terface that enables the coupling of hardware and software models specified at various levels of abstraction. Besides that, a <b>hardware</b> modeling <b>strategy</b> using abstract macro-cycle based C++ processes to increase hardware modeling efficiency and simulation speed is presented. ...|$|R
40|$|In {{this paper}} we shall address the {{possibility}} of incorporating a new degree of freedom {{in the design of}} electronic systems. It consists of providing the ability to evolve its internal meso-structure while in operation. This new design strategy is allowed by the features included in a new family of FPGA devices, which is called FIPSOC (Field Programmable System On a Chip). Besides a programmable digital section composed of an array of LUT-like configurable cells, the device includes a configurable analog part and a general purpose microcontroller. Furthermore, the configuration scheme used for the programmable digital section allows for an efficient and fast realisation of dynamic reconfiguration principles. As we shall show in this paper, these properties offer two new on-line <b>hardware</b> evolution <b>strategies,</b> giving rise to what we have called virtual meso-structures. 1...|$|R
40|$|In {{the last}} few years, {{efficient}} resource management {{turned out to be}} one of the major challenges for <b>hardware</b> designers. <b>Strategies</b> of reusability through reconfiguration have demonstrated interesting potentials to address it, providing also power and area minimization. The Multi-Dataflow Composer (MDC) tool has been presented to the scientific community to automatically build-up runtime coarse-grained reconfigurable platforms. Originally conceived in the field of Reconfigurable Video Coding (RVC), the MDC allows achieving attractive results also for hardware designers operating in different application fields. In this work, we intend to demonstrate the potential orthogonality of the MDC approach with respect to the RVC domain. A runtime reconfigurable wavelet denoiser, targeted for biomedical applications, has been developed and prototyped onto an FPGA Development Board Spartan 3 E 1600. Impressive results in terms of resource minimization have been achieved with respect to more traditional solutions...|$|R
40|$|Each of the 3 km long {{transfer}} lines between the SPS and the LHC {{is equipped with}} two beam stoppers (TEDs), one {{at the beginning of}} the line and one close to the LHC injection point, which need to absorb the full transferred beam. The beam stoppers are used for setting up the SPS extractions and {{transfer lines}} with beam without having to inject into the LHC. Energy deposition and thermo-mechanical simulations have, however, shown that the TEDs will not be robust enough to safely absorb the high intensity beams foreseen for the high-luminosity LHC era. This paper will summarize the simulation results and limitations for upgrading the beam stoppers. An outline of the <b>hardware</b> upgrade <b>strategy</b> for the TEDs together with modifications to the SPS extraction interlock system to enforce intensity limitations for beam on the beam stoppers will be given...|$|R
40|$|This paper {{proposes a}} novel <b>hardware</b> {{implementation}} <b>strategy</b> to achieve low-cost design for digital predistortion (DPD) of radio frequency (RF) power amplifiers (PAs) using a modified decomposed vector rotation (DVR) -based behavioral model. To make the model hardware friendly, we first modify the model into a sub-decomposed format which significantly reduces the computational complexity in model extraction. We then reassemble the coefficients and propose a simple digital implementation structure for real-time signal processing in the transmit path. A new Dual-Direction COordinate Rotation DIgital Computer (DD-CORDIC) design is also proposed to simultaneously calculate both magnitude and values {{to facilitate the}} model implementation. To validate hardware implementation, a wide-band signal is employed to evaluate the performance with a Doherty power amplifier. Experimental {{results show that the}} proposed approach can achieve comparable performance with much lower system complexity compared to that using the conventional approaches...|$|R
40|$|We {{develop and}} apply several {{strategies}} for setting physical parameters on quantum annealers for application problems {{that do not}} fit natively on the <b>hardware</b> graph. The <b>strategies</b> are tested with a culled random set of mixed satisfiability problems, yielding results that generalize to guidelines regarding which parameter setting strategies to use for different classes of problems, and how to choose other necessary hardware quantities as well. Alternate methods of changing the hardware implementation of an application problem are also considered and their utility discussed...|$|R
