7|112|Public
40|$|The {{temporal}} {{envelope of}} a <b>decorrelated</b> <b>signal</b> derived from an original signal can be shaped without introducing additional distortion, when a spectral flattener {{is used to}} spectrally flatten the spectrum of the <b>decorrelated</b> <b>signal</b> and the original signal prior to using the flattened spectra for deriving a gain factor describing the energy distribution between the flattened spectra, and when the so derived gain factor is used by an envelope shaper to timely shape the envelope of the <b>decorrelated</b> <b>signal...</b>|$|E
40|$|An {{apparatus}} {{for enhancing}} an audio signal comprises a signal processor for processing the audio signal {{in order to}} reduce or eliminate transient and tonal portions of the processed signal and a decorrelator for generating a first <b>decorrelated</b> <b>signal</b> and a second <b>decorrelated</b> <b>signal</b> from the processed signal. The apparatus further comprises a combiner for weightedly combining the first and the second <b>decorrelated</b> <b>signal</b> and the audio signal or a signal derived from the audio signal by coherence enhancement using time variant weighting factors and to obtain a two-channel audio signal. The apparatus further comprises a controller for controlling the time variant weighting factors by analyzing the audio signal so that different portions of the audio signal are multiplied by different weighting factors and the two-channel audio signal has a time variant degree of decorrelation...|$|E
3000|$|In {{practical}} situations, {{audio signals}} are often simply modeled as a {{sum of the}} primary and ambient components. In this case, the mono downmix (S) and its <b>decorrelated</b> <b>signal</b> (S [...]...|$|E
50|$|Linear {{predictive}} coders can {{be modeled}} {{as an attempt}} to <b>decorrelate</b> <b>signals</b> by subtracting the best possible linear prediction from the input signal, leaving a whitened residual signal.|$|R
40|$|Purpose: Human infants at {{greatest}} risk for esotropia {{are those who}} suffer cerebral insults that could <b>decorrelate</b> <b>signals</b> from the 2 eyes during an early critical period of binocular, visuomotor development. The author reared normal infant monkeys, under conditions of binocular decorrelation, to determine if this alone was sufficient to cause esotropia and associated behavioral as well as neuroanatomic deficits...|$|R
40|$|This paper {{proposes a}} simple scheme for audio coding {{that does not}} use perceptual models. The audio coder {{is based on the}} {{discrete}} wavelet transform to <b>decorrelate</b> <b>signals,</b> computed through the lifting scheme, and followed by Huffman coding. The evaluation of the coding scheme is presented by using some. wav audio test files, coded for different conditions, and also includes subjective evaluation. Experimental results show the compression ratios achieved, the degradation of the signals expressed as values of signal to noise ratio and the changes in spectrum information...|$|R
40|$|In {{this paper}} we {{developed}} lossless audio compression by using reversible transforms that map their coefficients as integers to integers. Three reversible transforms, S-transform, TS-transform, and SP-transform were implemented to decorrelate redundant signals in music samples. Golomb-Rice code {{combined with the}} Laplacian probability density function (PDF) was used to encode the <b>decorrelated</b> <b>signal.</b> Various audio samples excerpted from the SQAM-CD were tested by prototypical lossless compression system we developed and compression results are presented with comparing with the result obtained by using linear prediction method in our previous work...|$|E
40|$|Abstract—We {{present a}} novel {{approach}} {{to the problem of}} the indoor localization in wireless environments. The main contribution of this paper is four folds: (a) We show that, by projecting the measured signal into a <b>decorrelated</b> <b>signal</b> space, the positioning accuracy is improved since the cross correlation between each AP is reduced. (b) We demonstrate that this novel approach achieves a more efficient information compaction and provides a better scheme to reduce online computation. The drawback of AP selection techniques is overcome since we reduce the dimensionality by combing features. Each component in the decorrelated space is the linear combination of all APs. Therefore a more efficient mechanism is provided to utilize information of all APs while reducing the computational complexity. (c) Experimental results show that the size of training samples can be greatly reduced in the decorrelated space. That is, fewer human efforts are required for developing the system. (d) We carry out comparisons between RSS and three classical decorre-lated spaces including Discrete Cosine Transform (DCT) ...|$|E
40|$|Objectives: We {{developed}} a method {{with the aim}} of decorrelating scalp EEG based on a set of spatial constraints. Methods: We assume that the scalp EEG can be modelled by a small number of current dipoles of fixed location and orientation, placed at regions of interest. The algorithm is based on weighted linear spatial decomposition in order to obtain a weighted solution to the inverse problem. An EEG data matrix is first weighted in favour of a single dipole in the set. The dipole moment is then calculated from the weighted EEG by the pseudo-inverse method. This is repeated for each dipole. Results: Six seizures were processed from 4 patients using the standard least-squares solution and our weighted version. The average cross-correlation between channels was calculated for each case. The first method resulted in a mean drop in cross-correlation of 16. 5 % from that of the scalp. Our method resulted in a reduction of 34. 5 %. Conclusions: Our method gives a more spatially <b>decorrelated</b> <b>signal</b> in regions of interest (although it is not intended as an accurate localization tool). Subsequent analysis is more robust and less likely to be dependent on specific recording montages. This is more than could be obtained using a standard least-squares solution using the same model...|$|E
40|$|The {{compensation}} of nonlinear signal distortions as caused by small, low-cost loudspeakers driven at high volume by second-order Volterra filters {{has been investigated}} in recent works. In the field of acoustic echo cancellation, such undesired signal components are removed by adaptive filtering. Since {{the performance of the}} usually applied LMS adaptation suffers from correlations of the input data, preceding decorrelation of the excitation signal is desirable in order to increase the speed of convergence. This contribution discusses an efficient configuration for incorporating a decorrelation filter into nonlinear adaptive filtering scenarios. Simulation results for both noise and speech indicate an increase in convergence speed by providing <b>decorrelated</b> <b>signals</b> as filter input. Index Terms — decorrelation, nonlinear AEC, adaptive Volterra filter 1...|$|R
3000|$|... where μ 0 is a Lagrange multiplier. In {{order to}} avoid the {{influence}} of correlated noise subspace when <b>decorrelating</b> mixed-up <b>signals,</b> the pre-whitening step is omitted. Finally, the desired weight vector with unit variance constraint in the proposed method is as follows (details are presented in Appendix 1): [...]...|$|R
40|$|We {{study the}} spatiotemporal {{correlation}} in natural time-varying images {{and explore the}} hypothesis that the visual system is concerned with the optimal coding of visual representation through spatiotemporal decorrelation of the input signal. Based on the measured spatiotemporal power spectrum, the transform needed to <b>decorrelate</b> input <b>signal</b> is derived analytically and then compared with the actual processing observed in psychophysical experiments...|$|R
40|$|The {{problems}} of designing image compression algorithms have been considered. The {{problems of}} increasing compression coefficients, {{accuracy of the}} image reproduction at productivity of the algorithm at keeping of the sizes, shape, orientation and coordinated of the image parts have been formulated. The image coding algorithm distinguishing with the high productivity and increased accuracy in the reproduction of the image parts has been proposed and investigated. The recurrent relation for desing of the quantization intervals for the instructive-distibuted signal readings has been obtained. The density of the probabilistic values in the <b>decorrelated</b> <b>signal</b> discretized by a proposed algorithms has been designed that permitted to coordinate {{the parameters of the}} discretization and quantization units proceeding from condition of the equal shares of the introduced disturbances. The algorithm for elimination of the non-linear relation in the neighbour readings and algorithm for the entropy coding with several tables of the non-stationary sequences have been created on base of the proposed signal model. The proposed algorithms and expressions optimizing the parameters of their operation are the new results. The results have been used at creation of the software for the devices of the image input, processing, transmission and storage developed during the carrying-out of the researchAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|Abstract: Conventional spatially-adaptive regularized image {{restoration}} schemes weight the ∗ Corresponding author amount of regularization {{according to the}} spatial content of an image. In this correspondence, we first separately <b>decorrelate</b> the <b>signals</b> under analysis into uncorrelated components and then weight the amount of regularization performed to these components accordingly. The proposed approach works better than conventional schemes especially in edge regions...|$|R
40|$|Neurons in {{the early}} stages of {{processing}} in the primate visual system efficiently encode natural scenes. In previous studies of the chromatic properties of natural images, the inputs were sampled on a regular array, with complete color information at every location. However, in the retina cone photoreceptors with different spectral sensitivities are arranged in a mosaic. We used an unsupervised neural network model to analyze the statistical structure of retinal cone mosaic responses to calibrated color natural images. The second-order statistical dependencies derived from the covariance matrix of the sensory signals were removed in the first stage Neural Computation 15, 397 – 417 (2003) c ○ 2002 Massachusetts Institute of Technology 398 E. Doi, T. Inui, T. Lee, T. Wachtler, and T. Sejnowski of processing. These decorrelating filters were similar to type I receptive fields in parvo- or konio-cellular LGN in both spatial and chromatic characteristics. In the subsequent stage, the <b>decorrelated</b> <b>signals</b> were linearly transformed to make the output as statistically independent as possible...|$|R
40|$|Within {{digital audio}} codification, the {{processing}} of multichannel signals {{has become one of}} the main fields of research. Current work on the subject look for effective ways to exploit the existing redundancy between the different channels in order to reduce the codification binary rate. This work studies the Karhunen-Loeve Transform (KLT) as a method of <b>decorrelating</b> multi-channel <b>signals</b> prior to coding. Results on codification via AAC are reported...|$|R
40|$|A new online signal {{processing}} technique is described to reduce speckle noise in ultrasound images. In the imaging system, a focused piston transducer {{is divided into}} thirty-two sectors. In the receive mode, parallel {{signal processing}} arranges the sectors into eight maltese crosses. The rf signals of the perpendicular arms of each cross are multiplied in a phase sensitive process. designed to reduce side lobes resulting from the sector shapes while maintaining lateral resolution {{through the use of}} the full aperture diameter. The signals from the crosses are then combined via postdetection sumnation. The six maltese crosses show <b>decorrelated</b> <b>signals</b> equivalent to four independent samples of the speckle noise which decreases noise contrast by a factor of two with no measureable loss of spatial resolution. Post summation compression is included to retain the conventional signal dynamic range. processing maintains the normal image line rate. Images of tissue-mimicking phantoms including speckle targets show improved detectability of simil. ated The orthogonal receive mode multiplication is Six of the eight crosses perform successfully. Parallel signa...|$|R
40|$|A {{high quality}} 5 - 2 - 5 matrix encoder and decoder system offers the {{prospect}} of inexpensive compatible media for multichannel sound. The advantages to the consumer, music and film producers, and broadcasters, are obvious. This paper reports on a system which offers excellent 5 - 2 - 5 codec performance, while preserving or improving the balance, frontal perspective, and spaciousness of standard stereo recordings. The decoder provides two or four independent rear outputs, which are capable of complete separation from the other outputs for a single steered sound effect, and which preserve full left/right separation during music. <b>Decorrelated</b> <b>signals</b> such as music can be panned forward and back with full left/right separation. Frontal perspective and the balance between center material such as dialog and vocals and other material is preserved through careful control of the center channel level {{as a function of}} the center content of the input signal. This paper will present a mathematical description of the matrix elements of the new decoder, and discuss some of the psychoacoustic data on which it is based...|$|R
40|$|The {{nonlinear}} Fourier transform (NFT), {{a powerful}} tool in soliton theory and exactly solvable models, is a method for solving integrable partial differential equations governing wave propagation in certain nonlinear media. The NFT <b>decorrelates</b> <b>signal</b> degrees-of-freedom in such models, {{in much the same}} way that the Fourier transform does for linear systems. In this three-part series of papers, this observation is exploited for data transmission over integrable channels such as optical fibers, where pulse propagation is governed by the nonlinear Schrödinger equation. In this transmission scheme, which can be viewed as a nonlinear analogue of orthogonal frequency-division multiplexing commonly used in linear channels, information is encoded in the nonlinear frequencies and their spectral amplitudes. Unlike most other fiber-optic transmission schemes, this technique deals with both dispersion and nonlinearity directly and unconditionally without the need for dispersion or nonlinearity compensation methods. This first paper explains the mathematical tools that underlie the method. Comment: This version contains minor updates of IEEE Transactions on Information Theory, vol. 60, no. 7, pp. 4312 [...] 4328, July 201...|$|R
40|$|A correlated-noise source {{has been}} {{developed}} for use in calibrating an airborne or spaceborne Earth-observing correlation microwave polarimeter that operates in a in a pass band that includes a nominal frequency of 10. 7 GHz. Deviations from ideal behavior of the hardware of correlation polarimeters are such as to <b>decorrelate</b> the <b>signals</b> measured by such an instrument. A correlated-noise source provides known input signals, measurements {{of which can be}} processed to estimate and correct for the decorrelation effect...|$|R
40|$|The {{performance}} of signal enhancement systems based on adaptive filtering is {{highly dependent on}} the quality of the noise reference, In the LMS algorithm, signal leakage into the mise reference leads to signal distortion and poor noise cancellation, The origin of the problem lies in the fact that LMS <b>decorrelates</b> the <b>signal</b> estimate with the noise reference, which, in the case of signal leakage, makes little sense, An algorithm is proposed that <b>decorrelates</b> the <b>signal</b> estimate with a ''signal-free'' noise estimate, obtained by adding a symmetric filter to the classical structure, The symmetric adaptive decorrelation (SAD) algorithm no longer makes a distinction between signal and noise and is therefore a signal separator rather than a noise canceler, Stability and convergence are of the utmost importance in adaptive algorithms and hence are carefully studied, Apart from limitations on the adaptation constants, stability around the desired solution can only be guaranteed for a subclass of signal mixtures, Furthermore, the decorrelation criterion does not yield a unique solution, and expressions for the ''phantom'' solutions are derived, Simulations with short FIR filters confirm the predicted behavior. status: publishe...|$|R
30|$|In addition, {{with the}} same {{standard}} deviation, the expected value of the exponential terms approaches zero for decreasing λ, representing better noise suppressing ability for the signals in high-frequency bands. Wider spread of DPDs is needed to <b>decorrelate</b> the <b>signal</b> source with low frequencies, such as male voice. In this article, in order {{to focus on the}} impact of DPDs derived from array geometry, colored noise generated by SII mode is applied as the excitation of the simulations to compute performance metrics.|$|R
40|$|A new {{direction}} of arrival (DOA) estimation method for the {{uniform linear array}} is proposed for correlated non-circular source signals. The new DOA estimation method applies a Toeplitz matrix reconstruction method to <b>decorrelate</b> the <b>signals</b> directly without using spatial smoothing. The method makes full use of the array aperture and achieves complete decorrelation. Therefore, the algorithm is suitable for DOA estimation for real-valued coherent signals with {{a small number of}} snapshots or low SNR. Simulation results demonstrate the validity and efficiency of the proposed method. Yuexian Wang, Matthew Trinkl...|$|R
40|$|Conventional {{spatially}} adaptive regularised {{image restoration}} schemes weight {{the amount of}} regularisation according to the spatial content of an image. The authors first separately <b>decorrelate</b> the <b>signals</b> under analysis into uncorrelated components and then weight the amount of regularisation performed to these components accordingly. The proposed approach works better than conventional schemes, especially in edge regions. Department of Electronic and Information EngineeringAuthor name used in this publication: S. O. ChoyAuthor name used in this publication: Y. H. ChanAuthor name used in this publication: W. C. SiuCentre for Multimedia Signal Processing, Department of Electronic and Information Engineerin...|$|R
40|$|This study {{deals with}} the bearing and the range {{estimation}} for buried objects problem. We propose a new method that combines the array processing approaches with an accurate acoustical modeling for the buried objects localization problem in the underwater acoustics environment. This method incorporates the exact solution for the scattered field (instead of using the plane wave model) in the MUSIC method, uses the focusing operator to <b>decorrelate</b> the <b>signals</b> and estimates both the range and the bearing objects. Finally, the performances of the proposed method are validated on experimental data recorded during an underwater acoustics experiments. 1...|$|R
5000|$|Many data {{compression}} algorithms incorporate a decorrelation stage. For example, many transform coders first apply a fixed linear transformation that would, on average, {{have the effect}} of <b>decorrelating</b> a typical <b>signal</b> of the class to be coded, prior to any later processing. This is typically a Karhunen-Loève transform, or a simplified approximation such as the discrete cosine transform.|$|R
40|$|We {{propose a}} {{parallel}} factor (PARAFAC) analysis-based angle and polarization estimation algorithm for multiple coherent sources using a uniformly-spaced linear tripole sensor array. By forming a PARAFAC model using the spatial {{signature of the}} tripole array, the new algorithm requires neither spatial smoothing nor vector-field smoothing to <b>decorrelate</b> the <b>signal</b> coherency. We also establish that the angle-polarization parameters of K coherent signals can be uniquely determined by PARAFAC analysis, {{as long as the}} number of tripoles L ≥ 2 K − 1. In addition, the proposed algorithm can offer enhanced angle and polarization estimation accuracy by extending the interspacing of the tripoles beyond a half wavelength...|$|R
40|$|International audienceState {{of the art}} video coders {{are based}} on {{prediction}} and transform coding. The transform <b>decorrelates</b> the <b>signal</b> to achieve high compression levels. In this paper we propose improving the performances of the latest video coding standard, HEVC, by adding a set of rate-distortion optimised transforms (RDOTs). The transform design is based upon a cost function that incorporates a bit rate constraint. These new RDOTs compete against classical HEVC transforms in the rate-distortion optim-isation (RDO) loop {{in the same way}} as prediction modes and block sizes, providing additional coding possibilities. Reductions in BD-rate of around 2 % are demonstrated when making these transforms available in HEVC...|$|R
40|$|It is {{well known}} that the {{performance}} of direction-of-arrival (DOA) estimation and beamforming algorithms degrades in the presence of correlated signals. Since the techniques like spatial and weighted smoothing, which were developed for <b>decorrelating</b> the <b>signals,</b> suffer from reduced effective aperture, several authors have recently proposed redundancy averaging as an alternative spatial averaging method. In this correspondence, we analyze this method for the asymptotic case and show that the eigenstructure of the resulting matrix, after redundancy averaging, is inconsistent with that of the underlying signal model, thereby leading to biased DOA estimates. Further, perfect decorrelation of the signals is not guaranteed even if the array size is made infinitely large...|$|R
40|$|Abstract In this paper, {{a hybrid}} method is {{proposed}} for multi-channel electroen-cephalograms (EEG) signal compression. This new method {{takes advantage of}} two different compression techniques: fractal and wavelet-based coding. First, an effec-tive decorrelation is performed through the principal component analysis of different channels to efficiently compress the multi-channel EEG data. Then, the <b>decorrelated</b> EEG <b>signal</b> is decomposed using wavelet packet transform (WPT). Finally, fractal encoding {{is applied to the}} low frequency coefficients of WPT, and a modified wavelet-based coding is used for coding the remaining high frequency coefficients. This new method provides improved compression results as compared to the wavelet and fractal compression methods...|$|R
40|$|Direct imaging of exoplanets {{involves}} {{the extraction of}} very faint signals from highly noisy data sets, with noise that often exhibits significant spatial, spectral and temporal correlations. As a results, {{a large number of}} post-processing algorithms have been developed in order to optimally <b>decorrelate</b> the <b>signal</b> from the noise. In this paper, we explore four such closely related algorithms, all of which depend heavily on the calculation of covariances between large data sets of imaging data. We discuss the similarities and differences between these methods, and demonstrate how the use sequential calculation techniques can significantly improve their computational efficiencies. Comment: 30 pages, 3 figures, accepted to Ap...|$|R
40|$|The {{correlation}} between waveforms arriving at {{an array of}} sensors, which is generally a consequence of multipath propagation, can drastically degrade the performance of source localization and detection schemes. Most approaches proposed so far to handle this difficulty, consist in performing some preprocessing aiming to <b>decorrelate</b> the <b>signals</b> and have limited effects. They are moreover restricted to specific array geometries. We present a technique that works for any geometry and that is able to handle coherent signals as well. It simply relies on no prior assumption on spatial stationarity. Index Terms — DOA estimation, correlated waveforms, global matched filter, generalized maximum likelihood ratio 1...|$|R
30|$|Pilot {{sequence}} hopping: This component {{refers to}} random shuffling {{of the pilots}} applied within a cell. This shuffle occurs between every time slot. The purpose of this component is to <b>decorrelate</b> the contaminating <b>signals.</b> When pilots are shuffled, the set of contaminating users {{will be replaced by}} a new set, whose channel coefficients are uncorrelated with those of the previous set.|$|R
40|$|Purpose: Human infants at {{greatest}} risk for esotropia {{are those who}} suffer cerebral insults that could <b>decorrelate</b> <b>signals</b> from the 2 eyes during an early critical period of binocular, visuomotor development. The author reared normal infant monkeys, under conditions of binocular decorrelation, to determine if this alone was sufficient to cause esotropia and associated behavioral as well as neuroanatomic deficits. Methods: Binocular decorrelation was imposed using prism-goggles for durations of 3 to 24 weeks (in 6 experimental, 2 control monkeys). Behavioral recordings were obtained, followed by neuroanatomic analysis of ocular dominance columns and binocular, horizontal connections in the striate visual cortex (area V 1). Results: Concomitant, constant esotropia developed in each monkey exposed to decorrelation for a duration of 12 to 24 weeks. The severity of ocular motor signs (esotropia-angle; dissociated vertical deviation; latent nystagmus; pursuit/optokinetic tracking asymmetry; fusional vergence deficits), {{and the loss of}} V 1 binocular connections, increased as a function of decorrelation duration. Stereopsis was deficient and motion visual evoked potentials were asymmetric. Monkeys exposed to decorrelation for 3 weeks showed transient esotropia but regained normal visuomotor behaviors and binocular V 1 connections. Conclusions: Binocular decorrelation is a sufficient cause of infantile esotropia when imposed during a critical period of visuomotor development. The systematic relationship between severity of visuomotor sign, and severity of V 1 connectivity deficit, provides a neuroanatomic mechanism for several of these signs. Restoration of binocular fusion and V 1 connections, after short durations of decorrelation, helps explain the benefits of early repair in human strabismus. Trans Am Ophthalmol Soc 2007; 105 : 564 - 59...|$|R
3000|$|To {{localize}} immersed sources, we {{proposed to}} compare two methods: classical methods, {{based on a}} spatial analysis of the spatial covariance matrix of the data to estimate the DOA [5], and the proposed method, based on a spatio-temporal analysis which first estimates TDOA from the frequential covariance matrix of the data on each sensor and then estimates the DOA and range of the sources. To <b>decorrelate</b> the <b>signals,</b> smoothing methods are used. Spatial smoothing for classical methods [18] and frequential smoothing for the proposed methods are used. The smoothing methods in spatial (respectively, frequential) domain require {{that the number of}} sensors N (respectively, the number M of frequencies) must be {{greater than or equal to}} [...]...|$|R
40|$|Abstract—Microwave {{radar and}} microwave-induced thermoacoustic {{technique}} exploit the contrast in the permittivity and conductivity between malignant and healthy tissue. They {{have emerged as}} promising techniques for detecting breast cancers. This paper compares the imaging capability of these techniques {{in the presence of}} homogeneous and heterogeneous breast tissue. Relying on the data from the finite-difference time-domain simulations, the study shows that both techniques are capable of imaging homogeneous objects. In the presence of electromagnetic dispersion and heterogeneity, radar signals suffer from strong dispersion and multiple scattering, which <b>decorrelate</b> the <b>signals</b> with the scatterers. The microwaveinduced thermoacoustic technique takes the advantage of breast being acoustically homogeneous and is capable of generating high-quality images. 1...|$|R
