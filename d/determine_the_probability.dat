1261|10000|Public
25|$|For example, in {{probability}} theory, integrals {{are used}} to <b>determine</b> <b>the</b> <b>probability</b> of some random variable falling within a certain range. Moreover, the integral under an entire probability density function must equal 1, which provides a test of whether a function with no negative values could be a density function or not.|$|E
500|$|Neverwinter Nights 2 {{is played}} in the third-person from a {{top-down}} perspective, where the player controls a hero {{and his or her}} attendant party. As a role-playing video game based on the Dungeons & Dragons 3.5 edition ruleset, players build a player character in accordance with the character creation rules of Dungeons & Dragons, which includes selecting a race and class, then assigning skill points. There are sixteen races and twelve classes available, including the rogue and the wizard, as well as an additional seventeen unlockable classes. [...] Neverwinter Nights 2 makes use of the d20 system introduced in Dungeons & Dragons, where a die roll or random number is used to <b>determine</b> <b>the</b> <b>probability</b> and effectiveness of every action, including attacks and saving throws. The player character can recruit companions during the campaign, and may form a party with up to three of them. Party members can be controlled directly by the player or given orders dictating how to behave in combat.|$|E
2500|$|... bitstrings {{of length}} n that are {{incompressible}} by c. [...] To <b>determine</b> <b>the</b> <b>probability,</b> divide by 2n.|$|E
5000|$|... decoding, <b>determining</b> <b>the</b> <b>probability</b> {{of a given}} label {{sequence}} [...] given [...]|$|R
5000|$|... where [...] is <b>the</b> {{potential}} <b>determining</b> <b>the</b> <b>probability</b> of each {{value of}} [...]|$|R
5000|$|A {{model of}} how worlds are {{constructed}} {{is used in}} <b>determining</b> <b>the</b> <b>probabilities</b> of theories, ...|$|R
2500|$|Calculus {{can be used}} in {{conjunction}} with other mathematical disciplines. For example, it can be used with linear algebra to find the [...] "best fit" [...] linear approximation for a set of points in a domain. Or it {{can be used in}} probability theory to <b>determine</b> <b>the</b> <b>probability</b> of a continuous random variable from an assumed density function. In analytic geometry, the study of graphs of functions, calculus is used to find high points and low points (maxima and minima), slope, concavity and inflection points.|$|E
2500|$|A homeowner named Anthony Pizzitola, who was {{resident}} in the Braeswood area, unsuccessfully sued HISD {{to stop the}} demolition of his house and asked historian Janet Wagner to <b>determine</b> <b>the</b> <b>probability</b> of historic artifacts at Gregory-Lincoln because there were rumors {{that there was a}} grave site from the American Reconstruction era. These rumors of prevented any development for several years. In 2006 Houston ISD did not find any new grave sites and started development of Gregory-Lincoln. The new Gregory-Lincoln campus was scheduled to be completed by 2008. http://www.houstonisd.org/HISDPortal/departments/ContentPage/0,3099,45555309_59997080_64882212,00.html ...|$|E
2500|$|The frequentist {{view has}} its own problems. It is of course {{impossible}} to actually perform an infinity of repetitions of a random experiment to <b>determine</b> <b>the</b> <b>probability</b> of an event. But if only {{a finite number of}} repetitions of the process are performed, different relative frequencies will appear in different series of trials. If these relative frequencies are to define the probability, the probability will be slightly different every time it is measured. But the real probability should be the same every time. If we acknowledge the fact that we only can measure a probability with some error of measurement attached, we still get into problems as the error of measurement can only be expressed as a probability, the very concept we are trying to define. This renders even the frequency definition circular; see for example “” ...|$|E
3000|$|... where u is {{a random}} number, T is {{the maximum number}} of generations, and η is an {{exponent}} <b>determining</b> <b>the</b> <b>probability</b> distribution.|$|R
25|$|It is {{traditionally}} defined as <b>the</b> process that <b>determines</b> <b>the</b> <b>probability</b> that a population will go extinct {{within a given}} number of years.|$|R
5000|$|Recommendations for {{research}} in <b>determining</b> <b>the</b> <b>probability</b> of mineral occurrence with Robert G. Garrett. U.S. Geological Survey Circular No. 0980, pp. 278-282, 1986 ...|$|R
2500|$|Forensic DNA typing {{has been}} an {{effective}} way of identifying or exonerating criminal suspects due to analysis of evidence discovered at a crime scene. The human genome has many repetitive regions {{that can be found}} within gene sequences or in non-coding regions of the genome. Specifically, up to 40% of human DNA is repetitive. There are two distinct categories for these repetitive, non-coding regions in the genome. The first category is called variable number tandem repeats (VNTR), which are 10-100 base pairs long and the second category is called short tandem repeats (STR) and these consist of repeated 2-10 base pair sections. [...] PCR is used to amplify several well-known VNTRs and STRs using primers that flank each of the repetitive regions. The sizes of the fragments obtained from any individual for each of the STRs will indicate which alleles are present. By analyzing several STRs for an individual, a set of alleles for each person will be found that statistically is likely to be unique. [...] Researchers have identified the complete sequence of the human genome. This sequence can be easily accessed through the NCBI website and is used in many real-life applications. For example, the FBI has compiled a set of DNA marker sites used for identification, and these are called the Combined DNA Index System (CODIS) DNA database. Using this database enables statistical analysis to be used to <b>determine</b> <b>the</b> <b>probability</b> that a DNA sample will match. [...] PCR is a very powerful and significant analytical tool to use for forensic DNA typing because researchers only need a very small amount of the target DNA to be used for analysis. For example, a single human hair with attached hair follicle has enough DNA to conduct the analysis. Similarly, a few sperm, skin samples from under the fingernails, or a small amount of blood can provide enough DNA for conclusive analysis.|$|E
5000|$|The piling-up lemma {{allows the}} {{cryptanalyst}} to <b>determine</b> <b>the</b> <b>probability</b> that the equality: ...|$|E
5000|$|... bitstrings {{of length}} n that are {{incompressible}} by c. To <b>determine</b> <b>the</b> <b>probability,</b> divide by 2n.|$|E
25|$|The first {{principle}} assumes equal probabilities for all events. When {{this is not}} true, we {{must first}} <b>determine</b> <b>the</b> <b>probabilities</b> of each event. Then, <b>the</b> <b>probability</b> is <b>the</b> sum of <b>the</b> <b>probabilities</b> of all possible favoured events.|$|R
3000|$|This {{equation}} <b>determines</b> <b>the</b> <b>probability</b> of {{a certain}} image pixel being skin-colored using a lookup table indexed with the pixel's color. <b>The</b> resultant <b>probability</b> map thresholds are then set to be threshold [...]...|$|R
40|$|The {{focus of}} this study was to generalize the theory of runs to multinomial {{outcomes}} using the generating function approach. Detailed discussion is provided for <b>determining</b> <b>the</b> <b>probability</b> distributions for all runs of length i in a sequence of n trials for the binomial and trinomial cases. The generalization to multinomial case is also presented. Application to data for patients from a long term disability care facility is presented to illustrate the use of Run Theory in <b>determining</b> <b>the</b> <b>probability</b> of a dominant state of treatment associated with a patient during his/her hospitalization. ...|$|R
5000|$|There {{are several}} {{techniques}} when performing {{qualitative risk analysis}} to <b>determine</b> <b>the</b> <b>probability</b> and impact of risks, including the following: ...|$|E
5000|$|... (For delay networks, the Erlang-C formula allows network {{operators}} to <b>determine</b> <b>the</b> <b>probability</b> of delay depending on peak traffic {{and the number}} of circuits.) ...|$|E
5000|$|... anomaly {{detection}} using a statistical {{model of the}} pixels in the image to <b>determine</b> <b>the</b> <b>probability</b> that a pixel does not match the profile, and ...|$|E
3000|$|... is the {{particles}} predisposition to make 1 or 0; it <b>determines</b> <b>the</b> <b>probability</b> threshold {{to make this}} choice. The individual {{is more likely to}} choose 1 for higher [...]...|$|R
50|$|GenePeeks is {{a genetic}} {{research}} {{company that owns}} and runs Matchright, a simulation that <b>determines</b> <b>the</b> <b>probability</b> of genetic disorders being present in a child given two people's DNA.|$|R
5000|$|... ψ(r, t) is the wavefunction, {{which is}} the quantum {{mechanical}} function that <b>determines</b> <b>the</b> <b>probability</b> amplitude for <b>the</b> particle to have a given position r {{at any given time}} t, ...|$|R
50|$|Models can use {{one or more}} {{classifiers}} {{in trying}} to <b>determine</b> <b>the</b> <b>probability</b> {{of a set of}} data belonging to another set, say spam or 'ham'.|$|E
50|$|The pair of nomograms {{at the top}} of {{the image}} <b>determine</b> <b>the</b> <b>probability</b> of {{occurrence}} and the availability, which are then incorporated into the bottom multistage nomogram.|$|E
50|$|However, {{given the}} sample, the {{evidence}} is a constant and thus scales both posteriors equally. It therefore does not affect classification and can be ignored. We now <b>determine</b> <b>the</b> <b>probability</b> distribution for {{the sex of the}} sample.|$|E
50|$|Spelling {{correction}} is {{the process}} of automatically detecting and correcting spelling errors in search queries. Most spelling correction algorithms are based on a language model, which <b>determines</b> <b>the</b> a priori <b>probability</b> of an intended query, and an error model (typically a noisy channel model), which <b>determines</b> <b>the</b> <b>probability</b> of a particular misspelling, given an intended query.|$|R
3000|$|With {{regard to}} {{clustering}} the extracted feature vectors from section “Feature extraction”, the Problem-Solving relation, i.e. the DiseaseSymptom-Treatment relation, is learnt by using Weka to <b>determine</b> <b>the</b> <b>probabilities</b> of y [...]...|$|R
40|$|Motivated by {{the problem}} of finding light (i. e., low weight) and short (i. e., low degree) codewords in narrow-sense, {{primitive}} BCH codes we consider <b>the</b> problem of <b>determining</b> <b>the</b> <b>probability</b> that a random t-set of vectors in an n dimensional vector space over GF (q) contains an r-dimensional subspace (or affine subspace). We find some bounds for this and similar probabilities and apply these techniques to estimate how short a minimum weight codeword can be in a narrowsense BCH code. 1 Introduction In Section 2 we consider <b>the</b> problem of <b>determining</b> <b>the</b> <b>probability</b> that a randomly chosen t-subset of an n-dimensional vector space over GF (q) contains an r-dimensional subspace. We also consider the more general problem of <b>determining</b> <b>the</b> <b>probability</b> that a randomly chosen t-subset of an n-set X contains at least one element of a fixed family of a-subsets of X. Our main result in Section 2 is a lower bound for this probablity. In the following sections we apply the results of Section 2 [...] ...|$|R
50|$|On {{completion}} of the assessment each control may be rated based on the responses received to <b>determine</b> <b>the</b> <b>probability</b> of its failure and the impact if a failure occurred. These ratings can be mapped to produce a heatmap showing potential areas of vulnerability.|$|E
5000|$|... where [...] is {{the initial}} number of nuclide A. When {{measuring}} {{the production of}} one nuclide, one can only observe the total decay constant [...] The decay constants [...] and [...] <b>determine</b> <b>the</b> <b>probability</b> for the decay to result in products [...] or [...] as follows: ...|$|E
5000|$|Once {{data has}} been collected, {{it can be}} sorted to <b>determine</b> <b>the</b> <b>probability</b> of co-occurrences. One common and {{well-known}} way is with a concordance: the KWIC is centered and shown with dozens of examples of it in use, as with the example for [...] "possibility" [...] below.|$|E
5000|$|<b>The</b> trade-probability function, , <b>determines</b> <b>the</b> <b>probability</b> that <b>the</b> item will be {{transferred}} from the seller to the buyer (in a deterministic mechanism, this probability is either 0 or 1, but the formalism also allows random mechanisms).|$|R
30|$|Overall, gender, age, {{previous}} labor experience, motivation, entrepreneurial {{education and}} training, initial size, legal form, size of start-up capital, industry type, and formal system, therefore, are {{important factors in}} <b>determining</b> <b>the</b> <b>probability</b> of MSEs’ survival in Ethiopia.|$|R
40|$|In {{this paper}} the fullest {{conception}} of the probabilistically combinatorial approach has been presented. This conception {{is the result of}} previous long preliminary works. The approach gives the possibility to establish the reasons of algorithms overtraining, to define the possible ways of it reduction and to build the most precise estimates of <b>the</b> recognition <b>probability.</b> <b>The</b> combinatorial approach works with <b>determined</b> data of <b>the</b> recognition process and <b>the</b> probabilistic one <b>determines</b> <b>the</b> <b>probability</b> of these results existence. The most usefulness of the combinatorial approach consists in <b>the</b> possibility to <b>determine</b> <b>the</b> effect of the training set variation on the different algorithms and select the most appropriate one from these algorithms or algorithm composition. The probabilistic part of this approach <b>determines</b> <b>the</b> <b>probability</b> of results, obtained on the basis of combinatorial approach...|$|R
