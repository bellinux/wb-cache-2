1|10000|Public
40|$|While 3 {{percent of}} the fields in Norway are grown {{organically}} in {{the advent of the}} 21 st century, only a small share of the resulting products reaches the consumers as organic food. A number of factors can explain the relative lack of success of organic products through the value chain. Lack of differentiation from conventional foods may discourage consumers. Extra costs limit the <b>interest</b> <b>of</b> <b>processors</b> and retailers. The political decisions and subsidies are directed at production, and have few direct effects on the organization of the value chain. The marketing of organic products has followed different strategies. Organic milk is handled through the national dairy cooperative, and around forty percent is sold as organic varieties of conventional brands. Meat producers have been less successful as only about twenty {{percent of the}} certified production is marketed as organic. In some of the more promising cases organic products are marketed in a niche strategy where organic production methods is one of several differentiating product attributes. ...|$|E
40|$|The {{introduction}} of a fast, but accurate and standardised, method for measuring the fineness of ultrafine wools and speciality fibres (especially cashmere) {{has always been a}} vital <b>interest</b> <b>of</b> breeders, <b>processors</b> and fibre experts. In the context of the EU cashmere project (AIR 3 -CT 94 - 0822), the OFDA (Optical Fibre Diamete...|$|R
50|$|The Soybean <b>Processors</b> Association <b>of</b> India (SOPA) {{is one of}} the apex trade associations of India. The {{organisation}} {{represents the}} <b>interests</b> <b>of</b> soybean <b>processors,</b> farmers, exporters and brokers in India, and acts as an interface between industry, government and other relevant stakeholders on policy issues and initiatives. It is authorized by the Government of India to issue Certificates of Origin for the products of exports and also authorized to issue recommendations for Visa. SOPA has R&D center for soybean and soybean products. It also help in the export promotion by providing latest information from international and national markets. SOPA also publishes monthly journal SOPA Digest to disseminate the information about researches, Agriculture news and economical review on soy industry.|$|R
40|$|International audienceThe parallelization of {{numerical}} simulation algo- rithms, i. e., their adaptation to parallel processing architectures, is an aim to reach {{in order to}} hinder exorbitant execution times. The parallelism has been imposed at the level <b>of</b> <b>processor</b> ar- chitectures and graphics cards are now used for general-purpose calculation, also known as "General-Purpose computation on Graphics Processing Unit (GPGPU) ". The clear benefit is the excellent performance over price ratio. Besides hiding the low level programming, software engineering leads to a faster and more secure application development. This paper presents the real <b>interest</b> <b>of</b> using GPU <b>processors</b> to increase performance of larger problems which concern electrical machines simulation. Indeed, we show that our auto-generated code applied to several models allows achieving speedups {{of the order of}} 10 x...|$|R
40|$|Short-neck clams oryeiiow-foot clams (Paphiamalabarica) in Ashtam udi Lake are fished by hand rake, diving and handpicking by 1, 000 - 1, 500 fishers. Commercial {{fishing for}} clams started about 30 years ago - {{prior to that}} there had been little demand for them outside the {{immediate}} local area where the clams have been eaten for generations. The growth of the commercial fishery was fuelled by demand from export markets and the <b>interest</b> <b>of</b> local fish <b>processors</b> in cooking, freezing and exporting the clam meat to customers in Vietnam, Thailand and Malaysia in the 1980 s and 1990 s...|$|R
40|$|This paper {{presents}} a processor group membership protocol designed {{to run on}} top of a local area network. The protocol maintains information about a selected group of stations that explicitly join the protocol by keeping a replica of a global membership table at every member. Additionally, the protocol guarantees that a given station always occupies the same entry in the table. As a result, table indexes do uniquely and universally identify a station and can thus be used as short identifiers. The <b>interest</b> <b>of</b> a <b>processor</b> group membership is twofold: it is a powerful auxiliary for process group membership management and it provides support for efficient message addressing. Keywords: Distributed Systems, Distributed Algorithms, Fault-Tolerance, Communication Protocols, Real-Time. 1 Introduction Distributed systems may take advantage of the local availability of up to date information about the nodes in the system. This information is not static: during the lifetime of the system, statio [...] ...|$|R
40|$|In {{this paper}} we analyze the {{performance}} of multiprocessor systems with multithreaded processing nodes. Multithreading presents challenging issues to the performance tuning because when multiple outstanding requests from a processor are being processed in the system, the feedback effect of the load at the memory and network on the processor utilization must not be ignored. Our integrated system model, based on closed queuing networks, {{takes into account the}} interaction between processors, memories and interconnection network under various application program load. We present the formulation of the model, its solution technique, and its application to the performance evaluation of multithreaded architectures. Our integrated system model takes as input, workload (e. g., number of threads, thread runlength, remote access pattern) and architectural (e. g., memory access time, network switch delay) parameters. The model predicts key performance measures <b>of</b> <b>interest</b> [...] <b>processor</b> utilization, me [...] ...|$|R
40|$|Abstract. An efficient, semi-rigorous {{synchronous}} algorithm for parallel kinetic Monte Carlo simulations is presented. The {{accuracy and}} parallel efficiency are studied {{as a function}} <b>of</b> <b>processor</b> size, number <b>of</b> <b>processors,</b> and the ratio D/F of monomer hopping rate (D) to deposition rate (F) for two different simple models of epitaxial growth. Since only local communication is required, the algorithm scales, i. e. for a large number <b>of</b> <b>processors</b> the parallel efficiency is independent of the number <b>of</b> <b>processors.</b> ...|$|R
40|$|AbstractWe {{investigate}} the effect, on {{the rate of}} convergence of {{a model of the}} asychronized parallel iteration method, of allowing the number <b>of</b> <b>processors</b> to differ from the number of splittings. Under certain regularization assumptions we prove that decreasing the number <b>of</b> <b>processors</b> increases the convergence rate. Our interpretation of this result for the model is as follows: increasing the number <b>of</b> <b>processors</b> means that each processor updates the global approximation in the host node with a local iteration which is computed from older global data. Hence the convergence rate is reduced. To prove our results we develop theorems for comparison of the spectral radii for certain nonnegative matrices which are <b>of</b> <b>interest</b> in their own right. We provide numerical examples to illustrate our results...|$|R
50|$|Due {{to the end}} of {{frequency}} scaling <b>of</b> <b>processors,</b> which is largely attributed to the effect of Dennard scaling around the year 2005, a common trend <b>of</b> <b>processor</b> manufacturers was to continue to exploit Moore's law by increasing the number <b>of</b> <b>processors</b> on a single chip, which are termed multi-core processors as opposed to uniprocessors.|$|R
40|$|Frequently used {{problems}} of linear algebra, {{such as the}} solution of linear systems, triangular decomposition and matrix multiplication, are computationally extensive. To increase the speed, those problems should be solved with systolic structures, where many processors are used concurrently to compute the result. Since two-dimensional array <b>of</b> <b>processors</b> is very consumptive, considering space and resources, {{it is better to}} use one-dimensional array <b>of</b> <b>processors.</b> This leads to the operation reallocation and causes unequal utilization <b>of</b> <b>processors,</b> but {{it is much easier to}} implernent since there is only one linear array <b>of</b> <b>processors.</b> ...|$|R
40|$|Abstract—For the {{management}} of a virtual P 2 P super-computer one is <b>interested</b> in subgroups <b>of</b> <b>processors</b> that can {{communicate with each other}} efficiently. The task of finding these subgroups can be formulated as a graph clustering problem, where clusters are vertex subsets that are densely connected within themselves, but sparsely connected to each other. Due to resource constraints, clustering using global knowledge (i. e., knowing (nearly) the whole input graph) might not be permissible in a P 2 P scenario, e. g., because collecting the data is not possible or would consume a high amount of resources. That is why we present a distributed heuristic using only limited local knowledge for clustering static and dynamic graphs. Based on disturbed diffusion, our algorithm DIDIC implicitly optimizes cut-related quality measures such as modularity. It thus settles between distributed clustering algorithms for other quality measures (e. g., energy efficiency in the field of ad-hoc-networking) and graph clustering algorithms optimizing cut-related measures with global knowledge. Our experiments show the promising potential of our new approach: Although each node starts with a random cluster number, may communicate only with its direct neighbors within the graph, and requires only a small amount of additional memory space, the solutions computed by DIDIC converge to clusterings that are comparable in quality to those computed by the established non-distributed graph clustering library mcl, whose main algorithm uses global knowledge...|$|R
50|$|Generally, large <b>of</b> <b>processor</b> {{register}} {{shows how}} big numbers core <b>of</b> <b>processor</b> can count one time. Number of registers is important too, {{because they can}} connect together for a moment with some instructions.|$|R
40|$|When using {{thousands}} <b>of</b> <b>processors</b> simultaneously, {{the application}} developer {{can no longer}} assume that the computing platform is failure free. The probability that one <b>of</b> the computing <b>processors</b> crashes drastically increases with the number <b>of</b> <b>processors</b> [9]. Safety issues not only occur in large scale computin...|$|R
40|$|We {{present an}} {{algorithm}} for all-to-all personalized communication, {{in which every}} processor has an individual message to deliver to every other processor. The machine model we consider is a cluster of processing nodes where each node, possibly consisting <b>of</b> several <b>processors,</b> can participate in only one communication operation with another node at a time. The nodes may have different numbers <b>of</b> <b>processors.</b> This general model {{is important for the}} implementation of all-to-all communication in libraries such as MPI where collective communication may take place over arbitrary subsets <b>of</b> <b>processors.</b> The algorithm is simple and optimal up to an additive term that is small if the total number <b>of</b> <b>processors</b> is large compared to the maximal number <b>of</b> <b>processors</b> in a node...|$|R
40|$|Abstract: This {{paper is}} focused on a {{parallel}} JAVA implementation <b>of</b> a <b>processor</b> defined in a Network <b>of</b> Evolutionary <b>Processors.</b> Processor description is based on JDom, which provides a complete, Java-based solution for accessing, manipulating, and outputting XML data from Java code. Communication among different processor to obtain a fully functional simulation of a Network <b>of</b> Evolutionary <b>Processors</b> will be treated in future. A safe-thread model <b>of</b> <b>processors</b> performs all parallel operations such as rules and filters. A non-deterministic behavior <b>of</b> <b>processors</b> is achieved with a thread for each rule and for each filter (input and output). Different results <b>of</b> a <b>processor</b> evolution are shown...|$|R
40|$|Abstract. In {{recent times}} {{the work on}} {{networks}} <b>of</b> <b>processors</b> has become very important, due to the low cost {{and the availability of}} these systems. This is why it is interesting to study algorithms on networks <b>of</b> <b>processors.</b> In this paper we study on networks <b>of</b> <b>processors</b> different Eigenvalue Solvers. In particular, the Power method, deflation, Givens algorithm, Davidson methods and Jacobi methods are analized using PVM and MPI. The conclusion is that the solution of Eigenvalue Problems can be accelerated by using networks <b>of</b> <b>processors</b> and typical parallel algorithms, but the high cost of communications in these systems gives rise to small modifications in the algorithms to achieve good performance. ...|$|R
40|$|This {{paper is}} focused on a {{parallel}} JAVA implementation <b>of</b> a <b>processor</b> defined in a Network <b>of</b> Evolutionary <b>Processors.</b> Processor description is based on JDom, which provides a complete, Java-based solution for accessing, manipulating, and outputting XML data from Java code. Communication among different processor to obtain a fully functional simulation of a Network <b>of</b> Evolutionary <b>Processors</b> will be treated in future. A safe-thread model <b>of</b> <b>processors</b> performs all parallel operations such as rules and filters. A non-deterministic behavior <b>of</b> <b>processors</b> is achieved with a thread for each rule and for each filter (input and output). Different results <b>of</b> a <b>processor</b> evolution are shown...|$|R
5000|$|Pipeline <b>of</b> <b>processors</b> - {{each stage}} of the {{pipeline}} consisting <b>of</b> a <b>processor</b> performing one <b>of</b> the functions listed above.|$|R
50|$|HDC pays special {{attention}} to the subproblem's granularity and its relation with the number ofAvailable processors. The total number <b>of</b> <b>processors</b> is a key parameter for the performance of theskeleton program as HDC strives to estimate an adequate assignment <b>of</b> <b>processors</b> for each partof the program. Thus, the performance of the application is strongly related with the estimatednumber <b>of</b> <b>processors</b> leading to either exceeding number of subproblems, or not enough parallelismto exploit available processors.|$|R
50|$|Throughout its lifecycle, the GTD-5 EAX {{incorporated}} a quad-redundant processor architecture. The main <b>processor</b> complex <b>of</b> the APC, TPC, TCU, RLU, and RSU all {{consisted of a}} pair <b>of</b> <b>processor</b> cards, and each <b>of</b> those <b>processor</b> cards contained a pair <b>of</b> <b>processors.</b> The on-card pair <b>of</b> <b>processors</b> executed precisely the same sequence of instructions, and {{the output of the}} pair were compared each clock cycle. If the results were not identical, the processors were immediately reset, and the pair <b>of</b> <b>processors</b> on the other card were brought online as the active processor complex. The active processor always kept memory up-to-date so that when these forced switches occurred, little data loss was suffered. When the switch was requested as a part of routine maintenance, the switch could be accomplished with no data loss at all.|$|R
40|$|Abstract. Standard job {{scheduling}} uses static job sizes which lacks flexibility regarding changing load {{in the system}} and fragmentation handling. Adaptive resource allocation is known to provide the flexibility needed to obtain better response times under such conditions. We present a scheduling approach (SCOJO-P) which decides resource allocation, i. e. the number <b>of</b> <b>processors,</b> at job start time and then keeps the allocation fixed throughout the execution (i. e. molds the jobs). SCOJO-P uses a heuristic to predict the average load on the system over the runtime of a job and then uses that information to determine the number <b>of</b> <b>processors</b> to allocate to the job. When determining how many processors to allocate to a job, our algorithm attempts to balance the <b>interests</b> <b>of</b> the job with the <b>interests</b> <b>of</b> jobs that are currently waiting {{in the system and}} jobs that are expected to arrive in the near future. We compare our approach with traditional fixed-size scheduling and with the Cirne-Berman approach which decides job sizes at job submission time by simulating the scheduling of the jobs currently running or waiting. Our results show that SCOJO-P improves mean response times by approximately 70 % vs. traditional fixed-size scheduling while the Cirne-Berman approach only improves it 30 % (which means SCOJO-P improves mean response time by 59 % vs. Cirne-Berman). ...|$|R
5|$|Both Amdahl's law and Gustafson's law {{assume that}} the running time of the serial {{part of the program}} is {{independent}} of the number <b>of</b> <b>processors.</b> Amdahl's law assumes that the entire problem is of fixed size so that the total amount {{of work to be done}} in parallel is also independent of the number <b>of</b> <b>processors,</b> whereas Gustafson's law assumes that the total amount of work to be done in parallel varies linearly with the number <b>of</b> <b>processors.</b>|$|R
50|$|Classify the <b>processors</b> <b>of</b> the systemographs in categories, {{types and}} levels; {{building}} a comparative table <b>of</b> <b>processors.</b>|$|R
40|$|This paper {{presents}} {{an overview of}} the main trends in processor architecture. It starts with an analysis of the past evolution <b>of</b> <b>processors</b> and the main driving forces behind it, and then it focuses on a description of the main architectural features <b>of</b> current <b>processors.</b> Finally, it presents a discussion on some promising directions for future evolution <b>of</b> <b>processor</b> architectures...|$|R
40|$|Previous {{researches}} on real-time scheduling {{assume that}} the number <b>of</b> <b>processors</b> required to execute a task is fixed and its computation time is given based on this fixed number <b>of</b> <b>processors.</b> However, in multiprocessor systems, the computation time of scalable task varies depending on the number <b>of</b> <b>processors</b> allocated to it. By determining a proper number <b>of</b> <b>processors</b> to be allocated to each real-time task, more real-time tasks complete their execution before deadlines. In this paper, we propose a new on-line scheduling algorithm for scalable, aperiodic, nonpreemptive, and independent tasks. The proposed algorithm uses workload to represent the computational requirement of tasks and tries to reduce the total workload of all scheduled tasks so that a newly arrived task should have more feasibility to complete its execution before deadline. The algorithm works based on three rules. First, the number <b>of</b> <b>processors</b> allocated to tasks is kept as small as possible without violating deadl [...] ...|$|R
40|$|The LogP {{model is}} a model of {{parallel}} computation that characterises a parallel computer architecture by four parameters: the latency L, the overhead o, the gap g and the number <b>of</b> <b>processors</b> P. We study the problem of constructing minimum-length schedules for treestructured programs in the LogP model. This problem is proved to be NP-hard, even for outtrees of height two in LogP models with an unlimited number <b>of</b> <b>processors.</b> For outtrees <b>of</b> height two, a 2 -approximation algorithm is presented. For intrees of height two, two approximation algorithms are presented: a 3 -approximation algorithm for LogP models with an unrestricted number <b>of</b> <b>processors</b> and a 4 Γ 2 P -approximation algorithm for LogP models with a finite number <b>of</b> <b>processors.</b> For the problem of constructing minimum-length schedules for d-ary intrees in a LogP model with a finite number <b>of</b> <b>processors,</b> three approximation algorithms are presented that are applicable in many models of parallel computation. The first con [...] ...|$|R
2500|$|... /NUMPROC=nnn [...] Sets {{the number}} <b>of</b> <b>processors</b> that Windows will run at startup. With this switch, the user can force a {{multiprocessor}} system {{to use only}} the quantity <b>of</b> <b>processors</b> (number) that you specify. Useful for troubleshooting performance problems and defective CPUs.|$|R
50|$|These are {{member of}} the second {{generation}} <b>of</b> <b>processors</b> with 16/24/32 bit instruction lengths. This gives better code density {{at the expense of}} silicon footprint, these processors are marginally larger compared to their equivalents in the first family <b>of</b> <b>processors</b> from Cortus.|$|R
50|$|Heterogeneous {{computing}} {{refers to}} systems that uses {{more than one}} kind <b>of</b> <b>processor</b> or cores. These systems gain performance or energy efficiency not just by adding the same type <b>of</b> <b>processors,</b> but by adding dissimilar coprocessors, usually incorporating specialized processing capabilities to handle particular tasks.|$|R
5000|$|... /NUMPROC=nnn [...] - [...] Sets {{the number}} <b>of</b> <b>processors</b> that Windows will run at startup. With this switch, the user can force a {{multiprocessor}} system {{to use only}} the quantity <b>of</b> <b>processors</b> (number) that you specify. Useful for troubleshooting performance problems and defective CPUs.|$|R
40|$|AbstractThe report {{presents}} {{some results}} in solving finite element equations via a parallel {{version of the}} preconditioned cg-method (ParPCG). We use a nonoverlapping domain decomposition and construct preconditioners based on Additive and Multiplicative Schwarz Methods (ASM/MSM). As components in the preconditioner, multigrid methods, hierarchical bases, new extension techniques and modified BPS- and BPX-preconditioners for handling the unknowns at the coupling nodes on the boundaries between subdomains are used. The scale up efficiency (e. g., an increasing number <b>of</b> <b>processors</b> causes an increasing problem size) of the algorithm by doubling the number <b>of</b> <b>processors</b> is larger than 95 %. Even the practical not relevant speed up efficiency (e. g., an increasing number <b>of</b> <b>processors</b> and a constant problem size) reaches 80 % by doubling the number <b>of</b> <b>processors...</b>|$|R
40|$|Efficient {{implementation}} <b>of</b> {{problems on}} <b>processor</b> arrays requires dedicated compiling techniques. This paper proposes synthesis techniques {{in the design}} <b>of</b> <b>processor</b> array architectures from system of affine recurrence equations. They implement the spacetime mapping which determine the scheduling of the calculations and the allocation of these calculations to a surface <b>of</b> <b>processors.</b> The paper emphazises the two-steps space mapping which is composed of a classical linear allocation followed by the application of two specific partitioning techniques. These techniques reduce the number <b>of</b> <b>processors</b> and therefore result in more efficient parallel solutions. The paper is illustrated with the Cholesky factorization...|$|R
40|$|The {{principles}} of the RISC architecture guided {{the design of the}} previous generation <b>of</b> <b>processors.</b> These principles have accelerated the performance gains <b>of</b> these <b>processors</b> over their predecessors. The current generation of CPUs is poised to continue this rapid acceleration of performance. In this paper we assert that the performance gains of the current generation are due to changes that are decidedly not RISC. We call this current generation <b>of</b> <b>processors</b> Post-RISC and, we describe the characteristics <b>of</b> Post-RISC <b>processors.</b> In addition, we survey six <b>processors</b> <b>of</b> the current generation that highlight the {{principles of}} Post-RISC...|$|R
40|$|The Garey-Johnson {{algorithm}} {{is a well}} known polynomial-time al-gorithm constructing an optimal schedule for the maximum lateness problem with unit execution time tasks, two parallel identical proces-sors, precedence constraints and release times. The paper {{is concerned with the}} worst-case analysis of a generalisation of the Garey-Johnson algorithm to the case of arbitrary number <b>of</b> <b>processors.</b> In contrast to other algorithms for the maximum lateness problem, the tight per-formance guarantee for the even number <b>of</b> <b>processors</b> differs from the tight performance guarantee for the odd number <b>of</b> <b>processors...</b>|$|R
40|$|The Garey-Johnson {{algorithm}} {{is one of}} only two known polynomial-time algorithms allowing to construct an optimal schedule for the maximum lateness problem with unit execution tasks, two parallel identical processors, precedence constraints and release times. The paper is concerned with the worst-case analysis of a generalisation of the Garey-Johnson algorithm for the case of arbitrary number <b>of</b> <b>processors.</b> We prove that for even number <b>of</b> <b>processors</b> the {{algorithm is}} characterised by the best currently known performance guarantee, whereas for odd number <b>of</b> <b>processors</b> it is less competitive...|$|R
