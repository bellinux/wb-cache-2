10000|10000|Public
25|$|Where M is the {{variance-covariance matrix}} {{relative}} to both independent and <b>dependent</b> <b>variables.</b>|$|E
25|$|In statistics, Wilks's lambda {{is used in}} multivariate {{analysis}} of variance (MANOVA analysis) to compare group means on a combination of <b>dependent</b> <b>variables.</b>|$|E
25|$|A true {{experiment}} with random allocation of subjects to conditions allows researchers to make strong inferences about causal relationships. In an experiment, the researcher alters parameters of influence, called independent variables, and measures resulting changes of interest, called <b>dependent</b> <b>variables.</b> Prototypical experimental research is {{conducted in a}} laboratory with a carefully controlled environment.|$|E
50|$|Manipulations are not {{intended}} to verify that the manipulated factor caused variation in the <b>dependent</b> <b>variable.</b> This is verified by random assignment, manipulation before measurement of the <b>dependent</b> <b>variable,</b> and statistical tests of effect of the manipulated <b>variable</b> on the <b>dependent</b> <b>variable.</b> Thus, a failed manipulation check does not refute {{the hypothesis that the}} manipulation caused variation in the <b>dependent</b> <b>variable.</b>|$|R
40|$|The {{regression}} model with categorical <b>dependent</b> <b>variable</b> {{is a natural}} generalization of the model with binary <b>dependent</b> <b>variable.</b> It {{is based on the}} use of baseline logits. For its building and for the evaluation of its quality, analogous procedures to the case of binary <b>dependent</b> <b>variable</b> are applied. When the categories of <b>dependent</b> <b>variable</b> are ordered (ordinal variable) the construction of model can be based on adjacent or cumulative logits or on proportional odds. The way of building of the model influences the meaning and the interpretation of its parameters. categorical <b>dependent</b> <b>variable,</b> logistic regression, logit models...|$|R
50|$|Regress the <b>dependent</b> <b>variable</b> on the {{independent}} variable to confirm that {{the independent}} variable is a significant predictor of the <b>dependent</b> <b>variable.</b>|$|R
25|$|It is {{important}} to note that the Durbin–Watson statistic, while displayed by many regression analysis programs, is not applicable in certain situations. For instance, when lagged <b>dependent</b> <b>variables</b> are included in the explanatory variables, then it is inappropriate to use this test. Durbin's h-test (see below) or likelihood ratio tests, that are valid in large samples, should be used.|$|E
25|$|Selection bias {{may result}} in a non-representative {{population}} of test subjects on spite of best efforts to obtain a representative sample. Even a double-blind study may be subject to biased selection of <b>dependent</b> <b>variables,</b> population (via inclusion and exclusion criteria), sample size, statistical methods, or inappropriate comparators, any of which can bias the outcome of a study to favor a particular conclusion.|$|E
25|$|Regression for {{prediction}}. Here a {{model is}} fitted {{to provide a}} prediction rule for application {{in a similar situation}} to which the data used for fitting apply. Here the <b>dependent</b> <b>variables</b> corresponding to such future application would be subject to the same types of observation error as those in the data used for fitting. It is therefore logically consistent to use the least-squares prediction rule for such data.|$|E
50|$|Partial {{mediation}} {{maintains that}} the mediating variable accounts for some, but not all, {{of the relationship between}} the independent <b>variable</b> and <b>dependent</b> <b>variable.</b> Partial mediation implies that there is not only a significant relationship between the mediator and the <b>dependent</b> <b>variable,</b> but also some direct relationship between the independent and <b>dependent</b> <b>variable.</b>|$|R
30|$|We {{have argued}} that {{ordinary}} least squares (OLS) multiple regression has several advantages, but a limitation is a requirement of a normally distributed <b>dependent</b> <b>variable</b> (see Wooldridge 2006, Ch. 4). Since the <b>dependent</b> <b>variable</b> of export rate was measured crudely according to four classes (none export, less than 10  % export, 10 – 50  % export, and more than 50  % export), this may violate the requirement of a normally distributed <b>dependent</b> <b>variable.</b> The <b>dependent</b> <b>variable</b> may instead take a property of an ordinal (or ordered categorical) distribution.|$|R
5000|$|When {{autocorrelation}} is present, it {{can often}} be removed to get unbiased estimates of regression coefficients and their variances by constructing a respecified <b>dependent</b> <b>variable</b> that is [...] "lagged" [...] by weightings on the <b>dependent</b> <b>variable</b> on other locations, where the weights are degree of relationship. This lagged <b>dependent</b> <b>variable</b> is endogenous, and estimation requires either two-stage least squares or maximum likelihood methods.|$|R
25|$|Repeated-measures {{experiments}} are those which take place through intervention on multiple occasions. In {{research on the}} effectiveness of psychotherapy, experimenters often compare a given treatment with placebo treatments, or compare different treatments against each other. Treatment type is the independent variable. The <b>dependent</b> <b>variables</b> are outcomes, ideally assessed in several ways by different professionals. Using crossover design, researchers can further increase the strength of their results by testing both of two treatments on two groups of subjects.|$|E
25|$|A {{common goal}} for a {{statistical}} research {{project is to}} investigate causality, and in particular to draw a conclusion {{on the effect of}} changes in the values of predictors or independent variables on <b>dependent</b> <b>variables.</b> There are two major types of causal statistical studies: experimental studies and observational studies. In both types of studies, the effect of differences of an independent variable (or variables) on the behavior of the dependent variable are observed. The difference between the two types lies in how the study is actually conducted. Each can be very effective.|$|E
25|$|Confidence limits can {{be found}} if the {{probability}} distribution of the parameters is known, or an asymptotic approximation is made, or assumed. Likewise statistical tests on the residuals can be made if the probability distribution of the residuals is known or assumed. The probability distribution of any linear combination of the <b>dependent</b> <b>variables</b> can be derived if the probability distribution of experimental errors is known or assumed. Inference is particularly straightforward if the errors are assumed to follow a normal distribution, which implies that the parameter estimates and residuals will also be normally distributed conditional on {{the values of the}} independent variables.|$|E
50|$|In {{traditional}} data studies, extracting {{the cause}} for the <b>dependent</b> <b>variable</b> to change {{may prove to be}} difficult. Experimentalists have the ability to create certain tasks that elicit the <b>dependent</b> <b>variable.</b>|$|R
40|$|The logit {{regression}} model is generally {{used as a}} method for estimating relationships in which the <b>dependent</b> <b>variable</b> is binary in nature, though it is also useful for estimation when the <b>dependent</b> <b>variable</b> is continuous but bounded on the unit intervals. Logit parameter estimates in this case are obtained by ordinary least squares regression on a simple transformation on the <b>dependent</b> <b>variable.</b> In such applications, however, measurement error in the <b>dependent</b> <b>variable,</b> rather than being relatively benign as in ordinary linear regressions, {{is a source of}} heteroscedasticity, calling into question the efficiency of the OLS estimator in such cases. ...|$|R
3000|$|... {{where the}} <b>dependent</b> <b>variable</b> of (1) is labor {{productivity}} (or value added per employee) of firm “i” in sector “j” in year “t”, while the <b>dependent</b> <b>variable</b> of (2) is average firm wage.|$|R
25|$|Animal {{experiments}} aid {{in investigating}} {{many aspects of}} human psychology, including perception, emotion, learning, memory, and thought, to name a few. In the 1890s, Russian physiologist Ivan Pavlov famously used dogs to demonstrate classical conditioning. Non-human primates, cats, dogs, pigeons, rats, and other rodents are often used in psychological experiments. Ideally, controlled experiments introduce only one independent variable at a time, in order to ascertain its unique effects upon <b>dependent</b> <b>variables.</b> These conditions are approximated best in laboratory settings. In contrast, human environments and genetic backgrounds vary so widely, and depend upon so many factors, {{that it is difficult}} to control important variables for human subjects. Of course, there are pitfalls in generalizing findings from animal studies to humans through animal models.|$|E
25|$|Johnson’s first {{published}} {{review of the}} research on cooperation and competition appeared in 1970 in his book, The Social Psychology of Education. This was followed by a more comprehensive review, with his brother Roger, published in the Review of Educational Research in 1974 and the editing of a special issue of the Journal of Research and Development in Education in 1978. In 1981 and 1983 he pioneered the use of meta-analysis in publishing reviews of the impact of cooperative, competitive, and individualistic on achievement/productivity and on interpersonal attraction. In 1989 he and his brother published a book, Cooperation and Competition: Theory and Research, which contained a series of meta-analyses (currently being revised with updates)on many of the <b>dependent</b> <b>variables</b> relevant to Social Interdependence Theory.|$|E
25|$|The consumer's preferences, {{monetary}} income and prices {{play an important}} role in solving the consumer's optimization problem (choosing how much of various goods to consume so as to maximize their utility subject to a budget constraint). The comparative statics of consumer behavior investigates the effects of changes in the exogenous or independent variables (especially prices and money incomes of the consumers) on the chosen values of the endogenous or <b>dependent</b> <b>variables</b> (the consumer's demands for the goods). When the income of the consumer rises with the prices held constant, the optimal bundle chosen by the consumer changes as the feasible set available to him changes. The income–consumption curve is the set of tangency points of indifference curves with the various budget constraint lines, with prices held constant, as income increases shifting the budget constraint out.|$|E
5000|$|The {{measurement}} of the <b>dependent</b> <b>variable</b> was originally conceptualized as the public's perceived issue [...] "salience", but subsequent studies have conceptualized the <b>dependent</b> <b>variable</b> as awareness, attention, or concern, leading to differing outcomes.|$|R
5000|$|... (1) Temporal precedence. For example, if the {{independent}} <b>variable</b> precedes the <b>dependent</b> <b>variable</b> in time, this would provide evidence suggesting a directional, and potentially causal, link from {{the independent}} <b>variable</b> to the <b>dependent</b> <b>variable.</b>|$|R
50|$|In {{statistical}} modeling, {{regression analysis}} is a statistical process for estimating {{the relationships among}} variables. It includes many techniques for modeling and analyzing several variables, when {{the focus is on}} the relationship between a <b>dependent</b> <b>variable</b> and one or more independent variables (or 'predictors'). More specifically, regression analysis helps one understand how the typical value of the <b>dependent</b> <b>variable</b> (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed. Most commonly, regression analysis estimates the conditional expectation of the <b>dependent</b> <b>variable</b> given the independent variables - that is, the average value of the <b>dependent</b> <b>variable</b> when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the <b>dependent</b> <b>variable</b> given the independent variables. In all cases, the estimation target is a function of the independent variables called the regression function. In regression analysis, it is also of interest to characterize the variation of the <b>dependent</b> <b>variable</b> around the regression function which can be described by a probability distribution. A related but distinct approach is necessary condition analysis (NCA), which estimates the maximum (rather than average) value of the <b>dependent</b> <b>variable</b> for a given value of the independent variable (ceiling line rather than central line) in order to identify what value of the independent variable is necessary but not sufficient for a given value of the <b>dependent</b> <b>variable.</b>|$|R
25|$|Different {{choices for}} the frame of {{reference}} and expansion parameters are possible in Stokes-like approaches to the non-linear wave problem. In 1880, Stokes himself inverted the dependent and independent variables, by taking the velocity potential and stream function as the independent variables, and the coordinates (x,z) as the <b>dependent</b> <b>variables,</b> with x and z being the horizontal and vertical coordinates respectively. This has the advantage that the free surface, in a frame of reference in which the wave is steady (i.e. moving with the phase velocity), corresponds with a line on which the stream function is a constant. Then the free surface location is known beforehand, and not an unknown part of the solution. The disadvantage is that the radius of convergence of the rephrased series expansion reduces.|$|E
25|$|Objectification theory {{suggests}} both {{direct and indirect}} consequences of objectification to women. Indirect consequences include self consciousness in terms that a woman is consistently checking or rearranging her clothes or appearance to ensure that she is presentable. More direct consequences are related to sexual victimization. Rape and sexual harassment are examples of this. Doob (2012) states that sexual harassment {{is one of the}} challenges faced by women in workplace. This may constitute sexual jokes or comments, most of which are degrading. Research indicates that objectification theory is valuable to understanding how repeated visual images in the media are socialized and translated into mental health problems, including psychological consequences on the individual and societal level. These include increased self-consciousness, increased body anxiety, heightened mental health threats (depression, anorexia nervosa, bulimia, and sexual dysfunction), and increased body shame. Therefore, the theory has been used to explore an array of <b>dependent</b> <b>variables</b> including disordered eating, mental health, depression, motor performance, body image, idealized body type, stereotype formation, sexual perception and sexual typing. Body shame is a byproduct of the concept of an idealized body type adopted by most Western cultures that depicts a thin, model-type figure. Thus, women will engage in actions meant to change their body such as dieting, exercise, eating disorders, cosmetic surgery, etc. Effects of objectification theory are identified on both the individual and societal levels.|$|E
500|$|Derivatives may be {{generalized}} to functions of several real variables. In this generalization, the derivative is reinterpreted as a linear transformation whose graph is (after an appropriate translation) the best linear approximation to the graph of the original function. The Jacobian matrix is the matrix that represents this linear transformation {{with respect to the}} basis given by the choice of independent and <b>dependent</b> <b>variables.</b> [...] It can be calculated in terms of the partial derivatives with respect to the independent variables. [...] For a real-valued function of several variables, the Jacobian matrix reduces to the gradient vector.|$|E
50|$|As {{mentioned}} above, Sobel’s test {{is performed}} {{to determine if}} the relationship between the independent <b>variable</b> and <b>dependent</b> <b>variable</b> has been significantly reduced after inclusion of the mediator variable. In other words, this test assesses whether a mediation effect is significant. It examines the relationship between the independent <b>variable</b> and the <b>dependent</b> <b>variable</b> compared to the relationship between the independent <b>variable</b> and <b>dependent</b> <b>variable</b> including the mediation factor.|$|R
40|$|Many {{statistical}} tests rely on {{the assumption}} that the residuals of a model are normally distributed. Rank-based inverse normal transformation (INT) of the <b>dependent</b> <b>variable</b> is one of the most popular approaches to satisfy the normality assumption. Studies regularly adjust for covariates and then normalize the residuals. This study investigated the effect of regressing covariates against the <b>dependent</b> <b>variable</b> and then applying rank-based INT to the residuals. The correlation between the <b>dependent</b> <b>variable</b> and covariates at each stage of processing was assessed. An alternative approach was tested of applying rank-based INT to the <b>dependent</b> <b>variable</b> before regressing covariates was tested. Analyses based on both simulated and real data examples demonstrated that applying rank-based INT to the <b>dependent</b> <b>variable</b> residuals after regressing out covariates re-introduces a linear correlation between the <b>dependent</b> <b>variable</b> and covariates in almost all situations. This will increase type- 1 errors and reduce power. Our proposed alternative approach, where rank-based INT was applied prior to controlling for covariate effects, gave residuals that were normally distributed and linearly uncorrelated with covariates. This approach is therefore recommended...|$|R
50|$|In statistics, {{regression}} analysis is a statistical process for estimating {{the relationships among}} variables. It includes many techniques for modeling and analyzing several variables, when {{the focus is on}} the relationship between a <b>dependent</b> <b>variable</b> and one or more independent variables. More specifically, {{regression analysis}} helps one understand how the typical value of the <b>dependent</b> <b>variable</b> (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed. Most commonly, regression analysis estimates the conditional expectation of the <b>dependent</b> <b>variable</b> given the independent variables - that is, the average value of the <b>dependent</b> <b>variable</b> when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the <b>dependent</b> <b>variable</b> given the independent variables. In all cases, the estimation target is a function of the independent variables called the regression function. In regression analysis, it is also of interest to characterize the variation of the <b>dependent</b> <b>variable</b> around the regression function which can be described by a probability distribution.|$|R
500|$|The {{vertical}} coordinate {{is handled}} in various ways. Lewis Fry Richardson's 1922 model used geometric height (...) as the vertical coordinate. Later models substituted the geometric [...] coordinate with a pressure coordinate system, {{in which the}} geopotential heights of constant-pressure surfaces become <b>dependent</b> <b>variables,</b> greatly simplifying the primitive equations. [...] This correlation between coordinate systems can be made since pressure decreases with height through the Earth's atmosphere. The first model used for operational forecasts, the single-layer barotropic model, used a single pressure coordinate at the 500-millibar (about [...] ) level, and thus was essentially two-dimensional. High-resolution models—also called mesoscale models—such as the Weather Research and Forecasting model tend to use normalized pressure coordinates referred to as sigma coordinates. [...] This coordinate system receives {{its name from the}} independent variable [...] used to scale atmospheric pressures with respect to the pressure at the surface, and in some cases also with the pressure {{at the top of the}} domain.|$|E
2500|$|... {{showing how}} the {{variance}} at the ith point {{is determined by}} the variances of both independent and <b>dependent</b> <b>variables</b> and by the model being used to fit the data. The expression may be generalized by noting that the parameter [...] is the slope of the line.|$|E
2500|$|A {{data point}} may consist {{of more than}} one {{independent}} variable. For example, when fitting a plane to a set of height measurements, the plane is a function of two independent variables, x and z, say. In the most general case there may be one or more independent variables and one or more <b>dependent</b> <b>variables</b> at each data point.|$|E
50|$|Optimal {{discriminant}} analysis may {{be thought of}} as a generalization of Fisher's linear {{discriminant analysis}}. Optimal discriminant analysis is an alternative to ANOVA (analysis of variance) and regression analysis, which attempt to express one <b>dependent</b> <b>variable</b> as a linear combination of other features or measurements. However, ANOVA and regression analysis give a <b>dependent</b> <b>variable</b> that is a numerical variable, while optimal discriminant analysis gives a <b>dependent</b> <b>variable</b> that is a class variable.|$|R
5000|$|In {{mathematical}} modeling, the <b>dependent</b> <b>variable</b> is {{studied to}} see if {{and how much it}} varies as the independent variables vary. In the simple stochastic linear model [...] the term [...] is the i th value of the <b>dependent</b> <b>variable</b> and [...] is i th value of the independent variable. The term [...] is known as the [...] "error" [...] and contains the variability of the <b>dependent</b> <b>variable</b> not explained by the independent variable.|$|R
50|$|In the Arellano-Bond method, first {{difference}} {{of the regression}} equation are taken to eliminate the fixed effects. Then, deeper lags of the <b>dependent</b> <b>variable</b> are used as instruments for differenced lags of the <b>dependent</b> <b>variable</b> (which are endogenous).|$|R
