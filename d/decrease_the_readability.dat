12|10000|Public
5000|$|Requiring the human-readable {{part of the}} tracing data to be {{separated}} from the code can <b>decrease</b> <b>the</b> <b>readability</b> of the code.|$|E
50|$|After 1973 {{the format}} changed to three letters {{followed}} by three digits. The typeface was custom made to increase readability, and the plates {{were made in}} embossed sheet steel. In January 1984 the plates were changed to plastic with reflective tape on them, still embossed. This caused problems since the tape would wear off and <b>decrease</b> <b>the</b> <b>readability</b> of the plate. In January 1994 a new plate was introduced that was made from a solid piece of plastic, with a customised Helvetica typeface. The issue of these plates was halted quickly when Photoblocker spray paint became popular and on 1 January 2002 they were replaced with embossed aluminium plates clad in 3M reflective film.|$|E
40|$|This {{technical}} report is the {{documentation of the}} work I did during my 6 months visit from August 1, 1994 to February 1995 at the GRASP Laboratory, University of Pennsylvania, Philadelphia, USA. This report has evolved from being working notes into what is presented here. I hope that this does not <b>decrease</b> <b>the</b> <b>readability</b> of the repor...|$|E
40|$|International audienceDesigning and {{maintaining}} a huge class model {{is a very complex}} task. When an object oriented software or model grows, duplicated elements start to appear, <b>decreasing</b> <b>the</b> <b>readability</b> and <b>the</b> maintainability. In this paper, we present an approach, implemented in a tool and validated by a case study, that helps software architects designing and improving their class models, discarding redundancy and adding relevant abstractions. Since many different languages allow to express class models, this approach has been made generic i. e. capable of dealing with any language described by a meta-model...|$|R
40|$|Designing and {{maintaining}} a huge class model {{is a very complex}} task. When an object oriented software or model becomes bigger and bigger, duplicated elements start to ap-pear, <b>decreasing</b> <b>the</b> <b>readability</b> and <b>the</b> maintainability of the software. In this paper, we present an approach, imple-mented in a tool and validated by a case study, that helps software architects designing and improving their class models. Since many different languages (UML, EMOF, Java, [...] .) allow to express class models, this approach has been made generic i. e. capable of dealing with any lan-guage described by a meta-model. Using this approach, software architects will be able to design and maintain more efficiently their class models. 1...|$|R
5000|$|As you can see, this <b>decreases</b> <b>the</b> code <b>readability</b> by {{rendering}} Objective-C parameter naming useless. So, {{there is}} another convenient way to write the method calls — the [...] method, which accepts Ruby symbols as parameter names. For example, the previous code can also be written as: ...|$|R
40|$|Right Angle Crossing (RAC) {{drawings}} are polyline drawings {{where each}} crossing forms four right angles. RAC drawings {{have been introduced}} because cognitive experiments provided evidence that {{increasing the number of}} crossings does not <b>decrease</b> <b>the</b> <b>readability</b> of the drawing if the edges cross at right angles. We investigate to what extent RAC drawings can help in overcoming the limitations o...|$|E
40|$|Software debugging, {{maintenance}} and reuse {{have to deal}} with many problems from Fortran scientific codes that do not fully respect the standard specification. Our study on Linpack, PerfectClub and SPEC 95 benchmarks and several industrial software reveals a large number of unprecise variable declarations that prevent program analysis, verification and parallelization. Furthermore, they <b>decrease</b> <b>the</b> <b>readability</b> of programs and make reverse-engineering more difficult. This pape...|$|E
40|$|Interaction {{diagrams}} like Message Sequence Charts and the Sequence Diagrams of UML {{can be used}} {{to describe}} a set of possible interaction sequences which are all correct system behaviour. These so-called generative diagrams make use of complex graphical elements in order to specify iteration or choice. However, heavy use of these elements can lead to overcharging and, therefore, may <b>decrease</b> <b>the</b> <b>readability</b> of diagrams. Moreover, many specication tools do not support the complex graphical elements. Therefore, we introduce a small language for textual annotations which {{can be used to}} specify the more involved elements of generative interaction diagrams. This language has been successfully applied in an industrial project. ...|$|E
30|$|In {{the three}} scans in Fig. 5 a {{transition}} from a superficial picture to a more in-depth picture is visible. The calcium map shows only the front side of the fragment, because the fluorescence lines of calcium are relatively weak [3.691 keV (K_ 1) and 4.012 keV (K_ 1)]. This means that the fluorescence of calcium in depth is too weak to penetrate the surrounding parchment. Iron fluorescence, however, has higher energy [6.403 keV (K_ 1) and 7.057 keV (K_ 1)] and therefore is able to penetrate more layers of parchment. This results in overlap of text from the front and the backside (recto and verso) of <b>the</b> fragment, which <b>decreases</b> <b>the</b> <b>readability</b> of <b>the</b> text. In theory the backside of the fragment could be retrieved {{by a series of}} steps including the creation of a binary mask and subtraction. This problem has been encountered before and image processing techniques such as the pseudo-color technique were employed to enhance readability, but this is outside {{the scope of this article}} [15]. Even more penetrating than iron is the much heavier mercury [9.987 keV (L_ 1) and 11.823 keV (L_ 1)]. This is the reason why the mercury distribution map reveals more layers that are hidden inside this book cover. Multiple paragraph marks are visible that seem randomly distributed across the fragment, because they correspond to different layers. We also see some words that are rotated 90 ° relative to the word “decollatio”. In short, looking at fluorescence lines with increasing energy provides us with an in-depth profile of the fragment.|$|R
40|$|This paper {{introduces}} {{research that}} evolved {{out of an}} analysis of Gillan, Wickens, Hollands, & Carswell’s (1998) guidelines for the graphical presentation of quantitative data in HFES publications. The impetus for this research stemmed from a concern about substandard illustrations accompanying publications and the difficulty in communicating how {{to improve the quality}} of those illustrations. The aim in this paper is twofold: (1) to offer a pragmatic method for operationalizing and measuring the adherence of a specific graphic to the aforementioned guidelines; and (2) to present the analysis of preliminary data gathered using the metric developed. I will first present the methodology used to develop a Web-based rating interface, then examine the implementation of that interface, and finally discuss the results of a comparative analysis performed on samples of graphics published before and after the original guidelines. Counterintuitively, the only evidence we found of a change between graphs published before the guidelines and those published after was a <b>decrease</b> in <b>the</b> <b>readability</b> of text...|$|R
40|$|In the {{construction}} industry, {{one of the}} aspects that affect the productivity of {{the construction}} crew is the availability of tools and supplies. Unavailability of tools and supplies results in a delay of the project, which in turn increases {{the cost of the}} project. If any such delays on job sites could be reduced, it would help the construction industry in reduction of time and cost losses. The construction industry is in need of a technology that would improve the presentday tool management system (TMS) to reduce the construction costs from delays in projects. Radio Frequency Identification (RFID) technology offers the possibility that tools and supplies, tagged with RFID devices, could be tracked down automatically. Although the potential of RFID is real, it does have limitations like any other technology. Without understanding and working with the limitations of RFID, this technology may disappoint many before its true and significant capabilities are realized. Before the technology is executed fullfledged, it needs to be tested for reliability on construction sites in particular. Researchers, from many parts of the world, have performed tests to understand the reliability of the RFID technology considering variables like metal interferences, reading range, multiple tag identification, etc. But these tests conducted could not discuss all the factors that may affect the reliability of the technology. This paper identifies other factors that might affect the reliability of RFID technology and tests are conducted to understand the influence of these factors on <b>the</b> <b>readability</b> of <b>the</b> RFID tags. Number of tools and the velocity with which tools are taken across the portal are two variables that are tested for reliability of RFID. Tests are conducted using the experiment setup that resembles a construction site tool management room entrance/exit. Results show a radical <b>decrease</b> in <b>the</b> <b>readability</b> of tags, while the numbers of the tools are increased gradually. And also, when the tools were taken across the RFID portal with gradual increasing velocity, <b>the</b> <b>readability</b> reduced. These results prove that both the tested parameters {{have an effect on the}} reliability of RFID technology for tool tracking...|$|R
40|$|This {{technical}} report is the {{documentation of the}} work I did during my 6 months visit from August 1 st 1994 to February 1 st 1995 at the GRASP Laboratory, University of Pennsylvania, Philadelphia, USA. The report has evolved from being working notes into what is presented here. I hope that this does not <b>decrease</b> <b>the</b> <b>readability</b> of the report. I {{would like to thank}} Dr. M. Mintz, Dr. R. Bajcsy, and Dr. H. I. Christensen for their valuable discussions and R. Mandelbaum for providing much of the sonar sensing stuff. Of course any shortcomings are mine and not theirs. Steen Kristensen Aalborg, March 1995 i Contents 1 Introduction 1 2 Bayesian Decision Analysis...|$|E
40|$|Abstract—The micro-Doppler {{effect is}} caused by fast moving reflectors. This effect may {{significantly}} <b>decrease</b> <b>the</b> <b>readability</b> of the ISAR/SAR images. An L-statistics based method for micro-Doppler effects removal is proposed in this paper. The L-statistics approach is performed on the spectrogram, while the rigid body signal synthesis {{is done in the}} complex time-frequency domain. The proposed method is very simple to use and produces better results than the other time-frequency based approaches. In addition to being capable of separating the rigid body and the micro-Doppler parts, this approach is robust to the noise influence. It may also separate close rigid body points, which are not separated in the original radar image. In the numerical implementation of this approach for the radar imaging, the computational efficiency is further improved by using two thresholds. The first threshold determines whether there is a target signal in a range cell, while the second threshold determines whether there are micro-Doppler effects in this range cell. These thresholds could significantly decrease the computation time in real-time applications. Theory is illustrated by examples. Index Terms—Radar imaging, ISAR/SAR, micro-Doppler, L-statistics, time-frequency analysis, short-time Fourier trans-form. I...|$|E
40|$|ABSTRACT Software debugging, {{maintenance}} and reuse {{have to deal}} with many problems from Fortran scientific codes that do not fully respect the standard specification. Our study on Linpack, PerfectClub and SPEC 95 benchmarks and several industrial software reveals a large number of unprecise variable declarations that prevent program analysis, verification and parallelization. Furthermore, they <b>decrease</b> <b>the</b> <b>readability</b> of programs and make reverse-engineering more difficult. This paper presents two different methods to compute the exact size of arrays in Fortran codes that have pointer-type REAL A(1) or assumed-size REAL A(*) declarations. The first method uses the relationship between actual and formal arguments from parameter-passing rules. New array declarations in the called procedure are computed with respect to the declarations in the calling procedures. The second approach is based on an array region analysis that gives information about the set of array elements accessed during the execution of code. This approach to array resizing could be applied to other languages without array declaration such as MATLAB and APL {{in order to reduce the}} execution overhead of dynamic test and resizing. Our two approaches are combined to yield very good results for Linpack, PerfectClub and SPEC 95 benchmarks...|$|E
40|$|Reading {{comprehension}} in {{pupils in}} Years Four and Five {{was investigated in}} a series of experiments predominantly using error detection in short, narrative passages. The claim that readers of this age may exclusively accept decodability as sufficient to judge text as non-problematic was investigated. Little evidence was found in support of this claim. However evidence was obtained that consonant strings were more often detected than nonsense words and more nonsense words were detected than real words of inappropriate meaning when they were substituted into the same passages at the same points. Fewer real words of inappropriate meaning were detected when they were the same part of speech as the word they replaced than when they were a different part of speech. No evidence was obtained that significant numbers of children exclusively detected only nonsense words. However <b>decreasing</b> <b>the</b> <b>readability</b> of <b>the</b> passages significantly reduced the detection rate for real words of inappropriate meaning while the detection rate for consonant strings and nonsense words remained both higher and more stable. It was suggested that children who are asked to read passages of too low a readability for them {{may be more likely to}} exclusively employ a lexical standard of comprehension. No evidence was obtained that asking children to read or listen to a passage a second time before completing an error detection task improved their performance. Moreover no difference in semantic comprehension monitoring was found to be dependent on whether the material was presented orally or visually. Better comprehenders were better than less good comprehenders on both error detection and doze tasks. However there was no difference in the relationship between performance on prompted e. g. doze, as compared to unprompted e. g. error detection, comprehension tasks between better and less good comprehenders. Both groups performed better on the prompted comprehension tasks. Better performance was maintained on doze tasks even when the subjects were not only alerted to having to read the passage for meaning but knew they were to be asked questions on it. The extensive use of unprompted comprehension tasks with feedback was proposed as a method of closing the gap between students' performance on unprompted as contrasted with prompted measures of comprehension. Better comprehenders were better at sequencing sentences to make a story but did not perform better than less good comprehenders at recognising sentences from stories they had just read. Both better and less good comprehenders were less good at rejecting as having just been read sentences semantically congruent with the stories as contrasted with sentences semantically incongruent with the stories. This was consistent with most readers engaging in constructive processing of short stories. The results of this series of experiments were compatible with and discussed in terms of comprehension involving the construction of a mental model of what is heard or read while listening to or reading short stories. Suggestions for further experiments were made...|$|R
40|$|Summary: Written patient {{education}} {{materials are}} an important part of ambulatory pediatric practices. We evaluated <b>the</b> <b>readability</b> of 33 representative pediatric education materials using three common formulas: Fog, Fry, and SMOG. The majority of pamphlets had readabilities of grade nine or above. The need to use multiple readability formulas was also demonstrated. Although <b>the</b> three <b>readability</b> formulas were highly correlated, they were significantly different from each other when using a repeated measures analysis of variance (ANOVA) design. In almost half, <b>the</b> <b>readability</b> estimates differed by at least two grade levels. In addition, a large intrapamphlet variability for some pamphlets suggests a need to focus more attention on <b>the</b> <b>readability</b> of multiple sections within a pamphlet, not only on the overall or average readability. We conclude that <b>the</b> <b>readability</b> levels of patient education materials continue to be too high...|$|R
40|$|Includes bibliographical {{references}} (pages 40 - 48) This study evaluates <b>the</b> <b>readability</b> {{levels of}} frequently used literacy materials, specifically the power builder {{component of the}} SRA Reading Laboratory IIIB. A review of <b>the</b> <b>readability</b> literature reveals numerous studies performed on content area textbooks but relatively few studies performed on literacy materials. Three questions are asked: a) What is <b>the</b> Dale-Chall <b>readability</b> level of each power builder; b) What is <b>the</b> average Dale-Chall <b>readability</b> level of each color level; and c) Do <b>the</b> Dale-Chall <b>readability</b> levels for each color level correspond to <b>the</b> <b>readability</b> levels asserted by the publisher? A computer analysis of the power builders indicates that a) readability scores for individual power builders range from grade 4. 0 to grade 14. 0; b) <b>the</b> average <b>readability</b> score for each level ranges from grade 5. 8 to grade 12. 2; and c) <b>the</b> average Dale-Chall <b>readability</b> score for all levels is. 2 to 1. 4 years higher than the publisher-determined grade level. Recommendations are made for application of the research findings and the revision of the Dale-Chall formula...|$|R
40|$|Right Angle Crossing (RAC) {{drawings}} are polyline drawings {{where each}} crossing forms four right angles. RAC drawings {{have been introduced}} because cognitive experiments provided evidence that {{increasing the number of}} crossings does not <b>decrease</b> <b>the</b> <b>readability</b> of the drawing if the edges cross at right angles. We investigate to what extent RAC drawings can help in overcoming the limitations of widely adopted planar graph drawing conventions, providing both positive and negative results. First, we prove that there exist acyclic planar digraphs not admitting any straight-line upward RAC drawing and that the corresponding decision problem is NP-hard. Also, we show digraphs whose straightline upward RAC drawings require exponential area. Second, we study if RAC drawings allow us to draw bounded-degree graphs with lower curve complexity than the one required by more constrained drawing conventions. We prove that every graph with vertex-degree at most 6 (at most 3) admits a RAC drawing with curve complexity 2 (resp. 1) and with quadratic area. Third, we consider a natural non-planar generalization of planar embedded graphs. Here we give bounds for curve complexity and area different from the ones known for planar embeddings. ...|$|E
40|$|Right Angle Crossing (RAC) {{drawings}} are polyline drawings {{where each}} crossing forms four right angles. RAC drawings {{have been introduced}} because cognitive experiments provided evidence that {{increasing the number of}} crossings does not <b>decrease</b> <b>the</b> <b>readability</b> of a drawing if edges cross at right angles. We investigate to what extent RAC drawings can help in overcoming the limitations of widely adopted planar graph drawing conventions, providing both positive and negative results. First, we prove that there exist acyclic planar digraphs not admitting any straight-line upward RAC drawing and that the corresponding decision problem is NP-hard. Also, we show digraphs whose straight-line upward RAC drawings require exponential area. Exploiting the techniques introduced for studying straight-line upward RAC drawings, we also show that there exist planar undirected graphs requiring quadratic area in any straight-line RAC drawing. Second, we study whether RAC drawings allow us to draw boundeddegree graphs with lower curve complexity than the one required by more constrained drawing conventions. We prove that every graph with vertexdegree at most six (at most three) admits a RAC drawing with curve complexity two (resp. one) and with quadratic area. Third, we consider a natural non-planar generalization of planar embedded graphs. Here we give bounds for curve complexity and area different from the ones known for planar embeddings...|$|E
40|$|Among {{the most}} widely used data {{structures}} to represent pairwise relationships between entities, graphs play a key role. Graph applications can, indeed, be found in every field, ranging from maps to circuits, and from networks to interpersonal relationships. Visualizing a graph {{is probably one of the}} most expressive ways to describe the information encoded in it. Such an issue is addressed in the research field of Graph Drawing, which inherits techniques from the areas of Graph Theory, Graph Algorithms, and Computational Geometry. Namely, in a drawing of a graph each entity -called vertex - is usually represented by a point in the plane and each relationship -called edge- between two entities as a curve connecting the corresponding points. Clearly, not every drawing can be considered a good representation of the graph. Vertices and edges should be drawn in such a way that the human eye is facilitated in identifying the relationships among the entities at a glance. Namely, the drawing should be readable. During the years, some topological and geometric features that a drawing should satisfy in order to be easily readable have been recognized and formally characterized. The main goals of Graph Drawings are, then, creating algorithms that automatically produce drawings respecting such criteria and, possibly, defining new ones. Planarity, that is the absence of partial or total overlapping among vertices and edges, is proba- bly the most natural and desirable characteristic a drawing can have, as it allows a viewer to easily distinguish the curve used to represent any edge-relationship and hence to immediately recognize which entities-vertices participate in that relationship. Unfortunately, due to their topological structure, not all the graphs admit a planar drawing. In such cases, a natural requirement for the drawing is that of containing as few crossings as possible. Moreover, especially if the input graph -and hence the area of the drawing- is large, it is convenient that the points where two edges cross are easily distinguishable from the points where vertices are placed. Observe that, while planarity is a property that a drawing may ful ll or not, the area and the number of crossings are two examples of measure of quality that can be used to compare two drawings of the same graph. From the geometric point of view, it would be preferable that edges are drawn as straight- lines. Edges that bend and repeatedly or abruptly change direction might sensibly <b>decrease</b> <b>the</b> <b>readability</b> of the drawing. In straight-line drawings, however, the information of interest for a user might not be sufficiently emphasized. In that case, edges can be represented as poly-lines bending only a limited number of times or having a limited number of slopes, so that the negative impact on the readability of the drawing is limited. Other required features for a drawing of a graph to describe some meta-information, we recall the representation of groups (called clusters) of vertices that, aside from the relationship described by the edges, represent objects that share some properties, as in the case of clustered graphs. Also, in some contexts it might be required to emphasize the chains of relationships that indirectly involve pairs of entities. In this case, the placement of the vertices and the fashion in which edges are drawn should be able to " the eye of a viewer from an object to another through the chain of relationships that are of interest. Of course, some of such desired features can be in contrast with each other and hence cannot be simultaneously satisfied by a single drawing. It is easy to imagine contexts in which several drawings of the same graph, which can be substantially different from each other, are of interest to the same observer. Due to the great difference between two drawings, a considerable effort might be required to the user, while switching from one drawing to another, in " the mental map he or she has of the graph. In order to support the user in this operation, a smooth transformation of a drawing into another might be desirable. Clearly, since the purpose of this transformation is to support the user in changing the focus from a drawing to another, it should introduce as few distracting elements, e. g. crossings, bends in the edges, or non-linear trajectories, as possible. In this thesis we mainly deal with algorithms that compute planar linear morphs, i. e., trans- formations, of planar drawings of the same graph in which planarity is preserved at any time and vertices move at uniform speed along straight-line trajectories. We also consider the problem of constructing drawings that, at the same time, emphasize certain properties of a given graph and require small area. We mainly deal with planar embedded graphs, namely, graphs in which the circular order of the edges around each vertex is xed and such that there exists a planar drawing of the graph in which such an order is maintained. In Part I we present an algorithm for the construction of planar linear morphs of series-parallel graphs with a number of moves that is linear in the size of the graph, prove that such an algorithm is asymptotically optimal by providing a lower bound on the number of linear moves that are required to transform a planar drawing of a plane graph, and give an algorithm for constructing planar linear morphs of general plane graphs with a number of moves that is quadratic in the size of the graph. In Part II we consider the problem of computing drawings of graphs in which some features, namely chains of relationships between pairs of vertices and the difference between vertices and crossings in drawings of non-planar graphs, are emphasized, thus allowing the user to easily " the underlying graph...|$|E
50|$|Indentation is optional, but {{it helps}} improve <b>the</b> <b>readability.</b>|$|R
5000|$|The {{following}} changes greatly improve <b>the</b> <b>readability</b> of regexes: ...|$|R
40|$|Orthopaedic Surgeons (AAOS) is to {{disseminate}} patient education materials that suit <b>the</b> <b>readability</b> skills of <b>the</b> patient population. According to standard guidelines from healthcare organizations, <b>the</b> <b>readability</b> of patient educa-tion materials {{should be no}} higher than the sixth-grade level. We hypothesized <b>the</b> <b>readability</b> level of patient education materials available on the AAOS Web site would be higher than the recommended grade level, regardless when the material was available online. Readability scores of all articles from the AAOS Internet-based patient information Web site, ‘‘Your Orthopaedic Connection,’’ were determined using the Flesch-Kincaid grade formula. The mean Flesch-Kincaid grade level of the 426 unique articles was 10. 43. Only 10 (2 %) of the articles had <b>the</b> recommended <b>readability</b> level of sixth grade or lower. <b>The</b> <b>readability</b> of <b>the</b> articles did not change with time. Our findings suggest {{the majority of the}} patient education materials available on the AAOS Web site had readability scores that may be too difficult for comprehension by {{a substantial portion of the}} patient population...|$|R
40|$|Nowadays, {{information}} is primarily searched on the WWW. From a user perspective, <b>the</b> <b>readability</b> {{is an important}} criterion for measuring the accessibility and thereby the quality of an information. We show that modern content extraction algorithms help to estimate <b>the</b> <b>readability</b> of a web document quite accurate. Categories and Subject Descriptor...|$|R
40|$|AbstractThis paper {{presents}} {{a project that}} explores the possibility of assessing <b>the</b> <b>readability</b> level of Arabic medicine information leaflets using machine learning techniques. There {{are a number of}} popular readability formulas and tools that have been successfully used to assess <b>the</b> <b>readability</b> of health-related information in several languages. However, there is limited work on <b>the</b> <b>readability</b> assessment of health-related information, specifically medicine information leaflets in Arabic. We describe the design of a tool that uses machine learning to assess <b>the</b> <b>readability</b> of medicine information leaflets. We utilize a corpus comprising 1112 medicine information leaflets annotated with three difficulty levels. Based on a study of existing literature, we selected a number of features influencing text difficulty. The tool will help specialized organizations in medicine information leaflets production to produce the leaflets at appropriate level of reading for the majority of leaflets consumers...|$|R
40|$|Abstract Background State governments provide {{preprinted}} advance directive {{forms to}} the general public. However, many adults in the United States (US) lack {{the skills necessary to}} read and comprehend health care-related materials. In this study, we sought to determine <b>the</b> <b>readability</b> of state government-sponsored advance directive forms. Methods A cross sectional study design was used. <b>The</b> <b>readability</b> of advance directive forms available online from all 50 US states and the District of Columbia was determined using 6 validated readability scales. Results Overall, 62 advance directive forms were obtained. For 47 states, forms were available by way of government-sponsored Web sites. <b>The</b> average (SD) <b>readability</b> (with <b>the</b> Flesch-Kincaid score) of all forms was grade level 11. 9 (2. 6). Similar results were obtained with <b>the</b> other <b>readability</b> scales. No form had a <b>readability</b> score at <b>the</b> 5 th grade level or lower, the level recommended by the National Work Group on Literacy and Health. <b>The</b> <b>readability</b> of <b>the</b> forms exceeded this level by an average of 6. 9 grade levels (95 % confidence interval, 6. 3 - 7. 6; P P Conclusions <b>The</b> <b>readability</b> of US state government-sponsored advance directive forms exceeds <b>the</b> <b>readability</b> level recommended by the National Work Group on Literacy and Health and the average reading skill level of most US adults. Such forms may inhibit advance care planning and therefore patient autonomy. </p...|$|R
40|$|Dr. Cindy Hendricks, Advisor Many U. S. history {{teachers}} use textbooks {{as the primary}} reading in their classrooms. Generally, the textbooks are written at a higher <b>readability</b> level than <b>the</b> grade level for which the text is intended. Also, the reliability of <b>the</b> <b>readability</b> levels published by textbook companies should be questioned. This investigation sought to explore <b>the</b> <b>readability</b> of textbooks for use in U. S. history classes. The research question in this study was: What is the variability of <b>the</b> three different <b>readability</b> formulas on selected U. S. history textbooks? In <b>the</b> study, three <b>readability</b> formulas were analyzed: the Flesch-Kincaid, Gunning (FOG), and Fry Graph. Three U. S. history textbooks previously used in classrooms were chosen for the study. Descriptive statistics {{were used to determine}} the variance amongst the results. The results show there was a great amount of variance amongst <b>the</b> <b>readability</b> formulas regarding U. S. history textbooks. Teachers {{should be aware of the}} variability amongst the formulas and question <b>the</b> <b>readability</b> level provided by the publishers. i...|$|R
40|$|One of {{the goals}} of the American Academy of Orthopaedic Surgeons (AAOS) is to {{disseminate}} patient education materials that suit <b>the</b> <b>readability</b> skills of <b>the</b> patient population. According to standard guidelines from healthcare organizations, <b>the</b> <b>readability</b> of patient education materials should be no higher than the sixth-grade level. We hypothesized <b>the</b> <b>readability</b> level of patient education materials available on the AAOS Web site would be higher than the recommended grade level, regardless when the material was available online. Readability scores of all articles from the AAOS Internet-based patient information Web site, “Your Orthopaedic Connection,” were determined using the Flesch-Kincaid grade formula. The mean Flesch-Kincaid grade level of the 426 unique articles was 10. 43. Only 10 (2 %) of the articles had <b>the</b> recommended <b>readability</b> level of sixth grade or lower. <b>The</b> <b>readability</b> of <b>the</b> articles did not change with time. Our findings suggest the majority of the patient education materials available on the AAOS Web site had readability scores that may be too difficult for comprehension by {{a substantial portion of the}} patient population...|$|R
5000|$|To improve <b>the</b> <b>readability</b> of {{object-oriented}} code {{by giving}} system behavior first-class status; ...|$|R
40|$|Software metrics gives {{developers}} and their client and users of Software {{information about the}} quality of their Software products. They are employed in taking decisions at various levels of Software Life Cycle (SLC). This paper presents a novel metric for measuring <b>the</b> <b>readability</b> of Software Source Code (SC). Maintenance changes (addition, removal or modification), though, are initially carried out on the Software design artifacts, they are eventually performed on the Software SC as the finished product. Thus this metric is relevant in estimating <b>the</b> <b>readability</b> quality of SCs. The metric is ratio scaled and size independent. Results showed that the metric objectively measures <b>the</b> <b>readability</b> of SC. to alleviate such impacts...|$|R
40|$|Master of EducationThe present {{submission}} {{consists of}} three papers. The first paper is a review of theory and research in <b>the</b> field of <b>readability.</b> <b>The</b> emphasis is upon approaches to <b>the</b> measurement of <b>readability,</b> and <b>the</b> theoretical bases of such approaches. Two broad types of approach are considered: analytic or formula approaches, and synthetic approaches. The second paper {{is concerned with the}} reliability and validity of <b>the</b> <b>Readability</b> Reference Scale (developed by Anderson). This paper reports research which focusses upon <b>the</b> <b>Readability</b> Reference Scale in comparison with formula approaches. The third paper, also a research report, describes research which seeks to assess the applicability of the Rasch model (a probabilistic model for item analysis) to <b>the</b> measurement of <b>readability.</b> Restricted Access: Metadata Onl...|$|R
40|$|Background: The {{package leaflet}} {{included}} in the packaging of all medicinal products {{plays an important role}} in the transmission of medicine-related information to patients. Therefore, in 2009, the European Commission published readability guidelines to try to ensure that the information contained in the package leaflet is understood by patients. Objective: The main objective of this study was to calculate and compare <b>the</b> <b>readability</b> levels and length (number of words) of the package leaflets for biological medicines in 2007, 2010, and 2013. Methods: Thesampleofthisstudyincluded 36 biologicalmedicinepackageleafletsthatweredownloadedfromtheEuropean Medicines Agency website in three different years: 2007, 2010, and 2013. <b>The</b> <b>readability</b> of <b>the</b> selected package leaflets was obtained using <b>the</b> following <b>readability</b> formulas: SMOG grade, Flesch-Kincaid grade level, and Szigriszt's perspicuity index. The length (number of words) of the package leaflets was also measured. Afterwards, the relationship between these quantitative variables (three readability indexes and length) and categorical (or qualitative) variables were analyzed. The categorical variables were the year when the package leaflet was downloaded, the package leaflet section, type of medicine, year of authorization of biological medicine, and marketing authorization holder. Results: <b>The</b> <b>readability</b> values of all the package leaflets exceeded the sixth-grade reading level, which is the recommended value for health-related written materials. No statistically significant differences were found between the three years of study in <b>the</b> <b>readability</b> indexes, although differences were observed in the case of the length (P=. 002), which increased over the study period. When <b>the</b> relationship between <b>readability</b> indexes and length and the other variables was analyzed, statistically significant differences were found between package leaflet sections (P<. 001) and between the groups of medicine only with regard to the length over the three studied years (P=. 002 in 2007, P=. 007 in 2010, P=. 009 in 2013). Linear correlation was observed between <b>the</b> <b>readability</b> indexes (SMOG grade and Flesch-Kincaid grade level: r 2 =. 92; SMOG grade and Szigriszt's perspicuity index: r 2 =. 81; Flesch-Kincaid grade level and Szigriszt's perspicuity index: r 2 =. 95), but not between <b>the</b> <b>readability</b> indexes and <b>the</b> length (length and SMOG grade: r 2 =. 05; length and Flesch-Kincaid grade level: r 2 =. 03; length and Szigriszt's perspicuity index: r 2 =. 02). Conclusions: There was no improvement in <b>the</b> <b>readability</b> of <b>the</b> package leaflets studied between 2007 and 2013 despite the European Commission's 2009 guideline on <b>the</b> <b>readability</b> of package leaflets. The results obtained from <b>the</b> different <b>readability</b> formulas coincided from a qualitative point of view. Efforts to improve <b>the</b> <b>readability</b> of package leaflets for biological medicines are required to promote the understandability and accessibility of this online health information by patients and thereby contribute to the appropriate use of medicines and medicine safety...|$|R
5000|$|... 1944. Criteria for {{determining}} <b>the</b> <b>readability</b> of typefaces. Journal of Educational Psychology, Vol. 35.|$|R
40|$|This report {{describes}} {{a number of}} tests of <b>the</b> <b>readability</b> of {{variable message traffic sign}}s that were carried out in a period from the spring of 2008 until the autumn of 2009. An even earlier test is not mentioned. A variable message traffic sign is called VMS in the following. The tests are described approximately in the sequence they were carried out. To some degree the sequence {{describes a}} "learning by doing" process in which later tests were based on earlier tests. All the tests involve presentation of a number of prearranged messages on a VMS, representing variation of some parameters supposedly related to <b>the</b> <b>readability</b> of <b>the</b> messages, to a group of test persons. In the early tests, the criterion for <b>the</b> <b>readability</b> was <b>the</b> reading distance of each of the messages for each of the test persons. In the later tests the criterion was rating of <b>the</b> <b>readability</b> at predetermined distances...|$|R
40|$|The {{purpose of}} the study are to find out <b>the</b> <b>readability</b> level of 14 reading texts from Life: Elementary, <b>the</b> <b>readability</b> level of 6 reading texts from Issues for Today and to see whether <b>the</b> <b>readability</b> level of <b>the</b> reading texts in Life: Elementary and <b>the</b> <b>readability</b> level of <b>the</b> reading texts in Issues for Today are graded or not using Fry <b>Readability</b> Graph. <b>The</b> steps of the {{research}} are: (1) the researcher found the average number of syllables per 100 -words both from Life: Elementary reading texts and and Issues for Today reading texts which define as “x” on the graph. (2) Then, the researcher found the average number of sentences per 100 -word both from Life: Elementary reading texts and and Issues for Today reading texts which define as “y” on the graph. (3) After getting the number of the “x” and the “y”, the researcher determined <b>the</b> <b>readability</b> level from each text by marking the dot on the Fry Graph. (4) Then, the researcher put the result on the table of data analysis. In this study, the researcher uses descriptive quantitative content analysis design. The researcher collects the data based on the percentage and theme. She takes 50...|$|R
