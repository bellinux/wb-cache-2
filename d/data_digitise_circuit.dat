0|115|Public
3000|$|ISC-GEM—basic seismic {{measurement}} <b>data</b> <b>digitised</b> {{from the}} original station and network bulletins at the ISC during the ISC-GEM project (Di Giacomo et al. 2015); [...]...|$|R
40|$|The Natural History Museum, London (NHMUK) has {{embarked}} on an ambitious programme to digitise its collections. The first phase of this programme has been to undertake a series of pilot projects that will develop the necessary workflows and infrastructure development needed to support mass digitisation of very large scientific collections. This paper {{presents the results of}} one of the pilot projects – iCollections. This project digitised all the lepidopteran specimens usually considered as butterflies, 181, 545 specimens representing 89 species from the British Isles and Ireland. The <b>data</b> <b>digitised</b> includes, species name, georeferenced location, collector and collection date - the what, where, who and when of specimen data. In addition, a digital image of each specimen was taken. This paper explains the way the data were obtained and the background to the collections which made up the project. Specimen-level data associated with British and Irish butterfly specimens have not been available before and the iCollections project has released this valuable resource through the NHM data portal...|$|R
40|$|The AddressingHistory project aims {{to create}} an online tool which will enable members of the community, both within and out with academia (particularly local history groups and genealogists), to combine <b>data</b> from <b>digitised</b> {{historical}} Scottish Post Office Directories (PODs) with contemporaneous historical maps. The AddressingHistory web tool would allow individuals to plot the location on a map of any address, street name, advert, or listing from the directories onto an appropriate map...|$|R
40|$|The AddressingHistory {{project was}} funded {{as part of}} the Developing Community Content strand of the JISC Digitisation and e-Content Programme and ran from April 2010 until September 2010. The aim of the project was to create an online {{engagement}} tool built around Web 2. 0 principles and using open standards. Such a tool would enable members of the community, both within and outwith academia (particularly local history groups and genealogists), to enhance and combine <b>data</b> from <b>digitised</b> historical Scottish Post Office Directories (PODs) with contemporaneous large-scale historical maps...|$|R
40|$|An {{algorithm}} for fairing two-dimensional (2 D) shape {{formed by}} <b>digitised</b> <b>data</b> points is described. The application aims to derive a fair curve from {{a set of}} dense and error-®lled <b>data</b> points <b>digitised</b> from a complex surface, such that the basic shape information recorded in the original point data is relatively unaffected. The algorithm is an adaptive process in which each cycle consists of several steps. Given a 2 D point set, the bad points are identi®ed by analysing the property of their discrete curvatures (D-curvatures) and ®rst-order difference of Dcurvatures, in two consecutive fairing stages. The point set is then segmented into single bad point (SBP) segments and multiple bad point (MBP) segments. For each MBP segment, a specially designed energy function is used to identify the bad point to be modi®ed in the current cycle. Each segment is then faired by directly adjusting the geometric position of the worst point. The amount of adjustment in each cycle is kept less than a given shape tolerance. This algorithm is particularly effective in terms of shape preservation when dealing with MB...|$|R
40|$|Computer-based and {{electronic}} sensing technologies are opening new opportunities in insect ecology and management. This paper describes some existing and forthcoming technologies for collecting <b>data</b> (3 D <b>digitising,</b> scanning), interpreting information (scientific visualisation, virtual reality [VR]) and managing pests (Precision Pest Management [PPM]). The {{focus is on}} interactions between individual insects and plants...|$|R
40|$|This thesis aims {{to answer}} the {{question}} whether heterogeneity of agricultural landscapes affects the richness of species, and looks at community composition of butterflies inhabiting 38 insular steppe grassland reserves situated in Southern Moravia, Czech Republic, using quantitative butterfly records and <b>digitised</b> <b>data</b> on landscape composition within the reserves and in surrounding perimeters...|$|R
40|$|Thermoforming is {{commonly}} used to produce shaped plastic sheets for packaging consumer products. The conventional method of designing and making thermoforming moulds is laborious and time consuming. A method based on a reverse engineering approach and thermoforming feature concept is proposed. The method {{involves the use of}} a self-developed device to digitise the surface of a product. A CAD model that corresponds to the thermoforming mould of the product is then constructed by using the <b>digitised</b> <b>data.</b> The construction of the mould surface is based on the concept of a defined set of thermoforming mould features. A modified Laplacian smoothing technique is applied to process the <b>digitised</b> <b>data</b> for generating the thermoforming mould surfaces. Several examples are used to explain the working principle and demonstrate the viability of the proposed method. © 2006 Elsevier Ltd. All rights reserved. link_to_subscribed_fulltex...|$|R
50|$|The Estonian ID {{cards are}} used in health care, {{electronic}} banking, signing contracts, public transit, encrypting email and voting. Estonia offers over 600 e-services to citizens and 2400 to business. The card's chip stores <b>digitised</b> <b>data</b> about the authorised user, most importantly: the user's full name, gender, national identification number, and cryptographic keys and public key certificates.|$|R
40|$|The UK {{observatory}} hourly values {{published in}} yearbooks were digitised in the 1970 s, using data entry by groups of prisoners. These were {{made available for}} research purposes via the WDC for geomagnetism. It has recently been discovered [1] that the hourly values from Eskdalemuir (ESK) observatory for years 1911 to 1931 are 2 -hour running means, instead of the original hourly values published in the yearbooks (see Fig 2). Unfortunately there was no record of the original <b>digitised</b> <b>data.</b> This filtering was carried out to centre the data at 30 minutes past each hour instead of at 0 minutes, for homogeneity with the data from 1932 onwards. It {{may also have been}} the belief at the time, that the raw data from the yearbooks were spot values rather than estimated mean values, and averaging would have been appropriate. In any case the original raw <b>digitised</b> <b>data</b> should also have been stored. Following this discovery a campaign to re-digitise the ESK yearbook data began...|$|R
5000|$|NCRB {{has been}} conferred with ‘Digital India Awards 2016’ in open data {{championship}} category with Silver on 9th December, 2016 for updation {{of more than}} 3,000 datasets on Open Government Data (OGD) Platform India in open source format. NCRB has digitised ‘Crime in India’ since 1967 and Accidental Deaths & Suicides in India since 1998. The <b>digitised</b> <b>data</b> have been made available on national data portal [...]|$|R
50|$|In October 2006, Virtual Map became {{embroiled in}} a civil suit against the ex-provider, Singapore Land Authority (SLA), a {{statutory}} board under the Singapore Ministry of Law. Until July 2004, Singapore Land Authority (SLA) provided <b>digitised</b> <b>data</b> to Virtual Map non-exclusively under seven agreements that the latter has signed, and claims that the latter has infringed SLA's copyright by continually selling and redistributing its maps even after the expiration of the agreements.|$|R
50|$|At about 1000 ft {{above sea}} level, Buxton {{is the highest}} market town in England. Due to this {{relatively}} high elevation, Buxton tends to be cooler than surrounding towns, with daytime temperature typically around 2 °C lower than Manchester. A Met Office weather station has collected climate date for the town since 1908, with <b>digitised</b> <b>data</b> from 1959 available online. In June 1975, the town {{was hit by a}} freak snowstorm that stopped play during a cricket match.|$|R
25|$|The {{dialogue}} between the handset and the cell site is a stream of digital <b>data</b> that includes <b>digitised</b> audio (except for the first generation analog networks). The technology that achieves this depends on the system which the mobile phone operator has adopted. The technologies are grouped by generation. The first-generation systems started in 1979 with Japan, are all analog and include AMPS and NMT. Second-generation systems, started in 1991 in Finland, are all digital and include GSM, CDMA and TDMA.|$|R
40|$|This simple MatLab script {{will provide}} pressure, impulse, arrival time and {{duration}} predictions for a user defined explosive charge mass and stand-off. The parameter predictions for {{positive and negative}} phase are given by <b>digitised</b> <b>data</b> from UFC- 3 - 340 - 02, Structures to Resist the Effects of Accidental Explosions. The negative phase is approximated with a cubic expression from Granstrom, Loading Characteristics of Air Blasts From Detonating Charges, Technical Report 100, Transactions of the Royal Institute of Technology, Stockholm...|$|R
40|$|This {{article was}} {{published}} in the serial, Journal of Biomechanics [© Elsevier]. The definitive version is available at: [URL] paper presents a general method for synchronising <b>digitised</b> video <b>data</b> using a mathematical approach based upon the direct linear transformation reconstruction technique. The method was tested using <b>digitised</b> <b>data</b> from genlocked video recordings of gymnastic vaulting, tumbling, high bar and rings. The mean synchronisation error was less than 0. 002 s for vaulting and less than 0. 001 s for the other activities...|$|R
50|$|The {{dialogue}} between the handset and the cell site is a stream of digital <b>data</b> that includes <b>digitised</b> audio (except for the first generation analog networks). The technology that achieves this depends on the system which the mobile phone operator has adopted. The technologies are grouped by generation. The first-generation systems started in 1979 with Japan, are all analog and include AMPS and NMT. Second-generation systems, started in 1991 in Finland, are all digital and include GSM, CDMA and TDMA.|$|R
40|$|An {{up-to-date}} microprocessor controlled thermoluminescence dosemeter (TLD) {{system for}} environmental and space dose measurements has been developed. The {{earlier version of}} the portable TLD system, Pille, was successfully used on Soviet orbital stations {{as well as on}} the US Space Shuttle, and for environmental monitoring. The new portable TLD system, Pille' 95, consists of a reader and TL bulb dosemeters, and each dosemeter is provided with an EEPROM chip for automatic identification. The glow curve <b>data</b> are <b>digitised</b> and analysed by the program of the reader. The measured data and the identification number appear on the LED display of the reader. Up to several thousand measured data together with the glow curves can be stored on a removable flash memory card. The whole system is supplied either from built-in rechargeable batteries or from the mains of the space station...|$|R
40|$|Name {{variants}} which differ {{more than}} a few characters can seriously hamper record linkage. A method is described by which variants of first names and surnames can be learned automatically from records that contain more information than needed for a true link decision. Post-processing and limited manual intervention (active learning) is unavoidable, however, to differentiate errors in the original and the <b>digitised</b> <b>data</b> from variants. The method is demonstrated on the basis of an analysis of 14. 8 million records from the Dutch vital registration...|$|R
40|$|A low-latency, {{sub-micron}} resolution stripline beam {{position monitoring}} (BPM) {{system has been}} developed and tested with beam at the KEK Accelerator Test Facility (ATF 2), {{where it has been}} used to drive a beam stabilisation system. The fast analogue front-end signal processor is based on a single-stage radio-frequency down-mixer, with a measured latency of 16 ns and a demonstrated single-pass beam position resolution of below 300 nm using a beam with a bunch charge of approximately 1 nC. The BPM position <b>data</b> are <b>digitised</b> on a digital feedback board which is used to drive a pair of kickers local to the BPMs and nominally orthogonal in phase in closed-loop feedback mode, thus achieving both beam position and angle stabilisation. We report the reduction in jitter as measured at a witness stripline BPM located 30 metres downstream of the feedback system and its propagation to the ATF interaction point...|$|R
40|$|The {{majority}} of machine vision systems derive their input <b>data</b> by <b>digitising</b> an image {{to produce a}} square grid of sampled points. However, other sampling techniques can represent equal picture information in {{a smaller number of}} samples, with a consequent reduction in data rate. Several workers have looked at regular hexagonal sampling of images which produces optimum data rates for a given information content. Previous work on hexagonal sampling by the authors and others, has shown that image processing operators are computationally more efficient, and as accurate, as their square counterparts. Historically, one factor which has lead to the predominance of square sampling in vision systems, is that this produces images which are more visually pleasing to human observers. This paper describes an investigation of machine vision systems performing industrial inspection tasks, which suggests that in such applications, hexagonal systems outperform square systems. In particular hexagonal op [...] ...|$|R
40|$|Digitizing the past: {{next steps}} for public sector digitization, looks at at history of {{digitisation}} {{projects in the}} UK. It looks at the issues relating to programmes such as the Arts and Humanities Research Council Resource Enhancement Scheme, the lottery-supported New Opportunties Fund and the JISC Digitisation Programme. It reviews {{some of the reasons}} for successes and failures within these programmes, in particular looking at the greater emphasis being placed on sustainability and the need for managers of digital resources to ensure their <b>digitised</b> <b>data</b> is available from multiple locations...|$|R
40|$|LHCb {{will study}} CP {{violation}} and other rare phenomena in B-decays with a forward spectrometer at the LHC. The LHCb trigger has to efficiently select a few Hz of interesting B-decays from a non- elastic pp interaction cross-section of 80 mb, which corresponds to 16 MHz of interactions at the preferred LHCb luminosity of 2 * 10 /sup 32 / cm/sup - 2 /s/sup - 1 /. The first trigger level reduces the rate to 1 MHz using large E/sub T/ triggers. At 1 MHz all <b>data</b> is <b>digitised,</b> and {{a subset of}} tracking information is used to reduce the rate to 40 kHz, at which rate the full event building is performed. Having access to all detector information, the rate is subsequently reduced to around 200 Hz and written to storage. This paper emphasises the data available at the various trigger stages and the algorithms employed to select B-decay candidates, rather than describing {{the implementation of the}} trigger. (12 refs) ...|$|R
40|$|This paper {{describes}} {{issues and}} opportunities of the Creative Commons licence framework for digital libraries. It briefly describes how trade-oriented copyright has become problematic for digital content. The role of Creative Commons licences {{are discussed in}} respect to digital information markets, as well as problems of usage of these licences in respect to current collective rights management practices. Internal organisational structures and challenges of Creative Commons as a « Public Layer Service » are reviewed, describing the frictions and potential of global self-organising movements. Practical use of Creative Commons licences in scholarly information environments and the « Science Commons » project are examined in relation to « Open Access » principles. Finally, it is shown how the digital library infrastructure would benefit from adopting Creative Commons licences, regarding catalogue <b>data</b> and <b>digitised</b> content, arguing that library and heritage institutions should be more pro-active in defining the legal and technical frameworks on which their mission depends so heavily...|$|R
40|$|This project {{constructed}} virtual plant leaf surfaces from <b>digitised</b> <b>data</b> {{sets for}} use in droplet spray models. Digitisation techniques for obtaining data sets for cotton, chenopodium and wheat leaves are discussed and novel algorithms for {{the reconstruction of the}} leaves from these three plant species are developed. The reconstructed leaf surfaces are included into agricultural droplet spray models to investigate the effect of the nozzle and spray formulation combination on the proportion of spray retained by the plant. A numerical study of the post-impaction motion of large droplets that have formed on the leaf surface is also considered...|$|R
40|$|Diptera: types (non-De Meijere) ZMAN {{contains}} important type {{material of}} Diptera, mainly originating from the Oriental and Australasian regions. Basically the {{types in the}} Diptera collection {{can be divided into}} those of species described by J. C. H. de Meijere and those that were described by other authors. The approximately 1. 200 De Meijere species with circa 4. 000 type specimens have been inventoried and their <b>data</b> have been <b>digitised</b> and made publicly available. The non-De Meijere types count approximately 5200 specimens (of which 60 non-types). Types constitute the unique building blocks in taxonomy and knowledge of this material is essential for an adequate reconstruction of the Tree of Life...|$|R
40|$|Thirty two time {{interval}} maps have been presented, which de-pict the global plate tectonic configuration {{as well as}} palaeoge-ography and lithofacies for South-East Asia region (Fig. 1) from Cambrian to Neogene. The presented maps were primarily gene-rated as Intergraph ™ design files and CorelDraw ™ files using computer software and databases. The plate tectonic model used to create palaeocontinental base maps is based on Plates and PALEOMAP tectonic reconstruction programs. These programs take tectonic features {{in the form of}} <b>digitised</b> <b>data</b> files and as-semble those features in accordance with user specified rotation criteria. The detail information about the database, including the palaeopoles used {{can be found in the}} Plates homepage...|$|R
40|$|The use {{of digital}} {{communication}} systems is increasing very rapidly. This {{is due to}} lower system implementation cost compared to analogue transmission {{and at the same}} time, the ease with which several types of <b>data</b> sources (<b>data,</b> <b>digitised</b> speech and video, etc.) can be mixed. The emergence of packet broadcast techniques as an efficient type of multiplexing, especially with the use of contention random multiple access protocols, has led to a wide-spread application of these distributed access protocols in local area networks (LANs) and a further extension of them to radio and mobile radio communication applications. In this research, a proposal for {{a modified version of the}} distributed access contention protocol which uses the packet broadcast switching technique has been achieved. The carrier sense multiple access with collision avoidance (CSMA/CA) is found to be the most appropriate protocol which has the ability to satisfy equally the operational requirements for local area networks as well as for radio and mobile radio applications. The suggested version of the protocol is designed in a way in which all desirable features of its precedents is maintained. However, all the shortcomings are eliminated and additional features have been added to strengthen its ability to work with radio and mobile radio channels. Operational performance evaluation of the protocol has been carried out for the two types of non-persistent and slotted non-persistent, through mathematical and simulation modelling of the protocol. The results obtained from the two modelling procedures validate the accuracy of both methods, which compares favourably with its precedent protocol CSMA/CD (with collision detection). A further extension of the protocol operation has been suggested to operate with multichannel systems. Two multichannel systems based on the CSMA/CA protocol for medium access are therefore proposed. These are; the dynamic multichannel system, which is based on two types of channel selection, the random choice (RC) and the idle choice (IC), and the sequential multichannel system. The latter has been proposed in order to supress the effect of the hidden terminal, which always represents a major problem with the usage of the contention random multiple access protocols with radio and mobile radio channels. Verification of their operation performance evaluation has been carried out using mathematical modelling for the dynamic system. However, simulation modelling has been chosen for the sequential system. Both systems are found to improve system operation and fault tolerance when compared to single channel operation...|$|R
3000|$|ACRE’s {{meetings}} and workshops {{also include a}} range of invitees and speakers from different fields including historians, archivists, librarians, and physical scientists. This provides an ideal venue for scholars from different backgrounds and countries to mix, share knowledge and ideas. This has had particular value in highlighting new sources of weather observations, as well as thinking about ways to recover, store and <b>digitise</b> <b>data</b> on a mass scale. The contributions of organisations such as IEDRO, the British Library, Galaxy Zoo, and the Citizen Science Alliance have been invaluable in this respect. Information about ACRE and other regional data recovery projects {{can be found on}} the developing I-DARE website, part of a joint WMO/GCFS initiative. 16 [...]...|$|R
40|$|Natural science {{collections}} {{comprise a}} small {{component of a}} more extensive source of data on which questions about the natural world may be addressed. However, NHC <b>data</b> offer, when <b>digitised,</b> an exceptional resource: within collections lies the most extensive dataset that exists of the planet’s biodiversity. Indeed, our entire knowledge of most species is based on just one or very few specimens housed in natural science collections. Nevertheless, for most species, collections provide us with the best record available. The physical presence of specimens allows us to examine them many times using new techniques (e. g. the extraction and study of molecular data). In this article we argue in favor of expedited digitisation of NHC data...|$|R
50|$|The {{volunteer}} {{group has}} also <b>digitised</b> <b>data</b> from the Todd folios {{which have been}} forwarded {{for inclusion in the}} International Surface Pressure Databank (ISPD). This has been done as part of Project ACRE(Atmospheric Circulation Reconstructions over the Earth) of the Climate Monitoring and Attribution Group, Meteorology Office Hadley Centre, UK. ACRE exists to gather data to fuel a weather ‘backcasting’ model extending back to 1750. The Todd folios contain data of value to this initiative, data that is no longer available through other records. In many cases, the original documents containing the data recorded by weather observers are no longer in existence or are irretrievably lost, which gives significance to their recording in Todd’s synoptic charts and ancillary documents.|$|R
40|$|An {{analysis}} of below-knee amputee take-off technique {{was performed on}} two athletes competing in the high jump finals of the 2004 Paralympic Games. Two digital video cameras were used to film the event with the <b>data</b> later <b>digitised</b> and reconstructed using standard 3 - 0 OLT procedures. Some similarities with non-amputee high jump technique were noted in that centre of mass height was low at touch-down (TO), there was a similar reported magnitude of negative vertical velocity at TO, {{and most of the}} vertical velocity generated occurred {{in the first half of}} the take-off phase. However, both below-knee amputee athletes exhibited a slower horizontal approach velocity, a lower positive vertical take-off velocity, a more upright leg position at touch-down and a greater range of motion of the hip throughout the take-off phase compared to what is known about non-amputee high jump technique. These differences may be associated with taking off from the prosthetic limb on the last stride of approach. Understanding why these differences occur has implications for coaching and improving technique. KEY WORDS: high jump, amputee, biomechanics, technique, below-knee INTRODUCTION: Identifying the biomechanical elements associated with success in th...|$|R
40|$|Real-time {{technology}} has {{the capability of}} symbolising both customers and call center representatives (and the moment of interaction), purely by/as numbers, or forms. The pinnacle of this data processing is customer relationship management (CRM), where the <b>digitised</b> <b>data</b> is assembled so as to reproduce a mimetic model of the customer. This {{could be seen as}} a metamyth (Adams & Ingersoll, 1990) that, in its concealed appearance within corporate databases, seems to cuts loose from any critical inquiry. In this paper, we offer an embryonic form of such a critique through the analysis of a number of original call center case studies. It seeks to analyze the nature of abstraction at the heart of IT-based CRM practices, and the contradictions that such abstraction can foster...|$|R
40|$|This report {{describes}} the continued {{development of the}} database of nitrate porewater profiles produced by both BGS and other organisations since the mid 1970 s. A large number of sites for which profiles were either partially or completely missing from {{the first version of}} the database were identified, including investigations by the Southern Water Authority and the University of Birmingham. It was also considered that it would be desirable to capture other relevant data, primarily other nitrogen species and tritium. All identified profiles were added to the database, using original data where possible and otherwise as scanned and <b>digitised</b> <b>data.</b> A few profiles are outstanding where available plots are of poor quality. Dataholdings have increased from 32, 000 to 51, 000 individual records of quality data...|$|R
40|$|The {{creation}} of virtual models of Plans-Reliefs (sometimes called relief maps) {{is a project}} to preserve and to make known masterpieces of European Cultural Heritage. In this paper, we present the first experiments {{carried out in the}} automatic reconstruction of the fortifications modelled in every plan-relief. Their scale, size and state mean that <b>digitising</b> <b>data</b> alone is not usable. The study of historical documents like the many treatises of fortification allows us to fill in the gap by retrieving all the modelling information required in the {{creation of}} a library of parametric components with canonical values. These components are then adjusted according to theoretical ranges with a first set of reference documents like the plans that have been used by the original model makers...|$|R
40|$|VARD 2 : A {{tool for}} dealing with {{spelling}} variation in historical corpora Spelling variation causes considerable problems for corpus linguistic techniques such as frequency analysis, concordancing and automatic tagging, with a significant impact being made on recall and the accuracy of results [1]. This paper will focus on Early Modern English, the most recent period of the English language to include {{a large amount of}} inconsistent spelling. Although many corpora of Early Modern English have been constructed, including Helsinki, ARCHER [2], the Corpus of Early English Correspondence [3], Corpus of English Dialogues [4] and also many different versions of Shakespeare’s works, little research has been completed {{to deal with the problem}} of spelling variation within digitised forms of these texts. With the increasing amount of historical <b>data</b> being <b>digitised</b> through current initiatives, including Early English Books Online 1, it is imperative that techniques are found to aid the search and retrieval within such datasets. The amount of spelling variation within Early Modern English text is due to many different factors, such as adding and removing letters for the justification of lines and the influence of local dialect, but mainly because there were no standard spelling rules and no notion of the importance of a single spelling t...|$|R
