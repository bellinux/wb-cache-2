231|526|Public
5000|$|... as an <b>intermediate</b> <b>variable,</b> {{and first}} compute E as a {{function}} of M by solving Kepler's equation below, and then compute the true anomaly θ from the eccentric anomaly E. Here are the details.|$|E
5000|$|The {{chain rule}} may be written, in Leibniz's notation, in the {{following}} way. If a variable z depends on the variable y, which itself depends on the variable x, so that y and z are therefore dependent variables, then z, via the <b>intermediate</b> <b>variable</b> of y, depends on x as well. The chain rule then states, ...|$|E
50|$|Here η is an <b>intermediate</b> <b>variable</b> {{representing}} a linear combination, containing the regression parameters, of the explanatory variables. The functiong is the {{cumulative distribution function}} (cdf) of some probability distribution. Usually this probability distribution has a range from minus infinity to plus infinity so that any finite value of η is transformed by the function g to a value inside the range 0 to 1.|$|E
40|$|Outcomes {{studies of}} infections with {{resistant}} bacteria {{often do not}} account appropriately for <b>intermediate</b> <b>variables</b> – events in the causal pathway between the exposure and the outcome – when controlling for confounders. We discuss how failure to distinguish between confounders and <b>intermediate</b> <b>variables</b> can bias the analysis, and we address methods of approaching this issue...|$|R
5000|$|The {{interval}} domains {{that should}} be associated to the new <b>intermediate</b> <b>variables</b> are ...|$|R
25|$|More general {{analogous}} expressions hold, {{in which}} the <b>intermediate</b> <b>variables</b> x'i depend {{on more than one}} variable.|$|R
50|$|Circulation {{is often}} used in {{computational}} fluid dynamics as an <b>intermediate</b> <b>variable</b> to calculate forces on an airfoil or other body. When an airfoil is generating lift the circulation around the airfoil is finite, and {{is related to the}} vorticity of the boundary layer. Outside the boundary layer the vorticity is zero everywhere and therefore the circulation is the same around every circuit, regardless of the length of the circumference of the circuit.|$|E
50|$|According to Rose, the ‘high-risk strategy' to {{prevention}} is a clinically oriented approach to preventive medicine which focuses its efforts on needy individuals {{with the highest}} levels of the risk factor (‘the deviant minority with high-risk status’), and utilizes the established framework of medical services. In other words, the ‘high-risk strategy' is ‘a targeted rescue operation for vulnerable individuals’. The aim is to help each person reduce the high level of exposure to a cause or to some <b>intermediate</b> <b>variable.</b> Main strengths of this strategy include: the intervention may be matched to the needs of the individual; it may avoid interference with those who are not at a special risk; it may be accommodated within the ethical and cultural values, organization, and economics, of the health care system; selectivity may increase the likelihood of a cost-effective use of resources. Main weaknesses of the high-risk strategy are: prevention may become medicalized; success may be palliative and temporary; the contribution to overall (population) control of a disease may be small; the preventive intervention may be behaviorally or culturally inadequate or unsustainable; it has a poor ability to predict which individuals will benefit from the intervention.|$|E
40|$|Elasticities {{of demand}} for cocaine and heroin are {{estimated}} {{as the product of}} the elasticity of demand with respect to an <b>intermediate</b> <b>variable</b> and the elasticity of the <b>intermediate</b> <b>variable</b> with respect to price. The <b>intermediate</b> <b>variable</b> used here is the percent of arrestees testing positive for the drug. The demand for cocaine, at least, appears to be substantially more responsive to price changes than had previously been supposed...|$|E
40|$|This thesis {{examines}} causal inference related topics involving <b>intermediate</b> <b>variables,</b> {{and uses}} Bayesian methodologies to advance analysis capabilities in these areas. First, joint modeling of outcome <b>variables</b> with <b>intermediate</b> <b>variables</b> is {{considered in the}} context of birthweight and censored gestational age analyses. The proposed methodology provides improved inference capabilities for birthweight and gestational age, avoids post-treatment selection bias problems associated with conditional on gestational age analyses, and appropriately assesses the uncertainty associated with censored gestational age. Second, principal stratification methodology for settings where causal inference analysis requires appropriate adjustment of <b>intermediate</b> <b>variables</b> is extended to observational settings with binary treatments and binary <b>intermediate</b> <b>variables.</b> This is done by uncovering the structural pathways of unmeasured confounding affecting principal stratification analysis and directly incorporating them into a model based sensitivity analysis methodology. Demonstration focuses on a study of the efficacy of influenza vaccination in elderly populations. Third, flexibility, interpretability, and capability of principal stratification analyses for continuous <b>intermediate</b> <b>variables</b> are improved by replacing the current fully parametric methodologies with semiparametric Bayesian alternatives. This presentation {{is one of the first}} uses of nonparametric techniques in causal inference analysis, and opens a connection between these two fields. Demonstration focuses on two studies, one involving a cholesterol reduction drug, and one examine the effect of physical activity on cardiovascular disease as it relates to body mass index. Dissertatio...|$|R
30|$|Then {{we turn to}} the {{validation}} of an optimal-order convergence between the <b>intermediate</b> <b>variables</b> and the exact solutions.|$|R
5000|$|More general {{analogous}} expressions hold, {{in which}} the <b>intermediate</b> <b>variables</b> x i depend {{on more than one}} variable.|$|R
40|$|We {{extend the}} {{definition}} of the controlled direct effect of a point exposure on a survival outcome, other than through some given, time-fixed <b>intermediate</b> <b>variable,</b> to the additive hazard scale. We propose two-stage estimators for this effect when the exposure is dichotomous and randomly assigned and when the association between the <b>intermediate</b> <b>variable</b> and the survival outcome is confounded only by measured factors, which may themselves be affected by the exposure. The first stage of the estimation procedure involves assessing the effect of the <b>intermediate</b> <b>variable</b> on the survival outcome via Aalen's additive regression for the event time, given exposure, <b>intermediate</b> <b>variable</b> and confounders. The second stage involves applying Aalen's additive model, given the exposure alone, to a modified stochastic process (i. e. a modification of the observed counting process based on the first-stage estimates). We give the large sample properties of the estimator proposed and investigate its small sample properties by Monte Carlo simulation. A real data example is provided for illustration...|$|E
40|$|Given a {{classical}} channel, a stochastic map from inputs to outputs, can we replace the input {{with a simple}} <b>intermediate</b> <b>variable</b> that still yields the correct conditional output distribution? We examine two cases: first, when the <b>intermediate</b> <b>variable</b> is classical; second, when the <b>intermediate</b> <b>variable</b> is quantum. We show that the quantum variable's size is generically smaller than the classical, according to two different measures [...] -cardinality and entropy. We demonstrate optimality conditions for a special case. We end with several related results: a proposal for extending the special case, {{a demonstration of the}} impact of quantum phases, and a case study concerning pure versus mixed states. Comment: 11 pages, 3 figures; [URL]...|$|E
3000|$|... is an <b>intermediate</b> <b>variable</b> which I {{use as a}} {{basis for}} the {{construction}} of binary dummies for income mobility but do not include in the regression analysis.|$|E
3000|$|Subjective {{beliefs of}} initiative, independence, and self-guidance as {{perceived}} behavioral control vary significantly with <b>intermediating</b> <b>variable</b> Part-time Job and target variable Apprenticeship [...]...|$|R
30|$|Now we {{are ready}} to prove Theorem 4.4 in three steps. First, we prove a direct result between the <b>intermediate</b> <b>variables</b> and the {{numerical}} solutions.|$|R
30|$|These {{expressions}} lead {{to evaluate}} the average SER for all three cases, with the corresponding <b>intermediate</b> <b>variables</b> derived in Section ‘Signal models with channel estimation errors’.|$|R
40|$|This paper {{considers}} a team production {{model in which}} the final output {{is a function of}} one or more observable intermediate variables that are functions of the actions of the team members. When there is only one <b>intermediate</b> <b>variable,</b> our model essentially reduces to the standard models in which only the final output is observable. We provide a necessary and sufficient condition for implementing an outcome. This condition imposes restrictions on the possible deviations from the outcome that can be caused by every member of the team unilaterally. As a consequence of this characterization, when there are more than one <b>intermediate</b> <b>variable,</b> we are able to show that in a broad class of problems these intermediate variables may be sufficiently informative to allow sharing rules that implement efficient outcomes. Copyright Springer-Verlag Berlin Heidelberg 2003 Keywords and Phrases: Team, Sub-team, <b>Intermediate</b> <b>variable,</b> Outcome, Sharing rule, Implementability, Efficiency., JEL Classification Numbers: D 82, J 54, D 2, C 72.,...|$|E
40|$|The causal {{effect of}} a {{treatment}} on an outcome is generally mediated by several intermediate variables. Estimation of the component of the causal {{effect of a}} treatment that is mediated by a given <b>intermediate</b> <b>variable</b> (the indirect effect of the treatment), and the component that is not mediated by that <b>intermediate</b> <b>variable</b> (the direct effect of the treatment) is often relevant to mechanistic understanding and {{to the design of}} clinical and public health interventions. Under the assumption of no-unmeasured confounders for treatment and the <b>intermediate</b> <b>variable,</b> Robins 2 ̆ 6 Greenland (1992) define an individual direct effect as the counterfactual effect of a treatment on an outcome when the <b>intermediate</b> <b>variable</b> is set at the value it would have had if the individual had not been treated, and the population direct effect as the mean of these individual counterfactual direct effects. In this article we first generalize this definition of a direct effect. Given a user-supplied model for the population direct effect of treatment actions, possibly conditional on a user-supplied subset of the baseline co-variables, we propose inverse probability of treatment weighted estimators, likelihood-based estimators, and double robust inverse probability of treatment weighted estimators of the unknown parameters of this model. The inverse probability of treatment weighted estimator corresponds with a weighted regression and can thus be implemented with standard software...|$|E
3000|$|Fuzzy and {{stochastic}} simulation. In this step, uncertain {{variables are}} generated {{according to the}} corresponding stochastic and fuzzy distributions. Each summation of a fuzzy stochastic variable over M [...] s [...] simulations gives an <b>intermediate</b> <b>variable</b> e.|$|E
40|$|Many {{methods have}} been {{proposed}} to solve the age-period-cohort (APC) linear identification problem, but most are not theoretically informed and may lead to biased estimators of APC effects. One exception is the mechanism-based approach recently proposed and based on Pearl’s front door criterion; it ensures consistent APC effect estimators {{in the presence of}} a complete set of <b>intermediate</b> <b>variables</b> between one of age, period, cohort and the outcome of interest, as long as the assumed parametric models for all the relevant causal pathways are correct. Through a simulation study mimicking APC data on cardiovascular mortality, we assess the performance of the mechanism-based approach under realistic conditions, namely when 1) the set of available <b>intermediate</b> <b>variables</b> is incomplete; 2) <b>intermediate</b> <b>variables</b> are affected by two or more of the APC variables, but this feature is not acknowledged in the analysis 3) unaccounted confounding is present between <b>intermediate</b> <b>variables</b> and the outcome. Furthermore, we show how the mechanism-based approach can be extended beyond the originally proposed linear and probit regression models to incorporate all generalized linear models, as well as non-linearities in the predictors using Monte Carlo simulation. We find that the mechanism-based approach (extended or not) is only slightly affected by bias when the departures from the assumptions are small...|$|R
40|$|In Australia {{there has}} been {{comparatively}} little research into the effect of electronic commerce on small businesses. Electronic commerce (EC) comprises several different technologies (especially those associated with the Internet); this paper investigates the use and utility of these technologies in small Australian businesses. The technologies are differently associated with <b>intermediate</b> <b>variables</b> such as the attraction of new customers {{and the ability to}} participate in overseas markets. The statistical evidence that e-commerce is positively correlated with some <b>intermediate</b> <b>variables</b> is overwhelming. We consider the statistical relationships between <b>intermediate</b> <b>variables</b> and final variables (revenues, costs and competitive advantage). There are significant correlations between some sets of intermediate and final variables; most of these correlations had plausible explanations and suggest what EC techniques are most fruitful. There are clear implications for small businesses, for example, the Internet allows them to maintain a low-cost foreign presence but it allows foreign firms to compete (at marginal cost) in Australia...|$|R
50|$|In {{the theory}} of {{stochastic}} processes in probability theory and statistics, a nuisance variable is a random variable that is fundamental to the probabilistic model, but that is of no particular interest in itself or is no longer of interest: one such usage arises for the Chapman-Kolmogorov equation. For example, {{a model for a}} stochastic process may be defined conceptually using <b>intermediate</b> <b>variables</b> that are not observed in practice. If the problem is to derive the theoretical properties, such as the mean, variance and covariances of quantities that would be observed, then the <b>intermediate</b> <b>variables</b> are nuisance variables.|$|R
40|$|This paper {{presents}} a new nonlinear model predictive control (MPC) algorithm for Hammerstein systems subject to {{constraints on the}} state, input, and <b>intermediate</b> <b>variable.</b> Taking no account of constraints, a desired linear controller of the <b>intermediate</b> <b>variable</b> is obtained by applying pole placement to the linear subsystem. Then, actual control actions are determined in consideration of constraints by online solving a finite horizon optimal control problem, where only the first control is calculated and others are approximated to reduce the computational demand. Moreover, the asymptotic stability can be guaranteed in certain condition. Finally, the simulation example of the grade transition control of industrial polypropylene plants is used to demonstrate {{the effectiveness of the}} results proposed here...|$|E
40|$|This study aims to {{describe}} the influence of Experiential Marketing on Customer Loyaltythrough Customer Satisfaction as an <b>intermediate</b> <b>variable.</b> Explanatory research wasconducted by using questionnaire survey on 50 respondents as the customer of HypermartMalang Town Square (MATOS). Path {{analysis was used to}} analyse the research data. Theresult shows that Experiential Marketing has significantly influence the Customer Loyalty inRetail Business and Customer Satisfaction as an <b>intermediate</b> <b>variable.</b> Based on this result,Hypermart of Malang Town Square should maintain and continue to provide a goodexperience to customers through experiential marketing so it can increase their satisfaction. In addition, the need for the Hypermart of Malang Town Square continues to maintain anddeliver customer satisfaction in order to achieve customer loyalty...|$|E
3000|$|... 1 Note that σ _U_n^ 2 {{is just an}} <b>intermediate</b> <b>variable</b> and it {{does not}} {{represent}} the true variance of the random variable U_n^l. The actual variance of the U_n^l is equal to 2 σ _I^ 2 σ _h_mn^ 2 as E [(h_mn^l)^ 2]= 2 σ _h_mn^ 2.|$|E
3000|$|... 0, λ _T_u, λ _T_d, Δ, ρ, δ are 0.6, 0.9, 0.2, 0.001, 0.7, 0.001, respectively. ξ {{is decided}} by the {{required}} BER of FH system. Step (1) prepares the initial values of <b>intermediate</b> <b>variables.</b>|$|R
40|$|Constraint {{propagation}} solvers interleave propagation (removing impossible {{values from}} variables domains) with search. In order to specify constraint {{problems with a}} propagation solver often many new <b>intermediate</b> <b>variables</b> need to be introduced. Each variable {{plays a role in}} calculating the value of some expression. But as search proceeds not all of these expressions will be of interest any longer, but the propagators implementing them will remain active. In this paper we show how we can analyse the propagation graph of the solver in linear time to determine <b>intermediate</b> <b>variables</b> that can be removed without effecting the result. Experiments show that applying this analysis can reduce the space and time requirements for constraint propagation on example problems. 1...|$|R
40|$|Outcomes {{studies of}} infections with {{resistant}} bacteria {{often do not}} account appropriately for <b>intermediate</b> <b>variables</b> – events in the causal pathway between the exposure and the outcome – when controlling for confounders. We discuss how failure to distinguish between confounders and <b>intermediate</b> <b>variables</b> can bias the analysis, and we address methods of approaching this issue. Antimicrobial resistance in invasive infections is associated with adverse outcomes, including increased mortality, increased length of stay, and increased hospital costs [1 - 4]. A number of reasons have been suggested for this observation: a delay in institution of effective therapy, inferior definitive therapy as compared with that available for susceptible bacteria, and greater virulence of some resistant strains [3 - 5]. Pseudomonas aeruginosa, although inherentl...|$|R
40|$|Summary. This paper {{considers}} a team production {{model in which}} the final output {{is a function of}} one or more observable intermediate variables that are functions of the actions of the team members. When there is only one <b>intermediate</b> <b>variable,</b> our model essentially reduces to the standard models in which only the final output is observable. We provide a necessary and sufficient condition for implementing an outcome. This condition imposes restrictions on the possible deviations from the outcome that can be caused by every member of the team unilaterally. As a consequence of this characterization, when there are more than one <b>intermediate</b> <b>variable,</b> we are able to show that in a broad class of problems these intermediate variables may be sufficiently informative to allow sharing rules that implement efficient outcomes...|$|E
40|$|Some interplanetary shocks {{detected}} by ISEE- 3 are preceded by {{many hours of}} strongly enhanced plasma wave noise at a few kHz, while others have essentially no wave precursors above background. It {{has been shown that}} these extremes correspond to quasi-parallel and quasi-perpendicular shocks, respectively, based on the instantaneous orientation angle of the interplanetary magnetic field (IMF) to the shock normal at the time the shocks cross the spacecraft. It is shown that precursor wave noise level is correlated with field orientation and an extrapolated instantaneous orientation angle throughout the preshock observation interval for two contrasting active and quiet cases, and that <b>intermediate,</b> <b>variable</b> noise levels correspond to <b>intermediate,</b> <b>variable</b> IMF orientations. It is inferred that foreshocks are an intrinsic part of the structure of quasiparallel interplanetary shocks...|$|E
40|$|The causal {{effect of}} a {{treatment}} on an outcome is generally mediated by several intermediate variables. Estimation of the component of the causal {{effect of a}} treatment that is mediated by a given <b>intermediate</b> <b>variable</b> (the indirect effect of the treatment), and the component that is not mediated by that <b>intermediate</b> <b>variable</b> (the direct effect of the treatment) is often relevant to mechanistic understanding and {{to the design of}} clinical and public health interventions. Under the assumption of no-unmeasured confounders, Robins & Greenland (1992) and Pearl (2000), develop two identifiability results for direct and indirect causal effects. They define an individual direct effect as the counterfactual effect of a treatment on an outcome when the <b>intermediate</b> <b>variable</b> is set at the value it would have had if the individual had not been treated, and the population direct effect as the mean of these individual counterfactual direct effects. The identifiability result developed by Robins & Greenland (1992) relies on an additional ``No-Interaction Assumption'', while the identifiability result developed by Pearl (2000) relies on a particular assumption about conditional independence in the population being sampled. Both assumptions are considered very restrictive. As a result, estimation of direct and indirect effects has been considered infeasible in many settings. We show that the identifiability result of Pearl (2000), also holds under a new conditional independence assumption which states that, within strata of baseline covariates, the individual direct effect at a fixed level of the <b>intermediate</b> <b>variable</b> is independent of the no-treatment counterfactual <b>intermediate</b> <b>variable.</b> We argue that our assumption is typically less restrictive than both the assumption of Pearl (2000), and the ``No-interaction Assumption'' of Robins & Greenland (1992). We also generalize the current definition of the direct (and indirect) effect of a treatment as the population mean of individual counterfactual direct (and indirect) effects to 1) a general parameter of the population distribution of individual counterfactual direct (and indirect) effects, and 2) change of a general parameter of the population distribution of the appropriate counterfactual treatment-specific outcome. Subsequently, we generalize our identifiability result for the mean to identifiability results for these generally defined direct effects. We also discuss methods for modelling, testing, and estimation, and we illustrate our results throughout using an example drawn from the treatment of HIV infection. Causal inference, confounding, counterfactual, direct causal effect, double robust estimation, G-computation estimation, indirect causal effect, inverse probability of treatment weighted estimation, longitudinal data,...|$|E
40|$|We extend Pearl's {{criticisms of}} {{principal}} stratification analysis {{as a method}} for interpreting and adjusting for <b>intermediate</b> <b>variables</b> in a causal analysis. We argue {{that this can be}} meaningful only in those rare cases that involve strong functional dependence, and even then may not be appropriate...|$|R
40|$|Currently, {{there is}} {{considerable}} attention for health impact [...] as measured by mortality, morbidity or nutrition indicators, {{in the evaluation of}} primary health care (PHC) programmes. In most cases, health impact evaluations tend to be dominated by methodological discussions on data collection, analysis and interpretation, which are not relevant to the majority of PHC programmes. In this paper a theoretical framework of variables, affecting child survival, is presented. The key to this action-oriented framework is the identification of a set of <b>intermediate</b> <b>variables</b> which directly affect the health status of children, but can be influenced by PHC interventions as well. It is recommended that evaluations of PHC programmes should focus on these <b>intermediate</b> <b>variables</b> and be less concerned with health impact of the interventions. primary health care evaluation model child survival indicators...|$|R
30|$|Note {{that several}} <b>intermediate</b> <b>variables,</b> {{such as the}} {{pipeline}} gas vector and the compressor gas consumption vector, are introduced into the equations of the coupled system [13, 14, 15]. This {{increase in the number}} of variables greatly improves the convenience of the generation of the Jacobi matrix in the subsequent model.|$|R
