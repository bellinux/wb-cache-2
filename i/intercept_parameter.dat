86|103|Public
5000|$|... where N is {{the number}} of {{precipitation}} particles between a given diameter D and D + dD, N0 is the <b>intercept</b> <b>parameter,</b> λ is the slope parameter, and D is the diameter of the particles. They used the same model and microphysics scheme, turning off different microphysical mechanisms to understand which ones are the most important. They note that modifications to the microphysics scheme dramatically impacted the hurricane intensity. The most intense hurricanes were when melting was suppressed, or when no evaporation was allowed. They interpret this as meaning that the energy needed to either melt or evaporate the particles could instead be used to heat the air column, which increased convection leading to a stronger storm. During the weakest simulated storm, the fall speed of the snow and graupel particles was increased. The increased rate of fallout also increased the evaporation, leading to weakened convection. Changes in the <b>intercept</b> <b>parameter</b> showed little change. This implies that the total number of particles does not matter as much as the relative distribution between different sizes of particles.|$|E
50|$|This is {{negative}} if {{and only if}} g - b > 0, in which case the demand <b>intercept</b> <b>parameter</b> a positively influences the price. So we can say that while the direction of effect of the demand intercept on the equilibrium price is ambiguous when all we know is that the reciprocal of the supply curve's slope, g, {{is negative}}, in the only relevant case (in which the price actually goes to its new equilibrium value) an increase in the demand intercept increases the price. Note that this case, with g - b > 0, is the case in which the supply curve, if negatively sloped, is steeper than the demand curve.|$|E
40|$|This note {{considers}} a paradox arising in the least-squares estimation of linear regression models {{in which the}} error terms {{are assumed to be}} i. i. d. and possess finite rth moment, for r[set membership, variant][1, 2). We give a concrete example to show that the least-squares estimator of the slope parameter is inconsistent when the <b>intercept</b> <b>parameter</b> of the model is given. However, surprisingly this estimator is consistent when the <b>intercept</b> <b>parameter</b> is intendedly assumed to be unknown and re-estimated simultaneously with the slope parameter. Consistency Least-squares estimate rth moment...|$|E
30|$|Measurement {{invariance}} (MI) {{in multiple}} group comparison may pertain to different parameters of psychological assessment (Chen 2008; Sass 2011). In {{the case of}} continuous observed variables, the following parameters are constrained to establish different levels of MI across groups: <b>intercept</b> <b>parameters,</b> factor loadings, and residual variances. Hence, {{in the case of}} continuous observed variables, four levels of MI are typically tested (see e.g. Widaman and Reise 1997): (1) configural, (2) weak or metric, (3) strong or scalar, and (4) strict. Configural MI means that the parameters (e.g., factor loadings, <b>intercept</b> <b>parameters,</b> and residual variances) in the measurement model are not constrained, but freely estimated in all groups. Weak (or metric) MI implies that the factor loadings are set equal in all groups. However, the intercept and residual variances are allowed to vary across groups. Strong (or scalar) MI is established if the factor loadings and <b>intercept</b> <b>parameters</b> are held equal in all groups. For identification purposes the means of latent factors is fixed to zero in one group (i.e., the reference group) and freely estimated in all remaining groups when testing for strong MI. Strict MI requires that researchers constrain all parameters in the measurement model. Hence, strict MI is established if the <b>intercept</b> <b>parameters,</b> factor loadings and residual variances are held equal in groups. From a psychometrical point of view, strong measurement invariance is sufficient to ensure that the same construct is measured in all groups and to compare the means of the latent factor across countries (Widaman and Reise 1997).|$|R
3000|$|This {{finding is}} a direct {{consequence}} of the behavior apparent in Fig. 2 which demonstrates—in accordance with Eq. 5 —that with good accuracy, all DTP-derived SUR pairs can be described by straight lines with quite small y-axis <b>intercepts</b> (<b>parameter</b> V [...]...|$|R
40|$|Three {{distinctive}} {{methods of}} assessing measurement equivalence of ordinal items, namely, confirmatory factor analysis, differential item functioning using item response theory, and latent class factor analysis, make different modeling assumptions and adopt different procedures. Simulation data {{are used to}} compare the performance of these three approaches in detecting the sources of measurement inequivalence. For this purpose, the authors simulated Likert-type data using two nonlinear models, one with categorical and one with continuous latent variables. Inequivalence was set up in the slope parameters (loadings) {{as well as in the}} item <b>intercept</b> <b>parameters</b> in a form resembling agreement and extreme response styles. Results indicate that the item response theory and latent class factor models can relatively accurately detect and locate inequivalence in the <b>intercept</b> and slope <b>parameters</b> both at the scale and the item levels. Confirmatory factor analysis performs well when inequivalence is located in the slope parameters but wrongfully indicates inequivalence in the slope parameters when inequivalence is located in the <b>intercept</b> <b>parameters.</b> Influences of sample size, number of inequivalent items in a scale, and model fit criteria on the performance of the three methods are also analyzed. ordinal items, inequivalence, modeling assumptions, simulation data...|$|R
40|$|Abstract]: This paper {{considers}} alternative estimators of the <b>intercept</b> <b>parameter</b> of {{the linear}} regression model with normal error when uncertain non-sample prior {{information about the}} value of the slope parameter is available. The maximum likelihood, restricted, preliminary test and shrinkage estimators are considered. Based on their quadratic biases and mean square errors the relative performances of the estimators are investigated. Both analytical and graphical methods are explored. None of the estimators is found to be uniformly dominating the others. However, if the non-sample prior information regarding the value of the slope is not too far from its true value, the shrinkage estimator of the <b>intercept</b> <b>parameter</b> dominates the rest of the estimators...|$|E
40|$|A {{generalization}} of the core/halo {{model to the}} Bose-Einstein correlation function of any number of particles is presented. In particular, a simple prediction is obtained for the <b>intercept</b> <b>parameter</b> of the n-particle inclusive Bose-Einstein correlation functions for arbitrary large values of n. Comment: 10 pages, LaTeX, no figures (Shortened version...|$|E
40|$|The minimum Hellinger {{distance}} estimation {{in simple}} linear regression models is considered. It is shown that the estimators of the slope parameter and the <b>intercept</b> <b>parameter</b> are asymptotically fully efficient, and that the estimator of the scale parameter is asymptotically reasonably efficient. Also, the asymptotic normality of these estimators is shown. Asymptotic efficiency Hellinger distance Kernel density...|$|E
30|$|In this study, we {{treated the}} items as ordered {{categorical}} observed variables. Because factor models with categorical observed variables {{are based on}} conditional probabilities, <b>intercept</b> <b>parameters</b> are fixed to zero and residual variances are fixed to 1 using a factor analytical approach (Millsap and Yun-Tein 2004). This means that researchers may impose restrictions on thresholds and/or factors loadings {{in order to test}} the level of MI in case of ordered categorical data.|$|R
40|$|It is {{well-known}} that the {{ordinary least squares}} (OLS) estimator 8 of the slope and <b>intercept</b> <b>parameters</b> 8 in a linear regression model with errors of measurement {{for some of the}} independent variables (~redictors) is inconsistent. However, Gallo (1982) has shown that certain linear combinations of Bare consistently estimated by the corresponding linear combinations of 8. this paper, it is shown that under reasonable regularity conditions such linear combinations are (jointly) asymptotically normally distributed. methodological consequences of our results are given in a companion pape...|$|R
40|$|The {{parameters}} in the cointegration vector and {{the loading}} parameters {{are not the}} only interesting parameters in a vector cointegration model. With a reformulation of the model the <b>intercept</b> <b>parameters</b> can be decomposed into growth parameters and cointegration mean parameters. These parameters have economic interpretations and are therefore also important. We show how these parameters can be estimated and restricted. The latter can be achieved by using a linear switching algorithm. Consumption and money demand applications illustrate the method. Johansen procedure; cointegrated VAR; growth rates; cointegration means; linear switching algorithm; consumption; money demand; savings ratio. ...|$|R
40|$|Inference about {{population}} parameters {{could be}} improved using non-sample prior information (NSPI) from reliable sources along with the available data. This paper studies the problem of testing the <b>intercept</b> <b>parameter</b> of a simple regression model when NSPI {{is available on the}} value of the slope. The information on the slope may have the three different scenarios: (i) unknown (unspecified), (ii) known (certain or specified), and (iii) uncertain if the suspected value is unsure, for which we define the unrestricted test (UT), restricted test (RT) and pre-test test (PTT) for the <b>intercept</b> <b>parameter.</b> The test statistics, their sampling distributions, and power functions are derived. Comparison of the power functions and size of the tests are used to search and recommend a best test. The study reveals that the PTT has a reasonable dominance over the UT and RT both in terms of achieving highest power and lowest size. ...|$|E
40|$|The <b>intercept</b> <b>parameter</b> of the two-pion Bose-Einstein {{correlation}} functions at low transverse {{momentum is}} shown {{to play the role}} of an experimentally accessible measure of the (partial) restoration of U_A(1) symmetry in ultra-relativistic nuclear collisions. Comment: 6 pages, 1 figure, Latex 2 e, talk given by T. Csorgo at the XXIX-th International Symposium on Multiparticle Dynamics, Brown University, Providence, RI, August 199...|$|E
40|$|Accurate {{estimation}} of precipitation at high {{spatial and temporal}} resolution of weather radars is an open problem in hydrometeorological applications. The use of dual polarization gives the advantage of multiparameter measurements using orthogonal polarization states. These measurements carry significant information, useful for estimating rain-path signal attenuation, drop size distribution (DSD), and rainfall rate. This study evaluates a new self-consistent with optimal parameterization attenuation correction and rain microphysics estimation algorithm (named SCOP-ME). Long-term X-band dual-polarization measurements and disdrometer DSD parameter data, acquired in Athens, Greece, {{have been used to}} quantitatively and qualitatively compare SCOP-ME retrievals of median volume diameter D 0 and <b>intercept</b> <b>parameter</b> NW with two existing rain microphysical estimation algorithms and the SCOP-ME retrievals of rain rate with three available radar rainfall estimation algorithms. Error statistics for rain rate estimation, in terms of relative mean and root-mean-square error and efficiency, show that the SCOP-ME has low relative error if compared to the other three methods, which systematically underestimate rainfall. The SCOP-ME rain microphysics algorithm also shows a lower relative error statistic when compared to the other two microphysical algorithms. However, measurement noise or other signal degradation effects can significantly affect the {{estimation of}} the DSD <b>intercept</b> <b>parameter</b> from the three different algorithms used in this study. Rainfall rate estimates with SCOP-ME mostly depend on the median volume diameter, which is estimated much more efficiently than the <b>intercept</b> <b>parameter.</b> Comparisons based on the long-term dataset are relatively insensitive to pathintegrated attenuation variability and rainfall rates, providing relatively accurate retrievals of the DSD parameters when compared to the other two algorithms. © 2013 American Meteorological Society...|$|E
3000|$|In {{order to}} {{identify}} and estimate the model (Eq.  1) certain restrictions have to be made. First, all intercepts α_ig have to be fixed to zero, as there are no <b>intercept</b> <b>parameters</b> in case of categorical observed variables. Second, for each factor one loading parameter has to be fixed to a value greater than zero (usually to one). Third, the variances Var([...] ε_ig) of the error variables have to be fixed to a value larger than zero (usually to one) in one group. In many SEM packages (e.g., Mplus, Muthén and Muthén 1998) the latent mean of η [...]...|$|R
40|$|Abstract: The {{parameters}} in the cointegration vector and {{the loading}} parameters {{are not the}} only interesting parameters in a vector cointegration model. With a reformulation of the model the <b>intercept</b> <b>parameters</b> can be decomposed into growth parameters and cointegration mean parameters. These parameters have economic interpretations and are therefore also important. We show how these parameters can be estimated and restricted. The latter can be achieved by using a linear switching algorithm. Consumption and money demand applications illustrate the method. Keywords: Johansen procedure, cointegrated VAR, growth rates, cointegration means, linear switching algorithm, consumption, money demand, savings ratio...|$|R
5000|$|... where [...] is the {{quantity}} demanded, [...] is {{the quantity}} supplied, P is the price, a and c are <b>intercept</b> <b>parameters</b> determined by exogenous influences on demand and supply respectively, b < 0 is the reciprocal {{of the slope}} of the demand curve, and g is the reciprocal of {{the slope of the}} supply curve; g > 0 if the supply curve is upward sloped, g = 0 if the supply curve is vertical, and g < 0 if the supply curve is backward-bending. If we equate quantity supplied with quantity demanded to find the equilibrium price , we find that ...|$|R
40|$|The {{exponential}} distribution N (D) = N 0 exp (! &quot; D) with a fixed <b>intercept</b> <b>parameter</b> N 0 is {{most commonly used}} to represent raindrop size distribution (DSD) in rainfall estimation and in single-moment bulk microphysics parameterization schemes. Disdrometer observations show that the <b>intercept</b> <b>parameter</b> is far from constant and systematically depends on the rain type and intensity. In this study, a diagnostic relation of N 0 {{as a function of}} rain water content (W) is derived based on Two-Dimensional Video Disdrometer (2 DVD) measurements. The data reveal a clear correlation between N 0 and the rain water content (W) where N 0 increases as W increases. To minimize the effects of sampling error, a relation between two middle moments is used to derive the N 0 – W relation. This diagnostic relation has the potential to improve rainfall estimation and bulk microphysics parameterizations. A parameterization scheme for warm rain processes based on the diagnostic N 0 is formulated and presented. The diagnostic N 0 -based parameterization yields less evaporation and accretion than the fixed N 0 model for stratiform rain. ...|$|E
40|$|In the {{framework}} of semihard (k_T factorization) QCD approach, we consider the differential cross sections of D^*± meson production at HERA. The consideration is based on BFKL and CCFM gluon distributions. We find {{that in the case}} of BFKL LO gluon distribution the theoretical results are sensitive to the Pomeron <b>intercept</b> <b>parameter</b> Δ. We present a comparison of the theoretical results with available ZEUS experimental data. Comment: to be published in proceedings of Diffraction 200...|$|E
40|$|In this study, power-law {{relations}} are developed between the <b>intercept</b> <b>parameter</b> of the exponential {{particle size distribution}} and the water content for the rain, hail, graupel and snow hydrometeor categories. The derived {{relations are}} implemented within the Milbrandt and Yau microphysics scheme. Simulations of the 3 May 1999 Oklahoma tornadic supercell are performed using the diagnostic relations for rain only, and alternately for all four precipitating species, and results are compared with those from the original single- and double-moment versions of the microphysics schemes. Diagnosing the <b>intercept</b> <b>parameter</b> for rain is found to improve {{the results of the}} simulation in terms of reproducing the key features of the doublemoment simulation while still retaining the computational efficiency of a single-moment scheme. Improvements were seen in general storm structure, cold pool structure and intensity, and the number concentration fields. Diagnosing the intercept parameters for all four species, including those for the ice species, within the single-moment scheme yields even closer alignment with the double-moment simulation results. The decreased cold pool intensity is very similar to that produced by the double-moment simulation, and the areal extent of the storm is more accuratel...|$|E
5000|$|Pattnaik and Krishnamurtil (2007) {{simulated}} hurricane Charley of 2004 {{to assess}} the impact of cloud microphysics on hurricane intensity. They report that their control run was successful in simulating the track, intensity, speed and precipitation. They used the microphysics scheme from NASA Goddard Space Flight Center. This scheme uses five different classifications of cloud water: liquid cloud water, cloud ice, rain water, snow, and hail/graupel. It also allows for supercooled water. Their study attempts to show how fall speed and <b>intercept</b> <b>parameters</b> can influence the tropical cyclone intensity. The size distribution of precipitation particles is parametrized as: ...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedA computer program is proposed to classify a signal intercepted with an ECM receiver {{going through a}} file of up to 3400 radiators. The ECM receiver tolerances in measuring the <b>intercepted</b> <b>parameters</b> are taken into account. Also the ranges and tolerances in the radiators are taken into account. The search is {{made on the basis}} of parameter importance. The readout is comprised of all possible radiators included in the file that match the intercepted signal. The program is written in such a manner that certain errors are recognized by the Computer and indicates to the operator that an error is present. The language used for the program is Fortron 60 symbolic. [URL] Commander, Chilean Nav...|$|R
30|$|Data were {{analyzed}} using conventional structural equation modeling techniques. All scales used were configured as latent variables in models. To facilitate estimation of parameters, items of social support scale were grouped in three parcel items {{on the basis of}} covariances between items and different <b>intercepts.</b> <b>Parameters</b> of items were estimated by maximum likelihood with standardized errors (MLF), implemented in Mplus software (v. 7.11), and integration algorithm (Monte Carlo). We also separated tested models by urban and rural groups, which were fixed with items’ <b>parameters</b> (loadings and <b>intercepts)</b> as being equal across groups. This procedure was performed using a multi-group structural equation modeling approach, which aimed to guarantee that possible differences in regression coefficients between rural and urban groups could be attributed to group status instead of differences among parameters of the items.|$|R
40|$|The exact {{forecast}} of precipitation is a challenge. New microphysics formulations were introduced recently into the COSMO model {{in order to}} improve the precipitation forecast. An important modification was the change from the autoconversion and accretion scheme following the Kessler (1969) formulation to the Seifert and Beheng (2001) scheme. The other main modification was implemented in the snow parameterisation by replacing the constant <b>intercept</b> <b>parameter</b> to a temperature dependent <b>intercept</b> <b>parameter.</b> These microphysics modifications are evaluated in detail in three case studies (one stratiform and two convective cases) by comparing the modelled and observed reflectivity and precipitation data. Comparisons to weather radar reflectivity data show that especially light to moderate precipitation forecast (< 20 dB) is improved. For the evaluation of the modelled precipitation, weather radar and rain gauge data are combined in order to get spatially high resolution data of high accuracy. For the quality analysis, the new error measure SAL (analysis of structure, amplitude and location) is used. The results show that the new microphysics formulations improve the precipitation amplitude {{forecast of}} up to 50 % for the convective cases while the forecast for the stratiform case is not improved. status: publishe...|$|E
40|$|PHENIX and STAR {{data on the}} <b>intercept</b> <b>parameter</b> of the two-pion Bose-Einstein {{correlation}} {{functions in}} √(s_NN) = 200 GeV Au+Au collisions were analysed in terms of various models of hadronic abundances. To describe these data, an in-medium η^' mass decrease of at least 200 MeV was needed in each case. Comment: Dedicated to 60 th birthday of Miklos Gyulassy. 2 pages, 4 figures - To appear in the conference proceedings for Quark Matter 2009, March 30 - April 4, Knoxville, Tennesse...|$|E
40|$|The {{effective}} <b>intercept</b> <b>parameter</b> of the two-pion Bose-Einstein Correlation function, lambda_*, {{is found}} to be sensitive to partial restoration of U_A(1) symmetry in ultra-relativistic nuclear collisions. An increase in the yield of the eta' meson, proposed earlier as a signal of partial U_A(1) restoration, is shown to create a ``hole'' in the low p_t region of lambda_*. A comparison with NA 44 data for central S+Pb collisions at 200 AGeV is made and implications for forthcoming heavy ion experiments are discussed...|$|E
40|$|The {{extended}} {{logistic model}} of crop response to applied nutrients provides quantitative coupling of seasonal dry matter (Y), plant N uptake (Nu), and plant N concentration (Nc) with applied nutrient (N). It predicts a hyperbolic relationship between Y and Nc with Nu. Analysis {{of data from}} numerous studies has confirmed the model. In this article the model was applied to data for Midland and Tifton 44 bermudagrass (Cynodon dactylon L.) grown on the same soil in Oklahoma. Results showed that the <b>intercept</b> <b>parameters</b> b and bn, {{as well as the}} nitrogen response coefficient c, were common to the two cultivars. The difference was accounted for in yield parameter A and plant N uptake parameter An. Applied N required to achieve 50 % of maximum yield was 92 kg ha 21 for both cultivars...|$|R
40|$|The {{performance}} of the Gibbs sampling procedure for the three-parameter normal ogive (3 PNO) IRT model was investigated using Monte Carlo simulations. Model parameters were estimated for tests with 10, 20, and 40 items and samples of 100, 300, 500, and 1000 examinees, where different actual values and prior specifications were considered for the item parameters. Summary statistics showed that this procedure was more affected by {{the choice of the}} prior distributions for the three-parameter model than the two-parameter model. For the 3 PNO model, appropriate informative priors with relatively small spread should be adopted for the slope and <b>intercept</b> <b>parameters</b> to obtain more efficient and accurate MCMC estimates when sample sizes are not large and/or tests are not long enough. When {{it is not clear whether}} the prior information is appropriate, informative priors with small prior variances are not recommended...|$|R
40|$|We used poisson and {{negative}} binomial models to estimate future demand of recreation trips to a closed site using internet and <b>intercept</b> surveys. <b>Parameter</b> estimates were validated using 1, 000 bootstrap replications. Result {{indicated a significant}} negative impact of travel time and positive impact of income on the future recreational demand. Resource /Energy Economics and Policy,...|$|R
40|$|Bose-Einstein {{correlations}} of two identically charged Q-bosons are derived considering these particles to be confined in finite volumes. Boundary effects on single Q-boson spectrum are also studied. We illustrate {{the effects on}} the spectrum and on the two-Q-boson correlation function by means of two toy models. We also derive a generalized expression for the Wigner function depending on the deformation parameter Q, which is reduced to its original functional form {{in the limit of}} Q → 1. Comment: coherence parameter change to <b>intercept</b> <b>parameter</b> and appendix adde...|$|E
40|$|AbstractFor {{the simple}} linear model Y=θ 1 +βx+ϵ where the error vector follows the elliptically {{contoured}} distribution, {{we consider the}} unrestricted, restricted, preliminary test and shrinkage estimators for the <b>intercept</b> <b>parameter,</b> θ when it is suspected that the slope parameter β may be βo. The exact bias and MSE expressions are derived and the mean-square relative efficiency is taken to determine the relative dominance properties of the proposed estimators in comparison. In the continuation, the optimal level of significance of the preliminary test estimator is tabulated and some graphical result are also displayed...|$|E
40|$|AbstractIn the {{regression}} model, {{we assume that}} the independent variables are random instead of fixed. Consider the problem of estimating the coverage function of a usual confidence interval for the unknown <b>intercept</b> <b>parameter.</b> In this paper, we consider a case in which the number of unknown parameters is smaller than 5. We show that the usual constant coverage probability estimator is admissible in the usual sense in this case. Note that this estimator is inadmissible in the usual sense in the other case where the number of unknown parameters is greater than 4...|$|E
40|$|We {{develop a}} model based {{approach}} to estimate small area (county) prevalence using information from two surveys {{assumed to be}} an in person area survey and a telephone survey. Here, we demonstrate the ability to estimate parameters generated from the assumed model using a Monte-Carlo EM algorithm. The proposed estimation method is investigated using simulated data. We assess {{the accuracy of the}} parameter estimates and also the accuracy of the county, state, and national estimates. The estimation accuracy of slope and <b>intercept</b> <b>parameters</b> of the model is good while some of the elements of the covariance matrix estimates are biased. The small area estimates are approximately unbiased. However, the coverage of the true values is less than the nominal value – most likely caused by the inaccurate covariance estimation. The model allows a test of whether non-response bias is present in the telephone survey estimates...|$|R
40|$|The {{problem of}} {{parallelism}} for bi-linear regression lines arises in many real life investi-gations. For two linear regression models with normal errors, {{the estimation of}} the slope {{as well as the}} <b>intercept</b> <b>parameters</b> is considered when it is apriori suspected that the two lines are parallel. Three di®erent estimators are de¯ned by using both the sample data and the non-sample uncertain prior information. The relative performances of the unrestricted, restricted and preliminary test estimators are investigated based on the analysis of the bias, and risk functions under quadratic loss. An example based on a medical study is used to illustrate the method. Key Words: Two parallel regression lines; non-sample uncertain prior information; multi-variate normal distribution; central and non-central chi-squared and F-distributions; max-imum likelihood, restricted and preliminary test estimators; bias and quadratic risk. AMS 1991 Subject Classi¯cation: Primary 62 F 30 and Secondary 62 J 05. ...|$|R
30|$|In this paper, {{we apply}} {{for the first time}} the moving-windows {{application}} of the Poisson’s theorem to the synthetic gravity and magnetic data, followed by calculations of the correlations of the Bouguer gravity and aeromagnetic data of Western Anatolia. The correlation coefficient, slope and <b>intercept</b> <b>parameters</b> were generated from the internal correlations existing between the gravity and magnetic anomalies. Relative negative correlation values of positive gravity and negative magnetic anomalies were found on the Menderes Massif and in the southern part of the Marmara sea. Higher heat flow values were also obtained from these regions. The negative correlation values can be seen on a profile taken along the 28 °E longitude and are sourced from a large graben system which has been generated as a result of lithospheric extension in Western Anatolia since the Early Miocene. The grabens were filled up by approximately 2000 -m-thick sediments. The negative correlation coefficients and high heat flow values correspond to relative uplift of the asthenosphere in these regions.|$|R
