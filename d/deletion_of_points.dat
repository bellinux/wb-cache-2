18|10000|Public
40|$|A data {{structure}} {{is said to}} be succinct if it uses an amount of space that is close to the information-theoretic lower bound, but still allows for efficient query processing. Quadtrees are among the most widely used {{data structure}}s for answering queries on point sets in Euclidean space. In this paper we present a succinct quadtree structure. Our data structure can efficiently answer approximate range queries and approximate nearest neighbor queries and supports insertion and <b>deletion</b> <b>of</b> <b>points.</b> ...|$|E
40|$|A {{variant of}} k-d trees, the divided k-d tree, is {{described}} {{that has some}} important advantages over ordinary k-d trees. The divided k-d tree is fully dynamic and allows for the insertion and <b>deletion</b> <b>of</b> <b>points</b> in O(log n) worst-case time. Moreover, divided k-d trees allow for split and concatenate operations. Different types of queries can be performed with equal or almost equal efficiency as on ordinary k-d trees. Both two- and multi-dimensional divided k-d trees are studied...|$|E
40|$|Matérn's hard-core {{processes}} are valuable point process models in spatial statistics. In order {{to extend their}} field of application, Matérn's original models are generalized here, both as point processes and particle processes. The thinning rule uses a distance-dependent probability function, which controls <b>deletion</b> <b>of</b> <b>points</b> close together. For this general setting, explicit formulas for first- and second-order characteristics can be given. Two examples from materials science illustrate {{the application of the}} models. Comment: 21 pages, 17 figure...|$|E
40|$|We {{show how}} {{to compute the}} width of a dynamic set <b>of</b> {{low-dimensional}} <b>points</b> in the streaming model. In particular, we assume the stream contains both insertions <b>of</b> <b>points</b> and <b>deletions</b> <b>of</b> <b>points</b> to a set S, and the goal is to compute the width of the set S, namely the minimal distance between two parallel hyperplanes sandwiching the pointset S. Our algorithm (1 +ɛ) -approximates the width of the set S using space polylogarithmic in the size of S and the aspect ratio of S. This is the first such algorithm that supports both insertions and <b>deletions</b> <b>of</b> <b>points</b> to the set S: previous algorithms for approximating {{the width of a}} pointset only supported additions [Agarwal et al. 2004; Chan 2006], or a sliding window [Chan and Sadjad 2006]. This solves an open question from the “ 2009 Kanpur list ” of Open Problems in Data Streams, Propert...|$|R
40|$|Let S be a set <b>of</b> n <b>points</b> in d-space and let 1 ≤ k ≤ n be an integer. A unified {{approach}} is given for {{solving the problem}} of finding a subset of S of size k that minimizes some closeness measure, such as the diameter, perimeter or the circumradius. Moreover, data structures are given that maintain such a subset under insertions and <b>deletions</b> <b>of</b> <b>points...</b>|$|R
40|$|Abstract. We {{consider}} the half-space range-reporting problem: Given a set S <b>of</b> n <b>points</b> in ~a, preprocess {{it into a}} data structure, so that, given a query half-space 7, all k <b>points</b> <b>of</b> S n? can be reported efficiently. We extend previously known static solutions to dynamic ones, supporting insertions and <b>deletions</b> <b>of</b> <b>points</b> <b>of</b> S. For a given parameter m, n 3). We present, among others, the following applications: an O(n 1 +~) -time algorithm for computing convex layers in R 3, and an output sensitive algorithm for computing a level in an arrangements of planes in R 3, whose time complexity is O((b + n) 'n~), where b {{is the size of}} the level. Key Words...|$|R
40|$|Abstract. Matérn’s hard-core {{processes}} are valuable point process models in spa-tial statistics. In order {{to extend their}} field of application, Matérn’s original models are generalized here, both as point processes and particle processes. The thinning rule uses a distance-dependent probability function, which controls <b>deletion</b> <b>of</b> <b>points</b> close together. For this general setting, explicit formulas for first- and second-order charac-teristics can be given. Two examples from materials science illustrate {{the application of the}} models. Key words: Point process, marked Poisson process, Matérn hard-core process, dependent thinning, independent thinning, pair correlation function. ...|$|E
40|$|In {{this paper}} we {{determine}} the amortized computational {{complexity of the}} dynamic convex hull problem in the planar case. We present a data structure that maintains a finite set of n points in the plane under insertion and <b>deletion</b> <b>of</b> <b>points</b> in amortized O(log n) time per operation. The space usage of the data structure is O(n). The data structure supports extreme point queries in a given direction, tangent queries through a given point, and queries for the neighboring points on the convex hull in O(log n) time. The extreme point queries {{can be used to}} decide whether or not a given line intersects the convex hull, and the tangent queries to determine whether a given point is inside the convex hull. We give a lower bound on the amortized asymptotic time complexity that matches the performance of this data structure...|$|E
40|$|AbstractFor a set S {{of points}} in Rd, an s-spanner is a {{subgraph}} {{of the complete}} graph with node set S such that any pair of points is connected via some path in the spanner whose total length is at most s times the Euclidean distance between the points. In this {{paper we propose a}} new sparse (1 +ε) -spanner with O(n/εd) edges, where ε is a specified parameter. The key property of this spanner is that it can be efficiently maintained under dynamic insertion or <b>deletion</b> <b>of</b> <b>points,</b> as well as under continuous motion of the points in both the kinetic data structures setting and in the more realistic blackbox displacement model we introduce. Our deformable spanner succinctly encodes all proximity information in a deforming point cloud, giving us efficient kinetic algorithms for problems such as the closest pair, the near neighbors of all points, approximate nearest neighbor search (aka approximate Voronoi diagram), well-separated pair decompositions, and approximate k-centers...|$|E
40|$|The {{width of}} a set <b>of</b> n <b>points</b> in the plane is the {{smallest}} distance between two parallel lines that enclose the set. We maintain the set <b>of</b> <b>points</b> under insertions and <b>deletions</b> <b>of</b> <b>points</b> and {{we are able to}} report an approximation of the width <b>of</b> this dynamic <b>point</b> set. Our data structure takes linear space and allows for reporting the approximation with relative accuracy ffl in O(p 1 =ffl log n) time; and the update time is O(log² n). The method uses the tentative prune-and-search strategy of Kirkpatrick and Snoeyink...|$|R
40|$|AbstractFor {{a number}} of common {{configurations}} <b>of</b> <b>points</b> (lines) in the plane, we develop data structures in which insertions and <b>deletions</b> <b>of</b> <b>points</b> (or lines, respectively) can be processed rapidly, without sacrificing much of the efficiency of query answering which known static structures for these configurations attain. As a main result we establish a fully dynamic maintenance algorithm for convex hulls that can process insertions and <b>deletions</b> <b>of</b> single <b>points</b> in only O(log 2 n) steps per transaction, where n is the number <b>of</b> <b>points</b> currently in the set. The algorithm has several intriguing applications, {{including the fact that}} the “trimmed” mean of a set <b>of</b> n <b>points</b> in the plane can be determined in only O(n log 2 n) steps. Likewise, efficient algorithms are obtained for dynamically maintaining the common intersection of a set of half-spaces and for dynamically maintaining the maximal elements of a set <b>of</b> <b>points.</b> The results are all derived by means of one master technique, which is applied repeatedly and which captures an appropriate notion of “decomposability” for configurations closely related to the existence of divide-and-conquer solutions...|$|R
40|$|Jack Snoeyink x The {{width of}} a set <b>of</b> n <b>points</b> in the plane is the {{smallest}} distance between two parallel lines that enclose the set. We maintain the set <b>of</b> <b>points</b> under insertions and <b>deletions</b> <b>of</b> <b>points</b> and {{we are able to}} report an approximation of the width <b>of</b> this dynamic <b>point</b> set. Our data structure takes linear space and allows for reporting the approximation with relative accuracy � in O � p 1 = � log n � time; and the update time is O�log 2 n�. The method uses the tentative prune-and-search strategy of Kirkpatrick and Snoeyink. ...|$|R
40|$|An {{external}} memory {{data structure}} is presented for maintaining a dynamic set of N two-dimensional points under the insertion and <b>deletion</b> <b>of</b> <b>points,</b> and supporting 3 -sided range reporting queries and top-k queries, where top-k queries report the k points with highest y-value {{within a given}} x-range. For any constant 0 <ε≤ 1 / 2, a data structure is constructed that supports updates in amortized O(1 /ε B^ 1 -ε_B N) IOs and queries in amortized O(1 /ε_B N+K/B) IOs, where B is the external memory block size, and K {{is the size of}} the output to the query (for top-k queries K is the minimum of k and the number of points in the query interval). The data structure uses linear space. The update bound is a significant factor B^ 1 -ε improvement over the previous best update bounds for the two query problems, while staying within the same query and space bounds...|$|E
40|$|For a set S {{of points}} in R d, an s-spanner is a graph on S such that any pair of points is {{connected}} via some {{path in the}} spanner whose total length is at most s times the Euclidean distance between the points. In this {{paper we propose a}} new sparse (1 +ε) -spanner with O(n/ε d) edges, where ε is a specified parameter. The key property of this spanner is that it can be efficiently maintained under dynamic insertion or <b>deletion</b> <b>of</b> <b>points,</b> as well as under continuous motion of the points in both the kinetic data structures setting and in the more realistic blackbox displacement model we introduce. Our deformable spanner succinctly encodes all proximity information in a deforming point cloud, giving us efficient kinetic algorithms for problems such as the closest pair, the near neighbors of all points, approximate nearest neighbor search (aka approximate Voronoi diagram), well-separated pair decompositions, and approximate k-centers. ...|$|E
40|$|In {{this paper}} we present an {{approach}} for interactive visualization and manipulation of huge point clouds. Archaeological monuments like the Domitilla Catacomb in Rome lead to data sets surpassing 1 Billion (10 9) points or 20 GB of storage space, which makes standard techniques like mesh conversion or in-core point-based rendering infeasible. Our system uses an out-of-core octree structure {{and a number}} of interactive editing tools to enable many archaeological tasks to be carried out on the whole point cloud that would not be possible using traditional methods. We allow fast selection, insertion and <b>deletion</b> <b>of</b> <b>points,</b> and through out-of-core rendering, the frame rate always stays above 20 frames per second on a fast workstation. To the best of our knowledge, this is the first interactive visualization of the complete data set of a large subterranean catacomb, and we show that direct point cloud visualization on the complete data set of a scan campaign is an important tool in archaeological practice. 1...|$|E
40|$|We present {{efficient}} algorithms for {{two problems}} concerning {{the discrepancy of}} a set S <b>of</b> n <b>points</b> in the unit square in the plane. First, we describe an algorithm for maintaining the half-plane discrepancy of S under insertions and <b>deletions</b> <b>of</b> <b>points.</b> The algorithm runs in O(nlogn) worst-case time per update, and it requires only relatively simple data structures. Second, we give an algorithm that computes the strip discrepancy of S in O(n 2 a(n) logn) time, where a(n) is the extremely slowly growing functional inverse of Ackermann's function...|$|R
40|$|AbstractA short {{probabilistic}} {{proof of}} Kallenberg's theorem [2] on thinning <b>of</b> <b>point</b> processes is given. It is {{extended to the}} case where the probability <b>of</b> <b>deletion</b> <b>of</b> a <b>point</b> depends on the position <b>of</b> the <b>point</b> and is itself random. The proof also leads easily to a statement about the rate of convergence in Renyi's theorem on thinning a renewal process...|$|R
40|$|In this chapter, {{we discuss}} quadtrees which is arguably {{one of the}} {{simplest}} and most powerful geometric data-structure. We begin in Section 2. 1 by giving a simple application of quadtrees and describe a clever way for performing point-location queries quickly in such a quadtree. In Section 2. 2, we describe how such quadtrees can be compressed {{and how they can}} be quickly constructed and used for point-location queries. In Section 2. 3 we show how to dynamically maintain a compressed quadtree under insertions and <b>deletions</b> <b>of</b> <b>points.</b> In Section 2. 4, we turn our attention to applications of compressed quadtrees, showing how quadtrees can be used to compute good triangulations <b>of</b> an input <b>point</b> set...|$|R
40|$|The nonhomogeneous Poisson {{process is}} a widely used model {{for a series of}} events (stochastic point process) in which the rate or {{intensity}} of occurrence of points varies, usually with time. The process has the characteristic properties that the number of points in any finite set of nonoverlapping intervals are mutually independent random varialbes, and that the number of points in any of these intervals has a Poisson distribution. This paper first discusses several general methods for simulation of the one-dimensional nonhomogeneous Poisson process. Then a particular and very efficient method for simulation of nonhomogeneous Poisson processes is stated with log-linear rate function. The method is based on an identity relating the nonhomogeneous Poisson process to the gap statistics from a random number of exponential random variables with suitably chosen parameters. Finally, a simple and relatively efficient new method for simulation of one-dimensional and two-dimensional nonhomogeneous Poisson processes is described. The method is applicable for any given rate function and is based on controlled <b>deletion</b> <b>of</b> <b>points</b> in a Poisson process with a rate function that dominates the given rate function[URL]...|$|E
40|$|We {{present a}} new {{approach}} for approximate nearest neighbor queries for sets of high dimensional points under any L t -metric, t = 1, 2, 3, [...] . The proposed algorithm is efficient and simple to implement. The algorithm uses multiple shifted copies of the data points and stores them in up to (d + 1) B-trees where d is the dimensionality of the data, sorted according to their position along a space filling curve. This is done {{in a way that}} allows us to guarantee that a neighbor within an O(d^(1 + 1 /t)) factor of the exact nearest, can be returned with at most (d + 1) log p n page accesses, where p is the branching factor of the B-trees. In practice, for real data sets, our approximate technique finds the exact nearest neighbor between 87 % and 99 % of the time and a point no farther than the third nearest neighbor between 98 % and 100 % of the time. Our solution is dynamic, allowing insertion or <b>deletion</b> <b>of</b> <b>points</b> in O(d log p n) page accesses and generalizes easily to find approximate k-nea [...] ...|$|E
40|$|We {{determine}} the computational {{complexity of the}} dynamic convex hull problem in the planar case. We present a data structure that maintains a finite set of n points in the plane under insertion and <b>deletion</b> <b>of</b> <b>points</b> in amortized O(log n) time per operation. The space usage of the data structure is O(n). The data structure supports extreme point queries in a given direction, tangent queries through a given point, and queries for the neighboring points on the convex hull in O(log n) time. The extreme point queries {{can be used to}} decide whether or not a given line intersects the convex hull, and the tangent queries to determine whether a given point is inside the convex hull. The space usage of the data structure is O(n). We give a lower bound on the amortized asymptotic time complexity that matches the performance of this data structure. v Preface This PhD-Thesis is the result of my studies at BRICS. It was handed in February 21 st 2002 and defended May 31 st 2002. During this process several small errors in the writing have been discovered and are corrected in this version. Additionall...|$|E
40|$|Given a set <b>of</b> <b>point</b> P is {{an element}} of R- 2, we {{consider}} the well-known maxima problem, consisting of reporting the maxima (not dominated) <b>points</b> <b>of</b> P, in the dynamic setting of boundary updates. In this setting we allow insertions and <b>deletions</b> <b>of</b> <b>points</b> at the extremities of P: this permits to move a resizable vertical window on the point set. We present a data structure capable of answering maxima queries in optimal O(k) worst case time, where k is the size of the answer. Moreover we show how to maintain the data structure under boundary updates operation in O(log n) time per update. This is the first technique in a dynamic setting capable of both performing update operations and answering maxima queries in optimal worst case time...|$|R
40|$|A short {{probabilistic}} {{proof of}} Kallenberg's theorem [2] on thinning <b>of</b> <b>point</b> processes is given. It is {{extended to the}} case where the probability <b>of</b> <b>deletion</b> <b>of</b> a <b>point</b> depends on the position <b>of</b> the <b>point</b> and is itself random. The proof also leads easily to a statement about the rate of convergence in Renyi's theorem on thinning a renewal process. Point process random measure thinning convergence in distribution Poisson process Cox process...|$|R
40|$|By {{deletion}} constructions we mean several {{methods of}} generation of new geometric configurations by the judicious <b>deletion</b> <b>of</b> certain <b>points</b> and lines, and introduction of other lines or <b>points.</b> A number <b>of</b> such procedures {{have recently been}} developed in a systematic way. We present here one family of such constructions, and will describe other families in the following parts...|$|R
40|$|Abstract. Given a set P of n {{points in}} R d, an ε-kernel K ⊆ P approximates the {{directional}} width of P {{in every direction}} within a relative (1 −ε) factor. In this paper we study the stability of ε-kernels under dynamic insertion and <b>deletion</b> <b>of</b> <b>points</b> to P and by changing the approximation factor ε. In the first case, we say an algorithm for dynamically maintaining a ε-kernel is stable if at most O(1) points change in K as one point is inserted or deleted from P. We describe an algorithm to maintain an ε-kernel of size O(1 /ε (d− 1) / 2) in O(1 /ε (d− 1) / 2 + log n) time per update. Not only does our algorithm maintain a stable ε-kernel, its update time is faster than any known algorithm that maintains an ε-kernel of size O(1 /ε (d− 1) / 2). Next, we show {{that if there is}} an ε-kernel of P of size κ, which may be dramatically less than O(1 /ε (d− 1) / 2), then there is an (ε/ 2) -kernel of P of size O(min{ 1 /ε (d− 1) / 2, κ ⌊d/ 2 ⌋ log d− 2 (1 /ε) }). Moreover, there exists a point set P in R d and a parameter ε> 0 such that if every ε-kernel of P has size at least κ, then any (ε/ 2) -kernel of P has size Ω(κ ⌊d/ 2 ⌋). 1...|$|E
40|$|Given a set P of n {{points in}} |R^d, an eps-kernel K subset P approximates the {{directional}} width of P {{in every direction}} within a relative (1 -eps) factor. In this paper we study the stability of eps-kernels under dynamic insertion and <b>deletion</b> <b>of</b> <b>points</b> to P and by changing the approximation factor eps. In the first case, we say an algorithm for dynamically maintaining a eps-kernel is stable if at most O(1) points change in K as one point is inserted or deleted from P. We describe an algorithm to maintain an eps-kernel of size O(1 /eps^{(d- 1) / 2 }) in O(1 /eps^{(d- 1) / 2 } + log n) time per update. Not only does our algorithm maintain a stable eps-kernel, its update time is faster than any known algorithm that maintains an eps-kernel of size O(1 /eps^{(d- 1) / 2 }). Next, we show {{that if there is}} an eps-kernel of P of size k, which may be dramatically less than O(1 /eps^{(d- 1) / 2 }), then there is an (eps/ 2) -kernel of P of size O(min { 1 /eps^{(d- 1) / 2 }, k^{floor(d/ 2) } log^{d- 2 } (1 /eps) }). Moreover, there exists a point set P in |R^d and a parameter eps > 0 such that if every eps-kernel of P has size at least k, then any (eps/ 2) -kernel of P has size Omega(k^{floor(d/ 2) }). Comment: 15 pages, 7 figure...|$|E
40|$|Given a set P of n {{points in}} R d, an ε-kernel K ⊆ P approximates the {{directional}} width of P {{in every direction}} within a relative (1 − ε) factor. In this paper we study the stability of ε-kernels under dynamic insertion and <b>deletion</b> <b>of</b> <b>points</b> to P and by changing the approximation factor ε. In the first case, we say an algorithm for dynamically maintaining a ε-kernel is stable if at most O(1) points change in K as one point is inserted or deleted from P. We describe an algorithm to maintain an ε-kernel of size O(1 /ε (d− 1) / 2) in O(1 /ε (d− 1) / 2 + log n) time per update. Not only does our algorithm maintain a stable ε-kernel, its update time is faster than any known algorithm that maintains an ε-kernel of size O(1 /ε (d− 1) / 2). Next, we show {{that if there is}} an ε-kernel of P of size κ, which may be dramatically less than O(1 /ε (d− 1) / 2), then there is an (ε/ 2) -kernel of P of size O(min{ 1 /ε (d− 1) / 2, κ ⌊d/ 2 ⌋ log d− 2 (1 /ε) }). Moreover, there exists a point set P in R d and a parameter ε> 0 such that if every ε-kernel of P has size at least κ, then any (ε/ 2) -kernel of P has siz...|$|E
40|$|Utilizing a {{combination}} of flanking marker analysis and deletion mapping we have constructed a fine structure map of the am locus which includes 63 point mutants and ten unique <b>deletions.</b> Positions <b>of</b> <b>point</b> mutants can be rapidly {{assigned to one of}} 13 segments within the gene on the basis of crosses to nine deletion strains...|$|R
40|$|One of {{the authors}} has {{proposed}} a study of homotopy and simplicity in partially ordered sets 1, 2 (or posets). The notion <b>of</b> unipolar <b>point</b> was introduced : a unipolar point {{can be seen as}} an "inessential" element for the topology. Thus, the iterative <b>deletion</b> <b>of</b> unipolar <b>points</b> constitutes a first thinning algorithm. We show in this paper, that such an algorithm does not "thin enough" certain images. This is the reason why we use the notion <b>of</b> ff-simple <b>point,</b> introduced in the framework of posets, in Ref. 1. The definition <b>of</b> such a <b>point</b> is recursive. As we can locally decide whether a point is ff-simple, we can use classical techniques (such as a binary decision diagram) to characterize them more quickly. Furthermore, it is possible to remove in parallel ff-simple points in a poset, while preserving the topology of the image. Then, we discuss the characterization <b>of</b> end <b>points</b> in order to produce various skeletons. Particularly, we propose a new approach to characterize surface end points. This approach permits us to keep certain junctions of surfaces. Then, we propose very simple parallel algorithms based on the <b>deletion</b> <b>of</b> ff-simple <b>points,</b> consisting in the repetition of two subiterations...|$|R
40|$|We {{consider}} the geodesic convex hulls <b>of</b> <b>points</b> {{in a simple}} polygonal region {{in the presence of}} non-crossing line segments (barriers) that subdivide the region into simply connected faces. We present an algorithm together with data structures for maintaining the geodesic convex hull <b>of</b> <b>points</b> in each face in a sublinear update time under the fully-dynamic setting where both input points and barriers change by insertions and deletions. The algorithm processes a mixed update sequence <b>of</b> insertions and <b>deletions</b> <b>of</b> <b>points</b> and barriers. Each update takes O(n^ 2 / 3 log^ 2 n) time with high probability, where n is the total number <b>of</b> the <b>points</b> and barriers at the moment. Our data structures support basic queries on the geodesic convex hull, each of which takes O(polylog n) time. In addition, we present an algorithm together with data structures for geodesic triangle counting queries under the fully-dynamic setting. With high probability, each update takes O(n^ 2 / 3 log n) time, and each query takes O(n^ 2 / 3 log n) time...|$|R
40|$|This is {{the first}} of a series of papers {{treating}} randomly sampled random processes. Spectral analysis of the resulting samples pre-supposes knowledge of the statistics of 1 t~}, the random point process whose variates represent the sampling times. We introduce a class of stationary point processes, whose stationarity (as characterized by any of several equivalent criteria) leads to wide-sense stationary sampling trains when applied to wide-sense stationary processes. Of greatest importance are the nth forward [backward] recurrence times (distances from t to the nth point thereafter [preceding!), whose dis-tribution functions prove more useful to the computation of co-variances than interval statistics, and which possess remarkable properties that facilitate the analysis. The moments of the number of points in an interval are evaluated by weighted sums of recurrence time distribution functions, the moments being finite if and only if the associated sum converges. If the first moment is finite, these distribution functions are absolutely continuous, and obey some convexity relations. Certain formulas relate recurrence statistics to interval length statistics, and con-versely; further, the latter are also suitable for a direct evaluation of moments of points in intervals. Our point process requires neither independent nor identically distributed interval lengths. It embraces most of the common sam-pling schemes (e. g., periodic, Poisson, i ittered), as well as some new models. Of particular interest are point processes obtained from others by a random <b>deletion</b> <b>of</b> <b>points</b> (skip processes), as for in-stance a j ittered cyclically periodic process with (random or sys...|$|E
40|$|Abstract In {{the course}} of {{developing}} a system for fitting smooth curves to camera input we have developed several direct (i. e. noniterative) methods for fitting a shape (line, circle, conic, cubic, plane, sphere, quadric, etc.) {{to a set of}} points, namely exact fit, simple fit, spherical fit, and blend fit. These methods are all dimension-independent, being just as suitable for 3 D surfaces as for the 2 D curves they were originally developed for. Exact fit generalizes to arbitrary shapes (in the sense of the term defined in this paper) the well-known determinant method for planar exact fit. Simple fit is a naive reduction of the general overconstrained case to the exact case. Spherical fit takes advantage of a special property of circles and spheres that permits robust fitting; no prior direct circle fitters have been as robust, and there have been no previous sphere fitters. Blend fit finds the best fit to a set of points of a useful generalization of Middleditch-Sears blending curves and surfaces, via a nonpolynomial generalization of planar fit. These methods all require (am + bn) n 2 operations for fitting a surface of order n to m points, with a = 2 and b = 1 / 3 typically, except for spherical fit where b is larger due to the need to extract eigenvectors. All these methods save simple fit achieve a robustness previously attained by direct algorithms only for fitting planes. All admit incremental batched addition and <b>deletion</b> <b>of</b> <b>points</b> at cost an 2 per point and bn 3 per batch. 1...|$|E
40|$|We study dynamic data {{structures}} for different variants of orthogonal range reporting query problems. In particular, we consider (1) the planar orthogonal 3 -sided range reporting problem: given a set <b>of</b> <b>points</b> in the plane, report {{the points that}} lie within a given 3 -sided rectangle with one unbounded side, (2) the planar orthogonal range maxima reporting problem: given a set <b>of</b> <b>points</b> in the plane, report the points that lie within a given orthogonal range and are not dominated by any other point in the range, and (3) the problem of designing fully persistent B-trees for external memory. Dynamic problems like the above arise in various applications of network optimization, VLSI layout design, computer graphics and distributed computing. For the first problem, we present dynamic data {{structures for}} internal and external memory that support planar orthogonal 3 -sided range reporting queries, and insertions and <b>deletions</b> <b>of</b> <b>points</b> efficiently over an average case sequence of update operations. The external memory data structures find applications in constraint and temporal databases. In particular, {{we assume that the}} coordinate...|$|R
40|$|We present {{efficient}} algorithms for {{two problems}} concerning {{the discrepancy of}} a set S <b>of</b> n <b>points</b> in the unit square in the plane. First, we describe an algorithm for maintaining the half-plane discrepancy of S under insertions and <b>deletions</b> <b>of</b> <b>points.</b> The algorithm runs in O(n log n) worst-case time per update, and it requires only relatively simple data structures. Second, we give an algorithm that computes the strip discrepancy of S in O(n 2 2 ff(n) log n) time, where ff(n) is the extremely slowly growing functional inverse of Ackermann's function. 1 Introduction For many computational problems in computer graphics a closed form solution is not available or extremely expensive to compute. In such cases statistical sampling methods can often be used to compute an approximate solution of the problem. Consider as an example the rendering of a three-dimensional scene using ray tracing. The intensity of a pixel on the screen should correspond {{to the amount of}} light that is `visi [...] ...|$|R
40|$|AbstractP. J. Kelly first {{mentioned}} {{the possibility of}} determining a graph from subgraphs obtained by deleting several points. While such problems have received {{a great deal of}} attention in the case <b>of</b> <b>deletions</b> <b>of</b> single <b>points,</b> the problem for several points is virtually untouched. This paper contains some basic results on that problem, including the negative observation that for every k, there exist two non-isomorphic graphs with the same collection of k-point subgraphs...|$|R
5000|$|TCF4 - In 2007, <b>deletions</b> <b>of</b> or <b>point</b> {{mutations}} in this gene {{were identified as}} the cause of Pitt-Hopkins syndrome. [...] This is the first gene that has been definitively shown to directly cause a clinical phenotype when deleted. If a deletion includes the TCF4 gene (located at 52,889,562-52,946,887), features of Pitt-Hopkins may be present, including abnormal corpus callosum, short neck, small penis, accessory and wide-spaced nipples, broad or clubbed fingers, and sacral dimple. Those with <b>deletions</b> inclusive <b>of</b> TCF4 have a significantly more severe cognitive phenotype.|$|R
