13|0|Public
50|$|Neste Renewable Diesel (formerly NEXBTL) is a {{renewable}} {{diesel fuel}} production process commercialized by the Finnish oil and refining company Neste. Whether as an admixture or in its pure form, Neste Renewable Diesel {{is able to}} supplement or partially replace diesel fuel without problems. Unblended Neste Renewable Diesel meets the requirements set by the <b>European</b> <b>pre-standard</b> CEN TS 15940. Fuel blends meet the European diesel fuel standard EN 590.|$|E
40|$|A <b>European</b> <b>pre-standard</b> and an {{intermediate}} representation facilitated exchange of two independently authored compositional knowledge bases: one formal and automatically classified, the other manually classified. The exchange highlights different {{strengths and weaknesses}} in each approach, and offers a mechanism for partial, mutual quality assurance...|$|E
40|$|In 1998, the Technical Committee 'Health Informatics' (TC 251) of CEN (European Committee for Standardisation) {{set up a}} {{specific}} project team to address aspects of sharing patient-related information needed {{in the process of}} care, in order to support continuity of care, giving way to a <b>European</b> <b>pre-standard,</b> numbered ENV 13940. The authors were both members of that project team. The system of concepts and the terms defined in this <b>European</b> <b>pre-standard</b> are designed to support the management of healthcare-related information over time, and the delivery of relevant health care by different agents, encompassing primary care professionals and teams, healthcare funding organisations, managers, patients, secondary and tertiary healthcare providers, and community care teams. Beyond the terms used in the standard, which have no actual value outside the framework of the document itself, the goal is to establish a common conceptual framework for continuity of care across national, cultural and professional barriers. It is neither to define how the processes should be performed in a particular healthcare framework, nor to have any regulatory impact on the actual delivery of care. The <b>European</b> <b>pre-standard</b> does not address other aspects of health care, such as security, the specific management of professional acts and their life cycle, terminology and classification, nor the financing mechanism for healthcare delivery...|$|E
40|$|The <b>European</b> <b>Pre-Standard</b> for {{protective}} clothing against cold ENV 342 : 1998 (1) {{suggests that the}} testing of thermal insulation should be made on a moving thermal manikiin. In this way, the value {{can be used to}} match require-ments specified by the REQ-method (2) or as realistic input for prediction o...|$|E
40|$|Diploma {{presents}} {{basic rules}} of <b>european</b> <b>pre-standard</b> ENV 1996 - 1 - 1 and method {{for the design}} of axially and shear loaded unreinforced masonry structures. Instead of complicated normal method {{for the design of}} axially loaded unreinforced masonry structures based on ENV 1996 - 1 - 1 we can use as alternative simplified calculation method for the design of axially loaded unreinforced masonry structures. For using this method some conditions have to be field. For faster and easier designing axially and shear loaded unreinforced masonry structures based on normal method I developed and made, within the sphere of my diploma, software ZIDKO, which practical use is demonstrate with calculating example...|$|E
40|$|The European project Continuing Education in Structural Connections (CeStruCo) under Leonardo da Vinci {{initiative}} No. CZ/ 00 /B/F/PP- 134049 {{was prepared}} by partners from seven European countries to disseminate the latest results {{in research and}} standardization {{during the period of}} transferring the <b>European</b> <b>Pre-Standard</b> into the European Standard. The project has started by a collection of questions from the European practice. The answers to those questions have been prepared in the form of textbooks in the project partners national languages. The material is available as an easily accessible Internet/CD (www. fsv. cvut. cz/cestruco) media, and includes video and audio files, slides and worked examples. Godkänd; 2004; 20070913 (ysko...|$|E
40|$|Abstract: To support {{cooperative}} {{work among}} health professionals and institutions {{it is necessary}} to share healthcare information about patients in a meaningful way. But, nowadays, in most hospitals health data are distributed across several information systems whose interconnection is difficult to achieve, this leads to the so called islands of information. This paper briefly describes the architecture, design and implementation of the PANGEA mediator system. PANGEA allows healthcare professionals to access patient information stored in heterogeneous autonomous information systems through a set of formal aggregates of health data based on the <b>European</b> <b>pre-standard</b> of Healthcare Record Architecture ENV 13606 from CEN/TC 251. ENV 13606 is also used as canonical model for the representation of healthcare information, therefore the overall system can also be considered as a system for publishing legacy relational data as XML-Electronic Healthcare Records compliant with ENV 13606...|$|E
40|$|A major {{obstacle}} in deploying computer-based clinical guidelines {{at the point}} of care is the variability of electronic medical records and the consequent need to adapt guideline modeling languages, guideline knowledge bases, and execution engines to idiosyncratic data models in the deployment environment. This paper reports an approach, developed jointly by researchers at Newcastle and Stanford, where guideline models are encoded assuming a uniform virtual electronic medical record and guideline-specific concept ontologies. For implementing a guideline-based decision-support system in multiple deployment environments, we created mapping knowledge bases to link terms in the concept ontology with the terminology used in the deployment systems. Mediation components use these mapping knowledge bases to map data in locally deployed medical record architectures to the virtual medical record. We discuss the possibility of using the HL 7 Reference Information Model (RIM) as the basis for a standardized virtual medical record, showing how this approach also complies with the <b>European</b> <b>pre-standard</b> ENV 13606 for electronic healthcare record communication...|$|E
40|$|At a {{national}} level in Denmark {{the development of a}} Conceptual Model for Communication in Electronic Health Records (EHR) has moved towards a two-folded structure, i. e. a conceptual model for documentation of clinical information, the Clinical Process, and a Reference Information Model. The coupled structure derived in the final phase of the development of the Conceptual Model for Communication in EHR by the end of year 2001. This was inspired by the in-put and collaboration of several parties in the Danish healthcare sector throughout the period of development from 1999 to the current version 1. 01 of the national standard was launched by The National Board of Health in January 2002. The modelling of the Clinical Process meets the need for a more clinical understanding of how the use of information technology, i. e. EHR, can support the work processes of shared-care and continuity of care in hospital settings. The Clinical Process as a model for documentation in EHR facilitates the capturing of clinical information where it emerges in the clinical work processes. The model retains in a logical way the clinical relevant relations between different information elements that comply with the concept of problem-oriented documentation. A comparison between <b>European</b> <b>Pre-standard</b> CEN/ENV 13606 and the Danish Conceptual Model reveals different approaches with regard to the focus of modelling the EHR information...|$|E
40|$|The <b>European</b> <b>Pre-Standard</b> for {{protective}} clothing against cold ENV 342 : 1998 {{suggests that the}} testing of thermal insulation should be made on a moving thermal manikin. In this way the value {{can be used to}} match requirements specified by the IREQ-method or as realistic input for prediction of thermal stress in other standards. It is known from prior work that insulation values measured with human subjects can be reduced by up to 70 % from the value measured on a standing thermal manikin. This paper will focus on the principals of reduction made on total insulation calculated according to methods presented in ENV 342 : 1998. A general reduction equation that takes into account the insulation reduction effects from wind, permeability and walk has been developed. The equation makes it possible to calculate the reduction of different activity and weather conditions for most winter work clothing, if the static clothing insu-lation is known from measurements or tables. Three different permeability classes are suggested high (> 100 l/m 2 s), medium (5 - 100 l/m 2 s) and low (< 5 l/m 2 s) air permeability. The air permeability has little influence on the insulation for wind speed below 2 m/s. For calculations below this limit the air perme-ability could be omitted. In the future only measurements on standing manikin should be needed. The wind, permeability and walk reductions will be produced with correction equations. To validate these relationships more measurements on subjects exposed to wind and motion in working life are needed. The Swedish Council for Work Life Research and Finnish Work Environment Fund has supported this work...|$|E
40|$|The {{increasing}} demand for transparent constructions {{leads to an}} expanded use of glass as a supporting element. To solve safety {{issues related to the}} brittle nature of the material, commonly laminated glass is used. The latter consists of several glass sheets which are attached to plastic interlayers over their entire surface. In case of fracture of a glass pane, this polymer interlayer is able to absorb energy, so the fraction of multiple glass sheets is in most cases avoided. Moreover, the glass fragments stick to the interlayer, so the risk of possible injury is diminished. This research specifically focuses on the mechanical behaviour of laminated glass with an ionomer interlayer, namely SentryGlas®, in structural applications. SentryGlas® is a relatively stiff interlayer, of which the mechanical behaviour is less known than e. g. the more traditional interlayer material PVB. Therefore, an extensive test program was executed with both torsional and bending tests, by which the time and temperature dependent stiffness of the laminates was determined experimentally. As a first step in the analysis, the relationship between the test temperature and the load duration was determined. The corresponding time-shift function allows the prediction of the long term behaviour at a certain temperature level based on the experimental results of short tests performed at a higher temperature. Additionally, it becomes possible to analyse together the results of multiple test series, performed between 5 °C and 65 °C. All results were then processed using the equivalent thickness method, as proposed in the <b>European</b> <b>pre-standard</b> prEN 13474. The outcome indicated that the resulting equivalent thickness is highly dependent on the test configuration and therefore not directly useful to predict the laminate stiffness under divergent loading conditions. Therefore, all results of experiments on laminated glass were transformed into the actual material properties of the intermediate layer itself, using both analytical and finite element modelling. Finally, a user-friendly material model was composed, based on the numerically obtained shear modulus of the interlayer which yielded the lowest dispersion and seemed to fit best with the real test configuration. The model allows the calculation of a laminated structural element in an application with realistic loading conditions. This is possible with both simplified elastic models, as with finite element packages for more complex visco-elastic simulations...|$|E
40|$|The growing {{availability}} of spatial data along with growing {{ease to use}} the spatial data (thanks to wide-scale adoption of GIS) {{have made it possible}} to use spatial data in applications inappropriate considering the quality of the data. As a result, concerns about spatial data quality have increased. To deal with these concerns, it is necessary to (1) formalise and standardise descriptions of spatial data quality and (2) to apply these descriptions in assessing the suitability (fitness for use) of spatial data, before using the data. The aim of this thesis was twofold: (1) to enhance the description of spatial data quality and (2) to improve our understanding of the implications of spatial data quality. Chapter 1 sets the scene with a discussion on uncertainty and an explanation of why concerns about spatial data quality exist. Knowledge gaps are identified and the chapter concludes with six research questions. Chapter 2 presents an overview of definitions of spatial data quality. Overall, I found a strong agreement on which elements together define spatial data quality. Definitions appear to differ in two aspects: (1) the location within the meta-data report: some elements occur not in the spatial data quality section but in another section of the meta-data report; and (2) the explicitness with which elements are recognised as individual elements. For example, the <b>European</b> <b>pre-standard</b> explicitly recognises the element 'homogeneity'. Other standards recognise the importance of documenting the variation in quality, without naming it explicitly as an individual element. In chapter 3 we quantified the spatial variability in classification accuracy for the agricultural crops in the Dutch national land cover database (LGN). Classification accuracy was significantly correlated with: (1) the crop present according to LGN, (2) the homogeneity of the 8 -cell neighbourhood around each cell, (3) the size of the patch in which a cell is located, and (4) the heterogeneity of the landscape in which a cell is located. In chapter 4 I present methods that use error matrices and change detection error matrices as input to make more accurate land cover change estimates. It was shown that temporal correlation in classification errors has a significant impact and must be taken into account. Producers of time series land cover data are recommended not only to report error matrices, but also change detection error matrices. Chapter 5 focuses on positional accuracy and area estimates. From the positional accuracy of vertices delineating polygons, the variance and covariance in area can be derived. Earlier studies derived equations for the variance, this chapter presents a covariance equation. The variance and covariance equation were implemented in a model and applied in a case-study. The case-study consisted of 97 polygons with a small subsidy value (in euros per hectare) assigned to each polygon. With the model we could calculate the uncertainty in the total subsidy value (in euros) of the complete set of polygons as a consequence of uncertainty in the position of vertices. Chapter 6 explores the relationship between completeness of spatial data and risk in digging activities around underground cables and pipelines. A model is presented for calculating the economic implications of over- and incompleteness. An important element of this model is the relationship between detection time and costs. The model can be used to calculate the optimal detection time, i. e. the time at which expected costs are at their minimum. Chapter 7 addresses the question why risk analysis (RA) is so rarely applied to assess the suitability of spatial data prior to using the data. In theory, the use of RA is beneficial because it allows the user to judge if the use of certain spatial data does not produce unacceptable risks. Frequently proposed hypotheses explaining the scarce adoption of RA are all technical and educational. In chapter 7 we propose a new group of hypotheses, based on decision theory. We found that the willingness to spend resources on RA depends (1) on the presence of feedback mechanisms in the decision-making process, (2) on how much is at stake and (3) to a minor extent on how well the decision-making process can be modelled. Chapter 8 presents conclusions on the six research questions (chapters 2 - 7) and lists recommendations for users, producers and researchers of spatial data. With regard to the description, four recommendations are given. Firstly, spend more effort on documenting the lineage of reference data. Secondly, quantify and report correlation of quality between related data sets. Thirdly, investigate the integration of different forms of uncertainty (error, vagueness, ambiguity). Fourthly, study the implementation and use of spatial data quality standards. With regard to the application of spatial data quality descriptions, I have two main recommendations. Firstly, to continue the line of research followed in this thesis: quantification of implications of spatial data quality, through development of theory along with tangible illustrations in case-studies. Secondly, {{there is a need for}} more empirical research into how users cope with spatial data quality...|$|E

