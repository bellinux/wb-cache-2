37|0|Public
5000|$|Comment <b>fonctionne</b> mon cerveau : essai de {{psychologie}} introspective, 1909. Revue Philosophique 67:29-40 ...|$|E
50|$|Comment <b>fonctionne</b> la Russie ? Le politique, le bureaucrate et l’oligarque, ed., Paris, CERI/Autrement, 2003, 124 p.Un Etat pour la Russie, ed., Bruxelles Complexe, Coll. Espace international,1992, 145 p.|$|E
5000|$|Boris Vian adapted it in French {{under the}} name [...] "Tout <b>fonctionne</b> à l'italiano" [...] ("Everything goes italiano") to parodize the then French craving for Italian things. The song was created in 1957 by Freddy Balta on its humoristic EP Fredo Minablo et sa pizza musicale (Fredo Minablo and its musical pizza).|$|E
5000|$|L'union musical de Villers bocageLa Fanfare Municipale est fondée en 1850 et dirigée par Jules MARCHAND. Plusieurs chefs lui succèdent: André VOITURIER (1865-1875), Isaïe MARCHAND (1875-1886), Alfred SAGUEZ père (1886-1935). Cette formation, qui remporta de nombreux succès à différents {{concours}}, est partiellement sinistrée pendant la Grande Guerre. La période suivante est marquée par la personnalité d’Alfred SAGUEZ fils qui dirigera la société jusqu’en 1958. A son départ, Léonce BALESDENS, sous-chef, maintient l’activité. Puis, vient le tour de Claude DAUBERCIES. Pourtant, l’Harmonie va sommeiller, au point qu’en 1969, les activités sont abandonnées. En 1974, quelques bonnes volontés, assistées de Claude DAUBERCIES et Eric CLOCHEPIN réussissent à redonner vie à l’école et à sa société. Cette dernière <b>fonctionne</b> sous la Présidence de Lucien DUBOIS, prédécesseur de Michel BAILLY, en 1988. L'harmonie en 1954Aux rentrées 2001-2002, David BOTTE reprend la responsabilité de l’ensemble avec l’aide d’Yvette BELLETTRE, Présidente, école et société prennent alors un nouvel essor. Dorénavant les élèves passent les examens fédéraux et confédéraux. L’harmonie participe à de nombreuses manifestations. En Mai 2007, l'harmonie participe au concours national de Doullens en deuxième division et obient un premier prix mention trés bien. Elle obtient aussi le fanion fédéral de fédération Musicale de la Somme. L'harmonie en 1950Présidents: M.DEWAILLY (1924-1927), G. PETIT (1927-1946), Achille RAMBOUR (1946-1952), Victor HENON (1952-1969), arrêt de 1969 à 1974 - Lucien DUBOIS (1974-1981), Lucien CAILLEUX (1981-1982), Eric CLOCHEPIN ( [...] 1982-1985), Michel BAILLY (1985-1990), Yvette BELLETTRE (1990-1992), Jean-Jacques CODET (1992-1994), Yvette BELLETTRE (1994-2008), Martine Bouthors (2008-2010), Jean Paul Lesot (2010-2012), Martine Bouthors (2012-2015), Marie Ange Marmillon depuis 2015Chefs d'orchestre : Alfred SAGUEZ père (1924-1946), Alfred SAGUEZ fils (1946-1958), Léonce BALESDENS (1958-1960), Claude DAUBERCIES (1960-1969) - en sommeil 5 ans- Claude DAUBERCIES (1974-1976), Eric CLOCHEPIN (1976-2001), David BOTTE (2001-2009), Jérome LEFEVRE (2009-2013), Eric VANHELLE Depuis Janvier 2013, Fort de la dynamique donné par ses prédécesseurs, Eric vanhelle continue de dynamiser et à faire évoluer le répertoire de L'union musicale de Villers Bocage (UMVB).site de l'harmmonie de Villers Bocage http://vanhellee.wix.com/umvbpoporchestra ...|$|E
40|$|Working Paper du GATE 2002 - 13 How does {{leadership}} work in teams? In this paper, {{leadership is}} grounded {{on both the}} possession of a private information by the leader and by her ability to communicate credibly with followers in order to induce them to expand high efforts. This paper reports an experiment testing the efficiency of two costly communication devices introduced by Hermalin (1998) : leading-by-example and leading-by-sacrifice. In leading-by-example, the leader's effort is observable by the follower. Experimental evidence shows that leadership works more through reciprocity than through signaling. In leading-by-sacrifice, the leader can give up {{a part of her}} payoff. Experimental evidence indicates that this sacrifice works as a truthful signaling device when it is lost for the follower but not when it is transferred to him. Comment <b>fonctionne</b> le leadership au sein des équipes? Le leadership s'appuie à la fois sur la possession d'une information privée par un leader et sur sa capacité à transmettre cette information de manière crédible aux autres membres de l'équipe de façon à les amener à exercer un effort important. Cet article présente une expérience visant à tester l'efficacité de deux modes de communication coûteux tels qu'introduits par Hermalin (1998). Avec le « leadership par l'exemple », seul l'effort du leader est observable par l'autre membre de l'équipe. Les résultats montrent que ce leadership <b>fonctionne</b> davantage par la réciprocité que par l'effet de signal. Avec le “leadership par le sacrifice”, le leader peut renoncer à une partie de son gain, ce qui constitue une information sur l'état de la nature. Ce sacrifice <b>fonctionne</b> comme un mode de communication crédible lorsqu'il n'augmente pas le gain de l'autre membre de l'équipe mais pas quand il l'accroît directement...|$|E
40|$|URL] (DOI indiqué sur le site ne <b>fonctionne</b> pas.) International audienceThe virtual fields {{method has}} been {{developed}} for extracting constitutive parameters from full-field measurements provided by optical non-contact techniques for instance. It {{is based on the}} principle of virtual work written with some particular virtual fields. This paper can be regarded as a general review summarising some 15 years of developments of this method. The main aspects of the method are first recalled in the case of both linear and non-linear constitutive equations. They are then illustrated by some recent relevant examples. Some studies underway as well as relevant issues to be addressed in the near future are eventually discussed...|$|E
40|$|The {{valley of}} Sula which is {{characterized}} by the agro-export and maquiladora activity is strongly connected with the World-System though it works in a very autonomous way compared to the Honduran socio-spatial system. The Sanpedrano actors are transforming this Honduran margin into an interface between the World- System {{and the rest of the}} Honduran Nation-State to maintain a territorial system they consider efficient. La vallée de Sula, caractérisée par l'activité agro-exportatrice et maquiladora entretient d'intenses relations avec le système Monde, mais <b>fonctionne</b> de façon très autonome par rapport au système sociospatial hondurien. Pour maintenir un système territorial qu'ils jugent efficace, les acteurs sanpedranos transforment cette marge hondurienne en une interface entre le système Monde et le reste de l'Etat-nation hondurien...|$|E
40|$|With {{the aim of}} {{examining}} {{the institution of the}} Justice of the Peace, this article analyzes the judiciary annual reports written between 2005 and 2008. This study stresses that the contribution provided by the honorary magistracy is important for the good performance of the justice system. However, the need to draw up a balance highlighting both the positive aspects of the work of the Justice of the Peace as well what does not function yet is clearly underlined. Dans le but d'examiner l'institution de la justice de paix, cet article analyse les rapports inauguraux des années judiciaires rédigés entre 2005 et 2008. Cette étude souligne que l'apport fourni par la magistrature honoraire est important pour le bon fonctionnement de la machine judiciaire. Toutefois, la nécessité de dresser un bilan mettant en évidence aussi bien les aspects positifs du travail des juges de paix que ce qui ne <b>fonctionne</b> pas encore s'impose...|$|E
40|$|Abstract. A {{modification}} over Sakoe and Chiba's dynamic {{time warping}} algorithm for isolated word recognition is proposed. It is shown that this modified algorithm works better without any slope constraint. Also, this algorithm not only consumes less computation time but also improves the word recognition accuracy. Zusammenlassung. Eine Ver~inderung yon Sakoe und Chiba's 'Dynamic Time warping ' Algorithmus fiir die Erkennung von freistehende W 6 rter ist vorgestellt. Es wird gezeigt dass das ver/inderte Algorithmus ohne Abhangszwang bessere Ergebnisse gibt. Es hat sich herausgestellt dass die vereinfachte Methode weniger Rechnenzeit ben&igt und dass sic die Erkennungs-sch/irfe erhfht. R 6 sum 6. Une modification de ralgorithme de programmation dynamique de Sakoe et Chiba pour reconnaissance de mots isol 6 s est propos 6 e. Cet algorithme modifi 6 <b>fonctionne</b> mieux sans contrainte de pente. II est plus rapide en temps de calcul tout en permettant une am 61 ioration du taux de reconnaissance. Key-words. Speech, isolated word recognition, dyamic time warping. 1...|$|E
40|$|Iridium is {{the first}} satellite-based {{personal}} communications system offering global service via an interconnected constellation of low earth orbit (LEO) satellites communicating directly with handheld terminals. The total constellation of satellites was launched over a 12 -month period ending May 1998. Voice service commenced in November 1998 followed by paging services in March 1999. This technical memorandum describes {{an evaluation of the}} Iridium paging service carried out by the Military Satellite Communications (MSC) Group at Defence Research Establishment Ottawa (DREO) during the period March to June 1999. Paging tests were performed under two principle scenarios: stationary and inflight paging. Performance parameters observed include delivery time and message error performance. RESUME Le Systeme Iridium est le premier Systeme de communication personnelle par satellite offrant un service global. Le Systeme consiste en une constellation de satellites interconnected en basse orbite terrestre et qui <b>fonctionne</b> directement avec les terminaux portatifs. Tous les satellites ont ete lances sur une periode de 12 mois se terminant en mai 1998. Le service de voix a commenc...|$|E
40|$|This article {{presents}} the results of the application of computer software programs developed for evolutionary biology to manuscript stemmatics. In a test case comparing manual stemmatics methodologies with the computer software when applied to analysis of the Middle English poem, «Kings of England» by John Lydgate, the researchers found that the computer programs performed well, delivering results comparable to those arrived at through manual stemmatic analysis. L'article présente les résultats de l'application d'un programme électronique développé pour la biologie de l'évolution à la constitution d'un stemma. Dans une application au poème en moyen anglais Kings of England de John Lydgate, la comparaison des méthodes manuelles avec le logiciel a permis de conclure que le logiciel <b>fonctionne</b> bien et procure des résultats comparables à ceux obtenus par l'analyse stemmatique manuelle. Mooney Linne R., Barbrook Adrian C., Howe Christopher J., Spencer Matthew. Stemmatic analysis of Lydgate's «Kings of England» : a test case for the application of software developed for evolutionary biology to manuscript stemmatics. In: Revue d'histoire des textes, bulletin n° 31 (2001), 2003. pp. 275 - 297...|$|E
40|$|International audienceIt is {{increasingly}} common to find XML views used to enforce access control {{as found in}} many applications and commercial database systems. To overcome the overhead of view materialization and maintenance, XML views are necessarily virtual. With this comes the need for answering XML queries posed over virtual views, by rewriting them into equivalent queries on the underlying documents. A major concern here is that query rewriting for recursive XML views is still an open problem, and proposed approaches deal only with non-recursive XML views. Moreover, {{a small number of}} works have studied the access rights for updates. In this paper, we present SVMAX (Secure and Valid MAnipulation of XML), the first system that supports specification and enforcement of both read and update access policies over arbitrary XML views (recursive or non). SVMAX defines general and expressive models for controlling access to XML data using significant class of XPath queries and {{in the presence of the}} update primitives of W 3 C XQuery Update Facility. Furthermore, SVMAX features an additional module enabling efficient validation of XML documents after primitive updates of XQuery. The wide use of W 3 C standards makes of SVMAX a useful system that can be easily integrated within commercial database systems as we will show. We give extensive experimental results, based on real-life DTDs, that show the efficiency and scalability of our system. Nous présentons un système de contrôle d'accès pour documents XML par récriture de requête qui <b>fonctionne</b> aussi sur les vues récursives...|$|E
40|$|International audienceAlzheimer disease (AD) induces {{researchers}} to consider with attentiveness the links existing between language, memory and patients' personal experiences. In this paper, these links are comprehended through {{the analysis of}} language disorders that are specific to AD, and through their interpretation {{into the light of}} some particular models of cognition that are essential to the comprehension of the linguistic dimension of AD. Finally, we present our own ongoing research project which aims at finding some reliable early cues for AD diagnosis and which originality is to investigate the correlation between some linguistic indicators such as idea density and the efficiency of patients' cognitive system. " In any well-made machine one is ignorant of the working of most of the parts - the better they work the less we are conscious of them [...] . it is only a fault which draws our attention to the existence of a mechanism at all " [1] (" Une machine bien construite permet d'oublier le fonctionnement des parties qui la composent - mieux cela <b>fonctionne,</b> moins l'on est conscient de celles-ci [...] . c'est seulement lorsque survient une incident que notre attention est attirée par l'existence d'un mécanisme sous-jacent", notre traduction). Un système aussi naturel et complexe que celui du langage révèle son fonctionnement intime plus clairement dès lors qu'il dysfonctionne (notion de " reverse engineering ") [2]. L'exemple de la maladie d'Alzheimer (MA) nous invite à considérer avec attention les rapports entre langage et mémoire. Ces rapports seront d'abord envisagés au travers des symptômes dont souffrent les patients, puis interprétés à la lumière des modèles de la cognition, essentiels à la compréhension de la dimension linguistique de la maladie...|$|E
40|$|The map: {{transitional}} functionality and surpassing life storytelling. Thisarticle aims at {{demonstrating the}} ability of the map to reactivate classical life storytelling,under certain conditions of graphic shaping and, above all, of collection and constitution ofrequired information as well as conditions of use. In doing this, life storytelling can become areal tool to understand the affective relation to urban places instead of being the smooth,conventional narrative of facts consciously chosen by the person interviewed. Indeed, the useof this type of map allows us to complete the strictly rational and rationalizing dimension ofdiscourse, by surpassing the formal and artificial coherence of telling and highlighting theaffective dimensions of the relation to space. From then on, the map plays the role ofWinnicott’s “transitional object”. The map emerges as a tool that communicates, andmoreover, encourages communication about aspects which are generally omitted because theyare personal, even intimate. This is innovative in cartography as well as in psychoanalysis andsociology. The authors propose first a critical presentation of life storytelling, and then aspatialized life storytelling of urban living individuals and the resulting map, with the aim ofshowing this new use of the map as an efficient means of reactivating life storytelling in linkwith the value of urban places. – L'objectif de cet article est de montrer la possibilité qu'a la carte, sous certaines conditions de forme graphique, de constitution de l'information préalablement nécessaire et d'utilisation, de réactiver le classique récit de vie et, de discours lissé, d'en faire un véritable outil de connaissance du rapport affectif de chaque individu à la ville. En effet, l'utilisation de ce type de carte permet de compléter la dimension strictement rationalisante du discours, en dépassant la cohérence formelle et artificielle du récit, par les dimensions affectives du rapport à l'espace : la carte <b>fonctionne</b> alors comme un objet transitionnel au sens de Winnicott. Les auteurs font d'abord une présentation critique du récit de vie pour proposer ensuite le récit de vie spatialisé et la carte qu'il permet de construire, en vue de montrer cette utilisation nouvelle de la carte comme mode de réactivation efficace du récit de vie pour appréhender les valeurs des lieux urbains. Mots-clés : cartographie; récit de vie; objet transitionnel; psychanalyse; ville aimable 1 Abstract – The map: transitional functionality and surpassing life storytelling. This article aims at demonstrating {{the ability of}} the map to reactivate classical life storytelling...|$|E
40|$|Quoique l'évaluation des tâches soit une {{technique}} de plus en plus utilisée dans nos entreprises, il n'en demeure pas moins qu'elle est souvent peu comprise de ceux qui l'appliquent, la défendent ou la combattent. De plus, bien des systèmes ont mal <b>fonctionné</b> ou tout simplement échoué parce qu'on attendait d'eux des résultats qu'ils ne pouvaient ou ne devaient pas produire. Job {{evaluation is}} an objective technique {{to establish the}} relative importance of jobs in a given group. The wage structure {{may be the result of}} the application of a job evaluation system, but such a system can serve many other purposes. Therefore, the wage structure itself is independant of the job evaluation technique and must be discussed outside the committee involved in the process of evaluating the jobs. Job evaluation is a technique, not a science. It is a tool which permits an objective judgment on the importance of a job in relation with others. Therefore, both parties, management and employees, should participate in the process of evaluating jobs. Job evaluation, however, must be done by competent persons. If everybody in the organizations has a word to say on how the problem must be solved, there are great possibilities that the plan will never be applied because of deadlocks which will arise. One main problem which has to be solved in designing a job evaluation system is the weight to be given to factors and sub-factors. There is important differences between plans, in particular between the C. W. S. and the N. E. M. A., when the former gives about 25 % of the points to skill and 50 % to responsibility and the latter gives 50 % to skill and 20 % to responsibility. One can say that the weight gives to factors depends on the degree of evolution of the society, the labor market and first of all on the caracteristics of the jobs which are to be evaluated. As far as the C. W. S. and the N. E. M. A. are concerned, it is possible that their differences are only apparent as skill and responsibility work in the same direction, i. e. a job requiring great skill imposes also great responsibility on the incumbent, so that we can vary the weight between these two without influencing the final result. The main advantage of a job evaluation system is to remunarate a job according to the requirements of the job and not to the individual himself, and to permit an objective judgment on {{the relative importance of}} jobs in a given group...|$|E
40|$|In {{this thesis}} we give new means for a machine to {{understand}} complex and dynamic visual scenes in real time. In particular, we {{solve the problem}} of simultaneously reconstructing a certain representation of the world's geometry, the observer's trajectory, and the moving objects' structures and trajectories, with the aid of vision exteroceptive sensors. We proceeded by dividing the problem into three main steps: First, we give a solution to the Simultaneous Localization And Mapping problem (SLAM) for monocular vision that is able to adequately perform in the most ill-conditioned situations: those where the observer approaches the scene in straight line. Second, we incorporate full 3 D instantaneous observability by duplicating vision hardware with monocular algorithms. This permits us to avoid some of the inherent drawbacks of classic stereo systems, notably their limited range of 3 D observability and the necessity of frequent mechanical calibration. Third, we add detection and tracking of moving objects by making use of this full 3 D observability, whose necessity we judge almost inevitable. We choose a sparse, punctual representation of both the world and the moving objects in order to alleviate the computational payload of the image processing algorithms, which are required to extract the necessary geometrical information out of the images. This alleviation is additionally supported by active feature detection and search mechanisms which focus the attention to those image regions with the highest interest. This focusing is achieved by an extensive exploitation of the current knowledge available on the system (all the mapped information), something that we finally highlight to be the ultimate key to success. Dans cette thèse, nous résolvons le problème de reconstruire simultanément une représentation de la géométrie du monde, de la trajectoire de l'observateur, et de la trajectoire des objets mobiles, à l'aide de la vision. Nous divisons le problème en trois étapes : D'abord, nous donnons une solution au problème de la cartographie et localisation simultanées pour la vision monoculaire qui <b>fonctionne</b> dans les situations les moins bien conditionnées géométriquement. Ensuite, nous incorporons l'observabilité 3 D instantanée en dupliquant le matériel de vision avec traitement monoculaire. Ceci élimine les inconvénients inhérents aux systèmes stéréo classiques. Nous ajoutons enfin la détection et suivi des objets mobiles proches en nous servant de cette observabilité 3 D. Nous choisissons une représentation éparse et ponctuelle du monde et ses objets. La charge calculatoire des algorithmes de perception est allégée en focalisant activement l'attention aux régions de l'image avec plus d'intérêt...|$|E
40|$|CE TRAVAIL A CONSISTE, EN PREMIER, A DEVELOPPER DE NOUVELLES COMMANDES BASEES SUR L'IDA-PBC (ASSIGNATION DE L INTERCONNEXION ET D AMORTISSEMENT COMMANDE BASEE SUR LA PASSIVITE) POUR LE CONTROLE DE LA MACHINE A INDUCTION (MI), AINSI QU'UNE NOUVELLE APPROCHE DE L'IDA-PBC APPLIQUEE AUX STRUCTURES PCH PERTURBEES. EN SECONDE PARTIE, ON S'EST INTERESSE A LA COMMANDE SANS CAPTEUR DE MACHINES ELECTRIQUES COMPLETEMENT ACTIONNEES. LE BUT ETANT D'ELABORER UNE LOI DE COMMANDE QUI <b>FONCTIONNE</b> A TRES BASSES VITESSES. L'UTILISATION D'OBSERVATEUR À TRES BASSES VITESSES EST UN REEL PROBLEME. L'IDEE EST D'ASSERVIR LA VITESSE DE LA MACHINE SYNCHRONE A AIMANTS PERMANENTS (MSAP) EN UTILISANT COMME SEULESMESURES LES DEUX COURANTS STATORIQUES ET SANS RECOURIR A L'UTILISATION D'UN OBSERVATEUR OU D'UN ESTIMATEUR. AINSI UNE COMMANDE BASEE SUR LA PASSIVITE ET UN MODELE INTERNE À ETE ELABOREE. LES RESULTATS DE SIMULATIONS ONT ETE VALIDES PAR UNE EXPERIMENTATION. EN TROISIEME VOLET, LE TRAVAIL A CONSISTE EN LA COMMANDE, PAR PASSIVITE A BOUCLES IMBRIQUEES, D'UNE GENERATRICE ASYNCHRONE (DFIG) ENTRAINEE PAR UN DISPOSITIF EXTERIEUR (EOLIENNE PAR EXEMPLE) ET QUI EST CONNECTEE A UNE MI A TRAVERS LE STATOR DES DEUX MACHINES. IL S'AGISSAIT D'ASSERVIR LA VITESSE MECANIQUE DE LA MI-QUI EST CONSIDEREE COMME UNE CHARGE- PAR L'INTERMEDIAIRE DE LA TENSION ROTORIQUE DE LA GENERATRICE. ON DISPOSE ALORS D'UN SYSTEME D'ORDRE HUIT, QUI A DEUX COORDONNEES MECANIQUES ET UN SEUL SIGNAL DE COMMANDE DE DIMENSION 2. UNE COLLABORATION AVEC UNE EQUIPE DE L'UNIVERSITE POLYTECHNIQUE DE BARCELONE (ESPAGNE) A ABOUTIT A LA MISE EN MARCHE D'UN BANC D'ESSAI SUR LA DFIG-MI, DES EXPERIMENTATIONS ONT VALIDE LES LOIS DE COMMANDES. THE AIMS OF THIS WORK WERE, FIRST, TO DEVELOP CONTROLLERS BASED ON THE IDA-PBC (INTERCONNECTION AND DAMPING ASSIGNMENT - PASSIVITY BASED CONTROL) FOR INDUCTION MACHINE (IM). A NEW APPROACH USING THE IDA-PBC APPLIED TO THE DISTURBED PORT CONTROLLED HAMILTONIAN (PCH) STRUCTURES HAS BEEN PRESENTED. IN A SECOND PART, WE WERE INTERESTED IN THE SENSORLESS CONTROL OF FULLY ACTUATED ELECTRICAL MACHINES AT LOW SPEEDS. THE OBSERVERS AND ESTIMATORS USED IN THE SENSORLESS CONTROL CAUSES A LOT OF PROBLEM AT VERY LOW SPEEDS. WE PROPOSED A SENSORLESS CONTROL-FEEDING BACK THE STATORIC CURRENTS ONLY-OF THE PERMANENT MAGNET SYNCHRONOUS MOTOR (PMSM) WITHOUT RECONSTRUCTING THE UNMEASURED STATES BY THE MEAN OF THE PBC AND THE INTERNAL MODEL PRINCIPLE. THE RESULTS WERE VALIDATED BY EXPERIMENTATION. IN THE THIRD PART, WE ADDRESSED THE PROBLEM OF SPEED CONTROL OF DFIG INTERCONNECTED WITH IM, SOLUTIONS WERE PRESENTED USING NESTED PBC LOOP CONTROL. WE DEAL WITH AN EIGHT ORDER SYSTEM WITH TWO MECHANICAL COORDINATES AND A SINGLE TWO DIMENSIONAL CONTROL SIGNAL. A COLLABORATION WITH A TEAM OF THE POLYTECHNICAL UNIVERSITY OF BARCELONA (SPAIN) LEADED TO A REALIZATION OF A BENCHMARK, WHERE THE EXPERIMENTATIONS ON A DFIG WITH IM WERE SUCCESSFULLY DONE. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|LE PROBLÈME DE L'ALTÉRITÉ EST INHÉRENT À L'ACTIVITÉ FICTIONNELLE DE PIERRE LOTI. CELUI-CI PROCÈDE EN EFFET À UN TRAVAIL (AUTO) BIOGRAPHIQUE EN METTANT SA PROPRE EXPÉRIENCE EN PERSPECTIVE. L'AUTOBIOGRAPHIE, QUI EST ÉCRITURE DE SOI, SE CONFOND AVEC L'ÉCRITURE DE L'AUTRE. L'ALTÉRITÉ FAIT CORPS AVEC L'IDENTITÉ ET SE SAISIT DANS UN RAPPORT IMAGINAIRE OÙ LA CRÉATION <b>FONCTIONNE</b> À LA LIMITE ENTRE LA RÉALITÉ ET LE FANTASME QUI SONT POSÉS COMME INDISSOCIABLES. LA THÈSES ENTREPREND D'INTERROGER LE SENS DU VOYAGE DE PIERRE LOTI ET LE RAPPORT PROBLÉMATIQUE QUE CELUI-CI ENTRETIENT AVEC L'AUTRE QUI EST ÉTUDIÉ EN TANT QU'ALTER-EGO. NOTRE TRAVAIL S'ORGANISE AUTOUR DE DEUX AXES : LA FEMME ET LA RELIGION. LA SUBLIMATION DE LA FEMME EXOTIQUE EST L'ALTERNATIVE AU VIDE QUI ENVAHIT L'AUTEUR FACE À L'ENNUI. LE RAPPORT DE LOTI À L'ESPACE MYSTIQUE SE DÉFINIT PAR RAPPORT À L'ORIGINE, AU TEMPS ET À L'HISTOIRE. MAIS CE RAPPORT N'EST P AS DYNAMIQUE. MÉLANCOLIE ET NOSTALGIE SONT FONDATRICES DE SOI À AUTRUI. POURTANT, VU À TRAVERS LE NÉANT, L'AUTRE LOTIEN N'EST PAS SYNONYME DU DÉSESPOIR. OR, LE TRAVAIL DE LOTI EST UNE MÉDAILLE DONT LA F ACE NÉGATIVE, DÉFORMATRICE, EST INDISSOCIABLE D'UNE FACE POSITIVE. NOUS AVONS PU ILLUSTRER CETTE VÉRITÉ EN RÉFLÉCHISSANT SUR LA PROJECTION DANS L'ŒUVRE, DES STRUCTURES NARCISSIQUES DE LOTI. EN DÉPIT DE LA TRISTESSE, SUBJECTIVE, RESSENTIE EN FACE DE L'AUTRE, ON A PU REMARQUER QUE L'AUTRE N'EST PAS L'ANTITHÈSE SANS RECOURS. COMME LE FUT WERTHER POUR GOËTHE, l'AUTRE, POUR LOTI EST LE CHEMIN QUI MÈNE À LA SÉRÉNITÉ. D'OÙ LA VALEUR THÉRAPEUTIQUE DU VOYAGE ET DE L'ÉCRITURE DU VOYAGE. L'AUTRE EST SAL V A TEUR DANS LA MESURE OÙ LA SUBJECTIVITÉ DE L'AUTRE PERMET À L'EGO DE S'OBJECTIVER. THE PROBLEM OF THE OTHERNESS IS INHERENT TO THE FICTIONNELLE ACTIVITY OF PIERRE LOTI. THIS ONE PRACTISES AN AUTOBIOGRAPHICAL WORK BY HIGHLIGHTING ITS OWN EXPERIENCE. THE AUBIOGRAPHY BECOMES CONFUSED WITHE THE WRITING OF THE OTHER ONE. THE OTHERNESS AND THE IDENTITY ARE SEIZED IN AN IMAGINARY REPORT WHERE THE CREATION WORKS AT THE LIMIT BETWEEN THE REALITY AND THE FANTASY WHICH ARE PRESENTED AS INEXTRICABLE. THE THESIS INTERROGATES THE SENSE OF THE JOURNEY OF PIERRE LOTI AND THE PROBLEMATIC REPORT WHICH IT MAINTAINS WITH THE OTHER ONE WHICH IS STUDIED AS ALTER-EGO. OWR WORK GETS ORGANIZED AROUND TWO AXES: THE WOMAN AND THE RELIGION. THE SUBLIMATION OF THE EXOTIC WOMAN IS THE ALTERNATIVE TO THE SUFFERING WHICH INVADES THE AUTHOR IN FRONT OF THE BOREDOM. PIERRE 'S REPORT WITH THE MYSTIC SPACE DEFINES ITSELF ACCORDING TO THE ORIGIN, THE TIME AND THE HISTORY. BUT THIS REPORT IS NOT DYNAMIC. MELANCOLY AND HOMESICKNESS ARE FOUNDERS OF THIS REPORT. NEVERTHELESS, SEEN THROUGH THE NOTHINGNESS, THE OTHER ONE IS NOT SYNONYM OF THE DESP AIR. THE WORK OF PIERRE LOTI IS A MEDAL THE FACE OF WHICH NEGATIVE, DEFORMATRICE, IS INEXTRICABLE OF A POSITIVE FACE. WE ARE ABLE TO ILLUSTRATE THIS TRUTH BY THINKING ABOUT THE PROJECTION IN THE TEXT, OF NARCISSISTIC STRUCTURES OF PIERRE LOTI. IN SPITE OF THE SADNESS, SUBJECTIVE, BEING IN FRONT OF THE IRE OTHER ONE, WE WERE ABLE TO NOTICE THAT THE OTHER ONE IS NOT THE ANTITHESIS WITHOUT APPEAL, AS WAS WERTHER FOR GOËTHE, THE OTHER ONE FOR PIERRE LOTI IS THE ROAD WHICH LEADS TO THE SERENITY. THIS DEDUCTION JUSTIFIES THE THERAPEUTIC VALUE OF THE JOURNEY AND OF THE WRITING OF JOURNEY. THE OTHER ONE IS INDISPENSABLE BECAUSE THE SUBJECTIVITY OF THE OTHER ONE ALLOWS THE OBJECTIVITY OF EGO. MONTPELLIER-BU Lettres (341722103) / SudocPARIS 7 -Bibliothèque {{centrale}} (751132105) / SudocSudocFranceF...|$|E
40|$|The DFM (design for manufacturing) {{methods are}} used during {{technology}} alignment and adoption {{processes in the}} semiconductor industry (SI) for manufacturability and yield assessments. These methods have worked well till 250 nm technology for the transformation of systematic variations into rules and/or models based on the single-source data analyses, but beyond this technology they have turned into ineffective R&D efforts. The {{reason for this is}} our inability to capture newly emerging spatial variations. It has led an exponential increase in technology lead times and costs that must be addressed; hence, objectively in this thesis we are focused on identifying and removing causes associated with the DFM ineffectiveness. The fabless, foundry and traditional integrated device manufacturer (IDM) business models are first analyzed to see coherence against a recent shift in business objectives from time-to-market (T 2 M) and time-to-volume towards (T 2 V) towards ramp-up rate. The increasing technology lead times and costs are identified as a big challenge in achieving quick ramp-up rates; hence, an extended IDM (e-IDM) business model is proposed to support quick ramp-up rates which is based on improving the DFM ineffectiveness followed by its smooth integration. We have found (i) single-source analyses and (ii) inability to exploit huge manufacturing data volumes as core limiting factors (failure modes) towards DFM ineffectiveness during technology alignment and adoption efforts within an IDM. The causes for single-source root cause analysis are identified as the (i) varying metrology reference frames and (ii) test structures orientations that require wafer rotation prior to the measurements, resulting in varying metrology coordinates (die/site level mismatches). A generic coordinates mapping and alignment model (MAM) is proposed to remove these die/site level mismatches, however to accurately capture the emerging spatial variations, we have proposed a spatial positioning model (SPM) to perform multi-source parametric correlation based on the shortest distance between respective test structures used to measure the parameters. The (i) unstructured model evolution, (ii) ontology issues and (iii) missing links among production databases are found as causes towards our inability to exploit huge manufacturing data volumes. The ROMMII (referential ontology Meta model for information integration) framework is then proposed to remove these issues and enable the dynamic and efficient multi-source root cause analyses. An interdisciplinary failure mode effect analysis (i-FMEA) methodology is also proposed to find cyclic failure modes and causes across the business functions which require generic solutions rather than operational fixes for improvement. The proposed e-IDM, MAM, SPM, and ROMMII framework results in accurate analysis and modeling of emerging spatial variations based on dynamic exploitation of the huge manufacturing data volumes. La « conception pour la fabrication » ou DFM (Design for Manufacturing) est une méthode maintenant classique pour assurer lors de la conception des produits simultanément la faisabilité, la qualité et le rendement de la production. Dans l'industrie microélectronique, le Design Rule Manual (DRM) a bien <b>fonctionné</b> jusqu'à la technologie 250 nm avec la prise en compte des variations systématiques dans les règles et/ou des modèles basés sur l'analyse des causes profondes, mais au-delà de cette technologie, des limites ont été atteintes en raison de l'incapacité à sasir les corrélations entre variations spatiales. D'autre part, l'évolution rapide des produits et des technologies contraint à une mise à jour « dynamique » des DRM en fonction des améliorations trouvées dans les fabs. Dans ce contexte les contributions de thèse sont (i) une définition interdisciplinaire des AMDEC et analyse de risques pour contribuer aux défis du DFM dynamique, (ii) un modèle MAM (mapping and alignment model) de localisation spatiale pour les données de tests, (iii) un référentiel de données basé sur une ontologie ROMMII (referential ontology Meta model for information integration) pour effectuer le mapping entre des données hétérogènes issues de sources variées et (iv) un modèle SPM (spatial positioning model) qui vise à intégrer les facteurs spatiaux dans les méthodes DFM de la microélectronique, pour effectuer une analyse précise et la modélisation des variations spatiales basées sur l'exploitation dynamique des données de fabrication avec des volumétries importantes...|$|E
40|$|Massé, dans ses deux volumes (1946), discute le problème de la gestion optimale des lâchures dans le cas d'un seul réservoir quand le bénéfice est dérivé de la {{production}} d'énergie hydroélectrique. Massé obtint ses résultats à la fois par un raisonnement économique et par une généralisation du Calcul des Variations. Sa méthode lui permit de fournir la preuve rigoureuse de la méthode graphique de Varlet (1923), dite du "fil tendu". Dans cet {{article on}} généralise la procédure de Massé au cas où (1) le bénéfice est réalisé bien en aval du point de lâchure, et (2) il y a plusieurs "point-cibles" (points où un certain objectif doit être assuré). Massé avait trouvé que la gestion optimale est celle qui maintient la valeur marginale du bénéfice constante dans le temps, pourvu que la gestion soit en régime libre, c' est à dire tant que le réservoir ne <b>fonctionne</b> ni à plein ni à vide. Par contre si le réservoir <b>fonctionne</b> par exemple à plein, Massé montra que la stratégie qui consiste à garder le réservoir plein ne peut être optimale que si la valeur marginale du bénéfice croît constamment avec le temps durant la période où le réservoir reste plein. On montre de manière rigoureuse dans le cas général que pour une gestion optimale ce qui doit rester constant c' est la valeur marginale future du bénéfice. Dans un article ultérieur on fournira la généralisation pour plusieurs réservoirs. The problem for operations of reservoirs {{is to choose}} on a day to day basis {{the value of the}} release at the dam location. The choice of the value of that discharge is conditioned by a criterion of satisfaction of one or several objectives. These objectives are defined in one or several points in the system on the river, or the rivers, downstream from the point, or the points, of release. Typical objectives may be to maximize electric production, or to minimize damage due to flooding downstream from the dams or due to shortages of water in the rivers at diversion points for municipal water supply or other uses, etc. adapted to the concerns of the managers, and relatively intuitive. The approach described in this article pursues the reasoning of Massé (1946) but generalizes it and therefore makes it more applicable. At first we look at the case of a single reservoir, located directly on the stream for the production of electric energy. In this case the target-point (the point where an objective function is to be evaluated) coincides with the point of release. This was precisely the problem studied by Massé (1946) in his classical two volumes on "Reserves and the Regulation of the Future". We pursue his reasoning but we use a more appropriate mathematical procedure which will allow us to obtain more general results. The same results are derived using two different approaches. The first one is more intuitive and uses the concept of marginal value to secure the necessary condition of optimality to be satisfied by the releases. The second procedure is more mathematical and uses, basically, the method of Calculus of Variations, generalized to the case where there are inequality constraints that must be satisfied. In the case of a single reservoir one shows that the optimality condition provides the rigorous proof of the graphical method of Varlet (1923). The results of Massé are generalized to the case where the objective function is evaluated downstream from the point of release and the management strategy must account for the phenomenon of propagation of discharges in the streams. Again in this case the results are obtained in two ways, (1) by the economic reasoning on the marginal values and (2) with the Constrained Calculus of Variations. Massé had found that the optimal policy for the releases was the one that maintained the marginal benefit constant in time. That applied for the case of a single reservoir and where the target-point coincides with the point of release. If B{x(t),t} is the instantaneous benefit obtained from making the release at the dam at a rate x(t) at time t, then the optimality condition is mathematically: b{x(t),t}=L=constant with timewhere b{x(t),t} is the marginal benefit, i. e. the partial derivative of B{x(t),t} with respect to the argument x. L is a constant, which in the mathematical formulation of the problem is the Lagrange multiplier associated with the mass balance constraint to be satisfied over the selected horizon of operations. In other words the cumulative volume of releases over the time horizon must be equal to the cumulative volume of inflows plus the drop in reservoir storage between the initial and final times. Economically the marginal benefit is the incremental benefit realized by making an extra release of one unit of water, given that the rate of release was x(t). Typically the marginal benefit decreases as the rate of release increases and that {{is often referred to as}} the "law of decreasing returns". For the case of electric production the marginal benefit will depend on the amount of releases made through the turbines but also on the season of year or day of week or hour of day. The price of electricity is higher in winter than it is in summer. It is higher during peak hours during the week than it is on weekends, etc. If on the other hand the marginal benefit is only a function of the release, and not a function of time, then the constancy of the marginal benefit with time is equivalent to the constancy of the release with time. Optimality becomes synonymous with regulation, i. e. releasing at a constant rate. It is only under these conditions that the graphical method of Varlet is applicable. In the graphical domain of cumulative volume of releases versus time, the optimal "trajectory" is a straight line where such a strategy is feasible i. e. does not make the reservoir more than full nor less than empty. When the objective is evaluated at a point downstream from the point of release and the marginal benefit (or cost) has a seasonal character, neither the graphical procedure of Varlet nor the mathematical result of Massé apply. For this more general case the derived optimality condition states that it is no longer an instantaneous marginal benefit that must remain constant in time. What must remain constant in time is a time integrated and weighted value of the marginal benefit (or damage) between the time the release is made and a later time. That later time is the release time plus the memory of the propagation system. The memory time is the time that must lapse before an upstream release is no longer felt at the target point downstream. The longer the distance between the release point and the target-point the longer is the memory of the propagation system. At the downstream point the damage depends on the discharge at that point, which is of course related to the release rate but also to the lateral inflows in between from tributaries and on the amount of attenuation that happens between the point of release and the target-point downstream. The integrand at dummy integration time t' is the marginal damage at that time multiplied by the instantaneous unit hydrograph at that time. Mathematically the integrand is: f{q(t'),t'}*k(t'-t) where f is marginal damage, q(t') is discharge at target point and k(.) is instantaneous unit hydrograph of propagation between release and target points. This integrand is to be integrated between time t of the release and time t + M, where M is the memory of the system. It is that integral that we have called the "Integrated Marginal Future" (or IMF for short) value that must remain constant in time. That optimality condition applies as long as the trajectory remains in the feasible domain bounded by the constraints of the problem, the "interior domain". When on a bound, the IMF value does not remain constant but must vary monotonically in a given direction, i. e. increases or decreases with time, depending on the constraint on which the solution rests...|$|E
40|$|Polymer gears present several advantages: {{they can}} be used without lubricant, their meshing is silencer, {{resistance}} to corrosion is better, weight is reduced. However they have a poor heat resistance and are limited to rotation transmission. In order to improve the gears performance, glass fibre reinforcement is being increasingly used, where their lower cost and higher strength, compared to unreinforced polyamide, offer a potential increase in gear performance. Mechanical behaviour of polymers materials is very complex; it depends on time, history of displacement, temperature and for several polymers, on humidity. Moreover, an addition of fibres can make the material properties heterogeneous and anisotropic. The particular case of Polyamide 6 + 30 % glass fibres which is the most common fibre reinforced plastic is studied in this work. In {{the first part of this}} work, a mould was developed to better control the material choice and moulding conditions. Using tomographic observations, investigations were done to better understand the relation between moulding conditions, gears geometry and fibres orientation. Based on these observations and with the help of mechanical characterisation, a linear rheological generalized-Kelvin model was developed to simulate the viscoelastic behavior of the polymer material. In a second part, this model taking into account temperature, humidity and rotation speed is integrated in quasi-static load sharing computation developed by the LaMCoS laboratory. In the load sharing calculus, the displacements are obtained on a large meshing covering the entire surface of the tooth. This relation integrates the viscoelastic displacement, the fibre orientation and the geometrical influence coefficients. The method permits to obtain results such as the loaded transmission error, the instantaneous meshing stiffness, the load sharing and the root tooth stress at different temperature, humidity and rotation speeds within a reasonable computation time. Investigation have shown interesting results regarding the historic of displacements which represents up to 15 % of the total displacement at the tip radius, the localization of the maximal tooth root stress, which is the same than metal gears, or the influence of the thermal expansion toward transmission error. On another hand, we have highlighted the low difference between a realistic description of the fibre orientation and an homogeneous anisotropic one. The last step concerns the validation of the numerical. The measurements are carried out on a test bench developed at the LaMCoS laboratory. It provides two experimental results: the temperature of the gear during operation, and the load transmission error using optical encoders to measure the angular positions of the pinion and the gear. This one is global enough to validate the three steps of the model: geometry, kinematics and load sharing. Les engrenages en matériau polymère présentent de nombreux avantages par rapport aux aciers. Ils sont plus légers, résistants à la corrosion, <b>fonctionne</b> sans lubrifiant et leurs coûts de revient est moindre grâce au moulage par injection. Ils sont de plus en plus utilisés dans des domaines variés, mais se limitent à la transmission de mouvement. L’ajout de fibre de verre courte permet d’augmenter leur tenue mécanique et de diversifier leur domaine d’utilisation à des transmissions de petite à moyenne puissance. Le polyamide (Nylon) renforcé de fibres de verre est le composite le plus couramment utilisé dans le domaine des engrenages. Néanmoins, son comportement viscoélastique ainsi que la présence de fibres introduit une difficulté supplémentaire dans la modélisation. En outre, le comportement viscoélastique dépend de la température et pour le Polyamide, de l’humidité. Par conséquent, la viscoélasticité impacte directement la répartition des charges, l’erreur de transmission sous charge, la raideur d’engrènement. Dans cette thèse, une méthode numérique originale modélisant le comportement mécanique des engrenages en Polyamide 6 renforcé de fibre de verre est proposée. L’approche utilise le modèle rhéologique linéaire de Kelvin généralisé pour simuler le comportement viscoélastique du matériau et prendre en compte la température, l’humidité ainsi que le taux de fibre et leur anisotropie. Ensuite ce modèle rhéologique est intégré dans le modèle quasi-statique du partage des charges développé par le LaMCoS. Ce processus de calcul permet d’obtenir les résultats essentiels pour les engrenages (répartition des charges, pressions de contact, erreur de transmission sous charge, raideur d’engrènement) avec un temps de calcul assez court. Afin de de valider les modèles numériques développés, un banc d’essai a été mis en place, permettant la mesure de l'erreur de transmission et la visualisation de la température de l’engrenage pendant son fonctionnement...|$|E
40|$|Dans cette thèse nous présentons les résultats ainsi que la méthodologie adoptée pour la création d'un système d'analyse morphosyntaxique {{automatique}} et de lemmatisation sans dictionnaire des formes verbales monolexicales du grec moderne standard. Avec le modèle rétrograde MOSAIC (Koktova 1985) sur le chech comme point de départ, ainsi que d'autres modèles similaires sur le français (Caradec & Saada 1982) et le grec moderne (Lexifanis, Kotsanis & Maistros 1985), notre recherche a couvert 8. 485 lexèmes verbaux grecs, en prenant les données des dictionnaires les plus récents (Kyriacopoulou 1990, Iordanidou 1992, Kriaras 1995, Babiniotis 1998, Institut d'Études Néohelléniques 1998). Il a ainsi été créé: un nouveau système de conjugaison de 385 modèles qui sert à la génération automatique de tous les morphèmes lexicaux/radicaux ainsi que de toutes les formes flexionnelles monolexicales une base de données des séquences graphémiques finales qui permet l'attribution automatique de modèle de conjugaison à n'importe quel lemme verbal une base de données de 151. 527 séquences graphémiques finales, statistiquement établie et manuellement perfectionnée, qui peut s'employer pour la reconnaissance automatique de n'importe quelle forme verbale monolexicale et un système des règles morphophonologiques rétrogrades utilisées pour la lemmatisation linéaire des formes flexionnelles, qui <b>fonctionne</b> sur la base du nouveau système de conjugaison de 385 modèles. In this dissertation {{we present}} {{the final results}} of our 10 -year research on the Modern Greek verbal system. The objective of the research has been twofold: i) {{the development of a}} statistical database containing word-final grapheme sequences, which, on the basis of Koktova's (1985) retrograde analysis model MOSAIC, allow for the automatic morphosyntactic recognition (tagging) of all monolexical verbal forms of the language without any access to relevant electronic lexicons and ii) the development of a verb lemmatization morphophonological rule system, both providing various applications in all major areas of Text Processing as well as Teaching of Modern Greek Standard. Within this framework, 24 Mb of verbal linguistic data have been collected, generated and classified automatically, and manually checked and enriched. These have been submitted to the University {{in the form of an}} appendix. Only representative extracts appear in the dissertation. More specifically, they consist of: a) a file of 8, 485 Modern Greek verbal lemmas, developed in accordance with the evidence provided by the most recent dictionaries of the language (Dictionary of the Modern Greek Dhemotiki, Kriaras 1995, Greek Dictionary,Tegopoulos-Fytrakis 1993, Abridged Dictionary of Modern Greek, Pagoulatou Publ. 1991, Dictionary of Modern Greek, Babiniotis 1998 and Dictionary of Modern Greek Koine, Triantafyllidis Inst., Aristotle University of Thessaloniki 1998) b) a new conjugation system of 385 paradigmatic models, which allows for the automatic generation of all verbal stems and monolexical forms c) a file of 1 st person singular word-final grapheme sequences, which allows for the automatic attribution of paradigmatic model codes to any verbal lemmas of the language d) a file of 27, 383 verbal stems characterized solely on the basis of their conjugation model and their permissible suffix set e) 103 files of 519, 694 automatically generated and classified verbal forms f) 17 files of 151, 527 word-final grapheme sequences, which declare the conjugation model, morphosyntactic content, absolute frequency and lemmatization code of verbal forms g) a linear lemmatization morphophonological rule system, which functions on the basis of the newly developed 385 conjugation model system. More analytically, in the 1 st chapter we discuss the role which morphological lexicons and statistical approaches play in the automatic morphosyntactic recognition of word tokens (tagging). In the 2 nd chapter we discuss the Modern Greek verb system, including a brief description of the vocabulary of the language (Katharevousa-Dhemotiki) : the morphosyntactic categories marked, the conjugation system as presented in various grammatical descriptions over the last 40 years, the verbal stems and inflectional affixes involved, the stress pattern, the external/internal augment and reduplication occurrences, as well as the 2 most recently developed conjugation systems (Kyriacopoulou 1990 and Iordanidou 1992), in an effort to account for the need of developing a new conjugation system. In the 3 rd chapter we describe the methodology employed for the collection and processing of data, whereas in the 4 th chapter we present extensive extracts from the 10 databases developed all together. A pilot application of the proposed language tool is available on the Internet and can be found on the site of the Language and Education Technology Laboratory of the University of Athens Informatics/Telecommunications Department. ...|$|E
40|$|International audienceThe parent–child {{attachment}} is {{an emotional}} bond between the child and his mother, or his father, who allows it to use her, or him, as a safety haven, when in distress, {{and then as a}} security base from which it can explore again when the danger has disappeared. Initially focused on the mother–child dyad, attachment theory then spread to the one established by the father and his child, then a set of figures closed to the child (brothers, sisters, grandparents, peers, and so on.). Today, more than 30 years after its initial empirical validation, the parent–child attachment is still interviewing scientists. Meanwhile, another theory involves research in psychology, the family system. Consisting of interacting elements, the family functions as a system and is also the first milieu in which steeps the child. The junction between the two theories is widely desired, and many are the authors who seek to understand the influence of intra-family relations on the quality of parent–child attachment. These relationshipsinclude marital relations, co-parenting, parent–child and sibling relationships. We propose here to take stock of all the researches that have studied the impact of each of them on the quality of parent–child attachment. This work is part of an eco-systemic perspective and is an important step toward a systemic approach, taking into account the dynamics of all family relationships. L'attachement parent–enfant constitue un lien affectif entre l'enfant et sa mère ou son père, qui lui permet d'utiliser celle-ci, ou celui-ci, comme un port de sécurité lorsqu'il est en situation de détresse, puis comme une base de sécurité à partir de laquelle il peut à nouveau explorer lorsque le danger a disparu. D'abord focalisée sur la dyade mère–enfant, la théorie de l'attachement s'est ensuite étendue à celle constituée par le père et son enfant, puis à un ensemble de figures proches de l'enfant (frères, soeurs, grands-parents, pairs, etc.). Aujourd'hui, plus de 30 ans après sa validation empirique initiale, l'attachement parent–enfant interroge encore la communauté scientifique. Parallèlement, la théorie du système familial nous enseigne que, constituée d'éléments en interaction, la famille, premier milieu dans lequel baigne l'enfant, <b>fonctionne</b> comme un système. Ainsi la jonction entre ces deux modèles théoriques est-elle largement souhaitée et nombreux sont les auteurs qui la sollicitent afin de comprendre l'influence des relations intrafamiliales sur la qualité de l'attachement parent–enfant. Ces relations incluent les relations conjugales, coparentales, parent–enfant et les relations fraternelles. Nous nous proposons ici de faire le point sur l'ensemble des recherches qui ont étudié l'impact de chacune d'elles sur la qualité de l'attachement parent–enfant. Ce travail s'inscrit dans une perspective écosystémique et constitue une étape importante vers une approche systémique de l'attachement, prenant en compte la dynamique de l'ensemble des relations familiales. Abstract The parent–child attachment {{is an emotional}} bond between the child and his mother, or his father, who allows it to use her, or him, as a safety haven, when in distress, and then as a security base from which it can explore again when the danger has disappeared. Initially focused on the mother–child dyad, attachment theory then spread to the one established by the father and his child, then a set of figures closed to the child (brothers, sisters, grandparents, peers, and so on.). Today, more than 30 years after its initial empirical validation, the parent–child attachment is still interviewing scientists. Meanwhile, another theory involves research in psychology, the family system. Consisting of interacting elements, the family functions as a system and is also the first milieu in which steeps the child. The junction between the two theories is widely desired, and many are the authors who seek to understand the influence of intra-family relations on the quality of parent–child attachment. These relationships include marital relations, co-parenting, parent–child and sibling relationships. We propose here to take stock of all the researches that have studied the impact of each of them on the quality of parent–child attachment. This work is part of an eco-systemic perspective and is an important step toward a systemic approach, taking into account the dynamics of all family relationships...|$|E
40|$|Second person narratives” {{may often}} be experimental, but are hardly new. The forms they take today {{are just the}} latest in a long history that {{stretches}} back to our earliest records of written English narratives. This dissertation traces the various forms they have taken in the past and the criticism they have provoked, exploring the historical links between narratorial apostrophe, indefinite or generic “you” address, and “experimental” uses of second person. This dissertation argues that what many theorists of narrative call “second person fiction” can no longer be limited to texts which use the pronoun “you” to designate a fictional protagonist. While examples of such texts date back at least as far as the 19 th century (Nathaniel Hawethorne provides one notable early example), and sections of longer texts have used this technique as early as the 17 th century, interest in 2 nd person protagonist fiction mounted in the latter half of the 20 th century. As authors like Butor, Perec, and Calvino found international critical success, experimenting with second person became almost a rite of passage for many writers, spawning hybrid and partial forms of use. Moreover, second person use once considered experimental has become commonplace in contemporary fiction – both literary and mainstream. Part One examines narratorial apostrophe, first in several Old English texts and then in a range of texts from the 13 th century to the 17 th, when, with the influence of continental linguistic habit, writers for a time had a choice of second person pronouns: the quotidian “thou,” the socially formal “you,” and the plural “ye. ” A brief inquiry into how pronoun use adapted to social, political, and cultural changes closes with a study of the use of second person in texts by Sterne, Kirkland, and Fielding. The fluctuating use of “thou” and “you” in these 18 th texts seems by turns to indicate reference to an ideal or “textual reader” (Mieke Bal), and to a growing awareness on the part of these writers of a wider audience now present with the advent of mass production and distribution of literary texts: an audience at once unknown and in control of authors' financial success. Part Two explores how writers in the 19 th century adapted narratorial apostrophe to the general disappearance of “thou” and how perceptions of their reading audience might have been related. More importantly, this section examines the increasing use of indefinite “you,” especially in the U. S., in 19 th century texts by Melville and Hawethorne. Increasing use of indefinite “you” – and the creation of a “generic narrattee” capable of becoming an actor on certain narratological levels of a text – opened the door for the “you” protagonist. Part Three examines 20 th century critics' early responses to second person protagonists, tracing reactions from the New Critics through Poststructuralism, and finally through the work of several contemporary narratologists. The increasing volume of “second person fictions” being produced in the latter half of the 20 th century caused theorists like Genette, Fludernik, and Bal to reexamine and revamp traditional narratological “levels” of texts, and to examine how integral metalepse has become to contemporary fiction. Finally, this dissertation asks how we might place texts which increasingly use a mix of indefinite “you,” apostrophe, and other more complex forms of second person within a traditional narratological framework. A synthesis of Greimas, Bremond, and Ricoeur is useful for diagramming what author-reader-character relations are indicated by such use, in a time where, according to linguist Eric Hyman, indefinite “you” may be fast becoming the unmarked use of the pronoun. We also examine a more general perspective on the dialogical relations of locuteur and interlocuteur, identification and alterity with fictional figures through the writings of Martin Buber, Kaya Silverman, and Mark Currie. Part Four uses the narratological schema developed in part three to examine several contemporary fictions not normally considered “second person fiction. ” Finally, I examine how the increasing use of second person in contemporary fiction isn't limited to French and American writers, but is also increasingly present in the work of foreign writers who work in English or French. Cette thèse analyse les fonctionnements de la deuxième personne dans la littérature anglaise et nord américaine de 1750 à 2000. Après avoir démontré comment elle <b>fonctionne</b> comme système chez des romanistes britanniques du 18 ème siècle et de diviser ses usages en catégories, elle trace les développements de son usage en commençant avec son apparition dans les premières écritures nord américaines. Elle la suivra jusqu'à la fin du vingtième siècle, avec une concentration sur la littérature contemporaine et son évolution depuis les années quatre-vingts. La thèse part de l'idée que la narration d'un auteur à ses lecteurs en utilisant “you” est plus directe et crée une relation particulière entre auteur et lecteur qui est en train de se développer de plus en plus dans la littérature contemporaine, notamment en Amérique. Enfin, elle explique comment ça a un lien direct avec les communications en général entre les gens de cette fin du siècle: des communications qui sont á la fois plus direct et plus compliqué. Elle traite aussi de la comparaison de cet usage en anglais et en français, en vue de montrer des différences entre la relation auteur-lecteur dans les deux langues...|$|E
40|$|Despite {{the growing}} {{strength}} of commercial broadcastingmedia, public service broadcasting (PSB) {{remains at the}} core of Europe's cultures and economies. Currently, three PSB outlets - BBC, France Television and RAI - lead revenue generation in this growing Europe-wide sector, and lead in terms of audience and cultural influence within all the other media in their respective countries. But PSB's fiscal vigour aside, Europe's emerging new-media landscape, defined by novel moral codes embedded in the programming and innovative forms of interactive production and distribution, is arguably transforming the debate around the principles that sustain public television's legitimacy. Generally associated with social-democratic ideals, PSB's traditional legitimating principles were nonetheless aligned with particular types of morally conservative views. John Reith, the BBC's first director, was arguably the moral programmer of PSB in Europe (Hodkinson, 2011), initially set up to "improve society's knowledge, taste and moral awareness" (cf. Reith's claim in 1924, cited in Hodkinson, p. 285). PSB's enlightened claim to the monopoly of reason and "quality" implied a protection from commercial involvement and competition, and the necessity to achieve a universalised character among the population. Reith's perspective bears an interesting yet complicated relation with the ideas of Pierre Bourdieu (1993; 1996), for whom "quality" is never objective but reflects class divisions, a concern to mitigate the contradiction between the production of democracy and massive dissemination of new meanings throughout market structures. Due to its structural attachment to audience ratings, television is profoundly subject to market pressures, institutionally incapable of progressively affecting the symbolic order of society. Clearly influenced by Bourdieu, the still abiding debate about PSB pivots on "quality" and "market pressures," echoing as well the Habermasian notion of the public sphere, according to which Europe's PSB "has to" aim at informing rational debate. At the same time, proponents of commercial television discursively associated the structural search for "audiences" with a democratic sense of the collective. They portrayed PSB as misaligned with the actual civil sphere, arrogantly imposing undemocratic yet politicized benchmarks of "quality. " PSB's proponents traditionally argue that "commerce," the primary objective of private television, is in itself de-attached from the collective principle of the civil sphere for it promotes a type of programming oriented to short-term individual preferences - escapist forms of entertainment and sensationalist yellow journalism that appeal to negative emotions - and not to long-term goals and processes that foster civil-sphere solidarity. From the emergence in the 1980 s of a dual nature in Europe's television market - "audience" constructed as society, "more rational" vs commercial content - there arose during the 1990 s a new internal language around the material fragmentation of audiences and programmes due to the multiplication of options and channels. This fragmentation and the new organizational language have not disconnected the institution of television from the universalistic character of the civil sphere. But the relationship between the civil sphere and television has indeed changed. We can outline this change along three axes. First, given the redefinition of the internal logic of television production and reception within a new context of technological transformation, de-regulation and market liberation, and of globalization along with audience fragmentation, the post-consensus system is discernible by the creation and legitimation of new televisual forms that transcend the traditional imperative to appeal to the broadest possible "audiences," understood as a commercial and political construct. Second, {{a significant portion of the}} commercial-television industry operates according to an amplified quantitative logic in terms of viewership through overtly exaggerated narratives, judgments and dubious journalistic practices. Third, the Internet and content digitization provide for dispersed, previously "voiceless" agents of the civil sphere with a mass-media production and distribution platform that is potentially more participatory and "grassrooted" (Freedman, 2000). The objective of this paper is to propose a coherent set of theoretical and methodological tools to explain the emerging cultural dynamics of the institution of television in Europe. We wish to illuminate the changing structure of the public vs commercial TV debate through the lens of Alexander's theoretical concept of the civil sphere. Alexander (2006) argues for a sociological theory of the civil sphere defined by its relative autonomy from political and economic interests. At the core of the civil sphere, we find the institutions of communication, which contribute to the collective feelings of solidarity around ideals of community and justice, empathy and integration. Such institutions frame the debate of civil society through discourses and institutions, providing universalistic civil codes for democratic critique, action, reform and also exclusion. The civil sphere operates as a skeletal structure of binary codes for opposed civil and anti-civil human "motives," social "relations" and "institutions," and of corresponding categories: "pure" or "impure," as in "the discourse of liberty" as opposed to "the discourse of repression. " The positive codes represent the "sacred" and the "civic" while their opposites stand for the "profane" and the "anti-civic" insofar as they emerge from extra-civil spheres such as markets, states, sections or parties. In the first part of this paper, we describe Alexander's civil sphere, establishing the study of the debate between public and commercial television as a particular way of encoding the discourse of civil society. In the second part, we use this theoretical framework to examine the discourses appearing in both mainstream and alternative Spanish media in regard to crucial events in Spanish PSB's limelight: the audio-visual sector reform proposed by the Government in June 2005, the intent of the Board of Directors of RTVE to control the news in September 2011, and the recent announcement by the government to reduce state funding to RTVE. This empirical investigation suggests that the emerging forms of discursive legitimation of both private and public television are now mediated by both the civil sphere and "civil television," signified and materialized by the Internet. Both private and public television try to associate with these cultural structures, in a process that is condensed in the emergence of a new concept of "audience" which is not based on rationalistic principles of taste but on the generation of collective expectations as a cultural experience per se. Public television's renewal may thus emerge in the convergence of the commercial, the public and the civil. La télévision publique, commerciale et civile dans le paysage européen des nouveaux médias Malgré la force croissante des médias commerciaux, les services publics de l'audiovisuel (PSB) restent au cœur de la culture et de l'économie en Europe. Actuellement, trois de ces chaînes publiques - BBC, France Télévisions et la RAI - génèrent des revenus conséquents dans ce secteur en pleine croissance à l'échelle européenne, et entraînent, notamment grâce à leurs audiences, une influence culturelle indiscutable dans chacun de ces pays. Mais la loi fiscale entrée en vigueur, l'émergence des nouveaux médias et les formes innovantes de production interactive et de distribution posent avant tout le débat de la légitimité de la télévision publique et des principes qui la sous-tendent. Généralement associé à des idéaux sociaux-démocrates, le service public traditionnel a souvent été le fruit d'une politique conservatrice et morale. John Reith, premier directeur de la BBC, a été sans doute le créateur de ce service public en Europe (Hodkinson, 2011), qu'il avait initialement mis en place pour "améliorer la connaissance de la société, le goût et la conscience morale" (cf. Reith, en 1924, cité dans Hodkinson, p. 285). Le rayonnement du service public se réclamant du monopole de la raison et de la "qualité", il devient une protection contre la récupération commerciale et contre la concurrence, et participe de la nécessité de construire un portrait-type de la population, dans lequel tout le monde puisse se reconnaître. La perspective de Reith porte un regard intéressant sur les idées de Pierre Bourdieu (1993, 1996), pour qui la "qualité" n'est jamais objective mais reflète les divisions de classe, dans un souci d'atténuer la contradiction entre la production de la démocratie et la diffusion massive de nouvelles significations à travers les structures du marché. En raison de son attachement à la structure d'audience, la télévision est profondément soumise aux pressions du marché, et institutionnellement incapable d'affecter progressivement l'ordre symbolique de la société. Clairement influencé par Pierre Bourdieu, le débat reste centré sur le service public, la "qualité" et "les pressions du marché", faisant ainsi écho à la notion habermassienne de la sphère publique, selon laquelle le service public de l'Europe doit viser à éclairer le débat rationnel. Dans le même temps, les promoteurs de la télévision commerciale sont discursivement associés à la recherche de structure pour " le public " avec un sens démocratique de la convention collective. Ils ont dépeint le service public tel qu'une structure mal alignée avec la sphère civile réelle, imposant des repères qualitatifs avec une arrogance assez antidémocratique. Les partisans du service public soutiennent traditionnellement que le "commerce", l'objectif principal de la télévision privée, est attaché en soi au principe de collectivité de la sphère civile. Elle est destinée à favoriser un type de programmation orienté à court terme selon les préférences individuelles - les formes d'évasion de divertissement et de sensationnalisme journalistique qui font appel à des émotions négatives - et non pas à long terme selon des objectifs et des processus qui favorisent la sphère civile de solidarité. Depuis l'émergence dans les années 1980 au sein du marché télévisuel européen d'une certain dualité entre l'"audience" telle qu'elle est construite par la société et le contenu commercial, il se développe pendant les années 1990 une nouvelle forme de langage orientée autour de la fragmentation matérielle des audiences et des programmes, dû à la multiplication des de l'offre et des chaînes. Cette fragmentation et le nouveau langage organisationnel n'ont pas déconnecté la télévision en tant qu'institution de l'universel portrait-type de la sphère civile. Mais la relation entre la sphère civile et la télévision a incontestablement changé. Nous pouvons expliquer ce changement selon trois axes distincts. Premièrement, étant donné la redéfinition de la logique interne de la production télévisuelle, sa réception dans un nouveau contexte de transformation technologique, la déréglementation et la libéralisation du marché, la mondialisation, ainsi que la fragmentation des auditoires, le système post-consensus est perceptible par la création et la légitimation de nouvelles formes télévisuelles qui transcendent l'impératif traditionnel et qui appellent au public le plus large possible qui doit être compris comme une construction commerciale et politique. Deuxièmement, une partie importante de l'industrie commerciale de la télévision <b>fonctionne</b> selon une logique quantitative amplifiée en termes de téléspectateurs, à travers des récits ouvertement exagérés, mais aussi des jugements et des pratiques journalistiques douteuses. Troisièmement, la numérisation et le développement du contenu Internet ont fourni à des agents de la sphère civile auparavant "sans voix" un accès à l'information grâce à des plateformes de distribution qui sont potentiellement plus participatives et terre à terre (Freedman, 2000). L'objectif de ce papier est de proposer un ensemble cohérent d'outils théoriques et méthodologiques pour expliquer la dynamique culturelle naissante de la télévision institutionnelle en Europe. Nous souhaitons mettre en lumière la structure changeante du débat public face à la télévision commerciale, à travers la lentille du concept théorique de la sphère civile selon Alexandre. Alexandre (2006) plaide en faveur d'une théorie sociologique de la sphère civile définie par son autonomie par rapport aux intérêts politiques et économiques. Au cœur de la sphère civile, on trouve des institutions de communication, qui contribuent aux sentiments collectifs de solidarité autour des idéaux de communauté et de justice, et qui favorisent l'empathie et l'intégration. Ces institutions permettent de recadrer le débat de la société civile à travers les discours et les institutions, fournissant à la critique démocratique des codes civils universels. La sphère civile <b>fonctionne</b> comme une structure squelettique de codes binaires qui opposent les motivations civilisées aux non-civilisées, le relations" sociales " aux "institutions", et leurs catégories correspondantes : "pur" ou "impur", comme dans "le discours de la liberté "plutôt que" le discours de la répression ". Les codes positifs représentent le" sacré "et le" civique ", tandis que leurs opposés représentent le" profane "et l'" anticivique "dans la mesure où ils émergent de domaines extra-civils tels que les marchés, les Etats, les sections ou les partis. Dans la première partie de cet article, nous décrivons la sphère civile d'Alexandre, et établissons un débat entre la télévision publique et commerciale en étudiant l'encodage du discours de la société civile. Dans la seconde partie, nous utilisons ce cadre théorique pour examiner les discours apparaissant dans les deux grands médias de service public espagnols ainsi que dans les médias alternatifs. Nous nous focaliserons sur les évènements qui ont été dans le feu des projecteurs des médias espagnols: la réforme du secteur audiovisuel proposé par le gouvernement en Juin 2005, l'intention du conseil d'administration de la RTVE de contrôler l'information en Septembre 2011, et l'annonce récente par le gouvernement de la réduction du financement public à la RTVE. Cette étude empirique suggère que les formes émergentes de légitimation discursive des télévisions publique et privée sont désormais inspirées à la fois par la sphère civile et par la "télévision publique", comme on peut l'observer grâce au phénomène de l'internet. Les formes privées et publiques de télévision tentent de s'associer à ces structures culturelles, selon un processus qui se condense dans l'émergence d'un nouveau concept de "public" qui n'est pas basé sur des principes rationnels de goût, mais sur la génération d'attentes collectives comme expérience culturelle. Le renouvellement de la télévision publique peut donc émerger dans la convergence de la publicité, du public et du civil...|$|E
40|$|This {{research}} {{essay is}} a critical analysis of two drag queen performers on the U. S. televised show RuPaul's Drag Race: Season 3 (RPDR). Focusing on two queer Asian identified queens, this essay understands the drag performances as multifaceted performances of identity that work to disidentify with hegemonic and heterosexist norms. Situated within a U. S. media context, these performances conflict with stereotypical portrayals {{of gay and lesbian}} life in U. S. media (Fejes & Petrich, 1993). Disidentifying performances by these two queers of color are important because they offer a worldview outside the stereotypical, gay, middle-class white male depiction of queer realities in T. V. drag performances by queers of color call into question the performative components of identity and identity construction. Race, ethnicity, gender, sexuality, and social class are reinterpreted and transformed through these performances. The performances of these two queens are important because they claim queer space through their incessant intersectionality. Focusing on Axis 4, "Communication Between Cultures: Another Globalization?" this essay addresses the power of queer media spaces and queer representations. The paths for intercultural communication through media are not as clear-cut as standardization (essentialism) or diversity (quotas), but rather should be a path of intersections that allow for transformation and new significations and representations in media. Using disidentification (Muñoz, 1999), queer theory, critical race theory, and thick intersectionality (Yep, 2010), this research essay offers an analysis of RPDR portrayal of two Asian identified queens: Raja and Manila Luzon. The focus is upon these two queens because each disidentify with components of their identity differently, and because both were in the finale to win the title of "America's Next Drag Superstar. " Both queens identify as gay, male, and Asian. However, each enacts these complex intersections of identity in strategic ways. Therefore, this essay engages the identities of the two queens as portrayed in RPDR to understand the fluidity and performative nature of identity within a queer counterpublic. The queer identity is usually found at the periphery of the norm in resistance to societal norms. Yep (2010) writes, "in a broader sense 'queer' signifies nonnormativity" (p. 36). The drag performances of the two queens are specific embodiments of this resistance as they personify queer resistance to heterosexist and gender norms. As a mode of disrupting hegemonic understandings of identity, Muñoz (1999) writes, "Disidentification is the third mode of dealing with dominant ideology, one that neither opts to assimilate within such a structure nor strictly opposes it [...] . a strategy that works on and against dominant ideology" (11). Thus, a disidentifying identity attempts to inhabit standardized identity performances to transform the structure from within. Drag queens of color employ a disidentificatory tactics to recreate identity and expose the slippage of monolithic identities. The disidentifying queer, in order to create disidentification, uses strategic discourse to change the ideological rigidity of norms and monoliths. RPDR is corporately sponsored, but still chips away at norms that inform dominant understandings and portrayals of queer reality. Muñoz (1999) confirms that sanitized drag can be seen in mainstream media, but, "there is also a queerer modality of drag that is performed by queer-identified drag artists in spaces of queer consumption" (p. 99). Since RPDR is broadcast on a queer network, it does work to affirm a queer counterpublic, or group "that contest the hegemonic supremacy of the majoritarian public sphere" (Muñoz, 1999, p. 11). RPDR is a competition in which men dress and perform in drag to embody femininity to question the social constructs of gender. Through performance, drag displays a range of queer identities to the audience. Drag is complicated because bodies are always situated into discourse through competing and conflicting identities and histories. Therefore, these performances are made much more complex through thick intersectionality as, "the discourses of race, gender, and sexuality work not as separate entities but within and through each other" (Moreman & McIntosh, 2010, p. 116). The way that identities are enacted, performed, and exposed during the drag performances of these queens provides a space for practioners of queer and critical race theory to understand these complex performances of identity. People of color must use survival strategies to cope with the hegemonic structure of a U. S. Western society and discourse that privileges the identity of the white, Judeo-Christian, heterosexual male. These survival techniques are multiplied and intensified when that person of color also identifies as queer. Queers of color find a special home in performing drag because drag allows queers of color to create schisms between the categories of identity through their intersectionality. Drag queens of color specifically employ disidentificatory tactics to recreate identity and expose the slippage in racial tropes. Moreman and McIntosh write, " [...] . Race, like gender, is a fiction [...] . [and] these racial repetitions offer possibilities for interruptions that might resist foreclosure. These interruptions [...] . denormalize race and open up rescriptings for how race can be re-understood outside of, say, an American structure of racial feeling" (123). These identity markers, when understood outside the somatic, lend space for transformative and disidentificatory performances of self to resist the norm. Performances of disidentification situate themselves in counterpublics. Counterpublics are as diverse in their intersecting identities as the performances that create them. Queers of color perform a range of disidentifications that resonate in counterpublics and cannot be reduced to U. S. white/black binary discourse, as counterpublic creation is outside normative binaries. Moreman and McIntosh write, "[the] brown body performs between black and white, confounding dichotomies by identification with other 'others' such as the categorically difficult Latina/o, Filipina/o, Middle Eastern and South Asian" (123). In the separation of the binaries that describe race, the Asian queer body is a site of possibility. Although it may be defined by what it is not (white), the Asian body holds many possibilities to signify multiple intersecting identities and transforming the meanings and confines of identity. Using this foundation, this essay explores three main areas of these Asian drag performances: utilizing Blackness as a route to Whiteness, performance as disidentification of heterosexist desire norms, and employing stereotypes to critique the often invisible identity of Whiteness. Cet essai de recherche est une analyse critique de deux artistes de drag queens sur Drag Race aux États-Unis télévisée spectacle RuPaul de: Saison 3 (RPDR). Mettre l'accent sur deux reines asiatiques bizarres identifiés, cet essai comprend les spectacles drag que des représentations multiples de l'identité que le travail à désidentifier avec les normes hégémoniques et hétérosexiste. Situé dans un contexte américain des médias, ces conflits performances avec représentations stéréotypées de la vie gay et lesbienne dans les médias américains (Fejes & Petrich, 1993). Performances Disidentifying par ces deux pédés de couleur sont importants car ils offrent une vision du monde en dehors de la stéréotypée, gay, de la classe moyenne représentation mâle blanc des réalités homosexuelles dans les spectacles drag TV par pédés de couleur appel en question les éléments performatifs de l'identité et la construction identitaire. Race, l'ethnicité, le sexe, la sexualité, et la classe sociale sont réinterprétées et transformées par ces performances. Les performances de ces deux reines sont importants parce qu'ils prétendent l'espace étrange à travers leur intersectionnalité incessante. En se concentrant sur l'axe 4, "La communication entre les cultures:? Une autre mondialisation" cet essai traite de la puissance des espaces médias et les représentations queer queer. Les chemins de la communication interculturelle à travers les médias ne sont pas aussi tranchée que la normalisation (essentialisme) ou de la diversité (des quotas), mais devrait plutôt être un chemin d'intersections qui permettent de transformation et de nouvelles significations et des représentations dans les médias. Utilisation de désidentification (Muñoz, 1999), la théorie queer, la théorie critique de la race, et l'intersectionnalité épaisse (Yep, 2010), cet essai de recherche propose une analyse de la représentation de deux RPDR asiatique identifié reines: Raja et Manille Luzon. L'accent est mis sur ces deux reines, car chaque désidentifier avec des composants de leur identité différemment, et parce que les deux étaient dans la finale pour remporter le titre de "Superstar en Amérique du Drag Suivant. " Les deux reines s'identifient comme gay, hommes, et d'Asie. Cependant, chaque édicte ces intersections complexes de l'identité de manière stratégique. Par conséquent, cet essai en prise avec les identités des deux reines que dépeintes dans RPDR à comprendre la fluidité et la nature performative de l'identité au sein d'une drôle de counterpublic. L'identité bizarre se trouve généralement à la périphérie de la norme de résistance aux normes sociales. Yep (2010) écrit: "dans un sens plus large" queer "signifie nonnormativity" (p. 36). Les performances de traînée des deux reines sont des réalisations spécifiques de cette résistance comme ils personnifient la résistance queer à des normes hétérosexistes et le sexe. Comme un mode de perturber la compréhension hégémoniques de l'identité, Muñoz (1999) écrit: "désidentification est le troisième mode de traiter avec l'idéologie dominante, celle qui opte ni à assimiler dans une telle structure ne s'oppose strictement il [...] . une stratégie qui <b>fonctionne</b> sur et contre l'idéologie dominante "(11). Ainsi, une identité disidentifying tente d'habiter les performances d'identité normalisées pour transformer la structure de l'intérieur. Faites glisser les reines de couleur emploient une tactique disidentificatory pour recréer l'identité et d'exposer le glissement des identités monolithiques. Le drôle de disidentifying, afin de créer désidentification, utilise le discours stratégique de changer la rigidité idéologique des normes et des monolithes. RPDR est parrainé corporative, mais encore loin à puces normes qui informent la compréhension et les représentations dominantes de la réalité queer. Muñoz (1999) confirme que la traînée désinfectés peuvent être vu dans les médias traditionnels, mais, "il ya aussi une modalité de plus étrange traînée qui est effectuée par des artistes drag queer identifiés dans les espaces de consommation queer" (p. 99). Depuis RPDR est diffusée sur un réseau bizarre, il <b>fonctionne</b> à affirmer un pédé counterpublic, ou d'un groupe "qui contestent la suprématie hégémonique de la sphère publique majoritaire" (Muñoz, 1999, p. 11). RPDR est une compétition dans laquelle les hommes s'habillent et effectuer de la traînée d'incarner la féminité à la question des constructions sociales de sexe. Grâce à la performance, la traînée affiche un ensemble d'identités queer à l'auditoire. Drag est compliquée parce que les corps sont toujours situés dans le discours à travers les identités concurrentes et contradictoires et des histoires. Par conséquent, ces performances sont beaucoup plus complexes par le biais intersectionnalité épais que, "les discours de la race, le sexe, la sexualité et le travail non pas comme des entités distinctes, mais dans et à travers les uns des autres" (Moreman & McIntosh, 2010, p. 116). La façon dont les identités sont adoptées, effectuées, et exposé lors des représentations de traînée de ces reines fournit un espace pour les praticiens de la théorie queer et la race essentiel de comprendre ces performances complexes de l'identité. Les personnes de couleur doit utiliser des stratégies de survie pour faire face à la structure hégémonique d'une société aux États-Unis de l'Ouest et le discours que les privilèges de l'identité du blanc, judéo-chrétienne, homme hétérosexuel. Ces techniques de survie sont multipliées et intensifiées lorsque cette personne de couleur identifie également comme queer. Queers de couleur à trouver une maison particulière dans l'exercice de glisser, car la traînée permet pédés de couleur pour créer des schismes entre les catégories de l'identité à travers leur intersectionnalité. Faites glisser les reines de couleur spécifiquement emploient des tactiques disidentificatory pour recréer l'identité et d'exposer le glissement dans les tropes raciales. Moreman et McIntosh écrire, " [...] . la course, comme le sexe, est une fiction [...] . [et] ces répétitions raciales offrent des possibilités pour les interruptions qui pourraient résister à la forclusion. Ces interruptions internautes dénormaliser la race et d'ouvrir rescriptings sur la façon dont la race peut être re-compris en dehors de, disons, une structure américaine de sentiment racial "(123). Ces marqueurs de l'identité, quand il est compris en dehors de la somatique, prêter l'espace pour les spectacles de transformation et de disidentificatory auto pour résister à la norme. Performances de désidentification se situer dans contre-publics. Counterpublics sont aussi divers dans leurs identités se croisent comme les performances qui les créent. Queers de couleur effectuer une série de disidentifications qui résonnent dans les contre-publics et ne peut être ramené à US blanc / noir binaire discours, que la création est à l'extérieur counterpublic normative binaires. Moreman et McIntosh écriture, "[l] corps brun effectue entre noir et blanc, les dichotomies de confusion par l'identification avec les autres" des autres tels que l'catégoriquement difficile Latina / o, Philippine / o, Moyen-Orient et l'Asie du Sud "(123). Dans la séparation des binaires qui décrivent la race, le corps asiatique queer est un site de possibilité. Bien qu'il puisse être définie par ce qu'elle n'est pas (blanc), le corps d'Asie détient de nombreuses possibilités pour signifier plusieurs identités se croisent et la transformation des significations et confins de l'identité. L'utilisation de ce fond de teint, cet essai explore trois domaines principaux de ces performances drag asiatiques: l'utilisation de Blackness comme un moyen de blancheur, la performance, la désidentification des normes hétérosexistes désir, et en employant des stéréotypes à la critique de l'identité souvent invisibles de la blancheur...|$|E
40|$|Cette étude s’attache à comprendre ce qu’est un habitat seigneurial {{secondaire}} en Hainaut à la fin du Moyen Age et aux Temps Modernes. La disparition de la plupart des résidences de la haute noblesse en Hainaut, nous a amenée à nous pencher sur l’étude des habitats de la petite noblesse, dont le manque de reconnaissance, entrainant la démolition ou les transformations irréversibles de ces habitats, rend ces édifices sujets à l’oubli. Ajoutons à cela que, victimes d’une tradition castrale héritée du 19 e siècle, archéologues et historiens de l’art ont bien souvent eu leur attention d’abord attirée par les grands châteaux et donc la haute noblesse, laissant de côté toute une tranche de la population noble et de leurs possessions. Notre étude a comme objectif majeur de comprendre comment ces habitats ont <b>fonctionné</b> comme structures de vie, mais aussi comme des architectures à travers lesquelles et par lesquelles les habitants pouvaient exprimer leurs identités. Dans cette optique, après avoir considéré les différents types architecturaux (types de plans, types de corps de logis, types de tours), suivant une typo-chronologie, nous considérons les matériaux utilisés et la distribution intérieure de ces édifices. Ce sont ensuite les entourages de l’habitat en tant qu’espace construit, leur situation dans le paysage, et {{par rapport}} au relief, à l’hydrographie, aux villages, aux terres de cultures, et aux réseaux de communication, qui occupent une grande partie de l’étude. Les liens avec leurs habitants, ces membres de la « petite noblesse » sont ensuite considérés. Leurs fonctions, leurs origines et leurs zones de déplacements sont abordés, afin de mieux percevoir le rôle et la détermination de ce groupe social, qui s’avère être en rupture avec la haute noblesse. L’opposition traditionnelle entre villes et campagnes est dépassée, de même que la question des maisons principales et secondaires, au profit d’une approche plus fluide, favorisant une interaction entre villes et campagnes, et considérant les mouvements de population émergeant de l’un ou l’autre milieu. La partie interprétative suit ensuite, permettant d’aboutir à une caractérisation de ce type d’habitat. Le but est notamment de mettre en lumière la relation entre les aspects défensifs et résidentiels des édifices. Pour ce faire, les éléments de défense active et passive sont examinés, ainsi que le degré d’efficacité de ces structures. La suite de cette partie a pour but de replacer les habitats de la petite noblesse dans le contexte des types architecturaux des campagnes, de la haute noblesse et des villes du Hainaut et des anciens Pays-Bas, afin de mieux dégager les liens ou les ruptures entre les différents groupes sociaux et architecturaux. Les rapports avec les habitats ruraux sont établis {{en ce qui concerne}} les diverses composantes que sont les douves, les pont-levis, les orifices de tir, les espaces verts et les aménagements hydrographiques d’agrément, la basse-cour, les tours, les typologies des plans et de maisons, les matériaux et leur qualité de mise en œuvre, les intérieurs, les ouvertures et les styles, les armoiries et les millésimes. La catégorie intermédiaire que sont les habitats des élites rurales, est également abordée, puisqu’elle développe des types architecturaux ambigus et se rapprochant davantage des habitats de la petite noblesse que des autres ruraux. Cette catégorie est examinée d’un point de vue architectural et social. /This research is aiming at understanding {{what is a}} gentry’s settlement in the County of Hainault {{at the end of the}} Middle Ages and during the Modern Times. The disappearance of most of the castles of the high nobility in Hainault, led us to study the gentry’s settlement. The lack of recognition of this kind of building is often leading to their destruction and irreversible transformations. There is also the fact that the archaeologists and art historians often inherited from the 19 th century tradition, whose attention was mostly attracted by the main castles and the high nobility, forgetting by the same occasion a side of the nobility –the gentry- and his settlement. The main objective of this research is to understand how these settlements were linked with their inhabitants, expressing their identities, ways of living and behaviours. In this framework, we first analyse the architectural typologies (plans, residential buildings, towers) in connection with the chronology, the materials, and the inner organisation of these buildings. Afterwards, we consider the surroundings of the buildings, the location in the landscape, the relief, hydrography, the village, the lands, the communication net. The lesser nobility is also studied, through its functions, origins, movement areas, in order to have a better understanding of the role and definition of this social group which is distinctly separated from the high nobility. The traditional opposition between cities and countryside, and between the main and secondary housing, is overstepped, in order to reach a more flexible approach. We therefore consider the topic through an interaction between cities and countryside, and their inhabitants. The rest of the research is dedicated to the interpretations, in order to draw the characterists of the gentry’s settlement. First, the relationships between the defensive and residential aspects are considered. The active and passive defensive elements are studied, as well as the efficiency of these structures. Secondly, we replace the gentry’s settlement in the context of the other architectural types of the countryside, high nobility and cities of the county of Hainaut and the Southern Low Countries, in order to have a better understanding of the links and breaks between the different social and architectural groups. The link with the rural settlement is established concerning the following elements :drawbridges, moats, arrow slits, green spaces and water structures, farms, towers, plans and houses typologies, materials and their quality, interiors, openings and styles, coats of arms. The intermediate category of the settlement of the rural elites is also considered, as the architectural types are close to the gentry’s settlement. This category is examined on an architectural and social point of view. The link with the settlement of the cities and the high nobility is also studied, allowing to see a lack of link between the different categories at least until the end of the 17 th century. In the last chapters, the gentry’s settlement of Hainault is replaced in the context of the Southern Low Countries, through a comparative approach. We also consider the link with this kind of settlement and the tradition and the modernity, as well as the link with the social status of their inhabitants and builders. The conclusion is the occasion to remind all the characteristics of the gentry’s settlement in Hainault, and the evolution of the architectural types through the centuries. Some comparisons with the same kind of settlement in surroundings countries are also established, opening new research perspectives. In the epilogue, we consider the buildings on a conservation, restoration and preservation point of view. The state of the art of the legislative situation is given, and prescriptions for a better future conservation are drawn, in order to avoid a disappearance of the architectural information, together with an important part of the history. Doctorat en Histoire, art et archéologieinfo:eu-repo/semantics/nonPublishe...|$|E
40|$|Cette étude est destinée à tester expérimentalement les capacités d'épuration des eaux usées par lagunage à macrophytes (jacinthe d'eau : Eichhornia crassipes), sous les {{conditions}} climatiques de Marrakech. L'installation <b>fonctionne</b> en continu avec un débit constant à l'entrée de 10 l/min. La charge admise est de 40 g DCO/M 2 /j. Sous l'aspect de la production de biomasse végétale, les effluents domestiques constituent un bon substrat nutritionnel. Les taux de croissance et les productions obtenues montrent dans l'ensemble une excellent adaptation d'Eichhornia crassipesà ce milieu. Le maximum de biomasse et de productivité ont été obtenu en période estivale et sont respectivement de: 40 kg MF/m 2 et 38, 6 MS/m 2 /j. Il s'est avéré également que la jacinthe d'eau est persistante toute l'année sous le climat méditerranéen aride de Marrakech. L'épuration des eaux usées domestiques par lagunage à macrophyles aboutit à des rendements satisfaisants surtout en période estivale où on obtient un abattement de 87 % de la DCO et une réduction de 95 % des MEST. Sur te plan sanitaire, l'abattement de la charge bactérienne exprimée par les bactéries témoins de contamination fécale peut atteindre jusqu'à 2 ULog pour un temps de séjour théorique très court (7 jours). Ce système e par ailleurs fourni des abattement de 100 % des oeufs d'helminthes parasites {{au niveau}} de l'eau épurée. The aim {{of the present study}} is to experimentaly test the capacities of the mater hyacinth (Eichhornia crassipes) in order to purify wastewater under Manakesh climatic conditions. The experiment was carried al wastewater spreading zone of Marrakesh pretraitement. The experimant's installation is made of two lined water yacinth ponds that receive domestic wastewater. The proposed process is a continuous system with a constant flow rate of 10 l/mn. The theoritical retention time was estimated to 7 days. The allowed load is 40 g COD/m 2 /day. Macrophytic biomass was observed for both ponds during the experimental period (Match, 1986 - February, 1987). Parameters of organic, bacterial and parasitological loads are studied {{in order to determine the}} system efficiency under arid climate. Obtained results show the water hyacinth ability to adapt to Marrakesh climatic conditions. The number of plants doubled at 12 days, this is coherent with results obtained by PENFOUND (1956), BOCK (1969), WESTLAKE (1963, 1975) and SCULTHORPE (1967). Maximum biomass level and productivity were achieved during the summer period : 40 kg WW/m 2 /day and 38, 6 g DW/m 2 /day respectively. Biomass and productivity obtained under arid climate are similar to results obtained by WOOTEN and DODD (1976), and by DINGES (1976) under subtropical conditions, and higher than chose obtained by JOHN (1985) under temperate climate. The growth period of water hyacinth is estimated to 9 months at Marrakesh, 10 months at subtropical climate (WOLVERTON and MC DONALD, 1976) and limited to 6 months under cold climate (COPELLI et al., 1982; DUBOIS, 1983; SAUZE, 1983; DE CASABIANCA, 1985). Temperature is considered as a limited growth factor of water yacinth. According to FRANCOIS et al. (1977), the water hyacinth growth was stopped when the temperature is lower than 10 °C. Linder Marrakesh arid climate, the temperature is always higher than 10 °C. It was also found that the water hyacinth survive all a year around in the arid climate of Marrakesh. Domestic sewage purification by water hyacinth leads to satisfactory efficiency during the summer concerning reduction of COD: 87 % and TSS : 95 %. This phenomenon may be jointed to the retention time wich was lengthed (9, 4 days) in the summer, and the higher biomass density of water hyacinths in this one. The purifying action of floating macrophytes (Eichharnia crassipes) is physical and biological. The root system stabilizes the medium thus favoring sedimentation of TSS and particulate COD both on the bottom of the tank and by trapping in the root hairs. Elimination of COD is realized by means of the action of bacteria which are present, by sedimentation of particulate COD and root filtration. The biological action of the plants is not an important mechanism for COD elimination. The system efficiency is low at the winter and the reduction of COD and TSS have not exceed 60 % and 82 % respectively because the degenering of the water hyacinths. From sanitary point of view, bacterial load reduction expressed by control faecal contamination bacteria achieved 2 log Units for a short theoritical retention time (7 days). This is higher than the result obtained by DUBOIS (1985). Two hypothesis are given to explain reduction of bacterial load by water hyacinths : 1) the bacteria are sedimented or trapped in the root hairs of the water hyacinths whith TSS. 2) Water hyacinths may have a capacity to secrete a chemical substance wich could have bactericid or bacteriostatic effect. The improvement of retention time and the addition of one or two supplementary ponds will probably lead to better results. Moreover, this process had also reduced parasitical helminth eggs to undetectable levels (100 %). The parasitical helminth eggs distinguisched at domestic sewage received by the experimental installation, are Taenia, Hymenolepis, Trichuris and Ascaris geints. Their total number vary tram 0 to 120 eggs/l with a mean of 32. Other types of eggs could be encountred generally in waste water as : Toxocara, Oxyure, Capillaria and Taxoascaris (FOX and FITZGERALD, 1976) but was not detected by our technique. No helminth eggs were found in purified wastewater descended through water hyacinth ponds. This phenomenon is explained by supposing that the helminth eggs are present in the effluent but it was the detection limit of the employed technique (Bailenger method), or there is no eggs really at the effluent because of their higher specific weight. Ascaris, Taenia and Trichuris eggs have a sedimentation rate of 0, 65 m/h, 0, 26 m/h and 1, 5 m/h respectively (FEACHEM et al., 1983). The eggs sedimented rapidly in the water hyacinths ponds involving a transfer of the effluent pollution to the sediment. Several authors affirmed that the stabilization ponds are an effective means to reduce parasitical helminth eggs of the wastewaters (GLOYNA, 1972; KOWAL, 1985). Hence, if the parasitical risk could be controled in the purified water (effluent), particular attention should be given to sediments. It is also important to point out, that no parasitical nematode is found at the influent. Nematofauna associated to wastewater and roots of water hyacinth, was represented by bacteria consumer nematode. The abundance of nematode is definite by the existence of bacterial food in the wastewaters (CALAWAY, 1963; SHIEMER, 1976). The principal genus determined are Rhabditis sp, Plectus sp. and Mononchoïdes sp. It appears that Rhabditis genus, is dominant in the first pond (94, 7 %) of the nematode population. However, the two genus Rhabditis sp. and Plectus sp. are dominant in the second one and represent 50 % and 49 % respectively. The presence of Plectidae in the second basin indicates that is less loaded (ZULINI, 1976). However, under the arid climate conditions of Marrakesh, the process based on water hyacinth for wastewater purification, is faced with two major problems : first, the water loss by evapotranspiration reachs 60 % during the summer time under arid climate of Marrakesh. The development of Mousquito particularly in the summer, constitutes the second problem of our proposed process. Moreover, front economical point of view, the water hyacinths show a good productivity in the summer under arid climate and could be exploited in several field...|$|E
40|$|The present {{thesis is}} a {{semantic}} {{study of the}} polysemous French pronoun ON. In order to describe the complex semantics of ON, the thesis examines some linguistic theories on semantic interpretation {{in order to develop}} a theoretical framework that might explain how the interpretation of ON comes about. In order to evaluate the theoretical reflections the thesis then analyses the use of ON in a material of contemporary French texts. The thesis is inspired by the theoretical framework of textual semantics - Sémantique des textes - inspired by the works of François Rastier. Textual semantics is a multi-level model for the interpretation of language. It poses semes, or semantic traits as the basic descriptive unit. In this sense, it is similar to French structuralist semantics. However, the semantic traits serve primarily as a tool for the analysis of higher-order linguistic levels. Firstly, the recurrence of semantic traits constitutes isotopies, i. e. semantic chains constituted by the repetition of traits. Secondly, the semantic chains are studied in a larger context: the text and the genre, since these levels impose constraints on the lower levels. As opposed to structuralism, textual semantics do not see the semantic traits as binary, minimal traits. Rather, the semantic traits can be seen as semantic features that are realised or cancelled in context. According to this line of reasoning, the use of the personal value of ON, for instance, is linked to the cancellation of the seme /indefinite/ while the use of ON for female referents, entailing the agreement in gender for verbs and adjectives, realises the seme /feminine/. It is the text, however, that is the basis for analyses in textual semantics, as the label indicates. The text is a considered as the fundamental linguistic unit, with its own constraints and meaning structures that influence lower level units. In this sense, textual semantics is close to neighbouring disciplines such as philology and hermeneutics, because it requires a critical interpretation of the text in order to identify linguistic meaning. Finally, the notion of context was expanded to include norm systems influencing pronominal use. Following Rastier, the thesis distinguishes the language system, the genre and individual style as different norm systems that might influence the use of ON. On the basis of this theoretical framework, the thesis examines the use of ON in different texts and on different contextual levels. My aim was to find out if there were any regularities in the contexts that co-occur with specific interpretations of ON. Analyses The empirical analyses presented in the thesis are divided into two major parts, focussing on the genre of the research article and poetry, respectively. The first part examines the contribution of ON to important textual functions in the genre of the research article and particularly the textual representation of the author. In French, ON is frequently used in academic prose to refer to the author herself, as the use of the first person singular is often discouraged. But it is of course also used in the indefinite sense. ON is therefore, consciously or unconsciously, used as a tool to manage the different constraints of the genre: respect and deference to others, argumenting by authority, promoting one's own research. As a consequence, we see a complex play and interaction between the different values of ON in this genre. These values often correspond to what we can call author-functions or more precisely textual representations of argumentation, description etc. Secondly, the thesis analyses the influence of the linearity of the text and its potential influence on the use of ON. In research articles, there is often a close link between surface and content: specific thematic content is distributed in a pre-fixed manner: “Introduction” section in the beginning, then “Discussion and methods” and finally the conclusion at the end. In many disciplines, this sequence is explicitly fixed in journal guidelines. It is quite obvious that this schema influences textual, rhetorical functions. However, as my analysis shows, lower level linguistic units, such as ON, are also influenced the linearity of the text. The frequency of ON, as well as its values, change and evolve across the text. This is clearly an example of the decisive influence of the text on micro-level units such as pronouns. In this sense, the study of ON brings up features that can be generalised to the study of other grammatical units. The second part of the empirical analyses focuses on poetry, and more precisely on what could be called testimonial poetry. The thesis presents a study of a work of poetry, “L'excès- l'usine”, by the French author Leslie Kaplan. The text describes the experience of factory work, emphasizing the interior experience of this kind of work and the alienation it brings with it. This text is characterized by a very frequent and very idiosyncratic use of ON. ON is consistently used to refer to a woman, which can be seen by the consistent agreement of adjectives and participles. This creates an important textual effect, because it poses the feminine as a default perspective in the textual universe, in contrast to everyday French, where the general or universal ON has agreement for the masculine gender. In this sense, the text questions our assumptions about how language represents identity. What this text shows then, is how a tiny pronoun, used in a special way, can challenge {{the way we think about}} subjectivity. Furthermore, the text represents a genre where the use of ON has been little explored, even though this pronoun has been used in quite remarkable ways in French testimonials, and notably testimonials from concentration camps. ON seems particularly suited to this genre, because it represents the border between the I, the subject, and the exterior. Cette thèse propose une méthodologie pour l'analyse des éléments grammaticaux polysémiques, notamment le pronom ON, à partir d'une réflexion sur le cadre théorique de la Sémantique de Textes. À travers des analyses de deux genres déterminés - l'article scientifique et la poésie - la thèse montre l'interaction et l'influence réciproque de ON et le contexte, aussi bien au niveau de la phrase qu'au celui du texte. La première partie de la thèse traite de la sémantique de ON et de sa classification grammaticale. Elle montre les limitations des descriptions grammaticales basées sur des critères peu précis, et la confusion entre emplois indéfinis et emplois pour des personnes déterminées qui s'exprime par l'oxymoron « pronom personnel indéfini ». Par conséquent, la thèse se propose d'affiner la description sémantique de ON, notamment par une élaboration de la notion de contexte et son influence sur l'interprétation de ce pronom. La variation dans les emplois de ON ne peut pas se réduire à un seul noyau de sens (core meaning) et l'on propose un modèle sémique approprié à l'analyse de ON selon l'hypothèse que les différents emplois correspondent à la réalisation ou l'annulation des différents sèmes en contexte. La seconde partie de la thèse présente deux études de l'emploi de ON dans des genres déterminés; l'article scientifique et la poésie. La première étude examine l'emploi de ON dans un corpus d'articles scientifiques (le corpus KIAP, voir www. kiap. uib. no) et montre l'influence de paramètres contextuels aussi bien au niveau micro (verbes, temps verbaux, adverbes) qu'au niveau macro (disposition linéaire du texte). La seconde étude analyse l'emploi de ON dans L'excès - l'usine de Leslie Kaplan (1994) à partir de la notion de zones anthropiques (Rastier 1996) qui décrit les relations entre dimensions sémantiques et expériences humaines. Dans cette perspective, ON <b>fonctionne</b> comme un médiateur entre les différentes zones, notamment entre le sujet et le monde qui l'entoure. La flexibilité discursive de ON, allant de l'indéfini jusqu'au déterminé, constitue un facteur remarquable dans la représentation textuelle de l'aliénation du sujet dans ce texte...|$|E
40|$|Introduction: The thesis {{deals with}} the {{adaptation}} of referral hospitals in two regions of the Eastern Democratic Republic of Congo to a changing environment that have been affected {{for more than a}} decade by intermittent armed conflicts : Ituri (Bunia and Logo Hospitals) and South Kivu (Katana Hospital). The objective is to generate theoretical proposals to address in different ways the governance of hospitals, the analysis of their performance, and how to improve that performance. It confronts in effect the provision of hospital care to the events occurring in the life of the hospital by identifying major changes over time and responsiveness of management teams of hospitals at the time of change. Such work finds its originality and interest in the type of approach for analyzing the referral hospital, not just from the angle of a logical and bureaucratic model where the relationship of cause and effect (means versus results) predominates, but also especially in terms of complexity, according to an adaptive and flexible approach, where the outcome is not predictable but results from the interaction between several actors who sometimes have conflicting interests. Based on the facts observed on field and a series of questions from the interpretive synthesis of the literature on the concepts of complex adaptive systems, strategic management and leadership, adaptive governance and performance, the referral hospital is thus analyzed as a complex adaptive system in order to improve its performance. Methodology: The methodological approach applied uses multiple case studies using mixed methods (qualitative and quantitative) for data collection. It uses (1) hospital data to measure the output of hospitals, (2) literature review to identify among others, the events and interventions recorded in the history of hospitals during the study period and (3) information from individual interviews to validate the interpretation of the results of the previous two sources of data and understand the responsiveness of management teams referral hospitals during times of change. Results: Two case studies. The first study compares the evolution of two referral hospitals in Ituri (Logo and Bunia) exposed to the same program for four years (2006 - 2010) and notes two different paths of development in their provision of care. It describes the main actors in referral hospitals categorized in three key types: the management team, hospital staff, and the owner; and reveals the characteristics of the interaction between these agents in the two hospitals and in relation to their environment which is marked by an external program with development partners. The characteristics of the agents in the two hospitals are different. This study generates a theoretical proposal that explains the adaptation hospitals to change. It considers that the nature of the interaction between agents plays an important role in the " stability " or " lability" of a hospital and that this interaction is mainly based on institutional arrangements. The more solid these are, the more the interaction between players is balanced and stronger and the hospital is stable. The second case study, conducted in the province of South Kivu, refines previous evolving theory through the analysis of hospital Katana over a longer period, from 1990 to 2010 (20 years). It compares three periods of the life of the hospital separated by events considered major. The period between 1990 and 1995, then the period between 1996 and 2003, and finally the period between 2004 and 2010. It brings new elements to the theoretical propositions namely : (1) The more the interaction between the three key agents is strong and positive, the better the external support is delivered in the form of development cooperation (participatory support) rather than as the development assistance (substitution) and the better hospitals adapt through their provision health care, (2) the strength of the interaction between agents is largely based on existing or new institutional arrangements associated with a new owner of the hospital, (3) the transfer of an isolated, independent, autonomous hospital into a hospital network (diocesan network for example) brings new priorities, those of the network, which must now take into account more of the priorities of population and institution (Referral Hospital), (4) external expertise, national or international, managerial (Logo, Katana, Bunia) and medical (Surgery in Katana) is an essential component for a better functioning referral hospitals in a changing context. The synthesis of case studies develops and reveals theoretical propositions and provides answers to the issues identified in the initial theoretical framework. It presents the role of the management board of the hospital and the role of competition between hospitals, reveals the weak regulation of hospitals by the intermediate level, and comments on hospital performance which is difficult to assess in this study as a multidimensional concept. Discussion and conclusion: In the discussion, the thesis outlines the methodological, theoretical, and practical contributions of this research; addresses the strengths and limitations of this work (in relation to the reliability and validity of results); and discusses the main theories that came from the case studies with a focus on development aid (including the "technical assistance" component), institutional arrangements, interaction between actors, competition between hospitals, the passage of a single hospital into a hospital network, regulation by the intermediate level, and hospital performance. In conclusion, the research shows that it is not enough just to provide support (financial and technical), or to manage or to evaluate a hospital for it to operate and adapt to a changing environment. It is necessary (and perhaps especially) to motivate, through inspirational leadership, keeping in consideration that it is a complex adaptive system and that this motivation is nothing other than the induction of a positive interaction between agents. The study suggests that analyzing hospitals this way, taking into consideration that these are complex adaptive systems for multidimensional performance and addressing the determinants of their adaptation to change during the implementation of programs of development assistance, is essential in unstable contexts to improving their performance. These proposed determinants are among others the nature of the interaction between agents, national or international external expertise, and the institutional arrangements in place. Introduction: La thèse traite de l’adaptation d’hôpitaux de référence à un environnement changeant dans deux régions de l’Est de la République Démocratique du Congo qui sont frappées depuis plus d’une décennie par des conflits armés intermittents: l’Ituri (hôpitaux de Bunia et de Logo) et le Sud-Kivu (Hôpital de Katana). Elle a pour objectif de générer des propositions théoriques permettant d'aborder différemment la gouvernance d'hôpitaux, l'analyse de leur performance et la manière d'améliorer cette performance. Elle confronte en effet la production des soins des hôpitaux aux évènements survenus dans la vie de l’hôpital en identifiant les changements majeurs au cours du temps et la réactivité des équipes dirigeantes des hôpitaux au moment des changements. Un tel travail trouve son originalité et son intérêt dans le type d’approche pour analyser l’hôpital de référence, non pas seulement sous un angle de modèle logique et bureaucratique où prédomine la relation de cause à effet (moyens versus résultats), mais aussi et surtout sous l’angle de la complexité, selon une approche adaptative et flexible, où le résultat n’est pas prédictible mais découle de l’interaction entre plusieurs acteurs, qui parfois, ont des intérêts divergents. Sur base des faits observés sur terrain et d’une série de questions issues de la synthèse interprétative de la littérature sur les concepts de système complexe adaptatif, de management stratégique et leadership, de gouvernance adaptative et de performance, l’hôpital de référence est ainsi analysé en tant qu’un système complexe adaptatif dans le but d’améliorer sa performance. Méthodologie: L’approche méthodologique appliquée recourt à une étude de cas multiple utilisant des techniques mixtes (qualitatives et quantitatives) pour la collecte de données. Elle fait appel (1) à des données hospitalières pour mesurer la production des hôpitaux, (2) à la revue documentaire pour identifier entr’autres, les événements et interventions enregistrés dans l’histoire des hôpitaux au cours des périodes d’étude et (3) à des informations issues des entrevues individuelles pour valider l’interprétation des résultats des deux précédentes sources des données et comprendre la réactivité des équipes dirigeantes des hôpitaux de référence pendant des moments de changements. Résultats: Deux études de cas. La première étude compare l’évolution de deux hôpitaux de référence en Ituri (Logo et Bunia) exposés à un même programme durant 4 ans (2006 à 2010) et note deux évolutions différentes au niveau de leurs productions des soins. Elle décrit les principaux acteurs au sein des hôpitaux de référence qu’elle catégorise en 3 agents clés à savoir l’équipe dirigeante, le staff hospitalier et le propriétaire; et dégage des caractéristiques de l’interaction entre ces agents dans les deux hôpitaux et par rapport à leur environnement marqué par un programme exogène avec des partenaires de développement. Les caractéristiques des agents dans les deux hôpitaux sont différentes. Cette étude génère une proposition théorique qui explique l’adaptation des hôpitaux au changement. Elle considère en effet que la nature de l’interaction entre agents joue un rôle important dans la « stabilité » ou la « labilité » d’un hôpital et que cette interaction repose essentiellement sur les arrangements institutionnels. Plus ces derniers sont solides, plus l’interaction entre acteurs est équilibrée et forte et plus l’hôpital est stable. La seconde étude de cas, réalisée dans la province du Sud Kivu, raffine la théorie évolutive précédente à travers l’analyse de l’hôpital de Katana sur une plus longue période, allant de 1990 à 2010 (20 ans). Elle compare trois périodes de la vie de l’hôpital séparées par des événements jugés majeurs. La période entre 1990 et 1995, ensuite la période entre 1996 et 2003 et enfin la période entre 2004 et 2010. Elle apporte de nouveaux éléments aux propositions théoriques à savoir : (1) Plus l’interaction entre les trois agents clés est solide et positive, mieux les appuis extérieurs se font sous forme de coopération au développement (accompagnement participatif) plutôt que sous forme de l’aide au développement (substitution) et mieux les hôpitaux s’adaptent au travers de leur production des soins de santé; (2) la solidité de l’interaction entre agents repose notamment sur des arrangements institutionnels préexistants ou nouveaux associés à un nouveau propriétaire de l’hôpital; (3) le passage d’un hôpital indépendant, autonome, isolé, à un réseau hospitalier (réseau diocésain par exemple) apporte de nouvelles priorités, celles du réseau, dont il faut désormais tenir compte en plus des priorités de la population et de l’institution (HGR); (4) une expertise externe, nationale ou internationale, managériale (Logo, Katana, Bunia) et médicale (Chirurgie à Katana) constitue une composante incontournable pour un meilleur fonctionnement des hôpitaux de référence en contexte changeant. La synthèse des études de cas dégage et complète les propositions théoriques et apporte des éléments de réponse aux questions initiales définies dans le cadre théorique. Elle présente le rôle du comité de gestion de l’hôpital, aborde la compétition entre hôpitaux, évoque la faiblesse de la régulation des hôpitaux par le niveau intermédiaire et commente la performance hospitalière, difficile à évaluer dans la présente étude en tant que concept multidimensionnel. Discussion et conclusion : Dans la discussion, la thèse précise les apports méthodologiques, théoriques et pratiques de la présente recherche; traite des forces et des limites de ce travail (en rapport avec la fiabilité et la validité des résultats) et commente les principales théories issues des études de cas avec une insistance sur l’aide au développement (y compris le volet « assistance technique»), les arrangements institutionnels, l’interaction entre agents, la compétition entre hôpitaux, le passage d’un hôpital isolé à un réseau hospitalier, la régulation par le niveau intermédiaire et la performance hospitalière. En conclusion, la recherche démontre qu’il ne suffit pas seulement d’apporter un appui (financier et technique), de gérer ni d’évaluer un hôpital pour qu’il <b>fonctionne</b> et s’adapte à un environnement changeant mais encore faut-il (et peut-être surtout) l’animer, grâce à un leadership inspirant, en considérant que c’est un système complexe adaptatif, et que cette animation n’est rien d’autre que l’induction d’une interaction positive entre acteurs. L’étude suggère ainsi d’analyser autrement les hôpitaux, en considérant que ce sont des Systèmes Complexes Adaptatifs visant une performance multidimensionnelle, et de tenir compte des déterminants de leur adaptation au changement lors de l’implémentation des programmes d’aide au développement, incontournables en contextes instables, en vue d’améliorer leur performance. Ces déterminants proposés sont entr’autres la nature de l’interaction entre agents, l’expertise externe nationale ou internationale et les arrangements institutionnels en place. (SP - Sciences de la santé publique) [...] UCL, 201...|$|E
40|$|In Northern Iceland, {{the active}} rift is located 120 km eastward {{with respect to}} the Kolbeinsey Mid-Atlantic Ridge. The Tjörnes Fracture Zone connects these two rifts and {{accommodates}} a dextral transform motion. A major active fault of the Tjörnes Fracture Zone is the WNW-ESE trending Húsavík-Flatey Fault (HFF). The seismic activity associated to the HFF defined a nearly vertical fault surface that cuts through the 12 km thick seismogenic crust. Analyses of major structures combined with inversion of fault slip data allow us to discuss the kinematics and mechanics of the HFF since the Late Tertiary. For the present-day kinematics, we also use inversion of earthquake focal mechanisms provided by the Icelandic Meteorological Office. The main state of stress along the HFF corresponds to a dextral transtension, with an ENE-WSW trending extension due to the obliquity of the transform fault relative to the E-W direction of plate divergence. This overall mechanism is subject to slip partitioning that include an extension trending NW-SE, parallel to the HFF, and an extension trending NE-SW, perpendicular to the fault. These three regimes do not reflect a succession in time of tectonic events, but occur simultaneously at different places and in various chronological orders. They are thought to express the geometric accommodation of the transform motion in the oblique transform zone. Near the connection of the HFF to the Kolbeinsey Ridge, most dextral transform faults that trend parallel to the HFF are replaced by normal faults with a dextral component. On {{the opposite side of the}} HFF, at its junction with the northern Icelandic rift, two main transform fault segments have been mapped out. The northern fault directly connects to the northern Icelandic rift as a triple point junction, whereas the southern one progressively evolves from a WNW-ESE trending dextral transform fault to a N-S trending normal fault, parallel to the direction of the rift structures. One hypothesis, which would explain these structural differences, involves the presence of pre-existing structures, like volcanoes, that affect the direction of propagation of the southern transform fault segment. Another hypothesis would be that the southern transform fault, the oldest between these two transform faults, developed and then was connected to the northern Icelandic rift before the rift propagated northward. After this northward propagation of the northern Icelandic rift, the northern transform fault segment propagated linearly to the rift. Moreover, near the junction of the HFF with the northern Icelandic rift, the behaviour of the normal faults associated with the rift appears to be strongly influenced by the dextral transtension characterising the HFF. On other hand, seismic faults have been mapped out near the eastern border of the Flateyjarskagi shelf. Inversions of related focal mechanisms suggest that movements associated with the present-day unlocking of the eastern part of the HFF, considered as locked until recently because of its low seismic activity, are compatible with the proposed model of dextral transtension. The present-day offset between the Kolbeinsey Ridge and the northern Icelandic rift results from an eastward rift jump of the Mid-Atlantic Ridge in Iceland. As the North American-Eurasian plate boundary drifts westward, eastward rift jumps relocate the rift zones above the Icelandic hotspot. Using 40 Ar/ 39 Ar dating of dykes along a profile parallel to the direction of plate motion in Northern Iceland, a paleo-rift axis has been recognised 60 km eastward to the previously accepted location. This paleo-rift, localised in the continuation of fjord of Skagafjördur and referred to as, remained active until approximately 3 Ma ago. The activity of the northern Icelandic rift started about 8 - 8. 5 My ago, intruding the presently dated 9 - 9. 5 Ma old eastern flank of the Skagafjördur paleo-rift. This age of 1 Ma for the intruded paleo-rift rocks at the rift jump time is considered as a minimal value, resulting to hypotheses assumed in the theoretical model for the dating data interpretation. An important plio-pleistocene glacial erosion, inducing a decrease of the lava pile thickness and thus a diminution of the area covered by the production of the northern Icelandic rift, would explain the presence of dykes related to the northern Icelandic rift as far as 25 km outside of its borders. The two rifts were thus simultaneously active during 5 - 5. 5 Ma. During this period, the accretion rates along the two rift zones were nearly equal. However, accretion was asymmetrical along each rift, with the higher rate of accretion situated on the external flank. The supposed absence of drift from the northern Icelandic rift since its initiation implies a strong asymmetry of accretion, favouring the Northern American plate. A decrease of the hotspot activity would release the northern Icelandic rift and allow it to drift westward with the Mid-Atlantic Ridge. Then, an increase of the hotspot activity would facilitate the shift of the accretion zone above to the hotspot by an eastward rift jump. The tectonic changes related to the last rift jump explains the observed deformations in Northern Iceland. The Skagafjördur paleo-rift shrank, after it became extinct, both towards the Kolbeinsey Ridge and towards the active volcanic zone of central Iceland. This volcanic zone of central Iceland probably corresponds to an "en échelon" zone between the northern and the southern Icelandic rifts. The weight of the lava flows spread out by the volcanic zone of central Iceland since 3 Ma has induced a flexuring of the tertiary lava flow pile produced by the Skagafjördur paleo-rift. In a similar way, the lava flows erupted by the Skagafjördur paleo-rift have been flexured by those erupted by the northern Icelandic rift. These flexures are directed towards the volcanic zone of central Iceland and towards the northern Icelandic rift, respectively. They define a continuous flexure belt through Northern Iceland. An important extensive fracturing is related to the flexure of the lava flows. Such a flexure would explain that the synform-like arrangement of the lava flows, considered as a characteristic of an Icelandic rift axis, is absent along the southern part of the Skagafjördur paleo-rift axis, whereas such a structural shape is recognised along its northern part. The synform that was initially thought to localise the axis of the paleo-rift would be the axis of the flexural zone produced by the weight of plio-pleistocene lava flows erupted from the south, in the volcanic zone of central Iceland. Despite the limited number of radiochronological data available as time constraints in Southern Iceland, a global model of the tectonic evolution of the island, based on the model proposed for the evolution of Northern Iceland, is presented. This model highlights the importance of the volcanic zone of central Iceland. This volcanic zone would accommodate the differences in the tectonic evolution, like diachronisms in rift jump process and consequently shifts of the accretion zones, between the northern and southern parts of Iceland. Le rift nord islandais peut être considéré comme l'équivalent émergé de la dorsale de Kolbeinsey. Il est cependant décalé de 120 km vers l'est par rapport à celle-ci. La Zone de Fracture de Tjörnes, une zone transformante dextre, absorbe ce décalage. L'analyse des grandes structures ainsi que l'inversion de données de failles à stries ont permis de caractériser la géométrie et le fonctionnement de la faille d'Húsavík-Flatey (FHF), l'une des structures majeures de la Zone de Fracture de Tjörnes. L'inversion de mécanismes au foyer, fournis par l'Office Météorologique Islandais, a permis de compléter l'étude, pour la période actuelle. L'obliquité de la FHF, de direction WNW-ESE, par rapport à la divergence des plaques de direction E-W induit depuis la fin du Tertiaire une transtension dextre de direction ENE-WSW le long de la FHF. Ce mouvement transtensif se partitionne localement en une extension de direction NE-SW, sub-perpendiculaire à la FHF, et une extension de direction NW-SE, sub-parallèle à la FHF. Ces trois régimes ne correspondent pas à une succession bien définie d'épisodes régionaux mais à des variations locales et temporelles du mouvement transformant. A proximité de la jonction de la FHF avec la dorsale de Kolbeinsey, les failles dextres qui accommodent principalement le mouvement décrochant sont majoritairement remplacées par des failles normales à composante dextre. A l'autre extrémité de la FHF, au niveau de sa jonction avec le rift nord islandais, la faille est divisée en deux branches parallèles. L'une d'elles se connecte directement au rift nord islandais en définissant un point triple tandis que l'autre branche évolue progressivement d'une faille transformante de direction WNW-ESE jusqu'à une faille normale de direction N-S parallèle au rift. Ces différences structurales s'expliqueraient par la propagation vers le nord du rift nord islandais ainsi que par l'influence de structures préexistantes, telles que des volcans, lors du développement de ces deux failles. De plus, le fonctionnement du rift nord islandais à proximité de la FHF paraît fortement influencé par celui de cette dernière. Enfin, l'activité séismique liée à l'actuel déblocage de la partie de la FHF bloquée depuis la dernière crise éruptive du rift nord islandais s'intégrerait dans le modèle de fonctionnement en transtension dextre de cette faille. Le décalage du rift nord islandais et de la dorsale de Kolbeinsey résulte d'un saut vers l'est de la zone d'accrétion nord islandaise. La dérive vers l'ouest de la dorsale médio-Atlantique par rapport au point chaud islandais serait à l'origine de tels sauts. A partir de datations 40 Ar/ 39 Ar de dykes échantillonnés le long d'un profil parallèle à la direction de divergence des plaques, l'initiation de l'actuel rift nord islandais a été datée à 8 - 8. 5 Ma. Elle eut lieu dans des roches qui n'avaient alors que 1 Ma. Le paléo-rift, dont l'axe a été localisé le long du fjord de Skagafjördur, c'est-à-dire 60 km à l'est de l'emplacement généralement admis, et le rift actuel ont <b>fonctionné</b> simultanément et de façon asymétrique, l'accrétion étant plus importante sur leurs flancs extérieurs, jusqu'à 3 Ma. L'absence supposée de dérive du rift nord islandais par rapport au point chaud implique une très forte asymétrie d'accrétion de la plaque Nord Amérique par rapport à la plaque Eurasie. Si l'activité du point chaud venait à diminuer, le rift nord islandais pourrait être libéré et dériver vers l'ouest jusqu'à ce qu'un nouveau pulse mantellique provoque un saut de rift vers l'est et ramène la zone d'accrétion à l'aplomb du point chaud. Les déformations observées dans le Nord de l'Islande s'expliquent par la réorganisation tectonique liée au dernier saut de rift. Le mécanisme d'abandon du paléo-rift de Skagafjördur est interprété comme un retrait symétrique et synchrone vers la ride de Kolbeinsey et vers la zone volcanique du centre de l'Islande, cette dernière constituant probablement une zone de relais entre les rifts nord et sud islandais. Le poids des laves émises depuis 3 Ma par la zone volcanique du centre de l'Islande a provoqué une flexuration des laves issues du paléo-rift vers le centre de l'Islande de la même manière qu'elles ont été flexurées par et en direction de celles émises par le rift nord islandais. Cette profonde réorganisation structurale expliquerait l'absence d'une synforme le long de la partie méridionale du paléo-rift de Skagafjördur alors qu'une telle synforme, caractéristique d'un rift en Islande, est présente le long de sa partie septentrionale. La synforme initialement considérée comme localisant l'axe du paléo-rift dans le Nord de l'Islande ne serait alors que l'axe d'une zone de flexure due à l'épanchement des laves plio-pléistocènes. Malgré la faible quantité de données radiochronologiques disponibles pour la partie sud de l'Islande, le modèle d'évolution tectonique proposé pour le Nord de l'Islande a été intégré dans un schéma d'évolution de l'ensemble de l'île. En accommodant les différences d'évolution entre les parties nord et sud de l'île, telles que le diachronisme entre les sauts de rift ayant eu lieu dans ces deux parties de l'Islande et donc le décalage des zones d'accrétion au travers de l'île, la zone volcanique du centre de l'Islande a ainsi joué un rôle primordial tout le long du développement de l'île...|$|E
40|$|Since 50 Ma, the {{lithosphere}} Aegean showed {{very different}} mechanical behaviors. During {{the formation of}} Hellenides, convergence between Africa and Eurasia was induced partial burial and exhumation in context syn-orogenic high-pressure low temperature (HP-LV) {{of a series of}} layers (the Cycladic blueschist - SBC - and the Cycladic Continental Base - CSC) stacked on top of the unit Pelagonian (obducted on an ophiolite fragments of continental shelf). Following the withdrawal to southern Africa started diving board to 30 - 35 Ma, the Hellenic internal zones are passed back-arc area and the building of layers disintegrated. The NS extension distributed in back-arc induced the formation of metamorphic core complexes (MCCs) in which the HP-LT units were exhumed to the surface without significant retrogression in the context of low pressure-high temperature (BP-HT). Around 5 Ma, the system of North Anatolian Fault has spread within the Aegean in the form of localized lithospheric discontinuities. The study of post-orogenic extension in the Cyclades has led to models of continental lithosphere, which would collapse as soon as the boundary conditions are more compressive. In these models, it is the flow in the ductile crust that direct the movements of blocks of upper crust. Conversely, patterns of elasto-plastic lithosphere can account for the propagation of North Anatolian Fault. They consider that plastic deformation is limited to faults which separate blocks whose internal deformation is elastic. The opposition between these two conceptions of the rheology of the lithosphere is in a general debate on the strength of the lower crust and lithospheric mantle, previously focused on the area of India-Asia collision, which was partially shifted towards the Aegean. The aim of my work is to clarify the rheological behavior of the lithosphere during post-orogenic extension in combining the acquisition of field data, metamorphic petrology and radiochronology Ar / Ar thermomechanical modeling. In particular, I sought to answer two questions. (1) Under what conditions MCCs "cold" can they be trained? (2) What is the influence {{of the structure of the}} crust during compression syn-orogenic on how to post-orogenic extension? A field study in Ios (southern Cyclades) has found traces of syn-orogenic structure. The contact SBC on the CSC is a south vergent thrust that worked in terms of HP-BT. In addition, verging shear zones north confirms the asymmetric nature of post-orogenic extension controlled by detachments to the north. The modeling of mineral assemblages with the DOMINO software brings new con-straints on the pressure-temperature metamorphic units of Ios. The conditions of peak pressure (510 ° C- 18. 5 kbar for SBC and 500 ° C- 16. 5 kbar for CSC) and the beginning of the retrograde evolution are different in the two units. The syn-orogenic exhumation of units controlled by the shear to the south took place until about 400 ° C- 8 kbar, conditions which both units are secured. Following the exhumation is done in the post-orogenic. It is marked by continuous cooling to 250 ° C- 1 kbar, associated with shear to the north. Dating Ar / Ar phengite were performed on samples of the islands of Andros, Tinos, Syros and Ios. Three complementary methods were used: conventional methods (dating people and Drills) and a method to directly date deformation (in-situ dating by laser ablation). The age data obtained on Andros, Tinos, Syros and Ios helped bring new time constraints on the exhumation of the SBC. Integrated with those of the literature, these data indicate the timing of the exhumation of the SBC / CSC, and the associated velocities. The data from the field and laboratory help rebuild the structure earlier crustal extension induced by the stacking of layers in the Cyclades. This structure is characterized by a lithological stratification reversed, that is to say that the upper crust had a strength far greater than the lower crust. This stratification and the thermal state of the PT paths inferred for the late syn-orogenic episode, was used to compel a baseline reference for modeling. Parametric studies performed with the code thermomechanical PARA (O) VOZ showed that stratification of lithologic inherited syn-orogenic structure is a parameter that controls the first order terms of post-orogenic extension. In particular, a reverse lithological stratification allows the formation of MCCs, even in relatively cold temperature conditions. The numerical experiments also showed that the formation of MCCs in a crust with lithological layering is reversed, the resistance is independent of the lithospheric mantle. This result, in contradiction with what is generally accepted, due to the decoupling of major ductile-brittle transition that occurs during the formation of MCC in the models. The modeling work has important implications for the interpretation of the geodynamics of the Aegean area. Since the formation of an MCC in a crust of reverse stratification is independent of the strength of the lithospheric mantle, the presence of MCCs Aegean domain is not incompatible with the propagation of North Anatolian fault within the lithosphere. In addition, during the formation of an MCC, the lower crust is transferred laterally and vertically to the upper crust. Thus, one consequence of post-orogenic extension in the Aegean is the emptying of the lower crust. This process is likely to induce an increased resistance of the entire lithosphere and facilitate the spread of a lithospheric detachment. This work also has implications for understanding the rheology of the lithosphere post-orogenic. It appears that the crustal structure of a post-orogenic lithosphere can be described by a model of "Yarrow" composed of a succession of non-standard layers of different composition and rheology. Such lithosphere, in fact, an integrated low resistance due to structural softening without the lithospheric mantle is necessarily low. Finally the process of coupling and decoupling in a "Yarrow" are complex. They help explain the apparent coherence of the deformation at the scale of the lithosphere, but that it is vertically coupled. Depuis 50 Ma, la lithosphère égéenne a montré des comportements mécaniques très différents. Lors de la formation des Hellénides, la convergence entre l'Afrique et l'Eurasie a induit l'enfouissement puis l'exhumation partielle en contexte syn-orogénique de haute pression-basse température (HP-BT) d'une série de nappes (les Schistes Bleus Cycladiques - SBC - et le Socle Continental Cycladique - SCC) empilées sous l'unité supérieure du Pélagonien (une ophiolite obductée sur des lambeaux de socle continental). Suite au retrait vers le sud du panneau plongeant africain initié vers 30 - 35 Ma, les zones internes Helléniques sont passées en domaine arrière-arc et l'édifice de nappes s'est disloqué. L'extension N-S distribuée dans le domaine arrière-arc a induit la formation de metamorphic core complexes (MCCs) dans lesquels les unités de HP-BT ont été exhumées jusqu'à la surface sans rétromorphose importante, en contexte de basse pression-haute température (BP-HT). Vers 5 Ma, le système de la faille Nord-Anatolienne s'est propagé dans le domaine égéen sous la forme de décrochements lithosphériques localisés. L' étude de l'extension post-orogénique dans les Cyclades a conduit à des modèles de lithosphère continentale qui s' écroule dès que les conditions aux limites ne sont plus compressives. Dans ces modèles, ce sont les flux dans la croûte ductile qui dirigent les mouvements de blocs de croûte supérieure. A l'inverse, les modèles de lithosphère élasto- plastique permettent de rendre compte de la propagation de la faille Nord-Anatolienne. Ceux-ci considèrent que la déformation plastique est limitée à des failles qui séparent des blocs dont la déformation interne est élastique. L'opposition entre ces deux conceptions de la rhéologie de la lithosphère s'inscrit dans un débat général sur la résistance de la croûte inférieure et du manteau lithosphérique, autrefois focalisé sur la zone de collision Inde-Asie, et qui s'est partiellement déplacé vers le domaine égéen. L'objectif de mon travail est de préciser le comportement rhéologique de la lithosphère lors de l'extension post-orogénique en alliant l'acquisition de données de terrain, de pétrologie du métamorphisme et de radiochronologie Ar/Ar avec la modélisation thermomécanique. En particulier, je me suis attaché à répondre à deux questions. (1) Dans quelles conditions les MCCs " froids " peuvent-ils se former ? (2) Quelle est l'influence de la structuration de la croûte lors de la compression syn-orogénique sur les modalités de l'extension post-orogénique ? Une étude de terrain à Ios (sud des Cyclades) a permis de retrouver les traces de la structuration syn-orogénique. Le contact des SBC sur le SCC est un chevauchement à vergence sud qui a <b>fonctionné</b> dans des conditions de HP-BT. En outre, la vergence des zones de cisaillement vers le nord confirme le caractère asymétrique de l'extension post-orogénique contrôlée par des détachements vers le nord. La modélisation des assemblages minéralogiques avec le logiciel DOMINO apporte des con-traintes nouvelles sur l'évolution pression-température des unités métamorphiques de Ios. Les conditions du pic de pression (510 °C- 18. 5 kbar pour les SBC et 500 °C- 16. 5 kbar pour le SCC) ainsi que le début de l'évolution rétrograde sont différents dans les deux unités. L'exhumation syn-orogénique des unités contrôlée par les cisaillements vers le sud s'est effectuée jusqu'a' environ 400 °C- 8 kbar, conditions auxquelles les deux unités se sont solidarisées. La suite de l'exhumation se fait en contexte post-orogénique. Elle est marquée par un refroidissement continu jusqu'à 250 °C- 1 kbar, associé aux cisaillements vers le nord. Des datations Ar/Ar sur phengites ont été effectuées sur des échantillons des îles d'Andros, de Tinos, de Syros et de Ios. Trois méthodes complémentaires ont été utilisées : des méthodes conventionnelles (datation de populations et de monograins) et une méthode qui permet de dater directement la déformation (datation in situ par ablation au laser). Les données d'âge obtenues sur Andros, Tinos, Syros et Ios ont permis d'apporter des contraintes temporelles nouvelles sur l'exhumation des SBC. Intégrées à celles de la bibliographie, ces données précisent le calendrier de l'exhumation des SBC et du SCC, ainsi que les vitesses associées. L'ensemble des données acquises sur le terrain et en laboratoire permet de reconstruire la structure anté-extension de la croûte induite par l'empilement de nappes dans les Cyclades. Cette structure est caractérisée par une stratification lithologique inversée, c'est-à-dire que la croûte supérieure présentait une résistance beaucoup importante que la croûte inférieure. Cette stratification, ainsi que l'état thermique déduit des chemins P-T pour la fin de l'épisode syn-orogénique, a servi à contraindre un état initial de référence pour la modélisation. Les études paramétriques effectuées avec le code thermomécanique PARA(O) VOZ ont montré que la stratification lithologique héritée de la structuration syn-orogénique est un paramètre qui contrôle au premier ordre les modalités de l'extension post-orogénique. En particulier, une stratification lithologique inversée permet la formation de MCCs, même dans des conditions thermiques relativement froides. Les expériences numériques ont en outre montré que la formation des MCCs, dans une croûte dont la stratification lithologique est inversée, est indépendante de la résistance du manteau lithosphérique. Ce résultat, en contradiction avec ce qui est généralement admis, s'explique par le découplage majeur à la transition cassant-ductile qui intervient lors de la formation d'un MCC dans les modèles. Les travaux de modélisation ont des implications importantes sur l'interprétation de la géodynamique du domaine égéen. Comme la formation d'un MCC dans une croûte de stratification inversée est indépendante de la résistance du manteau lithosphérique, la présence des MCCs du domaine égéen n'est pas incompatible avec la propagation de la faille Nord Anatolienne dans la même lithosphère. De plus, lors de la formation d'un MCC, la croûte inférieure est transférée latéralement puis verticalement vers la croûte supérieure. Ainsi, une des conséquences de l'extension post-orogénique dans le domaine égéen est la vidange de la croûte inférieure. Ce processus est susceptible d'induire une augmentation de la résistance de l'ensemble de la lithosphère et de faciliter la propagation d'un décrochement lithosphérique. Ce travail a également des conséquences sur la compréhension de la rhéologie de la lithosphère post-orogénique. Il semble que la structure de la croûte d'une lithosphère post- orogénique peut être décrite par un modèle de " millefeuille " composé d'une succession non-standard de couches de composition et de rhéologie différentes. Une telle lithosphère a, de fait, une résistance intégrée faible à cause de l'adoucissement structural, sans que le manteau lithosphérique soit nécessairement faible. Enfin les processus de couplage et de découplage dans un " millefeuille " sont complexes. Ils permettent d'expliquer la cohérence apparente de la déformation à l'échelle de la lithosphère, sans que celle-ci soit verticalement couplée...|$|E
40|$|Abstract : The {{transfer}} of energy between excited state chromophores {{is a topic}} {{of interest in the}} area of natural and laboratory photonic devices. Indeed, energy transfer is a process seen in nature in all photosynthetic organisms from complex multicellular plants to simple, single cell photosynthetic bacteria. For example, the purple photosynthetic bacteria uses two protein assemblies, referred to as the light-harvesting protein 1 (LH 1) and the light-harvesting protein 2 (LH 2), to collect light energy in order to survive. The LH 2 protein serves only to absorb and transmit light energy to the LH 1, which contains a special pair in a central reaction center. Energy transfer is essential to the survival of the organism. A photon of light absorbed by a bacteriochlorophyll molecule in the LH 2 protein will undergo efficient energy transfer to other bacteriochlorophylls within the same protein structure. Energy transfer will also occur between different LH 2 proteins and between the LH 2 and LH 1 protein. These energy transfer processes all serve to funnel the light to the reaction center which itself is excited by energy transfer. This process is highly efficient and essential to the organism’s survival. In the area of material sciences, the design of a covalent or non-covalent donor-acceptor assembly that exhibits efficient energy transfer, is a topic of interest for application in solar energy and light emitting diodes. Using the purple photosynthetic bacteria as a model, designs that append different dyes that serve to absorb and transmit light energy to a central backbone (a process referred to as the antenna effect) are being investigated. The principle being that the use of these antenna allows for the absorption of more light in regions of the electromagnetic spectrum that we cannot necessarily obtain with a single dye. The fall-back is that, in order for the process to work efficiently, the energy transfer between the antenna and backbone must be rapid. This work presents an investigation of the energy transfer processes between oligopyrrole dyes that are bridged by a truxene core, which exhibits a structural similarity to graphene. The aim of this work is to further understand the energy transfer processes between chromophores. We demonstrate in our work that the presence of a conjugated bridge between the donor and acceptor provides the possibility of a dual energy transfer process governed by both the Förster and Dexter mechanisms. We demonstrate that the use of this conjugated bridge leads to a very fast energy transfer process despite the large distance that separates the donor and acceptor. We further demonstrate that the process, although being a dual process, is dominated by the Dexter ix mechanism which is mediated by the conjugated system connecting the donor and acceptor. The rapid and efficient energy transfer processes suggest that in order {{to take full advantage of}} the antenna effect in man-made photonic devices, designs should be built upon the use of conjugated bridges between the donor and acceptor. The work presented in this thesis is divided into eight sections. In the introduction, a brief description of the chromophores that are seen throughout the rest of this work, is provided along with some general concepts with regard to density functional theory (DFT), which was employed as a tool throughout the presented works to demonstrate a certain degree of molecular orbital coupling. Chapter 1, entitled The Basic Principles of Photophysics, provides an introductory explanation of the theory that is required to fully understand the works that are presented in this thesis. Chapter 2 is simply entitled Instrumentation and serves to provide a description of the instruments used throughout the works. In Chapter 3 : Maple™-Assisted Calculations of the J-integral: A Key Parameter for the Understanding of Excited State Energy Transfer in Porphyrins and other Chromophores a detailed description of the J-integral is provided and a tool for is calculation from spectral data is presented. The investigation of the energy transfer processes between truxene bridged chromophores begins in Chapter 4 : Origin of the Temperature Dependence of the Rate of Singlet Energy Transfer in a Three-Component Truxene-bridged Dyads. In this chapter, the energy transfer between a Zn-porphyrin donor and a set of free-base porphyrin acceptors is investigated. Circumstantial evidence suggests that the energy transfer process that is observed, is occurring through a dual mechanism that may be dominated by the Dexter mechanism is provided. Chapter 5 : Antenna Effect in Truxene-bridged BODIPY Triarylzinc(II) porphyrin Dyads: Evidence for a Dual Dexter-Förster Mechanism presents the investigation of the energy transfer processes between a BODIPY donor and two zinc(II) -porphyrin acceptors. In this chapter the comparison of the the energy transfer process to a similar dyad, that contains a non-conjugated bridge between the donor and acceptor, is made and it is shown that the truxene bridged dyad not only presents a faster rate, but that this faster rate can only be explained by a Dexter dominant process. In Chapter 6 : Very Fast Singlet and Triplet Energy Transfers in a Tri-chromophoric Porphyrin Dyad Aided by the Truxene Platform the investigation of the energy transfer between a palladium(II) -porphyrin donor and pair of Zn-porphyrin acceptors bridged by a truxene core is x carried out. Here, a very fast triplet energy transfer process is observed, coroborating that the conjugated system promotes the Dexter process and leads to an efficient {{transfer of}} energy from the donor to the acceptor. Finally, Chapter 7 presents the last work that is included in this thesis. Chapter 7 is entitled Excited State N-H Tautomer Selectivity in the Singlet Energy Transfer in a Zinc(II) Porphyrin-Truxene-Corrole Assembly and once again presents a very fast and efficient energy transfer process. In this work the energy transfer occurs between a Zn-porphyrin donor and a set to free-base corrole acceptors. The rapid energy transfer process exhibits a rate constant that falls in the same order of magnitude of those presented in the earlier chapters, suggesting that the process is occurring through the same dual mechanism that is Dexter dominated. Interestingly, in this last the energy transfer process was found to occur selectively to only one of the two corrole tautomeric species. This prompted an investigation into the excited state tautomerization rates of the free base corrole and lead to the first report of an experimentally measured tautomerization rate from free-base corrole. This thesis closes with a general discussion of the works presented within its pages and a discussion of the impact that the results have on the scientific community. Les transferts d’énergie entre les états excités de chromophores est un sujet d’intérêt dans le domaine des dispositifs photovoltaïques naturelles ou artificielles. En effet, le transfert d’énergie est un processus que l’on observe dans la nature au sein de tous les organismes phototrophes depuis les végétaux multicellulaires complexes jusqu’aux bactéries unicellulaires photosynthétiques. Par exemple, dans le cas des bactéries photosynthétiques pourpres, ces dernières utilisent un photosystème de deux protéines assemblées, la première étant appelé protéine collectrice de lumière 1 (LH 1 pour light-harvesting protein 1) et la seconde appelé protéine collectrice de lumière 2 (LH 2 pour light-harvesting protein 2) afin de capter suffisamment d’énergie lumineuse pour assurer leur survie. La protéine LH 2 n’a pour vocation que d’absorber et de transmettre l’énergie lumineuse à la protéine LH 1, qui contient une paire spéciale dans un centre réactionnel. Les transferts d’énergie sont des phénomènes essentiels à la survie des organismes. Un photon absorbé par une molécule de type bactériochlorophylle dans la protéine LH 2 subira un transfert d’énergie efficace à d’autres bactériochlorophylles au sein de la même structure protéique. Les transferts d’énergie se dérouleront aussi bien entre différentes protéines LH 2 qu’entre des protéines LH 1 et LH 2. Ces processus de transfert d’énergie servent à canaliser l’énergie lumineuse jusqu’au centre réactionnel qui devient à son tour excité par transfert d’énergie. Ces processus sont hautement efficaces et essentiels à la survie de l’organisme en question. En science des matériaux, la conception d'un assemblage donneur-accepteur, covalent ou non, qui présente un transfert d'énergie efficace est un sujet d'intérêt pour des applications en photovoltaïque et diodes émettrices de lumière. En utilisant les bactéries pourpres photosynthétiques comme modèle, des structures similaires étudiant différents colorants permettant d'absorber et de transmettre de l'énergie lumineuse à un squelette central (un processus appelé effet antenne) font l'objet de recherches actives. Le principe étant que l'utilisation de ces antennes permet d'absorber plus de lumière dans les régions du spectre électromagnétique qu’il serait impossible d’obtenir avec un seul colorant. La conséquence est que, pour que le processus <b>fonctionne</b> efficacement, le transfert d'énergie entre l'antenne et le squelette doit être rapide, et parfois contrôlé. Dans ce travail, nous étudierons les processus de transfert d'énergie entre des colorants oligopyrroliques reliés par un noyau truxène, qui montre une similarité structurale avec le graphène. L'objectif du travail est de mieux comprendre les processus de transfert d'énergie entre les chromophores. Nous montrerons dans notre travail que la présence d'un système conjugué entre le donneur et l'accepteur ouvre la porte à l’hypothèse de la présence d'un double processus de transfert d'énergie régi par les mécanismes Förster et Dexter. Nous démontrerons que l'utilisation de ce système conjugué conduit à un processus de transfert d'énergie très rapide malgré la distance importante séparant le donneur et l’accepteur. Nous démontrerons en outre que le processus, bien qu'il s'agisse d'un double processus, est dominé par le processus Dexter grâce au système conjugué reliant le donneur et l'accepteur qui fait office de pont communiquant. Les processus de transfert d'énergie rapides et efficaces suggèrent que, pour tirer pleinement parti de l'effet antenne dans des applications photovoltaïques, les designs devraient être basés sur l'utilisation de ponts conjugués reliant donneurs et accepteurs. Le travail présenté dans cette thèse est divisé en huit sections. Dans l'introduction, une brève description des chromophores utilisés tout au long du présent travail sera fournie avec des concepts généraux non-exhaustifs pour la théorie de la fonctionnelle de la densité (DFT) qui a été utilisé comme outil tout au long des travaux actuels pour démontrer un certain degré de couplage orbitalaire. Le chapitre 1, intitulé Les principes fondamentaux de la photophysique, proposera une introduction à la théorie nécessaire à la bonne compréhension des travaux présentés dans cette thèse. Le chapitre 2 est simplement intitulé Instrumentation et fournira une description des instruments utilisés tout au long des travaux. Au chapitre 3 : « Maple™-Assisted Calculations of the J-integral: A Key Parameter for the Understanding of Excited State Energy Transfer in Porphyrins and other Chromophores », une description détaillée de l'intégrale J ainsi qu’un outil pour le calcul à partir de données spectrales seront exposés. L'étude des processus de transfert d'énergie entre les chromophores pontés par truxène commencera au chapitre 4 : « Origin of the Temperature Dependence of the Rate of Singlet Energy Transfer in a Three-Component Truxene-bridged Dyads ». Dans ce chapitre, nous étudierons le transfert d'énergie entre un donneur de type zinc(II) -porphyrine et un ensemble d'accepteurs de porphyrine base libre. Des preuves circonstancielles indiquant que le processus de transfert d'énergie observé se produit à travers un double mécanisme qui peut être dominé par le mécanisme Dexter seront présentées. Le Chapitre 5 : « Antenna Effect in Truxene-bridged BODIPY Triarylzinc(II) porphyrin Dyads: Evidence for a Dual Dexter-Förster Mechanism » présentera quant à lui l'étude des processus de transfert d'énergie entre un donneur BODIPY et deux accepteurs de type Zn-porphyrine. Dans ce chapitre, la comparaison du processus de transfert d'énergie à une dyade similaire qui contient un pont non-conjugué entre le donneur et l'accepteur sera effectuée et il sera démontré que la dyade ponté par truxène présente non seulement un taux plus rapide, mais que ce taux ne peut être expliqué que par un processus Dexter dominant. Au chapitre 6 : « Very Fast Singlet and Triplet Energy Transfers in a Tri-chromophoric Porphyrin Dyad Aided by the Truxene Platform », l'étude du transfert d'énergie entre une porphyrine de palladium(II) donneuse et une paire d'accepteurs de type zinc(II) -porphyrine pontés par un noyau de truxène sera montré. Ici, un processus de transfert d'énergie triplet très rapide est observé, ce qui prouve que le système conjugué favorise le processus Dexter et conduit à un transfert efficace d'énergie du donneur vers l'accepteur. Enfin, le chapitre 7 présentera le dernier travail inclus dans cette thèse. Le chapitre 7 est intitulé « Excited State N-H Tautomer Selectivity in the Singlet Energy Transfer in a Zinc(II) Porphyrin-Truxene-Corrole Assembly » et exposera une dernière fois un processus de transfert d'énergie très rapide et efficace. Dans ce travail, le transfert d'énergie se produit entre un donneur de type Zn-porphyrine et une corrole base libre acceptrice. Le processus de transfert d'énergie rapide présente une constante de vitesse qui se situe dans le même ordre de grandeur que ceux présentés dans les chapitres précédents, ce qui suggère que le processus se produit par le biais du même double mécanisme dominé par Dexter. Il est intéressant de noter que, dans ce dernier cas, le processus de transfert d'énergie s'est révélé sélectif sur l'une des deux espèces tautomériques du corrole. Ceci a mené à une étude sur les taux de tautomérisation de l'état excité de la corrole base libre conduisant à la premier mesure expérimentale du taux de tautomérisation de la corrole base libre. Cette thèse s’achèvera par une discussion générale sur les travaux présentés dans ces pages ainsi que sur l'impact que les résultats ont eus dans communauté scientifique dans ce domaine...|$|E
40|$|International audienceIn video games, {{the body}} {{is central to the}} experience. Even when it is not represented, as in First Person Shooters for instance, it remains a place of vertigo. This {{impossible}} disembodiment assuredly expresses a feeling of loss of control and imbalance. Should the player have the «hand of God" or should he be a third person avatar, he moves in the here and now, through digital devices in a virtual space or an augmented reality. As a real, intimate and alien place, our body is central to our perception of the world. It is through it, with it, that we watch, touch, smell, listen. The body is the familiar and intimate space of our lives. It sometimes is the only witness to certain actions or thoughts otherwise condonable. As Michel Foucault said in «Le Corps utopique", "I can’t move without him, I can’t leave it where it is and go, myself, elsewhere. I could go {{to the end of the}} world, I could cringe in the morning under my blankets, make myself as small as I could, let myself burn in the sun on a beach, there it will always be, where I am. It is here, and nowhere else. «And yet, one of the peculiarities of the body with which we are permanently attached is that it often works without our conscious input. As a matter of fact, only pain and dysfunction allows us to recall its presence. When our eyes accidentally capture our reflection in a window or when we discover our expressions and poses on a photograph, we often experience difficulty recognizing ourselves physiologically. Thus we feel intimately connected to our bodies, but its social and aesthetic representation almost entirely escapes us. Hence perhaps our time spent dressing up, being other, carving ourselves to control this reflection. A game's avatar becomes a reflection of this elsewhere, stranger to his own image, yet embedded in everyday cultural practices. In video games, the player plays with his identity and progresses masked to achieve the ultimate dream of a ubiquitous place, where he will finally be another one. Today's media and video games act as symbolic avatars where are built the models of socialization and our individual identities. As such the individual incorporates, both symbolically and unconsciously, attitudes issued from the prevailing spirit of its inhabited time through singular practices and uses. Henceforth, the stereotypical representations associated with the body configure, discipline and dominate the individual, allowing him new experiences, discoveries and other cognitive and communicational skills. For Michel Foucault, the definition of identity as a set of relationships with others (of varied class, gender, and culture) is crossed and shaped by various hegemonic forms. In cultural studies, these representations are the expression of what is called a soft power. Indeed, «by incorporating these values, from game to game, in all of our lives, these products actively generate consent[1] ". Which invites, methodologically speaking, to consider immediately the links between symbolic forces, where hegemonic values, especially technological ones, are confronted to countercultural values until these one are in turn getting back by the process of speculative, polymorphic, opportunistic capitalism – this hegemonic figure of the contemporary world. In this way some games like Call of Duty (while they require payment for access) provide possibilities for customizing objects, weapons, accessible spaces, unusual venues for agile players with their credit card. At the heart of player-experience, marketing solicitations are coloring the structure of game mechanics, and, according to financial players, players can acquire a specific eye retina or get access to unpublished areas (Call Of Duty on Xbox 360 using the Kinect device). This hyper rationality increased of the body, is also expressed in the transhuman and posthuman ultimate dream, trying to overcome nature by incorporating the technique in order to achieve immortality (Bioshock, Deus Ex Human Revolution, Minority Report). In recent years, augmented reality has colonized the familiar gestures and video game action with the arrival of touch and gestural interfaces, video game consoles (Wii and Nintendo DS, Kinect, Microsoft Xbox and Sony Move, PlayStation) and various other technical features such as Leap Motion, tablets and cell phones. Actions unfold and dancing fingers on the keyboard becomes involuntary choreographies in the living room, on the street or becomes sensual caress of singular objects. Copenhagen Game Collective gave us B. U. T. T. O. N (Brutally Unfair Tactics Totally OK Now) and Magnetize me: these games disguise the social space with meetings and conviviality, and invite players in body contact. At the same time as the body become interfaces, devices leave the screen and grow to be seized. In this way Gigantomachia by One Life Remains or Giant Joystick by Tiltfactory depicts situations of gigantism, wondering the miniaturization of electronic components and the hyperindividualisation of computers-player relationships. In Giant Joystick, Mary Flanagan depicts a giant Joystick such as a phallus, highlighting ironically male hegemony of these practices: players find themselves caressing and embracing the joystick to interact. These intuitive interfaces allow different categories of players to have fun, regardless of their practices. Also parents, grandparents and teenagers can share a play time in which a pleasure of “playing together” seems necessary. The video game is no longer reserved to stereotype hardcore players – adolescent, geek and asocial. On the Wii Fit, we see women doing fitness activities; we see pensioners in nursing homes enjoying the Wii bowling, or also patients with the physiotherapist rehabilitating themselves with a video game. Everyone seems happy, dynamic and powerful in this gamefull society! However by carrying bodies, these interfaces create psychological discomfort. They force a performative staging, which borrows from smiles with disarray, but which also shows the difference between the canonical and ideal body presents in virtual worlds and visible and material reality. This gap is so important that it is impossible to transfer mechanisms, rhythms and sequences of actions feasible on the keyboard, of video games ‘standards to gestural devices. So if the avatar and the keyboard disappear, the player finds himself in a destabilizing primitive nakedness, where he has to face a virtual and technological space with his own body. A new kind asserts oneself with these new interfaces: the "slow gaming" close to the concept of "calm computing" by Mark Weiser probably making echo movements such as "slow food" interfaces. In this way the work of Flower That Game Company, offers PlayStation 3 games where the player is either the wind or a flower petal in a poetic walk. Child Of Eden - adaptation of the game Rez - uses the Kinect peripheral for the Xbox 360 console in a sweet musical performance that respects the rhythm of human body. Dans les jeux vidéo, le corps est central. Quand bien même celui-ci ne serait pas représenté comme dans les jeux de tir à la première personne (First Person Shooter), il reste le lieu d’un vertige. L’impossible désincorporation s’exprime assurément dans un sentiment de perte de contrôle et de déséquilibre. Que le joueur ait « la main de Dieu » ou qu’il soit l’avatar à la troisième personne, il se déplace, ici et maintenant, par l’intermédiaire de périphériques dans un espace virtuel numérique ou une réalité augmentée. Comme lieu réel, intime et étranger, le corps est au centre de notre perception du monde, c’est de lui et avec lui que nous regardons, touchons, sentons, écoutons. Le corps est l’espace familier et intime de notre vie, il est même parfois le seul témoin de certaines actions ou pensées inavouables. Comme le dit Michel Foucault dans « le corps utopique », « je ne peux pas me déplacer sans lui; je ne peux pas le laisser là où il est pour m’en aller, moi, ailleurs. Je peux bien aller au bout du monde, je peux bien me tapir, le matin, sous mes couvertures, me faire aussi petit que je pourrais, je peux bien me laisser fondre au soleil sur la plage, il sera toujours là où je suis. Il est ici irréparablement, jamais ailleurs. » Et pourtant, une des particularités de ce corps auquel nous sommes irrémédiablement attachés est qu’il <b>fonctionne</b> sans que nous en ayons toujours conscience. D’ailleurs, seule la douleur et ses dysfonctionnements rappellent sa présence. Lorsque notre regard capte par hasard notre reflet dans une vitrine ou que nous découvrons nos expressions et allures sur une photographie, nous éprouvons souvent des difficultés à nous reconnaître physiologiquement. Ainsi nous nous sentons intimement liés à notre corps, mais sa représentation sociale et esthétique nous échappe presque entièrement. D’où sans doute le temps passé à s’habiller, à se faire autre, à se sculpter, pour tenter de maîtriser ce reflet, cette image projetée vers les autres. L’avatar vidéoludique devient le reflet de cet ailleurs, l’étranger de sa propre image, incorporé pourtant dans des pratiques culturelles quotidiennes. Dans les jeux vidéo, le joueur joue avec son identité et avance masqué pour trouver avec et dans l’avatar la possibilité d’atteindre l’ultime rêve d’un lieu ubiquitaire où il serait enfin autre. Les médias et les jeux vidéo jouent aujourd’hui le rôle d’avatars symboliques où se construisent les modèles de socialisation et l’identité des individus. Ainsi l’individu incorpore symboliquement et inconsciemment des comportements, acquiert des mentalités issues de l’esprit dominant du temps par le biais de pratiques et d’usages singuliers. Dès lors les représentations stéréotypées attachées aux corps configurent, disciplinent et dominent l’individu, tout en lui permettant de faire de nouvelles expériences et de découvrir d’autres capacités cognitives et communicationnelles. Pour Michel Foucault, la définition de l’identité comme des relations avec autrui (de classe, de genres, de culture) sont traversées et façonnées par diverses formes hégémoniques. En études culturelles, ces représentations sont l’expression d’un pouvoir dit doux (softpower). En effet, « en incorporant ces valeurs, de jeu en jeu, dans notre vie à tous, ces produits ludiques fabriquent du consentement[1] »[i]. Lequel invite, méthodologiquement parlant, à considérer immédiatement les rapports de forces symboliques en présence, où les valeurs hégémoniques, et notamment technologiques, viennent se confronter aux valeurs en résistance, jusqu’à ce que ces dernières soient récupérées par le processus d’un capitalisme spéculatif, polymorphe et opportuniste, cette figure hégémonique du monde contemporain. Ainsi certains jeux comme Call of Duty (alors qu’ils sont payants d’accès), offrent des possibilités de personnalisation d’objets et d’armes, des espaces accessibles, des lieux inédits pour les joueurs agiles de leur carte bancaire. Au cœur même de l’expérience-joueur, des sollicitations marketing viennent colorer la structure des mécanismes de jeu, et selon les moyens financiers des joueurs, ceux-ci peuvent acquérir une rétine oculaire spécifique ou accéder à des zones inédites (Call Of Duty sur Xbox 360 utilisant le périphérique Kinect). Cette hyperrationalité augmentée du corps, s’exprime également dans l’ultime rêve transhumain et posthumain en cherchant à dépasser la nature par incorporation de la technique afin d’atteindre l’immortalité (Bioschok, Deus Ex Human Revolution, Minority Report). Ces dernières années, la réalité augmentée a colonisé les gestes familiers et les actions vidéoludiques avec l’arrivée d’interfaces tactiles et gestuelles, de consoles de jeux vidéo (Wii et la DS chez Nintendo, Kinect chez Microsoft Xbox et Move chez Sony, Playstation), ainsi que d’autres dispositifs techniques différents tels que la Leap Motion, les tablettes tactiles et les téléphones cellulaires. Les gestes se déploient et la danse des doigts sur le clavier se transforme en chorégraphies involontaires dans le salon, dans la rue ou devient caresse sensuelle d’objets singuliers. Copenhague Game Collective propose B. U. T. T. O. N (Brutally Unfair Tactics Totally OK Now) et Magnetize me, où les jeux viennent habiller l’espace social de rencontre et de convivialité en invitant les joueurs au contact corporel. En même temps que les corps deviennent interfaces, les périphériques quittent l’écran et grandissent afin d’être saisis, ainsi Gigantomachie de One Life Remains ou Giant Joystick de Tiltfactory mettent en scène des situations de gigantisme, interrogeant la miniaturisation des composants électroniques et l’hyperindividualisation des relations ordinateurs-joueurs. Dans Giant Joystick Mary Flanagan met en scène un Joystick géant tel un phallus mettant en évidence ironiquement l’hégémonie masculine de ces pratiques : les joueurs se retrouvent à caresser et embrasser ce joystick pour interagir. Ces interfaces intuitives permettent à différentes catégories de joueurs de prendre du plaisir, quelles que soient leurs pratiques. Ainsi parents, grands-parents et adolescents peuvent partager un temps de jeu où s’impose un plaisir de « jouer ensemble », le jeu vidéo n’étant plus réservé à des joueurs inconditionnels dont le stéréotype est l’adolescent, geek et asocial. On voit alors des femmes sur la Wii Fit faire leurs activités de fitness, des retraités dans les maisons de retraite s’amuser au Wii bowling, des patients chez le kinésithérapeute se rééduquer devant un jeu vidéo. Tous semblent heureux, dynamiques et performants dans une société de plus en plus gamifiée ! Pourtant en convoquant les corps, ces interfaces créent aussi un malaise psychologique, elles forcent une mise en scène performative, qui, si elle fait rire de désarrois, montre l’écart entre les canons d’un corps idéal dans les univers virtuels et sa réalité matérielle visible. Cet écart apparaît alors si important qu’il est impossible de transférer les mécanismes de jeu vidéo standards vers ces dispositifs gestuels, les rythmes et les séquences d’actions devenant irréalisables hors du clavier. Ainsi si l’avatar et le clavier disparaissent, le joueur se retrouve dans une nudité primitive déstabilisante, où il doit avec son seul corps se confronter à un espace virtuel et technologique. Un nouveau genre s’affirme alors avec ces interfaces le « slow gaming » proche du concept de « calm computing » de Mark Weiser faisant sans doute écho aux mouvements tels que « slow food ». Ainsi l’œuvre Flower de That Game Compagny, propose un jeu sur PlayStation 3 où le joueur incarne soit le vent soit un pétale de fleur dans une promenade poétique. Child Of Eden adaptation du jeu Rez, utilise le périphérique Kinect de la console Xbox 360 dans une performance musicale douce qui respecte le rythme corporel humain...|$|E
40|$|China {{realized}} {{during the}} last 15 years spectacular economic growth success. However, its economic growth was also accompanied by serious environmental degradation problems. China has been ranked {{as one of the}} most polluted countries in the world by some international organizations, particularly on the aspect of air pollution. Although many scholars start to consider China as the future number one economic power given its current marvelous economic success, the verification of such hypothesis closely depends on the sustainability of China's future growth path—its actual economic growth speed can be sustainable only if today's economic achievement is not obtained by mortgaging that of tomorrow. This dissertation, focusing on the case of industrial SO 2 emission in China, aims to study the potential relationship between economic growth, trade liberalization and environment in China, in the aims of identifying the possibility, the sufficient and necessary conditions for China to realize its sustainable development. After a comprehensive literature review on the existing Environmental Kuznets Curve studies, I started my analysis by a reduced-form Environmental Kuznets Curve analysis (Chapter 2). The results showed that although the EKC analysis predicts a turning point at about 9000 yuan (1990 price) for the case of per capita industrial SO 2 emission, the evolution of total industrial SO 2 emission seems to continue its increasing tendency. To understand the underlying reasons for the increasing tendency in total SO 2 emission, I further carried out two structural analyses, in which the structural determinants of SO 2 emission are decomposed either parametrically (Chapter 3) or non-parametrically (Divisia index decomposition method based on the detailed data on production and SO 2 emission intensity of 13 industrial sectors in each province during 1991 - 2001, Chapter 4) into scale, composition and technique effects. The results showed that, the per capita income, acting as an omnibus variable representing all the three aspects of underlying structural determinants, only impart a “net-effect” of income growth on environment. The real reason for the ever-increasing trend of total industrial SO 2 emission in China is actually due to the domination of pollution-increasing impact of scale enlargement over the pollution-reducing contribution from technical progress, combined with a province-specific composition transformation which exerts modest pollution-increasing impact in most of the Chinese provinces, given their current industrialization process. The second part of this dissertation further amplified my decomposition efforts by giving particular attention to the emission determination role of international trade. Previously redeemed by some pessimistic economists as a channel for the richer developed countries to discharge their pollution burdens to their poorer trade-partners, international trade has been considered as a static explanation for the formation of the inverted-U-shaped growth-pollution relationship. Nevertheless, all three analyses carried out in this part, by investigating the different channels through which international trade can exerts impact on the three determinants of emission, only provide very limited supportive evidence for the “pollution haven” hypothesis in China. As China's factor-endowment-based comparative advantages are much attractive than its potential as a “pollution haven”, the conclusion of the ACT-style (Antweiler, Copeland and Taylor, 2001) model estimation in Chapter 5 shows that trade liberalization can actually reduce the pollution burden of China's industrialization process by deviating its industrial composition transformation towards less polluting labour-intensive sectors. By noticing that the actual role of trade is more complicated, in Chapter 6, I re-employed the decomposed results of Chapter 4 and further checked the indirect impact of trade (export and import separated this time) on industrial emission through its three structural determinants. This study confirmed the significantly positive impact of trade in both scale enlargement and technical progress. The analysis based on a simultaneous system in Chapter 7 permits me to combine these three aspects' indirect impact of international trade on emission into the same estimation. Its results reveal the total role of export in China is environment-friendly while that of import (measured by the accumulation of imported machinery and equipments) is pollution-enhancing. In the CGE model analysis in Chapter 8 (Part 3), I related emission results directly to energy input used in production activities and included the principal coefficients estimated in the previous into the modelling and simulation work. This model offered me an opportunity to parameterise the multiple aspects of trade-pollution and growth-pollution nexus and to finally obtain an explicit numerical comparison between the magnitude of environmental impact of trade and economic growth. This analysis reveals that, compared to the scale effect resulting from rapid economic expansion in China, the actual pollution-increasing impact of trade liberalization is very small. The most important pollution reduction contribution actually comes from efficiency improvement in energy uses and depends largely on the existence of a more stringent and efficient pollution control policies combined with a flexible energy substitution process. Facing the potential dangers for China's future environmental situation, I investigated in the chapter 9 (Part 3) the potential feedback effect from pollution to China's future growth sustainability. The analysis reveals a significant negative relationship between industrial SO 2 emission and public health after the industrial SO 2 emission density attains the critical threshold of 8 g/m 2. Fortunately, the estimated model inn this chapter seems also to reveal some possible dynamism through which the significant negative impact of industrial SO 2 emission on public health status can be gradually reduced with economic growth. But to realize this dynamism, China need to realise a more-than-proportion increase in de-sulfur technology investment with respect to its economic growth rate in the coming years. To sum up, the analyses carried out in this dissertation actually indicate both opportunity and challenge for China's pursuit for a sustainable development path. Given the current environmental deterioration tendency, whether China can preserve its future growth sustainability actually depends on the existence of the technological capacities to improve the pollution abatement efficiency (sufficient condition) and the correct function of a stricter pollution control policies (necessary condition). Both aspects further put forward the requirement for the availability of efficient institutional and market system in China. La Chine, pays le plus peuplé du monde, connaît depuis une quinzaine d'années des taux de croissance spectaculaires. Malheureusement, cette croissance a aussi été accompagnée d'une très forte dégradation de l'environnement et a positionné la Chine parmi les pays les plus pollués du monde, notamment au niveau de son atmosphère. Ainsi, le considérable succès que représente cette croissance économique, au point de vouloir présenter la Chine comme la prochaine première puissance économique mondiale, conduit à poser la question de sa soutenabilité. Nous postulons que la croissance actuelle de la Chine ne pourra être durable que dans la mesure où elle n'hypothèque pas celle de son futur. Cette thèse se base sur le cas de l'émission industrielle de SO 2 – la pollution aérienne la plus importante en Chine. En analysant son évolution au cours des années 1990 et en se focalisant sur ses relations avec la croissance économique, l'industrialisation et l'ouverture commerciale – les trois caractères les plus évidents du développement économique chinois –, cette thèse vise à identifier la possibilité et les conditions nécessaires et suffisantes pour la Chine de réaliser un développement soutenable. Après une revue de la littérature sur la Courbe de Kuznets Environnementale (CKE), nous commençons notre analyse par l'étude d'une CKE de forme réduite (Chap. 2), qui révèle une relation assez optimiste entre la croissance chinoise et l'émission industrielle de SO 2 par tête. Cependant, cette CKE « par tête » ne garantit pas un même retournement de trajectoire pour l'émission industrielle totale de SO 2. Bien que notre analyse prédise ce retournement aux environs de 9000 yuan par tête (prix constants 1990) pour le cas de l'émission industrielle de SO 2 par tête, l'évolution de l'émission industrielle de SO 2 totale semble continuer à augmenter. Pour comprendre les raisons de cette tendance à la hausse de l'émission industrielle de SO 2 totale, nous menons deux analyses structurelles, dans lesquelles les variations de l'émission sont décomposées de façon paramétrique (Chap. 3) et non-paramétrique (la méthode de décomposition de l'indice de Divisia basée sur des données détaillées de la production et de l'intensité d'émission de SO 2 de 13 secteurs industriels dans chaque province entre 1991 et 2002, Chap. 4) en contributions de ses trois déterminants structurels - effets d'échelle, de composition et de technique. Les résultats montrent que le revenu par tête <b>fonctionne</b> comme une variable omnibus qui capte les effets des trois déterminants structurels et révèle seulement un « effet net » de la croissance sur l'environnement. Le détail de nos analyses permet cependant de trouver les véritables raisons de cette tendance à la hausse de l'émission industrielle de SO 2. Cela serait principalement dû à une domination de l'effet d'échelle sur l'effet réducteur d'émission issu des progrès techniques, le tout combiné à une transformation de la composition industrielle exerçant un modeste impact à la hausse des émissions dans la plupart des provinces chinoises. La seconde partie de cette thèse accroît ses efforts de décomposition en donnant une attention particulière au rôle déterminant du commerce international sur l'émission. Perçu par certains économistes pessimistes comme un canal à travers lequel les pays riches déchargeaient leurs fardeaux de pollution sur leurs partenaires commerciaux relativement plus pauvres (hypothèse de « havre de pollution »), le commerce international a ainsi souvent été considéré comme une explication statique de la formation d'une relation en U inversé entre le revenu et la pollution. Cependant, les trois analyses menées dans cette partie, en recherchant les différents canaux de transmission à travers lesquels le commerce affecte les trois déterminants structurels de l'émission, nous offrent pour la Chine des preuves très limitées en faveur de l'hypothèse de « havre de pollution ». Etant donné que l'avantage comparatif de la Chine basé sur sa dotation extrêmement riche en travail est beaucoup plus attractif que son avantage de « havre de pollution », la conclusion d'une analyse de style Antweiler, Copeland et Taylor (ACT, 2001) au Chapitre 5 nous montre que la libéralisation commerciale peut réduire les dangers d'une augmentation de pollution liée à l'effet de « havre de pollution » en guidant la transformation de la composition industrielle chinoise vers les secteurs intensifs en travail, souvent considérés comme moins polluants. Le rôle du commerce sur l'environnement n'est cependant pas aussi simple. Dans le Chapitre 6, en re-employant les résultats de la décomposition de Divisia du Chapitre 4, nous vérifions les impacts indirects du commerce (exportations et importations introduites de façon séparées) sur l'émission à travers les trois déterminants structurels. Cette analyse confirme l'impact significativement positif du commerce dans l'élargissement de l'échelle de production et sur les progrès techniques. Les analyses basées sur un système d'équations simultanées au Chapitre 7 nous permettent de combiner ces trois aspects des impacts indirects du commerce sur l'émission et d'inclure leurs interactions potentielles dans une même estimation. Les résultats révèlent que le rôle total des exportations est positif pour l'environnement mais que celui des importations (mesurées par l'accumulation de machines et d'équipements importés) est négatif. Dans le modèle en Equilibre Général Calculable (EGC) du Chapitre 8 (Partie 3), nous relions directement les résultats de l'émission à la combustion des énergies dans les activités productives et incluons toutes les interactions entre les variables économiques et l'environnement dont nous avons pu discuter dans les chapitres précédents pour la spécification du modèle. Ce modèle nous offre l'opportunité de paramétrer et de simuler de multiples aspects des relations entre croissance, ouverture commerciale et émission. Les simulations basées sur ce modèle nous permettent d'obtenir des comparaisons numériques de l'ampleur des impacts environnementaux du commerce et de la croissance économique. La conclusion de ce chapitre montre que, sans une politique de contrôle de pollution plus efficace, la croissance économique chinoise devrait s'avérer très polluante et que l'accession à l'OMC devrait provoquer une hausse supplémentaire mais marginale de pollution. En considérant les dangers potentiels de cette situation sur l'environnement chinois, nous décidons de rechercher dans le dernier chapitre de cette thèse (Chap. 9) l'effet de « feedback » potentiel de la pollution sur la capacité de croissance de l'économie chinoise. Les résultats confirment un effet négatif de l'émission de SO 2 sur la prévalence des maladies chroniques au sein de la population. Une fois dépassé le seuil de 8 g/m 2, une augmentation de 1 g/m 2 de la densité de l'émission industrielle de SO 2 accroît la probabilité pour une personne représentative de souffrir de maladies chroniques de 0, 25 %. Cependant, si les progrès techniques réalisés dans les activités de contrôle de la pollution augmentent de façon continue dans le temps, nos résultats indiquent également une dynamique potentielle pouvant réduire de façon graduelle l'impact négatif de la pollution sur la santé avec la croissance économique. En résumé, les analyses menées dans cette thèse présentent un certain nombre de défis à relever et d'opportunités à saisir pour que la Chine puisse poursuivre un chemin de développement qui soit soutenable. Etant donnée la tendance actuelle à la détérioration de son environnement, la capacité de la Chine à préserver une croissance soutenable dans le futur dépendra étroitement de l'adoption de progrès techniques (conditions suffisantes) et d'un fonctionnement efficace et plus strict des politiques de contrôle de pollution (conditions nécessaires), ainsi que d'une meilleure efficacité des systèmes institutionnels et de marché...|$|E
40|$|SUMMARYThis methodological {{study of}} {{quantitative}} electroencephalography {{starts with the}} history of EEG methods of analysis and of their applications. This thesis is basically focused on a comparative study of the most important methods of analysis. In the presentation of methods I first present the analysis of the instantaneous amplitude histograms of EEGs which is dependent upon the sampling frequency. Considering now the Fourier spectral analysis this method implies to take quite a number of precautions before being properly applied to EEG. For instance, it is necessary to compute enough measures to allow later on the statistical validation of a power spectrum analysis G(f). Then, I propose the example of spectral multiple EEG channels analysis, which is based on the method of spectral regression. This method of analysis gives more precisely the relations of causality at specific frequencies by finding their sources across EEG channels and determining if those sources are based on real signals source or random noise. I have later specified the mathematical relations between the integrative method of Drohocki and spectral analysis. The mean value l of n measures of successive epochs of an EEG signal, which is rectified and integrated: l is proportional to the root­mean­square (rms) value of the analyzed signal and also to its standard error. The coefficient of variation CV(l) of the integrated measures is proportional to the spectral coefficient of variation CV(k), which for a first approximation is equal to k/√T, with T being the time epoch of analysis and k a “coefficient of spectral regression” that I have defined by the formula (k 2 = ∑G 2 /(∑G) 2) in reference to Blackman and Tuckey. This presentation of methods is achieved with the period analysis and its relations to spectral analysis, followed by a brief survey of new heuristic methods, which are mimicking the electroencephalographist practitioner in his way and are applying methods of linear prediction. My results are divided into three chapters. In the first chapter I present first Applications of quantitative EEG recorded in rat. Then I give three examples of applying the integrative method of Drohocki. First by computing the ratio of integrated values of ECoG/EMG for quantifying the phases of wakefulness and sleep. When this ratio is above or below an experimentally first computed predetermined threshold, this ratio can well determine the state of wakefulness or sleep. I have applied this technique {{to the study of the}} hypovariability of the ECoG and of the neck muscles EMG recorded in rats before and after administration of neuroleptics. The ECoG/EMG ratio provides the time­course of the electro­pharmacokinetic effect through hours of the neuroleptic treatment. Secondly I have studied the statistical decomposition of the observed polymodal composite distributions of values of integrated ECoG signals computed over successive periods of one­hour time span. Such an analysis provides a decomposition of these polymodal distributions into a sum of elementary Gaussian distributions. Each elementary Gaussian distribution being specific of a homogeneous state of vigilance. Thirdly, this chapter is mainly concerned with the comparative study between the three different tracings of occipital ECoG in the rat for quantifying homogeneous phases of wakefulness, slow wave sleep and REM sleep (paradoxical sleep). The four principal methods of EEG analysis previously compared theoretically, have then been now compared experimentally, based on the three different states of vigilance. I have first verified the precedent mathematical relationships established between the integrative method and spectral analysis. By correlation analysis and multi­linear regression, I have been able to obtain pertinent information which has been reduced to 5 independent parameters. Step-by­step discriminant analysis has shown that the mean frequency of the spectral peak and the mean integrated amplitude are sufficient for a good discrimination between the three analyzed states of vigilance. The second chapter of results is based on EEG recordings in man. in order to give Applications of quantitative EEG recorded in man. I describe a program of statistical spectral analysis, which works in real time based on four EEG channels simultaneously recorded with a double rejection of artifacts and a pre­treatment of the sampled EEGs. After longitudinal studies of different quantified recordings I have computed a four factor variance analysis on a transversal study sample of EEG recordings for a group of 7 subjects receiving two different treatments (placebo at the beginning of the night before and nitrazépam 5 mg, p. o. the day after), 2 sequences (eyes open followed by eyes closed EEG recordings), 4 posterior EEG channels, and computed characteristic spectral parameters. Results of variance analysis reveal that only sequences and parameters appear to be statistically different. Later further 3 factor variance analyses over the 32 computed spectral parameters have found, which parameters are the best discriminant parameters between EEG sequences : the spectral peak, the coefficient of resonance and of complexity, the fast mean frequencies. etc. These factorial analyses have allowed me to compare spectral differences between two mean power spectra by applying Student t tests in different conditions : between treatments, sequences, EEG channels and between subjects. Finally, in the third chapter of results, I have presented a first modulation analysis of EEG by applying Hilbert transform to EEG. Starting from an EEG signal x(t) we can evaluate a signal y(t), which is characterized by a Gaussian random narrow band process, from an analysis of modulation y(t) = m(t) cos(ω 0 t + φ(t)), with m(t) being the amplitude modulation and φ(t) the frequency modulation around a broadcasting frequency ω 0 = 2 πfo. This modulation analysis is based on the Hilbert transform ˆx(t) obtained from the Fourier transform X(f) of x(t), by a multiplication by (­j. sign(f)) followed by inverse transformation. This gives directly the computation of the “envelope” m(t) of x(t), in the radioelectric sense of the word envelope. The frequency modulation is obtained directly by derivation of the phase modulation. I have applied this analysis to the precedent three tracings of states of vigilance in rat. I have found that the hippocampal theta rhythm is characteristic of a specific amplitude modulation during the REM state of sleep in rat together with a frequency modulation, which is not present in the two other states of wakefulness and of slow wave sleep in rat. This last method can be applied in case of non­stationary EEG tracings and it keeps all the signal information. The amplitude and frequency modulations are specific respectively of the instantaneous amplitude and frequency and we know the difficulty to obtain directly this last instantaneous frequency. This is why I have attempted to apply the techniques of statistical radioelectricity in quantitative electroencephalography. In this thesis, which is based on 15 articles, I have wanted to illustrate the theory of analysis of electrobiological signal by some various examples of applications in animal and in man. I have wished to show also how new methods of analyses may lead and drive to new applications. Cette étude méthodologique de l'électroencéphalographie quantitative fait d'abord l'historique des méthodes d'analyse de l'EEG et de leurs applications. Cette thèse est centrée principalement autour de la comparaison des principales méthodes d'analyse. Dans l'exposé des méthodes, je présente tout d'abord l'analyse des histogrammes d'amplitudes instantanées de l'EEG, qui dépend de la fréquence d'échantillonnage. L'analyse spectrale exige un certain nombre de précautions pour être correctement utilisée. C'est ainsi qu'il convient de moyenner suffisamment les mesures effectuées si l'on veut procéder à une validation statistique d'un spectre de puissance G(f). Je propose ensuite l'exemple d'une analyse multivoies appliquée à quatre dérivations enregistrées simultanément et qui utilise la méthode de "régression spectrale". Cette analyse permet de préciser les relations de causalité de fréquences particulières, en déterminant leur origine parmi les dérivations et s'il s'agit d'une source ou d'un bruit. J'énonce ensuite les relations mathématiques qui relient particulièrement la méthode intégrative de DROHOCKI et l'analyse spectrale. La moyenne I de n mesures successives d'EEG redressé et intégré, est proportionnelle à la valeur efficace du signal analysé, ou bien encore à son écart type. Le coefficient de variation des mesures intégrées CV(I) est proportionnel à un coefficient de variation spectral CV(k) qui est égal en première approximation à k/√T. où T est la période d'analyse et k est un "coefficient de résonance spectral" que j'ai défini (k 2 = ∑G 2 /(∑G) 2) en référence aux travaux de BLACKMAN et TUKEY. L'exposé des méthodes s'achève par l'analyse de période et ses relations avec l'analyse spectrale, puis par un bref aperçu des nouvelles méthodes d'analyse, heuristiques, imitant la démarche de l'électro encéphalographiste ou utilisant des méthodes de prédiction linéaire. Mes résultats sont divisés en trois chapitres. Dans le premier chapitre, je présente des applications de l’électroencéphalographie quantitative chez le rat. Je donne ainsi trois exemples d'utilisation du rapport des valeurs intégrées ECoG/EMG; pour la quantification des phases d’évei 1 et de sommeil, par rapport à un dépassement de seuil prédéterminé et pour l'étude de l'hypovariabilité des tracés observée après administration de substance neuroleptique. Puis, j'étudie la décomposition statistique des distributions composites polymodales des valeurs intégrées d'ECoG, calculées pour des périodes successives d'une heure. Cette analyse permet de décomposer simplement en une somme de distributions gaussiennes élémentaires les distributions polymodales. Chaque distribution élémentaire correspond alors à un état de vigilance homogène. Enfin, ce chapitre est surtout consacré à l'étude comparée de trois tracés d'ECoG occipital pour des phases homogènes d'éveil, de sommeil à ondes lentes et de sommeil paradoxal. Les quatre principales méthodes d'analyse de l'EEG ont été ainsi comparées à partir de ces trois tracés. J'ai tout d'abord vérifié les relations mathématiques établies au préalable entre la méthode intégrative et l'analyse spectrale. Par analyse de corrélation et de régression multilinéaire, j'ai pu réduire l'information pertinente à 5 paramètres indépendants entre eux. Une analyse discriminante pas à pas a alors montré que la fréquence dominante du pic spectral et l'amplitude moyenne I suffisaient à bien discriminer entre eux les trois états de vigilance analysés. Le deuxième chapitre de résultats fait état d'applications de l’électroencéphalographie quantitative chez l’homme. J'expose le programme d'analyse spectrale statistique qui <b>fonctionne</b> en temps réel, à partir de quatre dérivations enregistrées simultanément et qui utilise un double rejet d'artéfacts ainsi qu'un prétraitement des EEG échantillonnés. Après des études longitudinales de divers enregistrements quantifiés, j'ai effectué une analyse de variance à quatre facteurs pour l'étude transversale d'un ensemble de tracés de 7 sujets: 2 traitements (placebo la veille au soir et nitrazépam 5 mg, p. o. le lendemain), 2 séquences (yeux ouverts ou fermés), 4 dérivations postérieures, et les paramètres spectraux caractéristiques. Seuls, les séquences et les paramètres apparaissent significativement différents. Puis des analyses de variance à trois facteurs pour chacun des 32 paramètres spectraux caractéristiques calculés révèlent quels sont ceux qui discriminent le mieux entre les traitements: pic spectral, coefficient de résonance et de complexité, fréquences rapides, etc. Ces analyses factorielles m'ont permis de valider l'utilisation de l'épreuve du t de Student appliquée aux différences spectrales que je préconise afin de comparer entre eux deux spectres moyens de puissance dans différentes conditions: intertraitements, interséquences, interdérivations, intra et intersujets. Enfin, dans le troisième chapitre de résultats, j'ai présenté l’analyse de modulation de l’EEG, qui partant d'un signal x(t), permet d'évaluer un signal y(t), caractérisant un processus aléatoire gaussien à bande étroite à partir d'une analyse de modulation: y(t) = m(t) cos(ω 0 t + φ(t)), où m(t) est alors la modulation d'amplitude et φ(t) la modulation de phase autour d'une fréquence porteuse ω 0 = 2 πfo. Cette analyse de modulation utilise la transformée de Hilbert ˆx(t) obtenue à partir de la transformée de Fourier X(f) de x(t), par multiplication par (-j. signef) et transformation de Fourier inverse. Cela conduit directement au calcul de "l'enveloppe" m(t) de x(t), au sens radioélectrique du terme. La modulation de fréquence est obtenue directement par dérivation de la modulation de phase. J'ai appliqué cette analyse aux tracés des trois états de vigilance chez le rat. J'ai trouvé pour le rythme thêta hippocampique caractéristique du tracé de sommeil paradoxal, une modulation d'amplitude particulière ainsi qu'une modulation de fréquence qui n'apparaît pas pour les deux autres tracés analysés. Cette dernière méthode est susceptible d'être appliquée dans le cas de tracés non-stationnaires, elle conserve toute l'information du signal. Les modulations d'amplitude et de fréquence caractérisent respectivement l'amplitude et la fréquence instantanée, on connaît la difficulté de l'obtention directe de cette dernière. J'ai ainsi tenté d'élaborer une première utilisation des techniques de radioélectricité statistique en électroencéphalographie quantitative. Dans cette thèse, qui s'appuie sur 15 publications, j'ai voulu illustrer la théorie de l'analyse du signal électrobiologique par des exemples d'applications variées pris chez l’homme et l'animal. J'ai souhaité montrer en retour que de nouvelles méthodes d'analyse peuvent conduire à de nouvelles applications...|$|E
